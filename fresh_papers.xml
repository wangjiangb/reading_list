<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 23 Oct 2024 01:00:22 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>On-Device LLMs for SMEs: Challenges and Opportunities</title><link>http://arxiv.org/abs/2410.16070v2</link><description>This paper presents a systematic review of the infrastructure requirementsfor deploying Large Language Models (LLMs) on-device within the context ofsmall and medium-sized enterprises (SMEs), focusing on both hardware andsoftware perspectives. From the hardware viewpoint, we discuss the utilizationof processing units like GPUs and TPUs, efficient memory and storage solutions,and strategies for effective deployment, addressing the challenges of limitedcomputational resources typical in SME settings. From the software perspective,we explore framework compatibility, operating system optimization, and the useof specialized libraries tailored for resource-constrained environments. Thereview is structured to first identify the unique challenges faced by SMEs indeploying LLMs on-device, followed by an exploration of the opportunities thatboth hardware innovations and software adaptations offer to overcome theseobstacles. Such a structured review provides practical insights, contributingsignificantly to the community by enhancing the technological resilience ofSMEs in integrating LLMs.</description><author>Jeremy Stephen Gabriel Yee, Pai Chet Ng, Zhengkui Wang, Ian McLoughlin, Aik Beng Ng, Simon See</author><pubDate>Tue, 22 Oct 2024 13:40:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16070v2</guid></item><item><title>ExDBN: Exact learning of Dynamic Bayesian Networks</title><link>http://arxiv.org/abs/2410.16100v2</link><description>Causal learning from data has received much attention in recent years. Oneway of capturing causal relationships is by utilizing Bayesian networks. There,one recovers a weighted directed acyclic graph, in which random variables arerepresented by vertices, and the weights associated with each edge representthe strengths of the causal relationships between them. This concept isextended to capture dynamic effects by introducing a dependency on past data,which may be captured by the structural equation model, which is utilized inthe present contribution to formulate a score-based learning approach. Amixed-integer quadratic program is formulated and an algorithmic solutionproposed, in which the pre-generation of exponentially many acyclicityconstraints is avoided by utilizing the so-called branch-and-cut ("lazyconstraint") method. Comparing the novel approach to the state of the art, weshow that the proposed approach turns out to produce excellent results whenapplied to small and medium-sized synthetic instances of up to 25 time-series.Lastly, two interesting applications in bio-science and finance, to which themethod is directly applied, further stress the opportunities in developinghighly accurate, globally convergent solvers that can handle modest instances.</description><author>Pavel Rytir, Ales Wodecki, Georgios Korpas, Jakub Marecek</author><pubDate>Tue, 22 Oct 2024 12:16:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16100v2</guid></item><item><title>PROMPTHEUS: A Human-Centered Pipeline to Streamline SLRs with LLMs</title><link>http://arxiv.org/abs/2410.15978v2</link><description>The growing volume of academic publications poses significant challenges forresearchers conducting timely and accurate Systematic Literature Reviews,particularly in fast-evolving fields like artificial intelligence. This growthof academic literature also makes it increasingly difficult for lay people toaccess scientific knowledge effectively, meaning academic literature is oftenmisrepresented in the popular press and, more broadly, in society. TraditionalSLR methods are labor-intensive and error-prone, and they struggle to keep upwith the rapid pace of new research. To address these issues, we developed\textit{PROMPTHEUS}: an AI-driven pipeline solution that automates the SLRprocess using Large Language Models. We aimed to enhance efficiency by reducingthe manual workload while maintaining the precision and coherence required forcomprehensive literature synthesis. PROMPTHEUS automates key stages of the SLRprocess, including systematic search, data extraction, topic modeling usingBERTopic, and summarization with transformer models. Evaluations conductedacross five research domains demonstrate that PROMPTHEUS reduces review time,achieves high precision, and provides coherent topic organization, offering ascalable and effective solution for conducting literature reviews in anincreasingly crowded research landscape. In addition, such tools may reduce theincreasing mistrust in science by making summarization more accessible tolaypeople. The code for this project can be found on the GitHub repository athttps://github.com/joaopftorres/PROMPTHEUS.git</description><author>Jo√£o Pedro Fernandes Torres, Catherine Mulligan, Joaquim Jorge, Catarina Moreira</author><pubDate>Tue, 22 Oct 2024 10:56:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15978v2</guid></item><item><title>CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian Product Routing in Mixture-of-Experts</title><link>http://arxiv.org/abs/2410.16077v2</link><description>Large language models (LLM) have been attracting much attention from thecommunity recently, due to their remarkable performance in all kinds ofdownstream tasks. According to the well-known scaling law, scaling up a denseLLM enhances its capabilities, but also significantly increases thecomputational complexity. Mixture-of-Experts (MoE) models address that byallowing the model size to grow without substantially raising training orinference costs. Yet MoE models face challenges regarding knowledge sharingamong experts, making their performance somehow sensitive to routing accuracy.To tackle that, previous works introduced shared experts and combined theiroutputs with those of the top $K$ routed experts in an ``addition'' manner. Inthis paper, inspired by collective matrix factorization to learn sharedknowledge among data, we propose CartesianMoE, which implements more effectiveknowledge sharing among experts in more like a ``multiplication'' manner.Extensive experimental results indicate that CartesianMoE outperforms previousMoE models for building LLMs, in terms of both perplexity and downstream taskperformance. And we also find that CartesianMoE achieves better expert routingrobustness.</description><author>Zhenpeng Su, Xing Wu, Zijia Lin, Yizhe Xiong, Minxuan Lv, Guangyuan Ma, Hui Chen, Songlin Hu, Guiguang Ding</author><pubDate>Tue, 22 Oct 2024 09:37:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16077v2</guid></item><item><title>Mini-InternVL: A Flexible-Transfer Pocket Multimodal Model with 5% Parameters and 90% Performance</title><link>http://arxiv.org/abs/2410.16261v2</link><description>Multimodal large language models (MLLMs) have demonstrated impressiveperformance in vision-language tasks across a broad spectrum of domains.However, the large model scale and associated high computational costs posesignificant challenges for training and deploying MLLMs on consumer-grade GPUsor edge devices, thereby hindering their widespread application. In this work,we introduce Mini-InternVL, a series of MLLMs with parameters ranging from 1Bto 4B, which achieves 90% of the performance with only 5% of the parameters.This significant improvement in efficiency and effectiveness makes our modelsmore accessible and applicable in various real-world scenarios. To furtherpromote the adoption of our models, we develop a unified adaptation frameworkfor Mini-InternVL, which enables our models to transfer and outperformspecialized models in downstream tasks, including autonomous driving, medicalimages, and remote sensing. We believe that our study can provide valuableinsights and resources to advance the development of efficient and effectiveMLLMs. Code is available at https://github.com/OpenGVLab/InternVL.</description><author>Zhangwei Gao, Zhe Chen, Erfei Cui, Yiming Ren, Weiyun Wang, Jinguo Zhu, Hao Tian, Shenglong Ye, Junjun He, Xizhou Zhu, Lewei Lu, Tong Lu, Yu Qiao, Jifeng Dai, Wenhai Wang</author><pubDate>Tue, 22 Oct 2024 08:09:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16261v2</guid></item><item><title>Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced Extrapolation in LLMs</title><link>http://arxiv.org/abs/2410.15859v2</link><description>Large language models (LLMs), although having revolutionized many fields,still suffer from the challenging extrapolation problem, where the inferenceability of LLMs sharply declines beyond their max training lengths. In thiswork, we conduct a theoretical analysis to better understand why No PositionEncoding (NoPE) fails outside its effective range, as well as examining thepower of Position Encoding (PE) in this context. Our findings reveal that withmeticulous weave position, PE can indeed be extended beyond effective range.Our theorems establish that LLMs equipped with weave PE can achieve improvedextrapolation performance without additional cost. Furthermore, we introduce anovel weave PE method, Mesa-Extrapolation, which utilizes a chunk-basedtriangular attention matrix and applies Stair PE to manage the final chunk.This method not only retains competitive performance but also offerssubstantial benefits such as significantly reduced memory demand and fasterinference speed. Extensive experiments validate the effectiveness ofMesa-Extrapolation, demonstrating its potential as a scalable solution toenhancing LLMs applicative reach.</description><author>Xin Ma, Yang Liu, Jingjing Liu, Xiaoxu Ma</author><pubDate>Tue, 22 Oct 2024 08:00:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15859v2</guid></item><item><title>Language Model Alignment in Multilingual Trolley Problems</title><link>http://arxiv.org/abs/2407.02273v4</link><description>We evaluate the moral alignment of large language models (LLMs) with humanpreferences in multilingual trolley problems. Building on the Moral Machineexperiment, which captures over 40 million human judgments across 200+countries, we develop a cross-lingual corpus of moral dilemma vignettes in over100 languages called MultiTP. This dataset enables the assessment of LLMs'decision-making processes in diverse linguistic contexts. Our analysis exploresthe alignment of 19 different LLMs with human judgments, capturing preferencesacross six moral dimensions: species, gender, fitness, status, age, and thenumber of lives involved. By correlating these preferences with the demographicdistribution of language speakers and examining the consistency of LLMresponses to various prompt paraphrasings, our findings provide insights intocross-lingual and ethical biases of LLMs and their intersection. We discoversignificant variance in alignment across languages, challenging the assumptionof uniform moral reasoning in AI systems and highlighting the importance ofincorporating diverse perspectives in AI ethics. The results underscore theneed for further research on the integration of multilingual dimensions inresponsible AI research to ensure fair and equitable AI interactions worldwide.Our code and data are at https://github.com/causalNLP/moralmachine</description><author>Zhijing Jin, Max Kleiman-Weiner, Giorgio Piatti, Sydney Levine, Jiarui Liu, Fernando Gonzalez, Francesco Ortu, Andr√°s Strausz, Mrinmaya Sachan, Rada Mihalcea, Yejin Choi, Bernhard Sch√∂lkopf</author><pubDate>Tue, 22 Oct 2024 06:48:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.02273v4</guid></item><item><title>Granularity Matters in Long-Tail Learning</title><link>http://arxiv.org/abs/2410.15980v2</link><description>Balancing training on long-tail data distributions remains a long-standingchallenge in deep learning. While methods such as re-weighting and re-samplinghelp alleviate the imbalance issue, limited sample diversity continues tohinder models from learning robust and generalizable feature representations,particularly for tail classes. In contrast to existing methods, we offer anovel perspective on long-tail learning, inspired by an observation: datasetswith finer granularity tend to be less affected by data imbalance. In thispaper, we investigate this phenomenon through both quantitative and qualitativestudies, showing that increased granularity enhances the generalization oflearned features in tail categories. Motivated by these findings, we propose amethod to increase dataset granularity through category extrapolation.Specifically, we introduce open-set auxiliary classes that are visually similarto existing ones, aiming to enhance representation learning for both head andtail classes. This forms the core contribution and insight of our approach. Toautomate the curation of auxiliary data, we leverage large language models(LLMs) as knowledge bases to search for auxiliary categories and retrieverelevant images through web crawling. To prevent the overwhelming presence ofauxiliary classes from disrupting training, we introduce a neighbor-silencingloss that encourages the model to focus on class discrimination within thetarget dataset. During inference, the classifier weights for auxiliarycategories are masked out, leaving only the target class weights for use.Extensive experiments and ablation studies on three standard long-tailbenchmarks demonstrate the effectiveness of our approach, notably outperformingstrong baseline methods that use the same amount of data. The code will be madepublicly available.</description><author>Shizhen Zhao, Xin Wen, Jiahui Liu, Chuofan Ma, Chunfeng Yuan, Xiaojuan Qi</author><pubDate>Tue, 22 Oct 2024 06:35:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15980v2</guid></item><item><title>CamI2V: Camera-Controlled Image-to-Video Diffusion Model</title><link>http://arxiv.org/abs/2410.15957v2</link><description>Recently, camera pose, as a user-friendly and physics-related condition, hasbeen introduced into text-to-video diffusion model for camera control. However,existing methods simply inject camera conditions through a side input. Theseapproaches neglect the inherent physical knowledge of camera pose, resulting inimprecise camera control, inconsistencies, and also poor interpretability. Inthis paper, we emphasize the necessity of integrating explicit physicalconstraints into model design. Epipolar attention is proposed for modeling allcross-frame relationships from a novel perspective of noised condition. Thisensures that features are aggregated from corresponding epipolar lines in allnoised frames, overcoming the limitations of current attention mechanisms intracking displaced features across frames, especially when features movesignificantly with the camera and become obscured by noise. Additionally, weintroduce register tokens to handle cases without intersections between frames,commonly caused by rapid camera movements, dynamic objects, or occlusions. Tosupport image-to-video, we propose the multiple guidance scale to allow forprecise control for image, text, and camera, respectively. Furthermore, weestablish a more robust and reproducible evaluation pipeline to solve theinaccuracy and instability of existing camera control measurement. We achieve a25.5% improvement in camera controllability on RealEstate10K while maintainingstrong generalization to out-of-domain images. Only 24GB and 12GB are requiredfor training and inference, respectively. We plan to release checkpoints, alongwith training and evaluation codes. Dynamic videos are best viewed athttps://zgctroy.github.io/CamI2V.</description><author>Guangcong Zheng, Teng Li, Rui Jiang, Yehao Lu, Tao Wu, Xi Li</author><pubDate>Tue, 22 Oct 2024 06:26:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15957v2</guid></item><item><title>Diverse Policies Recovering via Pointwise Mutual Information Weighted Imitation Learning</title><link>http://arxiv.org/abs/2410.15910v2</link><description>Recovering a spectrum of diverse policies from a set of expert trajectoriesis an important research topic in imitation learning. After determining alatent style for a trajectory, previous diverse policies recovering methodsusually employ a vanilla behavioral cloning learning objective conditioned onthe latent style, treating each state-action pair in the trajectory with equalimportance. Based on an observation that in many scenarios, behavioral stylesare often highly relevant with only a subset of state-action pairs, this paperpresents a new principled method in diverse polices recovery. In particular,after inferring or assigning a latent style for a trajectory, we enhance thevanilla behavioral cloning by incorporating a weighting mechanism based onpointwise mutual information. This additional weighting reflects thesignificance of each state-action pair's contribution to learning the style,thus allowing our method to focus on state-action pairs most representative ofthat style. We provide theoretical justifications for our new objective, andextensive empirical evaluations confirm the effectiveness of our method inrecovering diverse policies from expert data.</description><author>Hanlin Yang, Jian Yao, Weiming Liu, Qing Wang, Hanmin Qin, Hansheng Kong, Kirk Tang, Jiechao Xiong, Chao Yu, Kai Li, Junliang Xing, Hongwu Chen, Juchao Zhuo, Qiang Fu, Yang Wei, Haobo Fu</author><pubDate>Tue, 22 Oct 2024 05:06:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15910v2</guid></item><item><title>Reducing Hallucinations in Vision-Language Models via Latent Space Steering</title><link>http://arxiv.org/abs/2410.15778v2</link><description>Hallucination poses a challenge to the deployment of large vision-languagemodels (LVLMs) in applications. Unlike in large language models (LLMs),hallucination in LVLMs often arises from misalignments between visual inputsand textual outputs. This paper investigates the underlying mechanisms ofhallucination, focusing on the unique structure of LVLMs that distinguishesthem from large language models (LLMs). We identify that hallucinations oftenarise from the sensitivity of text decoders to vision inputs, a naturalphenomenon when image encoders and text decoders are pre-trained separately.Inspired by this, we introduce Visual and Textual Intervention (VTI), a noveltechnique designed to reduce hallucinations by steering latent spacerepresentations during inference to enhance the stability of vision features.As a task-agnostic test-time intervention, VTI can be easily applied to anyproblem without additional cost. Extensive experiments demonstrate that it caneffectively reduce hallucinations and outperform baseline methods acrossmultiple metrics, highlighting the critical role of vision feature stability inLVLMs.</description><author>Sheng Liu, Haotian Ye, Lei Xing, James Zou</author><pubDate>Tue, 22 Oct 2024 05:01:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.15778v2</guid></item><item><title>Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models</title><link>http://arxiv.org/abs/2410.16152v2</link><description>Using image models naively for solving inverse video problems often suffersfrom flickering, texture-sticking, and temporal inconsistency in generatedvideos. To tackle these problems, in this paper, we view frames as continuousfunctions in the 2D space, and videos as a sequence of continuous warpingtransformations between different frames. This perspective allows us to trainfunction space diffusion models only on images and utilize them to solvetemporally correlated inverse problems. The function space diffusion modelsneed to be equivariant with respect to the underlying spatial transformations.To ensure temporal consistency, we introduce a simple post-hoc test-timeguidance towards (self)-equivariant solutions. Our method allows us to deploystate-of-the-art latent diffusion models such as Stable Diffusion XL to solvevideo inverse problems. We demonstrate the effectiveness of our method forvideo inpainting and $8\times$ video super-resolution, outperforming existingtechniques based on noise transformations. We provide generated video results:https://giannisdaras.github.io/warped_diffusion.github.io/.</description><author>Giannis Daras, Weili Nie, Karsten Kreis, Alex Dimakis, Morteza Mardani, Nikola Borislavov Kovachki, Arash Vahdat</author><pubDate>Tue, 22 Oct 2024 03:37:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16152v2</guid></item><item><title>Is the MMI Criterion Necessary for Interpretability? Degenerating Non-causal Features to Plain Noise for Self-Rationalization</title><link>http://arxiv.org/abs/2410.06003v4</link><description>An important line of research in the field of explainability is to extract asmall subset of crucial rationales from the full input. The most widely usedcriterion for rationale extraction is the maximum mutual information (MMI)criterion. However, in certain datasets, there are spurious featuresnon-causally correlated with the label and also get high mutual information,complicating the loss landscape of MMI. Although some penalty-based methodshave been developed to penalize the spurious features (e.g., invariancepenalty, intervention penalty, etc) to help MMI work better, these are merelyremedial measures. In the optimization objectives of these methods, spuriousfeatures are still distinguished from plain noise, which hinders the discoveryof causal rationales. This paper aims to develop a new criterion that treatsspurious features as plain noise, allowing the model to work on datasets richin spurious features as if it were working on clean datasets, thereby makingrationale extraction easier. We theoretically observe that removing eitherplain noise or spurious features from the input does not alter the conditionaldistribution of the remaining components relative to the task label. However,significant changes in the conditional distribution occur only when causalfeatures are eliminated. Based on this discovery, the paper proposes acriterion for \textbf{M}aximizing the \textbf{R}emaining \textbf{D}iscrepancy(MRD). Experiments on six widely used datasets show that our MRD criterionimproves rationale quality (measured by the overlap with human-annotatedrationales) by up to $10.4\%$ as compared to several recent competitive MMIvariants. Code: \url{https://github.com/jugechengzi/Rationalization-MRD}.</description><author>Wei Liu, Zhiying Deng, Zhongyu Niu, Jun Wang, Haozhao Wang, YuanKai Zhang, Ruixuan Li</author><pubDate>Tue, 22 Oct 2024 03:30:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.06003v4</guid></item><item><title>EP-SAM: Weakly Supervised Histopathology Segmentation via Enhanced Prompt with Segment Anything</title><link>http://arxiv.org/abs/2410.13621v4</link><description>This work proposes a novel approach beyond supervised learning for effectivepathological image analysis, addressing the challenge of limited robust labeleddata. Pathological diagnosis of diseases like cancer has conventionally reliedon the evaluation of morphological features by physicians and pathologists.However, recent advancements in compute-aided diagnosis (CAD) systems aregaining significant attention as diagnostic support tools. Although theadvancement of deep learning has improved CAD significantly, segmentationmodels typically require large pixel-level annotated dataset, and such labelingis expensive. Existing studies not based on supervised approaches stillstruggle with limited generalization, and no practical approach has emergedyet. To address this issue, we present a weakly supervised semanticsegmentation (WSSS) model by combining class activation map and SegmentAnything Model (SAM)-based pseudo-labeling. For effective pretraining, we adoptthe SAM-a foundation model that is pretrained on large datasets and operates inzero-shot configurations using only coarse prompts. The proposed approachtransfer enhanced Attention Dropout Layer's knowledge to SAM, therebygenerating pseudo-labels. To demonstrate the superiority of the proposedmethod, experimental studies are conducted on histopathological breast cancerdatasets. The proposed method outperformed other WSSS methods across threedatasets, demonstrating its efficiency by achieving this with only 12GB of GPUmemory during training. Our code is available at :https://github.com/QI-NemoSong/EP-SAM</description><author>Joonhyeon Song, Seohwan Yun, Seongho Yoon, Joohyeok Kim, Sangmin Lee</author><pubDate>Tue, 22 Oct 2024 01:47:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13621v4</guid></item><item><title>MvDrag3D: Drag-based Creative 3D Editing via Multi-view Generation-Reconstruction Priors</title><link>http://arxiv.org/abs/2410.16272v1</link><description>Drag-based editing has become popular in 2D content creation, driven by thecapabilities of image generative models. However, extending this technique to3D remains a challenge. Existing 3D drag-based editing methods, whetheremploying explicit spatial transformations or relying on implicit latentoptimization within limited-capacity 3D generative models, fall short inhandling significant topology changes or generating new textures across diverseobject categories. To overcome these limitations, we introduce MVDrag3D, anovel framework for more flexible and creative drag-based 3D editing thatleverages multi-view generation and reconstruction priors. At the core of ourapproach is the usage of a multi-view diffusion model as a strong generativeprior to perform consistent drag editing over multiple rendered views, which isfollowed by a reconstruction model that reconstructs 3D Gaussians of the editedobject. While the initial 3D Gaussians may suffer from misalignment betweendifferent views, we address this via view-specific deformation networks thatadjust the position of Gaussians to be well aligned. In addition, we propose amulti-view score function that distills generative priors from multiple viewsto further enhance the view consistency and visual quality. Extensiveexperiments demonstrate that MVDrag3D provides a precise, generative, andflexible solution for 3D drag-based editing, supporting more versatile editingeffects across various object categories and 3D representations.</description><author>Honghua Chen, Yushi Lan, Yongwei Chen, Yifan Zhou, Xingang Pan</author><pubDate>Mon, 21 Oct 2024 17:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16272v1</guid></item><item><title>FrugalNeRF: Fast Convergence for Few-shot Novel View Synthesis without Learned Priors</title><link>http://arxiv.org/abs/2410.16271v1</link><description>Neural Radiance Fields (NeRF) face significant challenges in few-shotscenarios, primarily due to overfitting and long training times forhigh-fidelity rendering. Existing methods, such as FreeNeRF and SparseNeRF, usefrequency regularization or pre-trained priors but struggle with complexscheduling and bias. We introduce FrugalNeRF, a novel few-shot NeRF frameworkthat leverages weight-sharing voxels across multiple scales to efficientlyrepresent scene details. Our key contribution is a cross-scale geometricadaptation scheme that selects pseudo ground truth depth based on reprojectionerrors across scales. This guides training without relying on externallylearned priors, enabling full utilization of the training data. It can alsointegrate pre-trained priors, enhancing quality without slowing convergence.Experiments on LLFF, DTU, and RealEstate-10K show that FrugalNeRF outperformsother few-shot NeRF methods while significantly reducing training time, makingit a practical solution for efficient and accurate 3D scene reconstruction.</description><author>Chin-Yang Lin, Chung-Ho Wu, Chang-Han Yeh, Shih-Han Yen, Cheng Sun, Yu-Lun Liu</author><pubDate>Mon, 21 Oct 2024 17:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16271v1</guid></item><item><title>Reflection-Bench: probing AI intelligence with reflection</title><link>http://arxiv.org/abs/2410.16270v1</link><description>The ability to adapt beliefs or behaviors in response to unexpected outcomes,reflection, is fundamental to intelligent systems' interaction with the world.From a cognitive science perspective, this serves as a core principle ofintelligence applicable to both human and AI systems. To address the debate onthe intelligence of large language models (LLMs), we propose Reflection-Bench,a comprehensive benchmark comprising 7 tasks spanning core cognitive functionscrucial for reflection, including perception, memory, belief updating,decision-making, prediction, counterfactual thinking, and meta-reflection. Weevaluate the performances of 13 prominent LLMs such as OpenAI o1, GPT-4, Claude3.5 Sonnet, etc. The results indicate that current LLMs still lack satisfactoryreflection ability. We discuss the underlying causes of these results andsuggest potential avenues for future research. In conclusion, Reflection-Benchoffers both evaluation tools and inspiration for developing AI capable ofreliably interacting with the environment. Our data and code are available athttps://github.com/YabYum/ReflectionBench.</description><author>Lingyu Li, Yixu Wang, Haiquan Zhao, Shuqi Kong, Yan Teng, Chunbo Li, Yingchun Wang</author><pubDate>Mon, 21 Oct 2024 17:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16270v1</guid></item><item><title>SAM2Long: Enhancing SAM 2 for Long Video Segmentation with a Training-Free Memory Tree</title><link>http://arxiv.org/abs/2410.16268v1</link><description>The Segment Anything Model 2 (SAM 2) has emerged as a powerful foundationmodel for object segmentation in both images and videos, paving the way forvarious downstream video applications. The crucial design of SAM 2 for videosegmentation is its memory module, which prompts object-aware memories fromprevious frames for current frame prediction. However, its greedy-selectionmemory design suffers from the "error accumulation" problem, where an erroredor missed mask will cascade and influence the segmentation of the subsequentframes, which limits the performance of SAM 2 toward complex long-term videos.To this end, we introduce SAM2Long, an improved training-free video objectsegmentation strategy, which considers the segmentation uncertainty within eachframe and chooses the video-level optimal results from multiple segmentationpathways in a constrained tree search manner. In practice, we maintain a fixednumber of segmentation pathways throughout the video. For each frame, multiplemasks are proposed based on the existing pathways, creating various candidatebranches. We then select the same fixed number of branches with highercumulative scores as the new pathways for the next frame. After processing thefinal frame, the pathway with the highest cumulative score is chosen as thefinal segmentation result. Benefiting from its heuristic search design,SAM2Long is robust toward occlusions and object reappearances, and caneffectively segment and track objects for complex long-term videos. Notably,SAM2Long achieves an average improvement of 3.0 points across all 24head-to-head comparisons, with gains of up to 5.3 points in J&amp;F on long-termvideo object segmentation benchmarks such as SA-V and LVOS. The code isreleased at https://github.com/Mark12Ding/SAM2Long.</description><author>Shuangrui Ding, Rui Qian, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Yuwei Guo, Dahua Lin, Jiaqi Wang</author><pubDate>Mon, 21 Oct 2024 17:59:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16268v1</guid></item><item><title>RILe: Reinforced Imitation Learning</title><link>http://arxiv.org/abs/2406.08472v2</link><description>Reinforcement Learning has achieved significant success in generating complexbehavior but often requires extensive reward function engineering. Adversarialvariants of Imitation Learning and Inverse Reinforcement Learning offer analternative by learning policies from expert demonstrations via adiscriminator. However, these methods struggle in complex tasks where randomlysampling expert-like behaviors is challenging. This limitation stems from theirreliance on policy-agnostic discriminators, which provide insufficient guidancefor agent improvement, especially as task complexity increases and expertbehavior becomes more distinct. We introduce RILe (Reinforced ImitationLearning environment), a novel trainer-student system that learns a dynamicreward function based on the student's performance and alignment with expertdemonstrations. In RILe, the student learns an action policy while the trainer,using reinforcement learning, continuously updates itself via thediscriminator's feedback to optimize the alignment between the student and theexpert. The trainer optimizes for long-term cumulative rewards from thediscriminator, enabling it to provide nuanced feedback that accounts for thecomplexity of the task and the student's current capabilities. This approachallows for greater exploration of agent actions by providing graduated feedbackrather than binary expert/non-expert classifications. By reducing dependence onpolicy-agnostic discriminators, RILe enables better performance in complexsettings where traditional methods falter, outperforming existing methods by 2xin complex simulated robot-locomotion tasks.</description><author>Mert Albaba, Sammy Christen, Thomas Langarek, Christoph Gebhardt, Otmar Hilliges, Michael J. Black</author><pubDate>Mon, 21 Oct 2024 17:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08472v2</guid></item><item><title>xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs</title><link>http://arxiv.org/abs/2410.16267v1</link><description>We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model forvideos, particularly designed to efficiently capture temporal information overmultiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' inaddition to the conventional visual tokenizer, which maps a sequence of tokensover multiple frames into a compact set of visual tokens. This enablesBLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32vs. 4608 tokens). We explore different types of temporal encoders, includinglearnable spatio-temporal pooling as well as sequential models like TokenTuring Machines. We experimentally confirm that BLIP-3-Video obtains videoquestion-answering accuracies comparable to much larger state-of-the-art models(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by usingfewer visual tokens. The project website is athttps://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html</description><author>Michael S. Ryoo, Honglu Zhou, Shrikant Kendre, Can Qin, Le Xue, Manli Shu, Silvio Savarese, Ran Xu, Caiming Xiong, Juan Carlos Niebles</author><pubDate>Mon, 21 Oct 2024 17:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16267v1</guid></item><item><title>3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors</title><link>http://arxiv.org/abs/2410.16266v1</link><description>Novel-view synthesis aims to generate novel views of a scene from multipleinput images or videos, and recent advancements like 3D Gaussian splatting(3DGS) have achieved notable success in producing photorealistic renderingswith efficient pipelines. However, generating high-quality novel views underchallenging settings, such as sparse input views, remains difficult due toinsufficient information in under-sampled areas, often resulting in noticeableartifacts. This paper presents 3DGS-Enhancer, a novel pipeline for enhancingthe representation quality of 3DGS representations. We leverage 2D videodiffusion priors to address the challenging 3D view consistency problem,reformulating it as achieving temporal consistency within a video generationprocess. 3DGS-Enhancer restores view-consistent latent features of renderednovel views and integrates them with the input views through a spatial-temporaldecoder. The enhanced views are then used to fine-tune the initial 3DGS model,significantly improving its rendering performance. Extensive experiments onlarge-scale datasets of unbounded scenes demonstrate that 3DGS-Enhancer yieldssuperior reconstruction performance and high-fidelity rendering resultscompared to state-of-the-art methods. The project webpage ishttps://xiliu8006.github.io/3DGS-Enhancer-project .</description><author>Xi Liu, Chaoyi Zhou, Siyu Huang</author><pubDate>Mon, 21 Oct 2024 17:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16266v1</guid></item><item><title>Mini-InternVL: A Flexible-Transfer Pocket Multimodal Model with 5% Parameters and 90% Performance</title><link>http://arxiv.org/abs/2410.16261v1</link><description>Multimodal large language models (MLLMs) have demonstrated impressiveperformance in vision-language tasks across a broad spectrum of domains.However, the large model scale and associated high computational costs posesignificant challenges for training and deploying MLLMs on consumer-grade GPUsor edge devices, thereby hindering their widespread application. In this work,we introduce Mini-InternVL, a series of MLLMs with parameters ranging from 1Bto 4B, which achieves 90% of the performance with only 5% of the parameters.This significant improvement in efficiency and effectiveness makes our modelsmore accessible and applicable in various real-world scenarios. To furtherpromote the adoption of our models, we develop a unified adaptation frameworkfor Mini-InternVL, which enables our models to transfer and outperformspecialized models in downstream tasks, including autonomous driving, medicalimages, and remote sensing. We believe that our study can provide valuableinsights and resources to advance the development of efficient and effectiveMLLMs. Code is available at https://github.com/OpenGVLab/InternVL.</description><author>Zhangwei Gao, Zhe Chen, Erfei Cui, Yiming Ren, Weiyun Wang, Jinguo Zhu, Hao Tian, Shenglong Ye, Junjun He, Xizhou Zhu, Lewei Lu, Tong Lu, Yu Qiao, Jifeng Dai, Wenhai Wang</author><pubDate>Mon, 21 Oct 2024 17:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16261v1</guid></item><item><title>Agent-to-Sim: Learning Interactive Behavior Models from Casual Longitudinal Videos</title><link>http://arxiv.org/abs/2410.16259v1</link><description>We present Agent-to-Sim (ATS), a framework for learning interactive behaviormodels of 3D agents from casual longitudinal video collections. Different fromprior works that rely on marker-based tracking and multiview cameras, ATSlearns natural behaviors of animal and human agents non-invasively throughvideo observations recorded over a long time-span (e.g., a month) in a singleenvironment. Modeling 3D behavior of an agent requires persistent 3D tracking(e.g., knowing which point corresponds to which) over a long time period. Toobtain such data, we develop a coarse-to-fine registration method that tracksthe agent and the camera over time through a canonical 3D space, resulting in acomplete and persistent spacetime 4D representation. We then train a generativemodel of agent behaviors using paired data of perception and motion of an agentqueried from the 4D reconstruction. ATS enables real-to-sim transfer from videorecordings of an agent to an interactive behavior simulator. We demonstrateresults on pets (e.g., cat, dog, bunny) and human given monocular RGBD videoscaptured by a smartphone.</description><author>Gengshan Yang, Andrea Bajcsy, Shunsuke Saito, Angjoo Kanazawa</author><pubDate>Mon, 21 Oct 2024 17:57:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16259v1</guid></item><item><title>Elucidating the design space of language models for image generation</title><link>http://arxiv.org/abs/2410.16257v1</link><description>The success of autoregressive (AR) language models in text generation hasinspired the computer vision community to adopt Large Language Models (LLMs)for image generation. However, considering the essential differences betweentext and image modalities, the design space of language models for imagegeneration remains underexplored. We observe that image tokens exhibit greaterrandomness compared to text tokens, which presents challenges when trainingwith token prediction. Nevertheless, AR models demonstrate their potential byeffectively learning patterns even from a seemingly suboptimal optimizationproblem. Our analysis also reveals that while all models successfully grasp theimportance of local information in image generation, smaller models struggle tocapture the global context. In contrast, larger models showcase improvedcapabilities in this area, helping to explain the performance gains achievedwhen scaling up model size. We further elucidate the design space of languagemodels for vision generation, including tokenizer choice, model choice, modelscalability, vocabulary design, and sampling strategy through extensivecomparative experiments. Our work is the first to analyze the optimizationbehavior of language models in vision generation, and we believe it can inspiremore effective designs when applying LMs to other domains. Finally, ourelucidated language model for image generation, termed as ELM, achievesstate-of-the-art performance on the ImageNet 256*256 benchmark. The code isavailable at https://github.com/Pepperlll/LMforImageGeneration.git.</description><author>Xuantong Liu, Shaozhe Hao, Xianbiao Qi, Tianyang Hu, Jun Wang, Rong Xiao, Yuan Yao</author><pubDate>Mon, 21 Oct 2024 17:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16257v1</guid></item><item><title>CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution</title><link>http://arxiv.org/abs/2410.16256v1</link><description>Efficient and accurate evaluation is crucial for the continuous improvementof large language models (LLMs). Among various assessment methods, subjectiveevaluation has garnered significant attention due to its superior alignmentwith real-world usage scenarios and human preferences. However, human-basedevaluations are costly and lack reproducibility, making precise automatedevaluators (judgers) vital in this process. In this report, we introduce\textbf{CompassJudger-1}, the first open-source \textbf{all-in-one} judge LLM.CompassJudger-1 is a general-purpose LLM that demonstrates remarkableversatility. It is capable of: 1. Performing unitary scoring and two-modelcomparisons as a reward model; 2. Conducting evaluations according to specifiedformats; 3. Generating critiques; 4. Executing diverse tasks like a generalLLM. To assess the evaluation capabilities of different judge models under aunified setting, we have also established \textbf{JudgerBench}, a new benchmarkthat encompasses various subjective evaluation tasks and covers a wide range oftopics. CompassJudger-1 offers a comprehensive solution for various evaluationtasks while maintaining the flexibility to adapt to diverse requirements. BothCompassJudger and JudgerBench are released and available to the researchcommunity athttps://github.com/open-compass/CompassJudger. We believe that byopen-sourcing these tools, we can foster collaboration and accelerate progressin LLM evaluation methodologies.</description><author>Maosong Cao, Alexander Lam, Haodong Duan, Hongwei Liu, Songyang Zhang, Kai Chen</author><pubDate>Mon, 21 Oct 2024 17:56:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16256v1</guid></item><item><title>Revisiting Deep Feature Reconstruction for Logical and Structural Industrial Anomaly Detection</title><link>http://arxiv.org/abs/2410.16255v1</link><description>Industrial anomaly detection is crucial for quality control and predictivemaintenance, but it presents challenges due to limited training data, diverseanomaly types, and external factors that alter object appearances. Existingmethods commonly detect structural anomalies, such as dents and scratches, byleveraging multi-scale features from image patches extracted through deeppre-trained networks. However, significant memory and computational demandsoften limit their practical application. Additionally, detecting logicalanomalies-such as images with missing or excess elements-requires anunderstanding of spatial relationships that traditional patch-based methodsfail to capture. In this work, we address these limitations by focusing on DeepFeature Reconstruction (DFR), a memory- and compute-efficient approach fordetecting structural anomalies. We further enhance DFR into a unifiedframework, called ULSAD, which is capable of detecting both structural andlogical anomalies. Specifically, we refine the DFR training objective toimprove performance in structural anomaly detection, while introducing anattention-based loss mechanism using a global autoencoder-like network tohandle logical anomaly detection. Our empirical evaluation across fivebenchmark datasets demonstrates the performance of ULSAD in detecting andlocalizing both structural and logical anomalies, outperforming eightstate-of-the-art methods. An extensive ablation study further highlights thecontribution of each component to the overall performance improvement. Our codeis available at https://github.com/sukanyapatra1997/ULSAD-2024.git</description><author>Sukanya Patra, Souhaib Ben Taieb</author><pubDate>Mon, 21 Oct 2024 17:56:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16255v1</guid></item><item><title>Distribution Learning with Valid Outputs Beyond the Worst-Case</title><link>http://arxiv.org/abs/2410.16253v1</link><description>Generative models at times produce "invalid" outputs, such as images withgeneration artifacts and unnatural sounds. Validity-constrained distributionlearning attempts to address this problem by requiring that the learneddistribution have a provably small fraction of its mass in invalid parts ofspace -- something which standard loss minimization does not always ensure. Tothis end, a learner in this model can guide the learning via "validityqueries", which allow it to ascertain the validity of individual examples.Prior work on this problem takes a worst-case stance, showing that properlearning requires an exponential number of validity queries, and demonstratingan improper algorithm which -- while generating guarantees in a wide-range ofsettings -- makes an atypical polynomial number of validity queries. In thiswork, we take a first step towards characterizing regimes where guaranteeingvalidity is easier than in the worst-case. We show that when the datadistribution lies in the model class and the log-loss is minimized, the numberof samples required to ensure validity has a weak dependence on the validityrequirement. Additionally, we show that when the validity region belongs to aVC-class, a limited number of validity queries are often sufficient.</description><author>Nick Rittler, Kamalika Chaudhuri</author><pubDate>Mon, 21 Oct 2024 17:56:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16253v1</guid></item><item><title>Can Knowledge Editing Really Correct Hallucinations?</title><link>http://arxiv.org/abs/2410.16251v1</link><description>Large Language Models (LLMs) suffer from hallucinations, referring to thenon-factual information in generated content, despite their superior capacitiesacross tasks. Meanwhile, knowledge editing has been developed as a new popularparadigm to correct the erroneous factual knowledge encoded in LLMs with theadvantage of avoiding retraining from scratch. However, one common issue ofexisting evaluation datasets for knowledge editing is that they do not ensureLLMs actually generate hallucinated answers to the evaluation questions beforeediting. When LLMs are evaluated on such datasets after being edited bydifferent techniques, it is hard to directly adopt the performance to assessthe effectiveness of different knowledge editing methods in correctinghallucinations. Thus, the fundamental question remains insufficientlyvalidated: Can knowledge editing really correct hallucinations in LLMs? Weproposed HalluEditBench to holistically benchmark knowledge editing methods incorrecting real-world hallucinations. First, we rigorously construct a massivehallucination dataset with 9 domains, 26 topics and more than 6,000hallucinations. Then, we assess the performance of knowledge editing methods ina holistic way on five dimensions including Efficacy, Generalization,Portability, Locality, and Robustness. Through HalluEditBench, we have providednew insights into the potentials and limitations of different knowledge editingmethods in correcting hallucinations, which could inspire future improvementsand facilitate the progress in the field of knowledge editing.</description><author>Baixiang Huang, Canyu Chen, Xiongxiao Xu, Ali Payani, Kai Shu</author><pubDate>Mon, 21 Oct 2024 17:55:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16251v1</guid></item><item><title>Implicit Regularization for Tubal Tensor Factorizations via Gradient Descent</title><link>http://arxiv.org/abs/2410.16247v1</link><description>We provide a rigorous analysis of implicit regularization in anoverparametrized tensor factorization problem beyond the lazy training regime.For matrix factorization problems, this phenomenon has been studied in a numberof works. A particular challenge has been to design universal initializationstrategies which provably lead to implicit regularization in gradient-descentmethods. At the same time, it has been argued by Cohen et. al. 2016 that moregeneral classes of neural networks can be captured by considering tensorfactorizations. However, in the tensor case, implicit regularization has onlybeen rigorously established for gradient flow or in the lazy training regime.In this paper, we prove the first tensor result of its kind for gradientdescent rather than gradient flow. We focus on the tubal tensor product and theassociated notion of low tubal rank, encouraged by the relevance of this modelfor image data. We establish that gradient descent in an overparametrizedtensor factorization model with a small random initialization exhibits animplicit bias towards solutions of low tubal rank. Our theoretical findings areillustrated in an extensive set of numerical simulations show-casing thedynamics predicted by our theory as well as the crucial role of using a smallrandom initialization.</description><author>Santhosh Karnik, Anna Veselovska, Mark Iwen, Felix Krahmer</author><pubDate>Mon, 21 Oct 2024 17:52:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16247v1</guid></item><item><title>Analyzing Context Contributions in LLM-based Machine Translation</title><link>http://arxiv.org/abs/2410.16246v1</link><description>Large language models (LLMs) have achieved state-of-the-art performance inmachine translation (MT) and demonstrated the ability to leverage in-contextlearning through few-shot examples. However, the mechanisms by which LLMs usedifferent parts of the input context remain largely unexplored. In this work,we provide a comprehensive analysis of context utilization in MT, studying howLLMs use various context parts, such as few-shot examples and the source text,when generating translations. We highlight several key findings: (1) the sourcepart of few-shot examples appears to contribute more than its correspondingtargets, irrespective of translation direction; (2) finetuning LLMs withparallel data alters the contribution patterns of different context parts; and(3) there is a positional bias where earlier few-shot examples have highercontributions to the translated sequence. Finally, we demonstrate thatinspecting anomalous context contributions can potentially uncover pathologicaltranslations, such as hallucinations. Our findings shed light on the internalworkings of LLM-based MT which go beyond those known for standardencoder-decoder MT models.</description><author>Emmanouil Zaranis, Nuno M. Guerreiro, Andr√© F. T. Martins</author><pubDate>Mon, 21 Oct 2024 17:51:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16246v1</guid></item><item><title>Comparing the information content of probabilistic representation spaces</title><link>http://arxiv.org/abs/2405.21042v2</link><description>Probabilistic representation spaces convey information about a dataset, andto understand the effects of factors such as training loss and networkarchitecture, we seek to compare the information content of such spaces.However, most existing methods to compare representation spaces assumerepresentations are points, and neglect the distributional nature ofprobabilistic representations. Here, instead of building upon point-basedmeasures of comparison, we build upon classic methods from literature on hardclustering. We generalize two information-theoretic methods of comparing hardclustering assignments to be applicable to general probabilistic representationspaces. We then propose a practical method of estimation that is based onfingerprinting a representation space with a sample of the dataset and isapplicable when the communicated information is only a handful of bits. Withunsupervised disentanglement as a motivating problem, we find informationfragments that are repeatedly contained in individual latent dimensions in VAEand InfoGAN ensembles. Then, by comparing the full latent spaces of models, wefind highly consistent information content across datasets, methods, andhyperparameters, even though there is often a point during training withsubstantial variety across repeat runs. Finally, we leverage thedifferentiability of the proposed method and perform model fusion bysynthesizing the information content of multiple weak learners, each incapableof representing the global structure of a dataset. Across the case studies, thedirect comparison of information content provides a natural basis forunderstanding the processing of information.</description><author>Kieran A. Murphy, Sam Dillavou, Dani S. Bassett</author><pubDate>Mon, 21 Oct 2024 17:50:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.21042v2</guid></item><item><title>MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays, ECGs, and Diagnostic Report</title><link>http://arxiv.org/abs/2410.16239v1</link><description>In this paper, we introduce a novel Multi-Modal Contrastive Pre-trainingFramework that synergistically combines X-rays, electrocardiograms (ECGs), andradiology/cardiology reports. Our approach leverages transformers to encodethese diverse modalities into a unified representation space, aiming to enhancediagnostic accuracy and facilitate comprehensive patient assessments. Weutilize LoRA-Peft to significantly reduce trainable parameters in the LLM andincorporate recent linear attention dropping strategy in the VisionTransformer(ViT) for smoother attention. Furthermore, we provide novelmultimodal attention explanations and retrieval for our model. To the best ofour knowledge, we are the first to propose an integrated model that combinesX-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizingcontrastive loss, MoRE effectively aligns modality-specific features into acoherent embedding, which supports various downstream tasks such as zero-shotclassification and multimodal retrieval. Employing our proposed methodology, weachieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, andPtbXl downstream datasets, surpassing existing multimodal approaches. Ourproposed framework shows significant improvements in capturing intricateinter-modal relationships and its robustness in medical diagnosis thatestablishes a framework for future research in multimodal learning in thehealthcare sector.</description><author>Samrajya Thapa, Koushik Howlader, Subhankar Bhattacharjee, Wei le</author><pubDate>Mon, 21 Oct 2024 17:42:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16239v1</guid></item><item><title>Deep Radiomics Detection of Clinically Significant Prostate Cancer on Multicenter MRI: Initial Comparison to PI-RADS Assessment</title><link>http://arxiv.org/abs/2410.16238v1</link><description>Objective: To develop and evaluate a deep radiomics model for clinicallysignificant prostate cancer (csPCa, grade group &gt;= 2) detection and compare itsperformance to Prostate Imaging Reporting and Data System (PI-RADS) assessmentin a multicenter cohort. Materials and Methods: This retrospective studyanalyzed biparametric (T2W and DW) prostate MRI sequences of 615 patients (meanage, 63.1 +/- 7 years) from four datasets acquired between 2010 and 2020:PROSTATEx challenge, Prostate158 challenge, PCaMAP trial, and an in-house(NTNU/St. Olavs Hospital) dataset. With expert annotations as ground truth, adeep radiomics model was trained, including nnU-Net segmentation of theprostate gland, voxel-wise radiomic feature extraction, extreme gradient boostclassification, and post-processing of tumor probability maps into csPCadetection maps. Training involved 5-fold cross-validation using the PROSTATEx(n=199), Prostate158 (n=138), and PCaMAP (n=78) datasets, and testing on thein-house (n=200) dataset. Patient- and lesion-level performance were comparedto PI-RADS using area under ROC curve (AUROC [95% CI]), sensitivity, andspecificity analysis. Results: On the test data, the radiologist achieved apatient-level AUROC of 0.94 [0.91-0.98] with 94% (75/80) sensitivity and 77%(92/120) specificity at PI-RADS &gt;= 3. The deep radiomics model at a tumorprobability cut-off &gt;= 0.76 achieved 0.91 [0.86-0.95] AUROC with 90% (72/80)sensitivity and 73% (87/120) specificity, not significantly different (p =0.068) from PI-RADS. On the lesion level, PI-RADS cut-off &gt;= 3 had 84% (91/108)sensitivity at 0.2 (40/200) false positives per patient, while deep radiomicsattained 68% (73/108) sensitivity at the same false positive rate. Conclusion:Deep radiomics machine learning model achieved comparable performance toPI-RADS assessment in csPCa detection at the patient-level but not at thelesion-level.</description><author>G. A. Nketiah, M. R. Sunoqrot, E. Sandsmark, S. Lang√∏rgen, K. M. Seln√¶s, H. Bertilsson, M. Elschot, T. F. Bathen</author><pubDate>Mon, 21 Oct 2024 17:41:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16238v1</guid></item><item><title>LLaVA-KD: A Framework of Distilling Multimodal Large Language Models</title><link>http://arxiv.org/abs/2410.16236v1</link><description>The success of Large Language Models (LLM) has led researchers to exploreMultimodal Large Language Models (MLLM) for unified visual and linguisticunderstanding. However, the increasing model size and computational complexityof MLLM limit their use in resource-constrained environments. Small-scale MLLM(s-MLLM) aims to retain the capabilities of the large-scale model (l-MLLM)while reducing computational demands, but resulting in a significant decline inperformance. To address the aforementioned issues, we propose a novel LLaVA-KDframework to transfer knowledge from l-MLLM to s-MLLM. Specifically, weintroduce Multimodal Distillation (MDist) to minimize the divergence betweenthe visual-textual output distributions of l-MLLM and s-MLLM, and RelationDistillation (RDist) to transfer l-MLLM's ability to model correlations betweenvisual features. Additionally, we propose a three-stage training scheme tofully exploit the potential of s-MLLM: 1) Distilled Pre-Training to alignvisual-textual representations, 2) Supervised Fine-Tuning to equip the modelwith multimodal understanding, and 3) Distilled Fine-Tuning to further transferl-MLLM capabilities. Our approach significantly improves performance withoutaltering the small model's architecture. Extensive experiments and ablationstudies validate the effectiveness of each proposed component. Code will beavailable at https://github.com/caiyuxuan1120/LLaVA-KD.</description><author>Yuxuan Cai, Jiangning Zhang, Haoyang He, Xinwei He, Ao Tong, Zhenye Gan, Chengjie Wang, Xiang Bai</author><pubDate>Mon, 21 Oct 2024 17:41:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16236v1</guid></item><item><title>ToW: Thoughts of Words Improve Reasoning in Large Language Models</title><link>http://arxiv.org/abs/2410.16235v1</link><description>We introduce thoughts of words (ToW), a novel training-time data-augmentationmethod for next-word prediction. ToW views next-word prediction as a corereasoning task and injects fine-grained thoughts explaining what the next wordshould be and how it is related to the previous contexts in pre-training texts.Our formulation addresses two fundamental drawbacks of existing next-wordprediction learning schemes: they induce factual hallucination and areinefficient for models to learn the implicit reasoning processes in raw texts.While there are many ways to acquire such thoughts of words, we explore thefirst step of acquiring ToW annotations through distilling from larger models.After continual pre-training with only 70K ToW annotations, we effectivelyimprove models' reasoning performances by 7% to 9% on average and reduce modelhallucination by up to 10%. At the same time, ToW is entirely agnostic to tasksand applications, introducing no additional biases on labels or semantics.</description><author>Zhikun Xu, Ming Shen, Jacob Dineen, Zhaonan Li, Xiao Ye, Shijie Lu, Aswin RRV, Chitta Baral, Ben Zhou</author><pubDate>Mon, 21 Oct 2024 17:41:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16235v1</guid></item><item><title>Sketch2Code: Evaluating Vision-Language Models for Interactive Web Design Prototyping</title><link>http://arxiv.org/abs/2410.16232v1</link><description>Sketches are a natural and accessible medium for UI designers toconceptualize early-stage ideas. However, existing research on UI/UX automationoften requires high-fidelity inputs like Figma designs or detailed screenshots,limiting accessibility and impeding efficient design iteration. To bridge thisgap, we introduce Sketch2Code, a benchmark that evaluates state-of-the-artVision Language Models (VLMs) on automating the conversion of rudimentarysketches into webpage prototypes. Beyond end-to-end benchmarking, Sketch2Codesupports interactive agent evaluation that mimics real-world design workflows,where a VLM-based agent iteratively refines its generations by communicatingwith a simulated user, either passively receiving feedback instructions orproactively asking clarification questions. We comprehensively analyze tencommercial and open-source models, showing that Sketch2Code is challenging forexisting VLMs; even the most capable models struggle to accurately interpretsketches and formulate effective questions that lead to steady improvement.Nevertheless, a user study with UI/UX experts reveals a significant preferencefor proactive question-asking over passive feedback reception, highlighting theneed to develop more effective paradigms for multi-turn conversational agents.</description><author>Ryan Li, Yanzhe Zhang, Diyi Yang</author><pubDate>Mon, 21 Oct 2024 17:39:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16232v1</guid></item><item><title>Language Model Alignment in Multilingual Trolley Problems</title><link>http://arxiv.org/abs/2407.02273v3</link><description>We evaluate the moral alignment of large language models (LLMs) with humanpreferences in multilingual trolley problems. Building on the Moral Machineexperiment, which captures over 40 million human judgments across 200+countries, we develop a cross-lingual corpus of moral dilemma vignettes in over100 languages called MultiTP. This dataset enables the assessment of LLMs'decision-making processes in diverse linguistic contexts. Our analysis exploresthe alignment of 19 different LLMs with human judgments, capturing preferencesacross six moral dimensions: species, gender, fitness, status, age, and thenumber of lives involved. By correlating these preferences with the demographicdistribution of language speakers and examining the consistency of LLMresponses to various prompt paraphrasings, our findings provide insights intocross-lingual and ethical biases of LLMs and their intersection. We discoversignificant variance in alignment across languages, challenging the assumptionof uniform moral reasoning in AI systems and highlighting the importance ofincorporating diverse perspectives in AI ethics. The results underscore theneed for further research on the integration of multilingual dimensions inresponsible AI research to ensure fair and equitable AI interactions worldwide.Our code and data are at https://github.com/causalNLP/moralmachine</description><author>Zhijing Jin, Max Kleiman-Weiner, Giorgio Piatti, Sydney Levine, Jiarui Liu, Fernando Gonzalez, Francesco Ortu, Andr√°s Strausz, Mrinmaya Sachan, Rada Mihalcea, Yejin Choi, Bernhard Sch√∂lkopf</author><pubDate>Mon, 21 Oct 2024 17:37:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.02273v3</guid></item><item><title>Building A Coding Assistant via the Retrieval-Augmented Language Model</title><link>http://arxiv.org/abs/2410.16229v1</link><description>Pretrained language models have shown strong effectiveness in code-relatedtasks, such as code retrieval, code generation, code summarization, and codecompletion tasks. In this paper, we propose COde assistaNt viAretrieval-augmeNted language model (CONAN), which aims to build a codeassistant by mimicking the knowledge-seeking behaviors of humans during coding.Specifically, it consists of a code structure aware retriever (CONAN-R) and adual-view code representation-based retrieval-augmented generation model(CONAN-G). CONAN-R pretrains CodeT5 using Code-Documentation Alignment andMasked Entity Prediction tasks to make language models code structure-aware andlearn effective representations for code snippets and documentation. ThenCONAN-G designs a dual-view code representation mechanism for implementing aretrieval-augmented code generation model. CONAN-G regards the codedocumentation descriptions as prompts, which help language models betterunderstand the code semantics. Our experiments show that CONAN achievesconvincing performance on different code generation tasks and significantlyoutperforms previous retrieval augmented code generation models. Our furtheranalyses show that CONAN learns tailored representations for both code snippetsand documentation by aligning code-documentation data pairs and capturingstructural semantics by masking and predicting entities in the code data.Additionally, the retrieved code snippets and documentation provide necessaryinformation from both program language and natural language to assist the codegeneration process. CONAN can also be used as an assistant for Large LanguageModels (LLMs), providing LLMs with external knowledge in shorter code documentlengths to improve their effectiveness on various code tasks. It shows theability of CONAN to extract necessary information and help filter out the noisefrom retrieved code documents.</description><author>Xinze Li, Hanbin Wang, Zhenghao Liu, Shi Yu, Shuo Wang, Shuo Wang, Yukun Yan, Yukai Fu, Yu Gu, Ge Yu</author><pubDate>Mon, 21 Oct 2024 17:34:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16229v1</guid></item><item><title>Hypergraph: A Unified and Uniform Definition with Application to Chemical Hypergraph and More</title><link>http://arxiv.org/abs/2405.12235v6</link><description>The conventional definition of hypergraph has two major issues: (1) there isnot a standard definition of directed hypergraph and (2) there is not a formaldefinition of nested hypergraph. To resolve these issues, we propose a newdefinition of hypergraph that unifies the concepts of undirected, directed andnested hypergraphs, and that is uniform in using hyperedge as a singleconstruct for representing high-order correlations among things, i.e., nodesand hyperedges. Specifically, we define a hyperedge to be a simple hyperedge, anesting hyperedge, or a directed hyperedge. With this new definition, ahypergraph is nested if it has nesting hyperedge(s), and is directed if it hasdirected hyperedge(s). Otherwise, a hypergraph is a simple hypergraph. Theuniformity and power of this new definition, with visualization, shouldfacilitate the use of hypergraph for representing (hierarchical) high-ordercorrelations in general and chemical systems in particular. Graph has beenwidely used as a mathematical structure for machine learning on molecularstructures and 3D molecular geometries. However, graph has a major limitation:it can represent only pairwise correlations between nodes. Hypergraph extendsgraph with high-order correlations among nodes. This extension is significantor essential for machine learning on chemical systems. For molecules, this issignificant as it allows the direct, explicit representation of multicenterbonds and molecular substructures. For chemical reactions, this is essentialsince most chemical reactions involve multiple participants. We propose the useof chemical hypergraph, a multilevel hypergraph with simple, nesting anddirected hyperedges, as a single mathematical structure for representingchemical systems. We apply the new definition of hypergraph to chemicalhypergraph and, as simplified versions, molecular hypergraph and chemicalreaction hypergraph.</description><author>Daniel T. Chang</author><pubDate>Mon, 21 Oct 2024 17:34:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.12235v6</guid></item><item><title>Managing Bandwidth: The Key to Cloud-Assisted Autonomous Driving</title><link>http://arxiv.org/abs/2410.16227v1</link><description>Prevailing wisdom asserts that one cannot rely on the cloud for criticalreal-time control systems like self-driving cars. We argue that we can, andmust. Following the trends of increasing model sizes, improvements in hardware,and evolving mobile networks, we identify an opportunity to offload parts oftime-sensitive and latency-critical compute to the cloud. Doing so requirescarefully allocating bandwidth to meet strict latency SLOs, while maximizingbenefit to the car.</description><author>Alexander Krentsel, Peter Schafhalter, Joseph E. Gonzalez, Sylvia Ratnasamy, Scott Shenker, Ion Stoica</author><pubDate>Mon, 21 Oct 2024 17:32:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16227v1</guid></item><item><title>A Realistic Threat Model for Large Language Model Jailbreaks</title><link>http://arxiv.org/abs/2410.16222v1</link><description>A plethora of jailbreaking attacks have been proposed to obtain harmfulresponses from safety-tuned LLMs. In their original settings, these methods alllargely succeed in coercing the target output, but their attacks varysubstantially in fluency and computational effort. In this work, we propose aunified threat model for the principled comparison of these methods. Our threatmodel combines constraints in perplexity, measuring how far a jailbreakdeviates from natural text, and computational budget, in total FLOPs. For theformer, we build an N-gram model on 1T tokens, which, in contrast tomodel-based perplexity, allows for an LLM-agnostic and inherently interpretableevaluation. We adapt popular attacks to this new, realistic threat model, withwhich we, for the first time, benchmark these attacks on equal footing. After arigorous comparison, we not only find attack success rates against safety-tunedmodern models to be lower than previously presented but also find that attacksbased on discrete optimization significantly outperform recent LLM-basedattacks. Being inherently interpretable, our threat model allows for acomprehensive analysis and comparison of jailbreak attacks. We find thateffective attacks exploit and abuse infrequent N-grams, either selectingN-grams absent from real-world text or rare ones, e.g. specific to codedatasets.</description><author>Valentyn Boreiko, Alexander Panfilov, Vaclav Voracek, Matthias Hein, Jonas Geiping</author><pubDate>Mon, 21 Oct 2024 17:27:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16222v1</guid></item><item><title>Bidirectional Decoding: Improving Action Chunking via Closed-Loop Resampling</title><link>http://arxiv.org/abs/2408.17355v2</link><description>Predicting and executing a sequence of actions without intermediatereplanning, known as action chunking, is increasingly used in robot learningfrom human demonstrations. Yet, its reported effects on the learned policy areinconsistent: some studies find it crucial for achieving strong results, whileothers observe decreased performance. In this paper, we first dissect howaction chunking impacts the divergence between a learner and a demonstrator. Wefind that action chunking allows the learner to better capture the temporaldependencies in demonstrations but at the cost of reduced reactivity instochastic environments. To address this tradeoff, we propose BidirectionalDecoding (BID), a test-time inference algorithm that bridges action chunkingwith closed-loop operations. BID samples multiple predictions at each time stepand searches for the optimal one based on two criteria: (i) backward coherence,which favors samples that align with previous decisions; (ii) forward contrast,which seeks samples of high likelihood for future plans. By coupling decisionswithin and across action chunks, BID promotes consistency over time whilemaintaining reactivity to unexpected changes. Experimental results show thatBID boosts the performance of two state-of-the-art generative policies acrossseven simulation benchmarks and two real-world tasks. Code and videos areavailable at https://bid-robot.github.io.</description><author>Yuejiang Liu, Jubayer Ibn Hamid, Annie Xie, Yoonho Lee, Maximilian Du, Chelsea Finn</author><pubDate>Mon, 21 Oct 2024 17:27:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17355v2</guid></item><item><title>Decomposing and Interpreting Image Representations via Text in ViTs Beyond CLIP</title><link>http://arxiv.org/abs/2406.01583v2</link><description>Recent work has explored how individual components of the CLIP-ViT modelcontribute to the final representation by leveraging the shared image-textrepresentation space of CLIP. These components, such as attention heads andMLPs, have been shown to capture distinct image features like shape, color ortexture. However, understanding the role of these components in arbitraryvision transformers (ViTs) is challenging. To this end, we introduce a generalframework which can identify the roles of various components in ViTs beyondCLIP. Specifically, we (a) automate the decomposition of the finalrepresentation into contributions from different model components, and (b)linearly map these contributions to CLIP space to interpret them via text.Additionally, we introduce a novel scoring function to rank components by theirimportance with respect to specific features. Applying our framework to variousViT variants (e.g. DeiT, DINO, DINOv2, Swin, MaxViT), we gain insights into theroles of different components concerning particular image features. Theseinsights facilitate applications such as image retrieval using textdescriptions or reference images, visualizing token importance heatmaps, andmitigating spurious correlations. We release our code to reproduce theexperiments at https://github.com/SriramB-98/vit-decompose</description><author>Sriram Balasubramanian, Samyadeep Basu, Soheil Feizi</author><pubDate>Mon, 21 Oct 2024 17:25:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01583v2</guid></item><item><title>On Creating an English-Thai Code-switched Machine Translation in Medical Domain</title><link>http://arxiv.org/abs/2410.16221v1</link><description>Machine translation (MT) in the medical domain plays a pivotal role inenhancing healthcare quality and disseminating medical knowledge. Despiteadvancements in English-Thai MT technology, common MT approaches oftenunderperform in the medical field due to their inability to precisely translatemedical terminologies. Our research prioritizes not merely improvingtranslation accuracy but also maintaining medical terminology in English withinthe translated text through code-switched (CS) translation. We developed amethod to produce CS medical translation data, fine-tuned a CS translationmodel with this data, and evaluated its performance against strong baselines,such as Google Neural Machine Translation (NMT) and GPT-3.5/GPT-4. Our modeldemonstrated competitive performance in automatic metrics and was highlyfavored in human preference evaluations. Our evaluation result also shows thatmedical professionals significantly prefer CS translations that maintaincritical English terms accurately, even if it slightly compromises fluency. Ourcode and test set are publicly availablehttps://github.com/preceptorai-org/NLLB_CS_EM_NLP2024.</description><author>Parinthapat Pengpun, Krittamate Tiankanon, Amrest Chinkamol, Jiramet Kinchagawat, Pitchaya Chairuengjitjaras, Pasit Supholkhan, Pubordee Aussavavirojekul, Chiraphat Boonnag, Kanyakorn Veerakanjana, Hirunkul Phimsiri, Boonthicha Sae-jia, Nattawach Sataudom, Piyalitt Ittichaiwong, Peerat Limkonchotiwat</author><pubDate>Mon, 21 Oct 2024 17:25:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16221v1</guid></item><item><title>Generation through the lens of learning theory</title><link>http://arxiv.org/abs/2410.13714v2</link><description>We study generation through the lens of statistical learning theory. First,we abstract and formalize the results of Gold [1967], Angluin [1979, 1980], andKleinberg and Mullainathan [2024] for language identification/generation in thelimit in terms of a binary hypothesis class defined over an abstract instancespace. Then, we formalize a different paradigm of generation studied byKleinberg and Mullainathan [2024], which we call ``uniform generation," andprovide a characterization of which hypothesis classes are uniformlygeneratable. As is standard in statistical learning theory, ourcharacterization is in terms of the finiteness of a new combinatorial dimensionwe call the Closure dimension. By doing so, we are able to comparegeneratability with predictability (captured via PAC and online learnability)and show that these two properties of hypothesis classes are\emph{incompatible} - there are classes that are generatable but notpredictable and vice versa.</description><author>Vinod Raman, Ambuj Tewari</author><pubDate>Mon, 21 Oct 2024 17:21:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13714v2</guid></item><item><title>Pre-training Distillation for Large Language Models: A Design Space Exploration</title><link>http://arxiv.org/abs/2410.16215v1</link><description>Knowledge distillation (KD) aims to transfer knowledge from a large teachermodel to a smaller student model. Previous work applying KD in the field oflarge language models (LLMs) typically focused on the post-training phase,where the student LLM learns directly from instructions and correspondingresponses generated by the teacher model. In this paper, we extend KD to thepre-training phase of LLMs, named pre-training distillation (PD). We firstconduct a preliminary experiment using GLM-4-9B as the teacher LLM to distill a1.9B parameter student LLM, validating the effectiveness of PD. Considering thekey impact factors of distillation, we systematically explore the design spaceof pre-training distillation across four aspects: logits processing, lossselection, scaling law, and offline or online logits. We conduct extensiveexperiments to explore the design space of pre-training distillation and findbetter configurations and interesting conclusions, such as larger student LLMsgenerally benefiting more from pre-training distillation, while a largerteacher LLM does not necessarily guarantee better results. We hope ourexploration of the design space will inform future practices in pre-trainingdistillation.</description><author>Hao Peng, Xin Lv, Yushi Bai, Zijun Yao, Jiajie Zhang, Lei Hou, Juanzi Li</author><pubDate>Mon, 21 Oct 2024 17:16:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16215v1</guid></item><item><title>Asymmetries in Financial Spillovers</title><link>http://arxiv.org/abs/2410.16214v1</link><description>This paper analyzes nonlinearities in the international transmission offinancial shocks originating in the US. To do so, we develop a flexiblenonlinear multi-country model. Our framework is capable of producingasymmetries in the responses to financial shocks for shock size and sign, andover time. We show that international reactions to US-based financial shocksare asymmetric along these dimensions. Particularly, we find that adverseshocks trigger stronger declines in output, inflation, and stock markets thanbenign shocks. Further, we investigate time variation in the estimated dynamiceffects and characterize the responsiveness of three major central banks tofinancial shocks.</description><author>Florian Huber, Karin Klieber, Massimiliano Marcellino, Luca Onorante, Michael Pfarrhofer</author><pubDate>Mon, 21 Oct 2024 17:14:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16214v1</guid></item><item><title>Comprehensive benchmarking of large language models for RNA secondary structure prediction</title><link>http://arxiv.org/abs/2410.16212v1</link><description>Inspired by the success of large language models (LLM) for DNA and proteins,several LLM for RNA have been developed recently. RNA-LLM uses large datasetsof RNA sequences to learn, in a self-supervised way, how to represent each RNAbase with a semantically rich numerical vector. This is done under thehypothesis that obtaining high-quality RNA representations can enhancedata-costly downstream tasks. Among them, predicting the secondary structure isa fundamental task for uncovering RNA functional mechanisms. In this work wepresent a comprehensive experimental analysis of several pre-trained RNA-LLM,comparing them for the RNA secondary structure prediction task in an unifieddeep learning framework. The RNA-LLM were assessed with increasinggeneralization difficulty on benchmark datasets. Results showed that two LLMclearly outperform the other models, and revealed significant challenges forgeneralization in low-homology scenarios.</description><author>L. I. Zablocki, L. A. Bugnon, M. Gerard, L. Di Persia, G. Stegmayer, D. H. Milone</author><pubDate>Mon, 21 Oct 2024 17:12:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16212v1</guid></item><item><title>Compute-Constrained Data Selection</title><link>http://arxiv.org/abs/2410.16208v1</link><description>Data selection can reduce the amount of training data needed to finetuneLLMs; however, the efficacy of data selection scales directly with its compute.Motivated by the practical challenge of compute-constrained finetuning, weconsider the setting in which both the cost of selecting data and training arebudgeted for. We first formalize the problem of data selection with acost-aware utility function, and model the data selection problem as tradingoff initial-selection cost for training gain. We run a comprehensive sweep ofexperiments across multiple tasks, varying compute budget by scaling finetuningtokens, model sizes, and data selection compute. These experiments show thevalidity of this model in real-world experiments. Interestingly we find thatmany powerful data selection methods are almost never compute-optimal, and thatcheaper data selection alternatives dominate both from a theoretical andempirical perspective.</description><author>Junjie Oscar Yin, Alexander M. Rush</author><pubDate>Mon, 21 Oct 2024 17:11:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16208v1</guid></item><item><title>CoT-TL: Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning</title><link>http://arxiv.org/abs/2410.16207v1</link><description>Autonomous agents often face the challenge of interpreting uncertain naturallanguage instructions for planning tasks. Representing these instructions asLinear Temporal Logic (LTL) enables planners to synthesize actionable plans. Weintroduce CoT-TL, a data-efficient in-context learning framework fortranslating natural language specifications into LTL representations. CoT-TLaddresses the limitations of large language models, which typically rely onextensive fine-tuning data, by extending chain-of-thought reasoning andsemantic roles to align with the requirements of formal logic creation. Thisapproach enhances the transparency and rationale behind LTL generation,fostering user trust. CoT-TL achieves state-of-the-art accuracy across threediverse datasets in low-data scenarios, outperforming existing methods withoutfine-tuning or intermediate translations. To improve reliability and minimizehallucinations, we incorporate model checking to validate the syntax of thegenerated LTL output. We further demonstrate CoT-TL's effectiveness throughablation studies and evaluations on unseen LTL structures and formulas in a newdataset. Finally, we validate CoT-TL's practicality by integrating it into aQuadCopter for multi-step drone planning based on natural languageinstructions.</description><author>Kumar Manas, Stefan Zwicklbauer, Adrian Paschke</author><pubDate>Mon, 21 Oct 2024 17:10:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16207v1</guid></item><item><title>Systematic Review: Text Processing Algorithms in Machine Learning and Deep Learning for Mental Health Detection on Social Media</title><link>http://arxiv.org/abs/2410.16204v1</link><description>The global rise in depression necessitates innovative detection methods forearly intervention. Social media provides a unique opportunity to identifydepression through user-generated posts. This systematic review evaluatesmachine learning (ML) models for depression detection on social media, focusingon biases and methodological challenges throughout the ML lifecycle. A searchof PubMed, IEEE Xplore, and Google Scholar identified 47 relevant studiespublished after 2010. The Prediction model Risk Of Bias ASsessment Tool(PROBAST) was utilized to assess methodological quality and risk of bias.Significant biases impacting model reliability and generalizability were found.There is a predominant reliance on Twitter (63.8%) and English-language content(over 90%), with most studies focusing on users from the United States andEurope. Non-probability sampling methods (approximately 80%) limitrepresentativeness. Only 23% of studies explicitly addressed linguistic nuanceslike negations, crucial for accurate sentiment analysis. Inconsistenthyperparameter tuning was observed, with only 27.7% properly tuning models.About 17% did not adequately partition data into training, validation, and testsets, risking overfitting. While 74.5% used appropriate evaluation metrics forimbalanced data, others relied on accuracy without addressing class imbalance,potentially skewing results. Reporting transparency varied, often lackingcritical methodological details. These findings highlight the need to diversifydata sources, standardize preprocessing protocols, ensure consistent modeldevelopment practices, address class imbalance, and enhance reportingtransparency. By overcoming these challenges, future research can develop morerobust and generalizable ML models for depression detection on social media,contributing to improved mental health outcomes globally.</description><author>Yuchen Cao, Jianglai Dai, Zhongyan Wang, Yeyubei Zhang, Xiaorui Shen, Yunchong Liu, Yexin Tian</author><pubDate>Mon, 21 Oct 2024 17:05:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16204v1</guid></item><item><title>Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys</title><link>http://arxiv.org/abs/2405.19323v2</link><description>Can large language models (LLMs) simulate social surveys? To answer thisquestion, we conducted millions of simulations in which LLMs were asked toanswer subjective questions. A comparison of different LLM responses with theEuropean Social Survey (ESS) data suggests that the effect of prompts on biasand variability is fundamental, highlighting major cultural, age, and genderbiases. We further discussed statistical methods for measuring the differencebetween LLM answers and survey data and proposed a novel measure inspired byJaccard similarity, as LLM-generated responses are likely to have a smallervariance. Our experiments also reveal that it is important to analyze therobustness and variability of prompts before using LLMs to simulate socialsurveys, as their imitation abilities are approximate at best.</description><author>Mingmeng Geng, Sihong He, Roberto Trotta</author><pubDate>Mon, 21 Oct 2024 17:05:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19323v2</guid></item><item><title>Theoretical Limitations of Ensembles in the Age of Overparameterization</title><link>http://arxiv.org/abs/2410.16201v1</link><description>Classic tree-based ensembles generalize better than any single decision tree.In contrast, recent empirical studies find that modern ensembles of(overparameterized) neural networks may not provide any inherent generalizationadvantage over single but larger neural networks. This paper clarifies howmodern overparameterized ensembles differ from their classic underparameterizedcounterparts, using ensembles of random feature (RF) regressors as a basis fordeveloping theory. In contrast to the underparameterized regime, whereensembling typically induces regularization and increases generalization, weprove that infinite ensembles of overparameterized RF regressors becomepointwise equivalent to (single) infinite-width RF regressors. Thisequivalence, which is exact for ridgeless models and approximate for smallridge penalties, implies that overparameterized ensembles and single largemodels exhibit nearly identical generalization. As a consequence, we cancharacterize the predictive variance amongst ensemble members, and demonstratethat it quantifies the expected effects of increasing capacity rather thancapturing any conventional notion of uncertainty. Our results challenge commonassumptions about the advantages of ensembles in overparameterized settings,prompting a reconsideration of how well intuitions from underparameterizedensembles transfer to deep ensembles and the overparameterized regime.</description><author>Niclas Dern, John P. Cunningham, Geoff Pleiss</author><pubDate>Mon, 21 Oct 2024 17:03:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16201v1</guid></item><item><title>Improve Vision Language Model Chain-of-thought Reasoning</title><link>http://arxiv.org/abs/2410.16198v1</link><description>Chain-of-thought (CoT) reasoning in vision language models (VLMs) is crucialfor improving interpretability and trustworthiness. However, current trainingrecipes lack robust CoT reasoning data, relying on datasets dominated by shortannotations with minimal rationales. In this work, we show that training VLM onshort answers does not generalize well to reasoning tasks that require moredetailed responses. To address this, we propose a two-fold approach. First, wedistill rationales from GPT-4o model to enrich the training data and fine-tuneVLMs, boosting their CoT performance. Second, we apply reinforcement learningto further calibrate reasoning quality. Specifically, we construct positive(correct) and negative (incorrect) pairs of model-generated reasoning chains,by comparing their predictions with annotated short answers. Using thispairwise data, we apply the Direct Preference Optimization algorithm to refinethe model's reasoning abilities. Our experiments demonstrate significantimprovements in CoT reasoning on benchmark datasets and better generalizationto direct answer prediction as well. This work emphasizes the importance ofincorporating detailed rationales in training and leveraging reinforcementlearning to strengthen the reasoning capabilities of VLMs.</description><author>Ruohong Zhang, Bowen Zhang, Yanghao Li, Haotian Zhang, Zhiqing Sun, Zhe Gan, Yinfei Yang, Ruoming Pang, Yiming Yang</author><pubDate>Mon, 21 Oct 2024 17:00:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16198v1</guid></item><item><title>Information for Conversation Generation: Proposals Utilising Knowledge Graphs</title><link>http://arxiv.org/abs/2410.16196v1</link><description>LLMs are frequently used tools for conversational generation. Withoutadditional information LLMs can generate lower quality responses due to lackingrelevant content and hallucinations, as well as the perception of pooremotional capability, and an inability to maintain a consistent character.Knowledge graphs are commonly used forms of external knowledge and may providesolutions to these challenges. This paper introduces three proposals, utilizingknowledge graphs to enhance LLM generation. Firstly, dynamic knowledge graphembeddings and recommendation could allow for the integration of newinformation and the selection of relevant knowledge for response generation.Secondly, storing entities with emotional values as additional features mayprovide knowledge that is better emotionally aligned with the user input.Thirdly, integrating character information through narrative bubbles wouldmaintain character consistency, as well as introducing a structure that wouldreadily incorporate new information.</description><author>Alex Clay, Ernesto Jim√©nez-Ruiz</author><pubDate>Mon, 21 Oct 2024 16:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16196v1</guid></item><item><title>A Trust-Region Method for Graphical Stein Variational Inference</title><link>http://arxiv.org/abs/2410.16195v1</link><description>Stein variational inference (SVI) is a sample-based approximate Bayesianinference technique that generates a sample set by jointly optimizing thesamples' locations to minimize an information-theoretic measure of discrepancywith the target probability distribution. SVI thus provides a fast andsignificantly more sample-efficient approach to Bayesian inference thantraditional (random-sampling-based) alternatives. However, the optimizationtechniques employed in existing SVI methods struggle to address problems inwhich the target distribution is high-dimensional, poorly-conditioned, ornon-convex, which severely limits the range of their practical applicability.In this paper, we propose a novel trust-region optimization approach for SVIthat successfully addresses each of these challenges. Our method builds uponprior work in SVI by leveraging conditional independences in the targetdistribution (to achieve high-dimensional scaling) and second-order information(to address poor conditioning), while additionally providing an effectiveadaptive step control procedure, which is essential for ensuring convergence onchallenging non-convex optimization problems. Experimental results show ourmethod achieves superior numerical performance, both in convergence rate andsample accuracy, and scales better in high-dimensional distributions, thanprevious SVI techniques.</description><author>Liam Pavlovic, David M. Rosen</author><pubDate>Mon, 21 Oct 2024 16:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16195v1</guid></item><item><title>IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards for Better Well-Being</title><link>http://arxiv.org/abs/2406.13791v3</link><description>Sustainable Development Goals (SDGs) give the UN a road map for developmentwith Agenda 2030 as a target. SDG3 "Good Health and Well-Being" ensures healthylives and promotes well-being for all ages. Digital technologies can supportSDG3. Burnout and even depression could be reduced by encouraging betterpreventive health. Due to the lack of patient knowledge and focus to take careof their health, it is necessary to help patients before it is too late. Newtrends such as positive psychology and mindfulness are highly encouraged in theUSA. Digital Twins (DTs) can help with the continuous monitoring of emotionusing physiological signals (e.g., collected via wearables). DTs facilitatemonitoring and provide constant health insight to improve quality of life andwell-being with better personalization. Healthcare DTs challenges arestandardizing data formats, communication protocols, and data exchangemechanisms. As an example, ISO has the ISO/IEC JTC 1/SC 41 Internet of Things(IoT) and DTs Working Group, with standards such as "ISO/IEC 21823-3:2021 IoT -Interoperability for IoT Systems - Part 3 Semantic interoperability", "ISO/IECCD 30178 - IoT - Data format, value and coding". To achieve those dataintegration and knowledge challenges, we designed the Mental Health KnowledgeGraph (ontology and dataset) to boost mental health. As an example, explicitknowledge is described such as chocolate contains magnesium which isrecommended for depression. The Knowledge Graph (KG) acquires knowledge fromontology-based mental health projects classified within the LOV4IoT ontologycatalog (Emotion, Depression, and Mental Health). Furthermore, the KG is mappedto standards when possible. Standards from ETSI SmartM2M can be used such asSAREF4EHAW to represent medical devices and sensors, but also ITU/WHO, ISO,W3C, NIST, and IEEE standards relevant to mental health can be considered.</description><author>Amelie Gyrard, Seyedali Mohammadi, Manas Gaur, Antonio Kung</author><pubDate>Mon, 21 Oct 2024 16:55:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13791v3</guid></item><item><title>Training Better Deep Learning Models Using Human Saliency</title><link>http://arxiv.org/abs/2410.16190v1</link><description>This work explores how human judgement about salient regions of an image canbe introduced into deep convolutional neural network (DCNN) training.Traditionally, training of DCNNs is purely data-driven. This often results inlearning features of the data that are only coincidentally correlated withclass labels. Human saliency can guide network training using our proposed newcomponent of the loss function that ConveYs Brain Oversight to RaiseGeneralization (CYBORG) and penalizes the model for using non-salient regions.This mechanism produces DCNNs achieving higher accuracy and generalizationcompared to using the same training data without human salience. Experimentalresults demonstrate that CYBORG applies across multiple network architecturesand problem domains (detection of synthetic faces, iris presentation attacksand anomalies in chest X-rays), while requiring significantly less data thantraining without human saliency guidance. Visualizations show thatCYBORG-trained models' saliency is more consistent across independent trainingruns than traditionally-trained models, and also in better agreement withhumans. To lower the cost of collecting human annotations, we also exploreusing deep learning to provide automated annotations. CYBORG training of CNNsaddresses important issues such as reducing the appetite for large trainingsets, increasing interpretability, and reducing fragility by generalizingbetter to new types of data.</description><author>Aidan Boyd, Patrick Tinsley, Kevin W. Bowyer, Adam Czajka</author><pubDate>Mon, 21 Oct 2024 16:52:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16190v1</guid></item><item><title>Harmful Fine-tuning Attacks and Defenses for Large Language Models: A Survey</title><link>http://arxiv.org/abs/2409.18169v3</link><description>Recent research demonstrates that the nascent fine-tuning-as-a-servicebusiness model exposes serious safety concerns -- fine-tuning over a fewharmful data uploaded by the users can compromise the safety alignment of themodel. The attack, known as harmful fine-tuning, has raised a broad researchinterest among the community. However, as the attack is still new, \textbf{weobserve from our miserable submission experience that there are generalmisunderstandings within the research community.} We in this paper aim to clearsome common concerns for the attack setting, and formally establish theresearch problem. Specifically, we first present the threat model of theproblem, and introduce the harmful fine-tuning attack and its variants. Then wesystematically survey the existing literature on attacks/defenses/mechanicalanalysis of the problem. Finally, we outline future research directions thatmight contribute to the development of the field. Additionally, we present alist of questions of interest, which might be useful to refer to when reviewersin the peer review process question the realism of theexperiment/attack/defense setting. A curated list of relevant papers ismaintained and made accessible at:\url{https://github.com/git-disl/awesome_LLM-harmful-fine-tuning-papers}.</description><author>Tiansheng Huang, Sihao Hu, Fatih Ilhan, Selim Furkan Tekin, Ling Liu</author><pubDate>Mon, 21 Oct 2024 16:51:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.18169v3</guid></item><item><title>Contamination Report for Multilingual Benchmarks</title><link>http://arxiv.org/abs/2410.16186v1</link><description>Benchmark contamination refers to the presence of test datasets in LargeLanguage Model (LLM) pre-training or post-training data. Contamination can leadto inflated scores on benchmarks, compromising evaluation results and making itdifficult to determine the capabilities of models. In this work, we study thecontamination of popular multilingual benchmarks in LLMs that support multiplelanguages. We use the Black Box test to determine whether $7$ frequently usedmultilingual benchmarks are contaminated in $7$ popular open and closed LLMsand find that almost all models show signs of being contaminated with almostall the benchmarks we test. Our findings can help the community determine thebest set of benchmarks to use for multilingual evaluation.</description><author>Sanchit Ahuja, Varun Gumma, Sunayana Sitaram</author><pubDate>Mon, 21 Oct 2024 16:49:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16186v1</guid></item><item><title>RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style</title><link>http://arxiv.org/abs/2410.16184v1</link><description>Reward models are critical in techniques like Reinforcement Learning fromHuman Feedback (RLHF) and Inference Scaling Laws, where they guide languagemodel alignment and select optimal responses. Despite their importance,existing reward model benchmarks often evaluate models by asking them todistinguish between responses generated by models of varying power. However,this approach fails to assess reward models on subtle but critical contentchanges and variations in style, resulting in a low correlation with policymodel performance. To this end, we introduce RM-Bench, a novel benchmarkdesigned to evaluate reward models based on their sensitivity to subtle contentdifferences and resistance to style biases. Extensive experiments demonstratethat RM-Bench strongly correlates with policy model performance, making it areliable reference for selecting reward models to align language modelseffectively. We evaluate nearly 40 reward models on RM-Bench. Our resultsreveal that even state-of-the-art models achieve an average performance of only46.6%, which falls short of random-level accuracy (50%) when faced with stylebias interference. These findings highlight the significant room forimprovement in current reward models. Related code and data are available athttps://github.com/THU-KEG/RM-Bench.</description><author>Yantao Liu, Zijun Yao, Rui Min, Yixin Cao, Lei Hou, Juanzi Li</author><pubDate>Mon, 21 Oct 2024 16:48:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16184v1</guid></item><item><title>SleeperNets: Universal Backdoor Poisoning Attacks Against Reinforcement Learning Agents</title><link>http://arxiv.org/abs/2405.20539v2</link><description>Reinforcement learning (RL) is an actively growing field that is seeingincreased usage in real-world, safety-critical applications -- making itparamount to ensure the robustness of RL algorithms against adversarialattacks. In this work we explore a particularly stealthy form of training-timeattacks against RL -- backdoor poisoning. Here the adversary intercepts thetraining of an RL agent with the goal of reliably inducing a particular actionwhen the agent observes a pre-determined trigger at inference time. We uncovertheoretical limitations of prior work by proving their inability to generalizeacross domains and MDPs. Motivated by this, we formulate a novel poisoningattack framework which interlinks the adversary's objectives with those offinding an optimal policy -- guaranteeing attack success in the limit. Usinginsights from our theoretical analysis we develop ``SleeperNets'' as auniversal backdoor attack which exploits a newly proposed threat model andleverages dynamic reward poisoning techniques. We evaluate our attack in 6environments spanning multiple domains and demonstrate significant improvementsin attack success over existing methods, while preserving benign episodicreturn.</description><author>Ethan Rathbun, Christopher Amato, Alina Oprea</author><pubDate>Mon, 21 Oct 2024 16:44:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20539v2</guid></item><item><title>MagicPIG: LSH Sampling for Efficient LLM Generation</title><link>http://arxiv.org/abs/2410.16179v1</link><description>Large language models (LLMs) with long context windows have gainedsignificant attention. However, the KV cache, stored to avoid re-computation,becomes a bottleneck. Various dynamic sparse or TopK-based attentionapproximation methods have been proposed to leverage the common insight thatattention is sparse. In this paper, we first show that TopK attention itselfsuffers from quality degradation in certain downstream tasks because attentionis not always as sparse as expected. Rather than selecting the keys and valueswith the highest attention scores, sampling with theoretical guarantees canprovide a better estimation for attention output. To make the sampling-basedapproximation practical in LLM generation, we propose MagicPIG, a heterogeneoussystem based on Locality Sensitive Hashing (LSH). MagicPIG significantlyreduces the workload of attention computation while preserving high accuracyfor diverse tasks. MagicPIG stores the LSH hash tables and runs the attentioncomputation on the CPU, which allows it to serve longer contexts and largerbatch sizes with high approximation accuracy. MagicPIG can improve decodingthroughput by $1.9\sim3.9\times$ across various GPU hardware and achieve 110msdecoding latency on a single RTX 4090 for Llama-3.1-8B-Instruct model with acontext of 96k tokens. The code is available at\url{https://github.com/Infini-AI-Lab/MagicPIG}.</description><author>Zhuoming Chen, Ranajoy Sadhukhan, Zihao Ye, Yang Zhou, Jianyu Zhang, Niklas Nolte, Yuandong Tian, Matthijs Douze, Leon Bottou, Zhihao Jia, Beidi Chen</author><pubDate>Mon, 21 Oct 2024 16:44:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16179v1</guid></item><item><title>A Framework for Evaluating Predictive Models Using Synthetic Image Covariates and Longitudinal Data</title><link>http://arxiv.org/abs/2410.16177v1</link><description>We present a novel framework for synthesizing patient data with complexcovariates (e.g., eye scans) paired with longitudinal observations (e.g.,visual acuity over time), addressing privacy concerns in healthcare research.Our approach introduces controlled association in latent spaces generating eachdata modality, enabling the creation of complex covariate-longitudinalobservation pairs. This framework facilitates the development of predictivemodels and provides openly available benchmarking datasets for healthcareresearch. We demonstrate our framework using optical coherence tomography (OCT)scans, though it is applicable across domains. Using 109,309 2D OCT scanslices, we trained an image generative model combining a variationalautoencoder and a diffusion model. Longitudinal observations were simulatedusing a nonlinear mixed effect (NLME) model from a low-dimensional space ofrandom effects. We generated 1.1M OCT scan slices paired with five sets oflongitudinal observations at controlled association levels (100%, 50%, 10%,5.26%, and 2% of between-subject variability). To assess the framework, wemodeled synthetic longitudinal observations with another NLME model, computedempirical Bayes estimates of random effects, and trained a ResNet to predictthese estimates from synthetic OCT scans. We then incorporated ResNetpredictions into the NLME model for patient-individualized predictions.Prediction accuracy on withheld data declined as intended with reducedassociation between images and longitudinal measurements. Notably, in all butthe 2% case, we achieved within 50% of the theoretical best possible predictionon withheld data, demonstrating our ability to detect even weak signals. Thisconfirms the effectiveness of our framework in generating synthetic data withcontrolled levels of association, providing a valuable tool for healthcareresearch.</description><author>Simon Deltadahl, Andreu Vall, Vijay Ivaturi, Niklas Korsbo</author><pubDate>Mon, 21 Oct 2024 16:43:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16177v1</guid></item><item><title>Spiking Neural Networks as a Controller for Emergent Swarm Agents</title><link>http://arxiv.org/abs/2410.16175v1</link><description>Drones which can swarm and loiter in a certain area cost hundreds of dollars,but mosquitos can do the same and are essentially worthless. To control swarmsof low-cost robots, researchers may end up spending countless hoursbrainstorming robot configurations and policies to ``organically" createbehaviors which do not need expensive sensors and perception. Existing researchexplores the possible emergent behaviors in swarms of robots with only a binarysensor and a simple but hand-picked controller structure. Even agents in thishighly limited sensing, actuation, and computational capability class canexhibit relatively complex global behaviors such as aggregation, milling, anddispersal, but finding the local interaction rules that enable more collectivebehaviors remains a significant challenge. This paper investigates thefeasibility of training spiking neural networks to find those local interactionrules that result in particular emergent behaviors. In this paper, we focus onsimulating a specific milling behavior already known to be producible usingvery simple binary sensing and acting agents. To do this, we use evolutionaryalgorithms to evolve not only the parameters (the weights, biases, and delays)of a spiking neural network, but also its structure. To create a baseline, wealso show an evolutionary search strategy over the parameters for the incumbenthand-picked binary controller structure. Our simulations show that spikingneural networks can be evolved in binary sensing agents to form a mill.</description><author>Kevin Zhu, Connor Mattson, Shay Snyder, Ricardo Vega, Daniel S. Brown, Maryam Parsa, Cameron Nowzari</author><pubDate>Mon, 21 Oct 2024 16:41:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16175v1</guid></item><item><title>This Too Shall Pass: Removing Stale Observations in Dynamic Bayesian Optimization</title><link>http://arxiv.org/abs/2405.14540v2</link><description>Bayesian Optimization (BO) has proven to be very successful at optimizing astatic, noisy, costly-to-evaluate black-box function $f : \mathcal{S} \to\mathbb{R}$. However, optimizing a black-box which is also a function of time(i.e., a dynamic function) $f : \mathcal{S} \times \mathcal{T} \to \mathbb{R}$remains a challenge, since a dynamic Bayesian Optimization (DBO) algorithm hasto keep track of the optimum over time. This changes the nature of theoptimization problem in at least three aspects: (i) querying an arbitrary pointin $\mathcal{S} \times \mathcal{T}$ is impossible, (ii) past observationsbecome less and less relevant for keeping track of the optimum as time goes byand (iii) the DBO algorithm must have a high sampling frequency so it cancollect enough relevant observations to keep track of the optimum through time.In this paper, we design a Wasserstein distance-based criterion able toquantify the relevancy of an observation with respect to future predictions.Then, we leverage this criterion to build W-DBO, a DBO algorithm able to removeirrelevant observations from its dataset on the fly, thus maintainingsimultaneously a good predictive performance and a high sampling frequency,even in continuous-time optimization tasks with unknown horizon. Numericalexperiments establish the superiority of W-DBO, which outperformsstate-of-the-art methods by a comfortable margin.</description><author>Anthony Bardou, Patrick Thiran, Giovanni Ranieri</author><pubDate>Mon, 21 Oct 2024 16:40:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14540v2</guid></item><item><title>The First VoicePrivacy Attacker Challenge Evaluation Plan</title><link>http://arxiv.org/abs/2410.07428v2</link><description>The First VoicePrivacy Attacker Challenge is a new kind of challengeorganized as part of the VoicePrivacy initiative and supported by ICASSP 2025as the SP Grand Challenge It focuses on developing attacker systems againstvoice anonymization, which will be evaluated against a set of anonymizationsystems submitted to the VoicePrivacy 2024 Challenge. Training, development,and evaluation datasets are provided along with a baseline attacker system.Participants shall develop their attacker systems in the form of automaticspeaker verification systems and submit their scores on the development andevaluation data to the organizers. To do so, they can use any additionaltraining data and models, provided that they are openly available and declaredbefore the specified deadline. The metric for evaluation is equal error rate(EER). Results will be presented at the ICASSP 2025 special session to which 5selected top-ranked participants will be invited to submit and present theirchallenge systems.</description><author>Natalia Tomashenko, Xiaoxiao Miao, Emmanuel Vincent, Junichi Yamagishi</author><pubDate>Mon, 21 Oct 2024 16:37:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07428v2</guid></item><item><title>Learning How to Vote With Principles: Axiomatic Insights Into the Collective Decisions of Neural Networks</title><link>http://arxiv.org/abs/2410.16170v1</link><description>Can neural networks be applied in voting theory, while satisfying the needfor transparency in collective decisions? We propose axiomatic deep voting: aframework to build and evaluate neural networks that aggregate preferences,using the well-established axiomatic method of voting theory. Our findings are:(1) Neural networks, despite being highly accurate, often fail to align withthe core axioms of voting rules, revealing a disconnect between mimickingoutcomes and reasoning. (2) Training with axiom-specific data does not enhancealignment with those axioms. (3) By solely optimizing axiom satisfaction,neural networks can synthesize new voting rules that often surpass andsubstantially differ from existing ones. This offers insights for both fields:For AI, important concepts like bias and value-alignment are studied in amathematically rigorous way; for voting theory, new areas of the space ofvoting rules are explored.</description><author>Levin Hornischer, Zoi Terzopoulou</author><pubDate>Mon, 21 Oct 2024 16:35:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16170v1</guid></item><item><title>Differentiable Optimization of Similarity Scores Between Models and Brains</title><link>http://arxiv.org/abs/2407.07059v2</link><description>How do we know if two systems - biological or artificial - processinformation in a similar way? Similarity measures such as linear regression,Centered Kernel Alignment (CKA), Normalized Bures Similarity (NBS), and angularProcrustes distance, are often used to quantify this similarity. However, it iscurrently unclear what drives high similarity scores and even what constitutesa "good" score. Here, we introduce a novel tool to investigate these questionsby differentiating through similarity measures to directly maximize the score.Surprisingly, we find that high similarity scores do not guarantee encodingtask-relevant information in a manner consistent with neural data; and this isparticularly acute for CKA and even some variations of cross-validated andregularized linear regression. We find no consistent threshold for a goodsimilarity score - it depends on both the measure and the dataset. In addition,synthetic datasets optimized to maximize similarity scores initially learn thehighest variance principal component of the target dataset, but some methodslike angular Procrustes capture lower variance dimensions much earlier thanmethods like CKA. To shed light on this, we mathematically derive thesensitivity of CKA, angular Procrustes, and NBS to the variance of principalcomponent dimensions, and explain the emphasis CKA places on high variancecomponents. Finally, by jointly optimizing multiple similarity measures, wecharacterize their allowable ranges and reveal that some similarity measuresare more constraining than others. While current measures offer a seeminglystraightforward way to quantify the similarity between neural systems, our workunderscores the need for careful interpretation. We hope the tools we developedwill be used by practitioners to better understand current and futuresimilarity measures.</description><author>Nathan Cloos, Moufan Li, Markus Siegel, Scott L. Brincat, Earl K. Miller, Guangyu Robert Yang, Christopher J. Cueva</author><pubDate>Mon, 21 Oct 2024 16:34:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07059v2</guid></item><item><title>Exploring Pretraining via Active Forgetting for Improving Cross Lingual Transfer for Decoder Language Models</title><link>http://arxiv.org/abs/2410.16168v1</link><description>Large Language Models (LLMs) demonstrate exceptional capabilities in amultitude of NLP tasks. However, the efficacy of such models to languages otherthan English is often limited. Prior works have shown that encoder-only modelssuch as BERT or XLM-RoBERTa show impressive cross lingual transfer of theircapabilities from English to other languages. In this work, we propose apretraining strategy that uses active forgetting to achieve similar crosslingual transfer in decoder-only LLMs. We show that LLMs pretrained with activeforgetting are highly effective when adapting to new and unseen languages.Through extensive experimentation, we find that LLMs pretrained with activeforgetting are able to learn better multilingual representations whichtranslates to better performance in many downstream tasks.</description><author>Divyanshu Aggarwal, Ashutosh Sathe, Sunayana Sitaram</author><pubDate>Mon, 21 Oct 2024 16:33:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16168v1</guid></item><item><title>Beyond Filtering: Adaptive Image-Text Quality Enhancement for MLLM Pretraining</title><link>http://arxiv.org/abs/2410.16166v1</link><description>Multimodal large language models (MLLMs) have made significant strides byintegrating visual and textual modalities. A critical factor in training MLLMsis the quality of image-text pairs within multimodal pretraining datasets.However, $\textit {de facto}$ filter-based data quality enhancement paradigmsoften discard a substantial portion of high-quality image data due toinadequate semantic alignment between images and texts, leading toinefficiencies in data utilization and scalability. In this paper, we proposethe Adaptive Image-Text Quality Enhancer (AITQE), a model that dynamicallyassesses and enhances the quality of image-text pairs. AITQE employs a textrewriting mechanism for low-quality pairs and incorporates a negative samplelearning strategy to improve evaluative capabilities by integratingdeliberately selected low-quality samples during training. Unlike priorapproaches that significantly alter text distributions, our method minimallyadjusts text to preserve data volume while enhancing quality. Experimentalresults demonstrate that AITQE surpasses existing methods on various benchmark,effectively leveraging raw data and scaling efficiently with increasing datavolumes. We hope our work will inspire future works. The code and model areavailable at: https://github.com/hanhuang22/AITQE.</description><author>Han Huang, Yuqi Huo, Zijia Zhao, Haoyu Lu, Shu Wu, Bingning Wang, Qiang Liu, Weipeng Chen, Liang Wang</author><pubDate>Mon, 21 Oct 2024 16:32:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16166v1</guid></item><item><title>Adaptive $Q$-Network: On-the-fly Target Selection for Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2405.16195v2</link><description>Deep Reinforcement Learning (RL) is well known for being highly sensitive tohyperparameters, requiring practitioners substantial efforts to optimize themfor the problem at hand. This also limits the applicability of RL in real-worldscenarios. In recent years, the field of automated Reinforcement Learning(AutoRL) has grown in popularity by trying to address this issue. However,these approaches typically hinge on additional samples to selectwell-performing hyperparameters, hindering sample-efficiency and practicality.Furthermore, most AutoRL methods are heavily based on already existing AutoMLmethods, which were originally developed neglecting the additional challengesinherent to RL due to its non-stationarities. In this work, we propose a newapproach for AutoRL, called Adaptive $Q$-Network (AdaQN), that is tailored toRL to take into account the non-stationarity of the optimization procedurewithout requiring additional samples. AdaQN learns several $Q$-functions, eachone trained with different hyperparameters, which are updated online using the$Q$-function with the smallest approximation error as a shared target. Ourselection scheme simultaneously handles different hyperparameters while copingwith the non-stationarity induced by the RL optimization procedure and beingorthogonal to any critic-based RL algorithm. We demonstrate that AdaQN istheoretically sound and empirically validate it in MuJoCo control problems andAtari $2600$ games, showing benefits in sample-efficiency, overall performance,robustness to stochasticity and training stability.</description><author>Th√©o Vincent, Fabian Wahren, Jan Peters, Boris Belousov, Carlo D'Eramo</author><pubDate>Mon, 21 Oct 2024 16:32:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16195v2</guid></item><item><title>From Tokens to Materials: Leveraging Language Models for Scientific Discovery</title><link>http://arxiv.org/abs/2410.16165v1</link><description>Exploring the predictive capabilities of language models in material scienceis an ongoing interest. This study investigates the application of languagemodel embeddings to enhance material property prediction in materials science.By evaluating various contextual embedding methods and pre-trained models,including Bidirectional Encoder Representations from Transformers (BERT) andGenerative Pre-trained Transformers (GPT), we demonstrate that domain-specificmodels, particularly MatBERT significantly outperform general-purpose models inextracting implicit knowledge from compound names and material properties. Ourfindings reveal that information-dense embeddings from the third layer ofMatBERT, combined with a context-averaging approach, offer the most effectivemethod for capturing material-property relationships from the scientificliterature. We also identify a crucial "tokenizer effect," highlighting theimportance of specialized text processing techniques that preserve completecompound names while maintaining consistent token counts. These insightsunderscore the value of domain-specific training and tokenization in materialsscience applications and offer a promising pathway for accelerating thediscovery and development of new materials through AI-driven approaches.</description><author>Yuwei Wan, Tong Xie, Nan Wu, Wenjie Zhang, Chunyu Kit, Bram Hoex</author><pubDate>Mon, 21 Oct 2024 16:31:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16165v1</guid></item><item><title>GenAI Assisting Medical Training</title><link>http://arxiv.org/abs/2410.16164v1</link><description>Medical procedures such as venipuncture and cannulation are essential fornurses and require precise skills. Learning this skill, in turn, is a challengefor educators due to the number of teachers per class and the complexity of thetask. The study aims to help students with skill acquisition and alleviate theeducator's workload by integrating generative AI methods to provide real-timefeedback on medical procedures such as venipuncture and cannulation.</description><author>Stefan Fritsch, Matthias Tschoepe, Vitor Fortes Rey, Lars Krupp, Agnes Gruenerbl, Eloise Monger, Sarah Travenna</author><pubDate>Mon, 21 Oct 2024 16:31:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16164v1</guid></item><item><title>Griffon-G: Bridging Vision-Language and Vision-Centric Tasks via Large Multimodal Models</title><link>http://arxiv.org/abs/2410.16163v1</link><description>Large Multimodal Models (LMMs) have achieved significant breakthroughs invarious vision-language and vision-centric tasks based on auto-regressivemodeling. However, these models typically focus on either vision-centric tasks,such as visual grounding and region description, or vision-language tasks, likeimage caption and multi-scenario VQAs. None of the LMMs have yetcomprehensively unified both types of tasks within a single model, as seen inLarge Language Models in the natural language processing field. Furthermore,even with abundant multi-task instruction-following data, directly stackingthese data for universal capabilities extension remains challenging. To addressthese issues, we introduce a novel multi-dimension curated and consolidatedmultimodal dataset, named CCMD-8M, which overcomes the data barriers ofunifying vision-centric and vision-language tasks through multi-level datacuration and multi-task consolidation. More importantly, we present Griffon-G,a general large multimodal model that addresses both vision-centric andvision-language tasks within a single end-to-end paradigm. Griffon-G resolvesthe training collapse issue encountered during the joint optimization of thesetasks, achieving better training efficiency. Evaluations across multimodalbenchmarks, general Visual Question Answering (VQA) tasks, scene text-centricVQA tasks, document-related VQA tasks, Referring Expression Comprehension, andobject detection demonstrate that Griffon-G surpasses the advanced LMMs andachieves expert-level performance in complicated vision-centric tasks.</description><author>Yufei Zhan, Hongyin Zhao, Yousong Zhu, Fan Yang, Ming Tang, Jinqiao Wang</author><pubDate>Mon, 21 Oct 2024 16:30:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16163v1</guid></item><item><title>Adversarial Inception for Bounded Backdoor Poisoning in Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2410.13995v2</link><description>Recent works have demonstrated the vulnerability of Deep ReinforcementLearning (DRL) algorithms against training-time, backdoor poisoning attacks.These attacks induce pre-determined, adversarial behavior in the agent uponobserving a fixed trigger during deployment while allowing the agent to solveits intended task during training. Prior attacks rely on arbitrarily largeperturbations to the agent's rewards to achieve both of these objectives -leaving them open to detection. Thus, in this work, we propose a new class ofbackdoor attacks against DRL which achieve state of the art performance whileminimally altering the agent's rewards. These "inception" attacks train theagent to associate the targeted adversarial behavior with high returns byinducing a disjunction between the agent's chosen action and the true actionexecuted in the environment during training. We formally define these attacksand prove they can achieve both adversarial objectives. We then devise anonline inception attack which significantly out-performs prior attacks underbounded reward constraints.</description><author>Ethan Rathbun, Christopher Amato, Alina Oprea</author><pubDate>Mon, 21 Oct 2024 16:27:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13995v2</guid></item><item><title>Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models Elicits Generalization to Composite Spatial Reasoning</title><link>http://arxiv.org/abs/2410.16162v1</link><description>Vision language models (VLMs) have demonstrated impressive performance acrossa wide range of downstream tasks. However, their proficiency in spatialreasoning remains limited, despite its crucial role in tasks involvingnavigation and interaction with physical environments. Specifically, much ofthe spatial reasoning in these tasks occurs in two-dimensional (2D)environments, and our evaluation reveals that state-of-the-art VLMs frequentlygenerate implausible and incorrect responses to composite spatial reasoningproblems, including simple pathfinding tasks that humans can solve effortlesslyat a glance. To address this, we explore an effective approach to enhance 2Dspatial reasoning within VLMs by training the model on basic spatialcapabilities. We begin by disentangling the key components of 2D spatialreasoning: direction comprehension, distance estimation, and localization. Ourcentral hypothesis is that mastering these basic spatial capabilities cansignificantly enhance a model's performance on composite spatial tasksrequiring advanced spatial understanding and combinatorial problem-solving. Toinvestigate this hypothesis, we introduce Sparkle, a framework that fine-tunesVLMs on these three basic spatial capabilities by synthetic data generation andtargeted supervision to form an instruction dataset for each capability. Ourexperiments demonstrate that VLMs fine-tuned with Sparkle achieve significantperformance gains, not only in the basic tasks themselves but also ingeneralizing to composite and out-of-distribution spatial reasoning tasks(e.g., improving from 13.5% to 40.0% on the shortest path problem). Thesefindings underscore the effectiveness of mastering basic spatial capabilitiesin enhancing composite spatial problem-solving, offering insights for improvingVLMs' spatial reasoning capabilities.</description><author>Yihong Tang, Ao Qu, Zhaokai Wang, Dingyi Zhuang, Zhaofeng Wu, Wei Ma, Shenhao Wang, Yunhan Zheng, Zhan Zhao, Jinhua Zhao</author><pubDate>Mon, 21 Oct 2024 16:26:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16162v1</guid></item><item><title>DMM: Distributed Matrix Mechanism for Differentially-Private Federated Learning using Packed Secret Sharing</title><link>http://arxiv.org/abs/2410.16161v1</link><description>Federated Learning (FL) has gained lots of traction recently, both inindustry and academia. In FL, a machine learning model is trained using datafrom various end-users arranged in committees across several rounds. Since suchdata can often be sensitive, a primary challenge in FL is providing privacywhile still retaining utility of the model. Differential Privacy (DP) hasbecome the main measure of privacy in the FL setting. DP comes in two flavors:central and local. In the former, a centralized server is trusted to receivethe users' raw gradients from a training step, and then perturb theiraggregation with some noise before releasing the next version of the model. Inthe latter (more private) setting, noise is applied on users' local devices,and only the aggregation of users' noisy gradients is revealed even to theserver. Great strides have been made in increasing the privacy-utilitytrade-off in the central DP setting, by utilizing the so-called matrixmechanism. However, progress has been mostly stalled in the local DP setting.In this work, we introduce the distributed matrix mechanism to achieve thebest-of-both-worlds; local DP and also better privacy-utility trade-off fromthe matrix mechanism. We accomplish this by proposing a cryptographic protocolthat securely transfers sensitive values across rounds, which makes use ofpacked secret sharing. This protocol accommodates the dynamic participation ofusers per training round required by FL, including those that may drop out fromthe computation. We provide experiments which show that our mechanism indeedsignificantly improves the privacy-utility trade-off of FL models compared toprevious local DP mechanisms, with little added overhead.</description><author>Alexander Bienstock, Ujjwal Kumar, Antigoni Polychroniadou</author><pubDate>Mon, 21 Oct 2024 16:25:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16161v1</guid></item><item><title>A Survey on Knowledge Distillation of Large Language Models</title><link>http://arxiv.org/abs/2402.13116v4</link><description>In the era of Large Language Models (LLMs), Knowledge Distillation (KD)emerges as a pivotal methodology for transferring advanced capabilities fromleading proprietary LLMs, such as GPT-4, to their open-source counterparts likeLLaMA and Mistral. Additionally, as open-source LLMs flourish, KD plays acrucial role in both compressing these models, and facilitating theirself-improvement by employing themselves as teachers. This paper presents acomprehensive survey of KD's role within the realm of LLM, highlighting itscritical function in imparting advanced knowledge to smaller models and itsutility in model compression and self-improvement. Our survey is meticulouslystructured around three foundational pillars: \textit{algorithm},\textit{skill}, and \textit{verticalization} -- providing a comprehensiveexamination of KD mechanisms, the enhancement of specific cognitive abilities,and their practical implications across diverse fields. Crucially, the surveynavigates the intricate interplay between data augmentation (DA) and KD,illustrating how DA emerges as a powerful paradigm within the KD framework tobolster LLMs' performance. By leveraging DA to generate context-rich,skill-specific training data, KD transcends traditional boundaries, enablingopen-source models to approximate the contextual adeptness, ethical alignment,and deep semantic insights characteristic of their proprietary counterparts.This work aims to provide an insightful guide for researchers andpractitioners, offering a detailed overview of current methodologies in KD andproposing future research directions. Importantly, we firmly advocate forcompliance with the legal terms that regulate the use of LLMs, ensuring ethicaland lawful application of KD of LLMs. An associated Github repository isavailable at https://github.com/Tebmer/Awesome-Knowledge-Distillation-of-LLMs.</description><author>Xiaohan Xu, Ming Li, Chongyang Tao, Tao Shen, Reynold Cheng, Jinyang Li, Can Xu, Dacheng Tao, Tianyi Zhou</author><pubDate>Mon, 21 Oct 2024 16:22:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13116v4</guid></item><item><title>Metric as Transform: Exploring beyond Affine Transform for Interpretable Neural Network</title><link>http://arxiv.org/abs/2410.16159v1</link><description>Artificial Neural Networks of varying architectures are generally paired withaffine transformation at the core. However, we find dot product neurons withglobal influence less interpretable as compared to local influence of euclideandistance (as used in Radial Basis Function Network). In this work, we explorethe generalization of dot product neurons to $l^p$-norm, metrics, and beyond.We find that metrics as transform performs similarly to affine transform whenused in MultiLayer Perceptron or Convolutional Neural Network. Moreover, weexplore various properties of Metrics, compare it with Affine, and presentmultiple cases where metrics seem to provide better interpretability. Wedevelop an interpretable local dictionary based Neural Networks and use it tounderstand and reject adversarial examples.</description><author>Suman Sapkota</author><pubDate>Mon, 21 Oct 2024 16:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16159v1</guid></item><item><title>Limpeh ga li gong: Challenges in Singlish Annotations</title><link>http://arxiv.org/abs/2410.16156v1</link><description>Singlish, or Colloquial Singapore English, is a language formed from oral andsocial communication within multicultural Singapore. In this work, we work on afundamental Natural Language Processing (NLP) task: Parts-Of-Speech (POS)tagging of Singlish sentences. For our analysis, we build a parallel Singlishdataset containing direct English translations and POS tags, with translationand POS annotation done by native Singlish speakers. Our experiments show thatautomatic transition- and transformer- based taggers perform with only $\sim80\%$ accuracy when evaluated against human-annotated POS labels, suggestingthat there is indeed room for improvement on computation analysis of thelanguage. We provide an exposition of challenges in Singlish annotation: itsinconsistencies in form and semantics, the highly context-dependent particlesof the language, its structural unique expressions, and the variation of thelanguage on different mediums. Our task definition, resultant labels andresults reflects the challenges in analysing colloquial languages formulatedfrom a variety of dialects, and paves the way for future studies beyond POStagging.</description><author>Lynnette Hui Xian Ng, Luo Qi Chan</author><pubDate>Mon, 21 Oct 2024 16:21:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16156v1</guid></item><item><title>A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns</title><link>http://arxiv.org/abs/2410.16155v1</link><description>With the development of large language models, they are widely used as agentsin various fields. A key component of agents is memory, which stores vitalinformation but is susceptible to jailbreak attacks. Existing research mainlyfocuses on single-agent attacks and shared memory attacks. However, real-worldscenarios often involve independent memory. In this paper, we propose theTroublemaker Makes Chaos in Honest Town (TMCHT) task, a large-scale,multi-agent, multi-topology text-based attack evaluation framework. TMCHTinvolves one attacker agent attempting to mislead an entire society of agents.We identify two major challenges in multi-agent attacks: (1) Non-complete graphstructure, (2) Large-scale systems. We attribute these challenges to aphenomenon we term toxicity disappearing. To address these issues, we proposean Adversarial Replication Contagious Jailbreak (ARCJ) method, which optimizesthe retrieval suffix to make poisoned samples more easily retrieved andoptimizes the replication suffix to make poisoned samples have contagiousability. We demonstrate the superiority of our approach in TMCHT, with 23.51%,18.95%, and 52.93% improvements in line topology, star topology, and 100-agentsettings. Encourage community attention to the security of multi-agent systems.</description><author>Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao</author><pubDate>Mon, 21 Oct 2024 16:21:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16155v1</guid></item><item><title>Unsupervised Replay Strategies for Continual Learning with Limited Data</title><link>http://arxiv.org/abs/2410.16154v1</link><description>Artificial neural networks (ANNs) show limited performance with scarce orimbalanced training data and face challenges with continuous learning, such asforgetting previously learned data after new tasks training. In contrast, thehuman brain can learn continuously and from just a few examples. This researchexplores the impact of 'sleep', an unsupervised phase incorporating stochasticactivation with local Hebbian learning rules, on ANNs trained incrementallywith limited and imbalanced datasets, specifically MNIST and Fashion MNIST. Wediscovered that introducing a sleep phase significantly enhanced accuracy inmodels trained with limited data. When a few tasks were trained sequentially,sleep replay not only rescued previously learned information that had beencatastrophically forgetting following new task training but often enhancedperformance in prior tasks, especially those trained with limited data. Thisstudy highlights the multifaceted role of sleep replay in augmenting learningefficiency and facilitating continual learning in ANNs.</description><author>Anthony Bazhenov, Pahan Dewasurendra, Giri P. Krishnan, Jean Erik Delanois</author><pubDate>Mon, 21 Oct 2024 16:21:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16154v1</guid></item><item><title>Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages</title><link>http://arxiv.org/abs/2410.16153v1</link><description>Despite recent advances in multimodal large language models (MLLMs), theirdevelopment has predominantly focused on English- and western-centric datasetsand tasks, leaving most of the world's languages and diverse cultural contextsunderrepresented. This paper introduces Pangea, a multilingual multimodal LLMtrained on PangeaIns, a diverse 6M instruction dataset spanning 39 languages.PangeaIns features: 1) high-quality English instructions, 2) carefullymachine-translated instructions, and 3) culturally relevant multimodal tasks toensure cross-cultural coverage. To rigorously assess models' capabilities, weintroduce PangeaBench, a holistic evaluation suite encompassing 14 datasetscovering 47 languages. Results show that Pangea significantly outperformsexisting open-source models in multilingual settings and diverse culturalcontexts. Ablation studies further reveal the importance of English dataproportions, language popularity, and the number of multimodal training sampleson overall performance. We fully open-source our data, code, and trainedcheckpoints, to facilitate the development of inclusive and robust multilingualMLLMs, promoting equity and accessibility across a broader linguistic andcultural spectrum.</description><author>Xiang Yue, Yueqi Song, Akari Asai, Seungone Kim, Jean de Dieu Nyandwi, Simran Khanuja, Anjali Kantharuban, Lintang Sutawika, Sathyanarayanan Ramamoorthy, Graham Neubig</author><pubDate>Mon, 21 Oct 2024 16:19:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16153v1</guid></item><item><title>Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models</title><link>http://arxiv.org/abs/2410.16152v1</link><description>Using image models naively for solving inverse video problems often suffersfrom flickering, texture-sticking, and temporal inconsistency in generatedvideos. To tackle these problems, in this paper, we view frames as continuousfunctions in the 2D space, and videos as a sequence of continuous warpingtransformations between different frames. This perspective allows us to trainfunction space diffusion models only on images and utilize them to solvetemporally correlated inverse problems. The function space diffusion modelsneed to be equivariant with respect to the underlying spatial transformations.To ensure temporal consistency, we introduce a simple post-hoc test-timeguidance towards (self)-equivariant solutions. Our method allows us to deploystate-of-the-art latent diffusion models such as Stable Diffusion XL to solvevideo inverse problems. We demonstrate the effectiveness of our method forvideo inpainting and $8\times$ video super-resolution, outperforming existingtechniques based on noise transformations. We provide generated video results:https://giannisdaras.github.io/warped\_diffusion.github.io/.</description><author>Giannis Daras, Weili Nie, Karsten Kreis, Alex Dimakis, Morteza Mardani, Nikola Borislavov Kovachki, Arash Vahdat</author><pubDate>Mon, 21 Oct 2024 16:19:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16152v1</guid></item><item><title>RACCooN: A Versatile Instructional Video Editing Framework with Auto-Generated Narratives</title><link>http://arxiv.org/abs/2405.18406v2</link><description>Recent video generative models primarily rely on carefully written textprompts for specific tasks, like inpainting or style editing. They requirelabor-intensive textual descriptions for input videos, hindering theirflexibility to adapt personal/raw videos to user specifications. This paperproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-videogenerative framework that supports multiple video editing capabilities such asremoval, addition, and modification, through a unified pipeline. RACCooNconsists of two principal stages: Video-to-Paragraph (V2P) andParagraph-to-Video (P2V). In the V2P stage, we automatically describe videoscenes in well-structured natural language, capturing both the holistic contextand focused object details. Subsequently, in the P2V stage, users canoptionally refine these descriptions to guide the video diffusion model,enabling various modifications to the input video, such as removing, changingsubjects, and/or adding new objects. The proposed approach stands out fromother methods through several significant contributions: (1) RACCooN suggests amulti-granular spatiotemporal pooling strategy to generate well-structuredvideo descriptions, capturing both the broad context and object details withoutrequiring complex human annotations, simplifying precise video content editingbased on text for users. (2) Our video generative model incorporatesauto-generated narratives or instructions to enhance the quality and accuracyof the generated content. (3) RACCooN also plans to imagine new objects in agiven video, so users simply prompt the model to receive a detailed videoediting plan for complex video editing. The proposed framework demonstratesimpressive versatile capabilities in video-to-paragraph generation, videocontent editing, and can be incorporated into other SoTA video generativemodels for further enhancement.</description><author>Jaehong Yoon, Shoubin Yu, Mohit Bansal</author><pubDate>Mon, 21 Oct 2024 16:18:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18406v2</guid></item><item><title>Small Contributions, Small Networks: Efficient Neural Network Pruning Based on Relative Importance</title><link>http://arxiv.org/abs/2410.16151v1</link><description>Recent advancements have scaled neural networks to unprecedented sizes,achieving remarkable performance across a wide range of tasks. However,deploying these large-scale models on resource-constrained devices posessignificant challenges due to substantial storage and computationalrequirements. Neural network pruning has emerged as an effective technique tomitigate these limitations by reducing model size and complexity. In thispaper, we introduce an intuitive and interpretable pruning method based onactivation statistics, rooted in information theory and statistical analysis.Our approach leverages the statistical properties of neuron activations toidentify and remove weights with minimal contributions to neuron outputs.Specifically, we build a distribution of weight contributions across thedataset and utilize its parameters to guide the pruning process. Furthermore,we propose a Pruning-aware Training strategy that incorporates an additionalregularization term to enhance the effectiveness of our pruning method.Extensive experiments on multiple datasets and network architecturesdemonstrate that our method consistently outperforms several baseline andstate-of-the-art pruning techniques.</description><author>Mostafa Hussien, Mahmoud Afifi, Kim Khoa Nguyen, Mohamed Cheriet</author><pubDate>Mon, 21 Oct 2024 16:18:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16151v1</guid></item><item><title>Modelling Structured Data Learning with Restricted Boltzmann Machines in the Teacher-Student Setting</title><link>http://arxiv.org/abs/2410.16150v1</link><description>Restricted Boltzmann machines (RBM) are generative models capable to learndata with a rich underlying structure. We study the teacher-student settingwhere a student RBM learns structured data generated by a teacher RBM. Theamount of structure in the data is controlled by adjusting the number of hiddenunits of the teacher and the correlations in the rows of the weights, a.k.a.patterns. In the absence of correlations, we validate the conjecture that theperformance is independent of the number of teacher patters and hidden units ofthe student RBMs, and we argue that the teacher-student setting can be used asa toy model for studying the lottery ticket hypothesis. Beyond this regime, wefind that the critical amount of data required to learn the teacher patternsdecreases with both their number and correlations. In both regimes, we findthat, even with an relatively large dataset, it becomes impossible to learn theteacher patterns if the inference temperature used for regularization is kepttoo low. In our framework, the student can learn teacher patterns one-to-one ormany-to-one, generalizing previous findings about the teacher-student settingwith two hidden units to any arbitrary finite number of hidden units.</description><author>Robin Th√©riault, Francesco Tosello, Daniele Tantari</author><pubDate>Mon, 21 Oct 2024 16:18:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16150v1</guid></item><item><title>PODTILE: Facilitating Podcast Episode Browsing with Auto-generated Chapters</title><link>http://arxiv.org/abs/2410.16148v1</link><description>Listeners of long-form talk-audio content, such as podcast episodes, oftenfind it challenging to understand the overall structure and locate relevantsections. A practical solution is to divide episodes intochapters--semantically coherent segments labeled with titles and timestamps.Since most episodes on our platform at Spotify currently lack creator-providedchapters, automating the creation of chapters is essential. Scaling thechapterization of podcast episodes presents unique challenges. First, episodestend to be less structured than written texts, featuring spontaneousdiscussions with nuanced transitions. Second, the transcripts are usuallylengthy, averaging about 16,000 tokens, which necessitates efficient processingthat can preserve context. To address these challenges, we introduce PODTILE, afine-tuned encoder-decoder transformer to segment conversational data. Themodel simultaneously generates chapter transitions and titles for the inputtranscript. To preserve context, each input text is augmented with globalcontext, including the episode's title, description, and previous chaptertitles. In our intrinsic evaluation, PODTILE achieved an 11% improvement inROUGE score over the strongest baseline. Additionally, we provide insights intothe practical benefits of auto-generated chapters for listeners navigatingepisode content. Our findings indicate that auto-generated chapters serve as auseful tool for engaging with less popular podcasts. Finally, we presentempirical evidence that using chapter titles can enhance effectiveness ofsparse retrieval in search tasks.</description><author>Azin Ghazimatin, Ekaterina Garmash, Gustavo Penha, Kristen Sheets, Martin Achenbach, Oguz Semerci, Remi Galvez, Marcus Tannenberg, Sahitya Mantravadi, Divya Narayanan, Ofeliya Kalaydzhyan, Douglas Cole, Ben Carterette, Ann Clifton, Paul N. Bennett, Claudia Hauff, Mounia Lalmas</author><pubDate>Mon, 21 Oct 2024 16:17:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16148v1</guid></item><item><title>Towards Combating Frequency Simplicity-biased Learning for Domain Generalization</title><link>http://arxiv.org/abs/2410.16146v1</link><description>Domain generalization methods aim to learn transferable knowledge from sourcedomains that can generalize well to unseen target domains. Recent studies showthat neural networks frequently suffer from a simplicity-biased learningbehavior which leads to over-reliance on specific frequency sets, namely asfrequency shortcuts, instead of semantic information, resulting in poorgeneralization performance. Despite previous data augmentation techniquessuccessfully enhancing generalization performances, they intend to apply morefrequency shortcuts, thereby causing hallucinations of generalizationimprovement. In this paper, we aim to prevent such learning behavior ofapplying frequency shortcuts from a data-driven perspective. Given thetheoretical justification of models' biased learning behavior on differentspatial frequency components, which is based on the dataset frequencyproperties, we argue that the learning behavior on various frequency componentscould be manipulated by changing the dataset statistical structure in theFourier domain. Intuitively, as frequency shortcuts are hidden in the dominantand highly dependent frequencies of dataset structure, dynamically perturbatingthe over-reliance frequency components could prevent the application offrequency shortcuts. To this end, we propose two effective data augmentationmodules designed to collaboratively and adaptively adjust the frequencycharacteristic of the dataset, aiming to dynamically influence the learningbehavior of the model and ultimately serving as a strategy to mitigate shortcutlearning. Code is available at AdvFrequency(https://github.com/C0notSilly/AdvFrequency).</description><author>Xilin He, Jingyu Hu, Qinliang Lin, Cheng Luo, Weicheng Xie, Siyang Song, Muhammad Haris Khan, Linlin Shen</author><pubDate>Mon, 21 Oct 2024 16:17:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16146v1</guid></item><item><title>1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs</title><link>http://arxiv.org/abs/2410.16144v1</link><description>Recent advances in 1-bit Large Language Models (LLMs), such as BitNet andBitNet b1.58, present a promising approach to enhancing the efficiency of LLMsin terms of speed and energy consumption. These developments also enable localLLM deployment across a broad range of devices. In this work, we introducebitnet.cpp, a tailored software stack designed to unlock the full potential of1-bit LLMs. Specifically, we develop a set of kernels to support fast andlossless inference of ternary BitNet b1.58 LLMs on CPUs. Extensive experimentsdemonstrate that bitnet.cpp achieves significant speedups, ranging from 2.37xto 6.17x on x86 CPUs and from 1.37x to 5.07x on ARM CPUs, across various modelsizes. The code is available at https://github.com/microsoft/BitNet.</description><author>Jinheng Wang, Hansong Zhou, Ting Song, Shaoguang Mao, Shuming Ma, Hongyu Wang, Yan Xia, Furu Wei</author><pubDate>Mon, 21 Oct 2024 16:14:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16144v1</guid></item><item><title>An Explainable Contrastive-based Dilated Convolutional Network with Transformer for Pediatric Pneumonia Detection</title><link>http://arxiv.org/abs/2410.16143v1</link><description>Pediatric pneumonia remains a significant global threat, posing a largermortality risk than any other communicable disease. According to UNICEF, it isa leading cause of mortality in children under five and requires promptdiagnosis. Early diagnosis using chest radiographs is the prevalent standard,but limitations include low radiation levels in unprocessed images and dataimbalance issues. This necessitates the development of efficient,computer-aided diagnosis techniques. To this end, we propose a novelEXplainable Contrastive-based Dilated Convolutional Network with Transformer(XCCNet) for pediatric pneumonia detection. XCCNet harnesses the spatial powerof dilated convolutions and the global insights from contrastive-basedtransformers for effective feature refinement. A robust chest X-ray processingmodule tackles low-intensity radiographs, while adversarial-based dataaugmentation mitigates the skewed distribution of chest X-rays in the dataset.Furthermore, we actively integrate an explainability approach through featurevisualization, directly aligning it with the attention region that pinpointsthe presence of pneumonia or normality in radiographs. The efficacy of XCCNetis comprehensively assessed on four publicly available datasets. Extensiveperformance evaluation demonstrates the superiority of XCCNet compared tostate-of-the-art methods.</description><author>Chandravardhan Singh Raghaw, Parth Shirish Bhore, Mohammad Zia Ur Rehman, Nagendra Kumar</author><pubDate>Mon, 21 Oct 2024 16:14:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16143v1</guid></item><item><title>A Psycholinguistic Evaluation of Language Models' Sensitivity to Argument Roles</title><link>http://arxiv.org/abs/2410.16139v1</link><description>We present a systematic evaluation of large language models' sensitivity toargument roles, i.e., who did what to whom, by replicating psycholinguisticstudies on human argument role processing. In three experiments, we find thatlanguage models are able to distinguish verbs that appear in plausible andimplausible contexts, where plausibility is determined through the relationbetween the verb and its preceding arguments. However, none of the modelscapture the same selective patterns that human comprehenders exhibit duringreal-time verb prediction. This indicates that language models' capacity todetect verb plausibility does not arise from the same mechanism that underlieshuman real-time sentence processing.</description><author>Eun-Kyoung Rosa Lee, Sathvik Nair, Naomi Feldman</author><pubDate>Mon, 21 Oct 2024 16:05:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16139v1</guid></item><item><title>Theoretical Insights into Line Graph Transformation on Graph Learning</title><link>http://arxiv.org/abs/2410.16138v1</link><description>Line graph transformation has been widely studied in graph theory, where eachnode in a line graph corresponds to an edge in the original graph. This hasinspired a series of graph neural networks (GNNs) applied to transformed linegraphs, which have proven effective in various graph representation learningtasks. However, there is limited theoretical study on how line graphtransformation affects the expressivity of GNN models. In this study, we focuson two types of graphs known to be challenging to the Weisfeiler-Leman (WL)tests: Cai-F\"urer-Immerman (CFI) graphs and strongly regular graphs, and showthat applying line graph transformation helps exclude these challenging graphproperties, thus potentially assist WL tests in distinguishing these graphs. Weempirically validate our findings by conducting a series of experiments thatcompare the accuracy and efficiency of graph isomorphism tests and GNNs on bothline-transformed and original graphs across these graph structure types.</description><author>Fan Yang, Xingyue Huang</author><pubDate>Mon, 21 Oct 2024 16:04:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16138v1</guid></item><item><title>Modeling dynamic neural activity by combining naturalistic video stimuli and stimulus-independent latent factors</title><link>http://arxiv.org/abs/2410.16136v1</link><description>Understanding how the brain processes dynamic natural stimuli remains afundamental challenge in neuroscience. Current dynamic neural encoding modelseither take stimuli as input but ignore shared variability in neural responses,or they model this variability by deriving latent embeddings from neuralresponses or behavior while ignoring the visual input. To address this gap, wepropose a probabilistic model that incorporates video inputs along withstimulus-independent latent factors to capture variability in neuronalresponses, predicting a joint distribution for the entire population. Aftertraining and testing our model on mouse V1 neuronal responses, we found that itoutperforms video-only models in terms of log-likelihood and achieves furtherimprovements when conditioned on responses from other neurons. Furthermore, wefind that the learned latent factors strongly correlate with mouse behavior,although the model was trained without behavior data.</description><author>Finn Schmidt, Suhas Shrinivasan, Polina Turishcheva, Fabian H. Sinz</author><pubDate>Mon, 21 Oct 2024 16:01:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16136v1</guid></item><item><title>Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference on GPUs</title><link>http://arxiv.org/abs/2410.16135v1</link><description>To date, 2:4 sparsity has stood as the only sparse pattern that can beaccelerated using sparse tensor cores on GPUs. In practice, 2:4 sparsity oftenpossesses low actual speedups ($\leq 1.3$) and requires fixed sparse ratios,meaning that other ratios, such as 4:8, 8:16, or those exceeding 50% sparsity,do not incur any speedups on GPUs. Recent studies suggest that V:N:M sparsityis promising in addressing these limitations of 2:4 sparsity. However,regarding accuracy, the effects of V:N:M sparsity on broader Transformermodels, such as vision Transformers and large language models (LLMs), arelargely unexamined. Moreover, Some specific issues related to V:N:M sparsity,such as how to select appropriate V and M values, remain unresolved. In thisstudy, we thoroughly investigate the application of V:N:M sparsity in visionmodels and LLMs across multiple tasks, from pertaining to downstream tasks. Wepropose three key approaches to enhance the applicability and accuracy ofV:N:M-sparse Transformers, including heuristic V and M selection,V:N:M-specific channel permutation, and three-staged LoRA training techniques.Experimental results show that, with our methods, the DeiT-small achieveslossless accuracy at 64:2:5 sparsity, while the DeiT-base maintains accuracyeven at 64:2:8 sparsity. In addition, the fine-tuned LLama2-7B at 64:2:5sparsity performs comparably or better than training-free 2:4 sparsealternatives on downstream tasks. More importantly, V:N:M-sparse Transformersoffer a wider range of speedup-accuracy trade-offs compared to 2:4 sparsity.Overall, our exploration largely facilitates the V:N:M sparsity to act as atruly effective acceleration solution for Transformers in cost-sensitiveinference scenarios.</description><author>Kang Zhao, Tao Yuan, Han Bao, Zhenfeng Su, Chang Gao, Zhaofeng Sun, Zichen Liang, Liping Jing, Jianfei Chen</author><pubDate>Mon, 21 Oct 2024 16:00:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16135v1</guid></item><item><title>Exploring the Potential of Large Language Models for Heterophilic Graphs</title><link>http://arxiv.org/abs/2408.14134v2</link><description>Large language models (LLMs) have presented significant opportunities toenhance various machine learning applications, including graph neural networks(GNNs). By leveraging the vast open-world knowledge within LLMs, we can moreeffectively interpret and utilize textual data to better characterizeheterophilic graphs, where neighboring nodes often have different labels.However, existing approaches for heterophilic graphs overlook the rich textualdata associated with nodes, which could unlock deeper insights into theirheterophilic contexts. In this work, we explore the potential of LLMs formodeling heterophilic graphs and propose a novel two-stage framework:LLM-enhanced edge discriminator and LLM-guided edge reweighting. In the firststage, we fine-tune the LLM to better identify homophilic and heterophilicedges based on the textual content of their nodes. In the second stage, weadaptively manage message propagation in GNNs for different edge types based onnode features, structures, and heterophilic or homophilic characteristics. Tocope with the computational demands when deploying LLMs in practical scenarios,we further explore model distillation techniques to fine-tune smaller, moreefficient models that maintain competitive performance. Extensive experimentsvalidate the effectiveness of our framework, demonstrating the feasibility ofusing LLMs to enhance node classification on heterophilic graphs.</description><author>Yuxia Wu, Shujie Li, Yuan Fang, Chuan Shi</author><pubDate>Mon, 21 Oct 2024 15:59:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14134v2</guid></item><item><title>Do Large Language Models Need a Content Delivery Network?</title><link>http://arxiv.org/abs/2409.13761v2</link><description>As the use of large language models (LLMs) expands rapidly, so does the rangeof knowledge needed to supplement various LLM queries. Thus, enabling flexibleand efficient injection of new knowledge in LLM inference is critical. Threehigh-level options exist: (i) embedding the knowledge in LLM's weights (i.e.,fine-tuning), (ii) including the knowledge as a part of LLM's text input (i.e.,in-context learning), or (iii) injecting the KV caches of the new knowledge toLLM during prefill. This paper argues that, although fine-tuning and in-contextlearning are popular, using KV caches as the medium of knowledge couldsimultaneously enable more modular management of knowledge injection and moreefficient LLM serving with low cost and fast response. To realize thesebenefits, we envision a Knowledge Delivery Network (KDN), a new systemcomponent in LLM services that dynamically optimizes the storage, transfer, andcomposition of KV cache across LLM engines and other compute and storageresources. We believe that, just like content delivery networks (CDNs), such asAkamai, enabled the success of the Internet ecosystem through their efficientdata delivery, KDNs will be critical to the success of LLM applications throughtheir efficient knowledge delivery. We have open-sourced a KDN prototype athttps://github.com/LMCache/LMCache.</description><author>Yihua Cheng, Kuntai Du, Jiayi Yao, Junchen Jiang</author><pubDate>Mon, 21 Oct 2024 15:59:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.13761v2</guid></item><item><title>MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs</title><link>http://arxiv.org/abs/2410.13502v2</link><description>Large language models (LLMs) can solve arithmetic word problems with highaccuracy, but little is known about how well they generalize to problems thatare more complex than the ones on which they have been trained. Empiricalinvestigations of such questions are impeded by two major flaws of currentevaluations: (i) much of the evaluation data is contaminated, in the sense thatit has already been seen during training, and (ii) benchmark datasets do notcapture how problem proofs may be arbitrarily complex in various ways. As astep towards addressing these issues, we present a framework for evaluatingLLMs on problems with arbitrarily complex arithmetic proofs, called MathGAP.MathGAP generates problems that follow fixed proof specifications -- along withchain-of-thought reasoning annotations -- enabling systematic studies ongeneralization with respect to arithmetic proof complexity. We apply MathGAP toanalyze how in-context learning interacts with generalization to problems thathave more complex proofs. We find that among the models tested, most show asignificant decrease in performance as proofs get deeper and wider. This effectis more pronounced in complex, nonlinear proof structures, which arechallenging even for GPT-4o. Surprisingly, providing in-context examples fromthe same distribution as the test set is not always beneficial for performance.In particular, zero-shot prompting as well as demonstrating a diverse range ofexamples that are less complex than the test data sometimes yield similar orhigher accuracies.</description><author>Andreas Opedal, Haruki Shirakami, Bernhard Sch√∂lkopf, Abulhair Saparov, Mrinmaya Sachan</author><pubDate>Mon, 21 Oct 2024 15:58:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.13502v2</guid></item><item><title>Human-Agent Joint Learning for Efficient Robot Manipulation Skill Acquisition</title><link>http://arxiv.org/abs/2407.00299v4</link><description>Employing a teleoperation system for gathering demonstrations offers thepotential for more efficient learning of robot manipulation. However,teleoperating a robot arm equipped with a dexterous hand or gripper, via ateleoperation system presents inherent challenges due to the task's highdimensionality, complexity of motion, and differences between physiologicalstructures. In this study, we introduce a novel system for joint learningbetween human operators and robots, that enables human operators to sharecontrol of a robot end-effector with a learned assistive agent, simplifies thedata collection process, and facilitates simultaneous human demonstrationcollection and robot manipulation training. As data accumulates, the assistiveagent gradually learns. Consequently, less human effort and attention arerequired, enhancing the efficiency of the data collection process. It alsoallows the human operator to adjust the control ratio to achieve a trade-offbetween manual and automated control. We conducted experiments in bothsimulated environments and physical real-world settings. Through user studiesand quantitative evaluations, it is evident that the proposed system couldenhance data collection efficiency and reduce the need for human adaptationwhile ensuring the collected data is of sufficient quality for downstreamtasks. \textit{For more details, please refer to our webpagehttps://norweig1an.github.io/HAJL.github.io/.</description><author>Shengcheng Luo, Quanquan Peng, Jun Lv, Kaiwen Hong, Katherine Rose Driggs-Campbell, Cewu Lu, Yong-Lu Li</author><pubDate>Mon, 21 Oct 2024 15:56:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00299v4</guid></item></channel></rss>