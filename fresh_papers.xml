<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 30 Jan 2025 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>CubeDiff: Repurposing Diffusion-Based Image Models for Panorama Generation</title><link>http://arxiv.org/abs/2501.17162v1</link><description>We introduce a novel method for generating 360{\deg} panoramas from textprompts or images. Our approach leverages recent advances in 3D generation byemploying multi-view diffusion models to jointly synthesize the six faces of acubemap. Unlike previous methods that rely on processing equirectangularprojections or autoregressive generation, our method treats each face as astandard perspective image, simplifying the generation process and enabling theuse of existing multi-view diffusion models. We demonstrate that these modelscan be adapted to produce high-quality cubemaps without requiringcorrespondence-aware attention layers. Our model allows for fine-grained textcontrol, generates high resolution panorama images and generalizes well beyondits training set, whilst achieving state-of-the-art results, both qualitativelyand quantitatively. Project page: https://cubediff.github.io/</description><author>Nikolai Kalischek, Michael Oechsle, Fabian Manhardt, Philipp Henzler, Konrad Schindler, Federico Tombari</author><pubDate>Tue, 28 Jan 2025 18:59:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17162v1</guid></item><item><title>SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training</title><link>http://arxiv.org/abs/2501.17161v1</link><description>Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely usedpost-training techniques for foundation models. However, their roles inenhancing model generalization capabilities remain unclear. This paper studiesthe difference between SFT and RL on generalization and memorization, focusingon text-based rule variants and visual variants. We introduce GeneralPoints, anarithmetic reasoning card game, and adopt V-IRL, a real-world navigationenvironment, to assess how models trained with SFT and RL generalize to unseenvariants in both textual and visual domains. We show that RL, especially whentrained with an outcome-based reward, generalizes across both rule-basedtextual and visual variants. SFT, in contrast, tends to memorize training dataand struggles to generalize out-of-distribution scenarios. Further analysisreveals that RL improves the model's underlying visual recognitioncapabilities, contributing to its enhanced generalization in the visual domain.Despite RL's superior generalization, we show that SFT remains essential foreffective RL training; SFT stabilizes the model's output format, enablingsubsequent RL to achieve its performance gains. These findings demonstrates thecapability of RL for acquiring generalizable knowledge in complex, multi-modaltasks.</description><author>Tianzhe Chu, Yuexiang Zhai, Jihan Yang, Shengbang Tong, Saining Xie, Dale Schuurmans, Quoc V. Le, Sergey Levine, Yi Ma</author><pubDate>Tue, 28 Jan 2025 18:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17161v1</guid></item><item><title>A Hybrid Deep Learning CNN Model for Enhanced COVID-19 Detection from Computed Tomography (CT) Scan Images</title><link>http://arxiv.org/abs/2501.17160v1</link><description>Early detection of COVID-19 is crucial for effective treatment andcontrolling its spread. This study proposes a novel hybrid deep learning modelfor detecting COVID-19 from CT scan images, designed to assist overburdenedmedical professionals. Our proposed model leverages the strengths of VGG16,DenseNet121, and MobileNetV2 to extract features, followed by PrincipalComponent Analysis (PCA) for dimensionality reduction, after which the featuresare stacked and classified using a Support Vector Classifier (SVC). Weconducted comparative analysis between the proposed hybrid model and individualpre-trained CNN models, using a dataset of 2,108 training images and 373 testimages comprising both COVID-positive and non-COVID images. Our proposed hybridmodel achieved an accuracy of 98.93%, outperforming the individual models interms of precision, recall, F1 scores, and ROC curve performance.</description><author>Suresh Babu Nettur, Shanthi Karpurapu, Unnati Nettur, Likhit Sagar Gajja, Sravanthy Myneni, Akhil Dusi, Lalithya Posham</author><pubDate>Tue, 28 Jan 2025 18:59:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17160v1</guid></item><item><title>IC-Portrait: In-Context Matching for View-Consistent Personalized Portrait</title><link>http://arxiv.org/abs/2501.17159v1</link><description>Existing diffusion models show great potential for identity-preservinggeneration. However, personalized portrait generation remains challenging dueto the diversity in user profiles, including variations in appearance andlighting conditions. To address these challenges, we propose IC-Portrait, anovel framework designed to accurately encode individual identities forpersonalized portrait generation. Our key insight is that pre-trained diffusionmodels are fast learners (e.g.,100 ~ 200 steps) for in-context densecorrespondence matching, which motivates the two major designs of ourIC-Portrait framework. Specifically, we reformulate portrait generation intotwo sub-tasks: 1) Lighting-Aware Stitching: we find that masking a highproportion of the input image, e.g., 80%, yields a highly effectiveself-supervisory representation learning of reference image lighting. 2)View-Consistent Adaptation: we leverage a synthetic view-consistent profiledataset to learn the in-context correspondence. The reference profile can thenbe warped into arbitrary poses for strong spatial-aligned view conditioning.Coupling these two designs by simply concatenating latents to formControlNet-like supervision and modeling, enables us to significantly enhancethe identity preservation fidelity and stability. Extensive evaluationsdemonstrate that IC-Portrait consistently outperforms existing state-of-the-artmethods both quantitatively and qualitatively, with particularly notableimprovements in visual qualities. Furthermore, IC-Portrait even demonstrates3D-aware relighting capabilities.</description><author>Han Yang, Enis Simsar, Sotiris Anagnostidi, Yanlong Zang, Thomas Hofmann, Ziwei Liu</author><pubDate>Tue, 28 Jan 2025 18:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17159v1</guid></item><item><title>Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile Compensation Using Deep Energy Model</title><link>http://arxiv.org/abs/2501.17152v1</link><description>Three-dimensional (3D) multi-slab acquisition is a technique frequentlyemployed in high-resolution diffusion-weighted MRI in order to achieve the bestsignal-to-noise ratio (SNR) efficiency. However, this technique is limited byslab boundary artifacts that cause intensity fluctuations and aliasing betweenslabs which reduces the accuracy of anatomical imaging. Addressing this issueis crucial for advancing diffusion MRI quality and making high-resolutionimaging more feasible for clinical and research applications. In this work, wepropose a regularized slab profile encoding (PEN) method within a Plug-and-PlayADMM framework, incorporating multi-scale energy (MuSE) regularization toeffectively improve the slab combined reconstruction. Experimental resultsdemonstrate that the proposed method significantly improves image qualitycompared to non-regularized and TV-regularized PEN approaches. The regularizedPEN framework provides a more robust and efficient solution for high-resolution3D diffusion MRI, potentially enabling clearer, more reliable anatomicalimaging across various applications.</description><author>Reza Ghorbani, Jyothi Rikhab Chand, Chu-Yu Lee, Mathews Jacob, Merry Mani</author><pubDate>Tue, 28 Jan 2025 18:53:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17152v1</guid></item><item><title>Scanning Trojaned Models Using Out-of-Distribution Samples</title><link>http://arxiv.org/abs/2501.17151v1</link><description>Scanning for trojan (backdoor) in deep neural networks is crucial due totheir significant real-world applications. There has been an increasing focuson developing effective general trojan scanning methods across various trojanattacks. Despite advancements, there remains a shortage of methods that performeffectively without preconceived assumptions about the backdoor attack method.Additionally, we have observed that current methods struggle to identifyclassifiers trojaned using adversarial training. Motivated by these challenges,our study introduces a novel scanning method named TRODO (TROjan scanning byDetection of adversarial shifts in Out-of-distribution samples). TRODOleverages the concept of "blind spots"--regions where trojaned classifierserroneously identify out-of-distribution (OOD) samples as in-distribution (ID).We scan for these blind spots by adversarially shifting OOD samples towardsin-distribution. The increased likelihood of perturbed OOD samples beingclassified as ID serves as a signature for trojan detection. TRODO is bothtrojan and label mapping agnostic, effective even against adversarially trainedtrojaned classifiers. It is applicable even in scenarios where training data isabsent, demonstrating high accuracy and adaptability across various scenariosand datasets, highlighting its potential as a robust trojan scanning strategy.</description><author>Hossein Mirzaei, Ali Ansari, Bahar Dibaei Nia, Mojtaba Nafez, Moein Madadi, Sepehr Rezaee, Zeinab Sadat Taghavi, Arad Maleki, Kian Shamsaie, Mahdi Hajialilue, Jafar Habibi, Mohammad Sabokrou, Mohammad Hossein Rohban</author><pubDate>Tue, 28 Jan 2025 18:53:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17151v1</guid></item><item><title>AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders</title><link>http://arxiv.org/abs/2501.17148v1</link><description>Fine-grained steering of language model outputs is essential for safety andreliability. Prompting and finetuning are widely used to achieve these goals,but interpretability researchers have proposed a variety ofrepresentation-based techniques as well, including sparse autoencoders (SAEs),linear artificial tomography, supervised steering vectors, linear probes, andrepresentation finetuning. At present, there is no benchmark for making directcomparisons between these proposals. Therefore, we introduce AxBench, alarge-scale benchmark for steering and concept detection, and reportexperiments on Gemma-2-2B and 9B. For steering, we find that promptingoutperforms all existing methods, followed by finetuning. For conceptdetection, representation-based methods such as difference-in-means, performthe best. On both evaluations, SAEs are not competitive. We introduce a novelweakly-supervised representational method (Rank-1 Representation Finetuning;ReFT-r1), which is competitive on both tasks while providing theinterpretability advantages that prompting lacks. Along with AxBench, we trainand publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.</description><author>Zhengxuan Wu, Aryaman Arora, Atticus Geiger, Zheng Wang, Jing Huang, Dan Jurafsky, Christopher D. Manning, Christopher Potts</author><pubDate>Tue, 28 Jan 2025 18:51:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17148v1</guid></item><item><title>FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data</title><link>http://arxiv.org/abs/2501.17144v1</link><description>Prior research on training grounded factuality classification models todetect hallucinations in large language models (LLMs) has relied on publicnatural language inference (NLI) data and synthetic data. However, conventionalNLI datasets are not well-suited for document-level reasoning, which iscritical for detecting LLM hallucinations. Recent approaches to document-levelsynthetic data generation involve iteratively removing sentences from documentsand annotating factuality using LLM-based prompts. While effective, this methodis computationally expensive for long documents and limited by the LLM'scapabilities. In this work, we analyze the differences between existingsynthetic training data used in state-of-the-art models and real LLM outputclaims. Based on our findings, we propose a novel approach for synthetic datageneration, CG2C, that leverages multi-hop reasoning on context graphsextracted from documents. Our fact checker model, FactCG, demonstrates improvedperformance with more connected reasoning, using the same backbone models.Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmarkwith much smaller model size.</description><author>Deren Lei, Yaxi Li, Siyao Li, Mengya Hu, Rui Xu, Ken Archer, Mingyu Wang, Emily Ching, Alex Deng</author><pubDate>Tue, 28 Jan 2025 18:45:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17144v1</guid></item><item><title>Abstract Operations Research Modeling Using Natural Language Inputs</title><link>http://arxiv.org/abs/2408.07272v2</link><description>Operations research (OR) uses mathematical models to enhance decision-making,but developing these models requires expert knowledge and can betime-consuming. Automated mathematical programming (AMP) has emerged tosimplify this process, but existing systems have limitations. This paperintroduces a novel methodology that uses recent advances in Large LanguageModel (LLM) to create and edit OR solutions from non-expert user queriesexpressed using Natural Language. This reduces the need for domain expertiseand the time to formulate a problem. The paper presents an end-to-end pipeline,named NL2OR, that generates solutions to OR problems from natural languageinput, and shares experimental results on several important OR problems.</description><author>Junxuan Li, Ryan Wickman, Sahil Bhatnagar, Raj Kumar Maity, Arko Mukherjee</author><pubDate>Tue, 28 Jan 2025 18:40:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07272v2</guid></item><item><title>LUDVIG: Learning-free Uplifting of 2D Visual features to Gaussian Splatting scenes</title><link>http://arxiv.org/abs/2410.14462v4</link><description>We address the problem of extending the capabilities of vision foundationmodels such as DINO, SAM, and CLIP, to 3D tasks. Specifically, we introduce anovel method to uplift 2D image features into Gaussian Splattingrepresentations of 3D scenes. Unlike traditional approaches that rely onminimizing a reconstruction loss, our method employs a simpler and moreefficient feature aggregation technique, augmented by a graph diffusionmechanism. Graph diffusion refines 3D features, such as coarse segmentationmasks, by leveraging 3D geometry and pairwise similarities induced by DINOv2.Our approach achieves performance comparable to the state of the art onmultiple downstream tasks while delivering significant speed-ups. Notably, weobtain competitive segmentation results using generic DINOv2 features, despiteDINOv2 not being trained on millions of annotated segmentation masks like SAM.When applied to CLIP features, our method demonstrates strong performance inopen-vocabulary object localization tasks, highlighting the versatility of ourapproach.</description><author>Juliette Marrie, Romain Menegaux, Michael Arbel, Diane Larlus, Julien Mairal</author><pubDate>Tue, 28 Jan 2025 18:35:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14462v4</guid></item><item><title>ASTRAL: Automated Safety Testing of Large Language Models</title><link>http://arxiv.org/abs/2501.17132v1</link><description>Large Language Models (LLMs) have recently gained attention due to theirability to understand and generate sophisticated human-like content. However,ensuring their safety is paramount as they might provide harmful and unsaferesponses. Existing LLM testing frameworks address various safety-relatedconcerns (e.g., drugs, terrorism, animal abuse) but often face challenges dueto unbalanced and obsolete datasets. In this paper, we present ASTRAL, a toolthat automates the generation and execution of test cases (i.e., prompts) fortesting the safety of LLMs. First, we introduce a novel black-box coveragecriterion to generate balanced and diverse unsafe test inputs across a diverseset of safety categories as well as linguistic writing characteristics (i.e.,different style and persuasive writing techniques). Second, we propose anLLM-based approach that leverages Retrieval Augmented Generation (RAG),few-shot prompting strategies and web browsing to generate up-to-date testinputs. Lastly, similar to current LLM test automation techniques, we leverageLLMs as test oracles to distinguish between safe and unsafe test outputs,allowing a fully automated testing approach. We conduct an extensive evaluationon well-known LLMs, revealing the following key findings: i) GPT3.5 outperformsother LLMs when acting as the test oracle, accurately detecting unsaferesponses, and even surpassing more recent LLMs (e.g., GPT-4), as well as LLMsthat are specifically tailored to detect unsafe LLM outputs (e.g., LlamaGuard);ii) the results confirm that our approach can uncover nearly twice as manyunsafe LLM behaviors with the same number of test inputs compared to currentlyused static datasets; and iii) our black-box coverage criterion combined withweb browsing can effectively guide the LLM on generating up-to-date unsafe testinputs, significantly increasing the number of unsafe LLM behaviors.</description><author>Miriam Ugarte, Pablo Valle, José Antonio Parejo, Sergio Segura, Aitor Arrieta</author><pubDate>Tue, 28 Jan 2025 18:25:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17132v1</guid></item><item><title>Coupling without Communication and Drafter-Invariant Speculative Decoding</title><link>http://arxiv.org/abs/2408.07978v3</link><description>Suppose Alice has a distribution $P$ and Bob has a distribution $Q$. Alicewants to draw a sample $a\sim P$ and Bob a sample $b \sim Q$ such that $a = b$with as high of probability as possible. It is well-known that, by samplingfrom an optimal coupling between the distributions, Alice and Bob can achieve$\Pr[a = b] = 1 - D_{TV}(P,Q)$, where $D_{TV}(P,Q)$ is the total variationdistance between $P$ and $Q$. What if Alice and Bob must solve this sameproblem \emph{without communicating at all?} Perhaps surprisingly, with accessto public randomness, they can still achieve $\Pr[a = b] \geq \frac{1 -D_{TV}(P,Q)}{1 + D_{TV}(P,Q)} \geq 1-2D_{TV}(P,Q)$ using a simple protocolbased on the Weighted MinHash algorithm. This bound was shown to be optimal inthe worst-case by [Bavarian et al., 2020]. In this work, we revisit thecommunication-free coupling problem. We provide a simpler proof of theoptimality result from [Bavarian et al., 2020]. We show that, while theworst-case success probability of Weighted MinHash cannot be improved, anequally simple protocol based on Gumbel sampling offers a Pareto improvement:for every pair of distributions $P, Q$, Gumbel sampling achieves an equal orhigher value of $\Pr[a = b]$ than Weighted MinHash. Importantly, thisimprovement translates to practice. We demonstrate an application ofcommunication-free coupling to \emph{speculative decoding}, a recent method foraccelerating autoregressive large language models [Leviathan, Kalman, Matias,ICML 2023]. We show that communication-free protocols can be used to contruct\emph{\CSD{}} schemes, which have the desirable property that their output isfixed given a fixed random seed, regardless of what drafter is used forspeculation. In experiments on a language generation task, Gumbel samplingoutperforms Weighted MinHash. Code is available athttps://github.com/majid-daliri/DISD.</description><author>Majid Daliri, Christopher Musco, Ananda Theertha Suresh</author><pubDate>Tue, 28 Jan 2025 18:23:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07978v3</guid></item><item><title>Scenario Understanding of Traffic Scenes Through Large Visual Language Models</title><link>http://arxiv.org/abs/2501.17131v1</link><description>Deep learning models for autonomous driving, encompassing perception,planning, and control, depend on vast datasets to achieve their highperformance. However, their generalization often suffers due to domain-specificdata distributions, making an effective scene-based categorization of samplesnecessary to improve their reliability across diverse domains. Manualcaptioning, though valuable, is both labor-intensive and time-consuming,creating a bottleneck in the data annotation process. Large Visual LanguageModels (LVLMs) present a compelling solution by automating image analysis andcategorization through contextual queries, often without requiring retrainingfor new categories. In this study, we evaluate the capabilities of LVLMs,including GPT-4 and LLaVA, to understand and classify urban traffic scenes onboth an in-house dataset and the BDD100K. We propose a scalable captioningpipeline that integrates state-of-the-art models, enabling a flexibledeployment on new datasets. Our analysis, combining quantitative metrics withqualitative insights, demonstrates the effectiveness of LVLMs to understandurban traffic scenarios and highlights their potential as an efficient tool fordata-driven advancements in autonomous driving.</description><author>Rivera Esteban, Lübberstedt Jannik, Nico Uhlemann, Markus Lienkamp</author><pubDate>Tue, 28 Jan 2025 18:23:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17131v1</guid></item><item><title>CoRe-Net: Co-Operational Regressor Network with Progressive Transfer Learning for Blind Radar Signal Restoration</title><link>http://arxiv.org/abs/2501.17125v1</link><description>Real-world radar signals are frequently corrupted by various artifacts,including sensor noise, echoes, interference, and intentional jamming,differing in type, severity, and duration. This pilot study introduces a novelmodel, called Co-Operational Regressor Network (CoRe-Net) for blind radarsignal restoration, designed to address such limitations and drawbacks.CoRe-Net replaces adversarial training with a novel cooperative learningstrategy, leveraging the complementary roles of its Apprentice Regressor (AR)and Master Regressor (MR). The AR restores radar signals corrupted by variousartifacts, while the MR evaluates the quality of the restoration and providesimmediate and task-specific feedback, ensuring stable and efficient learning.The AR, therefore, has the advantage of both self-learning and assistivelearning by the MR. The proposed model has been extensively evaluated over thebenchmark Blind Radar Signal Restoration (BRSR) dataset, which simulatesdiverse real-world artifact scenarios. Under the fair experimental setup, thisstudy shows that the CoRe-Net surpasses the Op-GANs over a 1 dB mean SNRimprovement. To further boost the performance gain, this study proposesmulti-pass restoration by cascaded CoRe-Nets trained with a novel paradigmcalled Progressive Transfer Learning (PTL), which enables iterative refinement,thus achieving an additional 2 dB mean SNR enhancement. Multi-pass CoRe-Nettraining by PTL consistently yields incremental performance improvementsthrough successive restoration passes whilst highlighting CoRe-Net ability tohandle such a complex and varying blend of artifacts.</description><author>Muhammad Uzair Zahid, Serkan Kiranyaz, Alper Yildirim, Moncef Gabbouj</author><pubDate>Tue, 28 Jan 2025 18:15:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17125v1</guid></item><item><title>Hybrid Deep Learning Model for Multiple Cache Side Channel Attacks Detection: A Comparative Analysis</title><link>http://arxiv.org/abs/2501.17123v1</link><description>Cache side channel attacks are a sophisticated and persistent threat thatexploit vulnerabilities in modern processors to extract sensitive information.These attacks leverage weaknesses in shared computational resources,particularly the last level cache, to infer patterns in data access andexecution flows, often bypassing traditional security defenses. Such attacksare especially dangerous as they can be executed remotely without requiringphysical access to the victim's device. This study focuses on a specific classof these threats: fingerprinting attacks, where an adversary monitors andanalyzes the behavior of co-located processes via cache side channels. This canpotentially reveal confidential information, such as encryption keys or useractivity patterns. A comprehensive threat model illustrates how attackerssharing computational resources with target systems exploit these side channelsto compromise sensitive data. To mitigate such risks, a hybrid deep learningmodel is proposed for detecting cache side channel attacks. Its performance iscompared with five widely used deep learning models: Multi-Layer Perceptron,Convolutional Neural Network, Simple Recurrent Neural Network, Long Short-TermMemory, and Gated Recurrent Unit. The experimental results demonstrate that thehybrid model achieves a detection rate of up to 99.96%. These findingshighlight the limitations of existing models, the need for enhanced defensivemechanisms, and directions for future research to secure sensitive data againstevolving side channel threats.</description><author>Tejal Joshi, Aarya Kawalay, Anvi Jamkhande, Amit Joshi</author><pubDate>Tue, 28 Jan 2025 18:14:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17123v1</guid></item><item><title>Convergence of two-timescale gradient descent ascent dynamics: finite-dimensional and mean-field perspectives</title><link>http://arxiv.org/abs/2501.17122v1</link><description>The two-timescale gradient descent-ascent (GDA) is a canonical gradientalgorithm designed to find Nash equilibria in min-max games. We analyze thetwo-timescale GDA by investigating the effects of learning rate ratios onconvergence behavior in both finite-dimensional and mean-field settings. Inparticular, for finite-dimensional quadratic min-max games, we obtain long-timeconvergence in near quasi-static regimes through the hypocoercivity method. Formean-field GDA dynamics, we investigate convergence under a finite-scale ratiousing a mixed synchronous-reflection coupling technique.</description><author>Jing An, Jianfeng Lu</author><pubDate>Tue, 28 Jan 2025 18:13:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17122v1</guid></item><item><title>Histoires Morales: A French Dataset for Assessing Moral Alignment</title><link>http://arxiv.org/abs/2501.17117v1</link><description>Aligning language models with human values is crucial, especially as theybecome more integrated into everyday life. While models are often adapted touser preferences, it is equally important to ensure they align with moral normsand behaviours in real-world social situations. Despite significant progress inlanguages like English and Chinese, French has seen little attention in thisarea, leaving a gap in understanding how LLMs handle moral reasoning in thislanguage. To address this gap, we introduce Histoires Morales, a French datasetderived from Moral Stories, created through translation and subsequentlyrefined with the assistance of native speakers to guarantee grammaticalaccuracy and adaptation to the French cultural context. We also rely onannotations of the moral values within the dataset to ensure their alignmentwith French norms. Histoires Morales covers a wide range of social situations,including differences in tipping practices, expressions of honesty inrelationships, and responsibilities toward animals. To foster future research,we also conduct preliminary experiments on the alignment of multilingual modelson French and English data and the robustness of the alignment. We find thatwhile LLMs are generally aligned with human moral norms by default, they can beeasily influenced with user-preference optimization for both moral and immoraldata.</description><author>Thibaud Leteno, Irina Proskurina, Antoine Gourru, Julien Velcin, Charlotte Laclau, Guillaume Metzler, Christophe Gravier</author><pubDate>Tue, 28 Jan 2025 18:07:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17117v1</guid></item><item><title>Optimizing Large Language Model Training Using FP4 Quantization</title><link>http://arxiv.org/abs/2501.17116v1</link><description>The growing computational demands of training large language models (LLMs)necessitate more efficient methods. Quantized training presents a promisingsolution by enabling low-bit arithmetic operations to reduce these costs. WhileFP8 precision has demonstrated feasibility, leveraging FP4 remains a challengedue to significant quantization errors and limited representational capacity.This work introduces the first FP4 training framework for LLMs, addressingthese challenges with two key innovations: a differentiable quantizationestimator for precise weight updates and an outlier clamping and compensationstrategy to prevent activation collapse. To ensure stability, the frameworkintegrates a mixed-precision training scheme and vector-wise quantization.Experimental results demonstrate that our FP4 framework achieves accuracycomparable to BF16 and FP8, with minimal degradation, scaling effectively to13B-parameter LLMs trained on up to 100B tokens. With the emergence ofnext-generation hardware supporting FP4, our framework sets a foundation forefficient ultra-low precision training.</description><author>Ruizhe Wang, Yeyun Gong, Xiao Liu, Guoshuai Zhao, Ziyue Yang, Baining Guo, Zhengjun Zha, Peng Cheng</author><pubDate>Tue, 28 Jan 2025 18:04:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17116v1</guid></item><item><title>Evidence on the Regularisation Properties of Maximum-Entropy Reinforcement Learning</title><link>http://arxiv.org/abs/2501.17115v1</link><description>The generalisation and robustness properties of policies learnt throughMaximum-Entropy Reinforcement Learning are investigated on chaotic dynamicalsystems with Gaussian noise on the observable. First, the robustness undernoise contamination of the agent's observation of entropy regularised policiesis observed. Second, notions of statistical learning theory, such as complexitymeasures on the learnt model, are borrowed to explain and predict thephenomenon. Results show the existence of a relationship betweenentropy-regularised policy optimisation and robustness to noise, which can bedescribed by the chosen complexity measures.</description><author>Rémy Hosseinkhan Boucher, Onofrio Semeraro, Lionel Mathelin</author><pubDate>Tue, 28 Jan 2025 18:04:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17115v1</guid></item><item><title>Preferences Evolve And So Should Your Bandits: Bandits with Evolving States for Online Platforms</title><link>http://arxiv.org/abs/2307.11655v5</link><description>We propose a model for learning with bandit feedback while accounting fordeterministically evolving and unobservable states that we call Bandits withDeterministically Evolving States ($B$-$DES$). The workhorse applications ofour model are learning for recommendation systems and learning for online ads.In both cases, the reward that the algorithm obtains at each round is afunction of the short-term reward of the action chosen and how "healthy" thesystem is (i.e., as measured by its state). For example, in recommendationsystems, the reward that the platform obtains from a user's engagement with aparticular type of content depends not only on the inherent features of thespecific content, but also on how the user's preferences have evolved as aresult of interacting with other types of content on the platform. Our generalmodel accounts for the different rate $\lambda \in [0,1]$ at which the stateevolves (e.g., how fast a user's preferences shift as a result of previouscontent consumption) and encompasses standard multi-armed bandits as a specialcase. The goal of the algorithm is to minimize a notion of regret against thebest-fixed sequence of arms pulled, which is significantly harder to attaincompared to standard benchmark of the best-fixed action in hindsight. Wepresent online learning algorithms for any possible value of the evolution rate$\lambda$ and we show the robustness of our results to various modelmisspecifications.</description><author>Khashayar Khosravi, Renato Paes Leme, Chara Podimata, Apostolis Tsorvantzis</author><pubDate>Tue, 28 Jan 2025 18:01:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11655v5</guid></item><item><title>Self-reflecting Large Language Models: A Hegelian Dialectical Approach</title><link>http://arxiv.org/abs/2501.14917v2</link><description>Investigating NLP through a philosophical lens has recently caughtresearcher's eyes as it connects computational methods with classical schoolsof philosophy. This paper introduces a philosophical approach inspired by theHegelian Dialectic for LLMs' self-reflection, utilizing a self-dialecticalapproach to emulate internal critiques and then synthesize new ideas byresolving the contradicting points. Moreover, this paper investigates theeffect of LLMs' temperature for generation by establishing a dynamic annealingapproach, which promotes the creativity in the early stages and graduallyrefines it by focusing on the nuances, as well as a fixed temperature strategyfor generation. Our proposed approach is examined to determine its ability togenerate novel ideas from an initial proposition. Additionally, a Multi AgentMajority Voting (MAMV) strategy is leveraged to assess the validity and noveltyof the generated ideas, which proves beneficial in the absence of domainexperts. Our experiments show promise in generating new ideas and provide astepping stone for future research.</description><author>Sara Abdali, Can Goksen, Saeed Amizadeh, Kazuhito Koishida</author><pubDate>Tue, 28 Jan 2025 18:00:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14917v2</guid></item><item><title>Unlocking Transparent Alignment Through Enhanced Inverse Constitutional AI for Principle Extraction</title><link>http://arxiv.org/abs/2501.17112v1</link><description>Traditional methods for aligning Large Language Models (LLMs), such asReinforcement Learning from Human Feedback (RLHF) and Direct PreferenceOptimization (DPO), rely on implicit principles, limiting interpretability.Constitutional AI (CAI) offers an explicit, rule-based framework for guidingmodel outputs. Building on this, we refine the Inverse Constitutional AI (ICAI)algorithm, which extracts constitutions from preference datasets. By improvingprinciple generation, clustering, and embedding processes, our approachenhances the accuracy and generalizability of extracted principles acrosssynthetic and real-world datasets. While in-context alignment yields modestimprovements, our results highlight the potential of these principles to fostermore transparent and adaptable alignment methods, offering a promisingdirection for future advancements beyond traditional fine-tuning.</description><author>Carl-Leander Henneking, Claas Beger</author><pubDate>Tue, 28 Jan 2025 17:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17112v1</guid></item><item><title>Solving Roughly Forced Nonlinear PDEs via Misspecified Kernel Methods and Neural Networks</title><link>http://arxiv.org/abs/2501.17110v1</link><description>We consider the use of Gaussian Processes (GPs) or Neural Networks (NNs) tonumerically approximate the solutions to nonlinear partial differentialequations (PDEs) with rough forcing or source terms, which commonly arise aspathwise solutions to stochastic PDEs. Kernel methods have recently beengeneralized to solve nonlinear PDEs by approximating their solutions as themaximum a posteriori estimator of GPs that are conditioned to satisfy the PDEat a finite set of collocation points. The convergence and error guarantees ofthese methods, however, rely on the PDE being defined in a classical sense andits solution possessing sufficient regularity to belong to the associatedreproducing kernel Hilbert space. We propose a generalization of these methodsto handle roughly forced nonlinear PDEs while preserving convergence guaranteeswith an oversmoothing GP kernel that is misspecified relative to the truesolution's regularity. This is achieved by conditioning a regular GP to satisfythe PDE with a modified source term in a weak sense (when integrated against afinite number of test functions). This is equivalent to replacing the empirical$L^2$-loss on the PDE constraint by an empirical negative-Sobolev norm. Wefurther show that this loss function can be used to extend physics-informedneural networks (PINNs) to stochastic equations, thereby resulting in a newNN-based variant termed Negative Sobolev Norm-PINN (NeS-PINN).</description><author>Matthieu Darcy, Edoardo Calvello, Ricardo Baptista, Houman Owhadi, Andrew M. Stuart, Xianjin Yang</author><pubDate>Tue, 28 Jan 2025 17:58:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17110v1</guid></item><item><title>COS(M+O)S: Curiosity and RL-Enhanced MCTS for Exploring Story Space via Language Models</title><link>http://arxiv.org/abs/2501.17104v1</link><description>We present COS(M+O)S, a System 2-inspired framework for open-ended plotdevelopment that systematically explores the vast space of possible storyexpansions, enabling a 3B-parameter language model to approach the plot qualityof a 70B model on select short-story tasks. The method accomplishes this bycombining Monte Carlo Tree Search (MCTS), guided by a step-level value modelthat rewards moderate surprisal (curiosity) while penalizing incoherence, andOdds Ratio Preference Optimization (ORPO) to fine-tune the policy on high-valueplot expansions. This iterative reinforcement learning loop systematicallyexplores multiple candidate plot branches, backpropagates quality signals, andadapts the policy for faster convergence, notably shifting the policy frompuzzle-based Chain-of-Thought to more character-driven storytelling. Insmall-scale tests with short-story prompts, 67%-77% of participants favoredCOS(M+O)S's highest-rated expansions over lower-rated ones, suggesting that ourlearned value function aligns. GPT-4o ratings further show that COS(M+O)Ssurpasses naive single-pass decoding from Llama 3.2 3B by 0.59 SD, comingwithin 0.06 SD of Llama 3.1 70B (no significant difference, p=0.93). Pairwisecomparisons with o1 place COS(M+O)S 1.5 SD above the 3B baseline and find nostatistically significant gap from 70B. Nevertheless, absolute story qualityremains modest, constrained by the small model's capacity and limited trainingdata.</description><author>Tobias Materzok</author><pubDate>Tue, 28 Jan 2025 17:44:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17104v1</guid></item><item><title>Text-to-Image Generation for Vocabulary Learning Using the Keyword Method</title><link>http://arxiv.org/abs/2501.17099v1</link><description>The 'keyword method' is an effective technique for learning vocabulary of aforeign language. It involves creating a memorable visual link between what aword means and what its pronunciation in a foreign language sounds like in thelearner's native language. However, these memorable visual links remainimplicit in the people's mind and are not easy to remember for a large set ofwords. To enhance the memorisation and recall of the vocabulary, we developedan application that combines the keyword method with text-to-image generatorsto externalise the memorable visual links into visuals. These visuals representadditional stimuli during the memorisation process. To explore theeffectiveness of this approach we first run a pilot study to investigate howdifficult it is to externalise the descriptions of mental visualisations ofmemorable links, by asking participants to write them down. We used thesedescriptions as prompts for text-to-image generator (DALL-E2) to convert theminto images and asked participants to select their favourites. Next, wecompared different text-to-image generators (DALL-E2, Midjourney, Stable andLatent Diffusion) to evaluate the perceived quality of the generated images byeach. Despite heterogeneous results, participants mostly preferred imagesgenerated by DALL-E2, which was used also for the final study. In this study,we investigated whether providing such images enhances the retention ofvocabulary being learned, compared to the keyword method only. Our resultsindicate that people did not encounter difficulties describing theirvisualisations of memorable links and that providing corresponding imagessignificantly improves memory retention.</description><author>Nuwan T. Attygalle, Matjaž Kljun, Aaron Quigley, Klen čOpič Pucihar, Jens Grubert, Verena Biener, Luis A. Leiva, Juri Yoneyama, Alice Toniolo, Angela Miguel, Hirokazu Kato, Maheshya Weerasinghe</author><pubDate>Tue, 28 Jan 2025 17:39:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17099v1</guid></item><item><title>Learning to Mitigate Externalities: the Coase Theorem with Hindsight Rationality</title><link>http://arxiv.org/abs/2406.19824v3</link><description>In economic theory, the concept of externality refers to any indirect effectresulting from an interaction between players that affects the social welfare.Most of the models within which externality has been studied assume that agentshave perfect knowledge of their environment and preferences. This is a majorhindrance to the practical implementation of many proposed solutions. Toaddress this issue, we consider a two-player bandit setting where the actionsof one of the players affect the other player and we extend the Coase theorem[Coase, 1960]. This result shows that the optimal approach for maximizing thesocial welfare in the presence of externality is to establish property rights,i.e., enable transfers and bargaining between the players. Our work removes theclassical assumption that bargainers possess perfect knowledge of theunderlying game. We first demonstrate that in the absence of property rights,the social welfare breaks down. We then design a policy for the players whichallows them to learn a bargaining strategy which maximizes the total welfare,recovering the Coase theorem under uncertainty.</description><author>Antoine Scheid, Aymeric Capitaine, Etienne Boursier, Eric Moulines, Michael I Jordan, Alain Durmus</author><pubDate>Tue, 28 Jan 2025 17:37:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19824v3</guid></item><item><title>Decictor: Towards Evaluating the Robustness of Decision-Making in Autonomous Driving Systems</title><link>http://arxiv.org/abs/2402.18393v3</link><description>Autonomous Driving System (ADS) testing is crucial in ADS development, withthe current primary focus being on safety. However, the evaluation ofnon-safety-critical performance, particularly the ADS's ability to make optimaldecisions and produce optimal paths for autonomous vehicles (AVs), is alsovital to ensure the intelligence and reduce risks of AVs. Currently, there islittle work dedicated to assessing the robustness of ADSs' path-planningdecisions (PPDs), i.e., whether an ADS can maintain the optimal PPD after aninsignificant change in the environment. The key challenges include the lack ofclear oracles for assessing PPD optimality and the difficulty in searching forscenarios that lead to non-optimal PPDs. To fill this gap, in this paper, wefocus on evaluating the robustness of ADSs' PPDs and propose the first method,Decictor, for generating non-optimal decision scenarios (NoDSs), where the ADSdoes not plan optimal paths for AVs. Decictor comprises three main components:Non-invasive Mutation, Consistency Check, and Feedback. To overcome the oraclechallenge, Non-invasive Mutation is devised to implement conservativemodifications, ensuring the preservation of the original optimal path in themutated scenarios. Subsequently, the Consistency Check is applied to determinethe presence of non-optimal PPDs by comparing the driving paths in the originaland mutated scenarios. To deal with the challenge of large environment space,we design Feedback metrics that integrate spatial and temporal dimensions ofthe AV's movement. These metrics are crucial for effectively steering thegeneration of NoDSs. We evaluate Decictor on Baidu Apollo, an open-source andproduction-grade ADS. The experimental results validate the effectiveness ofDecictor in detecting non-optimal PPDs of ADSs.</description><author>Mingfei Cheng, Yuan Zhou, Xiaofei Xie, Junjie Wang, Guozhu Meng, Kairui Yang</author><pubDate>Tue, 28 Jan 2025 17:36:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18393v3</guid></item><item><title>Adversarial Vulnerabilities in Large Language Models for Time Series Forecasting</title><link>http://arxiv.org/abs/2412.08099v3</link><description>Large Language Models (LLMs) have recently demonstrated significant potentialin the field of time series forecasting, offering impressive capabilities inhandling complex temporal data. However, their robustness and reliability inreal-world applications remain under-explored, particularly concerning theirsusceptibility to adversarial attacks. In this paper, we introduce a targetedadversarial attack framework for LLM-based time series forecasting. Byemploying both gradient-free and black-box optimization methods, we generateminimal yet highly effective perturbations that significantly degrade theforecasting accuracy across multiple datasets and LLM architectures. Ourexperiments, which include models like TimeGPT and LLM-Time with GPT-3.5,GPT-4, LLaMa, and Mistral, show that adversarial attacks lead to much moresevere performance degradation than random noise, and demonstrate the broadeffectiveness of our attacks across different LLMs. The results underscore thecritical vulnerabilities of LLMs in time series forecasting, highlighting theneed for robust defense mechanisms to ensure their reliable deployment inpractical applications.</description><author>Fuqiang Liu, Sicong Jiang, Luis Miranda-Moreno, Seongjin Choi, Lijun Sun</author><pubDate>Tue, 28 Jan 2025 17:33:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.08099v3</guid></item><item><title>Large Language Models for cross-language code clone detection</title><link>http://arxiv.org/abs/2408.04430v2</link><description>With the involvement of multiple programming languages in modern softwaredevelopment, cross-lingual code clone detection has gained traction within thesoftware engineering community. Numerous studies have explored this topic,proposing various promising approaches. Inspired by the significant advances inmachine learning in recent years, particularly Large Language Models (LLMs),which have demonstrated their ability to tackle various tasks, this paperrevisits cross-lingual code clone detection. We evaluate the performance offive (05) LLMs and eight prompts (08) for the identification of cross-lingualcode clones. Additionally, we compare these results against two baselinemethods. Finally, we evaluate a pre-trained embedding model to assess theeffectiveness of the generated representations for classifying clone andnon-clone pairs. The studies involving LLMs and Embedding models are evaluatedusing two widely used cross-lingual datasets, XLCoST and CodeNet. Our resultsshow that LLMs can achieve high F1 scores, up to 0.99, for straightforwardprogramming examples. However, they not only perform less well on programsassociated with complex programming challenges but also do not necessarilyunderstand the meaning of "code clones" in a cross-lingual setting. We showthat embedding models used to represent code fragments from differentprogramming languages in the same representation space enable the training of abasic classifier that outperforms all LLMs by ~1 and ~20 percentage points onthe XLCoST and CodeNet datasets, respectively. This finding suggests that,despite the apparent capabilities of LLMs, embeddings provided by embeddingmodels offer suitable representations to achieve state-of-the-art performancein cross-lingual code clone detection.</description><author>Micheline Bénédicte Moumoula, Abdoul Kader Kabore, Jacques Klein, Tegawendé Bissyande</author><pubDate>Tue, 28 Jan 2025 17:32:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.04430v2</guid></item><item><title>Why is the estimation of metaorder impact with public market data so challenging?</title><link>http://arxiv.org/abs/2501.17096v1</link><description>Estimating market impact and transaction costs of large trades (metaorders)is a very important topic in finance. However, using models of price and tradebased on public market data provide average price trajectories which arequalitatively different from what is observed during real metaorder executions:the price increases linearly, rather than in a concave way, during theexecution and the amount of reversion after its end is very limited. We claimthat this is a generic phenomenon due to the fact that even sophisticatedstatistical models are unable to correctly describe the origin of theautocorrelation of the order flow. We propose a modified Transient Impact Modelwhich provides more realistic trajectories by assuming that only a fraction ofthe metaorder trading triggers market order flow. Interestingly, in our modelthere is a critical condition on the kernels of the price and order flowequations in which market impact becomes permanent.</description><author>Manuel Naviglio, Giacomo Bormetti, Francesco Campigli, German Rodikov, Fabrizio Lillo</author><pubDate>Tue, 28 Jan 2025 17:29:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17096v1</guid></item><item><title>NeRAF: 3D Scene Infused Neural Radiance and Acoustic Fields</title><link>http://arxiv.org/abs/2405.18213v3</link><description>Sound plays a major role in human perception. Along with vision, it providesessential information for understanding our surroundings. Despite advances inneural implicit representations, learning acoustics that align with visualscenes remains a challenge. We propose NeRAF, a method that jointly learnsacoustic and radiance fields. NeRAF synthesizes both novel views andspatialized room impulse responses (RIR) at new positions by conditioning theacoustic field on 3D scene geometric and appearance priors from the radiancefield. The generated RIR can be applied to auralize any audio signal. Eachmodality can be rendered independently and at spatially distinct positions,offering greater versatility. We demonstrate that NeRAF generates high-qualityaudio on SoundSpaces and RAF datasets, achieving significant performanceimprovements over prior methods while being more data-efficient. Additionally,NeRAF enhances novel view synthesis of complex scenes trained with sparse datathrough cross-modal learning. NeRAF is designed as a Nerfstudio module,providing convenient access to realistic audio-visual generation.</description><author>Amandine Brunetto, Sascha Hornauer, Fabien Moutarde</author><pubDate>Tue, 28 Jan 2025 17:28:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18213v3</guid></item><item><title>Mamba-Shedder: Post-Transformer Compression for Efficient Selective Structured State Space Models</title><link>http://arxiv.org/abs/2501.17088v1</link><description>Large pre-trained models have achieved outstanding results in sequencemodeling. The Transformer block and its attention mechanism have been the maindrivers of the success of these models. Recently, alternative architectures,such as Selective Structured State Space Models (SSMs), have been proposed toaddress the inefficiencies of Transformers. This paper explores the compressionof SSM-based models, particularly Mamba and its hybrids. We study thesensitivity of these models to the removal of selected components at differentgranularities to reduce the model size and computational overhead, thusimproving their efficiency while maintaining accuracy. The proposed solutions,collectively referred to as Mamba-Shedder, achieve a speedup of up to 1.4xduring inference, demonstrating that model efficiency can be improved byeliminating several redundancies with minimal impact on the overall modelperformance. The code is available athttps://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.</description><author>J. Pablo Muñoz, Jinjie Yuan, Nilesh Jain</author><pubDate>Tue, 28 Jan 2025 17:22:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17088v1</guid></item><item><title>Cyber Shadows: Neutralizing Security Threats with AI and Targeted Policy Measures</title><link>http://arxiv.org/abs/2501.09025v2</link><description>The digital age, driven by the AI revolution, brings significantopportunities but also conceals security threats, which we refer to as cybershadows. These threats pose risks at individual, organizational, and societallevels. This paper examines the systemic impact of these cyber threats andproposes a comprehensive cybersecurity strategy that integrates AI-drivensolutions, such as Intrusion Detection Systems (IDS), with targeted policyinterventions. By combining technological and regulatory measures, we create amultilevel defense capable of addressing both direct threats and indirectnegative externalities. We emphasize that the synergy between AI-drivensolutions and policy interventions is essential for neutralizing cyber threatsand mitigating their negative impact on the digital economy. Finally, weunderscore the need for continuous adaptation of these strategies, especiallyin response to the rapid advancement of autonomous AI-driven attacks, to ensurethe creation of secure and resilient digital ecosystems.</description><author>Marc Schmitt, Pantelis Koutroumpis</author><pubDate>Tue, 28 Jan 2025 17:15:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09025v2</guid></item><item><title>Accelerated Training through Iterative Gradient Propagation Along the Residual Path</title><link>http://arxiv.org/abs/2501.17086v1</link><description>Despite being the cornerstone of deep learning, backpropagation is criticizedfor its inherent sequentiality, which can limit the scalability of very deepmodels. Such models faced convergence issues due to vanishing gradient, laterresolved using residual connections. Variants of these are now widely used inmodern architecture. However, the computational cost of backpropagation remainsa major burden, accounting for most of the training time. Taking advantage ofresidual-like architectural designs, we introduce Highway backpropagation, aparallelizable iterative algorithm that approximates backpropagation, byalternatively i) accumulating the gradient estimates along the residual path,and ii) backpropagating them through every layer in parallel. This algorithm isnaturally derived from a decomposition of the gradient as the sum of gradientsflowing through all paths and is adaptable to a diverse set of commonarchitectures, ranging from ResNets and Transformers to recurrent neuralnetworks. Through an extensive empirical study on a large selection of tasksand models, we evaluate Highway-BP and show that major speedups can be achievedwith minimal performance degradation.</description><author>Erwan Fagnou, Paul Caillon, Blaise Delattre, Alexandre Allauzen</author><pubDate>Tue, 28 Jan 2025 17:14:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17086v1</guid></item><item><title>Evaluating CrowdSplat: Perceived Level of Detail for Gaussian Crowds</title><link>http://arxiv.org/abs/2501.17085v1</link><description>Efficient and realistic crowd rendering is an important element of manyreal-time graphics applications such as Virtual Reality (VR) and games. To thisend, Levels of Detail (LOD) avatar representations such as polygonal meshes,image-based impostors, and point clouds have been proposed and evaluated. Morerecently, 3D Gaussian Splatting has been explored as a potential method forreal-time crowd rendering. In this paper, we present a two-alternative forcedchoice (2AFC) experiment that aims to determine the perceived quality of 3DGaussian avatars. Three factors were explored: Motion, LOD (i.e., #Gaussians),and the avatar height in Pixels (corresponding to the viewing distance).Participants viewed pairs of animated 3D Gaussian avatars and were tasked withchoosing the most detailed one. Our findings can inform the optimization of LODstrategies in Gaussian-based crowd rendering, thereby helping to achieveefficient rendering while maintaining visual quality in real-time applications.</description><author>Xiaohan Sun, Yinghan Xu, John Dingliana, Carol O'Sullivan</author><pubDate>Tue, 28 Jan 2025 17:14:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17085v1</guid></item><item><title>Token-by-Token Regeneration and Domain Biases: A Benchmark of LLMs on Advanced Mathematical Problem-Solving</title><link>http://arxiv.org/abs/2501.17084v1</link><description>Large language models (LLMs) excel in many natural language tasks, yet theystruggle with complex mathemat-ical problem-solving, particularly in symbolicreasoning and maintaining consistent output. This study evalu-ates 10 LLMs with7 to 8 billion parameters using 945 competition-level problems from the MATHdataset. The focus is on their ability to generate executable Python code as astep in their reasoning process, involving over 9,450 code executions. Theresearch introduces an evaluation framework using mistral-large-2411 to rateanswers on a 5-point scale, which helps address inconsistencies in mathematicalnotation. It also examines the impact of regenerating output token-by-token onrefining results. The findings reveal a significant 34.5% per-formance gapbetween the top commercial model (gpt-4o-mini, scoring 83.7%) and the leasteffective open-source model (open-codestral-mamba:v0.1, scoring 49.2%). Thisdisparity is especially noticeable in complex areas like Number Theory. Whiletoken-by-token regeneration slightly improved accuracy (+0.8%) for the modelllama3.1:8b, it also reduced code execution time by 36.7%, highlighting atrade-off between efficiency and precision. The study also noted a consistenttrend where harder problems correlated with lower accuracy across all models.Despite using controlled execution environments, less than 1% of the generatedcode was unsafe, and 3.17% of problems remained unsolved after 10 attempts,suggesting that hybrid reasoning methods may be beneficial.</description><author>Evgenii Evstafev</author><pubDate>Tue, 28 Jan 2025 17:11:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17084v1</guid></item><item><title>Distilling foundation models for robust and efficient models in digital pathology</title><link>http://arxiv.org/abs/2501.16239v2</link><description>In recent years, the advent of foundation models (FM) for digital pathologyhas relied heavily on scaling the pre-training datasets and the model size,yielding large and powerful models. While it resulted in improving theperformance on diverse downstream tasks, it also introduced increasedcomputational cost and inference time. In this work, we explore thedistillation of a large foundation model into a smaller one, reducing thenumber of parameters by several orders of magnitude. Leveraging distillationtechniques, our distilled model, H0-mini, achieves nearly comparableperformance to large FMs at a significantly reduced inference cost. It isevaluated on several public benchmarks, achieving 3rd place on the HESTbenchmark and 5th place on the EVA benchmark. Additionally, a robustnessanalysis conducted on the PLISM dataset demonstrates that our distilled modelreaches excellent robustness to variations in staining and scanning conditions,significantly outperforming other state-of-the art models. This opens newperspectives to design lightweight and robust models for digital pathology,without compromising on performance.</description><author>Alexandre Filiot, Nicolas Dop, Oussama Tchita, Auriane Riou, Rémy Dubois, Thomas Peeters, Daria Valter, Marin Scalbert, Charlie Saillard, Geneviève Robin, Antoine Olivier</author><pubDate>Tue, 28 Jan 2025 17:09:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16239v2</guid></item><item><title>Graph Transformers for inverse physics: reconstructing flows around arbitrary 2D airfoils</title><link>http://arxiv.org/abs/2501.17081v1</link><description>We introduce a Graph Transformer framework that serves as a general inversephysics engine on meshes, demonstrated through the challenging task ofreconstructing aerodynamic flow fields from sparse surface measurements. Whiledeep learning has shown promising results in forward physics simulation,inverse problems remain particularly challenging due to their ill-posed natureand the difficulty of propagating information from limited boundaryobservations. Our approach addresses these challenges by combining thegeometric expressiveness of message-passing neural networks with the globalreasoning of Transformers, enabling efficient learning of inverse mappings fromboundary conditions to complete states. We evaluate this framework on acomprehensive dataset of steady-state RANS simulations around diverse airfoilgeometries, where the task is to reconstruct full pressure and velocity fieldsfrom surface pressure measurements alone. The architecture achieves highreconstruction accuracy while maintaining fast inference times. We conductexperiments and provide insights into the relative importance of localgeometric processing and global attention mechanisms in mesh-based inverseproblems. We also find that the framework is robust to reduced sensor coverage.These results suggest that Graph Transformers can serve as effective inversephysics engines across a broader range of applications where complete systemstates must be reconstructed from limited boundary observations.</description><author>Gregory Duthé, Imad Abdallah, Eleni Chatzi</author><pubDate>Tue, 28 Jan 2025 17:06:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17081v1</guid></item><item><title>Autonomous Bootstrapping of Quantum Dot Devices</title><link>http://arxiv.org/abs/2407.20061v2</link><description>Semiconductor quantum dots (QDs) are a promising platform for multipledifferent qubit implementations, all of which are voltage controlled byprogrammable gate electrodes. However, as the QD arrays grow in size andcomplexity, tuning procedures that can fully autonomously handle the increasingnumber of control parameters are becoming essential for enabling scalability.We propose a bootstrapping algorithm for initializing a depletion-mode QDdevice in preparation for subsequent phases of tuning. During bootstrapping,the QD device functionality is validated, all gates are characterized, and theQD charge sensor is made operational. We demonstrate the bootstrapping protocolin conjunction with a coarse-tuning module, showing that the combined algorithmcan efficiently and reliably take a cooled-down QD device to a desiredglobal-state configuration in under 8 min with a success rate of 96 %. Finally,by following heuristic approaches to QD device initialization and combining theefficient ray-based measurement with the rapid radio-frequency reflectometrymeasurements, the proposed algorithm establishes a reference in terms ofperformance, reliability, and efficiency against which alternative algorithmscan be benchmarked.</description><author>Anton Zubchenko, Danielle Middlebrooks, Torbjørn Rasmussen, Lara Lausen, Ferdinand Kuemmeth, Anasua Chatterjee, Justyna P. Zwolak</author><pubDate>Tue, 28 Jan 2025 17:03:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20061v2</guid></item><item><title>Learning Mean Field Control on Sparse Graphs</title><link>http://arxiv.org/abs/2501.17079v1</link><description>Large agent networks are abundant in applications and nature and posedifficult challenges in the field of multi-agent reinforcement learning (MARL)due to their computational and theoretical complexity. While graphon mean fieldgames and their extensions provide efficient learning algorithms for dense andmoderately sparse agent networks, the case of realistic sparser graphs remainslargely unsolved. Thus, we propose a novel mean field control model inspired bylocal weak convergence to include sparse graphs such as power law networks withcoefficients above two. Besides a theoretical analysis, we design scalablelearning algorithms which apply to the challenging class of graph sequenceswith finite first moment. We compare our model and algorithms for variousexamples on synthetic and real world networks with mean field algorithms basedon Lp graphons and graphexes. As it turns out, our approach outperformsexisting methods in many examples and on various networks due to the specialdesign aiming at an important, but so far hard to solve class of MARL problems.</description><author>Christian Fabian, Kai Cui, Heinz Koeppl</author><pubDate>Tue, 28 Jan 2025 17:03:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17079v1</guid></item><item><title>Induced Modularity and Community Detection for Functionally Interpretable Reinforcement Learning</title><link>http://arxiv.org/abs/2501.17077v1</link><description>Interpretability in reinforcement learning is crucial for ensuring AI systemsalign with human values and fulfill the diverse related requirements includingsafety, robustness and fairness. Building on recent approaches to encouragingsparsity and locality in neural networks, we demonstrate how the penalisationof non-local weights leads to the emergence of functionally independent modulesin the policy network of a reinforcement learning agent. To illustrate this, wedemonstrate the emergence of two parallel modules for assessment of movementalong the X and Y axes in a stochastic Minigrid environment. Through the novelapplication of community detection algorithms, we show how these modules can beautomatically identified and their functional roles verified through directintervention on the network weights prior to inference. This establishes ascalable framework for reinforcement learning interpretability throughfunctional modularity, addressing challenges regarding the trade-off betweencompleteness and cognitive tractability of reinforcement learning explanations.</description><author>Anna Soligo, Pietro Ferraro, David Boyle</author><pubDate>Tue, 28 Jan 2025 17:02:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17077v1</guid></item><item><title>DINOSTAR: Deep Iterative Neural Object Detector Self-Supervised Training for Roadside LiDAR Applications</title><link>http://arxiv.org/abs/2501.17076v1</link><description>Recent advancements in deep-learning methods for object detection inpoint-cloud data have enabled numerous roadside applications, fosteringimprovements in transportation safety and management. However, the intricatenature of point-cloud data poses significant challenges for human-supervisedlabeling, resulting in substantial expenditures of time and capital. This paperaddresses the issue by developing an end-to-end, scalable, and self-supervisedframework for training deep object detectors tailored for roadside point-clouddata. The proposed framework leverages self-supervised, statistically modeledteachers to train off-the-shelf deep object detectors, thus circumventing theneed for human supervision. The teacher models follow fine-tuned set standardpractices of background filtering, object clustering, bounding-box fitting, andclassification to generate noisy labels. It is presented that by training thestudent model over the combined noisy annotations from multitude of teachersenhances its capacity to discern background/foreground more effectively andforces it to learn diverse point-cloud-representations for object categories ofinterest. The evaluations, involving publicly available roadside datasets andstate-of-art deep object detectors, demonstrate that the proposed frameworkachieves comparable performance to deep object detectors trained onhuman-annotated labels, despite not utilizing such human-annotations in itstraining process.</description><author>Muhammad Shahbaz, Shaurya Agarwal</author><pubDate>Tue, 28 Jan 2025 17:01:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17076v1</guid></item><item><title>Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks</title><link>http://arxiv.org/abs/2501.11733v2</link><description>Smartphones have become indispensable in modern life, yet navigating complextasks on mobile devices often remains frustrating. Recent advancements in largemultimodal model (LMM)-based mobile agents have demonstrated the ability toperceive and act in mobile environments. However, current approaches facesignificant limitations: they fall short in addressing real-world human needs,struggle with reasoning-intensive and long-horizon tasks, and lack mechanismsto learn and improve from prior experiences. To overcome these challenges, weintroduce Mobile-Agent-E, a hierarchical multi-agent framework capable ofself-evolution through past experience. By hierarchical, we mean an explicitseparation of high-level planning and low-level action execution. The frameworkcomprises a Manager, responsible for devising overall plans by breaking downcomplex tasks into subgoals, and four subordinate agents--Perceptor, Operator,Action Reflector, and Notetaker--which handle fine-grained visual perception,immediate action execution, error verification, and information aggregation,respectively. Mobile-Agent-E also features a novel self-evolution module whichmaintains a persistent long-term memory comprising Tips and Shortcuts. Tips aregeneral guidance and lessons learned from prior tasks on how to effectivelyinteract with the environment. Shortcuts are reusable, executable sequences ofatomic operations tailored for specific subroutines. The inclusion of Tips andShortcuts facilitates continuous refinement in performance and efficiency.Alongside this framework, we introduce Mobile-Eval-E, a new benchmark featuringcomplex mobile tasks requiring long-horizon, multi-app interactions. Empiricalresults show that Mobile-Agent-E achieves a 22% absolute improvement overprevious state-of-the-art approaches across three foundation model backbones.Project page: https://x-plug.github.io/MobileAgent.</description><author>Zhenhailong Wang, Haiyang Xu, Junyang Wang, Xi Zhang, Ming Yan, Ji Zhang, Fei Huang, Heng Ji</author><pubDate>Tue, 28 Jan 2025 16:58:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11733v2</guid></item><item><title>Context is Key in Agent Security</title><link>http://arxiv.org/abs/2501.17070v1</link><description>Judging the safety of an action, whether taken by a human or a system, musttake into account the context in which the action takes place. Deleting anemail from user's mailbox may or may not be appropriate depending on email'scontent, user's goals, or even available space. Systems today that make thesejudgements -- providing security against harmful or inappropriate actions --rely on manually-crafted policies or user confirmation for each relevantcontext. With the upcoming deployment of systems like generalist agents, weargue that we must rethink security designs to adapt to the scale of contextsand capabilities of these systems. As a first step, this paper explorescontextual security in the domain of agents and proposes contextual securityfor agents (Conseca), a framework to generate just-in-time, contextual, andhuman-verifiable security policies.</description><author>Lillian Tsai, Eugene Bagdasarian</author><pubDate>Tue, 28 Jan 2025 16:55:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17070v1</guid></item><item><title>Generalized Distribution Prediction for Asset Returns</title><link>http://arxiv.org/abs/2410.23296v2</link><description>We present a novel approach for predicting the distribution of asset returnsusing a quantile-based method with Long Short-Term Memory (LSTM) networks. Ourmodel is designed in two stages: the first focuses on predicting the quantilesof normalized asset returns using asset-specific features, while the secondstage incorporates market data to adjust these predictions for broader economicconditions. This results in a generalized model that can be applied acrossvarious asset classes, including commodities, cryptocurrencies, as well assynthetic datasets. The predicted quantiles are then converted into fullprobability distributions through kernel density estimation, allowing for moreprecise return distribution predictions and inferencing. The LSTM modelsignificantly outperforms a linear quantile regression baseline by 98% and adense neural network model by over 50%, showcasing its ability to capturecomplex patterns in financial return distributions across both synthetic andreal-world data. By using exclusively asset-class-neutral features, our modelachieves robust, generalizable results.</description><author>Ísak Pétursson, María Óskarsdóttir</author><pubDate>Tue, 28 Jan 2025 16:51:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23296v2</guid></item><item><title>On AI-Inspired UI-Design</title><link>http://arxiv.org/abs/2406.13631v2</link><description>Graphical User Interface (or simply UI) is a primary mean of interactionbetween users and their devices. In this paper, we discuss three complementaryArtificial Intelligence (AI) approaches for triggering the creativity of appdesigners and inspiring them create better and more diverse UI designs. First,designers can prompt a Large Language Model (LLM) to directly generate andadjust UIs. Second, a Vision-Language Model (VLM) enables designers toeffectively search a large screenshot dataset, e.g. from apps published in appstores. Third, a Diffusion Model (DM) can be trained to specifically generateUIs as inspirational images. We present an AI-inspired design process anddiscuss the implications and limitations of the approaches.</description><author>Jialiang Wei, Anne-Lise Courbis, Thomas Lambolais, Gérard Dray, Walid Maalej</author><pubDate>Tue, 28 Jan 2025 16:42:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13631v2</guid></item><item><title>EdgeMLOps: Operationalizing ML models with Cumulocity IoT and thin-edge.io for Visual quality Inspection</title><link>http://arxiv.org/abs/2501.17062v1</link><description>This paper introduces EdgeMLOps, a framework leveraging Cumulocity IoT andthin-edge.io for deploying and managing machine learning models onresource-constrained edge devices. We address the challenges of modeloptimization, deployment, and lifecycle management in edge environments. Theframework's efficacy is demonstrated through a visual quality inspection (VQI)use case where images of assets are processed on edge devices, enablingreal-time condition updates within an asset management system. Furthermore, weevaluate the performance benefits of different quantization methods,specifically static and dynamic signed-int8, on a Raspberry Pi 4, demonstratingsignificant inference time reductions compared to FP32 precision. Our resultshighlight the potential of EdgeMLOps to enable efficient and scalable AIdeployments at the edge for industrial applications.</description><author>Kanishk Chaturvedi, Johannes Gasthuber, Mohamed Abdelaal</author><pubDate>Tue, 28 Jan 2025 16:40:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17062v1</guid></item><item><title>PAPILLON: Privacy Preservation from Internet-based and Local Language Model Ensembles</title><link>http://arxiv.org/abs/2410.17127v2</link><description>Users can divulge sensitive information to proprietary LLM providers, raisingsignificant privacy concerns. While open-source models, hosted locally on theuser's machine, alleviate some concerns, models that users can host locally areoften less capable than proprietary frontier models. Toward preserving userprivacy while retaining the best quality, we propose Privacy-ConsciousDelegation, a novel task for chaining API-based and local models. We utilizerecent public collections of user-LLM interactions to construct a naturalbenchmark called PUPA, which contains personally identifiable information(PII). To study potential approaches, we devise PAPILLON, a multi-stage LLMpipeline that uses prompt optimization to address a simpler version of ourtask. Our best pipeline maintains high response quality for 85.5% of userqueries while restricting privacy leakage to only 7.5%. We still leave a largemargin to the generation quality of proprietary LLMs for future work. Our dataand code will be available at https://github.com/siyan-sylvia-li/PAPILLON.</description><author>Li Siyan, Vethavikashini Chithrra Raghuram, Omar Khattab, Julia Hirschberg, Zhou Yu</author><pubDate>Tue, 28 Jan 2025 16:31:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17127v2</guid></item><item><title>Generative diffusion models from a PDE perspective</title><link>http://arxiv.org/abs/2501.17054v1</link><description>Diffusion models have become the de facto framework for generating newdatasets. The core of these models lies in the ability to reverse a diffusionprocess in time. The goal of this manuscript is to explain, from a PDEperspective, how this method works and how to derive the PDE governing thereverse dynamics as well as to study its solution analytically. By linkingforward and reverse dynamics, we show that the reverse process's distributionhas its support contained within the original distribution. Consequently,diffusion methods, in their analytical formulation, do not inherentlyregularize the original distribution, and thus, there is no generalizationprinciple. This raises a question: where does generalization arise, given thatin practice it does occur? Moreover, we derive an explicit solution to thereverse process's SDE under the assumption that the starting point of theforward process is fixed. This provides a new derivation that links two popularapproaches to generative diffusion models: stable diffusion (discrete dynamics)and the score-based approach (continuous dynamics). Finally, we explore thecase where the original distribution consists of a finite set of data points.In this scenario, the reverse dynamics are explicit (i.e., the loss functionhas a clear minimizer), and solving the dynamics fails to generate new samples:the dynamics converge to the original samples. In a sense, solving theminimization problem exactly is "too good for its own good" (i.e., anoverfitting regime).</description><author>Fei Cao, Kimball Johnston, Thomas Laurent, Justin Le, Sébastien Motsch</author><pubDate>Tue, 28 Jan 2025 16:29:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17054v1</guid></item><item><title>MINTQA: A Multi-Hop Question Answering Benchmark for Evaluating LLMs on New and Tail Knowledge</title><link>http://arxiv.org/abs/2412.17032v2</link><description>Large language models (LLMs) have demonstrated impressive capabilities invarious reasoning tasks but face significant challenges with complex,knowledge-intensive multi-hop queries, particularly those involving new orlong-tail knowledge. Existing benchmarks often fail to fully address thesechallenges. To bridge this gap, we introduce MINTQA (Multi-hop QuestionAnswering on New and Tail Knowledge), a comprehensive benchmark to evaluateLLMs' capabilities in multi-hop reasoning across four critical dimensions:question handling strategy, sub-question generation, retrieval-augmentedgeneration, and iterative or dynamic decomposition and retrieval. MINTQAcomprises 10,479 question-answer pairs for evaluating new knowledge and 17,887pairs for assessing long-tail knowledge, with each question equipped withcorresponding sub-questions and answers. Our systematic evaluation of 22state-of-the-art LLMs on MINTQA reveals significant limitations in theirability to handle complex knowledge base queries, particularly in handling newor unpopular knowledge. Our findings highlight critical challenges and offerinsights for advancing multi-hop reasoning capabilities. The MINTQA benchmarkis available at https://github.com/probe2/multi-hop/.</description><author>Jie He, Nan Hu, Wanqiu Long, Jiaoyan Chen, Jeff Z. Pan</author><pubDate>Tue, 28 Jan 2025 16:28:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17032v2</guid></item><item><title>Contextual Self-paced Learning for Weakly Supervised Spatio-Temporal Video Grounding</title><link>http://arxiv.org/abs/2501.17053v1</link><description>In this work, we focus on Weakly Supervised Spatio-Temporal Video Grounding(WSTVG). It is a multimodal task aimed at localizing specific subjectsspatio-temporally based on textual queries without bounding box supervision.Motivated by recent advancements in multi-modal foundation models for groundingtasks, we first explore the potential of state-of-the-art object detectionmodels for WSTVG. Despite their robust zero-shot capabilities, our adaptationreveals significant limitations, including inconsistent temporal predictions,inadequate understanding of complex queries, and challenges in adapting todifficult scenarios. We propose CoSPaL (Contextual Self-Paced Learning), anovel approach which is designed to overcome these limitations. CoSPaLintegrates three core components: (1) Tubelet Phrase Grounding (TPG), whichintroduces spatio-temporal prediction by linking textual queries to tubelets;(2) Contextual Referral Grounding (CRG), which improves comprehension ofcomplex queries by extracting contextual information to refine objectidentification over time; and (3) Self-Paced Scene Understanding (SPS), atraining paradigm that progressively increases task difficulty, enabling themodel to adapt to complex scenarios by transitioning from coarse tofine-grained understanding.</description><author>Akash Kumar, Zsolt Kira, Yogesh Singh Rawat</author><pubDate>Tue, 28 Jan 2025 16:25:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17053v1</guid></item><item><title>Intelligent Tutors for Adult Learners: An Analysis of Needs and Challenges</title><link>http://arxiv.org/abs/2412.04477v2</link><description>This research examines the sociotechnical factors that influence the adoptionand usage of intelligent tutoring systems in self-directed learning contexts,focusing specifically on adult learners. The study is divided into two parts.First, we present Apprentice Tutors, a novel intelligent tutoring systemdesigned to address the unique needs of adult learners. The platform includesadaptive problem selection, real-time feedback, and visual dashboards tosupport learning in college algebra topics. Second, we investigate the specificneeds and experiences of adult users through a deployment study and a series offocus groups. Using thematic analysis, we identify key challenges andopportunities for improving tutor design and adoption. Based on these findings,we offer actionable design recommendations to help developers createintelligent tutoring systems that better align with the motivations andlearning preferences of adult learners. This work contributes to the broaderunderstanding of how to enhance educational technologies to support lifelonglearning and professional development.</description><author>Adit Gupta, Momin Siddiqui, Glen Smith, Jenn Reddig, Christopher MacLellan</author><pubDate>Tue, 28 Jan 2025 16:24:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04477v2</guid></item><item><title>Hellinger-Kantorovich Gradient Flows: Global Exponential Decay of Entropy Functionals</title><link>http://arxiv.org/abs/2501.17049v1</link><description>We investigate a family of gradient flows of positive and probabilitymeasures, focusing on the Hellinger-Kantorovich (HK) geometry, which unifiestransport mechanism of Otto-Wasserstein, and the birth-death mechanism ofHellinger (or Fisher-Rao). A central contribution is a completecharacterization of global exponential decay behaviors of entropy functionals(e.g. KL, $\chi^2$) under Otto-Wasserstein and Hellinger-type gradient flows.In particular, for the more challenging analysis of HK gradient flows onpositive measures -- where the typical log-Sobolev arguments fail -- we developa specialized shape-mass decomposition that enables new analysis results. Ourapproach also leverages the (Polyak-)\L{}ojasiewicz-type functionalinequalities and a careful extension of classical dissipation estimates. Thesefindings provide a unified and complete theoretical framework for gradientflows and underpin applications in computational algorithms for statisticalinference, optimization, and machine learning.</description><author>Alexander Mielke, Jia-Jie Zhu</author><pubDate>Tue, 28 Jan 2025 16:17:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17049v1</guid></item><item><title>How Linguistics Learned to Stop Worrying and Love the Language Models</title><link>http://arxiv.org/abs/2501.17047v1</link><description>Language models can produce fluent, grammatical text. Nonetheless, somemaintain that language models don't really learn language and also that, evenif they did, that would not be informative for the study of human learning andprocessing. On the other side, there have been claims that the success of LMsobviates the need for studying linguistic theory and structure. We argue thatboth extremes are wrong. LMs can contribute to fundamental questions aboutlinguistic structure, language processing, and learning. They force us torethink arguments about learning and are informative for major questions inlinguistic theory. But they do not replace linguistic structure and theory. Weoffer an optimistic take on the relationship between language models andlinguistics.</description><author>Richard Futrell, Kyle Mahowald</author><pubDate>Tue, 28 Jan 2025 16:13:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17047v1</guid></item><item><title>Synthesizing 3D Abstractions by Inverting Procedural Buildings with Transformers</title><link>http://arxiv.org/abs/2501.17044v1</link><description>We generate abstractions of buildings, reflecting the essential aspects oftheir geometry and structure, by learning to invert procedural models. We firstbuild a dataset of abstract procedural building models paired with simulatedpoint clouds and then learn the inverse mapping through a transformer. Given apoint cloud, the trained transformer then infers the corresponding abstractedbuilding in terms of a programmatic language description. This approachleverages expressive procedural models developed for gaming and animation, andthereby retains desirable properties such as efficient rendering of theinferred abstractions and strong priors for regularity and symmetry. Ourapproach achieves good reconstruction accuracy in terms of geometry andstructure, as well as structurally consistent inpainting.</description><author>Max Dax, Jordi Berbel, Jan Stria, Leonidas Guibas, Urs Bergmann</author><pubDate>Tue, 28 Jan 2025 16:09:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17044v1</guid></item><item><title>Benchmarking Quantum Convolutional Neural Networks for Signal Classification in Simulated Gamma-Ray Burst Detection</title><link>http://arxiv.org/abs/2501.17041v1</link><description>This study evaluates the use of Quantum Convolutional Neural Networks (QCNNs)for identifying signals resembling Gamma-Ray Bursts (GRBs) within simulatedastrophysical datasets in the form of light curves. The task addressed herefocuses on distinguishing GRB-like signals from background noise in simulatedCherenkov Telescope Array Observatory (CTAO) data, the next-generationastrophysical observatory for very high-energy gamma-ray science. QCNNs, aquantum counterpart of classical Convolutional Neural Networks (CNNs), leveragequantum principles to process and analyze high-dimensional data efficiently. Weimplemented a hybrid quantum-classical machine learning technique using theQiskit framework, with the QCNNs trained on a quantum simulator. Several QCNNarchitectures were tested, employing different encoding methods such as DataReuploading and Amplitude encoding. Key findings include that QCNNs achievedaccuracy comparable to classical CNNs, often surpassing 90\%, while using fewerparameters, potentially leading to more efficient models in terms ofcomputational resources. A benchmark study further examined how hyperparameterslike the number of qubits and encoding methods affected performance, with morequbits and advanced encoding methods generally enhancing accuracy butincreasing complexity. QCNNs showed robust performance on time-series datasets,successfully detecting GRB signals with high precision. The research is apioneering effort in applying QCNNs to astrophysics, offering insights intotheir potential and limitations. This work sets the stage for futureinvestigations to fully realize the advantages of QCNNs in astrophysical dataanalysis.</description><author>Farida Farsian, Nicolò Parmiggiani, Alessandro Rizzo, Gabriele Panebianco, Andrea Bulgarelli, Francesco Schillirò, Carlo Burigana, Vincenzo Cardone, Luca Cappelli, Massimo Meneghetti, Giuseppe Murante, Giuseppe Sarracino, Roberto Scaramella, Vincenzo Testa, Tiziana Trombetti</author><pubDate>Tue, 28 Jan 2025 16:07:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17041v1</guid></item><item><title>PokeFlex: A Real-World Dataset of Volumetric Deformable Objects for Robotics</title><link>http://arxiv.org/abs/2410.07688v2</link><description>Data-driven methods have shown great potential in solving challengingmanipulation tasks; however, their application in the domain of deformableobjects has been constrained, in part, by the lack of data. To address thislack, we propose PokeFlex, a dataset featuring real-world multimodal data thatis paired and annotated. The modalities include 3D textured meshes, pointclouds, RGB images, and depth maps. Such data can be leveraged for severaldownstream tasks, such as online 3D mesh reconstruction, and it can potentiallyenable underexplored applications such as the real-world deployment oftraditional control methods based on mesh simulations. To deal with thechallenges posed by real-world 3D mesh reconstruction, we leverage aprofessional volumetric capture system that allows complete 360{\deg}reconstruction. PokeFlex consists of 18 deformable objects with varyingstiffness and shapes. Deformations are generated by dropping objects onto aflat surface or by poking the objects with a robot arm. Interaction wrenchesand contact locations are also reported for the latter case. Using differentdata modalities, we demonstrated a use case for our dataset training modelsthat, given the novelty of the multimodal nature of Pokeflex, constitute thestate-of-the-art in multi-object online template-based mesh reconstruction frommultimodal data, to the best of our knowledge. We refer the reader to ourwebsite ( https://pokeflex-dataset.github.io/ ) for further demos and examples.</description><author>Jan Obrist, Miguel Zamora, Hehui Zheng, Ronan Hinchet, Firat Ozdemir, Juan Zarate, Robert K. Katzschmann, Stelian Coros</author><pubDate>Tue, 28 Jan 2025 16:02:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07688v2</guid></item><item><title>Standardised schema and taxonomy for AI incident databases in critical digital infrastructure</title><link>http://arxiv.org/abs/2501.17037v1</link><description>The rapid deployment of Artificial Intelligence (AI) in critical digitalinfrastructure introduces significant risks, necessitating a robust frameworkfor systematically collecting AI incident data to prevent future incidents.Existing databases lack the granularity as well as the standardized structurerequired for consistent data collection and analysis, impeding effectiveincident management. This work proposes a standardized schema and taxonomy forAI incident databases, addressing these challenges by enabling detailed andstructured documentation of AI incidents across sectors. Key contributionsinclude developing a unified schema, introducing new fields such as incidentseverity, causes, and harms caused, and proposing a taxonomy for classifying AIincidents in critical digital infrastructure. The proposed solution facilitatesmore effective incident data collection and analysis, thus supportingevidence-based policymaking, enhancing industry safety measures, and promotingtransparency. This work lays the foundation for a coordinated global responseto AI incidents, ensuring trust, safety, and accountability in using AI acrossregions.</description><author>Avinash Agarwal, Manisha J. Nene</author><pubDate>Tue, 28 Jan 2025 15:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17037v1</guid></item><item><title>Acquiring Submillimeter-Accurate Multi-Task Vision Datasets for Computer-Assisted Orthopedic Surgery</title><link>http://arxiv.org/abs/2501.15371v2</link><description>Advances in computer vision, particularly in optical image-based 3Dreconstruction and feature matching, enable applications like marker-lesssurgical navigation and digitization of surgery. However, their development ishindered by a lack of suitable datasets with 3D ground truth. This workexplores an approach to generating realistic and accurate ex vivo datasetstailored for 3D reconstruction and feature matching in open orthopedic surgery.A set of posed images and an accurately registered ground truth surface mesh ofthe scene are required to develop vision-based 3D reconstruction and matchingmethods suitable for surgery. We propose a framework consisting of three coresteps and compare different methods for each step: 3D scanning, calibration ofviewpoints for a set of high-resolution RGB images, and an optical-based methodfor scene registration. We evaluate each step of this framework on an ex vivoscoliosis surgery using a pig spine, conducted under real operating roomconditions. A mean 3D Euclidean error of 0.35 mm is achieved with respect tothe 3D ground truth. The proposed method results in submillimeter accurate 3Dground truths and surgical images with a spatial resolution of 0.1 mm. Thisopens the door to acquiring future surgical datasets for high-precisionapplications.</description><author>Emma Most, Jonas Hein, Frédéric Giraud, Nicola A. Cavalcanti, Lukas Zingg, Baptiste Brument, Nino Louman, Fabio Carrillo, Philipp Fürnstahl, Lilian Calvet</author><pubDate>Tue, 28 Jan 2025 15:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.15371v2</guid></item><item><title>Challenges in Ensuring AI Safety in DeepSeek-R1 Models: The Shortcomings of Reinforcement Learning Strategies</title><link>http://arxiv.org/abs/2501.17030v1</link><description>Large Language Models (LLMs) have achieved remarkable progress in reasoning,alignment, and task-specific performance. However, ensuring harmlessness inthese systems remains a critical challenge, particularly in advanced modelslike DeepSeek-R1. This paper examines the limitations of Reinforcement Learning(RL) as the primary approach for reducing harmful outputs in DeepSeek-R1 andcompares it with Supervised Fine-Tuning (SFT). While RL improves reasoningcapabilities, it faces challenges such as reward hacking, generalizationfailures, language mixing, and high computational costs. We propose hybridtraining approaches combining RL and SFT to achieve robust harmlessnessreduction. Usage recommendations and future directions for deployingDeepSeek-R1 responsibly are also presented.</description><author>Manojkumar Parmar, Yuvaraj Govindarajulu</author><pubDate>Tue, 28 Jan 2025 15:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17030v1</guid></item><item><title>Conditional Distribution Learning on Graphs</title><link>http://arxiv.org/abs/2411.15206v2</link><description>Leveraging the diversity and quantity of data provided by variousgraph-structured data augmentations while preserving intrinsic semanticinformation is challenging. Additionally, successive layers in graph neuralnetwork (GNN) tend to produce more similar node embeddings, while graphcontrastive learning aims to increase the dissimilarity between negative pairsof node embeddings. This inevitably results in a conflict between themessage-passing mechanism (MPM) of GNNs and the contrastive learning (CL) ofnegative pairs via intraviews. In this paper, we propose a conditionaldistribution learning (CDL) method that learns graph representations fromgraph-structured data for semisupervised graph classification. Specifically, wepresent an end-to-end graph representation learning model to align theconditional distributions of weakly and strongly augmented features over theoriginal features. This alignment enables the CDL model to effectively preserveintrinsic semantic information when both weak and strong augmentations areapplied to graph-structured data. To avoid the conflict between the MPM and theCL of negative pairs, positive pairs of node representations are retained formeasuring the similarity between the original features and the correspondingweakly augmented features. Extensive experiments with several benchmark graphdatasets demonstrate the effectiveness of the proposed CDL method.</description><author>Jie Chen, Hua Mao, Yuanbiao Gou, Zhu Wang, Xi Peng</author><pubDate>Tue, 28 Jan 2025 15:27:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.15206v2</guid></item><item><title>Revisit Mixture Models for Multi-Agent Simulation: Experimental Study within a Unified Framework</title><link>http://arxiv.org/abs/2501.17015v1</link><description>Simulation plays a crucial role in assessing autonomous driving systems,where the generation of realistic multi-agent behaviors is a key aspect. Inmulti-agent simulation, the primary challenges include behavioral multimodalityand closed-loop distributional shifts. In this study, we revisit mixture modelsfor generating multimodal agent behaviors, which can cover the mainstreammethods including continuous mixture models and GPT-like discrete models.Furthermore, we introduce a closed-loop sample generation approach tailored formixture models to mitigate distributional shifts. Within the unified mixturemodel~(UniMM) framework, we recognize critical configurations from both modeland data perspectives. We conduct a systematic examination of various modelconfigurations, including positive component matching, continuous regression,prediction horizon, and the number of components. Moreover, our investigationinto the data configuration highlights the pivotal role of closed-loop samplesin achieving realistic simulations. To extend the benefits of closed-loopsamples across a broader range of mixture models, we further address theshortcut learning and off-policy learning issues. Leveraging insights from ourexploration, the distinct variants proposed within the UniMM framework,including discrete, anchor-free, and anchor-based models, all achievestate-of-the-art performance on the WOSAC benchmark.</description><author>Longzhong Lin, Xuewu Lin, Kechun Xu, Haojian Lu, Lichao Huang, Rong Xiong, Yue Wang</author><pubDate>Tue, 28 Jan 2025 15:26:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17015v1</guid></item><item><title>MIDI-GPT: A Controllable Generative Model for Computer-Assisted Multitrack Music Composition</title><link>http://arxiv.org/abs/2501.17011v1</link><description>We present and release MIDI-GPT, a generative system based on the Transformerarchitecture that is designed for computer-assisted music compositionworkflows. MIDI-GPT supports the infilling of musical material at the track andbar level, and can condition generation on attributes including: instrumenttype, musical style, note density, polyphony level, and note duration. In orderto integrate these features, we employ an alternative representation formusical material, creating a time-ordered sequence of musical events for eachtrack and concatenating several tracks into a single sequence, rather thanusing a single time-ordered sequence where the musical events corresponding todifferent tracks are interleaved. We also propose a variation of ourrepresentation allowing for expressiveness. We present experimental resultsthat demonstrate that MIDI-GPT is able to consistently avoid duplicating themusical material it was trained on, generate music that is stylisticallysimilar to the training dataset, and that attribute controls allow enforcingvarious constraints on the generated material. We also outline severalreal-world applications of MIDI-GPT, including collaborations with industrypartners that explore the integration and evaluation of MIDI-GPT intocommercial products, as well as several artistic works produced using it.</description><author>Philippe Pasquier, Jeff Ens, Nathan Fradet, Paul Triana, Davide Rizzotti, Jean-Baptiste Rolland, Maryam Safi</author><pubDate>Tue, 28 Jan 2025 15:17:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17011v1</guid></item><item><title>Robust Policy Search for Robot Navigation</title><link>http://arxiv.org/abs/2003.01000v2</link><description>Complex robot navigation and control problems can be framed as policy searchproblems. However, interactive learning in uncertain environments can beexpensive, requiring the use of data-efficient methods. Bayesian optimizationis an efficient nonlinear optimization method where queries are carefullyselected to gather information about the optimum location. This is achieved bya surrogate model, which encodes past information, and the acquisition functionfor query selection. Bayesian optimization can be very sensitive to uncertaintyin the input data or prior assumptions. In this work, we incorporate bothrobust optimization and statistical robustness, showing that both types ofrobustness are synergistic. For robust optimization we use an improved versionof unscented Bayesian optimization which provides safe and repeatable policiesin the presence of policy uncertainty. We also provide new theoreticalinsights. For statistical robustness, we use an adaptive surrogate model and weintroduce the Boltzmann selection as a stochastic acquisition method to haveconvergence guarantees and improved performance even with surrogate modelingerrors. We present results in several optimization benchmarks and robot tasks.</description><author>Javier Garcia-Barcos, Ruben Martinez-Cantin</author><pubDate>Tue, 28 Jan 2025 15:17:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2003.01000v2</guid></item><item><title>Reinforcement Learning for Control of Non-Markovian Cellular Population Dynamics</title><link>http://arxiv.org/abs/2410.08439v3</link><description>Many organisms and cell types, from bacteria to cancer cells, exhibit aremarkable ability to adapt to fluctuating environments. Additionally, cellscan leverage a memory of past environments to better survivepreviously-encountered stressors. From a control perspective, this adaptabilityposes significant challenges in driving cell populations toward extinction, andthus poses an open question with great clinical significance. In this work, wefocus on drug dosing in cell populations exhibiting phenotypic plasticity. Forspecific dynamical models switching between resistant and susceptible states,exact solutions are known. However, when the underlying system parameters areunknown, and for complex memory-based systems, obtaining the optimal solutionis currently intractable. To address this challenge, we apply reinforcementlearning (RL) to identify informed dosing strategies to control cellpopulations evolving under novel non-Markovian dynamics. We find thatmodel-free deep RL is able to recover exact solutions and control cellpopulations even in the presence of long-range temporal dynamics. To furthertest our approach in more realistic settings, we demonstrate robust RL-basedcontrol strategies in environments with measurement noise and dynamic memorystrength.</description><author>Josiah C. Kratz, Jacob Adamczyk</author><pubDate>Tue, 28 Jan 2025 15:13:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.08439v3</guid></item><item><title>Privacy-Preserving Personalized Federated Prompt Learning for Multimodal Large Language Models</title><link>http://arxiv.org/abs/2501.13904v2</link><description>Multimodal Large Language Models (LLMs) are pivotal in revolutionizingcustomer support and operations by integrating multiple modalities such astext, images, and audio. Federated Prompt Learning (FPL) is a recently proposedapproach that combines pre-trained multimodal LLMs such as vision-languagemodels with federated learning to create personalized, privacy-preserving AIsystems. However, balancing the competing goals of personalization,generalization, and privacy remains a significant challenge.Over-personalization can lead to overfitting, reducing generalizability, whilestringent privacy measures, such as differential privacy, can hinder bothpersonalization and generalization. In this paper, we propose a DifferentiallyPrivate Federated Prompt Learning (DP-FPL) approach to tackle this challenge byleveraging a low-rank adaptation scheme to capture generalization whilemaintaining a residual term that preserves expressiveness for personalization.To ensure privacy, we introduce a novel method where we apply localdifferential privacy to the two low-rank components of the local prompt, andglobal differential privacy to the global prompt. Our approach mitigates theimpact of privacy noise on the model performance while balancing the tradeoffbetween personalization and generalization. Extensive experiments demonstratethe effectiveness of our approach over other benchmarks.</description><author>Linh Tran, Wei Sun, Stacy Patterson, Ana Milanova</author><pubDate>Tue, 28 Jan 2025 15:11:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13904v2</guid></item><item><title>Q-learning with temporal memory to navigate turbulence</title><link>http://arxiv.org/abs/2404.17495v2</link><description>We consider the problem of olfactory searches in a turbulent environment. Wefocus on agents that respond solely to odor stimuli, with no access to spatialperception nor prior information about the odor. We ask whether navigation to atarget can be learned robustly within a sequential decision making framework.We develop a reinforcement learning algorithm using a small set ofinterpretable olfactory states and train it with realistic turbulent odor cues.By introducing a temporal memory, we demonstrate that two salient features ofodor traces, discretized in few olfactory states, are sufficient to learnnavigation in a realistic odor plume. Performance is dictated by the sparsenature of turbulent odors. An optimal memory exists which ignores blanks withinthe plume and activates a recovery strategy outside the plume. We obtain thebest performance by letting agents learn their recovery strategy and show thatit is mostly casting cross wind, similar to behavior observed in flyinginsects. The optimal strategy is robust to substantial changes in the odorplumes, suggesting minor parameter tuning may be sufficient to adapt todifferent environments.</description><author>Marco Rando, Martin James, Alessandro Verri, Lorenzo Rosasco, Agnese Seminara</author><pubDate>Tue, 28 Jan 2025 15:07:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17495v2</guid></item><item><title>CNMBERT: A Model for Converting Hanyu Pinyin Abbreviations to Chinese Characters</title><link>http://arxiv.org/abs/2411.11770v4</link><description>The task of converting Hanyu Pinyin abbreviations to Chinese characters is asignificant branch within the domain of Chinese Spelling Correction (CSC). Itplays an important role in many downstream applications such as named entityrecognition and sentiment analysis. This task typically involves text-lengthalignment and seems easy to solve; however, due to the limited informationcontent in pinyin abbreviations, achieving accurate conversion is challenging.In this paper, we treat this as a fill-mask task and propose CNMBERT, whichstands for zh-CN Pinyin Multi-mask BERT Model, as a solution to this issue. Byintroducing a multi-mask strategy and Mixture of Experts (MoE) layers, CNMBERToutperforms fine-tuned GPT models and ChatGPT-4o with a 61.53% MRR score and51.86% accuracy on a 10,373-sample test dataset.</description><author>Zishuo Feng, Feng Cao</author><pubDate>Tue, 28 Jan 2025 14:54:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.11770v4</guid></item><item><title>MAUCell: An Adaptive Multi-Attention Framework for Video Frame Prediction</title><link>http://arxiv.org/abs/2501.16997v1</link><description>Temporal sequence modeling stands as the fundamental foundation for videoprediction systems and real-time forecasting operations as well as anomalydetection applications. The achievement of accurate predictions throughefficient resource consumption remains an ongoing issue in contemporarytemporal sequence modeling. We introduce the Multi-Attention Unit (MAUCell)which combines Generative Adversarial Networks (GANs) and spatio-temporalattention mechanisms to improve video frame prediction capabilities. Ourapproach implements three types of attention models to capture intricate motionsequences. A dynamic combination of these attention outputs allows the model toreach both advanced decision accuracy along with superior quality whileremaining computationally efficient. The integration of GAN elements makesgenerated frames appear more true to life therefore the framework createsoutput sequences which mimic real-world footage. The new design systemmaintains equilibrium between temporal continuity and spatial accuracy todeliver reliable video prediction. Through a comprehensive evaluationmethodology which merged the perceptual LPIPS measurement together with classictests MSE, MAE, SSIM and PSNR exhibited enhancing capabilities thancontemporary approaches based on direct benchmark tests of Moving MNIST, KTHAction, and CASIA-B (Preprocessed) datasets. Our examination indicates thatMAUCell shows promise for operational time requirements. The research findingsdemonstrate how GANs work best with attention mechanisms to create betterapplications for predicting video sequences.</description><author>Shreyam Gupta, P. Agrawal, Priyam Gupta</author><pubDate>Tue, 28 Jan 2025 14:52:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16997v1</guid></item><item><title>FedEFM: Federated Endovascular Foundation Model with Unseen Data</title><link>http://arxiv.org/abs/2501.16992v1</link><description>In endovascular surgery, the precise identification of catheters andguidewires in X-ray images is essential for reducing intervention risks.However, accurately segmenting catheter and guidewire structures is challengingdue to the limited availability of labeled data. Foundation models offer apromising solution by enabling the collection of similar domain data to trainmodels whose weights can be fine-tuned for downstream tasks. Nonetheless,large-scale data collection for training is constrained by the necessity ofmaintaining patient privacy. This paper proposes a new method to train afoundation model in a decentralized federated learning setting for endovascularintervention. To ensure the feasibility of the training, we tackle the unseendata issue using differentiable Earth Mover's Distance within a knowledgedistillation framework. Once trained, our foundation model's weights providevaluable initialization for downstream tasks, thereby enhancing task-specificperformance. Intensive experiments show that our approach achieves newstate-of-the-art results, contributing to advancements in endovascularintervention and robotic-assisted endovascular surgery, while addressing thecritical issue of data sharing in the medical domain.</description><author>Tuong Do, Nghia Vu, Tudor Jianu, Baoru Huang, Minh Vu, Jionglong Su, Erman Tjiputra, Quang D. Tran, Te-Chuan Chiu, Anh Nguyen</author><pubDate>Tue, 28 Jan 2025 14:46:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16992v1</guid></item><item><title>Multi-View Spectral Clustering for Graphs with Multiple View Structures</title><link>http://arxiv.org/abs/2501.11422v2</link><description>Despite the fundamental importance of clustering, to this day, much of therelevant research is still based on ambiguous foundations, leading to anunclear understanding of whether or how the various clustering methods areconnected with each other. In this work, we provide an additional steppingstone towards resolving such ambiguities by presenting a general clusteringframework that subsumes a series of seemingly disparate clustering methods,including various methods belonging to the widely popular spectral clusteringframework. In fact, the generality of the proposed framework is additionallycapable of shedding light to the largely unexplored area of multi-view graphswhere each view may have differently clustered nodes. In turn, we proposeGenClus: a method that is simultaneously an instance of this framework and ageneralization of spectral clustering, while also being closely related tok-means as well. This results in a principled alternative to the few existingmethods studying this special type of multi-view graphs. Then, we conductin-depth experiments, which demonstrate that GenClus is more computationallyefficient than existing methods, while also attaining similar or betterclustering performance. Lastly, a qualitative real-world case-study furtherdemonstrates the ability of GenClus to produce meaningful clusterings.</description><author>Yorgos Tsitsikas, Evangelos E. Papalexakis</author><pubDate>Tue, 28 Jan 2025 14:43:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11422v2</guid></item><item><title>Marginal and Conditional Importance Measures from Machine Learning Models and Their Relationship with Conditional Average Treatment Effect</title><link>http://arxiv.org/abs/2501.16988v1</link><description>Interpreting black-box machine learning models is challenging due to theirstrong dependence on data and inherently non-parametric nature. This paperreintroduces the concept of importance through "Marginal Variable ImportanceMetric" (MVIM), a model-agnostic measure of predictor importance based on thetrue conditional expectation function. MVIM evaluates predictors' influence oncontinuous or discrete outcomes. A permutation-based estimation approach,inspired by \citet{breiman2001random} and \citet{fisher2019all}, is proposed toestimate MVIM. MVIM estimator is biased when predictors are highly correlated,as black-box models struggle to extrapolate in low-probability regions. Toaddress this, we investigated the bias-variance decomposition of MVIM tounderstand the source and pattern of the bias under high correlation. AConditional Variable Importance Metric (CVIM), adapted from\citet{strobl2008conditional}, is introduced to reduce this bias. Both MVIM andCVIM exhibit a quadratic relationship with the conditional average treatmenteffect (CATE).</description><author>Mohammad Kaviul Anam Khan, Olli Saarela, Rafal Kustra</author><pubDate>Tue, 28 Jan 2025 14:41:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16988v1</guid></item><item><title>Learning Curves for Decision Making in Supervised Machine Learning: A Survey</title><link>http://arxiv.org/abs/2201.12150v2</link><description>Learning curves are a concept from social sciences that has been adopted inthe context of machine learning to assess the performance of a learningalgorithm with respect to a certain resource, e.g., the number of trainingexamples or the number of training iterations. Learning curves have importantapplications in several machine learning contexts, most notably in dataacquisition, early stopping of model training, and model selection. Forinstance, learning curves can be used to model the performance of thecombination of an algorithm and its hyperparameter configuration, providinginsights into their potential suitability at an early stage and oftenexpediting the algorithm selection process. Various learning curve models havebeen proposed to use learning curves for decision making. Some of these modelsanswer the binary decision question of whether a given algorithm at a certainbudget will outperform a certain reference performance, whereas more complexmodels predict the entire learning curve of an algorithm. We contribute aframework that categorises learning curve approaches using three criteria: thedecision-making situation they address, the intrinsic learning curve questionthey answer and the type of resources they use. We survey papers from theliterature and classify them into this framework.</description><author>Felix Mohr, Jan N. van Rijn</author><pubDate>Tue, 28 Jan 2025 14:39:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.12150v2</guid></item><item><title>Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver</title><link>http://arxiv.org/abs/2501.16986v1</link><description>Quantum computing is entering a transformative phase with the emergence oflogical quantum processors, which hold the potential to tackle complex problemsbeyond classical capabilities. While significant progress has been made,applying quantum algorithms to real-world problems remains challenging. Hybridquantum-classical techniques have been explored to bridge this gap, but theyoften face limitations in expressiveness, trainability, or scalability. In thiswork, we introduce conditional Generative Quantum Eigensolver(conditional-GQE), a context-aware quantum circuit generator powered by anencoder-decoder Transformer. Focusing on combinatorial optimization, we trainour generator for solving problems with up to 10 qubits, exhibiting nearlyperfect performance on new problems. By leveraging the high expressiveness andflexibility of classical generative models, along with an efficientpreference-based training scheme, conditional-GQE provides a generalizable andscalable framework for quantum circuit generation. Our approach advances hybridquantum-classical computing and contributes to accelerate the transition towardfault-tolerant quantum computing.</description><author>Shunya Minami, Kouhei Nakaji, Yohichi Suzuki, Alán Aspuru-Guzik, Tadashi Kadowaki</author><pubDate>Tue, 28 Jan 2025 14:35:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16986v1</guid></item><item><title>Uni-Renderer: Unifying Rendering and Inverse Rendering Via Dual Stream Diffusion</title><link>http://arxiv.org/abs/2412.15050v3</link><description>Rendering and inverse rendering are pivotal tasks in both computer vision andgraphics. The rendering equation is the core of the two tasks, as an idealconditional distribution transfer function from intrinsic properties to RGBimages. Despite achieving promising results of existing rendering methods, theymerely approximate the ideal estimation for a specific scene and come with ahigh computational cost. Additionally, the inverse conditional distributiontransfer is intractable due to the inherent ambiguity. To address thesechallenges, we propose a data-driven method that jointly models rendering andinverse rendering as two conditional generation tasks within a single diffusionframework. Inspired by UniDiffuser, we utilize two distinct time schedules tomodel both tasks, and with a tailored dual streaming module, we achievecross-conditioning of two pre-trained diffusion models. This unified approach,named Uni-Renderer, allows the two processes to facilitate each other through acycle-consistent constrain, mitigating ambiguity by enforcing consistencybetween intrinsic properties and rendered images. Combined with a meticulouslyprepared dataset, our method effectively decomposition of intrinsic propertiesand demonstrates a strong capability to recognize changes during rendering. Wewill open-source our training and inference code to the public, fosteringfurther research and development in this area.</description><author>Zhifei Chen, Tianshuo Xu, Wenhang Ge, Leyi Wu, Dongyu Yan, Jing He, Luozhou Wang, Lu Zeng, Shunsi Zhang, Yingcong Chen, Hui Xiong</author><pubDate>Tue, 28 Jan 2025 14:33:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15050v3</guid></item><item><title>Modulating CNN Features with Pre-Trained ViT Representations for Open-Vocabulary Object Detection</title><link>http://arxiv.org/abs/2501.16981v1</link><description>Owing to large-scale image-text contrastive training, pre-trained visionlanguage model (VLM) like CLIP shows superior open-vocabulary recognitionability. Most existing open-vocabulary object detectors attempt to utilize thepre-trained VLM to attain generative representation. F-ViT uses the pre-trainedvisual encoder as the backbone network and freezes it during training. However,the frozen backbone doesn't benefit from the labeled data to strengthen therepresentation. Therefore, we propose a novel two-branch backbone networkdesign, named as ViT-Feature-Modulated Multi-Scale Convolutional network(VMCNet). VMCNet consists of a trainable convolutional branch, a frozenpre-trained ViT branch and a feature modulation module. The trainable CNNbranch could be optimized with labeled data while the frozen pre-trained ViTbranch could keep the representation ability derived from large-scalepre-training. Then, the proposed feature modulation module could modulate themulti-scale CNN features with the representations from ViT branch. With theproposed mixed structure, detector is more likely to discover novel categories.Evaluated on two popular benchmarks, our method boosts the detectionperformance on novel category and outperforms the baseline. On OV-COCO, theproposed method achieves 44.3 AP$_{50}^{\mathrm{novel}}$ with ViT-B/16 and 48.5AP$_{50}^{\mathrm{novel}}$ with ViT-L/14. On OV-LVIS, VMCNet with ViT-B/16 andViT-L/14 reaches 27.8 and 38.4 mAP$_{r}$.</description><author>Xiangyu Gao, Yu Dai, Benliu Qiu, Hongliang Li</author><pubDate>Tue, 28 Jan 2025 14:28:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16981v1</guid></item><item><title>DynaGRAG | Exploring the Topology of Information for Advancing Language Understanding and Generation in Graph Retrieval-Augmented Generation</title><link>http://arxiv.org/abs/2412.18644v3</link><description>Graph Retrieval-Augmented Generation (GRAG or Graph RAG) architectures aim toenhance language understanding and generation by leveraging external knowledge.However, effectively capturing and integrating the rich semantic informationpresent in textual and structured data remains a challenge. To address this, anovel GRAG framework, Dynamic Graph Retrieval-Agumented Generation (DynaGRAG),is proposed to focus on enhancing subgraph representation and diversity withinthe knowledge graph. By improving graph density, capturing entity and relationinformation more effectively, and dynamically prioritizing relevant and diversesubgraphs and information within them, the proposed approach enables a morecomprehensive understanding of the underlying semantic structure. This isachieved through a combination of de-duplication processes, two-step meanpooling of embeddings, query-aware retrieval considering unique nodes, and aDynamic Similarity-Aware BFS (DSA-BFS) traversal algorithm. Integrating GraphConvolutional Networks (GCNs) and Large Language Models (LLMs) through hardprompting further enhances the learning of rich node and edge representationswhile preserving the hierarchical subgraph structure. Experimental resultsdemonstrate the effectiveness of DynaGRAG, showcasing the significance ofenhanced subgraph representation and diversity for improved languageunderstanding and generation.</description><author>Karishma Thakrar</author><pubDate>Tue, 28 Jan 2025 14:23:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.18644v3</guid></item><item><title>Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling</title><link>http://arxiv.org/abs/2501.16975v1</link><description>Tokenization is a fundamental component of large language models (LLMs), yetits influence on model scaling and performance is not fully explored. In thispaper, we introduce Over-Tokenized Transformers, a novel framework thatdecouples input and output vocabularies to improve language modelingperformance. Specifically, our approach scales up input vocabularies toleverage multi-gram tokens. Through extensive experiments, we uncover alog-linear relationship between input vocabulary size and training loss,demonstrating that larger input vocabularies consistently enhance modelperformance, regardless of model size. Using a large input vocabulary, weachieve performance comparable to double-sized baselines with no additionalcost. Our findings highlight the importance of tokenization in scaling laws andprovide practical insight for tokenizer design, paving the way for moreefficient and powerful LLMs.</description><author>Hongzhi Huang, Defa Zhu, Banggu Wu, Yutao Zeng, Ya Wang, Qiyang Min, Xun Zhou</author><pubDate>Tue, 28 Jan 2025 14:15:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16975v1</guid></item><item><title>Excited-state nonadiabatic dynamics in explicit solvent using machine learned interatomic potentials</title><link>http://arxiv.org/abs/2501.16974v1</link><description>Excited-state nonadiabatic simulations with quantum mechanics/molecularmechanics (QM/MM) are essential to understand photoinduced processes inexplicit environments. However, the high computational cost of the underlyingquantum chemical calculations limits its application in combination withtrajectory surface hopping methods. Here, we use FieldSchNet, a machine-learnedinteratomic potential capable of incorporating electric field effects into theelectronic states, to replace traditional QM/MM electrostatic embedding withits ML/MM counterpart for nonadiabatic excited state trajectories. Thedeveloped method is applied to furan in water, including five coupled singletstates. Our results demonstrate that with sufficiently curated training data,the ML/MM model reproduces the electronic kinetics and structuralrearrangements of QM/MM surface hopping reference simulations. Furthermore, weidentify performance metrics that provide robust and interpretable validationof model accuracy.</description><author>Maximilian X. Tiefenbacher, Brigitta Bachmair, Cheng Giuseppe Chen, Julia Westermayr, Philipp Marquetand, Johannes C. B. Dietschreit, Leticia González</author><pubDate>Tue, 28 Jan 2025 14:14:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16974v1</guid></item><item><title>Rethinking External Slow-Thinking: From Snowball Errors to Probability of Correct Reasoning</title><link>http://arxiv.org/abs/2501.15602v2</link><description>Test-time scaling, which is also often referred to as slow-thinking, has beendemonstrated to enhance multi-step reasoning in large language models (LLMs).However, despite its widespread utilization, the mechanisms underlyingslow-thinking methods remain poorly understood. This paper explores themechanisms of external slow-thinking from a theoretical standpoint. We begin byexamining the snowball error effect within the LLM reasoning process andconnect it to the likelihood of correct reasoning using information theory.Building on this, we show that external slow-thinking methods can beinterpreted as strategies to mitigate the error probability. We further providea comparative analysis of popular external slow-thinking approaches, rangingfrom simple to complex, highlighting their differences and interrelationships.Our findings suggest that the efficacy of these methods is not primarilydetermined by the specific framework employed, and that expanding the searchscope or the model's internal reasoning capacity may yield more sustainedimprovements in the long term. We open-source our code athttps://github.com/ZyGan1999/Snowball-Errors-and-Probability.</description><author>Zeyu Gan, Yun Liao, Yong Liu</author><pubDate>Tue, 28 Jan 2025 14:14:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.15602v2</guid></item><item><title>RODEO: Robust Outlier Detection via Exposing Adaptive Out-of-Distribution Samples</title><link>http://arxiv.org/abs/2501.16971v1</link><description>In recent years, there have been significant improvements in various forms ofimage outlier detection. However, outlier detection performance underadversarial settings lags far behind that in standard settings. This is due tothe lack of effective exposure to adversarial scenarios during training,especially on unseen outliers, leading to detection models failing to learnrobust features. To bridge this gap, we introduce RODEO, a data-centricapproach that generates effective outliers for robust outlier detection. Morespecifically, we show that incorporating outlier exposure (OE) and adversarialtraining can be an effective strategy for this purpose, as long as the exposedtraining outliers meet certain characteristics, including diversity, and bothconceptual differentiability and analogy to the inlier samples. We leverage atext-to-image model to achieve this goal. We demonstrate both quantitativelyand qualitatively that our adaptive OE method effectively generates ``diverse''and ``near-distribution'' outliers, leveraging information from both text andimage domains. Moreover, our experimental results show that utilizing oursynthesized outliers significantly enhances the performance of the outlierdetector, particularly in adversarial settings.</description><author>Hossein Mirzaei, Mohammad Jafari, Hamid Reza Dehbashi, Ali Ansari, Sepehr Ghobadi, Masoud Hadi, Arshia Soltani Moakhar, Mohammad Azizmalayeri, Mahdieh Soleymani Baghshah, Mohammad Hossein Rohban</author><pubDate>Tue, 28 Jan 2025 14:13:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16971v1</guid></item><item><title>The Hatching-Box: A Novel System for Automated Monitoring and Quantification of Drosophila melanogaster Developmental Behavior</title><link>http://arxiv.org/abs/2411.15390v3</link><description>In this paper we propose the Hatching-Box, a novel imaging and analysissystem to automatically monitor and quantify the developmental behavior ofDrosophila in standard rearing vials and during regular rearing routines,rendering explicit experiments obsolete. This is achieved by combining customtailored imaging hardware with dedicated detection and tracking algorithms,enabling the quantification of larvae, filled/empty pupae and flies overmultiple days. Given the affordable and reproducible design of the Hatching-Boxin combination with our generic client/server-based software, the system caneasily be scaled to monitor an arbitrary amount of rearing vialssimultaneously. We evaluated our system on a curated image dataset comprisingnearly 470,000 annotated objects and performed several studies on real worldexperiments. We successfully reproduced results from well-established circadianexperiments by comparing the eclosion periods of wild type flies to the clockmutants $\textit{per}^{short}$, $\textit{per}^{long}$ and $\textit{per}^0$without involvement of any manual labor. Furthermore we show, that theHatching-Box is able to extract additional information about group behavior aswell as to reconstruct the whole life-cycle of the individual specimens. Theseresults not only demonstrate the applicability of our system for long-termexperiments but also indicate its benefits for automated monitoring in thegeneral cultivation process.</description><author>Julian Bigge, Maite Ogueta, Luis Garcia, Benjamin Risse</author><pubDate>Tue, 28 Jan 2025 14:12:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.15390v3</guid></item><item><title>What Really Matters for Learning-based LiDAR-Camera Calibration</title><link>http://arxiv.org/abs/2501.16969v1</link><description>Calibration is an essential prerequisite for the accurate data fusion ofLiDAR and camera sensors. Traditional calibration techniques often requirespecific targets or suitable scenes to obtain reliable 2D-3D correspondences.To tackle the challenge of target-less and online calibration, deep neuralnetworks have been introduced to solve the problem in a data-driven manner.While previous learning-based methods have achieved impressive performance onspecific datasets, they still struggle in complex real-world scenarios. Mostexisting works focus on improving calibration accuracy but overlook theunderlying mechanisms. In this paper, we revisit the development oflearning-based LiDAR-Camera calibration and encourage the community to pay moreattention to the underlying principles to advance practical applications. Wesystematically analyze the paradigm of mainstream learning-based methods, andidentify the critical limitations of regression-based methods with the widelyused data generation pipeline. Our findings reveal that most learning-basedmethods inadvertently operate as retrieval networks, focusing more onsingle-modality distributions rather than cross-modality correspondences. Wealso investigate how the input data format and preprocessing operations impactnetwork performance and summarize the regression clues to inform furtherimprovements.</description><author>Shujuan Huang, Chunyu Lin, Yao Zhao</author><pubDate>Tue, 28 Jan 2025 14:12:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16969v1</guid></item><item><title>Heterogeneity-aware Personalized Federated Learning via Adaptive Dual-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2501.16966v1</link><description>Federated Learning (FL) empowers multiple clients to collaboratively trainmachine learning models without sharing local data, making it highly applicablein heterogeneous Internet of Things (IoT) environments. However, intrinsicheterogeneity in clients' model architectures and computing capabilities oftenresults in model accuracy loss and the intractable straggler problem, whichsignificantly impairs training effectiveness. To tackle these challenges, thispaper proposes a novel Heterogeneity-aware Personalized Federated Learningmethod, named HAPFL, via multi-level Reinforcement Learning (RL) mechanisms.HAPFL optimizes the training process by incorporating three strategiccomponents: 1) An RL-based heterogeneous model allocation mechanism. Theparameter server employs a Proximal Policy Optimization (PPO)-based RL agent toadaptively allocate appropriately sized, differentiated models to clients basedon their performance, effectively mitigating performance disparities. 2) AnRL-based training intensity adjustment scheme. The parameter server leveragesanother PPO-based RL agent to dynamically fine-tune the training intensity foreach client to further enhance training efficiency and reduce stragglinglatency. 3) A knowledge distillation-based mutual learning mechanism. Eachclient deploys both a heterogeneous local model and a homogeneous lightweightmodel named LiteModel, where these models undergo mutual learning throughknowledge distillation. This uniform LiteModel plays a pivotal role inaggregating and sharing global knowledge, significantly enhancing theeffectiveness of personalized local training. Experimental results acrossmultiple benchmark datasets demonstrate that HAPFL not only achieves highaccuracy but also substantially reduces the overall training time by20.9%-40.4% and decreases straggling latency by 19.0%-48.0% compared toexisting solutions.</description><author>Xi Chen, Qin Li, Haibin Cai, Ting Wang</author><pubDate>Tue, 28 Jan 2025 14:08:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16966v1</guid></item><item><title>Few Edges Are Enough: Few-Shot Network Attack Detection with Graph Neural Networks</title><link>http://arxiv.org/abs/2501.16964v1</link><description>Detecting cyberattacks using Graph Neural Networks (GNNs) has seen promisingresults recently. Most of the state-of-the-art models that leverage thesetechniques require labeled examples, hard to obtain in many real-worldscenarios. To address this issue, unsupervised learning and Self-SupervisedLearning (SSL) have emerged as interesting approaches to reduce the dependencyon labeled data. Nonetheless, these methods tend to yield more anomalousdetection algorithms rather than effective attack detection systems. This paperintroduces Few Edges Are Enough (FEAE), a GNN-based architecture trained withSSL and Few-Shot Learning (FSL) to better distinguish between false positiveanomalies and actual attacks. To maximize the potential of few-shot examples,our model employs a hybrid self-supervised objective that combines theadvantages of contrastive-based and reconstruction-based SSL. By leveragingonly a minimal number of labeled attack events, represented as attack edges,FEAE achieves competitive performance on two well-known network datasetscompared to both supervised and unsupervised methods. Remarkably, ourexperimental results unveil that employing only 1 malicious event for eachattack type in the dataset is sufficient to achieve substantial improvements.FEAE not only outperforms self-supervised GNN baselines but also surpasses somesupervised approaches on one of the datasets.</description><author>Tristan Bilot, Nour El Madhoun, Khaldoun Al Agha, Anis Zouaoui</author><pubDate>Tue, 28 Jan 2025 14:07:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16964v1</guid></item><item><title>Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers</title><link>http://arxiv.org/abs/2501.16961v1</link><description>Robustness of reasoning remains a significant challenge for large languagemodels, and addressing it is essential for the practical applicability ofAI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), anovel approach that addresses the key challenge in combining language modelswith the rigor of logical solvers: to accurately formulate the reasoningproblem from natural language to the formal language of the solver. SSV uses aconsistency-based approach to produce strong abstract formalizations ofproblems using concrete instantiations that are generated by the model andverified by the solver. In addition to significantly advancing the overallreasoning accuracy over the state-of-the-art, a key novelty that this approachpresents is a feature of verification that has near-perfect precision over asignificant coverage of cases, as we demonstrate on open reasoning benchmarks.We propose such *near-certain reasoning* as a new approach to reduce the needfor manual verification in many cases, taking us closer to more dependable andautonomous AI reasoning systems.</description><author>Mohammad Raza, Natasa Milic-Frayling</author><pubDate>Tue, 28 Jan 2025 14:04:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16961v1</guid></item><item><title>Smooth Exact Gradient Descent Learning in Spiking Neural Networks</title><link>http://arxiv.org/abs/2309.14523v2</link><description>Gradient descent prevails in artificial neural network training, but seemsinept for spiking neural networks as small parameter changes can cause sudden,disruptive (dis-)appearances of spikes. Here, we demonstrate exact gradientdescent based on continuously changing spiking dynamics. These are generated byneuron models whose spikes vanish and appear at the end of a trial, where itcannot influence subsequent dynamics. This also enables gradient-based spikeaddition and removal. We illustrate our scheme with various tasks and setups,including recurrent and deep, initially silent networks.</description><author>Christian Klos, Raoul-Martin Memmesheimer</author><pubDate>Tue, 28 Jan 2025 14:01:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14523v2</guid></item><item><title>The empirical median for estimating the common mean of heteroscedastic random variables</title><link>http://arxiv.org/abs/2501.16956v1</link><description>We study the problem of mean estimation in the heteroscedastic setting. Inparticular, we consider symmetric random variables having the same locationparameter and different and unknown scale parameters. Our goal is then toestimate their unknown common location parameter. It is an elementary topic butyet a not very well-studied one since we always make the assumption that therandom variables are independent and identically distributed. In this paper, westudy the median estimator and we establish upper and lower bounds on itsestimation error that are of the same order and that generalize and improverecent results of Devroye et al. and Xia.</description><author>Sirine Louati</author><pubDate>Tue, 28 Jan 2025 13:57:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16956v1</guid></item><item><title>Multiple Abstraction Level Retrieve Augment Generation</title><link>http://arxiv.org/abs/2501.16952v1</link><description>A Retrieval-Augmented Generation (RAG) model powered by a large languagemodel (LLM) provides a faster and more cost-effective solution for adapting tonew data and knowledge. It also delivers more specialized responses compared topre-trained LLMs. However, most existing approaches rely on retrievingprefix-sized chunks as references to support question-answering (Q/A). Thisapproach is often deployed to address information needs at a single level ofabstraction, as it struggles to generate answers across multiple levels ofabstraction. In an RAG setting, while LLMs can summarize and answer questionseffectively when provided with sufficient details, retrieving excessiveinformation often leads to the 'lost in the middle' problem and exceeds tokenlimitations. We propose a novel RAG approach that uses chunks of multipleabstraction levels (MAL), including multi-sentence-level, paragraph-level,section-level, and document-level. The effectiveness of our approach isdemonstrated in an under-explored scientific domain of Glycoscience. Comparedto traditional single-level RAG approaches, our approach improves AI evaluatedanswer correctness of Q/A by 25.739\% on Glyco-related papers.</description><author>Zheng Zheng, Xinyi Ni, Pengyu Hong</author><pubDate>Tue, 28 Jan 2025 13:49:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16952v1</guid></item><item><title>Image-based Geo-localization for Robotics: Are Black-box Vision-Language Models there yet?</title><link>http://arxiv.org/abs/2501.16947v1</link><description>The advances in Vision-Language models (VLMs) offer exciting opportunitiesfor robotic applications involving image geo-localization, the problem ofidentifying the geo-coordinates of a place based on visual data only. Recentresearch works have focused on using a VLM as embeddings extractor forgeo-localization, however, the most sophisticated VLMs may only be available asblack boxes that are accessible through an API, and come with a number oflimitations: there is no access to training data, model features and gradients;retraining is not possible; the number of predictions may be limited by theAPI; training on model outputs is often prohibited; and queries are open-ended.The utilization of a VLM as a stand-alone, zero-shot geo-localization systemusing a single text-based prompt is largely unexplored. To bridge this gap,this paper undertakes the first systematic study, to the best of our knowledge,to investigate the potential of some of the state-of-the-art VLMs asstand-alone, zero-shot geo-localization systems in a black-box setting withrealistic constraints. We consider three main scenarios for this thoroughinvestigation: a) fixed text-based prompt; b) semantically-equivalenttext-based prompts; and c) semantically-equivalent query images. We also takeinto account the auto-regressive and probabilistic generation process of theVLMs when investigating their utility for geo-localization task by using modelconsistency as a metric in addition to traditional accuracy. Our work providesnew insights in the capabilities of different VLMs for the above-mentionedscenarios.</description><author>Sania Waheed, Bruno Ferrarini, Michael Milford, Sarvapali D. Ramchurn, Shoaib Ehsan</author><pubDate>Tue, 28 Jan 2025 13:46:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16947v1</guid></item><item><title>ToolFactory: Automating Tool Generation by Leveraging LLM to Understand REST API Documentations</title><link>http://arxiv.org/abs/2501.16945v1</link><description>LLM-based tool agents offer natural language interfaces, enabling users toseamlessly interact with computing services. While REST APIs are valuableresources for building such agents, they must first be transformed intoAI-compatible tools. Automatically generating AI-compatible tools from REST APIdocuments can greatly streamline tool agent development and minimize userlearning curves. However, API documentation often suffers from a lack ofstandardization, inconsistent schemas, and incomplete information. To addressthese issues, we developed \textbf{ToolFactory}, an open-source pipeline forautomating tool generation from unstructured API documents. To enhance thereliability of the developed tools, we implemented an evaluation method todiagnose errors. Furthermore, we built a knowledge base of verified tools,which we leveraged to infer missing information from poorly documented APIs. Wedeveloped the API Extraction Benchmark, comprising 167 API documents and 744endpoints in various formats, and designed a JSON schema to annotate them. Thisannotated dataset was utilized to train and validate ToolFactory. Theexperimental results highlight the effectiveness of ToolFactory. We alsodemonstrated ToolFactory by creating a domain-specific AI agent forglycomaterials research. ToolFactory exhibits significant potential forfacilitating the seamless integration of scientific REST APIs into AIworkflows.</description><author>Xinyi Ni, Qiuyang Wang, Yukun Zhang, Pengyu Hong</author><pubDate>Tue, 28 Jan 2025 13:42:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16945v1</guid></item><item><title>Exact Computation of Any-Order Shapley Interactions for Graph Neural Networks</title><link>http://arxiv.org/abs/2501.16944v1</link><description>Albeit the ubiquitous use of Graph Neural Networks (GNNs) in machine learning(ML) prediction tasks involving graph-structured data, their interpretabilityremains challenging. In explainable artificial intelligence (XAI), the ShapleyValue (SV) is the predominant method to quantify contributions of individualfeatures to a ML model's output. Addressing the limitations of SVs in complexprediction models, Shapley Interactions (SIs) extend the SV to groups offeatures. In this work, we explain single graph predictions of GNNs with SIsthat quantify node contributions and interactions among multiple nodes. Byexploiting the GNN architecture, we show that the structure of interactions innode embeddings are preserved for graph prediction. As a result, theexponential complexity of SIs depends only on the receptive fields, i.e. themessage-passing ranges determined by the connectivity of the graph and thenumber of convolutional layers. Based on our theoretical results, we introduceGraphSHAP-IQ, an efficient approach to compute any-order SIs exactly.GraphSHAP-IQ is applicable to popular message passing techniques in conjunctionwith a linear global pooling and output layer. We showcase that GraphSHAP-IQsubstantially reduces the exponential complexity of computing exact SIs onmultiple benchmark datasets. Beyond exact computation, we evaluateGraphSHAP-IQ's approximation of SIs on popular GNN architectures and comparewith existing baselines. Lastly, we visualize SIs of real-world waterdistribution networks and molecule structures using a SI-Graph.</description><author>Fabian Fumagalli, Maximilian Muschalik, Paolo Frazzetto, Janine Strotherm, Luca Hermes, Alessandro Sperduti, Eyke Hüllermeier, Barbara Hammer</author><pubDate>Tue, 28 Jan 2025 13:37:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16944v1</guid></item><item><title>TAID: Temporally Adaptive Interpolated Distillation for Efficient Knowledge Transfer in Language Models</title><link>http://arxiv.org/abs/2501.16937v1</link><description>Causal language models have demonstrated remarkable capabilities, but theirsize poses significant challenges for deployment in resource-constrainedenvironments. Knowledge distillation, a widely-used technique for transferringknowledge from a large teacher model to a small student model, presents apromising approach for model compression. A significant remaining issue lies inthe major differences between teacher and student models, namely thesubstantial capacity gap, mode averaging, and mode collapse, which posebarriers during distillation. To address these issues, we introduce$\textit{Temporally Adaptive Interpolated Distillation (TAID)}$, a novelknowledge distillation approach that dynamically interpolates student andteacher distributions through an adaptive intermediate distribution, graduallyshifting from the student's initial distribution towards the teacher'sdistribution. We provide a theoretical analysis demonstrating TAID's ability toprevent mode collapse and empirically show its effectiveness in addressing thecapacity gap while balancing mode averaging and mode collapse. Ourcomprehensive experiments demonstrate TAID's superior performance acrossvarious model sizes and architectures in both instruction tuning andpre-training scenarios. Furthermore, we showcase TAID's practical impact bydeveloping two state-of-the-art compact foundation models:$\texttt{TAID-LLM-1.5B}$ for language tasks and $\texttt{TAID-VLM-2B}$ forvision-language tasks. These results demonstrate TAID's effectiveness increating high-performing and efficient models, advancing the development ofmore accessible AI technologies.</description><author>Makoto Shing, Kou Misaki, Han Bao, Sho Yokoi, Takuya Akiba</author><pubDate>Tue, 28 Jan 2025 13:31:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16937v1</guid></item><item><title>A Generative Framework for Probabilistic, Spatiotemporally Coherent Downscaling of Climate Simulation</title><link>http://arxiv.org/abs/2412.15361v3</link><description>Local climate information is crucial for impact assessment anddecision-making, yet coarse global climate simulations cannot capturesmall-scale phenomena. Current statistical downscaling methods infer thesephenomena as temporally decoupled spatial patches. However, to preservephysical properties, estimating spatio-temporally coherent high-resolutionweather dynamics for multiple variables across long time horizons is crucial.We present a novel generative framework that uses a score-based diffusion modeltrained on high-resolution reanalysis data to capture the statisticalproperties of local weather dynamics. After training, we condition on coarseclimate model data to generate weather patterns consistent with the aggregateinformation. As this predictive task is inherently uncertain, we leverage theprobabilistic nature of diffusion models and sample multiple trajectories. Weevaluate our approach with high-resolution reanalysis information beforeapplying it to the climate model downscaling task. We then demonstrate that themodel generates spatially and temporally coherent weather dynamics that alignwith global climate output.</description><author>Jonathan Schmidt, Luca Schmidt, Felix Strnad, Nicole Ludwig, Philipp Hennig</author><pubDate>Tue, 28 Jan 2025 13:22:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15361v3</guid></item><item><title>Online-BLS: An Accurate and Efficient Online Broad Learning System for Data Stream Classification</title><link>http://arxiv.org/abs/2501.16932v1</link><description>The state-of-the-art online learning models generally conduct a single onlinegradient descent when a new sample arrives and thus suffer from suboptimalmodel weights. To this end, we introduce an online broad learning systemframework with closed-form solutions for each online update. Different fromemploying existing incremental broad learning algorithms for online learningtasks, which tend to incur degraded accuracy and expensive online updateoverhead, we design an effective weight estimation algorithm and an efficientonline updating strategy to remedy the above two deficiencies, respectively.Specifically, an effective weight estimation algorithm is first developed byreplacing notorious matrix inverse operations with Cholesky decomposition andforward-backward substitution to improve model accuracy. Second, we devise anefficient online updating strategy that dramatically reduces online updatetime. Theoretical analysis exhibits the splendid error bound and low timecomplexity of our model. The most popular test-then-training evaluationexperiments on various real-world datasets prove its superiority andefficiency. Furthermore, our framework is naturally extended to data streamscenarios with concept drift and exceeds state-of-the-art baselines.</description><author>Chunyu Lei, Guang-Ze Chen, C. L. Philip Chen, Tong Zhang</author><pubDate>Tue, 28 Jan 2025 13:21:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16932v1</guid></item><item><title>Quantifying Uncertainty and Variability in Machine Learning: Confidence Intervals for Quantiles in Performance Metric Distributions</title><link>http://arxiv.org/abs/2501.16931v1</link><description>Machine learning models are widely used in applications where reliability androbustness are critical. Model evaluation often relies on single-pointestimates of performance metrics such as accuracy, F1 score, or mean squarederror, that fail to capture the inherent variability in model performance. Thisvariability arises from multiple sources, including train-test split, weightsinitialization, and hyperparameter tuning. Investigating the characteristics ofperformance metric distributions, rather than focusing on a single point only,is essential for informed decision-making during model selection andoptimization, especially in high-stakes settings. How does the performance metric vary due to intrinsic uncertainty in theselected modeling approach? For example, train-test split is modified, initialweights for optimization are modified or hyperparameter tuning is done using analgorithm with probabilistic nature? This is shifting the focus from identifying a single best model tounderstanding a distribution of the performance metric that capturesvariability across different training conditions. By running multipleexperiments with varied settings, empirical distributions of performancemetrics can be generated. Analyzing these distributions can lead to more robustmodels that generalize well across diverse scenarios. This contribution explores the use of quantiles and confidence intervals toanalyze such distributions, providing a more complete understanding of modelperformance and its uncertainty. Aimed at a statistically interested audiencewithin the machine learning community, the suggested approaches are easy toimplement and apply to various performance metrics for classification andregression problems. Given the often long training times in ML, particularattention is given to small sample sizes (in the order of 10-25).</description><author>Christoph Lehmann, Yahor Paromau</author><pubDate>Tue, 28 Jan 2025 13:21:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16931v1</guid></item><item><title>LPBSA: Enhancing Optimization Efficiency through Learner Performance-based Behavior and Simulated Annealing</title><link>http://arxiv.org/abs/2501.14759v2</link><description>This study introduces the LPBSA, an advanced optimization algorithm thatcombines Learner Performance-based Behavior (LPB) and Simulated Annealing (SA)in a hybrid approach. Emphasizing metaheuristics, the LPBSA addresses andmitigates the challenges associated with traditional LPB methodologies,enhancing convergence, robustness, and adaptability in solving complexoptimization problems. Through extensive evaluations using benchmark testfunctions, the LPBSA demonstrates superior performance compared to LPB andcompetes favorably with established algorithms such as PSO, FDO, LEO, and GA.Real-world applications underscore the algorithm's promise, with LPBSAoutperforming the LEO algorithm in two tested scenarios. Based on the studyresults many test function results such as TF5 by recording (4.76762333) andsome other test functions provided in the result section prove that LPBSAoutperforms popular algorithms. This research highlights the efficacy of ahybrid approach in the ongoing evolution of optimization algorithms, showcasingthe LPBSA's capacity to navigate diverse optimization landscapes and contributesignificantly to addressing intricate optimization challenges.</description><author>Dana R. Hamad, Tarik A. Rashid</author><pubDate>Tue, 28 Jan 2025 13:19:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14759v2</guid></item><item><title>Foundational Large Language Models for Materials Research</title><link>http://arxiv.org/abs/2412.09560v2</link><description>Materials discovery and development are critical for addressing globalchallenges. Yet, the exponential growth in materials science literaturecomprising vast amounts of textual data has created significant bottlenecks inknowledge extraction, synthesis, and scientific reasoning. Large LanguageModels (LLMs) offer unprecedented opportunities to accelerate materialsresearch through automated analysis and prediction. Still, their effectivedeployment requires domain-specific adaptation for understanding and solvingdomain-relevant tasks. Here, we present LLaMat, a family of foundational modelsfor materials science developed through continued pretraining of LLaMA modelson an extensive corpus of materials literature and crystallographic data.Through systematic evaluation, we demonstrate that LLaMat excels inmaterials-specific NLP and structured information extraction while maintaininggeneral linguistic capabilities. The specialized LLaMat-CIF variantdemonstrates unprecedented capabilities in crystal structure generation,predicting stable crystals with high coverage across the periodic table.Intriguingly, despite LLaMA-3's superior performance in comparison to LLaMA-2,we observe that LLaMat-2 demonstrates unexpectedly enhanced domain-specificperformance across diverse materials science tasks, including structuredinformation extraction from text and tables, more particularly in crystalstructure generation, a potential adaptation rigidity in overtrained LLMs.Altogether, the present work demonstrates the effectiveness of domainadaptation towards developing practically deployable LLM copilots for materialsresearch. Beyond materials science, our findings reveal importantconsiderations for domain adaptation of LLMs, such as model selection, trainingmethodology, and domain-specific performance, which may influence thedevelopment of specialized scientific AI systems.</description><author>Vaibhav Mishra, Somaditya Singh, Dhruv Ahlawat, Mohd Zaki, Vaibhav Bihani, Hargun Singh Grover, Biswajit Mishra, Santiago Miret, Mausam, N. M. Anoop Krishnan</author><pubDate>Tue, 28 Jan 2025 13:17:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.09560v2</guid></item><item><title>Detecting harassment and defamation in cyberbullying with emotion-adaptive training</title><link>http://arxiv.org/abs/2501.16925v1</link><description>Existing research on detecting cyberbullying incidents on social media hasprimarily concentrated on harassment and is typically approached as a binaryclassification task. However, cyberbullying encompasses various forms, such asdenigration and harassment, which celebrities frequently face. Furthermore,suitable training data for these diverse forms of cyberbullying remains scarce.In this study, we first develop a celebrity cyberbullying dataset thatencompasses two distinct types of incidents: harassment and defamation. Weinvestigate various types of transformer-based models, namely masked (RoBERTa,Bert and DistilBert), replacing(Electra), autoregressive (XLnet),masked&amp;permuted (Mpnet), text-text (T5) and large language models (Llama2 andLlama3) under low source settings. We find that they perform competitively onexplicit harassment binary detection. However, their performance issubstantially lower on harassment and denigration multi-classification tasks.Therefore, we propose an emotion-adaptive training framework (EAT) that helpstransfer knowledge from the domain of emotion detection to the domain ofcyberbullying detection to help detect indirect cyberbullying events. EATconsistently improves the average macro F1, precision and recall by 20% incyberbullying detection tasks across nine transformer-based models underlow-resource settings. Our claims are supported by intuitive theoreticalinsights and extensive experiments.</description><author>Peiling Yi, Arkaitz Zubiaga, Yunfei Long</author><pubDate>Tue, 28 Jan 2025 13:15:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16925v1</guid></item><item><title>Agential AI for Integrated Continual Learning, Deliberative Behavior, and Comprehensible Models</title><link>http://arxiv.org/abs/2501.16922v1</link><description>Contemporary machine learning paradigm excels in statistical data analysis,solving problems that classical AI couldn't. However, it faces key limitations,such as a lack of integration with planning, incomprehensible internalstructure, and inability to learn continually. We present the initial designfor an AI system, Agential AI (AAI), in principle operating independently or ontop of statistical methods, designed to overcome these issues. AAI's core is alearning method that models temporal dynamics with guarantees of completeness,minimality, and continual learning, using component-level variation andselection to learn the structure of the environment. It integrates this with abehavior algorithm that plans on a learned model and encapsulates high-levelbehavior patterns. Preliminary experiments on a simple environment show AAI'seffectiveness and potential.</description><author>Zeki Doruk Erden, Boi Faltings</author><pubDate>Tue, 28 Jan 2025 13:09:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16922v1</guid></item></channel></rss>