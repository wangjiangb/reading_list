<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 07 May 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Complex Video Reasoning and Robustness Evaluation Suite for Video-LMMs</title><link>http://arxiv.org/abs/2405.03690v1</link><description>Recent advancements in Large Language Models (LLMs) have led to thedevelopment of Video Large Multi-modal Models (Video-LMMs) that can handle awide range of video understanding tasks. These models have the potential to bedeployed in real-world applications such as robotics, AI assistants, medicalimaging, and autonomous vehicles. The widespread adoption of Video-LMMs in ourdaily lives underscores the importance of ensuring and evaluating their robustperformance in mirroring human-like reasoning and interaction capabilities incomplex, real-world contexts. However, existing benchmarks for Video-LMMsprimarily focus on general video comprehension abilities and neglect assessingtheir reasoning capabilities over complex videos in the real-world context, androbustness of these models through the lens of user prompts as text queries. Inthis paper, we present the Complex Video Reasoning and Robustness EvaluationSuite (CVRR-ES), a novel benchmark that comprehensively assesses theperformance of Video-LMMs across 11 diverse real-world video dimensions. Weevaluate 9 recent models, including both open-source and closed-sourcevariants, and find that most of the Video-LMMs, {especially open-source ones,}struggle with robustness and reasoning when dealing with complex videos. Basedon our analysis, we develop a training-free Dual-Step Contextual Prompting(DSCP) technique to enhance the performance of existing Video-LMMs. Ourfindings provide valuable insights for building the next generation ofhuman-centric AI systems with advanced robustness and reasoning capabilities.Our dataset and code are publicly available at:https://mbzuai-oryx.github.io/CVRR-Evaluation-Suite/.</description><author>Muhammad Uzair Khattak, Muhammad Ferjad Naeem, Jameel Hassan, Muzammal Naseer, Federico Tombari, Fahad Shahbaz Khan, Salman Khan</author><pubDate>Mon, 06 May 2024 18:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03690v1</guid></item><item><title>Pose Priors from Language Models</title><link>http://arxiv.org/abs/2405.03689v1</link><description>We present a zero-shot pose optimization method that enforces accuratephysical contact constraints when estimating the 3D pose of humans. Our centralinsight is that since language is often used to describe physical interaction,large pretrained text-based models can act as priors on pose estimation. We can thus leverage this insight to improve pose estimation by convertingnatural language descriptors, generated by a large multimodal model (LMM), intotractable losses to constrain the 3D pose optimization. Despite its simplicity,our method produces surprisingly compelling pose reconstructions of people inclose contact, correctly capturing the semantics of the social and physicalinteractions. We demonstrate that our method rivals more complexstate-of-the-art approaches that require expensive human annotation of contactpoints and training specialized models. Moreover, unlike previous approaches,our method provides a unified framework for resolving self-contact andperson-to-person contact.</description><author>Sanjay Subramanian, Evonne Ng, Lea Müller, Dan Klein, Shiry Ginosar, Trevor Darrell</author><pubDate>Mon, 06 May 2024 18:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03689v1</guid></item><item><title>Large Language Models Reveal Information Operation Goals, Tactics, and Narrative Frames</title><link>http://arxiv.org/abs/2405.03688v1</link><description>Adversarial information operations can destabilize societies by underminingfair elections, manipulating public opinions on policies, and promoting scams.Despite their widespread occurrence and potential impacts, our understanding ofinfluence campaigns is limited by manual analysis of messages and subjectiveinterpretation of their observable behavior. In this paper, we explore whetherthese limitations can be mitigated with large language models (LLMs), usingGPT-3.5 as a case-study for coordinated campaign annotation. We first useGPT-3.5 to scrutinize 126 identified information operations spanning over adecade. We utilize a number of metrics to quantify the close (if imperfect)agreement between LLM and ground truth descriptions. We next extractcoordinated campaigns from two large multilingual datasets from X (formerlyTwitter) that respectively discuss the 2022 French election and 2023 BalikaranPhilippine-U.S. military exercise in 2023. For each coordinated campaign, weuse GPT-3.5 to analyze posts related to a specific concern and extract goals,tactics, and narrative frames, both before and after critical events (such asthe date of an election). While the GPT-3.5 sometimes disagrees with subjectiveinterpretation, its ability to summarize and interpret demonstrates LLMs'potential to extract higher-order indicators from text to provide a morecomplete picture of the information campaigns compared to previous methods.</description><author>Keith Burghardt, Kai Chen, Kristina Lerman</author><pubDate>Mon, 06 May 2024 18:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03688v1</guid></item><item><title>Automated Generation of High-Quality Medical Simulation Scenarios Through Integration of Semi-Structured Data and Large Language Models</title><link>http://arxiv.org/abs/2404.19713v2</link><description>This study introduces a transformative framework for medical education byintegrating semi-structured data with Large Language Models (LLMs), primarilyOpenAIs ChatGPT3.5, to automate the creation of medical simulation scenarios.Traditionally, developing these scenarios was a time-intensive process withlimited flexibility to meet diverse educational needs. The proposed approachutilizes AI to efficiently generate detailed, clinically relevant scenariosthat are tailored to specific educational objectives. This innovation hassignificantly reduced the time and resources required for scenario development,allowing for a broader variety of simulations. Preliminary feedback fromeducators and learners has shown enhanced engagement and improved knowledgeacquisition, confirming the effectiveness of this AI-enhanced methodology insimulation-based learning. The integration of structured data with LLMs notonly streamlines the creation process but also offers a scalable, dynamicsolution that could revolutionize medical training, highlighting the criticalrole of AI in advancing educational outcomes and patient care standards.</description><author>Scott Sumpter</author><pubDate>Mon, 06 May 2024 18:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19713v2</guid></item><item><title>Language-Image Models with 3D Understanding</title><link>http://arxiv.org/abs/2405.03685v1</link><description>Multi-modal large language models (MLLMs) have shown incredible capabilitiesin a variety of 2D vision and language tasks. We extend MLLMs' perceptualcapabilities to ground and reason about images in 3-dimensional space. To thatend, we first develop a large-scale pre-training dataset for 2D and 3D calledLV3D by combining multiple existing 2D and 3D recognition datasets under acommon task formulation: as multi-turn question-answering. Next, we introduce anew MLLM named Cube-LLM and pre-train it on LV3D. We show that pure datascaling makes a strong 3D perception capability without 3D specificarchitectural design or training objective. Cube-LLM exhibits intriguingproperties similar to LLMs: (1) Cube-LLM can apply chain-of-thought promptingto improve 3D understanding from 2D context information. (2) Cube-LLM canfollow complex and diverse instructions and adapt to versatile input and outputformats. (3) Cube-LLM can be visually prompted such as 2D box or a set ofcandidate 3D boxes from specialists. Our experiments on outdoor benchmarksdemonstrate that Cube-LLM significantly outperforms existing baselines by 21.3points of AP-BEV on the Talk2Car dataset for 3D grounded reasoning and 17.7points on the DriveLM dataset for complex reasoning about driving scenarios,respectively. Cube-LLM also shows competitive results in general MLLMbenchmarks such as refCOCO for 2D grounding with (87.0) average score, as wellas visual question answering benchmarks such as VQAv2, GQA, SQA, POPE, etc. forcomplex reasoning. Our project is available athttps://janghyuncho.github.io/Cube-LLM.</description><author>Jang Hyun Cho, Boris Ivanovic, Yulong Cao, Edward Schmerling, Yue Wang, Xinshuo Weng, Boyi Li, Yurong You, Philipp Krähenbühl, Yan Wang, Marco Pavone</author><pubDate>Mon, 06 May 2024 18:57:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03685v1</guid></item><item><title>An Empty Room is All We Want: Automatic Defurnishing of Indoor Panoramas</title><link>http://arxiv.org/abs/2405.03682v1</link><description>We propose a pipeline that leverages Stable Diffusion to improve inpaintingresults in the context of defurnishing -- the removal of furniture items fromindoor panorama images. Specifically, we illustrate how increased context,domain-specific model fine-tuning, and improved image blending can producehigh-fidelity inpaints that are geometrically plausible without needing to relyon room layout estimation. We demonstrate qualitative and quantitativeimprovements over other furniture removal techniques.</description><author>Mira Slavcheva, Dave Gausebeck, Kevin Chen, David Buchhofer, Azwad Sabik, Chen Ma, Sachal Dhillon, Olaf Brandt, Alan Dolhasz</author><pubDate>Mon, 06 May 2024 18:57:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03682v1</guid></item><item><title>Towards A Human-in-the-Loop LLM Approach to Collaborative Discourse Analysis</title><link>http://arxiv.org/abs/2405.03677v1</link><description>LLMs have demonstrated proficiency in contextualizing their outputs usinghuman input, often matching or beating human-level performance on a variety oftasks. However, LLMs have not yet been used to characterize synergisticlearning in students' collaborative discourse. In this exploratory work, wetake a first step towards adopting a human-in-the-loop prompt engineeringapproach with GPT-4-Turbo to summarize and categorize students' synergisticlearning during collaborative discourse. Our preliminary findings suggestGPT-4-Turbo may be able to characterize students' synergistic learning in amanner comparable to humans and that our approach warrants furtherinvestigation.</description><author>Clayton Cohn, Caitlin Snyder, Justin Montenegro, Gautam Biswas</author><pubDate>Mon, 06 May 2024 18:53:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03677v1</guid></item><item><title>Why is SAM Robust to Label Noise?</title><link>http://arxiv.org/abs/2405.03676v1</link><description>Sharpness-Aware Minimization (SAM) is most known for achieving state-ofthe-art performances on natural image and language tasks. However, its mostpronounced improvements (of tens of percent) is rather in the presence of labelnoise. Understanding SAM's label noise robustness requires a departure fromcharacterizing the robustness of minimas lying in "flatter" regions of the losslandscape. In particular, the peak performance under label noise occurs withearly stopping, far before the loss converges. We decompose SAM's robustnessinto two effects: one induced by changes to the logit term and the otherinduced by changes to the network Jacobian. The first can be observed in linearlogistic regression where SAM provably up-weights the gradient contributionfrom clean examples. Although this explicit up-weighting is also observable inneural networks, when we intervene and modify SAM to remove this effect,surprisingly, we see no visible degradation in performance. We infer that SAM'seffect in deeper networks is instead explained entirely by the effect SAM hason the network Jacobian. We theoretically derive the implicit regularizationinduced by this Jacobian effect in two layer linear networks. Motivated by ouranalysis, we see that cheaper alternatives to SAM that explicitly induce theseregularization effects largely recover the benefits in deep networks trained onreal-world datasets.</description><author>Christina Baek, Zico Kolter, Aditi Raghunathan</author><pubDate>Mon, 06 May 2024 18:52:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03676v1</guid></item><item><title>MemoryMamba: Memory-Augmented State Space Model for Defect Recognition</title><link>http://arxiv.org/abs/2405.03673v1</link><description>As automation advances in manufacturing, the demand for precise andsophisticated defect detection technologies grows. Existing vision models fordefect recognition methods are insufficient for handling the complexities andvariations of defects in contemporary manufacturing settings. These modelsespecially struggle in scenarios involving limited or imbalanced defect data.In this work, we introduce MemoryMamba, a novel memory-augmented state spacemodel (SSM), designed to overcome the limitations of existing defectrecognition models. MemoryMamba integrates the state space model with thememory augmentation mechanism, enabling the system to maintain and retrieveessential defect-specific information in training. Its architecture is designedto capture dependencies and intricate defect characteristics, which are crucialfor effective defect detection. In the experiments, MemoryMamba was evaluatedacross four industrial datasets with diverse defect types and complexities. Themodel consistently outperformed other methods, demonstrating its capability toadapt to various defect recognition scenarios.</description><author>Qianning Wang, He Hu, Yucheng Zhou</author><pubDate>Mon, 06 May 2024 18:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03673v1</guid></item><item><title>Cutting through buggy adversarial example defenses: fixing 1 line of code breaks Sabre</title><link>http://arxiv.org/abs/2405.03672v1</link><description>Sabre is a defense to adversarial examples that was accepted at IEEE S&amp;P2024. We first reveal significant flaws in the evaluation that point to clearsigns of gradient masking. We then show the cause of this gradient masking: abug in the original evaluation code. By fixing a single line of code in theoriginal repository, we reduce Sabre's robust accuracy to 0%. In response tothis, the authors modify the defense and introduce a new defense component notdescribed in the original paper. But this fix contains a second bug; modifyingone more line of code reduces robust accuracy to below baseline levels.</description><author>Nicholas Carlini</author><pubDate>Mon, 06 May 2024 18:48:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03672v1</guid></item><item><title>Prompting Task Trees using Gemini: Methodologies and Insights</title><link>http://arxiv.org/abs/2405.03671v1</link><description>Robots are the future of every technology where every advanced technologyeventually will be used to make robots which are more efficient. The majorchallenge today is to train the robots exactly and empathetically usingknowledge representation. This paper gives you insights of how we can useunstructured knowledge representation and convert them to meaningful structuredrepresentation with the help of prompt engineering which can be eventually usedin the robots to make help them understand how human brain can make wonderswith the minimal data or objects can providing to them.</description><author>Pallavi Tandra</author><pubDate>Mon, 06 May 2024 18:48:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03671v1</guid></item><item><title>A Simple and Effective Pruning Approach for Large Language Models</title><link>http://arxiv.org/abs/2306.11695v3</link><description>As their size increases, Large Languages Models (LLMs) are natural candidatesfor network pruning methods: approaches that drop a subset of network weightswhile striving to preserve performance. Existing methods, however, requireeither retraining, which is rarely affordable for billion-scale LLMs, orsolving a weight reconstruction problem reliant on second-order information,which may also be computationally expensive. In this paper, we introduce anovel, straightforward yet effective pruning method, termed Wanda (Pruning byWeights and activations), designed to induce sparsity in pretrained LLMs.Motivated by the recent observation of emergent large magnitude features inLLMs, our approach prunes weights with the smallest magnitudes multiplied bythe corresponding input activations, on a per-output basis. Notably, Wandarequires no retraining or weight update, and the pruned LLM can be used as is.We conduct a thorough evaluation of our method Wanda on LLaMA and LLaMA-2across various language benchmarks. Wanda significantly outperforms theestablished baseline of magnitude pruning and performs competitively againstrecent method involving intensive weight update. Code is available athttps://github.com/locuslab/wanda.</description><author>Mingjie Sun, Zhuang Liu, Anna Bair, J. Zico Kolter</author><pubDate>Mon, 06 May 2024 18:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11695v3</guid></item><item><title>Can Language Model Moderators Improve the Health of Online Discourse?</title><link>http://arxiv.org/abs/2311.10781v2</link><description>Conversational moderation of online communities is crucial to maintainingcivility for a constructive environment, but it is challenging to scale andharmful to moderators. The inclusion of sophisticated natural languagegeneration modules as a force multiplier to aid human moderators is atantalizing prospect, but adequate evaluation approaches have so far beenelusive. In this paper, we establish a systematic definition of conversationalmoderation effectiveness grounded on moderation literature and establish designcriteria for conducting realistic yet safe evaluation. We then propose acomprehensive evaluation framework to assess models' moderation capabilitiesindependently of human intervention. With our framework, we conduct the firstknown study of language models as conversational moderators, finding thatappropriately prompted models that incorporate insights from social science canprovide specific and fair feedback on toxic behavior but struggle to influenceusers to increase their levels of respect and cooperation.</description><author>Hyundong Cho, Shuai Liu, Taiwei Shi, Darpan Jain, Basem Rizk, Yuyang Huang, Zixun Lu, Nuan Wen, Jonathan Gratch, Emilio Ferrara, Jonathan May</author><pubDate>Mon, 06 May 2024 18:44:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10781v2</guid></item><item><title>Fault Detection and Monitoring using an Information-Driven Strategy: Method, Theory, and Application</title><link>http://arxiv.org/abs/2405.03667v1</link><description>The ability to detect when a system undergoes an incipient fault is ofparamount importance in preventing a critical failure. In this work, we proposean information-driven fault detection method based on a novel concept driftdetector. The method is tailored to identifying drifts in input-outputrelationships of additive noise models (i.e., model drifts) and is based on adistribution-free mutual information (MI) estimator. Our scheme does notrequire prior faulty examples and can be applied distribution-free over a largeclass of system models. Our core contributions are twofold. First, wedemonstrate the connection between fault detection, model drift detection, andtesting independence between two random variables. Second, we prove severaltheoretical properties of the proposed MI-based fault detection scheme: (i)strong consistency, (ii) exponentially fast detection of the non-faulty case,and (iii) control of both significance levels and power of the test. Toconclude, we validate our theory with synthetic data and the benchmark datasetN-CMAPSS of aircraft turbofan engines. These empirical results support theusefulness of our methodology in many practical and realistic settings, and thetheoretical results show performance guarantees that other methods cannotoffer.</description><author>Camilo Ramírez, Jorge F. Silva, Ferhat Tamssaouet, Tomás Rojas, Marcos E. Orchard</author><pubDate>Mon, 06 May 2024 18:43:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03667v1</guid></item><item><title>ScrewMimic: Bimanual Imitation from Human Videos with Screw Space Projection</title><link>http://arxiv.org/abs/2405.03666v1</link><description>Bimanual manipulation is a longstanding challenge in robotics due to thelarge number of degrees of freedom and the strict spatial and temporalsynchronization required to generate meaningful behavior. Humans learn bimanualmanipulation skills by watching other humans and by refining their abilitiesthrough play. In this work, we aim to enable robots to learn bimanualmanipulation behaviors from human video demonstrations and fine-tune themthrough interaction. Inspired by seminal work in psychology and biomechanics,we propose modeling the interaction between two hands as a serial kinematiclinkage -- as a screw motion, in particular, that we use to define a new actionspace for bimanual manipulation: screw actions. We introduce ScrewMimic, aframework that leverages this novel action representation to facilitatelearning from human demonstration and self-supervised policy fine-tuning. Ourexperiments demonstrate that ScrewMimic is able to learn several complexbimanual behaviors from a single human video demonstration, and that itoutperforms baselines that interpret demonstrations and fine-tune directly inthe original space of motion of both arms. For more information and videoresults, https://robin-lab.cs.utexas.edu/ScrewMimic/</description><author>Arpit Bahety, Priyanka Mandikal, Ben Abbatematteo, Roberto Martín-Martín</author><pubDate>Mon, 06 May 2024 18:43:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03666v1</guid></item><item><title>A New Robust Partial $p$-Wasserstein-Based Metric for Comparing Distributions</title><link>http://arxiv.org/abs/2405.03664v1</link><description>The $2$-Wasserstein distance is sensitive to minor geometric differencesbetween distributions, making it a very powerful dissimilarity metric. However,due to this sensitivity, a small outlier mass can also cause a significantincrease in the $2$-Wasserstein distance between two similar distributions.Similarly, sampling discrepancy can cause the empirical $2$-Wassersteindistance on $n$ samples in $\mathbb{R}^2$ to converge to the true distance at arate of $n^{-1/4}$, which is significantly slower than the rate of $n^{-1/2}$for $1$-Wasserstein distance. We introduce a new family of distances parameterized by $k \ge 0$, called$k$-RPW, that is based on computing the partial $2$-Wasserstein distance. Weshow that (1) $k$-RPW satisfies the metric properties, (2) $k$-RPW is robust tosmall outlier mass while retaining the sensitivity of $2$-Wasserstein distanceto minor geometric differences, and (3) when $k$ is a constant, $k$-RPWdistance between empirical distributions on $n$ samples in $\mathbb{R}^2$converges to the true distance at a rate of $n^{-1/3}$, which is faster thanthe convergence rate of $n^{-1/4}$ for the $2$-Wasserstein distance. Using the partial $p$-Wasserstein distance, we extend our distance to any $p\in [1,\infty]$. By setting parameters $k$ or $p$ appropriately, we can reduceour distance to the total variation, $p$-Wasserstein, and the L\'evy-Prokhorovdistances. Experiments show that our distance function achieves higher accuracyin comparison to the $1$-Wasserstein, $2$-Wasserstein, and TV distances forimage retrieval tasks on noisy real-world data sets.</description><author>Sharath Raghvendra, Pouyan Shirzadian, Kaiyi Zhang</author><pubDate>Mon, 06 May 2024 18:41:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03664v1</guid></item><item><title>Diffeomorphic Template Registration for Atmospheric Turbulence Mitigation</title><link>http://arxiv.org/abs/2405.03662v1</link><description>We describe a method for recovering the irradiance underlying a collection ofimages corrupted by atmospheric turbulence. Since supervised data is oftentechnically impossible to obtain, assumptions and biases have to be imposed tosolve this inverse problem, and we choose to model them explicitly. Rather thaninitializing a latent irradiance ("template") by heuristics to estimatedeformation, we select one of the images as a reference, and model thedeformation in this image by the aggregation of the optical flow from it toother images, exploiting a prior imposed by Central Limit Theorem. Then with anovel flow inversion module, the model registers each image TO the template butWITHOUT the template, avoiding artifacts related to poor templateinitialization. To illustrate the robustness of the method, we simply (i)select the first frame as the reference and (ii) use the simplest optical flowto estimate the warpings, yet the improvement in registration is decisive inthe final reconstruction, as we achieve state-of-the-art performance despiteits simplicity. The method establishes a strong baseline that can be furtherimproved by integrating it seamlessly into more sophisticated pipelines, orwith domain-specific methods if so desired.</description><author>Dong Lao, Congli Wang, Alex Wong, Stefano Soatto</author><pubDate>Mon, 06 May 2024 18:39:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03662v1</guid></item><item><title>Competitive strategies to use "warm start" algorithms with predictions</title><link>http://arxiv.org/abs/2405.03661v1</link><description>We consider the problem of learning and using predictions for warm startalgorithms with predictions. In this setting, an algorithm is given an instanceof a problem, and a prediction of the solution. The runtime of the algorithm isbounded by the distance from the predicted solution to the true solution of theinstance. Previous work has shown that when instances are drawn iid from somedistribution, it is possible to learn an approximately optimal fixed prediction(Dinitz et al, NeurIPS 2021), and in the adversarial online case, it ispossible to compete with the best fixed prediction in hindsight (Khodak et al,NeurIPS 2022). In this work we give competitive guarantees against stronger benchmarks thatconsider a set of $k$ predictions $\mathbf{P}$. That is, the "optimal offlinecost" to solve an instance with respect to $\mathbf{P}$ is the distance fromthe true solution to the closest member of $\mathbf{P}$. This is analogous tothe $k$-medians objective function. In the distributional setting, we show asimple strategy that incurs cost that is at most an $O(k)$ factor worse thanthe optimal offline cost. We then show a way to leverage learnable coarseinformation, in the form of partitions of the instance space into groups of"similar" instances, that allows us to potentially avoid this $O(k)$ factor. Finally, we consider an online version of the problem, where we competeagainst offline strategies that are allowed to maintain a moving set of $k$predictions or "trajectories," and are charged for how much the predictionsmove. We give an algorithm that does at most $O(k^4 \ln^2 k)$ times as muchwork as any offline strategy of $k$ trajectories. This algorithm isdeterministic (robust to an adaptive adversary), and oblivious to the settingof $k$. Thus the guarantee holds for all $k$ simultaneously.</description><author>Vaidehi Srinivas, Avrim Blum</author><pubDate>Mon, 06 May 2024 18:38:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03661v1</guid></item><item><title>CICA: Content-Injected Contrastive Alignment for Zero-Shot Document Image Classification</title><link>http://arxiv.org/abs/2405.03660v1</link><description>Zero-shot learning has been extensively investigated in the broader field ofvisual recognition, attracting significant interest recently. However, thecurrent work on zero-shot learning in document image classification remainsscarce. The existing studies either focus exclusively on zero-shot inference,or their evaluation does not align with the established criteria of zero-shotevaluation in the visual recognition domain. We provide a comprehensivedocument image classification analysis in Zero-Shot Learning (ZSL) andGeneralized Zero-Shot Learning (GZSL) settings to address this gap. Ourmethodology and evaluation align with the established practices of this domain.Additionally, we propose zero-shot splits for the RVL-CDIP dataset.Furthermore, we introduce CICA (pronounced 'ki-ka'), a framework that enhancesthe zero-shot learning capabilities of CLIP. CICA consists of a novel 'contentmodule' designed to leverage any generic document-related textual information.The discriminative features extracted by this module are aligned with CLIP'stext and image features using a novel 'coupled-contrastive' loss. Our moduleimproves CLIP's ZSL top-1 accuracy by 6.7% and GZSL harmonic mean by 24% on theRVL-CDIP dataset. Our module is lightweight and adds only 3.3% more parametersto CLIP. Our work sets the direction for future research in zero-shot documentclassification.</description><author>Sankalp Sinha, Muhammad Saif Ullah Khan, Talha Uddin Sheikh, Didier Stricker, Muhammad Zeshan Afzal</author><pubDate>Mon, 06 May 2024 18:37:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03660v1</guid></item><item><title>A Construct-Optimize Approach to Sparse View Synthesis without Camera Pose</title><link>http://arxiv.org/abs/2405.03659v1</link><description>Novel view synthesis from a sparse set of input images is a challengingproblem of great practical interest, especially when camera poses are absent orinaccurate. Direct optimization of camera poses and usage of estimated depthsin neural radiance field algorithms usually do not produce good results becauseof the coupling between poses and depths, and inaccuracies in monocular depthestimation. In this paper, we leverage the recent 3D Gaussian splatting methodto develop a novel construct-and-optimize method for sparse view synthesiswithout camera poses. Specifically, we construct a solution progressively byusing monocular depth and projecting pixels back into the 3D world. Duringconstruction, we optimize the solution by detecting 2D correspondences betweentraining views and the corresponding rendered images. We develop a unifieddifferentiable pipeline for camera registration and adjustment of both cameraposes and depths, followed by back-projection. We also introduce a novel notionof an expected surface in Gaussian splatting, which is critical to ouroptimization. These steps enable a coarse solution, which can then be low-passfiltered and refined using standard optimization methods. We demonstrateresults on the Tanks and Temples and Static Hikes datasets with as few as threewidely-spaced views, showing significantly better quality than competingmethods, including those with approximate camera pose information. Moreover,our results improve with more views and outperform previous InstantNGP andGaussian Splatting algorithms even when using half the dataset.</description><author>Kaiwen Jiang, Yang Fu, Mukund Varma T, Yash Belhe, Xiaolong Wang, Hao Su, Ravi Ramamoorthi</author><pubDate>Mon, 06 May 2024 18:36:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03659v1</guid></item><item><title>A review on data-driven constitutive laws for solids</title><link>http://arxiv.org/abs/2405.03658v1</link><description>This review article highlights state-of-the-art data-driven techniques todiscover, encode, surrogate, or emulate constitutive laws that describe thepath-independent and path-dependent response of solids. Our objective is toprovide an organized taxonomy to a large spectrum of methodologies developed inthe past decades and to discuss the benefits and drawbacks of the varioustechniques for interpreting and forecasting mechanics behavior across differentscales. Distinguishing between machine-learning-based and model-free methods,we further categorize approaches based on their interpretability and on theirlearning process/type of required data, while discussing the key problems ofgeneralization and trustworthiness. We attempt to provide a road map of howthese can be reconciled in a data-availability-aware context. We also touchupon relevant aspects such as data sampling techniques, design of experiments,verification, and validation.</description><author>Jan Niklas Fuhg, Govinda Anantha Padmanabha, Nikolaos Bouklas, Bahador Bahmani, WaiChing Sun, Nikolaos N. Vlassis, Moritz Flaschel, Pietro Carrara, Laura De Lorenzis</author><pubDate>Mon, 06 May 2024 18:33:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03658v1</guid></item><item><title>Recent Trends in 3D Reconstruction of General Non-Rigid Scenes</title><link>http://arxiv.org/abs/2403.15064v2</link><description>Reconstructing models of the real world, including 3D geometry, appearance,and motion of real scenes, is essential for computer graphics and computervision. It enables the synthesizing of photorealistic novel views, useful forthe movie industry and AR/VR applications. It also facilitates the contentcreation necessary in computer games and AR/VR by avoiding laborious manualdesign processes. Further, such models are fundamental for intelligentcomputing systems that need to interpret real-world scenes and actions to actand interact safely with the human world. Notably, the world surrounding us isdynamic, and reconstructing models of dynamic, non-rigidly moving scenes is aseverely underconstrained and challenging problem. This state-of-the-art report(STAR) offers the reader a comprehensive summary of state-of-the-art techniqueswith monocular and multi-view inputs such as data from RGB and RGB-D sensors,among others, conveying an understanding of different approaches, theirpotential applications, and promising further research directions. The reportcovers 3D reconstruction of general non-rigid scenes and further addresses thetechniques for scene decomposition, editing and controlling, and generalizableand generative modeling. More specifically, we first review the common andfundamental concepts necessary to understand and navigate the field and thendiscuss the state-of-the-art techniques by reviewing recent approaches that usetraditional and machine-learning-based neural representations, including adiscussion on the newly enabled applications. The STAR is concluded with adiscussion of the remaining limitations and open challenges.</description><author>Raza Yunus, Jan Eric Lenssen, Michael Niemeyer, Yiyi Liao, Christian Rupprecht, Christian Theobalt, Gerard Pons-Moll, Jia-Bin Huang, Vladislav Golyanik, Eddy Ilg</author><pubDate>Mon, 06 May 2024 18:28:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15064v2</guid></item><item><title>Can LLMs Deeply Detect Complex Malicious Queries? A Framework for Jailbreaking via Obfuscating Intent</title><link>http://arxiv.org/abs/2405.03654v1</link><description>To demonstrate and address the underlying maliciousness, we propose atheoretical hypothesis and analytical approach, and introduce a new black-boxjailbreak attack methodology named IntentObfuscator, exploiting this identifiedflaw by obfuscating the true intentions behind user prompts.This approachcompels LLMs to inadvertently generate restricted content, bypassing theirbuilt-in content security measures. We detail two implementations under thisframework: "Obscure Intention" and "Create Ambiguity", which manipulate querycomplexity and ambiguity to evade malicious intent detection effectively. Weempirically validate the effectiveness of the IntentObfuscator method acrossseveral models, including ChatGPT-3.5, ChatGPT-4, Qwen and Baichuan, achievingan average jailbreak success rate of 69.21\%. Notably, our tests onChatGPT-3.5, which claims 100 million weekly active users, achieved aremarkable success rate of 83.65\%. We also extend our validation to diversetypes of sensitive content like graphic violence, racism, sexism, politicalsensitivity, cybersecurity threats, and criminal skills, further proving thesubstantial impact of our findings on enhancing 'Red Team' strategies againstLLM content security frameworks.</description><author>Shang Shang, Xinqiang Zhao, Zhongjiang Yao, Yepeng Yao, Liya Su, Zijing Fan, Xiaodan Zhang, Zhengwei Jiang</author><pubDate>Mon, 06 May 2024 18:26:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03654v1</guid></item><item><title>Field-of-View Extension for Diffusion MRI via Deep Generative Models</title><link>http://arxiv.org/abs/2405.03652v1</link><description>Purpose: In diffusion MRI (dMRI), the volumetric and bundle analyses ofwhole-brain tissue microstructure and connectivity can be severely impeded byan incomplete field-of-view (FOV). This work aims to develop a method forimputing the missing slices directly from existing dMRI scans with anincomplete FOV. We hypothesize that the imputed image with complete FOV canimprove the whole-brain tractography for corrupted data with incomplete FOV.Therefore, our approach provides a desirable alternative to discarding thevaluable dMRI data, enabling subsequent tractography analyses that wouldotherwise be challenging or unattainable with corrupted data. Approach: Wepropose a framework based on a deep generative model that estimates the absentbrain regions in dMRI scans with incomplete FOV. The model is capable oflearning both the diffusion characteristics in diffusion-weighted images (DWI)and the anatomical features evident in the corresponding structural images forefficiently imputing missing slices of DWI outside of incomplete FOV. Results:For evaluating the imputed slices, on the WRAP dataset the proposed frameworkachieved PSNRb0=22.397, SSIMb0=0.905, PSNRb1300=22.479, SSIMb1300=0.893; on theNACC dataset it achieved PSNRb0=21.304, SSIMb0=0.892, PSNRb1300=21.599,SSIMb1300= 0.877. The proposed framework improved the tractography accuracy, asdemonstrated by an increased average Dice score for 72 tracts (p &lt; 0.001) onboth the WRAP and NACC datasets. Conclusions: Results suggest that the proposedframework achieved sufficient imputation performance in dMRI data withincomplete FOV for improving whole-brain tractography, thereby repairing thecorrupted data. Our approach achieved more accurate whole-brain tractographyresults with extended and complete FOV and reduced the uncertainty whenanalyzing bundles associated with Alzheimer's Disease.</description><author>Chenyu Gao, Shunxing Bao, Michael Kim, Nancy Newlin, Praitayini Kanakaraj, Tianyuan Yao, Gaurav Rudravaram, Yuankai Huo, Daniel Moyer, Kurt Schilling, Walter Kukull, Arthur Toga, Derek Archer, Timothy Hohman, Bennett Landman, Zhiyuan Li</author><pubDate>Mon, 06 May 2024 18:23:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03652v1</guid></item><item><title>Adaptive Retrieval and Scalable Indexing for k-NN Search with Cross-Encoders</title><link>http://arxiv.org/abs/2405.03651v1</link><description>Cross-encoder (CE) models which compute similarity by jointly encoding aquery-item pair perform better than embedding-based models (dual-encoders) atestimating query-item relevance. Existing approaches perform k-NN search withCE by approximating the CE similarity with a vector embedding space fit eitherwith dual-encoders (DE) or CUR matrix factorization. DE-basedretrieve-and-rerank approaches suffer from poor recall on new domains and theretrieval with DE is decoupled from the CE. While CUR-based approaches can bemore accurate than the DE-based approach, they require a prohibitively largenumber of CE calls to compute item embeddings, thus making it impractical fordeployment at scale. In this paper, we address these shortcomings with ourproposed sparse-matrix factorization based method that efficiently computeslatent query and item embeddings to approximate CE scores and performs k-NNsearch with the approximate CE similarity. We compute item embeddings offlineby factorizing a sparse matrix containing query-item CE scores for a set oftrain queries. Our method produces a high-quality approximation while requiringonly a fraction of CE calls as compared to CUR-based methods, and allows forleveraging DE to initialize the embedding space while avoiding compute- andresource-intensive finetuning of DE via distillation. At test time, the itemembeddings remain fixed and retrieval occurs over rounds, alternating betweena) estimating the test query embedding by minimizing error in approximating CEscores of items retrieved thus far, and b) using the updated test queryembedding for retrieving more items. Our k-NN search method improves recall byup to 5% (k=1) and 54% (k=100) over DE-based approaches. Additionally, ourindexing approach achieves a speedup of up to 100x over CUR-based and 5x overDE distillation methods, while matching or improving k-NN search recall overbaselines.</description><author>Nishant Yadav, Nicholas Monath, Manzil Zaheer, Rob Fergus, Andrew McCallum</author><pubDate>Mon, 06 May 2024 18:14:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03651v1</guid></item><item><title>Generated Contents Enrichment</title><link>http://arxiv.org/abs/2405.03650v1</link><description>In this paper, we investigate a novel artificial intelligence generationtask, termed as generated contents enrichment (GCE). Different fromconventional artificial intelligence contents generation task that enriches thegiven textual description implicitly with limited semantics for generatingvisually real content, our proposed GCE strives to perform content enrichmentexplicitly on both the visual and textual domain, from which the enrichedcontents are visually real, structurally reasonable, and semantically abundant.Towards to solve GCE, we propose a deep end-to-end method that explicitlyexplores the semantics and inter-semantic relationships during the enrichment.Specifically, we first model the input description as a semantic graph, whereineach node represents an object and each edge corresponds to the inter-objectrelationship. We then adopt Graph Convolutional Networks on top of the inputscene description to predict the enriching objects and their relationships withthe input objects. Finally, the enriched graph is fed into an image synthesismodel to carry out the visual contents generation. Our experiments conducted onthe Visual Genome dataset exhibit promising and visually plausible results.</description><author>Mahdi Naseri, Jiayan Qiu, Zhou Wang</author><pubDate>Mon, 06 May 2024 18:14:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03650v1</guid></item><item><title>On-the-Fly Fusion of Large Language Models and Machine Translation</title><link>http://arxiv.org/abs/2311.08306v2</link><description>We propose the on-the-fly ensembling of a machine translation model with anLLM, prompted on the same task and input. We perform experiments on 4 languagepairs (both directions) with varying data amounts. We find that a slightlyweaker-at-translation LLM can improve translations of a NMT model, andensembling with an LLM can produce better translations than ensembling twostronger MT models. We combine our method with various techniques from LLMprompting, such as in context learning and translation context.</description><author>Hieu Hoang, Huda Khayrallah, Marcin Junczys-Dowmunt</author><pubDate>Mon, 06 May 2024 18:13:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08306v2</guid></item><item><title>Learning Robust Classifiers with Self-Guided Spurious Correlation Mitigation</title><link>http://arxiv.org/abs/2405.03649v1</link><description>Deep neural classifiers tend to rely on spurious correlations betweenspurious attributes of inputs and targets to make predictions, which couldjeopardize their generalization capability. Training classifiers robust tospurious correlations typically relies on annotations of spurious correlationsin data, which are often expensive to get. In this paper, we tackle anannotation-free setting and propose a self-guided spurious correlationmitigation framework. Our framework automatically constructs fine-grainedtraining labels tailored for a classifier obtained with empirical riskminimization to improve its robustness against spurious correlations. Thefine-grained training labels are formulated with different prediction behaviorsof the classifier identified in a novel spuriousness embedding space. Weconstruct the space with automatically detected conceptual attributes and anovel spuriousness metric which measures how likely a class-attributecorrelation is exploited for predictions. We demonstrate that training theclassifier to distinguish different prediction behaviors reduces its relianceon spurious correlations without knowing them a priori and outperforms priormethods on five real-world datasets.</description><author>Guangtao Zheng, Wenqian Ye, Aidong Zhang</author><pubDate>Mon, 06 May 2024 18:12:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03649v1</guid></item><item><title>When LLMs Meet Cybersecurity: A Systematic Literature Review</title><link>http://arxiv.org/abs/2405.03644v1</link><description>The rapid advancements in large language models (LLMs) have opened newavenues across various fields, including cybersecurity, which faces anever-evolving threat landscape and need for innovative technologies. Despiteinitial explorations into the application of LLMs in cybersecurity, there is alack of a comprehensive overview of this research area. This paper bridge thisgap by providing a systematic literature review, encompassing an analysis ofover 180 works, spanning across 25 LLMs and more than 10 downstream scenarios.Our comprehensive overview addresses three critical research questions: theconstruction of cybersecurity-oriented LLMs, LLMs' applications in variouscybersecurity tasks, and the existing challenges and further research in thisarea. This study aims to shed light on the extensive potential of LLMs inenhancing cybersecurity practices, and serve as a valuable resource forapplying LLMs in this doamin. We also maintain and regularly updated list ofpractical guides on LLMs for cybersecurity athttps://github.com/tmylla/Awesome-LLM4Cybersecurity.</description><author>Jie Zhang, Haoyu Bu, Hui Wen, Yu Chen, Lun Li, Hongsong Zhu</author><pubDate>Mon, 06 May 2024 18:07:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03644v1</guid></item><item><title>Collecting Consistently High Quality Object Tracks with Minimal Human Involvement by Using Self-Supervised Learning to Detect Tracker Errors</title><link>http://arxiv.org/abs/2405.03643v1</link><description>We propose a hybrid framework for consistently producing high-quality objecttracks by combining an automated object tracker with little human input. Thekey idea is to tailor a module for each dataset to intelligently decide when anobject tracker is failing and so humans should be brought in to re-localize anobject for continued tracking. Our approach leverages self-supervised learningon unlabeled videos to learn a tailored representation for a target object thatis then used to actively monitor its tracked region and decide when the trackerfails. Since labeled data is not needed, our approach can be applied to novelobject categories. Experiments on three datasets demonstrate our methodoutperforms existing approaches, especially for small, fast moving, or occludedobjects.</description><author>Samreen Anjum, Suyog Jain, Danna Gurari</author><pubDate>Mon, 06 May 2024 18:06:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03643v1</guid></item><item><title>Classification of Breast Cancer Histopathology Images using a Modified Supervised Contrastive Learning Method</title><link>http://arxiv.org/abs/2405.03642v1</link><description>Deep neural networks have reached remarkable achievements in medical imageprocessing tasks, specifically classifying and detecting various diseases.However, when confronted with limited data, these networks face a criticalvulnerability, often succumbing to overfitting by excessively memorizing thelimited information available. This work addresses the challenge mentionedabove by improving the supervised contrastive learning method to reduce theimpact of false positives. Unlike most existing methods that rely predominantlyon fully supervised learning, our approach leverages the advantages ofself-supervised learning in conjunction with employing the available labeleddata. We evaluate our method on the BreakHis dataset, which consists of breastcancer histopathology images, and demonstrate an increase in classificationaccuracy by 1.45% at the image level and 1.42% at the patient level compared tothe state-of-the-art method. This improvement corresponds to 93.63% absoluteaccuracy, highlighting our approach's effectiveness in leveraging dataproperties to learn more appropriate representation space.</description><author>Matina Mahdizadeh Sani, Ali Royat, Mahdieh Soleymani Baghshah</author><pubDate>Mon, 06 May 2024 18:06:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03642v1</guid></item><item><title>Uncertainty Quantification in Multivariable Regression for Material Property Prediction with Bayesian Neural Networks</title><link>http://arxiv.org/abs/2311.02495v3</link><description>With the increased use of data-driven approaches and machine learning-basedmethods in material science, the importance of reliable uncertaintyquantification (UQ) of the predicted variables for informed decision-makingcannot be overstated. UQ in material property prediction poses uniquechallenges, including the multi-scale and multi-physics nature of advancedmaterials, intricate interactions between numerous factors, limitedavailability of large curated datasets for model training, etc. Recently,Bayesian Neural Networks (BNNs) have emerged as a promising approach for UQ,offering a probabilistic framework for capturing uncertainties within neuralnetworks. In this work, we introduce an approach for UQ within physics-informedBNNs, which integrates knowledge from governing laws in material modeling toguide the models toward physically consistent predictions. To evaluate theeffectiveness of this approach, we present case studies for predicting thecreep rupture life of steel alloys. Experimental validation with three datasetsof collected measurements from creep tests demonstrates the ability of BNNs toproduce accurate point and uncertainty estimates that are competitive or exceedthe performance of the conventional method of Gaussian Process Regression.Similarly, we evaluated the suitability of BNNs for UQ in an active learningapplication and reported competitive performance. The most promising frameworkfor creep life prediction is BNNs based on Markov Chain Monte Carloapproximation of the posterior distribution of network parameters, as itprovided more reliable results in comparison to BNNs based on variationalinference approximation or related NNs with probabilistic outputs. The codesare available at:https://github.com/avakanski/Creep-uncertainty-quantification.</description><author>Longze Li, Jiang Chang, Aleksandar Vakanski, Yachun Wang, Tiankai Yao, Min Xian</author><pubDate>Mon, 06 May 2024 18:00:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02495v3</guid></item><item><title>From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction</title><link>http://arxiv.org/abs/2310.16802v2</link><description>Foundation models have been transformational in machine learning fields suchas natural language processing and computer vision. Similar success in atomicproperty prediction has been limited due to the challenges of trainingeffective models across multiple chemical domains. To address this, weintroduce Joint Multi-domain Pre-training (JMP), a supervised pre-trainingstrategy that simultaneously trains on multiple datasets from differentchemical domains, treating each dataset as a unique pre-training task within amulti-task framework. Our combined training dataset consists of $\sim$120Msystems from OC20, OC22, ANI-1x, and Transition-1x. We evaluate performance andgeneralization by fine-tuning over a diverse set of downstream tasks anddatasets including: QM9, rMD17, MatBench, QMOF, SPICE, and MD22. JMPdemonstrates an average improvement of 59% over training from scratch, andmatches or sets state-of-the-art on 34 out of 40 tasks. Our work highlights thepotential of pre-training strategies that utilize diverse data to advanceproperty prediction across chemical domains, especially for low-data tasks.Please visit https://nima.sh/jmp for further information.</description><author>Nima Shoghi, Adeesh Kolluru, John R. Kitchin, Zachary W. Ulissi, C. Lawrence Zitnick, Brandon M. Wood</author><pubDate>Mon, 06 May 2024 17:57:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.16802v2</guid></item><item><title>Collage: Light-Weight Low-Precision Strategy for LLM Training</title><link>http://arxiv.org/abs/2405.03637v1</link><description>Large models training is plagued by the intense compute cost and limitedhardware memory. A practical solution is low-precision representation but istroubled by loss in numerical accuracy and unstable training rendering themodel less useful. We argue that low-precision floating points can perform wellprovided the error is properly compensated at the critical locations in thetraining process. We propose Collage which utilizes multi-component floatrepresentation in low-precision to accurately perform operations with numericalerrors accounted. To understand the impact of imprecision to training, wepropose a simple and novel metric which tracks the lost information duringtraining as well as differentiates various precision strategies. Our methodworks with commonly used low-precision such as half-precision ($16$-bitfloating points) and can be naturally extended to work with even lowerprecision such as $8$-bit. Experimental results show that pre-training usingCollage removes the requirement of using $32$-bit floating-point copies of themodel and attains similar/better training performance compared to $(16,32)$-bit mixed-precision strategy, with up to $3.7\times$ speedup and $\sim15\%$ to $23\%$ less memory usage in practice.</description><author>Tao Yu, Gaurav Gupta, Karthick Gopalswamy, Amith Mamidala, Hao Zhou, Jeffrey Huynh, Youngsuk Park, Ron Diamant, Anoop Deoras, Luke Huan</author><pubDate>Mon, 06 May 2024 17:55:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03637v1</guid></item><item><title>Federated Learning Privacy: Attacks, Defenses, Applications, and Policy Landscape - A Survey</title><link>http://arxiv.org/abs/2405.03636v1</link><description>Deep learning has shown incredible potential across a vast array of tasks andaccompanying this growth has been an insatiable appetite for data. However, alarge amount of data needed for enabling deep learning is stored on personaldevices and recent concerns on privacy have further highlighted challenges foraccessing such data. As a result, federated learning (FL) has emerged as animportant privacy-preserving technology enabling collaborative training ofmachine learning models without the need to send the raw, potentiallysensitive, data to a central server. However, the fundamental premise thatsending model updates to a server is privacy-preserving only holds if theupdates cannot be "reverse engineered" to infer information about the privatetraining data. It has been shown under a wide variety of settings that thispremise for privacy does {\em not} hold. In this survey paper, we provide a comprehensive literature review of thedifferent privacy attacks and defense methods in FL. We identify the currentlimitations of these attacks and highlight the settings in which FL clientprivacy can be broken. We dissect some of the successful industry applicationsof FL and draw lessons for future successful adoption. We survey the emerginglandscape of privacy regulation for FL. We conclude with future directions fortaking FL toward the cherished goal of generating accurate models whilepreserving the privacy of the data from its participants.</description><author>Joshua C. Zhao, Saurabh Bagchi, Salman Avestimehr, Kevin S. Chan, Somali Chaterji, Dimitris Dimitriadis, Jiacheng Li, Ninghui Li, Arash Nourian, Holger R. Roth</author><pubDate>Mon, 06 May 2024 17:55:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03636v1</guid></item><item><title>An algorithm for forensic toolmark comparisons</title><link>http://arxiv.org/abs/2312.00032v2</link><description>Forensic toolmark analysis traditionally relies on subjective human judgment,leading to inconsistencies and inaccuracies. The multitude of variables,including angles and directions of mark generation, further complicatescomparisons. To address this, we introduce a novel approach leveraging 3D datacapturing toolmarks from various angles and directions. Through algorithmictraining, we objectively compare toolmark signals, revealing clustering by toolrather than angle or direction. Our method utilizes similarity matrices anddensity plots to establish thresholds for classification, enabling thederivation of likelihood ratios for new mark pairs. With a cross-validatedsensitivity of 98% and specificity of 96%, our approach enhances thereliability of toolmark analysis. While its applicability to diverse tools andfactors warrants further exploration, this empirically trained, open-sourcesolution offers forensic examiners a standardized means to objectively comparetoolmarks, potentially curbing miscarriages of justice in the legal system.</description><author>Maria Cuellar, Sheng Gao, Heike Hofmann</author><pubDate>Mon, 06 May 2024 17:51:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00032v2</guid></item><item><title>Neural Graph Mapping for Dense SLAM with Efficient Loop Closure</title><link>http://arxiv.org/abs/2405.03633v1</link><description>Existing neural field-based SLAM methods typically employ a single monolithicfield as their scene representation. This prevents efficient incorporation ofloop closure constraints and limits scalability. To address these shortcomings,we propose a neural mapping framework which anchors lightweight neural fieldsto the pose graph of a sparse visual SLAM system. Our approach shows theability to integrate large-scale loop closures, while limiting necessaryreintegration. Furthermore, we verify the scalability of our approach bydemonstrating successful building-scale mapping taking multiple loop closuresinto account during the optimization, and show that our method outperformsexisting state-of-the-art approaches on large scenes in terms of quality andruntime. Our code is available athttps://kth-rpl.github.io/neural_graph_mapping/.</description><author>Leonard Bruns, Jun Zhang, Patric Jensfelt</author><pubDate>Mon, 06 May 2024 17:50:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03633v1</guid></item><item><title>A Linear Time and Space Local Point Cloud Geometry Encoder via Vectorized Kernel Mixture (VecKM)</title><link>http://arxiv.org/abs/2404.01568v2</link><description>We propose VecKM, a local point cloud geometry encoder that is descriptiveand efficient to compute. VecKM leverages a unique approach by vectorizing akernel mixture to represent the local point cloud. Such representation'sdescriptiveness is supported by two theorems that validate its ability toreconstruct and preserve the similarity of the local shape. Unlike existingencoders downsampling the local point cloud, VecKM constructs the localgeometry encoding using all neighboring points, producing a more descriptiveencoding. Moreover, VecKM is efficient to compute and scalable to large point cloudinputs: VecKM reduces the memory cost from $(n^2+nKd)$ to $(nd+np)$; andreduces the major runtime cost from computing $nK$ MLPs to $n$ MLPs, where $n$is the size of the point cloud, $K$ is the neighborhood size, $d$ is theencoding dimension, and $p$ is a marginal factor. The efficiency is due toVecKM's unique factorizable property that eliminates the need of explicitlygrouping points into neighbors. In the normal estimation task, VecKM demonstrates not only 100x fasterinference speed but also highest accuracy and strongest robustness. Inclassification and segmentation tasks, integrating VecKM as a preprocessingmodule achieves consistently better performance than the PointNet, PointNet++,and point transformer baselines, and runs consistently faster by up to 10times.</description><author>Dehao Yuan, Cornelia Fermüller, Tahseen Rabbani, Furong Huang, Yiannis Aloimonos</author><pubDate>Mon, 06 May 2024 17:49:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01568v2</guid></item><item><title>Early years of Biased Random-Key Genetic Algorithms: A systematic review</title><link>http://arxiv.org/abs/2405.01765v2</link><description>This paper presents a systematic literature review and bibliometric analysisfocusing on Biased Random-Key Genetic Algorithms (BRKGA). BRKGA is ametaheuristic framework that uses random-key-based chromosomes with biased,uniform, and elitist mating strategies alongside a genetic algorithm. Thisreview encompasses around~250 papers, covering a diverse array of applicationsranging from classical combinatorial optimization problems to real-worldindustrial scenarios, and even non-traditional applications like hyperparametertuning in machine learning and scenario generation for two-stage problems. Insummary, this study offers a comprehensive examination of the BRKGAmetaheuristic and its various applications, shedding light on key areas forfuture research.</description><author>Mariana A. Londe, Luciana S. Pessoa, Cartlos E. Andrade, Mauricio G. C. Resende</author><pubDate>Mon, 06 May 2024 17:46:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01765v2</guid></item><item><title>$ε$-Policy Gradient for Online Pricing</title><link>http://arxiv.org/abs/2405.03624v1</link><description>Combining model-based and model-free reinforcement learning approaches, thispaper proposes and analyzes an $\epsilon$-policy gradient algorithm for theonline pricing learning task. The algorithm extends $\epsilon$-greedy algorithmby replacing greedy exploitation with gradient descent step and facilitateslearning via model inference. We optimize the regret of the proposed algorithmby quantifying the exploration cost in terms of the exploration probability$\epsilon$ and the exploitation cost in terms of the gradient descentoptimization and gradient estimation errors. The algorithm achieves an expectedregret of order $\mathcal{O}(\sqrt{T})$ (up to a logarithmic factor) over $T$trials.</description><author>Lukasz Szpruch, Tanut Treetanthiploet, Yufei Zhang</author><pubDate>Mon, 06 May 2024 17:41:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03624v1</guid></item><item><title>Detecting Android Malware: From Neural Embeddings to Hands-On Validation with BERTroid</title><link>http://arxiv.org/abs/2405.03620v1</link><description>As cyber threats and malware attacks increasingly alarm both individuals andbusinesses, the urgency for proactive malware countermeasures intensifies. Thishas driven a rising interest in automated machine learning solutions.Transformers, a cutting-edge category of attention-based deep learning methods,have demonstrated remarkable success. In this paper, we present BERTroid, aninnovative malware detection model built on the BERT architecture. Overall,BERTroid emerged as a promising solution for combating Android malware. Itsability to outperform state-of-the-art solutions demonstrates its potential asa proactive defense mechanism against malicious software attacks. Additionally,we evaluate BERTroid on multiple datasets to assess its performance acrossdiverse scenarios. In the dynamic landscape of cybersecurity, our approach hasdemonstrated promising resilience against the rapid evolution of malware onAndroid systems. While the machine learning model captures broad patterns, weemphasize the role of manual validation for deeper comprehension and insightinto these behaviors. This human intervention is critical for discerningintricate and context-specific behaviors, thereby validating and reinforcingthe model's findings.</description><author>Meryam Chaieb, Mostafa Anouar Ghorab, Mohamed Aymen Saied</author><pubDate>Mon, 06 May 2024 17:35:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03620v1</guid></item><item><title>CoVid-19 Detection leveraging Vision Transformers and Explainable AI</title><link>http://arxiv.org/abs/2307.16033v2</link><description>Lung disease is a common health problem in many parts of the world. It is asignificant risk to people health and quality of life all across the globesince it is responsible for five of the top thirty leading causes of death.Among them are COVID 19, pneumonia, and tuberculosis, to name just a few. It iscritical to diagnose lung diseases in their early stages. Several differentmodels including machine learning and image processing have been developed forthis purpose. The earlier a condition is diagnosed, the better the patientchances of making a full recovery and surviving into the long term. Thanks todeep learning algorithms, there is significant promise for the autonomous,rapid, and accurate identification of lung diseases based on medical imaging.Several different deep learning strategies, including convolutional neuralnetworks (CNN), vanilla neural networks, visual geometry group based networks(VGG), and capsule networks , are used for the goal of making lung diseaseforecasts. The standard CNN has a poor performance when dealing with rotated,tilted, or other aberrant picture orientations. As a result of this, within thescope of this study, we have suggested a vision transformer based approach endto end framework for the diagnosis of lung disorders. In the architecture, dataaugmentation, training of the suggested models, and evaluation of the modelsare all included. For the purpose of detecting lung diseases such as pneumonia,Covid 19, lung opacity, and others, a specialised Compact ConvolutionTransformers (CCT) model have been tested and evaluated on datasets such as theCovid 19 Radiography Database. The model has achieved a better accuracy forboth its training and validation purposes on the Covid 19 Radiography Database.</description><author>Pangoth Santhosh Kumar, Kundrapu Supriya, Mallikharjuna Rao K, Taraka Satya Krishna Teja Malisetti</author><pubDate>Mon, 06 May 2024 17:32:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.16033v2</guid></item><item><title>A Controlled Experiment on the Energy Efficiency of the Source Code Generated by Code Llama</title><link>http://arxiv.org/abs/2405.03616v1</link><description>Context. Nowadays, 83% of software developers use Large Language Models(LLMs) to generate code. LLMs recently became essential to increase theproductivity of software developers and decrease the time and cost of softwaredevelopment. Developers ranging from novices to experts use LLM tools not onlyto detect and patch bugs, but also to integrate generated code into theirsoftware. However, as of today there is no objective assessment of the energyefficiency of the source code generated by LLM tools. Released in August 2023,Code Llama is one of the most recent LLM tools. Goal. In this paper, we present an empirical study that assesses the energyefficiency of Code Llama with respect to human-written source code. Method. We design an experiment involving three human-written benchmarksimplemented in C++, JavaScript, and Python. We ask Code Llama to generate thecode of the benchmarks using different prompts and temperatures. Therefore, weexecute both implementations and profile their energy efficiency. Results. Our study shows that the energy efficiency of code generated by CodeLlama is heavily-dependent on the chosen programming language and the specificcode problem at hand. Also, human implementations tend to be more energyefficient overall, with generated JavaScript code outperforming its humancounterpart. Moreover, explicitly asking Code Llama to generateenergy-efficient code results in an equal or worse energy efficiency, as wellas using different temperatures seems not to affect the energy efficiency ofgenerated code. Conclusions. According to our results, code generated using Code Llama doesnot guarantee energy efficiency, even when prompted to do so. Therefore,software developers should evaluate the energy efficiency of generated codebefore integrating it into the software system under development.</description><author>Vlad-Andrei Cursaru, Laura Duits, Joel Milligan, Damla Ural, Berta Rodriguez Sanchez, Vincenzo Stoico, Ivano Malavolta</author><pubDate>Mon, 06 May 2024 17:32:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03616v1</guid></item><item><title>Nonnegative Matrix Factorization in Dimensionality Reduction: A Survey</title><link>http://arxiv.org/abs/2405.03615v1</link><description>Dimensionality Reduction plays a pivotal role in improving feature learningaccuracy and reducing training time by eliminating redundant features, noise,and irrelevant data. Nonnegative Matrix Factorization (NMF) has emerged as apopular and powerful method for dimensionality reduction. Despite its extensiveuse, there remains a need for a comprehensive analysis of NMF in the context ofdimensionality reduction. To address this gap, this paper presents acomprehensive survey of NMF, focusing on its applications in both featureextraction and feature selection. We introduce a classification ofdimensionality reduction, enhancing understanding of the underlying concepts.Subsequently, we delve into a thorough summary of diverse NMF approaches usedfor feature extraction and selection. Furthermore, we discuss the latestresearch trends and potential future directions of NMF in dimensionalityreduction, aiming to highlight areas that need further exploration anddevelopment.</description><author>Farid Saberi-Movahed, Kamal Berahman, Razieh Sheikhpour, Yuefeng Li, Shirui Pan</author><pubDate>Mon, 06 May 2024 17:32:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03615v1</guid></item><item><title>Dual Relation Mining Network for Zero-Shot Learning</title><link>http://arxiv.org/abs/2405.03613v1</link><description>Zero-shot learning (ZSL) aims to recognize novel classes through transferringshared semantic knowledge (e.g., attributes) from seen classes to unseenclasses. Recently, attention-based methods have exhibited significant progresswhich align visual features and attributes via a spatial attention mechanism.However, these methods only explore visual-semantic relationship in the spatialdimension, which can lead to classification ambiguity when different attributesshare similar attention regions, and semantic relationship between attributesis rarely discussed. To alleviate the above problems, we propose a DualRelation Mining Network (DRMN) to enable more effective visual-semanticinteractions and learn semantic relationship among attributes for knowledgetransfer. Specifically, we introduce a Dual Attention Block (DAB) forvisual-semantic relationship mining, which enriches visual information bymulti-level feature fusion and conducts spatial attention for visual tosemantic embedding. Moreover, an attribute-guided channel attention is utilizedto decouple entangled semantic features. For semantic relationship modeling, weutilize a Semantic Interaction Transformer (SIT) to enhance the generalizationof attribute representations among images. Additionally, a globalclassification branch is introduced as a complement to human-defined semanticattributes, and we then combine the results with attribute-basedclassification. Extensive experiments demonstrate that the proposed DRMN leadsto new state-of-the-art performances on three standard ZSL benchmarks, i.e.,CUB, SUN, and AwA2.</description><author>Jinwei Han, Yingguo Gao, Zhiwen Lin, Ke Yan, Shouhong Ding, Yuan Gao, Gui-Song Xia</author><pubDate>Mon, 06 May 2024 17:31:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03613v1</guid></item><item><title>Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods</title><link>http://arxiv.org/abs/2310.02671v2</link><description>Markov Decision Processes (MDPs) are a formal framework for modeling andsolving sequential decision-making problems. In finite-time horizons suchproblems are relevant for instance for optimal stopping or specific supplychain problems, but also in the training of large language models. In contrastto infinite horizon MDPs optimal policies are not stationary, policies must belearned for every single epoch. In practice all parameters are often trainedsimultaneously, ignoring the inherent structure suggested by dynamicprogramming. This paper introduces a combination of dynamic programming andpolicy gradient called dynamic policy gradient, where the parameters aretrained backwards in time. For the tabular softmax parametrisation we carry outthe convergence analysis for simultaneous and dynamic policy gradient towardsglobal optima, both in the exact and sampled gradient settings withoutregularisation. It turns out that the use of dynamic policy gradient trainingmuch better exploits the structure of finite- time problems which is reflectedin improved convergence bounds.</description><author>Sara Klein, Simon Weissmann, Leif Döring</author><pubDate>Mon, 06 May 2024 17:29:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02671v2</guid></item><item><title>MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation</title><link>http://arxiv.org/abs/2404.11565v2</link><description>We introduce a new architecture for personalization of text-to-imagediffusion models, coined Mixture-of-Attention (MoA). Inspired by theMixture-of-Experts mechanism utilized in large language models (LLMs), MoAdistributes the generation workload between two attention pathways: apersonalized branch and a non-personalized prior branch. MoA is designed toretain the original model's prior by fixing its attention layers in the priorbranch, while minimally intervening in the generation process with thepersonalized branch that learns to embed subjects in the layout and contextgenerated by the prior branch. A novel routing mechanism manages thedistribution of pixels in each layer across these branches to optimize theblend of personalized and generic content creation. Once trained, MoAfacilitates the creation of high-quality, personalized images featuringmultiple subjects with compositions and interactions as diverse as thosegenerated by the original model. Crucially, MoA enhances the distinctionbetween the model's pre-existing capability and the newly augmentedpersonalized intervention, thereby offering a more disentangled subject-contextcontrol that was previously unattainable. Project page:https://snap-research.github.io/mixture-of-attention</description><author>Kuan-Chieh Wang, Daniil Ostashev, Yuwei Fang, Sergey Tulyakov, Kfir Aberman</author><pubDate>Mon, 06 May 2024 17:29:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.11565v2</guid></item><item><title>GPLaSDI: Gaussian Process-based Interpretable Latent Space Dynamics Identification through Deep Autoencoder</title><link>http://arxiv.org/abs/2308.05882v2</link><description>Numerically solving partial differential equations (PDEs) can be challengingand computationally expensive. This has led to the development of reduced-ordermodels (ROMs) that are accurate but faster than full order models (FOMs).Recently, machine learning advances have enabled the creation of non-linearprojection methods, such as Latent Space Dynamics Identification (LaSDI). LaSDImaps full-order PDE solutions to a latent space using autoencoders and learnsthe system of ODEs governing the latent space dynamics. By interpolating andsolving the ODE system in the reduced latent space, fast and accurate ROMpredictions can be made by feeding the predicted latent space dynamics into thedecoder. In this paper, we introduce GPLaSDI, a novel LaSDI-based frameworkthat relies on Gaussian process (GP) for latent space ODE interpolations. UsingGPs offers two significant advantages. First, it enables the quantification ofuncertainty over the ROM predictions. Second, leveraging this predictionuncertainty allows for efficient adaptive training through a greedy selectionof additional training data points. This approach does not require priorknowledge of the underlying PDEs. Consequently, GPLaSDI is inherentlynon-intrusive and can be applied to problems without a known PDE or itsresidual. We demonstrate the effectiveness of our approach on the Burgersequation, Vlasov equation for plasma physics, and a rising thermal bubbleproblem. Our proposed method achieves between 200 and 100,000 times speed-up,with up to 7% relative error.</description><author>Christophe Bonneville, Youngsoo Choi, Debojyoti Ghosh, Jonathan L. Belof</author><pubDate>Mon, 06 May 2024 17:25:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05882v2</guid></item><item><title>ShadowNav: Autonomous Global Localization for Lunar Navigation in Darkness</title><link>http://arxiv.org/abs/2405.01673v2</link><description>The ability to determine the pose of a rover in an inertial frameautonomously is a crucial capability necessary for the next generation ofsurface rover missions on other planetary bodies. Currently, most on-goingrover missions utilize ground-in-the-loop interventions to manually correct fordrift in the pose estimate and this human supervision bottlenecks the distanceover which rovers can operate autonomously and carry out scientificmeasurements. In this paper, we present ShadowNav, an autonomous approach forglobal localization on the Moon with an emphasis on driving in darkness and atnighttime. Our approach uses the leading edge of Lunar craters as landmarks anda particle filtering approach is used to associate detected craters with knownones on an offboard map. We discuss the key design decisions in developing theShadowNav framework for use with a Lunar rover concept equipped with a stereocamera and an external illumination source. Finally, we demonstrate theefficacy of our proposed approach in both a Lunar simulation environment and ondata collected during a field test at Cinder Lakes, Arizona.</description><author>Deegan Atha, R. Michael Swan, Abhishek Cauligi, Anne Bettens, Edwin Goh, Dima Kogan, Larry Matthies, Masahiro Ono</author><pubDate>Mon, 06 May 2024 17:24:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01673v2</guid></item><item><title>Efficient and Near-Optimal Noise Generation for Streaming Differential Privacy</title><link>http://arxiv.org/abs/2404.16706v3</link><description>In the task of differentially private (DP) continual counting, we receive astream of increments and our goal is to output an approximate running total ofthese increments, without revealing too much about any specific increment.Despite its simplicity, differentially private continual counting has attractedsignificant attention both in theory and in practice. Existing algorithms fordifferentially private continual counting are either inefficient in terms oftheir space usage or add an excessive amount of noise, inducing suboptimalutility. The most practical DP continual counting algorithms add carefully correlatedGaussian noise to the values. The task of choosing the covariance for thisnoise can be expressed in terms of factoring the lower-triangular matrix ofones (which computes prefix sums). We present two approaches from this class(for different parameter regimes) that achieve near-optimal utility for DPcontinual counting and only require logarithmic or polylogarithmic space (andtime). Our first approach is based on a space-efficient streaming matrixmultiplication algorithm for a class of Toeplitz matrices. We show that toinstantiate this algorithm for DP continual counting, it is sufficient to finda low-degree rational function that approximates the square root on a circle inthe complex plane. We then apply and extend tools from approximation theory toachieve this. We also derive efficient closed-forms for the objective functionfor arbitrarily many steps, and show direct numerical optimization yields ahighly practical solution to the problem. Our second approach combines ourfirst approach with a recursive construction similar to the binary treemechanism.</description><author>Krishnamurthy Dvijotham, H. Brendan McMahan, Krishna Pillutla, Thomas Steinke, Abhradeep Thakurta</author><pubDate>Mon, 06 May 2024 17:19:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.16706v3</guid></item><item><title>CORP: A Multi-Modal Dataset for Campus-Oriented Roadside Perception Tasks</title><link>http://arxiv.org/abs/2404.03191v2</link><description>Numerous roadside perception datasets have been introduced to propeladvancements in autonomous driving and intelligent transportation systemsresearch and development. However, it has been observed that the majority oftheir concentrates is on urban arterial roads, inadvertently overlookingresidential areas such as parks and campuses that exhibit entirely distinctcharacteristics. In light of this gap, we propose CORP, which stands as thefirst public benchmark dataset tailored for multi-modal roadside perceptiontasks under campus scenarios. Collected in a university campus, CORP consistsof over 205k images plus 102k point clouds captured from 18 cameras and 9 LiDARsensors. These sensors with different configurations are mounted on roadsideutility poles to provide diverse viewpoints within the campus region. Theannotations of CORP encompass multi-dimensional information beyond 2D and 3Dbounding boxes, providing extra support for 3D seamless tracking and instancesegmentation with unique IDs and pixel masks for identifying targets, toenhance the understanding of objects and their behaviors distributed across thecampus premises. Unlike other roadside datasets about urban traffic, CORPextends the spectrum to highlight the challenges for multi-modal perception incampuses and other residential areas.</description><author>Beibei Wang, Shuang Meng, Lu Zhang, Chenjie Wang, Jingjing Huang, Yao Li, Haojie Ren, Yuxuan Xiao, Yuru Peng, Jianmin Ji, Yu Zhang, Yanyong Zhang</author><pubDate>Mon, 06 May 2024 17:18:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03191v2</guid></item><item><title>Trackable Island-model Genetic Algorithms at Wafer Scale</title><link>http://arxiv.org/abs/2405.03605v1</link><description>Emerging ML/AI hardware accelerators, like the 850,000 processor CerebrasWafer-Scale Engine (WSE), hold great promise to scale up the capabilities ofevolutionary computation. However, challenges remain in maintaining visibilityinto underlying evolutionary processes while efficiently utilizing theseplatforms' large processor counts. Here, we focus on the problem of extractingphylogenetic information from digital evolution on the WSE platform. We presenta tracking-enabled asynchronous island-based genetic algorithm (GA) frameworkfor WSE hardware. Emulated and on-hardware GA benchmarks with a simpletracking-enabled agent model clock upwards of 1 million generations a minutefor population sizes reaching 16 million. This pace enables quadrillions ofevaluations a day. We validate phylogenetic reconstructions from these trialsand demonstrate their suitability for inference of underlying evolutionaryconditions. In particular, we demonstrate extraction of clear phylometricsignals that differentiate wafer-scale runs with adaptive dynamics enabledversus disabled. Together, these benchmark and validation trials reflect strongpotential for highly scalable evolutionary computation that is both efficientand observable. Kernel code implementing the island-model GA supports drop-incustomization to support any fixed-length genome content and fitness criteria,allowing it to be leveraged to advance research interests across the community.</description><author>Matthew Andres Moreno, Connor Yang, Emily Dolson, Luis Zaman</author><pubDate>Mon, 06 May 2024 17:17:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03605v1</guid></item><item><title>DiffCLIP: Leveraging Stable Diffusion for Language Grounded 3D Classification</title><link>http://arxiv.org/abs/2305.15957v3</link><description>Large pre-trained models have had a significant impact on computer vision byenabling multi-modal learning, where the CLIP model has achieved impressiveresults in image classification, object detection, and semantic segmentation.However, the model's performance on 3D point cloud processing tasks is limiteddue to the domain gap between depth maps from 3D projection and training imagesof CLIP. This paper proposes DiffCLIP, a new pre-training framework thatincorporates stable diffusion with ControlNet to minimize the domain gap in thevisual branch. Additionally, a style-prompt generation module is introduced forfew-shot tasks in the textual branch. Extensive experiments on the ModelNet10,ModelNet40, and ScanObjectNN datasets show that DiffCLIP has strong abilitiesfor 3D understanding. By using stable diffusion and style-prompt generation,DiffCLIP achieves an accuracy of 43.2\% for zero-shot classification on OBJ\_BGof ScanObjectNN, which is state-of-the-art performance, and an accuracy of80.6\% for zero-shot classification on ModelNet10, which is comparable tostate-of-the-art performance.</description><author>Sitian Shen, Zilin Zhu, Linqian Fan, Harry Zhang, Xinxiao Wu</author><pubDate>Mon, 06 May 2024 17:15:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15957v3</guid></item><item><title>"Ask Me Anything": How Comcast Uses LLMs to Assist Agents in Real Time</title><link>http://arxiv.org/abs/2405.00801v2</link><description>Customer service is how companies interface with their customers. It cancontribute heavily towards the overall customer satisfaction. However,high-quality service can become expensive, creating an incentive to make it ascost efficient as possible and prompting most companies to utilize AI-poweredassistants, or "chat bots". On the other hand, human-to-human interaction isstill desired by customers, especially when it comes to complex scenarios suchas disputes and sensitive topics like bill payment. This raises the bar for customer service agents. They need to accuratelyunderstand the customer's question or concern, identify a solution that isacceptable yet feasible (and within the company's policy), all while handlingmultiple conversations at once. In this work, we introduce "Ask Me Anything" (AMA) as an add-on feature to anagent-facing customer service interface. AMA allows agents to ask questions toa large language model (LLM) on demand, as they are handling customerconversations -- the LLM provides accurate responses in real-time, reducing theamount of context switching the agent needs. In our internal experiments, wefind that agents using AMA versus a traditional search experience spendapproximately 10% fewer seconds per conversation containing a search,translating to millions of dollars of savings annually. Agents that used theAMA feature provided positive feedback nearly 80% of the time, demonstratingits usefulness as an AI-assisted feature for customer care.</description><author>Scott Rome, Tianwen Chen, Raphael Tang, Luwei Zhou, Ferhan Ture</author><pubDate>Mon, 06 May 2024 17:15:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00801v2</guid></item><item><title>SCULPT: Shape-Conditioned Unpaired Learning of Pose-dependent Clothed and Textured Human Meshes</title><link>http://arxiv.org/abs/2308.10638v2</link><description>We present SCULPT, a novel 3D generative model for clothed and textured 3Dmeshes of humans. Specifically, we devise a deep neural network that learns torepresent the geometry and appearance distribution of clothed human bodies.Training such a model is challenging, as datasets of textured 3D meshes forhumans are limited in size and accessibility. Our key observation is that thereexist medium-sized 3D scan datasets like CAPE, as well as large-scale 2D imagedatasets of clothed humans and multiple appearances can be mapped to a singlegeometry. To effectively learn from the two data modalities, we propose anunpaired learning procedure for pose-dependent clothed and textured humanmeshes. Specifically, we learn a pose-dependent geometry space from 3D scandata. We represent this as per vertex displacements w.r.t. the SMPL model.Next, we train a geometry conditioned texture generator in an unsupervised wayusing the 2D image data. We use intermediate activations of the learnedgeometry model to condition our texture generator. To alleviate entanglementbetween pose and clothing type, and pose and clothing appearance, we conditionboth the texture and geometry generators with attribute labels such as clothingtypes for the geometry, and clothing colors for the texture generator. Weautomatically generated these conditioning labels for the 2D images based onthe visual question answering model BLIP and CLIP. We validate our method onthe SCULPT dataset, and compare to state-of-the-art 3D generative models forclothed human bodies. Our code and data can be found athttps://sculpt.is.tue.mpg.de.</description><author>Soubhik Sanyal, Partha Ghosh, Jinlong Yang, Michael J. Black, Justus Thies, Timo Bolkart</author><pubDate>Mon, 06 May 2024 17:14:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10638v2</guid></item><item><title>Ordinal Classification with Distance Regularization for Robust Brain Age Prediction</title><link>http://arxiv.org/abs/2403.10522v2</link><description>Age is one of the major known risk factors for Alzheimer's Disease (AD).Detecting AD early is crucial for effective treatment and preventingirreversible brain damage. Brain age, a measure derived from brain imagingreflecting structural changes due to aging, may have the potential to identifyAD onset, assess disease risk, and plan targeted interventions. Deeplearning-based regression techniques to predict brain age from magneticresonance imaging (MRI) scans have shown great accuracy recently. However,these methods are subject to an inherent regression to the mean effect, whichcauses a systematic bias resulting in an overestimation of brain age in youngsubjects and underestimation in old subjects. This weakens the reliability ofpredicted brain age as a valid biomarker for downstream clinical applications.Here, we reformulate the brain age prediction task from regression toclassification to address the issue of systematic bias. Recognizing theimportance of preserving ordinal information from ages to understand agingtrajectory and monitor aging longitudinally, we propose a novel ORdinalDistance Encoded Regularization (ORDER) loss that incorporates the order of agelabels, enhancing the model's ability to capture age-related patterns.Extensive experiments and ablation studies demonstrate that this frameworkreduces systematic bias, outperforms state-of-art methods by statisticallysignificant margins, and can better capture subtle differences between clinicalgroups in an independent AD dataset. Our implementation is publicly availableat https://github.com/jaygshah/Robust-Brain-Age-Prediction.</description><author>Jay Shah, Md Mahfuzur Rahman Siddiquee, Yi Su, Teresa Wu, Baoxin Li</author><pubDate>Mon, 06 May 2024 17:13:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.10522v2</guid></item><item><title>GREEN: Generative Radiology Report Evaluation and Error Notation</title><link>http://arxiv.org/abs/2405.03595v1</link><description>Evaluating radiology reports is a challenging problem as factual correctnessis extremely important due to the need for accurate medical communication aboutmedical images. Existing automatic evaluation metrics either suffer fromfailing to consider factual correctness (e.g., BLEU and ROUGE) or are limitedin their interpretability (e.g., F1CheXpert and F1RadGraph). In this paper, weintroduce GREEN (Generative Radiology Report Evaluation and Error Notation), aradiology report generation metric that leverages the natural languageunderstanding of language models to identify and explain clinically significanterrors in candidate reports, both quantitatively and qualitatively. Compared tocurrent metrics, GREEN offers: 1) a score aligned with expert preferences, 2)human interpretable explanations of clinically significant errors, enablingfeedback loops with end-users, and 3) a lightweight open-source method thatreaches the performance of commercial counterparts. We validate our GREENmetric by comparing it to GPT-4, as well as to error counts of 6 experts andpreferences of 2 experts. Our method demonstrates not only higher correlationwith expert error counts, but simultaneously higher alignment with expertpreferences when compared to previous approaches."</description><author>Sophie Ostmeier, Justin Xu, Zhihong Chen, Maya Varma, Louis Blankemeier, Christian Bluethgen, Arne Edward Michalson, Michael Moseley, Curtis Langlotz, Akshay S Chaudhari, Jean-Benoit Delbrouck</author><pubDate>Mon, 06 May 2024 17:04:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03595v1</guid></item><item><title>Enabling High-Sparsity Foundational Llama Models with Efficient Pretraining and Deployment</title><link>http://arxiv.org/abs/2405.03594v1</link><description>Large language models (LLMs) have revolutionized Natural Language Processing(NLP), but their size creates computational bottlenecks. We introduce a novelapproach to create accurate, sparse foundational versions of performant LLMsthat achieve full accuracy recovery for fine-tuning tasks at up to 70%sparsity. We achieve this for the LLaMA-2 7B model by combining the SparseGPTone-shot pruning method and sparse pretraining of those models on a subset ofthe SlimPajama dataset mixed with a Python subset of The Stack dataset. Weexhibit training acceleration due to sparsity on Cerebras CS-3 chips thatclosely matches theoretical scaling. In addition, we establish inferenceacceleration of up to 3x on CPUs by utilizing Neural Magic's DeepSparse engineand 1.7x on GPUs through Neural Magic's nm-vllm engine. The above gains arerealized via sparsity alone, thus enabling further gains through additional useof quantization. Specifically, we show a total speedup on CPUs forsparse-quantized LLaMA models of up to 8.6x. We demonstrate these resultsacross diverse, challenging tasks, including chat, instruction following, codegeneration, arithmetic reasoning, and summarization to prove their generality.This work paves the way for rapidly creating smaller and faster LLMs withoutsacrificing accuracy.</description><author>Abhinav Agarwalla, Abhay Gupta, Alexandre Marques, Shubhra Pandit, Michael Goin, Eldar Kurtic, Kevin Leong, Tuan Nguyen, Mahmoud Salem, Dan Alistarh, Sean Lie, Mark Kurtz</author><pubDate>Mon, 06 May 2024 17:03:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03594v1</guid></item><item><title>SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking</title><link>http://arxiv.org/abs/2306.05426v3</link><description>In many domains, autoregressive models can attain high likelihood on the taskof predicting the next observation. However, this maximum-likelihood (MLE)objective does not necessarily match a downstream use-case of autoregressivelygenerating high-quality sequences. The MLE objective weights sequencesproportionally to their frequency under the data distribution, with no guidancefor the model's behaviour out of distribution (OOD): leading to compoundingerror during autoregressive generation. In order to address this compoundingerror problem, we formulate sequence generation as an imitation learning (IL)problem. This allows us to minimize a variety of divergences between thedistribution of sequences generated by an autoregressive model and sequencesfrom a dataset, including divergences with weight on OOD generated sequences.The IL framework also allows us to incorporate backtracking by introducing abackspace action into the generation process. This further mitigates thecompounding error problem by allowing the model to revert a sampled token if ittakes the sequence OOD. Our resulting method, SequenceMatch, can be implementedwithout adversarial training or architectural changes. We identify theSequenceMatch-$\chi^2$ divergence as a more suitable training objective forautoregressive models which are used for generation. We show that empirically,SequenceMatch training leads to improvements over MLE on text generation withlanguage models and arithmetic.</description><author>Chris Cundy, Stefano Ermon</author><pubDate>Mon, 06 May 2024 17:02:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05426v3</guid></item><item><title>Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion</title><link>http://arxiv.org/abs/2308.12517v3</link><description>Several earlier studies have shown impressive control performance in complexrobotic systems by designing the controller using a neural network and trainingit with model-free reinforcement learning. However, these outstandingcontrollers with natural motion style and high task performance are developedthrough extensive reward engineering, which is a highly laborious andtime-consuming process of designing numerous reward terms and determiningsuitable reward coefficients. In this work, we propose a novel reinforcementlearning framework for training neural network controllers for complex roboticsystems consisting of both rewards and constraints. To let the engineersappropriately reflect their intent to constraints and handle them with minimalcomputation overhead, two constraint types and an efficient policy optimizationalgorithm are suggested. The learning framework is applied to train locomotioncontrollers for several legged robots with different morphology and physicalattributes to traverse challenging terrains. Extensive simulation andreal-world experiments demonstrate that performant controllers can be trainedwith significantly less reward engineering, by tuning only a single rewardcoefficient. Furthermore, a more straightforward and intuitive engineeringprocess can be utilized, thanks to the interpretability and generalizability ofconstraints. The summary video is available at https://youtu.be/KAlm3yskhvM.</description><author>Yunho Kim, Hyunsik Oh, Jeonghyun Lee, Jinhyeok Choi, Gwanghyeon Ji, Moonkyu Jung, Donghoon Youm, Jemin Hwangbo</author><pubDate>Mon, 06 May 2024 17:01:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12517v3</guid></item><item><title>Deep Clustering with Self-Supervision using Pairwise Similarities</title><link>http://arxiv.org/abs/2405.03590v1</link><description>Deep clustering incorporates embedding into clustering to find alower-dimensional space appropriate for clustering. In this paper, we propose anovel deep clustering framework with self-supervision using pairwisesimilarities (DCSS). The proposed method consists of two successive phases. Inthe first phase, we propose to form hypersphere-like groups of similar datapoints, i.e. one hypersphere per cluster, employing an autoencoder that istrained using cluster-specific losses. The hyper-spheres are formed in theautoencoder's latent space. In the second phase, we propose to employ pairwisesimilarities to create a $K$-dimensional space that is capable of accommodatingmore complex cluster distributions, hence providing more accurate clusteringperformance. $K$ is the number of clusters. The autoencoder's latent spaceobtained in the first phase is used as the input of the second phase. Theeffectiveness of both phases is demonstrated on seven benchmark datasets byconducting a rigorous set of experiments.</description><author>Mohammadreza Sadeghi, Narges Armanfard</author><pubDate>Mon, 06 May 2024 17:01:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03590v1</guid></item><item><title>Collaborative Learning for Cyberattack Detection in Blockchain Networks</title><link>http://arxiv.org/abs/2203.11076v4</link><description>This article aims to study intrusion attacks and then develop a novelcyberattack detection framework to detect cyberattacks at the network layer(e.g., Brute Password and Flooding of Transactions) of blockchain networks.Specifically, we first design and implement a blockchain network in ourlaboratory. This blockchain network will serve two purposes, i.e., to generatethe real traffic data (including both normal data and attack data) for ourlearning models and to implement real-time experiments to evaluate theperformance of our proposed intrusion detection framework. To the best of ourknowledge, this is the first dataset that is synthesized in a laboratory forcyberattacks in a blockchain network. We then propose a novel collaborativelearning model that allows efficient deployment in the blockchain network todetect attacks. The main idea of the proposed learning model is to enableblockchain nodes to actively collect data, learn the knowledge from data usingthe Deep Belief Network, and then share the knowledge learned from its datawith other blockchain nodes in the network. In this way, we can not onlyleverage the knowledge from all the nodes in the network but also do not needto gather all raw data for training at a centralized node like conventionalcentralized learning solutions. Such a framework can also avoid the risk ofexposing local data's privacy as well as excessive network overhead/congestion.Both intensive simulations and real-time experiments clearly show that ourproposed intrusion detection framework can achieve an accuracy of up to 98.6%in detecting attacks.</description><author>Tran Viet Khoa, Do Hai Son, Dinh Thai Hoang, Nguyen Linh Trung, Tran Thi Thuy Quynh, Diep N. Nguyen, Nguyen Viet Ha, Eryk Dutkiewicz</author><pubDate>Mon, 06 May 2024 16:58:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.11076v4</guid></item><item><title>Functional Latent Dynamics for Irregularly Sampled Time Series Forecasting</title><link>http://arxiv.org/abs/2405.03582v1</link><description>Irregularly sampled time series with missing values are often observed inmultiple real-world applications such as healthcare, climate and astronomy.They pose a significant challenge to standard deep learn- ing models thatoperate only on fully observed and regularly sampled time series. In order tocapture the continuous dynamics of the irreg- ular time series, many modelsrely on solving an Ordinary Differential Equation (ODE) in the hidden state.These ODE-based models tend to perform slow and require large memory due tosequential operations and a complex ODE solver. As an alternative to complexODE-based mod- els, we propose a family of models called Functional LatentDynamics (FLD). Instead of solving the ODE, we use simple curves which exist atall time points to specify the continuous latent state in the model. Thecoefficients of these curves are learned only from the observed values in thetime series ignoring the missing values. Through extensive experi- ments, wedemonstrate that FLD achieves better performance compared to the best ODE-basedmodel while reducing the runtime and memory overhead. Specifically, FLDrequires an order of magnitude less time to infer the forecasts compared to thebest performing forecasting model.</description><author>Christian Klötergens, Vijaya Krishna Yalavarthi, Maximilian Stubbemann, Lars Schmidt-Thieme</author><pubDate>Mon, 06 May 2024 16:53:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03582v1</guid></item><item><title>Beyond Memorization: Violating Privacy Via Inference with Large Language Models</title><link>http://arxiv.org/abs/2310.07298v2</link><description>Current privacy research on large language models (LLMs) primarily focuses onthe issue of extracting memorized training data. At the same time, models'inference capabilities have increased drastically. This raises the key questionof whether current LLMs could violate individuals' privacy by inferringpersonal attributes from text given at inference time. In this work, we presentthe first comprehensive study on the capabilities of pretrained LLMs to inferpersonal attributes from text. We construct a dataset consisting of real Redditprofiles, and show that current LLMs can infer a wide range of personalattributes (e.g., location, income, sex), achieving up to $85\%$ top-1 and$95\%$ top-3 accuracy at a fraction of the cost ($100\times$) and time($240\times$) required by humans. As people increasingly interact withLLM-powered chatbots across all aspects of life, we also explore the emergingthreat of privacy-invasive chatbots trying to extract personal informationthrough seemingly benign questions. Finally, we show that common mitigations,i.e., text anonymization and model alignment, are currently ineffective atprotecting user privacy against LLM inference. Our findings highlight thatcurrent LLMs can infer personal data at a previously unattainable scale. In theabsence of working defenses, we advocate for a broader discussion around LLMprivacy implications beyond memorization, striving for a wider privacyprotection.</description><author>Robin Staab, Mark Vero, Mislav Balunović, Martin Vechev</author><pubDate>Mon, 06 May 2024 16:52:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07298v2</guid></item><item><title>ILILT: Implicit Learning of Inverse Lithography Technologies</title><link>http://arxiv.org/abs/2405.03574v1</link><description>Lithography, transferring chip design masks to the silicon wafer, is the mostimportant phase in modern semiconductor manufacturing flow. Due to thelimitations of lithography systems, Extensive design optimizations are requiredto tackle the design and silicon mismatch. Inverse lithography technology (ILT)is one of the promising solutions to perform pre-fabrication optimization,termed mask optimization. Because of mask optimization problems' constrainednon-convexity, numerical ILT solvers rely heavily on good initialization toavoid getting stuck on sub-optimal solutions. Machine learning (ML) techniquesare hence proposed to generate mask initialization for ILT solvers withone-shot inference, targeting faster and better convergence during ILT. Thispaper addresses the question of \textit{whether ML models can directly generatehigh-quality optimized masks without engaging ILT solvers in the loop}. Wepropose an implicit learning ILT framework: ILILT, which leverages the implicitlayer learning method and lithography-conditioned inputs to ground the model.Trained to understand the ILT optimization procedure, ILILT can outperform thestate-of-the-art machine learning solutions, significantly improving efficiencyand quality.</description><author>Haoyu Yang, Haoxing Ren</author><pubDate>Mon, 06 May 2024 16:49:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03574v1</guid></item><item><title>Trackable Agent-based Evolution Models at Wafer Scale</title><link>http://arxiv.org/abs/2404.10861v2</link><description>Continuing improvements in computing hardware are poised to transformcapabilities for in silico modeling of cross-scale phenomena underlying majoropen questions in evolutionary biology and artificial life, such as transitionsin individuality, eco-evolutionary dynamics, and rare evolutionary events.Emerging ML/AI-oriented hardware accelerators, like the 850,000 processorCerebras Wafer Scale Engine (WSE), hold particular promise. However, practicalchallenges remain in conducting informative evolution experiments thatefficiently utilize these platforms' large processor counts. Here, we focus onthe problem of extracting phylogenetic information from agent-based evolutionon the WSE platform. This goal drove significant refinements to decentralizedin silico phylogenetic tracking, reported here. These improvements yieldorder-of-magnitude performance improvements. We also present an asynchronousisland-based genetic algorithm (GA) framework for WSE hardware. Emulated andon-hardware GA benchmarks with a simple tracking-enabled agent model clockupwards of 1 million generations a minute for population sizes reaching 16million agents. We validate phylogenetic reconstructions from these trials anddemonstrate their suitability for inference of underlying evolutionaryconditions. In particular, we demonstrate extraction, from wafer-scalesimulation, of clear phylometric signals that differentiate runs with adaptivedynamics enabled versus disabled. Together, these benchmark and validationtrials reflect strong potential for highly scalable agent-based evolutionsimulation that is both efficient and observable. Developed capabilities willbring entirely new classes of previously intractable research questions withinreach, benefiting further explorations within the evolutionary biology andartificial life communities across a variety of emerging high-performancecomputing platforms.</description><author>Matthew Andres Moreno, Connor Yang, Emily Dolson, Luis Zaman</author><pubDate>Mon, 06 May 2024 16:46:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10861v2</guid></item><item><title>FeNNol: an Efficient and Flexible Library for Building Force-field-enhanced Neural Network Potentials</title><link>http://arxiv.org/abs/2405.01491v2</link><description>Neural network interatomic potentials (NNPs) have recently proven to bepowerful tools to accurately model complex molecular systems while bypassingthe high numerical cost of ab-initio molecular dynamics simulations. In recentyears, numerous advances in model architectures as well as the development ofhybrid models combining machine-learning (ML) with more traditional,physically-motivated, force-field interactions have considerably increased thedesign space of ML potentials. In this paper, we present FeNNol, a new libraryfor building, training and running force-field-enhanced neural networkpotentials. It provides a flexible and modular system for building hybridmodels, allowing to easily combine state-of-the-art embeddings withML-parameterized physical interaction terms without the need for explicitprogramming. Furthermore, FeNNol leverages the automatic differentiation andjust-in-time compilation features of the Jax Python library to enable fastevaluation of NNPs, shrinking the performance gap between ML potentials andstandard force-fields. This is demonstrated with the popular ANI-2x modelreaching simulation speeds nearly on par with the AMOEBA polarizableforce-field on commodity GPUs (GPU=Graphics processing unit). We hope thatFeNNol will facilitate the development and application of new hybrid NNParchitectures for a wide range of molecular simulation problems.</description><author>Thomas Plé, Olivier Adjoua, Louis Lagardère, Jean-Philip Piquemal</author><pubDate>Mon, 06 May 2024 16:45:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01491v2</guid></item><item><title>Frozen Transformers in Language Models Are Effective Visual Encoder Layers</title><link>http://arxiv.org/abs/2310.12973v2</link><description>This paper reveals that large language models (LLMs), despite being trainedsolely on textual data, are surprisingly strong encoders for purely visualtasks in the absence of language. Even more intriguingly, this can be achievedby a simple yet previously overlooked strategy -- employing a frozentransformer block from pre-trained LLMs as a constituent encoder layer todirectly process visual tokens. Our work pushes the boundaries of leveragingLLMs for computer vision tasks, significantly departing from conventionalpractices that typically necessitate a multi-modal vision-language setup withassociated language prompts, inputs, or outputs. We demonstrate that ourapproach consistently enhances performance across a diverse range of tasks,encompassing pure 2D and 3D visual recognition tasks (e.g., image and pointcloud classification), temporal modeling tasks (e.g., action recognition),non-semantic tasks (e.g., motion forecasting), and multi-modal tasks (e.g.,2D/3D visual question answering and image-text retrieval). Such improvementsare a general phenomenon, applicable to various types of LLMs (e.g., LLaMA andOPT) and different LLM transformer blocks. We additionally propose theinformation filtering hypothesis to explain the effectiveness of pre-trainedLLMs in visual encoding -- the pre-trained LLM transformer blocks discerninformative visual tokens and further amplify their effect. This hypothesis isempirically supported by the observation that the feature activation, aftertraining with LLM transformer blocks, exhibits a stronger focus on relevantregions. We hope that our work inspires new perspectives on utilizing LLMs anddeepening our understanding of their underlying mechanisms. Code is availableat https://github.com/ziqipang/LM4VisualEncoding.</description><author>Ziqi Pang, Ziyang Xie, Yunze Man, Yu-Xiong Wang</author><pubDate>Mon, 06 May 2024 16:45:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12973v2</guid></item><item><title>Deep Space Separable Distillation for Lightweight Acoustic Scene Classification</title><link>http://arxiv.org/abs/2405.03567v1</link><description>Acoustic scene classification (ASC) is highly important in the real world.Recently, deep learning-based methods have been widely employed for acousticscene classification. However, these methods are currently not lightweightenough as well as their performance is not satisfactory. To solve theseproblems, we propose a deep space separable distillation network. Firstly, thenetwork performs high-low frequency decomposition on the log-mel spectrogram,significantly reducing computational complexity while maintaining modelperformance. Secondly, we specially design three lightweight operators for ASC,including Separable Convolution (SC), Orthonormal Separable Convolution (OSC),and Separable Partial Convolution (SPC). These operators exhibit highlyefficient feature extraction capabilities in acoustic scene classificationtasks. The experimental results demonstrate that the proposed method achieves aperformance gain of 9.8% compared to the currently popular deep learningmethods, while also having smaller parameter count and computationalcomplexity.</description><author>ShuQi Ye, Yuan Tian</author><pubDate>Mon, 06 May 2024 16:41:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03567v1</guid></item><item><title>Liberating Seen Classes: Boosting Few-Shot and Zero-Shot Text Classification via Anchor Generation and Classification Reframing</title><link>http://arxiv.org/abs/2405.03565v1</link><description>Few-shot and zero-shot text classification aim to recognize samples fromnovel classes with limited labeled samples or no labeled samples at all. Whileprevailing methods have shown promising performance via transferring knowledgefrom seen classes to unseen classes, they are still limited by (1) Inherentdissimilarities among classes make the transformation of features learned fromseen classes to unseen classes both difficult and inefficient. (2) Rare labelednovel samples usually cannot provide enough supervision signals to enable themodel to adjust from the source distribution to the target distribution,especially for complicated scenarios. To alleviate the above issues, we proposea simple and effective strategy for few-shot and zero-shot text classification.We aim to liberate the model from the confines of seen classes, therebyenabling it to predict unseen categories without the necessity of training onseen classes. Specifically, for mining more related unseen category knowledge,we utilize a large pre-trained language model to generate pseudo novel samples,and select the most representative ones as category anchors. After that, weconvert the multi-class classification task into a binary classification taskand use the similarities of query-anchor pairs for prediction to fully leveragethe limited supervision signals. Extensive experiments on six widely usedpublic datasets show that our proposed method can outperform other strongbaselines significantly in few-shot and zero-shot tasks, even without using anyseen class samples.</description><author>Han Liu, Siyang Zhao, Xiaotong Zhang, Feng Zhang, Wei Wang, Fenglong Ma, Hongyang Chen, Hong Yu, Xianchao Zhang</author><pubDate>Mon, 06 May 2024 16:38:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03565v1</guid></item><item><title>The Chosen One: Consistent Characters in Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2311.10093v3</link><description>Recent advances in text-to-image generation models have unlocked vastpotential for visual creativity. However, these models struggle with generationof consistent characters, a crucial aspect for numerous real-world applicationssuch as story visualization, game development asset design, advertising, andmore. Current methods typically rely on multiple pre-existing images of thetarget character or involve labor-intensive manual processes. In this work, wepropose a fully automated solution for consistent character generation, withthe sole input being a text prompt. We introduce an iterative procedure that,at each stage, identifies a coherent set of images sharing a similar identityand extracts a more consistent identity from this set. Our quantitativeanalysis demonstrates that our method strikes a better balance between promptalignment and identity consistency compared to the baseline methods, and thesefindings are reinforced by a user study. To conclude, we showcase severalpractical applications of our approach. Project page is available athttps://omriavrahami.com/the-chosen-one</description><author>Omri Avrahami, Amir Hertz, Yael Vinker, Moab Arar, Shlomi Fruchter, Ohad Fried, Daniel Cohen-Or, Dani Lischinski</author><pubDate>Mon, 06 May 2024 16:38:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10093v3</guid></item><item><title>Data-Copilot: Bridging Billions of Data and Humans with Autonomous Workflow</title><link>http://arxiv.org/abs/2306.07209v3</link><description>Various industries such as finance, meteorology, and energy produce vastamounts of heterogeneous data every day. There is a natural demand for humansto manage, process, and display data efficiently. However, it necessitateslabor-intensive efforts and a high level of expertise for these data-relatedtasks. Considering large language models (LLMs) showcase promising capabilitiesin semantic understanding and reasoning, we advocate that the deployment ofLLMs could autonomously manage and process massive amounts of data whileinteracting and displaying in a human-friendly manner. Based on this, wepropose Data-Copilot, an LLM-based system that connects numerous data sourceson one end and caters to diverse human demands on the other end. Acting as anexperienced expert, Data-Copilot autonomously transforms raw data intomulti-form output that best matches the user's intent. Specifically, it firstdesigns multiple universal interfaces to satisfy diverse data-related requests,like querying, analysis, prediction, and visualization. In real-time response,it automatically deploys a concise workflow by invoking correspondinginterfaces. The whole process is fully controlled by Data-Copilot, withouthuman assistance. We release Data-Copilot-1.0 using massive Chinese financialdata, e.g., stocks, funds, and news. Experiments indicate it achieves reliableperformance with lower token consumption, showing promising applicationprospects.</description><author>Wenqi Zhang, Yongliang Shen, Weiming Lu, Yueting Zhuang</author><pubDate>Mon, 06 May 2024 16:36:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07209v3</guid></item><item><title>CreoleVal: Multilingual Multitask Benchmarks for Creoles</title><link>http://arxiv.org/abs/2310.19567v3</link><description>Creoles represent an under-explored and marginalized group of languages, withfew available resources for NLP research.While the genealogical ties betweenCreoles and a number of highly-resourced languages imply a significantpotential for transfer learning, this potential is hampered due to this lack ofannotated data. In this work we present CreoleVal, a collection of benchmarkdatasets spanning 8 different NLP tasks, covering up to 28 Creole languages; itis an aggregate of novel development datasets for reading comprehension,relation classification, and machine translation for Creoles, in addition to apractical gateway to a handful of preexisting benchmarks. For each benchmark,we conduct baseline experiments in a zero-shot setting in order to furtherascertain the capabilities and limitations of transfer learning for Creoles.Ultimately, we see CreoleVal as an opportunity to empower research on Creolesin NLP and computational linguistics, and in general, a step towards moreequitable language technology around the globe.</description><author>Heather Lent, Kushal Tatariya, Raj Dabre, Yiyi Chen, Marcell Fekete, Esther Ploeger, Li Zhou, Ruth-Ann Armstrong, Abee Eijansantos, Catriona Malau, Hans Erik Heje, Ernests Lavrinovics, Diptesh Kanojia, Paul Belony, Marcel Bollmann, Loïc Grobol, Miryam de Lhoneux, Daniel Hershcovich, Michel DeGraff, Anders Søgaard, Johannes Bjerva</author><pubDate>Mon, 06 May 2024 16:30:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19567v3</guid></item><item><title>Torch2Chip: An End-to-end Customizable Deep Neural Network Compression and Deployment Toolkit for Prototype Hardware Accelerator Design</title><link>http://arxiv.org/abs/2405.01775v2</link><description>The development of model compression is continuously motivated by theevolution of various neural network accelerators with ASIC or FPGA. On thealgorithm side, the ultimate goal of quantization or pruning is acceleratingthe expensive DNN computations on low-power hardware. However, such a"design-and-deploy" workflow faces under-explored challenges in the currenthardware-algorithm co-design community. First, although the state-of-the-artquantization algorithm can achieve low precision with negligible degradation ofaccuracy, the latest deep learning framework (e.g., PyTorch) can only supportnon-customizable 8-bit precision, data format, and parameter extraction.Secondly, the objective of quantization is to enable the computation withlow-precision data. However, the current SoTA algorithm treats the quantizedinteger as an intermediate result, while the final output of the quantizer isthe "discretized" floating-point values, ignoring the practical needs andadding additional workload to hardware designers for integer parameterextraction and layer fusion. Finally, the compression toolkits designed by theindustry are constrained to their in-house product or a handful of algorithms.The limited degree of freedom in the current toolkit and the under-exploredcustomization hinder the prototype ASIC or FPGA-based accelerator design. Toresolve these challenges, we propose Torch2Chip, an open-sourced, fullycustomizable, and high-performance toolkit that supports user-designedcompression followed by automatic model fusion and parameter extraction.Torch2Chip incorporates the hierarchical design workflow, and theuser-customized compression algorithm will be directly packed into thedeployment-ready format for prototype chip verification with either CNN orvision transformer (ViT). The code is available athttps://github.com/SeoLabCornell/torch2chip.</description><author>Jian Meng, Yuan Liao, Anupreetham Anupreetham, Ahmed Hasssan, Shixing Yu, Han-sok Suh, Xiaofeng Hu, Jae-sun Seo</author><pubDate>Mon, 06 May 2024 16:27:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01775v2</guid></item><item><title>AlphaMath Almost Zero: process Supervision without process</title><link>http://arxiv.org/abs/2405.03553v1</link><description>Recent advancements in large language models (LLMs) have substantiallyenhanced their mathematical reasoning abilities. However, these models stillstruggle with complex problems that require multiple reasoning steps,frequently leading to logical or numerical errors. While numerical mistakes canlargely be addressed by integrating a code interpreter, identifying logicalerrors within intermediate steps is more challenging. Moreover, manuallyannotating these steps for training is not only expensive but also demandsspecialized expertise. In this study, we introduce an innovative approach thateliminates the need for manual annotation by leveraging the Monte Carlo TreeSearch (MCTS) framework to generate both the process supervision and evaluationsignals automatically. Essentially, when a LLM is well pre-trained, only themathematical questions and their final answers are required to generate ourtraining data, without requiring the solutions. We proceed to train astep-level value model designed to improve the LLM's inference process inmathematical domains. Our experiments indicate that using automaticallygenerated solutions by LLMs enhanced with MCTS significantly improves themodel's proficiency in dealing with intricate mathematical reasoning tasks.</description><author>Guoxin Chen, Minpeng Liao, Chengxi Li, Kai Fan</author><pubDate>Mon, 06 May 2024 16:20:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03553v1</guid></item><item><title>Exploring Interactive Semantic Alignment for Efficient HOI Detection with Vision-language Model</title><link>http://arxiv.org/abs/2404.12678v2</link><description>Human-Object Interaction (HOI) detection aims to localize human-object pairsand comprehend their interactions. Recently, two-stage transformer-basedmethods have demonstrated competitive performance. However, these methodsfrequently focus on object appearance features and ignore global contextualinformation. Besides, vision-language model CLIP which effectively alignsvisual and text embeddings has shown great potential in zero-shot HOIdetection. Based on the former facts, We introduce a novel HOI detector namedISA-HOI, which extensively leverages knowledge from CLIP, aligning interactivesemantics between visual and textual features. We first extract global contextof image and local features of object to Improve interaction Features in images(IF). On the other hand, we propose a Verb Semantic Improvement (VSI) module toenhance textual features of verb labels via cross-modal fusion. Ultimately, ourmethod achieves competitive results on the HICO-DET and V-COCO benchmarks withmuch fewer training epochs, and outperforms the state-of-the-art underzero-shot settings.</description><author>Jihao Dong, Renjie Pan, Hua Yang</author><pubDate>Mon, 06 May 2024 16:16:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12678v2</guid></item><item><title>An Optimized Ensemble Deep Learning Model For Brain Tumor Classification</title><link>http://arxiv.org/abs/2305.12844v2</link><description>Brain tumors present a grave risk to human life, demanding precise and timelydiagnosis for effective treatment. Inaccurate identification of brain tumorscan significantly diminish life expectancy, underscoring the critical need forprecise diagnostic methods. Manual identification of brain tumors within vastMagnetic Resonance Imaging (MRI) image datasets is arduous and time-consuming.Thus, the development of a reliable deep learning (DL) model is essential toenhance diagnostic accuracy and ultimately save lives. This study introduces aninnovative optimization-based deep ensemble approach employing transferlearning (TL) to efficiently classify brain tumors. Our methodology includesmeticulous preprocessing, reconstruction of TL architectures, fine-tuning, andensemble DL models utilizing weighted optimization techniques such as GeneticAlgorithm-based Weight Optimization (GAWO) and Grid Search-based WeightOptimization (GSWO). Experimentation is conducted on the FigshareContrast-Enhanced MRI (CE-MRI) brain tumor dataset, comprising 3064 images. Ourapproach achieves notable accuracy scores, with Xception, ResNet50V2,ResNet152V2, InceptionResNetV2, GAWO, and GSWO attaining 99.42%, 98.37%,98.22%, 98.26%, 99.71%, and 99.76% accuracy, respectively. Notably, GSWOdemonstrates superior accuracy, averaging 99.76\% accuracy across five folds onthe Figshare CE-MRI brain tumor dataset. The comparative analysis highlightsthe significant performance enhancement of our proposed model over existingcounterparts. In conclusion, our optimized deep ensemble model exhibitsexceptional accuracy in swiftly classifying brain tumors. Furthermore, it hasthe potential to assist neurologists and clinicians in making accurate andimmediate diagnostic decisions.</description><author>Md. Alamin Talukder, Md. Manowarul Islam, Md Ashraf Uddin</author><pubDate>Mon, 06 May 2024 16:16:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12844v2</guid></item><item><title>Bridging Stereo Geometry and BEV Representation with Reliable Mutual Interaction for Semantic Scene Completion</title><link>http://arxiv.org/abs/2303.13959v6</link><description>3D semantic scene completion (SSC) is an ill-posed perception task thatrequires inferring a dense 3D scene from limited observations. Previouscamera-based methods struggle to predict accurate semantic scenes due toinherent geometric ambiguity and incomplete observations. In this paper, weresort to stereo matching technique and bird's-eye-view (BEV) representationlearning to address such issues in SSC. Complementary to each other, stereomatching mitigates geometric ambiguity with epipolar constraint while BEVrepresentation enhances the hallucination ability for invisible regions withglobal semantic context. However, due to the inherent representation gapbetween stereo geometry and BEV features, it is non-trivial to bridge them fordense prediction task of SSC. Therefore, we further develop a unifiedoccupancy-based framework dubbed BRGScene, which effectively bridges these tworepresentations with dense 3D volumes for reliable semantic scene completion.Specifically, we design a novel Mutual Interactive Ensemble (MIE) block forpixel-level reliable aggregation of stereo geometry and BEV features. Withinthe MIE block, a Bi-directional Reliable Interaction (BRI) module, enhancedwith confidence re-weighting, is employed to encourage fine-grained interactionthrough mutual guidance. Besides, a Dual Volume Ensemble (DVE) module isintroduced to facilitate complementary aggregation through channel-wiserecalibration and multi-group voting. Our method outperforms all publishedcamera-based methods on SemanticKITTI for semantic scene completion. Our codeis available on https://github.com/Arlo0o/StereoScene.</description><author>Bohan Li, Yasheng Sun, Zhujin Liang, Dalong Du, Zhuanghui Zhang, Xiaofeng Wang, Yunnan Wang, Xin Jin, Wenjun Zeng</author><pubDate>Mon, 06 May 2024 16:14:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.13959v6</guid></item><item><title>Bridging discrete and continuous state spaces: Exploring the Ehrenfest process in time-continuous diffusion models</title><link>http://arxiv.org/abs/2405.03549v1</link><description>Generative modeling via stochastic processes has led to remarkable empiricalresults as well as to recent advances in their theoretical understanding. Inprinciple, both space and time of the processes can be discrete or continuous.In this work, we study time-continuous Markov jump processes on discrete statespaces and investigate their correspondence to state-continuous diffusionprocesses given by SDEs. In particular, we revisit the $\textit{Ehrenfestprocess}$, which converges to an Ornstein-Uhlenbeck process in the infinitestate space limit. Likewise, we can show that the time-reversal of theEhrenfest process converges to the time-reversed Ornstein-Uhlenbeck process.This observation bridges discrete and continuous state spaces and allows tocarry over methods from one to the respective other setting. Additionally, wesuggest an algorithm for training the time-reversal of Markov jump processeswhich relies on conditional expectations and can thus be directly related todenoising score matching. We demonstrate our methods in multiple convincingnumerical experiments.</description><author>Ludwig Winkler, Lorenz Richter, Manfred Opper</author><pubDate>Mon, 06 May 2024 16:12:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03549v1</guid></item><item><title>SceneTracker: Long-term Scene Flow Estimation Network</title><link>http://arxiv.org/abs/2403.19924v3</link><description>Considering the complementarity of scene flow estimation in the spatialdomain's focusing capability and 3D object tracking in the temporal domain'scoherence, this study aims to address a comprehensive new task that cansimultaneously capture fine-grained and long-term 3D motion in an onlinemanner: long-term scene flow estimation (LSFE). We introduce SceneTracker, anovel learning-based LSFE network that adopts an iterative approach toapproximate the optimal trajectory. Besides, it dynamically indexes andconstructs appearance and depth correlation features simultaneously and employsthe Transformer to explore and utilize long-range connections within andbetween trajectories. With detailed experiments, SceneTracker shows superiorcapabilities in handling 3D spatial occlusion and depth noise interference,highly tailored to the LSFE task's needs. Finally, we build the firstreal-world evaluation dataset, LSFDriving, further substantiatingSceneTracker's commendable generalization capacity. The code and data forSceneTracker is available at https://github.com/wwsource/SceneTracker.</description><author>Bo Wang, Jian Li, Yang Yu, Li Liu, Zhenping Sun, Dewen Hu</author><pubDate>Mon, 06 May 2024 16:12:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19924v3</guid></item><item><title>MAmmoTH2: Scaling Instructions from the Web</title><link>http://arxiv.org/abs/2405.03548v1</link><description>Instruction tuning improves the reasoning abilities of large language models(LLMs), with data quality and scalability being the crucial factors. Mostinstruction tuning data come from human crowd-sourcing or GPT-4 distillation.We propose a paradigm to efficiently harvest 10 million naturally existinginstruction data from the pre-training web corpus to enhance LLM reasoning. Ourapproach involves (1) recalling relevant documents, (2) extractinginstruction-response pairs, and (3) refining the extracted pairs usingopen-source LLMs. Fine-tuning base LLMs on this dataset, we build MAmmoTH2models, which significantly boost performance on reasoning benchmarks. Notably,MAmmoTH2-7B's (Mistral) performance increases from 11% to 34% on MATH and from36% to 67% on GSM8K without training on any in-domain data. Further trainingMAmmoTH2 on public instruction tuning datasets yields MAmmoTH2-Plus, achievingstate-of-the-art performance on several reasoning and chatbot benchmarks. Ourwork demonstrates how to harvest large-scale, high-quality instruction datawithout costly human annotation or GPT-4 distillation, providing a new paradigmfor building better instruction tuning data.</description><author>Xiang Yue, Tuney Zheng, Ge Zhang, Wenhu Chen</author><pubDate>Mon, 06 May 2024 16:11:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03548v1</guid></item><item><title>Position Paper: Leveraging Foundational Models for Black-Box Optimization: Benefits, Challenges, and Future Directions</title><link>http://arxiv.org/abs/2405.03547v1</link><description>Undeniably, Large Language Models (LLMs) have stirred an extraordinary waveof innovation in the machine learning research domain, resulting in substantialimpact across diverse fields such as reinforcement learning, robotics, andcomputer vision. Their incorporation has been rapid and transformative, markinga significant paradigm shift in the field of machine learning research. However, the field of experimental design, grounded on black-boxoptimization, has been much less affected by such a paradigm shift, even thoughintegrating LLMs with optimization presents a unique landscape ripe forexploration. In this position paper, we frame the field of black-boxoptimization around sequence-based foundation models and organize theirrelationship with previous literature. We discuss the most promising waysfoundational language models can revolutionize optimization, which includeharnessing the vast wealth of information encapsulated in free-form text toenrich task comprehension, utilizing highly flexible sequence models such asTransformers to engineer superior optimization strategies, and enhancingperformance prediction over previously unseen search spaces.</description><author>Xingyou Song, Yingtao Tian, Robert Tjarko Lange, Chansoo Lee, Yujin Tang, Yutian Chen</author><pubDate>Mon, 06 May 2024 16:10:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03547v1</guid></item><item><title>CCDM: Continuous Conditional Diffusion Models for Image Generation</title><link>http://arxiv.org/abs/2405.03546v1</link><description>Continuous Conditional Generative Modeling (CCGM) aims to estimate thedistribution of high-dimensional data, typically images, conditioned on scalarcontinuous variables known as regression labels. While Continuous conditionalGenerative Adversarial Networks (CcGANs) were initially designed for this task,their adversarial training mechanism remains vulnerable to extremely sparse orimbalanced data, resulting in suboptimal outcomes. To enhance the quality ofgenerated images, a promising alternative is to replace CcGANs with ConditionalDiffusion Models (CDMs), renowned for their stable training process and abilityto produce more realistic images. However, existing CDMs encounter challengeswhen applied to CCGM tasks due to several limitations such as inadequate U-Netarchitectures and deficient model fitting mechanisms for handling regressionlabels. In this paper, we introduce Continuous Conditional Diffusion Models(CCDMs), the first CDM designed specifically for the CCGM task. CCDMs addressthe limitations of existing CDMs by introducing specially designed conditionaldiffusion processes, a modified denoising U-Net with a custom-made conditioningmechanism, a novel hard vicinal loss for model fitting, and an efficientconditional sampling procedure. With comprehensive experiments on four datasetswith varying resolutions ranging from 64x64 to 192x192, we demonstrate thesuperiority of the proposed CCDM over state-of-the-art CCGM models,establishing new benchmarks in CCGM. Extensive ablation studies validate themodel design and implementation configuration of the proposed CCDM. Our code ispublicly available at https://github.com/UBCDingXin/CCDM.</description><author>Xin Ding, Yongwei Wang, Kao Zhang, Z. Jane Wang</author><pubDate>Mon, 06 May 2024 16:10:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03546v1</guid></item><item><title>Optimizing Hand Region Detection in MediaPipe Holistic Full-Body Pose Estimation to Improve Accuracy and Avoid Downstream Errors</title><link>http://arxiv.org/abs/2405.03545v1</link><description>This paper addresses a critical flaw in MediaPipe Holistic's hand Region ofInterest (ROI) prediction, which struggles with non-ideal hand orientations,affecting sign language recognition accuracy. We propose a data-driven approachto enhance ROI estimation, leveraging an enriched feature set includingadditional hand keypoints and the z-dimension. Our results demonstrate betterestimates, with higher Intersection-over-Union compared to the current method.Our code and optimizations are available athttps://github.com/sign-language-processing/mediapipe-hand-crop-fix.</description><author>Amit Moryossef</author><pubDate>Mon, 06 May 2024 16:10:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03545v1</guid></item><item><title>Inherent Trade-Offs between Diversity and Stability in Multi-Task Benchmarks</title><link>http://arxiv.org/abs/2405.01719v2</link><description>We examine multi-task benchmarks in machine learning through the lens ofsocial choice theory. We draw an analogy between benchmarks and electoralsystems, where models are candidates and tasks are voters. This suggests adistinction between cardinal and ordinal benchmark systems. The formeraggregate numerical scores into one model ranking; the latter aggregaterankings for each task. We apply Arrow's impossibility theorem to ordinalbenchmarks to highlight the inherent limitations of ordinal systems,particularly their sensitivity to the inclusion of irrelevant models. Inspiredby Arrow's theorem, we empirically demonstrate a strong trade-off betweendiversity and sensitivity to irrelevant changes in existing multi-taskbenchmarks. Our result is based on new quantitative measures of diversity andsensitivity that we introduce. Sensitivity quantifies the impact thatirrelevant changes to tasks have on a benchmark. Diversity captures the degreeof disagreement in model rankings across tasks. We develop efficientapproximation algorithms for both measures, as exact computation iscomputationally challenging. Through extensive experiments on seven cardinalbenchmarks and eleven ordinal benchmarks, we demonstrate a clear trade-offbetween diversity and stability: The more diverse a multi-task benchmark, themore sensitive to trivial changes it is. Additionally, we show that theaggregated rankings of existing benchmarks are highly unstable under irrelevantchanges. The codes and data are available athttps://socialfoundations.github.io/benchbench/.</description><author>Guanhua Zhang, Moritz Hardt</author><pubDate>Mon, 06 May 2024 16:09:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01719v2</guid></item><item><title>RepVGG-GELAN: Enhanced GELAN with VGG-STYLE ConvNets for Brain Tumour Detection</title><link>http://arxiv.org/abs/2405.03541v1</link><description>Object detection algorithms particularly those based on YOLO havedemonstrated remarkable efficiency in balancing speed and accuracy. However,their application in brain tumour detection remains underexplored. This studyproposes RepVGG-GELAN, a novel YOLO architecture enhanced with RepVGG, areparameterized convolutional approach for object detection tasks particularlyfocusing on brain tumour detection within medical images. RepVGG-GELANleverages the RepVGG architecture to improve both speed and accuracy indetecting brain tumours. Integrating RepVGG into the YOLO framework aims toachieve a balance between computational efficiency and detection performance.This study includes a spatial pyramid pooling-based Generalized Efficient LayerAggregation Network (GELAN) architecture which further enhances the capabilityof RepVGG. Experimental evaluation conducted on a brain tumour datasetdemonstrates the effectiveness of RepVGG-GELAN surpassing existing RCS-YOLO interms of precision and speed. Specifically, RepVGG-GELAN achieves an increasedprecision of 4.91% and an increased AP50 of 2.54% over the latest existingapproach while operating at 240.7 GFLOPs. The proposed RepVGG-GELAN with GELANarchitecture presents promising results establishing itself as astate-of-the-art solution for accurate and efficient brain tumour detection inmedical images. The implementation code is publicly available athttps://github.com/ThensiB/RepVGG-GELAN.</description><author>Thennarasi Balakrishnan, Sandeep Singh Sengar</author><pubDate>Mon, 06 May 2024 16:02:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03541v1</guid></item><item><title>Uncovering What, Why and How: A Comprehensive Benchmark for Causation Understanding of Video Anomaly</title><link>http://arxiv.org/abs/2405.00181v2</link><description>Video anomaly understanding (VAU) aims to automatically comprehend unusualoccurrences in videos, thereby enabling various applications such as trafficsurveillance and industrial manufacturing. While existing VAU benchmarksprimarily concentrate on anomaly detection and localization, our focus is onmore practicality, prompting us to raise the following crucial questions: "whatanomaly occurred?", "why did it happen?", and "how severe is this abnormalevent?". In pursuit of these answers, we present a comprehensive benchmark forCausation Understanding of Video Anomaly (CUVA). Specifically, each instance ofthe proposed benchmark involves three sets of human annotations to indicate the"what", "why" and "how" of an anomaly, including 1) anomaly type, start and endtimes, and event descriptions, 2) natural language explanations for the causeof an anomaly, and 3) free text reflecting the effect of the abnormality. Inaddition, we also introduce MMEval, a novel evaluation metric designed tobetter align with human preferences for CUVA, facilitating the measurement ofexisting LLMs in comprehending the underlying cause and corresponding effect ofvideo anomalies. Finally, we propose a novel prompt-based method that can serveas a baseline approach for the challenging CUVA. We conduct extensiveexperiments to show the superiority of our evaluation metric and theprompt-based approach. Our code and dataset are available athttps://github.com/fesvhtr/CUVA.</description><author>Hang Du, Sicheng Zhang, Binzhu Xie, Guoshun Nan, Jiayang Zhang, Junrui Xu, Hangyu Liu, Sicong Leng, Jiangming Liu, Hehe Fan, Dajiu Huang, Jing Feng, Linli Chen, Can Zhang, Xuhuan Li, Hao Zhang, Jianhang Chen, Qimei Cui, Xiaofeng Tao</author><pubDate>Mon, 06 May 2024 15:57:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00181v2</guid></item><item><title>FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions</title><link>http://arxiv.org/abs/2403.15246v2</link><description>Modern Language Models (LMs) are capable of following long and complexinstructions that enable a large and diverse set of user requests. WhileInformation Retrieval (IR) models use these LMs as the backbone of theirarchitectures, virtually none of them allow users to provide detailedinstructions alongside queries, thus limiting their ability to satisfy complexinformation needs. In this work, we study the use of instructions in IRsystems. First, we introduce our dataset FollowIR, which contains a rigorousinstruction evaluation benchmark as well as a training set for helping IRmodels learn to better follow real-world instructions. FollowIR repurposesdetailed instructions -- also known as narratives -- developed for professionalassessors to evaluate retrieval systems. In particular, we build our benchmarkfrom three collections curated for shared tasks at the Text REtrievalConference (TREC). These collections contains hundreds to thousands of labeleddocuments per query, making them suitable for our exploration. Through thisprocess, we can measure how well IR models follow instructions, through a newpairwise evaluation framework. Our results indicate that existing retrievalmodels fail to correctly use instructions, using them for basic keywords andstruggling to understand long-form information. However, we show that it ispossible for IR models to learn to follow complex instructions: our newFollowIR-7B model has significant improvements after fine-tuning on ourtraining set.</description><author>Orion Weller, Benjamin Chang, Sean MacAvaney, Kyle Lo, Arman Cohan, Benjamin Van Durme, Dawn Lawrie, Luca Soldaini</author><pubDate>Mon, 06 May 2024 15:56:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15246v2</guid></item><item><title>Exploring the Efficacy of Federated-Continual Learning Nodes with Attention-Based Classifier for Robust Web Phishing Detection: An Empirical Investigation</title><link>http://arxiv.org/abs/2405.03537v1</link><description>Web phishing poses a dynamic threat, requiring detection systems to quicklyadapt to the latest tactics. Traditional approaches of accumulating data andperiodically retraining models are outpaced. We propose a novel paradigmcombining federated learning and continual learning, enabling distributed nodesto continually update models on streams of new phishing data, withoutaccumulating data. These locally adapted models are then aggregated at acentral server via federated learning. To enhance detection, we introduce acustom attention-based classifier model with residual connections, tailored forweb phishing, leveraging attention mechanisms to capture intricate phishingpatterns. We evaluate our hybrid learning paradigm across continual learningstrategies (cumulative, replay, MIR, LwF) and model architectures through anempirical investigation. Our main contributions are: (1) a new hybridfederated-continual learning paradigm for robust web phishing detection, and(2) a novel attention + residual connections based model explicitly designedfor this task, attaining 0.93 accuracy, 0.90 precision, 0.96 recall and 0.93f1-score with the LwF strategy, outperforming traditional approaches indetecting emerging phishing threats while retaining past knowledge.</description><author>Jesher Joshua M, Adhithya R, Sree Dananjay S, M Revathi</author><pubDate>Mon, 06 May 2024 15:55:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03537v1</guid></item><item><title>Graph Convolutional Neural Networks Sensitivity under Probabilistic Error Model</title><link>http://arxiv.org/abs/2203.07831v4</link><description>Graph Neural Networks (GNNs), particularly Graph Convolutional NeuralNetworks (GCNNs), have emerged as pivotal instruments in machine learning andsignal processing for processing graph-structured data. This paper proposes ananalysis framework to investigate the sensitivity of GCNNs to probabilisticgraph perturbations, directly impacting the graph shift operator (GSO). Ourstudy establishes tight expected GSO error bounds, which are explicitly linkedto the error model parameters, and reveals a linear relationship between GSOperturbations and the resulting output differences at each layer of GCNNs. Thislinearity demonstrates that a single-layer GCNN maintains stability under graphedge perturbations, provided that the GSO errors remain bounded, regardless ofthe perturbation scale. For multilayer GCNNs, the dependency of system's outputdifference on GSO perturbations is shown to be a recursion of linearity.Finally, we exemplify the framework with the Graph Isomorphism Network (GIN)and Simple Graph Convolution Network (SGCN). Experiments validate ourtheoretical derivations and the effectiveness of our approach.</description><author>Xinjue Wang, Esa Ollila, Sergiy A. Vorobyov</author><pubDate>Mon, 06 May 2024 15:55:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.07831v4</guid></item><item><title>Meta-Evolve: Continuous Robot Evolution for One-to-many Policy Transfer</title><link>http://arxiv.org/abs/2405.03534v1</link><description>We investigate the problem of transferring an expert policy from a sourcerobot to multiple different robots. To solve this problem, we propose a methodnamed $Meta$-$Evolve$ that uses continuous robot evolution to efficientlytransfer the policy to each target robot through a set of tree-structuredevolutionary robot sequences. The robot evolution tree allows the robotevolution paths to be shared, so our approach can significantly outperformnaive one-to-one policy transfer. We present a heuristic approach to determinean optimized robot evolution tree. Experiments have shown that our method isable to improve the efficiency of one-to-three transfer of manipulation policyby up to 3.2$\times$ and one-to-six transfer of agile locomotion policy by2.4$\times$ in terms of simulation cost over the baseline of launching multipleindependent one-to-one policy transfers.</description><author>Xingyu Liu, Deepak Pathak, Ding Zhao</author><pubDate>Mon, 06 May 2024 15:52:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03534v1</guid></item><item><title>Investigating the ability of deep learning to predict Welding Depth and Pore Volume in Hairpin Welding</title><link>http://arxiv.org/abs/2312.01606v3</link><description>To advance quality assurance in the welding process, this study presents arobust deep learning model that enables the prediction of two critical weldsKey Performance Characteristics (KPCs): welding depth and average pore volume.In the proposed approach, a comprehensive range of laser welding Key InputCharacteristics (KICs) is utilized, including welding beam geometries, weldingfeed rates, path repetitions for weld beam geometries, and bright light weldratios for all paths, all of which were obtained from hairpin weldingexperiments. Two deep learning networks are employed with multiple hidden denselayers and linear activation functions to showcase the capabilities of deepneural networks in capturing the intricate nonlinear connections inherentwithin welding KPCs and KICs. Applying deep learning networks to the smallnumerical experimental hairpin welding dataset has shown promising results,achieving Mean Absolute Error (MAE) values as low as 0.1079 for predictingwelding depth and 0.0641 for average pore volume. Additionally, the validityverification demonstrates the reliability of the proposed method. This, inturn, promises significant advantages in controlling welding outcomes, movingbeyond the current trend of relying merely on monitoring for defectclassification.</description><author>Amena Darwish, Stefan Ericson, Rohollah Ghasemi, Tobias Andersson, Dan Lönn, Andreas Andersson Lassila, Kent Salomonsson</author><pubDate>Mon, 06 May 2024 15:51:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01606v3</guid></item><item><title>ReinWiFi: A Reinforcement-Learning-Based Framework for the Application-Layer QoS Optimization of WiFi Networks</title><link>http://arxiv.org/abs/2405.03526v1</link><description>In this paper, a reinforcement-learning-based scheduling framework isproposed and implemented to optimize the application-layer quality-of-service(QoS) of a practical wireless local area network (WLAN) suffering from unknowninterference. Particularly, application-layer tasks of file delivery anddelay-sensitive communication, e.g., screen projection, in a WLAN with enhanceddistributed channel access (EDCA) mechanism, are jointly scheduled by adjustingthe contention window sizes and application-layer throughput limitation, suchthat their QoS, including the throughput of file delivery and the round triptime of the delay-sensitive communication, can be optimized. Due to the unknowninterference and vendor-dependent implementation of the network interface card,the relation between the scheduling policy and the system QoS is unknown.Hence, a reinforcement learning method is proposed, in which a novel Q-networkis trained to map from the historical scheduling parameters and QoSobservations to the current scheduling action. It is demonstrated on a testbedthat the proposed framework can achieve a significantly better QoS than theconventional EDCA mechanism.</description><author>Qianren Li, Bojie Lv, Yuncong Hong, Rui Wang</author><pubDate>Mon, 06 May 2024 15:44:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03526v1</guid></item><item><title>EAMA : Entity-Aware Multimodal Alignment Based Approach for News Image Captioning</title><link>http://arxiv.org/abs/2402.19404v4</link><description>News image captioning requires model to generate an informative caption richin entities, with the news image and the associated news article. ThoughMultimodal Large Language Models (MLLMs) have demonstrated remarkablecapabilities in addressing various vision-language tasks, our research findsthat current MLLMs still bear limitations in handling entity information onnews image captioning task. Besides, while MLLMs have the ability to processlong inputs, generating high-quality news image captions still requires atrade-off between sufficiency and conciseness of textual input information. Toexplore the potential of MLLMs and address problems we discovered, we propose :an Entity-Aware Multimodal Alignment based approach for news image captioning.Our approach first aligns the MLLM through Balance Training Strategy with twoextra alignment tasks: Entity-Aware Sentence Selection task and EntitySelection task, together with News Image Captioning task, to enhance itscapability in handling multimodal entity information. The aligned MLLM willutilizes the additional entity-related information it explicitly extracts tosupplement its textual input while generating news image captions. Our approachachieves better results than all previous models in CIDEr score on GoodNewsdataset (72.33 -&gt; 88.39) and NYTimes800k dataset (70.83 -&gt; 85.61).</description><author>Junzhe Zhang, Huixuan Zhang, Xunjian Yin, Xiaojun Wan</author><pubDate>Mon, 06 May 2024 15:41:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19404v4</guid></item><item><title>Exploring knowledge graph-based neural-symbolic system from application perspective</title><link>http://arxiv.org/abs/2405.03524v1</link><description>The rapid advancement in artificial intelligence (AI), particularly throughdeep neural networks, has catalyzed significant progress in fields such asvision and text processing. Nonetheless, the pursuit of AI systems that exhibithuman-like reasoning and interpretability continues to pose a substantialchallenge. The Neural-Symbolic paradigm, which integrates the deep learningprowess of neural networks with the reasoning capabilities of symbolic systems,presents a promising pathway toward developing more transparent andcomprehensible AI systems. Within this paradigm, the Knowledge Graph (KG)emerges as a crucial element, offering a structured and dynamic method forrepresenting knowledge through interconnected entities and relationships,predominantly utilizing the triple (subject, predicate, object). This paperexplores recent advancements in neural-symbolic integration based on KG,elucidating how KG underpins this integration across three key categories:enhancing the reasoning and interpretability of neural networks through theincorporation of symbolic knowledge (Symbol for Neural), refining thecompleteness and accuracy of symbolic systems via neural network methodologies(Neural for Symbol), and facilitating their combined application in HybridNeural-Symbolic Integration. It highlights current trends and proposesdirections for future research in the domain of Neural-Symbolic AI.</description><author>Shenzhe Zhu</author><pubDate>Mon, 06 May 2024 15:40:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03524v1</guid></item><item><title>Optimisation challenge for superconducting adiabatic neural network implementing XOR and OR boolean functions</title><link>http://arxiv.org/abs/2405.03521v1</link><description>In this article, we consider designs of simple analog artificial neuralnetworks based on adiabatic Josephson cells with a sigmoid activation function.A new approach based on the gradient descent method is developed to adjust thecircuit parameters, allowing efficient signal transmission between the networklayers. The proposed solution is demonstrated on the example of the systemimplementing XOR and OR logical operations.</description><author>D. S. Pashin, M. V. Bastrakova, D. A. Rybin, I. I. Soloviev, A. E. Schegolev, N. V. Klenov</author><pubDate>Mon, 06 May 2024 15:38:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03521v1</guid></item><item><title>Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond</title><link>http://arxiv.org/abs/2405.03520v1</link><description>General world models represent a crucial pathway toward achieving ArtificialGeneral Intelligence (AGI), serving as the cornerstone for various applicationsranging from virtual environments to decision-making systems. Recently, theemergence of the Sora model has attained significant attention due to itsremarkable simulation capabilities, which exhibits an incipient comprehensionof physical laws. In this survey, we embark on a comprehensive exploration ofthe latest advancements in world models. Our analysis navigates through theforefront of generative methodologies in video generation, where world modelsstand as pivotal constructs facilitating the synthesis of highly realisticvisual content. Additionally, we scrutinize the burgeoning field ofautonomous-driving world models, meticulously delineating their indispensablerole in reshaping transportation and urban mobility. Furthermore, we delve intothe intricacies inherent in world models deployed within autonomous agents,shedding light on their profound significance in enabling intelligentinteractions within dynamic environmental contexts. At last, we examinechallenges and limitations of world models, and discuss their potential futuredirections. We hope this survey can serve as a foundational reference for theresearch community and inspire continued innovation. This survey will beregularly updated at:https://github.com/GigaAI-research/General-World-Models-Survey.</description><author>Zheng Zhu, Xiaofeng Wang, Wangbo Zhao, Chen Min, Nianchen Deng, Min Dou, Yuqi Wang, Botian Shi, Kai Wang, Chi Zhang, Yang You, Zhaoxiang Zhang, Dawei Zhao, Liang Xiao, Jian Zhao, Jiwen Lu, Guan Huang</author><pubDate>Mon, 06 May 2024 15:37:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03520v1</guid></item><item><title>Low-light Object Detection</title><link>http://arxiv.org/abs/2405.03519v1</link><description>In this competition we employed a model fusion approach to achieve objectdetection results close to those of real images. Our method is based on theCO-DETR model, which was trained on two sets of data: one containing imagesunder dark conditions and another containing images enhanced with low-lightconditions. We used various enhancement techniques on the test data to generatemultiple sets of prediction results. Finally, we applied a clusteringaggregation method guided by IoU thresholds to select the optimal results.</description><author>Pengpeng Li, Haowei Gu, Yang Yang</author><pubDate>Mon, 06 May 2024 15:36:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03519v1</guid></item><item><title>PopulAtion Parameter Averaging (PAPA)</title><link>http://arxiv.org/abs/2304.03094v4</link><description>Ensemble methods combine the predictions of multiple models to improveperformance, but they require significantly higher computation costs atinference time. To avoid these costs, multiple neural networks can be combinedinto one by averaging their weights. However, this usually performssignificantly worse than ensembling. Weight averaging is only beneficial whendifferent enough to benefit from combining them, but similar enough to averagewell. Based on this idea, we propose PopulAtion Parameter Averaging (PAPA): amethod that combines the generality of ensembling with the efficiency of weightaveraging. PAPA leverages a population of diverse models (trained on differentdata orders, augmentations, and regularizations) while slowly pushing theweights of the networks toward the population average of the weights. We alsopropose PAPA variants (PAPA-all, and PAPA-2) that average weights rarely ratherthan continuously; all methods increase generalization, but PAPA tends toperform best. PAPA reduces the performance gap between averaging andensembling, increasing the average accuracy of a population of models by up to0.8% on CIFAR-10, 1.9% on CIFAR-100, and 1.6% on ImageNet when compared totraining independent (non-averaged) models.</description><author>Alexia Jolicoeur-Martineau, Emy Gervais, Kilian Fatras, Yan Zhang, Simon Lacoste-Julien</author><pubDate>Mon, 06 May 2024 15:32:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03094v4</guid></item><item><title>Circuit Component Reuse Across Tasks in Transformer Language Models</title><link>http://arxiv.org/abs/2310.08744v3</link><description>Recent work in mechanistic interpretability has shown that behaviors inlanguage models can be successfully reverse-engineered through circuitanalysis. A common criticism, however, is that each circuit is task-specific,and thus such analysis cannot contribute to understanding the models at ahigher level. In this work, we present evidence that insights (both low-levelfindings about specific heads and higher-level findings about generalalgorithms) can indeed generalize across tasks. Specifically, we study thecircuit discovered in Wang et al. (2022) for the Indirect Object Identification(IOI) task and 1.) show that it reproduces on a larger GPT2 model, and 2.) thatit is mostly reused to solve a seemingly different task: Colored Objects(Ippolito &amp; Callison-Burch, 2023). We provide evidence that the processunderlying both tasks is functionally very similar, and contains about a 78%overlap in in-circuit attention heads. We further present a proof-of-conceptintervention experiment, in which we adjust four attention heads in middlelayers in order to 'repair' the Colored Objects circuit and make it behave likethe IOI circuit. In doing so, we boost accuracy from 49.6% to 93.7% on theColored Objects task and explain most sources of error. The interventionaffects downstream attention heads in specific ways predicted by theirinteractions in the IOI circuit, indicating that this subcircuit behavior isinvariant to the different task inputs. Overall, our results provide evidencethat it may yet be possible to explain large language models' behavior in termsof a relatively small number of interpretable task-general algorithmic buildingblocks and computational components.</description><author>Jack Merullo, Carsten Eickhoff, Ellie Pavlick</author><pubDate>Mon, 06 May 2024 15:31:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08744v3</guid></item></channel></rss>