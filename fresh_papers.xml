<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sat, 01 Feb 2025 13:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>DeltaLLM: Compress LLMs with Low-Rank Deltas between Shared Weights</title><link>http://arxiv.org/abs/2501.18596v1</link><description>We introduce DeltaLLM, a new post-training compression technique to reducethe memory footprint of LLMs. We propose an alternative way of structuring LLMswith weight sharing between layers in subsequent Transformer blocks, along withadditional low-rank difference matrices between them. For training, we adoptthe progressing module replacement method and show that the lightweighttraining of the low-rank modules with approximately 30M-40M tokens issufficient to achieve performance on par with LLMs of comparable sizes trainedfrom scratch. We release the resultant models, DeltaLLAMA and DeltaPHI, with a12% parameter reduction, retaining 90% of the performance of the base Llama andPhi models on common knowledge and reasoning benchmarks. Our method alsooutperforms compression techniques JointDrop, LaCo, ShortGPT and SliceGPT withthe same number of parameters removed. For example, DeltaPhi 2.9B with a 24%reduction achieves similar average zero-shot accuracies as recovery fine-tunedSlicedPhi 3.3B with a 12% reduction, despite being approximately 400Mparameters smaller with no fine-tuning applied. This work provides new insightsinto LLM architecture design and compression methods when storage space iscritical.</description><author>Liana Mikaelyan, Ayyoob Imani, Mathew Salvaris, Parth Pathak, Mohsen Fayyaz</author><pubDate>Thu, 30 Jan 2025 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18596v1</guid></item><item><title>ROSA: Reconstructing Object Shape and Appearance Textures by Adaptive Detail Transfer</title><link>http://arxiv.org/abs/2501.18595v1</link><description>Reconstructing an object's shape and appearance in terms of a mesh texturedby a spatially-varying bidirectional reflectance distribution function (SVBRDF)from a limited set of images captured under collocated light is an ill-posedproblem. Previous state-of-the-art approaches either aim to reconstruct theappearance directly on the geometry or additionally use texture normals as partof the appearance features. However, this requires detailed but inefficientlylarge meshes, that would have to be simplified in a post-processing step, orsuffers from well-known limitations of normal maps such as missing shadows orincorrect silhouettes. Another limiting factor is the fixed and typically lowresolution of the texture estimation resulting in loss of important surfacedetails. To overcome these problems, we present ROSA, an inverse renderingmethod that directly optimizes mesh geometry with spatially adaptive meshresolution solely based on the image data. In particular, we refine the meshand locally condition the surface smoothness based on the estimated normaltexture and mesh curvature. In addition, we enable the reconstruction of fineappearance details in high-resolution textures through a pioneering tile-basedmethod that operates on a single pre-trained decoder network but is not limitedby the network output resolution.</description><author>Julian Kaltheuner, Patrick Stotko, Reinhard Klein</author><pubDate>Thu, 30 Jan 2025 18:59:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18595v1</guid></item><item><title>Foundational Models for 3D Point Clouds: A Survey and Outlook</title><link>http://arxiv.org/abs/2501.18594v1</link><description>The 3D point cloud representation plays a crucial role in preserving thegeometric fidelity of the physical world, enabling more accurate complex 3Denvironments. While humans naturally comprehend the intricate relationshipsbetween objects and variations through a multisensory system, artificialintelligence (AI) systems have yet to fully replicate this capacity. To bridgethis gap, it becomes essential to incorporate multiple modalities. Models thatcan seamlessly integrate and reason across these modalities are known asfoundation models (FMs). The development of FMs for 2D modalities, such asimages and text, has seen significant progress, driven by the abundantavailability of large-scale datasets. However, the 3D domain has lagged due tothe scarcity of labelled data and high computational overheads. In response,recent research has begun to explore the potential of applying FMs to 3D tasks,overcoming these challenges by leveraging existing 2D knowledge. Additionally,language, with its capacity for abstract reasoning and description of theenvironment, offers a promising avenue for enhancing 3D understanding throughlarge pre-trained language models (LLMs). Despite the rapid development andadoption of FMs for 3D vision tasks in recent years, there remains a gap incomprehensive and in-depth literature reviews. This article aims to addressthis gap by presenting a comprehensive overview of the state-of-the-art methodsthat utilize FMs for 3D visual understanding. We start by reviewing variousstrategies employed in the building of various 3D FMs. Then we categorize andsummarize use of different FMs for tasks such as perception tasks. Finally, thearticle offers insights into future directions for research and development inthis field. To help reader, we have curated list of relevant papers on thetopic: https://github.com/vgthengane/Awesome-FMs-in-3D.</description><author>Vishal Thengane, Xiatian Zhu, Salim Bouzerdoum, Son Lam Phung, Yunpeng Li</author><pubDate>Thu, 30 Jan 2025 18:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18594v1</guid></item><item><title>Diffusion Autoencoders are Scalable Image Tokenizers</title><link>http://arxiv.org/abs/2501.18593v1</link><description>Tokenizing images into compact visual representations is a key step inlearning efficient and high-quality image generative models. We present asimple diffusion tokenizer (DiTo) that learns compact visual representationsfor image generation models. Our key insight is that a single learningobjective, diffusion L2 loss, can be used for training scalable imagetokenizers. Since diffusion is already widely used for image generation, ourinsight greatly simplifies training such tokenizers. In contrast, currentstate-of-the-art tokenizers rely on an empirically found combination ofheuristics and losses, thus requiring a complex training recipe that relies onnon-trivially balancing different losses and pretrained supervised models. Weshow design decisions, along with theoretical grounding, that enable us toscale DiTo for learning competitive image representations. Our results showthat DiTo is a simpler, scalable, and self-supervised alternative to thecurrent state-of-the-art image tokenizer which is supervised. DiTo achievescompetitive or better quality than state-of-the-art in image reconstruction anddownstream image generation tasks.</description><author>Yinbo Chen, Rohit Girdhar, Xiaolong Wang, Sai Saketh Rambhatla, Ishan Misra</author><pubDate>Thu, 30 Jan 2025 18:59:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18593v1</guid></item><item><title>Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models</title><link>http://arxiv.org/abs/2501.18592v1</link><description>In real-world scenarios, achieving domain adaptation and generalization posessignificant challenges, as models must adapt to or generalize across unknowntarget distributions. Extending these capabilities to unseen multimodaldistributions, i.e., multimodal domain adaptation and generalization, is evenmore challenging due to the distinct characteristics of different modalities.Significant progress has been made over the years, with applications rangingfrom action recognition to semantic segmentation. Besides, the recent advent oflarge-scale pre-trained multimodal foundation models, such as CLIP, hasinspired works leveraging these models to enhance adaptation and generalizationperformances or adapting them to downstream tasks. This survey provides thefirst comprehensive review of recent advances from traditional approaches tofoundation models, covering: (1) Multimodal domain adaptation; (2) Multimodaltest-time adaptation; (3) Multimodal domain generalization; (4) Domainadaptation and generalization with the help of multimodal foundation models;and (5) Adaptation of multimodal foundation models. For each topic, we formallydefine the problem and thoroughly review existing methods. Additionally, weanalyze relevant datasets and applications, highlighting open challenges andpotential future research directions. We maintain an active repository thatcontains up-to-date literature athttps://github.com/donghao51/Awesome-Multimodal-Adaptation.</description><author>Hao Dong, Moru Liu, Kaiyang Zhou, Eleni Chatzi, Juho Kannala, Cyrill Stachniss, Olga Fink</author><pubDate>Thu, 30 Jan 2025 18:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18592v1</guid></item><item><title>DiffusionRenderer: Neural Inverse and Forward Rendering with Video Diffusion Models</title><link>http://arxiv.org/abs/2501.18590v1</link><description>Understanding and modeling lighting effects are fundamental tasks in computervision and graphics. Classic physically-based rendering (PBR) accuratelysimulates the light transport, but relies on precise scenerepresentations--explicit 3D geometry, high-quality material properties, andlighting conditions--that are often impractical to obtain in real-worldscenarios. Therefore, we introduce DiffusionRenderer, a neural approach thataddresses the dual problem of inverse and forward rendering within a holisticframework. Leveraging powerful video diffusion model priors, the inverserendering model accurately estimates G-buffers from real-world videos,providing an interface for image editing tasks, and training data for therendering model. Conversely, our rendering model generates photorealisticimages from G-buffers without explicit light transport simulation. Experimentsdemonstrate that DiffusionRenderer effectively approximates inverse andforwards rendering, consistently outperforming the state-of-the-art. Our modelenables practical applications from a single video input--including relighting,material editing, and realistic object insertion.</description><author>Ruofan Liang, Zan Gojcic, Huan Ling, Jacob Munkberg, Jon Hasselgren, Zhi-Hao Lin, Jun Gao, Alexander Keller, Nandita Vijaykumar, Sanja Fidler, Zian Wang</author><pubDate>Thu, 30 Jan 2025 18:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18590v1</guid></item><item><title>Inkspire: Supporting Design Exploration with Generative AI through Analogical Sketching</title><link>http://arxiv.org/abs/2501.18588v1</link><description>With recent advancements in the capabilities of Text-to-Image (T2I) AImodels, product designers have begun experimenting with them in their work.However, T2I models struggle to interpret abstract language and the currentuser experience of T2I tools can induce design fixation rather than a moreiterative, exploratory process. To address these challenges, we developedInkspire, a sketch-driven tool that supports designers in prototyping productdesign concepts with analogical inspirations and a completesketch-to-design-to-sketch feedback loop. To inform the design of Inkspire, weconducted an exchange session with designers and distilled design goals forimproving T2I interactions. In a within-subjects study comparing Inkspire toControlNet, we found that Inkspire supported designers with more inspirationand exploration of design ideas, and improved aspects of the co-creativeprocess by allowing designers to effectively grasp the current state of the AIto guide it towards novel design intentions.</description><author>David Chuan-En Lin, Hyeonsu B. Kang, Nikolas Martelaro, Aniket Kittur, Yan-Ying Chen, Matthew K. Hong</author><pubDate>Thu, 30 Jan 2025 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18588v1</guid></item><item><title>Beyond Browsing: API-Based Web Agents</title><link>http://arxiv.org/abs/2410.16464v2</link><description>Web browsers are a portal to the internet, where much of human activity isundertaken. Thus, there has been significant research work in AI agents thatinteract with the internet through web browsing. However, there is also anotherinterface designed specifically for machine interaction with online content:application programming interfaces (APIs). In this paper we ask -- what if wewere to take tasks traditionally tackled by browsing agents, and give AI agentsaccess to APIs? To do so, we propose two varieties of agents: (1) anAPI-calling agent that attempts to perform online tasks through APIs only,similar to traditional coding agents, and (2) a Hybrid Agent that can interactwith online data through both web browsing and APIs. In experiments onWebArena, a widely-used and realistic benchmark for web navigation tasks, wefind that API-based agents outperform web browsing agents. Hybrid Agentsout-perform both others nearly uniformly across tasks, resulting in a more than20.0% absolute improvement over web browsing alone, achieving a success rate of35.8%, achiving the SOTA performance among task-agnostic agents. These resultsstrongly suggest that when APIs are available, they present an attractivealternative to relying on web browsing alone.</description><author>Yueqi Song, Frank Xu, Shuyan Zhou, Graham Neubig</author><pubDate>Thu, 30 Jan 2025 18:58:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16464v2</guid></item><item><title>Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs</title><link>http://arxiv.org/abs/2501.18585v1</link><description>Large language models (LLMs) such as OpenAI's o1 have demonstrated remarkableabilities in complex reasoning tasks by scaling test-time compute andexhibiting human-like deep thinking. However, we identify a phenomenon we termunderthinking, where o1-like LLMs frequently switch between different reasoningthoughts without sufficiently exploring promising paths to reach a correctsolution. This behavior leads to inadequate depth of reasoning and decreasedperformance, particularly on challenging mathematical problems. Tosystematically analyze this issue, we conduct experiments on three challengingtest sets and two representative open-source o1-like models, revealing thatfrequent thought switching correlates with incorrect responses. We introduce anovel metric to quantify underthinking by measuring token efficiency inincorrect answers. To address underthinking, we propose a decoding strategywith thought switching penalty TIP that discourages premature transitionsbetween thoughts, encouraging deeper exploration of each reasoning path.Experimental results demonstrate that our approach improves accuracy acrosschallenging datasets without requiring model fine-tuning. Our findingscontribute to understanding reasoning inefficiencies in o1-like LLMs and offera practical solution to enhance their problem-solving capabilities.</description><author>Yue Wang, Qiuzhi Liu, Jiahao Xu, Tian Liang, Xingyu Chen, Zhiwei He, Linfeng Song, Dian Yu, Juntao Li, Zhuosheng Zhang, Rui Wang, Zhaopeng Tu, Haitao Mi, Dong Yu</author><pubDate>Thu, 30 Jan 2025 18:58:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18585v1</guid></item><item><title>Accuracy and Robustness of Weight-Balancing Methods for Training PINNs</title><link>http://arxiv.org/abs/2501.18582v1</link><description>Physics-Informed Neural Networks (PINNs) have emerged as powerful tools forintegrating physics-based models with data by minimizing both data and physicslosses. However, this multi-objective optimization problem is notoriouslychallenging, with some benchmark problems leading to unfeasible solutions. Toaddress these issues, various strategies have been proposed, including adaptiveweight adjustments in the loss function. In this work, we introduce cleardefinitions of accuracy and robustness in the context of PINNs and propose anovel training algorithm based on the Primal-Dual (PD) optimization framework.Our approach enhances the robustness of PINNs while maintaining comparableperformance to existing weight-balancing methods. Numerical experimentsdemonstrate that the PD method consistently achieves reliable solutions acrossall investigated cases and can be easily implemented, facilitating itspractical adoption. The code is available athttps://github.com/haoming-SHEN/Accuracy-and-Robustness-of-Weight-Balancing-Methods-for-Training-PINNs.git.</description><author>Matthieu Barreau, Haoming Shen</author><pubDate>Thu, 30 Jan 2025 18:54:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18582v1</guid></item><item><title>Bias-variance decompositions: the exclusive privilege of Bregman divergences</title><link>http://arxiv.org/abs/2501.18581v1</link><description>Bias-variance decompositions are widely used to understand the generalizationperformance of machine learning models. While the squared error loss permits astraightforward decomposition, other loss functions - such as zero-one loss or$L_1$ loss - either fail to sum bias and variance to the expected loss or relyon definitions that lack the essential properties of meaningful bias andvariance. Recent research has shown that clean decompositions can be achievedfor the broader class of Bregman divergences, with the cross-entropy loss as aspecial case. However, the necessary and sufficient conditions for thesedecompositions remain an open question. In this paper, we address this question by studying continuous, nonnegativeloss functions that satisfy the identity of indiscernibles under mildregularity conditions. We prove that so-called $g$-Bregman divergences are theonly such loss functions that have a clean bias-variance decomposition. A$g$-Bregman divergence can be transformed into a standard Bregman divergencethrough an invertible change of variables. This makes the squared Mahalanobisdistance, up to such a variable transformation, the only symmetric lossfunction with a clean bias-variance decomposition. We also examine the impactof relaxing the restrictions on the loss functions and how this affects ourresults.</description><author>Tom Heskes</author><pubDate>Thu, 30 Jan 2025 18:52:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18581v1</guid></item><item><title>Node Classification and Search on the Rubik's Cube Graph with GNNs</title><link>http://arxiv.org/abs/2501.18580v1</link><description>This study focuses on the application of deep geometric models to solve the3x3x3 Rubik's Cube. We begin by discussing the cube's graph representation anddefining distance as the model's optimization objective. The distanceapproximation task is reformulated as a node classification problem,effectively addressed using Graph Neural Networks (GNNs). After training themodel on a random subgraph, the predicted classes are used to construct aheuristic for $A^*$ search. We conclude with experiments comparing ourheuristic to that of the DeepCubeA model.</description><author>Alessandro Barro</author><pubDate>Thu, 30 Jan 2025 18:52:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18580v1</guid></item><item><title>R.I.P.: Better Models by Survival of the Fittest Prompts</title><link>http://arxiv.org/abs/2501.18578v1</link><description>Training data quality is one of the most important drivers of final modelquality. In this work, we introduce a method for evaluating data integritybased on the assumption that low-quality input prompts result in high varianceand low quality responses. This is achieved by measuring the rejected responsequality and the reward gap between the chosen and rejected preference pair. Ourmethod, Rejecting Instruction Preferences (RIP) can be used to filter promptsfrom existing training sets, or to make high quality synthetic datasets,yielding large performance gains across various benchmarks compared tounfiltered data. Using Llama 3.1-8B-Instruct, RIP improves AlpacaEval2 LC WinRate by 9.4%, Arena-Hard by 8.7%, and WildBench by 9.9%. Using Llama3.3-70B-Instruct, RIP improves Arena-Hard from 67.5 to 82.9, which is from 18thplace to 6th overall in the leaderboard.</description><author>Ping Yu, Weizhe Yuan, Olga Golovneva, Tianhao Wu, Sainbayar Sukhbaatar, Jason Weston, Jing Xu</author><pubDate>Thu, 30 Jan 2025 18:50:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18578v1</guid></item><item><title>Vision-based autonomous structural damage detection using data-driven methods</title><link>http://arxiv.org/abs/2501.16662v2</link><description>This study addresses the urgent need for efficient and accurate damagedetection in wind turbine structures, a crucial component of renewable energyinfrastructure. Traditional inspection methods, such as manual assessments andnon-destructive testing (NDT), are often costly, time-consuming, and prone tohuman error. To tackle these challenges, this research investigates advanceddeep learning algorithms for vision-based structural health monitoring (SHM). Adataset of wind turbine surface images, featuring various damage types andpollution, was prepared and augmented for enhanced model training. Threealgorithms-YOLOv7, its lightweight variant, and Faster R-CNN- were employed todetect and classify surface damage. The models were trained and evaluated on adataset split into training, testing, and evaluation subsets (80%-10%-10%).Results indicate that YOLOv7 outperformed the others, achieving 82.4% mAP@50and high processing speed, making it suitable for real-time inspections. Byoptimizing hyperparameters like learning rate and batch size, the models'accuracy and efficiency improved further. YOLOv7 demonstrated significantadvancements in detection precision and execution speed, especially forreal-time applications. However, challenges such as dataset limitations andenvironmental variability were noted, suggesting future work on segmentationmethods and larger datasets. This research underscores the potential ofvision-based deep learning techniques to transform SHM practices by reducingcosts, enhancing safety, and improving reliability, thus contributing to thesustainable maintenance of critical infrastructure and supporting the longevityof wind energy systems.</description><author>Seyyed Taghi Ataei, Parviz Mohammad Zadeh, Saeid Ataei</author><pubDate>Thu, 30 Jan 2025 18:48:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16662v2</guid></item><item><title>Prediction-Powered Inference with Imputed Covariates and Nonuniform Sampling</title><link>http://arxiv.org/abs/2501.18577v1</link><description>Machine learning models are increasingly used to produce predictions thatserve as input data in subsequent statistical analyses. For example, computervision predictions of economic and environmental indicators based on satelliteimagery are used in downstream regressions; similarly, language models arewidely used to approximate human ratings and opinions in social scienceresearch. However, failure to properly account for errors in the machinelearning predictions renders standard statistical procedures invalid. Priorwork uses what we call the Predict-Then-Debias estimator to give validconfidence intervals when machine learning algorithms impute missing variables,assuming a small complete sample from the population of interest. We expand thescope by introducing bootstrap confidence intervals that apply when thecomplete data is a nonuniform (i.e., weighted, stratified, or clustered) sampleand to settings where an arbitrary subset of features is imputed. Importantly,the method can be applied to many settings without requiring additionalcalculations. We prove that these confidence intervals are valid under noassumptions on the quality of the machine learning model and are no wider thanthe intervals obtained by methods that do not use machine learning predictions.</description><author>Dan M. Kluger, Kerri Lu, Tijana Zrnic, Sherrie Wang, Stephen Bates</author><pubDate>Thu, 30 Jan 2025 18:46:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18577v1</guid></item><item><title>Token-Hungry, Yet Precise: DeepSeek R1 Highlights the Need for Multi-Step Reasoning Over Speed in MATH</title><link>http://arxiv.org/abs/2501.18576v1</link><description>This study investigates the performance of the DeepSeek R1 language model on30 challenging mathematical problems derived from the MATH dataset, problemsthat previously proved unsolvable by other models under time constraints.Unlike prior work, this research removes time limitations to explore whetherDeepSeek R1's architecture, known for its reliance on token-based reasoning,can achieve accurate solutions through a multi-step process. The study comparesDeepSeek R1 with four other models (gemini-1.5-flash-8b,gpt-4o-mini-2024-07-18, llama3.1:8b, and mistral-8b-latest) across 11temperature settings. Results demonstrate that DeepSeek R1 achieves superioraccuracy on these complex problems but generates significantly more tokens thanother models, confirming its token-intensive approach. The findings highlight atrade-off between accuracy and efficiency in mathematical problem-solving withlarge language models: while DeepSeek R1 excels in accuracy, its reliance onextensive token generation may not be optimal for applications requiring rapidresponses. The study underscores the importance of considering task-specificrequirements when selecting an LLM and emphasizes the role of temperaturesettings in optimizing performance.</description><author>Evgenii Evstafev</author><pubDate>Thu, 30 Jan 2025 18:45:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18576v1</guid></item><item><title>BounTCHA: A CAPTCHA Utilizing Boundary Identification in AI-extended Videos</title><link>http://arxiv.org/abs/2501.18565v1</link><description>In recent years, the rapid development of artificial intelligence (AI)especially multi-modal Large Language Models (MLLMs), has enabled it tounderstand text, images, videos, and other multimedia data, allowing AI systemsto execute various tasks based on human-provided prompts. However, AI-poweredbots have increasingly been able to bypass most existing CAPTCHA systems,posing significant security threats to web applications. This makes the designof new CAPTCHA mechanisms an urgent priority. We observe that humans are highlysensitive to shifts and abrupt changes in videos, while current AI systemsstill struggle to comprehend and respond to such situations effectively. Basedon this observation, we design and implement BounTCHA, a CAPTCHA mechanism thatleverages human perception of boundaries in video transitions and disruptions.By utilizing AI's capability to expand original videos with prompts, weintroduce unexpected twists and changes to create a pipeline for generatingshort videos for CAPTCHA purposes. We develop a prototype and conductexperiments to collect data on humans' time biases in boundary identification.This data serves as a basis for distinguishing between human users and bots.Additionally, we perform a detailed security analysis of BounTCHA,demonstrating its resilience against various types of attacks. We hope thatBounTCHA will act as a robust defense, safeguarding millions of webapplications in the AI-driven era.</description><author>Lehao Lin, Ke Wang, Maha Abdallah, Wei Cai</author><pubDate>Thu, 30 Jan 2025 18:38:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18565v1</guid></item><item><title>No Equations Needed: Learning System Dynamics Without Relying on Closed-Form ODEs</title><link>http://arxiv.org/abs/2501.18563v1</link><description>Data-driven modeling of dynamical systems is a crucial area of machinelearning. In many scenarios, a thorough understanding of the model's behaviorbecomes essential for practical applications. For instance, understanding thebehavior of a pharmacokinetic model, constructed as part of drug development,may allow us to both verify its biological plausibility (e.g., the drugconcentration curve is non-negative and decays to zero) and to design dosingguidelines. Discovery of closed-form ordinary differential equations (ODEs) canbe employed to obtain such insights by finding a compact mathematical equationand then analyzing it (a two-step approach). However, its widespread use iscurrently hindered because the analysis process may be time-consuming,requiring substantial mathematical expertise, or even impossible if theequation is too complex. Moreover, if the found equation's behavior does notsatisfy the requirements, editing it or influencing the discovery algorithms torectify it is challenging as the link between the symbolic form of an ODE andits behavior can be elusive. This paper proposes a conceptual shift to modelinglow-dimensional dynamical systems by departing from the traditional two-stepmodeling process. Instead of first discovering a closed-form equation and thenanalyzing it, our approach, direct semantic modeling, predicts the semanticrepresentation of the dynamical system (i.e., description of its behavior)directly from data, bypassing the need for complex post-hoc analysis. Thisdirect approach also allows the incorporation of intuitive inductive biasesinto the optimization algorithm and editing the model's behavior directly,ensuring that the model meets the desired specifications. Our approach not onlysimplifies the modeling pipeline but also enhances the transparency andflexibility of the resulting models compared to traditional closed-form ODEs.</description><author>Krzysztof Kacprzyk, Mihaela van der Schaar</author><pubDate>Thu, 30 Jan 2025 18:36:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18563v1</guid></item><item><title>Bandits with Anytime Knapsacks</title><link>http://arxiv.org/abs/2501.18560v1</link><description>We consider bandits with anytime knapsacks (BwAK), a novel version of the BwKproblem where there is an \textit{anytime} cost constraint instead of a totalcost budget. This problem setting introduces additional complexities as itmandates adherence to the constraint throughout the decision-making process. Wepropose SUAK, an algorithm that utilizes upper confidence bounds to identifythe optimal mixture of arms while maintaining a balance between exploration andexploitation. SUAK is an adaptive algorithm that strategically utilizes theavailable budget in each round in the decision-making process and skips a roundwhen it is possible to violate the anytime cost constraint. In particular, SUAKslightly under-utilizes the available cost budget to reduce the need forskipping rounds. We show that SUAK attains the same problem-dependent regretupper bound of $ O(K \log T)$ established in prior work under the simpler BwKframework. Finally, we provide simulations to verify the utility of SUAK inpractical settings.</description><author>Eray Can Elumar, Cem Tekin, Osman Yagan</author><pubDate>Thu, 30 Jan 2025 18:36:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18560v1</guid></item><item><title>Perspectives: Comparison of Deep Learning Segmentation Models on Biophysical and Biomedical Data</title><link>http://arxiv.org/abs/2408.07786v2</link><description>Deep learning based approaches are now widely used across biophysics to helpautomate a variety of tasks including image segmentation, feature selection,and deconvolution. However, the presence of multiple competing deep learningarchitectures, each with its own unique advantages and disadvantages, makes itchallenging to select an architecture best suited for a specific application.As such, we present a comprehensive comparison of common models. Here, we focuson the task of segmentation assuming the typically small training dataset sizesavailable from biophysics experiments and compare the following four commonlyused architectures: convolutional neural networks, U-Nets, vision transformers,and vision state space models. In doing so, we establish criteria fordetermining optimal conditions under which each model excels, thereby offeringpractical guidelines for researchers and practitioners in the field.</description><author>J Shepard Bryan IV, Pedro Pessoa, Meyam Tavakoli, Steve Presse</author><pubDate>Thu, 30 Jan 2025 18:18:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07786v2</guid></item><item><title>More Expressive Attention with Negative Weights</title><link>http://arxiv.org/abs/2411.07176v3</link><description>We propose a novel attention mechanism, named Cog Attention, that enablesattention weights to be negative for enhanced expressiveness, which stems fromtwo key factors: (1) Cog Attention enhances parameter flexibility. For example,unlike traditional softmax attention heads that use a static output-value (OV)matrix to delete or copy inputs that the heads attend to, Cog Attentionnaturally learns to use the sign of dynamic query-key (QK) inner products torepresent these operations. This enables Cog Attention to perform multipleoperations simultaneously within a single head. Meanwhile, Cog Attention's OVmatrix can focus more on refinement or modification. (2) Cog Attention enhancesthe model's robustness against representational collapse by preventing the``over-squashing'' of earlier tokens into later positions. We developTransformer-like models which use Cog Attention as attention modules, includingdecoder-only models at various scales for language modeling and U-ViT diffusionmodels for image generation. Experiments show that models using Cog Attentionexhibit superior performance compared to those employing traditional softmaxattention modules. Our approach suggests a promising research direction forrethinking and breaking the entrenched constraints of traditional softmaxattention, such as the requirement for non-negative weights.</description><author>Ang Lv, Ruobing Xie, Shuaipeng Li, Jiayi Liao, Xingwu Sun, Zhanhui Kang, Di Wang, Rui Yan</author><pubDate>Thu, 30 Jan 2025 18:17:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07176v3</guid></item><item><title>R-LLaVA: Improving Med-VQA Understanding through Visual Region of Interest</title><link>http://arxiv.org/abs/2410.20327v3</link><description>Artificial intelligence has made significant strides in medical visualquestion answering (Med-VQA), yet prevalent studies often interpret imagesholistically, overlooking the visual regions of interest that may containcrucial information, potentially aligning with a doctor's prior knowledge thatcan be incorporated with minimal annotations (e.g., bounding boxes). To addressthis gap, this paper introduces R-LLaVA, designed to enhance biomedical VQAunderstanding by integrating simple medical annotations as prior knowledgedirectly into the image space through CLIP. These annotated visual regions ofinterest are then fed into the LLaVA model during training, aiming to enrichthe model's understanding of biomedical queries. Experimental evaluation onfour standard Med-VQA datasets demonstrates R-LLaVA's superiority over existingstate-of-the-art (SoTA) methods. Additionally, to verify the model's capabilityin visual comprehension, a novel multiple-choice medical visual understandingdataset is introduced, confirming the positive impact of focusing on visualregions of interest in advancing biomedical VQA understanding.</description><author>Xupeng Chen, Zhixin Lai, Kangrui Ruan, Shichu Chen, Jiaxiang Liu, Zuozhu Liu</author><pubDate>Thu, 30 Jan 2025 18:16:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20327v3</guid></item><item><title>UDC-VIT: A Real-World Video Dataset for Under-Display Cameras</title><link>http://arxiv.org/abs/2501.18545v1</link><description>Under Display Camera (UDC) is an advanced imaging system that places adigital camera lens underneath a display panel, effectively concealing thecamera. However, the display panel significantly degrades captured images orvideos, introducing low transmittance, blur, noise, and flare issues. Tacklingsuch issues is challenging because of the complex degradation of UDCs,including diverse flare patterns. Despite extensive research on UDC images andtheir restoration models, studies on videos have yet to be significantlyexplored. While two UDC video datasets exist, they primarily focus onunrealistic or synthetic UDC degradation rather than real-world UDCdegradation. In this paper, we propose a real-world UDC video dataset calledUDC-VIT. Unlike existing datasets, only UDC-VIT exclusively includes humanmotions that target facial recognition. We propose a video-capturing system tosimultaneously acquire non-degraded and UDC-degraded videos of the same scene.Then, we align a pair of captured videos frame by frame, using discrete Fouriertransform (DFT). We compare UDC-VIT with six representative UDC still imagedatasets and two existing UDC video datasets. Using six deep-learning models,we compare UDC-VIT and an existing synthetic UDC video dataset. The resultsindicate the ineffectiveness of models trained on earlier synthetic UDC videodatasets, as they do not reflect the actual characteristics of UDC-degradedvideos. We also demonstrate the importance of effective UDC restoration byevaluating face recognition accuracy concerning PSNR, SSIM, and LPIPS scores.UDC-VIT enables further exploration in the UDC video restoration and offersbetter insights into the challenge. UDC-VIT is available at our project site.</description><author>Kyusu Ahn, JiSoo Kim, Sangik Lee, HyunGyu Lee, Byeonghyun Ko, Chanwoo Park, Jaejin Lee</author><pubDate>Thu, 30 Jan 2025 18:13:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18545v1</guid></item><item><title>Verify with Caution: The Pitfalls of Relying on Imperfect Factuality Metrics</title><link>http://arxiv.org/abs/2501.14883v2</link><description>Improvements in large language models have led to increasing optimism thatthey can serve as reliable evaluators of natural language generation outputs.In this paper, we challenge this optimism by thoroughly re-evaluating fivestate-of-the-art factuality metrics on a collection of 11 datasets forsummarization, retrieval-augmented generation, and question answering. We findthat these evaluators are inconsistent with each other and often misestimatesystem-level performance, both of which can lead to a variety of pitfalls. Wefurther show that these metrics exhibit biases against highly paraphrasedoutputs and outputs that draw upon faraway parts of the source documents. Weurge users of these factuality metrics to proceed with caution and manuallyvalidate the reliability of these metrics in their domain of interest beforeproceeding.</description><author>Ameya Godbole, Robin Jia</author><pubDate>Thu, 30 Jan 2025 18:13:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14883v2</guid></item><item><title>Learning Priors of Human Motion With Vision Transformers</title><link>http://arxiv.org/abs/2501.18543v1</link><description>A clear understanding of where humans move in a scenario, their usual pathsand speeds, and where they stop, is very important for different applications,such as mobility studies in urban areas or robot navigation tasks withinhuman-populated environments. We propose in this article, a neural architecturebased on Vision Transformers (ViTs) to provide this information. This solutioncan arguably capture spatial correlations more effectively than ConvolutionalNeural Networks (CNNs). In the paper, we describe the methodology and proposedneural architecture and show the experiments' results with a standard dataset.We show that the proposed ViT architecture improves the metrics compared to amethod based on a CNN.</description><author>Placido Falqueto, Alberto Sanfeliu, Luigi Palopoli, Daniele Fontanelli</author><pubDate>Thu, 30 Jan 2025 18:12:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18543v1</guid></item><item><title>Semantic Web and Creative AI -- A Technical Report from ISWS 2023</title><link>http://arxiv.org/abs/2501.18542v1</link><description>The International Semantic Web Research School (ISWS) is a week-longintensive program designed to immerse participants in the field. This documentreports a collaborative effort performed by ten teams of students, each guidedby a senior researcher as their mentor, attending ISWS 2023. Each team provideda different perspective to the topic of creative AI, substantiated by a set ofresearch questions as the main subject of their investigation. The 2023 editionof ISWS focuses on the intersection of Semantic Web technologies and CreativeAI. ISWS 2023 explored various intersections between Semantic Web technologiesand creative AI. A key area of focus was the potential of LLMs as support toolsfor knowledge engineering. Participants also delved into the multifacetedapplications of LLMs, including legal aspects of creative content production,humans in the loop, decentralised approaches to multimodal generative AImodels, nanopublications and AI for personal scientific knowledge graphs,commonsense knowledge in automatic story and narrative completion, generativeAI for art critique, prompt engineering, automatic music composition,commonsense prototyping and conceptual blending, and elicitation of tacitknowledge. As Large Language Models and semantic technologies continue toevolve, new exciting prospects are emerging: a future where the boundariesbetween creative expression and factual knowledge become increasingly permeableand porous, leading to a world of knowledge that is both informative andinspiring.</description><author>Raia Abu Ahmad, Reham Alharbi, Roberto Barile, Martin Böckling, Francisco Bolanos, Sara Bonfitto, Oleksandra Bruns, Irene Celino, Yashrajsinh Chudasama, Martin Critelli, Claudia d'Amato, Giada D'Ippolito, Ioannis Dasoulas, Stefano De Giorgis, Vincenzo De Leo, Chiara Di Bonaventura, Marco Di Panfilo, Daniil Dobriy, John Domingue, Xuemin Duan, Michel Dumontier, Sefika Efeoglu, Ruben Eschauzier, Fakih Ginwa, Nicolas Ferranti, Arianna Graciotti, Philipp Hanisch, George Hannah, Golsa Heidari, Aidan Hogan, Hassan Hussein, Alexane Jouglar, Jan-Christoph Kalo, Manoé Kieffer, Antonis Klironomos, Inês Koch, Weronika Lajewska, Nicolas Lazzari, Mikael Lindekrans, Anna Sofia Lippolis, Majlinda Llugiqi, Eleonora Mancini, Eleonora Marzi, Laura Menotti, Daniela Milon Flores, Soulakshmee Nagowah, Kerstin N</author><pubDate>Thu, 30 Jan 2025 18:10:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18542v1</guid></item><item><title>Technical report on label-informed logit redistribution for better domain generalization in low-shot classification with foundation models</title><link>http://arxiv.org/abs/2501.17595v2</link><description>Confidence calibration is an emerging challenge in real-world decisionsystems based on foundations models when used for downstream visionclassification tasks. Due to various reasons exposed, logit scores on the CLIPhead remain large irrespective of whether the image-language pairs reconcile.It is difficult to address in data space, given the few-shot regime. We proposea penalty incorporated into loss objective that penalizes incorrectclassifications whenever one is made during finetuning, by moving an amount oflog-likelihood to the true class commensurate to the relative amplitudes of thetwo likelihoods. We refer to it as \textit{confidence misalignment penalty(CMP)}. Extensive experiments on $12$ vision datasets and $5$ domaingeneralization datasets supports the calibration performance of our methodagainst stat-of-the-art. CMP outperforms the benchmarked prompt learningmethods, demonstrating average improvement in Expected Calibration Error (ECE)by average $6.01$\%, $4.01$ \% at minimum and $9.72$\% at maximum.</description><author>Behraj Khan, Tahir Syed</author><pubDate>Thu, 30 Jan 2025 18:07:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17595v2</guid></item><item><title>Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method</title><link>http://arxiv.org/abs/2501.18539v1</link><description>Real-world open-domain questions can be complicated, particularly whenanswering them involves information from multiple information sources. LLMshave demonstrated impressive performance in decomposing complex tasks intosimpler steps, and previous work has used it for better retrieval in support ofcomplex questions. However, LLM's decomposition of questions is unaware of whatdata is available and how data is organized, often leading to a sub-optimalretrieval performance. Recent effort in agentic RAG proposes to performretrieval in an iterative fashion, where a followup query is derived as anaction based on previous rounds of retrieval. While this provides one way ofinteracting with the data collection, agentic RAG's exploration of data isinefficient because successive queries depend on previous results rather thanbeing guided by the organization of available data in the collection. Toaddress this problem, we propose an LLM-based retrieval method -- ARM, thataims to better align the question with the organization of the data collectionby exploring relationships among data objects beyond matching the utterance ofthe query, thus leading to a retrieve-all-at-once solution for complex queries.We evaluated ARM on two datasets, Bird and OTT-QA. On Bird, it outperformsstandard RAG with query decomposition by up to 5.2 pt in execution accuracy andagentic RAG (ReAct) by up to 15.9 pt. On OTT-QA, it achieves up to 5.5 pt and19.3 pt higher F1 match scores compared to these approaches.</description><author>Peter Baile Chen, Yi Zhang, Michael Cafarella, Dan Roth</author><pubDate>Thu, 30 Jan 2025 18:07:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18539v1</guid></item><item><title>Mini-ResEmoteNet: Leveraging Knowledge Distillation for Human-Centered Design</title><link>http://arxiv.org/abs/2501.18538v1</link><description>Facial Emotion Recognition has emerged as increasingly pivotal in the domainof User Experience, notably within modern usability testing, as it facilitatesa deeper comprehension of user satisfaction and engagement. This study aims toextend the ResEmoteNet model by employing a knowledge distillation framework todevelop Mini-ResEmoteNet models - lightweight student models - tailored forusability testing. Experiments were conducted on the FER2013 and RAF-DBdatasets to assess the efficacy of three student model architectures: StudentModel A, Student Model B, and Student Model C. Their development involvesreducing the number of feature channels in each layer of the teacher model byapproximately 50%, 75%, and 87.5%. Demonstrating exceptional performance on theFER2013 dataset, Student Model A (E1) achieved a test accuracy of 76.33%,marking a 0.21% absolute improvement over EmoNeXt. Moreover, the resultsexhibit absolute improvements in terms of inference speed and memory usageduring inference compared to the ResEmoteNet model. The findings indicate thatthe proposed methods surpass other state-of-the-art approaches.</description><author>Amna Murtada, Omnia Abdelrhman, Tahani Abdalla Attia</author><pubDate>Thu, 30 Jan 2025 18:06:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18538v1</guid></item><item><title>Loss Functions and Operators Generated by f-Divergences</title><link>http://arxiv.org/abs/2501.18537v1</link><description>The logistic loss (a.k.a. cross-entropy loss) is one of the most popular lossfunctions used for multiclass classification. It is also the loss function ofchoice for next-token prediction in language modeling. It is associated withthe Kullback--Leibler (KL) divergence and the softargmax operator. In thiswork, we propose to construct new convex loss functions based on$f$-divergences. Our loss functions generalize the logistic loss in twodirections: i) by replacing the KL divergence with $f$-divergences and ii) byallowing non-uniform reference measures. We instantiate our framework fornumerous $f$-divergences, recovering existing losses and creating new ones. Byanalogy with the logistic loss, the loss function generated by an$f$-divergence is associated with an operator, that we dub $f$-softargmax. Wederive a novel parallelizable bisection algorithm for computing the$f$-softargmax associated with any $f$-divergence. On the empirical side, oneof the goals of this paper is to determine the effectiveness of loss functionsbeyond the classical cross-entropy in a language model setting, including onpre-training, post-training (SFT) and distillation. We show that the lossfunction generated by the $\alpha$-divergence (which is equivalent to Tsallis$\alpha$-negentropy in the case of unit reference measures) with $\alpha=1.5$performs well across several tasks.</description><author>Vincent Roulet, Tianlin Liu, Nino Vieillard, Michael E. Sander, Mathieu Blondel</author><pubDate>Thu, 30 Jan 2025 18:06:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18537v1</guid></item><item><title>A Hybrid Data-Driven Approach For Analyzing And Predicting Inpatient Length Of Stay In Health Centre</title><link>http://arxiv.org/abs/2501.18535v1</link><description>Patient length of stay (LoS) is a critical metric for evaluating the efficacyof hospital management. The primary objectives encompass to improve efficiencyand reduce costs while enhancing patient outcomes and hospital capacity withinthe patient journey. By seamlessly merging data-driven techniques withsimulation methodologies, the study proposes an all-encompassing framework forthe optimization of patient flow. Using a comprehensive dataset of 2.3 millionde-identified patient records, we analyzed demographics, diagnoses, treatments,services, costs, and charges with machine learning models (Decision Tree,Logistic Regression, Random Forest, Adaboost, LightGBM) and Python tools(Spark, AWS clusters, dimensionality reduction). Our model predicts patientlength of stay (LoS) upon admission using supervised learning algorithms. Thishybrid approach enables the identification of key factors influencing LoS,offering a robust framework for hospitals to streamline patient flow andresource utilization. The research focuses on patient flow, corroborating theefficacy of the approach, illustrating decreased patient length of stay withina real healthcare environment. The findings underscore the potential of hybriddata-driven models in transforming hospital management practices. Thisinnovative methodology provides generally flexible decision-making, training,and patient flow enhancement; such a system could have huge implications forhealthcare administration and overall satisfaction with healthcare.</description><author>Tasfia Noor Chowdhury, Sanjida Afrin Mou, Kazi Naimur Rahman</author><pubDate>Thu, 30 Jan 2025 18:01:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18535v1</guid></item><item><title>Rethinking Bottlenecks in Safety Fine-Tuning of Vision Language Models</title><link>http://arxiv.org/abs/2501.18533v1</link><description>Large Vision-Language Models (VLMs) have achieved remarkable performanceacross a wide range of tasks. However, their deployment in safety-criticaldomains poses significant challenges. Existing safety fine-tuning methods,which focus on textual or multimodal content, fall short in addressingchallenging cases or disrupt the balance between helpfulness and harmlessness.Our evaluation highlights a safety reasoning gap: these methods lack safetyvisual reasoning ability, leading to such bottlenecks. To address thislimitation and enhance both visual perception and reasoning in safety-criticalcontexts, we propose a novel dataset that integrates multi-image inputs withsafety Chain-of-Thought (CoT) labels as fine-grained reasoning logic to improvemodel performance. Specifically, we introduce the Multi-Image Safety (MIS)dataset, an instruction-following dataset tailored for multi-image safetyscenarios, consisting of training and test splits. Our experiments demonstratethat fine-tuning InternVL2.5-8B with MIS significantly outperforms bothpowerful open-source models and API-based models in challenging multi-imagetasks requiring safety-related visual reasoning. This approach not onlydelivers exceptional safety performance but also preserves general capabilitieswithout any trade-offs. Specifically, fine-tuning with MIS increases averageaccuracy by 0.83% across five general benchmarks and reduces the Attack SuccessRate (ASR) on multiple safety benchmarks by a large margin. Data and Models arereleased under:\href{https://dripnowhy.github.io/MIS/}{\texttt{https://dripnowhy.github.io/MIS/}}</description><author>Yi Ding, Lijun Li, Bing Cao, Jing Shao</author><pubDate>Thu, 30 Jan 2025 17:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18533v1</guid></item><item><title>In-Context Meta LoRA Generation</title><link>http://arxiv.org/abs/2501.17635v2</link><description>Low-rank Adaptation (LoRA) has demonstrated remarkable capabilities for taskspecific fine-tuning. However, in scenarios that involve multiple tasks,training a separate LoRA model for each one results in considerableinefficiency in terms of storage and inference. Moreover, existing parametergeneration methods fail to capture the correlations among these tasks, makingmulti-task LoRA parameter generation challenging. To address these limitations,we propose In-Context Meta LoRA (ICM-LoRA), a novel approach that efficientlyachieves task-specific customization of large language models (LLMs).Specifically, we use training data from all tasks to train a tailoredgenerator, Conditional Variational Autoencoder (CVAE). CVAE takes taskdescriptions as inputs and produces task-aware LoRA weights as outputs. TheseLoRA weights are then merged with LLMs to create task-specialized modelswithout the need for additional fine-tuning. Furthermore, we utilize in-contextmeta-learning for knowledge enhancement and task mapping, to capture therelationship between tasks and parameter distributions. As a result, our methodachieves more accurate LoRA parameter generation for diverse tasks using CVAE.ICM-LoRA enables more accurate LoRA parameter reconstruction than currentparameter reconstruction methods and is useful for implementing task-specificenhancements of LoRA parameters. At the same time, our method occupies 283MB,only 1\% storage compared with the original LoRA.</description><author>Yihua Shao, Minxi Yan, Yang Liu, Siyu Chen, Wenjie Chen, Xinwei Long, Ziyang Yan, Lei Li, Chenyu Zhang, Nicu Sebe, Hao Tang, Yan Wang, Hao Zhao, Mengzhu Wang, Jingcai Guo</author><pubDate>Thu, 30 Jan 2025 17:59:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17635v2</guid></item><item><title>Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate</title><link>http://arxiv.org/abs/2501.17703v2</link><description>Supervised Fine-Tuning (SFT) is commonly used to train language models toimitate annotated responses for given instructions. In this paper, we challengethis paradigm and propose Critique Fine-Tuning (CFT), a strategy where modelslearn to critique noisy responses rather than simply imitate correct ones.Inspired by human learning processes that emphasize critical thinking, CFTencourages deeper analysis and nuanced understanding-traits often overlooked bystandard SFT. To validate the effectiveness of CFT, we construct a 50K-sampledataset from WebInstruct, using GPT-4o as the teacher to generate critiques inthe form of ([query; noisy response], critique). CFT on this dataset yields aconsistent 4-10% improvement over SFT on six math benchmarks with differentbase models like Qwen2.5, Qwen2.5-Math and DeepSeek-Math. We further expand toMetaMath and NuminaMath datasets and observe similar gains over SFT. Notably,our model Qwen2.5-Math-CFT only requires 1 hour training on 8xH100 over the 50Kexamples. It can match or outperform strong competitors likeQwen2.5-Math-Instruct on most benchmarks, which use over 2M samples. Moreover,it can match the performance of SimpleRL, which is a deepseek-r1 replicationtrained with 140x more compute. Ablation studies show that CFT is robust to thesource of noisy response and teacher critique model. Through these findings, weargue that CFT offers a more effective alternative to advance the reasoning oflanguage models.</description><author>Yubo Wang, Xiang Yue, Wenhu Chen</author><pubDate>Thu, 30 Jan 2025 17:58:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17703v2</guid></item><item><title>Differentially Private Steering for Large Language Model Alignment</title><link>http://arxiv.org/abs/2501.18532v1</link><description>Aligning Large Language Models (LLMs) with human values and away fromundesirable behaviors (such as hallucination) has become increasinglyimportant. Recently, steering LLMs towards a desired behavior via activationediting has emerged as an effective method to mitigate harmful generations atinference-time. Activation editing modifies LLM representations by preservinginformation from positive demonstrations (e.g., truthful) and minimisinginformation from negative demonstrations (e.g., hallucinations). When thesedemonstrations come from a private dataset, the aligned LLM may leak privateinformation contained in those private samples. In this work, we present thefirst study of aligning LLM behavior with private datasets. Our work proposesthe \textit{\underline{P}rivate \underline{S}teering for LLM\underline{A}lignment (PSA)} algorithm to edit LLM activations withdifferential privacy (DP) guarantees. We conduct extensive experiments on sevendifferent benchmarks with open-source LLMs of different sizes (0.5B to 7B) andmodel families (LlaMa, Qwen, Mistral and Gemma). Our results show that PSAachieves DP guarantees for LLM alignment with minimal loss in performance,including alignment metrics, open-ended text generation quality, andgeneral-purpose reasoning. We also develop the first Membership InferenceAttack (MIA) for evaluating and auditing the empirical privacy for the problemof LLM steering via activation editing. Our attack is tailored for activationediting and relies solely on the generated texts without their associatedprobabilities. Our experiments support the theoretical guarantees by showingimproved guarantees for our \textit{PSA} algorithm compared to several existingnon-private techniques.</description><author>Anmol Goel, Yaxi Hu, Iryna Gurevych, Amartya Sanyal</author><pubDate>Thu, 30 Jan 2025 17:58:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18532v1</guid></item><item><title>Graph Learning for Bidirectional Disease Contact Tracing on Real Human Mobility Data</title><link>http://arxiv.org/abs/2501.18531v1</link><description>For rapidly spreading diseases where many cases show no symptoms, swift andeffective contact tracing is essential. While exposure notificationapplications provide alerts on potential exposures, a fully automated system isneeded to track the infectious transmission routes. To this end, our researchleverages large-scale contact networks from real human mobility data toidentify the path of transmission. More precisely, we introduce a newInfectious Path Centrality network metric that informs a graph learning edgeclassifier to identify important transmission events, achieving an F1-score of94%. Additionally, we explore bidirectional contact tracing, which quarantinesindividuals both retroactively and proactively, and compare its effectivenessagainst traditional forward tracing, which only isolates individuals aftertesting positive. Our results indicate that when only 30% of symptomaticindividuals are tested, bidirectional tracing can reduce infectious effectivereproduction rate by 71%, thus significantly controlling the outbreak.</description><author>Sofia Hurtado, Radu Marculescu</author><pubDate>Thu, 30 Jan 2025 17:57:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18531v1</guid></item><item><title>Optimal generalisation and learning transition in extensive-width shallow neural networks near interpolation</title><link>http://arxiv.org/abs/2501.18530v1</link><description>We consider a teacher-student model of supervised learning with afully-trained 2-layer neural network whose width $k$ and input dimension $d$are large and proportional. We compute the Bayes-optimal generalisation errorof the network for any activation function in the regime where the number oftraining data $n$ scales quadratically with the input dimension, i.e., aroundthe interpolation threshold where the number of trainable parameters $kd+k$ andof data points $n$ are comparable. Our analysis tackles generic weightdistributions. Focusing on binary weights, we uncover a discontinuous phasetransition separating a "universal" phase from a "specialisation" phase. In thefirst, the generalisation error is independent of the weight distribution anddecays slowly with the sampling rate $n/d^2$, with the student learning onlysome non-linear combinations of the teacher weights. In the latter, the erroris weight distribution-dependent and decays faster due to the alignment of thestudent towards the teacher network. We thus unveil the existence of a highlypredictive solution near interpolation, which is however potentially hard tofind.</description><author>Jean Barbier, Francesco Camilli, Minh-Toan Nguyen, Mauro Pastore, Rudy Skerk</author><pubDate>Thu, 30 Jan 2025 17:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18530v1</guid></item><item><title>S-LoRA: Scalable Low-Rank Adaptation for Class Incremental Learning</title><link>http://arxiv.org/abs/2501.13198v2</link><description>Continual Learning with foundation models has recently emerged as a promisingapproach to harnessing the power of pre-trained models for sequential tasks.Existing prompt-based methods generally use a gating mechanism to selectrelevant prompts aligned with the test query for further processing. However,the success of these methods largely depends on the precision of the gatingmechanism, which becomes less scalable with additional computational overheadas tasks increases. To overcome these issues, we propose a Scalable Low-RankAdaptation (S-LoRA) method for CL (in particular class incremental learning),which incrementally decouples the learning of the direction and magnitude ofLoRA parameters. S-LoRA supports efficient inference by employing thelast-stage trained model for direct testing without a gating process. Ourtheoretical and empirical analysis demonstrates that S-LoRA tends to follow alow-loss trajectory that converges to an overlapped low-loss region, resultingin an excellent stability-plasticity trade-off in CL. Furthermore, based on ourfindings, we develop variants of S-LoRA with further improved scalability.Extensive experiments across multiple CL benchmarks and various foundationmodels consistently validate the effectiveness of S-LoRA.</description><author>Yichen Wu, Hongming Piao, Long-Kai Huang, Renzhen Wang, Wanhua Li, Hanspeter Pfister, Deyu Meng, Kede Ma, Ying Wei</author><pubDate>Thu, 30 Jan 2025 17:55:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13198v2</guid></item><item><title>Towards Automated Penetration Testing: Introducing LLM Benchmark, Analysis, and Improvements</title><link>http://arxiv.org/abs/2410.17141v3</link><description>Hacking poses a significant threat to cybersecurity, inflicting billions ofdollars in damages annually. To mitigate these risks, ethical hacking, orpenetration testing, is employed to identify vulnerabilities in systems andnetworks. Recent advancements in large language models (LLMs) have shownpotential across various domains, including cybersecurity. However, there iscurrently no comprehensive, open, end-to-end automated penetration testingbenchmark to drive progress and evaluate the capabilities of these models insecurity contexts. This paper introduces a novel open benchmark for LLM-basedautomated penetration testing, addressing this critical gap. We first evaluatethe performance of LLMs, including GPT-4o and Llama 3.1-405B, using thestate-of-the-art PentestGPT tool. Our findings reveal that while Llama 3.1demonstrates an edge over GPT-4o, both models currently fall short ofperforming fully automated, end-to-end penetration testing. Next, we advancethe state-of-the-art and present ablation studies that provide insights intoimproving the PentestGPT tool. Our research illuminates the challenges LLMsface in each aspect of Pentesting, e.g. enumeration, exploitation, andprivilege escalation. This work contributes to the growing body of knowledge onAI-assisted cybersecurity and lays the foundation for future research inautomated penetration testing using large language models.</description><author>Isamu Isozaki, Manil Shrestha, Rick Console, Edward Kim</author><pubDate>Thu, 30 Jan 2025 17:50:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17141v3</guid></item><item><title>A conditional gradient homotopy method with applications to Semidefinite Programming</title><link>http://arxiv.org/abs/2207.03101v3</link><description>We propose a new homotopy-based conditional gradient method for solvingconvex optimization problems with a large number of simple conic constraints.Instances of this template naturally appear in semidefinite programmingproblems arising as convex relaxations of combinatorial optimization problems.Our method is a double-loop algorithm in which the conic constraint is treatedvia a self-concordant barrier, and the inner loop employs a conditionalgradient algorithm to approximate the analytic central path, while the outerloop updates the accuracy imposed on the temporal solution and the homotopyparameter. Our theoretical iteration complexity is competitive when confrontedto state-of-the-art SDP solvers, with the decisive advantage of cheapprojection-free subroutines. Preliminary numerical experiments are provided forillustrating the practical performance of the method.</description><author>Pavel Dvurechensky, Gabriele Iommazzo, Shimrit Shtern, Mathias Staudigl</author><pubDate>Thu, 30 Jan 2025 17:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.03101v3</guid></item><item><title>Joint Learning of Energy-based Models and their Partition Function</title><link>http://arxiv.org/abs/2501.18528v1</link><description>Energy-based models (EBMs) offer a flexible framework for parameterizingprobability distributions using neural networks. However, learning EBMs byexact maximum likelihood estimation (MLE) is generally intractable, due to theneed to compute the partition function (normalization constant). In this paper,we propose a novel formulation for approximately learning probabilistic EBMs incombinatorially-large discrete spaces, such as sets or permutations. Our keyidea is to jointly learn both an energy model and its log-partition, bothparameterized as a neural network. Our approach not only provides a noveltractable objective criterion to learn EBMs by stochastic gradient descent(without relying on MCMC), but also a novel means to estimate the log-partitionfunction on unseen data points. On the theoretical side, we show that ourapproach recovers the optimal MLE solution when optimizing in the space ofcontinuous functions. Furthermore, we show that our approach naturally extendsto the broader family of Fenchel-Young losses, allowing us to obtain the firsttractable method for optimizing the sparsemax loss in combinatorially-largespaces. We demonstrate our approach on multilabel classification and labelranking.</description><author>Michael E. Sander, Vincent Roulet, Tianlin Liu, Mathieu Blondel</author><pubDate>Thu, 30 Jan 2025 17:46:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18528v1</guid></item><item><title>Neural Discovery in Mathematics: Do Machines Dream of Colored Planes?</title><link>http://arxiv.org/abs/2501.18527v1</link><description>We demonstrate how neural networks can drive mathematical discovery through acase study of the Hadwiger-Nelson problem, a long-standing open problem fromdiscrete geometry and combinatorics about coloring the plane avoidingmonochromatic unit-distance pairs. Using neural networks as approximators, wereformulate this mixed discrete-continuous geometric coloring problem as anoptimization task with a probabilistic, differentiable loss function. Thisenables gradient-based exploration of admissible configurations that mostsignificantly led to the discovery of two novel six-colorings, providing thefirst improvements in thirty years to the off-diagonal variant of the originalproblem (Mundinger et al., 2024a). Here, we establish the underlying machinelearning approach used to obtain these results and demonstrate its broaderapplicability through additional results and numerical insights.</description><author>Konrad Mundinger, Max Zimmer, Aldo Kiem, Christoph Spiegel, Sebastian Pokutta</author><pubDate>Thu, 30 Jan 2025 17:44:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18527v1</guid></item><item><title>Density Matrix Emulation of Quantum Recurrent Neural Networks for Multivariate Time Series Prediction</title><link>http://arxiv.org/abs/2310.20671v2</link><description>Quantum Recurrent Neural Networks (QRNNs) are robust candidates for modellingand predicting future values in multivariate time series. However, theeffective implementation of some QRNN models is limited by the need formid-circuit measurements. Those increase the requirements for quantum hardware,which in the current NISQ era does not allow reliable computations. Emulationarises as the main near-term alternative to explore the potential of QRNNs, butexisting quantum emulators are not dedicated to circuits with multipleintermediate measurements. In this context, we design a specific emulationmethod that relies on density matrix formalism. Using a compact tensornotation, we provide the mathematical formulation of the operator-sumrepresentation involved. This allows us to show how the present and pastinformation from a time series is transmitted through the circuit, and how toreduce the computational cost in every time step of the emulated network. Inaddition, we derive the analytical gradient and the Hessian of the networkoutputs with respect to its trainable parameters, which are needed when theoutputs have stochastic noise due to hardware errors and a finite number ofcircuit shots (sampling). We finally test the presented methods using ahardware-efficient ansatz and four diverse datasets that include univariate andmultivariate time series, with and without sampling noise. In addition, wecompare the model with other existing quantum and classical approaches. Ourresults show how QRNNs can be trained with numerical and analytical gradientsto make accurate predictions of future values by capturing non-trivial patternsof input series with different complexities.</description><author>José Daniel Viqueira, Daniel Faílde, Mariamo M. Juane, Andrés Gómez, David Mera</author><pubDate>Thu, 30 Jan 2025 17:44:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20671v2</guid></item><item><title>Temporal Preference Optimization for Long-Form Video Understanding</title><link>http://arxiv.org/abs/2501.13919v2</link><description>Despite significant advancements in video large multimodal models(video-LMMs), achieving effective temporal grounding in long-form videosremains a challenge for existing models. To address this limitation, we proposeTemporal Preference Optimization (TPO), a novel post-training frameworkdesigned to enhance the temporal grounding capabilities of video-LMMs throughpreference learning. TPO adopts a self-training approach that enables models todifferentiate between well-grounded and less accurate temporal responses byleveraging curated preference datasets at two granularities: localized temporalgrounding, which focuses on specific video segments, and comprehensive temporalgrounding, which captures extended temporal dependencies across entire videosequences. By optimizing on these preference datasets, TPO significantlyenhances temporal understanding while reducing reliance on manually annotateddata. Extensive experiments on three long-form video understandingbenchmarks--LongVideoBench, MLVU, and Video-MME--demonstrate the effectivenessof TPO across two state-of-the-art video-LMMs. Notably, LLaVA-Video-TPOestablishes itself as the leading 7B model on the Video-MME benchmark,underscoring the potential of TPO as a scalable and efficient solution foradvancing temporal reasoning in long-form video understanding. Project page:https://ruili33.github.io/tpo_website.</description><author>Rui Li, Xiaohan Wang, Yuhui Zhang, Zeyu Wang, Serena Yeung-Levy</author><pubDate>Thu, 30 Jan 2025 17:35:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13919v2</guid></item><item><title>GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering</title><link>http://arxiv.org/abs/2409.06595v3</link><description>Retrieval-Augmented Generation (RAG) has emerged as a common paradigm to useLarge Language Models (LLMs) alongside private and up-to-date knowledge bases.In this work, we address the challenges of using LLM-as-a-Judge when evaluatinggrounded answers generated by RAG systems. To assess the calibration anddiscrimination capabilities of judge models, we identify 7 generator failuremodes and introduce GroUSE (Grounded QA Unitary Scoring of Evaluators), ameta-evaluation benchmark of 144 unit tests. This benchmark reveals thatexisting automated RAG evaluation frameworks often overlook important failuremodes, even when using GPT-4 as a judge. To improve on the current design of automated RAG evaluation frameworks, wepropose a novel pipeline and find that while closed models perform well onGroUSE, state-of-the-art open-source judges do not generalize to our proposedcriteria, despite strong correlation with GPT-4's judgement. Our findingssuggest that correlation with GPT-4 is an incomplete proxy for the practicalperformance of judge models and should be supplemented with evaluations on unittests for precise failure mode detection. We further show that finetuning Llama-3 on GPT-4's reasoning tracessignificantly boosts its evaluation capabilities, improving upon bothcorrelation with GPT-4's evaluations and calibration on reference situations.</description><author>Sacha Muller, António Loison, Bilel Omrani, Gautier Viaud</author><pubDate>Thu, 30 Jan 2025 17:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.06595v3</guid></item><item><title>LLaRA: Supercharging Robot Learning Data for Vision-Language Policy</title><link>http://arxiv.org/abs/2406.20095v3</link><description>Vision Language Models (VLMs) have recently been leveraged to generaterobotic actions, forming Vision-Language-Action (VLA) models. However, directlyadapting a pretrained VLM for robotic control remains challenging, particularlywhen constrained by a limited number of robot demonstrations. In this work, weintroduce LLaRA: Large Language and Robotics Assistant, a framework thatformulates robot action policy as visuo-textual conversations and enables anefficient transfer of a pretrained VLM into a powerful VLA, motivated by thesuccess of visual instruction tuning in Computer Vision. First, we present anautomated pipeline to generate conversation-style instruction tuning data forrobots from existing behavior cloning datasets, aligning robotic actions withimage pixel coordinates. Further, we enhance this dataset in a self-supervisedmanner by defining six auxiliary tasks, without requiring any additional actionannotations. We show that a VLM finetuned with a limited amount of suchdatasets can produce meaningful action decisions for robotic control. Throughexperiments across multiple simulated and real-world tasks, we demonstrate thatLLaRA achieves state-of-the-art performance while preserving the generalizationcapabilities of large language models. The code, datasets, and pretrainedmodels are available at https://github.com/LostXine/LLaRA.</description><author>Xiang Li, Cristina Mata, Jongwoo Park, Kumara Kahatapitiya, Yoo Sung Jang, Jinghuan Shang, Kanchana Ranasinghe, Ryan Burgert, Mu Cai, Yong Jae Lee, Michael S. Ryoo</author><pubDate>Thu, 30 Jan 2025 17:34:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20095v3</guid></item><item><title>Integrating Spatial and Frequency Information for Under-Display Camera Image Restoration</title><link>http://arxiv.org/abs/2501.18517v1</link><description>Under-Display Camera (UDC) houses a digital camera lens under a displaypanel. However, UDC introduces complex degradations such as noise, blur,decrease in transmittance, and flare. Despite the remarkable progress, previousresearch on UDC mainly focuses on eliminating diffraction in the spatial domainand rarely explores its potential in the frequency domain. It is essential toconsider both the spatial and frequency domains effectively. For example,degradations, such as noise and blur, can be addressed by local information(e.g., CNN kernels in the spatial domain). At the same time, tackling flaresmay require leveraging global information (e.g., the frequency domain). In thispaper, we revisit the UDC degradations in the Fourier space and figure outintrinsic frequency priors that imply the presence of the flares. Based on thisobservation, we propose a novel multi-level DNN architecture called SFIM. Itefficiently restores UDC-distorted images by integrating local and global (thecollective contribution of all points in the image) information. Thearchitecture exploits CNNs to capture local information and FFT-based models tocapture global information. SFIM comprises a spatial domain block (SDB), aFrequency Domain Block (FDB), and an Attention-based Multi-level IntegrationBlock (AMIB). Specifically, SDB focuses more on detailed textures such as noiseand blur, FDB emphasizes irregular texture loss in extensive areas such asflare, and AMIB enables effective cross-domain interaction. SFIM's superiorperformance over state-of-the-art approaches is demonstrated through rigorousquantitative and qualitative assessments across three UDC benchmarks.</description><author>Kyusu Ahn, Jinpyo Kim, Chanwoo Park, JiSoo Kim, Jaejin Lee</author><pubDate>Thu, 30 Jan 2025 17:30:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18517v1</guid></item><item><title>Streaming DiLoCo with overlapping communication: Towards a Distributed Free Lunch</title><link>http://arxiv.org/abs/2501.18512v1</link><description>Training of large language models (LLMs) is typically distributed across alarge number of accelerators to reduce training time. Since internal states andparameter gradients need to be exchanged at each and every single gradientstep, all devices need to be co-located using low-latency high-bandwidthcommunication links to support the required high volume of exchanged bits.Recently, distributed algorithms like DiLoCo have relaxed such co-locationconstraint: accelerators can be grouped into ``workers'', wheresynchronizations between workers only occur infrequently. This in turn meansthat workers can afford being connected by lower bandwidth communication linkswithout affecting learning quality. However, in these methods, communicationacross workers still requires the same peak bandwidth as before, as thesynchronizations require all parameters to be exchanged across all workers. Inthis paper, we improve DiLoCo in three ways. First, we synchronize only subsetsof parameters in sequence, rather than all at once, which greatly reduces peakbandwidth. Second, we allow workers to continue training while synchronizing,which decreases wall clock time. Third, we quantize the data exchanged byworkers, which further reduces bandwidth across workers. By properly combiningthese modifications, we show experimentally that we can distribute training ofbillion-scale parameters and reach similar quality as before, but reducingrequired bandwidth by two orders of magnitude.</description><author>Arthur Douillard, Yanislav Donchev, Keith Rush, Satyen Kale, Zachary Charles, Zachary Garrett, Gabriel Teston, Dave Lacey, Ross McIlroy, Jiajun Shen, Alexandre Ramé, Arthur Szlam, Marc'Aurelio Ranzato, Paul Barham</author><pubDate>Thu, 30 Jan 2025 17:23:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18512v1</guid></item><item><title>WILDCHAT-50M: A Deep Dive Into the Role of Synthetic Data in Post-Training</title><link>http://arxiv.org/abs/2501.18511v1</link><description>Language model (LLM) post-training, from DPO to distillation, can refinebehaviors and unlock new skills, but the open science supporting thesepost-training techniques is still in its infancy. One limiting factor has beenthe difficulty of conducting large-scale comparative analyses of synthetic datagenerating models and LLM judges. To close this gap, we introduce WILDCHAT-50M,the largest public chat dataset to date. We extend the existing WildChatdataset to include responses not only from GPT, but from over 50 differentopen-weight models, ranging in size from 0.5B to 104B parameters. We conduct anextensive comparative analysis and demonstrate the potential of this dataset bycreating RE-WILD, our own public SFT mix, which outperforms the recent Tulu-3SFT mixture from Allen AI with only 40% as many samples. Our dataset, samplesand code are available at https://github.com/penfever/wildchat-50m.</description><author>Benjamin Feuer, Chinmay Hegde</author><pubDate>Thu, 30 Jan 2025 17:21:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18511v1</guid></item><item><title>Deconstruct Complexity (DeComplex): A Novel Perspective on Tackling Dense Action Detection</title><link>http://arxiv.org/abs/2501.18509v1</link><description>Dense action detection involves detecting multiple co-occurring actions in anuntrimmed video while action classes are often ambiguous and representoverlapping concepts. To address this challenge task, we introduce a novelperspective inspired by how humans tackle complex tasks by breaking them intomanageable sub-tasks. Instead of relying on a single network to address theentire problem, as in current approaches, we propose decomposing the probleminto detecting key concepts present in action classes, specifically, detectingdense static concepts and detecting dense dynamic concepts, and assigning themto distinct, specialized networks. Furthermore, simultaneous actions in a videooften exhibit interrelationships, and exploiting these relationships canimprove performance. However, we argue that current networks fail toeffectively learn these relationships due to their reliance on binarycross-entropy optimization, which treats each class independently. To addressthis limitation, we propose providing explicit supervision on co-occurringconcepts during network optimization through a novel language-guidedcontrastive learning loss. Our extensive experiments demonstrate thesuperiority of our approach over state-of-the-art methods, achievingsubstantial relative improvements of 23.4% and 2.5% mAP on the challengingbenchmark datasets, Charades and MultiTHUMOS.</description><author>Faegheh Sardari, Armin Mustafa, Philip J. B. Jackson, Adrian Hilton</author><pubDate>Thu, 30 Jan 2025 17:20:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18509v1</guid></item><item><title>Bayesian Neural Networks for One-to-Many Mapping in Image Enhancement</title><link>http://arxiv.org/abs/2501.14265v2</link><description>In image enhancement tasks, such as low-light and underwater imageenhancement, a degraded image can correspond to multiple plausible targetimages due to dynamic photography conditions, such as variations inillumination. This naturally results in a one-to-many mapping challenge. Toaddress this, we propose a Bayesian Enhancement Model (BEM) that incorporatesBayesian Neural Networks (BNNs) to capture data uncertainty and produce diverseoutputs. To achieve real-time inference, we introduce a two-stage approach:Stage I employs a BNN to model the one-to-many mappings in the low-dimensionalspace, while Stage II refines fine-grained image details using a DeterministicNeural Network (DNN). To accelerate BNN training and convergence, we introducea dynamic Momentum Prior. Extensive experiments on multiple low-light andunderwater image enhancement benchmarks demonstrate the superiority of ourmethod over deterministic models.</description><author>Guoxi Huang, Nantheera Anantrasirichai, Fei Ye, Zipeng Qi, RuiRui Lin, Qirui Yang, David Bull</author><pubDate>Thu, 30 Jan 2025 17:19:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14265v2</guid></item><item><title>CLEAR: Cue Learning using Evolution for Accurate Recognition Applied to Sustainability Data Extraction</title><link>http://arxiv.org/abs/2501.18504v1</link><description>Large Language Model (LLM) image recognition is a powerful tool forextracting data from images, but accuracy depends on providing sufficient cuesin the prompt - requiring a domain expert for specialized tasks. We introduceCue Learning using Evolution for Accurate Recognition (CLEAR), which uses acombination of LLMs and evolutionary computation to generate and optimize cuessuch that recognition of specialized features in images is improved. Itachieves this by auto-generating a novel domain-specific representation andthen using it to optimize suitable textual cues with a genetic algorithm. Weapply CLEAR to the real-world task of identifying sustainability data frominterior and exterior images of buildings. We investigate the effects of usinga variable-length representation compared to fixed-length and show how LLMconsistency can be improved by refactoring from categorical to real-valuedestimates. We show that CLEAR enables higher accuracy compared to expert humanrecognition and human-authored prompts in every task with error rates improvedby up to two orders of magnitude and an ablation study evincing solutionconcision.</description><author>Peter J. Bentley, Soo Ling Lim, Fuyuki Ishikawa</author><pubDate>Thu, 30 Jan 2025 17:13:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18504v1</guid></item><item><title>Beyond Prior Limits: Addressing Distribution Misalignment in Particle Filtering</title><link>http://arxiv.org/abs/2501.18501v1</link><description>Particle filtering is a Bayesian inference method and a fundamental tool instate estimation for dynamic systems, but its effectiveness is often limited bythe constraints of the initial prior distribution, a phenomenon we define asthe Prior Boundary Phenomenon. This challenge arises when target states lieoutside the prior's support, rendering traditional particle filtering methodsinadequate for accurate estimation. Although techniques like unbounded priorsand larger particle sets have been proposed, they remain computationallyprohibitive and lack adaptability in dynamic scenarios. To systematicallyovercome these limitations, we propose the Diffusion-Enhanced ParticleFiltering Framework, which introduces three key innovations: adaptive diffusionthrough exploratory particles, entropy-driven regularisation to prevent weightcollapse, and kernel-based perturbations for dynamic support expansion. Thesemechanisms collectively enable particle filtering to explore beyond priorboundaries, ensuring robust state estimation for out-of-boundary targets.Theoretical analysis and extensive experiments validate framework'seffectiveness, indicating significant improvements in success rates andestimation accuracy across high-dimensional and non-convex scenarios.</description><author>Yiwei Shi, Jingyu Hu, Yu Zhang, Mengyue Yang, Weinan Zhang, Cunjia Liu, Weiru Liu</author><pubDate>Thu, 30 Jan 2025 17:11:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18501v1</guid></item><item><title>HSRMamba: Contextual Spatial-Spectral State Space Model for Single Hyperspectral Super-Resolution</title><link>http://arxiv.org/abs/2501.18500v1</link><description>Mamba has demonstrated exceptional performance in visual tasks due to itspowerful global modeling capabilities and linear computational complexity,offering considerable potential in hyperspectral image super-resolution(HSISR). However, in HSISR, Mamba faces challenges as transforming images into1D sequences neglects the spatial-spectral structural relationships betweenlocally adjacent pixels, and its performance is highly sensitive to inputorder, which affects the restoration of both spatial and spectral details. Inthis paper, we propose HSRMamba, a contextual spatial-spectral modeling statespace model for HSISR, to address these issues both locally and globally.Specifically, a local spatial-spectral partitioning mechanism is designed toestablish patch-wise causal relationships among adjacent pixels in 3D features,mitigating the local forgetting issue. Furthermore, a global spectralreordering strategy based on spectral similarity is employed to enhance thecausal representation of similar pixels across both spatial and spectraldimensions. Finally, experimental results demonstrate our HSRMamba outperformsthe state-of-the-art methods in quantitative quality and visual results. Codewill be available soon.</description><author>Shi Chen, Lefei Zhang, Liangpei Zhang</author><pubDate>Thu, 30 Jan 2025 17:10:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18500v1</guid></item><item><title>Fold Bifurcation Identification through Scientific Machine Learning</title><link>http://arxiv.org/abs/2312.14210v2</link><description>This study employs scientific machine learning to identify transient timeseries of dynamical systems near a fold bifurcation of periodic solutions. Theunique aspect of this work is that a convolutional neural network (CNN) istrained with a relatively small amount of data and on a single, very simplesystem, yet it is tested on much more complicated systems. This task requiresstrong generalization capabilities, which are achieved by incorporatingphysics-based information. This information is provided through a specificpre-processing of the input data, which includes transformation into polarcoordinates, normalization, transformation into the logarithmic scale, andfiltering through a moving mean. The results demonstrate that such datapre-processing enables the CNN to grasp the important features related totransient time-series near a fold bifurcation, namely, the trend of theoscillation amplitude, and disregard other characteristics that are notparticularly relevant, such as the vibration frequency. The developed CNN wasable to correctly classify transient trajectories near a fold for amass-on-moving-belt system, a van der Pol-Duffing oscillator with an attachedtuned mass damper, and a pitch-and-plunge wing profile. The results contributeto the progress towards the development of similar CNNs effective in real-lifeapplications such as safety monitoring of dynamical systems.</description><author>Giuseppe Habib, Ádám Horváth</author><pubDate>Thu, 30 Jan 2025 17:08:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14210v2</guid></item><item><title>Runway vs. Taxiway: Challenges in Automated Line Identification and Notation Approaches</title><link>http://arxiv.org/abs/2501.18494v1</link><description>The increasing complexity of autonomous systems has amplified the need foraccurate and reliable labeling of runway and taxiway markings to ensureoperational safety. Precise detection and labeling of these markings arecritical for tasks such as navigation, landing assistance, and ground controlautomation. Existing labeling algorithms, like the Automated LineIdentification and Notation Algorithm (ALINA), have demonstrated success inidentifying taxiway markings but encounter significant challenges when appliedto runway markings. This limitation arises due to notable differences in linecharacteristics, environmental context, and interference from elements such asshadows, tire marks, and varying surface conditions. To address thesechallenges, we modified ALINA by adjusting color thresholds and refining regionof interest (ROI) selection to better suit runway-specific contexts. Whilethese modifications yielded limited improvements, the algorithm still struggledwith consistent runway identification, often mislabeling elements such as thehorizon or non-relevant background features. This highlighted the need for amore robust solution capable of adapting to diverse visual interferences. Inthis paper, we propose integrating a classification step using a ConvolutionalNeural Network (CNN) named AssistNet. By incorporating this classificationstep, the detection pipeline becomes more resilient to environmental variationsand misclassifications. This work not only identifies the challenges but alsooutlines solutions, paving the way for improved automated labeling techniquesessential for autonomous aviation systems.</description><author>Parth Ganeriwala, Amy Alvarez, Abdullah AlQahtani, Siddhartha Bhattacharyya, Mohammed Abdul Hafeez Khan, Natasha Neogi</author><pubDate>Thu, 30 Jan 2025 17:07:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18494v1</guid></item><item><title>GuardReasoner: Towards Reasoning-based LLM Safeguards</title><link>http://arxiv.org/abs/2501.18492v1</link><description>As LLMs increasingly impact safety-critical applications, ensuring theirsafety using guardrails remains a key challenge. This paper proposesGuardReasoner, a new safeguard for LLMs, by guiding the guard model to learn toreason. Concretely, we first create the GuardReasonerTrain dataset, whichconsists of 127K samples with 460K detailed reasoning steps. Then, we introducereasoning SFT to unlock the reasoning capability of guard models. In addition,we present hard sample DPO to further strengthen their reasoning ability. Inthis manner, GuardReasoner achieves better performance, explainability, andgeneralizability. Extensive experiments and analyses on 13 benchmarks of 3guardrail tasks demonstrate its superiority. Remarkably, GuardReasoner 8Bsurpasses GPT-4o+CoT by 5.74% and LLaMA Guard 3 8B by 20.84% F1 score onaverage. We release the training data, code, and models with different scales(1B, 3B, 8B) of GuardReasoner : https://github.com/yueliu1999/GuardReasoner/.</description><author>Yue Liu, Hongcheng Gao, Shengfang Zhai, Jun Xia, Tianyi Wu, Zhiwei Xue, Yulin Chen, Kenji Kawaguchi, Jiaheng Zhang, Bryan Hooi</author><pubDate>Thu, 30 Jan 2025 17:06:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18492v1</guid></item><item><title>Curriculum-based Sample Efficient Reinforcement Learning for Robust Stabilization of a Quadrotor</title><link>http://arxiv.org/abs/2501.18490v1</link><description>This article introduces a curriculum learning approach to develop areinforcement learning-based robust stabilizing controller for a Quadrotor thatmeets predefined performance criteria. The learning objective is to achievedesired positions from random initial conditions while adhering to bothtransient and steady-state performance specifications. This objective ischallenging for conventional one-stage end-to-end reinforcement learning, dueto the strong coupling between position and orientation dynamics, thecomplexity in designing and tuning the reward function, and poor sampleefficiency, which necessitates substantial computational resources and leads toextended convergence times. To address these challenges, this work decomposesthe learning objective into a three-stage curriculum that incrementallyincreases task complexity. The curriculum begins with learning to achievestable hovering from a fixed initial condition, followed by progressivelyintroducing randomization in initial positions, orientations and velocities. Anovel additive reward function is proposed, to incorporate transient andsteady-state performance specifications. The results demonstrate that theProximal Policy Optimization (PPO)-based curriculum learning approach, coupledwith the proposed reward structure, achieves superior performance compared to asingle-stage PPO-trained policy with the same reward function, whilesignificantly reducing computational resource requirements and convergencetime. The curriculum-trained policy's performance and robustness are thoroughlyvalidated under random initial conditions and in the presence of disturbances.</description><author>Fausto Mauricio Lagos Suarez, Akshit Saradagi, Vidya Sumathy, Shruti Kotpaliwar, George Nikolakopoulos</author><pubDate>Thu, 30 Jan 2025 17:05:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18490v1</guid></item><item><title>Can Optimization Trajectories Explain Multi-Task Transfer?</title><link>http://arxiv.org/abs/2408.14677v2</link><description>Despite the widespread adoption of multi-task training in deep learning,little is understood about how multi-task learning (MTL) affectsgeneralization. Prior work has conjectured that the negative effects of MTL aredue to optimization challenges that arise during training, and manyoptimization methods have been proposed to improve multi-task performance.However, recent work has shown that these methods fail to consistently improvemulti-task generalization. In this work, we seek to improve our understandingof these failures by empirically studying how MTL impacts the optimization oftasks, and whether this impact can explain the effects of MTL ongeneralization. We show that MTL results in a generalization gap (a gap ingeneralization at comparable training loss) between single-task and multi-tasktrajectories early into training. However, we find that factors of theoptimization trajectory previously proposed to explain generalization gaps insingle-task settings cannot explain the generalization gaps between single-taskand multi-task models. Moreover, we show that the amount of gradient conflictbetween tasks is correlated with negative effects to task optimization, but isnot predictive of generalization. Our work sheds light on the underlying causesfor failures in MTL and, importantly, raises questions about the role ofgeneral purpose multi-task optimization algorithms.</description><author>David Mueller, Mark Dredze, Nicholas Andrews</author><pubDate>Thu, 30 Jan 2025 17:04:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14677v2</guid></item><item><title>Track-On: Transformer-based Online Point Tracking with Memory</title><link>http://arxiv.org/abs/2501.18487v1</link><description>In this paper, we consider the problem of long-term point tracking, whichrequires consistent identification of points across multiple frames in a video,despite changes in appearance, lighting, perspective, and occlusions. We targetonline tracking on a frame-by-frame basis, making it suitable for real-world,streaming scenarios. Specifically, we introduce Track-On, a simpletransformer-based model designed for online long-term point tracking. Unlikeprior methods that depend on full temporal modeling, our model processes videoframes causally without access to future frames, leveraging two memory modules-- spatial memory and context memory -- to capture temporal information andmaintain reliable point tracking over long time horizons. At inference time, itemploys patch classification and refinement to identify correspondences andtrack points with high accuracy. Through extensive experiments, we demonstratethat Track-On sets a new state-of-the-art for online models and deliverssuperior or competitive results compared to offline approaches on sevendatasets, including the TAP-Vid benchmark. Our method offers a robust andscalable solution for real-time tracking in diverse applications. Project page:https://kuis-ai.github.io/track_on</description><author>Görkay Aydemir, Xiongyi Cai, Weidi Xie, Fatma Güney</author><pubDate>Thu, 30 Jan 2025 17:04:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18487v1</guid></item><item><title>FLRONet: Deep Operator Learning for High-Fidelity Fluid Flow Field Reconstruction from Sparse Sensor Measurements</title><link>http://arxiv.org/abs/2412.08009v3</link><description>Reconstructing high-fidelity fluid flow fields from sparse sensormeasurements is vital for many science and engineering applications but remainschallenging because of dimensional disparities between state and observationalspaces. Due to such dimensional differences, the measurement operator becomesill-conditioned and non-invertible, making the reconstruction of flow fieldsfrom sensor measurements extremely difficult. Although sparse optimization andmachine learning address the above problems to some extent, questions abouttheir generalization and efficiency remain, particularly regarding thediscretization dependence of these models. In this context, deep operatorlearning offers a better solution as this approach models mappings betweeninfinite-dimensional functional spaces, enabling superior generalization anddiscretization-independent reconstruction. We introduce FLRONet, a deepoperator learning framework that is trained to reconstruct fluid flow fieldsfrom sparse sensor measurements. FLRONet employs a branch-trunk networkarchitecture to represent the inverse measurement operator that maps sensorobservations to the original flow field, a continuous function of both spaceand time. Validation performed on the CFDBench dataset has demonstrated thatFLRONet consistently achieves high levels of reconstruction accuracy androbustness, even in scenarios where sensor measurements are inaccurate ormissing. Furthermore, the operator learning approach endows FLRONet with thecapability to perform zero-shot super-resolution in both spatial and temporaldomains, offering a solution for rapid reconstruction of high-fidelity flowfields.</description><author>Hiep Vo Dang, Joseph B. Choi, Phong C. H. Nguyen</author><pubDate>Thu, 30 Jan 2025 17:02:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.08009v3</guid></item><item><title>Improving Model's Interpretability and Reliability using Biomarkers</title><link>http://arxiv.org/abs/2402.12394v2</link><description>Accurate and interpretable diagnostic models are crucial in thesafety-critical field of medicine. We investigate the interpretability of ourproposed biomarker-based lung ultrasound diagnostic pipeline to enhanceclinicians' diagnostic capabilities. The objective of this study is to assesswhether explanations from a decision tree classifier, utilizing biomarkers, canimprove users' ability to identify inaccurate model predictions compared toconventional saliency maps. Our findings demonstrate that decision treeexplanations, based on clinically established biomarkers, can assist cliniciansin detecting false positives, thus improving the reliability of diagnosticmodels in medicine.</description><author>Gautam Rajendrakumar Gare, Tom Fox, Beam Chansangavej, Amita Krishnan, Ricardo Luis Rodriguez, Bennett P deBoisblanc, Deva Kannan Ramanan, John Michael Galeotti</author><pubDate>Thu, 30 Jan 2025 16:55:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12394v2</guid></item><item><title>Transformer Semantic Genetic Programming for Symbolic Regression</title><link>http://arxiv.org/abs/2501.18479v1</link><description>In standard genetic programming (stdGP), solutions are varied by modifyingtheir syntax, with uncertain effects on their semantics. Geometric-semanticgenetic programming (GSGP), a popular variant of GP, effectively searches thesemantic solution space using variation operations based on linearcombinations, although it results in significantly larger solutions. This paperpresents Transformer Semantic Genetic Programming (TSGP), a novel and flexiblesemantic approach that uses a generative transformer model as search operator.The transformer is trained on synthetic test problems and learns semanticsimilarities between solutions. Once the model is trained, it can be used tocreate offspring solutions with high semantic similarity also for unseen andunknown problems. Experiments on several symbolic regression problems show thatTSGP generates solutions with comparable or even significantly betterprediction quality than stdGP, SLIM_GSGP, DSR, and DAE-GP. Like SLIM_GSGP, TSGPis able to create new solutions that are semantically similar without creatingsolutions of large size. An analysis of the search dynamic reveals that thesolutions generated by TSGP are semantically more similar than the solutionsgenerated by the benchmark approaches allowing a better exploration of thesemantic solution space.</description><author>Philipp Anthes, Dominik Sobania, Franz Rothlauf</author><pubDate>Thu, 30 Jan 2025 16:51:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18479v1</guid></item><item><title>SimpleDepthPose: Fast and Reliable Human Pose Estimation with RGBD-Images</title><link>http://arxiv.org/abs/2501.18478v1</link><description>In the rapidly advancing domain of computer vision, accurately estimating theposes of multiple individuals from various viewpoints remains a significantchallenge, especially when reliability is a key requirement. This paperintroduces a novel algorithm that excels in multi-view, multi-person poseestimation by incorporating depth information. An extensive evaluationdemonstrates that the proposed algorithm not only generalizes well to unseendatasets, and shows a fast runtime performance, but also is adaptable todifferent keypoints. To support further research, all of the work is publiclyaccessible.</description><author>Daniel Bermuth, Alexander Poeppel, Wolfgang Reif</author><pubDate>Thu, 30 Jan 2025 16:51:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18478v1</guid></item><item><title>CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization</title><link>http://arxiv.org/abs/2501.18475v1</link><description>Fine-tuning large language models (LLMs) using low-rank adaptation (LoRA) hasbecome a highly efficient approach for downstream tasks, particularly inscenarios with limited computational resources. However, applying LoRAtechniques to quantized LLMs poses unique challenges due to the reducedrepresentational precision of quantized weights. In this paper, we introduceCLoQ (Calibrated LoRA initialization for Quantized LLMs), a simplisticinitialization strategy designed to overcome these challenges. Our approachfocuses on minimizing the layer-wise discrepancy between the original LLM andits quantized counterpart with LoRA components during initialization. Byleveraging a small calibration dataset, CLoQ quantizes a pre-trained LLM anddetermines the optimal LoRA components for each layer, ensuring a strongfoundation for subsequent fine-tuning. A key contribution of this work is anovel theoretical result that enables the accurate and closed-form constructionof these optimal LoRA components. We validate the efficacy of CLoQ acrossmultiple tasks such as language generation, arithmetic reasoning, andcommonsense reasoning, demonstrating that it consistently outperforms existingLoRA fine-tuning methods for quantized LLMs, especially at ultra low-bitwidths.</description><author>Yanxia Deng, Aozhong Zhang, Naigang Wang, Selcuk Gurses, Zi Yang, Penghang Yin</author><pubDate>Thu, 30 Jan 2025 16:48:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18475v1</guid></item><item><title>Tuning Vision Foundation Model via Test-Time Prompt-Guided Training for VFSS Segmentations</title><link>http://arxiv.org/abs/2501.18474v1</link><description>Vision foundation models have demonstrated exceptional generalizationcapabilities in segmentation tasks for both generic and specialized images.However, a performance gap persists between foundation models andtask-specific, specialized models. Fine-tuning foundation models on downstreamdatasets is often necessary to bridge this gap. Unfortunately, obtaining fullyannotated ground truth for downstream datasets is both challenging and costly.To address this limitation, we propose a novel test-time training paradigm thatenhances the performance of foundation models on downstream datasets withoutrequiring full annotations. Specifically, our method employs simple pointprompts to guide a test-time semi-self-supervised training task. The modellearns by resolving the ambiguity of the point prompt through variousaugmentations. This approach directly tackles challenges in the medical imagingfield, where acquiring annotations is both time-intensive and expensive. Weconducted extensive experiments on our new Videofluoroscopy dataset (VFSS-5k)for the instance segmentation task, achieving an average Dice coefficient of0.868 across 12 anatomies with a single model.</description><author>Chengxi Zeng, David Smithard, Alberto M Gambaruto, Tilo Burghardt</author><pubDate>Thu, 30 Jan 2025 16:48:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18474v1</guid></item><item><title>Resampling Filter Design for Multirate Neural Audio Effect Processing</title><link>http://arxiv.org/abs/2501.18470v1</link><description>Neural networks have become ubiquitous in audio effects modelling, especiallyfor guitar amplifiers and distortion pedals. One limitation of such models isthat the sample rate of the training data is implicitly encoded in the modelweights and therefore not readily adjustable at inference. Recent work exploredmodifications to recurrent neural network architecture to approximate a samplerate independent system, enabling audio processing at a rate that differs fromthe original training rate. This method works well for integer oversampling andcan reduce aliasing caused by nonlinear activation functions. For smallfractional changes in sample rate, fractional delay filters can be used toapproximate sample rate independence, but in some cases this method failsentirely. Here, we explore the use of signal resampling at the input and outputof the neural network as an alternative solution. We investigate severalresampling filter designs and show that a two-stage design consisting of ahalf-band IIR filter cascaded with a Kaiser window FIR filter can give similaror better results to the previously proposed model adjustment method with manyfewer operations per sample and less than one millisecond of latency at typicalaudio rates. Furthermore, we investigate interpolation and decimation filtersfor the task of integer oversampling and show that cascaded half-band IIR andFIR designs can be used in conjunction with the model adjustment method toreduce aliasing in a range of distortion effect models.</description><author>Alistair Carson, Vesa Välimäki, Alec Wright, Stefan Bilbao</author><pubDate>Thu, 30 Jan 2025 16:44:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18470v1</guid></item><item><title>Return of the Encoder: Maximizing Parameter Efficiency for SLMs</title><link>http://arxiv.org/abs/2501.16273v2</link><description>The dominance of large decoder-only language models has overshadowedencoder-decoder architectures, despite their fundamental efficiency advantagesin sequence processing. For small language models (SLMs) - those with 1 billionparameters or fewer - our systematic analysis across GPU, CPU, and NPUplatforms reveals that encoder-decoder architectures achieve 47% lowerfirst-token latency and 4.7x higher throughput compared to decoder-only modelson edge devices. These gains may be attributed to encoder-decoder's one-timeinput processing and efficient separation of understanding and generationphases. We introduce a novel knowledge distillation framework that enablesencoder-decoder models to leverage capabilities from large scalabledecoder-only teachers while preserving their architectural advantages,achieving up to 6 average performance points improvement across diverse tasks,with significant gains in asymmetric sequence tasks where input and outputdistributions can benefit from different processing approaches. When combined with modern advances like Rotary Positional Embeddings (RoPE)and Vision encoders, our systematic investigation demonstrates thatencoder-decoder architectures provide a more practical path toward deployingcapable language models in resource-constrained environments. Our findingschallenge the prevailing trend toward decoder-only scaling, showing thatarchitectural choices become increasingly crucial as parameter budgetsdecrease, particularly for on-device and edge deployments where computationalefficiency is paramount.</description><author>Mohamed Elfeki, Rui Liu, Chad Voegele</author><pubDate>Thu, 30 Jan 2025 16:44:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16273v2</guid></item><item><title>LLM-AutoDiff: Auto-Differentiate Any LLM Workflow</title><link>http://arxiv.org/abs/2501.16673v2</link><description>Large Language Models (LLMs) have reshaped natural language processing,powering applications from multi-hop retrieval and question answering toautonomous agent workflows. Yet, prompt engineering -- the task of craftingtextual inputs to effectively direct LLMs -- remains difficult andlabor-intensive, particularly for complex pipelines that combine multiple LLMcalls with functional operations like retrieval and data formatting. Weintroduce LLM-AutoDiff: a novel framework for Automatic Prompt Engineering(APE) that extends textual gradient-based methods (such as Text-Grad) tomulti-component, potentially cyclic LLM architectures. Implemented within theAdalFlow library, LLM-AutoDiff treats each textual input as a trainableparameter and uses a frozen backward engine LLM to generate feedback-akin totextual gradients -- that guide iterative prompt updates. Unlike priorsingle-node approaches, LLM-AutoDiff inherently accommodates functional nodes,preserves time-sequential behavior in repeated calls (e.g., multi-hop loops),and combats the "lost-in-the-middle" problem by isolating distinct sub-prompts(instructions, formats, or few-shot examples). It further boosts trainingefficiency by focusing on error-prone samples through selective gradientcomputation. Across diverse tasks, including single-step classification,multi-hop retrieval-based QA, and agent-driven pipelines, LLM-AutoDiffconsistently outperforms existing textual gradient baselines in both accuracyand training cost. By unifying prompt optimization through a graph-centriclens, LLM-AutoDiff offers a powerful new paradigm for scaling and automatingLLM workflows - mirroring the transformative role that automaticdifferentiation libraries have long played in neural network research.</description><author>Li Yin, Zhangyang Wang</author><pubDate>Thu, 30 Jan 2025 16:40:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16673v2</guid></item><item><title>Beyond Instructed Tasks: Recognizing In-the-Wild Reading Behaviors in the Classroom Using Eye Tracking</title><link>http://arxiv.org/abs/2501.18468v1</link><description>Understanding reader behaviors such as skimming, deep reading, and scanningis essential for improving educational instruction. While prior eye-trackingstudies have trained models to recognize reading behaviors, they often rely oninstructed reading tasks, which can alter natural behaviors and limit theapplicability of these findings to in-the-wild settings. Additionally, there isa lack of clear definitions for reading behavior archetypes in the literature.We conducted a classroom study to address these issues by collecting instructedand in-the-wild reading data. We developed a mixed-method framework, includinga human-driven theoretical model, statistical analyses, and an AI classifier,to differentiate reading behaviors based on their velocity, density, andsequentiality. Our lightweight 2D CNN achieved an F1 score of 0.8 for behaviorrecognition, providing a robust approach for understanding in-the-wild reading.This work advances our ability to provide detailed behavioral insights toeducators, supporting more targeted and effective assessment and instruction.</description><author>Eduardo Davalos, Jorge Alberto Salas, Yike Zhang, Namrata Srivastava, Yashvitha Thatigotla, Abbey Gonzales, Sara McFadden, Sun-Joo Cho, Gautam Biswas, Amanda Goodwin</author><pubDate>Thu, 30 Jan 2025 16:39:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18468v1</guid></item><item><title>How Much Can We Forget about Data Contamination?</title><link>http://arxiv.org/abs/2410.03249v3</link><description>The leakage of benchmark data into the training data has emerged as asignificant challenge for evaluating the capabilities of large language models(LLMs). In this work, we challenge the common assumption that small-scalecontamination renders benchmark evaluations invalid. First, we experimentallyquantify the magnitude of benchmark overfitting based on scaling along threedimensions: The number of model parameters (up to 1.6B), the number of times anexample is seen (up to 144), and the number of training tokens (up to 40B). Ifmodel and data follow the Chinchilla scaling laws, minor contamination indeedleads to overfitting. At the same time, even 144 times of contamination can beforgotten if the training data is scaled beyond five times Chinchilla, a regimecharacteristic of many modern LLMs. Continual pre-training of OLMo-7Bcorroborates these results. Next, we study the impact of the weight decayparameter on example forgetting, showing that empirical forgetting occursfaster than the cumulative weight decay. This allows us to gauge the degree ofexample forgetting in large-scale training runs, indicating that many LLMs,including Lllama 3 405B, have forgotten the data seen at the beginning oftraining.</description><author>Sebastian Bordt, Suraj Srinivas, Valentyn Boreiko, Ulrike von Luxburg</author><pubDate>Thu, 30 Jan 2025 16:31:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.03249v3</guid></item><item><title>Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models</title><link>http://arxiv.org/abs/2404.12920v4</link><description>Localizing the exact pathological regions in a given medical scan is animportant imaging problem that traditionally requires a large amount ofbounding box ground truth annotations to be accurately solved. However, thereexist alternative, potentially weaker, forms of supervision, such asaccompanying free-text reports, which are readily available. The task ofperforming localization with textual guidance is commonly referred to as phrasegrounding. In this work, we use a publicly available Foundation Model, namelythe Latent Diffusion Model, to perform this challenging task. This choice issupported by the fact that the Latent Diffusion Model, despite being generativein nature, contains cross-attention mechanisms that implicitly align visual andtextual features, thus leading to intermediate representations that aresuitable for the task at hand. In addition, we aim to perform this task in azero-shot manner, i.e., without any training on the target task, meaning thatthe model's weights remain frozen. To this end, we devise strategies to selectfeatures and also refine them via post-processing without extra learnableparameters. We compare our proposed method with state-of-the-art approacheswhich explicitly enforce image-text alignment in a joint embedding space viacontrastive learning. Results on a popular chest X-ray benchmark indicate thatour method is competitive with SOTA on different types of pathology, and evenoutperforms them on average in terms of two metrics (mean IoU and AUC-ROC).Source code will be released upon acceptance at https://github.com/vios-s.</description><author>Konstantinos Vilouras, Pedro Sanchez, Alison Q. O'Neil, Sotirios A. Tsaftaris</author><pubDate>Thu, 30 Jan 2025 16:31:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12920v4</guid></item><item><title>A Benchmark and Evaluation for Real-World Out-of-Distribution Detection Using Vision-Language Models</title><link>http://arxiv.org/abs/2501.18463v1</link><description>Out-of-distribution (OOD) detection is a task that detects OOD samples duringinference to ensure the safety of deployed models. However, conventionalbenchmarks have reached performance saturation, making it difficult to comparerecent OOD detection methods. To address this challenge, we introduce threenovel OOD detection benchmarks that enable a deeper understanding of methodcharacteristics and reflect real-world conditions. First, we presentImageNet-X, designed to evaluate performance under challenging semantic shifts.Second, we propose ImageNet-FS-X for full-spectrum OOD detection, assessingrobustness to covariate shifts (feature distribution shifts). Finally, wepropose Wilds-FS-X, which extends these evaluations to real-world datasets,offering a more comprehensive testbed. Our experiments reveal that recentCLIP-based OOD detection methods struggle to varying degrees across the threeproposed benchmarks, and none of them consistently outperforms the others. Wehope the community goes beyond specific benchmarks and includes morechallenging conditions reflecting real-world scenarios. The code ishttps://github.com/hoshi23/OOD-X-Banchmarks.</description><author>Shiho Noda, Atsuyuki Miyai, Qing Yu, Go Irie, Kiyoharu Aizawa</author><pubDate>Thu, 30 Jan 2025 16:30:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18463v1</guid></item><item><title>Energy-based physics-informed neural network for frictionless contact problems under large deformation</title><link>http://arxiv.org/abs/2411.03671v2</link><description>Numerical methods for contact mechanics are of great importance inengineering applications, enabling the prediction and analysis of complexsurface interactions under various conditions. In this work, we propose anenergy-based physics-informed neural network (PINNs) framework for solvingfrictionless contact problems under large deformation. Inspired by microscopicLennard-Jones potential, a surface contact energy is used to describe thecontact phenomena. To ensure the robustness of the proposed PINN framework,relaxation, gradual loading and output scaling techniques are introduced. Inthe numerical examples, the well-known Hertz contact benchmark problem isconducted, demonstrating the effectiveness and robustness of the proposed PINNsframework. Moreover, challenging contact problems with the consideration ofgeometrical and material nonlinearities are tested. It has been shown that theproposed PINNs framework provides a reliable and powerful tool for nonlinearcontact mechanics. More importantly, the proposed PINNs framework exhibitscompetitive computational efficiency to the commercial FEM software whendealing with those complex contact problems. The codes used in this manuscriptare available at https://github.com/JinshuaiBai/energy_PINN_Contact.(The codewill be available after acceptance)</description><author>Jinshuai Bai, Zhongya Lin, Yizheng Wang, Jiancong Wen, Yinghua Liu, Timon Rabczuk, YuanTong Gu, Xi-Qiao Feng</author><pubDate>Thu, 30 Jan 2025 16:30:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03671v2</guid></item><item><title>A Hype-Adjusted Probability Measure for NLP Stock Return Forecasting</title><link>http://arxiv.org/abs/2412.07587v5</link><description>This article introduces a Hype-Adjusted Probability Measure in the context ofa new Natural Language Processing (NLP) approach for stock return andvolatility forecasting. A novel sentiment score equation is proposed torepresent the impact of intraday news on forecasting next-period stock returnand volatility for selected U.S. semiconductor tickers, a very vibrant industrysector. This work improves the forecast accuracy by addressing news bias,memory, and weight, and incorporating shifts in sentiment direction. Moreimportantly, it extends the use of the remarkable tool of change of ProbabilityMeasure developed in the finance of Asset Pricing to NLP forecasting byconstructing a Hype-Adjusted Probability Measure, obtained from aredistribution of the weights in the probability space, meant to correct forexcessive or insufficient news.</description><author>Zheng Cao, Helyette Geman</author><pubDate>Thu, 30 Jan 2025 16:23:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.07587v5</guid></item><item><title>xJailbreak: Representation Space Guided Reinforcement Learning for Interpretable LLM Jailbreaking</title><link>http://arxiv.org/abs/2501.16727v2</link><description>Safety alignment mechanism are essential for preventing large language models(LLMs) from generating harmful information or unethical content. However,cleverly crafted prompts can bypass these safety measures without accessing themodel's internal parameters, a phenomenon known as black-box jailbreak.Existing heuristic black-box attack methods, such as genetic algorithms, sufferfrom limited effectiveness due to their inherent randomness, while recentreinforcement learning (RL) based methods often lack robust and informativereward signals. To address these challenges, we propose a novel black-boxjailbreak method leveraging RL, which optimizes prompt generation by analyzingthe embedding proximity between benign and malicious prompts. This approachensures that the rewritten prompts closely align with the intent of theoriginal prompts while enhancing the attack's effectiveness. Furthermore, weintroduce a comprehensive jailbreak evaluation framework incorporatingkeywords, intent matching, and answer validation to provide a more rigorous andholistic assessment of jailbreak success. Experimental results show thesuperiority of our approach, achieving state-of-the-art (SOTA) performance onseveral prominent open and closed-source LLMs, including Qwen2.5-7B-Instruct,Llama3.1-8B-Instruct, and GPT-4o-0806. Our method sets a new benchmark injailbreak attack effectiveness, highlighting potential vulnerabilities in LLMs.The codebase for this work is available athttps://github.com/Aegis1863/xJailbreak.</description><author>Sunbowen Lee, Shiwen Ni, Chi Wei, Shuaimin Li, Liyang Fan, Ahmadreza Argha, Hamid Alinejad-Rokny, Ruifeng Xu, Yicheng Gong, Min Yang</author><pubDate>Thu, 30 Jan 2025 16:17:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16727v2</guid></item><item><title>Bayesian Despeckling of Structured Sources</title><link>http://arxiv.org/abs/2501.11860v2</link><description>Speckle noise is a fundamental challenge in coherent imaging systems,significantly degrading image quality. Over the past decades, numerousdespeckling algorithms have been developed for applications such as SyntheticAperture Radar (SAR) and digital holography. In this paper, we aim to establisha theoretically grounded approach to despeckling. We propose a methodapplicable to general structured stationary stochastic sources. We demonstratethe effectiveness of the proposed method on piecewise constant sources.Additionally, we theoretically derive a lower bound on the despecklingperformance for such sources. The proposed depseckler applied to the 1-Markovstructured sources achieves better reconstruction performance with no strongsimplification of the ground truth signal model or speckle noise.</description><author>Ali Zafari, Shirin Jalali</author><pubDate>Thu, 30 Jan 2025 16:16:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11860v2</guid></item><item><title>CALM: Unleashing the Cross-Lingual Self-Aligning Ability of Language Model Question Answering</title><link>http://arxiv.org/abs/2501.18457v1</link><description>Large Language Models (LLMs) are pretrained on extensive multilingual corporato acquire both language-specific cultural knowledge and general knowledge.Ideally, while LLMs should provide consistent responses to culture-independentquestions across languages, we observe significant performance disparities. Toaddress this, we explore the Cross-Lingual Self-Aligning ability of LanguageModels (CALM) to align knowledge across languages. Specifically, for a givenquestion, we sample multiple responses across different languages, and selectthe most self-consistent response as the target, leaving the remainingresponses as negative examples. We then employ direct preference optimization(DPO) to align the model's knowledge across different languages. Evaluations onthe MEDQA and X-CSQA datasets demonstrate CALM's effectiveness in enhancingcross-lingual knowledge question answering, both in zero-shot and retrievalaugmented settings. We also found that increasing the number of languagesinvolved in CALM training leads to even higher accuracy and consistency. Weoffer a qualitative analysis of how cross-lingual consistency can enhanceknowledge alignment and explore the method's generalizability. The source codeand data of this paper are available on GitHub.</description><author>Yumeng Wang, Zhiyuan Fan, Qingyun Wang, May Fung, Heng Ji</author><pubDate>Thu, 30 Jan 2025 16:15:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18457v1</guid></item><item><title>adabmDCA 2.0 -- a flexible but easy-to-use package for Direct Coupling Analysis</title><link>http://arxiv.org/abs/2501.18456v1</link><description>In this methods article, we provide a flexible but easy-to-use implementationof Direct Coupling Analysis (DCA) based on Boltzmann machine learning, togetherwith a tutorial on how to use it. The package \texttt{adabmDCA 2.0} isavailable in different programming languages (C++, Julia, Python) usable ondifferent architectures (single-core and multi-core CPU, GPU) using a commonfront-end interface. In addition to several learning protocols for dense andsparse generative DCA models, it allows to directly address common downstreamtasks like residue-residue contact prediction, mutational-effect prediction,scoring of sequence libraries and generation of artificial sequences forsequence design. It is readily applicable to protein and RNA sequence data.</description><author>Lorenzo Rosset, Roberto Netti, Anna Paola Muntoni, Martin Weigt, Francesco Zamponi</author><pubDate>Thu, 30 Jan 2025 16:15:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18456v1</guid></item><item><title>Conversation Games and a Strategic View of the Turing Test</title><link>http://arxiv.org/abs/2501.18455v1</link><description>Although many game-theoretic models replicate real interactions that oftenrely on natural language, explicit study of games where language is central tostrategic interaction remains limited. This paper introduces the\emph{conversation game}, a multi-stage, extensive-form game based onlinguistic strategic interaction. We focus on a subset of the games, calledverdict games. In a verdict game, two players alternate to contribute to aconversation, which is evaluated at each stage by a non-strategic judge who mayrender a conclusive binary verdict, or a decision to continue the dialogue. Thegame ends once a limit is reached or a verdict is given. We show many familiarprocesses, such as interrogation or a court process fall under this category.We also, show that the Turing test is an instance of verdict game, and discussthe significance of a strategic view of the Turing test in the age of advancedAI deception. We show the practical relevance of the proposed concepts bysimulation experiments, and show that a strategic agent outperforms a naiveagent by a high margin.</description><author>Kaveh Aryan</author><pubDate>Thu, 30 Jan 2025 16:08:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18455v1</guid></item><item><title>Transfer Learning for Keypoint Detection in Low-Resolution Thermal TUG Test Images</title><link>http://arxiv.org/abs/2501.18453v1</link><description>This study presents a novel approach to human keypoint detection inlow-resolution thermal images using transfer learning techniques. We introducethe first application of the Timed Up and Go (TUG) test in thermal imagecomputer vision, establishing a new paradigm for mobility assessment. Ourmethod leverages a MobileNetV3-Small encoder and a ViTPose decoder, trainedusing a composite loss function that balances latent representation alignmentand heatmap accuracy. The model was evaluated using the Object KeypointSimilarity (OKS) metric from the COCO Keypoint Detection Challenge. Theproposed model achieves better performance with AP, AP50, and AP75 scores of0.861, 0.942, and 0.887 respectively, outperforming traditional supervisedlearning approaches like Mask R-CNN and ViTPose-Base. Moreover, our modeldemonstrates superior computational efficiency in terms of parameter count andFLOPS. This research lays a solid foundation for future clinical applicationsof thermal imaging in mobility assessment and rehabilitation monitoring.</description><author>Wei-Lun Chen, Chia-Yeh Hsieh, Yu-Hsiang Kao, Kai-Chun Liu, Sheng-Yu Peng, Yu Tsao</author><pubDate>Thu, 30 Jan 2025 16:05:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18453v1</guid></item><item><title>Clustering Properties of Self-Supervised Learning</title><link>http://arxiv.org/abs/2501.18452v1</link><description>Self-supervised learning (SSL) methods via joint embedding architectures haveproven remarkably effective at capturing semantically rich representations withstrong clustering properties, magically in the absence of label supervision.Despite this, few of them have explored leveraging these untapped properties toimprove themselves. In this paper, we provide an evidence through variousmetrics that the encoder's output $encoding$ exhibits superior and more stableclustering properties compared to other components. Building on this insight,we propose a novel positive-feedback SSL method, termed Representation SoftAssignment (ReSA), which leverages the model's clustering properties to promotelearning in a self-guided manner. Extensive experiments on standard SSLbenchmarks reveal that models pretrained with ReSA outperform otherstate-of-the-art SSL methods by a significant margin. Finally, we analyze howReSA facilitates better clustering properties, demonstrating that iteffectively enhances clustering performance at both fine-grained andcoarse-grained levels, shaping representations that are inherently morestructured and semantically meaningful.</description><author>Xi Weng, Jianing An, Xudong Ma, Binhang Qi, Jie Luo, Xi Yang, Jin Song Dong, Lei Huang</author><pubDate>Thu, 30 Jan 2025 16:05:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18452v1</guid></item><item><title>Swin transformers are robust to distribution and concept drift in endoscopy-based longitudinal rectal cancer assessment</title><link>http://arxiv.org/abs/2405.03762v4</link><description>Endoscopic images are used at various stages of rectal cancer treatmentstarting from cancer screening, diagnosis, during treatment to assess responseand toxicity from treatments such as colitis, and at follow up to detect newtumor or local regrowth (LR). However, subjective assessment is highly variableand can underestimate the degree of response in some patients, subjecting themto unnecessary surgery, or overestimate response that places patients at riskof disease spread. Advances in deep learning has shown the ability to produceconsistent and objective response assessment for endoscopic images. However,methods for detecting cancers, regrowth, and monitoring response during theentire course of patient treatment and follow-up are lacking. This is because,automated diagnosis and rectal cancer response assessment requires methods thatare robust to inherent imaging illumination variations and confoundingconditions (blood, scope, blurring) present in endoscopy images as well aschanges to the normal lumen and tumor during treatment. Hence, a hierarchicalshifted window (Swin) transformer was trained to distinguish rectal cancer fromnormal lumen using endoscopy images. Swin as well as two convolutional(ResNet-50, WideResNet-50), and vision transformer (ViT) models were trainedand evaluated on follow-up longitudinal images to detect LR on private datasetas well as on out-of-distribution (OOD) public colonoscopy datasets to detectpre/non-cancerous polyps. Color shifts were applied using optimal transport tosimulate distribution shifts. Swin and ResNet models were similarly accurate inthe in-distribution dataset. Swin was more accurate than other methods(follow-up: 0.84, OOD: 0.83) even when subject to color shifts (follow-up:0.83, OOD: 0.87), indicating capability to provide robust performance forlongitudinal cancer assessment.</description><author>Jorge Tapias Gomez, Aneesh Rangnekar, Hannah Williams, Hannah Thompson, Julio Garcia-Aguilar, Joshua Jesse Smith, Harini Veeraraghavan</author><pubDate>Thu, 30 Jan 2025 16:01:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03762v4</guid></item><item><title>Autonomy and Safety Assurance in the Early Development of Robotics and Autonomous Systems</title><link>http://arxiv.org/abs/2501.18448v1</link><description>This report provides an overview of the workshop titled Autonomy and SafetyAssurance in the Early Development of Robotics and Autonomous Systems, hostedby the Centre for Robotic Autonomy in Demanding and Long-Lasting Environments(CRADLE) on September 2, 2024, at The University of Manchester, UK. The eventbrought together representatives from six regulatory and assurance bodiesacross diverse sectors to discuss challenges and evidence for ensuring thesafety of autonomous and robotic systems, particularly autonomous inspectionrobots (AIR). The workshop featured six invited talks by the regulatory andassurance bodies. CRADLE aims to make assurance an integral part of engineeringreliable, transparent, and trustworthy autonomous systems. Key discussionsrevolved around three research questions: (i) challenges in assuring safety forAIR; (ii) evidence for safety assurance; and (iii) how assurance cases need todiffer for autonomous systems. Following the invited talks, the breakout groupsfurther discussed the research questions using case studies from ground (rail),nuclear, underwater, and drone-based AIR. This workshop offered a valuableopportunity for representatives from industry, academia, and regulatory bodiesto discuss challenges related to assured autonomy. Feedback from participantsindicated a strong willingness to adopt a design-for-assurance process toensure that robots are developed and verified to meet regulatory expectations.</description><author>Dhaminda B. Abeywickrama, Michael Fisher, Frederic Wheeler, Louise Dennis</author><pubDate>Thu, 30 Jan 2025 16:00:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18448v1</guid></item><item><title>Probabilistic Verification of Neural Networks using Branch and Bound</title><link>http://arxiv.org/abs/2405.17556v2</link><description>Probabilistic verification of neural networks is concerned with formallyanalysing the output distribution of a neural network under a probabilitydistribution of the inputs. Examples of probabilistic verification includeverifying the demographic parity fairness notion or quantifying the safety of aneural network. We present a new algorithm for the probabilistic verificationof neural networks based on an algorithm for computing and iteratively refininglower and upper bounds on probabilities over the outputs of a neural network.By applying state-of-the-art bound propagation and branch and bound techniquesfrom non-probabilistic neural network verification, our algorithm significantlyoutpaces existing probabilistic verification algorithms, reducing solving timesfor various benchmarks from the literature from tens of minutes to tens ofseconds. Furthermore, our algorithm compares favourably even to dedicatedalgorithms for restricted subsets of probabilistic verification. We complementour empirical evaluation with a theoretical analysis, proving that ouralgorithm is sound and, under mildly restrictive conditions, also complete whenusing a suitable set of heuristics.</description><author>David Boetius, Stefan Leue, Tobias Sutter</author><pubDate>Thu, 30 Jan 2025 15:57:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17556v2</guid></item><item><title>Quantifying uncertainty in lung cancer segmentation with foundation models applied to mixed-domain datasets</title><link>http://arxiv.org/abs/2403.13113v3</link><description>Medical image foundation models have shown the ability to segment organs andtumors with minimal fine-tuning. These models are typically evaluated ontask-specific in-distribution (ID) datasets. However, reliable performance onID datasets does not guarantee robust generalization on out-of-distribution(OOD) datasets. Importantly, once deployed for clinical use, it is impracticalto have `ground truth' delineations to assess ongoing performance drifts,especially when images fall into the OOD category due to different imagingprotocols. Hence, we introduced a comprehensive set of computationally fastmetrics to evaluate the performance of multiple foundation models (Swin UNETR,SimMIM, iBOT, SMIT) trained with self-supervised learning (SSL). All modelswere fine-tuned on identical datasets for lung tumor segmentation from computedtomography (CT) scans. The evaluation was performed on two public lung cancerdatasets (LRAD: n = 140, 5Rater: n = 21) with different image acquisitions andtumor stages compared to training data (n = 317 public resource with stageIII-IV lung cancers) and a public non-cancer dataset containing volumetric CTscans of patients with pulmonary embolism (n = 120). All models producedsimilarly accurate tumor segmentation on the lung cancer testing datasets. SMITproduced the highest F1-score (LRAD: 0.60, 5Rater: 0.64) and lowest entropy(LRAD: 0.06, 5Rater: 0.12), indicating higher tumor detection rate andconfident segmentations. In the OOD dataset, SMIT misdetected the least numberof tumors, marked by a median volume occupancy of 5.67 cc compared to the bestmethod SimMIM of 9.97 cc. Our analysis shows that additional metrics such asentropy and volume occupancy may help better understand model performance onmixed domain datasets.</description><author>Aneesh Rangnekar, Nishant Nadkarni, Jue Jiang, Harini Veeraraghavan</author><pubDate>Thu, 30 Jan 2025 15:57:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13113v3</guid></item><item><title>Adaptive Object Detection for Indoor Navigation Assistance: A Performance Evaluation of Real-Time Algorithms</title><link>http://arxiv.org/abs/2501.18444v1</link><description>This study addresses the need for accurate and efficient object detection inassistive technologies for visually impaired individuals. We evaluate fourreal-time object detection algorithms YOLO, SSD, Faster R-CNN, and Mask R-CNNwithin the context of indoor navigation assistance. Using the Indoor ObjectsDetection dataset, we analyze detection accuracy, processing speed, andadaptability to indoor environments. Our findings highlight the trade-offsbetween precision and efficiency, offering insights into selecting optimalalgorithms for realtime assistive navigation. This research advances adaptivemachine learning applications, enhancing indoor navigation solutions for thevisually impaired and promoting accessibility.</description><author>Abhinav Pratap, Sushant Kumar, Suchinton Chakravarty</author><pubDate>Thu, 30 Jan 2025 15:56:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18444v1</guid></item><item><title>Generative Adversarial Reduced Order Modelling</title><link>http://arxiv.org/abs/2305.15881v2</link><description>In this work, we present GAROM, a new approach for reduced order modelling(ROM) based on generative adversarial networks (GANs). GANs have the potentialto learn data distribution and generate more realistic data. While widelyapplied in many areas of deep learning, little research is done on theirapplication for ROM, i.e. approximating a high-fidelity model with a simplerone. In this work, we combine the GAN and ROM framework, by introducing adata-driven generative adversarial model able to learn solutions to parametricdifferential equations. The latter is achieved by modelling the discriminatornetwork as an autoencoder, extracting relevant features of the input, andapplying a conditioning mechanism to the generator and discriminator networksspecifying the differential equation parameters. We show how to apply ourmethodology for inference, provide experimental evidence of the modelgeneralisation, and perform a convergence study of the method.</description><author>Dario Coscia, Nicola Demo, Gianluigi Rozza</author><pubDate>Thu, 30 Jan 2025 15:55:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15881v2</guid></item><item><title>MolGraph-xLSTM: A graph-based dual-level xLSTM framework with multi-head mixture-of-experts for enhanced molecular representation and interpretability</title><link>http://arxiv.org/abs/2501.18439v1</link><description>Predicting molecular properties is essential for drug discovery, andcomputational methods can greatly enhance this process. Molecular graphs havebecome a focus for representation learning, with Graph Neural Networks (GNNs)widely used. However, GNNs often struggle with capturing long-rangedependencies. To address this, we propose MolGraph-xLSTM, a novel graph-basedxLSTM model that enhances feature extraction and effectively models moleculelong-range interactions. Our approach processes molecular graphs at two scales: atom-level andmotif-level. For atom-level graphs, a GNN-based xLSTM framework with jumpingknowledge extracts local features and aggregates multilayer information tocapture both local and global patterns effectively. Motif-level graphs providecomplementary structural information for a broader molecular view. Embeddingsfrom both scales are refined via a multi-head mixture of experts (MHMoE),further enhancing expressiveness and performance. We validate MolGraph-xLSTM on 10 molecular property prediction datasets,covering both classification and regression tasks. Our model demonstratesconsistent performance across all datasets, with improvements of up to 7.03% onthe BBBP dataset for classification and 7.54% on the ESOL dataset forregression compared to baselines. On average, MolGraph-xLSTM achieves an AUROCimprovement of 3.18\% for classification tasks and an RMSE reduction of 3.83\%across regression datasets compared to the baseline methods. These resultsconfirm the effectiveness of our model, offering a promising solution formolecular representation learning for drug discovery.</description><author>Yan Sun, Yutong Lu, Yan Yi Li, Zihao Jing, Carson K. Leung, Pingzhao Hu</author><pubDate>Thu, 30 Jan 2025 15:47:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18439v1</guid></item><item><title>LLMs &amp; XAI for Water Sustainability: Seasonal Water Quality Prediction with LIME Explainable AI and a RAG-based Chatbot for Insights</title><link>http://arxiv.org/abs/2409.10898v2</link><description>Ensuring safe water supplies requires effective water quality monitoring,especially in developing countries like Nepal, where contamination risks arehigh. This paper introduces a hybrid deep learning model to predict Nepal'sseasonal water quality using a small dataset with multiple water qualityparameters. Models such as CatBoost, XGBoost, Extra Trees, and LightGBM, alongwith a neural network combining CNN and RNN layers, are used to capturetemporal and spatial patterns in the data. The model demonstrated notableaccuracy improvements, aiding proactive water quality control. CatBoost,XGBoost, and Extra Trees Regressor predicted Water Quality Index (WQI) valueswith an average RMSE of 1.2 and an R2 score of 0.99. Additionally, classifiersachieved 99 percent accuracy, cross-validated across models. LIME analysishighlighted the importance of indicators like EC and DO levels in XGBoostclassification decisions. The neural network model achieved 92 percentclassification accuracy and an R2 score of 0.97, with an RMSE of 2.87 inregression analysis. Furthermore, a multifunctional application was developedto predict WQI values using both regression and classification methods.</description><author>Biplov Paneru, Bishwash Paneru</author><pubDate>Thu, 30 Jan 2025 15:47:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.10898v2</guid></item><item><title>o3-mini vs DeepSeek-R1: Which One is Safer?</title><link>http://arxiv.org/abs/2501.18438v1</link><description>The irruption of DeepSeek-R1 constitutes a turning point for the AI industryin general and the LLMs in particular. Its capabilities have demonstratedoutstanding performance in several tasks, including creative thinking, codegeneration, maths and automated program repair, at apparently lower executioncost. However, LLMs must adhere to an important qualitative property, i.e.,their alignment with safety and human values. A clear competitor of DeepSeek-R1is its American counterpart, OpenAI's o3-mini model, which is expected to sethigh standards in terms of performance, safety and cost. In this paper weconduct a systematic assessment of the safety level of both, DeepSeek-R1 (70bversion) and OpenAI's o3-mini (beta version). To this end, we make use of ourrecently released automated safety testing tool, named ASTRAL. By leveragingthis tool, we automatically and systematically generate and execute a total of1260 unsafe test inputs on both models. After conducting a semi-automatedassessment of the outcomes provided by both LLMs, the results indicate thatDeepSeek-R1 is highly unsafe as compared to OpenAI's o3-mini. Based on ourevaluation, DeepSeek-R1 answered unsafely to 11.98% of the executed promptswhereas o3-mini only to 1.19%.</description><author>Aitor Arrieta, Miriam Ugarte, Pablo Valle, José Antonio Parejo, Sergio Segura</author><pubDate>Thu, 30 Jan 2025 15:45:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18438v1</guid></item><item><title>Large Language Models Reflect the Ideology of their Creators</title><link>http://arxiv.org/abs/2410.18417v2</link><description>Large language models (LLMs) are trained on vast amounts of data to generatenatural language, enabling them to perform tasks like text summarization andquestion answering. These models have become popular in artificial intelligence(AI) assistants like ChatGPT and already play an influential role in how humansaccess information. However, the behavior of LLMs varies depending on theirdesign, training, and use. In this paper, we prompt a diverse panel of popular LLMs to describe a largenumber of prominent personalities with political relevance, in all six officiallanguages of the United Nations. By identifying and analyzing moral assessmentsreflected in their responses, we find normative differences between LLMs fromdifferent geopolitical regions, as well as between the responses of the sameLLM when prompted in different languages. Among only models in the UnitedStates, we find that popularly hypothesized disparities in political views arereflected in significant normative differences related to progressive values.Among Chinese models, we characterize a division between internationally- anddomestically-focused models. Our results show that the ideological stance of an LLM appears to reflect theworldview of its creators. This poses the risk of political instrumentalizationand raises concerns around technological and regulatory efforts with the statedaim of making LLMs ideologically 'unbiased'.</description><author>Maarten Buyl, Alexander Rogiers, Sander Noels, Guillaume Bied, Iris Dominguez-Catena, Edith Heiter, Iman Johary, Alexandru-Cristian Mara, Raphaël Romero, Jefrey Lijffijt, Tijl De Bie</author><pubDate>Thu, 30 Jan 2025 15:45:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.18417v2</guid></item><item><title>GENIE: Generative Note Information Extraction model for structuring EHR data</title><link>http://arxiv.org/abs/2501.18435v1</link><description>Electronic Health Records (EHRs) hold immense potential for advancinghealthcare, offering rich, longitudinal data that combines structuredinformation with valuable insights from unstructured clinical notes. However,the unstructured nature of clinical text poses significant challenges forsecondary applications. Traditional methods for structuring EHR free-text data,such as rule-based systems and multi-stage pipelines, are often limited bytheir time-consuming configurations and inability to adapt across clinicalnotes from diverse healthcare settings. Few systems provide a comprehensiveattribute extraction for terminologies. While giant large language models(LLMs) like GPT-4 and LLaMA 405B excel at structuring tasks, they are slow,costly, and impractical for large-scale use. To overcome these limitations, weintroduce GENIE, a Generative Note Information Extraction system that leveragesLLMs to streamline the structuring of unstructured clinical text into usabledata with standardized format. GENIE processes entire paragraphs in a singlepass, extracting entities, assertion statuses, locations, modifiers, values,and purposes with high accuracy. Its unified, end-to-end approach simplifiesworkflows, reduces errors, and eliminates the need for extensive manualintervention. Using a robust data preparation pipeline and fine-tuned smallscale LLMs, GENIE achieves competitive performance across multiple informationextraction tasks, outperforming traditional tools like cTAKES and MetaMap andcan handle extra attributes to be extracted. GENIE strongly enhances real-worldapplicability and scalability in healthcare systems. By open-sourcing the modeland test data, we aim to encourage collaboration and drive further advancementsin EHR structurization.</description><author>Huaiyuan Ying, Hongyi Yuan, Jinsen Lu, Zitian Qu, Yang Zhao, Zhengyun Zhao, Isaac Kohane, Tianxi Cai, Sheng Yu</author><pubDate>Thu, 30 Jan 2025 15:42:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18435v1</guid></item><item><title>Solving Drone Routing Problems with Quantum Computing: A Hybrid Approach Combining Quantum Annealing and Gate-Based Paradigms</title><link>http://arxiv.org/abs/2501.18432v1</link><description>This paper presents a novel hybrid approach to solving real-world dronerouting problems by leveraging the capabilities of quantum computing. Theproposed method, coined Quantum for Drone Routing (Q4DR), integrates the twomost prominent paradigms in the field: quantum gate-based computing, throughthe Eclipse Qrisp programming language; and quantum annealers, by means ofD-Wave System's devices. The algorithm is divided into two different phases: aninitial clustering phase executed using a Quantum Approximate OptimizationAlgorithm (QAOA), and a routing phase employing quantum annealers. The efficacyof Q4DR is demonstrated through three use cases of increasing complexity, eachincorporating real-world constraints such as asymmetric costs, forbidden paths,and itinerant charging points. This research contributes to the growing body ofwork in quantum optimization, showcasing the practical applications of quantumcomputing in logistics and route planning.</description><author>Eneko Osaba, Pablo Miranda-Rodriguez, Andreas Oikonomakis, Matic Petrič, Sebastian Bock, Michail-Alexandros Kourtis</author><pubDate>Thu, 30 Jan 2025 15:38:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18432v1</guid></item><item><title>Universal Rates of Empirical Risk Minimization</title><link>http://arxiv.org/abs/2412.02810v2</link><description>The well-known empirical risk minimization (ERM) principle is the basis ofmany widely used machine learning algorithms, and plays an essential role inthe classical PAC theory. A common description of a learning algorithm'sperformance is its so-called "learning curve", that is, the decay of theexpected error as a function of the input sample size. As the PAC model failsto explain the behavior of learning curves, recent research has explored analternative universal learning model and has ultimately revealed a distinctionbetween optimal universal and uniform learning rates (Bousquet et al., 2021).However, a basic understanding of such differences with a particular focus onthe ERM principle has yet to be developed. In this paper, we consider the problem of universal learning by ERM in therealizable case and study the possible universal rates. Our main result is afundamental tetrachotomy: there are only four possible universal learning ratesby ERM, namely, the learning curves of any concept class learnable by ERM decayeither at $e^{-n}$, $1/n$, $\log(n)/n$, or arbitrarily slow rates. Moreover, weprovide a complete characterization of which concept classes fall into each ofthese categories, via new complexity structures. We also develop newcombinatorial dimensions which supply sharp asymptotically-valid constantfactors for these rates, whenever possible.</description><author>Steve Hanneke, Mingyue Xu</author><pubDate>Thu, 30 Jan 2025 15:36:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.02810v2</guid></item><item><title>Advancing the Understanding and Evaluation of AR-Generated Scenes: When Vision-Language Models Shine and Stumble</title><link>http://arxiv.org/abs/2501.13964v2</link><description>Augmented Reality (AR) enhances the real world by integrating virtualcontent, yet ensuring the quality, usability, and safety of AR experiencespresents significant challenges. Could Vision-Language Models (VLMs) offer asolution for the automated evaluation of AR-generated scenes? CouldVision-Language Models (VLMs) offer a solution for the automated evaluation ofAR-generated scenes? In this study, we evaluate the capabilities of threestate-of-the-art commercial VLMs -- GPT, Gemini, and Claude -- in identifyingand describing AR scenes. For this purpose, we use DiverseAR, the first ARdataset specifically designed to assess VLMs' ability to analyze virtualcontent across a wide range of AR scene complexities. Our findings demonstratethat VLMs are generally capable of perceiving and describing AR scenes,achieving a True Positive Rate (TPR) of up to 93% for perception and 71% fordescription. While they excel at identifying obvious virtual objects, such as aglowing apple, they struggle when faced with seamlessly integrated content,such as a virtual pot with realistic shadows. Our results highlight both thestrengths and the limitations of VLMs in understanding AR scenarios. Weidentify key factors affecting VLM performance, including virtual contentplacement, rendering quality, and physical plausibility. This study underscoresthe potential of VLMs as tools for evaluating the quality of AR experiences.</description><author>Lin Duan, Yanming Xiu, Maria Gorlatova</author><pubDate>Thu, 30 Jan 2025 15:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13964v2</guid></item><item><title>Clipped SGD Algorithms for Performative Prediction: Tight Bounds for Clipping Bias and Remedies</title><link>http://arxiv.org/abs/2404.10995v2</link><description>This paper studies the convergence of clipped stochastic gradient descent(SGD) algorithms with decision-dependent data distribution. Our setting ismotivated by privacy preserving optimization algorithms that interact withperformative data where the prediction models can influence future outcomes.This challenging setting involves the non-smooth clipping operator andnon-gradient dynamics due to distribution shifts. We make two contributions inpursuit for a performative stable solution using clipped SGD algorithms. First,we characterize the clipping bias with projected clipped SGD (PCSGD) algorithmwhich is caused by the clipping operator that prevents PCSGD from reaching astable solution. When the loss function is strongly convex, we quantify thelower and upper bounds for this clipping bias and demonstrate a biasamplification phenomenon with the sensitivity of data distribution. When theloss function is non-convex, we bound the magnitude of stationarity bias.Second, we propose remedies to mitigate the bias either by utilizing an optimalstep size design for PCSGD, or to apply the recent DiceSGD algorithm [Zhang etal., 2024]. Our analysis is also extended to show that the latter algorithm isfree from clipping bias in the performative setting. Numerical experimentsverify our findings.</description><author>Qiang Li, Michal Yemini, Hoi-To Wai</author><pubDate>Thu, 30 Jan 2025 15:32:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10995v2</guid></item><item><title>SANA 1.5: Efficient Scaling of Training-Time and Inference-Time Compute in Linear Diffusion Transformer</title><link>http://arxiv.org/abs/2501.18427v1</link><description>This paper presents SANA-1.5, a linear Diffusion Transformer for efficientscaling in text-to-image generation. Building upon SANA-1.0, we introduce threekey innovations: (1) Efficient Training Scaling: A depth-growth paradigm thatenables scaling from 1.6B to 4.8B parameters with significantly reducedcomputational resources, combined with a memory-efficient 8-bit optimizer. (2)Model Depth Pruning: A block importance analysis technique for efficient modelcompression to arbitrary sizes with minimal quality loss. (3) Inference-timeScaling: A repeated sampling strategy that trades computation for modelcapacity, enabling smaller models to match larger model quality at inferencetime. Through these strategies, SANA-1.5 achieves a text-image alignment scoreof 0.72 on GenEval, which can be further improved to 0.80 through inferencescaling, establishing a new SoTA on GenEval benchmark. These innovations enableefficient model scaling across different compute budgets while maintaining highquality, making high-quality image generation more accessible.</description><author>Enze Xie, Junsong Chen, Yuyang Zhao, Jincheng Yu, Ligeng Zhu, Yujun Lin, Zhekai Zhang, Muyang Li, Junyu Chen, Han Cai, Bingchen Liu, Daquan Zhou, Song Han</author><pubDate>Thu, 30 Jan 2025 15:31:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18427v1</guid></item><item><title>Effective Learning with Node Perturbation in Multi-Layer Neural Networks</title><link>http://arxiv.org/abs/2310.00965v5</link><description>Backpropagation (BP) remains the dominant and most successful method fortraining parameters of deep neural network models. However, BP relies on twocomputationally distinct phases, does not provide a satisfactory explanation ofbiological learning, and can be challenging to apply for training of networkswith discontinuities or noisy node dynamics. By comparison, node perturbation(NP) proposes learning by the injection of noise into network activations, andsubsequent measurement of the induced loss change. NP relies on two forward(inference) passes, does not make use of network derivatives, and has beenproposed as a model for learning in biological systems. However, standard NP ishighly data inefficient and unstable due to its unguided noise-based searchprocess. In this work, we investigate different formulations of NP and relateit to the concept of directional derivatives as well as combining it with adecorrelating mechanism for layer-wise inputs. We find that a closer alignmentwith directional derivatives together with input decorrelation at every layerstrongly enhances performance of NP learning with large improvements inparameter convergence and much higher performance on the test data, approachingthat of BP. Furthermore, our novel formulation allows for application to noisysystems in which the noise process itself is inaccessible.</description><author>Sander Dalm, Marcel van Gerven, Nasir Ahmad</author><pubDate>Thu, 30 Jan 2025 15:30:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00965v5</guid></item><item><title>Guaranteed confidence-band enclosures for PDE surrogates</title><link>http://arxiv.org/abs/2501.18426v1</link><description>We propose a method for obtaining statistically guaranteed confidence bandsfor functional machine learning techniques: surrogate models which map betweenfunction spaces, motivated by the need build reliable PDE emulators. The methodconstructs nested confidence sets on a low-dimensional representation (an SVD)of the surrogate model's prediction error, and then maps these sets to theprediction space using set-propagation techniques. The result areconformal-like coverage guaranteed prediction sets for functional surrogatemodels. We use zonotopes as basis of the set construction, due to their wellstudied set-propagation and verification properties. The method is modelagnostic and can thus be applied to complex Sci-ML models, including NeuralOperators, but also in simpler settings. We also elicit a technique to capturethe truncation error of the SVD, ensuring the guarantees of the method.</description><author>Ander Gray, Vignesh Gopakumar, Sylvain Rousseau, Sébastien Destercke</author><pubDate>Thu, 30 Jan 2025 15:29:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18426v1</guid></item></channel></rss>