<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 19 Jan 2025 01:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Distilling Multi-modal Large Language Models for Autonomous Driving</title><link>http://arxiv.org/abs/2501.09757v1</link><description>Autonomous driving demands safe motion planning, especially in critical"long-tail" scenarios. Recent end-to-end autonomous driving systems leveragelarge language models (LLMs) as planners to improve generalizability to rareevents. However, using LLMs at test time introduces high computational costs.To address this, we propose DiMA, an end-to-end autonomous driving system thatmaintains the efficiency of an LLM-free (or vision-based) planner whileleveraging the world knowledge of an LLM. DiMA distills the information from amulti-modal LLM to a vision-based end-to-end planner through a set of speciallydesigned surrogate tasks. Under a joint training strategy, a scene encodercommon to both networks produces structured representations that aresemantically grounded as well as aligned to the final planning objective.Notably, the LLM is optional at inference, enabling robust planning withoutcompromising on efficiency. Training with DiMA results in a 37% reduction inthe L2 trajectory error and an 80% reduction in the collision rate of thevision-based planner, as well as a 44% trajectory error reduction in longtailscenarios. DiMA also achieves state-of-the-art performance on the nuScenesplanning benchmark.</description><author>Deepti Hegde, Rajeev Yasarla, Hong Cai, Shizhong Han, Apratim Bhattacharyya, Shweta Mahajan, Litian Liu, Risheek Garrepalli, Vishal M. Patel, Fatih Porikli</author><pubDate>Thu, 16 Jan 2025 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09757v1</guid></item><item><title>Algorithmic Collective Action in Recommender Systems: Promoting Songs by Reordering Playlists</title><link>http://arxiv.org/abs/2404.04269v2</link><description>We investigate algorithmic collective action in transformer-based recommendersystems. Our use case is a music streaming platform where a collective of fansaims to promote the visibility of an underrepresented artist by strategicallyplacing one of their songs in the existing playlists they control. We introducetwo easily implementable strategies to select the position at which to insertthe song with the goal to boost recommendations at test time. The strategiesexploit statistical properties of the learner by targeting discontinuities inthe recommendations, and leveraging the long-tail nature of song distributions.We evaluate the efficacy of our strategies using a publicly availablerecommender system model released by a major music streaming platform. Ourfindings reveal that through strategic placement even small collectives(controlling less than 0.01\% of the training data) can achieve up to$40\times$ more test time recommendations than an average song with the samenumber of training set occurrences. Focusing on the externalities of thestrategy, we find that the recommendations of other songs are largelypreserved, and the newly gained recommendations are distributed across variousartists. Together, our findings demonstrate how carefully designed collectiveaction strategies can be effective while not necessarily being adversarial.</description><author>Joachim Baumann, Celestine Mendler-Dünner</author><pubDate>Thu, 16 Jan 2025 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04269v2</guid></item><item><title>SynthLight: Portrait Relighting with Diffusion Model by Learning to Re-render Synthetic Faces</title><link>http://arxiv.org/abs/2501.09756v1</link><description>We introduce SynthLight, a diffusion model for portrait relighting. Ourapproach frames image relighting as a re-rendering problem, where pixels aretransformed in response to changes in environmental lighting conditions. Usinga physically-based rendering engine, we synthesize a dataset to simulate thislighting-conditioned transformation with 3D head assets under varying lighting.We propose two training and inference strategies to bridge the gap between thesynthetic and real image domains: (1) multi-task training that takes advantageof real human portraits without lighting labels; (2) an inference timediffusion sampling procedure based on classifier-free guidance that leveragesthe input portrait to better preserve details. Our method generalizes todiverse real photographs and produces realistic illumination effects, includingspecular highlights and cast shadows, while preserving the subject's identity.Our quantitative experiments on Light Stage data demonstrate results comparableto state-of-the-art relighting methods. Our qualitative results on in-the-wildimages showcase rich and unprecedented illumination effects. Project Page:\url{https://vrroom.github.io/synthlight/}</description><author>Sumit Chaturvedi, Mengwei Ren, Yannick Hold-Geoffroy, Jingyuan Liu, Julie Dorsey, Zhixin Shu</author><pubDate>Thu, 16 Jan 2025 18:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09756v1</guid></item><item><title>Learnings from Scaling Visual Tokenizers for Reconstruction and Generation</title><link>http://arxiv.org/abs/2501.09755v1</link><description>Visual tokenization via auto-encoding empowers state-of-the-art image andvideo generative models by compressing pixels into a latent space. Althoughscaling Transformer-based generators has been central to recent advances, thetokenizer component itself is rarely scaled, leaving open questions about howauto-encoder design choices influence both its objective of reconstruction anddownstream generative performance. Our work aims to conduct an exploration ofscaling in auto-encoders to fill in this blank. To facilitate this exploration,we replace the typical convolutional backbone with an enhanced VisionTransformer architecture for Tokenization (ViTok). We train ViTok onlarge-scale image and video datasets far exceeding ImageNet-1K, removing dataconstraints on tokenizer scaling. We first study how scaling the auto-encoderbottleneck affects both reconstruction and generation -- and find that while itis highly correlated with reconstruction, its relationship with generation ismore complex. We next explored the effect of separately scaling theauto-encoders' encoder and decoder on reconstruction and generationperformance. Crucially, we find that scaling the encoder yields minimal gainsfor either reconstruction or generation, while scaling the decoder boostsreconstruction but the benefits for generation are mixed. Building on ourexploration, we design ViTok as a lightweight auto-encoder that achievescompetitive performance with state-of-the-art auto-encoders on ImageNet-1K andCOCO reconstruction tasks (256p and 512p) while outperforming existingauto-encoders on 16-frame 128p video reconstruction for UCF-101, all with 2-5xfewer FLOPs. When integrated with Diffusion Transformers, ViTok demonstratescompetitive performance on image generation for ImageNet-1K and sets newstate-of-the-art benchmarks for class-conditional video generation on UCF-101.</description><author>Philippe Hansen-Estruch, David Yan, Ching-Yao Chung, Orr Zohar, Jialiang Wang, Tingbo Hou, Tao Xu, Sriram Vishwanath, Peter Vajda, Xinlei Chen</author><pubDate>Thu, 16 Jan 2025 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09755v1</guid></item><item><title>Lost in Translation, Found in Context: Sign Language Translation with Contextual Cues</title><link>http://arxiv.org/abs/2501.09754v1</link><description>Our objective is to translate continuous sign language into spoken languagetext. Inspired by the way human interpreters rely on context for accuratetranslation, we incorporate additional contextual cues together with thesigning video, into a new translation framework. Specifically, besides visualsign recognition features that encode the input video, we integratecomplementary textual information from (i) captions describing the backgroundshow, (ii) translation of previous sentences, as well as (iii) pseudo-glossestranscribing the signing. These are automatically extracted and inputted alongwith the visual features to a pre-trained large language model (LLM), which wefine-tune to generate spoken language translations in text form. Throughextensive ablation studies, we show the positive contribution of each input cueto the translation performance. We train and evaluate our approach on BOBSL --the largest British Sign Language dataset currently available. We show that ourcontextual approach significantly enhances the quality of the translationscompared to previously reported results on BOBSL, and also to state-of-the-artmethods that we implement as baselines. Furthermore, we demonstrate thegenerality of our approach by applying it also to How2Sign, an American SignLanguage dataset, and achieve competitive results.</description><author>Youngjoon Jang, Haran Raajesh, Liliane Momeni, Gül Varol, Andrew Zisserman</author><pubDate>Thu, 16 Jan 2025 18:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09754v1</guid></item><item><title>SRE-Conv: Symmetric Rotation Equivariant Convolution for Biomedical Image Classification</title><link>http://arxiv.org/abs/2501.09753v1</link><description>Convolutional neural networks (CNNs) are essential tools for computer visiontasks, but they lack traditionally desired properties of extracted featuresthat could further improve model performance, e.g., rotational equivariance.Such properties are ubiquitous in biomedical images, which often lack explicitorientation. While current work largely relies on data augmentation or explicitmodules to capture orientation information, this comes at the expense ofincreased training costs or ineffective approximations of the desiredequivariance. To overcome these challenges, we propose a novel and efficientimplementation of the Symmetric Rotation-Equivariant (SRE) Convolution(SRE-Conv) kernel, designed to learn rotation-invariant features whilesimultaneously compressing the model size. The SRE-Conv kernel can easily beincorporated into any CNN backbone. We validate the ability of a deep SRE-CNNto capture equivariance to rotation using the public MedMNISTv2 dataset (16total tasks). SRE-Conv-CNN demonstrated improved rotated image classificationperformance accuracy on all 16 test datasets in both 2D and 3D images, allwhile increasing efficiency with fewer parameters and reduced memory footprint.The code is available at https://github.com/XYPB/SRE-Conv.</description><author>Yuexi Du, Jiazhen Zhang, Tal Zeevi, Nicha C. Dvornek, John A. Onofrey</author><pubDate>Thu, 16 Jan 2025 18:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09753v1</guid></item><item><title>FutureDepth: Learning to Predict the Future Improves Video Depth Estimation</title><link>http://arxiv.org/abs/2403.12953v2</link><description>In this paper, we propose a novel video depth estimation approach,FutureDepth, which enables the model to implicitly leverage multi-frame andmotion cues to improve depth estimation by making it learn to predict thefuture at training. More specifically, we propose a future prediction network,F-Net, which takes the features of multiple consecutive frames and is trainedto predict multi-frame features one time step ahead iteratively. In this way,F-Net learns the underlying motion and correspondence information, and weincorporate its features into the depth decoding process. Additionally, toenrich the learning of multiframe correspondence cues, we further leverage areconstruction network, R-Net, which is trained via adaptively maskedauto-encoding of multiframe feature volumes. At inference time, both F-Net andR-Net are used to produce queries to work with the depth decoder, as well as afinal refinement network. Through extensive experiments on several benchmarks,i.e., NYUDv2, KITTI, DDAD, and Sintel, which cover indoor, driving, andopen-domain scenarios, we show that FutureDepth significantly improves uponbaseline models, outperforms existing video depth estimation methods, and setsnew state-of-the-art (SOTA) accuracy. Furthermore, FutureDepth is moreefficient than existing SOTA video depth estimation models and has similarlatencies when comparing to monocular models</description><author>Rajeev Yasarla, Manish Kumar Singh, Hong Cai, Yunxiao Shi, Jisoo Jeong, Yinhao Zhu, Shizhong Han, Risheek Garrepalli, Fatih Porikli</author><pubDate>Thu, 16 Jan 2025 18:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.12953v2</guid></item><item><title>OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking</title><link>http://arxiv.org/abs/2501.09751v1</link><description>Machine writing with large language models often relies onretrieval-augmented generation. However, these approaches remain confinedwithin the boundaries of the model's predefined scope, limiting the generationof content with rich information. Specifically, vanilla-retrieved informationtends to lack depth, utility, and suffers from redundancy, which negativelyimpacts the quality of generated articles, leading to shallow, repetitive, andunoriginal outputs. To address these issues, we propose OmniThink, a machinewriting framework that emulates the human-like process of iterative expansionand reflection. The core idea behind OmniThink is to simulate the cognitivebehavior of learners as they progressively deepen their knowledge of thetopics. Experimental results demonstrate that OmniThink improves the knowledgedensity of generated articles without compromising metrics such as coherenceand depth. Human evaluations and expert feedback further highlight thepotential of OmniThink to address real-world challenges in the generation oflong-form articles.</description><author>Zekun Xi, Wenbiao Yin, Jizhan Fang, Jialong Wu, Runnan Fang, Ningyu Zhang, Jiang Yong, Pengjun Xie, Fei Huang, Huajun Chen</author><pubDate>Thu, 16 Jan 2025 18:58:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09751v1</guid></item><item><title>Enhancing Lexicon-Based Text Embeddings with Large Language Models</title><link>http://arxiv.org/abs/2501.09749v1</link><description>Recent large language models (LLMs) have demonstrated exceptional performanceon general-purpose text embedding tasks. While dense embeddings have dominatedrelated research, we introduce the first Lexicon-based EmbeddiNgS (LENS)leveraging LLMs that achieve competitive performance on these tasks. Regardingthe inherent tokenization redundancy issue and unidirectional attentionlimitations in traditional causal LLMs, LENS consolidates the vocabulary spacethrough token embedding clustering, and investigates bidirectional attentionand various pooling strategies. Specifically, LENS simplifies lexicon matchingby assigning each dimension to a specific token cluster, where semanticallysimilar tokens are grouped together, and unlocking the full potential of LLMsthrough bidirectional attention. Extensive experiments demonstrate that LENSoutperforms dense embeddings on the Massive Text Embedding Benchmark (MTEB),delivering compact feature representations that match the sizes of densecounterparts. Notably, combining LENSE with dense embeddings achievesstate-of-the-art performance on the retrieval subset of MTEB (i.e. BEIR).</description><author>Yibin Lei, Tao Shen, Yu Cao, Andrew Yates</author><pubDate>Thu, 16 Jan 2025 18:57:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09749v1</guid></item><item><title>FAST: Efficient Action Tokenization for Vision-Language-Action Models</title><link>http://arxiv.org/abs/2501.09747v1</link><description>Autoregressive sequence models, such as Transformer-based vision-languageaction (VLA) policies, can be tremendously effective for capturing complex andgeneralizable robotic behaviors. However, such models require us to choose atokenization of our continuous action signals, which determines how thediscrete symbols predicted by the model map to continuous robot actions. Wefind that current approaches for robot action tokenization, based on simpleper-dimension, per-timestep binning schemes, typically perform poorly whenlearning dexterous skills from high-frequency robot data. To address thischallenge, we propose a new compression-based tokenization scheme for robotactions, based on the discrete cosine transform. Our tokenization approach,Frequency-space Action Sequence Tokenization (FAST), enables us to trainautoregressive VLAs for highly dexterous and high-frequency tasks wherestandard discretization methods fail completely. Based on FAST, we releaseFAST+, a universal robot action tokenizer, trained on 1M real robot actiontrajectories. It can be used as a black-box tokenizer for a wide range of robotaction sequences, with diverse action spaces and control frequencies. Finally,we show that, when combined with the pi0 VLA, our method can scale to trainingon 10k hours of robot data and match the performance of diffusion VLAs, whilereducing training time by up to 5x.</description><author>Karl Pertsch, Kyle Stachowicz, Brian Ichter, Danny Driess, Suraj Nair, Quan Vuong, Oier Mees, Chelsea Finn, Sergey Levine</author><pubDate>Thu, 16 Jan 2025 18:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09747v1</guid></item><item><title>Meaning-Typed Programming: Language-level Abstractions and Runtime for GenAI Applications</title><link>http://arxiv.org/abs/2405.08965v3</link><description>Software is rapidly evolving from being programmed with traditional logicalcode, to neuro-integrated applications that leverage generative AI and largelanguage models (LLMs) for application functionality. This shift increases thecomplexity of building applications, as developers now must reasoning about,program, and prompt LLMs. Despite efforts to create tools to assist with promptengineering, these solutions often introduce additional layers of complexity tothe development of neuro-integrated applications. This paper proposesmeaning-typed programming (MTP), a novel approach to simplify the creation ofneuro-integrated applications by introducing new language-level abstractionsthat hide the complexities of LLM integration. Our key insight is that typicalconventional code already possesses a high level of semantic richness that canbe automatically reasoned about, as it is designed to be readable andmaintainable by humans. Leveraging this insight, we conceptualize LLMs asmeaning-typed code constructs and introduce a by abstraction at the languagelevel, MT-IR, a new meaning-based intermediate representation at the compilerlevel, and MT Runtime, an automated run-time engine for LLM integration andoperations. We implement MTP in a production-grade Python super-set languagecalled Jac and perform an extensive evaluation. Our results demonstrate thatMTP not only simplifies the development process but also meets or exceeds theefficacy of state-of-the-art manual and tool-assisted prompt engineeringtechniques in terms of accuracy and usability.</description><author>Jason Mars, Yiping Kang, Jayanaka L. Dantanarayana, Kugesan Sivasothynathan, Christopher Clarke, Baichuan Li, Krisztian Flautner, Lingjia Tang</author><pubDate>Thu, 16 Jan 2025 18:56:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08965v3</guid></item><item><title>Suggesting Code Edits in Interactive Machine Learning Notebooks Using Large Language Models</title><link>http://arxiv.org/abs/2501.09745v1</link><description>Machine learning developers frequently use interactive computationalnotebooks, such as Jupyter notebooks, to host code for data processing andmodel training. Jupyter notebooks provide a convenient tool for writing machinelearning pipelines and interactively observing outputs, however, maintainingJupyter notebooks, e.g., to add new features or fix bugs, can be challengingdue to the length and complexity of the notebooks. Moreover, there is noexisting benchmark related to developer edits on Jupyter notebooks. To addressthis, we present the first dataset of 48,398 Jupyter notebook edits derivedfrom 20,095 revisions of 792 machine learning repositories on GitHub, andperform the first study of the using LLMs to predict code edits in Jupyternotebooks. Our dataset captures granular details of cell-level and line-levelmodifications, offering a foundation for understanding real-world maintenancepatterns in machine learning workflows. We observed that the edits on Jupyternotebooks are highly localized, with changes averaging only 166 lines of codein repositories. While larger models outperform smaller counterparts in codeediting, all models have low accuracy on our dataset even after finetuning,demonstrating the complexity of real-world machine learning maintenance tasks.Our findings emphasize the critical role of contextual information in improvingmodel performance and point toward promising avenues for advancing largelanguage models' capabilities in engineering machine learning code.</description><author>Bihui Jin, Jiayue Wang, Pengyu Nie</author><pubDate>Thu, 16 Jan 2025 18:55:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09745v1</guid></item><item><title>MAMo: Leveraging Memory and Attention for Monocular Video Depth Estimation</title><link>http://arxiv.org/abs/2307.14336v3</link><description>We propose MAMo, a novel memory and attention frame-work for monocular videodepth estimation. MAMo can augment and improve any single-image depthestimation networks into video depth estimation models, enabling them to takeadvantage of the temporal information to predict more accurate depth. In MAMo,we augment model with memory which aids the depth prediction as the modelstreams through the video. Specifically, the memory stores learned visual anddisplacement tokens of the previous time instances. This allows the depthnetwork to cross-reference relevant features from the past when predictingdepth on the current frame. We introduce a novel scheme to continuously updatethe memory, optimizing it to keep tokens that correspond with both the past andthe present visual information. We adopt attention-based approach to processmemory features where we first learn the spatio-temporal relation among theresultant visual and displacement memory tokens using self-attention module.Further, the output features of self-attention are aggregated with the currentvisual features through cross-attention. The cross-attended features arefinally given to a decoder to predict depth on the current frame. Throughextensive experiments on several benchmarks, including KITTI, NYU-Depth V2, andDDAD, we show that MAMo consistently improves monocular depth estimationnetworks and sets new state-of-the-art (SOTA) accuracy. Notably, our MAMo videodepth estimation provides higher accuracy with lower latency, when omparing toSOTA cost-volume-based video depth models.</description><author>Rajeev Yasarla, Hong Cai, Jisoo Jeong, Yunxiao Shi, Risheek Garrepalli, Fatih Porikli</author><pubDate>Thu, 16 Jan 2025 18:55:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14336v3</guid></item><item><title>KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports</title><link>http://arxiv.org/abs/2501.09744v1</link><description>The objective of BioCreative8 Track 3 is to extract phenotypic key medicalfindings embedded within EHR texts and subsequently normalize these findings totheir Human Phenotype Ontology (HPO) terms. However, the presence of diversesurface forms in phenotypic findings makes it challenging to accuratelynormalize them to the correct HPO terms. To address this challenge, we exploredvarious models for named entity recognition and implemented data augmentationtechniques such as synonym marginalization to enhance the normalization step.Our pipeline resulted in an exact extraction and normalization F1 score 2.6\%higher than the mean score of all submissions received in response to thechallenge. Furthermore, in terms of the normalization F1 score, our approachsurpassed the average performance by 1.9\%. These findings contribute to theadvancement of automated medical data extraction and normalization techniques,showcasing potential pathways for future research and application in thebiomedical domain.</description><author>Hajung Kim, Chanhwi Kim, Jiwoong Sohn, Tim Beck, Marek Rei, Sunkyu Kim, T Ian Simpson, Joram M Posma, Antoine Lain, Mujeen Sung, Jaewoo Kang</author><pubDate>Thu, 16 Jan 2025 18:53:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09744v1</guid></item><item><title>Using Machine Learning to Discover Parsimonious and Physically-Interpretable Representations of Catchment-Scale Rainfall-Runoff Dynamics</title><link>http://arxiv.org/abs/2412.04845v2</link><description>Despite the excellent real-world predictive performance of modern machinelearning (ML) methods, many scientists remain hesitant to discard traditionalphysical-conceptual (PC) approaches due mainly to their relativeinterpretability, which contributes to credibility during decision-making. Inthis context, a currently underexplored aspect of ML is how to developminimally-optimal representations that can facilitate better insight regardingsystem functioning. Regardless of how this is achieved, it is arguably truethat parsimonious representations better support the advancement of scientificunderstanding. Our own view is that ML-based modeling of geoscientific systemsshould be based in the use of computational units that are fundamentallyinterpretable by design. This paper continues our exploration of how the strengths of ML can beexploited in the service of better understanding via scientific investigation.Here, we use the Mass Conserving Perceptron (MCP) as the fundamentalcomputational unit in a generic network architecture consisting of nodesarranged in series and parallel to explore several generic and important issuesrelated to the use of observational data for constructing input-state-outputmodels of dynamical systems. In the context of lumped catchment modeling, weshow that physical interpretability and excellent predictive performance canboth be achieved using a relatively parsimonious distributed-statemultiple-flow-path network with context-dependent gating and informationsharing across the nodes, suggesting that MCP-based modeling can play asignificant role in application of ML to geoscientific investigation.</description><author>Yuan-Heng Wang, Hoshin V. Gupta</author><pubDate>Thu, 16 Jan 2025 18:48:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04845v2</guid></item><item><title>Random Subspace Cubic-Regularization Methods, with Applications to Low-Rank Functions</title><link>http://arxiv.org/abs/2501.09734v1</link><description>We propose and analyze random subspace variants of the second-order AdaptiveRegularization using Cubics (ARC) algorithm. These methods iteratively restrictthe search space to some random subspace of the parameters, constructing andminimizing a local model only within this subspace. Thus, our variants onlyrequire access to (small-dimensional) projections of first- and second-orderproblem derivatives and calculate a reduced step inexpensively. Under suitableassumptions, the ensuing methods maintain the optimal first-order, andsecond-order, global rates of convergence of (full-dimensional) cubicregularization, while showing improved scalability both theoretically andnumerically, particularly when applied to low-rank functions. When applied tothe latter, our adaptive variant naturally adapts the subspace size to the truerank of the function, without knowing it a priori.</description><author>Coralia Cartis, Zhen Shao, Edward Tansley</author><pubDate>Thu, 16 Jan 2025 18:37:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09734v1</guid></item><item><title>ComplexVAD: Detecting Interaction Anomalies in Video</title><link>http://arxiv.org/abs/2501.09733v1</link><description>Existing video anomaly detection datasets are inadequate for representingcomplex anomalies that occur due to the interactions between objects. Theabsence of complex anomalies in previous video anomaly detection datasetsaffects research by shifting the focus onto simple anomalies. To address thisproblem, we introduce a new large-scale dataset: ComplexVAD. In addition, wepropose a novel method to detect complex anomalies via modeling theinteractions between objects using a scene graph with spatio-temporalattributes. With our proposed method and two other state-of-the-art videoanomaly detection methods, we obtain baseline scores on ComplexVAD anddemonstrate that our new method outperforms existing works.</description><author>Furkan Mumcu, Michael J. Jones, Yasin Yilmaz, Anoop Cherian</author><pubDate>Thu, 16 Jan 2025 18:35:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09733v1</guid></item><item><title>Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps</title><link>http://arxiv.org/abs/2501.09732v1</link><description>Generative models have made significant impacts across various domains,largely due to their ability to scale during training by increasing data,computational resources, and model size, a phenomenon characterized by thescaling laws. Recent research has begun to explore inference-time scalingbehavior in Large Language Models (LLMs), revealing how performance can furtherimprove with additional computation during inference. Unlike LLMs, diffusionmodels inherently possess the flexibility to adjust inference-time computationvia the number of denoising steps, although the performance gains typicallyflatten after a few dozen. In this work, we explore the inference-time scalingbehavior of diffusion models beyond increasing denoising steps and investigatehow the generation performance can further improve with increased computation.Specifically, we consider a search problem aimed at identifying better noisesfor the diffusion sampling process. We structure the design space along twoaxes: the verifiers used to provide feedback, and the algorithms used to findbetter noise candidates. Through extensive experiments on class-conditioned andtext-conditioned image generation benchmarks, our findings reveal thatincreasing inference-time compute leads to substantial improvements in thequality of samples generated by diffusion models, and with the complicatednature of images, combinations of the components in the framework can bespecifically chosen to conform with different application scenario.</description><author>Nanye Ma, Shangyuan Tong, Haolin Jia, Hexiang Hu, Yu-Chuan Su, Mingda Zhang, Xuan Yang, Yandong Li, Tommi Jaakkola, Xuhui Jia, Saining Xie</author><pubDate>Thu, 16 Jan 2025 18:30:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09732v1</guid></item><item><title>Predictions as Surrogates: Revisiting Surrogate Outcomes in the Age of AI</title><link>http://arxiv.org/abs/2501.09731v1</link><description>We establish a formal connection between the decades-old surrogate outcomemodel in biostatistics and economics and the emerging field ofprediction-powered inference (PPI). The connection treats predictions frompre-trained models, prevalent in the age of AI, as cost-effective surrogatesfor expensive outcomes. Building on the surrogate outcomes literature, wedevelop recalibrated prediction-powered inference, a more efficient approach tostatistical inference than existing PPI proposals. Our method departs from theexisting proposals by using flexible machine learning techniques to learn theoptimal ``imputed loss'' through a step we call recalibration. Importantly, themethod always improves upon the estimator that relies solely on the data withavailable true outcomes, even when the optimal imputed loss is estimatedimperfectly, and it achieves the smallest asymptotic variance among PPIestimators if the estimate is consistent. Computationally, our optimizationobjective is convex whenever the loss function that defines the targetparameter is convex. We further analyze the benefits of recalibration, boththeoretically and numerically, in several common scenarios where machinelearning predictions systematically deviate from the outcome of interest. Wedemonstrate significant gains in effective sample size over existing PPIproposals via three applications leveraging state-of-the-art machinelearning/AI models.</description><author>Wenlong Ji, Lihua Lei, Tijana Zrnic</author><pubDate>Thu, 16 Jan 2025 18:30:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09731v1</guid></item><item><title>Generating particle physics Lagrangians with transformers</title><link>http://arxiv.org/abs/2501.09729v1</link><description>In physics, Lagrangians provide a systematic way to describe laws governingphysical systems. In the context of particle physics, they encode theinteractions and behavior of the fundamental building blocks of our universe.By treating Lagrangians as complex, rule-based constructs similar to linguisticexpressions, we trained a transformer model -- proven to be effective innatural language tasks -- to predict the Lagrangian corresponding to a givenlist of particles. We report on the transformer's performance in constructingLagrangians respecting the Standard Model $\mathrm{SU}(3)\times\mathrm{SU}(2)\times \mathrm{U}(1)$ gauge symmetries. The resulting model isshown to achieve high accuracies (over 90\%) with Lagrangians up to six matterfields, with the capacity to generalize beyond the training distribution,albeit within architectural constraints. We show through an analysis of inputembeddings that the model has internalized concepts such as grouprepresentations and conjugation operations as it learned to generateLagrangians. We make the model and training datasets available to thecommunity. An interactive demonstration can be found at:\url{https://huggingface.co/spaces/JoseEliel/generate-lagrangians}.</description><author>Yong Sheng Koay, Rikard Enberg, Stefano Moretti, Eliel Camargo-Molina</author><pubDate>Thu, 16 Jan 2025 18:25:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09729v1</guid></item><item><title>Parallel multi-objective metaheuristics for smart communications in vehicular networks</title><link>http://arxiv.org/abs/2501.09725v1</link><description>This article analyzes the use of two parallel multi-objective soft computingalgorithms to automatically search for high-quality settings of the Ad hoc OnDemand Vector routing protocol for vehicular networks. These methods are basedon an evolutionary algorithm and on a swarm intelligence approach. Theexperimental analysis demonstrates that the configurations computed by ouroptimization algorithms outperform other state-of-the-art optimized ones. Inturn, the computational efficiency achieved by all the parallel versions isgreater than 87 %. Therefore, the line of work presented in this articlerepresents an efficient framework to improve vehicular communications.</description><author>Jamal Toutouh, Enrique Alba</author><pubDate>Thu, 16 Jan 2025 18:16:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09725v1</guid></item><item><title>Attention based Bidirectional GRU hybrid model for inappropriate content detection in Urdu language</title><link>http://arxiv.org/abs/2501.09722v1</link><description>With the increased use of the internet and social networks for onlinediscussions, the spread of toxic and inappropriate content on social networkingsites has also increased. Several studies have been conducted in differentlanguages. However, there is less work done for South Asian languages forinappropriate content identification using deep learning techniques. In Urdulanguage, the spellings are not unique, and people write different commonspellings for the same word, while mixing it other languages, like English inthe text makes it more challenging, and limited research work is available toprocess such language with the finest algorithms. The use of attention layerwith a deep learning model can help handling the long-term dependencies andincrease its efficiency . To explore the effects of the attention layer, thisstudy proposes attention-based Bidirectional GRU hybrid model for identifyinginappropriate content in Urdu Unicode text language. Four different baselinedeep learning models; LSTM, Bi-LSTM, GRU, and TCN, are used to compare theperformance of the proposed model. The results of these models were comparedbased on evaluation metrics, dataset size, and impact of the word embeddinglayer. The pre-trained Urdu word2Vec embeddings were utilized for our case. Ourproposed model BiGRU-A outperformed all other baseline models by yielding 84\%accuracy without using pre-trained word2Vec layer. From our experiments, wehave established that the attention layer improves the model's efficiency, andpre-trained word2Vec embedding does not work well with an inappropriate contentdataset.</description><author>Ezzah Shoukat, Rabia Irfan, Iqra Basharat, Muhammad Ali Tahir, Sameen Shaukat</author><pubDate>Thu, 16 Jan 2025 18:10:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09722v1</guid></item><item><title>A Simple Aerial Detection Baseline of Multimodal Language Models</title><link>http://arxiv.org/abs/2501.09720v1</link><description>The multimodal language models (MLMs) based on generative pre-trainedTransformer are considered powerful candidates for unifying various domains andtasks. MLMs developed for remote sensing (RS) have demonstrated outstandingperformance in multiple tasks, such as visual question answering and visualgrounding. In addition to visual grounding that detects specific objectscorresponded to given instruction, aerial detection, which detects all objectsof multiple categories, is also a valuable and challenging task for RSfoundation models. However, aerial detection has not been explored by existingRS MLMs because the autoregressive prediction mechanism of MLMs differssignificantly from the detection outputs. In this paper, we present a simplebaseline for applying MLMs to aerial detection for the first time, namedLMMRotate. Specifically, we first introduce a normalization method to transformdetection outputs into textual outputs to be compatible with the MLM framework.Then, we propose a evaluation method, which ensures a fair comparison betweenMLMs and conventional object detection models. We construct the baseline byfine-tuning open-source general-purpose MLMs and achieve impressive detectionperformance comparable to conventional detector. We hope that this baselinewill serve as a reference for future MLM development, enabling morecomprehensive capabilities for understanding RS images. Code is available athttps://github.com/Li-Qingyun/mllm-mmrotate.</description><author>Qingyun Li, Yushi Chen, Xinya Shu, Dong Chen, Xin He, Yi Yu, Xue Yang</author><pubDate>Thu, 16 Jan 2025 18:09:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09720v1</guid></item><item><title>NL2KQL: From Natural Language to Kusto Query</title><link>http://arxiv.org/abs/2404.02933v3</link><description>Data is growing rapidly in volume and complexity. Proficiency in databasequery languages is pivotal for crafting effective queries. As coding assistantsbecome more prevalent, there is significant opportunity to enhance databasequery languages. The Kusto Query Language (KQL) is a widely used query languagefor large semi-structured data such as logs, telemetries, and time-series forbig data analytics platforms. This paper introduces NL2KQL an innovativeframework that uses large language models (LLMs) to convert natural languagequeries (NLQs) to KQL queries. The proposed NL2KQL framework includes severalkey components: Schema Refiner which narrows down the schema to its mostpertinent elements; the Few-shot Selector which dynamically selects relevantexamples from a few-shot dataset; and the Query Refiner which repairs syntacticand semantic errors in KQL queries. Additionally, this study outlines a methodfor generating large datasets of synthetic NLQ-KQL pairs which are valid withina specific database contexts. To validate NL2KQL's performance, we utilize anarray of online (based on query execution) and offline (based on query parsing)metrics. Through ablation studies, the significance of each framework componentis examined, and the datasets used for benchmarking are made publiclyavailable. This work is the first of its kind and is compared with availablebaselines to demonstrate its effectiveness.</description><author>Xinye Tang, Amir H. Abdi, Jeremias Eichelbaum, Mahan Das, Alex Klein, Nihal Irmak Pakis, William Blum, Daniel L Mace, Tanvi Raja, Namrata Padmanabhan, Ye Xing</author><pubDate>Thu, 16 Jan 2025 18:08:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02933v3</guid></item><item><title>Comparative Insights from 12 Machine Learning Models in Extracting Economic Ideology from Political Text</title><link>http://arxiv.org/abs/2501.09719v1</link><description>This study conducts a systematic assessment of the capabilities of 12 machinelearning models and model variations in detecting economic ideology. As anevaluation benchmark, I use manifesto data spanning six elections in the UnitedKingdom and pre-annotated by expert and crowd coders. The analysis assesses theperformance of several generative, fine-tuned, and zero-shot models at thegranular and aggregate levels. The results show that generative models such asGPT-4o and Gemini 1.5 Flash consistently outperform other models against allbenchmarks. However, they pose issues of accessibility and resourceavailability. Fine-tuning yielded competitive performance and offers a reliablealternative through domain-specific optimization. But its dependency ontraining data severely limits scalability. Zero-shot models consistently facedifficulties with identifying signals of economic ideology, often resulting innegative associations with human coding. Using general knowledge for thedomain-specific task of ideology scaling proved to be unreliable. Other keyfindings include considerable within-party variation, fine-tuning benefitingfrom larger training data, and zero-shot's sensitivity to prompt content. Theassessments include the strengths and limitations of each model and derivebest-practices for automated analyses of political content.</description><author>Jihed Ncib</author><pubDate>Thu, 16 Jan 2025 18:06:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09719v1</guid></item><item><title>FLOL: Fast Baselines for Real-World Low-Light Enhancement</title><link>http://arxiv.org/abs/2501.09718v1</link><description>Low-Light Image Enhancement (LLIE) is a key task in computational photographyand imaging. The problem of enhancing images captured during night or in darkenvironments has been well-studied in the image signal processing literature.However, current deep learning-based solutions struggle with efficiency androbustness in real-world scenarios (e.g. scenes with noise, saturated pixels,bad illumination). We propose a lightweight neural network that combines imageprocessing in the frequency and spatial domains. Our method, FLOL+, is one ofthe fastest models for this task, achieving state-of-the-art results on popularreal scenes datasets such as LOL and LSRW. Moreover, we are able to process1080p images under 12ms. Code and models at https://github.com/cidautai/FLOL</description><author>Juan C. Benito, Daniel Feijoo, Alvaro Garcia, Marcos V. Conde</author><pubDate>Thu, 16 Jan 2025 18:06:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09718v1</guid></item><item><title>Intelligent OLSR Routing Protocol Optimization for VANETs</title><link>http://arxiv.org/abs/2501.09716v1</link><description>Recent advances in wireless technologies have given rise to the emergence ofvehicular ad hoc networks (VANETs). In such networks, the limited coverage ofWiFi and the high mobility of the nodes generate frequent topology changes andnetwork fragmentations. For these reasons, and taking into account that thereis no central manager entity, routing packets through the network is achallenging task. Therefore, offering an efficient routing strategy is crucialto the deployment of VANETs. This paper deals with the optimal parametersetting of the optimized link state routing (OLSR), which is a well-knownmobile ad hoc network routing protocol, by defining an optimization problem.This way, a series of representative metaheuristic algorithms (particle swarmoptimization, differential evolution, genetic algorithm, and simulatedannealing) are studied in this paper to find automatically optimalconfigurations of this routing protocol. In addition, a set of realistic VANETscenarios (based in the city of M\'alaga) have been defined to accuratelyevaluate the performance of the network under our automatic OLSR. In theexperiments, our tuned OLSR configurations result in better quality of service(QoS) than the standard request for comments (RFC 3626), as well as severalhuman experts, making it amenable for utilization in VANET configurations.</description><author>Jamal Toutouh, José García-Nieto, Enrique Alba</author><pubDate>Thu, 16 Jan 2025 18:05:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09716v1</guid></item><item><title>CyberMentor: AI Powered Learning Tool Platform to Address Diverse Student Needs in Cybersecurity Education</title><link>http://arxiv.org/abs/2501.09709v1</link><description>Many non-traditional students in cybersecurity programs often lack access toadvice from peers, family members and professors, which can hinder theireducational experiences. Additionally, these students may not fully benefitfrom various LLM-powered AI assistants due to issues like content relevance,locality of advice, minimum expertise, and timing. This paper addresses thesechallenges by introducing an application designed to provide comprehensivesupport by answering questions related to knowledge, skills, and careerpreparation advice tailored to the needs of these students. We developed alearning tool platform, CyberMentor, to address the diverse needs and painpoints of students majoring in cybersecurity. Powered by agentic workflow andGenerative Large Language Models (LLMs), the platform leveragesRetrieval-Augmented Generation (RAG) for accurate and contextually relevantinformation retrieval to achieve accessibility and personalization. Wedemonstrated its value in addressing knowledge requirements for cybersecurityeducation and for career marketability, in tackling skill requirements foranalytical and programming assignments, and in delivering real time on demandlearning support. Using three use scenarios, we showcased CyberMentor infacilitating knowledge acquisition and career preparation and providingseamless skill-based guidance and support. We also employed the LangChainprompt-based evaluation methodology to evaluate the platform's impact,confirming its strong performance in helpfulness, correctness, andcompleteness. These results underscore the system's ability to support studentsin developing practical cybersecurity skills while improving equity andsustainability within higher education. Furthermore, CyberMentor's open-sourcedesign allows for adaptation across other disciplines, fostering educationalinnovation and broadening its potential impact.</description><author>Tianyu Wang, Nianjun Zhou, Zhixiong Chen</author><pubDate>Thu, 16 Jan 2025 18:00:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09709v1</guid></item><item><title>The Goofus &amp; Gallant Story Corpus for Practical Value Alignment</title><link>http://arxiv.org/abs/2501.09707v1</link><description>Values or principles are key elements of human society that influence peopleto behave and function according to an accepted standard set of social rules tomaintain social order. As AI systems are becoming ubiquitous in human society,it is a major concern that they could violate these norms or values andpotentially cause harm. Thus, to prevent intentional or unintentional harm, AIsystems are expected to take actions that align with these principles. Trainingsystems to exhibit this type of behavior is difficult and often requires aspecialized dataset. This work presents a multi-modal dataset illustratingnormative and non-normative behavior in real-life situations described throughnatural language and artistic images. This training set contains curated setsof images that are designed to teach young children about social principles. Weargue that this is an ideal dataset to use for training socially normativeagents given this fact.</description><author>Md Sultan Al Nahian, Tasmia Tasrin, Spencer Frazier, Mark Riedl, Brent Harrison</author><pubDate>Thu, 16 Jan 2025 17:58:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09707v1</guid></item><item><title>Domain Adaptation of Foundation LLMs for e-Commerce</title><link>http://arxiv.org/abs/2501.09706v1</link><description>We present the e-Llama models: 8 billion and 70 billion parameter largelanguage models that are adapted towards the e-commerce domain. These modelsare meant as foundation models with deep knowledge about e-commerce, that forma base for instruction- and fine-tuning. The e-Llama models are obtained bycontinuously pretraining the Llama 3.1 base models on 1 trillion tokens ofdomain-specific data. We discuss our approach and motivate our choice of hyperparameters with aseries of ablation studies. To quantify how well the models have been adaptedto the e-commerce domain, we define and implement a set of multilingual,e-commerce specific evaluation tasks. We show that, when carefully choosing the training setup, the Llama 3.1models can be adapted towards the new domain without sacrificing significantperformance on general domain tasks. We also explore the possibility of mergingthe adapted model and the base model for a better control of the performancetrade-off between domains.</description><author>Christian Herold, Michael Kozielski, Tala Bazazo, Pavel Petrushkov, Hadi Hashemi, Patrycja Cieplicka, Dominika Basaj, Shahram Khadivi</author><pubDate>Thu, 16 Jan 2025 17:58:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09706v1</guid></item><item><title>Practical Continual Forgetting for Pre-trained Vision Models</title><link>http://arxiv.org/abs/2501.09705v1</link><description>For privacy and security concerns, the need to erase unwanted informationfrom pre-trained vision models is becoming evident nowadays. In real-worldscenarios, erasure requests originate at any time from both users and modelowners, and these requests usually form a sequence. Therefore, under such asetting, selective information is expected to be continuously removed from apre-trained model while maintaining the rest. We define this problem ascontinual forgetting and identify three key challenges. (i) For unwantedknowledge, efficient and effective deleting is crucial. (ii) For remainingknowledge, the impact brought by the forgetting procedure should be minimal.(iii) In real-world scenarios, the training samples may be scarce or partiallymissing during the process of forgetting. To address them, we first proposeGroup Sparse LoRA (GS-LoRA). Specifically, towards (i), we introduce LoRAmodules to fine-tune the FFN layers in Transformer blocks for each forgettingtask independently, and towards (ii), a simple group sparse regularization isadopted, enabling automatic selection of specific LoRA groups and zeroing outthe others. To further extend GS-LoRA to more practical scenarios, weincorporate prototype information as additional supervision and introduce amore practical approach, GS-LoRA++. For each forgotten class, we move thelogits away from its original prototype. For the remaining classes, we pull thelogits closer to their respective prototypes. We conduct extensive experimentson face recognition, object detection and image classification and demonstratethat our method manages to forget specific classes with minimal impact on otherclasses. Codes have been released on https://github.com/bjzhb666/GS-LoRA.</description><author>Hongbo Zhao, Fei Zhu, Bolin Ni, Feng Zhu, Gaofeng Meng, Zhaoxiang Zhang</author><pubDate>Thu, 16 Jan 2025 17:57:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09705v1</guid></item><item><title>Frechet Music Distance: A Metric For Generative Symbolic Music Evaluation</title><link>http://arxiv.org/abs/2412.07948v2</link><description>In this paper we introduce the Frechet Music Distance (FMD), a novelevaluation metric for generative symbolic music models, inspired by the FrechetInception Distance (FID) in computer vision and Frechet Audio Distance (FAD) ingenerative audio. FMD calculates the distance between distributions ofreference and generated symbolic music embeddings, capturing abstract musicalfeatures. We validate FMD across several datasets and models. Results indicatethat FMD effectively differentiates model quality, providing a domain-specificmetric for evaluating symbolic music generation, and establishing areproducible standard for future research in symbolic music modeling.</description><author>Jan Retkowski, Jakub Stępniak, Mateusz Modrzejewski</author><pubDate>Thu, 16 Jan 2025 17:56:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.07948v2</guid></item><item><title>Cueless EEG imagined speech for subject identification: dataset and benchmarks</title><link>http://arxiv.org/abs/2501.09700v1</link><description>Electroencephalogram (EEG) signals have emerged as a promising modality forbiometric identification. While previous studies have explored the use ofimagined speech with semantically meaningful words for subject identification,most have relied on additional visual or auditory cues. In this study, weintroduce a cueless EEG-based imagined speech paradigm, where subjects imaginethe pronunciation of semantically meaningful words without any external cues.This innovative approach addresses the limitations of prior methods byrequiring subjects to select and imagine words from a predefined listnaturally. The dataset comprises over 4,350 trials from 11 subjects across fivesessions. We assess a variety of classification methods, including traditionalmachine learning techniques such as Support Vector Machines (SVM) and XGBoost,as well as time-series foundation models and deep learning architecturesspecifically designed for EEG classification, such as EEG Conformer and ShallowConvNet. A session-based hold-out validation strategy was employed to ensurereliable evaluation and prevent data leakage. Our results demonstrateoutstanding classification accuracy, reaching 97.93%. These findings highlightthe potential of cueless EEG paradigms for secure and reliable subjectidentification in real-world applications, such as brain-computer interfaces(BCIs).</description><author>Ali Derakhshesh, Zahra Dehghanian, Reza Ebrahimpour, Hamid R. Rabiee</author><pubDate>Thu, 16 Jan 2025 17:54:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09700v1</guid></item><item><title>Mitigating Hallucinations in Large Vision-Language Models via DPO: On-Policy Data Hold the Key</title><link>http://arxiv.org/abs/2501.09695v1</link><description>Hallucination remains a major challenge for Large Vision-Language Models(LVLMs). Direct Preference Optimization (DPO) has gained increasing attentionas a simple solution to hallucination issues. It directly learns fromconstructed preference pairs that reflect the severity of hallucinations inresponses to the same prompt and image. Nonetheless, different dataconstruction methods in existing works bring notable performance variations. Weidentify a crucial factor here: outcomes are largely contingent on whether theconstructed data aligns on-policy w.r.t the initial (reference) policy of DPO.Theoretical analysis suggests that learning from off-policy data is impeded bythe presence of KL-divergence between the updated policy and the referencepolicy. From the perspective of dataset distribution, we systematicallysummarize the inherent flaws in existing algorithms that employ DPO to addresshallucination issues. To alleviate the problems, we propose On-Policy Alignment(OPA)-DPO framework, which uniquely leverages expert feedback to correcthallucinated responses and aligns both the original and expert-revisedresponses in an on-policy manner. Notably, with only 4.8k data, OPA-DPOachieves an additional reduction in the hallucination rate of LLaVA-1.5-7B:13.26% on the AMBER benchmark and 5.39% on the Object-Hal benchmark, comparedto the previous SOTA algorithm trained with 16k samples.</description><author>Zhihe Yang, Xufang Luo, Dongqi Han, Yunjian Xu, Dongsheng Li</author><pubDate>Thu, 16 Jan 2025 17:48:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09695v1</guid></item><item><title>A Near-optimal Algorithm for Learning Margin Halfspaces with Massart Noise</title><link>http://arxiv.org/abs/2501.09691v1</link><description>We study the problem of PAC learning $\gamma$-margin halfspaces in thepresence of Massart noise. Without computational considerations, the samplecomplexity of this learning problem is known to be$\widetilde{\Theta}(1/(\gamma^2 \epsilon))$. Prior computationally efficientalgorithms for the problem incur sample complexity $\tilde{O}(1/(\gamma^4\epsilon^3))$ and achieve 0-1 error of $\eta+\epsilon$, where $\eta&lt;1/2$ is theupper bound on the noise rate. Recent work gave evidence of aninformation-computation tradeoff, suggesting that a quadratic dependence on$1/\epsilon$ is required for computationally efficient algorithms. Our mainresult is a computationally efficient learner with sample complexity$\widetilde{\Theta}(1/(\gamma^2 \epsilon^2))$, nearly matching this lowerbound. In addition, our algorithm is simple and practical, relying on onlineSGD on a carefully selected sequence of convex losses.</description><author>Ilias Diakonikolas, Nikos Zarifis</author><pubDate>Thu, 16 Jan 2025 17:44:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09691v1</guid></item><item><title>Fine-Grained Image-Text Correspondence with Cost Aggregation for Open-Vocabulary Part Segmentation</title><link>http://arxiv.org/abs/2501.09688v1</link><description>Open-Vocabulary Part Segmentation (OVPS) is an emerging field for recognizingfine-grained parts in unseen categories. We identify two primary challenges inOVPS: (1) the difficulty in aligning part-level image-text correspondence, and(2) the lack of structural understanding in segmenting object parts. To addressthese issues, we propose PartCATSeg, a novel framework that integratesobject-aware part-level cost aggregation, compositional loss, and structuralguidance from DINO. Our approach employs a disentangled cost aggregationstrategy that handles object and part-level costs separately, enhancing theprecision of part-level segmentation. We also introduce a compositional loss tobetter capture part-object relationships, compensating for the limited partannotations. Additionally, structural guidance from DINO features improvesboundary delineation and inter-part understanding. Extensive experiments onPascal-Part-116, ADE20K-Part-234, and PartImageNet datasets demonstrate thatour method significantly outperforms state-of-the-art approaches, setting a newbaseline for robust generalization to unseen part categories.</description><author>Jiho Choi, Seonho Lee, Minhyun Lee, Seungho Lee, Hyunjung Shim</author><pubDate>Thu, 16 Jan 2025 17:40:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09688v1</guid></item><item><title>U-Fair: Uncertainty-based Multimodal Multitask Learning for Fairer Depression Detection</title><link>http://arxiv.org/abs/2501.09687v1</link><description>Machine learning bias in mental health is becoming an increasingly pertinentchallenge. Despite promising efforts indicating that multitask approaches oftenwork better than unitask approaches, there is minimal work investigating theimpact of multitask learning on performance and fairness in depressiondetection nor leveraged it to achieve fairer prediction outcomes. In this work,we undertake a systematic investigation of using a multitask approach toimprove performance and fairness for depression detection. We propose a novelgender-based task-reweighting method using uncertainty grounded in how thePHQ-8 questionnaire is structured. Our results indicate that, although amultitask approach improves performance and fairness compared to a unitaskapproach, the results are not always consistent and we see evidence of negativetransfer and a reduction in the Pareto frontier, which is concerning given thehigh-stake healthcare setting. Our proposed approach of gender-basedreweighting with uncertainty improves performance and fairness and alleviatesboth challenges to a certain extent. Our findings on each PHQ-8 subitem taskdifficulty are also in agreement with the largest study conducted on the PHQ-8subitem discrimination capacity, thus providing the very first tangibleevidence linking ML findings with large-scale empirical population studiesconducted on the PHQ-8.</description><author>Jiaee Cheong, Aditya Bangar, Sinan Kalkan, Hatice Gunes</author><pubDate>Thu, 16 Jan 2025 17:39:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09687v1</guid></item><item><title>Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models</title><link>http://arxiv.org/abs/2501.09686v1</link><description>Language has long been conceived as an essential tool for human reasoning.The breakthrough of Large Language Models (LLMs) has sparked significantresearch interest in leveraging these models to tackle complex reasoning tasks.Researchers have moved beyond simple autoregressive token generation byintroducing the concept of "thought" -- a sequence of tokens representingintermediate steps in the reasoning process. This innovative paradigm enablesLLMs' to mimic complex human reasoning processes, such as tree search andreflective thinking. Recently, an emerging trend of learning to reason hasapplied reinforcement learning (RL) to train LLMs to master reasoningprocesses. This approach enables the automatic generation of high-qualityreasoning trajectories through trial-and-error search algorithms, significantlyexpanding LLMs' reasoning capacity by providing substantially more trainingdata. Furthermore, recent studies demonstrate that encouraging LLMs to "think"with more tokens during test-time inference can further significantly boostreasoning accuracy. Therefore, the train-time and test-time scaling combined toshow a new research frontier -- a path toward Large Reasoning Model. Theintroduction of OpenAI's o1 series marks a significant milestone in thisresearch direction. In this survey, we present a comprehensive review of recentprogress in LLM reasoning. We begin by introducing the foundational backgroundof LLMs and then explore the key technical components driving the developmentof large reasoning models, with a focus on automated data construction,learning-to-reason techniques, and test-time scaling. We also analyze popularopen-source projects at building large reasoning models, and conclude with openchallenges and future research directions.</description><author>Fengli Xu, Qianyue Hao, Zefang Zong, Jingwei Wang, Yunke Zhang, Jingyi Wang, Xiaochong Lan, Jiahui Gong, Tianjian Ouyang, Fanjin Meng, Chenyang Shao, Yuwei Yan, Qinglong Yang, Yiwen Song, Sijian Ren, Xinyuan Hu, Yu Li, Jie Feng, Chen Gao, Yong Li</author><pubDate>Thu, 16 Jan 2025 17:37:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09686v1</guid></item><item><title>Reward-Guided Controlled Generation for Inference-Time Alignment in Diffusion Models: Tutorial and Review</title><link>http://arxiv.org/abs/2501.09685v1</link><description>This tutorial provides an in-depth guide on inference-time guidance andalignment methods for optimizing downstream reward functions in diffusionmodels. While diffusion models are renowned for their generative modelingcapabilities, practical applications in fields such as biology often requiresample generation that maximizes specific metrics (e.g., stability, affinity inproteins, closeness to target structures). In these scenarios, diffusion modelscan be adapted not only to generate realistic samples but also to explicitlymaximize desired measures at inference time without fine-tuning. This tutorialexplores the foundational aspects of such inference-time algorithms. We reviewthese methods from a unified perspective, demonstrating that current techniques-- such as Sequential Monte Carlo (SMC)-based guidance, value-based sampling,and classifier guidance -- aim to approximate soft optimal denoising processes(a.k.a. policies in RL) that combine pre-trained denoising processes with valuefunctions serving as look-ahead functions that predict from intermediate statesto terminal rewards. Within this framework, we present several novel algorithmsnot yet covered in the literature. Furthermore, we discuss (1) fine-tuningmethods combined with inference-time techniques, (2) inference-time algorithmsbased on search algorithms such as Monte Carlo tree search, which have receivedlimited attention in current research, and (3) connections betweeninference-time algorithms in language models and diffusion models. The code ofthis tutorial on protein design is available athttps://github.com/masa-ue/AlignInversePro</description><author>Masatoshi Uehara, Yulai Zhao, Chenyu Wang, Xiner Li, Aviv Regev, Sergey Levine, Tommaso Biancalani</author><pubDate>Thu, 16 Jan 2025 17:37:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09685v1</guid></item><item><title>Rough kernel hedging</title><link>http://arxiv.org/abs/2501.09683v1</link><description>Building on the functional-analytic framework of operator-valued kernels andun-truncated signature kernels, we propose a scalable, provably convergentsignature-based algorithm for a broad class of high-dimensional, path-dependenthedging problems. We make minimal assumptions about market dynamics bymodelling them as general geometric rough paths, yielding a fully model-freeapproach. Furthermore, through a representer theorem, we provide theoreticalguarantees on the existence and uniqueness of a global minimum for theresulting optimization problem and derive an analytic solution under highlygeneral loss functions. Similar to the popular deep hedging approach, but in amore rigorous fashion, our method can also incorporate additional features viathe underlying operator-valued kernel, such as trading signals, news analytics,and past hedging decisions, closely aligning with true machine-learningpractice.</description><author>Nicola Muca Cirone, Cristopher Salvi</author><pubDate>Thu, 16 Jan 2025 17:34:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09683v1</guid></item><item><title>Incorporating Quantum Advantage in Quantum Circuit Generation through Genetic Programming</title><link>http://arxiv.org/abs/2501.09682v1</link><description>Designing efficient quantum circuits that leverage quantum advantage comparedto classical computing has become increasingly critical. Genetic algorithmshave shown potential in generating such circuits through artificial evolution.However, integrating quantum advantage into the fitness function of thesealgorithms remains unexplored. In this paper, we aim to enhance the efficiencyof quantum circuit design by proposing two novel approaches for incorporatingquantum advantage metrics into the fitness function of genetic algorithms.1 Weevaluate our approaches based on the Bernstein-Vazirani Problem and theUnstructured Database Search Problem as test cases. The results demonstratethat our approaches not only improve the convergence speed of the geneticalgorithm but also produce circuits comparable to expert-designed solutions.Our findings suggest that automated quantum circuit design using geneticalgorithms that incorporate a measure of quantum advantage is a promisingapproach to accelerating the development of quantum algorithms.</description><author>Christoph Stein, Michael Färber</author><pubDate>Thu, 16 Jan 2025 17:34:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09682v1</guid></item><item><title>Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents</title><link>http://arxiv.org/abs/2403.04202v7</link><description>Growing concerns about safety and alignment of AI systems highlight theimportance of embedding moral capabilities in artificial agents: a promisingsolution is the use of learning from experience, i.e., Reinforcement Learning.In multi-agent (social) environments, complex population-level phenomena mayemerge from interactions between individual learning agents. Many of theexisting studies rely on simulated social dilemma environments to study theinteractions of independent learning agents; however, they tend to ignore themoral heterogeneity that is likely to be present in societies of agents inpractice. For example, at different points in time a single learning agent mayface opponents who are consequentialist (i.e., focused on maximizing outcomesover time), norm-based (i.e., conforming to specific norms), or virtue-based(i.e., considering a combination of different virtues). The extent to whichagents' co-development may be impacted by such moral heterogeneity inpopulations is not well understood. In this paper, we present a study of thelearning dynamics of morally heterogeneous populations interacting in a socialdilemma setting. Using an Iterated Prisoner's Dilemma environment with apartner selection mechanism, we investigate the extent to which the prevalenceof diverse moral agents in populations affects individual agents' learningbehaviors and emergent population-level outcomes. We observe several types ofnon-trivial interactions between pro-social and anti-social agents, and findthat certain types of moral agents are able to steer selfish agents towardsmore cooperative behavior.</description><author>Elizaveta Tennant, Stephen Hailes, Mirco Musolesi</author><pubDate>Thu, 16 Jan 2025 17:28:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.04202v7</guid></item><item><title>Authenticated Delegation and Authorized AI Agents</title><link>http://arxiv.org/abs/2501.09674v1</link><description>The rapid deployment of autonomous AI agents creates urgent challenges aroundauthorization, accountability, and access control in digital spaces. Newstandards are needed to know whom AI agents act on behalf of and guide theiruse appropriately, protecting online spaces while unlocking the value of taskdelegation to autonomous agents. We introduce a novel framework forauthenticated, authorized, and auditable delegation of authority to AI agents,where human users can securely delegate and restrict the permissions and scopeof agents while maintaining clear chains of accountability. This frameworkbuilds on existing identification and access management protocols, extendingOAuth 2.0 and OpenID Connect with agent-specific credentials and metadata,maintaining compatibility with established authentication and webinfrastructure. Further, we propose a framework for translating flexible,natural language permissions into auditable access control configurations,enabling robust scoping of AI agent capabilities across diverse interactionmodalities. Taken together, this practical approach facilitates immediatedeployment of AI agents while addressing key security and accountabilityconcerns, working toward ensuring agentic AI systems perform only appropriateactions and providing a tool for digital service providers to enable AI agentinteractions without risking harm from scalable interaction.</description><author>Tobin South, Samuele Marro, Thomas Hardjono, Robert Mahari, Cedric Deslandes Whitney, Dazza Greenwood, Alan Chan, Alex Pentland</author><pubDate>Thu, 16 Jan 2025 17:11:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09674v1</guid></item><item><title>Vulnerability-Aware Spatio-Temporal Learning for Generalizable and Interpretable Deepfake Video Detection</title><link>http://arxiv.org/abs/2501.01184v2</link><description>Detecting deepfake videos is highly challenging due to the complexintertwined spatial and temporal artifacts in forged sequences. Most recentapproaches rely on binary classifiers trained on both real and fake data.However, such methods may struggle to focus on important artifacts, which canhinder their generalization capability. Additionally, these models often lackinterpretability, making it difficult to understand how predictions are made.To address these issues, we propose FakeSTormer, offering two keycontributions. First, we introduce a multi-task learning framework withadditional spatial and temporal branches that enable the model to focus onsubtle spatio-temporal artifacts. These branches also provide interpretabilityby highlighting video regions that may contain artifacts. Second, we propose avideo-level data synthesis algorithm that generates pseudo-fake videos withsubtle artifacts, providing the model with high-quality samples and groundtruth data for our spatial and temporal branches. Extensive experiments onseveral challenging benchmarks demonstrate the competitiveness of our approachcompared to recent state-of-the-art methods. The code is available athttps://github.com/10Ring/FakeSTormer.</description><author>Dat Nguyen, Marcella Astrid, Anis Kacem, Enjie Ghorbel, Djamila Aouada</author><pubDate>Thu, 16 Jan 2025 17:11:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.01184v2</guid></item><item><title>Super-class guided Transformer for Zero-Shot Attribute Classification</title><link>http://arxiv.org/abs/2501.05728v2</link><description>Attribute classification is crucial for identifying specific characteristicswithin image regions. Vision-Language Models (VLMs) have been effective inzero-shot tasks by leveraging their general knowledge from large-scaledatasets. Recent studies demonstrate that transformer-based models withclass-wise queries can effectively address zero-shot multi-labelclassification. However, poor utilization of the relationship between seen andunseen attributes makes the model lack generalizability. Additionally,attribute classification generally involves many attributes, making maintainingthe model's scalability difficult. To address these issues, we proposeSuper-class guided transFormer (SugaFormer), a novel framework that leveragessuper-classes to enhance scalability and generalizability for zero-shotattribute classification. SugaFormer employs Super-class Query Initialization(SQI) to reduce the number of queries, utilizing common semantic informationfrom super-classes, and incorporates Multi-context Decoding (MD) to handlediverse visual cues. To strengthen generalizability, we introduce two knowledgetransfer strategies that utilize VLMs. During training, Super-class guidedConsistency Regularization (SCR) aligns model's features with VLMs usingsuper-class guided prompts, and during inference, Zero-shot Retrieval-basedScore Enhancement (ZRSE) refines predictions for unseen attributes. Extensiveexperiments demonstrate that SugaFormer achieves state-of-the-art performanceacross three widely-used attribute classification benchmarks under zero-shot,and cross-dataset transfer settings. Our code is available athttps://github.com/mlvlab/SugaFormer.</description><author>Sehyung Kim, Chanhyeong Yang, Jihwan Park, Taehoon Song, Hyunwoo J. Kim</author><pubDate>Thu, 16 Jan 2025 17:09:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05728v2</guid></item><item><title>Robin: a Suite of Multi-Scale Vision-Language Models and the CHIRP Evaluation Benchmark</title><link>http://arxiv.org/abs/2501.09672v1</link><description>The proliferation of Vision-Language Models (VLMs) in the past several yearscalls for rigorous and comprehensive evaluation methods and benchmarks. Thiswork analyzes existing VLM evaluation techniques, including automated metrics,AI-based assessments, and human evaluations across diverse tasks. We firstintroduce Robin - a novel suite of VLMs that we built by combining LargeLanguage Models (LLMs) and Vision Encoders (VEs) at multiple scales, and useRobin to identify shortcomings of current evaluation approaches across scales.Next, to overcome the identified limitations, we introduce CHIRP - a new longform response benchmark we developed for more robust and complete VLMevaluation. We provide open access to the Robin training code, model suite, andCHIRP benchmark to promote reproducibility and advance VLM research.</description><author>Alexis Roger, Prateek Humane, Daniel Z. Kaplan, Kshitij Gupta, Qi Sun, George Adamopoulos, Jonathan Siu Chi Lim, Quentin Anthony, Edwin Fennell, Irina Rish</author><pubDate>Thu, 16 Jan 2025 17:08:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09672v1</guid></item><item><title>Fokker-Planck to Callan-Symanzik: evolution of weight matrices under training</title><link>http://arxiv.org/abs/2501.09659v1</link><description>The dynamical evolution of a neural network during training has been anincredibly fascinating subject of study. First principal derivation of genericevolution of variables in statistical physics systems has proved useful whenused to describe training dynamics conceptually, which in practice meansnumerically solving equations such as Fokker-Planck equation. Simulating entirenetworks inevitably runs into the curse of dimensionality. In this paper, weutilize Fokker-Planck to simulate the probability density evolution ofindividual weight matrices in the bottleneck layers of a simple2-bottleneck-layered auto-encoder and compare the theoretical evolutionsagainst the empirical ones by examining the output data distributions. We alsoderive physically relevant partial differential equations such asCallan-Symanzik and Kardar-Parisi-Zhang equations from the dynamical equationwe have.</description><author>Wei Bu, Uri Kol, Ziming Liu</author><pubDate>Thu, 16 Jan 2025 16:54:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09659v1</guid></item><item><title>A Survey of Research in Large Language Models for Electronic Design Automation</title><link>http://arxiv.org/abs/2501.09655v1</link><description>Within the rapidly evolving domain of Electronic Design Automation (EDA),Large Language Models (LLMs) have emerged as transformative technologies,offering unprecedented capabilities for optimizing and automating variousaspects of electronic design. This survey provides a comprehensive explorationof LLM applications in EDA, focusing on advancements in model architectures,the implications of varying model sizes, and innovative customizationtechniques that enable tailored analytical insights. By examining theintersection of LLM capabilities and EDA requirements, the paper highlights thesignificant impact these models have on extracting nuanced understandings fromcomplex datasets. Furthermore, it addresses the challenges and opportunities inintegrating LLMs into EDA workflows, paving the way for future research andapplication in this dynamic field. Through this detailed analysis, the surveyaims to offer valuable insights to professionals in the EDA industry, AIresearchers, and anyone interested in the convergence of advanced AItechnologies and electronic design.</description><author>Jingyu Pan, Guanglei Zhou, Chen-Chia Chang, Isaac Jacobson, Jiang Hu, Yiran Chen</author><pubDate>Thu, 16 Jan 2025 16:51:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09655v1</guid></item><item><title>The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating Large Language Models</title><link>http://arxiv.org/abs/2501.09653v1</link><description>The recent rise in the popularity of large language models has spurred thedevelopment of extensive code datasets needed to train them. This has leftlimited code available for collection and use in the downstream investigationof specific behaviors, or evaluation of large language models without sufferingfrom data contamination. To address this problem, we release The Heap, a largemultilingual dataset covering 57 programming languages that has beendeduplicated with respect to other open datasets of code, enabling researchersto conduct fair evaluations of large language models without significant datacleaning overhead.</description><author>Jonathan Katzy, Razvan Mihai Popescu, Arie van Deursen, Maliheh Izadi</author><pubDate>Thu, 16 Jan 2025 16:48:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09653v1</guid></item><item><title>VIS-MAE: An Efficient Self-supervised Learning Approach on Medical Image Segmentation and Classification</title><link>http://arxiv.org/abs/2402.01034v2</link><description>Artificial Intelligence (AI) has the potential to revolutionize diagnosis andsegmentation in medical imaging. However, development and clinicalimplementation face multiple challenges including limited data availability,lack of generalizability, and the necessity to incorporate multi-modal dataeffectively. A foundation model, which is a large-scale pre-trained AI model,offers a versatile base that can be adapted to a variety of specific tasks andcontexts. Here, we present VIsualization and Segmentation Masked AutoEncoder(VIS-MAE), novel model weights specifically designed for medical imaging.Specifically, VIS-MAE is trained on a dataset of 2.5 million unlabeled imagesfrom various modalities (CT, MR, PET,X-rays, and ultrasound), usingself-supervised learning techniques. It is then adapted to classification andsegmentation tasks using explicit labels. VIS-MAE has high label efficiency,outperforming several benchmark models in both in-domain and out-of-domainapplications. In addition, VIS-MAE has improved label efficiency as it canachieve similar performance to other models with a reduced amount of labeledtraining data (50% or 80%) compared to other pre-trained weights. VIS-MAErepresents a significant advancement in medical imaging AI, offering ageneralizable and robust solution for improving segmentation and classificationtasks while reducing the data annotation workload. The source code of this workis available at https://github.com/lzl199704/VIS-MAE.</description><author>Zelong Liu, Andrew Tieu, Nikhil Patel, Georgios Soultanidis, Louisa Deyer, Ying Wang, Sean Huver, Alexander Zhou, Yunhao Mei, Zahi A. Fayad, Timothy Deyer, Xueyan Mei</author><pubDate>Thu, 16 Jan 2025 16:45:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01034v2</guid></item><item><title>Monte Carlo Tree Search with Velocity Obstacles for safe and efficient motion planning in dynamic environments</title><link>http://arxiv.org/abs/2501.09649v1</link><description>Online motion planning is a challenging problem for intelligent robots movingin dense environments with dynamic obstacles, e.g., crowds. In this work, wepropose a novel approach for optimal and safe online motion planning withminimal information about dynamic obstacles. Specifically, our approachrequires only the current position of the obstacles and their maximum speed,but it does not need any information about their exact trajectories or dynamicmodel. The proposed methodology combines Monte Carlo Tree Search (MCTS), foronline optimal planning via model simulations, with Velocity Obstacles (VO),for obstacle avoidance. We perform experiments in a cluttered simulatedenvironment with walls, and up to 40 dynamic obstacles moving with randomvelocities and directions. With an ablation study, we show the key contributionof VO in scaling up the efficiency of MCTS, selecting the safest and mostrewarding actions in the tree of simulations. Moreover, we show the superiorityof our methodology with respect to state-of-the-art planners, includingNon-linear Model Predictive Control (NMPC), in terms of improved collisionrate, computational and task performance.</description><author>Lorenzo Bonanni, Daniele Meli, Alberto Castellini, Alessandro Farinelli</author><pubDate>Thu, 16 Jan 2025 16:45:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09649v1</guid></item><item><title>Convex Markov Games: A Framework for Creativity, Imitation, Fairness, and Safety in Multiagent Learning</title><link>http://arxiv.org/abs/2410.16600v2</link><description>Behavioral diversity, expert imitation, fairness, safety goals and othersgive rise to preferences in sequential decision making domains that do notdecompose additively across time. We introduce the class of convex Markov gamesthat allow general convex preferences over occupancy measures. Despite infinitetime horizon and strictly higher generality than Markov games, pure strategyNash equilibria exist. Furthermore, equilibria can be approximated empiricallyby performing gradient descent on an upper bound of exploitability. Ourexperiments reveal novel solutions to classic repeated normal-form games, findfair solutions in a repeated asymmetric coordination game, and prioritize safelong-term behavior in a robot warehouse environment. In the prisoner's dilemma,our algorithm leverages transient imitation to find a policy profile thatdeviates from observed human play only slightly, yet achieves higher per-playerutility while also being three orders of magnitude less exploitable.</description><author>Ian Gemp, Andreas Haupt, Luke Marris, Siqi Liu, Georgios Piliouras</author><pubDate>Thu, 16 Jan 2025 16:42:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16600v2</guid></item><item><title>NS-Gym: Open-Source Simulation Environments and Benchmarks for Non-Stationary Markov Decision Processes</title><link>http://arxiv.org/abs/2501.09646v1</link><description>In many real-world applications, agents must make sequential decisions inenvironments where conditions are subject to change due to various exogenousfactors. These non-stationary environments pose significant challenges totraditional decision-making models, which typically assume stationary dynamics.Non-stationary Markov decision processes (NS-MDPs) offer a framework to modeland solve decision problems under such changing conditions. However, the lackof standardized benchmarks and simulation tools has hindered systematicevaluation and advance in this field. We present NS-Gym, the first simulationtoolkit designed explicitly for NS-MDPs, integrated within the popularGymnasium framework. In NS-Gym, we segregate the evolution of the environmentalparameters that characterize non-stationarity from the agent's decision-makingmodule, allowing for modular and flexible adaptations to dynamic environments.We review prior work in this domain and present a toolkit encapsulating keyproblem characteristics and types in NS-MDPs. This toolkit is the first effortto develop a set of standardized interfaces and benchmark problems to enableconsistent and reproducible evaluation of algorithms under non-stationaryconditions. We also benchmark six algorithmic approaches from prior work onNS-MDPs using NS-Gym. Our vision is that NS-Gym will enable researchers toassess the adaptability and robustness of their decision-making algorithms tonon-stationary conditions.</description><author>Nathaniel S. Keplinger, Baiting Luo, Iliyas Bektas, Yunuo Zhang, Kyle Hollins Wray, Aron Laszka, Abhishek Dubey, Ayan Mukhopadhyay</author><pubDate>Thu, 16 Jan 2025 16:38:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09646v1</guid></item><item><title>CarMem: Enhancing Long-Term Memory in LLM Voice Assistants through Category-Bounding</title><link>http://arxiv.org/abs/2501.09645v1</link><description>In today's assistant landscape, personalisation enhances interactions,fosters long-term relationships, and deepens engagement. However, many systemsstruggle with retaining user preferences, leading to repetitive user requestsand disengagement. Furthermore, the unregulated and opaque extraction of userpreferences in industry applications raises significant concerns about privacyand trust, especially in regions with stringent regulations like Europe. Inresponse to these challenges, we propose a long-term memory system for voiceassistants, structured around predefined categories. This approach leveragesLarge Language Models to efficiently extract, store, and retrieve preferenceswithin these categories, ensuring both personalisation and transparency. Wealso introduce a synthetic multi-turn, multi-session conversation dataset(CarMem), grounded in real industry data, tailored to an in-car voice assistantsetting. Benchmarked on the dataset, our system achieves an F1-score of .78 to.95 in preference extraction, depending on category granularity. Ourmaintenance strategy reduces redundant preferences by 95% and contradictoryones by 92%, while the accuracy of optimal retrieval is at .87. Collectively,the results demonstrate the system's suitability for industrial applications.</description><author>Johannes Kirmayr, Lukas Stappen, Phillip Schneider, Florian Matthes, Elisabeth André</author><pubDate>Thu, 16 Jan 2025 16:37:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09645v1</guid></item><item><title>Electronic Health Records: Towards Digital Twins in Healthcare</title><link>http://arxiv.org/abs/2501.09640v1</link><description>The pivotal shift from traditional paper-based records to sophisticatedElectronic Health Records (EHR), enabled systematic collection and analysis ofpatient data through descriptive statistics, providing insight into patternsand trends across patient populations. This evolution continued towardpredictive analytics, allowing healthcare providers to anticipate patientoutcomes and potential complications before they occur. This progression frombasic digital record-keeping to sophisticated predictive modelling and digitaltwins reflects healthcare's broader evolution toward more integrated,patient-centred approaches that combine data-driven insights with personalizedcare delivery. This chapter explores the evolution and significance ofhealthcare information systems, beginning with an examination of theimplementation of EHR in the UK and the USA. It provides a comprehensiveoverview of the International Classification of Diseases (ICD) system, tracingits development from ICD-9 to ICD-10. Central to this discussion is theMIMIC-III database, a landmark achievement in healthcare data sharing andarguably the most comprehensive critical care database freely available toresearchers worldwide. MIMIC-III has democratized access to high-qualityhealthcare data, enabling unprecedented opportunities for research andanalysis. The chapter examines its structure, clinical outcome analysiscapabilities, and practical applications through case studies, with aparticular focus on mortality and length of stay metrics, vital signsextraction, and ICD coding. Through detailed entity-relationship diagrams andpractical examples, the text illustrates MIMIC's complex data structure anddemonstrates how different querying approaches can lead to subtly differentresults, emphasizing the critical importance of understanding the database'sarchitecture for accurate data extraction.</description><author>Muhammet Alkan, Hester Huijsdens, Yola Jones, Fani Deligianni</author><pubDate>Thu, 16 Jan 2025 16:30:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09640v1</guid></item><item><title>A Systems Thinking Approach to Algorithmic Fairness</title><link>http://arxiv.org/abs/2412.16641v3</link><description>Systems thinking provides us with a way to model the algorithmic fairnessproblem by allowing us to encode prior knowledge and assumptions about where webelieve bias might exist in the data generating process. We can then encodethese beliefs as a series of causal graphs, enabling us to link AI/ML systemsto politics and the law. This allows us to combine techniques from machinelearning, causal inference, and system dynamics in order to capture differentemergent aspects of the fairness problem. We can use systems thinking to helppolicymakers on both sides of the political aisle to understand the complextrade-offs that exist from different types of fairness policies, providing asociotechnical foundation for designing AI policy that is aligned to theirpolitical agendas.</description><author>Chris Lam</author><pubDate>Thu, 16 Jan 2025 16:29:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16641v3</guid></item><item><title>A Comparative Study on Multi-task Uncertainty Quantification in Semantic Segmentation and Monocular Depth Estimation</title><link>http://arxiv.org/abs/2405.17097v2</link><description>Deep neural networks excel in perception tasks such as semantic segmentationand monocular depth estimation, making them indispensable in safety-criticalapplications like autonomous driving and industrial inspection. However, theyoften suffer from overconfidence and poor explainability, especially forout-of-domain data. While uncertainty quantification has emerged as a promisingsolution to these challenges, multi-task settings have yet to be explored. Inan effort to shed light on this, we evaluate Monte Carlo Dropout, DeepSub-Ensembles, and Deep Ensembles for joint semantic segmentation and monoculardepth estimation. Thereby, we reveal that Deep Ensembles stand out as thepreferred choice, particularly in out-of-domain scenarios, and show thepotential benefit of multi-task learning with regard to the uncertainty qualityin comparison to solving both tasks separately. Additionally, we highlight theimpact of employing different uncertainty thresholds to classify pixels ascertain or uncertain, with the median uncertainty emerging as a robust default.</description><author>Steven Landgraf, Markus Hillemann, Theodor Kapler, Markus Ulrich</author><pubDate>Thu, 16 Jan 2025 16:27:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17097v2</guid></item><item><title>LLM-Based Routing in Mixture of Experts: A Novel Framework for Trading</title><link>http://arxiv.org/abs/2501.09636v1</link><description>Recent advances in deep learning and large language models (LLMs) havefacilitated the deployment of the mixture-of-experts (MoE) mechanism in thestock investment domain. While these models have demonstrated promising tradingperformance, they are often unimodal, neglecting the wealth of informationavailable in other modalities, such as textual data. Moreover, the traditionalneural network-based router selection mechanism fails to consider contextualand real-world nuances, resulting in suboptimal expert selection. To addressthese limitations, we propose LLMoE, a novel framework that employs LLMs as therouter within the MoE architecture. Specifically, we replace the conventionalneural network-based router with LLMs, leveraging their extensive worldknowledge and reasoning capabilities to select experts based on historicalprice data and stock news. This approach provides a more effective andinterpretable selection mechanism. Our experiments on multimodal real-worldstock datasets demonstrate that LLMoE outperforms state-of-the-art MoE modelsand other deep neural network approaches. Additionally, the flexiblearchitecture of LLMoE allows for easy adaptation to various downstream tasks.</description><author>Kuan-Ming Liu, Ming-Chih Lo</author><pubDate>Thu, 16 Jan 2025 16:25:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09636v1</guid></item><item><title>Unified Face Matching and Physical-Digital Spoofing Attack Detection</title><link>http://arxiv.org/abs/2501.09635v1</link><description>Face recognition technology has dramatically transformed the landscape ofsecurity, surveillance, and authentication systems, offering a user-friendlyand non-invasive biometric solution. However, despite its significantadvantages, face recognition systems face increasing threats from physical anddigital spoofing attacks. Current research typically treats face recognitionand attack detection as distinct classification challenges. This approachnecessitates the implementation of separate models for each task, leading toconsiderable computational complexity, particularly on devices with limitedresources. Such inefficiencies can stifle scalability and hinder performance.In response to these challenges, this paper introduces an innovative unifiedmodel designed for face recognition and detection of physical and digitalattacks. By leveraging the advanced Swin Transformer backbone and incorporatingHiLo attention in a convolutional neural network framework, we address unifiedface recognition and spoof attack detection more effectively. Moreover, weintroduce augmentation techniques that replicate the traits of physical anddigital spoofing cues, significantly enhancing our model robustness. Throughcomprehensive experimental evaluation across various datasets, we showcase theeffectiveness of our model in unified face recognition and spoof detection.Additionally, we confirm its resilience against unseen physical and digitalspoofing attacks, underscoring its potential for real-world applications.</description><author>Arun Kunwar, Ajita Rattani</author><pubDate>Thu, 16 Jan 2025 16:24:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09635v1</guid></item><item><title>Platform-Aware Mission Planning</title><link>http://arxiv.org/abs/2501.09632v1</link><description>Planning for autonomous systems typically requires reasoning with models atdifferent levels of abstraction, and the harmonization of two competing sets ofobjectives: high-level mission goals that refer to an interaction of the systemwith the external environment, and low-level platform constraints that aim topreserve the integrity and the correct interaction of the subsystems. Thecomplicated interplay between these two models makes it very hard to reason onthe system as a whole, especially when the objective is to find plans withrobustness guarantees, considering the non-deterministic behavior of the lowerlayers of the system. In this paper, we introduce the problem of Platform-Aware Mission Planning(PAMP), addressing it in the setting of temporal durative actions. The PAMPproblem differs from standard temporal planning for its exists-forall nature:the high-level plan dealing with mission goals is required to satisfy safetyand executability constraints, for all the possible non-deterministicexecutions of the low-level model of the platform and the environment. Wepropose two approaches for solving PAMP. The first baseline approachamalgamates the mission and platform levels, while the second is based on anabstraction-refinement loop that leverages the combination of a planner and averification engine. We prove the soundness and completeness of the proposedapproaches and validate them experimentally, demonstrating the importance ofheterogeneous modeling and the superiority of the technique based onabstraction-refinement.</description><author>Stefan Panjkovic, Alessandro Cimatti, Andrea Micheli, Stefano Tonetta</author><pubDate>Thu, 16 Jan 2025 16:20:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09632v1</guid></item><item><title>Empowering Large Language Models in Wireless Communication: A Novel Dataset and Fine-Tuning Framework</title><link>http://arxiv.org/abs/2501.09631v1</link><description>In this work, we develop a specialized dataset aimed at enhancing theevaluation and fine-tuning of large language models (LLMs) specifically forwireless communication applications. The dataset includes a diverse set ofmulti-hop questions, including true/false and multiple-choice types, spanningvarying difficulty levels from easy to hard. By utilizing advanced languagemodels for entity extraction and question generation, rigorous data curationprocesses are employed to maintain high quality and relevance. Additionally, weintroduce a Pointwise V-Information (PVI) based fine-tuning method, providing adetailed theoretical analysis and justification for its use in quantifying theinformation content of training data with 2.24\% and 1.31\% performance boostfor different models compared to baselines, respectively. To demonstrate theeffectiveness of the fine-tuned models with the proposed methodologies onpractical tasks, we also consider different tasks, including summarizingoptimization problems from technical papers and solving the mathematicalproblems related to non-orthogonal multiple access (NOMA), which are generatedby using the proposed multi-agent framework. Simulation results showsignificant performance gain in summarization tasks with 20.9\% in the ROUGE-Lmetrics. We also study the scaling laws of fine-tuning LLMs and the challengesLLMs face in the field of wireless communications, offering insights into theiradaptation to wireless communication tasks. This dataset and fine-tuningmethodology aim to enhance the training and evaluation of LLMs, contributing toadvancements in LLMs for wireless communication research and applications.</description><author>Yushen Lin, Ruichen Zhang, Wenqi Huang, Kaidi Wang, Zhiguo Ding, Daniel K. C. So, Dusit Niyato</author><pubDate>Thu, 16 Jan 2025 16:19:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09631v1</guid></item><item><title>Aligning Brain Activity with Advanced Transformer Models: Exploring the Role of Punctuation in Semantic Processing</title><link>http://arxiv.org/abs/2501.06278v2</link><description>This research examines the congruence between neural activity and advancedtransformer models, emphasizing the semantic significance of punctuation intext understanding. Utilizing an innovative approach originally proposed byToneva and Wehbe, we evaluate four advanced transformer models RoBERTa,DistiliBERT, ALBERT, and ELECTRA against neural activity data. Our findingsindicate that RoBERTa exhibits the closest alignment with neural activity,surpassing BERT in accuracy. Furthermore, we investigate the impact ofpunctuation removal on model performance and neural alignment, revealing thatBERT's accuracy enhances in the absence of punctuation. This study contributesto the comprehension of how neural networks represent language and theinfluence of punctuation on semantic processing within the human brain.</description><author>Zenon Lamprou, Frank Polick, Yashar Moshfeghi</author><pubDate>Thu, 16 Jan 2025 16:19:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.06278v2</guid></item><item><title>Artificial Intelligence-Driven Clinical Decision Support Systems</title><link>http://arxiv.org/abs/2501.09628v1</link><description>As artificial intelligence (AI) becomes increasingly embedded in healthcaredelivery, this chapter explores the critical aspects of developing reliable andethical Clinical Decision Support Systems (CDSS). Beginning with thefundamental transition from traditional statistical models to sophisticatedmachine learning approaches, this work examines rigorous validation strategiesand performance assessment methods, including the crucial role of modelcalibration and decision curve analysis. The chapter emphasizes that creatingtrustworthy AI systems in healthcare requires more than just technicalaccuracy; it demands careful consideration of fairness, explainability, andprivacy. The challenge of ensuring equitable healthcare delivery through AI isstressed, discussing methods to identify and mitigate bias in clinicalpredictive models. The chapter then delves into explainability as a cornerstoneof human-centered CDSS. This focus reflects the understanding that healthcareprofessionals must not only trust AI recommendations but also comprehend theirunderlying reasoning. The discussion advances in an analysis of privacyvulnerabilities in medical AI systems, from data leakage in deep learningmodels to sophisticated attacks against model explanations. The text exploresprivacy-preservation strategies such as differential privacy and federatedlearning, while acknowledging the inherent trade-offs between privacyprotection and model performance. This progression, from technical validationto ethical considerations, reflects the multifaceted challenges of developingAI systems that can be seamlessly and reliably integrated into daily clinicalpractice while maintaining the highest standards of patient care and dataprotection.</description><author>Muhammet Alkan, Idris Zakariyya, Samuel Leighton, Kaushik Bhargav Sivangi, Christos Anagnostopoulos, Fani Deligianni</author><pubDate>Thu, 16 Jan 2025 16:17:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09628v1</guid></item><item><title>Flexible task abstractions emerge in linear networks with fast and bounded units</title><link>http://arxiv.org/abs/2411.03840v2</link><description>Animals survive in dynamic environments changing at arbitrary timescales, butsuch data distribution shifts are a challenge to neural networks. To adapt tochange, neural systems may change a large number of parameters, which is a slowprocess involving forgetting past information. In contrast, animals leveragedistribution changes to segment their stream of experience into tasks andassociate them with internal task abstracts. Animals can then respond flexiblyby selecting the appropriate task abstraction. However, how such flexible taskabstractions may arise in neural systems remains unknown. Here, we analyze alinear gated network where the weights and gates are jointly optimized viagradient descent, but with neuron-like constraints on the gates including afaster timescale, nonnegativity, and bounded activity. We observe that theweights self-organize into modules specialized for tasks or sub-tasksencountered, while the gates layer forms unique representations that switch theappropriate weight modules (task abstractions). We analytically reduce thelearning dynamics to an effective eigenspace, revealing a virtuous cycle: fastadapting gates drive weight specialization by protecting previous knowledge,while weight specialization in turn increases the update rate of the gatinglayer. Task switching in the gating layer accelerates as a function ofcurriculum block size and task training, mirroring key findings in cognitiveneuroscience. We show that the discovered task abstractions supportgeneralization through both task and subtask composition, and we extend ourfindings to a non-linear network switching between two tasks. Overall, our workoffers a theory of cognitive flexibility in animals as arising from jointgradient descent on synaptic and neural gating in a neural networkarchitecture.</description><author>Kai Sandbrink, Jan P. Bauer, Alexandra M. Proca, Andrew M. Saxe, Christopher Summerfield, Ali Hummos</author><pubDate>Thu, 16 Jan 2025 16:12:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03840v2</guid></item><item><title>A Comprehensive Survey of Foundation Models in Medicine</title><link>http://arxiv.org/abs/2406.10729v3</link><description>Foundation models (FMs) are large-scale deep learning models trained onmassive datasets, often using self-supervised learning techniques. These modelsserve as a versatile base for a wide range of downstream tasks, including thosein medicine and healthcare. FMs have demonstrated remarkable success acrossmultiple healthcare domains. However, existing surveys in this field do notcomprehensively cover all areas where FMs have made significant strides. Inthis survey, we present a comprehensive review of FMs in medicine, focusing ontheir evolution, learning strategies, flagship models, applications, andassociated challenges. We examine how prominent FMs, such as the BERT and GPTfamilies, are transforming various aspects of healthcare, including clinicallarge language models, medical image analysis, and omics research.Additionally, we provide a detailed taxonomy of FM-enabled healthcareapplications, spanning clinical natural language processing, medical computervision, graph learning, and other biology- and omics- related tasks. Despitethe transformative potentials of FMs, they also pose unique challenges. Thissurvey delves into these challenges and highlights open research questions andlessons learned to guide researchers and practitioners. Our goal is to providevaluable insights into the capabilities of FMs in health, facilitatingresponsible deployment and mitigating associated risks.</description><author>Wasif Khan, Seowung Leem, Kyle B. See, Joshua K. Wong, Shaoting Zhang, Ruogu Fang</author><pubDate>Thu, 16 Jan 2025 16:04:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10729v3</guid></item><item><title>Weight for Robustness: A Comprehensive Approach towards Optimal Fault-Tolerant Asynchronous ML</title><link>http://arxiv.org/abs/2501.09621v1</link><description>We address the challenges of Byzantine-robust training in asynchronousdistributed machine learning systems, aiming to enhance efficiency amid massiveparallelization and heterogeneous computing resources. Asynchronous systems,marked by independently operating workers and intermittent updates, uniquelystruggle with maintaining integrity against Byzantine failures, which encompassmalicious or erroneous actions that disrupt learning. The inherent delays insuch settings not only introduce additional bias to the system but also obscurethe disruptions caused by Byzantine faults. To tackle these issues, we adaptthe Byzantine framework to asynchronous dynamics by introducing a novelweighted robust aggregation framework. This allows for the extension of robustaggregators and a recent meta-aggregator to their weighted versions, mitigatingthe effects of delayed updates. By further incorporating a recentvariance-reduction technique, we achieve an optimal convergence rate for thefirst time in an asynchronous Byzantine environment. Our methodology isrigorously validated through empirical and theoretical analysis, demonstratingits effectiveness in enhancing fault tolerance and optimizing performance inasynchronous ML systems.</description><author>Tehila Dahan, Kfir Y. Levy</author><pubDate>Thu, 16 Jan 2025 16:00:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09621v1</guid></item><item><title>Improving Zero-Shot Object-Level Change Detection by Incorporating Visual Correspondence</title><link>http://arxiv.org/abs/2501.05555v2</link><description>Detecting object-level changes between two images across possibly differentviews is a core task in many applications that involve visual inspection orcamera surveillance. Existing change-detection approaches suffer from threemajor limitations: (1) lack of evaluation on image pairs that contain nochanges, leading to unreported false positive rates; (2) lack ofcorrespondences (i.e., localizing the regions before and after a change); and(3) poor zero-shot generalization across different domains. To address theseissues, we introduce a novel method that leverages change correspondences (a)during training to improve change detection accuracy, and (b) at test time, tominimize false positives. That is, we harness the supervision labels of wherean object is added or removed to supervise change detectors, improving theiraccuracy over previous work by a large margin. Our work is also the first topredict correspondences between pairs of detected changes using estimatedhomography and the Hungarian algorithm. Our model demonstrates superiorperformance over existing methods, achieving state-of-the-art results in changedetection and change correspondence accuracy across both in-distribution andzero-shot benchmarks.</description><author>Hung Huy Nguyen, Pooyan Rahmanzadehgervi, Long Mai, Anh Totti Nguyen</author><pubDate>Thu, 16 Jan 2025 16:00:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05555v2</guid></item><item><title>Beyond Reward Hacking: Causal Rewards for Large Language Model Alignment</title><link>http://arxiv.org/abs/2501.09620v1</link><description>Recent advances in large language models (LLMs) have demonstrated significantprogress in performing complex tasks. While Reinforcement Learning from HumanFeedback (RLHF) has been effective in aligning LLMs with human preferences, itis susceptible to spurious correlations in reward modeling. Consequently, itoften introduces biases-such as length bias, sycophancy, conceptual bias, anddiscrimination that hinder the model's ability to capture true causalrelationships. To address this, we propose a novel causal reward modelingapproach that integrates causal inference to mitigate these spuriouscorrelations. Our method enforces counterfactual invariance, ensuring rewardpredictions remain consistent when irrelevant variables are altered. Throughexperiments on both synthetic and real-world datasets, we show that ourapproach mitigates various types of spurious correlations effectively,resulting in more reliable and fair alignment of LLMs with human preferences.As a drop-in enhancement to the existing RLHF workflow, our causal rewardmodeling provides a practical way to improve the trustworthiness and fairnessof LLM finetuning.</description><author>Chaoqi Wang, Zhuokai Zhao, Yibo Jiang, Zhaorun Chen, Chen Zhu, Yuxin Chen, Jiayi Liu, Lizhu Zhang, Xiangjun Fan, Hao Ma, Sinong Wang</author><pubDate>Thu, 16 Jan 2025 16:00:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09620v1</guid></item><item><title>Hybrid Approaches for Moral Value Alignment in AI Agents: a Manifesto</title><link>http://arxiv.org/abs/2312.01818v3</link><description>Increasing interest in ensuring the safety of next-generation ArtificialIntelligence (AI) systems calls for novel approaches to embedding morality intoautonomous agents. This goal differs qualitatively from traditionaltask-specific AI methodologies. In this paper, we provide a systematization ofexisting approaches to the problem of introducing morality in machines -modelled as a continuum. Our analysis suggests that popular techniques lie atthe extremes of this continuum - either being fully hard-coded into top-down,explicit rules, or entirely learned in a bottom-up, implicit fashion with nodirect statement of any moral principle (this includes learning from humanfeedback, as applied to the training and finetuning of large language models,or LLMs). Given the relative strengths and weaknesses of each type ofmethodology, we argue that more hybrid solutions are needed to create adaptableand robust, yet controllable and interpretable agentic systems. To that end,this paper discusses both the ethical foundations (including deontology,consequentialism and virtue ethics) and implementations of morally aligned AIsystems. We present a series of case studies that rely on intrinsic rewards, moralconstraints or textual instructions, applied to either pure-ReinforcementLearning or LLM-based agents. By analysing these diverse implementations underone framework, we compare their relative strengths and shortcomings indeveloping morally aligned AI systems. We then discuss strategies forevaluating the effectiveness of moral learning agents. Finally, we present openresearch questions and implications for the future of AI safety and ethicswhich are emerging from this hybrid framework.</description><author>Elizaveta Tennant, Stephen Hailes, Mirco Musolesi</author><pubDate>Thu, 16 Jan 2025 15:58:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01818v3</guid></item><item><title>Monte Carlo Tree Search for Comprehensive Exploration in LLM-Based Automatic Heuristic Design</title><link>http://arxiv.org/abs/2501.08603v2</link><description>Handcrafting heuristics for solving complex planning tasks (e.g., NP-hardcombinatorial optimization (CO) problems) is a common practice but requiresextensive domain knowledge. Recently, Large Language Model (LLM)-basedautomatic heuristics design (AHD) methods have shown promise in generatinghigh-quality heuristics without manual intervention. Existing LLM-based AHDmethods employ a population to maintain a fixed number of top-performingLLM-generated heuristics and introduce evolutionary computation (EC) to enhancethe population iteratively. However, the population-based procedure bringsgreedy properties, often resulting in convergence to local optima. Instead, tomore comprehensively explore the space of heuristics, we propose using MonteCarlo Tree Search (MCTS) for LLM-based heuristic evolution while preserving allLLM-generated heuristics in a tree structure. With a novel thought-alignmentprocess and an exploration-decay technique, the proposed MCTS-AHD methoddelivers significantly higher-quality heuristics on various complex tasks. Ourcode is available at https://github.com/zz1358m/MCTS-AHD-master.</description><author>Zhi Zheng, Zhuoliang Xie, Zhenkun Wang, Bryan Hooi</author><pubDate>Thu, 16 Jan 2025 15:57:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.08603v2</guid></item><item><title>ReFactor GNNs: Revisiting Factorisation-based Models from a Message-Passing Perspective</title><link>http://arxiv.org/abs/2207.09980v4</link><description>Factorisation-based Models (FMs), such as DistMult, have enjoyed enduringsuccess for Knowledge Graph Completion (KGC) tasks, often outperforming GraphNeural Networks (GNNs). However, unlike GNNs, FMs struggle to incorporate nodefeatures and generalise to unseen nodes in inductive settings. Our work bridgesthe gap between FMs and GNNs by proposing ReFactor GNNs. This new architecturedraws upon both modelling paradigms, which previously were largely thought ofas disjoint. Concretely, using a message-passing formalism, we show how FMs canbe cast as GNNs by reformulating the gradient descent procedure asmessage-passing operations, which forms the basis of our ReFactor GNNs. Acrossa multitude of well-established KGC benchmarks, our ReFactor GNNs achievecomparable transductive performance to FMs, and state-of-the-art inductiveperformance while using an order of magnitude fewer parameters.</description><author>Yihong Chen, Pushkar Mishra, Luca Franceschi, Pasquale Minervini, Pontus Stenetorp, Sebastian Riedel</author><pubDate>Thu, 16 Jan 2025 15:56:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.09980v4</guid></item><item><title>PolInterviews -- A Dataset of German Politician Public Broadcast Interviews</title><link>http://arxiv.org/abs/2501.04484v2</link><description>This paper presents a novel dataset of public broadcast interviews featuringhigh-ranking German politicians. The interviews were sourced from YouTube,transcribed, processed for speaker identification, and stored in a tidy andopen format. The dataset comprises 99 interviews with 33 different Germanpoliticians across five major interview formats, containing a total of 28,146sentences. As the first of its kind, this dataset offers valuable opportunitiesfor research on various aspects of political communication in the (German)political contexts, such as agenda-setting, interviewer dynamics, orpoliticians' self-presentation.</description><author>Lukas Birkenmaier, Laureen Sieber, Felix Bergstein</author><pubDate>Thu, 16 Jan 2025 15:49:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04484v2</guid></item><item><title>Crafting Customisable Characters with LLMs: Introducing SimsChat, a Persona-Driven Role-Playing Agent Framework</title><link>http://arxiv.org/abs/2406.17962v4</link><description>Large Language Models (LLMs) demonstrate remarkable ability to comprehendinstructions and generate human-like text, enabling sophisticated agentsimulation beyond basic behavior replication. However, the potential forcreating freely customisable characters remains underexplored. We introduce theCustomisable Conversation Agent Framework, which employs LLMs to simulatereal-world characters through personalised characteristic feature injection,enabling diverse character creation according to user preferences. We proposethe SimsConv dataset, comprising 68 customised characters and 13,971 multi-turnrole-playing dialogues across 1,360 real-world scenes. Characters are initiallycustomised using pre-defined elements (career, aspiration, traits, skills),then expanded through personal and social profiles. Building on this, wepresent SimsChat, a freely customisable role-playing agent incorporatingvarious realistic settings and topic-specified character interactions.Experimental results on both SimsConv and WikiRoleEval datasets demonstrateSimsChat's superior performance in maintaining character consistency, knowledgeaccuracy, and appropriate question rejection compared to existing models. Ourframework provides valuable insights for developing more accurate andcustomisable human simulacra. Our data and code are publicly available athttps://github.com/Bernard-Yang/SimsChat.</description><author>Bohao Yang, Dong Liu, Chenghao Xiao, Kun Zhao, Chen Tang, Chao Li, Lin Yuan, Guang Yang, Lanxiao Huang, Chenghua Lin</author><pubDate>Thu, 16 Jan 2025 15:47:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17962v4</guid></item><item><title>Local Anti-Concentration Class: Logarithmic Regret for Greedy Linear Contextual Bandit</title><link>http://arxiv.org/abs/2411.12878v2</link><description>We study the performance guarantees of exploration-free greedy algorithms forthe linear contextual bandit problem. We introduce a novel condition, named the\textit{Local Anti-Concentration} (LAC) condition, which enables a greedybandit algorithm to achieve provable efficiency. We show that the LAC conditionis satisfied by a broad class of distributions, including Gaussian,exponential, uniform, Cauchy, and Student's~$t$ distributions, along with otherexponential family distributions and their truncated variants. Thissignificantly expands the class of distributions under which greedy algorithmscan perform efficiently. Under our proposed LAC condition, we prove that thecumulative expected regret of the greedy algorithm for the linear contextualbandit is bounded by $O(\operatorname{poly} \log T)$. Our results establish thewidest range of distributions known to date that allow a sublinear regret boundfor greedy algorithms, further achieving a sharp poly-logarithmic regret.</description><author>Seok-Jin Kim, Min-hwan Oh</author><pubDate>Thu, 16 Jan 2025 15:46:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12878v2</guid></item><item><title>WMamba: Wavelet-based Mamba for Face Forgery Detection</title><link>http://arxiv.org/abs/2501.09617v1</link><description>With the rapid advancement of deepfake generation technologies, the demandfor robust and accurate face forgery detection algorithms has becomeincreasingly critical. Recent studies have demonstrated that wavelet analysiscan uncover subtle forgery artifacts that remain imperceptible in the spatialdomain. Wavelets effectively capture important facial contours, which are oftenslender, fine-grained, and global in nature. However, existing wavelet-basedapproaches fail to fully leverage these unique characteristics, resulting insub-optimal feature extraction and limited generalizability. To address thischallenge, we introduce WMamba, a novel wavelet-based feature extractor builtupon the Mamba architecture. WMamba maximizes the utility of waveletinformation through two key innovations. First, we propose Dynamic ContourConvolution (DCConv), which employs specially crafted deformable kernels toadaptively model slender facial contours. Second, by leveraging the Mambaarchitecture, our method captures long-range spatial relationships with linearcomputational complexity. This efficiency allows for the extraction offine-grained, global forgery artifacts from small image patches. Extensiveexperimental results show that WMamba achieves state-of-the-art (SOTA)performance, highlighting its effectiveness and superiority in face forgerydetection.</description><author>Siran Peng, Tianshuo Zhang, Li Gao, Xiangyu Zhu, Haoyuan Zhang, Kai Pang, Zhen Lei</author><pubDate>Thu, 16 Jan 2025 15:44:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09617v1</guid></item><item><title>ARMAX identification of low rank graphical models</title><link>http://arxiv.org/abs/2501.09616v1</link><description>In large-scale systems, complex internal relationships are often present.Such interconnected systems can be effectively described by low rank stochasticprocesses. When identifying a predictive model of low rank processes fromsampling data, the rank-deficient property of spectral densities is oftenobscured by the inevitable measurement noise in practice. However, existing lowrank identification approaches often did not take noise into explicitconsideration, leading to non-negligible inaccuracies even under weak noise. Inthis paper, we address the identification issue of low rank processes undermeasurement noise. We find that the noisy measurement model admits a sparseplus low rank structure in latent-variable graphical models. Specifically, wefirst decompose the problem into a maximum entropy covariance extensionproblem, and a low rank graphical estimation problem based on an autoregressivemoving-average with exogenous input (ARMAX) model. To identify the ARMAX lowrank graphical models, we propose an estimation approach based on maximumlikelihood. The identifiability and consistency of this approach are provenunder certain conditions. Simulation results confirm the reliable performanceof the entire algorithm in both the parameter estimation and noisy datafiltering.</description><author>Wenqi Cao, Aming Li</author><pubDate>Thu, 16 Jan 2025 15:43:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09616v1</guid></item><item><title>EVaDE : Event-Based Variational Thompson Sampling for Model-Based Reinforcement Learning</title><link>http://arxiv.org/abs/2501.09611v1</link><description>Posterior Sampling for Reinforcement Learning (PSRL) is a well-knownalgorithm that augments model-based reinforcement learning (MBRL) algorithmswith Thompson sampling. PSRL maintains posterior distributions of theenvironment transition dynamics and the reward function, which are intractablefor tasks with high-dimensional state and action spaces. Recent works show thatdropout, used in conjunction with neural networks, induces variationaldistributions that can approximate these posteriors. In this paper, we proposeEvent-based Variational Distributions for Exploration (EVaDE), which arevariational distributions that are useful for MBRL, especially when theunderlying domain is object-based. We leverage the general domain knowledge ofobject-based domains to design three types of event-based convolutional layersto direct exploration. These layers rely on Gaussian dropouts and are insertedbetween the layers of the deep neural network model to help facilitatevariational Thompson sampling. We empirically show the effectiveness ofEVaDE-equipped Simulated Policy Learning (EVaDE-SimPLe) on the 100K Atari gamesuite.</description><author>Siddharth Aravindan, Dixant Mittal, Wee Sun Lee</author><pubDate>Thu, 16 Jan 2025 15:35:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09611v1</guid></item><item><title>Adversarial-Ensemble Kolmogorov Arnold Networks for Enhancing Indoor Wi-Fi Positioning: A Defensive Approach Against Spoofing and Signal Manipulation Attacks</title><link>http://arxiv.org/abs/2501.09609v1</link><description>The research presents a study on enhancing the robustness of Wi-Fi-basedindoor positioning systems against adversarial attacks. The goal is to improvethe positioning accuracy and resilience of these systems under two attackscenarios: Wi-Fi Spoofing and Signal Strength Manipulation. Three models aredeveloped and evaluated: a baseline model (M_Base), an adversarially trainedrobust model (M_Rob), and an ensemble model (M_Ens). All models utilize aKolmogorov-Arnold Network (KAN) architecture. The robust model is trained withadversarially perturbed data, while the ensemble model combines predictionsfrom both the base and robust models. Experimental results show that the robustmodel reduces positioning error by approximately 10% compared to the baseline,achieving 2.03 meters error under Wi-Fi spoofing and 2.00 meters under signalstrength manipulation. The ensemble model further outperforms with errors of2.01 meters and 1.975 meters for the respective attack types. This analysishighlights the effectiveness of adversarial training techniques in mitigatingattack impacts. The findings underscore the importance of consideringadversarial scenarios in developing indoor positioning systems, as improvedresilience can significantly enhance the accuracy and reliability of suchsystems in mission-critical environments.</description><author>Mitul Goswami, Romit Chatterjee, Somnath Mahato, Prasant Kumar Pattnaik</author><pubDate>Thu, 16 Jan 2025 15:34:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09609v1</guid></item><item><title>Metric Learning with Progressive Self-Distillation for Audio-Visual Embedding Learning</title><link>http://arxiv.org/abs/2501.09608v1</link><description>Metric learning projects samples into an embedded space, where similaritiesand dissimilarities are quantified based on their learned representations.However, existing methods often rely on label-guided representation learning,where representations of different modalities, such as audio and visual data,are aligned based on annotated labels. This approach tends to underutilizelatent complex features and potential relationships inherent in thedistributions of audio and visual data that are not directly tied to thelabels, resulting in suboptimal performance in audio-visual embedding learning.To address this issue, we propose a novel architecture that integratescross-modal triplet loss with progressive self-distillation. Our methodenhances representation learning by leveraging inherent distributions anddynamically refining soft audio-visual alignments -- probabilistic alignmentsbetween audio and visual data that capture the inherent relationships beyondexplicit labels. Specifically, the model distills audio-visualdistribution-based knowledge from annotated labels in a subset of each batch.This self-distilled knowledge is used t</description><author>Donghuo Zeng, Kazushi Ikeda</author><pubDate>Thu, 16 Jan 2025 15:32:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09608v1</guid></item><item><title>Higher-Order Topological Directionality and Directed Simplicial Neural Networks</title><link>http://arxiv.org/abs/2409.08389v3</link><description>Topological Deep Learning (TDL) has emerged as a paradigm to process andlearn from signals defined on higher-order combinatorial topological spaces,such as simplicial or cell complexes. Although many complex systems have anasymmetric relational structure, most TDL models forcibly symmetrize theserelationships. In this paper, we first introduce a novel notion of higher-orderdirectionality and we then design Directed Simplicial Neural Networks(Dir-SNNs) based on it. Dir-SNNs are message-passing networks operating ondirected simplicial complexes able to leverage directed and possibly asymmetricinteractions among the simplices. To our knowledge, this is the first TDL modelusing a notion of higher-order directionality. We theoretically and empiricallyprove that Dir-SNNs are more expressive than their directed graph counterpartin distinguishing isomorphic directed graphs. Experiments on a synthetic sourcelocalization task demonstrate that Dir-SNNs outperform undirected SNNs when theunderlying complex is directed, and perform comparably when the underlyingcomplex is undirected.</description><author>Manuel Lecha, Andrea Cavallo, Francesca Dominici, Elvin Isufi, Claudio Battiloro</author><pubDate>Thu, 16 Jan 2025 15:32:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.08389v3</guid></item><item><title>MECD+: Unlocking Event-Level Causal Graph Discovery for Video Reasoning</title><link>http://arxiv.org/abs/2501.07227v2</link><description>Video causal reasoning aims to achieve a high-level understanding of videosfrom a causal perspective. However, it exhibits limitations in its scope,primarily executed in a question-answering paradigm and focusing on brief videosegments containing isolated events and basic causal relations, lackingcomprehensive and structured causality analysis for videos with multipleinterconnected events. To fill this gap, we introduce a new task and dataset,Multi-Event Causal Discovery (MECD). It aims to uncover the causal relationsbetween events distributed chronologically across long videos. Given visualsegments and textual descriptions of events, MECD identifies the causalassociations between these events to derive a comprehensive and structuredevent-level video causal graph explaining why and how the result eventoccurred. To address the challenges of MECD, we devise a novel frameworkinspired by the Granger Causality method, incorporating an efficient mask-basedevent prediction model to perform an Event Granger Test. It estimates causalityby comparing the predicted result event when premise events are masked versusunmasked. Furthermore, we integrate causal inference techniques such asfront-door adjustment and counterfactual inference to mitigate challenges inMECD like causality confounding and illusory causality. Additionally, contextchain reasoning is introduced to conduct more robust and generalized reasoning.Experiments validate the effectiveness of our framework in reasoning completecausal relations, outperforming GPT-4o and VideoChat2 by 5.77% and 2.70%,respectively. Further experiments demonstrate that causal relation graphs canalso contribute to downstream video understanding tasks such as video questionanswering and video event prediction.</description><author>Tieyuan Chen, Huabin Liu, Yi Wang, Yihang Chen, Tianyao He, Chaofan Gan, Huanyu He, Weiyao Lin</author><pubDate>Thu, 16 Jan 2025 15:30:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.07227v2</guid></item><item><title>Managed-Retention Memory: A New Class of Memory for the AI Era</title><link>http://arxiv.org/abs/2501.09605v1</link><description>AI clusters today are one of the major uses of High Bandwidth Memory (HBM).However, HBM is suboptimal for AI workloads for several reasons. Analysis showsHBM is overprovisioned on write performance, but underprovisioned on densityand read bandwidth, and also has significant energy per bit overheads. It isalso expensive, with lower yield than DRAM due to manufacturing complexity. Wepropose a new memory class: Managed-Retention Memory (MRM), which is moreoptimized to store key data structures for AI inference workloads. We believethat MRM may finally provide a path to viability for technologies that wereoriginally proposed to support Storage Class Memory (SCM). These technologiestraditionally offered long-term persistence (10+ years) but provided poor IOperformance and/or endurance. MRM makes different trade-offs, and byunderstanding the workload IO patterns, MRM foregoes long-term data retentionand write performance for better potential performance on the metrics importantfor these workloads.</description><author>Sergey Legtchenko, Ioan Stefanovici, Richard Black, Antony Rowstron, Junyi Liu, Paolo Costa, Burcu Canakci, Dushyanth Narayanan, Xingbo Wu</author><pubDate>Thu, 16 Jan 2025 15:25:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09605v1</guid></item><item><title>From Scarcity to Capability: Empowering Fake News Detection in Low-Resource Languages with LLMs</title><link>http://arxiv.org/abs/2501.09604v1</link><description>The rapid spread of fake news presents a significant global challenge,particularly in low-resource languages like Bangla, which lack adequatedatasets and detection tools. Although manual fact-checking is accurate, it isexpensive and slow to prevent the dissemination of fake news. Addressing thisgap, we introduce BanFakeNews-2.0, a robust dataset to enhance Bangla fake newsdetection. This version includes 11,700 additional, meticulously curated fakenews articles validated from credible sources, creating a proportional datasetof 47,000 authentic and 13,000 fake news items across 13 categories. Inaddition, we created a manually curated independent test set of 460 fake and540 authentic news items for rigorous evaluation. We invest efforts incollecting fake news from credible sources and manually verified whilepreserving the linguistic richness. We develop a benchmark system utilizingtransformer-based architectures, including fine-tuned Bidirectional EncoderRepresentations from Transformers variants (F1-87\%) and Large Language Modelswith Quantized Low-Rank Approximation (F1-89\%), that significantly outperformstraditional methods. BanFakeNews-2.0 offers a valuable resource to advanceresearch and application in fake news detection for low-resourced languages. Wepublicly release our dataset and model on Github to foster research in thisdirection.</description><author>Hrithik Majumdar Shibu, Shrestha Datta, Md. Sumon Miah, Nasrullah Sami, Mahruba Sharmin Chowdhury, Md. Saiful Islam</author><pubDate>Thu, 16 Jan 2025 15:24:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09604v1</guid></item><item><title>Mesh2SLAM in VR: A Fast Geometry-Based SLAM Framework for Rapid Prototyping in Virtual Reality Applications</title><link>http://arxiv.org/abs/2501.09600v1</link><description>SLAM is a foundational technique with broad applications in robotics andAR/VR. SLAM simulations evaluate new concepts, but testing onresource-constrained devices, such as VR HMDs, faces challenges: highcomputational cost and restricted sensor data access. This work proposes asparse framework using mesh geometry projections as features, which improvesefficiency and circumvents direct sensor data access, advancing SLAM researchas we demonstrate in VR and through numerical evaluation.</description><author>Carlos Augusto Pinheiro de Sousa, Heiko Hamann, Oliver Deussen</author><pubDate>Thu, 16 Jan 2025 15:22:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09600v1</guid></item><item><title>Reducing the Sensitivity of Neural Physics Simulators to Mesh Topology via Pretraining</title><link>http://arxiv.org/abs/2501.09597v1</link><description>Meshes are used to represent complex objects in high fidelity physicssimulators across a variety of domains, such as radar sensing and aerodynamics.There is growing interest in using neural networks to accelerate physicssimulations, and also a growing body of work on applying neural networksdirectly to irregular mesh data. Since multiple mesh topologies can representthe same object, mesh augmentation is typically required to handle topologicalvariation when training neural networks. Due to the sensitivity of physicssimulators to small changes in mesh shape, it is challenging to use theseaugmentations when training neural network-based physics simulators. In thiswork, we show that variations in mesh topology can significantly reduce theperformance of neural network simulators. We evaluate whether pretraining canbe used to address this issue, and find that employing an establishedautoencoder pretraining technique with graph embedding models reduces thesensitivity of neural network simulators to variations in mesh topology.Finally, we highlight future research directions that may further reduce neuralsimulator sensitivity to mesh topology.</description><author>Nathan Vaska, Justin Goodwin, Robin Walters, Rajmonda S. Caceres</author><pubDate>Thu, 16 Jan 2025 15:21:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09597v1</guid></item><item><title>IFRA: a machine learning-based Instrumented Fall Risk Assessment Scale derived from Instrumented Timed Up and Go test in stroke patients</title><link>http://arxiv.org/abs/2501.09595v1</link><description>Effective fall risk assessment is critical for post-stroke patients. Thepresent study proposes a novel, data-informed fall risk assessment method basedon the instrumented Timed Up and Go (ITUG) test data, bringing in many mobilitymeasures that traditional clinical scales fail to capture. IFRA, which standsfor Instrumented Fall Risk Assessment, has been developed using a two-stepprocess: first, features with the highest predictive power among thosecollected in a ITUG test have been identified using machine learningtechniques; then, a strategy is proposed to stratify patients into low, medium,or high-risk strata. The dataset used in our analysis consists of 142participants, out of which 93 were used for training (15 syntheticallygenerated), 17 for validation and 32 to test the resulting IFRA scale (22non-fallers and 10 fallers). Features considered in the IFRA scale include gaitspeed, vertical acceleration during sit-to-walk transition, and turning angularvelocity, which align well with established literature on the risk of fall inneurological patients. In a comparison with traditional clinical scales such asthe traditional Timed Up &amp; Go and the Mini-BESTest, IFRA demonstratescompetitive performance, being the only scale to correctly assign more thanhalf of the fallers to the high-risk stratum (Fischer's Exact test p = 0.004).Despite the dataset's limited size, this is the first proof-of-concept study topave the way for future evidence regarding the use of IFRA tool for continuouspatient monitoring and fall prevention both in clinical stroke rehabilitationand at home post-discharge.</description><author>Simone Macciò, Alessandro Carfì, Alessio Capitanelli, Peppino Tropea, Massimo Corbo, Fulvio Mastrogiovanni, Michela Picardi</author><pubDate>Thu, 16 Jan 2025 15:20:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09595v1</guid></item><item><title>Metrics for Inter-Dataset Similarity with Example Applications in Synthetic Data and Feature Selection Evaluation -- Extended Version</title><link>http://arxiv.org/abs/2501.09591v1</link><description>Measuring inter-dataset similarity is an important task in machine learningand data mining with various use cases and applications. Existing methods formeasuring inter-dataset similarity are computationally expensive, limited, orsensitive to different entities and non-trivial choices for parameters. Theyalso lack a holistic perspective on the entire dataset. In this paper, wepropose two novel metrics for measuring inter-dataset similarity. We discussthe mathematical foundation and the theoretical basis of our proposed metrics.We demonstrate the effectiveness of the proposed metrics by investigating twoapplications in the evaluation of synthetic data and in the evaluation offeature selection methods. The theoretical and empirical studies conducted inthis paper illustrate the effectiveness of the proposed metrics.</description><author>Muhammad Rajabinasab, Anton D. Lautrup, Arthur Zimek</author><pubDate>Thu, 16 Jan 2025 15:17:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09591v1</guid></item><item><title>Atleus: Accelerating Transformers on the Edge Enabled by 3D Heterogeneous Manycore Architectures</title><link>http://arxiv.org/abs/2501.09588v1</link><description>Transformer architectures have become the standard neural network model forvarious machine learning applications including natural language processing andcomputer vision. However, the compute and memory requirements introduced bytransformer models make them challenging to adopt for edge applications.Furthermore, fine-tuning pre-trained transformers (e.g., foundation models) isa common task to enhance the model's predictive performance on specifictasks/applications. Existing transformer accelerators are oblivious tocomplexities introduced by fine-tuning. In this paper, we propose the design ofa three-dimensional (3D) heterogeneous architecture referred to as Atleus thatincorporates heterogeneous computing resources specifically optimized toaccelerate transformer models for the dual purposes of fine-tuning andinference. Specifically, Atleus utilizes non-volatile memory and systolic arrayfor accelerating transformer computational kernels using an integrated 3Dplatform. Moreover, we design a suitable NoC to achieve high performance andenergy efficiency. Finally, Atleus adopts an effective quantization scheme tosupport model compression. Experimental results demonstrate that Atleusoutperforms existing state-of-the-art by up to 56x and 64.5x in terms ofperformance and energy efficiency respectively</description><author>Pratyush Dhingra, Janardhan Rao Doppa, Partha Pratim Pande</author><pubDate>Thu, 16 Jan 2025 15:11:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09588v1</guid></item><item><title>Hybrid additive modeling with partial dependence for supervised regression and dynamical systems forecasting</title><link>http://arxiv.org/abs/2307.02229v2</link><description>Learning processes by exploiting restricted domain knowledge is an importanttask across a plethora of scientific areas, with more and more hybrid trainingmethods additively combining data-driven and model-based approaches. Althoughthe obtained models are more accurate than purely data-driven models, theoptimization process usually comes with sensitive regularization constraints.Furthermore, while such hybrid methods have been tested in various scientificapplications, they have been mostly tested on dynamical systems, with onlylimited study about the influence of each model component on global performanceand parameter identification. In this work, we introduce a new hybrid trainingapproach based on partial dependence, which removes the need for intricateregularization. Moreover, we assess the performance of hybrid modeling againsttraditional machine learning methods on standard regression problems. Wecompare, on both synthetic and real regression problems, several approaches fortraining such hybrid models. We focus on hybrid methods that additively combinea parametric term with a machine learning term and investigate model-agnostictraining procedures. Therefore, experiments are carried out with differenttypes of machine learning models, including tree-based models and artificialneural networks. We also extend our partial dependence optimization process fordynamical systems forecasting and compare it to existing schemes.</description><author>Yann Claes, Vân Anh Huynh-Thu, Pierre Geurts</author><pubDate>Thu, 16 Jan 2025 15:00:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02229v2</guid></item><item><title>VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction</title><link>http://arxiv.org/abs/2501.01957v2</link><description>Recent Multimodal Large Language Models (MLLMs) have typically focused onintegrating visual and textual modalities, with less emphasis placed on therole of speech in enhancing interaction. However, speech plays a crucial rolein multimodal dialogue systems, and implementing high-performance in bothvision and speech tasks remains a significant challenge due to the fundamentalmodality differences. In this paper, we propose a carefully designedmulti-stage training methodology that progressively trains LLM to understandboth visual and speech information, ultimately enabling fluent vision andspeech interaction. Our approach not only preserves strong vision-languagecapacity, but also enables efficient speech-to-speech dialogue capabilitieswithout separate ASR and TTS modules, significantly accelerating multimodalend-to-end response speed. By comparing our method against state-of-the-artcounterparts across benchmarks for image, video, and speech tasks, wedemonstrate that our model is equipped with both strong visual and speechcapabilities, making near real-time vision and speech interaction.</description><author>Chaoyou Fu, Haojia Lin, Xiong Wang, Yi-Fan Zhang, Yunhang Shen, Xiaoyu Liu, Yangze Li, Zuwei Long, Heting Gao, Ke Li, Long Ma, Xiawu Zheng, Rongrong Ji, Xing Sun, Caifeng Shan, Ran He</author><pubDate>Thu, 16 Jan 2025 15:00:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.01957v2</guid></item><item><title>Sequential PatchCore: Anomaly Detection for Surface Inspection using Synthetic Impurities</title><link>http://arxiv.org/abs/2501.09579v1</link><description>The appearance of surface impurities (e.g., water stains, fingerprints,stickers) is an often-mentioned issue that causes degradation of automatedvisual inspection systems. At the same time, synthetic data generationtechniques for visual surface inspection have focused primarily on generatingperfect examples and defects, disregarding impurities. This study highlightsthe importance of considering impurities when generating synthetic data. Weintroduce a procedural method to include photorealistic water stains insynthetic data. The synthetic datasets are generated to correspond to realdatasets and are further used to train an anomaly detection model andinvestigate the influence of water stains. The high-resolution images used forsurface inspection lead to memory bottlenecks during anomaly detectiontraining. To address this, we introduce Sequential PatchCore - a method tobuild coresets sequentially and make training on large images usingconsumer-grade hardware tractable. This allows us to perform transfer learningusing coresets pre-trained on different dataset versions. Our results show thebenefits of using synthetic data for pre-training an explicit coreset anomalymodel and the extended performance benefits of finetuning the coreset usingreal data. We observed how the impurities and labelling ambiguity lower themodel performance and have additionally reported the defect-wise recall toprovide an industrially relevant perspective on model performance.</description><author>Runzhou Mao, Juraj Fulir, Christoph Garth, Petra Gospodnetić</author><pubDate>Thu, 16 Jan 2025 14:56:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09579v1</guid></item><item><title>Towards Spectral Convergence of Locally Linear Embedding on Manifolds with Boundary</title><link>http://arxiv.org/abs/2501.09572v1</link><description>We study the eigenvalues and eigenfunctions of a differential operator thatgoverns the asymptotic behavior of the unsupervised learning algorithm known asLocally Linear Embedding when a large data set is sampled from an interval ordisc. In particular, the differential operator is of second order, mixed-type,and degenerates near the boundary. We show that a natural regularity conditionon the eigenfunctions imposes a consistent boundary condition and use theFrobenius method to estimate pointwise behavior. We then determine the limitingsequence of eigenvalues analytically and compare them to numerical predictions.Finally, we propose a variational framework for determining eigenvalues onother compact manifolds.</description><author>Andrew Lyons</author><pubDate>Thu, 16 Jan 2025 14:45:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09572v1</guid></item><item><title>Provably Efficient Reinforcement Learning with Multinomial Logit Function Approximation</title><link>http://arxiv.org/abs/2405.17061v3</link><description>We study a new class of MDPs that employs multinomial logit (MNL) functionapproximation to ensure valid probability distributions over the state space.Despite its significant benefits, incorporating the non-linear function raisessubstantial challenges in both statistical and computational efficiency. Thebest-known result of Hwang and Oh [2023] has achieved an$\widetilde{\mathcal{O}}(\kappa^{-1}dH^2\sqrt{K})$ regret upper bound, where$\kappa$ is a problem-dependent quantity, $d$ is the feature dimension, $H$ isthe episode length, and $K$ is the number of episodes. However, we observe that$\kappa^{-1}$ exhibits polynomial dependence on the number of reachable states,which can be as large as the state space size in the worst case and thusundermines the motivation for function approximation. Additionally, theirmethod requires storing all historical data and the time complexity scaleslinearly with the episode count, which is computationally expensive. In thiswork, we propose a statistically efficient algorithm that achieves a regret of$\widetilde{\mathcal{O}}(dH^2\sqrt{K} + \kappa^{-1}d^2H^2)$, eliminating thedependence on $\kappa^{-1}$ in the dominant term for the first time. We thenaddress the computational challenges by introducing an enhanced algorithm thatachieves the same regret guarantee but with only constant cost. Finally, weestablish the first lower bound for this problem, justifying the optimality ofour results in $d$ and $K$.</description><author>Long-Fei Li, Yu-Jie Zhang, Peng Zhao, Zhi-Hua Zhou</author><pubDate>Thu, 16 Jan 2025 14:45:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17061v3</guid></item><item><title>Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks</title><link>http://arxiv.org/abs/2407.20891v4</link><description>Computational complexity of Bayesian learning is impeding its adoption inpractical, large-scale tasks. Despite demonstrations of significant merits suchas improved robustness and resilience to unseen or out-of-distribution inputsover their non- Bayesian counterparts, their practical use has faded to nearinsignificance. In this study, we introduce an innovative framework to mitigatethe computational burden of Bayesian neural networks (BNNs). Our approachfollows the principle of Bayesian techniques based on deep ensembles, butsignificantly reduces their cost via multiple low-rank perturbations ofparameters arising from a pre-trained neural network. Both vanilla version ofensembles as well as more sophisticated schemes such as Bayesian learning withStein Variational Gradient Descent (SVGD), previously deemed impractical forlarge models, can be seamlessly implemented within the proposed framework,called Bayesian Low-Rank LeArning (Bella). In a nutshell, i) Bella achieves adramatic reduction in the number of trainable parameters required toapproximate a Bayesian posterior; and ii) it not only maintains, but in someinstances, surpasses the performance of conventional Bayesian learning methodsand non-Bayesian baselines. Our results with large-scale tasks such asImageNet, CAMELYON17, DomainNet, VQA with CLIP, LLaVA demonstrate theeffectiveness and versatility of Bella in building highly scalable andpractical Bayesian deep models for real-world applications.</description><author>Bao Gia Doan, Afshar Shamsi, Xiao-Yu Guo, Arash Mohammadi, Hamid Alinejad-Rokny, Dino Sejdinovic, Damien Teney, Damith C. Ranasinghe, Ehsan Abbasnejad</author><pubDate>Thu, 16 Jan 2025 14:45:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20891v4</guid></item><item><title>MatrixNet: Learning over symmetry groups using learned group representations</title><link>http://arxiv.org/abs/2501.09571v1</link><description>Group theory has been used in machine learning to provide a theoreticallygrounded approach for incorporating known symmetry transformations in tasksfrom robotics to protein modeling. In these applications, equivariant neuralnetworks use known symmetry groups with predefined representations to learnover geometric input data. We propose MatrixNet, a neural network architecturethat learns matrix representations of group element inputs instead of usingpredefined representations. MatrixNet achieves higher sample efficiency andgeneralization over several standard baselines in prediction tasks over theseveral finite groups and the Artin braid group. We also show that MatrixNetrespects group relations allowing generalization to group elements of greaterword length than in the training set.</description><author>Lucas Laird, Circe Hsu, Asilata Bapat, Robin Walters</author><pubDate>Thu, 16 Jan 2025 14:45:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09571v1</guid></item><item><title>Latent Space Characterization of Autoencoder Variants</title><link>http://arxiv.org/abs/2412.04755v2</link><description>Understanding the latent spaces learned by deep learning models is crucial inexploring how they represent and generate complex data. Autoencoders (AEs) haveplayed a key role in the area of representation learning, with numerousregularization techniques and training principles developed not only to enhancetheir ability to learn compact and robust representations, but also to revealhow different architectures influence the structure and smoothness of thelower-dimensional non-linear manifold. We strive to characterize the structureof the latent spaces learned by different autoencoders including convolutionalautoencoders (CAEs), denoising autoencoders (DAEs), and variationalautoencoders (VAEs) and how they change with the perturbations in the input. Bycharacterizing the matrix manifolds corresponding to the latent spaces, weprovide an explanation for the well-known observation that the latent spaces ofCAE and DAE form non-smooth manifolds, while that of VAE forms a smoothmanifold. We also map the points of the matrix manifold to a Hilbert spaceusing distance preserving transforms and provide an alternate view in terms ofthe subspaces generated in the Hilbert space as a function of the distortion inthe input. The results show that the latent manifolds of CAE and DAE arestratified with each stratum being a smooth product manifold, while themanifold of VAE is a smooth product manifold of two symmetric positive definitematrices and a symmetric positive semi-definite matrix.</description><author>Anika Shrivastava, Renu Rameshan, Samar Agnihotri</author><pubDate>Thu, 16 Jan 2025 14:44:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04755v2</guid></item><item><title>A New Teacher-Reviewer-Student Framework for Semi-supervised 2D Human Pose Estimation</title><link>http://arxiv.org/abs/2501.09565v1</link><description>Conventional 2D human pose estimation methods typically require extensivelabeled annotations, which are both labor-intensive and expensive. In contrast,semi-supervised 2D human pose estimation can alleviate the above problems byleveraging a large amount of unlabeled data along with a small portion oflabeled data. Existing semi-supervised 2D human pose estimation methods updatethe network through backpropagation, ignoring crucial historical informationfrom the previous training process. Therefore, we propose a novelsemi-supervised 2D human pose estimation method by utilizing a newly designedTeacher-Reviewer-Student framework. Specifically, we first mimic the phenomenonthat human beings constantly review previous knowledge for consolidation todesign our framework, in which the teacher predicts results to guide thestudent's learning and the reviewer stores important historical parameters toprovide additional supervision signals. Secondly, we introduce a Multi-levelFeature Learning strategy, which utilizes the outputs from different stages ofthe backbone to estimate the heatmap to guide network training, enriching thesupervisory information while effectively capturing keypoint relationships.Finally, we design a data augmentation strategy, i.e., Keypoint-Mix, to perturbpose information by mixing different keypoints, thus enhancing the network'sability to discern keypoints. Extensive experiments on publicly availabledatasets, demonstrate our method achieves significant improvements compared tothe existing methods.</description><author>Wulian Yun, Mengshi Qi, Fei Peng, Huadong Ma</author><pubDate>Thu, 16 Jan 2025 14:40:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09565v1</guid></item><item><title>Can linguists better understand DNA?</title><link>http://arxiv.org/abs/2412.07678v2</link><description>Multilingual transfer ability, which reflects how well models fine-tuned onone source language can be applied to other languages, has been well studied inmultilingual pre-trained models. However, the existence of such capabilitytransfer between natural language and gene sequences/languages remains underexplored.This study addresses this gap by drawing inspiration from thesentence-pair classification task used for evaluating sentence similarity innatural language. We constructed two analogous tasks: DNA-pairclassification(DNA sequence similarity) and DNA-protein-pairclassification(gene coding determination). These tasks were designed tovalidate the transferability of capabilities from natural language to genesequences. Even a small-scale pre-trained model like GPT-2-small, which waspre-trained on English, achieved an accuracy of 78% on the DNA-pairclassification task after being fine-tuned on English sentence-pairclassification data(XTREME PAWS-X). While training a BERT model on multilingualtext, the precision reached 89%. On the more complex DNA-protein-pairclassification task, however, the model's output was barely distinguishablefrom random output.Experimental validation has confirmed that the transfer ofcapabilities from natural language to biological language is unequivocallypresent. Building on this foundation, we have also investigated the impact ofmodel parameter scale and pre-training on this capability transfer. We providerecommendations for facilitating the transfer of capabilities from naturallanguage to genetic language,as well as new approaches for conductingbiological research based on this capability.This study offers an intriguingnew perspective on exploring the relationship between natural language andgenetic language.</description><author>Wang Liang</author><pubDate>Thu, 16 Jan 2025 14:33:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.07678v2</guid></item><item><title>FSDEM: Feature Selection Dynamic Evaluation Metric</title><link>http://arxiv.org/abs/2408.14234v3</link><description>Expressive evaluation metrics are indispensable for informative experimentsin all areas, and while several metrics are established in some areas, inothers, such as feature selection, only indirect or otherwise limitedevaluation metrics are found. In this paper, we propose a novel evaluationmetric to address several problems of its predecessors and allow for flexibleand reliable evaluation of feature selection algorithms. The proposed metric isa dynamic metric with two properties that can be used to evaluate both theperformance and the stability of a feature selection algorithm. We conductseveral empirical experiments to illustrate the use of the proposed metric inthe successful evaluation of feature selection algorithms. We also provide acomparison and analysis to show the different aspects involved in theevaluation of the feature selection algorithms. The results indicate that theproposed metric is successful in carrying out the evaluation task for featureselection algorithms. This paper is an extended version of a paper published at SISAP 2024.</description><author>Muhammad Rajabinasab, Anton D. Lautrup, Tobias Hyrup, Arthur Zimek</author><pubDate>Thu, 16 Jan 2025 14:29:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14234v3</guid></item><item><title>Stylomech: Unveiling Authorship via Computational Stylometry in English and Romanized Sinhala</title><link>http://arxiv.org/abs/2501.09561v1</link><description>With the advent of Web 2.0, the development in social technology coupled withglobal communication systematically brought positive and negative impacts tosociety. Copyright claims and Author identification are deemed crucial as therehas been a considerable amount of increase in content violation owing to thelack of proper ethics in society. The Author's attribution in both English andRomanized Sinhala became a major requirement in the last few decades. As anarea largely unexplored, particularly within the context of Romanized Sinhala,the research contributes significantly to the field of computationallinguistics. The proposed author attribution system offers a unique approach,allowing for the comparison of only two sets of text: suspect author andanonymous text, a departure from traditional methodologies which often rely onlarger corpora. This work focuses on using the numerical representation ofvarious pairs of the same and different authors allowing for, the model totrain on these representations as opposed to text, this allows for it to applyto a multitude of authors and contexts, given that the suspected author text,and the anonymous text are of reasonable quality. By expanding the scope ofauthorship attribution to encompass diverse linguistic contexts, the workcontributes to fostering trust and accountability in digital communication,especially in Sri Lanka. This research presents a pioneering approach to authorattribution in both English and Romanized Sinhala, addressing a critical needfor content verification and intellectual property rights enforcement in thedigital age.</description><author>Nabeelah Faumi, Adeepa Gunathilake, Benura Wickramanayake, Deelaka Dias, TGDK Sumanathilaka</author><pubDate>Thu, 16 Jan 2025 14:26:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09561v1</guid></item></channel></rss>