<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 25 Jun 2024 06:00:30 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>StableNormal: Reducing Diffusion Variance for Stable and Sharp Normal</title><link>http://arxiv.org/abs/2406.16864v1</link><description>This work addresses the challenge of high-quality surface normal estimationfrom monocular colored inputs (i.e., images and videos), a field which hasrecently been revolutionized by repurposing diffusion priors. However, previousattempts still struggle with stochastic inference, conflicting with thedeterministic nature of the Image2Normal task, and costly ensembling step,which slows down the estimation process. Our method, StableNormal, mitigatesthe stochasticity of the diffusion process by reducing inference variance, thusproducing "Stable-and-Sharp" normal estimates without any additional ensemblingprocess. StableNormal works robustly under challenging imaging conditions, suchas extreme lighting, blurring, and low quality. It is also robust againsttransparent and reflective surfaces, as well as cluttered scenes with numerousobjects. Specifically, StableNormal employs a coarse-to-fine strategy, whichstarts with a one-step normal estimator (YOSO) to derive an initial normalguess, that is relatively coarse but reliable, then followed by asemantic-guided refinement process (SG-DRN) that refines the normals to recovergeometric details. The effectiveness of StableNormal is demonstrated throughcompetitive performance in standard datasets such as DIODE-indoor, iBims,ScannetV2 and NYUv2, and also in various downstream tasks, such as surfacereconstruction and normal enhancement. These results evidence that StableNormalretains both the "stability" and "sharpness" for accurate normal estimation.StableNormal represents a baby attempt to repurpose diffusion priors fordeterministic estimation. To democratize this, code and models have beenpublicly available in hf.co/Stable-X</description><author>Chongjie Ye, Lingteng Qiu, Xiaodong Gu, Qi Zuo, Yushuang Wu, Zilong Dong, Liefeng Bo, Yuliang Xiu, Xiaoguang Han</author><pubDate>Mon, 24 Jun 2024 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16864v1</guid></item><item><title>Revisiting Referring Expression Comprehension Evaluation in the Era of Large Multimodal Models</title><link>http://arxiv.org/abs/2406.16866v1</link><description>Referring expression comprehension (REC) involves localizing a targetinstance based on a textual description. Recent advancements in REC have beendriven by large multimodal models (LMMs) like CogVLM, which achieved 92.44%accuracy on RefCOCO. However, this study questions whether existing benchmarkssuch as RefCOCO, RefCOCO+, and RefCOCOg, capture LMMs' comprehensivecapabilities. We begin with a manual examination of these benchmarks, revealinghigh labeling error rates: 14% in RefCOCO, 24% in RefCOCO+, and 5% in RefCOCOg,which undermines the authenticity of evaluations. We address this by excludingproblematic instances and reevaluating several LMMs capable of handling the RECtask, showing significant accuracy improvements, thus highlighting the impactof benchmark noise. In response, we introduce Ref-L4, a comprehensive RECbenchmark, specifically designed to evaluate modern REC models. Ref-L4 isdistinguished by four key features: 1) a substantial sample size with 45,341annotations; 2) a diverse range of object categories with 365 distinct typesand varying instance scales from 30 to 3,767; 3) lengthy referring expressionsaveraging 24.2 words; and 4) an extensive vocabulary comprising 22,813 uniquewords. We evaluate a total of 24 large models on Ref-L4 and provide valuableinsights. The cleaned versions of RefCOCO, RefCOCO+, and RefCOCOg, as well asour Ref-L4 benchmark and evaluation code, are available athttps://github.com/JierunChen/Ref-L4.</description><author>Jierun Chen, Fangyun Wei, Jinjing Zhao, Sizhe Song, Bohuai Wu, Zhuoxuan Peng, S. -H. Gary Chan, Hongyang Zhang</author><pubDate>Mon, 24 Jun 2024 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16866v1</guid></item><item><title>FreeTraj: Tuning-Free Trajectory Control in Video Diffusion Models</title><link>http://arxiv.org/abs/2406.16863v1</link><description>Diffusion model has demonstrated remarkable capability in video generation,which further sparks interest in introducing trajectory control into thegeneration process. While existing works mainly focus on training-based methods(e.g., conditional adapter), we argue that diffusion model itself allows decentcontrol over the generated content without requiring any training. In thisstudy, we introduce a tuning-free framework to achieve trajectory-controllablevideo generation, by imposing guidance on both noise construction and attentioncomputation. Specifically, 1) we first show several instructive phenomenons andanalyze how initial noises influence the motion trajectory of generatedcontent. 2) Subsequently, we propose FreeTraj, a tuning-free approach thatenables trajectory control by modifying noise sampling and attentionmechanisms. 3) Furthermore, we extend FreeTraj to facilitate longer and largervideo generation with controllable trajectories. Equipped with these designs,users have the flexibility to provide trajectories manually or opt fortrajectories automatically generated by the LLM trajectory planner. Extensiveexperiments validate the efficacy of our approach in enhancing the trajectorycontrollability of video diffusion models.</description><author>Haonan Qiu, Zhaoxi Chen, Zhouxia Wang, Yingqing He, Menghan Xia, Ziwei Liu</author><pubDate>Mon, 24 Jun 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16863v1</guid></item><item><title>Dreamitate: Real-World Visuomotor Policy Learning via Video Generation</title><link>http://arxiv.org/abs/2406.16862v1</link><description>A key challenge in manipulation is learning a policy that can robustlygeneralize to diverse visual environments. A promising mechanism for learningrobust policies is to leverage video generative models, which are pretrained onlarge-scale datasets of internet videos. In this paper, we propose a visuomotorpolicy learning framework that fine-tunes a video diffusion model on humandemonstrations of a given task. At test time, we generate an example of anexecution of the task conditioned on images of a novel scene, and use thissynthesized execution directly to control the robot. Our key insight is thatusing common tools allows us to effortlessly bridge the embodiment gap betweenthe human hand and the robot manipulator. We evaluate our approach on fourtasks of increasing complexity and demonstrate that harnessing internet-scalegenerative models allows the learned policy to achieve a significantly higherdegree of generalization than existing behavior cloning approaches.</description><author>Junbang Liang, Ruoshi Liu, Ege Ozguroglu, Sruthi Sudhakar, Achal Dave, Pavel Tokmakov, Shuran Song, Carl Vondrick</author><pubDate>Mon, 24 Jun 2024 18:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16862v1</guid></item><item><title>Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs</title><link>http://arxiv.org/abs/2406.16860v1</link><description>We introduce Cambrian-1, a family of multimodal LLMs (MLLMs) designed with avision-centric approach. While stronger language models can enhance multimodalcapabilities, the design choices for vision components are often insufficientlyexplored and disconnected from visual representation learning research. Thisgap hinders accurate sensory grounding in real-world scenarios. Our study usesLLMs and visual instruction tuning as an interface to evaluate various visualrepresentations, offering new insights into different models and architectures-- self-supervised, strongly supervised, or combinations thereof -- based onexperiments with over 20 vision encoders. We critically examine existing MLLMbenchmarks, addressing the difficulties involved in consolidating andinterpreting results from various tasks, and introduce a new vision-centricbenchmark, CV-Bench. To further improve visual grounding, we propose theSpatial Vision Aggregator (SVA), a dynamic and spatially-aware connector thatintegrates high-resolution vision features with LLMs while reducing the numberof tokens. Additionally, we discuss the curation of high-quality visualinstruction-tuning data from publicly available sources, emphasizing theimportance of data source balancing and distribution ratio. Collectively,Cambrian-1 not only achieves state-of-the-art performance but also serves as acomprehensive, open cookbook for instruction-tuned MLLMs. We provide modelweights, code, supporting tools, datasets, and detailed instruction-tuning andevaluation recipes. We hope our release will inspire and accelerateadvancements in multimodal systems and visual representation learning.</description><author>Shengbang Tong, Ellis Brown, Penghao Wu, Sanghyun Woo, Manoj Middepogu, Sai Charitha Akula, Jihan Yang, Shusheng Yang, Adithya Iyer, Xichen Pan, Austin Wang, Rob Fergus, Yann LeCun, Saining Xie</author><pubDate>Mon, 24 Jun 2024 18:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16860v1</guid></item><item><title>EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees</title><link>http://arxiv.org/abs/2406.16858v1</link><description>Inference with modern Large Language Models (LLMs) is expensive andtime-consuming, and speculative sampling has proven to be an effectivesolution. Most speculative sampling methods such as EAGLE use a static drafttree, implicitly assuming that the acceptance rate of draft tokens depends onlyon their position. Interestingly, we found that the acceptance rate of drafttokens is also context-dependent. In this paper, building upon EAGLE, wepropose EAGLE-2, which introduces a new technique of context-aware dynamicdraft tree into drafting modeling. This improvement leverages the fact that thedraft model of EAGLE is well-calibrated: the confidence scores from the draftmodel approximate acceptance rates with small errors. We conducted extensiveevaluations on three series of LLMs and six tasks, with EAGLE-2 achievingspeedup ratios 3.05x-4.26x, which is 20%-40% faster than EAGLE-1. EAGLE-2 alsoensures that the distribution of the generated text remains unchanged, makingit a lossless acceleration algorithm.</description><author>Yuhui Li, Fangyun Wei, Chao Zhang, Hongyang Zhang</author><pubDate>Mon, 24 Jun 2024 18:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16858v1</guid></item><item><title>DreamBench++: A Human-Aligned Benchmark for Personalized Image Generation</title><link>http://arxiv.org/abs/2406.16855v1</link><description>Personalized image generation holds great promise in assisting humans ineveryday work and life due to its impressive function in creatively generatingpersonalized content. However, current evaluations either are automated butmisalign with humans or require human evaluations that are time-consuming andexpensive. In this work, we present DreamBench++, a human-aligned benchmarkautomated by advanced multimodal GPT models. Specifically, we systematicallydesign the prompts to let GPT be both human-aligned and self-aligned, empoweredwith task reinforcement. Further, we construct a comprehensive datasetcomprising diverse images and prompts. By benchmarking 7 modern generativemodels, we demonstrate that DreamBench++ results in significantly morehuman-aligned evaluation, helping boost the community with innovative findings.</description><author>Yuang Peng, Yuxin Cui, Haomiao Tang, Zekun Qi, Runpei Dong, Jing Bai, Chunrui Han, Zheng Ge, Xiangyu Zhang, Shu-Tao Xia</author><pubDate>Mon, 24 Jun 2024 18:58:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16855v1</guid></item><item><title>GeoMFormer: A General Architecture for Geometric Molecular Representation Learning</title><link>http://arxiv.org/abs/2406.16853v1</link><description>Molecular modeling, a central topic in quantum mechanics, aims to accuratelycalculate the properties and simulate the behaviors of molecular systems. Themolecular model is governed by physical laws, which impose geometricconstraints such as invariance and equivariance to coordinate rotation andtranslation. While numerous deep learning approaches have been developed tolearn molecular representations under these constraints, most of them are builtupon heuristic and costly modules. We argue that there is a strong need for ageneral and flexible framework for learning both invariant and equivariantfeatures. In this work, we introduce a novel Transformer-based molecular modelcalled GeoMFormer to achieve this goal. Using the standard Transformer modules,two separate streams are developed to maintain and learn invariant andequivariant representations. Carefully designed cross-attention modules bridgethe two streams, allowing information fusion and enhancing geometric modelingin each stream. As a general and flexible architecture, we show that manyprevious architectures can be viewed as special instantiations of GeoMFormer.Extensive experiments are conducted to demonstrate the power of GeoMFormer. Allempirical results show that GeoMFormer achieves strong performance on bothinvariant and equivariant tasks of different types and scales. Code and modelswill be made publicly available at https://github.com/c-tl/GeoMFormer.</description><author>Tianlang Chen, Shengjie Luo, Di He, Shuxin Zheng, Tie-Yan Liu, Liwei Wang</author><pubDate>Mon, 24 Jun 2024 18:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16853v1</guid></item><item><title>Long Context Transfer from Language to Vision</title><link>http://arxiv.org/abs/2406.16852v1</link><description>Video sequences offer valuable temporal information, but existing largemultimodal models (LMMs) fall short in understanding extremely long videos.Many works address this by reducing the number of visual tokens using visualresamplers. Alternatively, in this paper, we approach this problem from theperspective of the language model. By simply extrapolating the context lengthof the language backbone, we enable LMMs to comprehend orders of magnitude morevisual tokens without any video training. We call this phenomenon long contexttransfer and carefully ablate its properties. To effectively measure LMMs'ability to generalize to long contexts in the vision modality, we developV-NIAH (Visual Needle-In-A-Haystack), a purely synthetic long vision benchmarkinspired by the language model's NIAH test. Our proposed Long Video Assistant(LongVA) can process 2000 frames or over 200K visual tokens without additionalcomplexities. With its extended context length, LongVA achievesstate-of-the-art performance on Video-MME among 7B-scale models by denselysampling more input frames. Our work is open-sourced athttps://github.com/EvolvingLMMs-Lab/LongVA.</description><author>Peiyuan Zhang, Kaichen Zhang, Bo Li, Guangtao Zeng, Jingkang Yang, Yuanhan Zhang, Ziyue Wang, Haoran Tan, Chunyuan Li, Ziwei Liu</author><pubDate>Mon, 24 Jun 2024 18:58:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16852v1</guid></item><item><title>Losing Visual Needles in Image Haystacks: Vision Language Models are Easily Distracted in Short and Long Contexts</title><link>http://arxiv.org/abs/2406.16851v1</link><description>We present LoCoVQA, a dynamic benchmark generator for evaluating long-contextextractive reasoning in vision language models (VLMs). LoCoVQA augments testexamples for mathematical reasoning, VQA, and character recognition tasks withincreasingly long visual contexts composed of both in-distribution andout-of-distribution distractor images. Across these tasks, a diverse set of VLMs rapidly lose performance as thevisual context length grows, often exhibiting a striking exponential decaytrend. This test assesses how well VLMs can ignore irrelevant information whenanswering queries -- a task that is quite easy for language models (LMs) in thetext domain -- demonstrating that current state-of-the-art VLMs lack thisessential capability for many long-context applications.</description><author>Aditya Sharma, Michael Saxon, William Yang Wang</author><pubDate>Mon, 24 Jun 2024 18:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16851v1</guid></item><item><title>From Perfect to Noisy World Simulation: Customizable Embodied Multi-modal Perturbations for SLAM Robustness Benchmarking</title><link>http://arxiv.org/abs/2406.16850v1</link><description>Embodied agents require robust navigation systems to operate in unstructuredenvironments, making the robustness of Simultaneous Localization and Mapping(SLAM) models critical to embodied agent autonomy. While real-world datasetsare invaluable, simulation-based benchmarks offer a scalable approach forrobustness evaluations. However, the creation of a challenging and controllablenoisy world with diverse perturbations remains under-explored. To this end, wepropose a novel, customizable pipeline for noisy data synthesis, aimed atassessing the resilience of multi-modal SLAM models against variousperturbations. The pipeline comprises a comprehensive taxonomy of sensor andmotion perturbations for embodied multi-modal (specifically RGB-D) sensing,categorized by their sources and propagation order, allowing for proceduralcomposition. We also provide a toolbox for synthesizing these perturbations,enabling the transformation of clean environments into challenging noisysimulations. Utilizing the pipeline, we instantiate the large-scaleNoisy-Replica benchmark, which includes diverse perturbation types, to evaluatethe risk tolerance of existing advanced RGB-D SLAM models. Our extensiveanalysis uncovers the susceptibilities of both neural (NeRF and GaussianSplatting -based) and non-neural SLAM models to disturbances, despite theirdemonstrated accuracy in standard benchmarks. Our code is publicly available athttps://github.com/Xiaohao-Xu/SLAM-under-Perturbation.</description><author>Xiaohao Xu, Tianyi Zhang, Sibo Wang, Xiang Li, Yongqi Chen, Ye Li, Bhiksha Raj, Matthew Johnson-Roberson, Xiaonan Huang</author><pubDate>Mon, 24 Jun 2024 18:57:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16850v1</guid></item><item><title>Unsupervised Domain Adaptation for Pediatric Brain Tumor Segmentation</title><link>http://arxiv.org/abs/2406.16848v1</link><description>Significant advances have been made toward building accurate automaticsegmentation models for adult gliomas. However, the performance of these modelsoften degrades when applied to pediatric glioma due to their imaging andclinical differences (domain shift). Obtaining sufficient annotated data forpediatric glioma is typically difficult because of its rare nature. Also,manual annotations are scarce and expensive. In this work, we proposeDomain-Adapted nnU-Net (DA-nnUNet) to perform unsupervised domain adaptationfrom adult glioma (source domain) to pediatric glioma (target domain).Specifically, we add a domain classifier connected with a gradient reversallayer (GRL) to a backbone nnU-Net. Once the classifier reaches a very highaccuracy, the GRL is activated with the goal of transferring domain-invariantfeatures from the classifier to the segmentation model while preservingsegmentation accuracy on the source domain. The accuracy of the classifierslowly degrades to chance levels. No annotations are used in the target domain.The method is compared to 8 different supervised models using BraTS-Adultglioma (N=1251) and BraTS-PED glioma data (N=99). The proposed method showsnotable performance enhancements in the tumor core (TC) region compared to themodel that only uses adult data: ~32% better Dice scores and ~20 better 95thpercentile Hausdorff distances. Moreover, our unsupervised approach shows nostatistically significant difference compared to the practical upper boundmodel using manual annotations from both datasets in TC region. The code isshared at https://github.com/Fjr9516/DA_nnUNet.</description><author>Jingru Fu, Simone Bendazzoli, Örjan Smedby, Rodrigo Moreno</author><pubDate>Mon, 24 Jun 2024 18:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16848v1</guid></item><item><title>Improving physics-informed DeepONets with hard constraints</title><link>http://arxiv.org/abs/2309.07899v2</link><description>Current physics-informed (standard or deep operator) neural networks stillrely on accurately learning the initial and/or boundary conditions of thesystem of differential equations they are solving. In contrast, standardnumerical methods involve such conditions in computations without needing tolearn them. In this study, we propose to improve current physics-informed deeplearning strategies such that initial and/or boundary conditions do not need tobe learned and are represented exactly in the predicted solution. Moreover,this method guarantees that when a deep operator network is applied multipletimes to time-step a solution of an initial value problem, the resultingfunction is at least continuous.</description><author>Rüdiger Brecht, Dmytro R. Popovych, Alex Bihlo, Roman O. Popovych</author><pubDate>Mon, 24 Jun 2024 18:54:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.07899v2</guid></item><item><title>Data Debiasing with Datamodels (D3M): Improving Subgroup Robustness via Data Selection</title><link>http://arxiv.org/abs/2406.16846v1</link><description>Machine learning models can fail on subgroups that are underrepresentedduring training. While techniques such as dataset balancing can improveperformance on underperforming groups, they require access to training groupannotations and can end up removing large portions of the dataset. In thispaper, we introduce Data Debiasing with Datamodels (D3M), a debiasing approachwhich isolates and removes specific training examples that drive the model'sfailures on minority groups. Our approach enables us to efficiently traindebiased classifiers while removing only a small number of examples, and doesnot require training group annotations or additional hyperparameter tuning.</description><author>Saachi Jain, Kimia Hamidieh, Kristian Georgiev, Andrew Ilyas, Marzyeh Ghassemi, Aleksander Madry</author><pubDate>Mon, 24 Jun 2024 18:51:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16846v1</guid></item><item><title>Single-image camera calibration with model-free distortion correction</title><link>http://arxiv.org/abs/2403.01263v2</link><description>Camera calibration is a process of paramount importance in computer visionapplications that require accurate quantitative measurements. The popularmethod developed by Zhang relies on the use of a large number of images of aplanar grid of fiducial points captured in multiple poses. Although flexibleand easy to implement, Zhang's method has some limitations. The simultaneousoptimization of the entire parameter set, including the coefficients of apredefined distortion model, may result in poor distortion correction at theimage boundaries or in miscalculation of the intrinsic parameters, even with areasonably small reprojection error. Indeed, applications involving imagestitching (e.g. multi-camera systems) require accurate mapping of distortion upto the outermost regions of the image. Moreover, intrinsic parameters affectthe accuracy of camera pose estimation, which is fundamental for applicationssuch as vision servoing in robot navigation and automated assembly. This paperproposes a method for estimating the complete set of calibration parametersfrom a single image of a planar speckle pattern covering the entire sensor. Thecorrespondence between image points and physical points on the calibrationtarget is obtained using Digital Image Correlation. The effective focal lengthand the extrinsic parameters are calculated separately after a prior evaluationof the principal point. At the end of the procedure, a dense and uniformmodel-free distortion map is obtained over the entire image. Synthetic datawith different noise levels were used to test the feasibility of the proposedmethod and to compare its metrological performance with Zhang's method.Real-world tests demonstrate the potential of the developed method to revealaspects of the image formation that are hidden by averaging over multipleimages.</description><author>Katia Genovese</author><pubDate>Mon, 24 Jun 2024 18:49:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01263v2</guid></item><item><title>RaTEScore: A Metric for Radiology Report Generation</title><link>http://arxiv.org/abs/2406.16845v1</link><description>This paper introduces a novel, entity-aware metric, termed as RadiologicalReport (Text) Evaluation (RaTEScore), to assess the quality of medical reportsgenerated by AI models. RaTEScore emphasizes crucial medical entities such asdiagnostic outcomes and anatomical details, and is robust against complexmedical synonyms and sensitive to negation expressions. Technically, wedeveloped a comprehensive medical NER dataset, RaTE-NER, and trained an NERmodel specifically for this purpose. This model enables the decomposition ofcomplex radiological reports into constituent medical entities. The metricitself is derived by comparing the similarity of entity embeddings, obtainedfrom a language model, based on their types and relevance to clinicalsignificance. Our evaluations demonstrate that RaTEScore aligns more closelywith human preference than existing metrics, validated both on establishedpublic benchmarks and our newly proposed RaTE-Eval benchmark.</description><author>Weike Zhao, Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie</author><pubDate>Mon, 24 Jun 2024 18:49:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16845v1</guid></item><item><title>Exploring Factual Entailment with NLI: A News Media Study</title><link>http://arxiv.org/abs/2406.16842v1</link><description>We explore the relationship between factuality and Natural Language Inference(NLI) by introducing FactRel -- a novel annotation scheme that models\textit{factual} rather than \textit{textual} entailment, and use it toannotate a dataset of naturally occurring sentences from news articles. Ouranalysis shows that 84\% of factually supporting pairs and 63\% of factuallyundermining pairs do not amount to NLI entailment or contradiction,respectively, suggesting that factual relationships are more apt for analyzingmedia discourse. We experiment with models for pairwise classification on thenew dataset, and find that in some cases, generating synthetic data with GPT-4on the basis of the annotated dataset can improve performance. Surprisingly,few-shot learning with GPT-4 yields strong results on par with medium LMs(DeBERTa) trained on the labelled dataset. We hypothesize that these resultsindicate the fundamental dependence of this task on both world knowledge andadvanced reasoning abilities.</description><author>Guy Mor-Lan, Effi Levi</author><pubDate>Mon, 24 Jun 2024 18:47:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16842v1</guid></item><item><title>Scaling and renormalization in high-dimensional regression</title><link>http://arxiv.org/abs/2405.00592v2</link><description>This paper presents a succinct derivation of the training and generalizationperformance of a variety of high-dimensional ridge regression models using thebasic tools of random matrix theory and free probability. We provide anintroduction and review of recent results on these topics, aimed at readerswith backgrounds in physics and deep learning. Analytic formulas for thetraining and generalization errors are obtained in a few lines of algebradirectly from the properties of the $S$-transform of free probability. Thisallows for a straightforward identification of the sources of power-law scalingin model performance. We compute the generalization error of a broad class ofrandom feature models. We find that in all models, the $S$-transformcorresponds to the train-test generalization gap, and yields an analogue of thegeneralized-cross-validation estimator. Using these techniques, we derivefine-grained bias-variance decompositions for a very general class of randomfeature models with structured covariates. These novel results allow us todiscover a scaling regime for random feature models where the variance due tothe features limits performance in the overparameterized setting. We alsodemonstrate how anisotropic weight structure in random feature models can limitperformance and lead to nontrivial exponents for finite-width corrections inthe overparameterized setting. Our results extend and provide a unifyingperspective on earlier models of neural scaling laws.</description><author>Alexander Atanasov, Jacob A. Zavatone-Veth, Cengiz Pehlevan</author><pubDate>Mon, 24 Jun 2024 18:47:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00592v2</guid></item><item><title>From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models</title><link>http://arxiv.org/abs/2406.16838v1</link><description>One of the most striking findings in modern research on large language models(LLMs) is that scaling up compute during training leads to better results.However, less attention has been given to the benefits of scaling computeduring inference. This survey focuses on these inference-time approaches. Weexplore three areas under a unified mathematical formalism: token-levelgeneration algorithms, meta-generation algorithms, and efficient generation.Token-level generation algorithms, often called decoding algorithms, operate bysampling a single token at a time or constructing a token-level search spaceand then selecting an output. These methods typically assume access to alanguage model's logits, next-token distributions, or probability scores.Meta-generation algorithms work on partial or full sequences, incorporatingdomain knowledge, enabling backtracking, and integrating external information.Efficient generation methods aim to reduce token costs and improve the speed ofgeneration. Our survey unifies perspectives from three research communities:traditional natural language processing, modern LLMs, and machine learningsystems.</description><author>Sean Welleck, Amanda Bertsch, Matthew Finlayson, Hailey Schoelkopf, Alex Xie, Graham Neubig, Ilia Kulikov, Zaid Harchaoui</author><pubDate>Mon, 24 Jun 2024 18:45:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16838v1</guid></item><item><title>Concentration Inequalities for $(f,Γ)$-GANs</title><link>http://arxiv.org/abs/2406.16834v1</link><description>Generative adversarial networks (GANs) are unsupervised learning methods fortraining a generator distribution to produce samples that approximate thosedrawn from a target distribution. Many such methods can be formulated asminimization of a metric or divergence. Recent works have proven thestatistical consistency of GANs that are based on integral probability metrics(IPMs), e.g., WGAN which is based on the 1-Wasserstein metric. IPMs are definedby optimizing a linear functional (difference of expectations) over a space ofdiscriminators. A much larger class of GANs, which allow for the use ofnonlinear objective functionals, can be constructed using$(f,\Gamma)$-divergences; these generalize and interpolate between IPMs and$f$-divergences (e.g., KL or $\alpha$-divergences). Instances of$(f,\Gamma)$-GANs have been shown to exhibit improved performance in a numberof applications. In this work we study the statistical consistency of$(f,\Gamma)$-GANs for general $f$ and $\Gamma$. Specifically, we derivefinite-sample concentration inequalities. These derivations require novelarguments due to nonlinearity of the objective functional. We demonstrate thatour new results reduce to the known results for IPM-GANs in the appropriatelimit while also significantly extending the domain of applicability of thistheory.</description><author>Jeremiah Birrell</author><pubDate>Mon, 24 Jun 2024 18:42:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16834v1</guid></item><item><title>USDC: A Dataset of $\underline{U}$ser $\underline{S}$tance and $\underline{D}$ogmatism in Long $\underline{C}$onversations</title><link>http://arxiv.org/abs/2406.16833v1</link><description>Identifying user's opinions and stances in long conversation threads onvarious topics can be extremely critical for enhanced personalization, marketresearch, political campaigns, customer service, conflict resolution, targetedadvertising, and content moderation. Hence, training language models toautomate this task is critical. However, to train such models, gathering manualannotations has multiple challenges: 1) It is time-consuming and costly; 2)Conversation threads could be very long, increasing chances of noisyannotations; and 3) Interpreting instances where a user changes their opinionwithin a conversation is difficult because often such transitions are subtleand not expressed explicitly. Inspired by the recent success of large languagemodels (LLMs) for complex natural language processing (NLP) tasks, we leverageMistral Large and GPT-4 to automate the human annotation process on thefollowing two tasks while also providing reasoning: i) User Stanceclassification, which involves labeling a user's stance of a post in aconversation on a five-point scale; ii) User Dogmatism classification, whichdeals with labeling a user's overall opinion in the conversation on afour-point scale. The majority voting on zero-shot, one-shot, and few-shotannotations from these two LLMs on 764 multi-user Reddit conversations helps uscurate the USDC dataset. USDC is then used to finetune and instruction-tunemultiple deployable small language models for the 5-class stance and 4-classdogmatism classification tasks. We make the code and dataset publicly available[https://anonymous.4open.science/r/USDC-0F7F].</description><author>Mounika Marreddy, Subba Reddy Oota, Venkata Charan Chinni, Manish Gupta, Lucie Flek</author><pubDate>Mon, 24 Jun 2024 18:41:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16833v1</guid></item><item><title>Understanding and Mitigating Tokenization Bias in Language Models</title><link>http://arxiv.org/abs/2406.16829v1</link><description>State-of-the-art language models are autoregressive and operate on subwordunits known as tokens. Specifically, one must encode the conditioning stringinto a list of tokens before passing to the language models for next-tokenprediction. We show that, for encoding schemes such as maximum prefix matching,tokenization induces a sampling bias that cannot be mitigated with moretraining or data. To counter this universal problem, we propose a novelalgorithm to obtain unbiased estimates from a model that was trained ontokenized data. Our method does not require finetuning the model, and itscomplexity, defined as the number of model runs, scales linearly with thesequence length. As a consequence, we show that one can simulate token-freebehavior from a tokenized language model. We empirically verify the correctnessof our method through a Markov-chain setup, where it accurately recovers thetransition probabilities, as opposed to the conventional method of directlyprompting tokens into the language model.</description><author>Buu Phan, Marton Havasi, Matthew Muckley, Karen Ullrich</author><pubDate>Mon, 24 Jun 2024 18:38:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16829v1</guid></item><item><title>Ragnarök: A Reusable RAG Framework and Baselines for TREC 2024 Retrieval-Augmented Generation Track</title><link>http://arxiv.org/abs/2406.16828v1</link><description>Did you try out the new Bing Search? Or maybe you fiddled around with GoogleAI~Overviews? These might sound familiar because the modern-day search stackhas recently evolved to include retrieval-augmented generation (RAG) systems.They allow searching and incorporating real-time data into large languagemodels (LLMs) to provide a well-informed, attributed, concise summary incontrast to the traditional search paradigm that relies on displaying a rankedlist of documents. Therefore, given these recent advancements, it is crucial tohave an arena to build, test, visualize, and systematically evaluate RAG-basedsearch systems. With this in mind, we propose the TREC 2024 RAG Track to fosterinnovation in evaluating RAG systems. In our work, we lay out the steps we'vemade towards making this track a reality -- we describe the details of ourreusable framework, Ragnar\"ok, explain the curation of the new MS MARCO V2.1collection choice, release the development topics for the track, andstandardize the I/O definitions which assist the end user. Next, usingRagnar\"ok, we identify and provide key industrial baselines such as OpenAI'sGPT-4o or Cohere's Command R+. Further, we introduce a web-based user interfacefor an interactive arena allowing benchmarking pairwise RAG systems bycrowdsourcing. We open-source our Ragnar\"ok framework and baselines to achievea unified standard for future RAG systems.</description><author>Ronak Pradeep, Nandan Thakur, Sahel Sharifymoghaddam, Eric Zhang, Ryan Nguyen, Daniel Campos, Nick Craswell, Jimmy Lin</author><pubDate>Mon, 24 Jun 2024 18:37:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16828v1</guid></item><item><title>Reward Steering with Evolutionary Heuristics for Decoding-time Alignment</title><link>http://arxiv.org/abs/2406.15193v2</link><description>The widespread applicability and increasing omnipresence of LLMs haveinstigated a need to align LLM responses to user and stakeholder preferences.Many preference optimization approaches have been proposed that fine-tune LLMparameters to achieve good alignment. However, such parameter tuning is knownto interfere with model performance on many tasks. Moreover, keeping up withshifting user preferences is tricky in such a situation. Decoding-timealignment with reward model guidance solves these issues at the cost ofincreased inference time. However, most of such methods fail to strike theright balance between exploration and exploitation of reward -- often due tothe conflated formulation of these two aspects - to give well-alignedresponses. To remedy this we decouple these two aspects and implement them inan evolutionary fashion: exploration is enforced by decoding from mutatedinstructions and exploitation is represented as the periodic replacement ofpoorly-rewarded generations with well-rewarded ones. Empirical evidencesindicate that this strategy outperforms many preference optimization anddecode-time alignment approaches on two widely accepted alignment benchmarksAlpacaEval 2 and MT-Bench. Our implementation will be available at:https://darwin-alignment.github.io.</description><author>Chia-Yu Hung, Navonil Majumder, Ambuj Mehrish, Soujanya Poria</author><pubDate>Mon, 24 Jun 2024 18:36:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15193v2</guid></item><item><title>General Binding Affinity Guidance for Diffusion Models in Structure-Based Drug Design</title><link>http://arxiv.org/abs/2406.16821v1</link><description>Structure-Based Drug Design (SBDD) focuses on generating valid ligands thatstrongly and specifically bind to a designated protein pocket. Several methodsuse machine learning for SBDD to generate these ligands in 3D space,conditioned on the structure of a desired protein pocket. Recently, diffusionmodels have shown success here by modeling the underlying distributions ofatomic positions and types. While these methods are effective in consideringthe structural details of the protein pocket, they often fail to explicitlyconsider the binding affinity. Binding affinity characterizes how tightly theligand binds to the protein pocket, and is measured by the change in freeenergy associated with the binding process. It is one of the most crucialmetrics for benchmarking the effectiveness of the interaction between a ligandand protein pocket. To address this, we propose BADGER: Binding AffinityDiffusion Guidance with Enhanced Refinement. BADGER is a general guidancemethod to steer the diffusion sampling process towards improved protein-ligandbinding, allowing us to adjust the distribution of the binding affinity betweenligands and proteins. Our method is enabled by using a neural network (NN) tomodel the energy function, which is commonly approximated by AutoDock Vina(ADV). ADV's energy function is non-differentiable, and estimates the affinitybased on the interactions between a ligand and target protein receptor. Byusing a NN as a differentiable energy function proxy, we utilize the gradientof our learned energy function as a guidance method on top of any traineddiffusion model. We show that our method improves the binding affinity ofgenerated ligands to their protein receptors by up to 60\%, significantlysurpassing previous machine learning methods. We also show that our guidancemethod is flexible and can be easily applied to other diffusion-based SBDDframeworks.</description><author>Yue Jian, Curtis Wu, Danny Reidenbach, Aditi S. Krishnapriyan</author><pubDate>Mon, 24 Jun 2024 18:31:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16821v1</guid></item><item><title>GPT-4V Explorations: Mining Autonomous Driving</title><link>http://arxiv.org/abs/2406.16817v1</link><description>This paper explores the application of the GPT-4V(ision) large visuallanguage model to autonomous driving in mining environments, where traditionalsystems often falter in understanding intentions and making accurate decisionsduring emergencies. GPT-4V introduces capabilities for visual questionanswering and complex scene comprehension, addressing challenges in thesespecialized settings.Our evaluation focuses on its proficiency in sceneunderstanding, reasoning, and driving functions, with specific tests on itsability to recognize and interpret elements such as pedestrians, variousvehicles, and traffic devices. While GPT-4V showed robust comprehension anddecision-making skills, it faced difficulties in accurately identifyingspecific vehicle types and managing dynamic interactions. Despite thesechallenges, its effective navigation and strategic decision-making demonstrateits potential as a reliable agent for autonomous driving in the complexconditions of mining environments, highlighting its adaptability andoperational viability in industrial settings.</description><author>Zixuan Li</author><pubDate>Mon, 24 Jun 2024 18:26:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16817v1</guid></item><item><title>ClotheDreamer: Text-Guided Garment Generation with 3D Gaussians</title><link>http://arxiv.org/abs/2406.16815v1</link><description>High-fidelity 3D garment synthesis from text is desirable yet challenging fordigital avatar creation. Recent diffusion-based approaches via ScoreDistillation Sampling (SDS) have enabled new possibilities but eitherintricately couple with human body or struggle to reuse. We introduceClotheDreamer, a 3D Gaussian-based method for generating wearable,production-ready 3D garment assets from text prompts. We propose a novelrepresentation Disentangled Clothe Gaussian Splatting (DCGS) to enable separateoptimization. DCGS represents clothed avatar as one Gaussian model but freezesbody Gaussian splats. To enhance quality and completeness, we incorporatebidirectional SDS to supervise clothed avatar and garment RGBD renderingsrespectively with pose conditions and propose a new pruning strategy for looseclothing. Our approach can also support custom clothing templates as input.Benefiting from our design, the synthetic 3D garment can be easily applied tovirtual try-on and support physically accurate animation. Extensive experimentsshowcase our method's superior and competitive performance. Our project page isat https://ggxxii.github.io/clothedreamer.</description><author>Yufei Liu, Junshu Tang, Chu Zheng, Shijie Zhang, Jinkun Hao, Junwei Zhu, Dongjin Huang</author><pubDate>Mon, 24 Jun 2024 18:25:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16815v1</guid></item><item><title>PISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs</title><link>http://arxiv.org/abs/2406.16810v1</link><description>Recently, machine unlearning, which seeks to erase specific data stored inthe pre-trained or fine-tuned models, has emerged as a crucial protectivemeasure for LLMs. However, unlearning approaches for LLMs that have beenconsidered thus far have focused on the removal of independent data points andhave not taken into account that the stored facts are logically connected toone another and form an implicit knowledge graph. To facilitate the developmentof structural unlearning methods, which are essential for the practicalapplication of unlearning, we propose PISTOL, a pipeline for compilingmulti-scenario datasets for benchmarking structural LLM unlearning.Additionally, leveraging sample datasets synthesized using PISTOL, we conductedbenchmarks with four distinct unlearning methods on both Llama2-7B andMistral-7B models. This analysis helps to illustrate the prevailing challengesin effectively and robustly removing highly inter-connected data, batched data,or data skewed towards a specific domain. It also highlights the choice ofpre-trained model can impact unlearning performance. This work not onlyadvances our understandings on the limitation of current LLMs unlearningmethods and proposes future research directions, but also provides a replicableframework for ongoing exploration and validation in the field.</description><author>Xinchi Qiu, William F. Shen, Yihong Chen, Nicola Cancedda, Pontus Stenetorp, Nicholas D. Lane</author><pubDate>Mon, 24 Jun 2024 18:22:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16810v1</guid></item><item><title>Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback for Text-to-Image Generation</title><link>http://arxiv.org/abs/2406.16807v1</link><description>Human feedback plays a critical role in learning and refining reward modelsfor text-to-image generation, but the optimal form the feedback should take forlearning an accurate reward function has not been conclusively established.This paper investigates the effectiveness of fine-grained feedback whichcaptures nuanced distinctions in image quality and prompt-alignment, comparedto traditional coarse-grained feedback (for example, thumbs up/down or rankingbetween a set of options). While fine-grained feedback holds promise,particularly for systems catering to diverse societal preferences, we show thatdemonstrating its superiority to coarse-grained feedback is not automatic.Through experiments on real and synthetic preference data, we surface thecomplexities of building effective models due to the interplay of model choice,feedback type, and the alignment between human judgment and computationalinterpretation. We identify key challenges in eliciting and utilizingfine-grained feedback, prompting a reassessment of its assumed benefits andpracticality. Our findings -- e.g., that fine-grained feedback can lead toworse models for a fixed budget, in some settings; however, in controlledsettings with known attributes, fine grained rewards can indeed be more helpful-- call for careful consideration of feedback attributes and potentially beckonnovel modeling approaches to appropriately unlock the potential value offine-grained feedback in-the-wild.</description><author>Katherine M. Collins, Najoung Kim, Yonatan Bitton, Verena Rieser, Shayegan Omidshafiei, Yushi Hu, Sherol Chen, Senjuti Dutta, Minsuk Chang, Kimin Lee, Youwei Liang, Georgina Evans, Sahil Singla, Gang Li, Adrian Weller, Junfeng He, Deepak Ramachandran, Krishnamurthy Dj Dvijotham</author><pubDate>Mon, 24 Jun 2024 18:19:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16807v1</guid></item><item><title>Improved Regret Bounds for Bandits with Expert Advice</title><link>http://arxiv.org/abs/2406.16802v1</link><description>In this research note, we revisit the bandits with expert advice problem.Under a restricted feedback model, we prove a lower bound of order $\sqrt{K T\ln(N/K)}$ for the worst-case regret, where $K$ is the number of actions, $N&gt;K$the number of experts, and $T$ the time horizon. This matches a previouslyknown upper bound of the same order and improves upon the best available lowerbound of $\sqrt{K T (\ln N) / (\ln K)}$. For the standard feedback model, weprove a new instance-based upper bound that depends on the agreement betweenthe experts and provides a logarithmic improvement compared to prior results.</description><author>Nicolò Cesa-Bianchi, Khaled Eldowa, Emmanuel Esposito, Julia Olkhovskaya</author><pubDate>Mon, 24 Jun 2024 18:14:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16802v1</guid></item><item><title>RES-Q: Evaluating Code-Editing Large Language Model Systems at the Repository Scale</title><link>http://arxiv.org/abs/2406.16801v1</link><description>The instruction-following ability of Large Language Models (LLMs) hascultivated a class of LLM-based systems capable of approaching complex taskssuch as making edits to large code repositories. Due to the high sensitivityand unpredictability of LLM behavior in response to changes in prompting,robust evaluation tools are needed to drive future iteration of these systems.We propose RES-Q, a natural language instruction-based benchmark for evaluating$\textbf{R}$epository $\textbf{E}$diting $\textbf{S}$ystems, which consists of100 repository editing tasks derived from real GitHub commits. Given an editinstruction and a code repository, RES-Q evaluates an LLM system's ability togather information and construct an edit that satisfies the criteria set by theinstruction. We argue that evaluating LLMs in this way addresses issues withtraditional benchmarks and provides a more holistic assessment of a model'sabilities. We evaluate various state-of-the-art LLMs as language agents in arepository-editing system built on Qurrent OS, our language agent developmentsoftware. Despite their 1% pass@1 performance difference on HumanEval, we findClaude Sonnet 3.5 outperforms GPT-4o by 12% pass@1 on RES-Q, indicating RES-Q'scapacity to differentiate model capability as traditional benchmarks approachsaturation. We further investigate token efficiency, performance relationshipswith existing benchmarks, and interesting disparities between closed andopen-source LLMs. Code and dataset are available athttps://github.com/Qurrent-AI/RES-Q.</description><author>Beck LaBash, August Rosedale, Alex Reents, Colin Wiel</author><pubDate>Mon, 24 Jun 2024 18:08:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16801v1</guid></item><item><title>Generative Fractional Diffusion Models</title><link>http://arxiv.org/abs/2310.17638v2</link><description>We introduce the first continuous-time score-based generative model thatleverages fractional diffusion processes for its underlying dynamics. Althoughdiffusion models have excelled at capturing data distributions, they stillsuffer from various limitations such as slow convergence, mode-collapse onimbalanced data, and lack of diversity. These issues are partially linked tothe use of light-tailed Brownian motion (BM) with independent increments. Inthis paper, we replace BM with an approximation of its non-Markoviancounterpart, fractional Brownian motion (fBM), characterized by correlatedincrements and Hurst index $H \in (0,1)$, where $H=1/2$ recovers the classicalBM. To ensure tractable inference and learning, we employ a recentlypopularized Markov approximation of fBM (MA-fBM) and derive its reverse timemodel, resulting in generative fractional diffusion models (GFDMs). Wecharacterize the forward dynamics using a continuous reparameterization trickand propose an augmented score matching loss to efficiently learn thescore-function, which is partly known in closed form, at minimal added cost.The ability to drive our diffusion model via fBM provides flexibility andcontrol. $H \leq 1/2$ enters the regime of rough paths whereas $H&gt;1/2$regularizes diffusion paths and invokes long-term memory as well as aheavy-tailed behaviour (super-diffusion). The Markov approximation allows addedcontrol by varying the number of Markov processes linearly combined toapproximate fBM. Our evaluations on real image datasets demonstrate that GFDMachieves greater pixel-wise diversity and enhanced image quality, as indicatedby a lower FID, offering a promising alternative to traditional diffusionmodels.</description><author>Gabriel Nobis, Maximilian Springenberg, Marco Aversa, Michael Detzel, Rembert Daems, Roderick Murray-Smith, Shinichi Nakajima, Sebastian Lapuschkin, Stefano Ermon, Tolga Birdal, Manfred Opper, Christoph Knochenhauer, Luis Oala, Wojciech Samek</author><pubDate>Mon, 24 Jun 2024 18:00:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17638v2</guid></item><item><title>Low-Resource Multi-Granularity Academic Function Recognition Based on Multiple Prompt Knowledge</title><link>http://arxiv.org/abs/2305.03287v2</link><description>Fine-tuning pre-trained language models (PLMs), e.g., SciBERT, generallyrequires large numbers of annotated data to achieve state-of-the-artperformance on a range of NLP tasks in the scientific domain. However,obtaining the fine-tune data for scientific NLP task is still challenging andexpensive. Inspired by recent advancement in prompt learning, in this paper, wepropose the Mix Prompt Tuning (MPT), which is a semi-supervised method toalleviate the dependence on annotated data and improve the performance ofmulti-granularity academic function recognition tasks with a small number oflabeled examples. Specifically, the proposed method provides multi-perspectiverepresentations by combining manual prompt templates with automatically learnedcontinuous prompt templates to help the given academic function recognitiontask take full advantage of knowledge in PLMs. Based on these prompt templatesand the fine-tuned PLM, a large number of pseudo labels are assigned to theunlabeled examples. Finally, we fine-tune the PLM using the pseudo trainingset. We evaluate our method on three academic function recognition tasks ofdifferent granularity including the citation function, the abstract sentencefunction, and the keyword function, with datasets from computer science domainand biomedical domain. Extensive experiments demonstrate the effectiveness ofour method and statistically significant improvements against strong baselines.In particular, it achieves an average increase of 5% in Macro-F1 score comparedwith fine-tuning, and 6% in Macro-F1 score compared with other semi-supervisedmethod under low-resource settings. In addition, MPT is a general method thatcan be easily applied to other low-resource scientific classification tasks.</description><author>Jiawei Liu, Zi Xiong, Yi Jiang, Yongqiang Ma, Wei Lu, Yong Huang, Qikai Cheng</author><pubDate>Mon, 24 Jun 2024 18:00:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03287v2</guid></item><item><title>Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs</title><link>http://arxiv.org/abs/2406.16797v1</link><description>Existing methods for adapting large language models (LLMs) to new tasks arenot suited to multi-task adaptation because they modify all the model weights-- causing destructive interference between tasks. The resulting effects, suchas catastrophic forgetting of earlier tasks, make it challenging to obtain goodperformance on multiple tasks at the same time. To mitigate this, we proposeLottery Ticket Adaptation (LoTA), a sparse adaptation method that identifiesand optimizes only a sparse subnetwork of the model. We evaluate LoTA on a widerange of challenging tasks such as instruction following, reasoning, math, andsummarization. LoTA obtains better performance than full fine-tuning andlow-rank adaptation (LoRA), and maintains good performance even after trainingon other tasks -- thus, avoiding catastrophic forgetting. By extracting andfine-tuning over \emph{lottery tickets} (or \emph{sparse task vectors}), LoTAalso enables model merging over highly dissimilar tasks.</description><author>Ashwinee Panda, Berivan Isik, Xiangyu Qi, Sanmi Koyejo, Tsachy Weissman, Prateek Mittal</author><pubDate>Mon, 24 Jun 2024 17:58:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16797v1</guid></item><item><title>Adam-mini: Use Fewer Learning Rates To Gain More</title><link>http://arxiv.org/abs/2406.16793v1</link><description>We propose Adam-mini, an optimizer that achieves on-par or better performancethan AdamW with 45% to 50% less memory footprint. Adam-mini reduces memory bycutting down the number of learning rates in Adam: Instead of assigning anindividual learning rate for each parameter using $1/\sqrt{v}$, Adam-mini usesthe average of $v$ within a pre-defined parameter block as the learning ratefor that block. Such a design is inspired by two empirical findings. First, theHessian of Transformers exhibits a near-block diagonal structure with differentsizes of dense sub-blocks. Second, for each of these dense sub-blocks, thereexists a single high-quality learning rate that can outperform Adam, providedthat sufficient resources are available to search it out. Adam-mini providesone cost-effective way to find these good learning rates and manage to cut down$\geq 90% v$ in Adam. Empirically, we verify that Adam-mini performs on par orbetter than AdamW on various language models sized from 125M to 7B forpre-training, supervised fine-tuning, and RLHF. The reduced memory footprint ofAdam-mini also alleviates communication overheads among GPUs and CPUs, therebyincreasing throughput. For instance, Adam-mini achieves 49.6% higher throughputthan AdamW when pre-training Llama2-7B on 2x A800-80GB GPUs, which saves 33%wall-clock time for pre-training.</description><author>Yushun Zhang, Congliang Chen, Ziniu Li, Tian Ding, Chenwei Wu, Yinyu Ye, Zhi-Quan Luo, Ruoyu Sun</author><pubDate>Mon, 24 Jun 2024 17:56:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16793v1</guid></item><item><title>Enabling more efficient and cost-effective AI/ML systems with Collective Mind, virtualized MLOps, MLPerf, Collective Knowledge Playground and reproducible optimization tournaments</title><link>http://arxiv.org/abs/2406.16791v1</link><description>In this white paper, I present my community effort to automatically co-designcheaper, faster and more energy-efficient software and hardware for AI, ML andother popular workloads with the help of the Collective Mind framework (CM),virtualized MLOps, MLPerf benchmarks and reproducible optimization tournaments.I developed CM to modularize, automate and virtualize the tedious process ofbuilding, running, profiling and optimizing complex applications across rapidlyevolving open-source and proprietary AI/ML models, datasets, software andhardware. I achieved that with the help of portable, reusable andtechnology-agnostic automation recipes (ResearchOps) for MLOps and DevOps(CM4MLOps) discovered in close collaboration with academia and industry whenreproducing more than 150 research papers and organizing the 1st mass-scalecommunity benchmarking of ML and AI systems using CM and MLPerf. I donated CM and CM4MLOps to MLCommons to help connect academia and industryto learn how to build and run AI and other emerging workloads in the mostefficient and cost-effective way using a common and technology-agnosticautomation, virtualization and reproducibility framework while unifyingknowledge exchange, protecting everyone's intellectual property, enablingportable skills, and accelerating transfer of the state-of-the-art research toproduction. My long-term vision is to make AI accessible to everyone by makingit a commodity automatically produced from the most suitable open-source andproprietary components from different vendors based on user demand,requirements and constraints such as cost, latency, throughput, accuracy,energy, size and other important characteristics.</description><author>Grigori Fursin</author><pubDate>Mon, 24 Jun 2024 17:55:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16791v1</guid></item><item><title>The Progression of Transformers from Language to Vision to MOT: A Literature Review on Multi-Object Tracking with Transformers</title><link>http://arxiv.org/abs/2406.16784v1</link><description>The transformer neural network architecture allows for autoregressivesequence-to-sequence modeling through the use of attention layers. It wasoriginally created with the application of machine translation but hasrevolutionized natural language processing. Recently, transformers have alsobeen applied across a wide variety of pattern recognition tasks, particularlyin computer vision. In this literature review, we describe major advances incomputer vision utilizing transformers. We then focus specifically onMulti-Object Tracking (MOT) and discuss how transformers are increasinglybecoming competitive in state-of-the-art MOT works, yet still lag behindtraditional deep learning methods.</description><author>Abhi Kamboj</author><pubDate>Mon, 24 Jun 2024 17:45:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16784v1</guid></item><item><title>M2Lingual: Enhancing Multilingual, Multi-Turn Instruction Alignment in Large Language Models</title><link>http://arxiv.org/abs/2406.16783v1</link><description>Instruction finetuning (IFT) is critical for aligning Large Language Models(LLMs) to follow instructions. Numerous effective IFT datasets have beenproposed in the recent past, but most focus on high resource languages such asEnglish. In this work, we propose a fully synthetic, novel taxonomy (Evol)guided Multilingual, Multi-turn instruction finetuning dataset, calledM2Lingual, to better align LLMs on a diverse set of languages and tasks.M2Lingual contains a total of 182K IFT pairs that are built upon diverse seeds,covering 70 languages, 17 NLP tasks and general instruction-response pairs.LLMs finetuned with M2Lingual substantially outperform the majority of existingmultilingual IFT datasets. Importantly, LLMs trained with M2Lingualconsistently achieve competitive results across a wide variety of evaluationbenchmarks compared to existing multilingual IFT datasets. Specifically, LLMsfinetuned with M2Lingual achieve strong performance on our translatedmultilingual, multi-turn evaluation benchmark as well as a wide variety ofmultilingual tasks. Thus we contribute, and the 2 step Evol taxonomy used forits creation. M2Lingual repository -https://huggingface.co/datasets/ServiceNow-AI/M2Lingual</description><author>Rishabh Maheshwary, Vikas Yadav, Hoang Nguyen, Khyati Mahajan, Sathwik Tejaswi Madhusudhan</author><pubDate>Mon, 24 Jun 2024 17:45:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16783v1</guid></item><item><title>Confidence Aware Inverse Constrained Reinforcement Learning</title><link>http://arxiv.org/abs/2406.16782v1</link><description>In coming up with solutions to real-world problems, humans implicitly adhereto constraints that are too numerous and complex to be specified completely.However, reinforcement learning (RL) agents need these constraints to learn thecorrect optimal policy in these settings. The field of Inverse ConstraintReinforcement Learning (ICRL) deals with this problem and provides algorithmsthat aim to estimate the constraints from expert demonstrations collectedoffline. Practitioners prefer to know a measure of confidence in the estimatedconstraints, before deciding to use these constraints, which allows them toonly use the constraints that satisfy a desired level of confidence. However,prior works do not allow users to provide the desired level of confidence forthe inferred constraints. This work provides a principled ICRL method that cantake a confidence level with a set of expert demonstrations and outputs aconstraint that is at least as constraining as the true underlying constraintwith the desired level of confidence. Further, unlike previous methods, thismethod allows a user to know if the number of expert trajectories isinsufficient to learn a constraint with a desired level of confidence, andtherefore collect more expert trajectories as required to simultaneously learnconstraints with the desired level of confidence and a policy that achieves thedesired level of performance.</description><author>Sriram Ganapathi Subramanian, Guiliang Liu, Mohammed Elmahgiubi, Kasra Rezaee, Pascal Poupart</author><pubDate>Mon, 24 Jun 2024 17:44:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16782v1</guid></item><item><title>It Is Not About What You Say, It Is About How You Say It: A Surprisingly Simple Approach for Improving Reading Comprehension</title><link>http://arxiv.org/abs/2406.16779v1</link><description>Natural language processing has seen rapid progress over the past decade. Dueto the speed of developments, some practices get established without properevaluation. Considering one such case and focusing on reading comprehension, weask our first research question: 1) How does the order of inputs -- i.e.,question and context -- affect model performance? Additionally, given recentadvancements in input emphasis, we ask a second research question: 2) Doesemphasizing either the question, the context, or both enhance performance?Experimenting with 9 large language models across 3 datasets, we find thatpresenting the context before the question improves model performance, with anaccuracy increase of up to $31\%$. Furthermore, emphasizing the context yieldssuperior results compared to question emphasis, and in general, emphasizingparts of the input is particularly effective for addressing questions thatmodels lack the parametric knowledge to answer. Experimenting with bothprompt-based and attention-based emphasis methods, we additionally find thatthe best method is surprisingly simple: it only requires concatenating a fewtokens to the input and results in an accuracy improvement of up to $36\%$,allowing smaller models to outperform their significantly larger counterparts.</description><author>Sagi Shaier, Lawrence E Hunter, Katharina von der Wense</author><pubDate>Mon, 24 Jun 2024 17:43:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16779v1</guid></item><item><title>Why Transformers Need Adam: A Hessian Perspective</title><link>http://arxiv.org/abs/2402.16788v3</link><description>SGD performs worse than Adam by a significant margin on Transformers, but thereason remains unclear. In this work, we provide an explanation through thelens of Hessian: (i) Transformers are "heterogeneous": the Hessian spectrumacross parameter blocks vary dramatically, a phenomenon we call "blockheterogeneity"; (ii) Heterogeneity hampers SGD: SGD performs worse than Adam onproblems with block heterogeneity. To validate (i) and (ii), we check variousTransformers, CNNs, MLPs, and quadratic problems, and find that SGD can performon par with Adam on problems without block heterogeneity, but performs worsethan Adam when the heterogeneity exists. Our initial theoretical analysisindicates that SGD performs worse because it applies one single learning rateto all blocks, which cannot handle the heterogeneity among blocks. Thislimitation could be ameliorated if we use coordinate-wise learning rates, asdesigned in Adam.</description><author>Yushun Zhang, Congliang Chen, Tian Ding, Ziniu Li, Ruoyu Sun, Zhi-Quan Luo</author><pubDate>Mon, 24 Jun 2024 17:41:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16788v3</guid></item><item><title>Finding Transformer Circuits with Edge Pruning</title><link>http://arxiv.org/abs/2406.16778v1</link><description>The path to interpreting a language model often proceeds via analysis ofcircuits -- sparse computational subgraphs of the model that capture specificaspects of its behavior. Recent work has automated the task of discoveringcircuits. Yet, these methods have practical limitations, as they rely either oninefficient search algorithms or inaccurate approximations. In this paper, weframe automated circuit discovery as an optimization problem and propose *EdgePruning* as an effective and scalable solution. Edge Pruning leveragesgradient-based pruning techniques, but instead of removing neurons orcomponents, it prunes the \emph{edges} between components. Our method findscircuits in GPT-2 that use less than half the number of edges compared tocircuits found by previous methods while being equally faithful to the fullmodel predictions on standard circuit-finding tasks. Edge Pruning is efficienteven with as many as 100K examples, outperforming previous methods in speed andproducing substantially better circuits. It also perfectly recovers theground-truth circuits in two models compiled with Tracr. Thanks to itsefficiency, we scale Edge Pruning to CodeLlama-13B, a model over 100x the scalethat prior methods operate on. We use this setting for a case study comparingthe mechanisms behind instruction prompting and in-context learning. We findtwo circuits with more than 99.96% sparsity that match the performance of thefull model and reveal that the mechanisms in the two settings overlapsubstantially. Our case study shows that Edge Pruning is a practical andscalable tool for interpretability and sheds light on behaviors that onlyemerge in large models.</description><author>Adithya Bhaskar, Alexander Wettig, Dan Friedman, Danqi Chen</author><pubDate>Mon, 24 Jun 2024 17:40:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16778v1</guid></item><item><title>Blending LLMs into Cascaded Speech Translation: KIT's Offline Speech Translation System for IWSLT 2024</title><link>http://arxiv.org/abs/2406.16777v1</link><description>Large Language Models (LLMs) are currently under exploration for varioustasks, including Automatic Speech Recognition (ASR), Machine Translation (MT),and even End-to-End Speech Translation (ST). In this paper, we present KIT'soffline submission in the constrained + LLM track by incorporating recentlyproposed techniques that can be added to any cascaded speech translation.Specifically, we integrateMistral-7B\footnote{mistralai/Mistral-7B-Instruct-v0.1} into our system toenhance it in two ways. Firstly, we refine the ASR outputs by utilizing theN-best lists generated by our system and fine-tuning the LLM to predict thetranscript accurately. Secondly, we refine the MT outputs at the document levelby fine-tuning the LLM, leveraging both ASR and MT predictions to improvetranslation quality. We find that integrating the LLM into the ASR and MTsystems results in an absolute improvement of $0.3\%$ in Word Error Rate and$0.65\%$ in COMET for tst2019 test set. In challenging test sets withoverlapping speakers and background noise, we find that integrating LLM is notbeneficial due to poor ASR performance. Here, we use ASR with chunked long-formdecoding to improve context usage that may be unavailable when transcribingwith Voice Activity Detection segmentation alone.</description><author>Sai Koneru, Thai-Binh Nguyen, Ngoc-Quan Pham, Danni Liu, Zhaolin Li, Alexander Waibel, Jan Niehues</author><pubDate>Mon, 24 Jun 2024 17:38:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16777v1</guid></item><item><title>Instance Consistency Regularization for Semi-Supervised 3D Instance Segmentation</title><link>http://arxiv.org/abs/2406.16776v1</link><description>Large-scale datasets with point-wise semantic and instance labels are crucialto 3D instance segmentation but also expensive. To leverage unlabeled data,previous semi-supervised 3D instance segmentation approaches have exploredself-training frameworks, which rely on high-quality pseudo labels forconsistency regularization. They intuitively utilize both instance and semanticpseudo labels in a joint learning manner. However, semantic pseudo labelscontain numerous noise derived from the imbalanced category distribution andnatural confusion of similar but distinct categories, which leads to severecollapses in self-training. Motivated by the observation that 3D instances arenon-overlapping and spatially separable, we ask whether we can solely rely oninstance consistency regularization for improved semi-supervised segmentation.To this end, we propose a novel self-training network InsTeacher3D to exploreand exploit pure instance knowledge from unlabeled data. We first build aparallel base 3D instance segmentation model DKNet, which distinguishes eachinstance from the others via discriminative instance kernels without relianceon semantic segmentation. Based on DKNet, we further design a novel instanceconsistency regularization framework to generate and leverage high-qualityinstance pseudo labels. Experimental results on multiple large-scale datasetsshow that the InsTeacher3D significantly outperforms prior state-of-the-artsemi-supervised approaches. Code is available:https://github.com/W1zheng/InsTeacher3D.</description><author>Yizheng Wu, Zhiyu Pan, Kewei Wang, Xingyi Li, Jiahao Cui, Liwen Xiao, Guosheng Lin, Zhiguo Cao</author><pubDate>Mon, 24 Jun 2024 17:35:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16776v1</guid></item><item><title>OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?</title><link>http://arxiv.org/abs/2406.16772v1</link><description>In this report, we pose the following question: Who is the most intelligentAI model to date, as measured by the OlympicArena (an Olympic-level,multi-discipline, multi-modal benchmark for superintelligent AI)? Wespecifically focus on the most recently released models: Claude-3.5-Sonnet,Gemini-1.5-Pro, and GPT-4o. For the first time, we propose using an Olympicmedal Table approach to rank AI models based on their comprehensive performanceacross various disciplines. Empirical results reveal: (1) Claude-3.5-Sonnetshows highly competitive overall performance over GPT-4o, even surpassingGPT-4o on a few subjects (i.e., Physics, Chemistry, and Biology). (2)Gemini-1.5-Pro and GPT-4V are ranked consecutively just behind GPT-4o andClaude-3.5-Sonnet, but with a clear performance gap between them. (3) Theperformance of AI models from the open-source community significantly lagsbehind these proprietary models. (4) The performance of these models on thisbenchmark has been less than satisfactory, indicating that we still have a longway to go before achieving superintelligence. We remain committed tocontinuously tracking and evaluating the performance of the latest powerfulmodels on this benchmark (available athttps://github.com/GAIR-NLP/OlympicArena).</description><author>Zhen Huang, Zengzhi Wang, Shijie Xia, Pengfei Liu</author><pubDate>Mon, 24 Jun 2024 17:31:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16772v1</guid></item><item><title>WARP: On the Benefits of Weight Averaged Rewarded Policies</title><link>http://arxiv.org/abs/2406.16768v1</link><description>Reinforcement learning from human feedback (RLHF) aligns large languagemodels (LLMs) by encouraging their generations to have high rewards, using areward model trained on human preferences. To prevent the forgetting ofpre-trained knowledge, RLHF usually incorporates a KL regularization; thisforces the policy to remain close to its supervised fine-tuned initialization,though it hinders the reward optimization. To tackle the trade-off between KLand reward, in this paper we introduce a novel alignment strategy named WeightAveraged Rewarded Policies (WARP). WARP merges policies in the weight space atthree distinct stages. First, it uses the exponential moving average of thepolicy as a dynamic anchor in the KL regularization. Second, it appliesspherical interpolation to merge independently fine-tuned policies into a newenhanced one. Third, it linearly interpolates between this merged model and theinitialization, to recover features from pre-training. This procedure is thenapplied iteratively, with each iteration's final model used as an advancedinitialization for the next, progressively refining the KL-reward Pareto front,achieving superior rewards at fixed KL. Experiments with GEMMA policiesvalidate that WARP improves their quality and alignment, outperforming otheropen-source LLMs.</description><author>Alexandre Ramé, Johan Ferret, Nino Vieillard, Robert Dadashi, Léonard Hussenot, Pierre-Louis Cedoz, Pier Giuseppe Sessa, Sertan Girgin, Arthur Douillard, Olivier Bachem</author><pubDate>Mon, 24 Jun 2024 17:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16768v1</guid></item><item><title>The GPT-WritingPrompts Dataset: A Comparative Analysis of Character Portrayal in Short Stories</title><link>http://arxiv.org/abs/2406.16767v1</link><description>The improved generative capabilities of large language models have made thema powerful tool for creative writing and storytelling. It is thereforeimportant to quantitatively understand the nature of generated stories, and howthey differ from human storytelling. We augment the Reddit WritingPromptsdataset with short stories generated by GPT-3.5, given the same prompts. Wequantify and compare the emotional and descriptive features of storytellingfrom both generative processes, human and machine, along a set of sixdimensions. We find that generated stories differ significantly from humanstories along all six dimensions, and that human and machine generationsdisplay similar biases when grouped according to the narrative point-of-viewand gender of the main protagonist. We release our dataset and code athttps://github.com/KristinHuangg/gpt-writing-prompts.</description><author>Xi Yu Huang, Krishnapriya Vishnubhotla, Frank Rudzicz</author><pubDate>Mon, 24 Jun 2024 17:24:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16767v1</guid></item><item><title>Deep Reinforcement Learning: A Convex Optimization Approach</title><link>http://arxiv.org/abs/2402.19212v6</link><description>In this paper, we consider reinforcement learning of nonlinear systems withcontinuous state and action spaces. We present an episodic learning algorithm,where we for each episode use convex optimization to find a two-layer neuralnetwork approximation of the optimal $Q$-function. The convex optimizationapproach guarantees that the weights calculated at each episode are optimal,with respect to the given sampled states and actions of the current episode.For stable nonlinear systems, we show that the algorithm converges and that theconverging parameters of the trained neural network can be made arbitrarilyclose to the optimal neural network parameters. In particular, if theregularization parameter in the training phase is given by $\rho$, then theparameters of the trained neural network converge to $w$, where the distancebetween $w$ and the optimal parameters $w^\star$ is bounded by$\mathcal{O}(\rho)$. That is, when the number of episodes goes to infinity,there exists a constant $C$ such that \[ \|w-w^\star\| \le C\rho. \] In particular, our algorithm converges arbitrarily close to the optimalneural network parameters as the regularization parameter goes to zero. As aconsequence, our algorithm converges fast due to the polynomial-timeconvergence of convex optimization algorithms.</description><author>Ather Gattami</author><pubDate>Mon, 24 Jun 2024 17:23:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19212v6</guid></item><item><title>Conformal time series decomposition with component-wise exchangeability</title><link>http://arxiv.org/abs/2406.16766v1</link><description>Conformal prediction offers a practical framework for distribution-freeuncertainty quantification, providing finite-sample coverage guarantees underrelatively mild assumptions on data exchangeability. However, these assumptionscease to hold for time series due to their temporally correlated nature. Inthis work, we present a novel use of conformal prediction for time seriesforecasting that incorporates time series decomposition. This approach allowsus to model different temporal components individually. By applying specificconformal algorithms to each component and then merging the obtained predictionintervals, we customize our methods to account for the differentexchangeability regimes underlying each component. Our decomposition-basedapproach is thoroughly discussed and empirically evaluated on synthetic andreal-world data. We find that the method provides promising results onwell-structured time series, but can be limited by factors such as thedecomposition step for more complex data.</description><author>Derck W. E. Prinzhorn, Thijmen Nijdam, Putri A. van der Linden, Alexander Timans</author><pubDate>Mon, 24 Jun 2024 17:23:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16766v1</guid></item><item><title>VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation</title><link>http://arxiv.org/abs/2406.15252v2</link><description>The recent years have witnessed great advances in video generation. However,the development of automatic video metrics is lagging significantly behind.None of the existing metric is able to provide reliable scores over generatedvideos. The main barrier is the lack of large-scale human-annotated dataset. Inthis paper, we release VideoFeedback, the first large-scale dataset containinghuman-provided multi-aspect score over 37.6K synthesized videos from 11existing video generative models. We train VideoScore (initialized from Mantis)based on VideoFeedback to enable automatic video quality assessment.Experiments show that the Spearman correlation between VideoScore and humanscan reach 77.1 on VideoFeedback-test, beating the prior best metrics by about50 points. Further result on other held-out EvalCrafter, GenAI-Bench, andVBench show that VideoScore has consistently much higher correlation with humanjudges than other metrics. Due to these results, we believe VideoScore canserve as a great proxy for human raters to (1) rate different video models totrack progress (2) simulate fine-grained human feedback in ReinforcementLearning with Human Feedback (RLHF) to improve current video generation models.</description><author>Xuan He, Dongfu Jiang, Ge Zhang, Max Ku, Achint Soni, Sherman Siu, Haonan Chen, Abhranil Chandra, Ziyan Jiang, Aaran Arulraj, Kai Wang, Quy Duc Do, Yuansheng Ni, Bohan Lyu, Yaswanth Narsupalli, Rongqi Fan, Zhiheng Lyu, Yuchen Lin, Wenhu Chen</author><pubDate>Mon, 24 Jun 2024 17:22:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15252v2</guid></item><item><title>Pandora's White-Box: Precise Training Data Detection and Extraction in Large Language Models</title><link>http://arxiv.org/abs/2402.17012v3</link><description>In this paper we develop state-of-the-art privacy attacks against LargeLanguage Models (LLMs), where an adversary with some access to the model triesto learn something about the underlying training data. Our headline results arenew membership inference attacks (MIAs) against pretrained LLMs that performhundreds of times better than baseline attacks, and a pipeline showing thatover 50% (!) of the fine-tuning dataset can be extracted from a fine-tuned LLMin natural settings. We consider varying degrees of access to the underlyingmodel, pretraining and fine-tuning data, and both MIAs and training dataextraction. For pretraining data, we propose two new MIAs: a supervised neuralnetwork classifier that predicts training data membership on the basis of(dimensionality-reduced) model gradients, as well as a variant of this attackthat only requires logit access to the model by leveraging recentmodel-stealing work on LLMs. To our knowledge this is the first MIA thatexplicitly incorporates model-stealing information. Both attacks outperformexisting black-box baselines, and our supervised attack closes the gap betweenMIA attack success against LLMs and the strongest known attacks for othermachine learning models. In fine-tuning, we find that a simple attack based onthe ratio of the loss between the base and fine-tuned models is able to achievenear-perfect MIA performance; we then leverage our MIA to extract a largefraction of the fine-tuning dataset from fine-tuned Pythia and Llama models.Our code is available at github.com/safr-ai-lab/pandora-llm.</description><author>Jeffrey G. Wang, Jason Wang, Marvin Li, Seth Neel</author><pubDate>Mon, 24 Jun 2024 17:18:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17012v3</guid></item><item><title>Unlearnable Examples for Diffusion Models: Protect Data from Unauthorized Exploitation</title><link>http://arxiv.org/abs/2306.01902v2</link><description>Diffusion models have demonstrated remarkable performance in image generationtasks, paving the way for powerful AIGC applications. However, thesewidely-used generative models can also raise security and privacy concerns,such as copyright infringement, and sensitive data leakage. To tackle theseissues, we propose a method, Unlearnable Diffusion Perturbation, to safeguardimages from unauthorized exploitation. Our approach involves designing analgorithm to generate sample-wise perturbation noise for each image to beprotected. This imperceptible protective noise makes the data almostunlearnable for diffusion models, i.e., diffusion models trained or fine-tunedon the protected data cannot generate high-quality and diverse images relatedto the protected training data. Theoretically, we frame this as a max-minoptimization problem and introduce EUDP, a noise scheduler-based method toenhance the effectiveness of the protective noise. We evaluate our methods onboth Denoising Diffusion Probabilistic Model and Latent Diffusion Models,demonstrating that training diffusion models on the protected data lead to asignificant reduction in the quality of the generated images. Especially, theexperimental results on Stable Diffusion demonstrate that our methodeffectively safeguards images from being used to train Diffusion Models invarious tasks, such as training specific objects and styles. This achievementholds significant importance in real-world scenarios, as it contributes to theprotection of privacy and copyright against AI-generated content.</description><author>Zhengyue Zhao, Jinhao Duan, Xing Hu, Kaidi Xu, Chenan Wang, Rui Zhang, Zidong Du, Qi Guo, Yunji Chen</author><pubDate>Mon, 24 Jun 2024 17:11:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01902v2</guid></item><item><title>Structured Packing in LLM Training Improves Long Context Utilization</title><link>http://arxiv.org/abs/2312.17296v7</link><description>Recent advancements in long-context large language models have attractedsignificant attention, yet their practical applications often suffer fromsuboptimal context utilization. This study investigates structuring trainingdata to enhance semantic interdependence, demonstrating that this approacheffectively improves context utilization. To this end, we introduce theStructured Packing for Long Context (SPLiCe) method, which utilizes retrievalto collate mutually relevant documents into long and coherent trainingexamples. We validate SPLiCe empirically across models of varying sizes -- 3B,7B, and 13B -- achieving improved performance in long-context tasks, such asQasper and HotpotQA. Remarkably, even brief fine-tuning with SPLiCe issufficient to realize these benefits. Additionally, SPLiCe effectivelymitigates the lost-in-middle phenomenon often observed in large models. Ourcomprehensive analysis of SPLiCe explores its design choices and revealsintriguing transfer effects; for instance, training on programming codeenhances performance on natural language tasks.</description><author>Konrad Staniszewski, Szymon Tworkowski, Sebastian Jaszczur, Yu Zhao, Henryk Michalewski, Łukasz Kuciński, Piotr Miłoś</author><pubDate>Mon, 24 Jun 2024 17:10:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17296v7</guid></item><item><title>An Experimental Study on the Rashomon Effect of Balancing Methods in Imbalanced Classification</title><link>http://arxiv.org/abs/2405.01557v2</link><description>Predictive models may generate biased predictions when classifying imbalanceddatasets. This happens when the model favors the majority class, leading to lowperformance in accurately predicting the minority class. To address this issue,balancing or resampling methods are critical pre-processing steps in themodeling process. However, there have been debates and questioning of thefunctionality of these methods in recent years. In particular, many candidatemodels may exhibit very similar predictive performance, which is called theRashomon effect, in model selection. Selecting one of them without consideringpredictive multiplicity which is the case of yielding conflicting models'predictions for any sample may lead to a loss of using another model. In thisstudy, in addition to the existing debates, the impact of balancing methods onpredictive multiplicity is examined through the Rashomon effect. It isimportant because the blind model selection is risky from a set ofapproximately equally accurate models. This may lead to serious problems inmodel selection, validation, and explanation. To tackle this matter, weconducted real dataset experiments to observe the impact of balancing methodson predictive multiplicity through the Rashomon effect. Our findings showedthat balancing methods inflate the predictive multiplicity, and they yieldvarying results. To monitor the trade-off between performance and predictivemultiplicity for conducting the modeling process responsibly, we proposed usingthe extended performance-gain plot for the Rashomon effect.</description><author>Mustafa Cavus, Przemysław Biecek</author><pubDate>Mon, 24 Jun 2024 17:08:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01557v2</guid></item><item><title>Positive concave deep equilibrium models</title><link>http://arxiv.org/abs/2402.04029v2</link><description>Deep equilibrium (DEQ) models are widely recognized as a memory efficientalternative to standard neural networks, achieving state-of-the-art performancein language modeling and computer vision tasks. These models solve a fixedpoint equation instead of explicitly computing the output, which sets themapart from standard neural networks. However, existing DEQ models often lackformal guarantees of the existence and uniqueness of the fixed point, and theconvergence of the numerical scheme used for computing the fixed point is notformally established. As a result, DEQ models are potentially unstable inpractice. To address these drawbacks, we introduce a novel class of DEQ modelscalled positive concave deep equilibrium (pcDEQ) models. Our approach, which isbased on nonlinear Perron-Frobenius theory, enforces nonnegative weights andactivation functions that are concave on the positive orthant. By imposingthese constraints, we can easily ensure the existence and uniqueness of thefixed point without relying on additional complex assumptions commonly found inthe DEQ literature, such as those based on monotone operator theory in convexanalysis. Furthermore, the fixed point can be computed with the standard fixedpoint algorithm, and we provide theoretical guarantees of its geometricconvergence, which, in particular, simplifies the training process. Experimentsdemonstrate the competitiveness of our pcDEQ models against other implicitmodels.</description><author>Mateusz Gabor, Tomasz Piotrowski, Renato L. G. Cavalcante</author><pubDate>Mon, 24 Jun 2024 17:08:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04029v2</guid></item><item><title>Who Plays First? Optimizing the Order of Play in Stackelberg Games with Many Robots</title><link>http://arxiv.org/abs/2402.09246v3</link><description>We consider the multi-agent spatial navigation problem of computing thesocially optimal order of play, i.e., the sequence in which the agents committo their decisions, and its associated equilibrium in an N-player Stackelbergtrajectory game. We model this problem as a mixed-integer optimization problemover the space of all possible Stackelberg games associated with the order ofplay's permutations. To solve the problem, we introduce Branch and Play (B&amp;P),an efficient and exact algorithm that provably converges to a socially optimalorder of play and its Stackelberg equilibrium. As a subroutine for B&amp;P, weemploy and extend sequential trajectory planning, i.e., a popular multi-agentcontrol approach, to scalably compute valid local Stackelberg equilibria forany given order of play. We demonstrate the practical utility of B&amp;P tocoordinate air traffic control, swarm formation, and delivery vehicle fleets.We find that B&amp;P consistently outperforms various baselines, and computes thesocially optimal equilibrium.</description><author>Haimin Hu, Gabriele Dragotto, Zixu Zhang, Kaiqu Liang, Bartolomeo Stellato, Jaime F. Fisac</author><pubDate>Mon, 24 Jun 2024 17:06:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09246v3</guid></item><item><title>Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters</title><link>http://arxiv.org/abs/2406.16758v1</link><description>Large language models (LLMs) have revolutionized natural language processingand broadened their applicability across diverse commercial applications.However, the deployment of these models is constrained by high inference timein multilingual settings. To mitigate this challenge, this paper explores atraining recipe of an assistant model in speculative decoding, which areleveraged to draft and-then its future tokens are verified by the target LLM.We show that language-specific draft models, optimized through a targetedpretrain-and-finetune strategy, substantially brings a speedup of inferencetime compared to the previous methods. We validate these models across variouslanguages in inference time, out-of-domain speedup, and GPT-4o evaluation.</description><author>Euiin Yi, Taehyeon Kim, Hongseok Jeung, Du-Seong Chang, Se-Young Yun</author><pubDate>Mon, 24 Jun 2024 17:06:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16758v1</guid></item><item><title>Addressing Polarization and Unfairness in Performative Prediction</title><link>http://arxiv.org/abs/2406.16756v1</link><description>When machine learning (ML) models are used in applications that involvehumans (e.g., online recommendation, school admission, hiring, lending), themodel itself may trigger changes in the distribution of targeted data it aimsto predict. Performative prediction (PP) is a framework that explicitlyconsiders such model-dependent distribution shifts when learning ML models.While significant efforts have been devoted to finding performative stable (PS)solutions in PP for system robustness, their societal implications are lessexplored and it is unclear whether PS solutions are aligned with social normssuch as fairness. In this paper, we set out to examine the fairness property ofPS solutions in performative prediction. We first show that PS solutions canincur severe polarization effects and group-wise loss disparity. Althoughexisting fairness mechanisms commonly used in literature can help mitigateunfairness, they may fail and disrupt the stability under model-dependentdistribution shifts. We thus propose novel fairness intervention mechanismsthat can simultaneously achieve both stability and fairness in PP settings.Both theoretical analysis and experiments are provided to validate the proposedmethod.</description><author>Kun Jin, Tian Xie, Yang Liu, Xueru Zhang</author><pubDate>Mon, 24 Jun 2024 17:03:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16756v1</guid></item><item><title>Can Many-Shot In-Context Learning Help Long-Context LLM Judges? See More, Judge Better!</title><link>http://arxiv.org/abs/2406.11629v2</link><description>Leveraging Large Language Models (LLMs) as judges for evaluating theperformance of LLMs has recently garnered attention. Nonetheless, this type ofapproach concurrently introduces potential biases from LLMs, raising concernsabout the reliability of the evaluation results. To mitigate this issue, wepropose and study two versions of many-shot in-context prompts, Reinforced andUnsupervised ICL, for helping GPT-4o-as-a-Judge in single answer grading. Theformer uses in-context examples with model-generated rationales, and the latterwithout. Based on the designed prompts, we investigate the impact of scalingthe number of in-context examples on the agreement and quality of theevaluation. Furthermore, we first reveal the symbol bias in GPT-4o-as-a-Judgefor pairwise comparison and then propose a simple yet effective approach tomitigate it. Experimental results show that advanced long-context LLMs, such asGPT-4o, perform better in the many-shot regime than in the zero-shot regime.Meanwhile, the experimental results further verify the effectiveness of thesymbol bias mitigation approach.</description><author>Mingyang Song, Mao Zheng, Xuan Luo</author><pubDate>Mon, 24 Jun 2024 17:02:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11629v2</guid></item><item><title>The MRI Scanner as a Diagnostic: Image-less Active Sampling</title><link>http://arxiv.org/abs/2406.16754v1</link><description>Despite the high diagnostic accuracy of Magnetic Resonance Imaging (MRI),using MRI as a Point-of-Care (POC) disease identification tool posessignificant accessibility challenges due to the use of high magnetic fieldstrength and lengthy acquisition times. We ask a simple question: Can wedynamically optimise acquired samples, at the patient level, according to an(automated) downstream decision task, while discounting image reconstruction?We propose an ML-based framework that learns an active sampling strategy, viareinforcement learning, at a patient-level to directly infer disease fromundersampled k-space. We validate our approach by inferring Meniscus Tear inundersampled knee MRI data, where we achieve diagnostic performance comparablewith ML-based diagnosis, using fully sampled k-space data. We analysetask-specific sampling policies, showcasing the adaptability of our activesampling approach. The introduced frugal sampling strategies have the potentialto reduce high field strength requirements that in turn strengthen theviability of MRI-based POC disease identification and associated preliminaryscreening tools.</description><author>Yuning Du, Rohan Dharmakumar, Sotirios A. Tsaftaris</author><pubDate>Mon, 24 Jun 2024 17:00:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16754v1</guid></item><item><title>Towards Zero-Shot Text-To-Speech for Arabic Dialects</title><link>http://arxiv.org/abs/2406.16751v1</link><description>Zero-shot multi-speaker text-to-speech (ZS-TTS) systems have advanced forEnglish, however, it still lags behind due to insufficient resources. Weaddress this gap for Arabic, a language of more than 450 million nativespeakers, by first adapting a sizeable existing dataset to suit the needs ofspeech synthesis. Additionally, we employ a set of Arabic dialectidentification models to explore the impact of pre-defined dialect labels onimproving the ZS-TTS model in a multi-dialect setting. Subsequently, wefine-tune theXTTS\footnote{https://docs.coqui.ai/en/latest/models/xtts.html}\footnote{https://medium.com/machine-learns/xtts-v2-new-version-of-the-open-source-text-to-speech-model-af73914db81f}\footnote{https://medium.com/@erogol/xtts-v1-techincal-notes-eb83ff05bdc}model, an open-source architecture. We then evaluate our models on a datasetcomprising 31 unseen speakers and an in-house dialectal dataset. Our automatedand human evaluation results show convincing performance while capable ofgenerating dialectal speech. Our study highlights significant potential forimprovements in this emerging area of research in Arabic.</description><author>Khai Duy Doan, Abdul Waheed, Muhammad Abdul-Mageed</author><pubDate>Mon, 24 Jun 2024 16:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16751v1</guid></item><item><title>Inferring stochastic low-rank recurrent neural networks from neural data</title><link>http://arxiv.org/abs/2406.16749v1</link><description>A central aim in computational neuroscience is to relate the activity oflarge populations of neurons to an underlying dynamical system. Models of theseneural dynamics should ideally be both interpretable and fit the observed datawell. Low-rank recurrent neural networks (RNNs) exhibit such interpretabilityby having tractable dynamics. However, it is unclear how to best fit low-rankRNNs to data consisting of noisy observations of an underlying stochasticsystem. Here, we propose to fit stochastic low-rank RNNs with variationalsequential Monte Carlo methods. We validate our method on several datasetsconsisting of both continuous and spiking neural data, where we obtain lowerdimensional latent dynamics than current state of the art methods.Additionally, for low-rank models with piecewise linear nonlinearities, we showhow to efficiently identify all fixed points in polynomial rather thanexponential cost in the number of units, making analysis of the inferreddynamics tractable for large RNNs. Our method both elucidates the dynamicalsystems underlying experimental recordings and provides a generative modelwhose trajectories match observed trial-to-trial variability.</description><author>Matthijs Pals, A Erdem Sağtekin, Felix Pei, Manuel Gloeckler, Jakob H Macke</author><pubDate>Mon, 24 Jun 2024 16:57:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16749v1</guid></item><item><title>OCALM: Object-Centric Assessment with Language Models</title><link>http://arxiv.org/abs/2406.16748v1</link><description>Properly defining a reward signal to efficiently train a reinforcementlearning (RL) agent is a challenging task. Designing balanced objectivefunctions from which a desired behavior can emerge requires expert knowledge,especially for complex environments. Learning rewards from human feedback orusing large language models (LLMs) to directly provide rewards are promisingalternatives, allowing non-experts to specify goals for the agent. However,black-box reward models make it difficult to debug the reward. In this work, wepropose Object-Centric Assessment with Language Models (OCALM) to deriveinherently interpretable reward functions for RL agents from natural languagetask descriptions. OCALM uses the extensive world-knowledge of LLMs whileleveraging the object-centric nature common to many environments to derivereward functions focused on relational concepts, providing RL agents with theability to derive policies from task descriptions.</description><author>Timo Kaufmann, Jannis Blüml, Antonia Wüst, Quentin Delfosse, Kristian Kersting, Eyke Hüllermeier</author><pubDate>Mon, 24 Jun 2024 16:57:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16748v1</guid></item><item><title>Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers</title><link>http://arxiv.org/abs/2406.16747v1</link><description>Accommodating long sequences efficiently in autoregressive Transformers,especially within an extended context window, poses significant challenges dueto the quadratic computational complexity and substantial KV memoryrequirements inherent in self-attention mechanisms. In this work, we introduceSPARSEK Attention, a novel sparse attention mechanism designed to overcomethese computational and memory obstacles while maintaining performance. Ourapproach integrates a scoring network and a differentiable top-k mask operator,SPARSEK, to select a constant number of KV pairs for each query, therebyenabling gradient-based optimization. As a result, SPARSEK Attention offerslinear time complexity and constant memory footprint during generation.Experimental results reveal that SPARSEK Attention outperforms previous sparseattention methods and provides significant speed improvements during bothtraining and inference, particularly in language modeling and downstream tasks.Furthermore, our method can be seamlessly integrated into pre-trained LargeLanguage Models (LLMs) with minimal fine-tuning, offering a practical solutionfor effectively managing long-range dependencies in diverse applications.</description><author>Chao Lou, Zixia Jia, Zilong Zheng, Kewei Tu</author><pubDate>Mon, 24 Jun 2024 16:55:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16747v1</guid></item><item><title>The Responsible Foundation Model Development Cheatsheet: A Review of Tools &amp; Resources</title><link>http://arxiv.org/abs/2406.16746v1</link><description>Foundation model development attracts a rapidly expanding body ofcontributors, scientists, and applications. To help shape responsibledevelopment practices, we introduce the Foundation Model DevelopmentCheatsheet: a growing collection of 250+ tools and resources spanning text,vision, and speech modalities. We draw on a large body of prior work to surveyresources (e.g. software, documentation, frameworks, guides, and practicaltools) that support informed data selection, processing, and understanding,precise and limitation-aware artifact documentation, efficient model training,advance awareness of the environmental impact from training, careful modelevaluation of capabilities, risks, and claims, as well as responsible modelrelease, licensing and deployment practices. We hope this curated collection ofresources helps guide more responsible development. The process of curatingthis list, enabled us to review the AI development ecosystem, revealing whattools are critically missing, misused, or over-used in existing practices. Wefind that (i) tools for data sourcing, model evaluation, and monitoring arecritically under-serving ethical and real-world needs, (ii) evaluations formodel safety, capabilities, and environmental impact all lack reproducibilityand transparency, (iii) text and particularly English-centric analyses continueto dominate over multilingual and multi-modal analyses, and (iv) evaluation ofsystems, rather than just models, is needed so that capabilities and impact areassessed in context.</description><author>Shayne Longpre, Stella Biderman, Alon Albalak, Hailey Schoelkopf, Daniel McDuff, Sayash Kapoor, Kevin Klyman, Kyle Lo, Gabriel Ilharco, Nay San, Maribeth Rauh, Aviya Skowron, Bertie Vidgen, Laura Weidinger, Arvind Narayanan, Victor Sanh, David Adelani, Percy Liang, Rishi Bommasani, Peter Henderson, Sasha Luccioni, Yacine Jernite, Luca Soldaini</author><pubDate>Mon, 24 Jun 2024 16:55:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16746v1</guid></item><item><title>Feature learning as alignment: a structural property of gradient descent in non-linear neural networks</title><link>http://arxiv.org/abs/2402.05271v3</link><description>Understanding the mechanisms through which neural networks extract statisticsfrom input-label pairs through feature learning is one of the most importantunsolved problems in supervised learning. Prior works demonstrated that thegram matrices of the weights (the neural feature matrices, NFM) and the averagegradient outer products (AGOP) become correlated during training, in astatement known as the neural feature ansatz (NFA). Through the NFA, theauthors introduce mapping with the AGOP as a general mechanism for neuralfeature learning. However, these works do not provide a theoretical explanationfor this correlation or its origins. In this work, we further clarify thenature of this correlation, and explain its emergence. We show that thiscorrelation is equivalent to alignment between the left singular structure ofthe weight matrices and the newly defined pre-activation tangent features ateach layer. We further establish that the alignment is driven by theinteraction of weight changes induced by SGD with the pre-activation features,and analyze the resulting dynamics analytically at early times in terms ofsimple statistics of the inputs and labels. Finally, motivated by theobservation that the NFA is driven by this centered correlation, we introduce asimple optimization rule that dramatically increases the NFA correlations atany given layer and improves the quality of features learned.</description><author>Daniel Beaglehole, Ioannis Mitliagkas, Atish Agarwala</author><pubDate>Mon, 24 Jun 2024 16:55:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05271v3</guid></item><item><title>Bandits with Preference Feedback: A Stackelberg Game Perspective</title><link>http://arxiv.org/abs/2406.16745v1</link><description>Bandits with preference feedback present a powerful tool for optimizingunknown target functions when only pairwise comparisons are allowed instead ofdirect value queries. This model allows for incorporating human feedback intoonline inference and optimization and has been employed in systems forfine-tuning large language models. The problem is well understood in simplifiedsettings with linear target functions or over finite small domains that limitpractical interest. Taking the next step, we consider infinite domains andnonlinear (kernelized) rewards. In this setting, selecting a pair of actions isquite challenging and requires balancing exploration and exploitation at twolevels: within the pair, and along the iterations of the algorithm. We proposeMAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, andchooses action pairs that are informative and yield favorable rewards.MAXMINLCB consistently outperforms existing algorithms and satisfies ananytime-valid rate-optimal regret guarantee. This is due to our novelpreference-based confidence sequences for kernelized logistic estimators.</description><author>Barna Pásztor, Parnian Kassraie, Andreas Krause</author><pubDate>Mon, 24 Jun 2024 16:53:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16745v1</guid></item><item><title>EGTR: Extracting Graph from Transformer for Scene Graph Generation</title><link>http://arxiv.org/abs/2404.02072v5</link><description>Scene Graph Generation (SGG) is a challenging task of detecting objects andpredicting relationships between objects. After DETR was developed, one-stageSGG models based on a one-stage object detector have been actively studied.However, complex modeling is used to predict the relationship between objects,and the inherent relationship between object queries learned in the multi-headself-attention of the object detector has been neglected. We propose alightweight one-stage SGG model that extracts the relation graph from thevarious relationships learned in the multi-head self-attention layers of theDETR decoder. By fully utilizing the self-attention by-products, the relationgraph can be extracted effectively with a shallow relation extraction head.Considering the dependency of the relation extraction task on the objectdetection task, we propose a novel relation smoothing technique that adjuststhe relation label adaptively according to the quality of the detected objects.By the relation smoothing, the model is trained according to the continuouscurriculum that focuses on object detection task at the beginning of trainingand performs multi-task learning as the object detection performance graduallyimproves. Furthermore, we propose a connectivity prediction task that predictswhether a relation exists between object pairs as an auxiliary task of therelation extraction. We demonstrate the effectiveness and efficiency of ourmethod for the Visual Genome and Open Image V6 datasets. Our code is publiclyavailable at https://github.com/naver-ai/egtr.</description><author>Jinbae Im, JeongYeon Nam, Nokyung Park, Hyungmin Lee, Seunghyun Park</author><pubDate>Mon, 24 Jun 2024 16:52:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02072v5</guid></item><item><title>Adversarial Contrastive Decoding: Boosting Safety Alignment of Large Language Models via Opposite Prompt Optimization</title><link>http://arxiv.org/abs/2406.16743v1</link><description>With the widespread application of Large Language Models (LLMs), it hasbecome a significant concern to ensure their safety and prevent harmfulresponses. While current safe-alignment methods based on instructionfine-tuning and Reinforcement Learning from Human Feedback (RLHF) caneffectively reduce harmful responses from LLMs, they often require high-qualitydatasets and heavy computational overhead during model training. Another way toalign language models is to modify the logit of tokens in model outputs withoutheavy training. Recent studies have shown that contrastive decoding can enhancethe performance of language models by reducing the likelihood of confusedtokens. However, these methods require the manual selection of contrastivemodels or instruction templates. To this end, we propose AdversarialContrastive Decoding (ACD), an optimization-based framework to generate twoopposite system prompts for prompt-based contrastive decoding. ACD only needsto apply a lightweight prompt tuning on a rather small anchor dataset (&lt; 3 minfor each model) without training the target model. Experiments conducted onextensive models and benchmarks demonstrate that the proposed method achievesmuch better safety performance than previous model training-free decodingmethods without sacrificing its original generation ability.</description><author>Zhengyue Zhao, Xiaoyun Zhang, Kaidi Xu, Xing Hu, Rui Zhang, Zidong Du, Qi Guo, Yunji Chen</author><pubDate>Mon, 24 Jun 2024 16:51:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16743v1</guid></item><item><title>Attribute Diversity Determines the Systematicity Gap in VQA</title><link>http://arxiv.org/abs/2311.08695v2</link><description>The degree to which neural networks can generalize to new combinations offamiliar concepts, and the conditions under which they are able to do so, haslong been an open question. In this work, we study the systematicity gap invisual question answering: the performance difference between reasoning onpreviously seen and unseen combinations of object attributes. To test, weintroduce a novel diagnostic dataset, CLEVR-HOPE. We find that while increasedquantity of training data does not reduce the systematicity gap, increasedtraining data diversity of the attributes in the unseen combination does. Inall, our experiments suggest that the more distinct attribute type combinationsare seen during training, the more systematic we can expect the resulting modelto be.</description><author>Ian Berlot-Attwell, Kumar Krishna Agrawal, A. Michael Carrell, Yash Sharma, Naomi Saphra</author><pubDate>Mon, 24 Jun 2024 16:51:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08695v2</guid></item><item><title>Flow of Reasoning: Efficient Training of LLM Policy with Divergent Thinking</title><link>http://arxiv.org/abs/2406.05673v2</link><description>Divergent thinking, the cognitive process of generating diverse solutions, isa hallmark of human creativity and problem-solving. For machines, samplingdiverse solution trajectories in complex reasoning problems is crucial forrobust outcomes, data augmentation, and enhanced model generalization. Largelanguage models (LLMs) often struggle with generating high-quality, diversereasoning. While supervised fine-tuning helps with quality, it requiresextensive supervision data to capture the full diversity of solutions.Alternatively, reinforcement learning methods like PPO aim to find limitedhighest-reward solutions while neglecting the solution diversity, akin toconvergent thinking. To address these limitations, we propose Flow of Reasoning(FoR) -- an efficient LLM training approach enabling diverse reasoning withminimal data. FoR formulates multi-step LLM reasoning as a Markovian flow froman initial state to terminal states. The formulation allows to adapt principledGFlowNet approaches to train the LLM as a policy, which is able to samplemultiple reasoning paths with probabilities proportional to the unnormalizedreward. Empirical results show that, with limited training data (e.g., 15examples), FoR can discover diverse high-quality solutions that excel greatlybeyond current state-of-the-art methods across three tasks, including embodiedreasoning (BlocksWorld), math puzzle solving (Game24), and logical reasoning(PrOntoQA). Code is available at https://github.com/Yu-Fangxu/FoR.</description><author>Fangxu Yu, Lai Jiang, Haoqiang Kang, Shibo Hao, Lianhui Qin</author><pubDate>Mon, 24 Jun 2024 16:49:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05673v2</guid></item><item><title>Extracting thin film structures of energy materials using transformers</title><link>http://arxiv.org/abs/2406.16741v1</link><description>Neutron-Transformer Reflectometry and Advanced Computation Engine (N-TRACE ),a neural network model using transformer architecture, is introduced forneutron reflectometry data analysis. It offers fast, accurate initial parameterestimations and efficient refinements, improving efficiency and precision forreal-time data analysis of lithium-mediated nitrogen reduction forelectrochemical ammonia synthesis, with relevance to other chemicaltransformations and batteries. Despite limitations in generalizing acrosssystems, it shows promises for the use of transformers as the basis for modelsthat could replace trial-and-error approaches to modeling reflectometry data.</description><author>Chen Zhang, Valerie A. Niemann, Peter Benedek, Thomas F. Jaramillo, Mathieu Doucet</author><pubDate>Mon, 24 Jun 2024 16:48:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16741v1</guid></item><item><title>Learning the boundary-to-domain mapping using Lifting Product Fourier Neural Operators for partial differential equations</title><link>http://arxiv.org/abs/2406.16740v1</link><description>Neural operators such as the Fourier Neural Operator (FNO) have been shown toprovide resolution-independent deep learning models that can learn mappingsbetween function spaces. For example, an initial condition can be mapped to thesolution of a partial differential equation (PDE) at a future time-step using aneural operator. Despite the popularity of neural operators, their use topredict solution functions over a domain given only data over the boundary(such as a spatially varying Dirichlet boundary condition) remains unexplored.In this paper, we refer to such problems as boundary-to-domain problems; theyhave a wide range of applications in areas such as fluid mechanics, solidmechanics, heat transfer etc. We present a novel FNO-based architecture, namedLifting Product FNO (or LP-FNO) which can map arbitrary boundary functionsdefined on the lower-dimensional boundary to a solution in the entire domain.Specifically, two FNOs defined on the lower-dimensional boundary are liftedinto the higher dimensional domain using our proposed lifting product layer. Wedemonstrate the efficacy and resolution independence of the proposed LP-FNO forthe 2D Poisson equation.</description><author>Aditya Kashi, Arka Daw, Muralikrishnan Gopalakrishnan Meena, Hao Lu</author><pubDate>Mon, 24 Jun 2024 16:45:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16740v1</guid></item><item><title>Inducing Group Fairness in LLM-Based Decisions</title><link>http://arxiv.org/abs/2406.16738v1</link><description>Prompting Large Language Models (LLMs) has created new and interesting meansfor classifying textual data. While evaluating and remediating group fairnessis a well-studied problem in classifier fairness literature, some classicalapproaches (e.g., regularization) do not carry over, and some new opportunitiesarise (e.g., prompt-based remediation). We measure fairness of LLM-basedclassifiers on a toxicity classification task, and empirically show thatprompt-based classifiers may lead to unfair decisions. We introduce severalremediation techniques and benchmark their fairness and performance trade-offs.We hope our work encourages more research on group fairness in LLM-basedclassifiers.</description><author>James Atwood, Preethi Lahoti, Ananth Balashankar, Flavien Prost, Ahmad Beirami</author><pubDate>Mon, 24 Jun 2024 16:45:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16738v1</guid></item><item><title>Can Protective Perturbation Safeguard Personal Data from Being Exploited by Stable Diffusion?</title><link>http://arxiv.org/abs/2312.00084v2</link><description>Stable Diffusion has established itself as a foundation model in generativeAI artistic applications, receiving widespread research and application. Somerecent fine-tuning methods have made it feasible for individuals to implantpersonalized concepts onto the basic Stable Diffusion model with minimalcomputational costs on small datasets. However, these innovations have alsogiven rise to issues like facial privacy forgery and artistic copyrightinfringement. In recent studies, researchers have explored the addition ofimperceptible adversarial perturbations to images to prevent potentialunauthorized exploitation and infringements when personal data is used forfine-tuning Stable Diffusion. Although these studies have demonstrated theability to protect images, it is essential to consider that these methods maynot be entirely applicable in real-world scenarios. In this paper, wesystematically evaluate the use of perturbations to protect images within apractical threat model. The results suggest that these approaches may not besufficient to safeguard image privacy and copyright effectively. Furthermore,we introduce a purification method capable of removing protected perturbationswhile preserving the original image structure to the greatest extent possible.Experiments reveal that Stable Diffusion can effectively learn from purifiedimages over all protective methods.</description><author>Zhengyue Zhao, Jinhao Duan, Kaidi Xu, Chenan Wang, Rui Zhang, Zidong Du, Qi Guo, Xing Hu</author><pubDate>Mon, 24 Jun 2024 16:44:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00084v2</guid></item><item><title>A practical existence theorem for reduced order models based on convolutional autoencoders</title><link>http://arxiv.org/abs/2402.00435v2</link><description>In recent years, deep learning has gained increasing popularity in the fieldsof Partial Differential Equations (PDEs) and Reduced Order Modeling (ROM),providing domain practitioners with new powerful data-driven techniques such asPhysics-Informed Neural Networks (PINNs), Neural Operators, Deep OperatorNetworks (DeepONets) and Deep-Learning based ROMs (DL-ROMs). In this context,deep autoencoders based on Convolutional Neural Networks (CNNs) have provenextremely effective, outperforming established techniques, such as the reducedbasis method, when dealing with complex nonlinear problems. However, despitethe empirical success of CNN-based autoencoders, there are only a fewtheoretical results supporting these architectures, usually stated in the formof universal approximation theorems. In particular, although the existingliterature provides users with guidelines for designing convolutionalautoencoders, the subsequent challenge of learning the latent features has beenbarely investigated. Furthermore, many practical questions remain unanswered,e.g., the number of snapshots needed for convergence or the neural networktraining strategy. In this work, using recent techniques from sparsehigh-dimensional function approximation, we fill some of these gaps byproviding a new practical existence theorem for CNN-based autoencoders when theparameter-to-solution map is holomorphic. This regularity assumption arises inmany relevant classes of parametric PDEs, such as the parametric diffusionequation, for which we discuss an explicit application of our general theory.</description><author>Nicola Rares Franco, Simone Brugiapaglia</author><pubDate>Mon, 24 Jun 2024 16:42:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00435v2</guid></item><item><title>Fusion of Movement and Naive Predictions for Point Forecasting in Univariate Random Walks</title><link>http://arxiv.org/abs/2406.14469v2</link><description>Traditional methods for point forecasting in univariate random walks oftenfail to surpass naive benchmarks due to data unpredictability. This studyintroduces a novel forecasting method that fuses movement prediction (binaryclassification) with naive forecasts for accurate one-step-ahead pointforecasting. The method's efficacy is demonstrated through theoreticalanalysis, simulations, and real-world data experiments. It reliably exceedsnaive forecasts with movement prediction accuracies as low as 0.55,outperforming baseline models like ARIMA, linear regression, MLP, and LSTMnetworks in forecasting the S\&amp;P 500 index and Bitcoin prices. This method isparticularly advantageous when accurate point predictions are challenging butaccurate movement predictions are attainable, translating movement predictionsinto point forecasts in random walk contexts.</description><author>Cheng Zhang</author><pubDate>Mon, 24 Jun 2024 16:40:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14469v2</guid></item><item><title>Versatile Backdoor Attack with Visible, Semantic, Sample-Specific, and Compatible Triggers</title><link>http://arxiv.org/abs/2306.00816v4</link><description>Deep neural networks (DNNs) can be manipulated to exhibit specific behaviorswhen exposed to specific trigger patterns, without affecting their performanceon benign samples, dubbed \textit{backdoor attack}. Currently, implementingbackdoor attacks in physical scenarios still faces significant challenges.Physical attacks are labor-intensive and time-consuming, and the triggers areselected in a manual and heuristic way. Moreover, expanding digital attacks tophysical scenarios faces many challenges due to their sensitivity to visualdistortions and the absence of counterparts in the real world. To address thesechallenges, we define a novel trigger called the \textbf{V}isible,\textbf{S}emantic, \textbf{S}ample-Specific, and \textbf{C}ompatible (VSSC)trigger, to achieve effective, stealthy and robust simultaneously, which canalso be effectively deployed in the physical scenario using correspondingobjects. To implement the VSSC trigger, we propose an automated pipelinecomprising three modules: a trigger selection module that systematicallyidentifies suitable triggers leveraging large language models, a triggerinsertion module that employs generative models to seamlessly integratetriggers into images, and a quality assessment module that ensures the naturaland successful insertion of triggers through vision-language models. Extensiveexperimental results and analysis validate the effectiveness, stealthiness, androbustness of the VSSC trigger. It can not only maintain robustness undervisual distortions but also demonstrates strong practicality in the physicalscenario. We hope that the proposed VSSC trigger and implementation approachcould inspire future studies on designing more practical triggers in backdoorattacks.</description><author>Ruotong Wang, Hongrui Chen, Zihao Zhu, Li Liu, Baoyuan Wu</author><pubDate>Mon, 24 Jun 2024 16:40:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00816v4</guid></item><item><title>FairytaleQA Translated: Enabling Educational Question and Answer Generation in Less-Resourced Languages</title><link>http://arxiv.org/abs/2406.04233v2</link><description>Question Answering (QA) datasets are crucial in assessing readingcomprehension skills for both machines and humans. While numerous datasets havebeen developed in English for this purpose, a noticeable void exists inless-resourced languages. To alleviate this gap, our paper introducesmachine-translated versions of FairytaleQA, a renowned QA dataset designed toassess and enhance narrative comprehension skills in young children. Byemploying fine-tuned, modest-scale models, we establish benchmarks for bothQuestion Generation (QG) and QA tasks within the translated datasets. Inaddition, we present a case study proposing a model for generatingquestion-answer pairs, with an evaluation incorporating quality metrics such asquestion well-formedness, answerability, relevance, and children suitability.Our evaluation prioritizes quantifying and describing error cases, along withproviding directions for future work. This paper contributes to the advancementof QA and QG research in less-resourced languages, promoting accessibility andinclusivity in the development of these models for reading comprehension. Thecode and data is publicly available atgithub.com/bernardoleite/fairytaleqa-translated.</description><author>Bernardo Leite, Tomás Freitas Osório, Henrique Lopes Cardoso</author><pubDate>Mon, 24 Jun 2024 16:39:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04233v2</guid></item><item><title>Sim2Real Bilevel Adaptation for Object Surface Classification using Vision-Based Tactile Sensors</title><link>http://arxiv.org/abs/2311.01380v2</link><description>In this paper, we address the Sim2Real gap in the field of vision-basedtactile sensors for classifying object surfaces. We train a Diffusion Model tobridge this gap using a relatively small dataset of real-world images randomlycollected from unlabeled everyday objects via the DIGIT sensor. Subsequently,we employ a simulator to generate images by uniformly sampling the surface ofobjects from the YCB Model Set. These simulated images are then translated intothe real domain using the Diffusion Model and automatically labeled to train aclassifier. During this training, we further align features of the two domainsusing an adversarial procedure. Our evaluation is conducted on a dataset oftactile images obtained from a set of ten 3D printed YCB objects. The resultsreveal a total accuracy of 81.9%, a significant improvement compared to the34.7% achieved by the classifier trained solely on simulated images. Thisdemonstrates the effectiveness of our approach. We further validate ourapproach using the classifier on a 6D object pose estimation task from tactiledata.</description><author>Gabriele M. Caddeo, Andrea Maracani, Paolo D. Alfano, Nicola A. Piga, Lorenzo Rosasco, Lorenzo Natale</author><pubDate>Mon, 24 Jun 2024 16:39:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01380v2</guid></item><item><title>CLIMATELI: Evaluating Entity Linking on Climate Change Data</title><link>http://arxiv.org/abs/2406.16732v1</link><description>Climate Change (CC) is a pressing topic of global importance, attractingincreasing attention across research fields, from social sciences to NaturalLanguage Processing (NLP). CC is also discussed in various settings andcommunication platforms, from academic publications to social media forums.Understanding who and what is mentioned in such data is a first critical stepto gaining new insights into CC. We present CLIMATELI (CLIMATe Entity LInking),the first manually annotated CC dataset that links 3,087 entity spans toWikipedia. Using CLIMATELI (CLIMATe Entity LInking), we evaluate existingentity linking (EL) systems on the CC topic across various genres and proposeautomated filtering methods for CC entities. We find that the performance of ELmodels notably lags behind humans at both token and entity levels. Testingwithin the scope of retaining or excluding non-nominal and/or non-CC entitiesparticularly impacts the models' performances.</description><author>Shijia Zhou, Siyao Peng, Barbara Plank</author><pubDate>Mon, 24 Jun 2024 16:36:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16732v1</guid></item><item><title>Convolutional neural network for Lyman break galaxies classification and redshift regression in DESI (Dark Energy Spectroscopic Instrument)</title><link>http://arxiv.org/abs/2406.16730v1</link><description>DESI is a groundbreaking international project to observe more than 40million quasars and galaxies over a 5-year period to create a 3D map of thesky. This map will enable us to probe multiple aspects of cosmology, from darkenergy to neutrino mass. We are focusing here on one type of object observed byDESI, the Lyman Break Galaxies (LBGs). The aim is to use their spectra todetermine whether they are indeed LBGs, and if so, to determine their distancefrom the Earth using a phenomenon called redshift. This will enable us to placethese galaxies on the DESI 3D map. The aim is therefore to develop a convolutional neural network (CNN) inspiredby QuasarNET (See arXiv:1808.09955), performing simultaneously a classification(LBG type or not) and a regression task (determine the redshift of the LBGs).Initially, data augmentation techniques such as shifting the spectra inwavelengths, adding noise to the spectra, or adding synthetic spectra were usedto increase the model training dataset from 3,019 data to over 66,000. In asecond phase, modifications to the QuasarNET architecture, notably throughtransfer learning and hyperparameter tuning with Bayesian optimization, boostedmodel performance. Gains of up to 26% were achieved on the Purity/Efficiency curve, which isused to evaluate model performance, particularly in areas with interestingredshifts, at low (around 2) and high (around 4) redshifts. The best modelobtained an average score of 94%, compared with 75% for the initial model.</description><author>Julien Taran</author><pubDate>Mon, 24 Jun 2024 16:35:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16730v1</guid></item><item><title>GPTFUZZER: Red Teaming Large Language Models with Auto-Generated Jailbreak Prompts</title><link>http://arxiv.org/abs/2309.10253v3</link><description>Large language models (LLMs) have recently experienced tremendous popularityand are widely used from casual conversations to AI-driven programming.However, despite their considerable success, LLMs are not entirely reliable andcan give detailed guidance on how to conduct harmful or illegal activities.While safety measures can reduce the risk of such outputs, adversarialjailbreak attacks can still exploit LLMs to produce harmful content. Thesejailbreak templates are typically manually crafted, making large-scale testingchallenging. In this paper, we introduce GPTFuzz, a novel black-box jailbreak fuzzingframework inspired by the AFL fuzzing framework. Instead of manual engineering,GPTFuzz automates the generation of jailbreak templates for red-teaming LLMs.At its core, GPTFuzz starts with human-written templates as initial seeds, thenmutates them to produce new templates. We detail three key components ofGPTFuzz: a seed selection strategy for balancing efficiency and variability,mutate operators for creating semantically equivalent or similar sentences, anda judgment model to assess the success of a jailbreak attack. We evaluate GPTFuzz against various commercial and open-source LLMs,including ChatGPT, LLaMa-2, and Vicuna, under diverse attack scenarios. Ourresults indicate that GPTFuzz consistently produces jailbreak templates with ahigh success rate, surpassing human-crafted templates. Remarkably, GPTFuzzachieves over 90% attack success rates against ChatGPT and Llama-2 models, evenwith suboptimal initial seed templates. We anticipate that GPTFuzz will beinstrumental for researchers and practitioners in examining LLM robustness andwill encourage further exploration into enhancing LLM safety.</description><author>Jiahao Yu, Xingwei Lin, Zheng Yu, Xinyu Xing</author><pubDate>Mon, 24 Jun 2024 16:34:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10253v3</guid></item><item><title>CausalMMM: Learning Causal Structure for Marketing Mix Modeling</title><link>http://arxiv.org/abs/2406.16728v1</link><description>In online advertising, marketing mix modeling (MMM) is employed to predictthe gross merchandise volume (GMV) of brand shops and help decision-makers toadjust the budget allocation of various advertising channels. Traditional MMMmethods leveraging regression techniques can fail in handling the complexity ofmarketing. Although some efforts try to encode the causal structures for betterprediction, they have the strict restriction that causal structures areprior-known and unchangeable. In this paper, we define a new causal MMM problemthat automatically discovers the interpretable causal structures from data andyields better GMV predictions. To achieve causal MMM, two essential challengesshould be addressed: (1) Causal Heterogeneity. The causal structures ofdifferent kinds of shops vary a lot. (2) Marketing Response Patterns. Variousmarketing response patterns i.e., carryover effect and shape effect, have beenvalidated in practice. We argue that causal MMM needs dynamically discoverspecific causal structures for different shops and the predictions shouldcomply with the prior known marketing response patterns. Thus, we proposeCausalMMM that integrates Granger causality in a variational inferenceframework to measure the causal relationships between different channels andpredict the GMV with the regularization of both temporal and saturationmarketing response patterns. Extensive experiments show that CausalMMM can notonly achieve superior performance of causal structure learning on syntheticdatasets with improvements of 5.7%\sim 7.1%, but also enhance the GMVprediction results on a representative E-commerce platform.</description><author>Chang Gong, Di Yao, Lei Zhang, Sheng Chen, Wenbin Li, Yueyang Su, Jingping Bi</author><pubDate>Mon, 24 Jun 2024 16:33:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16728v1</guid></item><item><title>Children's Speech Recognition through Discrete Token Enhancement</title><link>http://arxiv.org/abs/2406.13431v2</link><description>Children's speech recognition is considered a low-resource task mainly due tothe lack of publicly available data. There are several reasons for such datascarcity, including expensive data collection and annotation processes, anddata privacy, among others. Transforming speech signals into discrete tokensthat do not carry sensitive information but capture both linguistic andacoustic information could be a solution for privacy concerns. In this study,we investigate the integration of discrete speech tokens into children's speechrecognition systems as input without significantly degrading the ASRperformance. Additionally, we explored single-view and multi-view strategiesfor creating these discrete labels. Furthermore, we tested the models forgeneralization capabilities with unseen domain and nativity dataset. Resultsreveal that the discrete token ASR for children achieves nearly equivalentperformance with an approximate 83% reduction in parameters.</description><author>Vrunda N. Sukhadia, Shammur Absar Chowdhury</author><pubDate>Mon, 24 Jun 2024 16:31:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13431v2</guid></item><item><title>LatentExplainer: Explaining Latent Representations in Deep Generative Models with Multi-modal Foundation Models</title><link>http://arxiv.org/abs/2406.14862v2</link><description>Deep generative models like VAEs and diffusion models have advanced variousgeneration tasks by leveraging latent variables to learn data distributions andgenerate high-quality samples. Despite the field of explainable AI makingstrides in interpreting machine learning models, understanding latent variablesin generative models remains challenging. This paper introducesLatentExplainer, a framework for automatically generating semanticallymeaningful explanations of latent variables in deep generative models.LatentExplainer tackles three main challenges: inferring the meaning of latentvariables, aligning explanations with inductive biases, and handling varyingdegrees of explainability. By perturbing latent variables and interpretingchanges in generated data, the framework provides a systematic approach tounderstanding and controlling the data generation process, enhancing thetransparency and interpretability of deep generative models. We evaluate ourproposed method on several real-world and synthetic datasets, and the resultsdemonstrate superior performance in generating high-quality explanations oflatent variables.</description><author>Mengdan Zhu, Raasikh Kanjiani, Jiahui Lu, Andrew Choi, Qirui Ye, Liang Zhao</author><pubDate>Mon, 24 Jun 2024 16:30:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14862v2</guid></item><item><title>μ-Net: A Deep Learning-Based Architecture for μ-CT Segmentation</title><link>http://arxiv.org/abs/2406.16724v1</link><description>X-ray computed microtomography ({\mu}-CT) is a non-destructive technique thatcan generate high-resolution 3D images of the internal anatomy of medical andbiological samples. These images enable clinicians to examine internal anatomyand gain insights into the disease or anatomical morphology. However,extracting relevant information from 3D images requires semantic segmentationof the regions of interest, which is usually done manually and resultstime-consuming and tedious. In this work, we propose a novel framework thatuses a convolutional neural network (CNN) to automatically segment the fullmorphology of the heart of Carassius auratus. The framework employs anoptimized 2D CNN architecture that can infer a 3D segmentation of the sample,avoiding the high computational cost of a 3D CNN architecture. We tackle thechallenges of handling large and high-resoluted image data (over a thousandpixels in each dimension) and a small training database (only three samples) byproposing a standard protocol for data normalization and processing. Moreover,we investigate how the noise, contrast, and spatial resolution of the sampleand the training of the architecture are affected by the reconstructiontechnique, which depends on the number of input images. Experiments show thatour framework significantly reduces the time required to segment new samples,allowing a faster microtomography analysis of the Carassius auratus heartshape. Furthermore, our framework can work with any bio-image (biological andmedical) from {\mu}-CT with high-resolution and small dataset size</description><author>Pierangela Bruno, Edoardo De Rose, Carlo Adornetto, Francesco Calimeri, Sandro Donato, Raffaele Giuseppe Agostino, Daniela Amelio, Riccardo Barberi, Maria Carmela Cerra, Maria Caterina Crocco, Mariacristina Filice, Raffaele Filosa, Gianluigi Greco, Sandra Imbrogno, Vincenzo Formoso</author><pubDate>Mon, 24 Jun 2024 16:29:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16724v1</guid></item><item><title>Venturing into Uncharted Waters: The Navigation Compass from Transformer to Mamba</title><link>http://arxiv.org/abs/2406.16722v1</link><description>Transformer, a deep neural network architecture, has long dominated the fieldof natural language processing and beyond. Nevertheless, the recentintroduction of Mamba challenges its supremacy, sparks considerable interestamong researchers, and gives rise to a series of Mamba-based models that haveexhibited notable potential. This survey paper orchestrates a comprehensivediscussion, diving into essential research dimensions, covering: (i) thefunctioning of the Mamba mechanism and its foundation on the principles ofstructured state space models; (ii) the proposed improvements and theintegration of Mamba with various networks, exploring its potential as asubstitute for Transformers; (iii) the combination of Transformers and Mamba tocompensate for each other's shortcomings. We have also made efforts tointerpret Mamba and Transformer in the framework of kernel functions, allowingfor a comparison of their mathematical nature within a unified context. Ourpaper encompasses the vast majority of improvements related to Mamba to date.</description><author>Yuchen Zou, Yineng Chen, Zuchao Li, Lefei Zhang, Hai Zhao</author><pubDate>Mon, 24 Jun 2024 16:27:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16722v1</guid></item><item><title>FT-AED: Benchmark Dataset for Early Freeway Traffic Anomalous Event Detection</title><link>http://arxiv.org/abs/2406.15283v2</link><description>Early and accurate detection of anomalous events on the freeway, such asaccidents, can improve emergency response and clearance. However, existingdelays and errors in event identification and reporting make it a difficultproblem to solve. Current large-scale freeway traffic datasets are not designedfor anomaly detection and ignore these challenges. In this paper, we introducethe first large-scale lane-level freeway traffic dataset for anomaly detection.Our dataset consists of a month of weekday radar detection sensor datacollected in 4 lanes along an 18-mile stretch of Interstate 24 heading towardNashville, TN, comprising over 3.7 million sensor measurements. We also collectofficial crash reports from the Nashville Traffic Management Center andmanually label all other potential anomalies in the dataset. To show thepotential for our dataset to be used in future machine learning and trafficresearch, we benchmark numerous deep learning anomaly detection models on ourdataset. We find that unsupervised graph neural network autoencoders are apromising solution for this problem and that ignoring spatial relationshipsleads to decreased performance. We demonstrate that our methods can reducereporting delays by over 10 minutes on average while detecting 75% of crashes.Our dataset and all preprocessing code needed to get started are publiclyreleased at https://vu.edu/ft-aed/ to facilitate future research.</description><author>Austin Coursey, Junyi Ji, Marcos Quinones-Grueiro, William Barbour, Yuhang Zhang, Tyler Derr, Gautam Biswas, Daniel B. Work</author><pubDate>Mon, 24 Jun 2024 16:24:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15283v2</guid></item><item><title>State Representation Learning Using an Unbalanced Atlas</title><link>http://arxiv.org/abs/2305.10267v3</link><description>The manifold hypothesis posits that high-dimensional data often lies on alower-dimensional manifold and that utilizing this manifold as the target spaceyields more efficient representations. While numerous traditionalmanifold-based techniques exist for dimensionality reduction, their applicationin self-supervised learning has witnessed slow progress. The recent MSimCLRmethod combines manifold encoding with SimCLR but requires extremely low targetencoding dimensions to outperform SimCLR, limiting its applicability. Thispaper introduces a novel learning paradigm using an unbalanced atlas (UA),capable of surpassing state-of-the-art self-supervised learning approaches. Weinvestigated and engineered the DeepInfomax with an unbalanced atlas (DIM-UA)method by adapting the Spatiotemporal DeepInfomax (ST-DIM) framework to alignwith our proposed UA paradigm. The efficacy of DIM-UA is demonstrated throughtraining and evaluation on the Atari Annotated RAM Interface (AtariARI)benchmark, a modified version of the Atari 2600 framework that producesannotated image samples for representation learning. The UA paradigm improvesexisting algorithms significantly as the number of target encoding dimensionsgrows. For instance, the mean F1 score averaged over categories of DIM-UA is~75% compared to ~70% of ST-DIM when using 16384 hidden units.</description><author>Li Meng, Morten Goodwin, Anis Yazidi, Paal Engelstad</author><pubDate>Mon, 24 Jun 2024 16:19:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10267v3</guid></item><item><title>GC-Bench: A Benchmark Framework for Graph Condensation with New Insights</title><link>http://arxiv.org/abs/2406.16715v1</link><description>Graph condensation (GC) is an emerging technique designed to learn asignificantly smaller graph that retains the essential information of theoriginal graph. This condensed graph has shown promise in accelerating graphneural networks while preserving performance comparable to those achieved withthe original, larger graphs. Additionally, this technique facilitatesdownstream applications such as neural architecture search and enhances ourunderstanding of redundancy in large graphs. Despite the rapid development ofGC methods, a systematic evaluation framework remains absent, which isnecessary to clarify the critical designs for particular evaluative aspects.Furthermore, several meaningful questions have not been investigated, such aswhether GC inherently preserves certain graph properties and offers robustnesseven without targeted design efforts. In this paper, we introduce GC-Bench, acomprehensive framework to evaluate recent GC methods across multipledimensions and to generate new insights. Our experimental findings provide adeeper insights into the GC process and the characteristics of condensedgraphs, guiding future efforts in enhancing performance and exploring newapplications. Our code is available at\url{https://github.com/Emory-Melody/GraphSlim/tree/main/benchmark}.</description><author>Shengbo Gong, Juntong Ni, Noveen Sachdeva, Carl Yang, Wei Jin</author><pubDate>Mon, 24 Jun 2024 16:17:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16715v1</guid></item><item><title>AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models</title><link>http://arxiv.org/abs/2406.16714v1</link><description>Although Large Language Models (LLMs) are becoming increasingly powerful,they still exhibit significant but subtle weaknesses, such as mistakes ininstruction-following or coding tasks. As these unexpected errors could lead tosevere consequences in practical deployments, it is crucial to investigate thelimitations within LLMs systematically. Traditional benchmarking approachescannot thoroughly pinpoint specific model deficiencies, while manualinspections are costly and not scalable. In this paper, we introduce a unifiedframework, AutoDetect, to automatically expose weaknesses in LLMs acrossvarious tasks. Inspired by the educational assessment process that measuresstudents' learning outcomes, AutoDetect consists of three LLM-powered agents:Examiner, Questioner, and Assessor. The collaboration among these three agentsis designed to realize comprehensive and in-depth weakness identification. Ourframework demonstrates significant success in uncovering flaws, with anidentification success rate exceeding 30% in prominent models such as ChatGPTand Claude. More importantly, these identified weaknesses can guide specificmodel improvements, proving more effective than untargeted data augmentationmethods like Self-Instruct. Our approach has led to substantial enhancements inpopular LLMs, including the Llama series and Mistral-7b, boosting theirperformance by over 10% across several benchmarks. Code and data are publiclyavailable at https://github.com/thu-coai/AutoDetect.</description><author>Jiale Cheng, Yida Lu, Xiaotao Gu, Pei Ke, Xiao Liu, Yuxiao Dong, Hongning Wang, Jie Tang, Minlie Huang</author><pubDate>Mon, 24 Jun 2024 16:16:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16714v1</guid></item><item><title>When Parts are Greater Than Sums: Individual LLM Components Can Outperform Full Models</title><link>http://arxiv.org/abs/2406.13131v2</link><description>This paper studies in-context learning (ICL) by decomposing the output oflarge language models into the individual contributions of attention heads andMLPs (components). We observe curious components: good-performing ones thatindividually do well on a classification task, even when the model performspoorly; bad-performing ones that do much worse than chance; and label-biasedcomponents that always predict the same label. We find that componentaccuracies are well-correlated across different demonstration sets andperturbations of prompt templates, even when the full-model accuracy variesgreatly. Based on our findings, we propose component reweighting, which learnsto linearly re-scale the component activations from a few labeled examples.Given 24 labeled examples, our method improves by an average of 6.0% accuracypoints over 24-shot ICL across 8 tasks on Llama-2-7B. Overall, this paper bothenriches our understanding of ICL and provides a practical method forimprovement by examining model internals.</description><author>Ting-Yun Chang, Jesse Thomason, Robin Jia</author><pubDate>Mon, 24 Jun 2024 16:13:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13131v2</guid></item><item><title>Portrait3D: 3D Head Generation from Single In-the-wild Portrait Image</title><link>http://arxiv.org/abs/2406.16710v1</link><description>While recent works have achieved great success on one-shot 3D common objectgeneration, high quality and fidelity 3D head generation from a single imageremains a great challenge. Previous text-based methods for generating 3D headswere limited by text descriptions and image-based methods struggled to producehigh-quality head geometry. To handle this challenging problem, we propose anovel framework, Portrait3D, to generate high-quality 3D heads while preservingtheir identities. Our work incorporates the identity information of theportrait image into three parts: 1) geometry initialization, 2) geometrysculpting, and 3) texture generation stages. Given a reference portrait image,we first align the identity features with text features to realize ID-awareguidance enhancement, which contains the control signals representing the faceinformation. We then use the canny map, ID features of the portrait image, anda pre-trained text-to-normal/depth diffusion model to generate ID-awaregeometry supervision, and 3D-GAN inversion is employed to generate ID-awaregeometry initialization. Furthermore, with the ability to inject identityinformation into 3D head generation, we use ID-aware guidance to calculateID-aware Score Distillation (ISD) for geometry sculpting. For texturegeneration, we adopt the ID Consistent Texture Inpainting and Refinement whichprogressively expands the view for texture inpainting to obtain aninitialization UV texture map. We then use the id-aware guidance to provideimage-level supervision for noisy multi-view images to obtain a refined texturemap. Extensive experiments demonstrate that we can generate high-quality 3Dheads with accurate geometry and texture from single in-the-wild portraitimages. The project page is at https://jinkun-hao.github.io/Portrait3D/.</description><author>Jinkun Hao, Junshu Tang, Jiangning Zhang, Ran Yi, Yijia Hong, Moran Li, Weijian Cao, Yating Wang, Lizhuang Ma</author><pubDate>Mon, 24 Jun 2024 16:11:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16710v1</guid></item><item><title>Asymmetrical Siamese Network for Point Clouds Normal Estimation</title><link>http://arxiv.org/abs/2406.09681v2</link><description>In recent years, deep learning-based point cloud normal estimation has madegreat progress. However, existing methods mainly rely on the PCPNet dataset,leading to overfitting. In addition, the correlation between point clouds withdifferent noise scales remains unexplored, resulting in poor performance incross-domain scenarios. In this paper, we explore the consistency of intrinsicfeatures learned from clean and noisy point clouds using an Asymmetric SiameseNetwork architecture. By applying reasonable constraints between featuresextracted from different branches, we enhance the quality of normal estimation.Moreover, we introduce a novel multi-view normal estimation dataset thatincludes a larger variety of shapes with different noise levels. Evaluation ofexisting methods on this new dataset reveals their inability to adapt todifferent types of shapes, indicating a degree of overfitting. Extensiveexperiments show that the proposed dataset poses significant challenges forpoint cloud normal estimation and that our feature constraint mechanismeffectively improves upon existing methods and reduces overfitting in currentarchitectures.</description><author>Wei Jin, Jun Zhou, Nannan Li, Haba Madeline, Xiuping Liu</author><pubDate>Mon, 24 Jun 2024 16:11:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.09681v2</guid></item><item><title>CausalFormer: An Interpretable Transformer for Temporal Causal Discovery</title><link>http://arxiv.org/abs/2406.16708v1</link><description>Temporal causal discovery is a crucial task aimed at uncovering the causalrelations within time series data. The latest temporal causal discovery methodsusually train deep learning models on prediction tasks to uncover the causalitybetween time series. They capture causal relations by analyzing the parametersof some components of the trained models, e.g., attention weights andconvolution weights. However, this is an incomplete mapping process from themodel parameters to the causality and fails to investigate the othercomponents, e.g., fully connected layers and activation functions, that arealso significant for causal discovery. To facilitate the utilization of thewhole deep learning models in temporal causal discovery, we proposed aninterpretable transformer-based causal discovery model termed CausalFormer,which consists of the causality-aware transformer and the decomposition-basedcausality detector. The causality-aware transformer learns the causalrepresentation of time series data using a prediction task with the designedmulti-kernel causal convolution which aggregates each input time series alongthe temporal dimension under the temporal priority constraint. Then, thedecomposition-based causality detector interprets the global structure of thetrained causality-aware transformer with the proposed regression relevancepropagation to identify potential causal relations and finally construct thecausal graph. Experiments on synthetic, simulated, and real datasetsdemonstrate the state-of-the-art performance of CausalFormer on discoveringtemporal causality. Our code is available athttps://github.com/lingbai-kong/CausalFormer.</description><author>Lingbai Kong, Wengen Li, Hanchen Yang, Yichao Zhang, Jihong Guan, Shuigeng Zhou</author><pubDate>Mon, 24 Jun 2024 16:09:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16708v1</guid></item><item><title>Probabilistic Subgoal Representations for Hierarchical Reinforcement learning</title><link>http://arxiv.org/abs/2406.16707v1</link><description>In goal-conditioned hierarchical reinforcement learning (HRL), a high-levelpolicy specifies a subgoal for the low-level policy to reach. Effective HRLhinges on a suitable subgoal represen tation function, abstracting state spaceinto latent subgoal space and inducing varied low-level behaviors. Existingmethods adopt a subgoal representation that provides a deterministic mappingfrom state space to latent subgoal space. Instead, this paper utilizes GaussianProcesses (GPs) for the first probabilistic subgoal representation. Our methodemploys a GP prior on the latent subgoal space to learn a posteriordistribution over the subgoal representation functions while exploiting thelong-range correlation in the state space through learnable kernels. Thisenables an adaptive memory that integrates long-range subgoal information fromprior planning steps allowing to cope with stochastic uncertainties.Furthermore, we propose a novel learning objective to facilitate thesimultaneous learning of probabilistic subgoal representations and policieswithin a unified framework. In experiments, our approach outperformsstate-of-the-art baselines in standard benchmarks but also in environments withstochastic elements and under diverse reward conditions. Additionally, ourmodel shows promising capabilities in transferring low-level policies acrossdifferent tasks.</description><author>Vivienne Huiling Wang, Tinghuai Wang, Wenyan Yang, Joni-Kristian Kämäräinen, Joni Pajarinen</author><pubDate>Mon, 24 Jun 2024 16:09:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16707v1</guid></item><item><title>Incorporating temporal dynamics of mutations to enhance the prediction capability of antiretroviral therapy's outcome for HIV-1</title><link>http://arxiv.org/abs/2311.04846v2</link><description>Motivation: In predicting HIV therapy outcomes, a critical clinical questionis whether using historical information can enhance predictive capabilitiescompared with current or latest available data analysis. This study analyseswhether historical knowledge, which includes viral mutations detected in allgenotypic tests before therapy, their temporal occurrence, and concomitantviral load measurements, can bring improvements. We introduce a method to weighmutations, considering the previously enumerated factors and the referencemutation-drug Stanford resistance tables. We compare a model encompassinghistory (H) with one not using it (NH). Results: The H-model demonstratessuperior discriminative ability, with a higher ROC-AUC score (76.34%) than theNH-model (74.98%). Significant Wilcoxon test results confirm that incorporatinghistorical information improves consistently predictive accuracy for treatmentoutcomes. The better performance of the H-model might be attributed to itsconsideration of latent HIV reservoirs, probably obtained when leveraginghistorical information. The findings emphasize the importance of temporaldynamics in mutations, offering insights into HIV infection complexities.However, our result also shows that prediction accuracy remains relatively higheven when no historical information is available. Supplementary information:Supplementary material is available.</description><author>Giulia Di Teodoro, Martin Pirkl, Francesca Incardona, Ilaria Vicenti, Anders Sönnerborg, Rolf Kaiser, Laura Palagi, Maurizio Zazzi, Thomas Lengauer</author><pubDate>Mon, 24 Jun 2024 16:07:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04846v2</guid></item><item><title>QUBIQ: Uncertainty Quantification for Biomedical Image Segmentation Challenge</title><link>http://arxiv.org/abs/2405.18435v2</link><description>Uncertainty in medical image segmentation tasks, especially inter-ratervariability, arising from differences in interpretations and annotations byvarious experts, presents a significant challenge in achieving consistent andreliable image segmentation. This variability not only reflects the inherentcomplexity and subjective nature of medical image interpretation but alsodirectly impacts the development and evaluation of automated segmentationalgorithms. Accurately modeling and quantifying this variability is essentialfor enhancing the robustness and clinical applicability of these algorithms. Wereport the set-up and summarize the benchmark results of the Quantification ofUncertainties in Biomedical Image Quantification Challenge (QUBIQ), which wasorganized in conjunction with International Conferences on Medical ImageComputing and Computer-Assisted Intervention (MICCAI) 2020 and 2021. Thechallenge focuses on the uncertainty quantification of medical imagesegmentation which considers the omnipresence of inter-rater variability inimaging datasets. The large collection of images with multi-rater annotationsfeatures various modalities such as MRI and CT; various organs such as thebrain, prostate, kidney, and pancreas; and different image dimensions 2D-vs-3D.A total of 24 teams submitted different solutions to the problem, combiningvarious baseline models, Bayesian neural networks, and ensemble modeltechniques. The obtained results indicate the importance of the ensemblemodels, as well as the need for further research to develop efficient 3Dmethods for uncertainty quantification methods in 3D segmentation tasks.</description><author>Hongwei Bran Li, Fernando Navarro, Ivan Ezhov, Amirhossein Bayat, Dhritiman Das, Florian Kofler, Suprosanna Shit, Diana Waldmannstetter, Johannes C. Paetzold, Xiaobin Hu, Benedikt Wiestler, Lucas Zimmer, Tamaz Amiranashvili, Chinmay Prabhakar, Christoph Berger, Jonas Weidner, Michelle Alonso-Basant, Arif Rashid, Ujjwal Baid, Wesam Adel, Deniz Ali, Bhakti Baheti, Yingbin Bai, Ishaan Bhatt, Sabri Can Cetindag, Wenting Chen, Li Cheng, Prasad Dutand, Lara Dular, Mustafa A. Elattar, Ming Feng, Shengbo Gao, Henkjan Huisman, Weifeng Hu, Shubham Innani, Wei Jiat, Davood Karimi, Hugo J. Kuijf, Jin Tae Kwak, Hoang Long Le, Xiang Lia, Huiyan Lin, Tongliang Liu, Jun Ma, Kai Ma, Ting Ma, Ilkay Oksuz, Robbie Holland, Arlindo L. Oliveira, Jimut Bahan Pal, Xuan Pei, Maoying Qiao, Anindo Saha, Raghavendra </author><pubDate>Mon, 24 Jun 2024 16:07:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18435v2</guid></item><item><title>Demystifying the Effect of Receptive Field Size in U-Net Models for Medical Image Segmentation</title><link>http://arxiv.org/abs/2406.16701v1</link><description>Medical image segmentation is a critical task in healthcare applications, andU-Nets have demonstrated promising results. This work delves into theunderstudied aspect of receptive field (RF) size and its impact on the U-Netand Attention U-Net architectures. This work explores several critical elementsincluding the relationship between RF size, characteristics of the region ofinterest, and model performance, as well as the balance between RF size andcomputational costs for U-Net and Attention U-Net methods for differentdatasets. This work also proposes a mathematical notation for representing thetheoretical receptive field (TRF) of a given layer in a network and proposestwo new metrics - effective receptive field (ERF) rate and the Object rate toquantify the fraction of significantly contributing pixels within the ERFagainst the TRF area and assessing the relative size of the segmentation objectcompared to the TRF size respectively. The results demonstrate that thereexists an optimal TRF size that successfully strikes a balance betweencapturing a wider global context and maintaining computational efficiency,thereby optimizing model performance. Interestingly, a distinct correlation isobserved between the data complexity and the required TRF size; segmentationbased solely on contrast achieved peak performance even with smaller TRF sizes,whereas more complex segmentation tasks necessitated larger TRFs. AttentionU-Net models consistently outperformed their U-Net counterparts, highlightingthe value of attention mechanisms regardless of TRF size. These novel insightspresent an invaluable resource for developing more efficient U-Net-basedarchitectures for medical imaging and pave the way for future exploration. Atool is also developed that calculates the TRF for a U-Net (and AttentionU-Net) model, and also suggest an appropriate TRF size for a given model anddataset.</description><author>Vincent Loos, Rohit Pardasani, Navchetan Awasthi</author><pubDate>Mon, 24 Jun 2024 16:04:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16701v1</guid></item></channel></rss>