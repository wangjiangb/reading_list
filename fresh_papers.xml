<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 26 Jul 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Benchmarking and Analyzing Generative Data for Visual Recognition</title><link>http://arxiv.org/abs/2307.13697v1</link><description>Advancements in large pre-trained generative models have expanded theirpotential as effective data generators in visual recognition. This work delvesinto the impact of generative images, primarily comparing paradigms thatharness external data (\ie generative \vs retrieval \vs original). Our key contributions are: \textbf{1) GenBench Construction:} We devise\textbf{GenBench}, a broad benchmark comprising 22 datasets with 2548categories, to appraise generative data across various visual recognitiontasks. \textbf{2) CLER Score:} To address the insufficient correlation ofexisting metrics (\eg, FID, CLIP score) with downstream recognitionperformance, we propose \textbf{CLER}, a training-free metric indicatinggenerative data's efficiency for recognition tasks prior to training.\textbf{3) New Baselines:} Comparisons of generative data with retrieved datafrom the same external pool help to elucidate the unique traits of generativedata. \textbf{4) External Knowledge Injection:} By fine-tuning special tokenembeddings for each category via Textual Inversion, performance improves across17 datasets, except when dealing with low-resolution reference images. Our exhaustive benchmark and analysis spotlight generative data's promise invisual recognition, while identifying key challenges for future investigation.</description><author>Bo Li, Haotian Liu, Liangyu Chen, Yong Jae Lee, Chunyuan Li, Ziwei Liu</author><pubDate>Tue, 25 Jul 2023 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13697v1</guid></item><item><title>Evaluating Large Language Models for Radiology Natural Language Processing</title><link>http://arxiv.org/abs/2307.13693v1</link><description>The rise of large language models (LLMs) has marked a pivotal shift in thefield of natural language processing (NLP). LLMs have revolutionized amultitude of domains, and they have made a significant impact in the medicalfield. Large language models are now more abundant than ever, and many of thesemodels exhibit bilingual capabilities, proficient in both English and Chinese.However, a comprehensive evaluation of these models remains to be conducted.This lack of assessment is especially apparent within the context of radiologyNLP. This study seeks to bridge this gap by critically evaluating thirty twoLLMs in interpreting radiology reports, a crucial component of radiology NLP.Specifically, the ability to derive impressions from radiologic findings isassessed. The outcomes of this evaluation provide key insights into theperformance, strengths, and weaknesses of these LLMs, informing their practicalapplications within the medical domain.</description><author>Zhengliang Liu, Tianyang Zhong, Yiwei Li, Yutong Zhang, Yi Pan, Zihao Zhao, Peixin Dong, Chao Cao, Yuxiao Liu, Peng Shu, Yaonai Wei, Zihao Wu, Chong Ma, Jiaqi Wang, Sheng Wang, Mengyue Zhou, Zuowei Jiang, Chunlin Li, Shaochen Xu, Lu Zhang, Haixing Dai, Kai Zhang, Xu Liu, Lin Zhao, Peilong Wang, Pingkun Yan, Jun Liu, Bao Ge, Lichao Sun, Dajiang Zhu, Xiang Li, Wei Liu, Xiaoyan Cai, Xintao Hu, Xi Jiang, Shu Zhang, Xin Zhang, Tuo Zhang, Shijie Zhao, Quanzheng Li, Hongtu Zhu, Dinggang Shen, Tianming Liu</author><pubDate>Tue, 25 Jul 2023 18:57:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13693v1</guid></item><item><title>Towards a Visual-Language Foundation Model for Computational Pathology</title><link>http://arxiv.org/abs/2307.12914v2</link><description>The accelerated adoption of digital pathology and advances in deep learninghave enabled the development of powerful models for various pathology tasksacross a diverse array of diseases and patient cohorts. However, model trainingis often difficult due to label scarcity in the medical domain and the model'susage is limited by the specific task and disease for which it is trained.Additionally, most models in histopathology leverage only image data, a starkcontrast to how humans teach each other and reason about histopathologicentities. We introduce CONtrastive learning from Captions for Histopathology(CONCH), a visual-language foundation model developed using diverse sources ofhistopathology images, biomedical text, and notably over 1.17 millionimage-caption pairs via task-agnostic pretraining. Evaluated on a suite of 13diverse benchmarks, CONCH can be transferred to a wide range of downstreamtasks involving either or both histopathology images and text, achievingstate-of-the-art performance on histology image classification, segmentation,captioning, text-to-image and image-to-text retrieval. CONCH represents asubstantial leap over concurrent visual-language pretrained systems forhistopathology, with the potential to directly facilitate a wide array ofmachine learning-based workflows requiring minimal or no further supervisedfine-tuning.</description><author>Ming Y. Lu, Bowen Chen, Drew F. K. Williamson, Richard J. Chen, Ivy Liang, Tong Ding, Guillaume Jaume, Igor Odintsov, Andrew Zhang, Long Phi Le, Georg Gerber, Anil V Parwani, Faisal Mahmood</author><pubDate>Tue, 25 Jul 2023 18:56:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12914v2</guid></item><item><title>ARB: Advanced Reasoning Benchmark for Large Language Models</title><link>http://arxiv.org/abs/2307.13692v1</link><description>Large Language Models (LLMs) have demonstrated remarkable performance onvarious quantitative reasoning and knowledge benchmarks. However, many of thesebenchmarks are losing utility as LLMs get increasingly high scores, despite notyet reaching expert performance in these domains. We introduce ARB, a novelbenchmark composed of advanced reasoning problems in multiple fields. ARBpresents a more challenging test than prior benchmarks, featuring problems inmathematics, physics, biology, chemistry, and law. As a subset of ARB, weintroduce a challenging set of math and physics problems which require advancedsymbolic reasoning and domain knowledge. We evaluate recent models such asGPT-4 and Claude on ARB and demonstrate that current models score well below50% on more demanding tasks. In order to improve both automatic and assistedevaluation capabilities, we introduce a rubric-based evaluation approach,allowing GPT-4 to score its own intermediate reasoning steps. Further, weconduct a human evaluation of the symbolic subset of ARB, finding promisingagreement between annotators and GPT-4 rubric evaluation scores.</description><author>Tomohiro Sawada, Daniel Paleka, Alexander Havrilla, Pranav Tadepalli, Paula Vidas, Alexander Kranias, John J. Nay, Kshitij Gupta, Aran Komatsuzaki</author><pubDate>Tue, 25 Jul 2023 18:55:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13692v1</guid></item><item><title>Geometric Wavelet Scattering Networks on Compact Riemannian Manifolds</title><link>http://arxiv.org/abs/1905.10448v4</link><description>The Euclidean scattering transform was introduced nearly a decade ago toimprove the mathematical understanding of convolutional neural networks.Inspired by recent interest in geometric deep learning, which aims togeneralize convolutional neural networks to manifold and graph-structureddomains, we define a geometric scattering transform on manifolds. Similar tothe Euclidean scattering transform, the geometric scattering transform is basedon a cascade of wavelet filters and pointwise nonlinearities. It is invariantto local isometries and stable to certain types of diffeomorphisms. Empiricalresults demonstrate its utility on several geometric learning tasks. Ourresults generalize the deformation stability and local translation invarianceof Euclidean scattering, and demonstrate the importance of linking the usedfilter structures to the underlying geometry of the data.</description><author>Michael Perlmutter, Feng Gao, Guy Wolf, Matthew Hirn</author><pubDate>Tue, 25 Jul 2023 18:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1905.10448v4</guid></item><item><title>Stabilizing Transformer Training by Preventing Attention Entropy Collapse</title><link>http://arxiv.org/abs/2303.06296v2</link><description>Training stability is of great importance to Transformers. In this work, weinvestigate the training dynamics of Transformers by examining the evolution ofthe attention layers. In particular, we track the attention entropy for eachattention head during the course of training, which is a proxy for modelsharpness. We identify a common pattern across different architectures andtasks, where low attention entropy is accompanied by high training instability,which can take the form of oscillating loss or divergence. We denote thepathologically low attention entropy, corresponding to highly concentratedattention scores, as $\textit{entropy collapse}$. As a remedy, we propose$\sigma$Reparam, a simple and efficient solution where we reparametrize alllinear layers with spectral normalization and an additional learned scalar. Wedemonstrate that $\sigma$Reparam successfully prevents entropy collapse in theattention layers, promoting more stable training. Additionally, we prove atight lower bound of the attention entropy, which decreases exponentially fastwith the spectral norm of the attention logits, providing additional motivationfor our approach. We conduct experiments with $\sigma$Reparam on imageclassification, image self-supervised learning, machine translation, speechrecognition, and language modeling tasks. We show that $\sigma$Reparam providesstability and robustness with respect to the choice of hyperparameters, goingso far as enabling training (a) a Vision Transformer {to competitiveperformance} without warmup, weight decay, layer normalization or adaptiveoptimizers; (b) deep architectures in machine translation and (c) speechrecognition to competitive performance without warmup and adaptive optimizers.Code is available at \url{https://github.com/apple/ml-sigma-reparam}.</description><author>Shuangfei Zhai, Tatiana Likhomanenko, Etai Littwin, Dan Busbridge, Jason Ramapuram, Yizhe Zhang, Jiatao Gu, Josh Susskind</author><pubDate>Tue, 25 Jul 2023 18:42:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06296v2</guid></item><item><title>The Visual Language of Fabrics</title><link>http://arxiv.org/abs/2307.13681v1</link><description>We introduce text2fabric, a novel dataset that links free-text descriptionsto various fabric materials. The dataset comprises 15,000 natural languagedescriptions associated to 3,000 corresponding images of fabric materials.Traditionally, material descriptions come in the form of tags/keywords, whichlimits their expressivity, induces pre-existing knowledge of the appropriatevocabulary, and ultimately leads to a chopped description system. Therefore, westudy the use of free-text as a more appropriate way to describe materialappearance, taking the use case of fabrics as a common item that non-expertsmay often deal with. Based on the analysis of the dataset, we identify acompact lexicon, set of attributes and key structure that emerge from thedescriptions. This allows us to accurately understand how people describefabrics and draw directions for generalization to other types of materials. Wealso show that our dataset enables specializing large vision-language modelssuch as CLIP, creating a meaningful latent space for fabric appearance, andsignificantly improving applications such as fine-grained material retrievaland automatic captioning.</description><author>Valentin Deschaintre, Julia Guerrero-Viu, Diego Gutierrez, Tamy Boubekeur, Belen Masia</author><pubDate>Tue, 25 Jul 2023 18:39:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13681v1</guid></item><item><title>High Probability Analysis for Non-Convex Stochastic Optimization with Clipping</title><link>http://arxiv.org/abs/2307.13680v1</link><description>Gradient clipping is a commonly used technique to stabilize the trainingprocess of neural networks. A growing body of studies has shown that gradientclipping is a promising technique for dealing with the heavy-tailed behaviorthat emerged in stochastic optimization as well. While gradient clipping issignificant, its theoretical guarantees are scarce. Most theoretical guaranteesonly provide an in-expectation analysis and only focus on optimizationperformance. In this paper, we provide high probability analysis in thenon-convex setting and derive the optimization bound and the generalizationbound simultaneously for popular stochastic optimization algorithms withgradient clipping, including stochastic gradient descent and its variants ofmomentum and adaptive stepsizes. With the gradient clipping, we study aheavy-tailed assumption that the gradients only have bounded $\alpha$-thmoments for some $\alpha \in (1, 2]$, which is much weaker than the standardbounded second-moment assumption. Overall, our study provides a relativelycomplete picture for the theoretical guarantee of stochastic optimizationalgorithms with clipping.</description><author>Shaojie Li, Yong Liu</author><pubDate>Tue, 25 Jul 2023 18:36:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13680v1</guid></item><item><title>RED CoMETS: An ensemble classifier for symbolically represented multivariate time series</title><link>http://arxiv.org/abs/2307.13679v1</link><description>Multivariate time series classification is a rapidly growing research fieldwith practical applications in finance, healthcare, engineering, and more. Thecomplexity of classifying multivariate time series data arises from its highdimensionality, temporal dependencies, and varying lengths. This paperintroduces a novel ensemble classifier called RED CoMETS (Random EnhancedCo-eye for Multivariate Time Series), which addresses these challenges. REDCoMETS builds upon the success of Co-eye, an ensemble classifier specificallydesigned for symbolically represented univariate time series, and extends itscapabilities to handle multivariate data. The performance of RED CoMETS isevaluated on benchmark datasets from the UCR archive, where it demonstratescompetitive accuracy when compared to state-of-the-art techniques inmultivariate settings. Notably, it achieves the highest reported accuracy inthe literature for the 'HandMovementDirection' dataset. Moreover, the proposedmethod significantly reduces computation time compared to Co-eye, making it anefficient and effective choice for multivariate time series classification.</description><author>Luca A. Bennett, Zahraa S. Abdallah</author><pubDate>Tue, 25 Jul 2023 18:36:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13679v1</guid></item><item><title>Efficiently Learning One-Hidden-Layer ReLU Networks via Schur Polynomials</title><link>http://arxiv.org/abs/2307.12840v2</link><description>We study the problem of PAC learning a linear combination of $k$ ReLUactivations under the standard Gaussian distribution on $\mathbb{R}^d$ withrespect to the square loss. Our main result is an efficient algorithm for thislearning task with sample and computational complexity $(dk/\epsilon)^{O(k)}$,where $\epsilon&gt;0$ is the target accuracy. Prior work had given an algorithmfor this problem with complexity $(dk/\epsilon)^{h(k)}$, where the function$h(k)$ scales super-polynomially in $k$. Interestingly, the complexity of ouralgorithm is near-optimal within the class of Correlational Statistical Queryalgorithms. At a high-level, our algorithm uses tensor decomposition toidentify a subspace such that all the $O(k)$-order moments are small in theorthogonal directions. Its analysis makes essential use of the theory of Schurpolynomials to show that the higher-moment error tensors are small given thatthe lower-order ones are.</description><author>Ilias Diakonikolas, Daniel M. Kane</author><pubDate>Tue, 25 Jul 2023 18:25:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12840v2</guid></item><item><title>Accelerated primal-dual methods with enlarged step sizes and operator learning for nonsmooth optimal control problems</title><link>http://arxiv.org/abs/2307.00296v2</link><description>We consider a general class of nonsmooth optimal control problems withpartial differential equation (PDE) constraints, which are very challenging dueto its nonsmooth objective functionals and the resulting high-dimensional andill-conditioned systems after discretization. We focus on the application of aprimal-dual method, with which different types of variables can be treatedindividually and thus its main computation at each iteration only requiressolving two PDEs. Our target is to accelerate the primal-dual method witheither larger step sizes or operator learning techniques. For the acceleratedprimal-dual method with larger step sizes, its convergence can be still provedrigorously while it numerically accelerates the original primal-dual method ina simple and universal way. For the operator learning acceleration, weconstruct deep neural network surrogate models for the involved PDEs. Once aneural operator is learned, solving a PDE requires only a forward pass of theneural network, and the computational cost is thus substantially reduced. Theaccelerated primal-dual method with operator learning is mesh-free, numericallyefficient, and scalable to different types of PDEs. The accelerationeffectiveness of these two techniques is promisingly validated by somepreliminary numerical results.</description><author>Yongcun Song, Xiaoming Yuan, Hangrui Yue</author><pubDate>Tue, 25 Jul 2023 18:15:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00296v2</guid></item><item><title>Sharp Convergence Rates for Matching Pursuit</title><link>http://arxiv.org/abs/2307.07679v2</link><description>We study the fundamental limits of matching pursuit, or the pure greedyalgorithm, for approximating a target function by a sparse linear combinationof elements from a dictionary. When the target function is contained in thevariation space corresponding to the dictionary, many impressive works over thepast few decades have obtained upper and lower bounds on the error of matchingpursuit, but they do not match. The main contribution of this paper is to closethis gap and obtain a sharp characterization of the decay rate of matchingpursuit. Specifically, we construct a worst case dictionary which shows thatthe existing best upper bound cannot be significantly improved. It turns outthat, unlike other greedy algorithm variants, the converge rate is suboptimaland is determined by the solution to a certain non-linear equation. Thisenables us to conclude that any amount of shrinkage improves matching pursuitin the worst case.</description><author>Jason M. Klusowski, Jonathan W. Siegel</author><pubDate>Tue, 25 Jul 2023 18:12:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07679v2</guid></item><item><title>Towards an AI Accountability Policy</title><link>http://arxiv.org/abs/2307.13658v1</link><description>This white paper is a response to the "AI Accountability Policy Request forComments" by the National Telecommunications and Information Administration ofthe United States. The question numbers for which comments were requested areprovided in superscripts at the end of key sentences answering the respectivequestions. The white paper offers a set of interconnected recommendations foran AI accountability policy.</description><author>Przemyslaw Grabowicz, Nicholas Perello, Yair Zick</author><pubDate>Tue, 25 Jul 2023 18:09:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13658v1</guid></item><item><title>A Comprehensive Evaluation and Analysis Study for Chinese Spelling Check</title><link>http://arxiv.org/abs/2307.13655v1</link><description>With the development of pre-trained models and the incorporation of phoneticand graphic information, neural models have achieved high scores in ChineseSpelling Check (CSC). However, it does not provide a comprehensive reflectionof the models' capability due to the limited test sets. In this study, weabstract the representative model paradigm, implement it with nine structuresand experiment them on comprehensive test sets we constructed with differentpurposes. We perform a detailed analysis of the results and find that: 1)Fusing phonetic and graphic information reasonably is effective for CSC. 2)Models are sensitive to the error distribution of the test set, which reflectsthe shortcomings of models and reveals the direction we should work on. 3)Whether or not the errors and contexts have been seen has a significant impacton models. 4) The commonly used benchmark, SIGHAN, can not reliably evaluatemodels' performance.</description><author>Xunjian Yin, Xiaojun Wan</author><pubDate>Tue, 25 Jul 2023 18:02:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13655v1</guid></item><item><title>Personal Protective Equipment Detection in Extreme Construction Conditions</title><link>http://arxiv.org/abs/2307.13654v1</link><description>Object detection has been widely applied for construction safety management,especially personal protective equipment (PPE) detection. Though the existingPPE detection models trained on conventional datasets have achieved excellentresults, their performance dramatically declines in extreme constructionconditions. A robust detection model NST-YOLOv5 is developed by combining theneural style transfer (NST) and YOLOv5 technologies. Five extreme conditionsare considered and simulated via the NST module to endow the detection modelwith excellent robustness, including low light, intense light, sand dust, fog,and rain. Experiments show that the NST has great potential as a tool forextreme data synthesis since it is better at simulating extreme conditions thanother traditional image processing algorithms and helps the NST-YOLOv5 achieve0.141 and 0.083 mAP_(05:95) improvements in synthesized and real-world extremedata. This study provides a new feasible way to obtain a more robust detectionmodel for extreme construction conditions.</description><author>Yuexiong Ding, Xiaowei Luo</author><pubDate>Tue, 25 Jul 2023 18:01:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13654v1</guid></item><item><title>Generalizing DP-SGD with Shuffling and Batch Clipping</title><link>http://arxiv.org/abs/2212.05796v3</link><description>Classical differential private DP-SGD implements individual clipping withrandom subsampling, which forces a mini-batch SGD approach. We provide ageneral differential private algorithmic framework that goes beyond DP-SGD andallows any possible first order optimizers (e.g., classical SGD and momentumbased SGD approaches) in combination with batch clipping, which clips anaggregate of computed gradients rather than summing clipped gradients (as isdone in individual clipping). The framework also admits sampling techniquesbeyond random subsampling such as shuffling. Our DP analysis follows the $f$-DPapproach and introduces a new proof technique which allows us to derive simpleclosed form expressions and to also analyse group privacy. In particular, for$E$ epochs work and groups of size $g$, we show a $\sqrt{g E}$ DP dependencyfor batch clipping with shuffling.</description><author>Marten van Dijk, Phuong Ha Nguyen, Toan N. Nguyen, Lam M. Nguyen</author><pubDate>Tue, 25 Jul 2023 17:57:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.05796v3</guid></item><item><title>QuickQual: Lightweight, convenient retinal image quality scoring with off-the-shelf pretrained models</title><link>http://arxiv.org/abs/2307.13646v1</link><description>Image quality remains a key problem for both traditional and deep learning(DL)-based approaches to retinal image analysis, but identifying poor qualityimages can be time consuming and subjective. Thus, automated methods forretinal image quality scoring (RIQS) are needed. The current state-of-the-artis MCFNet, composed of three Densenet121 backbones each operating in adifferent colour space. MCFNet, and the EyeQ dataset released by the sameauthors, was a huge step forward for RIQS. We present QuickQual, a simpleapproach to RIQS, consisting of a single off-the-shelf ImageNet-pretrainedDensenet121 backbone plus a Support Vector Machine (SVM). QuickQual performsvery well, setting a new state-of-the-art for EyeQ (Accuracy: 88.50% vs 88.00%for MCFNet; AUC: 0.9687 vs 0.9588). This suggests that RIQS can be solved withgeneric perceptual features learned on natural images, as opposed to requiringDL models trained on large amounts of fundus images. Additionally, we propose aFixed Prior linearisation scheme, that converts EyeQ from a 3-wayclassification to a continuous logistic regression task. For this task, wepresent a second model, QuickQual MEga Minified Estimator (QuickQual-MEME),that consists of only 10 parameters on top of an off-the-shelf Densenet121 andcan distinguish between gradable and ungradable images with an accuracy of89.18% (AUC: 0.9537). Code and model are available on GitHub:https://github.com/justinengelmann/QuickQual . QuickQual is so lightweight,that the entire inference code (and even the parameters for QuickQual-MEME) isalready contained in this paper.</description><author>Justin Engelmann, Amos Storkey, Miguel O. Bernabeu</author><pubDate>Tue, 25 Jul 2023 17:55:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13646v1</guid></item><item><title>Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation</title><link>http://arxiv.org/abs/2307.13645v1</link><description>Obtaining labelled data in medical image segmentation is challenging due tothe need for pixel-level annotations by experts. Recent works have shown thataugmenting the object of interest with deformable transformations can helpmitigate this challenge. However, these transformations have been learnedglobally for the image, limiting their transferability across datasets orapplicability in problems where image alignment is difficult. Whileobject-centric augmentations provide a great opportunity to overcome theseissues, existing works are only focused on position and random transformationswithout considering shape variations of the objects. To this end, we propose anovel object-centric data augmentation model that is able to learn the shapevariations for the objects of interest and augment the object in place withoutmodifying the rest of the image. We demonstrated its effectiveness in improvingkidney tumour segmentation when leveraging shape variations learned both fromwithin the same dataset and transferred from external datasets.</description><author>Nilesh Kumar, Prashnna K. Gyawali, Sandesh Ghimire, Linwei Wang</author><pubDate>Tue, 25 Jul 2023 17:54:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13645v1</guid></item><item><title>Safety Margins for Reinforcement Learning</title><link>http://arxiv.org/abs/2307.13642v1</link><description>Any autonomous controller will be unsafe in some situations. The ability toquantitatively identify when these unsafe situations are about to occur iscrucial for drawing timely human oversight in, e.g., freight transportationapplications. In this work, we demonstrate that the true criticality of anagent's situation can be robustly defined as the mean reduction in reward givensome number of random actions. Proxy criticality metrics that are computable inreal-time (i.e., without actually simulating the effects of random actions) canbe compared to the true criticality, and we show how to leverage these proxymetrics to generate safety margins, which directly tie the consequences ofpotentially incorrect actions to an anticipated loss in overall performance. Weevaluate our approach on learned policies from APE-X and A3C within an Atarienvironment, and demonstrate how safety margins decrease as agents approachfailure states. The integration of safety margins into programs for monitoringdeployed agents allows for the real-time identification of potentiallycatastrophic situations.</description><author>Alexander Grushin, Walt Woods, Alvaro Velasquez, Simon Khan</author><pubDate>Tue, 25 Jul 2023 17:49:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13642v1</guid></item><item><title>Optical Flow boosts Unsupervised Localization and Segmentation</title><link>http://arxiv.org/abs/2307.13640v1</link><description>Unsupervised localization and segmentation are long-standing robot visionchallenges that describe the critical ability for an autonomous robot to learnto decompose images into individual objects without labeled data. These tasksare important because of the limited availability of dense image manualannotation and the promising vision of adapting to an evolving set of objectcategories in lifelong learning. Most recent methods focus on using visualappearance continuity as object cues by spatially clustering features obtainedfrom self-supervised vision transformers (ViT). In this work, we leveragemotion cues, inspired by the common fate principle that pixels that sharesimilar movements tend to belong to the same object. We propose a new loss termformulation that uses optical flow in unlabeled videos to encourageself-supervised ViT features to become closer to each other if theircorresponding spatial locations share similar movements, and vice versa. We usethe proposed loss function to finetune vision transformers that were originallytrained on static images. Our fine-tuning procedure outperformsstate-of-the-art techniques for unsupervised semantic segmentation throughlinear probing, without the use of any labeled data. This procedure alsodemonstrates increased performance over original ViT networks acrossunsupervised object localization and semantic segmentation benchmarks.</description><author>Xinyu Zhang, Abdeslam Boularias</author><pubDate>Tue, 25 Jul 2023 17:45:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13640v1</guid></item><item><title>Self-supervised video pretraining yields human-aligned visual representations</title><link>http://arxiv.org/abs/2210.06433v2</link><description>Humans learn powerful representations of objects and scenes by observing howthey evolve over time. Yet, outside of specific tasks that require explicittemporal understanding, static image pretraining remains the dominant paradigmfor learning visual foundation models. We question this mismatch, and askwhether video pretraining can yield visual representations that bear thehallmarks of human perception: generalisation across tasks, robustness toperturbations, and consistency with human judgements. To that end we propose anovel procedure for curating videos, and develop a contrastive framework whichlearns from the complex transformations therein. This simple paradigm fordistilling knowledge from videos, called VITO, yields general representationsthat far outperform prior video pretraining methods on image understandingtasks, and image pretraining methods on video understanding tasks. Moreover,VITO representations are significantly more robust to natural and syntheticdeformations than image-, video-, and adversarially-trained ones. Finally,VITO's predictions are strongly aligned with human judgements, surpassingmodels that were specifically trained for that purpose. Together, these resultssuggest that video pretraining could be a simple way of learning unified,robust, and human-aligned representations of the visual world.</description><author>Nikhil Parthasarathy, S. M. Ali Eslami, João Carreira, Olivier J. Hénaff</author><pubDate>Tue, 25 Jul 2023 17:43:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.06433v2</guid></item><item><title>Fake It Without Making It: Conditioned Face Generation for Accurate 3D Face Shape Estimation</title><link>http://arxiv.org/abs/2307.13639v1</link><description>Accurate 3D face shape estimation is an enabling technology with applicationsin healthcare, security, and creative industries, yet current state-of-the-artmethods either rely on self-supervised training with 2D image data orsupervised training with very limited 3D data. To bridge this gap, we present anovel approach which uses a conditioned stable diffusion model for face imagegeneration, leveraging the abundance of 2D facial information to inform 3Dspace. By conditioning stable diffusion on depth maps sampled from a 3DMorphable Model (3DMM) of the human face, we generate diverse andshape-consistent images, forming the basis of SynthFace. We introduce thislarge-scale synthesised dataset of 250K photorealistic images and corresponding3DMM parameters. We further propose ControlFace, a deep neural network, trainedon SynthFace, which achieves competitive performance on the NoW benchmark,without requiring 3D supervision or manual 3D asset creation.</description><author>Will Rowan, Patrik Huber, Nick Pears, Andrew Keeling</author><pubDate>Tue, 25 Jul 2023 17:42:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13639v1</guid></item><item><title>Unification of popular artificial neural network activation functions</title><link>http://arxiv.org/abs/2302.11007v2</link><description>We present a unified representation of the most popular neural networkactivation functions. Adopting Mittag-Leffler functions of fractional calculus,we propose a flexible and compact functional form that is able to interpolatebetween various activation functions and mitigate common problems in trainingneural networks such as vanishing and exploding gradients. The presented gatedrepresentation extends the scope of fixed-shape activation functions to theiradaptive counterparts whose shape can be learnt from the training data. Thederivatives of the proposed functional form can also be expressed in terms ofMittag-Leffler functions making it a suitable candidate for gradient-basedbackpropagation algorithms. By training multiple neural networks of differentcomplexities on various datasets with different sizes, we demonstrate thatadopting a unified gated representation of activation functions offers apromising and affordable alternative to individual built-in implementations ofactivation functions in conventional machine learning frameworks.</description><author>Mohammad Mostafanejad</author><pubDate>Tue, 25 Jul 2023 17:38:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.11007v2</guid></item><item><title>Variability of echo state network prediction horizon for partially observed dynamical systems</title><link>http://arxiv.org/abs/2306.10797v2</link><description>Study of dynamical systems using partial state observation is an importantproblem due to its applicability to many real-world systems. We address theproblem by proposing an echo state network (ESN) framework with partial stateinput with partial or full state output. Application to the Lorenz system andChua's oscillator (both numerically simulated and experimental systems)demonstrate the effectiveness of our method. We show that the ESN, as anautonomous dynamical system, is capable of making short-term predictions up toa few Lyapunov times. However, the prediction horizon has high variabilitydepending on the initial condition - an aspect that we explore in detail usingthe distribution of the prediction horizon. Further, using a variety ofstatistical metrics to compare the long-term dynamics of the ESN predictionswith numerically simulated or experimental dynamics and observed similarresults, we show that the ESN can effectively learn the system's dynamics evenwhen trained with noisy numerical or experimental datasets. Thus, wedemonstrate the potential of ESNs to serve as cheap surrogate models forsimulating the dynamics of systems where complete observations are unavailable.</description><author>Ajit Mahata, Reetish Padhi, Amit Apte</author><pubDate>Tue, 25 Jul 2023 17:33:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10797v2</guid></item><item><title>Contributions to the Improvement of Question Answering Systems in the Biomedical Domain</title><link>http://arxiv.org/abs/2307.13631v1</link><description>This thesis work falls within the framework of question answering (QA) in thebiomedical domain where several specific challenges are addressed, such asspecialized lexicons and terminologies, the types of treated questions, and thecharacteristics of targeted documents. We are particularly interested instudying and improving methods that aim at finding accurate and short answersto biomedical natural language questions from a large scale of biomedicaltextual documents in English. QA aims at providing inquirers with direct, shortand precise answers to their natural language questions. In this Ph.D. thesis,we propose four contributions to improve the performance of QA in thebiomedical domain. In our first contribution, we propose a machinelearning-based method for question type classification to determine the typesof given questions which enable to a biomedical QA system to use theappropriate answer extraction method. We also propose an another machinelearning-based method to assign one or more topics (e.g., pharmacological,test, treatment, etc.) to given questions in order to determine the semantictypes of the expected answers which are very useful in generating specificanswer retrieval strategies. In the second contribution, we first propose adocument retrieval method to retrieve a set of relevant documents that arelikely to contain the answers to biomedical questions from the MEDLINEdatabase. We then present a passage retrieval method to retrieve a set ofrelevant passages to questions. In the third contribution, we propose specificanswer extraction methods to generate both exact and ideal answers. Finally, inthe fourth contribution, we develop a fully automated semantic biomedical QAsystem called SemBioNLQA which is able to deal with a variety of naturallanguage questions and to generate appropriate answers by providing both exactand ideal answers.</description><author>Mourad Sarrouti</author><pubDate>Tue, 25 Jul 2023 17:31:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13631v1</guid></item><item><title>Scaling machine learning-based chemical plant simulation: A method for fine-tuning a model to induce stable fixed points</title><link>http://arxiv.org/abs/2307.13621v1</link><description>Idealized first-principles models of chemical plants can be inaccurate. Analternative is to fit a Machine Learning (ML) model directly to plant sensordata. We use a structured approach: Each unit within the plant gets representedby one ML model. After fitting the models to the data, the models are connectedinto a flowsheet-like directed graph. We find that for smaller plants, thisapproach works well, but for larger plants, the complex dynamics arising fromlarge and nested cycles in the flowsheet lead to instabilities in the cyclesolver. We analyze this problem in depth and show that it is not merely aspecialized concern but rather a more pervasive challenge that will likelyoccur whenever ML is applied to larger plants. To address this problem, wepresent a way to fine-tune ML models such that solving cycles with the usualmethods becomes robust again.</description><author>Malte Esders, Gimmy Alex Fernandez Ramirez, Michael Gastegger, Satya Swarup Samal</author><pubDate>Tue, 25 Jul 2023 17:23:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13621v1</guid></item><item><title>RecursiveDet: End-to-End Region-based Recursive Object Detection</title><link>http://arxiv.org/abs/2307.13619v1</link><description>End-to-end region-based object detectors like Sparse R-CNN usually havemultiple cascade bounding box decoding stages, which refine the currentpredictions according to their previous results. Model parameters within eachstage are independent, evolving a huge cost. In this paper, we find the generalsetting of decoding stages is actually redundant. By simply sharing parametersand making a recursive decoder, the detector already obtains a significantimprovement. The recursive decoder can be further enhanced by positionalencoding (PE) of the proposal box, which makes it aware of the exact locationsand sizes of input bounding boxes, thus becoming adaptive to proposals fromdifferent stages during the recursion. Moreover, we also designcenterness-based PE to distinguish the RoI feature element and dynamicconvolution kernels at different positions within the bounding box. To validatethe effectiveness of the proposed method, we conduct intensive ablations andbuild the full model on three recent mainstream region-based detectors. TheRecusiveDet is able to achieve obvious performance boosts with even fewer modelparameters and slightly increased computation cost. Codes are available athttps://github.com/bravezzzzzz/RecursiveDet.</description><author>Jing Zhao, Li Sun, Qingli Li</author><pubDate>Tue, 25 Jul 2023 17:22:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13619v1</guid></item><item><title>GPT-3 Models are Few-Shot Financial Reasoners</title><link>http://arxiv.org/abs/2307.13617v1</link><description>Financial analysis is an important tool for evaluating company performance.Practitioners work to answer financial questions to make profitable investmentdecisions, and use advanced quantitative analyses to do so. As a result,Financial Question Answering (QA) is a question answering task that requiresdeep reasoning about numbers. Furthermore, it is unknown how well pre-trainedlanguage models can reason in the financial domain. The currentstate-of-the-art requires a retriever to collect relevant facts about thefinancial question from the text and a generator to produce a valid financialprogram and a final answer. However, recently large language models like GPT-3have achieved state-of-the-art performance on wide variety of tasks with just afew shot examples. We run several experiments with GPT-3 and find that aseparate retrieval model and logic engine continue to be essential componentsto achieving SOTA performance in this task, particularly due to the precisenature of financial questions and the complex information stored in financialdocuments. With this understanding, our refined prompt-engineering approach onGPT-3 achieves near SOTA accuracy without any fine-tuning.</description><author>Raul Salles de Padua, Imran Qureshi, Mustafa U. Karakaplan</author><pubDate>Tue, 25 Jul 2023 17:21:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13617v1</guid></item><item><title>AI and ethics in insurance: a new solution to mitigate proxy discrimination in risk modeling</title><link>http://arxiv.org/abs/2307.13616v1</link><description>The development of Machine Learning is experiencing growing interest from thegeneral public, and in recent years there have been numerous press articlesquestioning its objectivity: racism, sexism, \dots Driven by the growingattention of regulators on the ethical use of data in insurance, the actuarialcommunity must rethink pricing and risk selection practices for fairerinsurance. Equity is a philosophy concept that has many different definitionsin every jurisdiction that influence each other without currently reachingconsensus. In Europe, the Charter of Fundamental Rights defines guidelines ondiscrimination, and the use of sensitive personal data in algorithms isregulated. If the simple removal of the protected variables prevents anyso-called `direct' discrimination, models are still able to `indirectly'discriminate between individuals thanks to latent interactions betweenvariables, which bring better performance (and therefore a betterquantification of risk, segmentation of prices, and so on). After introducingthe key concepts related to discrimination, we illustrate the complexity ofquantifying them. We then propose an innovative method, not yet met in theliterature, to reduce the risks of indirect discrimination thanks tomathematical concepts of linear algebra. This technique is illustrated in aconcrete case of risk selection in life insurance, demonstrating its simplicityof use and its promising performance.</description><author>Marguerite Sauce, Antoine Chancel, Antoine Ly</author><pubDate>Tue, 25 Jul 2023 17:20:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13616v1</guid></item><item><title>Deep Reinforcement Learning-Assisted Federated Learning for Robust Short-term Utility Demand Forecasting in Electricity Wholesale Markets</title><link>http://arxiv.org/abs/2206.11715v2</link><description>Short-term load forecasting (STLF) plays a significant role in the operationof electricity trading markets. Considering the growing concern of dataprivacy, federated learning (FL) is increasingly adopted to train STLF modelsfor utility companies (UCs) in recent research. Inspiringly, in wholesalemarkets, as it is not realistic for power plants (PPs) to access UCs' datadirectly, FL is definitely a feasible solution of obtaining an accurate STLFmodel for PPs. However, due to FL's distributed nature and intense competitionamong UCs, defects increasingly occur and lead to poor performance of the STLFmodel, indicating that simply adopting FL is not enough. In this paper, wepropose a DRL-assisted FL approach, DEfect-AwaRe federated soft actor-critic(DearFSAC), to robustly train an accurate STLF model for PPs to forecastprecise short-term utility electricity demand. Firstly. we design a STLF modelbased on long short-term memory (LSTM) using just historical load data and timedata. Furthermore, considering the uncertainty of defects occurrence, a deepreinforcement learning (DRL) algorithm is adopted to assist FL by alleviatingmodel degradation caused by defects. In addition, for faster convergence of FLtraining, an auto-encoder is designed for both dimension reduction and qualityevaluation of uploaded models. In the simulations, we validate our approach onreal data of Helsinki's UCs in 2019. The results show that DearFSAC outperformsall the other approaches no matter if defects occur or not.</description><author>Chenghao Huang, Weilong Chen, Shengrong Bu, Yanru Zhang</author><pubDate>Tue, 25 Jul 2023 17:18:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.11715v2</guid></item><item><title>Replica Analysis of the Linear Model with Markov or Hidden Markov Signal Priors</title><link>http://arxiv.org/abs/2009.13370v5</link><description>This paper estimates free energy, average mutual information, and minimummean square error (MMSE) of a linear model under two assumptions: (1) thesource is generated by a Markov chain, (2) the source is generated via a hiddenMarkov model. Our estimates are based on the replica method in statisticalphysics. We show that under the posterior mean estimator, the linear model withMarkov sources or hidden Markov sources is decoupled into single-input AWGNchannels with state information available at both encoder and decoder where thestate distribution follows the left Perron-Frobenius eigenvector with unitManhattan norm of the stochastic matrix of Markov chains. Numerical resultsshow that the free energies and MSEs obtained via the replica method areclosely approximate to their counterparts achieved by the Metropolis-Hastingsalgorithm or some well-known approximate message passing algorithms in theresearch literature.</description><author>Lan V. Truong</author><pubDate>Tue, 25 Jul 2023 17:15:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2009.13370v5</guid></item><item><title>Object-based Probabilistic Similarity Evidence of Sparse Latent Features from Fully Convolutional Networks</title><link>http://arxiv.org/abs/2307.13606v1</link><description>Similarity analysis using neural networks has emerged as a powerful techniquefor understanding and categorizing complex patterns in various domains. Byleveraging the latent representations learned by neural networks, data objectssuch as images can be compared effectively. This research explores theutilization of latent information generated by fully convolutional networks(FCNs) in similarity analysis, notably to estimate the visual resemblance ofobjects segmented in 2D pictures. To do this, the analytical scheme comprisestwo steps: (1) extracting and transforming feature patterns per 2D object froma trained FCN, and (2) identifying the most similar patterns through fuzzyinference. The step (2) can be further enhanced by incorporating a weightingscheme that considers the significance of latent variables in the analysis. Theresults provide valuable insights into the benefits and challenges of employingneural network-based similarity analysis for discerning data patternseffectively.</description><author>Cyril Juliani</author><pubDate>Tue, 25 Jul 2023 17:15:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13606v1</guid></item><item><title>marl-jax: Multi-Agent Reinforcement Leaning Framework</title><link>http://arxiv.org/abs/2303.13808v2</link><description>Recent advances in Reinforcement Learning (RL) have led to many excitingapplications. These advancements have been driven by improvements in bothalgorithms and engineering, which have resulted in faster training of RLagents. We present marl-jax, a multi-agent reinforcement learning softwarepackage for training and evaluating social generalization of the agents. Thepackage is designed for training a population of agents in multi-agentenvironments and evaluating their ability to generalize to diverse backgroundagents. It is built on top of DeepMind's JAX ecosystem~\cite{deepmind2020jax}and leverages the RL ecosystem developed by DeepMind. Our framework marl-jax iscapable of working in cooperative and competitive, simultaneous-actingenvironments with multiple agents. The package offers an intuitive anduser-friendly command-line interface for training a population and evaluatingits generalization capabilities. In conclusion, marl-jax provides a valuableresource for researchers interested in exploring social generalization in thecontext of MARL. The open-source code for marl-jax is available at:\href{https://github.com/kinalmehta/marl-jax}{https://github.com/kinalmehta/marl-jax}</description><author>Kinal Mehta, Anuj Mahajan, Pawan Kumar</author><pubDate>Tue, 25 Jul 2023 17:12:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.13808v2</guid></item><item><title>Decisive Data using Multi-Modality Optical Sensors for Advanced Vehicular Systems</title><link>http://arxiv.org/abs/2307.13600v1</link><description>Optical sensors have played a pivotal role in acquiring real world data forcritical applications. This data, when integrated with advanced machinelearning algorithms provides meaningful information thus enhancing humanvision. This paper focuses on various optical technologies for design anddevelopment of state-of-the-art out-cabin forward vision systems and in-cabindriver monitoring systems. The focused optical sensors include Longwave ThermalImaging (LWIR) cameras, Near Infrared (NIR), Neuromorphic/ event cameras,Visible CMOS cameras and Depth cameras. Further the paper discusses differentpotential applications which can be employed using the unique strengths of eachthese optical modalities in real time environment.</description><author>Muhammad Ali Farooq, Waseem Shariff, Mehdi Sefidgar Dilmaghani, Wang Yao, Moazam Soomro, Peter Corcoran</author><pubDate>Tue, 25 Jul 2023 17:03:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13600v1</guid></item><item><title>Scalable Stochastic Gradient Riemannian Langevin Dynamics in Non-Diagonal Metrics</title><link>http://arxiv.org/abs/2303.05101v2</link><description>Stochastic-gradient sampling methods are often used to perform Bayesianinference on neural networks. It has been observed that the methods in whichnotions of differential geometry are included tend to have better performances,with the Riemannian metric improving posterior exploration by accounting forthe local curvature. However, the existing methods often resort to simplediagonal metrics to remain computationally efficient. This loses some of thegains. We propose two non-diagonal metrics that can be used instochastic-gradient samplers to improve convergence and exploration but haveonly a minor computational overhead over diagonal metrics. We show that forfully connected neural networks (NNs) with sparsity-inducing priors andconvolutional NNs with correlated priors, using these metrics can provideimprovements. For some other choices the posterior is sufficiently easy alsofor the simpler metrics.</description><author>Hanlin Yu, Marcelo Hartmann, Bernardo Williams, Arto Klami</author><pubDate>Tue, 25 Jul 2023 16:51:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05101v2</guid></item><item><title>Multi-GPU Approach for Training of Graph ML Models on large CFD Meshes</title><link>http://arxiv.org/abs/2307.13592v1</link><description>Mesh-based numerical solvers are an important part in many design toolchains. However, accurate simulations like computational fluid dynamics aretime and resource consuming which is why surrogate models are employed tospeed-up the solution process. Machine Learning based surrogate models on theother hand are fast in predicting approximate solutions but often lackaccuracy. Thus, the development of the predictor in a predictor-correctorapproach is the focus here, where the surrogate model predicts a flow field andthe numerical solver corrects it. This paper scales a state-of-the-artsurrogate model from the domain of graph-based machine learning toindustry-relevant mesh sizes of a numerical flow simulation. The approachpartitions and distributes the flow domain to multiple GPUs and provides haloexchange between these partitions during training. The utilized graph neuralnetwork operates directly on the numerical mesh and is able to preserve complexgeometries as well as all other properties of the mesh. The proposed surrogatemodel is evaluated with an application on a three dimensional turbomachinerysetup and compared to a traditionally trained distributed model. The resultsshow that the traditional approach produces superior predictions andoutperforms the proposed surrogate model. Possible explanations, improvementsand future directions are outlined.</description><author>Sebastian Strönisch, Maximilian Sander, Andreas Knüpfer, Marcus Meyer</author><pubDate>Tue, 25 Jul 2023 16:49:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13592v1</guid></item><item><title>Settling the Sample Complexity of Online Reinforcement Learning</title><link>http://arxiv.org/abs/2307.13586v1</link><description>A central issue lying at the heart of online reinforcement learning (RL) isdata efficiency. While a number of recent works achieved asymptotically minimalregret in online RL, the optimality of these results is only guaranteed in a``large-sample'' regime, imposing enormous burn-in cost in order for theiralgorithms to operate optimally. How to achieve minimax-optimal regret withoutincurring any burn-in cost has been an open problem in RL theory. We settle this problem for the context of finite-horizon inhomogeneous Markovdecision processes. Specifically, we prove that a modified version of MonotonicValue Propagation (MVP), a model-based algorithm proposed by\cite{zhang2020reinforcement}, achieves a regret on the order of (modulo logfactors) \begin{equation*} \min\big\{ \sqrt{SAH^3K}, \,HK \big\}, \end{equation*} where $S$ is thenumber of states, $A$ is the number of actions, $H$ is the planning horizon,and $K$ is the total number of episodes. This regret matches the minimax lowerbound for the entire range of sample size $K\geq 1$, essentially eliminatingany burn-in requirement. It also translates to a PAC sample complexity (i.e.,the number of episodes needed to yield $\varepsilon$-accuracy) of$\frac{SAH^3}{\varepsilon^2}$ up to log factor, which is minimax-optimal forthe full $\varepsilon$-range. Further, we extend our theory to unveil the influences of problem-dependentquantities like the optimal value/cost and certain variances. The key technicalinnovation lies in the development of a new regret decomposition strategy and anovel analysis paradigm to decouple complicated statistical dependency -- along-standing challenge facing the analysis of online RL in the sample-hungryregime.</description><author>Zihan Zhang, Yuxin Chen, Jason D. Lee, Simon S. Du</author><pubDate>Tue, 25 Jul 2023 16:42:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13586v1</guid></item><item><title>Argument Attribution Explanations in Quantitative Bipolar Argumentation Frameworks</title><link>http://arxiv.org/abs/2307.13582v1</link><description>Argumentative explainable AI has been advocated by several in recent years,with an increasing interest on explaining the reasoning outcomes ofArgumentation Frameworks (AFs). While there is a considerable body of researchon qualitatively explaining the reasoning outcomes of AFs withdebates/disputes/dialogues in the spirit of \emph{extension-based semantics},explaining the quantitative reasoning outcomes of AFs under \emph{gradualsemantics} has not received much attention, despite widespread use inapplications. In this paper, we contribute to filling this gap by proposing anovel theory of \emph{Argument Attribution Explanations (AAEs)} byincorporating the spirit of feature attribution from machine learning in thecontext of Quantitative Bipolar Argumentation Frameworks (QBAFs): whereasfeature attribution is used to determine the influence of features towardsoutputs of machine learning models, AAEs are used to determine the influence ofarguments towards \emph{topic argument}s of interest. We study desirableproperties of AAEs, including some new ones and some partially adapted from theliterature to our setting. To demonstrate the applicability of our AAEs inpractice, we conclude by carrying out two case studies in the scenarios of fakenews detection and movie recommender systems.</description><author>Xiang Yin, Nico Potyka, Francesca Toni</author><pubDate>Tue, 25 Jul 2023 16:36:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13582v1</guid></item><item><title>Comparing Forward and Inverse Design Paradigms: A Case Study on Refractory High-Entropy Alloys</title><link>http://arxiv.org/abs/2307.13581v1</link><description>The rapid design of advanced materials is a topic of great scientificinterest. The conventional, ``forward'' paradigm of materials design involvesevaluating multiple candidates to determine the best candidate that matches thetarget properties. However, recent advances in the field of deep learning havegiven rise to the possibility of an ``inverse'' design paradigm for advancedmaterials, wherein a model provided with the target properties is able to findthe best candidate. Being a relatively new concept, there remains a need tosystematically evaluate how these two paradigms perform in practicalapplications. Therefore, the objective of this study is to directly,quantitatively compare the forward and inverse design modeling paradigms. We doso by considering two case studies of refractory high-entropy alloy design withdifferent objectives and constraints and comparing the inverse design method toother forward schemes like localized forward search, high throughput screening,and multi objective optimization.</description><author>Arindam Debnath, Lavanya Raman, Wenjie Li, Adam M. Krajewski, Marcia Ahn, Shuang Lin, Shunli Shang, Allison M. Beese, Zi-Kui Liu, Wesley F. Reinhart</author><pubDate>Tue, 25 Jul 2023 16:35:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13581v1</guid></item><item><title>Reinterpreting survival analysis in the universal approximator age</title><link>http://arxiv.org/abs/2307.13579v1</link><description>Survival analysis is an integral part of the statistical toolbox. However,while most domains of classical statistics have embraced deep learning,survival analysis only recently gained some minor attention from the deeplearning community. This recent development is likely in part motivated by theCOVID-19 pandemic. We aim to provide the tools needed to fully harness thepotential of survival analysis in deep learning. On the one hand, we discusshow survival analysis connects to classification and regression. On the otherhand, we provide technical tools. We provide a new loss function, evaluationmetrics, and the first universal approximating network that provably producessurvival curves without numeric integration. We show that the loss function andmodel outperform other approaches using a large numerical study.</description><author>Sören Dittmer, Michael Roberts, Jacobus Preller, AIX COVNET, James H. F. Rudd, John A. D. Aston, Carola-Bibiane Schönlieb</author><pubDate>Tue, 25 Jul 2023 16:33:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13579v1</guid></item><item><title>PT$\mathrm{L}^{p}$: Partial Transport $\mathrm{L}^{p}$ Distances</title><link>http://arxiv.org/abs/2307.13571v1</link><description>Optimal transport and its related problems, including optimal partialtransport, have proven to be valuable tools in machine learning for computingmeaningful distances between probability or positive measures. This success hasled to a growing interest in defining transport-based distances that allow forcomparing signed measures and, more generally, multi-channeled signals.Transport $\mathrm{L}^{p}$ distances are notable extensions of the optimaltransport framework to signed and possibly multi-channeled signals. In thispaper, we introduce partial transport $\mathrm{L}^{p}$ distances as a newfamily of metrics for comparing generic signals, benefiting from the robustnessof partial transport distances. We provide theoretical background such as theexistence of optimal plans and the behavior of the distance in various limits.Furthermore, we introduce the sliced variation of these distances, which allowsfor rapid comparison of generic signals. Finally, we demonstrate theapplication of the proposed distances in signal class separability and nearestneighbor classification.</description><author>Xinran Liu, Yikun Bai, Huy Tran, Zhanqi Zhu, Matthew Thorpe, Soheil Kolouri</author><pubDate>Tue, 25 Jul 2023 16:23:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13571v1</guid></item><item><title>Mystique: Deconstructing SVG Charts for Layout Reuse</title><link>http://arxiv.org/abs/2307.13567v1</link><description>To facilitate the reuse of existing charts, previous research has examinedhow to obtain a semantic understanding of a chart by deconstructing its visualrepresentation into reusable components, such as encodings. However, existingdeconstruction approaches primarily focus on chart styles, handling only basiclayouts. In this paper, we investigate how to deconstruct chart layouts,focusing on rectangle-based ones as they cover not only 17 chart types but alsoadvanced layouts (e.g., small multiples, nested layouts). We develop aninteractive tool, called Mystique, adopting a mixed-initiative approach toextract the axes and legend, and deconstruct a chart's layout into foursemantic components: mark groups, spatial relationships, data encodings, andgraphical constraints. Mystique employs a wizard interface that guides chartauthors through a series of steps to specify how the deconstructed componentsmap to their own data. On 150 rectangle-based SVG charts, Mystique achievesabove 85% accuracy for axis and legend extraction and 96% accuracy for layoutdeconstruction. In a chart reproduction study, participants could easily reuseexisting charts on new datasets. We discuss the current limitations of Mystiqueand future research directions.</description><author>Chen Chen, Bongshin Lee, Yunhai Wang, Yunjeong Chang, Zhicheng Liu</author><pubDate>Tue, 25 Jul 2023 16:20:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13567v1</guid></item><item><title>MaxMin-L2-SVC-NCH: A Novel Approach for Support Vector Classifier Training and Parameter Selection</title><link>http://arxiv.org/abs/2307.07343v2</link><description>The selection of Gaussian kernel parameters plays an important role in theapplications of support vector classification (SVC). A commonly used method isthe k-fold cross validation with grid search (CV), which is extremelytime-consuming because it needs to train a large number of SVC models. In thispaper, a new approach is proposed to train SVC and optimize the selection ofGaussian kernel parameters. We first formulate the training and parameterselection of SVC as a minimax optimization problem named as MaxMin-L2-SVC-NCH,in which the minimization problem is an optimization problem of finding theclosest points between two normal convex hulls (L2-SVC-NCH) while themaximization problem is an optimization problem of finding the optimal Gaussiankernel parameters. A lower time complexity can be expected in MaxMin-L2-SVC-NCHbecause CV is not needed. We then propose a projected gradient algorithm (PGA)for training L2-SVC-NCH. The famous sequential minimal optimization (SMO)algorithm is a special case of the PGA. Thus, the PGA can provide moreflexibility than the SMO. Furthermore, the solution of the maximization problemis done by a gradient ascent algorithm with dynamic learning rate. Thecomparative experiments between MaxMin-L2-SVC-NCH and the previous bestapproaches on public datasets show that MaxMin-L2-SVC-NCH greatly reduces thenumber of models to be trained while maintaining competitive test accuracy.These findings indicate that MaxMin-L2-SVC-NCH is a better choice for SVCtasks.</description><author>Linkai Luo, Qiaoling Yang, Hong Peng, Yiding Wang, Ziyang Chen</author><pubDate>Tue, 25 Jul 2023 16:20:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07343v2</guid></item><item><title>The Impact of Imperfect XAI on Human-AI Decision-Making</title><link>http://arxiv.org/abs/2307.13566v1</link><description>Explainability techniques are rapidly being developed to improve human-AIdecision-making across various cooperative work settings. Consequently,previous research has evaluated how decision-makers collaborate with imperfectAI by investigating appropriate reliance and task performance with the aim ofdesigning more human-centered computer-supported collaborative tools. Severalhuman-centered explainable AI (XAI) techniques have been proposed in hopes ofimproving decision-makers' collaboration with AI; however, these techniques aregrounded in findings from previous studies that primarily focus on the impactof incorrect AI advice. Few studies acknowledge the possibility for theexplanations to be incorrect even if the AI advice is correct. Thus, it iscrucial to understand how imperfect XAI affects human-AI decision-making. Inthis work, we contribute a robust, mixed-methods user study with 136participants to evaluate how incorrect explanations influence humans'decision-making behavior in a bird species identification task taking intoaccount their level of expertise and an explanation's level of assertiveness.Our findings reveal the influence of imperfect XAI and humans' level ofexpertise on their reliance on AI and human-AI team performance. We alsodiscuss how explanations can deceive decision-makers during human-AIcollaboration. Hence, we shed light on the impacts of imperfect XAI in thefield of computer-supported cooperative work and provide guidelines fordesigners of human-AI collaboration systems.</description><author>Katelyn Morrison, Philipp Spitzer, Violet Turri, Michelle Feng, Niklas Kühl, Adam Perer</author><pubDate>Tue, 25 Jul 2023 16:19:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13566v1</guid></item><item><title>Decision-Focused Learning: Foundations, State of the Art, Benchmark and Future Opportunities</title><link>http://arxiv.org/abs/2307.13565v1</link><description>Decision-focused learning (DFL) is an emerging paradigm in machine learningwhich trains a model to optimize decisions, integrating prediction andoptimization in an end-to-end system. This paradigm holds the promise torevolutionize decision-making in many real-world applications which operateunder uncertainty, where the estimation of unknown parameters within thesedecision models often becomes a substantial roadblock. This paper presents acomprehensive review of DFL. It provides an in-depth analysis of the varioustechniques devised to integrate machine learning and optimization modelsintroduces a taxonomy of DFL methods distinguished by their uniquecharacteristics, and conducts an extensive empirical evaluation of thesemethods proposing suitable benchmark dataset and tasks for DFL. Finally, thestudy provides valuable insights into current and potential future avenues inDFL research.</description><author>Jayanta Mandi, James Kotary, Senne Berden, Maxime Mulamba, Victor Bucarey, Tias Guns, Ferdinando Fioretto</author><pubDate>Tue, 25 Jul 2023 16:17:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13565v1</guid></item><item><title>TF-ICON: Diffusion-Based Training-Free Cross-Domain Image Composition</title><link>http://arxiv.org/abs/2307.12493v2</link><description>Text-driven diffusion models have exhibited impressive generativecapabilities, enabling various image editing tasks. In this paper, we proposeTF-ICON, a novel Training-Free Image COmpositioN framework that harnesses thepower of text-driven diffusion models for cross-domain image-guidedcomposition. This task aims to seamlessly integrate user-provided objects intoa specific visual context. Current diffusion-based methods often involve costlyinstance-based optimization or finetuning of pretrained models on customizeddatasets, which can potentially undermine their rich prior. In contrast,TF-ICON can leverage off-the-shelf diffusion models to perform cross-domainimage-guided composition without requiring additional training, finetuning, oroptimization. Moreover, we introduce the exceptional prompt, which contains noinformation, to facilitate text-driven diffusion models in accurately invertingreal images into latent representations, forming the basis for compositing. Ourexperiments show that equipping Stable Diffusion with the exceptional promptoutperforms state-of-the-art inversion methods on various datasets (CelebA-HQ,COCO, and ImageNet), and that TF-ICON surpasses prior baselines in versatilevisual domains. Code is available at https://github.com/Shilin-LU/TF-ICON</description><author>Shilin Lu, Yanzhu Liu, Adams Wai-Kin Kong</author><pubDate>Tue, 25 Jul 2023 16:17:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12493v2</guid></item><item><title>Adversarial Agents For Attacking Inaudible Voice Activated Devices</title><link>http://arxiv.org/abs/2307.12204v2</link><description>The paper applies reinforcement learning to novel Internet of Thingconfigurations. Our analysis of inaudible attacks on voice-activated devicesconfirms the alarming risk factor of 7.6 out of 10, underlining significantsecurity vulnerabilities scored independently by NIST National VulnerabilityDatabase (NVD). Our baseline network model showcases a scenario in which anattacker uses inaudible voice commands to gain unauthorized access toconfidential information on a secured laptop. We simulated many attackscenarios on this baseline network model, revealing the potential for massexploitation of interconnected devices to discover and own privilegedinformation through physical access without adding new hardware or amplifyingdevice skills. Using Microsoft's CyberBattleSim framework, we evaluated sixreinforcement learning algorithms and found that Deep-Q learning withexploitation proved optimal, leading to rapid ownership of all nodes in fewersteps. Our findings underscore the critical need for understandingnon-conventional networks and new cybersecurity measures in an ever-expandingdigital landscape, particularly those characterized by mobile devices, voiceactivation, and non-linear microphones susceptible to malicious actorsoperating stealth attacks in the near-ultrasound or inaudible ranges. By 2024,this new attack surface might encompass more digital voice assistants thanpeople on the planet yet offer fewer remedies than conventional patching orfirmware fixes since the inaudible attacks arise inherently from the microphonedesign and digital signal processing.</description><author>Forrest McKee, David Noever</author><pubDate>Tue, 25 Jul 2023 16:16:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12204v2</guid></item><item><title>Integrating Curricula with Replays: Its Effects on Continual Learning</title><link>http://arxiv.org/abs/2307.05747v2</link><description>Humans engage in learning and reviewing processes with curricula whenacquiring new skills or knowledge. This human learning behavior has inspiredthe integration of curricula with replay methods in continual learning agents.The goal is to emulate the human learning process, thereby improving knowledgeretention and facilitating learning transfer. Existing replay methods incontinual learning agents involve the random selection and ordering of datafrom previous tasks, which has shown to be effective. However, limited researchhas explored the integration of different curricula with replay methods toenhance continual learning. Our study takes initial steps in examining theimpact of integrating curricula with replay methods on continual learning inthree specific aspects: the interleaved frequency of replayed exemplars withtraining data, the sequence in which exemplars are replayed, and the strategyfor selecting exemplars into the replay buffer. These aspects of curriculadesign align with cognitive psychology principles and leverage the benefits ofinterleaved practice during replays, easy-to-hard rehearsal, and exemplarselection strategy involving exemplars from a uniform distribution ofdifficulties. Based on our results, these three curricula effectively mitigatedcatastrophic forgetting and enhanced positive knowledge transfer, demonstratingthe potential of curricula in advancing continual learning methodologies. Ourcode and data are available:https://github.com/ZhangLab-DeepNeuroCogLab/Integrating-Curricula-with-Replays</description><author>Ren Jie Tee, Mengmi Zhang</author><pubDate>Tue, 25 Jul 2023 16:16:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.05747v2</guid></item><item><title>XDLM: Cross-lingual Diffusion Language Model for Machine Translation</title><link>http://arxiv.org/abs/2307.13560v1</link><description>Recently, diffusion models have excelled in image generation tasks and havealso been applied to neural language processing (NLP) for controllable textgeneration. However, the application of diffusion models in a cross-lingualsetting is less unexplored. Additionally, while pretraining with diffusionmodels has been studied within a single language, the potential ofcross-lingual pretraining remains understudied. To address these gaps, wepropose XDLM, a novel Cross-lingual diffusion model for machine translation,consisting of pretraining and fine-tuning stages. In the pretraining stage, wepropose TLDM, a new training objective for mastering the mapping betweendifferent languages; in the fine-tuning stage, we build up the translationsystem based on the pretrained model. We evaluate the result on several machinetranslation benchmarks and outperformed both diffusion and Transformerbaselines.</description><author>Linyao Chen, Aosong Feng, Boming Yang, Zihui Li</author><pubDate>Tue, 25 Jul 2023 16:08:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13560v1</guid></item><item><title>Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models</title><link>http://arxiv.org/abs/2307.08303v2</link><description>Dense retrieval (DR) converts queries and documents into dense embeddings andmeasures the similarity between queries and documents in vector space. One ofthe challenges in DR is the lack of domain-specific training data. While DRmodels can learn from large-scale public datasets like MS MARCO throughtransfer learning, evidence shows that not all DR models and domains canbenefit from transfer learning equally. Recently, some researchers haveresorted to large language models (LLMs) to improve the zero-shot and few-shotDR models. However, the hard prompts or human-written prompts utilized in theseworks cannot guarantee the good quality of generated weak queries. To tacklethis, we propose soft prompt tuning for augmenting DR (SPTAR): For each task,we leverage soft prompt-tuning to optimize a task-specific soft prompt onlimited ground truth data and then prompt the LLMs to tag unlabeled documentswith weak queries, yielding enough weak document-query pairs to traintask-specific dense retrievers. We design a filter to select high-qualityexample document-query pairs in the prompt to further improve the quality ofweak tagged queries. To the best of our knowledge, there is no prior workutilizing soft prompt tuning to augment DR models. The experiments demonstratethat SPTAR outperforms the unsupervised baselines BM25 and the recentlyproposed LLMs-based augmentation method for DR.</description><author>Zhiyuan Peng, Xuyang Wu, Yi Fang</author><pubDate>Tue, 25 Jul 2023 15:57:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08303v2</guid></item><item><title>On Solving the Rubik's Cube with Domain-Independent Planners Using Standard Representations</title><link>http://arxiv.org/abs/2307.13552v1</link><description>Rubik's Cube (RC) is a well-known and computationally challenging puzzle thathas motivated AI researchers to explore efficient alternative representationsand problem-solving methods. The ideal situation for planning here is that aproblem be solved optimally and efficiently represented in a standard notationusing a general-purpose solver and heuristics. The fastest solver today for RCis DeepCubeA with a custom representation, and another approach is withScorpion planner with State-Action-Space+ (SAS+) representation. In this paper,we present the first RC representation in the popular PDDL language so that thedomain becomes more accessible to PDDL planners, competitions, and knowledgeengineering tools, and is more human-readable. We then bridge across existingapproaches and compare performance. We find that in one comparable experiment,DeepCubeA solves all problems with varying complexities, albeit only 18\% areoptimal plans. For the same problem set, Scorpion with SAS+ representation andpattern database heuristics solves 61.50\% problems, while FastDownward withPDDL representation and FF heuristic solves 56.50\% problems, out of which allthe plans generated were optimal. Our study provides valuable insights into thetrade-offs between representational choice and plan optimality that can helpresearchers design future strategies for challenging domains combininggeneral-purpose solving methods (planning, reinforcement learning), heuristics,and representations (standard or custom).</description><author>Bharath Muppasani, Vishal Pallagani, Biplav Srivastava, Forest Agostinelli</author><pubDate>Tue, 25 Jul 2023 15:52:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13552v1</guid></item><item><title>A Planning Ontology to Represent and Exploit Planning Knowledge for Performance Efficiency</title><link>http://arxiv.org/abs/2307.13549v1</link><description>Ontologies are known for their ability to organize rich metadata, support theidentification of novel insights via semantic queries, and promote reuse. Inthis paper, we consider the problem of automated planning, where the objectiveis to find a sequence of actions that will move an agent from an initial stateof the world to a desired goal state. We hypothesize that given a large numberof available planners and diverse planning domains; they carry essentialinformation that can be leveraged to identify suitable planners and improvetheir performance for a domain. We use data on planning domains and plannersfrom the International Planning Competition (IPC) to construct a planningontology and demonstrate via experiments in two use cases that the ontology canlead to the selection of promising planners and improving their performanceusing macros - a form of action ordering constraints extracted from planningontology. We also make the planning ontology and associated resources availableto the community to promote further research.</description><author>Bharath Muppasani, Vishal Pallagani, Biplav Srivastava, Raghava Mutharaju, Michael N. Huhns, Vignesh Narayanan</author><pubDate>Tue, 25 Jul 2023 15:51:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13549v1</guid></item><item><title>Node Injection Link Stealing Attack</title><link>http://arxiv.org/abs/2307.13548v1</link><description>In this paper, we present a stealthy and effective attack that exposesprivacy vulnerabilities in Graph Neural Networks (GNNs) by inferring privatelinks within graph-structured data. Focusing on the inductive setting where newnodes join the graph and an API is used to query predictions, we investigatethe potential leakage of private edge information. We also propose methods topreserve privacy while maintaining model utility. Our attack demonstratessuperior performance in inferring the links compared to the state of the art.Furthermore, we examine the application of differential privacy (DP) mechanismsto mitigate the impact of our proposed attack, we analyze the trade-off betweenprivacy preservation and model utility. Our work highlights the privacyvulnerabilities inherent in GNNs, underscoring the importance of developingrobust privacy-preserving mechanisms for their application.</description><author>Oualid Zari, Javier Parra-Arnau, Ayşe Ünsal, Melek Önen</author><pubDate>Tue, 25 Jul 2023 15:51:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13548v1</guid></item><item><title>Transfer Learning for Portfolio Optimization</title><link>http://arxiv.org/abs/2307.13546v1</link><description>In this work, we explore the possibility of utilizing transfer learningtechniques to address the financial portfolio optimization problem. Weintroduce a novel concept called "transfer risk", within the optimizationframework of transfer learning. A series of numerical experiments are conductedfrom three categories: cross-continent transfer, cross-sector transfer, andcross-frequency transfer. In particular, 1. a strong correlation between thetransfer risk and the overall performance of transfer learning methods isestablished, underscoring the significance of transfer risk as a viableindicator of "transferability"; 2. transfer risk is shown to provide acomputationally efficient way to identify appropriate source tasks in transferlearning, enhancing the efficiency and effectiveness of the transfer learningapproach; 3. additionally, the numerical experiments offer valuable newinsights for portfolio management across these different settings.</description><author>Haoyang Cao, Haotian Gu, Xin Guo, Mathieu Rosenbaum</author><pubDate>Tue, 25 Jul 2023 15:48:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13546v1</guid></item><item><title>A model for efficient dynamical ranking in networks</title><link>http://arxiv.org/abs/2307.13544v1</link><description>We present a physics-inspired method for inferring dynamic rankings indirected temporal networks - networks in which each directed and timestampededge reflects the outcome and timing of a pairwise interaction. The inferredranking of each node is real-valued and varies in time as each new edge,encoding an outcome like a win or loss, raises or lowers the node's estimatedstrength or prestige, as is often observed in real scenarios includingsequences of games, tournaments, or interactions in animal hierarchies. Ourmethod works by solving a linear system of equations and requires only oneparameter to be tuned. As a result, the corresponding algorithm is scalable andefficient. We test our method by evaluating its ability to predict interactions(edges' existence) and their outcomes (edges' directions) in a variety ofapplications, including both synthetic and real data. Our analysis shows thatin many cases our method's performance is better than existing methods forpredicting dynamic rankings and interaction outcomes.</description><author>Andrea Della Vecchia, Kibidi Neocosmos, Daniel B. Larremore, Cristopher Moore, Caterina De Bacco</author><pubDate>Tue, 25 Jul 2023 15:47:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13544v1</guid></item><item><title>Group Activity Recognition in Computer Vision: A Comprehensive Review, Challenges, and Future Perspectives</title><link>http://arxiv.org/abs/2307.13541v1</link><description>Group activity recognition is a hot topic in computer vision. Recognizingactivities through group relationships plays a vital role in group activityrecognition. It holds practical implications in various scenarios, such asvideo analysis, surveillance, automatic driving, and understanding socialactivities. The model's key capabilities encompass efficiently modelinghierarchical relationships within a scene and accurately extracting distinctivespatiotemporal features from groups. Given this technology's extensiveapplicability, identifying group activities has garnered significant researchattention. This work examines the current progress in technology forrecognizing group activities, with a specific focus on global interactivity andactivities. Firstly, we comprehensively review the pertinent literature andvarious group activity recognition approaches, from traditional methodologiesto the latest methods based on spatial structure, descriptors, non-deeplearning, hierarchical recurrent neural networks (HRNN), relationship models,and attention mechanisms. Subsequently, we present the relational network andrelational architectures for each module. Thirdly, we investigate methods forrecognizing group activity and compare their performance with state-of-the-arttechnologies. We summarize the existing challenges and provide comprehensiveguidance for newcomers to understand group activity recognition. Furthermore,we review emerging perspectives in group activity recognition to explore newdirections and possibilities.</description><author>Chuanchuan Wang, Ahmad Sufril Azlan Mohamed</author><pubDate>Tue, 25 Jul 2023 15:44:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13541v1</guid></item><item><title>Multi-Armed Bandits and Quantum Channel Oracles</title><link>http://arxiv.org/abs/2301.08544v2</link><description>Multi-armed bandits are one of the theoretical pillars of reinforcementlearning. Recently, the investigation of quantum algorithms for multi-armedbandit problems was started, and it was found that a quadratic speed-up (inquery complexity) is possible when the arms and the randomness of the rewardsof the arms can be queried in superposition. Here we introduce further banditmodels where we only have limited access to the randomness of the rewards, butwe can still query the arms in superposition. We show that then the querycomplexity is the same as for classical algorithms. This generalizes the priorresult that no speed-up is possible for unstructured search when the oracle haspositive failure probability.</description><author>Simon Buchholz, Jonas M. Kübler, Bernhard Schölkopf</author><pubDate>Tue, 25 Jul 2023 15:43:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.08544v2</guid></item><item><title>Non-Invasive Fairness in Learning through the Lens of Data Drift</title><link>http://arxiv.org/abs/2303.17566v3</link><description>Machine Learning (ML) models are widely employed to drive many modern datasystems. While they are undeniably powerful tools, ML models often demonstrateimbalanced performance and unfair behaviors. The root of this problem oftenlies in the fact that different subpopulations commonly display divergenttrends: as a learning algorithm tries to identify trends in the data, itnaturally favors the trends of the majority groups, leading to a model thatperforms poorly and unfairly for minority populations. Our goal is to improvethe fairness and trustworthiness of ML models by applying only non-invasiveinterventions, i.e., without altering the data or the learning algorithm. Weuse a simple but key insight: the divergence of trends between differentpopulations, and, consecutively, between a learned model and minoritypopulations, is analogous to data drift, which indicates the poor conformancebetween parts of the data and the trained model. We explore two strategies(model-splitting and reweighing) to resolve this drift, aiming to improve theoverall conformance of models to the underlying data. Both our methodsintroduce novel ways to employ the recently-proposed data profiling primitiveof Conformance Constraints. Our experimental evaluation over 7 real-worlddatasets shows that both DifFair and ConFair improve the fairness of ML models.We demonstrate scenarios where DifFair has an edge, though ConFair has thegreatest practical impact and outperforms other baselines. Moreover, as amodel-agnostic technique, ConFair stays robust when used against differentmodels than the ones on which the weights have been learned, which is not thecase for other state of the art.</description><author>Ke Yang, Alexandra Meliou</author><pubDate>Tue, 25 Jul 2023 15:42:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.17566v3</guid></item><item><title>Learning Optimal Fair Classification Trees: Trade-offs Between Interpretability, Fairness, and Accuracy</title><link>http://arxiv.org/abs/2201.09932v5</link><description>The increasing use of machine learning in high-stakes domains -- wherepeople's livelihoods are impacted -- creates an urgent need for interpretable,fair, and highly accurate algorithms. With these needs in mind, we propose amixed integer optimization (MIO) framework for learning optimal classificationtrees -- one of the most interpretable models -- that can be augmented witharbitrary fairness constraints. In order to better quantify the "price ofinterpretability", we also propose a new measure of model interpretabilitycalled decision complexity that allows for comparisons across different classesof machine learning models. We benchmark our method against state-of-the-artapproaches for fair classification on popular datasets; in doing so, we conductone of the first comprehensive analyses of the trade-offs betweeninterpretability, fairness, and predictive accuracy. Given a fixed disparitythreshold, our method has a price of interpretability of about 4.2 percentagepoints in terms of out-of-sample accuracy compared to the best performing,complex models. However, our method consistently finds decisions with almostfull parity, while other methods rarely do.</description><author>Nathanael Jo, Sina Aghaei, Andrés Gómez, Phebe Vayanos</author><pubDate>Tue, 25 Jul 2023 15:41:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.09932v5</guid></item><item><title>Model Calibration in Dense Classification with Adaptive Label Perturbation</title><link>http://arxiv.org/abs/2307.13539v1</link><description>For safety-related applications, it is crucial to produce trustworthy deepneural networks whose prediction is associated with confidence that canrepresent the likelihood of correctness for subsequent decision-making.Existing dense binary classification models are prone to being over-confident.To improve model calibration, we propose Adaptive Stochastic Label Perturbation(ASLP) which learns a unique label perturbation level for each training image.ASLP employs our proposed Self-Calibrating Binary Cross Entropy (SC-BCE) loss,which unifies label perturbation processes including stochastic approaches(like DisturbLabel), and label smoothing, to correct calibration whilemaintaining classification rates. ASLP follows Maximum Entropy Inference ofclassic statistical mechanics to maximise prediction entropy with respect tomissing information. It performs this while: (1) preserving classificationaccuracy on known data as a conservative solution, or (2) specifically improvesmodel calibration degree by minimising the gap between the prediction accuracyand expected confidence of the target training label. Extensive resultsdemonstrate that ASLP can significantly improve calibration degrees of densebinary classification models on both in-distribution and out-of-distributiondata. The code is available on https://github.com/Carlisle-Liu/ASLP.</description><author>Jiawei Liu, Changkun Ye, Shan Wang, Ruikai Cui, Jing Zhang, Kaihao Zhang, Nick Barnes</author><pubDate>Tue, 25 Jul 2023 15:40:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13539v1</guid></item><item><title>INFINITY: Neural Field Modeling for Reynolds-Averaged Navier-Stokes Equations</title><link>http://arxiv.org/abs/2307.13538v1</link><description>For numerical design, the development of efficient and accurate surrogatemodels is paramount. They allow us to approximate complex physical phenomena,thereby reducing the computational burden of direct numerical simulations. Wepropose INFINITY, a deep learning model that utilizes implicit neuralrepresentations (INRs) to address this challenge. Our framework encodesgeometric information and physical fields into compact representations andlearns a mapping between them to infer the physical fields. We use an airfoildesign optimization problem as an example task and we evaluate our approach onthe challenging AirfRANS dataset, which closely resembles real-world industrialuse-cases. The experimental results demonstrate that our framework achievesstate-of-the-art performance by accurately inferring physical fields throughoutthe volume and surface. Additionally we demonstrate its applicability incontexts such as design exploration and shape optimization: our model cancorrectly predict drag and lift coefficients while adhering to the equations.</description><author>Louis Serrano, Leon Migus, Yuan Yin, Jocelyn Ahmed Mazari, Patrick Gallinari</author><pubDate>Tue, 25 Jul 2023 15:35:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13538v1</guid></item><item><title>Spectrum-guided Multi-granularity Referring Video Object Segmentation</title><link>http://arxiv.org/abs/2307.13537v1</link><description>Current referring video object segmentation (R-VOS) techniques extractconditional kernels from encoded (low-resolution) vision-language features tosegment the decoded high-resolution features. We discovered that this causessignificant feature drift, which the segmentation kernels struggle to perceiveduring the forward computation. This negatively affects the ability ofsegmentation kernels. To address the drift problem, we propose aSpectrum-guided Multi-granularity (SgMg) approach, which performs directsegmentation on the encoded features and employs visual details to furtheroptimize the masks. In addition, we propose Spectrum-guided Cross-modal Fusion(SCF) to perform intra-frame global interactions in the spectral domain foreffective multimodal representation. Finally, we extend SgMg to performmulti-object R-VOS, a new paradigm that enables simultaneous segmentation ofmultiple referred objects in a video. This not only makes R-VOS faster, butalso more practical. Extensive experiments show that SgMg achievesstate-of-the-art performance on four video benchmark datasets, outperformingthe nearest competitor by 2.8% points on Ref-YouTube-VOS. Our extended SgMgenables multi-object R-VOS, runs about 3 times faster while maintainingsatisfactory performance. Code is available at https://github.com/bo-miao/SgMg.</description><author>Bo Miao, Mohammed Bennamoun, Yongsheng Gao, Ajmal Mian</author><pubDate>Tue, 25 Jul 2023 15:35:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13537v1</guid></item><item><title>Harmonizing Feature Attributions Across Deep Learning Architectures: Enhancing Interpretability and Consistency</title><link>http://arxiv.org/abs/2307.02150v3</link><description>Ensuring the trustworthiness and interpretability of machine learning modelsis critical to their deployment in real-world applications. Feature attributionmethods have gained significant attention, which provide local explanations ofmodel predictions by attributing importance to individual input features. Thisstudy examines the generalization of feature attributions across various deeplearning architectures, such as convolutional neural networks (CNNs) and visiontransformers. We aim to assess the feasibility of utilizing a featureattribution method as a future detector and examine how these features can beharmonized across multiple models employing distinct architectures but trainedon the same data distribution. By exploring this harmonization, we aim todevelop a more coherent and optimistic understanding of feature attributions,enhancing the consistency of local explanations across diverse deep-learningmodels. Our findings highlight the potential for harmonized feature attributionmethods to improve interpretability and foster trust in machine learningapplications, regardless of the underlying architecture.</description><author>Md Abdul Kadir, Gowtham Krishna Addluri, Daniel Sonntag</author><pubDate>Tue, 25 Jul 2023 15:32:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02150v3</guid></item><item><title>Meta-Referential Games to Learn Compositional Learning Behaviours</title><link>http://arxiv.org/abs/2207.08012v2</link><description>Human beings use compositionality to generalise from past experiences tonovel experiences. We assume a separation of our experiences into fundamentalatomic components that can be recombined in novel ways to support our abilityto engage with novel experiences. We frame this as the ability to learn togeneralise compositionally, and we will refer to behaviours making use of thisability as compositional learning behaviours (CLBs). A central problem tolearning CLBs is the resolution of a binding problem (BP). While it is anotherfeat of intelligence that human beings perform with ease, it is not the casefor state-of-the-art artificial agents. Thus, in order to build artificialagents able to collaborate with human beings, we propose to develop a novelbenchmark to investigate agents' abilities to exhibit CLBs by solving adomain-agnostic version of the BP. We take inspiration from the languageemergence and grounding framework of referential games and propose ameta-learning extension of referential games, entitled Meta-Referential Games,and use this framework to build our benchmark, that we name Symbolic BehaviourBenchmark (S2B). We provide baseline results showing that our benchmark is acompelling challenge that we hope will spur the research community towardsdeveloping more capable artificial agents.</description><author>Kevin Denamganaï, Sondess Missaoui, James Alfred Walker</author><pubDate>Tue, 25 Jul 2023 15:30:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.08012v2</guid></item><item><title>Do algorithms and barriers for sparse principal component analysis extend to other structured settings?</title><link>http://arxiv.org/abs/2307.13535v1</link><description>We study a principal component analysis problem under the spiked Wishartmodel in which the structure in the signal is captured by a class ofunion-of-subspace models. This general class includes vanilla sparse PCA aswell as its variants with graph sparsity. With the goal of studying theseproblems under a unified statistical and computational lens, we establishfundamental limits that depend on the geometry of the problem instance, andshow that a natural projected power method exhibits local convergence to thestatistically near-optimal neighborhood of the solution. We complement theseresults with end-to-end analyses of two important special cases given by pathand tree sparsity in a general basis, showing initialization methods andmatching evidence of computational hardness. Overall, our results indicate thatseveral of the phenomena observed for vanilla sparse PCA extend in a naturalfashion to its structured counterparts.</description><author>Guanyi Wang, Mengqi Lou, Ashwin Pananjady</author><pubDate>Tue, 25 Jul 2023 15:30:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13535v1</guid></item><item><title>Differentiable Turbulence II</title><link>http://arxiv.org/abs/2307.13533v1</link><description>Differentiable fluid simulators are increasingly demonstrating value asuseful tools for developing data-driven models in computational fluid dynamics(CFD). Differentiable turbulence, or the end-to-end training of machinelearning (ML) models embedded in CFD solution algorithms, captures both thegeneralization power and limited upfront cost of physics-based simulations, andthe flexibility and automated training of deep learning methods. We develop aframework for integrating deep learning models into a generic finite elementnumerical scheme for solving the Navier-Stokes equations, applying thetechnique to learn a sub-grid scale closure using a multi-scale graph neuralnetwork. We demonstrate the method on several realizations of flow over abackwards-facing step, testing on both unseen Reynolds numbers and newgeometry. We show that the learned closure can achieve accuracy comparable totraditional large eddy simulation on a finer grid that amounts to an equivalentspeedup of 10x. As the desire and need for cheaper CFD simulations grows, wesee hybrid physics-ML methods as a path forward to be exploited in the nearfuture.</description><author>Varun Shankar, Romit Maulik, Venkatasubramanian Viswanathan</author><pubDate>Tue, 25 Jul 2023 15:27:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13533v1</guid></item><item><title>EdgeAL: An Edge Estimation Based Active Learning Approach for OCT Segmentation</title><link>http://arxiv.org/abs/2307.10745v2</link><description>Active learning algorithms have become increasingly popular for trainingmodels with limited data. However, selecting data for annotation remains achallenging problem due to the limited information available on unseen data. Toaddress this issue, we propose EdgeAL, which utilizes the edge information ofunseen images as {\it a priori} information for measuring uncertainty. Theuncertainty is quantified by analyzing the divergence and entropy in modelpredictions across edges. This measure is then used to select superpixels forannotation. We demonstrate the effectiveness of EdgeAL on multi-class OpticalCoherence Tomography (OCT) segmentation tasks, where we achieved a 99% dicescore while reducing the annotation label cost to 12%, 2.3%, and 3%,respectively, on three publicly available datasets (Duke, AROI, and UMN). Thesource code is available at \url{https://github.com/Mak-Ta-Reque/EdgeAL}</description><author>Md Abdul Kadir, Hasan Md Tusfiqur Alam, Daniel Sonntag</author><pubDate>Tue, 25 Jul 2023 15:25:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10745v2</guid></item><item><title>Re-mine, Learn and Reason: Exploring the Cross-modal Semantic Correlations for Language-guided HOI detection</title><link>http://arxiv.org/abs/2307.13529v1</link><description>Human-Object Interaction (HOI) detection is a challenging computer visiontask that requires visual models to address the complex interactiverelationship between humans and objects and predict HOI triplets. Despite thechallenges posed by the numerous interaction combinations, they also offeropportunities for multimodal learning of visual texts. In this paper, wepresent a systematic and unified framework (RmLR) that enhances HOI detectionby incorporating structured text knowledge. Firstly, we qualitatively andquantitatively analyze the loss of interaction information in the two-stage HOIdetector and propose a re-mining strategy to generate more comprehensive visualrepresentation.Secondly, we design more fine-grained sentence- and word-levelalignment and knowledge transfer strategies to effectively address themany-to-many matching problem between multiple interactions and multipletexts.These strategies alleviate the matching confusion problem that ariseswhen multiple interactions occur simultaneously, thereby improving theeffectiveness of the alignment process. Finally, HOI reasoning by visualfeatures augmented with textual knowledge substantially improves theunderstanding of interactions. Experimental results illustrate theeffectiveness of our approach, where state-of-the-art performance is achievedon public benchmarks. We further analyze the effects of different components ofour approach to provide insights into its efficacy.</description><author>Yichao Cao, Xiu Su, Qingfei Tang, Feng Yang, Shan You, Xiaobo Lu, Chang Xu</author><pubDate>Tue, 25 Jul 2023 15:20:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13529v1</guid></item><item><title>FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios</title><link>http://arxiv.org/abs/2307.13528v1</link><description>The emergence of generative pre-trained models has facilitated the synthesisof high-quality text, but it has also posed challenges in identifying factualerrors in the generated text. In particular: (1) A wider range of tasks nowface an increasing risk of containing factual errors when handled by generativemodels. (2) Generated texts tend to be lengthy and lack a clearly definedgranularity for individual facts. (3) There is a scarcity of explicit evidenceavailable during the process of fact checking. With the above challenges inmind, in this paper, we propose FacTool, a task and domain agnostic frameworkfor detecting factual errors of texts generated by large language models (e.g.,ChatGPT). Experiments on four different tasks (knowledge-based QA, codegeneration, mathematical reasoning, and scientific literature review) show theefficacy of the proposed method.</description><author>I-Chun Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu</author><pubDate>Tue, 25 Jul 2023 15:20:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13528v1</guid></item><item><title>Not with my name! Inferring artists' names of input strings employed by Diffusion Models</title><link>http://arxiv.org/abs/2307.13527v1</link><description>Diffusion Models (DM) are highly effective at generating realistic,high-quality images. However, these models lack creativity and merely composeoutputs based on their training data, guided by a textual input provided atcreation time. Is it acceptable to generate images reminiscent of an artist,employing his name as input? This imply that if the DM is able to replicate anartist's work then it was trained on some or all of his artworks thus violatingcopyright. In this paper, a preliminary study to infer the probability of useof an artist's name in the input string of a generated image is presented. Tothis aim we focused only on images generated by the famous DALL-E 2 andcollected images (both original and generated) of five renowned artists.Finally, a dedicated Siamese Neural Network was employed to have a first kindof probability. Experimental results demonstrate that our approach is anoptimal starting point and can be employed as a prior for predicting a completeinput string of an investigated image. Dataset and code are available at:https://github.com/ictlab-unict/not-with-my-name .</description><author>Roberto Leotta, Oliver Giudice, Luca Guarnera, Sebastiano Battiato</author><pubDate>Tue, 25 Jul 2023 15:18:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13527v1</guid></item><item><title>FDCT: Fast Depth Completion for Transparent Objects</title><link>http://arxiv.org/abs/2307.12274v2</link><description>Depth completion is crucial for many robotic tasks such as autonomousdriving, 3-D reconstruction, and manipulation. Despite the significantprogress, existing methods remain computationally intensive and often fail tomeet the real-time requirements of low-power robotic platforms. Additionally,most methods are designed for opaque objects and struggle with transparentobjects due to the special properties of reflection and refraction. To addressthese challenges, we propose a Fast Depth Completion framework for Transparentobjects (FDCT), which also benefits downstream tasks like object poseestimation. To leverage local information and avoid overfitting issues whenintegrating it with global information, we design a new fusion branch andshortcuts to exploit low-level features and a loss function to suppressoverfitting. This results in an accurate and user-friendly depth rectificationframework which can recover dense depth estimation from RGB-D images alone.Extensive experiments demonstrate that FDCT can run about 70 FPS with a higheraccuracy than the state-of-the-art methods. We also demonstrate that FDCT canimprove pose estimation in object grasping tasks. The source code is availableat https://github.com/Nonmy/FDCT</description><author>Tianan Li, Zhehan Chen, Huan Liu, Chen Wang</author><pubDate>Tue, 25 Jul 2023 15:17:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12274v2</guid></item><item><title>From CAD models to soft point cloud labels: An automatic annotation pipeline for cheaply supervised 3D semantic segmentation</title><link>http://arxiv.org/abs/2302.03114v3</link><description>We propose a fully automatic annotation scheme that takes a raw 3D pointcloud with a set of fitted CAD models as input and outputs convincingpoint-wise labels that can be used as cheap training data for point cloudsegmentation. Compared with manual annotations, we show that our automaticlabels are accurate while drastically reducing the annotation time andeliminating the need for manual intervention or dataset-specific parameters.Our labeling pipeline outputs semantic classes and soft point-wise objectscores, which can either be binarized into standard one-hot-encoded labels,thresholded into weak labels with ambiguous points left unlabeled, or useddirectly as soft labels during training. We evaluate the label quality andsegmentation performance of PointNet++ on a dataset of real industrial pointclouds and Scan2CAD, a public dataset of indoor scenes. Our results indicatethat reducing supervision in areas that are more difficult to labelautomatically is beneficial compared with the conventional approach of naivelyassigning a hard "best guess" label to every point.</description><author>Galadrielle Humblot-Renaux, Simon Buus Jensen, Andreas Møgelmose</author><pubDate>Tue, 25 Jul 2023 15:11:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.03114v3</guid></item><item><title>Towards Long-Term predictions of Turbulence using Neural Operators</title><link>http://arxiv.org/abs/2307.13517v1</link><description>This paper explores Neural Operators to predict turbulent flows, focusing onthe Fourier Neural Operator (FNO) model. It aims to developreduced-order/surrogate models for turbulent flow simulations using MachineLearning. Different model configurations are analyzed, with U-NET structures(UNO and U-FNET) performing better than the standard FNO in accuracy andstability. U-FNET excels in predicting turbulence at higher Reynolds numbers.Regularization terms, like gradient and stability losses, are essential forstable and accurate predictions. The study emphasizes the need for improvedmetrics for deep learning models in fluid flow prediction. Further researchshould focus on models handling complex flows and practical benchmarkingmetrics.</description><author>Fernando Gonzalez, François-Xavier Demoulin, Simon Bernard</author><pubDate>Tue, 25 Jul 2023 15:09:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13517v1</guid></item><item><title>DataComp: In search of the next generation of multimodal datasets</title><link>http://arxiv.org/abs/2304.14108v4</link><description>Multimodal datasets are a critical component in recent breakthroughs such asStable Diffusion and GPT-4, yet their design does not receive the same researchattention as model architectures or training algorithms. To address thisshortcoming in the ML ecosystem, we introduce DataComp, a testbed for datasetexperiments centered around a new candidate pool of 12.8 billion image-textpairs from Common Crawl. Participants in our benchmark design new filteringtechniques or curate new data sources and then evaluate their new dataset byrunning our standardized CLIP training code and testing the resulting model on38 downstream test sets. Our benchmark consists of multiple compute scalesspanning four orders of magnitude, which enables the study of scaling trendsand makes the benchmark accessible to researchers with varying resources. Ourbaseline experiments show that the DataComp workflow leads to better trainingsets. In particular, our best baseline, DataComp-1B, enables training a CLIPViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet, outperformingOpenAI's CLIP ViT-L/14 by 3.7 percentage points while using the same trainingprocedure and compute. We release DataComp and all accompanying code atwww.datacomp.ai.</description><author>Samir Yitzhak Gadre, Gabriel Ilharco, Alex Fang, Jonathan Hayase, Georgios Smyrnis, Thao Nguyen, Ryan Marten, Mitchell Wortsman, Dhruba Ghosh, Jieyu Zhang, Eyal Orgad, Rahim Entezari, Giannis Daras, Sarah Pratt, Vivek Ramanujan, Yonatan Bitton, Kalyani Marathe, Stephen Mussmann, Richard Vencu, Mehdi Cherti, Ranjay Krishna, Pang Wei Koh, Olga Saukh, Alexander Ratner, Shuran Song, Hannaneh Hajishirzi, Ali Farhadi, Romain Beaumont, Sewoong Oh, Alex Dimakis, Jenia Jitsev, Yair Carmon, Vaishaal Shankar, Ludwig Schmidt</author><pubDate>Tue, 25 Jul 2023 15:07:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14108v4</guid></item><item><title>HeightFormer: Explicit Height Modeling without Extra Data for Camera-only 3D Object Detection in Bird's Eye View</title><link>http://arxiv.org/abs/2307.13510v1</link><description>Vision-based Bird's Eye View (BEV) representation is an emerging perceptionformulation for autonomous driving. The core challenge is to construct BEVspace with multi-camera features, which is a one-to-many ill-posed problem.Diving into all previous BEV representation generation methods, we found thatmost of them fall into two types: modeling depths in image views or modelingheights in the BEV space, mostly in an implicit way. In this work, we proposeto explicitly model heights in the BEV space, which needs no extra data likeLiDAR and can fit arbitrary camera rigs and types compared to modeling depths.Theoretically, we give proof of the equivalence between height-based methodsand depth-based methods. Considering the equivalence and some advantages ofmodeling heights, we propose HeightFormer, which models heights anduncertainties in a self-recursive way. Without any extra data, the proposedHeightFormer could estimate heights in BEV accurately. Benchmark results showthat the performance of HeightFormer achieves SOTA compared with thosecamera-only methods.</description><author>Yiming Wu, Ruixiang Li, Zequn Qin, Xinhai Zhao, Xi Li</author><pubDate>Tue, 25 Jul 2023 15:02:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13510v1</guid></item><item><title>Online Streaming Video Super-Resolution with Convolutional Look-Up Table</title><link>http://arxiv.org/abs/2303.00334v4</link><description>Online video streaming has fundamental limitations on the transmissionbandwidth and computational capacity and super-resolution is a promisingpotential solution. However, applying existing video super-resolution methodsto online streaming is non-trivial. Existing video codecs and streamingprotocols (\eg, WebRTC) dynamically change the video quality both spatially andtemporally, which leads to diverse and dynamic degradations. Furthermore,online streaming has a strict requirement for latency that most existingmethods are less applicable. As a result, this paper focuses on the rarelyexploited problem setting of online streaming video super resolution. Tofacilitate the research on this problem, a new benchmark dataset namedLDV-WebRTC is constructed based on a real-world online streaming system.Leveraging the new benchmark dataset, we proposed a novel method specificallyfor online video streaming, which contains a convolution and Look-Up Table(LUT) hybrid model to achieve better performance-latency trade-off. To tacklethe changing degradations, we propose a mixture-of-expert-LUT module, where aset of LUT specialized in different degradations are built and adaptivelycombined to handle different degradations. Experiments show our method achieves720P video SR around 100 FPS, while significantly outperforms existingLUT-based methods and offers competitive performance compared to efficientCNN-based methods.</description><author>Guanghao Yin, Zefan Qu, Xinyang Jiang, Shan Jiang, Zhenhua Han, Ningxin Zheng, Xiaohong Liu, Huan Yang, Yuqing Yang, Dongsheng Li, Lili Qiu</author><pubDate>Tue, 25 Jul 2023 15:00:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.00334v4</guid></item><item><title>Assumption-lean falsification tests of rate double-robustness of double-machine-learning estimators</title><link>http://arxiv.org/abs/2306.10590v2</link><description>In this article we develop a feasible version of the assumption-lean tests inLiu et al. 20 that can falsify an analyst's justification for the validity of areported nominal $(1 - \alpha)$ Wald confidence interval (CI) centered at adouble machine learning (DML) estimator for any member of the class of doublyrobust (DR) functionals studied by Rotnitzky et al. 21. The class of DRfunctionals is broad and of central importance in economics and biostatistics.It strictly includes both (i) the class of mean-square continuous functionalsthat can be written as an expectation of an affine functional of a conditionalexpectation studied by Chernozhukov et al. 22 and the class of functionalsstudied by Robins et al. 08. The present state-of-the-art estimators for DRfunctionals $\psi$ are DML estimators $\hat{\psi}_{1}$. The bias of$\hat{\psi}_{1}$ depends on the product of the rates at which two nuisancefunctions $b$ and $p$ are estimated. Most commonly an analyst justifies thevalidity of her Wald CIs by proving that, under her complexity-reducingassumptions, the Cauchy-Schwarz (CS) upper bound for the bias of$\hat{\psi}_{1}$ is $o (n^{- 1 / 2})$. Thus if the hypothesis $H_{0}$: the CSupper bound is $o (n^{- 1 / 2})$ is rejected by our test, we will havefalsified the analyst's justification for the validity of her Wald CIs. In thiswork, we exhibit a valid assumption-lean falsification test of $H_{0}$, withoutrelying on complexity-reducing assumptions on $b, p$, or their estimates$\hat{b}, \hat{p}$. Simulation experiments are conducted to demonstrate how theproposed assumption-lean test can be used in practice. An unavoidablelimitation of our methodology is that no assumption-lean test of $H_{0}$,including ours, can be a consistent test. Thus failure of our test to reject isnot meaningful evidence in favor of $H_{0}$.</description><author>Lin Liu, Rajarshi Mukherjee, James M. Robins</author><pubDate>Tue, 25 Jul 2023 14:58:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10590v2</guid></item><item><title>Continuous Time Evidential Distributions for Irregular Time Series</title><link>http://arxiv.org/abs/2307.13503v1</link><description>Prevalent in many real-world settings such as healthcare, irregular timeseries are challenging to formulate predictions from. It is difficult to inferthe value of a feature at any given time when observations are sporadic, as itcould take on a range of values depending on when it was last observed. Tocharacterize this uncertainty we present EDICT, a strategy that learns anevidential distribution over irregular time series in continuous time. Thisdistribution enables well-calibrated and flexible inference of partiallyobserved features at any time of interest, while expanding uncertaintytemporally for sparse, irregular observations. We demonstrate that EDICTattains competitive performance on challenging time series classification tasksand enabling uncertainty-guided inference when encountering noisy data.</description><author>Taylor W. Killian, Haoran Zhang, Thomas Hartvigsen, Ava P. Amini</author><pubDate>Tue, 25 Jul 2023 14:54:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13503v1</guid></item><item><title>Deep Reinforcement Learning for Robust Goal-Based Wealth Management</title><link>http://arxiv.org/abs/2307.13501v1</link><description>Goal-based investing is an approach to wealth management that prioritizesachieving specific financial goals. It is naturally formulated as a sequentialdecision-making problem as it requires choosing the appropriate investmentuntil a goal is achieved. Consequently, reinforcement learning, a machinelearning technique appropriate for sequential decision-making, offers apromising path for optimizing these investment strategies. In this paper, anovel approach for robust goal-based wealth management based on deepreinforcement learning is proposed. The experimental results indicate itssuperiority over several goal-based wealth management benchmarks on bothsimulated and historical market data.</description><author>Tessa Bauman, Bruno Gašperov, Stjepan Begušić, Zvonko Kostanjčar</author><pubDate>Tue, 25 Jul 2023 14:51:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13501v1</guid></item><item><title>Finding Money Launderers Using Heterogeneous Graph Neural Networks</title><link>http://arxiv.org/abs/2307.13499v1</link><description>Current anti-money laundering (AML) systems, predominantly rule-based,exhibit notable shortcomings in efficiently and precisely detecting instancesof money laundering. As a result, there has been a recent surge towardexploring alternative approaches, particularly those utilizing machinelearning. Since criminals often collaborate in their money launderingendeavors, accounting for diverse types of customer relations and links becomescrucial. In line with this, the present paper introduces a graph neural network(GNN) approach to identify money laundering activities within a largeheterogeneous network constructed from real-world bank transactions andbusiness role data belonging to DNB, Norway's largest bank. Specifically, weextend the homogeneous GNN method known as the Message Passing Neural Network(MPNN) to operate effectively on a heterogeneous graph. As part of thisprocedure, we propose a novel method for aggregating messages across differentedges of the graph. Our findings highlight the importance of using anappropriate GNN architecture when combining information in heterogeneousgraphs. The performance results of our model demonstrate great potential inenhancing the quality of electronic surveillance systems employed by banks todetect instances of money laundering. To the best of our knowledge, this is thefirst published work applying GNN on a large real-world heterogeneous networkfor anti-money laundering purposes.</description><author>Fredrik Johannessen, Martin Jullum</author><pubDate>Tue, 25 Jul 2023 14:49:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13499v1</guid></item><item><title>Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition and Relation Extraction</title><link>http://arxiv.org/abs/2307.13497v1</link><description>The Zero-Shot Learning (ZSL) task pertains to the identification of entitiesor relations in texts that were not seen during training. ZSL has emerged as acritical research area due to the scarcity of labeled data in specific domains,and its applications have grown significantly in recent years. With the adventof large pretrained language models, several novel methods have been proposed,resulting in substantial improvements in ZSL performance. There is a growingdemand, both in the research community and industry, for a comprehensive ZSLframework that facilitates the development and accessibility of the latestmethods and pretrained models.In this study, we propose a novel ZSL frameworkcalled Zshot that aims to address the aforementioned challenges. Our primaryobjective is to provide a platform that allows researchers to compare differentstate-of-the-art ZSL methods with standard benchmark datasets. Additionally, wehave designed our framework to support the industry with readily available APIsfor production under the standard SpaCy NLP pipeline. Our API is extendible andevaluable, moreover, we include numerous enhancements such as boosting theaccuracy with pipeline ensembling and visualization utilities available as aSpaCy extension.</description><author>Gabriele Picco, Marcos Martínez Galindo, Alberto Purpura, Leopold Fuchs, Vanessa López, Hoang Thanh Lam</author><pubDate>Tue, 25 Jul 2023 14:46:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13497v1</guid></item><item><title>G-invariant diffusion maps</title><link>http://arxiv.org/abs/2306.07350v2</link><description>The diffusion maps embedding of data lying on a manifold have shown successin tasks ranging from dimensionality reduction and clustering, to datavisualization. In this work, we consider embedding data sets which were sampledfrom a manifold which is closed under the action of a continuous matrix group.An example of such a data set is images who's planar rotations are arbitrary.The G-invariant graph Laplacian, introduced in a previous work of the authors,admits eigenfunctions in the form of tensor products between the elements ofthe irreducible unitary representations of the group and eigenvectors ofcertain matrices. We employ these eigenfunctions to derive diffusion maps thatintrinsically account for the group action on the data. In particular, weconstruct both equivariant and invariant embeddings which can be used naturallyto cluster and align the data points. We demonstrate the effectiveness of ourconstruction with simulated data.</description><author>Eitan Rosen, Xiuyuan Cheng, Yoel Shkolnisky</author><pubDate>Tue, 25 Jul 2023 14:44:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07350v2</guid></item><item><title>Bound by the Bounty: Collaboratively Shaping Evaluation Processes for Queer AI Harms</title><link>http://arxiv.org/abs/2307.10223v2</link><description>Bias evaluation benchmarks and dataset and model documentation have emergedas central processes for assessing the biases and harms of artificialintelligence (AI) systems. However, these auditing processes have beencriticized for their failure to integrate the knowledge of marginalizedcommunities and consider the power dynamics between auditors and thecommunities. Consequently, modes of bias evaluation have been proposed thatengage impacted communities in identifying and assessing the harms of AIsystems (e.g., bias bounties). Even so, asking what marginalized communitieswant from such auditing processes has been neglected. In this paper, we askqueer communities for their positions on, and desires from, auditing processes.To this end, we organized a participatory workshop to critique and redesignbias bounties from queer perspectives. We found that when given space, thescope of feedback from workshop participants goes far beyond what bias bountiesafford, with participants questioning the ownership, incentives, and efficacyof bounties. We conclude by advocating for community ownership of bounties andcomplementing bounties with participatory processes (e.g., co-creation).</description><author>Organizers of QueerInAI, Nathan Dennler, Anaelia Ovalle, Ashwin Singh, Luca Soldaini, Arjun Subramonian, Huy Tu, William Agnew, Avijit Ghosh, Kyra Yee, Irene Font Peradejordi, Zeerak Talat, Mayra Russo, Jess de Jesus de Pinho Pinhal</author><pubDate>Tue, 25 Jul 2023 14:44:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10223v2</guid></item><item><title>FedTracker: Furnishing Ownership Verification and Traceability for Federated Learning Model</title><link>http://arxiv.org/abs/2211.07160v2</link><description>Federated learning (FL) is a distributed machine learning paradigm allowingmultiple clients to collaboratively train a global model without sharing theirlocal data. However, FL entails exposing the model to various participants.This poses a risk of unauthorized model distribution or resale by the maliciousclient, compromising the intellectual property rights of the FL group. To detersuch misbehavior, it is essential to establish a mechanism for verifying theownership of the model and as well tracing its origin to the leaker among theFL participants. In this paper, we present FedTracker, the first FL modelprotection framework that provides both ownership verification andtraceability. FedTracker adopts a bi-level protection scheme consisting ofglobal watermark mechanism and local fingerprint mechanism. The formerauthenticates the ownership of the global model, while the latter identifieswhich client the model is derived from. FedTracker leverages Continual Learning(CL) principles to embedding the watermark in a way that preserves the utilityof the FL model on both primitive task and watermark task. FedTracker alsodevises a novel metric to better discriminate different fingerprints.Experimental results show FedTracker is effective in ownership verification,traceability, and maintains good fidelity and robustness against variouswatermark removal attacks.</description><author>Shuo Shao, Wenyuan Yang, Hanlin Gu, Zhan Qin, Lixin Fan, Qiang Yang, Kui Ren</author><pubDate>Tue, 25 Jul 2023 14:43:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.07160v2</guid></item><item><title>Duet: efficient and scalable hybriD neUral rElation undersTanding</title><link>http://arxiv.org/abs/2307.13494v1</link><description>Cardinality estimation methods based on probability distribution estimationhave achieved high-precision estimation results compared to traditionalmethods. However, the most advanced methods suffer from high estimation costsdue to the sampling method they use when dealing with range queries. Also, sucha sampling method makes them difficult to differentiate, so the supervisionsignal from the query workload is difficult to train the model to improve theaccuracy of cardinality estimation. In this paper, we propose a new hybrid anddeterministic modeling approach (Duet) for the cardinality estimation problemwhich has better efficiency and scalability compared to previous approaches.Duet allows for direct cardinality estimation of range queries withsignificantly lower time and memory costs, as well as in a differentiable form.As the prediction process of this approach is differentiable, we canincorporate queries with larger model estimation errors into the trainingprocess to address the long-tail distribution problem of model estimationerrors on high dimensional tables. We evaluate Duet on classical datasets andbenchmarks, and the results prove the effectiveness of Duet.</description><author>Kaixin Zhang, Hongzhi Wang, Yabin Lu, Ziqi Li, Chang Shu, Yu Yan, Donghua Yang</author><pubDate>Tue, 25 Jul 2023 14:42:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13494v1</guid></item><item><title>NormAUG: Normalization-guided Augmentation for Domain Generalization</title><link>http://arxiv.org/abs/2307.13492v1</link><description>Deep learning has made significant advancements in supervised learning.However, models trained in this setting often face challenges due to domainshift between training and test sets, resulting in a significant drop inperformance during testing. To address this issue, several domaingeneralization methods have been developed to learn robust and domain-invariantfeatures from multiple training domains that can generalize well to unseen testdomains. Data augmentation plays a crucial role in achieving this goal byenhancing the diversity of the training data. In this paper, inspired by theobservation that normalizing an image with different statistics generated bydifferent batches with various domains can perturb its feature, we propose asimple yet effective method called NormAUG (Normalization-guided Augmentation).Our method includes two paths: the main path and the auxiliary (augmented)path. During training, the auxiliary path includes multiple sub-paths, eachcorresponding to batch normalization for a single domain or a randomcombination of multiple domains. This introduces diverse information at thefeature level and improves the generalization of the main path. Moreover, ourNormAUG method effectively reduces the existing upper boundary forgeneralization based on theoretical perspectives. During the test stage, weleverage an ensemble strategy to combine the predictions from the auxiliarypath of our model, further boosting performance. Extensive experiments areconducted on multiple benchmark datasets to validate the effectiveness of ourproposed method.</description><author>Lei Qi, Hongpeng Yang, Yinghuan Shi, Xin Geng</author><pubDate>Tue, 25 Jul 2023 14:35:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13492v1</guid></item><item><title>Cos R-CNN for Online Few-shot Object Detection</title><link>http://arxiv.org/abs/2307.13485v1</link><description>We propose Cos R-CNN, a simple exemplar-based R-CNN formulation that isdesigned for online few-shot object detection. That is, it is able to localiseand classify novel object categories in images with few examples withoutfine-tuning. Cos R-CNN frames detection as a learning-to-compare task: unseenclasses are represented as exemplar images, and objects are detected based ontheir similarity to these exemplars. The cosine-based classification headallows for dynamic adaptation of classification parameters to the exemplarembedding, and encourages the clustering of similar classes in embedding spacewithout the need for manual tuning of distance-metric hyperparameters. Thissimple formulation achieves best results on the recently proposed 5-wayImageNet few-shot detection benchmark, beating the online 1/5/10-shot scenariosby more than 8/3/1%, as well as performing up to 20% better in online 20-wayfew-shot VOC across all shots on novel classes.</description><author>Gratianus Wesley Putra Data, Henry Howard-Jenkins, David Murray, Victor Prisacariu</author><pubDate>Tue, 25 Jul 2023 14:22:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13485v1</guid></item><item><title>Rational kernel-based interpolation for complex-valued frequency response functions</title><link>http://arxiv.org/abs/2307.13484v1</link><description>This work is concerned with the kernel-based approximation of acomplex-valued function from data, where the frequency response function of apartial differential equation in the frequency domain is of particularinterest. In this setting, kernel methods are employed more and morefrequently, however, standard kernels do not perform well. Moreover, the roleand mathematical implications of the underlying pair of kernels, which arisesnaturally in the complex-valued case, remain to be addressed. We introduce newreproducing kernel Hilbert spaces of complex-valued functions, and formulatethe problem of complex-valued interpolation with a kernel pair as minimum norminterpolation in these spaces. Moreover, we combine the interpolant with alow-order rational function, where the order is adaptively selected based on anew model selection criterion. Numerical results on examples from differentfields, including electromagnetics and acoustic examples, illustrate theperformance of the method, also in comparison to available rationalapproximation methods.</description><author>Julien Bect, Niklas Georg, Ulrich Römer, Sebastian Schöps</author><pubDate>Tue, 25 Jul 2023 14:21:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13484v1</guid></item><item><title>Faster Predict-and-Optimize with Davis-Yin Splitting</title><link>http://arxiv.org/abs/2301.13395v2</link><description>In many applications, a combinatorial problem must be repeatedly solved withsimilar, but distinct parameters. Yet, the parameters $w$ are not directlyobserved; only contextual data $d$ that correlates with $w$ is available. It istempting to use a neural network to predict $w$ given $d$, but training such amodel requires reconciling the discrete nature of combinatorial optimizationwith the gradient-based frameworks used to train neural networks. When theproblem in question is an Integer Linear Program (ILP), one approach toovercoming this issue is to consider a continuous relaxation of thecombinatorial problem. While existing methods utilizing this approach haveshown to be highly effective on small problems (10-100 variables), they do notscale well to large problems. In this work, we draw on ideas from modern convexoptimization to design a network and training scheme which scales effortlesslyto problems with thousands of variables.</description><author>Daniel McKenzie, Samy Wu Fung, Howard Heaton</author><pubDate>Tue, 25 Jul 2023 14:13:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13395v2</guid></item><item><title>Revision Transformers: Instructing Language Models to Change their Values</title><link>http://arxiv.org/abs/2210.10332v3</link><description>Current transformer language models (LM) are large-scale models with billionsof parameters. They have been shown to provide high performances on a varietyof tasks but are also prone to shortcut learning and bias. Addressing suchincorrect model behavior via parameter adjustments is very costly. This isparticularly problematic for updating dynamic concepts, such as moral values,which vary culturally or interpersonally. In this work, we question the currentcommon practice of storing all information in the model parameters and proposethe Revision Transformer (RiT) to facilitate easy model updating. The specificcombination of a large-scale pre-trained LM that inherently but also diffuselyencodes world knowledge with a clear-structured revision engine makes itpossible to update the model's knowledge with little effort and the help ofuser interaction. We exemplify RiT on a moral dataset and simulate userfeedback demonstrating strong performance in model revision even with smalldata. This way, users can easily design a model regarding their preferences,paving the way for more transparent AI models.</description><author>Felix Friedrich, Wolfgang Stammer, Patrick Schramowski, Kristian Kersting</author><pubDate>Tue, 25 Jul 2023 14:02:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.10332v3</guid></item><item><title>Combinatorial Auctions and Graph Neural Networks for Local Energy Flexibility Markets</title><link>http://arxiv.org/abs/2307.13470v1</link><description>This paper proposes a new combinatorial auction framework for local energyflexibility markets, which addresses the issue of prosumers' inability tobundle multiple flexibility time intervals. To solve the underlying NP-completewinner determination problems, we present a simple yet powerful heterogeneoustri-partite graph representation and design graph neural network-based models.Our models achieve an average optimal value deviation of less than 5\% from anoff-the-shelf optimization tool and show linear inference time complexitycompared to the exponential complexity of the commercial solver. Contributionsand results demonstrate the potential of using machine learning to efficientlyallocate energy flexibility resources in local markets and solving optimizationproblems in general.</description><author>Awadelrahman M. A. Ahmed, Frank Eliassen, Yan Zhang</author><pubDate>Tue, 25 Jul 2023 14:01:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13470v1</guid></item><item><title>TEFL: Turbo Explainable Federated Learning for 6G Trustworthy Zero-Touch Network Slicing</title><link>http://arxiv.org/abs/2210.10147v2</link><description>Sixth-generation (6G) networks anticipate intelligently supporting a massivenumber of coexisting and heterogeneous slices associated with various verticaluse cases. Such a context urges the adoption of artificial intelligence(AI)-driven zero-touch management and orchestration (MANO) of the end-to-end(E2E) slices under stringent service level agreements (SLAs). Specifically, thetrustworthiness of the AI black-boxes in real deployment can be achieved byexplainable AI (XAI) tools to build transparency between the interacting actorsin the slicing ecosystem, such as tenants, infrastructure providers andoperators. Inspired by the turbo principle, this paper presents a noveliterative explainable federated learning (FL) approach where a constrainedresource allocation model and an \emph{explainer} exchange -- in a closed loop(CL) fashion -- soft attributions of the features as well as inferencepredictions to achieve a transparent and SLA-aware zero-touch servicemanagement (ZSM) of 6G network slices at RAN-Edge setup under non-independentidentically distributed (non-IID) datasets. In particular, we quantitativelyvalidate the faithfulness of the explanations via the so-calledattribution-based \emph{confidence metric} that is included as a constraint inthe run-time FL optimization task. In this respect, Integrated-Gradient (IG) aswell as Input $\times$ Gradient and SHAP are used to generate the attributionsfor the turbo explainable FL (TEFL), wherefore simulation results underdifferent methods confirm its superiority over an unconstrainedIntegrated-Gradient \emph{post-hoc} FL baseline.</description><author>Swastika Roy, Hatim Chergui, Christos Verikoukis</author><pubDate>Tue, 25 Jul 2023 13:57:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.10147v2</guid></item><item><title>Gaussian Graph with Prototypical Contrastive Learning in E-Commerce Bundle Recommendation</title><link>http://arxiv.org/abs/2307.13468v1</link><description>Bundle recommendation aims to provide a bundle of items to satisfy the userpreference on e-commerce platform. Existing successful solutions are based onthe contrastive graph learning paradigm where graph neural networks (GNNs) areemployed to learn representations from user-level and bundle-level graph viewswith a contrastive learning module to enhance the cooperative associationbetween different views. Nevertheless, they ignore the uncertainty issue whichhas a significant impact in real bundle recommendation scenarios due to thelack of discriminative information caused by highly sparsity or diversity. Wefurther suggest that their instancewise contrastive learning fails todistinguish the semantically similar negatives (i.e., sampling bias issue),resulting in performance degradation. In this paper, we propose a novelGaussian Graph with Prototypical Contrastive Learning (GPCL) framework toovercome these challenges. In particular, GPCL embeds each user/bundle/item asa Gaussian distribution rather than a fixed vector. We further design aprototypical contrastive learning module to capture the contextual informationand mitigate the sampling bias issue. Extensive experiments demonstrate thatbenefiting from the proposed components, we achieve new state-of-the-artperformance compared to previous methods on several public datasets. Moreover,GPCL has been deployed on real-world e-commerce platform and achievedsubstantial improvements.</description><author>Zhao-Yang Liu, Liucheng Sun, Chenwei Weng, Qijin Chen, Chengfu Huo</author><pubDate>Tue, 25 Jul 2023 13:56:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13468v1</guid></item><item><title>Integrating processed-based models and machine learning for crop yield prediction</title><link>http://arxiv.org/abs/2307.13466v1</link><description>Crop yield prediction typically involves the utilization of eithertheory-driven process-based crop growth models, which have proven to bedifficult to calibrate for local conditions, or data-driven machine learningmethods, which are known to require large datasets. In this work we investigatepotato yield prediction using a hybrid meta-modeling approach. A crop growthmodel is employed to generate synthetic data for (pre)training a convolutionalneural net, which is then fine-tuned with observational data. When applied insilico, our meta-modeling approach yields better predictions than a baselinecomprising a purely data-driven approach. When tested on real-world data fromfield trials (n=303) and commercial fields (n=77), the meta-modeling approachyields competitive results with respect to the crop growth model. In the latterset, however, both models perform worse than a simple linear regression with ahand-picked feature set and dedicated preprocessing designed by domain experts.Our findings indicate the potential of meta-modeling for accurate crop yieldprediction; however, further advancements and validation using extensivereal-world datasets is recommended to solidify its practical effectiveness.</description><author>Michiel G. J. Kallenberg, Bernardo Maestrini, Ron van Bree, Paul Ravensbergen, Christos Pylianidis, Frits van Evert, Ioannis N. Athanasiadis</author><pubDate>Tue, 25 Jul 2023 13:51:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13466v1</guid></item><item><title>Unlocking the Emotional World of Visual Media: An Overview of the Science, Research, and Impact of Understanding Emotion</title><link>http://arxiv.org/abs/2307.13463v1</link><description>The emergence of artificial emotional intelligence technology isrevolutionizing the fields of computers and robotics, allowing for a new levelof communication and understanding of human behavior that was once thoughtimpossible. While recent advancements in deep learning have transformed thefield of computer vision, automated understanding of evoked or expressedemotions in visual media remains in its infancy. This foundering stems from theabsence of a universally accepted definition of "emotion", coupled with theinherently subjective nature of emotions and their intricate nuances. In thisarticle, we provide a comprehensive, multidisciplinary overview of the field ofemotion analysis in visual media, drawing on insights from psychology,engineering, and the arts. We begin by exploring the psychological foundationsof emotion and the computational principles that underpin the understanding ofemotions from images and videos. We then review the latest research and systemswithin the field, accentuating the most promising approaches. We also discussthe current technological challenges and limitations of emotion analysis,underscoring the necessity for continued investigation and innovation. Wecontend that this represents a "Holy Grail" research problem in computing anddelineate pivotal directions for future inquiry. Finally, we examine theethical ramifications of emotion-understanding technologies and contemplatetheir potential societal impacts. Overall, this article endeavors to equipreaders with a deeper understanding of the domain of emotion analysis in visualmedia and to inspire further research and development in this captivating andrapidly evolving field.</description><author>James Z. Wang, Sicheng Zhao, Chenyan Wu, Reginald B. Adams, Michelle G. Newman, Tal Shafir, Rachelle Tsachor</author><pubDate>Tue, 25 Jul 2023 13:47:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13463v1</guid></item><item><title>Fundamental causal bounds of quantum random access memories</title><link>http://arxiv.org/abs/2307.13460v1</link><description>Quantum devices should operate in adherence to quantum physics principles.Quantum random access memory (QRAM), a fundamental component of many essentialquantum algorithms for tasks such as linear algebra, data search, and machinelearning, is often proposed to offer $\mathcal{O}(\log N)$ circuit depth for$\mathcal{O}(N)$ data size, given $N$ qubits. However, this claim appears tobreach the principle of relativity when dealing with a large number of qubitsin quantum materials interacting locally. In our study we critically explorethe intrinsic bounds of rapid quantum memories based on causality, employingthe relativistic quantum field theory and Lieb-Robinson bounds in quantummany-body systems. In this paper, we consider a hardware-efficient QRAM designin hybrid quantum acoustic systems. Assuming clock cycle times of approximately$10^{-3}$ seconds and a lattice spacing of about 1 micrometer, we show thatQRAM can accommodate up to $\mathcal{O}(10^7)$ logical qubits in 1 dimension,$\mathcal{O}(10^{15})$ to $\mathcal{O}(10^{20})$ in various 2D architectures,and $\mathcal{O}(10^{24})$ in 3 dimensions. We contend that this causalitybound broadly applies to other quantum hardware systems. Our findings highlightthe impact of fundamental quantum physics constraints on the long-termperformance of quantum computing applications in data science and suggestpotential quantum memory designs for performance enhancement.</description><author>Yunfei Wang, Yuri Alexeev, Liang Jiang, Frederic T. Chong, Junyu Liu</author><pubDate>Tue, 25 Jul 2023 13:40:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13460v1</guid></item><item><title>Weakly-supervised 3D Pose Transfer with Keypoints</title><link>http://arxiv.org/abs/2307.13459v1</link><description>The main challenges of 3D pose transfer are: 1) Lack of paired training datawith different characters performing the same pose; 2) Disentangling pose andshape information from the target mesh; 3) Difficulty in applying to mesheswith different topologies. We thus propose a novel weakly-supervisedkeypoint-based framework to overcome these difficulties. Specifically, we use atopology-agnostic keypoint detector with inverse kinematics to computetransformations between the source and target meshes. Our method only requiressupervision on the keypoints, can be applied to meshes with differenttopologies and is shape-invariant for the target which allows extraction ofpose-only information from the target meshes without transferring shapeinformation. We further design a cycle reconstruction to performself-supervised pose transfer without the need for ground truth deformed meshwith the same pose and shape as the target and source, respectively. Weevaluate our approach on benchmark human and animal datasets, where we achievesuperior performance compared to the state-of-the-art unsupervised approachesand even comparable performance with the fully supervised approaches. We teston the more challenging Mixamo dataset to verify our approach's ability inhandling meshes with different topologies and complex clothes. Cross-datasetevaluation further shows the strong generalization ability of our approach.</description><author>Jinnan Chen, Chen Li, Gim Hee Lee</author><pubDate>Tue, 25 Jul 2023 13:40:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13459v1</guid></item><item><title>A Deep Learning Approach for Overall Survival prediction in Lung Cancer with Missing Values</title><link>http://arxiv.org/abs/2307.11465v2</link><description>One of the most challenging fields where Artificial Intelligence (AI) can beapplied is lung cancer research, specifically non-small cell lung cancer(NSCLC). In particular, overall survival (OS), the time between diagnosis anddeath, is a vital indicator of patient status, enabling tailored treatment andimproved OS rates. In this analysis, there are two challenges to take intoaccount. First, few studies effectively exploit the information available fromeach patient, leveraging both uncensored (i.e., dead) and censored (i.e.,survivors) patients, considering also the events' time. Second, the handling ofincomplete data is a common issue in the medical field. This problem istypically tackled through the use of imputation methods. Our objective is topresent an AI model able to overcome these limits, effectively learning fromboth censored and uncensored patients and their available features, for theprediction of OS for NSCLC patients. We present a novel approach to survivalanalysis with missing values in the context of NSCLC, which exploits thestrengths of the transformer architecture to account only for availablefeatures without requiring any imputation strategy. By making use of ad-hoclosses for OS, it is able to account for both censored and uncensored patients,as well as changes in risks over time. We compared our method withstate-of-the-art models for survival analysis coupled with different imputationstrategies. We evaluated the results obtained over a period of 6 years usingdifferent time granularities obtaining a Ct-index, a time-dependent variant ofthe C-index, of 71.97, 77.58 and 80.72 for time units of 1 month, 1 year and 2years, respectively, outperforming all state-of-the-art methods regardless ofthe imputation method used.</description><author>Camillo Maria Caruso, Valerio Guarrasi, Sara Ramella, Paolo Soda</author><pubDate>Tue, 25 Jul 2023 13:39:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11465v2</guid></item><item><title>Monte-Carlo Tree Search for Multi-Agent Pathfinding: Preliminary Results</title><link>http://arxiv.org/abs/2307.13453v1</link><description>In this work we study a well-known and challenging problem of Multi-agentPathfinding, when a set of agents is confined to a graph, each agent isassigned a unique start and goal vertices and the task is to find a set ofcollision-free paths (one for each agent) such that each agent reaches itsrespective goal. We investigate how to utilize Monte-Carlo Tree Search (MCTS)to solve the problem. Although MCTS was shown to demonstrate superiorperformance in a wide range of problems like playing antagonistic games (e.g.Go, Chess etc.), discovering faster matrix multiplication algorithms etc., itsapplication to the problem at hand was not well studied before. To this end weintroduce an original variant of MCTS, tailored to multi-agent pathfinding. Thecrux of our approach is how the reward, that guides MCTS, is computed.Specifically, we use individual paths to assist the agents with the thegoal-reaching behavior, while leaving them freedom to get off the track if itis needed to avoid collisions. We also use a dedicated decomposition techniqueto reduce the branching factor of the tree search procedure. Empirically weshow that the suggested method outperforms the baseline planning algorithm thatinvokes heuristic search, e.g. A*, at each re-planning step.</description><author>Yelisey Pitanov, Alexey Skrynnik, Anton Andreychuk, Konstantin Yakovlev, Aleksandr Panov</author><pubDate>Tue, 25 Jul 2023 13:33:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13453v1</guid></item><item><title>Non-linear Neurons with Human-like Apical Dendrite Activations</title><link>http://arxiv.org/abs/2003.03229v4</link><description>In order to classify linearly non-separable data, neurons are typicallyorganized into multi-layer neural networks that are equipped with at least onehidden layer. Inspired by some recent discoveries in neuroscience, we propose anew model of artificial neuron along with a novel activation function enablingthe learning of nonlinear decision boundaries using a single neuron. We showthat a standard neuron followed by our novel apical dendrite activation (ADA)can learn the XOR logical function with 100% accuracy. Furthermore, we conductexperiments on six benchmark data sets from computer vision, signal processingand natural language processing, i.e. MOROCO, UTKFace, CREMA-D, Fashion-MNIST,Tiny ImageNet and ImageNet, showing that the ADA and the leaky ADA functionsprovide superior results to Rectified Linear Units (ReLU), leaky ReLU, RBF andSwish, for various neural network architectures, e.g. one-hidden-layer ortwo-hidden-layer multi-layer perceptrons (MLPs) and convolutional neuralnetworks (CNNs) such as LeNet, VGG, ResNet and Character-level CNN. We obtainfurther performance improvements when we change the standard model of theneuron with our pyramidal neuron with apical dendrite activations (PyNADA). Ourcode is available at: https://github.com/raduionescu/pynada.</description><author>Mariana-Iuliana Georgescu, Radu Tudor Ionescu, Nicolae-Catalin Ristea, Nicu Sebe</author><pubDate>Tue, 25 Jul 2023 13:25:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2003.03229v4</guid></item></channel></rss>