<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 26 Jun 2023 06:00:07 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>ProRes: Exploring Degradation-aware Visual Prompt for Universal Image Restoration</title><link>http://arxiv.org/abs/2306.13653v1</link><description>Image restoration aims to reconstruct degraded images, e.g., denoising ordeblurring. Existing works focus on designing task-specific methods and thereare inadequate attempts at universal methods. However, simply unifying multipletasks into one universal architecture suffers from uncontrollable and undesiredpredictions. To address those issues, we explore prompt learning in universalarchitectures for image restoration tasks. In this paper, we presentDegradation-aware Visual Prompts, which encode various types of imagedegradation, e.g., noise and blur, into unified visual prompts. Thesedegradation-aware prompts provide control over image processing and allowweighted combinations for customized image restoration. We then leveragedegradation-aware visual prompts to establish a controllable and universalmodel for image restoration, called ProRes, which is applicable to an extensiverange of image restoration tasks. ProRes leverages the vanilla VisionTransformer (ViT) without any task-specific designs. Furthermore, thepre-trained ProRes can easily adapt to new tasks through efficient prompttuning with only a few images. Without bells and whistles, ProRes achievescompetitive performance compared to task-specific methods and experiments candemonstrate its ability for controllable restoration and adaptation for newtasks. The code and models will be released in\url{https://github.com/leonmakise/ProRes}.</description><author>Jiaqi Ma, Tianheng Cheng, Guoli Wang, Qian Zhang, Xinggang Wang, Lefei Zhang</author><pubDate>Fri, 23 Jun 2023 18:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13653v1</guid></item><item><title>Bring Your Own Data! Self-Supervised Evaluation for Large Language Models</title><link>http://arxiv.org/abs/2306.13651v1</link><description>With the rise of Large Language Models (LLMs) and their ubiquitous deploymentin diverse domains, measuring language model behavior on realistic data isimperative. For example, a company deploying a client-facing chatbot mustensure that the model will not respond to client requests with profanity.Current evaluations approach this problem using small, domain-specific datasetswith human-curated labels. These evaluation sets are often sampled from anarrow and simplified distribution, and data sources can unknowingly be leakedinto the training set which can lead to misleading evaluations. To bypass thesedrawbacks, we propose a framework for self-supervised evaluation of LLMs byanalyzing their sensitivity or invariance to transformations on the input text.Self-supervised evaluation can directly monitor LLM behavior on datasetscollected in the wild or streamed during live model deployment. We demonstrateself-supervised evaluation strategies for measuring closed-book knowledge,toxicity, and long-range context dependence, in addition to sensitivity togrammatical structure and tokenization errors. When comparisons to similarhuman-labeled benchmarks are available, we find strong correlations betweenself-supervised and human-supervised evaluations. The self-supervised paradigmcomplements current evaluation strategies that rely on labeled data.</description><author>Neel Jain, Khalid Saifullah, Yuxin Wen, John Kirchenbauer, Manli Shu, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein</author><pubDate>Fri, 23 Jun 2023 18:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13651v1</guid></item><item><title>GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models</title><link>http://arxiv.org/abs/2306.13649v1</link><description>Knowledge distillation is commonly used for compressing neural networks toreduce their inference cost and memory footprint. However, current distillationmethods for auto-regressive models, such as generative language models (LMs),suffer from two key issues: (1) distribution mismatch between output sequencesduring training and the sequences generated by the student during itsdeployment, and (2) model under-specification, where the student model may notbe expressive enough to fit the teacher's distribution. To address theseissues, we propose Generalized Knowledge Distillation (GKD). GKD mitigatesdistribution mismatch by sampling output sequences from the student duringtraining. Furthermore, GKD handles model under-specification by optimizingalternative divergences, such as reverse KL, that focus on generating samplesfrom the student that are likely under the teacher's distribution. Wedemonstrate that GKD outperforms commonly-used approaches for distilling LLMson summarization, machine translation, and arithmetic reasoning tasks.</description><author>Rishabh Agarwal, Nino Vieillard, Piotr Stanczyk, Sabela Ramos, Matthieu Geist, Olivier Bachem</author><pubDate>Fri, 23 Jun 2023 18:56:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13649v1</guid></item><item><title>LightGlue: Local Feature Matching at Light Speed</title><link>http://arxiv.org/abs/2306.13643v1</link><description>We introduce LightGlue, a deep neural network that learns to match localfeatures across images. We revisit multiple design decisions of SuperGlue, thestate of the art in sparse matching, and derive simple but effectiveimprovements. Cumulatively, they make LightGlue more efficient - in terms ofboth memory and computation, more accurate, and much easier to train. One keyproperty is that LightGlue is adaptive to the difficulty of the problem: theinference is much faster on image pairs that are intuitively easy to match, forexample because of a larger visual overlap or limited appearance change. Thisopens up exciting prospects for deploying deep matchers in latency-sensitiveapplications like 3D reconstruction. The code and trained models are publiclyavailable at https://github.com/cvg/LightGlue.</description><author>Philipp Lindenberger, Paul-Edouard Sarlin, Marc Pollefeys</author><pubDate>Fri, 23 Jun 2023 18:52:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13643v1</guid></item><item><title>A New Paradigm for Generative Adversarial Networks based on Randomized Decision Rules</title><link>http://arxiv.org/abs/2306.13641v1</link><description>The Generative Adversarial Network (GAN) was recently introduced in theliterature as a novel machine learning method for training generative models.It has many applications in statistics such as nonparametric clustering andnonparametric conditional independence tests. However, training the GAN isnotoriously difficult due to the issue of mode collapse, which refers to thelack of diversity among generated data. In this paper, we identify the reasonswhy the GAN suffers from this issue, and to address it, we propose a newformulation for the GAN based on randomized decision rules. In the newformulation, the discriminator converges to a fixed point while the generatorconverges to a distribution at the Nash equilibrium. We propose to train theGAN by an empirical Bayes-like method by treating the discriminator as ahyper-parameter of the posterior distribution of the generator. Specifically,we simulate generators from its posterior distribution conditioned on thediscriminator using a stochastic gradient Markov chain Monte Carlo (MCMC)algorithm, and update the discriminator using stochastic gradient descent alongwith simulations of the generators. We establish convergence of the proposedmethod to the Nash equilibrium. Apart from image generation, we apply theproposed method to nonparametric clustering and nonparametric conditionalindependence tests. A portion of the numerical results is presented in thesupplementary material.</description><author>Sehwan Kim, Qifan Song, Faming Liang</author><pubDate>Fri, 23 Jun 2023 18:50:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13641v1</guid></item><item><title>Optimal Sensor Placement with Adaptive Constraints for Nuclear Digital Twins</title><link>http://arxiv.org/abs/2306.13637v1</link><description>Given harsh operating conditions and physical constraints in reactors,nuclear applications cannot afford to equip the physical asset with a largearray of sensors. Therefore, it is crucial to carefully determine the placementof sensors within the given spatial limitations, enabling the reconstruction ofreactor flow fields and the creation of nuclear digital twins. Various designconsiderations are imposed, such as predetermined sensor locations, restrictedareas within the reactor, a fixed number of sensors allocated to a specificregion, or sensors positioned at a designated distance from one another. Wedevelop a data-driven technique that integrates constraints into anoptimization procedure for sensor placement, aiming to minimize reconstructionerrors. Our approach employs a greedy algorithm that can optimize sensorlocations on a grid, adhering to user-defined constraints. We demonstrate thenear optimality of our algorithm by computing all possible configurations forselecting a certain number of sensors for a randomly generated state spacesystem. In this work, the algorithm is demonstrated on the Out-of-Pile Testingand Instrumentation Transient Water Irradiation System (OPTI-TWIST) prototypevessel, which is electrically heated to mimic the neutronics effect of theTransient Reactor Test facility (TREAT) at Idaho National Laboratory (INL). Theresulting sensor-based reconstruction of temperature within the OPTI-TWISTminimizes error, provides probabilistic bounds for noise-induced uncertaintyand will finally be used for communication between the digital twin andexperimental facility.</description><author>Niharika Karnik, Mohammad G. Abdo, Carlos E. Estrada Perez, Jun Soo Yoo, Joshua J. Cogliati, Richard S. Skifton, Pattrick Calderoni, Steven L. Brunton, Krithika Manohar</author><pubDate>Fri, 23 Jun 2023 18:47:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13637v1</guid></item><item><title>OpenMask3D: Open-Vocabulary 3D Instance Segmentation</title><link>http://arxiv.org/abs/2306.13631v1</link><description>We introduce the task of open-vocabulary 3D instance segmentation.Traditional approaches for 3D instance segmentation largely rely on existing 3Dannotated datasets, which are restricted to a closed-set of object categories.This is an important limitation for real-life applications where one might needto perform tasks guided by novel, open-vocabulary queries related to objectsfrom a wide variety. Recently, open-vocabulary 3D scene understanding methodshave emerged to address this problem by learning queryable features per eachpoint in the scene. While such a representation can be directly employed toperform semantic segmentation, existing methods have limitations in theirability to identify object instances. In this work, we address this limitation,and propose OpenMask3D, which is a zero-shot approach for open-vocabulary 3Dinstance segmentation. Guided by predicted class-agnostic 3D instance masks,our model aggregates per-mask features via multi-view fusion of CLIP-basedimage embeddings. We conduct experiments and ablation studies on the ScanNet200dataset to evaluate the performance of OpenMask3D, and provide insights aboutthe open-vocabulary 3D instance segmentation task. We show that our approachoutperforms other open-vocabulary counterparts, particularly on the long-taildistribution. Furthermore, OpenMask3D goes beyond the limitations ofclose-vocabulary approaches, and enables the segmentation of object instancesbased on free-form queries describing object properties such as semantics,geometry, affordances, and material properties.</description><author>Ayça Takmaz, Elisabetta Fedele, Robert W. Sumner, Marc Pollefeys, Federico Tombari, Francis Engelmann</author><pubDate>Fri, 23 Jun 2023 18:36:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13631v1</guid></item><item><title>Offline Skill Graph (OSG): A Framework for Learning and Planning using Offline Reinforcement Learning Skills</title><link>http://arxiv.org/abs/2306.13630v1</link><description>Reinforcement Learning has received wide interest due to its success incompetitive games. Yet, its adoption in everyday applications is limited (e.g.industrial, home, healthcare, etc.). In this paper, we address this limitationby presenting a framework for planning over offline skills and solving complextasks in real-world environments. Our framework is comprised of three modulesthat together enable the agent to learn from previously collected data andgeneralize over it to solve long-horizon tasks. We demonstrate our approach bytesting it on a robotic arm that is required to solve complex tasks.</description><author>Ben-ya Halevy, Yehudit Aperstein, Dotan Di Castro</author><pubDate>Fri, 23 Jun 2023 18:35:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13630v1</guid></item><item><title>From Contextual Data to Newsvendor Decisions: On the Actual Performance of Data-Driven Algorithms</title><link>http://arxiv.org/abs/2302.08424v2</link><description>In this work, we explore a framework for contextual decision-making to studyhow the relevance and quantity of past data affects the performance of adata-driven policy. We analyze a contextual Newsvendor problem in which adecision-maker needs to trade-off between an underage and an overage cost inthe face of uncertain demand. We consider a setting in which past demandsobserved under ``close by'' contexts come from close by distributions andanalyze the performance of data-driven algorithms through a notion ofcontext-dependent worst-case expected regret. We analyze the broad class ofWeighted Empirical Risk Minimization (WERM) policies which weigh past dataaccording to their similarity in the contextual space. This class includesclassical policies such as ERM, k-Nearest Neighbors and kernel-based policies.Our main methodological contribution is to characterize exactly the worst-caseregret of any WERM policy on any given configuration of contexts. To the bestof our knowledge, this provides the first understanding of tight performanceguarantees in any contextual decision-making problem, with past literaturefocusing on upper bounds via concentration inequalities. We instead take anoptimization approach, and isolate a structure in the Newsvendor loss functionthat allows to reduce the infinite-dimensional optimization problem overworst-case distributions to a simple line search. This in turn allows us to unveil fundamental insights that were obfuscated byprevious general-purpose bounds. We characterize actual guaranteed performanceas a function of the contexts, as well as granular insights on the learningcurve of algorithms.</description><author>Omar Besbes, Will Ma, Omar Mouchtaki</author><pubDate>Fri, 23 Jun 2023 18:22:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08424v2</guid></item><item><title>DeepGraviLens: a Multi-Modal Architecture for Classifying Gravitational Lensing Data</title><link>http://arxiv.org/abs/2205.00701v4</link><description>Gravitational lensing is the relativistic effect generated by massive bodies,which bend the space-time surrounding them. It is a deeply investigated topicin astrophysics and allows validating theoretical relativistic results andstudying faint astrophysical objects that would not be visible otherwise. Inrecent years Machine Learning methods have been applied to support the analysisof the gravitational lensing phenomena by detecting lensing effects in datasets consisting of images associated with brightness variation time series.However, the state-of-art approaches either consider only images and neglecttime-series data or achieve relatively low accuracy on the most difficult datasets. This paper introduces DeepGraviLens, a novel multi-modal network thatclassifies spatio-temporal data belonging to one non-lensed system type andthree lensed system types. It surpasses the current state of the art accuracyresults by $\approx 3\%$ to $\approx 11\%$, depending on the considered dataset. Such an improvement will enable the acceleration of the analysis of lensedobjects in upcoming astrophysical surveys, which will exploit the petabytes ofdata collected, e.g., from the Vera C. Rubin Observatory.</description><author>Nicolò Oreste Pinciroli Vago, Piero Fraternali</author><pubDate>Fri, 23 Jun 2023 18:13:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.00701v4</guid></item><item><title>DLKoopman: A deep learning software package for Koopman theory</title><link>http://arxiv.org/abs/2211.08992v2</link><description>We present DLKoopman -- a software package for Koopman theory that uses deeplearning to learn an encoding of a nonlinear dynamical system into a linearspace, while simultaneously learning the linear dynamics. While severalprevious efforts have either restricted the ability to learn encodings, or beenbespoke efforts designed for specific systems, DLKoopman is a generalized toolthat can be applied to data-driven learning and optimization of any dynamicalsystem. It can either be trained on data from individual states (snapshots) ofa system and used to predict its unknown states, or trained on data fromtrajectories of a system and used to predict unknown trajectories for newinitial states. DLKoopman is available on the Python Package Index (PyPI) as'dlkoopman', and includes extensive documentation and tutorials. Additionalcontributions of the package include a novel metric called Average NormalizedAbsolute Error for evaluating performance, and a ready-to-use hyperparametersearch module for improving performance.</description><author>Sourya Dey, Eric Davis</author><pubDate>Fri, 23 Jun 2023 18:10:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.08992v2</guid></item><item><title>ExpPoint-MAE: Better interpretability and performance for self-supervised point cloud transformers</title><link>http://arxiv.org/abs/2306.10798v2</link><description>In this paper we delve into the properties of transformers, attained throughself-supervision, in the point cloud domain. Specifically, we evaluate theeffectiveness of Masked Autoencoding as a pretraining scheme, and exploreMomentum Contrast as an alternative. In our study we investigate the impact ofdata quantity on the learned features, and uncover similarities in thetransformer's behavior across domains. Through comprehensive visualiations, weobserve that the transformer learns to attend to semantically meaningfulregions, indicating that pretraining leads to a better understanding of theunderlying geometry. Moreover, we examine the finetuning process and its effecton the learned representations. Based on that, we devise an unfreezing strategywhich consistently outperforms our baseline without introducing any othermodifications to the model or the training pipeline, and achievestate-of-the-art results in the classification task among transformer models.</description><author>Ioannis Romanelis, Vlassis Fotis, Konstantinos Moustakas, Adrian Munteanu</author><pubDate>Fri, 23 Jun 2023 18:09:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10798v2</guid></item><item><title>Linear-scaling kernels for protein sequences and small molecules outperform deep learning while providing uncertainty quantitation and improved interpretability</title><link>http://arxiv.org/abs/2302.03294v2</link><description>Gaussian process (GP) is a Bayesian model which provides several advantagesfor regression tasks in machine learning such as reliable quantitation ofuncertainty and improved interpretability. Their adoption has been precluded bytheir excessive computational cost and by the difficulty in adapting them foranalyzing sequences (e.g. amino acid and nucleotide sequences) and graphs (e.g.ones representing small molecules). In this study, we develop efficient andscalable approaches for fitting GP models as well as fast convolution kernelswhich scale linearly with graph or sequence size. We implement theseimprovements by building an open-source Python library called xGPR. We comparethe performance of xGPR with the reported performance of various deep learningmodels on 20 benchmarks, including small molecule, protein sequence and tabulardata. We show that xGRP achieves highly competitive performance with muchshorter training time. Furthermore, we also develop new kernels for sequenceand graph data and show that xGPR generally outperforms convolutional neuralnetworks on predicting key properties of proteins and small molecules.Importantly, xGPR provides uncertainty information not available from typicaldeep learning models. Additionally, xGPR provides a representation of the inputdata that can be used for clustering and data visualization. These resultsdemonstrate that xGPR provides a powerful and generic tool that can be broadlyuseful in protein engineering and drug discovery.</description><author>Jonathan Parkinson, Wei Wang</author><pubDate>Fri, 23 Jun 2023 18:06:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.03294v2</guid></item><item><title>Adversarial Robustness Certification for Bayesian Neural Networks</title><link>http://arxiv.org/abs/2306.13614v1</link><description>We study the problem of certifying the robustness of Bayesian neural networks(BNNs) to adversarial input perturbations. Given a compact set of input points$T \subseteq \mathbb{R}^m$ and a set of output points $S \subseteq\mathbb{R}^n$, we define two notions of robustness for BNNs in an adversarialsetting: probabilistic robustness and decision robustness. Probabilisticrobustness is the probability that for all points in $T$ the output of a BNNsampled from the posterior is in $S$. On the other hand, decision robustnessconsiders the optimal decision of a BNN and checks if for all points in $T$ theoptimal decision of the BNN for a given loss function lies within the outputset $S$. Although exact computation of these robustness properties ischallenging due to the probabilistic and non-convex nature of BNNs, we presenta unified computational framework for efficiently and formally bounding them.Our approach is based on weight interval sampling, integration, and boundpropagation techniques, and can be applied to BNNs with a large number ofparameters, and independently of the (approximate) inference method employed totrain the BNN. We evaluate the effectiveness of our methods on variousregression and classification tasks, including an industrial regressionbenchmark, MNIST, traffic sign recognition, and airborne collision avoidance,and demonstrate that our approach enables certification of robustness anduncertainty of BNN predictions.</description><author>Matthew Wicker, Andrea Patane, Luca Laurenti, Marta Kwiatkowska</author><pubDate>Fri, 23 Jun 2023 17:58:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13614v1</guid></item><item><title>Machine Learning methods for simulating particle response in the Zero Degree Calorimeter at the ALICE experiment, CERN</title><link>http://arxiv.org/abs/2306.13606v1</link><description>Currently, over half of the computing power at CERN GRID is used to run HighEnergy Physics simulations. The recent updates at the Large Hadron Collider(LHC) create the need for developing more efficient simulation methods. Inparticular, there exists a demand for a fast simulation of the neutron ZeroDegree Calorimeter, where existing Monte Carlo-based methods impose asignificant computational burden. We propose an alternative approach to theproblem that leverages machine learning. Our solution utilises neural networkclassifiers and generative models to directly simulate the response of thecalorimeter. In particular, we examine the performance of variationalautoencoders and generative adversarial networks, expanding the GANarchitecture by an additional regularisation network and a simple, yeteffective postprocessing step. Our approach increases the simulation speed by 2orders of magnitude while maintaining the high fidelity of the simulation.</description><author>Jan Dubiński, Kamil Deja, Sandro Wenzel, Przemysław Rokita, Tomasz Trzciński</author><pubDate>Fri, 23 Jun 2023 17:45:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13606v1</guid></item><item><title>Comparative Study on the Effects of Noise in ML-Based Anxiety Detection</title><link>http://arxiv.org/abs/2306.01110v2</link><description>Wearable health devices are ushering in a new age of continuous andnoninvasive remote monitoring. One application of this technology is in anxietydetection. Many advancements in anxiety detection have happened in controlledlab settings, but noise prevents these advancements from generalizing toreal-world conditions. We seek to progress the field by studying how noiseimpacts model performance and developing models that are robust to noisy,real-world conditions and, hence, attuned to the commotion of everyday life. Inthis study we look to investigate why and how previous methods have failed.Using the wearable stress and affect detection (WESAD) dataset, we compare theeffect of various intensities of noise on machine learning models classifyinglevels of physiological arousal in the three-class classification problem:baseline vs. stress vs. amusement. Before introducing noise, our baseline modelperformance reaches 98.7%, compared to Schmidt 2018's 80.3%. We discusspotential sources of this discrepancy in results through a careful evaluationof feature extraction and model architecture choices. Finally, after theintroduction of noise, we provide a thorough analysis of the effect of noise oneach model architecture.</description><author>Samuel Schapiro, Abdul Alkurdi, Elizabeth Hsiao-Wecksler</author><pubDate>Fri, 23 Jun 2023 17:44:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01110v2</guid></item><item><title>Phenotype Search Trajectory Networks for Linear Genetic Programming</title><link>http://arxiv.org/abs/2211.08516v2</link><description>Genotype-to-phenotype mappings translate genotypic variations such asmutations into phenotypic changes. Neutrality is the observation that somemutations do not lead to phenotypic changes. Studying the search trajectoriesin genotypic and phenotypic spaces, especially through neutral mutations, helpsus to better understand the progression of evolution and its algorithmicbehaviour. In this study, we visualise the search trajectories of a geneticprogramming system as graph-based models, where nodes are genotypes/phenotypesand edges represent their mutational transitions. We also quantitativelymeasure the characteristics of phenotypes including their genotypic abundance(the requirement for neutrality) and Kolmogorov complexity. We connect thesequantified metrics with search trajectory visualisations, and find that morecomplex phenotypes are under-represented by fewer genotypes and are harder forevolution to discover. Less complex phenotypes, on the other hand, areover-represented by genotypes, are easier to find, and frequently serve asstepping-stones for evolution.</description><author>Ting Hu, Gabriela Ochoa, Wolfgang Banzhaf</author><pubDate>Fri, 23 Jun 2023 17:42:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.08516v2</guid></item><item><title>Active Coverage for PAC Reinforcement Learning</title><link>http://arxiv.org/abs/2306.13601v1</link><description>Collecting and leveraging data with good coverage properties plays a crucialrole in different aspects of reinforcement learning (RL), including reward-freeexploration and offline learning. However, the notion of "good coverage" reallydepends on the application at hand, as data suitable for one context may not beso for another. In this paper, we formalize the problem of active coverage inepisodic Markov decision processes (MDPs), where the goal is to interact withthe environment so as to fulfill given sampling requirements. This framework issufficiently flexible to specify any desired coverage property, making itapplicable to any problem that involves online exploration. Our maincontribution is an instance-dependent lower bound on the sample complexity ofactive coverage and a simple game-theoretic algorithm, CovGame, that nearlymatches it. We then show that CovGame can be used as a building block to solvedifferent PAC RL tasks. In particular, we obtain a simple algorithm for PACreward-free exploration with an instance-dependent sample complexity that, incertain MDPs which are "easy to explore", is lower than the minimax one. Byfurther coupling this exploration algorithm with a new technique to do impliciteliminations in policy space, we obtain a computationally-efficient algorithmfor best-policy identification whose instance-dependent sample complexityscales with gaps between policy values.</description><author>Aymen Al-Marjani, Andrea Tirinzoni, Emilie Kaufmann</author><pubDate>Fri, 23 Jun 2023 17:39:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13601v1</guid></item><item><title>Margin Maximization in Attention Mechanism</title><link>http://arxiv.org/abs/2306.13596v1</link><description>Attention mechanism is a central component of the transformer architecturewhich led to the phenomenal success of large language models. However, thetheoretical principles underlying the attention mechanism are poorlyunderstood, especially its nonconvex optimization dynamics. In this work, weexplore the seminal softmax-attention model $f(\boldsymbol{X})=\langle\boldsymbol{Xv}, \texttt{softmax}(\boldsymbol{XWp})\rangle$, where,$\boldsymbol{X}$ is the token sequence and$(\boldsymbol{v},\boldsymbol{W},\boldsymbol{p})$ are tunable parameters. Weprove that running gradient descent on $\boldsymbol{p}$, or equivalently$\boldsymbol{W}$, converges in direction to a max-margin solution thatseparates $\textit{locally-optimal}$ tokens from non-optimal ones. This clearlyformalizes attention as a token separation mechanism. Remarkably, our resultsare applicable to general data and precisely characterize $\textit{optimality}$of tokens in terms of the value embeddings $\boldsymbol{Xv}$ and problemgeometry. We also provide a broader regularization path analysis thatestablishes the margin maximizing nature of attention even for nonlinearprediction heads. When optimizing $\boldsymbol{v}$ and $\boldsymbol{p}$simultaneously with logistic loss, we identify conditions under which theregularization paths directionally converge to their respective hard-margin SVMsolutions where $\boldsymbol{v}$ separates the input features based on theirlabels. Interestingly, the SVM formulation of $\boldsymbol{p}$ is influenced bythe support vector geometry of $\boldsymbol{v}$. Finally, we verify ourtheoretical findings via numerical experiments and provide insights.</description><author>Davoud Ataee Tarzanagh, Yingcong Li, Xuechen Zhang, Samet Oymak</author><pubDate>Fri, 23 Jun 2023 17:35:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13596v1</guid></item><item><title>Autoencoders for Real-Time SUEP Detection</title><link>http://arxiv.org/abs/2306.13595v1</link><description>Confining dark sectors with pseudo-conformal dynamics can produce SoftUnclustered Energy Patterns, or SUEPs, at the Large Hadron Collider: theproduction of dark quarks in proton-proton collisions leading to a dark showerand the high-multiplicity production of dark hadrons. The final experimentalsignature is spherically-symmetric energy deposits by an anomalously largenumber of soft Standard Model particles with a transverse energy of a fewhundred MeV. The dominant background for the SUEP search, if it gets producedvia gluon-gluon fusion, is multi-jet QCD events. We have developed a deeplearning-based Anomaly Detection technique to reject QCD jets and identify anyanomalous signature, including SUEP, in real-time in the High-Level Triggersystem of the Compact Muon Solenoid experiment at the Large Hadron Collider. Adeep convolutional neural autoencoder network has been trained using QCD eventsby taking transverse energy deposits in the inner tracker, electromagneticcalorimeter, and hadron calorimeter sub-detectors as 3-channel image data. Totackle the biggest challenge of the task, due to the sparse nature of the data:only ~0.5% of the total ~300 k image pixels have non-zero values, anon-standard loss function, the inverse of the so-called Dice Loss, has beenexploited. The trained autoencoder with learned spatial features of QCD jetscan detect 40% of the SUEP events, with a QCD event mistagging rate as low as2%. The model inference time has been measured using the Intel CoreTM i5-9600KFprocessor and found to be ~20 ms, which perfectly satisfies the High-LevelTrigger system's latency of O(100) ms. Given the virtue of the unsupervisedlearning of the autoencoders, the trained model can be applied to any newphysics model that predicts an experimental signature anomalous to QCD jets.</description><author>Simranjit Singh Chhibra, Nadezda Chernyavskaya, Benedikt Maier, Maurzio Pierini, Syed Hasan</author><pubDate>Fri, 23 Jun 2023 17:35:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13595v1</guid></item><item><title>Visually-Grounded Descriptions Improve Zero-Shot Image Classification</title><link>http://arxiv.org/abs/2306.06077v2</link><description>Language-vision models like CLIP have made significant progress in zero-shotvision tasks, such as zero-shot image classification (ZSIC). However,generating specific and expressive class descriptions remains a majorchallenge. Existing approaches suffer from granularity and label ambiguityissues. To tackle these challenges, we propose V-GLOSS: Visual Glosses, a novelmethod leveraging modern language models and semantic knowledge bases toproduce visually-grounded class descriptions. We demonstrate V-GLOSS'seffectiveness by achieving state-of-the-art results on benchmark ZSIC datasetsincluding ImageNet and STL-10. In addition, we introduce a silver dataset withclass descriptions generated by V-GLOSS, and show its usefulness for visiontasks. We make available our code and dataset.</description><author>Michael Ogezi, Bradley Hauer, Grzegorz Kondrak</author><pubDate>Fri, 23 Jun 2023 17:29:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06077v2</guid></item><item><title>TACOformer:Token-channel compounded Cross Attention for Multimodal Emotion Recognition</title><link>http://arxiv.org/abs/2306.13592v1</link><description>Recently, emotion recognition based on physiological signals has emerged as afield with intensive research. The utilization of multi-modal, multi-channelphysiological signals has significantly improved the performance of emotionrecognition systems, due to their complementarity. However, effectivelyintegrating emotion-related semantic information from different modalities andcapturing inter-modal dependencies remains a challenging issue. Many existingmultimodal fusion methods ignore either token-to-token or channel-to-channelcorrelations of multichannel signals from different modalities, which limitsthe classification capability of the models to some extent. In this paper, wepropose a comprehensive perspective of multimodal fusion that integrateschannel-level and token-level cross-modal interactions. Specifically, weintroduce a unified cross attention module called Token-chAnnel COmpound (TACO)Cross Attention to perform multimodal fusion, which simultaneously modelschannel-level and token-level dependencies between modalities. Additionally, wepropose a 2D position encoding method to preserve information about the spatialdistribution of EEG signal channels, then we use two transformer encoders aheadof the fusion module to capture long-term temporal dependencies from the EEGsignal and the peripheral physiological signal, respectively.Subject-independent experiments on emotional dataset DEAP and Dreamerdemonstrate that the proposed model achieves state-of-the-art performance.</description><author>Xinda Li</author><pubDate>Fri, 23 Jun 2023 17:28:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13592v1</guid></item><item><title>System-Level Natural Language Feedback</title><link>http://arxiv.org/abs/2306.13588v1</link><description>Natural language (NL) feedback contains rich information about the userexperience. Existing studies focus on an instance-level approach, wherefeedback is used to refine specific examples, disregarding its system-wideapplication. This paper proposes a general framework for unlocking thesystem-level use of NL feedback. We show how to use feedback to formalizesystem-level design decisions in a human-in-the-loop-process -- in order toproduce better models. In particular this is done through: (i) metric designfor tasks; and (ii) language model prompt design for refining model responses.We conduct two case studies of this approach for improving search querygeneration and dialog response generation, demonstrating the effectiveness ofthe use of system-level feedback. We show the combination of system-levelfeedback and instance-level feedback brings further gains, and that humanwritten instance-level feedback results in more grounded refinements thanGPT-3.5 written ones, underlying the importance of human feedback for buildingsystems.</description><author>Weizhe Yuan, Kyunghyun Cho, Jason Weston</author><pubDate>Fri, 23 Jun 2023 17:21:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13588v1</guid></item><item><title>Decoding Urban-health Nexus: Interpretable Machine Learning Illuminates Cancer Prevalence based on Intertwined City Features</title><link>http://arxiv.org/abs/2306.11847v2</link><description>This study investigates the interplay among social demographics, builtenvironment characteristics, and environmental hazard exposure features indetermining community level cancer prevalence. Utilizing data from fiveMetropolitan Statistical Areas in the United States: Chicago, Dallas, Houston,Los Angeles, and New York, the study implemented an XGBoost machine learningmodel to predict the extent of cancer prevalence and evaluate the importance ofdifferent features. Our model demonstrates reliable performance, with resultsindicating that age, minority status, and population density are among the mostinfluential factors in cancer prevalence. We further explore urban developmentand design strategies that could mitigate cancer prevalence, focusing on greenspace, developed areas, and total emissions. Through a series of experimentalevaluations based on causal inference, the results show that increasing greenspace and reducing developed areas and total emissions could alleviate cancerprevalence. The study and findings contribute to a better understanding of theinterplay among urban features and community health and also show the value ofinterpretable machine learning models for integrated urban design to promotepublic health. The findings also provide actionable insights for urban planningand design, emphasizing the need for a multifaceted approach to addressingurban health disparities through integrated urban design strategies.</description><author>Chenyue Liu, Ali Mostafavi</author><pubDate>Fri, 23 Jun 2023 17:20:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11847v2</guid></item><item><title>Creating Valid Adversarial Examples of Malware</title><link>http://arxiv.org/abs/2306.13587v1</link><description>Machine learning is becoming increasingly popular as a go-to approach formany tasks due to its world-class results. As a result, antivirus developersare incorporating machine learning models into their products. While thesemodels improve malware detection capabilities, they also carry the disadvantageof being susceptible to adversarial attacks. Although this vulnerability hasbeen demonstrated for many models in white-box settings, a black-box attack ismore applicable in practice for the domain of malware detection. We present agenerator of adversarial malware examples using reinforcement learningalgorithms. The reinforcement learning agents utilize a set offunctionality-preserving modifications, thus creating valid adversarialexamples. Using the proximal policy optimization (PPO) algorithm, we achievedan evasion rate of 53.84% against the gradient-boosted decision tree (GBDT)model. The PPO agent previously trained against the GBDT classifier scored anevasion rate of 11.41% against the neural network-based classifier MalConv andan average evasion rate of 2.31% against top antivirus programs. Furthermore,we discovered that random application of our functionality-preserving portableexecutable modifications successfully evades leading antivirus engines, with anaverage evasion rate of 11.65%. These findings indicate that machinelearning-based models used in malware detection systems are vulnerable toadversarial attacks and that better safeguards need to be taken to protectthese systems.</description><author>Matouš Kozák, Martin Jureček, Mark Stamp, Fabio Di Troia</author><pubDate>Fri, 23 Jun 2023 17:17:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13587v1</guid></item><item><title>NetBooster: Empowering Tiny Deep Learning By Standing on the Shoulders of Deep Giants</title><link>http://arxiv.org/abs/2306.13586v1</link><description>Tiny deep learning has attracted increasing attention driven by thesubstantial demand for deploying deep learning on numerous intelligentInternet-of-Things devices. However, it is still challenging to unleash tinydeep learning's full potential on both large-scale datasets and downstreamtasks due to the under-fitting issues caused by the limited model capacity oftiny neural networks (TNNs). To this end, we propose a framework calledNetBooster to empower tiny deep learning by augmenting the architectures ofTNNs via an expansion-then-contraction strategy. Extensive experiments showthat NetBooster consistently outperforms state-of-the-art tiny deep learningsolutions.</description><author>Zhongzhi Yu, Yonggan Fu, Jiayi Yuan, Haoran You, Yingyan Lin</author><pubDate>Fri, 23 Jun 2023 17:14:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13586v1</guid></item><item><title>A Semi-Paired Approach For Label-to-Image Translation</title><link>http://arxiv.org/abs/2306.13585v1</link><description>Data efficiency, or the ability to generalize from a few labeled data,remains a major challenge in deep learning. Semi-supervised learning hasthrived in traditional recognition tasks alleviating the need for large amountsof labeled data, yet it remains understudied in image-to-image translation(I2I) tasks. In this work, we introduce the first semi-supervised (semi-paired)framework for label-to-image translation, a challenging subtask of I2I whichgenerates photorealistic images from semantic label maps. In the semi-pairedsetting, the model has access to a small set of paired data and a larger set ofunpaired images and labels. Instead of using geometrical transformations as apretext task like previous works, we leverage an input reconstruction task byexploiting the conditional discriminator on the paired data as a reversegenerator. We propose a training algorithm for this shared network, and wepresent a rare classes sampling algorithm to focus on under-representedclasses. Experiments on 3 standard benchmarks show that the proposed modeloutperforms state-of-the-art unsupervised and semi-supervised approaches, aswell as some fully supervised approaches while using a much smaller number ofpaired samples.</description><author>George Eskandar, Shuai Zhang, Mohamed Abdelsamad, Mark Youssef, Diandian Guo, Bin Yang</author><pubDate>Fri, 23 Jun 2023 17:13:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13585v1</guid></item><item><title>Gradient Descent with Linearly Correlated Noise: Theory and Applications to Differential Privacy</title><link>http://arxiv.org/abs/2302.01463v2</link><description>We study gradient descent under linearly correlated noise. Our work ismotivated by recent practical methods for optimization with differentialprivacy (DP), such as DP-FTRL, which achieve strong performance in settingswhere privacy amplification techniques are infeasible (such as in federatedlearning). These methods inject privacy noise through a matrix factorizationmechanism, making the noise linearly correlated over iterations. We propose asimplified setting that distills key facets of these methods and isolates theimpact of linearly correlated noise. We analyze the behavior of gradientdescent in this setting, for both convex and non-convex functions. Our analysisis demonstrably tighter than prior work and recovers multiple important specialcases exactly (including anticorrelated perturbed gradient descent). We use ourresults to develop new, effective matrix factorizations for differentiallyprivate optimization, and highlight the benefits of these factorizationstheoretically and empirically.</description><author>Anastasia Koloskova, Ryan McKenna, Zachary Charles, Keith Rush, Brendan McMahan</author><pubDate>Fri, 23 Jun 2023 17:10:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01463v2</guid></item><item><title>Lower Complexity Adaptation for Empirical Entropic Optimal Transport</title><link>http://arxiv.org/abs/2306.13580v1</link><description>Entropic optimal transport (EOT) presents an effective and computationallyviable alternative to unregularized optimal transport (OT), offering diverseapplications for large-scale data analysis. In this work, we derive novelstatistical bounds for empirical plug-in estimators of the EOT cost and showthat their statistical performance in the entropy regularization parameter$\epsilon$ and the sample size $n$ only depends on the simpler of the twoprobability measures. For instance, under sufficiently smooth costs this yieldsthe parametric rate $n^{-1/2}$ with factor $\epsilon^{-d/2}$, where $d$ is theminimum dimension of the two population measures. This confirms that empiricalEOT also adheres to the lower complexity adaptation principle, a hallmarkfeature only recently identified for unregularized OT. As a consequence of ourtheory, we show that the empirical entropic Gromov-Wasserstein distance and itsunregularized version for measures on Euclidean spaces also obey thisprinciple. Additionally, we comment on computational aspects and complement ourfindings with Monte Carlo simulations. Our techniques employ empirical processtheory and rely on a dual formulation of EOT over a single function class.Crucial to our analysis is the observation that the entropiccost-transformation of a function class does not increase its uniform metricentropy by much.</description><author>Michel Groppe, Shayan Hundrieser</author><pubDate>Fri, 23 Jun 2023 17:06:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13580v1</guid></item><item><title>Penalty Gradient Normalization for Generative Adversarial Networks</title><link>http://arxiv.org/abs/2306.13576v1</link><description>In this paper, we propose a novel normalization method called penaltygradient normalization (PGN) to tackle the training instability of GenerativeAdversarial Networks (GANs) caused by the sharp gradient space. Unlike existingwork such as gradient penalty and spectral normalization, the proposed PGN onlyimposes a penalty gradient norm constraint on the discriminator function, whichincreases the capacity of the discriminator. Moreover, the proposed penaltygradient normalization can be applied to different GAN architectures withlittle modification. Extensive experiments on three datasets show that GANstrained with penalty gradient normalization outperform existing methods interms of both Frechet Inception and Distance and Inception Score.</description><author>Tian Xia</author><pubDate>Fri, 23 Jun 2023 16:57:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13576v1</guid></item><item><title>Scaling MLPs: A Tale of Inductive Bias</title><link>http://arxiv.org/abs/2306.13575v1</link><description>In this work we revisit the most fundamental building block in deep learning,the multi-layer perceptron (MLP), and study the limits of its performance onvision tasks. Empirical insights into MLPs are important for multiple reasons.(1) Given the recent narrative "less inductive bias is better", popularized dueto transformers eclipsing convolutional models, it is natural to explore thelimits of this hypothesis. To that end, MLPs offer an ideal test bed, beingcompletely free of any inductive bias. (2) MLPs have almost exclusively beenthe main protagonist in the deep learning theory literature due to theirmathematical simplicity, serving as a proxy to explain empirical phenomenaobserved for more complex architectures. Surprisingly, experimental datapointsfor MLPs are very difficult to find in the literature, especially when coupledwith large pre-training protocols. This discrepancy between practice and theoryis worrying: Do MLPs reflect the empirical advances exhibited by practicalmodels? Or do theorists need to rethink the role of MLPs as a proxy? We provideinsights into both these aspects. We show that the performance of MLPsdrastically improves with scale (93% on CIFAR10, 79% on CIFAR100, 69% onTinyImageNet), highlighting that lack of inductive bias can indeed becompensated. We observe that MLPs mimic the behaviour of their moderncounterparts faithfully, with some components in the learning setting howeversurprisingly exhibiting stronger or unexpected behaviours. Due to theirinherent computational efficiency, large pre-training experiments become moreaccessible for academic researchers. All of our experiments were run on asingle GPU.</description><author>Gregor Bachmann, Sotiris Anagnostidis, Thomas Hofmann</author><pubDate>Fri, 23 Jun 2023 16:55:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13575v1</guid></item><item><title>Thoughts on Architecture</title><link>http://arxiv.org/abs/2306.13572v1</link><description>The term architecture has evolved considerably from its original Greek rootsand its application to buildings and computers to its more recent manifestationfor minds. This article considers lessons from this history, in terms of a setof relevant distinctions introduced at each of these stages and a definition ofarchitecture that spans all three, and a reconsideration of three key issuesfrom cognitive architectures for architectures in general and cognitivearchitectures more particularly.</description><author>Paul S. Rosenbloom</author><pubDate>Fri, 23 Jun 2023 16:47:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13572v1</guid></item><item><title>Training with Mixed-Precision Floating-Point Assignments</title><link>http://arxiv.org/abs/2301.13464v2</link><description>When training deep neural networks, keeping all tensors in high precision(e.g., 32-bit or even 16-bit floats) is often wasteful. However, keeping alltensors in low precision (e.g., 8-bit floats) can lead to unacceptable accuracyloss. Hence, it is important to use a precision assignment -- a mapping fromall tensors (arising in training) to precision levels (high or low) -- thatkeeps most of the tensors in low precision and leads to sufficiently accuratemodels. We provide a technique that explores this memory-accuracy tradeoff bygenerating precision assignments for convolutional neural networks that (i) useless memory and (ii) lead to more accurate convolutional networks at the sametime, compared to the precision assignments considered by prior work inlow-precision floating-point training. We evaluate our technique on imageclassification tasks by training convolutional networks on CIFAR-10, CIFAR-100,and ImageNet. Our method typically provides &gt; 2x memory reduction over abaseline precision assignment while preserving training accuracy, and givesfurther reductions by trading off accuracy. Compared to other baselines whichsometimes cause training to diverge, our method provides similar or bettermemory reduction while avoiding divergence.</description><author>Wonyeol Lee, Rahul Sharma, Alex Aiken</author><pubDate>Fri, 23 Jun 2023 16:41:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13464v2</guid></item><item><title>Planning with Spatial-Temporal Abstraction from Point Clouds for Deformable Object Manipulation</title><link>http://arxiv.org/abs/2210.15751v2</link><description>Effective planning of long-horizon deformable object manipulation requiressuitable abstractions at both the spatial and temporal levels. Previous methodstypically either focus on short-horizon tasks or make strong assumptions thatfull-state information is available, which prevents their use on deformableobjects. In this paper, we propose PlAnning with Spatial-Temporal Abstraction(PASTA), which incorporates both spatial abstraction (reasoning about objectsand their relations to each other) and temporal abstraction (reasoning overskills instead of low-level actions). Our framework maps high-dimension 3Dobservations such as point clouds into a set of latent vectors and plans overskill sequences on top of the latent set representation. We show that ourmethod can effectively perform challenging sequential deformable objectmanipulation tasks in the real world, which require combining multiple tool-useskills such as cutting with a knife, pushing with a pusher, and spreading thedough with a roller.</description><author>Xingyu Lin, Carl Qi, Yunchu Zhang, Zhiao Huang, Katerina Fragkiadaki, Yunzhu Li, Chuang Gan, David Held</author><pubDate>Fri, 23 Jun 2023 16:40:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.15751v2</guid></item><item><title>The MI-Motion Dataset and Benchmark for 3D Multi-Person Motion Prediction</title><link>http://arxiv.org/abs/2306.13566v1</link><description>3D multi-person motion prediction is a challenging task that involvesmodeling individual behaviors and interactions between people. Despite theemergence of approaches for this task, comparing them is difficult due to thelack of standardized training settings and benchmark datasets. In this paper,we introduce the Multi-Person Interaction Motion (MI-Motion) Dataset, whichincludes skeleton sequences of multiple individuals collected by motion capturesystems and refined and synthesized using a game engine. The dataset contains167k frames of interacting people's skeleton poses and is categorized into 5different activity scenes. To facilitate research in multi-person motionprediction, we also provide benchmarks to evaluate the performance ofprediction methods in three settings: short-term, long-term, andultra-long-term prediction. Additionally, we introduce a novel baselineapproach that leverages graph and temporal convolutional networks, which hasdemonstrated competitive results in multi-person motion prediction. We believethat the proposed MI-Motion benchmark dataset and baseline will facilitatefuture research in this area, ultimately leading to better understanding andmodeling of multi-person interactions.</description><author>Xiaogang Peng, Xiao Zhou, Yikai Luo, Hao Wen, Yu Ding, Zizhao Wu</author><pubDate>Fri, 23 Jun 2023 16:38:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13566v1</guid></item><item><title>Estimating Residential Solar Potential Using Aerial Data</title><link>http://arxiv.org/abs/2306.13564v1</link><description>Project Sunroof estimates the solar potential of residential buildings usinghigh quality aerial data. That is, it estimates the potential solar energy (andassociated financial savings) that can be captured by buildings if solar panelswere to be installed on their roofs. Unfortunately its coverage is limited bythe lack of high resolution digital surface map (DSM) data. We present a deeplearning approach that bridges this gap by enhancing widely availablelow-resolution data, thereby dramatically increasing the coverage of Sunroof.We also present some ongoing efforts to potentially improve accuracy evenfurther by replacing certain algorithmic components of the Sunroof processingpipeline with deep learning.</description><author>Ross Goroshin, Alex Wilson, Andrew Lamb, Betty Peng, Brandon Ewonus, Cornelius Ratsch, Jordan Raisher, Marisa Leung, Max Burq, Thomas Colthurst, William Rucklidge, Carl Elkin</author><pubDate>Fri, 23 Jun 2023 16:37:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13564v1</guid></item><item><title>Efficient Model Selection for Predictive Pattern Mining Model by Safe Pattern Pruning</title><link>http://arxiv.org/abs/2306.13561v1</link><description>Predictive pattern mining is an approach used to construct prediction modelswhen the input is represented by structured data, such as sets, graphs, andsequences. The main idea behind predictive pattern mining is to build aprediction model by considering substructures, such as subsets, subgraphs, andsubsequences (referred to as patterns), present in the structured data asfeatures of the model. The primary challenge in predictive pattern mining liesin the exponential growth of the number of patterns with the complexity of thestructured data. In this study, we propose the Safe Pattern Pruning (SPP)method to address the explosion of pattern numbers in predictive patternmining. We also discuss how it can be effectively employed throughout theentire model building process in practical data analysis. To demonstrate theeffectiveness of the proposed method, we conduct numerical experiments onregression and classification problems involving sets, graphs, and sequences.</description><author>Takumi Yoshida, Hiroyuki Hanada, Kazuya Nakagawa, Kouichi Taji, Koji Tsuda, Ichiro Takeuchi</author><pubDate>Fri, 23 Jun 2023 16:34:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13561v1</guid></item><item><title>Enhancing Next Active Object-based Egocentric Action Anticipation with Guided Attention</title><link>http://arxiv.org/abs/2305.12953v2</link><description>Short-term action anticipation (STA) in first-person videos is a challengingtask that involves understanding the next active object interactions andpredicting future actions. Existing action anticipation methods have primarilyfocused on utilizing features extracted from video clips, but often overlookedthe importance of objects and their interactions. To this end, we propose anovel approach that applies a guided attention mechanism between the objects,and the spatiotemporal features extracted from video clips, enhancing themotion and contextual information, and further decoding the object-centric andmotion-centric information to address the problem of STA in egocentric videos.Our method, GANO (Guided Attention for Next active Objects) is a multi-modal,end-to-end, single transformer-based network. The experimental resultsperformed on the largest egocentric dataset demonstrate that GANO outperformsthe existing state-of-the-art methods for the prediction of the next activeobject label, its bounding box location, the corresponding future action, andthe time to contact the object. The ablation study shows the positivecontribution of the guided attention mechanism compared to other fusionmethods. Moreover, it is possible to improve the next active object locationand class label prediction results of GANO by just appending the learnableobject tokens with the region of interest embeddings.</description><author>Sanket Thakur, Cigdem Beyan, Pietro Morerio, Vittorio Murino, Alessio Del Bue</author><pubDate>Fri, 23 Jun 2023 16:34:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12953v2</guid></item><item><title>FPGA Implementation of Convolutional Neural Network for Real-Time Handwriting Recognition</title><link>http://arxiv.org/abs/2306.13557v1</link><description>Machine Learning (ML) has recently been a skyrocketing field in ComputerScience. As computer hardware engineers, we are enthusiastic about hardwareimplementations of popular software ML architectures to optimize theirperformance, reliability, and resource usage. In this project, we designed ahighly-configurable, real-time device for recognizing handwritten letters anddigits using an Altera DE1 FPGA Kit. We followed various engineering standards,including IEEE-754 32-bit Floating-Point Standard, Video Graphics Array (VGA)display protocol, Universal Asynchronous Receiver-Transmitter (UART) protocol,and Inter-Integrated Circuit (I2C) protocols to achieve the project goals.These significantly improved our design in compatibility, reusability, andsimplicity in verifications. Following these standards, we designed a 32-bitfloating-point (FP) instruction set architecture (ISA). We developed a 5-stageRISC processor in System Verilog to manage image processing, matrixmultiplications, ML classifications, and user interfaces. Three different MLarchitectures were implemented and evaluated on our design: LinearClassification (LC), a 784-64-10 fully connected neural network (NN), and aLeNet-like Convolutional Neural Network (CNN) with ReLU activation layers and36 classes (10 for the digits and 26 for the case-insensitive letters). Thetraining processes were done in Python scripts, and the resulting kernels andweights were stored in hex files and loaded into the FPGA's SRAM units.Convolution, pooling, data management, and various other ML features wereguided by firmware in our custom assembly language. This paper documents thehigh-level design block diagrams, interfaces between each System Verilogmodule, implementation details of our software and firmware components, andfurther discussions on potential impacts.</description><author>Shichen, Qiao, Haining Qiu, Lingkai, Zhao, Qikun Liu, Eric J. Hoffman</author><pubDate>Fri, 23 Jun 2023 16:31:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13557v1</guid></item><item><title>Comparing the Efficacy of Fine-Tuning and Meta-Learning for Few-Shot Policy Imitation</title><link>http://arxiv.org/abs/2306.13554v1</link><description>In this paper we explore few-shot imitation learning for control problems,which involves learning to imitate a target policy by accessing a limited setof offline rollouts. This setting has been relatively under-explored despiteits relevance to robotics and control applications. State-of-the-art methodsdeveloped to tackle few-shot imitation rely on meta-learning, which isexpensive to train as it requires access to a distribution over tasks (rolloutsfrom many target policies and variations of the base environment). Given thislimitation we investigate an alternative approach, fine-tuning, a family ofmethods that pretrain on a single dataset and then fine-tune on unseendomain-specific data. Recent work has shown that fine-tuners outperformmeta-learners in few-shot image classification tasks, especially when the datais out-of-domain. Here we evaluate to what extent this is true for controlproblems, proposing a simple yet effective baseline which relies on two stages:(i) training a base policy online via reinforcement learning (e.g. SoftActor-Critic) on a single base environment, (ii) fine-tuning the base policyvia behavioral cloning on a few offline rollouts of the target policy. Despiteits simplicity this baseline is competitive with meta-learning methods on avariety of conditions and is able to imitate target policies trained on unseenvariations of the original environment. Importantly, the proposed approach ispractical and easy to implement, as it does not need any complex meta-trainingprotocol. As a further contribution, we release an open source dataset callediMuJoCo (iMitation MuJoCo) consisting of 154 variants of popular OpenAI-GymMuJoCo environments with associated pretrained target policies and rollouts,which can be used by the community to study few-shot imitation learning andoffline reinforcement learning.</description><author>Massimiliano Patacchiola, Mingfei Sun, Katja Hofmann, Richard E. Turner</author><pubDate>Fri, 23 Jun 2023 16:29:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13554v1</guid></item><item><title>A Survey on Multimodal Large Language Models</title><link>http://arxiv.org/abs/2306.13549v1</link><description>Multimodal Large Language Model (MLLM) recently has been a new risingresearch hotspot, which uses powerful Large Language Models (LLMs) as a brainto perform multimodal tasks. The surprising emergent capabilities of MLLM, suchas writing stories based on images and OCR-free math reasoning, are rare intraditional methods, suggesting a potential path to artificial generalintelligence. In this paper, we aim to trace and summarize the recent progressof MLLM. First of all, we present the formulation of MLLM and delineate itsrelated concepts. Then, we discuss the key techniques and applications,including Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning(M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning(LAVR). Finally, we discuss existing challenges and point out promisingresearch directions. In light of the fact that the era of MLLM has only justbegun, we will keep updating this survey and hope it can inspire more research.An associated GitHub link collecting the latest papers is available athttps://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.</description><author>Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, Enhong Chen</author><pubDate>Fri, 23 Jun 2023 16:21:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13549v1</guid></item><item><title>Inferring Hierarchical Structure in Multi-Room Maze Environments</title><link>http://arxiv.org/abs/2306.13546v1</link><description>Cognitive maps play a crucial role in facilitating flexible behaviour byrepresenting spatial and conceptual relationships within an environment. Theability to learn and infer the underlying structure of the environment iscrucial for effective exploration and navigation. This paper introduces ahierarchical active inference model addressing the challenge of inferringstructure in the world from pixel-based observations. We propose a three-layerhierarchical model consisting of a cognitive map, an allocentric, and anegocentric world model, combining curiosity-driven exploration withgoal-oriented behaviour at the different levels of reasoning from context toplace to motion. This allows for efficient exploration and goal-directed searchin room-structured mini-grid environments.</description><author>Daria de Tinguy, Toon Van de Maele, Tim Verbelen, Bart Dhoedt</author><pubDate>Fri, 23 Jun 2023 16:15:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13546v1</guid></item><item><title>Manifold Contrastive Learning with Variational Lie Group Operators</title><link>http://arxiv.org/abs/2306.13544v1</link><description>Self-supervised learning of deep neural networks has become a prevalentparadigm for learning representations that transfer to a variety of downstreamtasks. Similar to proposed models of the ventral stream of biological vision,it is observed that these networks lead to a separation of category manifoldsin the representations of the penultimate layer. Although this observationmatches the manifold hypothesis of representation learning, currentself-supervised approaches are limited in their ability to explicitly modelthis manifold. Indeed, current approaches often only apply augmentations from apre-specified set of "positive pairs" during learning. In this work, we proposea contrastive learning approach that directly models the latent manifold usingLie group operators parameterized by coefficients with a sparsity-promotingprior. A variational distribution over these coefficients provides a generativemodel of the manifold, with samples which provide feature augmentationsapplicable both during contrastive training and downstream tasks. Additionally,learned coefficient distributions provide a quantification of whichtransformations are most likely at each point on the manifold while preservingidentity. We demonstrate benefits in self-supervised benchmarks for imagedatasets, as well as a downstream semi-supervised task. In the former case, wedemonstrate that the proposed methods can effectively apply manifold featureaugmentations and improve learning both with and without a projection head. Inthe latter case, we demonstrate that feature augmentations sampled from learnedLie group operators can improve classification performance when using fewlabels.</description><author>Kion Fallah, Alec Helbling, Kyle A. Johnsen, Christopher J. Rozell</author><pubDate>Fri, 23 Jun 2023 16:07:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13544v1</guid></item><item><title>Improving Gender Fairness of Pre-Trained Language Models without Catastrophic Forgetting</title><link>http://arxiv.org/abs/2110.05367v2</link><description>Existing studies addressing gender bias of pre-trained language models,usually build a small gender-neutral data set and conduct a second phasepre-training on the model with such data. However, given the limited size andconcentrated focus of the gender-neutral data, catastrophic forgetting wouldoccur during second-phase pre-training. Forgetting information in the originaltraining data may damage the model's downstream performance by a large margin.In this work, we empirically show that catastrophic forgetting occurs in suchmethods by evaluating them with general NLP tasks in GLUE. Then, we propose anew method, GEnder Equality Prompt (GEEP), to improve gender fairness ofpre-trained models with less forgetting. GEEP freezes the pre-trained model andlearns gender-related prompts with gender-neutral data. Empirical results showthat GEEP not only achieves SOTA performances on gender fairness tasks, butalso forgets less and performs better on GLUE by a large margin.</description><author>Zahra Fatemi, Chen Xing, Wenhao Liu, Caiming Xiong</author><pubDate>Fri, 23 Jun 2023 16:03:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.05367v2</guid></item><item><title>Network Slicing via Transfer Learning aided Distributed Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2301.03262v2</link><description>Deep reinforcement learning (DRL) has been increasingly employed to handlethe dynamic and complex resource management in network slicing. The deploymentof DRL policies in real networks, however, is complicated by heterogeneous cellconditions. In this paper, we propose a novel transfer learning (TL) aidedmulti-agent deep reinforcement learning (MADRL) approach with inter-agentsimilarity analysis for inter-cell inter-slice resource partitioning. First, wedesign a coordinated MADRL method with information sharing to intelligentlypartition resource to slices and manage inter-cell interference. Second, wepropose an integrated TL method to transfer the learned DRL policies amongdifferent local agents for accelerating the policy deployment. The method iscomposed of a new domain and task similarity measurement approach and a newknowledge transfer approach, which resolves the problem of from whom totransfer and how to transfer. We evaluated the proposed solution with extensivesimulations in a system-level simulator and show that our approach outperformsthe state-of-the-art solutions in terms of performance, convergence speed andsample efficiency. Moreover, by applying TL, we achieve an additional gain over27% higher than the coordinate MADRL approach without TL.</description><author>Tianlun Hu, Qi Liao, Qiang Liu, Georg Carle</author><pubDate>Fri, 23 Jun 2023 16:03:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.03262v2</guid></item><item><title>Solving Sample-Level Out-of-Distribution Detection on 3D Medical Images</title><link>http://arxiv.org/abs/2212.06506v2</link><description>Deep Learning (DL) models tend to perform poorly when the data comes from adistribution different from the training one. In critical applications such asmedical imaging, out-of-distribution (OOD) detection helps to identify suchdata samples, increasing the model's reliability. Recent works have developedDL-based OOD detection that achieves promising results on 2D medical images.However, scaling most of these approaches on 3D images is computationallyintractable. Furthermore, the current 3D solutions struggle to achieveacceptable results in detecting even synthetic OOD samples. Such limitedperformance might indicate that DL often inefficiently embeds large volumetricimages. We argue that using the intensity histogram of the original CT or MRIscan as embedding is descriptive enough to run OOD detection. Therefore, wepropose a histogram-based method that requires no DL and achieves almostperfect results in this domain. Our proposal is supported two-fold. We evaluatethe performance on the publicly available datasets, where our method scores 1.0AUROC in most setups. And we score second in the Medical Out-of-Distributionchallenge without fine-tuning and exploiting task-specific knowledge. Carefullydiscussing the limitations, we conclude that our method solves the sample-levelOOD detection on 3D medical images in the current setting.</description><author>Daria Frolova, Anton Vasiliuk, Mikhail Belyaev, Boris Shirokikh</author><pubDate>Fri, 23 Jun 2023 16:02:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.06506v2</guid></item><item><title>Torsion Graph Neural Networks</title><link>http://arxiv.org/abs/2306.13541v1</link><description>Geometric deep learning (GDL) models have demonstrated a great potential forthe analysis of non-Euclidian data. They are developed to incorporate thegeometric and topological information of non-Euclidian data into the end-to-enddeep learning architectures. Motivated by the recent success of discrete Riccicurvature in graph neural network (GNNs), we propose TorGNN, an analyticTorsion enhanced Graph Neural Network model. The essential idea is tocharacterize graph local structures with an analytic torsion based weightformula. Mathematically, analytic torsion is a topological invariant that candistinguish spaces which are homotopy equivalent but not homeomorphic. In ourTorGNN, for each edge, a corresponding local simplicial complex is identified,then the analytic torsion (for this local simplicial complex) is calculated,and further used as a weight (for this edge) in message-passing process. OurTorGNN model is validated on link prediction tasks from sixteen different typesof networks and node classification tasks from three types of networks. It hasbeen found that our TorGNN can achieve superior performance on both tasks, andoutperform various state-of-the-art models. This demonstrates that analytictorsion is a highly efficient topological invariant in the characterization ofgraph structures and can significantly boost the performance of GNNs.</description><author>Cong Shen, Xiang Liu, Jiawei Luo, Kelin Xia</author><pubDate>Fri, 23 Jun 2023 16:02:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13541v1</guid></item><item><title>DeepJoin: Joinable Table Discovery with Pre-trained Language Models</title><link>http://arxiv.org/abs/2212.07588v2</link><description>Due to the usefulness in data enrichment for data analysis tasks, joinabletable discovery has become an important operation in data lake management.Existing approaches target equi-joins, the most common way of combining tablesfor creating a unified view, or semantic joins, which tolerate misspellings anddifferent formats to deliver more join results. They are either exact solutionswhose running time is linear in the sizes of query column and target tablerepository or approximate solutions lacking precision. In this paper, wepropose Deepjoin, a deep learning model for accurate and efficient joinabletable discovery. Our solution is an embedding-based retrieval, which employs apre-trained language model (PLM) and is designed as one framework serving bothequi- and semantic joins. We propose a set of contextualization options totransform column contents to a text sequence. The PLM reads the sequence and isfine-tuned to embed columns to vectors such that columns are expected to bejoinable if they are close to each other in the vector space. Since the outputof the PLM is fixed in length, the subsequent search procedure becomesindependent of the column size. With a state-of-the-art approximate nearestneighbor search algorithm, the search time is logarithmic in the repositorysize. To train the model, we devise the techniques for preparing training dataas well as data augmentation. The experiments on real datasets demonstrate thatby training on a small subset of a corpus, Deepjoin generalizes to largedatasets and its precision consistently outperforms other approximatesolutions'. Deepjoin is even more accurate than an exact solution to semanticjoins when evaluated with labels from experts. Moreover, when equipped with aGPU, Deepjoin is up to two orders of magnitude faster than existing solutions.</description><author>Yuyang Dong, Chuan Xiao, Takuma Nozawa, Masafumi Enomoto, Masafumi Oyamada</author><pubDate>Fri, 23 Jun 2023 15:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.07588v2</guid></item><item><title>Extending the Pre-Training of BLOOM for Improved Support of Traditional Chinese: Models, Methods and Results</title><link>http://arxiv.org/abs/2303.04715v2</link><description>In this paper we present the multilingual language model BLOOM-zh thatfeatures enhanced support for Traditional Chinese. BLOOM-zh has its origins inthe open-source BLOOM models presented by BigScience in 2022. Starting fromreleased models, we extended the pre-training of BLOOM by additional 7.4billion tokens in Traditional Chinese and English covering a variety of domainssuch as news articles, books, encyclopedias, educational materials as well asspoken language. In order to show the properties of BLOOM-zh, both existing andnewly created benchmark scenarios are used for evaluating the performance.BLOOM-zh outperforms its predecessor on most Traditional Chinese benchmarkswhile maintaining its English capability. We release all our models to theresearch community.</description><author>Philipp Ennen, Po-Chun Hsu, Chan-Jan Hsu, Chang-Le Liu, Yen-Chen Wu, Yin-Hsiang Liao, Chin-Tung Lin, Da-Shan Shiu, Wei-Yun Ma</author><pubDate>Fri, 23 Jun 2023 15:54:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.04715v2</guid></item><item><title>PathMLP: Smooth Path Towards High-order Homophily</title><link>http://arxiv.org/abs/2306.13532v1</link><description>Real-world graphs exhibit increasing heterophily, where nodes no longer tendto be connected to nodes with the same label, challenging the homophilyassumption of classical graph neural networks (GNNs) and impeding theirperformance. Intriguingly, we observe that certain high-order information onheterophilous data exhibits high homophily, which motivates us to involvehigh-order information in node representation learning. However, commonpractices in GNNs to acquire high-order information mainly through increasingmodel depth and altering message-passing mechanisms, which, albeit effective toa certain extent, suffer from three shortcomings: 1) over-smoothing due toexcessive model depth and propagation times; 2) high-order information is notfully utilized; 3) low computational efficiency. In this regard, we design asimilarity-based path sampling strategy to capture smooth paths containinghigh-order homophily. Then we propose a lightweight model based on multi-layerperceptrons (MLP), named PathMLP, which can encode messages carried by pathsvia simple transformation and concatenation operations, and effectively learnnode representations in heterophilous graphs through adaptive path aggregation.Extensive experiments demonstrate that our method outperforms baselines on 16out of 20 datasets, underlining its effectiveness and superiority inalleviating the heterophily problem. In addition, our method is immune toover-smoothing and has high computational efficiency.</description><author>Chenxuan Xie, Jiajun Zhou, Shengbo Gong, Jiacheng Wan, Jiaxu Qian, Shanqing Yu, Qi Xuan, Xiaoniu Yang</author><pubDate>Fri, 23 Jun 2023 15:52:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13532v1</guid></item><item><title>WBCAtt: A White Blood Cell Dataset Annotated with Detailed Morphological Attributes</title><link>http://arxiv.org/abs/2306.13531v1</link><description>The examination of blood samples at a microscopic level plays a fundamentalrole in clinical diagnostics, influencing a wide range of medical conditions.For instance, an in-depth study of White Blood Cells (WBCs), a crucialcomponent of our blood, is essential for diagnosing blood-related diseases suchas leukemia and anemia. While multiple datasets containing WBC images have beenproposed, they mostly focus on cell categorization, often lacking the necessarymorphological details to explain such categorizations, despite the importanceof explainable artificial intelligence (XAI) in medical domains. This paperseeks to address this limitation by introducing comprehensive annotations forWBC images. Through collaboration with pathologists, a thorough literaturereview, and manual inspection of microscopic images, we have identified 11morphological attributes associated with the cell and its components (nucleus,cytoplasm, and granules). We then annotated ten thousand WBC images with theseattributes. Moreover, we conduct experiments to predict these attributes fromimages, providing insights beyond basic WBC classification. As the first publicdataset to offer such extensive annotations, we also illustrate specificapplications that can benefit from our attribute annotations. Overall, ourdataset paves the way for interpreting WBC recognition models, furtheradvancing XAI in the fields of pathology and hematology.</description><author>Satoshi Tsutsui, Winnie Pang, Bihan Wen</author><pubDate>Fri, 23 Jun 2023 15:52:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13531v1</guid></item><item><title>Test-Time Robust Personalization for Federated Learning</title><link>http://arxiv.org/abs/2205.10920v4</link><description>Federated Learning (FL) is a machine learning paradigm where many clientscollaboratively learn a shared global model with decentralized training data.Personalized FL additionally adapts the global model to different clients,achieving promising results on consistent local training and testdistributions. However, for real-world personalized FL applications, it iscrucial to go one step further: robustifying FL models under the evolving localtest set during deployment, where various distribution shifts can arise. Inthis work, we identify the pitfalls of existing works under test-timedistribution shifts and propose Federated Test-time Head Ensemble plustuning(FedTHE+), which personalizes FL models with robustness to varioustest-time distribution shifts. We illustrate the advancement of FedTHE+ (andits computationally efficient variant FedTHE) over strong competitors, bytraining various neural architectures (CNN, ResNet, and Transformer) on CIFAR10andImageNet with various test distributions. Along with this, we build abenchmark for assessing the performance and robustness of personalized FLmethods during deployment. Code: https://github.com/LINs-lab/FedTHE.</description><author>Liangze Jiang, Tao Lin</author><pubDate>Fri, 23 Jun 2023 15:50:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.10920v4</guid></item><item><title>Bridging the Performance Gap between DETR and R-CNN for Graphical Object Detection in Document Images</title><link>http://arxiv.org/abs/2306.13526v1</link><description>This paper takes an important step in bridging the performance gap betweenDETR and R-CNN for graphical object detection. Existing graphical objectdetection approaches have enjoyed recent enhancements in CNN-based objectdetection methods, achieving remarkable progress. Recently, Transformer-baseddetectors have considerably boosted the generic object detection performance,eliminating the need for hand-crafted features or post-processing steps such asNon-Maximum Suppression (NMS) using object queries. However, the effectivenessof such enhanced transformer-based detection algorithms has yet to be verifiedfor the problem of graphical object detection. Essentially, inspired by thelatest advancements in the DETR, we employ the existing detection transformerwith few modifications for graphical object detection. We modify object queriesin different ways, using points, anchor boxes and adding positive and negativenoise to the anchors to boost performance. These modifications allow for betterhandling of objects with varying sizes and aspect ratios, more robustness tosmall variations in object positions and sizes, and improved imagediscrimination between objects and non-objects. We evaluate our approach on thefour graphical datasets: PubTables, TableBank, NTable and PubLaynet. Uponintegrating query modifications in the DETR, we outperform prior works andachieve new state-of-the-art results with the mAP of 96.9\%, 95.7\% and 99.3\%on TableBank, PubLaynet, PubTables, respectively. The results from extensiveablations show that transformer-based methods are more effective for documentanalysis analogous to other applications. We hope this study draws moreattention to the research of using detection transformers in document imageanalysis.</description><author>Tahira Shehzadi, Khurram Azeem Hashmi, Didier Stricker, Marcus Liwicki, Muhammad Zeshan Afzal</author><pubDate>Fri, 23 Jun 2023 15:46:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13526v1</guid></item><item><title>On the Convergence Rate of Gaussianization with Random Rotations</title><link>http://arxiv.org/abs/2306.13520v1</link><description>Gaussianization is a simple generative model that can be trained withoutbackpropagation. It has shown compelling performance on low dimensional data.As the dimension increases, however, it has been observed that the convergencespeed slows down. We show analytically that the number of required layersscales linearly with the dimension for Gaussian input. We argue that this isbecause the model is unable to capture dependencies between dimensions.Empirically, we find the same linear increase in cost for arbitrary input$p(x)$, but observe favorable scaling for some distributions. We explorepotential speed-ups and formulate challenges for further research.</description><author>Felix Draxler, Lars Kühmichel, Armand Rousselot, Jens Müller, Christoph Schnörr, Ullrich Köthe</author><pubDate>Fri, 23 Jun 2023 15:35:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13520v1</guid></item><item><title>Segmentation and Tracking of Vegetable Plants by Exploiting Vegetable Shape Feature for Precision Spray of Agricultural Robots</title><link>http://arxiv.org/abs/2306.13518v1</link><description>With the increasing deployment of agricultural robots, the traditional manualspray of liquid fertilizer and pesticide is gradually being replaced byagricultural robots. For robotic precision spray application in vegetablefarms, accurate plant phenotyping through instance segmentation and robustplant tracking are of great importance and a prerequisite for the followingspray action. Regarding the robust tracking of vegetable plants, to solve thechallenging problem of associating vegetables with similar color and texture inconsecutive images, in this paper, a novel method of Multiple Object Trackingand Segmentation (MOTS) is proposed for instance segmentation and tracking ofmultiple vegetable plants. In our approach, contour and blob features areextracted to describe unique feature of each individual vegetable, andassociate the same vegetables in different images. By assigning a unique ID foreach vegetable, it ensures the robot to spray each vegetable exactly once,while traversing along the farm rows. Comprehensive experiments includingablation studies are conducted, which prove its superior performance over twoState-Of-The-Art (SOTA) MOTS methods. Compared to the conventional MOTSmethods, the proposed method is able to re-identify objects which have gone outof the camera field of view and re-appear again using the proposed dataassociation strategy, which is important to ensure each vegetable be sprayedonly once when the robot travels back and forth. Although the method is testedon lettuce farm, it can be applied to other similar vegetables such as broccoliand canola. Both code and the dataset of this paper is publicly released forthe benefit of the community: https://github.com/NanH5837/LettuceMOTS.</description><author>Nan Hu, Daobilige Su, Shuo Wang, Xuechang Wang, Huiyu Zhong, Zimeng Wang, Yongliang Qiao, Yu Tan</author><pubDate>Fri, 23 Jun 2023 15:35:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13518v1</guid></item><item><title>Binary domain generalization for sparsifying binary neural networks</title><link>http://arxiv.org/abs/2306.13515v1</link><description>Binary neural networks (BNNs) are an attractive solution for developing anddeploying deep neural network (DNN)-based applications in resource constraineddevices. Despite their success, BNNs still suffer from a fixed and limitedcompression factor that may be explained by the fact that existing pruningmethods for full-precision DNNs cannot be directly applied to BNNs. In fact,weight pruning of BNNs leads to performance degradation, which suggests thatthe standard binarization domain of BNNs is not well adapted for the task. Thiswork proposes a novel more general binary domain that extends the standardbinary one that is more robust to pruning techniques, thus guaranteeingimproved compression and avoiding severe performance losses. We demonstrate aclosed-form solution for quantizing the weights of a full-precision networkinto the proposed binary domain. Finally, we show the flexibility of ourmethod, which can be combined with other pruning strategies. Experiments overCIFAR-10 and CIFAR-100 demonstrate that the novel approach is able to generateefficient sparse networks with reduced memory usage and run-time latency, whilemaintaining performance.</description><author>Riccardo Schiavone, Francesco Galati, Maria A. Zuluaga</author><pubDate>Fri, 23 Jun 2023 15:32:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13515v1</guid></item><item><title>DISCO-10M: A Large-Scale Music Dataset</title><link>http://arxiv.org/abs/2306.13512v1</link><description>Music datasets play a crucial role in advancing research in machine learningfor music. However, existing music datasets suffer from limited size,accessibility, and lack of audio resources. To address these shortcomings, wepresent DISCO-10M, a novel and extensive music dataset that surpasses thelargest previously available music dataset by an order of magnitude. To ensurehigh-quality data, we implement a multi-stage filtering process. This processincorporates similarities based on textual descriptions and audio embeddings.Moreover, we provide precomputed CLAP embeddings alongside DISCO-10M,facilitating direct application on various downstream tasks. These embeddingsenable efficient exploration of machine learning applications on the provideddata. With DISCO-10M, we aim to democratize and facilitate new research to helpadvance the development of novel machine learning models for music.</description><author>Luca A. Lanzendörfer, Florian Grötschla, Emil Funke, Roger Wattenhofer</author><pubDate>Fri, 23 Jun 2023 15:27:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13512v1</guid></item><item><title>Exploring AI-enhanced Shared Control for an Assistive Robotic Arm</title><link>http://arxiv.org/abs/2306.13509v1</link><description>Assistive technologies and in particular assistive robotic arms have thepotential to enable people with motor impairments to live a self-determinedlife. More and more of these systems have become available for end users inrecent years, such as the Kinova Jaco robotic arm. However, they mostly requirecomplex manual control, which can overwhelm users. As a result, researchershave explored ways to let such robots act autonomously. However, at least forthis specific group of users, such an approach has shown to be futile. Here,users want to stay in control to achieve a higher level of personal autonomy,to which an autonomous robot runs counter. In our research, we explore howArtifical Intelligence (AI) can be integrated into a shared control paradigm.In particular, we focus on the consequential requirements for the interfacebetween human and robot and how we can keep humans in the loop while stillsignificantly reducing the mental load and required motor skills.</description><author>Max Pascher, Kirill Kronhardt1, Jan Freienstein, Jens Gerken</author><pubDate>Fri, 23 Jun 2023 15:19:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13509v1</guid></item><item><title>Curvature Filtrations for Graph Generative Model Evaluation</title><link>http://arxiv.org/abs/2301.12906v2</link><description>Graph generative model evaluation necessitates understanding differencesbetween graphs on the distributional level. This entails being able to harnesssalient attributes of graphs in an efficient manner. Curvature constitutes onesuch property of graphs, and has recently started to prove useful incharacterising graphs. Its expressive properties, stability, and practicalutility in model evaluation remain largely unexplored, however. We combinegraph curvature descriptors with emerging methods from topological dataanalysis to obtain robust, expressive descriptors for evaluating graphgenerative models.</description><author>Joshua Southern, Jeremy Wayland, Michael Bronstein, Bastian Rieck</author><pubDate>Fri, 23 Jun 2023 15:07:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12906v2</guid></item><item><title>Two derivations of Principal Component Analysis on datasets of distributions</title><link>http://arxiv.org/abs/2306.13503v1</link><description>In this brief note, we formulate Principal Component Analysis (PCA) overdatasets consisting not of points but of distributions, characterized by theirlocation and covariance. Just like the usual PCA on points can be equivalentlyderived via a variance-maximization principle and via a minimization ofreconstruction error, we derive a closed-form solution for distributional PCAfrom both of these perspectives.</description><author>Vlad Niculae</author><pubDate>Fri, 23 Jun 2023 15:00:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13503v1</guid></item><item><title>Knowledge-Infused Self Attention Transformers</title><link>http://arxiv.org/abs/2306.13501v1</link><description>Transformer-based language models have achieved impressive success in variousnatural language processing tasks due to their ability to capture complexdependencies and contextual information using self-attention mechanisms.However, they are not without limitations. These limitations includehallucinations, where they produce incorrect outputs with high confidence, andalignment issues, where they generate unhelpful and unsafe outputs for humanusers. These limitations stem from the absence of implicit and missing contextin the data alone. To address this, researchers have explored augmenting thesemodels with external knowledge from knowledge graphs to provide the necessaryadditional context. However, the ad-hoc nature of existing methods makes itdifficult to properly analyze the effects of knowledge infusion on the manymoving parts or components of a transformer. This paper introduces a systematicmethod for infusing knowledge into different components of a transformer-basedmodel. A modular framework is proposed to identify specific components withinthe transformer architecture, such as the self-attention mechanism, encoderlayers, or the input embedding layer, where knowledge infusion can be applied.Additionally, extensive experiments are conducted on the General LanguageUnderstanding Evaluation (GLUE) benchmark tasks, and the findings are reported.This systematic approach aims to facilitate more principled approaches toincorporating knowledge into language model architectures.</description><author>Kaushik Roy, Yuxin Zi, Vignesh Narayanan, Manas Gaur, Amit Sheth</author><pubDate>Fri, 23 Jun 2023 14:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13501v1</guid></item><item><title>Cascade Subspace Clustering for Outlier Detection</title><link>http://arxiv.org/abs/2306.13500v1</link><description>Many methods based on sparse and low-rank representation been developed alongwith guarantees of correct outlier detection. Self-representation states that apoint in a subspace can always be expressed as a linear combination of otherpoints in the subspace. A suitable Markov Chain can be defined on theself-representation and it allows us to recognize the difference betweeninliers and outliers. However, the reconstruction error of self-representationthat is still informative to detect outlier detection, is neglected.Inspired bythe gradient boosting, in this paper, we propose a new outlier detectionframework that combines a series of weak "outlier detectors" into a singlestrong one in an iterative fashion by constructing multi-passself-representation. At each stage, we construct a self-representation based onelastic-net and define a suitable Markov Chain on it to detect outliers. Theresidual of the self-representation is used for the next stage to learn thenext weaker outlier detector. Such a stage will repeat many times. And thefinal decision of outliers is generated by the previous all results.Experimental results on image and speaker datasets demonstrate its superioritywith respect to state-of-the-art sparse and low-rank outlier detection methods.</description><author>Qi Yang, Hao Zhu</author><pubDate>Fri, 23 Jun 2023 14:48:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13500v1</guid></item><item><title>Supplementary Features of BiLSTM for Enhanced Sequence Labeling</title><link>http://arxiv.org/abs/2305.19928v4</link><description>Sequence labeling tasks require the computation of sentence representationsfor each word within a given sentence. A prevalent method incorporates aBi-directional Long Short-Term Memory (BiLSTM) layer to enhance the sequencestructure information. However, empirical evidence Li (2020) suggests that thecapacity of BiLSTM to produce sentence representations for sequence labelingtasks is inherently limited. This limitation primarily results from theintegration of fragments from past and future sentence representations toformulate a complete sentence representation. In this study, we observed thatthe entire sentence representation, found in both the first and last cells ofBiLSTM, can supplement each the individual sentence representation of eachcell. Accordingly, we devised a global context mechanism to integrate entirefuture and past sentence representations into each cell's sentencerepresentation within the BiLSTM framework. By incorporating the BERT modelwithin BiLSTM as a demonstration, and conducting exhaustive experiments on ninedatasets for sequence labeling tasks, including named entity recognition (NER),part of speech (POS) tagging, and End-to-End Aspect-Based sentiment analysis(E2E-ABSA). We noted significant improvements in F1 scores and accuracy acrossall examined datasets.</description><author>Conglei Xu, Kun Shen, Hongguang Sun</author><pubDate>Fri, 23 Jun 2023 14:47:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19928v4</guid></item><item><title>On Uni-Modal Feature Learning in Supervised Multi-Modal Learning</title><link>http://arxiv.org/abs/2305.01233v3</link><description>We abstract the features (i.e. learned representations) of multi-modal datainto 1) uni-modal features, which can be learned from uni-modal training, and2) paired features, which can only be learned from cross-modal interactions.Multi-modal models are expected to benefit from cross-modal interactions on thebasis of ensuring uni-modal feature learning. However, recent supervisedmulti-modal late-fusion training approaches still suffer from insufficientlearning of uni-modal features on each modality. We prove that this phenomenondoes hurt the model's generalization ability. To this end, we propose to choosea targeted late-fusion learning method for the given supervised multi-modaltask from Uni-Modal Ensemble(UME) and the proposed Uni-Modal Teacher(UMT),according to the distribution of uni-modal and paired features. We demonstratethat, under a simple guiding strategy, we can achieve comparable results toother complex late-fusion or intermediate-fusion methods on various multi-modaldatasets, including VGG-Sound, Kinetics-400, UCF101, and ModelNet40.</description><author>Chenzhuang Du, Jiaye Teng, Tingle Li, Yichen Liu, Tianyuan Yuan, Yue Wang, Yang Yuan, Hang Zhao</author><pubDate>Fri, 23 Jun 2023 14:45:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.01233v3</guid></item><item><title>Retrieval of Boost Invariant Symbolic Observables via Feature Importance</title><link>http://arxiv.org/abs/2306.13496v1</link><description>Deep learning approaches for jet tagging in high-energy physics arecharacterized as black boxes that process a large amount of information fromwhich it is difficult to extract key distinctive observables. In thisproceeding, we present an alternative to deep learning approaches, BoostInvariant Polynomials, which enables direct analysis of simple analyticexpressions representing the most important features in a given task. Further,we show how this approach provides an extremely low dimensional classifier witha minimum set of features representing %effective discriminating physicallyrelevant observables and how it consequently speeds up the algorithm execution,with relatively close performance to the algorithm using the full information.</description><author>Jose M Munoz, Ilyes Batatia, Christoph Ortner, Francesco Romeo</author><pubDate>Fri, 23 Jun 2023 14:41:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13496v1</guid></item><item><title>Large-step neural network for learning the symplectic evolution from partitioned data</title><link>http://arxiv.org/abs/2208.14148v2</link><description>In this study, we focus on learning Hamiltonian systems, which involvespredicting the coordinate (q) and momentum (p) variables generated by asymplectic mapping. Based on Chen &amp; Tao (2021), the symplectic mapping isrepresented by a generating function. To extend the prediction time period, wedevelop a new learning scheme by splitting the time series (q_i, p_i) intoseveral partitions. We then train a large-step neural network (LSNN) toapproximate the generating function between the first partition (i.e. theinitial condition) and each one of the remaining partitions. This partitionapproach makes our LSNN effectively suppress the accumulative error whenpredicting the system evolution. Then we train the LSNN to learn the motions ofthe 2:3 resonant Kuiper belt objects for a long time period of 25000 yr. Theresults show that there are two significant improvements over the neuralnetwork constructed in our previous work (Li et al. 2022): (1) the conservationof the Jacobi integral, and (2) the highly accurate predictions of the orbitalevolution. Overall, we propose that the designed LSNN has the potential toconsiderably improve predictions of the long-term evolution of more generalHamiltonian systems.</description><author>Xin Li, Jian Li, Zhihong Jeff Xia, Nikolaos Georgakarakos</author><pubDate>Fri, 23 Jun 2023 14:22:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.14148v2</guid></item><item><title>Adaptive Planning Search Algorithm for Analog Circuit Verification</title><link>http://arxiv.org/abs/2306.13484v1</link><description>Integrated circuit verification has gathered considerable interest in recenttimes. Since these circuits keep growing in complexity year by year,pre-Silicon (pre-SI) verification becomes ever more important, in order toensure proper functionality. Thus, in order to reduce the time needed formanually verifying ICs, we propose a machine learning (ML) approach, which usesless simulations. This method relies on an initial evaluation set of operatingcondition configurations (OCCs), in order to train Gaussian process (GP)surrogate models. By using surrogate models, we can propose further, moredifficult OCCs. Repeating this procedure for several iterations has shownbetter GP estimation of the circuit's responses, on both synthetic and realcircuits, resulting in a better chance of finding the worst case, or evenfailures, for certain circuit responses. Thus, we show that the proposedapproach is able to provide OCCs closer to the specifications for all circuitsand identify a failure (specification violation) for one of the responses of areal circuit.</description><author>Cristian Manolache, Cristina Andronache, Alexandru Caranica, Horia Cucu, Andi Buzo, Cristian Diaconu, Georg Pelz</author><pubDate>Fri, 23 Jun 2023 13:57:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13484v1</guid></item><item><title>Instance-Adaptive Video Compression: Improving Neural Codecs by Training on the Test Set</title><link>http://arxiv.org/abs/2111.10302v2</link><description>We introduce a video compression algorithm based on instance-adaptivelearning. On each video sequence to be transmitted, we finetune a pretrainedcompression model. The optimal parameters are transmitted to the receiver alongwith the latent code. By entropy-coding the parameter updates under a suitablemixture model prior, we ensure that the network parameters can be encodedefficiently. This instance-adaptive compression algorithm is agnostic about thechoice of base model and has the potential to improve any neural video codec.On UVG, HEVC, and Xiph datasets, our codec improves the performance of ascale-space flow model by between 21% and 27% BD-rate savings, and that of astate-of-the-art B-frame model by 17 to 20% BD-rate savings. We alsodemonstrate that instance-adaptive finetuning improves the robustness to domainshift. Finally, our approach reduces the capacity requirements of compressionmodels. We show that it enables a competitive performance even after reducingthe network size by 70%.</description><author>Ties van Rozendaal, Johann Brehmer, Yunfan Zhang, Reza Pourreza, Auke Wiggers, Taco S. Cohen</author><pubDate>Fri, 23 Jun 2023 13:47:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.10302v2</guid></item><item><title>SC-Block: Supervised Contrastive Blocking within Entity Resolution Pipelines</title><link>http://arxiv.org/abs/2303.03132v2</link><description>The goal of entity resolution is to identify records in multiple datasetsthat represent the same real-world entity. However, comparing all recordsacross datasets can be computationally intensive, leading to long runtimes. Toreduce these runtimes, entity resolution pipelines are constructed of twoparts: a blocker that applies a computationally cheap method to selectcandidate record pairs, and a matcher that afterwards identifies matching pairsfrom this set using more expensive methods. This paper presents SC-Block, ablocking method that utilizes supervised contrastive learning for positioningrecords in the embedding space, and nearest neighbour search for candidate setbuilding. We benchmark SC-Block against eight state-of-the-art blockingmethods. In order to relate the training time of SC-Block to the reduction ofthe overall runtime of the entity resolution pipeline, we combine SC-Block withfour matching methods into complete pipelines. For measuring the overallruntime, we determine candidate sets with 99.5% pair completeness and pass themto the matcher. The results show that SC-Block is able to create smallercandidate sets and pipelines with SC-Block execute 1.5 to 2 times fastercompared to pipelines with other blockers, without sacrificing F1 score.Blockers are often evaluated using relatively small datasets which might leadto runtime effects resulting from a large vocabulary size being overlooked. Inorder to measure runtimes in a more challenging setting, we introduce a newbenchmark dataset that requires large numbers of product offers to be blocked.On this large-scale benchmark dataset, pipelines utilizing SC-Block and thebest-performing matcher execute 8 times faster than pipelines utilizing anotherblocker with the same matcher reducing the runtime from 2.5 hours to 18minutes, clearly compensating for the 5 minutes required for training SC-Block.</description><author>Alexander Brinkmann, Roee Shraga, Christian Bizer</author><pubDate>Fri, 23 Jun 2023 13:31:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03132v2</guid></item><item><title>Efficient Online Processing with Deep Neural Networks</title><link>http://arxiv.org/abs/2306.13474v1</link><description>The capabilities and adoption of deep neural networks (DNNs) grow at anexhilarating pace: Vision models accurately classify human actions in videosand identify cancerous tissue in medical scans as precisely than human experts;large language models answer wide-ranging questions, generate code, and writeprose, becoming the topic of everyday dinner-table conversations. Even thoughtheir uses are exhilarating, the continually increasing model sizes andcomputational complexities have a dark side. The economic cost and negativeenvironmental externalities of training and serving models is in evidentdisharmony with financial viability and climate action goals. Instead of pursuing yet another increase in predictive performance, thisdissertation is dedicated to the improvement of neural network efficiency.Specifically, a core contribution addresses the efficiency aspects duringonline inference. Here, the concept of Continual Inference Networks (CINs) isproposed and explored across four publications. CINs extend priorstate-of-the-art methods developed for offline processing of spatio-temporaldata and reuse their pre-trained weights, improving their online processingefficiency by an order of magnitude. These advances are attained through abottom-up computational reorganization and judicious architecturalmodifications. The benefit to online inference is demonstrated by reformulatingseveral widely used network architectures into CINs, including 3D CNNs,ST-GCNs, and Transformer Encoders. An orthogonal contribution tackles theconcurrent adaptation and computational acceleration of a large source modelinto multiple lightweight derived models. Drawing on fusible adapter networksand structured pruning, Structured Pruning Adapters achieve superior predictiveaccuracy under aggressive pruning using significantly fewer learned weightscompared to fine-tuning with pruning.</description><author>Lukas Hedegaard</author><pubDate>Fri, 23 Jun 2023 13:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13474v1</guid></item><item><title>Stochastic Gradient Descent under Markovian Sampling Schemes</title><link>http://arxiv.org/abs/2302.14428v3</link><description>We study a variation of vanilla stochastic gradient descent where theoptimizer only has access to a Markovian sampling scheme. These schemesencompass applications that range from decentralized optimization with a randomwalker (token algorithms), to RL and online system identification problems. Wefocus on obtaining rates of convergence under the least restrictive assumptionspossible on the underlying Markov chain and on the functions optimized. Wefirst unveil the theoretical lower bound for methods that sample stochasticgradients along the path of a Markov chain, making appear a dependency in thehitting time of the underlying Markov chain. We then study Markov chain SGD(MC-SGD) under much milder regularity assumptions than prior works (e.g., nobounded gradients or domain, and infinite state spaces). We finally introduceMC-SAG, an alternative to MC-SGD with variance reduction, that only depends onthe hitting time of the Markov chain, therefore obtaining acommunication-efficient token algorithm.</description><author>Mathieu Even</author><pubDate>Fri, 23 Jun 2023 13:28:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.14428v3</guid></item><item><title>Prediction under Latent Subgroup Shifts with High-Dimensional Observations</title><link>http://arxiv.org/abs/2306.13472v1</link><description>We introduce a new approach to prediction in graphical models withlatent-shift adaptation, i.e., where source and target environments differ inthe distribution of an unobserved confounding latent variable. Previous workhas shown that as long as "concept" and "proxy" variables with appropriatedependence are observed in the source environment, the latent-associateddistributional changes can be identified, and target predictions adaptedaccurately. However, practical estimation methods do not scale well when theobservations are complex and high-dimensional, even if the confounding latentis categorical. Here we build upon a recently proposed probabilisticunsupervised learning framework, the recognition-parametrised model (RPM), torecover low-dimensional, discrete latents from image observations. Applied tothe problem of latent shifts, our novel form of RPM identifies causal latentstructure in the source environment, and adapts properly to predict in thetarget. We demonstrate results in settings where predictor and proxy arehigh-dimensional images, a context to which previous methods fail to scale.</description><author>William I. Walker, Arthur Gretton, Maneesh Sahani</author><pubDate>Fri, 23 Jun 2023 13:26:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13472v1</guid></item><item><title>Incorporating Graph Information in Transformer-based AMR Parsing</title><link>http://arxiv.org/abs/2306.13467v1</link><description>Abstract Meaning Representation (AMR) is a Semantic Parsing formalism thataims at providing a semantic graph abstraction representing a given text.Current approaches are based on autoregressive language models such as BART orT5, fine-tuned through Teacher Forcing to obtain a linearized version of theAMR graph from a sentence. In this paper, we present LeakDistill, a model andmethod that explores a modification to the Transformer architecture, usingstructural adapters to explicitly incorporate graph information into thelearned representations and improve AMR parsing performance. Our experimentsshow how, by employing word-to-node alignment to embed graph structuralinformation into the encoder at training time, we can obtain state-of-the-artAMR parsing through self-knowledge distillation, even without the use ofadditional data. We release the code at\url{http://www.github.com/sapienzanlp/LeakDistill}.</description><author>Pavlo Vasylenko, Pere-Lluís Huguet Cabot, Abelardo Carlos Martínez Lorenzo, Roberto Navigli</author><pubDate>Fri, 23 Jun 2023 13:12:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13467v1</guid></item><item><title>3DSAM-adapter: Holistic Adaptation of SAM from 2D to 3D for Promptable Medical Image Segmentation</title><link>http://arxiv.org/abs/2306.13465v1</link><description>Despite that the segment anything model (SAM) achieved impressive results ongeneral-purpose semantic segmentation with strong generalization ability ondaily images, its demonstrated performance on medical image segmentation isless precise and not stable, especially when dealing with tumor segmentationtasks that involve objects of small sizes, irregular shapes, and low contrast.Notably, the original SAM architecture is designed for 2D natural images,therefore would not be able to extract the 3D spatial information fromvolumetric medical data effectively. In this paper, we propose a noveladaptation method for transferring SAM from 2D to 3D for promptable medicalimage segmentation. Through a holistically designed scheme for architecturemodification, we transfer the SAM to support volumetric inputs while retainingthe majority of its pre-trained parameters for reuse. The fine-tuning processis conducted in a parameter-efficient manner, wherein most of the pre-trainedparameters remain frozen, and only a few lightweight spatial adapters areintroduced and tuned. Regardless of the domain gap between natural and medicaldata and the disparity in the spatial arrangement between 2D and 3D, thetransformer trained on natural images can effectively capture the spatialpatterns present in volumetric medical images with only lightweightadaptations. We conduct experiments on four open-source tumor segmentationdatasets, and with a single click prompt, our model can outperform domainstate-of-the-art medical image segmentation models on 3 out of 4 tasks,specifically by 8.25%, 29.87%, and 10.11% for kidney tumor, pancreas tumor,colon cancer segmentation, and achieve similar performance for liver tumorsegmentation. We also compare our adaptation method with existing popularadapters, and observed significant performance improvement on most datasets.</description><author>Shizhan Gong, Yuan Zhong, Wenao Ma, Jinpeng Li, Zhao Wang, Jingyang Zhang, Pheng-Ann Heng, Qi Dou</author><pubDate>Fri, 23 Jun 2023 13:09:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13465v1</guid></item><item><title>Understanding quantum machine learning also requires rethinking generalization</title><link>http://arxiv.org/abs/2306.13461v1</link><description>Quantum machine learning models have shown successful generalizationperformance even when trained with few data. In this work, through systematicrandomization experiments, we show that traditional approaches to understandinggeneralization fail to explain the behavior of such quantum models. Ourexperiments reveal that state-of-the-art quantum neural networks accurately fitrandom states and random labeling of training data. This ability to memorizerandom data defies current notions of small generalization error,problematizing approaches that build on complexity measures such as the VCdimension, the Rademacher complexity, and all their uniform relatives. Wecomplement our empirical results with a theoretical construction showing thatquantum neural networks can fit arbitrary labels to quantum states, hinting attheir memorization ability. Our results do not preclude the possibility of goodgeneralization with few training data but rather rule out any possibleguarantees based only on the properties of the model family. These findingsexpose a fundamental challenge in the conventional understanding ofgeneralization in quantum machine learning and highlight the need for aparadigm shift in the design of quantum models for machine learning tasks.</description><author>Elies Gil-Fuster, Jens Eisert, Carlos Bravo-Prieto</author><pubDate>Fri, 23 Jun 2023 13:04:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13461v1</guid></item><item><title>Learning Descriptive Image Captioning via Semipermeable Maximum Likelihood Estimation</title><link>http://arxiv.org/abs/2306.13460v1</link><description>Image captioning aims to describe visual content in natural language. As 'apicture is worth a thousand words', there could be various correct descriptionsfor an image. However, with maximum likelihood estimation as the trainingobjective, the captioning model is penalized whenever its prediction mismatcheswith the label. For instance, when the model predicts a word expressing richersemantics than the label, it will be penalized and optimized to prefer moreconcise expressions, referred to as conciseness optimization. In contrast,predictions that are more concise than labels lead to richness optimization.Such conflicting optimization directions could eventually result in the modelgenerating general descriptions. In this work, we introduce SemipermeableMaxImum Likelihood Estimation (SMILE), which allows richness optimization whileblocking conciseness optimization, thus encouraging the model to generatelonger captions with more details. Extensive experiments on two mainstreamimage captioning datasets MSCOCO and Flickr30K demonstrate that SMILEsignificantly enhances the descriptiveness of generated captions. We furtherprovide in-depth investigations to facilitate a better understanding of howSMILE works.</description><author>Zihao Yue, Anwen Hu, Liang Zhang, Qin Jin</author><pubDate>Fri, 23 Jun 2023 13:03:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13460v1</guid></item><item><title>Enhanced Dengue Outbreak Prediction in Tamilnadu using Meteorological and Entomological data</title><link>http://arxiv.org/abs/2306.13456v1</link><description>This paper focuses on studying the impact of climate data and vector larvalindices on dengue outbreak. After a comparative study of the various LSTMmodels, Bidirectional Stacked LSTM network is selected to analyze the timeseries climate data and health data collected for the state of Tamil Nadu(India), for the period 2014 to 2020. Prediction accuracy of the model issignificantly improved by including the mosquito larval index, an indication ofVBD control measure.</description><author>Varalakshmi M, Daphne Lopez</author><pubDate>Fri, 23 Jun 2023 12:54:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13456v1</guid></item><item><title>DreamEditor: Text-Driven 3D Scene Editing with Neural Fields</title><link>http://arxiv.org/abs/2306.13455v1</link><description>Neural fields have achieved impressive advancements in view synthesis andscene reconstruction. However, editing these neural fields remains challengingdue to the implicit encoding of geometry and texture information. In thispaper, we propose DreamEditor, a novel framework that enables users to performcontrolled editing of neural fields using text prompts. By representing scenesas mesh-based neural fields, DreamEditor allows localized editing withinspecific regions. DreamEditor utilizes the text encoder of a pretrainedtext-to-Image diffusion model to automatically identify the regions to beedited based on the semantics of the text prompts. Subsequently, DreamEditoroptimizes the editing region and aligns its geometry and texture with the textprompts through score distillation sampling [29]. Extensive experiments havedemonstrated that DreamEditor can accurately edit neural fields of real-worldscenes according to the given text prompts while ensuring consistency inirrelevant areas. DreamEditor generates highly realistic textures and geometry,significantly surpassing previous works in both quantitative and qualitativeevaluations.</description><author>Jingyu Zhuang, Chen Wang, Lingjie Liu, Liang Lin, Guanbin Li</author><pubDate>Fri, 23 Jun 2023 12:53:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13455v1</guid></item><item><title>A Graph Neural Network Approach for Temporal Mesh Blending and Correspondence</title><link>http://arxiv.org/abs/2306.13452v1</link><description>We have proposed a self-supervised deep learning framework for solving themesh blending problem in scenarios where the meshes are not in correspondence.To solve this problem, we have developed Red-Blue MPNN, a novel graph neuralnetwork that processes an augmented graph to estimate the correspondence. Wehave designed a novel conditional refinement scheme to find the exactcorrespondence when certain conditions are satisfied. We further develop agraph neural network that takes the aligned meshes and the time value as inputand fuses this information to process further and generate the desired result.Using motion capture datasets and human mesh designing software, we create alarge-scale synthetic dataset consisting of temporal sequences of human meshesin motion. Our results demonstrate that our approach generates realisticdeformation of body parts given complex inputs.</description><author>Aalok Gangopadhyay, Abhinav Narayan Harish, Prajwal Singh, Shanmuganathan Raman</author><pubDate>Fri, 23 Jun 2023 12:47:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13452v1</guid></item><item><title>Beyond Weights: Deep learning in Spiking Neural Networks with pure synaptic-delay training</title><link>http://arxiv.org/abs/2306.06237v2</link><description>Biological evidence suggests that adaptation of synaptic delays on short tomedium timescales plays an important role in learning in the brain. Inspired bybiology, we explore the feasibility and power of using synaptic delays to solvechallenging tasks even when the synaptic weights are not trained but kept atrandomly chosen fixed values. We show that training ONLY the delays infeed-forward spiking networks using backpropagation can achieve performancecomparable to the more conventional weight training. Moreover, furtherconstraining the weights to ternary values does not significantly affect thenetworks' ability to solve the tasks using only the synaptic delays. Wedemonstrate the task performance of delay-only training on MNIST andFashion-MNIST datasets in preliminary experiments. This demonstrates a newparadigm for training spiking neural networks and sets the stage for modelsthat can be more efficient than the ones that use weights for computation.</description><author>Edoardo W. Grappolini, Anand Subramoney</author><pubDate>Fri, 23 Jun 2023 12:45:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06237v2</guid></item><item><title>Necessary and sufficient graphical conditions for optimal adjustment sets in causal graphical models with hidden variables</title><link>http://arxiv.org/abs/2102.10324v4</link><description>The problem of selecting optimal backdoor adjustment sets to estimate causaleffects in graphical models with hidden and conditioned variables is addressed.Previous work has defined optimality as achieving the smallest asymptoticestimation variance and derived an optimal set for the case without hiddenvariables. For the case with hidden variables there can be settings where nooptimal set exists and currently only a sufficient graphical optimalitycriterion of limited applicability has been derived. In the present workoptimality is characterized as maximizing a certain adjustment informationwhich allows to derive a necessary and sufficient graphical criterion for theexistence of an optimal adjustment set and a definition and algorithm toconstruct it. Further, the optimal set is valid if and only if a validadjustment set exists and has higher (or equal) adjustment information than theAdjust-set proposed in Perkovi{\'c} et al. [Journal of Machine LearningResearch, 18: 1--62, 2018] for any graph. The results translate to minimalasymptotic estimation variance for a class of estimators whose asymptoticvariance follows a certain information-theoretic relation. Numericalexperiments indicate that the asymptotic results also hold for relatively smallsample sizes and that the optimal adjustment set or minimized variants thereofoften yield better variance also beyond that estimator class. Surprisingly,among the randomly created setups more than 90\% fulfill the optimalityconditions indicating that also in many real-world scenarios graphicaloptimality may hold. Code is available as part of the python package\url{https://github.com/jakobrunge/tigramite}.</description><author>Jakob Runge</author><pubDate>Fri, 23 Jun 2023 12:44:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2102.10324v4</guid></item><item><title>Dermoscopic Dark Corner Artifacts Removal: Friend or Foe?</title><link>http://arxiv.org/abs/2306.13446v1</link><description>One of the more significant obstacles in classification of skin cancer is thepresence of artifacts. This paper investigates the effect of dark cornerartifacts, which result from the use of dermoscopes, on the performance of adeep learning binary classification task. Previous research attempted to removeand inpaint dark corner artifacts, with the intention of creating an idealcondition for models. However, such research has been shown to be inconclusivedue to lack of available datasets labelled with dark corner artifacts anddetailed analysis and discussion. To address these issues, we label 10,250 skinlesion images from publicly available datasets and introduce a balanced datasetwith an equal number of melanoma and non-melanoma cases. The training setcomprises 6126 images without artifacts, and the testing set comprises 4124images with dark corner artifacts. We conduct three experiments to provide newunderstanding on the effects of dark corner artifacts, including inpainted andsynthetically generated examples, on a deep learning method. Our resultssuggest that introducing synthetic dark corner artifacts which have beensuperimposed onto the training set improved model performance, particularly interms of the true negative rate. This indicates that deep learning learnt toignore dark corner artifacts, rather than treating it as melanoma, when darkcorner artifacts were introduced into the training set. Further, we propose anew approach to quantifying heatmaps indicating network focus using a root meansquare measure of the brightness intensity in the different regions of theheatmaps. This paper provides a new guideline for skin lesions analysis with anemphasis on reproducibility.</description><author>Samuel William Pewton, Bill Cassidy, Connah Kendrick, Moi Hoon Yap</author><pubDate>Fri, 23 Jun 2023 12:23:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13446v1</guid></item><item><title>Minibatch training of neural network ensembles via trajectory sampling</title><link>http://arxiv.org/abs/2306.13442v1</link><description>Most iterative neural network training methods use estimates of the lossfunction over small random subsets (or minibatches) of the data to update theparameters, which aid in decoupling the training time from the (often verylarge) size of the training datasets. Here, we show that a minibatch approachcan also be used to train neural network ensembles (NNEs) via trajectorymethods in a highly efficent manner. We illustrate this approach by trainingNNEs to classify images in the MNIST datasets. This method gives an improvementto the training times, allowing it to scale as the ratio of the size of thedataset to that of the average minibatch size which, in the case of MNIST,gives a computational improvement typically of two orders of magnitude. Wehighlight the advantage of using longer trajectories to represent NNEs, bothfor improved accuracy in inference and reduced update cost in terms of thesamples needed in minibatch updates.</description><author>Jamie F. Mair, Luke Causer, Juan P. Garrahan</author><pubDate>Fri, 23 Jun 2023 12:12:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13442v1</guid></item><item><title>Trading-off price for data quality to achieve fair online allocation</title><link>http://arxiv.org/abs/2306.13440v1</link><description>We consider the problem of online allocation subject to a long-term fairnesspenalty. Contrary to existing works, however, we do not assume that thedecision-maker observes the protected attributes -- which is often unrealisticin practice. Instead they can purchase data that help estimate them fromsources of different quality; and hence reduce the fairness penalty at somecost. We model this problem as a multi-armed bandit problem where each armcorresponds to the choice of a data source, coupled with the online allocationproblem. We propose an algorithm that jointly solves both problems and showthat it has a regret bounded by $\mathcal{O}(\sqrt{T})$. A key difficulty isthat the rewards received by selecting a source are correlated by the fairnesspenalty, which leads to a need for randomization (despite a stochasticsetting). Our algorithm takes into account contextual information availablebefore the source selection, and can adapt to many different fairness notions.We also show that in some instances, the estimates used can be learned on thefly.</description><author>Mathieu Molina, Nicolas Gast, Patrick Loiseau, Vianney Perchet</author><pubDate>Fri, 23 Jun 2023 12:09:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13440v1</guid></item><item><title>Compression with Bayesian Implicit Neural Representations</title><link>http://arxiv.org/abs/2305.19185v2</link><description>Many common types of data can be represented as functions that mapcoordinates to signal values, such as pixel locations to RGB values in the caseof an image. Based on this view, data can be compressed by overfitting acompact neural network to its functional representation and then encoding thenetwork weights. However, most current solutions for this are inefficient, asquantization to low-bit precision substantially degrades the reconstructionquality. To address this issue, we propose overfitting variational Bayesianneural networks to the data and compressing an approximate posterior weightsample using relative entropy coding instead of quantizing and entropy codingit. This strategy enables direct optimization of the rate-distortionperformance by minimizing the $\beta$-ELBO, and target differentrate-distortion trade-offs for a given network architecture by adjusting$\beta$. Moreover, we introduce an iterative algorithm for learning priorweight distributions and employ a progressive refinement process for thevariational posterior that significantly enhances performance. Experiments showthat our method achieves strong performance on image and audio compressionwhile retaining simplicity.</description><author>Zongyu Guo, Gergely Flamich, Jiajun He, Zhibo Chen, José Miguel Hernández-Lobato</author><pubDate>Fri, 23 Jun 2023 11:59:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19185v2</guid></item><item><title>On tracking varying bounds when forecasting bounded time series</title><link>http://arxiv.org/abs/2306.13428v1</link><description>We consider a new framework where a continuous, though bounded, randomvariable has unobserved bounds that vary over time. In the context ofunivariate time series, we look at the bounds as parameters of the distributionof the bounded random variable. We introduce an extended log-likelihoodestimation and design algorithms to track the bound through online maximumlikelihood estimation. Since the resulting optimization problem is not convex,we make use of recent theoretical results on Normalized Gradient Descent (NGD)for quasiconvex optimization, to eventually derive an Online NormalizedGradient Descent algorithm. We illustrate and discuss the workings of ourapproach based on both simulation studies and a real-world wind powerforecasting problem.</description><author>Amandine Pierrot, Pierre Pinson</author><pubDate>Fri, 23 Jun 2023 11:44:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13428v1</guid></item><item><title>Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction</title><link>http://arxiv.org/abs/2301.09209v3</link><description>We study object interaction anticipation in egocentric videos. This taskrequires an understanding of the spatiotemporal context formed by past actionson objects, coined action context. We propose TransFusion, a multimodaltransformer-based architecture. It exploits the representational power oflanguage by summarising the action context. TransFusion leverages pre-trainedimage captioning and vision-language models to extract the action context frompast video frames. This action context together with the next video frame isprocessed by the multimodal fusion module to forecast the next objectinteraction. Our model enables more efficient end-to-end learning. The largepre-trained language models add common sense and a generalisation capability.Experiments on Ego4D and EPIC-KITCHENS-100 show the effectiveness of ourmultimodal fusion model. They also highlight the benefits of usinglanguage-based context summaries in a task where vision seems to suffice. Ourmethod outperforms state-of-the-art approaches by 40.4% in relative terms inoverall mAP on the Ego4D test set. We validate the effectiveness of TransFusionvia experiments on EPIC-KITCHENS-100. Video and code are available athttps://eth-ait.github.io/transfusion-proj/.</description><author>Razvan-George Pasca, Alexey Gavryushin, Yen-Ling Kuo, Luc Van Gool, Otmar Hilliges, Xi Wang</author><pubDate>Fri, 23 Jun 2023 11:43:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.09209v3</guid></item><item><title>Day2Dark: Pseudo-Supervised Activity Recognition beyond Silent Daylight</title><link>http://arxiv.org/abs/2212.02053v2</link><description>This paper strives to recognize activities in the dark, as well as in theday. As our first contribution, we establish that state-of-the-art activityrecognizers are effective during the day, but not trustworthy in the dark. Themain causes are the limited availability of labeled dark videos as well as thedistribution shift from the lower color contrast. To compensate for the lack oflabeled dark videos, our second contribution is to introduce apseudo-supervised learning scheme, which utilizes unlabeled and task-irrelevantdark videos to improve an activity recognizer in low light. As the lower colorcontrast results in visual information loss, we propose to incorporate thecomplementary activity information within audio, which is invariant toillumination. Since the usefulness of audio and visual features differsdepending on the amount of illumination, we introduce our `darkness-adaptive'audio-visual recognizer as the third contribution. Experiments onEPIC-Kitchens, Kinetics-Sound, and Charades demonstrate our proposals aresuperior to image enhancement, domain adaptation and alternative audio-visualfusion methods, and can even improve robustness to occlusions.</description><author>Yunhua Zhang, Hazel Doughty, Cees G. M. Snoek</author><pubDate>Fri, 23 Jun 2023 11:37:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.02053v2</guid></item><item><title>Optimizing Agent Collaboration through Heuristic Multi-Agent Planning</title><link>http://arxiv.org/abs/2301.01246v3</link><description>The SOTA algorithms for addressing QDec-POMDP issues, QDec-FP and QDec-FPS,are unable to effectively tackle problems that involve different types ofsensing agents. We propose a new algorithm that addresses this issue byrequiring agents to adopt the same plan if one agent is unable to take asensing action but the other can. Our algorithm performs significantly betterthan both QDec-FP and QDec-FPS in these types of situations.</description><author>Nitsan Soffair</author><pubDate>Fri, 23 Jun 2023 11:28:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.01246v3</guid></item><item><title>A Weighted Autoencoder-Based Approach to Downlink NOMA Constellation Design</title><link>http://arxiv.org/abs/2306.13423v1</link><description>End-to-end design of communication systems using deep autoencoders (AEs) isgaining attention due to its flexibility and excellent performance. Besidessingle-user transmission, AE-based design is recently explored in multi-usersetup, e.g., for designing constellations for non-orthogonal multiple access(NOMA). In this paper, we further advance the design of AE-based downlink NOMAby introducing weighted loss function in the AE training. By changing theweight coefficients, one can flexibly tune the constellation design to balanceerror probability of different users, without relying on explicit informationabout their channel quality. Combined with the SICNet decoder, we demonstrate asignificant improvement in achievable levels and flexible control of errorprobability of different users using the proposed weighted AE-based framework.</description><author>Vukan Ninkovic, Dejan Vukobratovic, Adriano Pastore, Carles Anton-Haro</author><pubDate>Fri, 23 Jun 2023 11:19:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13423v1</guid></item><item><title>Long-range Language Modeling with Self-retrieval</title><link>http://arxiv.org/abs/2306.13421v1</link><description>Retrieval-augmented language models (LMs) have received much attentionrecently. However, typically the retriever is not trained jointly as a nativecomponent of the LM, but added to an already-pretrained LM, which limits theability of the LM and the retriever to adapt to one another. In this work, wepropose the Retrieval-Pretrained Transformer (RPT), an architecture andtraining procedure for jointly training a retrieval-augmented LM from scratchfor the task of modeling long texts. Given a recently generated text chunk in along document, the LM computes query representations, which are then used toretrieve earlier chunks in the document, located potentially tens of thousandsof tokens before. Information from retrieved chunks is fused into the LMrepresentations to predict the next target chunk. We train the retrievercomponent with a semantic objective, where the goal is to retrieve chunks thatincrease the probability of the next chunk, according to a reference LM. Weevaluate RPT on four long-range language modeling tasks, spanning books, code,and mathematical writing, and demonstrate that RPT improves retrieval qualityand subsequently perplexity across the board compared to strong baselines.</description><author>Ohad Rubin, Jonathan Berant</author><pubDate>Fri, 23 Jun 2023 11:18:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13421v1</guid></item><item><title>Towards Unseen Triples: Effective Text-Image-joint Learning for Scene Graph Generation</title><link>http://arxiv.org/abs/2306.13420v1</link><description>Scene Graph Generation (SGG) aims to structurally and comprehensivelyrepresent objects and their connections in images, it can significantly benefitscene understanding and other related downstream tasks. Existing SGG modelsoften struggle to solve the long-tailed problem caused by biased datasets.However, even if these models can fit specific datasets better, it may be hardfor them to resolve the unseen triples which are not included in the trainingset. Most methods tend to feed a whole triple and learn the overall featuresbased on statistical machine learning. Such models have difficulty predictingunseen triples because the objects and predicates in the training set arecombined differently as novel triples in the test set. In this work, we proposea Text-Image-joint Scene Graph Generation (TISGG) model to resolve the unseentriples and improve the generalisation capability of the SGG models. We proposea Joint Fearture Learning (JFL) module and a Factual Knowledge based Refinement(FKR) module to learn object and predicate categories separately at the featurelevel and align them with corresponding visual features so that the model is nolonger limited to triples matching. Besides, since we observe the long-tailedproblem also affects the generalization ability, we design a novel balancedlearning strategy, including a Charater Guided Sampling (CGS) and anInformative Re-weighting (IR) module, to provide tailor-made learning methodsfor each predicate according to their characters. Extensive experiments showthat our model achieves state-of-the-art performance. In more detail, TISGGboosts the performances by 11.7% of zR@20(zero-shot recall) on the PredClssub-task on the Visual Genome dataset.</description><author>Qianji Di, Wenxi Ma, Zhongang Qi, Tianxiang Hou, Ying Shan, Hanzi Wang</author><pubDate>Fri, 23 Jun 2023 11:17:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13420v1</guid></item><item><title>PP-GAN : Style Transfer from Korean Portraits to ID Photos Using Landmark Extractor with GAN</title><link>http://arxiv.org/abs/2306.13418v1</link><description>The objective of a style transfer is to maintain the content of an imagewhile transferring the style of another image. However, conventional researchon style transfer has a significant limitation in preserving facial landmarks,such as the eyes, nose, and mouth, which are crucial for maintaining theidentity of the image. In Korean portraits, the majority of individuals wear"Gat", a type of headdress exclusively worn by men. Owing to its distinctcharacteristics from the hair in ID photos, transferring the "Gat" ischallenging. To address this issue, this study proposes a deep learning networkthat can perform style transfer, including the "Gat", while preserving theidentity of the face. Unlike existing style transfer approaches, the proposedmethod aims to preserve texture, costume, and the "Gat" on the style image. TheGenerative Adversarial Network forms the backbone of the proposed network. Thecolor, texture, and intensity were extracted differently based on thecharacteristics of each block and layer of the pre-trained VGG-16, and only thenecessary elements during training were preserved using a facial landmark mask.The head area was presented using the eyebrow area to transfer the "Gat".Furthermore, the identity of the face was retained, and style correlation wasconsidered based on the Gram matrix. The proposed approach demonstratedsuperior transfer and preservation performance compared to previous studies.</description><author>Jongwook Si, Sungyoung Kim</author><pubDate>Fri, 23 Jun 2023 11:10:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13418v1</guid></item><item><title>Predicting Temporal Aspects of Movement for Predictive Replication in Fog Environments</title><link>http://arxiv.org/abs/2306.00575v3</link><description>To fully exploit the benefits of the fog environment, efficient management ofdata locality is crucial. Blind or reactive data replication falls short inharnessing the potential of fog computing, necessitating more advancedtechniques for predicting where and when clients will connect. While spatialprediction has received considerable attention, temporal prediction remainsunderstudied. Our paper addresses this gap by examining the advantages of incorporatingtemporal prediction into existing spatial prediction models. We also provide acomprehensive analysis of spatio-temporal prediction models, such as DeepNeural Networks and Markov models, in the context of predictive replication. Wepropose a novel model using Holt-Winter's Exponential Smoothing for temporalprediction, leveraging sequential and periodical user movement patterns. In afog network simulation with real user trajectories our model achieves a 15%reduction in excess data with a marginal 1% decrease in data availability.</description><author>Emil Balitzki, Tobias Pfandzelter, David Bermbach</author><pubDate>Fri, 23 Jun 2023 11:05:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00575v3</guid></item><item><title>Otter-Knowledge: benchmarks of multimodal knowledge graph representation learning from different sources for drug discovery</title><link>http://arxiv.org/abs/2306.12802v2</link><description>Recent research in representation learning utilizes large databases ofproteins or molecules to acquire knowledge of drug and protein structuresthrough unsupervised learning techniques. These pre-trained representationshave proven to significantly enhance the accuracy of subsequent tasks, such aspredicting the affinity between drugs and target proteins. In this study, wedemonstrate that by incorporating knowledge graphs from diverse sources andmodalities into the sequences or SMILES representation, we can further enrichthe representation and achieve state-of-the-art results on establishedbenchmark datasets. We provide preprocessed and integrated data obtained from 7public sources, which encompass over 30M triples. Additionally, we makeavailable the pre-trained models based on this data, along with the reportedoutcomes of their performance on three widely-used benchmark datasets fordrug-target binding affinity prediction found in the Therapeutic Data Commons(TDC) benchmarks. Additionally, we make the source code for training models onbenchmark datasets publicly available. Our objective in releasing thesepre-trained models, accompanied by clean data for model pretraining andbenchmark results, is to encourage research in knowledge-enhancedrepresentation learning.</description><author>Hoang Thanh Lam, Marco Luca Sbodio, Marcos Martínez Galindo, Mykhaylo Zayats, Raúl Fernández-Díaz, Víctor Valls, Gabriele Picco, Cesar Berrospi Ramis, Vanessa López</author><pubDate>Fri, 23 Jun 2023 11:03:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12802v2</guid></item><item><title>Reinforcement Learning-based Virtual Fixtures for Teleoperation of Hydraulic Construction Machine</title><link>http://arxiv.org/abs/2306.11897v2</link><description>The utilization of teleoperation is a crucial aspect of the constructionindustry, as it enables operators to control machines safely from a distance.However, remote operation of these machines at a joint level using individualjoysticks necessitates extensive training for operators to achieve proficiencydue to their multiple degrees of freedom. Additionally, verifying the machineresulting motion is only possible after execution, making optimal controlchallenging. In addressing this issue, this study proposes a reinforcementlearning-based approach to optimize task performance. The control policyacquired through learning is used to provide instructions on efficientlycontrolling and coordinating multiple joints. To evaluate the effectiveness ofthe proposed framework, a user study is conducted with a Brokk 170 constructionmachine by assessing its performance in a typical construction task involvinginserting a chisel into a borehole. The effectiveness of the proposed frameworkis evaluated by comparing the performance of participants in the presence andabsence of virtual fixtures. This study results demonstrate the proposedframework potential in enhancing the teleoperation process in the constructionindustry.</description><author>Hyung Joo Lee, Sigrid Brell-Cokcan</author><pubDate>Fri, 23 Jun 2023 11:02:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11897v2</guid></item><item><title>CLUE: Calibrated Latent Guidance for Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2306.13412v1</link><description>Offline reinforcement learning (RL) aims to learn an optimal policy frompre-collected and labeled datasets, which eliminates the time-consuming datacollection in online RL. However, offline RL still bears a large burden ofspecifying/handcrafting extrinsic rewards for each transition in the offlinedata. As a remedy for the labor-intensive labeling, we propose to endow offlineRL tasks with a few expert data and utilize the limited expert data to driveintrinsic rewards, thus eliminating the need for extrinsic rewards. To achievethat, we introduce \textbf{C}alibrated \textbf{L}atentg\textbf{U}idanc\textbf{E} (CLUE), which utilizes a conditional variationalauto-encoder to learn a latent space such that intrinsic rewards can bedirectly qualified over the latent space. CLUE's key idea is to align theintrinsic rewards consistent with the expert intention via enforcing theembeddings of expert data to a calibrated contextual representation. Weinstantiate the expert-driven intrinsic rewards in sparse-reward offline RLtasks, offline imitation learning (IL) tasks, and unsupervised offline RLtasks. Empirically, we find that CLUE can effectively improve the sparse-rewardoffline RL performance, outperform the state-of-the-art offline IL baselines,and discover diverse skills from static reward-free offline data.</description><author>Jinxin Liu, Lipeng Zu, Li He, Donglin Wang</author><pubDate>Fri, 23 Jun 2023 10:57:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13412v1</guid></item><item><title>Neural Algorithmic Reasoning Without Intermediate Supervision</title><link>http://arxiv.org/abs/2306.13411v1</link><description>Neural Algorithmic Reasoning is an emerging area of machine learning focusingon building models which can imitate the execution of classic algorithms, suchas sorting, shortest paths, etc. One of the main challenges is to learnalgorithms that are able to generalize to out-of-distribution data, inparticular with significantly larger input sizes. Recent work on this problemhas demonstrated the advantages of learning algorithms step-by-step, givingmodels access to all intermediate steps of the original algorithm. In thiswork, we instead focus on learning neural algorithmic reasoning only from theinput-output pairs without appealing to the intermediate supervision. Wepropose simple but effective architectural improvements and also build aself-supervised objective that can regularise intermediate computations of themodel without access to the algorithm trajectory. We demonstrate that ourapproach is competitive to its trajectory-supervised counterpart on tasks fromthe CLRS Algorithmic Reasoning Benchmark and achieves new state-of-the-artresults for several problems, including sorting, where we obtain significantimprovements. Thus, learning without intermediate supervision is a promisingdirection for further research on neural reasoners.</description><author>Gleb Rodionov, Liudmila Prokhorenkova</author><pubDate>Fri, 23 Jun 2023 10:57:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13411v1</guid></item><item><title>Explainable Lifelong Stream Learning Based on "Glocal" Pairwise Fusion</title><link>http://arxiv.org/abs/2306.13410v1</link><description>Real-time on-device continual learning applications are used on mobilephones, consumer robots, and smart appliances. Such devices have limitedprocessing and memory storage capabilities, whereas continual learning acquiresdata over a long period of time. By necessity, lifelong learning algorithmshave to be able to operate under such constraints while delivering goodperformance. This study presents the Explainable Lifelong Learning (ExLL)model, which incorporates several important traits: 1) learning to learn, in asingle pass, from streaming data with scarce examples and resources; 2) aself-organizing prototype-based architecture that expands as needed andclusters streaming data into separable groups by similarity and preserves dataagainst catastrophic forgetting; 3) an interpretable architecture to convertthe clusters into explainable IF-THEN rules as well as to justify modelpredictions in terms of what is similar and dissimilar to the inference; and 4)inferences at the global and local level using a pairwise decision fusionprocess to enhance the accuracy of the inference, hence ``Glocal PairwiseFusion.'' We compare ExLL against contemporary online learning algorithms forimage recognition, using OpenLoris, F-SIOL-310, and Places datasets to evaluateseveral continual learning scenarios for video streams, low-sample learning,ability to scale, and imbalanced data streams. The algorithms are evaluated fortheir performance in accuracy, number of parameters, and experiment runtimerequirements. ExLL outperforms all algorithms for accuracy in the majority ofthe tested scenarios.</description><author>Chu Kiong Loo, Wei Shiung Liew, Stefan Wermter</author><pubDate>Fri, 23 Jun 2023 10:54:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13410v1</guid></item><item><title>3D VR Sketch Guided 3D Shape Prototyping and Exploration</title><link>http://arxiv.org/abs/2306.10830v2</link><description>3D shape modeling is labor-intensive and time-consuming and requires years ofexpertise. Recently, 2D sketches and text inputs were considered as conditionalmodalities to 3D shape generation networks to facilitate 3D shape modeling.However, text does not contain enough fine-grained information and is moresuitable to describe a category or appearance rather than geometry, while 2Dsketches are ambiguous, and depicting complex 3D shapes in 2D again requiresextensive practice. Instead, we explore virtual reality sketches that are drawndirectly in 3D. We assume that the sketches are created by novices, without anyart training, and aim to reconstruct physically-plausible 3D shapes. Since suchsketches are potentially ambiguous, we tackle the problem of the generation ofmultiple 3D shapes that follow the input sketch structure. Limited in the sizeof the training data, we carefully design our method, training the modelstep-by-step and leveraging multi-modal 3D shape representation. To guaranteethe plausibility of generated 3D shapes we leverage the normalizing flow thatmodels the distribution of the latent space of 3D shapes. To encourage thefidelity of the generated 3D models to an input sketch, we propose a dedicatedloss that we deploy at different stages of the training process. We plan tomake our code publicly available.</description><author>Ling Luo, Pinaki Nath Chowdhury, Tao Xiang, Yi-Zhe Song, Yulia Gryaditskaya</author><pubDate>Fri, 23 Jun 2023 10:47:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10830v2</guid></item></channel></rss>