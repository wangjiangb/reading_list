<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 04 Feb 2024 06:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>We're Not Using Videos Effectively: An Updated Domain Adaptive Video Segmentation Baseline</title><link>http://arxiv.org/abs/2402.00868v1</link><description>There has been abundant work in unsupervised domain adaptation for semanticsegmentation (DAS) seeking to adapt a model trained on images from a labeledsource domain to an unlabeled target domain. While the vast majority of priorwork has studied this as a frame-level Image-DAS problem, a few Video-DAS workshave sought to additionally leverage the temporal signal present in adjacentframes. However, Video-DAS works have historically studied a distinct set ofbenchmarks from Image-DAS, with minimal cross-benchmarking. In this work, weaddress this gap. Surprisingly, we find that (1) even after carefullycontrolling for data and model architecture, state-of-the-art Image-DAS methods(HRDA and HRDA+MIC)} outperform Video-DAS methods on established Video-DASbenchmarks (+14.5 mIoU on Viper$\rightarrow$CityscapesSeq, +19.0 mIoU onSynthia$\rightarrow$CityscapesSeq), and (2) naive combinations of Image-DAS andVideo-DAS techniques only lead to marginal improvements across datasets. Toavoid siloed progress between Image-DAS and Video-DAS, we open-source ourcodebase with support for a comprehensive set of Video-DAS and Image-DASmethods on a common benchmark. Code available athttps://github.com/SimarKareer/UnifiedVideoDA</description><author>Simar Kareer, Vivek Vijaykumar, Harsh Maheshwari, Prithvijit Chattopadhyay, Judy Hoffman, Viraj Prabhu</author><pubDate>Thu, 01 Feb 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00868v1</guid></item><item><title>AToM: Amortized Text-to-Mesh using 2D Diffusion</title><link>http://arxiv.org/abs/2402.00867v1</link><description>We introduce Amortized Text-to-Mesh (AToM), a feed-forward text-to-meshframework optimized across multiple text prompts simultaneously. In contrast toexisting text-to-3D methods that often entail time-consuming per-promptoptimization and commonly output representations other than polygonal meshes,AToM directly generates high-quality textured meshes in less than 1 second witharound 10 times reduction in the training cost, and generalizes to unseenprompts. Our key idea is a novel triplane-based text-to-mesh architecture witha two-stage amortized optimization strategy that ensures stable training andenables scalability. Through extensive experiments on various promptbenchmarks, AToM significantly outperforms state-of-the-art amortizedapproaches with over 4 times higher accuracy (in DF415 dataset) and producesmore distinguishable and higher-quality 3D outputs. AToM demonstrates stronggeneralizability, offering finegrained 3D assets for unseen interpolatedprompts without further optimization during inference, unlike per-promptsolutions.</description><author>Guocheng Qian, Junli Cao, Aliaksandr Siarohin, Yash Kant, Chaoyang Wang, Michael Vasilkovsky, Hsin-Ying Lee, Yuwei Fang, Ivan Skorokhodov, Peiye Zhuang, Igor Gilitschenski, Jian Ren, Bernard Ghanem, Kfir Aberman, Sergey Tulyakov</author><pubDate>Thu, 01 Feb 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00867v1</guid></item><item><title>Geometry-Aware Normalizing Wasserstein Flows for Optimal Causal Inference</title><link>http://arxiv.org/abs/2311.18826v4</link><description>This paper presents a groundbreaking approach to causal inference byintegrating continuous normalizing flows (CNFs) with parametric submodels,enhancing their geometric sensitivity and improving upon traditional TargetedMaximum Likelihood Estimation (TMLE). Our method employs CNFs to refine TMLE,optimizing the Cram\'er-Rao bound and transitioning from a predefineddistribution $p_0$ to a data-driven distribution $p_1$. We innovate further byembedding Wasserstein gradient flows within Fokker-Planck equations, thusimposing geometric structures that boost the robustness of CNFs, particularlyin optimal transport theory. Our approach addresses the disparity between sample and populationdistributions, a critical factor in parameter estimation bias. We leverageoptimal transport and Wasserstein gradient flows to develop causal inferencemethodologies with minimal variance in finite-sample settings, outperformingtraditional methods like TMLE and AIPW. This novel framework, centered onWasserstein gradient flows, minimizes variance in efficient influence functionsunder distribution $p_t$. Preliminary experiments showcase our method'ssuperiority, yielding lower mean-squared errors compared to standard flows,thereby demonstrating the potential of geometry-aware normalizing Wassersteinflows in advancing statistical modeling and inference.</description><author>Kaiwen Hou</author><pubDate>Thu, 01 Feb 2024 18:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18826v4</guid></item><item><title>Towards Optimal Feature-Shaping Methods for Out-of-Distribution Detection</title><link>http://arxiv.org/abs/2402.00865v1</link><description>Feature shaping refers to a family of methods that exhibit state-of-the-artperformance for out-of-distribution (OOD) detection. These approachesmanipulate the feature representation, typically from the penultimate layer ofa pre-trained deep learning model, so as to better differentiate betweenin-distribution (ID) and OOD samples. However, existing feature-shaping methodsusually employ rules manually designed for specific model architectures and OODdatasets, which consequently limit their generalization ability. To addressthis gap, we first formulate an abstract optimization framework for studyingfeature-shaping methods. We then propose a concrete reduction of the frameworkwith a simple piecewise constant shaping function and show that existingfeature-shaping methods approximate the optimal solution to the concreteoptimization problem. Further, assuming that OOD data is inaccessible, wepropose a formulation that yields a closed-form solution for the piecewiseconstant shaping function, utilizing solely the ID data. Through extensiveexperiments, we show that the feature-shaping function optimized by our methodimproves the generalization ability of OOD detection across a large variety ofdatasets and model architectures.</description><author>Qinyu Zhao, Ming Xu, Kartik Gupta, Akshay Asthana, Liang Zheng, Stephen Gould</author><pubDate>Thu, 01 Feb 2024 18:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00865v1</guid></item><item><title>ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields</title><link>http://arxiv.org/abs/2402.00864v1</link><description>We introduce ViCA-NeRF, the first view-consistency-aware method for 3Dediting with text instructions. In addition to the implicit neural radiancefield (NeRF) modeling, our key insight is to exploit two sources ofregularization that explicitly propagate the editing information acrossdifferent views, thus ensuring multi-view consistency. For geometricregularization, we leverage the depth information derived from NeRF toestablish image correspondences between different views. For learnedregularization, we align the latent codes in the 2D diffusion model betweenedited and unedited images, enabling us to edit key views and propagate theupdate throughout the entire scene. Incorporating these two strategies, ourViCA-NeRF operates in two stages. In the initial stage, we blend edits fromdifferent views to create a preliminary 3D edit. This is followed by a secondstage of NeRF training, dedicated to further refining the scene's appearance.Experimental results demonstrate that ViCA-NeRF provides more flexible,efficient (3 times faster) editing with higher levels of consistency anddetails, compared with the state of the art. Our code is publicly available.</description><author>Jiahua Dong, Yu-Xiong Wang</author><pubDate>Thu, 01 Feb 2024 18:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00864v1</guid></item><item><title>Geometry Transfer for Stylizing Radiance Fields</title><link>http://arxiv.org/abs/2402.00863v1</link><description>Shape and geometric patterns are essential in defining stylistic identity.However, current 3D style transfer methods predominantly focus on transferringcolors and textures, often overlooking geometric aspects. In this paper, weintroduce Geometry Transfer, a novel method that leverages geometricdeformation for 3D style transfer. This technique employs depth maps to extracta style guide, subsequently applied to stylize the geometry of radiance fields.Moreover, we propose new techniques that utilize geometric cues from the 3Dscene, thereby enhancing aesthetic expressiveness and more accuratelyreflecting intended styles. Our extensive experiments show that GeometryTransfer enables a broader and more expressive range of stylizations, therebysignificantly expanding the scope of 3D style transfer.</description><author>Hyunyoung Jung, Seonghyeon Nam, Nikolaos SarafianosSungjoo Yoo, Alexander Sorkine-Hornung, Rakesh Ranjan</author><pubDate>Thu, 01 Feb 2024 18:58:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00863v1</guid></item><item><title>RLHF and IIA: Perverse Incentives</title><link>http://arxiv.org/abs/2312.01057v3</link><description>Existing algorithms for reinforcement learning from human feedback (RLHF) canincentivize responses at odds with preferences because they are based on modelsthat assume independence of irrelevant alternatives (IIA). The perverseincentives induced by IIA hinder innovations on query formats and learningalgorithms.</description><author>Wanqiao Xu, Shi Dong, Xiuyuan Lu, Grace Lam, Zheng Wen, Benjamin Van Roy</author><pubDate>Thu, 01 Feb 2024 18:57:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01057v3</guid></item><item><title>Evaluating Large Language Models for Generalization and Robustness via Data Compression</title><link>http://arxiv.org/abs/2402.00861v1</link><description>Existing methods for evaluating large language models face challenges such asdata contamination, sensitivity to prompts, and the high cost of benchmarkcreation. To address this, we propose a lossless data compression basedevaluation approach that tests how models' predictive abilities generalizeafter their training cutoff. Specifically, we collect comprehensive test dataspanning 83 months from 2017 to 2023 and split the data into training andtesting periods according to models' training data cutoff. We measure: 1) thecompression performance on the testing period as a measure of generalization onunseen data; and 2) the performance gap between the training and testing periodas a measure of robustness. Our experiments test 14 representative largelanguage models with various sizes on sources including Wikipedia, newsarticles, code, arXiv papers, and multi-modal data. We find that thecompression rate of many models reduces significantly after their cutoff date,but models such as Mistral and Llama-2 demonstrate a good balance betweenperformance and robustness. Results also suggest that models struggle togeneralize on news and code data, but work especially well on arXiv papers. Wealso find the context size and tokenization implementation have a big impact ofon the overall compression performance.</description><author>Yucheng Li, Yunhao Guo, Frank Guerin, Chenghua Lin</author><pubDate>Thu, 01 Feb 2024 18:56:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00861v1</guid></item><item><title>Can Large Language Models Understand Context?</title><link>http://arxiv.org/abs/2402.00858v1</link><description>Understanding context is key to understanding human language, an abilitywhich Large Language Models (LLMs) have been increasingly seen to demonstrateto an impressive extent. However, though the evaluation of LLMs encompassesvarious domains within the realm of Natural Language Processing, limitedattention has been paid to probing their linguistic capability of understandingcontextual features. This paper introduces a context understanding benchmark byadapting existing datasets to suit the evaluation of generative models. Thisbenchmark comprises of four distinct tasks and nine datasets, all featuringprompts designed to assess the models' ability to understand context. First, weevaluate the performance of LLMs under the in-context learning pretrainingscenario. Experimental results indicate that pre-trained dense models strugglewith understanding more nuanced contextual features when compared tostate-of-the-art fine-tuned models. Second, as LLM compression holds growingsignificance in both research and real-world applications, we assess thecontext understanding of quantized models under in-context-learning settings.We find that 3-bit post-training quantization leads to varying degrees ofperformance reduction on our benchmark. We conduct an extensive analysis ofthese scenarios to substantiate our experimental results.</description><author>Yilun Zhu, Joel Ruben Antony Moniz, Shruti Bhargava, Jiarui Lu, Dhivya Piraviperumal, Site Li, Yuan Zhang, Hong Yu, Bo-Hsiang Tseng</author><pubDate>Thu, 01 Feb 2024 18:55:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00858v1</guid></item><item><title>Early Time Classification with Accumulated Accuracy Gap Control</title><link>http://arxiv.org/abs/2402.00857v1</link><description>Early time classification algorithms aim to label a stream of featureswithout processing the full input stream, while maintaining accuracy comparableto that achieved by applying the classifier to the entire input. In this paper,we introduce a statistical framework that can be applied to any sequentialclassifier, formulating a calibrated stopping rule. This data-driven ruleattains finite-sample, distribution-free control of the accuracy gap betweenfull and early-time classification. We start by presenting a novel method thatbuilds on the Learn-then-Test calibration framework to control this gapmarginally, on average over i.i.d. instances. As this algorithm tends to yieldan excessively high accuracy gap for early halt times, our main contribution isthe proposal of a framework that controls a stronger notion of error, where theaccuracy gap is controlled conditionally on the accumulated halt times.Numerical experiments demonstrate the effectiveness, applicability, andusefulness of our method. We show that our proposed early stopping mechanismreduces up to 94% of timesteps used for classification while achieving rigorousaccuracy gap control.</description><author>Liran Ringel, Regev Cohen, Daniel Freedman, Michael Elad, Yaniv Romano</author><pubDate>Thu, 01 Feb 2024 18:54:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00857v1</guid></item><item><title>The Power of Populations in Decentralized Bandits</title><link>http://arxiv.org/abs/2306.08670v3</link><description>We study a cooperative multi-agent bandit setting in the distributed GOSSIPmodel: in every round, each of $n$ agents chooses an action from a common set,observes the action's corresponding reward, and subsequently exchangesinformation with a single randomly chosen neighbor, which informs its policy inthe next round. We introduce and analyze several families offully-decentralized local algorithms in this setting under the constraint thateach agent has only constant memory. We highlight a connection between theglobal evolution of such decentralized algorithms and a new class of "zero-sum"multiplicative weights update methods, and we develop a general framework foranalyzing the population-level regret of these natural protocols. Using thisframework, we derive sublinear regret bounds for both stationary andadversarial reward settings. Moreover, we show that these simple localalgorithms can approximately optimize convex functions over the simplex,assuming that the reward distributions are generated from a stochastic gradientoracle.</description><author>John Lazarsfeld, Dan Alistarh</author><pubDate>Thu, 01 Feb 2024 18:54:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08670v3</guid></item><item><title>Towards Efficient and Exact Optimization of Language Model Alignment</title><link>http://arxiv.org/abs/2402.00856v1</link><description>The alignment of language models with human preferences is vital for theirapplication in real-world tasks. The problem is formulated as optimizing themodel's policy to maximize the expected reward that reflects human preferenceswith minimal deviation from the initial policy. While considered as astraightforward solution, reinforcement learning (RL) suffers from highvariance in policy updates, which impedes efficient policy improvement.Recently, direct preference optimization (DPO) was proposed to directlyoptimize the policy from preference data. Though simple to implement, DPO isderived based on the optimal policy that is not assured to be achieved inpractice, which undermines its convergence to the intended solution. In this paper, we propose efficient exact optimization (EXO) of the alignmentobjective. We prove that EXO is guaranteed to optimize in the same direction asthe RL algorithms asymptotically for arbitary parametrization of the policy,while enables efficient optimization by circumventing the complexitiesassociated with RL algorithms. We compare our method to DPO with boththeoretical and empirical analyses, and further demonstrate the advantages ofour method over existing approaches on realistic human preference data.</description><author>Haozhe Ji, Cheng Lu, Yilin Niu, Pei Ke, Hongning Wang, Jun Zhu, Jie Tang, Minlie Huang</author><pubDate>Thu, 01 Feb 2024 18:51:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00856v1</guid></item><item><title>SymbolicAI: A framework for logic-based approaches combining generative models and solvers</title><link>http://arxiv.org/abs/2402.00854v1</link><description>We introduce SymbolicAI, a versatile and modular framework employing alogic-based approach to concept learning and flow management in generativeprocesses. SymbolicAI enables the seamless integration of generative modelswith a diverse range of solvers by treating large language models (LLMs) assemantic parsers that execute tasks based on both natural and formal languageinstructions, thus bridging the gap between symbolic reasoning and generativeAI. We leverage probabilistic programming principles to tackle complex tasks,and utilize differentiable and classical programming paradigms with theirrespective strengths. The framework introduces a set of polymorphic,compositional, and self-referential operations for data stream manipulation,aligning LLM outputs with user objectives. As a result, we can transitionbetween the capabilities of various foundation models endowed with zero- andfew-shot learning capabilities and specialized, fine-tuned models or solversproficient in addressing specific problems. In turn, the framework facilitatesthe creation and evaluation of explainable computational graphs. We conclude byintroducing a quality measure and its empirical score for evaluating thesecomputational graphs, and propose a benchmark that compares variousstate-of-the-art LLMs across a set of complex workflows. We refer to theempirical score as the "Vector Embedding for Relational Trajectory Evaluationthrough Cross-similarity", or VERTEX score for short. The framework codebaseand benchmark are linked below.</description><author>Marius-Constantin Dinu, Claudiu Leoveanu-Condrei, Markus Holzleitner, Werner Zellinger, Sepp Hochreiter</author><pubDate>Thu, 01 Feb 2024 18:50:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00854v1</guid></item><item><title>LTAU-FF: Loss Trajectory Analysis for Uncertainty in Atomistic Force Fields</title><link>http://arxiv.org/abs/2402.00853v1</link><description>Model ensembles are simple and effective tools for estimating the predictionuncertainty of deep learning atomistic force fields. Despite this, widespreadadoption of ensemble-based uncertainty quantification (UQ) techniques islimited by the high computational costs incurred by ensembles during bothtraining and inference. In this work we leverage the cumulative distributionfunctions (CDFs) of per-sample errors obtained over the course of training toefficiently represent the model ensemble, and couple them with a distance-basedsimilarity search in the model latent space. Using these tools, we develop asimple UQ metric (which we call LTAU) that leverages the strengths ofensemble-based techniques without requiring the evaluation of multiple modelsduring either training or inference. As an initial test, we apply our methodtowards estimating the epistemic uncertainty in atomistic force fields(LTAU-FF) and demonstrate that it can be easily calibrated to accuratelypredict test errors on multiple datasets from the literature. We thenillustrate the utility of LTAU-FF in two practical applications: 1) tuning thetraining-validation gap for an example dataset, and 2) predicting errors inrelaxation trajectories on the OC20 IS2RS task. Though in this work we focus onthe use of LTAU with deep learning atomistic force fields, we emphasize that itcan be readily applied to any regression task, or any ensemble-generationtechnique, to provide a reliable and easy-to-implement UQ metric.</description><author>Joshua A. Vita, Amit Samanta, Fei Zhou, Vincenzo Lordi</author><pubDate>Thu, 01 Feb 2024 18:50:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00853v1</guid></item><item><title>SugarViT -- Multi-objective Regression of UAV Images with Vision Transformers and Deep Label Distribution Learning Demonstrated on Disease Severity Prediction in Sugar Beet</title><link>http://arxiv.org/abs/2311.03076v3</link><description>Remote sensing and artificial intelligence are pivotal technologies ofprecision agriculture nowadays. The efficient retrieval of large-scale fieldimagery combined with machine learning techniques shows success in varioustasks like phenotyping, weeding, cropping, and disease control. This work willintroduce a machine learning framework for automatized large-scaleplant-specific trait annotation for the use case disease severity scoring forCercospora Leaf Spot (CLS) in sugar beet. With concepts of Deep LabelDistribution Learning (DLDL), special loss functions, and a tailored modelarchitecture, we develop an efficient Vision Transformer based model fordisease severity scoring called SugarViT. One novelty in this work is thecombination of remote sensing data with environmental parameters of theexperimental sites for disease severity prediction. Although the model isevaluated on this special use case, it is held as generic as possible to alsobe applicable to various image-based classification and regression tasks. Withour framework, it is even possible to learn models on multi-objective problemsas we show by a pretraining on environmental metadata.</description><author>Maurice Günder, Facundo Ramón Ispizua Yamati, Abel Andree Barreto Alcántara, Anne-Katrin Mahlein, Rafet Sifa, Christian Bauckhage</author><pubDate>Thu, 01 Feb 2024 18:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03076v3</guid></item><item><title>Data Augmentation Scheme for Raman Spectra with Highly Correlated Annotations</title><link>http://arxiv.org/abs/2402.00851v1</link><description>In biotechnology Raman Spectroscopy is rapidly gaining popularity as aprocess analytical technology (PAT) that measures cell densities, substrate-and product concentrations. As it records vibrational modes of molecules itprovides that information non-invasively in a single spectrum. Typically,partial least squares (PLS) is the model of choice to infer information aboutvariables of interest from the spectra. However, biological processes are knownfor their complexity where convolutional neural networks (CNN) present apowerful alternative. They can handle non-Gaussian noise and account for beammisalignment, pixel malfunctions or the presence of additional substances.However, they require a lot of data during model training, and they pick upnon-linear dependencies in the process variables. In this work, we exploit theadditive nature of spectra in order to generate additional data points from agiven dataset that have statistically independent labels so that a networktrained on such data exhibits low correlations between the model predictions.We show that training a CNN on these generated data points improves theperformance on datasets where the annotations do not bear the same correlationas the dataset that was used for model training. This data augmentationtechnique enables us to reuse spectra as training data for new contexts thatexhibit different correlations. The additional data allows for building abetter and more robust model. This is of interest in scenarios where largeamounts of historical data are available but are currently not used for modeltraining. We demonstrate the capabilities of the proposed method usingsynthetic spectra of Ralstonia eutropha batch cultivations to monitorsubstrate, biomass and polyhydroxyalkanoate (PHA) biopolymer concentrationsduring of the experiments.</description><author>Christoph Lange, Isabel Thiele, Lara Santolin, Sebastian L. Riedel, Maxim Borisyak, Peter Neubauer, M. Nicolas Cruz Bournazou</author><pubDate>Thu, 01 Feb 2024 18:46:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00851v1</guid></item><item><title>MAMBA: Multi-level Aggregation via Memory Bank for Video Object Detection</title><link>http://arxiv.org/abs/2401.09923v2</link><description>State-of-the-art video object detection methods maintain a memory structure,either a sliding window or a memory queue, to enhance the current frame usingattention mechanisms. However, we argue that these memory structures are notefficient or sufficient because of two implied operations: (1) concatenatingall features in memory for enhancement, leading to a heavy computational cost;(2) frame-wise memory updating, preventing the memory from capturing moretemporal information. In this paper, we propose a multi-level aggregationarchitecture via memory bank called MAMBA. Specifically, our memory bankemploys two novel operations to eliminate the disadvantages of existingmethods: (1) light-weight key-set construction which can significantly reducethe computational cost; (2) fine-grained feature-wise updating strategy whichenables our method to utilize knowledge from the whole video. To better enhancefeatures from complementary levels, i.e., feature maps and proposals, wefurther propose a generalized enhancement operation (GEO) to aggregatemulti-level features in a unified manner. We conduct extensive evaluations onthe challenging ImageNetVID dataset. Compared with existing state-of-the-artmethods, our method achieves superior performance in terms of both speed andaccuracy. More remarkably, MAMBA achieves mAP of 83.7/84.6% at 12.6/9.1 FPSwith ResNet-101. Code is available athttps://github.com/guanxiongsun/vfe.pytorch.</description><author>Guanxiong Sun, Yang Hua, Guosheng Hu, Neil Robertson</author><pubDate>Thu, 01 Feb 2024 18:43:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09923v2</guid></item><item><title>Score-based Causal Representation Learning: Linear and General Transformations</title><link>http://arxiv.org/abs/2402.00849v1</link><description>This paper addresses intervention-based causal representation learning (CRL)under a general nonparametric latent causal model and an unknown transformationthat maps the latent variables to the observed variables. Linear and generaltransformations are investigated. The paper addresses both the\emph{identifiability} and \emph{achievability} aspects. Identifiability refersto determining algorithm-agnostic conditions that ensure recovering the truelatent causal variables and the latent causal graph underlying them.Achievability refers to the algorithmic aspects and addresses designingalgorithms that achieve identifiability guarantees. By drawing novelconnections between \emph{score functions} (i.e., the gradients of thelogarithm of density functions) and CRL, this paper designs a \emph{score-basedclass of algorithms} that ensures both identifiability and achievability.First, the paper focuses on \emph{linear} transformations and shows that onestochastic hard intervention per node suffices to guarantee identifiability. Italso provides partial identifiability guarantees for soft interventions,including identifiability up to ancestors for general causal models and perfectlatent graph recovery for sufficiently non-linear causal models. Secondly, itfocuses on \emph{general} transformations and shows that two stochastic hardinterventions per node suffice for identifiability. Notably, one does\emph{not} need to know which pair of interventional environments have the samenode intervened.</description><author>Burak Varıcı, Emre Acartürk, Karthikeyan Shanmugam, Abhishek Kumar, Ali Tajer</author><pubDate>Thu, 01 Feb 2024 18:40:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00849v1</guid></item><item><title>BootsTAP: Bootstrapped Training for Tracking-Any-Point</title><link>http://arxiv.org/abs/2402.00847v1</link><description>To endow models with greater understanding of physics and motion, it isuseful to enable them to perceive how solid surfaces move and deform in realscenes. This can be formalized as Tracking-Any-Point (TAP), which requires thealgorithm to be able to track any point corresponding to a solid surface in avideo, potentially densely in space and time. Large-scale ground-truth trainingdata for TAP is only available in simulation, which currently has limitedvariety of objects and motion. In this work, we demonstrate how large-scale,unlabeled, uncurated real-world data can improve a TAP model with minimalarchitectural changes, using a self-supervised student-teacher setup. Wedemonstrate state-of-the-art performance on the TAP-Vid benchmark surpassingprevious results by a wide margin: for example, TAP-Vid-DAVIS performanceimproves from 61.3% to 66.4%, and TAP-Vid-Kinetics from 57.2% to 61.5%.</description><author>Carl Doersch, Yi Yang, Dilara Gokay, Pauline Luc, Skanda Koppula, Ankush Gupta, Joseph Heyward, Ross Goroshin, João Carreira, Andrew Zisserman</author><pubDate>Thu, 01 Feb 2024 18:38:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00847v1</guid></item><item><title>Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight in the Real World for Meeting Summarization?</title><link>http://arxiv.org/abs/2402.00841v1</link><description>Large Language Models (LLMs) have demonstrated impressive capabilities tosolve a wide range of tasks without being explicitly fine-tuned ontask-specific datasets. However, deploying LLMs in the real world is nottrivial, as it requires substantial computing resources. In this paper, weinvestigate whether smaller, compact LLMs are a good alternative to thecomparatively Larger LLMs2 to address significant costs associated withutilizing LLMs in the real world. In this regard, we study the meetingsummarization task in a real-world industrial environment and conduct extensiveexperiments by comparing the performance of fine-tuned compact LLMs (e.g.,FLAN-T5, TinyLLaMA, LiteLLaMA) with zero-shot larger LLMs (e.g., LLaMA-2,GPT-3.5, PaLM-2). We observe that most smaller LLMs, even after fine-tuning,fail to outperform larger zero-shot LLMs in meeting summarization datasets.However, a notable exception is FLAN-T5 (780M parameters), which performs onpar or even better than many zero-shot Larger LLMs (from 7B to above 70Bparameters), while being significantly smaller. This makes compact LLMs likeFLAN-T5 a suitable cost-efficient solution for real-world industrialdeployment.</description><author>Xue-Yong Fu, Md Tahmid Rahman Laskar, Elena Khasanova, Cheng Chen, Shashi Bhushan TN</author><pubDate>Thu, 01 Feb 2024 18:31:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00841v1</guid></item><item><title>X-CBA: Explainability Aided CatBoosted Anomal-E for Intrusion Detection System</title><link>http://arxiv.org/abs/2402.00839v1</link><description>The effectiveness of Intrusion Detection Systems (IDS) is critical in an erawhere cyber threats are becoming increasingly complex. Machine learning (ML)and deep learning (DL) models provide an efficient and accurate solution foridentifying attacks and anomalies in computer networks. However, using ML andDL models in IDS has led to a trust deficit due to their non-transparentdecision-making. This transparency gap in IDS research is significant,affecting confidence and accountability. To address, this paper introduces anovel Explainable IDS approach, called X-CBA, that leverages the structuraladvantages of Graph Neural Networks (GNNs) to effectively process networktraffic data, while also adapting a new Explainable AI (XAI) methodology.Unlike most GNN-based IDS that depend on labeled network traffic and nodefeatures, thereby overlooking critical packet-level information, our approachleverages a broader range of traffic data through network flows, including edgeattributes, to improve detection capabilities and adapt to novel threats.Through empirical testing, we establish that our approach not only achieveshigh accuracy with 99.47% in threat detection but also advances the field byproviding clear, actionable explanations of its analytical outcomes. Thisresearch also aims to bridge the current gap and facilitate the broaderintegration of ML/DL technologies in cybersecurity defenses by offering a localand global explainability solution that is both precise and interpretable.</description><author>Kiymet Kaya, Elif Ak, Sumeyye Bas, Berk Canberk, Sule Gunduz Oguducu</author><pubDate>Thu, 01 Feb 2024 18:29:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00839v1</guid></item><item><title>OLMo: Accelerating the Science of Language Models</title><link>http://arxiv.org/abs/2402.00838v1</link><description>Language models (LMs) have become ubiquitous in both NLP research and incommercial product offerings. As their commercial importance has surged, themost powerful models have become closed off, gated behind proprietaryinterfaces, with important details of their training data, architectures, anddevelopment undisclosed. Given the importance of these details inscientifically studying these models, including their biases and potentialrisks, we believe it is essential for the research community to have access topowerful, truly open LMs. To this end, this technical report details the firstrelease of OLMo, a state-of-the-art, truly Open Language Model and itsframework to build and study the science of language modeling. Unlike mostprior efforts that have only released model weights and inference code, werelease OLMo and the whole framework, including training data and training andevaluation code. We hope this release will empower and strengthen the openresearch community and inspire a new wave of innovation.</description><author>Dirk Groeneveld, Iz Beltagy, Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord, Ananya Harsh Jha, Hamish Ivison, Ian Magnusson, Yizhong Wang, Shane Arora, David Atkinson, Russell Authur, Khyathi Raghavi Chandu, Arman Cohan, Jennifer Dumas, Yanai Elazar, Yuling Gu, Jack Hessel, Tushar Khot, William Merrill, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E. Peters, Valentina Pyatkin, Abhilasha Ravichander, Dustin Schwenk, Saurabh Shah, Will Smith, Emma Strubell, Nishant Subramani, Mitchell Wortsman, Pradeep Dasigi, Nathan Lambert, Kyle Richardson, Luke Zettlemoyer, Jesse Dodge, Kyle Lo, Luca Soldaini, Noah A. Smith, Hannaneh Hajishirzi</author><pubDate>Thu, 01 Feb 2024 18:28:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00838v1</guid></item><item><title>Mitigating System Bias in Resource Constrained Asynchronous Federated Learning Systems</title><link>http://arxiv.org/abs/2401.13366v2</link><description>Federated learning (FL) systems face performance challenges in dealing withheterogeneous devices and non-identically distributed data across clients. Wepropose a dynamic global model aggregation method within Asynchronous FederatedLearning (AFL) deployments to address these issues. Our aggregation methodscores and adjusts the weighting of client model updates based on their uploadfrequency to accommodate differences in device capabilities. Additionally, wealso immediately provide an updated global model to clients after they uploadtheir local models to reduce idle time and improve training efficiency. Weevaluate our approach within an AFL deployment consisting of 10 simulatedclients with heterogeneous compute constraints and non-IID data. The simulationresults, using the FashionMNIST dataset, demonstrate over 10% and 19%improvement in global model accuracy compared to state-of-the-art methodsPAPAYA and FedAsync, respectively. Our dynamic aggregation method allowsreliable global model training despite limiting client resources andstatistical data heterogeneity. This improves robustness and scalability forreal-world FL deployments.</description><author>Jikun Gao, Ioannis Mavromatis, Peizheng Li, Pietro Carnelli, Aftab Khan</author><pubDate>Thu, 01 Feb 2024 18:26:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13366v2</guid></item><item><title>Engineering A Large Language Model From Scratch</title><link>http://arxiv.org/abs/2401.16736v2</link><description>The proliferation of deep learning in natural language processing (NLP) hasled to the development and release of innovative technologies capable ofunderstanding and generating human language with remarkable proficiency.Atinuke, a Transformer-based neural network, optimises performance acrossvarious language tasks by utilising a unique configuration. The architectureinterweaves layers for processing sequential data with attention mechanisms todraw meaningful affinities between inputs and outputs. Due to the configurationof its topology and hyperparameter tuning, it can emulate human-like languageby extracting features and learning complex mappings. Atinuke is modular,extensible, and integrates seamlessly with existing machine learning pipelines.Advanced matrix operations like softmax, embeddings, and multi-head attentionenable nuanced handling of textual, acoustic, and visual signals. By unifyingmodern deep learning techniques with software design principles andmathematical theory, the system achieves state-of-the-art results on naturallanguage tasks whilst remaining interpretable and robust.</description><author>Abiodun Finbarrs Oketunji</author><pubDate>Thu, 01 Feb 2024 18:24:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16736v2</guid></item><item><title>ALISON: Fast and Effective Stylometric Authorship Obfuscation</title><link>http://arxiv.org/abs/2402.00835v1</link><description>Authorship Attribution (AA) and Authorship Obfuscation (AO) are two competingtasks of increasing importance in privacy research. Modern AA leverages anauthor's consistent writing style to match a text to its author using an AAclassifier. AO is the corresponding adversarial task, aiming to modify a textin such a way that its semantics are preserved, yet an AA model cannotcorrectly infer its authorship. To address privacy concerns raised bystate-of-the-art (SOTA) AA methods, new AO methods have been proposed butremain largely impractical to use due to their prohibitively slow training andobfuscation speed, often taking hours. To this challenge, we propose apractical AO method, ALISON, that (1) dramatically reduces training/obfuscationtime, demonstrating more than 10x faster obfuscation than SOTA AO methods, (2)achieves better obfuscation success through attacking three transformer-basedAA methods on two benchmark datasets, typically performing 15% better thancompeting methods, (3) does not require direct signals from a target AAclassifier during obfuscation, and (4) utilizes unique stylometric features,allowing sound model interpretation for explainable obfuscation. We alsodemonstrate that ALISON can effectively prevent four SOTA AA methods fromaccurately determining the authorship of ChatGPT-generated texts, all whileminimally changing the original text semantics. To ensure the reproducibilityof our findings, our code and data are available at:https://github.com/EricX003/ALISON.</description><author>Eric Xing, Saranya Venkatraman, Thai Le, Dongwon Lee</author><pubDate>Thu, 01 Feb 2024 18:22:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00835v1</guid></item><item><title>Revisiting the Role of Language Priors in Vision-Language Models</title><link>http://arxiv.org/abs/2306.01879v3</link><description>Vision-language models (VLMs) are impactful in part because they can beapplied to a variety of visual understanding tasks in a zero-shot fashion,without any fine-tuning. We study $\textit{generative VLMs}$ that are trainedfor next-word generation given an image. We explore their zero-shot performanceon the illustrative task of image-text retrieval across 8 popularvision-language benchmarks. Our first observation is that they can berepurposed for discriminative tasks (such as image-text retrieval) by simplycomputing the match score of generating a particular text string given animage. We call this probabilistic score the $\textit{Visual GenerativePre-Training Score}$ (VisualGPTScore). While the VisualGPTScore producesnear-perfect accuracy on some retrieval benchmarks, it yields poor accuracy onothers. We analyze this behavior through a probabilistic lens, pointing outthat some benchmarks inadvertently capture unnatural language distributions bycreating adversarial but unlikely text captions. In fact, we demonstrate thateven a "blind" language model that ignores any image evidence can sometimesoutperform all prior art, reminiscent of similar challenges faced by thevisual-question answering (VQA) community many years ago. We derive aprobabilistic post-processing scheme that controls for the amount of linguisticbias in generative VLMs at test time without having to retrain or fine-tune themodel. We show that the VisualGPTScore, when appropriately debiased, is astrong zero-shot baseline for vision-language understanding, oftentimesproducing state-of-the-art accuracy.</description><author>Zhiqiu Lin, Xinyue Chen, Deepak Pathak, Pengchuan Zhang, Deva Ramanan</author><pubDate>Thu, 01 Feb 2024 18:22:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01879v3</guid></item><item><title>Past, Present, Future: A Comprehensive Exploration of AI Use Cases in the UMBRELLA IoT Testbed</title><link>http://arxiv.org/abs/2401.13346v2</link><description>UMBRELLA is a large-scale, open-access Internet of Things (IoT) ecosystemincorporating over 200 multi-sensor multi-wireless nodes, 20 collaborativerobots, and edge-intelligence-enabled devices. This paper provides a guide tothe implemented and prospective artificial intelligence (AI) capabilities ofUMBRELLA in real-world IoT systems. Four existing UMBRELLA applications arepresented in detail: 1) An automated streetlight monitoring for detectingissues and triggering maintenance alerts; 2) A Digital twin of buildingenvironments providing enhanced air quality sensing with reduced cost; 3) Alarge-scale Federated Learning framework for reducing communication overhead;and 4) An intrusion detection for containerised applications identifyingmalicious activities. Additionally, the potential of UMBRELLA is outlined forfuture smart city and multi-robot crowdsensing applications enhanced bysemantic communications and multi-agent planning. Finally, to realise the aboveuse-cases we discuss the need for a tailored MLOps platform to automateUMBRELLA model pipelines and establish trust.</description><author>Peizheng Li, Ioannis Mavromatis, Aftab Khan</author><pubDate>Thu, 01 Feb 2024 18:20:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13346v2</guid></item><item><title>A YANG-aided Unified Strategy for Black Hole Detection for Backbone Networks</title><link>http://arxiv.org/abs/2402.00831v1</link><description>Despite the crucial importance of addressing Black Hole failures in Internetbackbone networks, effective detection strategies in backbone networks arelacking. This is largely because previous research has been centered on MobileAd-hoc Networks (MANETs), which operate under entirely different dynamics,protocols, and topologies, making their findings not directly transferable tobackbone networks. Furthermore, detecting Black Hole failures in backbonenetworks is particularly challenging. It requires a comprehensive range ofnetwork data due to the wide variety of conditions that need to be considered,making data collection and analysis far from straightforward. Addressing thisgap, our study introduces a novel approach for Black Hole detection in backbonenetworks using specialized Yet Another Next Generation (YANG) data models withBlack Hole-sensitive Metric Matrix (BHMM) analysis. This paper details ourmethod of selecting and analyzing four YANG models relevant to Black Holedetection in ISP networks, focusing on routing protocols and ISP-specificconfigurations. Our BHMM approach derived from these models demonstrates a 10%improvement in detection accuracy and a 13% increase in packet delivery rate,highlighting the efficiency of our approach. Additionally, we evaluate theMachine Learning approach leveraged with BHMM analysis in two different networksettings, a commercial ISP network, and a scientific research-only networktopology. This evaluation also demonstrates the practical applicability of ourmethod, yielding significantly improved prediction outcomes in bothenvironments.</description><author>Elif Ak, Kiymet Kaya, Eren Ozaltun, Sule Gunduz Oguducu, Berk Canberk</author><pubDate>Thu, 01 Feb 2024 18:17:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00831v1</guid></item><item><title>Efficient Fine-tuning of Audio Spectrogram Transformers via Soft Mixture of Adapters</title><link>http://arxiv.org/abs/2402.00828v1</link><description>Mixture of Experts (MoE) architectures have recently started burgeoning dueto their ability to scale model's capacity while maintaining the computationalcost affordable. Furthermore, they can be applied to both Transformers andState Space Models, the current state-of-the-art models in numerous fields.While MoE has been mostly investigated for the pre-training stage, its use inparameter-efficient transfer learning settings is under-explored. To narrowthis gap, this paper attempts to demystify the use of MoE forparameter-efficient fine-tuning of Audio Spectrogram Transformers to audio andspeech downstream tasks. Specifically, we propose Soft Mixture of Adapters(Soft-MoA). It exploits adapters as the experts and, leveraging the recent SoftMoE method, it relies on a soft assignment between the input tokens and expertsto keep the computational time limited. Extensive experiments across 4benchmarks demonstrate that Soft-MoA outperforms the single adapter method andperforms on par with the dense MoA counterpart. We finally present ablationstudies on key elements of Soft-MoA, showing for example that Soft-MoA achievesbetter scaling with more experts, as well as ensuring that all expertscontribute to the computation of the output tokens, thus dispensing with theexpert imbalance issue.</description><author>Umberto Cappellazzo, Daniele Falavigna, Alessio Brutti</author><pubDate>Thu, 01 Feb 2024 18:16:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00828v1</guid></item><item><title>Distilling Mathematical Reasoning Capabilities into Small Language Models</title><link>http://arxiv.org/abs/2401.11864v4</link><description>This work addresses the challenge of democratizing advanced Large LanguageModels (LLMs) by compressing their mathematical reasoning capabilities intosub-billion parameter Small Language Models (SLMs) without compromisingperformance. We introduce Equation-of-Thought Distillation (EoTD), a noveltechnique that encapsulates the reasoning process into equation-basedrepresentations to construct an EoTD dataset for fine-tuning SLMs.Additionally, we propose the Ensemble Thoughts Distillation (ETD) framework toenhance the reasoning performance of SLMs. This involves creating a reasoningdataset with multiple thought processes, including Chain-of-Thought (CoT),Program-of-Thought (PoT), and Equation-of-Thought (EoT), and using it forfine-tuning. Our experimental findings demonstrate that EoTD significantlyboosts the reasoning abilities of SLMs, while ETD enables these models toachieve state-of-the-art reasoning performance.</description><author>Xunyu Zhu, Jian Li, Yong Liu, Can Ma, Weiping Wang</author><pubDate>Thu, 01 Feb 2024 18:16:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11864v4</guid></item><item><title>Emo-Avatar: Efficient Monocular Video Style Avatar through Texture Rendering</title><link>http://arxiv.org/abs/2402.00827v1</link><description>Artistic video portrait generation is a significant and sought-after task inthe fields of computer graphics and vision. While various methods have beendeveloped that integrate NeRFs or StyleGANs with instructional editing modelsfor creating and editing drivable portraits, these approaches face severalchallenges. They often rely heavily on large datasets, require extensivecustomization processes, and frequently result in reduced image quality. Toaddress the above problems, we propose the Efficient Monotonic Video StyleAvatar (Emo-Avatar) through deferred neural rendering that enhances StyleGAN'scapacity for producing dynamic, drivable portrait videos. We proposed atwo-stage deferred neural rendering pipeline. In the first stage, we utilizefew-shot PTI initialization to initialize the StyleGAN generator throughseveral extreme poses sampled from the video to capture the consistentrepresentation of aligned faces from the target portrait. In the second stage,we propose a Laplacian pyramid for high-frequency texture sampling from UV mapsdeformed by dynamic flow of expression for motion-aware texture priorintegration to provide torso features to enhance StyleGAN's ability to generatecomplete and upper body for portrait video rendering. Emo-Avatar reduces stylecustomization time from hours to merely 5 minutes compared with existingmethods. In addition, Emo-Avatar requires only a single reference image forediting and employs region-aware contrastive learning with semantic invariantCLIP guidance, ensuring consistent high-resolution output and identitypreservation. Through both quantitative and qualitative assessments, Emo-Avatardemonstrates superior performance over existing methods in terms of trainingefficiency, rendering quality and editability in self- and cross-reenactment.</description><author>Pinxin Liu, Luchuan Song, Daoan Zhang, Hang Hua, Yunlong Tang, Huaijin Tu, Jiebo Luo, Chenliang Xu</author><pubDate>Thu, 01 Feb 2024 18:14:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00827v1</guid></item><item><title>Conformal Prediction Sets Improve Human Decision Making</title><link>http://arxiv.org/abs/2401.13744v2</link><description>In response to everyday queries, humans explicitly signal uncertainty andoffer alternative answers when they are unsure. Machine learning models thatoutput calibrated prediction sets through conformal prediction mimic this humanbehaviour; larger sets signal greater uncertainty while providing alternatives.In this work, we study the usefulness of conformal prediction sets as an aidfor human decision making by conducting a pre-registered randomized controlledtrial with conformal prediction sets provided to human subjects. Withstatistical significance, we find that when humans are given conformalprediction sets their accuracy on tasks improves compared to fixed-sizeprediction sets with the same coverage guarantee. The results show thatquantifying model uncertainty with conformal prediction is helpful forhuman-in-the-loop decision making and human-AI teams.</description><author>Jesse C. Cresswell, Yi Sui, Bhargava Kumar, Noël Vouitsis</author><pubDate>Thu, 01 Feb 2024 18:14:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13744v2</guid></item><item><title>Resolution invariant deep operator network for PDEs with complex geometries</title><link>http://arxiv.org/abs/2402.00825v1</link><description>Neural operators (NO) are discretization invariant deep learning methods withfunctional output and can approximate any continuous operator. NO havedemonstrated the superiority of solving partial differential equations (PDEs)over other deep learning methods. However, the spatial domain of its inputfunction needs to be identical to its output, which limits its applicability.For instance, the widely used Fourier neural operator (FNO) fails toapproximate the operator that maps the boundary condition to the PDE solution.To address this issue, we propose a novel framework called resolution-invariantdeep operator (RDO) that decouples the spatial domain of the input and output.RDO is motivated by the Deep operator network (DeepONet) and it does notrequire retraining the network when the input/output is changed compared withDeepONet. RDO takes functional input and its output is also functional so thatit keeps the resolution invariant property of NO. It can also resolve PDEs withcomplex geometries whereas NO fail. Various numerical experiments demonstratethe advantage of our method over DeepONet and FNO.</description><author>Jianguo Huang, Yue Qiu</author><pubDate>Thu, 01 Feb 2024 18:11:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00825v1</guid></item><item><title>SLIM: Skill Learning with Multiple Critics</title><link>http://arxiv.org/abs/2402.00823v1</link><description>Self-supervised skill learning aims to acquire useful behaviors that leveragethe underlying dynamics of the environment. Latent variable models, based onmutual information maximization, have been particularly successful in this taskbut still struggle in the context of robotic manipulation. As it requiresimpacting a possibly large set of degrees of freedom composing the environment,mutual information maximization fails alone in producing useful manipulationbehaviors. To address this limitation, we introduce SLIM, a multi-criticlearning approach for skill discovery with a particular focus on roboticmanipulation. Our main insight is that utilizing multiple critics in anactor-critic framework to gracefully combine multiple reward functions leads toa significant improvement in latent-variable skill discovery for roboticmanipulation while overcoming possible interference occurring among rewardswhich hinders convergence to useful skills. Furthermore, in the context oftabletop manipulation, we demonstrate the applicability of our novel skilldiscovery approach to acquire safe and efficient motor primitives in ahierarchical reinforcement learning fashion and leverage them through planning,surpassing the state-of-the-art approaches for skill discovery by a largemargin.</description><author>David Emukpere, Bingbing Wu, Julien Perez</author><pubDate>Thu, 01 Feb 2024 18:07:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00823v1</guid></item><item><title>WiOpen: A Robust Wi-Fi-based Open-set Gesture Recognition Framework</title><link>http://arxiv.org/abs/2402.00822v1</link><description>Recent years have witnessed a growing interest in Wi-Fi-based gesturerecognition. However, existing works have predominantly focused on closed-setparadigms, where all testing gestures are predefined during training. Thisposes a significant challenge in real-world applications, as unseen gesturesmight be misclassified as known classes during testing. To address this issue,we propose WiOpen, a robust Wi-Fi-based Open-Set Gesture Recognition (OSGR)framework. Implementing OSGR requires addressing challenges caused by theunique uncertainty in Wi-Fi sensing. This uncertainty, resulting from noise anddomains, leads to widely scattered and irregular data distributions incollected Wi-Fi sensing data. Consequently, data ambiguity between classes andchallenges in defining appropriate decision boundaries to identify unknownsarise. To tackle these challenges, WiOpen adopts a two-fold approach toeliminate uncertainty and define precise decision boundaries. Initially, itaddresses uncertainty induced by noise during data preprocessing by utilizingthe CSI ratio. Next, it designs the OSGR network based on an uncertaintyquantification method. Throughout the learning process, this networkeffectively mitigates uncertainty stemming from domains. Ultimately, thenetwork leverages relationships among samples' neighbors to dynamically defineopen-set decision boundaries, successfully realizing OSGR. Comprehensiveexperiments on publicly accessible datasets confirm WiOpen's effectiveness.Notably, WiOpen also demonstrates superiority in cross-domain tasks whencompared to state-of-the-art approaches.</description><author>Xiang Zhang, Jingyang Huang, Huan Yan, Peng Zhao, Guohang Zhuang, Zhi Liu, Bin Liu</author><pubDate>Thu, 01 Feb 2024 18:05:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00822v1</guid></item><item><title>Gaze Detection and Analysis for Initiating Joint Activity in Industrial Human-Robot Collaboration</title><link>http://arxiv.org/abs/2312.06643v3</link><description>Collaborative robots (cobots) are widely used in industrial applications, yetextensive research is still needed to enhance human-robot collaborations andoperator experience. A potential approach to improve the collaborationexperience involves adapting cobot behavior based on natural cues from theoperator. Inspired by the literature on human-human interactions, we conducteda wizard-of-oz study to examine whether a gaze towards the cobot can serve as atrigger for initiating joint activities in collaborative sessions. In thisstudy, 37 participants engaged in an assembly task while their gaze behaviorwas analyzed. We employ a gaze-based attention recognition model to identifywhen the participants look at the cobot. Our results indicate that in mostcases (84.88\%), the joint activity is preceded by a gaze towards the cobot.Furthermore, during the entire assembly cycle, the participants tend to look atthe cobot around the time of the joint activity. To the best of our knowledge,this is the first study to analyze the natural gaze behavior of participantsworking on a joint activity with a robot during a collaborative assembly task.</description><author>Pooja Prajod, Matteo Lavit Nicora, Marta Mondellini, Giovanni Tauro, Rocco Vertechy, Matteo Malosio, Elisabeth André</author><pubDate>Thu, 01 Feb 2024 18:05:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06643v3</guid></item><item><title>HyperMask: Adaptive Hypernetwork-based Masks for Continual Learning</title><link>http://arxiv.org/abs/2310.00113v3</link><description>Artificial neural networks suffer from catastrophic forgetting when they aresequentially trained on multiple tasks. Many continual learning (CL) strategiesare trying to overcome this problem. One of the most effective is thehypernetwork-based approach. The hypernetwork generates the weights of a targetmodel based on the task's identity. The model's main limitation is that, inpractice, the hypernetwork can produce completely different architectures forsubsequent tasks. To solve such a problem, we use the lottery tickethypothesis, which postulates the existence of sparse subnetworks, named winningtickets, that preserve the performance of a whole network. In the paper, wepropose a method called HyperMask, which trains a single network for all CLtasks. The hypernetwork produces semi-binary masks to obtain target subnetworksdedicated to consecutive tasks. Moreover, due to the lottery ticket hypothesis,we can use a single network with weighted subnets. Depending on the task, theimportance of some weights may be dynamically enhanced while others may beweakened. HyperMask achieves competitive results in several CL datasets and, insome scenarios, goes beyond the state-of-the-art scores, both with derived andunknown task identities.</description><author>Kamil Książek, Przemysław Spurek</author><pubDate>Thu, 01 Feb 2024 18:01:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00113v3</guid></item><item><title>Stars Are All You Need: A Distantly Supervised Pyramid Network for Unified Sentiment Analysis</title><link>http://arxiv.org/abs/2305.01710v2</link><description>Data for the Rating Prediction (RP) sentiment analysis task such as starreviews are readily available. However, data for aspect-category detection(ACD) and aspect-category sentiment analysis (ACSA) is often desired because ofthe fine-grained nature but are expensive to collect. In this work, we proposeUnified Sentiment Analysis (Uni-SA) to understand aspect and review sentimentin a unified manner. Specifically, we propose a Distantly Supervised PyramidNetwork (DSPN) to efficiently perform ACD, ACSA, and RP using only RP labelsfor training. We evaluate DSPN on multi-aspect review datasets in English andChinese and find that in addition to the internal efficiency of sample size,DSPN also performs comparably well to a variety of benchmark models. We alsodemonstrate the interpretability of DSPN's outputs on reviews to show thepyramid structure inherent in unified sentiment analysis.</description><author>Wenchang Li, Yixing Chen, Shuang Zheng, Lei Wang, John P. Lalor</author><pubDate>Thu, 01 Feb 2024 17:57:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.01710v2</guid></item><item><title>Leveraging Approximate Model-based Shielding for Probabilistic Safety Guarantees in Continuous Environments</title><link>http://arxiv.org/abs/2402.00816v1</link><description>Shielding is a popular technique for achieving safe reinforcement learning(RL). However, classical shielding approaches come with quite restrictiveassumptions making them difficult to deploy in complex environments,particularly those with continuous state or action spaces. In this paper weextend the more versatile approximate model-based shielding (AMBS) framework tothe continuous setting. In particular we use Safety Gym as our test-bed,allowing for a more direct comparison of AMBS with popular constrained RLalgorithms. We also provide strong probabilistic safety guarantees for thecontinuous setting. In addition, we propose two novel penalty techniques thatdirectly modify the policy gradient, which empirically provide more stableconvergence in our experiments.</description><author>Alexander W. Goodall, Francesco Belardinelli</author><pubDate>Thu, 01 Feb 2024 17:55:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00816v1</guid></item><item><title>An Analysis of the Variance of Diffusion-based Speech Enhancement</title><link>http://arxiv.org/abs/2402.00811v1</link><description>Diffusion models proved to be powerful models for generative speechenhancement. In recent SGMSE+ approaches, training involves a stochasticdifferential equation for the diffusion process, adding both Gaussian andenvironmental noise to the clean speech signal gradually. The speechenhancement performance varies depending on the choice of the stochasticdifferential equation that controls the evolution of the mean and the variancealong the diffusion processes when adding environmental and Gaussian noise. Inthis work, we highlight that the scale of the variance is a dominant parameterfor speech enhancement performance and show that it controls the tradeoffbetween noise attenuation and speech distortions. More concretely, we show thata larger variance increases the noise attenuation and allows for reducing thecomputational footprint, as fewer function evaluations for generating theestimate are required.</description><author>Bunlong Lay, Timo Gerkmann</author><pubDate>Thu, 01 Feb 2024 17:46:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00811v1</guid></item><item><title>Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI</title><link>http://arxiv.org/abs/2402.00809v1</link><description>In the current landscape of deep learning research, there is a predominantemphasis on achieving high predictive accuracy in supervised tasks involvinglarge image and language datasets. However, a broader perspective reveals amultitude of overlooked metrics, tasks, and data types, such as uncertainty,active and continual learning, and scientific data, that demand attention.Bayesian deep learning (BDL) constitutes a promising avenue, offeringadvantages across these diverse settings. This paper posits that BDL canelevate the capabilities of deep learning. It revisits the strengths of BDL,acknowledges existing challenges, and highlights some exciting research avenuesaimed at addressing these obstacles. Looking ahead, the discussion focuses onpossible ways to combine large-scale foundation models with BDL to unlock theirfull potential.</description><author>Theodore Papamarkou, Maria Skoularidou, Konstantina Palla, Laurence Aitchison, Julyan Arbel, David Dunson, Maurizio Filippone, Vincent Fortuin, Philipp Hennig, Aliaksandr Hubin, Alexander Immer, Theofanis Karaletsos, Mohammad Emtiyaz Khan, Agustinus Kristiadi, Yingzhen Li, Jose Miguel Hernandez Lobato, Stephan Mandt, Christopher Nemeth, Michael A. Osborne, Tim G. J. Rudner, David Rügamer, Yee Whye Teh, Max Welling, Andrew Gordon Wilson, Ruqi Zhang</author><pubDate>Thu, 01 Feb 2024 17:45:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00809v1</guid></item><item><title>Exploring the Dynamics between Cobot's Production Rhythm, Locus of Control and Emotional State in a Collaborative Assembly Scenario</title><link>http://arxiv.org/abs/2402.00808v1</link><description>In industrial scenarios, there is widespread use of collaborative robots(cobots), and growing interest is directed at evaluating and measuring theimpact of some characteristics of the cobot on the human factor. In the presentpilot study, the effect that the production rhythm (C1 - Slow, C2 - Fast, C3 -Adapted to the participant's pace) of a cobot has on the Experiential Locus ofControl (ELoC) and the emotional state of 31 participants has been examined.The operators' performance, the degree of basic internal Locus of Control, andthe attitude towards the robots were also considered. No difference was foundregarding the emotional state and the ELoC in the three conditions, butconsidering the other psychological variables, a more complex situationemerges. Overall, results seem to indicate a need to consider the person'spsychological characteristics to offer a differentiated and optimal interactionexperience.</description><author>Marta Mondellini, Matteo Lavit Nicora, Pooja Prajod, Elisabeth André, Rocco Vertechy, Alessandro Antonietti, Matteo Malosio</author><pubDate>Thu, 01 Feb 2024 17:44:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00808v1</guid></item><item><title>Distilling Conditional Diffusion Models for Offline Reinforcement Learning through Trajectory Stitching</title><link>http://arxiv.org/abs/2402.00807v1</link><description>Deep generative models have recently emerged as an effective approach tooffline reinforcement learning. However, their large model size poseschallenges in computation. We address this issue by proposing a knowledgedistillation method based on data augmentation. In particular, high-returntrajectories are generated from a conditional diffusion model, and they areblended with the original trajectories through a novel stitching algorithm thatleverages a new reward generator. Applying the resulting dataset to behavioralcloning, the learned shallow policy whose size is much smaller outperforms ornearly matches deep generative planners on several D4RL benchmarks.</description><author>Shangzhe Li, Xinhua Zhang</author><pubDate>Thu, 01 Feb 2024 17:44:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00807v1</guid></item><item><title>Signal Quality Auditing for Time-series Data</title><link>http://arxiv.org/abs/2402.00803v1</link><description>Signal quality assessment (SQA) is required for monitoring the reliability ofdata acquisition systems, especially in AI-driven Predictive Maintenance (PMx)application contexts. SQA is vital for addressing "silent failures" of dataacquisition hardware and software, which when unnoticed, misinform the users ofdata, creating the risk for incorrect decisions with unintended or evencatastrophic consequences. We have developed an open-source softwareimplementation of signal quality indices (SQIs) for the analysis of time-seriesdata. We codify a range of SQIs, demonstrate them using established benchmarkdata, and show that they can be effective for signal quality assessment. Wealso study alternative approaches to denoising time-series data in an attemptto improve the quality of the already degraded signal, and evaluate themempirically on relevant real-world data. To our knowledge, our software toolkitis the first to provide an open source implementation of a broad range ofsignal quality assessment and improvement techniques validated on publiclyavailable benchmark data for ease of reproducibility. The generality of ourframework can be easily extended to assessing reliability of arbitrarytime-series measurements in complex systems, especially when morphologicalpatterns of the waveform shapes and signal periodicity are of key interest indownstream analyses.</description><author>Chufan Gao, Nicholas Gisolfi, Artur Dubrawski</author><pubDate>Thu, 01 Feb 2024 17:40:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00803v1</guid></item><item><title>Evidentiality-aware Retrieval for Overcoming Abstractiveness in Open-Domain Question Answering</title><link>http://arxiv.org/abs/2304.03031v6</link><description>The long-standing goal of dense retrievers in abtractive open-domain questionanswering (ODQA) tasks is to learn to capture evidence passages among relevantpassages for any given query, such that the reader produce factually correctoutputs from evidence passages. One of the key challenge is the insufficientamount of training data with the supervision of the answerability of thepassages. Recent studies rely on iterative pipelines to annotate answerabilityusing signals from the reader, but their high computational costs hamperpractical applications. In this paper, we instead focus on a data-centricapproach and propose Evidentiality-Aware Dense Passage Retrieval (EADPR), whichleverages synthetic distractor samples to learn to discriminate evidencepassages from distractors. We conduct extensive experiments to validate theeffectiveness of our proposed method on multiple abstractive ODQA tasks.</description><author>Yongho Song, Dahyun Lee, Myungha Jang, Seung-won Hwang, Kyungjae Lee, Dongha Lee, Jinyeong Yeo</author><pubDate>Thu, 01 Feb 2024 17:36:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03031v6</guid></item><item><title>Enhancing Energy-Awareness in Deep Learning through Fine-Grained Energy Measurement</title><link>http://arxiv.org/abs/2308.12264v2</link><description>With the increasing usage, scale, and complexity of Deep Learning (DL)models, their rapidly growing energy consumption has become a critical concern.Promoting green development and energy awareness at different granularities isthe need of the hour to limit carbon emissions of DL systems. However, the lackof standard and repeatable tools to accurately measure and optimize energyconsumption at a fine granularity (e.g., at method level) hinders progress inthis area. This paper introduces FECoM (Fine-grained Energy Consumption Meter),a framework for fine-grained DL energy consumption measurement. FECoM enablesresearchers and developers to profile DL APIs from energy perspective. FECoMaddresses the challenges of measuring energy consumption at fine-grained levelby using static instrumentation and considering various factors, includingcomputational load and temperature stability. We assess FECoM's capability tomeasure fine-grained energy consumption for one of the most popular open-sourceDL frameworks, namely TensorFlow. Using FECoM, we also investigate the impactof parameter size and execution time on energy consumption, enriching ourunderstanding of TensorFlow APIs' energy profiles. Furthermore, we elaborate onthe considerations, issues, and challenges that one needs to consider whiledesigning and implementing a fine-grained energy consumption measurement tool.This work will facilitate further advances in DL energy measurement and thedevelopment of energy-aware practices for DL systems.</description><author>Saurabhsingh Rajput, Tim Widmayer, Ziyuan Shang, Maria Kechagia, Federica Sarro, Tushar Sharma</author><pubDate>Thu, 01 Feb 2024 17:35:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12264v2</guid></item><item><title>Leveraging Open Information Extraction for More Robust Domain Transfer of Event Trigger Detection</title><link>http://arxiv.org/abs/2305.14163v2</link><description>Event detection is a crucial information extraction task in many domains,such as Wikipedia or news. The task typically relies on trigger detection (TD)-- identifying token spans in the text that evoke specific events. While thenotion of triggers should ideally be universal across domains, domain transferfor TD from high- to low-resource domains results in significant performancedrops. We address the problem of negative transfer in TD by coupling triggersbetween domains using subject-object relations obtained from a rule-based openinformation extraction (OIE) system. We demonstrate that OIE relations injectedthrough multi-task training can act as mediators between triggers in differentdomains, enhancing zero- and few-shot TD domain transfer and reducingperformance drops, in particular when transferring from a high-resource sourcedomain (Wikipedia) to a low(er)-resource target domain (news). Additionally, wecombine this improved transfer with masked language modeling on the targetdomain, observing further TD transfer gains. Finally, we demonstrate that thegains are robust to the choice of the OIE system.</description><author>David Dukić, Kiril Gashteovski, Goran Glavaš, Jan Šnajder</author><pubDate>Thu, 01 Feb 2024 17:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14163v2</guid></item><item><title>Generalized Video Anomaly Event Detection: Systematic Taxonomy and Comparison of Deep Models</title><link>http://arxiv.org/abs/2302.05087v3</link><description>Video Anomaly Detection (VAD) serves as a pivotal technology in theintelligent surveillance systems, enabling the temporal or spatialidentification of anomalous events within videos. While existing reviewspredominantly concentrate on conventional unsupervised methods, they oftenoverlook the emergence of weakly-supervised and fully-unsupervised approaches.To address this gap, this survey extends the conventional scope of VAD beyondunsupervised methods, encompassing a broader spectrum termed Generalized VideoAnomaly Event Detection (GVAED). By skillfully incorporating recentadvancements rooted in diverse assumptions and learning frameworks, this surveyintroduces an intuitive taxonomy that seamlessly navigates throughunsupervised, weakly-supervised, supervised and fully-unsupervised VADmethodologies, elucidating the distinctions and interconnections within theseresearch trajectories. In addition, this survey facilitates prospectiveresearchers by assembling a compilation of research resources, including publicdatasets, available codebases, programming tools, and pertinent literature.Furthermore, this survey quantitatively assesses model performance, delves intoresearch challenges and directions, and outlines potential avenues for futureexploration.</description><author>Yang Liu, Dingkang Yang, Yan Wang, Jing Liu, Jun Liu, Azzedine Boukerche, Peng Sun, Liang Song</author><pubDate>Thu, 01 Feb 2024 17:32:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.05087v3</guid></item><item><title>Formal-LLM: Integrating Formal Language and Natural Language for Controllable LLM-based Agents</title><link>http://arxiv.org/abs/2402.00798v1</link><description>Recent advancements on Large Language Models (LLMs) enable AI Agents toautomatically generate and execute multi-step plans to solve complex tasks.However, since LLM's content generation process is hardly controllable, currentLLM-based agents frequently generate invalid or non-executable plans, whichjeopardizes the performance of the generated plans and corrupts users' trust inLLM-based agents. In response, this paper proposes a novel ``Formal-LLM''framework for LLM-based agents by integrating the expressiveness of naturallanguage and the precision of formal language. Specifically, the frameworkallows human users to express their requirements or constraints for theplanning process as an automaton. A stack-based LLM plan generation process isthen conducted under the supervision of the automaton to ensure that thegenerated plan satisfies the constraints, making the planning processcontrollable. We conduct experiments on both benchmark tasks and practicalreal-life tasks, and our framework achieves over 50% overall performanceincrease, which validates the feasibility and effectiveness of employingFormal-LLM to guide the plan generation of agents, preventing the agents fromgenerating invalid and unsuccessful plans. Further, more controllable LLM-basedagents can facilitate the broader utilization of LLM in application scenarioswhere high validity of planning is essential. The work is open-sourced athttps://github.com/agiresearch/Formal-LLM.</description><author>Zelong Li, Wenyue Hua, Hao Wang, He Zhu, Yongfeng Zhang</author><pubDate>Thu, 01 Feb 2024 17:30:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00798v1</guid></item><item><title>LLMs learn governing principles of dynamical systems, revealing an in-context neural scaling law</title><link>http://arxiv.org/abs/2402.00795v1</link><description>Pretrained large language models (LLMs) are surprisingly effective atperforming zero-shot tasks, including time-series forecasting. However,understanding the mechanisms behind such capabilities remains highlychallenging due to the complexity of the models. In this paper, we study LLMs'ability to extrapolate the behavior of dynamical systems whose evolution isgoverned by principles of physical interest. Our results show that LLaMA 2, alanguage model trained primarily on texts, achieves accurate predictions ofdynamical system time series without fine-tuning or prompt engineering.Moreover, the accuracy of the learned physical rules increases with the lengthof the input context window, revealing an in-context version of neural scalinglaw. Along the way, we present a flexible and efficient algorithm forextracting probability density functions of multi-digit numbers directly fromLLMs.</description><author>Toni J. B. Liu, Nicolas Boullé, Raphaël Sarfati, Christopher J. Earls</author><pubDate>Thu, 01 Feb 2024 17:28:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00795v1</guid></item><item><title>ReAGent: Towards A Model-agnostic Feature Attribution Method for Generative Language Models</title><link>http://arxiv.org/abs/2402.00794v1</link><description>Feature attribution methods (FAs), such as gradients and attention, arewidely employed approaches to derive the importance of all input features tothe model predictions. Existing work in natural language processing has mostlyfocused on developing and testing FAs for encoder-only language models (LMs) inclassification tasks. However, it is unknown if it is faithful to use these FAsfor decoder-only models on text generation, due to the inherent differencesbetween model architectures and task settings respectively. Moreover, previouswork has demonstrated that there is no `one-wins-all' FA across models andtasks. This makes the selection of a FA computationally expensive for large LMssince input importance derivation often requires multiple forward and backwardpasses including gradient computations that might be prohibitive even withaccess to large compute. To address these issues, we present a model-agnosticFA for generative LMs called Recursive Attribution Generator (ReAGent). Ourmethod updates the token importance distribution in a recursive manner. Foreach update, we compute the difference in the probability distribution over thevocabulary for predicting the next token between using the original input andusing a modified version where a part of the input is replaced with RoBERTapredictions. Our intuition is that replacing an important token in the contextshould have resulted in a larger change in the model's confidence in predictingthe token than replacing an unimportant token. Our method can be universallyapplied to any generative LM without accessing internal model weights oradditional training and fine-tuning, as most other FAs require. We extensivelycompare the faithfulness of ReAGent with seven popular FAs across sixdecoder-only LMs of various sizes. The results show that our methodconsistently provides more faithful token importance distributions.</description><author>Zhixue Zhao, Boxuan Shan</author><pubDate>Thu, 01 Feb 2024 17:25:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00794v1</guid></item><item><title>Distinguishing the Indistinguishable: Human Expertise in Algorithmic Prediction</title><link>http://arxiv.org/abs/2402.00793v1</link><description>We introduce a novel framework for incorporating human expertise intoalgorithmic predictions. Our approach focuses on the use of human judgment todistinguish inputs which `look the same' to any feasible predictive algorithm.We argue that this framing clarifies the problem of human/AI collaboration inprediction tasks, as experts often have access to information -- particularlysubjective information -- which is not encoded in the algorithm's trainingdata. We use this insight to develop a set of principled algorithms forselectively incorporating human feedback only when it improves the performanceof any feasible predictor. We find empirically that although algorithms oftenoutperform their human counterparts on average, human judgment cansignificantly improve algorithmic predictions on specific instances (which canbe identified ex-ante). In an X-ray classification task, we find that thissubset constitutes nearly 30% of the patient population. Our approach providesa natural way of uncovering this heterogeneity and thus enabling effectivehuman-AI collaboration.</description><author>Rohan Alur, Manish Raghavan, Devavrat Shah</author><pubDate>Thu, 01 Feb 2024 17:23:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00793v1</guid></item><item><title>Graph-Mamba: Towards Long-Range Graph Sequence Modeling with Selective State Spaces</title><link>http://arxiv.org/abs/2402.00789v1</link><description>Attention mechanisms have been widely used to capture long-range dependenciesamong nodes in Graph Transformers. Bottlenecked by the quadratic computationalcost, attention mechanisms fail to scale in large graphs. Recent improvementsin computational efficiency are mainly achieved by attention sparsificationwith random or heuristic-based graph subsampling, which falls short indata-dependent context reasoning. State space models (SSMs), such as Mamba,have gained prominence for their effectiveness and efficiency in modelinglong-range dependencies in sequential data. However, adapting SSMs tonon-sequential graph data presents a notable challenge. In this work, weintroduce Graph-Mamba, the first attempt to enhance long-range context modelingin graph networks by integrating a Mamba block with the input-dependent nodeselection mechanism. Specifically, we formulate graph-centric nodeprioritization and permutation strategies to enhance context-aware reasoning,leading to a substantial improvement in predictive performance. Extensiveexperiments on ten benchmark datasets demonstrate that Graph-Mamba outperformsstate-of-the-art methods in long-range graph prediction tasks, with a fractionof the computational cost in both FLOPs and GPU memory consumption. The codeand models are publicly available at https://github.com/bowang-lab/Graph-Mamba.</description><author>Chloe Wang, Oleksii Tsepa, Jun Ma, Bo Wang</author><pubDate>Thu, 01 Feb 2024 17:21:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00789v1</guid></item><item><title>Learning and Calibrating Heterogeneous Bounded Rational Market Behaviour with Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2402.00787v1</link><description>Agent-based models (ABMs) have shown promise for modelling various real worldphenomena incompatible with traditional equilibrium analysis. However, acritical concern is the manual definition of behavioural rules in ABMs. Recentdevelopments in multi-agent reinforcement learning (MARL) offer a way toaddress this issue from an optimisation perspective, where agents strive tomaximise their utility, eliminating the need for manual rule specification.This learning-focused approach aligns with established economic and financialmodels through the use of rational utility-maximising agents. However, thisrepresentation departs from the fundamental motivation for ABMs: that realisticdynamics emerging from bounded rationality and agent heterogeneity can bemodelled. To resolve this apparent disparity between the two approaches, wepropose a novel technique for representing heterogeneous processing-constrainedagents within a MARL framework. The proposed approach treats agents asconstrained optimisers with varying degrees of strategic skills, permittingdeparture from strict utility maximisation. Behaviour is learnt throughrepeated simulations with policy gradients to adjust action likelihoods. Toallow efficient computation, we use parameterised shared policy learning withdistributions of agent skill levels. Shared policy learning avoids the need foragents to learn individual policies yet still enables a spectrum of boundedrational behaviours. We validate our model's effectiveness using real-worlddata on a range of canonical $n$-agent settings, demonstrating significantlyimproved predictive capability.</description><author>Benjamin Patrick Evans, Sumitra Ganesh</author><pubDate>Thu, 01 Feb 2024 17:21:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00787v1</guid></item><item><title>Emergence and Causality in Complex Systems: A Survey on Causal Emergence and Related Quantitative Studies</title><link>http://arxiv.org/abs/2312.16815v2</link><description>Emergence and causality are two fundamental concepts for understandingcomplex systems. They are interconnected. On one hand, emergence refers to thephenomenon where macroscopic properties cannot be solely attributed to thecause of individual properties. On the other hand, causality can exhibitemergence, meaning that new causal laws may arise as we increase the level ofabstraction. Causal emergence theory aims to bridge these two concepts and evenemploys measures of causality to quantify emergence. This paper provides acomprehensive review of recent advancements in quantitative theories andapplications of causal emergence. Two key problems are addressed: quantifyingcausal emergence and identifying it in data. Addressing the latter requires theuse of machine learning techniques, thus establishing a connection betweencausal emergence and artificial intelligence. We highlighted that thearchitectures used for identifying causal emergence are shared by causalrepresentation learning, causal model abstraction, and world model-basedreinforcement learning. Consequently, progress in any of these areas canbenefit the others. Potential applications and future perspectives are alsodiscussed in the final section of the review.</description><author>Bing Yuan, Zhang Jiang, Aobo Lyu, Jiayun Wu, Zhipeng Wang, Mingzhe Yang, Kaiwei Liu, Muyun Mou, Peng Cui</author><pubDate>Thu, 01 Feb 2024 17:20:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16815v2</guid></item><item><title>CroissantLLM: A Truly Bilingual French-English Language Model</title><link>http://arxiv.org/abs/2402.00786v1</link><description>We introduce CroissantLLM, a 1.3B language model pretrained on a set of 3TEnglish and French tokens, to bring to the research and industrial community ahigh-performance, fully open-sourced bilingual model that runs swiftly onconsumer-grade local hardware. To that end, we pioneer the approach of trainingan intrinsically bilingual model with a 1:1 English-to-French pretraining dataratio, a custom tokenizer, and bilingual finetuning datasets. We release thetraining dataset, notably containing a French split with manually curated,high-quality, and varied data sources. To assess performance outside ofEnglish, we craft a novel benchmark, FrenchBench, consisting of an array ofclassification and generation tasks, covering various orthogonal aspects ofmodel performance in the French Language. Additionally, rooted in transparencyand to foster further Large Language Model research, we release codebases, anddozens of checkpoints across various model sizes, training data distributions,and training steps, as well as fine-tuned Chat models, and strong translationmodels. We evaluate our model through the FMTI framework, and validate 81 % ofthe transparency criteria, far beyond the scores of even most open initiatives.This work enriches the NLP landscape, breaking away from previousEnglish-centric work in order to strengthen our understanding ofmultilinguality in language models.</description><author>Manuel Faysse, Patrick Fernandes, Nuno Guerreiro, António Loison, Duarte Alves, Caio Corro, Nicolas Boizard, João Alves, Ricardo Rei, Pedro Martins, Antoni Bigata Casademunt, François Yvon, André Martins, Gautier Viaud, Céline Hudelot, Pierre Colombo</author><pubDate>Thu, 01 Feb 2024 17:17:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00786v1</guid></item><item><title>Dense Reward for Free in Reinforcement Learning from Human Feedback</title><link>http://arxiv.org/abs/2402.00782v1</link><description>Reinforcement Learning from Human Feedback (RLHF) has been credited as thekey advance that has allowed Large Language Models (LLMs) to effectively followinstructions and produce useful assistance. Classically, this involvesgenerating completions from the LLM in response to a query before using aseparate reward model to assign a score to the full completion. As anauto-regressive process, the LLM has to take many "actions" (selectingindividual tokens) and only receives a single, sparse reward at the end of anepisode, a setup that is known to be difficult to optimise in traditionalreinforcement learning. In this work we leverage the fact that the reward modelcontains more information than just its scalar output, in particular, itcalculates an attention map over tokens as part of the transformerarchitecture. We use these attention weights to redistribute the reward alongthe whole completion, effectively densifying the signal and highlighting themost important tokens, all without incurring extra computational cost orrequiring any additional modelling. We demonstrate that, theoretically, thisapproach is equivalent to potential-based reward shaping, ensuring that theoptimal policy remains unchanged. Empirically, we show that it stabilisestraining, accelerates the rate of learning, and, in practical cases, may leadto better local optima.</description><author>Alex J. Chan, Hao Sun, Samuel Holt, Mihaela van der Schaar</author><pubDate>Thu, 01 Feb 2024 17:10:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00782v1</guid></item><item><title>Hybrid Quantum Vision Transformers for Event Classification in High Energy Physics</title><link>http://arxiv.org/abs/2402.00776v1</link><description>Models based on vision transformer architectures are consideredstate-of-the-art when it comes to image classification tasks. However, theyrequire extensive computational resources both for training and deployment. Theproblem is exacerbated as the amount and complexity of the data increases.Quantum-based vision transformer models could potentially alleviate this issueby reducing the training and operating time while maintaining the samepredictive power. Although current quantum computers are not yet able toperform high-dimensional tasks yet, they do offer one of the most efficientsolutions for the future. In this work, we construct several variations of aquantum hybrid vision transformer for a classification problem in high energyphysics (distinguishing photons and electrons in the electromagneticcalorimeter). We test them against classical vision transformer architectures.Our findings indicate that the hybrid models can achieve comparable performanceto their classical analogues with a similar number of parameters.</description><author>Eyup B. Unlu, Marçal Comajoan Cara, Gopal Ramesh Dahale, Zhongtian Dong, Roy T. Forestano, Sergei Gleyzer, Daniel Justice, Kyoungchul Kong, Tom Magorsch, Konstantin T. Matchev, Katia Matcheva</author><pubDate>Thu, 01 Feb 2024 17:05:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00776v1</guid></item><item><title>Mesh motion in fluid-structure interaction with deep operator networks</title><link>http://arxiv.org/abs/2402.00774v1</link><description>A mesh motion model based on deep operator networks is presented. The modelis trained on and evaluated against a biharmonic mesh motion model on afluid-structure interaction benchmark problem and further evaluated in asetting where biharmonic mesh motion fails. The performance of the proposedmesh motion model is comparable to the biharmonic mesh motion on the testproblems.</description><author>Ottar Hellan</author><pubDate>Thu, 01 Feb 2024 17:04:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00774v1</guid></item><item><title>Integrating Generative AI in Hackathons: Opportunities, Challenges, and Educational Implications</title><link>http://arxiv.org/abs/2401.17434v2</link><description>Hackathons and software competitions, increasingly pivotal in the softwareindustry, serve as vital catalysts for innovation and skill development forboth organizations and students. These platforms enable companies to prototypeideas swiftly, while students gain enriched learning experiences, enhancingtheir practical skills. Over the years, hackathons have transitioned from merecompetitive events to significant educational tools, fusing theoreticalknowledge with real-world problem-solving. The integration of hackathons intocomputer science and software engineering curricula aims to align educationalproficiencies within a collaborative context, promoting peer connectivity andenriched learning via industry-academia collaborations. However, the infusionof advanced technologies, notably artificial intelligence (AI), and machinelearning, into hackathons is revolutionizing their structure and outcomes. Thisevolution brings forth both opportunities, like enhanced learning experiences,and challenges, such as ethical concerns. This study delves into the impact ofgenerative AI, examining its influence on student's technological choices basedon a case study on the University of Iowa 2023 event. The exploration providesinsights into AI's role in hackathons, and its educational implications, andoffers a roadmap for the integration of such technologies in future events,ensuring innovation is balanced with ethical and educational considerations.</description><author>Ramteja Sajja, Carlos Erazo Ramirez, Zhouyayan Li, Bekir Z. Demiray, Yusuf Sermet, Ibrahim Demir</author><pubDate>Thu, 01 Feb 2024 16:59:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17434v2</guid></item><item><title>AnimateLCM: Accelerating the Animation of Personalized Diffusion Models and Adapters with Decoupled Consistency Learning</title><link>http://arxiv.org/abs/2402.00769v1</link><description>Video diffusion models has been gaining increasing attention for its abilityto produce videos that are both coherent and of high fidelity. However, theiterative denoising process makes it computationally intensive andtime-consuming, thus limiting its applications. Inspired by the ConsistencyModel (CM) that distills pretrained image diffusion models to accelerate thesampling with minimal steps and its successful extension Latent ConsistencyModel (LCM) on conditional image generation, we propose AnimateLCM, allowingfor high-fidelity video generation within minimal steps. Instead of directlyconducting consistency learning on the raw video dataset, we propose adecoupled consistency learning strategy that decouples the distillation ofimage generation priors and motion generation priors, which improves thetraining efficiency and enhance the generation visual quality. Additionally, toenable the combination of plug-and-play adapters in stable diffusion communityto achieve various functions (e.g., ControlNet for controllable generation). wepropose an efficient strategy to adapt existing adapters to our distilledtext-conditioned video consistency model or train adapters from scratch withoutharming the sampling speed. We validate the proposed strategy inimage-conditioned video generation and layout-conditioned video generation, allachieving top-performing results. Experimental results validate theeffectiveness of our proposed method. Code and weights will be made public.More details are available at https://github.com/G-U-N/AnimateLCM.</description><author>Fu-Yun Wang, Zhaoyang Huang, Xiaoyu Shi, Weikang Bian, Guanglu Song, Yu Liu, Hongsheng Li</author><pubDate>Thu, 01 Feb 2024 16:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00769v1</guid></item><item><title>Probability-Generating Function Kernels for Spherical Data</title><link>http://arxiv.org/abs/2112.00365v2</link><description>Probability-generating function (PGF) kernels are introduced, whichconstitute a class of kernels supported on the unit hypersphere, for thepurposes of spherical data analysis. PGF kernels generalize RBF kernels in thecontext of spherical data. The properties of PGF kernels are studied. Asemi-parametric learning algorithm is introduced to enable the use of PGFkernels with spherical data.</description><author>Theodore Papamarkou, Alexey Lindo</author><pubDate>Thu, 01 Feb 2024 16:58:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.00365v2</guid></item><item><title>360-GS: Layout-guided Panoramic Gaussian Splatting For Indoor Roaming</title><link>http://arxiv.org/abs/2402.00763v1</link><description>3D Gaussian Splatting (3D-GS) has recently attracted great attention withreal-time and photo-realistic renderings. This technique typically takesperspective images as input and optimizes a set of 3D elliptical Gaussians bysplatting them onto the image planes, resulting in 2D Gaussians. However,applying 3D-GS to panoramic inputs presents challenges in effectively modelingthe projection onto the spherical surface of ${360^\circ}$ images using 2DGaussians. In practical applications, input panoramas are often sparse, leadingto unreliable initialization of 3D Gaussians and subsequent degradation of3D-GS quality. In addition, due to the under-constrained geometry oftexture-less planes (e.g., walls and floors), 3D-GS struggles to model theseflat regions with elliptical Gaussians, resulting in significant floaters innovel views. To address these issues, we propose 360-GS, a novel $360^{\circ}$Gaussian splatting for a limited set of panoramic inputs. Instead of splatting3D Gaussians directly onto the spherical surface, 360-GS projects them onto thetangent plane of the unit sphere and then maps them to the sphericalprojections. This adaptation enables the representation of the projection usingGaussians. We guide the optimization of 360-GS by exploiting layout priorswithin panoramas, which are simple to obtain and contain strong structuralinformation about the indoor scene. Our experimental results demonstrate that360-GS allows panoramic rendering and outperforms state-of-the-art methods withfewer artifacts in novel view synthesis, thus providing immersive roaming inindoor scenarios.</description><author>Jiayang Bai, Letian Huang, Jie Guo, Wen Gong, Yuanqi Li, Yanwen Guo</author><pubDate>Thu, 01 Feb 2024 16:52:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00763v1</guid></item><item><title>Generative quantum machine learning via denoising diffusion probabilistic models</title><link>http://arxiv.org/abs/2310.05866v3</link><description>Deep generative models are key-enabling technology to computer vision, textgeneration and large language models. Denoising diffusion probabilistic models(DDPMs) have recently gained much attention due to their ability to generatediverse and high-quality samples in many computer vision tasks, as well as toincorporate flexible model architectures and relatively simple training scheme.Quantum generative models, empowered by entanglement and superposition, havebrought new insight to learning classical and quantum data. Inspired by theclassical counterpart, we propose the \emph{quantum denoising diffusionprobabilistic model} (QuDDPM) to enable efficiently trainable generativelearning of quantum data. QuDDPM adopts sufficient layers of circuits toguarantee expressivity, while introduces multiple intermediate training tasksas interpolation between the target distribution and noise to avoid barrenplateau and guarantee efficient training. We provide bounds on the learningerror and demonstrate QuDDPM's capability in learning correlated quantum noisemodel, quantum many-body phases and topological structure of quantum data. Theresults provide a paradigm for versatile and efficient quantum generativelearning.</description><author>Bingzhi Zhang, Peng Xu, Xiaohui Chen, Quntao Zhuang</author><pubDate>Thu, 01 Feb 2024 16:52:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05866v3</guid></item><item><title>Control-Theoretic Techniques for Online Adaptation of Deep Neural Networks in Dynamical Systems</title><link>http://arxiv.org/abs/2402.00761v1</link><description>Deep neural networks (DNNs), trained with gradient-based optimization andbackpropagation, are currently the primary tool in modern artificialintelligence, machine learning, and data science. In many applications, DNNsare trained offline, through supervised learning or reinforcement learning, anddeployed online for inference. However, training DNNs with standardbackpropagation and gradient-based optimization gives no intrinsic performanceguarantees or bounds on the DNN, which is essential for applications such ascontrols. Additionally, many offline-training and online-inference problems,such as sim2real transfer of reinforcement learning policies, experience domainshift from the training distribution to the real-world distribution. To addressthese stability and transfer learning issues, we propose using techniques fromcontrol theory to update DNN parameters online. We formulate thefully-connected feedforward DNN as a continuous-time dynamical system, and wepropose novel last-layer update laws that guarantee desirable error convergenceunder various conditions on the time derivative of the DNN input vector. Wefurther show that training the DNN under spectral normalization controls theupper bound of the error trajectories of the online DNN predictions, which isdesirable when numerically differentiated quantities or noisy statemeasurements are input to the DNN. The proposed online DNN adaptation laws arevalidated in simulation to learn the dynamics of the Van der Pol system underdomain shift, where parameters are varied in inference from the trainingdataset. The simulations demonstrate the effectiveness of usingcontrol-theoretic techniques to derive performance improvements and guaranteesin DNN-based learning systems.</description><author>Jacob G. Elkins, Farbod Fahimi</author><pubDate>Thu, 01 Feb 2024 16:51:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00761v1</guid></item><item><title>EuroPED-NN: Uncertainty aware surrogate model</title><link>http://arxiv.org/abs/2402.00760v1</link><description>This work successfully generates uncertainty aware surrogate models, via theBayesian neural network with noise contrastive prior (BNN-NCP) technique, ofthe EuroPED plasma pedestal model using data from the JET-ILW pedestal databaseand subsequent model evaluations. All this conform EuroPED-NN. The BNN-NCPtechnique is proven to be a good fit for uncertainty aware surrogate models,matching the output results as a regular neural network, providing prediction'sconfidence as uncertainties, and highlighting the out of distribution (OOD)regions using surrogate model uncertainties. This provides critical insightsinto model robustness and reliability. EuroPED-NN has been physicallyvalidated, first, analyzing electron density$n_e\!\left(\psi_{\text{pol}}=0.94\right)$ with respect to increasing plasmacurrent, $I_p$, and second, validating the $\Delta-\beta_{p,ped}$ relationassociated with the EuroPED model. Affirming the robustness of the underlyingphysics learned by the surrogate model.</description><author>A. Panera Alvarez, A. Ho, A. Jarvinen, S. Saarelma, S. Wiesen, JET Contributors</author><pubDate>Thu, 01 Feb 2024 16:50:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00760v1</guid></item><item><title>Emergent Dominance Hierarchies in Reinforcement Learning Agents</title><link>http://arxiv.org/abs/2401.12258v2</link><description>Modern Reinforcement Learning (RL) algorithms are able to outperform humansin a wide variety of tasks. Multi-agent reinforcement learning (MARL) settingspresent additional challenges, and successful cooperation in mixed-motivegroups of agents depends on a delicate balancing act between individual andgroup objectives. Social conventions and norms, often inspired by humaninstitutions, are used as tools for striking this balance. In this paper, we examine a fundamental, well-studied social convention thatunderlies cooperation in both animal and human societies: dominancehierarchies. We adapt the ethological theory of dominance hierarchies to artificialagents, borrowing the established terminology and definitions with as fewamendments as possible. We demonstrate that populations of RL agents, operatingwithout explicit programming or intrinsic rewards, can invent, learn, enforce,and transmit a dominance hierarchy to new populations. The dominancehierarchies that emerge have a similar structure to those studied in chickens,mice, fish, and other species.</description><author>Ram Rachum, Yonatan Nakar, Bill Tomlinson, Nitay Alon, Reuth Mirsky</author><pubDate>Thu, 01 Feb 2024 16:50:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12258v2</guid></item><item><title>Building Expressive and Tractable Probabilistic Generative Models: A Review</title><link>http://arxiv.org/abs/2402.00759v1</link><description>We present a comprehensive survey of the advancements and techniques in thefield of tractable probabilistic generative modeling, primarily focusing onProbabilistic Circuits (PCs). We provide a unified perspective on the inherenttrade-offs between expressivity and the tractability, highlighting the designprinciples and algorithmic extensions that have enabled building expressive andefficient PCs, and provide a taxonomy of the field. We also discuss recentefforts to build deep and hybrid PCs by fusing notions from deep neural models,and outline the challenges and open questions that can guide future research inthis evolving field.</description><author>Sahil Sidheekh, Sriraam Natarajan</author><pubDate>Thu, 01 Feb 2024 16:49:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00759v1</guid></item><item><title>Machine learning for sports betting: should model selection be based on accuracy or calibration?</title><link>http://arxiv.org/abs/2303.06021v4</link><description>Sports betting's recent federal legalisation in the USA coincides with thegolden age of machine learning. If bettors can leverage data to reliablypredict the probability of an outcome, they can recognise when the bookmaker'sodds are in their favour. As sports betting is a multi-billion dollar industryin the USA alone, identifying such opportunities could be extremely lucrative.Many researchers have applied machine learning to the sports outcome predictionproblem, generally using accuracy to evaluate the performance of predictivemodels. We hypothesise that for the sports betting problem, model calibrationis more important than accuracy. To test this hypothesis, we train models onNBA data over several seasons and run betting experiments on a single season,using published odds. We show that using calibration, rather than accuracy, asthe basis for model selection leads to greater returns, on average (return oninvestment of $+34.69\%$ versus $-35.17\%$) and in the best case ($+36.93\%$versus $+5.56\%$). These findings suggest that for sports betting (or anyprobabilistic decision-making problem), calibration is a more important metricthan accuracy. Sports bettors who wish to increase profits should thereforeselect their predictive model based on calibration, rather than accuracy.</description><author>Conor Walsh, Alok Joshi</author><pubDate>Thu, 01 Feb 2024 16:45:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06021v4</guid></item><item><title>GS++: Error Analyzing and Optimal Gaussian Splatting</title><link>http://arxiv.org/abs/2402.00752v1</link><description>3D Gaussian Splatting has garnered extensive attention and application inreal-time neural rendering. Concurrently, concerns have been raised about thelimitations of this technology in aspects such as point cloud storage,performance , and robustness in sparse viewpoints , leading to variousimprovements. However, there has been a notable lack of attention to theprojection errors introduced by the local affine approximation inherent in thesplatting itself, and the consequential impact of these errors on the qualityof photo-realistic rendering. This paper addresses the projection errorfunction of 3D Gaussian Splatting, commencing with the residual error from thefirst-order Taylor expansion of the projection function $\phi$. The analysisestablishes a correlation between the error and the Gaussian mean position.Subsequently, leveraging function optimization theory, this paper analyzes thefunction's minima to provide an optimal projection strategy for GaussianSplatting referred to Optimal Gaussian Splatting. Experimental validationfurther confirms that this projection methodology reduces artifacts, resultingin a more convincingly realistic rendering.</description><author>Letian Huang, Jiayang Bai, Jie Guo, Yanwen Guo</author><pubDate>Thu, 01 Feb 2024 16:43:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00752v1</guid></item><item><title>Unlearnable Algorithms for In-context Learning</title><link>http://arxiv.org/abs/2402.00751v1</link><description>Machine unlearning is a desirable operation as models get increasinglydeployed on data with unknown provenance. However, achieving exact unlearning-- obtaining a model that matches the model distribution when the data to beforgotten was never used -- is challenging or inefficient, often requiringsignificant retraining. In this paper, we focus on efficient unlearning methodsfor the task adaptation phase of a pretrained large language model (LLM). Weobserve that an LLM's ability to do in-context learning for task adaptationallows for efficient exact unlearning of task adaptation training data. Weprovide an algorithm for selecting few-shot training examples to prepend to theprompt given to an LLM (for task adaptation), ERASE, whose unlearning operationcost is independent of model and dataset size, meaning it scales to largemodels and datasets. We additionally compare our approach to fine-tuningapproaches and discuss the trade-offs between the two approaches. This leads usto propose a new holistic measure of unlearning cost which accounts for varyinginference costs, and conclude that in-context learning can often be morefavourable than fine-tuning for deployments involving unlearning requests.</description><author>Andrei Muresanu, Anvith Thudi, Michael R. Zhang, Nicolas Papernot</author><pubDate>Thu, 01 Feb 2024 16:43:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00751v1</guid></item><item><title>On the Second-Order Convergence of Biased Policy Gradient Algorithms</title><link>http://arxiv.org/abs/2311.02546v3</link><description>Since the objective functions of reinforcement learning problems aretypically highly nonconvex, it is desirable that policy gradient, the mostpopular algorithm, escapes saddle points and arrives at second-order stationarypoints. Existing results only consider vanilla policy gradient algorithms withunbiased gradient estimators, but practical implementations under theinfinite-horizon discounted reward setting are biased due to finite-horizonsampling. Moreover, actor-critic methods, whose second-order convergence hasnot yet been established, are also biased due to the critic approximation ofthe value function. We provide a novel second-order analysis of biased policygradient methods, including the vanilla gradient estimator computed fromMonte-Carlo sampling of trajectories as well as the double-loop actor-criticalgorithm, where in the inner loop the critic improves the approximation of thevalue function via TD(0) learning. Separately, we also establish theconvergence of TD(0) on Markov chains irrespective of initial statedistribution.</description><author>Siqiao Mu, Diego Klabjan</author><pubDate>Thu, 01 Feb 2024 16:42:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02546v3</guid></item><item><title>Fast Cerebral Blood Flow Analysis via Extreme Learning Machine</title><link>http://arxiv.org/abs/2401.05578v3</link><description>We introduce a rapid and precise analytical approach for analyzing cerebralblood flow (CBF) using Diffuse Correlation Spectroscopy (DCS) with theapplication of the Extreme Learning Machine (ELM). Our evaluation of ELM andexisting algorithms involves a comprehensive set of metrics. We assess thesealgorithms using synthetic datasets for both semi-infinite and multi-layermodels. The results demonstrate that ELM consistently achieves higher fidelityacross various noise levels and optical parameters, showcasing robustgeneralization ability and outperforming iterative fitting algorithms. Througha comparison with a computationally efficient neural network, ELM attainscomparable accuracy with reduced training and inference times. Notably, theabsence of a back-propagation process in ELM during training results insignificantly faster training speeds compared to existing neural networkapproaches. This proposed strategy holds promise for edge computingapplications with online training capabilities.</description><author>Xi Chen, Zhenya Zang, Xingda Li</author><pubDate>Thu, 01 Feb 2024 16:42:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05578v3</guid></item><item><title>Health-LLM: Personalized Retrieval-Augmented Disease Prediction Model</title><link>http://arxiv.org/abs/2402.00746v1</link><description>Artificial intelligence (AI) in healthcare has significantly advancedintelligent medical treatment. However, traditional intelligent healthcare islimited by static data and unified standards, preventing full integration withindividual situations and other challenges. Hence, a more professional anddetailed intelligent healthcare method is needed for development. To this end,we propose an innovative framework named Heath-LLM, which combines large-scalefeature extraction and medical knowledge trade-off scoring. Compared totraditional health management methods, our approach has three main advantages.First, our method integrates health reports into a large model to providedetailed task information. Second, professional medical expertise is used toadjust the weighted scores of health characteristics. Third, we use asemi-automated feature extraction framework to enhance the analytical power oflanguage models and incorporate expert insights to improve the accuracy ofdisease prediction. We have conducted disease prediction experiments on a largenumber of health reports to assess the effectiveness of Health-LLM. The resultsof the experiments indicate that the proposed method surpasses traditionalmethods and has the potential to revolutionize disease prediction andpersonalized health management. The code is available athttps://github.com/jmyissb/HealthLLM.</description><author>Mingyu Jin, Qinkai Yu, Chong Zhang, Dong Shu, Suiyuan Zhu, Mengnan Du, Yongfeng Zhang, Yanda Meng</author><pubDate>Thu, 01 Feb 2024 16:40:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00746v1</guid></item><item><title>Enhancing Ethical Explanations of Large Language Models through Iterative Symbolic Refinement</title><link>http://arxiv.org/abs/2402.00745v1</link><description>An increasing amount of research in Natural Language Inference (NLI) focuseson the application and evaluation of Large Language Models (LLMs) and theirreasoning capabilities. Despite their success, however, LLMs are still prone tofactual errors and inconsistencies in their explanations, offering limitedcontrol and interpretability for inference in complex domains. In this paper,we focus on ethical NLI, investigating how hybrid neuro-symbolic techniques canenhance the logical validity and alignment of ethical explanations produced byLLMs. Specifically, we present an abductive-deductive framework namedLogic-Explainer, which integrates LLMs with an external backward-chainingsolver to refine step-wise natural language explanations and jointly verifytheir correctness, reduce incompleteness and minimise redundancy. An extensiveempirical analysis demonstrates that Logic-Explainer can improve explanationsgenerated via in-context learning methods and Chain-of-Thought (CoT) onchallenging ethical NLI tasks, while, at the same time, producing formal proofsdescribing and supporting models' reasoning. As ethical NLI requirescommonsense reasoning to identify underlying moral violations, our resultssuggest the effectiveness of neuro-symbolic methods for multi-step NLI morebroadly, opening new opportunities to enhance the logical consistency,reliability, and alignment of LLMs.</description><author>Xin Quan, Marco Valentino, Louise A. Dennis, André Freitas</author><pubDate>Thu, 01 Feb 2024 16:39:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00745v1</guid></item><item><title>BATON: Aligning Text-to-Audio Model with Human Preference Feedback</title><link>http://arxiv.org/abs/2402.00744v1</link><description>With the development of AI-Generated Content (AIGC), text-to-audio models aregaining widespread attention. However, it is challenging for these models togenerate audio aligned with human preference due to the inherent informationdensity of natural language and limited model understanding ability. Toalleviate this issue, we formulate the BATON, a framework designed to enhancethe alignment between generated audio and text prompt using human preferencefeedback. Our BATON comprises three key stages: Firstly, we curated a datasetcontaining both prompts and the corresponding generated audio, which was thenannotated based on human feedback. Secondly, we introduced a reward model usingthe constructed dataset, which can mimic human preference by assigning rewardsto input text-audio pairs. Finally, we employed the reward model to fine-tunean off-the-shelf text-to-audio model. The experiment results demonstrate thatour BATON can significantly improve the generation quality of the originaltext-to-audio models, concerning audio integrity, temporal relationship, andalignment with human preference.</description><author>Huan Liao, Haonan Han, Kai Yang, Tianjiao Du, Rui Yang, Zunnan Xu, Qinmei Xu, Jingquan Liu, Jiasheng Lu, Xiu Li</author><pubDate>Thu, 01 Feb 2024 16:39:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00744v1</guid></item><item><title>Benefits of Transformer: In-Context Learning in Linear Regression Tasks with Unstructured Data</title><link>http://arxiv.org/abs/2402.00743v1</link><description>In practice, it is observed that transformer-based models can learn conceptsin context in the inference stage. While existing literature, e.g.,\citet{zhang2023trained,huang2023context}, provide theoretical explanations onthis in-context learning ability, they assume the input $x_i$ and the output$y_i$ for each sample are embedded in the same token (i.e., structured data).However, in reality, they are presented in two tokens (i.e., unstructured data\cite{wibisono2023role}). In this case, this paper conducts experiments inlinear regression tasks to study the benefits of the architecture oftransformers and provides some corresponding theoretical intuitions to explainwhy the transformer can learn from unstructured data. We study the exactcomponents in a transformer that facilitate the in-context learning. Inparticular, we observe that (1) a transformer with two layers of softmax(self-)attentions with look-ahead attention mask can learn from the prompt if$y_i$ is in the token next to $x_i$ for each example; (2) positional encodingcan further improve the performance; and (3) multi-head attention with a highinput embedding dimension has a better prediction performance than single-headattention.</description><author>Yue Xing, Xiaofeng Lin, Namjoon Suh, Qifan Song, Guang Cheng</author><pubDate>Thu, 01 Feb 2024 16:39:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00743v1</guid></item><item><title>Transforming and Combining Rewards for Aligning Large Language Models</title><link>http://arxiv.org/abs/2402.00742v1</link><description>A common approach for aligning language models to human preferences is tofirst learn a reward model from preference data, and then use this reward modelto update the language model. We study two closely related problems that arisein this approach. First, any monotone transformation of the reward modelpreserves preference ranking; is there a choice that is ``better'' than others?Second, we often wish to align language models to multiple properties: howshould we combine multiple reward models? Using a probabilistic interpretationof the alignment procedure, we identify a natural choice for transformation for(the common case of) rewards learned from Bradley-Terry preference models. Thisderived transformation has two important properties. First, it emphasizesimproving poorly-performing outputs, rather than outputs that already scorewell. This mitigates both underfitting (where some prompts are not improved)and reward hacking (where the model learns to exploit misspecification of thereward model). Second, it enables principled aggregation of rewards by linkingsummation to logical conjunction: the sum of transformed rewards corresponds tothe probability that the output is ``good'' in all measured properties, in asense we make precise. Experiments aligning language models to be both helpfuland harmless using RLHF show substantial improvements over the baseline(non-transformed) approach.</description><author>Zihao Wang, Chirag Nagpal, Jonathan Berant, Jacob Eisenstein, Alex D'Amour, Sanmi Koyejo, Victor Veitch</author><pubDate>Thu, 01 Feb 2024 16:39:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00742v1</guid></item><item><title>DRSM: efficient neural 4d decomposition for dynamic reconstruction in stationary monocular cameras</title><link>http://arxiv.org/abs/2402.00740v1</link><description>With the popularity of monocular videos generated by video sharing and livebroadcasting applications, reconstructing and editing dynamic scenes instationary monocular cameras has become a special but anticipated technology.In contrast to scene reconstructions that exploit multi-view observations, theproblem of modeling a dynamic scene from a single view is significantly moreunder-constrained and ill-posed. Inspired by recent progress in neuralrendering, we present a novel framework to tackle 4D decomposition problem fordynamic scenes in monocular cameras. Our framework utilizes decomposed staticand dynamic feature planes to represent 4D scenes and emphasizes the learningof dynamic regions through dense ray casting. Inadequate 3D clues from asingle-view and occlusion are also particular challenges in scenereconstruction. To overcome these difficulties, we propose deep supervisedoptimization and ray casting strategies. With experiments on various videos,our method generates higher-fidelity results than existing methods forsingle-view dynamic scene representation.</description><author>Weixing Xie, Xiao Dong, Yong Yang, Qiqin Lin, Jingze Chen, Junfeng Yao, Xiaohu Guo</author><pubDate>Thu, 01 Feb 2024 16:38:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00740v1</guid></item><item><title>Identifiability of Direct Effects from Summary Causal Graphs</title><link>http://arxiv.org/abs/2306.16958v3</link><description>Dynamic structural causal models (SCMs) are a powerful framework forreasoning in dynamic systems about direct effects which measure how a change inone variable affects another variable while holding all other variablesconstant. The causal relations in a dynamic structural causal model can bequalitatively represented with an acyclic full-time causal graph. Assuminglinearity and no hidden confounding and given the full-time causal graph, thedirect causal effect is always identifiable. However, in many application sucha graph is not available for various reasons but nevertheless experts haveaccess to the summary causal graph of the full-time causal graph whichrepresents causal relations between time series while omitting temporalinformation and allowing cycles. This paper presents a complete identifiabilityresult which characterizes all cases for which the direct effect is graphicallyidentifiable from a summary causal graph and gives two sound finite adjustmentsets that can be used to estimate the direct effect whenever it isidentifiable.</description><author>Simon Ferreira, Charles K. Assaad</author><pubDate>Thu, 01 Feb 2024 16:38:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16958v3</guid></item><item><title>FM3Q: Factorized Multi-Agent MiniMax Q-Learning for Two-Team Zero-Sum Markov Game</title><link>http://arxiv.org/abs/2402.00738v1</link><description>Many real-world applications involve some agents that fall into two teams,with payoffs that are equal within the same team but of opposite sign acrossthe opponent team. The so-called two-team zero-sum Markov games (2t0sMGs) canbe resolved with reinforcement learning in recent years. However, existingmethods are thus inefficient in light of insufficient consideration ofintra-team credit assignment, data utilization and computationalintractability. In this paper, we propose the individual-global-minimax (IGMM)principle to ensure the coherence between two-team minimax behaviors and theindividual greedy behaviors through Q functions in 2t0sMGs. Based on it, wepresent a novel multi-agent reinforcement learning framework, FactorizedMulti-Agent MiniMax Q-Learning (FM3Q), which can factorize the joint minimax Qfunction into individual ones and iteratively solve for the IGMM-satisfiedminimax Q functions for 2t0sMGs. Moreover, an online learning algorithm withneural networks is proposed to implement FM3Q and obtain the deterministic anddecentralized minimax policies for two-team players. A theoretical analysis isprovided to prove the convergence of FM3Q. Empirically, we use threeenvironments to evaluate the learning efficiency and final performance of FM3Qand show its superiority on 2t0sMGs.</description><author>Guangzheng Hu, Yuanheng Zhu, Haoran Li, Dongbin Zhao</author><pubDate>Thu, 01 Feb 2024 16:37:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00738v1</guid></item><item><title>Enhancing Blood Flow Assessment in Diffuse Correlation Spectroscopy: A Transfer Learning Approach with Noise Robustness Analysis</title><link>http://arxiv.org/abs/2401.05580v3</link><description>Diffuse correlation spectroscopy (DCS) is an emerging noninvasive techniquethat measures the tissue blood flow, by using near-infrared coherentpoint-source illumination to detect spectral changes. While machine learninghas demonstrated significant potential for measuring blood flow index (BFi), anopen question concerning the success of this approach pertains to itsrobustness in scenarios involving deviations between datasets with varyingSignal-to-Noise Ratios (SNRs) originating from diverse clinical applicationsand various setups. This study proposes a transfer learning approach, aims toassess the influence of SNRs on the generalization ability of learned features,and demonstrate the robustness for transfer learning. A synthetic dataset withvarying levels of added noise is utilized to simulate different SNRs. Theproposed network takes a 1x64 autocorrelation curve as input and generates BFiand the correlation parameter beta. The proposed model demonstrates excellentperformance across different SNRs, exhibiting enhanced fitting accuracy,particularly for low SNR datasets when compared with other fitting methods.This highlights its potential for clinical diagnosis and treatment acrossvarious scenarios under different clinical setups.</description><author>Xi Chen, Xingda Li</author><pubDate>Thu, 01 Feb 2024 16:36:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05580v3</guid></item><item><title>DP-SGD with weight clipping</title><link>http://arxiv.org/abs/2310.18001v2</link><description>Recently, due to the popularity of deep neural networks and other methodswhose training typically relies on the optimization of an objective function,and due to concerns for data privacy, there is a lot of interest indifferentially private gradient descent methods. To achieve differentialprivacy guarantees with a minimum amount of noise, it is important to be ableto bound precisely the sensitivity of the information which the participantswill observe. In this study, we present a novel approach that mitigates thebias arising from traditional gradient clipping. By leveraging a public upperbound of the Lipschitz value of the current model and its current locationwithin the search domain, we can achieve refined noise level adjustments. Wepresent a new algorithm with improved differential privacy guarantees and asystematic empirical evaluation, showing that our new approach outperformsexisting approaches also in practice.</description><author>Antoine Barczewski, Jan Ramon</author><pubDate>Thu, 01 Feb 2024 16:36:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18001v2</guid></item><item><title>CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots</title><link>http://arxiv.org/abs/2307.11865v3</link><description>This work explores the capacity of large language models (LLMs) to addressproblems at the intersection of spatial planning and natural languageinterfaces for navigation. We focus on following complex instructions that aremore akin to natural conversation than traditional explicit proceduraldirectives typically seen in robotics. Unlike most prior work where navigationdirectives are provided as simple imperative commands (e.g., "go to thefridge"), we examine implicit directives obtained through conversationalinteractions.We leverage the 3D simulator AI2Thor to create household queryscenarios at scale, and augment it by adding complex language queries for 40object types. We demonstrate that a robot using our method CARTIER(Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots)can parse descriptive language queries up to 42% more reliably than existingLLM-enabled methods by exploiting the ability of LLMs to interpret the userinteraction in the context of the objects in the scenario.</description><author>Dmitriy Rivkin, Nikhil Kakodkar, Francois Hogan, Bobak H. Baghi, Gregory Dudek</author><pubDate>Thu, 01 Feb 2024 16:32:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11865v3</guid></item><item><title>MobilityDL: A Review of Deep Learning From Trajectory Data</title><link>http://arxiv.org/abs/2402.00732v1</link><description>Trajectory data combines the complexities of time series, spatial data, and(sometimes irrational) movement behavior. As data availability and computingpower have increased, so has the popularity of deep learning from trajectorydata. This review paper provides the first comprehensive overview of deeplearning approaches for trajectory data. We have identified eight specificmobility use cases which we analyze with regards to the deep learning modelsand the training data used. Besides a comprehensive quantitative review of theliterature since 2018, the main contribution of our work is the data-centricanalysis of recent work in this field, placing it along the mobility datacontinuum which ranges from detailed dense trajectories of individual movers(quasi-continuous tracking data), to sparse trajectories (such as check-indata), and aggregated trajectories (crowd information).</description><author>Anita Graser, Anahid Jalali, Jasmin Lampert, Axel Weißenfeld, Krzysztof Janowicz</author><pubDate>Thu, 01 Feb 2024 16:30:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00732v1</guid></item><item><title>Dropout-Based Rashomon Set Exploration for Efficient Predictive Multiplicity Estimation</title><link>http://arxiv.org/abs/2402.00728v1</link><description>Predictive multiplicity refers to the phenomenon in which classificationtasks may admit multiple competing models that achieve almost-equally-optimalperformance, yet generate conflicting outputs for individual samples. Thispresents significant concerns, as it can potentially result in systemicexclusion, inexplicable discrimination, and unfairness in practicalapplications. Measuring and mitigating predictive multiplicity, however, iscomputationally challenging due to the need to explore all suchalmost-equally-optimal models, known as the Rashomon set, in potentially hugehypothesis spaces. To address this challenge, we propose a novel framework thatutilizes dropout techniques for exploring models in the Rashomon set. Weprovide rigorous theoretical derivations to connect the dropout parameters toproperties of the Rashomon set, and empirically evaluate our framework throughextensive experimentation. Numerical results show that our techniqueconsistently outperforms baselines in terms of the effectiveness of predictivemultiplicity metric estimation, with runtime speedup up to $20\times \sim5000\times$. With efficient Rashomon set exploration and metric estimation,mitigation of predictive multiplicity is then achieved through dropout ensembleand model selection.</description><author>Hsiang Hsu, Guihong Li, Shaohan Hu, Chun-Fu, Chen</author><pubDate>Thu, 01 Feb 2024 16:25:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00728v1</guid></item><item><title>Automatic Segmentation of the Spinal Cord Nerve Rootlets</title><link>http://arxiv.org/abs/2402.00724v1</link><description>Precise identification of spinal nerve rootlets is relevant to delineatespinal levels for the study of functional activity in the spinal cord. The goalof this study was to develop an automatic method for the semantic segmentationof spinal nerve rootlets from T2-weighted magnetic resonance imaging (MRI)scans. Images from two open-access MRI datasets were used to train a 3Dmulti-class convolutional neural network using an active learning approach tosegment C2-C8 dorsal nerve rootlets. Each output class corresponds to a spinallevel. The method was tested on 3T T2-weighted images from datasets unseenduring training to assess inter-site, inter-session, and inter-resolutionvariability. The test Dice score was 0.67 +- 0.16 (mean +- standard deviationacross rootlets levels), suggesting a good performance. The method alsodemonstrated low inter-vendor and inter-site variability (coefficient ofvariation &lt;= 1.41 %), as well as low inter-session variability (coefficient ofvariation &lt;= 1.30 %) indicating stable predictions across different MRIvendors, sites, and sessions. The proposed methodology is open-source andreadily available in the Spinal Cord Toolbox (SCT) v6.2 and higher.</description><author>Jan Valosek, Theo Mathieu, Raphaelle Schlienger, Olivia S. Kowalczyk, Julien Cohen-Adad</author><pubDate>Thu, 01 Feb 2024 16:14:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00724v1</guid></item><item><title>Improving Semantic Control in Discrete Latent Spaces with Transformer Quantized Variational Autoencoders</title><link>http://arxiv.org/abs/2402.00723v1</link><description>Achieving precise semantic control over the latent spaces of VariationalAutoEncoders (VAEs) holds significant value for downstream tasks in NLP as theunderlying generative mechanisms could be better localised, explained andimproved upon. Recent research, however, has struggled to achieve consistentresults, primarily due to the inevitable loss of semantic information in thevariational bottleneck and limited control over the decoding mechanism. Toovercome these challenges, we investigate discrete latent spaces in VectorQuantized Variational AutoEncoders (VQVAEs) to improve semantic control andgeneration in Transformer-based VAEs. In particular, We propose T5VQVAE, anovel model that leverages the controllability of VQVAEs to guide theself-attention mechanism in T5 at the token-level, exploiting its fullgeneralization capabilities. Experimental results indicate that T5VQVAEoutperforms existing state-of-the-art VAE models, including Optimus, in termsof controllability and preservation of semantic information across differenttasks such as auto-encoding of sentences and mathematical expressions, texttransfer, and inference. Moreover, T5VQVAE exhibits improved inferencecapabilities, suggesting potential applications for downstream natural languageand symbolic reasoning tasks.</description><author>Yingji Zhang, Danilo S. Carvalho, Marco Valentino, Ian Pratt-Hartmann, Andre Freitas</author><pubDate>Thu, 01 Feb 2024 16:14:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00723v1</guid></item><item><title>Neural Style Transfer with Twin-Delayed DDPG for Shared Control of Robotic Manipulators</title><link>http://arxiv.org/abs/2402.00722v1</link><description>Neural Style Transfer (NST) refers to a class of algorithms able tomanipulate an element, most often images, to adopt the appearance or style ofanother one. Each element is defined as a combination of Content and Style: theContent can be conceptually defined as the what and the Style as the how ofsaid element. In this context, we propose a custom NST framework fortransferring a set of styles to the motion of a robotic manipulator, e.g., thesame robotic task can be carried out in an angry, happy, calm, or sad way. Anautoencoder architecture extracts and defines the Content and the Style of thetarget robot motions. A Twin Delayed Deep Deterministic Policy Gradient (TD3)network generates the robot control policy using the loss defined by theautoencoder. The proposed Neural Policy Style Transfer TD3 (NPST3) alters therobot motion by introducing the trained style. Such an approach can beimplemented either offline, for carrying out autonomous robot motions indynamic environments, or online, for adapting at runtime the style of ateleoperated robot. The considered styles can be learned online from humandemonstrations. We carried out an evaluation with human subjects enrolling 73volunteers, asking them to recognize the style behind some representativerobotic motions. Results show a good recognition rate, proving that it ispossible to convey different styles to a robot using this approach.</description><author>Raul Fernandez-Fernandez, Marco Aggravi, Paolo Robuffo Giordano, Juan G. Victores, Claudio Pacchierotti</author><pubDate>Thu, 01 Feb 2024 16:14:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00722v1</guid></item><item><title>Intent Assurance using LLMs guided by Intent Drift</title><link>http://arxiv.org/abs/2402.00715v1</link><description>Intent-Based Networking (IBN) presents a paradigm shift for networkmanagement, by promising to align intents and business objectives with networkoperations--in an automated manner. However, its practical realization ischallenging: 1) processing intents, i.e., translate, decompose and identify thelogic to fulfill the intent, and 2) intent conformance, that is, consideringdynamic networks, the logic should be adequately adapted to assure intents. Toaddress the latter, intent assurance is tasked with continuous verification andvalidation, including taking the necessary actions to align the operational andtarget states. In this paper, we define an assurance framework that allows usto detect and act when intent drift occurs. To do so, we leverage AI-drivenpolicies, generated by Large Language Models (LLMs) which can quickly learn thenecessary in-context requirements, and assist with the fulfillment andassurance of intents.</description><author>Kristina Dzeparoska, Ali Tizghadam, Alberto Leon-Garcia</author><pubDate>Thu, 01 Feb 2024 16:09:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00715v1</guid></item><item><title>ChaosBench: A Multi-Channel, Physics-Based Benchmark for Subseasonal-to-Seasonal Climate Prediction</title><link>http://arxiv.org/abs/2402.00712v1</link><description>Accurate prediction of climate in the subseasonal-to-seasonal scale iscrucial for disaster readiness, reduced economic risk, and improvedpolicy-making amidst climate change. Yet, S2S prediction remains challengingdue to the chaotic nature of the system. At present, existing benchmarks forweather and climate applications, tend to (1) have shorter forecasting range ofup-to 14 days, (2) do not include a wide range of operational baselineforecasts, and (3) lack physics-based constraints for explainability. Thus, wepropose ChaosBench, a large-scale, multi-channel, physics-based benchmark forS2S prediction. ChaosBench has over 460K frames of real-world observations andsimulations, each with 60 variable-channels and spanning for up-to 45 years. Wealso propose several physics-based, in addition to vision-based metrics, thatenables for a more physically-consistent model. Furthermore, we include adiverse set of physics-based forecasts from 4 national weather agencies asbaselines to our data-driven counterpart. We establish two tasks that vary incomplexity: full and sparse dynamics prediction. Our benchmark is one of thefirst to perform large-scale evaluation on existing models includingPanguWeather, FourCastNetV2, GraphCast, and ClimaX, and finds methodsoriginally developed for weather-scale applications fails on S2S task. Werelease our benchmark code and datasets athttps://leap-stc.github.io/ChaosBench.</description><author>Juan Nathaniel, Yongquan Qu, Tung Nguyen, Sungduk Yu, Julius Busecke, Aditya Grover, Pierre Gentine</author><pubDate>Thu, 01 Feb 2024 16:07:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00712v1</guid></item><item><title>Explaining Text Classifiers with Counterfactual Representations</title><link>http://arxiv.org/abs/2402.00711v1</link><description>One well motivated explanation method for classifiers leveragescounterfactuals which are hypothetical events identical to real observations inall aspects except for one categorical feature. Constructing suchcounterfactual poses specific challenges for texts, however, as some attributevalues may not necessarily align with plausible real-world events. In thispaper we propose a simple method for generating counterfactuals by interveningin the space of text representations which bypasses this limitation. We arguethat our interventions are minimally disruptive and that they are theoreticallysound as they align with counterfactuals as defined in Pearl's causal inferenceframework. To validate our method, we first conduct experiments on a syntheticdataset of counterfactuals, allowing for a direct comparison between classifierpredictions based on ground truth counterfactuals (obtained through explicittext interventions) and our counterfactuals, derived through interventions inthe representation space. Second, we study a real world scenario where ourcounterfactuals can be leveraged both for explaining a classifier and for biasmitigation.</description><author>Pirmin Lemberger, Antoine Saillenfest</author><pubDate>Thu, 01 Feb 2024 16:06:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00711v1</guid></item><item><title>Online Graph Topology Learning from Matrix-valued Time Series</title><link>http://arxiv.org/abs/2107.08020v3</link><description>This paper is concerned with the statistical analysis of matrix-valued timeseries. These are data collected over a network of sensors (typically a set ofspatial locations) along time, where a vector of features is observed per timeinstant per sensor. Thus each sensor is characterized by a vectorial timeseries. We would like to identify the dependency structure among these sensorsand represent it by a graph. When there is only one feature per sensor, thevector auto-regressive models have been widely adapted to infer the structureof Granger causality. The resulting graph is referred to as causal graph. Ourfirst contribution is then extending VAR models to matrix-variate models toserve the purpose of graph learning. Secondly, we propose two online proceduresrespectively in low and high dimensions, which can update quickly the estimatesof coefficients when new samples arrive. In particular in high dimensionalregime, a novel Lasso-type is introduced and we develop its homotopy algorithmsfor the online learning. We also provide an adaptive tuning procedure for theregularization parameter. Lastly, we consider that, the application of ARmodels onto data usually requires detrending the raw data, however, this stepis forbidden in online context. Therefore, we augment the proposed AR models byincorporating trend as extra parameter, and then adapt the online algorithms tothe augmented data models, which allow us to simultaneously learn the graph andtrend from streaming samples. In this work, we consider primarily the periodictrend. Numerical experiments using both synthetic and real data are performed,whose results support the effectiveness of the proposed methods.</description><author>Yiye Jiang, Jérémie Bigot, Sofian Maabout</author><pubDate>Thu, 01 Feb 2024 16:05:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.08020v3</guid></item><item><title>Breaking the Communication-Privacy-Accuracy Tradeoff with $f$-Differential Privacy</title><link>http://arxiv.org/abs/2302.09624v3</link><description>We consider a federated data analytics problem in which a server coordinatesthe collaborative data analysis of multiple users with privacy concerns andlimited communication capability. The commonly adopted compression schemesintroduce information loss into local data while improving communicationefficiency, and it remains an open problem whether such discrete-valuedmechanisms provide any privacy protection. In this paper, we study the localdifferential privacy guarantees of discrete-valued mechanisms with finiteoutput space through the lens of $f$-differential privacy (DP). Morespecifically, we advance the existing literature by deriving tight $f$-DPguarantees for a variety of discrete-valued mechanisms, including the binomialnoise and the binomial mechanisms that are proposed for privacy preservation,and the sign-based methods that are proposed for data compression, inclosed-form expressions. We further investigate the amplification in privacy bysparsification and propose a ternary stochastic compressor. By leveragingcompression for privacy amplification, we improve the existing methods byremoving the dependency of accuracy (in terms of mean square error) oncommunication cost in the popular use case of distributed mean estimation,therefore breaking the three-way tradeoff between privacy, communication, andaccuracy. Finally, we discuss the Byzantine resilience of the proposedmechanism and its application in federated learning.</description><author>Richeng Jin, Zhonggen Su, Caijun Zhong, Zhaoyang Zhang, Tony Quek, Huaiyu Dai</author><pubDate>Thu, 01 Feb 2024 16:04:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.09624v3</guid></item><item><title>Non-Exchangeable Conformal Language Generation with Nearest Neighbors</title><link>http://arxiv.org/abs/2402.00707v1</link><description>Quantifying uncertainty in automatically generated text is important forletting humans check potential hallucinations and making systems more reliable.Conformal prediction is an attractive framework to provide predictions imbuedwith statistical guarantees, however, its application to text generation ischallenging since any i.i.d. assumptions are not realistic. In this paper, webridge this gap by leveraging recent results on non-exchangeable conformalprediction, which still ensures bounds on coverage. The result,non-exchangeable conformal nucleus sampling, is a novel extension of theconformal prediction framework to generation based on nearest neighbors. Ourmethod can be used post-hoc for an arbitrary model without extra training andsupplies token-level, calibrated prediction sets equipped with statisticalguarantees. Experiments in machine translation and language modeling showencouraging results in generation quality. By also producing tighter predictionsets with good coverage, we thus give a more theoretically principled way toperform sampling with conformal guarantees.</description><author>Dennis Ulmer, Chrysoula Zerva, André F. T. Martins</author><pubDate>Thu, 01 Feb 2024 16:04:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00707v1</guid></item><item><title>Combining the Strengths of Dutch Survey and Register Data in a Data Challenge to Predict Fertility (PreFer)</title><link>http://arxiv.org/abs/2402.00705v1</link><description>The social sciences have produced an impressive body of research ondeterminants of fertility outcomes, or whether and when people have children.However, the strength of these determinants and underlying theories are rarelyevaluated on their predictive ability on new data. This prevents us fromsystematically comparing studies, hindering the evaluation and accumulation ofknowledge. In this paper, we present two datasets which can be used to studythe predictability of fertility outcomes in the Netherlands. One dataset isbased on the LISS panel, a longitudinal survey which includes thousands ofvariables on a wide range of topics, including individual preferences andvalues. The other is based on the Dutch register data which lacks attitudinaldata but includes detailed information about the life courses of millions ofDutch residents. We provide information about the datasets and the samples, anddescribe the fertility outcome of interest. We also introduce the fertilityprediction data challenge PreFer which is based on these datasets and willstart in Spring 2024. We outline the ways in which measuring the predictabilityof fertility outcomes using these datasets and combining their strengths in thedata challenge can advance our understanding of fertility behaviour andcomputational social science. We further provide details for participants onhow to take part in the data challenge.</description><author>Elizaveta Sivak, Paulina Pankowska, Adrienne Mendrik, Tom Emery, Javier Garcia-Bernardo, Seyit Hocuk, Kasia Karpinska, Angelica Maineri, Joris Mulder, Malvina Nissim, Gert Stulp</author><pubDate>Thu, 01 Feb 2024 16:00:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00705v1</guid></item><item><title>Multi-Relational Hyperbolic Word Embeddings from Natural Language Definitions</title><link>http://arxiv.org/abs/2305.07303v2</link><description>Natural language definitions possess a recursive, self-explanatory semanticstructure that can support representation learning methods able to preserveexplicit conceptual relations and constraints in the latent space. This paperpresents a multi-relational model that explicitly leverages such a structure toderive word embeddings from definitions. By automatically extracting therelations linking defined and defining terms from dictionaries, we demonstratehow the problem of learning word embeddings can be formalised via atranslational framework in Hyperbolic space and used as a proxy to capture theglobal semantic structure of definitions. An extensive empirical analysisdemonstrates that the framework can help imposing the desired structuralconstraints while preserving the semantic mapping required for controllable andinterpretable traversal. Moreover, the experiments reveal the superiority ofthe Hyperbolic word embeddings over the Euclidean counterparts and demonstratethat the multi-relational approach can obtain competitive results when comparedto state-of-the-art neural models, with the advantage of being intrinsicallymore efficient and interpretable.</description><author>Marco Valentino, Danilo S. Carvalho, André Freitas</author><pubDate>Thu, 01 Feb 2024 16:00:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07303v2</guid></item><item><title>Vehicle Perception from Satellite</title><link>http://arxiv.org/abs/2402.00703v1</link><description>Satellites are capable of capturing high-resolution videos. It makes vehicleperception from satellite become possible. Compared to street surveillance,drive recorder or other equipments, satellite videos provide a much broadercity-scale view, so that the global dynamic scene of the traffic are capturedand displayed. Traffic monitoring from satellite is a new task with greatpotential applications, including traffic jams prediction, path planning,vehicle dispatching, \emph{etc.}. Practically, limited by the resolution andview, the captured vehicles are very tiny (a few pixels) and move slowly. Worsestill, these satellites are in Low Earth Orbit (LEO) to capture suchhigh-resolution videos, so the background is also moving. Under thiscircumstance, traffic monitoring from the satellite view is an extremelychallenging task. To attract more researchers into this field, we build alarge-scale benchmark for traffic monitoring from satellite. It supportsseveral tasks, including tiny object detection, counting and densityestimation. The dataset is constructed based on 12 satellite videos and 14synthetic videos recorded from GTA-V. They are separated into 408 video clips,which contain 7,336 real satellite images and 1,960 synthetic images. 128,801vehicles are annotated totally, and the number of vehicles in each image variesfrom 0 to 101. Several classic and state-of-the-art approaches in traditionalcomputer vision are evaluated on the datasets, so as to compare the performanceof different approaches, analyze the challenges in this task, and discuss thefuture prospects. The dataset is available at:https://github.com/Chenxi1510/Vehicle-Perception-from-Satellite-Videos.</description><author>Bin Zhao, Pengfei Han, Xuelong Li</author><pubDate>Thu, 01 Feb 2024 15:59:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00703v1</guid></item><item><title>In-Bed Pose Estimation: A Review</title><link>http://arxiv.org/abs/2402.00700v1</link><description>Human pose estimation, the process of identifying joint positions in aperson's body from images or videos, represents a widely utilized technologyacross diverse fields, including healthcare. One such healthcare applicationinvolves in-bed pose estimation, where the body pose of an individual lyingunder a blanket is analyzed. This task, for instance, can be used to monitor aperson's sleep behavior and detect symptoms early for potential diseasediagnosis in homes and hospitals. Several studies have utilized unimodal andmultimodal methods to estimate in-bed human poses. The unimodal studiesgenerally employ RGB images, whereas the multimodal studies use modalitiesincluding RGB, long-wavelength infrared, pressure map, and depth map.Multimodal studies have the advantage of using modalities in addition to RGBthat might capture information useful to cope with occlusions. Moreover, somemultimodal studies exclude RGB and, this way, better suit privacy preservation.To expedite advancements in this domain, we conduct a review of existingdatasets and approaches. Our objectives are to show the limitations of theprevious studies, current challenges, and provide insights for future works onthe in-bed human pose estimation field.</description><author>Ziya Ata Yazıcı, Sara Colantonio, Hazım Kemal Ekenel</author><pubDate>Thu, 01 Feb 2024 15:57:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00700v1</guid></item><item><title>PeaTMOSS: A Dataset and Initial Analysis of Pre-Trained Models in Open-Source Software</title><link>http://arxiv.org/abs/2402.00699v1</link><description>The development and training of deep learning models have become increasinglycostly and complex. Consequently, software engineers are adopting pre-trainedmodels (PTMs) for their downstream applications. The dynamics of the PTM supplychain remain largely unexplored, signaling a clear need for structured datasetsthat document not only the metadata but also the subsequent applications ofthese models. Without such data, the MSR community cannot comprehensivelyunderstand the impact of PTM adoption and reuse. This paper presents thePeaTMOSS dataset, which comprises metadata for 281,638 PTMs and detailedsnapshots for all PTMs with over 50 monthly downloads (14,296 PTMs), along with28,575 open-source software repositories from GitHub that utilize these models.Additionally, the dataset includes 44,337 mappings from 15,129 downstreamGitHub repositories to the 2,530 PTMs they use. To enhance the dataset'scomprehensiveness, we developed prompts for a large language model toautomatically extract model metadata, including the model's training datasets,parameters, and evaluation metrics. Our analysis of this dataset provides thefirst summary statistics for the PTM supply chain, showing the trend of PTMdevelopment and common shortcomings of PTM package documentation. Our exampleapplication reveals inconsistencies in software licenses across PTMs and theirdependent projects. PeaTMOSS lays the foundation for future research, offeringrich opportunities to investigate the PTM supply chain. We outline miningopportunities on PTMs, their downstream usage, and cross-cutting questions.</description><author>Wenxin Jiang, Jerin Yasmin, Jason Jones, Nicholas Synovic, Jiashen Kuo, Nathaniel Bielanski, Yuan Tian, George K. Thiruvathukal, James C. Davis</author><pubDate>Thu, 01 Feb 2024 15:55:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00699v1</guid></item></channel></rss>