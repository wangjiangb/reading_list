<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 22 Jun 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Benchmarking and Analyzing 3D-aware Image Synthesis with a Modularized Codebase</title><link>http://arxiv.org/abs/2306.12423v1</link><description>Despite the rapid advance of 3D-aware image synthesis, existing studiesusually adopt a mixture of techniques and tricks, leaving it unclear how eachpart contributes to the final performance in terms of generality. Following themost popular and effective paradigm in this field, which incorporates a neuralradiance field (NeRF) into the generator of a generative adversarial network(GAN), we build a well-structured codebase, dubbed Carver, through modularizingthe generation process. Such a design allows researchers to develop and replaceeach module independently, and hence offers an opportunity to fairly comparevarious approaches and recognize their contributions from the moduleperspective. The reproduction of a range of cutting-edge algorithmsdemonstrates the availability of our modularized codebase. We also perform avariety of in-depth analyses, such as the comparison across different types ofpoint feature, the necessity of the tailing upsampler in the generator, thereliance on the camera pose prior, etc., which deepen our understanding ofexisting methods and point out some further directions of the research work. Werelease code and models at https://github.com/qiuyu96/Carver to facilitate thedevelopment and evaluation of this field.</description><author>Qiuyu Wang, Zifan Shi, Kecheng Zheng, Yinghao Xu, Sida Peng, Yujun Shen</author><pubDate>Wed, 21 Jun 2023 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12423v1</guid></item><item><title>VisoGender: A dataset for benchmarking gender bias in image-text pronoun resolution</title><link>http://arxiv.org/abs/2306.12424v1</link><description>We introduce VisoGender, a novel dataset for benchmarking gender bias invision-language models. We focus on occupation-related gender biases, inspiredby Winograd and Winogender schemas, where each image is associated with acaption containing a pronoun relationship of subjects and objects in the scene.VisoGender is balanced by gender representation in professional roles,supporting bias evaluation in two ways: i) resolution bias, where we evaluatethe difference between gender resolution accuracies for men and women and ii)retrieval bias, where we compare ratios of male and female professionalsretrieved for a gender-neutral search query. We benchmark severalstate-of-the-art vision-language models and find that they lack the reasoningabilities to correctly resolve gender in complex scenes. While the directionand magnitude of gender bias depends on the task and the model being evaluated,captioning models generally are more accurate and less biased than CLIP-likemodels. Dataset and code are available at https://github.com/oxai/visogender</description><author>Siobhan Mackenzie Hall, Fernanda Gon√ßalves Abrantes, Hanwen Zhu, Grace Sodunke, Aleksandar Shtedritski, Hannah Rose Kirk</author><pubDate>Wed, 21 Jun 2023 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12424v1</guid></item><item><title>DreamTime: An Improved Optimization Strategy for Text-to-3D Content Creation</title><link>http://arxiv.org/abs/2306.12422v1</link><description>Text-to-image diffusion models pre-trained on billions of image-text pairshave recently enabled text-to-3D content creation by optimizing a randomlyinitialized Neural Radiance Fields (NeRF) with score distillation. However, theresultant 3D models exhibit two limitations: (a) quality concerns such assaturated color and the Janus problem; (b) extremely low diversity comparing totext-guided image synthesis. In this paper, we show that the conflict betweenNeRF optimization process and uniform timestep sampling in score distillationis the main reason for these limitations. To resolve this conflict, we proposeto prioritize timestep sampling with monotonically non-increasing functions,which aligns NeRF optimization with the sampling process of diffusion model.Extensive experiments show that our simple redesign significantly improvestext-to-3D content creation with higher quality and diversity.</description><author>Yukun Huang, Jianan Wang, Yukai Shi, Xianbiao Qi, Zheng-Jun Zha, Lei Zhang</author><pubDate>Wed, 21 Jun 2023 18:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12422v1</guid></item><item><title>LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models</title><link>http://arxiv.org/abs/2306.12420v1</link><description>Large foundation models have demonstrated a great ability to achieve generalhuman-level intelligence far beyond traditional approaches. As the techniquekeeps attracting attention from the AI community, more and more largefoundation models have become publically available. However, most of thosemodels exhibit a major deficiency in specialized-task applications, where thestep of finetuning is still required for obtaining satisfactory performance. Asthe number of available models and specialized tasks keeps growing, the job ofgeneral finetuning becomes highly nontrivial. In this paper, we take the firststep to address this issue. We introduce an extensible and lightweight toolkit,LMFlow, which aims to simplify the finetuning and inference of general largefoundation models. LMFlow offers a complete finetuning workflow for a largefoundation model to support personalized training with limited computingresources. Furthermore, it supports continuous pretraining, instruction tuning,parameter-efficient finetuning, alignment tuning, and large model inference,along with carefully designed and extensible APIs. This toolkit has beenthoroughly tested and is available at https://github.com/OptimalScale/LMFlow.</description><author>Shizhe Diao, Rui Pan, Hanze Dong, Ka Shun Shum, Jipeng Zhang, Wei Xiong, Tong Zhang</author><pubDate>Wed, 21 Jun 2023 18:58:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12420v1</guid></item><item><title>The False Dawn: Reevaluating Google's Reinforcement Learning for Chip Macro Placement</title><link>http://arxiv.org/abs/2306.09633v3</link><description>Reinforcement learning (RL) for physical design of silicon chips in a Google2021 Nature paper stirred controversy due to poorly documented claims thatraised eyebrows and attracted critical media coverage. The Nature paperwithheld most inputs needed to produce reported results and some critical stepsin the methodology. But two separate evaluations filled in the gaps anddemonstrated that Google RL lags behind human designers, behind a well-knownalgorithm (Simulated Annealing), and also behind generally-available commercialsoftware. Crosschecked data indicate that the integrity of the Nature paper issubstantially undermined owing to errors in the conduct, analysis andreporting.</description><author>Igor L. Markov</author><pubDate>Wed, 21 Jun 2023 18:53:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09633v3</guid></item><item><title>Addressing Discontinuous Root-Finding for Subsequent Differentiability in Machine Learning, Inverse Problems, and Control</title><link>http://arxiv.org/abs/2306.12413v1</link><description>There are many physical processes that have inherent discontinuities in theirmathematical formulations. This paper is motivated by the specific case ofcollisions between two rigid or deformable bodies and the intrinsic nature ofthat discontinuity. The impulse response to a collision is discontinuous withthe lack of any response when no collision occurs, which causes difficultiesfor numerical approaches that require differentiability which are typical inmachine learning, inverse problems, and control. We theoretically andnumerically demonstrate that the derivative of the collision time with respectto the parameters becomes infinite as one approaches the barrier separatingcolliding from not colliding, and use lifting to complexify the solution spaceso that solutions on the other side of the barrier are directly attainable asprecise values. Subsequently, we mollify the barrier posed by the unboundedderivatives, so that one can tunnel back and forth in a smooth and reliablefashion facilitating the use of standard numerical approaches. Moreover, weillustrate that standard approaches fail in numerous ways mostly due to a lackof understanding of the mathematical nature of the problem (e.g. typicalbackpropagation utilizes many rules of differentiation, but ignores L'Hopital'srule).</description><author>Daniel Johnson, Ronald Fedkiw</author><pubDate>Wed, 21 Jun 2023 18:51:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12413v1</guid></item><item><title>PATCorrect: Non-autoregressive Phoneme-augmented Transformer for ASR Error Correction</title><link>http://arxiv.org/abs/2302.05040v2</link><description>Speech-to-text errors made by automatic speech recognition (ASR) systemsnegatively impact downstream models. Error correction models as apost-processing text editing method have been recently developed for refiningthe ASR outputs. However, efficient models that meet the low latencyrequirements of industrial grade production systems have not been well studied.We propose PATCorrect-a novel non-autoregressive (NAR) approach based onmulti-modal fusion leveraging representations from both text and phonememodalities, to reduce word error rate (WER) and perform robustly with varyinginput transcription quality. We demonstrate that PATCorrect consistentlyoutperforms state-of-the-art NAR method on English corpus across differentupstream ASR systems, with an overall 11.62% WER reduction (WERR) compared to9.46% WERR achieved by other methods using text only modality. Besides, itsinference latency is at tens of milliseconds, making it ideal for systems withlow latency requirements.</description><author>Ziji Zhang, Zhehui Wang, Rajesh Kamma, Sharanya Eswaran, Narayanan Sadagopan</author><pubDate>Wed, 21 Jun 2023 18:44:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.05040v2</guid></item><item><title>Timely Asynchronous Hierarchical Federated Learning: Age of Convergence</title><link>http://arxiv.org/abs/2306.12400v1</link><description>We consider an asynchronous hierarchical federated learning (AHFL) settingwith a client-edge-cloud framework. The clients exchange the trained parameterswith their corresponding edge servers, which update the locally aggregatedmodel. This model is then transmitted to all the clients in the local cluster.The edge servers communicate to the central cloud server for global modelaggregation. The goal of each client is to converge to the global model, whilemaintaining timeliness of the clients, i.e., having optimum training iterationtime. We investigate the convergence criteria for such a system with denseclusters. Our analysis shows that for a system of $n$ clients with fixedaverage timeliness, the convergence in finite time is probabilisticallyguaranteed, if the nodes are divided into $O(1)$ number of clusters, that is,if the system is built as a sparse set of edge servers with dense client baseseach.</description><author>Purbesh Mitra, Sennur Ulukus</author><pubDate>Wed, 21 Jun 2023 18:39:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12400v1</guid></item><item><title>Multi-Task Consistency for Active Learning</title><link>http://arxiv.org/abs/2306.12398v1</link><description>Learning-based solutions for vision tasks require a large amount of labeledtraining data to ensure their performance and reliability. In single-taskvision-based settings, inconsistency-based active learning has proven to beeffective in selecting informative samples for annotation. However, there is alack of research exploiting the inconsistency between multiple tasks inmulti-task networks. To address this gap, we propose a novel multi-task activelearning strategy for two coupled vision tasks: object detection and semanticsegmentation. Our approach leverages the inconsistency between them to identifyinformative samples across both tasks. We propose three constraints thatspecify how the tasks are coupled and introduce a method for determining thepixels belonging to the object detected by a bounding box, to later quantifythe constraints as inconsistency scores. To evaluate the effectiveness of ourapproach, we establish multiple baselines for multi-task active learning andintroduce a new metric, mean Detection Segmentation Quality (mDSQ), tailoredfor the multi-task active learning comparison that addresses the performance ofboth tasks. We conduct extensive experiments on the nuImages and A9 datasets,demonstrating that our approach outperforms existing state-of-the-art methodsby up to 3.4% mDSQ on nuImages. Our approach achieves 95% of the fully-trainedperformance using only 67% of the available data, corresponding to 20% fewerlabels compared to random selection and 5% fewer labels compared tostate-of-the-art selection strategy. Our code will be made publicly availableafter the review process.</description><author>Aral Hekimoglu, Philipp Friedrich, Walter Zimmer, Michael Schmidt, Alvaro Marcos-Ramiro, Alois C. Knoll</author><pubDate>Wed, 21 Jun 2023 18:34:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12398v1</guid></item><item><title>ChemCrow: Augmenting large-language models with chemistry tools</title><link>http://arxiv.org/abs/2304.05376v4</link><description>Over the last decades, excellent computational chemistry tools have beendeveloped. Their full potential has not yet been reached as most arechallenging to learn and exist in isolation. Recently, large-language models(LLMs) have shown strong performance in tasks across domains, but struggle withchemistry-related problems. Moreover, these models lack access to externalknowledge sources, limiting their usefulness in scientific applications. Inthis study, we introduce ChemCrow, an LLM chemistry agent designed toaccomplish tasks across organic synthesis, drug discovery, and materialsdesign. By integrating 17 expert-designed tools, ChemCrow augments the LLMperformance in chemistry, and new capabilities emerge. Our agent autonomouslyplanned the syntheses of an insect repellent, three organocatalysts, as well asother relevant molecules. Our evaluation, including both LLM and expertassessments, demonstrates ChemCrow's effectiveness in automating a diverse setof chemical tasks. Surprisingly, we find that GPT-4 as an evaluator cannotdistinguish between clearly wrong GPT-4 completions and Chemcrow's performance.There is a significant risk of misuse of tools like ChemCrow, and we discusstheir potential harms. Employed responsibly, our work not only aids expertchemists and lowers barriers for non-experts, but also fosters scientificadvancement by bridging the gap between experimental and computationalchemistry. A subset of the code is publicly available at\url{https://github.com/ur-whitelab/chemcrow-public}.</description><author>Andres M Bran, Sam Cox, Andrew D White, Philippe Schwaller</author><pubDate>Wed, 21 Jun 2023 18:28:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05376v4</guid></item><item><title>One-shot Imitation Learning via Interaction Warping</title><link>http://arxiv.org/abs/2306.12392v1</link><description>Imitation learning of robot policies from few demonstrations is crucial inopen-ended applications. We propose a new method, Interaction Warping, forlearning SE(3) robotic manipulation policies from a single demonstration. Weinfer the 3D mesh of each object in the environment using shape warping, atechnique for aligning point clouds across object instances. Then, we representmanipulation actions as keypoints on objects, which can be warped with theshape of the object. We show successful one-shot imitation learning on threesimulated and real-world object re-arrangement tasks. We also demonstrate theability of our method to predict object meshes and robot grasps in the wild.</description><author>Ondrej Biza, Skye Thompson, Kishore Reddy Pagidi, Abhinav Kumar, Elise van der Pol, Robin Walters, Thomas Kipf, Jan-Willem van de Meent, Lawson L. S. Wong, Robert Platt</author><pubDate>Wed, 21 Jun 2023 18:26:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12392v1</guid></item><item><title>Improving Software Requirements Prioritization through the Lens of Constraint Solving</title><link>http://arxiv.org/abs/2306.12391v1</link><description>Requirements prioritization is a critical activity during the early softwaredevelopment process, which produces a set of key requirements to implement. Theprioritization process offers a parity among the requirements based on multiplecharacteristics, including end-users' preferences, cost to implement, andtechnical dependencies. This paper presents an interactive method torequirements prioritization that leverages the pairwise comparisons and aconstraint solver. Our method employs an interactive accumulation of knowledgefrom the requirements analyst when the relative priority among the requirementscannot be determined based on the existing knowledge from the requirementsdocuments. The final ranking of the requirements is produced via the constraintsolver and interactive pairwise comparisons. We evaluate the proposed methodusing the requirements from a real healthcare project. The proposedprioritization method relying on a constraint solver outperformsstate-of-the-art interactive prioritization methods in terms of effectivenessand robustness to analyst's errors.</description><author>Jonathan Winton, Francis Palma</author><pubDate>Wed, 21 Jun 2023 18:24:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12391v1</guid></item><item><title>MARBLE: Music Audio Representation Benchmark for Universal Evaluation</title><link>http://arxiv.org/abs/2306.10548v2</link><description>In the era of extensive intersection between art and Artificial Intelligence(AI), such as image generation and fiction co-creation, AI for music remainsrelatively nascent, particularly in music understanding. This is evident in thelimited work on deep music representations, the scarcity of large-scaledatasets, and the absence of a universal and community-driven benchmark. Toaddress this issue, we introduce the Music Audio Representation Benchmark foruniversaL Evaluation, termed MARBLE. It aims to provide a benchmark for variousMusic Information Retrieval (MIR) tasks by defining a comprehensive taxonomywith four hierarchy levels, including acoustic, performance, score, andhigh-level description. We then establish a unified protocol based on 14 taskson 8 public-available datasets, providing a fair and standard assessment ofrepresentations of all open-sourced pre-trained models developed on musicrecordings as baselines. Besides, MARBLE offers an easy-to-use, extendable, andreproducible suite for the community, with a clear statement on copyrightissues on datasets. Results suggest recently proposed large-scale pre-trainedmusical language models perform the best in most tasks, with room for furtherimprovement. The leaderboard and toolkit repository are published athttps://marble-bm.shef.ac.uk to promote future music AI research.</description><author>Ruibin Yuan, Yinghao Ma, Yizhi Li, Ge Zhang, Xingran Chen, Hanzhi Yin, Le Zhuo, Yiqi Liu, Jiawen Huang, Zeyue Tian, Binyue Deng, Ningzhi Wang, Chenghua Lin, Emmanouil Benetos, Anton Ragni, Norbert Gyenge, Roger Dannenbert, Wenhu Chen, Gus Xia, Wei Xue, Si Liu, Shi Wang, Ruibo Liu, Yike Guo, Jie Fu</author><pubDate>Wed, 21 Jun 2023 18:18:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10548v2</guid></item><item><title>Solving Dialogue Grounding Embodied Task in a Simulated Environment using Further Masked Language Modeling</title><link>http://arxiv.org/abs/2306.12387v1</link><description>Enhancing AI systems with efficient communication skills that align withhuman understanding is crucial for their effective assistance to human users.Proactive initiatives from the system side are needed to discern specificcircumstances and interact aptly with users to solve these scenarios. In thisresearch, we opt for a collective building assignment taken from the Minecraftdataset. Our proposed method employs language modeling to enhance taskunderstanding through state-of-the-art (SOTA) methods using language models.These models focus on grounding multi-modal understandinging and task-orienteddialogue comprehension tasks. This focus aids in gaining insights into how wellthese models interpret and respond to a variety of inputs and tasks. Ourexperimental results provide compelling evidence of the superiority of ourproposed method. This showcases a substantial improvement and points towards apromising direction for future research in this domain.</description><author>Weijie Jack Zhang</author><pubDate>Wed, 21 Jun 2023 18:17:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12387v1</guid></item><item><title>LEAD: Min-Max Optimization from a Physical Perspective</title><link>http://arxiv.org/abs/2010.13846v4</link><description>Adversarial formulations such as generative adversarial networks (GANs) haverekindled interest in two-player min-max games. A central obstacle in theoptimization of such games is the rotational dynamics that hinder theirconvergence. In this paper, we show that game optimization shares dynamicproperties with particle systems subject to multiple forces, and one canleverage tools from physics to improve optimization dynamics. Inspired by thephysical framework, we propose LEAD, an optimizer for min-max games. Next,using Lyapunov stability theory and spectral analysis, we study LEAD'sconvergence properties in continuous and discrete time settings for a class ofquadratic min-max games to demonstrate linear convergence to the Nashequilibrium. Finally, we empirically evaluate our method on synthetic setupsand CIFAR-10 image generation to demonstrate improvements in GAN training.</description><author>Reyhane Askari Hemmat, Amartya Mitra, Guillaume Lajoie, Ioannis Mitliagkas</author><pubDate>Wed, 21 Jun 2023 18:15:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2010.13846v4</guid></item><item><title>$\mathbf{\mathbb{E}^{FWI}}$: Multi-parameter Benchmark Datasets for Elastic Full Waveform Inversion of Geophysical Properties</title><link>http://arxiv.org/abs/2306.12386v1</link><description>Elastic geophysical properties (such as P- and S-wave velocities) are ofgreat importance to various subsurface applications like CO$_2$ sequestrationand energy exploration (e.g., hydrogen and geothermal). Elastic full waveforminversion (FWI) is widely applied for characterizing reservoir properties. Inthis paper, we introduce $\mathbf{\mathbb{E}^{FWI}}$, a comprehensive benchmarkdataset that is specifically designed for elastic FWI.$\mathbf{\mathbb{E}^{FWI}}$ encompasses 8 distinct datasets that cover diversesubsurface geologic structures (flat, curve, faults, etc). The benchmarkresults produced by three different deep learning methods are provided. Incontrast to our previously presented dataset (pressure recordings) for acousticFWI (referred to as OpenFWI), the seismic dataset in$\mathbf{\mathbb{E}^{FWI}}$ has both vertical and horizontal components.Moreover, the velocity maps in $\mathbf{\mathbb{E}^{FWI}}$ incorporate both P-and S-wave velocities. While the multicomponent data and the added S-wavevelocity make the data more realistic, more challenges are introduced regardingthe convergence and computational cost of the inversion. We conductcomprehensive numerical experiments to explore the relationship between P-waveand S-wave velocities in seismic data. The relation between P- and S-wavevelocities provides crucial insights into the subsurface properties such aslithology, porosity, fluid content, etc. We anticipate that$\mathbf{\mathbb{E}^{FWI}}$ will facilitate future research on multiparameterinversions and stimulate endeavors in several critical research topics ofcarbon-zero and new energy exploration. All datasets, codes and relevantinformation can be accessed through our website at https://efwi-lanl.github.io/</description><author>Shihang Feng, Hanchen Wang, Chengyuan Deng, Yinan Feng, Yanhua Liu, Min Zhu, Peng Jin, Yinpeng Chen, Youzuo Lin</author><pubDate>Wed, 21 Jun 2023 18:11:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12386v1</guid></item><item><title>Probing the limit of hydrologic predictability with the Transformer network</title><link>http://arxiv.org/abs/2306.12384v1</link><description>For a number of years since its introduction to hydrology, recurrent neuralnetworks like long short-term memory (LSTM) have proven remarkably difficult tosurpass in terms of daily hydrograph metrics on known, comparable benchmarks.Outside of hydrology, Transformers have now become the model of choice forsequential prediction tasks, making it a curious architecture to investigate.Here, we first show that a vanilla Transformer architecture is not competitiveagainst LSTM on the widely benchmarked CAMELS dataset, and lagged especiallyfor the high-flow metrics due to short-term processes. However, arecurrence-free variant of Transformer can obtain mixed comparisons with LSTM,producing the same Kling-Gupta efficiency coefficient (KGE), along with othermetrics. The lack of advantages for the Transformer is linked to the Markoviannature of the hydrologic prediction problem. Similar to LSTM, the Transformercan also merge multiple forcing dataset to improve model performance. While theTransformer results are not higher than current state-of-the-art, we stilllearned some valuable lessons: (1) the vanilla Transformer architecture is notsuitable for hydrologic modeling; (2) the proposed recurrence-free modificationcan improve Transformer performance so future work can continue to test more ofsuch modifications; and (3) the prediction limits on the dataset should beclose to the current state-of-the-art model. As a non-recurrent model, theTransformer may bear scale advantages for learning from bigger datasets andstoring knowledge. This work serves as a reference point for futuremodifications of the model.</description><author>Jiangtao Liu, Yuchen Bian, Chaopeng Shen</author><pubDate>Wed, 21 Jun 2023 18:06:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12384v1</guid></item><item><title>Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and Optimal Algorithms</title><link>http://arxiv.org/abs/2306.12383v1</link><description>In stochastic zeroth-order optimization, a problem of practical relevance isunderstanding how to fully exploit the local geometry of the underlyingobjective function. We consider a fundamental setting in which the objectivefunction is quadratic, and provide the first tight characterization of theoptimal Hessian-dependent sample complexity. Our contribution is twofold.First, from an information-theoretic point of view, we prove tight lower boundson Hessian-dependent complexities by introducing a concept called energyallocation, which captures the interaction between the searching algorithm andthe geometry of objective functions. A matching upper bound is obtained bysolving the optimal energy spectrum. Then, algorithmically, we show theexistence of a Hessian-independent algorithm that universally achieves theasymptotic optimal sample complexities for all Hessian instances. The optimalsample complexities achieved by our algorithm remain valid for heavy-tailednoise distributions, which are enabled by a truncation method.</description><author>Qian Yu, Yining Wang, Baihe Huang, Qi Lei, Jason D. Lee</author><pubDate>Wed, 21 Jun 2023 18:03:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12383v1</guid></item><item><title>PLay: Parametrically Conditioned Layout Generation using Latent Diffusion</title><link>http://arxiv.org/abs/2301.11529v2</link><description>Layout design is an important task in various design fields, including userinterface, document, and graphic design. As this task requires tedious manualeffort by designers, prior works have attempted to automate this process usinggenerative models, but commonly fell short of providing intuitive user controlsand achieving design objectives. In this paper, we build a conditional latentdiffusion model, PLay, that generates parametrically conditioned layouts invector graphic space from user-specified guidelines, which are commonly used bydesigners for representing their design intents in current practices. Ourmethod outperforms prior works across three datasets on metrics including FIDand FD-VG, and in user study. Moreover, it brings a novel and interactiveexperience to professional layout design processes.</description><author>Chin-Yi Cheng, Forrest Huang, Gang Li, Yang Li</author><pubDate>Wed, 21 Jun 2023 18:02:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11529v2</guid></item><item><title>Back to the Source: Diffusion-Driven Test-Time Adaptation</title><link>http://arxiv.org/abs/2207.03442v2</link><description>Test-time adaptation harnesses test inputs to improve the accuracy of a modeltrained on source data when tested on shifted target data. Existing methodsupdate the source model by (re-)training on each target domain. Whileeffective, re-training is sensitive to the amount and order of the data and thehyperparameters for optimization. We instead update the target data, byprojecting all test inputs toward the source domain with a generative diffusionmodel. Our diffusion-driven adaptation method, DDA, shares its models forclassification and generation across all domains. Both models are trained onthe source domain, then fixed during testing. We augment diffusion with imageguidance and self-ensembling to automatically decide how much to adapt. Inputadaptation by DDA is more robust than prior model adaptation approaches acrossa variety of corruptions, architectures, and data regimes on the ImageNet-Cbenchmark. With its input-wise updates, DDA succeeds where model adaptationdegrades on too little data in small batches, dependent data in non-uniformorder, or mixed data with multiple corruptions.</description><author>Jin Gao, Jialing Zhang, Xihui Liu, Trevor Darrell, Evan Shelhamer, Dequan Wang</author><pubDate>Wed, 21 Jun 2023 17:57:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.03442v2</guid></item><item><title>On the Validation of Gibbs Algorithms: Training Datasets, Test Datasets and their Aggregation</title><link>http://arxiv.org/abs/2306.12380v1</link><description>The dependence on training data of the Gibbs algorithm (GA) is analyticallycharacterized. By adopting the expected empirical risk as the performancemetric, the sensitivity of the GA is obtained in closed form. In this case,sensitivity is the performance difference with respect to an arbitraryalternative algorithm. This description enables the development of explicitexpressions involving the training errors and test errors of GAs trained withdifferent datasets. Using these tools, dataset aggregation is studied anddifferent figures of merit to evaluate the generalization capabilities of GAsare introduced. For particular sizes of such datasets and parameters of theGAs, a connection between Jeffrey's divergence, training and test errors isestablished.</description><author>Samir M. Perlaza, I√±aki Esnaola, Gaetan Bisson, H. Vincent Poor</author><pubDate>Wed, 21 Jun 2023 17:51:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12380v1</guid></item><item><title>Towards mutual synchronization of serially connected Spin Torque Oscillators based on magnetic tunnel junctions</title><link>http://arxiv.org/abs/2306.11608v2</link><description>Multiple neuromorphic applications require the tuning of two or more devicesto a common signal. Various types of neuromorphic computation can be realizedusing spintronic oscillators, where the DC current induces magnetizationprecession, which turns into an AC voltage generator. However, in spintronics,synchronization of two oscillators using a DC signal is still a challengingproblem because it requires a certain degree of similarity between devices thatare to be synchronized, which may be difficult to achieve due to deviceparameter distribution during the fabrication process. In this work, we presentexperimental results on the mechanisms of synchronization of spin-torqueoscillators. Devices are based on magnetic tunnel junction with aperpendicularly magnetized free layer and take advantage of a uniformmagnetization precision in the presence of the magnetic field and a DC bias. Byusing an external microwave source, we show the optimal condition for thesynchronization of the magnetic tunnel junctions. Finally, we present resultson the in-series connection of two junctions and discuss the possible pathtowards improving oscillation power and linewidth. In addition, using numericalsimulations of the coupled oscillators model, we aim to reproduce theconditions of the experiments and determine the tolerance for achievingsynchronization.</description><author>Piotr Rzeszut, Jakub Mojsiejuk, Witold Skowro≈Ñski, Sumito Tsunegi, Hitoshi Kubota, Shinji Yuasa</author><pubDate>Wed, 21 Jun 2023 17:45:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11608v2</guid></item><item><title>Geometric Algorithms for $k$-NN Poisoning</title><link>http://arxiv.org/abs/2306.12377v1</link><description>We propose a label poisoning attack on geometric data sets against$k$-nearest neighbor classification. We provide an algorithm that can computean $\varepsilon n$-additive approximation of the optimal poisoning in $n\cdot2^{2^{O(d+k/\varepsilon)}}$ time for a given data set $X \in \mathbb{R}^d$,where $|X| = n$. Our algorithm achieves its objectives through the applicationof multi-scale random partitions.</description><author>Diego Ihara Centurion, Karine Chubarian, Bohan Fan, Francesco Sgherzi, Thiruvenkadam S Radhakrishnan, Anastasios Sidiropoulos, Angelo Straight</author><pubDate>Wed, 21 Jun 2023 17:42:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12377v1</guid></item><item><title>M-VAAL: Multimodal Variational Adversarial Active Learning for Downstream Medical Image Analysis Tasks</title><link>http://arxiv.org/abs/2306.12376v1</link><description>Acquiring properly annotated data is expensive in the medical field as itrequires experts, time-consuming protocols, and rigorous validation. Activelearning attempts to minimize the need for large annotated samples by activelysampling the most informative examples for annotation. These examplescontribute significantly to improving the performance of supervised machinelearning models, and thus, active learning can play an essential role inselecting the most appropriate information in deep learning-based diagnosis,clinical assessments, and treatment planning. Although some existing works haveproposed methods for sampling the best examples for annotation in medical imageanalysis, they are not task-agnostic and do not use multimodal auxiliaryinformation in the sampler, which has the potential to increase robustness.Therefore, in this work, we propose a Multimodal Variational Adversarial ActiveLearning (M-VAAL) method that uses auxiliary information from additionalmodalities to enhance the active sampling. We applied our method to twodatasets: i) brain tumor segmentation and multi-label classification using theBraTS2018 dataset, and ii) chest X-ray image classification using theCOVID-QU-Ex dataset. Our results show a promising direction towarddata-efficient learning under limited annotations.</description><author>Bidur Khanal, Binod Bhattarai, Bishesh Khanal, Danail Stoyanov, Cristian A. Linte</author><pubDate>Wed, 21 Jun 2023 17:40:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12376v1</guid></item><item><title>The RL Perceptron: Generalisation Dynamics of Policy Learning in High Dimensions</title><link>http://arxiv.org/abs/2306.10404v2</link><description>Reinforcement learning (RL) algorithms have proven transformative in a rangeof domains. To tackle real-world domains, these systems often use neuralnetworks to learn policies directly from pixels or other high-dimensionalsensory input. By contrast, much theory of RL has focused on discrete statespaces or worst-case analysis, and fundamental questions remain about thedynamics of policy learning in high-dimensional settings. Here, we propose asolvable high-dimensional model of RL that can capture a variety of learningprotocols, and derive its typical dynamics as a set of closed-form ordinarydifferential equations (ODEs). We derive optimal schedules for the learningrates and task difficulty - analogous to annealing schemes and curricula duringtraining in RL - and show that the model exhibits rich behaviour, includingdelayed learning under sparse rewards; a variety of learning regimes dependingon reward baselines; and a speed-accuracy trade-off driven by rewardstringency. Experiments on variants of the Procgen game "Bossfight" and ArcadeLearning Environment game "Pong" also show such a speed-accuracy trade-off inpractice. Together, these results take a step towards closing the gap betweentheory and practice in high-dimensional RL.</description><author>Nishil Patel, Sebastian Lee, Stefano Sarao Mannelli, Sebastian Goldt, Adrew Saxe</author><pubDate>Wed, 21 Jun 2023 17:38:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10404v2</guid></item><item><title>WHAT, WHEN, and HOW to Ground: Designing User Persona-Aware Conversational Agents for Engaging Dialogue</title><link>http://arxiv.org/abs/2306.03361v2</link><description>This paper presents a method for building a personalized open-domain dialoguesystem to address the $\textit{WWH}$ ($\textit{WHAT}$, $\textit{WHEN}$, and$\textit{HOW}$) problem for natural response generation in a commercialsetting, where personalized dialogue responses are heavily interleaved withcasual response turns. The proposed approach involves weighted datasetblending, negative persona information augmentation methods, and the design ofpersonalized conversation datasets to address the challenges of $\textit{WWH}$in personalized, open-domain dialogue systems. Our work effectively balancesdialogue fluency and tendency to ground, while also introducing a response-typelabel to improve the controllability and explainability of the groundedresponses. The combination of these methods leads to more fluent conversations,as evidenced by subjective human evaluations as well as objective evaluations.</description><author>Deuksin Kwon, Sunwoo Lee, Ki Hyun Kim, Seojin Lee, Taeyoon Kim, Eric Davis</author><pubDate>Wed, 21 Jun 2023 17:37:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03361v2</guid></item><item><title>Contrastive Hierarchical Clustering</title><link>http://arxiv.org/abs/2303.03389v2</link><description>Deep clustering has been dominated by flat models, which split a dataset intoa predefined number of groups. Although recent methods achieve an extremelyhigh similarity with the ground truth on popular benchmarks, the informationcontained in the flat partition is limited. In this paper, we introduceCoHiClust, a Contrastive Hierarchical Clustering model based on deep neuralnetworks, which can be applied to typical image data. By employing aself-supervised learning approach, CoHiClust distills the base network into abinary tree without access to any labeled data. The hierarchical clusteringstructure can be used to analyze the relationship between clusters, as well asto measure the similarity between data points. Experiments demonstrate thatCoHiClust generates a reasonable structure of clusters, which is consistentwith our intuition and image semantics. Moreover, it obtains superiorclustering accuracy on most of the image datasets compared to thestate-of-the-art flat clustering models.</description><author>Micha≈Ç Znale≈∫niak, Przemys≈Çaw Rola, Patryk Kaszuba, Jacek Tabor, Marek ≈ömieja</author><pubDate>Wed, 21 Jun 2023 17:37:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03389v2</guid></item><item><title>Optimistic Active Exploration of Dynamical Systems</title><link>http://arxiv.org/abs/2306.12371v1</link><description>Reinforcement learning algorithms commonly seek to optimize policies forsolving one particular task. How should we explore an unknown dynamical systemsuch that the estimated model allows us to solve multiple downstream tasks in azero-shot manner? In this paper, we address this challenge, by developing analgorithm -- OPAX -- for active exploration. OPAX uses well-calibratedprobabilistic models to quantify the epistemic uncertainty about the unknowndynamics. It optimistically -- w.r.t. to plausible dynamics -- maximizes theinformation gain between the unknown dynamics and state observations. We showhow the resulting optimization problem can be reduced to an optimal controlproblem that can be solved at each episode using standard approaches. Weanalyze our algorithm for general models, and, in the case of Gaussian processdynamics, we give a sample complexity bound and show that the epistemicuncertainty converges to zero. In our experiments, we compare OPAX with otherheuristic active exploration approaches on several environments. Ourexperiments show that OPAX is not only theoretically sound but also performswell for zero-shot planning on novel downstream tasks.</description><author>Bhavya Sukhija, Lenart Treven, Cansu Sancaktar, Sebastian Blaes, Stelian Coros, Andreas Krause</author><pubDate>Wed, 21 Jun 2023 17:26:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12371v1</guid></item><item><title>PriorBand: Practical Hyperparameter Optimization in the Age of Deep Learning</title><link>http://arxiv.org/abs/2306.12370v1</link><description>Hyperparameters of Deep Learning (DL) pipelines are crucial for theirdownstream performance. While a large number of methods for HyperparameterOptimization (HPO) have been developed, their incurred costs are oftenuntenable for modern DL. Consequently, manual experimentation is still the mostprevalent approach to optimize hyperparameters, relying on the researcher'sintuition, domain knowledge, and cheap preliminary explorations. To resolvethis misalignment between HPO algorithms and DL researchers, we proposePriorBand, an HPO algorithm tailored to DL, able to utilize both expert beliefsand cheap proxy tasks. Empirically, we demonstrate PriorBand's efficiencyacross a range of DL benchmarks and show its gains under informative expertinput and robustness against poor expert beliefs</description><author>Neeratyoy Mallik, Edward Bergman, Carl Hvarfner, Danny Stoll, Maciej Janowski, Marius Lindauer, Luigi Nardi, Frank Hutter</author><pubDate>Wed, 21 Jun 2023 17:26:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12370v1</guid></item><item><title>Attention Hybrid Variational Net for Accelerated MRI Reconstruction</title><link>http://arxiv.org/abs/2306.12365v1</link><description>The application of compressed sensing (CS)-enabled data reconstruction foraccelerating magnetic resonance imaging (MRI) remains a challenging problem.This is due to the fact that the information lost in k-space from theacceleration mask makes it difficult to reconstruct an image similar to thequality of a fully sampled image. Multiple deep learning-based structures havebeen proposed for MRI reconstruction using CS, both in the k-space and imagedomains as well as using unrolled optimization methods. However, the drawbackof these structures is that they are not fully utilizing the information fromboth domains (k-space and image). Herein, we propose a deep learning-basedattention hybrid variational network that performs learning in both the k-spaceand image domain. We evaluate our method on a well-known open-source MRIdataset and a clinical MRI dataset of patients diagnosed with strokes from ourinstitution to demonstrate the performance of our network. In addition toquantitative evaluation, we undertook a blinded comparison of image qualityacross networks performed by a subspecialty trained radiologist. Overall, wedemonstrate that our network achieves a superior performance among others undermultiple reconstruction tasks.</description><author>Guoyao Shen, Boran Hao, Mengyu Li, Chad W. Farris, Ioannis Ch. Paschalidis, Stephan W. Anderson, Xin Zhang</author><pubDate>Wed, 21 Jun 2023 17:19:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12365v1</guid></item><item><title>Sigma-point Kalman Filter with Nonlinear Unknown Input Estimation via Optimization and Data-driven Approach for Dynamic Systems</title><link>http://arxiv.org/abs/2306.12361v1</link><description>Most works on joint state and unknown input (UI) estimation require theassumption that the UIs are linear; this is potentially restrictive as it doesnot hold in many intelligent autonomous systems. To overcome this restrictionand circumvent the need to linearize the system, we propose a derivative-freeUnknown Input Sigma-point Kalman Filter (SPKF-nUI) where the SPKF isinterconnected with a general nonlinear UI estimator that can be implementedvia nonlinear optimization and data-driven approaches. The nonlinear UIestimator uses the posterior state estimate which is less susceptible to stateprediction error. In addition, we introduce a joint sigma-point transformationscheme to incorporate both the state and UI uncertainties in the estimation ofSPKF-nUI. An in-depth stochastic stability analysis proves that the proposedSPKF-nUI yields exponentially converging estimation error bounds underreasonable assumptions. Finally, two case studies are carried out on asimulation-based rigid robot and a physical soft robot, i.e., robots made ofsoft materials with complex dynamics to validate effectiveness of the proposedfilter on nonlinear dynamic systems. Our results demonstrate that the proposedSPKF-nUI achieves the lowest state and UI estimation errors when compared tothe existing nonlinear state-UI filters.</description><author>Junn Yong Loo, Ze Yang Ding, Vishnu Monn Baskaran, Surya Girinatha Nurzaman, Chee Pin Tan</author><pubDate>Wed, 21 Jun 2023 17:14:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12361v1</guid></item><item><title>Provably Efficient Representation Learning with Tractable Planning in Low-Rank POMDP</title><link>http://arxiv.org/abs/2306.12356v1</link><description>In this paper, we study representation learning in partially observableMarkov Decision Processes (POMDPs), where the agent learns a decoder functionthat maps a series of high-dimensional raw observations to a compactrepresentation and uses it for more efficient exploration and planning. We focus our attention on the sub-classes of \textit{$\gamma$-observable} and\textit{decodable POMDPs}, for which it has been shown that statisticallytractable learning is possible, but there has not been any computationallyefficient algorithm. We first present an algorithm for decodable POMDPs thatcombines maximum likelihood estimation (MLE) and optimism in the face ofuncertainty (OFU) to perform representation learning and achieve efficientsample complexity, while only calling supervised learning computationaloracles. We then show how to adapt this algorithm to also work in the broaderclass of $\gamma$-observable POMDPs.</description><author>Jiacheng Guo, Zihao Li, Huazheng Wang, Mengdi Wang, Zhuoran Yang, Xuezhou Zhang</author><pubDate>Wed, 21 Jun 2023 17:04:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12356v1</guid></item><item><title>Geotechnical Parrot Tales (GPT): Harnessing Large Language Models in geotechnical engineering</title><link>http://arxiv.org/abs/2304.02138v3</link><description>The widespread adoption of large language models (LLMs), such as OpenAI'sChatGPT, could revolutionize various industries, including geotechnicalengineering. However, GPT models can sometimes generate plausible-sounding butfalse outputs, leading to hallucinations. In this article, we discuss theimportance of prompt engineering in mitigating these risks and harnessing thefull potential of GPT for geotechnical applications. We explore the challengesand pitfalls associated with LLMs and highlight the role of context in ensuringaccurate and valuable responses. Furthermore, we examine the development ofcontext-specific search engines and the potential of LLMs to become a naturalinterface for complex tasks, such as data analysis and design. We also developa unified interface using natural language to handle complex geotechnicalengineering tasks and data analysis. By integrating GPT into geotechnicalengineering workflows, professionals can streamline their work and developsustainable and resilient infrastructure systems for the future.</description><author>Krishna Kumar</author><pubDate>Wed, 21 Jun 2023 16:55:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02138v3</guid></item><item><title>Don't trust your eyes: on the (un)reliability of feature visualizations</title><link>http://arxiv.org/abs/2306.04719v2</link><description>How do neural networks extract patterns from pixels? Feature visualizationsattempt to answer this important question by visualizing highly activatingpatterns through optimization. Today, visualization methods form the foundationof our knowledge about the internal workings of neural networks, as a type ofmechanistic interpretability. Here we ask: How reliable are featurevisualizations? We start our investigation by developing network circuits thattrick feature visualizations into showing arbitrary patterns that arecompletely disconnected from normal network behavior on natural input. We thenprovide evidence for a similar phenomenon occurring in standard, unmanipulatednetworks: feature visualizations are processed very differently from standardinput, casting doubt on their ability to "explain" how neural networks processnatural images. We underpin this empirical finding by theory proving that theset of functions that can be reliably understood by feature visualization isextremely small and does not include general black-box neural networks.Therefore, a promising way forward could be the development of networks thatenforce certain structures in order to ensure more reliable featurevisualizations.</description><author>Robert Geirhos, Roland S. Zimmermann, Blair Bilodeau, Wieland Brendel, Been Kim</author><pubDate>Wed, 21 Jun 2023 16:52:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04719v2</guid></item><item><title>Fast Dynamic 1D Simulation of Divertor Plasmas with Neural PDE Surrogates</title><link>http://arxiv.org/abs/2305.18944v2</link><description>Managing divertor plasmas is crucial for operating reactor scale tokamakdevices due to heat and particle flux constraints on the divertor target.Simulation is an important tool to understand and control these plasmas,however, for real-time applications or exhaustive parameter scans only simpleapproximations are currently fast enough. We address this lack of fastsimulators using neural PDE surrogates, data-driven neural network-basedsurrogate models trained using solutions generated with a classical numericalmethod. The surrogate approximates a time-stepping operator that evolves thefull spatial solution of a reference physics-based model over time. We useDIV1D, a 1D dynamic model of the divertor plasma, as reference model togenerate data. DIV1D's domain covers a 1D heat flux tube from the X-point(upstream) to the target. We simulate a realistic TCV divertor plasma withdynamics induced by upstream density ramps and provide an exploratory outlooktowards fast transients. State-of-the-art neural PDE surrogates are evaluatedin a common framework and extended for properties of the DIV1D data. Weevaluate (1) the speed-accuracy trade-off; (2) recreating non-linear behavior;(3) data efficiency; and (4) parameter inter- and extrapolation. Once trained,neural PDE surrogates can faithfully approximate DIV1D's divertor plasmadynamics at sub real-time computation speeds: In the proposed configuration,2ms of plasma dynamics can be computed in $\approx$0.63ms of wall-clock time,several orders of magnitude faster than DIV1D.</description><author>Yoeri Poels, Gijs Derks, Egbert Westerhof, Koen Minartz, Sven Wiesen, Vlado Menkovski</author><pubDate>Wed, 21 Jun 2023 16:50:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18944v2</guid></item><item><title>Neighborhood Homophily-based Graph Convolutional Network</title><link>http://arxiv.org/abs/2301.09851v2</link><description>Graph neural networks (GNNs) have been proved powerful in graph-orientedtasks. However, many real-world graphs are heterophilous, challenging thehomophily assumption of classical GNNs. To solve the universality problem, manystudies deepen networks or concatenate intermediate representations, which doesnot inherently change neighbor aggregation and introduces noise. Recent studiespropose new metrics to characterize the homophily, but rarely consider thecorrelation of the proposed metrics and models. In this paper, we first designa new metric, Neighborhood Homophily (\textit{NH}), to measure the labelcomplexity or purity in node neighborhoods. Furthermore, we incorporate themetric into the classical graph convolutional network (GCN) architecture andpropose \textbf{N}eighborhood \textbf{H}omophily-based \textbf{G}raph\textbf{C}onvolutional \textbf{N}etwork (\textbf{NHGCN}). In this framework,neighbors are grouped by estimated \textit{NH} values and aggregated fromdifferent channels, and the resulting node predictions are then used in turn toestimate and update \textit{NH} values. The two processes of metric estimationand model inference are alternately optimized to achieve better nodeclassification. NHGCN achieves top overall performance on both homophilous andheterophilous benchmarks, with an improvement of up to 7.4\% compared to thecurrent SOTA methods.</description><author>Shengbo Gong, Jiajun Zhou, Chenxuan Xie, Qi Xuan</author><pubDate>Wed, 21 Jun 2023 16:44:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.09851v2</guid></item><item><title>Exploring Vision-Language Models for Imbalanced Learning</title><link>http://arxiv.org/abs/2304.01457v2</link><description>Vision-Language models (VLMs) that use contrastive language-imagepre-training have shown promising zero-shot classification performance.However, their performance on imbalanced dataset is relatively poor, where thedistribution of classes in the training dataset is skewed, leading to poorperformance in predicting minority classes. For instance, CLIP achieved only 5%accuracy on the iNaturalist18 dataset. We propose to add a lightweight decoderto VLMs to avoid OOM (out of memory) problem caused by large number of classesand capture nuanced features for tail classes. Then, we explore improvements ofVLMs using prompt tuning, fine-tuning, and incorporating imbalanced algorithmssuch as Focal Loss, Balanced SoftMax and Distribution Alignment. Experimentsdemonstrate that the performance of VLMs can be further boosted when used withdecoder and imbalanced methods. Specifically, our improved VLMs significantlyoutperforms zero-shot classification by an average accuracy of 6.58%, 69.82%,and 6.17%, on ImageNet-LT, iNaturalist18, and Places-LT, respectively. Wefurther analyze the influence of pre-training data size, backbones, andtraining cost. Our study highlights the significance of imbalanced learningalgorithms in face of VLMs pre-trained by huge data. We release our code athttps://github.com/Imbalance-VLM/Imbalance-VLM.</description><author>Yidong Wang, Zhuohao Yu, Jindong Wang, Qiang Heng, Hao Chen, Wei Ye, Rui Xie, Xing Xie, Shikun Zhang</author><pubDate>Wed, 21 Jun 2023 16:44:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.01457v2</guid></item><item><title>An efficient, provably exact algorithm for the 0-1 loss linear classification problem</title><link>http://arxiv.org/abs/2306.12344v1</link><description>Algorithms for solving the linear classification problem have a long history,dating back at least to 1936 with linear discriminant analysis. For linearlyseparable data, many algorithms can obtain the exact solution to thecorresponding 0-1 loss classification problem efficiently, but for data whichis not linearly separable, it has been shown that this problem, in fullgenerality, is NP-hard. Alternative approaches all involve approximations ofsome kind, including the use of surrogates for the 0-1 loss (for example, thehinge or logistic loss) or approximate combinatorial search, none of which canbe guaranteed to solve the problem exactly. Finding efficient algorithms toobtain an exact i.e. globally optimal solution for the 0-1 loss linearclassification problem with fixed dimension, remains an open problem. Inresearch we report here, we detail the construction of a new algorithm,incremental cell enumeration (ICE), that can solve the 0-1 loss classificationproblem exactly in polynomial time. To our knowledge, this is the first,rigorously-proven polynomial time algorithm for this long-standing problem.</description><author>Xi He, Max A. Little</author><pubDate>Wed, 21 Jun 2023 16:41:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12344v1</guid></item><item><title>flexBART: Flexible Bayesian regression trees with categorical predictors</title><link>http://arxiv.org/abs/2211.04459v2</link><description>Most implementations of Bayesian additive regression trees (BART) one-hotencode categorical predictors, replacing each one with several binaryindicators, one for every level or category. Regression trees built with theseindicators partition the discrete set of categorical levels by repeatedlyremoving one level at a time. Unfortunately, the vast majority of partitionscannot be built with this strategy, severely limiting BART's ability topartially pool data across groups of levels. Motivated by analyses of baseballdata and neighborhood-level crime dynamics, we overcame this limitation byre-implementing BART with regression trees that can assign multiple levels toboth branches of a decision tree node. To model spatial data aggregated intosmall regions, we further proposed a new decision rule prior that createsspatially contiguous regions by deleting a random edge from a random spanningtree of a suitably defined network. Our re-implementation, which is availablein the flexBART package, often yields improved out-of-sample predictiveperformance and scales better to larger datasets than existing implementationsof BART.</description><author>Sameer K. Deshpande</author><pubDate>Wed, 21 Jun 2023 16:40:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.04459v2</guid></item><item><title>Geometric Pooling: maintaining more useful information</title><link>http://arxiv.org/abs/2306.12341v1</link><description>Graph Pooling technology plays an important role in graph node classificationtasks. Sorting pooling technologies maintain large-value units for poolinggraphs of varying sizes. However, by analyzing the statistical characteristicof activated units after pooling, we found that a large number of units droppedby sorting pooling are negative-value units that contain useful information andcan contribute considerably to the final decision. To maintain more usefulinformation, a novel pooling technology, called Geometric Pooling (GP), wasproposed to contain the unique node features with negative values by measuringthe similarity of all node features. We reveal the effectiveness of GP from theentropy reduction view. The experiments were conducted on TUdatasets to showthe effectiveness of GP. The results showed that the proposed GP outperformsthe SOTA graph pooling technologies by 1%\sim5% with fewer parameters.</description><author>Hao Xu, Jia Liu, Yang Shen, Kenan Lou, Yanxia Bao, Ruihua Zhang, Shuyue Zhou, Hongsen Zhao, Shuai Wang</author><pubDate>Wed, 21 Jun 2023 16:39:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12341v1</guid></item><item><title>ProtoGate: Prototype-based Neural Networks with Local Feature Selection for Tabular Biomedical Data</title><link>http://arxiv.org/abs/2306.12330v1</link><description>Tabular biomedical data poses challenges in machine learning because it isoften high-dimensional and typically low-sample-size. Previous research hasattempted to address these challenges via feature selection approaches, whichcan lead to unstable performance on real-world data. This suggests that currentmethods lack appropriate inductive biases that capture patterns common todifferent samples. In this paper, we propose ProtoGate, a prototype-basedneural model that introduces an inductive bias by attending to both homogeneityand heterogeneity across samples. ProtoGate selects features in aglobal-to-local manner and leverages them to produce explainable predictionsvia an interpretable prototype-based model. We conduct comprehensiveexperiments to evaluate the performance of ProtoGate on synthetic andreal-world datasets. Our results show that exploiting the homogeneous andheterogeneous patterns in the data can improve prediction accuracy whileprototypes imbue interpretability.</description><author>Xiangjian Jiang, Andrei Margeloiu, Nikola Simidjievski, Mateja Jamnik</author><pubDate>Wed, 21 Jun 2023 16:17:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12330v1</guid></item><item><title>Dynamic Implicit Image Function for Efficient Arbitrary-Scale Image Representation</title><link>http://arxiv.org/abs/2306.12321v1</link><description>Recent years have witnessed the remarkable success of implicit neuralrepresentation methods. The recent work Local Implicit Image Function (LIIF)has achieved satisfactory performance for continuous image representation,where pixel values are inferred from a neural network in a continuous spatialdomain. However, the computational cost of such implicit arbitrary-scalesuper-resolution (SR) methods increases rapidly as the scale factor increases,which makes arbitrary-scale SR time-consuming. In this paper, we proposeDynamic Implicit Image Function (DIIF), which is a fast and efficient method torepresent images with arbitrary resolution. Instead of taking an imagecoordinate and the nearest 2D deep features as inputs to predict its pixelvalue, we propose a coordinate grouping and slicing strategy, which enables theneural network to perform decoding from coordinate slices to pixel valueslices. We further propose a Coarse-to-Fine Multilayer Perceptron (C2F-MLP) toperform decoding with dynamic coordinate slicing, where the number ofcoordinates in each slice varies as the scale factor varies. With dynamiccoordinate slicing, DIIF significantly reduces the computational cost whenencountering arbitrary-scale SR. Experimental results demonstrate that DIIF canbe integrated with implicit arbitrary-scale SR methods and achieves SOTA SRperformance with significantly superior computational efficiency, therebyopening a path for real-time arbitrary-scale image representation. Our code canbe found at https://github.com/HeZongyao/DIIF.</description><author>Zongyao He, Zhi Jin</author><pubDate>Wed, 21 Jun 2023 16:04:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12321v1</guid></item><item><title>Iterated Piecewise Affine (IPA) Approximation for Language Modeling</title><link>http://arxiv.org/abs/2306.12317v1</link><description>In this work, we demonstrate the application of a simple first-order Taylorexpansion to approximate a generic function $F: R^{n \times m} \to R^{n \timesm}$ and utilize it in language modeling. To enhance the basic Taylor expansion,we introduce iteration and piecewise modeling, leading us to name the algorithmthe Iterative Piecewise Affine (IPA) approximation. The final algorithmexhibits interesting resemblances to the Transformers decoder architecture. Bycomparing parameter arrangements in IPA and Transformers, we observe astrikingly similar performance, with IPA outperforming Transformers by 1.5\% inthe next token prediction task with cross-entropy loss for smaller sequencelengths.</description><author>Davood Shamsi, Wen-yu Hua, Brian Williams</author><pubDate>Wed, 21 Jun 2023 15:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12317v1</guid></item><item><title>Introspective Action Advising for Interpretable Transfer Learning</title><link>http://arxiv.org/abs/2306.12314v1</link><description>Transfer learning can be applied in deep reinforcement learning to acceleratethe training of a policy in a target task by transferring knowledge from apolicy learned in a related source task. This is commonly achieved by copyingpretrained weights from the source policy to the target policy prior totraining, under the constraint that they use the same model architecture.However, not only does this require a robust representation learned over a widedistribution of states -- often failing to transfer between specialist modelstrained over single tasks -- but it is largely uninterpretable and provideslittle indication of what knowledge is transferred. In this work, we propose analternative approach to transfer learning between tasks based on actionadvising, in which a teacher trained in a source task actively guides astudent's exploration in a target task. Through introspection, the teacher iscapable of identifying when advice is beneficial to the student and should begiven, and when it is not. Our approach allows knowledge transfer betweenpolicies agnostic of the underlying representations, and we empirically showthat this leads to improved convergence rates in Gridworld and Atarienvironments while providing insight into what knowledge is transferred.</description><author>Joseph Campbell, Yue Guo, Fiona Xie, Simon Stepputtis, Katia Sycara</author><pubDate>Wed, 21 Jun 2023 15:53:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12314v1</guid></item><item><title>Structured Cooperative Learning with Graphical Model Priors</title><link>http://arxiv.org/abs/2306.09595v2</link><description>We study how to train personalized models for different tasks ondecentralized devices with limited local data. We propose "StructuredCooperative Learning (SCooL)", in which a cooperation graph across devices isgenerated by a graphical model prior to automatically coordinate mutuallearning between devices. By choosing graphical models enforcing differentstructures, we can derive a rich class of existing and novel decentralizedlearning algorithms via variational inference. In particular, we show threeinstantiations of SCooL that adopt Dirac distribution, stochastic block model(SBM), and attention as the prior generating cooperation graphs. These EM-typealgorithms alternate between updating the cooperation graph and cooperativelearning of local models. They can automatically capture the cross-taskcorrelations among devices by only monitoring their model updating in order tooptimize the cooperation graph. We evaluate SCooL and compare it with existingdecentralized learning methods on an extensive set of benchmarks, on whichSCooL always achieves the highest accuracy of personalized models andsignificantly outperforms other baselines on communication efficiency. Our codeis available at https://github.com/ShuangtongLi/SCooL.</description><author>Shuangtong Li, Tianyi Zhou, Xinmei Tian, Dacheng Tao</author><pubDate>Wed, 21 Jun 2023 15:43:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09595v2</guid></item><item><title>Medical ministrations through web scraping</title><link>http://arxiv.org/abs/2306.12310v1</link><description>Web scraping is a technique that allows us to extract data from websitesautomatically. in the field of medicine, web scraping can be used to collectinformation about medical procedures, treatments, and healthcare providers.this information can be used to improve patient care, monitor the quality ofhealthcare services, and identify areas for improvement. one area where webscraping can be particularly useful is in medical ministrations. medicalministrations are the actions taken to provide medical care to patients, andweb scraping can help healthcare providers identify the most effectiveministrations for their patients. for example, healthcare providers can use webscraping to collect data about the symptoms and medical histories of theirpatients, and then use this information to determine the most appropriateministrations. they can also use web scraping to gather information about thelatest medical research and clinical trials, which can help them stayup-to-date with the latest treatments and procedures.</description><author>Niketha Sabesan, Nivethitha, J. N Shreyah, Pranauv A J, Shyam R</author><pubDate>Wed, 21 Jun 2023 15:43:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12310v1</guid></item><item><title>CLARA: Classifying and Disambiguating User Commands for Reliable Interactive Robotic Agents</title><link>http://arxiv.org/abs/2306.10376v2</link><description>In this paper, we focus on inferring whether the given user command is clear,ambiguous, or infeasible in the context of interactive robotic agents utilizinglarge language models (LLMs). To tackle this problem, we first present anuncertainty estimation method for LLMs to classify whether the command iscertain (i.e., clear) or not (i.e., ambiguous or infeasible). Once the commandis classified as uncertain, we further distinguish it between ambiguous orinfeasible commands leveraging LLMs with situational aware context in azero-shot manner. For ambiguous commands, we disambiguate the command byinteracting with users via question generation with LLMs. We believe thatproper recognition of the given commands could lead to a decrease inmalfunction and undesired actions of the robot, enhancing the reliability ofinteractive robot agents. We present a dataset for robotic situationalawareness, consisting pair of high-level commands, scene descriptions, andlabels of command type (i.e., clear, ambiguous, or infeasible). We validate theproposed method on the collected dataset, pick-and-place tabletop simulation.Finally, we demonstrate the proposed approach in real-world human-robotinteraction experiments, i.e., handover scenarios.</description><author>Jeongeun Park, Seungwon Lim, Joonhyung Lee, Sangbeom Park, Youngjae Yu, Sungjoon Choi</author><pubDate>Wed, 21 Jun 2023 15:39:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10376v2</guid></item><item><title>6D Object Pose Estimation from Approximate 3D Models for Orbital Robotics</title><link>http://arxiv.org/abs/2303.13241v3</link><description>We present a novel technique to estimate the 6D pose of objects from singleimages where the 3D geometry of the object is only given approximately and notas a precise 3D model. To achieve this, we employ a dense 2D-to-3Dcorrespondence predictor that regresses 3D model coordinates for every pixel.In addition to the 3D coordinates, our model also estimates the pixel-wisecoordinate error to discard correspondences that are likely wrong. This allowsus to generate multiple 6D pose hypotheses of the object, which we then refineiteratively using a highly efficient region-based approach. We also introduce anovel pixel-wise posterior formulation by which we can estimate the probabilityfor each hypothesis and select the most likely one. As we show in experiments,our approach is capable of dealing with extreme visual conditions includingoverexposure, high contrast, or low signal-to-noise ratio. This makes it apowerful technique for the particularly challenging task of estimating the poseof tumbling satellites for in-orbit robotic applications. Our method achievesstate-of-the-art performance on the SPEED+ dataset and has won the SPEC2021post-mortem competition.</description><author>Maximilian Ulmer, Maximilian Durner, Martin Sundermeyer, Manuel Stoiber, Rudolph Triebel</author><pubDate>Wed, 21 Jun 2023 15:36:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.13241v3</guid></item><item><title>Beyond Deep Ensembles -- A Large-Scale Evaluation of Bayesian Deep Learning under Distribution Shift</title><link>http://arxiv.org/abs/2306.12306v1</link><description>Bayesian deep learning (BDL) is a promising approach to achievewell-calibrated predictions on distribution-shifted data. Nevertheless, thereexists no large-scale survey that evaluates recent SOTA methods on diverse,realistic, and challenging benchmark tasks in a systematic manner. To provide aclear picture of the current state of BDL research, we evaluate modern BDLalgorithms on real-world datasets from the WILDS collection containingchallenging classification and regression tasks, with a focus on generalizationcapability and calibration under distribution shift. We compare the algorithmson a wide range of large, convolutional and transformer-based neural networkarchitectures. In particular, we investigate a signed version of the expectedcalibration error that reveals whether the methods are over- orunder-confident, providing further insight into the behavior of the methods.Further, we provide the first systematic evaluation of BDL for fine-tuninglarge pre-trained models, where training from scratch is prohibitivelyexpensive. Finally, given the recent success of Deep Ensembles, we extendpopular single-mode posterior approximations to multiple modes by the use ofensembles. While we find that ensembling single-mode approximations generallyimproves the generalization capability and calibration of the models by asignificant margin, we also identify a failure mode of ensembles whenfinetuning large transformer-based language models. In this setting,variational inference based approaches such as last-layer Bayes By Backpropoutperform other methods in terms of accuracy by a large margin, while modernapproximate inference algorithms such as SWAG achieve the best calibration.</description><author>Florian Seligmann, Philipp Becker, Michael Volpp, Gerhard Neumann</author><pubDate>Wed, 21 Jun 2023 15:36:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12306v1</guid></item><item><title>StarVQA+: Co-training Space-Time Attention for Video Quality Assessment</title><link>http://arxiv.org/abs/2306.12298v1</link><description>Self-attention based Transformer has achieved great success in many computervision tasks. However, its application to video quality assessment (VQA) hasnot been satisfactory so far. Evaluating the quality of in-the-wild videos ischallenging due to the unknown of pristine reference and shooting distortion.This paper presents a co-trained Space-Time Attention network for the VQAproblem, termed StarVQA+. Specifically, we first build StarVQA+ by alternatelyconcatenating the divided space-time attention. Then, to facilitate thetraining of StarVQA+, we design a vectorized regression loss by encoding themean opinion score (MOS) to the probability vector and embedding a specialtoken as the learnable variable of MOS, leading to better fitting of human'srating process. Finally, to solve the data hungry problem with Transformer, wepropose to co-train the spatial and temporal attention weights using bothimages and videos. Various experiments are conducted on the de-factoin-the-wild video datasets, including LIVE-Qualcomm, LIVE-VQC, KoNViD-1k,YouTube-UGC, LSVQ, LSVQ-1080p, and DVL2021. Experimental results demonstratethe superiority of the proposed StarVQA+ over the state-of-the-art.</description><author>Fengchuang Xing, Yuan-Gen Wang, Weixuan Tang, Guopu Zhu, Sam Kwong</author><pubDate>Wed, 21 Jun 2023 15:27:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12298v1</guid></item><item><title>On Scaled Methods for Saddle Point Problems</title><link>http://arxiv.org/abs/2206.08303v2</link><description>Methods with adaptive scaling of different features play a key role insolving saddle point problems, primarily due to Adam's popularity for solvingadversarial machine learning problems, including GANS training. This papercarries out a theoretical analysis of the following scaling techniques forsolving SPPs: the well-known Adam and RmsProp scaling and the newer AdaHessianand OASIS based on Hutchison approximation. We use the Extra Gradient and itsimproved version with negative momentum as the basic method. Experimentalstudies on GANs show good applicability not only for Adam, but also for otherless popular methods.</description><author>Aleksandr Beznosikov, Aibek Alanov, Dmitry Kovalev, Martin Tak√°ƒç, Alexander Gasnikov</author><pubDate>Wed, 21 Jun 2023 15:26:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.08303v2</guid></item><item><title>Diffusion Posterior Sampling for Informed Single-Channel Dereverberation</title><link>http://arxiv.org/abs/2306.12286v1</link><description>We present in this paper an informed single-channel dereverberation methodbased on conditional generation with diffusion models. With knowledge of theroom impulse response, the anechoic utterance is generated via reversediffusion using a measurement consistency criterion coupled with a neuralnetwork that represents the clean speech prior. The proposed approach islargely more robust to measurement noise compared to a state-of-the-artinformed single-channel dereverberation method, especially for non-stationarynoise. Furthermore, we compare to other blind dereverberation methods usingdiffusion models and show superiority of the proposed approach for largereverberation times. We motivate the presented algorithm by introducing anextension for blind dereverberation allowing joint estimation of the roomimpulse response and anechoic speech. Audio samples and code can be foundonline (https://uhh.de/inf-sp-derev-dps).</description><author>Jean-Marie Lemercier, Simon Welker, Timo Gerkmann</author><pubDate>Wed, 21 Jun 2023 15:14:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12286v1</guid></item><item><title>Resilient Sparse Array Radar with the Aid of Deep Learning</title><link>http://arxiv.org/abs/2306.12285v1</link><description>In this paper, we address the problem of direction of arrival (DOA)estimation for multiple targets in the presence of sensor failures in a sparsearray. Generally, sparse arrays are known with very high-resolutioncapabilities, where N physical sensors can resolve up to $\mathcal{O}(N^2)$uncorrelated sources. However, among the many configurations introduced in theliterature, the arrays that provide the largest hole-free co-array are the mostsusceptible to sensor failures. We propose here two machine learning (ML)methods to mitigate the effect of sensor failures and maintain the DOAestimation performance and resolution. The first method enhances theconventional spatial smoothing using deep neural network (DNN), while thesecond one is an end-to-end data-driven method. Numerical results show thatboth approaches can significantly improve the performance of MRA with twofailed sensors. The data-driven method can maintain the performance of thearray with no failures at high signal-tonoise ratio (SNR). Moreover, bothapproaches can even perform better than the original array at low SNR thanks tothe denoising effect of the proposed DNN</description><author>Aya Mostafa Ahmed, Udaya S. K. P. Miriya Thanthrige, Aydin Sezgin, Fulvio Gini</author><pubDate>Wed, 21 Jun 2023 15:13:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12285v1</guid></item><item><title>Online Resource Allocation with Convex-set Machine-Learned Advice</title><link>http://arxiv.org/abs/2306.12282v1</link><description>Decision-makers often have access to a machine-learned prediction aboutdemand, referred to as advice, which can potentially be utilized in onlinedecision-making processes for resource allocation. However, exploiting suchadvice poses challenges due to its potential inaccuracy. To address this issue,we propose a framework that enhances online resource allocation decisions withpotentially unreliable machine-learned (ML) advice. We assume here that thisadvice is represented by a general convex uncertainty set for the demandvector. We introduce a parameterized class of Pareto optimal online resourceallocation algorithms that strike a balance between consistent and robustratios. The consistent ratio measures the algorithm's performance (compared tothe optimal hindsight solution) when the ML advice is accurate, while therobust ratio captures performance under an adversarial demand process when theadvice is inaccurate. Specifically, in a C-Pareto optimal setting, we maximizethe robust ratio while ensuring that the consistent ratio is at least C. Ourproposed C-Pareto optimal algorithm is an adaptive protection level algorithm,which extends the classical fixed protection level algorithm introduced inLittlewood (2005) and Ball and Queyranne (2009). Solving a complex non-convexcontinuous optimization problem characterizes the adaptive protection levelalgorithm. To complement our algorithms, we present a simple method forcomputing the maximum achievable consistent ratio, which serves as an estimatefor the maximum value of the ML advice. Additionally, we present numericalstudies to evaluate the performance of our algorithm in comparison to benchmarkalgorithms. The results demonstrate that by adjusting the parameter C, ouralgorithms effectively strike a balance between worst-case and averageperformance, outperforming the benchmark algorithms.</description><author>Negin Golrezaei, Patrick Jaillet, Zijie Zhou</author><pubDate>Wed, 21 Jun 2023 15:09:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12282v1</guid></item><item><title>SIFTER: A Task-specific Alignment Strategy for Enhancing Sentence Embeddings</title><link>http://arxiv.org/abs/2306.12280v1</link><description>The paradigm of pre-training followed by fine-tuning on downstream tasks hasbecome the mainstream method in natural language processing tasks. Althoughpre-trained models have the advantage of generalization, their performance maystill vary significantly across different domain tasks. This is because thedata distribution in different domains varies. For example, the different partsof the sentence 'He married Smt. Dipali Ghosh in 1947 and led a very happymarried life' may have different impact for downstream tasks. For similaritycalculations, words such as 'led' and 'life' are more important. On the otherhand, for sentiment analysis, the word 'happy' is crucial. This indicates thatdifferent downstream tasks have different levels of sensitivity to sentencecomponents. Our starting point is to scale information of the model and dataaccording to the specifics of downstream tasks, enhancing domain information ofrelevant parts for these tasks and reducing irrelevant elements for differentdomain tasks, called SIFTER. In the experimental part, we use the SIFTER toimprove SimCSE by constructing positive sample pairs based on enhancing thesentence stem and reducing the unimportant components in the sentence, andmaximize the similarity between three sentences. Similarly, SIFTER can improvethe gate mechanism of the LSTM model by short-circuiting the input gate ofimportant words so that the LSTM model remembers the important parts of thesentence. Our experiments demonstrate that SIFTER outperforms the SimCSE andLSTM baselines.</description><author>Chao Yu, Wenhao Zhu, Chaoming Liu, Xiaoyu Zhang, Qiuhong zhai</author><pubDate>Wed, 21 Jun 2023 15:08:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12280v1</guid></item><item><title>Input Augmentation with SAM: Boosting Medical Image Segmentation with Segmentation Foundation Model</title><link>http://arxiv.org/abs/2304.11332v2</link><description>The Segment Anything Model (SAM) is a recently developed large model forgeneral-purpose segmentation for computer vision tasks. SAM was trained using11 million images with over 1 billion masks and can produce segmentationresults for a wide range of objects in natural scene images. SAM can be viewedas a general perception model for segmentation (partitioning images intosemantically meaningful regions). Thus, how to utilize such a large foundationmodel for medical image segmentation is an emerging research target. This papershows that although SAM does not immediately give high-quality segmentation formedical image data, its generated masks, features, and stability scores areuseful for building and training better medical image segmentation models. Inparticular, we demonstrate how to use SAM to augment image input forcommonly-used medical image segmentation models (e.g., U-Net). Experiments onthree segmentation tasks show the effectiveness of our proposed SAMAug method.The code is available at \url{https://github.com/yizhezhang2000/SAMAug}.</description><author>Yizhe Zhang, Tao Zhou, Shuo Wang, Peixian Liang, Danny Z. Chen</author><pubDate>Wed, 21 Jun 2023 15:04:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.11332v2</guid></item><item><title>Event Stream GPT: A Data Pre-processing and Modeling Library for Generative, Pre-trained Transformers over Continuous-time Sequences of Complex Events</title><link>http://arxiv.org/abs/2306.11547v2</link><description>Generative, pre-trained transformers (GPTs, a.k.a. "Foundation Models") havereshaped natural language processing (NLP) through their versatility in diversedownstream tasks. However, their potential extends far beyond NLP. This paperprovides a software utility to help realize this potential, extending theapplicability of GPTs to continuous-time sequences of complex events withinternal dependencies, such as medical record datasets. Despite theirpotential, the adoption of foundation models in these domains has been hamperedby the lack of suitable tools for model construction and evaluation. To bridgethis gap, we introduce Event Stream GPT (ESGPT), an open-source librarydesigned to streamline the end-to-end process for building GPTs forcontinuous-time event sequences. ESGPT allows users to (1) build flexible,foundation-model scale input datasets by specifying only a minimalconfiguration file, (2) leverage a Hugging Face compatible modeling API forGPTs over this modality that incorporates intra-event causal dependencystructures and autoregressive generation capabilities, and (3) evaluate modelsvia standardized processes that can assess few and even zero-shot performanceof pre-trained models on user-specified fine-tuning tasks.</description><author>Matthew B. A. McDermott, Bret Nestor, Peniel Argaw, Isaac Kohane</author><pubDate>Wed, 21 Jun 2023 15:02:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11547v2</guid></item><item><title>Decentralized Training of Foundation Models in Heterogeneous Environments</title><link>http://arxiv.org/abs/2206.01288v4</link><description>Training foundation models, such as GPT-3 and PaLM, can be extremelyexpensive, often involving tens of thousands of GPUs running continuously formonths. These models are typically trained in specialized clusters featuringfast, homogeneous interconnects and using carefully designed software systemsthat support both data parallelism and model/pipeline parallelism. Suchdedicated clusters can be costly and difficult to obtain. Can we insteadleverage the much greater amount of decentralized, heterogeneous, andlower-bandwidth interconnected compute? Previous works examining theheterogeneous, decentralized setting focus on relatively small models that canbe trained in a purely data parallel manner. State-of-the-art schemes for modelparallel foundation model training, such as Megatron, only consider thehomogeneous data center setting. In this paper, we present the first study oftraining large foundation models with model parallelism in a decentralizedregime over a heterogeneous network. Our key technical contribution is ascheduling algorithm that allocates different computational "tasklets" in thetraining of foundation models to a group of decentralized GPU devices connectedby a slow heterogeneous network. We provide a formal cost model and furtherpropose an efficient evolutionary algorithm to find the optimal allocationstrategy. We conduct extensive experiments that represent different scenariosfor learning over geo-distributed devices simulated using real-world networkmeasurements. In the most extreme case, across 8 different cities spanning 3continents, our approach is 4.8X faster than prior state-of-the-art trainingsystems (Megatron).</description><author>Binhang Yuan, Yongjun He, Jared Quincy Davis, Tianyi Zhang, Tri Dao, Beidi Chen, Percy Liang, Christopher Re, Ce Zhang</author><pubDate>Wed, 21 Jun 2023 14:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.01288v4</guid></item><item><title>Wildfire Detection Via Transfer Learning: A Survey</title><link>http://arxiv.org/abs/2306.12276v1</link><description>This paper surveys different publicly available neural network models usedfor detecting wildfires using regular visible-range cameras which are placed onhilltops or forest lookout towers. The neural network models are pre-trained onImageNet-1K and fine-tuned on a custom wildfire dataset. The performance ofthese models is evaluated on a diverse set of wildfire images, and the surveyprovides useful information for those interested in using transfer learning forwildfire detection. Swin Transformer-tiny has the highest AUC value butConvNext-tiny detects all the wildfire events and has the lowest false alarmrate in our dataset.</description><author>Ziliang Hong, Emadeldeen Hamdan, Yifei Zhao, Tianxiao Ye, Hongyi Pan, A. Enis Cetin</author><pubDate>Wed, 21 Jun 2023 14:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12276v1</guid></item><item><title>FigGen: Text to Scientific Figure Generation</title><link>http://arxiv.org/abs/2306.00800v2</link><description>The generative modeling landscape has experienced tremendous growth in recentyears, particularly in generating natural images and art. Recent techniqueshave shown impressive potential in creating complex visual compositions whiledelivering impressive realism and quality. However, state-of-the-art methodshave been focusing on the narrow domain of natural images, while otherdistributions remain unexplored. In this paper, we introduce the problem oftext-to-figure generation, that is creating scientific figures of papers fromtext descriptions. We present FigGen, a diffusion-based approach fortext-to-figure as well as the main challenges of the proposed task. Code andmodels are available at https://github.com/joanrod/figure-diffusion</description><author>Juan A. Rodriguez, David Vazquez, Issam Laradji, Marco Pedersoli, Pau Rodriguez</author><pubDate>Wed, 21 Jun 2023 14:55:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00800v2</guid></item><item><title>Revisit Weakly-Supervised Audio-Visual Video Parsing from the Language Perspective</title><link>http://arxiv.org/abs/2306.00595v4</link><description>We focus on the weakly-supervised audio-visual video parsing task (AVVP),which aims to identify and locate all the events in audio/visual modalities.Previous works only concentrate on video-level overall label denoising acrossmodalities, but overlook the segment-level label noise, where adjacent videosegments (i.e., 1-second video clips) may contain different events. However,recognizing events in the segment is challenging because its label could be anycombination of events that occur in the video. To address this issue, weconsider tackling AVVP from the language perspective, since language couldfreely describe how various events appear in each segment beyond fixed labels.Specifically, we design language prompts to describe all cases of eventappearance for each video. Then, the similarity between language prompts andsegments is calculated, where the event of the most similar prompt is regardedas the segment-level label. In addition, to deal with the mislabeled segments,we propose to perform dynamic re-weighting on the unreliable segments to adjusttheir labels. Experiments show that our simple yet effective approachoutperforms state-of-the-art methods by a large margin.</description><author>Yingying Fan, Yu Wu, Yutian Lin, Bo Du</author><pubDate>Wed, 21 Jun 2023 14:49:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00595v4</guid></item><item><title>From structure mining to unsupervised exploration of atomic octahedral networks</title><link>http://arxiv.org/abs/2306.12272v1</link><description>Networks of atom-centered coordination octahedra commonly occur in inorganicand hybrid solid-state materials. Characterizing their spatial arrangements andcharacteristics is crucial for relating structures to properties for manymaterials families. The traditional method using case-by-case inspectionbecomes prohibitive for discovering trends and similarities in large datasets.Here, we operationalize chemical intuition to automate the geometric parsing,quantification, and classification of coordination octahedral networks. We findaxis-resolved tilting trends in ABO$_{3}$ perovskite polymorphs, which assistin detecting oxidation state changes. Moreover, we develop a scale-invariantencoding scheme to represent these networks, which, combined withhuman-assisted unsupervised machine learning, allows us to taxonomize theinorganic framework polytypes in hybrid iodoplumbates (A$_x$Pb$_y$I$_z$).Consequently, we uncover a violation of Pauling's third rule and the designprinciples underpinning their topological diversity. Our results offer aglimpse into the vast design space of atomic octahedral networks and informhigh-throughput, targeted screening of specific structure types.</description><author>R. Patrick Xian, Ryan J. Morelock, Ido Hadar, Charles B. Musgrave, Christopher Sutton</author><pubDate>Wed, 21 Jun 2023 14:49:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12272v1</guid></item><item><title>A Finite Expression Method for Solving High-Dimensional Committor Problems</title><link>http://arxiv.org/abs/2306.12268v1</link><description>Transition path theory (TPT) is a mathematical framework for quantifying raretransition events between a pair of selected metastable states $A$ and $B$.Central to TPT is the committor function, which describes the probability tohit the metastable state $B$ prior to $A$ from any given starting point of thephase space. Once the committor is computed, the transition channels and thetransition rate can be readily found. The committor is the solution to thebackward Kolmogorov equation with appropriate boundary conditions. However,solving it is a challenging task in high dimensions due to the need to mesh awhole region of the ambient space. In this work, we explore the finiteexpression method (FEX, Liang and Yang (2022)) as a tool for computing thecommittor. FEX approximates the committor by an algebraic expression involvinga fixed finite number of nonlinear functions and binary arithmetic operations.The optimal nonlinear functions, the binary operations, and the numericalcoefficients in the expression template are found via reinforcement learning.The FEX-based committor solver is tested on several high-dimensional benchmarkproblems. It gives comparable or better results than neural network-basedsolvers. Most importantly, FEX is capable of correctly identifying thealgebraic structure of the solution which allows one to reduce the committorproblem to a low-dimensional one and find the committor with any desiredaccuracy.</description><author>Zezheng Song, Maria K. Cameron, Haizhao Yang</author><pubDate>Wed, 21 Jun 2023 14:43:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12268v1</guid></item><item><title>Combining multi-spectral data with statistical and deep-learning models for improved exoplanet detection in direct imaging at high contrast</title><link>http://arxiv.org/abs/2306.12266v1</link><description>Exoplanet detection by direct imaging is a difficult task: the faint signalsfrom the objects of interest are buried under a spatially structured nuisancecomponent induced by the host star. The exoplanet signals can only beidentified when combining several observations with dedicated detectionalgorithms. In contrast to most of existing methods, we propose to learn amodel of the spatial, temporal and spectral characteristics of the nuisance,directly from the observations. In a pre-processing step, a statistical modelof their correlations is built locally, and the data are centered and whitenedto improve both their stationarity and signal-to-noise ratio (SNR). Aconvolutional neural network (CNN) is then trained in a supervised fashion todetect the residual signature of synthetic sources in the pre-processed images.Our method leads to a better trade-off between precision and recall thanstandard approaches in the field. It also outperforms a state-of-the-artalgorithm based solely on a statistical framework. Besides, the exploitation ofthe spectral diversity improves the performance compared to a similar modelbuilt solely from spatio-temporal data.</description><author>Olivier Flasseur, Th√©o Bodrito, Julien Mairal, Jean Ponce, Maud Langlois, Anne-Marie Lagrange</author><pubDate>Wed, 21 Jun 2023 14:42:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12266v1</guid></item><item><title>Automatic Speech Disentanglement for Voice Conversion using Rank Module and Speech Augmentation</title><link>http://arxiv.org/abs/2306.12259v1</link><description>Voice Conversion (VC) converts the voice of a source speech to that of atarget while maintaining the source's content. Speech can be mainly decomposedinto four components: content, timbre, rhythm and pitch. Unfortunately, mostrelated works only take into account content and timbre, which results in lessnatural speech. Some recent works are able to disentangle speech into severalcomponents, but they require laborious bottleneck tuning or varioushand-crafted features, each assumed to contain disentangled speech information.In this paper, we propose a VC model that can automatically disentangle speechinto four components using only two augmentation functions, without therequirement of multiple hand-crafted features or laborious bottleneck tuning.The proposed model is straightforward yet efficient, and the empirical resultsdemonstrate that our model can achieve a better performance than the baseline,regarding disentanglement effectiveness and speech naturalness.</description><author>Zhonghua Liu, Shijun Wang, Ning Chen</author><pubDate>Wed, 21 Jun 2023 14:28:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12259v1</guid></item><item><title>Solving and Generating NPR Sunday Puzzles with Large Language Models</title><link>http://arxiv.org/abs/2306.12255v1</link><description>We explore the ability of large language models to solve and generate puzzlesfrom the NPR Sunday Puzzle game show using PUZZLEQA, a dataset comprising 15years of on-air puzzles. We evaluate four large language models using PUZZLEQA,in both multiple choice and free response formats, and explore two promptengineering techniques to improve free response performance: chain-of-thoughtreasoning and prompt summarization. We find that state-of-the-art largelanguage models can solve many PUZZLEQA puzzles: the best model, GPT-3.5,achieves 50.2% loose accuracy. However, in our few-shot puzzle generationexperiment, we find no evidence that models can generate puzzles: GPT-3.5generates puzzles with answers that do not conform to the generated rules.Puzzle generation remains a challenging task for future work.</description><author>Jingmiao Zhao, Carolyn Jane Anderson</author><pubDate>Wed, 21 Jun 2023 14:23:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12255v1</guid></item><item><title>GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection</title><link>http://arxiv.org/abs/2306.12251v1</link><description>With a long history of traditional Graph Anomaly Detection (GAD) algorithmsand recently popular Graph Neural Networks (GNNs), it is still not clear (1)how they perform under a standard comprehensive setting, (2) whether GNNsoutperform traditional algorithms such as tree ensembles, and (3) theirefficiency on large-scale graphs. In response, we present GADBench -- acomprehensive benchmark for supervised anomalous node detection on staticgraphs. GADBench provides a thorough comparison across 23 distinct models onten real-world GAD datasets ranging from thousands to millions of nodes($\sim$6M). Our main finding is that tree ensembles with simple neighborhoodaggregation outperform all other baselines, including the latest GNNs tailoredfor the GAD task. By making GADBench available as an open-source tool, we offerpivotal insights into the current advancements of GAD and establish a solidfoundation for future research. Our code is available athttps://github.com/squareRoot3/GADBench.</description><author>Jianheng Tang, Fengrui Hua, Ziqi Gao, Peilin Zhao, Jia Li</author><pubDate>Wed, 21 Jun 2023 14:16:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12251v1</guid></item><item><title>Handling Wikidata Qualifiers in Reasoning</title><link>http://arxiv.org/abs/2304.03375v2</link><description>Wikidata is a knowledge graph increasingly adopted by many communities fordiverse applications. Wikidata statements are annotated with qualifier-valuepairs that are used to depict information, such as the validity context of thestatement, its causality, provenances, etc. Handling the qualifiers inreasoning is a challenging problem. When defining inference rules (inparticular, rules on ontological properties (x subclass of y, z instance of x,etc.)), one must consider the qualifiers, as most of them participate in thesemantics of the statements. This poses a complex problem because a) there is amassive number of qualifiers, and b) the qualifiers of the inferred statementare often a combination of the qualifiers in the rule condition. In this work,we propose to address this problem by a) defining a categorization of thequalifiers b) formalizing the Wikidata model with a many-sorted logicallanguage; the sorts of this language are the qualifier categories. We couplethis logic with an algebraic specification that provides a means foreffectively handling qualifiers in inference rules. Using Wikidata ontologicalproperties, we show how to use the MSL and specification to reason onqualifiers. Finally, we discuss the methodology for practically implementingthe work and present a prototype implementation. The work can be naturallyextended, thanks to the extensibility of the many-sorted algebraicspecification, to cover more qualifiers in the specification, such as uncertaintime, recurring events, geographic locations, and others.</description><author>Sahar Aljalbout, Gilles Falquet, Didier Buchs</author><pubDate>Wed, 21 Jun 2023 14:12:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03375v2</guid></item><item><title>Knowledge-based Multimodal Music Similarity</title><link>http://arxiv.org/abs/2306.12249v1</link><description>Music similarity is an essential aspect of music retrieval, recommendationsystems, and music analysis. Moreover, similarity is of vital interest formusic experts, as it allows studying analogies and influences among composersand historical periods. Current approaches to musical similarity rely mainly onsymbolic content, which can be expensive to produce and is not always readilyavailable. Conversely, approaches using audio signals typically fail to provideany insight about the reasons behind the observed similarity. This researchaddresses the limitations of current approaches by focusing on the study ofmusical similarity using both symbolic and audio content. The aim of thisresearch is to develop a fully explainable and interpretable system that canprovide end-users with more control and understanding of music similarity andclassification systems.</description><author>Andrea Poltronieri</author><pubDate>Wed, 21 Jun 2023 14:12:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12249v1</guid></item><item><title>Bidirectional End-to-End Learning of Retriever-Reader Paradigm for Entity Linking</title><link>http://arxiv.org/abs/2306.12245v1</link><description>Entity Linking (EL) is a fundamental task for Information Extraction andKnowledge Graphs. The general form of EL (i.e., end-to-end EL) aims to firstfind mentions in the given input document and then link the mentions tocorresponding entities in a specific knowledge base. Recently, the paradigm ofretriever-reader promotes the progress of end-to-end EL, benefiting from theadvantages of dense entity retrieval and machine reading comprehension.However, the existing study only trains the retriever and the reader separatelyin a pipeline manner, which ignores the benefit that the interaction betweenthe retriever and the reader can bring to the task. To advance theretriever-reader paradigm to perform more perfectly on end-to-end EL, wepropose BEER$^2$, a Bidirectional End-to-End training framework for Retrieverand Reader. Through our designed bidirectional end-to-end training, BEER$^2$guides the retriever and the reader to learn from each other, make progresstogether, and ultimately improve EL performance. Extensive experiments onbenchmarks of multiple domains demonstrate the effectiveness of our proposedBEER$^2$.</description><author>Yinghui Li, Yong Jiang, Shen Huang, Xingyu Lu, Yangning Li, Pengjun Xie, Fei Huang, Hai-Tao Zheng</author><pubDate>Wed, 21 Jun 2023 14:04:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12245v1</guid></item><item><title>Discovering Intrinsic Spatial-Temporal Logic Rules to Explain Human Actions</title><link>http://arxiv.org/abs/2306.12244v1</link><description>We propose a logic-informed knowledge-driven modeling framework for humanmovements by analyzing their trajectories. Our approach is inspired by the factthat human actions are usually driven by their intentions or desires, and areinfluenced by environmental factors such as the spatial relationships withsurrounding objects. In this paper, we introduce a set of spatial-temporallogic rules as knowledge to explain human actions. These rules will beautomatically discovered from observational data. To learn the model parametersand the rule content, we design an expectation-maximization (EM) algorithm,which treats the rule content as latent variables. The EM algorithm alternatesbetween the E-step and M-step: in the E-step, the posterior distribution overthe latent rule content is evaluated; in the M-step, the rule generator andmodel parameters are jointly optimized by maximizing the current expectedlog-likelihood. Our model may have a wide range of applications in areas suchas sports analytics, robotics, and autonomous cars, where understanding humanmovements are essential. We demonstrate the model's superior interpretabilityand prediction performance on pedestrian and NBA basketball player datasets,both achieving promising results.</description><author>Chengzhi Cao, Chao Yang, Shuang Li</author><pubDate>Wed, 21 Jun 2023 14:04:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12244v1</guid></item><item><title>Inter-Instance Similarity Modeling for Contrastive Learning</title><link>http://arxiv.org/abs/2306.12243v1</link><description>The existing contrastive learning methods widely adopt one-hot instancediscrimination as pretext task for self-supervised learning, which inevitablyneglects rich inter-instance similarities among natural images, then leading topotential representation degeneration. In this paper, we propose a novel imagemix method, PatchMix, for contrastive learning in Vision Transformer (ViT), tomodel inter-instance similarities among images. Following the nature of ViT, werandomly mix multiple images from mini-batch in patch level to construct mixedimage patch sequences for ViT. Compared to the existing sample mix methods, ourPatchMix can flexibly and efficiently mix more than two images and simulatemore complicated similarity relations among natural images. In this manner, ourcontrastive framework can significantly reduce the gap between contrastiveobjective and ground truth in reality. Experimental results demonstrate thatour proposed method significantly outperforms the previous state-of-the-art onboth ImageNet-1K and CIFAR datasets, e.g., 3.0% linear accuracy improvement onImageNet-1K and 8.7% kNN accuracy improvement on CIFAR100. Moreover, our methodachieves the leading transfer performance on downstream tasks, object detectionand instance segmentation on COCO dataset. The code is available athttps://github.com/visresearch/patchmix.</description><author>Chengchao Shen, Dawei Liu, Hao Tang, Zhe Qu, Jianxin Wang</author><pubDate>Wed, 21 Jun 2023 14:03:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12243v1</guid></item><item><title>Concurrent ischemic lesion age estimation and segmentation of CT brain using a Transformer-based network</title><link>http://arxiv.org/abs/2306.12242v1</link><description>The cornerstone of stroke care is expedient management that varies dependingon the time since stroke onset. Consequently, clinical decision making iscentered on accurate knowledge of timing and often requires a radiologist tointerpret Computed Tomography (CT) of the brain to confirm the occurrence andage of an event. These tasks are particularly challenging due to the subtleexpression of acute ischemic lesions and the dynamic nature of theirappearance. Automation efforts have not yet applied deep learning to estimatelesion age and treated these two tasks independently, so, have overlooked theirinherent complementary relationship. To leverage this, we propose a novelend-to-end multi-task transformer-based network optimized for concurrentsegmentation and age estimation of cerebral ischemic lesions. By utilizinggated positional self-attention and CT-specific data augmentation, the proposedmethod can capture long-range spatial dependencies while maintaining itsability to be trained from scratch under low-data regimes commonly found inmedical imaging. Furthermore, to better combine multiple predictions, weincorporate uncertainty by utilizing quantile loss to facilitate estimating aprobability density function of lesion age. The effectiveness of our model isthen extensively evaluated on a clinical dataset consisting of 776 CT imagesfrom two medical centers. Experimental results demonstrate that our methodobtains promising performance, with an area under the curve (AUC) of 0.933 forclassifying lesion ages &lt;=4.5 hours compared to 0.858 using a conventionalapproach, and outperforms task-specific state-of-the-art algorithms.</description><author>Adam Marcus, Paul Bentley, Daniel Rueckert</author><pubDate>Wed, 21 Jun 2023 14:00:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12242v1</guid></item><item><title>Predicting protein variants with equivariant graph neural networks</title><link>http://arxiv.org/abs/2306.12231v1</link><description>Pre-trained models have been successful in many protein engineering tasks.Most notably, sequence-based models have achieved state-of-the-art performanceon protein fitness prediction while structure-based models have been usedexperimentally to develop proteins with enhanced functions. However, there is aresearch gap in comparing structure- and sequence-based methods for predictingprotein variants that are better than the wildtype protein. This paper aims toaddress this gap by conducting a comparative study between the abilities ofequivariant graph neural networks (EGNNs) and sequence-based approaches toidentify promising amino-acid mutations. The results show that our proposedstructural approach achieves a competitive performance to sequence-basedmethods while being trained on significantly fewer molecules. Additionally, wefind that combining assay labelled data with structure pre-trained modelsyields similar trends as with sequence pre-trained models.</description><author>Antonia Boca, Simon Mathis</author><pubDate>Wed, 21 Jun 2023 13:44:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12231v1</guid></item><item><title>Fantastic Weights and How to Find Them: Where to Prune in Dynamic Sparse Training</title><link>http://arxiv.org/abs/2306.12230v1</link><description>Dynamic Sparse Training (DST) is a rapidly evolving area of research thatseeks to optimize the sparse initialization of a neural network by adapting itstopology during training. It has been shown that under specific conditions, DSTis able to outperform dense models. The key components of this framework arethe pruning and growing criteria, which are repeatedly applied during thetraining process to adjust the network's sparse connectivity. While the growingcriterion's impact on DST performance is relatively well studied, the influenceof the pruning criterion remains overlooked. To address this issue, we designand perform an extensive empirical analysis of various pruning criteria tobetter understand their effect on the dynamics of DST solutions. Surprisingly,we find that most of the studied methods yield similar results. The differencesbecome more significant in the low-density regime, where the best performanceis predominantly given by the simplest technique: magnitude-based pruning. Thecode is provided at https://github.com/alooow/fantastic_weights_paper</description><author>Aleksandra I. Nowak, Bram Grooten, Decebal Constantin Mocanu, Jacek Tabor</author><pubDate>Wed, 21 Jun 2023 13:43:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12230v1</guid></item><item><title>Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors</title><link>http://arxiv.org/abs/2211.13224v2</link><description>Recently, text-to-image diffusion models have shown remarkable capabilitiesin creating realistic images from natural language prompts. However, few workshave explored using these models for semantic localization or grounding. Inthis work, we explore how an off-the-shelf text-to-image diffusion model,trained without exposure to localization information, can ground varioussemantic phrases without segmentation-specific re-training. We introduce aninference time optimization process capable of generating segmentation masksconditioned on natural language prompts. Our proposal, Peekaboo, is afirst-of-its-kind zero-shot, open-vocabulary, unsupervised semantic groundingtechnique leveraging diffusion models without any training. We evaluatePeekaboo on the Pascal VOC dataset for unsupervised semantic segmentation andthe RefCOCO dataset for referring segmentation, showing results competitivewith promising results. We also demonstrate how Peekaboo can be used togenerate images with transparency, even though the underlying diffusion modelwas only trained on RGB images - which to our knowledge we are the first toattempt. Please see our project page, including our code:https://ryanndagreat.github.io/peekaboo</description><author>Ryan Burgert, Kanchana Ranasinghe, Xiang Li, Michael S. Ryoo</author><pubDate>Wed, 21 Jun 2023 13:35:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.13224v2</guid></item><item><title>MutateNN: Mutation Testing of Image Recognition Models Deployed on Hardware Accelerators</title><link>http://arxiv.org/abs/2306.01697v2</link><description>With the research advancement of Artificial Intelligence in the last years,there are new opportunities to mitigate real-world problems and advancetechnologically. Image recognition models in particular, are assigned withperception tasks to mitigate complex real-world challenges and lead to newsolutions. Furthermore, the computational complexity and demand for resourcesof such models has also increased. To mitigate this, model optimization andhardware acceleration has come into play, but effectively integrating suchconcepts is a challenging and error-prone process. In order to allow developers and researchers to explore the robustness ofdeep learning image recognition models deployed on different hardwareacceleration devices, we propose MutateNN, a tool that provides mutationtesting and analysis capabilities for that purpose. To showcase itscapabilities, we utilized 21 mutations for 7 widely-known pre-trained deepneural network models. We deployed our mutants on 4 different devices ofvarying computational capabilities and observed discrepancies in mutantsrelated to conditional operations, as well as some unstable behaviour withthose related to arithmetic types.</description><author>Nikolaos Louloudakis, Perry Gibson, Jos√© Cano, Ajitha Rajan</author><pubDate>Wed, 21 Jun 2023 13:27:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01697v2</guid></item><item><title>Learning Interpretable Microscopic Features of Tumor by Multi-task Adversarial CNNs To Improve Generalization</title><link>http://arxiv.org/abs/2008.01478v3</link><description>Adopting Convolutional Neural Networks (CNNs) in the daily routine of primarydiagnosis requires not only near-perfect precision, but also a sufficientdegree of generalization to data acquisition shifts and transparency. ExistingCNN models act as black boxes, not ensuring to the physicians that importantdiagnostic features are used by the model. Building on top of successfullyexisting techniques such as multi-task learning, domain adversarial trainingand concept-based interpretability, this paper addresses the challenge ofintroducing diagnostic factors in the training objectives. Here we show thatour architecture, by learning end-to-end an uncertainty-based weightingcombination of multi-task and adversarial losses, is encouraged to focus onpathology features such as density and pleomorphism of nuclei, e.g. variationsin size and appearance, while discarding misleading features such as stainingdifferences. Our results on breast lymph node tissue show significantlyimproved generalization in the detection of tumorous tissue, with best averageAUC 0.89 (0.01) against the baseline AUC 0.86 (0.005). By applying theinterpretability technique of linearly probing intermediate representations, wealso demonstrate that interpretable pathology features such as nuclei densityare learned by the proposed CNN architecture, confirming the increasedtransparency of this model. This result is a starting point towards buildinginterpretable multi-task architectures that are robust to data heterogeneity.Our code is available at https://github.com/maragraziani/multitask_adversarial</description><author>Mara Graziani, Sebastian Otalora, Stephane Marchand-Maillet, Henning Muller, Vincent Andrearczyk</author><pubDate>Wed, 21 Jun 2023 13:25:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2008.01478v3</guid></item><item><title>Bayes-optimal Learning of Deep Random Networks of Extensive-width</title><link>http://arxiv.org/abs/2302.00375v2</link><description>We consider the problem of learning a target function corresponding to adeep, extensive-width, non-linear neural network with random Gaussian weights.We consider the asymptotic limit where the number of samples, the inputdimension and the network width are proportionally large. We propose aclosed-form expression for the Bayes-optimal test error, for regression andclassification tasks. We further compute closed-form expressions for the testerrors of ridge regression, kernel and random features regression. We find, inparticular, that optimally regularized ridge regression, as well as kernelregression, achieve Bayes-optimal performances, while the logistic loss yieldsa near-optimal test error for classification. We further show numerically thatwhen the number of samples grows faster than the dimension, ridge and kernelmethods become suboptimal, while neural networks achieve test error close tozero from quadratically many samples.</description><author>Hugo Cui, Florent Krzakala, Lenka Zdeborov√°</author><pubDate>Wed, 21 Jun 2023 13:24:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00375v2</guid></item><item><title>Lumbar spine segmentation in MR images: a dataset and a public benchmark</title><link>http://arxiv.org/abs/2306.12217v1</link><description>This paper presents a large publicly available multi-center lumbar spinemagnetic resonance imaging (MRI) dataset with reference segmentations ofvertebrae, intervertebral discs (IVDs), and spinal canal. The dataset includes447 sagittal T1 and T2 MRI series from 218 patients with a history of low backpain. It was collected from four different hospitals and was divided into atraining (179 patients) and validation (39 patients) set. An iterative dataannotation approach was used by training a segmentation algorithm on a smallpart of the dataset, enabling semi-automatic segmentation of the remainingimages. The algorithm provided an initial segmentation, which was subsequentlyreviewed, manually corrected, and added to the training data. We providereference performance values for this baseline algorithm and nnU-Net, whichperformed comparably. We set up a continuous segmentation challenge to allowfor a fair comparison of different segmentation algorithms. This study mayencourage wider collaboration in the field of spine segmentation, and improvethe diagnostic value of lumbar spine MRI.</description><author>Jasper W. van der Graaf, Miranda L. van Hooff, Constantinus F. M. Buckens, Matthieu Rutten, Job L. C. van Susante, Robert Jan Kroeze, Marinus de Kleuver, Bram van Ginneken, Nikolas Lessmann</author><pubDate>Wed, 21 Jun 2023 13:19:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12217v1</guid></item><item><title>Automated Machine Learning for Remaining Useful Life Predictions</title><link>http://arxiv.org/abs/2306.12215v1</link><description>Being able to predict the remaining useful life (RUL) of an engineeringsystem is an important task in prognostics and health management. Recently,data-driven approaches to RUL predictions are becoming prevalent overmodel-based approaches since no underlying physical knowledge of theengineering system is required. Yet, this just replaces required expertise ofthe underlying physics with machine learning (ML) expertise, which is oftenalso not available. Automated machine learning (AutoML) promises to buildend-to-end ML pipelines automatically enabling domain experts without MLexpertise to create their own models. This paper introduces AutoRUL, anAutoML-driven end-to-end approach for automatic RUL predictions. AutoRULcombines fine-tuned standard regression methods to an ensemble with highpredictive power. By evaluating the proposed method on eight real-world andsynthetic datasets against state-of-the-art hand-crafted models, we show thatAutoML provides a viable alternative to hand-crafted data-driven RULpredictions. Consequently, creating RUL predictions can be made more accessiblefor domain experts using AutoML by eliminating ML expertise from data-drivenmodel construction.</description><author>Marc-Andr√© Z√∂ller, Fabian Mauthe, Peter Zeiler, Marius Lindauer, Marco F. Huber</author><pubDate>Wed, 21 Jun 2023 13:15:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12215v1</guid></item><item><title>More PAC-Bayes bounds: From bounded losses, to losses with general tail behaviors, to anytime-validity</title><link>http://arxiv.org/abs/2306.12214v1</link><description>In this paper, we present new high-probability PAC-Bayes bounds for differenttypes of losses. Firstly, for losses with a bounded range, we present astrengthened version of Catoni's bound that holds uniformly for all parametervalues. This leads to new fast rate and mixed rate bounds that areinterpretable and tighter than previous bounds in the literature. Secondly, forlosses with more general tail behaviors, we introduce two new parameter-freebounds: a PAC-Bayes Chernoff analogue when the loss' cumulative generatingfunction is bounded, and a bound when the loss' second moment is bounded. Thesetwo bounds are obtained using a new technique based on a discretization of thespace of possible events for the "in probability" parameter optimizationproblem. Finally, we extend all previous results to anytime-valid bounds usinga simple technique applicable to any existing bound.</description><author>Borja Rodr√≠guez-G√°lvez, Ragnar Thobaben, Mikael Skoglund</author><pubDate>Wed, 21 Jun 2023 13:13:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12214v1</guid></item><item><title>Limits for Learning with Language Models</title><link>http://arxiv.org/abs/2306.12213v1</link><description>With the advent of large language models (LLMs), the trend in NLP has been totrain LLMs on vast amounts of data to solve diverse language understanding andgeneration tasks. The list of LLM successes is long and varied. Nevertheless,several recent papers provide empirical evidence that LLMs fail to captureimportant aspects of linguistic meaning. Focusing on universal quantification,we provide a theoretical foundation for these empirical findings by provingthat LLMs cannot learn certain fundamental semantic properties includingsemantic entailment and consistency as they are defined in formal semantics.More generally, we show that LLMs are unable to learn concepts beyond the firstlevel of the Borel Hierarchy, which imposes severe limits on the ability ofLMs, both large and small, to capture many aspects of linguistic meaning. Thismeans that LLMs will continue to operate without formal guarantees on tasksthat require entailments and deep linguistic understanding.</description><author>Nicholas Asher, Swarnadeep Bhar, Akshay Chaturvedi, Julie Hunter, Soumya Paul</author><pubDate>Wed, 21 Jun 2023 13:11:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12213v1</guid></item><item><title>MimiC: Combating Client Dropouts in Federated Learning by Mimicking Central Updates</title><link>http://arxiv.org/abs/2306.12212v1</link><description>Federated learning (FL) is a promising framework for privacy-preservingcollaborative learning. In FL, the model training tasks are distributed toclients and only the model updates need to be collected at a central server.However, when being deployed at the mobile edge network, clients (e.g.,smartphones and wearables) may have unpredictable availability and randomlydrop out of any training iteration, which hinders FL from achieving theconvergence. This paper tackles such a critical challenge of FL. In particular,we first investigate the convergence of the classical FedAvg algorithm witharbitrary client dropouts. We find that with the common choice of a decayinglearning rate, FedAvg can only oscillate within the neighborhood of astationary point of the global loss function, which is caused by the divergencebetween the aggregated update and the desired central update. Motivated by thisnew observation, we then design a novel training algorithm named MimiC, wherethe server modifies each received model update based on the previous ones. Theproposed modification of the received model updates is able to mimic theimaginary central update irrespective of the dropout clients. The theoreticalanalysis of MimiC shows that the divergence between the aggregated update andthe central update diminishes with a proper choice of the learning rates,leading to its convergence. Simulation results further demonstrate that MimiCmaintains stable convergence performance in the presence of client dropouts andlearns better models than the baseline methods.</description><author>Yuchang Sun, Yuyi Mao, Jun Zhang</author><pubDate>Wed, 21 Jun 2023 13:11:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12212v1</guid></item><item><title>Equivariant Differentially Private Deep Learning: Why DP-SGD Needs Sparser Models</title><link>http://arxiv.org/abs/2301.13104v2</link><description>Differentially Private Stochastic Gradient Descent (DP-SGD) limits the amountof private information deep learning models can memorize during training. Thisis achieved by clipping and adding noise to the model's gradients, and thusnetworks with more parameters require proportionally stronger perturbation. Asa result, large models have difficulties learning useful information, renderingtraining with DP-SGD exceedingly difficult on more challenging training tasks.Recent research has focused on combating this challenge through trainingadaptations such as heavy data augmentation and large batch sizes. However,these techniques further increase the computational overhead of DP-SGD andreduce its practical applicability. In this work, we propose using theprinciple of sparse model design to solve precisely such complex tasks withfewer parameters, higher accuracy, and in less time, thus serving as apromising direction for DP-SGD. We achieve such sparsity by design byintroducing equivariant convolutional networks for model training withDifferential Privacy. Using equivariant networks, we show that small andefficient architecture design can outperform current state-of-the-art modelswith substantially lower computational requirements. On CIFAR-10, we achieve anincrease of up to $9\%$ in accuracy while reducing the computation time by morethan $85\%$. Our results are a step towards efficient model architectures thatmake optimal use of their parameters and bridge the privacy-utility gap betweenprivate and non-private deep learning for computer vision.</description><author>Florian A. H√∂lzl, Daniel Rueckert, Georgios Kaissis</author><pubDate>Wed, 21 Jun 2023 13:03:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13104v2</guid></item><item><title>Investigating Pre-trained Language Models on Cross-Domain Datasets, a Step Closer to General AI</title><link>http://arxiv.org/abs/2306.12205v1</link><description>Pre-trained language models have recently emerged as a powerful tool forfine-tuning a variety of language tasks. Ideally, when models are pre-trainedon large amount of data, they are expected to gain implicit knowledge. In thispaper, we investigate the ability of pre-trained language models to generalizeto different non-language tasks. In particular, we test them on tasks fromdifferent domains such as computer vision, reasoning on hierarchical data, andprotein fold prediction. The four pre-trained models that we used, T5, BART,BERT, and GPT-2 achieve outstanding results. They all have similar performanceand they outperform transformers that are trained from scratch by a largemargin. For instance, pre-trained language models perform better on the Listopsdataset, with an average accuracy of 58.7\%, compared to transformers trainedfrom scratch, which have an average accuracy of 29.0\%. The significantimprovement demonstrated across three types of datasets suggests thatpre-training on language helps the models to acquire general knowledge,bringing us a step closer to general AI. We also showed that reducing thenumber of parameters in pre-trained language models does not have a greatimpact as the performance drops slightly when using T5-Small instead ofT5-Base. In fact, when using only 2\% of the parameters, we achieved a greatimprovement compared to training from scratch. Finally, in contrast to priorwork, we find out that using pre-trained embeddings for the input layer isnecessary to achieve the desired results.</description><author>Mohamad Ballout, Ulf Krumnack, Gunther Heidemann, Kai-Uwe K√ºhnberger</author><pubDate>Wed, 21 Jun 2023 12:55:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12205v1</guid></item><item><title>Polygon Detection for Room Layout Estimation using Heterogeneous Graphs and Wireframes</title><link>http://arxiv.org/abs/2306.12203v1</link><description>This paper presents a neural network based semantic plane detection methodutilizing polygon representations. The method can for example be used to solveroom layout estimations tasks. The method is built on, combines and furtherdevelops several different modules from previous research. The network takes anRGB image and estimates a wireframe as well as a feature space using anhourglass backbone. From these, line and junction features are sampled. Thelines and junctions are then represented as an undirected graph, from whichpolygon representations of the sought planes are obtained. Two differentmethods for this last step are investigated, where the most promising method isbuilt on a heterogeneous graph transformer. The final output is in all cases aprojection of the semantic planes in 2D. The methods are evaluated on theStructured 3D dataset and we investigate the performance both using sampled andestimated wireframes. The experiments show the potential of the graph-basedmethod by outperforming state of the art methods in Room Layout estimation inthe 2D metrics using synthetic wireframe detections.</description><author>David Gillsj√∂, Gabrielle Flood, Kalle √Östr√∂m</author><pubDate>Wed, 21 Jun 2023 12:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12203v1</guid></item><item><title>Opening the Black Box: Analyzing Attention Weights and Hidden States in Pre-trained Language Models for Non-language Tasks</title><link>http://arxiv.org/abs/2306.12198v1</link><description>Investigating deep learning language models has always been a significantresearch area due to the ``black box" nature of most advanced models. With therecent advancements in pre-trained language models based on transformers andtheir increasing integration into daily life, addressing this issue has becomemore pressing. In order to achieve an explainable AI model, it is essential tocomprehend the procedural steps involved and compare them with human thoughtprocesses. Thus, in this paper, we use simple, well-understood non-languagetasks to explore these models' inner workings. Specifically, we apply apre-trained language model to constrained arithmetic problems with hierarchicalstructure, to analyze their attention weight scores and hidden states. Theinvestigation reveals promising results, with the model addressing hierarchicalproblems in a moderately structured manner, similar to human problem-solvingstrategies. Additionally, by inspecting the attention weights layer by layer,we uncover an unconventional finding that layer 10, rather than the model'sfinal layer, is the optimal layer to unfreeze for the least parameter-intensiveapproach to fine-tune the model. We support these findings with entropyanalysis and token embeddings similarity analysis. The attention analysisallows us to hypothesize that the model can generalize to longer sequences inListOps dataset, a conclusion later confirmed through testing on sequenceslonger than those in the training set. Lastly, by utilizing a straightforwardtask in which the model predicts the winner of a Tic Tac Toe game, we identifylimitations in attention analysis, particularly its inability to capture 2Dpatterns.</description><author>Mohamad Ballout, Ulf Krumnack, Gunther Heidemann, Kai-Uwe K√ºhnberger</author><pubDate>Wed, 21 Jun 2023 12:48:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12198v1</guid></item><item><title>Split Learning in 6G Edge Networks</title><link>http://arxiv.org/abs/2306.12194v1</link><description>With the proliferation of distributed edge computing resources, the 6G mobilenetwork will evolve into a network for connected intelligence. Along this line,the proposal to incorporate federated learning into the mobile edge has gainedconsiderable interest in recent years. However, the deployment of federatedlearning faces substantial challenges as massive resource-limited IoT devicescan hardly support on-device model training. This leads to the emergence ofsplit learning (SL) which enables servers to handle the major training workloadwhile still enhancing data privacy. In this article, we offer a brief overviewof key advancements in SL and articulate its seamless integration with wirelessedge networks. We begin by illustrating the tailored 6G architecture to supportedge SL. Then, we examine the critical design issues for edge SL, includinginnovative resource-efficient learning frameworks and resource managementstrategies under a single edge server. Additionally, we expand the scope tomulti-edge scenarios, exploring multi-edge collaboration and mobilitymanagement from a networking perspective. Finally, we discuss open problems foredge SL, including convergence analysis, asynchronous SL and U-shaped SL.</description><author>Zheng Lin, Guanqiao Qu, Xianhao Chen, Kaibin Huang</author><pubDate>Wed, 21 Jun 2023 12:42:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12194v1</guid></item><item><title>Quantifying lottery tickets under label noise: accuracy, calibration, and complexity</title><link>http://arxiv.org/abs/2306.12190v1</link><description>Pruning deep neural networks is a widely used strategy to alleviate thecomputational burden in machine learning. Overwhelming empirical evidencesuggests that pruned models retain very high accuracy even with a tiny fractionof parameters. However, relatively little work has gone into characterising thesmall pruned networks obtained, beyond a measure of their accuracy. In thispaper, we use the sparse double descent approach to identify univocally andcharacterise pruned models associated with classification tasks. We observeempirically that, for a given task, iterative magnitude pruning (IMP) tends toconverge to networks of comparable sizes even when starting from full networkswith sizes ranging over orders of magnitude. We analyse the best pruned modelsin a controlled experimental setup and show that their number of parametersreflects task difficulty and that they are much better than full networks atcapturing the true conditional probability distribution of the labels. On realdata, we similarly observe that pruned models are less prone to overconfidentpredictions. Our results suggest that pruned models obtained via IMP not onlyhave advantageous computational properties but also provide a betterrepresentation of uncertainty in learning.</description><author>Viplove Arora, Daniele Irto, Sebastian Goldt, Guido Sanguinetti</author><pubDate>Wed, 21 Jun 2023 12:35:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12190v1</guid></item><item><title>Annotating Ambiguous Images: General Annotation Strategy for Image Classification with Real-World Biomedical Validation on Vertebral Fracture Diagnosis</title><link>http://arxiv.org/abs/2306.12189v1</link><description>While numerous methods exist to solve classification problems within curateddatasets, these solutions often fall short in biomedical applications due tothe biased or ambiguous nature of the data. These difficulties are particularlyevident when inferring height reduction from vertebral data, a key component ofthe clinically-recognized Genant score. Although strategies such assemi-supervised learning, proposal usage, and class blending may provide someresolution, a clear and superior solution remains elusive. This paperintroduces a flowchart of general strategy to address these issues. Wedemonstrate the application of this strategy by constructing a vertebralfracture dataset with over 300,000 annotations. This work facilitates thetransition of the classification problem into clinically meaningful scores andenriches our understanding of vertebral height reduction.</description><author>Lars Schmarje, Vasco Grossmann, Claudius Zelenka, Reinhard Koch</author><pubDate>Wed, 21 Jun 2023 12:35:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12189v1</guid></item><item><title>Facial Expression Re-targeting from a Single Character</title><link>http://arxiv.org/abs/2306.12188v1</link><description>Video retargeting for digital face animation is used in virtual reality,social media, gaming, movies, and video conference, aiming to animate avatars'facial expressions based on videos of human faces. The standard method torepresent facial expressions for 3D characters is by blendshapes, a vector ofweights representing the avatar's neutral shape and its variations under facialexpressions, e.g., smile, puff, blinking. Datasets of paired frames withblendshape vectors are rare, and labeling can be laborious, time-consuming, andsubjective. In this work, we developed an approach that handles the lack ofappropriate datasets. Instead, we used a synthetic dataset of only onecharacter. To generalize various characters, we re-represented each frame toface landmarks. We developed a unique deep-learning architecture that groupslandmarks for each facial organ and connects them to relevant blendshapeweights. Additionally, we incorporated complementary methods for facialexpressions that landmarks did not represent well and gave special attention toeye expressions. We have demonstrated the superiority of our approach toprevious research in qualitative and quantitative metrics. Our approachachieved a higher MOS of 68% and a lower MSE of 44.2% when tested on videoswith various users and expressions.</description><author>Ariel Larey, Omri Asraf, Adam Kelder, Itzik Wilf, Ofer Kruzel, Nati Daniel</author><pubDate>Wed, 21 Jun 2023 12:35:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12188v1</guid></item><item><title>Multimodal Sentiment Analysis: A Survey</title><link>http://arxiv.org/abs/2305.07611v2</link><description>Multimodal sentiment analysis has become an important research area in thefield of artificial intelligence. With the latest advances in deep learning,this technology has reached new heights. It has great potential for bothapplication and research, making it a popular research topic. This reviewprovides an overview of the definition, background, and development ofmultimodal sentiment analysis. It also covers recent datasets and advancedmodels, emphasizing the challenges and future prospects of this technology.Finally, it looks ahead to future research directions. It should be noted thatthis review provides constructive suggestions for promising research directionsand building better performing multimodal sentiment analysis models, which canhelp researchers in this field.</description><author>Songning Lai, Haoxuan Xu, Xifeng Hu, Zhaoxia Ren, Zhi Liu</author><pubDate>Wed, 21 Jun 2023 12:35:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07611v2</guid></item><item><title>Cross-Domain Car Detection Model with Integrated Convolutional Block Attention Mechanism</title><link>http://arxiv.org/abs/2305.20055v3</link><description>Car detection, particularly through camera vision, has become a major focusin the field of computer vision and has gained widespread adoption. Whilecurrent car detection systems are capable of good detection, reliable detectioncan still be challenging due to factors such as proximity between the car,light intensity, and environmental visibility. To address these issues, wepropose cross-domain Car Detection Model with integrated convolutional blockAttention mechanism(CDMA) that we apply to car recognition for autonomousdriving and other areas. CDMA includes several novelties: 1)Building a completecross-domain target detection framework. 2)Developing an unpaired target domainpicture generation module with an integrated convolutional attention mechanismwhich specifically emphasizes the car headlights feature. 3)AdoptingGeneralized Intersection over Union (GIOU) as the loss function of the targetdetection framework. 4)Designing an object detection model integrated withtwo-headed Convolutional Block Attention Module(CBAM). 5)Utilizing an effectivedata enhancement method. To evaluate the model's effectiveness, we performed areduced will resolution process on the data in the SSLAD dataset and used it asthe benchmark dataset for our task. Experimental results show that theperformance of the cross-domain car target detection model improves by 40% overthe model without our framework, and our improvements have a significant impacton cross-domain car recognition.</description><author>Haoxuan Xu, Songning Lai, Xianyang Li, Yang Yang</author><pubDate>Wed, 21 Jun 2023 12:34:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.20055v3</guid></item><item><title>Adaptive DNN Surgery for Selfish Inference Acceleration with On-demand Edge Resource</title><link>http://arxiv.org/abs/2306.12185v1</link><description>Deep Neural Networks (DNNs) have significantly improved the accuracy ofintelligent applications on mobile devices. DNN surgery, which partitions DNNprocessing between mobile devices and multi-access edge computing (MEC)servers, can enable real-time inference despite the computational limitationsof mobile devices. However, DNN surgery faces a critical challenge: determiningthe optimal computing resource demand from the server and the correspondingpartition strategy, while considering both inference latency and MEC serverusage costs. This problem is compounded by two factors: (1) the finitecomputing capacity of the MEC server, which is shared among multiple devices,leading to inter-dependent demands, and (2) the shift in modern DNNarchitecture from chains to directed acyclic graphs (DAGs), which complicatespotential solutions. In this paper, we introduce a novel Decentralized DNN Surgery (DDS)framework. We formulate the partition strategy as a min-cut and propose aresource allocation game to adaptively schedule the demands of mobile devicesin an MEC environment. We prove the existence of a Nash Equilibrium (NE), anddevelop an iterative algorithm to efficiently reach the NE for each device. Ourextensive experiments demonstrate that DDS can effectively handle varying MECscenarios, achieving up to 1.25$\times$ acceleration compared to thestate-of-the-art algorithm.</description><author>Xiang Yang, Dezhi Chen, Qi Qi, Jingyu Wang, Haifeng Sun, Jianxin Liao, Song Guo</author><pubDate>Wed, 21 Jun 2023 12:32:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12185v1</guid></item><item><title>BayLing: Bridging Cross-lingual Alignment and Instruction Following through Interactive Translation for Large Language Models</title><link>http://arxiv.org/abs/2306.10968v2</link><description>Large language models (LLMs) have demonstrated remarkable prowess in languageunderstanding and generation. Advancing from foundation LLMs toinstructionfollowing LLMs, instruction tuning plays a vital role in aligningLLMs to human preferences. However, the existing LLMs are usually focused onEnglish, leading to inferior performance in non-English languages. In order toimprove the performance for non-English languages, it is necessary to collectlanguage-specific training data for foundation LLMs and constructlanguage-specific instructions for instruction tuning, both of which are heavyloads. To minimize human workload, we propose to transfer the capabilities oflanguage generation and instruction following from English to other languagesthrough an interactive translation task. We have developed BayLing, aninstruction-following LLM by utilizing LLaMA as the foundation LLM andautomatically constructing interactive translation instructions for instructingtuning. Extensive assessments demonstrate that BayLing achieves comparableperformance to GPT-3.5-turbo, despite utilizing a considerably smallerparameter size of only 13 billion. Experimental results on translation tasksshow that BayLing achieves 95% of single-turn translation capability comparedto GPT-4 with automatic evaluation and 96% of interactive translationcapability compared to GPT-3.5-turbo with human evaluation. To estimate theperformance on general tasks, we created a multi-turn instruction test setcalled BayLing-80. The experimental results on BayLing-80 indicate that BayLingachieves 89% of performance compared to GPT-3.5-turbo. BayLing alsodemonstrates outstanding performance on knowledge assessment of Chinese GaoKaoand English SAT, second only to GPT-3.5-turbo among a multitude ofinstruction-following LLMs. Demo, homepage, code and models of BayLing areavailable.</description><author>Shaolei Zhang, Qingkai Fang, Zhuocheng Zhang, Zhengrui Ma, Yan Zhou, Langlin Huang, Mengyu Bu, Shangtong Gui, Yunji Chen, Xilin Chen, Yang Feng</author><pubDate>Wed, 21 Jun 2023 12:31:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10968v2</guid></item><item><title>Adaptive Learning Path Navigation Based on Knowledge Tracing and Reinforcement Learning</title><link>http://arxiv.org/abs/2305.04475v2</link><description>This paper introduces the Adaptive Learning Path Navigation (ALPN) system, anovel approach for enhancing E-learning platforms by providing highly adaptivelearning paths for students. The ALPN system integrates the Attentive KnowledgeTracing (AKT) model, which assesses students' knowledge states, with theproposed Entropy-enhanced Proximal Policy Optimization (EPPO) algorithm. Thisnew algorithm optimizes the recommendation of learning materials. Byharmonizing these models, the ALPN system tailors the learning path tostudents' needs, significantly increasing learning effectiveness. Experimentalresults demonstrate that the ALPN system outperforms previous research by 8.2%in maximizing learning outcomes and provides a 10.5% higher diversity ingenerating learning paths. The proposed system marks a significant advancementin adaptive E-learning, potentially transforming the educational landscape inthe digital era.</description><author>Jyun-Yi Chen, Saeed Saeedvand, I-Wei Lai</author><pubDate>Wed, 21 Jun 2023 12:31:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04475v2</guid></item><item><title>DeepIPC: Deeply Integrated Perception and Control for an Autonomous Vehicle in Real Environments</title><link>http://arxiv.org/abs/2207.09934v5</link><description>We propose DeepIPC, an end-to-end autonomous driving model that handles bothperception and control tasks in driving a vehicle. The model consists of twomain parts, perception and controller modules. The perception module takes anRGBD image to perform semantic segmentation and bird's eye view (BEV) semanticmapping along with providing their encoded features. Meanwhile, the controllermodule processes these features with the measurement of GNSS locations andangular speed to estimate waypoints that come with latent features. Then, twodifferent agents are used to translate waypoints and latent features into a setof navigational controls to drive the vehicle. The model is evaluated bypredicting driving records and performing automated driving under variousconditions in real environments. The experimental results show that DeepIPCachieves the best drivability and multi-task performance even with fewerparameters compared to the other models. Codes will be published athttps://github.com/oskarnatan/DeepIPC.</description><author>Oskar Natan, Jun Miura</author><pubDate>Wed, 21 Jun 2023 12:31:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.09934v5</guid></item><item><title>Feature Interactions Reveal Linguistic Structure in Language Models</title><link>http://arxiv.org/abs/2306.12181v1</link><description>We study feature interactions in the context of feature attribution methodsfor post-hoc interpretability. In interpretability research, getting to gripswith feature interactions is increasingly recognised as an important challenge,because interacting features are key to the success of neural networks. Featureinteractions allow a model to build up hierarchical representations for itsinput, and might provide an ideal starting point for the investigation intolinguistic structure in language models. However, uncovering the exact rolethat these interactions play is also difficult, and a diverse range ofinteraction attribution methods has been proposed. In this paper, we focus onthe question which of these methods most faithfully reflects the inner workingsof the target models. We work out a grey box methodology, in which we trainmodels to perfection on a formal language classification task, using PCFGs. Weshow that under specific configurations, some methods are indeed able touncover the grammatical rules acquired by a model. Based on these findings weextend our evaluation to a case study on language models, providing novelinsights into the linguistic structure that these models have acquired.</description><author>Jaap Jumelet, Willem Zuidema</author><pubDate>Wed, 21 Jun 2023 12:24:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12181v1</guid></item><item><title>SGEM: Test-Time Adaptation for Automatic Speech Recognition via Sequential-Level Generalized Entropy Minimization</title><link>http://arxiv.org/abs/2306.01981v4</link><description>Automatic speech recognition (ASR) models are frequently exposed to datadistribution shifts in many real-world scenarios, leading to erroneouspredictions. To tackle this issue, an existing test-time adaptation (TTA)method has recently been proposed to adapt the pre-trained ASR model onunlabeled test instances without source data. Despite decent performance gain,this work relies solely on naive greedy decoding and performs adaptation acrosstimesteps at a frame level, which may not be optimal given the sequentialnature of the model output. Motivated by this, we propose a novel TTAframework, dubbed SGEM, for general ASR models. To treat the sequential output,SGEM first exploits beam search to explore candidate output logits and selectsthe most plausible one. Then, it utilizes generalized entropy minimization andnegative sampling as unsupervised objectives to adapt the model. SGEM achievesstate-of-the-art performance for three mainstream ASR models under variousdomain shifts.</description><author>Changhun Kim, Joonhyung Park, Hajin Shim, Eunho Yang</author><pubDate>Wed, 21 Jun 2023 12:13:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01981v4</guid></item></channel></rss>