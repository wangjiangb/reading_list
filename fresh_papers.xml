<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 26 Feb 2024 06:00:53 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Seamless Human Motion Composition with Blended Positional Encodings</title><link>http://arxiv.org/abs/2402.15509v1</link><description>Conditional human motion generation is an important topic with manyapplications in virtual reality, gaming, and robotics. While prior works havefocused on generating motion guided by text, music, or scenes, these typicallyresult in isolated motions confined to short durations. Instead, we address thegeneration of long, continuous sequences guided by a series of varying textualdescriptions. In this context, we introduce FlowMDM, the first diffusion-basedmodel that generates seamless Human Motion Compositions (HMC) without anypostprocessing or redundant denoising steps. For this, we introduce the BlendedPositional Encodings, a technique that leverages both absolute and relativepositional encodings in the denoising chain. More specifically, global motioncoherence is recovered at the absolute stage, whereas smooth and realistictransitions are built at the relative stage. As a result, we achievestate-of-the-art results in terms of accuracy, realism, and smoothness on theBabel and HumanML3D datasets. FlowMDM excels when trained with only a singledescription per motion sequence thanks to its Pose-Centric Cross-ATtention,which makes it robust against varying text descriptions at inference time.Finally, to address the limitations of existing HMC metrics, we propose two newmetrics: the Peak Jerk and the Area Under the Jerk, to detect abrupttransitions.</description><author>German Barquero, Sergio Escalera, Cristina Palmero</author><pubDate>Fri, 23 Feb 2024 18:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15509v1</guid></item><item><title>AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning</title><link>http://arxiv.org/abs/2402.15506v1</link><description>Autonomous agents powered by large language models (LLMs) have garneredsignificant research attention. However, fully harnessing the potential of LLMsfor agent-based tasks presents inherent challenges due to the heterogeneousnature of diverse data sources featuring multi-turn trajectories. In thispaper, we introduce \textbf{AgentOhana} as a comprehensive solution to addressthese challenges. \textit{AgentOhana} aggregates agent trajectories fromdistinct environments, spanning a wide array of scenarios. It meticulouslystandardizes and unifies these trajectories into a consistent format,streamlining the creation of a generic data loader optimized for agenttraining. Leveraging the data unification, our training pipeline maintainsequilibrium across different data sources and preserves independent randomnessacross devices during dataset partitioning and model training. Additionally, wepresent \textbf{xLAM-v0.1}, a large action model tailored for AI agents, whichdemonstrates exceptional performance across various benchmarks.</description><author>Jianguo Zhang, Tian Lan, Rithesh Murthy, Zhiwei Liu, Weiran Yao, Juntao Tan, Thai Hoang, Liangwei Yang, Yihao Feng, Zuxin Liu, Tulika Awalgaonkar, Juan Carlos Niebles, Silvio Savarese, Shelby Heinecke, Huan Wang, Caiming Xiong</author><pubDate>Fri, 23 Feb 2024 18:56:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15506v1</guid></item><item><title>Co-Supervised Learning: Improving Weak-to-Strong Generalization with Hierarchical Mixture of Experts</title><link>http://arxiv.org/abs/2402.15505v1</link><description>Steering the behavior of a strong model pre-trained on internet-scale datacan be difficult due to the scarcity of competent supervisors. Recent studiesreveal that, despite supervisory noises, a strong student model may surpass itsweak teacher when fine-tuned on specific objectives. Yet, the effectiveness ofsuch weak-to-strong generalization remains limited, especially in the presenceof large capability gaps. In this paper, we propose to address this challengeby harnessing a diverse set of specialized teachers, instead of a singlegeneralist one, that collectively supervises the strong student. Our approachresembles the classical hierarchical mixture of experts, with two componentstailored for co-supervision: (i) we progressively alternate student trainingand teacher assignment, leveraging the growth of the strong student to identifyplausible supervisions; (ii) we conservatively enforce teacher-student andlocal-global consistency, leveraging their dependencies to reject potentialannotation noises. We validate the proposed method through visual recognitiontasks on the OpenAI weak-to-strong benchmark and additional multi-domaindatasets. Our code is available at \url{https://github.com/yuejiangliu/csl}.</description><author>Yuejiang Liu, Alexandre Alahi</author><pubDate>Fri, 23 Feb 2024 18:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15505v1</guid></item><item><title>Chain of Logic: Rule-Based Reasoning with Large Language Models</title><link>http://arxiv.org/abs/2402.10400v2</link><description>Rule-based reasoning, a fundamental type of legal reasoning, enables us todraw conclusions by accurately applying a rule to a set of facts. We explorecausal language models as rule-based reasoners, specifically with respect tocompositional rules - rules consisting of multiple elements which form acomplex logical expression. Reasoning about compositional rules is challengingbecause it requires multiple reasoning steps, and attending to the logicalrelationships between elements. We introduce a new prompting method, Chain ofLogic, which elicits rule-based reasoning through decomposition (solvingelements as independent threads of logic), and recomposition (recombining thesesub-answers to resolve the underlying logical expression). This method wasinspired by the IRAC (Issue, Rule, Application, Conclusion) framework, asequential reasoning approach used by lawyers. We evaluate chain of logicacross eight rule-based reasoning tasks involving three distinct compositionalrules from the LegalBench benchmark and demonstrate it consistently outperformsother prompting methods, including chain of thought and self-ask, usingopen-source and commercial language models.</description><author>Sergio Servantez, Joe Barrow, Kristian Hammond, Rajiv Jain</author><pubDate>Fri, 23 Feb 2024 18:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10400v2</guid></item><item><title>Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition</title><link>http://arxiv.org/abs/2402.15504v1</link><description>Recent text-to-image diffusion models are able to learn and synthesize imagescontaining novel, personalized concepts (e.g., their own pets or specificitems) with just a few examples for training. This paper tackles twointerconnected issues within this realm of personalizing text-to-imagediffusion models. First, current personalization techniques fail to reliablyextend to multiple concepts -- we hypothesize this to be due to the mismatchbetween complex scenes and simple text descriptions in the pre-training dataset(e.g., LAION). Second, given an image containing multiple personalizedconcepts, there lacks a holistic metric that evaluates performance on not justthe degree of resemblance of personalized concepts, but also whether allconcepts are present in the image and whether the image accurately reflects theoverall text description. To address these issues, we introduce Gen4Gen, asemi-automated dataset creation pipeline utilizing generative models to combinepersonalized concepts into complex compositions along with text-descriptions.Using this, we create a dataset called MyCanvas, that can be used to benchmarkthe task of multi-concept personalization. In addition, we design acomprehensive metric comprising two scores (CP-CLIP and TI-CLIP) for betterquantifying the performance of multi-concept, personalized text-to-imagediffusion methods. We provide a simple baseline built on top of CustomDiffusion with empirical prompting strategies for future researchers toevaluate on MyCanvas. We show that by improving data quality and promptingstrategies, we can significantly increase multi-concept personalized imagegeneration quality, without requiring any modifications to model architectureor training algorithms.</description><author>Chun-Hsiao Yeh, Ta-Ying Cheng, He-Yen Hsieh, Chuan-En Lin, Yi Ma, Andrew Markham, Niki Trigoni, H. T. Kung, Yubei Chen</author><pubDate>Fri, 23 Feb 2024 18:55:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15504v1</guid></item><item><title>Scalable Human-Machine Point Cloud Compression</title><link>http://arxiv.org/abs/2402.12532v3</link><description>Due to the limited computational capabilities of edge devices, deep learninginference can be quite expensive. One remedy is to compress and transmit pointcloud data over the network for server-side processing. Unfortunately, thisapproach can be sensitive to network factors, including available bitrate.Luckily, the bitrate requirements can be reduced without sacrificing inferenceaccuracy by using a machine task-specialized codec. In this paper, we present ascalable codec for point-cloud data that is specialized for the machine task ofclassification, while also providing a mechanism for human viewing. In theproposed scalable codec, the "base" bitstream supports the machine task, and an"enhancement" bitstream may be used for better input reconstruction performancefor human viewing. We base our architecture on PointNet++, and test itsefficacy on the ModelNet40 dataset. We show significant improvements over priornon-specialized codecs.</description><author>Mateen Ulhaq, Ivan V. Bajić</author><pubDate>Fri, 23 Feb 2024 18:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12532v3</guid></item><item><title>Explainable Classification Techniques for Quantum Dot Device Measurements</title><link>http://arxiv.org/abs/2402.13699v2</link><description>In the physical sciences, there is an increased need for robust featurerepresentations of image data: image acquisition, in the generalized sense oftwo-dimensional data, is now widespread across a large number of fields,including quantum information science, which we consider here. Whiletraditional image features are widely utilized in such cases, their use israpidly being supplanted by Neural Network-based techniques that oftensacrifice explainability in exchange for high accuracy. To ameliorate thistrade-off, we propose a synthetic data-based technique that results inexplainable features. We show, using Explainable Boosting Machines (EBMs), thatthis method offers superior explainability without sacrificing accuracy.Specifically, we show that there is a meaningful benefit to this technique inthe context of quantum dot tuning, where human intervention is necessary at thecurrent stage of development.</description><author>Daniel Schug, Tyler J. Kovach, M. A. Wolfe, Jared Benson, Sanghyeok Park, J. P. Dodson, J. Corrigan, M. A. Eriksson, Justyna P. Zwolak</author><pubDate>Fri, 23 Feb 2024 18:31:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13699v2</guid></item><item><title>Mechanics-Informed Autoencoder Enables Automated Detection and Localization of Unforeseen Structural Damage</title><link>http://arxiv.org/abs/2402.15492v1</link><description>Structural health monitoring (SHM) is vital for ensuring the safety andlongevity of structures like buildings and bridges. As the volume and scale ofstructures and the impact of their failure continue to grow, there is a direneed for SHM techniques that are scalable, inexpensive, operate passivelywithout human intervention, and customized for each mechanical structurewithout the need for complex baseline models. We present a novel"deploy-and-forget" approach for automated detection and localization ofdamages in structures. It is based on a synergistic combination of fullypassive measurements from inexpensive sensors and a mechanics-informedautoencoder. Once deployed, our solution continuously learns and adapts abespoke baseline model for each structure, learning from its undamaged state'sresponse characteristics. After learning from just 3 hours of data, it canautonomously detect and localize different types of unforeseen damage. Resultsfrom numerical simulations and experiments indicate that incorporating themechanical characteristics into the variational autoencoder allows for up to35\% earlier detection and localization of damage over a standard autoencoder.Our approach holds substantial promise for a significant reduction in humanintervention and inspection costs and enables proactive and preventivemaintenance strategies, thus extending the lifespan, reliability, andsustainability of civil infrastructures.</description><author>Xuyang Li, Hamed Bolandi, Mahdi Masmoudi, Talal Salem, Nizar Lajnef, Vishnu Naresh Boddeti</author><pubDate>Fri, 23 Feb 2024 18:31:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15492v1</guid></item><item><title>API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs</title><link>http://arxiv.org/abs/2402.15491v1</link><description>There is a growing need for Large Language Models (LLMs) to effectively usetools and external Application Programming Interfaces (APIs) to plan andcomplete tasks. As such, there is tremendous interest in methods that canacquire sufficient quantities of train and test data that involve calls totools / APIs. Two lines of research have emerged as the predominant strategiesfor addressing this challenge. The first has focused on synthetic datageneration techniques, while the second has involved curating task-adjacentdatasets which can be transformed into API / Tool-based tasks. In this paper,we focus on the task of identifying, curating, and transforming existingdatasets and, in turn, introduce API-BLEND, a large corpora for training andsystematic testing of tool-augmented LLMs. The datasets mimic real-worldscenarios involving API-tasks such as API / tool detection, slot filling, andsequencing of the detected APIs. We demonstrate the utility of the API-BLENDdataset for both training and benchmarking purposes.</description><author>Kinjal Basu, Ibrahim Abdelaziz, Subhajit Chaudhury, Soham Dan, Maxwell Crouse, Asim Munawar, Sadhana Kumaravel, Vinod Muthusamy, Pavan Kapanipathi, Luis A. Lastras</author><pubDate>Fri, 23 Feb 2024 18:30:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15491v1</guid></item><item><title>A Comprehensive Survey of Convolutions in Deep Learning: Applications, Challenges, and Future Trends</title><link>http://arxiv.org/abs/2402.15490v1</link><description>In today's digital age, Convolutional Neural Networks (CNNs), a subset ofDeep Learning (DL), are widely used for various computer vision tasks such asimage classification, object detection, and image segmentation. There arenumerous types of CNNs designed to meet specific needs and requirements,including 1D, 2D, and 3D CNNs, as well as dilated, grouped, attention,depthwise convolutions, and NAS, among others. Each type of CNN has its uniquestructure and characteristics, making it suitable for specific tasks. It'scrucial to gain a thorough understanding and perform a comparative analysis ofthese different CNN types to understand their strengths and weaknesses.Furthermore, studying the performance, limitations, and practical applicationsof each type of CNN can aid in the development of new and improvedarchitectures in the future. We also dive into the platforms and frameworksthat researchers utilize for their research or development from variousperspectives. Additionally, we explore the main research fields of CNN like 6Dvision, generative models, and meta-learning. This survey paper provides acomprehensive examination and comparison of various CNN architectures,highlighting their architectural differences and emphasizing their respectiveadvantages, disadvantages, applications, challenges, and future trends.</description><author>Abolfazl Younesi, Mohsen Ansari, MohammadAmin Fazli, Alireza Ejlali, Muhammad Shafique, Jörg Henkel</author><pubDate>Fri, 23 Feb 2024 18:28:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15490v1</guid></item><item><title>RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for Robotic Manipulation</title><link>http://arxiv.org/abs/2402.15487v1</link><description>Robots need to explore their surroundings to adapt to and tackle tasks inunknown environments. Prior work has proposed building scene graphs of theenvironment but typically assumes that the environment is static, omittingregions that require active interactions. This severely limits their ability tohandle more complex tasks in household and office environments: before settingup a table, robots must explore drawers and cabinets to locate all utensils andcondiments. In this work, we introduce the novel task of interactive sceneexploration, wherein robots autonomously explore environments and produce anaction-conditioned scene graph (ACSG) that captures the structure of theunderlying environment. The ACSG accounts for both low-level information, suchas geometry and semantics, and high-level information, such as theaction-conditioned relationships between different entities in the scene. Tothis end, we present the Robotic Exploration (RoboEXP) system, whichincorporates the Large Multimodal Model (LMM) and an explicit memory design toenhance our system's capabilities. The robot reasons about what and how toexplore an object, accumulating new information through the interaction processand incrementally constructing the ACSG. We apply our system across variousreal-world settings in a zero-shot manner, demonstrating its effectiveness inexploring and modeling environments it has never seen before. Leveraging theconstructed ACSG, we illustrate the effectiveness and efficiency of our RoboEXPsystem in facilitating a wide range of real-world manipulation tasks involvingrigid, articulated objects, nested objects like Matryoshka dolls, anddeformable objects like cloth.</description><author>Hanxiao Jiang, Binghao Huang, Ruihai Wu, Zhuoran Li, Shubham Garg, Hooshang Nayyeri, Shenlong Wang, Yunzhu Li</author><pubDate>Fri, 23 Feb 2024 18:27:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15487v1</guid></item><item><title>A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts</title><link>http://arxiv.org/abs/2402.09727v2</link><description>Current Large Language Models (LLMs) are not only limited to some maximumcontext length, but also are not able to robustly consume long inputs. Toaddress these limitations, we propose ReadAgent, an LLM agent system thatincreases effective context length up to 20x in our experiments. Inspired byhow humans interactively read long documents, we implement ReadAgent as asimple prompting system that uses the advanced language capabilities of LLMs to(1) decide what content to store together in a memory episode, (2) compressthose memory episodes into short episodic memories called gist memories, and(3) take actions to look up passages in the original text if ReadAgent needs toremind itself of relevant details to complete a task. We evaluate ReadAgentagainst baselines using retrieval methods, using the original long contexts,and using the gist memories. These evaluations are performed on threelong-document reading comprehension tasks: QuALITY, NarrativeQA, and QMSum.ReadAgent outperforms the baselines on all three tasks while extending theeffective context window by 3-20x.</description><author>Kuang-Huei Lee, Xinyun Chen, Hiroki Furuta, John Canny, Ian Fischer</author><pubDate>Fri, 23 Feb 2024 18:21:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09727v2</guid></item><item><title>Prejudice and Caprice: A Statistical Framework for Measuring Social Discrimination in Large Language Models</title><link>http://arxiv.org/abs/2402.15481v1</link><description>The growing integration of large language models (LLMs) into socialoperations amplifies their impact on decisions in crucial areas such aseconomics, law, education, and healthcare, raising public concerns about thesemodels' discrimination-related safety and reliability. However, priordiscrimination measuring frameworks solely assess the average discriminatorybehavior of LLMs, often proving inadequate due to the overlook of an additionaldiscrimination-leading factor, i.e., the LLMs' prediction variation acrossdiverse contexts. In this work, we present the Prejudice-Caprice Framework(PCF) that comprehensively measures discrimination in LLMs by considering boththeir consistently biased preference and preference variation across diversecontexts. Specifically, we mathematically dissect the aggregated contextualizeddiscrimination risk of LLMs into prejudice risk, originating from LLMs'persistent prejudice, and caprice risk, stemming from their generationinconsistency. In addition, we utilize a data-mining approach to gatherpreference-detecting probes from sentence skeletons, devoid of attributeindications, to approximate LLMs' applied contexts. While initially intendedfor assessing discrimination in LLMs, our proposed PCF facilitates thecomprehensive and flexible measurement of any inductive biases, includingknowledge alongside prejudice, across various modality models. We apply ourdiscrimination-measuring framework to 12 common LLMs, yielding intriguingfindings: i) modern LLMs demonstrate significant pro-male stereotypes, ii)LLMs' exhibited discrimination correlates with several social and economicfactors, iii) prejudice risk dominates the overall discrimination risk andfollows a normal distribution, and iv) caprice risk contributes minimally tothe overall risk but follows a fat-tailed distribution, suggesting that it iswild risk requiring enhanced surveillance.</description><author>Yiran Liu, Ke Yang, Zehan Qi, Xiao Liu, Yang Yu, Chengxiang Zhai</author><pubDate>Fri, 23 Feb 2024 18:15:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15481v1</guid></item><item><title>Retinotopic Mapping Enhances the Robustness of Convolutional Neural Networks</title><link>http://arxiv.org/abs/2402.15480v1</link><description>Foveated vision, a trait shared by many animals, including humans, has notbeen fully utilized in machine learning applications, despite its significantcontributions to biological visual function. This study investigates whetherretinotopic mapping, a critical component of foveated vision, can enhance imagecategorization and localization performance when integrated into deepconvolutional neural networks (CNNs). Retinotopic mapping was integrated intothe inputs of standard off-the-shelf convolutional neural networks (CNNs),which were then retrained on the ImageNet task. As expected, thelogarithmic-polar mapping improved the network's ability to handle arbitraryimage zooms and rotations, particularly for isolated objects. Surprisingly, theretinotopically mapped network achieved comparable performance inclassification. Furthermore, the network demonstrated improved classificationlocalization when the foveated center of the transform was shifted. Thisreplicates a crucial ability of the human visual system that is absent intypical convolutional neural networks (CNNs). These findings suggest thatretinotopic mapping may be fundamental to significant preattentive visualprocesses.</description><author>Jean-Nicolas Jérémie, Emmanuel Daucé, Laurent U Perrinet</author><pubDate>Fri, 23 Feb 2024 18:15:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15480v1</guid></item><item><title>Transformers are Expressive, But Are They Expressive Enough for Regression?</title><link>http://arxiv.org/abs/2402.15478v1</link><description>Transformers have become pivotal in Natural Language Processing,demonstrating remarkable success in applications like Machine Translation andSummarization. Given their widespread adoption, several works have attempted toanalyze the expressivity of Transformers. Expressivity of a neural network isthe class of functions it can approximate. A neural network is fully expressiveif it can act as a universal function approximator. We attempt to analyze thesame for Transformers. Contrary to existing claims, our findings reveal thatTransformers struggle to reliably approximate continuous functions, relying onpiecewise constant approximations with sizable intervals. The central questionemerges as: "\textit{Are Transformers truly Universal Function Approximators}?"To address this, we conduct a thorough investigation, providing theoreticalinsights and supporting evidence through experiments. Our contributions includea theoretical analysis pinpointing the root of Transformers' limitation infunction approximation and extensive experiments to verify the limitation. Byshedding light on these challenges, we advocate a refined understanding ofTransformers' capabilities.</description><author>Swaroop Nath, Harshad Khadilkar, Pushpak Bhattacharyya</author><pubDate>Fri, 23 Feb 2024 18:12:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15478v1</guid></item><item><title>Debiasing Machine Learning Models by Using Weakly Supervised Learning</title><link>http://arxiv.org/abs/2402.15477v1</link><description>We tackle the problem of bias mitigation of algorithmic decisions in asetting where both the output of the algorithm and the sensitive variable arecontinuous. Most of prior work deals with discrete sensitive variables, meaningthat the biases are measured for subgroups of persons defined by a label,leaving out important algorithmic bias cases, where the sensitive variable iscontinuous. Typical examples are unfair decisions made with respect to the ageor the financial status. In our work, we then propose a bias mitigationstrategy for continuous sensitive variables, based on the notion of endogeneitywhich comes from the field of econometrics. In addition to solve this newproblem, our bias mitigation strategy is a weakly supervised learning methodwhich requires that a small portion of the data can be measured in a fairmanner. It is model agnostic, in the sense that it does not make any hypothesison the prediction model. It also makes use of a reasonably large amount ofinput observations and their corresponding predictions. Only a small fractionof the true output predictions should be known. This therefore limits the needfor expert interventions. Results obtained on synthetic data show theeffectiveness of our approach for examples as close as possible to real-lifeapplications in econometrics.</description><author>Renan D. B. Brotto, Jean-Michel Loubes, Laurent Risser, Jean-Pierre Florens, Kenji Nose-Filho, João M. T. Romano</author><pubDate>Fri, 23 Feb 2024 18:11:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15477v1</guid></item><item><title>Leveraging Domain Knowledge for Efficient Reward Modelling in RLHF: A Case-Study in E-Commerce Opinion Summarization</title><link>http://arxiv.org/abs/2402.15473v1</link><description>Reinforcement Learning from Human Feedback (RLHF) has become a dominatingstrategy in steering Language Models (LMs) towards human values/goals. The keyto the strategy is employing a reward model ({$\varphi$}) which can reflect alatent reward model with humans. While this strategy has proven to beeffective, the training methodology requires a lot of human preferenceannotation (usually of the order of tens of thousands) to train {$\varphi$}.Such large-scale preference annotations can be achievable if the reward modelcan be ubiquitously used. However, human values/goals are subjective and dependon the nature of the task. This poses a challenge in collecting diversepreferences for downstream applications. To address this, we propose a novelmethodology to infuse domain knowledge into {$\varphi$}, which reduces the sizeof preference annotation required. We validate our approach in E-CommerceOpinion Summarization, with a significant reduction in dataset size (just $940$samples) while advancing the state-of-the-art. Our contributions include anovel Reward Modelling technique, a new dataset (PromptOpinSumm) for OpinionSummarization, and a human preference dataset (OpinPref). The proposedmethodology opens avenues for efficient RLHF, making it more adaptable todiverse applications with varying human values. We release the artifacts forusage under MIT License.</description><author>Swaroop Nath, Tejpalsingh Siledar, Sankara Sri Raghava Ravindra Muddu, Rupasai Rangaraju, Harshad Khadilkar, Pushpak Bhattacharyya, Suman Banerjee, Amey Patil, Sudhanshu Shekhar Singh, Muthusamy Chelliah, Nikesh Garera</author><pubDate>Fri, 23 Feb 2024 18:05:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15473v1</guid></item><item><title>FAIR: Filtering of Automatically Induced Rules</title><link>http://arxiv.org/abs/2402.15472v1</link><description>The availability of large annotated data can be a critical bottleneck intraining machine learning algorithms successfully, especially when applied todiverse domains. Weak supervision offers a promising alternative byaccelerating the creation of labeled training data using domain-specific rules.However, it requires users to write a diverse set of high-quality rules toassign labels to the unlabeled data. Automatic Rule Induction (ARI) approachescircumvent this problem by automatically creating rules from features on asmall labeled set and filtering a final set of rules from them. In the ARIapproach, the crucial step is to filter out a set of a high-quality usefulsubset of rules from the large set of automatically created rules. In thispaper, we propose an algorithm (Filtering of Automatically Induced Rules) tofilter rules from a large number of automatically induced rules usingsubmodular objective functions that account for the collective precision,coverage, and conflicts of the rule set. We experiment with three ARIapproaches and five text classification datasets to validate the superiorperformance of our algorithm with respect to several semi-supervised labelaggregation approaches. Further, we show that achieves statisticallysignificant results in comparison to existing rule-filtering approaches.</description><author>Divya Jyoti Bajpai, Ayush Maheshwari, Manjesh Kumar Hanawal, Ganesh Ramakrishnan</author><pubDate>Fri, 23 Feb 2024 18:04:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15472v1</guid></item><item><title>Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning</title><link>http://arxiv.org/abs/2402.13950v2</link><description>Large language models (LLMs) have been shown to perform better when asked toreason step-by-step before answering a question. However, it is unclear to whatdegree the model's final answer is faithful to the stated reasoning steps. Inthis paper, we perform a causal mediation analysis on twelve LLMs to examinehow intermediate reasoning steps generated by the LLM influence the finaloutcome and find that LLMs do not reliably use their intermediate reasoningsteps when generating an answer. To address this issue, we introduce FRODO, aframework to tailor small-sized LMs to generate correct reasoning steps androbustly reason over these steps. FRODO consists of an inference module thatlearns to generate correct reasoning steps using an implicit causal rewardfunction and a reasoning module that learns to faithfully reason over theseintermediate inferences using a counterfactual and causal preference objective.Our experiments show that FRODO significantly outperforms four competitivebaselines. Furthermore, FRODO improves the robustness and generalizationability of the reasoning LM, yielding higher performance on out-of-distributiontest sets. Finally, we find that FRODO's rationales are more faithful to itsfinal answer predictions than standard supervised fine-tuning.</description><author>Debjit Paul, Robert West, Antoine Bosselut, Boi Faltings</author><pubDate>Fri, 23 Feb 2024 18:01:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13950v2</guid></item><item><title>Efficient error and variance estimation for randomized matrix computations</title><link>http://arxiv.org/abs/2207.06342v4</link><description>Randomized matrix algorithms have become workhorse tools in scientificcomputing and machine learning. To use these algorithms safely in applications,they should be coupled with posterior error estimates to assess the quality ofthe output. To meet this need, this paper proposes two diagnostics: aleave-one-out error estimator for randomized low-rank approximations and ajackknife resampling method to estimate the variance of the output of arandomized matrix computation. Both of these diagnostics are rapid to computefor randomized low-rank approximation algorithms such as the randomized SVD andrandomized Nystr\"om approximation, and they provide useful information thatcan be used to assess the quality of the computed output and guide algorithmicparameter choices.</description><author>Ethan N. Epperly, Joel A. Tropp</author><pubDate>Fri, 23 Feb 2024 18:01:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.06342v4</guid></item><item><title>Benchmarking the Robustness of Panoptic Segmentation for Automated Driving</title><link>http://arxiv.org/abs/2402.15469v1</link><description>Precise situational awareness is required for the safe decision-making ofassisted and automated driving (AAD) functions. Panoptic segmentation is apromising perception technique to identify and categorise objects, impendinghazards, and driveable space at a pixel level. While segmentation quality isgenerally associated with the quality of the camera data, a comprehensiveunderstanding and modelling of this relationship are paramount for AAD systemdesigners. Motivated by such a need, this work proposes a unifying pipeline toassess the robustness of panoptic segmentation models for AAD, correlating itwith traditional image quality. The first step of the proposed pipelineinvolves generating degraded camera data that reflects real-world noisefactors. To this end, 19 noise factors have been identified and implementedwith 3 severity levels. Of these factors, this work proposes novel models forunfavourable light and snow. After applying the degradation models, threestate-of-the-art CNN- and vision transformers (ViT)-based panoptic segmentationnetworks are used to analyse their robustness. The variations of thesegmentation performance are then correlated to 8 selected image qualitymetrics. This research reveals that: 1) certain specific noise factors producethe highest impact on panoptic segmentation, i.e. droplets on lens and Gaussiannoise; 2) the ViT-based panoptic segmentation backbones show better robustnessto the considered noise factors; 3) some image quality metrics (i.e. LPIPS andCW-SSIM) correlate strongly with panoptic segmentation performance andtherefore they can be used as predictive metrics for network performance.</description><author>Yiting Wang, Haonan Zhao, Daniel Gummadi, Mehrdad Dianati, Kurt Debattista, Valentina Donzella</author><pubDate>Fri, 23 Feb 2024 18:00:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15469v1</guid></item><item><title>Score-based generative models break the curse of dimensionality in learning a family of sub-Gaussian probability distributions</title><link>http://arxiv.org/abs/2402.08082v3</link><description>While score-based generative models (SGMs) have achieved remarkable successin enormous image generation tasks, their mathematical foundations are stilllimited. In this paper, we analyze the approximation and generalization of SGMsin learning a family of sub-Gaussian probability distributions. We introduce anotion of complexity for probability distributions in terms of their relativedensity with respect to the standard Gaussian measure. We prove that if thelog-relative density can be locally approximated by a neural network whoseparameters can be suitably bounded, then the distribution generated byempirical score matching approximates the target distribution in totalvariation with a dimension-independent rate. We illustrate our theory throughexamples, which include certain mixtures of Gaussians. An essential ingredientof our proof is to derive a dimension-free deep neural network approximationrate for the true score function associated with the forward process, which isinteresting in its own right.</description><author>Frank Cole, Yulong Lu</author><pubDate>Fri, 23 Feb 2024 17:51:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08082v3</guid></item><item><title>CLIPPER+: A Fast Maximal Clique Algorithm for Robust Global Registration</title><link>http://arxiv.org/abs/2402.15464v1</link><description>We present CLIPPER+, an algorithm for finding maximal cliques in unweightedgraphs for outlier-robust global registration. The registration problem can beformulated as a graph and solved by finding its maximum clique. Thisformulation leads to extreme robustness to outliers; however, finding themaximum clique is an NP-hard problem, and therefore approximation is requiredin practice for large-size problems. The performance of an approximationalgorithm is evaluated by its computational complexity (the lower the runtime,the better) and solution accuracy (how close the solution is to the maximumclique). Accordingly, the main contribution of CLIPPER+ is outperforming thestate-of-the-art in accuracy while maintaining a relatively low runtime.CLIPPER+ builds on prior work (CLIPPER [1] and PMC [2]) and prunes the graph byremoving vertices that have a small core number and cannot be a part of themaximum clique. This will result in a smaller graph, on which the maximumclique can be estimated considerably faster. We evaluate the performance ofCLIPPER+ on standard graph benchmarks, as well as synthetic and real-worldpoint cloud registration problems. These evaluations demonstrate that CLIPPER+has the highest accuracy and can register point clouds in scenarios where over$99\%$ of associations are outliers. Our code and evaluation benchmarks arereleased at https://github.com/ariarobotics/clipperp.</description><author>Kaveh Fathian, Tyler Summers</author><pubDate>Fri, 23 Feb 2024 17:50:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15464v1</guid></item><item><title>Factored Online Planning in Many-Agent POMDPs</title><link>http://arxiv.org/abs/2312.11434v3</link><description>In centralized multi-agent systems, often modeled as multi-agent partiallyobservable Markov decision processes (MPOMDPs), the action and observationspaces grow exponentially with the number of agents, making the value andbelief estimation of single-agent online planning ineffective. Prior workpartially tackles value estimation by exploiting the inherent structure ofmulti-agent settings via so-called coordination graphs. Additionally, beliefestimation methods have been improved by incorporating the likelihood ofobservations into the approximation. However, the challenges of valueestimation and belief estimation have only been tackled individually, whichprevents existing methods from scaling to settings with many agents. Therefore,we address these challenges simultaneously. First, we introduce weightedparticle filtering to a sample-based online planner for MPOMDPs. Second, wepresent a scalable approximation of the belief. Third, we bring an approachthat exploits the typical locality of agent interactions to novel onlineplanning algorithms for MPOMDPs operating on a so-called sparse particle filtertree. Our experimental evaluation against several state-of-the-art baselinesshows that our methods (1) are competitive in settings with only a few agentsand (2) improve over the baselines in the presence of many agents.</description><author>Maris F. L. Galesloot, Thiago D. Simão, Sebastian Junges, Nils Jansen</author><pubDate>Fri, 23 Feb 2024 17:35:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11434v3</guid></item><item><title>Turning Federated Learning Systems Into Covert Channels</title><link>http://arxiv.org/abs/2104.10561v3</link><description>Federated learning (FL) goes beyond traditional, centralized machine learningby distributing model training among a large collection of edge clients. Theseclients cooperatively train a global, e.g., cloud-hosted, model withoutdisclosing their local, private training data. The global model is then sharedamong all the participants which use it for local predictions. In this paper,we put forward a novel attacker model aiming at turning FL systems into covertchannels to implement a stealth communication infrastructure. The mainintuition is that, during federated training, a malicious sender can poison theglobal model by submitting purposely crafted examples. Although the effect ofthe model poisoning is negligible to other participants, and does not alter theoverall model performance, it can be observed by a malicious receiver and usedto transmit a single bit.</description><author>Gabriele Costa, Fabio Pinelli, Simone Soderi, Gabriele Tolomei</author><pubDate>Fri, 23 Feb 2024 17:27:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2104.10561v3</guid></item><item><title>DeepCode AI Fix: Fixing Security Vulnerabilities with Large Language Models</title><link>http://arxiv.org/abs/2402.13291v2</link><description>The automated program repair field has attracted substantial interest overthe years, but despite significant research efforts, creating a system thatworks well for complex semantic bugs such as security vulnerabilities hasproven difficult. A promising direction to solve this challenge is byleveraging large language models (LLMs), which are increasingly used to solvevarious programming tasks. In this paper, we investigate the effectiveness ofLLMs for solving code-repair task. We show that the task is difficult as itrequires the model to learn long-range code relationships, a task thatinherently relies on extensive amounts of training data. At the same time,creating a large, clean dataset for complex program bugs and theircorresponding fixes is non-trivial. We propose a technique to address thesechallenges with a new approach for querying and fine-tuning LLMs. The idea isto use program analysis to limit the LLM's attention mechanism on the portionsof code needed to perform the fix, drastically reducing the amount of requiredtraining data. Concretely, for training and inference, rather than feeding theentire program to the LLM, we reduce its code to a much shorter snippet thatcontains the reported defect together with the necessary context - and use thatinstead. Our evaluation shows that this code reduction approach substantiallyimproves available models such as GPT-4 using few-shot learning, as well asfine-tuning models. To train and evaluate our system, we created acomprehensive code fixing dataset by extensively labeling 156 bug patterns(including 40 security rules), requiring complex interprocedural dataflow todiscover. Our best system with Mixtral-8x7B can remove more than 80% of thereported defects while exactly matching the human fix in between 10 and 50% ofcases, outperforming baselines based on GPT-3.5 and GPT-4, or based onwindow-based models like TFix.</description><author>Berkay Berabi, Alexey Gronskiy, Veselin Raychev, Gishor Sivanrupan, Victor Chibotaru, Martin Vechev</author><pubDate>Fri, 23 Feb 2024 17:26:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13291v2</guid></item><item><title>Repetition Improves Language Model Embeddings</title><link>http://arxiv.org/abs/2402.15449v1</link><description>Recent approaches to improving the extraction of text embeddings fromautoregressive large language models (LLMs) have largely focused onimprovements to data, backbone pretrained language models, or improvingtask-differentiation via instructions. In this work, we address anarchitectural limitation of autoregressive models: token embeddings cannotcontain information from tokens that appear later in the input. To address thislimitation, we propose a simple approach, "echo embeddings," in which we repeatthe input twice in context and extract embeddings from the second occurrence.We show that echo embeddings of early tokens can encode information about latertokens, allowing us to maximally leverage high-quality LLMs for embeddings. Onthe MTEB leaderboard, echo embeddings improve over classical embeddings by over9% zero-shot and by around 0.7% when fine-tuned. Echo embeddings with aMistral-7B model achieve state-of-the-art compared to prior open source modelsthat do not leverage synthetic fine-tuning data.</description><author>Jacob Mitchell Springer, Suhas Kotha, Daniel Fried, Graham Neubig, Aditi Raghunathan</author><pubDate>Fri, 23 Feb 2024 17:25:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15449v1</guid></item><item><title>Experimental Design for Multi-Channel Imaging via Task-Driven Feature Selection</title><link>http://arxiv.org/abs/2210.06891v3</link><description>This paper presents a data-driven, task-specific paradigm for experimentaldesign, to shorten acquisition time, reduce costs, and accelerate thedeployment of imaging devices. Current approaches in experimental design focuson model-parameter estimation and require specification of a particular model,whereas in imaging, other tasks may drive the design. Furthermore, suchapproaches often lead to intractable optimization problems in real-worldimaging applications. Here we present a new paradigm for experimental designthat simultaneously optimizes the design (set of image channels) and trains amachine-learning model to execute a user-specified image-analysis task. Theapproach obtains data densely-sampled over the measurement space (many imagechannels) for a small number of acquisitions, then identifies a subset ofchannels of prespecified size that best supports the task. We propose a method:TADRED for TAsk-DRiven Experimental Design in imaging, to identify the mostinformative channel-subset whilst simultaneously training a network to executethe task given the subset. Experiments demonstrate the potential of TADRED indiverse imaging applications: several clinically-relevant tasks in magneticresonance imaging; and remote sensing and physiological applications ofhyperspectral imaging. Results show substantial improvement over classicalexperimental design, two recent application-specific methods within the newparadigm, and state-of-the-art approaches in supervised feature selection. Weanticipate further applications of our approach. Code is available:https://github.com/sbb-gh/experimental-design-multichannel</description><author>Stefano B. Blumberg, Paddy J. Slator, Daniel C. Alexander</author><pubDate>Fri, 23 Feb 2024 17:23:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.06891v3</guid></item><item><title>Computer Vision for Multimedia Geolocation in Human Trafficking Investigation: A Systematic Literature Review</title><link>http://arxiv.org/abs/2402.15448v1</link><description>The task of multimedia geolocation is becoming an increasingly essentialcomponent of the digital forensics toolkit to effectively combat humantrafficking, child sexual exploitation, and other illegal acts. Typically,metadata-based geolocation information is stripped when multimedia content isshared via instant messaging and social media. The intricacy of geolocating,geotagging, or finding geographical clues in this content is often overlyburdensome for investigators. Recent research has shown that contemporaryadvancements in artificial intelligence, specifically computer vision and deeplearning, show significant promise towards expediting the multimediageolocation task. This systematic literature review thoroughly examines thestate-of-the-art leveraging computer vision techniques for multimediageolocation and assesses their potential to expedite human traffickinginvestigation. This includes a comprehensive overview of the application ofcomputer vision-based approaches to multimedia geolocation, identifies theirapplicability in combating human trafficking, and highlights the potentialimplications of enhanced multimedia geolocation for prosecuting humantrafficking. 123 articles inform this systematic literature review. Thefindings suggest numerous potential paths for future impactful research on thesubject.</description><author>Opeyemi Bamigbade, John Sheppard, Mark Scanlon</author><pubDate>Fri, 23 Feb 2024 17:23:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15448v1</guid></item><item><title>Inversion dynamics of class manifolds in deep learning reveals tradeoffs underlying generalisation</title><link>http://arxiv.org/abs/2303.05161v2</link><description>To achieve near-zero training error in a classification problem, the layersof a feed-forward network have to disentangle the manifolds of data points withdifferent labels, to facilitate the discrimination. However, excessive classseparation can bring to overfitting since good generalisation requires learninginvariant features, which involve some level of entanglement. We report onnumerical experiments showing how the optimisation dynamics findsrepresentations that balance these opposing tendencies with a non-monotonictrend. After a fast segregation phase, a slower rearrangement (conserved acrossdata sets and architectures) increases the class entanglement.The trainingerror at the inversion is stable under subsampling, and across networkinitialisations and optimisers, which characterises it as a property solely ofthe data structure and (very weakly) of the architecture. The inversion is themanifestation of tradeoffs elicited by well-defined and maximally stableelements of the training set, coined ``stragglers'', particularly influentialfor generalisation.</description><author>Simone Ciceri, Lorenzo Cassani, Matteo Osella, Pietro Rotondo, Filippo Valle, Marco Gherardi</author><pubDate>Fri, 23 Feb 2024 17:21:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05161v2</guid></item><item><title>Can we forget how we learned? Doxastic redundancy in iterated belief revision</title><link>http://arxiv.org/abs/2402.15445v1</link><description>How information was acquired may become irrelevant. An obvious case is whensomething is confirmed many times. In terms of iterated belief revision, aspecific revision may become irrelevant in presence of others. Simplerepetitions are an example, but not the only case when this happens. Sometimes,a revision becomes redundant even in presence of none equal, or even no elseimplying it. A necessary and sufficient condition for the redundancy of thefirst of a sequence of lexicographic revisions is given. The problem iscoNP-complete even with two propositional revisions only. Complexity is thesame in the Horn case but only with an unbounded number of revisions: itbecomes polynomial with two revisions. Lexicographic revisions are not onlyrelevant by themselves, but also because sequences of them are the most compactof the common mechanisms used to represent the state of an iterated revisionprocess. Shortening sequences of lexicographic revisions is shortening the mostcompact representations of iterated belief revision states.</description><author>Paolo Liberatore</author><pubDate>Fri, 23 Feb 2024 17:09:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15445v1</guid></item><item><title>AccessLens: Auto-detecting Inaccessibility of Everyday Objects</title><link>http://arxiv.org/abs/2401.15996v2</link><description>In our increasingly diverse society, everyday physical interfaces oftenpresent barriers, impacting individuals across various contexts. Thisoversight, from small cabinet knobs to identical wall switches that can posedifferent contextual challenges, highlights an imperative need for solutions.Leveraging low-cost 3D-printed augmentations such as knob magnifiers andtactile labels seems promising, yet the process of discovering unrecognizedbarriers remains challenging because disability is context-dependent. Weintroduce AccessLens, an end-to-end system designed to identify inaccessibleinterfaces in daily objects, and recommend 3D-printable augmentations foraccessibility enhancement. Our approach involves training a detector using thenovel AccessDB dataset designed to automatically recognize 21 distinctInaccessibility Classes (e.g., bar-small and round-rotate) within 6 commonobject categories (e.g., handle and knob). AccessMeta serves as a robust way tobuild a comprehensive dictionary linking these accessibility classes toopen-source 3D augmentation designs. Experiments demonstrate our detector'sperformance in detecting inaccessible objects.</description><author>Nahyun Kwon, Qian Lu, Muhammad Hasham Qazi, Joanne Liu, Changhoon Oh, Shu Kong, Jeeeun Kim</author><pubDate>Fri, 23 Feb 2024 17:06:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15996v2</guid></item><item><title>Distilled Self-Critique of LLMs with Synthetic Data: a Bayesian Perspective</title><link>http://arxiv.org/abs/2312.01957v2</link><description>This paper proposes an interpretation of RLAIF as Bayesian inference byintroducing distilled Self-Critique (dSC), which refines the outputs of a LLMthrough a Gibbs sampler that is later distilled into a fine-tuned model. Onlyrequiring synthetic data, dSC is exercised in experiments regarding safety,sentiment, and privacy control, showing it can be a viable and cheapalternative to align LLMs. Code released at\url{https://github.com/vicgalle/distilled-self-critique}.</description><author>Victor Gallego</author><pubDate>Fri, 23 Feb 2024 17:03:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01957v2</guid></item><item><title>GROS: A General Robust Aggregation Strategy</title><link>http://arxiv.org/abs/2402.15442v1</link><description>A new, very general, robust procedure for combining estimators in metricspaces is introduced GROS. The method is reminiscent of the well-known medianof means, as described in \cite{devroye2016sub}. Initially, the sample isdivided into $K$ groups. Subsequently, an estimator is computed for each group.Finally, these $K$ estimators are combined using a robust procedure. We provethat this estimator is sub-Gaussian and we get its break-down point, in thesense of Donoho. The robust procedure involves a minimization problem on ageneral metric space, but we show that the same (up to a constant)sub-Gaussianity is obtained if the minimization is taken over the sample,making GROS feasible in practice. The performance of GROS is evaluated throughfive simulation studies: the first one focuses on classification using$k$-means, the second one on the multi-armed bandit problem, the third one onthe regression problem. The fourth one is the set estimation problem under anoisy model. Lastly, we apply GROS to get a robust persistent diagram.</description><author>Alejandro Cholaquidis, Emilien Joly, Leonardo Moreno</author><pubDate>Fri, 23 Feb 2024 17:00:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15442v1</guid></item><item><title>Universal Lower Bounds and Optimal Rates: Achieving Minimax Clustering Error in Sub-Exponential Mixture Models</title><link>http://arxiv.org/abs/2402.15432v1</link><description>Clustering is a pivotal challenge in unsupervised machine learning and isoften investigated through the lens of mixture models. The optimal error ratefor recovering cluster labels in Gaussian and sub-Gaussian mixture modelsinvolves ad hoc signal-to-noise ratios. Simple iterative algorithms, such asLloyd's algorithm, attain this optimal error rate. In this paper, we firstestablish a universal lower bound for the error rate in clustering any mixturemodel, expressed through a Chernoff divergence, a more versatile measure ofmodel information than signal-to-noise ratios. We then demonstrate thatiterative algorithms attain this lower bound in mixture models withsub-exponential tails, notably emphasizing location-scale mixtures featuringLaplace-distributed errors. Additionally, for datasets better modelled byPoisson or Negative Binomial mixtures, we study mixture models whosedistributions belong to an exponential family. In such mixtures, we establishthat Bregman hard clustering, a variant of Lloyd's algorithm employing aBregman divergence, is rate optimal.</description><author>Maximilien Dreveton, Alperen Gözeten, Matthias Grossglauser, Patrick Thiran</author><pubDate>Fri, 23 Feb 2024 16:51:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15432v1</guid></item><item><title>Hierarchical Invariance for Robust and Interpretable Vision Tasks at Larger Scales</title><link>http://arxiv.org/abs/2402.15430v1</link><description>Developing robust and interpretable vision systems is a crucial step towardstrustworthy artificial intelligence. In this regard, a promising paradigmconsiders embedding task-required invariant structures, e.g., geometricinvariance, in the fundamental image representation. However, such invariantrepresentations typically exhibit limited discriminability, limiting theirapplications in larger-scale trustworthy vision tasks. For this open problem,we conduct a systematic investigation of hierarchical invariance, exploringthis topic from theoretical, practical, and application perspectives. At thetheoretical level, we show how to construct over-complete invariants with aConvolutional Neural Networks (CNN)-like hierarchical architecture yet in afully interpretable manner. The general blueprint, specific definitions,invariant properties, and numerical implementations are provided. At thepractical level, we discuss how to customize this theoretical framework into agiven task. With the over-completeness, discriminative features w.r.t. the taskcan be adaptively formed in a Neural Architecture Search (NAS)-like manner. Wedemonstrate the above arguments with accuracy, invariance, and efficiencyresults on texture, digit, and parasite classification experiments.Furthermore, at the application level, our representations are explored inreal-world forensics tasks on adversarial perturbations and ArtificialIntelligence Generated Content (AIGC). Such applications reveal that theproposed strategy not only realizes the theoretically promised invariance, butalso exhibits competitive discriminability even in the era of deep learning.For robust and interpretable vision tasks at larger scales, hierarchicalinvariant representation can be considered as an effective alternative totraditional CNN and invariants.</description><author>Shuren Qi, Yushu Zhang, Chao Wang, Zhihua Xia, Jian Weng, Xiaochun Cao</author><pubDate>Fri, 23 Feb 2024 16:50:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15430v1</guid></item><item><title>ProTIP: Probabilistic Robustness Verification on Text-to-Image Diffusion Models against Stochastic Perturbation</title><link>http://arxiv.org/abs/2402.15429v1</link><description>Text-to-Image (T2I) Diffusion Models (DMs) have shown impressive abilities ingenerating high-quality images based on simple text descriptions. However, asis common with many Deep Learning (DL) models, DMs are subject to a lack ofrobustness. While there are attempts to evaluate the robustness of T2I DMs as abinary or worst-case problem, they cannot answer how robust in general themodel is whenever an adversarial example (AE) can be found. In this study, wefirst introduce a probabilistic notion of T2I DMs' robustness; and thenestablish an efficient framework, ProTIP, to evaluate it with statisticalguarantees. The main challenges stem from: i) the high computational cost ofthe generation process; and ii) determining if a perturbed input is an AEinvolves comparing two output distributions, which is fundamentally hardercompared to other DL tasks like classification where an AE is identified uponmisprediction of labels. To tackle the challenges, we employ sequentialanalysis with efficacy and futility early stopping rules in the statisticaltesting for identifying AEs, and adaptive concentration inequalities todynamically determine the "just-right" number of stochastic perturbationswhenever the verification target is met. Empirical experiments validate theeffectiveness and efficiency of ProTIP over common T2I DMs. Finally, wedemonstrate an application of ProTIP to rank commonly used defence methods.</description><author>Yi Zhang, Yun Tang, Wenjie Ruan, Xiaowei Huang, Siddartha Khastgir, Paul Jennings, Xingyu Zhao</author><pubDate>Fri, 23 Feb 2024 16:48:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15429v1</guid></item><item><title>Benchmarking Retrieval-Augmented Generation for Medicine</title><link>http://arxiv.org/abs/2402.13178v2</link><description>While large language models (LLMs) have achieved state-of-the-art performanceon a wide range of medical question answering (QA) tasks, they still facechallenges with hallucinations and outdated knowledge. Retrieval-augmentedgeneration (RAG) is a promising solution and has been widely adopted. However,a RAG system can involve multiple flexible components, and there is a lack ofbest practices regarding the optimal RAG setting for various medical purposes.To systematically evaluate such systems, we propose the Medical InformationRetrieval-Augmented Generation Evaluation (MIRAGE), a first-of-its-kindbenchmark including 7,663 questions from five medical QA datasets. UsingMIRAGE, we conducted large-scale experiments with over 1.8 trillion prompttokens on 41 combinations of different corpora, retrievers, and backbone LLMsthrough the MedRAG toolkit introduced in this work. Overall, MedRAG improvesthe accuracy of six different LLMs by up to 18% over chain-of-thoughtprompting, elevating the performance of GPT-3.5 and Mixtral to GPT-4-level. Ourresults show that the combination of various medical corpora and retrieversachieves the best performance. In addition, we discovered a log-linear scalingproperty and the "lost-in-the-middle" effects in medical RAG. We believe ourcomprehensive evaluations can serve as practical guidelines for implementingRAG systems for medicine.</description><author>Guangzhi Xiong, Qiao Jin, Zhiyong Lu, Aidong Zhang</author><pubDate>Fri, 23 Feb 2024 16:46:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13178v2</guid></item><item><title>SzCORE: A Seizure Community Open-source Research Evaluation framework for the validation of EEG-based automated seizure detection algorithms</title><link>http://arxiv.org/abs/2402.13005v2</link><description>The need for high-quality automated seizure detection algorithms based onelectroencephalography (EEG) becomes ever more pressing with the increasing useof ambulatory and long-term EEG monitoring. Heterogeneity in validation methodsof these algorithms influences the reported results and makes comprehensiveevaluation and comparison challenging. This heterogeneity concerns inparticular the choice of datasets, evaluation methodologies, and performancemetrics. In this paper, we propose a unified framework designed to establishstandardization in the validation of EEG-based seizure detection algorithms.Based on existing guidelines and recommendations, the framework introduces aset of recommendations and standards related to datasets, file formats, EEGdata input content, seizure annotation input and output, cross-validationstrategies, and performance metrics. We also propose the 10-20 seizuredetection benchmark, a machine-learning benchmark based on public datasetsconverted to a standardized format. This benchmark defines the machine-learningtask as well as reporting metrics. We illustrate the use of the benchmark byevaluating a set of existing seizure detection algorithms. The SzCORE (SeizureCommunity Open-source Research Evaluation) framework and benchmark are madepublicly available along with an open-source software library to facilitateresearch use, while enabling rigorous evaluation of the clinical significanceof the algorithms, fostering a collective effort to more optimally detectseizures to improve the lives of people with epilepsy.</description><author>Jonathan Dan, Una Pale, Alireza Amirshahi, William Cappelletti, Thorir Mar Ingolfsson, Xiaying Wang, Andrea Cossettini, Adriano Bernini, Luca Benini, Sándor Beniczky, David Atienza, Philippe Ryvlin</author><pubDate>Fri, 23 Feb 2024 16:45:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13005v2</guid></item><item><title>Representing states in iterated belief revision</title><link>http://arxiv.org/abs/2305.09200v2</link><description>Iterated belief revision requires information about the current beliefs. Thisinformation is represented by mathematical structures called doxastic states.Most literature concentrates on how to revise a doxastic state and neglectsthat it may exponentially grow. This problem is studied for the most commonways of storing a doxastic state. All four methods are able to store everydoxastic state, but some do it in less space than others. In particular, theexplicit representation (an enumeration of the current beliefs) is the morewasteful on space. The level representation (a sequence of propositionalformulae) and the natural representation (a history of natural revisions) aremore compact than it. The lexicographic representation (a history oflexicographic revision) is even more compact than them.</description><author>Paolo Liberatore</author><pubDate>Fri, 23 Feb 2024 16:45:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09200v2</guid></item><item><title>Understanding Entrainment in Human Groups: Optimising Human-Robot Collaboration from Lessons Learned during Human-Human Collaboration</title><link>http://arxiv.org/abs/2402.15427v1</link><description>Successful entrainment during collaboration positively affects trust,willingness to collaborate, and likeability towards collaborators. In thispaper, we present a mixed-method study to investigate characteristics ofsuccessful entrainment leading to pair and group-based synchronisation. Drawinginspiration from industrial settings, we designed a fast-paced, short-cyclerepetitive task. Using motion tracking, we investigated entrainment in bothdyadic and triadic task completion. Furthermore, we utilise audio-videorecordings and semi-structured interviews to contextualise participants'experiences. This paper contributes to the Human-Computer/Robot Interaction(HCI/HRI) literature using a human-centred approach to identify characteristicsof entrainment during pair- and group-based collaboration. We present fivecharacteristics related to successful entrainment. These are related to theoccurrence of entrainment, leader-follower patterns, interpersonalcommunication, the importance of the point-of-assembly, and the value ofacoustic feedback. Finally, we present three design considerations for futureresearch and design on collaboration with robots.</description><author>Eike Schneiders, Christopher Fourie, Stanley Celestin, Julie Shah, Malte Jung</author><pubDate>Fri, 23 Feb 2024 16:42:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15427v1</guid></item><item><title>Causal Discovery from Conditionally Stationary Time Series</title><link>http://arxiv.org/abs/2110.06257v2</link><description>Causal discovery, i.e., inferring underlying causal relationships fromobservational data, has been shown to be highly challenging for AI systems. Intime series modeling context, traditional causal discovery methods mainlyconsider constrained scenarios with fully observed variables and/or data fromstationary time-series. We develop a causal discovery approach to handle a wideclass of non-stationary time-series that are conditionally stationary, wherethe non-stationary behaviour is modeled as stationarity conditioned on a set of(possibly hidden) state variables. Named State-Dependent Causal Inference(SDCI), our approach is able to recover the underlying causal dependencies,provably with fully-observed states and empirically with hidden states. Thelatter is confirmed by experiments on synthetic linear system and nonlinearparticle interaction data, where SDCI achieves superior performance overbaseline causal discovery methods. Improved results over non-causal RNNs onmodeling NBA player movements demonstrate the potential of our method andmotivate the use of causality-driven methods for forecasting.</description><author>Carles Balsells-Rodas, Ruibo Tu, Hedvig Kjellstrom, Yingzhen Li</author><pubDate>Fri, 23 Feb 2024 16:41:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.06257v2</guid></item><item><title>CFDBench: A Large-Scale Benchmark for Machine Learning Methods in Fluid Dynamics</title><link>http://arxiv.org/abs/2310.05963v2</link><description>In recent years, applying deep learning to solve physics problems hasattracted much attention. Data-driven deep learning methods produce fastnumerical operators that can learn approximate solutions to the whole system ofpartial differential equations (i.e., surrogate modeling). Although theseneural networks may have lower accuracy than traditional numerical methods,they, once trained, are orders of magnitude faster at inference. Hence, onecrucial feature is that these operators can generalize to unseen PDE parameterswithout expensive re-training.In this paper, we construct CFDBench, a benchmarktailored for evaluating the generalization ability of neural operators aftertraining in computational fluid dynamics (CFD) problems. It features fourclassic CFD problems: lid-driven cavity flow, laminar boundary layer flow incircular tubes, dam flows through the steps, and periodic Karman vortex street.The data contains a total of 302K frames of velocity and pressure fields,involving 739 cases with different operating condition parameters, generatedwith numerical methods. We evaluate the effectiveness of popular neuraloperators including feed-forward networks, DeepONet, FNO, U-Net, etc. onCFDBnech by predicting flows with non-periodic boundary conditions, fluidproperties, and flow domain shapes that are not seen during training.Appropriate modifications were made to apply popular deep neural networks toCFDBench and enable the accommodation of more changing inputs. Empiricalresults on CFDBench show many baseline models have errors as high as 300% insome problems, and severe error accumulation when performing autoregressiveinference. CFDBench facilitates a more comprehensive comparison betweendifferent neural operators for CFD compared to existing benchmarks.</description><author>Yining Luo, Yingfa Chen, Zhen Zhang</author><pubDate>Fri, 23 Feb 2024 16:39:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05963v2</guid></item><item><title>A Data-Centric Approach To Generate Faithful and High Quality Patient Summaries with Large Language Models</title><link>http://arxiv.org/abs/2402.15422v1</link><description>Patients often face difficulties in understanding their hospitalizations,while healthcare workers have limited resources to provide explanations. Inthis work, we investigate the potential of large language models to generatepatient summaries based on doctors' notes and study the effect of training dataon the faithfulness and quality of the generated summaries. To this end, wedevelop a rigorous labeling protocol for hallucinations, and have two medicalexperts annotate 100 real-world summaries and 100 generated summaries. We showthat fine-tuning on hallucination-free data effectively reduces hallucinationsfrom 2.60 to 1.55 per summary for Llama 2, while preserving relevantinformation. Although the effect is still present, it is much smaller for GPT-4when prompted with five examples (0.70 to 0.40). We also conduct a qualitativeevaluation using hallucination-free and improved training data. GPT-4 showsvery good results even in the zero-shot setting. We find that commonquantitative metrics do not correlate well with faithfulness and quality.Finally, we test GPT-4 for automatic hallucination detection, which yieldspromising results.</description><author>Stefan Hegselmann, Shannon Zejiang Shen, Florian Gierse, Monica Agrawal, David Sontag, Xiaoyi Jiang</author><pubDate>Fri, 23 Feb 2024 16:32:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15422v1</guid></item><item><title>PREDILECT: Preferences Delineated with Zero-Shot Language-based Reasoning in Reinforcement Learning</title><link>http://arxiv.org/abs/2402.15420v1</link><description>Preference-based reinforcement learning (RL) has emerged as a new field inrobot learning, where humans play a pivotal role in shaping robot behavior byexpressing preferences on different sequences of state-action pairs. However,formulating realistic policies for robots demands responses from humans to anextensive array of queries. In this work, we approach the sample-efficiencychallenge by expanding the information collected per query to contain bothpreferences and optional text prompting. To accomplish this, we leverage thezero-shot capabilities of a large language model (LLM) to reason from the textprovided by humans. To accommodate the additional query information, wereformulate the reward learning objectives to contain flexible highlights --state-action pairs that contain relatively high information and are related tothe features processed in a zero-shot fashion from a pretrained LLM. In both asimulated scenario and a user study, we reveal the effectiveness of our work byanalyzing the feedback and its implications. Additionally, the collectivefeedback collected serves to train a robot on socially compliant trajectoriesin a simulated social navigation landscape. We provide video examples of thetrained policies at https://sites.google.com/view/rl-predilect</description><author>Simon Holk, Daniel Marta, Iolanda Leite</author><pubDate>Fri, 23 Feb 2024 16:30:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15420v1</guid></item><item><title>Reputational Algorithm Aversion</title><link>http://arxiv.org/abs/2402.15418v1</link><description>People are often reluctant to incorporate information produced by algorithmsinto their decisions, a phenomenon called "algorithm aversion". This papershows how algorithm aversion arises when the choice to follow an algorithmconveys information about a human's ability. I develop a model in which workersmake forecasts of a random outcome based on their own private information andan algorithm's signal. Low-skill workers receive worse information than thealgorithm and hence should always follow the algorithm's signal, whilehigh-skill workers receive better information than the algorithm and shouldsometimes override it. However, due to reputational concerns, low-skill workersinefficiently override the algorithm to increase the likelihood they areperceived as high-skill. The model provides a fully rational microfoundationfor algorithm aversion that aligns with the broad concern that AI systems willdisplace many types of workers.</description><author>Gregory Weitzner</author><pubDate>Fri, 23 Feb 2024 16:28:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15418v1</guid></item><item><title>The Impact of LoRA on the Emergence of Clusters in Transformers</title><link>http://arxiv.org/abs/2402.15415v1</link><description>In this paper, we employ the mathematical framework on Transformers developedby\citet{sander2022sinkformers,geshkovski2023emergence,geshkovski2023mathematical}to explore how variations in attention parameters and initial token valuesimpact the structural dynamics of token clusters. Our analysis demonstratesthat while the clusters within a modified attention matrix dynamics can exhibitsignificant divergence from the original over extended periods, they maintainclose similarities over shorter intervals, depending on the parameterdifferences. This work contributes to the fine-tuning field through practicalapplications to the LoRA algorithm \cite{hu2021lora,peft}, enhancing ourunderstanding of the behavior of LoRA-enhanced Transformer models.</description><author>Hugo Koubbi, Matthieu Boussard, Louis Hernandez</author><pubDate>Fri, 23 Feb 2024 16:26:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15415v1</guid></item><item><title>Does Combining Parameter-efficient Modules Improve Few-shot Transfer Accuracy?</title><link>http://arxiv.org/abs/2402.15414v1</link><description>Parameter-efficient fine-tuning stands as the standard for efficientlyfine-tuning large language and vision models on downstream tasks. Specifically,the efficiency of low-rank adaptation has facilitated the creation and sharingof hundreds of custom LoRA modules, each trained on distinct data from variousdownstream tasks. In this paper, we explore the composability of LoRA modules,examining if combining these pre-trained modules enhances generalization tounseen downstream tasks. Our investigation involves evaluating two approaches:(a) uniform composition, involving averaging upstream LoRA modules with equalweights, and (b) learned composition, where we learn the weights for eachupstream module and perform weighted averaging. Our experimental results onboth vision and language models reveal that in few-shot settings, where only alimited number of samples are available for the downstream task, both uniformand learned composition methods result in better transfer accuracy;outperforming full fine-tuning and training a LoRA from scratch. Moreover, infull-shot settings, learned composition performs comparably to regular LoRAtraining with significantly fewer number of trainable parameters. Our researchunveils the potential of uniform composition for enhancing transferability inlow-shot settings, without introducing additional learnable parameters.</description><author>Nader Asadi, Mahdi Beitollahi, Yasser Khalil, Yinchuan Li, Guojun Zhang, Xi Chen</author><pubDate>Fri, 23 Feb 2024 16:20:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15414v1</guid></item><item><title>G-RepsNet: A Fast and General Construction of Equivariant Networks for Arbitrary Matrix Groups</title><link>http://arxiv.org/abs/2402.15413v1</link><description>Group equivariance is a strong inductive bias useful in a wide range of deeplearning tasks. However, constructing efficient equivariant networks forgeneral groups and domains is difficult. Recent work by Finzi et al. (2021)directly solves the equivariance constraint for arbitrary matrix groups toobtain equivariant MLPs (EMLPs). But this method does not scale well andscaling is crucial in deep learning. Here, we introduce Group RepresentationNetworks (G-RepsNets), a lightweight equivariant network for arbitrary matrixgroups with features represented using tensor polynomials. The key intuitionfor our design is that using tensor representations in the hidden layers of aneural network along with simple inexpensive tensor operations can lead toexpressive universal equivariant networks. We find G-RepsNet to be competitiveto EMLP on several tasks with group symmetries such as O(5), O(1, 3), and O(3)with scalars, vectors, and second-order tensors as data types. On imageclassification tasks, we find that G-RepsNet using second-order representationsis competitive and often even outperforms sophisticated state-of-the-artequivariant models such as GCNNs (Cohen &amp; Welling, 2016a) and E(2)-CNNs (Weiler&amp; Cesa, 2019). To further illustrate the generality of our approach, we showthat G-RepsNet is competitive to G-FNO (Helwig et al., 2023) and EGNN (Satorraset al., 2021) on N-body predictions and solving PDEs, respectively, while beingefficient.</description><author>Sourya Basu, Suhas Lohit, Matthew Brand</author><pubDate>Fri, 23 Feb 2024 16:19:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15413v1</guid></item><item><title>Optimisic Information Directed Sampling</title><link>http://arxiv.org/abs/2402.15411v1</link><description>We study the problem of online learning in contextual bandit problems wherethe loss function is assumed to belong to a known parametric function class. Wepropose a new analytic framework for this setting that bridges the Bayesiantheory of information-directed sampling due to Russo and Van Roy (2018) and theworst-case theory of Foster, Kakade, Qian, and Rakhlin (2021) based on thedecision-estimation coefficient. Drawing from both lines of work, we propose aalgorithmic template called Optimistic Information-Directed Sampling and showthat it can achieve instance-dependent regret guarantees similar to the onesachievable by the classic Bayesian IDS method, but with the major advantage ofnot requiring any Bayesian assumptions. The key technical innovation of ouranalysis is introducing an optimistic surrogate model for the regret and usingit to define a frequentist version of the Information Ratio of Russo and VanRoy (2018), and a less conservative version of the Decision EstimationCoefficient of Foster et al. (2021). Keywords: Contextual bandits,information-directed sampling, decision estimation coefficient, first-orderregret bounds.</description><author>Gergely Neu, Matteo Papini, Ludovic Schwartz</author><pubDate>Fri, 23 Feb 2024 16:19:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15411v1</guid></item><item><title>Towards Efficient and Exact Optimization of Language Model Alignment</title><link>http://arxiv.org/abs/2402.00856v3</link><description>The alignment of language models with human preferences is vital for theirapplication in real-world tasks. The problem is formulated as optimizing themodel's policy to maximize the expected reward that reflects human preferenceswith minimal deviation from the initial policy. While considered as astraightforward solution, reinforcement learning (RL) suffers from highvariance in policy updates, which impedes efficient policy improvement.Recently, direct preference optimization (DPO) was proposed to directlyoptimize the policy from preference data. Though simple to implement, DPO isderived based on the optimal policy that is not assured to be achieved inpractice, which undermines its convergence to the intended solution. In this paper, we propose efficient exact optimization (EXO) of the alignmentobjective. We prove that EXO is guaranteed to optimize in the same direction asthe RL algorithms asymptotically for arbitary parametrization of the policy,while enables efficient optimization by circumventing the complexitiesassociated with RL algorithms. We compare our method to DPO with boththeoretical and empirical analyses, and further demonstrate the advantages ofour method over existing approaches on realistic human preference data. Code isavailable at https://github.com/haozheji/exact-optimization.</description><author>Haozhe Ji, Cheng Lu, Yilin Niu, Pei Ke, Hongning Wang, Jun Zhu, Jie Tang, Minlie Huang</author><pubDate>Fri, 23 Feb 2024 16:19:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00856v3</guid></item><item><title>Lasso with Latents: Efficient Estimation, Covariate Rescaling, and Computational-Statistical Gaps</title><link>http://arxiv.org/abs/2402.15409v1</link><description>It is well-known that the statistical performance of Lasso can suffersignificantly when the covariates of interest have strong correlations. Inparticular, the prediction error of Lasso becomes much worse thancomputationally inefficient alternatives like Best Subset Selection. Due to alarge conjectured computational-statistical tradeoff in the problem of sparselinear regression, it may be impossible to close this gap in general. In this work, we propose a natural sparse linear regression setting wherestrong correlations between covariates arise from unobserved latent variables.In this setting, we analyze the problem caused by strong correlations anddesign a surprisingly simple fix. While Lasso with standard normalization ofcovariates fails, there exists a heterogeneous scaling of the covariates withwhich Lasso will suddenly obtain strong provable guarantees for estimation.Moreover, we design a simple, efficient procedure for computing such a "smartscaling." The sample complexity of the resulting "rescaled Lasso" algorithm incurs (inthe worst case) quadratic dependence on the sparsity of the underlying signal.While this dependence is not information-theoretically necessary, we giveevidence that it is optimal among the class of polynomial-time algorithms, viathe method of low-degree polynomials. This argument reveals a new connectionbetween sparse linear regression and a special version of sparse PCA with anear-critical negative spike. The latter problem can be thought of as areal-valued analogue of learning a sparse parity. Using it, we also establishthe first computational-statistical gap for the closely related problem oflearning a Gaussian Graphical Model.</description><author>Jonathan Kelner, Frederic Koehler, Raghu Meka, Dhruv Rohatgi</author><pubDate>Fri, 23 Feb 2024 16:16:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15409v1</guid></item><item><title>The Challenges of Machine Learning for Trust and Safety: A Case Study on Misinformation Detection</title><link>http://arxiv.org/abs/2308.12215v2</link><description>We examine the disconnect between scholarship and practice in applyingmachine learning to trust and safety problems, using misinformation detectionas a case study. We systematize literature on automated detection ofmisinformation across a corpus of 270 well-cited papers in the field. We thenexamine subsets of papers for data and code availability, design missteps,reproducibility, and generalizability. Our paper corpus includes published workin security, natural language processing, and computational social science.Across these disparate disciplines, we identify common errors in dataset andmethod design. In general, detection tasks are often meaningfully distinct fromthe challenges that online services actually face. Datasets and modelevaluation are often non-representative of real-world contexts, and evaluationfrequently is not independent of model training. Data and code availability ispoor. We demonstrate the limitations of current detection methods in a seriesof three replication studies. Based on the results of these analyses and ourliterature survey, we offer recommendations for evaluating applications ofmachine learning to trust and safety problems in general. Our aim is for futurework to avoid the pitfalls that we identify.</description><author>Madelyne Xiao, Jonathan Mayer</author><pubDate>Fri, 23 Feb 2024 16:13:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12215v2</guid></item><item><title>Conformalized-DeepONet: A Distribution-Free Framework for Uncertainty Quantification in Deep Operator Networks</title><link>http://arxiv.org/abs/2402.15406v1</link><description>In this paper, we adopt conformal prediction, a distribution-free uncertaintyquantification (UQ) framework, to obtain confidence prediction intervals withcoverage guarantees for Deep Operator Network (DeepONet) regression. Initially,we enhance the uncertainty quantification frameworks (B-DeepONet andProb-DeepONet) previously proposed by the authors by using split conformalprediction. By combining conformal prediction with our Prob- and B-DeepONets,we effectively quantify uncertainty by generating rigorous confidence intervalsfor DeepONet prediction. Additionally, we design a novel Quantile-DeepONet thatallows for a more natural use of split conformal prediction. We refer to thisdistribution-free effective uncertainty quantification framework as splitconformal Quantile-DeepONet regression. Finally, we demonstrate theeffectiveness of the proposed methods using various ordinary, partialdifferential equation numerical examples, and multi-fidelity learning.</description><author>Christian Moya, Amirhossein Mollaali, Zecheng Zhang, Lu Lu, Guang Lin</author><pubDate>Fri, 23 Feb 2024 16:07:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15406v1</guid></item><item><title>United We Pretrain, Divided We Fail! Representation Learning for Time Series by Pretraining on 75 Datasets at Once</title><link>http://arxiv.org/abs/2402.15404v1</link><description>In natural language processing and vision, pretraining is utilized to learneffective representations. Unfortunately, the success of pretraining does noteasily carry over to time series due to potential mismatch between sources andtarget. Actually, common belief is that multi-dataset pretraining does not workfor time series! Au contraire, we introduce a new self-supervised contrastivepretraining approach to learn one encoding from many unlabeled and diverse timeseries datasets, so that the single learned representation can then be reusedin several target domains for, say, classification. Specifically, we proposethe XD-MixUp interpolation method and the Soft Interpolation ContextualContrasting (SICC) loss. Empirically, this outperforms both supervised trainingand other self-supervised pretraining methods when finetuning on low-dataregimes. This disproves the common belief: We can actually learn from multipletime series datasets, even from 75 at once.</description><author>Maurice Kraus, Felix Divo, David Steinmann, Devendra Singh Dhami, Kristian Kersting</author><pubDate>Fri, 23 Feb 2024 16:06:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15404v1</guid></item><item><title>Grasp, See and Place: Efficient Unknown Object Rearrangement with Policy Structure Prior</title><link>http://arxiv.org/abs/2402.15402v1</link><description>We focus on the task of unknown object rearrangement, where a robot issupposed to re-configure the objects into a desired goal configurationspecified by an RGB-D image. Recent works explore unknown object rearrangementsystems by incorporating learning-based perception modules. However, they aresensitive to perception error, and pay less attention to task-levelperformance. In this paper, we aim to develop an effective system for unknownobject rearrangement amidst perception noise. We theoretically reveal the noisyperception impacts grasp and place in a decoupled way, and show such adecoupled structure is non-trivial to improve task optimality. We propose GSP,a dual-loop system with the decoupled structure as prior. For the inner loop,we learn an active seeing policy for self-confident object matching to improvethe perception of place. For the outer loop, we learn a grasp policy aware ofobject matching and grasp capability guided by task-level rewards. We leveragethe foundation model CLIP for object matching, policy learning andself-termination. A series of experiments indicate that GSP can conduct unknownobject rearrangement with higher completion rate and less steps.</description><author>Kechun Xu, Zhongxiang Zhou, Jun Wu, Haojian Lu, Rong Xiong, Yue Wang</author><pubDate>Fri, 23 Feb 2024 16:05:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15402v1</guid></item><item><title>Bernstein Flows for Flexible Posteriors in Variational Bayes</title><link>http://arxiv.org/abs/2202.05650v2</link><description>Variational inference (VI) is a technique to approximate difficult to computeposteriors by optimization. In contrast to MCMC, VI scales to manyobservations. In the case of complex posteriors, however, state-of-the-art VIapproaches often yield unsatisfactory posterior approximations. This paperpresents Bernstein flow variational inference (BF-VI), a robust and easy-to-usemethod, flexible enough to approximate complex multivariate posteriors. BF-VIcombines ideas from normalizing flows and Bernstein polynomial-basedtransformation models. In benchmark experiments, we compare BF-VI solutionswith exact posteriors, MCMC solutions, and state-of-the-art VI methodsincluding normalizing flow based VI. We show for low-dimensional models thatBF-VI accurately approximates the true posterior; in higher-dimensional models,BF-VI outperforms other VI methods. Further, we develop with BF-VI a Bayesianmodel for the semi-structured Melanoma challenge data, combining a CNN modelpart for image data with an interpretable model part for tabular data, anddemonstrate for the first time how the use of VI in semi-structured models.</description><author>Oliver Dürr, Stephan Hörling, Daniel Dold, Ivonne Kovylov, Beate Sick</author><pubDate>Fri, 23 Feb 2024 16:04:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.05650v2</guid></item><item><title>Faithful Temporal Question Answering over Heterogeneous Sources</title><link>http://arxiv.org/abs/2402.15400v1</link><description>Temporal question answering (QA) involves time constraints, with phrases suchas "... in 2019" or "... before COVID". In the former, time is an explicitcondition, in the latter it is implicit. State-of-the-art methods havelimitations along three dimensions. First, with neural inference, timeconstraints are merely soft-matched, giving room to invalid or inexplicableanswers. Second, questions with implicit time are poorly supported. Third,answers come from a single source: either a knowledge base (KB) or a textcorpus. We propose a temporal QA system that addresses these shortcomings.First, it enforces temporal constraints for faithful answering with tangibleevidence. Second, it properly handles implicit questions. Third, it operatesover heterogeneous sources, covering KB, text and web tables in a unifiedmanner. The method has three stages: (i) understanding the question and itstemporal conditions, (ii) retrieving evidence from all sources, and (iii)faithfully answering the question. As implicit questions are sparse in priorbenchmarks, we introduce a principled method for generating diverse questions.Experiments show superior performance over a suite of baselines.</description><author>Zhen Jia, Philipp Christmann, Gerhard Weikum</author><pubDate>Fri, 23 Feb 2024 16:03:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15400v1</guid></item><item><title>Distributionally Robust Off-Dynamics Reinforcement Learning: Provable Efficiency with Linear Function Approximation</title><link>http://arxiv.org/abs/2402.15399v1</link><description>We study off-dynamics Reinforcement Learning (RL), where the policy istrained on a source domain and deployed to a distinct target domain. We aim tosolve this problem via online distributionally robust Markov decision processes(DRMDPs), where the learning algorithm actively interacts with the sourcedomain while seeking the optimal performance under the worst possible dynamicsthat is within an uncertainty set of the source domain's transition kernel. Weprovide the first study on online DRMDPs with function approximation foroff-dynamics RL. We find that DRMDPs' dual formulation can induce nonlinearity,even when the nominal transition kernel is linear, leading to errorpropagation. By designing a $d$-rectangular uncertainty set using the totalvariation distance, we remove this additional nonlinearity and bypass the errorpropagation. We then introduce DR-LSVI-UCB, the first provably efficient onlineDRMDP algorithm for off-dynamics RL with function approximation, and establisha polynomial suboptimality bound that is independent of the state and actionspace sizes. Our work makes the first step towards a deeper understanding ofthe provable efficiency of online DRMDPs with linear function approximation.Finally, we substantiate the performance and robustness of DR-LSVI-UCB throughdifferent numerical experiments.</description><author>Zhishuai Liu, Pan Xu</author><pubDate>Fri, 23 Feb 2024 16:01:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15399v1</guid></item><item><title>TransFlower: An Explainable Transformer-Based Model with Flow-to-Flow Attention for Commuting Flow Prediction</title><link>http://arxiv.org/abs/2402.15398v1</link><description>Understanding the link between urban planning and commuting flows is crucialfor guiding urban development and policymaking. This research, bridgingcomputer science and urban studies, addresses the challenge of integratingthese fields with their distinct focuses. Traditional urban studies methods,like the gravity and radiation models, often underperform in complex scenariosdue to their limited handling of multiple variables and reliance on overlysimplistic and unrealistic assumptions, such as spatial isotropy. While deeplearning models offer improved accuracy, their black-box nature poses atrade-off between performance and explainability -- both vital for analyzingcomplex societal phenomena like commuting flows. To address this, we introduceTransFlower, an explainable, transformer-based model employing flow-to-flowattention to predict urban commuting patterns. It features a geospatial encoderwith an anisotropy-aware relative location encoder for nuanced flowrepresentation. Following this, the transformer-based flow predictor enhancesthis by leveraging attention mechanisms to efficiently capture flowinteractions. Our model outperforms existing methods by up to 30.8% Common Partof Commuters, offering insights into mobility dynamics crucial for urbanplanning and policy decisions.</description><author>Yan Luo, Zhuoyue Wan, Yuzhong Chen, Gengchen Mai, Fu-lai Chung, Kent Larson</author><pubDate>Fri, 23 Feb 2024 16:00:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15398v1</guid></item><item><title>NeuralThink: Algorithm Synthesis that Extrapolates in General Tasks</title><link>http://arxiv.org/abs/2402.15393v1</link><description>While machine learning methods excel at pattern recognition, they strugglewith complex reasoning tasks in a scalable, algorithmic manner. Recent DeepThinking methods show promise in learning algorithms that extrapolate: learningin smaller environments and executing the learned algorithm in largerenvironments. However, these works are limited to symmetrical tasks, where theinput and output dimensionalities are the same. To address this gap, we proposeNeuralThink, a new recurrent architecture that can consistently extrapolate toboth symmetrical and asymmetrical tasks, where the dimensionality of the inputand output are different. We contribute with a novel benchmark of asymmetricaltasks for extrapolation. We show that NeuralThink consistently outperforms theprior state-of-the-art Deep Thinking architectures, in regards to stableextrapolation to large observations from smaller training sizes.</description><author>Bernardo Esteves, Miguel Vasco, Francisco S. Melo</author><pubDate>Fri, 23 Feb 2024 15:51:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15393v1</guid></item><item><title>Offline Inverse RL: New Solution Concepts and Provably Efficient Algorithms</title><link>http://arxiv.org/abs/2402.15392v1</link><description>Inverse reinforcement learning (IRL) aims to recover the reward function ofan expert agent from demonstrations of behavior. It is well known that the IRLproblem is fundamentally ill-posed, i.e., many reward functions can explain thedemonstrations. For this reason, IRL has been recently reframed in terms ofestimating the feasible reward set, thus, postponing the selection of a singlereward. However, so far, the available formulations and algorithmic solutionshave been proposed and analyzed mainly for the online setting, where thelearner can interact with the environment and query the expert at will. This isclearly unrealistic in most practical applications, where the availability ofan offline dataset is a much more common scenario. In this paper, we introducea novel notion of feasible reward set capturing the opportunities andlimitations of the offline setting and we analyze the complexity of itsestimation. This requires the introduction an original learning framework thatcopes with the intrinsic difficulty of the setting, for which the data coverageis not under control. Then, we propose two computationally and statisticallyefficient algorithms, IRLO and PIRLO, for addressing the problem. Inparticular, the latter adopts a specific form of pessimism to enforce the noveldesirable property of inclusion monotonicity of the delivered feasible set.With this work, we aim to provide a panorama of the challenges of the offlineIRL problem and how they can be fruitfully addressed.</description><author>Filippo Lazzati, Mirco Mutti, Alberto Maria Metelli</author><pubDate>Fri, 23 Feb 2024 15:49:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15392v1</guid></item><item><title>GNNShap: Scalable and Accurate GNN Explanation using Shapley Values</title><link>http://arxiv.org/abs/2401.04829v3</link><description>Graph neural networks (GNNs) are popular machine learning models for graphswith many applications across scientific domains. However, GNNs are consideredblack box models, and it is challenging to understand how the model makespredictions. Game theoric Shapley value approaches are popular explanationmethods in other domains but are not well-studied for graphs. Some studies haveproposed Shapley value based GNN explanations, yet they have severallimitations: they consider limited samples to approximate Shapley values; somemainly focus on small and large coalition sizes, and they are an order ofmagnitude slower than other explanation methods, making them inapplicable toeven moderate-size graphs. In this work, we propose GNNShap, which providesexplanations for edges since they provide more natural explanations for graphsand more fine-grained explanations. We overcome the limitations by samplingfrom all coalition sizes, parallelizing the sampling on GPUs, and speeding upmodel predictions by batching. GNNShap gives better fidelity scores and fasterexplanations than baselines on real-world datasets. The code is available athttps://github.com/HipGraph/GNNShap.</description><author>Selahattin Akkas, Ariful Azad</author><pubDate>Fri, 23 Feb 2024 15:49:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04829v3</guid></item><item><title>Genie: Generative Interactive Environments</title><link>http://arxiv.org/abs/2402.15391v1</link><description>We introduce Genie, the first generative interactive environment trained inan unsupervised manner from unlabelled Internet videos. The model can beprompted to generate an endless variety of action-controllable virtual worldsdescribed through text, synthetic images, photographs, and even sketches. At11B parameters, Genie can be considered a foundation world model. It iscomprised of a spatiotemporal video tokenizer, an autoregressive dynamicsmodel, and a simple and scalable latent action model. Genie enables users toact in the generated environments on a frame-by-frame basis despite trainingwithout any ground-truth action labels or other domain-specific requirementstypically found in the world model literature. Further the resulting learnedlatent action space facilitates training agents to imitate behaviors fromunseen videos, opening the path for training generalist agents of the future.</description><author>Jake Bruce, Michael Dennis, Ashley Edwards, Jack Parker-Holder, Yuge Shi, Edward Hughes, Matthew Lai, Aditi Mavalankar, Richie Steigerwald, Chris Apps, Yusuf Aytar, Sarah Bechtle, Feryal Behbahani, Stephanie Chan, Nicolas Heess, Lucy Gonzalez, Simon Osindero, Sherjil Ozair, Scott Reed, Jingwei Zhang, Konrad Zolna, Jeff Clune, Nando de Freitas, Satinder Singh, Tim Rocktäschel</author><pubDate>Fri, 23 Feb 2024 15:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15391v1</guid></item><item><title>Decoding News Narratives: A Critical Analysis of Large Language Models in Framing Bias Detection</title><link>http://arxiv.org/abs/2402.11621v2</link><description>This work contributes to the expanding research on the applicability of LLMsin social sciences by examining the performance of GPT-3.5 Turbo, GPT-4, andFlan-T5 models in detecting framing bias in news headlines through zero-shot,few-shot, and explainable prompting methods. A key insight from our evaluationis the notable efficacy of explainable prompting in enhancing the reliabilityof these models, highlighting the importance of explainable settings for socialscience research on framing bias. GPT-4, in particular, demonstrated enhancedperformance in few-shot scenarios when presented with a range of relevant,in-domain examples. FLAN-T5's poor performance indicates that smaller modelsmay require additional task-specific fine-tuning for identifying framing biasdetection. Our study also found that models, particularly GPT-4, oftenmisinterpret emotional language as an indicator of framing bias, underscoringthe challenge of distinguishing between reporting genuine emotional expressionand intentionally use framing bias in news headlines. We further evaluated themodels on two subsets of headlines where the presence or absence of framingbias was either clear-cut or more contested, with the results suggesting thatthese models' can be useful in flagging potential annotation inaccuracieswithin existing or new datasets. Finally, the study evaluates the models inreal-world conditions ("in the wild"), moving beyond the initial datasetfocused on U.S. Gun Violence, assessing the models' performance on framedheadlines covering a broad range of topics.</description><author>Valeria Pastorino, Jasivan A. Sivakumar, Nafise Sadat Moosavi</author><pubDate>Fri, 23 Feb 2024 15:43:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11621v2</guid></item><item><title>Sharp Lower Bounds on Interpolation by Deep ReLU Neural Networks at Irregularly Spaced Data</title><link>http://arxiv.org/abs/2302.00834v2</link><description>We study the interpolation power of deep ReLU neural networks. Specifically,we consider the question of how efficiently, in terms of the number ofparameters, deep ReLU networks can interpolate values at $N$ datapoints in theunit ball which are separated by a distance $\delta$. We show that $\Omega(N)$parameters are required in the regime where $\delta$ is exponentially small in$N$, which gives the sharp result in this regime since $O(N)$ parameters arealways sufficient. This also shows that the bit-extraction technique used toprove lower bounds on the VC dimension cannot be applied to irregularly spaceddatapoints. Finally, as an application we give a lower bound on theapproximation rates that deep ReLU neural networks can achieve for Sobolevspaces at the embedding endpoint.</description><author>Jonathan W. Siegel</author><pubDate>Fri, 23 Feb 2024 15:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00834v2</guid></item><item><title>Explorations of Self-Repair in Language Models</title><link>http://arxiv.org/abs/2402.15390v1</link><description>Prior interpretability research studying narrow distributions haspreliminarily identified self-repair, a phenomena where if components in largelanguage models are ablated, later components will change their behavior tocompensate. Our work builds off this past literature, demonstrating thatself-repair exists on a variety of models families and sizes when ablatingindividual attention heads on the full training distribution. We further showthat on the full training distribution self-repair is imperfect, as theoriginal direct effect of the head is not fully restored, and noisy, since thedegree of self-repair varies significantly across different prompts (sometimesovercorrecting beyond the original effect). We highlight two differentmechanisms that contribute to self-repair, including changes in the finalLayerNorm scaling factor (which can repair up to 30% of the direct effect) andsparse sets of neurons implementing Anti-Erasure. We additionally discuss theimplications of these results for interpretability practitioners and close witha more speculative discussion on the mystery of why self-repair occurs in thesemodels at all, highlighting evidence for the Iterative Inference hypothesis inlanguage models, a framework that predicts self-repair.</description><author>Cody Rushing, Neel Nanda</author><pubDate>Fri, 23 Feb 2024 15:42:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15390v1</guid></item><item><title>Hyperbolic Hierarchical Knowledge Graph Embeddings for Link Prediction in Low Dimensions</title><link>http://arxiv.org/abs/2204.13704v2</link><description>Knowledge graph embeddings (KGE) have been validated as powerful methods forinferring missing links in knowledge graphs (KGs) that they typically mapentities into Euclidean space and treat relations as transformations ofentities. Recently, some Euclidean KGE methods have been enhanced to modelsemantic hierarchies commonly found in KGs, improving the performance of linkprediction. To embed hierarchical data, hyperbolic space has emerged as apromising alternative to traditional Euclidean space, offering high fidelityand lower memory consumption. Unlike Euclidean, hyperbolic space providescountless curvatures to choose from. However, it is difficult for existinghyperbolic KGE methods to obtain the optimal curvature settings manually,thereby limiting their ability to effectively model semantic hierarchies. Toaddress this limitation, we propose a novel KGE model called$\textbf{Hyp}$erbolic $\textbf{H}$ierarchical $\textbf{KGE}$ (HypHKGE). Thismodel introduces attention-based learnable curvatures for hyperbolic space,which helps preserve rich semantic hierarchies. Furthermore, to utilize thepreserved hierarchies for inferring missing links, we define hyperbolichierarchical transformations based on the theory of hyperbolic geometry,including both inter-level and intra-level modeling. Experiments demonstratethe effectiveness of the proposed HypHKGE model on the three benchmark datasets(WN18RR, FB15K-237, and YAGO3-10). The source code will be publicly released athttps://github.com/wjzheng96/HypHKGE.</description><author>Wenjie Zheng, Wenxue Wang, Shu Zhao, Fulan Qian</author><pubDate>Fri, 23 Feb 2024 15:38:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.13704v2</guid></item><item><title>SparDL: Distributed Deep Learning Training with Efficient Sparse Communication</title><link>http://arxiv.org/abs/2304.00737v2</link><description>Top-k sparsification has recently been widely used to reduce thecommunication volume in distributed deep learning. However, due to the SparseGradient Accumulation (SGA) dilemma, the performance of top-k sparsificationstill has limitations. Recently, a few methods have been put forward to handlethe SGA dilemma. Regrettably, even the state-of-the-art method suffers fromseveral drawbacks, e.g., it relies on an inefficient communication algorithmand requires extra transmission steps. Motivated by the limitations of existingmethods, we propose a novel efficient sparse communication framework, calledSparDL. Specifically, SparDL uses the Spar-Reduce-Scatter algorithm, which isbased on an efficient Reduce-Scatter model, to handle the SGA dilemma withoutadditional communication operations. Besides, to further reduce the latencycost and improve the efficiency of SparDL, we propose the Spar-All-Gatheralgorithm. Moreover, we propose the global residual collection algorithm toensure fast convergence of model training. Finally, extensive experiments areconducted to validate the superiority of SparDL.</description><author>Minjun Zhao, Yichen Yin, Yuren Mao, Qing Liu, Lu Chen, Yunjun Gao</author><pubDate>Fri, 23 Feb 2024 15:35:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.00737v2</guid></item><item><title>Homeostatic motion planning with innate physics knowledge</title><link>http://arxiv.org/abs/2402.15384v1</link><description>Living organisms interact with their surroundings in a closed-loop fashion,where sensory inputs dictate the initiation and termination of behaviours. Evensimple animals are able to develop and execute complex plans, which has not yetbeen replicated in robotics using pure closed-loop input control. We propose asolution to this problem by defining a set of discrete and temporaryclosed-loop controllers, called "tasks", each representing a closed-loopbehaviour. We further introduce a supervisory module which has an innateunderstanding of physics and causality, through which it can simulate theexecution of task sequences over time and store the results in a model of theenvironment. On the basis of this model, plans can be made by chainingtemporary closed-loop controllers. The proposed framework was implemented for areal robot and tested in two scenarios as proof of concept.</description><author>Giulia Lafratta, Bernd Porr, Christopher Chandler, Alice Miller</author><pubDate>Fri, 23 Feb 2024 15:30:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15384v1</guid></item><item><title>InteRACT: Transformer Models for Human Intent Prediction Conditioned on Robot Actions</title><link>http://arxiv.org/abs/2311.12943v2</link><description>In collaborative human-robot manipulation, a robot must predict human intentsand adapt its actions accordingly to smoothly execute tasks. However, thehuman's intent in turn depends on actions the robot takes, creating achicken-or-egg problem. Prior methods ignore such inter-dependency and insteadtrain marginal intent prediction models independent of robot actions. This isbecause training conditional models is hard given a lack of paired human-robotinteraction datasets. Can we instead leverage large-scale human-humaninteraction data that is more easily accessible? Our key insight is to exploita correspondence between human and robot actions that enables transfer learningfrom human-human to human-robot data. We propose a novel architecture,InteRACT, that pre-trains a conditional intent prediction model on largehuman-human datasets and fine-tunes on a small human-robot dataset. We evaluateon a set of real-world collaborative human-robot manipulation tasks and showthat our conditional model improves over various marginal baselines. We alsointroduce new techniques to tele-operate a 7-DoF robot arm and collect adiverse range of human-robot collaborative manipulation data, which weopen-source.</description><author>Kushal Kedia, Atiksh Bhardwaj, Prithwish Dan, Sanjiban Choudhury</author><pubDate>Fri, 23 Feb 2024 15:29:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12943v2</guid></item><item><title>Outlier detection by ensembling uncertainty with negative objectness</title><link>http://arxiv.org/abs/2402.15374v1</link><description>Outlier detection is an essential capability in safety-critical applicationsof supervised visual recognition. Most of the existing methods deliver bestresults by encouraging standard closed-set models to produce low-confidencepredictions in negative training data. However, that approach conflatesprediction uncertainty with recognition of the negative class. We thereforereconsider direct prediction of K+1 logits that correspond to K groundtruthclasses and one outlier class. This setup allows us to formulate a novelanomaly score as an ensemble of in-distribution uncertainty and the posteriorof the outlier class which we term negative objectness. Now outliers can beindependently detected due to i) high prediction uncertainty or ii) similaritywith negative data. We embed our method into a dense prediction architecturewith mask-level recognition over K+2 classes. The training procedure encouragesthe novel K+2-th class to learn negative objectness at pasted negativeinstances. Our models outperform the current state-of-the art on standardbenchmarks for image-wide and pixel-level outlier detection with and withouttraining on real negative data.</description><author>Anja Delić, Matej Grcić, Siniša Šegvić</author><pubDate>Fri, 23 Feb 2024 15:19:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15374v1</guid></item><item><title>RoboLLM: Robotic Vision Tasks Grounded on Multimodal Large Language Models</title><link>http://arxiv.org/abs/2310.10221v2</link><description>Robotic vision applications often necessitate a wide range of visualperception tasks, such as object detection, segmentation, and identification.While there have been substantial advances in these individual tasks,integrating specialized models into a unified vision pipeline presentssignificant engineering challenges and costs. Recently, Multimodal LargeLanguage Models (MLLMs) have emerged as novel backbones for various downstreamtasks. We argue that leveraging the pre-training capabilities of MLLMs enablesthe creation of a simplified framework, thus mitigating the need fortask-specific encoders. Specifically, the large-scale pretrained knowledge inMLLMs allows for easier fine-tuning to downstream robotic vision tasks andyields superior performance. We introduce the RoboLLM framework, equipped witha BEiT-3 backbone, to address all visual perception tasks in the ARMBenchchallenge-a large-scale robotic manipulation dataset about real-world warehousescenarios. RoboLLM not only outperforms existing baselines but alsosubstantially reduces the engineering burden associated with model selectionand tuning. The source code is publicly available athttps://github.com/longkukuhi/armbench.</description><author>Zijun Long, George Killick, Richard McCreadie, Gerardo Aragon Camarasa</author><pubDate>Fri, 23 Feb 2024 15:18:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10221v2</guid></item><item><title>Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation</title><link>http://arxiv.org/abs/2311.04254v3</link><description>Recent advancements in Large Language Models (LLMs) have revolutionizeddecision-making by breaking down complex problems into more manageable languagesequences referred to as "thoughts". An effective thought design shouldconsider three key perspectives: performance, efficiency, and flexibility.However, existing thought can at most exhibit two of these attributes. Toaddress these limitations, we introduce a novel thought prompting approachcalled "Everything of Thoughts" (XoT) to defy the law of "Penrose triangle ofexisting thought paradigms. XoT leverages pretrained reinforcement learning andMonte Carlo Tree Search (MCTS) to incorporate external domain knowledge intothoughts, thereby enhancing LLMs' capabilities and enabling them to generalizeto unseen problems efficiently. Through the utilization of the MCTS-LLMcollaborative thought revision framework, this approach autonomously produceshigh-quality comprehensive cognitive mappings with minimal LLM interactions.Additionally, XoT empowers LLMs to engage in unconstrained thinking, allowingfor flexible cognitive mappings for problems with multiple solutions. Weevaluate XoT on several challenging multi-solution problem-solving tasks,including Game of 24, 8-Puzzle, and Pocket Cube. Our results demonstrate thatXoT significantly outperforms existing approaches. Notably, XoT can yieldmultiple solutions with just one LLM call, showcasing its remarkableproficiency in addressing complex problems across diverse domains.</description><author>Ruomeng Ding, Chaoyun Zhang, Lu Wang, Yong Xu, Minghua Ma, Wei Zhang, Si Qin, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang</author><pubDate>Fri, 23 Feb 2024 15:09:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04254v3</guid></item><item><title>Adaptive Deep Learning for Efficient Visual Pose Estimation aboard Ultra-low-power Nano-drones</title><link>http://arxiv.org/abs/2401.15236v2</link><description>Sub-10cm diameter nano-drones are gaining momentum thanks to theirapplicability in scenarios prevented to bigger flying drones, such as in narrowenvironments and close to humans. However, their tiny form factor also bringstheir major drawback: ultra-constrained memory and processors for the onboardexecution of their perception pipelines. Therefore, lightweight deeplearning-based approaches are becoming increasingly popular, stressing howcomputational efficiency and energy-saving are paramount as they can make thedifference between a fully working closed-loop system and a failing one. Inthis work, to maximize the exploitation of the ultra-limited resources aboardnano-drones, we present a novel adaptive deep learning-based mechanism for theefficient execution of a vision-based human pose estimation task. We leveragetwo State-of-the-Art (SoA) convolutional neural networks (CNNs) with differentregression performance vs. computational costs trade-offs. By combining theseCNNs with three novel adaptation strategies based on the output's temporalconsistency and on auxiliary tasks to swap the CNN being executed proactively,we present six different systems. On a real-world dataset and the actualnano-drone hardware, our best-performing system, compared to executing only thebigger and most accurate SoA model, shows 28% latency reduction while keepingthe same mean absolute error (MAE), 3% MAE reduction while being iso-latency,and the absolute peak performance, i.e., 6% better than SoA model.</description><author>Beatrice Alessandra Motetti, Luca Crupi, Mustafa Omer Mohammed Elamin Elshaigi, Matteo Risso, Daniele Jahier Pagliari, Daniele Palossi, Alessio Burrello</author><pubDate>Fri, 23 Feb 2024 15:07:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15236v2</guid></item><item><title>Dual Encoder: Exploiting the Potential of Syntactic and Semantic for Aspect Sentiment Triplet Extraction</title><link>http://arxiv.org/abs/2402.15370v1</link><description>Aspect Sentiment Triple Extraction (ASTE) is an emerging task in fine-grainedsentiment analysis. Recent studies have employed Graph Neural Networks (GNN) tomodel the syntax-semantic relationships inherent in triplet elements. However,they have yet to fully tap into the vast potential of syntactic and semanticinformation within the ASTE task. In this work, we propose a \emph{DualEncoder: Exploiting the potential of Syntactic and Semantic} model (D2E2S),which maximizes the syntactic and semantic relationships among words.Specifically, our model utilizes a dual-channel encoder with a BERT channel tocapture semantic information, and an enhanced LSTM channel for comprehensivesyntactic information capture. Subsequently, we introduce the heterogeneousfeature interaction module to capture intricate interactions between dependencysyntax and attention semantics, and to dynamically select vital nodes. Weleverage the synergy of these modules to harness the significant potential ofsyntactic and semantic information in ASTE tasks. Testing on public benchmarks,our D2E2S model surpasses the current state-of-the-art(SOTA), demonstrating itseffectiveness.</description><author>Xiaowei Zhao, Yong Zhou, Xiujuan Xu</author><pubDate>Fri, 23 Feb 2024 15:07:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15370v1</guid></item><item><title>Safe Task Planning for Language-Instructed Multi-Robot Systems using Conformal Prediction</title><link>http://arxiv.org/abs/2402.15368v1</link><description>This paper addresses task planning problems for language-instructed robotteams. Tasks are expressed in natural language (NL), requiring the robots toapply their capabilities (e.g., mobility, manipulation, and sensing) at variouslocations and semantic objects. Several recent works have addressed similarplanning problems by leveraging pre-trained Large Language Models (LLMs) todesign effective multi-robot plans. However, these approaches lack missionperformance and safety guarantees. To address this challenge, we introduce anew decentralized LLM-based planner that is capable of achieving high missionsuccess rates. This is accomplished by leveraging conformal prediction (CP), adistribution-free uncertainty quantification tool in black-box models. CPallows the proposed multi-robot planner to reason about its inherentuncertainty in a decentralized fashion, enabling robots to make individualdecisions when they are sufficiently certain and seek help otherwise. We show,both theoretically and empirically, that the proposed planner can achieveuser-specified task success rates while minimizing the overall number of helprequests. We demonstrate the performance of our approach on multi-robot homeservice applications. We also show through comparative experiments, that ourmethod outperforms recent centralized and decentralized multi-robot LLM-basedplanners in terms of in terms of its ability to design correct plans. Theadvantage of our algorithm over baselines becomes more pronounced withincreasing mission complexity and robot team size.</description><author>Jun Wang, Guocheng He, Yiannis Kantaros</author><pubDate>Fri, 23 Feb 2024 15:02:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15368v1</guid></item><item><title>Generating Zero-shot Abstractive Explanations for Rumour Verification</title><link>http://arxiv.org/abs/2401.12713v3</link><description>The task of rumour verification in social media concerns assessing theveracity of a claim on the basis of conversation threads that result from it.While previous work has focused on predicting a veracity label, here wereformulate the task to generate model-centric free-text explanations of arumour's veracity. The approach is model agnostic in that it generalises to anymodel. Here we propose a novel GNN-based rumour verification model. We follow azero-shot approach by first applying post-hoc explainability methods to scorethe most important posts within a thread and then we use these posts togenerate informative explanations using opinion-guided summarisation. Toevaluate the informativeness of the explanatory summaries, we exploit thefew-shot learning capabilities of a large language model (LLM). Our experimentsshow that LLMs can have similar agreement to humans in evaluating summaries.Importantly, we show explanatory abstractive summaries are more informative andbetter reflect the predicted rumour veracity than just using the highestranking posts in the thread.</description><author>Iman Munire Bilal, Preslav Nakov, Rob Procter, Maria Liakata</author><pubDate>Fri, 23 Feb 2024 15:01:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12713v3</guid></item><item><title>Efficient semi-supervised inference for logistic regression under case-control studies</title><link>http://arxiv.org/abs/2402.15365v1</link><description>Semi-supervised learning has received increasingly attention in statisticsand machine learning. In semi-supervised learning settings, a labeled data setwith both outcomes and covariates and an unlabeled data set with covariatesonly are collected. We consider an inference problem in semi-supervisedsettings where the outcome in the labeled data is binary and the labeled datais collected by case-control sampling. Case-control sampling is an effectivesampling scheme for alleviating imbalance structure in binary data. Under thelogistic model assumption, case-control data can still provide consistentestimator for the slope parameter of the regression model. However, theintercept parameter is not identifiable. Consequently, the marginal caseproportion cannot be estimated from case-control data. We find out that withthe availability of the unlabeled data, the intercept parameter can beidentified in semi-supervised learning setting. We construct the likelihoodfunction of the observed labeled and unlabeled data and obtain the maximumlikelihood estimator via an iterative algorithm. The proposed estimator isshown to be consistent, asymptotically normal, and semiparametricallyefficient. Extensive simulation studies are conducted to show the finite sampleperformance of the proposed method. The results imply that the unlabeled datanot only helps to identify the intercept but also improves the estimationefficiency of the slope parameter. Meanwhile, the marginal case proportion canbe estimated accurately by the proposed method.</description><author>Zhuojun Quan, Yuanyuan Lin, Kani Chen, Wen Yu</author><pubDate>Fri, 23 Feb 2024 14:55:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15365v1</guid></item><item><title>Centaur: Federated Learning for Constrained Edge Devices</title><link>http://arxiv.org/abs/2211.04175v3</link><description>Federated learning (FL) facilitates new applications at the edge, especiallyfor wearable and Internet-of-Thing devices. Such devices capture a large anddiverse amount of data, but they have memory, compute, power, and connectivityconstraints which hinder their participation in FL. We propose Centaur, amultitier FL framework, enabling ultra-constrained devices to efficientlyparticipate in FL on large neural nets. Centaur combines two major ideas: (i) adata selection scheme to choose a portion of samples that accelerates thelearning, and (ii) a partition-based training algorithm that integrates bothconstrained and powerful devices owned by the same user. Evaluations, on fourbenchmark neural nets and three datasets, show that Centaur gains ~10\% higheraccuracy than local training on constrained devices with ~58\% energy saving onaverage. Our experimental results also demonstrate the superior efficiency ofCentaur when dealing with imbalanced data, client participation heterogeneity,and various network connection probabilities.</description><author>Fan Mo, Mohammad Malekzadeh, Soumyajit Chatterjee, Fahim Kawsar, Akhil Mathur</author><pubDate>Fri, 23 Feb 2024 14:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.04175v3</guid></item><item><title>All Thresholds Barred: Direct Estimation of Call Density in Bioacoustic Data</title><link>http://arxiv.org/abs/2402.15360v1</link><description>Passive acoustic monitoring (PAM) studies generate thousands of hours ofaudio, which may be used to monitor specific animal populations, conduct broadbiodiversity surveys, detect threats such as poachers, and more. Machinelearning classifiers for species identification are increasingly being used toprocess the vast amount of audio generated by bioacoustic surveys, expeditinganalysis and increasing the utility of PAM as a management tool. In commonpractice, a threshold is applied to classifier output scores, and scores abovethe threshold are aggregated into a detection count. The choice of thresholdproduces biased counts of vocalizations, which are subject to falsepositive/negative rates that may vary across subsets of the dataset. In thiswork, we advocate for directly estimating call density: The proportion ofdetection windows containing the target vocalization, regardless of classifierscore. Our approach targets a desirable ecological estimator and provides amore rigorous grounding for identifying the core problems caused bydistribution shifts -- when the defining characteristics of the datadistribution change -- and designing strategies to mitigate them. We propose avalidation scheme for estimating call density in a body of data and obtain,through Bayesian reasoning, probability distributions of confidence scores forboth the positive and negative classes. We use these distributions to predictsite-level densities, which may be subject to distribution shifts. We test ourproposed methods on a real-world study of Hawaiian birds and provide simulationresults leveraging existing fully annotated datasets, demonstrating robustnessto variations in call density and classifier model quality.</description><author>Amanda K. Navine, Tom Denton, Matthew J. Weldy, Patrick J. Hart</author><pubDate>Fri, 23 Feb 2024 14:52:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15360v1</guid></item><item><title>Streaming Gaussian Dirichlet Random Fields for Spatial Predictions of High Dimensional Categorical Observations</title><link>http://arxiv.org/abs/2402.15359v1</link><description>We present the Streaming Gaussian Dirichlet Random Field (S-GDRF) model, anovel approach for modeling a stream of spatiotemporally distributed, sparse,high-dimensional categorical observations. The proposed approach efficientlylearns global and local patterns in spatiotemporal data, allowing for fastinference and querying with a bounded time complexity. Using a high-resolutiondata series of plankton images classified with a neural network, we demonstratethe ability of the approach to make more accurate predictions compared to aVariational Gaussian Process (VGP), and to learn a predictive distribution ofobservations from streaming categorical data. S-GDRFs open the door to enablingefficient informative path planning over high-dimensional categoricalobservations, which until now has not been feasible.</description><author>J. E. San Soucie, H. M. Sosik, Y. Girdhar</author><pubDate>Fri, 23 Feb 2024 14:52:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15359v1</guid></item><item><title>Generative Artificial Intelligence in Healthcare: Ethical Considerations and Assessment Checklist</title><link>http://arxiv.org/abs/2311.02107v2</link><description>The widespread use of ChatGPT and other emerging technology powered bygenerative artificial intelligence (GenAI) has drawn much attention topotential ethical issues, especially in high-stakes applications such ashealthcare, but ethical discussions are yet to translate into operationalisablesolutions. Furthermore, ongoing ethical discussions often neglect other typesof GenAI that have been used to synthesise data (e.g., images) for research andpractical purposes, which resolved some ethical issues and exposed others. Weconduct a scoping review of ethical discussions on GenAI in healthcare tocomprehensively analyse gaps in the current research, and further propose toreduce the gaps by developing a checklist for comprehensive assessment andtransparent documentation of ethical discussions in GenAI research. Thechecklist can be readily integrated into the current peer review andpublication system to enhance GenAI research, and may be used forethics-related disclosures for GenAI-powered products, healthcare applicationsof such products and beyond.</description><author>Yilin Ning, Salinelat Teixayavong, Yuqing Shang, Julian Savulescu, Vaishaanth Nagaraj, Di Miao, Mayli Mertens, Daniel Shu Wei Ting, Jasmine Chiat Ling Ong, Mingxuan Liu, Jiuwen Cao, Michael Dunn, Roger Vaughan, Marcus Eng Hock Ong, Joseph Jao-Yiu Sung, Eric J Topol, Nan Liu</author><pubDate>Fri, 23 Feb 2024 14:50:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02107v2</guid></item><item><title>Almost Equivariance via Lie Algebra Convolutions</title><link>http://arxiv.org/abs/2310.13164v5</link><description>Recently, the equivariance of models with respect to a group action hasbecome an important topic of research in machine learning. Analysis of thebuilt-in equivariance of existing neural network architectures, as well as thestudy of building models that explicitly "bake in" equivariance, have becomesignificant research areas in their own right. However, imbuing an architecturewith a specific group equivariance imposes a strong prior on the types of datatransformations that the model expects to see. While strictly-equivariantmodels enforce symmetries, real-world data does not always conform to suchstrict equivariances. In such cases, the prior of strict equivariance canactually prove too strong and cause models to underperform. Therefore, in thiswork we study a closely related topic, that of almost equivariance. We providea definition of almost equivariance and give a practical method for encodingalmost equivariance in models by appealing to the Lie algebra of a Lie group.Specifically, we define Lie algebra convolutions and demonstrate that theyoffer several benefits over Lie group convolutions, including beingwell-defined for non-compact Lie groups having non-surjective exponential map.From there, we demonstrate connections between the notions of equivariance andisometry and those of almost equivariance and almost isometry. We prove twoexistence theorems, one showing the existence of almost isometries withinbounded distance of isometries of a manifold, and another showing the conversefor Hilbert spaces. We extend these theorems to prove the existence of almostequivariant manifold embeddings within bounded distance of fully equivariantembedding functions, subject to certain constraints on the group action and thefunction class. Finally, we demonstrate the validity of our approach bybenchmarking against datasets in fully equivariant and almost equivariantsettings.</description><author>Daniel McNeela</author><pubDate>Fri, 23 Feb 2024 14:45:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13164v5</guid></item><item><title>Diffusion Models for Reinforcement Learning: A Survey</title><link>http://arxiv.org/abs/2311.01223v4</link><description>Diffusion models surpass previous generative models in sample quality andtraining stability. Recent works have shown the advantages of diffusion modelsin improving reinforcement learning (RL) solutions. This survey aims to providean overview of this emerging field and hopes to inspire new avenues ofresearch. First, we examine several challenges encountered by RL algorithms.Then, we present a taxonomy of existing methods based on the roles of diffusionmodels in RL and explore how the preceding challenges are addressed. We furtheroutline successful applications of diffusion models in various RL-relatedtasks. Finally, we conclude the survey and offer insights into future researchdirections. We are actively maintaining a GitHub repository for papers andother related resources in utilizing diffusion models in RL:https://github.com/apexrl/Diff4RLSurvey.</description><author>Zhengbang Zhu, Hanye Zhao, Haoran He, Yichao Zhong, Shenyu Zhang, Haoquan Guo, Tingting Chen, Weinan Zhang</author><pubDate>Fri, 23 Feb 2024 14:42:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01223v4</guid></item><item><title>Rapid Bayesian identification of sparse nonlinear dynamics from scarce and noisy data</title><link>http://arxiv.org/abs/2402.15357v1</link><description>We propose a fast probabilistic framework for identifying differentialequations governing the dynamics of observed data. We recast the SINDy methodwithin a Bayesian framework and use Gaussian approximations for the prior andlikelihood to speed up computation. The resulting method, Bayesian-SINDy, notonly quantifies uncertainty in the parameters estimated but also is more robustwhen learning the correct model from limited and noisy data. Using bothsynthetic and real-life examples such as Lynx-Hare population dynamics, wedemonstrate the effectiveness of the new framework in learning correct modelequations and compare its computational and data efficiency with existingmethods. Because Bayesian-SINDy can quickly assimilate data and is robustagainst noise, it is particularly suitable for biological data and real-timesystem identification in control. Its probabilistic framework also enables thecalculation of information entropy, laying the foundation for an activelearning strategy.</description><author>Lloyd Fung, Urban Fasel, Matthew P. Juniper</author><pubDate>Fri, 23 Feb 2024 14:41:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15357v1</guid></item><item><title>Can large language models build causal graphs?</title><link>http://arxiv.org/abs/2303.05279v2</link><description>Building causal graphs can be a laborious process. To ensure all relevantcausal pathways have been captured, researchers often have to discuss withclinicians and experts while also reviewing extensive relevant medicalliterature. By encoding common and medical knowledge, large language models(LLMs) represent an opportunity to ease this process by automatically scoringedges (i.e., connections between two variables) in potential graphs. LLMshowever have been shown to be brittle to the choice of probing words, context,and prompts that the user employs. In this work, we evaluate if LLMs can be auseful tool in complementing causal graph development.</description><author>Stephanie Long, Tibor Schuster, Alexandre Piché</author><pubDate>Fri, 23 Feb 2024 14:40:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05279v2</guid></item><item><title>A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence</title><link>http://arxiv.org/abs/2402.12928v2</link><description>By consolidating scattered knowledge, the literature review provides acomprehensive understanding of the investigated topic. However, excessivereviews, especially in the booming field of pattern analysis and machineintelligence (PAMI), raise concerns for both researchers and reviewers. Inresponse to these concerns, this Analysis aims to provide a thorough review ofreviews in the PAMI field from diverse perspectives. First, large languagemodel-empowered bibliometric indicators are proposed to evaluate literaturereviews automatically. To facilitate this, a meta-data database dubbed RiPAMI,and a topic dataset are constructed, which are utilized to obtain statisticalcharacteristics of PAMI reviews. Unlike traditional bibliometric measurements,the proposed article-level indicators provide real-time and field-normalizedquantified assessments of reviews without relying on user-defined keywords.Second, based on these indicators, the study presents comparative analyses ofdifferent reviews, unveiling the characteristics of publications across variousfields, periods, and journals. The newly emerging AI-generated literaturereviews are also appraised, and the observed differences suggest that mostAI-generated reviews still lag behind human-authored reviews in severalaspects. Third, we briefly provide a subjective evaluation of representativePAMI reviews and introduce a paper structure-based typology of literaturereviews. This typology may improve the clarity and effectiveness for scholarsin reading and writing reviews, while also serving as a guide for AI systems ingenerating well-organized reviews. Finally, this Analysis offers insights intothe current challenges of literature reviews and envisions future directionsfor their development.</description><author>Penghai Zhao, Xin Zhang, Ming-Ming Cheng, Jian Yang, Xiang Li</author><pubDate>Fri, 23 Feb 2024 14:40:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12928v2</guid></item><item><title>On normalization-equivariance properties of supervised and unsupervised denoising methods: a survey</title><link>http://arxiv.org/abs/2402.15352v1</link><description>Image denoising is probably the oldest and still one of the most activeresearch topic in image processing. Many methodological concepts have beenintroduced in the past decades and have improved performances significantly inrecent years, especially with the emergence of convolutional neural networksand supervised deep learning. In this paper, we propose a survey of guided tourof supervised and unsupervised learning methods for image denoising,classifying the main principles elaborated during this evolution, with aparticular concern given to recent developments in supervised learning. It isconceived as a tutorial organizing in a comprehensive framework currentapproaches. We give insights on the rationales and limitations of the mostperformant methods in the literature, and we highlight the common featuresbetween many of them. Finally, we focus on on the normalization equivarianceproperties that is surprisingly not guaranteed with most of supervised methods.It is of paramount importance that intensity shifting or scaling applied to theinput image results in a corresponding change in the denoiser output.</description><author>Sébastien Herbreteau, Charles Kervrann</author><pubDate>Fri, 23 Feb 2024 14:39:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15352v1</guid></item><item><title>AutoMMLab: Automatically Generating Deployable Models from Language Instructions for Computer Vision Tasks</title><link>http://arxiv.org/abs/2402.15351v1</link><description>Automated machine learning (AutoML) is a collection of techniques designed toautomate the machine learning development process. While traditional AutoMLapproaches have been successfully applied in several critical steps of modeldevelopment (e.g. hyperparameter optimization), there lacks a AutoML systemthat automates the entire end-to-end model production workflow. To fill thisblank, we present AutoMMLab, a general-purpose LLM-empowered AutoML system thatfollows user's language instructions to automate the whole model productionworkflow for computer vision tasks. The proposed AutoMMLab system effectivelyemploys LLMs as the bridge to connect AutoML and OpenMMLab community,empowering non-expert individuals to easily build task-specific models via auser-friendly language interface. Specifically, we propose RU-LLaMA tounderstand users' request and schedule the whole pipeline, and propose a novelLLM-based hyperparameter optimizer called HPO-LLaMA to effectively search forthe optimal hyperparameters. Experiments show that our AutoMMLab system isversatile and covers a wide range of mainstream tasks, includingclassification, detection, segmentation and keypoint estimation. We furtherdevelop a new benchmark, called LAMP, for studying key components in theend-to-end prompt-based model training pipeline. Code, model, and data will bereleased.</description><author>Zekang Yang, Wang Zeng, Sheng Jin, Chen Qian, Ping Luo, Wentao Liu</author><pubDate>Fri, 23 Feb 2024 14:38:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15351v1</guid></item><item><title>Farsight: Fostering Responsible AI Awareness During AI Application Prototyping</title><link>http://arxiv.org/abs/2402.15350v1</link><description>Prompt-based interfaces for Large Language Models (LLMs) have madeprototyping and building AI-powered applications easier than ever before.However, identifying potential harms that may arise from AI applicationsremains a challenge, particularly during prompt-based prototyping. To addressthis, we present Farsight, a novel in situ interactive tool that helps peopleidentify potential harms from the AI applications they are prototyping. Basedon a user's prompt, Farsight highlights news articles about relevant AIincidents and allows users to explore and edit LLM-generated use cases,stakeholders, and harms. We report design insights from a co-design study with10 AI prototypers and findings from a user study with 42 AI prototypers. Afterusing Farsight, AI prototypers in our user study are better able toindependently identify potential harms associated with a prompt and find ourtool more useful and usable than existing resources. Their qualitative feedbackalso highlights that Farsight encourages them to focus on end-users and thinkbeyond immediate harms. We discuss these findings and reflect on theirimplications for designing AI prototyping experiences that meaningfully engagewith AI harms. Farsight is publicly accessible at:https://PAIR-code.github.io/farsight.</description><author>Zijie J. Wang, Chinmay Kulkarni, Lauren Wilcox, Michael Terry, Michael Madaio</author><pubDate>Fri, 23 Feb 2024 14:38:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15350v1</guid></item><item><title>OmniPred: Language Models as Universal Regressors</title><link>http://arxiv.org/abs/2402.14547v2</link><description>Over the broad landscape of experimental design, regression has been apowerful tool to accurately predict the outcome metrics of a system or modelgiven a set of parameters, but has been traditionally restricted to methodswhich are only applicable to a specific task. In this paper, we proposeOmniPred, a framework for training language models as universal end-to-endregressors over $(x,y)$ evaluation data from diverse real world experiments.Using data sourced from Google Vizier, one of the largest blackbox optimizationdatabases in the world, our extensive experiments demonstrate that through onlytextual representations of mathematical parameters and values, language modelsare capable of very precise numerical regression, and if given the opportunityto train over multiple tasks, can significantly outperform traditionalregression models.</description><author>Xingyou Song, Oscar Li, Chansoo Lee, Bangding Yang, Daiyi Peng, Sagi Perel, Yutian Chen</author><pubDate>Fri, 23 Feb 2024 14:37:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14547v2</guid></item><item><title>SynTable: A Synthetic Data Generation Pipeline for Unseen Object Amodal Instance Segmentation of Cluttered Tabletop Scenes</title><link>http://arxiv.org/abs/2307.07333v2</link><description>In this work, we present SynTable, a unified and flexible Python-baseddataset generator built using NVIDIA's Isaac Sim Replicator Composer forgenerating high-quality synthetic datasets for unseen object amodal instancesegmentation of cluttered tabletop scenes. Our dataset generation tool canrender a complex 3D scene containing object meshes, materials, textures,lighting, and backgrounds. Metadata, such as modal and amodal instancesegmentation masks, occlusion masks, depth maps, bounding boxes, and materialproperties, can be generated to automatically annotate the scene according tothe users' requirements. Our tool eliminates the need for manual labeling inthe dataset generation process while ensuring the quality and accuracy of thedataset. In this work, we discuss our design goals, framework architecture, andthe performance of our tool. We demonstrate the use of a sample datasetgenerated using SynTable by ray tracing for training a state-of-the-art model,UOAIS-Net. The results show significantly improved performance in Sim-to-Realtransfer when evaluated on the OSD-Amodal dataset. We offer this tool as anopen-source, easy-to-use, photorealistic dataset generator for advancingresearch in deep learning and synthetic data generation.</description><author>Zhili Ng, Haozhe Wang, Zhengshen Zhang, Francis Tay Eng Hock, Marcelo H. Ang Jr</author><pubDate>Fri, 23 Feb 2024 14:34:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07333v2</guid></item><item><title>Information-Theoretic Safe Bayesian Optimization</title><link>http://arxiv.org/abs/2402.15347v1</link><description>We consider a sequential decision making task, where the goal is to optimizean unknown function without evaluating parameters that violate an a~prioriunknown (safety) constraint. A common approach is to place a Gaussian processprior on the unknown functions and allow evaluations only in regions that aresafe with high probability. Most current methods rely on a discretization ofthe domain and cannot be directly extended to the continuous case. Moreover,the way in which they exploit regularity assumptions about the constraintintroduces an additional critical hyperparameter. In this paper, we propose aninformation-theoretic safe exploration criterion that directly exploits the GPposterior to identify the most informative safe parameters to evaluate. Thecombination of this exploration criterion with a well known Bayesianoptimization acquisition function yields a novel safe Bayesian optimizationselection criterion. Our approach is naturally applicable to continuous domainsand does not require additional explicit hyperparameters. We theoreticallyanalyze the method and show that we do not violate the safety constraint withhigh probability and that we learn about the value of the safe optimum up toarbitrary precision. Empirical evaluations demonstrate improved data-efficiencyand scalability.</description><author>Alessandro G. Bottero, Carlos E. Luis, Julia Vinogradska, Felix Berkenkamp, Jan Peters</author><pubDate>Fri, 23 Feb 2024 14:31:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15347v1</guid></item><item><title>Contact Energy Based Hindsight Experience Prioritization</title><link>http://arxiv.org/abs/2312.02677v2</link><description>Multi-goal robot manipulation tasks with sparse rewards are difficult forreinforcement learning (RL) algorithms due to the inefficiency in collectingsuccessful experiences. Recent algorithms such as Hindsight Experience Replay(HER) expedite learning by taking advantage of failed trajectories andreplacing the desired goal with one of the achieved states so that any failedtrajectory can be utilized as a contribution to learning. However, HERuniformly chooses failed trajectories, without taking into account which onesmight be the most valuable for learning. In this paper, we address this problemand propose a novel approach Contact Energy Based Prioritization~(CEBP) toselect the samples from the replay buffer based on rich information due tocontact, leveraging the touch sensors in the gripper of the robot and objectdisplacement. Our prioritization scheme favors sampling of contact-richexperiences, which are arguably the ones providing the largest amount ofinformation. We evaluate our proposed approach on various sparse reward robotictasks and compare them with the state-of-the-art methods. We show that ourmethod surpasses or performs on par with those methods on robot manipulationtasks. Finally, we deploy the trained policy from our method to a real Frankarobot for a pick-and-place task. We observe that the robot can solve the tasksuccessfully. The videos and code are publicly available at:https://erdiphd.github.io/HER_force</description><author>Erdi Sayar, Zhenshan Bing, Carlo D'Eramo, Ozgur S. Oguz, Alois Knoll</author><pubDate>Fri, 23 Feb 2024 14:30:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02677v2</guid></item><item><title>Fourier Basis Density Model</title><link>http://arxiv.org/abs/2402.15345v1</link><description>We introduce a lightweight, flexible and end-to-end trainable probabilitydensity model parameterized by a constrained Fourier basis. We assess itsperformance at approximating a range of multi-modal 1D densities, which aregenerally difficult to fit. In comparison to the deep factorized modelintroduced in [1], our model achieves a lower cross entropy at a similarcomputational budget. In addition, we also evaluate our method on a toycompression task, demonstrating its utility in learned compression.</description><author>Alfredo De la Fuente, Saurabh Singh, Johannes Ballé</author><pubDate>Fri, 23 Feb 2024 14:26:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15345v1</guid></item><item><title>Iteration and Stochastic First-order Oracle Complexities of Stochastic Gradient Descent using Constant and Decaying Learning Rates</title><link>http://arxiv.org/abs/2402.15344v1</link><description>The performance of stochastic gradient descent (SGD), which is the simplestfirst-order optimizer for training deep neural networks, depends on not onlythe learning rate but also the batch size. They both affect the number ofiterations and the stochastic first-order oracle (SFO) complexity needed fortraining. In particular, the previous numerical results indicated that, for SGDusing a constant learning rate, the number of iterations needed for trainingdecreases when the batch size increases, and the SFO complexity needed fortraining is minimized at a critical batch size and that it increases once thebatch size exceeds that size. Here, we study the relationship between batchsize and the iteration and SFO complexities needed for nonconvex optimizationin deep learning with SGD using constant or decaying learning rates and showthat SGD using the critical batch size minimizes the SFO complexity. We alsoprovide numerical comparisons of SGD with the existing first-order optimizersand show the usefulness of SGD using a critical batch size. Moreover, we showthat measured critical batch sizes are close to the sizes estimated from ourtheoretical results.</description><author>Kento Imaizumi, Hideaki Iiduka</author><pubDate>Fri, 23 Feb 2024 14:24:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15344v1</guid></item><item><title>NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data</title><link>http://arxiv.org/abs/2402.15343v1</link><description>Large Language Models (LLMs) have shown impressive abilities in dataannotation, opening the way for new approaches to solve classic NLP problems.In this paper, we show how to use LLMs to create NuNER, a compact languagerepresentation model specialized in the Named Entity Recognition (NER) task.NuNER can be fine-tuned to solve downstream NER problems in a data-efficientway, outperforming similar-sized foundation models in the few-shot regime andcompeting with much larger LLMs. We find that the size and entity-typediversity of the pre-training dataset are key to achieving good performance. Weview NuNER as a member of the broader family of task-specific foundationmodels, recently unlocked by LLMs.</description><author>Sergei Bogdanov, Alexandre Constantin, Timothée Bernard, Benoit Crabbé, Etienne Bernard</author><pubDate>Fri, 23 Feb 2024 14:23:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15343v1</guid></item><item><title>Convolutional Deep Kernel Machines</title><link>http://arxiv.org/abs/2309.09814v2</link><description>Standard infinite-width limits of neural networks sacrifice the ability forintermediate layers to learn representations from data. Recent work (A theoryof representation learning gives a deep generalisation of kernel methods, Yanget al. 2023) modified the Neural Network Gaussian Process (NNGP) limit ofBayesian neural networks so that representation learning is retained.Furthermore, they found that applying this modified limit to a deep Gaussianprocess gives a practical learning algorithm which they dubbed the deep kernelmachine (DKM). However, they only considered the simplest possible setting:regression in small, fully connected networks with e.g. 10 input features.Here, we introduce convolutional deep kernel machines. This required us todevelop a novel inter-domain inducing point approximation, as well asintroducing and experimentally assessing a number of techniques not previouslyseen in DKMs, including analogues to batch normalisation, differentlikelihoods, and different types of top-layer. The resulting model trains inroughly 77 GPU hours, achieving around 99% test accuracy on MNIST, 72% onCIFAR-100, and 92.7% on CIFAR-10, which is SOTA for kernel methods.</description><author>Edward Milsom, Ben Anson, Laurence Aitchison</author><pubDate>Fri, 23 Feb 2024 14:23:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09814v2</guid></item><item><title>Ranking Entities along Conceptual Space Dimensions with LLMs: An Analysis of Fine-Tuning Strategies</title><link>http://arxiv.org/abs/2402.15337v1</link><description>Conceptual spaces represent entities in terms of their primitive semanticfeatures. Such representations are highly valuable but they are notoriouslydifficult to learn, especially when it comes to modelling perceptual andsubjective features. Distilling conceptual spaces from Large Language Models(LLMs) has recently emerged as a promising strategy. However, existing work hasbeen limited to probing pre-trained LLMs using relatively simple zero-shotstrategies. We focus in particular on the task of ranking entities according toa given conceptual space dimension. Unfortunately, we cannot directly fine-tuneLLMs on this task, because ground truth rankings for conceptual spacedimensions are rare. We therefore use more readily available features astraining data and analyse whether the ranking capabilities of the resultingmodels transfer to perceptual and subjective features. We find that this isindeed the case, to some extent, but having perceptual and subjective featuresin the training data seems essential for achieving the best results. Wefurthermore find that pointwise ranking strategies are competitive againstpairwise approaches, in defiance of common wisdom.</description><author>Nitesh Kumar, Usashi Chatterjee, Steven Schockaert</author><pubDate>Fri, 23 Feb 2024 14:17:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15337v1</guid></item></channel></rss>