<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 13 Feb 2024 14:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>MemGPT: Towards LLMs as Operating Systems</title><link>http://arxiv.org/abs/2310.08560v2</link><description>Large language models (LLMs) have revolutionized AI, but are constrained bylimited context windows, hindering their utility in tasks like extendedconversations and document analysis. To enable using context beyond limitedcontext windows, we propose virtual context management, a technique drawinginspiration from hierarchical memory systems in traditional operating systemsthat provide the appearance of large memory resources through data movementbetween fast and slow memory. Using this technique, we introduce MemGPT(Memory-GPT), a system that intelligently manages different memory tiers inorder to effectively provide extended context within the LLM's limited contextwindow, and utilizes interrupts to manage control flow between itself and theuser. We evaluate our OS-inspired design in two domains where the limitedcontext windows of modern LLMs severely handicaps their performance: documentanalysis, where MemGPT is able to analyze large documents that far exceed theunderlying LLM's context window, and multi-session chat, where MemGPT cancreate conversational agents that remember, reflect, and evolve dynamicallythrough long-term interactions with their users. We release MemGPT code anddata for our experiments at https://memgpt.ai.</description><author>Charles Packer, Sarah Wooders, Kevin Lin, Vivian Fang, Shishir G. Patil, Ion Stoica, Joseph E. Gonzalez</author><pubDate>Mon, 12 Feb 2024 18:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08560v2</guid></item><item><title>FAST: Factorizable Attention for Speeding up Transformers</title><link>http://arxiv.org/abs/2402.07901v1</link><description>Motivated by the factorization inherent in the original fast multipole methodand the improved fast Gauss transform we introduce a factorable form ofattention that operates efficiently in high dimensions. This approach reducesthe computational and memory complexity of the attention mechanism intransformers from $O(N^2)$ to $O(N)$. In comparison to previous attempts, ourwork presents a linearly scaled attention mechanism that maintains the fullrepresentation of the attention matrix without compromising on sparsificationand incorporates the all-to-all relationship between tokens. We explore theproperties of our new attention metric and conduct tests in various standardsettings. Results indicate that our attention mechanism has a robustperformance and holds significant promise for diverse applications whereself-attention is used.</description><author>Armin Gerami, Monte Hoover, Pranav S. Dulepet, Ramani Duraiswami</author><pubDate>Mon, 12 Feb 2024 18:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07901v1</guid></item><item><title>Wavefront Randomization Improves Deconvolution</title><link>http://arxiv.org/abs/2402.07900v1</link><description>The performance of an imaging system is limited by optical aberrations, whichcause blurriness in the resulting image. Digital correction techniques, such asdeconvolution, have limited ability to correct the blur, since some spatialfrequencies in the scene are not measured adequately due to the aberrations('zeros' of the system transfer function). We prove that the addition of arandom mask to an imaging system removes its dependence on aberrations,reducing the likelihood of zeros in the transfer function and consequentlyreducing the sensitivity to noise during deconvolution. and consequently resultin lower sensitivity to noise during deconvolution. In simulation, we show thatthis strategy improves image quality over a range of aberration types,aberration strengths, and signal-to-noise ratios.</description><author>Amit Kohli, Anastasios N. Angelopoulos, Laura Waller</author><pubDate>Mon, 12 Feb 2024 18:59:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07900v1</guid></item><item><title>A systematic investigation of learnability from single child linguistic input</title><link>http://arxiv.org/abs/2402.07899v1</link><description>Language models (LMs) have demonstrated remarkable proficiency in generatinglinguistically coherent text, sparking discussions about their relevance tounderstanding human language learnability. However, a significant gap existsbetween the training data for these models and the linguistic input a childreceives. LMs are typically trained on data that is orders of magnitude largerand fundamentally different from child-directed speech (Warstadt and Bowman,2022; Warstadt et al., 2023; Frank, 2023a). Addressing this discrepancy, ourresearch focuses on training LMs on subsets of a single child's linguisticinput. Previously, Wang, Vong, Kim, and Lake (2023) found that LMs trained inthis setting can form syntactic and semantic word clusters and developsensitivity to certain linguistic phenomena, but they only considered LSTMs andsimpler neural networks trained from just one single-child dataset. Here, toexamine the robustness of learnability from single-child input, wesystematically train six different model architectures on five datasets (3single-child and 2 baselines). We find that the models trained on single-childdatasets showed consistent results that matched with previous work,underscoring the robustness of forming meaningful syntactic and semanticrepresentations from a subset of a child's linguistic input.</description><author>Yulu Qin, Wentao Wang, Brenden M. Lake</author><pubDate>Mon, 12 Feb 2024 18:58:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07899v1</guid></item><item><title>Suppressing Pink Elephants with Direct Principle Feedback</title><link>http://arxiv.org/abs/2402.07896v1</link><description>Existing methods for controlling language models, such as RLHF andConstitutional AI, involve determining which LLM behaviors are desirable andtraining them into a language model. However, in many cases, it is desirablefor LLMs to be controllable \textit{at inference time}, so that they can beused in multiple contexts with diverse needs. We illustrate this with the\textbf{Pink Elephant Problem}: instructing an LLM to avoid discussing acertain entity (a ``Pink Elephant''), and instead discuss a preferred entity(``Grey Elephant''). We apply a novel simplification of Constitutional AI,\textbf{Direct Principle Feedback}, which skips the ranking of responses anduses DPO directly on critiques and revisions. Our results show that after DPFfine-tuning on our synthetic Pink Elephants dataset, our 13B fine-tuned LLaMA 2model significantly outperforms Llama-2-13B-Chat and a prompted baseline, andperforms as well as GPT-4 in on our curated test set assessing the PinkElephant Problem.</description><author>Louis Castricato, Nathan Lile, Suraj Anand, Hailey Schoelkopf, Siddharth Verma, Stella Biderman</author><pubDate>Mon, 12 Feb 2024 18:57:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07896v1</guid></item><item><title>Detection of Spider Mites on Labrador Beans through Machine Learning Approaches Using Custom Datasets</title><link>http://arxiv.org/abs/2402.07895v1</link><description>Amidst growing food production demands, early plant disease detection isessential to safeguard crops; this study proposes a visual machine learningapproach for plant disease detection, harnessing RGB and NIR data collected inreal-world conditions through a JAI FS-1600D-10GE camera to build an RGBNdataset. A two-stage early plant disease detection model with YOLOv8 and asequential CNN was used to train on a dataset with partial labels, which showeda 3.6% increase in mAP compared to a single-stage end-to-end segmentationmodel. The sequential CNN model achieved 90.62% validation accuracy utilisingRGBN data. An average of 6.25% validation accuracy increase is found using RGBNin classification compared to RGB using ResNet15 and the sequential CNN models.Further research and dataset improvements are needed to meet food productiondemands.</description><author>Violet Liu, Jason Chen, Ans Qureshi, Mahla Nejati</author><pubDate>Mon, 12 Feb 2024 18:57:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07895v1</guid></item><item><title>MODIPHY: Multimodal Obscured Detection for IoT using PHantom Convolution-Enabled Faster YOLO</title><link>http://arxiv.org/abs/2402.07894v1</link><description>Low-light conditions and occluded scenarios impede object detection inreal-world Internet of Things (IoT) applications like autonomous vehicles andsecurity systems. While advanced machine learning models strive for accuracy,their computational demands clash with the limitations of resource-constraineddevices, hampering real-time performance. In our current research, we tacklethis challenge, by introducing "YOLO Phantom", one of the smallest YOLO modelsever conceived. YOLO Phantom utilizes the novel Phantom Convolution block,achieving comparable accuracy to the latest YOLOv8n model while simultaneouslyreducing both parameters and model size by 43%, resulting in a significant 19%reduction in Giga Floating Point Operations (GFLOPs). YOLO Phantom leveragestransfer learning on our multimodal RGB-infrared dataset to address low-lightand occlusion issues, equipping it with robust vision under adverse conditions.Its real-world efficacy is demonstrated on an IoT platform with advancedlow-light and RGB cameras, seamlessly connecting to an AWS-based notificationendpoint for efficient real-time object detection. Benchmarks reveal asubstantial boost of 17% and 14% in frames per second (FPS) for thermal and RGBdetection, respectively, compared to the baseline YOLOv8n model. For communitycontribution, both the code and the multimodal dataset are available on GitHub.</description><author>Shubhabrata Mukherjee, Cory Beard, Zhu Li</author><pubDate>Mon, 12 Feb 2024 18:56:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07894v1</guid></item><item><title>Certifying LLM Safety against Adversarial Prompting</title><link>http://arxiv.org/abs/2309.02705v3</link><description>Large language models (LLMs) are vulnerable to adversarial attacks that addmalicious tokens to an input prompt to bypass the safety guardrails of an LLMand cause it to produce harmful content. In this work, we introduceerase-and-check, the first framework for defending against adversarial promptswith certifiable safety guarantees. Given a prompt, our procedure erases tokensindividually and inspects the resulting subsequences using a safety filter. Oursafety certificate guarantees that harmful prompts are not mislabeled as safedue to an adversarial attack up to a certain size. We implement the safetyfilter in two ways, using Llama 2 and DistilBERT, and compare the performanceof erase-and-check for the two cases. We defend against three attack modes: i)adversarial suffix, where an adversarial sequence is appended at the end of aharmful prompt; ii) adversarial insertion, where the adversarial sequence isinserted anywhere in the middle of the prompt; and iii) adversarial infusion,where adversarial tokens are inserted at arbitrary positions in the prompt, notnecessarily as a contiguous block. Our experimental results demonstrate thatthis procedure can obtain strong certified safety guarantees on harmful promptswhile maintaining good empirical performance on safe prompts. Additionally, wepropose three efficient empirical defenses: i) RandEC, a randomized subsamplingversion of erase-and-check; ii) GreedyEC, which greedily erases tokens thatmaximize the softmax score of the harmful class; and iii) GradEC, which usesgradient information to optimize tokens to erase. We demonstrate theireffectiveness against adversarial prompts generated by the Greedy CoordinateGradient (GCG) attack algorithm. The code for our experiments is available athttps://github.com/aounon/certified-llm-safety.</description><author>Aounon Kumar, Chirag Agarwal, Suraj Srinivas, Aaron Jiaxun Li, Soheil Feizi, Himabindu Lakkaraju</author><pubDate>Mon, 12 Feb 2024 18:55:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02705v3</guid></item><item><title>Label-Efficient Model Selection for Text Generation</title><link>http://arxiv.org/abs/2402.07891v1</link><description>Model selection for a given target task can be costly, as it may entailextensive annotation of the quality of outputs of different models. Weintroduce DiffUse, an efficient method to make an informed decision betweencandidate text generation models. DiffUse reduces the required amount ofpreference annotations, thus saving valuable time and resources in performingevaluation. DiffUse intelligently selects instances by clustering embeddingsthat represent the semantic differences between model outputs. Thus, it is ableto identify a subset of examples that are more informative for preferencedecisions. Our method is model-agnostic, and can be applied to any textgeneration model. Moreover, we propose a practical iterative approach fordynamically determining how many instances to annotate. In a series ofexperiments over hundreds of model pairs, we demonstrate that DiffUse candramatically reduce the required number of annotations -- by up to 75% -- whilemaintaining high evaluation reliability.</description><author>Shir Ashury-Tahan, Benjamin Sznajder, Leshem Choshen, Liat Ein-Dor, Eyal Shnarch, Ariel Gera</author><pubDate>Mon, 12 Feb 2024 18:54:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07891v1</guid></item><item><title>MAIDCRL: Semi-centralized Multi-Agent Influence Dense-CNN Reinforcement Learning</title><link>http://arxiv.org/abs/2402.07890v1</link><description>Distributed decision-making in multi-agent systems presents difficultchallenges for interactive behavior learning in both cooperative andcompetitive systems. To mitigate this complexity, MAIDRL presents asemi-centralized Dense Reinforcement Learning algorithm enhanced by agentinfluence maps (AIMs), for learning effective multi-agent control on StarCraftMulti-Agent Challenge (SMAC) scenarios. In this paper, we extend the DenseNetin MAIDRL and introduce semi-centralized Multi-Agent Dense-CNN ReinforcementLearning, MAIDCRL, by incorporating convolutional layers into the deep modelarchitecture, and evaluate the performance on both homogeneous andheterogeneous scenarios. The results show that the CNN-enabled MAIDCRLsignificantly improved the learning performance and achieved a faster learningrate compared to the existing MAIDRL, especially on more complicatedheterogeneous SMAC scenarios. We further investigate the stability androbustness of our model. The statistics reflect that our model not onlyachieves higher winning rate in all the given scenarios but also boosts theagent's learning process in fine-grained decision-making.</description><author>Ayesha Siddika Nipu, Siming Liu, Anthony Harris</author><pubDate>Mon, 12 Feb 2024 18:53:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07890v1</guid></item><item><title>Using Graph Theory for Improving Machine Learning-based Detection of Cyber Attacks</title><link>http://arxiv.org/abs/2402.07878v1</link><description>Early detection of network intrusions and cyber threats is one of the mainpillars of cybersecurity. One of the most effective approaches for this purposeis to analyze network traffic with the help of artificial intelligencealgorithms, with the aim of detecting the possible presence of an attacker bydistinguishing it from a legitimate user. This is commonly done by collectingthe traffic exchanged between terminals in a network and analyzing it on aper-packet or per-connection basis. In this paper, we propose instead toperform pre-processing of network traffic under analysis with the aim ofextracting some new metrics on which we can perform more efficient detectionand overcome some limitations of classical approaches. These new metrics arebased on graph theory, and consider the network as a whole, rather thanfocusing on individual packets or connections. Our approach is validatedthrough experiments performed on publicly available data sets, from which itresults that it can not only overcome some of the limitations of classicalapproaches, but also achieve a better detection capability of cyber threats.</description><author>Giacomo Zonneveld, Lorenzo Principi, Marco Baldi</author><pubDate>Mon, 12 Feb 2024 18:44:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07878v1</guid></item><item><title>WildfireGPT: Tailored Large Language Model for Wildfire Analysis</title><link>http://arxiv.org/abs/2402.07877v1</link><description>The recent advancement of large language models (LLMs) represents atransformational capability at the frontier of artificial intelligence (AI) andmachine learning (ML). However, LLMs are generalized models, trained onextensive text corpus, and often struggle to provide context-specificinformation, particularly in areas requiring specialized knowledge such aswildfire details within the broader context of climate change. Fordecision-makers and policymakers focused on wildfire resilience and adaptation,it is crucial to obtain responses that are not only precise but alsodomain-specific, rather than generic. To that end, we developed WildfireGPT, aprototype LLM agent designed to transform user queries into actionable insightson wildfire risks. We enrich WildfireGPT by providing additional context suchas climate projections and scientific literature to ensure its information iscurrent, relevant, and scientifically accurate. This enables WildfireGPT to bean effective tool for delivering detailed, user-specific insights on wildfirerisks to support a diverse set of end users, including researchers, engineers,urban planners, emergency managers, and infrastructure operators.</description><author>Yangxinyu Xie, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su</author><pubDate>Mon, 12 Feb 2024 18:41:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07877v1</guid></item><item><title>Policy Improvement using Language Feedback Models</title><link>http://arxiv.org/abs/2402.07876v1</link><description>We introduce Language Feedback Models (LFMs) that identify desirablebehaviour - actions that help achieve tasks specified in the instruction - forimitation learning in instruction following. To train LFMs, we obtain feedbackfrom Large Language Models (LLMs) on visual trajectories verbalized to languagedescriptions. First, by using LFMs to identify desirable behaviour to imitate,we improve in task-completion rate over strong behavioural cloning baselines onthree distinct language grounding environments (Touchdown, ScienceWorld, andALFWorld). Second, LFMs outperform using LLMs as experts to directly predictactions, when controlling for the number of LLM output tokens. Third, LFMsgeneralize to unseen environments, improving task-completion rate by 3.5-12.0%through one round of adaptation. Finally, LFM can be modified to providehuman-interpretable feedback without performance loss, allowing humanverification of desirable behaviour for imitation learning.</description><author>Victor Zhong, Dipendra Misra, Xingdi Yuan, Marc-Alexandre Côté</author><pubDate>Mon, 12 Feb 2024 18:41:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07876v1</guid></item><item><title>Implicit Bias of Policy Gradient in Linear Quadratic Control: Extrapolation to Unseen Initial States</title><link>http://arxiv.org/abs/2402.07875v1</link><description>In modern machine learning, models can often fit training data in numerousways, some of which perform well on unseen (test) data, while others do not.Remarkably, in such cases gradient descent frequently exhibits an implicit biasthat leads to excellent performance on unseen data. This implicit bias wasextensively studied in supervised learning, but is far less understood inoptimal control (reinforcement learning). There, learning a controller appliedto a system via gradient descent is known as policy gradient, and a question ofprime importance is the extent to which a learned controller extrapolates tounseen initial states. This paper theoretically studies the implicit bias ofpolicy gradient in terms of extrapolation to unseen initial states. Focusing onthe fundamental Linear Quadratic Regulator (LQR) problem, we establish that theextent of extrapolation depends on the degree of exploration induced by thesystem when commencing from initial states included in training. Experimentscorroborate our theory, and demonstrate its conclusions on problems beyond LQR,where systems are non-linear and controllers are neural networks. Wehypothesize that real-world optimal control may be greatly improved bydeveloping methods for informed selection of initial states to train on.</description><author>Noam Razin, Yotam Alexander, Edo Cohen-Karlik, Raja Giryes, Amir Globerson, Nadav Cohen</author><pubDate>Mon, 12 Feb 2024 18:41:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07875v1</guid></item><item><title>Robust Angular Synchronization via Directed Graph Neural Networks</title><link>http://arxiv.org/abs/2310.05842v2</link><description>The angular synchronization problem aims to accurately estimate (up to aconstant additive phase) a set of unknown angles $\theta_1, \dots,\theta_n\in[0, 2\pi)$ from $m$ noisy measurements of their offsets$\theta_i-\theta_j \;\mbox{mod} \; 2\pi.$ Applications include, for example,sensor network localization, phase retrieval, and distributed clocksynchronization. An extension of the problem to the heterogeneous setting(dubbed $k$-synchronization) is to estimate $k$ groups of anglessimultaneously, given noisy observations (with unknown group assignment) fromeach group. Existing methods for angular synchronization usually perform poorlyin high-noise regimes, which are common in applications. In this paper, weleverage neural networks for the angular synchronization problem, and itsheterogeneous extension, by proposing GNNSync, a theoretically-groundedend-to-end trainable framework using directed graph neural networks. Inaddition, new loss functions are devised to encode synchronization objectives.Experimental results on extensive data sets demonstrate that GNNSync attainscompetitive, and often superior, performance against a comprehensive set ofbaselines for the angular synchronization problem and its extension, validatingthe robustness of GNNSync even at high noise levels.</description><author>Yixuan He, Gesine Reinert, David Wipf, Mihai Cucuringu</author><pubDate>Mon, 12 Feb 2024 18:40:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05842v2</guid></item><item><title>PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs</title><link>http://arxiv.org/abs/2402.07872v1</link><description>Vision language models (VLMs) have shown impressive capabilities across avariety of tasks, from logical reasoning to visual understanding. This opensthe door to richer interaction with the world, for example robotic control.However, VLMs produce only textual outputs, while robotic control and otherspatial tasks require outputting continuous coordinates, actions, ortrajectories. How can we enable VLMs to handle such settings withoutfine-tuning on task-specific data? In this paper, we propose a novel visual prompting approach for VLMs that wecall Prompting with Iterative Visual Optimization (PIVOT), which casts tasks asiterative visual question answering. In each iteration, the image is annotatedwith a visual representation of proposals that the VLM can refer to (e.g.,candidate robot actions, localizations, or trajectories). The VLM then selectsthe best ones for the task. These proposals are iteratively refined, allowingthe VLM to eventually zero in on the best available answer. We investigatePIVOT on real-world robotic navigation, real-world manipulation from images,instruction following in simulation, and additional spatial inference taskssuch as localization. We find, perhaps surprisingly, that our approach enableszero-shot control of robotic systems without any robot training data,navigation in a variety of environments, and other capabilities. Althoughcurrent performance is far from perfect, our work highlights potentials andlimitations of this new regime and shows a promising approach forInternet-Scale VLMs in robotic and spatial reasoning domains. Website:pivot-prompt.github.io and HuggingFace:https://huggingface.co/spaces/pivot-prompt/pivot-prompt-demo.</description><author>Soroush Nasiriany, Fei Xia, Wenhao Yu, Ted Xiao, Jacky Liang, Ishita Dasgupta, Annie Xie, Danny Driess, Ayzaan Wahid, Zhuo Xu, Quan Vuong, Tingnan Zhang, Tsang-Wei Edward Lee, Kuang-Huei Lee, Peng Xu, Sean Kirmani, Yuke Zhu, Andy Zeng, Karol Hausman, Nicolas Heess, Chelsea Finn, Sergey Levine, Brian Ichter</author><pubDate>Mon, 12 Feb 2024 18:33:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07872v1</guid></item><item><title>Scaling Laws for Fine-Grained Mixture of Experts</title><link>http://arxiv.org/abs/2402.07871v1</link><description>Mixture of Experts (MoE) models have emerged as a primary solution forreducing the computational cost of Large Language Models. In this work, weanalyze their scaling properties, incorporating an expanded range of variables.Specifically, we introduce a new hyperparameter, granularity, whose adjustmentenables precise control over the size of the experts. Building on this, weestablish scaling laws for fine-grained MoE, taking into account the number oftraining tokens, model size, and granularity. Leveraging these laws, we derivethe optimal training configuration for a given computational budget. Ourfindings not only show that MoE models consistently outperform denseTransformers but also highlight that the efficiency gap between dense and MoEmodels widens as we scale up the model size and training budget. Furthermore,we demonstrate that the common practice of setting the size of experts in MoEto mirror the feed-forward layer is not optimal at almost any computationalbudget.</description><author>Jakub Krajewski, Jan Ludziejewski, Kamil Adamczewski, Maciej Pióro, Michał Krutul, Szymon Antoniak, Kamil Ciebiera, Krystian Król, Tomasz Odrzygóźdź, Piotr Sankowski, Marek Cygan, Sebastian Jaszczur</author><pubDate>Mon, 12 Feb 2024 18:33:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07871v1</guid></item><item><title>Nesting Particle Filters for Experimental Design in Dynamical Systems</title><link>http://arxiv.org/abs/2402.07868v1</link><description>In this paper, we propose a novel approach to Bayesian Experimental Design(BED) for non-exchangeable data that formulates it as risk-sensitive policyoptimization. We develop the Inside-Out SMC^2 algorithm that uses a nestedsequential Monte Carlo (SMC) estimator of the expected information gain andembeds it into a particle Markov chain Monte Carlo (pMCMC) framework to performgradient-based policy optimization. This is in contrast to recent approachesthat rely on biased estimators of the expected information gain (EIG) toamortize the cost of experiments by learning a design policy in advance.Numerical validation on a set of dynamical systems showcases the efficacy ofour method in comparison to other state-of-the-art strategies.</description><author>Sahel Iqbal, Adrien Corenflos, Simo Särkkä, Hany Abdulsamad</author><pubDate>Mon, 12 Feb 2024 18:29:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07868v1</guid></item><item><title>PoisonedRAG: Knowledge Poisoning Attacks to Retrieval-Augmented Generation of Large Language Models</title><link>http://arxiv.org/abs/2402.07867v1</link><description>Large language models (LLMs) have achieved remarkable success due to theirexceptional generative capabilities. Despite their success, they also haveinherent limitations such as a lack of up-to-date knowledge and hallucination.Retrieval-Augmented Generation (RAG) is a state-of-the-art technique tomitigate those limitations. In particular, given a question, RAG retrievesrelevant knowledge from a knowledge database to augment the input of the LLM.For instance, the retrieved knowledge could be a set of top-k texts that aremost semantically similar to the given question when the knowledge databasecontains millions of texts collected from Wikipedia. As a result, the LLM couldutilize the retrieved knowledge as the context to generate an answer for thegiven question. Existing studies mainly focus on improving the accuracy orefficiency of RAG, leaving its security largely unexplored. We aim to bridgethe gap in this work. Particularly, we propose PoisonedRAG , a set of knowledgepoisoning attacks to RAG, where an attacker could inject a few poisoned textsinto the knowledge database such that the LLM generates an attacker-chosentarget answer for an attacker-chosen target question. We formulate knowledgepoisoning attacks as an optimization problem, whose solution is a set ofpoisoned texts. Depending on the background knowledge (e.g., black-box andwhite-box settings) of an attacker on the RAG, we propose two solutions tosolve the optimization problem, respectively. Our results on multiple benchmarkdatasets and LLMs show our attacks could achieve 90% attack success rates wheninjecting 5 poisoned texts for each target question into a database withmillions of texts. We also evaluate recent defenses and our results show theyare insufficient to defend against our attacks, highlighting the need for newdefenses.</description><author>Wei Zou, Runpeng Geng, Binghui Wang, Jinyuan Jia</author><pubDate>Mon, 12 Feb 2024 18:28:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07867v1</guid></item><item><title>Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models</title><link>http://arxiv.org/abs/2402.07865v1</link><description>Visually-conditioned language models (VLMs) have seen growing adoption inapplications such as visual dialogue, scene understanding, and robotic taskplanning; adoption that has fueled a wealth of new models such as LLaVa,InstructBLIP, and PaLI-3. Despite the volume of new releases, key designdecisions around image preprocessing, architecture, and optimization areunder-explored, making it challenging to understand what factors account formodel performance $-$ a challenge further complicated by the lack of objective,consistent evaluations. To address these gaps, we first compile a suite ofstandardized evaluations spanning visual question answering, objectlocalization from language, and targeted challenge sets that probe propertiessuch as hallucination; evaluations that provide calibrated, fine-grainedinsight into a VLM's capabilities. Second, we rigorously investigate VLMs alongkey design axes, including pretrained visual representations and quantifyingthe tradeoffs of using base vs. instruct-tuned language models, amongst others.We couple our analysis with three resource contributions: (1) a unifiedframework for evaluating VLMs, (2) optimized, flexible code for VLM training,and (3) checkpoints for all models, including a family of VLMs at the 7-13Bscale that strictly outperform InstructBLIP and LLaVa v1.5, thestate-of-the-art in open-source VLMs.</description><author>Siddharth Karamcheti, Suraj Nair, Ashwin Balakrishna, Percy Liang, Thomas Kollar, Dorsa Sadigh</author><pubDate>Mon, 12 Feb 2024 18:21:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07865v1</guid></item><item><title>DAPR: A Benchmark on Document-Aware Passage Retrieval</title><link>http://arxiv.org/abs/2305.13915v2</link><description>The work of neural retrieval so far focuses on ranking short texts and ischallenged with long documents. There are many cases where the users want tofind a relevant passage within a long document from a huge corpus, e.g.Wikipedia articles, research papers, etc. We propose and name this task\emph{Document-Aware Passage Retrieval} (DAPR). While analyzing the errors ofthe State-of-The-Art (SoTA) passage retrievers, we find the major errors(53.5\%) are due to missing document context. This drives us to build abenchmark for this task including multiple datasets from heterogeneous domains.In the experiments, we extend the SoTA passage retrievers with document contextvia (1) hybrid retrieval with BM25 and (2) contextualized passagerepresentations, which inform the passage representation with document context.We find despite that hybrid retrieval performs the strongest on the mixture ofthe easy and the hard queries, it completely fails on the hard queries thatrequire document-context understanding. On the other hand, contextualizedpassage representations (e.g. prepending document titles) achieve goodimprovement on these hard queries, but overall they also perform rather poorly.Our created benchmark enables future research on developing and comparingretrieval systems for the new task. The code and the data are available athttps://https://github.com/UKPLab/arxiv2023-dapr.</description><author>Kexin Wang, Nils Reimers, Iryna Gurevych</author><pubDate>Mon, 12 Feb 2024 18:19:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13915v2</guid></item><item><title>AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy</title><link>http://arxiv.org/abs/2402.07862v1</link><description>Large language models (LLMs) show impressive capabilities, matching andsometimes exceeding human performance in many domains. This study explores thepotential of LLMs to augment judgement in forecasting tasks. We evaluated theimpact on forecasting accuracy of two GPT-4-Turbo assistants: one designed toprovide high-quality advice ('superforecasting'), and the other designed to beoverconfident and base-rate-neglecting. Participants (N = 991) had the optionto consult their assigned LLM assistant throughout the study, in contrast to acontrol group that used a less advanced model (DaVinci-003) without directforecasting support. Our preregistered analyses reveal that LLM augmentationsignificantly enhances forecasting accuracy by 23% across both types ofassistants, compared to the control group. This improvement occurs despite thesuperforecasting assistant's higher accuracy in predictions, indicating theaugmentation's benefit is not solely due to model prediction accuracy.Exploratory analyses showed a pronounced effect in one forecasting item,without which we find that the superforecasting assistant increased accuracy by43%, compared with 28% for the biased assistant. We further examine whether LLMaugmentation disproportionately benefits less skilled forecasters, degrades thewisdom-of-the-crowd by reducing prediction diversity, or varies ineffectiveness with question difficulty. Our findings do not consistentlysupport these hypotheses. Our results suggest that access to an LLM assistant,even a biased one, can be a helpful decision aid in cognitively demanding taskswhere the answer is not known at the time of interaction.</description><author>Philipp Schoenegger, Peter S. Park, Ezra Karger, Philip E. Tetlock</author><pubDate>Mon, 12 Feb 2024 18:14:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07862v1</guid></item><item><title>On the Detection of Reviewer-Author Collusion Rings From Paper Bidding</title><link>http://arxiv.org/abs/2402.07860v1</link><description>A major threat to the peer-review systems of computer science conferences isthe existence of "collusion rings" between reviewers. In such collusion rings,reviewers who have also submitted their own papers to the conference worktogether to manipulate the conference's paper assignment, with the aim of beingassigned to review each other's papers. The most straightforward way thatcolluding reviewers can manipulate the paper assignment is by indicating theirinterest in each other's papers through strategic paper bidding. One potentialapproach to solve this important problem would be to detect the colludingreviewers from their manipulated bids, after which the conference can takeappropriate action. While prior work has has developed effective techniques todetect other kinds of fraud, no research has yet established that detectingcollusion rings is even possible. In this work, we tackle the question ofwhether it is feasible to detect collusion rings from the paper bidding. Toanswer this question, we conduct empirical analysis of two realistic conferencebidding datasets, including evaluations of existing algorithms for frauddetection in other applications. We find that collusion rings can achieveconsiderable success at manipulating the paper assignment while remaininghidden from detection: for example, in one dataset, undetected colluders areable to achieve assignment to up to 30% of the papers authored by othercolluders. In addition, when 10 colluders bid on all of each other's papers, nodetection algorithm outputs a group of reviewers with more than 31% overlapwith the true colluders. These results suggest that collusion cannot beeffectively detected from the bidding, demonstrating the need to develop morecomplex detection algorithms that leverage additional metadata.</description><author>Steven Jecmen, Nihar B. Shah, Fei Fang, Leman Akoglu</author><pubDate>Mon, 12 Feb 2024 18:12:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07860v1</guid></item><item><title>Lissard: Long and Simple Sequential Reasoning Datasets</title><link>http://arxiv.org/abs/2402.07859v1</link><description>Language models are now capable of solving tasks that require dealing withlong sequences consisting of hundreds of thousands of tokens. However, theyoften fail on tasks that require repetitive use of simple rules, even onsequences that are much shorter than those seen during training. For example,state-of-the-art LLMs can find common items in two lists with up to 20 itemsbut fail when lists have 80 items. In this paper, we introduce Lissard, abenchmark comprising seven tasks whose goal is to assess the ability of modelsto process and generate wide-range sequence lengths, requiring repetitiveprocedural execution. Our evaluation of open-source (Mistral-7B andMixtral-8x7B) and proprietary models (GPT-3.5 and GPT-4) show a consistentdecline in performance across all models as the complexity of the sequenceincreases. The datasets and code are available athttps://github.com/unicamp-dl/Lissard</description><author>Mirelle Bueno, Roberto Lotufo, Rodrigo Nogueira</author><pubDate>Mon, 12 Feb 2024 18:10:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07859v1</guid></item><item><title>Multiscale Neuroimaging Features for the Identification of Medication Class and Non-Responders in Mood Disorder Treatment</title><link>http://arxiv.org/abs/2402.07858v1</link><description>In the clinical treatment of mood disorders, the complex behavioral symptomspresented by patients and variability of patient response to particularmedication classes can create difficulties in providing fast and reliabletreatment when standard diagnostic and prescription methods are used.Increasingly, the incorporation of physiological information such asneuroimaging scans and derivatives into the clinical process promises toalleviate some of the uncertainty surrounding this process. Particularly, ifneural features can help to identify patients who may not respond to standardcourses of anti-depressants or mood stabilizers, clinicians may elect to avoidlengthy and side-effect-laden treatments and seek out a different, moreeffective course that might otherwise not have been under consideration.Previously, approaches for the derivation of relevant neuroimaging featureswork at only one scale in the data, potentially limiting the depth ofinformation available for clinical decision support. In this work, we show thatthe utilization of multi spatial scale neuroimaging features - particularlyresting state functional networks and functional network connectivity measures- provide a rich and robust basis for the identification of relevant medicationclass and non-responders in the treatment of mood disorders. We demonstratethat the generated features, along with a novel approach for fast and automatedfeature selection, can support high accuracy rates in the identification ofmedication class and non-responders as well as the identification of novel,multi-scale biomarkers.</description><author>Bradley T. Baker, Mustafa S. Salman, Zening Fu, Armin Iraji, Elizabeth Osuch, Jeremy Bockholt, Vince D. Calhoun</author><pubDate>Mon, 12 Feb 2024 18:05:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07858v1</guid></item><item><title>Distributed Online Rollout for Multivehicle Routing in Unmapped Environments</title><link>http://arxiv.org/abs/2305.15596v2</link><description>In this work we consider a generalization of the well-known multivehiclerouting problem: given a network, a set of agents occupying a subset of itsnodes, and a set of tasks, we seek a minimum cost sequence of movements subjectto the constraint that each task is visited by some agent at least once. Theclassical version of this problem assumes a central computational server thatobserves the entire state of the system perfectly and directs individual agentsaccording to a centralized control scheme. In contrast, we assume that there isno centralized server and that each agent is an individual processor with no apriori knowledge of the underlying network (including task and agentlocations). Moreover, our agents possess strictly local communication andsensing capabilities (restricted to a fixed radius around their respectivelocations), aligning more closely with several real-world multiagentapplications. These restrictions introduce many challenges that are overcomethrough local information sharing and direct coordination between agents. Wepresent a fully distributed, online, and scalable reinforcement learningalgorithm for this problem whereby agents self-organize into local clusters andindependently apply a multiagent rollout scheme locally to each cluster. Wedemonstrate empirically via extensive simulations that there exists a criticalsensing radius beyond which the distributed rollout algorithm begins to improveover a greedy base policy. This critical sensing radius grows proportionally tothe $\log^*$ function of the size of the network, and is, therefore, a smallconstant for any relevant network. Our decentralized reinforcement learningalgorithm achieves approximately a factor of two cost improvement over the basepolicy for a range of radii bounded from below and above by two and three timesthe critical sensing radius, respectively.</description><author>Jamison W. Weber, Dhanush R. Giriyan, Devendra R. Parkar, Andréa W. Richa, Dimitri P. Bertsekas</author><pubDate>Mon, 12 Feb 2024 18:03:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15596v2</guid></item><item><title>Comparing skill of historical rainfall data based monsoon rainfall prediction in India with NCEP-NWP forecasts</title><link>http://arxiv.org/abs/2402.07851v1</link><description>In this draft we consider the problem of forecasting rainfall across Indiaduring the four monsoon months, one day as well as three days in advance. Wetrain neural networks using historical daily gridded precipitation data forIndia obtained from IMD for the time period $1901- 2022$, at a spatialresolution of $1^{\circ} \times 1^{\circ}$. This is compared with the numericalweather prediction (NWP) forecasts obtained from NCEP (National Centre forEnvironmental Prediction) available for the period 2011-2022. We conduct adetailed country wide analysis and separately analyze some of the mostpopulated cities in India. Our conclusion is that forecasts obtained byapplying deep learning to historical rainfall data are more accurate comparedto NWP forecasts as well as predictions based on persistence. On average,compared to our predictions, forecasts from NCEP-NWP model have about 34%higher error for a single day prediction, and over 68% higher error for a threeday prediction. Similarly, persistence estimates report a 29% higher error in asingle day forecast, and over 54% error in a three day forecast. We furtherobserve that data up to 20 days in the past is useful in reducing errors of oneand three day forecasts, when a transformer based learning architecture, and toa lesser extent when an LSTM is used. A key conclusion suggested by ourpreliminary analysis is that NWP forecasts can be substantially improved uponthrough more and diverse data relevant to monsoon prediction combined withcarefully selected neural network architecture.</description><author>Apoorva Narula, Aastha Jain, Jatin Batra, Sandeep Juneja</author><pubDate>Mon, 12 Feb 2024 17:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07851v1</guid></item><item><title>Generative Modeling of Discrete Joint Distributions by E-Geodesic Flow Matching on Assignment Manifolds</title><link>http://arxiv.org/abs/2402.07846v1</link><description>This paper introduces a novel generative model for discrete distributionsbased on continuous normalizing flows on the submanifold of factorizingdiscrete measures. Integration of the flow gradually assigns categories andavoids issues of discretizing the latent continuous model like rounding, sampletruncation etc. General non-factorizing discrete distributions capable ofrepresenting complex statistical dependencies of structured discrete data, canbe approximated by embedding the submanifold into a the meta-simplex of alljoint discrete distributions and data-driven averaging. Efficient training ofthe generative model is demonstrated by matching the flow of geodesics offactorizing discrete distributions. Various experiments underline theapproach's broad applicability.</description><author>Bastian Boll, Daniel Gonzalez-Alvarado, Christoph Schnörr</author><pubDate>Mon, 12 Feb 2024 17:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07846v1</guid></item><item><title>An Investigation into Using Unsupervised Metrics to Optimise GNNs for Node Clustering</title><link>http://arxiv.org/abs/2402.07845v1</link><description>Graph Neural Networks (GNNs) can be trained to detect communities within agraph by learning from the duality of feature and connectivity information.Currently, the common approach for optimisation of GNNs is to use comparisonsto ground-truth for hyperparameter tuning and model selection. In this work, weshow that nodes can be clustered into communities with GNNs by solelyoptimising for modularity, without any comparison to ground-truth. Althoughmodularity is a graph partitioning quality metric, we show that this can beused to optimise GNNs that also encode features without a drop in performance.We take it a step further and also study whether the unsupervised metricperformance can predict ground-truth performance. To investigate why modularitycan be used to optimise GNNs, we design synthetic experiments that show thelimitations of this approach. The synthetic graphs are created to highlightcurrent capabilities in distinct, random and zero information space partitionsin attributed graphs. We conclude that modularity can be used forhyperparameter optimisation and model selection on real-world datasets as wellas being a suitable proxy for predicting ground-truth performance, however,GNNs fail to balance the information duality when the spaces containconflicting signals.</description><author>William Leeney, Ryan McConville</author><pubDate>Mon, 12 Feb 2024 17:53:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07845v1</guid></item><item><title>Mercury: An Efficiency Benchmark for LLM Code Synthesis</title><link>http://arxiv.org/abs/2402.07844v1</link><description>Despite advancements in evaluating Large Language Models (LLMs) for codesynthesis, benchmarks have predominantly focused on functional correctness,overlooking the importance of code efficiency. We present Mercury, the firstbenchmark designated for assessing the code efficiency of LLM code synthesistasks. Mercury consists of 1,889 programming tasks covering diverse difficultylevels alongside test case generators generating unlimited cases forcomprehensive evaluation. Unlike existing benchmarks, Mercury integrates anovel metric Beyond@K to measure normalized code efficiency based on historicalsubmissions, leading to a new evaluation indicator for code synthesis, whichencourages generating functionally correct and computationally efficient code,mirroring the real-world software development standard. Our findings revealthat while LLMs demonstrate the remarkable capability to generate functionallycorrect code, there still exists a substantial gap in their efficiency output,underscoring a new frontier for LLM research and development.</description><author>Mingzhe Du, Anh Tuan Luu, Bin Ji, See-Kiong Ng</author><pubDate>Mon, 12 Feb 2024 17:53:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07844v1</guid></item><item><title>Do Membership Inference Attacks Work on Large Language Models?</title><link>http://arxiv.org/abs/2402.07841v1</link><description>Membership inference attacks (MIAs) attempt to predict whether a particulardatapoint is a member of a target model's training data. Despite extensiveresearch on traditional machine learning models, there has been limited workstudying MIA on the pre-training data of large language models (LLMs). Weperform a large-scale evaluation of MIAs over a suite of language models (LMs)trained on the Pile, ranging from 160M to 12B parameters. We find that MIAsbarely outperform random guessing for most settings across varying LLM sizesand domains. Our further analyses reveal that this poor performance can beattributed to (1) the combination of a large dataset and few trainingiterations, and (2) an inherently fuzzy boundary between members andnon-members. We identify specific settings where LLMs have been shown to bevulnerable to membership inference and show that the apparent success in suchsettings can be attributed to a distribution shift, such as when members andnon-members are drawn from the seemingly identical domain but with differenttemporal ranges. We release our code and data as a unified benchmark packagethat includes all existing MIAs, supporting future work.</description><author>Michael Duan, Anshuman Suri, Niloofar Mireshghallah, Sewon Min, Weijia Shi, Luke Zettlemoyer, Yulia Tsvetkov, Yejin Choi, David Evans, Hannaneh Hajishirzi</author><pubDate>Mon, 12 Feb 2024 17:52:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07841v1</guid></item><item><title>Towards Meta-Pruning via Optimal Transport</title><link>http://arxiv.org/abs/2402.07839v1</link><description>Structural pruning of neural networks conventionally relies on identifyingand discarding less important neurons, a practice often resulting insignificant accuracy loss that necessitates subsequent fine-tuning efforts.This paper introduces a novel approach named Intra-Fusion, challenging thisprevailing pruning paradigm. Unlike existing methods that focus on designingmeaningful neuron importance metrics, Intra-Fusion redefines the overlyingpruning procedure. Through utilizing the concepts of model fusion and OptimalTransport, we leverage an agnostically given importance metric to arrive at amore effective sparse model representation. Notably, our approach achievessubstantial accuracy recovery without the need for resource-intensivefine-tuning, making it an efficient and promising tool for neural networkcompression. Additionally, we explore how fusion can be added to the pruning process tosignificantly decrease the training time while maintaining competitiveperformance. We benchmark our results for various networks on commonly useddatasets such as CIFAR-10, CIFAR-100, and ImageNet. More broadly, we hope thatthe proposed Intra-Fusion approach invigorates exploration into a freshalternative to the predominant compression approaches. Our code is availablehere: https://github.com/alexandertheus/Intra-Fusion.</description><author>Alexander Theus, Olin Geimer, Friedrich Wicke, Thomas Hofmann, Sotiris Anagnostidis, Sidak Pal Singh</author><pubDate>Mon, 12 Feb 2024 17:50:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07839v1</guid></item><item><title>Evading Data Contamination Detection for Language Models is (too) Easy</title><link>http://arxiv.org/abs/2402.02823v2</link><description>Large language models are widespread, with their performance on benchmarksfrequently guiding user preferences for one model over another. However, thevast amount of data these models are trained on can inadvertently lead tocontamination with public benchmarks, thus compromising performancemeasurements. While recently developed contamination detection methods try toaddress this issue, they overlook the possibility of deliberate contaminationby malicious model providers aiming to evade detection. We argue that thissetting is of crucial importance as it casts doubt on the reliability of publicbenchmarks. To more rigorously study this issue, we propose a categorization ofboth model providers and contamination detection methods. This revealsvulnerabilities in existing methods that we exploit with EAL, a simple yeteffective contamination technique that significantly inflates benchmarkperformance while completely evading current detection methods.</description><author>Jasper Dekoninck, Mark Niklas Müller, Maximilian Baader, Marc Fischer, Martin Vechev</author><pubDate>Mon, 12 Feb 2024 17:50:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02823v2</guid></item><item><title>Generalizing across Temporal Domains with Koopman Operators</title><link>http://arxiv.org/abs/2402.07834v1</link><description>In the field of domain generalization, the task of constructing a predictivemodel capable of generalizing to a target domain without access to target dataremains challenging. This problem becomes further complicated when consideringevolving dynamics between domains. While various approaches have been proposedto address this issue, a comprehensive understanding of the underlyinggeneralization theory is still lacking. In this study, we contribute noveltheoretic results that aligning conditional distribution leads to the reductionof generalization bounds. Our analysis serves as a key motivation for solvingthe Temporal Domain Generalization (TDG) problem through the application ofKoopman Neural Operators, resulting in Temporal Koopman Networks (TKNets). Byemploying Koopman Operators, we effectively address the time-evolvingdistributions encountered in TDG using the principles of Koopman theory, wheremeasurement functions are sought to establish linear transition relationsbetween evolving domains. Through empirical evaluations conducted on syntheticand real-world datasets, we validate the effectiveness of our proposedapproach.</description><author>Qiuhao Zeng, Wei Wang, Fan Zhou, Gezheng Xu, Ruizhi Pu, Changjian Shui, Christian Gagne, Shichun Yang, Boyu Wang, Charles X. Ling</author><pubDate>Mon, 12 Feb 2024 17:45:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07834v1</guid></item><item><title>Improving Robustness via Tilted Exponential Layer: A Communication-Theoretic Perspective</title><link>http://arxiv.org/abs/2311.01047v2</link><description>State-of-the-art techniques for enhancing robustness of deep networks mostlyrely on empirical risk minimization with suitable data augmentation. In thispaper, we propose a complementary approach motivated by communication theory,aimed at enhancing the signal-to-noise ratio at the output of a neural networklayer via neural competition during learning and inference. In addition tominimization of a standard end-to-end cost, neurons compete to sparselyrepresent layer inputs by maximization of a tilted exponential (TEXP) objectivefunction for the layer. TEXP learning can be interpreted as maximum likelihoodestimation of matched filters under a Gaussian model for data noise. Inferencein a TEXP layer is accomplished by replacing batch norm by a tilted softmax,which can be interpreted as computation of posterior probabilities for thecompeting signaling hypotheses represented by each neuron. After providinginsights via simplified models, we show, by experimentation on standard imagedatasets, that TEXP learning and inference enhances robustness against noiseand other common corruptions, without requiring data augmentation. Furthercumulative gains in robustness against this array of distortions can beobtained by appropriately combining TEXP with data augmentation techniques.</description><author>Bhagyashree Puranik, Ahmad Beirami, Yao Qin, Upamanyu Madhow</author><pubDate>Mon, 12 Feb 2024 17:35:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01047v2</guid></item><item><title>Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model</title><link>http://arxiv.org/abs/2402.07827v1</link><description>Recent breakthroughs in large language models (LLMs) have centered around ahandful of data-rich languages. What does it take to broaden access tobreakthroughs beyond first-class citizen languages? Our work introduces Aya, amassively multilingual generative language model that follows instructions in101 languages of which over 50% are considered as lower-resourced. Ayaoutperforms mT0 and BLOOMZ on the majority of tasks while covering double thenumber of languages. We introduce extensive new evaluation suites that broadenthe state-of-art for multilingual eval across 99 languages -- includingdiscriminative and generative tasks, human evaluation, and simulated win ratesthat cover both held-out tasks and in-distribution performance. Furthermore, weconduct detailed investigations on the optimal finetuning mixture composition,data pruning, as well as the toxicity, bias, and safety of our models. Weopen-source our instruction datasets and our model athttps://hf.co/CohereForAI/aya-101</description><author>Ahmet Üstün, Viraat Aryabumi, Zheng-Xin Yong, Wei-Yin Ko, Daniel D'souza, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, Freddie Vargus, Phil Blunsom, Shayne Longpre, Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer, Sara Hooker</author><pubDate>Mon, 12 Feb 2024 17:34:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07827v1</guid></item><item><title>NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes</title><link>http://arxiv.org/abs/2312.14890v4</link><description>Complex reasoning ability is one of the most important features of currentLLMs, which has also been leveraged to play an integral role in complexdecision-making tasks. Therefore, the investigation into the reasoningcapabilities of Large Language Models (LLMs) is critical: numerous benchmarkshave been established to assess the reasoning abilities of LLMs. However,current benchmarks are inadequate in offering a rigorous evaluation of the fullextent of reasoning abilities that LLMs are capable of achieving. They are alsoprone to the risk of overfitting, as these benchmarks, being publiclyaccessible and static, allow models to potentially tailor their responses tospecific benchmark metrics, thereby inflating their performance. Addressingthese limitations, our research introduces a new benchmark, named NPHardEval.This benchmark is designed to evaluate the reasoning abilities of LLMs across abroad spectrum of 900 algorithmic questions, extending up to the NP-Hardcomplexity class. These questions are meticulously chosen to represent a widerange of complexity class below the NP-hard complexity class, offering arigorous measure of the reasoning ability of LLMs. Through this study, we shedlight on the current state of reasoning in LLMs, providing an objective andrigorous perspective through the comparison of LLMs' performance across complexclasses. Moreover, this benchmark is designed with a dynamic update mechanism,where the datapoints are refreshed on a monthly basis. Such regular updatesplay a crucial role in mitigating the risk of LLMs overfitting to thebenchmark, promoting a more accurate and reliable assessment of their reasoningcapabilities. The benchmark dataset and code of NPHardEval are available athttps://github.com/casmlab/NPHardEval.</description><author>Lizhou Fan, Wenyue Hua, Lingyao Li, Haoyang Ling, Yongfeng Zhang</author><pubDate>Mon, 12 Feb 2024 17:30:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14890v4</guid></item><item><title>Understanding fitness landscapes in morpho-evolution via local optima networks</title><link>http://arxiv.org/abs/2402.07822v1</link><description>Morpho-evolution (ME) refers to the simultaneous optimisation of a robot'sdesign and controller to maximise performance given a task and environment.Many genetic encodings have been proposed which are capable of representingdesign and control. Previous research has provided empirical comparisonsbetween encodings in terms of their performance with respect to an objectivefunction and the diversity of designs that are evaluated, however there hasbeen no attempt to explain the observed findings. We address this by applyingLocal Optima Network (LON) analysis to investigate the structure of the fitnesslandscapes induced by three different encodings when evolving a robot for alocomotion task, shedding new light on the ease by which different fitnesslandscapes can be traversed by a search process. This is the first time LONanalysis has been applied in the field of ME despite its popularity incombinatorial optimisation domains; the findings will facilitate design of newalgorithms or operators that are customised to ME landscapes in the future.</description><author>Sarah L. Thomson, Léni K. Le Goff, Emma Hart, Edgar Buchanan</author><pubDate>Mon, 12 Feb 2024 17:26:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07822v1</guid></item><item><title>On Computationally Efficient Multi-Class Calibration</title><link>http://arxiv.org/abs/2402.07821v1</link><description>Consider a multi-class labelling problem, where the labels can take values in$[k]$, and a predictor predicts a distribution over the labels. In this work,we study the following foundational question: Are there notions of multi-classcalibration that give strong guarantees of meaningful predictions and can beachieved in time and sample complexities polynomial in $k$? Prior notions ofcalibration exhibit a tradeoff between computational efficiency andexpressivity: they either suffer from having sample complexity exponential in$k$, or needing to solve computationally intractable problems, or give ratherweak guarantees. Our main contribution is a notion of calibration that achieves all thesedesiderata: we formulate a robust notion of projected smooth calibration formulti-class predictions, and give new recalibration algorithms for efficientlycalibrating predictors under this definition with complexity polynomial in $k$.Projected smooth calibration gives strong guarantees for all downstreamdecision makers who want to use the predictor for binary classificationproblems of the form: does the label belong to a subset $T \subseteq [k]$: e.g.is this an image of an animal? It ensures that the probabilities predicted bysumming the probabilities assigned to labels in $T$ are close to some perfectlycalibrated binary predictor for that task. We also show that naturalstrengthenings of our definition are computationally hard to achieve: they runinto information theoretic barriers or computational intractability. Underlyingboth our upper and lower bounds is a tight connection that we prove betweenmulti-class calibration and the well-studied problem of agnostic learning inthe (standard) binary prediction setting.</description><author>Parikshit Gopalan, Lunjia Hu, Guy N. Rothblum</author><pubDate>Mon, 12 Feb 2024 17:25:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07821v1</guid></item><item><title>A Benchmark Grocery Dataset of Realworld Point Clouds From Single View</title><link>http://arxiv.org/abs/2402.07819v1</link><description>Fine-grained grocery object recognition is an important computer visionproblem with broad applications in automatic checkout, in-store roboticnavigation, and assistive technologies for the visually impaired. Existingdatasets on groceries are mainly 2D images. Models trained on these datasetsare limited to learning features from the regular 2D grids. While portable 3Dsensors such as Kinect were commonly available for mobile phones, sensors suchas LiDAR and TrueDepth, have recently been integrated into mobile phones.Despite the availability of mobile 3D sensors, there are currently no dedicatedreal-world large-scale benchmark 3D datasets for grocery. In addition, existing3D datasets lack fine-grained grocery categories and have limited trainingsamples. Furthermore, collecting data by going around the object versus thetraditional photo capture makes data collection cumbersome. Thus, we introducea large-scale grocery dataset called 3DGrocery100. It constitutes 100 classes,with a total of 87,898 3D point clouds created from 10,755 RGB-D single-viewimages. We benchmark our dataset on six recent state-of-the-art 3D point cloudclassification models. Additionally, we also benchmark the dataset on few-shotand continual learning point cloud classification tasks. Project Page:https://bigdatavision.org/3DGrocery100/.</description><author>Shivanand Venkanna Sheshappanavar, Tejas Anvekar, Shivanand Kundargi, Yufan Wang, Chandra Kambhamettu</author><pubDate>Mon, 12 Feb 2024 17:24:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07819v1</guid></item><item><title>Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning</title><link>http://arxiv.org/abs/2402.07818v1</link><description>Finetuning on task-specific datasets is a widely-embraced paradigm ofharnessing the powerful capability of pretrained LLMs for various downstreamtasks. Due to the popularity of LLMs finetuning and its accompanying privacyconcerns, differentially private (DP) finetuning of pretrained LLMs hasgarnered increasing attention to safeguarding the privacy of task-specificdatasets. Lying at the design core of DP LLM finetuning methods is thesatisfactory tradeoff between privacy, utility, and scalability. Most existingmethods build upon the seminal work of DP-SGD. Despite pushing the scalabilityof DP-SGD to its limit, DP-SGD-based finetuning methods are unfortunatelylimited by the inherent inefficiency of SGD. In this paper, we investigate thepotential of DP zeroth-order methods for LLM pretraining, which avoids thescalability bottleneck of SGD by approximating the gradient with the moreefficient zeroth-order gradient. Rather than treating the zeroth-order methodas a drop-in replacement for SGD, this paper presents a comprehensive studyboth theoretically and empirically. First, we propose the stagewise DPzeroth-order method that dynamically schedules key hyperparameters. This designis grounded on the synergy between DP random perturbation and the gradientapproximation error of the zeroth-order method, and its effect on finetuningtrajectory. Second, we further enhance the scalability by reducing thetrainable parameters that are identified by repurposing a data-free pruningtechnique requiring no additional data or extra privacy budget. We providetheoretical analysis for both proposed methods. We conduct extensive empiricalanalysis on both encoder-only masked language model and decoder-onlyautoregressive language model, achieving impressive results in terms ofscalability and utility.</description><author>Z Liu, J Lou, W Bao, Z Qin, K Ren</author><pubDate>Mon, 12 Feb 2024 17:24:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07818v1</guid></item><item><title>Injecting Wiktionary to improve token-level contextual representations using contrastive learning</title><link>http://arxiv.org/abs/2402.07817v1</link><description>While static word embeddings are blind to context, for lexical semanticstasks context is rather too present in contextual word embeddings, vectors ofsame-meaning occurrences being too different (Ethayarajh, 2019). Fine-tuningpre-trained language models (PLMs) using contrastive learning was proposed,leveraging automatically self-augmented examples (Liu et al., 2021b). In thispaper, we investigate how to inject a lexicon as an alternative source ofsupervision, using the English Wiktionary. We also test how dimensionalityreduction impacts the resulting contextual word embeddings. We evaluate ourapproach on the Word-In-Context (WiC) task, in the unsupervised setting (notusing the training set). We achieve new SoTA result on the original WiC testset. We also propose two new WiC test sets for which we show that ourfine-tuning method achieves substantial improvements. We also observeimprovements, although modest, for the semantic frame induction task. Althoughwe experimented on English to allow comparison with related work, our method isadaptable to the many languages for which large Wiktionaries exist.</description><author>Anna Mosolova, Marie Candito, Carlos Ramisch</author><pubDate>Mon, 12 Feb 2024 17:22:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07817v1</guid></item><item><title>Computationally Efficient High-Dimensional Bayesian Optimization via Variable Selection</title><link>http://arxiv.org/abs/2109.09264v2</link><description>Bayesian Optimization (BO) is a method for globally optimizing black-boxfunctions. While BO has been successfully applied to many scenarios, developingeffective BO algorithms that scale to functions with high-dimensional domainsis still a challenge. Optimizing such functions by vanilla BO is extremelytime-consuming. Alternative strategies for high-dimensional BO that are basedon the idea of embedding the high-dimensional space to the one with lowdimension are sensitive to the choice of the embedding dimension, which needsto be pre-specified. We develop a new computationally efficienthigh-dimensional BO method that exploits variable selection. Our method is ableto automatically learn axis-aligned sub-spaces, i.e. spaces containing selectedvariables, without the demand of any pre-specified hyperparameters. Wetheoretically analyze the computational complexity of our algorithm and derivethe regret bound. We empirically show the efficacy of our method on severalsynthetic and real problems.</description><author>Yihang Shen, Carl Kingsford</author><pubDate>Mon, 12 Feb 2024 17:22:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.09264v2</guid></item><item><title>PICL: Physics Informed Contrastive Learning for Partial Differential Equations</title><link>http://arxiv.org/abs/2401.16327v2</link><description>Neural operators have recently grown in popularity as Partial DifferentialEquation (PDEs) surrogate models. Learning solution functionals, rather thanfunctions, has proven to be a powerful approach to calculate fast, accuratesolutions to complex PDEs. While much work has been done evaluating neuraloperator performance on a wide variety of surrogate modeling tasks, these worksnormally evaluate performance on a single equation at a time. In this work, wedevelop a novel contrastive pretraining framework utilizing GeneralizedContrastive Loss that improves neural operator generalization across multiplegoverning equations simultaneously. Governing equation coefficients are used tomeasure ground-truth similarity between systems. A combination ofphysics-informed system evolution and latent-space model output are anchored toinput data and used in our distance function. We find that physics-informedcontrastive pretraining improves both accuracy and generalization for theFourier Neural Operator in fixed-future task, with comparable performance onthe autoregressive rollout, and superresolution tasks for the 1D Heat,Burgers', and linear advection equations.</description><author>Cooper Lorsung, Amir Barati Farimani</author><pubDate>Mon, 12 Feb 2024 17:20:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16327v2</guid></item><item><title>PBADet: A One-Stage Anchor-Free Approach for Part-Body Association</title><link>http://arxiv.org/abs/2402.07814v1</link><description>The detection of human parts (e.g., hands, face) and their correctassociation with individuals is an essential task, e.g., for ubiquitoushuman-machine interfaces and action recognition. Traditional methods oftenemploy multi-stage processes, rely on cumbersome anchor-based systems, or donot scale well to larger part sets. This paper presents PBADet, a novelone-stage, anchor-free approach for part-body association detection. Buildingupon the anchor-free object representation across multi-scale feature maps, weintroduce a singular part-to-body center offset that effectively encapsulatesthe relationship between parts and their parent bodies. Our design isinherently versatile and capable of managing multiple parts-to-bodyassociations without compromising on detection accuracy or robustness.Comprehensive experiments on various datasets underscore the efficacy of ourapproach, which not only outperforms existing state-of-the-art techniques butalso offers a more streamlined and efficient solution to the part-bodyassociation challenge.</description><author>Zhongpai Gao, Huayi Zhou, Abhishek Sharma, Meng Zheng, Benjamin Planche, Terrence Chen, Ziyan Wu</author><pubDate>Mon, 12 Feb 2024 17:18:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07814v1</guid></item><item><title>Retrieval-Augmented Thought Process as Sequential Decision Making</title><link>http://arxiv.org/abs/2402.07812v1</link><description>Large Language Models (LLMs) have demonstrated their strong ability to assistpeople and show "sparks of intelligence". However, several open challengeshinder their wider application: such as concerns over privacy, tendencies toproduce hallucinations, and difficulties in handling long contexts. In thiswork, we address those challenges by introducing the Retrieval-AugmentedThought Process (RATP). Given access to external knowledge, RATP formulates thethought generation of LLMs as a multiple-step decision process. To optimizesuch a thought process, RATP leverages Monte-Carlo Tree Search, and learns aQ-value estimator that permits cost-efficient inference. In addressing the taskof question-answering with private data, where ethical and security concernslimit LLM training methods, RATP achieves a 50% improvement over existingin-context retrieval-augmented language models.</description><author>Thomas Pouplin, Hao Sun, Samuel Holt, Mihaela van der Schaar</author><pubDate>Mon, 12 Feb 2024 17:17:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07812v1</guid></item><item><title>Physics Informed Token Transformer for Solving Partial Differential Equations</title><link>http://arxiv.org/abs/2305.08757v3</link><description>Solving Partial Differential Equations (PDEs) is the core of many fields ofscience and engineering. While classical approaches are often prohibitivelyslow, machine learning models often fail to incorporate complete systeminformation. Over the past few years, transformers have had a significantimpact on the field of Artificial Intelligence and have seen increased usage inPDE applications. However, despite their success, transformers currently lackintegration with physics and reasoning. This study aims to address this issueby introducing PITT: Physics Informed Token Transformer. The purpose of PITT isto incorporate the knowledge of physics by embedding partial differentialequations (PDEs) into the learning process. PITT uses an equation tokenizationmethod to learn an analytically-driven numerical update operator. By tokenizingPDEs and embedding partial derivatives, the transformer models become aware ofthe underlying knowledge behind physical processes. To demonstrate this, PITTis tested on challenging 1D and 2D PDE neural operator prediction tasks. Theresults show that PITT outperforms popular neural operator models and has theability to extract physically relevant information from governing equations.</description><author>Cooper Lorsung, Zijie Li, Amir Barati Farimani</author><pubDate>Mon, 12 Feb 2024 17:16:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.08757v3</guid></item><item><title>Zero-Shot Robustification of Zero-Shot Models</title><link>http://arxiv.org/abs/2309.04344v2</link><description>Zero-shot inference is a powerful paradigm that enables the use of largepretrained models for downstream classification tasks without further training.However, these models are vulnerable to inherited biases that can impact theirperformance. The traditional solution is fine-tuning, but this undermines thekey advantage of pretrained models, which is their ability to be usedout-of-the-box. We propose RoboShot, a method that improves the robustness ofpretrained model embeddings in a fully zero-shot fashion. First, we uselanguage models (LMs) to obtain useful insights from task descriptions. Theseinsights are embedded and used to remove harmful and boost useful components inembeddings -- without any supervision. Theoretically, we provide a simple andtractable model for biases in zero-shot embeddings and give a resultcharacterizing under what conditions our approach can boost performance.Empirically, we evaluate RoboShot on nine image and NLP classification tasksand show an average improvement of 15.98% on worst group accuracy, with trivialdecrease in overall accuracy over several zero-shot baselines. Additionally, wedemonstrate that RoboShot is compatible with a variety of pretrained andlanguage models and propose a way to further boost performance with a zero-shotadaptation variant.</description><author>Dyah Adila, Changho Shin, Linrong Cai, Frederic Sala</author><pubDate>Mon, 12 Feb 2024 17:15:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04344v2</guid></item><item><title>Bayesian deep learning for cosmic volumes with modified gravity</title><link>http://arxiv.org/abs/2309.00612v2</link><description>The new generation of galaxy surveys will provide unprecedented data allowingus to test gravity at cosmological scales. A robust cosmological analysis ofthe large-scale structure demands exploiting the nonlinear information encodedin the cosmic web. Machine Learning techniques provide such tools, however, donot provide a priori assessment of uncertainties. This study aims at extractingcosmological parameters from modified gravity (MG) simulations through deepneural networks endowed with uncertainty estimations. We implement Bayesianneural networks (BNNs) with an enriched approximate posterior distributionconsidering two cases: one with a single Bayesian last layer (BLL), and anotherone with Bayesian layers at all levels (FullB). We train both BNNs withreal-space density fields and power-spectra from a suite of 2000 dark matteronly particle mesh $N$-body simulations including modified gravity modelsrelying on MG-PICOLA covering 256 $h^{-1}$ Mpc side cubical volumes with128$^3$ particles. BNNs excel in accurately predicting parameters for$\Omega_m$ and $\sigma_8$ and their respective correlation with the MGparameter. We find out that BNNs yield well-calibrated uncertainty estimatesovercoming the over- and under-estimation issues in traditional neuralnetworks. We observe that the presence of MG parameter leads to a significantdegeneracy with $\sigma_8$ being one of the possible explanations of the poorMG predictions. Ignoring MG, we obtain a deviation of the relative errors in$\Omega_m$ and $\sigma_8$ by at least $30\%$. Moreover, we report consistentresults from the density field and power spectra analysis, and comparableresults between BLL and FullB experiments which permits us to save computingtime by a factor of two. This work contributes in setting the path to extractcosmological parameters from complete small cosmic volumes towards the highlynonlinear regime.</description><author>Jorge Enrique García-Farieta, Héctor J Hortúa, Francisco-Shu Kitaura</author><pubDate>Mon, 12 Feb 2024 17:15:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00612v2</guid></item><item><title>Sourcerer: Sample-based Maximum Entropy Source Distribution Estimation</title><link>http://arxiv.org/abs/2402.07808v1</link><description>Scientific modeling applications often require estimating a distribution ofparameters consistent with a dataset of observations - an inference task alsoknown as source distribution estimation. This problem can be ill-posed,however, since many different source distributions might produce the samedistribution of data-consistent simulations. To make a principled choice amongmany equally valid sources, we propose an approach which targets the maximumentropy distribution, i.e., prioritizes retaining as much uncertainty aspossible. Our method is purely sample-based - leveraging the Sliced-Wassersteindistance to measure the discrepancy between the dataset and simulations - andthus suitable for simulators with intractable likelihoods. We benchmark ourmethod on several tasks, and show that it can recover source distributions withsubstantially higher entropy without sacrificing the fidelity of thesimulations. Finally, to demonstrate the utility of our approach, we infersource distributions for parameters of the Hodgkin-Huxley neuron model fromexperimental datasets with thousands of measurements. In summary, we propose aprincipled framework for inferring unique source distributions of scientificsimulator parameters while retaining as much uncertainty as possible.</description><author>Julius Vetter, Guy Moss, Cornelius Schröder, Richard Gao, Jakob H. Macke</author><pubDate>Mon, 12 Feb 2024 17:13:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07808v1</guid></item><item><title>Graph Neural Networks for Road Safety Modeling: Datasets and Evaluations for Accident Analysis</title><link>http://arxiv.org/abs/2311.00164v2</link><description>We consider the problem of traffic accident analysis on a road network basedon road network connections and traffic volume. Previous works have designedvarious deep-learning methods using historical records to predict trafficaccident occurrences. However, there is a lack of consensus on how accurateexisting methods are, and a fundamental issue is the lack of public accidentdatasets for comprehensive evaluations. This paper constructs a large-scale,unified dataset of traffic accident records from official reports of variousstates in the US, totaling 9 million records, accompanied by road networks andtraffic volume reports. Using this new dataset, we evaluate existingdeep-learning methods for predicting the occurrence of accidents on roadnetworks. Our main finding is that graph neural networks such as GraphSAGE canaccurately predict the number of accidents on roads with less than 22% meanabsolute error (relative to the actual count) and whether an accident willoccur or not with over 87% AUROC, averaged over states. We achieve theseresults by using multitask learning to account for cross-state variabilities(e.g., availability of accident labels) and transfer learning to combinetraffic volume with accident prediction. Ablation studies highlight theimportance of road graph-structural features, amongst other features. Lastly,we discuss the implications of the analysis and develop a package for easilyusing our new dataset.</description><author>Abhinav Nippani, Dongyue Li, Haotian Ju, Haris N. Koutsopoulos, Hongyang R. Zhang</author><pubDate>Mon, 12 Feb 2024 17:09:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00164v2</guid></item><item><title>Towards a mathematical theory for consistency training in diffusion models</title><link>http://arxiv.org/abs/2402.07802v1</link><description>Consistency models, which were proposed to mitigate the high computationaloverhead during the sampling phase of diffusion models, facilitate single-stepsampling while attaining state-of-the-art empirical performance. Whenintegrated into the training phase, consistency models attempt to train asequence of consistency functions capable of mapping any point at any time stepof the diffusion process to its starting point. Despite the empirical success,a comprehensive theoretical understanding of consistency training remainselusive. This paper takes a first step towards establishing theoreticalunderpinnings for consistency models. We demonstrate that, in order to generatesamples within $\varepsilon$ proximity to the target in distribution (measuredby some Wasserstein metric), it suffices for the number of steps in consistencylearning to exceed the order of $d^{5/2}/\varepsilon$, with $d$ the datadimension. Our theory offers rigorous insights into the validity and efficacyof consistency models, illuminating their utility in downstream inferencetasks.</description><author>Gen Li, Zhihan Huang, Yuting Wei</author><pubDate>Mon, 12 Feb 2024 17:07:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07802v1</guid></item><item><title>PeTailor: Improving Large Language Model by Tailored Chunk Scorer in Biomedical Triple Extraction</title><link>http://arxiv.org/abs/2310.18463v2</link><description>Biomedical triple extraction systems aim to automatically extract biomedicalentities and relations between entities. While current unified informationextraction models showcase state-of-the-art performance, they face challengesin understanding relationships between entities within intricate biomedicalsentences. Furthermore, the absence of a high-quality biomedical tripleextraction dataset impedes the progress in developing robust triple extractionsystems. To tackle these challenges, we propose a novel retrieval-basedframework for biomedical triple extraction, namely PeTailor, which explicitlyretrieves the relevant document from our pre-built diverse chunk database usinga novel tailored chunk scorer and integrates the retrieved information into theinput of a Large Language Model (LLM) to generate the corresponding triple(head entity, relation, tail entity) for the input sentence. Additionally, wepresent GM-CIHT, an expert-annotated biomedical triple extraction dataset thatcovers a wider range of relation types. Experimental results show that ourproposed PeTailor method achieves state-of-the-art performance on GM-CIHT andtwo standard biomedical triple extraction datasets</description><author>Mingchen Li, M. Chen, Huixue Zhou, Halil Kilicoglu, Rui Zhang</author><pubDate>Mon, 12 Feb 2024 17:05:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18463v2</guid></item><item><title>MENTOR: Human Perception-Guided Pretraining for Increased Generalization</title><link>http://arxiv.org/abs/2310.19545v2</link><description>Incorporating human perception into training of convolutional neural networks(CNN) has boosted generalization capabilities of such models in open-setrecognition tasks. One of the active research questions is where (in the modelarchitecture) and how to efficiently incorporate always-limited humanperceptual data into training strategies of models. In this paper, we introduceMENTOR (huMan pErceptioN-guided preTraining fOr increased geneRalization),which addresses this question through two unique rounds of training the CNNstasked with open-set anomaly detection. First, we train an autoencoder to learnhuman saliency maps given an input image, without class labels. The autoencoderis thus tasked with discovering domain-specific salient features which mimichuman perception. Second, we remove the decoder part, add a classificationlayer on top of the encoder, and fine-tune this new model conventionally. Weshow that MENTOR's benefits are twofold: (a) significant accuracy boost inanomaly detection tasks (in this paper demonstrated for detection of unknowniris presentation attacks, synthetically-generated faces, and anomalies inchest X-ray images), compared to models utilizing conventional transferlearning (e.g., sourcing the weights from ImageNet-pretrained models) as wellas to models trained with the state-of-the-art approach incorporating humanperception guidance into loss functions, and (b) an increase in the efficiencyof model training, requiring fewer epochs to converge compared tostate-of-the-art training methods.</description><author>Colton R. Crum, Adam Czajka</author><pubDate>Mon, 12 Feb 2024 17:04:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19545v2</guid></item><item><title>Generalising Planning Environment Redesign</title><link>http://arxiv.org/abs/2402.07799v1</link><description>In Environment Design, one interested party seeks to affect another agent'sdecisions by applying changes to the environment. Most research on planningenvironment (re)design assumes the interested party's objective is tofacilitate the recognition of goals and plans, and search over the space ofenvironment modifications to find the minimal set of changes that simplifythose tasks and optimise a particular metric. This search space is usuallyintractable, so existing approaches devise metric-dependent pruning techniquesfor performing search more efficiently. This results in approaches that are notable to generalise across different objectives and/or metrics. In this paper,we argue that the interested party could have objectives and metrics that arenot necessarily related to recognising agents' goals or plans. Thus, togeneralise the task of Planning Environment Redesign, we develop a generalenvironment redesign approach that is metric-agnostic and leverages recentresearch on top-quality planning to efficiently redesign planning environmentsaccording to any interested party's objective and metric. Experiments over aset of environment redesign benchmarks show that our general approachoutperforms existing approaches when using well-known metrics, such asfacilitating the recognition of goals, as well as its effectiveness whensolving environment redesign tasks that optimise a novel set of differentmetrics.</description><author>Alberto Pozanco, Ramon Fraga Pereira, Daniel Borrajo</author><pubDate>Mon, 12 Feb 2024 17:03:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07799v1</guid></item><item><title>Statistical inference using machine learning and classical techniques based on accumulated local effects (ALE)</title><link>http://arxiv.org/abs/2310.09877v3</link><description>Accumulated Local Effects (ALE) is a model-agnostic approach for globalexplanations of the results of black-box machine learning (ML) algorithms.There are at least three challenges with conducting statistical inference basedon ALE: ensuring the reliability of ALE analyses, especially in the context ofsmall datasets; intuitively characterizing a variable's overall effect in ML;and making robust inferences from ML data analysis. In response, we introduceinnovative tools and techniques for statistical inference using ALE,establishing bootstrapped confidence intervals tailored to dataset size andintroducing ALE effect size measures that intuitively indicate effects on boththe outcome variable scale and a normalized scale. Furthermore, we demonstratehow to use these tools to draw reliable statistical inferences, reflecting theflexible patterns ALE adeptly highlights, with implementations available in the'ale' package in R. This work propels the discourse on ALE and itsapplicability in ML and statistical analysis forward, offering practicalsolutions to prevailing challenges in the field.</description><author>Chitu Okoli</author><pubDate>Mon, 12 Feb 2024 17:00:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09877v3</guid></item><item><title>NetEffect: Discovery and Exploitation of Generalized Network Effects</title><link>http://arxiv.org/abs/2301.00270v3</link><description>Given a large graph with few node labels, how can we (a) identify whetherthere is generalized network-effects (GNE) or not, (b) estimate GNE to explainthe interrelations among node classes, and (c) exploit GNE efficiently toimprove the performance on downstream tasks? The knowledge of GNE is valuablefor various tasks like node classification, and targeted advertising. However,identifying GNE such as homophily, heterophily or their combination ischallenging in real-world graphs due to limited availability of node labels andnoisy edges. We propose NetEffect, a graph mining approach to address the aboveissues, enjoying the following properties: (i) Principled: a statistical testto determine the presence of GNE in a graph with few node labels; (ii) Generaland Explainable: a closed-form solution to estimate the specific type of GNEobserved; and (iii) Accurate and Scalable: the integration of GNE for accurateand fast node classification. Applied on real-world graphs, NetEffect discoversthe unexpected absence of GNE in numerous graphs, which were recognized toexhibit heterophily. Further, we show that incorporating GNE is effective onnode classification. On a million-scale real-world graph, NetEffect achievesover 7 times speedup (14 minutes vs. 2 hours) compared to most competitors.</description><author>Meng-Chieh Lee, Shubhranshu Shekhar, Jaemin Yoo, Christos Faloutsos</author><pubDate>Mon, 12 Feb 2024 16:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.00270v3</guid></item><item><title>Tuning-Free Stochastic Optimization</title><link>http://arxiv.org/abs/2402.07793v1</link><description>Large-scale machine learning problems make the cost of hyperparameter tuningever more prohibitive. This creates a need for algorithms that can tunethemselves on-the-fly. We formalize the notion of "tuning-free" algorithms thatcan match the performance of optimally-tuned optimization algorithms up topolylogarithmic factors given only loose hints on the relevant problemparameters. We consider in particular algorithms that can match optimally-tunedStochastic Gradient Descent (SGD). When the domain of optimization is bounded,we show tuning-free matching of SGD is possible and achieved by severalexisting algorithms. We prove that for the task of minimizing a convex andsmooth or Lipschitz function over an unbounded domain, tuning-free optimizationis impossible. We discuss conditions under which tuning-free optimization ispossible even over unbounded domains. In particular, we show that the recentlyproposed DoG and DoWG algorithms are tuning-free when the noise distribution issufficiently well-behaved. For the task of finding a stationary point of asmooth and potentially nonconvex function, we give a variant of SGD thatmatches the best-known high-probability convergence rate for tuned SGD at onlyan additional polylogarithmic cost. However, we also give an impossibilityresult that shows no algorithm can hope to match the optimal expectedconvergence rate for tuned SGD with high probability.</description><author>Ahmed Khaled, Chi Jin</author><pubDate>Mon, 12 Feb 2024 16:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07793v1</guid></item><item><title>Empowering Federated Learning for Massive Models with NVIDIA FLARE</title><link>http://arxiv.org/abs/2402.07792v1</link><description>In the ever-evolving landscape of artificial intelligence (AI) and largelanguage models (LLMs), handling and leveraging data effectively has become acritical challenge. Most state-of-the-art machine learning algorithms aredata-centric. However, as the lifeblood of model performance, necessary datacannot always be centralized due to various factors such as privacy,regulation, geopolitics, copyright issues, and the sheer effort required tomove vast datasets. In this paper, we explore how federated learning enabled byNVIDIA FLARE can address these challenges with easy and scalable integrationcapabilities, enabling parameter-efficient and full supervised fine-tuning ofLLMs for natural language processing and biopharmaceutical applications toenhance their accuracy and robustness.</description><author>Holger R. Roth, Ziyue Xu, Yuan-Ting Hsieh, Adithya Renduchintala, Isaac Yang, Zhihong Zhang, Yuhong Wen, Sean Yang, Kevin Lu, Kristopher Kersten, Camir Ricketts, Daguang Xu, Chester Chen, Yan Cheng, Andrew Feng</author><pubDate>Mon, 12 Feb 2024 16:59:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07792v1</guid></item><item><title>Design Space Exploration on Efficient and Accurate Human Pose Estimation from Sparse IMU-Sensing</title><link>http://arxiv.org/abs/2308.02397v2</link><description>Human Pose Estimation (HPE) to assess human motion in sports, rehabilitationor work safety requires accurate sensing without compromising the sensitiveunderlying personal data. Therefore, local processing is necessary and thelimited energy budget in such systems can be addressed by Inertial MeasurementUnits (IMU) instead of common camera sensing. The central trade-off betweenaccuracy and efficient use of hardware resources is rarely discussed inresearch. We address this trade-off by a simulative Design Space Exploration(DSE) of a varying quantity and positioning of IMU-sensors. First, we generateIMU-data from a publicly available body model dataset for different sensorconfigurations and train a deep learning model with this data. Additionally, wepropose a combined metric to assess the accuracy-resource trade-off. We usedthe DSE as a tool to evaluate sensor configurations and identify beneficialones for a specific use case. Exemplary, for a system with equal importance ofaccuracy and resources, we identify an optimal sensor configuration of 4sensors with a mesh error of 6.03 cm, increasing the accuracy by 32.7% andreducing the hardware effort by two sensors compared to state of the art. Ourwork can be used to design health applications with well-suited sensorpositioning and attention to data privacy and resource-awareness.</description><author>Iris Fürst-Walter, Antonio Nappi, Tanja Harbaum, Jürgen Becker</author><pubDate>Mon, 12 Feb 2024 16:58:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.02397v2</guid></item><item><title>Health-LLM: Personalized Retrieval-Augmented Disease Prediction Model</title><link>http://arxiv.org/abs/2402.00746v3</link><description>Artificial intelligence (AI) in healthcare has significantly advancedintelligent medical treatment. However, traditional intelligent healthcare islimited by static data and unified standards, preventing full integration withindividual situations and other challenges. Hence, a more professional anddetailed intelligent healthcare method is needed for development. To this end,we propose an innovative framework named Heath-LLM, which combines large-scalefeature extraction and medical knowledge trade-off scoring. Compared totraditional health management methods, our approach has three main advantages.First, our method integrates health reports into a large model to providedetailed task information. Second, professional medical expertise is used toadjust the weighted scores of health characteristics. Third, we use asemi-automated feature extraction framework to enhance the analytical power oflanguage models and incorporate expert insights to improve the accuracy ofdisease prediction. We have conducted disease prediction experiments on a largenumber of health reports to assess the effectiveness of Health-LLM. The resultsof the experiments indicate that the proposed method surpasses traditionalmethods and has the potential to revolutionize disease prediction andpersonalized health management. The code is available athttps://github.com/jmyissb/HealthLLM.</description><author>Mingyu Jin, Qinkai Yu, Chong Zhang, Dong Shu, Suiyuan Zhu, Mengnan Du, Yongfeng Zhang, Yanda Meng</author><pubDate>Mon, 12 Feb 2024 16:56:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00746v3</guid></item><item><title>From Uncertainty to Precision: Enhancing Binary Classifier Performance through Calibration</title><link>http://arxiv.org/abs/2402.07790v1</link><description>The assessment of binary classifier performance traditionally centers ondiscriminative ability using metrics, such as accuracy. However, these metricsoften disregard the model's inherent uncertainty, especially when dealing withsensitive decision-making domains, such as finance or healthcare. Given thatmodel-predicted scores are commonly seen as event probabilities, calibration iscrucial for accurate interpretation. In our study, we analyze the sensitivityof various calibration measures to score distortions and introduce a refinedmetric, the Local Calibration Score. Comparing recalibration methods, weadvocate for local regressions, emphasizing their dual role as effectiverecalibration tools and facilitators of smoother visualizations. We apply thesefindings in a real-world scenario using Random Forest classifier and regressorto predict credit default while simultaneously measuring calibration duringperformance optimization.</description><author>Agathe Fernandes Machado, Arthur Charpentier, Emmanuel Flachaire, Ewen Gallic, François Hu</author><pubDate>Mon, 12 Feb 2024 16:55:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07790v1</guid></item><item><title>Multi-Intent Attribute-Aware Text Matching in Searching</title><link>http://arxiv.org/abs/2402.07788v1</link><description>Text matching systems have become a fundamental service in most searchingplatforms. For instance, they are responsible for matching user queries torelevant candidate items, or rewriting the user-input query to a pre-selectedhigh-performing one for a better search experience. In practice, both thequeries and items often contain multiple attributes, such as the category ofthe item and the location mentioned in the query, which represent condensed keyinformation that is helpful for matching. However, most of the existing worksdownplay the effectiveness of attributes by integrating them into textrepresentations as supplementary information. Hence, in this work, we focus onexploring the relationship between the attributes from two sides. Sinceattributes from two ends are often not aligned in terms of number and type, wepropose to exploit the benefit of attributes by multiple-intent modeling. Theintents extracted from attributes summarize the diverse needs of queries andprovide rich content of items, which are more refined and abstract, and can bealigned for paired inputs. Concretely, we propose a multi-intentattribute-aware matching model (MIM), which consists of three main components:attribute-aware encoder, multi-intent modeling, and intent-aware matching. Inthe attribute-aware encoder, the text and attributes are weighted and processedthrough a scaled attention mechanism with regard to the attributes' importance.Afterward, the multi-intent modeling extracts intents from two ends and alignsthem. Herein, we come up with a distribution loss to ensure the learned intentsare diverse but concentrated, and a kullback-leibler divergence loss thataligns the learned intents. Finally, in the intent-aware matching, the intentsare evaluated by a self-supervised masking task, and then incorporated tooutput the final matching result.</description><author>Mingzhe Li, Xiuying Chen, Jing Xiang, Qishen Zhang, Changsheng Ma, Chenchen Dai, Jinxiong Chang, Zhongyi Liu, Guannan Zhang</author><pubDate>Mon, 12 Feb 2024 16:54:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07788v1</guid></item><item><title>Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis</title><link>http://arxiv.org/abs/2402.07787v1</link><description>Aspect-based Sentiment Analysis (ABSA) evaluates sentiment expressions withina text to comprehend sentiment information. Previous studies integratedexternal knowledge, such as knowledge graphs, to enhance the semantic featuresin ABSA models. Recent research has examined the use of Graph Neural Networks(GNNs) on dependency and constituent trees for syntactic analysis. With theongoing development of ABSA, more innovative linguistic and structural featuresare being incorporated (e.g. latent graph), but this also introduces complexityand confusion. As of now, a scalable framework for integrating diverselinguistic and structural features into ABSA does not exist. This paperpresents the Extensible Multi-Granularity Fusion (EMGF) network, whichintegrates information from dependency and constituent syntactic, attentionsemantic , and external knowledge graphs. EMGF, equipped with multi-anchortriplet learning and orthogonal projection, efficiently harnesses the combinedpotential of each granularity feature and their synergistic interactions,resulting in a cumulative effect without additional computational expenses.Experimental findings on SemEval 2014 and Twitter datasets confirm EMGF'ssuperiority over existing ABSA methods.</description><author>Xiaowei Zhao, Yong Zhou, Xiujuan Xu, Yu Liu</author><pubDate>Mon, 12 Feb 2024 16:52:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07787v1</guid></item><item><title>Boosting Multitask Learning on Graphs through Higher-Order Task Affinities</title><link>http://arxiv.org/abs/2306.14009v3</link><description>Predicting node labels on a given graph is a widely studied problem with manyapplications, including community detection and molecular graph prediction.This paper considers predicting multiple node labeling functions on graphssimultaneously and revisits this problem from a multitask learning perspective.For a concrete example, consider overlapping community detection: eachcommunity membership is a binary node classification task. Due to complexoverlapping patterns, we find that negative transfer is prevalent when we applynaive multitask learning to multiple community detection, as task relationshipsare highly nonlinear across different node labeling. To address the challenge,we develop an algorithm to cluster tasks into groups based on a higher-ordertask affinity measure. We then fit a multitask model on each task group,resulting in a boosting procedure on top of the baseline model. We estimate thehigher-order task affinity measure between two tasks as the prediction loss ofone task in the presence of another task and a random subset of other tasks.Then, we use spectral clustering on the affinity score matrix to identify taskgrouping. We design several speedup techniques to compute the higher-orderaffinity scores efficiently and show that they can predict negative transfersmore accurately than pairwise task affinities. We validate our procedure usingvarious community detection and molecular graph prediction data sets, showingfavorable results compared with existing methods. Lastly, we provide atheoretical analysis to show that under a planted block model of tasks ongraphs, our affinity scores can provably separate tasks into groups.</description><author>Dongyue Li, Haotian Ju, Aneesh Sharma, Hongyang R. Zhang</author><pubDate>Mon, 12 Feb 2024 16:51:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14009v3</guid></item><item><title>HYPO: Hyperspherical Out-of-Distribution Generalization</title><link>http://arxiv.org/abs/2402.07785v1</link><description>Out-of-distribution (OOD) generalization is critical for machine learningmodels deployed in the real world. However, achieving this can be fundamentallychallenging, as it requires the ability to learn invariant features acrossdifferent domains or environments. In this paper, we propose a novel frameworkHYPO (HYPerspherical OOD generalization) that provably learns domain-invariantrepresentations in a hyperspherical space. In particular, our hypersphericallearning algorithm is guided by intra-class variation and inter-classseparation principles -- ensuring that features from the same class (acrossdifferent training domains) are closely aligned with their class prototypes,while different class prototypes are maximally separated. We further providetheoretical justifications on how our prototypical learning objective improvesthe OOD generalization bound. Through extensive experiments on challenging OODbenchmarks, we demonstrate that our approach outperforms competitive baselinesand achieves superior performance. Code is available athttps://github.com/deeplearning-wisc/hypo.</description><author>Haoyue Bai, Yifei Ming, Julian Katz-Samuels, Yixuan Li</author><pubDate>Mon, 12 Feb 2024 16:50:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07785v1</guid></item><item><title>IR-Aware ECO Timing Optimization Using Reinforcement Learning</title><link>http://arxiv.org/abs/2402.07781v1</link><description>Engineering change orders (ECOs) in late stages make minimal design fixes torecover from timing shifts due to excessive IR drops. This paper integratesIR-drop-aware timing analysis and ECO timing optimization using reinforcementlearning (RL). The method operates after physical design and power gridsynthesis, and rectifies IR-drop-induced timing degradation through gatesizing. It incorporates the Lagrangian relaxation (LR) technique into a novelRL framework, which trains a relational graph convolutional network (R-GCN)agent to sequentially size gates to fix timing violations. The R-GCN agentoutperforms a classical LR-only algorithm: in an open 45nm technology, it (a)moves the Pareto front of the delay-area tradeoff curve to the left and (b)saves runtime over the classical method by running fast inference using trainedmodels at iso-quality. The RL model is transferable across timingspecifications, and transferable to unseen designs with zero-shot learning orfine tuning.</description><author>Vidya A. Chhabria, Wenjing Jiang, Sachin S. Sapatnekar</author><pubDate>Mon, 12 Feb 2024 16:47:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07781v1</guid></item><item><title>TELLER: A Trustworthy Framework for Explainable, Generalizable and Controllable Fake News Detection</title><link>http://arxiv.org/abs/2402.07776v1</link><description>The proliferation of fake news has emerged as a severe societal problem,raising significant interest from industry and academia. While existingdeep-learning based methods have made progress in detecting fake newsaccurately, their reliability may be compromised caused by the non-transparentreasoning processes, poor generalization abilities and inherent risks ofintegration with large language models (LLMs). To address this challenge, wepropose {\methodname}, a novel framework for trustworthy fake news detectionthat prioritizes explainability, generalizability and controllability ofmodels. This is achieved via a dual-system framework that integrates cognitionand decision systems, adhering to the principles above. The cognition systemharnesses human expertise to generate logical predicates, which guide LLMs ingenerating human-readable logic atoms. Meanwhile, the decision system deducesgeneralizable logic rules to aggregate these atoms, enabling the identificationof the truthfulness of the input news across diverse domains and enhancingtransparency in the decision-making process. Finally, we present comprehensiveevaluation results on four datasets, demonstrating the feasibility andtrustworthiness of our proposed framework. Our implementation is available at\url{https://github.com/less-and-less-bugs/Trust_TELLER}.</description><author>Hui Liu, Wenya Wang, Haoru Li, Haoliang Li</author><pubDate>Mon, 12 Feb 2024 16:41:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07776v1</guid></item><item><title>Biomarker Discovery with Quantum Neural Networks: A Case-study in CTLA4-Activation Pathways</title><link>http://arxiv.org/abs/2306.01745v2</link><description>Biomarker discovery is a challenging task due to the massive search space.Quantum computing and quantum Artificial Intelligence (quantum AI) can be usedto address the computational problem of biomarker discovery tasks. We propose aQuantum Neural Networks (QNNs) architecture to discover biomarkers for inputactivation pathways. The Maximum Relevance, Minimum Redundancy (mRMR) criteriais used to score biomarker candidate sets. Our proposed model is economicalsince the neural solution can be delivered on constrained hardware. Wedemonstrate the proof of concept on four activation pathways associated withCTLA4, including (1) CTLA4-activation stand-alone, (2) CTLA4-CD8A-CD8Bco-activation, (3) CTLA4-CD2 co-activation, and (4)CTLA4-CD2-CD48-CD53-CD58-CD84 co-activation. The model indicates new biomarkersassociated with the mutational activation of CLTA4-associated pathways,including 20 genes: CLIC4, CPE, ETS2, FAM107A, GPR116, HYOU1, LCN2, MACF1,MT1G, NAPA, NDUFS5, PAK1, PFN1, PGAP3, PPM1G, PSMD8, RNF213, SLC25A3, UBA1, andWLS. We open source the implementation at:https://github.com/namnguyen0510/Biomarker-Discovery-with-Quantum-Neural-Networks.</description><author>Nam Nguyen</author><pubDate>Mon, 12 Feb 2024 16:34:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01745v2</guid></item><item><title>End-to-End Learning for Fair Multiobjective Optimization Under Uncertainty</title><link>http://arxiv.org/abs/2402.07772v1</link><description>Many decision processes in artificial intelligence and operations researchare modeled by parametric optimization problems whose defining parameters areunknown and must be inferred from observable data. The Predict-Then-Optimize(PtO) paradigm in machine learning aims to maximize downstream decision qualityby training the parametric inference model end-to-end with the subsequentconstrained optimization. This requires backpropagation through theoptimization problem using approximation techniques specific to the problem'sform, especially for nondifferentiable linear and mixed-integer programs. Thispaper extends the PtO methodology to optimization problems withnondifferentiable Ordered Weighted Averaging (OWA) objectives, known for theirability to ensure properties of fairness and robustness in decision models.Through a collection of training techniques and proposed application settings,it shows how optimization of OWA functions can be effectively integrated withparametric prediction for fair and robust optimization under uncertainty.</description><author>My H Dinh, James Kotary, Ferdinando Fioretto</author><pubDate>Mon, 12 Feb 2024 16:33:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07772v1</guid></item><item><title>Quantitative knowledge retrieval from large language models</title><link>http://arxiv.org/abs/2402.07770v1</link><description>Large language models (LLMs) have been extensively studied for theirabilities to generate convincing natural language sequences, however theirutility for quantitative information retrieval is less well understood. In thispaper we explore the feasibility of LLMs as a mechanism for quantitativeknowledge retrieval to aid data analysis tasks such as elicitation of priordistributions for Bayesian models and imputation of missing data. We present aprompt engineering framework, treating an LLM as an interface to a latent spaceof scientific literature, comparing responses in different contexts and domainsagainst more established approaches. Implications and challenges of using LLMsas 'experts' are discussed.</description><author>David Selby, Kai Spriestersbach, Yuichiro Iwashita, Dennis Bappert, Archana Warrier, Sumantrak Mukherjee, Muhammad Nabeel Asim, Koichi Kise, Sebastian Vollmer</author><pubDate>Mon, 12 Feb 2024 16:32:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07770v1</guid></item><item><title>Understanding quantum machine learning also requires rethinking generalization</title><link>http://arxiv.org/abs/2306.13461v2</link><description>Quantum machine learning models have shown successful generalizationperformance even when trained with few data. In this work, through systematicrandomization experiments, we show that traditional approaches to understandinggeneralization fail to explain the behavior of such quantum models. Ourexperiments reveal that state-of-the-art quantum neural networks accurately fitrandom states and random labeling of training data. This ability to memorizerandom data defies current notions of small generalization error,problematizing approaches that build on complexity measures such as the VCdimension, the Rademacher complexity, and all their uniform relatives. Wecomplement our empirical results with a theoretical construction showing thatquantum neural networks can fit arbitrary labels to quantum states, hinting attheir memorization ability. Our results do not preclude the possibility of goodgeneralization with few training data but rather rule out any possibleguarantees based only on the properties of the model family. These findingsexpose a fundamental challenge in the conventional understanding ofgeneralization in quantum machine learning and highlight the need for aparadigm shift in the study of quantum models for machine learning tasks.</description><author>Elies Gil-Fuster, Jens Eisert, Carlos Bravo-Prieto</author><pubDate>Mon, 12 Feb 2024 16:30:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13461v2</guid></item><item><title>Text Detoxification as Style Transfer in English and Hindi</title><link>http://arxiv.org/abs/2402.07767v1</link><description>This paper focuses on text detoxification, i.e., automatically convertingtoxic text into non-toxic text. This task contributes to safer and morerespectful online communication and can be considered a Text Style Transfer(TST) task, where the text style changes while its content is preserved. Wepresent three approaches: knowledge transfer from a similar task, multi-tasklearning approach, combining sequence-to-sequence modeling with varioustoxicity classification tasks, and, delete and reconstruct approach. To supportour research, we utilize a dataset provided by Dementieva et al.(2021), whichcontains multiple versions of detoxified texts corresponding to toxic texts. Inour experiments, we selected the best variants through expert human annotators,creating a dataset where each toxic sentence is paired with a single,appropriate detoxified version. Additionally, we introduced a small Hindiparallel dataset, aligning with a part of the English dataset, suitable forevaluation purposes. Our results demonstrate that our approach effectivelybalances text detoxication while preserving the actual content and maintainingfluency.</description><author>Sourabrata Mukherjee, Akanksha Bansal, Atul Kr. Ojha, John P. McCrae, Ondřej Dušek</author><pubDate>Mon, 12 Feb 2024 16:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07767v1</guid></item><item><title>Multi-level Optimal Control with Neural Surrogate Models</title><link>http://arxiv.org/abs/2402.07763v1</link><description>Optimal actuator and control design is studied as a multi-level optimisationproblem, where the actuator design is evaluated based on the performance of theassociated optimal closed loop. The evaluation of the optimal closed loop for agiven actuator realisation is a computationally demanding task, for which theuse of a neural network surrogate is proposed. The use of neural networksurrogates to replace the lower level of the optimisation hierarchy enables theuse of fast gradient-based and gradient-free consensus-based optimisationmethods to determine the optimal actuator design. The effectiveness of theproposed surrogate models and optimisation methods is assessed in a testrelated to optimal actuator location for heat control.</description><author>Dante Kalise, Estefanía Loayza-Romero, Kirsten A. Morris, Zhengang Zhong</author><pubDate>Mon, 12 Feb 2024 16:28:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07763v1</guid></item><item><title>Scalable Structure Learning for Sparse Context-Specific Causal Systems</title><link>http://arxiv.org/abs/2402.07762v1</link><description>Several approaches to graphically representing context-specific relationsamong jointly distributed categorical variables have been proposed, along withstructure learning algorithms. While existing optimization-based methods havelimited scalability due to the large number of context-specific models, theconstraint-based methods are more prone to error than even constraint-based DAGlearning algorithms since more relations must be tested. We present a hybridalgorithm for learning context-specific models that scales to hundreds ofvariables while testing no more constraints than standard DAG learningalgorithms. Scalable learning is achieved through a combination of anorder-based MCMC algorithm and sparsity assumptions analogous to thosetypically invoked for DAG models. To implement the method, we solve a specialcase of an open problem recently posed by Alon and Balogh. The method is shownto perform well on synthetic data and real world examples, in terms of bothaccuracy and scalability.</description><author>Felix Leopoldo Rios, Alex Markham, Liam Solus</author><pubDate>Mon, 12 Feb 2024 16:28:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07762v1</guid></item><item><title>EmojiCrypt: Prompt Encryption for Secure Communication with Large Language Models</title><link>http://arxiv.org/abs/2402.05868v2</link><description>Cloud-based large language models (LLMs) such as ChatGPT have increasinglybecome integral to daily operations, serving as vital tools across variousapplications. While these models offer substantial benefits in terms ofaccessibility and functionality, they also introduce significant privacyconcerns: the transmission and storage of user data in cloud infrastructurespose substantial risks of data breaches and unauthorized access to sensitiveinformation; even if the transmission and storage of data is encrypted, the LLMservice provider itself still knows the real contents of the data, preventingindividuals or entities from confidently using such LLM services. To addressthese concerns, this paper proposes a simple yet effective mechanism EmojiCryptto protect user privacy. It uses Emoji to encrypt the user inputs beforesending them to LLM, effectively rendering them indecipherable to human orLLM's examination while retaining the original intent of the prompt, thusensuring the model's performance remains unaffected. We conduct experiments onthree tasks, personalized recommendation, sentiment analysis, and tabular dataanalysis. Experiment results reveal that EmojiCrypt can encrypt personalinformation within prompts in such a manner that not only prevents thediscernment of sensitive data by humans or LLM itself, but also maintains oreven improves the precision without further tuning, achieving comparable oreven better task accuracy than directly prompting the LLM without promptencryption. These results highlight the practicality of adopting encryptionmeasures that safeguard user privacy without compromising the functionalintegrity and performance of LLMs. Code and dataset are available athttps://github.com/agiresearch/EmojiCrypt.</description><author>Guo Lin, Wenyue Hua, Yongfeng Zhang</author><pubDate>Mon, 12 Feb 2024 16:26:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05868v2</guid></item><item><title>Towards an Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model</title><link>http://arxiv.org/abs/2402.07757v1</link><description>Stepwise inference protocols, such as scratchpads and chain-of-thought, helplanguage models solve complex problems by decomposing them into a sequence ofsimpler subproblems. Despite the significant gain in performance achieved viathese protocols, the underlying mechanisms of stepwise inference have remainedelusive. To address this, we propose to study autoregressive Transformer modelson a synthetic task that embodies the multi-step nature of problems wherestepwise inference is generally most useful. Specifically, we define a graphnavigation problem wherein a model is tasked with traversing a path from astart to a goal node on the graph. Despite is simplicity, we find we canempirically reproduce and analyze several phenomena observed at scale: (i) thestepwise inference reasoning gap, the cause of which we find in the structureof the training data; (ii) a diversity-accuracy tradeoff in model generationsas sampling temperature varies; (iii) a simplicity bias in the model's output;and (iv) compositional generalization and a primacy bias with in-contextexemplars. Overall, our work introduces a grounded, synthetic framework forstudying stepwise inference and offers mechanistic hypotheses that can lay thefoundation for a deeper understanding of this phenomenon.</description><author>Mikail Khona, Maya Okawa, Jan Hula, Rahul Ramesh, Kento Nishi, Robert Dick, Ekdeep Singh Lubana, Hidenori Tanaka</author><pubDate>Mon, 12 Feb 2024 16:25:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07757v1</guid></item><item><title>Solar Active Region Magnetogram Image Dataset for Studies of Space Weather</title><link>http://arxiv.org/abs/2305.09492v3</link><description>In this dataset we provide a comprehensive collection of magnetograms (imagesquantifying the strength of the magnetic field) from the National Aeronauticsand Space Administration's (NASA's) Solar Dynamics Observatory (SDO). Thedataset incorporates data from three sources and provides SDO Helioseismic andMagnetic Imager (HMI) magnetograms of solar active regions (regions of largemagnetic flux, generally the source of eruptive events) as well as labels ofcorresponding flaring activity. This dataset will be useful for image analysisor solar physics research related to magnetic structure, its evolution overtime, and its relation to solar flares. The dataset will be of interest tothose researchers investigating automated solar flare prediction methods,including supervised and unsupervised machine learning (classical and deep),binary and multi-class classification, and regression. This dataset is aminimally processed, user configurable dataset of consistently sized images ofsolar active regions that can serve as a benchmark dataset for solar flareprediction research.</description><author>Laura E. Boucheron, Ty Vincent, Jeremy A. Grajeda, Ellery Wuest</author><pubDate>Mon, 12 Feb 2024 16:23:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09492v3</guid></item><item><title>Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models</title><link>http://arxiv.org/abs/2402.07754v1</link><description>Diffusion models have gained attention in text processing, offering manypotential advantages over traditional autoregressive models. This work exploresthe integration of diffusion models and Chain-of-Thought (CoT), awell-established technique to improve the reasoning ability in autoregressivelanguage models. We propose Diffusion-of-Thought (DoT), allowing reasoningsteps to diffuse over time through the diffusion process. In contrast totraditional autoregressive language models that make decisions in aleft-to-right, token-by-token manner, DoT offers more flexibility in thetrade-off between computation and reasoning performance. Our experimentalresults demonstrate the effectiveness of DoT in multi-digit multiplication andgrade school math problems. Additionally, DoT showcases promisingself-correction abilities and benefits from existing reasoning-enhancingtechniques like self-consistency decoding. Our findings contribute to theunderstanding and development of reasoning capabilities in diffusion languagemodels.</description><author>Jiacheng Ye, Shansan Gong, Liheng Chen, Lin Zheng, Jiahui Gao, Han Shi, Chuan Wu, Zhenguo Li, Wei Bi, Lingpeng Kong</author><pubDate>Mon, 12 Feb 2024 16:23:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07754v1</guid></item><item><title>Mixed Q-Functionals: Advancing Value-Based Methods in Cooperative MARL with Continuous Action Domains</title><link>http://arxiv.org/abs/2402.07752v1</link><description>Tackling multi-agent learning problems efficiently is a challenging task incontinuous action domains. While value-based algorithms excel in sampleefficiency when applied to discrete action domains, they are usuallyinefficient when dealing with continuous actions. Policy-based algorithms, onthe other hand, attempt to address this challenge by leveraging critic networksfor guiding the learning process and stabilizing the gradient estimation. Thelimitations in the estimation of true return and falling into local optima inthese methods result in inefficient and often sub-optimal policies. In thispaper, we diverge from the trend of further enhancing critic networks, andfocus on improving the effectiveness of value-based methods in multi-agentcontinuous domains by concurrently evaluating numerous actions. We propose anovel multi-agent value-based algorithm, Mixed Q-Functionals (MQF), inspiredfrom the idea of Q-Functionals, that enables agents to transform their statesinto basis functions. Our algorithm fosters collaboration among agents bymixing their action-values. We evaluate the efficacy of our algorithm in sixcooperative multi-agent scenarios. Our empirical findings reveal that MQFoutperforms four variants of Deep Deterministic Policy Gradient through rapidaction evaluation and increased sample efficiency.</description><author>Yasin Findik, S. Reza Ahmadzadeh</author><pubDate>Mon, 12 Feb 2024 16:21:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07752v1</guid></item><item><title>Large language models can enhance persuasion through linguistic feature alignment</title><link>http://arxiv.org/abs/2311.16466v2</link><description>Although large language models (LLMs) are reshaping various aspects of humanlife, our current understanding of their impacts remains somewhat constrained.Here we investigate the impact of LLMs on human communication, using data onconsumer complaints in the financial industry. By employing an AI detectiontool on more than 820K complaints gathered by the Consumer Financial ProtectionBureau (CFPB), we find a sharp increase in the likely use of LLMs shortly afterthe release of ChatGPT. Moreover, the likely LLM usage was positivelycorrelated with message persuasiveness (i.e., increased likelihood of obtainingrelief from financial firms). Computational linguistic analyses suggest thatthe positive correlation may be explained by LLMs' enhancement of variouslinguistic features. Based on the results of these observational studies, wehypothesize that LLM usage may enhance a comprehensive set of linguisticfeatures, increasing message persuasiveness to receivers with heterogeneouslinguistic preferences (i.e., linguistic feature alignment). We test thishypothesis in preregistered experiments and find support for it. As an instanceof early empirical demonstrations of LLM usage for enhancing persuasion, ourresearch highlights the transformative potential of LLMs in humancommunication.</description><author>Minkyu Shin, Jin Kim</author><pubDate>Mon, 12 Feb 2024 16:20:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16466v2</guid></item><item><title>Optimal score estimation via empirical Bayes smoothing</title><link>http://arxiv.org/abs/2402.07747v1</link><description>We study the problem of estimating the score function of an unknownprobability distribution $\rho^*$ from $n$ independent and identicallydistributed observations in $d$ dimensions. Assuming that $\rho^*$ issubgaussian and has a Lipschitz-continuous score function $s^*$, we establishthe optimal rate of $\tilde \Theta(n^{-\frac{2}{d+4}})$ for this estimationproblem under the loss function $\|\hat s - s^*\|^2_{L^2(\rho^*)}$ that iscommonly used in the score matching literature, highlighting the curse ofdimensionality where sample complexity for accurate score estimation growsexponentially with the dimension $d$. Leveraging key insights in empiricalBayes theory as well as a new convergence rate of smoothed empiricaldistribution in Hellinger distance, we show that a regularized score estimatorbased on a Gaussian kernel attains this rate, shown optimal by a matchingminimax lower bound. We also discuss the implication of our theory on thesample complexity of score-based generative models.</description><author>Andre Wibisono, Yihong Wu, Kaylee Yingxi Yang</author><pubDate>Mon, 12 Feb 2024 16:17:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07747v1</guid></item><item><title>Minimally Interactive Segmentation of Soft-Tissue Tumors on CT and MRI using Deep Learning</title><link>http://arxiv.org/abs/2402.07746v1</link><description>Segmentations are crucial in medical imaging to obtain morphological,volumetric, and radiomics biomarkers. Manual segmentation is accurate but notfeasible in the radiologist's clinical workflow, while automatic segmentationgenerally obtains sub-par performance. We therefore developed a minimallyinteractive deep learning-based segmentation method for soft-tissue tumors(STTs) on CT and MRI. The method requires the user to click six points near thetumor's extreme boundaries. These six points are transformed into a distancemap and serve, with the image, as input for a Convolutional Neural Network. Fortraining and validation, a multicenter dataset containing 514 patients and nineSTT types in seven anatomical locations was used, resulting in a DiceSimilarity Coefficient (DSC) of 0.85$\pm$0.11 (mean $\pm$ standard deviation(SD)) for CT and 0.84$\pm$0.12 for T1-weighted MRI, when compared to manualsegmentations made by expert radiologists. Next, the method was externallyvalidated on a dataset including five unseen STT phenotypes in extremities,achieving 0.81$\pm$0.08 for CT, 0.84$\pm$0.09 for T1-weighted MRI, and0.88\pm0.08 for previously unseen T2-weighted fat-saturated (FS) MRI. Inconclusion, our minimally interactive segmentation method effectively segmentsdifferent types of STTs on CT and MRI, with robust generalization to previouslyunseen phenotypes and imaging modalities.</description><author>Douwe J. Spaanderman, Martijn P. A. Starmans, Gonnie C. M. van Erp, David F. Hanff, Judith H. Sluijter, Anne-Rose W. Schut, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Grunhagen, Wiro J. Niessen, Jacob J. Visser, Stefan Klein</author><pubDate>Mon, 12 Feb 2024 16:15:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07746v1</guid></item><item><title>Predictive Churn with the Set of Good Models</title><link>http://arxiv.org/abs/2402.07745v1</link><description>Machine learning models in modern mass-market applications are often updatedover time. One of the foremost challenges faced is that, despite increasingoverall performance, these updates may flip specific model predictions inunpredictable ways. In practice, researchers quantify the number of unstablepredictions between models pre and post update -- i.e., predictive churn. Inthis paper, we study this effect through the lens of predictive multiplicity --i.e., the prevalence of conflicting predictions over the set of near-optimalmodels (the Rashomon set). We show how traditional measures of predictivemultiplicity can be used to examine expected churn over this set of prospectivemodels -- i.e., the set of models that may be used to replace a baseline modelin deployment. We present theoretical results on the expected churn betweenmodels within the Rashomon set from different perspectives. And we characterizeexpected churn over model updates via the Rashomon set, pairing our analysiswith empirical results on real-world datasets -- showing how our approach canbe used to better anticipate, reduce, and avoid churn in consumer-facingapplications. Further, we show that our approach is useful even for modelsenhanced with uncertainty awareness.</description><author>Jamelle Watson-Daniels, Flavio du Pin Calmon, Alexander D'Amour, Carol Long, David C. Parkes, Berk Ustun</author><pubDate>Mon, 12 Feb 2024 16:15:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07745v1</guid></item><item><title>Towards Unified Alignment Between Agents, Humans, and Environment</title><link>http://arxiv.org/abs/2402.07744v1</link><description>The rapid progress of foundation models has led to the prosperity ofautonomous agents, which leverage the universal capabilities of foundationmodels to conduct reasoning, decision-making, and environmental interaction.However, the efficacy of agents remains limited when operating in intricate,realistic environments. In this work, we introduce the principles of$\mathbf{U}$nified $\mathbf{A}$lignment for $\mathbf{A}$gents($\mathbf{UA}^2$), which advocate for the simultaneous alignment of agents withhuman intentions, environmental dynamics, and self-constraints such as thelimitation of monetary budgets. From the perspective of $\mathbf{UA}^2$, wereview the current agent research and highlight the neglected factors inexisting agent benchmarks and method candidates. We also conductproof-of-concept studies by introducing realistic features to WebShop,including user profiles to demonstrate intentions, personalized reranking forcomplex environmental dynamics, and runtime cost statistics to reflectself-constraints. We then follow the principles of $\mathbf{UA}^2$ to proposean initial design of our agent, and benchmark its performance with severalcandidate baselines in the retrofitted WebShop. The extensive experimentalresults further prove the importance of the principles of $\mathbf{UA}^2$. Ourresearch sheds light on the next steps of autonomous agent research withimproved general problem-solving abilities.</description><author>Zonghan Yang, An Liu, Zijun Liu, Kaiming Liu, Fangzhou Xiong, Yile Wang, Zeyuan Yang, Qingyuan Hu, Xinrui Chen, Zhenhe Zhang, Fuwen Luo, Zhicheng Guo, Peng Li, Yang Liu</author><pubDate>Mon, 12 Feb 2024 16:14:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07744v1</guid></item><item><title>Class Distribution Shifts in Zero-Shot Learning: Learning Robust Representations</title><link>http://arxiv.org/abs/2311.18575v2</link><description>Class distribution shifts are particularly challenging for zero-shotclassifiers, which rely on representations learned from training classes butare deployed on new, unseen ones. Common causes for such shifts are changes inattributes associated with classes, such as race or gender in personidentification. In this work, we propose and analyze a model that adopts thissetting, assuming that the attribute responsible for the shift is unknownduring training. To address the challenge of learning data representationsrobust to such shifts, we introduce a framework based on hierarchical samplingto construct synthetic data environments. Despite key differences between thesettings, this framework allows us to formulate class distribution shifts inzero-shot learning as out-of-distribution problems. Consequently, we present analgorithm for learning robust representations, and show that our approachsignificantly improves generalization to diverse class distributions in bothsimulations and real-world datasets.</description><author>Yuli Slavutsky, Yuval Benjamini</author><pubDate>Mon, 12 Feb 2024 16:10:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18575v2</guid></item><item><title>Adaptive Proximal Gradient Method for Convex Optimization</title><link>http://arxiv.org/abs/2308.02261v2</link><description>In this paper, we explore two fundamental first-order algorithms in convexoptimization, namely, gradient descent (GD) and proximal gradient method(ProxGD). Our focus is on making these algorithms entirely adaptive byleveraging local curvature information of smooth functions. We propose adaptiveversions of GD and ProxGD that are based on observed gradient differences and,thus, have no added computational costs. Moreover, we prove convergence of ourmethods assuming only local Lipschitzness of the gradient. In addition, theproposed versions allow for even larger stepsizes than those initiallysuggested in [MM20].</description><author>Yura Malitsky, Konstantin Mishchenko</author><pubDate>Mon, 12 Feb 2024 16:05:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.02261v2</guid></item><item><title>Asking Multimodal Clarifying Questions in Mixed-Initiative Conversational Search</title><link>http://arxiv.org/abs/2402.07742v1</link><description>In mixed-initiative conversational search systems, clarifying questions areused to help users who struggle to express their intentions in a single query.These questions aim to uncover user's information needs and resolve queryambiguities. We hypothesize that in scenarios where multimodal information ispertinent, the clarification process can be improved by using non-textualinformation. Therefore, we propose to add images to clarifying questions andformulate the novel task of asking multimodal clarifying questions inopen-domain, mixed-initiative conversational search systems. To facilitateresearch into this task, we collect a dataset named Melon that contains over 4kmultimodal clarifying questions, enriched with over 14k images. We also proposea multimodal query clarification model named Marto and adopt a prompt-based,generative fine-tuning strategy to perform the training of different stageswith different prompts. Several analyses are conducted to understand theimportance of multimodal contents during the query clarification phase.Experimental results indicate that the addition of images leads to significantimprovements of up to 90% in retrieval performance when selecting the relevantimages. Extensive analyses are also performed to show the superiority of Martocompared with discriminative baselines in terms of effectiveness andefficiency.</description><author>Yifei Yuan, Clemencia Siro, Mohammad Aliannejadi, Maarten de Rijke, Wai Lam</author><pubDate>Mon, 12 Feb 2024 16:04:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07742v1</guid></item><item><title>Task-conditioned adaptation of visual features in multi-task policy learning</title><link>http://arxiv.org/abs/2402.07739v1</link><description>Successfully addressing a wide variety of tasks is a core ability ofautonomous agents, which requires flexibly adapting the underlyingdecision-making strategies and, as we argue in this work, also adapting theunderlying perception modules. An analogical argument would be the human visualsystem, which uses top-down signals to focus attention determined by thecurrent task. Similarly, in this work, we adapt pre-trained large vision modelsconditioned on specific downstream tasks in the context of multi-task policylearning. We introduce task-conditioned adapters that do not require finetuningany pre-trained weights, combined with a single policy trained with behaviorcloning and capable of addressing multiple tasks. We condition the policy andvisual adapters on task embeddings, which can be selected at inference if thetask is known, or alternatively inferred from a set of example demonstrations.To this end, we propose a new optimization-based estimator. We evaluate themethod on a wide variety of tasks of the CortexBench benchmark and show that,compared to existing work, it can be addressed with a single policy. Inparticular, we demonstrate that adapting visual features is a key design choiceand that the method generalizes to unseen tasks given visual demonstrations.</description><author>Pierre Marza, Laetitia Matignon, Olivier Simonin, Christian Wolf</author><pubDate>Mon, 12 Feb 2024 15:57:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07739v1</guid></item><item><title>Universal link predictor by In-context Learning</title><link>http://arxiv.org/abs/2402.07738v1</link><description>Link prediction is a crucial task in graph machine learning, where the goalis to infer missing or future links within a graph. Traditional approachesleverage heuristic methods based on widely observed connectivity patterns,offering broad applicability and generalizability without the need for modeltraining. Despite their utility, these methods are limited by their reliance onhuman-derived heuristics and lack the adaptability of data-driven approaches.Conversely, parametric link predictors excel in automatically learning theconnectivity patterns from data and achieving state-of-the-art but fail shortto directly transfer across different graphs. Instead, it requires the cost ofextensive training and hyperparameter optimization to adapt to the targetgraph. In this work, we introduce the Universal Link Predictor (UniLP), a novelmodel that combines the generalizability of heuristic approaches with thepattern learning capabilities of parametric models. UniLP is designed toautonomously identify connectivity patterns across diverse graphs, ready forimmediate application to any unseen graph dataset without targeted training. Weaddress the challenge of conflicting connectivity patterns-arising from theunique distributions of different graphs-through the implementation ofIn-context Learning (ICL). This approach allows UniLP to dynamically adjust tovarious target graphs based on contextual demonstrations, thereby avoidingnegative transfer. Through rigorous experimentation, we demonstrate UniLP'seffectiveness in adapting to new, unseen graphs at test time, showcasing itsability to perform comparably or even outperform parametric models that havebeen finetuned for specific datasets. Our findings highlight UniLP's potentialto set a new standard in link prediction, combining the strengths of heuristicand parametric methods in a single, versatile framework.</description><author>Kaiwen Dong, Haitao Mao, Zhichun Guo, Nitesh V. Chawla</author><pubDate>Mon, 12 Feb 2024 15:52:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07738v1</guid></item><item><title>Graph Structure Inference with BAM: Introducing the Bilinear Attention Mechanism</title><link>http://arxiv.org/abs/2402.07735v1</link><description>In statistics and machine learning, detecting dependencies in datasets is acentral challenge. We propose a novel neural network model for supervised graphstructure learning, i.e., the process of learning a mapping betweenobservational data and their underlying dependence structure. The model istrained with variably shaped and coupled simulated input data and requires onlya single forward pass through the trained network for inference. By leveragingstructural equation models and employing randomly generated multivariateChebyshev polynomials for the simulation of training data, our methoddemonstrates robust generalizability across both linear and various types ofnon-linear dependencies. We introduce a novel bilinear attention mechanism(BAM) for explicit processing of dependency information, which operates on thelevel of covariance matrices of transformed data and respects the geometry ofthe manifold of symmetric positive definite matrices. Empirical evaluationdemonstrates the robustness of our method in detecting a wide range ofdependencies, excelling in undirected graph estimation and proving competitivein completed partially directed acyclic graph estimation through a noveltwo-step approach.</description><author>Philipp Froehlich, Heinz Koeppl</author><pubDate>Mon, 12 Feb 2024 15:48:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07735v1</guid></item><item><title>Parameterized Projected Bellman Operator</title><link>http://arxiv.org/abs/2312.12869v2</link><description>Approximate value iteration (AVI) is a family of algorithms for reinforcementlearning (RL) that aims to obtain an approximation of the optimal valuefunction. Generally, AVI algorithms implement an iterated procedure where eachstep consists of (i) an application of the Bellman operator and (ii) aprojection step into a considered function space. Notoriously, the Bellmanoperator leverages transition samples, which strongly determine its behavior,as uninformative samples can result in negligible updates or long detours,whose detrimental effects are further exacerbated by the computationallyintensive projection step. To address these issues, we propose a novelalternative approach based on learning an approximate version of the Bellmanoperator rather than estimating it through samples as in AVI approaches. Thisway, we are able to (i) generalize across transition samples and (ii) avoid thecomputationally intensive projection step. For this reason, we call our noveloperator projected Bellman operator (PBO). We formulate an optimization problemto learn PBO for generic sequential decision-making problems, and wetheoretically analyze its properties in two representative classes of RLproblems. Furthermore, we theoretically study our approach under the lens ofAVI and devise algorithmic implementations to learn PBO in offline and onlinesettings by leveraging neural network parameterizations. Finally, weempirically showcase the benefits of PBO w.r.t. the regular Bellman operator onseveral RL problems.</description><author>Théo Vincent, Alberto Maria Metelli, Boris Belousov, Jan Peters, Marcello Restelli, Carlo D'Eramo</author><pubDate>Mon, 12 Feb 2024 15:42:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12869v2</guid></item><item><title>AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension</title><link>http://arxiv.org/abs/2402.07729v1</link><description>Recently, instruction-following audio-language models have received broadattention for human-audio interaction. However, the absence of benchmarkscapable of evaluating audio-centric interaction capabilities has impededadvancements in this field. Previous models primarily focus on assessingdifferent fundamental tasks, such as Automatic Speech Recognition (ASR), andlack an assessment of the open-ended generative capabilities centered aroundaudio. Thus, it is challenging to track the progression in the LargeAudio-Language Models (LALMs) domain and to provide guidance for futureimprovement. In this paper, we introduce AIR-Bench (\textbf{A}udio\textbf{I}nst\textbf{R}uction \textbf{Bench}mark), the first benchmark designedto evaluate the ability of LALMs to understand various types of audio signals(including human speech, natural sounds, and music), and furthermore, tointeract with humans in the textual format. AIR-Bench encompasses twodimensions: \textit{foundation} and \textit{chat} benchmarks. The formerconsists of 19 tasks with approximately 19k single-choice questions, intendingto inspect the basic single-task ability of LALMs. The latter one contains 2kinstances of open-ended question-and-answer data, directly assessing thecomprehension of the model on complex audio and its capacity to followinstructions. Both benchmarks require the model to generate hypothesesdirectly. We design a unified framework that leverages advanced languagemodels, such as GPT-4, to evaluate the scores of generated hypotheses given themeta-information of the audio. Experimental results demonstrate a high level ofconsistency between GPT-4-based evaluation and human evaluation. By revealingthe limitations of existing LALMs through evaluation results, AIR-Bench canprovide insights into the direction of future research.</description><author>Qian Yang, Jin Xu, Wenrui Liu, Yunfei Chu, Ziyue Jiang, Xiaohuan Zhou, Yichong Leng, Yuanjun Lv, Zhou Zhao, Chang Zhou, Jingren Zhou</author><pubDate>Mon, 12 Feb 2024 15:41:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07729v1</guid></item><item><title>Unsupervised Sign Language Translation and Generation</title><link>http://arxiv.org/abs/2402.07726v1</link><description>Motivated by the success of unsupervised neural machine translation (UNMT),we introduce an unsupervised sign language translation and generation network(USLNet), which learns from abundant single-modality (text and video) datawithout parallel sign language data. USLNet comprises two main components:single-modality reconstruction modules (text and video) that rebuild the inputfrom its noisy version in the same modality and cross-modality back-translationmodules (text-video-text and video-text-video) that reconstruct the input fromits noisy version in the different modality using back-translationprocedure.Unlike the single-modality back-translation procedure in text-basedUNMT, USLNet faces the cross-modality discrepancy in feature representation, inwhich the length and the feature dimension mismatch between text and videosequences. We propose a sliding window method to address the issues of aligningvariable-length text with video sequences. To our knowledge, USLNet is thefirst unsupervised sign language translation and generation model capable ofgenerating both natural language text and sign language video in a unifiedmanner. Experimental results on the BBC-Oxford Sign Language dataset (BOBSL)and Open-Domain American Sign Language dataset (OpenASL) reveal that USLNetachieves competitive results compared to supervised baseline models, indicatingits effectiveness in sign language translation and generation.</description><author>Zhengsheng Guo, Zhiwei He, Wenxiang Jiao, Xing Wang, Rui Wang, Kehai Chen, Zhaopeng Tu, Yong Xu, Min Zhang</author><pubDate>Mon, 12 Feb 2024 15:39:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07726v1</guid></item><item><title>Generalization Bounds for Heavy-Tailed SDEs through the Fractional Fokker-Planck Equation</title><link>http://arxiv.org/abs/2402.07723v1</link><description>Understanding the generalization properties of heavy-tailed stochasticoptimization algorithms has attracted increasing attention over the past years.While illuminating interesting aspects of stochastic optimizers by usingheavy-tailed stochastic differential equations as proxies, prior works eitherprovided expected generalization bounds, or introduced non-computableinformation theoretic terms. Addressing these drawbacks, in this work, we provehigh-probability generalization bounds for heavy-tailed SDEs which do notcontain any nontrivial information theoretic terms. To achieve this goal, wedevelop new proof techniques based on estimating the entropy flows associatedwith the so-called fractional Fokker-Planck equation (a partial differentialequation that governs the evolution of the distribution of the correspondingheavy-tailed SDE). In addition to obtaining high-probability bounds, we showthat our bounds have a better dependence on the dimension of parameters ascompared to prior art. Our results further identify a phase transitionphenomenon, which suggests that heavy tails can be either beneficial or harmfuldepending on the problem structure. We support our theory with experimentsconducted in a variety of settings.</description><author>Benjamin Dupuis, Umut Şimşekli</author><pubDate>Mon, 12 Feb 2024 15:35:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07723v1</guid></item><item><title>LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation</title><link>http://arxiv.org/abs/2402.07721v1</link><description>Low-Rank Adaptation (LoRA) introduces auxiliary parameters for each layer tofine-tune the pre-trained model under limited computing resources. But it stillfaces challenges of resource consumption when scaling up to larger models.Previous studies employ pruning techniques by evaluating the importance of LoRAparameters for different layers to address the problem. However, these effortsonly analyzed parameter features to evaluate their importance. Indeed, theoutput of LoRA related to the parameters and data is the factor that directlyimpacts the frozen model. To this end, we propose LoRA-drop which evaluates theimportance of the parameters by analyzing the LoRA output. We retain LoRA forimportant layers and the LoRA of the other layers share the same parameters.Abundant experiments on NLU and NLG tasks demonstrate the effectiveness ofLoRA-drop.</description><author>Hongyun Zhou, Xiangyu Lu, Wang Xu, Conghui Zhu, Tiejun Zhao</author><pubDate>Mon, 12 Feb 2024 15:34:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07721v1</guid></item><item><title>Efficient reductions between some statistical models</title><link>http://arxiv.org/abs/2402.07717v1</link><description>We study the problem of approximately transforming a sample from a sourcestatistical model to a sample from a target statistical model without knowingthe parameters of the source model, and construct several computationallyefficient such reductions between statistical experiments. In particular, weprovide computationally efficient procedures that approximately reduce uniform,Erlang, and Laplace location models to general target families. We illustrateour methodology by establishing nonasymptotic reductions between some canonicalhigh-dimensional problems, spanning mixtures of experts, phase retrieval, andsignal denoising. Notably, the reductions are structure preserving and canaccommodate missing data. We also point to a possible application intransforming one differentially private mechanism to another.</description><author>Mengqi Lou, Guy Bresler, Ashwin Pananjady</author><pubDate>Mon, 12 Feb 2024 15:32:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07717v1</guid></item><item><title>From Random Search to Bandit Learning in Metric Measure Spaces</title><link>http://arxiv.org/abs/2305.11509v6</link><description>Random Search is one of the most widely-used method for HyperparameterOptimization, and is critical to the success of deep learning models. Despiteits astonishing performance, little non-heuristic theory has been developed todescribe the underlying working mechanism. This paper gives a theoreticalaccounting of Random Search. We introduce the concept of \emph{scatteringdimension} that describes the landscape of the underlying function, andquantifies the performance of random search. We show that, when the environmentis noise-free, the output of random search converges to the optimal value inprobability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T}\right)^{ \frac{1}{d_s} } \right) $, where $ d_s \ge 0 $ is the scatteringdimension of the underlying function. When the observed function values arecorrupted by bounded $iid$ noise, the output of random search converges to theoptimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left(\frac{1}{T} \right)^{ \frac{1}{d_s + 1} } \right) $. In addition, based on theprinciples of random search, we introduce an algorithm, called BLiN-MOS, forLipschitz bandits in doubling metric spaces that are also endowed with aprobability measure, and show that under mild conditions, BLiN-MOS achieves aregret rate of order $ \widetilde{\mathcal{O}} \left( T^{ \frac{d_z}{d_z + 1} }\right) $, where $d_z$ is the zooming dimension of the problem instance.</description><author>Chuying Han, Yasong Feng, Tianyu Wang</author><pubDate>Mon, 12 Feb 2024 15:32:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11509v6</guid></item><item><title>LightCAM: A Fast and Light Implementation of Context-Aware Masking based D-TDNN for Speaker Verification</title><link>http://arxiv.org/abs/2402.06073v2</link><description>Traditional Time Delay Neural Networks (TDNN) have achieved state-of-the-artperformance at the cost of high computational complexity and slower inferencespeed, making them difficult to implement in an industrial environment. TheDensely Connected Time Delay Neural Network (D-TDNN) with Context Aware Masking(CAM) module has proven to be an efficient structure to reduce complexity whilemaintaining system performance. In this paper, we propose a fast andlightweight model, LightCAM, which further adopts a depthwise separableconvolution module (DSM) and uses multi-scale feature aggregation (MFA) forfeature fusion at different levels. Extensive experiments are conducted onVoxCeleb dataset, the comparative results show that it has achieved an EER of0.83 and MinDCF of 0.0891 in VoxCeleb1-O, which outperforms the othermainstream speaker verification methods. In addition, complexity analysisfurther demonstrates that the proposed architecture has lower computationalcost and faster inference speed.</description><author>Di Cao, Xianchen Wang, Junfeng Zhou, Jiakai Zhang, Yanjing Lei, Wenpeng Chen</author><pubDate>Mon, 12 Feb 2024 15:28:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06073v2</guid></item><item><title>Model Collapse Demystified: The Case of Regression</title><link>http://arxiv.org/abs/2402.07712v1</link><description>In the era of large language models like ChatGPT, the phenomenon of "modelcollapse" refers to the situation whereby as a model is trained recursively ondata generated from previous generations of itself over time, its performancedegrades until the model eventually becomes completely useless, i.e the modelcollapses. In this work, we study this phenomenon in the simplified setting ofkernel regression and obtain results which show a clear crossover between wherethe model can cope with fake data, and a regime where the model's performancecompletely collapses. Under polynomial decaying spectral and source conditions,we obtain modified scaling laws which exhibit new crossover phenomena from fastto slow rates. We also propose a simple strategy based on adaptiveregularization to mitigate model collapse. Our theoretical results arevalidated with experiments.</description><author>Elvis Dohmatob, Yunzhen Feng, Julia Kempe</author><pubDate>Mon, 12 Feb 2024 15:26:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07712v1</guid></item></channel></rss>