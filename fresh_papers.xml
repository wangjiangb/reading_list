<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 26 Jan 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities</title><link>http://arxiv.org/abs/2401.14405v1</link><description>We propose to improve transformers of a specific modality with irrelevantdata from other modalities, e.g., improve an ImageNet model with audio or pointcloud datasets. We would like to highlight that the data samples of the targetmodality are irrelevant to the other modalities, which distinguishes our methodfrom other works utilizing paired (e.g., CLIP) or interleaved data of differentmodalities. We propose a methodology named Multimodal Pathway - given a targetmodality and a transformer designed for it, we use an auxiliary transformertrained with data of another modality and construct pathways to connectcomponents of the two models so that data of the target modality can beprocessed by both models. In this way, we utilize the universalsequence-to-sequence modeling abilities of transformers obtained from twomodalities. As a concrete implementation, we use a modality-specific tokenizerand task-specific head as usual but utilize the transformer blocks of theauxiliary model via a proposed method named Cross-Modal Re-parameterization,which exploits the auxiliary weights without any inference costs. On the image,point cloud, video, and audio recognition tasks, we observe significant andconsistent performance improvements with irrelevant data from other modalities.The code and models are available at https://github.com/AILab-CVC/M2PT.</description><author>Yiyuan Zhang, Xiaohan Ding, Kaixiong Gong, Yixiao Ge, Ying Shan, Xiangyu Yue</author><pubDate>Thu, 25 Jan 2024 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14405v1</guid></item><item><title>Deconstructing Denoising Diffusion Models for Self-Supervised Learning</title><link>http://arxiv.org/abs/2401.14404v1</link><description>In this study, we examine the representation learning abilities of DenoisingDiffusion Models (DDM) that were originally purposed for image generation. Ourphilosophy is to deconstruct a DDM, gradually transforming it into a classicalDenoising Autoencoder (DAE). This deconstructive procedure allows us to explorehow various components of modern DDMs influence self-supervised representationlearning. We observe that only a very few modern components are critical forlearning good representations, while many others are nonessential. Our studyultimately arrives at an approach that is highly simplified and to a largeextent resembles a classical DAE. We hope our study will rekindle interest in afamily of classical methods within the realm of modern self-supervisedlearning.</description><author>Xinlei Chen, Zhuang Liu, Saining Xie, Kaiming He</author><pubDate>Thu, 25 Jan 2024 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14404v1</guid></item><item><title>Adaptive Mobile Manipulation for Articulated Objects In the Open World</title><link>http://arxiv.org/abs/2401.14403v1</link><description>Deploying robots in open-ended unstructured environments such as homes hasbeen a long-standing research problem. However, robots are often studied onlyin closed-off lab settings, and prior mobile manipulation work is restricted topick-move-place, which is arguably just the tip of the iceberg in this area. Inthis paper, we introduce Open-World Mobile Manipulation System, a full-stackapproach to tackle realistic articulated object operation, e.g. real-worlddoors, cabinets, drawers, and refrigerators in open-ended unstructuredenvironments. The robot utilizes an adaptive learning framework to initiallylearns from a small set of data through behavior cloning, followed by learningfrom online practice on novel objects that fall outside the trainingdistribution. We also develop a low-cost mobile manipulation hardware platformcapable of safe and autonomous online adaptation in unstructured environmentswith a cost of around 20,000 USD. In our experiments we utilize 20 articulateobjects across 4 buildings in the CMU campus. With less than an hour of onlinelearning for each object, the system is able to increase success rate from 50%of BC pre-training to 95% using online adaptation. Video results athttps://open-world-mobilemanip.github.io/</description><author>Haoyu Xiong, Russell Mendonca, Kenneth Shaw, Deepak Pathak</author><pubDate>Thu, 25 Jan 2024 18:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14403v1</guid></item><item><title>Range-Agnostic Multi-View Depth Estimation With Keyframe Selection</title><link>http://arxiv.org/abs/2401.14401v1</link><description>Methods for 3D reconstruction from posed frames require prior knowledge aboutthe scene metric range, usually to recover matching cues along the epipolarlines and narrow the search range. However, such prior might not be directlyavailable or estimated inaccurately in real scenarios -- e.g., outdoor 3Dreconstruction from video sequences -- therefore heavily hampering performance.In this paper, we focus on multi-view depth estimation without requiring priorknowledge about the metric range of the scene by proposing RAMDepth, anefficient and purely 2D framework that reverses the depth estimation andmatching steps order. Moreover, we demonstrate the capability of our frameworkto provide rich insights about the quality of the views used for prediction.Additional material can be found on our project pagehttps://andreaconti.github.io/projects/range_agnostic_multi_view_depth.</description><author>Andrea Conti, Matteo Poggi, Valerio Cambareri, Stefano Mattoccia</author><pubDate>Thu, 25 Jan 2024 18:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14401v1</guid></item><item><title>Modular Adaptation of Multilingual Encoders to Written Swiss German Dialect</title><link>http://arxiv.org/abs/2401.14400v1</link><description>Creating neural text encoders for written Swiss German is challenging due toa dearth of training data combined with dialectal variation. In this paper, webuild on several existing multilingual encoders and adapt them to Swiss Germanusing continued pre-training. Evaluation on three diverse downstream tasksshows that simply adding a Swiss German adapter to a modular encoder achieves97.5% of fully monolithic adaptation performance. We further find that for thetask of retrieving Swiss German sentences given Standard German queries,adapting a character-level model is more effective than the other adaptationstrategies. We release our code and the models trained for our experiments athttps://github.com/ZurichNLP/swiss-german-text-encoders</description><author>Jannis Vamvas, Noëmi Aepli, Rico Sennrich</author><pubDate>Thu, 25 Jan 2024 18:59:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14400v1</guid></item><item><title>pix2gestalt: Amodal Segmentation by Synthesizing Wholes</title><link>http://arxiv.org/abs/2401.14398v1</link><description>We introduce pix2gestalt, a framework for zero-shot amodal segmentation,which learns to estimate the shape and appearance of whole objects that areonly partially visible behind occlusions. By capitalizing on large-scalediffusion models and transferring their representations to this task, we learna conditional diffusion model for reconstructing whole objects in challengingzero-shot cases, including examples that break natural and physical priors,such as art. As training data, we use a synthetically curated datasetcontaining occluded objects paired with their whole counterparts. Experimentsshow that our approach outperforms supervised baselines on establishedbenchmarks. Our model can furthermore be used to significantly improve theperformance of existing object recognition and 3D reconstruction methods in thepresence of occlusions.</description><author>Ege Ozguroglu, Ruoshi Liu, Dídac Surís, Dian Chen, Achal Dave, Pavel Tokmakov, Carl Vondrick</author><pubDate>Thu, 25 Jan 2024 18:57:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14398v1</guid></item><item><title>Rethinking Patch Dependence for Masked Autoencoders</title><link>http://arxiv.org/abs/2401.14391v1</link><description>In this work, we re-examine inter-patch dependencies in the decodingmechanism of masked autoencoders (MAE). We decompose this decoding mechanismfor masked patch reconstruction in MAE into self-attention and cross-attention.Our investigations suggest that self-attention between mask patches is notessential for learning good representations. To this end, we propose a novelpretraining framework: Cross-Attention Masked Autoencoders (CrossMAE).CrossMAE's decoder leverages only cross-attention between masked and visibletokens, with no degradation in downstream performance. This design also enablesdecoding only a small subset of mask tokens, boosting efficiency. Furthermore,each decoder block can now leverage different encoder features, resulting inimproved representation learning. CrossMAE matches MAE in performance with 2.5to 3.7$\times$ less decoding compute. It also surpasses MAE on ImageNetclassification and COCO instance segmentation under the same compute. Code andmodels: https://crossmae.github.io</description><author>Letian Fu, Long Lian, Renhao Wang, Baifeng Shi, Xudong Wang, Adam Yala, Trevor Darrell, Alexei A. Efros, Ken Goldberg</author><pubDate>Thu, 25 Jan 2024 18:49:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14391v1</guid></item><item><title>Smooth Ranking SVM via Cutting-Plane Method</title><link>http://arxiv.org/abs/2401.14388v1</link><description>The most popular classification algorithms are designed to maximizeclassification accuracy during training. However, this strategy may fail in thepresence of class imbalance since it is possible to train models with highaccuracy by overfitting to the majority class. On the other hand, the AreaUnder the Curve (AUC) is a widely used metric to compare classificationperformance of different algorithms when there is a class imbalance, andvarious approaches focusing on the direct optimization of this metric duringtraining have been proposed. Among them, SVM-based formulations are especiallypopular as this formulation allows incorporating different regularizationstrategies easily. In this work, we develop a prototype learning approach thatrelies on cutting-plane method, similar to Ranking SVM, to maximize AUC. Ouralgorithm learns simpler models by iteratively introducing cutting planes, thusoverfitting is prevented in an unconventional way. Furthermore, it penalizesthe changes in the weights at each iteration to avoid large jumps that might beobserved in the test performance, thus facilitating a smooth learning process.Based on the experiments conducted on 73 binary classification datasets, ourmethod yields the best test AUC in 25 datasets among its relevant competitors.</description><author>Erhan Can Ozcan, Berk Görgülü, Mustafa G. Baydogan, Ioannis Ch. Paschalidis</author><pubDate>Thu, 25 Jan 2024 18:47:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14388v1</guid></item><item><title>Inconsistency Masks: Removing the Uncertainty from Input-Pseudo-Label Pairs</title><link>http://arxiv.org/abs/2401.14387v1</link><description>Generating sufficient labeled data is a significant hurdle in the efficientexecution of deep learning projects, especially in uncharted territories ofimage segmentation where labeling demands extensive time, unlike classificationtasks. Our study confronts this challenge, operating in an environmentconstrained by limited hardware resources and the lack of extensive datasets orpre-trained models. We introduce the novel use of Inconsistency Masks (IM) toeffectively filter uncertainty in image-pseudo-label pairs, substantiallyelevating segmentation quality beyond traditional semi-supervised learningtechniques. By integrating IM with other methods, we demonstrate remarkablebinary segmentation performance on the ISIC 2018 dataset, starting with just10% labeled data. Notably, three of our hybrid models outperform those trainedon the fully labeled dataset. Our approach consistently achieves exceptionalresults across three additional datasets and shows further improvement whencombined with other techniques. For comprehensive and robust evaluation, thispaper includes an extensive analysis of prevalent semi-supervised learningstrategies, all trained under identical starting conditions. The full code isavailable at: https://github.com/MichaelVorndran/InconsistencyMasks</description><author>Michael R. H. Vorndran, Bernhard F. Roeck</author><pubDate>Thu, 25 Jan 2024 18:46:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14387v1</guid></item><item><title>DyEdgeGAT: Dynamic Edge via Graph Attention for Early Fault Detection in IIoT Systems</title><link>http://arxiv.org/abs/2307.03761v3</link><description>In the Industrial Internet of Things (IIoT), condition monitoring sensorsignals from complex systems often exhibit nonlinear and stochasticspatial-temporal dynamics under varying conditions. These complex dynamics makefault detection particularly challenging. While previous methods effectivelymodel these dynamics, they often neglect the evolution of relationships betweensensor signals. Undetected shifts in these relationships can lead tosignificant system failures. Furthermore, these methods frequently misidentifynovel operating conditions as faults. Addressing these limitations, we proposeDyEdgeGAT (Dynamic Edge via Graph Attention), a novel approach for early-stagefault detection in IIoT systems. DyEdgeGAT's primary innovation lies in a novelgraph inference scheme for multivariate time series that tracks the evolutionof relationships between time series, enabled by dynamic edge construction.Another key innovation of DyEdgeGAT is its ability to incorporate operatingcondition contexts into node dynamics modeling, enhancing its accuracy androbustness. We rigorously evaluated DyEdgeGAT using both a synthetic dataset,simulating varying levels of fault severity, and a real-world industrial-scalemultiphase flow facility benchmark with diverse fault types under varyingoperating conditions and detection complexities. The results show thatDyEdgeGAT significantly outperforms other baseline methods in fault detection,particularly in the early stages with low severity, and exhibits robustperformance under novel operating conditions.</description><author>Mengjie Zhao, Olga Fink</author><pubDate>Thu, 25 Jan 2024 18:45:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03761v3</guid></item><item><title>An Orthogonal Polynomial Kernel-Based Machine Learning Model for Differential-Algebraic Equations</title><link>http://arxiv.org/abs/2401.14382v1</link><description>The recent introduction of the Least-Squares Support Vector Regression(LS-SVR) algorithm for solving differential and integral equations has sparkedinterest. In this study, we expand the application of this algorithm to addresssystems of differential-algebraic equations (DAEs). Our work presents a novelapproach to solving general DAEs in an operator format by establishingconnections between the LS-SVR machine learning model, weighted residualmethods, and Legendre orthogonal polynomials. To assess the effectiveness ofour proposed method, we conduct simulations involving various DAE scenarios,such as nonlinear systems, fractional-order derivatives, integro-differential,and partial DAEs. Finally, we carry out comparisons between our proposed methodand currently established state-of-the-art approaches, demonstrating itsreliability and effectiveness.</description><author>Tayebeh Taheri, Alireza Afzal Aghaei, Kourosh Parand</author><pubDate>Thu, 25 Jan 2024 18:37:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14382v1</guid></item><item><title>Manifold GCN: Diffusion-based Convolutional Neural Network for Manifold-valued Graphs</title><link>http://arxiv.org/abs/2401.14381v1</link><description>We propose two graph neural network layers for graphs with features in aRiemannian manifold. First, based on a manifold-valued graph diffusionequation, we construct a diffusion layer that can be applied to an arbitrarynumber of nodes and graph connectivity patterns. Second, we model a tangentmultilayer perceptron by transferring ideas from the vector neuron framework toour general setting. Both layers are equivariant with respect to nodepermutations and isometries of the feature manifold. These properties have beenshown to lead to a beneficial inductive bias in many deep learning tasks.Numerical examples on synthetic data as well as on triangle meshes of the righthippocampus to classify Alzheimer's disease demonstrate the very goodperformance of our layers.</description><author>Martin Hanik, Gabriele Steidl, Christoph von Tycowicz</author><pubDate>Thu, 25 Jan 2024 18:36:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14381v1</guid></item><item><title>MGAug: Multimodal Geometric Augmentation in Latent Spaces of Image Deformations</title><link>http://arxiv.org/abs/2312.13440v2</link><description>Geometric transformations have been widely used to augment the size oftraining images. Existing methods often assume a unimodal distribution of theunderlying transformations between images, which limits their power when datawith multimodal distributions occur. In this paper, we propose a novel model,Multimodal Geometric Augmentation (MGAug), that for the first time generatesaugmenting transformations in a multimodal latent space of geometricdeformations. To achieve this, we first develop a deep network that embeds thelearning of latent geometric spaces of diffeomorphic transformations (a.k.a.diffeomorphisms) in a variational autoencoder (VAE). A mixture of multivariateGaussians is formulated in the tangent space of diffeomorphisms and serves as aprior to approximate the hidden distribution of image transformations. We thenaugment the original training dataset by deforming images using randomlysampled transformations from the learned multimodal latent space of VAE. Tovalidate the efficiency of our model, we jointly learn the augmentationstrategy with two distinct domain-specific tasks: multi-class classification on2D synthetic datasets and segmentation on real 3D brain magnetic resonanceimages (MRIs). We also compare MGAug with state-of-the-art transformation-basedimage augmentation algorithms. Experimental results show that our proposedapproach outperforms all baselines by significantly improved predictionaccuracy. Our code is publicly available athttps://github.com/tonmoy-hossain/MGAug.</description><author>Tonmoy Hossain, Miaomiao Zhang</author><pubDate>Thu, 25 Jan 2024 18:31:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13440v2</guid></item><item><title>UrbanGenAI: Reconstructing Urban Landscapes using Panoptic Segmentation and Diffusion Models</title><link>http://arxiv.org/abs/2401.14379v1</link><description>In contemporary design practices, the integration of computer vision andgenerative artificial intelligence (genAI) represents a transformative shifttowards more interactive and inclusive processes. These technologies offer newdimensions of image analysis and generation, which are particularly relevant inthe context of urban landscape reconstruction. This paper presents a novelworkflow encapsulated within a prototype application, designed to leverage thesynergies between advanced image segmentation and diffusion models for acomprehensive approach to urban design. Our methodology encompasses theOneFormer model for detailed image segmentation and the Stable Diffusion XL(SDXL) diffusion model, implemented through ControlNet, for generating imagesfrom textual descriptions. Validation results indicated a high degree ofperformance by the prototype application, showcasing significant accuracy inboth object detection and text-to-image generation. This was evidenced bysuperior Intersection over Union (IoU) and CLIP scores across iterativeevaluations for various categories of urban landscape features. Preliminarytesting included utilising UrbanGenAI as an educational tool enhancing thelearning experience in design pedagogy, and as a participatory instrumentfacilitating community-driven urban planning. Early results suggested thatUrbanGenAI not only advances the technical frontiers of urban landscapereconstruction but also provides significant pedagogical and participatoryplanning benefits. The ongoing development of UrbanGenAI aims to furthervalidate its effectiveness across broader contexts and integrate additionalfeatures such as real-time feedback mechanisms and 3D modelling capabilities.Keywords: generative AI; panoptic image segmentation; diffusion models; urbanlandscape design; design pedagogy; co-design</description><author>Timo Kapsalis</author><pubDate>Thu, 25 Jan 2024 18:30:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14379v1</guid></item><item><title>TURNA: A Turkish Encoder-Decoder Language Model for Enhanced Understanding and Generation</title><link>http://arxiv.org/abs/2401.14373v1</link><description>The recent advances in natural language processing have predominantly favoredwell-resourced English-centric models, resulting in a significant gap withlow-resource languages. In this work, we introduce the language model TURNA,which is developed for the low-resource language Turkish and is capable of bothnatural language understanding and generation tasks. TURNA is pretrained withan encoder-decoder architecture based on the unified framework UL2 with adiverse corpus that we specifically curated for this purpose. We evaluatedTURNA with three generation tasks and five understanding tasks for Turkish. Theresults show that TURNA outperforms several multilingual models in bothunderstanding and generation tasks, and competes with monolingual Turkishmodels in understanding tasks. TURNA is made available athttps://huggingface.co/boun-tabi-LMG/TURNA .</description><author>Gökçe Uludoğan, Zeynep Yirmibeşoğlu Balal, Furkan Akkurt, Melikşah Türker, Onur Güngör, Susan Üsküdarlı</author><pubDate>Thu, 25 Jan 2024 18:24:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14373v1</guid></item><item><title>Efficient Optimisation of Physical Reservoir Computers using only a Delayed Input</title><link>http://arxiv.org/abs/2401.14371v1</link><description>We present an experimental validation of a recently proposed optimizationtechnique for reservoir computing, using an optoelectronic setup. Reservoircomputing is a robust framework for signal processing applications, and thedevelopment of efficient optimization approaches remains a key challenge. Thetechnique we address leverages solely a delayed version of the input signal toidentify the optimal operational region of the reservoir, simplifying thetraditionally time-consuming task of hyperparameter tuning. We verify theeffectiveness of this approach on different benchmark tasks and reservoiroperating conditions.</description><author>Enrico Picco, Lina Jaurigue, Kathy Lüdge, Serge Massar</author><pubDate>Thu, 25 Jan 2024 18:20:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14371v1</guid></item><item><title>A note on incorrect inferences in non-binary qualitative probabilistic networks</title><link>http://arxiv.org/abs/2208.09344v3</link><description>Qualitative probabilistic networks (QPNs) combine the conditionalindependence assumptions of Bayesian networks with the qualitative propertiesof positive and negative dependence. They formalise various intuitiveproperties of positive dependence to allow inferences over a large network ofvariables. However, we will demonstrate in this paper that, due to an incorrectsymmetry property, many inferences obtained in non-binary QPNs are notmathematically true. We will provide examples of such incorrect inferences andbriefly discuss possible resolutions.</description><author>Jack Storror Carter</author><pubDate>Thu, 25 Jan 2024 18:16:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.09344v3</guid></item><item><title>OpenPI2.0: An Improved Dataset for Entity Tracking in Texts</title><link>http://arxiv.org/abs/2305.14603v2</link><description>Much text describes a changing world (e.g., procedures, stories, newswires),and understanding them requires tracking how entities change. An earlierdataset, OpenPI, provided crowdsourced annotations of entity state changes intext. However, a major limitation was that those annotations were free-form anddid not identify salient changes, hampering model evaluation. To overcome theselimitations, we present an improved dataset, OpenPI2.0, where entities andattributes are fully canonicalized and additional entity salience annotationsare added. On our fairer evaluation setting, we find that currentstate-of-the-art language models are far from competent. We also show thatusing state changes of salient entities as a chain-of-thought prompt,downstream performance is improved on tasks such as question answering andclassical planning, outperforming the setting involving all related entitiesindiscriminately. We offer OpenPI2.0 for the continued development of modelsthat can understand the dynamics of entities in text.</description><author>Li Zhang, Hainiu Xu, Abhinav Kommula, Chris Callison-Burch, Niket Tandon</author><pubDate>Thu, 25 Jan 2024 18:15:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14603v2</guid></item><item><title>Genie: Achieving Human Parity in Content-Grounded Datasets Generation</title><link>http://arxiv.org/abs/2401.14367v1</link><description>The lack of high-quality data for content-grounded generation tasks has beenidentified as a major obstacle to advancing these tasks. To address this gap,we propose Genie, a novel method for automatically generating high-qualitycontent-grounded data. It consists of three stages: (a) Content Preparation,(b) Generation: creating task-specific examples from the content (e.g.,question-answer pairs or summaries). (c) Filtering mechanism aiming to ensurethe quality and faithfulness of the generated data. We showcase thismethodology by generating three large-scale synthetic data, making wishes, forLong-Form Question-Answering (LFQA), summarization, and information extraction.In a human evaluation, our generated data was found to be natural and of highquality. Furthermore, we compare models trained on our data with models trainedon human-written data -- ELI5 and ASQA for LFQA and CNN-DailyMail forSummarization. We show that our models are on par with or outperforming modelstrained on human-generated data and consistently outperforming them infaithfulness. Finally, we applied our method to create LFQA data within themedical domain and compared a model trained on it with models trained on otherdomains.</description><author>Asaf Yehudai, Boaz Carmeli, Yosi Mass, Ofir Arviv, Nathaniel Mills, Assaf Toledo, Eyal Shnarch, Leshem Choshen</author><pubDate>Thu, 25 Jan 2024 18:14:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14367v1</guid></item><item><title>The Typing Cure: Experiences with Large Language Model Chatbots for Mental Health Support</title><link>http://arxiv.org/abs/2401.14362v1</link><description>People experiencing severe distress increasingly use Large Language Model(LLM) chatbots as mental health support tools. Discussions on social media havedescribed how engagements were lifesaving for some, but evidence suggests thatgeneral-purpose LLM chatbots also have notable risks that could endanger thewelfare of users if not designed responsibly. In this study, we investigate thelived experiences of people who have used LLM chatbots for mental healthsupport. We build on interviews with 21 individuals from globally diversebackgrounds to analyze how users create unique support roles for theirchatbots, fill in gaps in everyday care, and navigate associated culturallimitations when seeking support from chatbots. We ground our analysis inpsychotherapy literature around effective support, and introduce the concept oftherapeutic alignment, or aligning AI with therapeutic values for mental healthcontexts. Our study offers recommendations for how designers can approach theethical and effective use of LLM chatbots and other AI mental health supporttools in mental health care.</description><author>Inhwa Song, Sachin R. Pendse, Neha Kumar, Munmun De Choudhury</author><pubDate>Thu, 25 Jan 2024 18:08:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14362v1</guid></item><item><title>MoE-Infinity: Activation-Aware Expert Offloading for Efficient MoE Serving</title><link>http://arxiv.org/abs/2401.14361v1</link><description>This paper presents MoE-Infinity, a cost-efficient mixture-of-expert (MoE)serving system that realizes activation-aware expert offloading. MoE-Infinityfeatures sequence-level expert activation tracing, a new approach adept atidentifying sparse activations and capturing the temporal locality of MoEinference. By analyzing these traces, MoE-Infinity performs novelactivation-aware expert prefetching and caching, substantially reducing thelatency overheads usually associated with offloading experts for improved costperformance. Extensive experiments in a cluster show that MoE-Infinityoutperforms numerous existing systems and approaches, reducing latency by 4 -20X and decreasing deployment costs by over 8X for various MoEs. MoE-Infinity'ssource code is publicly available at https://github.com/TorchMoE/MoE-Infinity</description><author>Leyang Xue, Yao Fu, Zhan Lu, Luo Mai, Mahesh Marina</author><pubDate>Thu, 25 Jan 2024 18:07:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14361v1</guid></item><item><title>A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis on Noisy Bengali Texts</title><link>http://arxiv.org/abs/2401.14360v1</link><description>While Bengali is considered a language with limited resources, sentimentanalysis has been a subject of extensive research in the literature.Nevertheless, there is a scarcity of exploration into sentiment analysisspecifically in the realm of noisy Bengali texts. In this paper, we introduce adataset (NC-SentNoB) that we annotated manually to identify ten different typesof noise found in a pre-existing sentiment analysis dataset comprising ofaround 15K noisy Bengali texts. At first, given an input noisy text, weidentify the noise type, addressing this as a multi-label classification task.Then, we introduce baseline noise reduction methods to alleviate noise prior toconducting sentiment analysis. Finally, we assess the performance of fine-tunedsentiment analysis models with both noisy and noise-reduced texts to makecomparisons. The experimental findings indicate that the noise reductionmethods utilized are not satisfactory, highlighting the need for more suitablenoise reduction methods in future research endeavors. We have made theimplementation and dataset presented in this paper publicly available athttps://github.com/ktoufiquee/A-Comparative-Analysis-of-Noise-Reduction-Methods-in-Sentiment-Analysis-on-Noisy-Bengali-Texts</description><author>Kazi Toufique Elahi, Tasnuva Binte Rahman, Shakil Shahriar, Samir Sarker, Md. Tanvir Rouf Shawon, G. M. Shahariar</author><pubDate>Thu, 25 Jan 2024 18:06:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14360v1</guid></item><item><title>Domain-invariant Clinical Representation Learning by Bridging Data Distribution Shift across EMR Datasets</title><link>http://arxiv.org/abs/2310.07799v2</link><description>Due to the limited information about emerging diseases, symptoms are hard tobe noticed and recognized, so that the window for clinical intervention couldbe ignored. An effective prognostic model is expected to assist doctors inmaking right diagnosis and designing personalized treatment plan, so topromptly prevent unfavorable outcomes. However, in the early stage of adisease, limited data collection and clinical experiences, plus the concern outof privacy and ethics, may result in restricted data availability forreference, to the extent that even data labels are difficult to mark correctly.In addition, Electronic Medical Record (EMR) data of different diseases or ofdifferent sources of the same disease can prove to be having seriouscross-dataset feature misalignment problems, greatly mutilating the efficiencyof deep learning models. This article introduces a domain-invariantrepresentation learning method to build a transition model from source datasetto target dataset. By way of constraining the distribution shift of featuresgenerated in disparate domains, domain-invariant features that are exclusivelyrelative to downstream tasks are captured, so to cultivate a unifieddomain-invariant encoder across various task domains to achieve better featurerepresentation. Experimental results of several target tasks demonstrate thatour proposed model outperforms competing baseline methods and has higher rateof training convergence, especially in dealing with limited data amount. Amultitude of experiences have proven the efficacy of our method to provide moreaccurate predictions concerning newly emergent pandemics and other diseases.</description><author>Zhongji Zhang, Yuhang Wang, Yinghao Zhu, Xinyu Ma, Tianlong Wang, Chaohe Zhang, Yasha Wang, Liantao Ma</author><pubDate>Thu, 25 Jan 2024 18:00:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07799v2</guid></item><item><title>Learning Robust Generalizable Radiance Field with Visibility and Feature Augmented Point Representation</title><link>http://arxiv.org/abs/2401.14354v1</link><description>This paper introduces a novel paradigm for the generalizable neural radiancefield (NeRF). Previous generic NeRF methods combine multiview stereo techniqueswith image-based neural rendering for generalization, yielding impressiveresults, while suffering from three issues. First, occlusions often result ininconsistent feature matching. Then, they deliver distortions and artifacts ingeometric discontinuities and locally sharp shapes due to their individualprocess of sampled points and rough feature aggregation. Third, theirimage-based representations experience severe degradations when source viewsare not near enough to the target view. To address challenges, we propose thefirst paradigm that constructs the generalizable neural field based onpoint-based rather than image-based rendering, which we call the Generalizableneural Point Field (GPF). Our approach explicitly models visibilities bygeometric priors and augments them with neural features. We propose a novelnonuniform log sampling strategy to improve both rendering speed andreconstruction quality. Moreover, we present a learnable kernel spatiallyaugmented with features for feature aggregations, mitigating distortions atplaces with drastically varying geometries. Besides, our representation can beeasily manipulated. Experiments show that our model can deliver bettergeometries, view consistencies, and rendering quality than all counterparts andbenchmarks on three datasets in both generalization and finetuning settings,preliminarily proving the potential of the new paradigm for generalizable NeRF.</description><author>Jiaxu Wang, Ziyi Zhang, Renjing Xu</author><pubDate>Thu, 25 Jan 2024 17:58:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14354v1</guid></item><item><title>Topic Bias in Emotion Classification</title><link>http://arxiv.org/abs/2312.09043v2</link><description>Emotion corpora are typically sampled based on keyword/hashtag search or byasking study participants to generate textual instances. In any case, thesecorpora are not uniform samples representing the entirety of a domain. Wehypothesize that this practice of data acquisition leads to unrealisticcorrelations between overrepresented topics in these corpora that harm thegeneralizability of models. Such topic bias could lead to wrong predictions forinstances like "I organized the service for my aunt's funeral." when funeralevents are over-represented for instances labeled with sadness, despite theemotion of pride being more appropriate here. In this paper, we study thistopic bias both from the data and the modeling perspective. We first label aset of emotion corpora automatically via topic modeling and show that emotionsin fact correlate with specific topics. Further, we see that emotionclassifiers are confounded by such topics. Finally, we show that theestablished debiasing method of adversarial correction via gradient reversalmitigates the issue. Our work points out issues with existing emotion corporaand that more representative resources are required for fair evaluation ofmodels predicting affective concepts from text.</description><author>Maximilian Wegge, Roman Klinger</author><pubDate>Thu, 25 Jan 2024 17:57:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09043v2</guid></item><item><title>ServerlessLLM: Locality-Enhanced Serverless Inference for Large Language Models</title><link>http://arxiv.org/abs/2401.14351v1</link><description>This paper presents ServerlessLLM, a locality-enhanced serverless inferencesystem for Large Language Models (LLMs). ServerlessLLM exploits the substantialcapacity and bandwidth of storage and memory devices available on GPU servers,thereby reducing costly remote checkpoint downloads and achieving efficientcheckpoint loading. ServerlessLLM achieves this through three maincontributions: (i) fast LLM checkpoint loading via a novel loading-optimizedcheckpoint format design, coupled with an efficient multi-tier checkpointloading system; (ii) locality-driven LLM inference with live migration, whichallows ServerlessLLM to effectively achieve locality-driven server allocationwhile preserving the low latency of ongoing LLM inference; and (iii)locality-aware server allocation, enabling ServerlessLLM to evaluate the statusof each server in a cluster and effectively schedule model startup time tocapitalize on local checkpoint placement. Our comprehensive experiments, whichinclude microbenchmarks and real-world traces, show that ServerlessLLMsurpasses state-of-the-art systems by 10 - 200X in latency performance whenrunning various LLM inference workloads.</description><author>Yao Fu, Leyang Xue, Yeqi Huang, Andrei-Octavian Brabete, Dmitrii Ustiugov, Yuvraj Patel, Luo Mai</author><pubDate>Thu, 25 Jan 2024 17:55:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14351v1</guid></item><item><title>System-Level Natural Language Feedback</title><link>http://arxiv.org/abs/2306.13588v2</link><description>Natural language (NL) feedback offers rich insights into user experience.While existing studies focus on an instance-level approach, where feedback isused to refine specific examples, we introduce a framework for system-level useof NL feedback. We show how to use feedback to formalize system-level designdecisions in a human-in-the-loop-process -- in order to produce better models.In particular this is done through: (i) metric design for tasks; and (ii)language model prompt design for refining model responses. We conduct two casestudies of this approach for improving search query and dialog responsegeneration, demonstrating the effectiveness of system-level feedback. We showthe combination of system-level and instance-level feedback brings furthergains, and that human written instance-level feedback results in more groundedrefinements than GPT-3.5 written ones, underlying the importance of humanfeedback for building systems. We release our code and data athttps://github.com/yyy-Apple/Sys-NL-Feedback.</description><author>Weizhe Yuan, Kyunghyun Cho, Jason Weston</author><pubDate>Thu, 25 Jan 2024 17:52:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13588v2</guid></item><item><title>Correlation Clustering with Active Learning of Pairwise Similarities</title><link>http://arxiv.org/abs/2302.10295v3</link><description>Correlation clustering is a well-known unsupervised learning setting thatdeals with positive and negative pairwise similarities. In this paper, we studythe case where the pairwise similarities are not given in advance and must bequeried in a cost-efficient way. Thereby, we develop a generic active learningframework for this task that benefits from several advantages, e.g.,flexibility in the type of feedback that a user/annotator can provide,adaptation to any correlation clustering algorithm and query strategy, androbustness to noise. In addition, we propose and analyze a number of novelquery strategies suited to this setting. We demonstrate the effectiveness ofour framework and the proposed query strategies via several experimentalstudies.</description><author>Linus Aronsson, Morteza Haghir Chehreghani</author><pubDate>Thu, 25 Jan 2024 17:51:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10295v3</guid></item><item><title>Convergence Rate Maximization for Split Learning-based Control of EMG Prosthetic Devices</title><link>http://arxiv.org/abs/2401.03233v2</link><description>Split Learning (SL) is a promising Distributed Learning approach inelectromyography (EMG) based prosthetic control, due to its applicabilitywithin resource-constrained environments. Other learning approaches, such asDeep Learning and Federated Learning (FL), provide suboptimal solutions, sinceprosthetic devices are extremely limited in terms of processing power andbattery life. The viability of implementing SL in such scenarios is caused byits inherent model partitioning, with clients executing the smaller modelsegment. However, selecting an inadequate cut layer hinders the trainingprocess in SL systems. This paper presents an algorithm for optimal cut layerselection in terms of maximizing the convergence rate of the model. Theperformance evaluation demonstrates that the proposed algorithm substantiallyaccelerates the convergence in an EMG pattern recognition task for improvingprosthetic device control.</description><author>Matea Marinova, Daniel Denkovski, Hristijan Gjoreski, Zoran Hadzi-Velkov, Valentin Rakovic</author><pubDate>Thu, 25 Jan 2024 17:50:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03233v2</guid></item><item><title>Learning to navigate efficiently and precisely in real environments</title><link>http://arxiv.org/abs/2401.14349v1</link><description>In the context of autonomous navigation of terrestrial robots, the creationof realistic models for agent dynamics and sensing is a widespread habit in therobotics literature and in commercial applications, where they are used formodel based control and/or for localization and mapping. The more recentEmbodied AI literature, on the other hand, focuses on modular or end-to-endagents trained in simulators like Habitat or AI-Thor, where the emphasis is puton photo-realistic rendering and scene diversity, but high-fidelity robotmotion is assigned a less privileged role. The resulting sim2real gapsignificantly impacts transfer of the trained models to real robotic platforms.In this work we explore end-to-end training of agents in simulation in settingswhich minimize the sim2real gap both, in sensing and in actuation. Our agentdirectly predicts (discretized) velocity commands, which are maintained throughclosed-loop control in the real robot. The behavior of the real robot(including the underlying low-level controller) is identified and simulated ina modified Habitat simulator. Noise models for odometry and localizationfurther contribute in lowering the sim2real gap. We evaluate on real navigationscenarios, explore different localization and point goal calculation methodsand report significant gains in performance and robustness compared to priorwork.</description><author>Guillaume Bono, Hervé Poirier, Leonid Antsfeld, Gianluca Monaci, Boris Chidlovskii, Christian Wolf</author><pubDate>Thu, 25 Jan 2024 17:50:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14349v1</guid></item><item><title>TrustLLM: Trustworthiness in Large Language Models</title><link>http://arxiv.org/abs/2401.05561v3</link><description>Large language models (LLMs), exemplified by ChatGPT, have gainedconsiderable attention for their excellent natural language processingcapabilities. Nonetheless, these LLMs present many challenges, particularly inthe realm of trustworthiness. Therefore, ensuring the trustworthiness of LLMsemerges as an important topic. This paper introduces TrustLLM, a comprehensivestudy of trustworthiness in LLMs, including principles for different dimensionsof trustworthiness, established benchmark, evaluation, and analysis oftrustworthiness for mainstream LLMs, and discussion of open challenges andfuture directions. Specifically, we first propose a set of principles fortrustworthy LLMs that span eight different dimensions. Based on theseprinciples, we further establish a benchmark across six dimensions includingtruthfulness, safety, fairness, robustness, privacy, and machine ethics. Wethen present a study evaluating 16 mainstream LLMs in TrustLLM, consisting ofover 30 datasets. Our findings firstly show that in general trustworthiness andutility (i.e., functional effectiveness) are positively related. Secondly, ourobservations reveal that proprietary LLMs generally outperform most open-sourcecounterparts in terms of trustworthiness, raising concerns about the potentialrisks of widely accessible open-source LLMs. However, a few open-source LLMscome very close to proprietary ones. Thirdly, it is important to note that someLLMs may be overly calibrated towards exhibiting trustworthiness, to the extentthat they compromise their utility by mistakenly treating benign prompts asharmful and consequently not responding. Finally, we emphasize the importanceof ensuring transparency not only in the models themselves but also in thetechnologies that underpin trustworthiness. Knowing the specific trustworthytechnologies that have been employed is crucial for analyzing theireffectiveness.</description><author>Lichao Sun, Yue Huang, Haoran Wang, Siyuan Wu, Qihui Zhang, Chujie Gao, Yixin Huang, Wenhan Lyu, Yixuan Zhang, Xiner Li, Zhengliang Liu, Yixin Liu, Yijue Wang, Zhikun Zhang, Bhavya Kailkhura, Caiming Xiong, Chaowei Xiao, Chunyuan Li, Eric Xing, Furong Huang, Hao Liu, Heng Ji, Hongyi Wang, Huan Zhang, Huaxiu Yao, Manolis Kellis, Marinka Zitnik, Meng Jiang, Mohit Bansal, James Zou, Jian Pei, Jian Liu, Jianfeng Gao, Jiawei Han, Jieyu Zhao, Jiliang Tang, Jindong Wang, John Mitchell, Kai Shu, Kaidi Xu, Kai-Wei Chang, Lifang He, Lifu Huang, Michael Backes, Neil Zhenqiang Gong, Philip S. Yu, Pin-Yu Chen, Quanquan Gu, Ran Xu, Rex Ying, Shuiwang Ji, Suman Jana, Tianlong Chen, Tianming Liu, Tianyi Zhou, William Wang, Xiang Li, Xiangliang Zhang, Xiao Wang, Xing Xie, Xun Chen, Xuyu Wang, Yan Liu, Yanf</author><pubDate>Thu, 25 Jan 2024 17:49:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05561v3</guid></item><item><title>Class-attribute Priors: Adapting Optimization to Heterogeneity and Fairness Objective</title><link>http://arxiv.org/abs/2401.14343v1</link><description>Modern classification problems exhibit heterogeneities across individualclasses: Each class may have unique attributes, such as sample size, labelquality, or predictability (easy vs difficult), and variable importance attest-time. Without care, these heterogeneities impede the learning process,most notably, when optimizing fairness objectives. Confirming this, under agaussian mixture setting, we show that the optimal SVM classifier for balancedaccuracy needs to be adaptive to the class attributes. This motivates us topropose CAP: An effective and general method that generates a class-specificlearning strategy (e.g. hyperparameter) based on the attributes of that class.This way, optimization process better adapts to heterogeneities. CAP leads tosubstantial improvements over the naive approach of assigning separatehyperparameters to each class. We instantiate CAP for loss function design andpost-hoc logit adjustment, with emphasis on label-imbalanced problems. We showthat CAP is competitive with prior art and its flexibility unlocks clearbenefits for fairness objectives beyond balanced accuracy. Finally, we evaluateCAP on problems with label noise as well as weighted test objectives toshowcase how CAP can jointly adapt to different heterogeneities.</description><author>Xuechen Zhang, Mingchen Li, Jiasi Chen, Christos Thrampoulidis, Samet Oymak</author><pubDate>Thu, 25 Jan 2024 17:43:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14343v1</guid></item><item><title>Estimation of partially known Gaussian graphical models with score-based structural priors</title><link>http://arxiv.org/abs/2401.14340v1</link><description>We propose a novel algorithm for the support estimation of partially knownGaussian graphical models that incorporates prior information about theunderlying graph. In contrast to classical approaches that provide a pointestimate based on a maximum likelihood or a maximum a posteriori criterionusing (simple) priors on the precision matrix, we consider a prior on the graphand rely on annealed Langevin diffusion to generate samples from the posteriordistribution. Since the Langevin sampler requires access to the score functionof the underlying graph prior, we use graph neural networks to effectivelyestimate the score from a graph dataset (either available beforehand orgenerated from a known distribution). Numerical experiments demonstrate thebenefits of our approach.</description><author>Martín Sevilla, Antonio García Marques, Santiago Segarra</author><pubDate>Thu, 25 Jan 2024 17:39:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14340v1</guid></item><item><title>Mitigating Label Noise through Data Ambiguation</title><link>http://arxiv.org/abs/2305.13764v2</link><description>Label noise poses an important challenge in machine learning, especially indeep learning, in which large models with high expressive power dominate thefield. Models of that kind are prone to memorizing incorrect labels, therebyharming generalization performance. Many methods have been proposed to addressthis problem, including robust loss functions and more complex label correctionapproaches. Robust loss functions are appealing due to their simplicity, buttypically lack flexibility, while label correction usually adds substantialcomplexity to the training setup. In this paper, we suggest to address theshortcomings of both methodologies by "ambiguating" the target information,adding additional, complementary candidate labels in case the learner is notsufficiently convinced of the observed training label. More precisely, weleverage the framework of so-called superset learning to construct set-valuedtargets based on a confidence threshold, which deliver imprecise yet morereliable beliefs about the ground-truth, effectively helping the learner tosuppress the memorization effect. In an extensive empirical evaluation, ourmethod demonstrates favorable learning behavior on synthetic and real-worldnoise, confirming the effectiveness in detecting and correcting erroneoustraining labels.</description><author>Julian Lienen, Eyke Hüllermeier</author><pubDate>Thu, 25 Jan 2024 17:39:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13764v2</guid></item><item><title>AI in Supply Chain Risk Assessment: A Systematic Literature Review and Bibliometric Analysis</title><link>http://arxiv.org/abs/2401.10895v2</link><description>Supply chain risk assessment (SCRA) has witnessed a profound evolutionthrough the integration of artificial intelligence (AI) and machine learning(ML) techniques, revolutionizing predictive capabilities and risk mitigationstrategies. The significance of this evolution stems from the critical role ofrobust risk management strategies in ensuring operational resilience andcontinuity within modern supply chains. Previous reviews have outlinedestablished methodologies but have overlooked emerging AI/ML techniques,leaving a notable research gap in understanding their practical implicationswithin SCRA. This paper conducts a systematic literature review combined with acomprehensive bibliometric analysis. We meticulously examined 1,717 papers andderived key insights from a select group of 48 articles published between 2014and 2023. The review fills this research gap by addressing pivotal researchquestions, and exploring existing AI/ML techniques, methodologies, findings,and future trajectories, thereby providing a more encompassing view of theevolving landscape of SCRA. Our study unveils the transformative impact ofAI/ML models, such as Random Forest, XGBoost, and hybrids, in substantiallyenhancing precision within SCRA. It underscores adaptable post-COVIDstrategies, advocating for resilient contingency plans and aligning withevolving risk landscapes. Significantly, this review surpasses previousexaminations by accentuating emerging AI/ML techniques and their practicalimplications within SCRA. Furthermore, it highlights the contributions througha comprehensive bibliometric analysis, revealing publication trends,influential authors, and highly cited articles.</description><author>Md Abrar Jahin, Saleh Akram Naife, Anik Kumar Saha, M. F. Mridha</author><pubDate>Thu, 25 Jan 2024 17:38:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10895v2</guid></item><item><title>ProteusNeRF: Fast Lightweight NeRF Editing using 3D-Aware Image Context</title><link>http://arxiv.org/abs/2310.09965v2</link><description>Neural Radiance Fields (NeRFs) have recently emerged as a popular option forphoto-realistic object capture due to their ability to faithfully capturehigh-fidelity volumetric content even from handheld video input. Although muchresearch has been devoted to efficient optimization leading to real-timetraining and rendering, options for interactive editing NeRFs remain limited.We present a very simple but effective neural network architecture that is fastand efficient while maintaining a low memory footprint. This architecture canbe incrementally guided through user-friendly image-based edits. Ourrepresentation allows straightforward object selection via semantic featuredistillation at the training stage. More importantly, we propose a local3D-aware image context to facilitate view-consistent image editing that canthen be distilled into fine-tuned NeRFs, via geometric and appearanceadjustments. We evaluate our setup on a variety of examples to demonstrateappearance and geometric edits and report 10-30x speedup over concurrent workfocusing on text-guided NeRF editing. Video results can be seen on our projectwebpage at https://proteusnerf.github.io.</description><author>Binglun Wang, Niladri Shekhar Dutt, Niloy J. Mitra</author><pubDate>Thu, 25 Jan 2024 17:37:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09965v2</guid></item><item><title>Progressive Multi-task Anti-Noise Learning and Distilling Frameworks for Fine-grained Vehicle Recognition</title><link>http://arxiv.org/abs/2401.14336v1</link><description>Fine-grained vehicle recognition (FGVR) is an essential fundamentaltechnology for intelligent transportation systems, but very difficult becauseof its inherent intra-class variation. Most previous FGVR studies only focus onthe intra-class variation caused by different shooting angles, positions, etc.,while the intra-class variation caused by image noise has received littleattention. This paper proposes a progressive multi-task anti-noise learning(PMAL) framework and a progressive multi-task distilling (PMD) framework tosolve the intra-class variation problem in FGVR due to image noise. The PMALframework achieves high recognition accuracy by treating image denoising as anadditional task in image recognition and progressively forcing a model to learnnoise invariance. The PMD framework transfers the knowledge of the PMAL-trainedmodel into the original backbone network, which produces a model with about thesame recognition accuracy as the PMAL-trained model, but without any additionaloverheads over the original backbone network. Combining the two frameworks, weobtain models that significantly exceed previous state-of-the-art methods inrecognition accuracy on two widely-used, standard FGVR datasets, namelyStanford Cars, and CompCars, as well as three additional surveillanceimage-based vehicle-type classification datasets, namely Beijing Institute ofTechnology (BIT)-Vehicle, Vehicle Type Image Data 2 (VTID2), and Vehicle ImagesDataset for Make Model Recognition (VIDMMR), without any additional overheadsover the original backbone networks. The source code is available athttps://github.com/Dichao-Liu/Anti-noise_FGVR</description><author>Dichao Liu</author><pubDate>Thu, 25 Jan 2024 17:34:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14336v1</guid></item><item><title>SunBlock: Cloudless Protection for IoT Systems</title><link>http://arxiv.org/abs/2401.14332v1</link><description>With an increasing number of Internet of Things (IoT) devices present inhomes, there is a rise in the number of potential information leakage channelsand their associated security threats and privacy risks. Despite a long historyof attacks on IoT devices in unprotected home networks, the problem ofaccurate, rapid detection and prevention of such attacks remains open. Manyexisting IoT protection solutions are cloud-based, sometimes ineffective, andmight share consumer data with unknown third parties. This paper investigatesthe potential for effective IoT threat detection locally, on a home router,using AI tools combined with classic rule-based traffic-filtering algorithms.Our results show that with a slight rise of router hardware resources caused bymachine learning and traffic filtering logic, a typical home routerinstrumented with our solution is able to effectively detect risks and protecta typical home IoT network, equaling or outperforming existing popularsolutions, without any effects on benign IoT functionality, and without relyingon cloud services and third parties.</description><author>Vadim Safronov, Anna Maria Mandalari, Daniel J. Dubois, David Choffnes, Hamed Haddadi</author><pubDate>Thu, 25 Jan 2024 17:30:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14332v1</guid></item><item><title>TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for Lazy Clients</title><link>http://arxiv.org/abs/2401.12012v2</link><description>Federated learning is a distributed collaborative machine learning paradigmthat has gained strong momentum in recent years. In federated learning, acentral server periodically coordinates models with clients and aggregates themodels trained locally by clients without necessitating access to local data.Despite its potential, the implementation of federated learning continues toencounter several challenges, predominantly the slow convergence that islargely due to data heterogeneity. The slow convergence becomes particularlyproblematic in cross-device federated learning scenarios where clients may bestrongly limited by computing power and storage space, and hence counteractingmethods that induce additional computation or memory cost on the client sidesuch as auxiliary objective terms and larger training iterations can beimpractical. In this paper, we propose a novel federated aggregation strategy,TurboSVM-FL, that poses no additional computation burden on the client side andcan significantly accelerate convergence for federated classification task,especially when clients are "lazy" and train their models solely for few epochsfor next global aggregation. TurboSVM-FL extensively utilizes support vectormachine to conduct selective aggregation and max-margin spread-outregularization on class embeddings. We evaluate TurboSVM-FL on multipledatasets including FEMNIST, CelebA, and Shakespeare using user-independentvalidation with non-iid data distribution. Our results show that TurboSVM-FLcan significantly outperform existing popular algorithms on convergence rateand reduce communication rounds while delivering better test metrics includingaccuracy, F1 score, and MCC.</description><author>Mengdi Wang, Anna Bodonhelyi, Efe Bozkir, Enkelejda Kasneci</author><pubDate>Thu, 25 Jan 2024 17:27:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12012v2</guid></item><item><title>Neural Processing of Tri-Plane Hybrid Neural Fields</title><link>http://arxiv.org/abs/2310.01140v2</link><description>Driven by the appealing properties of neural fields for storing andcommunicating 3D data, the problem of directly processing them to address taskssuch as classification and part segmentation has emerged and has beeninvestigated in recent works. Early approaches employ neural fieldsparameterized by shared networks trained on the whole dataset, achieving goodtask performance but sacrificing reconstruction quality. To improve the latter,later methods focus on individual neural fields parameterized as largeMulti-Layer Perceptrons (MLPs), which are, however, challenging to process dueto the high dimensionality of the weight space, intrinsic weight spacesymmetries, and sensitivity to random initialization. Hence, results turn outsignificantly inferior to those achieved by processing explicitrepresentations, e.g., point clouds or meshes. In the meantime, hybridrepresentations, in particular based on tri-planes, have emerged as a moreeffective and efficient alternative to realize neural fields, but their directprocessing has not been investigated yet. In this paper, we show that thetri-plane discrete data structure encodes rich information, which can beeffectively processed by standard deep-learning machinery. We define anextensive benchmark covering a diverse set of fields such as occupancy,signed/unsigned distance, and, for the first time, radiance fields. Whileprocessing a field with the same reconstruction quality, we achieve taskperformance far superior to frameworks that process large MLPs and, for thefirst time, almost on par with architectures handling explicit representations.</description><author>Adriano Cardace, Pierluigi Zama Ramirez, Francesco Ballerini, Allan Zhou, Samuele Salti, Luigi Di Stefano</author><pubDate>Thu, 25 Jan 2024 17:25:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01140v2</guid></item><item><title>SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation</title><link>http://arxiv.org/abs/2401.13527v2</link><description>Benefiting from effective speech modeling, current Speech Large LanguageModels (SLLMs) have demonstrated exceptional capabilities in in-context speechgeneration and efficient generalization to unseen speakers. However, theprevailing information modeling process is encumbered by certain redundancies,leading to inefficiencies in speech generation. We propose Chain-of-InformationGeneration (CoIG), a method for decoupling semantic and perceptual informationin large-scale speech generation. Building on this, we develop SpeechGPT-Gen,an 8-billion-parameter SLLM efficient in semantic and perceptual informationmodeling. It comprises an autoregressive model based on LLM for semanticinformation modeling and a non-autoregressive model employing flow matching forperceptual information modeling. Additionally, we introduce the novel approachof infusing semantic information into the prior distribution to enhance theefficiency of flow matching. Extensive experimental results demonstrate thatSpeechGPT-Gen markedly excels in zero-shot text-to-speech, zero-shot voiceconversion, and speech-to-speech dialogue, underscoring CoIG's remarkableproficiency in capturing and modeling speech's semantic and perceptualdimensions. Code and models are available athttps://github.com/0nutation/SpeechGPT.</description><author>Dong Zhang, Xin Zhang, Jun Zhan, Shimin Li, Yaqian Zhou, Xipeng Qiu</author><pubDate>Thu, 25 Jan 2024 17:24:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13527v2</guid></item><item><title>Unlocking Past Information: Temporal Embeddings in Cooperative Bird's Eye View Prediction</title><link>http://arxiv.org/abs/2401.14325v1</link><description>Accurate and comprehensive semantic segmentation of Bird's Eye View (BEV) isessential for ensuring safe and proactive navigation in autonomous driving.Although cooperative perception has exceeded the detection capabilities ofsingle-agent systems, prevalent camera-based algorithms in cooperativeperception neglect valuable information derived from historical observations.This limitation becomes critical during sensor failures or communication issuesas cooperative perception reverts to single-agent perception, leading todegraded performance and incomplete BEV segmentation maps. This paperintroduces TempCoBEV, a temporal module designed to incorporate historical cuesinto current observations, thereby improving the quality and reliability of BEVmap segmentations. We propose an importance-guided attention architecture toeffectively integrate temporal information that prioritizes relevant propertiesfor BEV map segmentation. TempCoBEV is an independent temporal module thatseamlessly integrates into state-of-the-art camera-based cooperative perceptionmodels. We demonstrate through extensive experiments on the OPV2V dataset thatTempCoBEV performs better than non-temporal models in predicting current andfuture BEV map segmentations, particularly in scenarios involving communicationfailures. We show the efficacy of TempCoBEV and its capability to integratehistorical cues into the current BEV map, improving predictions under optimalcommunication conditions by up to 2% and under communication failures by up to19%. The code will be published on GitHub.</description><author>Dominik Rößle, Jeremias Gerner, Klaus Bogenberger, Daniel Cremers, Stefanie Schmidtner, Torsten Schön</author><pubDate>Thu, 25 Jan 2024 17:21:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14325v1</guid></item><item><title>Generalized People Diversity: Learning a Human Perception-Aligned Diversity Representation for People Images</title><link>http://arxiv.org/abs/2401.14322v1</link><description>Capturing the diversity of people in images is challenging: recent literaturetends to focus on diversifying one or two attributes, requiring expensiveattribute labels or building classifiers. We introduce a diverse people imageranking method which more flexibly aligns with human notions of peoplediversity in a less prescriptive, label-free manner. The Perception-AlignedText-derived Human representation Space (PATHS) aims to capture all or manyrelevant features of people-related diversity, and, when used as therepresentation space in the standard Maximal Marginal Relevance (MMR) rankingalgorithm, is better able to surface a range of types of people-relateddiversity (e.g. disability, cultural attire). PATHS is created in two stages.First, a text-guided approach is used to extract a person-diversityrepresentation from a pre-trained image-text model. Then this representation isfine-tuned on perception judgments from human annotators so that it capturesthe aspects of people-related similarity that humans find most salient.Empirical results show that the PATHS method achieves diversity better thanbaseline methods, according to side-by-side ratings from human annotators.</description><author>Hansa Srinivasan, Candice Schumann, Aradhana Sinha, David Madras, Gbolahan Oluwafemi Olanubi, Alex Beutel, Susanna Ricco, Jilin Chen</author><pubDate>Thu, 25 Jan 2024 17:19:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14322v1</guid></item><item><title>Multi-Objective Optimization for Sparse Deep Multi-Task Learning</title><link>http://arxiv.org/abs/2308.12243v3</link><description>Different conflicting optimization criteria arise naturally in various DeepLearning scenarios. These can address different main tasks (i.e., in thesetting of Multi-Task Learning), but also main and secondary tasks such as lossminimization versus sparsity. The usual approach is a simple weighting of thecriteria, which formally only works in the convex setting. In this paper, wepresent a Multi-Objective Optimization algorithm using a modified WeightedChebyshev scalarization for training Deep Neural Networks (DNNs) with respectto several tasks. By employing this scalarization technique, the algorithm canidentify all optimal solutions of the original problem while reducing itscomplexity to a sequence of single-objective problems. The simplified problemsare then solved using an Augmented Lagrangian method, enabling the use ofpopular optimization techniques such as Adam and Stochastic Gradient Descent,while efficaciously handling constraints. Our work aims to address the(economical and also ecological) sustainability issue of DNN models, with aparticular focus on Deep Multi-Task models, which are typically designed with avery large number of weights to perform equally well on multiple tasks. Throughexperiments conducted on two Machine Learning datasets, we demonstrate thepossibility of adaptively sparsifying the model during training withoutsignificantly impacting its performance, if we are willing to applytask-specific adaptations to the network weights. The code is available athttps://github.com/salomonhotegni/MDMTN</description><author>S. S. Hotegni, M. Berkemeier, S. Peitz</author><pubDate>Thu, 25 Jan 2024 17:15:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12243v3</guid></item><item><title>PRISM: Leveraging Prototype Patient Representations with Feature-Missing-Aware Calibration for EHR Data Sparsity Mitigation</title><link>http://arxiv.org/abs/2309.04160v3</link><description>Electronic Health Record (EHR) data, while rich in information, often suffersfrom sparsity, posing significant challenges in predictive modeling.Traditional imputation methods inadequately distinguish between real andimputed data, leading to potential inaccuracies in models. Addressing this, weintroduce PRISM, a novel approach that indirectly imputes data throughprototype representations of similar patients, thus ensuring denser and moreaccurate embeddings. PRISM innovates further with a feature confidence learnermodule, which evaluates the reliability of each feature in light of missingdata. Additionally, it incorporates a novel patient similarity metric thataccounts for feature confidence, avoiding overreliance on imprecise imputedvalues. Our extensive experiments on the MIMIC-III and MIMIC-IV datasetsdemonstrate PRISM's superior performance in predicting in-hospital mortalityand 30-day readmission tasks, showcasing its effectiveness in handling EHR datasparsity. For the sake of reproducibility and further research, we have madethe code publicly available at https://github.com/yhzhu99/PRISM.</description><author>Yinghao Zhu, Zixiang Wang, Long He, Shiyun Xie, Liantao Ma, Chengwei Pan</author><pubDate>Thu, 25 Jan 2024 17:14:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04160v3</guid></item><item><title>SymTC: A Symbiotic Transformer-CNN Net for Instance Segmentation of Lumbar Spine MRI</title><link>http://arxiv.org/abs/2401.09627v2</link><description>Intervertebral disc disease, a prevalent ailment, frequently leads tointermittent or persistent low back pain, and diagnosing and assessing of thisdisease rely on accurate measurement of vertebral bone and intervertebral discgeometries from lumbar MR images. Deep neural network (DNN) models may assistclinicians with more efficient image segmentation of individual instances(disks and vertebrae) of the lumbar spine in an automated way, which is termedas instance image segmentation. In this work, we proposed SymTC, an innovativelumbar spine MR image segmentation model that combines the strengths ofTransformer and Convolutional Neural Network (CNN). Specifically, we designed aparallel dual-path architecture to merge CNN layers and Transformer layers, andwe integrated a novel position embedding into the self-attention module ofTransformer, enhancing the utilization of positional information for moreaccurate segmentation. To further improves model performance, we introduced anew data augmentation technique to create synthetic yet realistic MR imagedataset, named SSMSpine, which is made publicly available. We evaluated ourSymTC and the other 15 existing image segmentation models on our privatein-house dataset and the public SSMSpine dataset, using two metrics, DiceSimilarity Coefficient and 95% Hausdorff Distance. The results show that ourSymTC has the best performance for segmenting vertebral bones andintervertebral discs in lumbar spine MR images. The SymTC code and SSMSpinedataset are available at https://github.com/jiasongchen/SymTC.</description><author>Jiasong Chen, Linchen Qian, Linhai Ma, Timur Urakov, Weiyong Gu, Liang Liang</author><pubDate>Thu, 25 Jan 2024 17:09:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09627v2</guid></item><item><title>Adapting Segment Anything Model for Change Detection in HR Remote Sensing Images</title><link>http://arxiv.org/abs/2309.01429v4</link><description>Vision Foundation Models (VFMs) such as the Segment Anything Model (SAM)allow zero-shot or interactive segmentation of visual contents, thus they arequickly applied in a variety of visual scenes. However, their direct use inmany Remote Sensing (RS) applications is often unsatisfactory due to thespecial imaging characteristics of RS images. In this work, we aim to utilizethe strong visual recognition capabilities of VFMs to improve the changedetection of high-resolution Remote Sensing Images (RSIs). We employ the visualencoder of FastSAM, an efficient variant of the SAM, to extract visualrepresentations in RS scenes. To adapt FastSAM to focus on some specific groundobjects in the RS scenes, we propose a convolutional adaptor to aggregate thetask-oriented change information. Moreover, to utilize the semanticrepresentations that are inherent to SAM features, we introduce a task-agnosticsemantic learning branch to model the semantic latent in bi-temporal RSIs. Theresulting method, SAMCD, obtains superior accuracy compared to the SOTA methodsand exhibits a sample-efficient learning ability that is comparable tosemi-supervised CD methods. To the best of our knowledge, this is the firstwork that adapts VFMs for the CD of HR RSIs.</description><author>Lei Ding, Kun Zhu, Daifeng Peng, Hao Tang, Kuiwu Yang, Lorenzo Bruzzone</author><pubDate>Thu, 25 Jan 2024 17:02:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01429v4</guid></item><item><title>HyperSound: Generating Implicit Neural Representations of Audio Signals with Hypernetworks</title><link>http://arxiv.org/abs/2211.01839v2</link><description>Implicit neural representations (INRs) are a rapidly growing research field,which provides alternative ways to represent multimedia signals. Recentapplications of INRs include image super-resolution, compression ofhigh-dimensional signals, or 3D rendering. However, these solutions usuallyfocus on visual data, and adapting them to the audio domain is not trivial.Moreover, it requires a separately trained model for every data sample. Toaddress this limitation, we propose HyperSound, a meta-learning methodleveraging hypernetworks to produce INRs for audio signals unseen at trainingtime. We show that our approach can reconstruct sound waves with qualitycomparable to other state-of-the-art models.</description><author>Filip Szatkowski, Karol J. Piczak, Przemysław Spurek, Jacek Tabor, Tomasz Trzciński</author><pubDate>Thu, 25 Jan 2024 16:49:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.01839v2</guid></item><item><title>Efficient Visual Computing with Camera RAW Snapshots</title><link>http://arxiv.org/abs/2212.07778v2</link><description>Conventional cameras capture image irradiance on a sensor and convert it toRGB images using an image signal processor (ISP). The images can then be usedfor photography or visual computing tasks in a variety of applications, such aspublic safety surveillance and autonomous driving. One can argue that since RAWimages contain all the captured information, the conversion of RAW to RGB usingan ISP is not necessary for visual computing. In this paper, we propose a novel$\rho$-Vision framework to perform high-level semantic understanding andlow-level compression using RAW images without the ISP subsystem used fordecades. Considering the scarcity of available RAW image datasets, we firstdevelop an unpaired CycleR2R network based on unsupervised CycleGAN to trainmodular unrolled ISP and inverse ISP (invISP) models using unpaired RAW and RGBimages. We can then flexibly generate simulated RAW images (simRAW) using anyexisting RGB image dataset and finetune different models originally trained forthe RGB domain to process real-world camera RAW images. We demonstrate objectdetection and image compression capabilities in RAW-domain using RAW-domainYOLOv3 and RAW image compressor (RIC) on snapshots from various cameras.Quantitative results reveal that RAW-domain task inference provides betterdetection accuracy and compression compared to RGB-domain processing.Furthermore, the proposed \r{ho}-Vision generalizes across various camerasensors and different task-specific models. Additional advantages of theproposed $\rho$-Vision that eliminates the ISP are the potential reductions incomputations and processing times.</description><author>Zhihao Li, Ming Lu, Xu Zhang, Xin Feng, M. Salman Asif, Zhan Ma</author><pubDate>Thu, 25 Jan 2024 16:47:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.07778v2</guid></item><item><title>Finetuning Foundation Models for Joint Analysis Optimization</title><link>http://arxiv.org/abs/2401.13536v2</link><description>In this work we demonstrate that significant gains in performance and dataefficiency can be achieved in High Energy Physics (HEP) by moving beyond thestandard paradigm of sequential optimization or reconstruction and analysiscomponents. We conceptually connect HEP reconstruction and analysis to modernmachine learning workflows such as pretraining, finetuning, domain adaptationand high-dimensional embedding spaces and quantify the gains in the exampleusecase of searches of heavy resonances decaying via an intermediate di-Higgssystem to four $b$-jets.</description><author>Matthias Vigl, Nicole Hartman, Lukas Heinrich</author><pubDate>Thu, 25 Jan 2024 16:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13536v2</guid></item><item><title>Masked Particle Modeling on Sets: Towards Self-Supervised High Energy Physics Foundation Models</title><link>http://arxiv.org/abs/2401.13537v2</link><description>We propose masked particle modeling (MPM) as a self-supervised method forlearning generic, transferable, and reusable representations on unordered setsof inputs for use in high energy physics (HEP) scientific data. This workprovides a novel scheme to perform masked modeling based pre-training to learnpermutation invariant functions on sets. More generally, this work provides astep towards building large foundation models for HEP that can be genericallypre-trained with self-supervised learning and later fine-tuned for a variety ofdown-stream tasks. In MPM, particles in a set are masked and the trainingobjective is to recover their identity, as defined by a discretized tokenrepresentation of a pre-trained vector quantized variational autoencoder. Westudy the efficacy of the method in samples of high energy jets at colliderphysics experiments, including studies on the impact of discretization,permutation invariance, and ordering. We also study the fine-tuning capabilityof the model, showing that it can be adapted to tasks such as supervised andweakly supervised jet classification, and that the model can transferefficiently with small fine-tuning data sets to new classes and new datadomains.</description><author>Lukas Heinrich, Tobias Golling, Michael Kagan, Samuel Klein, Matthew Leigh, Margarita Osadchy, John Andrew Raine</author><pubDate>Thu, 25 Jan 2024 16:44:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13537v2</guid></item><item><title>"All of Me": Mining Users' Attributes from their Public Spotify Playlists</title><link>http://arxiv.org/abs/2401.14296v1</link><description>In the age of digital music streaming, playlists on platforms like Spotifyhave become an integral part of individuals' musical experiences. People createand publicly share their own playlists to express their musical tastes, promotethe discovery of their favorite artists, and foster social connections. Thesepublicly accessible playlists transcend the boundaries of mere musicalpreferences: they serve as sources of rich insights into users' attributes andidentities. For example, the musical preferences of elderly individuals maylean more towards Frank Sinatra, while Billie Eilish remains a favored choiceamong teenagers. These playlists thus become windows into the diverse andevolving facets of one's musical identity. In this work, we investigate the relationship between Spotify users'attributes and their public playlists. In particular, we focus on identifyingrecurring musical characteristics associated with users' individual attributes,such as demographics, habits, or personality traits. To this end, we conductedan online survey involving 739 Spotify users, yielding a dataset of 10,286publicly shared playlists encompassing over 200,000 unique songs and 55,000artists. Through extensive statistical analyses, we first assess a deepconnection between a user's Spotify playlists and their real-life attributes.For instance, we found individuals high in openness often create playlistsfeaturing a diverse array of artists, while female users prefer Pop and K-popmusic genres. Building upon these observed associations, we create accuratepredictive models for users' attributes, presenting a novel DeepSet applicationthat outperforms baselines in most of these users' attributes.</description><author>Pier Paolo Tricomi, Luca Pajola, Luca Pasa, Mauro Conti</author><pubDate>Thu, 25 Jan 2024 16:38:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14296v1</guid></item><item><title>A Strong and Simple Deep Learning Baseline for BCI MI Decoding</title><link>http://arxiv.org/abs/2309.07159v2</link><description>We propose EEG-SimpleConv, a straightforward 1D convolutional neural networkfor Motor Imagery decoding in BCI. Our main motivation is to propose a simpleand performing baseline to compare to, using only very standard ingredientsfrom the literature. We evaluate its performance on four EEG Motor Imagerydatasets, including simulated online setups, and compare it to recent DeepLearning and Machine Learning approaches. EEG-SimpleConv is at least as good orfar more efficient than other approaches, showing strong knowledge-transfercapabilities across subjects, at the cost of a low inference time. We advocatethat using off-the-shelf ingredients rather than coming with ad-hoc solutionscan significantly help the adoption of Deep Learning approaches for BCI. Wemake the code of the models and the experiments accessible.</description><author>Yassine El Ouahidi, Vincent Gripon, Bastien Pasdeloup, Ghaith Bouallegue, Nicolas Farrugia, Giulia Lioi</author><pubDate>Thu, 25 Jan 2024 16:35:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.07159v2</guid></item><item><title>Shabari: Delayed Decision-Making for Faster and Efficient Serverless Functions</title><link>http://arxiv.org/abs/2401.08859v2</link><description>Serverless computing relieves developers from the burden of resourcemanagement, thus providing ease-of-use to the users and the opportunity tooptimize resource utilization for the providers. However, today's serverlesssystems lack performance guarantees for function invocations, thus limitingsupport for performance-critical applications: we observed severe performancevariability (up to 6x). Providers lack visibility into user functions and hencefind it challenging to right-size them: we observed heavy resourceunderutilization (up to 80%). To understand the causes behind the performancevariability and underutilization, we conducted a measurement study of commonlydeployed serverless functions and learned that the function performance andresource utilization depend crucially on function semantics and inputs. Our keyinsight is to delay making resource allocation decisions until after thefunction inputs are available. We introduce Shabari, a resource managementframework for serverless systems that makes decisions as late as possible toright-size each invocation to meet functions' performance objectives (SLOs) andimprove resource utilization. Shabari uses an online learning agent toright-size each function invocation based on the features of the function inputand makes cold-start-aware scheduling decisions. For a range of serverlessfunctions and inputs, Shabari reduces SLO violations by 11-73% while notwasting any vCPUs and reducing wasted memory by 64-94% in the median case,compared to state-of-the-art systems, including Aquatope, Parrotfish, andCypress.</description><author>Prasoon Sinha, Kostis Kaffes, Neeraja J. Yadwadkar</author><pubDate>Thu, 25 Jan 2024 16:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08859v2</guid></item><item><title>Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts</title><link>http://arxiv.org/abs/2401.14295v1</link><description>The field of natural language processing (NLP) has witnessed significantprogress in recent years, with a notable focus on improving large languagemodels' (LLM) performance through innovative prompting techniques. Among these,prompt engineering coupled with structures has emerged as a promising paradigm,with designs such as Chain-of-Thought, Tree of Thoughts, or Graph of Thoughts,in which the overall LLM reasoning is guided by a structure such as a graph. Asillustrated with numerous examples, this paradigm significantly enhances theLLM's capability to solve numerous tasks, ranging from logical or mathematicalreasoning to planning or creative writing. To facilitate the understanding ofthis growing field and pave the way for future developments, we devise ageneral blueprint for effective and efficient LLM reasoning schemes. For this,we conduct an in-depth analysis of the prompt execution pipeline, clarifyingand clearly defining different concepts. We then build the first taxonomy ofstructure-enhanced LLM reasoning schemes. We focus on identifying fundamentalclasses of harnessed structures, and we analyze the representations of thesestructures, algorithms executed with these structures, and many others. Werefer to these structures as reasoning topologies, because their representationbecomes to a degree spatial, as they are contained within the LLM context. Ourstudy compares existing prompting schemes using the proposed taxonomy,discussing how certain design choices lead to different patterns in performanceand cost. We also outline theoretical underpinnings, relationships betweenprompting and others parts of the LLM ecosystem such as knowledge bases, andthe associated research challenges. Our work will help to advance future promptengineering techniques.</description><author>Maciej Besta, Florim Memedi, Zhenyu Zhang, Robert Gerstenberger, Nils Blach, Piotr Nyczyk, Marcin Copik, Grzegorz Kwaśniewski, Jürgen Müller, Lukas Gianinazzi, Ales Kubicek, Hubert Niewiadomski, Onur Mutlu, Torsten Hoefler</author><pubDate>Thu, 25 Jan 2024 16:34:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14295v1</guid></item><item><title>AST-2: Single and bi-layered 2-D acoustic soft tactile skin</title><link>http://arxiv.org/abs/2401.14292v1</link><description>This paper aims to present an innovative and cost-effective design forAcoustic Soft Tactile (AST) Skin, with the primary goal of significantlyenhancing the accuracy of 2-D tactile feature estimation. The existingchallenge lies in achieving precise tactile feature estimation, especiallyconcerning contact geometry characteristics, using cost-effective solutions. Wehypothesise that by harnessing acoustic energy through dedicated acousticchannels in 2 layers beneath the sensing surface and analysing amplitudemodulation, we can effectively decode interactions on the sensory surface,thereby improving tactile feature estimation. Our approach involves thedistinct separation of hardware components responsible for emitting andreceiving acoustic signals, resulting in a modular and highly customizable skindesign. Practical tests demonstrate the effectiveness of this novel design,achieving remarkable precision in estimating contact normal forces (MAE &lt; 0.8N), 2D contact localisation (MAE &lt; 0.7 mm), and contact surface diameter (MAE &lt;0.3 mm). In conclusion, the AST skin, with its innovative design and modulararchitecture, successfully addresses the challenge of tactile featureestimation. The presented results showcase its ability to precisely estimatevarious tactile features, making it a practical and cost-effective solution forrobotic applications.</description><author>Vishnu Rajendran, Simon Parsons, Amir Ghalamzan E</author><pubDate>Thu, 25 Jan 2024 16:30:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14292v1</guid></item><item><title>Facial Action Unit Detection Based on Multi-task Learning Strategy for Unlabeled Facial Images in the Wild</title><link>http://arxiv.org/abs/2310.05207v3</link><description>Facial Action Unit (AU) detection often relies on highly-cost accuratelabeling or inaccurate pseudo labeling techniques in recent years. How tointroduce large amounts of unlabeled facial images in the wild into supervisedAU detection frameworks has become a challenging problem. Additionally, nearlyevery type of AUs has the problem of unbalanced positive and negative samples.Inspired by other multi-task learning frameworks, we first propose a multi-tasklearning strategy boosting AU detection in the wild through jointing faciallandmark detection and AU domain separation and reconstruction. Our introduceddual domains facial landmark detection framework can solve the lack of accuratefacial landmark coordinates during the AU domain separation and reconstructiontraining process, while the parameters of homostructural facial extractionmodules from these two similar facial tasks are shared. Moreover, we propose apixel-level feature alignment scheme to maintain the consistency of featuresobtained from two separation and reconstruction processes. Furthermore, aweighted asymmetric loss is proposed to change the contribution of positive andnegative samples of each type of AUs to model parameters updating. Experimentalresults on three widely used benchmarks demonstrate our superiority to moststate-of-the-art methods for AU detection.</description><author>Ziqiao Shang, Bin Liu</author><pubDate>Thu, 25 Jan 2024 16:29:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05207v3</guid></item><item><title>Defending Against Physical Adversarial Patch Attacks on Infrared Human Detection</title><link>http://arxiv.org/abs/2309.15519v2</link><description>Infrared detection is an emerging technique for safety-critical tasks owingto its remarkable anti-interference capability. However, recent studies haverevealed that it is vulnerable to physically-realizable adversarial patches,posing risks in its real-world applications. To address this problem, we arethe first to investigate defense strategies against adversarial patch attackson infrared detection, especially human detection. We have devised astraightforward defense strategy, patch-based occlusion-aware detection (POD),which efficiently augments training samples with random patches andsubsequently detects them. POD not only robustly detects people but alsoidentifies adversarial patch locations. Surprisingly, while being extremelycomputationally efficient, POD easily generalizes to state-of-the-artadversarial patch attacks that are unseen during training. Furthermore, PODimproves detection precision even in a clean (i.e., no-attack) situation due tothe data augmentation effect. Evaluation demonstrated that POD is robust toadversarial patches of various shapes and sizes. The effectiveness of ourbaseline approach is shown to be a viable defense mechanism for real-worldinfrared human detection systems, paving the way for exploring future researchdirections.</description><author>Lukas Strack, Futa Waseda, Huy H. Nguyen, Yinqiang Zheng, Isao Echizen</author><pubDate>Thu, 25 Jan 2024 16:28:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15519v2</guid></item><item><title>Promoting Research Collaboration with Open Data Driven Team Recommendation in Response to Call for Proposals</title><link>http://arxiv.org/abs/2309.09404v5</link><description>Building teams and promoting collaboration are two very common businessactivities. An example of these are seen in the TeamingForFunding problem,where research institutions and researchers are interested to identifycollaborative opportunities when applying to funding agencies in response tolatter's calls for proposals. We describe a novel system to recommend teamsusing a variety of AI methods, such that (1) each team achieves the highestpossible skill coverage that is demanded by the opportunity, and (2) theworkload of distributing the opportunities is balanced amongst the candidatemembers. We address these questions by extracting skills latent in open data ofproposal calls (demand) and researcher profiles (supply), normalizing themusing taxonomies, and creating efficient algorithms that match demand tosupply. We create teams to maximize goodness along a novel metric balancingshort- and long-term objectives. We validate the success of our algorithms (1)quantitatively, by evaluating the recommended teams using a goodness score andfind that more informed methods lead to recommendations of smaller number ofteams but higher goodness, and (2) qualitatively, by conducting a large-scaleuser study at a college-wide level, and demonstrate that users overall foundthe tool very useful and relevant. Lastly, we evaluate our system in twodiverse settings in US and India (of researchers and proposal calls) toestablish generality of our approach, and deploy it at a major US universityfor routine use.</description><author>Siva Likitha Valluru, Biplav Srivastava, Sai Teja Paladi, Siwen Yan, Sriraam Natarajan</author><pubDate>Thu, 25 Jan 2024 16:22:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09404v5</guid></item><item><title>Rotation Invariant Quantization for Model Compression</title><link>http://arxiv.org/abs/2303.03106v2</link><description>Post-training Neural Network (NN) model compression is an attractive approachfor deploying large, memory-consuming models on devices with limited memoryresources. In this study, we investigate the rate-distortion tradeoff for NNmodel compression. First, we suggest a Rotation-Invariant Quantization (RIQ)technique that utilizes a single parameter to quantize the entire NN model,yielding a different rate at each layer, i.e., mixed-precision quantization.Then, we prove that our rotation-invariant approach is optimal in terms ofcompression. We rigorously evaluate RIQ and demonstrate its capabilities onvarious models and tasks. For example, RIQ facilitates $\times 19.4$ and$\times 52.9$ compression ratios on pre-trained VGG dense and pruned models,respectively, with $&lt;0.4\%$ accuracy degradation. Code is available in\url{https://github.com/ehaleva/RIQ}.</description><author>Joseph Kampeas, Yury Nahshan, Hanoch Kremer, Gil Lederman, Shira Zaloshinski, Zheng Li, Emir Haleva</author><pubDate>Thu, 25 Jan 2024 16:19:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03106v2</guid></item><item><title>POUR-Net: A Population-Prior-Aided Over-Under-Representation Network for Low-Count PET Attenuation Map Generation</title><link>http://arxiv.org/abs/2401.14285v1</link><description>Low-dose PET offers a valuable means of minimizing radiation exposure in PETimaging. However, the prevalent practice of employing additional CT scans forgenerating attenuation maps (u-map) for PET attenuation correctionsignificantly elevates radiation doses. To address this concern and furthermitigate radiation exposure in low-dose PET exams, we propose POUR-Net - aninnovative population-prior-aided over-under-representation network that aimsfor high-quality attenuation map generation from low-dose PET. First, POUR-Netincorporates an over-under-representation network (OUR-Net) to facilitateefficient feature extraction, encompassing both low-resolution abstracted andfine-detail features, for assisting deep generation on the full-resolutionlevel. Second, complementing OUR-Net, a population prior generation machine(PPGM) utilizing a comprehensive CT-derived u-map dataset, provides additionalprior information to aid OUR-Net generation. The integration of OUR-Net andPPGM within a cascade framework enables iterative refinement of $\mu$-mapgeneration, resulting in the production of high-quality $\mu$-maps.Experimental results underscore the effectiveness of POUR-Net, showing it as apromising solution for accurate CT-free low-count PET attenuation correction,which also surpasses the performance of previous baseline methods.</description><author>Bo Zhou, Jun Hou, Tianqi Chen, Yinchi Zhou, Xiongchao Chen, Huidong Xie, Qiong Liu, Xueqi Guo, Yu-Jung Tsai, Vladimir Y. Panin, Takuya Toyonaga, James S. Duncan, Chi Liu</author><pubDate>Thu, 25 Jan 2024 16:18:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14285v1</guid></item><item><title>Information Leakage Detection through Approximate Bayes-optimal Prediction</title><link>http://arxiv.org/abs/2401.14283v1</link><description>In today's data-driven world, the proliferation of publicly availableinformation intensifies the challenge of information leakage (IL), raisingsecurity concerns. IL involves unintentionally exposing secret (sensitive)information to unauthorized parties via systems' observable information.Conventional statistical approaches, which estimate mutual information (MI)between observable and secret information for detecting IL, face challengessuch as the curse of dimensionality, convergence, computational complexity, andMI misestimation. Furthermore, emerging supervised machine learning (ML)methods, though effective, are limited to binary system-sensitive informationand lack a comprehensive theoretical framework. To address these limitations,we establish a theoretical framework using statistical learning theory andinformation theory to accurately quantify and detect IL. We demonstrate that MIcan be accurately estimated by approximating the log-loss and accuracy of theBayes predictor. As the Bayes predictor is typically unknown in practice, wepropose to approximate it with the help of automated machine learning (AutoML).First, we compare our MI estimation approaches against current baselines, usingsynthetic data sets generated using the multivariate normal (MVN) distributionwith known MI. Second, we introduce a cut-off technique using one-sidedstatistical tests to detect IL, employing the Holm-Bonferroni correction toincrease confidence in detection decisions. Our study evaluates IL detectionperformance on real-world data sets, highlighting the effectiveness of theBayes predictor's log-loss estimation, and finds our proposed method toeffectively estimate MI on synthetic data sets and thus detect ILs accurately.</description><author>Pritha Gupta, Marcel Wever, Eyke Hüllermeier</author><pubDate>Thu, 25 Jan 2024 16:15:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14283v1</guid></item><item><title>RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization</title><link>http://arxiv.org/abs/2401.14280v1</link><description>This study addresses the challenge of extending Large Language Models (LLMs)to non-English languages, specifically those using non-Latin scripts. Wepropose an innovative approach that utilizes the romanized form of text as aninterface for LLMs, hypothesizing that its frequent informal use and sharedtokens with English enhance cross-lingual alignment. Focusing on Hindi, wedemonstrate through Hindi-to-English translation and sentiment analysis tasksthat romanized text not only significantly improves inference efficiency due toits lower fertility compared to native text but also achieves competitiveperformance with limited pre-training. Additionally, our novel multi-scriptprompting approach, which combines romanized and native texts, shows promise infurther enhancing task performance. These findings suggest the potential ofromanization in bridging the language gap for LLM applications, with futurework aimed at expanding this approach to more languages and tasks.</description><author>Jaavid Aktar Husain, Raj Dabre, Aswanth Kumar, Ratish Puduppully, Anoop Kunchukuttan</author><pubDate>Thu, 25 Jan 2024 16:11:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14280v1</guid></item><item><title>A Theory of General Difference in Continuous and Discrete Domain</title><link>http://arxiv.org/abs/2305.08098v2</link><description>Though a core element of the digital age, numerical difference algorithmsstruggle with noise susceptibility. This stems from a key disconnect betweenthe infinitesimal quantities in continuous differentiation and the finiteintervals in its discrete counterpart. This disconnect violates the fundamentaldefinition of differentiation (Leibniz and Cauchy). To bridge this gap, webuild a novel general difference (Tao General Difference, TGD). Departing fromderivative-by-integration, TGD generalizes differentiation to finite intervalsin continuous domains through three key constraints. This allows us tocalculate the general difference of a sequence in discrete domain via thecontinuous step function constructed from the sequence. Two constructionmethods, the rotational construction and the orthogonal construction, areproposed to construct the operators of TGD. The construction TGD operators takesame convolution mode in calculation for continuous functions, discretesequences, and arrays across any dimension. Our analysis with exampleoperations showcases TGD's capability in both continuous and discrete domains,paving the way for accurate and noise-resistant differentiation in the digitalera.</description><author>Linmi Tao, Ruiyang Liu, Donglai Tao, Wu Xia, Feilong Ma, Yu Cheng, Jingmao Cui</author><pubDate>Thu, 25 Jan 2024 16:10:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.08098v2</guid></item><item><title>Transformers and Cortical Waves: Encoders for Pulling In Context Across Time</title><link>http://arxiv.org/abs/2401.14267v1</link><description>The capabilities of transformer networks such as ChatGPT and other LargeLanguage Models (LLMs) have captured the world's attention. The crucialcomputational mechanism underlying their performance relies on transforming acomplete input sequence - for example, all the words in a sentence into a long"encoding vector" - that allows transformers to learn long-range temporaldependencies in naturalistic sequences. Specifically, "self-attention" appliedto this encoding vector enhances temporal context in transformers by computingassociations between pairs of words in the input sequence. We suggest thatwaves of neural activity, traveling across single cortical regions or acrossmultiple regions at the whole-brain scale, could implement a similar encodingprinciple. By encapsulating recent input history into a single spatial patternat each moment in time, cortical waves may enable temporal context to beextracted from sequences of sensory inputs, the same computational principleused in transformers.</description><author>Lyle Muller, Patricia S. Churchland, Terrence J. Sejnowski</author><pubDate>Thu, 25 Jan 2024 16:01:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14267v1</guid></item><item><title>Successor-Predecessor Intrinsic Exploration</title><link>http://arxiv.org/abs/2305.15277v3</link><description>Exploration is essential in reinforcement learning, particularly inenvironments where external rewards are sparse. Here we focus on explorationwith intrinsic rewards, where the agent transiently augments the externalrewards with self-generated intrinsic rewards. Although the study of intrinsicrewards has a long history, existing methods focus on composing the intrinsicreward based on measures of future prospects of states, ignoring theinformation contained in the retrospective structure of transition sequences.Here we argue that the agent can utilise retrospective information to generateexplorative behaviour with structure-awareness, facilitating efficientexploration based on global instead of local information. We proposeSuccessor-Predecessor Intrinsic Exploration (SPIE), an exploration algorithmbased on a novel intrinsic reward combining prospective and retrospectiveinformation. We show that SPIE yields more efficient and ethologicallyplausible exploratory behaviour in environments with sparse rewards andbottleneck states than competing methods. We also implement SPIE in deepreinforcement learning agents, and show that the resulting agent achievesstronger empirical performance than existing methods on sparse-reward Atarigames.</description><author>Changmin Yu, Neil Burgess, Maneesh Sahani, Samuel J. Gershman</author><pubDate>Thu, 25 Jan 2024 15:58:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15277v3</guid></item><item><title>A Survey on Trustworthy Edge Intelligence: From Security and Reliability To Transparency and Sustainability</title><link>http://arxiv.org/abs/2310.17944v2</link><description>Edge Intelligence (EI) integrates Edge Computing (EC) and ArtificialIntelligence (AI) to push the capabilities of AI to the network edge forreal-time, efficient and secure intelligent decision-making and computation.However, EI faces various challenges due to resource constraints, heterogeneousnetwork environments, and diverse service requirements of differentapplications, which together affect the trustworthiness of EI in the eyes ofstakeholders. This survey comprehensively summarizes the characteristics,architecture, technologies, and solutions of trustworthy EI. Specifically, wefirst emphasize the need for trustworthy EI in the context of the trend towardlarge models. We then provide an initial definition of trustworthy EI, exploreits key characteristics and give a multi-layered architecture for trustworthyEI. Then, we summarize several important issues that hinder the achievement oftrustworthy EI. Subsequently, we present enabling technologies for trustworthyEI systems and provide an in-depth literature review of the state-of-the-artsolutions for realizing the trustworthiness of EI. Finally, we discuss thecorresponding research challenges and open issues.</description><author>Xiaojie Wang, Beibei Wang, Yu Wu, Zhaolong Ning, Song Guo, Fei Richard Yu</author><pubDate>Thu, 25 Jan 2024 15:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17944v2</guid></item><item><title>Grounded Object Centric Learning</title><link>http://arxiv.org/abs/2307.09437v2</link><description>The extraction of modular object-centric representations for downstream tasksis an emerging area of research. Learning grounded representations of objectsthat are guaranteed to be stable and invariant promises robust performanceacross different tasks and environments. Slot Attention (SA) learnsobject-centric representations by assigning objects to \textit{slots}, butpresupposes a \textit{single} distribution from which all slots are randomlyinitialised. This results in an inability to learn \textit{specialized} slotswhich bind to specific object types and remain invariant to identity-preservingchanges in object appearance. To address this, we present\emph{\textsc{Co}nditional \textsc{S}lot \textsc{A}ttention} (\textsc{CoSA})using a novel concept of \emph{Grounded Slot Dictionary} (GSD) inspired byvector quantization. Our proposed GSD comprises (i) canonical object-levelproperty vectors and (ii) parametric Gaussian distributions, which define aprior over the slots. We demonstrate the benefits of our method in multipledownstream tasks such as scene generation, composition, and task adaptation,whilst remaining competitive with SA in popular object discovery benchmarks.</description><author>Avinash Kori, Francesco Locatello, Fabio De Sousa Ribeiro, Francesca Toni, Ben Glocker</author><pubDate>Thu, 25 Jan 2024 15:52:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09437v2</guid></item><item><title>TrojFST: Embedding Trojans in Few-shot Prompt Tuning</title><link>http://arxiv.org/abs/2312.10467v2</link><description>Prompt-tuning has emerged as a highly effective approach for adapting apre-trained language model (PLM) to handle new natural language processingtasks with limited input samples. However, the success of prompt-tuning has ledto adversaries attempting backdoor attacks against this technique. Previousprompt-based backdoor attacks faced challenges when implemented throughfew-shot prompt-tuning, requiring either full-model fine-tuning or a largetraining dataset. We observe the difficulty in constructing a prompt-basedbackdoor using few-shot prompt-tuning, which involves freezing the PLM andtuning a soft prompt with a restricted set of input samples. This approachintroduces an imbalanced poisoned dataset, making it susceptible to overfittingand lacking attention awareness. To address these challenges, we introduceTrojFST for backdoor attacks within the framework of few-shot prompt-tuning.TrojFST comprises three modules: balanced poison learning, selective tokenpoisoning, and trojan-trigger attention. In comparison to previous prompt-basedbackdoor attacks, TrojFST demonstrates significant improvements, enhancing ASR$&gt; 9\%$ and CDA by $&gt; 4\%$ across various PLMs and a diverse set of downstreamtasks.</description><author>Mengxin Zheng, Jiaqi Xue, Xun Chen, YanShan Wang, Qian Lou, Lei Jiang</author><pubDate>Thu, 25 Jan 2024 15:51:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10467v2</guid></item><item><title>Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation</title><link>http://arxiv.org/abs/2401.14257v1</link><description>Recently, text-to-3D approaches have achieved high-fidelity 3D contentgeneration using text description. However, the generated objects arestochastic and lack fine-grained control. Sketches provide a cheap approach tointroduce such fine-grained control. Nevertheless, it is challenging to achieveflexible control from these sketches due to their abstraction and ambiguity. Inthis paper, we present a multi-view sketch-guided text-to-3D generationframework (namely, Sketch2NeRF) to add sketch control to 3D generation.Specifically, our method leverages pretrained 2D diffusion models (e.g., StableDiffusion and ControlNet) to supervise the optimization of a 3D scenerepresented by a neural radiance field (NeRF). We propose a novel synchronizedgeneration and reconstruction method to effectively optimize the NeRF. In theexperiments, we collected two kinds of multi-view sketch datasets to evaluatethe proposed method. We demonstrate that our method can synthesize 3Dconsistent contents with fine-grained sketch control while being high-fidelityto text prompts. Extensive results show that our method achievesstate-of-the-art performance in terms of sketch similarity and text alignment.</description><author>Minglin Chen, Longguang Wang, Weihao Yuan, Yukun Wang, Zhe Sheng, Yisheng He, Zilong Dong, Liefeng Bo, Yulan Guo</author><pubDate>Thu, 25 Jan 2024 15:49:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14257v1</guid></item><item><title>Producing Plankton Classifiers that are Robust to Dataset Shift</title><link>http://arxiv.org/abs/2401.14256v1</link><description>Modern plankton high-throughput monitoring relies on deep learningclassifiers for species recognition in water ecosystems. Despite satisfactorynominal performances, a significant challenge arises from Dataset Shift, whichcauses performances to drop during deployment. In our study, we integrate theZooLake dataset with manually-annotated images from 10 independent days ofdeployment, serving as test cells to benchmark Out-Of-Dataset (OOD)performances. Our analysis reveals instances where classifiers, initiallyperforming well in In-Dataset conditions, encounter notable failures inpractical scenarios. For example, a MobileNet with a 92% nominal test accuracyshows a 77% OOD accuracy. We systematically investigate conditions leading toOOD performance drops and propose a preemptive assessment method to identifypotential pitfalls when classifying new data, and pinpoint features in OODimages that adversely impact classification. We present a three-step pipeline:(i) identifying OOD degradation compared to nominal test performance, (ii)conducting a diagnostic analysis of degradation causes, and (iii) providingsolutions. We find that ensembles of BEiT vision transformers, with targetedaugmentations addressing OOD robustness, geometric ensembling, androtation-based test-time augmentation, constitute the most robust model, whichwe call BEsT model. It achieves an 83% OOD accuracy, with errors concentratedon container classes. Moreover, it exhibits lower sensitivity to dataset shift,and reproduces well the plankton abundances. Our proposed pipeline isapplicable to generic plankton classifiers, contingent on the availability ofsuitable test cells. By identifying critical shortcomings and offeringpractical procedures to fortify models against dataset shift, our studycontributes to the development of more reliable plankton classificationtechnologies.</description><author>Cheng Chen, Sreenath Kyathanahally, Marta Reyes, Stefanie Merkli, Ewa Merz, Emanuele Francazi, Marvin Hoege, Francesco Pomati, Marco Baity-Jesi</author><pubDate>Thu, 25 Jan 2024 15:47:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14256v1</guid></item><item><title>Interpretable Solutions for Breast Cancer Diagnosis with Grammatical Evolution and Data Augmentation</title><link>http://arxiv.org/abs/2401.14255v1</link><description>Medical imaging diagnosis increasingly relies on Machine Learning (ML)models. This is a task that is often hampered by severely imbalanced datasets,where positive cases can be quite rare. Their use is further compromised bytheir limited interpretability, which is becoming increasingly important. Whilepost-hoc interpretability techniques such as SHAP and LIME have been used withsome success on so-called black box models, the use of inherentlyunderstandable models makes such endeavors more fruitful. This paper addressesthese issues by demonstrating how a relatively new synthetic data generationtechnique, STEM, can be used to produce data to train models produced byGrammatical Evolution (GE) that are inherently understandable. STEM is arecently introduced combination of the Synthetic Minority OversamplingTechnique (SMOTE), Edited Nearest Neighbour (ENN), and Mixup; it has previouslybeen successfully used to tackle both between class and within class imbalanceissues. We test our technique on the Digital Database for Screening Mammography(DDSM) and the Wisconsin Breast Cancer (WBC) datasets and compare Area Underthe Curve (AUC) results with an ensemble of the top three performingclassifiers from a set of eight standard ML classifiers with varying degrees ofinterpretability. We demonstrate that the GE-derived models present the bestAUC while still maintaining interpretable solutions.</description><author>Yumnah Hasan, Allan de Lima, Fatemeh Amerehi, Darian Reyes Fernandez de Bulnes, Patrick Healy, Conor Ryan</author><pubDate>Thu, 25 Jan 2024 15:45:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14255v1</guid></item><item><title>A powerful rank-based correction to multiple testing under positive dependency</title><link>http://arxiv.org/abs/2311.10900v2</link><description>We develop a novel multiple hypothesis testing correction with family-wiseerror rate (FWER) control that efficiently exploits positive dependenciesbetween potentially correlated statistical hypothesis tests. Our proposedalgorithm $\texttt{max-rank}$ is conceptually straight-forward, relying on theuse of a $\max$-operator in the rank domain of computed test statistics. Wecompare our approach to the frequently employed Bonferroni correction,theoretically and empirically demonstrating its superiority over Bonferroni inthe case of existing positive dependency, and its equivalence otherwise. Ouradvantage over Bonferroni increases as the number of tests rises, and wemaintain high statistical power whilst ensuring FWER control. We specificallyframe our algorithm in the context of parallel permutation testing, a scenariothat arises in our primary application of conformal prediction, a recentlypopularized approach for quantifying uncertainty in complex predictivesettings.</description><author>Alexander Timans, Christoph-Nikolas Straehle, Kaspar Sakmann, Eric Nalisnick</author><pubDate>Thu, 25 Jan 2024 15:43:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10900v2</guid></item><item><title>JUMP: A joint multimodal registration pipeline for neuroimaging with minimal preprocessing</title><link>http://arxiv.org/abs/2401.14250v1</link><description>We present a pipeline for unbiased and robust multimodal registration ofneuroimaging modalities with minimal pre-processing. While typical multimodalstudies need to use multiple independent processing pipelines, with diverseoptions and hyperparameters, we propose a single and structured framework tojointly process different image modalities. The use of state-of-the-artlearning-based techniques enables fast inferences, which makes the presentedmethod suitable for large-scale and/or multi-cohort datasets with a diversenumber of modalities per session. The pipeline currently works with structuralMRI, resting state fMRI and amyloid PET images. We show the predictive power ofthe derived biomarkers using in a case-control study and study the cross-modalrelationship between different image modalities. The code can be found inhttps: //github.com/acasamitjana/JUMP.</description><author>Adria Casamitjana, Juan Eugenio Iglesias, Raul Tudela, Aida Ninerola-Baizan, Roser Sala-Llonch</author><pubDate>Thu, 25 Jan 2024 15:40:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14250v1</guid></item><item><title>On generalisability of segment anything model for nuclear instance segmentation in histology images</title><link>http://arxiv.org/abs/2401.14248v1</link><description>Pre-trained on a large and diverse dataset, the segment anything model (SAM)is the first promptable foundation model in computer vision aiming at objectsegmentation tasks. In this work, we evaluate SAM for the task of nuclearinstance segmentation performance with zero-shot learning and finetuning. Wecompare SAM with other representative methods in nuclear instance segmentation,especially in the context of model generalisability. To achieve automaticnuclear instance segmentation, we propose using a nuclei detection model toprovide bounding boxes or central points of nu-clei as visual prompts for SAMin generating nuclear instance masks from histology images.</description><author>Kesi Xu, Lea Goetz, Nasir Rajpoot</author><pubDate>Thu, 25 Jan 2024 15:39:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14248v1</guid></item><item><title>General Phrase Debiaser: Debiasing Masked Language Models at a Multi-Token Level</title><link>http://arxiv.org/abs/2311.13892v3</link><description>The social biases and unwelcome stereotypes revealed by pretrained languagemodels are becoming obstacles to their application. Compared to numerousdebiasing methods targeting word level, there has been relatively lessattention on biases present at phrase level, limiting the performance ofdebiasing in discipline domains. In this paper, we propose an automaticmulti-token debiasing pipeline called \textbf{General Phrase Debiaser}, whichis capable of mitigating phrase-level biases in masked language models.Specifically, our method consists of a \textit{phrase filter stage} thatgenerates stereotypical phrases from Wikipedia pages as well as a \textit{modeldebias stage} that can debias models at the multi-token level to tackle biaschallenges on phrases. The latter searches for prompts that trigger model'sbias, and then uses them for debiasing. State-of-the-art results on standarddatasets and metrics show that our approach can significantly reduce genderbiases on both career and multiple disciplines, across models with varyingparameter sizes.</description><author>Bingkang Shi, Xiaodan Zhang, Dehan Kong, Yulei Wu, Zongzhen Liu, Honglei Lyu, Longtao Huang</author><pubDate>Thu, 25 Jan 2024 15:36:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13892v3</guid></item><item><title>Structural Group Unfairness: Measurement and Mitigation by means of the Effective Resistance</title><link>http://arxiv.org/abs/2305.03223v2</link><description>Social networks contribute to the distribution of social capital, defined asthe relationships, norms of trust and reciprocity within a community or societythat facilitate cooperation and collective action. Social capital exists in therelations among individuals, such that better positioned members in a socialnetwork benefit from faster access to diverse information and higher influenceon information dissemination. A variety of methods have been proposed in theliterature to measure social capital at an individual level. However, there isa lack of methods to quantify social capital at a group level, which isparticularly important when the groups are defined on the grounds of protectedattributes. Furthermore, state-of-the-art approaches fail to model the role oflong-range interactions between nodes in the network and their contributions tosocial capital. To fill this gap, we propose to measure the social capital of agroup of nodes by means of their information flow and emphasize the importanceof considering the whole network topology. Grounded in spectral graph theory,we introduce three effective resistance-based measures of group social capital,namely group isolation, group diameter and group control. We denote the socialcapital disparity among different groups in a network as structural groupunfairness, and propose to mitigate it by means of a budgeted edge augmentationheuristic that systematically increases the social capital of the mostdisadvantaged group. In experiments on real networks, we uncover significantlevels of structural group unfairness when using gender as the protectedattribute, with females being the most disadvantaged group in comparison tomales. We also illustrate how our proposed edge augmentation approach is ableto not only effectively mitigate the structural group unfairness but alsoincrease the social capital of all groups in the network.</description><author>Adrian Arnaiz-Rodriguez, Georgina Curto, Nuria Oliver</author><pubDate>Thu, 25 Jan 2024 15:36:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03223v2</guid></item><item><title>Learning from History: Task-agnostic Model Contrastive Learning for Image Restoration</title><link>http://arxiv.org/abs/2309.06023v5</link><description>Contrastive learning has emerged as a prevailing paradigm for high-levelvision tasks, which, by introducing properly negative samples, has also beenexploited for low-level vision tasks to achieve a compact optimization space toaccount for their ill-posed nature. However, existing methods rely on manuallypredefined and task-oriented negatives, which often exhibit pronouncedtask-specific biases. To address this challenge, our paper introduces aninnovative method termed 'learning from history', which dynamically generatesnegative samples from the target model itself. Our approach, named ModelContrastive Learning for Image Restoration (MCLIR), rejuvenates latency modelsas negative models, making it compatible with diverse image restoration tasks.We propose the Self-Prior guided Negative loss (SPN) to enable it. Thisapproach significantly enhances existing models when retrained with theproposed model contrastive paradigm. The results show significant improvementsin image restoration across various tasks and architectures. For example,models retrained with SPN outperform the original FFANet and DehazeFormer by3.41 dB and 0.57 dB on the RESIDE indoor dataset for image dehazing. Similarly,they achieve notable improvements of 0.47 dB on SPA-Data over IDT for imagederaining and 0.12 dB on Manga109 for a 4x scale super-resolution overlightweight SwinIR, respectively. Code and retrained models are available athttps://github.com/Aitical/MCLIR.</description><author>Gang Wu, Junjun Jiang, Kui Jiang, Xianming Liu</author><pubDate>Thu, 25 Jan 2024 15:35:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06023v5</guid></item><item><title>Benchmarking the Sim-to-Real Gap in Cloth Manipulation</title><link>http://arxiv.org/abs/2310.09543v2</link><description>Realistic physics engines play a crucial role for learning to manipulatedeformable objects such as garments in simulation. By doing so, researchers cancircumvent challenges such as sensing the deformation of the object in therealworld. In spite of the extensive use of simulations for this task, fewworks have evaluated the reality gap between deformable object simulators andreal-world data. We present a benchmark dataset to evaluate the sim-to-real gapin cloth manipulation. The dataset is collected by performing a dynamic as wellas a quasi-static cloth manipulation task involving contact with a rigid table.We use the dataset to evaluate the reality gap, computational time, andsimulation stability of four popular deformable object simulators: MuJoCo,Bullet, Flex, and SOFA. Additionally, we discuss the benefits and drawbacks ofeach simulator. The benchmark dataset is open-source. Supplementary material,videos, and code, can be found athttps://sites.google.com/view/cloth-sim2real-benchmark.</description><author>David Blanco-Mulero, Oriol Barbany, Gokhan Alcan, Adrià Colomé, Carme Torras, Ville Kyrki</author><pubDate>Thu, 25 Jan 2024 15:35:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09543v2</guid></item><item><title>Improving Natural Language Capability of Code Large Language Model</title><link>http://arxiv.org/abs/2401.14242v1</link><description>Code large language models (Code LLMs) have demonstrated remarkableperformance in code generation. Nonetheless, most existing works focus onboosting code LLMs from the perspective of programming capabilities, whiletheir natural language capabilities receive less attention. To fill this gap,we thus propose a novel framework, comprising two modules: AttentionExtractor,which is responsible for extracting key phrases from the user's naturallanguage requirements, and AttentionCoder, which leverages these extractedphrases to generate target code to solve the requirement. This frameworkpioneers an innovative idea by seamlessly integrating code LLMs withtraditional natural language processing tools. To validate the effectiveness ofthe framework, we craft a new code generation benchmark, called MultiNL-H,covering five natural languages. Extensive experimental results demonstrate theeffectiveness of our proposed framework.</description><author>Wei Li, Daoguang Zan, Bei Guan, Ailun Yu, Xiaolin Chen, Yongji Wang</author><pubDate>Thu, 25 Jan 2024 15:33:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14242v1</guid></item><item><title>Enhanced Labeling Technique for Reddit Text and Fine-Tuned Longformer Models for Classifying Depression Severity in English and Luganda</title><link>http://arxiv.org/abs/2401.14240v1</link><description>Depression is a global burden and one of the most challenging mental healthconditions to control. Experts can detect its severity early using the BeckDepression Inventory (BDI) questionnaire, administer appropriate medication topatients, and impede its progression. Due to the fear of potentialstigmatization, many patients turn to social media platforms like Reddit foradvice and assistance at various stages of their journey. This researchextracts text from Reddit to facilitate the diagnostic process. It employs aproposed labeling approach to categorize the text and subsequently fine-tunesthe Longformer model. The model's performance is compared against baselinemodels, including Naive Bayes, Random Forest, Support Vector Machines, andGradient Boosting. Our findings reveal that the Longformer model outperformsthe baseline models in both English (48%) and Luganda (45%) languages on acustom-made dataset.</description><author>Richard Kimera, Daniela N. Rim, Joseph Kirabira, Ubong Godwin Udomah, Heeyoul Choi</author><pubDate>Thu, 25 Jan 2024 15:28:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14240v1</guid></item><item><title>From Zero to Hero: Harnessing Transformers for Biomedical Named Entity Recognition in Zero- and Few-shot Contexts</title><link>http://arxiv.org/abs/2305.04928v4</link><description>Supervised named entity recognition (NER) in the biomedical domain depends onlarge sets of annotated texts with the given named entities. The creation ofsuch datasets can be time-consuming and expensive, while extraction of newentities requires additional annotation tasks and retraining the model. Toaddress these challenges, this paper proposes a method for zero- and few-shotNER in the biomedical domain. The method is based on transforming the task ofmulti-class token classification into binary token classification andpre-training on a large amount of datasets and biomedical entities, which allowthe model to learn semantic relations between the given and potentially novelnamed entity labels. We have achieved average F1 scores of 35.44% for zero-shotNER, 50.10% for one-shot NER, 69.94% for 10-shot NER, and 79.51% for 100-shotNER on 9 diverse evaluated biomedical entities with fine-tuned PubMedBERT-basedmodel. The results demonstrate the effectiveness of the proposed method forrecognizing new biomedical entities with no or limited number of examples,outperforming previous transformer-based methods, and being comparable toGPT3-based models using models with over 1000 times fewer parameters. We makemodels and developed code publicly available.</description><author>Miloš Košprdić, Nikola Prodanović, Adela Ljajić, Bojana Bašaragin, Nikola Milošević</author><pubDate>Thu, 25 Jan 2024 15:23:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04928v4</guid></item><item><title>Exploring the Unexplored: Understanding the Impact of Layer Adjustments on Image Classification</title><link>http://arxiv.org/abs/2401.14236v1</link><description>This paper investigates how adjustments to deep learning architectures impactmodel performance in image classification. Small-scale experiments generateinitial insights although the trends observed are not consistent with theentire dataset. Filtering operations in the image processing pipeline arecrucial, with image filtering before pre-processing yielding better results.The choice and order of layers as well as filter placement significantly impactmodel performance. This study provides valuable insights into optimizing deeplearning models, with potential avenues for future research includingcollaborative platforms.</description><author>Haixia Liu, Tim Brailsford, James Goulding, Gavin Smith, Larry Bull</author><pubDate>Thu, 25 Jan 2024 15:21:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14236v1</guid></item><item><title>Derivative-free Alternating Projection Algorithms for General Nonconvex-Concave Minimax Problems</title><link>http://arxiv.org/abs/2108.00473v5</link><description>In this paper, we study zeroth-order algorithms for nonconvex-concave minimaxproblems, which have attracted widely attention in machine learning, signalprocessing and many other fields in recent years. We propose a zeroth-orderalternating randomized gradient projection (ZO-AGP) algorithm for smoothnonconvex-concave minimax problems, and its iteration complexity to obtain an$\varepsilon$-stationary point is bounded by $\mathcal{O}(\varepsilon^{-4})$,and the number of function value estimation is bounded by$\mathcal{O}(d_{x}+d_{y})$ per iteration. Moreover, we propose a zeroth-orderblock alternating randomized proximal gradient algorithm (ZO-BAPG) for solvingblock-wise nonsmooth nonconvex-concave minimax optimization problems, and theiteration complexity to obtain an $\varepsilon$-stationary point is bounded by$\mathcal{O}(\varepsilon^{-4})$ and the number of function value estimation periteration is bounded by $\mathcal{O}(K d_{x}+d_{y})$. To the best of ourknowledge, this is the first time that zeroth-order algorithms with iterationcomplexity gurantee are developed for solving both general smooth andblock-wise nonsmooth nonconvex-concave minimax problems. Numerical results ondata poisoning attack problem and distributed nonconvex sparse principalcomponent analysis problem validate the efficiency of the proposed algorithms.</description><author>Zi Xu, Ziqi Wang, Jingjing Shen, Yuhong Dai</author><pubDate>Thu, 25 Jan 2024 15:15:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2108.00473v5</guid></item><item><title>Diffusion Language Models Generation Can Be Halted Early</title><link>http://arxiv.org/abs/2305.10818v3</link><description>Diffusion Language models (DLMs) are a promising avenue for text generationdue to their practical properties on tractable controllable generation. Theyalso have the advantage of not having to predict text autoregressively.However, despite these notable features, DLMs have not yet reached theperformance levels of their autoregressive counterparts. One of the ways toreduce the performance gap between these two types of language models is tospeed up the generation of DLMs. Therefore, we propose a novel methodology toaddress this issue in this work. It enables the execution of more generationsteps within a given time frame, leading to higher-quality outputs.Specifically, our methods estimate DLMs completeness of text generation andallow adaptive halting of the generation process. We evaluate our methods onPlaid, SSD, and CDCD DLMs and create a cohesive perspective on their generationworkflows. Finally, we confirm that our methods allow halting these models anddecrease the generation time by $10$-$40$\% without a drop in the quality ofmodel samples.</description><author>Sofia Maria Lo Cicero Vaina, Nikita Balagansky, Daniil Gavrilov</author><pubDate>Thu, 25 Jan 2024 15:15:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10818v3</guid></item><item><title>Assessing the Portability of Parameter Matrices Trained by Parameter-Efficient Finetuning Methods</title><link>http://arxiv.org/abs/2401.14228v1</link><description>As the cost of training ever larger language models has grown, so has theinterest in reusing previously learnt knowledge. Transfer learning methods haveshown how reusing non-task-specific knowledge can help in subsequenttask-specific learning. In this paper, we investigate the inverse: portingwhole functional modules that encode task-specific knowledge from one model toanother. We designed a study comprising 1,440 training/testing runs to test theportability of modules trained by parameter-efficient finetuning (PEFT)techniques, using sentiment analysis as an example task. We test portability ina wide range of scenarios, involving different PEFT techniques and differentpretrained host models, among other dimensions. We compare the performance ofported modules with that of equivalent modules trained (i) from scratch, and(ii) from parameters sampled from the same distribution as the ported module.We find that the ported modules far outperform the two alternatives tested, butthat there are interesting performance differences between the four PEFTtechniques. We conclude that task-specific knowledge in the form ofstructurally modular sets of parameters as produced by PEFT techniques ishighly portable, but that degree of success depends on type of PEFT and ondifferences between originating and receiving pretrained models.</description><author>Mohammed Sabry, Anya Belz</author><pubDate>Thu, 25 Jan 2024 15:11:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14228v1</guid></item><item><title>DiConStruct: Causal Concept-based Explanations through Black-Box Distillation</title><link>http://arxiv.org/abs/2401.08534v3</link><description>Model interpretability plays a central role in human-AI decision-makingsystems. Ideally, explanations should be expressed using human-interpretablesemantic concepts. Moreover, the causal relations between these concepts shouldbe captured by the explainer to allow for reasoning about the explanations.Lastly, explanation methods should be efficient and not compromise theperformance of the predictive task. Despite the rapid advances in AIexplainability in recent years, as far as we know to date, no method fulfillsthese three properties. Indeed, mainstream methods for local conceptexplainability do not produce causal explanations and incur a trade-off betweenexplainability and prediction performance. We present DiConStruct, anexplanation method that is both concept-based and causal, with the goal ofcreating more interpretable local explanations in the form of structural causalmodels and concept attributions. Our explainer works as a distillation model toany black-box machine learning model by approximating its predictions whileproducing the respective explanations. Because of this, DiConStruct generatesexplanations efficiently while not impacting the black-box prediction task. Wevalidate our method on an image dataset and a tabular dataset, showing thatDiConStruct approximates the black-box models with higher fidelity than otherconcept explainability baselines, while providing explanations that include thecausal relations between the concepts.</description><author>Ricardo Moreira, Jacopo Bono, Mário Cardoso, Pedro Saleiro, Mário A. T. Figueiredo, Pedro Bizarro</author><pubDate>Thu, 25 Jan 2024 15:06:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08534v3</guid></item><item><title>Sample Efficient Reinforcement Learning by Automatically Learning to Compose Subtasks</title><link>http://arxiv.org/abs/2401.14226v1</link><description>Improving sample efficiency is central to Reinforcement Learning (RL),especially in environments where the rewards are sparse. Some recent approacheshave proposed to specify reward functions as manually designed or learnedreward structures whose integrations in the RL algorithms are claimed tosignificantly improve the learning efficiency. Manually designed rewardstructures can suffer from inaccuracy and existing automatically learningmethods are often computationally intractable for complex tasks. Theintegration of inaccurate or partial reward structures in RL algorithms fail tolearn optimal policies. In this work, we propose an RL algorithm that canautomatically structure the reward function for sample efficiency, given a setof labels that signify subtasks. Given such minimal knowledge about the task,we train a high-level policy that selects optimal sub-tasks in each statetogether with a low-level policy that efficiently learns to complete eachsub-task. We evaluate our algorithm in a variety of sparse-reward environments.The experiment results show that our approach significantly outperforms thestate-of-art baselines as the difficulty of the task increases.</description><author>Shuai Han, Mehdi Dastani, Shihan Wang</author><pubDate>Thu, 25 Jan 2024 15:06:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14226v1</guid></item><item><title>The Surprising Harmfulness of Benign Overfitting for Adversarial Robustness</title><link>http://arxiv.org/abs/2401.12236v2</link><description>Recent empirical and theoretical studies have established the generalizationcapabilities of large machine learning models that are trained to(approximately or exactly) fit noisy data. In this work, we prove a surprisingresult that even if the ground truth itself is robust to adversarial examples,and the benignly overfitted model is benign in terms of the ``standard''out-of-sample risk objective, this benign overfitting process can be harmfulwhen out-of-sample data are subject to adversarial manipulation. Morespecifically, our main results contain two parts: (i) the min-norm estimator inoverparameterized linear model always leads to adversarial vulnerability in the``benign overfitting'' setting; (ii) we verify an asymptotic trade-off resultbetween the standard risk and the ``adversarial'' risk of every ridgeregression estimator, implying that under suitable conditions these two itemscannot both be small at the same time by any single choice of the ridgeregularization parameter. Furthermore, under the lazy training regime, wedemonstrate parallel results on two-layer neural tangent kernel (NTK) model,which align with empirical observations in deep neural networks. Our findingprovides theoretical insights into the puzzling phenomenon observed inpractice, where the true target function (e.g., human) is robust againstadverasrial attack, while beginly overfitted neural networks lead to modelsthat are not robust.</description><author>Yifan Hao, Tong Zhang</author><pubDate>Thu, 25 Jan 2024 14:57:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12236v2</guid></item><item><title>Private, fair and accurate: Training large-scale, privacy-preserving AI models in medical imaging</title><link>http://arxiv.org/abs/2302.01622v3</link><description>Artificial intelligence (AI) models are increasingly used in the medicaldomain. However, as medical data is highly sensitive, special precautions toensure its protection are required. The gold standard for privacy preservationis the introduction of differential privacy (DP) to model training. Prior workindicates that DP has negative implications on model accuracy and fairness,which are unacceptable in medicine and represent a main barrier to thewidespread use of privacy-preserving techniques. In this work, we evaluated theeffect of privacy-preserving training of AI models regarding accuracy andfairness compared to non-private training. For this, we used two datasets: (1)A large dataset (N=193,311) of high quality clinical chest radiographs, and (2)a dataset (N=1,625) of 3D abdominal computed tomography (CT) images, with thetask of classifying the presence of pancreatic ductal adenocarcinoma (PDAC).Both were retrospectively collected and manually labeled by experiencedradiologists. We then compared non-private deep convolutional neural networks(CNNs) and privacy-preserving (DP) models with respect to privacy-utilitytrade-offs measured as area under the receiver-operator-characteristic curve(AUROC), and privacy-fairness trade-offs, measured as Pearson's r orStatistical Parity Difference. We found that, while the privacy-preservingtrainings yielded lower accuracy, they did largely not amplify discriminationagainst age, sex or co-morbidity. Our study shows that -- under the challengingrealistic circumstances of a real-life clinical dataset -- theprivacy-preserving training of diagnostic deep learning models is possible withexcellent diagnostic accuracy and fairness.</description><author>Soroosh Tayebi Arasteh, Alexander Ziller, Christiane Kuhl, Marcus Makowski, Sven Nebelung, Rickmer Braren, Daniel Rueckert, Daniel Truhn, Georgios Kaissis</author><pubDate>Thu, 25 Jan 2024 14:55:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01622v3</guid></item><item><title>Commonsense-augmented Memory Construction and Management in Long-term Conversations via Context-aware Persona Refinement</title><link>http://arxiv.org/abs/2401.14215v1</link><description>Memorizing and utilizing speakers' personas is a common practice for responsegeneration in long-term conversations. Yet, human-authored datasets oftenprovide uninformative persona sentences that hinder response quality. Thispaper presents a novel framework that leverages commonsense-based personaexpansion to address such issues in long-term conversation. While prior workfocuses on not producing personas that contradict others, we focus ontransforming contradictory personas into sentences that contain rich speakerinformation, by refining them based on their contextual backgrounds withdesigned strategies. As the pioneer of persona expansion in multi-sessionsettings, our framework facilitates better response generation via human-likepersona refinement. The supplementary video of our work is available athttps://caffeine-15bbf.web.app/.</description><author>Hana Kim, Kai Tzu-iunn Ong, Seoyeon Kim, Dongha Lee, Jinyoung Yeo</author><pubDate>Thu, 25 Jan 2024 14:54:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14215v1</guid></item><item><title>Explicitly Representing Syntax Improves Sentence-to-layout Prediction of Unexpected Situations</title><link>http://arxiv.org/abs/2401.14212v1</link><description>Recognizing visual entities in a natural language sentence and arranging themin a 2D spatial layout require a compositional understanding of language andspace. This task of layout prediction is valuable in text-to-image synthesis asit allows localized and controlled in-painting of the image. In thiscomparative study it is shown that we can predict layouts from languagerepresentations that implicitly or explicitly encode sentence syntax, if thesentences mention similar entity-relationships to the ones seen duringtraining. To test compositional understanding, we collect a test set ofgrammatically correct sentences and layouts describing compositions of entitiesand relations that unlikely have been seen during training. Performance on thistest set substantially drops, showing that current models rely on correlationsin the training data and have difficulties in understanding the structure ofthe input sentences. We propose a novel structural loss function that betterenforces the syntactic structure of the input sentence and show largeperformance gains in the task of 2D spatial layout prediction conditioned ontext. The loss has the potential to be used in other generation tasks where atree-like structure underlies the conditioning modality. Code, trained modelsand the USCOCO evaluation set will be made available via github.</description><author>Wolf Nuyts, Ruben Cartuyvels, Marie-Francine Moens</author><pubDate>Thu, 25 Jan 2024 14:53:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14212v1</guid></item><item><title>CultureBERT: Measuring Corporate Culture With Transformer-Based Language Models</title><link>http://arxiv.org/abs/2212.00509v4</link><description>This paper introduces transformer-based language models to the literaturemeasuring corporate culture from text documents. We compile a unique data setof employee reviews that were labeled by human evaluators with respect to theinformation the reviews reveal about the firms' corporate culture. Using thisdata set, we fine-tune state-of-the-art transformer-based language models toperform the same classification task. In out-of-sample predictions, ourlanguage models classify 17 to 30 percentage points more of employee reviews inline with human evaluators than traditional approaches of text classification.We make our models publicly available.</description><author>Sebastian Koch, Stefan Pasch</author><pubDate>Thu, 25 Jan 2024 14:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.00509v4</guid></item><item><title>Communication-Efficient Federated Learning through Adaptive Weight Clustering and Server-Side Distillation</title><link>http://arxiv.org/abs/2401.14211v1</link><description>Federated Learning (FL) is a promising technique for the collaborativetraining of deep neural networks across multiple devices while preserving dataprivacy. Despite its potential benefits, FL is hindered by excessivecommunication costs due to repeated server-client communication duringtraining. To address this challenge, model compression techniques, such assparsification and weight clustering are applied, which often require modifyingthe underlying model aggregation schemes or involve cumbersome hyperparametertuning, with the latter not only adjusts the model's compression rate but alsolimits model's potential for continuous improvement over growing data. In thispaper, we propose FedCompress, a novel approach that combines dynamic weightclustering and server-side knowledge distillation to reduce communication costswhile learning highly generalizable models. Through a comprehensive evaluationon diverse public datasets, we demonstrate the efficacy of our approachcompared to baselines in terms of communication costs and inference speed. Wewill make our implementation public upon acceptance.</description><author>Vasileios Tsouvalas. Aaqib Saeed, Tanir Ozcelebi, Nirvana Meratnia</author><pubDate>Thu, 25 Jan 2024 14:49:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14211v1</guid></item><item><title>At the junction between deep learning and statistics of extremes: formalizing the landslide hazard definition</title><link>http://arxiv.org/abs/2401.14210v1</link><description>The most adopted definition of landslide hazard combines spatial informationabout landslide location (susceptibility), threat (intensity), and frequency(return period). Only the first two elements are usually considered andestimated when working over vast areas. Even then, separate models constitutethe standard, with frequency being rarely investigated. Frequency and intensityare intertwined and depend on each other because larger events occur lessfrequently and vice versa. However, due to the lack of multi-temporalinventories and joint statistical models, modelling such properties via aunified hazard model has always been challenging and has yet to be attempted.Here, we develop a unified model to estimate landslide hazard at the slope unitlevel to address such gaps. We employed deep learning, combined with a modelmotivated by extreme-value theory to analyse an inventory of 30 years ofobserved rainfall-triggered landslides in Nepal and assess landslide hazard formultiple return periods. We also use our model to further explore landslidehazard for the same return periods under different climate change scenarios upto the end of the century. Our results show that the proposed model performsexcellently and can be used to model landslide hazard in a unified manner.Geomorphologically, we find that under both climate change scenarios (SSP245and SSP885), landslide hazard is likely to increase up to two times on averagein the lower Himalayan regions while remaining the same in the middle Himalayanregion whilst decreasing slightly in the upper Himalayan region areas.</description><author>Ashok Dahal, Raphaël Huser, Luigi Lombardo</author><pubDate>Thu, 25 Jan 2024 14:48:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14210v1</guid></item><item><title>Exploiting Liver CT scans in Colorectal Carcinoma genomics mutation classification</title><link>http://arxiv.org/abs/2401.14206v1</link><description>The liver is the most involved organ by distant metastasis in colon-rectalcancer (CRC) patients and it comes necessary to be aware of the mutationalstatus of the lesions to correctly design the best individual treatment. Sofar, efforts have been made in order to develop non-invasive and real-timemethods that permit the analysis of the whole tumor, using new artificialintelligence tools to analyze the tumor's image obtained by Computed Tomography(CT) scan. In order to address the current medical workflow, that is biopsyanalysis-based, we propose the first DeepLearning-based exploration, to ourknowledge, of such classification approach from the patient medical imaging. Wepropose i) a solid pipeline for managing undersized datasets of available CTscans and ii) a baseline study for genomics mutation diagnosis support forpreemptive patient follow-up. Our method is able to identify CRC RAS mutationfamily from CT images with 0.73 F1 score.</description><author>Daniele Perlo, Luca Berton, Alessia Delpiano, Francesca Menchini, Stefano Tibaldi, Marco Grosso, Paolo Fonio</author><pubDate>Thu, 25 Jan 2024 14:40:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14206v1</guid></item><item><title>Not All Tasks Are Equally Difficult: Multi-Task Deep Reinforcement Learning with Dynamic Depth Routing</title><link>http://arxiv.org/abs/2312.14472v2</link><description>Multi-task reinforcement learning endeavors to accomplish a set of differenttasks with a single policy. To enhance data efficiency by sharing parametersacross multiple tasks, a common practice segments the network into distinctmodules and trains a routing network to recombine these modules intotask-specific policies. However, existing routing approaches employ a fixednumber of modules for all tasks, neglecting that tasks with varyingdifficulties commonly require varying amounts of knowledge. This work presentsa Dynamic Depth Routing (D2R) framework, which learns strategic skipping ofcertain intermediate modules, thereby flexibly choosing different numbers ofmodules for each task. Under this framework, we further introduce a ResRoutingmethod to address the issue of disparate routing paths between behavior andtarget policies during off-policy training. In addition, we design an automaticroute-balancing mechanism to encourage continued routing exploration forunmastered tasks without disturbing the routing of mastered ones. We conductextensive experiments on various robotics manipulation tasks in the Meta-Worldbenchmark, where D2R achieves state-of-the-art performance with significantlyimproved learning efficiency.</description><author>Jinmin He, Kai Li, Yifan Zang, Haobo Fu, Qiang Fu, Junliang Xing, Jian Cheng</author><pubDate>Thu, 25 Jan 2024 14:35:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14472v2</guid></item><item><title>What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition</title><link>http://arxiv.org/abs/2401.12756v2</link><description>The knowledge encapsulated in a model is the core factor determining itsfinal performance on downstream tasks. Much research in NLP has focused onefficient methods for storing and adapting different types of knowledge, e.g.,in dedicated modularized structures, and on how to effectively combine these,e.g., by learning additional parameters. However, given the many possibleoptions, a thorough understanding of the mechanisms involved in thesecompositions is missing, and hence it remains unclear which strategies toutilize. To address this research gap, we propose a novel framework forzero-shot module composition, which encompasses existing and some novelvariations for selecting, weighting, and combining parameter modules under asingle unified notion. Focusing on the scenario of domain knowledge and adapterlayers, our framework provides a systematic unification of concepts, allowingus to conduct the first comprehensive benchmarking study of various zero-shotknowledge composition strategies. In particular, we test two module combinationmethods and five selection and weighting strategies for their effectiveness andefficiency in an extensive experimental setup. Our results highlight theefficacy of ensembling but also hint at the power of simple thoughoften-ignored weighting methods. Further in-depth analyses allow us tounderstand the role of weighting vs. top-k selection, and show that, to acertain extent, the performance of adapter composition can even be predicted.</description><author>Carolin Holtermann, Markus Frohmann, Navid Rekabsaz, Anne Lauscher</author><pubDate>Thu, 25 Jan 2024 14:32:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12756v2</guid></item><item><title>MTRGL:Effective Temporal Correlation Discerning through Multi-modal Temporal Relational Graph Learning</title><link>http://arxiv.org/abs/2401.14199v1</link><description>In this study, we explore the synergy of deep learning and financial marketapplications, focusing on pair trading. This market-neutral strategy isintegral to quantitative finance and is apt for advanced deep-learningtechniques. A pivotal challenge in pair trading is discerning temporalcorrelations among entities, necessitating the integration of diverse datamodalities. Addressing this, we introduce a novel framework, Multi-modalTemporal Relation Graph Learning (MTRGL). MTRGL combines time series data anddiscrete features into a temporal graph and employs a memory-based temporalgraph neural network. This approach reframes temporal correlationidentification as a temporal graph link prediction task, which has shownempirical success. Our experiments on real-world datasets confirm the superiorperformance of MTRGL, emphasizing its promise in refining automated pairtrading strategies.</description><author>Junwei Su, Shan Wu, Jinhui Li</author><pubDate>Thu, 25 Jan 2024 14:21:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14199v1</guid></item><item><title>DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence</title><link>http://arxiv.org/abs/2401.14196v1</link><description>The rapid development of large language models has revolutionized codeintelligence in software development. However, the predominance ofclosed-source models has restricted extensive research and development. Toaddress this, we introduce the DeepSeek-Coder series, a range of open-sourcecode models with sizes from 1.3B to 33B, trained from scratch on 2 trilliontokens. These models are pre-trained on a high-quality project-level codecorpus and employ a fill-in-the-blank task with a 16K window to enhance codegeneration and infilling. Our extensive evaluations demonstrate thatDeepSeek-Coder not only achieves state-of-the-art performance among open-sourcecode models across multiple benchmarks but also surpasses existingclosed-source models like Codex and GPT-3.5. Furthermore, DeepSeek-Coder modelsare under a permissive license that allows for both research and unrestrictedcommercial use.</description><author>Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen, Xiao Bi, Y. Wu, Y. K. Li, Fuli Luo, Yingfei Xiong, Wenfeng Liang</author><pubDate>Thu, 25 Jan 2024 14:17:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14196v1</guid></item></channel></rss>