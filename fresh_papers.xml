<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 22 Jan 2024 06:00:20 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data</title><link>http://arxiv.org/abs/2401.10891v1</link><description>This work presents Depth Anything, a highly practical solution for robustmonocular depth estimation. Without pursuing novel technical modules, we aim tobuild a simple yet powerful foundation model dealing with any images under anycircumstances. To this end, we scale up the dataset by designing a data engineto collect and automatically annotate large-scale unlabeled data (~62M), whichsignificantly enlarges the data coverage and thus is able to reduce thegeneralization error. We investigate two simple yet effective strategies thatmake data scaling-up promising. First, a more challenging optimization targetis created by leveraging data augmentation tools. It compels the model toactively seek extra visual knowledge and acquire robust representations.Second, an auxiliary supervision is developed to enforce the model to inheritrich semantic priors from pre-trained encoders. We evaluate its zero-shotcapabilities extensively, including six public datasets and randomly capturedphotos. It demonstrates impressive generalization ability. Further, throughfine-tuning it with metric depth information from NYUv2 and KITTI, new SOTAsare set. Our better depth model also results in a better depth-conditionedControlNet. Our models are released athttps://github.com/LiheYoung/Depth-Anything.</description><author>Lihe Yang, Bingyi Kang, Zilong Huang, Xiaogang Xu, Jiashi Feng, Hengshuang Zhao</author><pubDate>Fri, 19 Jan 2024 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10891v1</guid></item><item><title>Event detection from novel data sources: Leveraging satellite imagery alongside GPS traces</title><link>http://arxiv.org/abs/2401.10890v1</link><description>Rapid identification and response to breaking events, particularly those thatpose a threat to human life such as natural disasters or conflicts, is ofparamount importance. The prevalence of mobile devices and the ubiquity ofnetwork connectivity has generated a massive amount of temporally- andspatially-stamped data. Numerous studies have used mobile data to deriveindividual human mobility patterns for various applications. Similarly, theincreasing number of orbital satellites has made it easier to gatherhigh-resolution images capturing a snapshot of a geographical area in sub-dailytemporal frequency. We propose a novel data fusion methodology integratingsatellite imagery with privacy-enhanced mobile data to augment the eventinference task, whether in real-time or historical. In the absence of boots onthe ground, mobile data is able to give an approximation of human mobility,proximity to one another, and the built environment. On the other hand,satellite imagery can provide visual information on physical changes to thebuilt and natural environment. The expected use cases for our methodologyinclude small-scale disaster detection (i.e., tornadoes, wildfires, and floods)in rural regions, search and rescue operation augmentation for lost hikers inremote wilderness areas, and identification of active conflict areas andpopulation displacement in war-torn states. Our implementation is open-sourceon GitHub: https://github.com/ekinugurel/SatMobFusion.</description><author>Ekin Ugurel, Steffen Coenen, Minda Zhou Chen, Cynthia Chen</author><pubDate>Fri, 19 Jan 2024 18:59:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10890v1</guid></item><item><title>Synthesizing Moving People with 3D Control</title><link>http://arxiv.org/abs/2401.10889v1</link><description>In this paper, we present a diffusion model-based framework for animatingpeople from a single image for a given target 3D motion sequence. Our approachhas two core components: a) learning priors about invisible parts of the humanbody and clothing, and b) rendering novel body poses with proper clothing andtexture. For the first part, we learn an in-filling diffusion model tohallucinate unseen parts of a person given a single image. We train this modelon texture map space, which makes it more sample-efficient since it isinvariant to pose and viewpoint. Second, we develop a diffusion-based renderingpipeline, which is controlled by 3D human poses. This produces realisticrenderings of novel poses of the person, including clothing, hair, andplausible in-filling of unseen regions. This disentangled approach allows ourmethod to generate a sequence of images that are faithful to the target motionin the 3D pose and, to the input image in terms of visual similarity. Inaddition to that, the 3D control allows various synthetic camera trajectoriesto render a person. Our experiments show that our method is resilient ingenerating prolonged motions and varied challenging and complex poses comparedto prior methods. Please check our website for more details:https://boyiliee.github.io/3DHM.github.io/.</description><author>Boyi Li, Jathushan Rajasegaran, Yossi Gandelsman, Alexei A. Efros, Jitendra Malik</author><pubDate>Fri, 19 Jan 2024 18:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10889v1</guid></item><item><title>SCENES: Subpixel Correspondence Estimation With Epipolar Supervision</title><link>http://arxiv.org/abs/2401.10886v1</link><description>Extracting point correspondences from two or more views of a scene is afundamental computer vision problem with particular importance for relativecamera pose estimation and structure-from-motion. Existing local featurematching approaches, trained with correspondence supervision on large-scaledatasets, obtain highly-accurate matches on the test sets. However, they do notgeneralise well to new datasets with different characteristics to those theywere trained on, unlike classic feature extractors. Instead, they requirefinetuning, which assumes that ground-truth correspondences or ground-truthcamera poses and 3D structure are available. We relax this assumption byremoving the requirement of 3D structure, e.g., depth maps or point clouds, andonly require camera pose information, which can be obtained from odometry. Wedo so by replacing correspondence losses with epipolar losses, which encourageputative matches to lie on the associated epipolar line. While weaker thancorrespondence supervision, we observe that this cue is sufficient forfinetuning existing models on new data. We then further relax the assumption ofknown camera poses by using pose estimates in a novel bootstrapping approach.We evaluate on highly challenging datasets, including an indoor drone datasetand an outdoor smartphone camera dataset, and obtain state-of-the-art resultswithout strong supervision.</description><author>Dominik A. Kloepfer, Jo√£o F. Henriques, Dylan Campbell</author><pubDate>Fri, 19 Jan 2024 18:57:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10886v1</guid></item><item><title>NeRF Revisited: Fixing Quadrature Instability in Volume Rendering</title><link>http://arxiv.org/abs/2310.20685v2</link><description>Neural radiance fields (NeRF) rely on volume rendering to synthesize novelviews. Volume rendering requires evaluating an integral along each ray, whichis numerically approximated with a finite sum that corresponds to the exactintegral along the ray under piecewise constant volume density. As aconsequence, the rendered result is unstable w.r.t. the choice of samples alongthe ray, a phenomenon that we dub quadrature instability. We propose amathematically principled solution by reformulating the sample-based renderingequation so that it corresponds to the exact integral under piecewise linearvolume density. This simultaneously resolves multiple issues: conflicts betweensamples along different rays, imprecise hierarchical sampling, andnon-differentiability of quantiles of ray termination distances w.r.t. modelparameters. We demonstrate several benefits over the classical sample-basedrendering equation, such as sharper textures, better geometric reconstruction,and stronger depth supervision. Our proposed formulation can be also be used asa drop-in replacement to the volume rendering equation of existing NeRF-basedmethods. Our project page can be found at pl-nerf.github.io.</description><author>Mikaela Angelina Uy, Kiyohiro Nakayama, Guandao Yang, Rahul Krishna Thomas, Leonidas Guibas, Ke Li</author><pubDate>Fri, 19 Jan 2024 18:53:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20685v2</guid></item><item><title>Reinforcement learning for question answering in programming domain using public community scoring as a human feedback</title><link>http://arxiv.org/abs/2401.10882v1</link><description>In this study, we investigate the enhancement of the GPT Neo 125M performancein Community Question Answering (CQA) with a focus on programming, through theintegration of Reinforcement Learning from Human Feedback (RLHF) and theutilization of scores from Stack Overflow. Two distinct reward model trainingstrategies are employed for fine-tuning with Proximal Policy Optimization(PPO). Notably, the improvements in performance achieved through this methodare comparable to those of GPT Neo 2.7B parameter variant. Additionally, anauxiliary scoring mechanism is introduced, which demonstrates the limitationsof conventional linguistic metrics in evaluating responses in the programmingdomain. Through accurate analysis, this paper looks at the divergence betweentraditional linguistic metrics and our human-preferences-based reward model,underscoring the imperative for domain-specific evaluation methods. Byelucidating the complexities involved in applying RLHF to programming CQA andaccentuating the significance of context-aware evaluation, this studycontributes to the ongoing efforts in refining Large Language Models throughfocused human feedback.</description><author>Alexey Gorbatovski, Sergey Kovalchuk</author><pubDate>Fri, 19 Jan 2024 18:49:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10882v1</guid></item><item><title>The Cadaver in the Machine: The Social Practices of Measurement and Validation in Motion Capture Technology</title><link>http://arxiv.org/abs/2401.10877v1</link><description>Motion capture systems, used across various domains, make bodyrepresentations concrete through technical processes. We argue that themeasurement of bodies and the validation of measurements for motion capturesystems can be understood as social practices. By analyzing the findings of asystematic literature review (N=278) through the lens of social practicetheory, we show how these practices, and their varying attention to errors,become ingrained in motion capture design and innovation over time. Moreover,we show how contemporary motion capture systems perpetuate assumptions abouthuman bodies and their movements. We suggest that social practices ofmeasurement and validation are ubiquitous in the development of data- andsensor-driven systems more broadly, and provide this work as a basis forinvestigating hidden design assumptions and their potential negativeconsequences in human-computer interaction.</description><author>Emma Harvey, Hauke Sandhaus, Abigail Z. Jacobs, Emanuel Moss, Mona Sloane</author><pubDate>Fri, 19 Jan 2024 18:41:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10877v1</guid></item><item><title>GBSD: Generative Bokeh with Stage Diffusion</title><link>http://arxiv.org/abs/2306.08251v2</link><description>The bokeh effect is an artistic technique that blurs out-of-focus areas in aphotograph and has gained interest due to recent developments in text-to-imagesynthesis and the ubiquity of smart-phone cameras and photo-sharing apps. Priorwork on rendering bokeh effects have focused on post hoc image manipulation toproduce similar blurring effects in existing photographs using classicalcomputer graphics or neural rendering techniques, but have either depthdiscontinuity artifacts or are restricted to reproducing bokeh effects that arepresent in the training data. More recent diffusion based models can synthesizeimages with an artistic style, but either require the generation ofhigh-dimensional masks, expensive fine-tuning, or affect global imagecharacteristics. In this paper, we present GBSD, the first generativetext-to-image model that synthesizes photorealistic images with a bokeh style.Motivated by how image synthesis occurs progressively in diffusion models, ourapproach combines latent diffusion models with a 2-stage conditioning algorithmto render bokeh effects on semantically defined objects. Since we can focus theeffect on objects, this semantic bokeh effect is more versatile than classicalrendering techniques. We evaluate GBSD both quantitatively and qualitativelyand demonstrate its ability to be applied in both text-to-image andimage-to-image settings.</description><author>Jieren Deng, Xin Zhou, Hao Tian, Zhihong Pan, Derek Aguiar</author><pubDate>Fri, 19 Jan 2024 18:35:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08251v2</guid></item><item><title>Applications of flow models to the generation of correlated lattice QCD ensembles</title><link>http://arxiv.org/abs/2401.10874v1</link><description>Machine-learned normalizing flows can be used in the context of latticequantum field theory to generate statistically correlated ensembles of latticegauge fields at different action parameters. This work demonstrates how thesecorrelations can be exploited for variance reduction in the computation ofobservables. Three different proof-of-concept applications are demonstratedusing a novel residual flow architecture: continuum limits of gauge theories,the mass dependence of QCD observables, and hadronic matrix elements based onthe Feynman-Hellmann approach. In all three cases, it is shown that statisticaluncertainties are significantly reduced when machine-learned flows areincorporated as compared with the same calculations performed with uncorrelatedensembles or direct reweighting.</description><author>Ryan Abbott, Aleksandar Botev, Denis Boyda, Daniel C. Hackett, Gurtej Kanwar, S√©bastien Racani√®re, Danilo J. Rezende, Fernando Romero-L√≥pez, Phiala E. Shanahan, Julian M. Urban</author><pubDate>Fri, 19 Jan 2024 18:33:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10874v1</guid></item><item><title>Optimal Sets and Solution Paths of ReLU Networks</title><link>http://arxiv.org/abs/2306.00119v2</link><description>We develop an analytical framework to characterize the set of optimal ReLUneural networks by reformulating the non-convex training problem as a convexprogram. We show that the global optima of the convex parameterization aregiven by a polyhedral set and then extend this characterization to the optimalset of the non-convex training objective. Since all stationary points of theReLU training problem can be represented as optima of sub-sampled convexprograms, our work provides a general expression for all critical points of thenon-convex objective. We then leverage our results to provide an optimalpruning algorithm for computing minimal networks, establish conditions for theregularization path of ReLU networks to be continuous, and develop sensitivityresults for minimal ReLU networks.</description><author>Aaron Mishkin, Mert Pilanci</author><pubDate>Fri, 19 Jan 2024 18:30:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00119v2</guid></item><item><title>Smooth and Stepwise Self-Distillation for Object Detection</title><link>http://arxiv.org/abs/2303.05015v2</link><description>Distilling the structured information captured in feature maps hascontributed to improved results for object detection tasks, but requirescareful selection of baseline architectures and substantial pre-training.Self-distillation addresses these limitations and has recently achievedstate-of-the-art performance for object detection despite making severalsimplifying architectural assumptions. Building on this work, we propose Smoothand Stepwise Self-Distillation (SSSD) for object detection. Our SSSDarchitecture forms an implicit teacher from object labels and a feature pyramidnetwork backbone to distill label-annotated feature maps using Jensen-Shannondistance, which is smoother than distillation losses used in prior work. Weadditionally add a distillation coefficient that is adaptively configured basedon the learning rate. We extensively benchmark SSSD against a baseline and twostate-of-the-art object detector architectures on the COCO dataset by varyingthe coefficients and backbone and detector networks. We demonstrate that SSSDachieves higher average precision in most experimental settings, is robust to awide range of coefficients, and benefits from our stepwise distillationprocedure.</description><author>Jieren Deng, Xin Zhou, Hao Tian, Zhihong Pan, Derek Aguiar</author><pubDate>Fri, 19 Jan 2024 18:23:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05015v2</guid></item><item><title>Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning</title><link>http://arxiv.org/abs/2401.10862v1</link><description>Large Language Models (LLMs) are vulnerable to `Jailbreaking' prompts, a typeof attack that can coax these models into generating harmful and illegalcontent. In this paper, we show that pruning up to 20% of LLM parametersmarkedly increases their resistance to such attacks without additional trainingand without sacrificing their performance in standard benchmarks. Intriguingly,we discovered that the enhanced safety observed post-pruning correlates to theinitial safety training level of the model, hinting that the effect of pruningcould be more general and may hold for other LLM behaviors beyond safety.Additionally, we introduce a curated dataset of 225 harmful tasks across fivecategories, inserted into ten different Jailbreaking prompts, showing thatpruning aids LLMs in concentrating attention on task-relevant tokens injailbreaking prompts. Lastly, our experiments reveal that the prominent chatmodels, such as LLaMA-2 Chat, Vicuna, and Mistral Instruct exhibit highsusceptibility to jailbreaking attacks, with some categories achieving nearly70-100% success rate. These insights underline the potential of pruning as ageneralizable approach for improving LLM safety, reliability, and potentiallyother desired behaviors.</description><author>Adib Hasan, Ileana Rugina, Alex Wang</author><pubDate>Fri, 19 Jan 2024 18:05:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10862v1</guid></item><item><title>Ensembler: Combating model inversion attacks using model ensemble during collaborative inference</title><link>http://arxiv.org/abs/2401.10859v1</link><description>Deep learning models have exhibited remarkable performance across variousdomains. Nevertheless, the burgeoning model sizes compel edge devices tooffload a significant portion of the inference process to the cloud. While thispractice offers numerous advantages, it also raises critical concerns regardinguser data privacy. In scenarios where the cloud server's trustworthiness is inquestion, the need for a practical and adaptable method to safeguard dataprivacy becomes imperative. In this paper, we introduce Ensembler, anextensible framework designed to substantially increase the difficulty ofconducting model inversion attacks for adversarial parties. Ensembler leveragesmodel ensembling on the adversarial server, running in parallel with existingapproaches that introduce perturbations to sensitive data during colloborativeinference. Our experiments demonstrate that when combined with even basicGaussian noise, Ensembler can effectively shield images from reconstructionattacks, achieving recognition levels that fall below human performance in somestrict settings, significantly outperforming baseline methods lacking theEnsembler framework.</description><author>Dancheng Liu, Jinjun Xiong</author><pubDate>Fri, 19 Jan 2024 18:03:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10859v1</guid></item><item><title>Motion Consistency Loss for Monocular Visual Odometry with Attention-Based Deep Learning</title><link>http://arxiv.org/abs/2401.10857v1</link><description>Deep learning algorithms have driven expressive progress in many complextasks. The loss function is a core component of deep learning techniques,guiding the learning process of neural networks. This paper contributes byintroducing a consistency loss for visual odometry with deep learning-basedapproaches. The motion consistency loss explores repeated motions that appearin consecutive overlapped video clips. Experimental results show that ourapproach increased the performance of a model on the KITTI odometry benchmark.</description><author>Andr√© O. Fran√ßani, Marcos R. O. A. Maximo</author><pubDate>Fri, 19 Jan 2024 18:00:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10857v1</guid></item><item><title>Advancements in eHealth Data Analytics through Natural Language Processing and Deep Learning</title><link>http://arxiv.org/abs/2401.10850v1</link><description>The healthcare environment is commonly referred to as "information-rich" butalso "knowledge poor". Healthcare systems collect huge amounts of data fromvarious sources: lab reports, medical letters, logs of medical tools orprograms, medical prescriptions, etc. These massive sets of data can providegreat knowledge and information that can improve the medical services, andoverall the healthcare domain, such as disease prediction by analyzing thepatient's symptoms or disease prevention, by facilitating the discovery ofbehavioral factors for diseases. Unfortunately, only a relatively small volumeof the textual eHealth data is processed and interpreted, an important factorbeing the difficulty in efficiently performing Big Data operations. In themedical field, detecting domain-specific multi-word terms is a crucial task asthey can define an entire concept with a few words. A term can be defined as alinguistic structure or a concept, and it is composed of one or more words witha specific meaning to a domain. All the terms of a domain create itsterminology. This chapter offers a critical study of the current, mostperformant solutions for analyzing unstructured (image and textual) eHealthdata. This study also provides a comparison of the current Natural LanguageProcessing and Deep Learning techniques in the eHealth context. Finally, weexamine and discuss some of the current issues, and we define a set of researchdirections in this area.</description><author>Elena-Simona Apostol, Ciprian-Octavian TruicƒÉ</author><pubDate>Fri, 19 Jan 2024 17:51:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10850v1</guid></item><item><title>Exploring the role of structure in a time constrained decision task</title><link>http://arxiv.org/abs/2401.10849v1</link><description>The structure of the basal ganglia is remarkably similar across a number ofspecies (often described in terms of direct, indirect and hyperdirect pathways)and is deeply involved in decision making and action selection. In thisarticle, we are interested in exploring the role of structure when solving adecision task while avoiding to make any strong assumption regarding the actualstructure. To do so, we exploit the echo state network paradigm that allows tosolve complex task based on a random architecture. Considering a temporaldecision task, the question is whether a specific structure allows for betterperformance and if so, whether this structure shares some similarity with thebasal ganglia. Our results highlight the advantage of having a slow (direct)and a fast (hyperdirect) pathway that allows to deal with late informationduring a decision making task.</description><author>Naomi Chaix-Eichel, Gautham Venugopal, Thomas Boraud, Nicolas P. Rougier</author><pubDate>Fri, 19 Jan 2024 17:48:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10849v1</guid></item><item><title>Source-Free and Image-Only Unsupervised Domain Adaptation for Category Level Object Pose Estimation</title><link>http://arxiv.org/abs/2401.10848v1</link><description>We consider the problem of source-free unsupervised category-level poseestimation from only RGB images to a target domain without any access to sourcedomain data or 3D annotations during adaptation. Collecting and annotatingreal-world 3D data and corresponding images is laborious, expensive, yetunavoidable process, since even 3D pose domain adaptation methods require 3Ddata in the target domain. We introduce 3DUDA, a method capable of adapting toa nuisance-ridden target domain without 3D or depth data. Our key insight stemsfrom the observation that specific object subparts remain stable acrossout-of-domain (OOD) scenarios, enabling strategic utilization of theseinvariant subcomponents for effective model updates. We represent objectcategories as simple cuboid meshes, and harness a generative model of neuralfeature activations modeled at each mesh vertex learnt using differentialrendering. We focus on individual locally robust mesh vertex features anditeratively update them based on their proximity to corresponding features inthe target domain even when the global pose is not correct. Our model is thentrained in an EM fashion, alternating between updating the vertex features andthe feature extractor. We show that our method simulates fine-tuning on aglobal pseudo-labeled dataset under mild assumptions, which converges to thetarget domain asymptotically. Through extensive empirical validation, includinga complex extreme UDA setup which combines real nuisances, synthetic noise, andocclusion, we demonstrate the potency of our simple approach in addressing thedomain shift challenge and significantly improving pose estimation accuracy.</description><author>Prakhar Kaushik, Aayush Mishra, Adam Kortylewski, Alan Yuille</author><pubDate>Fri, 19 Jan 2024 17:48:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10848v1</guid></item><item><title>Using LLMs to discover emerging coded antisemitic hate-speech emergence in extremist social media</title><link>http://arxiv.org/abs/2401.10841v1</link><description>Online hate speech proliferation has created a difficult problem for socialmedia platforms. A particular challenge relates to the use of coded language bygroups interested in both creating a sense of belonging for its users andevading detection. Coded language evolves quickly and its use varies over time.This paper proposes a methodology for detecting emerging coded hate-ladenterminology. The methodology is tested in the context of online antisemiticdiscourse. The approach considers posts scraped from social media platforms,often used by extremist users. The posts are scraped using seed expressionsrelated to previously known discourse of hatred towards Jews. The method beginsby identifying the expressions most representative of each post and calculatingtheir frequency in the whole corpus. It filters out grammatically incoherentexpressions as well as previously encountered ones so as to focus on emergentwell-formed terminology. This is followed by an assessment of semanticsimilarity to known antisemitic terminology using a fine-tuned large languagemodel, and subsequent filtering out of the expressions that are too distantfrom known expressions of hatred. Emergent antisemitic expressions containingterms clearly relating to Jewish topics are then removed to return only codedexpressions of hatred.</description><author>Dhanush Kikkisetti, Raza Ul Mustafa, Wendy Melillo, Roberto Corizzo, Zois Boukouvalas, Jeff Gill, Nathalie Japkowicz</author><pubDate>Fri, 19 Jan 2024 17:40:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10841v1</guid></item><item><title>LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models</title><link>http://arxiv.org/abs/2309.14393v2</link><description>The carbon footprint associated with large language models (LLMs) is asignificant concern, encompassing emissions from their training, inference,experimentation, and storage processes, including operational and embodiedcarbon emissions. An essential aspect is accurately estimating the carbonimpact of emerging LLMs even before their training, which heavily relies on GPUusage. Existing studies have reported the carbon footprint of LLM training, butonly one tool, mlco2, can predict the carbon footprint of new neural networksprior to physical training. However, mlco2 has several serious limitations. Itcannot extend its estimation to dense or mixture-of-experts (MoE) LLMs,disregards critical architectural parameters, focuses solely on GPUs, andcannot model embodied carbon footprints. Addressing these gaps, we introduce\textit{\carb}, an end-to-end carbon footprint projection model designed forboth dense and MoE LLMs. Compared to mlco2, \carb~significantly enhances theaccuracy of carbon footprint estimations for various LLMs. The source code isreleased at \url{https://github.com/SotaroKaneda/MLCarbon}.</description><author>Ahmad Faiz, Sotaro Kaneda, Ruhan Wang, Rita Osi, Prateek Sharma, Fan Chen, Lei Jiang</author><pubDate>Fri, 19 Jan 2024 17:33:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14393v2</guid></item><item><title>Choreographer: Learning and Adapting Skills in Imagination</title><link>http://arxiv.org/abs/2211.13350v2</link><description>Unsupervised skill learning aims to learn a rich repertoire of behaviorswithout external supervision, providing artificial agents with the ability tocontrol and influence the environment. However, without appropriate knowledgeand exploration, skills may provide control only over a restricted area of theenvironment, limiting their applicability. Furthermore, it is unclear how toleverage the learned skill behaviors for adapting to downstream tasks in adata-efficient manner. We present Choreographer, a model-based agent thatexploits its world model to learn and adapt skills in imagination. Our methoddecouples the exploration and skill learning processes, being able to discoverskills in the latent state space of the model. During adaptation, the agentuses a meta-controller to evaluate and adapt the learned skills efficiently bydeploying them in parallel in imagination. Choreographer is able to learnskills both from offline data, and by collecting data simultaneously with anexploration policy. The skills can be used to effectively adapt to downstreamtasks, as we show in the URL benchmark, where we outperform previous approachesfrom both pixels and states inputs. The learned skills also explore theenvironment thoroughly, finding sparse rewards more frequently, as shown ingoal-reaching tasks from the DMC Suite and Meta-World. Website and code:https://skillchoreographer.github.io/</description><author>Pietro Mazzaglia, Tim Verbelen, Bart Dhoedt, Alexandre Lacoste, Sai Rajeswar</author><pubDate>Fri, 19 Jan 2024 17:33:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.13350v2</guid></item><item><title>Weathering Ongoing Uncertainty: Learning and Planning in a Time-Varying Partially Observable Environment</title><link>http://arxiv.org/abs/2312.03263v2</link><description>Optimal decision-making presents a significant challenge for autonomoussystems operating in uncertain, stochastic and time-varying environments.Environmental variability over time can significantly impact the system'soptimal decision making strategy for mission completion. To model suchenvironments, our work combines the previous notion of Time-Varying MarkovDecision Processes (TVMDP) with partial observability and introducesTime-Varying Partially Observable Markov Decision Processes (TV-POMDP). Wepropose a two-pronged approach to accurately estimate and plan within theTV-POMDP: 1) Memory Prioritized State Estimation (MPSE), which leveragesweighted memory to provide more accurate time-varying transition estimates; and2) an MPSE-integrated planning strategy that optimizes long-term rewards whileaccounting for temporal constraint. We validate the proposed framework andalgorithms using simulations and hardware, with robots exploring a partiallyobservable, time-varying environments. Our results demonstrate superiorperformance over standard methods, highlighting the framework's effectivenessin stochastic, uncertain, time-varying domains.</description><author>Gokul Puthumanaillam, Xiangyu Liu, Negar Mehr, Melkior Ornik</author><pubDate>Fri, 19 Jan 2024 17:33:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03263v2</guid></item><item><title>Understanding Video Transformers via Universal Concept Discovery</title><link>http://arxiv.org/abs/2401.10831v1</link><description>This paper studies the problem of concept-based interpretability oftransformer representations for videos. Concretely, we seek to explain thedecision-making process of video transformers based on high-level,spatiotemporal concepts that are automatically discovered. Prior research onconcept-based interpretability has concentrated solely on image-level tasks.Comparatively, video models deal with the added temporal dimension, increasingcomplexity and posing challenges in identifying dynamic concepts over time. Inthis work, we systematically address these challenges by introducing the firstVideo Transformer Concept Discovery (VTCD) algorithm. To this end, we proposean efficient approach for unsupervised identification of units of videotransformer representations - concepts, and ranking their importance to theoutput of a model. The resulting concepts are highly interpretable, revealingspatio-temporal reasoning mechanisms and object-centric representations inunstructured video models. Performing this analysis jointly over a diverse setof supervised and self-supervised representations, we discover that some ofthese mechanism are universal in video transformers. Finally, we demonstratethat VTCDcan be used to improve model performance for fine-grained tasks.</description><author>Matthew Kowal, Achal Dave, Rares Ambrus, Adrien Gaidon, Konstantinos G. Derpanis, Pavel Tokmakov</author><pubDate>Fri, 19 Jan 2024 17:27:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10831v1</guid></item><item><title>A survey on recent advances in named entity recognition</title><link>http://arxiv.org/abs/2401.10825v1</link><description>Named Entity Recognition seeks to extract substrings within a text that namereal-world objects and to determine their type (for example, whether they referto persons or organizations). In this survey, we first present an overview ofrecent popular approaches, but we also look at graph- and transformer- basedmethods including Large Language Models (LLMs) that have not had much coveragein other surveys. Second, we focus on methods designed for datasets with scarceannotations. Third, we evaluate the performance of the main NER implementationson a variety of datasets with differing characteristics (as regards theirdomain, their size, and their number of classes). We thus provide a deepcomparison of algorithms that are never considered together. Our experimentsshed some light on how the characteristics of datasets affect the behavior ofthe methods that we compare.</description><author>Imed Keraghel, Stanislas Morbieu, Mohamed Nadif</author><pubDate>Fri, 19 Jan 2024 17:21:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10825v1</guid></item><item><title>ActAnywhere: Subject-Aware Video Background Generation</title><link>http://arxiv.org/abs/2401.10822v1</link><description>Generating video background that tailors to foreground subject motion is animportant problem for the movie industry and visual effects community. Thistask involves synthesizing background that aligns with the motion andappearance of the foreground subject, while also complies with the artist'screative intention. We introduce ActAnywhere, a generative model that automatesthis process which traditionally requires tedious manual efforts. Our modelleverages the power of large-scale video diffusion models, and is specificallytailored for this task. ActAnywhere takes a sequence of foreground subjectsegmentation as input and an image that describes the desired scene ascondition, to produce a coherent video with realistic foreground-backgroundinteractions while adhering to the condition frame. We train our model on alarge-scale dataset of human-scene interaction videos. Extensive evaluationsdemonstrate the superior performance of our model, significantly outperformingbaselines. Moreover, we show that ActAnywhere generalizes to diverseout-of-distribution samples, including non-human subjects. Please visit ourproject webpage at https://actanywhere.github.io.</description><author>Boxiao Pan, Zhan Xu, Chun-Hao Paul Huang, Krishna Kumar Singh, Yang Zhou, Leonidas J. Guibas, Jimei Yang</author><pubDate>Fri, 19 Jan 2024 17:16:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10822v1</guid></item><item><title>SAGE: Smart home Agent with Grounded Execution</title><link>http://arxiv.org/abs/2311.00772v2</link><description>The common sense reasoning abilities and vast general knowledge of LargeLanguage Models (LLMs) make them a natural fit for interpreting user requestsin a Smart Home assistant context. LLMs, however, lack specific knowledge aboutthe user and their home limit their potential impact. SAGE (Smart Home Agentwith Grounded Execution), overcomes these and other limitations by using ascheme in which a user request triggers an LLM-controlled sequence of discreteactions. These actions can be used to retrieve information, interact with theuser, or manipulate device states. SAGE controls this process through adynamically constructed tree of LLM prompts, which help it decide which actionto take next, whether an action was successful, and when to terminate theprocess. The SAGE action set augments an LLM's capabilities to support some ofthe most critical requirements for a Smart Home assistant. These include:flexible and scalable user preference management ("is my team playingtonight?"), access to any smart device's full functionality withoutdevice-specific code via API reading "turn down the screen brightness on mydryer", persistent device state monitoring ("remind me to throw out the milkwhen I open the fridge"), natural device references using only a photo of theroom ("turn on the light on the dresser"), and more. We introduce a benchmarkof 50 new and challenging smart home tasks where SAGE achieves a 75% successrate, significantly outperforming existing LLM-enabled baselines (30% successrate).</description><author>Dmitriy Rivkin, Francois Hogan, Amal Feriani, Abhisek Konar, Adam Sigal, Steve Liu, Greg Dudek</author><pubDate>Fri, 19 Jan 2024 17:14:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00772v2</guid></item><item><title>Towards Robust Offline Reinforcement Learning under Diverse Data Corruption</title><link>http://arxiv.org/abs/2310.12955v2</link><description>Offline reinforcement learning (RL) presents a promising approach forlearning reinforced policies from offline datasets without the need for costlyor unsafe interactions with the environment. However, datasets collected byhumans in real-world environments are often noisy and may even be maliciouslycorrupted, which can significantly degrade the performance of offline RL. Inthis work, we first investigate the performance of current offline RLalgorithms under comprehensive data corruption, including states, actions,rewards, and dynamics. Our extensive experiments reveal that implicitQ-learning (IQL) demonstrates remarkable resilience to data corruption amongvarious offline RL algorithms. Furthermore, we conduct both empirical andtheoretical analyses to understand IQL's robust performance, identifying itssupervised policy learning scheme as the key factor. Despite its relativerobustness, IQL still suffers from heavy-tail targets of Q functions underdynamics corruption. To tackle this challenge, we draw inspiration from robuststatistics to employ the Huber loss to handle the heavy-tailedness and utilizequantile estimators to balance penalization for corrupted data and learningstability. By incorporating these simple yet effective modifications into IQL,we propose a more robust offline RL approach named Robust IQL (RIQL). Extensiveexperiments demonstrate that RIQL exhibits highly robust performance whensubjected to diverse data corruption scenarios.</description><author>Rui Yang, Han Zhong, Jiawei Xu, Amy Zhang, Chongjie Zhang, Lei Han, Tong Zhang</author><pubDate>Fri, 19 Jan 2024 17:12:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12955v2</guid></item><item><title>Optimisation in Neurosymbolic Learning Systems</title><link>http://arxiv.org/abs/2401.10819v1</link><description>Neurosymbolic AI aims to integrate deep learning with symbolic AI. Thisintegration has many promises, such as decreasing the amount of data requiredto train a neural network, improving the explainability and interpretability ofanswers given by models and verifying the correctness of trained systems. Westudy neurosymbolic learning, where we have both data and background knowledgeexpressed using symbolic languages. How do we connect the symbolic and neuralcomponents to communicate this knowledge? One option is fuzzy reasoning, whichstudies degrees of truth. For example, being tall is not a binary concept.Instead, probabilistic reasoning studies the probability that something is trueor will happen. Our first research question studies how different forms offuzzy reasoning combine with learning. We find surprising results like aconnection to the Raven paradox stating we confirm "ravens are black" when weobserve a green apple. In this study, we did not use the background knowledgewhen we deployed our models after training. In our second research question, westudied how to use background knowledge in deployed models. We developed a newneural network layer based on fuzzy reasoning. Probabilistic reasoning is anatural fit for neural networks, which we usually train to be probabilistic.However, they are expensive to compute and do not scale well to large tasks. Inour third research question, we study how to connect probabilistic reasoningwith neural networks by sampling to estimate averages, while in the finalresearch question, we study scaling probabilistic neurosymbolic learning tomuch larger problems than before. Our insight is to train a neural network withsynthetic data to predict the result of probabilistic reasoning.</description><author>Emile van Krieken</author><pubDate>Fri, 19 Jan 2024 17:09:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10819v1</guid></item><item><title>Co-Pilot for Health: Personalized Algorithmic AI Nudging to Improve Health Outcomes</title><link>http://arxiv.org/abs/2401.10816v1</link><description>The ability to shape health behaviors of large populations automatically,across wearable types and disease conditions at scale has tremendous potentialto improve global health outcomes. We designed and implemented an AI drivenplatform for digital algorithmic nudging, enabled by a Graph-Neural Network(GNN) based Recommendation System, and granular health behavior data fromwearable fitness devices. Here we describe the efficacy results of thisplatform with its capabilities of personalized and contextual nudging to$n=84,764$ individuals over a 12-week period in Singapore. We statisticallyvalidated that participants in the target group who received such AI optimizeddaily nudges increased daily physical activity like step count by 6.17% ($p =3.09\times10^{-4}$) and weekly minutes of Moderate to Vigorous PhysicalActivity (MVPA) by 7.61% ($p = 1.16\times10^{-2}$), compared to matchedparticipants in control group who did not receive any nudges. Further, suchnudges were very well received, with a 13.1% of nudges sent being opened (openrate), and 11.7% of the opened nudges rated useful compared to 1.9% rated asnot useful thereby demonstrating significant improvement in population levelengagement metrics.</description><author>Jodi Chiam, Aloysius Lim, Cheryl Nott, Nicholas Mark, Ankur Teredesai, Sunil Shinde</author><pubDate>Fri, 19 Jan 2024 17:03:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10816v1</guid></item><item><title>RAD-DINO: Exploring Scalable Medical Image Encoders Beyond Text Supervision</title><link>http://arxiv.org/abs/2401.10815v1</link><description>Language-supervised pre-training has proven to be a valuable method forextracting semantically meaningful features from images, serving as afoundational element in multimodal systems within the computer vision andmedical imaging domains. However, resulting features are limited by theinformation contained within the text. This is particularly problematic inmedical imaging, where radiologists' written findings focus on specificobservations; a challenge compounded by the scarcity of paired imaging-textdata due to concerns over leakage of personal health information. In this work,we fundamentally challenge the prevailing reliance on language supervision forlearning general purpose biomedical imaging encoders. We introduce RAD-DINO, abiomedical image encoder pre-trained solely on unimodal biomedical imaging datathat obtains similar or greater performance than state-of-the-art biomedicallanguage supervised models on a diverse range of benchmarks. Specifically, thequality of learned representations is evaluated on standard imaging tasks(classification and semantic segmentation), and a vision-language alignmenttask (text report generation from images). To further demonstrate the drawbackof language supervision, we show that features from RAD-DINO correlate withother medical records (e.g., sex or age) better than language-supervisedmodels, which are generally not mentioned in radiology reports. Finally, weconduct a series of ablations determining the factors in RAD-DINO'sperformance; notably, we observe that RAD-DINO's downstream performance scaleswell with the quantity and diversity of training data, demonstrating thatimage-only supervision is a scalable approach for training a foundationalbiomedical image encoder.</description><author>Fernando P√©rez-Garc√≠a, Harshita Sharma, Sam Bond-Taylor, Kenza Bouzid, Valentina Salvatelli, Maximilian Ilse, Shruthi Bannur, Daniel C. Castro, Anton Schwaighofer, Matthew P. Lungren, Maria Wetscherek, Noel Codella, Stephanie L. Hyland, Javier Alvarez-Valle, Ozan Oktay</author><pubDate>Fri, 19 Jan 2024 17:02:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10815v1</guid></item><item><title>INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges</title><link>http://arxiv.org/abs/2401.05273v2</link><description>This paper introduces INACIA (Instru\c{c}\~ao Assistida com Intelig\^enciaArtificial), a groundbreaking system designed to integrate Large LanguageModels (LLMs) into the operational framework of Brazilian Federal Court ofAccounts (TCU). The system automates various stages of case analysis, includingbasic information extraction, admissibility examination, Periculum in mora andFumus boni iuris analyses, and recommendations generation. Through a series ofexperiments, we demonstrate INACIA's potential in extracting relevantinformation from case documents, evaluating its legal plausibility, andformulating propositions for judicial decision-making. Utilizing a validationdataset alongside LLMs, our evaluation methodology presents an innovativeapproach to assessing system performance, correlating highly with humanjudgment. The results highlight INACIA's proficiency in handling complex legaltasks, indicating its suitability for augmenting efficiency and judicialfairness within legal systems. The paper also discusses potential enhancementsand future applications, positioning INACIA as a model for worldwide AIintegration in legal domains.</description><author>Jayr Pereira, Andre Assumpcao, Julio Trecenti, Luiz Airosa, Caio Lente, Jhonatan Cl√©to, Guilherme Dobins, Rodrigo Nogueira, Luis Mitchell, Roberto Lotufo</author><pubDate>Fri, 19 Jan 2024 16:57:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05273v2</guid></item><item><title>Simulation Based Bayesian Optimization</title><link>http://arxiv.org/abs/2401.10811v1</link><description>Bayesian Optimization (BO) is a powerful method for optimizing black-boxfunctions by combining prior knowledge with ongoing function evaluations. BOconstructs a probabilistic surrogate model of the objective function given thecovariates, which is in turn used to inform the selection of future evaluationpoints through an acquisition function. For smooth continuous search spaces,Gaussian Processes (GPs) are commonly used as the surrogate model as they offeranalytical access to posterior predictive distributions, thus facilitating thecomputation and optimization of acquisition functions. However, in complexscenarios involving optimizations over categorical or mixed covariate spaces,GPs may not be ideal. This paper introduces Simulation Based Bayesian Optimization (SBBO) as anovel approach to optimizing acquisition functions that only requires\emph{sampling-based} access to posterior predictive distributions. SBBO allowsthe use of surrogate probabilistic models tailored for combinatorial spaceswith discrete variables. Any Bayesian model in which posterior inference iscarried out through Markov chain Monte Carlo can be selected as the surrogatemodel in SBBO. In applications involving combinatorial optimization, wedemonstrate empirically the effectiveness of SBBO method using various choicesof surrogate models.</description><author>Roi Naveiro, Becky Tang</author><pubDate>Fri, 19 Jan 2024 16:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10811v1</guid></item><item><title>Neglected Hessian component explains mysteries in Sharpness regularization</title><link>http://arxiv.org/abs/2401.10809v1</link><description>Recent work has shown that methods like SAM which either explicitly orimplicitly penalize second order information can improve generalization in deeplearning. Seemingly similar methods like weight noise and gradient penaltiesoften fail to provide such benefits. We show that these differences can beexplained by the structure of the Hessian of the loss. First, we show that acommon decomposition of the Hessian can be quantitatively interpreted asseparating the feature exploitation from feature exploration. The featureexploration, which can be described by the Nonlinear Modeling Error matrix(NME), is commonly neglected in the literature since it vanishes atinterpolation. Our work shows that the NME is in fact important as it canexplain why gradient penalties are sensitive to the choice of activationfunction. Using this insight we design interventions to improve performance. Wealso provide evidence that challenges the long held equivalence of weight noiseand gradient penalties. This equivalence relies on the assumption that the NMEcan be ignored, which we find does not hold for modern networks since theyinvolve significant feature learning. We find that regularizing featureexploitation but not feature exploration yields performance similar to gradientpenalties.</description><author>Yann N. Dauphin, Atish Agarwala, Hossein Mobahi</author><pubDate>Fri, 19 Jan 2024 16:52:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10809v1</guid></item><item><title>Algorithmic Assistance with Recommendation-Dependent Preferences</title><link>http://arxiv.org/abs/2208.07626v3</link><description>When an algorithm provides risk assessments, we typically think of them ashelpful inputs to human decisions, such as when risk scores are presented tojudges or doctors. However, a decision-maker may not only react to theinformation provided by the algorithm. The decision-maker may also view thealgorithmic recommendation as a default action, making it costly for them todeviate, such as when a judge is reluctant to overrule a high-risk assessmentfor a defendant or a doctor fears the consequences of deviating fromrecommended procedures. To address such unintended consequences of algorithmicassistance, we propose a principal-agent model of joint human-machinedecision-making. Within this model, we consider the effect and design ofalgorithmic recommendations when they affect choices not just by shiftingbeliefs, but also by altering preferences. We motivate this assumption frominstitutional factors, such as a desire to avoid audits, as well as fromwell-established models in behavioral science that predict loss aversionrelative to a reference point, which here is set by the algorithm. We show thatrecommendation-dependent preferences create inefficiencies where thedecision-maker is overly responsive to the recommendation. As a potentialremedy, we discuss algorithms that strategically withhold recommendations, andshow how they can improve the quality of final decisions.</description><author>Bryce McLaughlin, Jann Spiess</author><pubDate>Fri, 19 Jan 2024 16:52:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.07626v3</guid></item><item><title>How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?</title><link>http://arxiv.org/abs/2309.08565v2</link><description>Customizing machine translation models to comply with fine-grained attributessuch as formality has seen tremendous progress recently. However, currentapproaches mostly rely on at least some supervised data with attributeannotation. Data scarcity therefore remains a bottleneck to democratizing suchcustomization possibilities to a wider range of languages, lower-resource onesin particular. Given recent progress in pretrained massively multilingualtranslation models, we use them as a foundation to transfer the attributecontrolling capabilities to languages without supervised data. In this work, wepresent a comprehensive analysis of transferring attribute controllers based ona pretrained NLLB-200 model. We investigate both training- and inference-timecontrol techniques under various data scenarios, and uncover their relativestrengths and weaknesses in zero-shot performance and domain robustness. Weshow that both paradigms are complementary, as shown by consistent improvementson 5 zero-shot directions. Moreover, a human evaluation on a real low-resourcelanguage, Bengali, confirms our findings on zero-shot transfer to new targetlanguages. The code is$\href{https://github.com/dannigt/attribute-controller-transfer}{\text{here}}$.</description><author>Danni Liu, Jan Niehues</author><pubDate>Fri, 19 Jan 2024 16:48:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08565v2</guid></item><item><title>Learning to Visually Connect Actions and their Effects</title><link>http://arxiv.org/abs/2401.10805v1</link><description>In this work, we introduce the novel concept of visually Connecting Actionsand Their Effects (CATE) in video understanding. CATE can have applications inareas like task planning and learning from demonstration. We propose differentCATE-based task formulations, such as action selection and actionspecification, where video understanding models connect actions and effects atsemantic and fine-grained levels. We observe that different formulationsproduce representations capturing intuitive action properties. We also designvarious baseline models for action selection and action specification. Despitethe intuitive nature of the task, we observe that models struggle, and humansoutperform them by a large margin. The study aims to establish a foundation forfuture efforts, showcasing the flexibility and versatility of connectingactions and effects in video understanding, with the hope of inspiring advancedformulations and models.</description><author>Eric Peh, Paritosh Parmar, Basura Fernando</author><pubDate>Fri, 19 Jan 2024 16:48:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10805v1</guid></item><item><title>Estimation of AMOC transition probabilities using a machine learning based rare-event algorithm</title><link>http://arxiv.org/abs/2401.10800v1</link><description>The Atlantic Meridional Overturning Circulation (AMOC) is an importantcomponent of the global climate, known to be a tipping element, as it couldcollapse under global warming. The main objective of this study is to computethe probability that the AMOC collapses within a specified time window, using arare-event algorithm called Trajectory-Adaptive Multilevel Splitting (TAMS).However, the efficiency and accuracy of TAMS depend on the choice of the scorefunction. Although the definition of the optimal score function, called``committor function" is known, it is impossible in general to compute it apriori. Here, we combine TAMS with a Next-Generation Reservoir Computingtechnique that estimates the committor function from the data generated by therare-event algorithm. We test this technique in a stochastic box model of theAMOC for which two types of transition exist, the so-called F(ast)-transitionsand S(low)-transitions. Results for the F-transtions compare favorably withthose in the literature where a physically-informed score function was used. Weshow that coupling a rare-event algorithm with machine learning allows for acorrect estimation of transition probabilities, transition times, and eventransition paths for a wide range of model parameters. We then extend theseresults to the more difficult problem of S-transitions in the same model. Inboth cases of F- and S-transitions, we also show how the Next-GenerationReservoir Computing technique can be interpreted to retrieve an analyticalestimate of the committor function.</description><author>Val√©rian Jacques-Dumas, Ren√© M. van Westen, Henk A. Dijkstra</author><pubDate>Fri, 19 Jan 2024 16:36:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10800v1</guid></item><item><title>Novel Representation Learning Technique using Graphs for Performance Analytics</title><link>http://arxiv.org/abs/2401.10799v1</link><description>The performance analytics domain in High Performance Computing (HPC) usestabular data to solve regression problems, such as predicting the executiontime. Existing Machine Learning (ML) techniques leverage the correlations amongfeatures given tabular datasets, not leveraging the relationships betweensamples directly. Moreover, since high-quality embeddings from raw featuresimprove the fidelity of the downstream predictive models, existing methods relyon extensive feature engineering and pre-processing steps, costing time andmanual effort. To fill these two gaps, we propose a novel idea of transformingtabular performance data into graphs to leverage the advancement of GraphNeural Network-based (GNN) techniques in capturing complex relationshipsbetween features and samples. In contrast to other ML application domains, suchas social networks, the graph is not given; instead, we need to build it. Toaddress this gap, we propose graph-building methods where nodes representsamples, and the edges are automatically inferred iteratively based on thesimilarity between the features in the samples. We evaluate the effectivenessof the generated embeddings from GNNs based on how well they make even a simplefeed-forward neural network perform for regression tasks compared to otherstate-of-the-art representation learning techniques. Our evaluationdemonstrates that even with up to 25% random missing values for each dataset,our method outperforms commonly used graph and Deep Neural Network (DNN)-basedapproaches and achieves up to 61.67% &amp; 78.56% improvement in MSE loss over theDNN baseline respectively for HPC dataset and Machine Learning Datasets.</description><author>Tarek Ramadan, Ankur Lahiry, Tanzima Z. Islam</author><pubDate>Fri, 19 Jan 2024 16:34:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10799v1</guid></item><item><title>MCWDST: a Minimum-Cost Weighted Directed Spanning Tree Algorithm for Real-Time Fake News Mitigation in Social Media</title><link>http://arxiv.org/abs/2302.12190v2</link><description>The widespread availability of internet access and handheld devices confersto social media a power similar to the one newspapers used to have. People seekaffordable information on social media and can reach it within seconds. Yetthis convenience comes with dangers; any user may freely post whatever theyplease and the content can stay online for a long period, regardless of itstruthfulness. A need to detect untruthful information, also known as fake news,arises. In this paper, we present an end-to-end solution that accuratelydetects fake news and immunizes network nodes that spread them in real-time. Todetect fake news, we propose two new stack deep learning architectures thatutilize convolutional and bidirectional LSTM layers. To mitigate the spread offake news, we propose a real-time network-aware strategy that (1) constructs aminimum-cost weighted directed spanning tree for a detected node, and (2)immunizes nodes in that tree by scoring their harmfulness using a novel rankingfunction. We demonstrate the effectiveness of our solution on five real-worlddatasets.</description><author>Ciprian-Octavian TruicƒÉ, Elena-Simona Apostol, Radu-CƒÉtƒÉlin Nicolescu, Panagiotis Karras</author><pubDate>Fri, 19 Jan 2024 16:30:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.12190v2</guid></item><item><title>Towards Quantum Graph Neural Networks: An Ego-Graph Learning Approach</title><link>http://arxiv.org/abs/2201.05158v3</link><description>Quantum machine learning is a fast-emerging field that aims to tackle machinelearning using quantum algorithms and quantum computing. Due to the lack ofphysical qubits and an effective means to map real-world data from Euclideanspace to Hilbert space, most of these methods focus on quantum analogies orprocess simulations rather than devising concrete architectures based onqubits. In this paper, we propose a novel hybrid quantum-classical algorithmfor graph-structured data, which we refer to as the Ego-graph based QuantumGraph Neural Network (egoQGNN). egoQGNN implements the GNN theoreticalframework using the tensor product and unity matrix representation, whichgreatly reduces the number of model parameters required. When controlled by aclassical computer, egoQGNN can accommodate arbitrarily sized graphs byprocessing ego-graphs from the input graph using a modestly-sized quantumdevice. The architecture is based on a novel mapping from real-world data toHilbert space. This mapping maintains the distance relations present in thedata and reduces information loss. Experimental results show that the proposedmethod outperforms competitive state-of-the-art models with only 1.68\%parameters compared to those models.</description><author>Xing Ai, Zhihong Zhang, Luzhe Sun, Junchi Yan, Edwin Hancock</author><pubDate>Fri, 19 Jan 2024 16:26:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.05158v3</guid></item><item><title>Deep Reinforcement Learning Empowered Activity-Aware Dynamic Health Monitoring Systems</title><link>http://arxiv.org/abs/2401.10794v1</link><description>In smart healthcare, health monitoring utilizes diverse tools andtechnologies to analyze patients' real-time biosignal data, enabling immediateactions and interventions. Existing monitoring approaches were designed on thepremise that medical devices track several health metrics concurrently,tailored to their designated functional scope. This means that they report allrelevant health values within that scope, which can result in excess resourceuse and the gathering of extraneous data due to monitoring irrelevant healthmetrics. In this context, we propose Dynamic Activity-Aware Health Monitoringstrategy (DActAHM) for striking a balance between optimal monitoringperformance and cost efficiency, a novel framework based on Deep ReinforcementLearning (DRL) and SlowFast Model to ensure precise monitoring based on users'activities. Specifically, with the SlowFast Model, DActAHM efficientlyidentifies individual activities and captures these results for enhancedprocessing. Subsequently, DActAHM refines health metric monitoring in responseto the identified activity by incorporating a DRL framework. Extensiveexperiments comparing DActAHM against three state-of-the-art approachesdemonstrate it achieves 27.3% higher gain than the best-performing baselinethat fixes monitoring actions over timeline.</description><author>Ziqiaing Ye, Yulan Gao, Yue Xiao, Zehui Xiong, Dusit Niyato</author><pubDate>Fri, 19 Jan 2024 16:26:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10794v1</guid></item><item><title>Early alignment in two-layer networks training is a two-edged sword</title><link>http://arxiv.org/abs/2401.10791v1</link><description>Training neural networks with first order optimisation methods is at the coreof the empirical success of deep learning. The scale of initialisation is acrucial factor, as small initialisations are generally associated to a featurelearning regime, for which gradient descent is implicitly biased towards simplesolutions. This work provides a general and quantitative description of theearly alignment phase, originally introduced by Maennel et al. (2018) . Forsmall initialisation and one hidden ReLU layer networks, the early stage of thetraining dynamics leads to an alignment of the neurons towards key directions.This alignment induces a sparse representation of the network, which isdirectly related to the implicit bias of gradient flow at convergence. Thissparsity inducing alignment however comes at the expense of difficulties inminimising the training objective: we also provide a simple data example forwhich overparameterised networks fail to converge towards global minima andonly converge to a spurious stationary point instead.</description><author>Etienne Boursier, Nicolas Flammarion</author><pubDate>Fri, 19 Jan 2024 16:23:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10791v1</guid></item><item><title>Measuring the Impact of Scene Level Objects on Object Detection: Towards Quantitative Explanations of Detection Decisions</title><link>http://arxiv.org/abs/2401.10790v1</link><description>Although accuracy and other common metrics can provide a useful window intothe performance of an object detection model, they lack a deeper view of themodel's decision process. Regardless of the quality of the training data andprocess, the features that an object detection model learns cannot beguaranteed. A model may learn a relationship between certain backgroundcontext, i.e., scene level objects, and the presence of the labeled classes.Furthermore, standard performance verification and metrics would not identifythis phenomenon. This paper presents a new black box explainability method foradditional verification of object detection models by finding the impact ofscene level objects on the identification of the objects within the image. Bycomparing the accuracies of a model on test data with and without certain scenelevel objects, the contributions of these objects to the model's performancebecomes clearer. The experiment presented here will assess the impact ofbuildings and people in image context on the detection of emergency roadvehicles by a fine-tuned YOLOv8 model. A large increase in accuracy in thepresence of a scene level object will indicate the model's reliance on thatobject to make its detections. The results of this research lead to providing aquantitative explanation of the object detection model's decision process,enabling a deeper understanding of the model's performance.</description><author>Lynn Vonder Haar, Timothy Elvira, Luke Newcomb, Omar Ochoa</author><pubDate>Fri, 19 Jan 2024 16:21:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10790v1</guid></item><item><title>Sat2Scene: 3D Urban Scene Generation from Satellite Images with Diffusion</title><link>http://arxiv.org/abs/2401.10786v1</link><description>Directly generating scenes from satellite imagery offers excitingpossibilities for integration into applications like games and map services.However, challenges arise from significant view changes and scene scale.Previous efforts mainly focused on image or video generation, lackingexploration into the adaptability of scene generation for arbitrary views.Existing 3D generation works either operate at the object level or aredifficult to utilize the geometry obtained from satellite imagery. To overcomethese limitations, we propose a novel architecture for direct 3D scenegeneration by introducing diffusion models into 3D sparse representations andcombining them with neural rendering techniques. Specifically, our approachgenerates texture colors at the point level for a given geometry using a 3Ddiffusion model first, which is then transformed into a scene representation ina feed-forward manner. The representation can be utilized to render arbitraryviews which would excel in both single-frame quality and inter-frameconsistency. Experiments in two city-scale datasets show that our modeldemonstrates proficiency in generating photo-realistic street-view imagesequences and cross-view urban scenes from satellite imagery.</description><author>Zuoyue Li, Zhenqiang Li, Zhaopeng Cui, Marc Pollefeys, Martin R. Oswald</author><pubDate>Fri, 19 Jan 2024 16:15:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10786v1</guid></item><item><title>IPR-NeRF: Ownership Verification meets Neural Radiance Field</title><link>http://arxiv.org/abs/2401.09495v2</link><description>Neural Radiance Field (NeRF) models have gained significant attention in thecomputer vision community in the recent past with state-of-the-art visualquality and produced impressive demonstrations. Since then, technopreneurs havesought to leverage NeRF models into a profitable business. Therefore, NeRFmodels make it worth the risk of plagiarizers illegally copying,re-distributing, or misusing those models. This paper proposes a comprehensiveintellectual property (IP) protection framework for the NeRF model in bothblack-box and white-box settings, namely IPR-NeRF. In the black-box setting, adiffusion-based solution is introduced to embed and extract the watermark via atwo-stage optimization process. In the white-box setting, a designated digitalsignature is embedded into the weights of the NeRF model by adopting the signloss objective. Our extensive experiments demonstrate that not only does ourapproach maintain the fidelity (\ie, the rendering quality) of IPR-NeRF models,but it is also robust against both ambiguity and removal attacks compared toprior arts.</description><author>Win Kent Ong, Kam Woh Ng, Chee Seng Chan, Yi Zhe Song, Tao Xiang</author><pubDate>Fri, 19 Jan 2024 16:11:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09495v2</guid></item><item><title>Metric Dynamic Equilibrium Logic</title><link>http://arxiv.org/abs/2401.10781v1</link><description>In temporal extensions of Answer Set Programming (ASP) based on linear-time,the behavior of dynamic systems is captured by sequences of states. While thisrepresentation reflects their relative order, it abstracts away the specifictimes associated with each state. In many applications, however, timingconstraints are important like, for instance, when planning and scheduling gohand in hand. We address this by developing a metric extension of linear-timeDynamic Equilibrium Logic, in which dynamic operators are constrained byintervals over integers. The resulting Metric Dynamic Equilibrium Logicprovides the foundation of an ASP-based approach for specifying qualitative andquantitative dynamic constraints. As such, it constitutes the most generalamong a whole spectrum of temporal extensions of Equilibrium Logic. In detail,we show that it encompasses Temporal, Dynamic, Metric, and regular EquilibriumLogic, as well as its classic counterparts once the law of the excluded middleis added.</description><author>Arvid Becker, Pedro Cabalar, Mart√≠n Di√©guez, Luis Fari√±as, Torsten Schaub, Anna Schuhmann</author><pubDate>Fri, 19 Jan 2024 16:01:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10781v1</guid></item><item><title>Large Language Models for Information Retrieval: A Survey</title><link>http://arxiv.org/abs/2308.07107v3</link><description>As a primary means of information acquisition, information retrieval (IR)systems, such as search engines, have integrated themselves into our dailylives. These systems also serve as components of dialogue, question-answering,and recommender systems. The trajectory of IR has evolved dynamically from itsorigins in term-based methods to its integration with advanced neural models.While the neural models excel at capturing complex contextual signals andsemantic nuances, thereby reshaping the IR landscape, they still facechallenges such as data scarcity, interpretability, and the generation ofcontextually plausible yet potentially inaccurate responses. This evolutionrequires a combination of both traditional methods (such as term-based sparseretrieval methods with rapid response) and modern neural architectures (such aslanguage models with powerful language understanding capacity). Meanwhile, theemergence of large language models (LLMs), typified by ChatGPT and GPT-4, hasrevolutionized natural language processing due to their remarkable languageunderstanding, generation, generalization, and reasoning abilities.Consequently, recent research has sought to leverage LLMs to improve IRsystems. Given the rapid evolution of this research trajectory, it is necessaryto consolidate existing methodologies and provide nuanced insights through acomprehensive overview. In this survey, we delve into the confluence of LLMsand IR systems, including crucial aspects such as query rewriters, retrievers,rerankers, and readers. Additionally, we explore promising directions, such assearch agents, within this expanding field.</description><author>Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Haonan Chen, Zhicheng Dou, Ji-Rong Wen</author><pubDate>Fri, 19 Jan 2024 16:01:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07107v3</guid></item><item><title>Domain Adaptation for Deep Unit Test Case Generation</title><link>http://arxiv.org/abs/2308.08033v2</link><description>Recently, deep learning-based test case generation approaches have beenproposed to automate the generation of unit test cases. In this study, weleverage Transformer-based code models to generate unit tests with the help ofDomain Adaptation (DA) at a project level. Specifically, we use CodeT5, whichis a relatively small language model trained on source code data, and fine-tuneit on the test generation task; then again further fine-tune it on each targetproject data to learn the project-specific knowledge (project-level DA). We usethe Methods2test dataset to fine-tune CodeT5 for the test generation task andthe Defects4j dataset for project-level domain adaptation and evaluation. Wecompare our approach with (a) CodeT5 fine-tuned on the test generation withoutDA, (b) the A3Test tool, and (c) GPT-4, on 5 projects from the Defects4jdataset. The results show that using DA can increase the line coverage of thegenerated tests on average 18.62%, 19.88%, and 18.02% compared to the above(a), (b), and (c) baselines, respectively. The results also consistently showimprovements using other metrics such as BLEU and CodeBLEU. In addition, weshow that our approach can be seen as a complementary solution alongsideexisting search-based test generation tools such as EvoSuite, to increase theoverall coverage and mutation scores with an average of 34.42% and 6.8%, forline coverage and mutation score, respectively.</description><author>Jiho Shin, Sepehr Hashtroudi, Hadi Hemmati, Song Wang</author><pubDate>Fri, 19 Jan 2024 15:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.08033v2</guid></item><item><title>Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr√∂dinger Bridge and Reaction-Diffusion PDEs</title><link>http://arxiv.org/abs/2401.07961v2</link><description>Lambert's problem concerns with transferring a spacecraft from a giveninitial to a given terminal position within prescribed flight time via velocitycontrol subject to a gravitational force field. We consider a probabilisticvariant of the Lambert problem where the knowledge of the endpoint constraintsin position vectors are replaced by the knowledge of their respective jointprobability density functions. We show that the Lambert problem with endpointjoint probability density constraints is a generalized optimal mass transport(OMT) problem, thereby connecting this classical astrodynamics problem with aburgeoning area of research in modern stochastic control and stochastic machinelearning. This newfound connection allows us to rigorously establish theexistence and uniqueness of solution for the probabilistic Lambert problem. Thesame connection also helps to numerically solve the probabilistic Lambertproblem via diffusion regularization, i.e., by leveraging further connection ofthe OMT with the Schr\"odinger bridge problem (SBP). This also shows that theprobabilistic Lambert problem with additive dynamic process noise is in fact ageneralized SBP, and can be solved numerically using the so-calledSchr\"odinger factors, as we do in this work. We explain how the resultinganalysis leads to solving a boundary-coupled system of reaction-diffusion PDEswhere the nonlinear gravitational potential appears as the reaction rate. Wepropose novel algorithms for the same, and present illustrative numericalresults. Our analysis and the algorithmic framework are nonparametric, i.e., wemake neither statistical (e.g., Gaussian, first few moments, mixture orexponential family, finite dimensionality of the sufficient statistic) nordynamical (e.g., Taylor series) approximations.</description><author>Alexis M. H. Teter, Iman Nodozi, Abhishek Halder</author><pubDate>Fri, 19 Jan 2024 15:55:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07961v2</guid></item><item><title>Determination of efficiency indicators of the stand for intelligent control of manual operations in industrial production</title><link>http://arxiv.org/abs/2401.10777v1</link><description>Systems of intelligent control of manual operations in industrial productionare being implemented in many industries nowadays. Such systems usehigh-resolution cameras and computer vision algorithms to automatically trackthe operator's manipulations and prevent technological errors in the assemblyprocess. At the same time compliance with safety regulations in the workspaceis monitored. As a result, the defect rate of manufactured products and thenumber of accidents during the manual assembly of any device are decreased.Before implementing an intelligent control system into a real production it isnecessary to calculate its efficiency. In order to do it experiments on thestand for manual operations control systems were carried out. This paperproposes the methodology for calculating the efficiency indicators. Thismathematical approach is based on the IoU calculation of real- andpredicted-time intervals between assembly stages. The results show highprecision in tracking the validity of manual assembly and do not depend on theduration of the assembly process.</description><author>Anton Sergeev, Victor Minchenkov, Aleksei Soldatov</author><pubDate>Fri, 19 Jan 2024 15:51:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10777v1</guid></item><item><title>AUPIMO: Redefining Visual Anomaly Detection Benchmarks with High Speed and Low Tolerance</title><link>http://arxiv.org/abs/2401.01984v2</link><description>Recent advances in visual anomaly detection research have seen AUROC andAUPRO scores on public benchmark datasets such as MVTec and VisA convergetowards perfect recall, giving the impression that these benchmarks arenear-solved. However, high AUROC and AUPRO scores do not always reflectqualitative performance, which limits the validity of these metrics inreal-world applications. We argue that the artificial ceiling imposed by thelack of an adequate evaluation metric restrains progression of the field, andit is crucial that we revisit the evaluation metrics used to rate ouralgorithms. In response, we introduce Per-IMage Overlap (PIMO), a novel metricthat addresses the shortcomings of AUROC and AUPRO. PIMO retains therecall-based nature of the existing metrics but introduces two distinctions:the assignment of curves (and respective area under the curve) is per-image,and its X-axis relies solely on normal images. Measuring recall per imagesimplifies instance score indexing and is more robust to noisy annotations. Aswe show, it also accelerates computation and enables the usage of statisticaltests to compare models. By imposing low tolerance for false positives onnormal images, PIMO provides an enhanced model validation procedure andhighlights performance variations across datasets. Our experiments demonstratethat PIMO offers practical advantages and nuanced performance insights thatredefine anomaly detection benchmarks -- notably challenging the perceptionthat MVTec AD and VisA datasets have been solved by contemporary models.Available on GitHub: https://github.com/jpcbertoldo/aupimo.</description><author>Joao P. C. Bertoldo, Dick Ameln, Ashwin Vaidya, Samet Ak√ßay</author><pubDate>Fri, 19 Jan 2024 15:51:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01984v2</guid></item><item><title>Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads</title><link>http://arxiv.org/abs/2401.10774v1</link><description>The inference process in Large Language Models (LLMs) is often limited due tothe absence of parallelism in the auto-regressive decoding process, resultingin most operations being restricted by the memory bandwidth of accelerators.While methods such as speculative decoding have been suggested to address thisissue, their implementation is impeded by the challenges associated withacquiring and maintaining a separate draft model. In this paper, we presentMedusa, an efficient method that augments LLM inference by adding extradecoding heads to predict multiple subsequent tokens in parallel. Using atree-based attention mechanism, Medusa constructs multiple candidatecontinuations and verifies them simultaneously in each decoding step. Byleveraging parallel processing, Medusa introduces only minimal overhead interms of single-step latency while substantially reducing the number ofdecoding steps required. We present two levels of fine-tuning procedures for Medusa to meet the needsof different use cases: Medusa-1: Medusa is directly fine-tuned on top of afrozen backbone LLM, enabling lossless inference acceleration. Medusa-2: Medusais fine-tuned together with the backbone LLM, enabling better predictionaccuracy of Medusa heads and higher speedup but needing a special trainingrecipe that preserves the backbone model's capabilities. Moreover, we propose several extensions that improve or expand the utility ofMedusa, including a self-distillation to handle situations where no trainingdata is available and a typical acceptance scheme to boost the acceptance ratewhile maintaining generation quality. We evaluate Medusa on models of varioussizes and training procedures. Our experiments demonstrate that Medusa-1 canachieve over 2.2x speedup without compromising generation quality, whileMedusa-2 further improves the speedup to 2.3-3.6x.</description><author>Tianle Cai, Yuhong Li, Zhengyang Geng, Hongwu Peng, Jason D. Lee, Deming Chen, Tri Dao</author><pubDate>Fri, 19 Jan 2024 15:48:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10774v1</guid></item><item><title>Mitigating Hallucinations of Large Language Models via Knowledge Consistent Alignment</title><link>http://arxiv.org/abs/2401.10768v1</link><description>While Large Language Models (LLMs) have proven to be exceptional on a varietyof tasks after alignment, they may still produce responses that contradict thecontext or world knowledge confidently, a phenomenon known as``hallucination''. In this paper, we demonstrate that reducing theinconsistency between the external knowledge encapsulated in the training dataand the intrinsic knowledge inherited in the pretraining corpus could mitigatehallucination in alignment. Specifically, we introduce a novel knowledgeconsistent alignment (KCA) approach, which involves automatically formulatingexaminations based on external knowledge for accessing the comprehension ofLLMs. For data encompassing knowledge inconsistency, KCA implements severalsimple yet efficient strategies for processing. We illustrate the superiorperformance of the proposed KCA approach in mitigating hallucinations acrosssix benchmarks using LLMs of different backbones and scales. Furthermore, weconfirm the correlation between knowledge inconsistency and hallucination,signifying the effectiveness of reducing knowledge inconsistency in alleviatinghallucinations. Our code, model weights, and data are public at\url{https://github.com/fanqiwan/KCA}.</description><author>Fanqi Wan, Xinting Huang, Leyang Cui, Xiaojun Quan, Wei Bi, Shuming Shi</author><pubDate>Fri, 19 Jan 2024 15:39:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10768v1</guid></item><item><title>Starlit: Privacy-Preserving Federated Learning to Enhance Financial Fraud Detection</title><link>http://arxiv.org/abs/2401.10765v1</link><description>Federated Learning (FL) is a data-minimization approach enablingcollaborative model training across diverse clients with local data, avoidingdirect data exchange. However, state-of-the-art FL solutions to identifyfraudulent financial transactions exhibit a subset of the followinglimitations. They (1) lack a formal security definition and proof, (2) assumeprior freezing of suspicious customers' accounts by financial institutions(limiting the solutions' adoption), (3) scale poorly, involving either $O(n^2)$computationally expensive modular exponentiation (where $n$ is the total numberof financial institutions) or highly inefficient fully homomorphic encryption,(4) assume the parties have already completed the identity alignment phase,hence excluding it from the implementation, performance evaluation, andsecurity analysis, and (5) struggle to resist clients' dropouts. This workintroduces Starlit, a novel scalable privacy-preserving FL mechanism thatovercomes these limitations. It has various applications, such as enhancingfinancial fraud detection, mitigating terrorism, and enhancing digital health.We implemented Starlit and conducted a thorough performance analysis usingsynthetic data from a key player in global financial transactions. Theevaluation indicates Starlit's scalability, efficiency, and accuracy.</description><author>Aydin Abadi, Bradley Doyle, Francesco Gini, Kieron Guinamard, Sasi Kumar Murakonda, Jack Liddell, Paul Mellor, Steven J. Murdoch, Mohammad Naseri, Hector Page, George Theodorakopoulos, Suzanne Weller</author><pubDate>Fri, 19 Jan 2024 15:37:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10765v1</guid></item><item><title>NN-VVC: Versatile Video Coding boosted by self-supervisedly learned image coding for machines</title><link>http://arxiv.org/abs/2401.10761v1</link><description>The recent progress in artificial intelligence has led to an ever-increasingusage of images and videos by machine analysis algorithms, mainly neuralnetworks. Nonetheless, compression, storage and transmission of media havetraditionally been designed considering human beings as the viewers of thecontent. Recent research on image and video coding for machine analysis hasprogressed mainly in two almost orthogonal directions. The first is representedby end-to-end (E2E) learned codecs which, while offering high performance onimage coding, are not yet on par with state-of-the-art conventional videocodecs and lack interoperability. The second direction considers using theVersatile Video Coding (VVC) standard or any other conventional video codec(CVC) together with pre- and post-processing operations targeting machineanalysis. While the CVC-based methods benefit from interoperability and broadhardware and software support, the machine task performance is often lower thanthe desired level, particularly in low bitrates. This paper proposes a hybridcodec for machines called NN-VVC, which combines the advantages of anE2E-learned image codec and a CVC to achieve high performance in both image andvideo coding for machines. Our experiments show that the proposed systemachieved up to -43.20% and -26.8% Bj{\o}ntegaard Delta rate reduction over VVCfor image and video data, respectively, when evaluated on multiple differentdatasets and machine vision tasks. To the best of our knowledge, this is thefirst research paper showing a hybrid video codec that outperforms VVC onmultiple datasets and multiple machine vision tasks.</description><author>Jukka I. Ahonen, Nam Le, Honglei Zhang, Antti Hallapuro, Francesco Cricri, Hamed Rezazadegan Tavakoli, Miska M. Hannuksela, Esa Rahtu</author><pubDate>Fri, 19 Jan 2024 15:33:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10761v1</guid></item><item><title>Have it your way: Individualized Privacy Assignment for DP-SGD</title><link>http://arxiv.org/abs/2303.17046v2</link><description>When training a machine learning model with differential privacy, one sets aprivacy budget. This budget represents a maximal privacy violation that anyuser is willing to face by contributing their data to the training set. Weargue that this approach is limited because different users may have differentprivacy expectations. Thus, setting a uniform privacy budget across all pointsmay be overly conservative for some users or, conversely, not sufficientlyprotective for others. In this paper, we capture these preferences throughindividualized privacy budgets. To demonstrate their practicality, we introducea variant of Differentially Private Stochastic Gradient Descent (DP-SGD) whichsupports such individualized budgets. DP-SGD is the canonical approach totraining models with differential privacy. We modify its data sampling andgradient noising mechanisms to arrive at our approach, which we callIndividualized DP-SGD (IDP-SGD). Because IDP-SGD provides privacy guaranteestailored to the preferences of individual users and their data points, we findit empirically improves privacy-utility trade-offs.</description><author>Franziska Boenisch, Christopher M√ºhl, Adam Dziedzic, Roy Rinberg, Nicolas Papernot</author><pubDate>Fri, 19 Jan 2024 15:33:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.17046v2</guid></item><item><title>Interactions with Prompt Problems: A New Way to Teach Programming with Large Language Models</title><link>http://arxiv.org/abs/2401.10759v1</link><description>Large Language Models (LLMs) have upended decades of pedagogy in computingeducation. Students previously learned to code through \textit{writing} manysmall problems with less emphasis on code reading and comprehension. Recentresearch has shown that free code generation tools powered by LLMs can solveintroductory programming problems presented in natural language with ease. Inthis paper, we propose a new way to teach programming with Prompt Problems.Students receive a problem visually, indicating how input should be transformedto output, and must translate that to a prompt for an LLM to decipher. Theproblem is considered correct when the code that is generated by the studentprompt can pass all test cases. In this paper we present the design of thistool, discuss student interactions with it as they learn, and provide insightsinto this new class of programming problems as well as the design tools thatintegrate LLMs.</description><author>James Prather, Paul Denny, Juho Leinonen, David H. Smith IV, Brent N. Reeves, Stephen MacNeil, Brett A. Becker, Andrew Luxton-Reilly, Thezyrie Amarouche, Bailey Kimmel</author><pubDate>Fri, 19 Jan 2024 15:32:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10759v1</guid></item><item><title>Group-level Brain Decoding with Deep Learning</title><link>http://arxiv.org/abs/2205.14102v3</link><description>Decoding brain imaging data are gaining popularity, with applications inbrain-computer interfaces and the study of neural representations. Decoding istypicallysubject-specific and does not generalise well over subjects, due tohigh amounts ofbetween subject variability. Techniques that overcome this willnot only providericher neuroscientific insights but also make it possible forgroup-level models to out-perform subject-specific models. Here, we propose amethod that uses subjectembedding, analogous to word embedding in naturallanguage processing, to learnand exploit the structure in between-subjectvariability as part of a decoding model,our adaptation of the WaveNetarchitecture for classification. We apply this to mag-netoencephalography data,where 15 subjects viewed 118 different images, with30 examples per image; toclassify images using the entire 1 s window followingimage presentation. Weshow that the combination of deep learning and subjectembedding is crucial toclosing the performance gap between subject- and group-level decoding models.Importantly, group models outperform subject models onlow-accuracy subjects(although slightly impair high-accuracy subjects) and can behelpful forinitialising subject models. While we have not generally foundgroup-levelmodels to perform better than subject-level models, the performanceof groupmodelling is expected to be even higher with bigger datasets. In orderto providephysiological interpretation at the group level, we make use ofpermutation featureimportance. This provides insights into the spatiotemporaland spectral informationencoded in the models. All code is available on GitHub(https://github.com/ricsinaruto/MEG-group-decode).</description><author>Richard Csaky, Mats Van Es, Oiwi Parker Jones, Mark Woolrich</author><pubDate>Fri, 19 Jan 2024 15:30:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.14102v3</guid></item><item><title>Benchmarking Robustness of Multimodal Image-Text Models under Distribution Shift</title><link>http://arxiv.org/abs/2212.08044v3</link><description>Multimodal image-text models have shown remarkable performance in the pastfew years. However, evaluating robustness against distribution shifts iscrucial before adopting them in real-world applications. In this work, weinvestigate the robustness of 12 popular open-sourced image-text models undercommon perturbations on five tasks (image-text retrieval, visual reasoning,visual entailment, image captioning, and text-to-image generation). Inparticular, we propose several new multimodal robustness benchmarks by applying17 image perturbation and 16 text perturbation techniques on top of existingdatasets. We observe that multimodal models are not robust to image and textperturbations, especially to image perturbations. Among the tested perturbationmethods, character-level perturbations constitute the most severe distributionshift for text, and zoom blur is the most severe shift for image data. We alsointroduce two new robustness metrics (\textbf{MMI} for MultiModal Impact scoreand \textbf{MOR} for Missing Object Rate) for proper evaluations of multimodalmodels. We hope our extensive study sheds light on new directions for thedevelopment of robust multimodal models. More details can be found on theproject webpage: \url{https://MMRobustness.github.io}.</description><author>Jielin Qiu, Yi Zhu, Xingjian Shi, Florian Wenzel, Zhiqiang Tang, Ding Zhao, Bo Li, Mu Li</author><pubDate>Fri, 19 Jan 2024 15:29:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.08044v3</guid></item><item><title>Data Augmentation for Traffic Classification</title><link>http://arxiv.org/abs/2401.10754v1</link><description>Data Augmentation (DA) -- enriching training data by adding synthetic samples-- is a technique widely adopted in Computer Vision (CV) and Natural LanguageProcessing (NLP) tasks to improve models performance. Yet, DA has struggled togain traction in networking contexts, particularly in Traffic Classification(TC) tasks. In this work, we fulfill this gap by benchmarking 18 augmentationfunctions applied to 3 TC datasets using packet time series as inputrepresentation and considering a variety of training conditions. Our resultsshow that (i) DA can reap benefits previously unexplored with (ii)augmentations acting on time series sequence order and masking being a bettersuit for TC and (iii) simple latent space analysis can provide hints about whyaugmentations have positive or negative effects.</description><author>Chao Wang, Alessandro Finamore, Pietro Michiardi, Massimo Gallo, Dario Rossi</author><pubDate>Fri, 19 Jan 2024 15:25:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10754v1</guid></item><item><title>BoolGebra: Attributed Graph-learning for Boolean Algebraic Manipulation</title><link>http://arxiv.org/abs/2401.10753v1</link><description>Boolean algebraic manipulation is at the core of logic synthesis inElectronic Design Automation (EDA) design flow. Existing methods struggle tofully exploit optimization opportunities, and often suffer from an explosivesearch space and limited scalability efficiency. This work presents BoolGebra,a novel attributed graph-learning approach for Boolean algebraic manipulationthat aims to improve fundamental logic synthesis. BoolGebra incorporates GraphNeural Networks (GNNs) and takes initial feature embeddings from bothstructural and functional information as inputs. A fully connected neuralnetwork is employed as the predictor for direct optimization resultpredictions, significantly reducing the search space and efficiently locatingthe optimization space. The experiments involve training the BoolGebra modelw.r.t design-specific and cross-design inferences using the trained model,where BoolGebra demonstrates generalizability for cross-design inference andits potential to scale from small, simple training datasets to large, complexinference datasets. Finally, BoolGebra is integrated with existing synthesistool ABC to perform end-to-end logic minimization evaluation w.r.t SOTAbaselines.</description><author>Yingjie Li, Anthony Agnesina, Yanqing Zhang, Haoxing Ren, Cunxi Yu</author><pubDate>Fri, 19 Jan 2024 15:22:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10753v1</guid></item><item><title>HiCD: Change Detection in Quality-Varied Images via Hierarchical Correlation Distillation</title><link>http://arxiv.org/abs/2401.10752v1</link><description>Advanced change detection techniques primarily target image pairs of equaland high quality. However, variations in imaging conditions and platformsfrequently lead to image pairs with distinct qualities: one image beinghigh-quality, while the other being low-quality. These disparities in imagequality present significant challenges for understanding image pairssemantically and extracting change features, ultimately resulting in a notabledecline in performance. To tackle this challenge, we introduce an innovativetraining strategy grounded in knowledge distillation. The core idea revolvesaround leveraging task knowledge acquired from high-quality image pairs toguide the model's learning process when dealing with image pairs that exhibitdifferences in quality. Additionally, we develop a hierarchical correlationdistillation approach (involving self-correlation, cross-correlation, andglobal correlation). This approach compels the student model to replicate thecorrelations inherent in the teacher model, rather than focusing solely onindividual features. This ensures effective knowledge transfer whilemaintaining the student model's training flexibility.</description><author>Chao Pang, Xingxing Weng, Jiang Wu, Qiang Wang, Gui-Song Xia</author><pubDate>Fri, 19 Jan 2024 15:21:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10752v1</guid></item><item><title>EFO: the Emotion Frame Ontology</title><link>http://arxiv.org/abs/2401.10751v1</link><description>Emotions are a subject of intense debate in various disciplines. Despite theproliferation of theories and definitions, there is still no consensus on whatemotions are, and how to model the different concepts involved when we talkabout - or categorize - them. In this paper, we propose an OWL frame-basedontology of emotions: the Emotion Frames Ontology (EFO). EFO treats emotions assemantic frames, with a set of semantic roles that capture the differentaspects of emotional experience. EFO follows pattern-based ontology design, andis aligned to the DOLCE foundational ontology. EFO is used to model multipleemotion theories, which can be cross-linked as modules in an Emotion OntologyNetwork. In this paper, we exemplify it by modeling Ekman's Basic Emotions (BE)Theory as an EFO-BE module, and demonstrate how to perform automated inferenceson the representation of emotion situations. EFO-BE has been evaluated bylexicalizing the BE emotion frames from within the Framester knowledge graph,and implementing a graph-based emotion detector from text. In addition, an EFOintegration of multimodal datasets, including emotional speech and emotionalface expressions, has been performed to enable further inquiry into crossmodalemotion semantics.</description><author>Stefano De Giorgis, Aldo Gangemi</author><pubDate>Fri, 19 Jan 2024 15:20:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10751v1</guid></item><item><title>Salted Inference: Enhancing Privacy while Maintaining Efficiency of Split Inference in Mobile Computing</title><link>http://arxiv.org/abs/2310.13384v2</link><description>In split inference, a deep neural network (DNN) is partitioned to run theearly part of the DNN at the edge and the later part of the DNN in the cloud.This meets two key requirements for on-device machine learning: input privacyand computation efficiency. Still, an open question in split inference isoutput privacy, given that the outputs of the DNN are observable in the cloud.While encrypted computing can protect output privacy too, homomorphicencryption requires substantial computation and communication resources fromboth edge and cloud devices. In this paper, we introduce Salted DNNs: a novelapproach that enables clients at the edge, who run the early part of the DNN,to control the semantic interpretation of the DNN's outputs at inference time.Our proposed Salted DNNs maintain classification accuracy and computationefficiency very close to the standard DNN counterparts. Experimentalevaluations conducted on both images and wearable sensor data demonstrate thatSalted DNNs attain classification accuracy very close to standard DNNs,particularly when the Salted Layer is positioned within the early part to meetthe requirements of split inference. Our approach is general and can be appliedto various types of DNNs. As a benchmark for future studies, we open-source ourcode.</description><author>Mohammad Malekzadeh, Fahim Kawsar</author><pubDate>Fri, 19 Jan 2024 15:19:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13384v2</guid></item><item><title>Explaining dark matter halo density profiles with neural networks</title><link>http://arxiv.org/abs/2305.03077v2</link><description>We use explainable neural networks to connect the evolutionary history ofdark matter halos with their density profiles. The network captures independentfactors of variation in the density profiles within a low-dimensionalrepresentation, which we physically interpret using mutual information. Withoutany prior knowledge of the halos' evolution, the network recovers the knownrelation between the early time assembly and the inner profile, and discoversthat the profile beyond the virial radius is described by a single parametercapturing the most recent mass accretion rate. The results illustrate thepotential for machine-assisted scientific discovery in complicatedastrophysical datasets.</description><author>Luisa Lucie-Smith, Hiranya V. Peiris, Andrew Pontzen</author><pubDate>Fri, 19 Jan 2024 15:16:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03077v2</guid></item><item><title>A Systematic Evaluation of Euclidean Alignment with Deep Learning for EEG Decoding</title><link>http://arxiv.org/abs/2401.10746v1</link><description>Electroencephalography (EEG) signals are frequently used for variousBrain-Computer Interface (BCI) tasks. While Deep Learning (DL) techniques haveshown promising results, they are hindered by the substantial datarequirements. By leveraging data from multiple subjects, transfer learningenables more effective training of DL models. A technique that is gainingpopularity is Euclidean Alignment (EA) due to its ease of use, lowcomputational complexity, and compatibility with Deep Learning models. However,few studies evaluate its impact on the training performance of shared andindividual DL models. In this work, we systematically evaluate the effect of EAcombined with DL for decoding BCI signals. We used EA to train shared modelswith data from multiple subjects and evaluated its transferability to newsubjects. Our experimental results show that it improves decoding in the targetsubject by 4.33% and decreases convergence time by more than 70%. We alsotrained individual models for each subject to use as a majority-voting ensembleclassifier. In this scenario, using EA improved the 3-model ensemble accuracyby 3.7%. However, when compared to the shared model with EA, the ensembleaccuracy was 3.62% lower.</description><author>Bruna Junqueira, Bruno Aristimunha, Sylvain Chevallier, Raphael Y. de Camargo</author><pubDate>Fri, 19 Jan 2024 15:13:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10746v1</guid></item><item><title>A Fast, Performant, Secure Distributed Training Framework For Large Language Model</title><link>http://arxiv.org/abs/2401.09796v2</link><description>The distributed (federated) LLM is an important method for co-training thedomain-specific LLM using siloed data. However, maliciously stealing modelparameters and data from the server or client side has become an urgent problemto be solved. In this paper, we propose a secure distributed LLM based on modelslicing. In this case, we deploy the Trusted Execution Environment (TEE) onboth the client and server side, and put the fine-tuned structure (LoRA orembedding of P-tuning v2) into the TEE. Then, secure communication is executedin the TEE and general environments through lightweight encryption. In order tofurther reduce the equipment cost as well as increase the model performance andaccuracy, we propose a split fine-tuning scheme. In particular, we split theLLM by layers and place the latter layers in a server-side TEE (the client doesnot need a TEE). We then combine the proposed Sparsification ParameterFine-tuning (SPF) with the LoRA part to improve the accuracy of the downstreamtask. Numerous experiments have shown that our method guarantees accuracy whilemaintaining security.</description><author>Wei Huang, Yinggui Wang, Anda Cheng, Aihui Zhou, Chaofan Yu, Lei Wang</author><pubDate>Fri, 19 Jan 2024 15:09:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09796v2</guid></item><item><title>FinLLMs: A Framework for Financial Reasoning Dataset Generation with Large Language Models</title><link>http://arxiv.org/abs/2401.10744v1</link><description>Large Language models (LLMs) usually rely on extensive training datasets. Inthe financial domain, creating numerical reasoning datasets that include a mixof tables and long text often involves substantial manual annotation expenses.To address the limited data resources and reduce the annotation cost, weintroduce FinLLMs, a method for generating financial question-answering databased on common financial formulas using Large Language Models. First, wecompile a list of common financial formulas and construct a graph based on thevariables these formulas employ. We then augment the formula set by combiningthose that share identical variables as new elements. Specifically, we exploreformulas obtained by manual annotation and merge those formulas with sharedvariables by traversing the constructed graph. Finally, utilizing GPT-3.5, wegenerate financial question-answering data that encompasses both tabularinformation and long textual content, building on the collected formula set.Our experiments demonstrate that synthetic data generated by FinLLMseffectively enhances the performance of several large-scale numerical reasoningmodels in the financial domain, outperforming two established benchmarkfinancial question-answering datasets.</description><author>Ziqiang Yuan, Kaiyuan Wang, Shoutai Zhu, Ye Yuan, Jingya Zhou, Yanlin Zhu, Wenqi Wei</author><pubDate>Fri, 19 Jan 2024 15:09:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10744v1</guid></item><item><title>Generative User-Experience Research for Developing Domain-specific Natural Language Processing Applications</title><link>http://arxiv.org/abs/2306.16143v4</link><description>User experience (UX) is a part of human-computer interaction (HCI) researchand focuses on increasing intuitiveness, transparency, simplicity, and trustfor the system users. Most UX research for machine learning (ML) or naturallanguage processing (NLP) focuses on a data-driven methodology. It engagesdomain users mainly for usability evaluation. Moreover, more typical UX methodstailor the systems towards user usability, unlike learning about the user needsfirst. This paper proposes a new methodology for integrating generative UXresearch into developing domain NLP applications. Generative UX researchemploys domain users at the initial stages of prototype development, i.e.,ideation and concept evaluation, and the last stage for evaluating systemusefulness and user utility. The methodology emerged from and is evaluated on acase study about the full-cycle prototype development of a domain-specificsemantic search for daily operations in the process industry. A key finding ofour case study is that involving domain experts increases their interest andtrust in the final NLP application. The combined UX+NLP research of theproposed method efficiently considers data- and user-driven opportunities andconstraints, which can be crucial for developing NLP applications.</description><author>Anastasia Zhukova, Lukas von Sperl, Christian E. Matt, Bela Gipp</author><pubDate>Fri, 19 Jan 2024 15:05:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16143v4</guid></item><item><title>TemperatureGAN: Generative Modeling of Regional Atmospheric Temperatures</title><link>http://arxiv.org/abs/2306.17248v2</link><description>Stochastic generators are useful for estimating climate impacts on varioussectors. Projecting climate risk in various sectors, e.g. energy systems,requires generators that are accurate (statistical resemblance toground-truth), reliable (do not produce erroneous examples), and efficient.Leveraging data from the North American Land Data Assimilation System, weintroduce TemperatureGAN, a Generative Adversarial Network conditioned onmonths, locations, and time periods, to generate 2m above ground atmospherictemperatures at an hourly resolution. We propose evaluation methods and metricsto measure the quality of generated samples. We show that TemperatureGANproduces high-fidelity examples with good spatial representation and temporaldynamics consistent with known diurnal cycles.</description><author>Emmanuel Balogun, Ram Rajagopal, Arun Majumdar</author><pubDate>Fri, 19 Jan 2024 15:01:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17248v2</guid></item><item><title>Character Recognition in Byzantine Seals with Deep Neural Networks</title><link>http://arxiv.org/abs/2401.10741v1</link><description>Seals are small coin-shaped artifacts, mostly made of lead, held with stringsto seal letters. This work presents the first attempt towards automatic readingof text on Byzantine seal images.Byzantine seals are generally decorated withiconography on the obverse side and Greek text on the reverse side. Text mayinclude the sender's name, position in the Byzantine aristocracy, and elementsof prayers. Both text and iconography are precious literary sources that waitto be exploited electronically, so the development of computerized systems forinterpreting seals images is of paramount importance. This work's contributionis hence a deep, two-stages, character reading pipeline for transcribingByzantine seal images. A first deep convolutional neural network (CNN) detectscharacters in the seal (character localization). A second convolutional networkreads the localized characters (character classification). Finally, adiplomatic transcription of the seal is provided by post-processing the twonetwork outputs. We provide an experimental evaluation of each CNN in isolationand both CNNs in combination. All performances are evaluated bycross-validation. Character localization achieves a mean average precision(mAP@0.5) greater than 0.9. Classification of characters cropped from groundtruth bounding boxes achieves Top-1 accuracy greater than 0.92. End-to-endevaluation shows the efficiency of the proposed approach when compared to theSoTA for similar tasks.</description><author>Th√©ophile Rageau, Laurence Likforman-Sulem, Attilio Fiandrotti, Victoria Eyharabide, B√©atrice Caseau, Jean-Claude Cheynet</author><pubDate>Fri, 19 Jan 2024 14:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10741v1</guid></item><item><title>Let's do the time-warp-attend: Learning topological invariants of dynamical systems</title><link>http://arxiv.org/abs/2312.09234v2</link><description>Dynamical systems across the sciences, from electrical circuits to ecologicalnetworks, undergo qualitative and often catastrophic changes in behavior,called bifurcations, when their underlying parameters cross a threshold.Existing methods predict oncoming catastrophes in individual systems but areprimarily time-series-based and struggle both to categorize qualitativedynamical regimes across diverse systems and to generalize to real data. Toaddress this challenge, we propose a data-driven, physically-informeddeep-learning framework for classifying dynamical regimes and characterizingbifurcation boundaries based on the extraction of topologically invariantfeatures. We focus on the paradigmatic case of the supercritical Hopfbifurcation, which is used to model periodic dynamics across a wide range ofapplications. Our convolutional attention method is trained with dataaugmentations that encourage the learning of topological invariants which canbe used to detect bifurcation boundaries in unseen systems and to design modelsof biological systems like oscillatory gene regulatory networks. We furtherdemonstrate our method's use in analyzing real data by recovering distinctproliferation and differentiation dynamics along pancreatic endocrinogenesistrajectory in gene expression space based on single-cell data. Our methodprovides valuable insights into the qualitative, long-term behavior of a widerange of dynamical systems, and can detect bifurcations or catastrophictransitions in large-scale physical and biological systems.</description><author>Noa Moriel, Matthew Ricci, Mor Nitzan</author><pubDate>Fri, 19 Jan 2024 14:57:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09234v2</guid></item><item><title>$Œ±$-divergence Improves the Entropy Production Estimation via Machine Learning</title><link>http://arxiv.org/abs/2303.02901v2</link><description>Recent years have seen a surge of interest in the algorithmic estimation ofstochastic entropy production (EP) from trajectory data via machine learning. Acrucial element of such algorithms is the identification of a loss functionwhose minimization guarantees the accurate EP estimation. In this study, weshow that there exists a host of loss functions, namely those implementing avariational representation of the $\alpha$-divergence, which can be used forthe EP estimation. By fixing $\alpha$ to a value between $-1$ and $0$, the$\alpha$-NEEP (Neural Estimator for Entropy Production) exhibits a much morerobust performance against strong nonequilibrium driving or slow dynamics,which adversely affects the existing method based on the Kullback-Leiblerdivergence ($\alpha = 0$). In particular, the choice of $\alpha = -0.5$ tendsto yield the optimal results. To corroborate our findings, we present anexactly solvable simplification of the EP estimation problem, whose lossfunction landscape and stochastic properties give deeper intuition into therobustness of the $\alpha$-NEEP.</description><author>Euijoon Kwon, Yongjoo Baek</author><pubDate>Fri, 19 Jan 2024 14:53:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.02901v2</guid></item><item><title>Dynamic Q&amp;A of Clinical Documents with Large Language Models</title><link>http://arxiv.org/abs/2401.10733v1</link><description>Electronic health records (EHRs) house crucial patient data in clinicalnotes. As these notes grow in volume and complexity, manual extraction becomeschallenging. This work introduces a natural language interface using largelanguage models (LLMs) for dynamic question-answering on clinical notes. Ourchatbot, powered by Langchain and transformer-based LLMs, allows users to queryin natural language, receiving relevant answers from clinical notes.Experiments, utilizing various embedding models and advanced LLMs, show WizardVicuna's superior accuracy, albeit with high compute demands. Modeloptimization, including weight quantization, improves latency by approximately48 times. Promising results indicate potential, yet challenges such as modelhallucinations and limited diverse medical case evaluations remain. Addressingthese gaps is crucial for unlocking the value in clinical notes and advancingAI-driven clinical decision-making.</description><author>Ran Elgedawy, Sudarshan Srinivasan, Ioana Danciu</author><pubDate>Fri, 19 Jan 2024 14:50:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10733v1</guid></item><item><title>Bridging the gap between image coding for machines and humans</title><link>http://arxiv.org/abs/2401.10732v1</link><description>Image coding for machines (ICM) aims at reducing the bitrate required torepresent an image while minimizing the drop in machine vision analysisaccuracy. In many use cases, such as surveillance, it is also important thatthe visual quality is not drastically deteriorated by the compression process.Recent works on using neural network (NN) based ICM codecs have shownsignificant coding gains against traditional methods; however, the decompressedimages, especially at low bitrates, often contain checkerboard artifacts. Wepropose an effective decoder finetuning scheme based on adversarial training tosignificantly enhance the visual quality of ICM codecs, while preserving themachine analysis accuracy, without adding extra bitcost or parameters at theinference phase. The results show complete removal of the checkerboardartifacts at the negligible cost of -1.6% relative change in task performancescore. In the cases where some amount of artifacts is tolerable, such as whenmachine consumption is the primary target, this technique can enhance bothpixel-fidelity and feature-fidelity scores without losing task performance.</description><author>Nam Le, Honglei Zhang, Francesco Cricri, Ramin G. Youvalari, Hamed Rezazadegan Tavakoli, Emre Aksu, Miska M. Hannuksela, Esa Rahtu</author><pubDate>Fri, 19 Jan 2024 14:49:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10732v1</guid></item><item><title>Removal and Selection: Improving RGB-Infrared Object Detection via Coarse-to-Fine Fusion</title><link>http://arxiv.org/abs/2401.10731v1</link><description>Object detection in visible (RGB) and infrared (IR) images has been widelyapplied in recent years. Leveraging the complementary characteristics of RGBand IR images, the object detector provides reliable and robust objectlocalization from day to night. Existing fusion strategies directly inject RGBand IR images into convolution neural networks, leading to inferior detectionperformance. Since the RGB and IR features have modality-specific noise, thesestrategies will worsen the fused features along with the propagation. Inspiredby the mechanism of human brain processing multimodal information, this workintroduces a new coarse-to-fine perspective to purify and fuse two modalityfeatures. Specifically, following this perspective, we design a RedundantSpectrum Removal module to coarsely remove interfering information within eachmodality and a Dynamic Feature Selection module to finely select the desiredfeatures for feature fusion. To verify the effectiveness of the coarse-to-finefusion strategy, we construct a new object detector called Removal andSelection Detector (RSDet). Extensive experiments on three RGB-IR objectdetection datasets verify the superior performance of our method.</description><author>Tianyi Zhao, Maoxun Yuan, Xingxing Wei</author><pubDate>Fri, 19 Jan 2024 14:49:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10731v1</guid></item><item><title>Tool-LMM: A Large Multi-Modal Model for Tool Agent Learning</title><link>http://arxiv.org/abs/2401.10727v1</link><description>Recently, the astonishing performance of large language models (LLMs) innatural language comprehension and generation tasks triggered lots ofexploration of using them as central controllers to build agent systems.Multiple studies focus on bridging the LLMs to external tools to extend theapplication scenarios. However, the current LLMs' perceiving tool-use abilityis limited to a single text query, which may result in ambiguity inunderstanding the users' real intentions. LLMs are expected to eliminate thatby perceiving the visual- or auditory-grounded instructions' information.Therefore, in this paper, we propose Tool-LMM, a system incorporatingopen-source LLMs and multi-modal encoders so that the learnt LLMs can beconscious of multi-modal input instruction and then select the function-matchedtool correctly. To facilitate the evaluation of the model's capability, wecollect a dataset featured by consisting of multi-modal input tools fromHuggingFace. Another important feature of our dataset is that our dataset alsocontains multiple potential choices for the same instruction due to theexistence of identical functions and synonymous functions, which provides morepotential solutions for the same query. The experiments reveal that our LMM iscapable of recommending appropriate tools for multi-modal instructions. Codesand data are available at https://github.com/Tool-LMM/Tool-LMM.</description><author>Chenyu Wang, Weixin Luo, Qianyu Chen, Haonan Mai, Jindi Guo, Sixun Dong, Xiaohua, Xuan, Zhengxin Li, Lin Ma, Shenghua Gao</author><pubDate>Fri, 19 Jan 2024 14:44:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10727v1</guid></item><item><title>ClawCraneNet: Leveraging Object-level Relation for Text-based Video Segmentation</title><link>http://arxiv.org/abs/2103.10702v4</link><description>Text-based video segmentation is a challenging task that segments out thenatural language referred objects in videos. It essentially requires semanticcomprehension and fine-grained video understanding. Existing methods introducelanguage representation into segmentation models in a bottom-up manner, whichmerely conducts vision-language interaction within local receptive fields ofConvNets. We argue that such interaction is not fulfilled since the model canbarely construct region-level relationships given partial observations, whichis contrary to the description logic of natural language/referring expressions.In fact, people usually describe a target object using relations with otherobjects, which may not be easily understood without seeing the whole video. Toaddress the issue, we introduce a novel top-down approach by imitating how wehuman segment an object with the language guidance. We first figure out allcandidate objects in videos and then choose the refereed one by parsingrelations among those high-level objects. Three kinds of object-level relationsare investigated for precise relationship understanding, i.e., positionalrelation, text-guided semantic relation, and temporal relation. Extensiveexperiments on A2D Sentences and J-HMDB Sentences show our method outperformsstate-of-the-art methods by a large margin. Qualitative results also show ourresults are more explainable.</description><author>Chen Liang, Yu Wu, Yawei Luo, Yi Yang</author><pubDate>Fri, 19 Jan 2024 14:43:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2103.10702v4</guid></item><item><title>Empowering Aggregators with Practical Data-Driven Tools: Harnessing Aggregated and Disaggregated Flexibility for Demand Response</title><link>http://arxiv.org/abs/2401.10726v1</link><description>This study explores the crucial interplay between aggregators and buildingoccupants in activating flexibility through Demand Response (DR) programs, witha keen focus on achieving robust decarbonization and fortifying the resilienceof the energy system amidst the uncertainties presented by Renewable EnergySources (RES). Firstly, it introduces a methodology of optimizing aggregatedflexibility provision strategies in environments with limited data, utilizingDiscrete Fourier Transformation (DFT) and clustering techniques to identifybuilding occupant's activity patterns. Secondly, the study assesses thedisaggregated flexibility provision of Heating Ventilation and Air Conditioning(HVAC) systems during DR events, employing machine learning and optimizationtechniques for precise, device-level analysis. The first approach offers anon-intrusive pathway for aggregators to provide flexibility services inenvironments of a single smart meter for the whole building's consumption,while the second approach carefully considers building occupants' thermalcomfort profiles, while maximizing flexibility in case of existence ofdedicated smart meters to the HVAC systems. Through the application ofdata-driven techniques and encompassing case studies from both industrial andresidential buildings, this paper not only unveils pivotal opportunities foraggregators in the balancing and emerging flexibility markets but alsosuccessfully develops end-to-end practical tools for aggregators. Furthermore,the efficacy of this tool is validated through detailed case studies,substantiating its operational capability and contributing to the evolution ofa resilient and efficient energy system.</description><author>Costas Mylonas, Donata Boric, Leila Luttenberger Maric, Alexandros Tsitsanis, Eleftheria Petrianou, Magda Foti</author><pubDate>Fri, 19 Jan 2024 14:43:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10726v1</guid></item><item><title>Proceedings 14th International Conference on Automated Deduction in Geometry</title><link>http://arxiv.org/abs/2401.10725v1</link><description>ADG is a forum to exchange ideas and views, to present research results andprogress, and to demonstrate software tools at the intersection betweengeometry and automated deduction. The conference is held every two years. Theprevious editions of ADG were held in Hagenberg in 2021 (online, postponed from2020 due to COVID-19), Nanning in 2018, Strasbourg in 2016, Coimbra in 2014,Edinburgh in 2012, Munich in 2010, Shanghai in 2008, Pontevedra in 2006,Gainesville in 2004, Hagenberg in 2002, Zurich in 2000, Beijing in 1998, andToulouse in 1996. The 14th edition, ADG 2023, was held in Belgrade, Serbia, in September 20-22,2023. This edition of ADG had an additional special focus topic, Deduction inEducation. Invited Speakers: Julien Narboux, University of Strasbourg, France"Formalisation, arithmetization and automatisation of geometry"; Filip Mari\'c,University of Belgrade, Serbia, "Automatization, formalization andvisualization of hyperbolic geometry"; Zlatan Magajna, University of Ljubljana,Slovenia, "Workshop OK Geometry"</description><author>Pedro Quaresma, Zolt√°n Kov√°cs</author><pubDate>Fri, 19 Jan 2024 14:42:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10725v1</guid></item><item><title>Real-Time Zero-Day Intrusion Detection System for Automotive Controller Area Network on FPGAs</title><link>http://arxiv.org/abs/2401.10724v1</link><description>Increasing automation in vehicles enabled by increased connectivity to theoutside world has exposed vulnerabilities in previously siloed automotivenetworks like controller area networks (CAN). Attributes of CAN such asbroadcast-based communication among electronic control units (ECUs) thatlowered deployment costs are now being exploited to carry out active injectionattacks like denial of service (DoS), fuzzing, and spoofing attacks. Researchliterature has proposed multiple supervised machine learning models deployed asIntrusion detection systems (IDSs) to detect such malicious activity; however,these are largely limited to identifying previously known attack vectors. Withthe ever-increasing complexity of active injection attacks, detecting zero-day(novel) attacks in these networks in real-time (to prevent propagation) becomesa problem of particular interest. This paper presents anunsupervised-learning-based convolutional autoencoder architecture fordetecting zero-day attacks, which is trained only on benign (attack-free) CANmessages. We quantise the model using Vitis-AI tools from AMD/Xilinx targetinga resource-constrained Zynq Ultrascale platform as our IDS-ECU system forintegration. The proposed model successfully achieves equal or higherclassification accuracy (&gt; 99.5%) on unseen DoS, fuzzing, and spoofing attacksfrom a publicly available attack dataset when compared to the state-of-the-artunsupervised learning-based IDSs. Additionally, by cleverly overlapping IDSoperation on a window of CAN messages with the reception, the model is able tomeet line-rate detection (0.43 ms per window) of high-speed CAN, which whencoupled with the low energy consumption per inference, makes this architectureideally suited for detecting zero-day attacks on critical CAN networks.</description><author>Shashwat Khandelwal, Shreejith Shanker</author><pubDate>Fri, 19 Jan 2024 14:36:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10724v1</guid></item><item><title>A Foundation Graph Model</title><link>http://arxiv.org/abs/2311.03976v2</link><description>The principal benefit of unsupervised graph representation learning is that apre-trained model can be fine-tuned where data or labels are scarce. Existingapproaches are domain specific, maintaining consistent node and edge attributesacross the pre-training and target datasets. This precludes transfer to otherdomains. A model capable of positive transfer on arbitrary tasks and domainswould represent the first foundation graph model. In this work we use adversarial contrastive learning to present FoToM, agraph pre-training method based on node and edge feature exclusion. We useFoToM to pre-train models over multiple graph domains, producing the firstfoundation graph models. We demonstrate positive transfer on evaluationdatasets from multiple domains, including domains not present in pre-trainingdata. On all datasets performance is at worst on-par and on 76% significantlybetter than a supervised baseline ($P \leq 0.01$), with an 8 to 40% reductionin error at 95% confidence. Contrary to other research, pre-training on adataset with the target domain excluded leads us to better performance thanpre-training on a dataset from only the target domain. The multi-domain modelat worst, matches, and on 56% of tasks, significantly outperforms single-domain($P \leq 0.01$). These results include when node labels are used in evaluation,where performance is consistently superior to single-domain or non-pre-trainedmodels. Notably, FoToM benefits scenarios in both large or scarce data regimesfor the target domains.</description><author>Alex O. Davies, Riku W. Green, Nirav S. Ajmeri, Telmo M. Silva Filho</author><pubDate>Fri, 19 Jan 2024 14:34:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03976v2</guid></item><item><title>Generative Model for Constructing Reaction Path from Initial to Final States</title><link>http://arxiv.org/abs/2401.10721v1</link><description>Mapping out reaction pathways and their corresponding activation barriers isa significant aspect of molecular simulation. Given their inherent complexityand nonlinearity, even generating a initial guess of these paths remains achallenging problem. Presented in this paper is an innovative approach thatutilizes neural networks to generate initial guess for these reaction pathways.The proposed method is initiated by inputting the coordinates of the initialstate, followed by progressive alterations to its structure. This iterativeprocess culminates in the generation of the approximate representation of thereaction path and the coordinates of the final state. The application of thismethod extends to complex reaction pathways illustrated by organic reactions.Training was executed on the Transition1x dataset, an organic reaction pathwaydataset. The results revealed generation of reactions that bore substantialsimilarities with the corresponding test data. The method's flexibility allowsfor reactions to be generated either to conform to predetermined conditions orin a randomized manner.</description><author>Akihide Hayashi, So Takamoto, Ju Li, Daisuke Okanohara</author><pubDate>Fri, 19 Jan 2024 14:32:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10721v1</guid></item><item><title>Structured Code Representations Enable Data-Efficient Adaptation of Code Language Models</title><link>http://arxiv.org/abs/2401.10716v1</link><description>Current language models tailored for code tasks often adopt thepre-training-then-fine-tuning paradigm from natural language processing,modeling source code as plain text. This approach, however, overlooks theunambiguous structures inherent in programming languages. In this work, weexplore data-efficient adaptation of pre-trained code models by furtherpre-training and fine-tuning them with program structures. Specifically, werepresent programs as parse trees -- also known as concrete syntax trees (CSTs)-- and adapt pre-trained models on serialized CSTs. Although the models that weadapt have been pre-trained only on the surface form of programs, we find thata small amount of continual pre-training and fine-tuning on CSTs withoutchanging the model architecture yields improvements over the baseline approachacross various code tasks. The improvements are found to be particularlysignificant when there are limited training examples, demonstrating theeffectiveness of integrating program structures with plain-text representationeven when working with backbone models that have not been pre-trained withstructures.</description><author>Mayank Agarwal, Yikang Shen, Bailin Wang, Yoon Kim, Jie Chen</author><pubDate>Fri, 19 Jan 2024 14:27:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10716v1</guid></item><item><title>Q&amp;A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge</title><link>http://arxiv.org/abs/2401.10712v1</link><description>With the breakthrough of multi-modal large language models, answering complexvisual questions that demand advanced reasoning abilities and world knowledgehas become a much more important testbed for developing AI models than ever.However, equipping AI models with robust cross-modality reasoning abilityremains challenging since the cognition scheme of humans has not beenunderstood systematically. In this paper, we believe that if we can collectvisual clues in the given image as much as possible, we will recognize theimage more accurately, understand the question better, recall relevantknowledge more easily, and finally reason out the answer. We discover theserich visual clues by mining question-answer pairs in images and sending theminto multi-modal large language models as prompts. We call the proposed methodQ&amp;A Prompts. Specifically, we first use the image-answer pairs and thecorresponding questions in the training set as inputs and outputs to train avisual question generation model. Then, we use an image tagging model toidentify various instances and send packaged image-tag pairs into the visualquestion generation model to generate relevant questions with the extractedimage tags as answers. Finally, we encode these generated question-answer pairsas prompts with a visual-aware prompting module and send them into pre-trainedmulti-modal large language models to reason out the final answers. Experimentalresults show that, compared with state-of-the-art methods, our Q&amp;A Promptsachieves substantial improvements on the challenging visual question answeringdatasets requiring reasoning over diverse world knowledge, such as OK-VQA andA-OKVQA.</description><author>Haibi Wang, Weifeng Ge</author><pubDate>Fri, 19 Jan 2024 14:22:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10712v1</guid></item><item><title>Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal Models for Video Question Answering</title><link>http://arxiv.org/abs/2401.10711v1</link><description>Video Question Answering (VideoQA) aims to answer natural language questionsbased on the information observed in videos. Despite the recent success ofLarge Multimodal Models (LMMs) in image-language understanding and reasoning,they deal with VideoQA insufficiently by simply taking uniformly sampled framesas visual inputs, which ignores question-relevant visual clues. Moreover, thereare no human annotations for question-critical timestamps in existing VideoQAdatasets. In light of this, we propose a novel weakly supervised framework toenforce the LMMs to reason out the answers with question-critical moments asvisual inputs. Specifically, we fuse the question and answer pairs as eventdescriptions to find multiple keyframes as target moments, which will bepseudo-labels. With these pseudo-labels as additionally weak supervision, wedevise a lightweight Gaussian-based Contrastive Grounding (GCG) module. GCGlearns multiple Gaussian functions to characterize the temporal structure ofthe video, and sample question-critical frames as positive moments to be thevisual inputs of LMMs. Extensive experiments on several VideoQA benchmarksverify the effectiveness of our framework, and we achieve substantialimprovements compared to previous state-of-the-art methods.</description><author>Haibo Wang, Chenghang Lai, Yixuan Sun, Weifeng Ge</author><pubDate>Fri, 19 Jan 2024 14:21:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10711v1</guid></item><item><title>Classification with neural networks with quadratic decision functions</title><link>http://arxiv.org/abs/2401.10710v1</link><description>Neural network with quadratic decision functions have been introduced asalternatives to standard neural networks with affine linear one. They areadvantageous when the objects to be identified are of compact basic geometrieslike circles, ellipsis etc. In this paper we investigate the use of such ansatzfunctions for classification. In particular we test and compare the algorithmon the MNIST dataset for classification of handwritten digits and forclassification of subspecies. We also show, that the implementation can bebased on the neural network structure in the software Tensorflow and Keras,respectively.</description><author>Leon Frischauf, Otmar Scherzer, Cong Shi</author><pubDate>Fri, 19 Jan 2024 14:18:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10710v1</guid></item><item><title>Dense 3D Reconstruction Through Lidar: A Comparative Study on Ex-vivo Porcine Tissue</title><link>http://arxiv.org/abs/2401.10709v1</link><description>New sensing technologies and more advanced processing algorithms aretransforming computer-integrated surgery. While researchers are activelyinvestigating depth sensing and 3D reconstruction for vision-based surgicalassistance, it remains difficult to achieve real-time, accurate, and robust 3Drepresentations of the abdominal cavity for minimally invasive surgery. Thus,this work uses quantitative testing on fresh ex-vivo porcine tissue tothoroughly characterize the quality with which a 3D laser-based time-of-flightsensor (lidar) can perform anatomical surface reconstruction. Ground-truthsurface shapes are captured with a commercial laser scanner, and the resultingsigned error fields are analyzed using rigorous statistical tools. Whencompared to modern learning-based stereo matching from endoscopic images,time-of-flight sensing demonstrates higher precision, lower processing delay,higher frame rate, and superior robustness against sensor distance and poorillumination. Furthermore, we report on the potential negative effect ofnear-infrared light penetration on the accuracy of lidar measurements acrossdifferent tissue samples, identifying a significant measured depth offset formuscle in contrast to fat and liver. Our findings highlight the potential oflidar for intraoperative 3D perception and point toward new methods thatcombine complementary time-of-flight and spectral imaging.</description><author>Guido Caccianiga, Julian Nubert, Marco Hutter, Katherine J. Kuchenbecker</author><pubDate>Fri, 19 Jan 2024 14:14:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10709v1</guid></item><item><title>PoseScript: Linking 3D Human Poses and Natural Language</title><link>http://arxiv.org/abs/2210.11795v2</link><description>Natural language plays a critical role in many computer vision applications,such as image captioning, visual question answering, and cross-modal retrieval,to provide fine-grained semantic information. Unfortunately, while human poseis key to human understanding, current 3D human pose datasets lack detailedlanguage descriptions. To address this issue, we have introduced the PoseScriptdataset. This dataset pairs more than six thousand 3D human poses from AMASSwith rich human-annotated descriptions of the body parts and their spatialrelationships. Additionally, to increase the size of the dataset to a scalethat is compatible with data-hungry learning algorithms, we have proposed anelaborate captioning process that generates automatic synthetic descriptions innatural language from given 3D keypoints. This process extracts low-level poseinformation, known as "posecodes", using a set of simple but generic rules onthe 3D keypoints. These posecodes are then combined into higher level textualdescriptions using syntactic rules. With automatic annotations, the amount ofavailable data significantly scales up (100k), making it possible toeffectively pretrain deep models for finetuning on human captions. To showcasethe potential of annotated poses, we present three multi-modal learning tasksthat utilize the PoseScript dataset. Firstly, we develop a pipeline that maps3D poses and textual descriptions into a joint embedding space, allowing forcross-modal retrieval of relevant poses from large-scale datasets. Secondly, weestablish a baseline for a text-conditioned model generating 3D poses. Thirdly,we present a learned process for generating pose descriptions. Theseapplications demonstrate the versatility and usefulness of annotated poses invarious tasks and pave the way for future research in the field.</description><author>Ginger Delmas, Philippe Weinzaepfel, Thomas Lucas, Francesc Moreno-Noguer, Gr√©gory Rogez</author><pubDate>Fri, 19 Jan 2024 14:08:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.11795v2</guid></item><item><title>Privacy-Preserving Neural Graph Databases</title><link>http://arxiv.org/abs/2312.15591v2</link><description>In the era of big data and rapidly evolving information systems, efficientand accurate data retrieval has become increasingly crucial. Neural graphdatabases (NGDBs) have emerged as a powerful paradigm that combines thestrengths of graph databases (graph DBs) and neural networks to enableefficient storage, retrieval, and analysis of graph-structured data. The usageof neural embedding storage and complex neural logical query answering providesNGDBs with generalization ability. When the graph is incomplete, by extractinglatent patterns and representations, neural graph databases can fill gaps inthe graph structure, revealing hidden relationships and enabling accurate queryanswering. Nevertheless, this capability comes with inherent trade-offs, as itintroduces additional privacy risks to the database. Malicious attackers caninfer more sensitive information in the database using well-designedcombinatorial queries, such as by comparing the answer sets of where TuringAward winners born before 1950 and after 1940 lived, the living places ofTuring Award winner Hinton are probably exposed, although the living places mayhave been deleted in the training due to the privacy concerns. In this work,inspired by the privacy protection in graph embeddings, we propose aprivacy-preserving neural graph database (P-NGDB) to alleviate the risks ofprivacy leakage in NGDBs. We introduce adversarial training techniques in thetraining stage to force the NGDBs to generate indistinguishable answers whenqueried with private information, enhancing the difficulty of inferringsensitive information through combinations of multiple innocuous queries.Extensive experiment results on three datasets show that P-NGDB can effectivelyprotect private information in the graph database while delivering high-qualitypublic answers responses to queries.</description><author>Qi Hu, Haoran Li, Jiaxin Bai, Yangqiu Song</author><pubDate>Fri, 19 Jan 2024 14:08:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15591v2</guid></item><item><title>Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion Model</title><link>http://arxiv.org/abs/2401.10700v1</link><description>Safe offline RL is a promising way to bypass risky online interactionstowards safe policy learning. Most existing methods only enforce softconstraints, i.e., constraining safety violations in expectation belowthresholds predetermined. This can lead to potentially unsafe outcomes, thusunacceptable in safety-critical scenarios. An alternative is to enforce thehard constraint of zero violation. However, this can be challenging in offlinesetting, as it needs to strike the right balance among three highly intricateand correlated aspects: safety constraint satisfaction, reward maximization,and behavior regularization imposed by offline datasets. Interestingly, wediscover that via reachability analysis of safe-control theory, the hard safetyconstraint can be equivalently translated to identifying the largest feasibleregion given the offline dataset. This seamlessly converts the original trilogyproblem to a feasibility-dependent objective, i.e., maximizing reward valuewithin the feasible region while minimizing safety risks in the infeasibleregion. Inspired by these, we propose FISOR (FeasIbility-guided Safe OfflineRL), which allows safety constraint adherence, reward maximization, and offlinepolicy learning to be realized via three decoupled processes, while offeringstrong safety performance and stability. In FISOR, the optimal policy for thetranslated optimization problem can be derived in a special form of weightedbehavior cloning. Thus, we propose a novel energy-guided diffusion model thatdoes not require training a complicated time-dependent classifier to extractthe policy, greatly simplifying the training. We compare FISOR againstbaselines on DSRL benchmark for safe offline RL. Evaluation results show thatFISOR is the only method that can guarantee safety satisfaction in all tasks,while achieving top returns in most tasks.</description><author>Yinan Zheng, Jianxiong Li, Dongjie Yu, Yujie Yang, Shengbo Eben Li, Xianyuan Zhan, Jingjing Liu</author><pubDate>Fri, 19 Jan 2024 14:05:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10700v1</guid></item><item><title>Interplay between depth and width for interpolation in neural ODEs</title><link>http://arxiv.org/abs/2401.09902v2</link><description>Neural ordinary differential equations (neural ODEs) have emerged as anatural tool for supervised learning from a control perspective, yet a completeunderstanding of their optimal architecture remains elusive. In this work, weexamine the interplay between their width $p$ and number of layer transitions$L$ (effectively the depth $L+1$). Specifically, we assess the modelexpressivity in terms of its capacity to interpolate either a finite dataset$D$ comprising $N$ pairs of points or two probability measures in$\mathbb{R}^d$ within a Wasserstein error margin $\varepsilon&gt;0$. Our findingsreveal a balancing trade-off between $p$ and $L$, with $L$ scaling as$O(1+N/p)$ for dataset interpolation, and$L=O\left(1+(p\varepsilon^d)^{-1}\right)$ for measure interpolation. In the autonomous case, where $L=0$, a separate study is required, which weundertake focusing on dataset interpolation. We address the relaxed problem of$\varepsilon$-approximate controllability and establish an error decay of$\varepsilon\sim O(\log(p)p^{-1/d})$. This decay rate is a consequence ofapplying a universal approximation theorem to a custom-built Lipschitz vectorfield that interpolates $D$. In the high-dimensional setting, we furtherdemonstrate that $p=O(N)$ neurons are likely sufficient to achieve exactcontrol.</description><author>Antonio √Ålvarez-L√≥pez, Arselane Hadj Slimane, Enrique Zuazua</author><pubDate>Fri, 19 Jan 2024 14:04:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09902v2</guid></item><item><title>LangBridge: Multilingual Reasoning Without Multilingual Supervision</title><link>http://arxiv.org/abs/2401.10695v1</link><description>We introduce LangBridge, a zero-shot approach to adapt language models formultilingual reasoning tasks without multilingual supervision. LangBridgeoperates by bridging two models, each specialized in different aspects: (1) onespecialized in understanding multiple languages (e.g., mT5 encoder) and (2) onespecialized in reasoning (e.g., Orca 2). LangBridge connects the two models byintroducing minimal trainable parameters between them. Despite utilizing onlyEnglish data for training, LangBridge considerably enhances the performance oflanguage models on low-resource languages across mathematical reasoning,coding, and logical reasoning. Our analysis suggests that the efficacy ofLangBridge stems from the language-agnostic characteristics of multilingualrepresentations. We publicly release our code and models.</description><author>Dongkeun Yoon, Joel Jang, Sungdong Kim, Seungone Kim, Sheikh Shafayat, Minjoon Seo</author><pubDate>Fri, 19 Jan 2024 14:00:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10695v1</guid></item><item><title>Rethinking Cross-modal Interaction from a Top-down Perspective for Referring Video Object Segmentation</title><link>http://arxiv.org/abs/2106.01061v2</link><description>Referring video object segmentation (RVOS) aims to segment video objects withthe guidance of natural language reference. Previous methods typically tackleRVOS through directly grounding linguistic reference over the image lattice.Such bottom-up strategy fails to explore object-level cues, easily leading toinferior results. In this work, we instead put forward a two-stage, top-downRVOS solution. First, an exhaustive set of object tracklets is constructed bypropagating object masks detected from several sampled frames to the entirevideo. Second, a Transformer-based tracklet-language grounding module isproposed, which models instance-level visual relations and cross-modalinteractions simultaneously and efficiently. Our model ranks first place onCVPR2021 Referring Youtube-VOS challenge.</description><author>Chen Liang, Yu Wu, Tianfei Zhou, Wenguan Wang, Zongxin Yang, Yunchao Wei, Yi Yang</author><pubDate>Fri, 19 Jan 2024 13:44:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.01061v2</guid></item><item><title>Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and unfairness in dyadic regression models</title><link>http://arxiv.org/abs/2401.10690v1</link><description>Dyadic regression models, which predict real-valued outcomes for pairs ofentities, are fundamental in many domains (e.g. predicting the rating of a userto a product in Recommender Systems) and promising and under exploration inmany others (e.g. approximating the adequate dosage of a drug for a patient inpersonalized pharmacology). In this work, we demonstrate that non-uniformity inthe observed value distributions of individual entities leads to severelybiased predictions in state-of-the-art models, skewing predictions towards theaverage of observed past values for the entity and providing worse-than-randompredictive power in eccentric yet equally important cases. We show that theusage of global error metrics like Root Mean Squared Error (RMSE) and MeanAbsolute Error (MAE) is insufficient to capture this phenomenon, which we nameeccentricity bias, and we introduce Eccentricity-Area Under the Curve (EAUC) asa new complementary metric that can quantify it in all studied models anddatasets. We also prove the adequateness of EAUC by using naive de-biasingcorrections to demonstrate that a lower model bias correlates with a lower EAUCand vice-versa. This work contributes a bias-aware evaluation of dyadicregression models to avoid potential unfairness and risks in criticalreal-world applications of such systems.</description><author>Jorge Paz-Ruza, Amparo Alonso-Betanzos, Bertha Guijarro-Berdi√±as, Brais Cancela, Carlos Eiras-Franco</author><pubDate>Fri, 19 Jan 2024 13:41:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10690v1</guid></item><item><title>A Lightweight Multi-Attack CAN Intrusion Detection System on Hybrid FPGAs</title><link>http://arxiv.org/abs/2401.10689v1</link><description>Rising connectivity in vehicles is enabling new capabilities like connectedautonomous driving and advanced driver assistance systems (ADAS) for improvingthe safety and reliability of next-generation vehicles. This increased accessto in-vehicle functions compromises critical capabilities that use legacyinvehicle networks like Controller Area Network (CAN), which has no inherentsecurity or authentication mechanism. Intrusion detection and mitigationapproaches, particularly using machine learning models, have shown promisingresults in detecting multiple attack vectors in CAN through their ability togeneralise to new vectors. However, most deployments require dedicatedcomputing units like GPUs to perform line-rate detection, consuming much higherpower. In this paper, we present a lightweight multi-attack quantised machinelearning model that is deployed using Xilinx's Deep Learning Processing Unit IPon a Zynq Ultrascale+ (XCZU3EG) FPGA, which is trained and validated using thepublic CAN Intrusion Detection dataset. The quantised model detects denial ofservice and fuzzing attacks with an accuracy of above 99 % and a false positiverate of 0.07%, which are comparable to the state-of-the-art techniques in theliterature. The Intrusion Detection System (IDS) execution consumes just 2.0 Wwith software tasks running on the ECU and achieves a 25 % reduction inper-message processing latency over the state-of-the-art implementations. Thisdeployment allows the ECU function to coexist with the IDS with minimal changesto the tasks, making it ideal for real-time IDS in in-vehicle systems.</description><author>Shashwat Khandelwal, Shreejith Shanker</author><pubDate>Fri, 19 Jan 2024 13:39:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10689v1</guid></item><item><title>Manipulating Sparse Double Descent</title><link>http://arxiv.org/abs/2401.10686v1</link><description>This paper investigates the double descent phenomenon in two-layer neuralnetworks, focusing on the role of L1 regularization and representationdimensions. It explores an alternative double descent phenomenon, named sparsedouble descent. The study emphasizes the complex relationship between modelcomplexity, sparsity, and generalization, and suggests further research intomore diverse models and datasets. The findings contribute to a deeperunderstanding of neural network training and optimization.</description><author>Ya Shi Zhang</author><pubDate>Fri, 19 Jan 2024 13:33:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10686v1</guid></item><item><title>Efficient slot labelling</title><link>http://arxiv.org/abs/2401.09343v2</link><description>Slot labelling is an essential component of any dialogue system, aiming tofind important arguments in every user turn. Common approaches involve largepre-trained language models (PLMs) like BERT or RoBERTa, but they facechallenges such as high computational requirements and dependence onpre-training data. In this work, we propose a lightweight method which performson par or better than the state-of-the-art PLM-based methods, while havingalmost 10x less trainable parameters. This makes it especially applicable forreal-life industry scenarios.</description><author>Vladimir Vlasov</author><pubDate>Fri, 19 Jan 2024 13:33:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09343v2</guid></item><item><title>Towards End-to-End GPS Localization with Neural Pseudorange Correction</title><link>http://arxiv.org/abs/2401.10685v1</link><description>Pseudorange errors are the root cause of localization inaccuracy in GPS.Previous data-driven methods regress and eliminate pseudorange errors usinghandcrafted intermediate labels. Unlike them, we propose an end-to-end GPSlocalization framework, E2E-PrNet, to train a neural network for pseudorangecorrection (PrNet) directly using the final task loss calculated with theground truth of GPS receiver states. The gradients of the loss with respect tolearnable parameters are backpropagated through a differentiable nonlinearleast squares optimizer to PrNet. The feasibility is verified with GPS datacollected by Android phones, showing that E2E-PrNet outperforms thestate-of-the-art end-to-end GPS localization methods.</description><author>Xu Weng, KV Ling, Haochen Liu, Kun Cao</author><pubDate>Fri, 19 Jan 2024 13:32:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10685v1</guid></item><item><title>IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing</title><link>http://arxiv.org/abs/2301.13359v4</link><description>Image anomaly detection (IAD) is an emerging and vital computer vision taskin industrial manufacturing (IM). Recently, many advanced algorithms have beenreported, but their performance deviates considerably with various IM settings.We realize that the lack of a uniform IM benchmark is hindering the developmentand usage of IAD methods in real-world applications. In addition, it isdifficult for researchers to analyze IAD algorithms without a uniformbenchmark. To solve this problem, we propose a uniform IM benchmark, for thefirst time, to assess how well these algorithms perform, which includes variouslevels of supervision (unsupervised versus fully supervised), learningparadigms (few-shot, continual and noisy label), and efficiency (memory usageand inference speed). Then, we construct a comprehensive image anomalydetection benchmark (IM-IAD), which includes 19 algorithms on seven majordatasets with a uniform setting. Extensive experiments (17,017 total) on IM-IADprovide in-depth insights into IAD algorithm redesign or selection. Moreover,the proposed IM-IAD benchmark challenges existing algorithms and suggestsfuture research directions. To foster reproducibility and accessibility, thesource code of IM-IAD is uploaded on the website,https://github.com/M-3LAB/IM-IAD.</description><author>Guoyang Xie, Jinbao Wang, Jiaqi Liu, Jiayi Lyu, Yong Liu, Chengjie Wang, Feng Zheng, Yaochu Jin</author><pubDate>Fri, 19 Jan 2024 13:25:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13359v4</guid></item><item><title>Exploring Iterative Enhancement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models</title><link>http://arxiv.org/abs/2309.10444v3</link><description>Large language models exhibit superior capabilities in processing andunderstanding language, yet their applications in educational contexts remainunderexplored. Learnersourcing enhances learning by engaging students increating their own educational content. When learnersourcing multiple-choicequestions, creating explanations for the solution of a question is a crucialstep; it helps other students understand the solution and promotes a deeperunderstanding of related concepts. However, it is often difficult for studentsto craft effective solution explanations, due to limited subject understanding.To help scaffold the task of automated explanation generation, we present andevaluate a framework called "ILearner-LLM", that iteratively enhances thegenerated explanations for the given questions with large language models.Comprising an explanation generation model and an explanation evaluation model,the framework generates high-quality student-aligned explanations byiteratively feeding the quality rating score from the evaluation model backinto the instruction prompt of the explanation generation model. Experimentalresults demonstrate the effectiveness of our ILearner-LLM on LLaMA2-13B andGPT-4 to generate higher quality explanations that are closer to those writtenby students on five PeerWise datasets. Our findings represent a promising pathto enrich the learnersourcing experience for students and to enhance thecapabilities of large language models for educational applications.</description><author>Qiming Bao, Juho Leinonen, Alex Yuxuan Peng, Wanjun Zhong, Ga√´l Gendron, Timothy Pistotti, Alice Huang, Paul Denny, Michael Witbrock, Jiamou Liu</author><pubDate>Fri, 19 Jan 2024 13:19:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10444v3</guid></item></channel></rss>