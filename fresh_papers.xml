<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 20 Jun 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Depth Anywhere: Enhancing 360 Monocular Depth Estimation via Perspective Distillation and Unlabeled Data Augmentation</title><link>http://arxiv.org/abs/2406.12849v1</link><description>Accurately estimating depth in 360-degree imagery is crucial for virtualreality, autonomous navigation, and immersive media applications. Existingdepth estimation methods designed for perspective-view imagery fail whenapplied to 360-degree images due to different camera projections anddistortions, whereas 360-degree methods perform inferior due to the lack oflabeled data pairs. We propose a new depth estimation framework that utilizesunlabeled 360-degree data effectively. Our approach uses state-of-the-artperspective depth estimation models as teacher models to generate pseudo labelsthrough a six-face cube projection technique, enabling efficient labeling ofdepth in 360-degree images. This method leverages the increasing availabilityof large datasets. Our approach includes two main stages: offline maskgeneration for invalid regions and an online semi-supervised joint trainingregime. We tested our approach on benchmark datasets such as Matterport3D andStanford2D3D, showing significant improvements in depth estimation accuracy,particularly in zero-shot scenarios. Our proposed training pipeline can enhanceany 360 monocular depth estimator and demonstrates effective knowledge transferacross different camera projections and data types. See our project page forresults: https://albert100121.github.io/Depth-Anywhere/</description><author>Ning-Hsu Wang, Yu-Lun Liu</author><pubDate>Tue, 18 Jun 2024 18:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12849v1</guid></item><item><title>ChangeViT: Unleashing Plain Vision Transformers for Change Detection</title><link>http://arxiv.org/abs/2406.12847v1</link><description>Change detection in remote sensing images is essential for trackingenvironmental changes on the Earth's surface. Despite the success of visiontransformers (ViTs) as backbones in numerous computer vision applications, theyremain underutilized in change detection, where convolutional neural networks(CNNs) continue to dominate due to their powerful feature extractioncapabilities. In this paper, our study uncovers ViTs' unique advantage indiscerning large-scale changes, a capability where CNNs fall short.Capitalizing on this insight, we introduce ChangeViT, a framework that adopts aplain ViT backbone to enhance the performance of large-scale changes. Thisframework is supplemented by a detail-capture module that generates detailedspatial features and a feature injector that efficiently integratesfine-grained spatial information into high-level semantic learning. The featureintegration ensures that ChangeViT excels in both detecting large-scale changesand capturing fine-grained details, providing comprehensive change detectionacross diverse scales. Without bells and whistles, ChangeViT achievesstate-of-the-art performance on three popular high-resolution datasets (i.e.,LEVIR-CD, WHU-CD, and CLCD) and one low-resolution dataset (i.e., OSCD), whichunderscores the unleashed potential of plain ViTs for change detection.Furthermore, thorough quantitative and qualitative analyses validate theefficacy of the introduced modules, solidifying the effectiveness of ourapproach. The source code is available athttps://github.com/zhuduowang/ChangeViT.</description><author>Duowang Zhu, Xiaohu Huang, Haiyan Huang, Zhenfeng Shao, Qimin Cheng</author><pubDate>Tue, 18 Jun 2024 18:59:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12847v1</guid></item><item><title>DrVideo: Document Retrieval Based Long Video Understanding</title><link>http://arxiv.org/abs/2406.12846v1</link><description>Existing methods for long video understanding primarily focus on videos onlylasting tens of seconds, with limited exploration of techniques for handlinglonger videos. The increased number of frames in longer videos presents twomain challenges: difficulty in locating key information and performinglong-range reasoning. Thus, we propose DrVideo, a document-retrieval-basedsystem designed for long video understanding. Our key idea is to convert thelong-video understanding problem into a long-document understanding task so asto effectively leverage the power of large language models. Specifically,DrVideo transforms a long video into a text-based long document to initiallyretrieve key frames and augment the information of these frames, which is usedthis as the system's starting point. It then employs an agent-based iterativeloop to continuously search for missing information, augment relevant data, andprovide final predictions in a chain-of-thought manner once sufficientquestion-related information is gathered. Extensive experiments on long videobenchmarks confirm the effectiveness of our method. DrVideo outperformsexisting state-of-the-art methods with +3.8 accuracy on EgoSchema benchmark (3minutes), +17.9 in MovieChat-1K break mode, +38.0 in MovieChat-1K global mode(10 minutes), and +30.2 on the LLama-Vid QA dataset (over 60 minutes).</description><author>Ziyu Ma, Chenhui Gou, Hengcan Shi, Bin Sun, Shutao Li, Hamid Rezatofighi, Jianfei Cai</author><pubDate>Tue, 18 Jun 2024 18:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12846v1</guid></item><item><title>Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts</title><link>http://arxiv.org/abs/2406.12845v1</link><description>Reinforcement learning from human feedback (RLHF) has emerged as the primarymethod for aligning large language models (LLMs) with human preferences. TheRLHF process typically starts by training a reward model (RM) using humanpreference data. Conventional RMs are trained on pairwise responses to the sameuser request, with relative ratings indicating which response humans prefer.The trained RM serves as a proxy for human preferences. However, due to theblack-box nature of RMs, their outputs lack interpretability, as humans cannotintuitively understand why an RM thinks a response is good or not. As RMs actas human preference proxies, we believe they should be human-interpretable toensure that their internal decision processes are consistent with humanpreferences and to prevent reward hacking in LLM alignment. To build RMs withinterpretable preferences, we propose a two-stage approach: i) train anAbsolute-Rating Multi-Objective Reward Model (ArmoRM) with multi-dimensionalabsolute-rating data, each dimension corresponding to a human-interpretableobjective (e.g., honesty, verbosity, safety); ii) employ a Mixture-of-Experts(MoE) strategy with a gating network that automatically selects the mostsuitable reward objectives based on the context. We efficiently trained anArmoRM with Llama-3 8B and a gating network consisting of a shallow MLP on topof the ArmoRM. Our trained model, ArmoRM-Llama3-8B, obtains state-of-the-artperformance on RewardBench, a benchmark evaluating RMs for language modeling.Notably, the performance of our model surpasses the LLM-as-a-judge method withGPT-4 judges by a margin, and approaches the performance of the much largerNemotron-4 340B reward model.</description><author>Haoxiang Wang, Wei Xiong, Tengyang Xie, Han Zhao, Tong Zhang</author><pubDate>Tue, 18 Jun 2024 18:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12845v1</guid></item><item><title>Synergizing Foundation Models and Federated Learning: A Survey</title><link>http://arxiv.org/abs/2406.12844v1</link><description>The recent development of Foundation Models (FMs), represented by largelanguage models, vision transformers, and multimodal models, has been making asignificant impact on both academia and industry. Compared with small-scalemodels, FMs have a much stronger demand for high-volume data during thepre-training phase. Although general FMs can be pre-trained on data collectedfrom open sources such as the Internet, domain-specific FMs need proprietarydata, posing a practical challenge regarding the amount of data available dueto privacy concerns. Federated Learning (FL) is a collaborative learningparadigm that breaks the barrier of data availability from differentparticipants. Therefore, it provides a promising solution to customize andadapt FMs to a wide range of domain-specific tasks using distributed datasetswhilst preserving privacy. This survey paper discusses the potentials andchallenges of synergizing FL and FMs and summarizes core techniques, futuredirections, and applications. A periodically updated paper collection on FM-FLis available at https://github.com/lishenghui/awesome-fm-fl.</description><author>Shenghui Li, Fanghua Ye, Meng Fang, Jiaxu Zhao, Yun-Hin Chan, Edith C. -H. Ngai, Thiemo Voigt</author><pubDate>Tue, 18 Jun 2024 18:58:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12844v1</guid></item><item><title>Can Go AIs be adversarially robust?</title><link>http://arxiv.org/abs/2406.12843v1</link><description>Prior work found that superhuman Go AIs like KataGo can be defeated by simpleadversarial strategies. In this paper, we study if simple defenses can improveKataGo's worst-case performance. We test three natural defenses: adversarialtraining on hand-constructed positions, iterated adversarial training, andchanging the network architecture. We find that some of these defenses are ableto protect against previously discovered attacks. Unfortunately, we also findthat none of these defenses are able to withstand adaptive attacks. Inparticular, we are able to train new adversaries that reliably defeat ourdefended agents by causing them to blunder in ways humans would not. Ourresults suggest that building robust AI systems is challenging even in narrowdomains such as Go. For interactive examples of attacks and a link to ourcodebase, see https://goattack.far.ai.</description><author>Tom Tseng, Euan McLean, Kellin Pelrine, Tony T. Wang, Adam Gleave</author><pubDate>Tue, 18 Jun 2024 18:57:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12843v1</guid></item><item><title>Demystifying Higher-Order Graph Neural Networks</title><link>http://arxiv.org/abs/2406.12841v1</link><description>Higher-order graph neural networks (HOGNNs) are an important class of GNNmodels that harness polyadic relations between vertices beyond plain edges.They have been used to eliminate issues such as over-smoothing orover-squashing, to significantly enhance the accuracy of GNN predictions, toimprove the expressiveness of GNN architectures, and for numerous other goals.A plethora of HOGNN models have been introduced, and they come with diverseneural architectures, and even with different notions of what the"higher-order" means. This richness makes it very challenging to appropriatelyanalyze and compare HOGNN models, and to decide in what scenario to usespecific ones. To alleviate this, we first design an in-depth taxonomy and ablueprint for HOGNNs. This facilitates designing models that maximizeperformance. Then, we use our taxonomy to analyze and compare the availableHOGNN models. The outcomes of our analysis are synthesized in a set of insightsthat help to select the most beneficial GNN model in a given scenario, and acomprehensive list of challenges and opportunities for further research intomore powerful HOGNNs.</description><author>Maciej Besta, Florian Scheidl, Lukas Gianinazzi, Shachar Klaiman, Jürgen Müller, Torsten Hoefler</author><pubDate>Tue, 18 Jun 2024 18:57:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12841v1</guid></item><item><title>Evaluating the design space of diffusion-based generative models</title><link>http://arxiv.org/abs/2406.12839v1</link><description>Most existing theoretical investigations of the accuracy of diffusion models,albeit significant, assume the score function has been approximated to acertain accuracy, and then use this a priori bound to control the error ofgeneration. This article instead provides a first quantitative understanding ofthe whole generation process, i.e., both training and sampling. More precisely,it conducts a non-asymptotic convergence analysis of denoising score matchingunder gradient descent. In addition, a refined sampling error analysis forvariance exploding models is also provided. The combination of these tworesults yields a full error analysis, which elucidates (again, but this timetheoretically) how to design the training and sampling processes for effectivegeneration. For instance, our theory implies a preference toward noisedistribution and loss weighting that qualitatively agree with the ones used in[Karras et al. 2022]. It also provides some perspectives on why the time andvariance schedule used in [Karras et al. 2022] could be better tuned than thepioneering version in [Song et al. 2020].</description><author>Yuqing Wang, Ye He, Molei Tao</author><pubDate>Tue, 18 Jun 2024 18:56:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12839v1</guid></item><item><title>LayerMerge: Neural Network Depth Compression through Layer Pruning and Merging</title><link>http://arxiv.org/abs/2406.12837v1</link><description>Recent works show that reducing the number of layers in a convolutionalneural network can enhance efficiency while maintaining the performance of thenetwork. Existing depth compression methods remove redundant non-linearactivation functions and merge the consecutive convolution layers into a singlelayer. However, these methods suffer from a critical drawback; the kernel sizeof the merged layers becomes larger, significantly undermining the latencyreduction gained from reducing the depth of the network. We show that thisproblem can be addressed by jointly pruning convolution layers and activationfunctions. To this end, we propose LayerMerge, a novel depth compression methodthat selects which activation layers and convolution layers to remove, toachieve a desired inference speed-up while minimizing performance loss. Sincethe corresponding selection problem involves an exponential search space, weformulate a novel surrogate optimization problem and efficiently solve it viadynamic programming. Empirical results demonstrate that our method consistentlyoutperforms existing depth compression and layer pruning methods on variousnetwork architectures, both on image classification and generation tasks. Werelease the code at https://github.com/snu-mllab/LayerMerge.</description><author>Jinuk Kim, Marwa El Halabi, Mingi Ji, Hyun Oh Song</author><pubDate>Tue, 18 Jun 2024 18:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12837v1</guid></item><item><title>Influence Maximization via Graph Neural Bandits</title><link>http://arxiv.org/abs/2406.12835v1</link><description>We consider a ubiquitous scenario in the study of Influence Maximization(IM), in which there is limited knowledge about the topology of the diffusionnetwork. We set the IM problem in a multi-round diffusion campaign, aiming tomaximize the number of distinct users that are influenced. Leveraging thecapability of bandit algorithms to effectively balance the objectives ofexploration and exploitation, as well as the expressivity of neural networks,our study explores the application of neural bandit algorithms to the IMproblem. We propose the framework IM-GNB (Influence Maximization with GraphNeural Bandits), where we provide an estimate of the users' probabilities ofbeing influenced by influencers (also known as diffusion seeds). This initialestimate forms the basis for constructing both an exploitation graph and anexploration one. Subsequently, IM-GNB handles the exploration-exploitationtradeoff, by selecting seed nodes in real-time using Graph ConvolutionalNetworks (GCN), in which the pre-estimated graphs are employed to refine theinfluencers' estimated rewards in each contextual setting. Through extensiveexperiments on two large real-world datasets, we demonstrate the effectivenessof IM-GNB compared with other baseline methods, significantly improving thespread outcome of such diffusion campaigns, when the underlying network isunknown.</description><author>Yuting Feng, Vincent Y. F. Tan, Bogdan Cautis</author><pubDate>Tue, 18 Jun 2024 18:54:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12835v1</guid></item><item><title>GroPrompt: Efficient Grounded Prompting and Adaptation for Referring Video Object Segmentation</title><link>http://arxiv.org/abs/2406.12834v1</link><description>Referring Video Object Segmentation (RVOS) aims to segment the objectreferred to by the query sentence throughout the entire video. Most existingmethods require end-to-end training with dense mask annotations, which could becomputation-consuming and less scalable. In this work, we aim to efficientlyadapt foundation segmentation models for addressing RVOS from weak supervisionwith the proposed Grounded Prompting (GroPrompt) framework. More specifically,we propose Text-Aware Prompt Contrastive Learning (TAP-CL) to enhance theassociation between the position prompts and the referring sentences with onlybox supervisions, including Text-Contrastive Prompt Learning (TextCon) andModality-Contrastive Prompt Learning (ModalCon) at frame level and video level,respectively. With the proposed TAP-CL, our GroPrompt framework can generatetemporal-consistent yet text-aware position prompts describing locations andmovements for the referred object from the video. The experimental results inthe standard RVOS benchmarks (Ref-YouTube-VOS, Ref-DAVIS17, A2D-Sentences, andJHMDB-Sentences) demonstrate the competitive performance of our proposedGroPrompt framework given only bounding box weak supervisions.</description><author>Ci-Siang Lin, I-Jieh Liu, Min-Hung Chen, Chien-Yi Wang, Sifei Liu, Yu-Chiang Frank Wang</author><pubDate>Tue, 18 Jun 2024 18:54:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12834v1</guid></item><item><title>BTS: Building Timeseries Dataset: Empowering Large-Scale Building Analytics</title><link>http://arxiv.org/abs/2406.08990v2</link><description>Buildings play a crucial role in human well-being, influencing occupantcomfort, health, and safety. Additionally, they contribute significantly toglobal energy consumption, accounting for one-third of total energy usage, andcarbon emissions. Optimizing building performance presents a vital opportunityto combat climate change and promote human flourishing. However, research inbuilding analytics has been hampered by the lack of accessible, available, andcomprehensive real-world datasets on multiple building operations. In thispaper, we introduce the Building TimeSeries (BTS) dataset. Our dataset coversthree buildings over a three-year period, comprising more than ten thousandtimeseries data points with hundreds of unique ontologies. Moreover, themetadata is standardized using the Brick schema. To demonstrate the utility ofthis dataset, we performed benchmarks on two tasks: timeseries ontologyclassification and zero-shot forecasting. These tasks represent an essentialinitial step in addressing challenges related to interoperability in buildinganalytics. Access to the dataset and the code used for benchmarking areavailable here: https://github.com/cruiseresearchgroup/DIEF_BTS .</description><author>Arian Prabowo, Xiachong Lin, Imran Razzak, Hao Xue, Emily W. Yap, Matthew Amos, Flora D. Salim</author><pubDate>Tue, 18 Jun 2024 18:54:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08990v2</guid></item><item><title>LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional Adaptation</title><link>http://arxiv.org/abs/2406.12832v1</link><description>Low-rank adaptation (LoRA) has become the default approach to fine-tune largelanguage models (LLMs) due to its significant reduction in trainableparameters. However, trainable parameter demand for LoRA increases withincreasing model embedding dimensions, leading to high compute costs.Additionally, its backward updates require storing high-dimensionalintermediate activations and optimizer states, demanding high peak GPU memory.In this paper, we introduce large model fine-tuning via spectrally decomposedlow-dimensional adaptation (LaMDA), a novel approach to fine-tuning largelanguage models, which leverages low-dimensional adaptation to achievesignificant reductions in trainable parameters and peak GPU memory footprint.LaMDA freezes a first projection matrix (PMA) in the adaptation path whileintroducing a low-dimensional trainable square matrix, resulting in substantialreductions in trainable parameters and peak GPU memory usage. LaMDA graduallyfreezes a second projection matrix (PMB) during the early fine-tuning stages,reducing the compute cost associated with weight updates to enhance parameterefficiency further. We also present an enhancement, LaMDA++, incorporating a``lite-weight" adaptive rank allocation for the LoRA path via normalizedspectrum analysis of pre-trained model weights. We evaluate LaMDA/LaMDA++across various tasks, including natural language understanding with the GLUEbenchmark, text summarization, natural language generation, and complexreasoning on different LLMs. Results show that LaMDA matches or surpasses theperformance of existing alternatives while requiring up to 17.7x fewerparameter updates and up to 1.32x lower peak GPU memory usage duringfine-tuning. Code will be publicly available.</description><author>Seyedarmin Azizi, Souvik Kundu, Massoud Pedram</author><pubDate>Tue, 18 Jun 2024 18:52:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12832v1</guid></item><item><title>OccamLLM: Fast and Exact Language Model Arithmetic in a Single Step</title><link>http://arxiv.org/abs/2406.06576v2</link><description>Despite significant advancements in text generation and reasoning, LargeLanguage Models (LLMs) still face challenges in accurately performing complexarithmetic operations. To achieve accurate calculations, language model systemsoften enable LLMs to generate code for arithmetic operations. However, thisapproach compromises speed and security and, if finetuning is involved, risksthe language model losing prior capabilities. We propose a framework thatenables exact arithmetic in \textit{a single autoregressive step}, providingfaster, more secure, and more interpretable LLM systems with arithmeticcapabilities. We use the hidden states of an LLM to control a symbolicarchitecture which performs arithmetic. Our implementation using Llama 3 8BInstruct with OccamNet as a symbolic model (OccamLlama) achieves 100\% accuracyon single arithmetic operations($+,-,\times,\div,\sin{},\cos{},\log{},\exp{},\sqrt{}$), outperforming GPT 4oand on par with GPT 4o using a code interpreter. OccamLlama also outperformsGPT 4o both with and without a code interpreter on mathematical problem solvingbenchmarks involving challenging arithmetic, thus enabling small LLMs to matchthe arithmetic performance of even much larger models. We will make our codepublic shortly.</description><author>Owen Dugan, Donato Manuel Jimenez Beneto, Charlotte Loh, Zhuo Chen, Rumen Dangovski, Marin Soljačić</author><pubDate>Tue, 18 Jun 2024 18:51:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06576v2</guid></item><item><title>VIA: A Spatiotemporal Video Adaptation Framework for Global and Local Video Editing</title><link>http://arxiv.org/abs/2406.12831v1</link><description>Video editing stands as a cornerstone of digital media, from entertainmentand education to professional communication. However, previous methods oftenoverlook the necessity of comprehensively understanding both global and localcontexts, leading to inaccurate and inconsistency edits in the spatiotemporaldimension, especially for long videos. In this paper, we introduce VIA, aunified spatiotemporal VIdeo Adaptation framework for global and local videoediting, pushing the limits of consistently editing minute-long videos. First,to ensure local consistency within individual frames, the foundation of VIA isa novel test-time editing adaptation method, which adapts a pre-trained imageediting model for improving consistency between potential editing directionsand the text instruction, and adapts masked latent variables for precise localcontrol. Furthermore, to maintain global consistency over the video sequence,we introduce spatiotemporal adaptation that adapts consistent attentionvariables in key frames and strategically applies them across the wholesequence to realize the editing effects. Extensive experiments demonstratethat, compared to baseline methods, our VIA approach produces edits that aremore faithful to the source videos, more coherent in the spatiotemporalcontext, and more precise in local control. More importantly, we show that VIAcan achieve consistent long video editing in minutes, unlocking the potentialsfor advanced video editing tasks over long video sequences.</description><author>Jing Gu, Yuwei Fang, Ivan Skorokhodov, Peter Wonka, Xinya Du, Sergey Tulyakov, Xin Eric Wang</author><pubDate>Tue, 18 Jun 2024 18:51:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12831v1</guid></item><item><title>What Are the Odds? Language Models Are Capable of Probabilistic Reasoning</title><link>http://arxiv.org/abs/2406.12830v1</link><description>Language models (LM) are capable of remarkably complex linguistic tasks;however, numerical reasoning is an area in which they frequently struggle. Animportant but rarely evaluated form of reasoning is understanding probabilitydistributions. In this paper, we focus on evaluating the probabilisticreasoning capabilities of LMs using idealized and real-world statisticaldistributions. We perform a systematic evaluation of state-of-the-art LMs onthree tasks: estimating percentiles, drawing samples, and calculatingprobabilities. We evaluate three ways to provide context to LMs 1) anchoringexamples from within a distribution or family of distributions, 2) real-worldcontext, 3) summary statistics on which to base a Normal approximation. Modelscan make inferences about distributions, and can be further aided by theincorporation of real-world context, example shots and simplified assumptions,even if these assumptions are incorrect or misspecified. To conduct this work,we developed a comprehensive benchmark distribution dataset with associatedquestion-answer pairs that we will release publicly.</description><author>Akshay Paruchuri, Jake Garrison, Shun Liao, John Hernandez, Jacob Sunshine, Tim Althoff, Xin Liu, Daniel McDuff</author><pubDate>Tue, 18 Jun 2024 18:51:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12830v1</guid></item><item><title>Voxel Mamba: Group-Free State Space Models for Point Cloud based 3D Object Detection</title><link>http://arxiv.org/abs/2406.10700v2</link><description>Serialization-based methods, which serialize the 3D voxels and group theminto multiple sequences before inputting to Transformers, have demonstratedtheir effectiveness in 3D object detection. However, serializing 3D voxels into1D sequences will inevitably sacrifice the voxel spatial proximity. Such anissue is hard to be addressed by enlarging the group size with existingserialization-based methods due to the quadratic complexity of Transformerswith feature sizes. Inspired by the recent advances of state space models(SSMs), we present a Voxel SSM, termed as Voxel Mamba, which employs agroup-free strategy to serialize the whole space of voxels into a singlesequence. The linear complexity of SSMs encourages our group-free design,alleviating the loss of spatial proximity of voxels. To further enhance thespatial proximity, we propose a Dual-scale SSM Block to establish ahierarchical structure, enabling a larger receptive field in the 1Dserialization curve, as well as more complete local regions in 3D space.Moreover, we implicitly apply window partition under the group-free frameworkby positional encoding, which further enhances spatial proximity by encodingvoxel positional information. Our experiments on Waymo Open Dataset andnuScenes dataset show that Voxel Mamba not only achieves higher accuracy thanstate-of-the-art methods, but also demonstrates significant advantages incomputational efficiency.</description><author>Guowen Zhang, Lue Fan, Chenhang He, Zhen Lei, Zhaoxiang Zhang, Lei Zhang</author><pubDate>Tue, 18 Jun 2024 18:49:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10700v2</guid></item><item><title>From RAGs to rich parameters: Probing how language models utilize external knowledge over parametric information for factual queries</title><link>http://arxiv.org/abs/2406.12824v1</link><description>Retrieval Augmented Generation (RAG) enriches the ability of language modelsto reason using external context to augment responses for a given user prompt.This approach has risen in popularity due to practical applications in variousapplications of language models in search, question/answering, and chat-bots.However, the exact nature of how this approach works isn't clearly understood.In this paper, we mechanistically examine the RAG pipeline to highlight thatlanguage models take shortcut and have a strong bias towards utilizing only thecontext information to answer the question, while relying minimally on theirparametric memory. We probe this mechanistic behavior in language models with:(i) Causal Mediation Analysis to show that the parametric memory is minimallyutilized when answering a question and (ii) Attention Contributions andKnockouts to show that the last token residual stream do not get enriched fromthe subject token in the question, but gets enriched from other informativetokens in the context. We find this pronounced shortcut behaviour true acrossboth LLaMa and Phi family of models.</description><author>Hitesh Wadhwa, Rahul Seetharaman, Somyaa Aggarwal, Reshmi Ghosh, Samyadeep Basu, Soundararajan Srinivasan, Wenlong Zhao, Shreyas Chaudhari, Ehsan Aghazadeh</author><pubDate>Tue, 18 Jun 2024 18:46:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12824v1</guid></item><item><title>Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?</title><link>http://arxiv.org/abs/2406.12822v1</link><description>Large language models, particularly multilingual ones, are designed, claimed,and expected to cater to native speakers of varied languages. We hypothesisethat the current practices of fine-tuning and evaluating these models maymismatch this intention owing to a heavy reliance on translation, which canintroduce translation artefacts and defects. It remains unknown whether thenature of the instruction data has an impact on the model output; on the otherhand, it remains questionable whether translated test sets can capture suchnuances. Due to the often coupled practices of using translated data in bothstages, such imperfections could have been overlooked. This work investigatesthese issues by using controlled native or translated data during instructiontuning and evaluation stages and observing model results. Experiments on eightbase models and eight different benchmarks reveal that native or generationbenchmarks display a notable difference between native and translatedinstruction data especially when model performance is high, whereas other typesof test sets cannot. Finally, we demonstrate that regularization is beneficialto bridging this gap on structured but not generative tasks.</description><author>Pinzhen Chen, Simon Yu, Zhicheng Guo, Barry Haddow</author><pubDate>Tue, 18 Jun 2024 18:43:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12822v1</guid></item><item><title>DeformTime: Capturing Variable Dependencies with Deformable Attention for Time Series Forecasting</title><link>http://arxiv.org/abs/2406.07438v2</link><description>In multivariate time series (MTS) forecasting, existing state-of-the-art deeplearning approaches tend to focus on autoregressive formulations and overlookthe information within exogenous indicators. To address this limitation, wepresent DeformTime, a neural network architecture that attempts to capturecorrelated temporal patterns from the input space, and hence, improveforecasting accuracy. It deploys two core operations performed by deformableattention blocks (DABs): learning dependencies across variables from differenttime steps (variable DAB), and preserving temporal dependencies in data fromprevious time steps (temporal DAB). Input data transformation is explicitlydesigned to enhance learning from the deformed series of information whilepassing through a DAB. We conduct extensive experiments on 6 MTS data sets,using previously established benchmarks as well as challenging infectiousdisease modelling tasks with more exogenous variables. The results demonstratethat DeformTime improves accuracy against previous competitive methods acrossthe vast majority of MTS forecasting tasks, reducing the mean absolute error by10% on average. Notably, performance gains remain consistent across longerforecasting horizons.</description><author>Yuxuan Shu, Vasileios Lampos</author><pubDate>Tue, 18 Jun 2024 18:42:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07438v2</guid></item><item><title>Neural Approximate Mirror Maps for Constrained Diffusion Models</title><link>http://arxiv.org/abs/2406.12816v1</link><description>Diffusion models excel at creating visually-convincing images, but they oftenstruggle to meet subtle constraints inherent in the training data. Suchconstraints could be physics-based (e.g., satisfying a PDE), geometric (e.g.,respecting symmetry), or semantic (e.g., including a particular number ofobjects). When the training data all satisfy a certain constraint, enforcingthis constraint on a diffusion model not only improves itsdistribution-matching accuracy but also makes it more reliable for generatingvalid synthetic data and solving constrained inverse problems. However,existing methods for constrained diffusion models are inflexible with differenttypes of constraints. Recent work proposed to learn mirror diffusion models(MDMs) in an unconstrained space defined by a mirror map and to impose theconstraint with an inverse mirror map, but analytical mirror maps arechallenging to derive for complex constraints. We propose neural approximatemirror maps (NAMMs) for general constraints. Our approach only requires adifferentiable distance function from the constraint set. We learn anapproximate mirror map that pushes data into an unconstrained space and acorresponding approximate inverse that maps data back to the constraint set. Agenerative model, such as an MDM, can then be trained in the learned mirrorspace and its samples restored to the constraint set by the inverse map. Wevalidate our approach on a variety of constraints, showing that compared to anunconstrained diffusion model, a NAMM-based MDM substantially improvesconstraint satisfaction. We also demonstrate how existing diffusion-basedinverse-problem solvers can be easily applied in the learned mirror space tosolve constrained inverse problems.</description><author>Berthy T. Feng, Ricardo Baptista, Katherine L. Bouman</author><pubDate>Tue, 18 Jun 2024 18:36:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12816v1</guid></item><item><title>Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation</title><link>http://arxiv.org/abs/2406.12815v1</link><description>Machine learning (ML) and Artificial Intelligence (AI) have fueled remarkableadvancements, particularly in healthcare. Within medical imaging, ML modelshold the promise of improving disease diagnoses, treatment planning, andpost-treatment monitoring. Various computer vision tasks like imageclassification, object detection, and image segmentation are poised to becomeroutine in clinical analysis. However, privacy concerns surrounding patientdata hinder the assembly of large training datasets needed for developing andtraining accurate, robust, and generalizable models. Federated Learning (FL)emerges as a compelling solution, enabling organizations to collaborate on MLmodel training by sharing model training information (gradients) rather thandata (e.g., medical images). FL's distributed learning framework facilitatesinter-institutional collaboration while preserving patient privacy. However,FL, while robust in privacy preservation, faces several challenges. Sensitiveinformation can still be gleaned from shared gradients that are passed onbetween organizations during model training. Additionally, in medical imaging,quantifying model confidence\uncertainty accurately is crucial due to the noiseand artifacts present in the data. Uncertainty estimation in FL encountersunique hurdles due to data heterogeneity across organizations. This paperoffers a comprehensive review of FL, privacy preservation, and uncertaintyestimation, with a focus on medical imaging. Alongside a survey of currentresearch, we identify gaps in the field and suggest future directions for FLresearch to enhance privacy and address noisy medical imaging data challenges.</description><author>Nikolas Koutsoubis, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool</author><pubDate>Tue, 18 Jun 2024 18:35:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12815v1</guid></item><item><title>Adversarial Attacks on Multimodal Agents</title><link>http://arxiv.org/abs/2406.12814v1</link><description>Vision-enabled language models (VLMs) are now used to build autonomousmultimodal agents capable of taking actions in real environments. In thispaper, we show that multimodal agents raise new safety risks, even thoughattacking agents is more challenging than prior attacks due to limited accessto and knowledge about the environment. Our attacks use adversarial textstrings to guide gradient-based perturbation over one trigger image in theenvironment: (1) our captioner attack attacks white-box captioners if they areused to process images into captions as additional inputs to the VLM; (2) ourCLIP attack attacks a set of CLIP models jointly, which can transfer toproprietary VLMs. To evaluate the attacks, we curated VisualWebArena-Adv, a setof adversarial tasks based on VisualWebArena, an environment for web-basedmultimodal agent tasks. Within an L-infinity norm of $16/256$ on a singleimage, the captioner attack can make a captioner-augmented GPT-4V agent executethe adversarial goals with a 75% success rate. When we remove the captioner oruse GPT-4V to generate its own captions, the CLIP attack can achieve successrates of 21% and 43%, respectively. Experiments on agents based on other VLMs,such as Gemini-1.5, Claude-3, and GPT-4o, show interesting differences in theirrobustness. Further analysis reveals several key factors contributing to theattack's success, and we also discuss the implications for defenses as well.Project page: https://chenwu.io/attack-agent Code and data:https://github.com/ChenWu98/agent-attack</description><author>Chen Henry Wu, Jing Yu Koh, Ruslan Salakhutdinov, Daniel Fried, Aditi Raghunathan</author><pubDate>Tue, 18 Jun 2024 18:32:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12814v1</guid></item><item><title>Scalable MatMul-free Language Modeling</title><link>http://arxiv.org/abs/2406.02528v5</link><description>Matrix multiplication (MatMul) typically dominates the overall computationalcost of large language models (LLMs). This cost only grows as LLMs scale tolarger embedding dimensions and context lengths. In this work, we show thatMatMul operations can be completely eliminated from LLMs while maintainingstrong performance at billion-parameter scales. Our experiments show that ourproposed MatMul-free models achieve performance on-par with state-of-the-artTransformers that require far more memory during inference at a scale up to atleast 2.7B parameters. We investigate the scaling laws and find that theperformance gap between our MatMul-free models and full precision Transformersnarrows as the model size increases. We also provide a GPU-efficientimplementation of this model which reduces memory usage by up to 61% over anunoptimized baseline during training. By utilizing an optimized kernel duringinference, our model's memory consumption can be reduced by more than 10xcompared to unoptimized models. To properly quantify the efficiency of ourarchitecture, we build a custom hardware solution on an FPGA which exploitslightweight operations beyond what GPUs are capable of. We processedbillion-parameter scale models at 13W beyond human readable throughput, movingLLMs closer to brain-like efficiency. This work not only shows how far LLMs canbe stripped back while still performing effectively, but also points at thetypes of operations future accelerators should be optimized for in processingthe next generation of lightweight LLMs. Our code implementation is availableat https://github.com/ridgerchu/matmulfreellm.</description><author>Rui-Jie Zhu, Yu Zhang, Ethan Sifferman, Tyler Sheaves, Yiqiao Wang, Dustin Richmond, Peng Zhou, Jason K. Eshraghian</author><pubDate>Tue, 18 Jun 2024 18:30:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02528v5</guid></item><item><title>Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks</title><link>http://arxiv.org/abs/2404.02151v2</link><description>We show that even the most recent safety-aligned LLMs are not robust tosimple adaptive jailbreaking attacks. First, we demonstrate how to successfullyleverage access to logprobs for jailbreaking: we initially design anadversarial prompt template (sometimes adapted to the target LLM), and then weapply random search on a suffix to maximize a target logprob (e.g., of thetoken ``Sure''), potentially with multiple restarts. In this way, we achievenearly 100% attack success rate -- according to GPT-4 as a judge -- onVicuna-13B, Mistral-7B, Phi-3-Mini, Nemotron-4-340B, Llama-2-Chat-7B/13B/70B,Llama-3-Instruct-8B, Gemma-7B, GPT-3.5, GPT-4, and R2D2 from HarmBench that wasadversarially trained against the GCG attack. We also show how to jailbreak allClaude models -- that do not expose logprobs -- via either a transfer orprefilling attack with a 100% success rate. In addition, we show how to userandom search on a restricted set of tokens for finding trojan strings inpoisoned models -- a task that shares many similarities with jailbreaking --which is the algorithm that brought us the first place in the SaTML'24 TrojanDetection Competition. The common theme behind these attacks is that adaptivityis crucial: different models are vulnerable to different prompting templates(e.g., R2D2 is very sensitive to in-context learning prompts), some models haveunique vulnerabilities based on their APIs (e.g., prefilling for Claude), andin some settings, it is crucial to restrict the token search space based onprior knowledge (e.g., for trojan detection). For reproducibility purposes, weprovide the code, logs, and jailbreak artifacts in the JailbreakBench format athttps://github.com/tml-epfl/llm-adaptive-attacks.</description><author>Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion</author><pubDate>Tue, 18 Jun 2024 18:29:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02151v2</guid></item><item><title>Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?</title><link>http://arxiv.org/abs/2406.12809v1</link><description>Large language models (LLMs) have demonstrated impressive capabilities, butstill suffer from inconsistency issues (e.g. LLMs can react differently todisturbances like rephrasing or inconsequential order change). In addition tothese inconsistencies, we also observe that LLMs, while capable of solving hardproblems, can paradoxically fail at easier ones. To evaluate this hard-to-easyinconsistency, we develop the ConsisEval benchmark, where each entry comprisesa pair of questions with a strict order of difficulty. Furthermore, weintroduce the concept of consistency score to quantitatively measure thisinconsistency and analyze the potential for improvement in consistency byrelative consistency score. Based on comprehensive experiments across a varietyof existing models, we find: (1) GPT-4 achieves the highest consistency scoreof 92.2\% but is still inconsistent to specific questions due to distraction byredundant information, misinterpretation of questions, etc.; (2) models withstronger capabilities typically exhibit higher consistency, but exceptions alsoexist; (3) hard data enhances consistency for both fine-tuning and in-contextlearning. Our data and code will be publicly available on GitHub.</description><author>Zhe Yang, Yichang Zhang, Tianyu Liu, Jian Yang, Junyang Lin, Chang Zhou, Zhifang Sui</author><pubDate>Tue, 18 Jun 2024 18:25:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12809v1</guid></item><item><title>Graph Neural Networks in Histopathology: Emerging Trends and Future Directions</title><link>http://arxiv.org/abs/2406.12808v1</link><description>Histopathological analysis of Whole Slide Images (WSIs) has seen a surge inthe utilization of deep learning methods, particularly Convolutional NeuralNetworks (CNNs). However, CNNs often fall short in capturing the intricatespatial dependencies inherent in WSIs. Graph Neural Networks (GNNs) present apromising alternative, adept at directly modeling pairwise interactions andeffectively discerning the topological tissue and cellular structures withinWSIs. Recognizing the pressing need for deep learning techniques that harnessthe topological structure of WSIs, the application of GNNs in histopathologyhas experienced rapid growth. In this comprehensive review, we survey GNNs inhistopathology, discuss their applications, and exploring emerging trends thatpave the way for future advancements in the field. We begin by elucidating thefundamentals of GNNs and their potential applications in histopathology.Leveraging quantitative literature analysis, we identify four emerging trends:Hierarchical GNNs, Adaptive Graph Structure Learning, Multimodal GNNs, andHigher-order GNNs. Through an in-depth exploration of these trends, we offerinsights into the evolving landscape of GNNs in histopathological analysis.Based on our findings, we propose future directions to propel the fieldforward. Our analysis serves to guide researchers and practitioners towardsinnovative approaches and methodologies, fostering advancements inhistopathological analysis through the lens of graph neural networks.</description><author>Siemen Brussee, Giorgio Buzzanca, Anne M. R. Schrader, Jesper Kers</author><pubDate>Tue, 18 Jun 2024 18:23:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12808v1</guid></item><item><title>Probabilistic Temporal Prediction of Continuous Disease Trajectories and Treatment Effects Using Neural SDEs</title><link>http://arxiv.org/abs/2406.12807v1</link><description>Personalized medicine based on medical images, including predicting futureindividualized clinical disease progression and treatment response, would havean enormous impact on healthcare and drug development, particularly fordiseases (e.g. multiple sclerosis (MS)) with long term, complex, heterogeneousevolutions and no cure. In this work, we present the first stochastic causaltemporal framework to model the continuous temporal evolution of diseaseprogression via Neural Stochastic Differential Equations (NSDE). The proposedcausal inference model takes as input the patient's high dimensional images(MRI) and tabular data, and predicts both factual and counterfactualprogression trajectories on different treatments in latent space. The NSDEpermits the estimation of high-confidence personalized trajectories andtreatment effects. Extensive experiments were performed on a large,multi-centre, proprietary dataset of patient 3D MRI and clinical data acquiredduring several randomized clinical trials for MS treatments. Our resultspresent the first successful uncertainty-based causal Deep Learning (DL) modelto: (a) accurately predict future patient MS disability evolution (e.g. EDSS)and treatment effects leveraging baseline MRI, and (b) permit the discovery ofsubgroups of patients for which the model has high confidence in their responseto treatment even in clinical trials which did not reach their clinicalendpoints.</description><author>Joshua Durso-Finley, Berardino Barile, Jean-Pierre Falet, Douglas L. Arnold, Nick Pawlowski, Tal Arbel</author><pubDate>Tue, 18 Jun 2024 18:22:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12807v1</guid></item><item><title>Identifying Performance-Sensitive Configurations in Software Systems through Code Analysis with LLM Agents</title><link>http://arxiv.org/abs/2406.12806v1</link><description>Configuration settings are essential for tailoring software behavior to meetspecific performance requirements. However, incorrect configurations arewidespread, and identifying those that impact system performance is challengingdue to the vast number and complexity of possible settings. In this work, wepresent PerfSense, a lightweight framework that leverages Large Language Models(LLMs) to efficiently identify performance-sensitive configurations withminimal overhead. PerfSense employs LLM agents to simulate interactions betweendevelopers and performance engineers using advanced prompting techniques suchas prompt chaining and retrieval-augmented generation (RAG). Our evaluation ofseven open-source Java systems demonstrates that PerfSense achieves an averageaccuracy of 64.77% in classifying performance-sensitive configurations,outperforming both our LLM baseline (50.36%) and the previous state-of-the-artmethod (61.75%). Notably, our prompt chaining technique improves recall by 10%to 30% while maintaining similar precision levels. Additionally, a manualanalysis of 362 misclassifications reveals common issues, including LLMs'misunderstandings of requirements (26.8%). In summary, PerfSense significantlyreduces manual effort in classifying performance-sensitive configurations andoffers valuable insights for future LLM-based code analysis research.</description><author>Zehao Wang, Dong Jae Kim, Tse-Hsun Chen</author><pubDate>Tue, 18 Jun 2024 18:22:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12806v1</guid></item><item><title>AITTI: Learning Adaptive Inclusive Token for Text-to-Image Generation</title><link>http://arxiv.org/abs/2406.12805v1</link><description>Despite the high-quality results of text-to-image generation, stereotypicalbiases have been spotted in their generated contents, compromising the fairnessof generative models. In this work, we propose to learn adaptive inclusivetokens to shift the attribute distribution of the final generative outputs.Unlike existing de-biasing approaches, our method requires neither explicitattribute specification nor prior knowledge of the bias distribution.Specifically, the core of our method is a lightweight adaptive mapping network,which can customize the inclusive tokens for the concepts to be de-biased,making the tokens generalizable to unseen concepts regardless of their originalbias distributions. This is achieved by tuning the adaptive mapping networkwith a handful of balanced and inclusive samples using an anchor loss.Experimental results demonstrate that our method outperforms previous biasmitigation methods without attribute specification while preserving thealignment between generative results and text descriptions. Moreover, ourmethod achieves comparable performance to models that require specificattributes or editing directions for generation. Extensive experiments showcasethe effectiveness of our adaptive inclusive tokens in mitigating stereotypicalbias in text-to-image generation. The code will be available athttps://github.com/itsmag11/AITTI.</description><author>Xinyu Hou, Xiaoming Li, Chen Change Loy</author><pubDate>Tue, 18 Jun 2024 18:22:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12805v1</guid></item><item><title>Scalable Rule Lists Learning with Sampling</title><link>http://arxiv.org/abs/2406.12803v1</link><description>Learning interpretable models has become a major focus of machine learningresearch, given the increasing prominence of machine learning in sociallyimportant decision-making. Among interpretable models, rule lists are among thebest-known and easily interpretable ones. However, finding optimal rule listsis computationally challenging, and current approaches are impractical forlarge datasets. We present a novel and scalable approach to learn nearly optimal rule listsfrom large datasets. Our algorithm uses sampling to efficiently obtain anapproximation of the optimal rule list with rigorous guarantees on the qualityof the approximation. In particular, our algorithm guarantees to find a rulelist with accuracy very close to the optimal rule list when a rule list withhigh accuracy exists. Our algorithm builds on the VC-dimension of rule lists,for which we prove novel upper and lower bounds. Our experimental evaluation onlarge datasets shows that our algorithm identifies nearly optimal rule listswith a speed-up up to two orders of magnitude over state-of-the-art exactapproaches. Moreover, our algorithm is as fast as, and sometimes faster than,recent heuristic approaches, while reporting higher quality rule lists. Inaddition, the rules reported by our algorithm are more similar to the rules inthe optimal rule list than the rules from heuristic approaches.</description><author>Leonardo Pellegrina, Fabio Vandin</author><pubDate>Tue, 18 Jun 2024 18:15:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12803v1</guid></item><item><title>Gap-Free Clustering: Sensitivity and Robustness of SDP</title><link>http://arxiv.org/abs/2308.15642v2</link><description>We study graph clustering in the Stochastic Block Model (SBM) in the presenceof both large clusters and small, unrecoverable clusters. Previous convexrelaxation approaches achieving exact recovery do not allow any small clustersof size $o(\sqrt{n})$, or require a size gap between the smallest recoveredcluster and the largest non-recovered cluster. We provide an algorithm based onsemidefinite programming (SDP) which removes these requirements and provablyrecovers large clusters regardless of the remaining cluster sizes. Mid-sizedclusters pose unique challenges to the analysis, since their proximity to therecovery threshold makes them highly sensitive to small noise perturbations andprecludes a closed-form candidate solution. We develop novel techniques,including a leave-one-out-style argument which controls the correlation betweenSDP solutions and noise vectors even when the removal of one row of noise candrastically change the SDP solution. We also develop improved eigenvalueperturbation bounds of potential independent interest. Our results are robustto certain semirandom settings that are challenging for alternative algorithms.Using our gap-free clustering procedure, we obtain efficient algorithms for theproblem of clustering with a faulty oracle with superior query complexities,notably achieving $o(n^2)$ sample complexity even in the presence of a largenumber of small clusters. Our gap-free clustering procedure also leads toimproved algorithms for recursive clustering.</description><author>Matthew Zurek, Yudong Chen</author><pubDate>Tue, 18 Jun 2024 18:13:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15642v2</guid></item><item><title>ROOT-SGD: Sharp Nonasymptotics and Near-Optimal Asymptotics in a Single Algorithm</title><link>http://arxiv.org/abs/2008.12690v3</link><description>We study the problem of solving strongly convex and smooth unconstrainedoptimization problems using stochastic first-order algorithms. We devise anovel algorithm, referred to as \emph{Recursive One-Over-T SGD}(\textsf{ROOT-SGD}), based on an easily implementable, recursive averaging ofpast stochastic gradients. We prove that it simultaneously achievesstate-of-the-art performance in both a finite-sample, nonasymptotic sense andan asymptotic sense. On the nonasymptotic side, we prove risk bounds on thelast iterate of \textsf{ROOT-SGD} with leading-order terms that match theoptimal statistical risk with a unity pre-factor, along with a higher-orderterm that scales at the sharp rate of $O(n^{-3/2})$ under the Lipschitzcondition on the Hessian matrix. On the asymptotic side, we show that when amild, one-point Hessian continuity condition is imposed, the rescaled lastiterate of (multi-epoch) \textsf{ROOT-SGD} converges asymptotically to aGaussian limit with the Cram\'{e}r-Rao optimal asymptotic covariance, for abroad range of step-size choices.</description><author>Chris Junchi Li</author><pubDate>Tue, 18 Jun 2024 18:03:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2008.12690v3</guid></item><item><title>The Limits of Pure Exploration in POMDPs: When the Observation Entropy is Enough</title><link>http://arxiv.org/abs/2406.12795v1</link><description>The problem of pure exploration in Markov decision processes has been cast asmaximizing the entropy over the state distribution induced by the agent'spolicy, an objective that has been extensively studied. However, littleattention has been dedicated to state entropy maximization under partialobservability, despite the latter being ubiquitous in applications, e.g.,finance and robotics, in which the agent only receives noisy observations ofthe true state governing the system's dynamics. How can we address stateentropy maximization in those domains? In this paper, we study the simpleapproach of maximizing the entropy over observations in place of true latentstates. First, we provide lower and upper bounds to the approximation of thetrue state entropy that only depends on some properties of the observationfunction. Then, we show how knowledge of the latter can be exploited to computea principled regularization of the observation entropy to improve performance.With this work, we provide both a flexible approach to bring advances in stateentropy maximization to the POMDP setting and a theoretical characterization ofits intrinsic limits.</description><author>Riccardo Zamboni, Duilio Cirino, Marcello Restelli, Mirco Mutti</author><pubDate>Tue, 18 Jun 2024 18:00:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12795v1</guid></item><item><title>ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools</title><link>http://arxiv.org/abs/2406.12793v1</link><description>We introduce ChatGLM, an evolving family of large language models that wehave been developing over time. This report primarily focuses on the GLM-4language series, which includes GLM-4, GLM-4-Air, and GLM-4-9B. They representour most capable models that are trained with all the insights and lessonsgained from the preceding three generations of ChatGLM. To date, the GLM-4models are pre-trained on ten trillions of tokens mostly in Chinese andEnglish, along with a small set of corpus from 24 languages, and alignedprimarily for Chinese and English usage. The high-quality alignment is achievedvia a multi-stage post-training process, which involves supervised fine-tuningand learning from human feedback. Evaluations show that GLM-4 1) closely rivalsor outperforms GPT-4 in terms of general metrics such as MMLU, GSM8K, MATH,BBH, GPQA, and HumanEval, 2) gets close to GPT-4-Turbo in instruction followingas measured by IFEval, 3) matches GPT-4 Turbo (128K) and Claude 3 for longcontext tasks, and 4) outperforms GPT-4 in Chinese alignments as measured byAlignBench. The GLM-4 All Tools model is further aligned to understand userintent and autonomously decide when and which tool(s) touse -- including webbrowser, Python interpreter, text-to-image model, and user-defined functions --to effectively complete complex tasks. In practical applications, it matchesand even surpasses GPT-4 All Tools in tasks like accessing online informationvia web browsing and solving math problems using Python interpreter. Over thecourse, we have open-sourced a series of models, including ChatGLM-6B (threegenerations), GLM-4-9B (128K, 1M), GLM-4V-9B, WebGLM, and CodeGeeX, attractingover 10 million downloads on Hugging face in the year 2023 alone. The openmodels can be accessed through https://github.com/THUDM andhttps://huggingface.co/THUDM.</description><author>Team GLM, :, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, Hao Yu, Hongning Wang, Jiadai Sun, Jiajie Zhang, Jiale Cheng, Jiayi Gui, Jie Tang, Jing Zhang, Juanzi Li, Lei Zhao, Lindong Wu, Lucen Zhong, Mingdao Liu, Minlie Huang, Peng Zhang, Qinkai Zheng, Rui Lu, Shuaiqi Duan, Shudan Zhang, Shulin Cao, Shuxun Yang, Weng Lam Tam, Wenyi Zhao, Xiao Liu, Xiao Xia, Xiaohan Zhang, Xiaotao Gu, Xin Lv, Xinghan Liu, Xinyi Liu, Xinyue Yang, Xixuan Song, Xunkai Zhang, Yifan An, Yifan Xu, Yilin Niu, Yuantao Yang, Yueyan Li, Yushi Bai, Yuxiao Dong, Zehan Qi, Zhaoyu Wang, Zhen Yang, Zhengxiao Du, Zhenyu Hou, Zihan Wang</author><pubDate>Tue, 18 Jun 2024 17:58:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12793v1</guid></item><item><title>Let Me Teach You: Pedagogical Foundations of Feedback for Language Models</title><link>http://arxiv.org/abs/2307.00279v2</link><description>Natural Language Feedback (NLF) is an increasingly popular mechanism foraligning Large Language Models (LLMs) to human preferences. Despite thediversity of the information it can convey, NLF methods are often hand-designedand arbitrary, with little systematic grounding. At the same time, research inlearning sciences has long established several effective feedback models. Inthis opinion piece, we compile ideas from pedagogy to introduce FELT, afeedback framework for LLMs that outlines various characteristics of thefeedback space, and a feedback content taxonomy based on these variables,providing a general mapping of the feedback space. In addition to streamliningNLF designs, FELT also brings out new, unexplored directions for research inNLF. We make our taxonomy available to the community, providing guides andexamples for mapping our categorizations to future research.</description><author>Beatriz Borges, Niket Tandon, Tanja Käser, Antoine Bosselut</author><pubDate>Tue, 18 Jun 2024 17:55:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00279v2</guid></item><item><title>Generating Educational Materials with Different Levels of Readability using LLMs</title><link>http://arxiv.org/abs/2406.12787v1</link><description>This study introduces the leveled-text generation task, aiming to rewriteeducational materials to specific readability levels while preserving meaning.We assess the capability of GPT-3.5, LLaMA-2 70B, and Mixtral 8x7B, to generatecontent at various readability levels through zero-shot and few-shot prompting.Evaluating 100 processed educational materials reveals that few-shot promptingsignificantly improves performance in readability manipulation and informationpreservation. LLaMA-2 70B performs better in achieving the desired difficultyrange, while GPT-3.5 maintains original meaning. However, manual inspectionhighlights concerns such as misinformation introduction and inconsistent editdistribution. These findings emphasize the need for further research to ensurethe quality of generated educational content.</description><author>Chieh-Yang Huang, Jing Wei, Ting-Hao 'Kenneth' Huang</author><pubDate>Tue, 18 Jun 2024 17:55:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12787v1</guid></item><item><title>In-Context Learning of Energy Functions</title><link>http://arxiv.org/abs/2406.12785v1</link><description>In-context learning is a powerful capability of certain machine learningmodels that arguably underpins the success of today's frontier AI models.However, in-context learning is critically limited to settings where thein-context distribution of interest $p_{\theta}^{ICL}( x|\mathcal{D})$ can bestraightforwardly expressed and/or parameterized by the model; for instance,language modeling relies on expressing the next-token distribution as acategorical distribution parameterized by the network's output logits. In thiswork, we present a more general form of in-context learning without such alimitation that we call \textit{in-context learning of energy functions}. Theidea is to instead learn the unconstrained and arbitrary in-context energyfunction $E_{\theta}^{ICL}(x|\mathcal{D})$ corresponding to the in-contextdistribution $p_{\theta}^{ICL}(x|\mathcal{D})$. To do this, we use classicideas from energy-based modeling. We provide preliminary evidence that ourmethod empirically works on synthetic data. Interestingly, our work contributes(to the best of our knowledge) the first example of in-context learning wherethe input space and output space differ from one another, suggesting thatin-context learning is a more-general capability than previously realized.</description><author>Rylan Schaeffer, Mikail Khona, Sanmi Koyejo</author><pubDate>Tue, 18 Jun 2024 17:54:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12785v1</guid></item><item><title>UBENCH: Benchmarking Uncertainty in Large Language Models with Multiple Choice Questions</title><link>http://arxiv.org/abs/2406.12784v1</link><description>The rapid development of large language models (LLMs) has shown promisingpractical results. However, their low interpretability often leads to errors inunforeseen circumstances, limiting their utility. Many works have focused oncreating comprehensive evaluation systems, but previous benchmarks haveprimarily assessed problem-solving abilities while neglecting the response'suncertainty, which may result in unreliability. Recent methods for measuringLLM reliability are resource-intensive and unable to test black-box models. Toaddress this, we propose UBENCH, a comprehensive benchmark for evaluating LLMreliability. UBENCH includes 3,978 multiple-choice questions coveringknowledge, language, understanding, and reasoning abilities. Experimentalresults show that UBENCH has achieved state-of-the-art performance, while itssingle-sampling method significantly saves computational resources compared tobaseline methods that require multiple samplings. Additionally, based onUBENCH, we evaluate the reliability of 15 popular LLMs, finding GLM4 to be themost outstanding, closely followed by GPT-4. We also explore the impact ofChain-of-Thought prompts, role-playing prompts, option order, and temperatureon LLM reliability, analyzing the varying effects on different LLMs.</description><author>Xunzhi Wang, Zhuowei Zhang, Qiongyu Li, Gaonan Chen, Mengting Hu, Zhiyu li, Bitong Luo, Hang Gao, Zhixin Han, Haotian Wang</author><pubDate>Tue, 18 Jun 2024 17:50:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12784v1</guid></item><item><title>Zeroing neural dynamics solving time-variant complex conjugate matrix equation</title><link>http://arxiv.org/abs/2406.12783v1</link><description>Complex conjugate matrix equations (CCME) have aroused the interest of manyresearchers because of computations and antilinear systems. Existing researchis dominated by its time-invariant solving methods, but lacks proposed theoriesfor solving its time-variant version. Moreover, artificial neural networks arerarely studied for solving CCME. In this paper, starting with the earliestCCME, zeroing neural dynamics (ZND) is applied to solve its time-variantversion. Firstly, the vectorization and Kronecker product in the complex fieldare defined uniformly. Secondly, Con-CZND1 model and Con-CZND2 model areproposed and theoretically prove convergence and effectiveness. Thirdly, threenumerical experiments are designed to illustrate the effectiveness of the twomodels, compare their differences, highlight the significance of neuraldynamics in the complex field, and refine the theory related to ZND.</description><author>Jiakuang He, Dongqing Wu</author><pubDate>Tue, 18 Jun 2024 17:50:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12783v1</guid></item><item><title>Knowledge Graphs in Practice: Characterizing their Users, Challenges, and Visualization Opportunities</title><link>http://arxiv.org/abs/2304.01311v4</link><description>This study presents insights from interviews with nineteen Knowledge Graph(KG) practitioners who work in both enterprise and academic settings on a widevariety of use cases. Through this study, we identify critical challengesexperienced by KG practitioners when creating, exploring, and analyzing KGsthat could be alleviated through visualization design. Our findings revealthree major personas among KG practitioners - KG Builders, Analysts, andConsumers - each of whom have their own distinct expertise and needs. Wediscover that KG Builders would benefit from schema enforcers, while KGAnalysts need customizable query builders that provide interim query results.For KG Consumers, we identify a lack of efficacy for node-link diagrams, andthe need for tailored domain-specific visualizations to promote KG adoption andcomprehension. Lastly, we find that implementing KGs effectively in practicerequires both technical and social solutions that are not addressed withcurrent tools, technologies, and collaborative workflows. From the analysis ofour interviews, we distill several visualization research directions to improveKG usability, including knowledge cards that balance digestibility anddiscoverability, timeline views to track temporal changes, interfaces thatsupport organic discovery, and semantic explanations for AI and machinelearning predictions.</description><author>Harry Li, Gabriel Appleby, Camelia Daniela Brumar, Remco Chang, Ashley Suh</author><pubDate>Tue, 18 Jun 2024 17:47:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.01311v4</guid></item><item><title>Plasma Surrogate Modelling using Fourier Neural Operators</title><link>http://arxiv.org/abs/2311.05967v2</link><description>Predicting plasma evolution within a Tokamak reactor is crucial to realizingthe goal of sustainable fusion. Capabilities in forecasting the spatio-temporalevolution of plasma rapidly and accurately allow us to quickly iterate overdesign and control strategies on current Tokamak devices and future reactors.Modelling plasma evolution using numerical solvers is often expensive,consuming many hours on supercomputers, and hence, we need alternativeinexpensive surrogate models. We demonstrate accurate predictions of plasmaevolution both in simulation and experimental domains using deep learning-basedsurrogate modelling tools, viz., Fourier Neural Operators (FNO). We show thatFNO has a speedup of six orders of magnitude over traditional solvers inpredicting the plasma dynamics simulated from magnetohydrodynamic models, whilemaintaining a high accuracy (MSE in the normalised domain $\approx$ $10^{-5}$).Our modified version of the FNO is capable of solving multi-variable PartialDifferential Equations (PDE), and can capture the dependence among thedifferent variables in a single model. FNOs can also predict plasma evolutionon real-world experimental data observed by the cameras positioned within theMAST Tokamak, i.e., cameras looking across the central solenoid and thedivertor in the Tokamak. We show that FNOs are able to accurately forecast theevolution of plasma and have the potential to be deployed for real-timemonitoring. We also illustrate their capability in forecasting the plasmashape, the locations of interactions of the plasma with the central solenoidand the divertor for the full (available) duration of the plasma shot withinMAST. The FNO offers a viable alternative for surrogate modelling as it isquick to train and infer, and requires fewer data points, while being able todo zero-shot super-resolution and getting high-fidelity solutions.</description><author>Vignesh Gopakumar, Stanislas Pamela, Lorenzo Zanisi, Zongyi Li, Ander Gray, Daniel Brennand, Nitesh Bhatia, Gregory Stathopoulos, Matt Kusner, Marc Peter Deisenroth, Anima Anandkumar, JOREK Team, MAST Team</author><pubDate>Tue, 18 Jun 2024 17:46:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05967v2</guid></item><item><title>OPFData: Large-scale datasets for AC optimal power flow with topological perturbations</title><link>http://arxiv.org/abs/2406.07234v2</link><description>Solving the AC optimal power flow problem (AC-OPF) is critical to theefficient and safe planning and operation of power grids. Small efficiencyimprovements in this domain have the potential to lead to billions of dollarsof cost savings, and significant reductions in emissions from fossil fuelgenerators. Recent work on data-driven solution methods for AC-OPF shows thepotential for large speed improvements compared to traditional solvers;however, no large-scale open datasets for this problem exist. We present thelargest readily-available collection of solved AC-OPF problems to date. Thiscollection is orders of magnitude larger than existing readily-availabledatasets, allowing training of high-capacity data-driven models. Uniquely, itincludes topological perturbations - a critical requirement for usage inrealistic power grid operations. We hope this resource will spur the communityto scale research to larger grid sizes with variable topology.</description><author>Sean Lovett, Miha Zgubic, Sofia Liguori, Sephora Madjiheurem, Hamish Tomlinson, Sophie Elster, Chris Apps, Sims Witherspoon, Luis Piloto</author><pubDate>Tue, 18 Jun 2024 17:46:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07234v2</guid></item><item><title>Composited-Nested-Learning with Data Augmentation for Nested Named Entity Recognition</title><link>http://arxiv.org/abs/2406.12779v1</link><description>Nested Named Entity Recognition (NNER) focuses on addressing overlappedentity recognition. Compared to Flat Named Entity Recognition (FNER), annotatedresources are scarce in the corpus for NNER. Data augmentation is an effectiveapproach to address the insufficient annotated corpus. However, there is asignificant lack of exploration in data augmentation methods for NNER. Due tothe presence of nested entities in NNER, existing data augmentation methodscannot be directly applied to NNER tasks. Therefore, in this work, we focus ondata augmentation for NNER and resort to more expressive structures,Composited-Nested-Label Classification (CNLC) in which constituents arecombined by nested-word and nested-label, to model nested entities. The datasetis augmented using the Composited-Nested-Learning (CNL). In addition, wepropose the Confidence Filtering Mechanism (CFM) for a more efficient selectionof generated data. Experimental results demonstrate that this approach resultsin improvements in ACE2004 and ACE2005 and alleviates the impact of sampleimbalance.</description><author>Xingming Liao, Nankai Lin, Haowen Li, Lianglun Cheng, Zhuowei Wang, Chong Chen</author><pubDate>Tue, 18 Jun 2024 17:46:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12779v1</guid></item><item><title>Hopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries</title><link>http://arxiv.org/abs/2406.12775v1</link><description>Large language models (LLMs) can solve complex multi-step problems, butlittle is known about how these computations are implemented internally.Motivated by this, we study how LLMs answer multi-hop queries such as "Thespouse of the performer of Imagine is". These queries require two informationextraction steps: a latent one for resolving the first hop ("the performer ofImagine") into the bridge entity (John Lennon), and one for resolving thesecond hop ("the spouse of John Lennon") into the target entity (Yoko Ono).Understanding how the latent step is computed internally is key tounderstanding the overall computation. By carefully analyzing the internalcomputations of transformer-based LLMs, we discover that the bridge entity isresolved in the early layers of the model. Then, only after this resolution,the two-hop query is solved in the later layers. Because the second hopcommences in later layers, there could be cases where these layers no longerencode the necessary knowledge for correctly predicting the answer. Motivatedby this, we propose a novel "back-patching" analysis method whereby a hiddenrepresentation from a later layer is patched back to an earlier layer. We findthat in up to 57% of previously incorrect cases there exists a back-patch thatresults in the correct generation of the answer, showing that the later layersindeed sometimes lack the needed functionality. Overall our methods andfindings open further opportunities for understanding and improving latentreasoning in transformer-based LLMs.</description><author>Eden Biran, Daniela Gottesman, Sohee Yang, Mor Geva, Amir Globerson</author><pubDate>Tue, 18 Jun 2024 17:44:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12775v1</guid></item><item><title>Towards Exact Gradient-based Training on Analog In-memory Computing</title><link>http://arxiv.org/abs/2406.12774v1</link><description>Given the high economic and environmental costs of using large vision orlanguage models, analog in-memory accelerators present a promising solution forenergy-efficient AI. While inference on analog accelerators has been studiedrecently, the training perspective is underexplored. Recent studies have shownthat the "workhorse" of digital AI training - stochastic gradient descent (SGD)algorithm converges inexactly when applied to model training on non-idealdevices. This paper puts forth a theoretical foundation for gradient-basedtraining on analog devices. We begin by characterizing the non-convergent issueof SGD, which is caused by the asymmetric updates on the analog devices. Wethen provide a lower bound of the asymptotic error to show that there is afundamental performance limit of SGD-based analog training rather than anartifact of our analysis. To address this issue, we study a heuristic analogalgorithm called Tiki-Taka that has recently exhibited superior empiricalperformance compared to SGD and rigorously show its ability to exactly convergeto a critical point and hence eliminates the asymptotic error. The simulationsverify the correctness of the analyses.</description><author>Zhaoxian Wu, Tayfun Gokmen, Malte J. Rasch, Tianyi Chen</author><pubDate>Tue, 18 Jun 2024 17:43:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12774v1</guid></item><item><title>First-Order Methods for Linearly Constrained Bilevel Optimization</title><link>http://arxiv.org/abs/2406.12771v1</link><description>Algorithms for bilevel optimization often encounter Hessian computations,which are prohibitive in high dimensions. While recent works offer first-ordermethods for unconstrained bilevel problems, the constrained setting remainsrelatively underexplored. We present first-order linearly constrainedoptimization methods with finite-time hypergradient stationarity guarantees.For linear equality constraints, we attain $\epsilon$-stationarity in$\widetilde{O}(\epsilon^{-2})$ gradient oracle calls, which is nearly-optimal.For linear inequality constraints, we attain $(\delta,\epsilon)$-Goldsteinstationarity in $\widetilde{O}(d{\delta^{-1} \epsilon^{-3}})$ gradient oraclecalls, where $d$ is the upper-level dimension. Finally, we obtain for thelinear inequality setting dimension-free rates of $\widetilde{O}({\delta^{-1}\epsilon^{-4}})$ oracle complexity under the additional assumption of oracleaccess to the optimal dual variable. Along the way, we develop new nonsmoothnonconvex optimization methods with inexact oracles. We verify these guaranteeswith preliminary numerical experiments.</description><author>Guy Kornowski, Swati Padmanabhan, Kai Wang, Zhe Zhang, Suvrit Sra</author><pubDate>Tue, 18 Jun 2024 17:41:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12771v1</guid></item><item><title>Inference via Interpolation: Contrastive Representations Provably Enable Planning and Inference</title><link>http://arxiv.org/abs/2403.04082v2</link><description>Given time series data, how can we answer questions like "what will happen inthe future?" and "how did we get here?" These sorts of probabilistic inferencequestions are challenging when observations are high-dimensional. In thispaper, we show how these questions can have compact, closed form solutions interms of learned representations. The key idea is to apply a variant ofcontrastive learning to time series data. Prior work already shows that therepresentations learned by contrastive learning encode a probability ratio. Byextending prior work to show that the marginal distribution overrepresentations is Gaussian, we can then prove that joint distribution ofrepresentations is also Gaussian. Taken together, these results show thatrepresentations learned via temporal contrastive learning follow a Gauss-Markovchain, a graphical model where inference (e.g., prediction, planning) overrepresentations corresponds to inverting a low-dimensional matrix. In onespecial case, inferring intermediate representations will be equivalent tointerpolating between the learned representations. We validate our theory usingnumerical simulations on tasks up to 46-dimensions.</description><author>Benjamin Eysenbach, Vivek Myers, Ruslan Salakhutdinov, Sergey Levine</author><pubDate>Tue, 18 Jun 2024 17:40:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.04082v2</guid></item><item><title>Formatics &amp; dairy industry coalition: AI trends and present challenges</title><link>http://arxiv.org/abs/2406.12770v1</link><description>Artificial Intelligence (AI) can potentially transform the industry,enhancing the production process and minimizing manual, repetitive tasks.Accordingly, the synergy between high-performance computing and powerfulmathematical models enables the application of sophisticated data analysisprocedures like Machine Learning. However, challenges exist regardingeffective, efficient, and flexible processing to generate valuable knowledge.Consequently, this work comprehensively describes industrial challenges whereAI can be exploited, focusing on the dairy industry. The conclusions presentedcan help researchers apply novel approaches for cattle monitoring and farmersby proposing advanced technological solutions to their needs.</description><author>Silvia García-Méndez, Francisco de Arriba-Pérez, María del Carmen Somoza-López</author><pubDate>Tue, 18 Jun 2024 17:39:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12770v1</guid></item><item><title>Latent Intuitive Physics: Learning to Transfer Hidden Physics from A 3D Video</title><link>http://arxiv.org/abs/2406.12769v1</link><description>We introduce latent intuitive physics, a transfer learning framework forphysics simulation that can infer hidden properties of fluids from a single 3Dvideo and simulate the observed fluid in novel scenes. Our key insight is touse latent features drawn from a learnable prior distribution conditioned onthe underlying particle states to capture the invisible and complex physicalproperties. To achieve this, we train a parametrized prior learner given visualobservations to approximate the visual posterior of inverse graphics, and boththe particle states and the visual posterior are obtained from a learned neuralrenderer. The converged prior learner is embedded in our probabilistic physicsengine, allowing us to perform novel simulations on unseen geometries,boundaries, and dynamics without knowledge of the true physical parameters. Wevalidate our model in three ways: (i) novel scene simulation with the learnedvisual-world physics, (ii) future prediction of the observed fluid dynamics,and (iii) supervised particle simulation. Our model demonstrates strongperformance in all three tasks.</description><author>Xiangming Zhu, Huayu Deng, Haochen Yuan, Yunbo Wang, Xiaokang Yang</author><pubDate>Tue, 18 Jun 2024 17:37:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12769v1</guid></item><item><title>Quasi-Bayes meets Vines</title><link>http://arxiv.org/abs/2406.12764v1</link><description>Recently proposed quasi-Bayesian (QB) methods initiated a new era in Bayesiancomputation by directly constructing the Bayesian predictive distributionthrough recursion, removing the need for expensive computations involved insampling the Bayesian posterior distribution. This has proved to bedata-efficient for univariate predictions, but extensions to multipledimensions rely on a conditional decomposition resulting from predefinedassumptions on the kernel of the Dirichlet Process Mixture Model, which is theimplicit nonparametric model used. Here, we propose a different way to extendQuasi-Bayesian prediction to high dimensions through the use of Sklar's theoremby decomposing the predictive distribution into one-dimensional predictivemarginals and a high-dimensional copula. Thus, we use the efficient recursiveQB construction for the one-dimensional marginals and model the dependenceusing highly expressive vine copulas. Further, we tune hyperparameters usingrobust divergences (eg. energy score) and show that our proposed Quasi-BayesianVine (QB-Vine) is a fully non-parametric density estimator with \emph{ananalytical form} and convergence rate independent of the dimension of data insome situations. Our experiments illustrate that the QB-Vine is appropriate forhigh dimensional distributions ($\sim$64), needs very few samples to train($\sim$200) and outperforms state-of-the-art methods with analytical forms fordensity estimation and supervised tasks by a considerable margin.</description><author>David Huk, Yuanhe Zhang, Mark Steel, Ritabrata Dutta</author><pubDate>Tue, 18 Jun 2024 17:31:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12764v1</guid></item><item><title>Implicit Bias of Mirror Flow on Separable Data</title><link>http://arxiv.org/abs/2406.12763v1</link><description>We examine the continuous-time counterpart of mirror descent, namely mirrorflow, on classification problems which are linearly separable. Such problemsare minimised `at infinity' and have many possible solutions; we study whichsolution is preferred by the algorithm depending on the mirror potential. Forexponential tailed losses and under mild assumptions on the potential, we showthat the iterates converge in direction towards a $\phi_\infty$-maximum marginclassifier. The function $\phi_\infty$ is the $\textit{horizon function}$ ofthe mirror potential and characterises its shape `at infinity'. When thepotential is separable, a simple formula allows to compute this function. Weanalyse several examples of potentials and provide numerical experimentshighlighting our results.</description><author>Scott Pesme, Radu-Alexandru Dragomir, Nicolas Flammarion</author><pubDate>Tue, 18 Jun 2024 17:30:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12763v1</guid></item><item><title>Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners</title><link>http://arxiv.org/abs/2405.13816v2</link><description>Recently, Large Language Models (LLMs) have shown impressive languagecapabilities. While most of the existing LLMs have very unbalanced performanceacross different languages, multilingual alignment based on translationparallel data is an effective method to enhance the LLMs' multilingualcapabilities. In this work, we discover and comprehensively investigate thespontaneous multilingual alignment improvement of LLMs. We find that LLMsinstruction-tuned on the question translation data (i.e. without annotatedanswers) are able to encourage the alignment between English and a wide rangeof languages, even including those unseen during instruction-tuning.Additionally, we utilize different settings and mechanistic interpretabilitymethods to analyze the LLM's performance in the multilingual scenariocomprehensively. Our work suggests that LLMs have enormous potential forimproving multilingual alignment efficiently with great language and taskgeneralization.</description><author>Shimao Zhang, Changjiang Gao, Wenhao Zhu, Jiajun Chen, Xin Huang, Xue Han, Junlan Feng, Chao Deng, Shujian Huang</author><pubDate>Tue, 18 Jun 2024 17:30:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13816v2</guid></item><item><title>Unsupervised explainable activity prediction in competitive Nordic Walking from experimental data</title><link>http://arxiv.org/abs/2406.12762v1</link><description>Artificial Intelligence (AI) has found application in Human ActivityRecognition (HAR) in competitive sports. To date, most Machine Learning (ML)approaches for HAR have relied on offline (batch) training, imposing highercomputational and tagging burdens compared to online processing unsupervisedapproaches. Additionally, the decisions behind traditional ML predictors areopaque and require human interpretation. In this work, we apply an onlineprocessing unsupervised clustering approach based on low-cost wearable InertialMeasurement Units (IMUs). The outcomes generated by the system allow for theautomatic expansion of limited tagging available (e.g., by referees) withinthose clusters, producing pertinent information for the explainableclassification stage. Specifically, our work focuses on achieving automaticexplainability for predictions related to athletes' activities, distinguishingbetween correct, incorrect, and cheating practices in Nordic Walking. Theproposed solution achieved performance metrics of close to 100 % on average.</description><author>Silvia García-Méndez, Francisco de Arriba-Pérez, Francisco J. González-Castaño, Javier Vales-Alonso</author><pubDate>Tue, 18 Jun 2024 17:29:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12762v1</guid></item><item><title>MAC: A Benchmark for Multiple Attributes Compositional Zero-Shot Learning</title><link>http://arxiv.org/abs/2406.12757v1</link><description>Compositional Zero-Shot Learning (CZSL) aims to learn semantic primitives(attributes and objects) from seen compositions and recognize unseenattribute-object compositions. Existing CZSL datasets focus on singleattributes, neglecting the fact that objects naturally exhibit multipleinterrelated attributes. Real-world objects often possess multiple interrelatedattributes, and current datasets' narrow attribute scope and single attributelabeling introduce annotation biases, undermining model performance andevaluation. To address these limitations, we introduce the Multi-AttributeComposition (MAC) dataset, encompassing 18,217 images and 11,067 compositionswith comprehensive, representative, and diverse attribute annotations. MACincludes an average of 30.2 attributes per object and 65.4 objects perattribute, facilitating better multi-attribute composition predictions. Ourdataset supports deeper semantic understanding and higher-order attributeassociations, providing a more realistic and challenging benchmark for the CZSLtask. We also develop solutions for multi-attribute compositional learning andpropose the MM-encoder to disentangling the attributes and objects.</description><author>Shuo Xu, Sai Wang, Xinyue Hu, Yutian Lin, Bo Du, Yu Wu</author><pubDate>Tue, 18 Jun 2024 17:24:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12757v1</guid></item><item><title>GFM4MPM: Towards Geospatial Foundation Models for Mineral Prospectivity Mapping</title><link>http://arxiv.org/abs/2406.12756v1</link><description>Machine Learning (ML) for Mineral Prospectivity Mapping (MPM) remains achallenging problem as it requires the analysis of associations betweenlarge-scale multi-modal geospatial data and few historical mineral commodityobservations (positive labels). Recent MPM works have explored Deep Learning(DL) as a modeling tool with more representation capacity. However, theseoverparameterized methods may be more prone to overfitting due to theirreliance on scarce labeled data. While a large quantity of unlabeled geospatialdata exists, no prior MPM works have considered using such information in aself-supervised manner. Our MPM approach uses a masked image modeling frameworkto pretrain a backbone neural network in a self-supervised manner usingunlabeled geospatial data alone. After pretraining, the backbone networkprovides feature extraction for downstream MPM tasks. We evaluated our approachalongside existing methods to assess mineral prospectivity of MississippiValley Type (MVT) and Clastic-Dominated (CD) Lead-Zinc deposits in NorthAmerica and Australia. Our results demonstrate that self-supervision promotesrobustness in learned features, improving prospectivity predictions.Additionally, we leverage explainable artificial intelligence techniques todemonstrate that individual predictions can be interpreted from a geologicalperspective.</description><author>Angel Daruna, Vasily Zadorozhnyy, Georgina Lukoczki, Han-Pang Chiu</author><pubDate>Tue, 18 Jun 2024 17:24:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12756v1</guid></item><item><title>DataComp-LM: In search of the next generation of training sets for language models</title><link>http://arxiv.org/abs/2406.11794v2</link><description>We introduce DataComp for Language Models (DCLM), a testbed for controlleddataset experiments with the goal of improving language models. As part ofDCLM, we provide a standardized corpus of 240T tokens extracted from CommonCrawl, effective pretraining recipes based on the OpenLM framework, and a broadsuite of 53 downstream evaluations. Participants in the DCLM benchmark canexperiment with data curation strategies such as deduplication, filtering, anddata mixing at model scales ranging from 412M to 7B parameters. As a baselinefor DCLM, we conduct extensive experiments and find that model-based filteringis key to assembling a high-quality training set. The resulting dataset,DCLM-Baseline enables training a 7B parameter language model from scratch to64% 5-shot accuracy on MMLU with 2.6T training tokens. Compared to MAP-Neo, theprevious state-of-the-art in open-data language models, DCLM-Baselinerepresents a 6.6 percentage point improvement on MMLU while being trained with40% less compute. Our baseline model is also comparable to Mistral-7B-v0.3 andLlama 3 8B on MMLU (63% &amp; 66%), and performs similarly on an average of 53natural language understanding tasks while being trained with 6.6x less computethan Llama 3 8B. Our results highlight the importance of dataset design fortraining language models and offer a starting point for further research ondata curation.</description><author>Jeffrey Li, Alex Fang, Georgios Smyrnis, Maor Ivgi, Matt Jordan, Samir Gadre, Hritik Bansal, Etash Guha, Sedrick Keh, Kushal Arora, Saurabh Garg, Rui Xin, Niklas Muennighoff, Reinhard Heckel, Jean Mercat, Mayee Chen, Suchin Gururangan, Mitchell Wortsman, Alon Albalak, Yonatan Bitton, Marianna Nezhurina, Amro Abbas, Cheng-Yu Hsieh, Dhruba Ghosh, Josh Gardner, Maciej Kilian, Hanlin Zhang, Rulin Shao, Sarah Pratt, Sunny Sanyal, Gabriel Ilharco, Giannis Daras, Kalyani Marathe, Aaron Gokaslan, Jieyu Zhang, Khyathi Chandu, Thao Nguyen, Igor Vasiljevic, Sham Kakade, Shuran Song, Sujay Sanghavi, Fartash Faghri, Sewoong Oh, Luke Zettlemoyer, Kyle Lo, Alaaeldin El-Nouby, Hadi Pouransari, Alexander Toshev, Stephanie Wang, Dirk Groeneveld, Luca Soldaini, Pang Wei Koh, Jenia Jitsev, Thomas Kollar, Alex</author><pubDate>Tue, 18 Jun 2024 17:22:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11794v2</guid></item><item><title>Chumor 1.0: A Truly Funny and Challenging Chinese Humor Understanding Dataset from Ruo Zhi Ba</title><link>http://arxiv.org/abs/2406.12754v1</link><description>Existing humor datasets and evaluations predominantly focus on English,lacking resources for culturally nuanced humor in non-English languages likeChinese. To address this gap, we construct Chumor, a dataset sourced from RuoZhi Ba (RZB), a Chinese Reddit-like platform dedicated to sharingintellectually challenging and culturally specific jokes. We annotateexplanations for each joke and evaluate human explanations against twostate-of-the-art LLMs, GPT-4o and ERNIE Bot, through A/B testing by nativeChinese speakers. Our evaluation shows that Chumor is challenging even for SOTALLMs, and the human explanations for Chumor jokes are significantly better thanexplanations generated by the LLMs.</description><author>Ruiqi He, Yushu He, Longju Bai, Jiarui Liu, Zhenjie Sun, Zenghao Tang, He Wang, Hanchen Xia, Naihao Deng</author><pubDate>Tue, 18 Jun 2024 17:22:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12754v1</guid></item><item><title>Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review</title><link>http://arxiv.org/abs/2310.14735v4</link><description>This paper delves into the pivotal role of prompt engineering in unleashingthe capabilities of Large Language Models (LLMs). Prompt engineering is theprocess of structuring input text for LLMs and is a technique integral tooptimizing the efficacy of LLMs. This survey elucidates foundational principlesof prompt engineering, such as role-prompting, one-shot, and few-shotprompting, as well as more advanced methodologies such as the chain-of-thoughtand tree-of-thoughts prompting. The paper sheds light on how externalassistance in the form of plugins can assist in this task, and reduce machinehallucination by retrieving external knowledge. We subsequently delineateprospective directions in prompt engineering research, emphasizing the need fora deeper understanding of structures and the role of agents in ArtificialIntelligence-Generated Content (AIGC) tools. We discuss how to assess theefficacy of prompt methods from different perspectives and using differentmethods. Finally, we gather information about the application of promptengineering in such fields as education and programming, showing itstransformative potential. This comprehensive survey aims to serve as a friendlyguide for anyone venturing through the big world of LLMs and promptengineering.</description><author>Banghao Chen, Zhaofeng Zhang, Nicolas Langrené, Shengxin Zhu</author><pubDate>Tue, 18 Jun 2024 17:21:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14735v4</guid></item><item><title>OlympicArena: Benchmarking Multi-discipline Cognitive Reasoning for Superintelligent AI</title><link>http://arxiv.org/abs/2406.12753v1</link><description>The evolution of Artificial Intelligence (AI) has been significantlyaccelerated by advancements in Large Language Models (LLMs) and LargeMultimodal Models (LMMs), gradually showcasing potential cognitive reasoningabilities in problem-solving and scientific discovery (i.e., AI4Science) onceexclusive to human intellect. To comprehensively evaluate current models'performance in cognitive reasoning abilities, we introduce OlympicArena, whichincludes 11,163 bilingual problems across both text-only and interleavedtext-image modalities. These challenges encompass a wide range of disciplinesspanning seven fields and 62 international Olympic competitions, rigorouslyexamined for data leakage. We argue that the challenges in Olympic competitionproblems are ideal for evaluating AI's cognitive reasoning due to theircomplexity and interdisciplinary nature, which are essential for tacklingcomplex scientific challenges and facilitating discoveries. Beyond evaluatingperformance across various disciplines using answer-only criteria, we conductdetailed experiments and analyses from multiple perspectives. We delve into themodels' cognitive reasoning abilities, their performance across differentmodalities, and their outcomes in process-level evaluations, which are vitalfor tasks requiring complex reasoning with lengthy solutions. Our extensiveevaluations reveal that even advanced models like GPT-4o only achieve a 39.97%overall accuracy, illustrating current AI limitations in complex reasoning andmultimodal integration. Through the OlympicArena, we aim to advance AI towardssuperintelligence, equipping it to address more complex challenges in scienceand beyond. We also provide a comprehensive set of resources to support AIresearch, including a benchmark dataset, an open-source annotation platform, adetailed evaluation tool, and a leaderboard with automatic submission features.</description><author>Zhen Huang, Zengzhi Wang, Shijie Xia, Xuefeng Li, Haoyang Zou, Ruijie Xu, Run-Ze Fan, Lyumanshan Ye, Ethan Chern, Yixin Ye, Yikai Zhang, Yuqing Yang, Ting Wu, Binjie Wang, Shichao Sun, Yang Xiao, Yiyuan Li, Fan Zhou, Steffi Chern, Yiwei Qin, Yan Ma, Jiadi Su, Yixiu Liu, Yuxiang Zheng, Shaoting Zhang, Dahua Lin, Yu Qiao, Pengfei Liu</author><pubDate>Tue, 18 Jun 2024 17:20:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12753v1</guid></item><item><title>Extracting Training Data from Unconditional Diffusion Models</title><link>http://arxiv.org/abs/2406.12752v1</link><description>As diffusion probabilistic models (DPMs) are being employed as mainstreammodels for generative artificial intelligence (AI), the study of theirmemorization of the raw training data has attracted growing attention. Existingworks in this direction aim to establish an understanding of whether or to whatextent DPMs learn by memorization. Such an understanding is crucial foridentifying potential risks of data leakage and copyright infringement indiffusion models and, more importantly, for more controllable generation andtrustworthy application of Artificial Intelligence Generated Content (AIGC).While previous works have made important observations of when DPMs are prone tomemorization, these findings are mostly empirical, and the developed dataextraction methods only work for conditional diffusion models. In this work, weaim to establish a theoretical understanding of memorization in DPMs with 1) amemorization metric for theoretical analysis, 2) an analysis of conditionalmemorization with informative and random labels, and 3) two better evaluationmetrics for measuring memorization. Based on the theoretical analysis, wefurther propose a novel data extraction method called \textbf{SurrogatecondItional Data Extraction (SIDE)} that leverages a classifier trained ongenerated data as a surrogate condition to extract training data directly fromunconditional diffusion models. Our empirical results demonstrate that SIDE canextract training data from diffusion models where previous methods fail, and itis on average over 50\% more effective across different scales of the CelebAdataset.</description><author>Yunhao Chen, Xingjun Ma, Difan Zou, Yu-Gang Jiang</author><pubDate>Tue, 18 Jun 2024 17:20:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12752v1</guid></item><item><title>High-Performance Hybrid Algorithm for Minimum Sum-of-Squares Clustering of Infinitely Tall Data</title><link>http://arxiv.org/abs/2311.04517v4</link><description>This paper introduces a novel formulation of the clustering problem, namelythe Minimum Sum-of-Squares Clustering of Infinitely Tall Data (MSSC-ITD), andpresents HPClust, an innovative set of hybrid parallel approaches for itseffective solution. By utilizing modern high-performance computing techniques,HPClust enhances key clustering metrics: effectiveness, computationalefficiency, and scalability. In contrast to vanilla data parallelism, whichonly accelerates processing time through the MapReduce framework, our approachunlocks superior performance by leveraging the multi-strategycompetitive-cooperative parallelism and intricate properties of the objectivefunction landscape. Unlike other available algorithms that struggle to scale,our algorithm is inherently parallel in nature, improving solution qualitythrough increased scalability and parallelism, and outperforming even advancedalgorithms designed for small and medium-sized datasets. Our evaluation ofHPClust, featuring four parallel strategies, demonstrates its superiority overtraditional and cutting-edge methods by offering better performance in the keymetrics. These results also show that parallel processing not only enhances theclustering efficiency, but the accuracy as well. Additionally, we explore thebalance between computational efficiency and clustering quality, providinginsights into optimal parallel strategies based on dataset specifics andresource availability. This research advances our understanding of parallelismin clustering algorithms, demonstrating that a judicious hybridization ofadvanced parallel approaches yields optimal results for MSSC-ITD. Experimentson synthetic data further confirm HPClust's exceptional scalability androbustness to noise.</description><author>Ravil Mussabayev, Rustam Mussabayev</author><pubDate>Tue, 18 Jun 2024 17:19:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04517v4</guid></item><item><title>Reinforcement Learning from Multi-role Debates as Feedback for Bias Mitigation in LLMs</title><link>http://arxiv.org/abs/2404.10160v5</link><description>Bias in LLMs can harm user experience and societal outcomes. However, currentbias mitigation methods often require intensive human feedback, lacktransferability to other topics or yield overconfident and random outputs. Wefind that involving LLMs in role-playing scenario boosts their ability torecognize and mitigate biases. Based on this, we propose Reinforcement Learningfrom Multi-role Debates as Feedback (RLDF), a novel approach for biasmitigation replacing human feedback in traditional RLHF. We utilize LLMs inmulti-role debates to create a dataset that includes both high-bias andlow-bias instances for training the reward model in reinforcement learning. Ourapproach comprises two modes: (1) self-reflection, where the same LLMparticipates in multi-role debates, and (2) teacher-student, where a moreadvanced LLM like GPT-3.5-turbo guides the LLM to perform this task.Experimental results across different LLMs demonstrate the effectiveness of ourapproach in bias mitigation.</description><author>Ruoxi Cheng, Haoxuan Ma, Shuirong Cao, Jiaqi Li, Aihua Pei, Zhiqiang Wang, Pengliang Ji, Haoyu Wang, Jiaqi Huo</author><pubDate>Tue, 18 Jun 2024 17:19:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10160v5</guid></item><item><title>Challenges to Evaluating the Generalization of Coreference Resolution Models: A Measurement Modeling Perspective</title><link>http://arxiv.org/abs/2303.09092v2</link><description>It is increasingly common to evaluate the same coreference resolution (CR)model on multiple datasets. Do these multi-dataset evaluations allow us to drawmeaningful conclusions about model generalization? Or, do they rather reflectthe idiosyncrasies of a particular experimental setup (e.g., the specificdatasets used)? To study this, we view evaluation through the lens ofmeasurement modeling, a framework commonly used in the social sciences foranalyzing the validity of measurements. By taking this perspective, we show howmulti-dataset evaluations risk conflating different factors concerning what,precisely, is being measured. This in turn makes it difficult to draw moregeneralizable conclusions from these evaluations. For instance, we show thatacross seven datasets, measurements intended to reflect CR model generalizationare often correlated with differences in both how coreference is defined andhow it is operationalized; this limits our ability to draw conclusionsregarding the ability of CR models to generalize across any singular dimension.We believe the measurement modeling framework provides the needed vocabularyfor discussing challenges surrounding what is actually being measured by CRevaluations.</description><author>Ian Porada, Alexandra Olteanu, Kaheer Suleman, Adam Trischler, Jackie Chi Kit Cheung</author><pubDate>Tue, 18 Jun 2024 17:19:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09092v2</guid></item><item><title>Zero-Shot Neural Architecture Search: Challenges, Solutions, and Opportunities</title><link>http://arxiv.org/abs/2307.01998v3</link><description>Recently, zero-shot (or training-free) Neural Architecture Search (NAS)approaches have been proposed to liberate NAS from the expensive trainingprocess. The key idea behind zero-shot NAS approaches is to design proxies thatcan predict the accuracy of some given networks without training the networkparameters. The proxies proposed so far are usually inspired by recent progressin theoretical understanding of deep learning and have shown great potential onseveral datasets and NAS benchmarks. This paper aims to comprehensively reviewand compare the state-of-the-art (SOTA) zero-shot NAS approaches, with anemphasis on their hardware awareness. To this end, we first review themainstream zero-shot proxies and discuss their theoretical underpinnings. Wethen compare these zero-shot proxies through large-scale experiments anddemonstrate their effectiveness in both hardware-aware and hardware-obliviousNAS scenarios. Finally, we point out several promising ideas to design betterproxies. Our source code and the list of related papers are available onhttps://github.com/SLDGroup/survey-zero-shot-nas.</description><author>Guihong Li, Duc Hoang, Kartikeya Bhardwaj, Ming Lin, Zhangyang Wang, Radu Marculescu</author><pubDate>Tue, 18 Jun 2024 17:09:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01998v3</guid></item><item><title>TSI-Bench: Benchmarking Time Series Imputation</title><link>http://arxiv.org/abs/2406.12747v1</link><description>Effective imputation is a crucial preprocessing step for time seriesanalysis. Despite the development of numerous deep learning algorithms for timeseries imputation, the community lacks standardized and comprehensive benchmarkplatforms to effectively evaluate imputation performance across differentsettings. Moreover, although many deep learning forecasting algorithms havedemonstrated excellent performance, whether their modeling achievements can betransferred to time series imputation tasks remains unexplored. To bridge thesegaps, we develop TSI-Bench, the first (to our knowledge) comprehensivebenchmark suite for time series imputation utilizing deep learning techniques.The TSI-Bench pipeline standardizes experimental settings to enable fairevaluation of imputation algorithms and identification of meaningful insightsinto the influence of domain-appropriate missingness ratios and patterns onmodel performance. Furthermore, TSI-Bench innovatively provides a systematicparadigm to tailor time series forecasting algorithms for imputation purposes.Our extensive study across 34,804 experiments, 28 algorithms, and 8 datasetswith diverse missingness scenarios demonstrates TSI-Bench's effectiveness indiverse downstream tasks and potential to unlock future directions in timeseries imputation research and analysis. The source code and experiment logsare available at https://github.com/WenjieDu/AwesomeImputation.</description><author>Wenjie Du, Jun Wang, Linglong Qian, Yiyuan Yang, Fanxing Liu, Zepu Wang, Zina Ibrahim, Haoxin Liu, Zhiyuan Zhao, Yingjie Zhou, Wenjia Wang, Kaize Ding, Yuxuan Liang, B. Aditya Prakash, Qingsong Wen</author><pubDate>Tue, 18 Jun 2024 17:07:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12747v1</guid></item><item><title>Rationale-based Ensemble of Multiple QA Strategies for Zero-shot Knowledge-based VQA</title><link>http://arxiv.org/abs/2406.12746v1</link><description>Knowledge-based Visual Qustion-answering (K-VQA) necessitates the use ofbackground knowledge beyond what is depicted in the image. Current zero-shotK-VQA methods usually translate an image to a single type of textual decisioncontext and use a text-based model to answer the question based on it, whichconflicts with the fact that K-VQA questions often require the combination ofmultiple question-answering strategies. In light of this, we proposeRationale-based Ensemble of Answer Context Tactics (REACT) to achieve a dynamicensemble of multiple question-answering tactics, comprising Answer CandidateGeneration (ACG) and Rationale-based Strategy Fusion (RSF). In ACG, we generatethree distinctive decision contexts to provide different strategies for eachquestion, resulting in the generation of three answer candidates. RSF generatesautomatic and mechanistic rationales from decision contexts for each candidate,allowing the model to select the correct answer from all candidates. We conductcomprehensive experiments on the OK-VQA and A-OKVQA datasets, and our methodsignificantly outperforms state-of-the-art LLM-based baselines on all datasets.</description><author>Miaoyu Li, Haoxin Li, Zilin Du, Boyang Li</author><pubDate>Tue, 18 Jun 2024 17:06:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12746v1</guid></item><item><title>Ensuring Both Positivity and Stability Using Sector-Bounded Nonlinearity for Systems with Neural Network Controllers</title><link>http://arxiv.org/abs/2406.12744v1</link><description>This paper introduces a novel method for the stability analysis of positivefeedback systems with a class of fully connected feedforward neural networks(FFNN) controllers. By establishing sector bounds for fully connected FFNNswithout biases, we present a stability theorem that demonstrates the globalexponential stability of linear systems under fully connected FFNN control.Utilizing principles from positive Lur'e systems and the positive Aizermanconjecture, our approach effectively addresses the challenge of ensuringstability in highly nonlinear systems. The crux of our method lies inmaintaining sector bounds that preserve the positivity and Hurwitz property ofthe overall Lur'e system. We showcase the practical applicability of ourmethodology through its implementation in a linear system managed by a FFNNtrained on output feedback controller data, highlighting its potential forenhancing stability in dynamic systems.</description><author>Hamidreza Montazeri Hedesh, Milad Siami</author><pubDate>Tue, 18 Jun 2024 17:05:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12744v1</guid></item><item><title>MeshXL: Neural Coordinate Field for Generative 3D Foundation Models</title><link>http://arxiv.org/abs/2405.20853v2</link><description>The polygon mesh representation of 3D data exhibits great flexibility, fastrendering speed, and storage efficiency, which is widely preferred in variousapplications. However, given its unstructured graph representation, the directgeneration of high-fidelity 3D meshes is challenging. Fortunately, with apre-defined ordering strategy, 3D meshes can be represented as sequences, andthe generation process can be seamlessly treated as an auto-regressive problem.In this paper, we validate the Neural Coordinate Field (NeurCF), an explicitcoordinate representation with implicit neural embeddings, is asimple-yet-effective representation for large-scale sequential mesh modeling.After that, we present MeshXL, a family of generative pre-trainedauto-regressive models, which addresses the process of 3D mesh generation withmodern large language model approaches. Extensive experiments show that MeshXLis able to generate high-quality 3D meshes, and can also serve as foundationmodels for various down-stream applications.</description><author>Sijin Chen, Xin Chen, Anqi Pang, Xianfang Zeng, Wei Cheng, Yijun Fu, Fukun Yin, Yanru Wang, Zhibin Wang, Chi Zhang, Jingyi Yu, Gang Yu, Bin Fu, Tao Chen</author><pubDate>Tue, 18 Jun 2024 17:03:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20853v2</guid></item><item><title>Benchmarking Multi-Image Understanding in Vision and Language Models: Perception, Knowledge, Reasoning, and Multi-Hop Reasoning</title><link>http://arxiv.org/abs/2406.12742v1</link><description>The advancement of large language models (LLMs) has significantly broadenedthe scope of applications in natural language processing, with multi-modal LLMsextending these capabilities to integrate and interpret visual data. However,existing benchmarks for visual language models (VLMs) predominantly focus onsingle-image inputs, neglecting the crucial aspect of multi-imageunderstanding. In this paper, we introduce a Multi-Image Relational BenchmarkMIRB, designed to evaluate VLMs' ability to compare, analyze, and reason acrossmultiple images. Our benchmark encompasses four categories: perception, visualworld knowledge, reasoning, and multi-hop reasoning. Through a comprehensiveevaluation of a wide range of open-source and closed-source models, wedemonstrate that while open-source VLMs were shown to approach the performanceof GPT-4V in single-image tasks, a significant performance gap remains inmulti-image reasoning tasks. Our findings also reveal that even thestate-of-the-art GPT-4V model struggles with our benchmark, underscoring theneed for further research and development in this area. We believe ourcontribution of MIRB could serve as a testbed for developing thenext-generation multi-modal models.</description><author>Bingchen Zhao, Yongshuo Zong, Letian Zhang, Timothy Hospedales</author><pubDate>Tue, 18 Jun 2024 17:02:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12742v1</guid></item><item><title>To smooth a cloud or to pin it down: Guarantees and Insights on Score Matching in Denoising Diffusion Models</title><link>http://arxiv.org/abs/2305.09605v2</link><description>Denoising diffusion models are a class of generative models which haverecently achieved state-of-the-art results across many domains. Gradual noiseis added to the data using a diffusion process, which transforms the datadistribution into a Gaussian. Samples from the generative model are thenobtained by simulating an approximation of the time reversal of this diffusioninitialized by Gaussian samples. Recent research has explored adaptingdiffusion models for sampling and inference tasks. In this paper, we leverageknown connections to stochastic control akin to the F\"ollmer drift to extendestablished neural network approximation results for the F\"ollmer drift todenoising diffusion models and samplers.</description><author>Francisco Vargas, Teodora Reu, Anna Kerekes</author><pubDate>Tue, 18 Jun 2024 17:01:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09605v2</guid></item><item><title>Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+ Languages</title><link>http://arxiv.org/abs/2406.12739v1</link><description>LLMs have become a go-to solution not just for text generation, but also fornatural language understanding (NLU) tasks. Acquiring extensive knowledgethrough language modeling on web-scale corpora, they excel on English NLU, yetstruggle to extend their NLU capabilities to underrepresented languages. Incontrast, machine translation models (MT) produce excellent multilingualrepresentations, resulting in strong translation performance even forlow-resource languages. MT encoders, however, lack the knowledge necessary forcomprehensive NLU that LLMs obtain through language modeling training onimmense corpora. In this work, we get the best both worlds by integrating MTencoders directly into LLM backbones via sample-efficient self-distillation.The resulting MT-LLMs preserve the inherent multilingual representationalalignment from the MT encoder, allowing lower-resource languages to tap intothe rich knowledge embedded in English-centric LLMs. Merging the MT encoder andLLM in a single model, we mitigate the propagation of translation errors andinference overhead of MT decoding inherent to discrete translation-basedcross-lingual transfer (e.g., translate-test). Evaluation spanning threeprominent NLU tasks and 127 predominantly low-resource languages rendersMT-LLMs highly effective in cross-lingual transfer. MT-LLMs substantially andconsistently outperform translate-test based on the same MT model, showing thatwe truly unlock multilingual language understanding for LLMs.</description><author>Fabian David Schmidt, Philipp Borchert, Ivan Vulić, Goran Glavaš</author><pubDate>Tue, 18 Jun 2024 17:00:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12739v1</guid></item><item><title>Self-Control of LLM Behaviors by Compressing Suffix Gradient into Prefix Controller</title><link>http://arxiv.org/abs/2406.02721v2</link><description>We propose Self-Control, a novel method utilizing suffix gradients to controlthe behavior of large language models (LLMs) without explicit humanannotations. Given a guideline expressed in suffix string and the model'sself-assessment of adherence, Self-Control computes the gradient of thisself-judgment concerning the model's hidden states, directly influencing theauto-regressive generation process towards desired behaviors. To enhanceefficiency, we introduce Self-Control_{prefix}, a compact module thatencapsulates the learned representations from suffix gradients into a PrefixController, facilitating inference-time control for various LLM behaviors. Ourexperiments demonstrate Self-Control's efficacy across multiple domains,including emotional modulation, ensuring harmlessness, and enhancing complexreasoning. Especially, Self-Control_{prefix} enables a plug-and-play controland jointly controls multiple attributes, improving model outputs withoutaltering model parameters or increasing inference-time costs.</description><author>Min Cai, Yuchen Zhang, Shichang Zhang, Fan Yin, Difan Zou, Yisong Yue, Ziniu Hu</author><pubDate>Tue, 18 Jun 2024 16:58:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02721v2</guid></item><item><title>Large Language Model as a Universal Clinical Multi-task Decoder</title><link>http://arxiv.org/abs/2406.12738v1</link><description>The development of effective machine learning methodologies for enhancing theefficiency and accuracy of clinical systems is crucial. Despite significantresearch efforts, managing a plethora of diversified clinical tasks andadapting to emerging new tasks remain significant challenges. This paperpresents a novel paradigm that employs a pre-trained large language model as auniversal clinical multi-task decoder. This approach leverages the flexibilityand diversity of language expressions to handle task topic variations andassociated arguments. The introduction of a new task simply requires theaddition of a new instruction template. We validate this framework acrosshundreds of tasks, demonstrating its robustness in facilitating multi-taskpredictions, performing on par with traditional multi-task learning andsingle-task learning approaches. Moreover, it shows exceptional adaptability tonew tasks, with impressive zero-shot performance in some instances and superiordata efficiency in few-shot scenarios. This novel approach offers a unifiedsolution to manage a wide array of new and emerging tasks in clinicalapplications.</description><author>Yujiang Wu, Hongjian Song, Jiawen Zhang, Xumeng Wen, Shun Zheng, Jiang Bian</author><pubDate>Tue, 18 Jun 2024 16:58:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12738v1</guid></item><item><title>Beyond Visual Appearances: Privacy-sensitive Objects Identification via Hybrid Graph Reasoning</title><link>http://arxiv.org/abs/2406.12736v1</link><description>The Privacy-sensitive Object Identification (POI) task allocates boundingboxes for privacy-sensitive objects in a scene. The key to POI is settling anobject's privacy class (privacy-sensitive or non-privacy-sensitive). Incontrast to conventional object classes which are determined by the visualappearance of an object, one object's privacy class is derived from the scenecontexts and is subject to various implicit factors beyond its visualappearance. That is, visually similar objects may be totally opposite in theirprivacy classes. To explicitly derive the objects' privacy class from the scenecontexts, in this paper, we interpret the POI task as a visual reasoning taskaimed at the privacy of each object in the scene. Following thisinterpretation, we propose the PrivacyGuard framework for POI. PrivacyGuardcontains three stages. i) Structuring: an unstructured image is first convertedinto a structured, heterogeneous scene graph that embeds rich scene contexts.ii) Data Augmentation: a contextual perturbation oversampling strategy isproposed to create slightly perturbed privacy-sensitive objects in a scenegraph, thereby balancing the skewed distribution of privacy classes. iii)Hybrid Graph Generation &amp; Reasoning: the balanced, heterogeneous scene graph isthen transformed into a hybrid graph by endowing it with extra "node-node" and"edge-edge" homogeneous paths. These homogeneous paths allow direct messagepassing between nodes or edges, thereby accelerating reasoning and facilitatingthe capturing of subtle context changes. Based on this hybrid graph... **Forthe full abstract, see the original paper.**</description><author>Zhuohang Jiang, Bingkui Tong, Xia Du, Ahmed Alhammadi, Jizhe Zhou</author><pubDate>Tue, 18 Jun 2024 16:58:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12736v1</guid></item><item><title>Automatic generation of insights from workers' actions in industrial workflows with explainable Machine Learning</title><link>http://arxiv.org/abs/2406.12732v1</link><description>New technologies such as Machine Learning (ML) gave great potential forevaluating industry workflows and automatically generating key performanceindicators (KPIs). However, despite established standards for measuring theefficiency of industrial machinery, there is no precise equivalent for workers'productivity, which would be highly desirable given the lack of a skilledworkforce for the next generation of industry workflows. Therefore, an MLsolution combining data from manufacturing processes and workers' performancefor that goal is required. Additionally, in recent times intense effort hasbeen devoted to explainable ML approaches that can automatically explain theirdecisions to a human operator, thus increasing their trustworthiness. Wepropose to apply explainable ML solutions to differentiate between expert andinexpert workers in industrial workflows, which we validate at a qualityassessment industrial workstation. Regarding the methodology used, input dataare captured by a manufacturing machine and stored in a NoSQL database. Dataare processed to engineer features used in automatic classification and tocompute workers' KPIs to predict their level of expertise (with allclassification metrics exceeding 90 %). These KPIs, and the relevant featuresin the decisions are textually explained by natural language expansion on anexplainability dashboard. These automatic explanations made it possible toinfer knowledge from expert workers for inexpert workers. The latterillustrates the interest of research in self-explainable ML for automaticallygenerating insights to improve productivity in industrial workflows.</description><author>Francisco de Arriba-Pérez, Silvia García-Méndez, Javier Otero-Mosquera, Francisco J. González-Castaño, Felipe Gil-Castiñeira</author><pubDate>Tue, 18 Jun 2024 16:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12732v1</guid></item><item><title>Predicting the energetic proton flux with a machine learning regression algorithm</title><link>http://arxiv.org/abs/2406.12730v1</link><description>The need of real-time of monitoring and alerting systems for Space Weatherhazards has grown significantly in the last two decades. One of the mostimportant challenge for space mission operations and planning is the predictionof solar proton events (SPEs). In this context, artificial intelligence andmachine learning techniques have opened a new frontier, providing a newparadigm for statistical forecasting algorithms. The great majority of thesemodels aim to predict the occurrence of a SPE, i.e., they are based on theclassification approach. In this work we present a simple and efficient machinelearning regression algorithm which is able to forecast the energetic protonflux up to 1 hour ahead by exploiting features derived from the electron fluxonly. This approach could be helpful to improve monitoring systems of theradiation risk in both deep space and near-Earth environments. The model isvery relevant for mission operations and planning, especially when flarecharacteristics and source location are not available in real time, as at Marsdistance.</description><author>Mirko Stumpo, Monica Laurenza, Simone Benella, Maria Federica Marcucci</author><pubDate>Tue, 18 Jun 2024 16:54:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12730v1</guid></item><item><title>Leveraging Generative Models for Covert Messaging: Challenges and Tradeoffs for "Dead-Drop" Deployments</title><link>http://arxiv.org/abs/2110.07009v3</link><description>State of the art generative models of human-produced content are the focus ofmany recent papers that explore their use for steganographic communication. Inparticular, generative models of natural language text. Loosely, these works(invertibly) encode message-carrying bits into a sequence of samples from themodel, ultimately yielding a plausible natural language covertext. By focusingon this narrow steganographic piece, prior work has largely ignored thesignificant algorithmic challenges, and performance-security tradeoffs, thatarise when one actually tries to build a messaging pipeline around it. We makethese challenges concrete, by considering the natural application of such apipeline: namely, "dead-drop" covert messaging over large, public internetplatforms (e.g. social media sites). We explicate the challenges and describeapproaches to overcome them, surfacing in the process important performance andsecurity tradeoffs that must be carefully tuned. We implement a system aroundthis model-based format-transforming encryption pipeline, and give an empiricalanalysis of its performance and (heuristic) security.</description><author>Luke A. Bauer, James K. Howes IV, Sam A. Markelon, Vincent Bindschaedler, Thomas Shrimpton</author><pubDate>Tue, 18 Jun 2024 16:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.07009v3</guid></item><item><title>Can Large Language Models Code Like a Linguist?: A Case Study in Low Resource Sound Law Induction</title><link>http://arxiv.org/abs/2406.12725v1</link><description>Historical linguists have long written a kind of incompletely formalized''program'' that converts reconstructed words in an ancestor language intowords in one of its attested descendants that consist of a series of orderedstring rewrite functions (called sound laws). They do this by observing pairsof words in the reconstructed language (protoforms) and the descendent language(reflexes) and constructing a program that transforms protoforms into reflexes.However, writing these programs is error-prone and time-consuming. Prior workhas successfully scaffolded this process computationally, but fewer researchershave tackled Sound Law Induction (SLI), which we approach in this paper bycasting it as Programming by Examples. We propose a language-agnostic solutionthat utilizes the programming ability of Large Language Models (LLMs) bygenerating Python sound law programs from sound change examples. We evaluatethe effectiveness of our approach for various LLMs, propose effective methodsto generate additional language-agnostic synthetic data to fine-tune LLMs forSLI, and compare our method with existing automated SLI methods showing thatwhile LLMs lag behind them they can complement some of their weaknesses.</description><author>Atharva Naik, Kexun Zhang, Nathaniel Robinson, Aravind Mysore, Clayton Marr, Hong Sng Rebecca Byrnes, Anna Cai, Kalvin Chang, David Mortensen</author><pubDate>Tue, 18 Jun 2024 16:46:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12725v1</guid></item><item><title>BIOSCAN-5M: A Multimodal Dataset for Insect Biodiversity</title><link>http://arxiv.org/abs/2406.12723v1</link><description>As part of an ongoing worldwide effort to comprehend and monitor insectbiodiversity, this paper presents the BIOSCAN-5M Insect dataset to the machinelearning community and establish several benchmark tasks. BIOSCAN-5M is acomprehensive dataset containing multi-modal information for over 5 millioninsect specimens, and it significantly expands existing image-based biologicaldatasets by including taxonomic labels, raw nucleotide barcode sequences,assigned barcode index numbers, and geographical information. We propose threebenchmark experiments to demonstrate the impact of the multi-modal data typeson the classification and clustering accuracy. First, we pretrain a maskedlanguage model on the DNA barcode sequences of the \mbox{BIOSCAN-5M} dataset,and demonstrate the impact of using this large reference library on species-and genus-level classification performance. Second, we propose a zero-shottransfer learning task applied to images and DNA barcodes to cluster featureembeddings obtained from self-supervised learning, to investigate whethermeaningful clusters can be derived from these representation embeddings. Third,we benchmark multi-modality by performing contrastive learning on DNA barcodes,image data, and taxonomic information. This yields a general shared embeddingspace enabling taxonomic classification using multiple types of information andmodalities. The code repository of the BIOSCAN-5M Insect dataset is availableat {\url{https://github.com/zahrag/BIOSCAN-5M}}</description><author>Zahra Gharaee, Scott C. Lowe, ZeMing Gong, Pablo Millan Arias, Nicholas Pellegrino, Austin T. Wang, Joakim Bruslund Haurum, Iuliia Zarubiieva, Lila Kari, Dirk Steinke, Graham W. Taylor, Paul Fieguth, Angel X. Chang</author><pubDate>Tue, 18 Jun 2024 16:45:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12723v1</guid></item><item><title>Estimating class separability of text embeddings with persistent homology</title><link>http://arxiv.org/abs/2305.15016v4</link><description>This paper introduces an unsupervised method to estimate the classseparability of text datasets from a topological point of view. Usingpersistent homology, we demonstrate how tracking the evolution of embeddingmanifolds during training can inform about class separability. Morespecifically, we show how this technique can be applied to detect when thetraining process stops improving the separability of the embeddings. Ourresults, validated across binary and multi-class text classification tasks,show that the proposed method's estimates of class separability align withthose obtained from supervised methods. This approach offers a novelperspective on monitoring and improving the fine-tuning of sentencetransformers for classification tasks, particularly in scenarios where labeleddata is scarce. We also discuss how tracking these quantities can provideadditional insights into the properties of the trained classifier.</description><author>Kostis Gourgoulias, Najah Ghalyan, Maxime Labonne, Yash Satsangi, Sean Moran, Joseph Sabelja</author><pubDate>Tue, 18 Jun 2024 16:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15016v4</guid></item><item><title>Lower Bounds on the Expressivity of Recurrent Neural Language Models</title><link>http://arxiv.org/abs/2405.19222v2</link><description>The recent successes and spread of large neural language models (LMs) callfor a thorough understanding of their computational ability. Describing theircomputational abilities through LMs' \emph{representational capacity} is alively area of research. However, investigation into the representationalcapacity of neural LMs has predominantly focused on their ability to\emph{recognize} formal languages. For example, recurrent neural networks(RNNs) with Heaviside activations are tightly linked to regular languages,i.e., languages defined by finite-state automata (FSAs). Such results, however,fall short of describing the capabilities of RNN \emph{language models} (LMs),which are definitionally \emph{distributions} over strings. We take a freshlook at the representational capacity of RNN LMs by connecting them to\emph{probabilistic} FSAs and demonstrate that RNN LMs with linearly boundedprecision can express arbitrary regular LMs.</description><author>Anej Svete, Franz Nowak, Anisha Mohamed Sahabdeen, Ryan Cotterell</author><pubDate>Tue, 18 Jun 2024 16:42:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19222v2</guid></item><item><title>On the Robustness of Language Models for Tabular Question Answering</title><link>http://arxiv.org/abs/2406.12719v1</link><description>Large Language Models (LLMs), originally shown to ace various textcomprehension tasks have also remarkably been shown to tackle tablecomprehension tasks without specific training. While previous research hasexplored LLM capabilities with tabular dataset tasks, our study assesses theinfluence of $\textit{in-context learning}$,$ \textit{model scale}$,$\textit{instruction tuning}$, and $\textit{domain biases}$ on Tabular QuestionAnswering (TQA). We evaluate the robustness of LLMs on Wikipedia-based$\textbf{WTQ}$ and financial report-based $\textbf{TAT-QA}$ TQA datasets,focusing on their ability to robustly interpret tabular data under variousaugmentations and perturbations. Our findings indicate that instructionssignificantly enhance performance, with recent models like Llama3 exhibitinggreater robustness over earlier versions. However, data contamination andpractical reliability issues persist, especially with WTQ. We highlight theneed for improved methodologies, including structure-aware self-attentionmechanisms and better handling of domain-specific tabular data, to develop morereliable LLMs for table comprehension.</description><author>Kushal Raj Bhandari, Sixue Xing, Soham Dan, Jianxi Gao</author><pubDate>Tue, 18 Jun 2024 16:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12719v1</guid></item><item><title>AGLA: Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention</title><link>http://arxiv.org/abs/2406.12718v1</link><description>Despite their great success across various multimodal tasks, LargeVision-Language Models (LVLMs) are facing a prevalent problem with objecthallucinations, where the generated textual responses are inconsistent withground-truth objects in the given image. This paper investigates various LVLMsand pinpoints attention deficiency toward discriminative local image featuresas one root cause of object hallucinations. Specifically, LVLMs predominantlyattend to prompt-independent global image features, while failing to captureprompt-relevant local features, consequently undermining the visual groundingcapacity of LVLMs and leading to hallucinations. To this end, we proposeAssembly of Global and Local Attention (AGLA), a training-free andplug-and-play approach that mitigates object hallucinations by exploring anensemble of global features for response generation and local features forvisual discrimination simultaneously. Our approach exhibits an image-promptmatching scheme that captures prompt-relevant local features from images,leading to an augmented view of the input image where prompt-relevant contentis reserved while irrelevant distractions are masked. With the augmented view,a calibrated decoding distribution can be derived by integrating generativeglobal features from the original image and discriminative local features fromthe augmented image. Extensive experiments show that AGLA consistentlymitigates object hallucinations and enhances general perception capability forLVLMs across various discriminative and generative benchmarks. Our code will bereleased at https://github.com/Lackel/AGLA.</description><author>Wenbin An, Feng Tian, Sicong Leng, Jiahao Nie, Haonan Lin, QianYing Wang, Guang Dai, Ping Chen, Shijian Lu</author><pubDate>Tue, 18 Jun 2024 16:38:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12718v1</guid></item><item><title>On Differentially Private Subspace Estimation in a Distribution-Free Setting</title><link>http://arxiv.org/abs/2402.06465v2</link><description>Private data analysis faces a significant challenge known as the curse ofdimensionality, leading to increased costs. However, many datasets possess aninherent low-dimensional structure. For instance, during optimization viagradient descent, the gradients frequently reside near a low-dimensionalsubspace. If the low-dimensional structure could be privately identified usinga small amount of points, we could avoid paying for the high ambient dimension. On the negative side, Dwork, Talwar, Thakurta, and Zhang (STOC 2014) provedthat privately estimating subspaces, in general, requires an amount of pointsthat has a polynomial dependency on the dimension. However, their bound do notrule out the possibility to reduce the number of points for "easy'' instances.Yet, providing a measure that captures how much a given dataset is "easy'' forthis task turns out to be challenging, and was not properly addressed in priorworks. Inspired by the work of Singhal and Steinke (NeurIPS 2021), we provide thefirst measures that quantify easiness as a function of multiplicativesingular-value gaps in the input dataset, and support them with new upper andlower bounds. In particular, our results determine the first type of gap thatis sufficient and necessary for estimating a subspace with an amount of pointsthat is independent of the dimension. Furthermore, we realize our upper boundsusing a practical algorithm and demonstrate its advantage in high-dimensionalregimes compared to prior approaches.</description><author>Eliad Tsfadia</author><pubDate>Tue, 18 Jun 2024 16:37:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06465v2</guid></item><item><title>MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in Generative LLMs</title><link>http://arxiv.org/abs/2406.07243v2</link><description>Generative large language models (LLMs) have been shown to exhibit harmfulbiases and stereotypes. While safety fine-tuning typically takes place inEnglish, if at all, these models are being used by speakers of many differentlanguages. There is existing evidence that the performance of these models isinconsistent across languages and that they discriminate based on demographicfactors of the user. Motivated by this, we investigate whether the socialstereotypes exhibited by LLMs differ as a function of the language used toprompt them, while controlling for cultural differences and task accuracy. Tothis end, we present MBBQ (Multilingual Bias Benchmark for Question-answering),a carefully curated version of the English BBQ dataset extended to Dutch,Spanish, and Turkish, which measures stereotypes commonly held across theselanguages. We further complement MBBQ with a parallel control dataset tomeasure task performance on the question-answering task independently of bias.Our results based on several open-source and proprietary LLMs confirm that somenon-English languages suffer from bias more than English, even when controllingfor cultural shifts. Moreover, we observe significant cross-lingual differencesin bias behaviour for all except the most accurate models. With the release ofMBBQ, we hope to encourage further research on bias in multilingual settings.The dataset and code are available at https://github.com/Veranep/MBBQ.</description><author>Vera Neplenbroek, Arianna Bisazza, Raquel Fernández</author><pubDate>Tue, 18 Jun 2024 16:33:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07243v2</guid></item><item><title>Capturing Knowledge Graphs and Rules with Octagon Embeddings</title><link>http://arxiv.org/abs/2401.16270v2</link><description>Region based knowledge graph embeddings represent relations as geometricregions. This has the advantage that the rules which are captured by the modelare made explicit, making it straightforward to incorporate prior knowledge andto inspect learned models. Unfortunately, existing approaches are severelyrestricted in their ability to model relational composition, and hence alsotheir ability to model rules, thus failing to deliver on the main promise ofregion based models. With the aim of addressing these limitations, weinvestigate regions which are composed of axis-aligned octagons. Such octagonsare particularly easy to work with, as intersections and compositions can bestraightforwardly computed, while they are still sufficiently expressive tomodel arbitrary knowledge graphs. Among others, we also show that our octagonembeddings can properly capture a non-trivial class of rule bases. Finally, weshow that our model achieves competitive experimental results.</description><author>Victor Charpenay, Steven Schockaert</author><pubDate>Tue, 18 Jun 2024 16:29:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16270v2</guid></item><item><title>Learning Useful Representations of Recurrent Neural Network Weight Matrices</title><link>http://arxiv.org/abs/2403.11998v2</link><description>Recurrent Neural Networks (RNNs) are general-purpose parallel-sequentialcomputers. The program of an RNN is its weight matrix. How to learn usefulrepresentations of RNN weights that facilitate RNN analysis as well asdownstream tasks? While the mechanistic approach directly looks at some RNN'sweights to predict its behavior, the functionalist approach analyzes itsoverall functionality-specifically, its input-output mapping. We considerseveral mechanistic approaches for RNN weights and adapt the permutationequivariant Deep Weight Space layer for RNNs. Our two novel functionalistapproaches extract information from RNN weights by 'interrogating' the RNNthrough probing inputs. We develop a theoretical framework that demonstratesconditions under which the functionalist approach can generate richrepresentations that help determine RNN behavior. We release the first two'model zoo' datasets for RNN weight representation learning. One consists ofgenerative models of a class of formal languages, and the other one ofclassifiers of sequentially processed MNIST digits.With the help of anemulation-based self-supervised learning technique we compare and evaluate thedifferent RNN weight encoding techniques on multiple downstream applications.On the most challenging one, namely predicting which exact task the RNN wastrained on, functionalist approaches show clear superiority.</description><author>Vincent Herrmann, Francesco Faccio, Jürgen Schmidhuber</author><pubDate>Tue, 18 Jun 2024 16:27:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11998v2</guid></item><item><title>Self-Localized Collaborative Perception</title><link>http://arxiv.org/abs/2406.12712v1</link><description>Collaborative perception has garnered considerable attention due to itscapacity to address several inherent challenges in single-agent perception,including occlusion and out-of-range issues. However, existing collaborativeperception systems heavily rely on precise localization systems to establish aconsistent spatial coordinate system between agents. This reliance makes themsusceptible to large pose errors or malicious attacks, resulting in substantialreductions in perception performance. To address this, wepropose~$\mathtt{CoBEVGlue}$, a novel self-localized collaborative perceptionsystem, which achieves more holistic and robust collaboration without using anexternal localization system. The core of~$\mathtt{CoBEVGlue}$ is a novelspatial alignment module, which provides the relative poses between agents byeffectively matching co-visible objects across agents. We validate our methodon both real-world and simulated datasets. The results show that i)$\mathtt{CoBEVGlue}$ achieves state-of-the-art detection performance underarbitrary localization noises and attacks; and ii) the spatial alignment modulecan seamlessly integrate with a majority of previous methods, enhancing theirperformance by an average of $57.7\%$. Code is available athttps://github.com/VincentNi0107/CoBEVGlue</description><author>Zhenyang Ni, Zixing Lei, Yifan Lu, Dingju Wang, Chen Feng, Yanfeng Wang, Siheng Chen</author><pubDate>Tue, 18 Jun 2024 16:26:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12712v1</guid></item><item><title>Hypergraph: A Unified and Uniform Definition with Application to Chemical Hypergraph</title><link>http://arxiv.org/abs/2405.12235v4</link><description>The conventional definition of hypergraph has two major issues: (1) there isnot a standard definition of directed hypergraph and (2) there is not a formaldefinition of nested hypergraph. To resolve these issues, we propose a newdefinition of hypergraph that unifies the concepts of undirected, directed andnested hypergraphs, and that is uniform in using hyperedge as a singleconstruct for representing high-order correlations among things, i.e., nodesand hyperedges. Specifically, we define a hyperedge to be a simple hyperedge, anesting hyperedge, or a directed hyperedge. With this new definition, ahypergraph is nested if it has nesting hyperedge(s), and is directed if it hasdirected hyperedge(s). Otherwise, a hypergraph is a simple hypergraph. Theuniformity and power of this new definition, with visualization, shouldfacilitate the use of hypergraph for representing (hierarchical) high-ordercorrelations in general and chemical systems in particular. Graph has beenwidely used as a mathematical structure for machine learning on molecularstructures and 3D molecular geometries. However, graph has a major limitation:it can represent only pairwise correlations between nodes. Hypergraph extendsgraph with high-order correlations among nodes. This extension is significantor essential for machine learning on chemical systems. For molecules, this issignificant as it allows the direct, explicit representation of multicenterbonds and molecular substructures. For chemical reactions, this is essentialsince most chemical reactions involve multiple participants. We propose the useof chemical hypergraph, a multilevel hypergraph with simple, nesting anddirected hyperedges, as a single mathematical structure for representingchemical systems. We apply the new definition of hypergraph to chemicalhypergraph and, as simplified versions, molecular hypergraph and chemicalreaction hypergraph.</description><author>Daniel T. Chang</author><pubDate>Tue, 18 Jun 2024 16:25:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.12235v4</guid></item><item><title>Enhancing Spatio-temporal Quantile Forecasting with Curriculum Learning: Lessons Learned</title><link>http://arxiv.org/abs/2406.12709v1</link><description>Training models on spatio-temporal (ST) data poses an open problem due to thecomplicated and diverse nature of the data itself, and it is challenging toensure the model's performance directly trained on the original ST data. Whilelimiting the variety of training data can make training easier, it can alsolead to a lack of knowledge and information for the model, resulting in adecrease in performance. To address this challenge, we presented an innovativeparadigm that incorporates three separate forms of curriculum learningspecifically targeting from spatial, temporal, and quantile perspectives.Furthermore, our framework incorporates a stacking fusion module to combinediverse information from three types of curriculum learning, resulting in astrong and thorough learning process. We demonstrated the effectiveness of thisframework with extensive empirical evaluations, highlighting its betterperformance in addressing complex ST challenges. We provided thorough ablationstudies to investigate the effectiveness of our curriculum and to explain howit contributes to the improvement of learning efficiency on ST data.</description><author>Du Yin, Jinliang Deng, Shuang Ao, Zechen Li, Hao Xue, Arian Prabowo, Renhe Jiang, Xuan Song, Flora Salim</author><pubDate>Tue, 18 Jun 2024 16:23:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12709v1</guid></item><item><title>AgentReview: Exploring Peer Review Dynamics with LLM Agents</title><link>http://arxiv.org/abs/2406.12708v1</link><description>Peer review is fundamental to the integrity and advancement of scientificpublication. Traditional methods of peer review analyses often rely onexploration and statistics of existing peer review data, which do notadequately address the multivariate nature of the process, account for thelatent variables, and are further constrained by privacy concerns due to thesensitive nature of the data. We introduce AgentReview, the first largelanguage model (LLM) based peer review simulation framework, which effectivelydisentangles the impacts of multiple latent factors and addresses the privacyissue. Our study reveals significant insights, including a notable 37.1%variation in paper decisions due to reviewers' biases, supported bysociological theories such as the social influence theory, altruism fatigue,and authority bias. We believe that this study could offer valuable insights toimprove the design of peer review mechanisms.</description><author>Yiqiao Jin, Qinlin Zhao, Yiyang Wang, Hao Chen, Kaijie Zhu, Yijia Xiao, Jindong Wang</author><pubDate>Tue, 18 Jun 2024 16:22:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12708v1</guid></item><item><title>Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction</title><link>http://arxiv.org/abs/2406.12707v1</link><description>Large Language Model (LLM)-enhanced agents become increasingly prevalent inHuman-AI communication, offering vast potential from entertainment toprofessional domains. However, current multi-modal dialogue systems overlookthe acoustic information present in speech, which is crucial for understandinghuman communication nuances. This oversight can lead to misinterpretations ofspeakers' intentions, resulting in inconsistent or even contradictory responseswithin dialogues. To bridge this gap, in this paper, we proposePerceptiveAgent, an empathetic multi-modal dialogue system designed to discerndeeper or more subtle meanings beyond the literal interpretations of wordsthrough the integration of speech modality perception. Employing LLMs as acognitive core, PerceptiveAgent perceives acoustic information from inputspeech and generates empathetic responses based on speaking styles described innatural language. Experimental results indicate that PerceptiveAgent excels incontextual understanding by accurately discerning the speakers' true intentionsin scenarios where the linguistic meaning is either contrary to or inconsistentwith the speaker's true feelings, producing more nuanced and expressive spokendialogues. Code is publicly available at:\url{https://github.com/Haoqiu-Yan/PerceptiveAgent}.</description><author>Haoqiu Yan, Yongxin Zhu, Kai Zheng, Bing Liu, Haoyu Cao, Deqiang Jiang, Linli Xu</author><pubDate>Tue, 18 Jun 2024 16:19:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12707v1</guid></item><item><title>Coarse-Fine Spectral-Aware Deformable Convolution For Hyperspectral Image Reconstruction</title><link>http://arxiv.org/abs/2406.12703v1</link><description>We study the inverse problem of Coded Aperture Snapshot Spectral Imaging(CASSI), which captures a spatial-spectral data cube using snapshot 2Dmeasurements and uses algorithms to reconstruct 3D hyperspectral images (HSI).However, current methods based on Convolutional Neural Networks (CNNs) struggleto capture long-range dependencies and non-local similarities. The recentlypopular Transformer-based methods are poorly deployed on downstream tasks dueto the high computational cost caused by self-attention. In this paper, wepropose Coarse-Fine Spectral-Aware Deformable Convolution Network (CFSDCN),applying deformable convolutional networks (DCN) to this task for the firsttime. Considering the sparsity of HSI, we design a deformable convolutionmodule that exploits its deformability to capture long-range dependencies andnon-local similarities. In addition, we propose a new spectral informationinteraction module that considers both coarse-grained and fine-grained spectralsimilarities. Extensive experiments demonstrate that our CFSDCN significantlyoutperforms previous state-of-the-art (SOTA) methods on both simulated and realHSI datasets.</description><author>Jincheng Yang, Lishun Wang, Miao Cao, Huan Wang, Yinping Zhao, Xin Yuan</author><pubDate>Tue, 18 Jun 2024 16:15:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12703v1</guid></item><item><title>BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language Models</title><link>http://arxiv.org/abs/2406.11675v2</link><description>Large Language Models (LLMs) often suffer from overconfidence duringinference, particularly when adapted to downstream domain-specific tasks withlimited data. Previous work addresses this issue by employing approximateBayesian estimation after the LLMs are trained, enabling them to quantifyuncertainty. However, such post-training approaches' performance is severelylimited by the parameters learned during training. In this paper, we go beyondpost-training Bayesianization and propose Bayesian Low-Rank Adaptation byBackpropagation (BLoB), an algorithm that continuously and jointly adjusts boththe mean and covariance of LLM parameters throughout the whole fine-tuningprocess. Our empirical results verify the effectiveness of BLoB in terms ofgeneralization and uncertainty estimation, when evaluated on bothin-distribution and out-of-distribution data.</description><author>Yibin Wang, Haizhou Shi, Ligong Han, Dimitris Metaxas, Hao Wang</author><pubDate>Tue, 18 Jun 2024 16:15:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11675v2</guid></item><item><title>Jailbreak Paradox: The Achilles' Heel of LLMs</title><link>http://arxiv.org/abs/2406.12702v1</link><description>We introduce two paradoxes concerning jailbreak of foundation models: First,it is impossible to construct a perfect jailbreak classifier, and second, aweaker model cannot consistently detect whether a stronger (in apareto-dominant sense) model is jailbroken or not. We provide formal proofs forthese paradoxes and a short case study on Llama and GPT4-o to demonstrate this.We discuss broader theoretical and practical repercussions of these results.</description><author>Abhinav Rao, Monojit Choudhury, Somak Aditya</author><pubDate>Tue, 18 Jun 2024 16:14:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12702v1</guid></item><item><title>On Efficiently Representing Regular Languages as RNNs</title><link>http://arxiv.org/abs/2402.15814v2</link><description>Recent work by Hewitt et al. (2020) provides an interpretation of theempirical success of recurrent neural networks (RNNs) as language models (LMs).It shows that RNNs can efficiently represent bounded hierarchical structuresthat are prevalent in human language. This suggests that RNNs' success might belinked to their ability to model hierarchy. However, a closer inspection ofHewitt et al.'s (2020) construction shows that it is not inherently limited tohierarchical structures. This poses a natural question: What other classes ofLMs can RNNs efficiently represent? To this end, we generalize Hewitt et al.'s(2020) construction and show that RNNs can efficiently represent a larger classof LMs than previously claimed -- specifically, those that can be representedby a pushdown automaton with a bounded stack and a specific stack updatefunction. Altogether, the efficiency of representing this diverse class of LMswith RNN LMs suggests novel interpretations of their inductive bias.</description><author>Anej Svete, Robin Shing Moon Chan, Ryan Cotterell</author><pubDate>Tue, 18 Jun 2024 16:14:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15814v2</guid></item><item><title>SUPER: Selfie Undistortion and Head Pose Editing with Identity Preservation</title><link>http://arxiv.org/abs/2406.12700v1</link><description>Self-portraits captured from a short distance might look unnatural or evenunattractive due to heavy distortions making facial features malformed, andill-placed head poses. In this paper, we propose SUPER, a novel method ofeliminating distortions and adjusting head pose in a close-up face crop. Weperform 3D GAN inversion for a facial image by optimizing camera parameters andface latent code, which gives a generated image. Besides, we estimate depthfrom the obtained latent code, create a depth-induced 3D mesh, and render itwith updated camera parameters to obtain a warped portrait. Finally, we applythe visibility-based blending so that visible regions are reprojected, andoccluded parts are restored with a generative model. Experiments on faceundistortion benchmarks and on our self-collected Head Rotation dataset (HeRo),show that SUPER outperforms previous approaches both qualitatively andquantitatively, opening new possibilities for photorealistic selfie editing.</description><author>Polina Karpikova, Andrei Spiridonov, Anna Vorontsova, Anastasia Yaschenko, Ekaterina Radionova, Igor Medvedev, Alexander Limonov</author><pubDate>Tue, 18 Jun 2024 16:14:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12700v1</guid></item><item><title>LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation</title><link>http://arxiv.org/abs/2402.07721v2</link><description>Low-Rank Adaptation (LoRA) is currently the most commonly usedParameter-efficient fine-tuning (PEFT) method, it introduces auxiliaryparameters for each layer to fine-tune the pre-trained model under limitedcomputing resources. However, it still faces resource consumption challengesduring training when scaling up to larger models. Most previous studies havetackled this issue by using pruning techniques, which involve removing LoRAparameters deemed unimportant. Nonetheless, these efforts only analyze LoRAparameter features to evaluate their importance, such as parameter count, size,and gradient. In fact, the output of LoRA (product of LoRA parameter and hiddenstate), directly impacts the final results. Preliminary experiments indicatethat a fraction of LoRA elements possesses significantly high output values,substantially influencing the layer output. Motivated by the observation, wepropose LoRA-drop. Concretely, LoRA-drop evaluates the importance of LoRA basedon the LoRA output. Then we retain LoRA for important layers and the otherlayers share the same LoRA. We conduct abundant experiments with models ofdifferent scales on NLU and NLG tasks. Results demonstrate that LoRA-drop canachieve performance comparable to full fine-tuning and LoRA, while retaining50\% of the LoRA parameters on average.</description><author>Hongyun Zhou, Xiangyu Lu, Wang Xu, Conghui Zhu, Tiejun Zhao, Muyun Yang</author><pubDate>Tue, 18 Jun 2024 16:13:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07721v2</guid></item><item><title>Online-Adaptive Anomaly Detection for Defect Identification in Aircraft Assembly</title><link>http://arxiv.org/abs/2406.12698v1</link><description>Anomaly detection deals with detecting deviations from established patternswithin data. It has various applications like autonomous driving, predictivemaintenance, and medical diagnosis. To improve anomaly detection accuracy,transfer learning can be applied to large, pre-trained models and adapt them tothe specific application context. In this paper, we propose a novel frameworkfor online-adaptive anomaly detection using transfer learning. The approachadapts to different environments by selecting visually similar training imagesand online fitting a normality model to EfficientNet features extracted fromthe training subset. Anomaly detection is then performed by computing theMahalanobis distance between the normality model and the test image features.Different similarity measures (SIFT/FLANN, Cosine) and normality models (MVG,OCSVM) are employed and compared with each other. We evaluate the approach ondifferent anomaly detection benchmarks and data collected in controlledlaboratory settings. Experimental results showcase a detection accuracyexceeding 0.975, outperforming the state-of-the-art ET-NET approach.</description><author>Siddhant Shete, Dennis Mronga, Ankita Jadhav, Frank Kirchner</author><pubDate>Tue, 18 Jun 2024 16:11:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12698v1</guid></item></channel></rss>