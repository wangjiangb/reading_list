<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 09 Oct 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>BrainSCUBA: Fine-Grained Natural Language Captions of Visual Cortex Selectivity</title><link>http://arxiv.org/abs/2310.04420v1</link><description>Understanding the functional organization of higher visual cortex is acentral focus in neuroscience. Past studies have primarily mapped the visualand semantic selectivity of neural populations using hand-selected stimuli,which may potentially bias results towards pre-existing hypotheses of visualcortex functionality. Moving beyond conventional approaches, we introduce adata-driven method that generates natural language descriptions for imagespredicted to maximally activate individual voxels of interest. Our method --Semantic Captioning Using Brain Alignments ("BrainSCUBA") -- builds upon therich embedding space learned by a contrastive vision-language model andutilizes a pre-trained large language model to generate interpretable captions.We validate our method through fine-grained voxel-level captioning acrosshigher-order visual regions. We further perform text-conditioned imagesynthesis with the captions, and show that our images are semantically coherentand yield high predicted activations. Finally, to demonstrate how our methodenables scientific discovery, we perform exploratory investigations on thedistribution of "person" representations in the brain, and discoverfine-grained semantic selectivity in body-selective areas. Unlike earlierstudies that decode text, our method derives voxel-wise captions of semanticselectivity. Our results show that BrainSCUBA is a promising means forunderstanding functional preferences in the brain, and provides motivation forfurther hypothesis-driven investigation of visual cortex.</description><author>Andrew F. Luo, Margaret M. Henderson, Michael J. Tarr, Leila Wehbe</author><pubDate>Fri, 06 Oct 2023 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04420v1</guid></item><item><title>Learning Personalized Story Evaluation</title><link>http://arxiv.org/abs/2310.03304v2</link><description>While large language models (LLMs) have shown impressive results for moreobjective tasks such as QA and retrieval, it remains nontrivial to evaluatetheir performance on open-ended text generation for reasons including (1) datacontamination; (2) multi-dimensional evaluation criteria; and (3)subjectiveness stemming from reviewers' personal preferences. To address suchissues, we propose to model personalization in an uncontaminated open-endedgeneration assessment. We create two new datasets Per-MPST and Per-DOC forpersonalized story evaluation, by re-purposing existing datasets with properanonymization and new personalized labels. We further develop a personalizedstory evaluation model PERSE to infer reviewer preferences and provide apersonalized evaluation. Specifically, given a few exemplary reviews from aparticular reviewer, PERSE predicts either a detailed review or fine-grainedcomparison in several aspects (such as interestingness and surprise) for thatreviewer on a new text input. Experimental results show that PERSE outperformsGPT-4 by 15.8% on Kendall correlation of story ratings, and by 13.7% onpairwise preference prediction accuracy. Both datasets and code will bereleased at https://github.com/dqwang122/PerSE.</description><author>Danqing Wang, Kevin Yang, Hanlin Zhu, Xiaomeng Yang, Andrew Cohen, Lei Li, Yuandong Tian</author><pubDate>Fri, 06 Oct 2023 18:59:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03304v2</guid></item><item><title>Functional Interpolation for Relative Positions Improves Long Context Transformers</title><link>http://arxiv.org/abs/2310.04418v1</link><description>Preventing the performance decay of Transformers on inputs longer than thoseused for training has been an important challenge in extending the contextlength of these models. Though the Transformer architecture has fundamentallyno limits on the input sequence lengths it can process, the choice of positionencoding used during training can limit the performance of these models onlonger inputs. We propose a novel functional relative position encoding withprogressive interpolation, FIRE, to improve Transformer generalization tolonger contexts. We theoretically prove that this can represent some of thepopular relative position encodings, such as T5's RPE, Alibi, and Kerple. Wenext empirically show that FIRE models have better generalization to longercontexts on both zero-shot language modeling and long text benchmarks.</description><author>Shanda Li, Chong You, Guru Guruganesh, Joshua Ainslie, Santiago Ontanon, Manzil Zaheer, Sumit Sanghai, Yiming Yang, Sanjiv Kumar, Srinadh Bhojanapalli</author><pubDate>Fri, 06 Oct 2023 18:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04418v1</guid></item><item><title>Diffusion Random Feature Model</title><link>http://arxiv.org/abs/2310.04417v1</link><description>Diffusion probabilistic models have been successfully used to generate datafrom noise. However, most diffusion models are computationally expensive anddifficult to interpret with a lack of theoretical justification. Random featuremodels on the other hand have gained popularity due to their interpretabilitybut their application to complex machine learning tasks remains limited. Inthis work, we present a diffusion model-inspired deep random feature model thatis interpretable and gives comparable numerical results to a fully connectedneural network having the same number of trainable parameters. Specifically, weextend existing results for random features and derive generalization boundsbetween the distribution of sampled data and the true distribution usingproperties of score matching. We validate our findings by generating samples onthe fashion MNIST dataset and instrumental audio data.</description><author>Esha Saha, Giang Tran</author><pubDate>Fri, 06 Oct 2023 18:59:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04417v1</guid></item><item><title>Alice Benchmarks: Connecting Real World Object Re-Identification with the Synthetic</title><link>http://arxiv.org/abs/2310.04416v1</link><description>For object re-identification (re-ID), learning from synthetic data has becomea promising strategy to cheaply acquire large-scale annotated datasets andeffective models, with few privacy concerns. Many interesting research problemsarise from this strategy, e.g., how to reduce the domain gap between syntheticsource and real-world target. To facilitate developing more new approaches inlearning from synthetic data, we introduce the Alice benchmarks, large-scaledatasets providing benchmarks as well as evaluation protocols to the researchcommunity. Within the Alice benchmarks, two object re-ID tasks are offered:person and vehicle re-ID. We collected and annotated two challenging real-worldtarget datasets: AlicePerson and AliceVehicle, captured under variousilluminations, image resolutions, etc. As an important feature of our realtarget, the clusterability of its training set is not manually guaranteed tomake it closer to a real domain adaptation test scenario. Correspondingly, wereuse existing PersonX and VehicleX as synthetic source domains. The primarygoal is to train models from synthetic data that can work effectively in thereal world. In this paper, we detail the settings of Alice benchmarks, providean analysis of existing commonly-used domain adaptation methods, and discusssome interesting future directions. An online server will be set up for thecommunity to evaluate methods conveniently and fairly.</description><author>Xiaoxiao Sun, Yue Yao, Shengjin Wang, Hongdong Li, Liang Zheng</author><pubDate>Fri, 06 Oct 2023 18:58:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04416v1</guid></item><item><title>Why Do We Need Weight Decay in Modern Deep Learning?</title><link>http://arxiv.org/abs/2310.04415v1</link><description>Weight decay is a broadly used technique for training state-of-the-art deepnetworks, including large language models. Despite its widespread usage, itsrole remains poorly understood. In this work, we highlight that the role ofweight decay in modern deep learning is different from its regularizationeffect studied in classical learning theory. For overparameterized deepnetworks, we show how weight decay modifies the optimization dynamics enhancingthe ever-present implicit regularization of SGD via the loss stabilizationmechanism. In contrast, for underparameterized large language models trainedwith nearly online SGD, we describe how weight decay balances the bias-variancetradeoff in stochastic optimization leading to lower training loss. Moreover,we show that weight decay also prevents sudden loss divergences for bfloat16mixed-precision training which is a crucial tool for LLM training. Overall, wepresent a unifying perspective from ResNets on vision tasks to LLMs: weightdecay is never useful as an explicit regularizer but instead changes thetraining dynamics in a desirable way. Our code is available athttps://github.com/tml-epfl/why-weight-decay.</description><author>Maksym Andriushchenko, Francesco D'Angelo, Aditya Varre, Nicolas Flammarion</author><pubDate>Fri, 06 Oct 2023 18:58:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04415v1</guid></item><item><title>CIFAR-10-Warehouse: Broad and More Realistic Testbeds in Model Generalization Analysis</title><link>http://arxiv.org/abs/2310.04414v1</link><description>Analyzing model performance in various unseen environments is a criticalresearch problem in the machine learning community. To study this problem, itis important to construct a testbed with out-of-distribution test sets thathave broad coverage of environmental discrepancies. However, existing testbedstypically either have a small number of domains or are synthesized by imagecorruptions, hindering algorithm design that demonstrates real-worldeffectiveness. In this paper, we introduce CIFAR-10-Warehouse, consisting of180 datasets collected by prompting image search engines and diffusion modelsin various ways. Generally sized between 300 and 8,000 images, the datasetscontain natural images, cartoons, certain colors, or objects that do notnaturally appear. With CIFAR-10-W, we aim to enhance the evaluation and deepenthe understanding of two generalization tasks: domain generalization and modelaccuracy prediction in various out-of-distribution environments. We conductextensive benchmarking and comparison experiments and show that CIFAR-10-Woffers new and interesting insights inherent to these tasks. We also discussother fields that would benefit from CIFAR-10-W.</description><author>Xiaoxiao Sun, Xingjian Leng, Zijian Wang, Yang Yang, Zi Huang, Liang Zheng</author><pubDate>Fri, 06 Oct 2023 18:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04414v1</guid></item><item><title>Beyond Uniform Sampling: Offline Reinforcement Learning with Imbalanced Datasets</title><link>http://arxiv.org/abs/2310.04413v1</link><description>Offline policy learning is aimed at learning decision-making policies usingexisting datasets of trajectories without collecting additional data. Theprimary motivation for using reinforcement learning (RL) instead of supervisedlearning techniques such as behavior cloning is to find a policy that achievesa higher average return than the trajectories constituting the dataset.However, we empirically find that when a dataset is dominated by suboptimaltrajectories, state-of-the-art offline RL algorithms do not substantiallyimprove over the average return of trajectories in the dataset. We argue thisis due to an assumption made by current offline RL algorithms of staying closeto the trajectories in the dataset. If the dataset primarily consists ofsub-optimal trajectories, this assumption forces the policy to mimic thesuboptimal actions. We overcome this issue by proposing a sampling strategythat enables the policy to only be constrained to ``good data" rather than allactions in the dataset (i.e., uniform sampling). We present a realization ofthe sampling strategy and an algorithm that can be used as a plug-and-playmodule in standard offline RL algorithms. Our evaluation demonstratessignificant performance gains in 72 imbalanced datasets, D4RL dataset, andacross three different offline RL algorithms. Code is available athttps://github.com/Improbable-AI/dw-offline-rl.</description><author>Zhang-Wei Hong, Aviral Kumar, Sathwik Karnik, Abhishek Bhandwaldar, Akash Srivastava, Joni Pajarinen, Romain Laroche, Abhishek Gupta, Pulkit Agrawal</author><pubDate>Fri, 06 Oct 2023 18:58:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04413v1</guid></item><item><title>FedConv: Enhancing Convolutional Neural Networks for Handling Data Heterogeneity in Federated Learning</title><link>http://arxiv.org/abs/2310.04412v1</link><description>Federated learning (FL) is an emerging paradigm in machine learning, where ashared model is collaboratively learned using data from multiple devices tomitigate the risk of data leakage. While recent studies posit that VisionTransformer (ViT) outperforms Convolutional Neural Networks (CNNs) inaddressing data heterogeneity in FL, the specific architectural components thatunderpin this advantage have yet to be elucidated. In this paper, wesystematically investigate the impact of different architectural elements, suchas activation functions and normalization layers, on the performance withinheterogeneous FL. Through rigorous empirical analyses, we are able to offer thefirst-of-its-kind general guidance on micro-architecture design principles forheterogeneous FL. Intriguingly, our findings indicate that with strategic architecturalmodifications, pure CNNs can achieve a level of robustness that either matchesor even exceeds that of ViTs when handling heterogeneous data clients in FL.Additionally, our approach is compatible with existing FL techniques anddelivers state-of-the-art solutions across a broad spectrum of FL benchmarks.The code is publicly available at https://github.com/UCSC-VLAA/FedConv</description><author>Peiran Xu, Zeyu Wang, Jieru Mei, Liangqiong Qu, Alan Yuille, Cihang Xie, Yuyin Zhou</author><pubDate>Fri, 06 Oct 2023 18:57:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04412v1</guid></item><item><title>Understanding, Predicting and Better Resolving Q-Value Divergence in Offline-RL</title><link>http://arxiv.org/abs/2310.04411v1</link><description>The divergence of the Q-value estimation has been a prominent issue inoffline RL, where the agent has no access to real dynamics. Traditional beliefsattribute this instability to querying out-of-distribution actions whenbootstrapping value targets. Though this issue can be alleviated with policyconstraints or conservative Q estimation, a theoretical understanding of theunderlying mechanism causing the divergence has been absent. In this work, weaim to thoroughly comprehend this mechanism and attain an improved solution. Wefirst identify a fundamental pattern, self-excitation, as the primary cause ofQ-value estimation divergence in offline RL. Then, we propose a novelSelf-Excite Eigenvalue Measure (SEEM) metric based on Neural Tangent Kernel(NTK) to measure the evolving property of Q-network at training, which providesan intriguing explanation of the emergence of divergence. For the first time,our theory can reliably decide whether the training will diverge at an earlystage, and even predict the order of the growth for the estimated Q-value, themodel's norm, and the crashing step when an SGD optimizer is used. Theexperiments demonstrate perfect alignment with this theoretic analysis.Building on our insights, we propose to resolve divergence from a novelperspective, namely improving the model's architecture for better extrapolatingbehavior. Through extensive empirical studies, we identify LayerNorm as a goodsolution to effectively avoid divergence without introducing detrimental bias,leading to superior performance. Experimental results prove that it can stillwork in some most challenging settings, i.e. using only 1 transitions of thedataset, where all previous methods fail. Moreover, it can be easily pluggedinto modern offline RL methods and achieve SOTA results on many challengingtasks. We also give unique insights into its effectiveness.</description><author>Yang Yue, Rui Lu, Bingyi Kang, Shiji Song, Gao Huang</author><pubDate>Fri, 06 Oct 2023 18:57:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04411v1</guid></item><item><title>RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation</title><link>http://arxiv.org/abs/2310.04408v1</link><description>Retrieving documents and prepending them in-context at inference timeimproves performance of language model (LMs) on a wide range of tasks. However,these documents, often spanning hundreds of words, make inference substantiallymore expensive. We propose compressing the retrieved documents into textualsummaries prior to in-context integration. This not only reduces thecomputational costs but also relieves the burden of LMs to identify relevantinformation in long retrieved documents. We present two compressors -- anextractive compressor which selects useful sentences from retrieved documentsand an abstractive compressor which generates summaries by synthesizinginformation from multiple documents. Both compressors are trained to improveLMs' performance on end tasks when the generated summaries are prepended to theLMs' input, while keeping the summary concise.If the retrieved documents areirrelevant to the input or offer no additional information to LM, ourcompressor can return an empty string, implementing selective augmentation.Weevaluate our approach on language modeling task and open domain questionanswering task. We achieve a compression rate of as low as 6% with minimal lossin performance for both tasks, significantly outperforming the off-the-shelfsummarization models. We show that our compressors trained for one LM cantransfer to other LMs on the language modeling task and provide summarieslargely faithful to the retrieved documents.</description><author>Fangyuan Xu, Weijia Shi, Eunsol Choi</author><pubDate>Fri, 06 Oct 2023 18:55:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04408v1</guid></item><item><title>Policy-Gradient Training of Language Models for Ranking</title><link>http://arxiv.org/abs/2310.04407v1</link><description>Text retrieval plays a crucial role in incorporating factual knowledge fordecision making into language processing pipelines, ranging from chat-based websearch to question answering systems. Current state-of-the-art text retrievalmodels leverage pre-trained large language models (LLMs) to achieve competitiveperformance, but training LLM-based retrievers via typical contrastive lossesrequires intricate heuristics, including selecting hard negatives and usingadditional supervision as learning signals. This reliance on heuristics stemsfrom the fact that the contrastive loss itself is heuristic and does notdirectly optimize the downstream metrics of decision quality at the end of theprocessing pipeline. To address this issue, we introduce Neural PG-RANK, anovel training algorithm that learns to rank by instantiating a LLM as aPlackett-Luce ranking policy. Neural PG-RANK provides a principled method forend-to-end training of retrieval models as part of larger decision systems viapolicy gradient, with little reliance on complex heuristics, and it effectivelyunifies the training objective with downstream decision-making quality. Weconduct extensive experiments on various text retrieval benchmarks. The resultsdemonstrate that when the training objective aligns with the evaluation setup,Neural PG-RANK yields remarkable in-domain performance improvement, withsubstantial out-of-domain generalization to some critical datasets employed indownstream question answering tasks.</description><author>Ge Gao, Jonathan D. Chang, Claire Cardie, Kianté Brantley, Thorsten Joachim</author><pubDate>Fri, 06 Oct 2023 18:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04407v1</guid></item><item><title>Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models</title><link>http://arxiv.org/abs/2310.04406v1</link><description>While large language models (LLMs) have demonstrated impressive performanceon a range of decision-making tasks, they rely on simple acting processes andfall short of broad deployment as autonomous agents. We introduce LATS(Language Agent Tree Search), a general framework that synergizes thecapabilities of LLMs in planning, acting, and reasoning. Drawing inspirationfrom Monte Carlo tree search in model-based reinforcement learning, LATSemploys LLMs as agents, value functions, and optimizers, repurposing theirlatent strengths for enhanced decision-making. What is crucial in this methodis the use of an environment for external feedback, which offers a moredeliberate and adaptive problem-solving mechanism that moves beyond thelimitations of existing techniques. Our experimental evaluation across diversedomains, such as programming, HotPotQA, and WebShop, illustrates theapplicability of LATS for both reasoning and acting. In particular, LATSachieves 94.4\% for programming on HumanEval with GPT-4 and an average score of75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectivenessand generality of our method.</description><author>Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, Yu-Xiong Wang</author><pubDate>Fri, 06 Oct 2023 18:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04406v1</guid></item><item><title>Channel Vision Transformers: An Image Is Worth C x 16 x 16 Words</title><link>http://arxiv.org/abs/2309.16108v2</link><description>Vision Transformer (ViT) has emerged as a powerful architecture in the realmof modern computer vision. However, its application in certain imaging fields,such as microscopy and satellite imaging, presents unique challenges. In thesedomains, images often contain multiple channels, each carrying semanticallydistinct and independent information. Furthermore, the model must demonstraterobustness to sparsity in input channels, as they may not be densely availableduring training or testing. In this paper, we propose a modification to the ViTarchitecture that enhances reasoning across the input channels and introduceHierarchical Channel Sampling (HCS) as an additional regularization techniqueto ensure robustness when only partial channels are presented during test time.Our proposed model, ChannelViT, constructs patch tokens independently from eachinput channel and utilizes a learnable channel embedding that is added to thepatch tokens, similar to positional embeddings. We evaluate the performance ofChannelViT on ImageNet, JUMP-CP (microscopy cell imaging), and So2Sat(satellite imaging). Our results show that ChannelViT outperforms ViT onclassification tasks and generalizes well, even when a subset of input channelsis used during testing. Across our experiments, HCS proves to be a powerfulregularizer, independent of the architecture employed, suggesting itself as astraightforward technique for robust ViT training. Lastly, we find thatChannelViT generalizes effectively even when there is limited access to allchannels during training, highlighting its potential for multi-channel imagingunder real-world conditions with sparse sensors.</description><author>Yujia Bao, Srinivasan Sivanandan, Theofanis Karaletsos</author><pubDate>Fri, 06 Oct 2023 18:52:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16108v2</guid></item><item><title>On the Embedding Collapse when Scaling up Recommendation Models</title><link>http://arxiv.org/abs/2310.04400v1</link><description>Recent advances in deep foundation models have led to a promising trend ofdeveloping large recommendation models to leverage vast amounts of availabledata. However, we experiment to scale up existing recommendation models andobserve that the enlarged models do not improve satisfactorily. In thiscontext, we investigate the embedding layers of enlarged models and identify aphenomenon of embedding collapse, which ultimately hinders scalability, whereinthe embedding matrix tends to reside in a low-dimensional subspace. Throughempirical and theoretical analysis, we demonstrate that the feature interactionmodule specific to recommendation models has a two-sided effect. On the onehand, the interaction restricts embedding learning when interacting withcollapsed embeddings, exacerbating the collapse issue. On the other hand,feature interaction is crucial in mitigating the fitting of spurious features,thereby improving scalability. Based on this analysis, we propose a simple yeteffective multi-embedding design incorporating embedding-set-specificinteraction modules to capture diverse patterns and reduce collapse. Extensiveexperiments demonstrate that this proposed design provides consistentscalability for various recommendation models.</description><author>Xingzhuo Guo, Junwei Pan, Ximei Wang, Baixu Chen, Jie Jiang, Mingsheng Long</author><pubDate>Fri, 06 Oct 2023 18:50:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04400v1</guid></item><item><title>Improving Stability in Simultaneous Speech Translation: A Revision-Controllable Decoding Approach</title><link>http://arxiv.org/abs/2310.04399v1</link><description>Simultaneous Speech-to-Text translation serves a critical role in real-timecrosslingual communication. Despite the advancements in recent years,challenges remain in achieving stability in the translation process, a concernprimarily manifested in the flickering of partial results. In this paper, wepropose a novel revision-controllable method designed to address this issue.Our method introduces an allowed revision window within the beam search pruningprocess to screen out candidate translations likely to cause extensiverevisions, leading to a substantial reduction in flickering and, crucially,providing the capability to completely eliminate flickering. The experimentsdemonstrate the proposed method can significantly improve the decodingstability without compromising substantially on the translation quality.</description><author>Junkun Chen, Jian Xue, Peidong Wang, Jing Pan, Jinyu Li</author><pubDate>Fri, 06 Oct 2023 18:48:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04399v1</guid></item><item><title>Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner</title><link>http://arxiv.org/abs/2305.01711v4</link><description>Language models (LMs) trained on vast quantities of unlabelled data havegreatly advanced the field of natural language processing (NLP). In this study,we re-visit the widely accepted notion in NLP that continued pre-training LMson task-related texts improves the performance of fine-tuning (FT) indownstream tasks. Through experiments on eight single-sentence tasks and eightsentence-pair tasks in both semi-supervised and fully-supervised settings, wefind that conventional continued pre-training does not consistently providebenefits and can even be detrimental for sentence-pair tasks or whenprompt-based FT is used. To tackle these issues, we propose Prompt-basedContinued Pre-training (PCP), which combines the idea of instruction tuningwith conventional continued pre-training. Our approach aims to improve theperformance of prompt-based FT by presenting both task-related texts and prompttemplates to LMs through unsupervised pre-training objectives beforefine-tuning for the target task. Our empirical evaluations on 21 benchmarksdemonstrate that the PCP consistently improves the performance ofstate-of-the-art prompt-based FT approaches (up to 20.1% absolute) in bothsemi-supervised and fully-supervised settings, even with only hundreds ofunlabelled examples. Additionally, prompt-based FT with the PCP outperformsstate-of-the-art semi-supervised approaches with greater simplicity,eliminating the need for an iterative process and extra data augmentation. Ourfurther analysis explores the performance lower bound of the PCP and revealsthat the advantages of PCP persist across different sizes of models anddatasets.</description><author>Zhengxiang Shi, Aldo Lipani</author><pubDate>Fri, 06 Oct 2023 18:47:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.01711v4</guid></item><item><title>Leveraging Self-Consistency for Data-Efficient Amortized Bayesian Inference</title><link>http://arxiv.org/abs/2310.04395v1</link><description>We propose a method to improve the efficiency and accuracy of amortizedBayesian inference (ABI) by leveraging universal symmetries in theprobabilistic joint model $p(\theta, y)$ of parameters $\theta$ and data $y$.In a nutshell, we invert Bayes' theorem and estimate the marginal likelihoodbased on approximate representations of the joint model. Upon perfectapproximation, the marginal likelihood is constant across all parameter valuesby definition. However, approximation error leads to undesirable variance inthe marginal likelihood estimates across different parameter values. Weformulate violations of this symmetry as a loss function to accelerate thelearning dynamics of conditional neural density estimators. We apply our methodto a bimodal toy problem with an explicit likelihood (likelihood-based) and arealistic model with an implicit likelihood (simulation-based).</description><author>Marvin Schmitt, Daniel Habermann, Paul-Christian Bürkner, Ullrich Köthe, Stefan T. Radev</author><pubDate>Fri, 06 Oct 2023 18:41:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04395v1</guid></item><item><title>GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction</title><link>http://arxiv.org/abs/2310.03668v2</link><description>Large Language Models (LLMs) combined with instruction tuning have madesignificant progress when generalizing to unseen tasks. However, they have beenless successful in Information Extraction (IE), lagging behind task-specificmodels. Typically, IE tasks are characterized by complex annotation guidelineswhich describe the task and give examples to humans. Previous attempts toleverage such information have failed, even with the largest models, as theyare not able to follow the guidelines out-of-the-box. In this paper we proposeGoLLIE (Guideline-following Large Language Model for IE), a model able toimprove zero-shot results on unseen IE tasks by virtue of being fine-tuned tocomply with annotation guidelines. Comprehensive evaluation empiricallydemonstrates that GoLLIE is able to generalize to and follow unseen guidelines,outperforming previous attempts at zero-shot information extraction. Theablation study shows that detailed guidelines is key for good results.</description><author>Oscar Sainz, Iker García-Ferrero, Rodrigo Agerri, Oier Lopez de Lacalle, German Rigau, Eneko Agirre</author><pubDate>Fri, 06 Oct 2023 18:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03668v2</guid></item><item><title>Multi-Domain Long-Tailed Learning by Augmenting Disentangled Representations</title><link>http://arxiv.org/abs/2210.14358v3</link><description>There is an inescapable long-tailed class-imbalance issue in many real-worldclassification problems. Current methods for addressing this problem onlyconsider scenarios where all examples come from the same distribution. However,in many cases, there are multiple domains with distinct class imbalance. Westudy this multi-domain long-tailed learning problem and aim to produce a modelthat generalizes well across all classes and domains. Towards that goal, weintroduce TALLY, a method that addresses this multi-domain long-tailed learningproblem. Built upon a proposed selective balanced sampling strategy, TALLYachieves this by mixing the semantic representation of one example with thedomain-associated nuisances of another, producing a new representation for useas data augmentation. To improve the disentanglement of semanticrepresentations, TALLY further utilizes a domain-invariant class prototype thataverages out domain-specific effects. We evaluate TALLY on several benchmarksand real-world datasets and find that it consistently outperforms otherstate-of-the-art methods in both subpopulation and domain shift. Our code anddata have been released at https://github.com/huaxiuyao/TALLY.</description><author>Xinyu Yang, Huaxiu Yao, Allan Zhou, Chelsea Finn</author><pubDate>Fri, 06 Oct 2023 18:34:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.14358v3</guid></item><item><title>Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control</title><link>http://arxiv.org/abs/2306.07863v2</link><description>Building agents using large language models (LLMs) to control computers is anemerging research field, where the agent perceives computer states and performsactions to accomplish complex tasks. Previous computer agents have demonstratedthe benefits of in-context learning (ICL); however, their performance ishindered by several issues. First, the limited context length of LLMs andcomplex computer states restrict the number of exemplars, as a single webpagecan consume the entire context. Second, the exemplars in current methods, suchas high-level plans and multi-choice questions, cannot represent completetrajectories, leading to suboptimal performance in tasks that require manysteps or repeated actions. Third, existing computer agents rely ontask-specific exemplars and overlook the similarity among tasks, resulting inpoor generalization to novel tasks. To address these challenges, we introduceSynapse, featuring three key components: i) state abstraction, which filtersout task-irrelevant information from raw states, allowing more exemplars withinthe limited context, ii) trajectory-as-exemplar prompting, which prompts theLLM with complete trajectories of the abstracted states and actions forimproved multi-step decision-making, and iii) exemplar memory, which stores theembeddings of exemplars and retrieves them via similarity search forgeneralization to novel tasks. We evaluate Synapse on MiniWoB++, a standardtask suite, and Mind2Web, a real-world website benchmark. In MiniWoB++, Synapseachieves a 99.2% average success rate (a 10% relative improvement) across 64tasks using demonstrations from only 48 tasks. Notably, Synapse is the firstICL method to solve the book-flight task in MiniWoB++. Synapse also exhibits a53% relative improvement in average step success rate over the previousstate-of-the-art prompting scheme in Mind2Web.</description><author>Longtao Zheng, Rundong Wang, Xinrun Wang, Bo An</author><pubDate>Fri, 06 Oct 2023 18:28:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07863v2</guid></item><item><title>AdaptivePaste: Code Adaptation through Learning Semantics-aware Variable Usage Representations</title><link>http://arxiv.org/abs/2205.11023v3</link><description>In software development, it is common for programmers to copy-paste or portcode snippets and then adapt them to their use case. This scenario motivatesthe code adaptation task -- a variant of program repair which aims to adaptvariable identifiers in a pasted snippet of code to the surrounding,preexisting source code. However, no existing approach has been shown toeffectively address this task. In this paper, we introduce AdaptivePaste, alearning-based approach to source code adaptation, based on transformers and adedicated dataflow-aware deobfuscation pre-training task to learn meaningfulrepresentations of variable usage patterns. We evaluate AdaptivePaste on adataset of code snippets in Python. Results suggest that our model can learn toadapt source code with 79.8% accuracy. To evaluate how valuable isAdaptivePaste in practice, we perform a user study with 10 Python developers ona hundred real-world copy-paste instances. The results show that AdaptivePastereduces the dwell time to nearly half the time it takes for manual codeadaptation, and helps to avoid bugs. In addition, we utilize the participantfeedback to identify potential avenues for improvement of AdaptivePaste.</description><author>Xiaoyu Liu, Jinu Jang, Neel Sundaresan, Miltiadis Allamanis, Alexey Svyatkovskiy</author><pubDate>Fri, 06 Oct 2023 18:24:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.11023v3</guid></item><item><title>Blinder: End-to-end Privacy Protection in Sensing Systems via Personalized Federated Learning</title><link>http://arxiv.org/abs/2209.12046v3</link><description>This paper proposes a sensor data anonymization model that is trained ondecentralized data and strikes a desirable trade-off between data utility andprivacy, even in heterogeneous settings where the sensor data have differentunderlying distributions. Our anonymization model, dubbed Blinder, is based ona variational autoencoder and one or multiple discriminator networks trained inan adversarial fashion. We use the model-agnostic meta-learning framework toadapt the anonymization model trained via federated learning to each user'sdata distribution. We evaluate Blinder under different settings and show thatit provides end-to-end privacy protection on two IMU datasets at the cost ofincreasing privacy loss by up to 4.00% and decreasing data utility by up to4.24%, compared to the state-of-the-art anonymization model trained oncentralized data. We also showcase Blinder's ability to anonymize the radiofrequency sensing modality. Our experiments confirm that Blinder can obscuremultiple private attributes at once, and has sufficiently low power consumptionand computational overhead for it to be deployed on edge devices andsmartphones to perform real-time anonymization of sensor data.</description><author>Xin Yang, Omid Ardakanian</author><pubDate>Fri, 06 Oct 2023 18:23:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.12046v3</guid></item><item><title>Hermes: Unlocking Security Analysis of Cellular Network Protocols by Synthesizing Finite State Machines from Natural Language Specifications</title><link>http://arxiv.org/abs/2310.04381v1</link><description>In this paper, we present Hermes, an end-to-end framework to automaticallygenerate formal representations from natural language cellular specifications.We first develop a neural constituency parser, NEUTREX, to processtransition-relevant texts and extract transition components (i.e., states,conditions, and actions). We also design a domain-specific language totranslate these transition components to logical formulas by leveragingdependency parse trees. Finally, we compile these logical formulas to generatetransitions and create the formal model as finite state machines. Todemonstrate the effectiveness of Hermes, we evaluate it on 4G NAS, 5G NAS, and5G RRC specifications and obtain an overall accuracy of 81-87%, which is asubstantial improvement over the state-of-the-art. Our security analysis of theextracted models uncovers 3 new vulnerabilities and identifies 19 previousattacks in 4G and 5G specifications, and 7 deviations in commercial 4Gbasebands.</description><author>Abdullah Al Ishtiaq, Sarkar Snigdha Sarathi Das, Syed Md Mukit Rashid, Ali Ranjbar, Kai Tu, Tianwei Wu, Zhezheng Song, Weixuan Wang, Mujtahid Akon, Rui Zhang, Syed Rafiul Hussain</author><pubDate>Fri, 06 Oct 2023 18:19:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04381v1</guid></item><item><title>Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning</title><link>http://arxiv.org/abs/2305.15612v2</link><description>Bayesian optimization has attracted huge attention from diverse researchareas in science and engineering, since it is capable of finding a globaloptimum of an expensive-to-evaluate black-box function efficiently. In general,a probabilistic regression model, e.g., Gaussian processes and Bayesian neuralnetworks, is widely used as a surrogate function to model an explicitdistribution over function evaluations given an input to estimate and atraining dataset. Beyond the probabilistic regression-based Bayesianoptimization, density ratio estimation-based Bayesian optimization has beensuggested in order to estimate a density ratio of the groups relatively closeand relatively far to a global optimum. Developing this line of researchfurther, a supervised classifier can be employed to estimate a classprobability for the two groups instead of a density ratio. However, thesupervised classifiers used in this strategy are prone to be overconfident fora global solution candidate. To solve this problem, we propose density ratioestimation-based Bayesian optimization with semi-supervised learning. Finally,we demonstrate the experimental results of our methods and several baselinemethods in two distinct scenarios with unlabeled point sampling and afixed-size pool.</description><author>Jungtaek Kim</author><pubDate>Fri, 06 Oct 2023 18:13:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15612v2</guid></item><item><title>Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference</title><link>http://arxiv.org/abs/2310.04378v1</link><description>Latent Diffusion models (LDMs) have achieved remarkable results insynthesizing high-resolution images. However, the iterative sampling process iscomputationally intensive and leads to slow generation. Inspired by ConsistencyModels (song et al.), we propose Latent Consistency Models (LCMs), enablingswift inference with minimal steps on any pre-trained LDMs, including StableDiffusion (rombach et al). Viewing the guided reverse diffusion process assolving an augmented probability flow ODE (PF-ODE), LCMs are designed todirectly predict the solution of such ODE in latent space, mitigating the needfor numerous iterations and allowing rapid, high-fidelity sampling. Efficientlydistilled from pre-trained classifier-free guided diffusion models, ahigh-quality 768 x 768 2~4-step LCM takes only 32 A100 GPU hours for training.Furthermore, we introduce Latent Consistency Fine-tuning (LCF), a novel methodthat is tailored for fine-tuning LCMs on customized image datasets. Evaluationon the LAION-5B-Aesthetics dataset demonstrates that LCMs achievestate-of-the-art text-to-image generation performance with few-step inference.Project Page: https://latent-consistency-models.github.io/</description><author>Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, Hang Zhao</author><pubDate>Fri, 06 Oct 2023 18:11:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04378v1</guid></item><item><title>A Simple and Effective Pruning Approach for Large Language Models</title><link>http://arxiv.org/abs/2306.11695v2</link><description>As their size increases, Large Languages Models (LLMs) are natural candidatesfor network pruning methods: approaches that drop a subset of network weightswhile striving to preserve performance. Existing methods, however, requireeither retraining, which is rarely affordable for billion-scale LLMs, orsolving a weight reconstruction problem reliant on second-order information,which may also be computationally expensive. In this paper, we introduce anovel, straightforward yet effective pruning method, termed Wanda (Pruning byWeights and activations), designed to induce sparsity in pretrained LLMs.Motivated by the recent observation of emergent large magnitude features inLLMs, our approach prunes weights with the smallest magnitudes multiplied bythe corresponding input activations, on a per-output basis. Notably, Wandarequires no retraining or weight update, and the pruned LLM can be used as is.We conduct a thorough evaluation of our method Wanda on LLaMA and LLaMA-2across various language benchmarks. Wanda significantly outperforms theestablished baseline of magnitude pruning and performs competitively againstrecent method involving intensive weight update. Code is available athttps://github.com/locuslab/wanda.</description><author>Mingjie Sun, Zhuang Liu, Anna Bair, J. Zico Kolter</author><pubDate>Fri, 06 Oct 2023 18:11:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11695v2</guid></item><item><title>Manifestations of Xenophobia in AI Systems</title><link>http://arxiv.org/abs/2212.07877v2</link><description>Xenophobia is one of the key drivers of marginalisation, discrimination, andconflict, yet many prominent machine learning (ML) fairness frameworks fail tocomprehensively measure or mitigate the resulting xenophobic harms. Here we aimto bridge this conceptual gap and help facilitate safe and ethical design ofartificial intelligence (AI) solutions. We ground our analysis of the impact ofxenophobia by first identifying distinct types of xenophobic harms, and thenapplying this framework across a number of prominent AI application domains,reviewing the potential interplay between AI and xenophobia on social media andrecommendation systems, healthcare, immigration, employment, as well as biasesin large pre-trained models. These help inform our recommendations towards aninclusive, xenophilic design of future AI systems.</description><author>Nenad Tomasev, Jonathan Leader Maynard, Iason Gabriel</author><pubDate>Fri, 06 Oct 2023 17:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.07877v2</guid></item><item><title>Confronting Reward Model Overoptimization with Constrained RLHF</title><link>http://arxiv.org/abs/2310.04373v1</link><description>Large language models are typically aligned with human preferences byoptimizing $\textit{reward models}$ (RMs) fitted to human feedback. However,human preferences are multi-faceted, and it is increasingly common to derivereward from a composition of simpler reward models which each capture adifferent aspect of language quality. This itself presents a challenge, as itis difficult to appropriately weight these component RMs when combining them.Compounding this difficulty, because any RM is only a proxy for humanevaluation, this process is vulnerable to $\textit{overoptimization}$, whereinpast a certain point, accumulating higher reward is associated with worse humanratings. In this paper, we perform, to our knowledge, the first study onoveroptimization in composite RMs, showing that correlation between componentRMs has a significant effect on the locations of these points. We thenintroduce an approach to solve this issue using constrained reinforcementlearning as a means of preventing the agent from exceeding each RM's thresholdof usefulness. Our method addresses the problem of weighting component RMs bylearning dynamic weights, naturally given by the Lagrange multipliers. As aresult, each RM stays within the range at which it is an effective proxy,improving evaluation performance. Finally, we introduce an adaptive methodusing gradient-free optimization to identify and optimize towards these pointsduring a single run.</description><author>Ted Moskovitz, Aaditya K. Singh, DJ Strouse, Tuomas Sandholm, Ruslan Salakhutdinov, Anca D. Dragan, Stephen McAleer</author><pubDate>Fri, 06 Oct 2023 17:59:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04373v1</guid></item><item><title>MBTFNet: Multi-Band Temporal-Frequency Neural Network For Singing Voice Enhancement</title><link>http://arxiv.org/abs/2310.04369v1</link><description>A typical neural speech enhancement (SE) approach mainly handles speech andnoise mixtures, which is not optimal for singing voice enhancement scenarios.Music source separation (MSS) models treat vocals and various accompanimentcomponents equally, which may reduce performance compared to the model thatonly considers vocal enhancement. In this paper, we propose a novel multi-bandtemporal-frequency neural network (MBTFNet) for singing voice enhancement,which particularly removes background music, noise and even backing vocals fromsinging recordings. MBTFNet combines inter and intra-band modeling for betterprocessing of full-band signals. Dual-path modeling are introduced to expandthe receptive field of the model. We propose an implicit personalizedenhancement (IPE) stage based on signal-to-noise ratio (SNR) estimation, whichfurther improves the performance of MBTFNet. Experiments show that our proposedmodel significantly outperforms several state-of-the-art SE and MSS models.</description><author>Weiming Xu, Zhouxuan Chen, Zhili Tan, Shubo Lv, Runduo Han, Wenjiang Zhou, Weifeng Zhao, Lei Xie</author><pubDate>Fri, 06 Oct 2023 17:44:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04369v1</guid></item><item><title>A Marketplace Price Anomaly Detection System at Scale</title><link>http://arxiv.org/abs/2310.04367v1</link><description>Online marketplaces execute large volume of price updates that are initiatedby individual marketplace sellers each day on the platform. This pricedemocratization comes with increasing challenges with data quality. Lack ofcentralized guardrails that are available for a traditional online retailercauses a higher likelihood for inaccurate prices to get published on thewebsite, leading to poor customer experience and potential for revenue loss. Wepresent MoatPlus (Masked Optimal Anchors using Trees, Proximity-based Labelingand Unsupervised Statistical-features), a scalable price anomaly detectionframework for a growing marketplace platform. The goal is to leverage proximityand historical price trends from unsupervised statistical features to generatean upper price bound. We build an ensemble of models to detect irregularitiesin price-based features, exclude irregular features and use optimized weightingscheme to build a reliable price bound in real-time pricing pipeline. Weobserved that our approach improves precise anchor coverage by up to 46.6% inhigh-vulnerability item subsets</description><author>Akshit Sarpal, Qiwen Kang, Fangping Huang, Yang Song, Lijie Wan</author><pubDate>Fri, 06 Oct 2023 17:41:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04367v1</guid></item><item><title>Amortizing intractable inference in large language models</title><link>http://arxiv.org/abs/2310.04363v1</link><description>Autoregressive large language models (LLMs) compress knowledge from theirtraining data through next-token conditional distributions. This limitstractable querying of this knowledge to start-to-end autoregressive sampling.However, many tasks of interest -- including sequence continuation, infilling,and other forms of constrained generation -- involve sampling from intractableposterior distributions. We address this limitation by using amortized Bayesianinference to sample from these intractable posteriors. Such amortization isalgorithmically achieved by fine-tuning LLMs via diversity-seekingreinforcement learning algorithms: generative flow networks (GFlowNets). Weempirically demonstrate that this distribution-matching paradigm of LLMfine-tuning can serve as an effective alternative to maximum-likelihoodtraining and reward-maximizing policy optimization. As an importantapplication, we interpret chain-of-thought reasoning as a latent variablemodeling problem and demonstrate that our approach enables data-efficientadaptation of LLMs to tasks that require multi-step rationalization and tooluse.</description><author>Edward J. Hu, Moksh Jain, Eric Elmoznino, Younesse Kaddar, Guillaume Lajoie, Yoshua Bengio, Nikolay Malkin</author><pubDate>Fri, 06 Oct 2023 17:36:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04363v1</guid></item><item><title>Exploiting Transformer Activation Sparsity with Dynamic Inference</title><link>http://arxiv.org/abs/2310.04361v1</link><description>Transformer models, despite their impressive performance, often facepractical limitations due to their high computational requirements. At the sametime, previous studies have revealed significant activation sparsity in thesemodels, indicating the presence of redundant computations. In this paper, wepropose Dynamic Sparsified Transformer Inference (DSTI), a method thatradically reduces the inference cost of Transformer models by enforcingactivation sparsity and subsequently transforming a dense model into its sparseMixture of Experts (MoE) version. We demonstrate that it is possible to trainsmall gating networks that successfully predict the relative contribution ofeach expert during inference. Furthermore, we introduce a mechanism thatdynamically determines the number of executed experts individually for eachtoken. DSTI can be applied to any Transformer-based architecture and hasnegligible impact on the accuracy. For the BERT-base classification model, wereduce inference cost by almost 60%.</description><author>Mikołaj Piórczyński, Filip Szatkowski, Klaudia Bałazy, Bartosz Wójcik</author><pubDate>Fri, 06 Oct 2023 17:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04361v1</guid></item><item><title>SwimXYZ: A large-scale dataset of synthetic swimming motions and videos</title><link>http://arxiv.org/abs/2310.04360v1</link><description>Technologies play an increasingly important role in sports and become a realcompetitive advantage for the athletes who benefit from it. Among them, the useof motion capture is developing in various sports to optimize sportinggestures. Unfortunately, traditional motion capture systems are expensive andconstraining. Recently developed computer vision-based approaches also strugglein certain sports, like swimming, due to the aquatic environment. One of thereasons for the gap in performance is the lack of labeled datasets withswimming videos. In an attempt to address this issue, we introduce SwimXYZ, asynthetic dataset of swimming motions and videos. SwimXYZ contains 3.4 millionframes annotated with ground truth 2D and 3D joints, as well as 240 sequencesof swimming motions in the SMPL parameters format. In addition to making thisdataset publicly available, we present use cases for SwimXYZ in swimming strokeclustering and 2D pose estimation.</description><author>Fiche Guénolé, Sevestre Vincent, Gonzalez-Barral Camila, Leglaive Simon, Séguier Renaud</author><pubDate>Fri, 06 Oct 2023 17:33:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04360v1</guid></item><item><title>Transferring speech-generic and depression-specific knowledge for Alzheimer's disease detection</title><link>http://arxiv.org/abs/2310.04358v1</link><description>The detection of Alzheimer's disease (AD) from spontaneous speech hasattracted increasing attention while the sparsity of training data remains animportant issue. This paper handles the issue by knowledge transfer,specifically from both speech-generic and depression-specific knowledge. Thepaper first studies sequential knowledge transfer from generic foundationmodels pretrained on large amounts of speech and text data. A block-wiseanalysis is performed for AD diagnosis based on the representations extractedfrom different intermediate blocks of different foundation models. Apart fromthe knowledge from speech-generic representations, this paper also proposes tosimultaneously transfer the knowledge from a speech depression detection taskbased on the high comorbidity rates of depression and AD. A parallel knowledgetransfer framework is studied that jointly learns the information sharedbetween these two tasks. Experimental results show that the proposed methodimproves AD and depression detection, and produces a state-of-the-art F1 scoreof 0.928 for AD diagnosis on the commonly used ADReSSo dataset.</description><author>Ziyun Cui, Wen Wu, Wei-Qiang Zhang, Ji Wu, Chao Zhang</author><pubDate>Fri, 06 Oct 2023 17:28:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04358v1</guid></item><item><title>Asymptotically free sketched ridge ensembles: Risks, cross-validation, and tuning</title><link>http://arxiv.org/abs/2310.04357v1</link><description>We employ random matrix theory to establish consistency of generalized crossvalidation (GCV) for estimating prediction risks of sketched ridge regressionensembles, enabling efficient and consistent tuning of regularization andsketching parameters. Our results hold for a broad class of asymptotically freesketches under very mild data assumptions. For squared prediction risk, weprovide a decomposition into an unsketched equivalent implicit ridge bias and asketching-based variance, and prove that the risk can be globally optimized byonly tuning sketch size in infinite ensembles. For general subquadraticprediction risk functionals, we extend GCV to construct consistent riskestimators, and thereby obtain distributional convergence of the GCV-correctedpredictions in Wasserstein-2 metric. This in particular allows construction ofprediction intervals with asymptotically correct coverage conditional on thetraining data. We also propose an "ensemble trick" whereby the risk forunsketched ridge regression can be efficiently estimated via GCV using smallsketched ridge ensembles. We empirically validate our theoretical results usingboth synthetic and real large-scale datasets with practical sketches includingCountSketch and subsampled randomized discrete cosine transforms.</description><author>Pratik Patil, Daniel LeJeune</author><pubDate>Fri, 06 Oct 2023 17:27:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04357v1</guid></item><item><title>SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks</title><link>http://arxiv.org/abs/2206.05794v5</link><description>We study the bias of Stochastic Gradient Descent (SGD) to learn low-rankweight matrices when training deep ReLU neural networks. Our results show thattraining neural networks with mini-batch SGD and weight decay causes a biastowards rank minimization over the weight matrices. Specifically, we show, boththeoretically and empirically, that this bias is more pronounced when usingsmaller batch sizes, higher learning rates, or increased weight decay.Additionally, we predict and observe empirically that weight decay is necessaryto achieve this bias. Unlike previous literature, our analysis does not rely onassumptions about the data, convergence, or optimality of the weight matricesand applies to a wide range of neural network architectures of any width ordepth. Finally, we empirically investigate the connection between this bias andgeneralization, finding that it has a marginal effect on generalization.</description><author>Tomer Galanti, Zachary S. Siegel, Aparna Gupte, Tomaso Poggio</author><pubDate>Fri, 06 Oct 2023 17:23:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.05794v5</guid></item><item><title>Integrating Transformations in Probabilistic Circuits</title><link>http://arxiv.org/abs/2310.04354v1</link><description>This study addresses the predictive limitation of probabilistic circuits andintroduces transformations as a remedy to overcome it. We demonstrate thislimitation in robotic scenarios. We motivate that independent componentanalysis is a sound tool to preserve the independence properties ofprobabilistic circuits. Our approach is an extension of joint probabilitytrees, which are model-free deterministic circuits. By doing so, it isdemonstrated that the proposed approach is able to achieve higher likelihoodswhile using fewer parameters compared to the joint probability trees on sevenbenchmark data sets as well as on real robot data. Furthermore, we discuss howto integrate transformations into tree-based learning routines. Finally, weargue that exact inference with transformed quantile parameterizeddistributions is not tractable. However, our approach allows for efficientsampling and approximate inference.</description><author>Tom Schierenbeck, Vladimir Vutov, Thorsten Dickhaus, Michael Beetz</author><pubDate>Fri, 06 Oct 2023 17:23:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04354v1</guid></item><item><title>A Language-Agent Approach to Formal Theorem-Proving</title><link>http://arxiv.org/abs/2310.04353v1</link><description>Language agents, which use a large language model (LLM) capable of in-contextlearning to interact with an external environment, have recently emerged as apromising approach to control tasks. We present the first language-agentapproach to formal theorem-proving. Our method, COPRA, uses a high-capacity,black-box LLM (GPT-4) as part of a policy for a stateful backtracking search.During the search, the policy can select proof tactics and retrieve lemmas anddefinitions from an external database. Each selected tactic is executed in theunderlying proof framework, and the execution feedback is used to build theprompt for the next policy invocation. The search also tracks selectedinformation from its history and uses it to reduce hallucinations andunnecessary LLM queries. We evaluate COPRA on the miniF2F benchmark for Lean and a set of Coq tasksfrom the Compcert project. On these benchmarks, COPRA is significantly betterthan one-shot invocations of GPT-4, as well as state-of-the-art modelsfine-tuned on proof data, at finding correct proofs quickly.</description><author>Amitayush Thakur, Yeming Wen, Swarat Chaudhuri</author><pubDate>Fri, 06 Oct 2023 17:21:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04353v1</guid></item><item><title>Fair Feature Importance Scores for Interpreting Tree-Based Methods and Surrogates</title><link>http://arxiv.org/abs/2310.04352v1</link><description>Across various sectors such as healthcare, criminal justice, nationalsecurity, finance, and technology, large-scale machine learning (ML) andartificial intelligence (AI) systems are being deployed to make criticaldata-driven decisions. Many have asked if we can and should trust these MLsystems to be making these decisions. Two critical components are prerequisitesfor trust in ML systems: interpretability, or the ability to understand why theML system makes the decisions it does, and fairness, which ensures that MLsystems do not exhibit bias against certain individuals or groups. Bothinterpretability and fairness are important and have separately receivedabundant attention in the ML literature, but so far, there have been very fewmethods developed to directly interpret models with regard to their fairness.In this paper, we focus on arguably the most popular type of ML interpretation:feature importance scores. Inspired by the use of decision trees in knowledgedistillation, we propose to leverage trees as interpretable surrogates forcomplex black-box ML models. Specifically, we develop a novel fair featureimportance score for trees that can be used to interpret how each featurecontributes to fairness or bias in trees, tree-based ensembles, or tree-basedsurrogates of any complex ML system. Like the popular mean decrease in impurityfor trees, our Fair Feature Importance Score is defined based on the meandecrease (or increase) in group bias. Through simulations as well as realexamples on benchmark fairness datasets, we demonstrate that our Fair FeatureImportance Score offers valid interpretations for both tree-based ensembles andtree-based surrogates of other ML systems.</description><author>Camille Olivia Little, Debolina Halder Lina, Genevera I. Allen</author><pubDate>Fri, 06 Oct 2023 17:21:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04352v1</guid></item><item><title>FedFTN: Personalized Federated Learning with Deep Feature Transformation Network for Multi-institutional Low-count PET Denoising</title><link>http://arxiv.org/abs/2304.00570v3</link><description>Low-count PET is an efficient way to reduce radiation exposure andacquisition time, but the reconstructed images often suffer from lowsignal-to-noise ratio (SNR), thus affecting diagnosis and other downstreamtasks. Recent advances in deep learning have shown great potential in improvinglow-count PET image quality, but acquiring a large, centralized, and diversedataset from multiple institutions for training a robust model is difficult dueto privacy and security concerns of patient data. Moreover, low-count PET dataat different institutions may have different data distribution, thus requiringpersonalized models. While previous federated learning (FL) algorithms enablemulti-institution collaborative training without the need of aggregating localdata, addressing the large domain shift in the application ofmulti-institutional low-count PET denoising remains a challenge and is stillhighly under-explored. In this work, we propose FedFTN, a personalizedfederated learning strategy that addresses these challenges. FedFTN uses alocal deep feature transformation network (FTN) to modulate the feature outputsof a globally shared denoising network, enabling personalized low-count PETdenoising for each institution. During the federated learning process, only thedenoising network's weights are communicated and aggregated, while the FTNremains at the local institutions for feature transformation. We evaluated ourmethod using a large-scale dataset of multi-institutional low-count PET imagingdata from three medical centers located across three continents, and showedthat FedFTN provides high-quality low-count PET images, outperforming previousbaseline FL reconstruction methods across all low-count levels at all threeinstitutions.</description><author>Bo Zhou, Huidong Xie, Qiong Liu, Xiongchao Chen, Xueqi Guo, Zhicheng Feng, Jun Hou, S. Kevin Zhou, Biao Li, Axel Rominger, Kuangyu Shi, James S. Duncan, Chi Liu</author><pubDate>Fri, 06 Oct 2023 17:20:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.00570v3</guid></item><item><title>Robust One-Shot Singing Voice Conversion</title><link>http://arxiv.org/abs/2210.11096v2</link><description>Recent progress in deep generative models has improved the quality of voiceconversion in the speech domain. However, high-quality singing voice conversion(SVC) of unseen singers remains challenging due to the wider variety of musicalexpressions in pitch, loudness, and pronunciation. Moreover, singing voices areoften recorded with reverb and accompaniment music, which make SVC even morechallenging. In this work, we present a robust one-shot SVC (ROSVC) thatperforms any-to-any SVC robustly even on such distorted singing voices. To thisend, we first propose a one-shot SVC model based on generative adversarialnetworks that generalizes to unseen singers via partial domain conditioning andlearns to accurately recover the target pitch via pitch distribution matchingand AdaIN-skip conditioning. We then propose a two-stage training method calledRobustify that train the one-shot SVC model in the first stage on clean data toensure high-quality conversion, and introduces enhancement modules to theencoders of the model in the second stage to enhance the feature extractionfrom distorted singing voices. To further improve the voice quality and pitchreconstruction accuracy, we finally propose a hierarchical diffusion model forsinging voice neural vocoders. Experimental results show that the proposedmethod outperforms state-of-the-art one-shot SVC baselines for both seen andunseen singers and significantly improves the robustness against distortions.</description><author>Naoya Takahashi, Mayank Kumar Singh, Yuki Mitsufuji</author><pubDate>Fri, 06 Oct 2023 17:18:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.11096v2</guid></item><item><title>Learning to Grasp: from Somewhere to Anywhere</title><link>http://arxiv.org/abs/2310.04349v1</link><description>Robotic grasping is still a partially solved, multidisciplinary problem wheredata-driven techniques play an increasing role. The sparse nature of rewardsmake the automatic generation of grasping datasets challenging, especially forunconventional morphologies or highly actuated end-effectors. Most approachesfor obtaining large-scale datasets rely on numerous human-provideddemonstrations or heavily engineered solutions that do not scale well. Recentadvances in Quality-Diversity (QD) methods have investigated how to learnobject grasping at a specific pose with different robot morphologies. Thepresent work introduces a pipeline for adapting QD-generated trajectories tonew object poses. Using an RGB-D data stream, the vision pipeline first detectsthe targeted object, predicts its 6-DOF pose, and finally tracks it. Anautomatically generated reach-and-grasp trajectory can then be adapted byprojecting it relatively to the object frame. Hundreds of trajectories havebeen deployed into the real world on several objects and with different roboticsetups: a Franka Research 3 with a parallel gripper and a UR5 with a dexterousSIH Schunk hand. The transfer ratio obtained when applying transformation tothe object pose matches the one obtained when the object pose matches thesimulation, demonstrating the efficiency of the proposed approach.</description><author>François Hélénon, Johann Huber, Faïz Ben Amar, Stéphane Doncieux</author><pubDate>Fri, 06 Oct 2023 17:16:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04349v1</guid></item><item><title>Simple High Quality OoD Detection with L2 Normalization</title><link>http://arxiv.org/abs/2306.04072v2</link><description>We propose a simple modification to standard deep learning architecturesduring their training phase--L2 normalization over feature space--that producesresults competitive with state-of-the-art Out-of-Distribution (OoD) detectionbut with relatively little training time. When L2 normalization is removed attest time, magnitudes of feature vectors becomes a surprisingly goodmeasurement for OoD detection. Intuitively, In Distribution (ID) images resultin large vectors, while OoD images have small magnitudes, which permits asimple threshold scheme for screen OoD images. We provide a theoreticalanalysis of how this simple change works. Competitive results are possible inonly 60 epochs of training on a standard ResNet18.</description><author>Jarrod Haas, William Yolland, Bernhard Rabus</author><pubDate>Fri, 06 Oct 2023 17:14:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04072v2</guid></item><item><title>Neur2RO: Neural Two-Stage Robust Optimization</title><link>http://arxiv.org/abs/2310.04345v1</link><description>Robust optimization provides a mathematical framework for modeling andsolving decision-making problems under worst-case uncertainty. This workaddresses two-stage robust optimization (2RO) problems (also called adjustablerobust optimization), wherein first-stage and second-stage decisions are madebefore and after uncertainty is realized, respectively. This results in anested min-max-min optimization problem which is extremely challengingcomputationally, especially when the decisions are discrete. We proposeNeur2RO, an efficient machine learning-driven instantiation ofcolumn-and-constraint generation (CCG), a classical iterative algorithm for2RO. Specifically, we learn to estimate the value function of the second-stageproblem via a novel neural network architecture that is easy to optimize overby design. Embedding our neural network into CCG yields high-quality solutionsquickly as evidenced by experiments on two 2RO benchmarks, knapsack and capitalbudgeting. For knapsack, Neur2RO finds solutions that are within roughly $2\%$of the best-known values in a few seconds compared to the three hours of thestate-of-the-art exact branch-and-price algorithm; for larger and more complexinstances, Neur2RO finds even better solutions. For capital budgeting, Neur2ROoutperforms three variants of the $k$-adaptability algorithm, particularly onthe largest instances, with a 5 to 10-fold reduction in solution time. Our codeand data are available at https://github.com/khalil-research/Neur2RO.</description><author>Justin Dumouchelle, Esther Julien, Jannis Kurtz, Elias B. Khalil</author><pubDate>Fri, 06 Oct 2023 17:11:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04345v1</guid></item><item><title>Functional Geometry Guided Protein Sequence and Backbone Structure Co-Design</title><link>http://arxiv.org/abs/2310.04343v1</link><description>Proteins are macromolecules responsible for essential functions in almost allliving organisms. Designing reasonable proteins with desired functions iscrucial. A protein's sequence and structure are strongly correlated and theytogether determine its function. In this paper, we propose NAEPro, a model tojointly design Protein sequence and structure based on automatically detectedfunctional sites. NAEPro is powered by an interleaving network of attention andequivariant layers, which can capture global correlation in a whole sequenceand local influence from nearest amino acids in three dimensional (3D) space.Such an architecture facilitates effective yet economic message passing at twolevels. We evaluate our model and several strong baselines on two proteindatasets, $\beta$-lactamase and myoglobin. Experimental results show that ourmodel consistently achieves the highest amino acid recovery rate, TM-score, andthe lowest RMSD among all competitors. These findings prove the capability ofour model to design protein sequences and structures that closely resembletheir natural counterparts. Furthermore, in-depth analysis further confirms ourmodel's ability to generate highly effective proteins capable of binding totheir target metallocofactors. We provide code, data and models in Github.</description><author>Zhenqiao Song, Yunlong Zhao, Wenxian Shi, Yang Yang, Lei Li</author><pubDate>Fri, 06 Oct 2023 17:08:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04343v1</guid></item><item><title>A Cluster-Based Opposition Differential Evolution Algorithm Boosted by a Local Search for ECG Signal Classification</title><link>http://arxiv.org/abs/2305.02731v2</link><description>Electrocardiogram (ECG) signals, which capture the heart's electricalactivity, are used to diagnose and monitor cardiac problems. The accurateclassification of ECG signals, particularly for distinguishing among varioustypes of arrhythmias and myocardial infarctions, is crucial for the earlydetection and treatment of heart-related diseases. This paper proposes a novelapproach based on an improved differential evolution (DE) algorithm for ECGsignal classification for enhancing the performance. In the initial stages ofour approach, the preprocessing step is followed by the extraction of severalsignificant features from the ECG signals. These extracted features are thenprovided as inputs to an enhanced multi-layer perceptron (MLP). While MLPs arestill widely used for ECG signal classification, using gradient-based trainingmethods, the most widely used algorithm for the training process, hassignificant disadvantages, such as the possibility of being stuck in localoptimums. This paper employs an enhanced differential evolution (DE) algorithmfor the training process as one of the most effective population-basedalgorithms. To this end, we improved DE based on a clustering-based strategy,opposition-based learning, and a local search. Clustering-based strategies canact as crossover operators, while the goal of the opposition operator is toimprove the exploration of the DE algorithm. The weights and biases found bythe improved DE algorithm are then fed into six gradient-based local searchalgorithms. In other words, the weights found by the DE are employed as aninitialization point. Therefore, we introduced six different algorithms for thetraining process (in terms of different local search algorithms). In anextensive set of experiments, we showed that our proposed training algorithmcould provide better results than the conventional training algorithms.</description><author>Mehran Pourvahab, Seyed Jalaleddin Mousavirad, Virginie Felizardo, Nuno Pombo, Henriques Zacarias, Hamzeh Mohammadigheymasi, Sebastião Pais, Seyed Nooreddin Jafari, Nuno M. Garcia</author><pubDate>Fri, 06 Oct 2023 17:03:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.02731v2</guid></item><item><title>Adaptive Federated Learning with Auto-Tuned Clients</title><link>http://arxiv.org/abs/2306.11201v2</link><description>Federated learning (FL) is a distributed machine learning framework where theglobal model of a central server is trained via multiple collaborative steps byparticipating clients without sharing their data. While being a flexibleframework, where the distribution of local data, participation rate, andcomputing power of each client can greatly vary, such flexibility gives rise tomany new challenges, especially in the hyperparameter tuning on the clientside. We propose $\Delta$-SGD, a simple step size rule for SGD that enableseach client to use its own step size by adapting to the local smoothness of thefunction each client is optimizing. We provide theoretical and empiricalresults where the benefit of the client adaptivity is shown in various FLscenarios.</description><author>Junhyung Lyle Kim, Mohammad Taha Toghani, César A. Uribe, Anastasios Kyrillidis</author><pubDate>Fri, 06 Oct 2023 17:02:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11201v2</guid></item><item><title>A Structured Matrix Method for Nonequispaced Neural Operators</title><link>http://arxiv.org/abs/2305.19663v3</link><description>The computational efficiency of many neural operators, widely used forlearning solutions of PDEs, relies on the fast Fourier transform (FFT) forperforming spectral computations. However, as FFT is limited to equispaced(rectangular) grids, this limits the efficiency of such neural operators whenapplied to problems where the input and output functions need to be processedon general non-equispaced point distributions. We address this issue byproposing a novel method that leverages batch matrix multiplications toefficiently construct Vandermonde-structured matrices and compute forward andinverse transforms, on arbitrarily distributed points. An efficientimplementation of such structured matrix methods is coupled with existingneural operator models to allow the processing of data on arbitrarynon-equispaced distributions of points. With extensive empirical evaluation, wedemonstrate that the proposed method allows one to extend neural operators tovery general point distributions with significant gains in training speed overbaselines, while retaining or improving accuracy.</description><author>Levi Lingsch, Mike Michelis, Emmanuel de Bezenac, Sirani M. Perera, Robert K. Katzschmann, Siddhartha Mishra</author><pubDate>Fri, 06 Oct 2023 16:59:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19663v3</guid></item><item><title>Applying Reinforcement Learning to Option Pricing and Hedging</title><link>http://arxiv.org/abs/2310.04336v1</link><description>This thesis provides an overview of the recent advances in reinforcementlearning in pricing and hedging financial instruments, with a primary focus ona detailed explanation of the Q-Learning Black Scholes approach, introduced byHalperin (2017). This reinforcement learning approach bridges the traditionalBlack and Scholes (1973) model with novel artificial intelligence algorithms,enabling option pricing and hedging in a completely model-free and data-drivenway. This paper also explores the algorithm's performance under different statevariables and scenarios for a European put option. The results reveal that themodel is an accurate estimator under different levels of volatility and hedgingfrequency. Moreover, this method exhibits robust performance across variouslevels of option's moneyness. Lastly, the algorithm incorporates proportionaltransaction costs, indicating diverse impacts on profit and loss, affected bydifferent statistical properties of the state variables.</description><author>Zoran Stoiljkovic</author><pubDate>Fri, 06 Oct 2023 16:59:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04336v1</guid></item><item><title>Saliency-Guided Hidden Associative Replay for Continual Learning</title><link>http://arxiv.org/abs/2310.04334v1</link><description>Continual Learning is a burgeoning domain in next-generation AI, focusing ontraining neural networks over a sequence of tasks akin to human learning. WhileCL provides an edge over traditional supervised learning, its central challengeremains to counteract catastrophic forgetting and ensure the retention of priortasks during subsequent learning. Amongst various strategies to tackle this,replay based methods have emerged as preeminent, echoing biological memorymechanisms. However, these methods are memory intensive, often preservingentire data samples, an approach inconsistent with humans selective memoryretention of salient experiences. While some recent works have explored thestorage of only significant portions of data in episodic memory, the inherentnature of partial data necessitates innovative retrieval mechanisms. Currentsolutions, like inpainting, approximate full data reconstruction from partialcues, a method that diverges from genuine human memory processes. Addressingthese nuances, this paper presents the Saliency Guided Hidden AssociativeReplay for Continual Learning. This novel framework synergizes associativememory with replay-based strategies. SHARC primarily archives salient datasegments via sparse memory encoding. Importantly, by harnessing associativememory paradigms, it introduces a content focused memory retrieval mechanism,promising swift and near-perfect recall, bringing CL a step closer to authentichuman memory processes. Extensive experimental results demonstrate theeffectiveness of our proposed method for various continual learning tasks.</description><author>Guangji Bai, Qilong Zhao, Xiaoyang Jiang, Yifei Zhang, Liang Zhao</author><pubDate>Fri, 06 Oct 2023 16:54:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04334v1</guid></item><item><title>NeuroSURF: Neural Uncertainty-aware Robust Surface Reconstruction</title><link>http://arxiv.org/abs/2306.02099v2</link><description>Neural implicit functions have become popular for representing surfacesbecause they offer an adaptive resolution and support arbitrary topologies.While previous works rely on ground truth point clouds, they often ignore theeffect of input quality and sampling methods on the reconstruction. In thispaper, we introduce NeuroSURF, which generates significantly improvedqualitative and quantitative reconstructions driven by a novel sampling andinterpolation technique. We show that employing a sampling technique thatconsiders the geometric characteristics of inputs can enhance the trainingprocess. To this end, we introduce a strategy that efficiently computesdifferentiable geometric features, namely, mean curvatures, to augment thesampling phase during the training period. Moreover, we augment the neuralimplicit surface representation with uncertainty, which offers insights intothe occupancy and reliability of the output signed distance value, therebyexpanding representation capabilities into open surfaces. Finally, wedemonstrate that NeuroSURF leads to state-of-the-art reconstructions on bothsynthetic and real-world data.</description><author>Lu Sang, Abhishek Saroha, Maolin Gao, Daniel Cremers</author><pubDate>Fri, 06 Oct 2023 16:46:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02099v2</guid></item><item><title>Robust Losses for Decision-Focused Learning</title><link>http://arxiv.org/abs/2310.04328v1</link><description>Optimization models used to make discrete decisions often contain uncertainparameters that are context-dependent and are estimated through prediction. Toaccount for the quality of the decision made based on the prediction,decision-focused learning (end-to-end predict-then-optimize) aims at trainingthe predictive model to minimize regret, i.e., the loss incurred by making asuboptimal decision. Despite the challenge of this loss function being possiblynon-convex and in general non-differentiable, effective gradient-based learningapproaches have been proposed to minimize the expected loss, using theempirical loss as a surrogate. However, empirical regret can be an ineffectivesurrogate because the uncertainty in the optimization model makes the empiricalregret unequal to the expected regret in expectation. To illustrate the impactof this inequality, we evaluate the effect of aleatoric and epistemicuncertainty on the accuracy of empirical regret as a surrogate. Next, wepropose three robust loss functions that more closely approximate expectedregret. Experimental results show that training two state-of-the-artdecision-focused learning approaches using robust regret losses improvestest-sample empirical regret in general while keeping computational timeequivalent relative to the number of training epochs.</description><author>Noah Schutte, Krzysztof Postek, Neil Yorke-Smith</author><pubDate>Fri, 06 Oct 2023 16:45:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04328v1</guid></item><item><title>Program Synthesis with Best-First Bottom-Up Search</title><link>http://arxiv.org/abs/2310.04327v1</link><description>Cost-guided bottom-up search (BUS) algorithms use a cost function to guidethe search to solve program synthesis tasks. In this paper, we show thatcurrent state-of-the-art cost-guided BUS algorithms suffer from a commonproblem: they can lose useful information given by the model and fail toperform the search in a best-first order according to a cost function. Weintroduce a novel best-first bottom-up search algorithm, which we call BeeSearch, that does not suffer information loss and is able to performcost-guided bottom-up synthesis in a best-first manner. Importantly, Bee Searchperforms best-first search with respect to the generation of programs, i.e., itdoes not even create in memory programs that are more expensive than thesolution program. It attains best-first ordering with respect to generation byperforming a search in an abstract space of program costs. We also introduce anew cost function that better uses the information provided by an existing costmodel. Empirical results on string manipulation and bit-vector tasks show thatBee Search can outperform existing cost-guided BUS approaches when employingmore complex domain-specific languages (DSLs); Bee Search and previousapproaches perform equally well with simpler DSLs. Furthermore, our new costfunction with Bee Search outperforms previous cost functions on stringmanipulation tasks.</description><author>Saqib Ameen, Levi H. S. Lelis</author><pubDate>Fri, 06 Oct 2023 16:44:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04327v1</guid></item><item><title>CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots</title><link>http://arxiv.org/abs/2307.11865v2</link><description>This work explores the capacity of large language models (LLMs) to addressproblems at the intersection of spatial planning and natural languageinterfaces for navigation.Our focus is on following relatively complexinstructions that are more akin to natural conversation than traditionalexplicit procedural directives seen in robotics. Unlike most prior work, wherenavigation directives are provided as imperative commands (e.g., go to thefridge), we examine implicit directives within conversational interactions. Weleverage the 3D simulator AI2Thor to create complex and repeatable scenarios atscale, and augment it by adding complex language queries for 40 object types.We demonstrate that a robot can better parse descriptive language queries thanexisting methods by using an LLM to interpret the user interaction in thecontext of a list of the objects in the scene.</description><author>Dmitriy Rivkin, Nikhil Kakodkar, Francois Hogan, Bobak H. Baghi, Gregory Dudek</author><pubDate>Fri, 06 Oct 2023 16:41:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11865v2</guid></item><item><title>Adjustable Robust Reinforcement Learning for Online 3D Bin Packing</title><link>http://arxiv.org/abs/2310.04323v1</link><description>Designing effective policies for the online 3D bin packing problem (3D-BPP)has been a long-standing challenge, primarily due to the unpredictable natureof incoming box sequences and stringent physical constraints. While currentdeep reinforcement learning (DRL) methods for online 3D-BPP have shownpromising results in optimizing average performance over an underlying boxsequence distribution, they often fail in real-world settings where someworst-case scenarios can materialize. Standard robust DRL algorithms tend tooverly prioritize optimizing the worst-case performance at the expense ofperformance under normal problem instance distribution. To address theseissues, we first introduce a permutation-based attacker to investigate thepractical robustness of both DRL-based and heuristic methods proposed forsolving online 3D-BPP. Then, we propose an adjustable robust reinforcementlearning (AR2L) framework that allows efficient adjustment of robustnessweights to achieve the desired balance of the policy's performance in averageand worst-case environments. Specifically, we formulate the objective functionas a weighted sum of expected and worst-case returns, and derive the lowerperformance bound by relating to the return under a mixture dynamics. Torealize this lower bound, we adopt an iterative procedure that searches for theassociated mixture dynamics and improves the corresponding policy. We integratethis procedure into two popular robust adversarial algorithms to develop theexact and approximate AR2L algorithms. Experiments demonstrate that AR2L isversatile in the sense that it improves policy robustness while maintaining anacceptable level of performance for the nominal case.</description><author>Yuxin Pan, Yize Chen, Fangzhen Lin</author><pubDate>Fri, 06 Oct 2023 16:34:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04323v1</guid></item><item><title>Latent Graph Inference with Limited Supervision</title><link>http://arxiv.org/abs/2310.04314v1</link><description>Latent graph inference (LGI) aims to jointly learn the underlying graphstructure and node representations from data features. However, existing LGImethods commonly suffer from the issue of supervision starvation, where massiveedge weights are learned without semantic supervision and do not contribute tothe training loss. Consequently, these supervision-starved weights, which maydetermine the predictions of testing samples, cannot be semantically optimal,resulting in poor generalization. In this paper, we observe that this issue isactually caused by the graph sparsification operation, which severely destroysthe important connections established between pivotal nodes and labeled ones.To address this, we propose to restore the corrupted affinities and replenishthe missed supervision for better LGI. The key challenge then lies inidentifying the critical nodes and recovering the corrupted affinities. Webegin by defining the pivotal nodes as $k$-hop starved nodes, which can beidentified based on a given adjacency matrix. Considering the highcomputational burden, we further present a more efficient alternative inspiredby CUR matrix decomposition. Subsequently, we eliminate the starved nodes byreconstructing the destroyed connections. Extensive experiments onrepresentative benchmarks demonstrate that reducing the starved nodesconsistently improves the performance of state-of-the-art LGI methods,especially under extremely limited supervision (6.12% improvement on Pubmedwith a labeling rate of only 0.3%).</description><author>Jianglin Lu, Yi Xu, Huan Wang, Yue Bai, Yun Fu</author><pubDate>Fri, 06 Oct 2023 16:22:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04314v1</guid></item><item><title>Large-Scale Korean Text Dataset for Classifying Biased Speech in Real-World Online Services</title><link>http://arxiv.org/abs/2310.04313v1</link><description>With the growth of online services, the need for advanced text classificationalgorithms, such as sentiment analysis and biased text detection, has becomeincreasingly evident. The anonymous nature of online services often leads tothe presence of biased and harmful language, posing challenges to maintainingthe health of online communities. This phenomenon is especially relevant inSouth Korea, where large-scale hate speech detection algorithms have not yetbeen broadly explored. In this paper, we introduce a new comprehensive,large-scale dataset collected from a well-known South Korean SNS platform. Ourproposed dataset provides annotations including (1) Preferences, (2)Profanities, and (3) Nine types of Bias for the text samples, enablingmulti-task learning for simultaneous classification of user-generated texts.Leveraging state-of-the-art BERT-based language models, our approach surpasseshuman-level accuracy across diverse classification tasks, as measured byvarious metrics. Beyond academic contributions, our work can provide practicalsolutions for real-world hate speech and bias mitigation, contributing directlyto the improvement of online community health. Our work provides a robustfoundation for future research aiming to improve the quality of onlinediscourse and foster societal well-being. All source codes and datasets arepublicly accessible at https://github.com/Dasol-Choi/KoMultiText.</description><author>Dasol Choi, Jooyoung Song, Eunsun Lee, Jinwoo Seo, Heejune Park, Dongbin Na</author><pubDate>Fri, 06 Oct 2023 16:19:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04313v1</guid></item><item><title>A Survey of Dataset Refinement for Problems in Computer Vision Datasets</title><link>http://arxiv.org/abs/2210.11717v2</link><description>Large-scale datasets have played a crucial role in the advancement ofcomputer vision. However, they often suffer from problems such as classimbalance, noisy labels, dataset bias, or high resource costs, which caninhibit model performance and reduce trustworthiness. With the advocacy ofdata-centric research, various data-centric solutions have been proposed tosolve the dataset problems mentioned above. They improve the quality ofdatasets by re-organizing them, which we call dataset refinement. In thissurvey, we provide a comprehensive and structured overview of recent advancesin dataset refinement for problematic computer vision datasets. Firstly, wesummarize and analyze the various problems encountered in large-scale computervision datasets. Then, we classify the dataset refinement algorithms into threecategories based on the refinement process: data sampling, data subsetselection, and active learning. In addition, we organize these datasetrefinement methods according to the addressed data problems and provide asystematic comparative description. We point out that these three types ofdataset refinement have distinct advantages and disadvantages for datasetproblems, which informs the choice of the data-centric method appropriate to aparticular research objective. Finally, we summarize the current literature andpropose potential future research topics.</description><author>Zhijing Wan, Zhixiang Wang, CheukTing Chung, Zheng Wang</author><pubDate>Fri, 06 Oct 2023 16:17:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.11717v2</guid></item><item><title>Distributed Deep Joint Source-Channel Coding with Decoder-Only Side Information</title><link>http://arxiv.org/abs/2310.04311v1</link><description>We consider low-latency image transmission over a noisy wireless channel whencorrelated side information is present only at the receiver side (the Wyner-Zivscenario). In particular, we are interested in developing practical schemesusing a data-driven joint source-channel coding (JSCC) approach, which has beenpreviously shown to outperform conventional separation-based approaches in thepractical finite blocklength regimes, and to provide graceful degradation withchannel quality. We propose a novel neural network architecture thatincorporates the decoder-only side information at multiple stages at thereceiver side. Our results demonstrate that the proposed method succeeds inintegrating the side information, yielding improved performance at all channelnoise levels in terms of the various distortion criteria considered here,especially at low channel signal-to-noise ratios (SNRs) and small bandwidthratios (BRs). We also provide the source code of the proposed method to enablefurther research and reproducibility of the results.</description><author>Selim F. Yilmaz, Ezgi Ozyilkan, Deniz Gunduz, Elza Erkip</author><pubDate>Fri, 06 Oct 2023 16:17:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04311v1</guid></item><item><title>FASER: Binary Code Similarity Search through the use of Intermediate Representations</title><link>http://arxiv.org/abs/2310.03605v2</link><description>Being able to identify functions of interest in cross-architecture softwareis useful whether you are analysing for malware, securing the software supplychain or conducting vulnerability research. Cross-Architecture Binary CodeSimilarity Search has been explored in numerous studies and has used a widerange of different data sources to achieve its goals. The data sourcestypically used draw on common structures derived from binaries such as functioncontrol flow graphs or binary level call graphs, the output of the disassemblyprocess or the outputs of a dynamic analysis approach. One data source whichhas received less attention is binary intermediate representations. BinaryIntermediate representations possess two interesting properties: they are crossarchitecture by their very nature and encode the semantics of a functionexplicitly to support downstream usage. Within this paper we propose Functionas a String Encoded Representation (FASER) which combines long documenttransformers with the use of intermediate representations to create a modelcapable of cross architecture function search without the need for manualfeature engineering, pre-training or a dynamic analysis step. We compare ourapproach against a series of baseline approaches for two tasks; A generalfunction search task and a targeted vulnerability search task. Our approachdemonstrates strong performance across both tasks, performing better than allbaseline approaches.</description><author>Josh Collyer, Tim Watson, Iain Phillips</author><pubDate>Fri, 06 Oct 2023 16:17:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03605v2</guid></item><item><title>Towards A Robust Group-level Emotion Recognition via Uncertainty-Aware Learning</title><link>http://arxiv.org/abs/2310.04306v1</link><description>Group-level emotion recognition (GER) is an inseparable part of humanbehavior analysis, aiming to recognize an overall emotion in a multi-personscene. However, the existing methods are devoted to combing diverse emotioncues while ignoring the inherent uncertainties under unconstrainedenvironments, such as congestion and occlusion occurring within a group.Additionally, since only group-level labels are available, inconsistent emotionpredictions among individuals in one group can confuse the network. In thispaper, we propose an uncertainty-aware learning (UAL) method to extract morerobust representations for GER. By explicitly modeling the uncertainty of eachindividual, we utilize stochastic embedding drawn from a Gaussian distributioninstead of deterministic point embedding. This representation captures theprobabilities of different emotions and generates diverse predictions throughthis stochasticity during the inference stage. Furthermore,uncertainty-sensitive scores are adaptively assigned as the fusion weights ofindividuals' face within each group. Moreover, we develop an image enhancementmodule to enhance the model's robustness against severe noise. The overallthree-branch model, encompassing face, object, and scene component, is guidedby a proportional-weighted fusion strategy and integrates the proposeduncertainty-aware method to produce the final group-level output. Experimentalresults demonstrate the effectiveness and generalization ability of our methodacross three widely used databases.</description><author>Qing Zhu, Qirong Mao, Jialin Zhang, Xiaohua Huang, Wenming Zheng</author><pubDate>Fri, 06 Oct 2023 16:05:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04306v1</guid></item><item><title>Coding by Design: GPT-4 empowers Agile Model Driven Development</title><link>http://arxiv.org/abs/2310.04304v1</link><description>Generating code from a natural language using Large Language Models (LLMs)such as ChatGPT, seems groundbreaking. Yet, with more extensive use, it'sevident that this approach has its own limitations. The inherent ambiguity ofnatural language presents challenges for complex software designs. Accordingly,our research offers an Agile Model-Driven Development (MDD) approach thatenhances code auto-generation using OpenAI's GPT-4. Our work emphasizes"Agility" as a significant contribution to the current MDD method, particularlywhen the model undergoes changes or needs deployment in a different programminglanguage. Thus, we present a case-study showcasing a multi-agent simulationsystem of an Unmanned Vehicle Fleet. In the first and second layer of ourapproach, we constructed a textual representation of the case-study usingUnified Model Language (UML) diagrams. In the next layer, we introduced twosets of constraints that minimize model ambiguity. Object Constraints Language(OCL) is applied to fine-tune the code constructions details, while FIPAontology is used to shape communication semantics and protocols. Ultimately,leveraging GPT-4, our last layer auto-generates code in both Java and Python.The Java code is deployed within the JADE framework, while the Python code isdeployed in PADE framework. Concluding our research, we engaged in acomprehensive evaluation of the generated code. From a behavioural standpoint,the auto-generated code aligned perfectly with the expected UML sequencediagram. Structurally, we compared the complexity of code derived from UMLdiagrams constrained solely by OCL to that influenced by both OCL andFIPA-ontology. Results indicate that ontology-constrained model produceinherently more intricate code, but it remains manageable and low-risk forfurther testing and maintenance.</description><author>Ahmed R. Sadik, Sebastian Brulin, Markus Olhofer</author><pubDate>Fri, 06 Oct 2023 16:05:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04304v1</guid></item><item><title>Knowledge Graphs for the Life Sciences: Recent Developments, Challenges and Opportunities</title><link>http://arxiv.org/abs/2309.17255v2</link><description>The term life sciences refers to the disciplines that study living organismsand life processes, and include chemistry, biology, medicine, and a range ofother related disciplines. Research efforts in life sciences are heavilydata-driven, as they produce and consume vast amounts of scientific data, muchof which is intrinsically relational and graph-structured. The volume of data and the complexity of scientific concepts and relationsreferred to therein promote the application of advanced knowledge-driventechnologies for managing and interpreting data, with the ultimate aim toadvance scientific discovery. In this survey and position paper, we discuss recent developments andadvances in the use of graph-based technologies in life sciences and set out avision for how these technologies will impact these fields into the future. Wefocus on three broad topics: the construction and management of KnowledgeGraphs (KGs), the use of KGs and associated technologies in the discovery ofnew knowledge, and the use of KGs in artificial intelligence applications tosupport explanations (explainable AI). We select a few exemplary use cases foreach topic, discuss the challenges and open research questions within thesetopics, and conclude with a perspective and outlook that summarizes theoverarching challenges and their potential solutions as a guide for futureresearch.</description><author>Jiaoyan Chen, Hang Dong, Janna Hastings, Ernesto Jiménez-Ruiz, Vanessa López, Pierre Monnin, Catia Pesquita, Petr Škoda, Valentina Tamma</author><pubDate>Fri, 06 Oct 2023 16:02:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17255v2</guid></item><item><title>Convergent ADMM Plug and Play PET Image Reconstruction</title><link>http://arxiv.org/abs/2310.04299v1</link><description>In this work, we investigate hybrid PET reconstruction algorithms based oncoupling a model-based variational reconstruction and the application of aseparately learnt Deep Neural Network operator (DNN) in an ADMM Plug and Playframework. Following recent results in optimization, fixed point convergence ofthe scheme can be achieved by enforcing an additional constraint on networkparameters during learning. We propose such an ADMM algorithm and show in arealistic [18F]-FDG synthetic brain exam that the proposed scheme indeed leadexperimentally to convergence to a meaningful fixed point. When the proposedconstraint is not enforced during learning of the DNN, the proposed ADMMalgorithm was observed experimentally not to converge.</description><author>Florent Sureau, Mahdi Latreche, Marion Savanier, Claude Comtat</author><pubDate>Fri, 06 Oct 2023 16:01:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04299v1</guid></item><item><title>On convex decision regions in deep network representations</title><link>http://arxiv.org/abs/2305.17154v2</link><description>Current work on human-machine alignment aims at understanding machine-learnedlatent spaces and their correspondence to human representations.G{\"a}rdenfors' conceptual spaces is a prominent framework for understandinghuman representations. Convexity of object regions in conceptual spaces isargued to promote generalizability, few-shot learning, and interpersonalalignment. Based on these insights, we investigate the notion of convexity ofconcept regions in machine-learned latent spaces. We develop a set of tools formeasuring convexity in sampled data and evaluate emergent convexity in layeredrepresentations of state-of-the-art deep networks. We show that convexity isrobust to basic re-parametrization and, hence, meaningful as a quality ofmachine-learned latent spaces. We find that approximate convexity is pervasivein neural representations in multiple application domains, including models ofimages, audio, human activity, text, and medical images. Generally, we observethat fine-tuning increases the convexity of label regions. We find evidencethat pretraining convexity of class label regions predicts subsequentfine-tuning performance.</description><author>Lenka Tětková, Thea Brüsch, Teresa Karen Scheidt, Fabian Martin Mager, Rasmus Ørtoft Aagaard, Jonathan Foldager, Tommy Sonne Alstrøm, Lars Kai Hansen</author><pubDate>Fri, 06 Oct 2023 15:58:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17154v2</guid></item><item><title>Identifying Representations for Intervention Extrapolation</title><link>http://arxiv.org/abs/2310.04295v1</link><description>The premise of identifiable and causal representation learning is to improvethe current representation learning paradigm in terms of generalizability orrobustness. Despite recent progress in questions of identifiability, moretheoretical results demonstrating concrete advantages of these methods fordownstream tasks are needed. In this paper, we consider the task ofintervention extrapolation: predicting how interventions affect an outcome,even when those interventions are not observed at training time, and show thatidentifiable representations can provide an effective solution to this taskeven if the interventions affect the outcome non-linearly. Our setup includesan outcome Y, observed features X, which are generated as a non-lineartransformation of latent features Z, and exogenous action variables A, whichinfluence Z. The objective of intervention extrapolation is to predict howinterventions on A that lie outside the training support of A affect Y. Here,extrapolation becomes possible if the effect of A on Z is linear and theresidual when regressing Z on A has full support. As Z is latent, we combinethe task of intervention extrapolation with identifiable representationlearning, which we call Rep4Ex: we aim to map the observed features X into asubspace that allows for non-linear extrapolation in A. We show using Wiener'sTauberian theorem that the hidden representation is identifiable up to anaffine transformation in Z-space, which is sufficient for interventionextrapolation. The identifiability is characterized by a novel constraintdescribing the linearity assumption of A on Z. Based on this insight, wepropose a method that enforces the linear invariance constraint and can becombined with any type of autoencoder. We validate our theoretical findingsthrough synthetic experiments and show that our approach succeeds in predictingthe effects of unseen interventions.</description><author>Sorawit Saengkyongam, Elan Rosenfeld, Pradeep Ravikumar, Niklas Pfister, Jonas Peters</author><pubDate>Fri, 06 Oct 2023 15:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04295v1</guid></item><item><title>Graph learning in robotics: a survey</title><link>http://arxiv.org/abs/2310.04294v1</link><description>Deep neural networks for graphs have emerged as a powerful tool for learningon complex non-euclidean data, which is becoming increasingly common for avariety of different applications. Yet, although their potential has beenwidely recognised in the machine learning community, graph learning is largelyunexplored for downstream tasks such as robotics applications. To fully unlocktheir potential, hence, we propose a review of graph neural architectures froma robotics perspective. The paper covers the fundamentals of graph-basedmodels, including their architecture, training procedures, and applications. Italso discusses recent advancements and challenges that arise in appliedsettings, related for example to the integration of perception,decision-making, and control. Finally, the paper provides an extensive reviewof various robotic applications that benefit from learning on graph structures,such as bodies and contacts modelling, robotic manipulation, actionrecognition, fleet motion planning, and many more. This survey aims to providereaders with a thorough understanding of the capabilities and limitations ofgraph neural architectures in robotics, and to highlight potential avenues forfuture research.</description><author>Francesca Pistilli, Giuseppe Averta</author><pubDate>Fri, 06 Oct 2023 15:52:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04294v1</guid></item><item><title>Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets</title><link>http://arxiv.org/abs/2310.04292v1</link><description>Recently, pre-trained foundation models have enabled significant advancementsin multiple fields. In molecular machine learning, however, where datasets areoften hand-curated, and hence typically small, the lack of datasets withlabeled features, and codebases to manage those datasets, has hindered thedevelopment of foundation models. In this work, we present seven novel datasetscategorized by size into three distinct categories: ToyMix, LargeMix andUltraLarge. These datasets push the boundaries in both the scale and thediversity of supervised labels for molecular learning. They cover nearly 100million molecules and over 3000 sparsely defined tasks, totaling more than 13billion individual labels of both quantum and biological nature. In comparison,our datasets contain 300 times more data points than the widely used OGB-LSCPCQM4Mv2 dataset, and 13 times more than the quantum-only QM1B dataset. Inaddition, to support the development of foundational models based on ourproposed datasets, we present the Graphium graph machine learning library whichsimplifies the process of building and training molecular machine learningmodels for multi-task and multi-level molecular datasets. Finally, we present arange of baseline results as a starting point of multi-task and multi-leveltraining on these datasets. Empirically, we observe that performance onlow-resource biological datasets show improvement by also training on largeamounts of quantum data. This indicates that there may be potential inmulti-task and multi-level training of a foundation model and fine-tuning it toresource-constrained downstream tasks.</description><author>Dominique Beaini, Shenyang Huang, Joao Alex Cunha, Gabriela Moisescu-Pareja, Oleksandr Dymov, Samuel Maddrell-Mander, Callum McLean, Frederik Wenkel, Luis Müller, Jama Hussein Mohamud, Ali Parviz, Michael Craig, Michał Koziarski, Jiarui Lu, Zhaocheng Zhu, Cristian Gabellini, Kerstin Klaser, Josef Dean, Cas Wognum, Maciej Sypetkowski, Guillaume Rabusseau, Reihaneh Rabbany, Jian Tang, Christopher Morris, Mirco Ravanelli, Guy Wolf, Prudencio Tossou, Hadrien Mary, Therence Bois, Andrew Fitzgibbon, Błażej Banaszewski, Chad Martin, Dominic Masters</author><pubDate>Fri, 06 Oct 2023 15:51:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04292v1</guid></item><item><title>EvoX: A Distributed GPU-accelerated Framework for Scalable Evolutionary Computation</title><link>http://arxiv.org/abs/2301.12457v8</link><description>Inspired by natural evolutionary processes, Evolutionary Computation (EC) hasestablished itself as a cornerstone of Artificial Intelligence. EC possessesdistinctive attributes, including adaptability and the capability to exploreexpansive problem spaces, making it invaluable in domains that requireintricate black-box optimization. Recently, with the surge in data-intensiveapplications and large-scale complex systems, the demand for scalable ECsolutions has grown significantly. However, many existing EC libraries, whichwere originally designed for modest scales, fall short in catering to theheightened demands of modern problems. While the advent of some pioneeringGPU-accelerated EC libraries is a step forward, they too grapple withlimitations, particularly in terms of flexibility and architectural robustness.To address these limitations, we introduce EvoX: a computing framework tailoredfor automated, distributed, and heterogeneous execution of EC algorithms. Atthe core of EvoX lies a functional programming model that simplifies thedevelopment of parallelized EC algorithms, seamlessly integrated with ahigh-performance computation model designed specifically for distributedGPU-accelerated execution. Building upon foundation, we have crafted anextensive library comprising a wide spectrum of 45 EC algorithms for bothsingle- and multi-objective optimization. Furthermore, the library offerscomprehensive support for a diverse set of benchmark problems, ranging fromdozens of numerical test functions to hundreds of neuroevolution andreinforcement learning tasks/environments. Through extensive experiments acrossa range of problem scenarios and hardware configurations, EvoX has demonstratedrobust system and model performances. EvoX is open-source and accessible at:https://github.com/EMI-Group/EvoX.</description><author>Beichen Huang, Ran Cheng, Zhuozhao Li, Yaochu Jin, Kay Chen Tan</author><pubDate>Fri, 06 Oct 2023 15:51:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12457v8</guid></item><item><title>Searching for Optimal Runtime Assurance via Reachability and Reinforcement Learning</title><link>http://arxiv.org/abs/2310.04288v1</link><description>A runtime assurance system (RTA) for a given plant enables the exercise of anuntrusted or experimental controller while assuring safety with a backup (orsafety) controller. The relevant computational design problem is to create alogic that assures safety by switching to the safety controller as needed,while maximizing some performance criteria, such as the utilization of theuntrusted controller. Existing RTA design strategies are well-known to beoverly conservative and, in principle, can lead to safety violations. In thispaper, we formulate the optimal RTA design problem and present a new approachfor solving it. Our approach relies on reward shaping and reinforcementlearning. It can guarantee safety and leverage machine learning technologiesfor scalability. We have implemented this algorithm and present experimentalresults comparing our approach with state-of-the-art reachability andsimulation-based RTA approaches in a number of scenarios using aircraft modelsin 3D space with complex safety requirements. Our approach can guarantee safetywhile increasing utilization of the experimental controller over existingapproaches.</description><author>Kristina Miller, Christopher K. Zeitler, William Shen, Kerianne Hobbs, Sayan Mitra, John Schierman, Mahesh Viswanathan</author><pubDate>Fri, 06 Oct 2023 15:45:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04288v1</guid></item><item><title>De-Identification of French Unstructured Clinical Notes for Machine Learning Tasks</title><link>http://arxiv.org/abs/2209.09631v2</link><description>Unstructured textual data are at the heart of health systems: liaison lettersbetween doctors, operating reports, coding of procedures according to theICD-10 standard, etc. The details included in these documents make it possibleto get to know the patient better, to better manage him or her, to better studythe pathologies, to accurately remunerate the associated medical acts\ldots Allthis seems to be (at least partially) within reach of today by artificialintelligence techniques. However, for obvious reasons of privacy protection,the designers of these AIs do not have the legal right to access thesedocuments as long as they contain identifying data. De-identifying thesedocuments, i.e. detecting and deleting all identifying information present inthem, is a legally necessary step for sharing this data between twocomplementary worlds. Over the last decade, several proposals have been made tode-identify documents, mainly in English. While the detection scores are oftenhigh, the substitution methods are often not very robust to attack. In French,very few methods are based on arbitrary detection and/or substitution rules. Inthis paper, we propose a new comprehensive de-identification method dedicatedto French-language medical documents. Both the approach for the detection ofidentifying elements (based on deep learning) and their substitution (based ondifferential privacy) are based on the most proven existing approaches. Theresult is an approach that effectively protects the privacy of the patients atthe heart of these medical documents. The whole approach has been evaluated ona French language medical dataset of a French public hospital and the resultsare very encouraging.</description><author>Yakini Tchouka, Jean-François Couchot, Maxime Coulmeau, David Laiymani, Philippe Selles, Azzedine Rahmani</author><pubDate>Fri, 06 Oct 2023 15:40:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.09631v2</guid></item><item><title>A Large-Scale 3D Face Mesh Video Dataset via Neural Re-parameterized Optimization</title><link>http://arxiv.org/abs/2310.03205v2</link><description>We propose NeuFace, a 3D face mesh pseudo annotation method on videos vianeural re-parameterized optimization. Despite the huge progress in 3D facereconstruction methods, generating reliable 3D face labels for in-the-wilddynamic videos remains challenging. Using NeuFace optimization, we annotate theper-view/-frame accurate and consistent face meshes on large-scale face videos,called the NeuFace-dataset. We investigate how neural re-parameterization helpsto reconstruct image-aligned facial details on 3D meshes via gradient analysis.By exploiting the naturalness and diversity of 3D faces in our dataset, wedemonstrate the usefulness of our dataset for 3D face-related tasks: improvingthe reconstruction accuracy of an existing 3D face reconstruction model andlearning 3D facial motion prior. Code and datasets will be available athttps://neuface-dataset.github.io.</description><author>Kim Youwang, Lee Hyun, Kim Sung-Bin, Suekyeong Nam, Janghoon Ju, Tae-Hyun Oh</author><pubDate>Fri, 06 Oct 2023 15:37:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03205v2</guid></item><item><title>Assessing Robustness via Score-Based Adversarial Image Generation</title><link>http://arxiv.org/abs/2310.04285v1</link><description>Most adversarial attacks and defenses focus on perturbations within small$\ell_p$-norm constraints. However, $\ell_p$ threat models cannot capture allrelevant semantic-preserving perturbations, and hence, the scope of robustnessevaluations is limited. In this work, we introduce Score-Based AdversarialGeneration (ScoreAG), a novel framework that leverages the advancements inscore-based generative models to generate adversarial examples beyond$\ell_p$-norm constraints, so-called unrestricted adversarial examples,overcoming their limitations. Unlike traditional methods, ScoreAG maintains thecore semantics of images while generating realistic adversarial examples,either by transforming existing images or synthesizing new ones entirely fromscratch. We further exploit the generative capability of ScoreAG to purifyimages, empirically enhancing the robustness of classifiers. Our extensiveempirical evaluation demonstrates that ScoreAG matches the performance ofstate-of-the-art attacks and defenses across multiple benchmarks. This workhighlights the importance of investigating adversarial examples bounded bysemantics rather than $\ell_p$-norm constraints. ScoreAG represents animportant step towards more encompassing robustness assessments.</description><author>Marcel Kollovieh, Lukas Gosch, Yan Scholten, Marten Lienen, Stephan Günnemann</author><pubDate>Fri, 06 Oct 2023 15:37:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04285v1</guid></item><item><title>On the Error-Propagation of Inexact Deflation for Principal Component Analysis</title><link>http://arxiv.org/abs/2310.04283v1</link><description>Principal Component Analysis (PCA) is a popular tool in data analysis,especially when the data is high-dimensional. PCA aims to find subspaces,spanned by the so-called \textit{principal components}, that best explain thevariance in the dataset. The deflation method is a popular meta-algorithm --used to discover such subspaces -- that sequentially finds individual principalcomponents, starting from the most important one and working its way towardsthe less important ones. However, due to its sequential nature, the numericalerror introduced by not estimating principal components exactly -- e.g., due tonumerical approximations through this process -- propagates, as deflationproceeds. To the best of our knowledge, this is the first work thatmathematically characterizes the error propagation of the inexact deflationmethod, and this is the key contribution of this paper. We provide two mainresults: $i)$ when the sub-routine for finding the leading eigenvector isgeneric, and $ii)$ when power iteration is used as the sub-routine. In thelatter case, the additional directional information from power iteration allowsus to obtain a tighter error bound than the analysis of the sub-routineagnostic case. As an outcome, we provide explicit characterization on how theerror progresses and affects subsequent principal component estimations forthis fundamental problem.</description><author>Fangshuo Liao, Junhyung Lyle Kim, Cruz Barnum, Anastasios Kyrillidis</author><pubDate>Fri, 06 Oct 2023 15:33:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04283v1</guid></item><item><title>Model-based causal feature selection for general response types</title><link>http://arxiv.org/abs/2309.12833v2</link><description>Discovering causal relationships from observational data is a fundamental yetchallenging task. Invariant causal prediction (ICP, Peters et al., 2016) is amethod for causal feature selection which requires data from heterogeneoussettings and exploits that causal models are invariant. ICP has been extendedto general additive noise models and to nonparametric settings usingconditional independence tests. However, the latter often suffer from low power(or poor type I error control) and additive noise models are not suitable forapplications in which the response is not measured on a continuous scale, butreflects categories or counts. Here, we develop transformation-model (TRAM)based ICP, allowing for continuous, categorical, count-type, anduninformatively censored responses (these model classes, generally, do notallow for identifiability when there is no exogenous heterogeneity). As aninvariance test, we propose TRAM-GCM based on the expected conditionalcovariance between environments and score residuals with uniform asymptoticlevel guarantees. For the special case of linear shift TRAMs, we also considerTRAM-Wald, which tests invariance based on the Wald statistic. We provide anopen-source R package 'tramicp' and evaluate our approach on simulated data andin a case study investigating causal features of survival in critically illpatients.</description><author>Lucas Kook, Sorawit Saengkyongam, Anton Rask Lundborg, Torsten Hothorn, Jonas Peters</author><pubDate>Fri, 06 Oct 2023 15:27:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.12833v2</guid></item><item><title>From task structures to world models: What do LLMs know?</title><link>http://arxiv.org/abs/2310.04276v1</link><description>In what sense does a large language model have knowledge? The answer to thisquestion extends beyond the capabilities of a particular AI system, andchallenges our assumptions about the nature of knowledge and intelligence. Weanswer by granting LLMs "instrumental knowledge"; knowledge defined by acertain set of abilities. We then ask how such knowledge is related to the moreordinary, "worldly" knowledge exhibited by human agents, and explore this interms of the degree to which instrumental knowledge can be said to incorporatethe structured world models of cognitive science. We discuss ways LLMs couldrecover degrees of worldly knowledge, and suggest such recovery will begoverned by an implicit, resource-rational tradeoff between world models andtask demands.</description><author>Ilker Yildirim, L. A. Paul</author><pubDate>Fri, 06 Oct 2023 15:21:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04276v1</guid></item><item><title>Learning Robust, Agile, Natural Legged Locomotion Skills in the Wild</title><link>http://arxiv.org/abs/2304.10888v3</link><description>Recently, reinforcement learning has become a promising and polular solutionfor robot legged locomotion. Compared to model-based control, reinforcementlearning based controllers can achieve better robustness against uncertaintiesof environments through sim-to-real learning. However, the correspondinglearned gaits are in general overly conservative and unatural. In this paper,we propose a new framework for learning robust, agile and natural leggedlocomotion skills over challenging terrain. We incorporate an adversarialtraining branch based on real animal locomotion data upon a teacher-studenttraining pipeline for robust sim-to-real transfer. Empirical results on bothsimulation and real world of a quadruped robot demonstrate that our proposedalgorithm enables robustly traversing challenging terrains such as stairs,rocky ground and slippery floor with only proprioceptive perception. Meanwhile,the gaits are more agile, natural, and energy efficient compared to thebaselines. Both qualitative and quantitative results are presented in thispaper.</description><author>Yikai Wang, Zheyuan Jiang, Jianyu Chen</author><pubDate>Fri, 06 Oct 2023 15:17:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10888v3</guid></item><item><title>Compositional Servoing by Recombining Demonstrations</title><link>http://arxiv.org/abs/2310.04271v1</link><description>Learning-based manipulation policies from image inputs often show weak tasktransfer capabilities. In contrast, visual servoing methods allow efficienttask transfer in high-precision scenarios while requiring only a fewdemonstrations. In this work, we present a framework that formulates the visualservoing task as graph traversal. Our method not only extends the robustness ofvisual servoing, but also enables multitask capability based on a fewtask-specific demonstrations. We construct demonstration graphs by splittingexisting demonstrations and recombining them. In order to traverse thedemonstration graph in the inference case, we utilize a similarity functionthat helps select the best demonstration for a specific task. This enables usto compute the shortest path through the graph. Ultimately, we show thatrecombining demonstrations leads to higher task-respective success. We presentextensive simulation and real-world experimental results that demonstrate theefficacy of our approach.</description><author>Max Argus, Abhijeet Nayak, Martin Büchner, Silvio Galesso, Abhinav Valada, Thomas Brox</author><pubDate>Fri, 06 Oct 2023 15:16:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04271v1</guid></item><item><title>A Comprehensive Evaluation of Large Language Models on Benchmark Biomedical Text Processing Tasks</title><link>http://arxiv.org/abs/2310.04270v1</link><description>Recently, Large Language Models (LLM) have demonstrated impressive capabilityto solve a wide range of tasks. However, despite their success across varioustasks, no prior work has investigated their capability in the biomedical domainyet. To this end, this paper aims to evaluate the performance of LLMs onbenchmark biomedical tasks. For this purpose, we conduct a comprehensiveevaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets.To the best of our knowledge, this is the first work that conducts an extensiveevaluation and comparison of various LLMs in the biomedical domain.Interestingly, we find based on our evaluation that in biomedical datasets thathave smaller training sets, zero-shot LLMs even outperform the currentstate-of-the-art fine-tuned biomedical models. This suggests that pretrainingon large text corpora makes LLMs quite specialized even in the biomedicaldomain. We also find that not a single LLM can outperform other LLMs in alltasks, with the performance of different LLMs may vary depending on the task.While their performance is still quite poor in comparison to the biomedicalmodels that were fine-tuned on large training sets, our findings demonstratethat LLMs have the potential to be a valuable tool for various biomedical tasksthat lack large annotated data.</description><author>Israt Jahan, Md Tahmid Rahman Laskar, Chun Peng, Jimmy Huang</author><pubDate>Fri, 06 Oct 2023 15:16:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04270v1</guid></item><item><title>CancerUniT: Towards a Single Unified Model for Effective Detection, Segmentation, and Diagnosis of Eight Major Cancers Using a Large Collection of CT Scans</title><link>http://arxiv.org/abs/2301.12291v2</link><description>Human readers or radiologists routinely perform full-body multi-organmulti-disease detection and diagnosis in clinical practice, while most medicalAI systems are built to focus on single organs with a narrow list of a fewdiseases. This might severely limit AI's clinical adoption. A certain number ofAI models need to be assembled non-trivially to match the diagnostic process ofa human reading a CT scan. In this paper, we construct a Unified TumorTransformer (CancerUniT) model to jointly detect tumor existence &amp; location anddiagnose tumor characteristics for eight major cancers in CT scans. CancerUniTis a query-based Mask Transformer model with the output of multi-tumorprediction. We decouple the object queries into organ queries, tumor detectionqueries and tumor diagnosis queries, and further establish hierarchicalrelationships among the three groups. This clinically-inspired architectureeffectively assists inter- and intra-organ representation learning of tumorsand facilitates the resolution of these complex, anatomically relatedmulti-organ cancer image reading tasks. CancerUniT is trained end-to-end usinga curated large-scale CT images of 10,042 patients including eight major typesof cancers and occurring non-cancer tumors (all are pathology-confirmed with 3Dtumor masks annotated by radiologists). On the test set of 631 patients,CancerUniT has demonstrated strong performance under a set of clinicallyrelevant evaluation metrics, substantially outperforming both multi-diseasemethods and an assembly of eight single-organ expert models in tumor detection,segmentation, and diagnosis. This moves one step closer towards a universalhigh performance cancer screening tool.</description><author>Jieneng Chen, Yingda Xia, Jiawen Yao, Ke Yan, Jianpeng Zhang, Le Lu, Fakai Wang, Bo Zhou, Mingyan Qiu, Qihang Yu, Mingze Yuan, Wei Fang, Yuxing Tang, Minfeng Xu, Jian Zhou, Yuqian Zhao, Qifeng Wang, Xianghua Ye, Xiaoli Yin, Yu Shi, Xin Chen, Jingren Zhou, Alan Yuille, Zaiyi Liu, Ling Zhang</author><pubDate>Fri, 06 Oct 2023 15:14:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12291v2</guid></item><item><title>DRIFT: Deep Reinforcement Learning for Intelligent Floating Platforms Trajectories</title><link>http://arxiv.org/abs/2310.04266v1</link><description>This investigation introduces a novel deep reinforcement learning-based suiteto control floating platforms in both simulated and real-world environments.Floating platforms serve as versatile test-beds to emulate microgravityenvironments on Earth. Our approach addresses the system and environmentaluncertainties in controlling such platforms by training policies capable ofprecise maneuvers amid dynamic and unpredictable conditions. Leveragingstate-of-the-art deep reinforcement learning techniques, our suite achievesrobustness, adaptability, and good transferability from simulation to reality.Our Deep Reinforcement Learning (DRL) framework provides advantages such asfast training times, large-scale testing capabilities, rich visualizationoptions, and ROS bindings for integration with real-world robotic systems.Beyond policy development, our suite provides a comprehensive platform forresearchers, offering open-access athttps://github.com/elharirymatteo/RANS/tree/ICRA24.</description><author>Matteo El-Hariry, Antoine Richard, Vivek Muralidharan, Baris Can Yalcin, Matthieu Geist, Miguel Olivares-Mendez</author><pubDate>Fri, 06 Oct 2023 15:11:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04266v1</guid></item><item><title>C(NN)FD -- deep learning predictions of tip clearance variations on multi-stage axial compressors aerodynamic performance</title><link>http://arxiv.org/abs/2310.04264v1</link><description>Application of deep learning methods to physical simulations such as CFD(Computational Fluid Dynamics), have been so far of limited industrialrelevance. This paper demonstrates the development and application of a deeplearning framework for real-time predictions of the impact of tip clearancevariations on the aerodynamic performance of multi-stage axial compressors ingas turbines. The proposed C(NN)FD architecture is proven to be scalable toindustrial applications, and achieves in real-time accuracy comparable to theCFD benchmark. The deployed model, is readily integrated within themanufacturing and build process of gas turbines, thus providing the opportunityto analytically assess the impact on performance and potentially reducerequirements for expensive physical tests.</description><author>Giuseppe Bruni, Sepehr Maleki, Senthil K. Krishnababu</author><pubDate>Fri, 06 Oct 2023 15:11:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04264v1</guid></item><item><title>Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making</title><link>http://arxiv.org/abs/2310.03022v2</link><description>The recent success of Transformer in natural language processing has sparkedits use in various domains. In offline reinforcement learning (RL), DecisionTransformer (DT) is emerging as a promising model based on Transformer.However, we discovered that the attention module of DT is not appropriate tocapture the inherent local dependence pattern in trajectories of RL modeled asa Markov decision process. To overcome the limitations of DT, we propose anovel action sequence predictor, named Decision ConvFormer (DC), based on thearchitecture of MetaFormer, which is a general structure to process multipleentities in parallel and understand the interrelationship among the multipleentities. DC employs local convolution filtering as the token mixer and caneffectively capture the inherent local associations of the RL dataset. Inextensive experiments, DC achieved state-of-the-art performance across variousstandard RL benchmarks while requiring fewer resources. Furthermore, we showthat DC better understands the underlying meaning in data and exhibits enhancedgeneralization capability.</description><author>Jeonghye Kim, Suyoung Lee, Woojun Kim, Youngchul Sung</author><pubDate>Fri, 06 Oct 2023 15:04:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03022v2</guid></item><item><title>On Solving Close Enough Orienteering Problem with Overlapped Neighborhoods</title><link>http://arxiv.org/abs/2310.04257v1</link><description>The Close Enough Traveling Salesman Problem (CETSP) is a well-known variantof the classic Traveling Salesman Problem whereby the agent may complete itsmission at any point within a target neighborhood. Heuristics based onoverlapped neighborhoods, known as Steiner Zones (SZ), have gained attention inaddressing CETSPs. While SZs offer effective approximations to the originalgraph, their inherent overlap imposes constraints on the search space,potentially conflicting with global optimization objectives. Here we presentthe Close Enough Orienteering Problem with Non-uniform Neighborhoods (CEOP-N),which extends CETSP by introducing variable prize attributes and non-uniformcost considerations for prize collection. To tackle CEOP-N, we develop a newapproach featuring a Randomized Steiner Zone Discretization (RSZD) schemecoupled with a hybrid algorithm based on Particle Swarm Optimization (PSO) andAnt Colony System (ACS) - CRaSZe-AntS. The RSZD scheme identifies sub-regionsfor PSO exploration, and ACS determines the discrete visiting sequence. Weevaluate the RSZD's discretization performance on CEOP instances derived fromestablished CETSP instances, and compare CRaSZe-AntS against the most relevantstate-of-the-art heuristic focused on single-neighborhood optimization forCEOP. We also compare the performance of the interior search within SZs and theboundary search on individual neighborhoods in the context of CEOP-N. Ourresults show CRaSZe-AntS can yield comparable solution quality withsignificantly reduced computation time compared to the single-neighborhoodstrategy, where we observe an averaged 140.44% increase in prize collection and55.18% reduction of execution time. CRaSZe-AntS is thus highly effective insolving emerging CEOP-N, examples of which include truck-and-drone deliveryscenarios.</description><author>Qiuchen Qian, Yanran Wang, David Boyle</author><pubDate>Fri, 06 Oct 2023 15:02:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04257v1</guid></item><item><title>Ultra Dual-Path Compression For Joint Echo Cancellation And Noise Suppression</title><link>http://arxiv.org/abs/2308.11053v2</link><description>Echo cancellation and noise reduction are essential for full-duplexcommunication, yet most existing neural networks have high computational costsand are inflexible in tuning model complexity. In this paper, we introducetime-frequency dual-path compression to achieve a wide range of compressionratios on computational cost. Specifically, for frequency compression,trainable filters are used to replace manually designed filters for dimensionreduction. For time compression, only using frame skipped prediction causeslarge performance degradation, which can be alleviated by a post-processingnetwork with full sequence modeling. We have found that under fixed compressionratios, dual-path compression combining both the time and frequency methodswill give further performance improvement, covering compression ratios from 4xto 32x with little model size change. Moreover, the proposed models showcompetitive performance compared with fast FullSubNet and DeepFilterNet. A demopage can be found athangtingchen.github.io/ultra_dual_path_compression.github.io/.</description><author>Hangting Chen, Jianwei Yu, Yi Luo, Rongzhi Gu, Weihua Li, Zhuocheng Lu, Chao Weng</author><pubDate>Fri, 06 Oct 2023 15:01:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11053v2</guid></item><item><title>Collaborative Camouflaged Object Detection: A Large-Scale Dataset and Benchmark</title><link>http://arxiv.org/abs/2310.04253v1</link><description>In this paper, we provide a comprehensive study on a new task calledcollaborative camouflaged object detection (CoCOD), which aims tosimultaneously detect camouflaged objects with the same properties from a groupof relevant images. To this end, we meticulously construct the firstlarge-scale dataset, termed CoCOD8K, which consists of 8,528 high-quality andelaborately selected images with object mask annotations, covering 5superclasses and 70 subclasses. The dataset spans a wide range of natural andartificial camouflage scenes with diverse object appearances and backgrounds,making it a very challenging dataset for CoCOD. Besides, we propose the firstbaseline model for CoCOD, named bilateral-branch network (BBNet), whichexplores and aggregates co-camouflaged cues within a single image and betweenimages within a group, respectively, for accurate camouflaged object detectionin given images. This is implemented by an inter-image collaborative featureexploration (CFE) module, an intra-image object feature search (OFS) module,and a local-global refinement (LGR) module. We benchmark 18 state-of-the-artmodels, including 12 COD algorithms and 6 CoSOD algorithms, on the proposedCoCOD8K dataset under 5 widely used evaluation metrics. Extensive experimentsdemonstrate the effectiveness of the proposed method and the significantlysuperior performance compared to other competitors. We hope that our proposeddataset and model will boost growth in the COD community. The dataset, model,and results will be available at: https://github.com/zc199823/BBNet--CoCOD.</description><author>Cong Zhang, Hongbo Bi, Tian-Zhu Xiang, Ranwan Wu, Jinghui Tong, Xiufang Wang</author><pubDate>Fri, 06 Oct 2023 14:51:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04253v1</guid></item><item><title>Neighborhood Homophily-based Graph Convolutional Network</title><link>http://arxiv.org/abs/2301.09851v3</link><description>Graph neural networks (GNNs) have been proved powerful in graph-orientedtasks. However, many real-world graphs are heterophilous, challenging thehomophily assumption of classical GNNs. To solve the universality problem, manystudies deepen networks or concatenate intermediate representations, which doesnot inherently change neighbor aggregation and introduces noise. Recent studiespropose new metrics to characterize the homophily, but rarely consider thecorrelation of the proposed metrics and models. In this paper, we first designa new metric, Neighborhood Homophily (\textit{NH}), to measure the labelcomplexity or purity in node neighborhoods. Furthermore, we incorporate themetric into the classical graph convolutional network (GCN) architecture andpropose \textbf{N}eighborhood \textbf{H}omophily-based \textbf{G}raph\textbf{C}onvolutional \textbf{N}etwork (\textbf{NHGCN}). In this framework,neighbors are grouped by estimated \textit{NH} values and aggregated fromdifferent channels, and the resulting node predictions are then used in turn toestimate and update \textit{NH} values. The two processes of metric estimationand model inference are alternately optimized to achieve better nodeclassification. NHGCN achieves top overall performance on both homophilous andheterophilous benchmarks, with an improvement of up to 7.4\% compared to thecurrent SOTA methods.</description><author>Shengbo Gong, Jiajun Zhou, Chenxuan Xie, Qi Xuan</author><pubDate>Fri, 06 Oct 2023 14:45:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.09851v3</guid></item><item><title>Semantic segmentation of longitudinal thermal images for identification of hot and cool spots in urban areas</title><link>http://arxiv.org/abs/2310.04247v1</link><description>This work presents the analysis of semantically segmented, longitudinally,and spatially rich thermal images collected at the neighborhood scale toidentify hot and cool spots in urban areas. An infrared observatory wasoperated over a few months to collect thermal images of different types ofbuildings on the educational campus of the National University of Singapore. Asubset of the thermal image dataset was used to train state-of-the-art deeplearning models to segment various urban features such as buildings,vegetation, sky, and roads. It was observed that the U-Net segmentation modelwith `resnet34' CNN backbone has the highest mIoU score of 0.99 on the testdataset, compared to other models such as DeepLabV3, DeeplabV3+, FPN, andPSPnet. The masks generated using the segmentation models were then used toextract the temperature from thermal images and correct for differences in theemissivity of various urban features. Further, various statistical measure ofthe temperature extracted using the predicted segmentation masks is shown toclosely match the temperature extracted using the ground truth masks. Finally,the masks were used to identify hot and cool spots in the urban feature atvarious instances of time. This forms one of the very few studies demonstratingthe automated analysis of thermal images, which can be of potential use tourban planners for devising mitigation strategies for reducing the urban heatisland (UHI) effect, improving building energy efficiency, and maximizingoutdoor thermal comfort.</description><author>Vasantha Ramani, Pandarasamy Arjunan, Kameshwar Poolla, Clayton Miller</author><pubDate>Fri, 06 Oct 2023 14:41:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04247v1</guid></item><item><title>Vector Space Semantics for Lambek Calculus with Soft Subexponentials</title><link>http://arxiv.org/abs/2111.11331v3</link><description>We develop a vector space semantics for Lambek Calculus with SoftSubexponentials, apply the calculus to construct compositional vectorinterpretations for parasitic gap noun phrases and discourse units withanaphora and ellipsis, and experiment with the constructions in adistributional sentence similarity task. As opposed to previous work, whichused Lambek Calculus with a Relevant Modality the calculus used in this paperuses a bounded version of the modality and is decidable. The vector spacesemantics of this new modality allows us to meaningfully define contraction asprojection and provide a linear theory behind what we could previously onlyachieve via nonlinear maps.</description><author>Lachlan McPheat, Hadi Wazni, Mehrnoosh Sadrzadeh</author><pubDate>Fri, 06 Oct 2023 14:41:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.11331v3</guid></item><item><title>Leveraging Herpangina Data to Enhance Hospital-level Prediction of Hand-Foot-and-Mouth Disease Admissions Using UPTST</title><link>http://arxiv.org/abs/2309.14674v2</link><description>Outbreaks of hand-foot-and-mouth disease(HFMD) have been associated withsignificant morbidity and, in severe cases, mortality. Accurate forecasting ofdaily admissions of pediatric HFMD patients is therefore crucial for aiding thehospital in preparing for potential outbreaks and mitigating nosocomialtransmissions. To address this pressing need, we propose a noveltransformer-based model with a U-net shape, utilizing the patching strategy andthe joint prediction strategy that capitalizes on insights from herpangina, adisease closely correlated with HFMD. This model also integrates representationlearning by introducing reconstruction loss as an auxiliary loss. The resultsshow that our U-net Patching Time Series Transformer (UPTST) model outperformsexisting approaches in both long- and short-arm prediction accuracy of HFMD athospital-level. Furthermore, the exploratory extension experiments show thatthe model's capabilities extend beyond prediction of infectious disease,suggesting broader applicability in various domains.</description><author>Guoqi Yu, Hailun Yao, Huan Zheng, Ximing Xu</author><pubDate>Fri, 06 Oct 2023 14:38:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14674v2</guid></item><item><title>NeuralMatrix: Compute the Entire Neural Networks with Linear Matrix Operations for Efficient Inference</title><link>http://arxiv.org/abs/2305.14405v2</link><description>The inherent diversity of computation types within individual deep neuralnetwork (DNN) models necessitates a corresponding variety of computation unitswithin hardware processors, leading to a significant constraint on computationefficiency during neural network execution. In this study, we introduceNeuralMatrix, a framework that transforms the computation of entire DNNs intolinear matrix operations, effectively enabling their execution with onegeneral-purpose matrix multiplication (GEMM) accelerator. By surmounting theconstraints posed by the diverse computation types required by individualnetwork models, this approach provides both generality, allowing a wide rangeof DNN models to be executed using a single GEMM accelerator andapplication-specific acceleration levels without extra special function units,which are validated through main stream DNNs and their variant models.</description><author>Ruiqi Sun, Jie Zhao, Xin He, Yiran Li, An Zou</author><pubDate>Fri, 06 Oct 2023 14:28:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14405v2</guid></item><item><title>Comparing Auxiliary Tasks for Learning Representations for Reinforcement Learning</title><link>http://arxiv.org/abs/2310.04241v1</link><description>Learning state representations has gained steady popularity in reinforcementlearning (RL) due to its potential to improve both sample efficiency andreturns on many environments. A straightforward and efficient method is togenerate representations with a distinct neural network trained on an auxiliarytask, i.e. a task that differs from the actual RL task. While a whole range ofsuch auxiliary tasks has been proposed in the literature, a comparison ontypical continuous control benchmark environments is computationally expensiveand has, to the best of our knowledge, not been performed before. This paperpresents such a comparison of common auxiliary tasks, based on hundreds ofagents trained with state-of-the-art off-policy RL algorithms. We comparepossible improvements in both sample efficiency and returns for environmentsranging from simple pendulum to a complex simulated robotics task. Our findingsshow that representation learning with auxiliary tasks is beneficial forenvironments of higher dimension and complexity, and that learning environmentdynamics is preferable to predicting rewards. We believe these insights willenable other researchers to make more informed decisions on how to utilizerepresentation learning for their specific problem.</description><author>Moritz Lange, Noah Krystiniak, Raphael C. Engelhardt, Wolfgang Konen, Laurenz Wiskott</author><pubDate>Fri, 06 Oct 2023 14:22:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04241v1</guid></item><item><title>CellViT: Vision Transformers for Precise Cell Segmentation and Classification</title><link>http://arxiv.org/abs/2306.15350v2</link><description>Nuclei detection and segmentation in hematoxylin and eosin-stained (H&amp;E)tissue images are important clinical tasks and crucial for a wide range ofapplications. However, it is a challenging task due to nuclei variances instaining and size, overlapping boundaries, and nuclei clustering. Whileconvolutional neural networks have been extensively used for this task, weexplore the potential of Transformer-based networks in this domain. Therefore,we introduce a new method for automated instance segmentation of cell nuclei indigitized tissue samples using a deep learning architecture based on VisionTransformer called CellViT. CellViT is trained and evaluated on the PanNukedataset, which is one of the most challenging nuclei instance segmentationdatasets, consisting of nearly 200,000 annotated Nuclei into 5 clinicallyimportant classes in 19 tissue types. We demonstrate the superiority oflarge-scale in-domain and out-of-domain pre-trained Vision Transformers byleveraging the recently published Segment Anything Model and a ViT-encoderpre-trained on 104 million histological image patches - achievingstate-of-the-art nuclei detection and instance segmentation performance on thePanNuke dataset with a mean panoptic quality of 0.50 and an F1-detection scoreof 0.83. The code is publicly available at https://github.com/TIO-IKIM/CellViT</description><author>Fabian Hörst, Moritz Rempe, Lukas Heine, Constantin Seibold, Julius Keyl, Giulia Baldini, Selma Ugurel, Jens Siveke, Barbara Grünwald, Jan Egger, Jens Kleesiek</author><pubDate>Fri, 06 Oct 2023 14:22:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15350v2</guid></item><item><title>Bringing Quantum Algorithms to Automated Machine Learning: A Systematic Review of AutoML Frameworks Regarding Extensibility for QML Algorithms</title><link>http://arxiv.org/abs/2310.04238v1</link><description>This work describes the selection approach and analysis of existing AutoMLframeworks regarding their capability of a) incorporating Quantum MachineLearning (QML) algorithms into this automated solving approach of the AutoMLframing and b) solving a set of industrial use-cases with different ML problemtypes by benchmarking their most important characteristics. For that, availableopen-source tools are condensed into a market overview and suitable frameworksare systematically selected on a multi-phase, multi-criteria approach. This isdone by considering software selection approaches, as well as in terms of thetechnical perspective of AutoML. The requirements for the framework selectionare divided into hard and soft criteria regarding their software and MLattributes. Additionally, a classification of AutoML frameworks is made intohigh- and low-level types, inspired by the findings of. Finally, we select Rayand AutoGluon as the suitable low- and high-level frameworks respectively, asthey fulfil all requirements sufficiently and received the best evaluationfeedback during the use-case study. Based on those findings, we build anextended Automated Quantum Machine Learning (AutoQML) framework withQC-specific pipeline steps and decision characteristics for hardware andsoftware constraints.</description><author>Dennis Klau, Marc Zöller, Christian Tutschku</author><pubDate>Fri, 06 Oct 2023 14:21:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04238v1</guid></item><item><title>Written and spoken corpus of real and fake social media postings about COVID-19</title><link>http://arxiv.org/abs/2310.04237v1</link><description>This study investigates the linguistic traits of fake news and real news.There are two parts to this study: text data and speech data. The text data forthis study consisted of 6420 COVID-19 related tweets re-filtered from Patwa etal. (2021). After cleaning, the dataset contained 3049 tweets, with 2161labeled as 'real' and 888 as 'fake'. The speech data for this study wascollected from TikTok, focusing on COVID-19 related videos. Research assistantsfact-checked each video's content using credible sources and labeled them as'Real', 'Fake', or 'Questionable', resulting in a dataset of 91 real entriesand 109 fake entries from 200 TikTok videos with a total word count of 53,710words. The data was analysed using the Linguistic Inquiry and Word Count (LIWC)software to detect patterns in linguistic data. The results indicate a set oflinguistic features that distinguish fake news from real news in both writtenand speech data. This offers valuable insights into the role of language inshaping trust, social media interactions, and the propagation of fake news.</description><author>Ng Bee Chin, Ng Zhi Ee Nicole, Kyla Kwan, Lee Yong Han Dylann, Liu Fang, Xu Hong</author><pubDate>Fri, 06 Oct 2023 14:21:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04237v1</guid></item><item><title>Sleep Stage Classification Using a Pre-trained Deep Learning Model</title><link>http://arxiv.org/abs/2309.07182v2</link><description>One of the common human diseases is sleep disorders. The classification ofsleep stages plays a fundamental role in diagnosing sleep disorders, monitoringtreatment effectiveness, and understanding the relationship between sleepstages and various health conditions. A precise and efficient classification ofthese stages can significantly enhance our understanding of sleep-relatedphenomena and ultimately lead to improved health outcomes and diseasetreatment. Models others propose are often time-consuming and lack sufficient accuracy,especially in stage N1. The main objective of this research is to present amachine-learning model called "EEGMobile". This model utilizes pre-trainedmodels and learns from electroencephalogram (EEG) spectrograms of brainsignals. The model achieved an accuracy of 86.97% on a publicly availabledataset named "Sleep-EDF20", outperforming other models proposed by differentresearchers. Moreover, it recorded an accuracy of 56.4% in stage N1, which isbetter than other models. These findings demonstrate that this model has thepotential to achieve better results for the treatment of this disease.</description><author>Hassan Ardeshir, Mohammad Araghi</author><pubDate>Fri, 06 Oct 2023 14:18:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.07182v2</guid></item><item><title>The WayHome: Long-term Motion Prediction on Dynamically Scaled</title><link>http://arxiv.org/abs/2310.04232v1</link><description>One of the key challenges for autonomous vehicles is the ability toaccurately predict the motion of other objects in the surrounding environment,such as pedestrians or other vehicles. In this contribution, a novel motionforecasting approach for autonomous vehicles is developed, inspired by the workof Gilles et al. [1]. We predict multiple heatmaps with a neuralnetwork-basedmodel for every traffic participant in the vicinity of the autonomous vehicle;with one heatmap per timestep. The heatmaps are used as input to a novelsampling algorithm that extracts coordinates corresponding to the most likelyfuture positions. We experiment with different encoders and decoders, as wellas a comparison of two loss functions. Additionally, a new grid-scalingtechnique is introduced, showing further improved performance. Overall, ourapproach improves stateof-the-art miss rate performance for thefunction-relevant prediction interval of 3 seconds while being competitive inlonger prediction intervals (up to eight seconds). The evaluation is done onthe public 2022 Waymo motion challenge.</description><author>Kay Scheerer, Thomas Michalke, Juergen Mathes</author><pubDate>Fri, 06 Oct 2023 14:17:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04232v1</guid></item><item><title>Protocols for classically training quantum generative models on probability distributions</title><link>http://arxiv.org/abs/2210.13442v2</link><description>Quantum Generative Modelling (QGM) relies on preparing quantum states andgenerating samples from these states as hidden - or known - probabilitydistributions. As distributions from some classes of quantum states (circuits)are inherently hard to sample classically, QGM represents an excellent testbedfor quantum supremacy experiments. Furthermore, generative tasks areincreasingly relevant for industrial machine learning applications, and thusQGM is a strong candidate for demonstrating a practical quantum advantage.However, this requires that quantum circuits are trained to representindustrially relevant distributions, and the corresponding training stage hasan extensive training cost for current quantum hardware in practice. In thiswork, we propose protocols for classical training of QGMs based on circuits ofthe specific type that admit an efficient gradient computation, while remaininghard to sample. In particular, we consider Instantaneous Quantum Polynomial(IQP) circuits and their extensions. Showing their classical simulability interms of the time complexity, sparsity and anti-concentration properties, wedevelop a classically tractable way of simulating their output probabilitydistributions, allowing classical training to a target probabilitydistribution. The corresponding quantum sampling from IQPs can be performedefficiently, unlike when using classical sampling. We numerically demonstratethe end-to-end training of IQP circuits using probability distributions for upto 30 qubits on a regular desktop computer. When applied to industriallyrelevant distributions this combination of classical training with quantumsampling represents an avenue for reaching advantage in the NISQ era.</description><author>Sachin Kasture, Oleksandr Kyriienko, Vincent E. Elfving</author><pubDate>Fri, 06 Oct 2023 14:14:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.13442v2</guid></item><item><title>A Fixed-Parameter Tractable Algorithm for Counting Markov Equivalence Classes with the same Skeleton</title><link>http://arxiv.org/abs/2310.04218v1</link><description>Causal DAGs (also known as Bayesian networks) are a popular tool for encodingconditional dependencies between random variables. In a causal DAG, the randomvariables are modeled as vertices in the DAG, and it is stipulated that everyrandom variable is independent of its ancestors conditioned on its parents. Itis possible, however, for two different causal DAGs on the same set of randomvariables to encode exactly the same set of conditional dependencies. Suchcausal DAGs are said to be Markov equivalent, and equivalence classes of Markovequivalent DAGs are known as Markov Equivalent Classes (MECs). Beautifulcombinatorial characterizations of MECs have been developed in the past fewdecades, and it is known, in particular that all DAGs in the same MEC must havethe same ''skeleton'' (underlying undirected graph) and v-structures (inducedsubgraph of the form $a\rightarrow b \leftarrow c$). These combinatorial characterizations also suggest several naturalalgorithmic questions. One of these is: given an undirected graph $G$ as input,how many distinct Markov equivalence classes have the skeleton $G$? Much workhas been devoted in the last few years to this and other closely relatedproblems. However, to the best of our knowledge, a polynomial time algorithmfor the problem remains unknown. In this paper, we make progress towards this goal by giving a fixed parametertractable algorithm for the above problem, with the parameters being thetreewidth and the maximum degree of the input graph $G$. The main technicalingredient in our work is a construction we refer to as shadow, which lets uscreate a "local description'' of long-range constraints imposed by thecombinatorial characterizations of MECs.</description><author>Vidya Sagar Sharma</author><pubDate>Fri, 06 Oct 2023 14:05:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04218v1</guid></item></channel></rss>