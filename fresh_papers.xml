<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 16 May 2024 06:00:45 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>BEHAVIOR Vision Suite: Customizable Dataset Generation via Simulation</title><link>http://arxiv.org/abs/2405.09546v1</link><description>The systematic evaluation and understanding of computer vision models undervarying conditions require large amounts of data with comprehensive andcustomized labels, which real-world vision datasets rarely satisfy. Whilecurrent synthetic data generators offer a promising alternative, particularlyfor embodied AI tasks, they often fall short for computer vision tasks due tolow asset and rendering quality, limited diversity, and unrealistic physicalproperties. We introduce the BEHAVIOR Vision Suite (BVS), a set of tools andassets to generate fully customized synthetic data for systematic evaluation ofcomputer vision models, based on the newly developed embodied AI benchmark,BEHAVIOR-1K. BVS supports a large number of adjustable parameters at the scenelevel (e.g., lighting, object placement), the object level (e.g., jointconfiguration, attributes such as "filled" and "folded"), and the camera level(e.g., field of view, focal length). Researchers can arbitrarily vary theseparameters during data generation to perform controlled experiments. Weshowcase three example application scenarios: systematically evaluating therobustness of models across different continuous axes of domain shift,evaluating scene understanding models on the same set of images, and trainingand evaluating simulation-to-real transfer for a novel vision task: unary andbinary state prediction. Project website:https://behavior-vision-suite.github.io/</description><author>Yunhao Ge, Yihe Tang, Jiashu Xu, Cem Gokmen, Chengshu Li, Wensi Ai, Benjamin Jose Martinez, Arman Aydin, Mona Anvari, Ayush K Chakravarthy, Hong-Xing Yu, Josiah Wong, Sanjana Srivastava, Sharon Lee, Shengxin Zha, Laurent Itti, Yunzhu Li, Roberto Martín-Martín, Miao Liu, Pengchuan Zhang, Ruohan Zhang, Li Fei-Fei, Jiajun Wu</author><pubDate>Wed, 15 May 2024 18:57:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09546v1</guid></item><item><title>Classifying geospatial objects from multiview aerial imagery using semantic meshes</title><link>http://arxiv.org/abs/2405.09544v1</link><description>Aerial imagery is increasingly used in Earth science and natural resourcemanagement as a complement to labor-intensive ground-based surveys. Aerialsystems can collect overlapping images that provide multiple views of eachlocation from different perspectives. However, most prediction approaches (e.g.for tree species classification) use a single, synthesized top-down"orthomosaic" image as input that contains little to no information about thevertical aspects of objects and may include processing artifacts. We propose analternate approach that generates predictions directly on the raw images andaccurately maps these predictions into geospatial coordinates using semanticmeshes. This method$\unicode{x2013}$released as a user-friendly open-sourcetoolkit$\unicode{x2013}$enables analysts to use the highest quality data forpredictions, capture information about the sides of objects, and leveragemultiple viewpoints of each location for added robustness. We demonstrate thevalue of this approach on a new benchmark dataset of four forest sites in thewestern U.S. that consists of drone images, photogrammetry results, predictedtree locations, and species classification data derived from manual surveys. Weshow that our proposed multiview method improves classification accuracy from53% to 75% relative to an orthomosaic baseline on a challenging cross-site treespecies classification task.</description><author>David Russell, Ben Weinstein, David Wettergreen, Derek Young</author><pubDate>Wed, 15 May 2024 18:56:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09544v1</guid></item><item><title>Hoaxpedia: A Unified Wikipedia Hoax Articles Dataset</title><link>http://arxiv.org/abs/2405.02175v2</link><description>Hoaxes are a recognised form of disinformation created deliberately, withpotential serious implications in the credibility of reference knowledgeresources such as Wikipedia. What makes detecting Wikipedia hoaxes hard is thatthey often are written according to the official style guidelines. In thiswork, we first provide a systematic analysis of the similarities anddiscrepancies between legitimate and hoax Wikipedia articles, and introduceHoaxpedia, a collection of 311 Hoax articles (from existing literature as wellas official Wikipedia lists) alongside semantically similar real articles. Wereport results of binary classification experiments in the task of predictingwhether a Wikipedia article is real or hoax, and analyze several settings aswell as a range of language models. Our results suggest that detectingdeceitful content in Wikipedia based on content alone, despite not having beenexplored much in the past, is a promising direction.</description><author>Hsuvas Borkakoty, Luis Espinosa-Anke</author><pubDate>Wed, 15 May 2024 18:56:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02175v2</guid></item><item><title>Spectral complexity of deep neural networks</title><link>http://arxiv.org/abs/2405.09541v1</link><description>It is well-known that randomly initialized, push-forward, fully-connectedneural networks weakly converge to isotropic Gaussian processes, in the limitwhere the width of all layers goes to infinity. In this paper, we propose touse the angular power spectrum of the limiting field to characterize thecomplexity of the network architecture. In particular, we define sequences ofrandom variables associated with the angular power spectrum, and provide a fullcharacterization of the network complexity in terms of the asymptoticdistribution of these sequences as the depth diverges. On this basis, weclassify neural networks as low-disorder, sparse, or high-disorder; we show howthis classification highlights a number of distinct features for standardactivation functions, and in particular, sparsity properties of ReLU networks.Our theoretical results are also validated by numerical simulations.</description><author>Simmaco Di Lillo, Domenico Marinucci, Michele Salvi, Stefano Vigogna</author><pubDate>Wed, 15 May 2024 18:55:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09541v1</guid></item><item><title>SSUMamba: Spatial-Spectral Selective State Space Model for Hyperspectral Image Denoising</title><link>http://arxiv.org/abs/2405.01726v4</link><description>Denoising hyperspectral images (HSIs) is a crucial preprocessing proceduredue to the noise originating from intra-imaging mechanisms and environmentalfactors. Utilizing domain-specific knowledge of HSIs, such as spectralcorrelation, spatial self-similarity, and spatial-spectral correlation, isessential for deep learning-based denoising. Existing methods are oftenconstrained by running time, space complexity, and computational complexity,employing strategies that explore these priors separately. While thesestrategies can avoid some redundant information, they inevitably overlookbroader and more underlying long-range spatial-spectral information thatpositively impacts image restoration. This paper proposes a Spatial-SpectralSelective State Space Model-based U-shaped network, termed Spatial-SpectralU-Mamba (SSUMamba), for hyperspectral image denoising. We can obtain completeglobal spatial-spectral correlation within a module thanks to the linear spacecomplexity in State Space Model (SSM) computations. We introduce aSpatial-Spectral Alternating Scan (SSAS) strategy for HSIs, which helps modelthe information flow in multiple directions in 3-D HSIs. Experimental resultsdemonstrate that our method outperforms compared methods. The source code isavailable at https://github.com/lronkitty/SSUMamba.</description><author>Guanyiman Fu, Fengchao Xiong, Jianfeng Lu, Jun Zhou, Yuntao Qian</author><pubDate>Wed, 15 May 2024 18:53:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01726v4</guid></item><item><title>MMFusion: Multi-modality Diffusion Model for Lymph Node Metastasis Diagnosis in Esophageal Cancer</title><link>http://arxiv.org/abs/2405.09539v1</link><description>Esophageal cancer is one of the most common types of cancer worldwide andranks sixth in cancer-related mortality. Accurate computer-assisted diagnosisof cancer progression can help physicians effectively customize personalizedtreatment plans. Currently, CT-based cancer diagnosis methods have receivedmuch attention for their comprehensive ability to examine patients' conditions.However, multi-modal based methods may likely introduce information redundancy,leading to underperformance. In addition, efficient and effective interactionsbetween multi-modal representations need to be further explored, lackinginsightful exploration of prognostic correlation in multi-modality features. Inthis work, we introduce a multi-modal heterogeneous graph-based conditionalfeature-guided diffusion model for lymph node metastasis diagnosis based on CTimages as well as clinical measurements and radiomics data. To explore theintricate relationships between multi-modal features, we construct aheterogeneous graph. Following this, a conditional feature-guided diffusionapproach is applied to eliminate information redundancy. Moreover, we propose amasked relational representation learning strategy, aiming to uncover thelatent prognostic correlations and priorities of primary tumor and lymph nodeimage representations. Various experimental results validate the effectivenessof our proposed method. The code is available athttps://github.com/wuchengyu123/MMFusion.</description><author>Chengyu Wu, Chengkai Wang, Yaqi Wang, Huiyu Zhou, Yatao Zhang, Qifeng Wang, Shuai Wang</author><pubDate>Wed, 15 May 2024 18:52:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09539v1</guid></item><item><title>Prospects of Privacy Advantage in Quantum Machine Learning</title><link>http://arxiv.org/abs/2405.08801v2</link><description>Ensuring data privacy in machine learning models is critical, particularly indistributed settings where model gradients are typically shared among multipleparties to allow collaborative learning. Motivated by the increasing success ofrecovering input data from the gradients of classical models, this studyaddresses a central question: How hard is it to recover the input data from thegradients of quantum machine learning models? Focusing on variational quantumcircuits (VQC) as learning models, we uncover the crucial role played by thedynamical Lie algebra (DLA) of the VQC ansatz in determining privacyvulnerabilities. While the DLA has previously been linked to the classicalsimulatability and trainability of VQC models, this work, for the first time,establishes its connection to the privacy of VQC models. In particular, we showthat properties conducive to the trainability of VQCs, such as apolynomial-sized DLA, also facilitate the extraction of detailed snapshots ofthe input. We term this a weak privacy breach, as the snapshots enable trainingVQC models for distinct learning tasks without direct access to the originalinput. Further, we investigate the conditions for a strong privacy breach wherethe original input data can be recovered from these snapshots by classical orquantum-assisted polynomial time methods. We establish conditions on theencoding map such as classical simulatability, overlap with DLA basis, and itsFourier frequency characteristics that enable such a privacy breach of VQCmodels. Our findings thus play a crucial role in detailing the prospects ofquantum privacy advantage by guiding the requirements for designing quantummachine learning models that balance trainability with robust privacyprotection.</description><author>Jamie Heredge, Niraj Kumar, Dylan Herman, Shouvanik Chakrabarti, Romina Yalovetzky, Shree Hari Sureshbabu, Changhao Li, Marco Pistoia</author><pubDate>Wed, 15 May 2024 18:46:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08801v2</guid></item><item><title>Wasserstein Gradient Boosting: A General Framework with Applications to Posterior Regression</title><link>http://arxiv.org/abs/2405.09536v1</link><description>Gradient boosting is a sequential ensemble method that fits a new baselearner to the gradient of the remaining loss at each step. We propose a novelfamily of gradient boosting, Wasserstein gradient boosting, which fits a newbase learner to an exactly or approximately available Wasserstein gradient of aloss functional on the space of probability distributions. Wasserstein gradientboosting returns a set of particles that approximates a target probabilitydistribution assigned at each input. In probabilistic prediction, a parametricprobability distribution is often specified on the space of output variables,and a point estimate of the output-distribution parameter is produced for eachinput by a model. Our main application of Wasserstein gradient boosting is anovel distributional estimate of the output-distribution parameter, whichapproximates the posterior distribution over the output-distribution parameterdetermined pointwise at each data point. We empirically demonstrate thesuperior performance of the probabilistic prediction by Wasserstein gradientboosting in comparison with various existing methods.</description><author>Takuo Matsubara</author><pubDate>Wed, 15 May 2024 18:45:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09536v1</guid></item><item><title>Restoring balance: principled under/oversampling of data for optimal classification</title><link>http://arxiv.org/abs/2405.09535v1</link><description>Class imbalance in real-world data poses a common bottleneck for machinelearning tasks, since achieving good generalization on under-representedexamples is often challenging. Mitigation strategies, such as under oroversampling the data depending on their abundances, are routinely proposed andtested empirically, but how they should adapt to the data statistics remainspoorly understood. In this work, we determine exact analytical expressions ofthe generalization curves in the high-dimensional regime for linear classifiers(Support Vector Machines). We also provide a sharp prediction of the effects ofunder/oversampling strategies depending on class imbalance, first and secondmoments of the data, and the metrics of performance considered. We show thatmixed strategies involving under and oversampling of data lead to performanceimprovement. Through numerical experiments, we show the relevance of ourtheoretical predictions on real datasets, on deeper architectures and withsampling strategies based on unsupervised probabilistic models.</description><author>Emanuele Loffredo, Mauro Pastore, Simona Cocco, Rémi Monasson</author><pubDate>Wed, 15 May 2024 18:45:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09535v1</guid></item><item><title>Energy-Efficient Sleep Mode Optimization of 5G mmWave Networks Using Deep Contextual MAB</title><link>http://arxiv.org/abs/2405.09528v1</link><description>Millimeter-wave (mmWave) networks, integral to 5G communication, offer a vastspectrum that addresses the issue of spectrum scarcity and enhances peak rateand capacity. However, their dense deployment, necessary to counteractpropagation losses, leads to high power consumption. An effective strategy toreduce this energy consumption in mobile networks is the sleep modeoptimization (SMO) of base stations (BSs). In this paper, we propose a novelSMO approach for mmWave BSs in a 3D urban environment. This approach, whichincorporates a neural network (NN) based contextual multi-armed bandit (C-MAB)with an epsilon decay algorithm, accommodates the dynamic and diverse trafficof user equipment (UE) by clustering the UEs in their respective tracking areas(TAs). Our strategy includes beamforming, which helps reduce energy consumptionfrom the UE side, while SMO minimizes energy use from the BS perspective. Weextended our investigation to include Random, Epsilon Greedy, Upper ConfidenceBound (UCB), and Load Based sleep mode (SM) strategies. We compared theperformance of our proposed C-MAB based SM algorithm with those of All On andother alternative approaches. Simulation results show that our proposed methodoutperforms all other SM strategies in terms of the $10^{th}$ percentile ofuser rate and average throughput while demonstrating comparable averagethroughput to the All On approach. Importantly, it outperforms all approachesin terms of energy efficiency (EE).</description><author>Saad Masrur, Ismail Guvenc, David Lopez-Perez</author><pubDate>Wed, 15 May 2024 18:37:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09528v1</guid></item><item><title>Improved classical shadows from local symmetries in the Schur basis</title><link>http://arxiv.org/abs/2405.09525v1</link><description>We study the sample complexity of the classical shadows task: what is thefewest number of copies of an unknown state you need to measure to predictexpected values with respect to some class of observables? Large jointmeasurements are likely required in order to minimize sample complexity, butprevious joint measurement protocols only work when the unknown state is pure.We present the first joint measurement protocol for classical shadows whosesample complexity scales with the rank of the unknown state. In particular weprove $\mathcal O(\sqrt{rB}/\epsilon^2)$ samples suffice, where $r$ is the rankof the state, $B$ is a bound on the squared Frobenius norm of the observables,and $\epsilon$ is the target accuracy. In the low-rank regime, this is a nearlyquadratic advantage over traditional approaches that use single-copymeasurements. We present several intermediate results that may be of independent interest:a solution to a new formulation of classical shadows that captures functions ofnon-identical input states; a generalization of a ``nice'' Schur basis used foroptimal qubit purification and quantum majority vote; and a measurementstrategy that allows us to use local symmetries in the Schur basis to avoidintractable Weingarten calculations in the analysis.</description><author>Daniel Grier, Sihan Liu, Gaurav Mahajan</author><pubDate>Wed, 15 May 2024 18:33:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09525v1</guid></item><item><title>Cross-view Action Recognition Understanding From Exocentric to Egocentric Perspective</title><link>http://arxiv.org/abs/2305.15699v2</link><description>Understanding action recognition in egocentric videos has emerged as a vitalresearch topic with numerous practical applications. With the limitation in thescale of egocentric data collection, learning robust deep learning-based actionrecognition models remains difficult. Transferring knowledge learned from thelarge-scale exocentric data to the egocentric data is challenging due to thedifference in videos across views. Our work introduces a novel cross-viewlearning approach to action recognition (CVAR) that effectively transfersknowledge from the exocentric to the selfish view. First, we present a novelgeometric-based constraint into the self-attention mechanism in Transformerbased on analyzing the camera positions between two views. Then, we propose anew cross-view self-attention loss learned on unpaired cross-view data toenforce the self-attention mechanism learning to transfer knowledge acrossviews. Finally, to further improve the performance of our cross-view learningapproach, we present the metrics to measure the correlations in videos andattention maps effectively. Experimental results on standard egocentric actionrecognition benchmarks, i.e., Charades-Ego, EPIC-Kitchens-55, andEPIC-Kitchens-100, have shown our approach's effectiveness and state-of-the-artperformance.</description><author>Thanh-Dat Truong, Khoa Luu</author><pubDate>Wed, 15 May 2024 18:31:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15699v2</guid></item><item><title>ContourCraft: Learning to Resolve Intersections in Neural Multi-Garment Simulations</title><link>http://arxiv.org/abs/2405.09522v1</link><description>Learning-based approaches to cloth simulation have started to show theirpotential in recent years. However, handling collisions and intersections inneural simulations remains a largely unsolved problem. In this work, we present\moniker{}, a learning-based solution for handling intersections in neuralcloth simulations. Unlike conventional approaches that critically rely onintersection-free inputs, \moniker{} robustly recovers from intersectionsintroduced through missed collisions, self-penetrating bodies, or errors inmanually designed multi-layer outfits. The technical core of \moniker{} is anovel intersection contour loss that penalizes interpenetrations and encouragesrapid resolution thereof. We integrate our intersection loss with acollision-avoiding repulsion objective into a neural cloth simulation methodbased on graph neural networks (GNNs). We demonstrate our method's abilityacross a challenging set of diverse multi-layer outfits under dynamic humanmotions. Our extensive analysis indicates that \moniker{} significantlyimproves collision handling for learned simulation and produces visuallycompelling results.</description><author>Artur Grigorev, Giorgio Becherini, Michael J. Black, Otmar Hilliges, Bernhard Thomaszewski</author><pubDate>Wed, 15 May 2024 18:25:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09522v1</guid></item><item><title>Towards a fully declarative neuro-symbolic language</title><link>http://arxiv.org/abs/2405.09521v1</link><description>Neuro-symbolic systems (NeSy), which claim to combine the best of bothlearning and reasoning capabilities of artificial intelligence, are missing acore property of reasoning systems: Declarativeness. The lack ofdeclarativeness is caused by the functional nature of neural predicatesinherited from neural networks. We propose and implement a general frameworkfor fully declarative neural predicates, which hence extends to fullydeclarative NeSy frameworks. We first show that the declarative extensionpreserves the learning and reasoning capabilities while being able to answerarbitrary queries while only being trained on a single query type.</description><author>Tilman Hinnerichs, Robin Manhaeve, Giuseppe Marra, Sebastijan Dumancic</author><pubDate>Wed, 15 May 2024 18:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09521v1</guid></item><item><title>Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers</title><link>http://arxiv.org/abs/2405.05945v2</link><description>Sora unveils the potential of scaling Diffusion Transformer for generatingphotorealistic images and videos at arbitrary resolutions, aspect ratios, anddurations, yet it still lacks sufficient implementation details. In thistechnical report, we introduce the Lumina-T2X family - a series of Flow-basedLarge Diffusion Transformers (Flag-DiT) equipped with zero-initializedattention, as a unified framework designed to transform noise into images,videos, multi-view 3D objects, and audio clips conditioned on textinstructions. By tokenizing the latent spatial-temporal space and incorporatinglearnable placeholders such as [nextline] and [nextframe] tokens, Lumina-T2Xseamlessly unifies the representations of different modalities across variousspatial-temporal resolutions. This unified approach enables training within asingle framework for different modalities and allows for flexible generation ofmultimodal data at any resolution, aspect ratio, and length during inference.Advanced techniques like RoPE, RMSNorm, and flow matching enhance thestability, flexibility, and scalability of Flag-DiT, enabling models ofLumina-T2X to scale up to 7 billion parameters and extend the context window to128K tokens. This is particularly beneficial for creating ultra-high-definitionimages with our Lumina-T2I model and long 720p videos with our Lumina-T2Vmodel. Remarkably, Lumina-T2I, powered by a 5-billion-parameter Flag-DiT,requires only 35% of the training computational costs of a600-million-parameter naive DiT. Our further comprehensive analysis underscoresLumina-T2X's preliminary capability in resolution extrapolation,high-resolution editing, generating consistent 3D views, and synthesizingvideos with seamless transitions. We expect that the open-sourcing ofLumina-T2X will further foster creativity, transparency, and diversity in thegenerative AI community.</description><author>Peng Gao, Le Zhuo, Dongyang Liu, Ruoyi Du, Xu Luo, Longtian Qiu, Yuhang Zhang, Chen Lin, Rongjie Huang, Shijie Geng, Renrui Zhang, Junlin Xi, Wenqi Shao, Zhengkai Jiang, Tianshuo Yang, Weicai Ye, He Tong, Jingwen He, Yu Qiao, Hongsheng Li</author><pubDate>Wed, 15 May 2024 18:19:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05945v2</guid></item><item><title>Generalization Bounds for Causal Regression: Insights, Guarantees and Sensitivity Analysis</title><link>http://arxiv.org/abs/2405.09516v1</link><description>Many algorithms have been recently proposed for causal machine learning. Yet,there is little to no theory on their quality, especially considering finitesamples. In this work, we propose a theory based on generalization bounds thatprovides such guarantees. By introducing a novel change-of-measure inequality,we are able to tightly bound the model loss in terms of the deviation of thetreatment propensities over the population, which we show can be empiricallylimited. Our theory is fully rigorous and holds even in the face of hiddenconfounding and violations of positivity. We demonstrate our bounds onsemi-synthetic and real data, showcasing their remarkable tightness andpractical utility.</description><author>Daniel Csillag, Claudio José Struchiner, Guilherme Tegoni Goedert</author><pubDate>Wed, 15 May 2024 18:17:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09516v1</guid></item><item><title>A Reinforcement Learning Approach to Dairy Farm Battery Management using Q Learning</title><link>http://arxiv.org/abs/2403.09499v3</link><description>Dairy farming consumes a significant amount of energy, making it anenergy-intensive sector within agriculture. Integrating renewable energygeneration into dairy farming could help address this challenge. Effectivebattery management is important for integrating renewable energy generation.Managing battery charging and discharging poses significant challenges becauseof fluctuations in electrical consumption, the intermittent nature of renewableenergy generation, and fluctuations in energy prices. Artificial Intelligence(AI) has the potential to significantly improve the use of renewable energy indairy farming, however, there is limited research conducted in this particulardomain. This research considers Ireland as a case study as it works towardsattaining its 2030 energy strategy centered on the utilization of renewablesources. This study proposes a Q-learning-based algorithm for schedulingbattery charging and discharging in a dairy farm setting. This research alsoexplores the effect of the proposed algorithm by adding wind generation dataand considering additional case studies. The proposed algorithm reduces thecost of imported electricity from the grid by 13.41%, peak demand by 2%, and24.49% when utilizing wind generation. These results underline howreinforcement learning is highly effective in managing batteries in the dairyfarming sector.</description><author>Nawazish Ali, Abdul Wahid, Rachael Shaw, Karl Mason</author><pubDate>Wed, 15 May 2024 18:11:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09499v3</guid></item><item><title>Tackling Distribution Shifts in Task-Oriented Communication with Information Bottleneck</title><link>http://arxiv.org/abs/2405.09514v1</link><description>Task-oriented communication aims to extract and transmit task-relevantinformation to significantly reduce the communication overhead and transmissionlatency. However, the unpredictable distribution shifts between training andtest data, including domain shift and semantic shift, can dramaticallyundermine the system performance. In order to tackle these challenges, it iscrucial to ensure that the encoded features can generalize to domain-shifteddata and detect semanticshifted data, while remaining compact for transmission.In this paper, we propose a novel approach based on the information bottleneck(IB) principle and invariant risk minimization (IRM) framework. The proposedmethod aims to extract compact and informative features that possess highcapability for effective domain-shift generalization and accuratesemantic-shift detection without any knowledge of the test data duringtraining. Specifically, we propose an invariant feature encoding approach basedon the IB principle and IRM framework for domainshift generalization, whichaims to find the causal relationship between the input data and task result byminimizing the complexity and domain dependence of the encoded feature.Furthermore, we enhance the task-oriented communication with thelabel-dependent feature encoding approach for semanticshift detection whichachieves joint gains in IB optimization and detection performance. To avoid theintractable computation of the IB-based objective, we leverage variationalapproximation to derive a tractable upper bound for optimization. Extensivesimulation results on image classification tasks demonstrate that the proposedscheme outperforms state-of-the-art approaches and achieves a betterrate-distortion tradeoff.</description><author>Hongru Li, Jiawei Shao, Hengtao He, Shenghui Song, Jun Zhang, Khaled B. Letaief</author><pubDate>Wed, 15 May 2024 18:07:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09514v1</guid></item><item><title>Modeling Bilingual Sentence Processing: Evaluating RNN and Transformer Architectures for Cross-Language Structural Priming</title><link>http://arxiv.org/abs/2405.09508v1</link><description>This study evaluates the performance of Recurrent Neural Network (RNN) andTransformer in replicating cross-language structural priming: a key indicatorof abstract grammatical representations in human language processing. Focusingon Chinese-English priming, which involves two typologically distinctlanguages, we examine how these models handle the robust phenomenon ofstructural priming, where exposure to a particular sentence structure increasesthe likelihood of selecting a similar structure subsequently. Additionally, weutilize large language models (LLM) to measure the cross-lingual structuralpriming effect. Our findings indicate that Transformer outperform RNN ingenerating primed sentence structures, challenging the conventional belief thathuman sentence processing primarily involves recurrent and immediate processingand suggesting a role for cue-based retrieval mechanisms. Overall, this workcontributes to our understanding of how computational models may reflect humancognitive processes in multilingual contexts.</description><author>Bushi Xiao, Chao Gao, Demi Zhang</author><pubDate>Wed, 15 May 2024 18:01:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09508v1</guid></item><item><title>QueryNER: Segmentation of E-commerce Queries</title><link>http://arxiv.org/abs/2405.09507v1</link><description>We present QueryNER, a manually-annotated dataset and accompanying model fore-commerce query segmentation. Prior work in sequence labeling for e-commercehas largely addressed aspect-value extraction which focuses on extractingportions of a product title or query for narrowly defined aspects. Our workinstead focuses on the goal of dividing a query into meaningful chunks withbroadly applicable types. We report baseline tagging results and conductexperiments comparing token and entity dropping for null and low recall queryrecovery. Challenging test sets are created using automatic transformations andshow how simple data augmentation techniques can make the models more robust tonoise. We make the QueryNER dataset publicly available.</description><author>Chester Palen-Michel, Lizzie Liang, Zhe Wu, Constantine Lignos</author><pubDate>Wed, 15 May 2024 17:58:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09507v1</guid></item><item><title>Importance of realism in procedurally-generated synthetic images for deep learning: case studies in maize and canola</title><link>http://arxiv.org/abs/2404.05128v2</link><description>Artificial neural networks are often used to identify features of cropplants. However, training their models requires many annotated images, whichcan be expensive and time-consuming to acquire. Procedural models of plants,such as those developed with Lindenmayer-systems (L-systems) can be created toproduce visually realistic simulations, and hence images of plant simulations,where annotations are implicitly known. These synthetic images can eitheraugment or completely replace real images in training neural networks forphenotyping tasks. In this paper, we systematically vary amounts of real andsynthetic images used for training in both maize and canola to betterunderstand situations where synthetic images generated from L-systems can helpprediction on real images. This work also explores the degree to which realismin the synthetic images improves prediction. We have five different variants ofa procedural canola model (these variants were created by tuning the realismwhile using calibration), and the deep learning results showed how drasticallythese results improve as the canola synthetic images are made to be morerealistic. Furthermore, we see how neural network predictions can be used tohelp calibrate L-systems themselves, creating a feedback loop.</description><author>Nazifa Azam Khan, Mikolaj Cieslak, Ian McQuillan</author><pubDate>Wed, 15 May 2024 17:55:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05128v2</guid></item><item><title>ParaNames 1.0: Creating an Entity Name Corpus for 400+ Languages using Wikidata</title><link>http://arxiv.org/abs/2405.09496v1</link><description>We introduce ParaNames, a massively multilingual parallel name resourceconsisting of 140 million names spanning over 400 languages. Names are providedfor 16.8 million entities, and each entity is mapped from a complex typehierarchy to a standard type (PER/LOC/ORG). Using Wikidata as a source, wecreate the largest resource of this type to date. We describe our approach tofiltering and standardizing the data to provide the best quality possible.ParaNames is useful for multilingual language processing, both in definingtasks for name translation/transliteration and as supplementary data for taskssuch as named entity recognition and linking. We demonstrate the usefulness ofParaNames on two tasks. First, we perform canonical name translation betweenEnglish and 17 other languages. Second, we use it as a gazetteer formultilingual named entity recognition, obtaining performance improvements onall 10 languages evaluated.</description><author>Jonne Sälevä, Constantine Lignos</author><pubDate>Wed, 15 May 2024 17:44:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09496v1</guid></item><item><title>FlashBack:Efficient Retrieval-Augmented Language Modeling for Long Context Inference</title><link>http://arxiv.org/abs/2405.04065v2</link><description>Retrieval-Augmented Language Modeling (RALM) by integrating large languagemodels (LLM) with relevant documents from an external corpus is a proven methodfor enabling the LLM to generate information beyond the scope of itspre-training corpus. Previous work using utilizing retrieved content by simplyprepending retrieved contents to the input poses a high runtime issue, whichdegrades the inference efficiency of the LLMs because they fail to use theKey-Value (KV) cache efficiently. In this paper, we propose \textsc{FlashBack},a modular RALM designed to improve the inference efficiency of RALM withappending context pattern while maintaining decent performance after specificfine-tuning without heavily destruct the knowledge integrity of the LLM.\textsc{FlashBack} appends retrieved documents at the end of the context forefficiently utilizing the KV cache instead of prepending them. Our experimentshows that the inference speed of \textsc{FlashBack} is up to $4\times$ fasterthan the prepending method on a 7B LLM (Llama 2). Via bypassing unnecessaryre-computation, it demonstrates an advancement by achieving significantlyfaster inference speed, and this heightened efficiency will substantiallyreduce inferential cost. Our code will be publicly available.</description><author>Runheng Liu, Xingchen Xiao, Heyan Huang, Zewen Chi, Zhijing Wu</author><pubDate>Wed, 15 May 2024 17:42:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04065v2</guid></item><item><title>Constrained Learning for Causal Inference and Semiparametric Statistics</title><link>http://arxiv.org/abs/2405.09493v1</link><description>Causal estimation (e.g. of the average treatment effect) requires estimatingcomplex nuisance parameters (e.g. outcome models). To adjust for errors innuisance parameter estimation, we present a novel correction method that solvesfor the best plug-in estimator under the constraint that the first-order errorof the estimator with respect to the nuisance parameter estimate is zero. Ourconstrained learning framework provides a unifying perspective to prominentfirst-order correction approaches including debiasing (a.k.a. augmented inverseprobability weighting) and targeting (a.k.a. targeted maximum likelihoodestimation). Our semiparametric inference approach, which we call the"C-Learner", can be implemented with modern machine learning methods such asneural networks and tree ensembles, and enjoys standard guarantees likesemiparametric efficiency and double robustness. Empirically, we demonstrateour approach on several datasets, including those with text features thatrequire fine-tuning language models. We observe the C-Learner matches oroutperforms other asymptotically optimal estimators, with better performance insettings with less estimated overlap.</description><author>Tiffany Tianhui Cai, Yuri Fonseca, Kaiwen Hou, Hongseok Namkoong</author><pubDate>Wed, 15 May 2024 17:38:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09493v1</guid></item><item><title>MGSER-SAM: Memory-Guided Soft Experience Replay with Sharpness-Aware Optimization for Enhanced Continual Learning</title><link>http://arxiv.org/abs/2405.09492v1</link><description>Deep neural networks suffer from the catastrophic forgetting problem in thefield of continual learning (CL). To address this challenge, we proposeMGSER-SAM, a novel memory replay-based algorithm specifically engineered toenhance the generalization capabilities of CL models. We first intergrate theSAM optimizer, a component designed for optimizing flatness, which seamlesslyfits into well-known Experience Replay frameworks such as ER and DER++. Then,MGSER-SAM distinctively addresses the complex challenge of reconcilingconflicts in weight perturbation directions between ongoing tasks andpreviously stored memories, which is underexplored in the SAM optimizer. Thisis effectively accomplished by the strategic integration of soft logits and thealignment of memory gradient directions, where the regularization termsfacilitate the concurrent minimization of various training loss terms integralto the CL process. Through rigorous experimental analysis conducted acrossmultiple benchmarks, MGSER-SAM has demonstrated a consistent ability tooutperform existing baselines in all three CL scenarios. Comparing to therepresentative memory replay-based baselines ER and DER++, MGSER-SAM not onlyimproves the testing accuracy by $24.4\%$ and $17.6\%$ respectively, but alsoachieves the lowest forgetting on each benchmark.</description><author>Xingyu Li, Bo Tang</author><pubDate>Wed, 15 May 2024 17:37:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09492v1</guid></item><item><title>Automatic Programming: Large Language Models and Beyond</title><link>http://arxiv.org/abs/2405.02213v2</link><description>Automatic programming has seen increasing popularity due to the emergence oftools like GitHub Copilot which rely on Large Language Models (LLMs). At thesame time, automatically generated code faces challenges during deployment dueto concerns around quality and trust. In this article, we study automatedcoding in a general sense and study the concerns around code quality, securityand related issues of programmer responsibility. These are key issues fororganizations while deciding on the usage of automatically generated code. Wediscuss how advances in software engineering such as program repair andanalysis can enable automatic programming. We conclude with a forward lookingview, focusing on the programming environment of the near future, whereprogrammers may need to switch to different roles to fully utilize the power ofautomatic programming. Automated repair of automatically generated programsfrom LLMs, can help produce higher assurance code from LLMs, along withevidence of assurance</description><author>Michael R. Lyu, Baishakhi Ray, Abhik Roychoudhury, Shin Hwei Tan, Patanamon Thongtanunam</author><pubDate>Wed, 15 May 2024 17:33:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02213v2</guid></item><item><title>MusicMagus: Zero-Shot Text-to-Music Editing via Diffusion Models</title><link>http://arxiv.org/abs/2402.06178v2</link><description>Recent advances in text-to-music generation models have opened new avenues inmusical creativity. However, music generation usually involves iterativerefinements, and how to edit the generated music remains a significantchallenge. This paper introduces a novel approach to the editing of musicgenerated by such models, enabling the modification of specific attributes,such as genre, mood and instrument, while maintaining other aspects unchanged.Our method transforms text editing to \textit{latent space manipulation} whileadding an extra constraint to enforce consistency. It seamlessly integrateswith existing pretrained text-to-music diffusion models without requiringadditional training. Experimental results demonstrate superior performance overboth zero-shot and certain supervised baselines in style and timbre transferevaluations. Additionally, we showcase the practical applicability of ourapproach in real-world music editing scenarios.</description><author>Yixiao Zhang, Yukara Ikemiya, Gus Xia, Naoki Murata, Marco A. Martínez-Ramírez, Wei-Hsiang Liao, Yuki Mitsufuji, Simon Dixon</author><pubDate>Wed, 15 May 2024 17:30:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06178v2</guid></item><item><title>Color Space Learning for Cross-Color Person Re-Identification</title><link>http://arxiv.org/abs/2405.09487v1</link><description>The primary color profile of the same identity is assumed to remainconsistent in typical Person Re-identification (Person ReID) tasks. However,this assumption may be invalid in real-world situations and images hold variantcolor profiles, because of cross-modality cameras or identity with differentclothing. To address this issue, we propose Color Space Learning (CSL) forthose Cross-Color Person ReID problems. Specifically, CSL guides the model tobe less color-sensitive with two modules: Image-level Color-Augmentation andPixel-level Color-Transformation. The first module increases the colordiversity of the inputs and guides the model to focus more on the non-colorinformation. The second module projects every pixel of input images onto a newcolor space. In addition, we introduce a new Person ReID benchmark across RGBand Infrared modalities, NTU-Corridor, which is the first with privacyagreements from all participants. To evaluate the effectiveness and robustnessof our proposed CSL, we evaluate it on several Cross-Color Person ReIDbenchmarks. Our method surpasses the state-of-the-art methods consistently. Thecode and benchmark are available at: https://github.com/niejiahao1998/CSL</description><author>Jiahao Nie, Shan Lin, Alex C. Kot</author><pubDate>Wed, 15 May 2024 17:26:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09487v1</guid></item><item><title>Polarimetric Light Transport Analysis for Specular Inter-reflection</title><link>http://arxiv.org/abs/2312.04140v2</link><description>Polarization is well known for its ability to decompose diffuse and specularreflections. However, the existing decomposition methods only focus on directreflection and overlook multiple reflections, especially specularinter-reflection. In this paper, we propose a novel decomposition method forhandling specular inter-reflection of metal objects by using a uniquepolarimetric feature: the rotation direction of linear polarization. Thisrotation direction serves as a discriminative factor between direct andinter-reflection on specular surfaces. To decompose the reflectance components,we actively rotate the linear polarization of incident light and analyze therotation direction of the reflected light. We evaluate our method using bothsynthetic and real data, demonstrating its effectiveness in decomposingspecular inter-reflections of metal objects. Furthermore, we demonstrate thatour method can be combined with other decomposition methods for a detailedanalysis of light transport. As a practical application, we show itseffectiveness in improving the accuracy of 3D measurement against strongspecular inter-reflection.</description><author>Ryota Maeda, Shinsaku Hiura</author><pubDate>Wed, 15 May 2024 17:24:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04140v2</guid></item><item><title>DemOpts: Fairness corrections in COVID-19 case prediction models</title><link>http://arxiv.org/abs/2405.09483v1</link><description>COVID-19 forecasting models have been used to inform decision making aroundresource allocation and intervention decisions e.g., hospital beds orstay-at-home orders. State of the art deep learning models often use multimodaldata such as mobility or socio-demographic data to enhance COVID-19 caseprediction models. Nevertheless, related work has revealed under-reporting biasin COVID-19 cases as well as sampling bias in mobility data for certainminority racial and ethnic groups, which could in turn affect the fairness ofthe COVID-19 predictions along race labels. In this paper, we show that stateof the art deep learning models output mean prediction errors that aresignificantly different across racial and ethnic groups; and which could, inturn, support unfair policy decisions. We also propose a novel de-biasingmethod, DemOpts, to increase the fairness of deep learning based forecastingmodels trained on potentially biased datasets. Our results show that DemOptscan achieve better error parity that other state of the art de-biasingapproaches, thus effectively reducing the differences in the mean errordistributions across more racial and ethnic groups.</description><author>Naman Awasthi, Saad Abrar, Daniel Smolyak, Vanessa Frias-Martinez</author><pubDate>Wed, 15 May 2024 17:22:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09483v1</guid></item><item><title>Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty Classification of Educational Texts</title><link>http://arxiv.org/abs/2405.09482v1</link><description>Using large language models (LLMs) for educational applications likedialogue-based teaching is a hot topic. Effective teaching, however, requiresteachers to adapt the difficulty of content and explanations to the educationlevel of their students. Even the best LLMs today struggle to do this well. Ifwe want to improve LLMs on this adaptation task, we need to be able to measureadaptation success reliably. However, current Static metrics for textdifficulty, like the Flesch-Kincaid Reading Ease score, are known to be crudeand brittle. We, therefore, introduce and evaluate a new set of Prompt-basedmetrics for text difficulty. Based on a user study, we create Prompt-basedmetrics as inputs for LLMs. They leverage LLM's general language understandingcapabilities to capture more abstract and complex features than Static metrics.Regression experiments show that adding our Prompt-based metrics significantlyimproves text difficulty classification over Static metrics alone. Our resultsdemonstrate the promise of using LLMs to evaluate text adaptation to differenteducation levels.</description><author>Donya Rooein, Paul Rottger, Anastassia Shaitarova, Dirk Hovy</author><pubDate>Wed, 15 May 2024 17:22:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09482v1</guid></item><item><title>Harmonizing Human Insights and AI Precision: Hand in Hand for Advancing Knowledge Graph Task</title><link>http://arxiv.org/abs/2405.09477v1</link><description>Knowledge graph embedding (KGE) has caught significant interest for itseffectiveness in knowledge graph completion (KGC), specifically link prediction(LP), with recent KGE models cracking the LP benchmarks. Despite the rapidlygrowing literature, insufficient attention has been paid to the cooperationbetween humans and AI on KG. However, humans' capability to analyze graphsconceptually may further improve the efficacy of KGE models with semanticinformation. To this effect, we carefully designed a human-AI team (HAIT)system dubbed KG-HAIT, which harnesses the human insights on KG by leveragingfully human-designed ad-hoc dynamic programming (DP) on KG to produce humaninsightful feature (HIF) vectors that capture the subgraph structural featureand semantic similarities. By integrating HIF vectors into the training of KGEmodels, notable improvements are observed across various benchmarks andmetrics, accompanied by accelerated model convergence. Our results underscorethe effectiveness of human-designed DP in the task of LP, emphasizing thepivotal role of collaboration between humans and AI on KG. We open avenues forfurther exploration and innovation through KG-HAIT, paving the way towards moreeffective and insightful KG analysis techniques.</description><author>Shurong Wang, Yufei Zhang, Xuliang Huang, Hongwei Wang</author><pubDate>Wed, 15 May 2024 17:16:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09477v1</guid></item><item><title>Double Machine Learning for Static Panel Models with Fixed Effects</title><link>http://arxiv.org/abs/2312.08174v3</link><description>Recent advances in causal inference have seen the development of methodswhich make use of the predictive power of machine learning algorithms. In thispaper, we use double machine learning (DML) (Chernozhukov et al., 2018) toapproximate high-dimensional and non-linear nuisance functions of theconfounders to make inferences about the effects of policy interventions frompanel data. We propose new estimators by adapting correlated random effects,within-group and first-difference estimation for linear models to an extensionof Robinson (1988)'s partially linear regression model to static panel datamodels with individual fixed effects and unspecified non-linear confoundereffects. Using Monte Carlo simulations, we compare the relative performance ofdifferent machine learning algorithms and find that conventional least squaresestimators performs well when the data generating process is mildly non-linearand smooth, but there are substantial performance gains with DML in terms ofbias reduction when the true effect of the regressors is non-linear anddiscontinuous. However, inference based on individual learners can lead tobadly biased inference. Finally, we provide an illustrative example of DML forobservational panel data showing the impact of the introduction of the minimumwage on voting behavior in the UK.</description><author>Paul Clarke, Annalivia Polselli</author><pubDate>Wed, 15 May 2024 17:15:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08174v3</guid></item><item><title>AirIMU: Learning Uncertainty Propagation for Inertial Odometry</title><link>http://arxiv.org/abs/2310.04874v4</link><description>Inertial odometry (IO) using strap-down inertial measurement units (IMUs) iscritical in many robotic applications where precise orientation and positiontracking are essential. Prior kinematic motion model-based IO methods often usea simplified linearized IMU noise model and thus usually encounter difficultiesin modeling non-deterministic errors arising from environmental disturbancesand mechanical defects. In contrast, data-driven IO methods struggle toaccurately model the sensor motions, often leading to generalizability andinteroperability issues. To address these challenges, we present AirIMU, ahybrid approach to estimate the uncertainty, especially the non-deterministicerrors, by data-driven methods and increase the generalization abilities usingmodel-based methods. We demonstrate the adaptability of AirIMU using a fullspectrum of IMUs, from low-cost automotive grades to high-end navigationgrades. We also validate its effectiveness on various platforms, includinghand-held devices, vehicles, and a helicopter that covers a trajectory of 262kilometers. In the ablation study, we validate the effectiveness of our learneduncertainty in an IMU-GPS pose graph optimization experiment, achieving a31.6\% improvement in accuracy. Experiments demonstrate that jointly trainingthe IMU noise correction and uncertainty estimation synergistically benefitsboth tasks.</description><author>Yuheng Qiu, Chen Wang, Can Xu, Yutian Chen, Xunfei Zhou, Youjie Xia, Sebastian Scherer</author><pubDate>Wed, 15 May 2024 17:14:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04874v4</guid></item><item><title>Hierarchical Side-Tuning for Vision Transformers</title><link>http://arxiv.org/abs/2310.05393v4</link><description>Fine-tuning pre-trained Vision Transformers (ViTs) has showcased significantpromise in enhancing visual recognition tasks. Yet, the demand forindividualized and comprehensive fine-tuning processes for each task entailssubstantial computational and memory costs, posing a considerable challenge.Recent advancements in Parameter-Efficient Transfer Learning (PETL) have shownpotential for achieving high performance with fewer parameter updates comparedto full fine-tuning. However, their effectiveness is primarily observed insimple tasks like image classification, while they encounter challenges withmore complex vision tasks like dense prediction. To address this gap, thisstudy aims to identify an effective tuning method that caters to a wider rangeof visual tasks. In this paper, we introduce Hierarchical Side-Tuning (HST), aninnovative PETL method facilitating the transfer of ViT models to diversedownstream tasks. Diverging from existing methods that focus solely onfine-tuning parameters within specific input spaces or modules, HST employs alightweight Hierarchical Side Network (HSN). This network leveragesintermediate activations from the ViT backbone to model multi-scale features,enhancing prediction capabilities. To evaluate HST, we conducted comprehensiveexperiments across a range of visual tasks, including classification, objectdetection, instance segmentation, and semantic segmentation. Remarkably, HSTachieved state-of-the-art performance in 13 out of the 19 tasks on the VTAB-1Kbenchmark, with the highest average Top-1 accuracy of 76.1%, while fine-tuninga mere 0.78M parameters. When applied to object detection and semanticsegmentation tasks on the COCO and ADE20K testdev benchmarks, HST outperformedexisting PETL methods and even surpassed full fine-tuning.</description><author>Weifeng Lin, Ziheng Wu, Wentao Yang, Mingxin Huang, Jun Huang, Lianwen Jin</author><pubDate>Wed, 15 May 2024 17:13:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05393v4</guid></item><item><title>nnSAM: Plug-and-play Segment Anything Model Improves nnUNet Performance</title><link>http://arxiv.org/abs/2309.16967v3</link><description>Automatic segmentation of medical images is crucial in modern clinicalworkflows. The Segment Anything Model (SAM) has emerged as a versatile tool forimage segmentation without specific domain training, but it requires humanprompts and may have limitations in specific domains. Traditional models likennUNet perform automatic segmentation during inference and are effective inspecific domains but need extensive domain-specific training. To combine thestrengths of foundational and domain-specific models, we propose nnSAM,integrating SAM's robust feature extraction with nnUNet's automaticconfiguration to enhance segmentation accuracy on small datasets. Our nnSAMmodel optimizes two main approaches: leveraging SAM's feature extraction andnnUNet's domain-specific adaptation, and incorporating a boundary shapesupervision loss function based on level set functions and curvaturecalculations to learn anatomical shape priors from limited data. We evaluatednnSAM on four segmentation tasks: brain white matter, liver, lung, and heartsegmentation. Our method outperformed others, achieving the highest DICE scoreof 82.77% and the lowest ASD of 1.14 mm in brain white matter segmentation with20 training samples, compared to nnUNet's DICE score of 79.25% and ASD of 1.36mm. A sample size study highlighted nnSAM's advantage with fewer trainingsamples. Our results demonstrate significant improvements in segmentationperformance with nnSAM, showcasing its potential for small-sample learning inmedical image segmentation.</description><author>Yunxiang Li, Bowen Jing, Zihan Li, Jing Wang, You Zhang</author><pubDate>Wed, 15 May 2024 17:09:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16967v3</guid></item><item><title>Perception- and Fidelity-aware Reduced-Reference Super-Resolution Image Quality Assessment</title><link>http://arxiv.org/abs/2405.09472v1</link><description>With the advent of image super-resolution (SR) algorithms, how to evaluatethe quality of generated SR images has become an urgent task. Althoughfull-reference methods perform well in SR image quality assessment (SR-IQA),their reliance on high-resolution (HR) images limits their practicalapplicability. Leveraging available reconstruction information as much aspossible for SR-IQA, such as low-resolution (LR) images and the scale factors,is a promising way to enhance assessment performance for SR-IQA without HR forreference. In this letter, we attempt to evaluate the perceptual quality andreconstruction fidelity of SR images considering LR images and scale factors.Specifically, we propose a novel dual-branch reduced-reference SR-IQA network,\ie, Perception- and Fidelity-aware SR-IQA (PFIQA). The perception-aware branchevaluates the perceptual quality of SR images by leveraging the merits ofglobal modeling of Vision Transformer (ViT) and local relation of ResNet, andincorporating the scale factor to enable comprehensive visual perception.Meanwhile, the fidelity-aware branch assesses the reconstruction fidelitybetween LR and SR images through their visual perception. The combination ofthe two branches substantially aligns with the human visual system, enabling acomprehensive SR image evaluation. Experimental results indicate that our PFIQAoutperforms current state-of-the-art models across three widely-used SR-IQAbenchmarks. Notably, PFIQA excels in assessing the quality of real-world SRimages.</description><author>Xinying Lin, Xuyang Liu, Hong Yang, Xiaohai He, Honggang Chen</author><pubDate>Wed, 15 May 2024 17:09:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09472v1</guid></item><item><title>Towards Evaluating the Robustness of Automatic Speech Recognition Systems via Audio Style Transfer</title><link>http://arxiv.org/abs/2405.09470v1</link><description>In light of the widespread application of Automatic Speech Recognition (ASR)systems, their security concerns have received much more attention than everbefore, primarily due to the susceptibility of Deep Neural Networks. Previousstudies have illustrated that surreptitiously crafting adversarialperturbations enables the manipulation of speech recognition systems, resultingin the production of malicious commands. These attack methods mostly requireadding noise perturbations under $\ell_p$ norm constraints, inevitably leavingbehind artifacts of manual modifications. Recent research has alleviated thislimitation by manipulating style vectors to synthesize adversarial examplesbased on Text-to-Speech (TTS) synthesis audio. However, style modificationsbased on optimization objectives significantly reduce the controllability andeditability of audio styles. In this paper, we propose an attack on ASR systemsbased on user-customized style transfer. We first test the effect of StyleTransfer Attack (STA) which combines style transfer and adversarial attack insequential order. And then, as an improvement, we propose an iterative StyleCode Attack (SCA) to maintain audio quality. Experimental results show that ourmethod can meet the need for user-customized styles and achieve a success rateof 82% in attacks, while keeping sound naturalness due to our user study.</description><author>Weifei Jin, Yuxin Cao, Junjie Su, Qi Shen, Kai Ye, Derui Wang, Jie Hao, Ziyao Liu</author><pubDate>Wed, 15 May 2024 17:05:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09470v1</guid></item><item><title>3D Human Pose Perception from Egocentric Stereo Videos</title><link>http://arxiv.org/abs/2401.00889v2</link><description>While head-mounted devices are becoming more compact, they provide egocentricviews with significant self-occlusions of the device user. Hence, existingmethods often fail to accurately estimate complex 3D poses from egocentricviews. In this work, we propose a new transformer-based framework to improveegocentric stereo 3D human pose estimation, which leverages the sceneinformation and temporal context of egocentric stereo videos. Specifically, weutilize 1) depth features from our 3D scene reconstruction module withuniformly sampled windows of egocentric stereo frames, and 2) human jointqueries enhanced by temporal features of the video inputs. Our method is ableto accurately estimate human poses even in challenging scenarios, such ascrouching and sitting. Furthermore, we introduce two new benchmark datasets,i.e., UnrealEgo2 and UnrealEgo-RW (RealWorld). The proposed datasets offer amuch larger number of egocentric stereo views with a wider variety of humanmotions than the existing datasets, allowing comprehensive evaluation ofexisting and upcoming methods. Our extensive experiments show that the proposedapproach significantly outperforms previous methods. We will releaseUnrealEgo2, UnrealEgo-RW, and trained models on our project page.</description><author>Hiroyasu Akada, Jian Wang, Vladislav Golyanik, Christian Theobalt</author><pubDate>Wed, 15 May 2024 16:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00889v2</guid></item><item><title>Gaze-DETR: Using Expert Gaze to Reduce False Positives in Vulvovaginal Candidiasis Screening</title><link>http://arxiv.org/abs/2405.09463v1</link><description>Accurate detection of vulvovaginal candidiasis is critical for women'shealth, yet its sparse distribution and visually ambiguous characteristics posesignificant challenges for accurate identification by pathologists and neuralnetworks alike. Our eye-tracking data reveals that areas garnering sustainedattention - yet not marked by experts after deliberation - are often alignedwith false positives of neural networks. Leveraging this finding, we introduceGaze-DETR, a pioneering method that integrates gaze data to enhance neuralnetwork precision by diminishing false positives. Gaze-DETR incorporates auniversal gaze-guided warm-up protocol applicable across various detectionmethods and a gaze-guided rectification strategy specifically designed forDETR-based models. Our comprehensive tests confirm that Gaze-DETR surpassesexisting leading methods, showcasing remarkable improvements in detectionaccuracy and generalizability.</description><author>Yan Kong, Sheng Wang, Jiangdong Cai, Zihao Zhao, Zhenrong Shen, Yonghao Li, Manman Fei, Qian Wang</author><pubDate>Wed, 15 May 2024 16:56:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09463v1</guid></item><item><title>Fourier Boundary Features Network with Wider Catchers for Glass Segmentation</title><link>http://arxiv.org/abs/2405.09459v1</link><description>Glass largely blurs the boundary between the real world and the reflection.The special transmittance and reflectance quality have confused the semantictasks related to machine vision. Therefore, how to clear the boundary built byglass, and avoid over-capturing features as false positive information in deepstructure, matters for constraining the segmentation of reflection surface andpenetrating glass. We proposed the Fourier Boundary Features Network with WiderCatchers (FBWC), which might be the first attempt to utilize sufficiently widehorizontal shallow branches without vertical deepening for guiding the finegranularity segmentation boundary through primary glass semantic information.Specifically, we designed the Wider Coarse-Catchers (WCC) for anchoring largearea segmentation and reducing excessive extraction from a structuralperspective. We embed fine-grained features by Cross Transpose Attention (CTA),which is introduced to avoid the incomplete area within the boundary caused byreflection noise. For excavating glass features and balancing high-low layerscontext, a learnable Fourier Convolution Controller (FCC) is proposed toregulate information integration robustly. The proposed method has beenvalidated on three different public glass segmentation datasets. Experimentalresults reveal that the proposed method yields better segmentation performancecompared with the state-of-the-art (SOTA) methods in glass image segmentation.</description><author>Xiaolin Qin, Jiacen Liu, Qianlei Wang, Shaolin Zhang, Fei Zhu, Zhang Yi</author><pubDate>Wed, 15 May 2024 16:52:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09459v1</guid></item><item><title>Tell Me Why: Explainable Public Health Fact-Checking with Large Language Models</title><link>http://arxiv.org/abs/2405.09454v1</link><description>This paper presents a comprehensive analysis of explainable fact-checkingthrough a series of experiments, focusing on the ability of large languagemodels to verify public health claims and provide explanations orjustifications for their veracity assessments. We examine the effectiveness ofzero/few-shot prompting and parameter-efficient fine-tuning across various openand closed-source models, examining their performance in both isolated andjoint tasks of veracity prediction and explanation generation. Importantly, weemploy a dual evaluation approach comprising previously established automaticmetrics and a novel set of criteria through human evaluation. Our automaticevaluation indicates that, within the zero-shot scenario, GPT-4 emerges as thestandout performer, but in few-shot and parameter-efficient fine-tuningcontexts, open-source models demonstrate their capacity to not only bridge theperformance gap but, in some instances, surpass GPT-4. Human evaluation revealsyet more nuance as well as indicating potential problems with the goldexplanations.</description><author>Majid Zarharan, Pascal Wullschleger, Babak Behkam Kia, Mohammad Taher Pilehvar, Jennifer Foster</author><pubDate>Wed, 15 May 2024 16:49:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09454v1</guid></item><item><title>Kuramoto Oscillators and Swarms on Manifolds for Geometry Informed Machine Learning</title><link>http://arxiv.org/abs/2405.09453v1</link><description>We propose the idea of using Kuramoto models (including theirhigher-dimensional generalizations) for machine learning over non-Euclideandata sets. These models are systems of matrix ODE's describing collectivemotions (swarming dynamics) of abstract particles (generalized oscillators) onspheres, homogeneous spaces and Lie groups. Such models have been extensivelystudied from the beginning of XXI century both in statistical physics andcontrol theory. They provide a suitable framework for encoding maps betweenvarious manifolds and are capable of learning over spherical and hyperbolicgeometries. In addition, they can learn coupled actions of transformationgroups (such as special orthogonal, unitary and Lorentz groups). Furthermore,we overview families of probability distributions that provide appropriatestatistical models for probabilistic modeling and inference in Geometric DeepLearning. We argue in favor of using statistical models which arise indifferent Kuramoto models in the continuum limit of particles. The mostconvenient families of probability distributions are those which are invariantwith respect to actions of certain symmetry groups.</description><author>Vladimir Jacimovic</author><pubDate>Wed, 15 May 2024 16:48:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09453v1</guid></item><item><title>Adversarial Consistency and the Uniqueness of the Adversarial Bayes Classifier</title><link>http://arxiv.org/abs/2404.17358v2</link><description>Adversarial training is a common technique for learning robust classifiers.Prior work showed that convex surrogate losses are not statistically consistentin the adversarial context -- or in other words, a minimizing sequence of theadversarial surrogate risk will not necessarily minimize the adversarialclassification error. We connect the consistency of adversarial surrogatelosses to properties of minimizers to the adversarial classification risk,known as \emph{adversarial Bayes classifiers}. Specifically, under reasonabledistributional assumptions, a convex loss is statistically consistent foradversarial learning iff the adversarial Bayes classifier satisfies a certainnotion of uniqueness.</description><author>Natalie S. Frank</author><pubDate>Wed, 15 May 2024 16:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17358v2</guid></item><item><title>Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense of Privacy</title><link>http://arxiv.org/abs/2403.01218v2</link><description>The high cost of model training makes it increasingly desirable to developtechniques for unlearning. These techniques seek to remove the influence of atraining example without having to retrain the model from scratch. Intuitively,once a model has unlearned, an adversary that interacts with the model shouldno longer be able to tell whether the unlearned example was included in themodel's training set or not. In the privacy literature, this is known asmembership inference. In this work, we discuss adaptations of MembershipInference Attacks (MIAs) to the setting of unlearning (leading to their``U-MIA'' counterparts). We propose a categorization of existing U-MIAs into``population U-MIAs'', where the same attacker is instantiated for allexamples, and ``per-example U-MIAs'', where a dedicated attacker isinstantiated for each example. We show that the latter category, wherein theattacker tailors its membership prediction to each example under attack, issignificantly stronger. Indeed, our results show that the commonly used U-MIAsin the unlearning literature overestimate the privacy protection afforded byexisting unlearning techniques on both vision and language models. Ourinvestigation reveals a large variance in the vulnerability of differentexamples to per-example U-MIAs. In fact, several unlearning algorithms lead toa reduced vulnerability for some, but not all, examples that we wish tounlearn, at the expense of increasing it for other examples. Notably, we findthat the privacy protection for the remaining training examples may worsen as aconsequence of unlearning. We also discuss the fundamental difficulty ofequally protecting all examples using existing unlearning schemes, due to thedifferent rates at which examples are unlearned. We demonstrate that naiveattempts at tailoring unlearning stopping criteria to different examples failto alleviate these issues.</description><author>Jamie Hayes, Ilia Shumailov, Eleni Triantafillou, Amr Khalifa, Nicolas Papernot</author><pubDate>Wed, 15 May 2024 16:41:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01218v2</guid></item><item><title>A Resource Model For Neural Scaling Law</title><link>http://arxiv.org/abs/2402.05164v2</link><description>Neural scaling laws characterize how model performance improves as the modelsize scales up. Inspired by empirical observations, we introduce a resourcemodel of neural scaling. A task is usually composite hence can be decomposedinto many subtasks, which compete for resources (measured by the number ofneurons allocated to subtasks). On toy problems, we empirically find that: (1)The loss of a subtask is inversely proportional to its allocated neurons. (2)When multiple subtasks are present in a composite task, the resources acquiredby each subtask uniformly grow as models get larger, keeping the ratios ofacquired resources constants. We hypothesize these findings to be generallytrue and build a model to predict neural scaling laws for general compositetasks, which successfully replicates the neural scaling law of Chinchillamodels reported in arXiv:2203.15556. We believe that the notion of resourceused in this paper will be a useful tool for characterizing and diagnosingneural networks.</description><author>Jinyeop Song, Ziming Liu, Max Tegmark, Jeff Gore</author><pubDate>Wed, 15 May 2024 16:39:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05164v2</guid></item><item><title>Desk-AId: Humanitarian Aid Desk Assessment with Geospatial AI for Predicting Landmine Areas</title><link>http://arxiv.org/abs/2405.09444v1</link><description>The process of clearing areas, namely demining, starts by assessing andprioritizing potential hazardous areas (i.e., desk assessment) to go underthorough investigation of experts, who confirm the risk and proceed with themines clearance operations. This paper presents Desk-AId that supports the deskassessment phase by estimating landmine risks using geospatial data andsocioeconomic information. Desk-AId uses a Geospatial AI approach specializedto landmines. The approach includes mixed data sampling strategies andcontext-enrichment by historical conflicts and key multi-domain facilities(e.g., buildings, roads, health sites). The proposed system addresses the issueof having only ground-truth for confirmed hazardous areas by implementing a newhard-negative data sampling strategy, where negative points are sampled in thevicinity of hazardous areas. Experiments validate Desk-Aid in two domains forlandmine risk assessment: 1) country-wide, and 2) uncharted study areas). Theproposed approach increases the estimation accuracies up to 92%, for differentclassification models such as RandomForest (RF), Feedforward Neural Networks(FNN), and Graph Neural Networks (GNN).</description><author>Flavio Cirillo, Gürkan Solmaz, Yi-Hsuan Peng, Christian Bizer, Martin Jebens</author><pubDate>Wed, 15 May 2024 16:39:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09444v1</guid></item><item><title>MAmmoTH2: Scaling Instructions from the Web</title><link>http://arxiv.org/abs/2405.03548v3</link><description>Instruction tuning improves the reasoning abilities of large language models(LLMs), with data quality and scalability being the crucial factors. Mostinstruction tuning data come from human crowd-sourcing or GPT-4 distillation.We propose a paradigm to efficiently harvest 10 million naturally existinginstruction data from the pre-training web corpus to enhance LLM reasoning. Ourapproach involves (1) recalling relevant documents, (2) extractinginstruction-response pairs, and (3) refining the extracted pairs usingopen-source LLMs. Fine-tuning base LLMs on this dataset, we build MAmmoTH2models, which significantly boost performance on reasoning benchmarks. Notably,MAmmoTH2-7B's (Mistral) performance increases from 11% to 34% on MATH and from36% to 67% on GSM8K without training on any in-domain data. Further trainingMAmmoTH2 on public instruction tuning datasets yields MAmmoTH2-Plus, achievingstate-of-the-art performance on several reasoning and chatbot benchmarks. Ourwork demonstrates how to harvest large-scale, high-quality instruction datawithout costly human annotation or GPT-4 distillation, providing a new paradigmfor building better instruction tuning data.</description><author>Xiang Yue, Tuney Zheng, Ge Zhang, Wenhu Chen</author><pubDate>Wed, 15 May 2024 16:37:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03548v3</guid></item><item><title>Tailoring Instructions to Student's Learning Levels Boosts Knowledge Distillation</title><link>http://arxiv.org/abs/2305.09651v3</link><description>It has been commonly observed that a teacher model with superior performancedoes not necessarily result in a stronger student, highlighting a discrepancybetween current teacher training practices and effective knowledge transfer. Inorder to enhance the guidance of the teacher training process, we introduce theconcept of distillation influence to determine the impact of distillation fromeach training sample on the student's generalization ability. In this paper, wepropose Learning Good Teacher Matters (LGTM), an efficient training techniquefor incorporating distillation influence into the teacher's learning process.By prioritizing samples that are likely to enhance the student's generalizationability, our LGTM outperforms 10 common knowledge distillation baselines on 6text classification tasks in the GLUE benchmark.</description><author>Yuxin Ren, Zihan Zhong, Xingjian Shi, Yi Zhu, Chun Yuan, Mu Li</author><pubDate>Wed, 15 May 2024 16:32:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09651v3</guid></item><item><title>Facilitating Opinion Diversity through Hybrid NLP Approaches</title><link>http://arxiv.org/abs/2405.09439v1</link><description>Modern democracies face a critical issue of declining citizen participationin decision-making. Online discussion forums are an important avenue forenhancing citizen participation. This thesis proposal 1) identifies thechallenges involved in facilitating large-scale online discussions with NaturalLanguage Processing (NLP), 2) suggests solutions to these challenges byincorporating hybrid human-AI technologies, and 3) investigates what thesetechnologies can reveal about individual perspectives in online discussions. Wepropose a three-layered hierarchy for representing perspectives that can beobtained by a mixture of human intelligence and large language models. Weillustrate how these representations can draw insights into the diversity ofperspectives and allow us to investigate interactions in online discussions.</description><author>Michiel van der Meer</author><pubDate>Wed, 15 May 2024 16:30:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09439v1</guid></item><item><title>Multilingual Text-to-Image Generation Magnifies Gender Stereotypes and Prompt Engineering May Not Help You</title><link>http://arxiv.org/abs/2401.16092v3</link><description>Text-to-image generation models have recently achieved astonishing results inimage quality, flexibility, and text alignment, and are consequently employedin a fast-growing number of applications. Through improvements in multilingualabilities, a larger community now has access to this technology. However, ourresults show that multilingual models suffer from significant gender biasesjust as monolingual models do. Furthermore, the natural expectation thatmultilingual models will provide similar results across languages does not holdup. Instead, there are important differences between languages. We propose anovel benchmark, MAGBIG, intended to foster research on gender bias inmultilingual models. We use MAGBIG to investigate the effect of multilingualismon gender bias in T2I models. To this end, we construct multilingual promptsrequesting portraits of people with a certain occupation or trait. Our resultsshow that not only do models exhibit strong gender biases but they also behavedifferently across languages. Furthermore, we investigate prompt engineeringstrategies, such as indirect, neutral formulations, to mitigate these biases.Unfortunately, these approaches have limited success and result in worsetext-to-image alignment. Consequently, we call for more research into diverserepresentations across languages in image generators, as well as intosteerability to address biased model behavior.</description><author>Felix Friedrich, Katharina Hämmerl, Patrick Schramowski, Manuel Brack, Jindrich Libovicky, Kristian Kersting, Alexander Fraser</author><pubDate>Wed, 15 May 2024 16:29:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16092v3</guid></item><item><title>Not My Voice! A Taxonomy of Ethical and Safety Harms of Speech Generators</title><link>http://arxiv.org/abs/2402.01708v2</link><description>The rapid and wide-scale adoption of AI to generate human speech poses arange of significant ethical and safety risks to society that need to beaddressed. For example, a growing number of speech generation incidents areassociated with swatting attacks in the United States, where anonymousperpetrators create synthetic voices that call police officers to close downschools and hospitals, or to violently gain access to innocent citizens' homes.Incidents like this demonstrate that multimodal generative AI risks and harmsdo not exist in isolation, but arise from the interactions of multiplestakeholders and technical AI systems. In this paper we analyse speechgeneration incidents to study how patterns of specific harms arise. We findthat specific harms can be categorised according to the exposure of affectedindividuals, that is to say whether they are a subject of, interact with,suffer due to, or are excluded from speech generation systems. Similarly,specific harms are also a consequence of the motives of the creators anddeployers of the systems. Based on these insights we propose a conceptualframework for modelling pathways to ethical and safety harms of AI, which weuse to develop a taxonomy of harms of speech generators. Our relationalapproach captures the complexity of risks and harms in sociotechnical AIsystems, and yields a taxonomy that can support appropriate policyinterventions and decision making for the responsible development and releaseof speech generation models.</description><author>Wiebke Hutiri, Oresiti Papakyriakopoulos, Alice Xiang</author><pubDate>Wed, 15 May 2024 16:26:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01708v2</guid></item><item><title>A Survey On Text-to-3D Contents Generation In The Wild</title><link>http://arxiv.org/abs/2405.09431v1</link><description>3D content creation plays a vital role in various applications, such asgaming, robotics simulation, and virtual reality. However, the process islabor-intensive and time-consuming, requiring skilled designers to investconsiderable effort in creating a single 3D asset. To address this challenge,text-to-3D generation technologies have emerged as a promising solution forautomating 3D creation. Leveraging the success of large vision language models,these techniques aim to generate 3D content based on textual descriptions.Despite recent advancements in this area, existing solutions still facesignificant limitations in terms of generation quality and efficiency. In thissurvey, we conduct an in-depth investigation of the latest text-to-3D creationmethods. We provide a comprehensive background on text-to-3D creation,including discussions on datasets employed in training and evaluation metricsused to assess the quality of generated 3D models. Then, we delve into thevarious 3D representations that serve as the foundation for the 3D generationprocess. Furthermore, we present a thorough comparison of the rapidly growingliterature on generative pipelines, categorizing them into feedforwardgenerators, optimization-based generation, and view reconstruction approaches.By examining the strengths and weaknesses of these methods, we aim to shedlight on their respective capabilities and limitations. Lastly, we point outseveral promising avenues for future research. With this survey, we hope toinspire researchers further to explore the potential of open-vocabularytext-conditioned 3D content creation.</description><author>Chenhan Jiang</author><pubDate>Wed, 15 May 2024 16:23:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09431v1</guid></item><item><title>Kernel Limit of Recurrent Neural Networks Trained on Ergodic Data Sequences</title><link>http://arxiv.org/abs/2308.14555v2</link><description>Mathematical methods are developed to characterize the asymptotics ofrecurrent neural networks (RNN) as the number of hidden units, data samples inthe sequence, hidden state updates, and training steps simultaneously grow toinfinity. In the case of an RNN with a simplified weight matrix, we prove theconvergence of the RNN to the solution of an infinite-dimensional ODE coupledwith the fixed point of a random algebraic equation. The analysis requiresaddressing several challenges which are unique to RNNs. In typical mean-fieldapplications (e.g., feedforward neural networks), discrete updates are ofmagnitude $\mathcal{O}(\frac{1}{N})$ and the number of updates is$\mathcal{O}(N)$. Therefore, the system can be represented as an Eulerapproximation of an appropriate ODE/PDE, which it will converge to as $N\rightarrow \infty$. However, the RNN hidden layer updates are$\mathcal{O}(1)$. Therefore, RNNs cannot be represented as a discretization ofan ODE/PDE and standard mean-field techniques cannot be applied. Instead, wedevelop a fixed point analysis for the evolution of the RNN memory states, withconvergence estimates in terms of the number of update steps and the number ofhidden units. The RNN hidden layer is studied as a function in a Sobolev space,whose evolution is governed by the data sequence (a Markov chain), theparameter updates, and its dependence on the RNN hidden layer at the previoustime step. Due to the strong correlation between updates, a Poisson equationmust be used to bound the fluctuations of the RNN around its limit equation.These mathematical methods give rise to the neural tangent kernel (NTK) limitsfor RNNs trained on data sequences as the number of data samples and size ofthe neural network grow to infinity.</description><author>Samuel Chun-Hei Lam, Justin Sirignano, Konstantinos Spiliopoulos</author><pubDate>Wed, 15 May 2024 16:21:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.14555v2</guid></item><item><title>Global-Local Image Perceptual Score (GLIPS): Evaluating Photorealistic Quality of AI-Generated Images</title><link>http://arxiv.org/abs/2405.09426v1</link><description>This paper introduces the Global-Local Image Perceptual Score (GLIPS), animage metric designed to assess the photorealistic image quality ofAI-generated images with a high degree of alignment to human visual perception.Traditional metrics such as FID and KID scores do not align closely with humanevaluations. The proposed metric incorporates advanced transformer-basedattention mechanisms to assess local similarity and Maximum Mean Discrepancy(MMD) to evaluate global distributional similarity. To evaluate the performanceof GLIPS, we conducted a human study on photorealistic image quality.Comprehensive tests across various generative models demonstrate that GLIPSconsistently outperforms existing metrics like FID, SSIM, and MS-SSIM in termsof correlation with human scores. Additionally, we introduce the InterpolativeBinning Scale (IBS), a refined scaling method that enhances theinterpretability of metric scores by aligning them more closely with humanevaluative standards. The proposed metric and scaling approach not onlyprovides more reliable assessments of AI-generated images but also suggestpathways for future enhancements in image generation technologies.</description><author>Memoona Aziz, Umair Rehman, Muhammad Umair Danish, Katarina Grolinger</author><pubDate>Wed, 15 May 2024 16:19:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09426v1</guid></item><item><title>Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach</title><link>http://arxiv.org/abs/2402.01454v2</link><description>In practical statistical causal discovery (SCD), embedding domain expertknowledge as constraints into the algorithm is widely accepted as significantfor creating consistent meaningful causal models, despite the recognizedchallenges in systematic acquisition of the background knowledge. To overcomethese challenges, this paper proposes a novel methodology for causal inference,in which SCD methods and knowledge based causal inference (KBCI) with a largelanguage model (LLM) are synthesized through ``statistical causal prompting(SCP)'' for LLMs and prior knowledge augmentation for SCD. Experiments haverevealed that GPT-4 can cause the output of the LLM-KBCI and the SCD resultwith prior knowledge from LLM-KBCI to approach the ground truth, and that theSCD result can be further improved, if GPT-4 undergoes SCP. Furthermore, byusing an unpublished real-world dataset, we have demonstrated that thebackground knowledge provided by the LLM can improve SCD on this dataset, evenif this dataset has never been included in the training data of the LLM. Theproposed approach can thus address challenges such as dataset biases andlimitations, illustrating the potential of LLMs to improve data-driven causalinference across diverse scientific domains.</description><author>Masayuki Takayama, Tadahisa Okuda, Thong Pham, Tatsuyoshi Ikenoue, Shingo Fukuma, Shohei Shimizu, Akiyoshi Sannai</author><pubDate>Wed, 15 May 2024 16:16:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01454v2</guid></item><item><title>Invariant Risk Minimization Is A Total Variation Model</title><link>http://arxiv.org/abs/2405.01389v3</link><description>Invariant risk minimization (IRM) is an arising approach to generalizeinvariant features to different environments in machine learning. While mostrelated works focus on new IRM settings or new application scenarios, themathematical essence of IRM remains to be properly explained. We verify thatIRM is essentially a total variation based on $L^2$ norm (TV-$\ell_2$) of thelearning risk with respect to the classifier variable. Moreover, we propose anovel IRM framework based on the TV-$\ell_1$ model. It not only expands theclasses of functions that can be used as the learning risk, but also has robustperformance in denoising and invariant feature preservation based on the coareaformula. We also illustrate some requirements for IRM-TV-$\ell_1$ to achieveout-of-distribution generalization. Experimental results show that the proposedframework achieves competitive performance in several benchmark machinelearning scenarios.</description><author>Zhao-Rong Lai, Weiwen Wang</author><pubDate>Wed, 15 May 2024 16:14:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01389v3</guid></item><item><title>On the Correspondence of Non-flat Assumption-based Argumentation and Logic Programming with Negation as Failure in the Head</title><link>http://arxiv.org/abs/2405.09415v1</link><description>The relation between (a fragment of) assumption-based argumentation (ABA) andlogic programs (LPs) under stable model semantics is well-studied. However, forobtaining this relation, the ABA framework needs to be restricted to beingflat, i.e., a fragment where the (defeasible) assumptions can never beentailed, only assumed to be true or false. Here, we remove this restrictionand show a correspondence between non-flat ABA and LPs with negation as failurein their head. We then extend this result to so-called set-stable ABAsemantics, originally defined for the fragment of non-flat ABA called bipolarABA. We showcase how to define set-stable semantics for LPs with negation asfailure in their head and show the correspondence to set-stable ABA semantics.</description><author>Anna Rapberger, Markus Ulbricht, Francesca Toni</author><pubDate>Wed, 15 May 2024 16:10:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09415v1</guid></item><item><title>Distinguishing Tor From Other Encrypted Network Traffic Through Character Analysis</title><link>http://arxiv.org/abs/2405.09412v1</link><description>For journalists reporting from a totalitarian regime, whistleblowers andresistance fighters, the anonymous use of cloud services on the Internet can bevital for survival. The Tor network provides a free and widely usedanonymization service for everyone. However, there are different approaches todistinguishing Tor from non-Tor encrypted network traffic, most recently onlydue to the (relative) frequencies of hex digits in a single encrypted payloadpacket. While conventional data traffic is usually encrypted once, but at leastthree times in the case of Tor due to the structure and principle of the Tornetwork, we have examined to what extent the number of encryptions contributesto being able to distinguish Tor from non-Tor encrypted data traffic.</description><author>Pitpimon Choorod, Tobias J. Bauer, Andreas Aßmuth</author><pubDate>Wed, 15 May 2024 16:07:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09412v1</guid></item><item><title>Real-World Federated Learning in Radiology: Hurdles to overcome and Benefits to gain</title><link>http://arxiv.org/abs/2405.09409v1</link><description>Objective: Federated Learning (FL) enables collaborative model training whilekeeping data locally. Currently, most FL studies in radiology are conducted insimulated environments due to numerous hurdles impeding its translation intopractice. The few existing real-world FL initiatives rarely communicatespecific measures taken to overcome these hurdles, leaving behind a significantknowledge gap. Minding efforts to implement real-world FL, there is a notablelack of comprehensive assessment comparing FL to less complex alternatives.Materials &amp; Methods: We extensively reviewed FL literature, categorizinginsights along with our findings according to their nature and phase whileestablishing a FL initiative, summarized to a comprehensive guide. We developedour own FL infrastructure within the German Radiological Cooperative Network(RACOON) and demonstrated its functionality by training FL models on lungpathology segmentation tasks across six university hospitals. We extensivelyevaluated FL against less complex alternatives in three distinct evaluationscenarios. Results: The proposed guide outlines essential steps, identifiedhurdles, and proposed solutions for establishing successful FL initiativesconducting real-world experiments. Our experimental results show that FLoutperforms less complex alternatives in all evaluation scenarios, justifyingthe effort required to translate FL into real-world applications. Discussion &amp;Conclusion: Our proposed guide aims to aid future FL researchers incircumventing pitfalls and accelerating translation of FL into radiologicalapplications. Our results underscore the value of efforts needed to translateFL into real-world applications by demonstrating advantageous performance overalternatives, and emphasize the importance of strategic organization, robustmanagement of distributed data and infrastructure in real-world settings.</description><author>Markus R. Bujotzek, Ünal Akünal, Stefan Denner, Peter Neher, Maximilian Zenk, Eric Frodl, Astha Jaiswal, Moon Kim, Nicolai R. Krekiehn, Manuel Nickel, Richard Ruppel, Marcus Both, Felix Döllinger, Marcel Opitz, Thorsten Persigehl, Jens Kleesiek, Tobias Penzkofer, Klaus Maier-Hein, Rickmer Braren, Andreas Bucher</author><pubDate>Wed, 15 May 2024 16:04:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09409v1</guid></item><item><title>Time-Equivariant Contrastive Learning for Degenerative Disease Progression in Retinal OCT</title><link>http://arxiv.org/abs/2405.09404v1</link><description>Contrastive pretraining provides robust representations by ensuring theirinvariance to different image transformations while simultaneously preventingrepresentational collapse. Equivariant contrastive learning, on the other hand,provides representations sensitive to specific image transformations whileremaining invariant to others. By introducing equivariance to time-inducedtransformations, such as disease-related anatomical changes in longitudinalimaging, the model can effectively capture such changes in the representationspace. In this work, we pro-pose a Time-equivariant Contrastive Learning (TC)method. First, an encoder embeds two unlabeled scans from different time pointsof the same patient into the representation space. Next, a temporalequivariance module is trained to predict the representation of a later visitbased on the representation from one of the previous visits and thecorresponding time interval with a novel regularization loss term whilepreserving the invariance property to irrelevant image transformations. On alarge longitudinal dataset, our model clearly outperforms existing equivariantcontrastive methods in predicting progression from intermediate age-relatedmacular degeneration (AMD) to advanced wet-AMD within a specified time-window.</description><author>Taha Emre, Arunava Chakravarty, Dmitrii Lachinov, Antoine Rivail, Ursula Schmidt-Erfurth, Hrvoje Bogunović</author><pubDate>Wed, 15 May 2024 16:00:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09404v1</guid></item><item><title>Federated Full-Parameter Tuning of Billion-Sized Language Models with Communication Cost under 18 Kilobytes</title><link>http://arxiv.org/abs/2312.06353v4</link><description>Pre-trained large language models (LLMs) need fine-tuning to improve theirresponsiveness to natural language instructions. Federated learning offers away to fine-tune LLMs using the abundant data on end devices withoutcompromising data privacy. Most existing federated fine-tuning methods for LLMsrely on parameter-efficient fine-tuning techniques, which may not reach theperformance height possible with full-parameter tuning. However, federatedfull-parameter tuning of LLMs is a non-trivial problem due to the immensecommunication cost. This work introduces FedKSeed that employs zeroth-orderoptimization with a finite set of random seeds. It significantly reducestransmission requirements between the server and clients to just a few randomseeds and scalar gradients, amounting to only a few thousand bytes, makingfederated full-parameter tuning of billion-sized LLMs possible on devices.Building on it, we develop a strategy enabling probability-differentiated seedsampling, prioritizing perturbations with greater impact on model accuracy.Experiments across six scenarios with various LLMs, datasets and datapartitions demonstrate that our approach outperforms existing federated LLMfine-tuning methods in both communication efficiency and new taskgeneralization.</description><author>Zhen Qin, Daoyuan Chen, Bingchen Qian, Bolin Ding, Yaliang Li, Shuiguang Deng</author><pubDate>Wed, 15 May 2024 15:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06353v4</guid></item><item><title>Identity Overlap Between Face Recognition Train/Test Data: Causing Optimistic Bias in Accuracy Measurement</title><link>http://arxiv.org/abs/2405.09403v1</link><description>A fundamental tenet of pattern recognition is that overlap between trainingand testing sets causes an optimistic accuracy estimate. Deep CNNs for facerecognition are trained for N-way classification of the identities in thetraining set. Accuracy is commonly estimated as average 10-fold classificationaccuracy on image pairs from test sets such as LFW, CALFW, CPLFW, CFP-FP andAgeDB-30. Because train and test sets have been independently assembled, imagesand identities in any given test set may also be present in any given trainingset. In particular, our experiments reveal a surprising degree of identity andimage overlap between the LFW family of test sets and the MS1MV2 training set.Our experiments also reveal identity label noise in MS1MV2. We compare accuracyachieved with same-size MS1MV2 subsets that are identity-disjoint and notidentity-disjoint with LFW, to reveal the size of the optimistic bias. Usingmore challenging test sets from the LFW family, we find that the size of theoptimistic bias is larger for more challenging test sets. Our results highlightthe lack of and the need for identity-disjoint train and test methodology inface recognition research.</description><author>Haiyu Wu, Sicong Tian, Jacob Gutierrez, Aman Bhatta, Kağan Öztürk, Kevin W. Bowyer</author><pubDate>Wed, 15 May 2024 15:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09403v1</guid></item><item><title>Federated Learning and Differential Privacy Techniques on Multi-hospital Population-scale Electrocardiogram Data</title><link>http://arxiv.org/abs/2405.00725v2</link><description>This research paper explores ways to apply Federated Learning (FL) andDifferential Privacy (DP) techniques to population-scale Electrocardiogram(ECG) data. The study learns a multi-label ECG classification model using FLand DP based on 1,565,849 ECG tracings from 7 hospitals in Alberta, Canada. TheFL approach allowed collaborative model training without sharing raw databetween hospitals while building robust ECG classification models fordiagnosing various cardiac conditions. These accurate ECG classification modelscan facilitate the diagnoses while preserving patient confidentiality using FLand DP techniques. Our results show that the performance achieved using ourimplementation of the FL approach is comparable to that of the pooled approach,where the model is trained over the aggregating data from all hospitals.Furthermore, our findings suggest that hospitals with limited ECGs for trainingcan benefit from adopting the FL model compared to single-site training. Inaddition, this study showcases the trade-off between model performance and dataprivacy by employing DP during model training. Our code is available athttps://github.com/vikhyatt/Hospital-FL-DP.</description><author>Vikhyat Agrawal, Sunil Vasu Kalmady, Venkataseetharam Manoj Malipeddi, Manisimha Varma Manthena, Weijie Sun, Saiful Islam, Abram Hindle, Padma Kaul, Russell Greiner</author><pubDate>Wed, 15 May 2024 15:52:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00725v2</guid></item><item><title>Stationarity without mean reversion in improper Gaussian processes</title><link>http://arxiv.org/abs/2310.02877v2</link><description>The behavior of a GP regression depends on the choice of covariance function.Stationary covariance functions are preferred in machine learning applications.However, (non-periodic) stationary covariance functions are always meanreverting and can therefore exhibit pathological behavior when applied to datathat does not relax to a fixed global mean value. In this paper we show that itis possible to use improper GP priors with infinite variance to defineprocesses that are stationary but not mean reverting. To this aim, we use ofnon-positive kernels that can only be defined in this limit regime. Theresulting posterior distributions can be computed analytically and it involvesa simple correction of the usual formulas. The main contribution of the paperis the introduction of a large family of smooth non-reverting covariancefunctions that closely resemble the kernels commonly used in the GP literature(e.g. squared exponential and Mat\'ern class). By analyzing both synthetic andreal data, we demonstrate that these non-positive kernels solve some knownpathologies of mean reverting GP regression while retaining most of thefavorable properties of ordinary smooth stationary kernels.</description><author>Luca Ambrogioni</author><pubDate>Wed, 15 May 2024 15:52:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02877v2</guid></item><item><title>$O_2$ is a multiple context-free grammar: an implementation-, formalisation-friendly proof</title><link>http://arxiv.org/abs/2405.09396v1</link><description>Classifying formal languages according to the expressiveness of grammars ableto generate them is a fundamental problem in computational linguistics and,therefore, in the theory of computation. Furthermore, such kind of analysis cangive insight into the classification of abstract algebraic structure such asgroups, for example through the correspondence given by the word problem. Whilemany such classification problems remain open, others have been settled.Recently, it was proved that $n$-balanced languages (i.e., whose stringscontain the same occurrences of letters $a_i$ and $A_i$ with $1\leq i \leq n$)can be generated by multiple context-free grammars (MCFGs), which are one ofthe several slight extensions of context free grammars added to the classicalChomsky hierarchy to make the mentioned classification more precise. This paperanalyses the existing proofs from the computational and the proof-theoreticalpoint of views, systematically studying whether each proof can lead to averified (i.e., checked by a proof assistant) algorithm parsing balancedlanguages via MCFGs. We conclude that none of the existing proofs isrealistically suitable against this practical goal, and proceed to provide aradically new, elementary, extremely short proof for the crucial case $n \leq2$. A comparative analysis with respect to the existing proofs is finallyperformed to justify why the proposed proof is a substantial step towardsconcretely obtaining a verified parsing algorithm for $O_2$.</description><author>Marco B. Caminati</author><pubDate>Wed, 15 May 2024 15:51:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09396v1</guid></item><item><title>Matching domain experts by training from scratch on domain knowledge</title><link>http://arxiv.org/abs/2405.09395v1</link><description>Recently, large language models (LLMs) have outperformed human experts inpredicting the results of neuroscience experiments (Luo et al., 2024). What isthe basis for this performance? One possibility is that statistical patterns inthat specific scientific literature, as opposed to emergent reasoning abilitiesarising from broader training, underlie LLMs' performance. To evaluate thispossibility, we trained (next word prediction) a relatively small124M-parameter GPT-2 model on 1.3 billion tokens of domain-specific knowledge.Despite being orders of magnitude smaller than larger LLMs trained on trillionsof tokens, small models achieved expert-level performance in predictingneuroscience results. Small models trained on the neuroscience literaturesucceeded when they were trained from scratch using a tokenizer specificallytrained on neuroscience text or when the neuroscience literature was used tofinetune a pretrained GPT-2. Our results indicate that expert-level performancemay be attained by even small LLMs through domain-specific, auto-regressivetraining approaches.</description><author>Xiaoliang Luo, Guangzhi Sun, Bradley C. Love</author><pubDate>Wed, 15 May 2024 15:50:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09395v1</guid></item><item><title>SA-FedLora: Adaptive Parameter Allocation for Efficient Federated Learning with LoRA Tuning</title><link>http://arxiv.org/abs/2405.09394v1</link><description>Fine-tuning large-scale pre-trained models via transfer learning is anemerging important paradigm for a wide range of downstream tasks, withperformance heavily reliant on extensive data. Federated learning (FL), as adistributed framework, provides a secure solution to train models on localdatasets while safeguarding raw sensitive data. However, FL networks encounterhigh communication costs due to the massive parameters of large-scalepre-trained models, necessitating parameter-efficient methods. Notably,parameter efficient fine tuning, such as Low-Rank Adaptation (LoRA), has shownremarkable success in fine-tuning pre-trained models. However, prior researchindicates that the fixed parameter budget may be prone to the overfitting orslower convergence. To address this challenge, we propose a SimulatedAnnealing-based Federated Learning with LoRA tuning (SA-FedLoRA) approach byreducing trainable parameters. Specifically, SA-FedLoRA comprises two stages:initiating and annealing. (1) In the initiating stage, we implement a parameterregularization approach during the early rounds of aggregation, aiming tomitigate client drift and accelerate the convergence for the subsequent tuning.(2) In the annealing stage, we allocate higher parameter budget during theearly 'heating' phase and then gradually shrink the budget until the 'cooling'phase. This strategy not only facilitates convergence to the global optimum butalso reduces communication costs. Experimental results demonstrate thatSA-FedLoRA is an efficient FL, achieving superior performance to FedAvg andsignificantly reducing communication parameters by up to 93.62%.</description><author>Yuning Yang, Xiaohong Liu, Tianrun Gao, Xiaodong Xu, Guangyu Wang</author><pubDate>Wed, 15 May 2024 15:50:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09394v1</guid></item><item><title>LLM Voting: Human Choices and AI Collective Decision Making</title><link>http://arxiv.org/abs/2402.01766v2</link><description>This paper investigates the voting behaviors of Large Language Models (LLMs),specifically GPT-4 and LLaMA-2, their biases, and how they align with humanvoting patterns. Our methodology involved using a dataset from a human votingexperiment to establish a baseline for human preferences and a correspondingexperiment with LLM agents. We observed that the methods used for voting inputand the presentation of choices influence LLM voting behavior. We discoveredthat varying the persona can reduce some of these biases and enhance alignmentwith human choices. While the Chain-of-Thought approach did not improveprediction accuracy, it has potential for AI explainability in the votingprocess. We also identified a trade-off between preference diversity andalignment accuracy in LLMs, influenced by different temperature settings. Ourfindings indicate that LLMs may lead to less diverse collective outcomes andbiased assumptions when used in voting scenarios, emphasizing the importance ofcautious integration of LLMs into democratic processes.</description><author>Joshua C. Yang, Damian Dailisan, Marcin Korecki, Carina I. Hausladen, Dirk Helbing</author><pubDate>Wed, 15 May 2024 15:50:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01766v2</guid></item><item><title>Phylotrack: C++ and Python libraries for in silico phylogenetic tracking</title><link>http://arxiv.org/abs/2405.09389v1</link><description>In silico evolution instantiates the processes of heredity, variation, anddifferential reproductive success (the three "ingredients" for evolution bynatural selection) within digital populations of computational agents.Consequently, these populations undergo evolution, and can be used as virtualmodel systems for studying evolutionary dynamics. This experimental paradigm --used across biological modeling, artificial life, and evolutionary computation-- complements research done using in vitro and in vivo systems by enablingexperiments that would be impossible in the lab or field. One key benefit iscomplete, exact observability. For example, it is possible to perfectly recordall parent-child relationships across simulation history, yielding completephylogenies (ancestry trees). This information reveals when traits were gainedor lost, and also facilitates inference of underlying evolutionary dynamics. The Phylotrack project provides libraries for tracking and analyzingphylogenies in in silico evolution. The project is composed of 1)Phylotracklib: a header-only C++ library, developed under the umbrella of theEmpirical project, and 2) Phylotrackpy: a Python wrapper around Phylotracklib,created with Pybind11. Both components supply a public-facing API to attachphylogenetic tracking to digital evolution systems, as well as a stand-aloneinterface for measuring a variety of popular phylogenetic topology metrics.Underlying design and C++ implementation prioritizes efficiency, allowing forfast generational turnover for agent populations numbering in the tens ofthousands. Several explicit features (e.g., phylogeny pruning and abstraction,etc.) are provided for reducing the memory footprint of phylogeneticinformation.</description><author>Emily Dolson, Santiago Rodriguez-Papa, Matthew Andres Moreno</author><pubDate>Wed, 15 May 2024 15:47:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09389v1</guid></item><item><title>Robust Lagrangian and Adversarial Policy Gradient for Robust Constrained Markov Decision Processes</title><link>http://arxiv.org/abs/2308.11267v3</link><description>The robust constrained Markov decision process (RCMDP) is a recenttask-modelling framework for reinforcement learning that incorporatesbehavioural constraints and that provides robustness to errors in thetransition dynamics model through the use of an uncertainty set. SimulatingRCMDPs requires computing the worst-case dynamics based on value estimates foreach state, an approach which has previously been used in the RobustConstrained Policy Gradient (RCPG). Highlighting potential downsides of RCPGsuch as not robustifying the full constrained objective and the lack ofincremental learning, this paper introduces two algorithms, called RCPG withRobust Lagrangian and Adversarial RCPG. RCPG with Robust Lagrangian modifiesRCPG by taking the worst-case dynamics based on the Lagrangian rather thaneither the value or the constraint. Adversarial RCPG also formulates theworst-case dynamics based on the Lagrangian but learns this directly andincrementally as an adversarial policy through gradient descent rather thanindirectly and abruptly through constrained optimisation on a sorted valuelist. A theoretical analysis first derives the Lagrangian policy gradient forthe policy optimisation of both proposed algorithms and then the adversarialpolicy gradient to learn the adversary for Adversarial RCPG. Empiricalexperiments injecting perturbations in inventory management and safe navigationtasks demonstrate the competitive performance of both algorithms compared totraditional RCPG variants as well as non-robust and non-constrained ablations.In particular, Adversarial RCPG ranks among the top two performing algorithmson all tests.</description><author>David M. Bossens</author><pubDate>Wed, 15 May 2024 15:46:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11267v3</guid></item><item><title>Parameter-Efficient Instruction Tuning of Large Language Models For Extreme Financial Numeral Labelling</title><link>http://arxiv.org/abs/2405.06671v2</link><description>We study the problem of automatically annotating relevant numerals (GAAPmetrics) occurring in the financial documents with their corresponding XBRLtags. Different from prior works, we investigate the feasibility of solvingthis extreme classification problem using a generative paradigm throughinstruction tuning of Large Language Models (LLMs). To this end, we leveragemetric metadata information to frame our target outputs while proposing aparameter efficient solution for the task using LoRA. We perform experiments ontwo recently released financial numeric labeling datasets. Our proposed model,FLAN-FinXC, achieves new state-of-the-art performances on both the datasets,outperforming several strong baselines. We explain the better scores of ourproposed model by demonstrating its capability for zero-shot as well as theleast frequently occurring tags. Also, even when we fail to predict the XBRLtags correctly, our generated output has substantial overlap with theground-truth in majority of the cases.</description><author>Subhendu Khatuya, Rajdeep Mukherjee, Akash Ghosh, Manjunath Hegde, Koustuv Dasgupta, Niloy Ganguly, Saptarshi Ghosh, Pawan Goyal</author><pubDate>Wed, 15 May 2024 15:43:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06671v2</guid></item><item><title>Sourcerer: Sample-based Maximum Entropy Source Distribution Estimation</title><link>http://arxiv.org/abs/2402.07808v2</link><description>Scientific modeling applications often require estimating a distribution ofparameters consistent with a dataset of observations - an inference task alsoknown as source distribution estimation. This problem can be ill-posed,however, since many different source distributions might produce the samedistribution of data-consistent simulations. To make a principled choice amongmany equally valid sources, we propose an approach which targets the maximumentropy distribution, i.e., prioritizes retaining as much uncertainty aspossible. Our method is purely sample-based - leveraging the Sliced-Wassersteindistance to measure the discrepancy between the dataset and simulations - andthus suitable for simulators with intractable likelihoods. We benchmark ourmethod on several tasks, and show that it can recover source distributions withsubstantially higher entropy than recent source estimation methods, withoutsacrificing the fidelity of the simulations. Finally, to demonstrate theutility of our approach, we infer source distributions for parameters of theHodgkin-Huxley model from experimental datasets with thousands of single-neuronmeasurements. In summary, we propose a principled method for inferring sourcedistributions of scientific simulator parameters while retaining as muchuncertainty as possible.</description><author>Julius Vetter, Guy Moss, Cornelius Schröder, Richard Gao, Jakob H. Macke</author><pubDate>Wed, 15 May 2024 15:32:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07808v2</guid></item><item><title>PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models</title><link>http://arxiv.org/abs/2405.09373v1</link><description>Recent advances in large language models (LLMs) have led to their extensiveglobal deployment, and ensuring their safety calls for comprehensive andmultilingual toxicity evaluations. However, existing toxicity benchmarks areoverwhelmingly focused on English, posing serious risks to deploying LLMs inother languages. We address this by introducing PolygloToxicityPrompts (PTP),the first large-scale multilingual toxicity evaluation benchmark of 425Knaturally occurring prompts spanning 17 languages. We overcome the scarcity ofnaturally occurring toxicity in web-text and ensure coverage across languageswith varying resources by automatically scraping over 100M web-text documents.Using PTP, we investigate research questions to study the impact of model size,prompt language, and instruction and preference-tuning methods on toxicity bybenchmarking over 60 LLMs. Notably, we find that toxicity increases as languageresources decrease or model size increases. Although instruction- andpreference-tuning reduce toxicity, the choice of preference-tuning method doesnot have any significant impact. Our findings shed light on crucialshortcomings of LLM safeguarding and highlight areas for future research.</description><author>Devansh Jain, Priyanshu Kumar, Samuel Gehman, Xuhui Zhou, Thomas Hartvigsen, Maarten Sap</author><pubDate>Wed, 15 May 2024 15:22:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09373v1</guid></item><item><title>SARATR-X: A Foundation Model for Synthetic Aperture Radar Images Target Recognition</title><link>http://arxiv.org/abs/2405.09365v1</link><description>Synthetic aperture radar (SAR) is essential in actively acquiring informationfor Earth observation. SAR Automatic Target Recognition (ATR) focuses ondetecting and classifying various target categories under different imageconditions. The current deep learning-based SAR ATR methods are typicallydesigned for specific datasets and applications. Various targetcharacteristics, scene background information, and sensor parameters across ATRdatasets challenge the generalization of those methods. This paper aims toachieve general SAR ATR based on a foundation model with Self-SupervisedLearning (SSL). Our motivation is to break through the specific dataset andcondition limitations and obtain universal perceptual capabilities across thetarget, scene, and sensor. A foundation model named SARATR-X is proposed withthe following four aspects: pre-training dataset, model backbone, SSL, andevaluation task. First, we integrated 14 datasets with various targetcategories and imaging conditions as a pre-training dataset. Second, differentmodel backbones were discussed to find the most suitable approaches forremote-sensing images. Third, we applied two-stage training and SAR gradientfeatures to ensure the diversity and scalability of SARATR-X. Finally, SARATR-Xhas achieved competitive and superior performance on 5 datasets with 8 tasksettings, which shows that the foundation model can achieve universal SAR ATR.We believe it is time to embrace fundamental models for SAR imageinterpretation in the era of increasing big data.</description><author>Weijie L, Wei Yang, Yuenan Hou, Li Liu, Yongxiang Liu, Xiang Li</author><pubDate>Wed, 15 May 2024 15:17:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09365v1</guid></item><item><title>On the Saturation Effect of Kernel Ridge Regression</title><link>http://arxiv.org/abs/2405.09362v1</link><description>The saturation effect refers to the phenomenon that the kernel ridgeregression (KRR) fails to achieve the information theoretical lower bound whenthe smoothness of the underground truth function exceeds certain level. Thesaturation effect has been widely observed in practices and a saturation lowerbound of KRR has been conjectured for decades. In this paper, we provide aproof of this long-standing conjecture.</description><author>Yicheng Li, Haobo Zhang, Qian Lin</author><pubDate>Wed, 15 May 2024 15:15:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09362v1</guid></item><item><title>RAGFormer: Learning Semantic Attributes and Topological Structure for Fraud Detection</title><link>http://arxiv.org/abs/2402.17472v2</link><description>Fraud detection remains a challenging task due to the complex and deceptivenature of fraudulent activities. Current approaches primarily concentrate onlearning only one perspective of the graph: either the topological structure ofthe graph or the attributes of individual nodes. However, we conduct empiricalstudies to reveal that these two types of features, while nearly orthogonal,are each independently effective. As a result, previous methods can not fullycapture the comprehensive characteristics of the fraud graph. To address thisdilemma, we present a novel framework called Relation-Aware GNN withtransFormer~(RAGFormer) which simultaneously embeds both semantic andtopological features into a target node. The simple yet effective networkconsists of a semantic encoder, a topology encoder, and an attention fusionmodule. The semantic encoder utilizes Transformer to learn semantic featuresand node interactions across different relations. We introduce Relation-AwareGNN as the topology encoder to learn topological features and node interactionswithin each relation. These two complementary features are interleaved throughan attention fusion module to support prediction by both orthogonal features.Extensive experiments on two popular public datasets demonstrate that RAGFormerachieves state-of-the-art performance. The significant improvement of RAGFormerin an industrial credit card fraud detection dataset further validates theapplicability of our method in real-world business scenarios.</description><author>Haolin Li, Shuyang Jiang, Lifeng Zhang, Siyuan Du, Guangnan Ye, Hongfeng Chai</author><pubDate>Wed, 15 May 2024 15:13:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17472v2</guid></item><item><title>The Unfairness of $\varepsilon$-Fairness</title><link>http://arxiv.org/abs/2405.09360v1</link><description>Fairness in decision-making processes is often quantified using probabilisticmetrics. However, these metrics may not fully capture the real-worldconsequences of unfairness. In this article, we adopt a utility-based approachto more accurately measure the real-world impacts of decision-making process.In particular, we show that if the concept of $\varepsilon$-fairness isemployed, it can possibly lead to outcomes that are maximally unfair in thereal-world context. Additionally, we address the common issue of unavailabledata on false negatives by proposing a reduced setting that still capturesessential fairness considerations. We illustrate our findings with tworeal-world examples: college admissions and credit risk assessment. Ouranalysis reveals that while traditional probability-based evaluations mightsuggest fairness, a utility-based approach uncovers the necessary actions totruly achieve equality. For instance, in the college admission case, we findthat enhancing completion rates is crucial for ensuring fairness. Summarizing,this paper highlights the importance of considering the real-world context whenevaluating fairness.</description><author>Tolulope Fadina, Thorsten Schmidt</author><pubDate>Wed, 15 May 2024 15:13:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09360v1</guid></item><item><title>Vision-Based Neurosurgical Guidance: Unsupervised Localization and Camera-Pose Prediction</title><link>http://arxiv.org/abs/2405.09355v1</link><description>Localizing oneself during endoscopic procedures can be problematic due to thelack of distinguishable textures and landmarks, as well as difficulties due tothe endoscopic device such as a limited field of view and challenging lightingconditions. Expert knowledge shaped by years of experience is required forlocalization within the human body during endoscopic procedures. In this work,we present a deep learning method based on anatomy recognition, that constructsa surgical path in an unsupervised manner from surgical videos, modellingrelative location and variations due to different viewing angles. At inferencetime, the model can map an unseen video's frames on the path and estimate theviewing angle, aiming to provide guidance, for instance, to reach a particulardestination. We test the method on a dataset consisting of surgical videos oftranssphenoidal adenomectomies, as well as on a synthetic dataset. An onlinetool that lets researchers upload their surgical videos to obtain anatomydetections and the weights of the trained YOLOv7 model are available at:https://surgicalvision.bmic.ethz.ch.</description><author>Gary Sarwin, Alessandro Carretta, Victor Staartjes, Matteo Zoli, Diego Mazzatenta, Luca Regli, Carlo Serra, Ender Konukoglu</author><pubDate>Wed, 15 May 2024 15:09:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09355v1</guid></item><item><title>Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset</title><link>http://arxiv.org/abs/2404.02543v3</link><description>Unbiased learning-to-rank (ULTR) is a well-established framework for learningfrom user clicks, which are often biased by the ranker collecting the data.While theoretically justified and extensively tested in simulation, ULTRtechniques lack empirical validation, especially on modern search engines. TheBaidu-ULTR dataset released for the WSDM Cup 2023, collected from Baidu'ssearch engine, offers a rare opportunity to assess the real-world performanceof prominent ULTR techniques. Despite multiple submissions during the WSDM Cup2023 and the subsequent NTCIR ULTRE-2 task, it remains unclear whether theobserved improvements stem from applying ULTR or other learning techniques. In this work, we revisit and extend the available experiments on theBaidu-ULTR dataset. We find that standard unbiased learning-to-rank techniquesrobustly improve click predictions but struggle to consistently improve rankingperformance, especially considering the stark differences obtained by choice ofranking loss and query-document features. Our experiments reveal that gains inclick prediction do not necessarily translate to enhanced ranking performanceon expert relevance annotations, implying that conclusions strongly depend onhow success is measured in this benchmark.</description><author>Philipp Hager, Romain Deffayet, Jean-Michel Renders, Onno Zoeter, Maarten de Rijke</author><pubDate>Wed, 15 May 2024 15:04:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02543v3</guid></item><item><title>Large coordinate kernel attention network for lightweight image super-resolution</title><link>http://arxiv.org/abs/2405.09353v1</link><description>The multi-scale receptive field and large kernel attention (LKA) module havebeen shown to significantly improve performance in the lightweight imagesuper-resolution task. However, existing lightweight super-resolution (SR)methods seldom pay attention to designing efficient building block withmulti-scale receptive field for local modeling, and their LKA modules face aquadratic increase in computational and memory footprints as the convolutionalkernel size increases. To address the first issue, we propose the multi-scaleblueprint separable convolutions (MBSConv) as highly efficient building blockwith multi-scale receptive field, it can focus on the learning for themulti-scale information which is a vital component of discriminativerepresentation. As for the second issue, we revisit the key properties of LKAin which we find that the adjacent direct interaction of local information andlong-distance dependencies is crucial to provide remarkable performance. Thus,taking this into account and in order to mitigate the complexity of LKA, wepropose a large coordinate kernel attention (LCKA) module which decomposes the2D convolutional kernels of the depth-wise convolutional layers in LKA intohorizontal and vertical 1-D kernels. LCKA enables the adjacent directinteraction of local information and long-distance dependencies not only in thehorizontal direction but also in the vertical. Besides, LCKA allows for thedirect use of extremely large kernels in the depth-wise convolutional layers tocapture more contextual information, which helps to significantly improve thereconstruction performance, and it incurs lower computational complexity andmemory footprints. Integrating MBSConv and LCKA, we propose a large coordinatekernel attention network (LCAN).</description><author>Fangwei Hao, Jiesheng Wu, Haotian Lu, Ji Du, Jing Xu</author><pubDate>Wed, 15 May 2024 15:03:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09353v1</guid></item><item><title>Analysis of the Geometric Structure of Neural Networks and Neural ODEs via Morse Functions</title><link>http://arxiv.org/abs/2405.09351v1</link><description>Besides classical feed-forward neural networks, also neural ordinarydifferential equations (neural ODEs) gained particular interest in recentyears. Neural ODEs can be interpreted as an infinite depth limit offeed-forward or residual neural networks. We study the input-output dynamics offinite and infinite depth neural networks with scalar output. In the finitedepth case, the input is a state associated to a finite number of nodes, whichmaps under multiple non-linear transformations to the state of one output node.In analogy, a neural ODE maps a linear transformation of the input to a lineartransformation of its time-$T$ map. We show that depending on the specificstructure of the network, the input-output map has different propertiesregarding the existence and regularity of critical points. These properties canbe characterized via Morse functions, which are scalar functions, where everycritical point is non-degenerate. We prove that critical points cannot exist,if the dimension of the hidden layer is monotonically decreasing or thedimension of the phase space is smaller or equal to the input dimension. In thecase that critical points exist, we classify their regularity depending on thespecific architecture of the network. We show that each critical point isnon-degenerate, if for finite depth neural networks the underlying graph has nobottleneck, and if for neural ODEs, the linear transformations used have fullrank. For each type of architecture, the proven properties are comparable inthe finite and in the infinite depth case. The established theorems allow us toformulate results on universal embedding, i.e.\ on the exact representation ofmaps by neural networks and neural ODEs. Our dynamical systems viewpoint on thegeometric structure of the input-output map provides a fundamentalunderstanding, why certain architectures perform better than others.</description><author>Christian Kuehn, Sara-Viola Kuntz</author><pubDate>Wed, 15 May 2024 15:00:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09351v1</guid></item><item><title>Learning Reward for Robot Skills Using Large Language Models via Self-Alignment</title><link>http://arxiv.org/abs/2405.07162v2</link><description>Learning reward functions remains the bottleneck to equip a robot with abroad repertoire of skills. Large Language Models (LLM) contain valuabletask-related knowledge that can potentially aid in the learning of rewardfunctions. However, the proposed reward function can be imprecise, thusineffective which requires to be further grounded with environment information.We proposed a method to learn rewards more efficiently in the absence ofhumans. Our approach consists of two components: We first use the LLM topropose features and parameterization of the reward, then update the parametersthrough an iterative self-alignment process. In particular, the processminimizes the ranking inconsistency between the LLM and the learnt rewardfunctions based on the execution feedback. The method was validated on 9 tasksacross 2 simulation environments. It demonstrates a consistent improvement overtraining efficacy and efficiency, meanwhile consuming significantly fewer GPTtokens compared to the alternative mutation-based method.</description><author>Yuwei Zeng, Yao Mu, Lin Shao</author><pubDate>Wed, 15 May 2024 14:59:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.07162v2</guid></item><item><title>BiLLM: Pushing the Limit of Post-Training Quantization for LLMs</title><link>http://arxiv.org/abs/2402.04291v2</link><description>Pretrained large language models (LLMs) exhibit exceptional general languageprocessing capabilities but come with significant demands on memory andcomputational resources. As a powerful compression technology, binarization canextremely reduce model weights to a mere 1 bit, lowering the expensivecomputation and memory requirements. However, existing quantization techniquesfall short of maintaining LLM performance under ultra-low bit-widths. Inresponse to this challenge, we present BiLLM, a groundbreaking 1-bitpost-training quantization scheme tailored for pretrained LLMs. Based on theweight distribution of LLMs, BiLLM first identifies and structurally selectssalient weights, and minimizes the compression loss through an effective binaryresidual approximation strategy. Moreover, considering the bell-shapeddistribution of the non-salient weights, we propose an optimal splitting searchto group and binarize them accurately. BiLLM achieving for the first timehigh-accuracy inference (e.g. 8.41 perplexity on LLaMA2-70B) with only 1.08-bitweights across various LLMs families and evaluation metrics, outperforms SOTAquantization methods of LLM by significant margins. Moreover, BiLLM enables thebinarization process of the LLM with 7 billion weights within 0.5 hours on asingle GPU, demonstrating satisfactory time efficiency. Our code is availableat https://github.com/Aaronhuang-778/BiLLM.</description><author>Wei Huang, Yangdong Liu, Haotong Qin, Ying Li, Shiming Zhang, Xianglong Liu, Michele Magno, Xiaojuan Qi</author><pubDate>Wed, 15 May 2024 14:55:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04291v2</guid></item><item><title>A vector quantized masked autoencoder for audiovisual speech emotion recognition</title><link>http://arxiv.org/abs/2305.03568v2</link><description>The limited availability of labeled data is a major challenge in audiovisualspeech emotion recognition (SER). Self-supervised learning approaches haverecently been proposed to mitigate the need for labeled data in variousapplications. This paper proposes the VQ-MAE-AV model, a vector quantizedmasked autoencoder (MAE) designed for audiovisual speech self-supervisedrepresentation learning and applied to SER. Unlike previous approaches, theproposed method employs a self-supervised paradigm based on discrete audio andvisual speech representations learned by vector quantized variationalautoencoders. A multimodal MAE with self- or cross-attention mechanisms isproposed to fuse the audio and visual speech modalities and to learn local andglobal representations of the audiovisual speech sequence, which are then usedfor an SER downstream task. Experimental results show that the proposedapproach, which is pre-trained on the VoxCeleb2 database and fine-tuned onstandard emotional audiovisual speech datasets, outperforms thestate-of-the-art audiovisual SER methods. Extensive ablation experiments arealso provided to assess the contribution of the different model components.</description><author>Samir Sadok, Simon Leglaive, Renaud Séguier</author><pubDate>Wed, 15 May 2024 14:54:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03568v2</guid></item><item><title>Learning functions on symmetric matrices and point clouds via lightweight invariant features</title><link>http://arxiv.org/abs/2405.08097v2</link><description>In this work, we present a mathematical formulation for machine learning of(1) functions on symmetric matrices that are invariant with respect to theaction of permutations by conjugation, and (2) functions on point clouds thatare invariant with respect to rotations, reflections, and permutations of thepoints. To achieve this, we construct $O(n^2)$ invariant features derived fromgenerators for the field of rational functions on $n\times n$ symmetricmatrices that are invariant under joint permutations of rows and columns. Weshow that these invariant features can separate all distinct orbits ofsymmetric matrices except for a measure zero set; such features can be used touniversally approximate invariant functions on almost all weighted graphs. Forpoint clouds in a fixed dimension, we prove that the number of invariantfeatures can be reduced, generically without losing expressivity, to $O(n)$,where $n$ is the number of points. We combine these invariant features withDeepSets to learn functions on symmetric matrices and point clouds with varyingsizes. We empirically demonstrate the feasibility of our approach on moleculeproperty regression and point cloud distance prediction.</description><author>Ben Blum-Smith, Ningyuan Huang, Marco Cuturi, Soledad Villar</author><pubDate>Wed, 15 May 2024 14:48:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08097v2</guid></item><item><title>Progressive Depth Decoupling and Modulating for Flexible Depth Completion</title><link>http://arxiv.org/abs/2405.09342v1</link><description>Image-guided depth completion aims at generating a dense depth map fromsparse LiDAR data and RGB image. Recent methods have shown promisingperformance by reformulating it as a classification problem with two sub-tasks:depth discretization and probability prediction. They divide the depth rangeinto several discrete depth values as depth categories, serving as priors forscene depth distributions. However, previous depth discretization methods areeasy to be impacted by depth distribution variations across different scenes,resulting in suboptimal scene depth distribution priors. To address the aboveproblem, we propose a progressive depth decoupling and modulating network,which incrementally decouples the depth range into bins and adaptivelygenerates multi-scale dense depth maps in multiple stages. Specifically, wefirst design a Bins Initializing Module (BIM) to construct the seed bins byexploring the depth distribution information within a sparse depth map,adapting variations of depth distribution. Then, we devise an incremental depthdecoupling branch to progressively refine the depth distribution informationfrom global to local. Meanwhile, an adaptive depth modulating branch isdeveloped to progressively improve the probability representation fromcoarse-grained to fine-grained. And the bi-directional information interactionsare proposed to strengthen the information interaction between those twobranches (sub-tasks) for promoting information complementation in each branch.Further, we introduce a multi-scale supervision mechanism to learn the depthdistribution information in latent features and enhance the adaptationcapability across different scenes. Experimental results on public datasetsdemonstrate that our method outperforms the state-of-the-art methods. The codewill be open-sourced at [this https URL](https://github.com/Cisse-away/PDDM).</description><author>Zhiwen Yang, Jiehua Zhang, Liang Li, Chenggang Yan, Yaoqi Sun, Haibing Yin</author><pubDate>Wed, 15 May 2024 14:45:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09342v1</guid></item><item><title>Large Language Model Bias Mitigation from the Perspective of Knowledge Editing</title><link>http://arxiv.org/abs/2405.09341v1</link><description>Existing debiasing methods inevitably make unreasonable or undesiredpredictions as they are designated and evaluated to achieve parity acrossdifferent social groups but leave aside individual facts, resulting in modifiedexisting knowledge. In this paper, we first establish a new bias mitigationbenchmark BiasKE leveraging existing and additional constructed datasets, whichsystematically assesses debiasing performance by complementary metrics onfairness, specificity, and generalization. Meanwhile, we propose a noveldebiasing method, Fairness Stamp (FAST), which enables editable fairnessthrough fine-grained calibration on individual biased knowledge. Comprehensiveexperiments demonstrate that FAST surpasses state-of-the-art baselines withremarkable debiasing performance while not hampering overall model capabilityfor knowledge preservation, highlighting the prospect of fine-grained debiasingstrategies for editable fairness in LLMs.</description><author>Ruizhe Chen, Yichen Li, Zikai Xiao, Zuozhu Liu</author><pubDate>Wed, 15 May 2024 14:44:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09341v1</guid></item><item><title>A Survey of Large Language Models in Medicine: Progress, Application, and Challenge</title><link>http://arxiv.org/abs/2311.05112v5</link><description>Large language models (LLMs), such as ChatGPT, have received substantialattention due to their capabilities for understanding and generating humanlanguage. While there has been a burgeoning trend in research focusing on theemployment of LLMs in supporting different medical tasks (e.g., enhancingclinical diagnostics and providing medical education), a review of theseefforts, particularly their development, practical applications, and outcomesin medicine, remains scarce. Therefore, this review aims to provide a detailedoverview of the development and deployment of LLMs in medicine, including thechallenges and opportunities they face. In terms of development, we provide adetailed introduction to the principles of existing medical LLMs, includingtheir basic model structures, number of parameters, and sources and scales ofdata used for model development. It serves as a guide for practitioners indeveloping medical LLMs tailored to their specific needs. In terms ofdeployment, we offer a comparison of the performance of different LLMs acrossvarious medical tasks, and further compare them with state-of-the-artlightweight models, aiming to provide an understanding of the advantages andlimitations of LLMs in medicine. Overall, in this review, we address thefollowing questions: 1) What are the practices for developing medical LLMs 2)How to measure the medical task performance of LLMs in a medical setting? 3)How have medical LLMs been employed in real-world practice? 4) What challengesarise from the use of medical LLMs? and 5) How to more effectively develop anddeploy medical LLMs? By answering these questions, this review aims to provideinsights into the opportunities for LLMs in medicine and serve as a practicalresource. We also maintain a regularly updated list of practical guides onmedical LLMs at: https://github.com/AI-in-Health/MedLLMsPracticalGuide.</description><author>Hongjian Zhou, Fenglin Liu, Boyang Gu, Xinyu Zou, Jinfa Huang, Jinge Wu, Yiru Li, Sam S. Chen, Peilin Zhou, Junling Liu, Yining Hua, Chengfeng Mao, Chenyu You, Xian Wu, Yefeng Zheng, Lei Clifton, Zheng Li, Jiebo Luo, David A. Clifton</author><pubDate>Wed, 15 May 2024 14:38:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05112v5</guid></item><item><title>Prompting-based Synthetic Data Generation for Few-Shot Question Answering</title><link>http://arxiv.org/abs/2405.09335v1</link><description>Although language models (LMs) have boosted the performance of QuestionAnswering, they still need plenty of data. Data annotation, in contrast, is atime-consuming process. This especially applies to Question Answering, wherepossibly large documents have to be parsed and annotated with questions andtheir corresponding answers. Furthermore, Question Answering models often onlywork well for the domain they were trained on. Since annotation is costly, weargue that domain-agnostic knowledge from LMs, such as linguisticunderstanding, is sufficient to create a well-curated dataset. With thismotivation, we show that using large language models can improve QuestionAnswering performance on various datasets in the few-shot setting compared tostate-of-the-art approaches. For this, we perform data generation leveragingthe Prompting framework, suggesting that language models contain valuabletask-agnostic knowledge that can be used beyond the commonpre-training/fine-tuning scheme. As a result, we consistently outperformprevious approaches on few-shot Question Answering.</description><author>Maximilian Schmidt, Andrea Bartezzaghi, Ngoc Thang Vu</author><pubDate>Wed, 15 May 2024 14:36:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09335v1</guid></item><item><title>Simple Techniques for Enhancing Sentence Embeddings in Generative Language Models</title><link>http://arxiv.org/abs/2404.03921v2</link><description>Sentence Embedding stands as a fundamental task within the realm of NaturalLanguage Processing, finding extensive application in search engines, expertsystems, and question-and-answer platforms. With the continuous evolution oflarge language models such as LLaMA and Mistral, research on sentence embeddinghas recently achieved notable breakthroughs. However, these advancements mainlypertain to fine-tuning scenarios, leaving explorations into computationallyefficient direct inference methods for sentence representation in a nascentstage. This paper endeavors to bridge this research gap. Through comprehensiveexperimentation, we challenge the widely held belief in the necessity of anExplicit One-word Limitation for deriving sentence embeddings from Pre-trainedLanguage Models (PLMs). We demonstrate that this approach, while beneficial forgenerative models under direct inference scenario, is not imperative fordiscriminative models or the fine-tuning of generative PLMs. This discoverysheds new light on the design of manual templates in future studies. Buildingupon this insight, we propose two innovative prompt engineering techniquescapable of further enhancing the expressive power of PLMs' raw embeddings:Pretended Chain of Thought and Knowledge Enhancement. We confirm theireffectiveness across various PLM types and provide a detailed exploration ofthe underlying factors contributing to their success.</description><author>Bowen Zhang, Kehua Chang, Chunping Li</author><pubDate>Wed, 15 May 2024 14:34:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03921v2</guid></item><item><title>Content-Based Image Retrieval for Multi-Class Volumetric Radiology Images: A Benchmark Study</title><link>http://arxiv.org/abs/2405.09334v1</link><description>While content-based image retrieval (CBIR) has been extensively studied innatural image retrieval, its application to medical images presents ongoingchallenges, primarily due to the 3D nature of medical images. Recent studieshave shown the potential use of pre-trained vision embeddings for CBIR in thecontext of radiology image retrieval. However, a benchmark for the retrieval of3D volumetric medical images is still lacking, hindering the ability toobjectively evaluate and compare the efficiency of proposed CBIR approaches inmedical imaging. In this study, we extend previous work and establish abenchmark for region-based and multi-organ retrieval using the TotalSegmentatordataset (TS) with detailed multi-organ annotations. We benchmark embeddingsderived from pre-trained supervised models on medical images against embeddingsderived from pre-trained unsupervised models on non-medical images for 29coarse and 104 detailed anatomical structures in volume and region levels. Weadopt a late interaction re-ranking method inspired by text matching for imageretrieval, comparing it against the original method proposed for volume andregion retrieval achieving retrieval recall of 1.0 for diverse anatomicalregions with a wide size range. The findings and methodologies presented inthis paper provide essential insights and benchmarks for the development andevaluation of CBIR approaches in the context of medical imaging.</description><author>Farnaz Khun Jush, Steffen Vogler, Tuan Truong, Matthias Lenga</author><pubDate>Wed, 15 May 2024 14:34:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09334v1</guid></item><item><title>Application of Gated Recurrent Units for CT Trajectory Optimization</title><link>http://arxiv.org/abs/2405.09333v1</link><description>Recent advances in computed tomography (CT) imaging, especially withdual-robot systems, have introduced new challenges for scan trajectoryoptimization. This paper presents a novel approach using Gated Recurrent Units(GRUs) to optimize CT scan trajectories. Our approach exploits the flexibilityof robotic CT systems to select projections that enhance image quality byimproving resolution and contrast while reducing scan time. We focus oncone-beam CT and employ several projection-based metrics, including absorption,pixel intensities, contrast-to-noise ratio, and data completeness. The GRUnetwork aims to minimize data redundancy and maximize completeness with alimited number of projections. We validate our method using simulated data of atest specimen, focusing on a specific voxel of interest. The results show thatthe GRU-optimized scan trajectories can outperform traditional circular CTtrajectories in terms of image quality metrics. For the used specimen, SSIMimproves from 0.38 to 0.49 and CNR increases from 6.97 to 9.08. This findingsuggests that the application of GRU in CT scan trajectory optimization canlead to more efficient, cost-effective, and high-quality imaging solutions.</description><author>Yuedong Yuan, Linda-Sophie Schneider, Andreas Maier</author><pubDate>Wed, 15 May 2024 14:33:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09333v1</guid></item><item><title>Multi-Source Conformal Inference Under Distribution Shift</title><link>http://arxiv.org/abs/2405.09331v1</link><description>Recent years have experienced increasing utilization of complex machinelearning models across multiple sources of data to inform more generalizabledecision-making. However, distribution shifts across data sources and privacyconcerns related to sharing individual-level data, coupled with a lack ofuncertainty quantification from machine learning predictions, make itchallenging to achieve valid inferences in multi-source environments. In thispaper, we consider the problem of obtaining distribution-free predictionintervals for a target population, leveraging multiple potentially biased datasources. We derive the efficient influence functions for the quantiles ofunobserved outcomes in the target and source populations, and show that one canincorporate machine learning prediction algorithms in the estimation ofnuisance functions while still achieving parametric rates of convergence tonominal coverage probabilities. Moreover, when conditional outcome invarianceis violated, we propose a data-adaptive strategy to upweight informative datasources for efficiency gain and downweight non-informative data sources forbias reduction. We highlight the robustness and efficiency of our proposals fora variety of conformal scores and data-generating mechanisms via extensivesynthetic experiments. Hospital length of stay prediction intervals forpediatric patients undergoing a high-risk cardiac surgical procedure between2016-2022 in the U.S. illustrate the utility of our methodology.</description><author>Yi Liu, Alexander W. Levis, Sharon-Lise Normand, Larry Han</author><pubDate>Wed, 15 May 2024 14:33:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09331v1</guid></item><item><title>Learning Coarse-Grained Dynamics on Graph</title><link>http://arxiv.org/abs/2405.09324v1</link><description>We consider a Graph Neural Network (GNN) non-Markovian modeling framework toidentify coarse-grained dynamical systems on graphs. Our main idea is tosystematically determine the GNN architecture by inspecting how the leadingterm of the Mori-Zwanzig memory term depends on the coarse-grained interactioncoefficients that encode the graph topology. Based on this analysis, we foundthat the appropriate GNN architecture that will account for $K$-hop dynamicalinteractions has to employ a Message Passing (MP) mechanism with at least $2K$steps. We also deduce that the memory length required for an accurate closuremodel decreases as a function of the interaction strength under the assumptionthat the interaction strength exhibits a power law that decays as a function ofthe hop distance. Supporting numerical demonstrations on two examples, aheterogeneous Kuramoto oscillator model and a power system, suggest that theproposed GNN architecture can predict the coarse-grained dynamics under fixedand time-varying graph topologies.</description><author>Yin Yu, John Harlim, Daning Huang, Yan Li</author><pubDate>Wed, 15 May 2024 14:25:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09324v1</guid></item><item><title>AI Art is Theft: Labour, Extraction, and Exploitation, Or, On the Dangers of Stochastic Pollocks</title><link>http://arxiv.org/abs/2401.06178v2</link><description>Since the launch of applications such as DALL-E, Midjourney, and StableDiffusion, generative artificial intelligence has been controversial as a toolfor creating artwork. While some have presented longtermist worries about thesetechnologies as harbingers of fully automated futures to come, more pressing isthe impact of generative AI on creative labour in the present. Already,business leaders have begun replacing human artistic labour with AI-generatedimages. In response, the artistic community has launched a protest movement,which argues that AI image generation is a kind of theft. This paper analyzes,substantiates, and critiques these arguments, concluding that AI imagegenerators involve an unethical kind of labour theft. If correct, many other AIapplications also rely upon theft.</description><author>Trystan S. Goetze</author><pubDate>Wed, 15 May 2024 14:22:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06178v2</guid></item><item><title>ReconBoost: Boosting Can Achieve Modality Reconcilement</title><link>http://arxiv.org/abs/2405.09321v1</link><description>This paper explores a novel multi-modal alternating learning paradigmpursuing a reconciliation between the exploitation of uni-modal features andthe exploration of cross-modal interactions. This is motivated by the fact thatcurrent paradigms of multi-modal learning tend to explore multi-modal featuressimultaneously. The resulting gradient prohibits further exploitation of thefeatures in the weak modality, leading to modality competition, where thedominant modality overpowers the learning process. To address this issue, westudy the modality-alternating learning paradigm to achieve reconcilement.Specifically, we propose a new method called ReconBoost to update a fixedmodality each time. Herein, the learning objective is dynamically adjusted witha reconcilement regularization against competition with the historical models.By choosing a KL-based reconcilement, we show that the proposed methodresembles Friedman's Gradient-Boosting (GB) algorithm, where the updatedlearner can correct errors made by others and help enhance the overallperformance. The major difference with the classic GB is that we only preservethe newest model for each modality to avoid overfitting caused by ensemblingstrong learners. Furthermore, we propose a memory consolidation scheme and aglobal rectification scheme to make this strategy more effective. Experimentsover six multi-modal benchmarks speak to the efficacy of the method. We releasethe code at https://github.com/huacong/ReconBoost.</description><author>Cong Hua, Qianqian Xu, Shilong Bao, Zhiyong Yang, Qingming Huang</author><pubDate>Wed, 15 May 2024 14:22:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09321v1</guid></item><item><title>Transfer Learning in Pre-Trained Large Language Models for Malware Detection Based on System Calls</title><link>http://arxiv.org/abs/2405.09318v1</link><description>In the current cybersecurity landscape, protecting military devices such ascommunication and battlefield management systems against sophisticated cyberattacks is crucial. Malware exploits vulnerabilities through stealth methods,often evading traditional detection mechanisms such as software signatures. Theapplication of ML/DL in vulnerability detection has been extensively exploredin the literature. However, current ML/DL vulnerability detection methodsstruggle with understanding the context and intent behind complex attacks.Integrating large language models (LLMs) with system call analysis offers apromising approach to enhance malware detection. This work presents a novelframework leveraging LLMs to classify malware based on system call data. Theframework uses transfer learning to adapt pre-trained LLMs for malwaredetection. By retraining LLMs on a dataset of benign and malicious systemcalls, the models are refined to detect signs of malware activity. Experimentswith a dataset of over 1TB of system calls demonstrate that models with largercontext sizes, such as BigBird and Longformer, achieve superior accuracy andF1-Score of approximately 0.86. The results highlight the importance of contextsize in improving detection rates and underscore the trade-offs betweencomputational complexity and performance. This approach shows significantpotential for real-time detection in high-stakes environments, offering arobust solution to evolving cyber threats.</description><author>Pedro Miguel Sánchez Sánchez, Alberto Huertas Celdrán, Gérôme Bovet, Gregorio Martínez Pérez</author><pubDate>Wed, 15 May 2024 14:19:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09318v1</guid></item><item><title>Online Self-Supervised Deep Learning for Intrusion Detection Systems</title><link>http://arxiv.org/abs/2306.13030v2</link><description>This paper proposes a novel Self-Supervised Intrusion Detection (SSID)framework, which enables a fully online Deep Learning (DL) based IntrusionDetection System (IDS) that requires no human intervention or prior off-linelearning. The proposed framework analyzes and labels incoming traffic packetsbased only on the decisions of the IDS itself using an Auto-Associative DeepRandom Neural Network, and on an online estimate of its statistically measuredtrustworthiness. The SSID framework enables IDS to adapt rapidly totime-varying characteristics of the network traffic, and eliminates the needfor offline data collection. This approach avoids human errors in datalabeling, and human labor and computational costs of model training and datacollection. The approach is experimentally evaluated on public datasets andcompared with well-known {machine learning and deep learning} models, showingthat this SSID framework is very useful and advantageous as an accurate andonline learning DL-based IDS for IoT systems.</description><author>Mert Nakıp, Erol Gelenbe</author><pubDate>Wed, 15 May 2024 14:15:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13030v2</guid></item><item><title>Physics-informed generative neural networks for RF propagation prediction with application to indoor body perception</title><link>http://arxiv.org/abs/2405.02131v2</link><description>Electromagnetic (EM) body models designed to predict Radio-Frequency (RF)propagation are time-consuming methods which prevent their adoption in strictreal-time computational imaging problems, such as human body localization andsensing. Physics-informed Generative Neural Network (GNN) models have beenrecently proposed to reproduce EM effects, namely to simulate or reconstructmissing data or samples by incorporating relevant EM principles andconstraints. The paper discusses a Variational Auto-Encoder (VAE) model whichis trained to reproduce the effects of human motions on the EM field andincorporate EM body diffraction principles. Proposed physics-informedgenerative neural network models are verified against both classicaldiffraction-based EM tools and full-wave EM body simulations.</description><author>Federica Fieramosca, Vittorio Rampa, Michele D'Amico, Stefano Savazzi</author><pubDate>Wed, 15 May 2024 14:11:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02131v2</guid></item></channel></rss>