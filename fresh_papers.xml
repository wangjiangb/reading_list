<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 04 Sep 2024 13:00:17 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>PID Accelerated Temporal Difference Algorithms</title><link>http://arxiv.org/abs/2407.08803v2</link><description>Long-horizon tasks, which have a large discount factor, pose a challenge formost conventional reinforcement learning (RL) algorithms. Algorithms such asValue Iteration and Temporal Difference (TD) learning have a slow convergencerate and become inefficient in these tasks. When the transition distributionsare given, PID VI was recently introduced to accelerate the convergence ofValue Iteration using ideas from control theory. Inspired by this, we introducePID TD Learning and PID Q-Learning algorithms for the RL setting, in which onlysamples from the environment are available. We give a theoretical analysis ofthe convergence of PID TD Learning and its acceleration compared to theconventional TD Learning. We also introduce a method for adapting PID gains inthe presence of noise and empirically verify its effectiveness.</description><author>Mark Bedaywi, Amin Rakhsha, Amir-massoud Farahmand</author><pubDate>Tue, 03 Sep 2024 16:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.08803v2</guid></item><item><title>Improving Rare Word Translation With Dictionaries and Attention Masking</title><link>http://arxiv.org/abs/2408.09075v2</link><description>In machine translation, rare words continue to be a problem for the dominantencoder-decoder architecture, especially in low-resource and out-of-domaintranslation settings. Human translators solve this problem with monolingual orbilingual dictionaries. In this paper, we propose appending definitions from abilingual dictionary to source sentences and using attention masking to linktogether rare words with their definitions. We find that including definitionsfor rare words improves performance by up to 1.0 BLEU and 1.6 MacroF1.</description><author>Kenneth J. Sible, David Chiang</author><pubDate>Tue, 03 Sep 2024 16:47:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09075v2</guid></item><item><title>Low-Rank Quantization-Aware Training for LLMs</title><link>http://arxiv.org/abs/2406.06385v3</link><description>Large language models (LLMs) are omnipresent, however their practicaldeployment is challenging due to their ever increasing computational and memorydemands. Quantization is one of the most effective ways to make them morecompute and memory efficient. Quantization-aware training (QAT) methods,generally produce the best quantized performance, however it comes at the costof potentially long training time and excessive memory usage, making itimpractical when applying for LLMs. Inspired by parameter-efficient fine-tuning(PEFT) and low-rank adaptation (LoRA) literature, we propose LR-QAT -- alightweight and memory-efficient QAT algorithm for LLMs. LR-QAT employs severalcomponents to save memory without sacrificing predictive performance: (a)low-rank auxiliary weights that are aware of the quantization grid; (b) adowncasting operator using fixed-point or double-packed integers and (c)checkpointing. Unlike most related work, our method (i) is inference-efficient,leading to no additional overhead compared to traditional PTQ; (ii) can be seenas a general extended pretraining framework, meaning that the resulting modelcan still be utilized for any downstream task afterwards; (iii) can be appliedacross a wide range of quantization settings, such as different choicesquantization granularity, activation quantization, and seamlessly combined withmany PTQ techniques. We apply LR-QAT to LLaMA-1/2/3 and Mistral model familiesand validate its effectiveness on several downstream tasks. Our methodoutperforms common post-training quantization (PTQ) approaches and reaches thesame model performance as full-model QAT at the fraction of its memory usage.Specifically, we can train a 7B LLM on a single consumer grade GPU with 24GB ofmemory. Our source code is available athttps://github.com/qualcomm-ai-research/LR-QAT</description><author>Yelysei Bondarenko, Riccardo Del Chiaro, Markus Nagel</author><pubDate>Tue, 03 Sep 2024 16:36:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06385v3</guid></item><item><title>Chemical Reaction Neural Networks for Fitting Accelerating Rate Calorimetry Data</title><link>http://arxiv.org/abs/2408.11984v2</link><description>As the demand for lithium-ion batteries rapidly increases there is a need todesign these cells in a safe manner to mitigate thermal runaway. Thermalrunaway in batteries leads to an uncontrollable temperature rise andpotentially fires, which is a major safety concern. Typically, when modellingthe chemical kinetics of thermal runaway calorimetry data ( e.g. AcceleratingRate Calorimetry (ARC)) is needed to determine the temperature-drivendecomposition kinetics. Conventional methods of fitting Arrhenius OrdinaryDifferential Equation (ODE) thermal runaway models to Accelerated RateCalorimetry (ARC) data make several assumptions that reduce the fidelity andgeneralizability of the obtained model. In this paper, Chemical Reaction NeuralNetworks (CRNNs) are trained to fit the kinetic parameters of N-equationArrhenius ODEs to ARC data obtained from a Molicel 21700 P45B. The models arefound to be better approximations of the experimental data. The flexibility ofthe method is demonstrated by experimenting with two-equation and four-equationmodels. Thermal runaway simulations are conducted in 3D using the obtainedkinetic parameters, showing the applicability of the obtained thermal runawaymodels to large-scale simulations.</description><author>Saakaar Bhatnagar, Andrew Comerford, Zelu Xu, Davide Berti Polato, Araz Banaeizadeh, Alessandro Ferraris</author><pubDate>Tue, 03 Sep 2024 16:31:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.11984v2</guid></item><item><title>Open-vocabulary Temporal Action Localization using VLMs</title><link>http://arxiv.org/abs/2408.17422v2</link><description>Video action localization aims to find timings of a specific action from along video. Although existing learning-based approaches have been successful,those require annotating videos that come with a considerable labor cost. Thispaper proposes a learning-free, open-vocabulary approach based on emergingoff-the-shelf vision-language models (VLM). The challenge stems from the factthat VLMs are neither designed to process long videos nor tailored for findingactions. We overcome these problems by extending an iterative visual promptingtechnique. Specifically, we sample video frames into a concatenated image withframe index labels, making a VLM guess a frame that is considered to be closestto the start/end of the action. Iterating this process by narrowing a samplingtime window results in finding a specific frame of start and end of an action.We demonstrate that this sampling technique yields reasonable results,illustrating a practical extension of VLMs for understanding videos. A samplecode is available athttps://microsoft.github.io/VLM-Video-Action-Localization/.</description><author>Naoki Wake, Atsushi Kanehira, Kazuhiro Sasabuchi, Jun Takamatsu, Katsushi Ikeuchi</author><pubDate>Tue, 03 Sep 2024 16:00:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17422v2</guid></item><item><title>A Multiscale Gradient Fusion Method for Edge Detection in Color Images Utilizing the CBM3D Filter</title><link>http://arxiv.org/abs/2408.14013v2</link><description>In this paper, a color edge detection strategy based on collaborativefiltering combined with multiscale gradient fusion is proposed. Theblock-matching and 3D (BM3D) filter are used to enhance the sparserepresentation in the transform domain and achieve the effect of denoising,whereas the multiscale gradient fusion makes up for the defect of loss ofdetails in single-scale edge detection and improves the edge detectionresolution and quality. First, the RGB images in the dataset are converted toXYZ color space images through mathematical operations. Second, the coloredblock-matching and 3D (CBM3D) filter are used on the sparse images and toremove noise interference. Then, the vector gradients of the color image andthe anisotropic Gaussian directional derivative of the two scale parameters arecalculated and averaged pixel-by-pixel to obtain a new edge strength map.Finally, the edge features are enhanced by image normalization and non-maximumsuppression technology, and on that basis, the edge contour is obtained bydouble threshold selection and a new morphological refinement method. Throughan experimental analysis of the edge detection dataset, the method proposed hasgood noise robustness and high edge quality, which is better than the ColorSobel, Color Canny, SE and Color AGDD as shown by the PR curve, AUC, PSNR, MSE,and FOM indicators.</description><author>Zhuoyue Wang, Yiyi Tao, Danqing Ma, Jiajing Chen</author><pubDate>Tue, 03 Sep 2024 15:34:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14013v2</guid></item><item><title>Force-Guided Bridge Matching for Full-Atom Time-Coarsened Dynamics of Peptides</title><link>http://arxiv.org/abs/2408.15126v3</link><description>Molecular Dynamics (MD) simulations are irreplaceable and ubiquitous infields of materials science, chemistry, pharmacology just to name a few.Conventional MD simulations are plagued by numerical stability as well as longequilibration time issues, which limits broader applications of MD simulations.Recently, a surge of deep learning approaches have been devised fortime-coarsened dynamics, which learns the state transition mechanism over muchlarger time scales to overcome these limitations. However, only a few methodstarget the underlying Boltzmann distribution by resampling techniques, whereproposals are rarely accepted as new states with low efficiency. In this work,we propose a force-guided bridge matching model, FBM, a novel framework thatfirst incorporates physical priors into bridge matching for full-atomtime-coarsened dynamics. With the guidance of our well-designed intermediateforce field, FBM is feasible to target the Boltzmann-like distribution bydirect inference without extra steps. Experiments on small peptides verify oursuperiority in terms of comprehensive metrics and demonstrate transferabilityto unseen peptide systems.</description><author>Ziyang Yu, Wenbing Huang, Yang Liu</author><pubDate>Tue, 03 Sep 2024 15:30:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15126v3</guid></item><item><title>Verifiable cloud-based variational quantum algorithms</title><link>http://arxiv.org/abs/2408.13713v3</link><description>Variational quantum algorithms (VQAs) have shown potential for quantumadvantage with noisy intermediate-scale quantum (NISQ) devices for quantummachine learning (QML). However, given the high cost and limited availabilityof quantum resources, delegating VQAs via cloud networks is a more practicalsolution for clients with limited quantum capabilities. Recently, Shingu etal.[Physical Review A, 105, 022603 (2022)] proposed a variational secure cloudquantum computing protocol, utilizing ancilla-driven quantum computation (ADQC)for cloud-based VQAs with minimal quantum resource consumption. However, theirprotocol lacks verifiability, which exposes it to potential malicious behaviorsby the server. Additionally, channel loss requires frequent re-delegation asthe size of the delegated variational circuit grows, complicating verificationdue to increased circuit complexity. This paper introduces a new protocol toaddress these challenges and enhance both verifiability and tolerance tochannel loss in cloud-based VQAs.</description><author>Junhong Yang, Banghai Wang, Junyu Quan, Qin Li</author><pubDate>Tue, 03 Sep 2024 15:28:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13713v3</guid></item><item><title>Bayesian Learning in a Nonlinear Multiscale State-Space Model</title><link>http://arxiv.org/abs/2408.06425v6</link><description>The ubiquity of multiscale interactions in complex systems iswell-recognized, with development and heredity serving as a prime example ofhow processes at different temporal scales influence one another. This workintroduces a novel multiscale state-space model to explore the dynamicinterplay between systems interacting across different time scales, withfeedback between each scale. We propose a Bayesian learning framework toestimate unknown states by learning the unknown process noise covarianceswithin this multiscale model. We develop a Particle Gibbs with AncestorSampling (PGAS) algorithm for inference and demonstrate through simulations theefficacy of our approach.</description><author>Nayely Vélez-Cruz, Manfred D. Laubichler</author><pubDate>Tue, 03 Sep 2024 15:07:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06425v6</guid></item><item><title>Distributionally robust risk evaluation with an isotonic constraint</title><link>http://arxiv.org/abs/2407.06867v2</link><description>Statistical learning under distribution shift is challenging when neitherprior knowledge nor fully accessible data from the target distribution isavailable. Distributionally robust learning (DRL) aims to control theworst-case statistical performance within an uncertainty set of candidatedistributions, but how to properly specify the set remains challenging. Toenable distributional robustness without being overly conservative, in thispaper, we propose a shape-constrained approach to DRL, which incorporates priorinformation about the way in which the unknown target distribution differs fromits estimate. More specifically, we assume the unknown density ratio betweenthe target distribution and its estimate is isotonic with respect to somepartial order. At the population level, we provide a solution to theshape-constrained optimization problem that does not involve the isotonicconstraint. At the sample level, we provide consistency results for anempirical estimator of the target in a range of different settings. Empiricalstudies on both synthetic and real data examples demonstrate the improvedaccuracy of the proposed shape-constrained approach.</description><author>Yu Gui, Rina Foygel Barber, Cong Ma</author><pubDate>Tue, 03 Sep 2024 14:57:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06867v2</guid></item><item><title>IBO: Inpainting-Based Occlusion to Enhance Explainable Artificial Intelligence Evaluation in Histopathology</title><link>http://arxiv.org/abs/2408.16395v2</link><description>Histopathological image analysis is crucial for accurate cancer diagnosis andtreatment planning. While deep learning models, especially convolutional neuralnetworks, have advanced this field, their "black-box" nature raises concernsabout interpretability and trustworthiness. Explainable Artificial Intelligence(XAI) techniques aim to address these concerns, but evaluating theireffectiveness remains challenging. A significant issue with currentocclusion-based XAI methods is that they often generate Out-of-Distribution(OoD) samples, leading to inaccurate evaluations. In this paper, we introduceInpainting-Based Occlusion (IBO), a novel occlusion strategy that utilizes aDenoising Diffusion Probabilistic Model to inpaint occluded regions inhistopathological images. By replacing cancerous areas with realistic,non-cancerous tissue, IBO minimizes OoD artifacts and preserves data integrity.We evaluate our method on the CAMELYON16 dataset through two phases: first, byassessing perceptual similarity using the Learned Perceptual Image PatchSimilarity (LPIPS) metric, and second, by quantifying the impact on modelpredictions through Area Under the Curve (AUC) analysis. Our resultsdemonstrate that IBO significantly improves perceptual fidelity, achievingnearly twice the improvement in LPIPS scores compared to the best existingocclusion strategy. Additionally, IBO increased the precision of XAIperformance prediction from 42% to 71% compared to traditional methods. Theseresults demonstrate IBO's potential to provide more reliable evaluations of XAItechniques, benefiting histopathology and other applications. The source codefor this study is available at https://github.com/a-fsh-r/IBO.</description><author>Pardis Afshar, Sajjad Hashembeiki, Pouya Khani, Emad Fatemizadeh, Mohammad Hossein Rohban</author><pubDate>Tue, 03 Sep 2024 14:57:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.16395v2</guid></item><item><title>Foundation Models for Music: A Survey</title><link>http://arxiv.org/abs/2408.14340v3</link><description>In recent years, foundation models (FMs) such as large language models (LLMs)and latent diffusion models (LDMs) have profoundly impacted diverse sectors,including music. This comprehensive review examines state-of-the-art (SOTA)pre-trained models and foundation models in music, spanning from representationlearning, generative learning and multimodal learning. We first contextualisethe significance of music in various industries and trace the evolution of AIin music. By delineating the modalities targeted by foundation models, wediscover many of the music representations are underexplored in FM development.Then, emphasis is placed on the lack of versatility of previous methods ondiverse music applications, along with the potential of FMs in musicunderstanding, generation and medical application. By comprehensively exploringthe details of the model pre-training paradigm, architectural choices,tokenisation, finetuning methodologies and controllability, we emphasise theimportant topics that should have been well explored, like instruction tuningand in-context learning, scaling law and emergent ability, as well aslong-sequence modelling etc. A dedicated section presents insights into musicagents, accompanied by a thorough analysis of datasets and evaluationsessential for pre-training and downstream tasks. Finally, by underscoring thevital importance of ethical considerations, we advocate that following researchon FM for music should focus more on such issues as interpretability,transparency, human responsibility, and copyright issues. The paper offersinsights into future challenges and trends on FMs for music, aiming to shapethe trajectory of human-AI collaboration in the music realm.</description><author>Yinghao Ma, Anders Øland, Anton Ragni, Bleiz MacSen Del Sette, Charalampos Saitis, Chris Donahue, Chenghua Lin, Christos Plachouras, Emmanouil Benetos, Elona Shatri, Fabio Morreale, Ge Zhang, György Fazekas, Gus Xia, Huan Zhang, Ilaria Manco, Jiawen Huang, Julien Guinot, Liwei Lin, Luca Marinelli, Max W. Y. Lam, Megha Sharma, Qiuqiang Kong, Roger B. Dannenberg, Ruibin Yuan, Shangda Wu, Shih-Lun Wu, Shuqi Dai, Shun Lei, Shiyin Kang, Simon Dixon, Wenhu Chen, Wenhao Huang, Xingjian Du, Xingwei Qu, Xu Tan, Yizhi Li, Zeyue Tian, Zhiyong Wu, Zhizheng Wu, Ziyang Ma, Ziyu Wang</author><pubDate>Tue, 03 Sep 2024 14:53:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14340v3</guid></item><item><title>Different Victims, Same Layout: Email Visual Similarity Detection for Enhanced Email Protection</title><link>http://arxiv.org/abs/2408.16945v2</link><description>In the pursuit of an effective spam detection system, the focus has oftenbeen on identifying known spam patterns either through rule-based detectionsystems or machine learning (ML) solutions that rely on keywords. However, bothsystems are susceptible to evasion techniques and zero-day attacks that can beachieved at low cost. Therefore, an email that bypassed the defense system oncecan do it again in the following days, even though rules are updated or the MLmodels are retrained. The recurrence of failures to detect emails that exhibitlayout similarities to previously undetected spam is concerning for customersand can erode their trust in a company. Our observations show that threatactors reuse email kits extensively and can bypass detection with littleeffort, for example, by making changes to the content of emails. In this work,we propose an email visual similarity detection approach, named Pisco, toimprove the detection capabilities of an email threat defense system. We applyour proof of concept to some real-world samples received from differentsources. Our results show that email kits are being reused extensively andvisually similar emails are sent to our customers at various time intervals.Therefore, this method could be very helpful in situations where detectionfeatures that rely on textual features and keywords are bypassed, an occurrenceour observations show happens frequently.</description><author>Sachin Shukla, Omid Mirzaei</author><pubDate>Tue, 03 Sep 2024 14:20:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.16945v2</guid></item><item><title>On the Convergence of Gradient Descent for Large Learning Rates</title><link>http://arxiv.org/abs/2402.13108v2</link><description>A vast literature on convergence guarantees for gradient descent and derivedmethods exists at the moment. However, a simple practical situation remainsunexplored: when a fixed step size is used, can we expect gradient descent toconverge starting from any initialization? We provide fundamental impossibilityresults showing that convergence becomes impossible no matter theinitialization if the step size gets too big. Looking at the asymptotic valueof the gradient norm along the optimization trajectory, we see that there is aphase transition as the step size crosses a critical value. This has beenobserved by practitioners, yet the true mechanisms through which this happensremain unclear beyond heuristics. Using results from dynamical systems theory,we provide a proof of this in the case of linear neural networks with a squaredloss. We also prove the impossibility of convergence for more general losseswithout requiring strong assumptions such as Lipschitz continuity for thegradient. We validate our findings through experiments with non-linearnetworks.</description><author>Alexandru Crăciun, Debarghya Ghoshdastidar</author><pubDate>Tue, 03 Sep 2024 14:09:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13108v2</guid></item><item><title>InkubaLM: A small language model for low-resource African languages</title><link>http://arxiv.org/abs/2408.17024v2</link><description>High-resource language models often fall short in the African context, wherethere is a critical need for models that are efficient, accessible, and locallyrelevant, even amidst significant computing and data constraints. This paperintroduces InkubaLM, a small language model with 0.4 billion parameters, whichachieves performance comparable to models with significantly larger parametercounts and more extensive training data on tasks such as machine translation,question-answering, AfriMMLU, and the AfriXnli task. Notably, InkubaLMoutperforms many larger models in sentiment analysis and demonstratesremarkable consistency across multiple languages. This work represents apivotal advancement in challenging the conventional paradigm that effectivelanguage models must rely on substantial resources. Our model and datasets arepublicly available at https://huggingface.co/lelapa to encourage research anddevelopment on low-resource languages.</description><author>Atnafu Lambebo Tonja, Bonaventure F. P. Dossou, Jessica Ojo, Jenalea Rajab, Fadel Thior, Eric Peter Wairagala, Anuoluwapo Aremu, Pelonomi Moiloa, Jade Abbott, Vukosi Marivate, Benjamin Rosman</author><pubDate>Tue, 03 Sep 2024 13:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17024v2</guid></item><item><title>$OC^4-ReID$: Occluded Cloth-Changing Person Re-Identification</title><link>http://arxiv.org/abs/2403.08557v3</link><description>The study of Cloth-Changing Person Re-identification (CC-ReID) focuses onretrieving specific pedestrians when their clothing has changed, typicallyunder the assumption that the entire pedestrian images are visible. Pedestrianimages in real-world scenarios, however, are often partially obscured byobstacles, presenting a significant challenge to existing CC-ReID systems. Inthis paper, we introduce a more challenging task termed Occluded Cloth-ChangingPerson Re-Identification ($OC^4-ReID$), which simultaneously addresses twochallenges of clothing changes and occlusion. Concretely, we construct two newdatasets, Occ-LTCC and Occ-PRCC, based on original CC-ReID datasets to includerandom occlusions of key pedestrians components (e.g., head, torso). Moreover,a novel benchmark is proposed for $OC^4-ReID$ incorporating a Train-Test MicroGranularity Screening ($T^2MGS$) module to mitigate the influence of occlusionand proposing a Part-Robust Triplet (PRT) loss for partial features learning.Comprehensive experiments on the proposed datasets, as well as on two CC-ReIDbenchmark datasets demonstrate the superior performance of proposed methodagainst other state-of-the-art methods. The codes and datasets are availableat: https://github.com/1024AILab/OC4-ReID.</description><author>Zhihao Chen, Yiyuan Ge, Ziyang Wang, Jiaju Kang, Mingya Zhang</author><pubDate>Tue, 03 Sep 2024 13:40:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08557v3</guid></item><item><title>Restorer: Removing Multi-Degradation with All-Axis Attention and Prompt Guidance</title><link>http://arxiv.org/abs/2406.12587v2</link><description>There are many excellent solutions in image restoration.However, most methodsrequire on training separate models to restore images with different types ofdegradation.Although existing all-in-one models effectively address multipletypes of degradation simultaneously, their performance in real-world scenariosis still constrained by the task confusion problem.In this work, we attempt toaddress this issue by introducing \textbf{Restorer}, a novel Transformer-basedall-in-one image restoration model.To effectively address the complexdegradation present in real-world images, we propose All-Axis Attention (AAA),a mechanism that simultaneously models long-range dependencies across bothspatial and channel dimensions, capturing potential correlations along allaxes.Additionally, we introduce textual prompts in Restorer to incorporateexplicit task priors, enabling the removal of specific degradation types basedon user instructions. By iterating over these prompts, Restorer can handlecomposite degradation in real-world scenarios without requiring additionaltraining.Based on these designs, Restorer with one set of parametersdemonstrates state-of-the-art performance in multiple image restoration taskscompared to existing all-in-one and even single-task models.Additionally,Restorer is efficient during inference, suggesting the potential in real-worldapplications.</description><author>Jiawei Mao, Juncheng Wu, Yuyin Zhou, Xuesong Yin, Yuanqi Chang</author><pubDate>Tue, 03 Sep 2024 13:36:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12587v2</guid></item><item><title>On the Federated Learning Framework for Cooperative Perception</title><link>http://arxiv.org/abs/2404.17147v4</link><description>Cooperative perception is essential to enhance the efficiency and safety offuture transportation systems, requiring extensive data sharing among vehicleson the road, which raises significant privacy concerns. Federated learningoffers a promising solution by enabling data privacy-preserving collaborativeenhancements in perception, decision-making, and planning among connected andautonomous vehicles (CAVs). However, federated learning is impeded bysignificant challenges arising from data heterogeneity across diverse clients,potentially diminishing model accuracy and prolonging convergence periods. Thisstudy introduces a specialized federated learning framework for CP, termed thefederated dynamic weighted aggregation (FedDWA) algorithm, facilitated bydynamic adjusting loss (DALoss) function. This framework employs dynamic clientweighting to direct model convergence and integrates a novel loss function thatutilizes Kullback-Leibler divergence (KLD) to counteract the detrimentaleffects of non-independently and identically distributed (Non-IID) andunbalanced data. Utilizing the BEV transformer as the primary model, ourrigorous testing on the OpenV2V dataset, augmented with FedBEVT data,demonstrates significant improvements in the average intersection over union(IoU). These results highlight the substantial potential of our federatedlearning framework to address data heterogeneity challenges in CP, therebyenhancing the accuracy of environmental perception models and facilitating morerobust and efficient collaborative learning solutions in the transportationsector.</description><author>Zhenrong Zhang, Jianan Liu, Xi Zhou, Tao Huang, Qing-Long Han, Jingxin Liu, Hongbin Liu</author><pubDate>Tue, 03 Sep 2024 12:55:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17147v4</guid></item><item><title>An embedding-based distance for temporal graphs</title><link>http://arxiv.org/abs/2401.12843v2</link><description>Temporal graphs are commonly used to represent time-resolved relationsbetween entities in many natural and artificial systems. Many techniques weredevised to investigate the evolution of temporal graphs by comparing theirstate at different time points. However, quantifying the similarity betweentemporal graphs as a whole is an open problem. Here, we use embeddings based ontime-respecting random walks to introduce a new notion of distance betweentemporal graphs. This distance is well-defined for pairs of temporal graphswith different numbers of nodes and different time spans. We study the case ofa matched pair of graphs, when a known relation exists between their nodes, andthe case of unmatched graphs, when such a relation is unavailable and thegraphs may be of different sizes. We use empirical and synthetic temporalnetwork data to show that the distance we introduce discriminates graphs withdifferent topological and temporal properties. We provide an efficientimplementation of the distance computation suitable for large-scale temporalgraphs.</description><author>Lorenzo Dall'Amico, Alain Barrat, Ciro Cattuto</author><pubDate>Tue, 03 Sep 2024 12:49:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12843v2</guid></item><item><title>Heterogeneity-Informed Meta-Parameter Learning for Spatiotemporal Time Series Forecasting</title><link>http://arxiv.org/abs/2405.10800v2</link><description>Spatiotemporal time series forecasting plays a key role in a wide range ofreal-world applications. While significant progress has been made in this area,fully capturing and leveraging spatiotemporal heterogeneity remains afundamental challenge. Therefore, we propose a novel Heterogeneity-InformedMeta-Parameter Learning scheme. Specifically, our approach implicitly capturesspatiotemporal heterogeneity through learning spatial and temporal embeddings,which can be viewed as a clustering process. Then, a novel spatiotemporalmeta-parameter learning paradigm is proposed to learn spatiotemporal-specificparameters from meta-parameter pools, which is informed by the capturedheterogeneity. Based on these ideas, we develop a Heterogeneity-InformedSpatiotemporal Meta-Network (HimNet) for spatiotemporal time seriesforecasting. Extensive experiments on five widely-used benchmarks demonstrateour method achieves state-of-the-art performance while exhibiting superiorinterpretability. Our code is available athttps://github.com/XDZhelheim/HimNet.</description><author>Zheng Dong, Renhe Jiang, Haotian Gao, Hangchen Liu, Jinliang Deng, Qingsong Wen, Xuan Song</author><pubDate>Tue, 03 Sep 2024 12:43:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.10800v2</guid></item><item><title>FairX: A comprehensive benchmarking tool for model analysis using fairness, utility, and explainability</title><link>http://arxiv.org/abs/2406.14281v4</link><description>We present FairX, an open-source Python-based benchmarking tool designed forthe comprehensive analysis of models under the umbrella of fairness, utility,and eXplainability (XAI). FairX enables users to train benchmarkingbias-mitigation models and evaluate their fairness using a wide array offairness metrics, data utility metrics, and generate explanations for modelpredictions, all within a unified framework. Existing benchmarking tools do nothave the way to evaluate synthetic data generated from fair generative models,also they do not have the support for training fair generative models either.In FairX, we add fair generative models in the collection of our fair-modellibrary (pre-processing, in-processing, post-processing) and evaluation metricsfor evaluating the quality of synthetic fair data. This version of FairXsupports both tabular and image datasets. It also allows users to provide theirown custom datasets. The open-source FairX benchmarking package is publiclyavailable at \url{https://github.com/fahim-sikder/FairX}.</description><author>Md Fahim Sikder, Resmi Ramachandranpillai, Daniel de Leng, Fredrik Heintz</author><pubDate>Tue, 03 Sep 2024 12:38:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14281v4</guid></item><item><title>Behavioral Learning of Dish Rinsing and Scrubbing based on Interruptive Direct Teaching Considering Assistance Rate</title><link>http://arxiv.org/abs/2408.09360v2</link><description>Robots are expected to manipulate objects in a safe and dexterous way. Forexample, washing dishes is a dexterous operation that involves scrubbing thedishes with a sponge and rinsing them with water. It is necessary to learn itsafely without splashing water and without dropping the dishes. In this study,we propose a safe and dexterous manipulation system. The robot learns adynamics model of the object by estimating the state of the object and therobot itself, the control input, and the amount of human assistance required(assistance rate) after the human corrects the initial trajectory of therobot's hands by interruptive direct teaching. By backpropagating the errorbetween the estimated and the reference value using the acquired dynamicsmodel, the robot can generate a control input that approaches the referencevalue, for example, so that human assistance is not required and the dish doesnot move excessively. This allows for adaptive rinsing and scrubbing of disheswith unknown shapes and properties. As a result, it is possible to generatesafe actions that require less human assistance.</description><author>Shumpei Wakabayashi, Kento Kawaharazuka, Kei Okada, Masayuki Inaba</author><pubDate>Tue, 03 Sep 2024 12:31:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09360v2</guid></item><item><title>3DGS.zip: A survey on 3D Gaussian Splatting Compression Methods</title><link>http://arxiv.org/abs/2407.09510v3</link><description>We present a work-in-progress survey on 3D Gaussian Splatting compressionmethods, focusing on their statistical performance across various benchmarks.This survey aims to facilitate comparability by summarizing key statistics ofdifferent compression approaches in a tabulated format. The datasets evaluatedinclude TanksAndTemples, MipNeRF360, DeepBlending, and SyntheticNeRF. For eachmethod, we report the Peak Signal-to-Noise Ratio (PSNR), Structural SimilarityIndex (SSIM), Learned Perceptual Image Patch Similarity (LPIPS), and theresultant size in megabytes (MB), as provided by the respective authors. Thisis an ongoing, open project, and we invite contributions from the researchcommunity as GitHub issues or pull requests. Please visithttp://w-m.github.io/3dgs-compression-survey/ for more information and asortable version of the table.</description><author>Milena T. Bagdasarian, Paul Knoll, Florian Barthel, Anna Hilsmann, Peter Eisert, Wieland Morgenstern</author><pubDate>Tue, 03 Sep 2024 11:54:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09510v3</guid></item><item><title>Towards Explainable Traffic Flow Prediction with Large Language Models</title><link>http://arxiv.org/abs/2404.02937v5</link><description>Traffic forecasting is crucial for intelligent transportation systems. It hasexperienced significant advancements thanks to the power of deep learning incapturing latent patterns of traffic data. However, recent deep-learningarchitectures require intricate model designs and lack an intuitiveunderstanding of the mapping from input data to predicted results. Achievingboth accuracy and explainability in traffic prediction models remains achallenge due to the complexity of traffic data and the inherent opacity ofdeep learning models. To tackle these challenges, we propose a Traffic flowPrediction model based on Large Language Models (LLMs) to generate explainabletraffic predictions, named xTP-LLM. By transferring multi-modal traffic datainto natural language descriptions, xTP-LLM captures complex time-seriespatterns and external factors from comprehensive traffic data. The LLMframework is fine-tuned using language-based instructions to align withspatial-temporal traffic flow data. Empirically, xTP-LLM shows competitiveaccuracy compared with deep learning baselines, while providing an intuitiveand reliable explanation for predictions. This paper contributes to advancingexplainable traffic prediction models and lays a foundation for futureexploration of LLM applications in transportation. To the best of ourknowledge, this is the first study to use LLM for explainable prediction oftraffic flows.</description><author>Xusen Guo, Qiming Zhang, Junyue Jiang, Mingxing Peng, Meixin Zhu, Hao, Yang</author><pubDate>Tue, 03 Sep 2024 11:32:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02937v5</guid></item><item><title>rerankers: A Lightweight Python Library to Unify Ranking Methods</title><link>http://arxiv.org/abs/2408.17344v2</link><description>This paper presents rerankers, a Python library which provides an easy-to-useinterface to the most commonly used re-ranking approaches. Re-ranking is anintegral component of many retrieval pipelines; however, there exist numerousapproaches to it, relying on different implementation methods. rerankersunifies these methods into a single user-friendly interface, allowingpractitioners and researchers alike to explore different methods while onlychanging a single line of Python code. Moreover ,rerankers ensures that itsimplementations are done with the fewest dependencies possible, and re-uses theoriginal implementation whenever possible, guaranteeing that our simplifiedinterface results in no performance degradation compared to more complex ones.The full source code and list of supported models are updated regularly andavailable at https://github.com/answerdotai/rerankers.</description><author>Benjamin Clavié</author><pubDate>Tue, 03 Sep 2024 10:50:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17344v2</guid></item><item><title>SUMix: Mixup with Semantic and Uncertain Information</title><link>http://arxiv.org/abs/2407.07805v3</link><description>Mixup data augmentation approaches have been applied for various tasks ofdeep learning to improve the generalization ability of deep neural networks.Some existing approaches CutMix, SaliencyMix, etc. randomly replace a patch inone image with patches from another to generate the mixed image. Similarly, thecorresponding labels are linearly combined by a fixed ratio $\lambda$ by l. Theobjects in two images may be overlapped during the mixing process, so somesemantic information is corrupted in the mixed samples. In this case, the mixedimage does not match the mixed label information. Besides, such a label maymislead the deep learning model training, which results in poor performance. Tosolve this problem, we proposed a novel approach named SUMix to learn themixing ratio as well as the uncertainty for the mixed samples during thetraining process. First, we design a learnable similarity function to computean accurate mix ratio. Second, an approach is investigated as a regularizedterm to model the uncertainty of the mixed samples. We conduct experiments onfive image benchmarks, and extensive experimental results imply that our methodis capable of improving the performance of classifiers with differentcutting-based mixup approaches. The source code is available athttps://github.com/JinXins/SUMix.</description><author>Huafeng Qin, Xin Jin, Hongyu Zhu, Hongchao Liao, Mounîm A. El-Yacoubi, Xinbo Gao</author><pubDate>Tue, 03 Sep 2024 10:46:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07805v3</guid></item><item><title>OceanGPT: A Large Language Model for Ocean Science Tasks</title><link>http://arxiv.org/abs/2310.02031v8</link><description>Ocean science, which delves into the oceans that are reservoirs of life andbiodiversity, is of great significance given that oceans cover over 70% of ourplanet's surface. Recently, advances in Large Language Models (LLMs) havetransformed the paradigm in science. Despite the success in other domains,current LLMs often fall short in catering to the needs of domain experts likeoceanographers, and the potential of LLMs for ocean science is under-explored.The intrinsic reasons are the immense and intricate nature of ocean data aswell as the necessity for higher granularity and richness in knowledge. Toalleviate these issues, we introduce OceanGPT, the first-ever large languagemodel in the ocean domain, which is expert in various ocean science tasks. Wealso propose OceanGPT, a novel framework to automatically obtain a large volumeof ocean domain instruction data, which generates instructions based onmulti-agent collaboration. Additionally, we construct the first oceanographybenchmark, OceanBench, to evaluate the capabilities of LLMs in the oceandomain. Though comprehensive experiments, OceanGPT not only shows a higherlevel of knowledge expertise for oceans science tasks but also gainspreliminary embodied intelligence capabilities in ocean technology.</description><author>Zhen Bi, Ningyu Zhang, Yida Xue, Yixin Ou, Daxiong Ji, Guozhou Zheng, Huajun Chen</author><pubDate>Tue, 03 Sep 2024 10:19:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02031v8</guid></item><item><title>SPIdepth: Strengthened Pose Information for Self-supervised Monocular Depth Estimation</title><link>http://arxiv.org/abs/2404.12501v3</link><description>Self-supervised monocular depth estimation has garnered considerableattention for its applications in autonomous driving and robotics. While recentmethods have made strides in leveraging techniques like the Self Query Layer(SQL) to infer depth from motion, they often overlook the potential ofstrengthening pose information. In this paper, we introduce SPIdepth, a novelapproach that prioritizes enhancing the pose network for improved depthestimation. Building upon the foundation laid by SQL, SPIdepth emphasizes theimportance of pose information in capturing fine-grained scene structures. Byenhancing the pose network's capabilities, SPIdepth achieves remarkableadvancements in scene understanding and depth estimation. Experimental resultson benchmark datasets such as KITTI, Cityscapes, and Make3D showcase SPIdepth'sstate-of-the-art performance, surpassing previous methods by significantmargins. Specifically, SPIdepth tops the self-supervised KITTI benchmark.Additionally, SPIdepth achieves the lowest AbsRel (0.029), SqRel (0.069), andRMSE (1.394) on KITTI, establishing new state-of-the-art results. OnCityscapes, SPIdepth shows improvements over SQLdepth of 21.7% in AbsRel, 36.8%in SqRel, and 16.5% in RMSE, even without using motion masks. On Make3D,SPIdepth in zero-shot outperforms all other models. Remarkably, SPIdepthachieves these results using only a single image for inference, surpassing evenmethods that utilize video sequences for inference, thus demonstrating itsefficacy and efficiency in real-world applications. Our approach represents asignificant leap forward in self-supervised monocular depth estimation,underscoring the importance of strengthening pose information for advancingscene understanding in real-world applications. The code and pre-trained modelsare publicly available at https://github.com/Lavreniuk/SPIdepth.</description><author>Mykola Lavreniuk</author><pubDate>Tue, 03 Sep 2024 10:12:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12501v3</guid></item><item><title>Realigned Softmax Warping for Deep Metric Learning</title><link>http://arxiv.org/abs/2408.15656v2</link><description>Deep Metric Learning (DML) loss functions traditionally aim to control theforces of separability and compactness within an embedding space so that thesame class data points are pulled together and different class ones are pushedapart. Within the context of DML, a softmax operation will typically normalizedistances into a probability for optimization, thus coupling all the push/pullforces together. This paper proposes a potential new class of loss functionsthat operate within a euclidean domain and aim to take full advantage of thecoupled forces governing embedding space formation under a softmax. Theseforces of compactness and separability can be boosted or mitigated withincontrolled locations at will by using a warping function. In this work, weprovide a simple example of a warping function and use it to achievecompetitive, state-of-the-art results on various metric learning benchmarks.</description><author>Michael G. DeMoor, John J. Prevost</author><pubDate>Tue, 03 Sep 2024 09:45:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15656v2</guid></item><item><title>Progressive Domain Adaptation for Thermal Infrared Object Tracking</title><link>http://arxiv.org/abs/2407.19430v2</link><description>Due to the lack of large-scale labeled Thermal InfraRed (TIR) trainingdatasets, most existing TIR trackers are trained directly on RGB datasets.However, tracking methods trained on RGB datasets suffer a significant drop-offin TIR data due to the domain shift issue. To this end, in this work, wepropose a Progressive Domain Adaptation framework for TIR Tracking (PDAT),which transfers useful knowledge learned from RGB tracking to TIR tracking. Theframework makes full use of large-scale labeled RGB datasets without requiringtime-consuming and labor-intensive labeling of large-scale TIR data.Specifically, we first propose an adversarial-based global domain adaptationmodule to reduce domain gap on the feature level coarsely. Second, we design aclustering-based subdomain adaptation method to further align the featuredistributions of the RGB and TIR datasets finely. These two domain adaptationmodules gradually eliminate the discrepancy between the two domains, and thuslearn domain-invariant fine-grained features through progressive training.Additionally, we collect a largescale TIR dataset with over 1.48 millionunlabeled TIR images for training the proposed domain adaptation framework.Experimental results on five TIR tracking benchmarks show that the proposedmethod gains a nearly 6% success rate, demonstrating its effectiveness.</description><author>Qiao Li, Kanlun Tan, Qiao Liu, Di Yuan, Xin Li, Yunpeng Liu</author><pubDate>Tue, 03 Sep 2024 09:42:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.19430v2</guid></item><item><title>Sentinel: An Aggregation Function to Secure Decentralized Federated Learning</title><link>http://arxiv.org/abs/2310.08097v3</link><description>Decentralized Federated Learning (DFL) emerges as an innovative paradigm totrain collaborative models, addressing the single point of failure limitation.However, the security and trustworthiness of FL and DFL are compromised bypoisoning attacks, negatively impacting its performance. Existing defensemechanisms have been designed for centralized FL and they do not adequatelyexploit the particularities of DFL. Thus, this work introduces Sentinel, adefense strategy to counteract poisoning attacks in DFL. Sentinel leverages theaccessibility of local data and defines a three-step aggregation protocolconsisting of similarity filtering, bootstrap validation, and normalization tosafeguard against malicious model updates. Sentinel has been evaluated withdiverse datasets and data distributions. Besides, various poisoning attacktypes and threat levels have been verified. The results improve thestate-of-the-art performance against both untargeted and targeted poisoningattacks when data follows an IID (Independent and Identically Distributed)configuration. Besides, under non-IID configuration, it is analyzed howperformance degrades both for Sentinel and other state-of-the-art robustaggregation methods.</description><author>Chao Feng, Alberto Huertas Celdran, Janosch Baltensperger, Enrique Tomas Martinez Beltran, Gerome Bovet, Burkhard Stiller</author><pubDate>Tue, 03 Sep 2024 09:28:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08097v3</guid></item><item><title>Statistical Context Detection for Deep Lifelong Reinforcement Learning</title><link>http://arxiv.org/abs/2405.19047v2</link><description>Context detection involves labeling segments of an online stream of data asbelonging to different tasks. Task labels are used in lifelong learningalgorithms to perform consolidation or other procedures that preventcatastrophic forgetting. Inferring task labels from online experiences remainsa challenging problem. Most approaches assume finite and low-dimensionobservation spaces or a preliminary training phase during which task labels arelearned. Moreover, changes in the transition or reward functions can bedetected only in combination with a policy, and therefore are more difficult todetect than changes in the input distribution. This paper presents an approachto learning both policies and labels in an online deep reinforcement learningsetting. The key idea is to use distance metrics, obtained via optimaltransport methods, i.e., Wasserstein distance, on suitable latent action-rewardspaces to measure distances between sets of data points from past and currentstreams. Such distances can then be used for statistical tests based on anadapted Kolmogorov-Smirnov calculation to assign labels to sequences ofexperiences. A rollback procedure is introduced to learn multiple policies byensuring that only the appropriate data is used to train the correspondingpolicy. The combination of task detection and policy deployment allows for theoptimization of lifelong reinforcement learning agents without an oracle thatprovides task labels. The approach is tested using two benchmarks and theresults show promising performance when compared with related context detectionalgorithms. The results suggest that optimal transport statistical methodsprovide an explainable and justifiable procedure for online context detectionand reward optimization in lifelong reinforcement learning.</description><author>Jeffery Dick, Saptarshi Nath, Christos Peridis, Eseoghene Benjamin, Soheil Kolouri, Andrea Soltoggio</author><pubDate>Tue, 03 Sep 2024 09:25:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19047v2</guid></item><item><title>An Efficient Instance Segmentation Framework Using Segmentation Foundation Models with Oriented Bounding Box Prompts</title><link>http://arxiv.org/abs/2401.08174v4</link><description>Instance segmentation in unmanned aerial vehicle measurement is along-standing challenge. Since horizontal bounding boxes introduce manyinterference objects, oriented bounding boxes (OBBs) are usually used forinstance identification. However, based on ``segmentation within bounding box''paradigm, current instance segmentation methods using OBBs are overly dependenton bounding box detection performance. To tackle this, this paper proposesOBSeg, an efficient instance segmentation framework using OBBs. OBSeg is basedon box prompt-based segmentation foundation models (BSMs), e.g., SegmentAnything Model. Specifically, OBSeg first detects OBBs to distinguish instancesand provide coarse localization information. Then, it predicts OBBprompt-related masks for fine segmentation. Since OBBs only serve as prompts,OBSeg alleviates the over-dependence on bounding box detection performance ofcurrent instance segmentation methods using OBBs. In addition, to enable BSMsto handle OBB prompts, we propose a novel OBB prompt encoder. To make OBSegmore lightweight and further improve the performance of lightweight distilledBSMs, a Gaussian smoothing-based knowledge distillation method is introduced.Experiments demonstrate that OBSeg outperforms current instance segmentationmethods on multiple public datasets. The code is available athttps://github.com/zhen6618/OBBInstanceSegmentation.</description><author>Zhen Zhou, Junfeng Fan, Yunkai Ma, Sihan Zhao, Fengshui Jing, Min Tan</author><pubDate>Tue, 03 Sep 2024 09:16:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08174v4</guid></item><item><title>Enhancing Cell Tracking with a Time-Symmetric Deep Learning Approach</title><link>http://arxiv.org/abs/2308.03887v3</link><description>The accurate tracking of live cells using video microscopy recordings remainsa challenging task for popular state-of-the-art image processing based objecttracking methods. In recent years, several existing and new applications haveattempted to integrate deep-learning based frameworks for this task, but mostof them still heavily rely on consecutive frame based tracking embedded intheir architecture or other premises that hinder generalized learning. Toaddress this issue, we aimed to develop a new deep-learning based trackingmethod that relies solely on the assumption that cells can be tracked based ontheir spatio-temporal neighborhood, without restricting it to consecutiveframes. The proposed method has the additional benefit that the motion patternsof the cells can be learned completely by the predictor without any priorassumptions, and it has the potential to handle a large number of video frameswith heavy artifacts. The efficacy of the proposed method is demonstratedthrough biologically motivated validation strategies and compared againstmultiple state-of-the-art cell tracking methods.</description><author>Gergely Szabó, Paolo Bonaiuti, Andrea Ciliberto, András Horváth</author><pubDate>Tue, 03 Sep 2024 08:53:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.03887v3</guid></item><item><title>Controllable Edge-Type-Specific Interpretation in Multi-Relational Graph Neural Networks for Drug Response Prediction</title><link>http://arxiv.org/abs/2408.17129v2</link><description>Graph Neural Networks have been widely applied in critical decision-makingareas that demand interpretable predictions, leading to the flourishingdevelopment of interpretability algorithms. However, current graphinterpretability algorithms tend to emphasize generality and often overlookbiological significance, thereby limiting their applicability in predictingcancer drug responses. In this paper, we propose a novel post-hocinterpretability algorithm for cancer drug response prediction, CETExplainer,which incorporates a controllable edge-type-specific weighting mechanism. Itconsiders the mutual information between subgraphs and predictions, proposing astructural scoring approach to provide fine-grained, biologically meaningfulexplanations for predictive models. We also introduce a method for constructingground truth based on real-world datasets to quantitatively evaluate theproposed interpretability algorithm. Empirical analysis on the real-worlddataset demonstrates that CETExplainer achieves superior stability and improvesexplanation quality compared to leading algorithms, thereby offering a robustand insightful tool for cancer drug prediction.</description><author>Xiaodi Li, Jianfeng Gui, Qian Gao, Haoyuan Shi, Zhenyu Yue</author><pubDate>Tue, 03 Sep 2024 08:45:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17129v2</guid></item><item><title>GANs Conditioning Methods: A Survey</title><link>http://arxiv.org/abs/2408.15640v3</link><description>In recent years, Generative Adversarial Networks (GANs) have seen significantadvancements, leading to their widespread adoption across various fields. Theoriginal GAN architecture enables the generation of images without any specificcontrol over the content, making it an unconditional generation process.However, many practical applications require precise control over the generatedoutput, which has led to the development of conditional GANs (cGANs) thatincorporate explicit conditioning to guide the generation process. cGANs extendthe original framework by incorporating additional information (conditions),enabling the generation of samples that adhere to that specific criteria.Various conditioning methods have been proposed, each differing in how theyintegrate the conditioning information into both the generator and thediscriminator networks. In this work, we review the conditioning methodsproposed for GANs, exploring the characteristics of each method andhighlighting their unique mechanisms and theoretical foundations. Furthermore,we conduct a comparative analysis of these methods, evaluating theirperformance on various image datasets. Through these analyses, we aim toprovide insights into the strengths and limitations of various conditioningtechniques, guiding future research and application in generative modeling.</description><author>Anis Bourou, Valérie Mezger, Auguste Genovesio</author><pubDate>Tue, 03 Sep 2024 08:35:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15640v3</guid></item><item><title>Collaborative Group: Composed Image Retrieval via Consensus Learning from Noisy Annotations</title><link>http://arxiv.org/abs/2306.02092v2</link><description>Composed image retrieval extends content-based image retrieval systems byenabling users to search using reference images and captions that describetheir intention. Despite great progress in developing image-text compositors toextract discriminative visual-linguistic features, we identify a hithertooverlooked issue, triplet ambiguity, which impedes robust feature extraction.Triplet ambiguity refers to a type of semantic ambiguity that arises betweenthe reference image, the relative caption, and the target image. It is mainlydue to the limited representation of the annotated text, resulting in manynoisy triplets where multiple visually dissimilar candidate images can bematched to an identical reference pair (i.e., a reference image + a relativecaption). To address this challenge, we propose the Consensus Network(Css-Net), inspired by the psychological concept that groups outperformindividuals. Css-Net comprises two core components: (1) a consensus module withfour diverse compositors, each generating distinct image-text embeddings,fostering complementary feature extraction and mitigating dependence on anysingle, potentially biased compositor; (2) a Kullback-Leibler divergence lossthat encourages learning of inter-compositor interactions to promote consensualoutputs. During evaluation, the decisions of the four compositors are combinedthrough a weighting scheme, enhancing overall agreement. On benchmark datasets,particularly FashionIQ, Css-Net demonstrates marked improvements. Notably, itachieves significant recall gains, with a 2.77% increase in R@10 and 6.67%boost in R@50, underscoring its competitiveness in addressing the fundamentallimitations of existing methods.</description><author>Xu Zhang, Zhedong Zheng, Linchao Zhu, Yi Yang</author><pubDate>Tue, 03 Sep 2024 08:25:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02092v2</guid></item><item><title>CAST: Cross-Attention in Space and Time for Video Action Recognition</title><link>http://arxiv.org/abs/2311.18825v2</link><description>Recognizing human actions in videos requires spatial and temporalunderstanding. Most existing action recognition models lack a balancedspatio-temporal understanding of videos. In this work, we propose a noveltwo-stream architecture, called Cross-Attention in Space and Time (CAST), thatachieves a balanced spatio-temporal understanding of videos using only RGBinput. Our proposed bottleneck cross-attention mechanism enables the spatialand temporal expert models to exchange information and make synergisticpredictions, leading to improved performance. We validate the proposed methodwith extensive experiments on public benchmarks with different characteristics:EPIC-KITCHENS-100, Something-Something-V2, and Kinetics-400. Our methodconsistently shows favorable performance across these datasets, while theperformance of existing methods fluctuates depending on the datasetcharacteristics.</description><author>Dongho Lee, Jongseo Lee, Jinwoo Choi</author><pubDate>Tue, 03 Sep 2024 08:16:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18825v2</guid></item><item><title>TALDS-Net: Task-Aware Adaptive Local Descriptors Selection for Few-shot Image Classification</title><link>http://arxiv.org/abs/2312.05449v2</link><description>Few-shot image classification aims to classify images from unseen novelclasses with few samples. Recent works demonstrate that deep local descriptorsexhibit enhanced representational capabilities compared to image-levelfeatures. However, most existing methods solely rely on either employing alllocal descriptors or directly utilizing partial descriptors, potentiallyresulting in the loss of crucial information. Moreover, these methods primarilyemphasize the selection of query descriptors while overlooking supportdescriptors. In this paper, we propose a novel Task-Aware Adaptive LocalDescriptors Selection Network (TALDS-Net), which exhibits the capacity foradaptive selection of task-aware support descriptors and query descriptors.Specifically, we compare the similarity of each local support descriptor withother local support descriptors to obtain the optimal support descriptor subsetand then compare the query descriptors with the optimal support subset toobtain discriminative query descriptors. Extensive experiments demonstrate thatour TALDS-Net outperforms state-of-the-art methods on both general andfine-grained datasets.</description><author>Qian Qiao, Yu Xie, Ziyin Zeng, Fanzhang Li</author><pubDate>Tue, 03 Sep 2024 08:01:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05449v2</guid></item><item><title>A Survey on Stability of Learning with Limited Labelled Data and its Sensitivity to the Effects of Randomness</title><link>http://arxiv.org/abs/2312.01082v2</link><description>Learning with limited labelled data, such as prompting, in-context learning,fine-tuning, meta-learning or few-shot learning, aims to effectively train amodel using only a small amount of labelled samples. However, these approacheshave been observed to be excessively sensitive to the effects of uncontrolledrandomness caused by non-determinism in the training process. The randomnessnegatively affects the stability of the models, leading to large variances inresults across training runs. When such sensitivity is disregarded, it canunintentionally, but unfortunately also intentionally, create an imaginaryperception of research progress. Recently, this area started to attractresearch attention and the number of relevant studies is continuously growing.In this survey, we provide a comprehensive overview of 415 papers addressingthe effects of randomness on the stability of learning with limited labelleddata. We distinguish between four main tasks addressed in the papers(investigate/evaluate; determine; mitigate; benchmark/compare/report randomnesseffects), providing findings for each one. Furthermore, we identify and discussseven challenges and open problems together with possible directions tofacilitate further research. The ultimate goal of this survey is to emphasisethe importance of this growing research area, which so far has not received anappropriate level of attention, and reveal impactful directions for futureresearch.</description><author>Branislav Pecher, Ivan Srba, Maria Bielikova</author><pubDate>Tue, 03 Sep 2024 07:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01082v2</guid></item><item><title>Asynchronous Blob Tracker for Event Cameras</title><link>http://arxiv.org/abs/2307.10593v2</link><description>Event-based cameras are popular for tracking fast-moving objects due to theirhigh temporal resolution, low latency, and high dynamic range. In this paper,we propose a novel algorithm for tracking event blobs using raw eventsasynchronously in real time. We introduce the concept of an event blob as aspatio-temporal likelihood of event occurrence where the conditional spatiallikelihood is blob-like. Many real-world objects such as car headlights or anyquickly moving foreground objects generate event blob data. The proposedalgorithm uses a nearest neighbour classifier with a dynamic threshold criteriafor data association coupled with an extended Kalman filter to track the eventblob state. Our algorithm achieves highly accurate blob tracking, velocityestimation, and shape estimation even under challenging lighting conditions andhigh-speed motions (&gt; 11000 pixels/s). The microsecond time resolution achievedmeans that the filter output can be used to derive secondary information suchas time-to-contact or range estimation, that will enable applications toreal-world problems such as collision avoidance in autonomous driving.</description><author>Ziwei Wang, Timothy Molloy, Pieter van Goor, Robert Mahony</author><pubDate>Tue, 03 Sep 2024 07:50:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10593v2</guid></item><item><title>Efficient Heterogeneous Graph Learning via Random Projection</title><link>http://arxiv.org/abs/2310.14481v2</link><description>Heterogeneous Graph Neural Networks (HGNNs) are powerful tools for deeplearning on heterogeneous graphs. Typical HGNNs require repetitive messagepassing during training, limiting efficiency for large-scale real-world graphs.Recent pre-computation-based HGNNs use one-time message passing to transform aheterogeneous graph into regular-shaped tensors, enabling efficient mini-batchtraining. Existing pre-computation-based HGNNs can be mainly categorized intotwo styles, which differ in how much information loss is allowed andefficiency. We propose a hybrid pre-computation-based HGNN, named RandomProjection Heterogeneous Graph Neural Network (RpHGNN), which combines thebenefits of one style's efficiency with the low information loss of the otherstyle. To achieve efficiency, the main framework of RpHGNN consists ofpropagate-then-update iterations, where we introduce a Random ProjectionSquashing step to ensure that complexity increases only linearly. To achievelow information loss, we introduce a Relation-wise Neighbor Collectioncomponent with an Even-odd Propagation Scheme, which aims to collectinformation from neighbors in a finer-grained way. Experimental resultsindicate that our approach achieves state-of-the-art results on seven small andlarge benchmark datasets while also being 230% faster compared to the mosteffective baseline. Surprisingly, our approach not only surpassespre-processing-based baselines but also outperforms end-to-end methods.</description><author>Jun Hu, Bryan Hooi, Bingsheng He</author><pubDate>Tue, 03 Sep 2024 07:46:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14481v2</guid></item><item><title>Rethinking Barely-Supervised Volumetric Medical Image Segmentation from an Unsupervised Domain Adaptation Perspective</title><link>http://arxiv.org/abs/2405.09777v2</link><description>This paper investigates an extremely challenging problem: barely-supervisedvolumetric medical image segmentation (BSS). A BSS training dataset consists oftwo parts: 1) a barely-annotated labeled set, where each labeled image containsonly a single-slice annotation, and 2) an unlabeled set comprising numerousunlabeled volumetric images. State-of-the-art BSS methods employ aregistration-based paradigm, which uses inter-slice image registration topropagate single-slice annotations into volumetric pseudo labels, constructinga completely annotated labeled set, to which a semi-supervised segmentationscheme can be applied. However, the paradigm has a critical limitation: thepseudo-labels generated by image registration are unreliable and noisy.Motivated by this, we propose a new perspective: instead of solving BSS withina semi-supervised learning scheme, this work formulates BSS as an unsuperviseddomain adaptation problem. To this end, we propose a novel BSS framework,\textbf{B}arely-supervised learning \textbf{via} unsupervised domain\textbf{A}daptation (BvA), as an alternative to the dominant registrationparadigm. Specifically, we first design a novel noise-free labeled dataconstruction algorithm (NFC) for slice-to-volume labeled data synthesis. Then,we introduce a frequency and spatial Mix-Up strategy (FSX) to mitigate thedomain shifts. Extensive experiments demonstrate that our method provides apromising alternative for BSS. Remarkably, the proposed method, trained on theleft atrial segmentation dataset with \textbf{only one} barely-labeled image,achieves a Dice score of 81.20%, outperforming the state-of-the-art by 61.71%.The code is available at\href{https://github.com/Senyh/BvA}{\textit{\texttt{https://github.com/Senyh/BvA}}}.</description><author>Zhiqiang Shen, Peng Cao, Junming Su, Jinzhu Yang, Osmar R. Zaiane</author><pubDate>Tue, 03 Sep 2024 07:46:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09777v2</guid></item><item><title>Planning and Rendering: Towards Product Poster Generation with Diffusion Models</title><link>http://arxiv.org/abs/2312.08822v2</link><description>Product poster generation significantly optimizes design efficiency andreduces production costs. Prevailing methods predominantly rely onimage-inpainting methods to generate clean background images for givenproducts. Subsequently, poster layout generation methods are employed toproduce corresponding layout results. However, the background images may not besuitable for accommodating textual content due to their complexity, and thefixed location of products limits the diversity of layout results. To alleviatethese issues, we propose a novel product poster generation framework based ondiffusion models named P\&amp;R. The P\&amp;R draws inspiration from the workflow ofdesigners in creating posters, which consists of two stages: Planning andRendering. At the planning stage, we propose a PlanNet to generate the layoutof the product and other visual components considering both the appearancefeatures of the product and semantic features of the text, which improves thediversity and rationality of the layouts. At the rendering stage, we propose aRenderNet to generate the background for the product while considering thegenerated layout, where a spatial fusion module is introduced to fuse thelayout of different visual components. To foster the advancement of this field,we propose the first product poster generation dataset PPG30k, comprising 30kexquisite product poster images along with comprehensive image and textannotations. Our method outperforms the state-of-the-art product postergeneration methods on PPG30k. The PPG30k will be released soon.</description><author>Zhaochen Li, Fengheng Li, Wei Feng, Honghe Zhu, Yaoyu Li, Zheng Zhang, Jingjing Lv, Junjie Shen, Zhangang Lin, Jingping Shao, Zhenglu Yang</author><pubDate>Tue, 03 Sep 2024 07:42:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08822v2</guid></item><item><title>KTO: Model Alignment as Prospect Theoretic Optimization</title><link>http://arxiv.org/abs/2402.01306v3</link><description>Kahneman &amp; Tversky's $\textit{prospect theory}$ tells us that humans perceiverandom variables in a biased but well-defined manner (1992); for example,humans are famously loss-averse. We show that objectives for aligning LLMs withhuman feedback implicitly incorporate many of these biases -- the success ofthese objectives (e.g., DPO) over cross-entropy minimization can partly beascribed to them belonging to a family of loss functions that we call$\textit{human-aware losses}$ (HALOs). However, the utility functions thesemethods attribute to humans still differ from those in the prospect theoryliterature. Using a Kahneman-Tversky model of human utility, we propose a HALOthat directly maximizes the utility of generations instead of maximizing thelog-likelihood of preferences, as current methods do. We call this approachKTO, and it matches or exceeds the performance of preference-based methods atscales from 1B to 30B, despite only learning from a binary signal of whether anoutput is desirable. More broadly, our work suggests that there is no one HALOthat is universally superior; the best loss depends on the inductive biasesmost appropriate for a given setting, an oft-overlooked consideration.</description><author>Kawin Ethayarajh, Winnie Xu, Niklas Muennighoff, Dan Jurafsky, Douwe Kiela</author><pubDate>Tue, 03 Sep 2024 07:41:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01306v3</guid></item><item><title>Unveiling the Human-like Similarities of Automatic Facial Expression Recognition: An Empirical Exploration through Explainable AI</title><link>http://arxiv.org/abs/2401.11835v3</link><description>Facial expression recognition is vital for human behavior analysis, and deeplearning has enabled models that can outperform humans. However, it is unclearhow closely they mimic human processing. This study aims to explore thesimilarity between deep neural networks and human perception by comparingtwelve different networks, including both general object classifiers andFER-specific models. We employ an innovative global explainable AI method togenerate heatmaps, revealing crucial facial regions for the twelve networkstrained on six facial expressions. We assess these results both quantitativelyand qualitatively, comparing them to ground truth masks based on Friesen andEkman's description and among them. We use Intersection over Union (IoU) andnormalized correlation coefficients for comparisons. We generate 72 heatmaps tohighlight critical regions for each expression and architecture. Qualitatively,models with pre-trained weights show more similarity in heatmaps compared tothose without pre-training. Specifically, eye and nose areas influence certainfacial expressions, while the mouth is consistently important across all modelsand expressions. Quantitatively, we find low average IoU values (avg. 0.2702)across all expressions and architectures. The best-performing architectureaverages 0.3269, while the worst-performing one averages 0.2066. Dendrograms,built with the normalized correlation coefficient, reveal two main clusters formost expressions: models with pre-training and models without pre-training.Findings suggest limited alignment between human and AI facial expressionrecognition, with network architectures influencing the similarity, as similararchitectures prioritize similar facial regions.</description><author>F. Xavier Gaya-Morey, Silvia Ramis-Guarinos, Cristina Manresa-Yee, Jose M. Buades-Rubio</author><pubDate>Tue, 03 Sep 2024 07:39:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11835v3</guid></item><item><title>Learning Exposure Correction in Dynamic Scenes</title><link>http://arxiv.org/abs/2402.17296v3</link><description>Exposure correction aims to enhance visual data suffering from improperexposures, which can greatly improve satisfactory visual effects. However,previous methods mainly focus on the image modality, and the video counterpartis less explored in the literature. Directly applying prior image-based methodsto videos results in temporal incoherence with low visual quality. Throughthorough investigation, we find that the development of relevant communities islimited by the absence of a benchmark dataset. Therefore, in this paper, weconstruct the first real-world paired video dataset, including bothunderexposure and overexposure dynamic scenes. To achieve spatial alignment, weutilize two DSLR cameras and a beam splitter to simultaneously capture improperand normal exposure videos. Additionally, we propose an end-to-end videoexposure correction network, in which a dual-stream module is designed to dealwith both underexposure and overexposure factors, enhancing the illuminationbased on Retinex theory. The extensive experiments based on various metrics anduser studies demonstrate the significance of our dataset and the effectivenessof our method. The code and dataset are available athttps://github.com/kravrolens/VECNet.</description><author>Jin Liu, Bo Wang, Chuanming Wang, Huiyuan Fu, Huadong Ma</author><pubDate>Tue, 03 Sep 2024 07:38:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17296v3</guid></item><item><title>End-to-end Feature Selection Approach for Learning Skinny Trees</title><link>http://arxiv.org/abs/2310.18542v2</link><description>We propose a new optimization-based approach for feature selection in treeensembles, an important problem in statistics and machine learning. Populartree ensemble toolkits e.g., Gradient Boosted Trees and Random Forests supportfeature selection post-training based on feature importance scores, while verypopular, they are known to have drawbacks. We propose Skinny Trees: anend-to-end toolkit for feature selection in tree ensembles where we train atree ensemble while controlling the number of selected features. Ouroptimization-based approach learns an ensemble of differentiable trees, andsimultaneously performs feature selection using a grouped $\ell_0$-regularizer.We use first-order methods for optimization and present convergence guaranteesfor our approach. We use a dense-to-sparse regularization scheduling schemethat can lead to more expressive and sparser tree ensembles. On 15 syntheticand real-world datasets, Skinny Trees can achieve $1.5\!\times\!-~620~\!\times\!$ feature compression rates, leading up to $10\times$ fasterinference over dense trees, without any loss in performance. Skinny Trees leadto superior feature selection than many existing toolkits e.g., in terms of AUCperformance for 25\% feature budget, Skinny Trees outperforms LightGBM by$10.2\%$ (up to $37.7\%$), and Random Forests by $3\%$ (up to $12.5\%$).</description><author>Shibal Ibrahim, Kayhan Behdin, Rahul Mazumder</author><pubDate>Tue, 03 Sep 2024 07:34:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18542v2</guid></item><item><title>Deep Learning for Computer Vision based Activity Recognition and Fall Detection of the Elderly: a Systematic Review</title><link>http://arxiv.org/abs/2401.11790v3</link><description>As the percentage of elderly people in developed countries increasesworldwide, the healthcare of this collective is a worrying matter, especiallyif it includes the preservation of their autonomy. In this direction, manystudies are being published on Ambient Assisted Living (AAL) systems, whichhelp to reduce the preoccupations raised by the independent living of theelderly. In this study, a systematic review of the literature is presented onfall detection and Human Activity Recognition (HAR) for the elderly, as the twomain tasks to solve to guarantee the safety of elderly people living alone. Toaddress the current tendency to perform these two tasks, the review focuses onthe use of Deep Learning (DL) based approaches on computer vision data. Inaddition, different collections of data like DL models, datasets or hardware(e.g. depth or thermal cameras) are gathered from the reviewed studies andprovided for reference in future studies. Strengths and weaknesses of existingapproaches are also discussed and, based on them, our recommendations forfuture works are provided.</description><author>F. Xavier Gaya-Morey, Cristina Manresa-Yee, Jose M. Buades-Rubio</author><pubDate>Tue, 03 Sep 2024 07:34:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11790v3</guid></item><item><title>RefSAM: Efficiently Adapting Segmenting Anything Model for Referring Video Object Segmentation</title><link>http://arxiv.org/abs/2307.00997v3</link><description>The Segment Anything Model (SAM) has gained significant attention for itsimpressive performance in image segmentation. However, it lacks proficiency inreferring video object segmentation (RVOS) due to the need for preciseuser-interactive prompts and a limited understanding of different modalities,such as language and vision. This paper presents the RefSAM model, whichexplores the potential of SAM for RVOS by incorporating multi-view informationfrom diverse modalities and successive frames at different timestamps in anonline manner. Our proposed approach adapts the original SAM model to enhancecross-modality learning by employing a lightweight Cross-Modal MLP thatprojects the text embedding of the referring expression into sparse and denseembeddings, serving as user-interactive prompts. Additionally, we haveintroduced the hierarchical dense attention module to fuse hierarchical visualsemantic information with sparse embeddings to obtain fine-grained denseembeddings, and an implicit tracking module to generate a tracking token andprovide historical information for the mask decoder. Furthermore, we employ aparameter-efficient tuning strategy to align and fuse the language and visionfeatures effectively. Through comprehensive ablation studies, we demonstrateour model's practical and effective design choices. Extensive experimentsconducted on Refer-Youtube-VOS, Ref-DAVIS17, and three referring imagesegmentation datasets validate the superiority and effectiveness of our RefSAMmodel over existing methods.</description><author>Yonglin Li, Jing Zhang, Xiao Teng, Long Lan, Xinwang Liu</author><pubDate>Tue, 03 Sep 2024 07:25:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00997v3</guid></item><item><title>Fair Mixed Effects Support Vector Machine</title><link>http://arxiv.org/abs/2405.06433v3</link><description>To ensure unbiased and ethical automated predictions, fairness must be a coreprinciple in machine learning applications. Fairness in machine learning aimsto mitigate biases present in the training data and model imperfections thatcould lead to discriminatory outcomes. This is achieved by preventing the modelfrom making decisions based on sensitive characteristics like ethnicity orsexual orientation. A fundamental assumption in machine learning is theindependence of observations. However, this assumption often does not hold truefor data describing social phenomena, where data points are often clusteredbased. Hence, if the machine learning models do not account for the clustercorrelations, the results may be biased. Especially high is the bias in caseswhere the cluster assignment is correlated to the variable of interest. Wepresent a fair mixed effects support vector machine algorithm that can handleboth problems simultaneously. With a reproducible simulation study wedemonstrate the impact of clustered data on the quality of fair machinelearning predictions.</description><author>João Vitor Pamplona, Jan Pablo Burgard</author><pubDate>Tue, 03 Sep 2024 07:10:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.06433v3</guid></item><item><title>Towards Scalable Automated Alignment of LLMs: A Survey</title><link>http://arxiv.org/abs/2406.01252v3</link><description>Alignment is the most critical step in building large language models (LLMs)that meet human needs. With the rapid development of LLMs gradually surpassinghuman capabilities, traditional alignment methods based on human-annotation areincreasingly unable to meet the scalability demands. Therefore, there is anurgent need to explore new sources of automated alignment signals and technicalapproaches. In this paper, we systematically review the recently emergingmethods of automated alignment, attempting to explore how to achieve effective,scalable, automated alignment once the capabilities of LLMs exceed those ofhumans. Specifically, we categorize existing automated alignment methods into 4major categories based on the sources of alignment signals and discuss thecurrent status and potential development of each category. Additionally, weexplore the underlying mechanisms that enable automated alignment and discussthe essential factors that make automated alignment technologies feasible andeffective from the fundamental role of alignment.</description><author>Boxi Cao, Keming Lu, Xinyu Lu, Jiawei Chen, Mengjie Ren, Hao Xiang, Peilin Liu, Yaojie Lu, Ben He, Xianpei Han, Le Sun, Hongyu Lin, Bowen Yu</author><pubDate>Tue, 03 Sep 2024 07:07:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01252v3</guid></item><item><title>PointRWKV: Efficient RWKV-Like Model for Hierarchical Point Cloud Learning</title><link>http://arxiv.org/abs/2405.15214v2</link><description>Transformers have revolutionized the point cloud learning task, but thequadratic complexity hinders its extension to long sequence and makes a burdenon limited computational resources. The recent advent of RWKV, a fresh breed ofdeep sequence models, has shown immense potential for sequence modeling in NLPtasks. In this paper, we present PointRWKV, a model of linear complexityderived from the RWKV model in the NLP field with necessary modifications forpoint cloud learning tasks. Specifically, taking the embedded point patches asinput, we first propose to explore the global processing capabilities withinPointRWKV blocks using modified multi-headed matrix-valued states and a dynamicattention recurrence mechanism. To extract local geometric featuressimultaneously, we design a parallel branch to encode the point cloudefficiently in a fixed radius near-neighbors graph with a graph stabilizer.Furthermore, we design PointRWKV as a multi-scale framework for hierarchicalfeature learning of 3D point clouds, facilitating various downstream tasks.Extensive experiments on different point cloud learning tasks show our proposedPointRWKV outperforms the transformer- and mamba-based counterparts, whilesignificantly saving about 42\% FLOPs, demonstrating the potential option forconstructing foundational 3D models.</description><author>Qingdong He, Jiangning Zhang, Jinlong Peng, Haoyang He, Xiangtai Li, Yabiao Wang, Chengjie Wang</author><pubDate>Tue, 03 Sep 2024 06:40:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15214v2</guid></item><item><title>White-Box Transformers via Sparse Rate Reduction: Compression Is All There Is?</title><link>http://arxiv.org/abs/2311.13110v3</link><description>In this paper, we contend that a natural objective of representation learningis to compress and transform the distribution of the data, say sets of tokens,towards a low-dimensional Gaussian mixture supported on incoherent subspaces.The goodness of such a representation can be evaluated by a principled measure,called sparse rate reduction, that simultaneously maximizes the intrinsicinformation gain and extrinsic sparsity of the learned representation. Fromthis perspective, popular deep network architectures, including transformers,can be viewed as realizing iterative schemes to optimize this measure.Particularly, we derive a transformer block from alternating optimization onparts of this objective: the multi-head self-attention operator compresses therepresentation by implementing an approximate gradient descent step on thecoding rate of the features, and the subsequent multi-layer perceptronsparsifies the features. This leads to a family of white-box transformer-likedeep network architectures, named CRATE, which are mathematically fullyinterpretable. We show, by way of a novel connection between denoising andcompression, that the inverse to the aforementioned compressive encoding can berealized by the same class of CRATE architectures. Thus, the so-derivedwhite-box architectures are universal to both encoders and decoders.Experiments show that these networks, despite their simplicity, indeed learn tocompress and sparsify representations of large-scale real-world image and textdatasets, and achieve performance very close to highly engineeredtransformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe theproposed computational framework demonstrates great potential in bridging thegap between theory and practice of deep learning, from a unified perspective ofdata compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .</description><author>Yaodong Yu, Sam Buchanan, Druv Pai, Tianzhe Chu, Ziyang Wu, Shengbang Tong, Hao Bai, Yuexiang Zhai, Benjamin D. Haeffele, Yi Ma</author><pubDate>Tue, 03 Sep 2024 06:31:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13110v3</guid></item><item><title>Correlation-Embedded Transformer Tracking: A Single-Branch Framework</title><link>http://arxiv.org/abs/2401.12743v2</link><description>Developing robust and discriminative appearance models has been along-standing research challenge in visual object tracking. In the prevalentSiamese-based paradigm, the features extracted by the Siamese-like networks areoften insufficient to model the tracked targets and distractor objects, therebyhindering them from being robust and discriminative simultaneously. While mostSiamese trackers focus on designing robust correlation operations, we propose anovel single-branch tracking framework inspired by the transformer. Unlike theSiamese-like feature extraction, our tracker deeply embeds cross-image featurecorrelation in multiple layers of the feature network. By extensively matchingthe features of the two images through multiple layers, it can suppressnon-target features, resulting in target-aware feature extraction. The outputfeatures can be directly used for predicting target locations withoutadditional correlation steps. Thus, we reformulate the two-branch Siamesetracking as a conceptually simple, fully transformer-based Single-BranchTracking pipeline, dubbed SBT. After conducting an in-depth analysis of the SBTbaseline, we summarize many effective design principles and propose an improvedtracker dubbed SuperSBT. SuperSBT adopts a hierarchical architecture with alocal modeling layer to enhance shallow-level features. A unified relationmodeling is proposed to remove complex handcrafted layer pattern designs.SuperSBT is further improved by masked image modeling pre-training, integratingtemporal modeling, and equipping with dedicated prediction heads. Thus,SuperSBT outperforms the SBT baseline by 4.7%,3.0%, and 4.5% AUC scores inLaSOT, TrackingNet, and GOT-10K. Notably, SuperSBT greatly raises the speed ofSBT from 37 FPS to 81 FPS. Extensive experiments show that our method achievessuperior results on eight VOT benchmarks.</description><author>Fei Xie, Wankou Yang, Chunyu Wang, Lei Chu, Yue Cao, Chao Ma, Wenjun Zeng</author><pubDate>Tue, 03 Sep 2024 06:13:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12743v2</guid></item><item><title>A Fundamental Trade-off in Aligned Language Models and its Relation to Sampling Adaptors</title><link>http://arxiv.org/abs/2406.10203v2</link><description>The relationship between the quality of a string, as judged by a humanreader, and its probability, $p(\boldsymbol{y})$ under a language modelundergirds the development of better language models. For example, many popularalgorithms for sampling from a language model have been conceived with the goalof manipulating $p(\boldsymbol{y})$ to place higher probability on strings thathumans deem of high quality. In this article, we examine theprobability--quality relationship in language models explicitly aligned tohuman preferences, e.g., through reinforcement learning through human feedback.We show that, when sampling corpora from an aligned language model, thereexists a trade-off between the strings' average reward and averagelog-likelihood under the prior language model, i.e., the same model beforealignment with human preferences. We provide a formal treatment of thisphenomenon and demonstrate how a choice of sampling adaptor allows for aselection of how much likelihood we exchange for the reward.</description><author>Naaman Tan, Josef Valvoda, Tianyu Liu, Anej Svete, Yanxia Qin, Kan Min-Yen, Ryan Cotterell</author><pubDate>Tue, 03 Sep 2024 06:05:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10203v2</guid></item><item><title>Contrastive Learning and Abstract Concepts: The Case of Natural Numbers</title><link>http://arxiv.org/abs/2408.02247v4</link><description>Contrastive Learning (CL) has been successfully applied to classification andother downstream tasks related to concrete concepts, such as objects containedin the ImageNet dataset. No attempts seem to have been made so far in applyingthis promising scheme to more abstract entities. A prominent example of thesecould be the concept of (discrete) Quantity. CL can be frequently interpretedas a self-supervised scheme guided by some profound and ubiquitous conservationprinciple (e.g. conservation of identity in object classification tasks). Inthis introductory work we apply a suitable conservation principle to thesemi-abstract concept of natural numbers by which discrete quantities can beestimated or predicted. We experimentally show, by means of a toy problem, thatcontrastive learning can be trained to count at a glance with high accuracyboth at human as well as at super-human ranges.. We compare this with theresults of a trained-to-count at a glance supervised learning (SL) neuralnetwork scheme of similar architecture. We show that both schemes exhibitsimilar good performance on baseline experiments, where the distributions ofthe training and testing stages are equal. Importantly, we demonstrate that insome generalization scenarios, where training and testing distributions differ,CL boasts more robust and much better error performance.</description><author>Daniel N. Nissani</author><pubDate>Tue, 03 Sep 2024 06:02:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02247v4</guid></item><item><title>Correcting misinformation on social media with a large language model</title><link>http://arxiv.org/abs/2403.11169v4</link><description>Real-world misinformation, often multimodal, can be partially or fullyfactual but misleading using diverse tactics like conflating correlation withcausation. Such misinformation is severely understudied, challenging toaddress, and harms various social domains, particularly on social media, whereit can spread rapidly. High-quality and timely correction of misinformationthat identifies and explains its (in)accuracies effectively reduces falsebeliefs. Despite the wide acceptance of manual correction, it is difficult tobe timely and scalable. While LLMs have versatile capabilities that couldaccelerate misinformation correction, they struggle due to a lack of recentinformation, a tendency to produce false content, and limitations in addressingmultimodal information. We propose MUSE, an LLM augmented with access to andcredibility evaluation of up-to-date information. By retrieving evidence asrefutations or supporting context, MUSE identifies and explains content(in)accuracies with references. It conducts multimodal retrieval and interpretsvisual content to verify and correct multimodal content. Given the absence of acomprehensive evaluation approach, we propose 13 dimensions of misinformationcorrection quality. Then, fact-checking experts evaluate responses to socialmedia content that are not presupposed to be misinformation but broadly include(partially) incorrect and correct posts that may (not) be misleading. Resultsdemonstrate MUSE's ability to write high-quality responses to potentialmisinformation--across modalities, tactics, domains, political leanings, andfor information that has not previously been fact-checked online--withinminutes of its appearance on social media. Overall, MUSE outperforms GPT-4 by37% and even high-quality responses from laypeople by 29%. Our work provides ageneral methodological and evaluative framework to correct misinformation atscale.</description><author>Xinyi Zhou, Ashish Sharma, Amy X. Zhang, Tim Althoff</author><pubDate>Tue, 03 Sep 2024 05:51:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11169v4</guid></item><item><title>NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment</title><link>http://arxiv.org/abs/2405.01481v2</link><description>Aligning Large Language Models (LLMs) with human values and preferences isessential for making them helpful and safe. However, building efficient toolsto perform alignment can be challenging, especially for the largest and mostcompetent LLMs which often contain tens or hundreds of billions of parameters.We create NeMo-Aligner, a toolkit for model alignment that can efficientlyscale to a thousand GPUs for training the largest open-source LLMs such asNemotron 4 340B and Llama 3.1 405B. NeMo-Aligner comes with highly optimizedand scalable implementations for major paradigms of model alignment such as:Reinforcement Learning from Human Feedback (RLHF), Direct PreferenceOptimization (DPO), SteerLM, and Self-Play Fine-Tuning (SPIN). Additionally,our toolkit supports running most of the alignment techniques in a ParameterEfficient Fine-Tuning (PEFT) setting. NeMo-Aligner is designed forextensibility, allowing support for other alignment techniques with minimaleffort. It is open-sourced with Apache 2.0 License and we invite communitycontributions at https://github.com/NVIDIA/NeMo-Aligner</description><author>Gerald Shen, Zhilin Wang, Olivier Delalleau, Jiaqi Zeng, Yi Dong, Daniel Egert, Shengyang Sun, Jimmy Zhang, Sahil Jain, Ali Taghibakhshi, Markel Sanz Ausin, Ashwath Aithal, Oleksii Kuchaiev</author><pubDate>Tue, 03 Sep 2024 05:47:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.01481v2</guid></item><item><title>Learning from the Web: Language Drives Weakly-Supervised Incremental Learning for Semantic Segmentation</title><link>http://arxiv.org/abs/2407.13363v2</link><description>Current weakly-supervised incremental learning for semantic segmentation(WILSS) approaches only consider replacing pixel-level annotations withimage-level labels, while the training images are still from well-designeddatasets. In this work, we argue that widely available web images can also beconsidered for the learning of new classes. To achieve this, firstly weintroduce a strategy to select web images which are similar to previously seenexamples in the latent space using a Fourier-based domain discriminator. Then,an effective caption-driven reharsal strategy is proposed to preservepreviously learnt classes. To our knowledge, this is the first work to relysolely on web images for both the learning of new concepts and the preservationof the already learned ones in WILSS. Experimental results show that theproposed approach can reach state-of-the-art performances without usingmanually selected and annotated data in the incremental steps.</description><author>Chang Liu, Giulia Rizzoli, Pietro Zanuttigh, Fu Li, Yi Niu</author><pubDate>Tue, 03 Sep 2024 05:10:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.13363v2</guid></item><item><title>PokerKit: A Comprehensive Python Library for Fine-Grained Multi-Variant Poker Game Simulations</title><link>http://arxiv.org/abs/2308.07327v6</link><description>PokerKit is an open-source Python library designed to overcome therestrictions of existing poker game simulation and hand evaluation tools, whichtypically support only a handful of poker variants and lack flexibility in gamestate control. In contrast, PokerKit significantly expands this scope bysupporting an extensive array of poker variants and it provides a flexiblearchitecture for users to define their custom games. This paper details thedesign and implementation of PokerKit, including its intuitive programmaticAPI, multi-variant game support, and a unified hand evaluation suite acrossdifferent hand types. The flexibility of PokerKit allows for applications indiverse areas, such as poker AI development, tool creation, and online pokercasino implementation. PokerKit's reliability has been established throughstatic type checking, extensive doctests, and unit tests, achieving 99% codecoverage. The introduction of PokerKit represents a significant contribution tothe field of computer poker, fostering future research and advanced AIdevelopment for a wide variety of poker games. The source code is available athttps://github.com/uoftcprg/pokerkit</description><author>Juho Kim</author><pubDate>Tue, 03 Sep 2024 05:01:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07327v6</guid></item><item><title>On the Optimality of Misspecified Spectral Algorithms</title><link>http://arxiv.org/abs/2303.14942v3</link><description>In the misspecified spectral algorithms problem, researchers usually assumethe underground true function $f_{\rho}^{*} \in [\mathcal{H}]^{s}$, aless-smooth interpolation space of a reproducing kernel Hilbert space (RKHS)$\mathcal{H}$ for some $s\in (0,1)$. The existing minimax optimal resultsrequire $\|f_{\rho}^{*}\|_{L^{\infty}}&lt;\infty$ which implicitly requires $s &gt;\alpha_{0}$ where $\alpha_{0}\in (0,1)$ is the embedding index, a constantdepending on $\mathcal{H}$. Whether the spectral algorithms are optimal for all$s\in (0,1)$ is an outstanding problem lasting for years. In this paper, weshow that spectral algorithms are minimax optimal for any$\alpha_{0}-\frac{1}{\beta} &lt; s &lt; 1$, where $\beta$ is the eigenvalue decayrate of $\mathcal{H}$. We also give several classes of RKHSs whose embeddingindex satisfies $ \alpha_0 = \frac{1}{\beta} $. Thus, the spectral algorithmsare minimax optimal for all $s\in (0,1)$ on these RKHSs.</description><author>Haobo Zhang, Yicheng Li, Qian Lin</author><pubDate>Tue, 03 Sep 2024 04:57:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.14942v3</guid></item><item><title>Squid: Long Context as a New Modality for Energy-Efficient On-Device Language Models</title><link>http://arxiv.org/abs/2408.15518v2</link><description>This paper presents Dolphin, a novel decoder-decoder architecture forenergy-efficient processing of long contexts in language models. Our approachaddresses the significant energy consumption and latency challenges inherent inon-device models. Dolphin employs a compact 0.5B parameter decoder to distillextensive contextual information into a memory embedding, substantiallyreducing the input length for the primary 7B parameter decoder model. Inspiredby vision-language models, we repurpose the image embedding projector to encodelong textual contexts, effectively treating extended context as a distinctmodality. This innovative method enables processing of substantially longercontexts without the typical computational overhead associated with extendedinput sequences. Empirical evaluations demonstrate a 10-fold improvement inenergy efficiency and a 5-fold reduction in latency compared to conventionalfull-length context processing methods without losing quality of the response.Our work contributes to the development of more sustainable and scalablelanguage models for on-device applications, addressing the critical need forenergy-efficient and responsive AI technologies in resource-constrainedenvironments while maintaining the accuracy to understand long contexts. Thisresearch has implications for the broader field of natural language processing,particularly in the domain of efficient model design for resource-limitedsettings. By enabling more sophisticated AI capabilities on edge devices,Dolphin paves the way for advanced language processing in a wide range ofapplications where computational resources are at a premium. The Dolphin modelis publicly available at https://huggingface.co/NexaAIDev/Dolphin.</description><author>Wei Chen, Zhiyuan Li, Shuo Xin, Yihao Wang</author><pubDate>Tue, 03 Sep 2024 04:38:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15518v2</guid></item><item><title>Safety Constrained Multi-Agent Reinforcement Learning for Active Voltage Control</title><link>http://arxiv.org/abs/2405.08443v2</link><description>Active voltage control presents a promising avenue for relieving powercongestion and enhancing voltage quality, taking advantage of the distributedcontrollable generators in the power network, such as roof-top photovoltaics.While Multi-Agent Reinforcement Learning (MARL) has emerged as a compellingapproach to address this challenge, existing MARL approaches tend to overlookthe constrained optimization nature of this problem, failing in guaranteeingsafety constraints. In this paper, we formalize the active voltage controlproblem as a constrained Markov game and propose a safety-constrained MARLalgorithm. We expand the primal-dual optimization RL method to multi-agentsettings, and augment it with a novel approach of double safety estimation tolearn the policy and to update the Lagrange-multiplier. In addition, weproposed different cost functions and investigated their influences on thebehavior of our constrained MARL method. We evaluate our approach in the powerdistribution network simulation environment with real-world scale scenarios.Experimental results demonstrate the effectiveness of the proposed methodcompared with the state-of-the-art MARL methods. This paper is published at\url{https://www.ijcai.org/Proceedings/2024/}.</description><author>Yang Qu, Jinming Ma, Feng Wu</author><pubDate>Tue, 03 Sep 2024 04:10:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08443v2</guid></item><item><title>Image-Based Virtual Try-On: A Survey</title><link>http://arxiv.org/abs/2311.04811v4</link><description>Image-based virtual try-on aims to synthesize a naturally dressed personimage with a clothing image, which revolutionizes online shopping and inspiresrelated topics within image generation, showing both research significance andcommercial potential. However, there is a gap between current research progressand commercial applications and an absence of comprehensive overview of thisfield to accelerate the development.In this survey, we provide a comprehensiveanalysis of the state-of-the-art techniques and methodologies in aspects ofpipeline architecture, person representation and key modules such as try-onindication, clothing warping and try-on stage. We additionally apply CLIP toassess the semantic alignment of try-on results, and evaluate representativemethods with uniformly implemented evaluation metrics on the same dataset.Inaddition to quantitative and qualitative evaluation of current open-sourcemethods, unresolved issues are highlighted and future research directions areprospected to identify key trends and inspire further exploration. Theuniformly implemented evaluation metrics, dataset and collected methods will bemade public available athttps://github.com/little-misfit/Survey-Of-Virtual-Try-On.</description><author>Dan Song, Xuanpu Zhang, Juan Zhou, Weizhi Nie, Ruofeng Tong, Mohan Kankanhalli, An-An Liu</author><pubDate>Tue, 03 Sep 2024 03:54:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04811v4</guid></item><item><title>DocKylin: A Large Multimodal Model for Visual Document Understanding with Efficient Visual Slimming</title><link>http://arxiv.org/abs/2406.19101v2</link><description>Current multimodal large language models (MLLMs) face significant challengesin visual document understanding (VDU) tasks due to the high resolution, densetext, and complex layouts typical of document images. These characteristicsdemand a high level of detail perception ability from MLLMs. While increasinginput resolution improves detail perception capability, it also leads to longersequences of visual tokens, increasing computational costs and straining themodels' ability to handle long contexts. To address these challenges, weintroduce DocKylin, a document-centric MLLM that performs visual contentslimming at both the pixel and token levels, thereby reducing token sequencelength in VDU scenarios. We introduce an Adaptive Pixel Slimming (APS)preprocessing module to perform pixel-level slimming, increasing the proportionof informative pixels. Moreover, we propose a novel Dynamic Token Slimming(DTS) module to conduct token-level slimming, filtering essential tokens andremoving others to adaptively create a more compact visual sequence.Experiments demonstrate DocKylin's promising performance across various VDUbenchmarks and the effectiveness of each component.</description><author>Jiaxin Zhang, Wentao Yang, Songxuan Lai, Zecheng Xie, Lianwen Jin</author><pubDate>Tue, 03 Sep 2024 03:51:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19101v2</guid></item><item><title>Halfway Escape Optimization: A Quantum-Inspired Solution for General Optimization Problems</title><link>http://arxiv.org/abs/2405.02850v6</link><description>This paper first proposes the Halfway Escape Optimization (HEO) algorithm, aquantum-inspired metaheuristic designed to address general optimizationproblems characterized by rugged landscapes and high-dimensionality with anefficient convergence rate. The study presents a comprehensive comparativeevaluation of HEO's performance against established optimization algorithms,including Particle Swarm Optimization (PSO), Genetic Algorithm (GA), ArtificialFish Swarm Algorithm (AFSA), Grey Wolf Optimizer (GWO), and Quantum behavedParticle Swarm Optimization (QPSO). The primary analysis encompasses 14benchmark functions with dimension 30, demonstrating HEO's effectiveness andadaptability in navigating general optimization problems and providing valuableinsights into its performance. The test of HEO in Pressure Vessel Design andTubular Column Design infers its feasibility and potential in real-timeapplications. Further validation in Osmancik-97 and Cammeo Rice Classificationproves the effectiveness of HEO and achieves a higher accuracy record.</description><author>Jiawen Li, Anwar PP Abdul Majeed, Pascal Lefevre</author><pubDate>Tue, 03 Sep 2024 03:49:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02850v6</guid></item><item><title>Antidote: Post-fine-tuning Safety Alignment for Large Language Models against Harmful Fine-tuning</title><link>http://arxiv.org/abs/2408.09600v2</link><description>Safety aligned Large Language Models (LLMs) are vulnerable to harmfulfine-tuning attacks \cite{qi2023fine}-- a few harmful data mixed in thefine-tuning dataset can break the LLMs's safety alignment. Existing mitigationstrategies include alignment stage solutions \cite{huang2024vaccine,rosati2024representation} and fine-tuning stage solutions\cite{huang2024lazy,mukhoti2023fine}. However, our evaluation shows that bothcategories of defenses fail \textit{when some specific traininghyper-parameters are chosen} -- a large learning rate or a large number oftraining epochs in the fine-tuning stage can easily invalidate the defense,which however, is necessary to guarantee finetune performance. To this end, wepropose Antidote, a post-fine-tuning stage solution, which remains\textbf{\textit{agnostic to the training hyper-parameters in the fine-tuningstage}}. Antidote relies on the philosophy that by removing the harmfulparameters, the harmful model can be recovered from the harmful behaviors,regardless of how those harmful parameters are formed in the fine-tuning stage.With this philosophy, we introduce a one-shot pruning stage after harmfulfine-tuning to remove the harmful weights that are responsible for thegeneration of harmful content. Despite its embarrassing simplicity, empiricalresults show that Antidote can reduce harmful score while maintaining accuracyon downstream tasks.Our project page is at\url{https://huangtiansheng.github.io/Antidote_gh_page/}</description><author>Tiansheng Huang, Gautam Bhattacharya, Pratik Joshi, Josh Kimball, Ling Liu</author><pubDate>Tue, 03 Sep 2024 03:45:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09600v2</guid></item><item><title>Towards reliable respiratory disease diagnosis based on cough sounds and vision transformers</title><link>http://arxiv.org/abs/2408.15667v2</link><description>Recent advancements in deep learning techniques have sparked performanceboosts in various real-world applications including disease diagnosis based onmulti-modal medical data. Cough sound data-based respiratory disease (e.g.,COVID-19 and Chronic Obstructive Pulmonary Disease) diagnosis has alsoattracted much attention. However, existing works usually utilise traditionalmachine learning or deep models of moderate scales. On the other hand, thedeveloped approaches are trained and evaluated on small-scale data due to thedifficulty of curating and annotating clinical data on scale. To address theseissues in prior works, we create a unified framework to evaluate various deepmodels from lightweight Convolutional Neural Networks (e.g., ResNet18) tomodern vision transformers and compare their performance in respiratory diseaseclassification. Based on the observations from such an extensive empiricalstudy, we propose a novel approach to cough-based disease classification basedon both self-supervised and supervised learning on a large-scale cough dataset. Experimental results demonstrate our proposed approach outperforms priorarts consistently on two benchmark datasets for COVID-19 diagnosis and aproprietary dataset for COPD/non-COPD classification with an AUROC of 92.5%.</description><author>Qian Wang, Zhaoyang Bu, Jiaxuan Mao, Wenyu Zhu, Jingya Zhao, Wei Du, Guochao Shi, Min Zhou, Si Chen, Jieming Qu</author><pubDate>Tue, 03 Sep 2024 03:22:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.15667v2</guid></item><item><title>Learn Suspected Anomalies from Event Prompts for Video Anomaly Detection</title><link>http://arxiv.org/abs/2403.01169v2</link><description>Most models for weakly supervised video anomaly detection (WS-VAD) rely onmultiple instance learning, aiming to distinguish normal and abnormal snippetswithout specifying the type of anomaly. However, the ambiguous nature ofanomaly definitions across contexts may introduce inaccuracy in discriminatingabnormal and normal events. To show the model what is anomalous, a novelframework is proposed to guide the learning of suspected anomalies from eventprompts. Given a textual prompt dictionary of potential anomaly events and thecaptions generated from anomaly videos, the semantic anomaly similarity betweenthem could be calculated to identify the suspected events for each videosnippet. It enables a new multi-prompt learning process to constrain thevisual-semantic features across all videos, as well as provides a new way tolabel pseudo anomalies for self-training. To demonstrate its effectiveness,comprehensive experiments and detailed ablation studies are conducted on fourdatasets, namely XD-Violence, UCF-Crime, TAD, and ShanghaiTech. Our proposedmodel outperforms most state-of-the-art methods in terms of AP or AUC (86.5\%,\hl{90.4}\%, 94.4\%, and 97.4\%). Furthermore, it shows promising performancein open-set and cross-dataset cases. The data, code, and models can be foundat: \url{https://github.com/shiwoaz/lap}.</description><author>Chenchen Tao, Xiaohao Peng, Chong Wang, Jiafei Wu, Puning Zhao, Jun Wang, Jiangbo Qian</author><pubDate>Tue, 03 Sep 2024 03:21:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01169v2</guid></item><item><title>TagCLIP: Improving Discrimination Ability of Open-Vocabulary Semantic Segmentation</title><link>http://arxiv.org/abs/2304.07547v2</link><description>Contrastive Language-Image Pre-training (CLIP) has recently shown greatpromise in pixel-level zero-shot learning tasks. However, existing approachesutilizing CLIP's text and patch embeddings to generate semantic masks oftenmisidentify input pixels from unseen classes, leading to confusion betweennovel classes and semantically similar ones. In this work, we propose a novelapproach, TagCLIP (Trusty-aware guided CLIP), to address this issue. Wedisentangle the ill-posed optimization problem into two parallel processes:semantic matching performed individually and reliability judgment for improvingdiscrimination ability. Building on the idea of special tokens in languagemodeling representing sentence-level embeddings, we introduce a trusty tokenthat enables distinguishing novel classes from known ones in prediction. Toevaluate our approach, we conduct experiments on two benchmark datasets, PASCALVOC 2012, COCO-Stuff 164K and PASCAL Context. Our results show that TagCLIPimproves the Intersection over Union (IoU) of unseen classes by 7.4%, 1.7% and2.1%, respectively, with negligible overheads. The code is available athttps://github.com/dvlab-research/TagCLIP.</description><author>Jingyao Li, Pengguang Chen, Shengju Qian, Shu Liu, Jiaya Jia</author><pubDate>Tue, 03 Sep 2024 03:20:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.07547v2</guid></item><item><title>Cross-Platform Video Person ReID: A New Benchmark Dataset and Adaptation Approach</title><link>http://arxiv.org/abs/2408.07500v2</link><description>In this paper, we construct a large-scale benchmark dataset forGround-to-Aerial Video-based person Re-Identification, named G2A-VReID, whichcomprises 185,907 images and 5,576 tracklets, featuring 2,788 distinctidentities. To our knowledge, this is the first dataset for video ReID underGround-to-Aerial scenarios. G2A-VReID dataset has the followingcharacteristics: 1) Drastic view changes; 2) Large number of annotatedidentities; 3) Rich outdoor scenarios; 4) Huge difference in resolution.Additionally, we propose a new benchmark approach for cross-platform ReID bytransforming the cross-platform visual alignment problem into visual-semanticalignment through vision-language model (i.e., CLIP) and applying aparameter-efficient Video Set-Level-Adapter module to adapt image-basedfoundation model to video ReID tasks, termed VSLA-CLIP. Besides, to furtherreduce the great discrepancy across the platforms, we also devise theplatform-bridge prompts for efficient visual feature alignment. Extensiveexperiments demonstrate the superiority of the proposed method on all existingvideo ReID datasets and our proposed G2A-VReID dataset.</description><author>Shizhou Zhang, Wenlong Luo, De Cheng, Qingchun Yang, Lingyan Ran, Yinghui Xing, Yanning Zhang</author><pubDate>Tue, 03 Sep 2024 02:50:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.07500v2</guid></item><item><title>TimeSeriesBench: An Industrial-Grade Benchmark for Time Series Anomaly Detection Models</title><link>http://arxiv.org/abs/2402.10802v3</link><description>Time series anomaly detection (TSAD) has gained significant attention due toits real-world applications to improve the stability of modern softwaresystems. However, there is no effective way to verify whether they can meet therequirements for real-world deployment. Firstly, current algorithms typicallytrain a specific model for each time series. Maintaining such many models isimpractical in a large-scale system with tens of thousands of curves. Theperformance of using merely one unified model to detect anomalies remainsunknown. Secondly, most TSAD models are trained on the historical part of atime series and are tested on its future segment. In distributed systems,however, there are frequent system deployments and upgrades, with new,previously unseen time series emerging daily. The performance of testing newlyincoming unseen time series on current TSAD algorithms remains unknown. Lastly,the assumptions of the evaluation metrics in existing benchmarks are far frompractical demands. To solve the above-mentioned problems, we propose anindustrial-grade benchmark TimeSeriesBench. We assess the performance ofexisting algorithms across more than 168 evaluation settings and providecomprehensive analysis for the future design of anomaly detection algorithms.An industrial dataset is also released along with TimeSeriesBench.</description><author>Haotian Si, Jianhui Li, Changhua Pei, Hang Cui, Jingwen Yang, Yongqian Sun, Shenglin Zhang, Jingjing Li, Haiming Zhang, Jing Han, Dan Pei, Gaogang Xie</author><pubDate>Tue, 03 Sep 2024 02:37:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10802v3</guid></item><item><title>Investigating Recurrent Transformers with Dynamic Halt</title><link>http://arxiv.org/abs/2402.00976v3</link><description>In this paper, we comprehensively study the inductive biases of two majorapproaches to augmenting Transformers with a recurrent mechanism: (1) theapproach of incorporating a depth-wise recurrence similar to UniversalTransformers; and (2) the approach of incorporating a chunk-wise temporalrecurrence like Temporal Latent Bottleneck. Furthermore, we propose andinvestigate novel ways to extend and combine the above methods - for example,we propose a global mean-based dynamic halting mechanism for UniversalTransformers and an augmentation of Temporal Latent Bottleneck with elementsfrom Universal Transformer. We compare the models and probe their inductivebiases in several diagnostic tasks, such as Long Range Arena (LRA), flip-floplanguage modeling, ListOps, and Logical Inference. The code is released in:https://github.com/JRC1995/InvestigatingRecurrentTransformers/tree/main</description><author>Jishnu Ray Chowdhury, Cornelia Caragea</author><pubDate>Tue, 03 Sep 2024 02:35:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00976v3</guid></item><item><title>OccamLLM: Fast and Exact Language Model Arithmetic in a Single Step</title><link>http://arxiv.org/abs/2406.06576v4</link><description>Despite significant advancements in text generation and reasoning, LargeLanguage Models (LLMs) still face challenges in accurately performing complexarithmetic operations. Language model systems often enable LLMs to generatecode for arithmetic operations to achieve accurate calculations. However, thisapproach compromises speed and security, and fine-tuning risks the languagemodel losing prior capabilities. We propose a framework that enables exactarithmetic in a single autoregressive step, providing faster, more secure, andmore interpretable LLM systems with arithmetic capabilities. We use the hiddenstates of a LLM to control a symbolic architecture that performs arithmetic.Our implementation using Llama 3 with OccamNet as a symbolic model (OccamLlama)achieves 100\% accuracy on single arithmetic operations($+,-,\times,\div,\sin{},\cos{},\log{},\exp{},\sqrt{}$), outperforming GPT 4owith and without a code interpreter. Furthermore, OccamLlama outperforms GPT 4owith and without a code interpreter on average across a range of mathematicalproblem solving benchmarks, demonstrating that OccamLLMs can excel inarithmetic tasks, even surpassing much larger models. We will make our codepublic shortly.</description><author>Owen Dugan, Donato Manuel Jimenez Beneto, Charlotte Loh, Zhuo Chen, Rumen Dangovski, Marin Soljačić</author><pubDate>Tue, 03 Sep 2024 02:11:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06576v4</guid></item><item><title>Flood of Techniques and Drought of Theories: Emotion Mining in Disasters</title><link>http://arxiv.org/abs/2407.05219v3</link><description>Emotion mining has become a crucial tool for understanding human emotionsduring disasters, leveraging the extensive data generated on social mediaplatforms. This paper aims to summarize existing research on emotion miningwithin disaster contexts, highlighting both significant discoveries andpersistent issues. On the one hand, emotion mining techniques have achievedacceptable accuracy enabling applications such as rapid damage assessment andmental health surveillance. On the other hand, with many studies adoptingdata-driven approaches, several methodological issues remain. These includearbitrary emotion classification, ignoring biases inherent in data collectionfrom social media, such as the overrepresentation of individuals from highersocioeconomic status on Twitter, and the lack of application of theoreticalframeworks like cross-cultural comparisons. These problems can be summarized asa notable lack of theory-driven research and ignoring insights from social andbehavioral sciences. This paper underscores the need for interdisciplinarycollaboration between computer scientists and social scientists to develop morerobust and theoretically grounded approaches in emotion mining. By addressingthese gaps, we aim to enhance the effectiveness and reliability of emotionmining methodologies, ultimately contributing to improved disasterpreparedness, response, and recovery. Keywords: emotion mining, sentiment analysis, natural disasters, psychology,technological disasters</description><author>Soheil Shapouri, Saber Soleymani, Saed Rezayi</author><pubDate>Tue, 03 Sep 2024 02:10:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05219v3</guid></item><item><title>The Impact of Print-Scanning in Heterogeneous Morph Evaluation Scenarios</title><link>http://arxiv.org/abs/2404.06559v2</link><description>Face morphing attacks pose an increasing threat to face recognition (FR)systems. A morphed photo contains biometric information from two differentsubjects to take advantage of vulnerabilities in FRs. These systems areparticularly susceptible to attacks when the morphs are subjected toprint-scanning to mask the artifacts generated during the morphing process. Weinvestigate the impact of print-scanning on morphing attack detection through aseries of evaluations on heterogeneous morphing attack scenarios. Ourexperiments show that we can increase the Mated Morph Presentation Match Rate(MMPMR) by up to 8.48%. Furthermore, when a Single-image Morphing AttackDetection (S-MAD) algorithm is not trained to detect print-scanned morphs theMorphing Attack Classification Error Rate (MACER) can increase by up to 96.12%,indicating significant vulnerability.</description><author>Richard E. Neddo, Zander W. Blasingame, Chen Liu</author><pubDate>Tue, 03 Sep 2024 01:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06559v2</guid></item><item><title>AIGCs Confuse AI Too: Investigating and Explaining Synthetic Image-induced Hallucinations in Large Vision-Language Models</title><link>http://arxiv.org/abs/2403.08542v2</link><description>The evolution of Artificial Intelligence Generated Contents (AIGCs) isadvancing towards higher quality. The growing interactions with AIGCs present anew challenge to the data-driven AI community: While AI-generated contents haveplayed a crucial role in a wide range of AI models, the potential hidden risksthey introduce have not been thoroughly examined. Beyond human-oriented forgerydetection, AI-generated content poses potential issues for AI models originallydesigned to process natural data. In this study, we underscore the exacerbatedhallucination phenomena in Large Vision-Language Models (LVLMs) caused byAI-synthetic images. Remarkably, our findings shed light on a consistent AIGC\textbf{hallucination bias}: the object hallucinations induced by syntheticimages are characterized by a greater quantity and a more uniform positiondistribution, even these synthetic images do not manifest unrealistic oradditional relevant visual features compared to natural images. Moreover, ourinvestigations on Q-former and Linear projector reveal that synthetic imagesmay present token deviations after visual projection, thereby amplifying thehallucination bias.</description><author>Yifei Gao, Jiaqi Wang, Zhiyu Lin, Jitao Sang</author><pubDate>Tue, 03 Sep 2024 01:53:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08542v2</guid></item><item><title>Enhancing Representation in Radiography-Reports Foundation Model: A Granular Alignment Algorithm Using Masked Contrastive Learning</title><link>http://arxiv.org/abs/2309.05904v3</link><description>Recently, multi-modal vision-language foundation models have gainedsignificant attention in the medical field. While these models offer greatopportunities, they still face crucial challenges, such as the requirement forfine-grained knowledge understanding in computer-aided diagnosis and thecapability of utilizing very limited or even no task-specific labeled data inreal-world clinical applications. In this study, we present MaCo, a maskedcontrastive chest X-ray foundation model that tackles these challenges. MaCoexplores masked contrastive learning to simultaneously achieve fine-grainedimage understanding and zero-shot learning for a variety of medical imagingtasks. It designs a correlation weighting mechanism to adjust the correlationbetween masked chest X-ray image patches and their corresponding reports,thereby enhancing the model's representation learning capabilities. To evaluatethe performance of MaCo, we conducted extensive experiments using 6 well-knownopen-source X-ray datasets. The experimental results demonstrate thesuperiority of MaCo over 10 state-of-the-art approaches across tasks such asclassification, segmentation, detection, and phrase grounding. These findingshighlight the significant potential of MaCo in advancing a wide range ofmedical image analysis tasks.</description><author>Weijian Huang, Cheng Li, Hong-Yu Zhou, Hao Yang, Jiarun Liu, Yong Liang, Hairong Zheng, Shaoting Zhang, Shanshan Wang</author><pubDate>Tue, 03 Sep 2024 01:40:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.05904v3</guid></item><item><title>How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments</title><link>http://arxiv.org/abs/2403.11807v3</link><description>Decision-making, a complicated task requiring various types of abilities,presents an excellent framework for assessing Large Language Models (LLMs). Ourresearch investigates decision-making capabilities of LLMs through the lens ofGame Theory. We focus specifically on games that support the simultaneousparticipation of more than two agents. We introduce GAMA($\gamma$)-Bench, whichevaluates LLMs' Gaming Ability in Multi-Agent environments. $\gamma$-Benchincludes eight classical multi-agent games and a scoring scheme speciallydesigned to quantitatively assess LLMs' performance. Leveraging $\gamma$-Bench,we investigate LLMs' robustness, generalizability, and strategies forenhancement. Results reveal that while GPT-3.5 shows satisfying robustness, itsgeneralizability is relatively limited. However, its performance can beimproved through approaches such as Chain-of-Thought. Additionally, we evaluatetwelve versions from six models, including GPT-3.5, GPT-4, Gemini, LLaMA-3.1,Mixtral, and Qwen-2. We find that Gemini-1.5-Pro outperforms other models witha score of $63.8$ out of $100$, followed by LLaMA-3.1-70B and GPT-4 with scoresof $60.9$ and $60.5$, respectively. The code and experimental results are madepublicly available via https://github.com/CUHK-ARISE/GAMABench.</description><author>Jen-tse Huang, Eric John Li, Man Ho Lam, Tian Liang, Wenxuan Wang, Youliang Yuan, Wenxiang Jiao, Xing Wang, Zhaopeng Tu, Michael R. Lyu</author><pubDate>Tue, 03 Sep 2024 01:14:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11807v3</guid></item><item><title>MPruner: Optimizing Neural Network Size with CKA-Based Mutual Information Pruning</title><link>http://arxiv.org/abs/2408.13482v2</link><description>Determining the optimal size of a neural network is critical, as it directlyimpacts runtime performance and memory usage. Pruning is a well-establishedmodel compression technique that reduces the size of neural networks whilemathematically guaranteeing accuracy preservation. However, many recent pruningmethods overlook the global contributions of individual model components,making it difficult to ensure that a pruned model meets the desired dataset andperformance requirements. To address these challenges, we developed a newpruning algorithm, MPruner, that leverages mutual information through vectorsimilarity. MPruner utilizes layer clustering with the Centered KernelAlignment (CKA) similarity metric, allowing us to incorporate globalinformation from the neural network for more precise and efficient layer-wisepruning. We evaluated MPruner across various architectures and configurations,demonstrating its versatility and providing practical guidelines. MPrunerachieved up to a 50% reduction in parameters and memory usage for CNN andtransformer-based models, with minimal to no loss in accuracy.</description><author>Seungbeom Hu, ChanJun Park, Andrew Ferraiuolo, Sang-Ki Ko, Jinwoo Kim, Haein Song, Jieung Kim</author><pubDate>Tue, 03 Sep 2024 00:48:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13482v2</guid></item><item><title>Advanced Predictive Modeling for Enhanced Mortality Prediction in ICU Stroke Patients Using Clinical Data</title><link>http://arxiv.org/abs/2407.14211v2</link><description>Background: Stroke is second-leading cause of disability and death amongadults. Approximately 17 million people suffer from a stroke annually, withabout 85% being ischemic strokes. Predicting mortality of ischemic strokepatients in intensive care unit (ICU) is crucial for optimizing treatmentstrategies, allocating resources, and improving survival rates. Methods: Weacquired data on ICU ischemic stroke patients from MIMIC-IV database, includingdiagnoses, vital signs, laboratory tests, medications, procedures, treatments,and clinical notes. Stroke patients were randomly divided into training (70%,n=2441), test (15%, n=523), and validation (15%, n=523) sets. To address dataimbalances, we applied Synthetic Minority Over-sampling Technique (SMOTE). Weselected 30 features for model development, significantly reducing featurenumber from 1095 used in the best study. We developed a deep learning model toassess mortality risk and implemented several baseline machine learning modelsfor comparison. Results: XGB-DL model, combining XGBoost for feature selectionand deep learning, effectively minimized false positives. Model's AUROCimproved from 0.865 (95% CI: 0.821 - 0.905) on first day to 0.903 (95% CI:0.868 - 0.936) by fourth day using data from 3,646 ICU mortality patients inthe MIMIC-IV database with 0.945 AUROC (95% CI: 0.944 - 0.947) during training.Although other ML models also performed well in terms of AUROC, we chose DeepLearning for its higher specificity. Conclusions: Through enhanced featureselection and data cleaning, proposed model demonstrates a 13% AUROCimprovement compared to existing models while reducing feature number from 1095in previous studies to 30.</description><author>Armin Abdollahi, Negin Ashrafi, Maryam Pishgar</author><pubDate>Mon, 02 Sep 2024 23:41:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14211v2</guid></item><item><title>PhysORD: A Neuro-Symbolic Approach for Physics-infused Motion Prediction in Off-road Driving</title><link>http://arxiv.org/abs/2404.01596v2</link><description>Motion prediction is critical for autonomous off-road driving, however, itpresents significantly more challenges than on-road driving because of thecomplex interaction between the vehicle and the terrain. Traditionalphysics-based approaches encounter difficulties in accurately modeling dynamicsystems and external disturbance. In contrast, data-driven neural networksrequire extensive datasets and struggle with explicitly capturing thefundamental physical laws, which can easily lead to poor generalization. Bymerging the advantages of both methods, neuro-symbolic approaches present apromising direction. These methods embed physical laws into neural models,potentially significantly improving generalization capabilities. However, noprior works were evaluated in real-world settings for off-road driving. Tobridge this gap, we present PhysORD, a neural-symbolic approach integrating theconservation law, i.e., the Euler-Lagrange equation, into data-driven neuralmodels for motion prediction in off-road driving. Our experiments showed thatPhysORD can accurately predict vehicle motion and tolerate external disturbanceby modeling uncertainties. It outperforms existing methods both in accuracy andefficiency and demonstrates data-efficient learning and generalization abilityin long-term prediction.</description><author>Zhipeng Zhao, Bowen Li, Yi Du, Taimeng Fu, Chen Wang</author><pubDate>Mon, 02 Sep 2024 23:35:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01596v2</guid></item><item><title>Inter-Frame Compression for Dynamic Point Cloud Geometry Coding</title><link>http://arxiv.org/abs/2207.12554v2</link><description>Efficient point cloud compression is essential for applications like virtualand mixed reality, autonomous driving, and cultural heritage. This paperproposes a deep learning-based inter-frame encoding scheme for dynamic pointcloud geometry compression. We propose a lossy geometry compression scheme thatpredicts the latent representation of the current frame using the previousframe by employing a novel feature space inter-prediction network. The proposednetwork utilizes sparse convolutions with hierarchical multiscale 3D featurelearning to encode the current frame using the previous frame. The proposedmethod introduces a novel predictor network for motion compensation in thefeature domain to map the latent representation of the previous frame to thecoordinates of the current frame to predict the current frame's featureembedding. The framework transmits the residual of the predicted features andthe actual features by compressing them using a learned probabilisticfactorized entropy model. At the receiver, the decoder hierarchicallyreconstructs the current frame by progressively rescaling the featureembedding. The proposed framework is compared to the state-of-the-artVideo-based Point Cloud Compression (V-PCC) and Geometry-based Point CloudCompression (G-PCC) schemes standardized by the Moving Picture Experts Group(MPEG). The proposed method achieves more than 88% BD-Rate (Bjontegaard DeltaRate) reduction against G-PCCv20 Octree, more than 56% BD-Rate savings againstG-PCCv20 Trisoup, more than 62% BD-Rate reduction against V-PCC intra-frameencoding mode, and more than 52% BD-Rate savings against V-PCC P-frame-basedinter-frame encoding mode using HEVC. These significant performance gains arecross-checked and verified in the MPEG working group.</description><author>Anique Akhtar, Zhu Li, Geert Van der Auwera</author><pubDate>Mon, 02 Sep 2024 22:49:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.12554v2</guid></item><item><title>AlphaFold Meets Flow Matching for Generating Protein Ensembles</title><link>http://arxiv.org/abs/2402.04845v2</link><description>The biological functions of proteins often depend on dynamic structuralensembles. In this work, we develop a flow-based generative modeling approachfor learning and sampling the conformational landscapes of proteins. Werepurpose highly accurate single-state predictors such as AlphaFold and ESMFoldand fine-tune them under a custom flow matching framework to obtainsequence-conditoned generative models of protein structure called AlphaFlow andESMFlow. When trained and evaluated on the PDB, our method provides a superiorcombination of precision and diversity compared to AlphaFold with MSAsubsampling. When further trained on ensembles from all-atom MD, our methodaccurately captures conformational flexibility, positional distributions, andhigher-order ensemble observables for unseen proteins. Moreover, our method candiversify a static PDB structure with faster wall-clock convergence to certainequilibrium properties than replicate MD trajectories, demonstrating itspotential as a proxy for expensive physics-based simulations. Code is availableat https://github.com/bjing2016/alphaflow.</description><author>Bowen Jing, Bonnie Berger, Tommi Jaakkola</author><pubDate>Mon, 02 Sep 2024 22:43:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04845v2</guid></item><item><title>Dissociation of Faithful and Unfaithful Reasoning in LLMs</title><link>http://arxiv.org/abs/2405.15092v2</link><description>Large language models (LLMs) often improve their performance in downstreamtasks when they generate Chain of Thought reasoning text before producing ananswer. We investigate how LLMs recover from errors in Chain of Thought.Through analysis of error recovery behaviors, we find evidence forunfaithfulness in Chain of Thought, which occurs when models arrive at thecorrect answer despite invalid reasoning text. We identify factors that shiftLLM recovery behavior: LLMs recover more frequently from obvious errors and incontexts that provide more evidence for the correct answer. Critically, thesefactors have divergent effects on faithful and unfaithful recoveries. Ourresults indicate that there are distinct mechanisms driving faithful andunfaithful error recoveries. Selective targeting of these mechanisms may beable to drive down the rate of unfaithful reasoning and improve modelinterpretability.</description><author>Evelyn Yee, Alice Li, Chenyu Tang, Yeon Ho Jung, Ramamohan Paturi, Leon Bergen</author><pubDate>Mon, 02 Sep 2024 22:40:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15092v2</guid></item><item><title>Automatic Differentiation is Essential in Training Neural Networks for Solving Differential Equations</title><link>http://arxiv.org/abs/2405.14099v3</link><description>Neural network-based approaches have recently shown significant promise insolving partial differential equations (PDEs) in science and engineering,especially in scenarios featuring complex domains or incorporation of empiricaldata. One advantage of the neural network methods for PDEs lies in itsautomatic differentiation (AD), which necessitates only the sample pointsthemselves, unlike traditional finite difference (FD) approximations thatrequire nearby local points to compute derivatives. In this paper, wequantitatively demonstrate the advantage of AD in training neural networks. Theconcept of truncated entropy is introduced to characterize the trainingproperty. Specifically, through comprehensive experimental and theoreticalanalyses conducted on random feature models and two-layer neural networks, wediscover that the defined truncated entropy serves as a reliable metric forquantifying the residual loss of random feature models and the training speedof neural networks for both AD and FD methods. Our experimental and theoreticalanalyses demonstrate that, from a training perspective, AD outperforms FD insolving PDEs.</description><author>Chuqi Chen, Yahong Yang, Yang Xiang, Wenrui Hao</author><pubDate>Mon, 02 Sep 2024 21:40:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14099v3</guid></item><item><title>SEDMamba: Enhancing Selective State Space Modelling with Bottleneck Mechanism and Fine-to-Coarse Temporal Fusion for Efficient Error Detection in Robot-Assisted Surgery</title><link>http://arxiv.org/abs/2406.15920v2</link><description>Automated detection of surgical errors can improve robotic-assisted surgery.Despite promising progress, existing methods still face challenges in capturingrich temporal context to establish long-term dependencies while maintainingcomputational efficiency. In this paper, we propose a novel hierarchical modelnamed SEDMamba, which incorporates the selective state space model (SSM) intosurgical error detection, facilitating efficient long sequence modelling withlinear complexity. SEDMamba enhances selective SSM with a bottleneck mechanismand fine-to-coarse temporal fusion (FCTF) to detect and temporally localizesurgical errors in long videos. The bottleneck mechanism compresses andrestores features within their spatial dimension, thereby reducingcomputational complexity. FCTF utilizes multiple dilated 1D convolutionallayers to merge temporal information across diverse scale ranges, accommodatingerrors of varying duration. Our work also contributes the first-of-its-kind,frame-level, in-vivo surgical error dataset to support error detection in realsurgical cases. Specifically, we deploy the clinically validated observationalclinical human reliability assessment tool (OCHRA) to annotate the errorsduring suturing tasks in an open-source radical prostatectomy dataset(SAR-RARP50). Experimental results demonstrate that our SEDMamba outperformsstate-of-the-art methods with at least 1.82% AUC and 3.80% AP performance gainswith significantly reduced computational complexity. The corresponding errorannotations, code and models will be released athttps://github.com/wzjialang/SEDMamba.</description><author>Jialang Xu, Nazir Sirajudeen, Matthew Boal, Nader Francis, Danail Stoyanov, Evangelos Mazomenos</author><pubDate>Mon, 02 Sep 2024 21:35:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15920v2</guid></item><item><title>Manipulating Large Language Models to Increase Product Visibility</title><link>http://arxiv.org/abs/2404.07981v2</link><description>Large language models (LLMs) are increasingly being integrated into searchengines to provide natural language responses tailored to user queries.Customers and end-users are also becoming more dependent on these models forquick and easy purchase decisions. In this work, we investigate whetherrecommendations from LLMs can be manipulated to enhance a product's visibility.We demonstrate that adding a strategic text sequence (STS) -- a carefullycrafted message -- to a product's information page can significantly increaseits likelihood of being listed as the LLM's top recommendation. To understandthe impact of STS, we use a catalog of fictitious coffee machines and analyzeits effect on two target products: one that seldom appears in the LLM'srecommendations and another that usually ranks second. We observe that thestrategic text sequence significantly enhances the visibility of both productsby increasing their chances of appearing as the top recommendation. Thisability to manipulate LLM-generated search responses provides vendors with aconsiderable competitive advantage and has the potential to disrupt fair marketcompetition. Just as search engine optimization (SEO) revolutionized howwebpages are customized to rank higher in search engine results, influencingLLM recommendations could profoundly impact content optimization for AI-drivensearch services. Code for our experiments is available athttps://github.com/aounon/llm-rank-optimizer.</description><author>Aounon Kumar, Himabindu Lakkaraju</author><pubDate>Mon, 02 Sep 2024 21:29:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07981v2</guid></item><item><title>On the limits of neural network explainability via descrambling</title><link>http://arxiv.org/abs/2301.07820v3</link><description>We characterize the exact solutions to neural network descrambling--amathematical model for explaining the fully connected layers of trained neuralnetworks (NNs). By reformulating the problem to the minimization of theBrockett function arising in graph matching and complexity theory we show thatthe principal components of the hidden layer preactivations can becharacterized as the optimal explainers or descramblers for the layer weights,leading to descrambled weight matrices. We show that in typical deep learningcontexts these descramblers take diverse and interesting forms including (1)matching largest principal components with the lowest frequency modes of theFourier basis for isotropic hidden data, (2) discovering the semanticdevelopment in two-layer linear NNs for signal recovery problems, and (3)explaining CNNs by optimally permuting the neurons. Our numerical experimentsindicate that the eigendecompositions of the hidden layer data--now understoodas the descramblers--can also reveal the layer's underlying transformation.These results illustrate that the SVD is more directly related to theexplainability of NNs than previously thought and offers a promising avenue fordiscovering interpretable motifs for the hidden action of NNs, especially incontexts of operator learning or physics-informed NNs, where the input/outputdata has limited human readability.</description><author>Shashank Sule, Richard G. Spencer, Wojciech Czaja</author><pubDate>Mon, 02 Sep 2024 21:17:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.07820v3</guid></item><item><title>Efficient Video Object Segmentation via Modulated Cross-Attention Memory</title><link>http://arxiv.org/abs/2403.17937v2</link><description>Recently, transformer-based approaches have shown promising results forsemi-supervised video object segmentation. However, these approaches typicallystruggle on long videos due to increased GPU memory demands, as they frequentlyexpand the memory bank every few frames. We propose a transformer-basedapproach, named MAVOS, that introduces an optimized and dynamic long-termmodulated cross-attention (MCA) memory to model temporal smoothness withoutrequiring frequent memory expansion. The proposed MCA effectively encodes bothlocal and global features at various levels of granularity while efficientlymaintaining consistent speed regardless of the video length. Extensiveexperiments on multiple benchmarks, LVOS, Long-Time Video, and DAVIS 2017,demonstrate the effectiveness of our proposed contributions leading toreal-time inference and markedly reduced memory demands without any degradationin segmentation accuracy on long videos. Compared to the best existingtransformer-based approach, our MAVOS increases the speed by 7.6x, whilesignificantly reducing the GPU memory by 87% with comparable segmentationperformance on short and long video datasets. Notably on the LVOS dataset, ourMAVOS achieves a J&amp;F score of 63.3% while operating at 37 frames per second(FPS) on a single V100 GPU. Our code and models will be publicly available at:https://github.com/Amshaker/MAVOS.</description><author>Abdelrahman Shaker, Syed Talal Wasim, Martin Danelljan, Salman Khan, Ming-Hsuan Yang, Fahad Shahbaz Khan</author><pubDate>Mon, 02 Sep 2024 20:58:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17937v2</guid></item><item><title>MAP: Low-compute Model Merging with Amortized Pareto Fronts via Quadratic Approximation</title><link>http://arxiv.org/abs/2406.07529v3</link><description>Model merging has emerged as an effective approach to combine multiplesingle-task models, fine-tuned from the same pre-trained model, into amultitask model. This process typically involves computing a weighted averageof the model parameters without any additional training. Existing model-mergingmethods focus on enhancing average task accuracy. However, interference andconflicts between the objectives of different tasks can lead to trade-offsduring model merging. In real-world applications, a set of solutions withvarious trade-offs can be more informative, helping practitioners makedecisions based on diverse preferences. In this paper, we introduce a novellow-compute algorithm, Model Merging with Amortized Pareto Front (MAP). MAPidentifies a Pareto set of scaling coefficients for merging multiple models toreflect the trade-offs. The core component of MAP is approximating theevaluation metrics of the various tasks using a quadratic approximationsurrogate model derived from a pre-selected set of scaling coefficients,enabling amortized inference. Experimental results on vision and naturallanguage processing tasks show that MAP can accurately identify the Paretofront. To further reduce the required computation of MAP, we propose (1) aBayesian adaptive sampling algorithm and (2) a nested merging scheme withmultiple stages.</description><author>Lu Li, Tianyu Zhang, Zhiqi Bu, Suyuchen Wang, Huan He, Jie Fu, Yonghui Wu, Jiang Bian, Yong Chen, Yoshua Bengio</author><pubDate>Mon, 02 Sep 2024 20:42:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07529v3</guid></item><item><title>RISSOLE: Parameter-efficient Diffusion Models via Block-wise Generation and Retrieval-Guidance</title><link>http://arxiv.org/abs/2408.17095v2</link><description>Diffusion-based models demonstrate impressive generation capabilities.However, they also have a massive number of parameters, resulting in enormousmodel sizes, thus making them unsuitable for deployment on resource-constraintdevices. Block-wise generation can be a promising alternative for designingcompact-sized (parameter-efficient) deep generative models since the model cangenerate one block at a time instead of generating the whole image at once.However, block-wise generation is also considerably challenging becauseensuring coherence across generated blocks can be non-trivial. To this end, wedesign a retrieval-augmented generation (RAG) approach and leverage thecorresponding blocks of the images retrieved by the RAG module to condition thetraining and generation stages of a block-wise denoising diffusion model. Ourconditioning schemes ensure coherence across the different blocks duringtraining and, consequently, during generation. While we showcase our approachusing the latent diffusion model (LDM) as the base model, it can be used withother variants of denoising diffusion models. We validate the solution of thecoherence problem through the proposed approach by reporting substantiveexperiments to demonstrate our approach's effectiveness in compact model sizeand excellent generation quality.</description><author>Avideep Mukherjee, Soumya Banerjee, Piyush Rai, Vinay P. Namboodiri</author><pubDate>Mon, 02 Sep 2024 20:33:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.17095v2</guid></item><item><title>Balancing Rigor and Utility: Mitigating Cognitive Biases in Large Language Models for Multiple-Choice Questions</title><link>http://arxiv.org/abs/2406.10999v2</link><description>This paper examines the role of cognitive biases in the decision-makingprocesses of large language models (LLMs), challenging the conventional goal ofeliminating all biases. We show that certain cognitive biases when properlybalanced, can enhance decision-making efficiency through rational deviationsand heuristic shortcuts. By introducing heuristic moderation and an abstentionoption, which allows LLMs to withhold responses when uncertain, we reduce errorrates, improve decision accuracy, and optimize decision rates. Using theBalance Rigor and Utility (BRU) dataset, developed through expertcollaboration, our findings demonstrate that targeted inspection of cognitivebiases aligns LLM decisions more closely with human reasoning, enhancingreliability and suggesting strategies for future improvements. This approachoffers a novel way to leverage cognitive biases to improve the practicalutility of LLMs across various applications.</description><author>Liman Wang, Hanyang Zhong</author><pubDate>Mon, 02 Sep 2024 20:26:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10999v2</guid></item><item><title>On the Impacts of Contexts on Repository-Level Code Generation</title><link>http://arxiv.org/abs/2406.11927v3</link><description>CodeLLMs have gained widespread adoption for code generation tasks, yet theircapacity to handle repository-level code generation with complex contextualdependencies remains underexplored. Our work underscores the criticalimportance of leveraging repository-level contexts to generate executable andfunctionally correct code. We present \textbf{\methodnamews}, a novel benchmarkdesigned to evaluate repository-level code generation, with a focus on threekey aspects: executability, functional correctness through comprehensive testcase generation, and accurate utilization of cross-file contexts. Our studyexamines a controlled scenario where developers specify essential codedependencies (contexts), challenging models to integrate them effectively.Additionally, we introduce an instruction-tuned dataset that enhances CodeLLMs'ability to leverage dependencies, along with a new metric, \textit{DependencyInvocation Rate (DIR)}, to quantify context utilization. Experimental resultsreveal that while pretrained LLMs demonstrate superior performance in terms ofcorrectness, instruction-tuned models excel in context utilization anddebugging capabilities. \methodnamews offers a comprehensive evaluationframework for assessing code functionality and alignment with developer intent,thereby advancing the development of more reliable CodeLLMs for real-worldapplications. The dataset and source code are availableat~\url{https://github.com/FSoft-AI4Code/RepoExec}.</description><author>Nam Le Hai, Dung Manh Nguyen, Nghi D. Q. Bui</author><pubDate>Mon, 02 Sep 2024 20:26:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11927v3</guid></item><item><title>Eliciting Informative Text Evaluations with Large Language Models</title><link>http://arxiv.org/abs/2405.15077v4</link><description>Peer prediction mechanisms motivate high-quality feedback with provableguarantees. However, current methods only apply to rather simple reports, likemultiple-choice or scalar numbers. We aim to broaden these techniques to thelarger domain of text-based reports, drawing on the recent developments inlarge language models. This vastly increases the applicability of peerprediction mechanisms as textual feedback is the norm in a large variety offeedback channels: peer reviews, e-commerce customer reviews, and comments onsocial media. We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM)and the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanismsutilize LLMs as predictors, mapping from one agent's report to a prediction ofher peer's report. Theoretically, we show that when the LLM prediction issufficiently accurate, our mechanisms can incentivize high effort andtruth-telling as an (approximate) Bayesian Nash equilibrium. Empirically, weconfirm the efficacy of our mechanisms through experiments conducted on tworeal datasets: the Yelp review dataset and the ICLR OpenReview dataset. Wehighlight the results that on the ICLR dataset, our mechanisms candifferentiate three quality levels -- human-written reviews, GPT-4-generatedreviews, and GPT-3.5-generated reviews in terms of expected scores.Additionally, GSPPM penalizes LLM-generated reviews more effectively than GPPM.</description><author>Yuxuan Lu, Shengwei Xu, Yichi Zhang, Yuqing Kong, Grant Schoenebeck</author><pubDate>Mon, 02 Sep 2024 20:25:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15077v4</guid></item><item><title>Uplift Modeling Under Limited Supervision</title><link>http://arxiv.org/abs/2403.19289v4</link><description>Estimating causal effects in e-commerce tends to involve costly treatmentassignments which can be impractical in large-scale settings. Leveragingmachine learning to predict such treatment effects without actual interventionis a standard practice to diminish the risk. However, existing methods fortreatment effect prediction tend to rely on training sets of substantial size,which are built from real experiments and are thus inherently risky to create.In this work we propose a graph neural network to diminish the requiredtraining set size, relying on graphs that are common in e-commerce data.Specifically, we view the problem as node regression with a restricted numberof labeled instances, develop a two-model neural architecture akin to previouscausal effect estimators, and test varying message-passing layers for encoding.Furthermore, as an extra step, we combine the model with an acquisitionfunction to guide the creation of the training set in settings with extremelylow experimental budget. The framework is flexible since each step can be usedseparately with other models or treatment policies. The experiments on reallarge-scale networks indicate a clear advantage of our methodology over thestate of the art, which in many cases performs close to random, underlining theneed for models that can generalize with limited supervision to reduceexperimental risks.</description><author>George Panagopoulos, Daniele Malitesta, Fragkiskos D. Malliaros, Jun Pang</author><pubDate>Mon, 02 Sep 2024 20:21:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19289v4</guid></item><item><title>Multi-Visual-Inertial System: Analysis, Calibration and Estimation</title><link>http://arxiv.org/abs/2308.05303v4</link><description>In this paper, we study state estimation of multi-visual-inertial systems(MVIS) and develop sensor fusion algorithms to optimally fuse an arbitrarynumber of asynchronous inertial measurement units (IMUs) or gyroscopes andglobal and(or) rolling shutter cameras. We are especially interested in thefull calibration of the associated visual-inertial sensors, including the IMUor camera intrinsics and the IMU-IMU(or camera) spatiotemporal extrinsics aswell as the image readout time of rolling-shutter cameras (if used). To thisend, we develop a new analytic combined IMU integration with intrinsics-termedACI3-to preintegrate IMU measurements, which is leveraged to fuse auxiliaryIMUs and(or) gyroscopes alongside a base IMU. We model the multi-inertialmeasurements to include all the necessary inertial intrinsic and IMU-IMUspatiotemporal extrinsic parameters, while leveraging IMU-IMU rigid-bodyconstraints to eliminate the necessity of auxiliary inertial poses and thusreducing computational complexity. By performing observability analysis ofMVIS, we prove that the standard four unobservable directions remain - nomatter how many inertial sensors are used, and also identify, for the firsttime, degenerate motions for IMU-IMU spatiotemporal extrinsics and auxiliaryinertial intrinsics. In addition to the extensive simulations that validate ouranalysis and algorithms, we have built our own MVIS sensor rig and collectedover 25 real-world datasets to experimentally verify the proposed calibrationagainst the state-of-the-art calibration method such as Kalibr. We show thatthe proposed MVIS calibration is able to achieve competing accuracy withimproved convergence and repeatability, which is open sourced to better benefitthe community.</description><author>Yulin Yang, Patrick Geneva, Guoquan Huang</author><pubDate>Mon, 02 Sep 2024 19:49:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05303v4</guid></item><item><title>On Evaluating Adversarial Robustness of Volumetric Medical Segmentation Models</title><link>http://arxiv.org/abs/2406.08486v2</link><description>Volumetric medical segmentation models have achieved significant success onorgan and tumor-based segmentation tasks in recent years. However, theirvulnerability to adversarial attacks remains largely unexplored, raisingserious concerns regarding the real-world deployment of tools employing suchmodels in the healthcare sector. This underscores the importance ofinvestigating the robustness of existing models. In this context, our work aimsto empirically examine the adversarial robustness across current volumetricsegmentation architectures, encompassing Convolutional, Transformer, andMamba-based models. We extend this investigation across four volumetricsegmentation datasets, evaluating robustness under both white box and black boxadversarial attacks. Overall, we observe that while both pixel andfrequency-based attacks perform reasonably well under \emph{white box} setting,the latter performs significantly better under transfer-based black boxattacks. Across our experiments, we observe transformer-based models showhigher robustness than convolution-based models with Mamba-based models beingthe most vulnerable. Additionally, we show that large-scale training ofvolumetric segmentation models improves the model's robustness againstadversarial attacks. The code and robust models are available athttps://github.com/HashmatShadab/Robustness-of-Volumetric-Medical-Segmentation-Models.</description><author>Hashmat Shadab Malik, Numan Saeed, Asif Hanif, Muzammal Naseer, Mohammad Yaqub, Salman Khan, Fahad Shahbaz Khan</author><pubDate>Mon, 02 Sep 2024 19:04:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08486v2</guid></item><item><title>Into the Unknown: Self-Learning Large Language Models</title><link>http://arxiv.org/abs/2402.09147v3</link><description>We address the main problem of self-learning LLM: the question of what tolearn. We propose a self-learning LLM framework that enables an LLM toindependently learn previously unknown knowledge through self-assessment oftheir own hallucinations. We introduce a concept called Point in the Unknown(PiU) to identify atomic knowledge unknown to a model, along with four methodsfor automatic PiUs identification, facilitating the creation of a self-learningloop that focuses exclusively on the absorption of currently unknown knowledgeinto the model. Additionally, we developed evaluation metrics to gauge an LLM'sself-learning capability. Our experiments revealed that LLMs with at least 3Bparameters that have undergone some instruction training would be able toperform self-learning well. We further proved the effectiveness ofself-learning by comparing the performance of a model that has undergoneself-learning to a model that has not. Our self-learning concept allows moreefficient LLM updates and opens new perspectives for LLM knowledge exchange.</description><author>Teddy Ferdinan, Jan Kocoń, Przemysław Kazienko</author><pubDate>Mon, 02 Sep 2024 19:01:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09147v3</guid></item></channel></rss>