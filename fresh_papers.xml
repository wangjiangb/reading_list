<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 28 Jan 2025 01:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>HERMES: A Unified Self-Driving World Model for Simultaneous 3D Scene Understanding and Generation</title><link>http://arxiv.org/abs/2501.14729v1</link><description>Driving World Models (DWMs) have become essential for autonomous driving byenabling future scene prediction. However, existing DWMs are limited to scenegeneration and fail to incorporate scene understanding, which involvesinterpreting and reasoning about the driving environment. In this paper, wepresent a unified Driving World Model named HERMES. We seamlessly integrate 3Dscene understanding and future scene evolution (generation) through a unifiedframework in driving scenarios. Specifically, HERMES leverages a Bird's-EyeView (BEV) representation to consolidate multi-view spatial information whilepreserving geometric relationships and interactions. We also introduce worldqueries, which incorporate world knowledge into BEV features via causalattention in the Large Language Model (LLM), enabling contextual enrichment forunderstanding and generation tasks. We conduct comprehensive studies onnuScenes and OmniDrive-nuScenes datasets to validate the effectiveness of ourmethod. HERMES achieves state-of-the-art performance, reducing generation errorby 32.4% and improving understanding metrics such as CIDEr by 8.0%. The modeland code will be publicly released at https://github.com/LMD0311/HERMES.</description><author>Xin Zhou, Dingkang Liang, Sifan Tu, Xiwu Chen, Yikang Ding, Dingyuan Zhang, Feiyang Tan, Hengshuang Zhao, Xiang Bai</author><pubDate>Fri, 24 Jan 2025 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14729v1</guid></item><item><title>Mitigating GenAI-powered Evidence Pollution for Out-of-Context Multimodal Misinformation Detection</title><link>http://arxiv.org/abs/2501.14728v1</link><description>While large generative artificial intelligence (GenAI) models have achievedsignificant success, they also raise growing concerns about online informationsecurity due to their potential misuse for generating deceptive content.Out-of-context (OOC) multimodal misinformation detection, which often retrievesWeb evidence to identify the repurposing of images in false contexts, faces theissue of reasoning over GenAI-polluted evidence to derive accurate predictions.Existing works simulate GenAI-powered pollution at the claim level withstylistic rewriting to conceal linguistic cues, and ignore evidence-levelpollution for such information-seeking applications. In this work, weinvestigate how polluted evidence affects the performance of existing OOCdetectors, revealing a performance degradation of more than 9 percentagepoints. We propose two strategies, cross-modal evidence reranking andcross-modal claim-evidence reasoning, to address the challenges posed bypolluted evidence. Extensive experiments on two benchmark datasets show thatthese strategies can effectively enhance the robustness of existingout-of-context detectors amidst polluted evidence.</description><author>Zehong Yan, Peng Qi, Wynne Hsu, Mong Li Lee</author><pubDate>Fri, 24 Jan 2025 18:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14728v1</guid></item><item><title>Relightable Full-Body Gaussian Codec Avatars</title><link>http://arxiv.org/abs/2501.14726v1</link><description>We propose Relightable Full-Body Gaussian Codec Avatars, a new approach formodeling relightable full-body avatars with fine-grained details including faceand hands. The unique challenge for relighting full-body avatars lies in thelarge deformations caused by body articulation and the resulting impact onappearance caused by light transport. Changes in body pose can dramaticallychange the orientation of body surfaces with respect to lights, resulting inboth local appearance changes due to changes in local light transportfunctions, as well as non-local changes due to occlusion between body parts. Toaddress this, we decompose the light transport into local and non-localeffects. Local appearance changes are modeled using learnable zonal harmonicsfor diffuse radiance transfer. Unlike spherical harmonics, zonal harmonics arehighly efficient to rotate under articulation. This allows us to learn diffuseradiance transfer in a local coordinate frame, which disentangles the localradiance transfer from the articulation of the body. To account for non-localappearance changes, we introduce a shadow network that predicts shadows givenprecomputed incoming irradiance on a base mesh. This facilitates the learningof non-local shadowing between the body parts. Finally, we use a deferredshading approach to model specular radiance transfer and better capturereflections and highlights such as eye glints. We demonstrate that our approachsuccessfully models both the local and non-local light transport required forrelightable full-body avatars, with a superior generalization ability undernovel illumination conditions and unseen poses.</description><author>Shaofei Wang, Tomas Simon, Igor Santesteban, Timur Bagautdinov, Junxuan Li, Vasu Agrawal, Fabian Prada, Shoou-I Yu, Pace Nalbone, Matt Gramlich, Roman Lubachersky, Chenglei Wu, Javier Romero, Jason Saragih, Michael Zollhoefer, Andreas Geiger, Siyu Tang, Shunsuke Saito</author><pubDate>Fri, 24 Jan 2025 18:59:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14726v1</guid></item><item><title>MLPs at the EOC: Concentration of the NTK</title><link>http://arxiv.org/abs/2501.14724v1</link><description>We study the concentration of the Neural Tangent Kernel (NTK) $K_\theta :\mathbb{R}^{m_0} \times \mathbb{R}^{m_0} \to \mathbb{R}^{m_l \times m_l}$ of$l$-layer Multilayer Perceptrons (MLPs) $N : \mathbb{R}^{m_0} \times \Theta \to\mathbb{R}^{m_l}$ equipped with activation functions $\phi(s) = a s + b \vert s\vert$ for some $a,b \in \mathbb{R}$ with the parameter $\theta \in \Theta$being initialized at the Edge Of Chaos (EOC). Without relying on the gradientindependence assumption that has only been shown to hold asymptotically in theinfinitely wide limit, we prove that an approximate version of gradientindependence holds at finite width. Showing that the NTK entries$K_\theta(x_{i_1},x_{i_2})$ for $i_1,i_2 \in [1:n]$ over a dataset$\{x_1,\cdots,x_n\} \subset \mathbb{R}^{m_0}$ concentrate simultaneously viamaximal inequalities, we prove that the NTK matrix $K(\theta) = [\frac{1}{n}K_\theta(x_{i_1},x_{i_2}) : i_1,i_2 \in [1:n]] \in \mathbb{R}^{nm_l \timesnm_l}$ concentrates around its infinitely wide limit$\overset{\scriptscriptstyle\infty}{K} \in \mathbb{R}^{nm_l \times nm_l}$without the need for linear overparameterization. Our results imply that inorder to accurately approximate the limit, hidden layer widths have to growquadratically as $m_k = k^2 m$ for some $m \in \mathbb{N}+1$ for sufficientconcentration. For such MLPs, we obtain the concentration bound $\mathbb{P}(\Vert K(\theta) - \overset{\scriptscriptstyle\infty}{K} \Vert \leqO((\Delta_\phi^{-2} + m_l^{\frac{1}{2}} l) \kappa_\phi^2 m^{-\frac{1}{2}}))\geq 1-O(m^{-1})$ modulo logarithmic terms, where we denoted $\Delta_\phi =\frac{b^2}{a^2+b^2}$ and $\kappa_\phi = \frac{\vert a \vert + \vert b\vert}{\sqrt{a^2 + b^2}}$. This reveals in particular that the absolute value($\Delta_\phi=1$, $\kappa_\phi=1$) beats the ReLU ($\Delta_\phi=\frac{1}{2}$,$\kappa_\phi=\sqrt{2}$) in terms of the concentration of the NTK.</description><author>Dávid Terjék, Diego González-Sánchez</author><pubDate>Fri, 24 Jan 2025 18:58:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14724v1</guid></item><item><title>CodeMonkeys: Scaling Test-Time Compute for Software Engineering</title><link>http://arxiv.org/abs/2501.14723v1</link><description>Scaling test-time compute is a promising axis for improving LLM capabilities.However, test-time compute can be scaled in a variety of ways, and effectivelycombining different approaches remains an active area of research. Here, weexplore this problem in the context of solving real-world GitHub issues fromthe SWE-bench dataset. Our system, named CodeMonkeys, allows models toiteratively edit a codebase by jointly generating and running a testing scriptalongside their draft edit. We sample many of these multi-turn trajectories forevery issue to generate a collection of candidate edits. This approach lets usscale "serial" test-time compute by increasing the number of iterations pertrajectory and "parallel" test-time compute by increasing the number oftrajectories per problem. With parallel scaling, we can amortize up-front costsacross multiple downstream samples, allowing us to identify relevant codebasecontext using the simple method of letting an LLM read every file. In order toselect between candidate edits, we combine voting using model-generated testswith a final multi-turn trajectory dedicated to selection. Overall, CodeMonkeysresolves 57.4% of issues from SWE-bench Verified using a budget ofapproximately 2300 USD. Our selection method can also be used to combinecandidates from different sources. Selecting over an ensemble of edits fromexisting top SWE-bench Verified submissions obtains a score of 66.2% andoutperforms the best member of the ensemble on its own. We fully release ourcode and data at https://scalingintelligence.stanford.edu/pubs/codemonkeys.</description><author>Ryan Ehrlich, Bradley Brown, Jordan Juravsky, Ronald Clark, Christopher Ré, Azalia Mirhoseini</author><pubDate>Fri, 24 Jan 2025 18:58:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14723v1</guid></item><item><title>A Note on the Prediction-Powered Bootstrap</title><link>http://arxiv.org/abs/2405.18379v3</link><description>We introduce PPBoot: a bootstrap-based method for prediction-poweredinference. PPBoot is applicable to arbitrary estimation problems and is verysimple to implement, essentially only requiring one application of thebootstrap. Through a series of examples, we demonstrate that PPBoot oftenperforms nearly identically to (and sometimes better than) the earlier PPI(++)method based on asymptotic normality$\unicode{x2013}$when the latter isapplicable$\unicode{x2013}$without requiring any asymptotic characterizations.Given its versatility, PPBoot could simplify and expand the scope ofapplication of prediction-powered inference to problems where central limittheorems are hard to prove.</description><author>Tijana Zrnic</author><pubDate>Fri, 24 Jan 2025 18:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18379v3</guid></item><item><title>Navigating the Cultural Kaleidoscope: A Hitchhiker's Guide to Sensitivity in Large Language Models</title><link>http://arxiv.org/abs/2410.12880v3</link><description>As LLMs are increasingly deployed in global applications, the importance ofcultural sensitivity becomes paramount, ensuring that users from diversebackgrounds feel respected and understood. Cultural harm can arise when thesemodels fail to align with specific cultural norms, resulting inmisrepresentations or violations of cultural values. This work addresses thechallenges of ensuring cultural sensitivity in LLMs, especially insmall-parameter models that often lack the extensive training data needed tocapture global cultural nuances. We present two key contributions: (1) Acultural harm test dataset, created to assess model outputs across differentcultural contexts through scenarios that expose potential culturalinsensitivities, and (2) A culturally aligned preference dataset, aimed atrestoring cultural sensitivity through fine-tuning based on feedback fromdiverse annotators. These datasets facilitate the evaluation and enhancement ofLLMs, ensuring their ethical and safe deployment across different culturallandscapes. Our results show that integrating culturally aligned feedback leadsto a marked improvement in model behavior, significantly reducing thelikelihood of generating culturally insensitive or harmful content. Ultimately,this work paves the way for more inclusive and respectful AI systems, fosteringa future where LLMs can safely and ethically navigate the complexities ofdiverse cultural landscapes.</description><author>Somnath Banerjee, Sayan Layek, Hari Shrawgi, Rajarshi Mandal, Avik Halder, Shanu Kumar, Sagnik Basu, Parag Agrawal, Rima Hazra, Animesh Mukherjee</author><pubDate>Fri, 24 Jan 2025 18:56:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12880v3</guid></item><item><title>Comparable Corpora: Opportunities for New Research Directions</title><link>http://arxiv.org/abs/2501.14721v1</link><description>Most conference papers present new results, but this paper will focus more onopportunities for the audience to make their own contributions. This paper isintended to challenge the community to think more broadly about what we can dowith comparable corpora. We will start with a review of the history, and thensuggest new directions for future research. This was a keynote at BUCC-2025, aworkshop associated with Coling-2025.</description><author>Kenneth Church</author><pubDate>Fri, 24 Jan 2025 18:54:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14721v1</guid></item><item><title>Do LLMs Provide Consistent Answers to Health-Related Questions across Languages?</title><link>http://arxiv.org/abs/2501.14719v1</link><description>Equitable access to reliable health information is vital for public health,but the quality of online health resources varies by language, raising concernsabout inconsistencies in Large Language Models (LLMs) for healthcare. In thisstudy, we examine the consistency of responses provided by LLMs tohealth-related questions across English, German, Turkish, and Chinese. Welargely expand the HealthFC dataset by categorizing health-related questions bydisease type and broadening its multilingual scope with Turkish and Chinesetranslations. We reveal significant inconsistencies in responses that couldspread healthcare misinformation. Our main contributions are 1) a multilingualhealth-related inquiry dataset with meta-information on disease categories, and2) a novel prompt-based evaluation workflow that enables sub-dimensionalcomparisons between two languages through parsing. Our findings highlight keychallenges in deploying LLM-based tools in multilingual contexts and emphasizethe need for improved cross-lingual alignment to ensure accurate and equitablehealthcare information.</description><author>Ipek Baris Schlicht, Zhixue Zhao, Burcu Sayin, Lucie Flek, Paolo Rosso</author><pubDate>Fri, 24 Jan 2025 18:51:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14719v1</guid></item><item><title>Towards Better Understanding Table Instruction Tuning: Decoupling the Effects from Data versus Models</title><link>http://arxiv.org/abs/2501.14717v1</link><description>Recent advances in natural language processing have leveraged instructiontuning to enhance Large Language Models (LLMs) for table-related tasks.However, previous works train different base models with different trainingdata, lacking an apples-to-apples comparison across the result table LLMs. Toaddress this, we fine-tune base models from the Mistral, OLMo, and Phi familieson existing public training datasets. Our replication achieves performance onpar with or surpassing existing table LLMs, establishing new state-of-the-artperformance on Hitab, a table question-answering dataset. More importantly,through systematic out-of-domain evaluation, we decouple the contributions oftraining data and the base model, providing insight into their individualimpacts. In addition, we assess the effects of table-specific instructiontuning on general-purpose benchmarks, revealing trade-offs betweenspecialization and generalization.</description><author>Naihao Deng, Sheng Zhang, Henghui Zhu, Shuaichen Chang, Jiani Zhang, Alexander Hanbo Li, Chung-Wei Hang, Hideo Kobayashi, Yiqun Hu, Patrick Ng</author><pubDate>Fri, 24 Jan 2025 18:50:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14717v1</guid></item><item><title>FlexiGPT: Pruning and Extending Large Language Models with Low-Rank Weight Sharing</title><link>http://arxiv.org/abs/2501.14713v1</link><description>The rapid proliferation of large language models (LLMs) in natural languageprocessing (NLP) has created a critical need for techniques that enableefficient deployment on memory-constrained devices without compromisingperformance. We present a method to prune LLMs that selectively prunes modelblocks based on an importance score and replaces them with a low-parameterreplacement strategy. Specifically, we propose a principled metric to replaceeach pruned block using a weight-sharing mechanism that leverages unprunedcounterparts from the model and block-specific low-rank adapters. Furthermore,we facilitate the learning of these replacement blocks with output featurenormalization and an adapter initialization scheme built on low-rank SVDreconstructions. Empirical evaluations demonstrate substantial performancegains over existing methods, achieving state-of-the-art performance on 5/6benchmarks for a compression rate of 30% and 6/6 benchmarks for a compressionrate of 40%. We also demonstrate that our approach can extend smaller models,boosting performance on 6/6 benchmarks using only ~0.3% tokens of extendedtraining with minimal additional parameter costs.</description><author>James Seale Smith, Chi-Heng Lin, Shikhar Tuli, Haris Jeelani, Shangqian Gao, Yilin Shen, Hongxia Jin, Yen-Chang Hsu</author><pubDate>Fri, 24 Jan 2025 18:46:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14713v1</guid></item><item><title>Overcoming Fairness Trade-offs via Pre-processing: A Causal Perspective</title><link>http://arxiv.org/abs/2501.14710v1</link><description>Training machine learning models for fair decisions faces two key challenges:The \emph{fairness-accuracy trade-off} results from enforcing fairness whichweakens its predictive performance in contrast to an unconstrained model. Theincompatibility of different fairness metrics poses another trade-off -- alsoknown as the \emph{impossibility theorem}. Recent work identifies the biaswithin the observed data as a possible root cause and shows that fairness andpredictive performance are in fact in accord when predictive performance ismeasured on unbiased data. We offer a causal explanation for these findingsusing the framework of the FiND (fictitious and normatively desired) world, a"fair" world, where protected attributes have no causal effects on the targetvariable. We show theoretically that (i) classical fairness metrics deemed tobe incompatible are naturally satisfied in the FiND world, while (ii) fairnessaligns with high predictive performance. We extend our analysis by suggestinghow one can benefit from these theoretical insights in practice, using causalpre-processing methods that approximate the FiND world. Additionally, wepropose a method for evaluating the approximation of the FiND world viapre-processing in practical use cases where we do not have access to the FiNDworld. In simulations and empirical studies, we demonstrate that thesepre-processing methods are successful in approximating the FiND world andresolve both trade-offs. Our results provide actionable solutions forpractitioners to achieve fairness and high predictive performancesimultaneously.</description><author>Charlotte Leininger, Simon Rittel, Ludwig Bothmann</author><pubDate>Fri, 24 Jan 2025 18:33:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14710v1</guid></item><item><title>Enhanced Confocal Laser Scanning Microscopy with Adaptive Physics Informed Deep Autoencoders</title><link>http://arxiv.org/abs/2501.14709v1</link><description>We present a physics-informed deep learning framework to address commonlimitations in Confocal Laser Scanning Microscopy (CLSM), such as diffractionlimited resolution, noise, and undersampling due to low laser power conditions.The optical system's point spread function (PSF) and common CLSM imagedegradation mechanisms namely photon shot noise, dark current noise, motionblur, speckle noise, and undersampling were modeled and were directly includedinto model architecture. The model reconstructs high fidelity images fromheavily noisy inputs by using convolutional and transposed convolutionallayers. Following the advances in compressed sensing, our approachsignificantly reduces data acquisition requirements without compromising imageresolution. The proposed method was extensively evaluated on simulated CLSMimages of diverse structures, including lipid droplets, neuronal networks, andfibrillar systems. Comparisons with traditional deconvolution algorithms suchas Richardson-Lucy (RL), non-negative least squares (NNLS), and other methodslike Total Variation (TV) regularization, Wiener filtering, and Waveletdenoising demonstrate the superiority of the network in restoring finestructural details with high fidelity. Assessment metrics like StructuralSimilarity Index (SSIM) and Peak Signal to Noise Ratio (PSNR), underlines thatthe AdaptivePhysicsAutoencoder achieved robust image enhancement across diverseCLSM conditions, helping faster acquisition, reduced photodamage, and reliableperformance in low light and sparse sampling scenarios holding promise forapplications in live cell imaging, dynamic biological studies, and highthroughput material characterization.</description><author>Zaheer Ahmad, Junaid Shabeer, Usman Saleem, Tahir Qadeer, Abdul Sami, Zahira El Khalidi, Saad Mehmood</author><pubDate>Fri, 24 Jan 2025 18:32:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14709v1</guid></item><item><title>Decision-Focused Learning for Complex System Identification: HVAC Management System Application</title><link>http://arxiv.org/abs/2501.14708v1</link><description>As opposed to conventional training methods tailored to minimize a givenstatistical metric or task-agnostic loss (e.g., mean squared error),Decision-Focused Learning (DFL) trains machine learning models for optimalperformance in downstream decision-making tools. We argue that DFL can beleveraged to learn the parameters of system dynamics, expressed as constraintof the convex optimization control policy, while the system control signal isbeing optimized, thus creating an end-to-end learning framework. This isparticularly relevant for systems in which behavior changes once the controlpolicy is applied, hence rendering historical data less applicable. Theproposed approach can perform system identification - i.e., determineappropriate parameters for the system analytical model - and controlsimultaneously to ensure that the model's accuracy is focused on areas mostrelevant to control. Furthermore, because black-box systems arenon-differentiable, we design a loss function that requires solely to measurethe system response. We propose pre-training on historical data and constraintrelaxation to stabilize the DFL and deal with potential infeasibilities inlearning. We demonstrate the usefulness of the method on a building Heating,Ventilation, and Air Conditioning day-ahead management system for a realistic15-zone building located in Denver, US. The results show that the conventionalRC building model, with the parameters obtained from historical data usingsupervised learning, underestimates HVAC electrical power consumption. For ourcase study, the ex-post cost is on average six times higher than the expectedone. Meanwhile, the same RC model with parameters obtained via DFLunderestimates the ex-post cost only by 3%.</description><author>Pietro Favaro, Jean-François Toubeau, François Vallée, Yury Dvorkin</author><pubDate>Fri, 24 Jan 2025 18:32:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14708v1</guid></item><item><title>Leveraging heterogeneous spillover in maximizing contextual bandit rewards</title><link>http://arxiv.org/abs/2310.10259v2</link><description>Recommender systems relying on contextual multi-armed bandits continuouslyimprove relevant item recommendations by taking into account the contextualinformation. The objective of bandit algorithms is to learn the best arm (e.g.,best item to recommend) for each user and thus maximize the cumulative rewardsfrom user engagement with the recommendations. The context that thesealgorithms typically consider are the user and item attributes. However, in thecontext of social networks where $\textit{the action of one user can influencethe actions and rewards of other users,}$ neighbors' actions are also a veryimportant context, as they can have not only predictive power but also canimpact future rewards through spillover. Moreover, influence susceptibility canvary for different people based on their preferences and the closeness of tiesto other users which leads to heterogeneity in the spillover effects. Here, wepresent a framework that allows contextual multi-armed bandits to account forsuch heterogeneous spillovers when choosing the best arm for each user. Ourexperiments on several semi-synthetic and real-world datasets show that ourframework leads to significantly higher rewards than existing state-of-the-artsolutions that ignore the network information and potential spillover.</description><author>Ahmed Sayeed Faruk, Elena Zheleva</author><pubDate>Fri, 24 Jan 2025 18:30:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10259v2</guid></item><item><title>The Karp Dataset</title><link>http://arxiv.org/abs/2501.14705v1</link><description>Understanding the mathematical reasoning capabilities of Large LanguageModels (LLMs) is a central topic in the study of artificial intelligence. Thisnew domain necessitates the creation of datasets of reasoning tasks for bothtraining and benchmarking the performance of LLMs. To this end, we introducethe Karp dataset: The first dataset composed of detailed proofs ofNP-completeness reductions. The reductions vary in difficulty, ranging fromsimple exercises of undergraduate courses to more challenging reductions fromacademic papers. We compare the performance of state-of-the-art models on thistask and demonstrate the effect of fine-tuning with the Karp dataset onreasoning capacity.</description><author>Mason DiCicco, Eamon Worden, Conner Olsen, Nikhil Gangaram, Daniel Reichman, Neil Heffernan</author><pubDate>Fri, 24 Jan 2025 18:30:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14705v1</guid></item><item><title>Stroke classification using Virtual Hybrid Edge Detection from in silico electrical impedance tomography data</title><link>http://arxiv.org/abs/2501.14704v1</link><description>Electrical impedance tomography (EIT) is a non-invasive imaging method forrecovering the internal conductivity of a physical body from electric boundarymeasurements. EIT combined with machine learning has shown promise for theclassification of strokes. However, most previous works have used raw EITvoltage data as network inputs. We build upon a recent development whichsuggested the use of special noise-robust Virtual Hybrid Edge Detection (VHED)functions as network inputs, although that work used only highly simplified andmathematically ideal models. In this work we strengthen the case for the use ofEIT, and VHED functions especially, for stroke classification. We design modelswith high detail and mathematical realism to test the use of VHED functions asinputs. Virtual patients are created using a physically detailed 2D head modelwhich includes features known to create challenges in real-world imagingscenarios. Conductivity values are drawn from statistically realisticdistributions, and phantoms are afflicted with either hemorrhagic or ischemicstrokes of various shapes and sizes. Simulated noisy EIT electrode data,generated using the realistic Complete Electrode Model (CEM) as opposed to themathematically ideal continuum model, is processed to obtain VHED functions. Wecompare the use of VHED functions as inputs against the alternative paradigm ofusing raw EIT voltages. Our results show that (i) stroke classification can beperformed with high accuracy using 2D EIT data from physically detailed andmathematically realistic models, and (ii) in the presence of noise, VHEDfunctions outperform raw data as network inputs.</description><author>Juan Pablo Agnelli, Fernando S. Moura, Siiri Rautio, Melody Alsaker, Rashmi Murthy, Matti Lassas, Samuli Siltanen</author><pubDate>Fri, 24 Jan 2025 18:29:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14704v1</guid></item><item><title>NLP-based assessment of prescription appropriateness from Italian referrals</title><link>http://arxiv.org/abs/2501.14701v1</link><description>Objective: This study proposes a Natural Language Processing pipeline toevaluate prescription appropriateness in Italian referrals, where reasons forprescriptions are recorded only as free text, complicating automatedcomparisons with guidelines. The pipeline aims to derive, for the first time, acomprehensive summary of the reasons behind these referrals and aquantification of their appropriateness. While demonstrated in a specific casestudy, the approach is designed to generalize to other types of examinations. Methods: Leveraging embeddings from a transformer-based model, the proposedapproach clusters referral texts, maps clusters to labels, and aligns theselabels with existing guidelines. We present a case study on a dataset of496,971 referrals, consisting of all referrals for venous echocolordopplers ofthe lower limbs between 2019 and 2021 in the Lombardy Region. A sample of 1,000referrals was manually annotated to validate the results. Results: The pipeline exhibited high performance for referrals' reasons(Prec=92.43%, Rec=83.28%) and excellent results for referrals' appropriateness(Prec=93.58%, Rec=91.52%) on the annotated subset. Analysis of the entiredataset identified clusters matching guideline-defined reasons - bothappropriate and inappropriate - as well as clusters not addressed in theguidelines. Overall, 34.32% of referrals were marked as appropriate, 34.07%inappropriate, 14.37% likely inappropriate, and 17.24% could not be mapped toguidelines. Conclusions: The proposed pipeline effectively assessed prescriptionappropriateness across a large dataset, serving as a valuable tool for healthauthorities. Findings have informed the Lombardy Region's efforts to strengthenrecommendations and reduce the burden of inappropriate referrals.</description><author>Vittorio Torri, Annamaria Bottelli, Michele Ercolanoni, Olivia Leoni, Francesca Ieva</author><pubDate>Fri, 24 Jan 2025 18:24:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14701v1</guid></item><item><title>An Attentive Graph Agent for Topology-Adaptive Cyber Defence</title><link>http://arxiv.org/abs/2501.14700v1</link><description>As cyber threats grow increasingly sophisticated, reinforcement learning isemerging as a promising technique to create intelligent, self-improvingdefensive systems. However, most existing autonomous defensive agents haveoverlooked the inherent graph structure of computer networks subject to cyberattacks, potentially missing critical information. To address this gap, wedeveloped a custom version of the Cyber Operations Research Gym (CybORG)environment that encodes the observable network state as a directed graph,utilizing realistic and interpretable low-level features. %, like number ofopen ports and unexpected detected connections. We leverage a Graph AttentionNetwork (GAT) architecture to process node, edge, and global features, andmodify its output to be compatible with policy gradient methods inreinforcement learning. GAT policies offer several advantages over standardapproaches based on simplistic flattened state observations. They can handlethe changes in network topology that occur at runtime when dynamic connectionsbetween hosts appear. Policies can be deployed to networks that differ in sizeto the ones seen during training, enabling a degree of generalisationinaccessible with alternative approaches. Furthermore, the graph neural networkpolicies outputs are explainable in terms of tangible network properties,providing enhanced interpretability of defensive actions. We verify that ourlow-level graph observations are meaningful enough to train GAT defensivepolicies that are able to adapt to changing topologies. We evaluate how ourtrained policies perform when deployed on networks of varying sizes with thesame subnetwork structure, comparing them against policies specifically trainedfor each network configuration. Our study contributes to the development ofrobust cyber defence systems that can better adapt to real-world networksecurity challenges.</description><author>Ilya Orson Sandoval, Isaac Symes Thompson, Vasilios Mavroudis, Chris Hicks</author><pubDate>Fri, 24 Jan 2025 18:22:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14700v1</guid></item><item><title>Hierarchical Count Echo State Network Models with Application to Graduate Student Enrollments</title><link>http://arxiv.org/abs/2501.14698v1</link><description>Poisson autoregressive count models have evolved into a time series staplefor correlated count data. This paper proposes an alternative to Poissonautoregressions: count echo state networks. Echo state networks can bestatistically analyzed in frequentist manners via optimizing penalizedlikelihoods, or in Bayesian manners via MCMC sampling. This paper developsPoisson echo state techniques for count data and applies them to a massivecount data set containing the number of graduate students from 1,758 UnitedStates universities during the years 1972-2021 inclusive. Negative binomialmodels are also implemented to better handle overdispersion in the counts.Performance of the proposed models are compared via their forecastingperformance as judged by several methods. In the end, a hierarchical negativebinomial based echo state network is judged as the superior model.</description><author>Qi Wang, Paul A. Parker, Robert B. Lund</author><pubDate>Fri, 24 Jan 2025 18:19:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14698v1</guid></item><item><title>Towards Automated Self-Supervised Learning for Truly Unsupervised Graph Anomaly Detection</title><link>http://arxiv.org/abs/2501.14694v1</link><description>Self-supervised learning (SSL) is an emerging paradigm that exploitssupervisory signals generated from the data itself, and many recent studieshave leveraged SSL to conduct graph anomaly detection. However, we empiricallyfound that three important factors can substantially impact detectionperformance across datasets: 1) the specific SSL strategy employed; 2) thetuning of the strategy's hyperparameters; and 3) the allocation of combinationweights when using multiple strategies. Most SSL-based graph anomaly detectionmethods circumvent these issues by arbitrarily or selectively (i.e., guided bylabel information) choosing SSL strategies, hyperparameter settings, andcombination weights. While an arbitrary choice may lead to subpar performance,using label information in an unsupervised setting is label information leakageand leads to severe overestimation of a method's performance. Leakage has beencriticized as "one of the top ten data mining mistakes", yet many recentstudies on SSL-based graph anomaly detection have been using label informationto select hyperparameters. To mitigate this issue, we propose to use aninternal evaluation strategy (with theoretical analysis) to selecthyperparameters in SSL for unsupervised anomaly detection. We perform extensiveexperiments using 10 recent SSL-based graph anomaly detection algorithms onvarious benchmark datasets, demonstrating both the prior issues withhyperparameter selection and the effectiveness of our proposed strategy.</description><author>Zhong Li, Yuhang Wang, Matthijs van Leeuwen</author><pubDate>Fri, 24 Jan 2025 18:13:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14694v1</guid></item><item><title>Rethinking Table Instruction Tuning</title><link>http://arxiv.org/abs/2501.14693v1</link><description>Recent advances in table understanding have focused on instruction-tuninglarge language models (LLMs) for table-related tasks. However, existingresearch has overlooked the impact of hyperparameter choices and lacks acomprehensive evaluation of the out-of-domain table understanding ability andthe general capabilities of these table LLMs. In this paper, we evaluate theseabilities in existing table LLMs, and reveal significant declines in bothout-of-domain table understanding and general capabilities compared to theirbase models. Through systematic analysis, we show that hyperparameters, such aslearning rate, can significantly influence both table-specific and generalcapabilities. Contrary to the existing table instruction-tuning works, wedemonstrate that smaller learning rates and fewer training instances canenhance table understanding while preserving general capabilities. Based on ourfindings, we introduce TAMA, a TAble LLM instruction-tuned from LLaMA 3.1 8BInstruct, which achieves performance on par with, or surpassing GPT-3.5 andGPT-4 on table tasks, while maintaining strong out-of-domain generalization andgeneral capabilities. Our findings highlight the potential for reduced dataannotation costs and more efficient model development through carefulhyperparameter selection.</description><author>Naihao Deng, Rada Mihalcea</author><pubDate>Fri, 24 Jan 2025 18:06:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14693v1</guid></item><item><title>Approach to Designing CV Systems for Medical Applications: Data, Architecture and AI</title><link>http://arxiv.org/abs/2501.14689v1</link><description>This paper introduces an innovative software system for fundus image analysisthat deliberately diverges from the conventional screening approach, opting notto predict specific diagnoses. Instead, our methodology mimics the diagnosticprocess by thoroughly analyzing both normal and pathological features of fundusstructures, leaving the ultimate decision-making authority in the hands ofhealthcare professionals. Our initiative addresses the need for objectiveclinical analysis and seeks to automate and enhance the clinical workflow offundus image examination. The system, from its overarching architecture to themodular analysis design powered by artificial intelligence (AI) models, alignsseamlessly with ophthalmological practices. Our unique approach utilizes acombination of state-of-the-art deep learning methods and traditional computervision algorithms to provide a comprehensive and nuanced analysis of fundusstructures. We present a distinctive methodology for designing medicalapplications, using our system as an illustrative example. Comprehensiveverification and validation results demonstrate the efficacy of our approach inrevolutionizing fundus image analysis, with potential applications acrossvarious medical domains.</description><author>Dmitry Ryabtsev, Boris Vasilyev, Sergey Shershakov</author><pubDate>Fri, 24 Jan 2025 18:02:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14689v1</guid></item><item><title>Decoding Generalization from Memorization in Deep Neural Networks</title><link>http://arxiv.org/abs/2501.14687v1</link><description>Overparameterized Deep Neural Networks that generalize well have been key tothe dramatic success of Deep Learning in recent years. The reasons for theirremarkable ability to generalize are not well understood yet. It has also beenknown that deep networks possess the ability to memorize training data, asevidenced by perfect or high training accuracies on models trained withcorrupted data that have class labels shuffled to varying degrees.Concomitantly, such models are known to generalize poorly, i.e. they sufferfrom poor test accuracies, due to which it is thought that the act ofmemorizing substantially degrades the ability to generalize. It has, however,been unclear why the poor generalization that accompanies such memorization,comes about. One possibility is that in the process of training with corrupteddata, the layers of the network irretrievably reorganize their representationsin a manner that makes generalization difficult. The other possibility is thatthe network retains significant ability to generalize, but the trained networksomehow chooses to readout in a manner that is detrimental to generalization.Here, we provide evidence for the latter possibility by demonstrating,empirically, that such models possess information in their representations forsubstantially improved generalization, even in the face of memorization.Furthermore, such generalization abilities can be easily decoded from theinternals of the trained model, and we build a technique to do so from theoutputs of specific layers of the network. We demonstrate results on multiplemodels trained with a number of standard datasets.</description><author>Simran Ketha, Venkatakrishnan Ramaswamy</author><pubDate>Fri, 24 Jan 2025 18:01:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14687v1</guid></item><item><title>Rethinking Foundation Models for Medical Image Classification through a Benchmark Study on MedMNIST</title><link>http://arxiv.org/abs/2501.14685v1</link><description>Foundation models are widely employed in medical image analysis, due to theirhigh adaptability and generalizability for downstream tasks. With theincreasing number of foundation models being released, model selection hasbecome an important issue. In this work, we study the capabilities offoundation models in medical image classification tasks by conducting abenchmark study on the MedMNIST dataset. Specifically, we adopt variousfoundation models ranging from convolutional to Transformer-based models andimplement both end-to-end training and linear probing for all classificationtasks. The results demonstrate the significant potential of these pre-trainedmodels when transferred for medical image classification. We further conductexperiments with different image sizes and various sizes of training data. Byanalyzing all the results, we provide preliminary, yet useful insights andconclusions on this topic.</description><author>Fuping Wu, Bartlomiej W. Papiez</author><pubDate>Fri, 24 Jan 2025 18:01:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14685v1</guid></item><item><title>Surface Vision Mamba: Leveraging Bidirectional State Space Model for Efficient Spherical Manifold Representation</title><link>http://arxiv.org/abs/2501.14679v1</link><description>Attention-based methods have demonstrated exceptional performance inmodelling long-range dependencies on spherical cortical surfaces, surpassingtraditional Geometric Deep Learning (GDL) models. However, their extensiveinference time and high memory demands pose challenges for application to largedatasets with limited computing resources. Inspired by the state space model incomputer vision, we introduce the attention-free Vision Mamba (Vim) tospherical surfaces, presenting a domain-agnostic architecture for analyzingdata on spherical manifolds. Our method achieves surface patching byrepresenting spherical data as a sequence of triangular patches derived from asubdivided icosphere. The proposed Surface Vision Mamba (SiM) is evaluated onmultiple neurodevelopmental phenotype regression tasks using cortical surfacemetrics from neonatal brains. Experimental results demonstrate that SiMoutperforms both attention- and GDL-based methods, delivering 4.8 times fasterinference and achieving 91.7% lower memory consumption compared to the SurfaceVision Transformer (SiT) under the Ico-4 grid partitioning. Sensitivityanalysis further underscores the potential of SiM to identify subtle cognitivedevelopmental patterns. The code is available athttps://github.com/Rongzhao-He/surface-vision-mamba.</description><author>Rongzhao He, Weihao Zheng</author><pubDate>Fri, 24 Jan 2025 17:57:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14679v1</guid></item><item><title>A Predictive Approach for Enhancing Accuracy in Remote Robotic Surgery Using Informer Model</title><link>http://arxiv.org/abs/2501.14678v1</link><description>Precise and real-time estimation of the robotic arm's position on thepatient's side is essential for the success of remote robotic surgery inTactile Internet (TI) environments. This paper presents a prediction modelbased on the Transformer-based Informer framework for accurate and efficientposition estimation. Additionally, it combines a Four-State Hidden Markov Model(4-State HMM) to simulate realistic packet loss scenarios. The proposedapproach addresses challenges such as network delays, jitter, and packet lossto ensure reliable and precise operation in remote surgical applications. Themethod integrates the optimization problem into the Informer model by embeddingconstraints such as energy efficiency, smoothness, and robustness into itstraining process using a differentiable optimization layer. The Informerframework uses features such as ProbSparse attention, attention distilling, anda generative-style decoder to focus on position-critical features whilemaintaining a low computational complexity of O(L log L). The method isevaluated using the JIGSAWS dataset, achieving a prediction accuracy of over 90percent under various network scenarios. A comparison with models such as TCN,RNN, and LSTM demonstrates the Informer framework's superior performance inhandling position prediction and meeting real-time requirements, making itsuitable for Tactile Internet-enabled robotic surgery.</description><author>Muhammad Hanif Lashari, Shakil Ahmed, Wafa Batayneh, Ashfaq Khokhar</author><pubDate>Fri, 24 Jan 2025 17:57:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14678v1</guid></item><item><title>MatAnyone: Stable Video Matting with Consistent Memory Propagation</title><link>http://arxiv.org/abs/2501.14677v1</link><description>Auxiliary-free human video matting methods, which rely solely on inputframes, often struggle with complex or ambiguous backgrounds. To address this,we propose MatAnyone, a robust framework tailored for target-assigned videomatting. Specifically, building on a memory-based paradigm, we introduce aconsistent memory propagation module via region-adaptive memory fusion, whichadaptively integrates memory from the previous frame. This ensures semanticstability in core regions while preserving fine-grained details along objectboundaries. For robust training, we present a larger, high-quality, and diversedataset for video matting. Additionally, we incorporate a novel trainingstrategy that efficiently leverages large-scale segmentation data, boostingmatting stability. With this new network design, dataset, and trainingstrategy, MatAnyone delivers robust and accurate video matting results indiverse real-world scenarios, outperforming existing methods.</description><author>Peiqing Yang, Shangchen Zhou, Jixin Zhao, Qingyi Tao, Chen Change Loy</author><pubDate>Fri, 24 Jan 2025 17:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14677v1</guid></item><item><title>State Space Models for Extractive Summarization in Low Resource Scenarios</title><link>http://arxiv.org/abs/2501.14673v1</link><description>Extractive summarization involves selecting the most relevant sentences froma text. Recently, researchers have focused on advancing methods to improvestate-of-the-art results in low-resource settings. Motivated by theseadvancements, we propose the MPoincareSum method. This method applies the Mambastate space model to generate the semantics of reviews and sentences, which arethen concatenated. A Poincare compression is used to select the most meaningfulfeatures, followed by the application of a linear layer to predict sentencerelevance based on the corresponding review. Finally, we paraphrase therelevant sentences to create the final summary. To evaluate the effectivenessof MPoincareSum, we conducted extensive experiments using the Amazon reviewdataset. The performance of the method was assessed using ROUGE scores. Theexperimental results demonstrate that MPoincareSum outperforms several existingapproaches in the literature</description><author>Nisrine Ait Khayi</author><pubDate>Fri, 24 Jan 2025 17:49:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14673v1</guid></item><item><title>Hierarchical Vector Quantization for Unsupervised Action Segmentation</title><link>http://arxiv.org/abs/2412.17640v2</link><description>In this work, we address unsupervised temporal action segmentation, whichsegments a set of long, untrimmed videos into semantically meaningful segmentsthat are consistent across videos. While recent approaches combinerepresentation learning and clustering in a single step for this task, they donot cope with large variations within temporal segments of the same class. Toaddress this limitation, we propose a novel method, termed Hierarchical VectorQuantization (HVQ), that consists of two subsequent vector quantizationmodules. This results in a hierarchical clustering where the additionalsubclusters cover the variations within a cluster. We demonstrate that ourapproach captures the distribution of segment lengths much better than thestate of the art. To this end, we introduce a new metric based on theJensen-Shannon Distance (JSD) for unsupervised temporal action segmentation. Weevaluate our approach on three public datasets, namely Breakfast, YouTubeInstructional and IKEA ASM. Our approach outperforms the state of the art interms of F1 score, recall and JSD.</description><author>Federico Spurio, Emad Bahrami, Gianpiero Francesca, Juergen Gall</author><pubDate>Fri, 24 Jan 2025 17:43:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17640v2</guid></item><item><title>End-to-end workflow for machine learning-based qubit readout with QICK and hls4ml</title><link>http://arxiv.org/abs/2501.14663v1</link><description>We present an end-to-end workflow for superconducting qubit readout thatembeds co-designed Neural Networks (NNs) into the Quantum InstrumentationControl Kit (QICK). Capitalizing on the custom firmware and software of theQICK platform, which is built on Xilinx RFSoC FPGAs, we aim to leverage machinelearning (ML) to address critical challenges in qubit readout accuracy andscalability. The workflow utilizes the hls4ml package and employsquantization-aware training to translate ML models into hardware-efficient FPGAimplementations via user-friendly Python APIs. We experimentally demonstratethe design, optimization, and integration of an ML algorithm for singletransmon qubit readout, achieving 96% single-shot fidelity with a latency of32ns and less than 16% FPGA look-up table resource utilization. Our resultsoffer the community an accessible workflow to advance ML-driven readout andadaptive control in quantum information processing applications.</description><author>Giuseppe Di Guglielmo, Botao Du, Javier Campos, Alexandra Boltasseva, Akash V. Dixit, Farah Fahim, Zhaxylyk Kudyshev, Santiago Lopez, Ruichao Ma, Gabriel N. Perdue, Nhan Tran, Omer Yesilyurt, Daniel Bowring</author><pubDate>Fri, 24 Jan 2025 17:35:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14663v1</guid></item><item><title>Time-MMD: Multi-Domain Multimodal Dataset for Time Series Analysis</title><link>http://arxiv.org/abs/2406.08627v4</link><description>Time series data are ubiquitous across a wide range of real-world domains.While real-world time series analysis (TSA) requires human experts to integratenumerical series data with multimodal domain-specific knowledge, most existingTSA models rely solely on numerical data, overlooking the significance ofinformation beyond numerical series. This oversight is due to the untappedpotential of textual series data and the absence of a comprehensive,high-quality multimodal dataset. To overcome this obstacle, we introduceTime-MMD, the first multi-domain, multimodal time series dataset covering 9primary data domains. Time-MMD ensures fine-grained modality alignment,eliminates data contamination, and provides high usability. Additionally, wedevelop MM-TSFlib, the first-cut multimodal time-series forecasting (TSF)library, seamlessly pipelining multimodal TSF evaluations based on Time-MMD forin-depth analyses. Extensive experiments conducted on Time-MMD throughMM-TSFlib demonstrate significant performance enhancements by extendingunimodal TSF to multimodality, evidenced by over 15% mean squared errorreduction in general, and up to 40% in domains with rich textual data. Moreimportantly, our datasets and library revolutionize broader applications,impacts, research topics to advance TSA. The dataset is available athttps://github.com/AdityaLab/Time-MMD.</description><author>Haoxin Liu, Shangqing Xu, Zhiyuan Zhao, Lingkai Kong, Harshavardhan Kamarthi, Aditya B. Sasanur, Megha Sharma, Jiaming Cui, Qingsong Wen, Chao Zhang, B. Aditya Prakash</author><pubDate>Fri, 24 Jan 2025 17:34:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08627v4</guid></item><item><title>Neural-Symbolic Message Passing with Dynamic Pruning</title><link>http://arxiv.org/abs/2501.14661v1</link><description>Complex Query Answering (CQA) over incomplete Knowledge Graphs (KGs) is achallenging task. Recently, a line of message-passing-based research has beenproposed to solve CQA. However, they perform unsatisfactorily on negativequeries and fail to address the noisy messages between variable nodes in thequery graph. Moreover, they offer little interpretability and require complexquery data and resource-intensive training. In this paper, we propose aNeural-Symbolic Message Passing (NSMP) framework based on pre-trained neurallink predictors. By introducing symbolic reasoning and fuzzy logic, NSMP cangeneralize to arbitrary existential first order logic queries without requiringtraining while providing interpretable answers. Furthermore, we introduce adynamic pruning strategy to filter out noisy messages between variable nodes.Experimental results show that NSMP achieves a strong performance.Additionally, through complexity analysis and empirical verification, wedemonstrate the superiority of NSMP in inference time over the currentstate-of-the-art neural-symbolic method. Compared to this approach, NSMPdemonstrates faster inference times across all query types on benchmarkdatasets, with speedup ranging from 2$\times$ to over 150$\times$.</description><author>Chongzhi Zhang, Junhao Zheng, Zhiping Peng, Qianli Ma</author><pubDate>Fri, 24 Jan 2025 17:30:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14661v1</guid></item><item><title>Mean-field limit from general mixtures of experts to quantum neural networks</title><link>http://arxiv.org/abs/2501.14660v1</link><description>In this work, we study the asymptotic behavior of Mixture of Experts (MoE)trained via gradient flow on supervised learning problems. Our main resultestablishes the propagation of chaos for a MoE as the number of expertsdiverges. We demonstrate that the corresponding empirical measure of theirparameters is close to a probability measure that solves a nonlinear continuityequation, and we provide an explicit convergence rate that depends solely onthe number of experts. We apply our results to a MoE generated by a quantumneural network.</description><author>Anderson Melchor Hernandez, Davide Pastorello, Giacomo De Palma</author><pubDate>Fri, 24 Jan 2025 17:29:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14660v1</guid></item><item><title>Towards Unified Structured Light Optimization</title><link>http://arxiv.org/abs/2501.14659v1</link><description>Structured light (SL) 3D reconstruction captures the precise surface shape ofobjects, providing high-accuracy 3D data essential for industrial inspectionand robotic vision systems. However, current research on optimizing projectionpatterns in SL 3D reconstruction faces two main limitations: each scenerequires separate training of calibration parameters, and optimization isrestricted to specific types of SL, which restricts their application range. Totackle these limitations, we present a unified framework for SL optimization,adaptable to diverse lighting conditions, object types, and different types ofSL. Our framework quickly determines the optimal projection pattern using onlya single projected image. Key contributions include a novel global matchingmethod for projectors, enabling precise projector-camera alignment with justone projected image, and a new projection compensation model with a photometricadjustment module to reduce artifacts from out-of-gamut clipping. Experimentalresults show our method achieves superior decoding accuracy across variousobjects, SL patterns, and lighting conditions, significantly outperformingprevious methods.</description><author>Tinglei Wan, Tonghua Su, Zhongjie Wang</author><pubDate>Fri, 24 Jan 2025 17:29:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14659v1</guid></item><item><title>From One to the Power of Many: Invariance to Multi-LiDAR Perception from Single-Sensor Datasets</title><link>http://arxiv.org/abs/2409.18592v2</link><description>Recently, LiDAR segmentation methods for autonomous vehicles, powered by deepneural networks, have experienced steep growth in performance on classicbenchmarks, such as nuScenes and SemanticKITTI. However, there are still largegaps in performance when deploying models trained on such single-sensor setupsto modern vehicles with multiple high-resolution LiDAR sensors. In this work,we introduce a new metric for feature-level invariance which can serve as aproxy to measure cross-domain generalization without requiring labeled data.Additionally, we propose two application-specific data augmentations, whichfacilitate better transfer to multi-sensor LiDAR setups, when trained onsingle-sensor datasets. We provide experimental evidence on both simulated andreal data, that our proposed augmentations improve invariance across LiDARsetups, leading to improved generalization.</description><author>Marc Uecker, J. Marius Zöllner</author><pubDate>Fri, 24 Jan 2025 17:21:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.18592v2</guid></item><item><title>MedAgentBench: Dataset for Benchmarking LLMs as Agents in Medical Applications</title><link>http://arxiv.org/abs/2501.14654v1</link><description>Recent large language models (LLMs) have demonstrated significantadvancements, particularly in their ability to serve as agents therebysurpassing their traditional role as chatbots. These agents can leverage theirplanning and tool utilization capabilities to address tasks specified at a highlevel. However, a standardized dataset to benchmark the agent capabilities ofLLMs in medical applications is currently lacking, making the evaluation ofLLMs on complex tasks in interactive healthcare environments challenging. Toaddress this gap, we introduce MedAgentBench, a broad evaluation suite designedto assess the agent capabilities of large language models within medicalrecords contexts. MedAgentBench encompasses 100 patient-specificclinically-derived tasks from 10 categories written by human physicians,realistic profiles of 100 patients with over 700,000 data elements, aFHIR-compliant interactive environment, and an accompanying codebase. Theenvironment uses the standard APIs and communication infrastructure used inmodern EMR systems, so it can be easily migrated into live EMR systems.MedAgentBench presents an unsaturated agent-oriented benchmark that currentstate-of-the-art LLMs exhibit some ability to succeed at. The best model(GPT-4o) achieves a success rate of 72%. However, there is still substantialspace for improvement to give the community a next direction to optimize.Furthermore, there is significant variation in performance across taskcategories. MedAgentBench establishes this and is publicly available athttps://github.com/stanfordmlgroup/MedAgentBench , offering a valuableframework for model developers to track progress and drive continuousimprovements in the agent capabilities of large language models within themedical domain.</description><author>Yixing Jiang, Kameron C. Black, Gloria Geng, Danny Park, Andrew Y. Ng, Jonathan H. Chen</author><pubDate>Fri, 24 Jan 2025 17:21:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14654v1</guid></item><item><title>Federated Domain Generalization with Data-free On-server Gradient Matching</title><link>http://arxiv.org/abs/2501.14653v1</link><description>Domain Generalization (DG) aims to learn from multiple known source domains amodel that can generalize well to unknown target domains. One of the keyapproaches in DG is training an encoder which generates domain-invariantrepresentations. However, this approach is not applicable in Federated DomainGeneralization (FDG), where data from various domains are distributed acrossdifferent clients. In this paper, we introduce a novel approach, dubbedFederated Learning via On-server Matching Gradient (FedOMG), which can\emph{efficiently leverage domain information from distributed domains}.Specifically, we utilize the local gradients as information about thedistributed models to find an invariant gradient direction across all domainsthrough gradient inner product maximization. The advantages are two-fold: 1)FedOMG can aggregate the characteristics of distributed models on thecentralized server without incurring any additional communication cost, and 2)FedOMG is orthogonal to many existing FL/FDG methods, allowing for additionalperformance improvements by being seamlessly integrated with them. Extensiveexperimental evaluations on various settings to demonstrate the robustness ofFedOMG compared to other FL/FDG baselines. Our method outperforms recent SOTAbaselines on four FL benchmark datasets (MNIST, EMNIST, CIFAR-10, andCIFAR-100), and three FDG benchmark datasets (PACS, VLCS, and OfficeHome).</description><author>Trong-Binh Nguyen, Minh-Duong Nguyen, Jinsun Park, Quoc-Viet Pham, Won Joo Hwang</author><pubDate>Fri, 24 Jan 2025 17:20:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14653v1</guid></item><item><title>Decoupled SGDA for Games with Intermittent Strategy Communication</title><link>http://arxiv.org/abs/2501.14652v1</link><description>We focus on reducing communication overhead in multiplayer games, wherefrequently exchanging strategies between players is not feasible and playershave noisy or outdated strategies of the other players. We introduce DecoupledSGDA, a novel adaptation of Stochastic Gradient Descent Ascent (SGDA). In thisapproach, players independently update their strategies based on outdatedopponent strategies, with periodic synchronization to align strategies. ForStrongly-Convex-Strongly-Concave (SCSC) games, we demonstrate that DecoupledSGDA achieves near-optimal communication complexity comparable to thebest-known GDA rates. For weakly coupled games where the interaction betweenplayers is lower relative to the non-interactive part of the game, DecoupledSGDA significantly reduces communication costs compared to standard SGDA. Ourfindings extend to multi-player games. To provide insights into the effect ofcommunication frequency and convergence, we extensively study the convergenceof Decoupled SGDA for quadratic minimax problems. Lastly, in settings where thenoise over the players is imbalanced, Decoupled SGDA significantly outperformsfederated minimax methods.</description><author>Ali Zindari, Parham Yazdkhasti, Anton Rodomanov, Tatjana Chavdarova, Sebastian U. Stich</author><pubDate>Fri, 24 Jan 2025 17:18:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14652v1</guid></item><item><title>Controlling Moments with Kernel Stein Discrepancies</title><link>http://arxiv.org/abs/2211.05408v6</link><description>Kernel Stein discrepancies (KSDs) measure the quality of a distributionalapproximation and can be computed even when the target density has anintractable normalizing constant. Notable applications include the diagnosis ofapproximate MCMC samplers and goodness-of-fit tests for unnormalizedstatistical models. The present work analyzes the convergence controlproperties of KSDs. We first show that standard KSDs used for weak convergencecontrol fail to control moment convergence. To address this limitation, we nextprovide sufficient conditions under which alternative diffusion KSDs controlboth moment and weak convergence. As an immediate consequence we develop, foreach $q &gt; 0$, the first KSDs known to exactly characterize $q$-Wassersteinconvergence.</description><author>Heishiro Kanagawa, Alessandro Barp, Arthur Gretton, Lester Mackey</author><pubDate>Fri, 24 Jan 2025 17:16:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.05408v6</guid></item><item><title>Investigating the (De)Composition Capabilities of Large Language Models in Natural-to-Formal Language Conversion</title><link>http://arxiv.org/abs/2501.14649v1</link><description>To achieve generalized and robust natural-to-formal language conversion(N2F), large language models (LLMs) need to have strong capabilities ofdecomposition and composition in N2F when faced with an unfamiliar formallanguage and be able to cope with compositional gaps and counter-intuitivesymbolic names. To investigate whether LLMs have this set of basic capabilitiesin N2F, we propose the DEDC framework. This framework semi-automaticallyperforms sample and task construction, allowing decoupled evaluation of the setof decomposition and composition capabilities of LLMs in N2F. Based on thisframework, we evaluate and analyze the most advanced LLMs, and the mainfindings include that: (1) the LLMs are deficient in both decomposition andcomposition; (2) the LLMs show a wide coverage of error types that can beattributed to deficiencies in natural language understanding and the learningand use of symbolic systems; (3) compositional gaps and counter-intuitivesymbolic names both affect the decomposition and composition of the LLMs. Ourwork provides a new perspective for investigating the basic capabilities ofdecomposition and composition of LLMs in N2F. The detailed analysis ofdeficiencies and attributions can help subsequent improvements of LLMs.</description><author>Ziyao Xu, Houfeng Wang</author><pubDate>Fri, 24 Jan 2025 17:15:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14649v1</guid></item><item><title>SyncAnimation: A Real-Time End-to-End Framework for Audio-Driven Human Pose and Talking Head Animation</title><link>http://arxiv.org/abs/2501.14646v1</link><description>Generating talking avatar driven by audio remains a significant challenge.Existing methods typically require high computational costs and often lacksufficient facial detail and realism, making them unsuitable for applicationsthat demand high real-time performance and visual quality. Additionally, whilesome methods can synchronize lip movement, they still face issues withconsistency between facial expressions and upper body movement, particularlyduring silent periods. In this paper, we introduce SyncAnimation, the firstNeRF-based method that achieves audio-driven, stable, and real-time generationof speaking avatar by combining generalized audio-to-pose matching andaudio-to-expression synchronization. By integrating AudioPose Syncer andAudioEmotion Syncer, SyncAnimation achieves high-precision poses and expressiongeneration, progressively producing audio-synchronized upper body, head, andlip shapes. Furthermore, the High-Synchronization Human Renderer ensuresseamless integration of the head and upper body, and achieves audio-sync lip.The project page can be found at https://syncanimation.github.io</description><author>Yujian Liu, Shidang Xu, Jing Guo, Dingbin Wang, Zairan Wang, Xianfeng Tan, Xiaoli Liu</author><pubDate>Fri, 24 Jan 2025 17:14:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14646v1</guid></item><item><title>Token Turing Machines are Efficient Vision Models</title><link>http://arxiv.org/abs/2409.07613v3</link><description>We propose Vision Token Turing Machines (ViTTM), an efficient, low-latency,memory-augmented Vision Transformer (ViT). Our approach builds on Neural TuringMachines and Token Turing Machines, which were applied to NLP and sequentialvisual understanding tasks. ViTTMs are designed for non-sequential computervision tasks such as image classification and segmentation. Our model createstwo sets of tokens: process tokens and memory tokens; process tokens passthrough encoder blocks and read-write from memory tokens at each encoder blockin the network, allowing them to store and retrieve information from memory. Byensuring that there are fewer process tokens than memory tokens, we are able toreduce the inference time of the network while maintaining its accuracy. OnImageNet-1K, the state-of-the-art ViT-B has median latency of 529.5ms and 81.0%accuracy, while our ViTTM-B is 56% faster (234.1ms), with 2.4 times fewerFLOPs, with an accuracy of 82.9%. On ADE20K semantic segmentation, ViT-Bachieves 45.65mIoU at 13.8 frame-per-second (FPS) whereas our ViTTM-B modelacheives a 45.17 mIoU with 26.8 FPS (+94%).</description><author>Purvish Jajal, Nick John Eliopoulos, Benjamin Shiue-Hal Chou, George K. Thiruvathukal, James C. Davis, Yung-Hsiang Lu</author><pubDate>Fri, 24 Jan 2025 17:06:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.07613v3</guid></item><item><title>Whisper D-SGD: Correlated Noise Across Agents for Differentially Private Decentralized Learning</title><link>http://arxiv.org/abs/2501.14644v1</link><description>Decentralized learning enables distributed agents to train a shared machinelearning model through local computation and peer-to-peer communication.Although each agent retains its dataset locally, the communication of localmodels can still expose private information to adversaries. To mitigate thesethreats, local differential privacy (LDP) injects independent noise per agent,but it suffers a larger utility gap than central differential privacy (CDP). Weintroduce Whisper D-SGD, a novel covariance-based approach that generatescorrelated privacy noise across agents, unifying several state-of-the-artmethods as special cases. By leveraging network topology and mixing weights,Whisper D-SGD optimizes the noise covariance to achieve network-wide noisecancellation. Experimental results show that Whisper D-SGD cancels more noisethan existing pairwise-correlation schemes, substantially narrowing the CDP-LDPgap and improving model performance under the same privacy guarantees.</description><author>Angelo Rodio, Zheng Chen, Erik G. Larsson</author><pubDate>Fri, 24 Jan 2025 17:05:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14644v1</guid></item><item><title>Modyn: Data-Centric Machine Learning Pipeline Orchestration</title><link>http://arxiv.org/abs/2312.06254v3</link><description>In real-world machine learning (ML) pipelines, datasets are continuouslygrowing. Models must incorporate this new training data to improvegeneralization and adapt to potential distribution shifts. The cost of modelretraining is proportional to how frequently the model is retrained and howmuch data it is trained on, which makes the naive approach of retraining fromscratch each time impractical. We present Modyn, a data-centric end-to-end machine learning platform.Modyn's ML pipeline abstraction enables users to declaratively describepolicies for continuously training a model on a growing dataset. Modynpipelines allow users to apply data selection policies (to reduce the number ofdata points) and triggering policies (to reduce the number of trainings). Modynexecutes and orchestrates these continuous ML training pipelines. The system isopen-source and comes with an ecosystem of benchmark datasets, models, andtooling. We formally discuss how to measure the performance of ML pipelines byintroducing the concept of composite models, enabling fair comparison ofpipelines with different data selection and triggering policies. We empiricallyanalyze how various data selection and triggering policies impact modelaccuracy, and also show that Modyn enables high throughput training withsample-level data selection.</description><author>Maximilian Böther, Ties Robroek, Viktor Gsteiger, Robin Holzinger, Xianzhe Ma, Pınar Tözün, Ana Klimovic</author><pubDate>Fri, 24 Jan 2025 17:04:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06254v3</guid></item><item><title>Towards Scalable Topological Regularizers</title><link>http://arxiv.org/abs/2501.14641v1</link><description>Latent space matching, which consists of matching distributions of featuresin latent space, is a crucial component for tasks such as adversarial attacksand defenses, domain adaptation, and generative modelling. Metrics forprobability measures, such as Wasserstein and maximum mean discrepancy, arecommonly used to quantify the differences between such distributions. However,these are often costly to compute, or do not appropriately take the geometricand topological features of the distributions into consideration. Persistenthomology is a tool from topological data analysis which quantifies themulti-scale topological structure of point clouds, and has recently been usedas a topological regularizer in learning tasks. However, computation costspreclude larger scale computations, and discontinuities in the gradient lead tounstable training behavior such as in adversarial tasks. We propose the use ofprincipal persistence measures, based on computing the persistent homology of alarge number of small subsamples, as a topological regularizer. We provide aparallelized GPU implementation of this regularizer, and prove that gradientsare continuous for smooth densities. Furthermore, we demonstrate the efficacyof this regularizer on shape matching, image generation, and semi-supervisedlearning tasks, opening the door towards a scalable regularizer for topologicalfeatures.</description><author>Hiu-Tung Wong, Darrick Lee, Hong Yan</author><pubDate>Fri, 24 Jan 2025 17:02:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14641v1</guid></item><item><title>A Paired Autoencoder Framework for Inverse Problems via Bayes Risk Minimization</title><link>http://arxiv.org/abs/2501.14636v1</link><description>In this work, we describe a new data-driven approach for inverse problemsthat exploits technologies from machine learning, in particular autoencodernetwork structures. We consider a paired autoencoder framework, where twoautoencoders are used to efficiently represent the input and target spacesseparately and optimal mappings are learned between latent spaces, thusenabling forward and inverse surrogate mappings. We focus on interpretationsusing Bayes risk and empirical Bayes risk minimization, and we provide varioustheoretical results and connections to existing works on low-rank matrixapproximations. Similar to end-to-end approaches, our paired approach creates asurrogate model for forward propagation and regularized inversion. However, ourapproach outperforms existing approaches in scenarios where training data forunsupervised learning are readily available but training pairs for supervisedlearning are scarce. Furthermore, we show that cheaply computable evaluationmetrics are available through this framework and can be used to predict whetherthe solution for a new sample should be predicted well.</description><author>Emma Hart, Julianne Chung, Matthias Chung</author><pubDate>Fri, 24 Jan 2025 16:55:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14636v1</guid></item><item><title>Optimal Transport Barycenter via Nonconvex-Concave Minimax Optimization</title><link>http://arxiv.org/abs/2501.14635v1</link><description>The optimal transport barycenter (a.k.a. Wasserstein barycenter) is afundamental notion of averaging that extends from the Euclidean space to theWasserstein space of probability distributions. Computation of theunregularized barycenter for discretized probability distributions on pointclouds is a challenging task when the domain dimension $d &gt; 1$. Most practicalalgorithms for approximating the barycenter problem are based on entropicregularization. In this paper, we introduce a nearly linear time $O(m \log{m})$and linear space complexity $O(m)$ primal-dual algorithm, theWasserstein-Descent $\dot{\mathbb{H}}^1$-Ascent (WDHA) algorithm, for computingthe exact barycenter when the input probability density functions arediscretized on an $m$-point grid. The key success of the WDHA algorithm hingeson alternating between two different yet closely related Wasserstein andSobolev optimization geometries for the primal barycenter and dual Kantorovichpotential subproblems. Under reasonable assumptions, we establish theconvergence rate and iteration complexity of WDHA to its stationary point whenthe step size is appropriately chosen. Superior computational efficacy,scalability, and accuracy over the existing Sinkhorn-type algorithms aredemonstrated on high-resolution (e.g., $1024 \times 1024$ images) 2D syntheticand real data.</description><author>Kaheon Kim, Rentian Yao, Changbo Zhu, Xiaohui Chen</author><pubDate>Fri, 24 Jan 2025 16:55:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14635v1</guid></item><item><title>Recommending Actionable Strategies: A Semantic Approach to Integrating Analytical Frameworks with Decision Heuristics</title><link>http://arxiv.org/abs/2501.14634v1</link><description>We present a novel approach for recommending actionable strategies byintegrating strategic frameworks with decision heuristics through semanticanalysis. While strategy frameworks provide systematic models for assessmentand planning, and decision heuristics encode experiential knowledge,thesetraditions have historically remained separate. Our methodology bridges thisgap using advanced natural language processing (NLP), demonstrated throughintegrating frameworks like the 6C model with the Thirty-Six Stratagems. Theapproach employs vector space representations and semantic similaritycalculations to map framework parameters to heuristic patterns, supported by acomputational architecture that combines deep semantic processing withconstrained use of Large Language Models. By processing both primary contentand secondary elements (diagrams, matrices) as complementary linguisticrepresentations, we demonstrate effectiveness through corporate strategy casestudies. The methodology generalizes to various analytical frameworks andheuristic sets, culminating in a plug-and-play architecture for generatingrecommender systems that enable cohesive integration of strategic frameworksand decision heuristics into actionable guidance.</description><author>Renato Ghisellini, Remo Pareschi, Marco Pedroni, Giovanni Battista Raggi</author><pubDate>Fri, 24 Jan 2025 16:53:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14634v1</guid></item><item><title>Extracting Problem Structure with LLMs for Optimized SAT Local Search</title><link>http://arxiv.org/abs/2501.14630v1</link><description>Local search preprocessing makes Conflict-Driven Clause Learning (CDCL)solvers faster by providing high-quality starting points and modern SAT solvershave incorporated this technique into their preprocessing steps. However, thesetools rely on basic strategies that miss the structural patterns in problems.We present a method that applies Large Language Models (LLMs) to analyzePython-based encoding code. This reveals hidden structural patterns in howproblems convert into SAT. Our method automatically generates specialized localsearch algorithms that find these patterns and use them to create stronginitial assignments. This works for any problem instance from the same encodingtype. Our tests show encouraging results, achieving faster solving timescompared to baseline preprocessing systems.</description><author>André Schilder, Stefan Szeider</author><pubDate>Fri, 24 Jan 2025 16:49:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14630v1</guid></item><item><title>LaMSUM: Amplifying Voices Against Harassment through LLM Guided Extractive Summarization of User Incident Reports</title><link>http://arxiv.org/abs/2406.15809v4</link><description>Citizen reporting platforms like Safe City in India help the public andauthorities stay informed about sexual harassment incidents. However, the highvolume of data shared on these platforms makes reviewing each individual casechallenging. Therefore, a summarization algorithm capable of processing andunderstanding various Indian code-mixed languages is essential. In recentyears, Large Language Models (LLMs) have shown exceptional performance in NLPtasks, including summarization. LLMs inherently produce abstractive summariesby paraphrasing the original text, while the generation of extractive summaries- selecting specific subsets from the original text - through LLMs remainslargely unexplored. Moreover, LLMs have a limited context window size,restricting the amount of data that can be processed at once. We tackle thesechallenge by introducing LaMSUM, a novel multi-level framework designed togenerate extractive summaries for large collections of Safe City posts usingLLMs. LaMSUM integrates summarization with different voting methods to achieverobust summaries. Extensive evaluation using three popular LLMs (Llama, Mistraland GPT-4o) demonstrates that LaMSUM outperforms state-of-the-art extractivesummarization methods for Safe City posts. Overall, this work represents one ofthe first attempts to achieve extractive summarization through LLMs, and islikely to support stakeholders by offering a comprehensive overview andenabling them to develop effective policies to minimize incidents ofunwarranted harassment.</description><author>Garima Chhikara, Anurag Sharma, V. Gurucharan, Kripabandhu Ghosh, Abhijnan Chakraborty</author><pubDate>Fri, 24 Jan 2025 16:45:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15809v4</guid></item><item><title>Accelerated Preference Elicitation with LLM-Based Proxies</title><link>http://arxiv.org/abs/2501.14625v1</link><description>Bidders in combinatorial auctions face significant challenges when describingtheir preferences to an auctioneer. Classical work on preference elicitationfocuses on query-based techniques inspired from proper learning--often viaproxies that interface between bidders and an auction mechanism--toincrementally learn bidder preferences as needed to compute efficientallocations. Although such elicitation mechanisms enjoy theoretical queryefficiency, the amount of communication required may still be too cognitivelytaxing in practice. We propose a family of efficient LLM-based proxy designs for elicitingpreferences from bidders using natural language. Our proposed mechanismcombines LLM pipelines and DNF-proper-learning techniques to quicklyapproximate preferences when communication is limited. To validate ourapproach, we create a testing sandbox for elicitation mechanisms thatcommunicate in natural language. In our experiments, our most promising LLMproxy design reaches approximately efficient outcomes with five times fewerqueries than classical proper learning based elicitation mechanisms.</description><author>David Huang, Francisco Marmolejo-Cossío, Edwin Lock, David Parkes</author><pubDate>Fri, 24 Jan 2025 16:42:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14625v1</guid></item><item><title>ACT-JEPA: Joint-Embedding Predictive Architecture Improves Policy Representation Learning</title><link>http://arxiv.org/abs/2501.14622v1</link><description>Learning efficient representations for decision-making policies is achallenge in imitation learning (IL). Current IL methods require expertdemonstrations, which are expensive to collect. Consequently, they often haveunderdeveloped world models. Self-supervised learning (SSL) offers analternative by allowing models to learn from diverse, unlabeled data, includingfailures. However, SSL methods often operate in raw input space, making theminefficient. In this work, we propose ACT-JEPA, a novel architecture thatintegrates IL and SSL to enhance policy representations. We train a policy topredict (1) action sequences and (2) abstract observation sequences. The firstobjective uses action chunking to improve action prediction and reducecompounding errors. The second objective extends this idea of chunking bypredicting abstract observation sequences. We utilize Joint-EmbeddingPredictive Architecture to predict in abstract representation space, allowingthe model to filter out irrelevant details, improve efficiency, and develop arobust world model. Our experiments show that ACT-JEPA improves the quality ofrepresentations by learning temporal environment dynamics. Additionally, themodel's ability to predict abstract observation sequences results inrepresentations that effectively generalize to action sequence prediction.ACT-JEPA performs on par with established baselines across a range ofdecision-making tasks.</description><author>Aleksandar Vujinovic, Aleksandar Kovacevic</author><pubDate>Fri, 24 Jan 2025 16:41:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14622v1</guid></item><item><title>Towards Human-Guided, Data-Centric LLM Co-Pilots</title><link>http://arxiv.org/abs/2501.10321v2</link><description>Machine learning (ML) has the potential to revolutionize various domains, butits adoption is often hindered by the disconnect between the needs of domainexperts and translating these needs into robust and valid ML tools. Despiterecent advances in LLM-based co-pilots to democratize ML for non-technicaldomain experts, these systems remain predominantly focused on model-centricaspects while overlooking critical data-centric challenges. This limitation isproblematic in complex real-world settings where raw data often containscomplex issues, such as missing values, label noise, and domain-specificnuances requiring tailored handling. To address this we introduce CliMB-DC, ahuman-guided, data-centric framework for LLM co-pilots that combines advanceddata-centric tools with LLM-driven reasoning to enable robust, context-awaredata processing. At its core, CliMB-DC introduces a novel, multi-agentreasoning system that combines a strategic coordinator for dynamic planning andadaptation with a specialized worker agent for precise execution. Domainexpertise is then systematically incorporated to guide the reasoning processusing a human-in-the-loop approach. To guide development, we formalize ataxonomy of key data-centric challenges that co-pilots must address.Thereafter, to address the dimensions of the taxonomy, we integratestate-of-the-art data-centric tools into an extensible, open-sourcearchitecture, facilitating the addition of new tools from the researchcommunity. Empirically, using real-world healthcare datasets we demonstrateCliMB-DC's ability to transform uncurated datasets into ML-ready formats,significantly outperforming existing co-pilot baselines for handlingdata-centric challenges. CliMB-DC promises to empower domain experts fromdiverse domains -- healthcare, finance, social sciences and more -- to activelyparticipate in driving real-world impact using ML.</description><author>Evgeny Saveliev, Jiashuo Liu, Nabeel Seedat, Anders Boyd, Mihaela van der Schaar</author><pubDate>Fri, 24 Jan 2025 16:37:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10321v2</guid></item><item><title>Funzac at CoMeDi Shared Task: Modeling Annotator Disagreement from Word-In-Context Perspectives</title><link>http://arxiv.org/abs/2501.14617v1</link><description>In this work, we evaluate annotator disagreement in Word-in-Context (WiC)tasks exploring the relationship between contextual meaning and disagreement aspart of the CoMeDi shared task competition. While prior studies have modeleddisagreement by analyzing annotator attributes with single-sentence inputs,this shared task incorporates WiC to bridge the gap between sentence-levelsemantic representation and annotator judgment variability. We describe threedifferent methods that we developed for the shared task, including a featureenrichment approach that combines concatenation, element-wise differences,products, and cosine similarity, Euclidean and Manhattan distances to extendcontextual embedding representations, a transformation by Adapter blocks toobtain task-specific representations of contextual embeddings, and classifiersof varying complexities, including ensembles. The comparison of our methodsdemonstrates improved performance for methods that include enriched andtask-specfic features. While the performance of our method falls short incomparison to the best system in subtask 1 (OGWiC), it is competitive to theofficial evaluation results in subtask 2 (DisWiC).</description><author>Olufunke O. Sarumi, Charles Welch, Lucie Flek, Jörg Schlötterer</author><pubDate>Fri, 24 Jan 2025 16:36:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14617v1</guid></item><item><title>Single-neuron deep generative model uncovers underlying physics of neuronal activity in Ca imaging data</title><link>http://arxiv.org/abs/2501.14615v1</link><description>Calcium imaging has become a powerful alternative to electrophysiology forstudying neuronal activity, offering spatial resolution and the ability tomeasure large populations of neurons in a minimally invasive manner. Thistechnique has broad applications in neuroscience, neuroengineering, andmedicine, enabling researchers to explore the relationship between neuronlocation and activity. Recent advancements in deep generative models (DGMs)have facilitated the modeling of neuronal population dynamics, uncoveringlatent representations that provide insights into behavior prediction andneuronal variance. However, these models often rely on spike inferencealgorithms and primarily focus on population-level dynamics, limiting theirapplicability for single-neuron analyses. To address this gap, we propose anovel framework for single-neuron representation learning using autoregressivevariational autoencoders (AVAEs). Our approach embeds individual neurons'spatiotemporal signals into a reduced-dimensional space without the need forspike inference algorithms. The AVAE excels over traditional linear methods bygenerating more informative and discriminative latent representations,improving tasks such as visualization, clustering, and the understanding ofneuronal activity. Additionally, the reconstruction performance of the AVAEoutperforms the state of the art, demonstrating its ability to accuratelyrecover the original fluorescence signal from the learned representation. Usingrealistic simulations, we show that our model captures underlying physicalproperties and connectivity patterns, enabling it to distinguish betweendifferent firing and connectivity types. These findings position the AVAE as aversatile and powerful tool for advancing single-neuron analysis and lays thegroundwork for future integration of multimodal single-cell datasets inneuroscience.</description><author>Jordi Abante, Angelo Piga, Berta Ros, Clara F López-León, Josep M Canals, Jordi Soriano</author><pubDate>Fri, 24 Jan 2025 16:33:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14615v1</guid></item><item><title>Leveraging Spatial Cues from Cochlear Implant Microphones to Efficiently Enhance Speech Separation in Real-World Listening Scenes</title><link>http://arxiv.org/abs/2501.14610v1</link><description>Speech separation approaches for single-channel, dry speech mixtures havesignificantly improved. However, real-world spatial and reverberant acousticenvironments remain challenging, limiting the effectiveness of these approachesfor assistive hearing devices like cochlear implants (CIs). To address this, wequantify the impact of real-world acoustic scenes on speech separation andexplore how spatial cues can enhance separation quality efficiently. We analyzeperformance based on implicit spatial cues (inherent in the acoustic input andlearned by the model) and explicit spatial cues (manually calculated spatialfeatures added as auxiliary inputs). Our findings show that spatial cues (bothimplicit and explicit) improve separation for mixtures with spatially separatedand nearby talkers. Furthermore, spatial cues enhance separation when spectralcues are ambiguous, such as when voices are similar. Explicit spatial cues areparticularly beneficial when implicit spatial cues are weak. For instance,single CI microphone recordings provide weaker implicit spatial cues thanbilateral CIs, but even single CIs benefit from explicit cues. These resultsemphasize the importance of training models on real-world data to improvegeneralizability in everyday listening scenarios. Additionally, our statisticalanalyses offer insights into how data properties influence model performance,supporting the development of efficient speech separation approaches for CIsand other assistive devices in real-world settings.</description><author>Feyisayo Olalere, Kiki van der Heijden, Christiaan H. Stronks, Jeroen Briaire, Johan HM Frijns, Marcel van Gerven</author><pubDate>Fri, 24 Jan 2025 16:30:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14610v1</guid></item><item><title>ReferDINO: Referring Video Object Segmentation with Visual Grounding Foundations</title><link>http://arxiv.org/abs/2501.14607v1</link><description>Referring video object segmentation (RVOS) aims to segment target objectsthroughout a video based on a text description. Despite notable progress inrecent years, current RVOS models remain struggle to handle complicated objectdescriptions due to their limited video-language understanding. To address thislimitation, we present \textbf{ReferDINO}, an end-to-end RVOS model thatinherits strong vision-language understanding from the pretrained visualgrounding foundation models, and is further endowed with effective temporalunderstanding and object segmentation capabilities. In ReferDINO, we contributethree technical innovations for effectively adapting the foundation models toRVOS: 1) an object-consistent temporal enhancer that capitalizes on thepretrained object-text representations to enhance temporal understanding andobject consistency; 2) a grounding-guided deformable mask decoder thatintegrates text and grounding conditions to generate accurate object masks; 3)a confidence-aware query pruning strategy that significantly improves theobject decoding efficiency without compromising performance. We conductextensive experiments on five public RVOS benchmarks to demonstrate that ourproposed ReferDINO outperforms state-of-the-art methods significantly. Projectpage: \url{https://isee-laboratory.github.io/ReferDINO}</description><author>Tianming Liang, Kun-Yu Lin, Chaolei Tan, Jianguo Zhang, Wei-Shi Zheng, Jian-Fang Hu</author><pubDate>Fri, 24 Jan 2025 16:24:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14607v1</guid></item><item><title>3DLabelProp: Geometric-Driven Domain Generalization for LiDAR Semantic Segmentation in Autonomous Driving</title><link>http://arxiv.org/abs/2501.14605v1</link><description>Domain generalization aims to find ways for deep learning models to maintaintheir performance despite significant domain shifts between training andinference datasets. This is particularly important for models that need to berobust or are costly to train. LiDAR perception in autonomous driving isimpacted by both of these concerns, leading to the emergence of variousapproaches. This work addresses the challenge by proposing a geometry-basedapproach, leveraging the sequential structure of LiDAR sensors, which sets itapart from the learning-based methods commonly found in the literature. Theproposed method, called 3DLabelProp, is applied on the task of LiDAR SemanticSegmentation (LSS). Through extensive experimentation on seven datasets, it isdemonstrated to be a state-of-the-art approach, outperforming both naive andother domain generalization methods.</description><author>Jules Sanchez, Jean-Emmanuel Deschaud, François Goulette</author><pubDate>Fri, 24 Jan 2025 16:22:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14605v1</guid></item><item><title>Inverse Evolution Data Augmentation for Neural PDE Solvers</title><link>http://arxiv.org/abs/2501.14604v1</link><description>Neural networks have emerged as promising tools for solving partialdifferential equations (PDEs), particularly through the application of neuraloperators. Training neural operators typically requires a large amount oftraining data to ensure accuracy and generalization. In this paper, we proposea novel data augmentation method specifically designed for training neuraloperators on evolution equations. Our approach utilizes insights from inverseprocesses of these equations to efficiently generate data from randominitialization that are combined with original data. To further enhance theaccuracy of the augmented data, we introduce high-order inverse evolutionschemes. These schemes consist of only a few explicit computation steps, yetthe resulting data pairs can be proven to satisfy the corresponding implicitnumerical schemes. In contrast to traditional PDE solvers that require smalltime steps or implicit schemes to guarantee accuracy, our data augmentationmethod employs explicit schemes with relatively large time steps, therebysignificantly reducing computational costs. Accuracy and efficacy experimentsconfirm the effectiveness of our approach. Additionally, we validate ourapproach through experiments with the Fourier Neural Operator and UNet on threecommon evolution equations that are Burgers' equation, the Allen-Cahn equationand the Navier-Stokes equation. The results demonstrate a significantimprovement in the performance and robustness of the Fourier Neural Operatorwhen coupled with our inverse evolution data augmentation method.</description><author>Chaoyu Liu, Chris Budd, Carola-Bibiane Schönlieb</author><pubDate>Fri, 24 Jan 2025 16:20:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14604v1</guid></item><item><title>Relaxed Equivariance via Multitask Learning</title><link>http://arxiv.org/abs/2410.17878v2</link><description>Incorporating equivariance as an inductive bias into deep learningarchitectures to take advantage of the data symmetry has been successful inmultiple applications, such as chemistry and dynamical systems. In particular,roto-translations are crucial for effectively modeling geometric graphs andmolecules, where understanding the 3D structures enhances generalization.However, equivariant models often pose challenges due to their highcomputational complexity. In this paper, we introduce REMUL, a trainingprocedure for approximating equivariance with multitask learning. We show thatunconstrained models (which do not build equivariance into the architecture)can learn approximate symmetries by minimizing an additional simpleequivariance loss. By formulating equivariance as a new learning objective, wecan control the level of approximate equivariance in the model. Our methodachieves competitive performance compared to equivariant baselines while being$10 \times$ faster at inference and $2.5 \times$ at training.</description><author>Ahmed A. Elhag, T. Konstantin Rusch, Francesco Di Giovanni, Michael Bronstein</author><pubDate>Fri, 24 Jan 2025 16:19:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17878v2</guid></item><item><title>Age and Power Minimization via Meta-Deep Reinforcement Learning in UAV Networks</title><link>http://arxiv.org/abs/2501.14603v1</link><description>Age-of-information (AoI) and transmission power are crucial performancemetrics in low energy wireless networks, where information freshness is ofparamount importance. This study examines a power-limited internet of things(IoT) network supported by a flying unmanned aerial vehicle(UAV) that collectsdata. Our aim is to optimize the UAV flight trajectory and scheduling policy tominimize a varying AoI and transmission power combination. To tackle thisvariation, this paper proposes a meta-deep reinforcement learning (RL) approachthat integrates deep Q-networks (DQNs) with model-agnostic meta-learning(MAML). DQNs determine optimal UAV decisions, while MAML enables scalabilityacross varying objective functions. Numerical results indicate that theproposed algorithm converges faster and adapts to new objectives moreeffectively than traditional deep RL methods, achieving minimal AoI andtransmission power overall.</description><author>Sankani Sarathchandra, Eslam Eldeeb, Mohammad Shehab, Hirley Alves, Konstantin Mikhaylov, Mohamed-Slim Alouini</author><pubDate>Fri, 24 Jan 2025 16:17:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14603v1</guid></item><item><title>ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image Captioning</title><link>http://arxiv.org/abs/2412.19289v3</link><description>Recent lightweight image captioning models using retrieved data mainly focuson text prompts. However, previous works only utilize the retrieved text astext prompts, and the visual information relies only on the CLIP visualembedding. Because of this issue, there is a limitation that the imagedescriptions inherent in the prompt are not sufficiently reflected in thevisual embedding space. To tackle this issue, we propose ViPCap, a novelretrieval text-based visual prompt for lightweight image captioning. ViPCapleverages the retrieved text with image information as visual prompts toenhance the ability of the model to capture relevant visual information. Bymapping text prompts into the CLIP space and generating multiple randomizedGaussian distributions, our method leverages sampling to explore randomlyaugmented distributions and effectively retrieves the semantic features thatcontain image information. These retrieved features are integrated into theimage and designated as the visual prompt, leading to performance improvementson the datasets such as COCO, Flickr30k, and NoCaps. Experimental resultsdemonstrate that ViPCap significantly outperforms prior lightweight captioningmodels in efficiency and effectiveness, demonstrating the potential for aplug-and-play solution. The source code is available athttps://github.com/taewhankim/VIPCAP.</description><author>Taewhan Kim, Soeun Lee, Si-Woo Kim, Dong-Jin Kim</author><pubDate>Fri, 24 Jan 2025 16:16:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19289v3</guid></item><item><title>Random-Key Algorithms for Optimizing Integrated Operating Room Scheduling</title><link>http://arxiv.org/abs/2501.10243v2</link><description>Efficient surgery room scheduling is essential for hospital efficiency,patient satisfaction, and resource utilization. This study addresses thischallenge by introducing a novel concept of Random-Key Optimizer (RKO),rigorously tested on literature and new, real-world inspired instances. Ourcombinatorial optimization problem incorporates multi-room scheduling,equipment scheduling, and complex availability constraints for rooms, patients,and surgeons, facilitating rescheduling and enhancing operational flexibility.The RKO approach represents solutions as points in a continuous space, whichare then mapped in the problem solution space via a deterministic functionknown as a decoder. The core idea is to operate metaheuristics and heuristicsin the random-key space, unaware of the original solution space. We design theBiased Random-Key Genetic Algorithm with $Q$-Learning, Simulated Annealing, andIterated Local Search for use within an RKO framework, employing a singledecoder function. The proposed metaheuristics are complemented by lower-boundformulations, providing optimal gaps for evaluating the effectiveness of theheuristic results. Our results demonstrate significant lower and upper boundsimprovements for the literature instances, notably proving one optimal result.Furthermore, the best-proposed metaheuristic efficiently generates schedulesfor the newly introduced instances, even in highly constrained scenarios. Thisresearch offers valuable insights and practical solutions for improving surgeryscheduling processes, offering tangible benefits to hospitals by optimisingresource allocation, reducing patient wait times, and enhancing overalloperational efficiency.</description><author>Bruno Salezze Vieira, Eduardo Machado Silva, Antonio Augusto Chaves</author><pubDate>Fri, 24 Jan 2025 15:59:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10243v2</guid></item><item><title>Geometric Mean Improves Loss For Few-Shot Learning</title><link>http://arxiv.org/abs/2501.14593v1</link><description>Few-shot learning (FSL) is a challenging task in machine learning, demandinga model to render discriminative classification by using only a few labeledsamples. In the literature of FSL, deep models are trained in a manner ofmetric learning to provide metric in a feature space which is wellgeneralizable to classify samples of novel classes; in the space, even a fewamount of labeled training examples can construct an effective classifier. Inthis paper, we propose a novel FSL loss based on \emph{geometric mean} to embeddiscriminative metric into deep features. In contrast to the other losses suchas utilizing arithmetic mean in softmax-based formulation, the proposed methodleverages geometric mean to aggregate pair-wise relationships among samples forenhancing discriminative metric across class categories. The proposed loss isnot only formulated in a simple form but also is thoroughly analyzed intheoretical ways to reveal its favorable characteristics which are favorablefor learning feature metric in FSL. In the experiments on few-shot imageclassification tasks, the method produces competitive performance in comparisonto the other losses.</description><author>Tong Wu, Takumi Kobayashi</author><pubDate>Fri, 24 Jan 2025 15:56:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14593v1</guid></item><item><title>Improved Vessel Segmentation with Symmetric Rotation-Equivariant U-Net</title><link>http://arxiv.org/abs/2501.14592v1</link><description>Automated segmentation plays a pivotal role in medical image analysis andcomputer-assisted interventions. Despite the promising performance of existingmethods based on convolutional neural networks (CNNs), they neglect usefulequivariant properties for images, such as rotational and reflectionequivariance. This limitation can decrease performance and lead to inconsistentpredictions, especially in applications like vessel segmentation where explicitorientation is absent. While existing equivariant learning approaches attemptto mitigate these issues, they substantially increase learning cost, modelsize, or both. To overcome these challenges, we propose a novel application ofan efficient symmetric rotation-equivariant (SRE) convolutional (SRE-Conv)kernel implementation to the U-Net architecture, to learn rotation andreflection-equivariant features, while also reducing the model sizedramatically. We validate the effectiveness of our method through improvedsegmentation performance on retina vessel fundus imaging. Our proposed SREU-Net not only significantly surpasses standard U-Net in handling rotatedimages, but also outperforms existing equivariant learning methods and does sowith a reduced number of trainable parameters and smaller memory cost. The codeis available at https://github.com/OnofreyLab/sre_conv_segm_isbi2025.</description><author>Jiazhen Zhang, Yuexi Du, Nicha C. Dvornek, John A. Onofrey</author><pubDate>Fri, 24 Jan 2025 15:54:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14592v1</guid></item><item><title>An Investigation of Prompt Variations for Zero-shot LLM-based Rankers</title><link>http://arxiv.org/abs/2406.14117v3</link><description>We provide a systematic understanding of the impact of specific componentsand wordings used in prompts on the effectiveness of rankers based on zero-shotLarge Language Models (LLMs). Several zero-shot ranking methods based on LLMshave recently been proposed. Among many aspects, methods differ across (1) theranking algorithm they implement, e.g., pointwise vs. listwise, (2) thebackbone LLMs used, e.g., GPT3.5 vs. FLAN-T5, (3) the components and wordingused in prompts, e.g., the use or not of role-definition (role-playing) and theactual words used to express this. It is currently unclear whether performancedifferences are due to the underlying ranking algorithm, or because of spuriousfactors such as better choice of words used in prompts. This confusion risks toundermine future research. Through our large-scale experimentation andanalysis, we find that ranking algorithms do contribute to differences betweenmethods for zero-shot LLM ranking. However, so do the LLM backbones -- but evenmore importantly, the choice of prompt components and wordings affect theranking. In fact, in our experiments, we find that, at times, these latterelements have more impact on the ranker's effectiveness than the actual rankingalgorithms, and that differences among ranking methods become more blurred whenprompt variations are considered.</description><author>Shuoqi Sun, Shengyao Zhuang, Shuai Wang, Guido Zuccon</author><pubDate>Fri, 24 Jan 2025 15:50:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14117v3</guid></item><item><title>Data Assetization via Resources-decoupled Federated Learning</title><link>http://arxiv.org/abs/2501.14588v1</link><description>With the development of the digital economy, data is increasingly recognizedas an essential resource for both work and life. However, due to privacyconcerns, data owners tend to maximize the value of data through informationflow rather than direct data transfer. Federated learning (FL) provides aneffective approach to collaborative training models while preserving privacy.However, different data owners not only have variations in the quantity andquality of their data resources but also face mismatches between data andcomputing resources as model parameters and training data grow. Thesechallenges hinder data owners' willingness to participate and reduce theeffectiveness of data assetization. In this work, we first identify theresource-decoupled FL environment, which includes model owners, data owners,and computing centers. We design a Tripartite Stackelberg Model andtheoretically analyze the Stackelberg-Nash Equilibrium (SNE) for participantsto optimize global utility. We propose the Quality-aware DynamicResources-decoupled FL algorithm (QD-RDFL), in which we derive and solve theoptimal strategies of all parties to achieve SHE using backward induction, anda dynamic optimization mechanism is designed to improve the optimal strategyprofile by evaluating the contribution of data quality from data owners to theglobal model during real training. Our comprehensive experiments demonstratethat our method effectively encourages the linkage of the three partiesinvolved, maximizing global utility and data asset value.</description><author>Jianzhe Zhao, Feida Zhu, Lingyan He, Zixin Tang, Mingce Gao, Shiyu Yang, Guibing Guo</author><pubDate>Fri, 24 Jan 2025 15:49:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14588v1</guid></item><item><title>Visual Localization via Semantic Structures in Autonomous Photovoltaic Power Plant Inspection</title><link>http://arxiv.org/abs/2501.14587v1</link><description>Inspection systems utilizing unmanned aerial vehicles (UAVs) equipped withthermal cameras are increasingly popular for the maintenance of photovoltaic(PV) power plants. However, automation of the inspection task is a challengingproblem as it requires precise navigation to capture images from optimaldistances and viewing angles. This paper presents a novel localization pipeline that directly integrates PVmodule detection with UAV navigation, allowing precise positioning duringinspection. Detections are used to identify the power plant structures in theimage and associate these with the power plant model. We define visuallyrecognizable anchor points for the initial association and use object trackingto discern global associations. We present three distinct methods for visualsegmentation of PV modules based on traditional computer vision, deep learning,and their fusion, and we evaluate their performance in relation to the proposedlocalization pipeline. The presented methods were verified and evaluated using custom aerialinspection data sets, demonstrating their robustness and applicability forreal-time navigation. Additionally, we evaluate the influence of the powerplant model's precision on the localization methods.</description><author>Viktor Kozák, Karel Košnar, Jan Chudoba, Miroslav Kulich, Libor Přeučil</author><pubDate>Fri, 24 Jan 2025 15:48:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14587v1</guid></item><item><title>Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering Tasks</title><link>http://arxiv.org/abs/2401.07494v5</link><description>Computational efficiency and robustness are essential in process modeling,optimization, and control for real-world engineering applications. While neuralnetwork-based approaches have gained significant attention in recent years,conventional neural networks often fail to address these two critical aspectssimultaneously or even independently. Inspired by natural physical systems andestablished literature, input convex architectures are known to enhancecomputational efficiency in optimization tasks, whereas Lipschitz-constrainedarchitectures improve robustness. However, combining these properties within asingle model requires careful review, as inappropriate methods for enforcingone property can undermine the other. To overcome this, we introduce a novelnetwork architecture, termed Input Convex Lipschitz Recurrent Neural Networks(ICLRNNs). This architecture seamlessly integrates the benefits of convexityand Lipschitz continuity, enabling fast and robust neural network-basedmodeling and optimization. The ICLRNN outperforms existing recurrent units inboth computational efficiency and robustness. Additionally, it has beensuccessfully applied to practical engineering scenarios, such as modeling andcontrol of chemical process and the modeling and real-world solar irradianceprediction for solar PV system planning at LHT Holdings in Singapore. Sourcecode is available at https://github.com/killingbear999/ICLRNN.</description><author>Zihao Wang, Zhe Wu</author><pubDate>Fri, 24 Jan 2025 15:48:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07494v5</guid></item><item><title>How VADER is your AI? Towards a definition of artificial intelligence systems appropriate for regulation</title><link>http://arxiv.org/abs/2402.05048v3</link><description>Artificial intelligence (AI) has driven many information and communicationtechnology (ICT) breakthroughs. Nonetheless, the scope of ICT systems hasexpanded far beyond AI since the Turing test proposal. Critically, recent AIregulation proposals adopt AI definitions affecting ICT techniques, approaches,and systems that are not AI. In some cases, even works from mathematics,statistics, and engineering would be affected. Worryingly, AI misdefinitionsare observed from Western societies to the Global South. In this paper, wepropose a framework to score how validated as appropriately-defined forregulation (VADER) an AI definition is. Our online, publicly-available VADERframework scores the coverage of premises that should underlie AI definitionsfor regulation, which aim to (i) reproduce principles observed in othersuccessful technology regulations, and (ii) include all AI techniques andapproaches while excluding non-AI works. Regarding the latter, our score isbased on a dataset of representative AI, non-AI ICT, and non-ICT examples. Wedemonstrate our contribution by reviewing the AI regulation proposals of keyplayers, namely the United States, United Kingdom, European Union, and Brazil.Importantly, none of the proposals assessed achieve the appropriateness score,ranging from a revision need to a concrete risk to ICT systems and works fromother fields.</description><author>Leonardo C. T. Bezerra, Alexander E. I. Brownlee, Luana Ferraz Alvarenga, Renan Cipriano Moioli, Thais Vasconcelos Batista</author><pubDate>Fri, 24 Jan 2025 15:45:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05048v3</guid></item><item><title>NLP Verification: Towards a General Methodology for Certifying Robustness</title><link>http://arxiv.org/abs/2403.10144v3</link><description>Machine Learning (ML) has exhibited substantial success in the field ofNatural Language Processing (NLP). For example large language models haveempirically proven to be capable of producing text of high complexity andcohesion. However, they are prone to inaccuracies and hallucinations. As thesesystems are increasingly integrated into real-world applications, ensuringtheir safety and reliability becomes a primary concern. There are safetycritical contexts where such models must be robust to variability or attack,and give guarantees over their output. Computer Vision had pioneered the use offormal verification of neural networks for such scenarios and developed commonverification standards and pipelines, leveraging precise formal reasoning aboutgeometric properties of data manifolds. In contrast, NLP verification methodshave only recently appeared in the literature. While presenting sophisticatedalgorithms, these papers have not yet crystallised into a common methodology.They are often light on the pragmatical issues of NLP verification and the arearemains fragmented. In this paper, we attempt to distil and evaluate generalcomponents of an NLP verification pipeline, that emerges from the progress inthe field to date. Our contributions are two-fold. Firstly, we propose ageneral methodology to analyse the effect of the embedding gap, a problem thatrefers to the discrepancy between verification of geometric subspaces and thesemantic meaning of sentences, which the geometric subspaces are supposed torepresent. We propose a number of practical NLP methods that can help toquantify the effects of the embedding gap. Secondly, we give a general methodfor training and verification of neural networks that leverages a more precisegeometric estimation of semantic similarity of sentences in the embedding spaceand helps to overcome the effects of the embedding gap in practice.</description><author>Marco Casadio, Tanvi Dinkar, Ekaterina Komendantskaya, Luca Arnaboldi, Matthew L. Daggitt, Omri Isac, Guy Katz, Verena Rieser, Oliver Lemon</author><pubDate>Fri, 24 Jan 2025 15:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.10144v3</guid></item><item><title>ZETA: Leveraging Z-order Curves for Efficient Top-k Attention</title><link>http://arxiv.org/abs/2501.14577v1</link><description>Over recent years, the Transformer has become a fundamental building blockfor sequence modeling architectures. Yet at its core is the use ofself-attention, whose memory and computational cost grow quadratically with thesequence length $N$, rendering it prohibitively expensive for long sequences. Apromising approach is top-$k$ attention, which selects only the $k$ mostrelevant tokens and achieves performance comparable to vanilla self-attentionwhile significantly reducing space and computational demands. However, causalmasks require the current query token to only attend to past tokens, preventingthe existing top-$k$ attention method from efficiently searching for the mostrelevant tokens in parallel, thereby limiting training efficiency. In thiswork, we propose ZETA, leveraging \textbf{Z}-Order Curves for\textbf{E}fficient \textbf{T}op-$k$ \textbf{A}ttention, to enable parallelquerying of past tokens for entire sequences. % in both space and timecomplexity of $\mathcal{O}(N \log N)$. We first theoretically show that thechoice of key and query dimensions involves a trade-off between the curse ofdimensionality and the preservation of relative distances after projection. Inlight of this insight, we propose reducing the dimensionality of keys andqueries in contrast to values and further leverage $Z$-order curves to maplow-dimensional keys and queries into \emph{one}-dimensional space, whichpermits parallel sorting, thereby largely improving the efficiency for top-$k$token selection. Experimental results demonstrate that ZETA matches theperformance of standard attention on the synthetic \textsc{Multi-QueryAssociative Recall} task and outperforms attention and its variants on\textsc{Long Range Arena} and \textsc{WikiText-103} language modeling.</description><author>Qiuhao Zeng, Jerry Huang, Peng Lu, Gezheng Xu, Boxing Chen, Charles Ling, Boyu Wang</author><pubDate>Fri, 24 Jan 2025 15:33:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14577v1</guid></item><item><title>An Interpretable X-ray Style Transfer via Trainable Local Laplacian Filter</title><link>http://arxiv.org/abs/2411.07072v2</link><description>Radiologists have preferred visual impressions or 'styles' of X-ray imagesthat are manually adjusted to their needs to support their diagnosticperformance. In this work, we propose an automatic and interpretable X-raystyle transfer by introducing a trainable version of the Local Laplacian Filter(LLF). From the shape of the LLF's optimized remap function, thecharacteristics of the style transfer can be inferred and reliability of thealgorithm can be ensured. Moreover, we enable the LLF to capture complex X-raystyle features by replacing the remap function with a Multi-Layer Perceptron(MLP) and adding a trainable normalization layer. We demonstrate theeffectiveness of the proposed method by transforming unprocessed mammographicX-ray images into images that match the style of target mammograms and achievea Structural Similarity Index (SSIM) of 0.94 compared to 0.82 of the baselineLLF style transfer method from Aubry et al.</description><author>Dominik Eckert, Ludwig Ritschl, Christopher Syben, Christian Hümmer, Julia Wicklein, Marcel Beister, Steffen Kappler, Sebastian Stober</author><pubDate>Fri, 24 Jan 2025 15:26:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07072v2</guid></item><item><title>coverforest: Conformal Predictions with Random Forest in Python</title><link>http://arxiv.org/abs/2501.14570v1</link><description>Conformal prediction provides a framework for uncertainty quantification,specifically in the forms of prediction intervals and sets withdistribution-free guaranteed coverage. While recent cross-conformal techniquessuch as CV+ and Jackknife+-after-bootstrap achieve better data efficiency thantraditional split conformal methods, they incur substantial computational costsdue to required pairwise comparisons between training and test samples'out-of-bag scores. Observing that these methods naturally extend from ensemblemodels, particularly random forests, we leverage existing optimized randomforest implementations to enable efficient cross-conformal predictions. We present coverforest, a Python package that implements efficient conformalprediction methods specifically optimized for random forests. coverforestsupports both regression and classification tasks through various conformalprediction methods, including split conformal, CV+, Jackknife+-after-bootstrap,and adaptive prediction sets. Our package leverages parallel computing andCython optimizations to speed up out-of-bag calculations. Our experimentsdemonstrate that coverforest's predictions achieve the desired level ofcoverage. In addition, its training and prediction times can be faster than anexisting implementation by 2--9 times. The source code for the coverforest ishosted on GitHub at https://github.com/donlapark/coverforest.</description><author>Panisara Meehinkong, Donlapark Ponnoprat</author><pubDate>Fri, 24 Jan 2025 15:24:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14570v1</guid></item><item><title>Self-playing Adversarial Language Game Enhances LLM Reasoning</title><link>http://arxiv.org/abs/2404.10642v3</link><description>We explore the potential of self-play training for large language models(LLMs) in a two-player adversarial language game called Adversarial Taboo. Inthis game, an attacker and a defender communicate around a target word onlyvisible to the attacker. The attacker aims to induce the defender to speak thetarget word unconsciously, while the defender tries to infer the target wordfrom the attacker's utterances. To win the game, both players must havesufficient knowledge about the target word and high-level reasoning ability toinfer and express in this information-reserved conversation. Hence, we arecurious about whether LLMs' reasoning ability can be further enhanced bySelf-Playing this Adversarial language Game (SPAG). With this goal, we selectseveral open-source LLMs and let each act as the attacker and play with a copyof itself as the defender on an extensive range of target words. Throughreinforcement learning on the game outcomes, we observe that the LLMs'performances uniformly improve on a broad range of reasoning benchmarks.Furthermore, iteratively adopting this self-play process can continuouslypromote LLMs' reasoning abilities. The code is available athttps://github.com/Linear95/SPAG.</description><author>Pengyu Cheng, Tianhao Hu, Han Xu, Zhisong Zhang, Zheng Yuan, Yong Dai, Lei Han, Nan Du, Xiaolong Li</author><pubDate>Fri, 24 Jan 2025 15:21:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10642v3</guid></item><item><title>Hybrid Quantum-Classical Multi-Agent Pathfinding</title><link>http://arxiv.org/abs/2501.14568v1</link><description>Multi-Agent Path Finding (MAPF) focuses on determining conflict-free pathsfor multiple agents navigating through a shared space to reach specified goallocations. This problem becomes computationally challenging, particularly whenhandling large numbers of agents, as frequently encountered in practicalapplications like coordinating autonomous vehicles. Quantum computing (QC) is apromising candidate in overcoming such limits. However, current quantumhardware is still in its infancy and thus limited in terms of computing powerand error robustness. In this work, we present the first optimal hybridquantum-classical MAPF algorithm which is based on branch-and-cut-and-prize. QCis integrated by iteratively solving QUBO problems, based on conflict graphs.Experiments on actual quantum hardware and results on benchmark data suggestthat our approach dominates previous QUBO formulations and baseline MAPFsolvers.</description><author>Thore Gerlach, Loong Kuan Lee, Frédéric Barbaresco, Nico Piatkowski</author><pubDate>Fri, 24 Jan 2025 15:20:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14568v1</guid></item><item><title>Bridging the Visual Gap: Fine-Tuning Multimodal Models with Knowledge-Adapted Captions</title><link>http://arxiv.org/abs/2411.09018v2</link><description>Recent research increasingly focuses on training vision-language models(VLMs) with long, detailed image captions. However, small-scale VLMs oftenstruggle to balance the richness of these captions with the risk ofhallucinating content during fine-tuning. In this paper, we explore how wellVLMs adapt to such captions. To quantify caption quality, we propose DecomposedNLI (DNLI), an evaluation framework that breaks down generated captions intoindividual propositions, assessing each in isolation. This fine-grainedanalysis reveals a critical balance between capturing descriptive details andpreventing hallucinations. Our findings show that simply reducing captioncomplexity or employing standard data curation techniques does not effectivelyresolve this issue. To tackle this challenge, we introduce Knowledge Adapted(KnowAda) fine-tuning, a data-centric approach that automatically adaptstraining data with the model's existing knowledge and visual understanding.KnowAda minimizes hallucinations while preserving high descriptiveness. Wevalidate this approach across several small-scale VLMs (up to 7B parameters)and dense caption datasets, demonstrating that KnowAda effectively balanceshallucination reduction and descriptiveness. Our results show that KnowAdaoutperforms various baselines in both automatic metrics and human evaluations.We will release our code and models.</description><author>Moran Yanuka, Assaf Ben Kish, Yonatan Bitton, Idan Szpektor, Raja Giryes</author><pubDate>Fri, 24 Jan 2025 15:12:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.09018v2</guid></item><item><title>Signature Methods in Machine Learning</title><link>http://arxiv.org/abs/2206.14674v6</link><description>Signature-based techniques give mathematical insight into the interactionsbetween complex streams of evolving data. These insights can be quite naturallytranslated into numerical approaches to understanding streamed data, andperhaps because of their mathematical precision, have proved useful inanalysing streamed data in situations where the data is irregular, and notstationary, and the dimension of the data and the sample sizes are bothmoderate. Understanding streamed multi-modal data is exponential: a word in $n$letters from an alphabet of size $d$ can be any one of $d^n$ messages.Signatures remove the exponential amount of noise that arises from samplingirregularity, but an exponential amount of information still remain. Thissurvey aims to stay in the domain where that exponential scaling can be manageddirectly. Scalability issues are an important challenge in many problems butwould require another survey article and further ideas. This survey describes arange of contexts where the data sets are small enough to remove thepossibility of massive machine learning, and the existence of small sets ofcontext free and principled features can be used effectively. The mathematicalnature of the tools can make their use intimidating to non-mathematicians. Theexamples presented in this article are intended to bridge this communicationgap and provide tractable working examples drawn from the machine learningcontext. Notebooks are available online for several of these examples. Thissurvey builds on the earlier paper of Ilya Chevryev and Andrey Kormilitzinwhich had broadly similar aims at an earlier point in the development of thismachinery. This article illustrates how the theoretical insights offered bysignatures are simply realised in the analysis of application data in a waythat is largely agnostic to the data type.</description><author>Terry Lyons, Andrew D. McLeod</author><pubDate>Fri, 24 Jan 2025 15:00:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.14674v6</guid></item><item><title>Fairness of Deep Ensembles: On the interplay between per-group task difficulty and under-representation</title><link>http://arxiv.org/abs/2501.14551v1</link><description>Ensembling is commonly regarded as an effective way to improve the generalperformance of models in machine learning, while also increasing the robustnessof predictions. When it comes to algorithmic fairness, heterogeneous ensembles,composed of multiple model types, have been employed to mitigate biases interms of demographic attributes such as sex, age or ethnicity. Moreover, recentwork has shown how in multi-class problems even simple homogeneous ensemblesmay favor performance of the worst-performing target classes. While homogeneousensembles are simpler to implement in practice, it is not yet clear whethertheir benefits translate to groups defined not in terms of their target class,but in terms of demographic or protected attributes, hence improving fairness.In this work we show how this simple and straightforward method is indeed ableto mitigate disparities, particularly benefiting under-performing subgroups.Interestingly, this can be achieved without sacrificing overall performance,which is a common trade-off observed in bias mitigation strategies. Moreover,we analyzed the interplay between two factors which may result in biases:sub-group under-representation and the inherent difficulty of the task for eachgroup. These results revealed that, contrary to popular assumptions, havingbalanced datasets may be suboptimal if the task difficulty varies betweensubgroups. Indeed, we found that a perfectly balanced dataset may hurt both theoverall performance and the gap between groups. This highlights the importanceof considering the interaction between multiple forces at play in fairness.</description><author>Estanislao Claucich, Sara Hooker, Diego H. Milone, Enzo Ferrante, Rodrigo Echeveste</author><pubDate>Fri, 24 Jan 2025 14:54:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14551v1</guid></item><item><title>Large-scale and Fine-grained Vision-language Pre-training for Enhanced CT Image Understanding</title><link>http://arxiv.org/abs/2501.14548v1</link><description>Artificial intelligence (AI) shows great potential in assisting radiologiststo improve the efficiency and accuracy of medical image interpretation anddiagnosis. However, a versatile AI model requires large-scale data andcomprehensive annotations, which are often impractical in medical settings.Recent studies leverage radiology reports as a naturally high-qualitysupervision for medical images, using contrastive language-image pre-training(CLIP) to develop language-informed models for radiological imageinterpretation. Nonetheless, these approaches typically contrast entire imageswith reports, neglecting the local associations between imaging regions andreport sentences, which may undermine model performance and interoperability.In this paper, we propose a fine-grained vision-language model (fVLM) foranatomy-level CT image interpretation. Specifically, we explicitly matchanatomical regions of CT images with corresponding descriptions in radiologyreports and perform contrastive pre-training for each anatomy individually.Fine-grained alignment, however, faces considerable false-negative challenges,mainly from the abundance of anatomy-level healthy samples and similarlydiseased abnormalities. To tackle this issue, we propose identifying falsenegatives of both normal and abnormal samples and calibrating contrastivelearning from patient-level to disease-aware pairing. We curated the largest CTdataset to date, comprising imaging and report data from 69,086 patients, andconducted a comprehensive evaluation of 54 major and important diseasediagnosis tasks across 15 main anatomies. Experimental results demonstrate thesubstantial potential of fVLM in versatile medical image interpretation. In thezero-shot classification task, we achieved an average AUC of 81.3% on 54diagnosis tasks, surpassing CLIP and supervised methods by 12.9% and 8.0%,respectively.</description><author>Zhongyi Shui, Jianpeng Zhang, Weiwei Cao, Sinuo Wang, Ruizhe Guo, Le Lu, Lin Yang, Xianghua Ye, Tingbo Liang, Qi Zhang, Ling Zhang</author><pubDate>Fri, 24 Jan 2025 14:50:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14548v1</guid></item><item><title>Leveraging ChatGPT's Multimodal Vision Capabilities to Rank Satellite Images by Poverty Level: Advancing Tools for Social Science Research</title><link>http://arxiv.org/abs/2501.14546v1</link><description>This paper investigates the novel application of Large Language Models (LLMs)with vision capabilities to analyze satellite imagery for village-level povertyprediction. Although LLMs were originally designed for natural languageunderstanding, their adaptability to multimodal tasks, including geospatialanalysis, has opened new frontiers in data-driven research. By leveragingadvancements in vision-enabled LLMs, we assess their ability to provideinterpretable, scalable, and reliable insights into human poverty fromsatellite images. Using a pairwise comparison approach, we demonstrate thatChatGPT can rank satellite images based on poverty levels with accuracycomparable to domain experts. These findings highlight both the promise and thelimitations of LLMs in socioeconomic research, providing a foundation for theirintegration into poverty assessment workflows. This study contributes to theongoing exploration of unconventional data sources for welfare analysis andopens pathways for cost-effective, large-scale poverty monitoring.</description><author>Hamid Sarmadi, Ola Hall, Thorsteinn Rögnvaldsson, Mattias Ohlsson</author><pubDate>Fri, 24 Jan 2025 14:49:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14546v1</guid></item><item><title>Distributed Conformal Prediction via Message Passing</title><link>http://arxiv.org/abs/2501.14544v1</link><description>Post-hoc calibration of pre-trained models is critical for ensuring reliableinference, especially in safety-critical domains such as healthcare. ConformalPrediction (CP) offers a robust post-hoc calibration framework, providingdistribution-free statistical coverage guarantees for prediction sets byleveraging held-out datasets. In this work, we address a decentralized settingwhere each device has limited calibration data and can communicate only withits neighbors over an arbitrary graph topology. We propose twomessage-passing-based approaches for achieving reliable inference via CP:quantile-based distributed conformal prediction (Q-DCP) and histogram-baseddistributed conformal prediction (H-DCP). Q-DCP employs distributed quantileregression enhanced with tailored smoothing and regularization terms toaccelerate convergence, while H-DCP uses a consensus-based histogram estimationapproach. Through extensive experiments, we investigate the trade-offs betweenhyperparameter tuning requirements, communication overhead, coverageguarantees, and prediction set sizes across different network topologies.</description><author>Haifeng Wen, Hong Xing, Osvaldo Simeone</author><pubDate>Fri, 24 Jan 2025 14:47:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14544v1</guid></item><item><title>Reducing Action Space for Deep Reinforcement Learning via Causal Effect Estimation</title><link>http://arxiv.org/abs/2501.14543v1</link><description>Intelligent decision-making within large and redundant action spaces remainschallenging in deep reinforcement learning. Considering similar but ineffectiveactions at each step can lead to repetitive and unproductive trials. Existingmethods attempt to improve agent exploration by reducing or penalizingredundant actions, yet they fail to provide quantitative and reliable evidenceto determine redundancy. In this paper, we propose a method to improveexploration efficiency by estimating the causal effects of actions. Unlikeprior methods, our approach offers quantitative results regarding the causalityof actions for one-step transitions. We first pre-train an inverse dynamicsmodel to serve as prior knowledge of the environment. Subsequently, we classifyactions across the entire action space at each time step and estimate thecausal effect of each action to suppress redundant actions during exploration.We provide a theoretical analysis to demonstrate the effectiveness of ourmethod and present empirical results from simulations in environments withredundant actions to evaluate its performance. Our implementation is availableat https://github.com/agi-brain/cee.git.</description><author>Wenzhang Liu, Lianjun Jin, Lu Ren, Chaoxu Mu, Changyin Sun</author><pubDate>Fri, 24 Jan 2025 14:47:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14543v1</guid></item><item><title>VERUS-LM: a Versatile Framework for Combining LLMs with Symbolic Reasoning</title><link>http://arxiv.org/abs/2501.14540v1</link><description>A recent approach to neurosymbolic reasoning is to explicitly combine thestrengths of large language models (LLMs) and symbolic solvers to tacklecomplex reasoning tasks. However, current approaches face significantlimitations, including poor generalizability due to task-specific prompts,inefficiencies caused by the lack of separation between knowledge and queries,and restricted inferential capabilities. These shortcomings hinder theirscalability and applicability across diverse domains. In this paper, weintroduce VERUS-LM, a novel framework designed to address these challenges.VERUS-LM employs a generic prompting mechanism, clearly separates domainknowledge from queries, and supports a wide range of different logicalreasoning tasks. This framework enhances adaptability, reduces computationalcost, and allows for richer forms of reasoning, such as optimization andconstraint satisfaction. We show that our approach succeeds in diversereasoning on a novel dataset, markedly outperforming LLMs. Additionally, oursystem achieves competitive results on common reasoning benchmarks whencompared to other state-of-the-art approaches, and significantly surpasses themon the difficult AR-LSAT dataset. By pushing the boundaries of hybridreasoning, VERUS-LM represents a significant step towards more versatileneurosymbolic AI systems</description><author>Benjamin Callewaert, Simon Vandevelde, Joost Vennekens</author><pubDate>Fri, 24 Jan 2025 14:45:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14540v1</guid></item><item><title>A Recurrent Spiking Network with Hierarchical Intrinsic Excitability Modulation for Schema Learning</title><link>http://arxiv.org/abs/2501.14539v1</link><description>Schema, a form of structured knowledge that promotes transfer learning, isattracting growing attention in both neuroscience and artificial intelligence(AI). Current schema research in neural computation is largely constrained to asingle behavioral paradigm and relies heavily on recurrent neural networks(RNNs) which lack the neural plausibility and biological interpretability. Toaddress these limitations, this work first constructs a generalized behavioralparadigm framework for schema learning and introduces three novel cognitivetasks, thus supporting a comprehensive schema exploration. Second, we propose anew model using recurrent spiking neural networks with hierarchical intrinsicexcitability modulation (HM-RSNNs). The top level of the model selectsexcitability properties for task-specific demands, while the bottom levelfine-tunes these properties for intra-task problems. Finally, extensivevisualization analyses of HM-RSNNs are conducted to showcase theircomputational advantages, track the intrinsic excitability evolution duringschema learning, and examine neural coordination differences across tasks.Biologically inspired lesion studies further uncover task-specificdistributions of intrinsic excitability within schemas. Experimental resultsshow that HM-RSNNs significantly outperform RSNN baselines across all tasks andexceed RNNs in three novel cognitive tasks. Additionally, HM-RSNNs offer deeperinsights into neural dynamics underlying schema learning.</description><author>Yingchao Yu, Yaochu Jin, Yuchen Xiao, Yuping Yan</author><pubDate>Fri, 24 Jan 2025 14:45:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14539v1</guid></item><item><title>Rethinking Encoder-Decoder Flow Through Shared Structures</title><link>http://arxiv.org/abs/2501.14535v1</link><description>Dense prediction tasks have enjoyed a growing complexity of encoderarchitectures, decoders, however, have remained largely the same. They rely onindividual blocks decoding intermediate feature maps sequentially. We introducebanks, shared structures that are used by each decoding block to provideadditional context in the decoding process. These structures, through applyingthem via resampling and feature fusion, improve performance on depth estimationfor state-of-the-art transformer-based architectures on natural and syntheticimages whilst training on large-scale datasets.</description><author>Frederik Laboyrie, Mehmet Kerim Yucel, Albert Saa-Garriga</author><pubDate>Fri, 24 Jan 2025 14:41:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14535v1</guid></item><item><title>Trick-GS: A Balanced Bag of Tricks for Efficient Gaussian Splatting</title><link>http://arxiv.org/abs/2501.14534v1</link><description>Gaussian splatting (GS) for 3D reconstruction has become quite popular due totheir fast training, inference speeds and high quality reconstruction. However,GS-based reconstructions generally consist of millions of Gaussians, whichmakes them hard to use on computationally constrained devices such assmartphones. In this paper, we first propose a principled analysis of advancesin efficient GS methods. Then, we propose Trick-GS, which is a carefulcombination of several strategies including (1) progressive training withresolution, noise and Gaussian scales, (2) learning to prune and maskprimitives and SH bands by their significance, and (3) accelerated GS trainingframework. Trick-GS takes a large step towards resource-constrained GS, wherefaster run-time, smaller and faster-convergence of models is of paramountconcern. Our results on three datasets show that Trick-GS achieves up to 2xfaster training, 40x smaller disk size and 2x faster rendering speed comparedto vanilla GS, while having comparable accuracy.</description><author>Anil Armagan, Albert Saà-Garriga, Bruno Manganelli, Mateusz Nowak, Mehmet Kerim Yucel</author><pubDate>Fri, 24 Jan 2025 14:40:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14534v1</guid></item><item><title>CheapNVS: Real-Time On-Device Narrow-Baseline Novel View Synthesis</title><link>http://arxiv.org/abs/2501.14533v1</link><description>Single-view novel view synthesis (NVS) is a notorious problem due to itsill-posed nature, and often requires large, computationally expensiveapproaches to produce tangible results. In this paper, we propose CheapNVS: afully end-to-end approach for narrow baseline single-view NVS based on a novel,efficient multiple encoder/decoder design trained in a multi-stage fashion.CheapNVS first approximates the laborious 3D image warping with lightweightlearnable modules that are conditioned on the camera pose embeddings of thetarget view, and then performs inpainting on the occluded regions in parallelto achieve significant performance gains. Once trained on a subset of OpenImages dataset, CheapNVS outperforms the state-of-the-art despite being 10times faster and consuming 6% less memory. Furthermore, CheapNVS runscomfortably in real-time on mobile devices, reaching over 30 FPS on a SamsungTab 9+.</description><author>Konstantinos Georgiadis, Mehmet Kerim Yucel, Albert Saa-Garriga</author><pubDate>Fri, 24 Jan 2025 14:40:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14533v1</guid></item><item><title>On the Representational Capacity of Neural Language Models with Chain-of-Thought Reasoning</title><link>http://arxiv.org/abs/2406.14197v2</link><description>The performance of modern language models (LMs) has been improved bychain-of-thought (CoT) reasoning, i.e., the process of generating intermediateresults that guide the model towards a final answer. A possible explanation forthis improvement is that CoT reasoning extends an LM's computational power, asRNNs and transformers with additional scratch space are known to be Turingcomplete. Comparing LMs to Turing machines, however, introduces a categoryerror - Turing machines decide language membership, whereas LMs definedistributions over strings. To bridge this gap, we formalize CoT reasoning in aprobabilistic setting. We present several results on the representationalcapacity of recurrent and transformer LMs with CoT reasoning, showing that theycan represent the same family of distributions over strings as probabilisticTuring machines.</description><author>Franz Nowak, Anej Svete, Alexandra Butoi, Ryan Cotterell</author><pubDate>Fri, 24 Jan 2025 14:40:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14197v2</guid></item><item><title>On Hardening DNNs against Noisy Computations</title><link>http://arxiv.org/abs/2501.14531v1</link><description>The success of deep learning has sparked significant interest in designingcomputer hardware optimized for the high computational demands of neuralnetwork inference. As further miniaturization of digital CMOS processorsbecomes increasingly challenging, alternative computing paradigms, such asanalog computing, are gaining consideration. Particularly for compute-intensivetasks such as matrix multiplication, analog computing presents a promisingalternative due to its potential for significantly higher energy efficiencycompared to conventional digital technology. However, analog computations areinherently noisy, which makes it challenging to maintain high accuracy on deepneural networks. This work investigates the effectiveness of training neuralnetworks with quantization to increase the robustness against noise.Experimental results across various network architectures show thatquantization-aware training with constant scaling factors enhances robustness.We compare these methods with noisy training, which incorporates a noiseinjection during training that mimics the noise encountered during inference.While both two methods increase tolerance against noise, noisy training emergesas the superior approach for achieving robust neural network performance,especially in complex neural architectures.</description><author>Xiao Wang, Hendrik Borras, Bernhard Klein, Holger Fröning</author><pubDate>Fri, 24 Jan 2025 14:37:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14531v1</guid></item><item><title>Idiom Detection in Sorani Kurdish Texts</title><link>http://arxiv.org/abs/2501.14528v1</link><description>Idiom detection using Natural Language Processing (NLP) is the computerizedprocess of recognizing figurative expressions within a text that conveymeanings beyond the literal interpretation of the words. While idiom detectionhas seen significant progress across various languages, the Kurdish languagefaces a considerable research gap in this area despite the importance of idiomsin tasks like machine translation and sentiment analysis. This study addressesidiom detection in Sorani Kurdish by approaching it as a text classificationtask using deep learning techniques. To tackle this, we developed a datasetcontaining 10,580 sentences embedding 101 Sorani Kurdish idioms across diversecontexts. Using this dataset, we developed and evaluated three deep learningmodels: KuBERT-based transformer sequence classification, a RecurrentConvolutional Neural Network (RCNN), and a BiLSTM model with an attentionmechanism. The evaluations revealed that the transformer model, the fine-tunedBERT, consistently outperformed the others, achieving nearly 99% accuracy whilethe RCNN achieved 96.5% and the BiLSTM 80%. These results highlight theeffectiveness of Transformer-based architectures in low-resource languages likeKurdish. This research provides a dataset, three optimized models, and insightsinto idiom detection, laying a foundation for advancing Kurdish NLP.</description><author>Skala Kamaran Omer, Hossein Hassani</author><pubDate>Fri, 24 Jan 2025 14:31:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14528v1</guid></item><item><title>On the Causal Sufficiency and Necessity of Multi-Modal Representation Learning</title><link>http://arxiv.org/abs/2407.14058v3</link><description>Multi-Modal Learning (MML) aims to learn effective representations acrossmodalities for accurate predictions. Existing methods typically focus onmodality consistency and specificity to learn effective representations.However, from a causal perspective, they may lead to representations thatcontain insufficient and unnecessary information. To address this, we proposethat effective MML representations should be causally sufficient and necessary.Considering practical issues like spurious correlations and modality conflicts,we relax the exogeneity and monotonicity assumptions prevalent in prior worksand explore the concepts specific to MML, i.e., Causal Complete Cause(\(C^3\)). We begin by defining \(C^3\), which quantifies the probability ofrepresentations being causally sufficient and necessary. We then discuss theidentifiability of \(C^3\) and introduce an instrumental variable to supportidentifying \(C^3\) with non-exogeneity and non-monotonicity. Building on this,we conduct the $C^3$ measurement, i.e., \(C^3\) risk. We propose a twin networkto estimate it through (i) the real-world branch: utilizing the instrumentalvariable for sufficiency, and (ii) the hypothetical-world branch: applyinggradient-based counterfactual modeling for necessity. Theoretical analysesconfirm its reliability. Based on these results, we propose $C^3$Regularization, a plug-and-play method that enforces the causal completeness ofthe learned representations by minimizing \(C^3\) risk. Extensive experimentsdemonstrate its effectiveness.</description><author>Jingyao Wang, Siyu Zhao, Wenwen Qiang, Jiangmeng Li, Fuchun Sun, Hui Xiong</author><pubDate>Fri, 24 Jan 2025 14:31:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14058v3</guid></item><item><title>Fair Decentralized Learning</title><link>http://arxiv.org/abs/2410.02541v3</link><description>Decentralized learning (DL) is an emerging approach that enables nodes tocollaboratively train a machine learning model without sharing raw data. Inmany application domains, such as healthcare, this approach faces challengesdue to the high level of heterogeneity in the training data's feature space.Such feature heterogeneity lowers model utility and negatively impactsfairness, particularly for nodes with under-represented training data. In thispaper, we introduce \textsc{Facade}, a clustering-based DL algorithmspecifically designed for fair model training when the training data exhibitsseveral distinct features. The challenge of \textsc{Facade} is to assign nodesto clusters, one for each feature, based on the similarity in the features oftheir local data, without requiring individual nodes to know apriori whichcluster they belong to. \textsc{Facade} (1) dynamically assigns nodes to theirappropriate clusters over time, and (2) enables nodes to collaboratively traina specialized model for each cluster in a fully decentralized manner. Wetheoretically prove the convergence of \textsc{Facade}, implement ouralgorithm, and compare it against three state-of-the-art baselines. Ourexperimental results on three datasets demonstrate the superiority of ourapproach in terms of model accuracy and fairness compared to all threecompetitors. Compared to the best-performing baseline, \textsc{Facade} on theCIFAR-10 dataset also reduces communication costs by 32.3\% to reach a targetaccuracy when cluster sizes are imbalanced.</description><author>Sayan Biswas, Anne-Marie Kermarrec, Rishi Sharma, Thibaud Trinca, Martijn de Vos</author><pubDate>Fri, 24 Jan 2025 14:30:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02541v3</guid></item><item><title>PCM Selector: Penalized Covariate-Mediator Selection Operator for Evaluating Linear Causal Effects</title><link>http://arxiv.org/abs/2412.18180v2</link><description>For a data-generating process for random variables that can be described witha linear structural equation model, we consider a situation in which (i) a setof covariates satisfying the back-door criterion cannot be observed or (ii)such a set can be observed, but standard statistical estimation methods cannotbe applied to estimate causal effects because ofmulticollinearity/high-dimensional data problems. We propose a novel two-stagepenalized regression approach, the penalized covariate-mediator selectionoperator (PCM Selector), to estimate the causal effects in such scenarios.Unlike existing penalized regression analyses, when a set of intermediatevariables is available, PCM Selector provides a consistent or less biasedestimator of the causal effect. In addition, PCM Selector provides a variableselection procedure for intermediate variables to obtain better estimationaccuracy of the causal effects than does the back-door criterion.</description><author>Hisayoshi Nanmo, Manabu Kuroki</author><pubDate>Fri, 24 Jan 2025 14:29:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.18180v2</guid></item><item><title>Training-Free Style and Content Transfer by Leveraging U-Net Skip Connections in Stable Diffusion 2.*</title><link>http://arxiv.org/abs/2501.14524v1</link><description>Despite significant recent advances in image generation with diffusionmodels, their internal latent representations remain poorly understood.Existing works focus on the bottleneck layer (h-space) of Stable Diffusion'sU-Net or leverage the cross-attention, self-attention, or decoding layers. Ourmodel, SkipInject takes advantage of U-Net's skip connections. We conductthorough analyses on the role of the skip connections and find that theresidual connections passed by the third encoder block carry most of thespatial information of the reconstructed image, splitting the content from thestyle. We show that injecting the representations from this block can be usedfor text-based editing, precise modifications, and style transfer. We compareour methods state-of-the-art style transfer and image editing methods anddemonstrate that our method obtains the best content alignment and optimalstructural preservation tradeoff.</description><author>Ludovica Schaerf, Andrea Alfarano, Fabrizio Silvestri, Leonardo Impett</author><pubDate>Fri, 24 Jan 2025 14:27:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14524v1</guid></item><item><title>Scene Understanding Enabled Semantic Communication with Open Channel Coding</title><link>http://arxiv.org/abs/2501.14520v1</link><description>As communication systems transition from symbol transmission to conveyingmeaningful information, sixth-generation (6G) networks emphasize semanticcommunication. This approach prioritizes high-level semantic information,improving robustness and reducing redundancy across modalities like text,speech, and images. However, traditional semantic communication faceslimitations, including static coding strategies, poor generalization, andreliance on task-specific knowledge bases that hinder adaptability. To overcomethese challenges, we propose a novel system combining scene understanding,Large Language Models (LLMs), and open channel coding, named \textbf{OpenSC}.Traditional systems rely on fixed domain-specific knowledge bases, limitingtheir ability to generalize. Our open channel coding approach leverages shared,publicly available knowledge, enabling flexible, adaptive encoding. Thisdynamic system reduces reliance on static task-specific data, enhancingadaptability across diverse tasks and environments. Additionally, we use scenegraphs for structured semantic encoding, capturing object relationships andcontext to improve tasks like Visual Question Answering (VQA). Our approachselectively encodes key semantic elements, minimizing redundancy and improvingtransmission efficiency. Experimental results show significant improvements inboth semantic understanding and efficiency, advancing the potential ofadaptive, generalizable semantic communication in 6G networks.</description><author>Zhe Xiang, Fei Yu, Quan Deng, Yuandi Li, Zhiguo Wan</author><pubDate>Fri, 24 Jan 2025 14:23:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14520v1</guid></item><item><title>Disentangled Condensation for Large-scale Graphs</title><link>http://arxiv.org/abs/2401.12231v3</link><description>Graph condensation has emerged as an intriguing technique to save theexpensive training costs of Graph Neural Networks (GNNs) by substituting acondensed small graph with the original graph. Despite the promising resultsachieved, previous methods usually employ an entangled paradigm of redundantparameters (nodes, edges, GNNs), which incurs complex joint optimization duringcondensation. This paradigm has considerably impeded the scalability of graphcondensation, making it challenging to condense extremely large-scale graphsand generate high-fidelity condensed graphs. Therefore, we propose todisentangle the condensation process into a two-stage GNN-free paradigm,independently condensing nodes and generating edges while eliminating the needto optimize GNNs at the same time. The node condensation module avoids thecomplexity of GNNs by focusing on node feature alignment with anchors of theoriginal graph, while the edge translation module constructs the edges of thecondensed nodes by transferring the original structure knowledge withneighborhood anchors. This simple yet effective approach achieves at least 10times faster than state-of-the-art methods with comparable accuracy onmedium-scale graphs. Moreover, the proposed DisCo can successfully scale up tothe Ogbn-papers100M graph containing over 100 million nodes with flexiblereduction rates and improves performance on the second-largest Ogbn-productsdataset by over 5%. Extensive downstream tasks and ablation study on fivecommon datasets further demonstrate the effectiveness of the proposed DisCoframework. Our code is available at https://github.com/BangHonor/DisCo.</description><author>Zhenbang Xiao, Yu Wang, Shunyu Liu, Bingde Hu, Huiqiong Wang, Mingli Song, Tongya Zheng</author><pubDate>Fri, 24 Jan 2025 14:18:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12231v3</guid></item><item><title>PARASIDE: An Automatic Paranasal Sinus Segmentation and Structure Analysis Tool for MRI</title><link>http://arxiv.org/abs/2501.14514v1</link><description>Chronic rhinosinusitis (CRS) is a common and persistent sinus imflammationthat affects 5 - 12\% of the general population. It significantly impactsquality of life and is often difficult to assess due to its subjective naturein clinical evaluation. We introduce PARASIDE, an automatic tool for segmentingair and soft tissue volumes of the structures of the sinus maxillaris,frontalis, sphenodalis and ethmoidalis in T1 MRI. By utilizing thatsegmentation, we can quantify feature relations that have been observed onlymanually and subjectively before. We performed an exemplary study and showedboth volume and intensity relations between structures and radiology reports.While the soft tissue segmentation is good, the automated annotations of theair volumes are excellent. The average intensity over air structures areconsistently below those of the soft tissues, close to perfect separability.Healthy subjects exhibit lower soft tissue volumes and lower intensities. Ourdeveloped system is the first automated whole nasal segmentation of 16structures, and capable of calculating medical relevant features such as theLund-Mackay score.</description><author>Hendrik Möller, Lukas Krautschick, Matan Atad, Robert Graf, Chia-Jung Busch, Achim Beule, Christian Scharf, Lars Kaderali, Bjoern Menze, Daniel Rueckert, Jan Kirschke, Fabian Schwitzing</author><pubDate>Fri, 24 Jan 2025 14:18:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14514v1</guid></item><item><title>ABPT: Amended Backpropagation through Time with Partially Differentiable Rewards</title><link>http://arxiv.org/abs/2501.14513v1</link><description>Using the exact gradients of the rewards to directly optimize policyparameters via backpropagation-through-time (BPTT) enables high trainingperformance for quadrotor tasks. However, designing a fully differentiablereward architecture is often challenging. Partially differentiable rewards willresult in biased gradient propagation that degrades training performance. Toovercome this limitation, we propose Amended Backpropagation-through-Time(ABPT), a novel approach that mitigates gradient bias while preserving thetraining efficiency of BPTT. ABPT combines 0-step and N-step returns,effectively reducing the bias by leveraging value gradients from the learnedQ-value function. Additionally, it adopts entropy regularization and stateinitialization mechanisms to encourage exploration during training. We evaluateABPT on four representative quadrotor flight tasks. Experimental resultsdemonstrate that ABPT converges significantly faster and achieves higherultimate rewards than existing learning algorithms, particularly in tasksinvolving partially differentiable rewards.</description><author>Fanxing Li, Fangyu Sun, Tianbao Zhang, Danping Zou</author><pubDate>Fri, 24 Jan 2025 14:18:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14513v1</guid></item></channel></rss>