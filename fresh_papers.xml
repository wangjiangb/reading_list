<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 27 May 2024 14:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>FastDrag: Manipulate Anything in One Step</title><link>http://arxiv.org/abs/2405.15769v1</link><description>Drag-based image editing using generative models provides precise controlover image contents, enabling users to manipulate anything in an image with afew clicks. However, prevailing methods typically adopt $n$-step iterations forlatent semantic optimization to achieve drag-based image editing, which istime-consuming and limits practical applications. In this paper, we introduce anovel one-step drag-based image editing method, i.e., FastDrag, to acceleratethe editing process. Central to our approach is a latent warpage function(LWF), which simulates the behavior of a stretched material to adjust thelocation of individual pixels within the latent space. This innovation achievesone-step latent semantic optimization and hence significantly promotes editingspeeds. Meanwhile, null regions emerging after applying LWF are addressed byour proposed bilateral nearest neighbor interpolation (BNNI) strategy. Thisstrategy interpolates these regions using similar features from neighboringareas, thus enhancing semantic integrity. Additionally, aconsistency-preserving strategy is introduced to maintain the consistencybetween the edited and original images by adopting semantic information fromthe original image, saved as key and value pairs in self-attention moduleduring diffusion inversion, to guide the diffusion sampling. Our FastDrag isvalidated on the DragBench dataset, demonstrating substantial improvements inprocessing time over existing methods, while achieving enhanced editingperformance.</description><author>Xuanjia Zhao, Jian Guan, Congyi Fan, Dongli Xu, Youtian Lin, Haiwei Pan, Pengming Feng</author><pubDate>Fri, 24 May 2024 18:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15769v1</guid></item><item><title>Canonical Variates in Wasserstein Metric Space</title><link>http://arxiv.org/abs/2405.15768v1</link><description>In this paper, we address the classification of instances each characterizednot by a singular point, but by a distribution on a vector space. We employ theWasserstein metric to measure distances between distributions, which are thenused by distance-based classification algorithms such as k-nearest neighbors,k-means, and pseudo-mixture modeling. Central to our investigation is dimensionreduction within the Wasserstein metric space to enhance classificationaccuracy. We introduce a novel approach grounded in the principle of maximizingFisher's ratio, defined as the quotient of between-class variation towithin-class variation. The directions in which this ratio is maximized aretermed discriminant coordinates or canonical variates axes. In practice, wedefine both between-class and within-class variations as the average squareddistances between pairs of instances, with the pairs either belonging to thesame class or to different classes. This ratio optimization is achieved throughan iterative algorithm, which alternates between optimal transport andmaximization steps within the vector space. We conduct empirical studies toassess the algorithm's convergence and, through experimental validation,demonstrate that our dimension reduction technique substantially enhancesclassification performance. Moreover, our method outperforms well-establishedalgorithms that operate on vector representations derived from distributionaldata. It also exhibits robustness against variations in the distributionalrepresentations of data clouds.</description><author>Jia Li, Lin Lin</author><pubDate>Fri, 24 May 2024 18:59:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15768v1</guid></item><item><title>Improved Particle Approximation Error for Mean Field Neural Networks</title><link>http://arxiv.org/abs/2405.15767v1</link><description>Mean-field Langevin dynamics (MFLD) minimizes an entropy-regularizednonlinear convex functional defined over the space of probabilitydistributions. MFLD has gained attention due to its connection with noisygradient descent for mean-field two-layer neural networks. Unlike standardLangevin dynamics, the nonlinearity of the objective functional inducesparticle interactions, necessitating multiple particles to approximate thedynamics in a finite-particle setting. Recent works (Chen et al., 2022; Suzukiet al., 2023b) have demonstrated the uniform-in-time propagation of chaos forMFLD, showing that the gap between the particle system and its mean-field limituniformly shrinks over time as the number of particles increases. In this work,we improve the dependence on logarithmic Sobolev inequality (LSI) constants intheir particle approximation errors, which can exponentially deteriorate withthe regularization coefficient. Specifically, we establish an LSI-constant-freeparticle approximation error concerning the objective gap by leveraging theproblem structure in risk minimization. As the application, we demonstrateimproved convergence of MFLD, sampling guarantee for the mean-field stationarydistribution, and uniform-in-time Wasserstein propagation of chaos in terms ofparticle complexity.</description><author>Atsushi Nitanda</author><pubDate>Fri, 24 May 2024 18:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15767v1</guid></item><item><title>Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus Creation and Model Development</title><link>http://arxiv.org/abs/2405.15766v1</link><description>The mining of adverse drug events (ADEs) is pivotal in pharmacovigilance,enhancing patient safety by identifying potential risks associated withmedications, facilitating early detection of adverse events, and guidingregulatory decision-making. Traditional ADE detection methods are reliable butslow, not easily adaptable to large-scale operations, and offer limitedinformation. With the exponential increase in data sources like social mediacontent, biomedical literature, and Electronic Medical Records (EMR),extracting relevant ADE-related information from these unstructured texts isimperative. Previous ADE mining studies have focused on text-basedmethodologies, overlooking visual cues, limiting contextual comprehension, andhindering accurate interpretation. To address this gap, we present a MultiModalAdverse Drug Event (MMADE) detection dataset, merging ADE-related textualinformation with visual aids. Additionally, we introduce a framework thatleverages the capabilities of LLMs and VLMs for ADE detection by generatingdetailed descriptions of medical images depicting ADEs, aiding healthcareprofessionals in visually identifying adverse events. Using our MMADE dataset,we showcase the significance of integrating visual cues from images to enhanceoverall performance. This approach holds promise for patient safety, ADEawareness, and healthcare accessibility, paving the way for further explorationin personalized healthcare.</description><author>Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Aman Chadha, Samrat Mondal</author><pubDate>Fri, 24 May 2024 18:58:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15766v1</guid></item><item><title>Scaling Laws for Discriminative Classification in Large Language Models</title><link>http://arxiv.org/abs/2405.15765v1</link><description>Modern large language models (LLMs) represent a paradigm shift in what canplausibly be expected of machine learning models. The fact that LLMs caneffectively generate sensible answers to a diverse range of queries suggeststhat they would be useful in customer support applications. While powerful,LLMs have been observed to be prone to hallucination which unfortunately makestheir near term use in customer support applications challenging. To addressthis issue we present a system that allows us to use an LLM to augment ourcustomer support advocates by re-framing the language modeling task as adiscriminative classification task. In this framing, we seek to present thetop-K best template responses for a customer support advocate to use whenresponding to a customer. We present the result of both offline and onlineexperiments where we observed offline gains and statistically significantonline lifts for our experimental system. Along the way, we present observedscaling curves for validation loss and top-K accuracy, resulted from modelparameter ablation studies. We close by discussing the space of trade-offs withrespect to model size, latency, and accuracy as well as and suggesting futureapplications to explore.</description><author>Dean Wyatte, Fatemeh Tahmasbi, Ming Li, Thomas Markovich</author><pubDate>Fri, 24 May 2024 18:58:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15765v1</guid></item><item><title>Event Detection from Social Media for Epidemic Prediction</title><link>http://arxiv.org/abs/2404.01679v2</link><description>Social media is an easy-to-access platform providing timely updates aboutsocietal trends and events. Discussions regarding epidemic-related events suchas infections, symptoms, and social interactions can be crucial for informingpolicymaking during epidemic outbreaks. In our work, we pioneer exploitingEvent Detection (ED) for better preparedness and early warnings of any upcomingepidemic by developing a framework to extract and analyze epidemic-relatedevents from social media posts. To this end, we curate an epidemic eventontology comprising seven disease-agnostic event types and construct a Twitterdataset SPEED with human-annotated events focused on the COVID-19 pandemic.Experimentation reveals how ED models trained on COVID-based SPEED caneffectively detect epidemic events for three unseen epidemics of Monkeypox,Zika, and Dengue; while models trained on existing ED datasets fail miserably.Furthermore, we show that reporting sharp increases in the extracted events byour framework can provide warnings 4-9 weeks earlier than the WHO epidemicdeclaration for Monkeypox. This utility of our framework lays the foundationsfor better preparedness against emerging epidemics.</description><author>Tanmay Parekh, Anh Mac, Jiarui Yu, Yuxuan Dong, Syed Shahriar, Bonnie Liu, Eric Yang, Kuan-Hao Huang, Wei Wang, Nanyun Peng, Kai-Wei Chang</author><pubDate>Fri, 24 May 2024 18:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01679v2</guid></item><item><title>FreeMotion: A Unified Framework for Number-free Text-to-Motion Synthesis</title><link>http://arxiv.org/abs/2405.15763v1</link><description>Text-to-motion synthesis is a crucial task in computer vision. Existingmethods are limited in their universality, as they are tailored forsingle-person or two-person scenarios and can not be applied to generatemotions for more individuals. To achieve the number-free motion synthesis, thispaper reconsiders motion generation and proposes to unify the single andmulti-person motion by the conditional motion distribution. Furthermore, ageneration module and an interaction module are designed for our FreeMotionframework to decouple the process of conditional motion generation and finallysupport the number-free motion synthesis. Besides, based on our framework, thecurrent single-person motion spatial control method could be seamlesslyintegrated, achieving precise control of multi-person motion. Extensiveexperiments demonstrate the superior performance of our method and ourcapability to infer single and multi-human motions simultaneously.</description><author>Ke Fan, Junshu Tang, Weijian Cao, Ran Yi, Moran Li, Jingyu Gong, Jiangning Zhang, Yabiao Wang, Chengjie Wang, Lizhuang Ma</author><pubDate>Fri, 24 May 2024 18:57:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15763v1</guid></item><item><title>GPT is Not an Annotator: The Necessity of Human Annotation in Fairness Benchmark Construction</title><link>http://arxiv.org/abs/2405.15760v1</link><description>Social biases in LLMs are usually measured via bias benchmark datasets.Current benchmarks have limitations in scope, grounding, quality, and humaneffort required. Previous work has shown success with a community-sourced,rather than crowd-sourced, approach to benchmark development. However, thiswork still required considerable effort from annotators with relevant livedexperience. This paper explores whether an LLM (specifically, GPT-3.5-Turbo)can assist with the task of developing a bias benchmark dataset from responsesto an open-ended community survey. We also extend the previous work to a newcommunity and set of biases: the Jewish community and antisemitism. Ouranalysis shows that GPT-3.5-Turbo has poor performance on this annotation taskand produces unacceptable quality issues in its output. Thus, we conclude thatGPT-3.5-Turbo is not an appropriate substitute for human annotation insensitive tasks related to social biases, and that its use actually negatesmany of the benefits of community-sourcing bias benchmarks.</description><author>Virginia K. Felkner, Jennifer A. Thompson, Jonathan May</author><pubDate>Fri, 24 May 2024 18:56:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15760v1</guid></item><item><title>InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation</title><link>http://arxiv.org/abs/2405.15758v1</link><description>Recent talking avatar generation models have made strides in achievingrealistic and accurate lip synchronization with the audio, but often fall shortin controlling and conveying detailed expressions and emotions of the avatar,making the generated video less vivid and controllable. In this paper, wepropose a novel text-guided approach for generating emotionally expressive 2Davatars, offering fine-grained control, improved interactivity, andgeneralizability to the resulting video. Our framework, named InstructAvatar,leverages a natural language interface to control the emotion as well as thefacial motion of avatars. Technically, we design an automatic annotationpipeline to construct an instruction-video paired training dataset, equippedwith a novel two-branch diffusion-based generator to predict avatars with audioand text instructions at the same time. Experimental results demonstrate thatInstructAvatar produces results that align well with both conditions, andoutperforms existing methods in fine-grained emotion control, lip-sync quality,and naturalness. Our project page ishttps://wangyuchi369.github.io/InstructAvatar/.</description><author>Yuchi Wang, Junliang Guo, Jianhong Bai, Runyi Yu, Tianyu He, Xu Tan, Xu Sun, Jiang Bian</author><pubDate>Fri, 24 May 2024 18:53:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15758v1</guid></item><item><title>Looking Backward: Streaming Video-to-Video Translation with Feature Banks</title><link>http://arxiv.org/abs/2405.15757v1</link><description>This paper introduces StreamV2V, a diffusion model that achieves real-timestreaming video-to-video (V2V) translation with user prompts. Unlike prior V2Vmethods using batches to process limited frames, we opt to process frames in astreaming fashion, to support unlimited frames. At the heart of StreamV2V liesa backward-looking principle that relates the present to the past. This isrealized by maintaining a feature bank, which archives information from pastframes. For incoming frames, StreamV2V extends self-attention to include bankedkeys and values and directly fuses similar past features into the output. Thefeature bank is continually updated by merging stored and new features, makingit compact but informative. StreamV2V stands out for its adaptability andefficiency, seamlessly integrating with image diffusion models withoutfine-tuning. It can run 20 FPS on one A100 GPU, being 15x, 46x, 108x, and 158xfaster than FlowVid, CoDeF, Rerender, and TokenFlow, respectively. Quantitativemetrics and user studies confirm StreamV2V's exceptional ability to maintaintemporal consistency.</description><author>Feng Liang, Akio Kodaira, Chenfeng Xu, Masayoshi Tomizuka, Kurt Keutzer, Diana Marculescu</author><pubDate>Fri, 24 May 2024 18:53:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15757v1</guid></item><item><title>Sparse Expansion and Neuronal Disentanglement</title><link>http://arxiv.org/abs/2405.15756v1</link><description>We show how to improve the inference efficiency of an LLM by expanding itinto a mixture of sparse experts, where each expert is a copy of the originalweights, one-shot pruned for a specific cluster of input values. We call thisapproach $\textit{Sparse Expansion}$. We show that, for models such as Llama 270B, as we increase the number of sparse experts, Sparse Expansion outperformsall other one-shot sparsification approaches for the same inference FLOP budgetper token, and that this gap grows as sparsity increases, leading to inferencespeedups. But why? To answer this, we provide strong evidence that the mixture ofsparse experts is effectively $\textit{disentangling}$ the input-outputrelationship of every individual neuron across clusters of inputs.Specifically, sparse experts approximate the dense neuron output distributionwith fewer weights by decomposing the distribution into a collection of simplerones, each with a separate sparse dot product covering it. Interestingly, weshow that the Wasserstein distance between a neuron's output distribution and aGaussian distribution is an indicator of its entanglement level andcontribution to the accuracy of the model. Every layer of an LLM has a fractionof highly entangled Wasserstein neurons, and model performance suffers morewhen these are sparsified as opposed to others.</description><author>Shashata Sawmya, Linghao Kong, Ilia Markov, Dan Alistarh, Nir Shavit</author><pubDate>Fri, 24 May 2024 18:51:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15756v1</guid></item><item><title>ETTrack: Enhanced Temporal Motion Predictor for Multi-Object Tracking</title><link>http://arxiv.org/abs/2405.15755v1</link><description>Many Multi-Object Tracking (MOT) approaches exploit motion information toassociate all the detected objects across frames. However, many methods thatrely on filtering-based algorithms, such as the Kalman Filter, often work wellin linear motion scenarios but struggle to accurately predict the locations ofobjects undergoing complex and non-linear movements. To tackle these scenarios,we propose a motion-based MOT approach with an enhanced temporal motionpredictor, ETTrack. Specifically, the motion predictor integrates a transformermodel and a Temporal Convolutional Network (TCN) to capture short-term andlong-term motion patterns, and it predicts the future motion of individualobjects based on the historical motion information. Additionally, we propose anovel Momentum Correction Loss function that provides additional informationregarding the motion direction of objects during training. This allows themotion predictor rapidly adapt to motion variations and more accurately predictfuture motion. Our experimental results demonstrate that ETTrack achieves acompetitive performance compared with state-of-the-art trackers on DanceTrackand SportsMOT, scoring 56.4% and 74.4% in HOTA metrics, respectively.</description><author>Xudong Han, Nobuyuki Oishi, Yueying Tian, Elif Ucurum, Rupert Young, Chris Chatwin, Philip Birch</author><pubDate>Fri, 24 May 2024 18:51:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15755v1</guid></item><item><title>Score-based generative models are provably robust: an uncertainty quantification perspective</title><link>http://arxiv.org/abs/2405.15754v1</link><description>Through an uncertainty quantification (UQ) perspective, we show thatscore-based generative models (SGMs) are provably robust to the multiplesources of error in practical implementation. Our primary tool is theWasserstein uncertainty propagation (WUP) theorem, a model-form UQ bound thatdescribes how the $L^2$ error from learning the score function propagates to aWasserstein-1 ($\mathbf{d}_1$) ball around the true data distribution under theevolution of the Fokker-Planck equation. We show how errors due to (a) finitesample approximation, (b) early stopping, (c) score-matching objective choice,(d) score function parametrization expressiveness, and (e) referencedistribution choice, impact the quality of the generative model in terms of a$\mathbf{d}_1$ bound of computable quantities. The WUP theorem relies onBernstein estimates for Hamilton-Jacobi-Bellman partial differential equations(PDE) and the regularizing properties of diffusion processes. Specifically, PDEregularity theory shows that stochasticity is the key mechanism ensuring SGMalgorithms are provably robust. The WUP theorem applies to integral probabilitymetrics beyond $\mathbf{d}_1$, such as the total variation distance and themaximum mean discrepancy. Sample complexity and generalization bounds in$\mathbf{d}_1$ follow directly from the WUP theorem. Our approach requiresminimal assumptions, is agnostic to the manifold hypothesis and avoids absolutecontinuity assumptions for the target distribution. Additionally, our resultsclarify the trade-offs among multiple error sources in SGMs.</description><author>Nikiforos Mimikos-Stamatopoulos, Benjamin J. Zhang, Markos A. Katsoulakis</author><pubDate>Fri, 24 May 2024 18:50:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15754v1</guid></item><item><title>How to Fix a Broken Confidence Estimator: Evaluating Post-hoc Methods for Selective Classification with Deep Neural Networks</title><link>http://arxiv.org/abs/2305.15508v4</link><description>This paper addresses the problem of selective classification for deep neuralnetworks, where a model is allowed to abstain from low-confidence predictionsto avoid potential errors. We focus on so-called post-hoc methods, whichreplace the confidence estimator of a given classifier without modifying orretraining it, thus being practically appealing. Considering neural networkswith softmax outputs, our goal is to identify the best confidence estimatorthat can be computed directly from the unnormalized logits. This problem ismotivated by the intriguing observation in recent work that many classifiersappear to have a "broken" confidence estimator, in the sense that theirselective classification performance is much worse than what could be expectedby their corresponding accuracies. We perform an extensive experimental studyof many existing and proposed confidence estimators applied to 84 pretrainedImageNet classifiers available from popular repositories. Our results show thata simple $p$-norm normalization of the logits, followed by taking the maximumlogit as the confidence estimator, can lead to considerable gains in selectiveclassification performance, completely fixing the pathological behaviorobserved in many classifiers. As a consequence, the selective classificationperformance of any classifier becomes almost entirely determined by itscorresponding accuracy. Moreover, these results are shown to be consistentunder distribution shift. Our code is available athttps://github.com/lfpc/FixSelectiveClassification.</description><author>Luís Felipe P. Cattelan, Danilo Silva</author><pubDate>Fri, 24 May 2024 18:48:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15508v4</guid></item><item><title>Filtered Corpus Training (FiCT) Shows that Language Models can Generalize from Indirect Evidence</title><link>http://arxiv.org/abs/2405.15750v1</link><description>This paper introduces Filtered Corpus Training, a method that trains languagemodels (LMs) on corpora with certain linguistic constructions filtered out fromthe training data, and uses it to measure the ability of LMs to performlinguistic generalization on the basis of indirect evidence. We apply themethod to both LSTM and Transformer LMs (of roughly comparable size),developing filtered corpora that target a wide range of linguistic phenomena.Our results show that while transformers are better qua LMs (as measured byperplexity), both models perform equally and surprisingly well on linguisticgeneralization measures, suggesting that they are capable of generalizing fromindirect evidence.</description><author>Abhinav Patil, Jaap Jumelet, Yu Ying Chiu, Andy Lapastora, Peter Shen, Lexie Wang, Clevis Willrich, Shane Steinert-Threlkeld</author><pubDate>Fri, 24 May 2024 18:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15750v1</guid></item><item><title>Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment</title><link>http://arxiv.org/abs/2402.10207v4</link><description>We consider the problem of multi-objective alignment of foundation modelswith human preferences, which is a critical step towards helpful and harmlessAI systems. However, it is generally costly and unstable to fine-tune largefoundation models using reinforcement learning (RL), and themulti-dimensionality, heterogeneity, and conflicting nature of humanpreferences further complicate the alignment process. In this paper, weintroduce Rewards-in-Context (RiC), which conditions the response of afoundation model on multiple rewards in its prompt context and appliessupervised fine-tuning for alignment. The salient features of RiC aresimplicity and adaptivity, as it only requires supervised fine-tuning of asingle foundation model and supports dynamic adjustment for user preferencesduring inference time. Inspired by the analytical solution of an abstractedconvex optimization problem, our dynamic inference-time adjustment methodapproaches the Pareto-optimal solution for multiple objectives. Empiricalevidence demonstrates the efficacy of our method in aligning both LargeLanguage Models (LLMs) and diffusion models to accommodate diverse rewards withonly around 10% GPU hours compared with multi-objective RL baseline.</description><author>Rui Yang, Xiaoman Pan, Feng Luo, Shuang Qiu, Han Zhong, Dong Yu, Jianshu Chen</author><pubDate>Fri, 24 May 2024 18:44:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10207v4</guid></item><item><title>Hierarchical NeuroSymbolic Approach for Comprehensive and Explainable Action Quality Assessment</title><link>http://arxiv.org/abs/2403.13798v2</link><description>Action quality assessment (AQA) applies computer vision to quantitativelyassess the performance or execution of a human action. Current AQA approachesare end-to-end neural models, which lack transparency and tend to be biasedbecause they are trained on subjective human judgements as ground-truth. Toaddress these issues, we introduce a neuro-symbolic paradigm for AQA, whichuses neural networks to abstract interpretable symbols from video data andmakes quality assessments by applying rules to those symbols. We take diving asthe case study. We found that domain experts prefer our system and find it moreinformative than purely neural approaches to AQA in diving. Our system alsoachieves state-of-the-art action recognition and temporal segmentation, andautomatically generates a detailed report that breaks the dive down into itselements and provides objective scoring with visual evidence. As verified by agroup of domain experts, this report may be used to assist judges in scoring,help train judges, and provide feedback to divers. Annotated training data andcode: https://github.com/laurenok24/NSAQA.</description><author>Lauren Okamoto, Paritosh Parmar</author><pubDate>Fri, 24 May 2024 18:44:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13798v2</guid></item><item><title>ACPO: A Policy Optimization Algorithm for Average MDPs with Constraints</title><link>http://arxiv.org/abs/2302.00808v4</link><description>Reinforcement Learning (RL) for constrained MDPs (CMDPs) is an increasinglyimportant problem for various applications. Often, the average criterion ismore suitable than the discounted criterion. Yet, RL for average-CMDPs (ACMDPs)remains a challenging problem. Algorithms designed for discounted constrainedRL problems often do not perform well for the average CMDP setting. In thispaper, we introduce a new policy optimization with function approximationalgorithm for constrained MDPs with the average criterion. TheAverage-Constrained Policy Optimization (ACPO) algorithm is inspired by trustregion-based policy optimization algorithms. We develop basic sensitivitytheory for average CMDPs, and then use the corresponding bounds in the designof the algorithm. We provide theoretical guarantees on its performance, andthrough extensive experimental work in various challenging OpenAI Gymenvironments, show its superior empirical performance when compared to otherstate-of-the-art algorithms adapted for the ACMDPs.</description><author>Akhil Agnihotri, Rahul Jain, Haipeng Luo</author><pubDate>Fri, 24 May 2024 18:43:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00808v4</guid></item><item><title>CAFe: Cost and Age aware Federated Learning</title><link>http://arxiv.org/abs/2405.15744v1</link><description>In many federated learning (FL) models, a common strategy employed to ensurethe progress in the training process, is to wait for at least $M$ clients outof the total $N$ clients to send back their local gradients based on areporting deadline $T$, once the parameter server (PS) has broadcasted theglobal model. If enough clients do not report back within the deadline, theparticular round is considered to be a failed round and the training round isrestarted from scratch. If enough clients have responded back, the round isdeemed successful and the local gradients of all the clients that respondedback are used to update the global model. In either case, the clients thatfailed to report back an update within the deadline would have wasted theircomputational resources. Having a tighter deadline (small $T$) and waiting fora larger number of participating clients (large $M$) leads to a large number offailed rounds and therefore greater communication cost and computation resourcewastage. However, having a larger $T$ leads to longer round durations whereassmaller $M$ may lead to noisy gradients. Therefore, there is a need to optimizethe parameters $M$ and $T$ such that communication cost and the resourcewastage is minimized while having an acceptable convergence rate. In thisregard, we show that the average age of a client at the PS appears explicitlyin the theoretical convergence bound, and therefore, can be used as a metric toquantify the convergence of the global model. We provide an analytical schemeto select the parameters $M$ and $T$ in this setting.</description><author>Sahan Liyanaarachchi, Kanchana Thilakarathna, Sennur Ulukus</author><pubDate>Fri, 24 May 2024 18:41:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15744v1</guid></item><item><title>Sparse maximal update parameterization: A holistic approach to sparse training dynamics</title><link>http://arxiv.org/abs/2405.15743v1</link><description>Several challenges make it difficult for sparse neural networks to competewith dense models. First, setting a large fraction of weights to zero impairsforward and gradient signal propagation. Second, sparse studies often need totest multiple sparsity levels, while also introducing new hyperparameters(HPs), leading to prohibitive tuning costs. Indeed, the standard practice is tore-use the learning HPs originally crafted for dense models. Unfortunately, weshow sparse and dense networks do not share the same optimal HPs. Withoutstable dynamics and effective training recipes, it is costly to test sparsityat scale, which is key to surpassing dense networks and making the businesscase for sparsity acceleration in hardware. A holistic approach is needed totackle these challenges and we propose S$\mu$Par as one such approach.S$\mu$Par ensures activations, gradients, and weight updates all scaleindependently of sparsity level. Further, by reparameterizing the HPs,S$\mu$Par enables the same HP values to be optimal as we vary both sparsitylevel and model width. HPs can be tuned on small dense networks and transferredto large sparse models, greatly reducing tuning costs. On large-scale languagemodeling, S$\mu$Par training improves loss by up to 8.2% over the commonapproach of using the dense model standard parameterization.</description><author>Nolan Dey, Shane Bergsma, Joel Hestness</author><pubDate>Fri, 24 May 2024 18:39:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15743v1</guid></item><item><title>Large Language Models Reflect Human Citation Patterns with a Heightened Citation Bias</title><link>http://arxiv.org/abs/2405.15739v1</link><description>Citation practices are crucial in shaping the structure of scientificknowledge, yet they are often influenced by contemporary norms and biases. Theemergence of Large Language Models (LLMs) like GPT-4 introduces a new dynamicto these practices. Interestingly, the characteristics and potential biases ofreferences recommended by LLMs that entirely rely on their parametricknowledge, and not on search or retrieval-augmented generation, remainunexplored. Here, we analyze these characteristics in an experiment using adataset of 166 papers from AAAI, NeurIPS, ICML, and ICLR, published afterGPT-4's knowledge cut-off date, encompassing 3,066 references in total. In ourexperiment, GPT-4 was tasked with suggesting scholarly references for theanonymized in-text citations within these papers. Our findings reveal aremarkable similarity between human and LLM citation patterns, but with a morepronounced high citation bias in GPT-4, which persists even after controllingfor publication year, title length, number of authors, and venue. Additionally,we observe a large consistency between the characteristics of GPT-4's existingand non-existent generated references, indicating the model's internalizationof citation patterns. By analyzing citation graphs, we show that the referencesrecommended by GPT-4 are embedded in the relevant citation context, suggestingan even deeper conceptual internalization of the citation networks. While LLMscan aid in citation generation, they may also amplify existing biases andintroduce new ones, potentially skewing scientific knowledge dissemination. Ourresults underscore the need for identifying the model's biases and fordeveloping balanced methods to interact with LLMs in general.</description><author>Andres Algaba, Carmen Mazijn, Vincent Holst, Floriano Tori, Sylvia Wenmackers, Vincent Ginis</author><pubDate>Fri, 24 May 2024 18:34:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15739v1</guid></item><item><title>ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models</title><link>http://arxiv.org/abs/2405.15738v1</link><description>High-resolution Large Multimodal Models (LMMs) encounter the challenges ofexcessive visual tokens and quadratic visual complexity. Currenthigh-resolution LMMs address the quadratic complexity while still generatingexcessive visual tokens. However, the redundancy in visual tokens is the keyproblem as it leads to more substantial compute. To mitigate this issue, wepropose ConvLLaVA, which employs ConvNeXt, a hierarchical backbone, as thevisual encoder of LMM to replace Vision Transformer (ViT). ConvLLaVA compresseshigh-resolution images into information-rich visual features, effectivelypreventing the generation of excessive visual tokens. To enhance thecapabilities of ConvLLaVA, we propose two critical optimizations. Since thelow-resolution pretrained ConvNeXt underperforms when directly applied on highresolution, we update it to bridge the gap. Moreover, since ConvNeXt's originalcompression ratio is inadequate for much higher resolution inputs, we train asuccessive stage to further compress the visual tokens, thereby reducingredundancy. These optimizations enable ConvLLaVA to support inputs of 1536x1536resolution generating only 576 visual tokens, capable of handling images ofarbitrary aspect ratios. Experimental results demonstrate that our methodachieves competitive performance with state-of-the-art models on mainstreambenchmarks. The ConvLLaVA model series are publicly available athttps://github.com/alibaba/conv-llava.</description><author>Chunjiang Ge, Sijie Cheng, Ziming Wang, Jiale Yuan, Yuan Gao, Jun Song, Shiji Song, Gao Huang, Bo Zheng</author><pubDate>Fri, 24 May 2024 18:34:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15738v1</guid></item><item><title>First-order methods for Stochastic Variational Inequality problems with Function Constraints</title><link>http://arxiv.org/abs/2304.04778v3</link><description>The monotone Variational Inequality (VI) is a general model with importantapplications in various engineering and scientific domains. In numerousinstances, the VI problems are accompanied by function constraints that can bedata-driven, making the usual projection operator challenging to compute. Thispaper presents novel first-order methods for the function-constrainedVariational Inequality (FCVI) problem in smooth or nonsmooth settings withpossibly stochastic operators and constraints. We introduce the AdOpEx method,which employs an operator extrapolation on the KKT operator of the FCVI in asmooth deterministic setting. Since this operator is not uniformly Lipschitzcontinuous in the Lagrange multipliers, we employ an adaptive two-timescalealgorithm leading to bounded multipliers and achieving the optimal $O(1/T)$convergence rate. For the nonsmooth and stochastic VIs, we introduce designchanges to the AdOpEx method and propose a novel P-OpEx method that takespartial extrapolation. It converges at the rate of $O(1/\sqrt{T})$ when boththe operator and constraints are stochastic or nonsmooth. This method hassuboptimal dependence on the noise and Lipschitz constants of functionconstraints. We propose a constraint extrapolation approach leading to theOpConEx method that improves this dependence by an order of magnitude. All ouralgorithms easily extend to saddle point problems with function constraintsthat couple the primal and dual variables while maintaining the same complexityresults. To the best of our knowledge, all our complexity results are new inthe literature</description><author>Digvijay Boob, Qi Deng, Mohammad Khalafi</author><pubDate>Fri, 24 May 2024 18:31:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.04778v3</guid></item><item><title>Multi-Track Timeline Control for Text-Driven 3D Human Motion Generation</title><link>http://arxiv.org/abs/2401.08559v2</link><description>Recent advances in generative modeling have led to promising progress onsynthesizing 3D human motion from text, with methods that can generatecharacter animations from short prompts and specified durations. However, usinga single text prompt as input lacks the fine-grained control needed byanimators, such as composing multiple actions and defining precise durationsfor parts of the motion. To address this, we introduce the new problem oftimeline control for text-driven motion synthesis, which provides an intuitive,yet fine-grained, input interface for users. Instead of a single prompt, userscan specify a multi-track timeline of multiple prompts organized in temporalintervals that may overlap. This enables specifying the exact timings of eachaction and composing multiple actions in sequence or at overlapping intervals.To generate composite animations from a multi-track timeline, we propose a newtest-time denoising method. This method can be integrated with any pre-trainedmotion diffusion model to synthesize realistic motions that accurately reflectthe timeline. At every step of denoising, our method processes each timelineinterval (text prompt) individually, subsequently aggregating the predictionswith consideration for the specific body parts engaged in each action.Experimental comparisons and ablations validate that our method producesrealistic motions that respect the semantics and timing of given text prompts.Our code and models are publicly available at https://mathis.petrovich.fr/stmc.</description><author>Mathis Petrovich, Or Litany, Umar Iqbal, Michael J. Black, Gül Varol, Xue Bin Peng, Davis Rempe</author><pubDate>Fri, 24 May 2024 18:28:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08559v2</guid></item><item><title>LM4LV: A Frozen Large Language Model for Low-level Vision Tasks</title><link>http://arxiv.org/abs/2405.15734v1</link><description>The success of large language models (LLMs) has fostered a new research trendof multi-modality large language models (MLLMs), which changes the paradigm ofvarious fields in computer vision. Though MLLMs have shown promising results innumerous high-level vision and vision-language tasks such as VQA andtext-to-image, no works have demonstrated how low-level vision tasks canbenefit from MLLMs. We find that most current MLLMs are blind to low-levelfeatures due to their design of vision modules, thus are inherently incapablefor solving low-level vision tasks. In this work, we purpose $\textbf{LM4LV}$,a framework that enables a FROZEN LLM to solve a range of low-level visiontasks without any multi-modal data or prior. This showcases the LLM's strongpotential in low-level vision and bridges the gap between MLLMs and low-levelvision tasks. We hope this work can inspire new perspectives on LLMs and deeperunderstanding of their mechanisms.</description><author>Boyang Zheng, Jinjin Gu, Shijun Li, Chao Dong</author><pubDate>Fri, 24 May 2024 18:25:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15734v1</guid></item><item><title>Score identity Distillation: Exponentially Fast Distillation of Pretrained Diffusion Models for One-Step Generation</title><link>http://arxiv.org/abs/2404.04057v3</link><description>We introduce Score identity Distillation (SiD), an innovative data-freemethod that distills the generative capabilities of pretrained diffusion modelsinto a single-step generator. SiD not only facilitates an exponentially fastreduction in Fr\'echet inception distance (FID) during distillation but alsoapproaches or even exceeds the FID performance of the original teacherdiffusion models. By reformulating forward diffusion processes as semi-implicitdistributions, we leverage three score-related identities to create aninnovative loss mechanism. This mechanism achieves rapid FID reduction bytraining the generator using its own synthesized images, eliminating the needfor real data or reverse-diffusion-based generation, all accomplished withinsignificantly shortened generation time. Upon evaluation across four benchmarkdatasets, the SiD algorithm demonstrates high iteration efficiency duringdistillation and surpasses competing distillation approaches, whether they areone-step or few-step, data-free, or dependent on training data, in terms ofgeneration quality. This achievement not only redefines the benchmarks forefficiency and effectiveness in diffusion distillation but also in the broaderfield of diffusion-based generation. The PyTorch implementation is available athttps://github.com/mingyuanzhou/SiD</description><author>Mingyuan Zhou, Huangjie Zheng, Zhendong Wang, Mingzhang Yin, Hai Huang</author><pubDate>Fri, 24 May 2024 18:20:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04057v3</guid></item><item><title>Neural Persistence Dynamics</title><link>http://arxiv.org/abs/2405.15732v1</link><description>We consider the problem of learning the dynamics in the topology oftime-evolving point clouds, the prevalent spatiotemporal model for systemsexhibiting collective behavior, such as swarms of insects and birds orparticles in physics. In such systems, patterns emerge from (local)interactions among self-propelled entities. While several well-understoodgoverning equations for motion and interaction exist, they are difficult to fitto data due to the often large number of entities and missing correspondencesbetween the observation times, which may also not be equidistant. To evade suchconfounding factors, we investigate collective behavior from a\textit{topological perspective}, but instead of summarizing entire observationsequences (as in prior work), we propose learning a latent dynamical model fromtopological features \textit{per time point}. The latter is then used toformulate a downstream regression task to predict the parametrization of some apriori specified governing equation. We implement this idea based on a latentODE learned from vectorized (static) persistence diagrams and show that thismodeling choice is justified by a combination of recent stability results forpersistent homology. Various (ablation) experiments not only demonstrate therelevance of each individual model component, but provide compelling empiricalevidence that our proposed model -- \textit{neural persistence dynamics} --substantially outperforms the state-of-the-art across a diverse set ofparameter regression tasks.</description><author>Sebastian Zeng, Florian Graf, Martin Uray, Stefan Huber, Roland Kwitt</author><pubDate>Fri, 24 May 2024 18:20:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15732v1</guid></item><item><title>Understanding the differences in Foundation Models: Attention, State Space Models, and Recurrent Neural Networks</title><link>http://arxiv.org/abs/2405.15731v1</link><description>Softmax attention is the principle backbone of foundation models for variousartificial intelligence applications, yet its quadratic complexity in sequencelength can limit its inference throughput in long-context settings. To addressthis challenge, alternative architectures such as linear attention, State SpaceModels (SSMs), and Recurrent Neural Networks (RNNs) have been considered asmore efficient alternatives. While connections between these approaches exist,such models are commonly developed in isolation and there is a lack oftheoretical understanding of the shared principles underpinning thesearchitectures and their subtle differences, greatly influencing performance andscalability. In this paper, we introduce the Dynamical Systems Framework (DSF),which allows a principled investigation of all these architectures in a commonrepresentation. Our framework facilitates rigorous comparisons, providing newinsights on the distinctive characteristics of each model class. For instance,we compare linear attention and selective SSMs, detailing their differences andconditions under which both are equivalent. We also provide principledcomparisons between softmax attention and other model classes, discussing thetheoretical conditions under which softmax attention can be approximated.Additionally, we substantiate these new insights with empirical validations andmathematical arguments. This shows the DSF's potential to guide the systematicdevelopment of future more efficient and scalable foundation models.</description><author>Jerome Sieber, Carmen Amo Alonso, Alexandre Didier, Melanie N. Zeilinger, Antonio Orvieto</author><pubDate>Fri, 24 May 2024 18:19:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15731v1</guid></item><item><title>Optimizing Large Language Models for OpenAPI Code Completion</title><link>http://arxiv.org/abs/2405.15729v1</link><description>Recent advancements in Large Language Models (LLMs) and their utilization incode generation tasks have significantly reshaped the field of softwaredevelopment. Despite the remarkable efficacy of code completion solutions inmainstream programming languages, their performance lags when applied to lessubiquitous formats such as OpenAPI definitions. This study evaluates theOpenAPI completion performance of GitHub Copilot, a prevalent commercial codecompletion tool, and proposes a set of task-specific optimizations leveragingMeta's open-source model Code Llama. A semantics-aware OpenAPI completionbenchmark proposed in this research is used to perform a series of experimentsthrough which the impact of various prompt-engineering and fine-tuningtechniques on the Code Llama model's performance is analyzed. The fine-tunedCode Llama model reaches a peak correctness improvement of 55.2% over GitHubCopilot despite utilizing 25 times fewer parameters than the commercialsolution's underlying Codex model. Additionally, this research proposes anenhancement to a widely used code infilling training technique, addressing theissue of underperformance when the model is prompted with context sizes smallerthan those used during training.</description><author>Bohdan Petryshyn, Mantas Lukoševičius</author><pubDate>Fri, 24 May 2024 18:19:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15729v1</guid></item><item><title>Disease-informed Adaptation of Vision-Language Models</title><link>http://arxiv.org/abs/2405.15728v1</link><description>In medical image analysis, the expertise scarcity and the high cost of dataannotation limits the development of large artificial intelligence models. Thispaper investigates the potential of transfer learning with pre-trainedvision-language models (VLMs) in this domain. Currently, VLMs still struggle totransfer to the underrepresented diseases with minimal presence and newdiseases entirely absent from the pretraining dataset. We argue that effectiveadaptation of VLMs hinges on the nuanced representation learning of diseaseconcepts. By capitalizing on the joint visual-linguistic capabilities of VLMs,we introduce disease-informed contextual prompting in a novel disease prototypelearning framework. This approach enables VLMs to grasp the concepts of newdisease effectively and efficiently, even with limited data. Extensiveexperiments across multiple image modalities showcase notable enhancements inperformance compared to existing techniques.</description><author>Jiajin Zhang, Ge Wang, Mannudeep K. Kalra, Pingkun Yan</author><pubDate>Fri, 24 May 2024 18:18:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15728v1</guid></item><item><title>Anomalous Change Point Detection Using Probabilistic Predictive Coding</title><link>http://arxiv.org/abs/2405.15727v1</link><description>Change point detection (CPD) and anomaly detection (AD) are essentialtechniques in various fields to identify abrupt changes or abnormal datainstances. However, existing methods are often constrained to univariate data,face scalability challenges with large datasets due to computational demands,and experience reduced performance with high-dimensional or intricate data, aswell as hidden anomalies. Furthermore, they often lack interpretability andadaptability to domain-specific knowledge, which limits their versatilityacross different fields. In this work, we propose a deep learning-based CPD/ADmethod called Probabilistic Predictive Coding (PPC) that jointly learns toencode sequential data to low dimensional latent space representations and topredict the subsequent data representations as well as the correspondingprediction uncertainties. The model parameters are optimized with maximumlikelihood estimation by comparing these predictions with the true encodings.At the time of application, the true and predicted encodings are used todetermine the probability of conformity, an interpretable and meaningfulanomaly score. Furthermore, our approach has linear time complexity,scalability issues are prevented, and the method can easily be adjusted to awide range of data types and intricate applications. We demonstrate theeffectiveness and adaptability of our proposed method across synthetic timeseries experiments, image data, and real-world magnetic resonance spectroscopicimaging data.</description><author>Roelof G. Hup, Julian P. Merkofer, Alex A. Bhogal, Ruud J. G. van Sloun, Reinder Haakma, Rik Vullings</author><pubDate>Fri, 24 May 2024 18:17:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15727v1</guid></item><item><title>Bisimulation Learning</title><link>http://arxiv.org/abs/2405.15723v1</link><description>We introduce a data-driven approach to computing finite bisimulations forstate transition systems with very large, possibly infinite state space. Ournovel technique computes stutter-insensitive bisimulations of deterministicsystems, which we characterize as the problem of learning a state classifiertogether with a ranking function for each class. Our procedure learns acandidate state classifier and candidate ranking functions from a finitedataset of sample states; then, it checks whether these generalise to theentire state space using satisfiability modulo theory solving. Upon theaffirmative answer, the procedure concludes that the classifier constitutes avalid stutter-insensitive bisimulation of the system. Upon a negative answer,the solver produces a counterexample state for which the classifier violatesthe claim, adds it to the dataset, and repeats learning and checking in acounterexample-guided inductive synthesis loop until a valid bisimulation isfound. We demonstrate on a range of benchmarks from reactive verification andsoftware model checking that our method yields faster verification results thanalternative state-of-the-art tools in practice. Our method produces succinctabstractions that enable an effective verification of linear temporal logicwithout next operator, and are interpretable for system diagnostics.</description><author>Alessandro Abate, Mirco Giacobbe, Yannik Schnitzer</author><pubDate>Fri, 24 May 2024 18:11:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15723v1</guid></item><item><title>Models That Prove Their Own Correctness</title><link>http://arxiv.org/abs/2405.15722v1</link><description>How can we trust the correctness of a learned model on a particular input ofinterest? Model accuracy is typically measured \emph{on average} over adistribution of inputs, giving no guarantee for any fixed input. This paperproposes a theoretically-founded solution to this problem: to train*Self-Proving models* that prove the correctness of their output to averification algorithm $V$ via an Interactive Proof. Self-Proving modelssatisfy that, with high probability over a random input, the model generates acorrect output \emph{and} successfully proves its correctness to $V\!$. The*soundness* property of $V$ guarantees that, for *every* input, no model canconvince $V$ of the correctness of an incorrect output. Thus, a Self-Provingmodel proves correctness of most of its outputs, while *all* incorrect outputs(of any model) are detected by $V$. We devise a generic method for learningSelf-Proving models, and we prove convergence bounds under certain assumptions.The theoretical framework and results are complemented by experiments on anarithmetic capability: computing the greatest common divisor (GCD) of twointegers. Our learning method is used to train a Self-Proving transformer thatcomputes the GCD *and* proves the correctness of its answer.</description><author>Noga Amit, Shafi Goldwasser, Orr Paradise, Guy Rothblum</author><pubDate>Fri, 24 May 2024 18:10:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15722v1</guid></item><item><title>Improved Distribution Matching Distillation for Fast Image Synthesis</title><link>http://arxiv.org/abs/2405.14867v2</link><description>Recent approaches have shown promises distilling diffusion models intoefficient one-step generators. Among them, Distribution Matching Distillation(DMD) produces one-step generators that match their teacher in distribution,without enforcing a one-to-one correspondence with the sampling trajectories oftheir teachers. However, to ensure stable training, DMD requires an additionalregression loss computed using a large set of noise-image pairs generated bythe teacher with many steps of a deterministic sampler. This is costly forlarge-scale text-to-image synthesis and limits the student's quality, tying ittoo closely to the teacher's original sampling paths. We introduce DMD2, a setof techniques that lift this limitation and improve DMD training. First, weeliminate the regression loss and the need for expensive dataset construction.We show that the resulting instability is due to the fake critic not estimatingthe distribution of generated samples accurately and propose a two time-scaleupdate rule as a remedy. Second, we integrate a GAN loss into the distillationprocedure, discriminating between generated samples and real images. This letsus train the student model on real data, mitigating the imperfect real scoreestimation from the teacher model, and enhancing quality. Lastly, we modify thetraining procedure to enable multi-step sampling. We identify and address thetraining-inference input mismatch problem in this setting, by simulatinginference-time generator samples during training time. Taken together, ourimprovements set new benchmarks in one-step image generation, with FID scoresof 1.28 on ImageNet-64x64 and 8.35 on zero-shot COCO 2014, surpassing theoriginal teacher despite a 500X reduction in inference cost. Further, we showour approach can generate megapixel images by distilling SDXL, demonstratingexceptional visual quality among few-step methods.</description><author>Tianwei Yin, Michaël Gharbi, Taesung Park, Richard Zhang, Eli Shechtman, Fredo Durand, William T. Freeman</author><pubDate>Fri, 24 May 2024 18:08:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14867v2</guid></item><item><title>Hierarchical Uncertainty Exploration via Feedforward Posterior Trees</title><link>http://arxiv.org/abs/2405.15719v1</link><description>When solving ill-posed inverse problems, one often desires to explore thespace of potential solutions rather than be presented with a single plausiblereconstruction. Valuable insights into these feasible solutions and theirassociated probabilities are embedded in the posterior distribution. However,when confronted with data of high dimensionality (such as images), visualizingthis distribution becomes a formidable challenge, necessitating the applicationof effective summarization techniques before user examination. In this work, weintroduce a new approach for visualizing posteriors across multiple levels ofgranularity using tree-valued predictions. Our method predicts a tree-valuedhierarchical summarization of the posterior distribution for any inputmeasurement, in a single forward pass of a neural network. We showcase theefficacy of our approach across diverse datasets and image restorationchallenges, highlighting its prowess in uncertainty quantification andvisualization. Our findings reveal that our method performs comparably to abaseline that hierarchically clusters samples from a diffusion-based posteriorsampler, yet achieves this with orders of magnitude greater speed.</description><author>Elias Nehme, Rotem Mulayoff, Tomer Michaeli</author><pubDate>Fri, 24 May 2024 18:06:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15719v1</guid></item><item><title>Infinite Limits of Multi-head Transformer Dynamics</title><link>http://arxiv.org/abs/2405.15712v1</link><description>In this work, we analyze various scaling limits of the training dynamics oftransformer models in the feature learning regime. We identify the set ofparameterizations that admit well-defined infinite width and depth limits,allowing the attention layers to update throughout training--a relevant notionof feature learning in these models. We then use tools from dynamical meanfield theory (DMFT) to analyze various infinite limits (infinite key/querydimension, infinite heads, and infinite depth) which have different statisticaldescriptions depending on which infinite limit is taken and how attentionlayers are scaled. We provide numerical evidence of convergence to the limitsand discuss how the parameterization qualitatively influences learned features.</description><author>Blake Bordelon, Hamza Tahir Chaudhry, Cengiz Pehlevan</author><pubDate>Fri, 24 May 2024 18:01:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15712v1</guid></item><item><title>Information-theoretic Generalization Analysis for Expected Calibration Error</title><link>http://arxiv.org/abs/2405.15709v1</link><description>While the expected calibration error (ECE), which employs binning, is widelyadopted to evaluate the calibration performance of machine learning models,theoretical understanding of its estimation bias is limited. In this paper, wepresent the first comprehensive analysis of the estimation bias in the twocommon binning strategies, uniform mass and uniform width binning. Our analysisestablishes upper bounds on the bias, achieving an improved convergence rate.Moreover, our bounds reveal, for the first time, the optimal number of bins tominimize the estimation bias. We further extend our bias analysis togeneralization error analysis based on the information-theoretic approach,deriving upper bounds that enable the numerical evaluation of how small the ECEis for unknown data. Experiments using deep learning models show that ourbounds are nonvacuous thanks to this information-theoretic generalizationanalysis approach.</description><author>Futoshi Futami, Masahiro Fujisawa</author><pubDate>Fri, 24 May 2024 17:59:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15709v1</guid></item><item><title>EmpathicStories++: A Multimodal Dataset for Empathy towards Personal Experiences</title><link>http://arxiv.org/abs/2405.15708v1</link><description>Modeling empathy is a complex endeavor that is rooted in interpersonal andexperiential dimensions of human interaction, and remains an open problemwithin AI. Existing empathy datasets fall short in capturing the richness ofempathy responses, often being confined to in-lab or acted scenarios, lackinglongitudinal data, and missing self-reported labels. We introduce a newmultimodal dataset for empathy during personal experience sharing: theEmpathicStories++ dataset(https://mitmedialab.github.io/empathic-stories-multimodal/) containing 53hours of video, audio, and text data of 41 participants sharing vulnerableexperiences and reading empathically resonant stories with an AI agent.EmpathicStories++ is the first longitudinal dataset on empathy, collected overa month-long deployment of social robots in participants' homes, asparticipants engage in natural, empathic storytelling interactions with AIagents. We then introduce a novel task of predicting individuals' empathytoward others' stories based on their personal experiences, evaluated in twocontexts: participants' own personal shared story context and their reflectionson stories they read. We benchmark this task using state-of-the-art models topave the way for future improvements in contextualized and longitudinal empathymodeling. Our work provides a valuable resource for further research indeveloping empathetic AI systems and understanding the intricacies of humanempathy within genuine, real-world settings.</description><author>Jocelyn Shen, Yubin Kim, Mohit Hulse, Wazeer Zulfikar, Sharifa Alghowinem, Cynthia Breazeal, Hae Won Park</author><pubDate>Fri, 24 May 2024 17:57:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15708v1</guid></item><item><title>The Impact of Geometric Complexity on Neural Collapse in Transfer Learning</title><link>http://arxiv.org/abs/2405.15706v1</link><description>Many of the recent remarkable advances in computer vision and language modelscan be attributed to the success of transfer learning via the pre-training oflarge foundation models. However, a theoretical framework which explains thisempirical success is incomplete and remains an active area of research.Flatness of the loss surface and neural collapse have recently emerged asuseful pre-training metrics which shed light on the implicit biases underlyingpre-training. In this paper, we explore the geometric complexity of a model'slearned representations as a fundamental mechanism that relates these twoconcepts. We show through experiments and theory that mechanisms which affectthe geometric complexity of the pre-trained network also influence the neuralcollapse. Furthermore, we show how this effect of the geometric complexitygeneralizes to the neural collapse of new classes as well, thus encouragingbetter performance on downstream tasks, particularly in the few-shot setting.</description><author>Michael Munn, Benoit Dherin, Javier Gonzalvo</author><pubDate>Fri, 24 May 2024 17:52:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15706v1</guid></item><item><title>Trackastra: Transformer-based cell tracking for live-cell microscopy</title><link>http://arxiv.org/abs/2405.15700v1</link><description>Cell tracking is an omnipresent image analysis task in live-cell microscopy.It is similar to multiple object tracking (MOT), however, each frame containshundreds of similar-looking objects that can divide, making it a challengingproblem. Current state-of-the-art approaches follow the tracking-by-detectionparadigm, i.e. first all cells are detected per frame and successively linkedin a second step to form biologically consistent cell tracks. Linking iscommonly solved via discrete optimization methods, which require manual tuningof hyperparameters for each dataset and are therefore cumbersome to use inpractice. Here we propose Trackastra, a general purpose cell tracking approachthat uses a simple transformer architecture to directly learn pairwiseassociations of cells within a temporal window from annotated data.Importantly, unlike existing transformer-based MOT pipelines, our learningarchitecture also accounts for dividing objects such as cells and allows foraccurate tracking even with simple greedy linking, thus making strides towardsremoving the requirement for a complex linking step. The proposed architectureoperates on the full spatio-temporal context of detections within a time windowby avoiding the computational burden of processing dense images. We show thatour tracking approach performs on par with or better than highly tunedstate-of-the-art cell tracking algorithms for various biological datasets, suchas bacteria, cell cultures and fluorescent particles. We provide code athttps://github.com/weigertlab/trackastra.</description><author>Benjamin Gallusser, Martin Weigert</author><pubDate>Fri, 24 May 2024 17:44:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15700v1</guid></item><item><title>Dimension-free deterministic equivalents for random feature regression</title><link>http://arxiv.org/abs/2405.15699v1</link><description>In this work we investigate the generalization performance of random featureridge regression (RFRR). Our main contribution is a general deterministicequivalent for the test error of RFRR. Specifically, under a certainconcentration property, we show that the test error is well approximated by aclosed-form expression that only depends on the feature map eigenvalues.Notably, our approximation guarantee is non-asymptotic, multiplicative, andindependent of the feature map dimension -- allowing for infinite-dimensionalfeatures. We expect this deterministic equivalent to hold broadly beyond ourtheoretical analysis, and we empirically validate its predictions on variousreal and synthetic datasets. As an application, we derive sharp excess errorrates under standard power-law assumptions of the spectrum and target decay. Inparticular, we provide a tight result for the smallest number of featuresachieving optimal minimax error rate.</description><author>Leonardo Defilippis, Bruno Loureiro, Theodor Misiakiewicz</author><pubDate>Fri, 24 May 2024 17:43:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15699v1</guid></item><item><title>Comparison of static and dynamic random forests models for EHR data in the presence of competing risks: predicting central line-associated bloodstream infection</title><link>http://arxiv.org/abs/2404.16127v2</link><description>Prognostic outcomes related to hospital admissions typically do not sufferfrom censoring, and can be modeled either categorically or as time-to-event.Competing events are common but often ignored. We compared the performance ofrandom forest (RF) models to predict the risk of central line-associatedbloodstream infections (CLABSI) using different outcome operationalizations. Weincluded data from 27478 admissions to the University Hospitals Leuven,covering 30862 catheter episodes (970 CLABSI, 1466 deaths and 28426 discharges)to build static and dynamic RF models for binary (CLABSI vs no CLABSI),multinomial (CLABSI, discharge, death or no event), survival (time to CLABSI)and competing risks (time to CLABSI, discharge or death) outcomes to predictthe 7-day CLABSI risk. We evaluated model performance across 100 train/testsplits. Performance of binary, multinomial and competing risks models wassimilar: AUROC was 0.74 for baseline predictions, rose to 0.78 for predictionsat day 5 in the catheter episode, and decreased thereafter. Survival modelsoverestimated the risk of CLABSI (E:O ratios between 1.2 and 1.6), and hadAUROCs about 0.01 lower than other models. Binary and multinomial models hadlowest computation times. Models including multiple outcome events (multinomialand competing risks) display a different internal structure compared to binaryand survival models. In the absence of censoring, complex modelling choices donot considerably improve the predictive performance compared to a binary modelfor CLABSI prediction in our studied settings. Survival models censoring thecompeting events at their time of occurrence should be avoided.</description><author>Elena Albu, Shan Gao, Pieter Stijnen, Frank Rademakers, Christel Janssens, Veerle Cossey, Yves Debaveye, Laure Wynants, Ben Van Calster</author><pubDate>Fri, 24 May 2024 17:43:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.16127v2</guid></item><item><title>Data-Copilot: Bridging Billions of Data and Humans with Autonomous Workflow</title><link>http://arxiv.org/abs/2306.07209v5</link><description>Industries such as finance, meteorology, and energy generate vast amounts ofdata daily. Efficiently managing, processing, and displaying this data requiresspecialized expertise and is often tedious and repetitive. Leveraging largelanguage models (LLMs) to develop an automated workflow presents a highlypromising solution. However, LLMs are not adept at handling complex numericalcomputations and table manipulations and are also constrained by a limitedcontext budget. Based on this, we propose Data-Copilot, a data analysis agentthat autonomously performs querying, processing, and visualization of massivedata tailored to diverse human requests. The advancements are twofold: First,it is a code-centric agent that receives human requests and generates code asan intermediary to handle massive data, which is quite flexible for large-scaledata processing tasks. Second, Data-Copilot involves a data exploration phasein advance, which explores how to design more universal and error-freeinterfaces for real-time response. Specifically, it actively explores datasources, discovers numerous common requests, and abstracts them into manyuniversal interfaces for daily invocation. When deployed in real-time requests,Data-Copilot only needs to invoke these pre-designed interfaces, transformingraw data into visualized outputs (e.g., charts, tables) that best match theuser's intent. Compared to generating code from scratch, invoking thesepre-designed and compiler-validated interfaces can significantly reduce errorsduring real-time requests. Additionally, interface workflows are more efficientand offer greater interpretability than code. We open-sourced Data-Copilot withmassive Chinese financial data, such as stocks, funds, and news, demonstratingpromising application prospects.</description><author>Wenqi Zhang, Yongliang Shen, Weiming Lu, Yueting Zhuang</author><pubDate>Fri, 24 May 2024 17:35:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07209v5</guid></item><item><title>Heart Murmur and Abnormal PCG Detection via Wavelet Scattering Transform &amp; a 1D-CNN</title><link>http://arxiv.org/abs/2303.11423v2</link><description>Heart murmurs provide valuable information about mechanical activity of theheart, which aids in diagnosis of various heart valve diseases. This work doesautomatic and accurate heart murmur detection from phonocardiogram (PCG)recordings. Two public PCG datasets (CirCor Digiscope 2022 dataset and PCG 2016dataset) from Physionet online database are utilized to train and test threecustom neural networks (NN): a 1D convolutional neural network (CNN), a longshort-term memory (LSTM) recurrent neural network (RNN), and a convolutionalRNN (C-RNN). We first do pre-processing which includes the following key steps:denoising, segmentation, re-labeling of noise-only segments, datanormalization, and time-frequency analysis of the PCG segments using waveletscattering transform. We then conduct four experiments, first three (E1-E3)using PCG 2022 dataset, and fourth (E4) using PCG 2016 dataset. It turns outthat our custom 1D-CNN outperforms other two NNs (LSTM-RNN and C-RNN). Further,our 1D-CNN model outperforms the related work in terms of accuracy, weightedaccuracy, F1-score and AUROC, for experiment E3 (that utilizes the cleaned andre-labeled PCG 2022 dataset). As for experiment E1 (that utilizes the originalPCG 2022 dataset), our model performs quite close to the related work in termsof weighted accuracy and F1-score.</description><author>Ahmed Patwa, Muhammad Mahboob Ur Rahman, Tareq Y. Al-Naffouri</author><pubDate>Fri, 24 May 2024 17:31:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11423v2</guid></item><item><title>WorDepth: Variational Language Prior for Monocular Depth Estimation</title><link>http://arxiv.org/abs/2404.03635v3</link><description>Three-dimensional (3D) reconstruction from a single image is an ill-posedproblem with inherent ambiguities, i.e. scale. Predicting a 3D scene from textdescription(s) is similarly ill-posed, i.e. spatial arrangements of objectsdescribed. We investigate the question of whether two inherently ambiguousmodalities can be used in conjunction to produce metric-scaled reconstructions.To test this, we focus on monocular depth estimation, the problem of predictinga dense depth map from a single image, but with an additional text captiondescribing the scene. To this end, we begin by encoding the text caption as amean and standard deviation; using a variational framework, we learn thedistribution of the plausible metric reconstructions of 3D scenes correspondingto the text captions as a prior. To "select" a specific reconstruction or depthmap, we encode the given image through a conditional sampler that samples fromthe latent space of the variational text encoder, which is then decoded to theoutput depth map. Our approach is trained alternatingly between the text andimage branches: in one optimization step, we predict the mean and standarddeviation from the text description and sample from a standard Gaussian, and inthe other, we sample using a (image) conditional sampler. Once trained, wedirectly predict depth from the encoded text using the conditional sampler. Wedemonstrate our approach on indoor (NYUv2) and outdoor (KITTI) scenarios, wherewe show that language can consistently improve performance in both.</description><author>Ziyao Zeng, Hyoungseob Park, Daniel Wang, Fengyu Yang, Yangchao Wu, Stefano Soatto, Byung-Woo Hong, Dong Lao, Alex Wong</author><pubDate>Fri, 24 May 2024 17:30:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03635v3</guid></item><item><title>Detecting Out-of-Distribution Through the Lens of Neural Collapse</title><link>http://arxiv.org/abs/2311.01479v4</link><description>Efficient and versatile Out-of-Distribution (OOD) detection is essential forthe safe deployment of AI yet remains challenging for existing algorithms.Inspired by Neural Collapse, we discover that features of in-distribution (ID)samples cluster closer to the weight vectors compared to features of OODsamples. In addition, we reveal that ID features tend to expand in space tostructure a simplex Equiangular Tight Framework, which nicely explains theprevalent observation that ID features reside further from the origin than OODfeatures. Taking both insights from Neural Collapse into consideration, wepropose to leverage feature proximity to weight vectors for OOD detection andfurther complement this perspective by using feature norms to filter OODsamples. Extensive experiments on off-the-shelf models demonstrate theefficiency and effectiveness of our method across diverse classification tasksand model architectures, enhancing the generalization capability of OODdetection.</description><author>Litian Liu, Yao Qin</author><pubDate>Fri, 24 May 2024 17:30:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01479v4</guid></item><item><title>Ctrl-Adapter: An Efficient and Versatile Framework for Adapting Diverse Controls to Any Diffusion Model</title><link>http://arxiv.org/abs/2404.09967v2</link><description>ControlNets are widely used for adding spatial control to text-to-imagediffusion models with different conditions, such as depth maps,scribbles/sketches, and human poses. However, when it comes to controllablevideo generation, ControlNets cannot be directly integrated into new backbonesdue to feature space mismatches, and training ControlNets for new backbones canbe a significant burden for many users. Furthermore, applying ControlNetsindependently to different frames cannot effectively maintain object temporalconsistency. To address these challenges, we introduce Ctrl-Adapter, anefficient and versatile framework that adds diverse controls to any image/videodiffusion model through the adaptation of pretrained ControlNets. Ctrl-Adapteroffers strong and diverse capabilities, including image and video control,sparse-frame video control, fine-grained patch-level multi-condition control(via an MoE router), zero-shot adaptation to unseen conditions, and supports avariety of downstream tasks beyond spatial control, including video editing,video style transfer, and text-guided motion control. With six diverseU-Net/DiT-based image/video diffusion models (SDXL, PixArt-$\alpha$, I2VGen-XL,SVD, Latte, Hotshot-XL), Ctrl-Adapter matches the performance of pretrainedControlNets on COCO and achieves the state-of-the-art on DAVIS 2017 withsignificantly lower computation (&lt; 10 GPU hours).</description><author>Han Lin, Jaemin Cho, Abhay Zala, Mohit Bansal</author><pubDate>Fri, 24 May 2024 17:29:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09967v2</guid></item><item><title>A Distributional Analogue to the Successor Representation</title><link>http://arxiv.org/abs/2402.08530v2</link><description>This paper contributes a new approach for distributional reinforcementlearning which elucidates a clean separation of transition structure and rewardin the learning process. Analogous to how the successor representation (SR)describes the expected consequences of behaving according to a given policy,our distributional successor measure (SM) describes the distributionalconsequences of this behaviour. We formulate the distributional SM as adistribution over distributions and provide theory connecting it withdistributional and model-based reinforcement learning. Moreover, we propose analgorithm that learns the distributional SM from data by minimizing a two-levelmaximum mean discrepancy. Key to our method are a number of algorithmictechniques that are independently valuable for learning generative models ofstate. As an illustration of the usefulness of the distributional SM, we showthat it enables zero-shot risk-sensitive policy evaluation in a way that wasnot previously possible.</description><author>Harley Wiltzer, Jesse Farebrother, Arthur Gretton, Yunhao Tang, André Barreto, Will Dabney, Marc G. Bellemare, Mark Rowland</author><pubDate>Fri, 24 May 2024 17:29:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08530v2</guid></item><item><title>Gaussian Splatting on the Move: Blur and Rolling Shutter Compensation for Natural Camera Motion</title><link>http://arxiv.org/abs/2403.13327v2</link><description>High-quality scene reconstruction and novel view synthesis based on GaussianSplatting (3DGS) typically require steady, high-quality photographs, oftenimpractical to capture with handheld cameras. We present a method that adaptsto camera motion and allows high-quality scene reconstruction with handheldvideo data suffering from motion blur and rolling shutter distortion. Ourapproach is based on detailed modelling of the physical image formation processand utilizes velocities estimated using visual-inertial odometry (VIO). Cameraposes are considered non-static during the exposure time of a single imageframe and camera poses are further optimized in the reconstruction process. Weformulate a differentiable rendering pipeline that leverages screen spaceapproximation to efficiently incorporate rolling-shutter and motion blureffects into the 3DGS framework. Our results with both synthetic and real datademonstrate superior performance in mitigating camera motion over existingmethods, thereby advancing 3DGS in naturalistic settings.</description><author>Otto Seiskari, Jerry Ylilammi, Valtteri Kaatrasalo, Pekka Rantalankila, Matias Turkulainen, Juho Kannala, Arno Solin</author><pubDate>Fri, 24 May 2024 17:29:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13327v2</guid></item><item><title>UNION: Unsupervised 3D Object Detection using Object Appearance-based Pseudo-Classes</title><link>http://arxiv.org/abs/2405.15688v1</link><description>Unsupervised 3D object detection methods have emerged to leverage vastamounts of data efficiently without requiring manual labels for training.Recent approaches rely on dynamic objects for learning to detect objects butpenalize the detections of static instances during training. Multiple rounds of(self) training are used in which detected static instances are added to theset of training targets; this procedure to improve performance iscomputationally expensive. To address this, we propose the method UNION. We usespatial clustering and self-supervised scene flow to obtain a set of static anddynamic object proposals from LiDAR. Subsequently, object proposals' visualappearances are encoded to distinguish static objects in the foreground andbackground by selecting static instances that are visually similar to dynamicobjects. As a result, static and dynamic foreground objects are obtainedtogether, and existing detectors can be trained with a single training. Inaddition, we extend 3D object discovery to detection by using objectappearance-based cluster labels as pseudo-class labels for training objectclassification. We conduct extensive experiments on the nuScenes dataset andincrease the state-of-the-art performance for unsupervised object discovery,i.e. UNION more than doubles the average precision to 33.9. The code will bemade publicly available.</description><author>Ted Lentsch, Holger Caesar, Dariu M. Gavrila</author><pubDate>Fri, 24 May 2024 17:27:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15688v1</guid></item><item><title>Chain-of-Thought Prompting for Demographic Inference with Large Multimodal Models</title><link>http://arxiv.org/abs/2405.15687v1</link><description>Conventional demographic inference methods have predominantly operated underthe supervision of accurately labeled data, yet struggle to adapt to shiftingsocial landscapes and diverse cultural contexts, leading to narrowspecialization and limited accuracy in applications. Recently, the emergence oflarge multimodal models (LMMs) has shown transformative potential acrossvarious research tasks, such as visual comprehension and description. In thisstudy, we explore the application of LMMs to demographic inference andintroduce a benchmark for both quantitative and qualitative evaluation. Ourfindings indicate that LMMs possess advantages in zero-shot learning,interpretability, and handling uncurated 'in-the-wild' inputs, albeit with apropensity for off-target predictions. To enhance LMM performance and achievecomparability with supervised learning baselines, we propose a Chain-of-Thoughtaugmented prompting approach, which effectively mitigates the off-targetprediction issue.</description><author>Yongsheng Yu, Jiebo Luo</author><pubDate>Fri, 24 May 2024 17:26:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15687v1</guid></item><item><title>Prompt-Aware Adapter: Towards Learning Adaptive Visual Tokens for Multimodal Large Language Models</title><link>http://arxiv.org/abs/2405.15684v1</link><description>To bridge the gap between vision and language modalities, Multimodal LargeLanguage Models (MLLMs) usually learn an adapter that converts visual inputs tounderstandable tokens for Large Language Models (LLMs). However, most adaptersgenerate consistent visual tokens, regardless of the specific objects ofinterest mentioned in the prompt. Since these adapters distribute equalattention to every detail in the image and focus on the entire scene, they mayincrease the cognitive load for LLMs, particularly when processing complexscenes. To alleviate this problem, we propose prompt-aware adapters. Theseadapters are designed with the capability to dynamically embed visual inputsbased on the specific focus of the prompt. Specifically, prompt-aware adaptersutilize both global and local textual features to capture the most relevantvisual clues from the prompt at both coarse and fine granularity levels. Thisapproach significantly enhances the ability of LLMs to understand and interpretvisual content. Experiments on various visual question answering tasks, such ascounting and position reasoning, demonstrate the effectiveness of prompt-awareadapters.</description><author>Yue Zhang, Hehe Fan, Yi Yang</author><pubDate>Fri, 24 May 2024 17:24:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15684v1</guid></item><item><title>Fast Sampling Through The Reuse Of Attention Maps In Diffusion Models</title><link>http://arxiv.org/abs/2401.01008v2</link><description>Text-to-image diffusion models have demonstrated unprecedented capabilitiesfor flexible and realistic image synthesis. Nevertheless, these models rely ona time-consuming sampling procedure, which has motivated attempts to reducetheir latency. When improving efficiency, researchers often use the originaldiffusion model to train an additional network designed specifically for fastimage generation. In contrast, our approach seeks to reduce latency directly,without any retraining, fine-tuning, or knowledge distillation. In particular,we find the repeated calculation of attention maps to be costly yet redundant,and instead suggest reusing them during sampling. Our specific reuse strategiesare based on ODE theory, which implies that the later a map is reused, thesmaller the distortion in the final image. We empirically compare these reusestrategies with few-step sampling procedures of comparable latency, findingthat reuse generates images that are closer to those produced by the originalhigh-latency diffusion model.</description><author>Rosco Hunter, Łukasz Dudziak, Mohamed S. Abdelfattah, Abhinav Mehrotra, Sourav Bhattacharya, Hongkai Wen</author><pubDate>Fri, 24 May 2024 17:23:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01008v2</guid></item><item><title>VDGD: Mitigating LVLM Hallucinations in Cognitive Prompts by Bridging the Visual Perception Gap</title><link>http://arxiv.org/abs/2405.15683v1</link><description>Recent interest in Large Vision-Language Models (LVLMs) for practicalapplications is moderated by the significant challenge of hallucination or theinconsistency between the factual information and the generated text. In thispaper, we first perform an in-depth analysis of hallucinations and discoverseveral novel insights about how and when LVLMs hallucinate. From our analysis,we show that: (1) The community's efforts have been primarily targeted towardsreducing hallucinations related to visual recognition (VR) prompts (e.g.,prompts that only require describing the image), thereby ignoringhallucinations for cognitive prompts (e.g., prompts that require additionalskills like reasoning on contents of the image). (2) LVLMs lack visualperception, i.e., they can see but not necessarily understand or perceive theinput image. We analyze responses to cognitive prompts and show that LVLMshallucinate due to a perception gap: although LVLMs accurately recognize visualelements in the input image and possess sufficient cognitive skills, theystruggle to respond accurately and hallucinate. To overcome this shortcoming,we propose Visual Description Grounded Decoding (VDGD), a simple, robust, andtraining-free method for alleviating hallucinations. Specifically, we firstdescribe the image and add it as a prefix to the instruction. Next, duringauto-regressive decoding, we sample from the plausible candidates according totheir KL-Divergence (KLD) to the description, where lower KLD is given higherpreference. Experimental results on several benchmarks and LVLMs show that VDGDimproves significantly over other baselines in reducing hallucinations. We alsopropose VaLLu, a benchmark for the comprehensive evaluation of the cognitivecapabilities of LVLMs.</description><author>Sreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Kumar, Utkarsh Tyagi, Oriol Nieto, Zeyu Jin, Dinesh Manocha</author><pubDate>Fri, 24 May 2024 17:21:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15683v1</guid></item><item><title>What AIs are not Learning (and Why): Bio-Inspired Foundation Models for Robots</title><link>http://arxiv.org/abs/2404.04267v8</link><description>It is hard to make robots (including telerobots) that are useful, and harderto make autonomous robots that are robust and general. Current smart robots arecreated using manual programming, mathematical models, planning frameworks, andreinforcement learning. These methods do not lead to the leaps in performanceand generality seen with deep learning, generative AI, and foundation models(FMs). Today's robots do not learn to provide home care, to be nursingassistants, or to do household chores nearly as well as people do. Addressingthe aspirational opportunities of robot service applications requires improvinghow they are created. The high cost of bipedal multi-sensory robots ("bodies")is a significant obstacle for both research and deployment. A deeper issue isthat mainstream FMs ("minds") do not support sensing, acting, and learning incontext in the real world. They do not lead to robots that communicate well orcollaborate. They do not lead to robots that try to learn by experimenting, byasking others, or by imitation learning as appropriate. They do not lead torobots that know enough to be deployed widely in service applications. Thispaper focuses on what human-compatible service robots need to know. Itrecommends developing experiential (aka "robotic") FMs for bootstrapping them.</description><author>Mark Stefik</author><pubDate>Fri, 24 May 2024 17:20:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04267v8</guid></item><item><title>The Road Less Scheduled</title><link>http://arxiv.org/abs/2405.15682v1</link><description>Existing learning rate schedules that do not require specification of theoptimization stopping step T are greatly out-performed by learning rateschedules that depend on T. We propose an approach that avoids the need forthis stopping time by eschewing the use of schedules entirely, while exhibitingstate-of-the-art performance compared to schedules across a wide family ofproblems ranging from convex problems to large-scale deep learning problems.Our Schedule-Free approach introduces no additional hyper-parameters overstandard optimizers with momentum. Our method is a direct consequence of a newtheory we develop that unifies scheduling and iterate averaging. An open sourceimplementation of our method is available(https://github.com/facebookresearch/schedule_free).</description><author>Aaron Defazio, Xingyu, Yang, Harsh Mehta, Konstantin Mishchenko, Ahmed Khaled, Ashok Cutkosky</author><pubDate>Fri, 24 May 2024 17:20:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15682v1</guid></item><item><title>Toward TransfORmers: Revolutionizing the Solution of Mixed Integer Programs with Transformers</title><link>http://arxiv.org/abs/2402.13380v3</link><description>In this study, we introduce an innovative deep learning framework thatemploys a transformer model to address the challenges of mixed-integerprograms, specifically focusing on the Capacitated Lot Sizing Problem (CLSP).Our approach, to our knowledge, is the first to utilize transformers to predictthe binary variables of a mixed-integer programming (MIP) problem.Specifically, our approach harnesses the encoder decoder transformer's abilityto process sequential data, making it well-suited for predicting binaryvariables indicating production setup decisions in each period of the CLSP.This problem is inherently dynamic, and we need to handle sequential decisionmaking under constraints. We present an efficient algorithm in which CLSPsolutions are learned through a transformer neural network. The proposedpost-processed transformer algorithm surpasses the state-of-the-art solver,CPLEX and Long Short-Term Memory (LSTM) in solution time, optimal gap, andpercent infeasibility over 240K benchmark CLSP instances tested. After the MLmodel is trained, conducting inference on the model, reduces the MIP into alinear program (LP). This transforms the ML-based algorithm, combined with anLP solver, into a polynomial-time approximation algorithm to solve a well-knownNP-Hard problem, with almost perfect solution quality.</description><author>Joshua F. Cooper, Seung Jin Choi, I. Esra Buyuktahtakin</author><pubDate>Fri, 24 May 2024 17:17:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13380v3</guid></item><item><title>SMART: Scalable Multi-agent Real-time Simulation via Next-token Prediction</title><link>http://arxiv.org/abs/2405.15677v1</link><description>Data-driven autonomous driving motion generation tasks are frequentlyimpacted by the limitations of dataset size and the domain gap betweendatasets, which precludes their extensive application in real-world scenarios.To address this issue, we introduce SMART, a novel autonomous driving motiongeneration paradigm that models vectorized map and agent trajectory data intodiscrete sequence tokens. These tokens are then processed through adecoder-only transformer architecture to train for the next token predictiontask across spatial-temporal series. This GPT-style method allows the model tolearn the motion distribution in real driving scenarios. SMART achievesstate-of-the-art performance across most of the metrics on the generative SimAgents challenge, ranking 1st on the leaderboards of Waymo Open Motion Dataset(WOMD), demonstrating remarkable inference speed. Moreover, SMART representsthe generative model in the autonomous driving motion domain, exhibitingzero-shot generalization capabilities: Using only the NuPlan dataset fortraining and WOMD for validation, SMART achieved a competitive score of 0.71 onthe Sim Agents challenge. Lastly, we have collected over 1 billion motiontokens from multiple datasets, validating the model's scalability. Theseresults suggest that SMART has initially emulated two important properties:scalability and zero-shot generalization, and preliminarily meets the needs oflarge-scale real-time simulation applications. We have released all the code topromote the exploration of models for motion generation in the autonomousdriving field.</description><author>Wei Wu, Xiaoxin Feng, Ziyan Gao, Yuheng Kan</author><pubDate>Fri, 24 May 2024 17:17:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15677v1</guid></item><item><title>Taming Score-Based Diffusion Priors for Infinite-Dimensional Nonlinear Inverse Problems</title><link>http://arxiv.org/abs/2405.15676v1</link><description>This work introduces a sampling method capable of solving Bayesian inverseproblems in function space. It does not assume the log-concavity of thelikelihood, meaning that it is compatible with nonlinear inverse problems. Themethod leverages the recently defined infinite-dimensional score-baseddiffusion models as a learning-based prior, while enabling provable posteriorsampling through a Langevin-type MCMC algorithm defined on function spaces. Anovel convergence analysis is conducted, inspired by the fixed-point methodsestablished for traditional regularization-by-denoising algorithms andcompatible with weighted annealing. The obtained convergence bound explicitlydepends on the approximation error of the score; a well-approximated score isessential to obtain a well-approximated posterior. Stylized and PDE-basedexamples are provided, demonstrating the validity of our convergence analysis.We conclude by presenting a discussion of the method's challenges related tolearning the score and computational complexity.</description><author>Lorenzo Baldassari, Ali Siahkoohi, Josselin Garnier, Knut Solna, Maarten V. de Hoop</author><pubDate>Fri, 24 May 2024 17:17:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15676v1</guid></item><item><title>Data-driven Semi-supervised Machine Learning with Surrogate Safety Measures for Abnormal Driving Behavior Detection</title><link>http://arxiv.org/abs/2312.04610v5</link><description>Detecting abnormal driving behavior is critical for road traffic safety andthe evaluation of drivers' behavior. With the advancement of machine learning(ML) algorithms and the accumulation of naturalistic driving data, many MLmodels have been adopted for abnormal driving behavior detection. Most existingML-based detectors rely on (fully) supervised ML methods, which requiresubstantial labeled data. However, ground truth labels are not always availablein the real world, and labeling large amounts of data is tedious. Thus, thereis a need to explore unsupervised or semi-supervised methods to make theanomaly detection process more feasible and efficient. To fill this researchgap, this study analyzes large-scale real-world data revealing several abnormaldriving behaviors (e.g., sudden acceleration, rapid lane-changing) and developsa Hierarchical Extreme Learning Machines (HELM) based semi-supervised ML methodusing partly labeled data to accurately detect the identified abnormal drivingbehaviors. Moreover, previous ML-based approaches predominantly utilize basicvehicle motion features (such as velocity and acceleration) to label and detectabnormal driving behaviors, while this study seeks to introduce SurrogateSafety Measures (SSMs) as the input features for ML models to improve thedetection performance. Results from extensive experiments demonstrate theeffectiveness of the proposed semi-supervised ML model with the introduced SSMsserving as important features. The proposed semi-supervised ML methodoutperforms other baseline semi-supervised or unsupervised methods regardingvarious metrics, e.g., delivering the best accuracy at 99.58% and the best F-1measure at 0.9913. The ablation study further highlights the significance ofSSMs for advancing detection performance.</description><author>Yongqi Dong, Lanxin Zhang, Haneen Farah, Arkady Zgonnikov, Bart van Arem</author><pubDate>Fri, 24 May 2024 17:16:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04610v5</guid></item><item><title>GES: Generalized Exponential Splatting for Efficient Radiance Field Rendering</title><link>http://arxiv.org/abs/2402.10128v2</link><description>Advancements in 3D Gaussian Splatting have significantly accelerated 3Dreconstruction and generation. However, it may require a large number ofGaussians, which creates a substantial memory footprint. This paper introducesGES (Generalized Exponential Splatting), a novel representation that employsGeneralized Exponential Function (GEF) to model 3D scenes, requiring far fewerparticles to represent a scene and thus significantly outperforming GaussianSplatting methods in efficiency with a plug-and-play replacement ability forGaussian-based utilities. GES is validated theoretically and empirically inboth principled 1D setup and realistic 3D scenes. It is shown to represent signals with sharp edges more accurately, which aretypically challenging for Gaussians due to their inherent low-passcharacteristics. Our empirical analysis demonstrates that GEF outperformsGaussians in fitting natural-occurring signals (e.g. squares, triangles, andparabolic signals), thereby reducing the need for extensive splittingoperations that increase the memory footprint of Gaussian Splatting. With theaid of a frequency-modulated loss, GES achieves competitive performance innovel-view synthesis benchmarks while requiring less than half the memorystorage of Gaussian Splatting and increasing the rendering speed by up to 39%.The code is available on the project website https://abdullahamdi.com/ges .</description><author>Abdullah Hamdi, Luke Melas-Kyriazi, Jinjie Mai, Guocheng Qian, Ruoshi Liu, Carl Vondrick, Bernard Ghanem, Andrea Vedaldi</author><pubDate>Fri, 24 May 2024 17:13:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10128v2</guid></item><item><title>FedAWARE: Maximizing Gradient Diversity for Heterogeneous Federated Server-side Optimization</title><link>http://arxiv.org/abs/2310.02702v3</link><description>Federated learning (FL) is a distributed learning framework where numerousclients collaborate with a central server to train a model without sharinglocal data. However, the standard federated optimization in real-worldapplications faces both statistical and system heterogeneity challenges, whichresult in unfavorable convergence behavior. The previous works attempted tomodify the local training process (client-side) to tackle heterogeneitychallenges. However, they ignored that the updates on the server side cancoordinate the diverse local updates efficiently. This work explores the effectof server-side updates against heterogeneity issues. We first introduce thegradient diversity maximization direction findings, suggesting the global modelmoves continuously in this direction for fast and stable convergence. Then, wederive a novel server-side optimizer \textsc{FedAWARE} with rigorousconvergence analysis for general non-convex settings. Our extensive experimentsacross multiple heterogeneous federated settings using four datasets showcasethat \textsc{FedAWARE} achieves competitive convergence performance incomparison to state-of-the-art adaptive federated optimizers. Furthermore, ourresults show that \textsc{FedAWARE} can enhance the performance of FLalgorithms as a plug-in module. Our source code is available at\url{https://github.com/dunzeng/FedAWARE}.</description><author>Dun Zeng, Zenglin Xu, Yu Pan, Qifan Wang, Xiaoying Tang</author><pubDate>Fri, 24 May 2024 17:13:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02702v3</guid></item><item><title>Consistency of Neural Causal Partial Identification</title><link>http://arxiv.org/abs/2405.15673v1</link><description>Recent progress in Neural Causal Models (NCMs) showcased how identificationand partial identification of causal effects can be automatically carried outvia training of neural generative models that respect the constraints encodedin a given causal graph [Xia et al. 2022, Balazadeh et al. 2022]. However,formal consistency of these methods has only been proven for the case ofdiscrete variables or only for linear causal models. In this work, we proveconsistency of partial identification via NCMs in a general setting with bothcontinuous and categorical variables. Further, our results highlight the impactof the design of the underlying neural network architecture in terms of depthand connectivity as well as the importance of applying Lipschitz regularizationin the training phase. In particular, we provide a counterexample showing thatwithout Lipschitz regularization the NCM may not be asymptotically consistent.Our results are enabled by new results on the approximability of structuralcausal models via neural generative models, together with an analysis of thesample complexity of the resulting architectures and how that translates intoan error in the constrained optimization problem that defines the partialidentification bounds.</description><author>Jiyuan Tan, Jose Blanchet, Vasilis Syrgkanis</author><pubDate>Fri, 24 May 2024 17:12:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15673v1</guid></item><item><title>Coordinated Disclosure for AI: Beyond Security Vulnerabilities</title><link>http://arxiv.org/abs/2402.07039v2</link><description>Harm reporting in the field of Artificial Intelligence (AI) currentlyoperates on an ad hoc basis, lacking a structured process for disclosing oraddressing algorithmic flaws. In contrast, the Coordinated VulnerabilityDisclosure (CVD) ethos and ecosystem play a pivotal role in software securityand transparency. Globally, there are ongoing efforts to establish frameworksthat promote transparency and collaboration in addressing AI-related issues,though challenges persist. Algorithmic flaws in machine learning (ML) modelspresent distinct challenges compared to traditional software vulnerabilities,warranting a specialized approach. To address this gap, we propose theimplementation of a dedicated Coordinated Flaw Disclosure (CFD) frameworktailored to the intricacies of machine learning and artificial intelligenceissues. This paper delves into the historical landscape of disclosures in ML,encompassing the ad hoc reporting of harms and the emergence of participatoryauditing. By juxtaposing these practices with the well-established disclosurenorms in cybersecurity, we argue that the broader adoption of CFD has thepotential to enhance public trust through transparent processes that carefullybalance the interests of both organizations and the community.</description><author>Sven Cattell, Avijit Ghosh, Lucie-Aimée Kaffee</author><pubDate>Fri, 24 May 2024 17:08:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07039v2</guid></item><item><title>Optimal Algorithms for Online Convex Optimization with Adversarial Constraints</title><link>http://arxiv.org/abs/2310.18955v2</link><description>A well-studied generalization of the standard online convex optimization(OCO) is constrained online convex optimization (COCO). In COCO, on everyround, a convex cost function and a convex constraint function are revealed tothe learner after the action for that round is chosen. The objective is todesign an online policy that simultaneously achieves a small regret whileensuring a small cumulative constraint violation (CCV) against an adaptiveadversary interacting over a horizon of length $T$. A long-standing openquestion in COCO is whether an online policy can simultaneously achieve$O(\sqrt{T})$ regret and $O(\sqrt{T})$ CCV without any restrictive assumptions.For the first time, we answer this in the affirmative and show that an onlinepolicy can simultaneously achieve $O(\sqrt{T})$ regret and$\tilde{O}(\sqrt{T})$ CCV. Furthermore, in the case of strongly convex cost andconvex constraint functions, the regret guarantee can be improved to $O(\logT)$ while keeping the CCV bound the same as above. We establish these resultsby effectively combining the adaptive regret bound of the AdaGrad algorithmwith Lyapunov optimization - a classic tool from control theory. Surprisingly,the analysis is short and elegant.</description><author>Abhishek Sinha, Rahul Vaze</author><pubDate>Fri, 24 May 2024 17:07:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18955v2</guid></item><item><title>Mirage: An RNS-Based Photonic Accelerator for DNN Training</title><link>http://arxiv.org/abs/2311.17323v2</link><description>Photonic computing is a compelling avenue for performing highly efficientmatrix multiplication, a crucial operation in Deep Neural Networks (DNNs).While this method has shown great success in DNN inference, meeting the highprecision demands of DNN training proves challenging due to the precisionlimitations imposed by costly data converters and the analog noise inherent inphotonic hardware. This paper proposes Mirage, a photonic DNN trainingaccelerator that overcomes the precision challenges in photonic hardware usingthe Residue Number System (RNS). RNS is a numeral system based on modulararithmetic, allowing us to perform high-precision operations via multiplelow-precision modular operations. In this work, we present a novelmicro-architecture and dataflow for an RNS-based photonic tensor coreperforming modular arithmetic in the analog domain. By combining RNS andphotonics, Mirage provides high energy efficiency without compromisingprecision and can successfully train state-of-the-art DNNs achieving accuracycomparable to FP32 training. Our study shows that on average across severalDNNs when compared to systolic arrays, Mirage achieves more than $23.8\times$faster training and $32.1\times$ lower EDP in an iso-energy scenario andconsumes $42.8\times$ lower power with comparable or better EDP in an iso-areascenario.</description><author>Cansu Demirkiran, Guowei Yang, Darius Bunandar, Ajay Joshi</author><pubDate>Fri, 24 May 2024 17:06:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17323v2</guid></item><item><title>What Do You See? Enhancing Zero-Shot Image Classification with Multimodal Large Language Models</title><link>http://arxiv.org/abs/2405.15668v1</link><description>Large language models (LLMs) has been effectively used for many computervision tasks, including image classification. In this paper, we present asimple yet effective approach for zero-shot image classification usingmultimodal LLMs. By employing multimodal LLMs, we generate comprehensivetextual representations from input images. These textual representations arethen utilized to generate fixed-dimensional features in a cross-modal embeddingspace. Subsequently, these features are fused together to perform zero-shotclassification using a linear classifier. Our method does not require promptengineering for each dataset; instead, we use a single, straightforward, set ofprompts across all datasets. We evaluated our method on several datasets, andour results demonstrate its remarkable effectiveness, surpassing benchmarkaccuracy on multiple datasets. On average over ten benchmarks, our methodachieved an accuracy gain of 4.1 percentage points, with an increase of 6.8percentage points on the ImageNet dataset, compared to prior methods. Ourfindings highlight the potential of multimodal LLMs to enhance computer visiontasks such as zero-shot image classification, offering a significantimprovement over traditional methods.</description><author>Abdelrahman Abdelhamed, Mahmoud Afifi, Alec Go</author><pubDate>Fri, 24 May 2024 17:05:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15668v1</guid></item><item><title>GroundGrid:LiDAR Point Cloud Ground Segmentation and Terrain Estimation</title><link>http://arxiv.org/abs/2405.15664v1</link><description>The precise point cloud ground segmentation is a crucial prerequisite ofvirtually all perception tasks for LiDAR sensors in autonomous vehicles.Especially the clustering and extraction of objects from a point cloud usuallyrelies on an accurate removal of ground points. The correct estimation of thesurrounding terrain is important for aspects of the drivability of a surface,path planning, and obstacle prediction. In this article, we propose our systemGroundGrid which relies on 2D elevation maps to solve the terrain estimationand point cloud ground segmentation problems. We evaluate the groundsegmentation and terrain estimation performance of GroundGrid and compare it toother state-of-the-art methods using the SemanticKITTI dataset and a novelevaluation method relying on airborne LiDAR scanning. The results show thatGroundGrid is capable of outperforming other state-of-the-art systems with anaverage IoU of 94.78% while maintaining a high run-time performance of 171Hz.The source code is available at https://github.com/dcmlr/groundgrid</description><author>Nicolai Steinke, Daniel Göhring, Raùl Rojas</author><pubDate>Fri, 24 May 2024 17:02:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15664v1</guid></item><item><title>Class Machine Unlearning for Complex Data via Concepts Inference and Data Poisoning</title><link>http://arxiv.org/abs/2405.15662v1</link><description>In current AI era, users may request AI companies to delete their data fromthe training dataset due to the privacy concerns. As a model owner, retraininga model will consume significant computational resources. Therefore, machineunlearning is a new emerged technology to allow model owner to delete requestedtraining data or a class with little affecting on the model performance.However, for large-scaling complex data, such as image or text data, unlearninga class from a model leads to a inferior performance due to the difficulty toidentify the link between classes and model. An inaccurate class deleting maylead to over or under unlearning. In this paper, to accurately defining theunlearning class of complex data, we apply the definition of Concept, ratherthan an image feature or a token of text data, to represent the semanticinformation of unlearning class. This new representation can cut the linkbetween the model and the class, leading to a complete erasing of the impact ofa class. To analyze the impact of the concept of complex data, we adopt aPost-hoc Concept Bottleneck Model, and Integrated Gradients to preciselyidentify concepts across different classes. Next, we take advantage of datapoisoning with random and targeted labels to propose unlearning methods. Wetest our methods on both image classification models and large language models(LLMs). The results consistently show that the proposed methods can accuratelyerase targeted information from models and can largely maintain the performanceof the models.</description><author>Wenhan Chang, Tianqing Zhu, Heng Xu, Wenjian Liu, Wanlei Zhou</author><pubDate>Fri, 24 May 2024 16:59:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15662v1</guid></item><item><title>Exposing Image Classifier Shortcuts with Counterfactual Frequency (CoF) Tables</title><link>http://arxiv.org/abs/2405.15661v1</link><description>The rise of deep learning in image classification has brought unprecedentedaccuracy but also highlighted a key issue: the use of 'shortcuts' by models.Such shortcuts are easy-to-learn patterns from the training data that fail togeneralise to new data. Examples include the use of a copyright watermark torecognise horses, snowy background to recognise huskies, or ink markings todetect malignant skin lesions. The explainable AI (XAI) community has suggestedusing instance-level explanations to detect shortcuts without external data,but this requires the examination of many explanations to confirm the presenceof such shortcuts, making it a labour-intensive process. To address thesechallenges, we introduce Counterfactual Frequency (CoF) tables, a novelapproach that aggregates instance-based explanations into global insights, andexposes shortcuts. The aggregation implies the need for some semantic conceptsto be used in the explanations, which we solve by labelling the segments of animage. We demonstrate the utility of CoF tables across several datasets,revealing the shortcuts learned from them.</description><author>James Hinns, David Martens</author><pubDate>Fri, 24 May 2024 16:58:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15661v1</guid></item><item><title>MuLan: Multimodal-LLM Agent for Progressive and Interactive Multi-Object Diffusion</title><link>http://arxiv.org/abs/2402.12741v2</link><description>Existing text-to-image models still struggle to generate images of multipleobjects, especially in handling their spatial positions, relative sizes,overlapping, and attribute bindings. To efficiently address these challenges,we develop a training-free Multimodal-LLM agent (MuLan), as a human painter,that can progressively generate multi-object with intricate planning andfeedback control. MuLan harnesses a large language model (LLM) to decompose aprompt to a sequence of sub-tasks, each generating only one object by stablediffusion, conditioned on previously generated objects. Unlike existingLLM-grounded methods, MuLan only produces a high-level plan at the beginningwhile the exact size and location of each object are determined upon eachsub-task by an LLM and attention guidance. Moreover, MuLan adopts avision-language model (VLM) to provide feedback to the image generated in eachsub-task and control the diffusion model to re-generate the image if itviolates the original prompt. Hence, each model in every step of MuLan onlyneeds to address an easy sub-task it is specialized for. The multi-step processalso allows human users to monitor the generation process and make preferredchanges at any intermediate step via text prompts, thereby improving thehuman-AI collaboration experience. We collect 200 prompts containingmulti-objects with spatial relationships and attribute bindings from differentbenchmarks to evaluate MuLan. The results demonstrate the superiority of MuLanin generating multiple objects over baselines and its creativity whencollaborating with human users. The code is available athttps://github.com/measure-infinity/mulan-code.</description><author>Sen Li, Ruochen Wang, Cho-Jui Hsieh, Minhao Cheng, Tianyi Zhou</author><pubDate>Fri, 24 May 2024 16:56:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12741v2</guid></item><item><title>Low-Light Video Enhancement via Spatial-Temporal Consistent Illumination and Reflection Decomposition</title><link>http://arxiv.org/abs/2405.15660v1</link><description>Low-Light Video Enhancement (LLVE) seeks to restore dynamic and static scenesplagued by severe invisibility and noise. One critical aspect is formulating aconsistency constraint specifically for temporal-spatial illumination andappearance enhanced versions, a dimension overlooked in existing methods. Inthis paper, we present an innovative video Retinex-based decomposition strategythat operates without the need for explicit supervision to delineateillumination and reflectance components. We leverage dynamic cross-framecorrespondences for intrinsic appearance and enforce a scene-level continuityconstraint on the illumination field to yield satisfactory consistentdecomposition results. To further ensure consistent decomposition, we introducea dual-structure enhancement network featuring a novel cross-frame interactionmechanism. This mechanism can seamlessly integrate with encoder-decodersingle-frame networks, incurring minimal additional parameter costs. Bysupervising different frames simultaneously, this network encourages them toexhibit matching decomposition features, thus achieving the desired temporalpropagation. Extensive experiments are conducted on widely recognized LLVEbenchmarks, covering diverse scenarios. Our framework consistently outperformsexisting methods, establishing a new state-of-the-art (SOTA) performance.</description><author>Xiaogang Xu, Kun Zhou, Tao Hu, Ruixing Wang, Hujun Bao</author><pubDate>Fri, 24 May 2024 16:56:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15660v1</guid></item><item><title>HDC: Hierarchical Semantic Decoding with Counting Assistance for Generalized Referring Expression Segmentation</title><link>http://arxiv.org/abs/2405.15658v1</link><description>The newly proposed Generalized Referring Expression Segmentation (GRES)amplifies the formulation of classic RES by involving multiple/non-targetscenarios. Recent approaches focus on optimizing the last modality-fusedfeature which is directly utilized for segmentation and object-existenceidentification. However, the attempt to integrate all-grained information intoa single joint representation is impractical in GRES due to the increasedcomplexity of the spatial relationships among instances and deceptive textdescriptions. Furthermore, the subsequent binary target justification acrossall referent scenarios fails to specify their inherent differences, leading toambiguity in object understanding. To address the weakness, we propose a$\textbf{H}$ierarchical Semantic $\textbf{D}$ecoding with $\textbf{C}$ountingAssistance framework (HDC). It hierarchically transfers complementary modalityinformation across granularities, and then aggregates each well-alignedsemantic correspondence for multi-level decoding. Moreover, with completesemantic context modeling, we endow HDC with explicit counting capability tofacilitate comprehensive object perception in multiple/single/non-targetsettings. Experimental results on gRefCOCO, Ref-ZOM, R-RefCOCO, and RefCOCObenchmarks demonstrate the effectiveness and rationality of HDC whichoutperforms the state-of-the-art GRES methods by a remarkable margin. Code willbe available $\href{https://github.com/RobertLuo1/HDC}{here}$.</description><author>Zhuoyan Luo, Yinghao Wu, Yong Liu, Yicheng Xiao, Xiao-Ping Zhang, Yujiu Yang</author><pubDate>Fri, 24 May 2024 16:53:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15658v1</guid></item><item><title>Light Unbalanced Optimal Transport</title><link>http://arxiv.org/abs/2303.07988v3</link><description>While the continuous Entropic Optimal Transport (EOT) field has been activelydeveloping in recent years, it became evident that the classic EOT problem isprone to different issues like the sensitivity to outliers and imbalance ofclasses in the source and target measures. This fact inspired the developmentof solvers that deal with the unbalanced EOT (UEOT) problem $-$ thegeneralization of EOT allowing for mitigating the mentioned issues by relaxingthe marginal constraints. Surprisingly, it turns out that the existing solversare either based on heuristic principles or heavy-weighted with complexoptimization objectives involving several neural networks. We address thischallenge and propose a novel theoretically-justified, lightweight, unbalancedEOT solver. Our advancement consists of developing a novel view on theoptimization of the UEOT problem yielding tractable and a non-minimaxoptimization objective. We show that combined with a light parametrizationrecently proposed in the field our objective leads to a fast, simple, andeffective solver which allows solving the continuous UEOT problem in minutes onCPU. We prove that our solver provides a universal approximation of UEOTsolutions and obtain its generalization bounds. We give illustrative examplesof the solver's performance.</description><author>Milena Gazdieva, Arip Asadulaev, Alexander Korotin, Evgeny Burnaev</author><pubDate>Fri, 24 May 2024 16:53:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07988v3</guid></item><item><title>Dual Lagrangian Learning for Conic Optimization</title><link>http://arxiv.org/abs/2402.03086v2</link><description>This paper presents Dual Lagrangian Learning (DLL), a principled learningmethodology for dual conic optimization proxies. DLL leverages conic dualityand the representation power of ML models to provide high-duality,dual-feasible solutions, and therefore valid Lagrangian dual bounds, for linearand nonlinear conic optimization problems. The paper introduces a systematicdual completion procedure, differentiable conic projection layers, and aself-supervised learning framework based on Lagrangian duality. It alsoprovides closed-form dual completion formulae for broad classes of conicproblems, which eliminate the need for costly implicit layers. Theeffectiveness of DLL is demonstrated on linear and nonlinear conic optimizationproblems. The proposed methodology significantly outperforms a state-of-the-artlearning-based method, and achieves 1000x speedups over commercialinterior-point solvers with optimality gaps under 0.5\% on average.</description><author>Mathieu Tanneau, Pascal Van Hentenryck</author><pubDate>Fri, 24 May 2024 16:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03086v2</guid></item><item><title>HiddenSpeaker: Generate Imperceptible Unlearnable Audios for Speaker Verification System</title><link>http://arxiv.org/abs/2405.15655v1</link><description>In recent years, the remarkable advancements in deep neural networks havebrought tremendous convenience. However, the training process of a highlyeffective model necessitates a substantial quantity of samples, which bringshuge potential threats, like unauthorized exploitation with privacy leakage. Inresponse, we propose a framework named HiddenSpeaker, embedding imperceptibleperturbations within the training speech samples and rendering them unlearnablefor deep-learning-based speaker verification systems that employ large-scalespeakers for efficient training. The HiddenSpeaker utilizes a simplifiederror-minimizing method named Single-Level Error-Minimizing (SLEM) to generatespecific and effective perturbations. Additionally, a hybrid objective functionis employed for human perceptual optimization, ensuring the perturbation isindistinguishable from human listeners. We conduct extensive experiments onmultiple state-of-the-art (SOTA) models in the speaker verification domain toevaluate HiddenSpeaker. Our results demonstrate that HiddenSpeaker not onlydeceives the model with unlearnable samples but also enhances theimperceptibility of the perturbations, showcasing strong transferability acrossdifferent models.</description><author>Zhisheng Zhang, Pengyang Huang</author><pubDate>Fri, 24 May 2024 16:49:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15655v1</guid></item><item><title>GLiDR: Topologically Regularized Graph Generative Network for Sparse LiDAR Point Clouds</title><link>http://arxiv.org/abs/2312.00068v3</link><description>Sparse LiDAR point clouds cause severe loss of detail of static structuresand reduce the density of static points available for navigation. Reduceddensity can be detrimental to navigation under several scenarios. We observethat despite high sparsity, in most cases, the global topology of LiDARoutlining the static structures can be inferred. We utilize this property toobtain a backbone skeleton of a LiDAR scan in the form of a single connectedcomponent that is a proxy to its global topology. We utilize the backbone toaugment new points along static structures to overcome sparsity. Newlyintroduced points could correspond to existing static structures or to staticpoints that were earlier obstructed by dynamic objects. To the best of ourknowledge, we are the first to use such a strategy for sparse LiDAR pointclouds. Existing solutions close to our approach fail to identify and preservethe global static LiDAR topology and generate sub-optimal points. We proposeGLiDR, a Graph Generative network that is topologically regularized using0-dimensional Persistent Homology ($\mathcal{PH}$) constraints. This enablesGLiDR to introduce newer static points along a topologically consistent globalstatic LiDAR backbone. GLiDR generates precise static points using $32\times$sparser dynamic scans and performs better than the baselines across threedatasets. GLiDR generates a valuable byproduct - an accurate binarysegmentation mask of static and dynamic objects that are helpful for navigationplanning and safety in constrained environments. The newly introduced staticpoints allow GLiDR to outperform LiDAR-based navigation using SLAM in severalsettings. Source code is available at https://kshitijbhat.github.io/glidr</description><author>Prashant Kumar, Kshitij Madhav Bhat, Vedang Bhupesh Shenvi Nadkarni, Prem Kalra</author><pubDate>Fri, 24 May 2024 16:48:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00068v3</guid></item><item><title>Exploring Interactive Semantic Alignment for Efficient HOI Detection with Vision-language Model</title><link>http://arxiv.org/abs/2404.12678v3</link><description>Human-Object Interaction (HOI) detection aims to localize human-object pairsand comprehend their interactions. Recently, two-stage transformer-basedmethods have demonstrated competitive performance. However, these methodsfrequently focus on object appearance features and ignore global contextualinformation. Besides, vision-language model CLIP which effectively alignsvisual and text embeddings has shown great potential in zero-shot HOIdetection. Based on the former facts, We introduce a novel HOI detector namedISA-HOI, which extensively leverages knowledge from CLIP, aligning interactivesemantics between visual and textual features. We first extract global contextof image and local features of object to Improve interaction Features in images(IF). On the other hand, we propose a Verb Semantic Improvement (VSI) module toenhance textual features of verb labels via cross-modal fusion. Ultimately, ourmethod achieves competitive results on the HICO-DET and V-COCO benchmarks withmuch fewer training epochs, and outperforms the state-of-the-art underzero-shot settings.</description><author>Jihao Dong, Renjie Pan, Hua Yang</author><pubDate>Fri, 24 May 2024 16:46:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12678v3</guid></item><item><title>Harnessing Increased Client Participation with Cohort-Parallel Federated Learning</title><link>http://arxiv.org/abs/2405.15644v1</link><description>Federated Learning (FL) is a machine learning approach where nodescollaboratively train a global model. As more nodes participate in a round ofFL, the effectiveness of individual model updates by nodes also diminishes. Inthis study, we increase the effectiveness of client updates by dividing thenetwork into smaller partitions, or cohorts. We introduce Cohort-ParallelFederated Learning (CPFL): a novel learning approach where each cohortindependently trains a global model using FL, until convergence, and theproduced models by each cohort are then unified using one-shot KnowledgeDistillation (KD) and a cross-domain, unlabeled dataset. The insight behindCPFL is that smaller, isolated networks converge quicker than in a one-networksetting where all nodes participate. Through exhaustive experiments involvingrealistic traces and non-IID data distributions on the CIFAR-10 and FEMNISTimage classification tasks, we investigate the balance between the number ofcohorts, model accuracy, training time, and compute and communicationresources. Compared to traditional FL, CPFL with four cohorts, non-IID datadistribution, and CIFAR-10 yields a 1.9$\times$ reduction in train time and a1.3$\times$ reduction in resource usage, with a minimal drop in test accuracy.</description><author>Akash Dhasade, Anne-Marie Kermarrec, Tuan-Anh Nguyen, Rafael Pires, Martijn de Vos</author><pubDate>Fri, 24 May 2024 16:34:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15644v1</guid></item><item><title>Reducing the cost of posterior sampling in linear inverse problems via task-dependent score learning</title><link>http://arxiv.org/abs/2405.15643v1</link><description>Score-based diffusion models (SDMs) offer a flexible approach to sample fromthe posterior distribution in a variety of Bayesian inverse problems. In theliterature, the prior score is utilized to sample from the posterior bydifferent methods that require multiple evaluations of the forward mapping inorder to generate a single posterior sample. These methods are often designedwith the objective of enabling the direct use of the unconditional prior scoreand, therefore, task-independent training. In this paper, we focus on linearinverse problems, when evaluation of the forward mapping is computationallyexpensive and frequent posterior sampling is required for new measurement data,such as in medical imaging. We demonstrate that the evaluation of the forwardmapping can be entirely bypassed during posterior sample generation. Instead,without introducing any error, the computational effort can be shifted to anoffline task of training the score of a specific diffusion-like random process.In particular, the training is task-dependent requiring information about theforward mapping but not about the measurement data. It is shown that theconditional score corresponding to the posterior can be obtained from theauxiliary score by suitable affine transformations. We prove that thisobservation generalizes to the framework of infinite-dimensional diffusionmodels introduced recently and provide numerical analysis of the method.Moreover, we validate our findings with numerical experiments.</description><author>Fabian Schneider, Duc-Lam Duong, Matti Lassas, Maarten V. de Hoop, Tapio Helin</author><pubDate>Fri, 24 May 2024 16:33:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15643v1</guid></item><item><title>Effective Confidence Region Prediction Using Probability Forecasters</title><link>http://arxiv.org/abs/2405.15642v1</link><description>Confidence region prediction is a practically useful extension to thecommonly studied pattern recognition problem. Instead of predicting a singlelabel, the constraint is relaxed to allow prediction of a subset of labelsgiven a desired confidence level 1-delta. Ideally, effective region predictionsshould be (1) well calibrated - predictive regions at confidence level 1-deltashould err with relative frequency at most delta and (2) be as narrow (orcertain) as possible. We present a simple technique to generate confidenceregion predictions from conditional probability estimates (probabilityforecasts). We use this 'conversion' technique to generate confidence regionpredictions from probability forecasts output by standard machine learningalgorithms when tested on 15 multi-class datasets. Our results show thatapproximately 44% of experiments demonstrate well-calibrated confidence regionpredictions, with the K-Nearest Neighbour algorithm tending to performconsistently well across all data. Our results illustrate the practicalbenefits of effective confidence region prediction with respect to medicaldiagnostics, where guarantees of capturing the true disease label can be given.</description><author>David Lindsay, Sian Lindsay</author><pubDate>Fri, 24 May 2024 16:33:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15642v1</guid></item><item><title>Informed Meta-Learning</title><link>http://arxiv.org/abs/2402.16105v3</link><description>In noisy and low-data regimes prevalent in real-world applications, a keychallenge of machine learning lies in effectively incorporating inductivebiases that promote data efficiency and robustness. Meta-learning and informedML stand out as two approaches for incorporating prior knowledge into MLpipelines. While the former relies on a purely data-driven source of priors,the latter is guided by prior domain knowledge. In this paper, we formalise ahybrid paradigm, informed meta-learning, facilitating the incorporation ofpriors from unstructured knowledge representations, such as natural language;thus, unlocking complementarity in cross-task knowledge sharing of humans andmachines. We establish the foundational components of informed meta-learningand present a concrete instantiation of this framework--the Informed NeuralProcess. Through a series of experiments, we demonstrate the potential benefitsof informed meta-learning in improving data efficiency, robustness toobservational noise and task distribution shifts.</description><author>Katarzyna Kobalczyk, Mihaela van der Schaar</author><pubDate>Fri, 24 May 2024 16:31:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16105v3</guid></item><item><title>GECKO: Generative Language Model for English, Code and Korean</title><link>http://arxiv.org/abs/2405.15640v1</link><description>We introduce GECKO, a bilingual large language model (LLM) optimized forKorean and English, along with programming languages. GECKO is pretrained onthe balanced, high-quality corpus of Korean and English employing LLaMAarchitecture. In this report, we share the experiences of several efforts tobuild a better data pipeline for the corpus and to train our model. GECKO showsgreat efficiency in token generations for both Korean and English, despite itssmall size of vocabulary. We measure the performance on the representativebenchmarks in terms of Korean, English and Code, and it exhibits greatperformance on KMMLU (Korean MMLU) and modest performance in English and Code,even with its smaller number of trained tokens compared to English-focusedLLMs. GECKO is available to the open-source community under a permissivelicense. We hope our work offers a research baseline and practical insights forKorean LLM research. The model can be found at:https://huggingface.co/kifai/GECKO-7B</description><author>Sungwoo Oh, Donggyu Kim</author><pubDate>Fri, 24 May 2024 16:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15640v1</guid></item><item><title>M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models</title><link>http://arxiv.org/abs/2405.15638v1</link><description>Multilingual multimodal reasoning is a core component in achievinghuman-level intelligence. However, most existing benchmarks for multilingualmultimodal reasoning struggle to differentiate between models of varyingperformance; even language models without visual capabilities can easilyachieve high scores. This leaves a comprehensive evaluation of leadingmultilingual multimodal models largely unexplored. In this work, we introduceM4U, a novel and challenging benchmark for assessing the capability ofmulti-discipline multilingual multimodal understanding and reasoning. M4Ucontains 8,931 samples covering 64 disciplines across 16 subfields in Science,Engineering, and Healthcare in Chinese, English, and German. Using M4U, weconduct extensive evaluations of 21 leading Large Multimodal Models (LMMs) andLarge Language Models (LLMs) with external tools. The evaluation results showthat the state-of-the-art model, GPT-4o, achieves only 47.6% average accuracyon M4U. Additionally, we observe that the leading LMMs exhibit significantlanguage preferences. Our in-depth analysis indicates that leading LMMs,including GPT-4o, suffer performance degradation when prompted withcross-lingual multimodal questions, such as images with key textual informationin Chinese while the question is in German. We believe that M4U can serve as acrucial tool for systematically evaluating LMMs based on their multilingualmultimodal reasoning capabilities and monitoring their development. Thehomepage, codes and data are public available.</description><author>Hongyu Wang, Jiayu Xu, Senwei Xie, Ruiping Wang, Jialin Li, Zhaojie Xie, Bin Zhang, Chuyan Xiong, Xilin Chen</author><pubDate>Fri, 24 May 2024 16:25:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15638v1</guid></item><item><title>On the Correspondence of Non-flat Assumption-based Argumentation and Logic Programming with Negation as Failure in the Head</title><link>http://arxiv.org/abs/2405.09415v2</link><description>The relation between (a fragment of) assumption-based argumentation (ABA) andlogic programs (LPs) under stable model semantics is well-studied. However, forobtaining this relation, the ABA framework needs to be restricted to beingflat, i.e., a fragment where the (defeasible) assumptions can never beentailed, only assumed to be true or false. Here, we remove this restrictionand show a correspondence between non-flat ABA and LPs with negation as failurein their head. We then extend this result to so-called set-stable ABAsemantics, originally defined for the fragment of non-flat ABA called bipolarABA. We showcase how to define set-stable semantics for LPs with negation asfailure in their head and show the correspondence to set-stable ABA semantics.</description><author>Anna Rapberger, Markus Ulbricht, Francesca Toni</author><pubDate>Fri, 24 May 2024 16:25:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09415v2</guid></item><item><title>Towards Weakly Supervised End-to-end Learning for Long-video Action Recognition</title><link>http://arxiv.org/abs/2311.17118v2</link><description>Developing end-to-end action recognition models on long videos is fundamentaland crucial for long-video action understanding. Due to the unaffordable costof end-to-end training on the whole long videos, existing works generally trainmodels on short clips trimmed from long videos. However, this``trimming-then-training'' practice requires action interval annotations forclip-level supervision, i.e., knowing which actions are trimmed into the clips.Unfortunately, collecting such annotations is very expensive and prevents modeltraining at scale. To this end, this work aims to build a weakly supervisedend-to-end framework for training recognition models on long videos, with onlyvideo-level action category labels. Without knowing the precise temporallocations of actions in long videos, our proposed weakly supervised framework,namely AdaptFocus, estimates where and how likely the actions will occur toadaptively focus on informative action clips for end-to-end training. Theeffectiveness of the proposed AdaptFocus framework is demonstrated on threelong-video datasets. Furthermore, for downstream long-video tasks, ourAdaptFocus framework provides a weakly supervised feature extraction pipelinefor extracting more robust long-video features, such that the state-of-the-artmethods on downstream tasks are significantly advanced. We will release thecode and models.</description><author>Jiaming Zhou, Hanjun Li, Kun-Yu Lin, Junwei Liang</author><pubDate>Fri, 24 May 2024 16:25:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17118v2</guid></item><item><title>DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</title><link>http://arxiv.org/abs/2405.04434v4</link><description>We present DeepSeek-V2, a strong Mixture-of-Experts (MoE) language modelcharacterized by economical training and efficient inference. It comprises 236Btotal parameters, of which 21B are activated for each token, and supports acontext length of 128K tokens. DeepSeek-V2 adopts innovative architecturesincluding Multi-head Latent Attention (MLA) and DeepSeekMoE. MLA guaranteesefficient inference through significantly compressing the Key-Value (KV) cacheinto a latent vector, while DeepSeekMoE enables training strong models at aneconomical cost through sparse computation. Compared with DeepSeek 67B,DeepSeek-V2 achieves significantly stronger performance, and meanwhile saves42.5% of training costs, reduces the KV cache by 93.3%, and boosts the maximumgeneration throughput to 5.76 times. We pretrain DeepSeek-V2 on a high-qualityand multi-source corpus consisting of 8.1T tokens, and further performSupervised Fine-Tuning (SFT) and Reinforcement Learning (RL) to fully unlockits potential. Evaluation results show that, even with only 21B activatedparameters, DeepSeek-V2 and its chat versions still achieve top-tierperformance among open-source models.</description><author>DeepSeek-AI, Aixin Liu, Bei Feng, Bin Wang, Bingxuan Wang, Bo Liu, Chenggang Zhao, Chengqi Dengr, Chong Ruan, Damai Dai, Daya Guo, Dejian Yang, Deli Chen, Dongjie Ji, Erhang Li, Fangyun Lin, Fuli Luo, Guangbo Hao, Guanting Chen, Guowei Li, H. Zhang, Hanwei Xu, Hao Yang, Haowei Zhang, Honghui Ding, Huajian Xin, Huazuo Gao, Hui Li, Hui Qu, J. L. Cai, Jian Liang, Jianzhong Guo, Jiaqi Ni, Jiashi Li, Jin Chen, Jingyang Yuan, Junjie Qiu, Junxiao Song, Kai Dong, Kaige Gao, Kang Guan, Lean Wang, Lecong Zhang, Lei Xu, Leyi Xia, Liang Zhao, Liyue Zhang, Meng Li, Miaojun Wang, Mingchuan Zhang, Minghua Zhang, Minghui Tang, Mingming Li, Ning Tian, Panpan Huang, Peiyi Wang, Peng Zhang, Qihao Zhu, Qinyu Chen, Qiushi Du, R. J. Chen, R. L. Jin, Ruiqi Ge, Ruizhe Pan, Runxin Xu, Ruyi Chen, S. S. Li, Shanghao</author><pubDate>Fri, 24 May 2024 16:24:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04434v4</guid></item><item><title>Visualize and Paint GAN Activations</title><link>http://arxiv.org/abs/2405.15636v1</link><description>We investigate how generated structures of GANs correlate with theiractivations in hidden layers, with the purpose of better understanding theinner workings of those models and being able to paint structures withunconditionally trained GANs. This gives us more control over the generatedimages, allowing to generate them from a semantic segmentation map while notrequiring such a segmentation in the training data. To this end we introducethe concept of tileable features, allowing us to identify activations that workwell for painting.</description><author>Rudolf Herdt, Peter Maass</author><pubDate>Fri, 24 May 2024 16:22:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15636v1</guid></item><item><title>SynGhost: Imperceptible and Universal Task-agnostic Backdoor Attack in Pre-trained Language Models</title><link>http://arxiv.org/abs/2402.18945v2</link><description>Pre-training has been a necessary phase for deploying pre-trained languagemodels (PLMs) to achieve remarkable performance in downstream tasks. However,we empirically show that backdoor attacks exploit such a phase as a vulnerableentry point for task-agnostic. In this paper, we first propose$\mathtt{maxEntropy}$, an entropy-based poisoning filtering defense, to provethat existing task-agnostic backdoors are easily exposed, due to explicittriggers used. Then, we present $\mathtt{SynGhost}$, an imperceptible anduniversal task-agnostic backdoor attack in PLMs. Specifically,$\mathtt{SynGhost}$ hostilely manipulates clean samples through differentsyntactic and then maps the backdoor to representation space without disturbingthe primitive representation. $\mathtt{SynGhost}$ further leverages contrastivelearning to achieve universal, which performs a uniform distribution ofbackdoors in the representation space. In light of the syntactic properties, wealso introduce an awareness module to alleviate the interference betweendifferent syntactic. Experiments show that $\mathtt{SynGhost}$ holds moreserious threats. Not only do severe harmfulness to various downstream tasks ontwo tuning paradigms but also to any PLMs. Meanwhile, $\mathtt{SynGhost}$ isimperceptible against three countermeasures based on perplexity, fine-pruning,and the proposed $\mathtt{maxEntropy}$.</description><author>Pengzhou Cheng, Wei Du, Zongru Wu, Fengwei Zhang, Libo Chen, Gongshen Liu</author><pubDate>Fri, 24 May 2024 16:21:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18945v2</guid></item><item><title>Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation</title><link>http://arxiv.org/abs/2405.14598v2</link><description>In recent years, with the realistic generation results and a wide range ofpersonalized applications, diffusion-based generative models gain hugeattention in both visual and audio generation areas. Compared to theconsiderable advancements of text2image or text2audio generation, research inaudio2visual or visual2audio generation has been relatively slow. The recentaudio-visual generation methods usually resort to huge large language model orcomposable diffusion models. Instead of designing another giant model foraudio-visual generation, in this paper we take a step back showing a simple andlightweight generative transformer, which is not fully investigated inmulti-modal generation, can achieve excellent results on image2audiogeneration. The transformer operates in the discrete audio and visualVector-Quantized GAN space, and is trained in the mask denoising manner. Aftertraining, the classifier-free guidance could be deployed off-the-shelfachieving better performance, without any extra training or modification. Sincethe transformer model is modality symmetrical, it could also be directlydeployed for audio2image generation and co-generation. In the experiments, weshow that our simple method surpasses recent image2audio generation methods.Generated audio samples can be found athttps://docs.google.com/presentation/d/1ZtC0SeblKkut4XJcRaDsSTuCRIXB3ypxmSi7HTY3IyQ/</description><author>Shiqi Yang, Zhi Zhong, Mengjie Zhao, Shusuke Takahashi, Masato Ishii, Takashi Shibuya, Yuki Mitsufuji</author><pubDate>Fri, 24 May 2024 16:21:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14598v2</guid></item><item><title>Less is more: Summarizing Patch Tokens for efficient Multi-Label Class-Incremental Learning</title><link>http://arxiv.org/abs/2405.15633v1</link><description>Prompt tuning has emerged as an effective rehearsal-free technique forclass-incremental learning (CIL) that learns a tiny set of task-specificparameters (or prompts) to instruct a pre-trained transformer to learn on asequence of tasks. Albeit effective, prompt tuning methods do not lend well inthe multi-label class incremental learning (MLCIL) scenario (where an imagecontains multiple foreground classes) due to the ambiguity in selecting thecorrect prompt(s) corresponding to different foreground objects belonging tomultiple tasks. To circumvent this issue we propose to eliminate the promptselection mechanism by maintaining task-specific pathways, which allow us tolearn representations that do not interact with the ones from the other tasks.Since independent pathways in truly incremental scenarios will result in anexplosion of computation due to the quadratically complex multi-headself-attention (MSA) operation in prompt tuning, we propose to reduce theoriginal patch token embeddings into summarized tokens. Prompt tuning is thenapplied to these fewer summarized tokens to compute the final representation.Our proposed method Multi-Label class incremental learning via summarisingpAtch tokeN Embeddings (MULTI-LANE) enables learning disentangled task-specificrepresentations in MLCIL while ensuring fast inference. We conduct experimentsin common benchmarks and demonstrate that our MULTI-LANE achieves a newstate-of-the-art in MLCIL. Additionally, we show that MULTI-LANE is alsocompetitive in the CIL setting. Source code available athttps://github.com/tdemin16/multi-lane</description><author>Thomas De Min, Massimiliano Mancini, Stéphane Lathuilière, Subhankar Roy, Elisa Ricci</author><pubDate>Fri, 24 May 2024 16:18:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15633v1</guid></item><item><title>Federated Behavioural Planes: Explaining the Evolution of Client Behaviour in Federated Learning</title><link>http://arxiv.org/abs/2405.15632v1</link><description>Federated Learning (FL), a privacy-aware approach in distributed deeplearning environments, enables many clients to collaboratively train a modelwithout sharing sensitive data, thereby reducing privacy risks. However,enabling human trust and control over FL systems requires understanding theevolving behaviour of clients, whether beneficial or detrimental for thetraining, which still represents a key challenge in the current literature. Toaddress this challenge, we introduce Federated Behavioural Planes (FBPs), anovel method to analyse, visualise, and explain the dynamics of FL systems,showing how clients behave under two different lenses: predictive performance(error behavioural space) and decision-making processes (counterfactualbehavioural space). Our experiments demonstrate that FBPs provide informativetrajectories describing the evolving states of clients and their contributionsto the global model, thereby enabling the identification of clusters of clientswith similar behaviours. Leveraging the patterns identified by FBPs, we proposea robust aggregation technique named Federated Behavioural Shields to detectmalicious or noisy client models, thereby enhancing security and surpassing theefficacy of existing state-of-the-art FL defense mechanisms.</description><author>Dario Fenoglio, Gabriele Dominici, Pietro Barbiero, Alberto Tonda, Martin Gjoreski, Marc Langheinrich</author><pubDate>Fri, 24 May 2024 16:17:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15632v1</guid></item><item><title>Nonlinear denoising score matching for enhanced learning of structured distributions</title><link>http://arxiv.org/abs/2405.15625v1</link><description>We present a novel method for training score-based generative models whichuses nonlinear noising dynamics to improve learning of structureddistributions. Generalizing to a nonlinear drift allows for additionalstructure to be incorporated into the dynamics, thus making the training betteradapted to the data, e.g., in the case of multimodality or (approximate)symmetries. Such structure can be obtained from the data by an inexpensivepreprocessing step. The nonlinear dynamics introduces new challenges intotraining which we address in two ways: 1) we develop a new nonlinear denoisingscore matching (NDSM) method, 2) we introduce neural control variates in orderto reduce the variance of the NDSM training objective. We demonstrate theeffectiveness of this method on several examples: a) a collection oflow-dimensional examples, motivated by clustering in latent space, b)high-dimensional images, addressing issues with mode collapse, small trainingsets, and approximate symmetries, the latter being a challenge for methodsbased on equivariant neural networks, which require exact symmetries.</description><author>Jeremiah Birrell, Markos A. Katsoulakis, Luc Rey-Bellet, Benjamin Zhang, Wei Zhu</author><pubDate>Fri, 24 May 2024 16:14:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15625v1</guid></item><item><title>Inverse-RLignment: Inverse Reinforcement Learning from Demonstrations for LLM Alignment</title><link>http://arxiv.org/abs/2405.15624v1</link><description>Aligning Large Language Models (LLMs) is crucial for enhancing their safetyand utility. However, existing methods, primarily based on preference datasets,face challenges such as noisy labels, high annotation costs, and privacyconcerns. In this work, we introduce Alignment from Demonstrations (AfD), anovel approach leveraging high-quality demonstration data to overcome thesechallenges. We formalize AfD within a sequential decision-making framework,highlighting its unique challenge of missing reward signals. Drawing insightsfrom forward and inverse reinforcement learning, we introduce divergenceminimization objectives for AfD. Analytically, we elucidate the mass-coveringand mode-seeking behaviors of various approaches, explaining when and whycertain methods are superior. Practically, we propose a computationallyefficient algorithm that extrapolates over a tailored reward model for AfD. Wevalidate our key insights through experiments on the Harmless and Helpfultasks, demonstrating their strong empirical performance while maintainingsimplicity.</description><author>Hao Sun, Mihaela van der Schaar</author><pubDate>Fri, 24 May 2024 16:13:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15624v1</guid></item><item><title>Beyond Trend and Periodicity: Guiding Time Series Forecasting with Textual Cues</title><link>http://arxiv.org/abs/2405.13522v2</link><description>This work introduces a novel Text-Guided Time Series Forecasting (TGTSF)task. By integrating textual cues, such as channel descriptions and dynamicnews, TGTSF addresses the critical limitations of traditional methods that relypurely on historical data. To support this task, we propose TGForecaster, arobust baseline model that fuses textual cues and time series data usingcross-attention mechanisms. We then present four meticulously curated benchmarkdatasets to validate the proposed framework, ranging from simple periodic datato complex, event-driven fluctuations. Our comprehensive evaluationsdemonstrate that TGForecaster consistently achieves state-of-the-artperformance, highlighting the transformative potential of incorporating textualinformation into time series forecasting. This work not only pioneers a novelforecasting task but also establishes a new benchmark for future research,driving advancements in multimodal data integration for time series models.</description><author>Zhijian Xu, Yuxuan Bian, Jianyuan Zhong, Xiangyu Wen, Qiang Xu</author><pubDate>Fri, 24 May 2024 16:10:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13522v2</guid></item><item><title>LAM3D: Large Image-Point-Cloud Alignment Model for 3D Reconstruction from Single Image</title><link>http://arxiv.org/abs/2405.15622v1</link><description>Large Reconstruction Models have made significant strides in the realm ofautomated 3D content generation from single or multiple input images. Despitetheir success, these models often produce 3D meshes with geometricinaccuracies, stemming from the inherent challenges of deducing 3D shapessolely from image data. In this work, we introduce a novel framework, the LargeImage and Point Cloud Alignment Model (LAM3D), which utilizes 3D point clouddata to enhance the fidelity of generated 3D meshes. Our methodology beginswith the development of a point-cloud-based network that effectively generatesprecise and meaningful latent tri-planes, laying the groundwork for accurate 3Dmesh reconstruction. Building upon this, our Image-Point-Cloud FeatureAlignment technique processes a single input image, aligning to the latenttri-planes to imbue image features with robust 3D information. This process notonly enriches the image features but also facilitates the production ofhigh-fidelity 3D meshes without the need for multi-view input, significantlyreducing geometric distortions. Our approach achieves state-of-the-arthigh-fidelity 3D mesh reconstruction from a single image in just 6 seconds, andexperiments on various datasets demonstrate its effectiveness.</description><author>Ruikai Cui, Xibin Song, Weixuan Sun, Senbo Wang, Weizhe Liu, Shenzhou Chen, Taizhang Shang, Yang Li, Nick Barnes, Hongdong Li, Pan Ji</author><pubDate>Fri, 24 May 2024 16:09:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15622v1</guid></item><item><title>Align as Ideal: Cross-Modal Alignment Binding for Federated Medical Vision-Language Pre-training</title><link>http://arxiv.org/abs/2404.03854v2</link><description>Vision-language pre-training (VLP) has arised as an efficient scheme formultimodal representation learning, but it requires large-scale multimodal datafor pre-training, making it an obstacle especially for medical applications. Toovercome the data limitation, federated learning (FL) can be a promisingstrategy to scale up the dataset for medical VLP while protecting data privacy.However, client data are often heterogeneous in real-world scenarios, and weobserve that local training on heterogeneous client data would distort themultimodal representation learning and lead to biased cross-modal alignment. Toaddress this challenge, we propose a Federated Align as IDeal (FedAID)framework for federated VLP with robustness to data heterogeneity, to bindlocal clients with an ideal crossmodal alignment. Specifically, to reducedistortions on global-aggregated features while learning diverse semantics fromclient datasets during local training, we propose to bind the cross-modelaligned representation space learned by local models with an unbiased one viaguidance-based regularization. Moreover, we employ a distribution-based min-maxoptimization to learn the unbiased cross-modal alignment at each communicationturn of federated pre-training. The experiments on real-world datasetsdemonstrate our method successfully promotes efficient federated multimodallearning for medical VLP with data heterogeneity.</description><author>Zitao Shuai, Liyue Shen</author><pubDate>Fri, 24 May 2024 16:08:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03854v2</guid></item><item><title>Interpreting Key Mechanisms of Factual Recall in Transformer-Based Language Models</title><link>http://arxiv.org/abs/2403.19521v4</link><description>In this paper, we delve into several mechanisms employed by Transformer-basedlanguage models (LLMs) for factual recall tasks. We outline a pipelineconsisting of three major steps: (1) Given a prompt ``The capital of Franceis,'' task-specific attention heads extract the topic token, such as``France,'' from the context and pass it to subsequent MLPs. (2) As attentionheads' outputs are aggregated with equal weight and added to the residualstream, the subsequent MLP acts as an ``activation,'' which either erases oramplifies the information originating from individual heads. As a result, thetopic token ``France'' stands out in the residual stream. (3) A deep MLP takes``France'' and generates a component that redirects the residual stream towardsthe direction of the correct answer, i.e., ``Paris.'' This procedure is akin toapplying an implicit function such as ``get\_capital($X$),'' and the argument$X$ is the topic token information passed by attention heads. To achieve theabove quantitative and qualitative analysis for MLPs, we proposed a novelanalytic method aimed at decomposing the outputs of the MLP into componentsunderstandable by humans. Additionally, we observed a universalanti-overconfidence mechanism in the final layer of models, which suppressescorrect predictions. We mitigate this suppression by leveraging ourinterpretation to improve factual recall confidence. The above interpretationsare evaluated across diverse tasks spanning various domains of factualknowledge, using various language models from the GPT-2 families, 1.3B OPT, upto 7B Llama-2, and in both zero- and few-shot setups.</description><author>Ang Lv, Yuhan Chen, Kaiyi Zhang, Yulong Wang, Lifeng Liu, Ji-Rong Wen, Jian Xie, Rui Yan</author><pubDate>Fri, 24 May 2024 16:06:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19521v4</guid></item><item><title>DiffCalib: Reformulating Monocular Camera Calibration as Diffusion-Based Dense Incident Map Generation</title><link>http://arxiv.org/abs/2405.15619v1</link><description>Monocular camera calibration is a key precondition for numerous 3D visionapplications. Despite considerable advancements, existing methods often hingeon specific assumptions and struggle to generalize across varied real-worldscenarios, and the performance is limited by insufficient training data.Recently, diffusion models trained on expansive datasets have been confirmed tomaintain the capability to generate diverse, high-quality images. This successsuggests a strong potential of the models to effectively understand variedvisual information. In this work, we leverage the comprehensive visualknowledge embedded in pre-trained diffusion models to enable more robust andaccurate monocular camera intrinsic estimation. Specifically, we reformulatethe problem of estimating the four degrees of freedom (4-DoF) of cameraintrinsic parameters as a dense incident map generation task. The map detailsthe angle of incidence for each pixel in the RGB image, and its format alignswell with the paradigm of diffusion models. The camera intrinsic then can bederived from the incident map with a simple non-learning RANSAC algorithmduring inference. Moreover, to further enhance the performance, we jointlyestimate a depth map to provide extra geometric information for the incidentmap estimation. Extensive experiments on multiple testing datasets demonstratethat our model achieves state-of-the-art performance, gaining up to a 40%reduction in prediction errors. Besides, the experiments also show that theprecise camera intrinsic and depth maps estimated by our pipeline can greatlybenefit practical applications such as 3D reconstruction from a singlein-the-wild image.</description><author>Xiankang He, Guangkai Xu, Bo Zhang, Hao Chen, Ying Cui, Dongyan Guo</author><pubDate>Fri, 24 May 2024 16:05:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15619v1</guid></item><item><title>MLPs Learn In-Context</title><link>http://arxiv.org/abs/2405.15618v1</link><description>In-context learning (ICL), the remarkable ability to solve a task from onlyinput exemplars, has commonly been assumed to be a unique hallmark ofTransformer models. In this study, we demonstrate that multi-layer perceptrons(MLPs) can also learn in-context. Moreover, we find that MLPs, and the closelyrelated MLP-Mixer models, learn in-context competitively with Transformersgiven the same compute budget. We further show that MLPs outperformTransformers on a subset of ICL tasks designed to test relational reasoning.These results suggest that in-context learning is not exclusive to Transformersand highlight the potential of exploring this phenomenon beyond attention-basedarchitectures. In addition, MLPs' surprising success on relational taskschallenges prior assumptions about simple connectionist models. Altogether, ourresults endorse the broad trend that ``less inductive bias is better" andcontribute to the growing interest in all-MLP alternatives to task-specificarchitectures.</description><author>William L. Tong, Cengiz Pehlevan</author><pubDate>Fri, 24 May 2024 16:04:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15618v1</guid></item></channel></rss>