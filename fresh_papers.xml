<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 04 Feb 2025 13:00:12 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>CodeMonkeys: Scaling Test-Time Compute for Software Engineering</title><link>http://arxiv.org/abs/2501.14723v2</link><description>Scaling test-time compute is a promising axis for improving LLM capabilities.However, test-time compute can be scaled in a variety of ways, and effectivelycombining different approaches remains an active area of research. Here, weexplore this problem in the context of solving real-world GitHub issues fromthe SWE-bench dataset. Our system, named CodeMonkeys, allows models toiteratively edit a codebase by jointly generating and running a testing scriptalongside their draft edit. We sample many of these multi-turn trajectories forevery issue to generate a collection of candidate edits. This approach lets usscale "serial" test-time compute by increasing the number of iterations pertrajectory and "parallel" test-time compute by increasing the number oftrajectories per problem. With parallel scaling, we can amortize up-front costsacross multiple downstream samples, allowing us to identify relevant codebasecontext using the simple method of letting an LLM read every file. In order toselect between candidate edits, we combine voting using model-generated testswith a final multi-turn trajectory dedicated to selection. Overall, CodeMonkeysresolves 57.4% of issues from SWE-bench Verified using a budget ofapproximately 2300 USD. Our selection method can also be used to combinecandidates from different sources. Selecting over an ensemble of edits fromexisting top SWE-bench Verified submissions obtains a score of 66.2% andoutperforms the best member of the ensemble on its own. We fully release ourcode and data at https://scalingintelligence.stanford.edu/pubs/codemonkeys.</description><author>Ryan Ehrlich, Bradley Brown, Jordan Juravsky, Ronald Clark, Christopher Ré, Azalia Mirhoseini</author><pubDate>Mon, 03 Feb 2025 18:57:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14723v2</guid></item><item><title>λ: A Benchmark for Data-Efficiency in Long-Horizon Indoor Mobile Manipulation Robotics</title><link>http://arxiv.org/abs/2412.05313v5</link><description>Efficiently learning and executing long-horizon mobile manipulation (MoMa)tasks is crucial for advancing robotics in household and workplace settings.However, current MoMa models are data-inefficient, underscoring the need forimproved models that require realistic-sized benchmarks to evaluate theirefficiency, which do not exist. To address this, we introduce the LAMBDA({\lambda}) benchmark (Long-horizon Actions for Mobile-manipulationBenchmarking of Directed Activities), which evaluates the data efficiency ofmodels on language-conditioned, long-horizon, multi-room, multi-floor,pick-and-place tasks using a dataset of manageable size, more feasible forcollection. The benchmark includes 571 human-collected demonstrations thatprovide realism and diversity in simulated and real-world settings. Unlikeplanner-generated data, these trajectories offer natural variability andreplay-verifiability, ensuring robust learning and evaluation. We benchmarkseveral models, including learning-based models and a neuro-symbolic modularapproach combining foundation models with task and motion planning.Learning-based models show suboptimal success rates, even when leveragingpretrained weights, underscoring significant data inefficiencies. However, theneuro-symbolic approach performs significantly better while being more dataefficient. Findings highlight the need for more data-efficient learning-basedMoMa approaches. {\lambda} addresses this gap by serving as a key benchmark forevaluating the data efficiency of those future models in handling householdrobotics tasks.</description><author>Ahmed Jaafar, Shreyas Sundara Raman, Yichen Wei, Sudarshan Harithas, Sofia Juliani, Anneke Wernerfelt, Benedict Quartey, Ifrah Idrees, Jason Xinyu Liu, Stefanie Tellex</author><pubDate>Mon, 03 Feb 2025 18:54:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05313v5</guid></item><item><title>E2Former: A Linear-time Efficient and Equivariant Transformer for Scalable Molecular Modeling</title><link>http://arxiv.org/abs/2501.19216v2</link><description>Equivariant Graph Neural Networks (EGNNs) have demonstrated significantsuccess in modeling microscale systems, including those in chemistry, biologyand materials science. However, EGNNs face substantial computational challengesdue to the high cost of constructing edge features via spherical tensorproducts, making them impractical for large-scale systems. To address thislimitation, we introduce E2Former, an equivariant and efficient transformerarchitecture that incorporates the Wigner $6j$ convolution (Wigner $6j$ Conv).By shifting the computational burden from edges to nodes, the Wigner $6j$ Convreduces the complexity from $O(|\mathcal{E}|)$ to $ O(| \mathcal{V}|)$ whilepreserving both the model's expressive power and rotational equivariance. Weshow that this approach achieves a 7x-30x speedup compared to conventional$\mathrm{SO}(3)$ convolutions. Furthermore, our empirical results demonstratethat the derived E2Former mitigates the computational challenges of existingapproaches without compromising the ability to capture detailed geometricinformation. This development could suggest a promising direction for scalableand efficient molecular modeling.</description><author>Yunyang Li, Lin Huang, Zhihao Ding, Chu Wang, Xinran Wei, Han Yang, Zun Wang, Chang Liu, Yu Shi, Peiran Jin, Jia Zhang, Mark Gerstein, Tao Qin</author><pubDate>Mon, 03 Feb 2025 18:46:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.19216v2</guid></item><item><title>Boosting Asynchronous Decentralized Learning with Model Fragmentation</title><link>http://arxiv.org/abs/2410.12918v2</link><description>Decentralized learning (DL) is an emerging technique that allows nodes on theweb to collaboratively train machine learning models without sharing raw data.Dealing with stragglers, i.e., nodes with slower compute or communication thanothers, is a key challenge in DL. We present DivShare, a novel asynchronous DLalgorithm that achieves fast model convergence in the presence of communicationstragglers. DivShare achieves this by having nodes fragment their models intoparameter subsets and send, in parallel to computation, each subset to a randomsample of other nodes instead of sequentially exchanging full models. Thetransfer of smaller fragments allows more efficient usage of the collectivebandwidth and enables nodes with slow network links to quickly contribute withat least some of their model parameters. By theoretically proving theconvergence of DivShare, we provide, to the best of our knowledge, the firstformal proof of convergence for a DL algorithm that accounts for the effects ofasynchronous communication with delays. We experimentally evaluate DivShareagainst two state-of-the-art DL baselines, AD-PSGD and Swift, and with twostandard datasets, CIFAR-10 and MovieLens. We find that DivShare withcommunication stragglers lowers time-to-accuracy by up to 3.9x compared toAD-PSGD on the CIFAR-10 dataset. Compared to baselines, DivShare also achievesup to 19.4% better accuracy and 9.5% lower test loss on the CIFAR-10 andMovieLens datasets, respectively.</description><author>Sayan Biswas, Anne-Marie Kermarrec, Alexis Marouani, Rafael Pires, Rishi Sharma, Martijn de Vos</author><pubDate>Mon, 03 Feb 2025 18:24:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12918v2</guid></item><item><title>Can sparse autoencoders make sense of latent representations?</title><link>http://arxiv.org/abs/2410.11468v2</link><description>Sparse autoencoders (SAEs) have lately been used to uncover interpretablelatent features in large language models. Here, we explore their potential fordecomposing latent representations in complex and high-dimensional biologicaldata, where the underlying variables are often unknown. Using simulated data,we find that latent representations can encode observable and directlyconnected upstream hidden variables in superposition. The degree to which theyare learned depends on the type of variable and the model architecture,favoring shallow and wide networks. Superpositions, however, are notidentifiable if the generative variables are unknown. SAEs can recover thesevariables and their structure with respect to the observables. Applied tosingle-cell multi-omics data, we show that SAEs can uncover key biologicalprocesses. We further present an automated method for linking SAE features tobiological concepts to enable large-scale analysis of single-cell expressionmodels.</description><author>Viktoria Schuster</author><pubDate>Mon, 03 Feb 2025 18:20:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11468v2</guid></item><item><title>The TIP of the Iceberg: Revealing a Hidden Class of Task-In-Prompt Adversarial Attacks on LLMs</title><link>http://arxiv.org/abs/2501.18626v2</link><description>We present a novel class of jailbreak adversarial attacks on LLMs, termedTask-in-Prompt (TIP) attacks. Our approach embeds sequence-to-sequence tasks(e.g., cipher decoding, riddles, code execution) into the model's prompt toindirectly generate prohibited inputs. To systematically assess theeffectiveness of these attacks, we introduce the PHRYGE benchmark. Wedemonstrate that our techniques successfully circumvent safeguards in sixstate-of-the-art language models, including GPT-4o and LLaMA 3.2. Our findingshighlight critical weaknesses in current LLM safety alignments and underscorethe urgent need for more sophisticated defence strategies. Warning: this paper contains examples of unethical inquiries used solely forresearch purposes.</description><author>Sergey Berezin, Reza Farahbakhsh, Noel Crespi</author><pubDate>Mon, 03 Feb 2025 18:19:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18626v2</guid></item><item><title>Global Public Sentiment on Decentralized Finance: A Spatiotemporal Analysis of Geo-tagged Tweets from 150 Countries</title><link>http://arxiv.org/abs/2409.00843v2</link><description>Blockchain technology and decentralized finance (DeFi) are reshaping globalfinancial systems. Despite their impact, the spatial distribution of publicsentiment and its economic and geopolitical determinants are often overlooked.This study analyzes over 150 million geo-tagged, DeFi-related tweets from 2012to 2022, sourced from a larger dataset of 7.4 billion tweets. Using sentimentscores from a BERT-based multilingual classification model, we integrated thesetweets with economic and geopolitical data to create a multimodal dataset.Employing techniques like sentiment analysis, spatial econometrics, clustering,and topic modeling, we uncovered significant global variations in DeFiengagement and sentiment. Our findings indicate that economic developmentsignificantly influences DeFi engagement, particularly after 2015.Geographically weighted regression analysis revealed GDP per capita as a keypredictor of DeFi tweet proportions, with its impact growing following majorincreases in cryptocurrency values such as bitcoin. While wealthier nations aremore actively engaged in DeFi discourse, the lowest-income countries oftendiscuss DeFi in terms of financial security and sudden wealth. Conversely,middle-income countries relate DeFi to social and religious themes, whereashigh-income countries view it mainly as a speculative instrument orentertainment. This research advances interdisciplinary studies incomputational social science and finance and supports open science by makingour dataset and code available on GitHub, and providing a non-code workflow onthe KNIME platform. These contributions enable a broad range of scholars toexplore DeFi adoption and sentiment, aiding policymakers, regulators, anddevelopers in promoting financial inclusion and responsible DeFi engagementglobally.</description><author>Yuqi Chen, Yifan Li, Kyrie Zhixuan Zhou, Xiaokang Fu, Lingbo Liu, Shuming Bao, Daniel Sui, Luyao Zhang</author><pubDate>Mon, 03 Feb 2025 18:18:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.00843v2</guid></item><item><title>The ALCHEmist: Automated Labeling 500x CHEaper Than LLM Data Annotators</title><link>http://arxiv.org/abs/2407.11004v2</link><description>Large pretrained models can be used as annotators, helping replace or augmentcrowdworkers and enabling distilling generalist models into smaller specialistmodels. Unfortunately, this comes at a cost: employing top-of-the-line modelsoften requires paying thousands of dollars for API calls, while the resultingdatasets are static and challenging to audit. To address these challenges, wepropose a simple alternative: rather than directly querying labels frompretrained models, we task models to generate programs that can produce labels.These programs can be stored and applied locally, re-used and extended, andcost orders of magnitude less. Our system, Alchemist, obtains comparable to orbetter performance than large language model-based annotation in a range oftasks for a fraction of the cost: on average, improvements amount to a 12.9%enhancement while the total labeling costs across all datasets are reduced by afactor of approximately 500x.</description><author>Tzu-Heng Huang, Catherine Cao, Vaishnavi Bhargava, Frederic Sala</author><pubDate>Mon, 03 Feb 2025 18:17:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11004v2</guid></item><item><title>Efficient Annotator Reliability Assessment and Sample Weighting for Knowledge-Based Misinformation Detection on Social Media</title><link>http://arxiv.org/abs/2410.14515v2</link><description>Misinformation spreads rapidly on social media, confusing the truth andtargeting potentially vulnerable people. To effectively mitigate the negativeimpact of misinformation, it must first be accurately detected before applyinga mitigation strategy, such as X's community notes, which is currently a manualprocess. This study takes a knowledge-based approach to misinformationdetection, modelling the problem similarly to one of natural languageinference. The EffiARA annotation framework is introduced, aiming to utiliseinter- and intra-annotator agreement to understand the reliability of eachannotator and influence the training of large language models forclassification based on annotator reliability. In assessing the EffiARAannotation framework, the Russo-Ukrainian Conflict Knowledge-BasedMisinformation Classification Dataset (RUC-MCD) was developed and made publiclyavailable. This study finds that sample weighting using annotator reliabilityperforms the best, utilising both inter- and intra-annotator agreement andsoft-label training. The highest classification performance achieved usingLlama-3.2-1B was a macro-F1 of 0.757 and 0.740 using TwHIN-BERT-large.</description><author>Owen Cook, Charlie Grimshaw, Ben Wu, Sophie Dillon, Jack Hicks, Luke Jones, Thomas Smith, Matyas Szert, Xingyi Song</author><pubDate>Mon, 03 Feb 2025 18:10:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14515v2</guid></item><item><title>STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions</title><link>http://arxiv.org/abs/2409.13843v2</link><description>Mitigating explicit and implicit biases in Large Language Models (LLMs) hasbecome a critical focus in the field of natural language processing. However,many current methodologies evaluate scenarios in isolation, without consideringthe broader context or the spectrum of potential biases within each situation.To address this, we introduce the Sensitivity Testing on Offensive Progressions(STOP) dataset, which includes 450 offensive progressions containing 2,700unique sentences of varying severity that progressively escalate from less tomore explicitly offensive. Covering a broad spectrum of 9 demographics and 46sub-demographics, STOP ensures inclusivity and comprehensive coverage. Weevaluate several leading closed- and open-source models, including GPT-4,Mixtral, and Llama 3. Our findings reveal that even the best-performing modelsdetect bias inconsistently, with success rates ranging from 19.3% to 69.8%. Wealso demonstrate how aligning models with human judgments on STOP can improvemodel answer rates on sensitive tasks such as BBQ, StereoSet, and CrowS-Pairsby up to 191%, while maintaining or even improving performance. STOP presents anovel framework for assessing the complex nature of biases in LLMs, which willenable more effective bias mitigation strategies and facilitates the creationof fairer language models.</description><author>Robert Morabito, Sangmitra Madhusudan, Tyler McDonald, Ali Emami</author><pubDate>Mon, 03 Feb 2025 18:06:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.13843v2</guid></item><item><title>Mind the Gap: a Spectral Analysis of Rank Collapse and Signal Propagation in Attention Layers</title><link>http://arxiv.org/abs/2410.07799v2</link><description>Attention layers are the core component of transformers, the currentstate-of-the-art neural network architecture. Alternatives to softmax-basedattention are being explored due to its tendency to hinder effectiveinformation flow. Even at initialisation, it remains poorly understood why thepropagation of signals and gradients through these random networks can bepathological, resulting in issues known as (i) vanishing/exploding gradientsand (ii) rank collapse $\textit{in depth}$, i.e. when all tokens converge to asingle representation along layers. While rank collapse in depth naturallyarises from repeated matrix multiplications$\unicode{x2013}$a common patternacross various architectures$\unicode{x2013}$we identify an additional andpreviously unknown challenge unique to softmax attention layers: (iii) rankcollapse $\textit{in width}$, which occurs as the context length increases.Using Random Matrix Theory, we conduct a rigorous analysis that uncovers aspectral gap between the two largest singular values of the attention matrix asthe cause of (iii), which in turn exacerbates (i) and (ii). Building on thisinsight, we propose a novel yet simple practical solution to mitigate rankcollapse in width by removing the outlier eigenvalue(s). Our theoreticalframework offers a fresh perspective on recent practical studies, such as (Yeet al., 2024; Ali et al., 2023), whose ad hoc solutions can now be interpretedas implicit efforts to address the spectral gap issue. This work providesvaluable theoretical support for ongoing large-scale empirical research,bringing theory and practice one step closer in the understanding oftransformers.</description><author>Alireza Naderi, Thiziri Nait Saada, Jared Tanner</author><pubDate>Mon, 03 Feb 2025 17:45:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07799v2</guid></item><item><title>Predict. Optimize. Revise. On Forecast and Policy Stability in Energy Management Systems</title><link>http://arxiv.org/abs/2407.03368v4</link><description>This research addresses the challenge of integrating forecasting andoptimization in energy management systems, focusing on the impacts of switchingcosts, forecast accuracy, and stability. It proposes a novel framework foranalyzing online optimization problems with switching costs and enabled bydeterministic and probabilistic forecasts. Through empirical evaluation andtheoretical analysis, the research reveals the balance between forecastaccuracy, stability, and switching costs in shaping policy performance.Conducted in the context of battery scheduling within energy managementapplications, it introduces a metric for evaluating probabilistic forecaststability and examines the effects of forecast accuracy and stability onoptimization outcomes using the real-world case of the Citylearn 2022competition. Findings indicate that switching costs significantly influence thetrade-off between forecast accuracy and stability, highlighting the importanceof integrated systems that enable collaboration between forecasting andoperational units for improved decision-making. The study shows that committingto a policy for longer periods can be advantageous over frequent updates.Results also show a correlation between forecast stability and policyperformance, suggesting that stable forecasts can mitigate switching costs. Theproposed framework provides valuable insights for energy sector decision-makersand forecast practitioners when designing the operation of an energy managementsystem.</description><author>Evgenii Genov, Julian Ruddick, Christoph Bergmeir, Majid Vafaeipour, Thierry Coosemans, Salvador Garcia, Maarten Messagie</author><pubDate>Mon, 03 Feb 2025 17:41:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03368v4</guid></item><item><title>SELMA: A Speech-Enabled Language Model for Virtual Assistant Interactions</title><link>http://arxiv.org/abs/2501.19377v2</link><description>In this work, we present and evaluate SELMA, a Speech-Enabled Language Modelfor virtual Assistant interactions that integrates audio and text as inputs toa Large Language Model (LLM). SELMA is designed to handle three primary and twoauxiliary tasks related to interactions with virtual assistants simultaneouslywithin a single end-to-end model. We employ low-rank adaptation modules forparameter-efficient training of both the audio encoder and the LLM.Additionally, we implement a feature pooling strategy enabling the system torecognize global patterns and improve accuracy on tasks less reliant onindividual sequence elements. Experimental results on Voice Trigger (VT)detection, Device-Directed Speech Detection (DDSD), and Automatic SpeechRecognition (ASR), demonstrate that our approach both simplifies the typicalinput processing pipeline of virtual assistants significantly and also improvesperformance compared to dedicated models for each individual task. SELMA yieldsrelative Equal-Error Rate improvements of 64% on the VT detection task, and 22%on DDSD, while also achieving word error rates close to the baseline.</description><author>Dominik Wagner, Alexander Churchill, Siddharth Sigtia, Erik Marchi</author><pubDate>Mon, 03 Feb 2025 17:35:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.19377v2</guid></item><item><title>What is causal about causal models and representations?</title><link>http://arxiv.org/abs/2501.19335v2</link><description>Causal Bayesian networks are 'causal' models since they make predictionsabout interventional distributions. To connect such causal model predictions toreal-world outcomes, we must determine which actions in the world correspond towhich interventions in the model. For example, to interpret an action as anintervention on a treatment variable, the action will presumably have to a)change the distribution of treatment in a way that corresponds to theintervention, and b) not change other aspects, such as how the outcome dependson the treatment; while the marginal distributions of some variables may changeas an effect. We introduce a formal framework to make such requirements fordifferent interpretations of actions as interventions precise. We prove thatthe seemingly natural interpretation of actions as interventions is circular:Under this interpretation, every causal Bayesian network that correctly modelsthe observational distribution is trivially also interventionally valid, and noaction yields empirical data that could possibly falsify such a model. We provean impossibility result: No interpretation exists that is non-circular andsimultaneously satisfies a set of natural desiderata. Instead, we examinenon-circular interpretations that may violate some desiderata and show how thismay in turn enable the falsification of causal models. By rigorously examininghow a causal Bayesian network could be a 'causal' model of the world instead ofmerely a mathematical object, our formal framework contributes to theconceptual foundations of causal representation learning, causal discovery, andcausal abstraction, while also highlighting some limitations of existingapproaches.</description><author>Frederik Hytting Jørgensen, Luigi Gresele, Sebastian Weichwald</author><pubDate>Mon, 03 Feb 2025 17:24:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.19335v2</guid></item><item><title>How Do the Architecture and Optimizer Affect Representation Learning? On the Training Dynamics of Representations in Deep Neural Networks</title><link>http://arxiv.org/abs/2405.17377v2</link><description>In this paper, we elucidate how representations in deep neural networks(DNNs) evolve during training. Our focus is on overparameterized learningsettings where the training continues much after the trained DNN starts toperfectly fit its training data. We examine the evolution of learnedrepresentations along the entire training process. We explore therepresentational similarity of DNN layers, each layer with respect to its ownrepresentations throughout the training process. For this, we use twosimilarity metrics: (1) The centered kernel alignment (CKA) similarity; (2)Similarity of decision regions of linear classifier probes that we train forthe DNN layers. We visualize and analyze the decision regions of the DNN outputand the layer probes during the DNN training to show how they geometricallyevolve. Our extensive experiments discover training dynamics patterns that canemerge in layers depending on the relative layer-depth, architecture andoptimizer. Among our findings: (i) The training phases, including those relatedto memorization, are more distinguishable in SGD training than in Adamtraining, and for Vision Transformer (ViT) than for ResNet; (ii) Unlike ResNet,the ViT layers have synchronized dynamics of representation learning.</description><author>Yuval Sharon, Yehuda Dar</author><pubDate>Mon, 03 Feb 2025 17:24:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17377v2</guid></item><item><title>Tazza: Shuffling Neural Network Parameters for Secure and Private Federated Learning</title><link>http://arxiv.org/abs/2412.07454v2</link><description>Federated learning enables decentralized model training without sharing rawdata, preserving data privacy. However, its vulnerability towards criticalsecurity threats, such as gradient inversion and model poisoning by maliciousclients, remain unresolved. Existing solutions often address these issuesseparately, sacrificing either system robustness or model accuracy. This workintroduces Tazza, a secure and efficient federated learning framework thatsimultaneously addresses both challenges. By leveraging the permutationequivariance and invariance properties of neural networks via weight shufflingand shuffled model validation, Tazza enhances resilience against diversepoisoning attacks, while ensuring data confidentiality and high model accuracy.Comprehensive evaluations on various datasets and embedded platforms show thatTazza achieves robust defense with up to 6.7x improved computational efficiencycompared to alternative schemes, without compromising performance.</description><author>Kichang Lee, Jaeho Jin, JaeYeon Park, Songkuk Kim, JeongGil Ko</author><pubDate>Mon, 03 Feb 2025 17:23:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.07454v2</guid></item><item><title>Brain-Inspired AI with Hyperbolic Geometry</title><link>http://arxiv.org/abs/2409.12990v3</link><description>Artificial neural networks (ANNs) were inspired by the architecture andfunctions of the human brain and have revolutionised the field of artificialintelligence (AI). Inspired by studies on the latent geometry of the brain, inthis perspective paper we posit that an increase in the research andapplication of hyperbolic geometry in ANNs and machine learning will lead toincreased accuracy, improved feature space representations and more efficientmodels across a range of tasks. We examine the structure and functions of thehuman brain, emphasising the correspondence between its scale-free hierarchicalorganization and hyperbolic geometry, and reflecting on the central rolehyperbolic geometry plays in facilitating human intelligence. Empiricalevidence indicates that hyperbolic neural networks outperform Euclidean modelsfor tasks including natural language processing, computer vision and complexnetwork analysis, requiring fewer parameters and exhibiting bettergeneralisation. Despite its nascent adoption, hyperbolic geometry holds promisefor improving machine learning models through brain-inspired geometricrepresentations.</description><author>Alexander Joseph, Nathan Francis, Meijke Balay</author><pubDate>Mon, 03 Feb 2025 17:14:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.12990v3</guid></item><item><title>What is the Relationship between Tensor Factorizations and Circuits (and How Can We Exploit it)?</title><link>http://arxiv.org/abs/2409.07953v2</link><description>This paper establishes a rigorous connection between circuit representationsand tensor factorizations, two seemingly distinct yet fundamentally relatedareas. By connecting these fields, we highlight a series of opportunities thatcan benefit both communities. Our work generalizes popular tensorfactorizations within the circuit language, and unifies various circuitlearning algorithms under a single, generalized hierarchical factorizationframework. Specifically, we introduce a modular "Lego block" approach to buildtensorized circuit architectures. This, in turn, allows us to systematicallyconstruct and explore various circuit and tensor factorization models whilemaintaining tractability. This connection not only clarifies similarities anddifferences in existing models, but also enables the development of acomprehensive pipeline for building and optimizing new circuit/tensorfactorization architectures. We show the effectiveness of our framework throughextensive empirical evaluations, and highlight new research opportunities fortensor factorizations in probabilistic modeling.</description><author>Lorenzo Loconte, Antonio Mari, Gennaro Gala, Robert Peharz, Cassio de Campos, Erik Quaeghebeur, Gennaro Vessio, Antonio Vergari</author><pubDate>Mon, 03 Feb 2025 17:00:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.07953v2</guid></item><item><title>The Master Key Filters Hypothesis: Deep Filters Are General</title><link>http://arxiv.org/abs/2412.16751v2</link><description>This paper challenges the prevailing view that convolutional neural network(CNN) filters become increasingly specialized in deeper layers. Motivated byrecent observations of clusterable repeating patterns in depthwise separableCNNs (DS-CNNs) trained on ImageNet, we extend this investigation across variousdomains and datasets. Our analysis of DS-CNNs reveals that deep filtersmaintain generality, contradicting the expected transition to class-specificfilters. We demonstrate the generalizability of these filters through transferlearning experiments, showing that frozen filters from models trained ondifferent datasets perform well and can be further improved when sourced fromlarger datasets. Our findings indicate that spatial features learned bydepthwise separable convolutions remain generic across all layers, domains, andarchitectures. This research provides new insights into the nature ofgeneralization in neural networks, particularly in DS-CNNs, and has significantimplications for transfer learning and model design.</description><author>Zahra Babaiee, Peyman M. Kiasari, Daniela Rus, Radu Grosu</author><pubDate>Mon, 03 Feb 2025 16:58:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16751v2</guid></item><item><title>Whom do Explanations Serve? A Systematic Literature Survey of User Characteristics in Explainable Recommender Systems Evaluation</title><link>http://arxiv.org/abs/2412.14193v2</link><description>Adding explanations to recommender systems is said to have multiple benefits,such as increasing user trust or system transparency. Previous work from otherapplication areas suggests that specific user characteristics impact the users'perception of the explanation. However, we rarely find this type of evaluationfor recommender systems explanations. This paper addresses this gap bysurveying 124 papers in which recommender systems explanations were evaluatedin user studies. We analyzed their participant descriptions and study resultswhere the impact of user characteristics on the explanation effects wasmeasured. Our findings suggest that the results from the surveyed studiespredominantly cover specific users who do not necessarily represent the usersof recommender systems in the evaluation domain. This may seriously hamper thegeneralizability of any insights we may gain from current studies onexplanations in recommender systems. We further find inconsistencies in thedata reporting, which impacts the reproducibility of the reported results.Hence, we recommend actions to move toward a more inclusive and reproducibleevaluation.</description><author>Kathrin Wardatzky, Oana Inel, Luca Rossetto, Abraham Bernstein</author><pubDate>Mon, 03 Feb 2025 16:50:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14193v2</guid></item><item><title>kNN Retrieval for Simple and Effective Zero-Shot Multi-speaker Text-to-Speech</title><link>http://arxiv.org/abs/2408.10771v3</link><description>While recent zero-shot multi-speaker text-to-speech (TTS) models achieveimpressive results, they typically rely on extensive transcribed speechdatasets from numerous speakers and intricate training pipelines. Meanwhile,self-supervised learning (SSL) speech features have emerged as effectiveintermediate representations for TTS. Further, SSL features from differentspeakers that are linearly close share phonetic information while maintainingindividual speaker identity. In this study, we introduce kNN-TTS, a simple andeffective framework for zero-shot multi-speaker TTS using retrieval methodswhich leverage the linear relationships between SSL features. Objective andsubjective evaluations show that our models, trained on transcribed speech froma single speaker only, achieve performance comparable to state-of-the-artmodels that are trained on significantly larger training datasets. The lowtraining data requirements mean that kNN-TTS is well suited for the developmentof multi-speaker TTS systems for low-resource domains and languages. We alsointroduce an interpolation parameter which enables fine-grained voice morphing.Demo samples are available at https://idiap.github.io/knn-tts</description><author>Karl El Hajal, Ajinkya Kulkarni, Enno Hermann, Mathew Magimai. -Doss</author><pubDate>Mon, 03 Feb 2025 16:47:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10771v3</guid></item><item><title>Toward Conditional Distribution Calibration in Survival Prediction</title><link>http://arxiv.org/abs/2410.20579v2</link><description>Survival prediction often involves estimating the time-to-event distributionfrom censored datasets. Previous approaches have focused on enhancingdiscrimination and marginal calibration. In this paper, we highlight thesignificance of conditional calibration for real-world applications --especially its role in individual decision-making. We propose a method based onconformal prediction that uses the model's predicted individual survivalprobability at that instance's observed time. This method effectively improvesthe model's marginal and conditional calibration, without compromisingdiscrimination. We provide asymptotic theoretical guarantees for both marginaland conditional calibration and test it extensively across 15 diversereal-world datasets, demonstrating the method's practical effectiveness andversatility in various settings.</description><author>Shi-ang Qi, Yakun Yu, Russell Greiner</author><pubDate>Mon, 03 Feb 2025 16:47:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20579v2</guid></item><item><title>Learning Time-Varying Multi-Region Communications via Scalable Markovian Gaussian Processes</title><link>http://arxiv.org/abs/2407.00397v2</link><description>Understanding and constructing brain communications that capture dynamiccommunications across multiple regions is fundamental to modern systemneuroscience, yet current methods struggle to find time-varying region-levelcommunications or scale to large neural datasets with long recording durations.We present a novel framework using Markovian Gaussian Processes to learn braincommunications with time-varying temporal delays from multi-region neuralrecordings, named Adaptive Delay Model (ADM). Our method combines GaussianProcesses with State Space Models and employs parallel scan inferencealgorithms, enabling efficient scaling to large datasets while identifyingconcurrent communication patterns that evolve over time. This time-varyingapproach captures how brain region interactions shift dynamically duringcognitive processes. Validated on synthetic and multi-region neural recordingsdatasets, our approach discovers both the directionality and temporal dynamicsof neural communication. This work advances our understanding of distributedneural computation and provides a scalable tool for analyzing dynamic brainnetworks.</description><author>Weihan Li, Yule Wang, Chengrui Li, Anqi Wu</author><pubDate>Mon, 03 Feb 2025 16:40:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00397v2</guid></item><item><title>Improving Pareto Set Learning for Expensive Multi-objective Optimization via Stein Variational Hypernetworks</title><link>http://arxiv.org/abs/2412.17312v2</link><description>Expensive multi-objective optimization problems (EMOPs) are common inreal-world scenarios where evaluating objective functions is costly andinvolves extensive computations or physical experiments. Current Pareto setlearning methods for such problems often rely on surrogate models like Gaussianprocesses to approximate the objective functions. These surrogate models canbecome fragmented, resulting in numerous small uncertain regions betweenexplored solutions. When using acquisition functions such as the LowerConfidence Bound (LCB), these uncertain regions can turn into pseudo-localoptima, complicating the search for globally optimal solutions. To addressthese challenges, we propose a novel approach called SVH-PSL, which integratesStein Variational Gradient Descent (SVGD) with Hypernetworks for efficientPareto set learning. Our method addresses the issues of fragmented surrogatemodels and pseudo-local optima by collectively moving particles in a mannerthat smooths out the solution space. The particles interact with each otherthrough a kernel function, which helps maintain diversity and encourages theexploration of underexplored regions. This kernel-based interaction preventsparticles from clustering around pseudo-local optima and promotes convergencetowards globally optimal solutions. Our approach aims to establish robustrelationships between trade-off reference vectors and their corresponding truePareto solutions, overcoming the limitations of existing methods. Throughextensive experiments across both synthetic and real-world MOO benchmarks, wedemonstrate that SVH-PSL significantly improves the quality of the learnedPareto set, offering a promising solution for expensive multi-objectiveoptimization problems.</description><author>Minh-Duc Nguyen, Phuong Mai Dinh, Quang-Huy Nguyen, Long P. Hoang, Dung D. Le</author><pubDate>Mon, 03 Feb 2025 16:33:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17312v2</guid></item><item><title>Symmetry-Aware Generative Modeling through Learned Canonicalization</title><link>http://arxiv.org/abs/2501.07773v2</link><description>Generative modeling of symmetric densities has a range of applications in AIfor science, from drug discovery to physics simulations. The existinggenerative modeling paradigm for invariant densities combines an invariantprior with an equivariant generative process. However, we observe that thistechnique is not necessary and has several drawbacks resulting from thelimitations of equivariant networks. Instead, we propose to model a learnedslice of the density so that only one representative element per orbit islearned. To accomplish this, we learn a group-equivariant canonicalizationnetwork that maps training samples to a canonical pose and train anon-equivariant generative model over these canonicalized samples. We implementthis idea in the context of diffusion models. Our preliminary experimentalresults on molecular modeling are promising, demonstrating improved samplequality and faster inference time.</description><author>Kusha Sareen, Daniel Levy, Arnab Kumar Mondal, Sékou-Oumar Kaba, Tara Akhound-Sadegh, Siamak Ravanbakhsh</author><pubDate>Mon, 03 Feb 2025 16:33:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.07773v2</guid></item><item><title>s1: Simple test-time scaling</title><link>http://arxiv.org/abs/2501.19393v2</link><description>Test-time scaling is a promising new approach to language modeling that usesextra test-time compute to improve performance. Recently, OpenAI's o1 modelshowed this capability but did not publicly share its methodology, leading tomany replication efforts. We seek the simplest approach to achieve test-timescaling and strong reasoning performance. First, we curate a small dataset s1Kof 1,000 questions paired with reasoning traces relying on three criteria wevalidate through ablations: difficulty, diversity, and quality. Second, wedevelop budget forcing to control test-time compute by forcefully terminatingthe model's thinking process or lengthening it by appending "Wait" multipletimes to the model's generation when it tries to end. This can lead the modelto double-check its answer, often fixing incorrect reasoning steps. Aftersupervised finetuning the Qwen2.5-32B-Instruct language model on s1K andequipping it with budget forcing, our model s1-32B exceeds o1-preview oncompetition math questions by up to 27% (MATH and AIME24). Further, scalings1-32B with budget forcing allows extrapolating beyond its performance withouttest-time intervention: from 50% to 57% on AIME24. Our model, data, and codeare open-source at https://github.com/simplescaling/s1</description><author>Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei-Fei, Hannaneh Hajishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel Candès, Tatsunori Hashimoto</author><pubDate>Mon, 03 Feb 2025 16:31:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.19393v2</guid></item><item><title>DeciMamba: Exploring the Length Extrapolation Potential of Mamba</title><link>http://arxiv.org/abs/2406.14528v2</link><description>Long-range sequence processing poses a significant challenge for Transformersdue to their quadratic complexity in input length. A promising alternative isMamba, which demonstrates high performance and achieves Transformer-levelcapabilities while requiring substantially fewer computational resources. Inthis paper we explore the length-generalization capabilities of Mamba, which wefind to be relatively limited. Through a series of visualizations and analyseswe identify that the limitations arise from a restricted effective receptivefield, dictated by the sequence length used during training. To address thisconstraint, we introduce DeciMamba, a context-extension method specificallydesigned for Mamba. This mechanism, built on top of a hidden filteringmechanism embedded within the S6 layer, enables the trained model toextrapolate well even without additional training. Empirical experiments overreal-world long-range NLP tasks show that DeciMamba can extrapolate to contextlengths that are significantly longer than the ones seen during training, whileenjoying faster inference.</description><author>Assaf Ben-Kish, Itamar Zimerman, Shady Abu-Hussein, Nadav Cohen, Amir Globerson, Lior Wolf, Raja Giryes</author><pubDate>Mon, 03 Feb 2025 16:26:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14528v2</guid></item><item><title>DeTrigger: A Gradient-Centric Approach to Backdoor Attack Mitigation in Federated Learning</title><link>http://arxiv.org/abs/2411.12220v2</link><description>Federated Learning (FL) enables collaborative model training acrossdistributed devices while preserving local data privacy, making it ideal formobile and embedded systems. However, the decentralized nature of FL also opensvulnerabilities to model poisoning attacks, particularly backdoor attacks,where adversaries implant trigger patterns to manipulate model predictions. Inthis paper, we propose DeTrigger, a scalable and efficient backdoor-robustfederated learning framework that leverages insights from adversarial attackmethodologies. By employing gradient analysis with temperature scaling,DeTrigger detects and isolates backdoor triggers, allowing for precise modelweight pruning of backdoor activations without sacrificing benign modelknowledge. Extensive evaluations across four widely used datasets demonstratethat DeTrigger achieves up to 251x faster detection than traditional methodsand mitigates backdoor attacks by up to 98.9%, with minimal impact on globalmodel accuracy. Our findings establish DeTrigger as a robust and scalablesolution to protect federated learning environments against sophisticatedbackdoor threats.</description><author>Kichang Lee, Yujin Shin, Jonghyuk Yun, Songkuk Kim, Jun Han, JeongGil Ko</author><pubDate>Mon, 03 Feb 2025 16:20:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12220v2</guid></item><item><title>ViewpointDepth: A New Dataset for Monocular Depth Estimation Under Viewpoint Shifts</title><link>http://arxiv.org/abs/2409.17851v3</link><description>Monocular depth estimation is a critical task for autonomous driving and manyother computer vision applications. While significant progress has been made inthis field, the effects of viewpoint shifts on depth estimation models remainlargely underexplored. This paper introduces a novel dataset and evaluationmethodology to quantify the impact of different camera positions andorientations on monocular depth estimation performance. We propose a groundtruth strategy based on homography estimation and object detection, eliminatingthe need for expensive LIDAR sensors. We collect a diverse dataset of roadscenes from multiple viewpoints and use it to assess the robustness of a moderndepth estimation model to geometric shifts. After assessing the validity of ourstrategy on a public dataset, we provide valuable insights into the limitationsof current models and highlight the importance of considering viewpointvariations in real-world applications.</description><author>Aurel Pjetri, Stefano Caprasecca, Leonardo Taccari, Matteo Simoncini, Henrique Piñeiro Monteagudo, Wallace Walter, Douglas Coimbra de Andrade, Francesco Sambo, Andrew David Bagdanov</author><pubDate>Mon, 03 Feb 2025 16:19:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.17851v3</guid></item><item><title>Trust-Oriented Adaptive Guardrails for Large Language Models</title><link>http://arxiv.org/abs/2408.08959v2</link><description>Guardrail, an emerging mechanism designed to ensure that large languagemodels (LLMs) align with human values by moderating harmful or toxic responses,requires a sociotechnical approach in their design. This paper addresses acritical issue: existing guardrails lack a well-founded methodology toaccommodate the diverse needs of different user groups, particularly concerningaccess rights. Supported by trust modeling (primarily on `social' aspect) andenhanced with online in-context learning via retrieval-augmented generation (on`technical' aspect), we introduce an adaptive guardrail mechanism, todynamically moderate access to sensitive content based on user trust metrics.User trust metrics, defined as a novel combination of direct interaction trustand authority-verified trust, enable the system to precisely tailor thestrictness of content moderation by aligning with the user's credibility andthe specific context of their inquiries. Our empirical evaluation demonstratesthe effectiveness of the adaptive guardrail in meeting diverse user needs,outperforming existing guardrails while securing sensitive information andprecisely managing potentially hazardous content through a context-awareknowledge base. To the best of our knowledge, this work is the first tointroduce trust-oriented concept into a guardrail system, offering a scalablesolution that enriches the discourse on ethical deployment for next-generationLLM service.</description><author>Jinwei Hu, Yi Dong, Xiaowei Huang</author><pubDate>Mon, 03 Feb 2025 16:03:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.08959v2</guid></item><item><title>Large Language Models are Advanced Anonymizers</title><link>http://arxiv.org/abs/2402.13846v2</link><description>Recent privacy research on large language models (LLMs) has shown that theyachieve near-human-level performance at inferring personal data from onlinetexts. With ever-increasing model capabilities, existing text anonymizationmethods are currently lacking behind regulatory requirements and adversarialthreats. In this work, we take two steps to bridge this gap: First, we presenta new setting for evaluating anonymization in the face of adversarial LLMinferences, allowing for a natural measurement of anonymization performancewhile remedying some of the shortcomings of previous metrics. Then, within thissetting, we develop a novel LLM-based adversarial anonymization frameworkleveraging the strong inferential capabilities of LLMs to inform ouranonymization procedure. We conduct a comprehensive experimental evaluation ofadversarial anonymization across 13 LLMs on real-world and synthetic onlinetexts, comparing it against multiple baselines and industry-grade anonymizers.Our evaluation shows that adversarial anonymization outperforms currentcommercial anonymizers both in terms of the resulting utility and privacy. Wesupport our findings with a human study (n=50) highlighting a strong andconsistent human preference for LLM-anonymized texts.</description><author>Robin Staab, Mark Vero, Mislav Balunović, Martin Vechev</author><pubDate>Mon, 03 Feb 2025 16:03:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13846v2</guid></item><item><title>Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models</title><link>http://arxiv.org/abs/2501.18592v2</link><description>In real-world scenarios, achieving domain adaptation and generalization posessignificant challenges, as models must adapt to or generalize across unknowntarget distributions. Extending these capabilities to unseen multimodaldistributions, i.e., multimodal domain adaptation and generalization, is evenmore challenging due to the distinct characteristics of different modalities.Significant progress has been made over the years, with applications rangingfrom action recognition to semantic segmentation. Besides, the recent advent oflarge-scale pre-trained multimodal foundation models, such as CLIP, hasinspired works leveraging these models to enhance adaptation and generalizationperformances or adapting them to downstream tasks. This survey provides thefirst comprehensive review of recent advances from traditional approaches tofoundation models, covering: (1) Multimodal domain adaptation; (2) Multimodaltest-time adaptation; (3) Multimodal domain generalization; (4) Domainadaptation and generalization with the help of multimodal foundation models;and (5) Adaptation of multimodal foundation models. For each topic, we formallydefine the problem and thoroughly review existing methods. Additionally, weanalyze relevant datasets and applications, highlighting open challenges andpotential future research directions. We maintain an active repository thatcontains up-to-date literature athttps://github.com/donghao51/Awesome-Multimodal-Adaptation.</description><author>Hao Dong, Moru Liu, Kaiyang Zhou, Eleni Chatzi, Juho Kannala, Cyrill Stachniss, Olga Fink</author><pubDate>Mon, 03 Feb 2025 16:01:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18592v2</guid></item><item><title>Neuromorphic Wireless Split Computing with Multi-Level Spikes</title><link>http://arxiv.org/abs/2411.04728v2</link><description>Inspired by biological processes, neuromorphic computing leverages spikingneural networks (SNNs) to perform inference tasks, offering significantefficiency gains for workloads involving sequential data. Recent advances inhardware and software have shown that embedding a small payload within eachspike exchanged between spiking neurons can enhance inference accuracy withoutincreasing energy consumption. To scale neuromorphic computing to largerworkloads, split computing - where an SNN is partitioned across two devices -is a promising solution. In such architectures, the device hosting the initiallayers must transmit information about the spikes generated by its outputneurons to the second device. This establishes a trade-off between the benefitsof multi-level spikes, which carry additional payload information, and thecommunication resources required for transmitting extra bits between devices.This paper presents the first comprehensive study of a neuromorphic wirelesssplit computing architecture that employs multi-level SNNs. We propose digitaland analog modulation schemes for an orthogonal frequency division multiplexing(OFDM) radio interface to enable efficient communication. Simulation andexperimental results using software-defined radios reveal performanceimprovements achieved by multi-level SNN models and provide insights into theoptimal payload size as a function of the connection quality between thetransmitter and receiver.</description><author>Dengyu Wu, Jiechen Chen, Bipin Rajendran, H. Vincent Poor, Osvaldo Simeone</author><pubDate>Mon, 03 Feb 2025 15:51:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.04728v2</guid></item><item><title>A Benchmark and Evaluation for Real-World Out-of-Distribution Detection Using Vision-Language Models</title><link>http://arxiv.org/abs/2501.18463v2</link><description>Out-of-distribution (OOD) detection is a task that detects OOD samples duringinference to ensure the safety of deployed models. However, conventionalbenchmarks have reached performance saturation, making it difficult to comparerecent OOD detection methods. To address this challenge, we introduce threenovel OOD detection benchmarks that enable a deeper understanding of methodcharacteristics and reflect real-world conditions. First, we presentImageNet-X, designed to evaluate performance under challenging semantic shifts.Second, we propose ImageNet-FS-X for full-spectrum OOD detection, assessingrobustness to covariate shifts (feature distribution shifts). Finally, wepropose Wilds-FS-X, which extends these evaluations to real-world datasets,offering a more comprehensive testbed. Our experiments reveal that recentCLIP-based OOD detection methods struggle to varying degrees across the threeproposed benchmarks, and none of them consistently outperforms the others. Wehope the community goes beyond specific benchmarks and includes morechallenging conditions reflecting real-world scenarios. The code ishttps://github.com/hoshi23/OOD-X-Benchmarks.</description><author>Shiho Noda, Atsuyuki Miyai, Qing Yu, Go Irie, Kiyoharu Aizawa</author><pubDate>Mon, 03 Feb 2025 15:51:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18463v2</guid></item><item><title>Harnessing Generative AI for Economic Insights</title><link>http://arxiv.org/abs/2410.03897v3</link><description>We use generative AI to extract managerial expectations about their economicoutlook from over 120,000 corporate conference call transcripts. The overallmeasure, AI Economy Score, robustly predicts future economic indicators such asGDP growth, production, and employment, both in the short term and to 10quarters. This predictive power is incremental to that of existing measures,including survey forecasts. Moreover, industry and firm-level measures providevaluable information about sector-specific and individual firm activities. Ourfindings suggest that managerial expectations carry unique insights abouteconomic activities, with implications for both macroeconomic and microeconomicdecision-making.</description><author>Manish Jha, Jialin Qian, Michael Weber, Baozhong Yang</author><pubDate>Mon, 03 Feb 2025 15:40:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.03897v3</guid></item><item><title>On Probabilistic Pullback Metrics on Latent Hyperbolic Manifolds</title><link>http://arxiv.org/abs/2410.20850v2</link><description>Probabilistic Latent Variable Models (LVMs) have proven effective incapturing complex, high-dimensional data through lower-dimensionalrepresentations. Recent advances show that using Riemannian manifolds as latentspaces provides more flexibility to learn higher quality embeddings. This paperfocuses on the hyperbolic manifold, a particularly suitable choice for modelinghierarchical relationships. Previous approaches relying on hyperbolic geodesicsfor interpolating the latent space often generate paths crossing low-dataregions, leading to highly uncertain predictions. Instead, we proposeaugmenting the hyperbolic metric with a pullback metric to account fordistortions introduced by the LVM's nonlinear mapping and provide a completedevelopment for pullback metrics of Gaussian Process LVMs (GPLVMs). Ourexperiments demonstrate that geodesics on the pullback metric not only respectthe geometry of the hyperbolic latent space but also align with the underlyingdata distribution, significantly reducing uncertainty in predictions.</description><author>Luis Augenstein, Noémie Jaquier, Tamim Asfour, Leonel Rozo</author><pubDate>Mon, 03 Feb 2025 15:36:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20850v2</guid></item><item><title>Scaling Up Membership Inference: When and How Attacks Succeed on Large Language Models</title><link>http://arxiv.org/abs/2411.00154v2</link><description>Membership inference attacks (MIA) attempt to verify the membership of agiven data sample in the training set for a model. MIA has become relevant inrecent years, following the rapid development of large language models (LLM).Many are concerned about the usage of copyrighted materials for training themand call for methods for detecting such usage. However, recent research haslargely concluded that current MIA methods do not work on LLMs. Even when theyseem to work, it is usually because of the ill-designed experimental setupwhere other shortcut features enable "cheating." In this work, we argue thatMIA still works on LLMs, but only when multiple documents are presented fortesting. We construct new benchmarks that measure the MIA performances at acontinuous scale of data samples, from sentences (n-grams) to a collection ofdocuments (multiple chunks of tokens). To validate the efficacy of current MIAapproaches at greater scales, we adapt a recent work on Dataset Inference (DI)for the task of binary membership detection that aggregates paragraph-level MIAfeatures to enable MIA at document and collection of documents level. Thisbaseline achieves the first successful MIA on pre-trained and fine-tuned LLMs.</description><author>Haritz Puerto, Martin Gubri, Sangdoo Yun, Seong Joon Oh</author><pubDate>Mon, 03 Feb 2025 15:33:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.00154v2</guid></item><item><title>Learning Transactions Representations for Information Management in Banks: Mastering Local, Global, and External Knowledge</title><link>http://arxiv.org/abs/2404.02047v3</link><description>In today's world, banks use artificial intelligence to optimize diversebusiness processes, aiming to improve customer experience. Most of thecustomer-related tasks can be categorized into two groups: 1) local ones, whichfocus on a client's current state, such as transaction forecasting, and 2)global ones, which consider the general customer behaviour, e.g., predictingsuccessful loan repayment. Unfortunately, maintaining separate models for eachtask is costly. Therefore, to better facilitate information management, wecompared eight state-of-the-art unsupervised methods on 11 tasks in search fora one-size-fits-all solution. Contrastive self-supervised learning methods weredemonstrated to excel at global problems, while generative techniques weresuperior at local tasks. We also introduced a novel approach, which enrichesthe client's representation by incorporating external information gathered fromother clients. Our method outperforms classical models, boosting accuracy by upto 20\%.</description><author>Alexandra Bazarova, Maria Kovaleva, Ilya Kuleshov, Evgenia Romanenkova, Alexander Stepikin, Alexandr Yugay, Dzhambulat Mollaev, Ivan Kireev, Andrey Savchenko, Alexey Zaytsev</author><pubDate>Mon, 03 Feb 2025 15:33:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02047v3</guid></item><item><title>Machine-Learning-Enhanced Optimization of Noise-Resilient Variational Quantum Eigensolvers</title><link>http://arxiv.org/abs/2501.17689v2</link><description>Variational Quantum Eigensolvers (VQEs) are a powerful class of hybridquantum-classical algorithms designed to approximate the ground state of aquantum system described by its Hamiltonian. VQEs hold promise for variousapplications, including lattice field theory. However, the inherent noise ofNoisy Intermediate-Scale Quantum (NISQ) devices poses a significant challengefor running VQEs as these algorithms are particularly susceptible to noise,e.g., measurement shot noise and hardware noise. In a recent work, it was proposed to enhance the classical optimization ofVQEs with Gaussian Processes (GPs) and Bayesian Optimization, as thesemachine-learning techniques are well-suited for handling noisy data. In theseproceedings, we provide additional insights into this new algorithm and presentfurther numerical experiments. In particular, we examine the impact of hardwarenoise and error mitigation on the algorithm's performance. We validate thealgorithm using classical simulations of quantum hardware, including hardwarenoise benchmarks, which have not been considered in previous works. Ournumerical experiments demonstrate that GP-enhanced algorithms can outperformstate-of-the-art baselines, laying the foundation for future research ondeploying these techniques to real quantum hardware and lattice field theorysetups.</description><author>Kim A. Nicoli, Luca J. Wagner, Lena Funcke</author><pubDate>Mon, 03 Feb 2025 15:30:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17689v2</guid></item><item><title>BLens: Contrastive Captioning of Binary Functions using Ensemble Embedding</title><link>http://arxiv.org/abs/2409.07889v2</link><description>Function names can greatly aid human reverse engineers, which has spurred thedevelopment of machine learning-based approaches to predicting function namesin stripped binaries. Much current work in this area now uses transformers,applying a metaphor of machine translation from code to function names. Still,function naming models face challenges in generalizing to projects unrelated tothe training set. In this paper, we take a completely new approach bytransferring advances in automated image captioning to the domain of binaryreverse engineering, such that different parts of a binary function can beassociated with parts of its name. We propose BLens, which combines multiplebinary function embeddings into a new ensemble representation, aligns it withthe name representation latent space via a contrastive learning approach, andgenerates function names with a transformer architecture tailored for functionnames. Our experiments demonstrate that BLens significantly outperforms thestate of the art. In the usual setting of splitting per binary, we achieve an$F_1$ score of 0.79 compared to 0.70. In the cross-project setting, whichemphasizes generalizability, we achieve an $F_1$ score of 0.46 compared to0.29. Finally, in an experimental setting reducing shared components acrossprojects, we achieve an $F_1$ score of $0.32$ compared to $0.19$.</description><author>Tristan Benoit, Yunru Wang, Moritz Dannehl, Johannes Kinder</author><pubDate>Mon, 03 Feb 2025 15:26:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.07889v2</guid></item><item><title>Iris: Breaking GUI Complexity with Adaptive Focus and Self-Refining</title><link>http://arxiv.org/abs/2412.10342v2</link><description>Digital agents are increasingly employed to automate tasks in interactivedigital environments such as web pages, software applications, and operatingsystems. While text-based agents built on Large Language Models (LLMs) oftenrequire frequent updates due to platform-specific APIs, visual agentsleveraging Multimodal Large Language Models (MLLMs) offer enhanced adaptabilityby interacting directly with Graphical User Interfaces (GUIs). However, theseagents face significant challenges in visual perception, particularly whenhandling high-resolution, visually complex digital environments. This paperintroduces Iris, a foundational visual agent that addresses these challengesthrough two key innovations: Information-Sensitive Cropping (ISC) andSelf-Refining Dual Learning (SRDL). ISC dynamically identifies and prioritizesvisually dense regions using a edge detection algorithm, enabling efficientprocessing by allocating more computational resources to areas with higherinformation density. SRDL enhances the agent's ability to handle complex tasksby leveraging a dual-learning loop, where improvements in referring (describingUI elements) reinforce grounding (locating elements) and vice versa, allwithout requiring additional annotated data. Empirical evaluations demonstratethat Iris achieves state-of-the-art performance across multiple benchmarks withonly 850K GUI annotations, outperforming methods using 10x more training data.These improvements further translate to significant gains in both web and OSagent downstream tasks.</description><author>Zhiqi Ge, Juncheng Li, Xinglei Pang, Minghe Gao, Kaihang Pan, Wang Lin, Hao Fei, Wenqiao Zhang, Siliang Tang, Yueting Zhuang</author><pubDate>Mon, 03 Feb 2025 15:23:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.10342v2</guid></item><item><title>Prithvi-EO-2.0: A Versatile Multi-Temporal Foundation Model for Earth Observation Applications</title><link>http://arxiv.org/abs/2412.02732v2</link><description>This technical report presents Prithvi-EO-2.0, a new geospatial foundationmodel that offers significant improvements over its predecessor,Prithvi-EO-1.0. Trained on 4.2M global time series samples from NASA'sHarmonized Landsat and Sentinel-2 data archive at 30m resolution, the new 300Mand 600M parameter models incorporate temporal and location embeddings forenhanced performance across various geospatial tasks. Through extensivebenchmarking with GEO-Bench, the 600M version outperforms the previousPrithvi-EO model by 8\% across a range of tasks. It also outperforms six othergeospatial foundation models when benchmarked on remote sensing tasks fromdifferent domains and resolutions (i.e. from 0.1m to 15m). The resultsdemonstrate the versatility of the model in both classical earth observationand high-resolution applications. Early involvement of end-users and subjectmatter experts (SMEs) are among the key factors that contributed to theproject's success. In particular, SME involvement allowed for constant feedbackon model and dataset design, as well as successful customization for diverseSME-led applications in disaster response, land use and crop mapping, andecosystem dynamics monitoring. Prithvi-EO-2.0 is available on Hugging Face andIBM terratorch, with additional resources on GitHub. The project exemplifiesthe Trusted Open Science approach embraced by all involved organizations.</description><author>Daniela Szwarcman, Sujit Roy, Paolo Fraccaro, Þorsteinn Elí Gíslason, Benedikt Blumenstiel, Rinki Ghosal, Pedro Henrique de Oliveira, Joao Lucas de Sousa Almeida, Rocco Sedona, Yanghui Kang, Srija Chakraborty, Sizhe Wang, Carlos Gomes, Ankur Kumar, Myscon Truong, Denys Godwin, Hyunho Lee, Chia-Yu Hsu, Ata Akbari Asanjan, Besart Mujeci, Disha Shidham, Trevor Keenan, Paulo Arevalo, Wenwen Li, Hamed Alemohammad, Pontus Olofsson, Christopher Hain, Robert Kennedy, Bianca Zadrozny, David Bell, Gabriele Cavallaro, Campbell Watson, Manil Maskey, Rahul Ramachandran, Juan Bernabe Moreno</author><pubDate>Mon, 03 Feb 2025 15:21:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.02732v2</guid></item><item><title>Applying the maximum entropy principle to neural networks enhances multi-species distribution models</title><link>http://arxiv.org/abs/2412.19217v3</link><description>The rapid expansion of citizen science initiatives has led to a significantgrowth of biodiversity databases, and particularly presence-only (PO)observations. PO data are invaluable for understanding species distributionsand their dynamics, but their use in a Species Distribution Model (SDM) iscurtailed by sampling biases and the lack of information on absences. Poissonpoint processes are widely used for SDMs, with Maxent being one of the mostpopular methods. Maxent maximises the entropy of a probability distributionacross sites as a function of predefined transformations of variables, calledfeatures. In contrast, neural networks and deep learning have emerged as apromising technique for automatic feature extraction from complex inputvariables. Arbitrarily complex transformations of input variables can belearned from the data efficiently through backpropagation and stochasticgradient descent (SGD). In this paper, we propose DeepMaxent, which harnessesneural networks to automatically learn shared features among species, using themaximum entropy principle. To do so, it employs a normalised Poisson loss wherefor each species, presence probabilities across sites are modelled by a neuralnetwork. We evaluate DeepMaxent on a benchmark dataset known for its spatialsampling biases, using PO data for calibration and presence-absence (PA) datafor validation across six regions with different biological groups andcovariates. Our results indicate that DeepMaxent performs better than Maxentand other leading SDMs across all regions and taxonomic groups. The methodperforms particularly well in regions of uneven sampling, demonstratingsubstantial potential to increase SDM performances. In particular, our approachyields more accurate predictions than traditional single-species models, whichopens up new possibilities for methodological enhancement.</description><author>Maxime Ryckewaert, Diego Marcos, Christophe Botella, Maximilien Servajean, Pierre Bonnet, Alexis Joly</author><pubDate>Mon, 03 Feb 2025 15:21:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19217v3</guid></item><item><title>Mitigating Information Loss in Tree-Based Reinforcement Learning via Direct Optimization</title><link>http://arxiv.org/abs/2408.08761v3</link><description>Reinforcement learning (RL) has seen significant success across variousdomains, but its adoption is often limited by the black-box nature of neuralnetwork policies, making them difficult to interpret. In contrast, symbolicpolicies allow representing decision-making strategies in a compact andinterpretable way. However, learning symbolic policies directly withinon-policy methods remains challenging. In this paper, we introduce SYMPOL, anovel method for SYMbolic tree-based on-POLicy RL. SYMPOL employs a tree-basedmodel integrated with a policy gradient method, enabling the agent to learn andadapt its actions while maintaining a high level of interpretability. Weevaluate SYMPOL on a set of benchmark RL tasks, demonstrating its superiorityover alternative tree-based RL approaches in terms of performance andinterpretability. Unlike existing methods, it enables gradient-based,end-to-end learning of interpretable, axis-aligned decision trees withinstandard on-policy RL algorithms. Therefore, SYMPOL can become the foundationfor a new class of interpretable RL based on decision trees.</description><author>Sascha Marton, Tim Grams, Florian Vogt, Stefan Lüdtke, Christian Bartelt, Heiner Stuckenschmidt</author><pubDate>Mon, 03 Feb 2025 15:19:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.08761v3</guid></item><item><title>Disentangling Exploration of Large Language Models by Optimal Exploitation</title><link>http://arxiv.org/abs/2501.08925v2</link><description>Exploration is a crucial skill for self-improvement and open-endedproblem-solving. However, it remains unclear if large language models caneffectively explore the state-space within an unknown environment. This workisolates exploration as the sole objective, tasking the agent with deliveringinformation that enhances future returns. Within this framework, we argue thatmeasuring agent returns is not sufficient for a fair evaluation and decomposemissing rewards into exploration and exploitation components based on theoptimal achievable return. Comprehensive experiments with various models revealthat most struggle to sufficiently explore the state-space and weak explorationis insufficient. We observe a positive correlation between parameter count andexploration performance, with larger models demonstrating superiorcapabilities. Furthermore, we show that our decomposition provides insightsinto differences in behaviors driven by prompt engineering, offering a valuabletool for refining performance in exploratory tasks.</description><author>Tim Grams, Patrick Betz, Christian Bartelt</author><pubDate>Mon, 03 Feb 2025 15:17:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.08925v2</guid></item><item><title>Metareasoning in uncertain environments: a meta-BAMDP framework</title><link>http://arxiv.org/abs/2408.01253v2</link><description>\textit{Reasoning} may be viewed as an algorithm $P$ that makes a choice ofan action $a^* \in \mathcal{A}$, aiming to optimize some outcome. However,executing $P$ itself bears costs (time, energy, limited capacity, etc.) andneeds to be considered alongside explicit utility obtained by making the choicein the underlying decision problem. Finding the right $P$ can itself be framedas an optimization problem over the space of reasoning processes $P$, generallyreferred to as \textit{metareasoning}. Conventionally, human metareasoningmodels assume that the agent knows the transition and reward distributions ofthe underlying MDP. This paper generalizes such models by proposing a metaBayes-Adaptive MDP (meta-BAMDP) framework to handle metareasoning inenvironments with unknown reward/transition distributions, which encompasses afar larger and more realistic set of planning problems that humans and AIsystems face. As a first step, we apply the framework to Bernoulli bandittasks. Owing to the meta problem's complexity, our solutions are necessarilyapproximate. However, we introduce two novel theorems that significantlyenhance the tractability of the problem, enabling stronger approximations thatare robust within a range of assumptions grounded in realistic humandecision-making scenarios. These results offer a resource-rational perspectiveand a normative framework for understanding human exploration under cognitiveconstraints, as well as providing experimentally testable predictions abouthuman behavior in Bernoulli Bandit tasks.</description><author>Prakhar Godara, Tilman Diego Aléman, Angela J. Yu</author><pubDate>Mon, 03 Feb 2025 15:11:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.01253v2</guid></item><item><title>Category-Theoretical and Topos-Theoretical Frameworks in Machine Learning: A Survey</title><link>http://arxiv.org/abs/2408.14014v3</link><description>In this survey, we provide an overview of category theory-derived machinelearning from four mainstream perspectives: gradient-based learning,probability-based learning, invariance and equivalence-based learning, andtopos-based learning. For the first three topics, we primarily review researchin the past five years, updating and expanding on the previous survey byShiebler et al.. The fourth topic, which delves into higher category theory,particularly topos theory, is surveyed for the first time in this paper. Incertain machine learning methods, the compositionality of functors plays avital role, prompting the development of specific categorical frameworks.However, when considering how the global properties of a network reflect inlocal structures and how geometric properties are expressed with logic, thetopos structure becomes particularly significant and profound.</description><author>Yiyang Jia, Guohong Peng, Zheng Yang, Tianhao Chen</author><pubDate>Mon, 03 Feb 2025 15:09:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14014v3</guid></item><item><title>DecTrain: Deciding When to Train a Monocular Depth DNN Online</title><link>http://arxiv.org/abs/2410.02980v2</link><description>Deep neural networks (DNNs) can deteriorate in accuracy when deployment datadiffers from training data. While performing online training at all timestepscan improve accuracy, it is computationally expensive. We propose DecTrain, anew algorithm that decides when to train a monocular depth DNN online usingself-supervision with low overhead. To make the decision at each timestep,DecTrain compares the cost of training with the predicted accuracy gain. Weevaluate DecTrain on out-of-distribution data, and find DecTrain maintainsaccuracy compared to online training at all timesteps, while training only 44%of the time on average. We also compare the recovery of a low inference costDNN using DecTrain and a more generalizable high inference cost DNN on varioussequences. DecTrain recovers the majority (97%) of the accuracy gain of onlinetraining at all timesteps while reducing computation compared to the highinference cost DNN which recovers only 66%. With an even smaller DNN, weachieve 89% recovery while reducing computation by 56%. DecTrain enableslow-cost online training for a smaller DNN to have competitive accuracy with alarger, more generalizable DNN at a lower overall computational cost.</description><author>Zih-Sing Fu, Soumya Sudhakar, Sertac Karaman, Vivienne Sze</author><pubDate>Mon, 03 Feb 2025 15:04:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02980v2</guid></item><item><title>COMPL-AI Framework: A Technical Interpretation and LLM Benchmarking Suite for the EU Artificial Intelligence Act</title><link>http://arxiv.org/abs/2410.07959v2</link><description>The EU's Artificial Intelligence Act (AI Act) is a significant step towardsresponsible AI development, but lacks clear technical interpretation, making itdifficult to assess models' compliance. This work presents COMPL-AI, acomprehensive framework consisting of (i) the first technical interpretation ofthe EU AI Act, translating its broad regulatory requirements into measurabletechnical requirements, with the focus on large language models (LLMs), and(ii) an open-source Act-centered benchmarking suite, based on thoroughsurveying and implementation of state-of-the-art LLM benchmarks. By evaluating12 prominent LLMs in the context of COMPL-AI, we reveal shortcomings inexisting models and benchmarks, particularly in areas like robustness, safety,diversity, and fairness. This work highlights the need for a shift in focustowards these aspects, encouraging balanced development of LLMs and morecomprehensive regulation-aligned benchmarks. Simultaneously, COMPL-AI for thefirst time demonstrates the possibilities and difficulties of bringing theAct's obligations to a more concrete, technical level. As such, our work canserve as a useful first step towards having actionable recommendations formodel providers, and contributes to ongoing efforts of the EU to enableapplication of the Act, such as the drafting of the GPAI Code of Practice.</description><author>Philipp Guldimann, Alexander Spiridonov, Robin Staab, Nikola Jovanović, Mark Vero, Velko Vechev, Anna-Maria Gueorguieva, Mislav Balunović, Nikola Konstantinov, Pavol Bielik, Petar Tsankov, Martin Vechev</author><pubDate>Mon, 03 Feb 2025 14:51:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07959v2</guid></item><item><title>CTBENCH: A Library and Benchmark for Certified Training</title><link>http://arxiv.org/abs/2406.04848v3</link><description>Training certifiably robust neural networks is an important but challengingtask. While many algorithms for (deterministic) certified training have beenproposed, they are often evaluated on different training schedules,certification methods, and systematically under-tuned hyperparameters, makingit difficult to compare their performance. To address this challenge, weintroduce CTBench, a unified library and a high-quality benchmark for certifiedtraining that evaluates all algorithms under fair settings and systematicallytuned hyperparameters. We show that (1) almost all algorithms in CTBenchsurpass the corresponding reported performance in literature in the magnitudeof algorithmic improvements, thus establishing new state-of-the-art, and (2)the claimed advantage of recent algorithms drops significantly when we enhancethe outdated baselines with a fair training schedule, a fair certificationmethod and well-tuned hyperparameters. Based on CTBench, we provide newinsights into the current state of certified training, including (1) certifiedmodels have less fragmented loss surface, (2) certified models share manymistakes, (3) certified models have more sparse activations, (4) reducingregularization cleverly is crucial for certified training especially for largeradii and (5) certified training has the potential to improveout-of-distribution generalization. We are confident that CTBench will serve asa benchmark and testbed for future research in certified training.</description><author>Yuhao Mao, Stefan Balauca, Martin Vechev</author><pubDate>Mon, 03 Feb 2025 14:49:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04848v3</guid></item><item><title>SetPINNs: Set-based Physics-informed Neural Networks</title><link>http://arxiv.org/abs/2409.20206v2</link><description>Physics-Informed Neural Networks (PINNs) solve partial differential equationsusing deep learning. However, conventional PINNs perform pointwise predictionsthat neglect dependencies within a domain, which may result in suboptimalsolutions. We introduce SetPINNs, a framework that effectively captures localdependencies. With a finite element-inspired sampling scheme, we partition adomain into sets to model local dependencies while simultaneously enforcingphysical laws. We provide rigorous theoretical analysis and bounds to show thatSetPINNs provide improved domain coverage over pointwise prediction methods.Extensive experiments across a range of synthetic and real-world tasks showimproved accuracy, efficiency, and robustness.</description><author>Mayank Nagda, Phil Ostheimer, Thomas Specht, Frank Rhein, Fabian Jirasek, Stephan Mandt, Marius Kloft, Sophie Fellenz</author><pubDate>Mon, 03 Feb 2025 14:41:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.20206v2</guid></item><item><title>GIFT: A Framework for Global Interpretable Faithful Textual Explanations of Vision Classifiers</title><link>http://arxiv.org/abs/2411.15605v2</link><description>Understanding deep models is crucial for deploying them in safety-criticalapplications. We introduce GIFT, a framework for deriving post-hoc, global,interpretable, and faithful textual explanations for vision classifiers. GIFTstarts from local faithful visual counterfactual explanations and employs(vision) language models to translate those into global textual explanations.Crucially, GIFT provides a verification stage measuring the causal effect ofthe proposed explanations on the classifier decision. Through experimentsacross diverse datasets, including CLEVR, CelebA, and BDD, we demonstrate thatGIFT effectively reveals meaningful insights, uncovering tasks, concepts, andbiases used by deep vision classifiers. The framework is released athttps://github.com/valeoai/GIFT.</description><author>Éloi Zablocki, Valentin Gerard, Amaia Cardiel, Eric Gaussier, Matthieu Cord, Eduardo Valle</author><pubDate>Mon, 03 Feb 2025 14:36:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.15605v2</guid></item><item><title>Stream-level flow matching with Gaussian processes</title><link>http://arxiv.org/abs/2409.20423v5</link><description>Flow matching (FM) is a family of training algorithms for fitting continuousnormalizing flows (CNFs). Conditional flow matching (CFM) exploits the factthat the marginal vector field of a CNF can be learned by fitting least-squaresregression to the conditional vector field specified given one or both ends ofthe flow path. In this paper, we extend the CFM algorithm by definingconditional probability paths along ``streams'', instances of latent stochasticpaths that connect data pairs of source and target, which are modeled withGaussian process (GP) distributions. The unique distributional properties ofGPs help preserve the ``simulation-free" nature of CFM training. We show thatthis generalization of the CFM can effectively reduce the variance in theestimated marginal vector field at a moderate computational cost, therebyimproving the quality of the generated samples under common metrics.Additionally, adopting the GP on the streams allows for flexibly linkingmultiple correlated training data points (e.g., time series). We empiricallyvalidate our claim through both simulations and applications to image andneural time series data.</description><author>Ganchao Wei, Li Ma</author><pubDate>Mon, 03 Feb 2025 14:31:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.20423v5</guid></item><item><title>Leveraging Multi-facet Paths for Heterogeneous Graph Representation Learning</title><link>http://arxiv.org/abs/2407.20648v2</link><description>Recent advancements in graph neural networks (GNNs) and heterogeneous GNNs(HGNNs) have advanced node embeddings and relationship learning for varioustasks. However, existing methods often rely on domain-specific predefinedmeta-paths, which are coarse-grained and focus solely on aspects like nodetype, limiting their ability to capture complex interactions. We introduceMF2Vec, a model that uses multi-faceted (fine-grained) paths instead ofpredefined meta-paths. MF2Vec extracts paths via random walks and generatesmulti-faceted vectors, ignoring predefined schemas. This method learns diverseaspects of nodes and their relationships, constructs a homogeneous network, andcreates node embeddings for classification, link prediction, and clustering.Extensive experiments show that MF2Vec outperforms existing methods, offering amore flexible and comprehensive framework for analyzing complex networks. Thecode is available at https://anonymous.4open.science/r/MF2Vec-6ABC.</description><author>JongWoo Kim, SeongYeub Chu, HyeongMin Park, Bryan Wong, MunYong Yi</author><pubDate>Mon, 03 Feb 2025 14:26:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20648v2</guid></item><item><title>DocNet: Semantic Structure in Inductive Bias Detection Models</title><link>http://arxiv.org/abs/2406.10965v3</link><description>News will be biased so long as people have opinions. As social media becomesthe primary entry point for news and partisan differences increase, it isincreasingly important for informed citizens to be able to recognize bias. Ifpeople are aware of the biases of the news they consume, they will be able totake action to avoid polarizing echo chambers. In this paper, we explore anoften overlooked aspect of bias detection in media: the semantic structure ofnews articles. We present DocNet, a novel, inductive, and low-resource documentembedding and political bias detection model. We also demonstrate that thesemantic structure of news articles from opposing political sides, asrepresented in document-level graph embeddings, have significant similarities.DocNet bypasses the need for pre-trained language models, reducing resourcedependency while achieving comparable performance. It can be used to advancepolitical bias detection in low-resource environments. Our code and data aremade available at: https://anonymous.4open.science/r/DocNet/</description><author>Jessica Zhu, Iain Cruickshank, Michel Cukier</author><pubDate>Mon, 03 Feb 2025 14:19:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10965v3</guid></item><item><title>ConDiff: A Challenging Dataset for Neural Solvers of Partial Differential Equations</title><link>http://arxiv.org/abs/2406.04709v2</link><description>We present ConDiff, a novel dataset for scientific machine learning. ConDifffocuses on the parametric diffusion equation with space dependent coefficients,a fundamental problem in many applications of partial differential equations(PDEs). The main novelty of the proposed dataset is that we considerdiscontinuous coefficients with high contrast. These coefficient functions aresampled from a selected set of distributions. This class of problems is notonly of great academic interest, but is also the basis for describing variousenvironmental and industrial problems. In this way, ConDiff shortens the gapwith real-world problems while remaining fully synthetic and easy to use.ConDiff consists of a diverse set of diffusion equations with coefficientscovering a wide range of contrast levels and heterogeneity with a measurablecomplexity metric for clearer comparison between different coefficientfunctions. We baseline ConDiff on standard deep learning models in the field ofscientific machine learning. By providing a large number of problem instances,each with its own coefficient function and right-hand side, we hope toencourage the development of novel physics-based deep learning approaches, suchas neural operators, ultimately driving progress towards more accurate andefficient solutions of complex PDE problems.</description><author>Vladislav Trifonov, Alexander Rudikov, Oleg Iliev, Yuri M. Laevsky, Ivan Oseledets, Ekaterina Muravleva</author><pubDate>Mon, 03 Feb 2025 14:09:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04709v2</guid></item><item><title>Improving the Robustness of Representation Misdirection for Large Language Model Unlearning</title><link>http://arxiv.org/abs/2501.19202v2</link><description>Representation Misdirection (RM) and variants are established large languagemodel (LLM) unlearning methods with state-of-the-art performance. In thispaper, we show that RM methods inherently reduce models' robustness, causingthem to misbehave even when a single non-adversarial forget-token is in theretain-query. Toward understanding underlying causes, we reframe the unlearningprocess as backdoor attacks and defenses: forget-tokens act as backdoortriggers that, when activated in retain-queries, cause disruptions in RMmodels' behaviors, similar to successful backdoor attacks. To mitigate thisvulnerability, we propose Random Noise Augmentation -- a model and methodagnostic approach with theoretical guarantees for improving the robustness ofRM methods. Extensive experiments demonstrate that RNA significantly improvesthe robustness of RM models while enhancing the unlearning performances.</description><author>Dang Huu-Tien, Hoang Thanh-Tung, Le-Minh Nguyen, Naoya Inoue</author><pubDate>Mon, 03 Feb 2025 14:05:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.19202v2</guid></item><item><title>Flow Matching: Markov Kernels, Stochastic Processes and Transport Plans</title><link>http://arxiv.org/abs/2501.16839v2</link><description>Among generative neural models, flow matching techniques stand out for theirsimple applicability and good scaling properties. Here, velocity fields ofcurves connecting a simple latent and a target distribution are learned. Thenthe corresponding ordinary differential equation can be used to sample from atarget distribution, starting in samples from the latent one. This paperreviews from a mathematical point of view different techniques to learn thevelocity fields of absolutely continuous curves in the Wasserstein geometry. Weshow how the velocity fields can be characterized and learned via i) transportplans (couplings) between latent and target distributions, ii) Markov kernelsand iii) stochastic processes, where the latter two include the couplingapproach, but are in general broader. Besides this main goal, we show how flowmatching can be used for solving Bayesian inverse problems, where thedefinition of conditional Wasserstein distances plays a central role. Finally,we briefly address continuous normalizing flows and score matching techniques,which approach the learning of velocity fields of curves from other directions.</description><author>Christian Wald, Gabriele Steidl</author><pubDate>Mon, 03 Feb 2025 14:03:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16839v2</guid></item><item><title>Rethinking Explainable Machine Learning as Applied Statistics</title><link>http://arxiv.org/abs/2402.02870v3</link><description>In the rapidly growing literature on explanation algorithms, it often remainsunclear what precisely these algorithms are for and how they should be used. Inthis position paper, we argue for a novel and pragmatic perspective:Explainable machine learning needs to recognize its parallels with appliedstatistics. Concretely, explanations are statistics of high-dimensionalfunctions, and we should think about them analogously to traditionalstatistical quantities. Among others, this implies that we must think carefullyabout the matter of interpretation, or how the explanations relate to intuitivequestions that humans have about the world. The fact that this is scarcelybeing discussed in research papers is one of the main drawbacks of the currentliterature. Luckily, the analogy between explainable machine learning andapplied statistics suggests fruitful ways for how research practices can beimproved.</description><author>Sebastian Bordt, Eric Raidl, Ulrike von Luxburg</author><pubDate>Mon, 03 Feb 2025 14:03:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02870v3</guid></item><item><title>Energy-Guided Continuous Entropic Barycenter Estimation for General Costs</title><link>http://arxiv.org/abs/2310.01105v4</link><description>Optimal transport (OT) barycenters are a mathematically grounded way ofaveraging probability distributions while capturing their geometric properties.In short, the barycenter task is to take the average of a collection ofprobability distributions w.r.t. given OT discrepancies. We propose a novelalgorithm for approximating the continuous Entropic OT (EOT) barycenter forarbitrary OT cost functions. Our approach is built upon the dual reformulationof the EOT problem based on weak OT, which has recently gained the attention ofthe ML community. Beyond its novelty, our method enjoys several advantageousproperties: (i) we establish quality bounds for the recovered solution; (ii)this approach seamlessly interconnects with the Energy-Based Models (EBMs)learning procedure enabling the use of well-tuned algorithms for the problem ofinterest; (iii) it provides an intuitive optimization scheme avoiding min-max,reinforce and other intricate technical tricks. For validation, we considerseveral low-dimensional scenarios and image-space setups, includingnon-Euclidean cost functions. Furthermore, we investigate the practical task oflearning the barycenter on an image manifold generated by a pretrainedgenerative model, opening up new directions for real-world applications. Ourcode is available at https://github.com/justkolesov/EnergyGuidedBarycenters.</description><author>Alexander Kolesov, Petr Mokrov, Igor Udovichenko, Milena Gazdieva, Gudmund Pammer, Anastasis Kratsios, Evgeny Burnaev, Alexander Korotin</author><pubDate>Mon, 03 Feb 2025 13:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01105v4</guid></item><item><title>RILe: Reinforced Imitation Learning</title><link>http://arxiv.org/abs/2406.08472v3</link><description>Acquiring complex behaviors is essential for artificially intelligent agents,yet learning these behaviors in high-dimensional settings poses a significantchallenge due to the vast search space. Traditional reinforcement learning (RL)requires extensive manual effort for reward function engineering. Inversereinforcement learning (IRL) uncovers reward functions from expertdemonstrations but relies on an iterative process that is often computationallyexpensive. Imitation learning (IL) provides a more efficient alternative bydirectly comparing an agent's actions to expert demonstrations; however, inhigh-dimensional environments, such direct comparisons offer insufficientfeedback for effective learning. We introduce RILe (Reinforced ImitationLearning), a framework that combines the strengths of imitation learning andinverse reinforcement learning to learn a dense reward function efficiently andachieve strong performance in high-dimensional tasks. RILe employs a noveltrainer-student framework: the trainer learns an adaptive reward function, andthe student uses this reward signal to imitate expert behaviors. By dynamicallyadjusting its guidance as the student evolves, the trainer provides nuancedfeedback across different phases of learning. Our framework produceshigh-performing policies in high-dimensional tasks where direct imitation failsto replicate complex behaviors. We validate RILe in challenging roboticlocomotion tasks, demonstrating that it significantly outperforms existingmethods and achieves near-expert performance across multiple settings.</description><author>Mert Albaba, Sammy Christen, Thomas Langarek, Christoph Gebhardt, Otmar Hilliges, Michael J. Black</author><pubDate>Mon, 03 Feb 2025 13:57:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.08472v3</guid></item><item><title>Learning from Linear Algebra: A Graph Neural Network Approach to Preconditioner Design for Conjugate Gradient Solvers</title><link>http://arxiv.org/abs/2405.15557v3</link><description>Large linear systems are ubiquitous in modern computational science andengineering. The main recipe for solving them is the use of Krylov subspaceiterative methods with well-designed preconditioners. Recently, GNNs have beenshown to be a promising tool for designing preconditioners to reduce theoverall computational cost of iterative methods by constructing them moreefficiently than with classical linear algebra techniques. Preconditionersdesigned with these approaches cannot outperform those designed with classicalmethods in terms of the number of iterations in CG. In our work, we recallwell-established preconditioners from linear algebra and use them as a startingpoint for training the GNN to obtain preconditioners that reduce the conditionnumber of the system more significantly than classical preconditioners.Numerical experiments show that our approach outperforms both classical andneural network-based methods for an important class of parametric partialdifferential equations. We also provide a heuristic justification for the lossfunction used and show that preconditioners obtained by learning with this lossfunction reduce the condition number in a more desirable way for CG.</description><author>Vladislav Trifonov, Alexander Rudikov, Oleg Iliev, Yuri M. Laevsky, Ivan Oseledets, Ekaterina Muravleva</author><pubDate>Mon, 03 Feb 2025 13:54:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15557v3</guid></item><item><title>Single-neuron deep generative model uncovers underlying physics of neuronal activity in Ca imaging data</title><link>http://arxiv.org/abs/2501.14615v2</link><description>Calcium imaging has become a powerful alternative to electrophysiology forstudying neuronal activity, offering spatial resolution and the ability tomeasure large populations of neurons in a minimally invasive manner. Thistechnique has broad applications in neuroscience, neuroengineering, andmedicine, enabling researchers to explore the relationship between neuronlocation and activity. Recent advancements in deep generative models (DGMs)have facilitated the modeling of neuronal population dynamics, uncoveringlatent representations that provide insights into behavior prediction andneuronal variance. However, these models often rely on spike inferencealgorithms and primarily focus on population-level dynamics, limiting theirapplicability for single-neuron analyses. To address this gap, we propose anovel framework for single-neuron representation learning using autoregressivevariational autoencoders (AVAEs). Our approach embeds individual neurons'spatiotemporal signals into a reduced-dimensional space without the need forspike inference algorithms. The AVAE excels over traditional linear methods bygenerating more informative and discriminative latent representations,improving tasks such as visualization, clustering, and the understanding ofneuronal activity. Additionally, the reconstruction performance of the AVAEoutperforms the state of the art, demonstrating its ability to accuratelyrecover the original fluorescence signal from the learned representation. Usingrealistic simulations, we show that our model captures underlying physicalproperties and connectivity patterns, enabling it to distinguish betweendifferent firing and connectivity types. These findings position the AVAE as aversatile and powerful tool for advancing single-neuron analysis and lays thegroundwork for future integration of multimodal single-cell datasets inneuroscience.</description><author>Jordi Abante, Angelo Piga, Berta Ros, Clara F López-León, Josep M Canals, Jordi Soriano</author><pubDate>Mon, 03 Feb 2025 13:46:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14615v2</guid></item><item><title>Inverse Entropic Optimal Transport Solves Semi-supervised Learning via Data Likelihood Maximization</title><link>http://arxiv.org/abs/2410.02628v2</link><description>Learning conditional distributions $\pi^*(\cdot|x)$ is a central problem inmachine learning, which is typically approached via supervised methods withpaired data $(x,y) \sim \pi^*$. However, acquiring paired data samples is oftenchallenging, especially in problems such as domain translation. Thisnecessitates the development of $\textit{semi-supervised}$ models that utilizeboth limited paired data and additional unpaired i.i.d. samples $x \sim\pi^*_x$ and $y \sim \pi^*_y$ from the marginal distributions. The usage ofsuch combined data is complex and often relies on heuristic approaches. Totackle this issue, we propose a new learning paradigm that integrates bothpaired and unpaired data $\textbf{seamlessly}$ through the data likelihoodmaximization techniques. We demonstrate that our approach also connectsintriguingly with inverse entropic optimal transport (OT). This finding allowsus to apply recent advances in computational OT to establish a $\textbf{light}$learning algorithm to get $\pi^*(\cdot|x)$. Furthermore, we demonstrate throughempirical tests that our method effectively learns conditional distributionsusing paired and unpaired data simultaneously.</description><author>Mikhail Persiianov, Arip Asadulaev, Nikita Andreev, Nikita Starodubcev, Dmitry Baranchuk, Anastasis Kratsios, Evgeny Burnaev, Alexander Korotin</author><pubDate>Mon, 03 Feb 2025 13:45:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02628v2</guid></item><item><title>Reflective Gaussian Splatting</title><link>http://arxiv.org/abs/2412.19282v2</link><description>Novel view synthesis has experienced significant advancements owing toincreasingly capable NeRF- and 3DGS-based methods. However, reflective objectreconstruction remains challenging, lacking a proper solution to achievereal-time, high-quality rendering while accommodating inter-reflection. To fillthis gap, we introduce a Reflective Gaussian splatting (Ref-Gaussian) frameworkcharacterized with two components: (I) Physically based deferred rendering thatempowers the rendering equation with pixel-level material properties viaformulating split-sum approximation; (II) Gaussian-grounded inter-reflectionthat realizes the desired inter-reflection function within a Gaussian splattingparadigm for the first time. To enhance geometry modeling, we further introducematerial-aware normal propagation and an initial per-Gaussian shading stage,along with 2D Gaussian primitives. Extensive experiments on standard datasetsdemonstrate that Ref-Gaussian surpasses existing approaches in terms ofquantitative metrics, visual quality, and compute efficiency. Further, we showthat our method serves as a unified solution for both reflective andnon-reflective scenes, going beyond the previous alternatives focusing on onlyreflective scenes. Also, we illustrate that Ref-Gaussian supports moreapplications such as relighting and editing.</description><author>Yuxuan Yao, Zixuan Zeng, Chun Gu, Xiatian Zhu, Li Zhang</author><pubDate>Mon, 03 Feb 2025 13:34:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.19282v2</guid></item><item><title>Conformal Prediction for Hierarchical Data</title><link>http://arxiv.org/abs/2411.13479v2</link><description>We consider conformal prediction of multivariate data series, which consistsof outputting prediction regions based on empirical quantiles of point-estimateerrors. We actually consider hierarchical multivariate data series, for whichsome components are linear combinations of others. The intuition is that thehierarchical structure may be leveraged to improve the prediction regions interms of their sizes for given coverage levels. We implement this intuition byincluding a projection step (also called reconciliation step) in the splitconformal prediction [SCP] procedure and prove that the resulting predictionregions are indeed globally smaller than without the projection step. Theassociated strategies and their analyses rely on the literatures of both SCPand forecast reconciliation. We also illustrate the theoretical findings, bothon artificial and on real data.</description><author>Guillaume Principato, Gilles Stoltz, Yvenn Amara-Ouali, Yannig Goude, Bachir Hamrouche, Jean-Michel Poggi</author><pubDate>Mon, 03 Feb 2025 13:16:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13479v2</guid></item><item><title>EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics</title><link>http://arxiv.org/abs/2408.08782v4</link><description>Designing emotionally intelligent conversational systems to provide comfortand advice to people experiencing distress is a compelling area of research.Recently, with advancements in large language models (LLMs), end-to-enddialogue agents without explicit strategy prediction steps have becomeprevalent. However, implicit strategy planning lacks transparency, and recentstudies show that LLMs' inherent preference bias towards certainsocio-emotional strategies hinders the delivery of high-quality emotionalsupport. To address this challenge, we propose decoupling strategy predictionfrom language generation, and introduce a novel dialogue strategy predictionframework, EmoDynamiX, which models the discourse dynamics between userfine-grained emotions and system strategies using a heterogeneous graph forbetter performance and transparency. Experimental results on two ESC datasetsshow EmoDynamiX outperforms previous state-of-the-art methods with asignificant margin (better proficiency and lower preference bias). Our approachalso exhibits better transparency by allowing backtracing of decision making.</description><author>Chenwei Wan, Matthieu Labeau, Chloé Clavel</author><pubDate>Mon, 03 Feb 2025 13:13:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.08782v4</guid></item><item><title>Mixture of Knowledge Minigraph Agents for Literature Review Generation</title><link>http://arxiv.org/abs/2411.06159v3</link><description>Literature reviews play a crucial role in scientific research forunderstanding the current state of research, identifying gaps, and guidingfuture studies on specific topics. However, the process of conducting acomprehensive literature review is yet time-consuming. This paper proposes anovel framework, collaborative knowledge minigraph agents (CKMAs), to automatescholarly literature reviews. A novel prompt-based algorithm, the knowledgeminigraph construction agent (KMCA), is designed to identify relations betweenconcepts from academic literature and automatically constructs knowledgeminigraphs. By leveraging the capabilities of large language models onconstructed knowledge minigraphs, the multiple path summarization agent (MPSA)efficiently organizes concepts and relations from different viewpoints togenerate literature review paragraphs. We evaluate CKMAs on three benchmarkdatasets. Experimental results show the effectiveness of the proposed method,further revealing promising applications of LLMs in scientific research.</description><author>Zhi Zhang, Yan Liu, Sheng-hua Zhong, Gong Chen, Yu Yang, Jiannong Cao</author><pubDate>Mon, 03 Feb 2025 13:11:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.06159v3</guid></item><item><title>Clarify Confused Nodes via Separated Learning</title><link>http://arxiv.org/abs/2306.02285v6</link><description>Graph neural networks (GNNs) have achieved remarkable advances ingraph-oriented tasks. However, real-world graphs invariably contain a certainproportion of heterophilous nodes, challenging the homophily assumption oftraditional GNNs and hindering their performance. Most existing studiescontinue to design generic models with shared weights between heterophilous andhomophilous nodes. Despite the incorporation of high-order messages ormulti-channel architectures, these efforts often fall short. A minority ofstudies attempt to train different node groups separately but suffer frominappropriate separation metrics and low efficiency. In this paper, we firstpropose a new metric, termed Neighborhood Confusion (NC), to facilitate a morereliable separation of nodes. We observe that node groups with different levelsof NC values exhibit certain differences in intra-group accuracy and visualizedembeddings. These pave the way for Neighborhood Confusion-guided GraphConvolutional Network (NCGCN), in which nodes are grouped by their NC valuesand accept intra-group weight sharing and message passing. Extensiveexperiments on both homophilous and heterophilous benchmarks demonstrate thatour framework can effectively separate nodes and yield significant performanceimprovement compared to the latest methods. The source code will be availablein https://github.com/GISec-Team/NCGNN.</description><author>Jiajun Zhou, Shengbo Gong, Xuanze Chen, Chenxuan Xie, Shanqing Yu, Qi Xuan, Xiaoniu Yang</author><pubDate>Mon, 03 Feb 2025 13:06:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02285v6</guid></item><item><title>A Unified Comparative Study with Generalized Conformity Scores for Multi-Output Conformal Regression</title><link>http://arxiv.org/abs/2501.10533v2</link><description>Conformal prediction provides a powerful framework for constructingdistribution-free prediction regions with finite-sample coverage guarantees.While extensively studied in univariate settings, its extension to multi-outputproblems presents additional challenges, including complex output dependenciesand high computational costs, and remains relatively underexplored. In thiswork, we present a unified comparative study of nine conformal methods withdifferent multivariate base models for constructing multivariate predictionregions within the same framework. This study highlights their key propertieswhile also exploring the connections between them. Additionally, we introducetwo novel classes of conformity scores for multi-output regression thatgeneralize their univariate counterparts. These scores ensure asymptoticconditional coverage while maintaining exact finite-sample marginal coverage.One class is compatible with any generative model, offering broadapplicability, while the other is computationally efficient, leveraging theproperties of invertible generative models. Finally, we conduct a comprehensiveempirical evaluation across 13 tabular datasets, comparing all the multi-outputconformal methods explored in this work. To ensure a fair and consistentcomparison, all methods are implemented within a unified code base.</description><author>Victor Dheur, Matteo Fontana, Yorick Estievenart, Naomi Desobry, Souhaib Ben Taieb</author><pubDate>Mon, 03 Feb 2025 12:58:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10533v2</guid></item><item><title>Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature</title><link>http://arxiv.org/abs/2410.10537v2</link><description>This study introduces a novel methodology for voice pathology detection usingthe publicly available Saarbr\"ucken Voice Database (SVD) database and a robustfeature set combining commonly used acoustic handcrafted features with twonovel ones: pitch difference (relative variation in fundamental frequency) anda NaN feature (failed fundamental frequency estimation). We evaluate six machine learning (ML) classifiers - support vector machine,k-nearest neighbors, naive Bayes, decision tree, random forest, and AdaBoost -using grid search for feasible hyperparameters of selected classifiers and20480 different feature subsets. Top 1000 classifier-feature subsetcombinations for each classifier type are validated with repeated stratifiedcross-validation. To address class imbalance, we apply K-Means SMOTE to augmentthe training data. Our approach achieves outstanding performance, reaching 85.61%, 84.69% and85.22% unweighted average recall (UAR) for females, males and combined resultsrespectivelly. We intentionally omit accuracy as it is a highly biased metricfor imbalanced data. This advancement demonstrates significant potential forclinical deployment of ML methods, offering a valuable supportive tool for anobjective examination of voice pathologies. To enable an easier use of ourmethodology and to support our claims, we provide a publicly available GitHubrepository with DOI 10.5281/zenodo.13771573. Finally, we provide a REFORMSchecklist to enhance readability, reproducibility and justification of ourapproach.</description><author>Jan Vrba, Jakub Steinbach, Tomáš Jirsa, Laura Verde, Roberta De Fazio, Yuwen Zeng, Kei Ichiji, Lukáš Hájek, Zuzana Sedláková, Zuzana Urbániová, Martin Chovanec, Jan Mareš, Noriyasu Homma</author><pubDate>Mon, 03 Feb 2025 12:57:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10537v2</guid></item><item><title>Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool Usage</title><link>http://arxiv.org/abs/2412.15606v2</link><description>The advancement of large language models (LLMs) prompts the development ofmulti-modal agents, which are used as a controller to call external tools,providing a feasible way to solve practical tasks. In this paper, we propose amulti-modal agent tuning method that automatically generates multi-modaltool-usage data and tunes a vision-language model (VLM) as the controller forpowerful tool-usage reasoning. To preserve the data quality, we prompt theGPT-4o mini model to generate queries, files, and trajectories, followed byquery-file and trajectory verifiers. Based on the data synthesis pipeline, wecollect the MM-Traj dataset that contains 20K tasks with trajectories of toolusage. Then, we develop the T3-Agent via \underline{T}rajectory\underline{T}uning on VLMs for \underline{T}ool usage using MM-Traj.Evaluations on the GTA and GAIA benchmarks show that the T3-Agent consistentlyachieves improvements on two popular VLMs: MiniCPM-V-8.5B and {Qwen2-VL-7B},which outperforms untrained VLMs by $20\%$, showing the effectiveness of theproposed data synthesis pipeline, leading to high-quality data for tool-usagecapabilities.</description><author>Zhi Gao, Bofei Zhang, Pengxiang Li, Xiaojian Ma, Tao Yuan, Yue Fan, Yuwei Wu, Yunde Jia, Song-Chun Zhu, Qing Li</author><pubDate>Mon, 03 Feb 2025 12:56:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15606v2</guid></item><item><title>AI-Assisted Generation of Difficult Math Questions</title><link>http://arxiv.org/abs/2407.21009v4</link><description>Current LLM training positions mathematical reasoning as a core capability.With publicly available sources fully tapped, there is unmet demand for diverseand challenging math questions. Relying solely on human experts is bothtime-consuming and costly, while LLM-generated questions often lack therequisite diversity and difficulty. We present a design framework that combinesthe strengths of LLMs with a human-in-the-loop approach to generate a diversearray of challenging math questions. We leverage LLM metacognition skills[Didolkar et al., 2024] of a strong LLM to extract core "skills" from existingmath datasets. These skills serve as the basis for generating novel anddifficult questions by prompting the LLM with random pairs of core skills. Theuse of two different skills within each question makes finding such questionsan "out of distribution" task for both LLMs and humans. Our pipeline employsLLMs to iteratively generate and refine questions and solutions throughmultiturn prompting. Human annotators then verify and further refine thequestions, with their efficiency enhanced via further LLM interactions.Applying this pipeline on skills extracted from the MATH dataset [Hendrycks etal., 2021] resulted in MATH$^2$ - a dataset of higher-quality math questions,as evidenced by: (a) Lower performance of all models on MATH$^2$ than on MATH(b) Higher performance on MATH when using MATH$^2$ questions as in-contextexamples. Although focused on mathematics, our methodology seems applicable toother domains requiring structured reasoning, and potentially as a component ofscalable oversight. Also of interest is a striking relationship observedbetween models' performance on the new dataset: the success rate on MATH$^2$ isthe square on MATH, suggesting that successfully solving the question inMATH$^2$ requires a nontrivial combination of two distinct math skills.</description><author>Vedant Shah, Dingli Yu, Kaifeng Lyu, Simon Park, Jiatong Yu, Yinghui He, Nan Rosemary Ke, Michael Mozer, Yoshua Bengio, Sanjeev Arora, Anirudh Goyal</author><pubDate>Mon, 03 Feb 2025 12:53:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21009v4</guid></item><item><title>The Russian-focused embedders' exploration: ruMTEB benchmark and Russian embedding model design</title><link>http://arxiv.org/abs/2408.12503v2</link><description>Embedding models play a crucial role in Natural Language Processing (NLP) bycreating text embeddings used in various tasks such as information retrievaland assessing semantic text similarity. This paper focuses on research relatedto embedding models in the Russian language. It introduces a newRussian-focused embedding model called ru-en-RoSBERTa and the ruMTEB benchmark,the Russian version extending the Massive Text Embedding Benchmark (MTEB). Ourbenchmark includes seven categories of tasks, such as semantic textualsimilarity, text classification, reranking, and retrieval.The research alsoassesses a representative set of Russian and multilingual models on theproposed benchmark. The findings indicate that the new model achieves resultsthat are on par with state-of-the-art models in Russian. We release the modelru-en-RoSBERTa, and the ruMTEB framework comes with open-source code,integration into the original framework and a public leaderboard.</description><author>Artem Snegirev, Maria Tikhonova, Anna Maksimova, Alena Fenogenova, Alexander Abramov</author><pubDate>Mon, 03 Feb 2025 12:53:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12503v2</guid></item><item><title>Learning Fairer Representations with FairVIC</title><link>http://arxiv.org/abs/2404.18134v2</link><description>Mitigating bias in automated decision-making systems, particularly in deeplearning models, is a critical challenge due to nuanced definitions offairness, dataset-specific biases, and the inherent trade-off between fairnessand accuracy. To address these issues, we introduce FairVIC, an innovativeapproach that enhances fairness in neural networks by integrating variance,invariance, and covariance terms into the loss function during training. Unlikemethods that rely on predefined fairness criteria, FairVIC abstracts fairnessconcepts to minimise dependency on protected characteristics. We evaluateFairVIC against comparable bias mitigation techniques on benchmark datasets,considering both group and individual fairness, and conduct an ablation studyon the accuracy-fairness trade-off. FairVIC demonstrates significantimprovements ($\approx70\%$) in fairness across all tested metrics withoutcompromising accuracy, thus offering a robust, generalisable solution for fairdeep learning across diverse tasks and datasets.</description><author>Charmaine Barker, Daniel Bethell, Dimitar Kazakov</author><pubDate>Mon, 03 Feb 2025 12:49:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.18134v2</guid></item><item><title>Robust Hyperbolic Learning with Curvature-Aware Optimization</title><link>http://arxiv.org/abs/2405.13979v3</link><description>Hyperbolic deep learning has become a growing research direction in computervision due to the unique properties afforded by the alternate embedding space.The negative curvature and exponentially growing distance metric provide anatural framework for capturing hierarchical relationships between datapointsand allowing for finer separability between their embeddings. However, currenthyperbolic learning approaches are still prone to overfitting, computationallyexpensive, and prone to instability, especially when attempting to learn themanifold curvature to adapt to tasks and different datasets. To address theseissues, our paper presents a derivation for Riemannian AdamW that helpsincrease hyperbolic generalization ability. For improved stability, weintroduce a novel fine-tunable hyperbolic scaling approach to constrainhyperbolic embeddings and reduce approximation errors. Using this along withour curvature-aware learning schema for Lorentzian Optimizers enables thecombination of curvature and non-trivialized hyperbolic parameter learning. Ourapproach demonstrates consistent performance improvements across ComputerVision, EEG classification, and hierarchical metric learning tasks achievingstate-of-the-art results in two domains and drastically reducing runtime.</description><author>Ahmad Bdeir, Johannes Burchert, Lars Schmidt-Thieme, Niels Landwehr</author><pubDate>Mon, 03 Feb 2025 12:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13979v3</guid></item><item><title>PostEdit: Posterior Sampling for Efficient Zero-Shot Image Editing</title><link>http://arxiv.org/abs/2410.04844v2</link><description>In the field of image editing, three core challenges persist:controllability, background preservation, and efficiency. Inversion-basedmethods rely on time-consuming optimization to preserve the features of theinitial images, which results in low efficiency due to the requirement forextensive network inference. Conversely, inversion-free methods lacktheoretical support for background similarity, as they circumvent the issue ofmaintaining initial features to achieve efficiency. As a consequence, none ofthese methods can achieve both high efficiency and background consistency. Totackle the challenges and the aforementioned disadvantages, we introducePostEdit, a method that incorporates a posterior scheme to govern the diffusionsampling process. Specifically, a corresponding measurement term related toboth the initial features and Langevin dynamics is introduced to optimize theestimated image generated by the given target prompt. Extensive experimentalresults indicate that the proposed PostEdit achieves state-of-the-art editingperformance while accurately preserving unedited regions. Furthermore, themethod is both inversion- and training-free, necessitating approximately 1.5seconds and 18 GB of GPU memory to generate high-quality results.</description><author>Feng Tian, Yixuan Li, Yichao Yan, Shanyan Guan, Yanhao Ge, Xiaokang Yang</author><pubDate>Mon, 03 Feb 2025 12:33:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.04844v2</guid></item><item><title>Jacobian Descent for Multi-Objective Optimization</title><link>http://arxiv.org/abs/2406.16232v3</link><description>Many optimization problems require balancing multiple conflicting objectives.As gradient descent is limited to single-objective optimization, we introduceits direct generalization: Jacobian descent (JD). This algorithm iterativelyupdates parameters using the Jacobian matrix of a vector-valued objectivefunction, in which each row is the gradient of an individual objective. Whileseveral methods to combine gradients already exist in the literature, they aregenerally hindered when the objectives conflict. In contrast, we proposeprojecting gradients to fully resolve conflict while ensuring that theypreserve an influence proportional to their norm. We prove significantlystronger convergence guarantees with this approach, supported by our empiricalresults. Our method also enables instance-wise risk minimization (IWRM), anovel learning paradigm in which the loss of each training example isconsidered a separate objective. Applied to simple image classification tasks,IWRM exhibits promising results compared to the direct minimization of theaverage loss. Additionally, we outline an efficient implementation of JD usingthe Gramian of the Jacobian matrix to reduce time and memory requirements.</description><author>Pierre Quinton, Valérian Rey</author><pubDate>Mon, 03 Feb 2025 12:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16232v3</guid></item><item><title>JoVALE: Detecting Human Actions in Video Using Audiovisual and Language Contexts</title><link>http://arxiv.org/abs/2412.13708v2</link><description>Video Action Detection (VAD) entails localizing and categorizing actioninstances within videos, which inherently consist of diverse informationsources such as audio, visual cues, and surrounding scene contexts. Leveragingthis multi-modal information effectively for VAD poses a significant challenge,as the model must identify action-relevant cues with precision. In this study,we introduce a novel multi-modal VAD architecture, referred to as the JointActor-centric Visual, Audio, Language Encoder (JoVALE). JoVALE is the first VADmethod to integrate audio and visual features with scene descriptive contextsourced from large-capacity image captioning models. At the heart of JoVALE isthe actor-centric aggregation of audio, visual, and scene descriptiveinformation, enabling adaptive integration of crucial features for recognizingeach actor's actions. We have developed a Transformer-based architecture, theActor-centric Multi-modal Fusion Network, specifically designed to capture thedynamic interactions among actors and their multi-modal contexts. Ourevaluation on three prominent VAD benchmarks, including AVA, UCF101-24, andJHMDB51-21, demonstrates that incorporating multi-modal informationsignificantly enhances performance, setting new state-of-the-art performancesin the field.</description><author>Taein Son, Soo Won Seo, Jisong Kim, Seok Hwan Lee, Jun Won Choi</author><pubDate>Mon, 03 Feb 2025 12:27:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13708v2</guid></item><item><title>Unified Breakdown Analysis for Byzantine Robust Gossip</title><link>http://arxiv.org/abs/2410.10418v2</link><description>In decentralized machine learning, different devices communicate in apeer-to-peer manner to collaboratively learn from each other's data. Suchapproaches are vulnerable to misbehaving (or Byzantine) devices. We introduce$\mathrm{F}\text{-}\rm RG$, a general framework for building robustdecentralized algorithms with guarantees arising from robust-sum-likeaggregation rules $\mathrm{F}$. We then investigate the notion of *breakdownpoint*, and show an upper bound on the number of adversaries that decentralizedalgorithms can tolerate. We introduce a practical robust aggregation rule,coined $\rm CS_{ours}$, such that $\rm CS_{ours}\text{-}RG$ has a near-optimalbreakdown. Other choices of aggregation rules lead to existing algorithms suchas $\rm ClippedGossip$ or $\rm NNA$. We give experimental evidence to validatethe effectiveness of $\rm CS_{ours}\text{-}RG$ and highlight the gap with$\mathrm{NNA}$, in particular against a novel attack tailored to decentralizedcommunications.</description><author>Renaud Gaucher, Aymeric Dieuleveut, Hadrien Hendrikx</author><pubDate>Mon, 03 Feb 2025 12:16:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10418v2</guid></item><item><title>Contrast-Aware Calibration for Fine-Tuned CLIP: Leveraging Image-Text Alignment</title><link>http://arxiv.org/abs/2501.19060v2</link><description>Vision-language models (VLMs), such as CLIP, have demonstrated exceptionalgeneralization capabilities and can quickly adapt to downstream tasks throughprompt fine-tuning. Unfortunately, in classification tasks involvingnon-training classes, known as open-vocabulary setting, fine-tuned VLMs oftenoverfit to train classes, resulting in a misalignment between confidence scoresand actual accuracy on unseen classes, which significantly undermines theirreliability in real-world deployments. Existing confidence calibration methodstypically require training parameters or analyzing features from the trainingdataset, restricting their ability to generalize unseen classes withoutcorresponding train data. Moreover, VLM-specific calibration methods relysolely on text features from train classes as calibration indicators, whichinherently limits their ability to calibrate train classes. To address thesechallenges, we propose an effective multimodal calibration methodContrast-Aware Calibration (CAC). Building on the original CLIP's zero-shotadaptability and the conclusion from empirical analysis that poor intra-classand inter-class discriminative ability on unseen classes is the root cause, wecalculate calibration weights based on the contrastive difference between theoriginal and fine-tuned CLIP. This method not only adapts to calibrating unseenclasses but also overcomes the limitations of previous VLM calibration methodsthat could not calibrate train classes. In experiments involving 11 datasetswith 5 fine-tuning methods, CAC consistently achieved the best calibrationeffect on both train and unseen classes without sacrificing accuracy andinference speed.</description><author>Song-Lin Lv, Yu-Yang Chen, Zhi Zhou, Yu-Feng Li, Lan-Zhe Guo</author><pubDate>Mon, 03 Feb 2025 12:12:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.19060v2</guid></item><item><title>Real-Time Anomaly Detection with Synthetic Anomaly Monitoring (SAM)</title><link>http://arxiv.org/abs/2501.18417v2</link><description>Anomaly detection is essential for identifying rare and significant eventsacross diverse domains such as finance, cybersecurity, and network monitoring.This paper presents Synthetic Anomaly Monitoring (SAM), an innovative approachthat applies synthetic control methods from causal inference to improve boththe accuracy and interpretability of anomaly detection processes. By modelingnormal behavior through the treatment of each feature as a control unit, SAMidentifies anomalies as deviations within this causal framework. We conductedextensive experiments comparing SAM with established benchmark models,including Isolation Forest, Local Outlier Factor (LOF), k-Nearest Neighbors(kNN), and One-Class Support Vector Machine (SVM), across five diversedatasets, including Credit Card Fraud, HTTP Dataset CSIC 2010, and KDD Cup1999, among others. Our results demonstrate that SAM consistently deliversrobust performance, highlighting its potential as a powerful tool for real-timeanomaly detection in dynamic and complex environments.</description><author>Emanuele Luzio, Moacir Antonelli Ponti</author><pubDate>Mon, 03 Feb 2025 12:12:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18417v2</guid></item><item><title>Hybrid Quantum Neural Networks with Amplitude Encoding: Advancing Recovery Rate Predictions</title><link>http://arxiv.org/abs/2501.15828v2</link><description>Recovery rate prediction plays a pivotal role in bond investment strategies,enhancing risk assessment, optimizing portfolio allocation, improving pricingaccuracy, and supporting effective credit risk management. However, forecastingfaces challenges like high-dimensional features, small sample sizes, andoverfitting. We propose a hybrid Quantum Machine Learning model incorporatingParameterized Quantum Circuits (PQC) within a neural network framework. PQCsinherently preserve unitarity, avoiding computationally costly orthogonalityconstraints, while amplitude encoding enables exponential data compression,reducing qubit requirements logarithmically. Applied to a global dataset of1,725 observations (1996-2023), our method achieved superior accuracy (RMSE0.228) compared to classical neural networks (0.246) and quantum models withangle encoding (0.242), with efficient computation times. This work highlightsthe potential of hybrid quantum-classical architectures in advancing recoveryrate forecasting.</description><author>Ying Chen, Paul Griffin, Paolo Recchia, Zhou Lei, Hongrui Zhang</author><pubDate>Mon, 03 Feb 2025 12:09:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.15828v2</guid></item><item><title>Task-free Lifelong Robot Learning with Retrieval-based Weighted Local Adaptation</title><link>http://arxiv.org/abs/2410.02995v3</link><description>A fundamental objective in intelligent robotics is to move towards lifelonglearning robot that can learn and adapt to unseen scenarios over time. However,continually learning new tasks would introduce catastrophic forgetting problemsdue to data distribution shifts. To mitigate this, we store a subset of datafrom previous tasks and utilize it in two manners: leveraging experience replayto retain learned skills and applying a novel Retrieval-based Local Adaptationtechnique to restore relevant knowledge. Since a lifelong learning robot mustoperate in task-free scenarios, where task IDs and even boundaries are notavailable, our method performs effectively without relying on such information.We also incorporate a selective weighting mechanism to focus on the most"forgotten" skill segment, ensuring effective knowledge restoration.Experimental results across diverse manipulation tasks demonstrate that ourframework provides a scalable paradigm for lifelong learning, enhancing robotperformance in open-ended, task-free scenarios.</description><author>Pengzhi Yang, Xinyu Wang, Ruipeng Zhang, Cong Wang, Frans A. Oliehoek, Jens Kober</author><pubDate>Mon, 03 Feb 2025 12:08:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02995v3</guid></item><item><title>Wave-U-Mamba: An End-To-End Framework For High-Quality And Efficient Speech Super Resolution</title><link>http://arxiv.org/abs/2409.09337v3</link><description>Speech Super-Resolution (SSR) is a task of enhancing low-resolution speechsignals by restoring missing high-frequency components. Conventional approachestypically reconstruct log-mel features, followed by a vocoder that generateshigh-resolution speech in the waveform domain. However, as mel features lackphase information, this can result in performance degradation during thereconstruction phase. Motivated by recent advances with Selective State SpacesModels (SSMs), we propose a method, referred to as Wave-U-Mamba that directlyperforms SSR in time domain. In our comparative study, including models such asWSRGlow, NU-Wave 2, and AudioSR, Wave-U-Mamba demonstrates superiorperformance, achieving the lowest Log-Spectral Distance (LSD) across variouslow-resolution sampling rates, ranging from 8 to 24 kHz. Additionally,subjective human evaluations, scored using Mean Opinion Score (MOS) reveal thatour method produces SSR with natural and human-like quality. Furthermore,Wave-U-Mamba achieves these results while generating high-resolution speechover nine times faster than baseline models on a single A100 GPU, withparameter sizes less than 2\% of those in the baseline models.</description><author>Yongjoon Lee, Chanwoo Kim</author><pubDate>Mon, 03 Feb 2025 12:07:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.09337v3</guid></item><item><title>Mutual Information Preserving Neural Network Pruning</title><link>http://arxiv.org/abs/2411.00147v2</link><description>Pruning has emerged as the primary approach used to limit the resourcerequirements of large neural networks (NNs). Since the proposal of the lotteryticket hypothesis, researchers have focused either on pruning at initializationor after training. However, recent theoretical findings have shown that thesample efficiency of robust pruned models is proportional to the mutualinformation (MI) between the pruning masks and the model's training datasets,\textit{whether at initialization or after training}. In this paper, startingfrom these results, we introduce Mutual Information Preserving Pruning (MIPP),a structured activation-based pruning technique applicable before or aftertraining. The core principle of MIPP is to select nodes in a way that conservesMI shared between the activations of adjacent layers, and consequently betweenthe data and masks. Approaching the pruning problem in this manner means we canprove that there exists a function that can map the pruned upstream layer'sactivations to the downstream layer's, implying re-trainability. We demonstratethat MIPP consistently outperforms state-of-the-art methods, regardless ofwhether pruning is performed before or after training.</description><author>Charles Westphal, Stephen Hailes, Mirco Musolesi</author><pubDate>Mon, 03 Feb 2025 11:55:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.00147v2</guid></item><item><title>PBI-Attack: Prior-Guided Bimodal Interactive Black-Box Jailbreak Attack for Toxicity Maximization</title><link>http://arxiv.org/abs/2412.05892v3</link><description>Understanding the vulnerabilities of Large Vision Language Models (LVLMs) tojailbreak attacks is essential for their responsible real-world deployment.Most previous work requires access to model gradients, or is based on humanknowledge (prompt engineering) to complete jailbreak, and they hardly considerthe interaction of images and text, resulting in inability to jailbreak inblack box scenarios or poor performance. To overcome these limitations, wepropose a Prior-Guided Bimodal Interactive Black-Box Jailbreak Attack fortoxicity maximization, referred to as PBI-Attack. Our method begins byextracting malicious features from a harmful corpus using an alternative LVLMand embedding these features into a benign image as prior information.Subsequently, we enhance these features through bidirectional cross-modalinteraction optimization, which iteratively optimizes the bimodal perturbationsin an alternating manner through greedy search, aiming to maximize the toxicityof the generated response. The toxicity level is quantified using awell-trained evaluation model. Experiments demonstrate that PBI-Attackoutperforms previous state-of-the-art jailbreak methods, achieving an averageattack success rate of 92.5% across three open-source LVLMs and around 67.3% onthree closed-source LVLMs. Disclaimer: This paper contains potentiallydisturbing and offensive content.</description><author>Ruoxi Cheng, Yizhong Ding, Shuirong Cao, Ranjie Duan, Xiaoshuang Jia, Shaowei Yuan, Zhiqiang Wang, Xiaojun Jia</author><pubDate>Mon, 03 Feb 2025 11:44:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.05892v3</guid></item><item><title>Multibranch Generative Models for Multichannel Imaging with an Application to PET/CT Synergistic Reconstruction</title><link>http://arxiv.org/abs/2404.08748v5</link><description>This paper presents a novel approach for learned synergistic reconstructionof medical images using multibranch generative models. Leveraging variationalautoencoders (VAEs), our model learns from pairs of images simultaneously,enabling effective denoising and reconstruction. Synergistic imagereconstruction is achieved by incorporating the trained models in a regularizerthat evaluates the distance between the images and the model. We demonstratethe efficacy of our approach on both Modified National Institute of Standardsand Technology (MNIST) and positron emission tomography (PET)/computedtomography (CT) datasets, showcasing improved image quality for low-doseimaging. Despite challenges such as patch decomposition and model limitations,our results underscore the potential of generative models for enhancing medicalimaging reconstruction.</description><author>Noel Jeffrey Pinton, Alexandre Bousse, Catherine Cheze-Le-Rest, Dimitris Visvikis</author><pubDate>Mon, 03 Feb 2025 11:40:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08748v5</guid></item><item><title>DyPCL: Dynamic Phoneme-level Contrastive Learning for Dysarthric Speech Recognition</title><link>http://arxiv.org/abs/2501.19010v2</link><description>Dysarthric speech recognition often suffers from performance degradation dueto the intrinsic diversity of dysarthric severity and extrinsic disparity fromnormal speech. To bridge these gaps, we propose a Dynamic Phoneme-levelContrastive Learning (DyPCL) method, which leads to obtaining invariantrepresentations across diverse speakers. We decompose the speech utterance intophoneme segments for phoneme-level contrastive learning, leveraging dynamicconnectionist temporal classification alignment. Unlike prior studies focusingon utterance-level embeddings, our granular learning allows discrimination ofsubtle parts of speech. In addition, we introduce dynamic curriculum learning,which progressively transitions from easy negative samples todifficult-to-distinguishable negative samples based on phonetic similarity ofphoneme. Our approach to training by difficulty levels alleviates the inherentvariability of speakers, better identifying challenging speeches. Evaluated onthe UASpeech dataset, DyPCL outperforms baseline models, achieving an average22.10\% relative reduction in word error rate (WER) across the overalldysarthria group.</description><author>Wonjun Lee, Solee Im, Heejin Do, Yunsu Kim, Jungseul Ok, Gary Geunbae Lee</author><pubDate>Mon, 03 Feb 2025 11:21:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.19010v2</guid></item><item><title>Generative AI Models: Opportunities and Risks for Industry and Authorities</title><link>http://arxiv.org/abs/2406.04734v2</link><description>Generative AI models are capable of performing a wide variety of tasks thathave traditionally required creativity and human understanding. Duringtraining, they learn patterns from existing data and can subsequently generatenew content such as texts, images, audio, and videos that align with thesepatterns. Due to their versatility and generally high-quality results, theyrepresent, on the one hand, an opportunity for digitalisation. On the otherhand, the use of generative AI models introduces novel IT security risks thatmust be considered as part of a comprehensive analysis of the IT securitythreat landscape. In response to this risk potential, companies or authoritiesintending to use generative AI should conduct an individual risk analysisbefore integrating it into their workflows. The same applies to developers andoperators, as many risks associated with generative AI must be addressed duringdevelopment or can only be influenced by the operating organisation. Based onthis, existing security measures can be adapted, and additional measuresimplemented.</description><author>Tobias Alt, Andrea Ibisch, Clemens Meiser, Anna Wilhelm, Raphael Zimmer, Jonas Ditz, Dominique Dresen, Christoph Droste, Jens Karschau, Friederike Laus, Oliver Müller, Matthias Neu, Rainer Plaga, Carola Plesch, Britta Sennewald, Thomas Thaeren, Kristina Unverricht, Steffen Waurick</author><pubDate>Mon, 03 Feb 2025 11:03:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04734v2</guid></item><item><title>Divide and Conquer: Provably Unveiling the Pareto Front with Multi-Objective Reinforcement Learning</title><link>http://arxiv.org/abs/2402.07182v2</link><description>An important challenge in multi-objective reinforcement learning is obtaininga Pareto front of policies to attain optimal performance under differentpreferences. We introduce Iterated Pareto Referent Optimisation (IPRO), whichdecomposes finding the Pareto front into a sequence of constrainedsingle-objective problems. This enables us to guarantee convergence whileproviding an upper bound on the distance to undiscovered Pareto optimalsolutions at each step. We evaluate IPRO using utility-based metrics and itshypervolume and find that it matches or outperforms methods that requireadditional assumptions. By leveraging problem-specific single-objectivesolvers, our approach also holds promise for applications beyondmulti-objective reinforcement learning, such as planning and pathfinding.</description><author>Willem Röpke, Mathieu Reymond, Patrick Mannion, Diederik M. Roijers, Ann Nowé, Roxana Rădulescu</author><pubDate>Mon, 03 Feb 2025 11:02:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07182v2</guid></item><item><title>Understanding Model Calibration -- A gentle introduction and visual exploration of calibration and the expected calibration error (ECE)</title><link>http://arxiv.org/abs/2501.19047v2</link><description>To be considered reliable, a model must be calibrated so that its confidencein each decision closely reflects its true outcome. In this blogpost we'll takea look at the most commonly used definition for calibration and then dive intoa frequently used evaluation measure for model calibration. We'll then coversome of the drawbacks of this measure and how these surfaced the need foradditional notions of calibration, which require their own new evaluationmeasures. This post is not intended to be an in-depth dissection of all workson calibration, nor does it focus on how to calibrate models. Instead, it ismeant to provide a gentle introduction to the different notions and theirevaluation measures as well as to re-highlight some issues with a measure thatis still widely used to evaluate calibration.</description><author>Maja Pavlovic</author><pubDate>Mon, 03 Feb 2025 10:57:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.19047v2</guid></item><item><title>Interpreting Outliers in Time Series Data through Decoding Autoencoder</title><link>http://arxiv.org/abs/2409.01713v2</link><description>Outlier detection is a crucial analytical tool in various fields. In criticalsystems like manufacturing, malfunctioning outlier detection can be costly andsafety-critical. Therefore, there is a significant need for explainableartificial intelligence (XAI) when deploying opaque models in suchenvironments. This study focuses on manufacturing time series data from aGerman automotive supply industry. We utilize autoencoders to compress theentire time series and then apply anomaly detection techniques to its latentfeatures. For outlier interpretation, we (i) adopt widely used XAI techniquesto the autoencoder's encoder. Additionally, (ii) we propose AEE, AggregatedExplanatory Ensemble, a novel approach that fuses explanations of multiple XAItechniques into a single, more expressive interpretation. For evaluation ofexplanations, (iii) we propose a technique to measure the quality of encoderexplanations quantitatively. Furthermore, we qualitatively assess theeffectiveness of outlier explanations with domain expertise.</description><author>Patrick Knab, Sascha Marton, Christian Bartelt, Robert Fuder</author><pubDate>Mon, 03 Feb 2025 10:56:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.01713v2</guid></item><item><title>Musical ethnocentrism in Large Language Models</title><link>http://arxiv.org/abs/2501.13720v2</link><description>Large Language Models (LLMs) reflect the biases in their training data and,by extension, those of the people who created this training data. Detecting,analyzing, and mitigating such biases is becoming a focus of research. One typeof bias that has been understudied so far are geocultural biases. Those can becaused by an imbalance in the representation of different geographic regionsand cultures in the training data, but also by value judgments containedtherein. In this paper, we make a first step towards analyzing musical biasesin LLMs, particularly ChatGPT and Mixtral. We conduct two experiments. In thefirst, we prompt LLMs to provide lists of the "Top 100" musical contributors ofvarious categories and analyze their countries of origin. In the secondexperiment, we ask the LLMs to numerically rate various aspects of the musicalcultures of different countries. Our results indicate a strong preference ofthe LLMs for Western music cultures in both experiments.</description><author>Anna Kruspe</author><pubDate>Mon, 03 Feb 2025 10:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13720v2</guid></item><item><title>DAWN: Domain-Adaptive Weakly Supervised Nuclei Segmentation via Cross-Task Interactions</title><link>http://arxiv.org/abs/2404.14956v3</link><description>Weakly supervised segmentation methods have gained significant attention dueto their ability to reduce the reliance on costly pixel-level annotationsduring model training. However, the current weakly supervised nucleisegmentation approaches typically follow a two-stage pseudo-label generationand network training process. The performance of the nuclei segmentationheavily relies on the quality of the generated pseudo-labels, thereby limitingits effectiveness. This paper introduces a novel domain-adaptive weaklysupervised nuclei segmentation framework using cross-task interactionstrategies to overcome the challenge of pseudo-label generation. Specifically,we utilize weakly annotated data to train an auxiliary detection task, whichassists the domain adaptation of the segmentation network. To enhance theefficiency of domain adaptation, we design a consistent feature constraintmodule integrating prior knowledge from the source domain. Furthermore, wedevelop pseudo-label optimization and interactive training methods to improvethe domain transfer capability. To validate the effectiveness of our proposedmethod, we conduct extensive comparative and ablation experiments on sixdatasets. The results demonstrate the superiority of our approach over existingweakly supervised approaches. Remarkably, our method achieves comparable oreven better performance than fully supervised methods. Our code will bereleased in https://github.com/zhangye-zoe/DAWN.</description><author>Ye Zhang, Yifeng Wang, Zijie Fang, Hao Bian, Linghan Cai, Ziyue Wang, Yongbing Zhang</author><pubDate>Mon, 03 Feb 2025 10:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14956v3</guid></item><item><title>CityLoc: 6DoF Pose Distributional Localization for Text Descriptions in Large-Scale Scenes with Gaussian Representation</title><link>http://arxiv.org/abs/2501.08982v2</link><description>Localizing textual descriptions within large-scale 3D scenes presentsinherent ambiguities, such as identifying all traffic lights in a city.Addressing this, we introduce a method to generate distributions of cameraposes conditioned on textual descriptions, facilitating robust reasoning forbroadly defined concepts. Our approach employs a diffusion-based architecture to refine noisy 6DoFcamera poses towards plausible locations, with conditional signals derived frompre-trained text encoders. Integration with the pretrained Vision-LanguageModel, CLIP, establishes a strong linkage between text descriptions and posedistributions. Enhancement of localization accuracy is achieved by renderingcandidate poses using 3D Gaussian splatting, which corrects misaligned samplesthrough visual reasoning. We validate our method's superiority by comparing it against standarddistribution estimation methods across five large-scale datasets, demonstratingconsistent outperformance. Code, datasets and more information will be publiclyavailable at our project page.</description><author>Qi Ma, Runyi Yang, Bin Ren, Nicu Sebe, Ender Konukoglu, Luc Van Gool, Danda Pani Paudel</author><pubDate>Mon, 03 Feb 2025 10:49:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.08982v2</guid></item><item><title>Large Language Models for Cryptocurrency Transaction Analysis: A Bitcoin Case Study</title><link>http://arxiv.org/abs/2501.18158v2</link><description>Cryptocurrencies are widely used, yet current methods for analyzingtransactions heavily rely on opaque, black-box models. These lackinterpretability and adaptability, failing to effectively capture behavioralpatterns. Many researchers, including us, believe that Large Language Models(LLMs) could bridge this gap due to their robust reasoning abilities forcomplex tasks. In this paper, we test this hypothesis by applying LLMs toreal-world cryptocurrency transaction graphs, specifically within the Bitcoinnetwork. We introduce a three-tiered framework to assess LLM capabilities:foundational metrics, characteristic overview, and contextual interpretation.This includes a new, human-readable graph representation format, LLM4TG, and aconnectivity-enhanced sampling algorithm, CETraS, which simplifies largertransaction graphs. Experimental results show that LLMs excel at foundationalmetrics and offer detailed characteristic overviews. Their effectiveness incontextual interpretation suggests they can provide useful explanations oftransaction behaviors, even with limited labeled data.</description><author>Yuchen Lei, Yuexin Xiang, Qin Wang, Rafael Dowsley, Tsz Hon Yuen, Jiangshan Yu</author><pubDate>Mon, 03 Feb 2025 10:45:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18158v2</guid></item><item><title>Beyond Pixels: Enhancing LIME with Hierarchical Features and Segmentation Foundation Models</title><link>http://arxiv.org/abs/2403.07733v4</link><description>LIME (Local Interpretable Model-agnostic Explanations) is a popular XAIframework for unraveling decision-making processes in vision machine-learningmodels. The technique utilizes image segmentation methods to identify fixedregions for calculating feature importance scores as explanations. Therefore,poor segmentation can weaken the explanation and reduce the importance ofsegments, ultimately affecting the overall clarity of interpretation. Toaddress these challenges, we introduce the DSEG-LIME (Data-Driven SegmentationLIME) framework, featuring: i) a data-driven segmentation for human-recognizedfeature generation by foundation model integration, and ii) a user-steeredgranularity in the hierarchical segmentation procedure through composition. Ourfindings demonstrate that DSEG outperforms on several XAI metrics onpre-trained ImageNet models and improves the alignment of explanations withhuman-recognized concepts. The code is available under: https://github.com/patrick-knab/DSEG-LIME</description><author>Patrick Knab, Sascha Marton, Christian Bartelt</author><pubDate>Mon, 03 Feb 2025 10:44:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.07733v4</guid></item><item><title>Dynamic Learning Rate for Deep Reinforcement Learning: A Bandit Approach</title><link>http://arxiv.org/abs/2410.12598v2</link><description>In deep Reinforcement Learning (RL) models trained using gradient-basedtechniques, the choice of optimizer and its learning rate are crucial toachieving good performance: higher learning rates can prevent the model fromlearning effectively, while lower ones might slow convergence. Additionally,due to the non-stationarity of the objective function, the best-performinglearning rate can change over the training steps. To adapt the learning rate, astandard technique consists of using decay schedulers. However, theseschedulers assume that the model is progressively approaching convergence,which may not always be true, leading to delayed or premature adjustments. Inthis work, we propose dynamic Learning Rate for deep Reinforcement Learning(LRRL), a meta-learning approach that selects the learning rate based on theagent's performance during training. LRRL is based on a multi-armed banditalgorithm, where each arm represents a different learning rate, and the banditfeedback is provided by the cumulative returns of the RL policy to update thearms' probability distribution. Our empirical results demonstrate that LRRL cansubstantially improve the performance of deep RL algorithms for some tasks.</description><author>Henrique Donâncio, Antoine Barrier, Leah F. South, Florence Forbes</author><pubDate>Mon, 03 Feb 2025 10:42:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12598v2</guid></item><item><title>Scalable Multi-phase Word Embedding Using Conjunctive Propositional Clauses</title><link>http://arxiv.org/abs/2501.19018v2</link><description>The Tsetlin Machine (TM) architecture has recently demonstrated effectivenessin Machine Learning (ML), particularly within Natural Language Processing(NLP). It has been utilized to construct word embedding using conjunctivepropositional clauses, thereby significantly enhancing our understanding andinterpretation of machine-derived decisions. The previous approach performedthe word embedding over a sequence of input words to consolidate theinformation into a cohesive and unified representation. However, that approachencounters scalability challenges as the input size increases. In this study,we introduce a novel approach incorporating two-phase training to discovercontextual embeddings of input sequences. Specifically, this methodencapsulates the knowledge for each input word within the dataset's vocabulary,subsequently constructing embeddings for a sequence of input words utilizingthe extracted knowledge. This technique not only facilitates the design of ascalable model but also preserves interpretability. Our experimental findingsrevealed that the proposed method yields competitive performance compared tothe previous approaches, demonstrating promising results in contrast tohuman-generated benchmarks. Furthermore, we applied the proposed approach tosentiment analysis on the IMDB dataset, where the TM embedding and the TMclassifier, along with other interpretable classifiers, offered a transparentend-to-end solution with competitive performance.</description><author>Ahmed K. Kadhim, Lei Jiao, Rishad Shafik, Ole-Christoffer Granmo, Bimal Bhattarai</author><pubDate>Mon, 03 Feb 2025 10:41:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.19018v2</guid></item></channel></rss>