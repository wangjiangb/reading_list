<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 01 Nov 2024 01:00:30 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>CrossEarth: Geospatial Vision Foundation Model for Domain Generalizable Remote Sensing Semantic Segmentation</title><link>http://arxiv.org/abs/2410.22629v2</link><description>The field of Remote Sensing Domain Generalization (RSDG) has emerged as acritical and valuable research frontier, focusing on developing models thatgeneralize effectively across diverse scenarios. Despite the substantial domaingaps in RS images that are characterized by variabilities such as location,wavelength, and sensor type, research in this area remains underexplored: (1)Current cross-domain methods primarily focus on Domain Adaptation (DA), whichadapts models to predefined domains rather than to unseen ones; (2) Few studiestargeting the RSDG issue, especially for semantic segmentation tasks, whereexisting models are developed for specific unknown domains, struggling withissues of underfitting on other unknown scenarios; (3) Existing RS foundationmodels tend to prioritize in-domain performance over cross-domaingeneralization. To this end, we introduce the first vision foundation model forRSDG semantic segmentation, CrossEarth. CrossEarth demonstrates strongcross-domain generalization through a specially designed data-level Earth-StyleInjection pipeline and a model-level Multi-Task Training pipeline. In addition,for the semantic segmentation task, we have curated an RSDG benchmarkcomprising 28 cross-domain settings across various regions, spectral bands,platforms, and climates, providing a comprehensive framework for testing thegeneralizability of future RSDG models. Extensive experiments on this benchmarkdemonstrate the superiority of CrossEarth over existing state-of-the-artmethods.</description><author>Ziyang Gong, Zhixiang Wei, Di Wang, Xianzheng Ma, Hongruixuan Chen, Yuru Jia, Yupeng Deng, Zhenming Ji, Xiangwei Zhu, Naoto Yokoya, Jing Zhang, Bo Du, Liangpei Zhang</author><pubDate>Thu, 31 Oct 2024 14:44:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22629v2</guid></item><item><title>Consistency Diffusion Bridge Models</title><link>http://arxiv.org/abs/2410.22637v2</link><description>Diffusion models (DMs) have become the dominant paradigm of generativemodeling in a variety of domains by learning stochastic processes from noise todata. Recently, diffusion denoising bridge models (DDBMs), a new formulation ofgenerative modeling that builds stochastic processes between fixed dataendpoints based on a reference diffusion process, have achieved empiricalsuccess across tasks with coupled data distribution, such as image-to-imagetranslation. However, DDBM's sampling process typically requires hundreds ofnetwork evaluations to achieve decent performance, which may impede theirpractical deployment due to high computational demands. In this work, inspiredby the recent advance of consistency models in DMs, we tackle this problem bylearning the consistency function of the probability-flow ordinary differentialequation (PF-ODE) of DDBMs, which directly predicts the solution at a startingstep given any point on the ODE trajectory. Based on a dedicated general-formODE solver, we propose two paradigms: consistency bridge distillation andconsistency bridge training, which is flexible to apply on DDBMs with broaddesign choices. Experimental results show that our proposed method could sample$4\times$ to $50\times$ faster than the base DDBM and produce better visualquality given the same step in various tasks with pixel resolution ranging from$64 \times 64$ to $256 \times 256$, as well as supporting downstream tasks suchas semantic interpolation in the data space.</description><author>Guande He, Kaiwen Zheng, Jianfei Chen, Fan Bao, Jun Zhu</author><pubDate>Thu, 31 Oct 2024 14:35:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22637v2</guid></item><item><title>DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data</title><link>http://arxiv.org/abs/2410.22938v2</link><description>The application of reinforcement learning in traffic signal control (TSC) hasbeen extensively researched and yielded notable achievements. However, mostexisting works for TSC assume that traffic data from all surroundingintersections is fully and continuously available through sensors. Inreal-world applications, this assumption often fails due to sensor malfunctionsor data loss, making TSC with missing data a critical challenge. To meet theneeds of practical applications, we introduce DiffLight, a novel conditionaldiffusion model for TSC under data-missing scenarios in the offline setting.Specifically, we integrate two essential sub-tasks, i.e., traffic dataimputation and decision-making, by leveraging a Partial Rewards ConditionedDiffusion (PRCD) model to prevent missing rewards from interfering with thelearning process. Meanwhile, to effectively capture the spatial-temporaldependencies among intersections, we design a Spatial-Temporal transFormer(STFormer) architecture. In addition, we propose a Diffusion CommunicationMechanism (DCM) to promote better communication and control performance underdata-missing scenarios. Extensive experiments on five datasets with variousdata-missing scenarios demonstrate that DiffLight is an effective controller toaddress TSC with missing data. The code of DiffLight is released athttps://github.com/lokol5579/DiffLight-release.</description><author>Hanyang Chen, Yang Jiang, Shengnan Guo, Xiaowei Mao, Youfang Lin, Huaiyu Wan</author><pubDate>Thu, 31 Oct 2024 13:39:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22938v2</guid></item><item><title>Why Gradient Subspace? Identifying and Mitigating LoRA's Bottlenecks in Federated Fine-Tuning of Large Language Models</title><link>http://arxiv.org/abs/2410.23111v2</link><description>Large Language Models (LLMs) have demonstrated remarkable capabilities acrossvarious domains, particularly in task generalization for both text and visiondata. While fine-tuning these models can significantly enhance theirperformance on specific downstream tasks, it often requires high-quality datathat cannot be shared due to privacy concerns. Federated Learning (FL) offers apromising solution for collaborative training without direct data sharing.However, many parameter-efficient fine-tuning strategies for LLMs in FL,particularly those based on Low-Rank Adaptation (LoRA), face limitations. Inthis paper, we critically analyze the convergence and performance guarantees ofpopular FL frameworks utilizing LoRA, highlighting its suboptimal nature due toconstrained subspace learning of low-rank matrices. This limitation hinderseffective fine-tuning of LLMs in federated settings. Through rigorousanalytical and empirical evaluations, we demonstrate that direct weightaveraging outperforms LoRA-based strategies, leading to superior performancefor fine-tuned models. Our comprehensive comparison exposes inefficiencies inLoRA approaches and underscores the advantages of direct weight aggregation. Weextend our analysis to low-rank gradient-based optimizers, such as GaLore, usedduring local training steps. Our findings show that GaLore is a more effectivealternative, outperforming federated LoRA methods like FlexLoRA and FFA-LoRAacross both text and image modalities. While privacy remains paramount in FLdiscourse, our focus is on assessing performance outcomes of federatedfine-tuned models and evaluating various FL frameworks from both theoreticaland empirical perspectives. Our findings advocate reassessing the reliance onLoRA within FL contexts, paving the way for more efficient trainingmethodologies.</description><author>Navyansh Mahla, Ganesh Ramakrishnan</author><pubDate>Thu, 31 Oct 2024 11:16:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23111v2</guid></item><item><title>NeuralSolver: Learning Algorithms For Consistent and Efficient Extrapolation Across General Tasks</title><link>http://arxiv.org/abs/2402.15393v4</link><description>We contribute NeuralSolver, a novel recurrent solver that can efficiently andconsistently extrapolate, i.e., learn algorithms from smaller problems (interms of observation size) and execute those algorithms in large problems.Contrary to previous recurrent solvers, NeuralSolver can be naturally appliedin both same-size problems, where the input and output sizes are the same, andin different-size problems, where the size of the input and output differ. Toallow for this versatility, we design NeuralSolver with three main components:a recurrent module, that iteratively processes input information at differentscales, a processing module, responsible for aggregating the previouslyprocessed information, and a curriculum-based training scheme, that improvesthe extrapolation performance of the method. To evaluate our method weintroduce a set of novel different-size tasks and we show that NeuralSolverconsistently outperforms the prior state-of-the-art recurrent solvers inextrapolating to larger problems, considering smaller training problems andrequiring less parameters than other approaches.</description><author>Bernardo Esteves, Miguel Vasco, Francisco S. Melo</author><pubDate>Thu, 31 Oct 2024 09:46:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15393v4</guid></item><item><title>Algebraic Positional Encodings</title><link>http://arxiv.org/abs/2312.16045v3</link><description>We introduce a novel positional encoding strategy for Transformer-stylemodels, addressing the shortcomings of existing, often ad hoc, approaches. Ourframework provides a flexible mapping from the algebraic specification of adomain to an interpretation as orthogonal operators. This design preserves thealgebraic characteristics of the source domain, ensuring that the model upholdsits desired structural properties. Our scheme can accommodate variousstructures, ncluding sequences, grids and trees, as well as their compositions.We conduct a series of experiments to demonstrate the practical applicabilityof our approach. Results suggest performance on par with or surpassing thecurrent state-of-the-art, without hyper-parameter optimizations or "tasksearch" of any kind. Code is available athttps://github.com/konstantinosKokos/ape.</description><author>Konstantinos Kogkalidis, Jean-Philippe Bernardy, Vikas Garg</author><pubDate>Thu, 31 Oct 2024 08:55:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16045v3</guid></item><item><title>ETO:Efficient Transformer-based Local Feature Matching by Organizing Multiple Homography Hypotheses</title><link>http://arxiv.org/abs/2410.22733v2</link><description>We tackle the efficiency problem of learning local feature matching. Recentadvancements have given rise to purely CNN-based and transformer-basedapproaches, each augmented with deep learning techniques. While CNN-basedmethods often excel in matching speed, transformer-based methods tend toprovide more accurate matches. We propose an efficient transformer-basednetwork architecture for local feature matching. This technique is built onconstructing multiple homography hypotheses to approximate the continuouscorrespondence in the real world and uni-directional cross-attention toaccelerate the refinement. On the YFCC100M dataset, our matching accuracy iscompetitive with LoFTR, a state-of-the-art transformer-based architecture,while the inference speed is boosted to 4 times, even outperforming theCNN-based methods. Comprehensive evaluations on other open datasets such asMegadepth, ScanNet, and HPatches demonstrate our method's efficacy,highlighting its potential to significantly enhance a wide array of downstreamapplications.</description><author>Junjie Ni, Guofeng Zhang, Guanglin Li, Yijin Li, Xinyang Liu, Zhaoyang Huang, Hujun Bao</author><pubDate>Thu, 31 Oct 2024 08:26:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22733v2</guid></item><item><title>One Prompt to Verify Your Models: Black-Box Text-to-Image Models Verification via Non-Transferable Adversarial Attacks</title><link>http://arxiv.org/abs/2410.22725v2</link><description>Recently, the success of Text-to-Image (T2I) models has led to the rise ofnumerous third-party platforms, which claim to provide cheaper API services andmore flexibility in model options. However, this also raises a new securityconcern: Are these third-party services truly offering the models they claim?To address this problem, we propose the first T2I model verification methodnamed Text-to-Image Model Verification via Non-Transferable Adversarial Attacks(TVN). The non-transferability of adversarial examples means that theseexamples are only effective on a target model and ineffective on other models,thereby allowing for the verification of the target model. TVN utilizes theNon-dominated Sorting Genetic Algorithm II (NSGA-II) to optimize the cosinesimilarity of a prompt's text encoding, generating non-transferable adversarialprompts. By calculating the CLIP-text scores between the non-transferableadversarial prompts without perturbations and the images, we can verify if themodel matches the claimed target model, based on a 3-sigma threshold. Theexperiments showed that TVN performed well in both closed-set and open-setscenarios, achieving a verification accuracy of over 90\%. Moreover, theadversarial prompts generated by TVN significantly reduced the CLIP-text scoresof the target model, while having little effect on other models.</description><author>Ji Guo, Wenbo Jiang, Rui Zhang, Guoming Lu, Hongwei Li</author><pubDate>Thu, 31 Oct 2024 08:08:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22725v2</guid></item><item><title>HiBO: Hierarchical Bayesian Optimization via Adaptive Search Space Partitioning</title><link>http://arxiv.org/abs/2410.23148v2</link><description>Optimizing black-box functions in high-dimensional search spaces has beenknown to be challenging for traditional Bayesian Optimization (BO). In thispaper, we introduce HiBO, a novel hierarchical algorithm integratingglobal-level search space partitioning information into the acquisitionstrategy of a local BO-based optimizer. HiBO employs a search-tree-basedglobal-level navigator to adaptively split the search space into partitionswith different sampling potential. The local optimizer then utilizes thisglobal-level information to guide its acquisition strategy towards mostpromising regions within the search space. A comprehensive set of evaluationsdemonstrates that HiBO outperforms state-of-the-art methods in high-dimensionalsynthetic benchmarks and presents significant practical effectiveness in thereal-world task of tuning configurations of database management systems(DBMSs).</description><author>Wenxuan Li, Taiyi Wang, Eiko Yoneki</author><pubDate>Thu, 31 Oct 2024 07:15:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23148v2</guid></item><item><title>Epipolar-Free 3D Gaussian Splatting for Generalizable Novel View Synthesis</title><link>http://arxiv.org/abs/2410.22817v2</link><description>Generalizable 3D Gaussian splitting (3DGS) can reconstruct new scenes fromsparse-view observations in a feed-forward inference manner, eliminating theneed for scene-specific retraining required in conventional 3DGS. However,existing methods rely heavily on epipolar priors, which can be unreliable incomplex realworld scenes, particularly in non-overlapping and occluded regions.In this paper, we propose eFreeSplat, an efficient feed-forward 3DGS-basedmodel for generalizable novel view synthesis that operates independently ofepipolar line constraints. To enhance multiview feature extraction with 3Dperception, we employ a selfsupervised Vision Transformer (ViT) with cross-viewcompletion pre-training on large-scale datasets. Additionally, we introduce anIterative Cross-view Gaussians Alignment method to ensure consistent depthscales across different views. Our eFreeSplat represents an innovative approachfor generalizable novel view synthesis. Different from the existing puregeometry-free methods, eFreeSplat focuses more on achieving epipolar-freefeature matching and encoding by providing 3D priors through cross-viewpretraining. We evaluate eFreeSplat on wide-baseline novel view synthesis tasksusing the RealEstate10K and ACID datasets. Extensive experiments demonstratethat eFreeSplat surpasses state-of-the-art baselines that rely on epipolarpriors, achieving superior geometry reconstruction and novel view synthesisquality. Project page: https://tatakai1.github.io/efreesplat/.</description><author>Zhiyuan Min, Yawei Luo, Jianwen Sun, Yi Yang</author><pubDate>Thu, 31 Oct 2024 07:07:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22817v2</guid></item><item><title>MILP-StuDio: MILP Instance Generation via Block Structure Decomposition</title><link>http://arxiv.org/abs/2410.22806v2</link><description>Mixed-integer linear programming (MILP) is one of the most popularmathematical formulations with numerous applications. In practice, improvingthe performance of MILP solvers often requires a large amount of high-qualitydata, which can be challenging to collect. Researchers thus turn to generationtechniques to generate additional MILP instances. However, existing approachesdo not take into account specific block structures -- which are closely relatedto the problem formulations -- in the constraint coefficient matrices (CCMs) ofMILPs. Consequently, they are prone to generate computationally trivial orinfeasible instances due to the disruptions of block structures and thusproblem formulations. To address this challenge, we propose a novel MILPgeneration framework, called Block Structure Decomposition (MILP-StuDio), togenerate high-quality instances by preserving the block structures.Specifically, MILP-StuDio begins by identifying the blocks in CCMs anddecomposing the instances into block units, which serve as the building blocksof MILP instances. We then design three operators to construct new instances byremoving, substituting, and appending block units in the original instances,enabling us to generate instances with flexible sizes. An appealing feature ofMILP-StuDio is its strong ability to preserve the feasibility and computationalhardness of the generated instances. Experiments on the commonly-usedbenchmarks demonstrate that using instances generated by MILP-StuDio is able tosignificantly reduce over 10% of the solving time for learning-based solvers.</description><author>Haoyang Liu, Jie Wang, Wanbo Zhang, Zijie Geng, Yufei Kuang, Xijun Li, Bin Li, Yongdong Zhang, Feng Wu</author><pubDate>Thu, 31 Oct 2024 07:03:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22806v2</guid></item><item><title>Online Feature Updates Improve Online (Generalized) Label Shift Adaptation</title><link>http://arxiv.org/abs/2402.03545v3</link><description>This paper addresses the prevalent issue of label shift in an online settingwith missing labels, where data distributions change over time and obtainingtimely labels is challenging. While existing methods primarily focus onadjusting or updating the final layer of a pre-trained classifier, we explorethe untapped potential of enhancing feature representations using unlabeleddata at test-time. Our novel method, Online Label Shift adaptation with OnlineFeature Updates (OLS-OFU), leverages self-supervised learning to refine thefeature extraction process, thereby improving the prediction model. Bycarefully designing the algorithm, theoretically OLS-OFU maintains the similaronline regret convergence to the results in the literature while taking theimproved features into account. Empirically, it achieves substantialimprovements over existing methods, which is as significant as the gainsexisting methods have over the baseline (i.e., without distribution shiftadaptations).</description><author>Ruihan Wu, Siddhartha Datta, Yi Su, Dheeraj Baby, Yu-Xiang Wang, Kilian Q. Weinberger</author><pubDate>Thu, 31 Oct 2024 06:45:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03545v3</guid></item><item><title>Aligning Audio-Visual Joint Representations with an Agentic Workflow</title><link>http://arxiv.org/abs/2410.23230v2</link><description>Visual content and accompanied audio signals naturally formulate a jointrepresentation to improve audio-visual (AV) related applications. While studiesdevelop various AV representation learning frameworks, the importance of AVdata alignment is usually undermined for achieving high-quality representation.We observe that an audio signal may contain background noise interference.Also, non-synchronization may appear between audio and video streams. Thesenon-strict data alignment limits representation quality and downgradeapplication performance. In this paper, we propose to improve AV jointrepresentations from a data-centric perspective by aligning audio signals tovisual data. Our alignment is conducted in an agentic workflow controlled by anLLM-based assistant named AVAgent. For each input AV data pair, our AVAgentuses a multi-modal LLM to convert audio and visual data into languagedescriptions separately (i.e., tool use). Then, AVAgent reasons whether thispaired data is aligned well and plans to edit the audio signal if needed (i.e.,planning). The audio editing is executed by predefined actions that filternoise or augment data. Moreover, we use a VLM to evaluate how modified audiosignals match the visual content and provide feedback to AVAgent (i.e.,reflection). The tool use, planning, and reflection steps operate cyclically tobecome an agentic workflow where audio signals are gradually aligned to visualcontent. To this end, existing methods can directly leverage the aligned AVdata via our agentic workflow to improve AV joint representations. Theexperimental results comprehensively demonstrate the state-of-the-artperformance of the proposed approach against previous baselines in diversedownstream tasks.</description><author>Shentong Mo, Yibing Song</author><pubDate>Thu, 31 Oct 2024 04:20:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23230v2</guid></item><item><title>(FL)$^2$: Overcoming Few Labels in Federated Semi-Supervised Learning</title><link>http://arxiv.org/abs/2410.23227v2</link><description>Federated Learning (FL) is a distributed machine learning framework thattrains accurate global models while preserving clients' privacy-sensitive data.However, most FL approaches assume that clients possess labeled data, which isoften not the case in practice. Federated Semi-Supervised Learning (FSSL)addresses this label deficiency problem, targeting situations where only theserver has a small amount of labeled data while clients do not. However, asignificant performance gap exists between Centralized Semi-Supervised Learning(SSL) and FSSL. This gap arises from confirmation bias, which is morepronounced in FSSL due to multiple local training epochs and the separation oflabeled and unlabeled data. We propose $(FL)^2$, a robust training method forunlabeled clients using sharpness-aware consistency regularization. We showthat regularizing the original pseudo-labeling loss is suboptimal, and hence wecarefully select unlabeled samples for regularization. We further introduceclient-specific adaptive thresholding and learning status-aware aggregation toadjust the training process based on the learning progress of each client. Ourexperiments on three benchmark datasets demonstrate that our approachsignificantly improves performance and bridges the gap with SSL, particularlyin scenarios with scarce labeled data.</description><author>Seungjoo Lee, Thanh-Long V. Le, Jaemin Shin, Sung-Ju Lee</author><pubDate>Thu, 31 Oct 2024 04:05:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23227v2</guid></item><item><title>On filter design in deep convolutional neural network</title><link>http://arxiv.org/abs/2410.21644v3</link><description>The deep convolutional neural network (DCNN) in computer vision has givenpromising results. It is widely applied in many areas, from medicine,agriculture, self-driving car, biometric system, and almost all computervision-based applications. Filters or weights are the critical elementsresponsible for learning in DCNN. Backpropagation has been the primary learningalgorithm for DCNN and provides promising results, but the size and numbers ofthe filters remain hyper-parameters. Various studies have been done in the lastdecade on semi-supervised, self-supervised, and unsupervised methods and theirproperties. The effects of filter initialization, size-shape selection, and thenumber of filters on learning and optimization have not been investigated in aseparate publication to collate all the options. Such attributes are oftentreated as hyper-parameters and lack mathematical understanding. Computervision algorithms have many limitations in real-life applications, andunderstanding the learning process is essential to have some significantimprovement. To the best of our knowledge, no separate investigation has beenpublished discussing the filters; this is our primary motivation. This studyfocuses on arguments for choosing specific physical parameters of filters,initialization, and learning technic over scattered methods. The promisingunsupervised approaches have been evaluated. Additionally, the limitations,current challenges, and future scope have been discussed in this paper.</description><author>Gaurav Hirani, Waleed Abdulla</author><pubDate>Thu, 31 Oct 2024 04:02:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21644v3</guid></item><item><title>Long$^2$RAG: Evaluating Long-Context &amp; Long-Form Retrieval-Augmented Generation with Key Point Recall</title><link>http://arxiv.org/abs/2410.23000v2</link><description>Retrieval-augmented generation (RAG) is a promising approach to address thelimitations of fixed knowledge in large language models (LLMs). However,current benchmarks for evaluating RAG systems suffer from two key deficiencies:(1) they fail to adequately measure LLMs' capability in handling long-contextretrieval due to a lack of datasets that reflect the characteristics ofretrieved documents, and (2) they lack a comprehensive evaluation method forassessing LLMs' ability to generate long-form responses that effectivelyexploits retrieved information. To address these shortcomings, we introduce theLong$^2$RAG benchmark and the Key Point Recall (KPR) metric. Long$^2$RAGcomprises 280 questions spanning 10 domains and across 8 question categories,each associated with 5 retrieved documents with an average length of 2,444words. KPR evaluates the extent to which LLMs incorporate key points extractedfrom the retrieved documents into their generated responses, providing a morenuanced assessment of their ability to exploit retrieved information.</description><author>Zehan Qi, Rongwu Xu, Zhijiang Guo, Cunxiang Wang, Hao Zhang, Wei Xu</author><pubDate>Thu, 31 Oct 2024 03:04:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23000v2</guid></item><item><title>LIVE: Learnable In-Context Vector for Visual Question Answering</title><link>http://arxiv.org/abs/2406.13185v3</link><description>As language models continue to scale, Large Language Models (LLMs) haveexhibited emerging capabilities in In-Context Learning (ICL), enabling them tosolve language tasks by prefixing a few in-context demonstrations (ICDs) ascontext. Inspired by these advancements, researchers have extended thesetechniques to develop Large Multimodal Models (LMMs) with ICL capabilities.However, applying ICL usually faces two major challenges: 1) using more ICDswill largely increase the inference time and 2) the performance is sensitive tothe selection of ICDs. These challenges are further exacerbated in LMMs due tothe integration of multiple data types and the combinational complexity ofmultimodal ICDs. Recently, to address these challenges, some NLP studiesintroduce non-learnable In-Context Vectors (ICVs) which extract useful taskinformation from ICDs into a single vector and then insert it into the LLM tohelp solve the corresponding task. However, although useful in simple NLPtasks, these non-learnable methods fail to handle complex multimodal tasks likeVisual Question Answering (VQA). In this study, we propose Learnable In-ContextVEctor (LIVE) to distill essential task information from demonstrations,improving ICL performance in LMMs. Experiments show that LIVE can significantlyreduce computational costs while enhancing accuracy in VQA tasks compared totraditional ICL and other non-learnable ICV methods. The code is available at\url{https://github.com/ForJadeForest/LIVE-Learnable-In-Context-Vector}.</description><author>Yingzhe Peng, Chenduo Hao, Xu Yang, Jiawei Peng, Xinting Hu, Xin Geng</author><pubDate>Thu, 31 Oct 2024 02:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13185v3</guid></item><item><title>PARE-Net: Position-Aware Rotation-Equivariant Networks for Robust Point Cloud Registration</title><link>http://arxiv.org/abs/2407.10142v3</link><description>Learning rotation-invariant distinctive features is a fundamental requirementfor point cloud registration. Existing methods often use rotation-sensitivenetworks to extract features, while employing rotation augmentation to learn anapproximate invariant mapping rudely. This makes networks fragile to rotations,overweight, and hinders the distinctiveness of features. To tackle theseproblems, we propose a novel position-aware rotation-equivariant network, forefficient, light-weighted, and robust registration. The network can provide astrong model inductive bias to learn rotation-equivariant/invariant features,thus addressing the aforementioned limitations. To further improve thedistinctiveness of descriptors, we propose a position-aware convolution, whichcan better learn spatial information of local structures. Moreover, we alsopropose a feature-based hypothesis proposer. It leverages rotation-equivariantfeatures that encode fine-grained structure orientations to generate reliablemodel hypotheses. Each correspondence can generate a hypothesis, thus it ismore efficient than classic estimators that require multiple reliablecorrespondences. Accordingly, a contrastive rotation loss is presented toenhance the robustness of rotation-equivariant features against datadegradation. Extensive experiments on indoor and outdoor datasets demonstratethat our method significantly outperforms the SOTA methods in terms ofregistration recall while being lightweight and keeping a fast speed. Moreover,experiments on rotated datasets demonstrate its robustness against rotationvariations. Code is available at https://github.com/yaorz97/PARENet.</description><author>Runzhao Yao, Shaoyi Du, Wenting Cui, Canhui Tang, Chengwu Yang</author><pubDate>Thu, 31 Oct 2024 02:18:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10142v3</guid></item><item><title>TLCM: Training-efficient Latent Consistency Model for Image Generation with 2-8 Steps</title><link>http://arxiv.org/abs/2406.05768v5</link><description>Distilling latent diffusion models (LDMs) into ones that are fast to samplefrom is attracting growing research interest. However, the majority of existingmethods face two critical challenges: (1) They hinge on long training using ahuge volume of real data. (2) They routinely lead to quality degradation forgeneration, especially in text-image alignment. This paper proposes a noveltraining-efficient Latent Consistency Model (TLCM) to overcome thesechallenges. Our method first accelerates LDMs via data-free multistep latentconsistency distillation (MLCD), and then data-free latent consistencydistillation is proposed to efficiently guarantee the inter-segment consistencyin MLCD. Furthermore, we introduce bags of techniques, e.g., distributionmatching, adversarial learning, and preference learning, to enhance TLCM'sperformance at few-step inference without any real data. TLCM demonstrates ahigh level of flexibility by enabling adjustment of sampling steps within therange of 2 to 8 while still producing competitive outputs compared to full-stepapproaches. Notably, TLCM enjoys the data-free merit by employing syntheticdata from the teacher for distillation. With just 70 training hours on an A100GPU, a 3-step TLCM distilled from SDXL achieves an impressive CLIP Score of33.68 and an Aesthetic Score of 5.97 on the MSCOCO-2017 5K benchmark,surpassing various accelerated models and even outperforming the teacher modelin human preference metrics. We also demonstrate the versatility of TLCMs inapplications including image style transfer, controllable generation, andChinese-to-image generation.</description><author>Qingsong Xie, Zhenyi Liao, Zhijie Deng, Chen chen, Haonan Lu</author><pubDate>Thu, 31 Oct 2024 02:16:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05768v5</guid></item><item><title>A Theory of Synaptic Neural Balance: From Local to Global Order</title><link>http://arxiv.org/abs/2405.09688v4</link><description>We develop a general theory of synaptic neural balance and how it can emergeor be enforced in neural networks. For a given regularizer, a neuron is said tobe in balance if the total cost of its input weights is equal to the total costof its output weights. The basic example is provided by feedforward networks ofReLU units trained with $L_2$ regularizers, which exhibit balance after propertraining. The theory explains this phenomenon and extends it in severaldirections. The first direction is the extension to bilinear and otheractivation functions. The second direction is the extension to more generalregularizers, including all $L_p$ regularizers. The third direction is theextension to non-layered architectures, recurrent architectures, convolutionalarchitectures, as well as architectures with mixed activation functions.Gradient descent on the error function alone does not converge in general to abalanced state, where every neuron is in balance, even when starting from abalanced state. However, gradient descent on the regularized error functionought to converge to a balanced state, and thus network balance can be used toassess learning progress. The theory is based on two local neuronal operations:scaling which is commutative, and balancing which is not commutative. Given anyinitial set of weights, when local balancing operations are applied to eachneuron in a stochastic manner, global order always emerges through theconvergence of the stochastic balancing algorithm to the same unique set ofbalanced weights. The reason for this is the existence of an underlyingstrictly convex optimization problem where the relevant variables areconstrained to a linear, only architecture-dependent, manifold. Simulationsshow that balancing neurons prior to learning, or during learning inalternation with gradient descent steps, can improve learning speed and finalperformance.</description><author>Pierre Baldi, Antonios Alexos, Ian Domingo, Alireza Rahmansetayesh</author><pubDate>Thu, 31 Oct 2024 02:01:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09688v4</guid></item><item><title>Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval</title><link>http://arxiv.org/abs/2410.23214v2</link><description>The hallucinations of large language models (LLMs) are increasingly mitigatedby allowing LLMs to search for information and to ground their answers in realsources. Unfortunately, LLMs often struggle with posing the right searchqueries, especially when dealing with complex or otherwise indirect topics.Observing that LLMs can learn to search for relevant facts by $\textit{trying}$different queries and learning to up-weight queries that successfully producerelevant results, we introduce $\underline{Le}$arning to $\underline{Re}$trieveby $\underline{T}$rying (LeReT), a reinforcement learning framework thatexplores search queries and uses preference-based optimization to improve theirquality. LeReT can improve the absolute retrieval accuracy by up to 29% and thedownstream generator evaluations by 17%. The simplicity and flexibility ofLeReT allows it to be applied to arbitrary off-the-shelf retrievers and makesit a promising technique for improving general LLM pipelines. Project website:http://sherylhsu.com/LeReT/.</description><author>Sheryl Hsu, Omar Khattab, Chelsea Finn, Archit Sharma</author><pubDate>Thu, 31 Oct 2024 01:34:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23214v2</guid></item><item><title>Bridging the Human to Robot Dexterity Gap through Object-Oriented Rewards</title><link>http://arxiv.org/abs/2410.23289v1</link><description>Training robots directly from human videos is an emerging area in roboticsand computer vision. While there has been notable progress with two-fingeredgrippers, learning autonomous tasks for multi-fingered robot hands in this wayremains challenging. A key reason for this difficulty is that a policy trainedon human hands may not directly transfer to a robot hand due to morphologydifferences. In this work, we present HuDOR, a technique that enables onlinefine-tuning of policies by directly computing rewards from human videos.Importantly, this reward function is built using object-oriented trajectoriesderived from off-the-shelf point trackers, providing meaningful learningsignals despite the morphology gap and visual differences between human androbot hands. Given a single video of a human solving a task, such as gentlyopening a music box, HuDOR enables our four-fingered Allegro hand to learn thetask with just an hour of online interaction. Our experiments across four tasksshow that HuDOR achieves a 4x improvement over baselines. Code and videos areavailable on our website, https://object-rewards.github.io.</description><author>Irmak Guzey, Yinlong Dai, Georgy Savva, Raunaq Bhirangi, Lerrel Pinto</author><pubDate>Wed, 30 Oct 2024 17:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23289v1</guid></item><item><title>ReferEverything: Towards Segmenting Everything We Can Speak of in Videos</title><link>http://arxiv.org/abs/2410.23287v1</link><description>We present REM, a framework for segmenting a wide range of concepts in videothat can be described through natural language. Our method capitalizes onvisual-language representations learned by video diffusion models onInternet-scale datasets. A key insight of our approach is preserving as much ofthe generative model's original representation as possible, while fine-tuningit on narrow-domain Referral Object Segmentation datasets. As a result, ourframework can accurately segment and track rare and unseen objects, despitebeing trained on object masks from a limited set of categories. Additionally,it can generalize to non-object dynamic concepts, such as waves crashing in theocean, as demonstrated in our newly introduced benchmark for Referral VideoProcess Segmentation (Ref-VPS). Our experiments show that REM performs on parwith state-of-the-art approaches on in-domain datasets, like Ref-DAVIS, whileoutperforming them by up to twelve points in terms of region similarity onout-of-domain data, leveraging the power of Internet-scale pre-training.</description><author>Anurag Bagchi, Zhipeng Bao, Yu-Xiong Wang, Pavel Tokmakov, Martial Hebert</author><pubDate>Wed, 30 Oct 2024 17:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23287v1</guid></item><item><title>Data Contamination Can Cross Language Barriers</title><link>http://arxiv.org/abs/2406.13236v2</link><description>The opacity in developing large language models (LLMs) is raising growingconcerns about the potential contamination of public benchmarks in thepre-training data. Existing contamination detection methods are typically basedon the text overlap between training and evaluation data, which can be toosuperficial to reflect deeper forms of contamination. In this paper, we firstpresent a cross-lingual form of contamination that inflates LLMs' performancewhile evading current detection methods, deliberately injected by overfittingLLMs on the translated versions of benchmark test sets. Then, we proposegeneralization-based approaches to unmask such deeply concealed contamination.Specifically, we examine the LLM's performance change after modifying theoriginal benchmark by replacing the false answer choices with correct ones fromother questions. Contaminated models can hardly generalize to such easiersituations, where the false choices can be \emph{not even wrong}, as allchoices are correct in their memorization. Experimental results demonstratethat cross-lingual contamination can easily fool existing detection methods,but not ours. In addition, we discuss the potential utilization ofcross-lingual contamination in interpreting LLMs' working mechanisms and inpost-training LLMs for enhanced multilingual capabilities. The code and datasetwe use can be obtained from \url{https://github.com/ShangDataLab/Deep-Contam}.</description><author>Feng Yao, Yufan Zhuang, Zihao Sun, Sunan Xu, Animesh Kumar, Jingbo Shang</author><pubDate>Wed, 30 Oct 2024 17:59:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13236v2</guid></item><item><title>Provable acceleration for diffusion models under minimal assumptions</title><link>http://arxiv.org/abs/2410.23285v1</link><description>While score-based diffusion models have achieved exceptional samplingquality, their sampling speeds are often limited by the high computationalburden of score function evaluations. Despite the recent remarkable empiricaladvances in speeding up the score-based samplers, theoretical understanding ofacceleration techniques remains largely limited. To bridge this gap, we proposea novel training-free acceleration scheme for stochastic samplers. Underminimal assumptions -- namely, $L^2$-accurate score estimates and a finitesecond-moment condition on the target distribution -- our accelerated samplerprovably achieves $\varepsilon$-accuracy in total variation within$\widetilde{O}(d^{5/4}/\sqrt{\varepsilon})$ iterations, thereby significantlyimproving upon the $\widetilde{O}(d/\varepsilon)$ iteration complexity ofstandard score-based samplers. Notably, our convergence theory does not rely onrestrictive assumptions on the target distribution or higher-order scoreestimation guarantees.</description><author>Gen Li, Changxiao Cai</author><pubDate>Wed, 30 Oct 2024 17:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23285v1</guid></item><item><title>RelationBooth: Towards Relation-Aware Customized Object Generation</title><link>http://arxiv.org/abs/2410.23280v1</link><description>Customized image generation is crucial for delivering personalized contentbased on user-provided image prompts, aligning large-scale text-to-imagediffusion models with individual needs. However, existing models often overlookthe relationships between customized objects in generated images. Instead, thiswork addresses that gap by focusing on relation-aware customized imagegeneration, which aims to preserve the identities from image prompts whilemaintaining the predicate relations described in text prompts. Specifically, weintroduce RelationBooth, a framework that disentangles identity and relationlearning through a well-curated dataset. Our training data consists ofrelation-specific images, independent object images containing identityinformation, and text prompts to guide relation generation. Then, we proposetwo key modules to tackle the two main challenges: generating accurate andnatural relations, especially when significant pose adjustments are required,and avoiding object confusion in cases of overlap. First, we introduce akeypoint matching loss that effectively guides the model in adjusting objectposes closely tied to their relationships. Second, we incorporate localfeatures from the image prompts to better distinguish between objects,preventing confusion in overlapping cases. Extensive results on threebenchmarks demonstrate the superiority of RelationBooth in generating preciserelations while preserving object identities across a diverse set of objectsand relations. The source code and trained models will be made available to thepublic.</description><author>Qingyu Shi, Lu Qi, Jianzong Wu, Jinbin Bai, Jingbo Wang, Yunhai Tong, Xiangtai Li, Ming-Husang Yang</author><pubDate>Wed, 30 Oct 2024 17:57:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23280v1</guid></item><item><title>A Neural Transformer Framework for Simultaneous Tasks of Segmentation, Classification, and Caller Identification of Marmoset Vocalization</title><link>http://arxiv.org/abs/2410.23279v1</link><description>Marmoset, a highly vocalized primate, has become a popular animal model forstudying social-communicative behavior and its underlying mechanism. In thestudy of vocal communication, it is vital to know the caller identities, callcontents, and vocal exchanges. Previous work of a CNN has achieved a jointmodel for call segmentation, classification, and caller identification formarmoset vocalizations. However, the CNN has limitations in modeling long-rangeacoustic patterns; the Transformer architecture that has been shown tooutperform CNNs, utilizes the self-attention mechanism that efficientlysegregates information parallelly over long distances and captures the globalstructure of marmoset vocalization. We propose using the Transformer to jointlysegment and classify the marmoset calls and identify the callers for eachvocalization.</description><author>Bin Wu, Sakriani Sakti, Shinnosuke Takamichi, Satoshi Nakamura</author><pubDate>Wed, 30 Oct 2024 17:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23279v1</guid></item><item><title>Guiding Through Complexity: What Makes Good Supervision for Hard Reasoning Tasks?</title><link>http://arxiv.org/abs/2410.20533v2</link><description>How can "weak teacher models" such as average human annotators or existing AIsystems, effectively supervise LLMs to improve performance on hard reasoningtasks, especially those that challenge and requires expertise or daily practicefrom the teacher models? In this paper, we seek for empirical answers to thisquestion by investigating various data-driven strategies that offer supervisiondata at different quality levels upon tasks of varying complexity. Twointuitive strategies emerge for teacher models to provide supervision duringalignment training: 1) using lower-quality supervision from complete tasks thatmatch the difficulty of the target reasoning tasks, and 2) leveraginghigher-quality supervision from easier subtasks that are less challenging.Interestingly, we find that even when the outcome error rate for hard tasksupervision is high (e.g., 90\%), training on such data can outperformperfectly correct supervision on easier subtasks on multiple hard mathbenchmarks. We further identify a more critical factor influencing trainingperformance: step-wise error rates, which indicate the severity of errors insolutions. Specifically, training on hard task supervision with the sameoutcome error rates but disparate step-wise error rates can lead to a 30\%accuracy gap on MATH benchmark. Our results also reveal that supplementing hardtask supervision with the corresponding subtask supervision can yield notableperformance improvements than simply combining rephrased hard full tasksupervision, suggesting new avenues for data augmentation. Data and code arereleased at \url{https://github.com/hexuan21/Weak-to-Strong}.</description><author>Xuan He, Da Yin, Nanyun Peng</author><pubDate>Wed, 30 Oct 2024 17:56:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20533v2</guid></item><item><title>OpenSatMap: A Fine-grained High-resolution Satellite Dataset for Large-scale Map Construction</title><link>http://arxiv.org/abs/2410.23278v1</link><description>In this paper, we propose OpenSatMap, a fine-grained, high-resolutionsatellite dataset for large-scale map construction. Map construction is one ofthe foundations of the transportation industry, such as navigation andautonomous driving. Extracting road structures from satellite images is anefficient way to construct large-scale maps. However, existing satellitedatasets provide only coarse semantic-level labels with a relatively lowresolution (up to level 19), impeding the advancement of this field. Incontrast, the proposed OpenSatMap (1) has fine-grained instance-levelannotations; (2) consists of high-resolution images (level 20); (3) iscurrently the largest one of its kind; (4) collects data with high diversity.Moreover, OpenSatMap covers and aligns with the popular nuScenes dataset andArgoverse 2 dataset to potentially advance autonomous driving technologies. Bypublishing and maintaining the dataset, we provide a high-quality benchmark forsatellite-based map construction and downstream tasks like autonomous driving.</description><author>Hongbo Zhao, Lue Fan, Yuntao Chen, Haochen Wang, yuran Yang, Xiaojuan Jin, Yixin Zhang, Gaofeng Meng, Zhaoxiang Zhang</author><pubDate>Wed, 30 Oct 2024 17:56:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23278v1</guid></item><item><title>SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation</title><link>http://arxiv.org/abs/2410.23277v1</link><description>Human beings are endowed with a complementary learning system, which bridgesthe slow learning of general world dynamics with fast storage of episodicmemory from a new experience. Previous video generation models, however,primarily focus on slow learning by pre-training on vast amounts of data,overlooking the fast learning phase crucial for episodic memory storage. Thisoversight leads to inconsistencies across temporally distant frames whengenerating longer videos, as these frames fall beyond the model's contextwindow. To this end, we introduce SlowFast-VGen, a novel dual-speed learningsystem for action-driven long video generation. Our approach incorporates amasked conditional video diffusion model for the slow learning of worlddynamics, alongside an inference-time fast learning strategy based on atemporal LoRA module. Specifically, the fast learning process updates itstemporal LoRA parameters based on local inputs and outputs, thereby efficientlystoring episodic memory in its parameters. We further propose a slow-fastlearning loop algorithm that seamlessly integrates the inner fast learning loopinto the outer slow learning loop, enabling the recall of prior multi-episodeexperiences for context-aware skill learning. To facilitate the slow learningof an approximate world model, we collect a large-scale dataset of 200k videoswith language action annotations, covering a wide range of scenarios. Extensiveexperiments show that SlowFast-VGen outperforms baselines across variousmetrics for action-driven video generation, achieving an FVD score of 514compared to 782, and maintaining consistency in longer videos, with an averageof 0.37 scene cuts versus 0.89. The slow-fast learning loop algorithmsignificantly enhances performances on long-horizon planning tasks as well.Project Website: https://slowfast-vgen.github.io</description><author>Yining Hong, Beide Liu, Maxine Wu, Yuanhao Zhai, Kai-Wei Chang, Lingjie Li, Kevin Lin, Chung-Ching Lin, Jianfeng Wang, Zhengyuan Yang, Yingnian Wu, Lijuan Wang</author><pubDate>Wed, 30 Oct 2024 17:55:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23277v1</guid></item><item><title>Emergent mechanisms for long timescales depend on training curriculum and affect performance in memory tasks</title><link>http://arxiv.org/abs/2309.12927v3</link><description>Recurrent neural networks (RNNs) in the brain and in silico excel at solvingtasks with intricate temporal dependencies. Long timescales required forsolving such tasks can arise from properties of individual neurons(single-neuron timescale, $\tau$, e.g., membrane time constant in biologicalneurons) or recurrent interactions among them (network-mediated timescale).However, the contribution of each mechanism for optimally solvingmemory-dependent tasks remains poorly understood. Here, we train RNNs to solve$N$-parity and $N$-delayed match-to-sample tasks with increasing memoryrequirements controlled by $N$ by simultaneously optimizing recurrent weightsand $\tau$s. We find that for both tasks RNNs develop longer timescales withincreasing $N$, but depending on the learning objective, they use differentmechanisms. Two distinct curricula define learning objectives: sequentiallearning of a single-$N$ (single-head) or simultaneous learning of multiple$N$s (multi-head). Single-head networks increase their $\tau$ with $N$ and areable to solve tasks for large $N$, but they suffer from catastrophicforgetting. However, multi-head networks, which are explicitly required to holdmultiple concurrent memories, keep $\tau$ constant and develop longertimescales through recurrent connectivity. Moreover, we show that themulti-head curriculum increases training speed and network stability toablations and perturbations, and allows RNNs to generalize better to tasksbeyond their training regime. This curriculum also significantly improvestraining GRUs and LSTMs for large-$N$ tasks. Our results suggest that adaptingtimescales to task requirements via recurrent interactions allows learning morecomplex objectives and improves the RNN's performance.</description><author>Sina Khajehabdollahi, Roxana Zeraati, Emmanouil Giannakakis, Tim Jakob Schäfer, Georg Martius, Anna Levina</author><pubDate>Wed, 30 Oct 2024 17:55:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.12927v3</guid></item><item><title>Conditional Forecasting of Margin Calls using Dynamic Graph Neural Networks</title><link>http://arxiv.org/abs/2410.23275v1</link><description>We introduce a novel Dynamic Graph Neural Network (DGNN) architecture forsolving conditional $m$-steps ahead forecasting problems in temporal financialnetworks. The proposed DGNN is validated on simulated data from a temporalfinancial network model capturing stylized features of Interest Rate Swaps(IRSs) transaction networks, where financial entities trade swap contractsdynamically and the network topology evolves conditionally on a reference rate.The proposed model is able to produce accurate conditional forecasts of netvariation margins up to a $21$-day horizon by leveraging conditionalinformation under pre-determined stress test scenarios. Our work shows that thenetwork dynamics can be successfully incorporated into stress-testingpractices, thus providing regulators and policymakers with a crucial tool forsystemic risk monitoring.</description><author>Matteo Citterio, Marco D'Errico, Gabriele Visentin</author><pubDate>Wed, 30 Oct 2024 17:55:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23275v1</guid></item><item><title>Multi-student Diffusion Distillation for Better One-step Generators</title><link>http://arxiv.org/abs/2410.23274v1</link><description>Diffusion models achieve high-quality sample generation at the cost of alengthy multistep inference procedure. To overcome this, diffusion distillationtechniques produce student generators capable of matching or surpassing theteacher in a single step. However, the student model's inference speed islimited by the size of the teacher architecture, preventing real-timegeneration for computationally heavy applications. In this work, we introduceMulti-Student Distillation (MSD), a framework to distill a conditional teacherdiffusion model into multiple single-step generators. Each student generator isresponsible for a subset of the conditioning data, thereby obtaining highergeneration quality for the same capacity. MSD trains multiple distilledstudents, allowing smaller sizes and, therefore, faster inference. Also, MSDoffers a lightweight quality boost over single-student distillation with thesame architecture. We demonstrate MSD is effective by training multiplesame-sized or smaller students on single-step distillation using distributionmatching and adversarial distillation techniques. With smaller students, MSDgets competitive results with faster inference for single-step generation.Using 4 same-sized students, MSD sets a new state-of-the-art for one-step imagegeneration: FID 1.20 on ImageNet-64x64 and 8.20 on zero-shot COCO2014.</description><author>Yanke Song, Jonathan Lorraine, Weili Nie, Karsten Kreis, James Lucas</author><pubDate>Wed, 30 Oct 2024 17:54:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23274v1</guid></item><item><title>Proportional Fairness in Non-Centroid Clustering</title><link>http://arxiv.org/abs/2410.23273v1</link><description>We revisit the recently developed framework of proportionally fairclustering, where the goal is to provide group fairness guarantees that becomestronger for groups of data points (agents) that are large and cohesive. Priorwork applies this framework to centroid clustering, where the loss of an agentis its distance to the centroid assigned to its cluster. We expand theframework to non-centroid clustering, where the loss of an agent is a functionof the other agents in its cluster, by adapting two proportional fairnesscriteria -- the core and its relaxation, fully justified representation (FJR)-- to this setting. We show that the core can be approximated only under structured lossfunctions, and even then, the best approximation we are able to establish,using an adaptation of the GreedyCapture algorithm developed for centroidclustering [Chen et al., 2019; Micha and Shah, 2020], is unappealing for anatural loss function. In contrast, we design a new (inefficient) algorithm,GreedyCohesiveClustering, which achieves the relaxation FJR exactly underarbitrary loss functions, and show that the efficient GreedyCapture algorithmachieves a constant approximation of FJR. We also design an efficient auditingalgorithm, which estimates the FJR approximation of any given clusteringsolution up to a constant factor. Our experiments on real data suggest thattraditional clustering algorithms are highly unfair, whereas GreedyCapture isconsiderably fairer and incurs only a modest loss in common clusteringobjectives.</description><author>Ioannis Caragiannis, Evi Micha, Nisarg Shah</author><pubDate>Wed, 30 Oct 2024 17:53:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23273v1</guid></item><item><title>A Monte Carlo Framework for Calibrated Uncertainty Estimation in Sequence Prediction</title><link>http://arxiv.org/abs/2410.23272v1</link><description>Probabilistic prediction of sequences from images and other high-dimensionaldata is a key challenge, particularly in risk-sensitive applications. In thesesettings, it is often desirable to quantify the uncertainty associated with theprediction (instead of just determining the most likely sequence, as inlanguage modeling). In this paper, we propose a Monte Carlo framework toestimate probabilities and confidence intervals associated with thedistribution of a discrete sequence. Our framework uses a Monte Carlosimulator, implemented as an autoregressively trained neural network, to samplesequences conditioned on an image input. We then use these samples to estimatethe probabilities and confidence intervals. Experiments on synthetic and realdata show that the framework produces accurate discriminative predictions, butcan suffer from miscalibration. In order to address this shortcoming, wepropose a time-dependent regularization method, which is shown to producecalibrated predictions.</description><author>Qidong Yang, Weicheng Zhu, Joseph Keslin, Laure Zanna, Tim G. J. Rudner, Carlos Fernandez-Granda</author><pubDate>Wed, 30 Oct 2024 17:53:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23272v1</guid></item><item><title>Adam with model exponential moving average is effective for nonconvex optimization</title><link>http://arxiv.org/abs/2405.18199v2</link><description>In this work, we offer a theoretical analysis of two modern optimizationtechniques for training large and complex models: (i) adaptive optimizationalgorithms, such as Adam, and (ii) the model exponential moving average (EMA).Specifically, we demonstrate that a clipped version of Adam with model EMAachieves the optimal convergence rates in various nonconvex optimizationsettings, both smooth and nonsmooth. Moreover, when the scale variessignificantly across different coordinates, we demonstrate that thecoordinate-wise adaptivity of Adam is provably advantageous. Notably, unlikeprevious analyses of Adam, our analysis crucially relies on its core elements-- momentum and discounting factors -- as well as model EMA, motivating theirwide applications in practice.</description><author>Kwangjun Ahn, Ashok Cutkosky</author><pubDate>Wed, 30 Oct 2024 17:51:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18199v2</guid></item><item><title>Towards Unifying Understanding and Generation in the Era of Vision Foundation Models: A Survey from the Autoregression Perspective</title><link>http://arxiv.org/abs/2410.22217v2</link><description>Autoregression in large language models (LLMs) has shown impressivescalability by unifying all language tasks into the next token predictionparadigm. Recently, there is a growing interest in extending this success tovision foundation models. In this survey, we review the recent advances anddiscuss future directions for autoregressive vision foundation models. First,we present the trend for next generation of vision foundation models, i.e.,unifying both understanding and generation in vision tasks. We then analyze thelimitations of existing vision foundation models, and present a formaldefinition of autoregression with its advantages. Later, we categorizeautoregressive vision foundation models from their vision tokenizers andautoregression backbones. Finally, we discuss several promising researchchallenges and directions. To the best of our knowledge, this is the firstsurvey to comprehensively summarize autoregressive vision foundation modelsunder the trend of unifying understanding and generation. A collection ofrelated resources is available at https://github.com/EmmaSRH/ARVFM.</description><author>Shenghao Xie, Wenqiang Zu, Mingyang Zhao, Duo Su, Shilong Liu, Ruohua Shi, Guoqi Li, Shanghang Zhang, Lei Ma</author><pubDate>Wed, 30 Oct 2024 17:51:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22217v2</guid></item><item><title>TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models</title><link>http://arxiv.org/abs/2410.23266v1</link><description>Existing benchmarks often highlight the remarkable performance achieved bystate-of-the-art Multimodal Foundation Models (MFMs) in leveraging temporalcontext for video understanding. However, how well do the models truly performvisual temporal reasoning? Our study of existing benchmarks shows that thiscapability of MFMs is likely overestimated as many questions can be solved byusing a single, few, or out-of-order frames. To systematically examine currentvisual temporal reasoning tasks, we propose three principles with correspondingmetrics: (1) Multi-Frame Gain, (2) Frame Order Sensitivity, and (3) FrameInformation Disparity. Following these principles, we introduce TOMATO,Temporal Reasoning Multimodal Evaluation, a novel benchmark crafted torigorously assess MFMs' temporal reasoning capabilities in video understanding.TOMATO comprises 1,484 carefully curated, human-annotated questions spanningsix tasks (i.e., action count, direction, rotation, shape &amp; trend, velocity &amp;frequency, and visual cues), applied to 1,417 videos, including 805self-recorded and -generated videos, that encompass human-centric, real-world,and simulated scenarios. Our comprehensive evaluation reveals a human-modelperformance gap of 57.3% with the best-performing model. Moreover, our in-depthanalysis uncovers more fundamental limitations beyond this gap in current MFMs.While they can accurately recognize events in isolated frames, they fail tointerpret these frames as a continuous sequence. We believe TOMATO will serveas a crucial testbed for evaluating the next-generation MFMs and as a call tothe community to develop AI systems capable of comprehending human worlddynamics through the video modality.</description><author>Ziyao Shangguan, Chuhan Li, Yuxuan Ding, Yanan Zheng, Yilun Zhao, Tesca Fitzgerald, Arman Cohan</author><pubDate>Wed, 30 Oct 2024 17:50:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23266v1</guid></item><item><title>Certified Robustness to Data Poisoning in Gradient-Based Training</title><link>http://arxiv.org/abs/2406.05670v2</link><description>Modern machine learning pipelines leverage large amounts of public data,making it infeasible to guarantee data quality and leaving models open topoisoning and backdoor attacks. Provably bounding model behavior under suchattacks remains an open problem. In this work, we address this challenge bydeveloping the first framework providing provable guarantees on the behavior ofmodels trained with potentially manipulated data without modifying the model orlearning algorithm. In particular, our framework certifies robustness againstuntargeted and targeted poisoning, as well as backdoor attacks, for bounded andunbounded manipulations of the training inputs and labels. Our method leveragesconvex relaxations to over-approximate the set of all possible parameterupdates for a given poisoning threat model, allowing us to bound the set of allreachable parameters for any gradient-based learning algorithm. Given this setof parameters, we provide bounds on worst-case behavior, including modelperformance and backdoor success rate. We demonstrate our approach on multiplereal-world datasets from applications including energy consumption, medicalimaging, and autonomous driving.</description><author>Philip Sosnin, Mark N. Müller, Maximilian Baader, Calvin Tsay, Matthew Wicker</author><pubDate>Wed, 30 Oct 2024 17:47:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05670v2</guid></item><item><title>EMMA: End-to-End Multimodal Model for Autonomous Driving</title><link>http://arxiv.org/abs/2410.23262v1</link><description>We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.Built on a multi-modal large language model foundation, EMMA directly maps rawcamera sensor data into various driving-specific outputs, including plannertrajectories, perception objects, and road graph elements. EMMA maximizes theutility of world knowledge from the pre-trained large language models, byrepresenting all non-sensor inputs (e.g. navigation instructions and egovehicle status) and outputs (e.g. trajectories and 3D locations) as naturallanguage text. This approach allows EMMA to jointly process various drivingtasks in a unified language space, and generate the outputs for each task usingtask-specific prompts. Empirically, we demonstrate EMMA's effectiveness byachieving state-of-the-art performance in motion planning on nuScenes as wellas competitive results on the Waymo Open Motion Dataset (WOMD). EMMA alsoyields competitive results for camera-primary 3D object detection on the WaymoOpen Dataset (WOD). We show that co-training EMMA with planner trajectories,object detection, and road graph tasks yields improvements across all threedomains, highlighting EMMA's potential as a generalist model for autonomousdriving applications. However, EMMA also exhibits certain limitations: it canprocess only a small amount of image frames, does not incorporate accurate 3Dsensing modalities like LiDAR or radar and is computationally expensive. Wehope that our results will inspire further research to mitigate these issuesand to further evolve the state of the art in autonomous driving modelarchitectures.</description><author>Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, James Guo, Dragomir Anguelov, Mingxing Tan</author><pubDate>Wed, 30 Oct 2024 17:46:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23262v1</guid></item><item><title>Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach</title><link>http://arxiv.org/abs/2410.00025v2</link><description>Recent progress in Spoken Language Modeling has shown that learning languagedirectly from speech is feasible. Generating speech through a pipeline thatoperates at the text level typically loses nuances, intonations, and non-verbalvocalizations. Modeling directly from speech opens up the path to more naturaland expressive systems. On the other hand, speech-only systems require up tothree orders of magnitude more data to catch up to their text-basedcounterparts in terms of their semantic abilities. We show that fine-tuningspeech representation models on phoneme classification leads to morecontext-invariant representations, and language models trained on these unitsachieve comparable lexical comprehension to ones trained on hundred times moredata.</description><author>Maxime Poli, Emmanuel Chemla, Emmanuel Dupoux</author><pubDate>Wed, 30 Oct 2024 17:46:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.00025v2</guid></item><item><title>$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources</title><link>http://arxiv.org/abs/2410.23261v1</link><description>Pre-training is notoriously compute-intensive and academic researchers arenotoriously under-resourced. It is, therefore, commonly assumed that academicscan't pre-train models. In this paper, we seek to clarify this assumption. Wefirst survey academic researchers to learn about their available compute andthen empirically measure the time to replicate models on such resources. Weintroduce a benchmark to measure the time to pre-train models on given GPUs andalso identify ideal settings for maximizing training speed. We run ourbenchmark on a range of models and academic GPUs, spending 2,000 GPU-hours onour experiments. Our results reveal a brighter picture for academicpre-training: for example, although Pythia-1B was originally trained on 64 GPUsfor 3 days, we find it is also possible to replicate this model (with the samehyper-parameters) in 3x fewer GPU-days: i.e. on 4 GPUs in 18 days. We concludewith a cost-benefit analysis to help clarify the trade-offs between price andpre-training time. We believe our benchmark will help academic researchersconduct experiments that require training larger models on more data. We fullyrelease our codebase at: https://github.com/apoorvkh/academic-pretraining.</description><author>Apoorv Khandelwal, Tian Yun, Nihal V. Nayak, Jack Merullo, Stephen H. Bach, Chen Sun, Ellie Pavlick</author><pubDate>Wed, 30 Oct 2024 17:46:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23261v1</guid></item><item><title>Extracting thin film structures of energy materials using transformers</title><link>http://arxiv.org/abs/2406.16741v2</link><description>Neutron-Transformer Reflectometry and Advanced Computation Engine (N-TRACE ),a neural network model using transformer architecture, is introduced forneutron reflectometry data analysis. It offers fast, accurate initial parameterestimations and efficient refinements, improving efficiency and precision forreal-time data analysis of lithium-mediated nitrogen reduction forelectrochemical ammonia synthesis, with relevance to other chemicaltransformations and batteries. Despite limitations in generalizing acrosssystems, it shows promises for the use of transformers as the basis for modelsthat could replace trial-and-error approaches to modeling reflectometry data.</description><author>Chen Zhang, Valerie A. Niemann, Peter Benedek, Thomas F. Jaramillo, Mathieu Doucet</author><pubDate>Wed, 30 Oct 2024 17:44:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16741v2</guid></item><item><title>DisC-GS: Discontinuity-aware Gaussian Splatting</title><link>http://arxiv.org/abs/2405.15196v2</link><description>Recently, Gaussian Splatting, a method that represents a 3D scene as acollection of Gaussian distributions, has gained significant attention inaddressing the task of novel view synthesis. In this paper, we highlight afundamental limitation of Gaussian Splatting: its inability to accuratelyrender discontinuities and boundaries in images due to the continuous nature ofGaussian distributions. To address this issue, we propose a novel frameworkenabling Gaussian Splatting to perform discontinuity-aware image rendering.Additionally, we introduce a B\'ezier-boundary gradient approximation strategywithin our framework to keep the "differentiability" of the proposeddiscontinuity-aware rendering process. Extensive experiments demonstrate theefficacy of our framework.</description><author>Haoxuan Qu, Zhuoling Li, Hossein Rahmani, Yujun Cai, Jun Liu</author><pubDate>Wed, 30 Oct 2024 17:38:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15196v2</guid></item><item><title>Keypoint Abstraction using Large Models for Object-Relative Imitation Learning</title><link>http://arxiv.org/abs/2410.23254v1</link><description>Generalization to novel object configurations and instances across diversetasks and environments is a critical challenge in robotics. Keypoint-basedrepresentations have been proven effective as a succinct representation forcapturing essential object features, and for establishing a reference frame inaction prediction, enabling data-efficient learning of robot skills. However,their manual design nature and reliance on additional human labels limit theirscalability. In this paper, we propose KALM, a framework that leverages largepre-trained vision-language models (LMs) to automatically generatetask-relevant and cross-instance consistent keypoints. KALM distills robust andconsistent keypoints across views and objects by generating proposals using LMsand verifies them against a small set of robot demonstration data. Based on thegenerated keypoints, we can train keypoint-conditioned policy models thatpredict actions in keypoint-centric frames, enabling robots to generalizeeffectively across varying object poses, camera views, and object instanceswith similar functional shapes. Our method demonstrates strong performance inthe real world, adapting to different tasks and environments from only ahandful of demonstrations while requiring no additional labels. Website:https://kalm-il.github.io/</description><author>Xiaolin Fang, Bo-Ruei Huang, Jiayuan Mao, Jasmine Shone, Joshua B. Tenenbaum, Tomás Lozano-Pérez, Leslie Pack Kaelbling</author><pubDate>Wed, 30 Oct 2024 17:37:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23254v1</guid></item><item><title>Derivative-enhanced Deep Operator Network</title><link>http://arxiv.org/abs/2402.19242v2</link><description>The deep operator networks (DeepONet), a class of neural operators that learnmappings between function spaces, have recently been developed as surrogatemodels for parametric partial differential equations (PDEs). In this work wepropose a derivative-enhanced deep operator network (DE-DeepONet), whichleverages derivative information to enhance the solution prediction accuracyand provides a more accurate approximation of solution-to-parameterderivatives, especially when training data are limited. DE-DeepONet explicitlyincorporates linear dimension reduction of high dimensional parameter inputinto DeepONet to reduce training cost and adds derivative loss in the lossfunction to reduce the number of required parameter-solution pairs. We furtherdemonstrate that the use of derivative loss can be extended to enhance otherneural operators, such as the Fourier neural operator (FNO). Numericalexperiments validate the effectiveness of our approach.</description><author>Yuan Qiu, Nolan Bridges, Peng Chen</author><pubDate>Wed, 30 Oct 2024 17:36:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19242v2</guid></item><item><title>Evaluating Cultural and Social Awareness of LLM Web Agents</title><link>http://arxiv.org/abs/2410.23252v1</link><description>As large language models (LLMs) expand into performing as agents forreal-world applications beyond traditional NLP tasks, evaluating theirrobustness becomes increasingly important. However, existing benchmarks oftenoverlook critical dimensions like cultural and social awareness. To addressthese, we introduce CASA, a benchmark designed to assess LLM agents'sensitivity to cultural and social norms across two web-based tasks: onlineshopping and social discussion forums. Our approach evaluates LLM agents'ability to detect and appropriately respond to norm-violating user queries andobservations. Furthermore, we propose a comprehensive evaluation framework thatmeasures awareness coverage, helpfulness in managing user queries, and theviolation rate when facing misleading web content. Experiments show thatcurrent LLMs perform significantly better in non-agent than in web-based agentenvironments, with agents achieving less than 10% awareness coverage and over40% violation rates. To improve performance, we explore two methods: promptingand fine-tuning, and find that combining both methods can offer complementaryadvantages -- fine-tuning on culture-specific datasets significantly enhancesthe agents' ability to generalize across different regions, while promptingboosts the agents' ability to navigate complex tasks. These findings highlightthe importance of constantly benchmarking LLM agents' cultural and socialawareness during the development cycle.</description><author>Haoyi Qiu, Alexander R. Fabbri, Divyansh Agarwal, Kung-Hsiang Huang, Sarah Tan, Nanyun Peng, Chien-Sheng Wu</author><pubDate>Wed, 30 Oct 2024 17:35:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23252v1</guid></item><item><title>Is Your LiDAR Placement Optimized for 3D Scene Understanding?</title><link>http://arxiv.org/abs/2403.17009v2</link><description>The reliability of driving perception systems under unprecedented conditionsis crucial for practical usage. Latest advancements have prompted increasinginterest in multi-LiDAR perception. However, prevailing driving datasetspredominantly utilize single-LiDAR systems and collect data devoid of adverseconditions, failing to capture the complexities of real-world environmentsaccurately. Addressing these gaps, we proposed Place3D, a full-cycle pipelinethat encompasses LiDAR placement optimization, data generation, and downstreamevaluations. Our framework makes three appealing contributions. 1) To identifythe most effective configurations for multi-LiDAR systems, we introduce theSurrogate Metric of the Semantic Occupancy Grids (M-SOG) to evaluate LiDARplacement quality. 2) Leveraging the M-SOG metric, we propose a noveloptimization strategy to refine multi-LiDAR placements. 3) Centered around thetheme of multi-condition multi-LiDAR perception, we collect a 280,000-framedataset from both clean and adverse conditions. Extensive experimentsdemonstrate that LiDAR placements optimized using our approach outperformvarious baselines. We showcase exceptional results in both LiDAR semanticsegmentation and 3D object detection tasks, under diverse weather and sensorfailure conditions.</description><author>Ye Li, Lingdong Kong, Hanjiang Hu, Xiaohao Xu, Xiaonan Huang</author><pubDate>Wed, 30 Oct 2024 17:35:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17009v2</guid></item><item><title>bit2bit: 1-bit quanta video reconstruction via self-supervised photon prediction</title><link>http://arxiv.org/abs/2410.23247v1</link><description>Quanta image sensors, such as SPAD arrays, are an emerging sensor technology,producing 1-bit arrays representing photon detection events over exposures asshort as a few nanoseconds. In practice, raw data are post-processed usingheavy spatiotemporal binning to create more useful and interpretable images atthe cost of degrading spatiotemporal resolution. In this work, we proposebit2bit, a new method for reconstructing high-quality image stacks at theoriginal spatiotemporal resolution from sparse binary quanta image data.Inspired by recent work on Poisson denoising, we developed an algorithm thatcreates a dense image sequence from sparse binary photon data by predicting thephoton arrival location probability distribution. However, due to the binarynature of the data, we show that the assumption of a Poisson distribution isinadequate. Instead, we model the process with a Bernoulli lattice process fromthe truncated Poisson. This leads to the proposal of a novel self-supervisedsolution based on a masked loss function. We evaluate our method using bothsimulated and real data. On simulated data from a conventional video, weachieve 34.35 mean PSNR with extremely photon-sparse binary input (&lt;0.06photons per pixel per frame). We also present a novel dataset containing a widerange of real SPAD high-speed videos under various challenging imagingconditions. The scenes cover strong/weak ambient light, strong motion,ultra-fast events, etc., which will be made available to the community, onwhich we demonstrate the promise of our approach. Both reconstruction qualityand throughput substantially surpass the state-of-the-art methods (e.g., QuantaBurst Photography (QBP)). Our approach significantly enhances the visualizationand usability of the data, enabling the application of existing analysistechniques.</description><author>Yehe Liu, Alexander Krull, Hector Basevi, Ales Leonardis, Michael W. Jenkins</author><pubDate>Wed, 30 Oct 2024 17:30:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23247v1</guid></item><item><title>Progression: an extrapolation principle for regression</title><link>http://arxiv.org/abs/2410.23246v1</link><description>The problem of regression extrapolation, or out-of-distributiongeneralization, arises when predictions are required at test points outside therange of the training data. In such cases, the non-parametric guarantees forregression methods from both statistics and machine learning typically fail.Based on the theory of tail dependence, we propose a novel statisticalextrapolation principle. After a suitable, data-adaptive marginaltransformation, it assumes a simple relationship between predictors and theresponse at the boundary of the training predictor samples. This assumptionholds for a wide range of models, including non-parametric regression functionswith additive noise. Our semi-parametric method, progression, leverages thisextrapolation principle and offers guarantees on the approximation error beyondthe training data range. We demonstrate how this principle can be effectivelyintegrated with existing approaches, such as random forests and additivemodels, to improve extrapolation performance on out-of-distribution samples.</description><author>Gloria Buriticá, Sebastian Engelke</author><pubDate>Wed, 30 Oct 2024 17:29:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23246v1</guid></item><item><title>PointRecon: Online Point-based 3D Reconstruction via Ray-based 2D-3D Matching</title><link>http://arxiv.org/abs/2410.23245v1</link><description>We propose a novel online, point-based 3D reconstruction method from posedmonocular RGB videos. Our model maintains a global point cloud representationof the scene, continuously updating the features and 3D locations of points asnew images are observed. It expands the point cloud with newly detected pointswhile carefully removing redundancies. The point cloud updates and depthpredictions for new points are achieved through a novel ray-based 2D-3D featurematching technique, which is robust against errors in previous point positionpredictions. In contrast to offline methods, our approach processesinfinite-length sequences and provides real-time updates. Additionally, thepoint cloud imposes no pre-defined resolution or scene size constraints, andits unified global representation ensures view consistency across perspectives.Experiments on the ScanNet dataset show that our method achievesstate-of-the-art quality among online MVS approaches. Project page:https://arthurhero.github.io/projects/pointrecon</description><author>Chen Ziwen, Zexiang Xu, Li Fuxin</author><pubDate>Wed, 30 Oct 2024 17:29:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23245v1</guid></item><item><title>Very fast Bayesian Additive Regression Trees on GPU</title><link>http://arxiv.org/abs/2410.23244v1</link><description>Bayesian Additive Regression Trees (BART) is a nonparametric Bayesianregression technique based on an ensemble of decision trees. It is part of thetoolbox of many statisticians. The overall statistical quality of theregression is typically higher than other generic alternatives, and it requiresless manual tuning, making it a good default choice. However, it is a nichemethod compared to its natural competitor XGBoost, due to the longer runningtime, making sample sizes above 10,000-100,000 a nuisance. I present aGPU-enabled implementation of BART, faster by up to 200x relative to a singleCPU core, making BART competitive in running time with XGBoost. Thisimplementation is available in the Python package bartz.</description><author>Giacomo Petrillo</author><pubDate>Wed, 30 Oct 2024 17:29:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23244v1</guid></item><item><title>A little less conversation, a little more action, please: Investigating the physical common-sense of LLMs in a 3D embodied environment</title><link>http://arxiv.org/abs/2410.23242v1</link><description>As general-purpose tools, Large Language Models (LLMs) must often reasonabout everyday physical environments. In a question-and-answer capacity,understanding the interactions of physical objects may be necessary to giveappropriate responses. Moreover, LLMs are increasingly used as reasoningengines in agentic systems, designing and controlling their action sequences.The vast majority of research has tackled this issue using static benchmarks,comprised of text or image-based questions about the physical world. However,these benchmarks do not capture the complexity and nuance of real-life physicalprocesses. Here we advocate for a second, relatively unexplored, approach:'embodying' the LLMs by granting them control of an agent within a 3Denvironment. We present the first embodied and cognitively meaningfulevaluation of physical common-sense reasoning in LLMs. Our framework allowsdirect comparison of LLMs with other embodied agents, such as those based onDeep Reinforcement Learning, and human and non-human animals. We employ theAnimal-AI (AAI) environment, a simulated 3D virtual laboratory, to studyphysical common-sense reasoning in LLMs. For this, we use the AAI Testbed, asuite of experiments that replicate laboratory studies with non-human animals,to study physical reasoning capabilities including distance estimation,tracking out-of-sight objects, and tool use. We demonstrate thatstate-of-the-art multi-modal models with no finetuning can complete this styleof task, allowing meaningful comparison to the entrants of the 2019 Animal-AIOlympics competition and to human children. Our results show that LLMs arecurrently outperformed by human children on these tasks. We argue that thisapproach allows the study of physical reasoning using ecologically validexperiments drawn directly from cognitive science, improving the predictabilityand reliability of LLMs.</description><author>Matteo G. Mecattaf, Ben Slater, Marko Tešić, Jonathan Prunty, Konstantinos Voudouris, Lucy G. Cheke</author><pubDate>Wed, 30 Oct 2024 17:28:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23242v1</guid></item><item><title>Super-resolution in disordered media using neural networks</title><link>http://arxiv.org/abs/2410.21556v2</link><description>We propose a methodology that exploits large and diverse data sets toaccurately estimate the ambient medium's Green's functions in stronglyscattering media. Given these estimates, obtained with and without the use ofneural networks, excellent imaging results are achieved, with a resolution thatis better than that of a homogeneous medium. This phenomenon, also known assuper-resolution, occurs because the ambient scattering medium effectivelyenhances the physical imaging aperture.</description><author>Alexander Christie, Matan Leibovich, Miguel Moscoso, Alexei Novikov, George Papanicolaou, Chrysoula Tsogka</author><pubDate>Wed, 30 Oct 2024 17:27:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21556v2</guid></item><item><title>Full-waveform earthquake source inversion using simulation-based inference</title><link>http://arxiv.org/abs/2410.23238v1</link><description>This paper presents a novel framework for full-waveform seismic sourceinversion using simulation-based inference (SBI). Traditional probabilisticapproaches often rely on simplifying assumptions about data errors, which weshow can lead to inaccurate uncertainty quantification. SBI addresses thislimitation by building an empirical probabilistic model of the data errorsusing machine learning models, known as neural density estimators, which canthen be integrated into the Bayesian inference framework. We apply the SBIframework to point-source moment tensor inversions as well as joint momenttensor and time-location inversions. We construct a range of synthetic examplesto explore the quality of the SBI solutions, as well as to compare the SBIresults with standard Gaussian likelihood-based Bayesian inversions. We thendemonstrate that under real seismic noise, common Gaussian likelihoodassumptions for treating full-waveform data yield overconfident posteriordistributions that underestimate the moment tensor component uncertainties byup to a factor of 3. We contrast this with SBI, which produces well-calibratedposteriors that generally agree with the true seismic source parameters, andoffers an order-of-magnitude reduction in the number of simulations required toperform inference compared to standard Monte Carlo techniques. Finally, weapply our methodology to a pair of moderate magnitude earthquakes in the NorthAtlantic. We utilise seismic waveforms recorded by the recent UPFLOW oceanbottom seismometer array as well as by regional land stations in the Azores,comparing full moment tensor and source-time location posteriors between SBIand a Gaussian likelihood approach. We find that our adaptation of SBI can bedirectly applied to real earthquake sources to efficiently produce high qualityposterior distributions that significantly improve upon Gaussian likelihoodapproaches.</description><author>A. A. Saoulis, D. Piras, A. Spurio Mancini, B. Joachimi, A. M. G. Ferreira</author><pubDate>Wed, 30 Oct 2024 17:25:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23238v1</guid></item><item><title>EMOTION: Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning</title><link>http://arxiv.org/abs/2410.23234v1</link><description>This paper introduces a framework, called EMOTION, for generating expressivemotion sequences in humanoid robots, enhancing their ability to engage inhumanlike non-verbal communication. Non-verbal cues such as facial expressions,gestures, and body movements play a crucial role in effective interpersonalinteractions. Despite the advancements in robotic behaviors, existing methodsoften fall short in mimicking the diversity and subtlety of human non-verbalcommunication. To address this gap, our approach leverages the in-contextlearning capability of large language models (LLMs) to dynamically generatesocially appropriate gesture motion sequences for human-robot interaction. Weuse this framework to generate 10 different expressive gestures and conductonline user studies comparing the naturalness and understandability of themotions generated by EMOTION and its human-feedback version, EMOTION++, againstthose by human operators. The results demonstrate that our approach eithermatches or surpasses human performance in generating understandable and naturalrobot motions under certain scenarios. We also provide design implications forfuture research to consider a set of variables when generating expressiverobotic gestures.</description><author>Peide Huang, Yuhan Hu, Nataliya Nechyporenko, Daehwa Kim, Walter Talbott, Jian Zhang</author><pubDate>Wed, 30 Oct 2024 17:22:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23234v1</guid></item><item><title>CoTran: An LLM-based Code Translator using Reinforcement Learning with Feedback from Compiler and Symbolic Execution</title><link>http://arxiv.org/abs/2306.06755v4</link><description>In this paper, we present an LLM-based code translation method and anassociated tool called CoTran, that translates whole-programs from onehigh-level programming language to another. Existing LLM-based code translationmethods lack training to ensure that the translated code reliably compiles orbears substantial functional equivalence to the input code. In our work, wefine-tune an LLM using reinforcement learning, incorporating compiler feedback,and symbolic execution (symexec)-based testing feedback to assess functionalequivalence between the input and output programs. The idea is to guide an LLMduring fine-tuning, via compiler and symexec-based testing feedback, by lettingit know how far it is from producing perfect translations. We conduct extensiveexperiments comparing CoTran with 14 other code translation tools, includinghuman-written transpilers, LLM-based translation tools, and ChatGPT. Using abenchmark of over \num{57000} code pairs in Java and Python, we demonstratethat CoTran outperforms the other tools on relevant metrics such as compilationaccuracy (CompAcc) and functional equivalence accuracy (FEqAcc). For example,in Python-to-Java translation, CoTran achieves 48.68% FEqAcc and 76.98%CompAcc, whereas the nearest competing tool (PLBART-base) gets 38.26% and75.77% respectively. Additionally, CoTran, built on top of CodeT5, improvesFEqAcc by +14.89% and CompAcc by +8.14% for Python-to-Java (resp., +12.94% and+4.30% for Java-to-Python).</description><author>Prithwish Jana, Piyush Jha, Haoyang Ju, Gautham Kishore, Aryan Mahajan, Vijay Ganesh</author><pubDate>Wed, 30 Oct 2024 17:22:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06755v4</guid></item><item><title>Joint Estimation of Conditional Mean and Covariance for Unbalanced Panels</title><link>http://arxiv.org/abs/2410.21858v2</link><description>We propose a novel nonparametric kernel-based estimator of cross-sectionalconditional mean and covariance matrices for large unbalanced panels. We showits consistency and provide finite-sample guarantees. In an empiricalapplication, we estimate conditional mean and covariance matrices for a largeunbalanced panel of monthly stock excess returns given macroeconomic andfirm-specific covariates from 1962 to 2021.The estimator performs well withrespect to statistical measures. It is informative for empirical asset pricing,generating conditional mean-variance efficient portfolios with substantialout-of-sample Sharpe ratios far beyond equal-weighted benchmarks.</description><author>Damir Filipovic, Paul Schneider</author><pubDate>Wed, 30 Oct 2024 17:21:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21858v2</guid></item><item><title>Attribute-to-Delete: Machine Unlearning via Datamodel Matching</title><link>http://arxiv.org/abs/2410.23232v1</link><description>Machine unlearning -- efficiently removing the effect of a small "forget set"of training data on a pre-trained machine learning model -- has recentlyattracted significant research interest. Despite this interest, however, recentwork shows that existing machine unlearning techniques do not hold up tothorough evaluation in non-convex settings. In this work, we introduce a newmachine unlearning technique that exhibits strong empirical performance even insuch challenging settings. Our starting point is the perspective that the goalof unlearning is to produce a model whose outputs are statisticallyindistinguishable from those of a model re-trained on all but the forget set.This perspective naturally suggests a reduction from the unlearning problem tothat of data attribution, where the goal is to predict the effect of changingthe training set on a model's outputs. Thus motivated, we propose the followingmeta-algorithm, which we call Datamodel Matching (DMM): given a trained model,we (a) use data attribution to predict the output of the model if it werere-trained on all but the forget set points; then (b) fine-tune the pre-trainedmodel to match these predicted outputs. In a simple convex setting, we show howthis approach provably outperforms a variety of iterative unlearningalgorithms. Empirically, we use a combination of existing evaluations and a newmetric based on the KL-divergence to show that even in non-convex settings, DMMachieves strong unlearning performance relative to existing algorithms. Anadded benefit of DMM is that it is a meta-algorithm, in the sense that futureadvances in data attribution translate directly into better unlearningalgorithms, pointing to a clear direction for future progress in unlearning.</description><author>Kristian Georgiev, Roy Rinberg, Sung Min Park, Shivam Garg, Andrew Ilyas, Aleksander Madry, Seth Neel</author><pubDate>Wed, 30 Oct 2024 17:20:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23232v1</guid></item><item><title>LGU-SLAM: Learnable Gaussian Uncertainty Matching with Deformable Correlation Sampling for Deep Visual SLAM</title><link>http://arxiv.org/abs/2410.23231v1</link><description>Deep visual Simultaneous Localization and Mapping (SLAM) techniques, e.g.,DROID, have made significant advancements by leveraging deep visual odometry ondense flow fields. In general, they heavily rely on global visual similaritymatching. However, the ambiguous similarity interference in uncertain regionscould often lead to excessive noise in correspondences, ultimately misleadingSLAM in geometric modeling. To address this issue, we propose a LearnableGaussian Uncertainty (LGU) matching. It mainly focuses on precisecorrespondence construction. In our scheme, a learnable 2D Gaussian uncertaintymodel is designed to associate matching-frame pairs. It could generateinput-dependent Gaussian distributions for each correspondence map.Additionally, a multi-scale deformable correlation sampling strategy is devisedto adaptively fine-tune the sampling of each direction by a priori look-upranges, enabling reliable correlation construction. Furthermore, a KAN-bias GRUcomponent is adopted to improve a temporal iterative enhancement foraccomplishing sophisticated spatio-temporal modeling with limited parameters.The extensive experiments on real-world and synthetic datasets are conducted tovalidate the effectiveness and superiority of our method.</description><author>Yucheng Huang, Luping Ji, Hudong Liu, Mao Ye</author><pubDate>Wed, 30 Oct 2024 17:20:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23231v1</guid></item><item><title>Entrywise error bounds for low-rank approximations of kernel matrices</title><link>http://arxiv.org/abs/2405.14494v2</link><description>In this paper, we derive entrywise error bounds for low-rank approximationsof kernel matrices obtained using the truncated eigen-decomposition (orsingular value decomposition). While this approximation is well-known to beoptimal with respect to the spectral and Frobenius norm error, little is knownabout the statistical behaviour of individual entries. Our error bounds fillthis gap. A key technical innovation is a delocalisation result for theeigenvectors of the kernel matrix corresponding to small eigenvalues, whichtakes inspiration from the field of Random Matrix Theory. Finally, we validateour theory with an empirical study of a collection of synthetic and real-worlddatasets.</description><author>Alexander Modell</author><pubDate>Wed, 30 Oct 2024 17:17:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14494v2</guid></item><item><title>Breach By A Thousand Leaks: Unsafe Information Leakage in `Safe' AI Responses</title><link>http://arxiv.org/abs/2407.02551v2</link><description>Vulnerability of Frontier language models to misuse and jailbreaks hasprompted the development of safety measures like filters and alignment trainingin an effort to ensure safety through robustness to adversarially craftedprompts. We assert that robustness is fundamentally insufficient for ensuringsafety goals, and current defenses and evaluation methods fail to account forrisks of dual-intent queries and their composition for malicious goals. Toquantify these risks, we introduce a new safety evaluation framework based onimpermissible information leakage of model outputs and demonstrate how ourproposed question-decomposition attack can extract dangerous knowledge from acensored LLM more effectively than traditional jailbreaking. Underlying ourproposed evaluation method is a novel information-theoretic threat model ofinferential adversaries, distinguished from security adversaries, such asjailbreaks, in that success is measured by inferring impermissible knowledgefrom victim outputs as opposed to forcing explicitly impermissible outputs fromthe victim. Through our information-theoretic framework, we show that to ensuresafety against inferential adversaries, defense mechanisms must ensureinformation censorship, bounding the leakage of impermissible information.However, we prove that such defenses inevitably incur a safety-utilitytrade-off.</description><author>David Glukhov, Ziwen Han, Ilia Shumailov, Vardan Papyan, Nicolas Papernot</author><pubDate>Wed, 30 Oct 2024 17:16:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.02551v2</guid></item><item><title>Emergence of meta-stable clustering in mean-field transformer models</title><link>http://arxiv.org/abs/2410.23228v1</link><description>We model the evolution of tokens within a deep stack of Transformer layers asa continuous-time flow on the unit sphere, governed by a mean-field interactingparticle system, building on the framework introduced in (Geshkovski et al.,2023). Studying the corresponding mean-field Partial Differential Equation(PDE), which can be interpreted as a Wasserstein gradient flow, in this paperwe provide a mathematical investigation of the long-term behavior of thissystem, with a particular focus on the emergence and persistence of meta-stablephases and clustering phenomena, key elements in applications like next-tokenprediction. More specifically, we perform a perturbative analysis of themean-field PDE around the iid uniform initialization and prove that, in thelimit of large number of tokens, the model remains close to a meta-stablemanifold of solutions with a given structure (e.g., periodicity). Further, thestructure characterizing the meta-stable manifold is explicitly identified, asa function of the inverse temperature parameter of the model, by the indexmaximizing a certain rescaling of Gegenbauer polynomials.</description><author>Giuseppe Bruno, Federico Pasqualotto, Andrea Agazzi</author><pubDate>Wed, 30 Oct 2024 17:16:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23228v1</guid></item><item><title>COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences</title><link>http://arxiv.org/abs/2410.23223v1</link><description>Many alignment methods, including reinforcement learning from human feedback(RLHF), rely on the Bradley-Terry reward assumption, which is insufficient tocapture the full range of general human preferences. To achieve robustalignment with general preferences, we model the alignment problem as atwo-player zero-sum game, where the Nash equilibrium policy guarantees a 50%win rate against any competing policy. However, previous algorithms for findingthe Nash policy either diverge or converge to a Nash policy in a modified game,even in a simple synthetic setting, thereby failing to maintain the 50% winrate guarantee against all other policies. We propose a meta-algorithm,Convergent Meta Alignment Algorithm (COMAL), for language model alignment withgeneral preferences, inspired by convergent algorithms in game theory.Theoretically, we prove that our meta-algorithm converges to an exact Nashpolicy in the last iterate. Additionally, our meta-algorithm is simple and canbe integrated with many existing methods designed for RLHF and preferenceoptimization with minimal changes. Experimental results demonstrate theeffectiveness of the proposed framework when combined with existing preferencepolicy optimization methods.</description><author>Yixin Liu, Argyris Oikonomou, Weiqiang Zheng, Yang Cai, Arman Cohan</author><pubDate>Wed, 30 Oct 2024 17:13:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23223v1</guid></item><item><title>Generative linguistics contribution to artificial intelligence: Where this contribution lies?</title><link>http://arxiv.org/abs/2410.20221v2</link><description>This article aims to characterize Generative linguistics (GL) contribution toartificial intelligence (AI), alluding to the debate among linguists and AIscientists on whether linguistics belongs to humanities or science. In thisarticle, I will try not to be biased as a linguist, studying the phenomenonfrom an independent scientific perspective. The article walks theresearcher/reader through the scientific theorems and rationales involved in AIwhich belong from GL, specifically the Chomsky School. It, thus, provides goodevidence from syntax, semantics, language faculty, Universal Grammar,computational system of human language, language acquisition, human brain,programming languages (e.g. Python), Large Language Models, and unbiased AIscientists that this contribution is huge, and that this contribution cannot bedenied. It concludes that however the huge GL contribution to AI, there arestill points of divergence including the nature and type of language input.</description><author>Mohammed Q. Shormani</author><pubDate>Wed, 30 Oct 2024 17:12:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20221v2</guid></item><item><title>Partial Channel Dependence with Channel Masks for Time Series Foundation Models</title><link>http://arxiv.org/abs/2410.23222v1</link><description>Recent advancements in foundation models have been successfully extended tothe time series (TS) domain, facilitated by the emergence of large-scale TSdatasets. However, previous efforts have primarily focused on designing modelarchitectures to address explicit heterogeneity among datasets such as variousnumbers of channels, while often overlooking implicit heterogeneity such asvarying dependencies between channels. In this work, we introduce the conceptof partial channel dependence (PCD), which enables a more sophisticatedadjustment of channel dependencies based on dataset-specific information. Toachieve PCD, we propose a channel mask that captures the relationships betweenchannels within a dataset using two key components: 1) a correlation matrixthat encodes relative dependencies between channels, and 2) domain parametersthat learn the absolute dependencies specific to each dataset, refining thecorrelation matrix. We validate the effectiveness of PCD across four tasks inTS including forecasting, classification, imputation, and anomaly detection,under diverse settings, including few-shot and zero-shot scenarios with both TSfoundation models and single-task models. Code is available athttps://github.com/seunghan96/CM.</description><author>Seunghan Lee, Taeyoung Park, Kibok Lee</author><pubDate>Wed, 30 Oct 2024 17:12:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23222v1</guid></item><item><title>DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET</title><link>http://arxiv.org/abs/2410.23219v1</link><description>Diagnosing dementia, particularly for Alzheimer's Disease (AD) andfrontotemporal dementia (FTD), is complex due to overlapping symptoms. Whilemagnetic resonance imaging (MRI) and positron emission tomography (PET) dataare critical for the diagnosis, integrating these modalities in deep learningfaces challenges, often resulting in suboptimal performance compared to usingsingle modalities. Moreover, the potential of multi-modal approaches indifferential diagnosis, which holds significant clinical importance, remainslargely unexplored. We propose a novel framework, DiaMond, to address theseissues with vision Transformers to effectively integrate MRI and PET. DiaMondis equipped with self-attention and a novel bi-attention mechanism thatsynergistically combine MRI and PET, alongside a multi-modal normalization toreduce redundant dependency, thereby boosting the performance. DiaMondsignificantly outperforms existing multi-modal methods across various datasets,achieving a balanced accuracy of 92.4% in AD diagnosis, 65.2% for AD-MCI-CNclassification, and 76.5% in differential diagnosis of AD and FTD. We alsovalidated the robustness of DiaMond in a comprehensive ablation study. The codeis available at https://github.com/ai-med/DiaMond.</description><author>Yitong Li, Morteza Ghahremani, Youssef Wally, Christian Wachinger</author><pubDate>Wed, 30 Oct 2024 17:11:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23219v1</guid></item><item><title>Bandits with Preference Feedback: A Stackelberg Game Perspective</title><link>http://arxiv.org/abs/2406.16745v2</link><description>Bandits with preference feedback present a powerful tool for optimizingunknown target functions when only pairwise comparisons are allowed instead ofdirect value queries. This model allows for incorporating human feedback intoonline inference and optimization and has been employed in systems forfine-tuning large language models. The problem is well understood in simplifiedsettings with linear target functions or over finite small domains that limitpractical interest. Taking the next step, we consider infinite domains andnonlinear (kernelized) rewards. In this setting, selecting a pair of actions isquite challenging and requires balancing exploration and exploitation at twolevels: within the pair, and along the iterations of the algorithm. We proposeMAXMINLCB, which emulates this trade-off as a zero-sum Stackelberg game, andchooses action pairs that are informative and yield favorable rewards.MAXMINLCB consistently outperforms existing algorithms and satisfies ananytime-valid rate-optimal regret guarantee. This is due to our novelpreference-based confidence sequences for kernelized logistic estimators.</description><author>Barna Pásztor, Parnian Kassraie, Andreas Krause</author><pubDate>Wed, 30 Oct 2024 17:10:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16745v2</guid></item><item><title>OS-ATLAS: A Foundation Action Model for Generalist GUI Agents</title><link>http://arxiv.org/abs/2410.23218v1</link><description>Existing efforts in building GUI agents heavily rely on the availability ofrobust commercial Vision-Language Models (VLMs) such as GPT-4o andGeminiProVision. Practitioners are often reluctant to use open-source VLMs dueto their significant performance lag compared to their closed-sourcecounterparts, particularly in GUI grounding and Out-Of-Distribution (OOD)scenarios. To facilitate future research in this area, we developed OS-Atlas -a foundational GUI action model that excels at GUI grounding and OOD agentictasks through innovations in both data and modeling. We have investedsignificant engineering effort in developing an open-source toolkit forsynthesizing GUI grounding data across multiple platforms, including Windows,Linux, MacOS, Android, and the web. Leveraging this toolkit, we are releasingthe largest open-source cross-platform GUI grounding corpus to date, whichcontains over 13 million GUI elements. This dataset, combined with innovationsin model training, provides a solid foundation for OS-Atlas to understand GUIscreenshots and generalize to unseen interfaces. Through extensive evaluationacross six benchmarks spanning three different platforms (mobile, desktop, andweb), OS-Atlas demonstrates significant performance improvements over previousstate-of-the-art models. Our evaluation also uncovers valuable insights intocontinuously improving and scaling the agentic capabilities of open-sourceVLMs.</description><author>Zhiyong Wu, Zhenyu Wu, Fangzhi Xu, Yian Wang, Qiushi Sun, Chengyou Jia, Kanzhi Cheng, Zichen Ding, Liheng Chen, Paul Pu Liang, Yu Qiao</author><pubDate>Wed, 30 Oct 2024 17:10:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23218v1</guid></item><item><title>CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision Language Models</title><link>http://arxiv.org/abs/2406.06007v2</link><description>Artificial intelligence has significantly impacted medical applications,particularly with the advent of Medical Large Vision Language Models(Med-LVLMs), sparking optimism for the future of automated and personalizedhealthcare. However, the trustworthiness of Med-LVLMs remains unverified,posing significant risks for future model deployment. In this paper, weintroduce CARES and aim to comprehensively evaluate the Trustworthiness ofMed-LVLMs across the medical domain. We assess the trustworthiness of Med-LVLMsacross five dimensions, including trustfulness, fairness, safety, privacy, androbustness. CARES comprises about 41K question-answer pairs in both closed andopen-ended formats, covering 16 medical image modalities and 27 anatomicalregions. Our analysis reveals that the models consistently exhibit concernsregarding trustworthiness, often displaying factual inaccuracies and failing tomaintain fairness across different demographic groups. Furthermore, they arevulnerable to attacks and demonstrate a lack of privacy awareness. We publiclyrelease our benchmark and code in https://cares-ai.github.io/.</description><author>Peng Xia, Ze Chen, Juanxi Tian, Yangrui Gong, Ruibo Hou, Yue Xu, Zhenbang Wu, Zhiyuan Fan, Yiyang Zhou, Kangyu Zhu, Wenhao Zheng, Zhaoyang Wang, Xiao Wang, Xuchao Zhang, Chetan Bansal, Marc Niethammer, Junzhou Huang, Hongtu Zhu, Yun Li, Jimeng Sun, Zongyuan Ge, Gang Li, James Zou, Huaxiu Yao</author><pubDate>Wed, 30 Oct 2024 17:08:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06007v2</guid></item><item><title>StyleAdapter: A Unified Stylized Image Generation Model</title><link>http://arxiv.org/abs/2309.01770v2</link><description>This work focuses on generating high-quality images with specific style ofreference images and content of provided textual descriptions. Current leadingalgorithms, i.e., DreamBooth and LoRA, require fine-tuning for each style,leading to time-consuming and computationally expensive processes. In thiswork, we propose StyleAdapter, a unified stylized image generation modelcapable of producing a variety of stylized images that match both the contentof a given prompt and the style of reference images, without the need forper-style fine-tuning. It introduces a two-path cross-attention (TPCA) moduleto separately process style information and textual prompt, which cooperatewith a semantic suppressing vision model (SSVM) to suppress the semanticcontent of style images. In this way, it can ensure that the prompt maintainscontrol over the content of the generated images, while also mitigating thenegative impact of semantic information in style references. This results inthe content of the generated image adhering to the prompt, and its stylealigning with the style references. Besides, our StyleAdapter can be integratedwith existing controllable synthesis methods, such as T2I-adapter andControlNet, to attain a more controllable and stable generation process.Extensive experiments demonstrate the superiority of our method over previousworks.</description><author>Zhouxia Wang, Xintao Wang, Liangbin Xie, Zhongang Qi, Ying Shan, Wenping Wang, Ping Luo</author><pubDate>Wed, 30 Oct 2024 17:05:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01770v2</guid></item><item><title>ELMGS: Enhancing memory and computation scaLability through coMpression for 3D Gaussian Splatting</title><link>http://arxiv.org/abs/2410.23213v1</link><description>3D models have recently been popularized by the potentiality of end-to-endtraining offered first by Neural Radiance Fields and most recently by 3DGaussian Splatting models. The latter has the big advantage of naturallyproviding fast training convergence and high editability. However, as theresearch around these is still in its infancy, there is still a gap in theliterature regarding the model's scalability. In this work, we propose anapproach enabling both memory and computation scalability of such models. Morespecifically, we propose an iterative pruning strategy that removes redundantinformation encoded in the model. We also enhance compressibility for the modelby including in the optimization strategy a differentiable quantization andentropy coding estimator. Our results on popular benchmarks showcase theeffectiveness of the proposed approach and open the road to the broaddeployability of such a solution even on resource-constrained devices.</description><author>Muhammad Salman Ali, Sung-Ho Bae, Enzo Tartaglione</author><pubDate>Wed, 30 Oct 2024 17:01:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23213v1</guid></item><item><title>Improved convergence rate of kNN graph Laplacians</title><link>http://arxiv.org/abs/2410.23212v1</link><description>In graph-based data analysis, $k$-nearest neighbor ($k$NN) graphs are widelyused due to their adaptivity to local data densities. Allowing weighted edgesin the graph, the kernelized graph affinity provides a more general type of$k$NN graph where the $k$NN distance is used to set the kernel bandwidthadaptively. In this work, we consider a general class of $k$NN graph where thegraph affinity is $W_{ij} = \epsilon^{-d/2} \; k_0 ( \| x_i - x_j \|^2 /\epsilon \phi( \widehat{\rho}(x_i), \widehat{\rho}(x_j) )^2 ) $, with$\widehat{\rho}(x)$ being the (rescaled) $k$NN distance at the point $x$,$\phi$ a symmetric bi-variate function, and $k_0$ a non-negative function on$[0,\infty)$. Under the manifold data setting, where $N$ i.i.d. samples $x_i$are drawn from a density $p$ on a $d$-dimensional unknown manifold embedded ina high dimensional Euclidean space, we prove the point-wise convergence of the$k$NN graph Laplacian to the limiting manifold operator (depending on $p$) atthe rate of $O(N^{-2/(d+6)}\,)$, up to a log factor, when $k_0$ and $\phi$ have$C^3$ regularity and satisfy other technical conditions. This fast rate isobtained when $\epsilon \sim N^{-2/(d+6)}\,$ and $k \sim N^{6/(d+6)}\,$, bothat the optimal order to balance the theoretical bias and variance errors. When$k_0$ and $\phi$ have lower regularities, including when $k_0$ is a compactlysupported function as in the standard $k$NN graph, the convergence ratedegenerates to $O(N^{-1/(d+4)}\,)$. Our improved convergence rate is based on arefined analysis of the $k$NN estimator, which can be of independent interest.We validate our theory by numerical experiments on simulated data.</description><author>Yixuan Tan, Xiuyuan Cheng</author><pubDate>Wed, 30 Oct 2024 17:01:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23212v1</guid></item><item><title>Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks</title><link>http://arxiv.org/abs/2410.23208v1</link><description>While large models trained with self-supervised learning on offline datasetshave shown remarkable capabilities in text and image domains, achieving thesame generalisation for agents that act in sequential decision problems remainsan open challenge. In this work, we take a step towards this goal byprocedurally generating tens of millions of 2D physics-based tasks and usingthese to train a general reinforcement learning (RL) agent for physicalcontrol. To this end, we introduce Kinetix: an open-ended space ofphysics-based RL environments that can represent tasks ranging from roboticlocomotion and grasping to video games and classic RL environments, all withina unified framework. Kinetix makes use of our novel hardware-acceleratedphysics engine Jax2D that allows us to cheaply simulate billions of environmentsteps during training. Our trained agent exhibits strong physical reasoningcapabilities, being able to zero-shot solve unseen human-designed environments.Furthermore, fine-tuning this general agent on tasks of interest showssignificantly stronger performance than training an RL agent *tabula rasa*.This includes solving some environments that standard RL training completelyfails at. We believe this demonstrates the feasibility of large scale,mixed-quality pre-training for online RL and we hope that Kinetix will serve asa useful framework to investigate this further.</description><author>Michael Matthews, Michael Beukman, Chris Lu, Jakob Foerster</author><pubDate>Wed, 30 Oct 2024 16:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23208v1</guid></item><item><title>Flow Snapshot Neurons in Action: Deep Neural Networks Generalize to Biological Motion Perception</title><link>http://arxiv.org/abs/2405.16493v2</link><description>Biological motion perception (BMP) refers to humans' ability to perceive andrecognize the actions of living beings solely from their motion patterns,sometimes as minimal as those depicted on point-light displays. While humansexcel at these tasks without any prior training, current AI models strugglewith poor generalization performance. To close this research gap, we proposethe Motion Perceiver (MP). MP solely relies on patch-level optical flows fromvideo clips as inputs. During training, it learns prototypical flow snapshotsthrough a competitive binding mechanism and integrates invariant motionrepresentations to predict action labels for the given video. During inference,we evaluate the generalization ability of all AI models and humans on 62,656video stimuli spanning 24 BMP conditions using point-light displays inneuroscience. Remarkably, MP outperforms all existing AI models with a maximumimprovement of 29% in top-1 action recognition accuracy on these conditions.Moreover, we benchmark all AI models in point-light displays of two standardvideo datasets in computer vision. MP also demonstrates superior performance inthese cases. More interestingly, via psychophysics experiments, we found thatMP recognizes biological movements in a way that aligns with human behaviors.Our data and code are available athttps://github.com/ZhangLab-DeepNeuroCogLab/MotionPerceiver.</description><author>Shuangpeng Han, Ziyu Wang, Mengmi Zhang</author><pubDate>Wed, 30 Oct 2024 16:58:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16493v2</guid></item><item><title>Impacts of floating-point non-associativity on reproducibility for HPC and deep learning applications</title><link>http://arxiv.org/abs/2408.05148v3</link><description>Run to run variability in parallel programs caused by floating-pointnon-associativity has been known to significantly affect reproducibility initerative algorithms, due to accumulating errors. Non-reproducibility cancritically affect the efficiency and effectiveness of correctness testing forstochastic programs. Recently, the sensitivity of deep learning training andinference pipelines to floating-point non-associativity has been found tosometimes be extreme. It can prevent certification for commercial applications,accurate assessment of robustness and sensitivity, and bug detection. Newapproaches in scientific computing applications have coupled deep learningmodels with high-performance computing, leading to an aggravation of debuggingand testing challenges. Here we perform an investigation of the statisticalproperties of floating-point non-associativity within modern parallelprogramming models, and analyze performance and productivity impacts ofreplacing atomic operations with deterministic alternatives on GPUs. We examinethe recently-added deterministic options in PyTorch within the context of GPUdeployment for deep learning, uncovering and quantifying the impacts of inputparameters triggering run to run variability and reporting on the reliabilityand completeness of the documentation. Finally, we evaluate the strategy ofexploiting automatic determinism that could be provided by deterministichardware, using the Groq accelerator for inference portions of the deeplearning pipeline. We demonstrate the benefits that a hardware-based strategycan provide within reproducibility and correctness efforts.</description><author>Sanjif Shanmugavelu, Mathieu Taillefumier, Christopher Culver, Oscar Hernandez, Mark Coletti, Ada Sedova</author><pubDate>Wed, 30 Oct 2024 16:52:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05148v3</guid></item><item><title>Resource-aware Mixed-precision Quantization for Enhancing Deployability of Transformers for Time-series Forecasting on Embedded FPGAs</title><link>http://arxiv.org/abs/2410.03294v3</link><description>This study addresses the deployment challenges of integer-only quantizedTransformers on resource-constrained embedded FPGAs (Xilinx Spartan-7 XC7S15).We enhanced the flexibility of our VHDL template by introducing a selectableresource type for storing intermediate results across model layers, therebybreaking the deployment bottleneck by utilizing BRAM efficiently. Moreover, wedeveloped a resource-aware mixed-precision quantization approach that enablesresearchers to explore hardware-level quantization strategies without requiringextensive expertise in Neural Architecture Search. This method providesaccurate resource utilization estimates with a precision discrepancy as low as3%, compared to actual deployment metrics. Compared to previous work, ourapproach has successfully facilitated the deployment of model configurationsutilizing mixed-precision quantization, thus overcoming the limitationsinherent in five previously non-deployable configurations with uniformquantization bitwidths. Consequently, this research enhances the applicabilityof Transformers in embedded systems, facilitating a broader range ofTransformer-powered applications on edge devices.</description><author>Tianheng Ling, Chao Qian, Gregor Schiele</author><pubDate>Wed, 30 Oct 2024 16:51:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.03294v3</guid></item><item><title>Position Coupling: Improving Length Generalization of Arithmetic Transformers Using Task Structure</title><link>http://arxiv.org/abs/2405.20671v2</link><description>Even for simple arithmetic tasks like integer addition, it is challenging forTransformers to generalize to longer sequences than those encountered duringtraining. To tackle this problem, we propose position coupling, a simple yeteffective method that directly embeds the structure of the tasks into thepositional encoding of a (decoder-only) Transformer. Taking a departure fromthe vanilla absolute position mechanism assigning unique position IDs to eachof the tokens, we assign the same position IDs to two or more "relevant"tokens; for integer addition tasks, we regard digits of the same significanceas in the same position. On the empirical side, we show that with the proposedposition coupling, our models trained on 1 to 30-digit additions can generalizeup to 200-digit additions (6.67x of the trained length). On the theoreticalside, we prove that a 1-layer Transformer with coupled positions can solve theaddition task involving exponentially many digits, whereas any 1-layerTransformer without positional information cannot entirely solve it. We alsodemonstrate that position coupling can be applied to other algorithmic taskssuch as Nx2 multiplication and a two-dimensional task.</description><author>Hanseul Cho, Jaeyoung Cha, Pranjal Awasthi, Srinadh Bhojanapalli, Anupam Gupta, Chulhee Yun</author><pubDate>Wed, 30 Oct 2024 16:50:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20671v2</guid></item><item><title>HEX: Hierarchical Emergence Exploitation in Self-Supervised Algorithms</title><link>http://arxiv.org/abs/2410.23200v1</link><description>In this paper, we propose an algorithm that can be used on top of a widevariety of self-supervised (SSL) approaches to take advantage of hierarchicalstructures that emerge during training. SSL approaches typically work throughsome invariance term to ensure consistency between similar samples and aregularization term to prevent global dimensional collapse. Dimensionalcollapse refers to data representations spanning a lower-dimensional subspace.Recent work has demonstrated that the representation space of these algorithmsgradually reflects a semantic hierarchical structure as training progresses.Data samples of the same hierarchical grouping tend to exhibit greaterdimensional collapse locally compared to the dataset as a whole due to sharingfeatures in common with each other. Ideally, SSL algorithms would takeadvantage of this hierarchical emergence to have an additional regularizationterm to account for this local dimensional collapse effect. However, theconstruction of existing SSL algorithms does not account for this property. Toaddress this, we propose an adaptive algorithm that performs a weighteddecomposition of the denominator of the InfoNCE loss into two terms: localhierarchical and global collapse regularization respectively. Thisdecomposition is based on an adaptive threshold that gradually lowers toreflect the emerging hierarchical structure of the representation spacethroughout training. It is based on an analysis of the cosine similaritydistribution of samples in a batch. We demonstrate that this hierarchicalemergence exploitation (HEX) approach can be integrated across a wide varietyof SSL algorithms. Empirically, we show performance improvements of up to 5.6%relative improvement over baseline SSL approaches on classification accuracy onImagenet with 100 epochs of training.</description><author>Kiran Kokilepersaud, Seulgi Kim, Mohit Prabhushankar, Ghassan AlRegib</author><pubDate>Wed, 30 Oct 2024 16:49:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23200v1</guid></item><item><title>Continuous Spatio-Temporal Memory Networks for 4D Cardiac Cine MRI Segmentation</title><link>http://arxiv.org/abs/2410.23191v1</link><description>Current cardiac cine magnetic resonance image (cMR) studies focus on the enddiastole (ED) and end systole (ES) phases, while ignoring the abundant temporalinformation in the whole image sequence. This is because whole sequencesegmentation is currently a tedious process and inaccurate. Conventional wholesequence segmentation approaches first estimate the motion field betweenframes, which is then used to propagate the mask along the temporal axis.However, the mask propagation results could be prone to error, especially forthe basal and apex slices, where through-plane motion leads to significantmorphology and structural change during the cardiac cycle. Inspired by recentadvances in video object segmentation (VOS), based on spatio-temporal memory(STM) networks, we propose a continuous STM (CSTM) network for semi-supervisedwhole heart and whole sequence cMR segmentation. Our CSTM network takes fulladvantage of the spatial, scale, temporal and through-plane continuity prior ofthe underlying heart anatomy structures, to achieve accurate and fast 4Dsegmentation. Results of extensive experiments across multiple cMR datasetsshow that our method can improve the 4D cMR segmentation performance,especially for the hard-to-segment regions.</description><author>Meng Ye, Bingyu Xin, Leon Axel, Dimitris Metaxas</author><pubDate>Wed, 30 Oct 2024 16:45:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23191v1</guid></item><item><title>Instigating Cooperation among LLM Agents Using Adaptive Information Modulation</title><link>http://arxiv.org/abs/2409.10372v3</link><description>This paper introduces a novel framework combining LLM agents as proxies forhuman strategic behavior with reinforcement learning (RL) to engage theseagents in evolving strategic interactions within team environments. Ourapproach extends traditional agent-based simulations by using strategic LLMagents (SLA) and introducing dynamic and adaptive governance through apro-social promoting RL agent (PPA) that modulates information access acrossagents in a network, optimizing social welfare and promoting pro-socialbehavior. Through validation in iterative games, including the prisonerdilemma, we demonstrate that SLA agents exhibit nuanced strategic adaptations.The PPA agent effectively learns to adjust information transparency, resultingin enhanced cooperation rates. This framework offers significant insights intoAI-mediated social dynamics, contributing to the deployment of AI in real-worldteam settings.</description><author>Qiliang Chen, Sepehr Ilami, Nunzio Lore, Babak Heydari</author><pubDate>Wed, 30 Oct 2024 16:45:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.10372v3</guid></item><item><title>A Hitchhikers Guide to Fine-Grained Face Forgery Detection Using Common Sense Reasoning</title><link>http://arxiv.org/abs/2410.00485v2</link><description>Explainability in artificial intelligence is crucial for restoring trust,particularly in areas like face forgery detection, where viewers often struggleto distinguish between real and fabricated content. Vision and Large LanguageModels (VLLM) bridge computer vision and natural language, offering numerousapplications driven by strong common-sense reasoning. Despite their success invarious tasks, the potential of vision and language remains underexplored inface forgery detection, where they hold promise for enhancing explainability byleveraging the intrinsic reasoning capabilities of language to analysefine-grained manipulation areas. As such, there is a need for a methodologythat converts face forgery detection to a Visual Question Answering (VQA) taskto systematically and fairly evaluate these capabilities. Previous efforts forunified benchmarks in deepfake detection have focused on the simpler binarytask, overlooking evaluation protocols for fine-grained detection andtext-generative models. We propose a multi-staged approach that diverges fromthe traditional binary decision paradigm to address this gap. In the firststage, we assess the models' performance on the binary task and theirsensitivity to given instructions using several prompts. In the second stage,we delve deeper into fine-grained detection by identifying areas ofmanipulation in a multiple-choice VQA setting. In the third stage, we convertthe fine-grained detection to an open-ended question and compare severalmatching strategies for the multi-label classification task. Finally, wequalitatively evaluate the fine-grained responses of the VLLMs included in thebenchmark. We apply our benchmark to several popular models, providing adetailed comparison of binary, multiple-choice, and open-ended VQA evaluationacross seven datasets.\url{https://nickyfot.github.io/hitchhickersguide.github.io/}</description><author>Niki Maria Foteinopoulou, Enjie Ghorbel, Djamila Aouada</author><pubDate>Wed, 30 Oct 2024 16:43:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.00485v2</guid></item><item><title>Reliability of Topic Modeling</title><link>http://arxiv.org/abs/2410.23186v1</link><description>Topic models allow researchers to extract latent factors from text data anduse those variables in downstream statistical analyses. However, thesemethodologies can vary significantly due to initialization differences,randomness in sampling procedures, or noisy data. Reliability of these methodsis of particular concern as many researchers treat learned topic models asground truth for subsequent analyses. In this work, we show that the standardpractice for quantifying topic model reliability fails to capture essentialaspects of the variation in two widely-used topic models. Drawing from aextensive literature on measurement theory, we provide empirical andtheoretical analyses of three other metrics for evaluating the reliability oftopic models. On synthetic and real-world data, we show that McDonald's$\omega$ provides the best encapsulation of reliability. This metric providesan essential tool for validation of topic model methodologies that should be astandard component of any topic model-based research.</description><author>Kayla Schroeder, Zach Wood-Doughty</author><pubDate>Wed, 30 Oct 2024 16:42:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23186v1</guid></item><item><title>Certification for Differentially Private Prediction in Gradient-Based Training</title><link>http://arxiv.org/abs/2406.13433v2</link><description>Differential privacy upper-bounds the information leakage of machine learningmodels, yet providing meaningful privacy guarantees has proven to bechallenging in practice. The private prediction setting where model outputs areprivatized is being investigated as an alternate way to provide formalguarantees at prediction time. Most current private prediction algorithms,however, rely on global sensitivity for noise calibration, which often resultsin large amounts of noise being added to the predictions. Data-specific noisecalibration, such as smooth sensitivity, could significantly reduce the amountof noise added, but were so far infeasible to compute exactly for modernmachine learning models. In this work we provide a novel and practical approachbased on convex relaxation and bound propagation to compute a provableupper-bound for the local and smooth sensitivity of a prediction. This boundallows us to reduce the magnitude of noise added or improve privacy accountingin the private prediction setting. We validate our framework on datasets fromfinancial services, medical image classification, and natural languageprocessing and across models and find our approach to reduce the noise added byup to order of magnitude.</description><author>Matthew Wicker, Philip Sosnin, Igor Shilov, Adrianna Janik, Mark N. Müller, Yves-Alexandre de Montjoye, Adrian Weller, Calvin Tsay</author><pubDate>Wed, 30 Oct 2024 16:40:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.13433v2</guid></item><item><title>ProTransformer: Robustify Transformers via Plug-and-Play Paradigm</title><link>http://arxiv.org/abs/2410.23182v1</link><description>Transformer-based architectures have dominated various areas of machinelearning in recent years. In this paper, we introduce a novel robust attentionmechanism designed to enhance the resilience of transformer-basedarchitectures. Crucially, this technique can be integrated into existingtransformers as a plug-and-play layer, improving their robustness without theneed for additional training or fine-tuning. Through comprehensive experimentsand ablation studies, we demonstrate that our ProTransformer significantlyenhances the robustness of transformer models across a variety of predictiontasks, attack mechanisms, backbone architectures, and data domains. Notably,without further fine-tuning, the ProTransformer consistently improves theperformance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT,ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFoolerattack. Furthermore, ProTransformer shows promising resilience in largelanguage models (LLMs) against prompting-based attacks, improving theperformance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancingVicuna by an average of 10.4% against the Jailbreaking attack. Beyond thelanguage domain, ProTransformer also demonstrates outstanding robustness inboth vision and graph domains.</description><author>Zhichao Hou, Weizhi Gao, Yuchen Shen, Feiyi Wang, Xiaorui Liu</author><pubDate>Wed, 30 Oct 2024 16:38:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23182v1</guid></item><item><title>ReasoningRec: Bridging Personalized Recommendations and Human-Interpretable Explanations through LLM Reasoning</title><link>http://arxiv.org/abs/2410.23180v1</link><description>This paper presents ReasoningRec, a reasoning-based recommendation frameworkthat leverages Large Language Models (LLMs) to bridge the gap betweenrecommendations and human-interpretable explanations. In contrast toconventional recommendation systems that rely on implicit user-iteminteractions, ReasoningRec employs LLMs to model users and items, focusing onpreferences, aversions, and explanatory reasoning. The framework utilizes alarger LLM to generate synthetic explanations for user preferences,subsequently used to fine-tune a smaller LLM for enhanced recommendationaccuracy and human-interpretable explanation. Our experimental studyinvestigates the impact of reasoning and contextual information on personalizedrecommendations, revealing that the quality of contextual and personalized datasignificantly influences the LLM's capacity to generate plausible explanations.Empirical evaluations demonstrate that ReasoningRec surpasses state-of-the-artmethods by up to 12.5\% in recommendation prediction while concurrentlyproviding human-intelligible explanations. The code is available here:https://github.com/millenniumbismay/reasoningrec.</description><author>Millennium Bismay, Xiangjue Dong, James Caverlee</author><pubDate>Wed, 30 Oct 2024 16:37:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23180v1</guid></item><item><title>Depth Anywhere: Enhancing 360 Monocular Depth Estimation via Perspective Distillation and Unlabeled Data Augmentation</title><link>http://arxiv.org/abs/2406.12849v2</link><description>Accurately estimating depth in 360-degree imagery is crucial for virtualreality, autonomous navigation, and immersive media applications. Existingdepth estimation methods designed for perspective-view imagery fail whenapplied to 360-degree images due to different camera projections anddistortions, whereas 360-degree methods perform inferior due to the lack oflabeled data pairs. We propose a new depth estimation framework that utilizesunlabeled 360-degree data effectively. Our approach uses state-of-the-artperspective depth estimation models as teacher models to generate pseudo labelsthrough a six-face cube projection technique, enabling efficient labeling ofdepth in 360-degree images. This method leverages the increasing availabilityof large datasets. Our approach includes two main stages: offline maskgeneration for invalid regions and an online semi-supervised joint trainingregime. We tested our approach on benchmark datasets such as Matterport3D andStanford2D3D, showing significant improvements in depth estimation accuracy,particularly in zero-shot scenarios. Our proposed training pipeline can enhanceany 360 monocular depth estimator and demonstrates effective knowledge transferacross different camera projections and data types. See our project page forresults: https://albert100121.github.io/Depth-Anywhere/</description><author>Ning-Hsu Wang, Yu-Lun Liu</author><pubDate>Wed, 30 Oct 2024 16:37:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12849v2</guid></item><item><title>Does equivariance matter at scale?</title><link>http://arxiv.org/abs/2410.23179v1</link><description>Given large data sets and sufficient compute, is it beneficial to designneural architectures for the structure and symmetries of each problem? Or is itmore efficient to learn them from data? We study empirically how equivariantand non-equivariant networks scale with compute and training samples. Focusingon a benchmark problem of rigid-body interactions and on general-purposetransformer architectures, we perform a series of experiments, varying themodel size, training steps, and dataset size. We find evidence for threeconclusions. First, equivariance improves data efficiency, but trainingnon-equivariant models with data augmentation can close this gap givensufficient epochs. Second, scaling with compute follows a power law, withequivariant models outperforming non-equivariant ones at each tested computebudget. Finally, the optimal allocation of a compute budget onto model size andtraining duration differs between equivariant and non-equivariant models.</description><author>Johann Brehmer, Sönke Behrends, Pim de Haan, Taco Cohen</author><pubDate>Wed, 30 Oct 2024 16:36:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23179v1</guid></item><item><title>Uncertainty quantification for fast reconstruction methods using augmented equivariant bootstrap: Application to radio interferometry</title><link>http://arxiv.org/abs/2410.23178v1</link><description>The advent of next-generation radio interferometers like the Square KilometerArray promises to revolutionise our radio astronomy observational capabilities.The unprecedented volume of data these devices generate requires fast andaccurate image reconstruction algorithms to solve the ill-posed radiointerferometric imaging problem. Most state-of-the-art reconstruction methodslack trustworthy and scalable uncertainty quantification, which is critical forthe rigorous scientific interpretation of radio observations. We propose anunsupervised technique based on a conformalized version of a radio-augmentedequivariant bootstrapping method, which allows us to quantify uncertainties forfast reconstruction methods. Noticeably, we rely on reconstructions fromultra-fast unrolled algorithms. The proposed method brings more reliableuncertainty estimations to our problem than existing alternatives.</description><author>Mostafa Cherif, Tobías I. Liaudat, Jonathan Kern, Christophe Kervazo, Jérôme Bobin</author><pubDate>Wed, 30 Oct 2024 16:36:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23178v1</guid></item><item><title>Aequitas Flow: Streamlining Fair ML Experimentation</title><link>http://arxiv.org/abs/2405.05809v2</link><description>Aequitas Flow is an open-source framework and toolkit for end-to-end FairMachine Learning (ML) experimentation, and benchmarking in Python. This packagefills integration gaps that exist in other fair ML packages. In addition to theexisting audit capabilities in Aequitas, the Aequitas Flow module provides apipeline for fairness-aware model training, hyperparameter optimization, andevaluation, enabling easy-to-use and rapid experiments and analysis of results.Aimed at ML practitioners and researchers, the framework offers implementationsof methods, datasets, metrics, and standard interfaces for these components toimprove extensibility. By facilitating the development of fair ML practices,Aequitas Flow hopes to enhance the incorporation of fairness concepts in AIsystems making AI systems more robust and fair.</description><author>Sérgio Jesus, Pedro Saleiro, Inês Oliveira e Silva, Beatriz M. Jorge, Rita P. Ribeiro, João Gama, Pedro Bizarro, Rayid Ghani</author><pubDate>Wed, 30 Oct 2024 16:34:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05809v2</guid></item><item><title>Exploring Design Choices for Building Language-Specific LLMs</title><link>http://arxiv.org/abs/2406.14670v2</link><description>Despite rapid progress in large language models (LLMs), their performance ona vast majority of languages remains unsatisfactory. In this paper, we studybuilding language-specific LLMs by adapting monolingual and multilingual LLMs.We conduct systematic experiments on how design choices (base model selection,vocabulary extension, and continued pretraining) impact the adapted LLM, bothin terms of efficiency (how many tokens are needed to encode the same amount ofinformation) and end task performance. We find that (1) the initial performanceof LLM does not always correlate with the final performance after theadaptation. Adapting an English-centric models can yield better results thanadapting multilingual models despite their worse initial performance onlow-resource languages. (2) Efficiency can easily improved with simplevocabulary extension and continued pretraining in most LLMs we study, and (3)The optimal adaptation method (choice of the base model, new vocabulary size,training data, initialization strategy) is highly language-dependent, and thesimplest embedding initialization works well across various experimentalsettings. Together, our work lays foundations on efficiently buildinglanguage-specific LLMs by adapting existing LLMs.</description><author>Atula Tejaswi, Nilesh Gupta, Eunsol Choi</author><pubDate>Wed, 30 Oct 2024 16:33:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14670v2</guid></item><item><title>Weight Copy and Low-Rank Adaptation for Few-Shot Distillation of Vision Transformers</title><link>http://arxiv.org/abs/2404.09326v3</link><description>Few-shot knowledge distillation recently emerged as a viable approach toharness the knowledge of large-scale pre-trained models, using limited data andcomputational resources. In this paper, we propose a novel few-shot featuredistillation approach for vision transformers. Our approach is based on two keysteps. Leveraging the fact that vision transformers have a consistentdepth-wise structure, we first copy the weights from intermittent layers ofexisting pre-trained vision transformers (teachers) into shallowerarchitectures (students), where the intermittence factor controls thecomplexity of the student transformer with respect to its teacher. Next, weemploy an enhanced version of Low-Rank Adaptation (LoRA) to distill knowledgeinto the student in a few-shot scenario, aiming to recover the informationprocessing carried out by the skipped teacher layers. We present comprehensiveexperiments with supervised and self-supervised transformers as teachers, onsix data sets from various domains (natural, medical and satellite images) andtasks (classification and segmentation). The empirical results confirm thesuperiority of our approach over state-of-the-art competitors. Moreover, theablation results demonstrate the usefulness of each component of the proposedpipeline. We release our code at https://github.com/dianagrigore/WeCoLoRA.</description><author>Diana-Nicoleta Grigore, Mariana-Iuliana Georgescu, Jon Alvarez Justo, Tor Johansen, Andreea Iuliana Ionescu, Radu Tudor Ionescu</author><pubDate>Wed, 30 Oct 2024 16:27:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09326v3</guid></item><item><title>Functional Gradient Flows for Constrained Sampling</title><link>http://arxiv.org/abs/2410.23170v1</link><description>Recently, through a unified gradient flow perspective of Markov chain MonteCarlo (MCMC) and variational inference (VI), particle-based variationalinference methods (ParVIs) have been proposed that tend to combine the best ofboth worlds. While typical ParVIs such as Stein Variational Gradient Descent(SVGD) approximate the gradient flow within a reproducing kernel Hilbert space(RKHS), many attempts have been made recently to replace RKHS with moreexpressive function spaces, such as neural networks. While successful, thesemethods are mainly designed for sampling from unconstrained domains. In thispaper, we offer a general solution to constrained sampling by introducing aboundary condition for the gradient flow which would confine the particleswithin the specific domain. This allows us to propose a new functional gradientParVI method for constrained sampling, called constrained functional gradientflow (CFG), with provable continuous-time convergence in total variation (TV).We also present novel numerical strategies to handle the boundary integral termarising from the domain constraints. Our theory and experiments demonstrate theeffectiveness of the proposed framework.</description><author>Shiyue Zhang, Longlin Yu, Ziheng Cheng, Cheng Zhang</author><pubDate>Wed, 30 Oct 2024 16:20:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23170v1</guid></item><item><title>The Persistence of Neural Collapse Despite Low-Rank Bias: An Analytic Perspective Through Unconstrained Features</title><link>http://arxiv.org/abs/2410.23169v1</link><description>Modern deep neural networks have been observed to exhibit a simple structurein their final layer features and weights, commonly referred to as neuralcollapse. This phenomenon has also been noted in layers beyond the final one,an extension known as deep neural collapse. Recent findings indicate that sucha structure is generally not optimal in the deep unconstrained feature model,an approximation of an expressive network. This is attributed to a low-rankbias induced by regularization, which favors solutions with lower-rank thanthose typically associated with deep neural collapse. In this work, we extendthese observations to the cross-entropy loss and analyze how the low-rank biasinfluences various solutions. Additionally, we explore how this bias inducesspecific structures in the singular values of the weights at global optima.Furthermore, we examine the loss surface of these models and provide evidencethat the frequent observation of deep neural collapse in practice, despite itssuboptimality, may result from its higher degeneracy on the loss surface.</description><author>Connall Garrod, Jonathan P. Keating</author><pubDate>Wed, 30 Oct 2024 16:20:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23169v1</guid></item><item><title>TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters</title><link>http://arxiv.org/abs/2410.23168v1</link><description>Transformers have become the predominant architecture in foundation modelsdue to their excellent performance across various domains. However, thesubstantial cost of scaling these models remains a significant concern. Thisproblem arises primarily from their dependence on a fixed number of parameterswithin linear projections. When architectural modifications (e.g., channeldimensions) are introduced, the entire model typically requires retraining fromscratch. As model sizes continue growing, this strategy results in increasinglyhigh computational costs and becomes unsustainable. To overcome this problem,we introduce TokenFormer, a natively scalable architecture that leverages theattention mechanism not only for computations among input tokens but also forinteractions between tokens and model parameters, thereby enhancingarchitectural flexibility. By treating model parameters as tokens, we replaceall the linear projections in Transformers with our token-parameter attentionlayer, where input tokens act as queries and model parameters as keys andvalues. This reformulation allows for progressive and efficient scaling withoutnecessitating retraining from scratch. Our model scales from 124M to 1.4Bparameters by incrementally adding new key-value parameter pairs, achievingperformance comparable to Transformers trained from scratch while greatlyreducing training costs. Code and models are available at\url{https://github.com/Haiyang-W/TokenFormer}.</description><author>Haiyang Wang, Yue Fan, Muhammad Ferjad Naeem, Yongqin Xian, Jan Eric Lenssen, Liwei Wang, Federico Tombari, Bernt Schiele</author><pubDate>Wed, 30 Oct 2024 16:19:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23168v1</guid></item><item><title>A Survey Analyzing Generalization in Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2401.02349v2</link><description>Reinforcement learning research obtained significant success and attentionwith the utilization of deep neural networks to solve problems in highdimensional state or action spaces. While deep reinforcement learning policiesare currently being deployed in many different fields from medical applicationsto large language models, there are still ongoing questions the field is tryingto answer on the generalization capabilities of deep reinforcement learningpolicies. In this paper, we will formalize and analyze generalization in deepreinforcement learning. We will explain the fundamental reasons why deepreinforcement learning policies encounter overfitting problems that limit theirgeneralization capabilities. Furthermore, we will categorize and explain themanifold solution approaches to increase generalization, and overcomeoverfitting in deep reinforcement learning policies. From exploration toadversarial analysis and from regularization to robustness our paper providesan analysis on a wide range of subfields within deep reinforcement learningwith a broad scope and in-depth view. We believe our study can provide acompact guideline for the current advancements in deep reinforcement learning,and help to construct robust deep neural policies with higher generalizationskills.</description><author>Ezgi Korkmaz</author><pubDate>Wed, 30 Oct 2024 16:18:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02349v2</guid></item><item><title>SciPIP: An LLM-based Scientific Paper Idea Proposer</title><link>http://arxiv.org/abs/2410.23166v1</link><description>The exponential growth of knowledge and the increasing complexity ofinterdisciplinary research pose significant challenges for researchers,including information overload and difficulties in exploring novel ideas. Theadvancements in large language models (LLMs), such as GPT-4, have shown greatpotential in enhancing idea proposals, but how to effectively utilize largemodels for reasonable idea proposal has not been thoroughly explored. Thispaper proposes a scientific paper idea proposer (SciPIP). Based on auser-provided research background, SciPIP retrieves helpful papers from aliterature database while leveraging the capabilities of LLMs to generate morenovel and feasible ideas. To this end, 1) we construct a literature retrievaldatabase, extracting lots of papers' multi-dimension information for fastaccess. Then, a literature retrieval method based on semantics, entity, andcitation co-occurrences is proposed to search relevant literature from multipleaspects based on the user-provided background. 2) After literature retrieval,we introduce dual-path idea proposal strategies, where one path inferssolutions from the retrieved literature and the other path generates originalideas through model brainstorming. We then combine the two to achieve a goodbalance between feasibility and originality. Through extensive experiments onthe natural language processing (NLP) field, we demonstrate that SciPIP canretrieve citations similar to those of existing top conference papers andgenerate many ideas consistent with them. Additionally, we evaluate theoriginality of other ideas generated by SciPIP using large language models,further validating the effectiveness of our proposed method. The code and thedatabase are released at https://github.com/cheerss/SciPIP.</description><author>Wenxiao Wang, Lihui Gu, Liye Zhang, Yunxiang Luo, Yi Dai, Chen Shen, Liang Xie, Binbin Lin, Xiaofei He, Jieping Ye</author><pubDate>Wed, 30 Oct 2024 16:18:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23166v1</guid></item><item><title>FlexTSF: A Universal Forecasting Model for Time Series with Variable Regularities</title><link>http://arxiv.org/abs/2410.23160v1</link><description>Developing a foundation model for time series forecasting across diversedomains has attracted significant attention in recent years. Existing workstypically assume regularly sampled, well-structured data, limiting theirapplicability to more generalized scenarios where time series often containmissing values, unequal sequence lengths, and irregular time intervals betweenmeasurements. To cover diverse domains and handle variable regularities, wepropose FlexTSF, a universal time series forecasting model that possessesbetter generalization and natively support both regular and irregular timeseries. FlexTSF produces forecasts in an autoregressive manner and incorporatesthree novel designs: VT-Norm, a normalization strategy to ablate data domainbarriers, IVP Patcher, a patching module to learn representations from flexiblystructured time series, and LED attention, an attention mechanism to seamlesslyintegrate these two and propagate forecasts with awareness of domain and timeinformation. Experiments on 12 datasets show that FlexTSF outperformsstate-of-the-art forecasting models respectively designed for regular andirregular time series. Furthermore, after self-supervised pre-training, FlexTSFshows exceptional performance in both zero-shot and few-show settings for timeseries forecasting.</description><author>Jingge Xiao, Yile Chen, Gao Cong, Wolfgang Nejdl, Simon Gottschalk</author><pubDate>Wed, 30 Oct 2024 16:14:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23160v1</guid></item><item><title>U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers</title><link>http://arxiv.org/abs/2405.02730v3</link><description>Diffusion Transformers (DiTs) introduce the transformer architecture todiffusion tasks for latent-space image generation. With an isotropicarchitecture that chains a series of transformer blocks, DiTs demonstratecompetitive performance and good scalability; but meanwhile, the abandonment ofU-Net by DiTs and their following improvements is worth rethinking. To thisend, we conduct a simple toy experiment by comparing a U-Net architectured DiTwith an isotropic one. It turns out that the U-Net architecture only gain aslight advantage amid the U-Net inductive bias, indicating potentialredundancies within the U-Net-style DiT. Inspired by the discovery that U-Netbackbone features are low-frequency-dominated, we perform token downsampling onthe query-key-value tuple for self-attention that bring further improvementsdespite a considerable amount of reduction in computation. Based onself-attention with downsampled tokens, we propose a series of U-shaped DiTs(U-DiTs) in the paper and conduct extensive experiments to demonstrate theextraordinary performance of U-DiT models. The proposed U-DiT could outperformDiT-XL/2 with only 1/6 of its computation cost. Codes are available athttps://github.com/YuchuanTian/U-DiT.</description><author>Yuchuan Tian, Zhijun Tu, Hanting Chen, Jie Hu, Chao Xu, Yunhe Wang</author><pubDate>Wed, 30 Oct 2024 16:13:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02730v3</guid></item><item><title>Fourier Amplitude and Correlation Loss: Beyond Using L2 Loss for Skillful Precipitation Nowcasting</title><link>http://arxiv.org/abs/2410.23159v1</link><description>Deep learning approaches have been widely adopted for precipitationnowcasting in recent years. Previous studies mainly focus on proposing newmodel architectures to improve pixel-wise metrics. However, they frequentlyresult in blurry predictions which provide limited utility to forecastingoperations. In this work, we propose a new Fourier Amplitude and CorrelationLoss (FACL) which consists of two novel loss terms: Fourier Amplitude Loss(FAL) and Fourier Correlation Loss (FCL). FAL regularizes the Fourier amplitudeof the model prediction and FCL complements the missing phase information. Thetwo loss terms work together to replace the traditional $L_2$ losses such asMSE and weighted MSE for the spatiotemporal prediction problem on signal-baseddata. Our method is generic, parameter-free and efficient. Extensiveexperiments using one synthetic dataset and three radar echo datasetsdemonstrate that our method improves perceptual metrics and meteorology skillscores, with a small trade-off to pixel-wise accuracy and structuralsimilarity. Moreover, to improve the error margin in meteorological skillscores such as Critical Success Index (CSI) and Fractions Skill Score (FSS), wepropose and adopt the Regional Histogram Divergence (RHD), a distance metricthat considers the patch-wise similarity between signal-based imagery patternswith tolerance to local transforms. Code is available athttps://github.com/argenycw/FACL</description><author>Chiu-Wai Yan, Shi Quan Foo, Van Hoan Trinh, Dit-Yan Yeung, Ka-Hing Wong, Wai-Kin Wong</author><pubDate>Wed, 30 Oct 2024 16:12:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23159v1</guid></item></channel></rss>