<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 31 Oct 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Does Role-Playing Chatbots Capture the Character Personalities? Assessing Personality Traits for Role-Playing Chatbots</title><link>http://arxiv.org/abs/2310.17976v2</link><description>The emergence of large-scale pretrained language models has revolutionizedthe capabilities of new AI application, especially in the realm of craftingchatbots with distinct personas. Given the "stimulus-response" nature ofchatbots, this paper unveils an innovative open-ended interview-style approachfor personality assessment on role-playing chatbots, which offers a richercomprehension of their intrinsic personalities. We conduct personalityassessments on 32 role-playing chatbots created by the ChatHaruhi library,across both the Big Five and MBTI dimensions, and measure their alignment withhuman perception. Evaluation results underscore that modern role-playingchatbots based on LLMs can effectively portray personality traits ofcorresponding characters, with an alignment rate of 82.8% compared withhuman-perceived personalities. Besides, we also suggest potential strategiesfor shaping chatbots' personalities. Hence, this paper serves as a cornerstonestudy for role-playing chatbots that intersects computational linguistics andpsychology. Our resources are available athttps://github.com/LC1332/Chat-Haruhi-Suzumiya</description><author>Xintao Wang, Quan Tu, Yaying Fei, Ziang Leng, Cheng Li</author><pubDate>Mon, 30 Oct 2023 04:13:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17976v2</guid></item><item><title>M4LE: A Multi-Ability Multi-Range Multi-Task Multi-Domain Long-Context Evaluation Benchmark for Large Language Models</title><link>http://arxiv.org/abs/2310.19240v1</link><description>Managing long sequences has become an important and necessary feature forlarge language models (LLMs). However, it is still an open question of how tocomprehensively and systematically evaluate the long-sequence capability ofLLMs. One of the reasons is that conventional and widely-used benchmarks mainlyconsist of short sequences. In this paper, we propose M4LE, a Multi-ability,Multi-range, Multi-task, Multi-domain benchmark for Long-context Evaluation.M4LE is based on a diverse NLP task pool comprising 36 NLP datasets, 11 tasktypes and 12 domains. To alleviate the scarcity of tasks with naturally longsequences and incorporate multiple-ability assessment, we propose an automaticapproach (but with negligible human annotations) to convert short-sequencetasks into a unified long-sequence scenario where LLMs have to identify singleor multiple relevant spans in long contexts based on explicit or semantichints. Specifically, the scenario includes five different types of abilities:(1) explicit single-span; (2) semantic single-span; (3) explicit multiple-span;(4) semantic multiple-span; and (5) global context understanding. The resultingsamples in M4LE are evenly distributed from 1k to 8k input length. We conducteda systematic evaluation on 11 well-established LLMs, especially those optimizedfor long-sequence inputs. Our results reveal that: 1) Current LLMs struggle tounderstand long context, particularly when tasks require multiple-spanattention. 2) Semantic retrieval task is more difficult for competent LLMs. 3)Models fine-tuned on longer text with position interpolation have comparableperformance to those using Neural Tangent Kernel (NTK) aware scaling methodswithout fine-tuning. We make our benchmark publicly available to encouragefuture research in this challenging area.</description><author>Wai-Chung Kwan, Xingshan Zeng, Yufei Wang, Yusen Sun, Liangyou Li, Lifeng Shang, Qun Liu, Kam-Fai Wong</author><pubDate>Mon, 30 Oct 2023 04:11:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19240v1</guid></item><item><title>GestureGPT: Zero-shot Interactive Gesture Understanding and Grounding with Large Language Model Agents</title><link>http://arxiv.org/abs/2310.12821v3</link><description>Current gesture recognition systems primarily focus on identifying gestureswithin a predefined set, leaving a gap in connecting these gestures tointeractive GUI elements or system functions (e.g., linking a 'thumb-up'gesture to a 'like' button). We introduce GestureGPT, a novel zero-shot gestureunderstanding and grounding framework leveraging large language models (LLMs).Gesture descriptions are formulated based on hand landmark coordinates fromgesture videos and fed into our dual-agent dialogue system. A gesture agentdeciphers these descriptions and queries about the interaction context (e.g.,interface, history, gaze data), which a context agent organizes and provides.Following iterative exchanges, the gesture agent discerns user intent,grounding it to an interactive function. We validated the gesture descriptionmodule using public first-view and third-view gesture datasets and tested thewhole system in two real-world settings: video streaming and smart home IoTcontrol. The highest zero-shot Top-5 grounding accuracies are 80.11% for videostreaming and 90.78% for smart home tasks, showing potential of the new gestureunderstanding paradigm.</description><author>Xin Zeng, Xiaoyu Wang, Tengxiang Zhang, Chun Yu, Shengdong Zhao, Yiqiang Chen</author><pubDate>Mon, 30 Oct 2023 04:04:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12821v3</guid></item><item><title>Boosting Learning for LDPC Codes to Improve the Error-Floor Performance</title><link>http://arxiv.org/abs/2310.07194v2</link><description>Low-density parity-check (LDPC) codes have been successfully commercializedin communication systems due to their strong error correction capabilities andsimple decoding process. However, the error-floor phenomenon of LDPC codes, inwhich the error rate stops decreasing rapidly at a certain level, presentschallenges for achieving extremely low error rates and deploying LDPC codes inscenarios demanding ultra-high reliability. In this work, we propose trainingmethods for neural min-sum (NMS) decoders to eliminate the error-floor effect.First, by leveraging the boosting learning technique of ensemble networks, wedivide the decoding network into two neural decoders and train the post decoderto be specialized for uncorrected words that the first decoder fails tocorrect. Secondly, to address the vanishing gradient issue in training, weintroduce a block-wise training schedule that locally trains a block of weightswhile retraining the preceding block. Lastly, we show that assigning differentweights to unsatisfied check nodes effectively lowers the error-floor with aminimal number of weights. By applying these training methods to standard LDPCcodes, we achieve the best error-floor performance compared to other decodingmethods. The proposed NMS decoder, optimized solely through novel trainingmethods without additional modules, can be integrated into existing LDPCdecoders without incurring extra hardware costs. The source code is availableat https://github.com/ghy1228/LDPC_Error_Floor .</description><author>Hee-Youl Kwak, Dae-Young Yun, Yongjune Kim, Sang-Hyo Kim, Jong-Seon No</author><pubDate>Mon, 30 Oct 2023 03:58:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07194v2</guid></item><item><title>LightLM: A Lightweight Deep and Narrow Language Model for Generative Recommendation</title><link>http://arxiv.org/abs/2310.17488v2</link><description>This paper presents LightLM, a lightweight Transformer-based language modelfor generative recommendation. While Transformer-based generative modeling hasgained importance in various AI sub-fields such as NLP and vision, generativerecommendation is still in its infancy due to its unique demand on personalizedgenerative modeling. Existing works on generative recommendation often useNLP-oriented Transformer architectures such as T5, GPT, LLaMA and M6, which areheavy-weight and are not specifically designed for recommendation tasks.LightLM tackles the issue by introducing a light-weight deep and narrowTransformer architecture, which is specifically tailored for direct generationof recommendation items. This structure is especially apt for straightforwardgenerative recommendation and stems from the observation that language modeldoes not have to be too wide for this task, as the input predominantly consistsof short tokens that are well-suited for the model's capacity. We also showthat our devised user and item ID indexing methods, i.e., SpectralCollaborative Indexing (SCI) and Graph Collaborative Indexing (GCI), enablesthe deep and narrow Transformer architecture to outperform large-scale languagemodels for recommendation. Besides, to address the hallucination problem ofgenerating items as output, we propose the constrained generation process forgenerative recommenders. Experiments on real-world datasets show that LightLMoutperforms various competitive baselines in terms of both recommendationaccuracy and efficiency. The code can be found athttps://github.com/dongyuanjushi/LightLM.</description><author>Kai Mei, Yongfeng Zhang</author><pubDate>Mon, 30 Oct 2023 03:50:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17488v2</guid></item><item><title>Latent Space Energy-based Model for Fine-grained Open Set Recognition</title><link>http://arxiv.org/abs/2309.10711v2</link><description>Fine-grained open-set recognition (FineOSR) aims to recognize imagesbelonging to classes with subtle appearance differences while rejecting imagesof unknown classes. A recent trend in OSR shows the benefit of generativemodels to discriminative unknown detection. As a type of generative model,energy-based models (EBM) are the potential for hybrid modeling of generativeand discriminative tasks. However, most existing EBMs suffer from densityestimation in high-dimensional space, which is critical to recognizing imagesfrom fine-grained classes. In this paper, we explore the low-dimensional latentspace with energy-based prior distribution for OSR in a fine-grained visualworld. Specifically, based on the latent space EBM, we propose anattribute-aware information bottleneck (AIB), a residual attribute featureaggregation (RAFA) module, and an uncertainty-based virtual outlier synthesis(UVOS) module to improve the expressivity, granularity, and density of thesamples in fine-grained classes, respectively. Our method is flexible to takeadvantage of recent vision transformers for powerful visual classification andgeneration. The method is validated on both fine-grained and general visualclassification datasets while preserving the capability of generatingphoto-realistic fake images with high resolution.</description><author>Wentao Bao, Qi Yu, Yu Kong</author><pubDate>Mon, 30 Oct 2023 03:37:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10711v2</guid></item><item><title>Denevil: Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning</title><link>http://arxiv.org/abs/2310.11053v2</link><description>Large Language Models (LLMs) have made unprecedented breakthroughs, yet theirincreasing integration into everyday life might raise societal risks due togenerated unethical content. Despite extensive study on specific issues likebias, the intrinsic values of LLMs remain largely unexplored from a moralphilosophy perspective. This work delves into ethical values utilizing MoralFoundation Theory. Moving beyond conventional discriminative evaluations withpoor reliability, we propose DeNEVIL, a novel prompt generation algorithmtailored to dynamically exploit LLMs' value vulnerabilities and elicit theviolation of ethics in a generative manner, revealing their underlying valueinclinations. On such a basis, we construct MoralPrompt, a high-quality datasetcomprising 2,397 prompts covering 500+ value principles, and then benchmark theintrinsic values across a spectrum of LLMs. We discovered that most models areessentially misaligned, necessitating further ethical value alignment. Inresponse, we develop VILMO, an in-context alignment method that substantiallyenhances the value compliance of LLM outputs by learning to generateappropriate value instructions, outperforming existing competitors. Our methodsare suitable for black-box and open-source models, offering a promising initialstep in studying the ethical values of LLMs.</description><author>Shitong Duan, Xiaoyuan Yi, Peng Zhang, Tun Lu, Xing Xie, Ning Gu</author><pubDate>Mon, 30 Oct 2023 03:30:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11053v2</guid></item><item><title>Building Real-World Meeting Summarization Systems using Large Language Models: A Practical Perspective</title><link>http://arxiv.org/abs/2310.19233v1</link><description>This paper studies how to effectively build meeting summarization systems forreal-world usage using large language models (LLMs). For this purpose, weconduct an extensive evaluation and comparison of various closed-source andopen-source LLMs, namely, GPT-4, GPT- 3.5, PaLM-2, and LLaMA-2. Our findingsreveal that most closed-source LLMs are generally better in terms ofperformance. However, much smaller open-source models like LLaMA- 2 (7B and13B) could still achieve performance comparable to the large closed-sourcemodels even in zero-shot scenarios. Considering the privacy concerns ofclosed-source models for only being accessible via API, alongside the high costassociated with using fine-tuned versions of the closed-source models, theopensource models that can achieve competitive performance are moreadvantageous for industrial use. Balancing performance with associated costsand privacy concerns, the LLaMA-2-7B model looks more promising for industrialusage. In sum, this paper offers practical insights on using LLMs forreal-world business meeting summarization, shedding light on the trade-offsbetween performance and cost.</description><author>Md Tahmid Rahman Laskar, Xue-Yong Fu, Cheng Chen, Shashi Bhushan TN</author><pubDate>Mon, 30 Oct 2023 03:25:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19233v1</guid></item><item><title>Adapter Pruning using Tropical Characterization</title><link>http://arxiv.org/abs/2310.19232v1</link><description>Adapters are widely popular parameter-efficient transfer learning approachesin natural language processing that insert trainable modules in between layersof a pre-trained language model. Apart from several heuristics, however, therehas been a lack of studies analyzing the optimal number of adapter parametersneeded for downstream applications. In this paper, we propose an adapterpruning approach by studying the tropical characteristics of trainable modules.We cast it as an optimization problem that aims to prune parameters from theadapter layers without changing the orientation of underlying tropicalhypersurfaces. Our experiments on five NLP datasets show that tropical geometrytends to identify more relevant parameters to prune when compared with themagnitude-based baseline, while a combined approach works best across thetasks.</description><author>Rishabh Bhardwaj, Tushar Vaidya, Soujanya Poria</author><pubDate>Mon, 30 Oct 2023 03:20:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19232v1</guid></item><item><title>There Are No Data Like More Data- Datasets for Deep Learning in Earth Observation</title><link>http://arxiv.org/abs/2310.19231v1</link><description>Carefully curated and annotated datasets are the foundation of machinelearning, with particularly data-hungry deep neural networks forming the coreof what is often called Artificial Intelligence (AI). Due to the massivesuccess of deep learning applied to Earth Observation (EO) problems, the focusof the community has been largely on the development of ever-more sophisticateddeep neural network architectures and training strategies largely ignoring theoverall importance of datasets. For that purpose, numerous task-specificdatasets have been created that were largely ignored by previously publishedreview articles on AI for Earth observation. With this article, we want tochange the perspective and put machine learning datasets dedicated to Earthobservation data and applications into the spotlight. Based on a review of thehistorical developments, currently available resources are described and aperspective for future developments is formed. We hope to contribute to anunderstanding that the nature of our data is what distinguishes the Earthobservation community from many other communities that apply deep learningtechniques to image data, and that a detailed understanding of EO datapeculiarities is among the core competencies of our discipline.</description><author>Michael Schmitt, Seyed Ali Ahmadi, Yonghao Xu, Gulsen Taskin, Ujjwal Verma, Francescopaolo Sica, Ronny Hansch</author><pubDate>Mon, 30 Oct 2023 03:19:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19231v1</guid></item><item><title>DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking</title><link>http://arxiv.org/abs/2310.18075v2</link><description>Inspired by the dual-process theory of human cognition, we introduce DUMA, anovel conversational agent framework that embodies a dual-mind mechanismthrough the utilization of two generative Large Language Models (LLMs)dedicated to fast and slow thinking respectively. The fast thinking modelserves as the primary interface for external interactions and initial responsegeneration, evaluating the necessity for engaging the slow thinking model basedon the complexity of the complete response. When invoked, the slow thinkingmodel takes over the conversation, engaging in meticulous planning, reasoning,and tool utilization to provide a well-analyzed response. This dual-mindconfiguration allows for a seamless transition between intuitive responses anddeliberate problem-solving processes based on the situation. We haveconstructed a conversational agent to handle online inquiries in the realestate industry. The experiment proves that our method balances effectivenessand efficiency, and has a significant improvement compared to the baseline.</description><author>Xiaoyu Tian, Liangyu Chen, Na Liu, Yaxuan Liu, Wei Zou, Kaijiang Chen, Ming Cui</author><pubDate>Mon, 30 Oct 2023 03:16:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18075v2</guid></item><item><title>Stochastic Configuration Machines: FPGA Implementation</title><link>http://arxiv.org/abs/2310.19225v1</link><description>Neural networks for industrial applications generally have additionalconstraints such as response speed, memory size and power usage. Randomizedlearners can address some of these issues. However, hardware solutions canprovide better resource reduction whilst maintaining the model's performance.Stochastic configuration networks (SCNs) are a prime choice in industrialapplications due to their merits and feasibility for data modelling. StochasticConfiguration Machines (SCMs) extend this to focus on reducing the memoryconstraints by limiting the randomized weights to a binary value with a scalarfor each node and using a mechanism model to improve the learning performanceand result interpretability. This paper aims to implement SCM models on a fieldprogrammable gate array (FPGA) and introduce binary-coded inputs to thealgorithm. Results are reported for two benchmark and two industrial datasets,including SCM with single-layer and deep architectures.</description><author>Matthew J. Felicetti, Dianhui Wang</author><pubDate>Mon, 30 Oct 2023 03:04:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19225v1</guid></item><item><title>CHAMMI: A benchmark for channel-adaptive models in microscopy imaging</title><link>http://arxiv.org/abs/2310.19224v1</link><description>Most neural networks assume that input images have a fixed number of channels(three for RGB images). However, there are many settings where the number ofchannels may vary, such as microscopy images where the number of channelschanges depending on instruments and experimental goals. Yet, there has notbeen a systemic attempt to create and evaluate neural networks that areinvariant to the number and type of channels. As a result, trained modelsremain specific to individual studies and are hardly reusable for othermicroscopy settings. In this paper, we present a benchmark for investigatingchannel-adaptive models in microscopy imaging, which consists of 1) a datasetof varied-channel single-cell images, and 2) a biologically relevant evaluationframework. In addition, we adapted several existing techniques to createchannel-adaptive models and compared their performance on this benchmark tofixed-channel, baseline models. We find that channel-adaptive models cangeneralize better to out-of-domain tasks and can be computationally efficient.We contribute a curated dataset (https://doi.org/10.5281/zenodo.7988357) and anevaluation API (https://github.com/broadinstitute/MorphEm.git) to facilitateobjective comparisons in future research and applications.</description><author>Zitong Chen, Chau Pham, Siqi Wang, Michael Doron, Nikita Moshkov, Bryan A. Plummer, Juan C. Caicedo</author><pubDate>Mon, 30 Oct 2023 03:03:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19224v1</guid></item><item><title>Modular Anti-noise Deep Learning Network for Robotic Grasp Detection Based on RGB Images</title><link>http://arxiv.org/abs/2310.19223v1</link><description>While traditional methods relies on depth sensors, the current trend leanstowards utilizing cost-effective RGB images, despite their absence of depthcues. This paper introduces an interesting approach to detect grasping posefrom a single RGB image. To this end, we propose a modular learning networkaugmented with grasp detection and semantic segmentation, tailored for robotsequipped with parallel-plate grippers. Our network not only identifiesgraspable objects but also fuses prior grasp analyses with semanticsegmentation, thereby boosting grasp detection precision. Significantly, ourdesign exhibits resilience, adeptly handling blurred and noisy visuals. Keycontributions encompass a trainable network for grasp detection from RGBimages, a modular design facilitating feasible grasp implementation, and anarchitecture robust against common image distortions. We demonstrate thefeasibility and accuracy of our proposed approach through practical experimentsand evaluations.</description><author>Zhaocong Li</author><pubDate>Mon, 30 Oct 2023 03:01:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19223v1</guid></item><item><title>Maximum Knowledge Orthogonality Reconstruction with Gradients in Federated Learning</title><link>http://arxiv.org/abs/2310.19222v1</link><description>Federated learning (FL) aims at keeping client data local to preserveprivacy. Instead of gathering the data itself, the server only collectsaggregated gradient updates from clients. Following the popularity of FL, therehas been considerable amount of work, revealing the vulnerability of FLapproaches by reconstructing the input data from gradient updates. Yet, mostexisting works assume an FL setting with unrealistically small batch size, andhave poor image quality when the batch size is large. Other works modify theneural network architectures or parameters to the point of being suspicious,and thus, can be detected by clients. Moreover, most of them can onlyreconstruct one sample input from a large batch. To address these limitations,we propose a novel and completely analytical approach, referred to as themaximum knowledge orthogonality reconstruction (MKOR), to reconstruct clients'input data. Our proposed method reconstructs a mathematically proven highquality image from large batches. MKOR only requires the server to sendsecretly modified parameters to clients and can efficiently and inconspicuouslyreconstruct the input images from clients' gradient updates. We evaluate MKOR'sperformance on the MNIST, CIFAR-100, and ImageNet dataset and compare it withthe state-of-the-art works. The results show that MKOR outperforms the existingapproaches, and draws attention to a pressing need for further research on theprivacy protection of FL so that comprehensive defense approaches can bedeveloped.</description><author>Feng Wang, Senem Velipasalar, M. Cenk Gursoy</author><pubDate>Mon, 30 Oct 2023 03:01:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19222v1</guid></item><item><title>From Stream to Pool: Dynamic Pricing Beyond i.i.d. Arrivals</title><link>http://arxiv.org/abs/2310.19220v1</link><description>The dynamic pricing problem has been extensively studied under the\textbf{stream} model: A stream of customers arrives sequentially, each with anindependently and identically distributed valuation. However, this formulationis not entirely reflective of the real world. In many scenarios, high-valuationcustomers tend to make purchases earlier and leave the market, leading to a\emph{shift} in the valuation distribution. Thus motivated, we consider a modelwhere a \textbf{pool} of $n$ non-strategic unit-demand customers interactrepeatedly with the seller. Each customer monitors the price intermittentlyaccording to an independent Poisson process and makes a purchase if theobserved price is lower than her \emph{private} valuation, whereupon she leavesthe market permanently. We present a minimax \emph{optimal} algorithm thatefficiently computes a non-adaptive policy which guarantees a $1/k$ fraction ofthe optimal revenue, given any set of $k$ prices. Moreover, we present anadaptive \emph{learn-then-earn} policy based on a novel \emph{debiasing}approach, and prove an $\tilde O(kn^{3/4})$ regret bound. We further improvethe bound to $\tilde O(k^{3/4} n^{3/4})$ using martingale concentrationinequalities.</description><author>Titing Cui, Su Jia, Thomas Lavastida</author><pubDate>Mon, 30 Oct 2023 02:53:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19220v1</guid></item><item><title>Large Language Models Are Semi-Parametric Reinforcement Learning Agents</title><link>http://arxiv.org/abs/2306.07929v2</link><description>Inspired by the insights in cognitive science with respect to human memoryand reasoning mechanism, a novel evolvable LLM-based (Large Language Model)agent framework is proposed as REMEMBERER. By equipping the LLM with along-term experience memory, REMEMBERER is capable of exploiting theexperiences from the past episodes even for different task goals, which excelsan LLM-based agent with fixed exemplars or equipped with a transient workingmemory. We further introduce Reinforcement Learning with Experience Memory(RLEM) to update the memory. Thus, the whole system can learn from theexperiences of both success and failure, and evolve its capability withoutfine-tuning the parameters of the LLM. In this way, the proposed REMEMBERERconstitutes a semi-parametric RL agent. Extensive experiments are conducted ontwo RL task sets to evaluate the proposed framework. The average results withdifferent initialization and training sets exceed the prior SOTA by 4% and 2%for the success rate on two task sets and demonstrate the superiority androbustness of REMEMBERER.</description><author>Danyang Zhang, Lu Chen, Situo Zhang, Hongshen Xu, Zihan Zhao, Kai Yu</author><pubDate>Mon, 30 Oct 2023 02:52:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07929v2</guid></item><item><title>Shape-centered Representation Learning for Visible-Infrared Person Re-identification</title><link>http://arxiv.org/abs/2310.17952v2</link><description>Current Visible-Infrared Person Re-Identification (VI-ReID) methodsprioritize extracting distinguishing appearance features, ignoring the naturalresistance of body shape against modality changes. Initially, we gauged thediscriminative potential of shapes by a straightforward concatenation of shapeand appearance features. However, two unresolved issues persist in theutilization of shape features. One pertains to the dependence on auxiliarymodels for shape feature extraction in the inference phase, along with theerrors in generated infrared shapes due to the intrinsic modality disparity.The other issue involves the inadequately explored correlation between shapeand appearance features. To tackle the aforementioned challenges, we proposethe Shape-centered Representation Learning framework (ScRL), which focuses onlearning shape features and appearance features associated with shapes.Specifically, we devise the Shape Feature Propagation (SFP), facilitatingdirect extraction of shape features from original images with minimalcomplexity costs during inference. To restitute inaccuracies in infrared bodyshapes at the feature level, we present the Infrared Shape Restitution (ISR).Furthermore, to acquire appearance features related to shape, we design theAppearance Feature Enhancement (AFE), which accentuates identity-relatedfeatures while suppressing identity-unrelated features guided by shapefeatures. Extensive experiments are conducted to validate the effectiveness ofthe proposed ScRL. Achieving remarkable results, the Rank-1 (mAP) accuracyattains 76.1%, 71.2%, 92.4% (72.6%, 52.9%, 86.7%) on the SYSU-MM01, HITSZ-VCM,RegDB datasets respectively, outperforming existing state-of-the-art methods.</description><author>Shuang Li, Jiaxu Leng, Ji Gan, Mengjingcheng Mo, Xinbo Gao</author><pubDate>Mon, 30 Oct 2023 02:37:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17952v2</guid></item><item><title>A Survey of Federated Unlearning: A Taxonomy, Challenges and Future Directions</title><link>http://arxiv.org/abs/2310.19218v1</link><description>With the development of trustworthy Federated Learning (FL), the requirementof implementing right to be forgotten gives rise to the area of FederatedUnlearning (FU). Comparing to machine unlearning, a major challenge of FU liesin the decentralized and privacy-preserving nature of FL, in which clientsjointly train a global model without sharing their raw data, making itsubstantially more intricate to selectively unlearn specific information. Inthat regard, many efforts have been made to tackle the challenges of FU andhave achieved significant progress. In this paper, we present a comprehensivesurvey of FU. Specially, we provide the existing algorithms, objectives,evaluation metrics, and identify some challenges of FU. By reviewing andcomparing some studies, we summarize them into a taxonomy for various schemes,potential applications and future directions.</description><author>Jiaxi Yang, Yang Zhao</author><pubDate>Mon, 30 Oct 2023 02:34:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19218v1</guid></item><item><title>Uncertainty-aware Grounded Action Transformation towards Sim-to-Real Transfer for Traffic Signal Control</title><link>http://arxiv.org/abs/2307.12388v3</link><description>Traffic signal control (TSC) is a complex and important task that affects thedaily lives of millions of people. Reinforcement Learning (RL) has shownpromising results in optimizing traffic signal control, but current RL-basedTSC methods are mainly trained in simulation and suffer from the performancegap between simulation and the real world. In this paper, we propose asimulation-to-real-world (sim-to-real) transfer approach called UGAT, whichtransfers a learned policy trained from a simulated environment to a real-worldenvironment by dynamically transforming actions in the simulation withuncertainty to mitigate the domain gap of transition dynamics. We evaluate ourmethod on a simulated traffic environment and show that it significantlyimproves the performance of the transferred RL policy in the real world.</description><author>Longchao Da, Hao Mei, Romir Sharma, Hua Wei</author><pubDate>Mon, 30 Oct 2023 02:16:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12388v3</guid></item><item><title>FormalGeo: The First Step Toward Human-like IMO-level Geometric Automated Reasoning</title><link>http://arxiv.org/abs/2310.18021v2</link><description>This is the first paper in a series of work we have accomplished over thepast three years. In this paper, we have constructed a complete and compatibleformal plane geometry system. This will serve as a crucial bridge betweenIMO-level plane geometry challenges and readable AI automated reasoning. Withthis formal system in place, we have been able to seamlessly integrate modernAI models with our formal system. Within this formal framework, AI is nowcapable of providing deductive reasoning solutions to IMO-level plane geometryproblems, just like handling other natural languages, and these proofs arereadable, traceable, and verifiable. We propose the geometry formalizationtheory (GFT) to guide the development of the geometry formal system. Based onthe GFT, we have established the FormalGeo, which consists of 88 geometricpredicates and 196 theorems. It can represent, validate, and solve IMO-levelgeometry problems. we also have crafted the FGPS (formal geometry problemsolver) in Python. It serves as both an interactive assistant for verifyingproblem-solving processes and an automated problem solver, utilizing variousmethods such as forward search, backward search and AI-assisted search. We'veannotated the FormalGeo7k dataset, containing 6,981 (expand to 186,832 throughdata augmentation) geometry problems with complete formal language annotations.Implementation of the formal system and experiments on the FormalGeo7k validatethe correctness and utility of the GFT. The backward depth-first search methodonly yields a 2.42% problem-solving failure rate, and we can incorporate deeplearning techniques to achieve lower one. The source code of FGPS andFormalGeo7k dataset are available at https://github.com/BitSecret/FormalGeo.</description><author>Xiaokai Zhang, Na Zhu, Yiming He, Jia Zou, Qike Huang, Xiaoxiao Jin, Yanjun Guo, Chenyang Mao, Zhe Zhu, Dengfeng Yue, Fangzhen Zhu, Yang Li, Yifan Wang, Yiwen Huang, Runan Wang, Cheng Qin, Zhenbing Zeng, Shaorong Xie, Xiangfeng Luo, Tuo Leng</author><pubDate>Mon, 30 Oct 2023 02:08:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18021v2</guid></item><item><title>On the accuracy and efficiency of group-wise clipping in differentially private optimization</title><link>http://arxiv.org/abs/2310.19215v1</link><description>Recent advances have substantially improved the accuracy, memory cost, andtraining speed of differentially private (DP) deep learning, especially onlarge vision and language models with millions to billions of parameters. Inthis work, we thoroughly study the per-sample gradient clipping style, a keycomponent in DP optimization. We show that different clipping styles have thesame time complexity but instantiate an accuracy-memory trade-off: while theall-layer clipping (of coarse granularity) is the most prevalent and usuallygives the best accuracy, it incurs heavier memory cost compared to othergroup-wise clipping, such as the layer-wise clipping (of finer granularity). Weformalize this trade-off through our convergence theory and complexityanalysis. Importantly, we demonstrate that the accuracy gap between group-wiseclipping and all-layer clipping becomes smaller for larger models, while thememory advantage of the group-wise clipping remains. Consequently, thegroup-wise clipping allows DP optimization of large models to achieve highaccuracy and low peak memory simultaneously.</description><author>Zhiqi Bu, Ruixuan Liu, Yu-Xiang Wang, Sheng Zha, George Karypis</author><pubDate>Mon, 30 Oct 2023 02:01:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19215v1</guid></item><item><title>Hierarchical Prompting Assists Large Language Model on Web Navigation</title><link>http://arxiv.org/abs/2305.14257v3</link><description>Large language models (LLMs) struggle on processing complicated observationsin interactive decision making tasks. To alleviate this issue, we propose asimple hierarchical prompting approach. Diverging from previous promptingapproaches that always put the full observation (e.g. a web page) to theprompt, we propose to first construct an action-aware observation which is morecondensed and relevant with a dedicated SUMMARIZER prompt. The ACTOR promptthen predicts the next action based on the summarized observation. While ourmethod has broad applicability, we particularly demonstrate its efficacy in thecomplex domain of web navigation where a full observation often containsredundant and irrelevant information. Our approach outperforms the previousstate-of-the-art prompting mechanics by 6.2% on task success rate,demonstrating its potential on interactive decision making tasks with longobservation traces.</description><author>Abishek Sridhar, Robert Lo, Frank F. Xu, Hao Zhu, Shuyan Zhou</author><pubDate>Mon, 30 Oct 2023 01:55:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14257v3</guid></item><item><title>Factor Fitting, Rank Allocation, and Partitioning in Multilevel Low Rank Matrices</title><link>http://arxiv.org/abs/2310.19214v1</link><description>We consider multilevel low rank (MLR) matrices, defined as a row and columnpermutation of a sum of matrices, each one a block diagonal refinement of theprevious one, with all blocks low rank given in factored form. MLR matricesextend low rank matrices but share many of their properties, such as the totalstorage required and complexity of matrix-vector multiplication. We addressthree problems that arise in fitting a given matrix by an MLR matrix in theFrobenius norm. The first problem is factor fitting, where we adjust thefactors of the MLR matrix. The second is rank allocation, where we choose theranks of the blocks in each level, subject to the total rank having a givenvalue, which preserves the total storage needed for the MLR matrix. The finalproblem is to choose the hierarchical partition of rows and columns, along withthe ranks and factors. This paper is accompanied by an open source package thatimplements the proposed methods.</description><author>Tetiana Parshakova, Trevor Hastie, Eric Darve, Stephen Boyd</author><pubDate>Mon, 30 Oct 2023 01:52:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19214v1</guid></item><item><title>EHRTutor: Enhancing Patient Understanding of Discharge Instructions</title><link>http://arxiv.org/abs/2310.19212v1</link><description>Large language models have shown success as a tutor in education in variousfields. Educating patients about their clinical visits plays a pivotal role inpatients' adherence to their treatment plans post-discharge. This paperpresents EHRTutor, an innovative multi-component framework leveraging the LargeLanguage Model (LLM) for patient education through conversationalquestion-answering. EHRTutor first formulates questions pertaining to theelectronic health record discharge instructions. It then educates the patientthrough conversation by administering each question as a test. Finally, itgenerates a summary at the end of the conversation. Evaluation results usingLLMs and domain experts have shown a clear preference for EHRTutor over thebaseline. Moreover, EHRTutor also offers a framework for generating syntheticpatient education dialogues that can be used for future in-house systemtraining.</description><author>Zihao Zhang, Zonghai Yao, Huixue Zhou, Feiyun ouyang, Hong Yu</author><pubDate>Mon, 30 Oct 2023 01:46:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19212v1</guid></item><item><title>Investigative Pattern Detection Framework for Counterterrorism</title><link>http://arxiv.org/abs/2310.19211v1</link><description>Law-enforcement investigations aimed at preventing attacks by violentextremists have become increasingly important for public safety. The problem isexacerbated by the massive data volumes that need to be scanned to identifycomplex behaviors of extremists and groups. Automated tools are required toextract information to respond queries from analysts, continually scan newinformation, integrate them with past events, and then alert about emergingthreats. We address challenges in investigative pattern detection and developan Investigative Pattern Detection Framework for Counterterrorism (INSPECT).The framework integrates numerous computing tools that include machine learningtechniques to identify behavioral indicators and graph pattern matchingtechniques to detect risk profiles/groups. INSPECT also automates multipletasks for large-scale mining of detailed forensic biographies, formingknowledge networks, and querying for behavioral indicators and radicalizationtrajectories. INSPECT targets human-in-the-loop mode of investigative searchand has been validated and evaluated using an evolving dataset on domesticjihadism.</description><author>Shashika R. Muramudalige, Benjamin W. K. Hung, Rosanne Libretti, Jytte Klausen, Anura P. Jayasumana</author><pubDate>Mon, 30 Oct 2023 01:45:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19211v1</guid></item><item><title>Diffused Redundancy in Pre-trained Representations</title><link>http://arxiv.org/abs/2306.00183v2</link><description>Representations learned by pre-training a neural network on a large datasetare increasingly used successfully to perform a variety of downstream tasks. Inthis work, we take a closer look at how features are encoded in suchpre-trained representations. We find that learned representations in a givenlayer exhibit a degree of diffuse redundancy, ie, any randomly chosen subset ofneurons in the layer that is larger than a threshold size shares a large degreeof similarity with the full layer and is able to perform similarly as the wholelayer on a variety of downstream tasks. For example, a linear probe trained on$20\%$ of randomly picked neurons from the penultimate layer of a ResNet50pre-trained on ImageNet1k achieves an accuracy within $5\%$ of a linear probetrained on the full layer of neurons for downstream CIFAR10 classification. Weconduct experiments on different neural architectures (including CNNs andTransformers) pre-trained on both ImageNet1k and ImageNet21k and evaluate avariety of downstream tasks taken from the VTAB benchmark. We find that theloss and dataset used during pre-training largely govern the degree of diffuseredundancy and the "critical mass" of neurons needed often depends on thedownstream task, suggesting that there is a task-inherentredundancy-performance Pareto frontier. Our findings shed light on the natureof representations learned by pre-trained deep neural networks and suggest thatentire layers might not be necessary to perform many downstream tasks. Weinvestigate the potential for exploiting this redundancy to achieve efficientgeneralization for downstream tasks and also draw caution to certain possibleunintended consequences. Our code is available at\url{https://github.com/nvedant07/diffused-redundancy}.</description><author>Vedant Nanda, Till Speicher, John P. Dickerson, Soheil Feizi, Krishna P. Gummadi, Adrian Weller</author><pubDate>Mon, 30 Oct 2023 01:43:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00183v2</guid></item><item><title>Generalized Category Discovery with Clustering Assignment Consistency</title><link>http://arxiv.org/abs/2310.19210v1</link><description>Generalized category discovery (GCD) is a recently proposed open-world task.Given a set of images consisting of labeled and unlabeled instances, the goalof GCD is to automatically cluster the unlabeled samples using informationtransferred from the labeled dataset. The unlabeled dataset comprises bothknown and novel classes. The main challenge is that unlabeled novel classsamples and unlabeled known class samples are mixed together in the unlabeleddataset. To address the GCD without knowing the class number of unlabeleddataset, we propose a co-training-based framework that encourages clusteringconsistency. Specifically, we first introduce weak and strong augmentationtransformations to generate two sufficiently different views for the samesample. Then, based on the co-training assumption, we propose a consistencyrepresentation learning strategy, which encourages consistency betweenfeature-prototype similarity and clustering assignment. Finally, we use thediscriminative embeddings learned from the semi-supervised representationlearning process to construct an original sparse network and use a communitydetection method to obtain the clustering results and the number of categoriessimultaneously. Extensive experiments show that our method achievesstate-of-the-art performance on three generic benchmarks and three fine-grainedvisual recognition datasets. Especially in the ImageNet-100 data set, ourmethod significantly exceeds the best baseline by 15.5\% and 7.0\% on the\texttt{Novel} and \texttt{All} classes, respectively.</description><author>Xiangli Yang, Xinglin Pan, Irwin King, Zenglin Xu</author><pubDate>Mon, 30 Oct 2023 01:32:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19210v1</guid></item><item><title>LitCab: Lightweight Calibration of Language Models on Outputs of Varied Lengths</title><link>http://arxiv.org/abs/2310.19208v1</link><description>A model is considered well-calibrated when its probability estimate alignswith the actual likelihood of the output being correct. Calibrating languagemodels (LMs) is crucial, as it plays a vital role in detecting and mitigatinghallucinations, a common issue of LMs, as well as building more trustworthymodels. Yet, popular neural model calibration techniques are not well-suitedfor LMs due to their lack of flexibility in discerning answer correctness andtheir high computational costs. For instance, post-processing methods liketemperature scaling are often unable to reorder the candidate generations.Moreover, training-based methods require finetuning the entire model, which isimpractical due to the increasing sizes of modern LMs. In this paper, wepresent LitCab, a lightweight calibration mechanism consisting of a singlelinear layer taking the input text representation and manipulateing the LMoutput logits. LitCab improves model calibration by only adding &lt; 2% of theoriginal model parameters. For evaluation, we construct CaT, a benchmarkconsisting of 7 text generation tasks, covering responses ranging from shortphrases to paragraphs. We test LitCab with Llama2-7B, where it improvescalibration across all tasks, by reducing the average ECE score by 20%. Wefurther conduct a comprehensive evaluation with 7 popular open-sourced LMs fromGPT and LLaMA families, yielding the following key findings: (1) Larger modelswithin the same family exhibit better calibration on tasks with shortgeneration tasks, but not necessarily for longer ones. (2) GPT-family modelsshow superior calibration compared to LLaMA, Llama2 and Vicuna models despitehaving much fewer parameters. (3) Finetuning pretrained model (e.g., LLaMA)with samples of limited purpose (e.g., conversations) may lead to worsecalibration, highlighting the importance of finetuning setups for calibratingLMs.</description><author>Xin Liu, Muhammad Khalifa, Lu Wang</author><pubDate>Mon, 30 Oct 2023 01:30:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19208v1</guid></item><item><title>Leveraging generative artificial intelligence to simulate student learning behavior</title><link>http://arxiv.org/abs/2310.19206v1</link><description>Student simulation presents a transformative approach to enhance learningoutcomes, advance educational research, and ultimately shape the future ofeffective pedagogy. We explore the feasibility of using large language models(LLMs), a remarkable achievement in AI, to simulate student learning behaviors.Unlike conventional machine learning based prediction, we leverage LLMs toinstantiate virtual students with specific demographics and uncover intricatecorrelations among learning experiences, course materials, understandinglevels, and engagement. Our objective is not merely to predict learningoutcomes but to replicate learning behaviors and patterns of real students. Wevalidate this hypothesis through three experiments. The first experiment, basedon a dataset of N = 145, simulates student learning outcomes from demographicdata, revealing parallels with actual students concerning various demographicfactors. The second experiment (N = 4524) results in increasingly realisticsimulated behaviors with more assessment history for virtual studentsmodelling. The third experiment (N = 27), incorporating prior knowledge andcourse interactions, indicates a strong link between virtual students' learningbehaviors and fine-grained mappings from test questions, course materials,engagement and understanding levels. Collectively, these findings deepen ourunderstanding of LLMs and demonstrate its viability for student simulation,empowering more adaptable curricula design to enhance inclusivity andeducational effectiveness.</description><author>Songlin Xu, Xinyu Zhang</author><pubDate>Mon, 30 Oct 2023 01:09:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19206v1</guid></item><item><title>Can ChatGPT advance software testing intelligence? An experience report on metamorphic testing</title><link>http://arxiv.org/abs/2310.19204v1</link><description>While ChatGPT is a well-known artificial intelligence chatbot being used toanswer human's questions, one may want to discover its potential in advancingsoftware testing. We examine the capability of ChatGPT in advancing theintelligence of software testing through a case study on metamorphic testing(MT), a state-of-the-art software testing technique. We ask ChatGPT to generatecandidates of metamorphic relations (MRs), which are basically necessaryproperties of the object program and which traditionally require humanintelligence to identify. These MR candidates are then evaluated in terms ofcorrectness by domain experts. We show that ChatGPT can be used to generate newcorrect MRs to test several software systems. Having said that, the majority ofMR candidates are either defined vaguely or incorrect, especially for systemsthat have never been tested with MT. ChatGPT can be used to advance softwaretesting intelligence by proposing MR candidates that can be later adopted forimplementing tests; but human intelligence should still inevitably be involvedto justify and rectify their correctness.</description><author>Quang-Hung Luu, Huai Liu, Tsong Yueh Chen</author><pubDate>Mon, 30 Oct 2023 01:01:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19204v1</guid></item><item><title>Forecasting Tropical Cyclones with Cascaded Diffusion Models</title><link>http://arxiv.org/abs/2310.01690v3</link><description>As cyclones become more intense due to climate change, the rise of AI-basedmodelling provides a more affordable and accessible approach compared totraditional methods based on mathematical models. This work leverages diffusionmodels to forecast cyclone trajectories and precipitation patterns byintegrating satellite imaging, remote sensing, and atmospheric data, employinga cascaded approach that incorporates forecasting, super-resolution, andprecipitation modelling, with training on a dataset of 51 cyclones from sixmajor basins. Experiments demonstrate that the final forecasts from thecascaded models show accurate predictions up to a 36-hour rollout, with SSIMand PSNR values exceeding 0.5 and 20 dB, respectively, for all three tasks.This work also highlights the promising efficiency of AI methods such asdiffusion models for high-performance needs, such as cyclone forecasting, whileremaining computationally affordable, making them ideal for highly vulnerableregions with critical forecasting needs and financial limitations. Codeaccessible at \url{https://github.com/nathzi1505/forecast-diffmodels}.</description><author>Pritthijit Nath, Pancham Shukla, César Quilodrán-Casas</author><pubDate>Mon, 30 Oct 2023 01:00:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01690v3</guid></item><item><title>Improved Motor Imagery Classification Using Adaptive Spatial Filters Based on Particle Swarm Optimization Algorithm</title><link>http://arxiv.org/abs/2310.19202v1</link><description>As a typical self-paced brain-computer interface (BCI) system, the motorimagery (MI) BCI has been widely applied in fields such as robot control,stroke rehabilitation, and assistance for patients with stroke or spinal cordinjury. Many studies have focused on the traditional spatial filters obtainedthrough the common spatial pattern (CSP) method. However, the CSP method canonly obtain fixed spatial filters for specific input signals. Besides, CSPmethod only focuses on the variance difference of two types ofelectroencephalogram (EEG) signals, so the decoding ability of EEG signals islimited. To obtain more effective spatial filters for better extraction ofspatial features that can improve classification to MI-EEG, this paper proposesan adaptive spatial filter solving method based on particle swarm optimizationalgorithm (PSO). A training and testing framework based on filter bank andspatial filters (FBCSP-ASP) is designed for MI EEG signal classification.Comparative experiments are conducted on two public datasets (2a and 2b) fromBCI competition IV, which show the outstanding average recognition accuracy ofFBCSP-ASP. The proposed method has achieved significant performance improvementon MI-BCI. The classification accuracy of the proposed method has reached74.61% and 81.19% on datasets 2a and 2b, respectively. Compared with thebaseline algorithm (FBCSP), the proposed algorithm improves 11.44% and 7.11% ontwo datasets respectively. Furthermore, the analysis based on mutualinformation, t-SNE and Shapley values further proves that ASP features haveexcellent decoding ability for MI-EEG signals, and explains the improvement ofclassification performance by the introduction of ASP features.</description><author>Xiong Xiong, Ying Wang, Tianyuan Song, Jinguo Huang, Guixia Kang</author><pubDate>Mon, 30 Oct 2023 00:53:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19202v1</guid></item><item><title>Enhancing Motor Imagery Decoding in Brain Computer Interfaces using Riemann Tangent Space Mapping and Cross Frequency Coupling</title><link>http://arxiv.org/abs/2310.19198v1</link><description>Objective: Motor Imagery (MI) serves as a crucial experimental paradigmwithin the realm of Brain Computer Interfaces (BCIs), aiming to decoding motorintentions from electroencephalogram (EEG) signals. Method: Drawing inspirationfrom Riemannian geometry and Cross-Frequency Coupling (CFC), this paperintroduces a novel approach termed Riemann Tangent Space Mapping usingDichotomous Filter Bank with Convolutional Neural Network (DFBRTS) to enhancethe representation quality and decoding capability pertaining to MI features.DFBRTS first initiates the process by meticulously filtering EEG signalsthrough a Dichotomous Filter Bank, structured in the fashion of a completebinary tree. Subsequently, it employs Riemann Tangent Space Mapping to extractsalient EEG signal features within each sub-band. Finally, a lightweightconvolutional neural network is employed for further feature extraction andclassification, operating under the joint supervision of cross-entropy andcenter loss. To validate the efficacy, extensive experiments were conductedusing DFBRTS on two well-established benchmark datasets: the BCI competition IV2a (BCIC-IV-2a) dataset and the OpenBMI dataset. The performance of DFBRTS wasbenchmarked against several state-of-the-art MI decoding methods, alongsideother Riemannian geometry-based MI decoding approaches. Results: DFBRTSsignificantly outperforms other MI decoding algorithms on both datasets,achieving a remarkable classification accuracy of 78.16% for four-class and71.58% for two-class hold-out classification, as compared to the existingbenchmarks.</description><author>Xiong Xiong, Li Su, Jinguo Huang, Guixia Kang</author><pubDate>Mon, 30 Oct 2023 00:37:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19198v1</guid></item><item><title>Unlocking Feature Visualization for Deeper Networks with MAgnitude Constrained Optimization</title><link>http://arxiv.org/abs/2306.06805v2</link><description>Feature visualization has gained substantial popularity, particularly afterthe influential work by Olah et al. in 2017, which established it as a crucialtool for explainability. However, its widespread adoption has been limited dueto a reliance on tricks to generate interpretable images, and correspondingchallenges in scaling it to deeper neural networks. Here, we describe MACO, asimple approach to address these shortcomings. The main idea is to generateimages by optimizing the phase spectrum while keeping the magnitude constant toensure that generated explanations lie in the space of natural images. Ourapproach yields significantly better results (both qualitatively andquantitatively) and unlocks efficient and interpretable feature visualizationsfor large state-of-the-art neural networks. We also show that our approachexhibits an attribution mechanism allowing us to augment feature visualizationswith spatial importance. We validate our method on a novel benchmark forcomparing feature visualization methods, and release its visualizations for allclasses of the ImageNet dataset on https://serre-lab.github.io/Lens/. Overall, our approach unlocks, for the first time, feature visualizations forlarge, state-of-the-art deep neural networks without resorting to anyparametric prior image model.</description><author>Thomas Fel, Thibaut Boissin, Victor Boutin, Agustin Picard, Paul Novello, Julien Colin, Drew Linsley, Tom Rousseau, Rémi Cadène, Laurent Gardes, Thomas Serre</author><pubDate>Mon, 30 Oct 2023 00:13:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06805v2</guid></item><item><title>Conformal Normalization in Recurrent Neural Network of Grid Cells</title><link>http://arxiv.org/abs/2310.19192v1</link><description>Grid cells in the entorhinal cortex of the mammalian brain exhibit strikinghexagon firing patterns in their response maps as the animal (e.g., a rat)navigates in a 2D open environment. The responses of the population of gridcells collectively form a vector in a high-dimensional neural activity space,and this vector represents the self-position of the agent in the 2D physicalspace. As the agent moves, the vector is transformed by a recurrent neuralnetwork that takes the velocity of the agent as input. In this paper, wepropose a simple and general conformal normalization of the input velocity forthe recurrent neural network, so that the local displacement of the positionvector in the high-dimensional neural space is proportional to the localdisplacement of the agent in the 2D physical space, regardless of the directionof the input velocity. Our numerical experiments on the minimally simple linearand non-linear recurrent networks show that conformal normalization leads tothe emergence of the hexagon grid patterns. Furthermore, we derive a newtheoretical understanding that connects conformal normalization to theemergence of hexagon grid patterns in navigation tasks.</description><author>Dehong Xu, Ruiqi Gao, Wen-Hao Zhang, Xue-Xin Wei, Ying Nian Wu</author><pubDate>Mon, 30 Oct 2023 00:12:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19192v1</guid></item><item><title>3DMiner: Discovering Shapes from Large-Scale Unannotated Image Datasets</title><link>http://arxiv.org/abs/2310.19188v1</link><description>We present 3DMiner -- a pipeline for mining 3D shapes from challenginglarge-scale unannotated image datasets. Unlike other unsupervised 3Dreconstruction methods, we assume that, within a large-enough dataset, theremust exist images of objects with similar shapes but varying backgrounds,textures, and viewpoints. Our approach leverages the recent advances inlearning self-supervised image representations to cluster images withgeometrically similar shapes and find common image correspondences betweenthem. We then exploit these correspondences to obtain rough camera estimates asinitialization for bundle-adjustment. Finally, for every image cluster, weapply a progressive bundle-adjusting reconstruction method to learn a neuraloccupancy field representing the underlying shape. We show that this procedureis robust to several types of errors introduced in previous steps (e.g., wrongcamera poses, images containing dissimilar shapes, etc.), allowing us to obtainshape and pose annotations for images in-the-wild. When using images from Pix3Dchairs, our method is capable of producing significantly better results thanstate-of-the-art unsupervised 3D reconstruction techniques, both quantitativelyand qualitatively. Furthermore, we show how 3DMiner can be applied toin-the-wild data by reconstructing shapes present in images from the LAION-5Bdataset. Project Page: https://ttchengab.github.io/3dminerOfficial</description><author>Ta-Ying Cheng, Matheus Gadelha, Soren Pirk, Thibault Groueix, Radomir Mech, Andrew Markham, Niki Trigoni</author><pubDate>Mon, 30 Oct 2023 00:08:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19188v1</guid></item><item><title>Jumping through Local Minima: Quantization in the Loss Landscape of Vision Transformers</title><link>http://arxiv.org/abs/2308.10814v2</link><description>Quantization scale and bit-width are the most important parameters whenconsidering how to quantize a neural network. Prior work focuses on optimizingquantization scales in a global manner through gradient methods (gradientdescent \&amp; Hessian analysis). Yet, when applying perturbations to quantizationscales, we observe a very jagged, highly non-smooth test loss landscape. Infact, small perturbations in quantization scale can greatly affect accuracy,yielding a $0.5-0.8\%$ accuracy boost in 4-bit quantized vision transformers(ViTs). In this regime, gradient methods break down, since they cannot reliablyreach local minima. In our work, dubbed Evol-Q, we use evolutionary search toeffectively traverse the non-smooth landscape. Additionally, we propose usingan infoNCE loss, which not only helps combat overfitting on the smallcalibration dataset ($1,000$ images) but also makes traversing such a highlynon-smooth surface easier. Evol-Q improves the top-1 accuracy of a fullyquantized ViT-Base by $10.30\%$, $0.78\%$, and $0.15\%$ for $3$-bit, $4$-bit,and $8$-bit weight quantization levels. Extensive experiments on a variety ofCNN and ViT architectures further demonstrate its robustness in extremequantization scenarios. Our code is available athttps://github.com/enyac-group/evol-q</description><author>Natalia Frumkin, Dibakar Gope, Diana Marculescu</author><pubDate>Mon, 30 Oct 2023 00:00:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10814v2</guid></item><item><title>Fast Trainable Projection for Robust Fine-Tuning</title><link>http://arxiv.org/abs/2310.19182v1</link><description>Robust fine-tuning aims to achieve competitive in-distribution (ID)performance while maintaining the out-of-distribution (OOD) robustness of apre-trained model when transferring it to a downstream task. Recently,projected gradient descent has been successfully used in robust fine-tuning byconstraining the deviation from the initialization of the fine-tuned modelexplicitly through projection. However, algorithmically, two limitationsprevent this method from being adopted more widely, scalability and efficiency.In this paper, we propose a new projection-based fine-tuning algorithm, FastTrainable Projection (FTP) for computationally efficient learning of per-layerprojection constraints, resulting in an average $35\%$ speedup on ourbenchmarks compared to prior works. FTP can be combined with existingoptimizers such as AdamW, and be used in a plug-and-play fashion. Finally, weshow that FTP is a special instance of hyper-optimizers that tune thehyper-parameters of optimizers in a learnable manner through nesteddifferentiation. Empirically, we show superior robustness on OOD datasets,including domain shifts and natural corruptions, across four different visiontasks with five different pre-trained models. Additionally, we demonstrate thatFTP is broadly applicable and beneficial to other learning scenarios such aslow-label and continual learning settings thanks to its easy adaptability. Thecode will be available at https://github.com/GT-RIPL/FTP.git.</description><author>Junjiao Tian, Yen-Cheng Liu, James Seale Smith, Zsolt Kira</author><pubDate>Sun, 29 Oct 2023 23:52:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19182v1</guid></item><item><title>From Chatbots to PhishBots? -- Preventing Phishing scams created using ChatGPT, Google Bard and Claude</title><link>http://arxiv.org/abs/2310.19181v1</link><description>The advanced capabilities of Large Language Models (LLMs) have made theminvaluable across various applications, from conversational agents and contentcreation to data analysis, research, and innovation. However, theireffectiveness and accessibility also render them susceptible to abuse forgenerating malicious content, including phishing attacks. This study exploresthe potential of using four popular commercially available LLMs - ChatGPT (GPT3.5 Turbo), GPT 4, Claude and Bard to generate functional phishing attacksusing a series of malicious prompts. We discover that these LLMs can generateboth phishing emails and websites that can convincingly imitate well-knownbrands, and also deploy a range of evasive tactics for the latter to eludedetection mechanisms employed by anti-phishing systems. Notably, these attackscan be generated using unmodified, or "vanilla," versions of these LLMs,without requiring any prior adversarial exploits such as jailbreaking. As acountermeasure, we build a BERT based automated detection tool that can be usedfor the early detection of malicious prompts to prevent LLMs from generatingphishing content attaining an accuracy of 97\% for phishing website prompts,and 94\% for phishing email prompts.</description><author>Sayak Saha Roy, Poojitha Thota, Krishna Vamsi Naragam, Shirin Nilizadeh</author><pubDate>Sun, 29 Oct 2023 23:52:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19181v1</guid></item><item><title>Diversify Your Vision Datasets with Automatic Diffusion-Based Augmentation</title><link>http://arxiv.org/abs/2305.16289v2</link><description>Many fine-grained classification tasks, like rare animal identification, havelimited training data and consequently classifiers trained on these datasetsoften fail to generalize to variations in the domain like changes in weather orlocation. As such, we explore how natural language descriptions of the domainsseen in training data can be used with large vision models trained on diversepretraining datasets to generate useful variations of the training data. Weintroduce ALIA (Automated Language-guided Image Augmentation), a method whichutilizes large vision and language models to automatically generate naturallanguage descriptions of a dataset's domains and augment the training data vialanguage-guided image editing. To maintain data integrity, a model trained onthe original dataset filters out minimal image edits and those which corruptclass-relevant information. The resulting dataset is visually consistent withthe original training data and offers significantly enhanced diversity. We showthat ALIA is able to surpasses traditional data augmentation and text-to-imagegenerated data on fine-grained classification tasks, including cases of domaingeneralization and contextual bias. Code is available athttps://github.com/lisadunlap/ALIA.</description><author>Lisa Dunlap, Alyssa Umino, Han Zhang, Jiezhi Yang, Joseph E. Gonzalez, Trevor Darrell</author><pubDate>Sun, 29 Oct 2023 23:52:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16289v2</guid></item><item><title>JEN-1 Composer: A Unified Framework for High-Fidelity Multi-Track Music Generation</title><link>http://arxiv.org/abs/2310.19180v1</link><description>With rapid advances in generative artificial intelligence, the text-to-musicsynthesis task has emerged as a promising direction for music generation fromscratch. However, finer-grained control over multi-track generation remains anopen challenge. Existing models exhibit strong raw generation capability butlack the flexibility to compose separate tracks and combine them in acontrollable manner, differing from typical workflows of human composers. Toaddress this issue, we propose JEN-1 Composer, a unified framework toefficiently model marginal, conditional, and joint distributions overmulti-track music via a single model. JEN-1 Composer framework exhibits thecapacity to seamlessly incorporate any diffusion-based music generation system,\textit{e.g.} Jen-1, enhancing its capacity for versatile multi-track musicgeneration. We introduce a curriculum training strategy aimed at incrementallyinstructing the model in the transition from single-track generation to theflexible generation of multi-track combinations. During the inference, usershave the ability to iteratively produce and choose music tracks that meet theirpreferences, subsequently creating an entire musical composition incrementallyfollowing the proposed Human-AI co-composition workflow. Quantitative andqualitative assessments demonstrate state-of-the-art performance incontrollable and high-fidelity multi-track music synthesis. The proposed JEN-1Composer represents a significant advance toward interactive AI-facilitatedmusic creation and composition. Demos will be available athttps://jenmusic.ai/audio-demos.</description><author>Yao Yao, Peike Li, Boyu Chen, Alex Wang</author><pubDate>Sun, 29 Oct 2023 23:51:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19180v1</guid></item><item><title>On the Vulnerability of DeepFake Detectors to Attacks Generated by Denoising Diffusion Models</title><link>http://arxiv.org/abs/2307.05397v2</link><description>The detection of malicious deepfakes is a constantly evolving problem thatrequires continuous monitoring of detectors to ensure they can detect imagemanipulations generated by the latest emerging models. In this paper, weinvestigate the vulnerability of single-image deepfake detectors to black-boxattacks created by the newest generation of generative methods, namelyDenoising Diffusion Models (DDMs). Our experiments are run on FaceForensics++,a widely used deepfake benchmark consisting of manipulated images generatedwith various techniques for face identity swapping and face reenactment.Attacks are crafted through guided reconstruction of existing deepfakes with aproposed DDM approach for face restoration. Our findings indicate thatemploying just a single denoising diffusion step in the reconstruction processof a deepfake can significantly reduce the likelihood of detection, all withoutintroducing any perceptible image modifications. While training detectors usingattack examples demonstrated some effectiveness, it was observed thatdiscriminators trained on fully diffusion-based deepfakes exhibited limitedgeneralizability when presented with our attacks.</description><author>Marija Ivanovska, Vitomir Štruc</author><pubDate>Sun, 29 Oct 2023 23:41:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.05397v2</guid></item><item><title>Robustifying Language Models with Test-Time Adaptation</title><link>http://arxiv.org/abs/2310.19177v1</link><description>Large-scale language models achieved state-of-the-art performance over anumber of language tasks. However, they fail on adversarial language examples,which are sentences optimized to fool the language models but with similarsemantic meanings for humans. While prior work focuses on making the languagemodel robust at training time, retraining for robustness is often unrealisticfor large-scale foundation models. Instead, we propose to make the languagemodels robust at test time. By dynamically adapting the input sentence withpredictions from masked words, we show that we can reverse many languageadversarial attacks. Since our approach does not require any training, it worksfor novel tasks at test time and can adapt to novel adversarial corruptions.Visualizations and empirical results on two popular sentence classificationdatasets demonstrate that our method can repair adversarial language attacksover 65% o</description><author>Noah Thomas McDermott, Junfeng Yang, Chengzhi Mao</author><pubDate>Sun, 29 Oct 2023 23:37:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19177v1</guid></item><item><title>Predicting recovery following stroke: deep learning, multimodal data and feature selection using explainable AI</title><link>http://arxiv.org/abs/2310.19174v1</link><description>Machine learning offers great potential for automated prediction ofpost-stroke symptoms and their response to rehabilitation. Major challenges forthis endeavour include the very high dimensionality of neuroimaging data, therelatively small size of the datasets available for learning, and how toeffectively combine neuroimaging and tabular data (e.g. demographic informationand clinical characteristics). This paper evaluates several solutions based ontwo strategies. The first is to use 2D images that summarise MRI scans. Thesecond is to select key features that improve classification accuracy.Additionally, we introduce the novel approach of training a convolutionalneural network (CNN) on images that combine regions-of-interest extracted fromMRIs, with symbolic representations of tabular data. We evaluate a series ofCNN architectures (both 2D and a 3D) that are trained on differentrepresentations of MRI and tabular data, to predict whether a composite measureof post-stroke spoken picture description ability is in the aphasic ornon-aphasic range. MRI and tabular data were acquired from 758 English speakingstroke survivors who participated in the PLORAS study. The classificationaccuracy for a baseline logistic regression was 0.678 for lesion size alone,rising to 0.757 and 0.813 when initial symptom severity and recovery time weresuccessively added. The highest classification accuracy 0.854 was observed when8 regions-of-interest was extracted from each MRI scan and combined with lesionsize, initial severity and recovery time in a 2D Residual Neural Network.Ourfindings demonstrate how imaging and tabular data can be combined for highpost-stroke classification accuracy, even when the dataset is small in machinelearning terms. We conclude by proposing how the current models could beimproved to achieve even higher levels of accuracy using images from hospitalscanners.</description><author>Adam White, Margarita Saranti, Artur d'Avila Garcez, Thomas M. H. Hope, Cathy J. Price, Howard Bowman</author><pubDate>Sun, 29 Oct 2023 23:31:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19174v1</guid></item><item><title>A Holistic Approach to Unifying Automatic Concept Extraction and Concept Importance Estimation</title><link>http://arxiv.org/abs/2306.07304v2</link><description>In recent years, concept-based approaches have emerged as some of the mostpromising explainability methods to help us interpret the decisions ofArtificial Neural Networks (ANNs). These methods seek to discover intelligiblevisual 'concepts' buried within the complex patterns of ANN activations in twokey steps: (1) concept extraction followed by (2) importance estimation. Whilethese two steps are shared across methods, they all differ in their specificimplementations. Here, we introduce a unifying theoretical framework thatcomprehensively defines and clarifies these two steps. This framework offersseveral advantages as it allows us: (i) to propose new evaluation metrics forcomparing different concept extraction approaches; (ii) to leverage modernattribution methods and evaluation metrics to extend and systematicallyevaluate state-of-the-art concept-based approaches and importance estimationtechniques; (iii) to derive theoretical guarantees regarding the optimality ofsuch methods. We further leverage our framework to try to tackle a crucialquestion in explainability: how to efficiently identify clusters of data pointsthat are classified based on a similar shared strategy. To illustrate thesefindings and to highlight the main strategies of a model, we introduce a visualrepresentation called the strategic cluster graph. Finally, we presenthttps://serre-lab.github.io/Lens, a dedicated website that offers a completecompilation of these visualizations for all classes of the ImageNet dataset.</description><author>Thomas Fel, Victor Boutin, Mazda Moayeri, Rémi Cadène, Louis Bethune, Léo andéol, Mathieu Chalvidal, Thomas Serre</author><pubDate>Sun, 29 Oct 2023 23:28:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07304v2</guid></item><item><title>Neural Fields with Hard Constraints of Arbitrary Differential Order</title><link>http://arxiv.org/abs/2306.08943v2</link><description>While deep learning techniques have become extremely popular for solving abroad range of optimization problems, methods to enforce hard constraintsduring optimization, particularly on deep neural networks, remainunderdeveloped. Inspired by the rich literature on meshless interpolation andits extension to spectral collocation methods in scientific computing, wedevelop a series of approaches for enforcing hard constraints on neural fields,which we refer to as Constrained Neural Fields (CNF). The constraints can bespecified as a linear operator applied to the neural field and its derivatives.We also design specific model representations and training strategies forproblems where standard models may encounter difficulties, such as conditioningof the system, memory consumption, and capacity of the network when beingconstrained. Our approaches are demonstrated in a wide range of real-worldapplications. Additionally, we develop a framework that enables highlyefficient model and constraint specification, which can be readily applied toany downstream task where hard constraints need to be explicitly satisfiedduring optimization.</description><author>Fangcheng Zhong, Kyle Fogarty, Param Hanji, Tianhao Wu, Alejandro Sztrajman, Andrew Spielberg, Andrea Tagliasacchi, Petra Bosilj, Cengiz Oztireli</author><pubDate>Sun, 29 Oct 2023 23:11:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08943v2</guid></item><item><title>Towards Improved Input Masking for Convolutional Neural Networks</title><link>http://arxiv.org/abs/2211.14646v3</link><description>The ability to remove features from the input of machine learning models isvery important to understand and interpret model predictions. However, this isnon-trivial for vision models since masking out parts of the input imagetypically causes large distribution shifts. This is because the baseline colorused for masking (typically grey or black) is out of distribution. Furthermore,the shape of the mask itself can contain unwanted signals which can be used bythe model for its predictions. Recently, there has been some progress inmitigating this issue (called missingness bias) in image masking for visiontransformers. In this work, we propose a new masking method for CNNs we calllayer masking in which the missingness bias caused by masking is reduced to alarge extent. Intuitively, layer masking applies a mask to intermediateactivation maps so that the model only processes the unmasked input. We showthat our method (i) is able to eliminate or minimize the influence of the maskshape or color on the output of the model, and (ii) is much better thanreplacing the masked region by black or grey for input perturbation basedinterpretability techniques like LIME. Thus, layer masking is much lessaffected by missingness bias than other masking strategies. We also demonstratehow the shape of the mask may leak information about the class, thus affectingestimates of model reliance on class-relevant features derived from inputmasking. Furthermore, we discuss the role of data augmentation techniques fortackling this problem, and argue that they are not sufficient for preventingmodel reliance on mask shape. The code for this project is publicly availableat https://github.com/SriramB-98/layer_masking</description><author>Sriram Balasubramanian, Soheil Feizi</author><pubDate>Sun, 29 Oct 2023 23:11:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.14646v3</guid></item><item><title>BirdSAT: Cross-View Contrastive Masked Autoencoders for Bird Species Classification and Mapping</title><link>http://arxiv.org/abs/2310.19168v1</link><description>We propose a metadata-aware self-supervised learning~(SSL)~framework usefulfor fine-grained classification and ecological mapping of bird species aroundthe world. Our framework unifies two SSL strategies: Contrastive Learning~(CL)and Masked Image Modeling~(MIM), while also enriching the embedding space withmetadata available with ground-level imagery of birds. We separately trainuni-modal and cross-modal ViT on a novel cross-view global bird species datasetcontaining ground-level imagery, metadata (location, time), and correspondingsatellite imagery. We demonstrate that our models learn fine-grained andgeographically conditioned features of birds, by evaluating on two downstreamtasks: fine-grained visual classification~(FGVC) and cross-modal retrieval.Pre-trained models learned using our framework achieve SotA performance on FGVCof iNAT-2021 birds and in transfer learning settings for CUB-200-2011 andNABirds datasets. Moreover, the impressive cross-modal retrieval performance ofour model enables the creation of species distribution maps across anygeographic region. The dataset and source code will be released athttps://github.com/mvrl/BirdSAT}.</description><author>Srikumar Sastry, Subash Khanal, Aayush Dhakal, Di Huang, Nathan Jacobs</author><pubDate>Sun, 29 Oct 2023 23:08:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19168v1</guid></item><item><title>Rare Event Probability Learning by Normalizing Flows</title><link>http://arxiv.org/abs/2310.19167v1</link><description>A rare event is defined by a low probability of occurrence. Accurateestimation of such small probabilities is of utmost importance across diversedomains. Conventional Monte Carlo methods are inefficient, demanding anexorbitant number of samples to achieve reliable estimates. Inspired by theexact sampling capabilities of normalizing flows, we revisit this challenge andpropose normalizing flow assisted importance sampling, termed NOFIS. NOFISfirst learns a sequence of proposal distributions associated with predefinednested subset events by minimizing KL divergence losses. Next, it estimates therare event probability by utilizing importance sampling in conjunction with thelast proposal. The efficacy of our NOFIS method is substantiated throughcomprehensive qualitative visualizations, affirming the optimality of thelearned proposal distribution, as well as a series of quantitative experimentsencompassing $10$ distinct test cases, which highlight NOFIS's superiority overbaseline approaches.</description><author>Zhenggqi Gao, Dinghuai Zhang, Luca Daniel, Duane S. Boning</author><pubDate>Sun, 29 Oct 2023 22:59:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19167v1</guid></item><item><title>The Power of Explainability in Forecast-Informed Deep Learning Models for Flood Mitigation</title><link>http://arxiv.org/abs/2310.19166v1</link><description>Floods can cause horrific harm to life and property. However, they can bemitigated or even avoided by the effective use of hydraulic structures such asdams, gates, and pumps. By pre-releasing water via these structures in advanceof extreme weather events, water levels are sufficiently lowered to preventfloods. In this work, we propose FIDLAR, a Forecast Informed Deep LearningArchitecture, achieving flood management in watersheds with hydraulicstructures in an optimal manner by balancing out flood mitigation andunnecessary wastage of water via pre-releases. We perform experiments withFIDLAR using data from the South Florida Water Management District, whichmanages a coastal area that is highly prone to frequent storms and floods.Results show that FIDLAR performs better than the current state-of-the-art withseveral orders of magnitude speedup and with provably better pre-releaseschedules. The dramatic speedups make it possible for FIDLAR to be used forreal-time flood management. The main contribution of this paper is theeffective use of tools for model explainability, allowing us to understand thecontribution of the various environmental factors towards its decisions.</description><author>Jimeng Shi, Vitalii Stebliankin, Giri Narasimhan</author><pubDate>Sun, 29 Oct 2023 22:56:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19166v1</guid></item><item><title>Decision Stacks: Flexible Reinforcement Learning via Modular Generative Models</title><link>http://arxiv.org/abs/2306.06253v2</link><description>Reinforcement learning presents an attractive paradigm to reason aboutseveral distinct aspects of sequential decision making, such as specifyingcomplex goals, planning future observations and actions, and critiquing theirutilities. However, the combined integration of these capabilities posescompeting algorithmic challenges in retaining maximal expressivity whileallowing for flexibility in modeling choices for efficient learning andinference. We present Decision Stacks, a generative framework that decomposesgoal-conditioned policy agents into 3 generative modules. These modulessimulate the temporal evolution of observations, rewards, and actions viaindependent generative models that can be learned in parallel via teacherforcing. Our framework guarantees both expressivity and flexibility indesigning individual modules to account for key factors such as architecturalbias, optimization objective and dynamics, transferrability across domains, andinference speed. Our empirical results demonstrate the effectiveness ofDecision Stacks for offline policy optimization for several MDP and POMDPenvironments, outperforming existing methods and enabling flexible generativedecision making.</description><author>Siyan Zhao, Aditya Grover</author><pubDate>Sun, 29 Oct 2023 22:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06253v2</guid></item><item><title>RAIFLE: Reconstruction Attacks on Interaction-based Federated Learning with Active Data Manipulation</title><link>http://arxiv.org/abs/2310.19163v1</link><description>Federated learning (FL) has recently emerged as a privacy-preserving approachfor machine learning in domains that rely on user interactions, particularlyrecommender systems (RS) and online learning to rank (OLTR). While there hasbeen substantial research on the privacy of traditional FL, little attentionhas been paid to studying the privacy properties of these interaction-based FL(IFL) systems. In this work, we show that IFL can introduce unique challengesconcerning user privacy, particularly when the central server has knowledge andcontrol over the items that users interact with. Specifically, we demonstratethe threat of reconstructing user interactions by presenting RAIFLE, a generaloptimization-based reconstruction attack framework customized for IFL. RAIFLEemploys Active Data Manipulation (ADM), a novel attack technique unique to IFL,where the server actively manipulates the training features of the items toinduce adversarial behaviors in the local FL updates. We show that RAIFLE ismore impactful than existing FL privacy attacks in the IFL context, anddescribe how it can undermine privacy defenses like secure aggregation andprivate information retrieval. Based on our findings, we propose and discusscountermeasure guidelines to mitigate our attack in the context of federatedRS/OLTR specifically and IFL more broadly.</description><author>Dzung Pham, Shreyas Kulkarni, Amir Houmansadr</author><pubDate>Sun, 29 Oct 2023 22:47:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19163v1</guid></item><item><title>LEACE: Perfect linear concept erasure in closed form</title><link>http://arxiv.org/abs/2306.03819v3</link><description>Concept erasure aims to remove specified features from a representation. Itcan improve fairness (e.g. preventing a classifier from using gender or race)and interpretability (e.g. removing a concept to observe changes in modelbehavior). We introduce LEAst-squares Concept Erasure (LEACE), a closed-formmethod which provably prevents all linear classifiers from detecting a conceptwhile changing the representation as little as possible, as measured by a broadclass of norms. We apply LEACE to large language models with a novel procedurecalled "concept scrubbing," which erases target concept information from everylayer in the network. We demonstrate our method on two tasks: measuring thereliance of language models on part-of-speech information, and reducing genderbias in BERT embeddings. Code is available athttps://github.com/EleutherAI/concept-erasure.</description><author>Nora Belrose, David Schneider-Joseph, Shauli Ravfogel, Ryan Cotterell, Edward Raff, Stella Biderman</author><pubDate>Sun, 29 Oct 2023 22:41:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03819v3</guid></item><item><title>ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers</title><link>http://arxiv.org/abs/2305.14591v2</link><description>Large language models (LLMs) excel at implementing code from functionalitydescriptions but struggle with algorithmic problems that require not onlyimplementation but also identification of the suitable algorithm. Moreover,LLM-generated programs lack guaranteed correctness and require humanverification. To address these challenges, we propose ALGO, a framework thatsynthesizes Algorithmic programs with LLM-Generated Oracles to guide thegeneration and verify their correctness. ALGO first generates a referenceoracle by prompting an LLM to exhaustively enumerate all the combinations ofrelevant variables. This oracle is then utilized to guide an arbitrary searchstrategy in exploring the algorithm space and to verify the synthesizedalgorithms. Our study shows that the LLM-generated oracles are correct for 88%of the cases. With the oracles as verifiers, ALGO can be integrated with anyexisting code generation model in a model-agnostic manner to enhance itsperformance. Experiments show that when equipped with ALGO, we achieve an 8xbetter one-submission pass rate over the Codex model and a 2.6x betterone-submission pass rate over CodeT, the current state-of-the-art model onCodeContests. We can also get 1.3x better pass rate over the ChatGPT CodeInterpreter on unseen problems. The problem set we used for testing, theprompts we used, the verifier and solution programs, and the test casesgenerated by ALGO are available at https://github.com/zkx06111/ALGO.</description><author>Kexun Zhang, Danqing Wang, Jingtao Xia, William Yang Wang, Lei Li</author><pubDate>Sun, 29 Oct 2023 22:37:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14591v2</guid></item><item><title>From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and Beyond</title><link>http://arxiv.org/abs/2310.10121v2</link><description>Graph neural networks (GNNs) have demonstrated significant promise inmodelling relational data and have been widely applied in various fields ofinterest. The key mechanism behind GNNs is the so-called message passing whereinformation is being iteratively aggregated to central nodes from theirneighbourhood. Such a scheme has been found to be intrinsically linked to aphysical process known as heat diffusion, where the propagation of GNNsnaturally corresponds to the evolution of heat density. Analogizing the processof message passing to the heat dynamics allows to fundamentally understand thepower and pitfalls of GNNs and consequently informs better model design.Recently, there emerges a plethora of works that proposes GNNs inspired fromthe continuous dynamics formulation, in an attempt to mitigate the knownlimitations of GNNs, such as oversmoothing and oversquashing. In this survey,we provide the first systematic and comprehensive review of studies thatleverage the continuous perspective of GNNs. To this end, we introducefoundational ingredients for adapting continuous dynamics to GNNs, along with ageneral framework for the design of graph neural dynamics. We then review andcategorize existing works based on their driven mechanisms and underlyingdynamics. We also summarize how the limitations of classic GNNs can beaddressed under the continuous framework. We conclude by identifying multipleopen research directions.</description><author>Andi Han, Dai Shi, Lequan Lin, Junbin Gao</author><pubDate>Sun, 29 Oct 2023 22:31:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10121v2</guid></item><item><title>Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis</title><link>http://arxiv.org/abs/2304.04675v3</link><description>Large language models (LLMs) have demonstrated remarkable potential inhandling multilingual machine translation (MMT). In this paper, wesystematically investigate the advantages and challenges of LLMs for MMT byanswering two questions: 1) How well do LLMs perform in translating massivelanguages? 2) Which factors affect LLMs' performance in translation? Wethoroughly evaluate eight popular LLMs, including ChatGPT and GPT-4. Ourempirical results show that translation capabilities of LLMs are continuallyimproving. GPT-4 has beat the strong supervised baseline NLLB in 40.91% oftranslation directions but still faces a large gap towards the commercialtranslation system, especially on low-resource languages. Through furtheranalysis, we discover that LLMs exhibit new working patterns when used for MMT.First, instruction semantics can surprisingly be ignored when given in-contextexemplars. Second, cross-lingual exemplars can provide better task guidance forlow-resource translation than exemplars in the same language pairs. Third, LLMcan acquire translation ability in a resource-efficient way and generatemoderate translation even on zero-resource languages.</description><author>Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Shujian Huang, Lingpeng Kong, Jiajun Chen, Lei Li</author><pubDate>Sun, 29 Oct 2023 22:23:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.04675v3</guid></item><item><title>Transfer Learning in Transformer-Based Demand Forecasting For Home Energy Management System</title><link>http://arxiv.org/abs/2310.19159v1</link><description>Increasingly, homeowners opt for photovoltaic (PV) systems and/or batterystorage to minimize their energy bills and maximize renewable energy usage.This has spurred the development of advanced control algorithms that maximallyachieve those goals. However, a common challenge faced while developing suchcontrollers is the unavailability of accurate forecasts of household powerconsumption, especially for shorter time resolutions (15 minutes) and in adata-efficient manner. In this paper, we analyze how transfer learning can helpby exploiting data from multiple households to improve a single house's loadforecasting. Specifically, we train an advanced forecasting model (a temporalfusion transformer) using data from multiple different households, and thenfinetune this global model on a new household with limited data (i.e. only afew days). The obtained models are used for forecasting power consumption ofthe household for the next 24 hours~(day-ahead) at a time resolution of 15minutes, with the intention of using these forecasts in advanced controllerssuch as Model Predictive Control. We show the benefit of this transfer learningsetup versus solely using the individual new household's data, both in terms of(i) forecasting accuracy ($\sim$15\% MAE reduction) and (ii) controlperformance ($\sim$2\% energy cost reduction), using real-world household data.</description><author>Gargya Gokhale, Jonas Van Gompel, Bert Claessens, Chris Develder</author><pubDate>Sun, 29 Oct 2023 22:19:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19159v1</guid></item><item><title>Poisoning Retrieval Corpora by Injecting Adversarial Passages</title><link>http://arxiv.org/abs/2310.19156v1</link><description>Dense retrievers have achieved state-of-the-art performance in variousinformation retrieval tasks, but to what extent can they be safely deployed inreal-world applications? In this work, we propose a novel attack for denseretrieval systems in which a malicious user generates a small number ofadversarial passages by perturbing discrete tokens to maximize similarity witha provided set of training queries. When these adversarial passages areinserted into a large retrieval corpus, we show that this attack is highlyeffective in fooling these systems to retrieve them for queries that were notseen by the attacker. More surprisingly, these adversarial passages candirectly generalize to out-of-domain queries and corpora with a high successattack rate -- for instance, we find that 50 generated passages optimized onNatural Questions can mislead &gt;94% of questions posed in financial documents oronline forums. We also benchmark and compare a range of state-of-the-art denseretrievers, both unsupervised and supervised. Although different systemsexhibit varying levels of vulnerability, we show they can all be successfullyattacked by injecting up to 500 passages, a small fraction compared to aretrieval corpus of millions of passages.</description><author>Zexuan Zhong, Ziqing Huang, Alexander Wettig, Danqi Chen</author><pubDate>Sun, 29 Oct 2023 22:13:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19156v1</guid></item><item><title>Real-World Implementation of Reinforcement Learning Based Energy Coordination for a Cluster of Households</title><link>http://arxiv.org/abs/2310.19155v1</link><description>Given its substantial contribution of 40\% to global power consumption, thebuilt environment has received increasing attention to serve as a source offlexibility to assist the modern power grid. In that respect, previous researchmainly focused on energy management of individual buildings. In contrast, inthis paper, we focus on aggregated control of a set of residential buildings,to provide grid supporting services, that eventually should include ancillaryservices. In particular, we present a real-life pilot study that studies theeffectiveness of reinforcement-learning (RL) in coordinating the powerconsumption of 8 residential buildings to jointly track a target power signal.Our RL approach relies solely on observed data from individual households anddoes not require any explicit building models or simulators, making itpractical to implement and easy to scale. We show the feasibility of ourproposed RL-based coordination strategy in a real-world setting. In a 4-weekcase study, we demonstrate a hierarchical control system, relying on anRL-based ranking system to select which households to activate flex assetsfrom, and a real-time PI control-based power dispatch mechanism to control theselected assets. Our results demonstrate satisfactory power tracking, and theeffectiveness of the RL-based ranks which are learnt in a purely data-drivenmanner.</description><author>Gargya Gokhale, Niels Tiben, Marie-Sophie Verwee, Manu Lahariya, Bert Claessens, Chris Develder</author><pubDate>Sun, 29 Oct 2023 22:10:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19155v1</guid></item><item><title>An Ensemble Approach to Question Classification: Integrating Electra Transformer, GloVe, and LSTM</title><link>http://arxiv.org/abs/2308.06828v3</link><description>Natural Language Processing (NLP) has emerged as a crucial technology forunderstanding and generating human language, playing an essential role in taskssuch as machine translation, sentiment analysis, and more pertinently, questionclassification. As a subfield within NLP, question classification focuses ondetermining the type of information being sought, a fundamental step fordownstream applications like question answering systems. This study presents aninnovative ensemble approach for question classification, combining thestrengths of Electra, GloVe, and LSTM models. Rigorously tested on thewell-regarded TREC dataset, the model demonstrates how the integration of thesedisparate technologies can lead to superior results. Electra brings in itstransformer-based capabilities for complex language understanding, GloVe offersglobal vector representations for capturing word-level semantics, and LSTMcontributes its sequence learning abilities to model long-term dependencies. Byfusing these elements strategically, our ensemble model delivers a robust andefficient solution for the complex task of question classification. Throughrigorous comparisons with well-known models like BERT, RoBERTa, and DistilBERT,the ensemble approach verifies its effectiveness by attaining an 80% accuracyscore on the test dataset.</description><author>Sanad Aburass, Osama Dorgham, Maha Abu Rumman</author><pubDate>Sun, 29 Oct 2023 22:07:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.06828v3</guid></item><item><title>BERT Lost Patience Won't Be Robust to Adversarial Slowdown</title><link>http://arxiv.org/abs/2310.19152v1</link><description>In this paper, we systematically evaluate the robustness of multi-exitlanguage models against adversarial slowdown. To audit their robustness, wedesign a slowdown attack that generates natural adversarial text bypassingearly-exit points. We use the resulting WAFFLE attack as a vehicle to conduct acomprehensive evaluation of three multi-exit mechanisms with the GLUE benchmarkagainst adversarial slowdown. We then show our attack significantly reduces thecomputational savings provided by the three methods in both white-box andblack-box settings. The more complex a mechanism is, the more vulnerable it isto adversarial slowdown. We also perform a linguistic analysis of the perturbedtext inputs, identifying common perturbation patterns that our attackgenerates, and comparing them with standard adversarial text attacks. Moreover,we show that adversarial training is ineffective in defeating our slowdownattack, but input sanitization with a conversational model, e.g., ChatGPT, canremove perturbations effectively. This result suggests that future work isneeded for developing efficient yet robust multi-exit models. Our code isavailable at: https://github.com/ztcoalson/WAFFLE</description><author>Zachary Coalson, Gabriel Ritter, Rakesh Bobba, Sanghyun Hong</author><pubDate>Sun, 29 Oct 2023 22:06:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19152v1</guid></item><item><title>MEGClass: Extremely Weakly Supervised Text Classification via Mutually-Enhancing Text Granularities</title><link>http://arxiv.org/abs/2304.01969v2</link><description>Text classification is essential for organizing unstructured text.Traditional methods rely on human annotations or, more recently, a set of classseed words for supervision, which can be costly, particularly for specializedor emerging domains. To address this, using class surface names alone asextremely weak supervision has been proposed. However, existing approachestreat different levels of text granularity (documents, sentences, or words)independently, disregarding inter-granularity class disagreements and thecontext identifiable exclusively through joint extraction. In order to tacklethese issues, we introduce MEGClass, an extremely weakly-supervised textclassification method that leverages Mutually-Enhancing Text Granularities.MEGClass utilizes coarse- and fine-grained context signals obtained by jointlyconsidering a document's most class-indicative words and sentences. Thisapproach enables the learning of a contextualized document representation thatcaptures the most discriminative class indicators. By preserving theheterogeneity of potential classes, MEGClass can select the most informativeclass-indicative documents as iterative feedback to enhance the initialword-based class representations and ultimately fine-tune a pre-trained textclassifier. Extensive experiments on seven benchmark datasets demonstrate thatMEGClass outperforms other weakly and extremely weakly supervised methods.</description><author>Priyanka Kargupta, Tanay Komarlu, Susik Yoon, Xuan Wang, Jiawei Han</author><pubDate>Sun, 29 Oct 2023 22:03:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.01969v2</guid></item><item><title>Learning in Zero-Sum Linear Quadratic Games with Last-Iterate Convergence</title><link>http://arxiv.org/abs/2309.04272v2</link><description>Zero-sum Linear Quadratic (LQ) games are fundamental in optimal control andcan be used (i)~as a dynamic game formulation for risk-sensitive or robustcontrol and (ii)~as a benchmark setting for multi-agent reinforcement learningwith two competing agents in continuous state-control spaces. In contrast tothe well-studied single-agent linear quadratic regulator problem, zero-sum LQgames entail solving a challenging nonconvex-nonconcave min-max problem with anobjective function that lacks coercivity. Recently, Zhang et al. showed thatan~$\epsilon$-Nash equilibrium (NE) of finite horizon zero-sum LQ games can belearned via nested model-free Natural Policy Gradient (NPG) algorithms withpoly$(1/\epsilon)$ sample complexity. In this work, we propose a simpler nestedZeroth-Order (ZO) algorithm improving sample complexity by several orders ofmagnitude and guaranteeing convergence of the last iterate. Our main resultsare two-fold: (i) in the deterministic setting, we establish the first globallast-iterate linear convergence result for the nested algorithm that seeks NEof zero-sum LQ games; (ii) in the model-free setting, we establisha~$\widetilde{\mathcal{O}}(\epsilon^{-2})$ sample complexity using asingle-point ZO estimator. For our last-iterate convergence results, ouranalysis leverages the Implicit Regularization (IR) property and a new gradientdomination condition for the primal function. Our key improvements in thesample complexity rely on a more sample-efficient nested algorithm design and afiner control of the ZO natural gradient estimation error utilizing thestructure endowed by the finite-horizon setting.</description><author>Jiduan Wu, Anas Barakat, Ilyas Fatkhullin, Niao He</author><pubDate>Sun, 29 Oct 2023 22:02:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04272v2</guid></item><item><title>Learning to Follow Object-Centric Image Editing Instructions Faithfully</title><link>http://arxiv.org/abs/2310.19145v1</link><description>Natural language instructions are a powerful interface for editing theoutputs of text-to-image diffusion models. However, several challenges need tobe addressed: 1) underspecification (the need to model the implicit meaning ofinstructions) 2) grounding (the need to localize where the edit has to beperformed), 3) faithfulness (the need to preserve the elements of the image notaffected by the edit instruction). Current approaches focusing on image editingwith natural language instructions rely on automatically generated paired data,which, as shown in our investigation, is noisy and sometimes nonsensical,exacerbating the above issues. Building on recent advances in segmentation,Chain-of-Thought prompting, and visual question answering, we significantlyimprove the quality of the paired data. In addition, we enhance the supervisionsignal by highlighting parts of the image that need to be changed by theinstruction. The model fine-tuned on the improved data is capable of performingfine-grained object-centric edits better than state-of-the-art baselines,mitigating the problems outlined above, as shown by automatic and humanevaluations. Moreover, our model is capable of generalizing to domains unseenduring training, such as visual metaphors.</description><author>Tuhin Chakrabarty, Kanishk Singh, Arkadiy Saakyan, Smaranda Muresan</author><pubDate>Sun, 29 Oct 2023 21:39:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19145v1</guid></item><item><title>MAG-GNN: Reinforcement Learning Boosted Graph Neural Network</title><link>http://arxiv.org/abs/2310.19142v1</link><description>While Graph Neural Networks (GNNs) recently became powerful tools in graphlearning tasks, considerable efforts have been spent on improving GNNs'structural encoding ability. A particular line of work proposed subgraph GNNsthat use subgraph information to improve GNNs' expressivity and achieved greatsuccess. However, such effectivity sacrifices the efficiency of GNNs byenumerating all possible subgraphs. In this paper, we analyze the necessity ofcomplete subgraph enumeration and show that a model can achieve a comparablelevel of expressivity by considering a small subset of the subgraphs. We thenformulate the identification of the optimal subset as a combinatorialoptimization problem and propose Magnetic Graph Neural Network (MAG-GNN), areinforcement learning (RL) boosted GNN, to solve the problem. Starting with acandidate subgraph set, MAG-GNN employs an RL agent to iteratively update thesubgraphs to locate the most expressive set for prediction. This reduces theexponential complexity of subgraph enumeration to the constant complexity of asubgraph search algorithm while keeping good expressivity. We conduct extensiveexperiments on many datasets, showing that MAG-GNN achieves competitiveperformance to state-of-the-art methods and even outperforms many subgraphGNNs. We also demonstrate that MAG-GNN effectively reduces the running time ofsubgraph GNNs.</description><author>Lecheng Kong, Jiarui Feng, Hao Liu, Dacheng Tao, Yixin Chen, Muhan Zhang</author><pubDate>Sun, 29 Oct 2023 21:32:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19142v1</guid></item><item><title>MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions</title><link>http://arxiv.org/abs/2305.14795v2</link><description>The information stored in large language models (LLMs) falls out of datequickly, and retraining from scratch is often not an option. This has recentlygiven rise to a range of techniques for injecting new facts through updatingmodel weights. Current evaluation paradigms are extremely limited, mainlyvalidating the recall of edited facts, but changing one fact should causerippling changes to the model's related beliefs. If we edit the UK PrimeMinister to now be Rishi Sunak, then we should get a different answer to Who ismarried to the British Prime Minister? In this work, we present a benchmark,MQuAKE (Multi-hop Question Answering for Knowledge Editing), comprisingmulti-hop questions that assess whether edited models correctly answerquestions where the answer should change as an entailed consequence of editedfacts. While we find that current knowledge-editing approaches can recalledited facts accurately, they fail catastrophically on the constructedmulti-hop questions. We thus propose a simple memory-based approach, MeLLo,which stores all edited facts externally while prompting the language modeliteratively to generate answers that are consistent with the edited facts.While MQuAKE remains challenging, we show that MeLLo scales well with LLMs (upto 175B) and outperforms previous model editors by a large margin.</description><author>Zexuan Zhong, Zhengxuan Wu, Christopher D. Manning, Christopher Potts, Danqi Chen</author><pubDate>Sun, 29 Oct 2023 21:28:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14795v2</guid></item><item><title>A Visual Active Search Framework for Geospatial Exploration</title><link>http://arxiv.org/abs/2211.15788v3</link><description>Many problems can be viewed as forms of geospatial search aided by aerialimagery, with examples ranging from detecting poaching activity to humantrafficking. We model this class of problems in a visual active search (VAS)framework, which has three key inputs: (1) an image of the entire search area,which is subdivided into regions, (2) a local search function, which determineswhether a previously unseen object class is present in a given region, and (3)a fixed search budget, which limits the number of times the local searchfunction can be evaluated. The goal is to maximize the number of objects foundwithin the search budget. We propose a reinforcement learning approach for VASthat learns a meta-search policy from a collection of fully annotated searchtasks. This meta-search policy is then used to dynamically search for a noveltarget-object class, leveraging the outcome of any previous queries todetermine where to query next. Through extensive experiments on severallarge-scale satellite imagery datasets, we show that the proposed approachsignificantly outperforms several strong baselines. We also propose noveldomain adaptation techniques that improve the policy at decision time whenthere is a significant domain gap with the training data. Code is publiclyavailable.</description><author>Anindya Sarkar, Michael Lanier, Scott Alfeld, Jiarui Feng, Roman Garnett, Nathan Jacobs, Yevgeniy Vorobeychik</author><pubDate>Sun, 29 Oct 2023 21:24:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.15788v3</guid></item><item><title>Backward and Forward Inference in Interacting Independent-Cascade Processes: A Scalable and Convergent Message-Passing Approach</title><link>http://arxiv.org/abs/2310.19138v1</link><description>We study the problems of estimating the past and future evolutions of twodiffusion processes that spread concurrently on a network. Specifically, givena known network $G=(V, \overrightarrow{E})$ and a (possibly noisy) snapshot$\mathcal{O}_n$ of its state taken at (a possibly unknown) time $W$, we wish todetermine the posterior distributions of the initial state of the network andthe infection times of its nodes. These distributions are useful in findingsource nodes of epidemics and rumors -- $\textit{backward inference}$ -- , andestimating the spread of a fixed set of source nodes -- $\textit{forwardinference}$. To model the interaction between the two processes, we study an extension ofthe independent-cascade (IC) model where, when a node gets infected with eitherprocess, its susceptibility to the other one changes. First, we derive theexact joint probability of the initial state of the network and theobservation-snapshot $\mathcal{O}_n$. Then, using the machinery offactor-graphs, factor-graph transformations, and the generalizeddistributive-law, we derive a Belief-Propagation (BP) based algorithm that isscalable to large networks and can converge on graphs of arbitrary topology (ata likely expense in approximation accuracy).</description><author>Nouman Khan, Kangle Mu, Mehrdad Moharrami, Vijay Subramanian</author><pubDate>Sun, 29 Oct 2023 21:03:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19138v1</guid></item><item><title>Automaton Distillation: Neuro-Symbolic Transfer Learning for Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2310.19137v1</link><description>Reinforcement learning (RL) is a powerful tool for finding optimal policiesin sequential decision processes. However, deep RL methods suffer from twoweaknesses: collecting the amount of agent experience required for practical RLproblems is prohibitively expensive, and the learned policies exhibit poorgeneralization on tasks outside of the training distribution. To mitigate theseissues, we introduce automaton distillation, a form of neuro-symbolic transferlearning in which Q-value estimates from a teacher are distilled into alow-dimensional representation in the form of an automaton. We then propose twomethods for generating Q-value estimates: static transfer, which reasons overan abstract Markov Decision Process constructed based on prior knowledge, anddynamic transfer, where symbolic information is extracted from a teacher DeepQ-Network (DQN). The resulting Q-value estimates from either method are used tobootstrap learning in the target environment via a modified DQN loss function.We list several failure modes of existing automaton-based transfer methods anddemonstrate that both static and dynamic automaton distillation decrease thetime required to find optimal policies for various decision tasks.</description><author>Suraj Singireddy, Andre Beckus, George Atia, Sumit Jha, Alvaro Velasquez</author><pubDate>Sun, 29 Oct 2023 20:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19137v1</guid></item><item><title>Alignment with human representations supports robust few-shot learning</title><link>http://arxiv.org/abs/2301.11990v3</link><description>Should we care whether AI systems have representations of the world that aresimilar to those of humans? We provide an information-theoretic analysis thatsuggests that there should be a U-shaped relationship between the degree ofrepresentational alignment with humans and performance on few-shot learningtasks. We confirm this prediction empirically, finding such a relationship inan analysis of the performance of 491 computer vision models. We also show thathighly-aligned models are more robust to both natural adversarial attacks anddomain shifts. Our results suggest that human-alignment is often a sufficient,but not necessary, condition for models to make effective use of limited data,be robust, and generalize well.</description><author>Ilia Sucholutsky, Thomas L. Griffiths</author><pubDate>Sun, 29 Oct 2023 20:45:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11990v3</guid></item><item><title>Koopman Kernel Regression</title><link>http://arxiv.org/abs/2305.16215v2</link><description>Many machine learning approaches for decision making, such as reinforcementlearning, rely on simulators or predictive models to forecast thetime-evolution of quantities of interest, e.g., the state of an agent or thereward of a policy. Forecasts of such complex phenomena are commonly describedby highly nonlinear dynamical systems, making their use in optimization-baseddecision-making challenging. Koopman operator theory offers a beneficialparadigm for addressing this problem by characterizing forecasts via lineartime-invariant (LTI) ODEs -- turning multi-step forecasting into sparse matrixmultiplications. Though there exists a variety of learning approaches, theyusually lack crucial learning-theoretic guarantees, making the behavior of theobtained models with increasing data and dimensionality unclear. We address theaforementioned by deriving a novel reproducing kernel Hilbert space (RKHS) overtrajectories that solely spans transformations into LTI dynamical systems. Theresulting Koopman Kernel Regression (KKR) framework enables the use ofstatistical learning tools from function approximation for novel convergenceresults and generalization error bounds under weaker assumptions than existingwork. Our experiments demonstrate superior forecasting performance compared toKoopman operator and sequential data predictors in RKHS.</description><author>Petar Bevanda, Max Beier, Armin Lederer, Stefan Sosnowski, Eyke Hüllermeier, Sandra Hirche</author><pubDate>Sun, 29 Oct 2023 20:44:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16215v2</guid></item><item><title>Women Wearing Lipstick: Measuring the Bias Between an Object and Its Related Gender</title><link>http://arxiv.org/abs/2310.19130v1</link><description>In this paper, we investigate the impact of objects on gender bias in imagecaptioning systems. Our results show that only gender-specific objects have astrong gender bias (e.g., women-lipstick). In addition, we propose a visualsemantic-based gender score that measures the degree of bias and can be used asa plug-in for any image captioning system. Our experiments demonstrate theutility of the gender score, since we observe that our score can measure thebias relation between a caption and its related gender; therefore, our scorecan be used as an additional metric to the existing Object Gender Co-Occapproach. Code and data are publicly available at\url{https://github.com/ahmedssabir/GenderScore}.</description><author>Ahmed Sabir, Lluís Padró</author><pubDate>Sun, 29 Oct 2023 20:39:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19130v1</guid></item><item><title>DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method</title><link>http://arxiv.org/abs/2305.16284v2</link><description>This paper proposes a new easy-to-implement parameter-free gradient-basedoptimizer: DoWG (Distance over Weighted Gradients). We prove that DoWG isefficient -- matching the convergence rate of optimally tuned gradient descentin convex optimization up to a logarithmic factor without tuning anyparameters, and universal -- automatically adapting to both smooth andnonsmooth problems. While popular algorithms following the AdaGrad frameworkcompute a running average of the squared gradients to use for normalization,DoWG maintains a new distance-based weighted version of the running average,which is crucial to achieve the desired properties. To complement our theory,we also show empirically that DoWG trains at the edge of stability, andvalidate its effectiveness on practical machine learning tasks.</description><author>Ahmed Khaled, Konstantin Mishchenko, Chi Jin</author><pubDate>Sun, 29 Oct 2023 20:36:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16284v2</guid></item><item><title>Federated Learning for Medical Applications: A Taxonomy, Current Trends, Challenges, and Future Research Directions</title><link>http://arxiv.org/abs/2208.03392v5</link><description>With the advent of the IoT, AI, ML, and DL algorithms, the landscape ofdata-driven medical applications has emerged as a promising avenue fordesigning robust and scalable diagnostic and prognostic models from medicaldata. This has gained a lot of attention from both academia and industry,leading to significant improvements in healthcare quality. However, theadoption of AI-driven medical applications still faces tough challenges,including meeting security, privacy, and quality of service (QoS) standards.Recent developments in \ac{FL} have made it possible to train complexmachine-learned models in a distributed manner and have become an activeresearch domain, particularly processing the medical data at the edge of thenetwork in a decentralized way to preserve privacy and address securityconcerns. To this end, in this paper, we explore the present and future of FLtechnology in medical applications where data sharing is a significantchallenge. We delve into the current research trends and their outcomes,unravelling the complexities of designing reliable and scalable \ac{FL} models.Our paper outlines the fundamental statistical issues in FL, tacklesdevice-related problems, addresses security challenges, and navigates thecomplexity of privacy concerns, all while highlighting its transformativepotential in the medical field. Our study primarily focuses on medicalapplications of \ac{FL}, particularly in the context of global cancerdiagnosis. We highlight the potential of FL to enable computer-aided diagnosistools that address this challenge with greater effectiveness than traditionaldata-driven methods. We hope that this comprehensive review will serve as acheckpoint for the field, summarizing the current state-of-the-art andidentifying open problems and future research directions.</description><author>Ashish Rauniyar, Desta Haileselassie Hagos, Debesh Jha, Jan Erik Håkegård, Ulas Bagci, Danda B. Rawat, Vladimir Vlassov</author><pubDate>Sun, 29 Oct 2023 20:32:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.03392v5</guid></item><item><title>Unified Representation for Non-compositional and Compositional Expressions</title><link>http://arxiv.org/abs/2310.19127v1</link><description>Accurate processing of non-compositional language relies on generating goodrepresentations for such expressions. In this work, we study the representationof language non-compositionality by proposing a language model, PIER, thatbuilds on BART and can create semantically meaningful and contextuallyappropriate representations for English potentially idiomatic expressions(PIEs). PIEs are characterized by their non-compositionality and contextualambiguity in their literal and idiomatic interpretations. Via intrinsicevaluation on embedding quality and extrinsic evaluation on PIE processing andNLU tasks, we show that representations generated by PIER result in 33% higherhomogeneity score for embedding clustering than BART, whereas 3.12% and 3.29%gains in accuracy and sequence accuracy for PIE sense classification and spandetection compared to the state-of-the-art IE representation model, GIEA. Thesegains are achieved without sacrificing PIER's performance on NLU tasks (+/- 1%accuracy) compared to BART.</description><author>Ziheng Zeng, Suma Bhat</author><pubDate>Sun, 29 Oct 2023 20:28:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19127v1</guid></item><item><title>Guided Motion Diffusion for Controllable Human Motion Synthesis</title><link>http://arxiv.org/abs/2305.12577v3</link><description>Denoising diffusion models have shown great promise in human motion synthesisconditioned on natural language descriptions. However, integrating spatialconstraints, such as pre-defined motion trajectories and obstacles, remains achallenge despite being essential for bridging the gap between isolated humanmotion and its surrounding environment. To address this issue, we proposeGuided Motion Diffusion (GMD), a method that incorporates spatial constraintsinto the motion generation process. Specifically, we propose an effectivefeature projection scheme that manipulates motion representation to enhance thecoherency between spatial information and local poses. Together with a newimputation formulation, the generated motion can reliably conform to spatialconstraints such as global motion trajectories. Furthermore, given sparsespatial constraints (e.g. sparse keyframes), we introduce a new dense guidanceapproach to turn a sparse signal, which is susceptible to being ignored duringthe reverse steps, into denser signals to guide the generated motion to thegiven constraints. Our extensive experiments justify the development of GMD,which achieves a significant improvement over state-of-the-art methods intext-based motion generation while allowing control of the synthesized motionswith spatial constraints.</description><author>Korrawe Karunratanakul, Konpat Preechakul, Supasorn Suwajanakorn, Siyu Tang</author><pubDate>Sun, 29 Oct 2023 20:27:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12577v3</guid></item><item><title>Worst-case Performance of Popular Approximate Nearest Neighbor Search Implementations: Guarantees and Limitations</title><link>http://arxiv.org/abs/2310.19126v1</link><description>Graph-based approaches to nearest neighbor search are popular and powerfultools for handling large datasets in practice, but they have limitedtheoretical guarantees. We study the worst-case performance of recentgraph-based approximate nearest neighbor search algorithms, such as HNSW, NSGand DiskANN. For DiskANN, we show that its "slow preprocessing" versionprovably supports approximate nearest neighbor search query with constantapproximation ratio and poly-logarithmic query time, on data sets with bounded"intrinsic" dimension. For the other data structure variants studied, includingDiskANN with "fast preprocessing", HNSW and NSG, we present a family ofinstances on which the empirical query time required to achieve a "reasonable"accuracy is linear in instance size. For example, for DiskANN, we show that thequery procedure can take at least $0.1 n$ steps on instances of size $n$ beforeit encounters any of the $5$ nearest neighbors of the query.</description><author>Piotr Indyk, Haike Xu</author><pubDate>Sun, 29 Oct 2023 20:25:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19126v1</guid></item><item><title>STHG: Spatial-Temporal Heterogeneous Graph Learning for Advanced Audio-Visual Diarization</title><link>http://arxiv.org/abs/2306.10608v3</link><description>This report introduces our novel method named STHG for the Audio-VisualDiarization task of the Ego4D Challenge 2023. Our key innovation is that wemodel all the speakers in a video using a single, unified heterogeneous graphlearning framework. Unlike previous approaches that require a separatecomponent solely for the camera wearer, STHG can jointly detect the speechactivities of all people including the camera wearer. Our final method obtains61.1% DER on the test set of Ego4D, which significantly outperforms all thebaselines as well as last year's winner. Our submission achieved 1st place inthe Ego4D Challenge 2023. We additionally demonstrate that applying theoff-the-shelf speech recognition system to the diarized speech segments by STHGproduces a competitive performance on the Speech Transcription task of thischallenge.</description><author>Kyle Min</author><pubDate>Sun, 29 Oct 2023 20:24:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10608v3</guid></item><item><title>Intel Labs at Ego4D Challenge 2022: A Better Baseline for Audio-Visual Diarization</title><link>http://arxiv.org/abs/2210.07764v3</link><description>This report describes our approach for the Audio-Visual Diarization (AVD)task of the Ego4D Challenge 2022. Specifically, we present multiple technicalimprovements over the official baselines. First, we improve the detectionperformance of the camera wearer's voice activity by modifying the trainingscheme of its model. Second, we discover that an off-the-shelf voice activitydetection model can effectively remove false positives when it is appliedsolely to the camera wearer's voice activities. Lastly, we show that betteractive speaker detection leads to a better AVD outcome. Our final methodobtains 65.9% DER on the test set of Ego4D, which significantly outperforms allthe baselines. Our submission achieved 1st place in the Ego4D Challenge 2022.</description><author>Kyle Min</author><pubDate>Sun, 29 Oct 2023 20:22:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.07764v3</guid></item><item><title>Software engineering for deep learning applications: usage of SWEng and MLops tools in GitHub repositories</title><link>http://arxiv.org/abs/2310.19124v1</link><description>The rising popularity of deep learning (DL) methods and techniques hasinvigorated interest in the topic of SE4DL, the application of softwareengineering (SE) practices on deep learning software. Despite the novelengineering challenges brought on by the data-driven and non-deterministicparadigm of DL software, little work has been invested into developingAI-targeted SE tools. On the other hand, tools tackling more generalengineering issues in DL are actively used and referred to under the umbrellaterm of ``MLOps tools''. Furthermore, the available literature supports theutility of conventional SE tooling in DL software development. Building uponprevious MSR research on tool usage in open-source software works, we identifyconventional and MLOps tools adopted in popular applied DL projects that usePython as the main programming language. About 70% of the GitHub repositoriesmined contained at least one conventional SE tool. Software configurationmanagement tools are the most adopted, while the opposite applies tomaintenance tools. Substantially fewer MLOps tools were in use, with only 9tools out of a sample of 80 used in at least one repository. The majority ofthem were open-source rather than proprietary. One of these tools, TensorBoard,was found to be adopted in about half of the repositories in our study.Consequently, the use of conventional SE tooling demonstrates its relevance toDL software. Further research is recommended on the adoption of MLOps toolingby open-source projects, focusing on the relevance of particular tool types,the development of required tools, as well as ways to promote the use ofalready available tools.</description><author>Evangelia Panourgia, Theodoros Plessas, Diomidis Spinellis</author><pubDate>Sun, 29 Oct 2023 20:21:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19124v1</guid></item><item><title>Three Dogmas, a Puzzle and its Solution</title><link>http://arxiv.org/abs/2310.19123v1</link><description>Modern Logics, as formulated notably by Frege, Russell and Tarski involvedbasic assumptions about Natural Languages in general and Indo-EuropeanLanguages in particular, which are contested by Linguists. Based upon thoseassumptions, formal Languages were designed to overcome what Logicians claimedto be 'defects' of Natural Language. In this paper we show that thoseassumptions contradict basic principles of Arabic. More specifically: TheLogicians ideas, that within Natural Language words refer to objects,'ToBe'-constructions represent identity statements, Indefinite Descriptionsmust be replaced by existential quantifiers to form meaningful Sentences andSymbols can have no interpretation-independent meanings, are all falsifiedusing undisputed principles of Arabic. The here presented falsification servestwo purposes. First, it is used as a factual basis for the rejection ofapproaches adopting Semantic axioms of Mathematical Logics as Models formeaning of Arabic Syntax. Second, it shows a way to approach the importantcomputational problem: Satisfiability (SAT). The described way is based uponthe realization that parsing Arabic utilizes the existence of'meaning-particles' within Syntax to efficiently recognize words, phrases andSentences. Similar meaning-particles are shown to exist in 3CNF formulas,which, when properly handled within the machinery of 3SAT-Solvers, enablestructural conditions to be imposed on formulas, sufficient alone to guaranteethe efficient production of non-exponentially sized Free Binary DecisionDiagrams (FBDDs). We show, why known exponential Lower Bounds on sizes of FBDDsdo not contradict our results and reveal practical evidence, obtained formultiplication circuits, supporting our claims.</description><author>Elnaserledinellah Mahmood Abdelwahab</author><pubDate>Sun, 29 Oct 2023 20:20:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19123v1</guid></item><item><title>Out-of-distribution Object Detection through Bayesian Uncertainty Estimation</title><link>http://arxiv.org/abs/2310.19119v1</link><description>The superior performance of object detectors is often established under thecondition that the test samples are in the same distribution as the trainingdata. However, in many practical applications, out-of-distribution (OOD)instances are inevitable and usually lead to uncertainty in the results. Inthis paper, we propose a novel, intuitive, and scalable probabilistic objectdetection method for OOD detection. Unlike other uncertainty-modeling methodsthat either require huge computational costs to infer the weight distributionsor rely on model training through synthetic outlier data, our method is able todistinguish between in-distribution (ID) data and OOD data via weight parametersampling from proposed Gaussian distributions based on pre-trained networks. Wedemonstrate that our Bayesian object detector can achieve satisfactory OODidentification performance by reducing the FPR95 score by up to 8.19% andincreasing the AUROC score by up to 13.94% when trained on BDD100k and VOCdatasets as the ID datasets and evaluated on COCO2017 dataset as the OODdataset.</description><author>Tianhao Zhang, Shenglin Wang, Nidhal Bouaynaya, Radu Calinescu, Lyudmila Mihaylova</author><pubDate>Sun, 29 Oct 2023 20:10:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19119v1</guid></item><item><title>Dynamic V2X Autonomous Perception from Road-to-Vehicle Vision</title><link>http://arxiv.org/abs/2310.19113v1</link><description>Vehicle-to-everything (V2X) perception is an innovative technology thatenhances vehicle perception accuracy, thereby elevating the security andreliability of autonomous systems. However, existing V2X perception methodsfocus on static scenes from mainly vehicle-based vision, which is constrainedby sensor capabilities and communication loads. To adapt V2X perception modelsto dynamic scenes, we propose to build V2X perception from road-to-vehiclevision and present Adaptive Road-to-Vehicle Perception (AR2VP) method. InAR2VP,we leverage roadside units to offer stable, wide-range sensingcapabilities and serve as communication hubs. AR2VP is devised to tackle bothintra-scene and inter-scene changes. For the former, we construct a dynamicperception representing module, which efficiently integrates vehicleperceptions, enabling vehicles to capture a more comprehensive range of dynamicfactors within the scene.Moreover, we introduce a road-to-vehicle perceptioncompensating module, aimed at preserving the maximized roadside unit perceptioninformation in the presence of intra-scene changes.For inter-scene changes, weimplement an experience replay mechanism leveraging the roadside unit's storagecapacity to retain a subset of historical scene data, maintaining modelrobustness in response to inter-scene shifts. We conduct perception experimenton 3D object detection and segmentation, and the results show that AR2VP excelsin both performance-bandwidth trade-offs and adaptability within dynamicenvironments.</description><author>Jiayao Tan, Fan Lyu, Linyan Li, Fuyuan Hu, Tingliang Feng, Fenglei Xu, Rui Yao</author><pubDate>Sun, 29 Oct 2023 20:01:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19113v1</guid></item><item><title>Efficient IoT Inference via Context-Awareness</title><link>http://arxiv.org/abs/2310.19112v1</link><description>While existing strategies for optimizing deep learning-based classificationmodels on low-power platforms assume the models are trained on all classes ofinterest, this paper posits that adopting context-awareness i.e. focusingsolely on the likely classes in the current context, can substantially enhanceperformance in resource-constrained environments. We propose a new paradigm,CACTUS, for scalable and efficient context-aware classification where amicro-classifier recognizes a small set of classes relevant to the currentcontext and, when context change happens, rapidly switches to another suitablemicro-classifier. CACTUS has several innovations including optimizing thetraining cost of context-aware classifiers, enabling on-the-fly context-awareswitching between classifiers, and selecting the best context-aware classifiersgiven limited resources. We show that CACTUS achieves significant benefits inaccuracy, latency, and compute budget across a range of datasets and IoTplatforms.</description><author>Mohammad Mehdi Rastikerdar, Jin Huang, Shiwei Fang, Hui Guan, Deepak Ganesan</author><pubDate>Sun, 29 Oct 2023 19:57:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19112v1</guid></item><item><title>A Spectral Approach to Item Response Theory</title><link>http://arxiv.org/abs/2210.04317v2</link><description>The Rasch model is one of the most fundamental models in \emph{item responsetheory} and has wide-ranging applications from education testing torecommendation systems. In a universe with $n$ users and $m$ items, the Raschmodel assumes that the binary response $X_{li} \in \{0,1\}$ of a user $l$ withparameter $\theta^*_l$ to an item $i$ with parameter $\beta^*_i$ (e.g., a userlikes a movie, a student correctly solves a problem) is distributed as$\Pr(X_{li}=1) = 1/(1 + \exp{-(\theta^*_l - \beta^*_i)})$. In this paper, wepropose a \emph{new item estimation} algorithm for this celebrated model (i.e.,to estimate $\beta^*$). The core of our algorithm is the computation of thestationary distribution of a Markov chain defined on an item-item graph. Wecomplement our algorithmic contributions with finite-sample error guarantees,the first of their kind in the literature, showing that our algorithm isconsistent and enjoys favorable optimality properties. We discuss practicalmodifications to accelerate and robustify the algorithm that practitioners canadopt. Experiments on synthetic and real-life datasets, ranging from smalleducation testing datasets to large recommendation systems datasets show thatour algorithm is scalable, accurate, and competitive with the most commonlyused methods in the literature.</description><author>Duc Nguyen, Anderson Zhang</author><pubDate>Sun, 29 Oct 2023 19:52:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04317v2</guid></item><item><title>Dynamic Task and Weight Prioritization Curriculum Learning for Multimodal Imagery</title><link>http://arxiv.org/abs/2310.19109v1</link><description>This paper explores post-disaster analytics using multimodal deep learningmodels trained with curriculum learning method. Studying post-disasteranalytics is important as it plays a crucial role in mitigating the impact ofdisasters by providing timely and accurate insights into the extent of damageand the allocation of resources. We propose a curriculum learning strategy toenhance the performance of multimodal deep learning models. Curriculum learningemulates the progressive learning sequence in human education by training deeplearning models on increasingly complex data. Our primary objective is todevelop a curriculum-trained multimodal deep learning model, with a particularfocus on visual question answering (VQA) capable of jointly processing imageand text data, in conjunction with semantic segmentation for disaster analyticsusing theFloodNet\footnote{https://github.com/BinaLab/FloodNet-Challenge-EARTHVISION2021}dataset. To achieve this, U-Net model is used for semantic segmentation andimage encoding. A custom built text classifier is used for visual questionanswering. Existing curriculum learning methods rely on manually defineddifficulty functions. We introduce a novel curriculum learning approach termedDynamic Task and Weight Prioritization (DATWEP), which leverages agradient-based method to automatically decide task difficulty during curriculumlearning training, thereby eliminating the need for explicit difficultycomputation. The integration of DATWEP into our multimodal model showsimprovement on VQA performance. Source code is available athttps://github.com/fualsan/DATWEP.</description><author>Huseyin Fuat Alsan, Taner Arsan</author><pubDate>Sun, 29 Oct 2023 19:46:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19109v1</guid></item><item><title>PACuna: Automated Fine-Tuning of Language Models for Particle Accelerators</title><link>http://arxiv.org/abs/2310.19106v1</link><description>Navigating the landscape of particle accelerators has become increasinglychallenging with recent surges in contributions. These intricate deviceschallenge comprehension, even within individual facilities. To address this, weintroduce PACuna, a fine-tuned language model refined through publiclyavailable accelerator resources like conferences, pre-prints, and books. Weautomated data collection and question generation to minimize expertinvolvement and make the data publicly available. PACuna demonstratesproficiency in addressing intricate accelerator questions, validated byexperts. Our approach shows adapting language models to scientific domains byfine-tuning technical texts and auto-generated corpora capturing the latestdevelopments can further produce pre-trained models to answer some intricatequestions that commercially available assistants cannot and can serve asintelligent assistants for individual facilities.</description><author>Antonin Sulc, Raimund Kammering, Annika Eichler, Tim Wilksen</author><pubDate>Sun, 29 Oct 2023 19:43:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19106v1</guid></item><item><title>Proving Linear Mode Connectivity of Neural Networks via Optimal Transport</title><link>http://arxiv.org/abs/2310.19103v1</link><description>The energy landscape of high-dimensional non-convex optimization problems iscrucial to understanding the effectiveness of modern deep neural networkarchitectures. Recent works have experimentally shown that two differentsolutions found after two runs of a stochastic training are often connected byvery simple continuous paths (e.g., linear) modulo a permutation of theweights. In this paper, we provide a framework theoretically explaining thisempirical observation. Based on convergence rates in Wasserstein distance ofempirical measures, we show that, with high probability, two wide enoughtwo-layer neural networks trained with stochastic gradient descent are linearlyconnected. Additionally, we express upper and lower bounds on the width of eachlayer of two deep neural networks with independent neuron weights to belinearly connected. Finally, we empirically demonstrate the validity of ourapproach by showing how the dimension of the support of the weight distributionof neurons, which dictates Wasserstein convergence rates is correlated withlinear mode connectivity.</description><author>Damien Ferbach, Baptiste Goujaud, Gauthier Gidel, Aymeric Dieuleveut</author><pubDate>Sun, 29 Oct 2023 19:35:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19103v1</guid></item><item><title>Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity</title><link>http://arxiv.org/abs/2306.02652v2</link><description>Modern predictive models are often deployed to environments in whichcomputational budgets are dynamic. Anytime algorithms are well-suited to suchenvironments as, at any point during computation, they can output a predictionwhose quality is a function of computation time. Early-exit neural networkshave garnered attention in the context of anytime computation due to theircapability to provide intermediate predictions at various stages throughout thenetwork. However, we demonstrate that current early-exit networks are notdirectly applicable to anytime settings, as the quality of predictions forindividual data points is not guaranteed to improve with longer computation. Toaddress this shortcoming, we propose an elegant post-hoc modification, based onthe Product-of-Experts, that encourages an early-exit network to becomegradually confident. This gives our deep models the property of conditionalmonotonicity in the prediction quality -- an essential stepping stone towardstruly anytime predictive modeling using early-exit architectures. Our empiricalresults on standard image-classification tasks demonstrate that such behaviorscan be achieved while preserving competitive accuracy on average.</description><author>Metod Jazbec, James Urquhart Allingham, Dan Zhang, Eric Nalisnick</author><pubDate>Sun, 29 Oct 2023 19:35:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02652v2</guid></item><item><title>Atom: Low-bit Quantization for Efficient and Accurate LLM Serving</title><link>http://arxiv.org/abs/2310.19102v1</link><description>The growing demand for Large Language Models (LLMs) in applications such ascontent generation, intelligent chatbots, and sentiment analysis posesconsiderable challenges for LLM service providers. To efficiently use GPUresources and boost throughput, batching multiple requests has emerged as apopular paradigm; to further speed up batching, LLM quantization techniquesreduce memory consumption and increase computing capacity. However, prevalentquantization schemes (e.g., 8-bit weight-activation quantization) cannot fullyleverage the capabilities of modern GPUs, such as 4-bit integer operators,resulting in sub-optimal performance. To maximize LLMs' serving throughput, we introduce Atom, a low-bitquantization method that achieves high throughput improvements with negligibleaccuracy loss. Atom significantly boosts serving throughput by using low-bitoperators and considerably reduces memory consumption via low-bit quantization.It attains high accuracy by applying a novel mixed-precision and fine-grainedquantization process. We evaluate Atom on 4-bit weight-activation quantizationsetups in the serving context. Atom improves end-to-end throughput by up to$7.73\times$ compared to the FP16 and by $2.53\times$ compared to INT8quantization, while maintaining the same latency target.</description><author>Yilong Zhao, Chien-Yu Lin, Kan Zhu, Zihao Ye, Lequn Chen, Size Zheng, Luis Ceze, Arvind Krishnamurthy, Tianqi Chen, Baris Kasikci</author><pubDate>Sun, 29 Oct 2023 19:33:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19102v1</guid></item><item><title>MEGANet: Multi-Scale Edge-Guided Attention Network for Weak Boundary Polyp Segmentation</title><link>http://arxiv.org/abs/2309.03329v2</link><description>Efficient polyp segmentation in healthcare plays a critical role in enablingearly diagnosis of colorectal cancer. However, the segmentation of polypspresents numerous challenges, including the intricate distribution ofbackgrounds, variations in polyp sizes and shapes, and indistinct boundaries.Defining the boundary between the foreground (i.e. polyp itself) and thebackground (surrounding tissue) is difficult. To mitigate these challenges, wepropose Multi-Scale Edge-Guided Attention Network (MEGANet) tailoredspecifically for polyp segmentation within colonoscopy images. This networkdraws inspiration from the fusion of a classical edge detection technique withan attention mechanism. By combining these techniques, MEGANet effectivelypreserves high-frequency information, notably edges and boundaries, which tendto erode as neural networks deepen. MEGANet is designed as an end-to-endframework, encompassing three key modules: an encoder, which is responsible forcapturing and abstracting the features from the input image, a decoder, whichfocuses on salient features, and the Edge-Guided Attention module (EGA) thatemploys the Laplacian Operator to accentuate polyp boundaries. Extensiveexperiments, both qualitative and quantitative, on five benchmark datasets,demonstrate that our EGANet outperforms other existing SOTA methods under sixevaluation metrics. Our code is available at\url{https://github.com/UARK-AICV/MEGANet}.</description><author>Nhat-Tan Bui, Dinh-Hieu Hoang, Quang-Thuc Nguyen, Minh-Triet Tran, Ngan Le</author><pubDate>Sun, 29 Oct 2023 19:28:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03329v2</guid></item><item><title>Web3 Meets AI Marketplace: Exploring Opportunities, Analyzing Challenges, and Suggesting Solutions</title><link>http://arxiv.org/abs/2310.19099v1</link><description>Web3 and AI have been among the most discussed fields over the recent years,with substantial hype surrounding each field's potential to transform the worldas we know it. However, as the hype settles, it's evident that neither AI norWeb3 can address all challenges independently. Consequently, the intersectionof AI and Web3 is gaining increased attention, emerging as a new field with thepotential to address the limitations of each. In this article, we will focus onthe integration of web3 and the AI marketplace, where AI services and productscan be provided in a decentralized manner (DeAI). A comprehensive review isprovided by summarizing the opportunities and challenges on this topic.Additionally, we offer analyses and solutions to address these challenges.We've developed a framework that lets users pay with any kind of cryptocurrencyto get AI services. Additionally, they can also enjoy AI services for free onour platform by simply locking up their assets temporarily in the protocol.This unique approach is a first in the industry. Before this, offering free AIservices in the web3 community wasn't possible. Our solution opens up excitingopportunities for the AI marketplace in the web3 space to grow and be widelyadopted.</description><author>Peihao Li</author><pubDate>Sun, 29 Oct 2023 19:21:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19099v1</guid></item><item><title>Energy cost and machine learning accuracy impact of k-anonymisation and synthetic data techniques</title><link>http://arxiv.org/abs/2305.07116v2</link><description>To address increasing societal concerns regarding privacy and climate, the EUadopted the General Data Protection Regulation (GDPR) and committed to theGreen Deal. Considerable research studied the energy efficiency of software andthe accuracy of machine learning models trained on anonymised data sets. Recentwork began exploring the impact of privacy-enhancing techniques (PET) on boththe energy consumption and accuracy of the machine learning models, focusing onk-anonymity. As synthetic data is becoming an increasingly popular PET, thispaper analyses the energy consumption and accuracy of two phases: a) applyingprivacy-enhancing techniques to the concerned data set, b) training the modelson the concerned privacy-enhanced data set. We use two privacy-enhancingtechniques: k-anonymisation (using generalisation and suppression) andsynthetic data, and three machine-learning models. Each model is trained oneach privacy-enhanced data set. Our results show that models trained onk-anonymised data consume less energy than models trained on the original data,with a similar performance regarding accuracy. Models trained on synthetic datahave a similar energy consumption and a similar to lower accuracy compared tomodels trained on the original data.</description><author>Pepijn de Reus, Ana Oprescu, Koen van Elsen</author><pubDate>Sun, 29 Oct 2023 19:19:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07116v2</guid></item><item><title>Beyond Geometry: Comparing the Temporal Structure of Computation in Neural Circuits with Dynamical Similarity Analysis</title><link>http://arxiv.org/abs/2306.10168v3</link><description>How can we tell whether two neural networks utilize the same internalprocesses for a particular computation? This question is pertinent for multiplesubfields of neuroscience and machine learning, including neuroAI, mechanisticinterpretability, and brain-machine interfaces. Standard approaches forcomparing neural networks focus on the spatial geometry of latent states. Yetin recurrent networks, computations are implemented at the level of dynamics,and two networks performing the same computation with equivalent dynamics neednot exhibit the same geometry. To bridge this gap, we introduce a novelsimilarity metric that compares two systems at the level of their dynamics,called Dynamical Similarity Analysis (DSA). Our method incorporates twocomponents: Using recent advances in data-driven dynamical systems theory, welearn a high-dimensional linear system that accurately captures core featuresof the original nonlinear dynamics. Next, we compare different systems passedthrough this embedding using a novel extension of Procrustes Analysis thataccounts for how vector fields change under orthogonal transformation. In fourcase studies, we demonstrate that our method disentangles conjugate andnon-conjugate recurrent neural networks (RNNs), while geometric methods fallshort. We additionally show that our method can distinguish learning rules inan unsupervised manner. Our method opens the door to comparative analyses ofthe essential temporal structure of computation in neural circuits.</description><author>Mitchell Ostrow, Adam Eisen, Leo Kozachkov, Ila Fiete</author><pubDate>Sun, 29 Oct 2023 19:13:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10168v3</guid></item><item><title>Fairness and Bias in Robot Learning</title><link>http://arxiv.org/abs/2207.03444v2</link><description>Machine learning has significantly enhanced the abilities of robots, enablingthem to perform a wide range of tasks in human environments and adapt to ouruncertain real world. Recent works in various machine learning domains havehighlighted the importance of accounting for fairness to ensure that thesealgorithms do not reproduce human biases and consequently lead todiscriminatory outcomes. With robot learning systems increasingly performingmore and more tasks in our everyday lives, it is crucial to understand theinfluence of such biases to prevent unintended behavior toward certain groupsof people. In this work, we present the first survey on fairness in robotlearning from an interdisciplinary perspective spanning technical, ethical, andlegal challenges. We propose a taxonomy for sources of bias and the resultingtypes of discrimination due to them. Using examples from different robotlearning domains, we examine scenarios of unfair outcomes and strategies tomitigate them. We present early advances in the field by covering differentfairness definitions, ethical and legal considerations, and methods for fairrobot learning. With this work, we aim to pave the road for groundbreakingdevelopments in fair robot learning.</description><author>Laura Londoño, Juana Valeria Hurtado, Nora Hertz, Philipp Kellmeyer, Silja Voeneky, Abhinav Valada</author><pubDate>Sun, 29 Oct 2023 19:12:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.03444v2</guid></item><item><title>Bridging the Gap: Towards an Expanded Toolkit for ML-Supported Decision-Making in the Public Sector</title><link>http://arxiv.org/abs/2310.19091v1</link><description>Machine Learning (ML) systems are becoming instrumental in the public sector,with applications spanning areas like criminal justice, social welfare,financial fraud detection, and public health. While these systems offer greatpotential benefits to institutional decision-making processes, such as improvedefficiency and reliability, they still face the challenge of aligning intricateand nuanced policy objectives with the precise formalization requirementsnecessitated by ML models. In this paper, we aim to bridge the gap between MLand public sector decision-making by presenting a comprehensive overview of keytechnical challenges where disjunctions between policy goals and ML modelscommonly arise. We concentrate on pivotal points of the ML pipeline thatconnect the model to its operational environment, delving into the significanceof representative training data and highlighting the importance of a modelsetup that facilitates effective decision-making. Additionally, we link thesechallenges with emerging methodological advancements, encompassing causal ML,domain adaptation, uncertainty quantification, and multi-objectiveoptimization, illustrating the path forward for harmonizing ML and publicsector objectives.</description><author>Unai Fischer Abaigar, Christoph Kern, Noam Barda, Frauke Kreuter</author><pubDate>Sun, 29 Oct 2023 18:44:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19091v1</guid></item><item><title>On the impact of activation and normalization in obtaining isometric embeddings at initialization</title><link>http://arxiv.org/abs/2305.18399v2</link><description>In this paper, we explore the structure of the penultimate Gram matrix indeep neural networks, which contains the pairwise inner products of outputscorresponding to a batch of inputs. In several architectures it has beenobserved that this Gram matrix becomes degenerate with depth at initialization,which dramatically slows training. Normalization layers, such as batch or layernormalization, play a pivotal role in preventing the rank collapse issue.Despite promising advances, the existing theoretical results do not extend tolayer normalization, which is widely used in transformers, and can notquantitatively characterize the role of non-linear activations. To bridge thisgap, we prove that layer normalization, in conjunction with activation layers,biases the Gram matrix of a multilayer perceptron towards the identity matrixat an exponential rate with depth at initialization. We quantify this rateusing the Hermite expansion of the activation function.</description><author>Amir Joudaki, Hadi Daneshmand, Francis Bach</author><pubDate>Sun, 29 Oct 2023 18:42:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18399v2</guid></item><item><title>Auditing Fairness by Betting</title><link>http://arxiv.org/abs/2305.17570v2</link><description>We provide practical, efficient, and nonparametric methods for auditing thefairness of deployed classification and regression models. Whereas previouswork relies on a fixed-sample size, our methods are sequential and allow forthe continuous monitoring of incoming data, making them highly amenable totracking the fairness of real-world systems. We also allow the data to becollected by a probabilistic policy as opposed to sampled uniformly from thepopulation. This enables auditing to be conducted on data gathered for anotherpurpose. Moreover, this policy may change over time and different policies maybe used on different subpopulations. Finally, our methods can handledistribution shift resulting from either changes to the model or changes in theunderlying population. Our approach is based on recent progress inanytime-valid inference and game-theoretic statistics-the "testing by betting"framework in particular. These connections ensure that our methods areinterpretable, fast, and easy to implement. We demonstrate the efficacy of ourapproach on three benchmark fairness datasets.</description><author>Ben Chugg, Santiago Cortes-Gomez, Bryan Wilder, Aaditya Ramdas</author><pubDate>Sun, 29 Oct 2023 18:40:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17570v2</guid></item><item><title>Locally Differentially Private Gradient Tracking for Distributed Online Learning over Directed Graphs</title><link>http://arxiv.org/abs/2310.16105v2</link><description>Distributed online learning has been proven extremely effective in solvinglarge-scale machine learning problems over streaming data. However, informationsharing between learners in distributed learning also raises concerns about thepotential leakage of individual learners' sensitive data. To mitigate thisrisk, differential privacy, which is widely regarded as the "gold standard" forprivacy protection, has been widely employed in many existing results ondistributed online learning. However, these results often face a fundamentaltradeoff between learning accuracy and privacy. In this paper, we propose alocally differentially private gradient tracking based distributed onlinelearning algorithm that successfully circumvents this tradeoff. We prove thatthe proposed algorithm converges in mean square to the exact optimal solutionwhile ensuring rigorous local differential privacy, with the cumulative privacybudget guaranteed to be finite even when the number of iterations tends toinfinity. The algorithm is applicable even when the communication graph amonglearners is directed. To the best of our knowledge, this is the first resultthat simultaneously ensures learning accuracy and rigorous local differentialprivacy in distributed online learning over directed graphs. We evaluate ouralgorithm's performance by using multiple benchmark machine-learningapplications, including logistic regression of the "Mushrooms" dataset andCNN-based image classification of the "MNIST" and "CIFAR-10" datasets,respectively. The experimental results confirm that the proposed algorithmoutperforms existing counterparts in both training and testing accuracies.</description><author>Ziqin Chen, Yongqiang Wang</author><pubDate>Sun, 29 Oct 2023 18:34:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.16105v2</guid></item></channel></rss>