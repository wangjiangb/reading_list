<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 11 Sep 2024 01:00:18 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>What Did My Car Say? Impact of Autonomous Vehicle Explanation Errors and Driving Context On Comfort, Reliance, Satisfaction, and Driving Confidence</title><link>http://arxiv.org/abs/2409.05731v2</link><description>Explanations for autonomous vehicle (AV) decisions may build trust, however,explanations can contain errors. In a simulated driving study (n = 232), wetested how AV explanation errors, driving context characteristics (perceivedharm and driving difficulty), and personal traits (prior trust and expertise)affected a passenger's comfort in relying on an AV, preference for control,confidence in the AV's ability, and explanation satisfaction. Errors negativelyaffected all outcomes. Surprisingly, despite identical driving, explanationerrors reduced ratings of the AV's driving ability. Severity and potential harmamplified the negative impact of errors. Contextual harm and driving difficultydirectly impacted outcome ratings and influenced the relationship betweenerrors and outcomes. Prior trust and expertise were positively associated withoutcome ratings. Results emphasize the need for accurate, contextuallyadaptive, and personalized AV explanations to foster trust, reliance,satisfaction, and confidence. We conclude with design, research, and deploymentrecommendations for trustworthy AV explanation systems.</description><author>Robert Kaufman, Aaron Broukhim, David Kirsh, Nadir Weibel</author><pubDate>Tue, 10 Sep 2024 16:25:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05731v2</guid></item><item><title>Question-Answering Dense Video Events</title><link>http://arxiv.org/abs/2409.04388v3</link><description>Multimodal Large Language Models (MLLMs) have shown excellent performance inquestion-answering of single-event videos. In this paper, we presentquestion-answering dense video events, a novel task that requires answering andgrounding the dense-event questions in long videos, thus challenging MLLMs tofaithfully comprehend and reason about multiple events occurring over extendedtime periods. To facilitate the study, we construct DeVE-QA - a datasetfeaturing 78K questions about 26K events on 10.6K long videos. We thenbenchmark and show that existing MLLMs excelling at single-event QA struggle toperform well in DeVE-QA. For improvement, we propose DeVi, a noveltraining-free MLLM approach that highlights a hierarchical captioning module, atemporal event memory module, and a self-consistency checking module torespectively detect, contextualize and memorize, and ground dense-events inlong videos for question answering. Extensive experiments show that DeVi issuperior at answering dense-event questions and grounding relevant videomoments. Compared with existing MLLMs, it achieves a remarkable increase of 4.1percent and 3.7 percent for G(round)QA accuracy on DeVE-QA and NExT-GQArespectively.</description><author>Hangyu Qin, Junbin Xiao, Angela Yao</author><pubDate>Tue, 10 Sep 2024 09:46:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.04388v3</guid></item><item><title>Retrofitting Temporal Graph Neural Networks with Transformer</title><link>http://arxiv.org/abs/2409.05477v2</link><description>Temporal graph neural networks (TGNNs) outperform regular GNNs byincorporating time information into graph-based operations. However, TGNNsadopt specialized models (e.g., TGN, TGAT, and APAN ) and require tailoredtraining frameworks (e.g., TGL and ETC). In this paper, we propose TF-TGN,which uses Transformer decoder as the backbone model for TGNN to enjoyTransformer's codebase for efficient training. In particular, Transformerachieves tremendous success for language modeling, and thus the communitydeveloped high-performance kernels (e.g., flash-attention and memory-efficientattention) and efficient distributed training schemes (e.g., PyTorch FSDP,DeepSpeed, and Megatron-LM). We observe that TGNN resembles language modeling,i.e., the message aggregation operation between chronologically occurring nodesand their temporal neighbors in TGNNs can be structured as sequence modeling.Beside this similarity, we also incorporate a series of algorithm designsincluding suffix infilling, temporal graph attention with self-loop, and causalmasking self-attention to make TF-TGN work. During training, existing systemsare slow in transforming the graph topology and conducting graph sampling. Assuch, we propose methods to parallelize the CSR format conversion and graphsampling. We also adapt Transformer codebase to train TF-TGN efficiently withmultiple GPUs. We experiment with 9 graphs and compare with 2 state-of-the-artTGNN training frameworks. The results show that TF-TGN can accelerate trainingby over 2.20 while providing comparable or even superior accuracy to existingSOTA TGNNs. TF-TGN is available at https://github.com/qianghuangwhu/TF-TGN.</description><author>Qiang Huang, Xiao Yan, Xin Wang, Susie Xi Rao, Zhichao Han, Fangcheng Fu, Wentao Zhang, Jiawei Jiang</author><pubDate>Tue, 10 Sep 2024 07:54:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05477v2</guid></item><item><title>An Atmospheric Correction Integrated LULC Segmentation Model for High-Resolution Satellite Imagery</title><link>http://arxiv.org/abs/2409.05494v2</link><description>The integration of fine-scale multispectral imagery with deep learning modelshas revolutionized land use and land cover (LULC) classification. However, theatmospheric effects present in Top-of-Atmosphere sensor measured Digital Numbervalues must be corrected to retrieve accurate Bottom-of-Atmosphere surfacereflectance for reliable analysis. This study employs look-up-table-basedradiative transfer simulations to estimate the atmospheric path reflectance andtransmittance for atmospherically correcting high-resolution CARTOSAT-3Multispectral (MX) imagery for several Indian cities. The corrected surfacereflectance data were subsequently used in supervised and semi-supervisedsegmentation models, demonstrating stability in multi-class (buildings, roads,trees and water bodies) LULC segmentation accuracy, particularly in scenarioswith sparsely labelled data.</description><author>Soham Mukherjee, Yash Dixit, Naman Srivastava, Joel D Joy, Rohan Olikara, Koesha Sinha, Swarup E, Rakshit Ramesh</author><pubDate>Tue, 10 Sep 2024 06:15:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05494v2</guid></item><item><title>DriveScape: Towards High-Resolution Controllable Multi-View Driving Video Generation</title><link>http://arxiv.org/abs/2409.05463v2</link><description>Recent advancements in generative models have provided promising solutionsfor synthesizing realistic driving videos, which are crucial for trainingautonomous driving perception models. However, existing approaches oftenstruggle with multi-view video generation due to the challenges of integrating3D information while maintaining spatial-temporal consistency and effectivelylearning from a unified model. In this paper, we propose an end-to-endframework named DriveScape for multi-view, 3D condition-guided videogeneration. DriveScape not only streamlines the process by integrating cameradata to ensure comprehensive spatial-temporal coverage, but also introduces aBi-Directional Modulated Transformer module to effectively align 3D roadstructural information. As a result, our approach enables precise control overvideo generation, significantly enhancing realism and providing a robustsolution for generating multi-view driving videos. Our framework achievesstate-of-the-art results on the nuScenes dataset, demonstrating impressivegenerative quality metrics with an FID score of 8.34 and an FVD score of 76.39,as well as superior performance across various perception tasks. This paves theway for more accurate environmental simulations in autonomous driving. Codewill be available at\href{https://metadrivescape.github.io/papers_project/drivescapev1/index.html}{ourproject homepage}.</description><author>Wei Wu, Xi Guo, Weixuan Tang, Tingxuan Huang, Chiyu Wang, Dongyue Chen, Chenjing Ding</author><pubDate>Tue, 10 Sep 2024 03:39:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05463v2</guid></item><item><title>CRADLE-VAE: Enhancing Single-Cell Gene Perturbation Modeling with Counterfactual Reasoning-based Artifact Disentanglement</title><link>http://arxiv.org/abs/2409.05484v2</link><description>Predicting cellular responses to various perturbations is a critical focus indrug discovery and personalized therapeutics, with deep learning models playinga significant role in this endeavor. Single-cell datasets contain technicalartifacts that may hinder the predictability of such models, which posesquality control issues highly regarded in this area. To address this, wepropose CRADLE-VAE, a causal generative framework tailored for single-cell geneperturbation modeling, enhanced with counterfactual reasoning-based artifactdisentanglement. Throughout training, CRADLE-VAE models the underlying latentdistribution of technical artifacts and perturbation effects present insingle-cell datasets. It employs counterfactual reasoning to effectivelydisentangle such artifacts by modulating the latent basal spaces and learnsrobust features for generating cellular response data with improved quality.Experimental results demonstrate that this approach improves not only treatmenteffect estimation performance but also generative quality as well. TheCRADLE-VAE codebase is publicly available athttps://github.com/dmis-lab/CRADLE-VAE.</description><author>Seungheun Baek, Soyon Park, Yan Ting Chok, Junhyun Lee, Jueon Park, Mogan Gim, Jaewoo Kang</author><pubDate>Tue, 10 Sep 2024 02:47:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05484v2</guid></item><item><title>Evaluating Multiview Object Consistency in Humans and Image Models</title><link>http://arxiv.org/abs/2409.05862v2</link><description>We introduce a benchmark to directly evaluate the alignment between humanobservers and vision models on a 3D shape inference task. We leverage anexperimental design from the cognitive sciences which requires zero-shot visualinferences about object shape: given a set of images, participants identifywhich contain the same/different objects, despite considerable viewpointvariation. We draw from a diverse range of images that include common objects(e.g., chairs) as well as abstract shapes (i.e., procedurally generated`nonsense' objects). After constructing over 2000 unique image sets, weadminister these tasks to human participants, collecting 35K trials ofbehavioral data from over 500 participants. This includes explicit choicebehaviors as well as intermediate measures, such as reaction time and gazedata. We then evaluate the performance of common vision models (e.g., DINOv2,MAE, CLIP). We find that humans outperform all models by a wide margin. Using amulti-scale evaluation approach, we identify underlying similarities anddifferences between models and humans: while human-model performance iscorrelated, humans allocate more time/processing on challenging trials. Allimages, data, and code can be accessed via our project page.</description><author>Tyler Bonnen, Stephanie Fu, Yutong Bai, Thomas O'Connell, Yoni Friedman, Nancy Kanwisher, Joshua B. Tenenbaum, Alexei A. Efros</author><pubDate>Tue, 10 Sep 2024 02:28:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05862v2</guid></item><item><title>NeurLZ: On Enhancing Lossy Compression Performance based on Error-Controlled Neural Learning for Scientific Data</title><link>http://arxiv.org/abs/2409.05785v2</link><description>Large-scale scientific simulations generate massive datasets that posesignificant challenges for storage and I/O. While traditional lossy compressiontechniques can improve performance, balancing compression ratio, data quality,and throughput remains difficult. To address this, we propose NeurLZ, a novelcross-field learning-based and error-controlled compression framework forscientific data. By integrating skipping DNN models, cross-field learning, anderror control, our framework aims to substantially enhance lossy compressionperformance. Our contributions are three-fold: (1) We design a lightweightskipping model to provide high-fidelity detail retention, further improvingprediction accuracy. (2) We adopt a cross-field learning approach tosignificantly improve data prediction accuracy, resulting in a substantiallyimproved compression ratio. (3) We develop an error control approach to providestrict error bounds according to user requirements. We evaluated NeurLZ onseveral real-world HPC application datasets, including Nyx (cosmologicalsimulation), Miranda (large turbulence simulation), and Hurricane (weathersimulation). Experiments demonstrate that our framework achieves up to a 90%relative reduction in bit rate under the same data distortion, compared to thebest existing approach.</description><author>Wenqi Jia, Youyuan Liu, Zhewen Hu, Jinzhen Wang, Boyuan Zhang, Wei Niu, Junzhou Huang, Stavros Kalafatis, Sian Jin, Miao Yin</author><pubDate>Tue, 10 Sep 2024 02:02:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05785v2</guid></item><item><title>MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery</title><link>http://arxiv.org/abs/2409.05591v2</link><description>Retrieval-Augmented Generation (RAG) leverages retrieval tools to accessexternal databases, thereby enhancing the generation quality of large languagemodels (LLMs) through optimized context. However, the existing retrievalmethods are constrained inherently, as they can only perform relevance matchingbetween explicitly stated queries and well-formed knowledge, but unable tohandle tasks involving ambiguous information needs or unstructured knowledge.Consequently, existing RAG systems are primarily effective for straightforwardquestion-answering tasks. In this work, we propose MemoRAG, a novelretrieval-augmented generation paradigm empowered by long-term memory. MemoRAGadopts a dual-system architecture. On the one hand, it employs a light butlong-range LLM to form the global memory of database. Once a task is presented,it generates draft answers, cluing the retrieval tools to locate usefulinformation within the database. On the other hand, it leverages an expensivebut expressive LLM, which generates the ultimate answer based on the retrievedinformation. Building on this general framework, we further optimize MemoRAG'sperformance by enhancing its cluing mechanism and memorization capacity. In ourexperiment, MemoRAG achieves superior performance across a variety ofevaluation tasks, including both complex ones where conventional RAG fails andstraightforward ones where RAG is commonly applied.</description><author>Hongjin Qian, Peitian Zhang, Zheng Liu, Kelong Mao, Zhicheng Dou</author><pubDate>Tue, 10 Sep 2024 02:01:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05591v2</guid></item><item><title>Flash Cache: Reducing Bias in Radiance Cache Based Inverse Rendering</title><link>http://arxiv.org/abs/2409.05867v1</link><description>State-of-the-art techniques for 3D reconstruction are largely based onvolumetric scene representations, which require sampling multiple points tocompute the color arriving along a ray. Using these representations for moregeneral inverse rendering -- reconstructing geometry, materials, and lightingfrom observed images -- is challenging because recursively path-tracing suchvolumetric representations is expensive. Recent works alleviate this issuethrough the use of radiance caches: data structures that store thesteady-state, infinite-bounce radiance arriving at any point from anydirection. However, these solutions rely on approximations that introduce biasinto the renderings and, more importantly, into the gradients used foroptimization. We present a method that avoids these approximations whileremaining computationally efficient. In particular, we leverage two techniquesto reduce variance for unbiased estimators of the rendering equation: (1) anocclusion-aware importance sampler for incoming illumination and (2) a fastcache architecture that can be used as a control variate for the radiance froma high-quality, but more expensive, volumetric cache. We show that by removingthese biases our approach improves the generality of radiance cache basedinverse rendering, as well as increasing quality in the presence of challenginglight transport effects such as specular reflections.</description><author>Benjamin Attal, Dor Verbin, Ben Mildenhall, Peter Hedman, Jonathan T. Barron, Matthew O'Toole, Pratul P. Srinivasan</author><pubDate>Mon, 09 Sep 2024 17:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05867v1</guid></item><item><title>A Framework for Evaluating PM2.5 Forecasts from the Perspective of Individual Decision Making</title><link>http://arxiv.org/abs/2409.05866v1</link><description>Wildfire frequency is increasing as the climate changes, and the resultingair pollution poses health risks. Just as people routinely use weatherforecasts to plan their activities around precipitation, reliable air qualityforecasts could help individuals reduce their exposure to air pollution. In thepresent work, we evaluate several existing forecasts of fine particular matter(PM2.5) within the continental United States in the context of individualdecision-making. Our comparison suggests there is meaningful room forimprovement in air pollution forecasting, which might be realized byincorporating more data sources and using machine learning tools. To facilitatefuture machine learning development and benchmarking, we set up a framework toevaluate and compare air pollution forecasts for individual decision making. Weintroduce a new loss to capture decisions about when to use mitigationmeasures. We highlight the importance of visualizations when comparingforecasts. Finally, we provide code to download and compare archived forecastpredictions.</description><author>Renato Berlinghieri, David R. Burt, Paolo Giani, Arlene M. Fiore, Tamara Broderick</author><pubDate>Mon, 09 Sep 2024 17:59:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05866v1</guid></item><item><title>Robot Utility Models: General Policies for Zero-Shot Deployment in New Environments</title><link>http://arxiv.org/abs/2409.05865v1</link><description>Robot models, particularly those trained with large amounts of data, haverecently shown a plethora of real-world manipulation and navigationcapabilities. Several independent efforts have shown that given sufficienttraining data in an environment, robot policies can generalize to demonstratedvariations in that environment. However, needing to finetune robot models toevery new environment stands in stark contrast to models in language or visionthat can be deployed zero-shot for open-world problems. In this work, wepresent Robot Utility Models (RUMs), a framework for training and deployingzero-shot robot policies that can directly generalize to new environmentswithout any finetuning. To create RUMs efficiently, we develop new tools toquickly collect data for mobile manipulation tasks, integrate such data into apolicy with multi-modal imitation learning, and deploy policies on-device onHello Robot Stretch, a cheap commodity robot, with an external mLLM verifierfor retrying. We train five such utility models for opening cabinet doors,opening drawers, picking up napkins, picking up paper bags, and reorientingfallen objects. Our system, on average, achieves 90% success rate in unseen,novel environments interacting with unseen objects. Moreover, the utilitymodels can also succeed in different robot and camera set-ups with no furtherdata, training, or fine-tuning. Primary among our lessons are the importance oftraining data over training algorithm and policy class, guidance about datascaling, necessity for diverse yet high-quality demonstrations, and a recipefor robot introspection and retrying to improve performance on individualenvironments. Our code, data, models, hardware designs, as well as ourexperiment and deployment videos are open sourced and can be found on ourproject website: https://robotutilitymodels.com</description><author>Haritheja Etukuru, Norihito Naka, Zijin Hu, Seungjae Lee, Julian Mehu, Aaron Edsinger, Chris Paxton, Soumith Chintala, Lerrel Pinto, Nur Muhammad Mahi Shafiullah</author><pubDate>Mon, 09 Sep 2024 17:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05865v1</guid></item><item><title>Neural MP: A Generalist Neural Motion Planner</title><link>http://arxiv.org/abs/2409.05864v1</link><description>The current paradigm for motion planning generates solutions from scratch forevery new problem, which consumes significant amounts of time and computationalresources. For complex, cluttered scenes, motion planning approaches can oftentake minutes to produce a solution, while humans are able to accurately andsafely reach any goal in seconds by leveraging their prior experience. We seekto do the same by applying data-driven learning at scale to the problem ofmotion planning. Our approach builds a large number of complex scenes insimulation, collects expert data from a motion planner, then distills it into areactive generalist policy. We then combine this with lightweight optimizationto obtain a safe path for real world deployment. We perform a thoroughevaluation of our method on 64 motion planning tasks across four diverseenvironments with randomized poses, scenes and obstacles, in the real world,demonstrating an improvement of 23%, 17% and 79% motion planning success rateover state of the art sampling, optimization and learning based planningmethods. Video results available at mihdalal.github.io/neuralmotionplanner</description><author>Murtaza Dalal, Jiahui Yang, Russell Mendonca, Youssef Khaky, Ruslan Salakhutdinov, Deepak Pathak</author><pubDate>Mon, 09 Sep 2024 17:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05864v1</guid></item><item><title>Promptable Closed-loop Traffic Simulation</title><link>http://arxiv.org/abs/2409.05863v1</link><description>Simulation stands as a cornerstone for safe and efficient autonomous drivingdevelopment. At its core a simulation system ought to produce realistic,reactive, and controllable traffic patterns. In this paper, we propose ProSim,a multimodal promptable closed-loop traffic simulation framework. ProSim allowsthe user to give a complex set of numerical, categorical or textual prompts toinstruct each agent's behavior and intention. ProSim then rolls out a trafficscenario in a closed-loop manner, modeling each agent's interaction with othertraffic participants. Our experiments show that ProSim achieves high promptcontrollability given different user prompts, while reaching competitiveperformance on the Waymo Sim Agents Challenge when no prompt is given. Tosupport research on promptable traffic simulation, we createProSim-Instruct-520k, a multimodal prompt-scenario paired driving dataset withover 10M text prompts for over 520k real-world driving scenarios. We willrelease code of ProSim as well as data and labeling tools ofProSim-Instruct-520k at https://ariostgx.github.io/ProSim.</description><author>Shuhan Tan, Boris Ivanovic, Yuxiao Chen, Boyi Li, Xinshuo Weng, Yulong Cao, Philipp Krähenbühl, Marco Pavone</author><pubDate>Mon, 09 Sep 2024 17:59:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05863v1</guid></item><item><title>Evaluating Multiview Object Consistency in Humans and Image Models</title><link>http://arxiv.org/abs/2409.05862v1</link><description>We introduce a benchmark to directly evaluate the alignment between humanobservers and vision models on a 3D shape inference task. We leverage anexperimental design from the cognitive sciences which requires zero-shot visualinferences about object shape: given a set of images, participants identifywhich contain the same/different objects, despite considerable viewpointvariation. We draw from a diverse range of images that include common objects(e.g., chairs) as well as abstract shapes (i.e., procedurally generated`nonsense' objects). After constructing over 2000 unique image sets, weadminister these tasks to human participants, collecting 35K trials ofbehavioral data from over 500 participants. This includes explicit choicebehaviors as well as intermediate measures, such as reaction time and gazedata. We then evaluate the performance of common vision models (e.g., DINOv2,MAE, CLIP). We find that humans outperform all models by a wide margin. Using amulti-scale evaluation approach, we identify underlying similarities anddifferences between models and humans: while human-model performance iscorrelated, humans allocate more time/processing on challenging trials. Allimages, data, and code can be accessed via our project page.</description><author>Tyler Bonnen, Stephanie Fu, Yutong Bai, Thomas O'Connell, Yoni Friedman, Nancy Kanwisher, Joshua B. Tenenbaum, Alexei A. Efros</author><pubDate>Mon, 09 Sep 2024 17:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05862v1</guid></item><item><title>Pre-processing and Compression: Understanding Hidden Representation Refinement Across Imaging Domains via Intrinsic Dimension</title><link>http://arxiv.org/abs/2408.08381v3</link><description>In recent years, there has been interest in how geometric properties such asintrinsic dimension (ID) of a neural network's hidden representations changethrough its layers, and how such properties are predictive of important modelbehavior such as generalization ability. However, evidence has begun to emergethat such behavior can change significantly depending on the domain of thenetwork's training data, such as natural versus medical images. Here, wefurther this inquiry by exploring how the ID of a network's learnedrepresentations changes through its layers, in essence, characterizing how thenetwork successively refines the information content of input data to be usedfor predictions. Analyzing eleven natural and medical image datasets across sixnetwork architectures, we find that how ID changes through the network differsnoticeably between natural and medical image models. Specifically, medicalimage models peak in representation ID earlier in the network, implying adifference in the image features and their abstractness that are typically usedfor downstream tasks in these domains. Additionally, we discover a strongcorrelation of this peak representation ID with the ID of the data in its inputspace, implying that the intrinsic information content of a model's learnedrepresentations is guided by that of the data it was trained on. Overall, ourfindings emphasize notable discrepancies in network behavior between naturaland non-natural imaging domains regarding hidden representation informationcontent, and provide further insights into how a network's learned features areshaped by its training data.</description><author>Nicholas Konz, Maciej A. Mazurowski</author><pubDate>Mon, 09 Sep 2024 17:58:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.08381v3</guid></item><item><title>Explainable AI for Engineering Design: A Unified Approach of Systems Engineering and Component- Based Deep Learning Demonstrated by Energy- Efficient Building Design</title><link>http://arxiv.org/abs/2108.13836v7</link><description>Data-driven models created by machine learning, gain in importance in allfields of design and engineering. They, have high potential to assistdecision-makers in creating novel, artefacts with better performance andsustainability. However,, limited generalization and the black-box nature ofthese models, lead to limited explainability and reusability. To overcome this,situation, we propose a component-based approach to create, partial componentmodels by machine learning (ML). This, component-based approach aligns deeplearning with systems, engineering (SE). The key contribution of thecomponent-based, method is that activations at interfaces between thecomponents, are interpretable engineering quantities. In this way, the,hierarchical component system forms a deep neural network, (DNN) that a prioriintegrates information for engineering, explainability. The, approach adaptsthe model structure to engineering methods of, systems engineering and todomain knowledge. We examine the, performance of the approach by the field ofenergy-efficient, building design: First, we observed better generalization ofthe, component-based method by analyzing prediction accuracy, outside thetraining data. Especially for representative designs, different in structure,we observe a much higher accuracy, (R2 = 0.94) compared to conventionalmonolithic methods, (R2 = 0.71). Second, we illustrate explainability byexemplary, demonstrating how sensitivity information from SE and rules, fromlow-depth decision trees serve engineering. Third, we, evaluate explainabilityby qualitative and quantitative methods, demonstrating the matching ofpreliminary knowledge and data-driven, derived strategies and show correctnessof activations at, component interfaces compared to white-box simulationresults, (envelope components: R2 = 0.92..0.99; zones: R2 = 0.78..0.93).</description><author>Philipp Geyer, Manav Mahan Singh, Xia Chen</author><pubDate>Mon, 09 Sep 2024 17:55:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2108.13836v7</guid></item><item><title>LSVOS Challenge Report: Large-scale Complex and Long Video Object Segmentation</title><link>http://arxiv.org/abs/2409.05847v1</link><description>Despite the promising performance of current video segmentation models onexisting benchmarks, these models still struggle with complex scenes. In thispaper, we introduce the 6th Large-scale Video Object Segmentation (LSVOS)challenge in conjunction with ECCV 2024 workshop. This year's challengeincludes two tasks: Video Object Segmentation (VOS) and Referring Video ObjectSegmentation (RVOS). In this year, we replace the classic YouTube-VOS andYouTube-RVOS benchmark with latest datasets MOSE, LVOS, and MeViS to assess VOSunder more challenging complex environments. This year's challenge attracted129 registered teams from more than 20 institutes across over 8 countries. Thisreport include the challenge and dataset introduction, and the methods used bytop 7 teams in two tracks. More details can be found in our homepagehttps://lsvos.github.io/.</description><author>Henghui Ding, Lingyi Hong, Chang Liu, Ning Xu, Linjie Yang, Yuchen Fan, Deshui Miao, Yameng Gu, Xin Li, Zhenyu He, Yaowei Wang, Ming-Hsuan Yang, Jinming Chai, Qin Ma, Junpei Zhang, Licheng Jiao, Fang Liu, Xinyu Liu, Jing Zhang, Kexin Zhang, Xu Liu, LingLing Li, Hao Fang, Feiyu Pan, Xiankai Lu, Wei Zhang, Runmin Cong, Tuyen Tran, Bin Cao, Yisi Zhang, Hanyi Wang, Xingjian He, Jing Liu</author><pubDate>Mon, 09 Sep 2024 17:45:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05847v1</guid></item><item><title>An Introduction to Quantum Reinforcement Learning (QRL)</title><link>http://arxiv.org/abs/2409.05846v1</link><description>Recent advancements in quantum computing (QC) and machine learning (ML) havesparked considerable interest in the integration of these two cutting-edgefields. Among the various ML techniques, reinforcement learning (RL) stands outfor its ability to address complex sequential decision-making problems. RL hasalready demonstrated substantial success in the classical ML community. Now,the emerging field of Quantum Reinforcement Learning (QRL) seeks to enhance RLalgorithms by incorporating principles from quantum computing. This paperoffers an introduction to this exciting area for the broader AI and MLcommunity.</description><author>Samuel Yen-Chi Chen</author><pubDate>Mon, 09 Sep 2024 17:45:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05846v1</guid></item><item><title>MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct</title><link>http://arxiv.org/abs/2409.05840v1</link><description>The development of Multimodal Large Language Models (MLLMs) has seensignificant advancements. However, the quantity and quality of multimodalinstruction data have emerged as significant bottlenecks in their progress.Manually creating multimodal instruction data is both time-consuming andinefficient, posing challenges in producing instructions of high complexity.Moreover, distilling instruction data from black-box commercial models (e.g.,GPT-4o, GPT-4V) often results in simplistic instruction data, which constrainsperformance to that of these models. The challenge of curating diverse andcomplex instruction data remains substantial. We propose MMEvol, a novelmultimodal instruction data evolution framework that combines fine-grainedperception evolution, cognitive reasoning evolution, and interaction evolution.This iterative approach breaks through data quality bottlenecks to generate acomplex and diverse image-text instruction dataset, thereby empowering MLLMswith enhanced capabilities. Beginning with an initial set of instructions,SEED-163K, we utilize MMEvol to systematically broadens the diversity ofinstruction types, integrates reasoning steps to enhance cognitivecapabilities, and extracts detailed information from images to improve visualunderstanding and robustness. To comprehensively evaluate the effectiveness ofour data, we train LLaVA-NeXT using the evolved data and conduct experimentsacross 13 vision-language tasks. Compared to the baseline trained with seeddata, our approach achieves an average accuracy improvement of 3.1 points andreaches state-of-the-art (SOTA) performance on 9 of these tasks.</description><author>Run Luo, Haonan Zhang, Longze Chen, Ting-En Lin, Xiong Liu, Yuchuan Wu, Min Yang, Minzheng Wang, Pengpeng Zeng, Lianli Gao, Heng Tao Shen, Yunshui Li, Xiaobo Xia, Fei Huang, Jingkuan Song, Yongbin Li</author><pubDate>Mon, 09 Sep 2024 17:44:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05840v1</guid></item><item><title>Vision-Driven 2D Supervised Fine-Tuning Framework for Bird's Eye View Perception</title><link>http://arxiv.org/abs/2409.05834v1</link><description>Visual bird's eye view (BEV) perception, due to its excellent perceptualcapabilities, is progressively replacing costly LiDAR-based perception systems,especially in the realm of urban intelligent driving. However, this type ofperception still relies on LiDAR data to construct ground truth databases, aprocess that is both cumbersome and time-consuming. Moreover, most massproducedautonomous driving systems are only equipped with surround camera sensors andlack LiDAR data for precise annotation. To tackle this challenge, we propose afine-tuning method for BEV perception network based on visual 2D semanticperception, aimed at enhancing the model's generalization capabilities in newscene data. Considering the maturity and development of 2D perceptiontechnologies, our method significantly reduces the dependency on high-cost BEVground truths and shows promising industrial application prospects. Extensiveexperiments and comparative analyses conducted on the nuScenes and Waymo publicdatasets demonstrate the effectiveness of our proposed method.</description><author>Lei He, Qiaoyi Wang, Honglin Sun, Qing Xu, Bolin Gao, Shengbo Eben Li, Jianqiang Wang, Keqiang Li</author><pubDate>Mon, 09 Sep 2024 17:40:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05834v1</guid></item><item><title>Guide-and-Rescale: Self-Guidance Mechanism for Effective Tuning-Free Real Image Editing</title><link>http://arxiv.org/abs/2409.01322v2</link><description>Despite recent advances in large-scale text-to-image generative models,manipulating real images with these models remains a challenging problem. Themain limitations of existing editing methods are that they either fail toperform with consistent quality on a wide range of image edits or requiretime-consuming hyperparameter tuning or fine-tuning of the diffusion model topreserve the image-specific appearance of the input image. We propose a novelapproach that is built upon a modified diffusion sampling process via theguidance mechanism. In this work, we explore the self-guidance technique topreserve the overall structure of the input image and its local regionsappearance that should not be edited. In particular, we explicitly introducelayout-preserving energy functions that are aimed to save local and globalstructures of the source image. Additionally, we propose a noise rescalingmechanism that allows to preserve noise distribution by balancing the norms ofclassifier-free guidance and our proposed guiders during generation. Such aguiding approach does not require fine-tuning the diffusion model and exactinversion process. As a result, the proposed method provides a fast andhigh-quality editing mechanism. In our experiments, we show through humanevaluation and quantitative analysis that the proposed method allows to producedesired editing which is more preferable by humans and also achieves a bettertrade-off between editing quality and preservation of the original image. Ourcode is available at https://github.com/FusionBrainLab/Guide-and-Rescale.</description><author>Vadim Titov, Madina Khalmatova, Alexandra Ivanova, Dmitry Vetrov, Aibek Alanov</author><pubDate>Mon, 09 Sep 2024 17:38:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.01322v2</guid></item><item><title>Using Natural Language Explanations to Rescale Human Judgments</title><link>http://arxiv.org/abs/2305.14770v5</link><description>The rise of large language models (LLMs) has brought a critical need forhigh-quality human-labeled data, particularly for processes like human feedbackand evaluation. A common practice is to label data via consensus annotationover human judgments. However, annotators' judgments for subjective tasks candiffer in many ways: they may reflect different qualitative judgments about anexample, and they may be mapped to a labeling scheme in different ways. We showthat these nuances can be captured by natural language explanations, andpropose a method to rescale ordinal annotations and explanations using LLMs.Specifically, we feed annotators' Likert ratings and corresponding explanationsinto an LLM and prompt it to produce a numeric score anchored in a scoringrubric. These scores should reflect the annotators' underlying assessments ofthe example. The rubric can be designed or modified after annotation, andinclude distinctions that may not have been known when the original errortaxonomy was devised. We explore our technique in the context of rating systemoutputs for a document-grounded question answering task, where LLMs achievenear-human performance. Our method rescales the raw judgments without impactingagreement and brings the scores closer to human judgments grounded in the samescoring rubric.</description><author>Manya Wadhwa, Jifan Chen, Junyi Jessy Li, Greg Durrett</author><pubDate>Mon, 09 Sep 2024 17:37:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14770v5</guid></item><item><title>Applying Attribution Explanations in Truth-Discovery Quantitative Bipolar Argumentation Frameworks</title><link>http://arxiv.org/abs/2409.05831v1</link><description>Explaining the strength of arguments under gradual semantics is receivingincreasing attention. For example, various studies in the literature offerexplanations by computing the attribution scores of arguments or edges inQuantitative Bipolar Argumentation Frameworks (QBAFs). These explanations,known as Argument Attribution Explanations (AAEs) and Relation AttributionExplanations (RAEs), commonly employ removal-based and Shapley-based techniquesfor computing the attribution scores. While AAEs and RAEs have proven useful inseveral applications with acyclic QBAFs, they remain largely unexplored forcyclic QBAFs. Furthermore, existing applications tend to focus solely on eitherAAEs or RAEs, but do not compare them directly. In this paper, we apply bothAAEs and RAEs, to Truth Discovery QBAFs (TD-QBAFs), which assess thetrustworthiness of sources (e.g., websites) and their claims (e.g., theseverity of a virus), and feature complex cycles. We find that both AAEs andRAEs can provide interesting explanations and can give non-trivial andsurprising insights.</description><author>Xiang Yin, Nico Potyka, Francesca Toni</author><pubDate>Mon, 09 Sep 2024 17:36:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05831v1</guid></item><item><title>Bi-Directional Transformers vs. word2vec: Discovering Vulnerabilities in Lifted Compiled Code</title><link>http://arxiv.org/abs/2405.20611v2</link><description>Detecting vulnerabilities within compiled binaries is challenging due to losthigh-level code structures and other factors such as architecturaldependencies, compilers, and optimization options. To address these obstacles,this research explores vulnerability detection using natural languageprocessing (NLP) embedding techniques with word2vec, BERT, and RoBERTa to learnsemantics from intermediate representation (LLVM IR) code. Long short-termmemory (LSTM) neural networks were trained on embeddings from encoders createdusing approximately 48k LLVM functions from the Juliet dataset. This study ispioneering in its comparison of word2vec models with multiple bidirectionaltransformer (BERT, RoBERTa) embeddings built using LLVM code to train neuralnetworks to detect vulnerabilities in compiled binaries. word2vec Skip-Grammodels achieved 92% validation accuracy in detecting vulnerabilities,outperforming word2vec Continuous Bag of Words (CBOW), BERT, and RoBERTa. Thissuggests that complex contextual embeddings may not provide advantages oversimpler word2vec models for this task when a limited number (e.g. 48K) of datasamples are used to train the bidirectional transformer-based models. Thecomparative results provide novel insights into selecting optimal embeddingsfor learning compiler-independent semantic code representations to advancemachine learning detection of vulnerabilities in compiled binaries.</description><author>Gary A. McCully, John D. Hastings, Shengjie Xu, Adam Fortier</author><pubDate>Mon, 09 Sep 2024 17:35:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20611v2</guid></item><item><title>A Lost Opportunity for Vision-Language Models: A Comparative Study of Online Test-Time Adaptation for Vision-Language Models</title><link>http://arxiv.org/abs/2405.14977v2</link><description>In deep learning, maintaining model robustness against distribution shifts iscritical. This work explores a broad range of possibilities to adaptvision-language foundation models at test-time, with a particular emphasis onCLIP and its variants. The study systematically examines prompt-basedtechniques and existing test-time adaptation methods, aiming to improve therobustness under distribution shift in diverse real-world scenarios.Specifically, the investigation covers various prompt engineering strategies,including handcrafted prompts, prompt ensembles, and prompt learningtechniques. Additionally, we introduce a vision-text-space ensemble thatsubstantially enhances average performance compared to text-space-onlyensembles. Since online test-time adaptation has shown to be effective tomitigate performance drops under distribution shift, the study extends itsscope to evaluate the effectiveness of existing test-time adaptation methodsthat were originally designed for vision-only classification models. Throughextensive experimental evaluations conducted across multiple datasets anddiverse model architectures, the research demonstrates the effectiveness ofthese adaptation strategies. Code is available at:https://github.com/mariodoebler/test-time-adaptation</description><author>Mario Döbler, Robert A. Marsden, Tobias Raichle, Bin Yang</author><pubDate>Mon, 09 Sep 2024 17:33:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14977v2</guid></item><item><title>MeshBrush: Painting the Anatomical Mesh with Neural Stylization for Endoscopy</title><link>http://arxiv.org/abs/2404.02999v2</link><description>Style transfer is a promising approach to close the sim-to-real gap inmedical endoscopy. Rendering synthetic endoscopic videos by traversingpre-operative scans (such as MRI or CT) can generate structurally accuratesimulations as well as ground truth camera poses and depth maps. Althoughimage-to-image (I2I) translation models such as CycleGAN can imitate realisticendoscopic images from these simulations, they are unsuitable forvideo-to-video synthesis due to the lack of temporal consistency, resulting inartifacts between frames. We propose MeshBrush, a neural mesh stylizationmethod to synthesize temporally consistent videos with differentiablerendering. MeshBrush uses the underlying geometry of patient imaging data whileleveraging existing I2I methods. With learned per-vertex textures, the stylizedmesh guarantees consistency while producing high-fidelity outputs. Wedemonstrate that mesh stylization is a promising approach for creatingrealistic simulations for downstream tasks such as training networks andpreoperative planning. Although our method is tested and designed forureteroscopy, its components are transferable to general endoscopic andlaparoscopic procedures. The code will be made public on GitHub.</description><author>John J. Han, Ayberk Acar, Nicholas Kavoussi, Jie Ying Wu</author><pubDate>Mon, 09 Sep 2024 17:33:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02999v2</guid></item><item><title>GASP: Gaussian Splatting for Physic-Based Simulations</title><link>http://arxiv.org/abs/2409.05819v1</link><description>Physics simulation is paramount for modeling and utilization of 3D scenes invarious real-world applications. However, its integration with state-of-the-art3D scene rendering techniques such as Gaussian Splatting (GS) remainschallenging. Existing models use additional meshing mechanisms, includingtriangle or tetrahedron meshing, marching cubes, or cage meshes. As analternative, we can modify the physics grounded Newtonian dynamics to alignwith 3D Gaussian components. Current models take the first-order approximationof a deformation map, which locally approximates the dynamics by lineartransformations. In contrast, our Gaussian Splatting for Physics-BasedSimulations (GASP) model uses such a map (without any modifications) and flatGaussian distributions, which are parameterized by three points (mesh faces).Subsequently, each 3D point (mesh face node) is treated as a discrete entitywithin a 3D space. Consequently, the problem of modeling Gaussian components isreduced to working with 3D points. Additionally, the information on mesh facescan be used to incorporate further properties into the physics model,facilitating the use of triangles. Resulting solution can be integrated intoany physics engine that can be treated as a black box. As demonstrated in ourstudies, the proposed model exhibits superior performance on a diverse range ofbenchmark datasets designed for 3D object rendering.</description><author>Piotr Borycki, Weronika Smolak, Joanna Waczyńska, Marcin Mazur, Sławomir Tadeja, Przemysław Spurek</author><pubDate>Mon, 09 Sep 2024 17:28:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05819v1</guid></item><item><title>VFA: Vision Frequency Analysis of Foundation Models and Human</title><link>http://arxiv.org/abs/2409.05817v1</link><description>Machine learning models often struggle with distribution shifts in real-worldscenarios, whereas humans exhibit robust adaptation. Models that better alignwith human perception may achieve higher out-of-distribution generalization. Inthis study, we investigate how various characteristics of large-scale computervision models influence their alignment with human capabilities and robustness.Our findings indicate that increasing model and data size and incorporatingrich semantic information and multiple modalities enhance models' alignmentwith human perception and their overall robustness. Our empirical analysisdemonstrates a strong correlation between out-of-distribution accuracy andhuman alignment.</description><author>Mohammad-Javad Darvishi-Bayazi, Md Rifat Arefin, Jocelyn Faubert, Irina Rish</author><pubDate>Mon, 09 Sep 2024 17:23:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05817v1</guid></item><item><title>Improving Pretraining Data Using Perplexity Correlations</title><link>http://arxiv.org/abs/2409.05816v1</link><description>Quality pretraining data is often seen as the key to high-performancelanguage models. However, progress in understanding pretraining data has beenslow due to the costly pretraining runs required for data selectionexperiments. We present a framework that avoids these costs and selectshigh-quality pretraining data without any LLM training of our own. Our work isbased on a simple observation: LLM losses on many pretraining texts arecorrelated with downstream benchmark performance, and selectinghigh-correlation documents is an effective pretraining data selection method.We build a new statistical framework for data selection centered aroundestimates of perplexity-benchmark correlations and perform data selection usinga sample of 90 LLMs taken from the Open LLM Leaderboard on texts from tens ofthousands of web domains. In controlled pretraining experiments at the 160Mparameter scale on 8 benchmarks, our approach outperforms DSIR on everybenchmark, while matching the best data selector found in DataComp-LM, ahand-engineered bigram classifier.</description><author>Tristan Thrush, Christopher Potts, Tatsunori Hashimoto</author><pubDate>Mon, 09 Sep 2024 17:23:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05816v1</guid></item><item><title>Improving Antibody Design with Force-Guided Sampling in Diffusion Models</title><link>http://arxiv.org/abs/2406.05832v2</link><description>Antibodies, crucial for immune defense, primarily rely oncomplementarity-determining regions (CDRs) to bind and neutralize antigens,such as viruses. The design of these CDRs determines the antibody's affinityand specificity towards its target. Generative models, particularly denoisingdiffusion probabilistic models (DDPMs), have shown potential to advance thestructure-based design of CDR regions. However, only a limited dataset of boundantibody-antigen structures is available, and generalization toout-of-distribution interfaces remains a challenge. Physics based force-fields,which approximate atomic interactions, offer a coarse but universal source ofinformation to better mold designs to target interfaces. Integrating thisfoundational information into diffusion models is, therefore, highly desirable.Here, we propose a novel approach to enhance the sampling process of diffusionmodels by integrating force field energy-based feedback. Our model, DiffForce,employs forces to guide the diffusion sampling process, effectively blendingthe two distributions. Through extensive experiments, we demonstrate that ourmethod guides the model to sample CDRs with lower energy, enhancing both thestructure and sequence of the generated antibodies.</description><author>Paulina Kulytė, Francisco Vargas, Simon Valentin Mathis, Yu Guang Wang, José Miguel Hernández-Lobato, Pietro Liò</author><pubDate>Mon, 09 Sep 2024 17:20:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05832v2</guid></item><item><title>A Flexible Framework for Universal Computational Aberration Correction via Automatic Lens Library Generation and Domain Adaptation</title><link>http://arxiv.org/abs/2409.05809v1</link><description>Emerging universal Computational Aberration Correction (CAC) paradigmsprovide an inspiring solution to light-weight and high-quality imaging withoutrepeated data preparation and model training to accommodate new lens designs.However, the training databases in these approaches, i.e., the lens libraries(LensLibs), suffer from their limited coverage of real-world aberrationbehaviors. In this work, we set up an OmniLens framework for universal CAC,considering both the generalization ability and flexibility. OmniLens extendsthe idea of universal CAC to a broader concept, where a base model is trainedfor three cases, including zero-shot CAC with the pre-trained model, few-shotCAC with a little lens-specific data for fine-tuning, and domain adaptive CACusing domain adaptation for lens-descriptions-unknown lens. In terms ofOmniLens's data foundation, we first propose an Evolution-based AutomaticOptical Design (EAOD) pipeline to construct LensLib automatically, coinedAODLib, whose diversity is enriched by an evolution framework, withcomprehensive constraints and a hybrid optimization strategy for achievingrealistic aberration behaviors. For network design, we introduce the guidanceof high-quality codebook priors to facilitate zero-shot CAC and few-shot CAC,which enhances the model's generalization ability, while also boosting itsconvergence in a few-shot case. Furthermore, based on the statisticalobservation of dark channel priors in optical degradation, we design anunsupervised regularization term to adapt the base model to the targetdescriptions-unknown lens using its aberration images without ground truth. Wevalidate OmniLens on 4 manually designed low-end lenses with various structuresand aberration behaviors. Remarkably, the base model trained on AODLib exhibitsstrong generalization capabilities, achieving 97% of the lens-specificperformance in a zero-shot setting.</description><author>Qi Jiang, Yao Gao, Shaohua Gao, Zhonghua Yi, Lei Sun, Hao Shi, Kailun Yang, Kaiwei Wang, Jian Bai</author><pubDate>Mon, 09 Sep 2024 17:12:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05809v1</guid></item><item><title>The Future of Software Testing: AI-Powered Test Case Generation and Validation</title><link>http://arxiv.org/abs/2409.05808v1</link><description>Software testing is a crucial phase in the software development lifecycle(SDLC), ensuring that products meet necessary functional, performance, andquality benchmarks before release. Despite advancements in automation,traditional methods of generating and validating test cases still facesignificant challenges, including prolonged timelines, human error, incompletetest coverage, and high costs of manual intervention. These limitations oftenlead to delayed product launches and undetected defects that compromisesoftware quality and user satisfaction. The integration of artificialintelligence (AI) into software testing presents a promising solution to thesepersistent challenges. AI-driven testing methods automate the creation ofcomprehensive test cases, dynamically adapt to changes, and leverage machinelearning to identify high-risk areas in the codebase. This approach enhancesregression testing efficiency while expanding overall test coverage.Furthermore, AI-powered tools enable continuous testing and self-healing testcases, significantly reducing manual oversight and accelerating feedback loops,ultimately leading to faster and more reliable software releases. This paperexplores the transformative potential of AI in improving test case generationand validation, focusing on its ability to enhance efficiency, accuracy, andscalability in testing processes. It also addresses key challenges associatedwith adapting AI for testing, including the need for high quality trainingdata, ensuring model transparency, and maintaining a balance between automationand human oversight. Through case studies and examples of real-worldapplications, this paper illustrates how AI can significantly enhance testingefficiency across both legacy and modern software systems.</description><author>Mohammad Baqar, Rajat Khanda</author><pubDate>Mon, 09 Sep 2024 17:12:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05808v1</guid></item><item><title>Benchmarking Chinese Knowledge Rectification in Large Language Models</title><link>http://arxiv.org/abs/2409.05806v1</link><description>While Large Language Models (LLMs) exhibit remarkable generativecapabilities, they are not without flaws, particularly in the form ofhallucinations. This issue is even more pronounced when LLMs are applied tospecific languages and domains. For example, LLMs may generate nonsenseinformation when handling Chinese ancient poetry, proverbs, or idioms, owing tothe lack of specific knowledge. To this end, this paper introduces a benchmarkfor rectifying Chinese knowledge in LLMs via knowledge editing. Specifically,we introduce a new Chinese dataset, CKnowEdit, by collecting seven type ofknowledge from various sources, including classical texts, idioms, and contentfrom Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony,antithesis, and logical constructs inherent in the Chinese language. Throughthe analysis of this dataset, we uncover the challenges faced by current LLMsin mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledgeediting techniques on this dataset unveil the substantial scope for advancementin the rectification of Chinese knowledge. Code and dataset are available athttps://github.com/zjunlp/EasyEdit.</description><author>Tianhe Lu, Jizhan Fang, Yunzhi Yao, Xin Xu, Ningyu Zhang, Huajun Chen</author><pubDate>Mon, 09 Sep 2024 17:11:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05806v1</guid></item><item><title>Celcomen: spatial causal disentanglement for single-cell and tissue perturbation modeling</title><link>http://arxiv.org/abs/2409.05804v1</link><description>Celcomen leverages a mathematical causality framework to disentangle intra-and inter- cellular gene regulation programs in spatial transcriptomics andsingle-cell data through a generative graph neural network. It can learngene-gene interactions, as well as generate post-perturbation counterfactualspatial transcriptomics, thereby offering access to experimentally inaccessiblesamples. We validated its disentanglement, identifiability, and counterfactualprediction capabilities through simulations and in clinically relevant humanglioblastoma, human fetal spleen, and mouse lung cancer samples. Celcomenprovides the means to model disease and therapy induced changes allowing fornew insights into single-cell spatially resolved tissue responses relevant tohuman health.</description><author>Stathis Megas, Daniel G. Chen, Krzysztof Polanski, Moshe Eliasof, Carola-Bibiane Schonlieb, Sarah A. Teichmann</author><pubDate>Mon, 09 Sep 2024 17:10:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05804v1</guid></item><item><title>Cross-Input Certified Training for Universal Perturbations</title><link>http://arxiv.org/abs/2405.09176v2</link><description>Existing work in trustworthy machine learning primarily focuses onsingle-input adversarial perturbations. In many real-world attack scenarios,input-agnostic adversarial attacks, e.g. universal adversarial perturbations(UAPs), are much more feasible. Current certified training methods train modelsrobust to single-input perturbations but achieve suboptimal clean and UAPaccuracy, thereby limiting their applicability in practical applications. Wepropose a novel method, CITRUS, for certified training of networks robustagainst UAP attackers. We show in an extensive evaluation across differentdatasets, architectures, and perturbation magnitudes that our methodoutperforms traditional certified training methods on standard accuracy (up to10.3\%) and achieves SOTA performance on the more practical certified UAPaccuracy metric.</description><author>Changming Xu, Gagandeep Singh</author><pubDate>Mon, 09 Sep 2024 17:09:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09176v2</guid></item><item><title>Input Space Mode Connectivity in Deep Neural Networks</title><link>http://arxiv.org/abs/2409.05800v1</link><description>We extend the concept of loss landscape mode connectivity to the input spaceof deep neural networks. Mode connectivity was originally studied withinparameter space, where it describes the existence of low-loss paths betweendifferent solutions (loss minimizers) obtained through gradient descent. Wepresent theoretical and empirical evidence of its presence in the input spaceof deep networks, thereby highlighting the broader nature of the phenomenon. Weobserve that different input images with similar predictions are generallyconnected, and for trained models, the path tends to be simple, with only asmall deviation from being a linear path. Our methodology utilizes real,interpolated, and synthetic inputs created using the input optimizationtechnique for feature visualization. We conjecture that input space modeconnectivity in high-dimensional spaces is a geometric effect that takes placeeven in untrained models and can be explained through percolation theory. Weexploit mode connectivity to obtain new insights about adversarial examples anddemonstrate its potential for adversarial detection. Additionally, we discussapplications for the interpretability of deep networks.</description><author>Jakub Vrabel, Ori Shem-Ur, Yaron Oz, David Krueger</author><pubDate>Mon, 09 Sep 2024 17:03:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05800v1</guid></item><item><title>PDAF: A Phonetic Debiasing Attention Framework For Speaker Verification</title><link>http://arxiv.org/abs/2409.05799v1</link><description>Speaker verification systems are crucial for authenticating identity throughvoice. Traditionally, these systems focus on comparing feature vectors,overlooking the speech's content. However, this paper challenges this byhighlighting the importance of phonetic dominance, a measure of the frequencyor duration of phonemes, as a crucial cue in speaker verification. A novelPhoneme Debiasing Attention Framework (PDAF) is introduced, integrating withexisting attention frameworks to mitigate biases caused by phonetic dominance.PDAF adjusts the weighting for each phoneme and influences feature extraction,allowing for a more nuanced analysis of speech. This approach paves the way formore accurate and reliable identity authentication through voice. Furthermore,by employing various weighting strategies, we evaluate the influence ofphonetic features on the efficacy of the speaker verification system.</description><author>Massa Baali, Abdulhamid Aldoobi, Hira Dhamyal, Rita Singh, Bhiksha Raj</author><pubDate>Mon, 09 Sep 2024 17:03:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05799v1</guid></item><item><title>Enhancing Preference-based Linear Bandits via Human Response Time</title><link>http://arxiv.org/abs/2409.05798v1</link><description>Binary human choice feedback is widely used in interactive preferencelearning for its simplicity, but it provides limited information aboutpreference strength. To overcome this limitation, we leverage human responsetimes, which inversely correlate with preference strength, as complementaryinformation. Our work integrates the EZ-diffusion model, which jointly modelshuman choices and response times, into preference-based linear bandits. Weintroduce a computationally efficient utility estimator that reformulates theutility estimation problem using both choices and response times as a linearregression problem. Theoretical and empirical comparisons with traditionalchoice-only estimators reveal that for queries with strong preferences ("easy"queries), choices alone provide limited information, while response times offervaluable complementary information about preference strength. As a result,incorporating response times makes easy queries more useful. We demonstratethis advantage in the fixed-budget best-arm identification problem, withsimulations based on three real-world datasets, consistently showingaccelerated learning when response times are incorporated.</description><author>Shen Li, Yuyang Zhang, Zhaolin Ren, Claire Liang, Na Li, Julie A. Shah</author><pubDate>Mon, 09 Sep 2024 17:02:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05798v1</guid></item><item><title>A Comprehensive Evaluation of Histopathology Foundation Models for Ovarian Cancer Subtype Classification</title><link>http://arxiv.org/abs/2405.09990v2</link><description>Large pretrained transformers are increasingly being developed as generalisedfoundation models which can underpin powerful task-specific artificialintelligence models. Histopathology foundation models show great promise acrossmany tasks, but analyses have typically been limited by arbitraryhyperparameters that were not tuned to the specific task. We report the mostrigorous single-task validation of histopathology foundation models to date,specifically in ovarian cancer morphological subtyping. Attention-basedmultiple instance learning classifiers were compared using threeImageNet-pretrained feature extractors and fourteen histopathology foundationmodels. The training set consisted of 1864 whole slide images from 434 ovariancarcinoma cases at Leeds Teaching Hospitals NHS Trust. Five-classclassification performance was evaluated through five-fold cross-validation,and these cross-validation models were ensembled for hold-out testing andexternal validation on the Transcanadian Study and OCEAN Challenge datasets.The best-performing model used the H-optimus-0 foundation model, withfive-class balanced accuracies of 89%, 97%, and 74% in the test sets.Normalisations and augmentations aided the performance of theImageNet-pretrained ResNets, but these were still outperformed by 13 of the 14foundation models. Hyperparameter tuning the downstream classifiers improvedperformance by a median 1.9% balanced accuracy, with many improvements beingstatistically significant. Histopathology foundation models offer a clearbenefit to ovarian cancer subtyping, improving classification performance to adegree where clinical utility is tangible, albeit with an increasedcomputational burden. Such models could provide a second opinion tohistopathologists diagnosing challenging cases and may improve the accuracy,objectivity, and efficiency of pathological diagnoses overall.</description><author>Jack Breen, Katie Allen, Kieran Zucker, Lucy Godson, Nicolas M. Orsi, Nishant Ravikumar</author><pubDate>Mon, 09 Sep 2024 16:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.09990v2</guid></item><item><title>Espresso: Robust Concept Filtering in Text-to-Image Models</title><link>http://arxiv.org/abs/2404.19227v5</link><description>Diffusion based text-to-image models are trained on large datasets scrapedfrom the Internet, potentially containing unacceptable concepts (e.g.,copyright infringing or unsafe). We need concept removal techniques (CRTs)which are effective in preventing the generation of images with unacceptableconcepts, utility-preserving on acceptable concepts, and robust against evasionwith adversarial prompts. None of the prior CRTs satisfy all these requirementssimultaneously. We introduce Espresso, the first robust concept filter based onContrastive Language-Image Pre-Training (CLIP). We configure CLIP to identifyunacceptable concepts in generated images using the distance of theirembeddings to the text embeddings of both unacceptable and acceptable concepts.This lets us fine-tune for robustness by separating the text embeddings ofunacceptable and acceptable concepts while preserving their pairing with imageembeddings for utility. We present a pipeline to evaluate various CRTs, attacksagainst them, and show that Espresso, is more effective and robust than priorCRTs, while retaining utility.</description><author>Anudeep Das, Vasisht Duddu, Rui Zhang, N. Asokan</author><pubDate>Mon, 09 Sep 2024 16:51:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19227v5</guid></item><item><title>Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks</title><link>http://arxiv.org/abs/2409.05790v1</link><description>Deep generative models (DGMs) have proven to be powerful in generatingrealistic data samples. Their capability to learn the underlying distributionof a dataset enable them to generate synthetic data samples that closelyresemble the original training dataset, thus addressing the challenge of datascarcity. In this work, we investigated the capabilities of DGMs by developinga conditional variational autoencoder (CVAE) model to augment the critical heatflux (CHF) measurement data that was used to generate the 2006 Groeneveldlookup table. To determine how this approach compared to traditional methods, afine-tuned deep neural network (DNN) regression model was created and evaluatedwith the same dataset. Both the CVAE and DNN models achieved small meanabsolute relative errors, with the CVAE model maintaining more favorableresults. To quantify the uncertainty in the model's predictions, uncertaintyquantification (UQ) was performed with repeated sampling of the CVAE model andensembling of the DNN model. Following UQ, the DNN ensemble notably improvedperformance when compared to the baseline DNN model, while the CVAE modelachieved similar results to its non-UQ results. The CVAE model was shown tohave significantly less variability and a higher confidence after assessment ofthe prediction-wise relative standard deviations. Evaluating domaingeneralization, both models achieved small mean error values when predictingboth inside and outside the training domain, with predictions outside thetraining domain showing slightly larger errors. Overall, the CVAE model wascomparable to the DNN regression model in predicting CHF values but with betteruncertainty behavior.</description><author>Farah Alsafadi, Aidan Furlong, Xu Wu</author><pubDate>Mon, 09 Sep 2024 16:50:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05790v1</guid></item><item><title>Leveraging Object Priors for Point Tracking</title><link>http://arxiv.org/abs/2409.05786v1</link><description>Point tracking is a fundamental problem in computer vision with numerousapplications in AR and robotics. A common failure mode in long-term pointtracking occurs when the predicted point leaves the object it belongs to andlands on the background or another object. We identify this as the failure tocorrectly capture objectness properties in learning to track. To address thislimitation of prior work, we propose a novel objectness regularization approachthat guides points to be aware of object priors by forcing them to stay insidethe the boundaries of object instances. By capturing objectness cues attraining time, we avoid the need to compute object masks during testing. Inaddition, we leverage contextual attention to enhance the featurerepresentation for capturing objectness at the feature level more effectively.As a result, our approach achieves state-of-the-art performance on three pointtracking benchmarks, and we further validate the effectiveness of ourcomponents via ablation studies. The source code is available at:https://github.com/RehgLab/tracking_objectness</description><author>Bikram Boote, Anh Thai, Wenqi Jia, Ozgur Kara, Stefan Stojanov, James M. Rehg, Sangmin Lee</author><pubDate>Mon, 09 Sep 2024 16:48:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05786v1</guid></item><item><title>NeurLZ: On Systematically Enhancing Lossy Compression Performance for Scientific Data based on Neural Learning with Error Control</title><link>http://arxiv.org/abs/2409.05785v1</link><description>Large-scale scientific simulations generate massive datasets that posesignificant challenges for storage and I/O. While traditional lossy compressiontechniques can improve performance, balancing compression ratio, data quality,and throughput remains difficult. To address this, we propose NeurLZ, a novelcross-field learning-based and error-controlled compression framework forscientific data. By integrating skipping DNN models, cross-field learning, anderror control, our framework aims to substantially enhance lossy compressionperformance. Our contributions are three-fold: (1) We design a lightweightskipping model to provide high-fidelity detail retention, further improvingprediction accuracy. (2) We adopt a cross-field learning approach tosignificantly improve data prediction accuracy, resulting in a substantiallyimproved compression ratio. (3) We develop an error control approach to providestrict error bounds according to user requirements. We evaluated NeurLZ onseveral real-world HPC application datasets, including Nyx (cosmologicalsimulation), Miranda (large turbulence simulation), and Hurricane (weathersimulation). Experiments demonstrate that our framework achieves up to a 90%relative reduction in bit rate under the same data distortion, compared to thebest existing approach.</description><author>Wenqi Jia, Youyuan Liu, Zhewen Hu, Jinzhen Wang, Boyuan Zhang, Wei Niu, Junzhou Huang, Stavros Kalafatis, Sian Jin, Miao Yin</author><pubDate>Mon, 09 Sep 2024 16:48:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05785v1</guid></item><item><title>Unified Neural Network Scaling Laws and Scale-time Equivalence</title><link>http://arxiv.org/abs/2409.05782v1</link><description>As neural networks continue to grow in size but datasets might not, it isvital to understand how much performance improvement can be expected: is itmore important to scale network size or data volume? Thus, neural networkscaling laws, which characterize how test error varies with network size anddata volume, have become increasingly important. However, existing scaling lawsare often applicable only in limited regimes and often do not incorporate orpredict well-known phenomena such as double descent. Here, we present a noveltheoretical characterization of how three factors -- model size, training time,and data volume -- interact to determine the performance of deep neuralnetworks. We first establish a theoretical and empirical equivalence betweenscaling the size of a neural network and increasing its training timeproportionally. Scale-time equivalence challenges the current practice, whereinlarge models are trained for small durations, and suggests that smaller modelstrained over extended periods could match their efficacy. It also leads to anovel method for predicting the performance of large-scale networks fromsmall-scale networks trained for extended epochs, and vice versa. We nextcombine scale-time equivalence with a linear model analysis of double descentto obtain a unified theoretical scaling law, which we confirm with experimentsacross vision benchmarks and network architectures. These laws explain severalpreviously unexplained phenomena: reduced data requirements for generalizationin larger models, heightened sensitivity to label noise in overparameterizedmodels, and instances where increasing model scale does not necessarily enhanceperformance. Our findings hold significant implications for the practicaldeployment of neural networks, offering a more accessible and efficient path totraining and fine-tuning large models.</description><author>Akhilan Boopathy, Ila Fiete</author><pubDate>Mon, 09 Sep 2024 16:45:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05782v1</guid></item><item><title>Stepping Stones: A Progressive Training Strategy for Audio-Visual Semantic Segmentation</title><link>http://arxiv.org/abs/2407.11820v2</link><description>Audio-Visual Segmentation (AVS) aims to achieve pixel-level localization ofsound sources in videos, while Audio-Visual Semantic Segmentation (AVSS), as anextension of AVS, further pursues semantic understanding of audio-visualscenes. However, since the AVSS task requires the establishment of audio-visualcorrespondence and semantic understanding simultaneously, we observe thatprevious methods have struggled to handle this mashup of objectives inend-to-end training, resulting in insufficient learning and sub-optimization.Therefore, we propose a two-stage training strategy called \textit{SteppingStones}, which decomposes the AVSS task into two simple subtasks fromlocalization to semantic understanding, which are fully optimized in each stageto achieve step-by-step global optimization. This training strategy has alsoproved its generalization and effectiveness on existing methods. To furtherimprove the performance of AVS tasks, we propose a novel framework AdaptiveAudio Visual Segmentation, in which we incorporate an adaptive audio querygenerator and integrate masked attention into the transformer decoder,facilitating the adaptive fusion of visual and audio features. Extensiveexperiments demonstrate that our methods achieve state-of-the-art results onall three AVS benchmarks. The project homepage can be accessed athttps://gewu-lab.github.io/stepping_stones/.</description><author>Juncheng Ma, Peiwen Sun, Yaoting Wang, Di Hu</author><pubDate>Mon, 09 Sep 2024 16:43:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11820v2</guid></item><item><title>PromptCCD: Learning Gaussian Mixture Prompt Pool for Continual Category Discovery</title><link>http://arxiv.org/abs/2407.19001v2</link><description>We tackle the problem of Continual Category Discovery (CCD), which aims toautomatically discover novel categories in a continuous stream of unlabeleddata while mitigating the challenge of catastrophic forgetting -- an openproblem that persists even in conventional, fully supervised continuallearning. To address this challenge, we propose PromptCCD, a simple yeteffective framework that utilizes a Gaussian Mixture Model (GMM) as a promptingmethod for CCD. At the core of PromptCCD lies the Gaussian Mixture Prompting(GMP) module, which acts as a dynamic pool that updates over time to facilitaterepresentation learning and prevent forgetting during category discovery.Moreover, GMP enables on-the-fly estimation of category numbers, allowingPromptCCD to discover categories in unlabeled data without prior knowledge ofthe category numbers. We extend the standard evaluation metric for GeneralizedCategory Discovery (GCD) to CCD and benchmark state-of-the-art methods ondiverse public datasets. PromptCCD significantly outperforms existing methods,demonstrating its effectiveness. Project page:https://visual-ai.github.io/promptccd .</description><author>Fernando Julio Cendra, Bingchen Zhao, Kai Han</author><pubDate>Mon, 09 Sep 2024 16:43:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.19001v2</guid></item><item><title>Breaking Neural Network Scaling Laws with Modularity</title><link>http://arxiv.org/abs/2409.05780v1</link><description>Modular neural networks outperform nonmodular neural networks on tasksranging from visual question answering to robotics. These performanceimprovements are thought to be due to modular networks' superior ability tomodel the compositional and combinatorial structure of real-world problems.However, a theoretical explanation of how modularity improves generalizability,and how to leverage task modularity while training networks remains elusive.Using recent theoretical progress in explaining neural network generalization,we investigate how the amount of training data required to generalize on a taskvaries with the intrinsic dimensionality of a task's input. We showtheoretically that when applied to modularly structured tasks, while nonmodularnetworks require an exponential number of samples with task dimensionality,modular networks' sample complexity is independent of task dimensionality:modular networks can generalize in high dimensions. We then develop a novellearning rule for modular networks to exploit this advantage and empiricallyshow the improved generalization of the rule, both in- and out-of-distribution,on high-dimensional, modular tasks.</description><author>Akhilan Boopathy, Sunshine Jiang, William Yue, Jaedong Hwang, Abhiram Iyer, Ila Fiete</author><pubDate>Mon, 09 Sep 2024 16:43:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05780v1</guid></item><item><title>Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning</title><link>http://arxiv.org/abs/2408.14774v2</link><description>We introduce Instruct-SkillMix, an automated approach for creating diverse,high quality SFT data. The Instruct-SkillMix pipeline involves two stages, eachleveraging an existing powerful LLM: (1) Skill extraction: uses the LLM toextract core "skills" for instruction-following, either from existing datasets,or by directly prompting the model; (2) Data generation: uses the powerful LLMto generate (instruction, response) data that exhibit a randomly chosen pair ofthese skills. Here, the use of random skill combinations promotes diversity anddifficulty. Vanilla SFT (i.e., no PPO, DPO, or RL methods) on data generated fromInstruct-SkillMix leads to strong gains on instruction following benchmarkssuch as AlpacaEval 2.0, MT-Bench, and WildBench. With just $4$K examples,LLaMA-3-8B-Base achieves 42.76% length-controlled win rate on AlpacaEval 2.0.To our knowledge, this achieves state-of-the-art performance among all modelsthat have only undergone SFT (no RL methods) and competes with proprietarymodels such as Claude 3 Opus and LLaMA-3.1-405B-Instruct. Ablation studies also suggest plausible reasons for why creating openinstruction-tuning datasets via naive crowd-sourcing has proved difficult.Introducing low quality answers ("shirkers") in $20\%$ of Instruct-SkillMixexamples causes performance to plummet, sometimes catastrophically. The Instruct-SkillMix pipeline is flexible and is adaptable to othersettings.</description><author>Simran Kaur, Simon Park, Anirudh Goyal, Sanjeev Arora</author><pubDate>Mon, 09 Sep 2024 16:41:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.14774v2</guid></item><item><title>Advanced LSTM Neural Networks for Predicting Directional Changes in Sector-Specific ETFs Using Machine Learning Techniques</title><link>http://arxiv.org/abs/2409.05778v1</link><description>Trading and investing in stocks for some is their full-time career, while forothers, it's simply a supplementary income stream. Universal among allinvestors is the desire to turn a profit. The key to achieving this goal isdiversification. Spreading investments across sectors is critical toprofitability and maximizing returns. This study aims to gauge the viability ofmachine learning methods in practicing the principle of diversification tomaximize portfolio returns. To test this, the study evaluates the Long-ShortTerm Memory (LSTM) model across nine different sectors and over 2,200 stocksusing Vanguard's sector-based ETFs. The R-squared value across all sectorsshowed promising results, with an average of 0.8651 and a high of 0.942 for theVNQ ETF. These findings suggest that the LSTM model is a capable and viablemodel for accurately predicting directional changes across various industrysectors, helping investors diversify and grow their portfolios.</description><author>Rifa Gowani, Zaryab Kanjiani</author><pubDate>Mon, 09 Sep 2024 16:41:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05778v1</guid></item><item><title>Enhancing Accuracy in Deep Learning Using Random Matrix Theory</title><link>http://arxiv.org/abs/2310.03165v3</link><description>We explore the applications of random matrix theory (RMT) in the training ofdeep neural networks (DNNs), focusing on layer pruning that is reducing thenumber of DNN parameters (weights). Our numerical results show that thispruning leads to a drastic reduction of parameters while not reducing theaccuracy of DNNs and CNNs. Moreover, pruning the fully connected DNNs actuallyincreases the accuracy and decreases the variance for random initializations.Our numerics indicate that this enhancement in accuracy is due to thesimplification of the loss landscape. We next provide rigorous mathematicalunderpinning of these numerical results by proving the RMT-based PruningTheorem. Our results offer valuable insights into the practical application ofRMT for the creation of more efficient and accurate deep-learning models.</description><author>Leonid Berlyand, Etienne Sandier, Yitzchak Shmalo, Lei Zhang</author><pubDate>Mon, 09 Sep 2024 16:40:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03165v3</guid></item><item><title>DiffCSG: Differentiable CSG via Rasterization</title><link>http://arxiv.org/abs/2409.01421v2</link><description>Differentiable rendering is a key ingredient for inverse rendering andmachine learning, as it allows to optimize scene parameters (shape, materials,lighting) to best fit target images. Differentiable rendering requires thateach scene parameter relates to pixel values through differentiable operations.While 3D mesh rendering algorithms have been implemented in a differentiableway, these algorithms do not directly extend to Constructive-Solid-Geometry(CSG), a popular parametric representation of shapes, because the underlyingboolean operations are typically performed with complex black-boxmesh-processing libraries. We present an algorithm, DiffCSG, to render CSGmodels in a differentiable manner. Our algorithm builds upon CSG rasterization,which displays the result of boolean operations between primitives withoutexplicitly computing the resulting mesh and, as such, bypasses black-box meshprocessing. We describe how to implement CSG rasterization within adifferentiable rendering pipeline, taking special care to apply antialiasingalong primitive intersections to obtain gradients in such critical areas. Ouralgorithm is simple and fast, can be easily incorporated into modern machinelearning setups, and enables a range of applications for computer-aided design,including direct and image-based editing of CSG primitives. Code and data:https://yyyyyhc.github.io/DiffCSG/.</description><author>Haocheng Yuan, Adrien Bousseau, Hao Pan, Chengquan Zhang, Niloy J. Mitra, Changjian Li</author><pubDate>Mon, 09 Sep 2024 16:37:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.01421v2</guid></item><item><title>Creativity and Visual Communication from Machine to Musician: Sharing a Score through a Robotic Camera</title><link>http://arxiv.org/abs/2409.05773v1</link><description>This paper explores the integration of visual communication and musicalinteraction by implementing a robotic camera within a "Guided Harmony" musicalgame. We aim to examine co-creative behaviors between human musicians androbotic systems. Our research explores existing methodologies likeimprovisational game pieces and extends these concepts to include roboticparticipation using a PTZ camera. The robotic system interprets and responds tononverbal cues from musicians, creating a collaborative and adaptive musicalexperience. This initial case study underscores the importance of intuitivevisual communication channels. We also propose future research directions,including parameters for refining the visual cue toolkit and data collectionmethods to understand human-machine co-creativity further. Our findingscontribute to the broader understanding of machine intelligence in augmentinghuman creativity, particularly in musical settings.</description><author>Ross Greer, Laura Fleig, Shlomo Dubnov</author><pubDate>Mon, 09 Sep 2024 16:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05773v1</guid></item><item><title>Mixture of Experts with Mixture of Precisions for Tuning Quality of Service</title><link>http://arxiv.org/abs/2407.14417v2</link><description>The increasing demand for deploying large Mixture-of-Experts (MoE) models inresource-constrained environments necessitates efficient approaches to addresstheir high memory and computational requirements challenges. Moreover, giventhat tasks come in different user-defined constraints and the availableresources change over time in multi-tenant environments, it is necessary todesign an approach which provides a flexible configuration space. This paperpresents an adaptive serving approach for the efficient deployment of MoEmodels, capitalizing on partial quantization of the experts. By dynamicallydetermining the number of quantized experts and their distribution across CPUand GPU, our approach explores the Pareto frontier and offers a fine-grainedrange of configurations for tuning throughput and model quality. Our evaluationon an NVIDIA A100 GPU using a Mixtral 8x7B MoE model for three languagemodelling benchmarks demonstrates that the throughput of token generation canbe adjusted from 0.63 to 13.00 token per second. This enhancement comes with amarginal perplexity increase of 3.81 to 4.00, 13.59 to 14.17, and 7.24 to 7.40for WikiText2, PTB, and C4 datasets respectively under maximum quantization.These results highlight the practical applicability of our approach in dynamicand accuracy-sensitive applications where both memory usage and output qualityare important.</description><author>HamidReza Imani, Abdolah Amirany, Tarek El-Ghazawi</author><pubDate>Mon, 09 Sep 2024 16:34:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14417v2</guid></item><item><title>Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models</title><link>http://arxiv.org/abs/2409.05771v1</link><description>Research has repeatedly demonstrated that intermediate hidden statesextracted from large language models are able to predict measured brainresponse to natural language stimuli. Yet, very little is known about therepresentation properties that enable this high prediction performance. Why isit the intermediate layers, and not the output layers, that are most capablefor this unique and highly general transfer task? In this work, we show thatevidence from language encoding models in fMRI supports the existence of atwo-phase abstraction process within LLMs. We use manifold learning methods toshow that this abstraction process naturally arises over the course of traininga language model and that the first "composition" phase of this abstractionprocess is compressed into fewer layers as training continues. Finally, wedemonstrate a strong correspondence between layerwise encoding performance andthe intrinsic dimensionality of representations from LLMs. We give initialevidence that this correspondence primarily derives from the inherentcompositionality of LLMs and not their next-word prediction properties.</description><author>Emily Cheng, Richard J. Antonello</author><pubDate>Mon, 09 Sep 2024 16:33:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05771v1</guid></item><item><title>Consensus-based Distributed Quantum Kernel Learning for Speech Recognition</title><link>http://arxiv.org/abs/2409.05770v1</link><description>This paper presents a Consensus-based Distributed Quantum Kernel Learning(CDQKL) framework aimed at improving speech recognition through distributedquantum computing.CDQKL addresses the challenges of scalability and dataprivacy in centralized quantum kernel learning. It does this by distributingcomputational tasks across quantum terminals, which are connected throughclassical channels. This approach enables the exchange of model parameterswithout sharing local training data, thereby maintaining data privacy andenhancing computational efficiency. Experimental evaluations on benchmarkspeech emotion recognition datasets demonstrate that CDQKL achieves competitiveclassification accuracy and scalability compared to centralized and localquantum kernel learning models. The distributed nature of CDQKL offersadvantages in privacy preservation and computational efficiency, making itsuitable for data-sensitive fields such as telecommunications, automotive, andfinance. The findings suggest that CDQKL can effectively leverage distributedquantum computing for large-scale machine-learning tasks.</description><author>Kuan-Cheng Chen, Wenxuan Ma, Xiaotian Xu</author><pubDate>Mon, 09 Sep 2024 16:33:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05770v1</guid></item><item><title>Balancing Rigor and Utility: Mitigating Cognitive Biases in Large Language Models for Multiple-Choice Questions</title><link>http://arxiv.org/abs/2406.10999v3</link><description>This paper examines the role of cognitive biases in the decision-makingprocesses of large language models (LLMs), challenging the conventional goal ofeliminating all biases. We show that certain cognitive biases when properlybalanced, can enhance decision-making efficiency through rational deviationsand heuristic shortcuts. By introducing heuristic moderation and an abstentionoption, which allows LLMs to withhold responses when uncertain, we reduce errorrates, improve decision accuracy, and optimize decision rates. Using theBalance Rigor and Utility (BRU) dataset, developed through expertcollaboration, our findings demonstrate that targeted inspection of cognitivebiases aligns LLM decisions more closely with human reasoning, enhancingreliability and suggesting strategies for future improvements. This approachoffers a novel way to leverage cognitive biases to improve the practicalutility of LLMs across various applications.</description><author>Liman Wang, Hanyang Zhong, Wenting Cao, Zeyuan Sun</author><pubDate>Mon, 09 Sep 2024 16:28:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10999v3</guid></item><item><title>Prediction-Feedback DETR for Temporal Action Detection</title><link>http://arxiv.org/abs/2408.16729v2</link><description>Temporal Action Detection (TAD) is fundamental yet challenging for real-worldvideo applications. Leveraging the unique benefits of transformers, variousDETR-based approaches have been adopted in TAD. However, it has recently beenidentified that the attention collapse in self-attention causes the performancedegradation of DETR for TAD. Building upon previous research, this paper newlyaddresses the attention collapse problem in cross-attention within DETR-basedTAD methods. Moreover, our findings reveal that cross-attention exhibitspatterns distinct from predictions, indicating a short-cut phenomenon. Toresolve this, we propose a new framework, Prediction-Feedback DETR (Pred-DETR),which utilizes predictions to restore the collapse and align the cross- andself-attention with predictions. Specifically, we devise novelprediction-feedback objectives using guidance from the relations of thepredictions. As a result, Pred-DETR significantly alleviates the collapse andachieves state-of-the-art performance among DETR-based methods on variouschallenging benchmarks including THUMOS14, ActivityNet-v1.3, HACS, andFineAction.</description><author>Jihwan Kim, Miso Lee, Cheol-Ho Cho, Jihyun Lee, Jae-Pil Heo</author><pubDate>Mon, 09 Sep 2024 16:27:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.16729v2</guid></item><item><title>Deep Convolutional Autoencoder for Assessment of Drive-Cycle Anomalies in Connected Vehicle Sensor Data</title><link>http://arxiv.org/abs/2202.07592v3</link><description>This work investigates a practical and novel method for automatedunsupervised fault detection in vehicles using a fully convolutionalautoencoder. The results demonstrate the algorithm we developed can detectanomalies which correspond to powertrain faults by learning patterns in themultivariate time-series data of hybrid-electric vehicle powertrain sensors.Data was collected by engineers at Ford Motor Company from numerous sensorsover several drive cycle variations. This study provides evidence of theanomaly detecting capability of our trained autoencoder and investigates thesuitability of our autoencoder relative to other unsupervised methods forautomatic fault detection in this data set. Preliminary results of testing theautoencoder on the powertrain sensor data indicate the data reconstructionapproach availed by the autoencoder is a robust technique for identifying theabnormal sequences in the multivariate series. These results support thatirregularities in hybrid-electric vehicles' powertrains are conveyed via sensorsignals in the embedded electronic communication system, and therefore can beidentified mechanistically with a trained algorithm. Additional unsupervisedmethods are tested and show the autoencoder performs better at fault detectionthan outlier detectors and other novel deep learning techniques.</description><author>Anthony Geglio, Eisa Hedayati, Mark Tascillo, Dyche Anderson, Jonathan Barker, Timothy C. Havens</author><pubDate>Mon, 09 Sep 2024 16:18:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.07592v3</guid></item><item><title>3D Lymphoma Segmentation on PET/CT Images via Multi-Scale Information Fusion with Cross-Attention</title><link>http://arxiv.org/abs/2402.02349v2</link><description>Background: Accurate segmentation of diffuse large B-cell lymphoma (DLBCL)lesions is challenging due to their complex patterns in medical imaging. Objective: This study aims to develop a precise segmentation method for DLBCLusing 18F-Fluorodeoxyglucose (FDG) positron emission tomography (PET) andcomputed tomography (CT) images. Methods: We propose a 3D dual-branch encoder segmentation method usingshifted window transformers and a Multi-Scale Information Fusion (MSIF) module.To enhance feature integration, the MSIF module performs multi-scale featurefusion using cross-attention mechanisms with a shifted window framework. Agated neural network within the MSIF module dynamically balances thecontributions from each modality. The model was optimized using the DiceSimilarity Coefficient (DSC) loss function. Additionally, we computed the totalmetabolic tumor volume (TMTV) and performed statistical analyses. Results: The model was trained and validated on a dataset of 165 DLBCLpatients using 5-fold cross-validation, achieving a DSC of 0.7512. Statisticalanalysis showed a significant improvement over comparative methods (p &lt; 0.05).Additionally, a Pearson correlation coefficient of 0.91 and an R^2 of 0.89 wereobserved when comparing manual annotations to segmentation results for TMTVmeasurement. Conclusion: This study presents an effective automatic segmentation methodfor DLBCL that leverages the complementary strengths of PET and CT imaging. Ourmethod has the potential to improve diagnostic interpretations and assist intreatment planning for DLBCL patients.</description><author>Huan Huang, Liheng Qiu, Shenmiao Yang, Longxi Li, Jiaofen Nan, Yanting Li, Chuang Han, Fubao Zhu, Chen Zhao, Weihua Zhou</author><pubDate>Mon, 09 Sep 2024 16:17:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02349v2</guid></item><item><title>Long-term Pre-training for Temporal Action Detection with Transformers</title><link>http://arxiv.org/abs/2408.13152v2</link><description>Temporal action detection (TAD) is challenging, yet fundamental forreal-world video applications. Recently, DETR-based models for TAD have beenprevailing thanks to their unique benefits. However, transformers demand a hugedataset, and unfortunately data scarcity in TAD causes a severe degeneration.In this paper, we identify two crucial problems from data scarcity: attentioncollapse and imbalanced performance. To this end, we propose a new pre-trainingstrategy, Long-Term Pre-training (LTP), tailored for transformers. LTP has twomain components: 1) class-wise synthesis, 2) long-term pretext tasks. Firstly,we synthesize long-form video features by merging video snippets of a targetclass and non-target classes. They are analogous to untrimmed data used in TAD,despite being created from trimmed data. In addition, we devise two types oflong-term pretext tasks to learn long-term dependency. They impose long-termconditions such as finding second-to-fourth or short-duration actions. Ourextensive experiments show state-of-the-art performances in DETR-based methodson ActivityNet-v1.3 and THUMOS14 by a large margin. Moreover, we demonstratethat LTP significantly relieves the data scarcity issues in TAD.</description><author>Jihwan Kim, Miso Lee, Jae-Pil Heo</author><pubDate>Mon, 09 Sep 2024 16:16:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13152v2</guid></item><item><title>TivNe-SLAM: Dynamic Mapping and Tracking via Time-Varying Neural Radiance Fields</title><link>http://arxiv.org/abs/2310.18917v5</link><description>Previous attempts to integrate Neural Radiance Fields (NeRF) into theSimultaneous Localization and Mapping (SLAM) framework either rely on theassumption of static scenes or require the ground truth camera poses, whichimpedes their application in real-world scenarios. This paper proposes atime-varying representation to track and reconstruct the dynamic scenes.Firstly, two processes, a tracking process and a mapping process, aremaintained simultaneously in our framework. In the tracking process, all inputimages are uniformly sampled and then progressively trained in aself-supervised paradigm. In the mapping process, we leverage motion masks todistinguish dynamic objects from the static background, and sample more pixelsfrom dynamic areas. Secondly, the parameter optimization for both processes iscomprised of two stages: the first stage associates time with 3D positions toconvert the deformation field to the canonical field. The second stageassociates time with the embeddings of the canonical field to obtain colors anda Signed Distance Function (SDF). Lastly, we propose a novel keyframe selectionstrategy based on the overlapping rate. Our approach is evaluated on twosynthetic datasets and one real-world dataset, and the experiments validatethat our method achieves competitive results in both tracking and mapping whencompared to existing state-of-the-art NeRF-based dynamic SLAM systems.</description><author>Chengyao Duan, Zhiliu Yang</author><pubDate>Mon, 09 Sep 2024 16:16:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18917v5</guid></item><item><title>Kernel-U-Net: Multivariate Time Series Forecasting using Custom Kernels</title><link>http://arxiv.org/abs/2401.01479v3</link><description>Time series forecasting task predicts future trends based on historicalinformation. Transformer-based U-Net architectures, despite their success inmedical image segmentation, have limitations in both expressiveness andcomputation efficiency in time series forecasting as evidenced in YFormer. Totackle these challenges, we introduce Kernel-U-Net, a flexible andkernel-customizable U-shape neural network architecture. The kernel-U-Netencoder compresses the input series into latent vectors, and its symmetricdecoder subsequently expands these vectors into output series. Specifically,Kernel-U-Net separates the procedure of partitioning input time series intopatches from kernel manipulation, thereby providing the convenience ofcustomized executing kernels. Our method offers two primary advantages: 1)Flexibility in kernel customization to adapt to specific datasets; and 2)Enhanced computational efficiency, with the complexity of the Transformer layerreduced to linear. Experiments on seven real-world datasets, demonstrate thatKernel-U-Net's performance either exceeds or meets that of the existingstate-of-the-art model in the majority of cases in channel-independentsettings. The source code for Kernel-U-Net will be made publicly available forfurther research and application.</description><author>Jiang You, Arben Cela, René Natowicz, Jacob Ouanounou, Patrick Siarry</author><pubDate>Mon, 09 Sep 2024 16:12:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01479v3</guid></item><item><title>Are Heterophily-Specific GNNs and Homophily Metrics Really Effective? Evaluation Pitfalls and New Benchmarks</title><link>http://arxiv.org/abs/2409.05755v1</link><description>Over the past decade, Graph Neural Networks (GNNs) have achieved greatsuccess on machine learning tasks with relational data. However, recent studieshave found that heterophily can cause significant performance degradation ofGNNs, especially on node-level tasks. Numerous heterophilic benchmark datasetshave been put forward to validate the efficacy of heterophily-specific GNNs andvarious homophily metrics have been designed to help people recognize thesemalignant datasets. Nevertheless, there still exist multiple pitfalls thatseverely hinder the proper evaluation of new models and metrics. In this paper,we point out three most serious pitfalls: 1) a lack of hyperparameter tuning;2) insufficient model evaluation on the real challenging heterophilic datasets;3) missing quantitative evaluation benchmark for homophily metrics on syntheticgraphs. To overcome these challenges, we first train and fine-tune baselinemodels on $27$ most widely used benchmark datasets, categorize them into threedistinct groups: malignant, benign and ambiguous heterophilic datasets, andidentify the real challenging subsets of tasks. To our best knowledge, we arethe first to propose such taxonomy. Then, we re-evaluate $10$heterophily-specific state-of-the-arts (SOTA) GNNs with fine-tunedhyperparameters on different groups of heterophilic datasets. Based on themodel performance, we reassess their effectiveness on addressing heterophilychallenge. At last, we evaluate $11$ popular homophily metrics on syntheticgraphs with three different generation approaches. To compare the metricsstrictly, we propose the first quantitative evaluation method based onFr\'echet distance.</description><author>Sitao Luan, Qincheng Lu, Chenqing Hua, Xinyu Wang, Jiaqi Zhu, Xiao-Wen Chang, Guy Wolf, Jian Tang</author><pubDate>Mon, 09 Sep 2024 16:11:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05755v1</guid></item><item><title>ReL-SAR: Representation Learning for Skeleton Action Recognition with Convolutional Transformers and BYOL</title><link>http://arxiv.org/abs/2409.05749v1</link><description>To extract robust and generalizable skeleton action recognition features,large amounts of well-curated data are typically required, which is achallenging task hindered by annotation and computation costs. Therefore,unsupervised representation learning is of prime importance to leverageunlabeled skeleton data. In this work, we investigate unsupervisedrepresentation learning for skeleton action recognition. For this purpose, wedesigned a lightweight convolutional transformer framework, named ReL-SAR,exploiting the complementarity of convolutional and attention layers forjointly modeling spatial and temporal cues in skeleton sequences. We also use aSelection-Permutation strategy for skeleton joints to ensure more informativedescriptions from skeletal data. Finally, we capitalize on Bootstrap Your OwnLatent (BYOL) to learn robust representations from unlabeled skeleton sequencedata. We achieved very competitive results on limited-size datasets: MCAD,IXMAS, JHMDB, and NW-UCLA, showing the effectiveness of our proposed methodagainst state-of-the-art methods in terms of both performance and computationalefficiency. To ensure reproducibility and reusability, the source codeincluding all implementation parameters is provided at:https://github.com/SafwenNaimi/Representation-Learning-for-Skeleton-Action-Recognition-with-Convolutional-Transformers-and-BYOL</description><author>Safwen Naimi, Wassim Bouachir, Guillaume-Alexandre Bilodeau</author><pubDate>Mon, 09 Sep 2024 16:03:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05749v1</guid></item><item><title>A Novel Idea Generation Tool using a Structured Conversational AI (CAI) System</title><link>http://arxiv.org/abs/2409.05747v1</link><description>This paper presents a novel conversational AI-enabled active ideationinterface as a creative idea-generation tool to assist novice designers inmitigating the initial latency and ideation bottlenecks that are commonlyobserved. It is a dynamic, interactive, and contextually responsive approach,actively involving a large language model (LLM) from the domain of naturallanguage processing (NLP) in artificial intelligence (AI) to produce multiplestatements of potential ideas for different design problems. Integrating suchAI models with ideation creates what we refer to as an Active Ideationscenario, which helps foster continuous dialogue-based interaction,context-sensitive conversation, and prolific idea generation. A pilot study wasconducted with thirty novice designers to generate ideas for given problemsusing traditional methods and the new CAI-based interface. The key parametersof fluency, novelty, and variety were used to compare the outcomesqualitatively by a panel of experts. The findings demonstrated theeffectiveness of the proposed tool for generating prolific, diverse and novelideas. The interface was enhanced by incorporating a prompt-engineeredstructured dialogue style for each ideation stage to make it uniform and moreconvenient for the designers. The resulting responses of such a structured CAIinterface were found to be more succinct and aligned towards the subsequentdesign stage, namely conceptualization. The paper thus established the richpotential of using Generative AI (Gen-AI) for the early ill-structured phase ofthe creative product design process.</description><author>B. Sankar, Dibakar Sen</author><pubDate>Mon, 09 Sep 2024 16:02:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05747v1</guid></item><item><title>LLMs Will Always Hallucinate, and We Need to Live With This</title><link>http://arxiv.org/abs/2409.05746v1</link><description>As Large Language Models become more ubiquitous across domains, it becomesimportant to examine their inherent limitations critically. This work arguesthat hallucinations in language models are not just occasional errors but aninevitable feature of these systems. We demonstrate that hallucinations stemfrom the fundamental mathematical and logical structure of LLMs. It is,therefore, impossible to eliminate them through architectural improvements,dataset enhancements, or fact-checking mechanisms. Our analysis draws oncomputational theory and Godel's First Incompleteness Theorem, which referencesthe undecidability of problems like the Halting, Emptiness, and AcceptanceProblems. We demonstrate that every stage of the LLM process-from training datacompilation to fact retrieval, intent classification, and text generation-willhave a non-zero probability of producing hallucinations. This work introducesthe concept of Structural Hallucination as an intrinsic nature of thesesystems. By establishing the mathematical certainty of hallucinations, wechallenge the prevailing notion that they can be fully mitigated.</description><author>Sourav Banerjee, Ayushi Agarwal, Saloni Singla</author><pubDate>Mon, 09 Sep 2024 16:01:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05746v1</guid></item><item><title>X-InstructBLIP: A Framework for aligning X-Modal instruction-aware representations to LLMs and Emergent Cross-modal Reasoning</title><link>http://arxiv.org/abs/2311.18799v2</link><description>Recent research has achieved significant advancements in visual reasoningtasks through learning image-to-language projections and leveraging theimpressive reasoning abilities of Large Language Models (LLMs). This paperintroduces an efficient and effective framework that integrates multiplemodalities (images, 3D, audio and video) to a frozen LLM and demonstrates anemergent ability for cross-modal reasoning (2+ modality inputs). Our approachexplores two distinct projection mechanisms: Q-Formers and Linear Projections(LPs). Through extensive experimentation across all four modalities on 16benchmarks, we explore both methods and assess their adaptability in integratedand separate cross-modal reasoning. The Q-Former projection demonstratessuperior performance in single modality scenarios and adaptability in jointversus discriminative reasoning involving two or more modalities. However, itexhibits lower generalization capabilities than linear projection in contextswhere task-modality data are limited. To enable this framework, we devise ascalable pipeline that automatically generates high-quality, instruction-tuningdatasets from readily available captioning data across different modalities,and contribute 24K QA data for audio and 250K QA data for 3D. To facilitatefurther research in cross-modal reasoning, we introduce the DisCRn(Discriminative Cross-modal Reasoning) benchmark comprising 9K audio-video QAsamples and 28K image-3D QA samples that require the model to reasondiscriminatively across disparate input modalities.</description><author>Artemis Panagopoulou, Le Xue, Ning Yu, Junnan Li, Dongxu Li, Shafiq Joty, Ran Xu, Silvio Savarese, Caiming Xiong, Juan Carlos Niebles</author><pubDate>Mon, 09 Sep 2024 16:00:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.18799v2</guid></item><item><title>PanoSent: A Panoptic Sextuple Extraction Benchmark for Multimodal Conversational Aspect-based Sentiment Analysis</title><link>http://arxiv.org/abs/2408.09481v2</link><description>While existing Aspect-based Sentiment Analysis (ABSA) has received extensiveeffort and advancement, there are still gaps in defining a more holisticresearch target seamlessly integrating multimodality, conversation context,fine-granularity, and also covering the changing sentiment dynamics as well ascognitive causal rationales. This paper bridges the gaps by introducing amultimodal conversational ABSA, where two novel subtasks are proposed: 1)Panoptic Sentiment Sextuple Extraction, panoramically recognizing holder,target, aspect, opinion, sentiment, rationale from multi-turn multi-partymultimodal dialogue. 2) Sentiment Flipping Analysis, detecting the dynamicsentiment transformation throughout the conversation with the causal reasons.To benchmark the tasks, we construct PanoSent, a dataset annotated bothmanually and automatically, featuring high quality, large scale, multimodality,multilingualism, multi-scenarios, and covering both implicit and explicitsentiment elements. To effectively address the tasks, we devise a novelChain-of-Sentiment reasoning framework, together with a novel multimodal largelanguage model (namely Sentica) and a paraphrase-based verification mechanism.Extensive evaluations demonstrate the superiority of our methods over strongbaselines, validating the efficacy of all our proposed methods. The work isexpected to open up a new era for the ABSA community, and thus all our codesand data are open at https://PanoSent.github.io/</description><author>Meng Luo, Hao Fei, Bobo Li, Shengqiong Wu, Qian Liu, Soujanya Poria, Erik Cambria, Mong-Li Lee, Wynne Hsu</author><pubDate>Mon, 09 Sep 2024 15:57:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09481v2</guid></item><item><title>Robust Loss Functions for Object Grasping under Limited Ground Truth</title><link>http://arxiv.org/abs/2409.05742v1</link><description>Object grasping is a crucial technology enabling robots to perceive andinteract with the environment sufficiently. However, in practical applications,researchers are faced with missing or noisy ground truth while training theconvolutional neural network, which decreases the accuracy of the model.Therefore, different loss functions are proposed to deal with these problems toimprove the accuracy of the neural network. For missing ground truth, a newpredicted category probability method is defined for unlabeled samples, whichworks effectively in conjunction with the pseudo-labeling method. Furthermore,for noisy ground truth, a symmetric loss function is introduced to resist thecorruption of label noises. The proposed loss functions are powerful, robust,and easy to use. Experimental results based on the typical grasping neuralnetwork show that our method can improve performance by 2 to 13 percent.</description><author>Yangfan Deng, Mengyao Zhang, Yong Zhao</author><pubDate>Mon, 09 Sep 2024 15:56:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05742v1</guid></item><item><title>The Influence of Faulty Labels in Data Sets on Human Pose Estimation</title><link>http://arxiv.org/abs/2409.03887v2</link><description>In this study we provide empirical evidence demonstrating that the quality oftraining data impacts model performance in Human Pose Estimation (HPE).Inaccurate labels in widely used data sets, ranging from minor errors to severemislabeling, can negatively influence learning and distort performance metrics.We perform an in-depth analysis of popular HPE data sets to show the extent andnature of label inaccuracies. Our findings suggest that accounting for theimpact of faulty labels will facilitate the development of more robust andaccurate HPE models for a variety of real-world applications. We show improvedperformance with cleansed data.</description><author>Arnold Schwarz, Levente Hernadi, Felix Bießmann, Kristian Hildebrand</author><pubDate>Mon, 09 Sep 2024 15:53:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.03887v2</guid></item><item><title>QEDCartographer: Automating Formal Verification Using Reward-Free Reinforcement Learning</title><link>http://arxiv.org/abs/2408.09237v4</link><description>Formal verification is a promising method for producing reliable software,but the difficulty of manually writing verification proofs severely limits itsutility in practice. Recent methods have automated some proof synthesis byguiding a search through the proof space using a theorem prover. Unfortunately,the theorem prover provides only the crudest estimate of progress, resulting ineffectively undirected search. To address this problem, we createQEDCartographer, an automated proof-synthesis tool that combines supervised andreinforcement learning to more effectively explore the proof space.QEDCartographer incorporates the proofs' branching structure, enablingreward-free search and overcoming the sparse reward problem inherent to formalverification. We evaluate QEDCartographer using the CoqGym benchmark of 68.5Ktheorems from 124 open-source Coq projects. QEDCartographer fully automaticallyproves 21.4% of the test-set theorems. Previous search-based proof-synthesistools Tok, Tac, ASTactic, Passport, and Proverbot9001, which rely only onsupervised learning, prove 9.6%, 9.8%, 10.9%, 12.5%, and 19.8%, respectively.Diva, which combines 62 tools, proves 19.2%. Comparing to the most effectiveprior tool, Proverbot9001, QEDCartographer produces 34% shorter proofs 29%faster, on average over the theorems both tools prove. Together,QEDCartographer and non-learning-based CoqHammer prove 30.3% of the theorems,while CoqHammer alone proves 26.6%. Our work demonstrates that reinforcementlearning is a fruitful research direction for improving proof-synthesis tools'search mechanisms.</description><author>Alex Sanchez-Stern, Abhishek Varghese, Zhanna Kaufman, Dylan Zhang, Talia Ringer, Yuriy Brun</author><pubDate>Mon, 09 Sep 2024 15:51:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09237v4</guid></item><item><title>A System and Benchmark for LLM-based Q\&amp;A on Heterogeneous Data</title><link>http://arxiv.org/abs/2409.05735v1</link><description>In many industrial settings, users wish to ask questions whose answers may befound in structured data sources such as a spreadsheets, databases, APIs, orcombinations thereof. Often, the user doesn't know how to identify or accessthe right data source. This problem is compounded even further if multiple (andpotentially siloed) data sources must be assembled to derive the answer.Recently, various Text-to-SQL applications that leverage Large Language Models(LLMs) have addressed some of these problems by enabling users to ask questionsin natural language. However, these applications remain impractical inrealistic industrial settings because they fail to cope with the data sourceheterogeneity that typifies such environments. In this paper, we addressheterogeneity by introducing the siwarex platform, which enables seamlessnatural language access to both databases and APIs. To demonstrate theeffectiveness of siwarex, we extend the popular Spider dataset and benchmark byreplacing some of its tables by data retrieval APIs. We find that siwarex doesa good job of coping with data source heterogeneity. Our modified Spiderbenchmark will soon be available to the research community</description><author>Achille Fokoue, Srideepika Jayaraman, Elham Khabiri, Jeffrey O. Kephart, Yingjie Li, Dhruv Shah, Youssef Drissi, Fenno F. Heath III, Anu Bhamidipaty, Fateh A. Tipu, Robert J. Baseman</author><pubDate>Mon, 09 Sep 2024 15:44:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05735v1</guid></item><item><title>Markov Chain Variance Estimation: A Stochastic Approximation Approach</title><link>http://arxiv.org/abs/2409.05733v1</link><description>We consider the problem of estimating the asymptotic variance of a functiondefined on a Markov chain, an important step for statistical inference of thestationary mean. We design the first recursive estimator that requires $O(1)$computation at each step, does not require storing any historical samples orany prior knowledge of run-length, and has optimal $O(\frac{1}{n})$ rate ofconvergence for the mean-squared error (MSE) with provable finite sampleguarantees. Here, $n$ refers to the total number of samples generated. Thepreviously best-known rate of convergence in MSE was $O(\frac{\log n}{n})$,achieved by jackknifed estimators, which also do not enjoy these otherdesirable properties. Our estimator is based on linear stochastic approximationof an equivalent formulation of the asymptotic variance in terms of thesolution of the Poisson equation. We generalize our estimator in several directions, including estimating thecovariance matrix for vector-valued functions, estimating the stationaryvariance of a Markov chain, and approximately estimating the asymptoticvariance in settings where the state space of the underlying Markov chain islarge. We also show applications of our estimator in average rewardreinforcement learning (RL), where we work with asymptotic variance as a riskmeasure to model safety-critical applications. We design a temporal-differencetype algorithm tailored for policy evaluation in this context. We consider boththe tabular and linear function approximation settings. Our work paves the wayfor developing actor-critic style algorithms for variance-constrained RL.</description><author>Shubhada Agrawal, Prashanth L. A., Siva Theja Maguluri</author><pubDate>Mon, 09 Sep 2024 15:42:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05733v1</guid></item><item><title>Towards Democratizing Multilingual Large Language Models For Medicine Through A Two-Stage Instruction Fine-tuning Approach</title><link>http://arxiv.org/abs/2409.05732v1</link><description>Open-source, multilingual medical large language models (LLMs) have thepotential to serve linguistically diverse populations across different regions.Adapting generic LLMs for healthcare often requires continual pretraining, butthis approach is computationally expensive and sometimes impractical.Instruction fine-tuning on a specific task may not always guarantee optimalperformance due to the lack of broader domain knowledge that the model needs tounderstand and reason effectively in diverse scenarios. To address thesechallenges, we introduce two multilingual instruction fine-tuning datasets,MMed-IFT and MMed-IFT-MC, containing over 200k high-quality medical samples insix languages. We propose a two-stage training paradigm: the first stageinjects general medical knowledge using MMed-IFT, while the second stagefine-tunes task-specific multiple-choice questions with MMed-IFT-MC. Our methodachieves competitive results on both English and multilingual benchmarks,striking a balance between computational efficiency and performance. We plan tomake our dataset and model weights public at\url{https://github.com/SpassMed/Med-Llama3} in the future.</description><author>Meng Zhou, Surajsinh Parmar, Anubhav Bhatti</author><pubDate>Mon, 09 Sep 2024 15:42:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05732v1</guid></item><item><title>What Did My Car Say? Autonomous Vehicle Explanation Errors, Context, and Personal Traits Impact Comfort, Reliance, Satisfaction, and Driving Confidence</title><link>http://arxiv.org/abs/2409.05731v1</link><description>Explanations for autonomous vehicle (AV) decisions may build trust, however,explanations can contain errors. In a simulated driving study (n = 232), wetested how AV explanation errors, driving context characteristics (perceivedharm and driving difficulty), and personal traits (prior trust and expertise)affected a passenger's comfort in relying on an AV, preference for control,confidence in the AV's ability, and explanation satisfaction. Errors negativelyaffected all outcomes. Surprisingly, despite identical driving, explanationerrors reduced ratings of the AV's driving ability. Severity and potential harmamplified the negative impact of errors. Contextual harm and driving difficultydirectly impacted outcome ratings and influenced the relationship betweenerrors and outcomes. Prior trust and expertise were positively associated withoutcome ratings. Results emphasize the need for accurate, contextuallyadaptive, and personalized AV explanations to foster trust, reliance,satisfaction, and confidence. We conclude with design, research, and deploymentrecommendations for trustworthy AV explanation systems.</description><author>Robert Kaufman, Aaron Broukhim, David Kirsh, Nadir Weibel</author><pubDate>Mon, 09 Sep 2024 15:41:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05731v1</guid></item><item><title>Exploiting the Vulnerability of Large Language Models via Defense-Aware Architectural Backdoor</title><link>http://arxiv.org/abs/2409.01952v2</link><description>Deep neural networks (DNNs) have long been recognized as vulnerable tobackdoor attacks. By providing poisoned training data in the fine-tuningprocess, the attacker can implant a backdoor into the victim model. Thisenables input samples meeting specific textual trigger patterns to beclassified as target labels of the attacker's choice. While such black-boxattacks have been well explored in both computer vision and natural languageprocessing (NLP), backdoor attacks relying on white-box attack philosophy havehardly been thoroughly investigated. In this paper, we take the first step tointroduce a new type of backdoor attack that conceals itself within theunderlying model architecture. Specifically, we propose to design separatebackdoor modules consisting of two functions: trigger detection and noiseinjection. The add-on modules of model architecture layers can detect thepresence of input trigger tokens and modify layer weights using Gaussian noiseto disturb the feature distribution of the baseline model. We conduct extensiveexperiments to evaluate our attack methods using two model architecturesettings on five different large language datasets. We demonstrate that thetraining-free architectural backdoor on a large language model poses a genuinethreat. Unlike the-state-of-art work, it can survive the rigorous fine-tuningand retraining process, as well as evade output probability-based defensemethods (i.e. BDDR). All the code and data is availablehttps://github.com/SiSL-URI/Arch_Backdoor_LLM.</description><author>Abdullah Arafat Miah, Yu Bi</author><pubDate>Mon, 09 Sep 2024 15:37:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.01952v2</guid></item><item><title>Referring Expression Generation in Visually Grounded Dialogue with Discourse-aware Comprehension Guiding</title><link>http://arxiv.org/abs/2409.05721v1</link><description>We propose an approach to referring expression generation (REG) in visuallygrounded dialogue that is meant to produce referring expressions (REs) that areboth discriminative and discourse-appropriate. Our method constitutes atwo-stage process. First, we model REG as a text- and image-conditionednext-token prediction task. REs are autoregressively generated based on theirpreceding linguistic context and a visual representation of the referent.Second, we propose the use of discourse-aware comprehension guiding as part ofa generate-and-rerank strategy through which candidate REs generated with ourREG model are reranked based on their discourse-dependent discriminatory power.Results from our human evaluation indicate that our proposed two-stage approachis effective in producing discriminative REs, with higher performance in termsof text-image retrieval accuracy for reranked REs compared to those generatedusing greedy decoding.</description><author>Bram Willemsen, Gabriel Skantze</author><pubDate>Mon, 09 Sep 2024 15:33:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05721v1</guid></item><item><title>Real-time optimal control of high-dimensional parametrized systems by deep learning-based reduced order models</title><link>http://arxiv.org/abs/2409.05709v1</link><description>Steering a system towards a desired target in a very short amount of time ischallenging from a computational standpoint. Indeed, the intrinsicallyiterative nature of optimal control problems requires multiple simulations ofthe physical system to be controlled. Moreover, the control action needs to beupdated whenever the underlying scenario undergoes variations. Full-ordermodels based on, e.g., the Finite Element Method, do not meet theserequirements due to the computational burden they usually entail. On the otherhand, conventional reduced order modeling techniques such as the Reduced Basismethod, are intrusive, rely on a linear superimposition of modes, and lack ofefficiency when addressing nonlinear time-dependent dynamics. In this work, wepropose a non-intrusive Deep Learning-based Reduced Order Modeling (DL-ROM)technique for the rapid control of systems described in terms of parametrizedPDEs in multiple scenarios. In particular, optimal full-order snapshots aregenerated and properly reduced by either Proper Orthogonal Decomposition ordeep autoencoders (or a combination thereof) while feedforward neural networksare exploited to learn the map from scenario parameters to reduced optimalsolutions. Nonlinear dimensionality reduction therefore allows us to considerstate variables and control actions that are both low-dimensional anddistributed. After (i) data generation, (ii) dimensionality reduction, and(iii) neural networks training in the offline phase, optimal control strategiescan be rapidly retrieved in an online phase for any scenario of interest. Thecomputational speedup and the high accuracy obtained with the proposed approachare assessed on different PDE-constrained optimization problems, ranging fromthe minimization of energy dissipation in incompressible flows modelled throughNavier-Stokes equations to the thermal active cooling in heat transfer.</description><author>Matteo Tomasetto, Andrea Manzoni, Francesco Braghin</author><pubDate>Mon, 09 Sep 2024 15:20:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05709v1</guid></item><item><title>pFedGPA: Diffusion-based Generative Parameter Aggregation for Personalized Federated Learning</title><link>http://arxiv.org/abs/2409.05701v1</link><description>Federated Learning (FL) offers a decentralized approach to model training,where data remains local and only model parameters are shared between theclients and the central server. Traditional methods, such as FederatedAveraging (FedAvg), linearly aggregate these parameters which are usuallytrained on heterogeneous data distributions, potentially overlooking thecomplex, high-dimensional nature of the parameter space. This can result indegraded performance of the aggregated model. While personalized FL approachescan mitigate the heterogeneous data issue to some extent, the limitation oflinear aggregation remains unresolved. To alleviate this issue, we investigatethe generative approach of diffusion model and propose a novel generativeparameter aggregation framework for personalized FL, \texttt{pFedGPA}. In thisframework, we deploy a diffusion model on the server to integrate the diverseparameter distributions and propose a parameter inversion method to efficientlygenerate a set of personalized parameters for each client. This inversionmethod transforms the uploaded parameters into a latent code, which is thenaggregated through denoising sampling to produce the final personalizedparameters. By encoding the dependence of a client's model parameters on thespecific data distribution using the high-capacity diffusion model,\texttt{pFedGPA} can effectively decouple the complexity of the overalldistribution of all clients' model parameters from the complexity of eachindividual client's parameter distribution. Our experimental resultsconsistently demonstrate the superior performance of the proposed method acrossmultiple datasets, surpassing baseline approaches.</description><author>Jiahao Lai, Jiaqi Li, Jian Xu, Yanru Wu, Boshi Tang, Siqi Chen, Yongfeng Huang, Wenbo Ding, Yang Li</author><pubDate>Mon, 09 Sep 2024 15:13:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05701v1</guid></item><item><title>Boosting CNN-based Handwriting Recognition Systems with Learnable Relaxation Labeling</title><link>http://arxiv.org/abs/2409.05699v1</link><description>The primary challenge for handwriting recognition systems lies in managinglong-range contextual dependencies, an issue that traditional models oftenstruggle with. To mitigate it, attention mechanisms have recently been employedto enhance context-aware labelling, thereby achieving state-of-the-artperformance. In the field of pattern recognition and image analysis, however,the use of contextual information in labelling problems has a long history andgoes back at least to the early 1970's. Among the various approaches developedin those years, Relaxation Labelling (RL) processes have played a prominentrole and have been the method of choice in the field for more than a decade.Contrary to recent transformer-based architectures, RL processes offer aprincipled approach to the use of contextual constraints, having a solidtheoretic foundation grounded on variational inequality and game theory, aswell as effective algorithms with convergence guarantees. In this paper, wepropose a novel approach to handwriting recognition that integrates thestrengths of two distinct methodologies. In particular, we propose integrating(trainable) RL processes with various well-established neural architectures andwe introduce a sparsification technique that accelerates the convergence of thealgorithm and enhances the overall system's performance. Experiments overseveral benchmark datasets show that RL processes can improve thegeneralisation ability, even surpassing in some cases transformer-basedarchitectures.</description><author>Sara Ferro, Alessandro Torcinovich, Arianna Traviglia, Marcello Pelillo</author><pubDate>Mon, 09 Sep 2024 15:12:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05699v1</guid></item><item><title>MANA-Net: Mitigating Aggregated Sentiment Homogenization with News Weighting for Enhanced Market Prediction</title><link>http://arxiv.org/abs/2409.05698v1</link><description>It is widely acknowledged that extracting market sentiments from news databenefits market predictions. However, existing methods of using financialsentiments remain simplistic, relying on equal-weight and static aggregation tomanage sentiments from multiple news items. This leads to a critical issuetermed ``Aggregated Sentiment Homogenization'', which has been explored throughour analysis of a large financial news dataset from industry practice. Thisphenomenon occurs when aggregating numerous sentiments, causing representationsto converge towards the mean values of sentiment distributions and therebysmoothing out unique and important information. Consequently, the aggregatedsentiment representations lose much predictive value of news data. To addressthis problem, we introduce the Market Attention-weighted News AggregationNetwork (MANA-Net), a novel method that leverages a dynamic market-newsattention mechanism to aggregate news sentiments for market prediction.MANA-Net learns the relevance of news sentiments to price changes and assignsvarying weights to individual news items. By integrating the news aggregationstep into the networks for market prediction, MANA-Net allows for trainablesentiment representations that are optimized directly for prediction. Weevaluate MANA-Net using the S&amp;P 500 and NASDAQ 100 indices, along withfinancial news spanning from 2003 to 2018. Experimental results demonstratethat MANA-Net outperforms various recent market prediction methods, enhancingProfit &amp; Loss by 1.1% and the daily Sharpe ratio by 0.252.</description><author>Mengyu Wang, Tiejun Ma</author><pubDate>Mon, 09 Sep 2024 15:12:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05698v1</guid></item><item><title>Segmentation by Factorization: Unsupervised Semantic Segmentation for Pathology by Factorizing Foundation Model Features</title><link>http://arxiv.org/abs/2409.05697v1</link><description>We introduce Segmentation by Factorization (F-SEG), an unsupervisedsegmentation method for pathology that generates segmentation masks frompre-trained deep learning models. F-SEG allows the use of pre-trained deepneural networks, including recently developed pathology foundation models, forsemantic segmentation. It achieves this without requiring additional trainingor finetuning, by factorizing the spatial features extracted by the models intosegmentation masks and their associated concept features. We create generictissue phenotypes for H&amp;E images by training clustering models for multiplenumbers of clusters on features extracted from several deep learning models onThe Cancer Genome Atlas Program (TCGA), and then show how the clusters can beused for factorizing corresponding segmentation masks using off-the-shelf deeplearning models. Our results show that F-SEG provides robust unsupervisedsegmentation capabilities for H&amp;E pathology images, and that the segmentationquality is greatly improved by utilizing pathology foundation models. Wediscuss and propose methods for evaluating the performance of unsupervisedsegmentation in pathology.</description><author>Jacob Gildenblat, Ofir Hadar</author><pubDate>Mon, 09 Sep 2024 15:11:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05697v1</guid></item><item><title>HiSC4D: Human-centered interaction and 4D Scene Capture in Large-scale Space Using Wearable IMUs and LiDAR</title><link>http://arxiv.org/abs/2409.04398v2</link><description>We introduce HiSC4D, a novel Human-centered interaction and 4D Scene Capturemethod, aimed at accurately and efficiently creating a dynamic digital world,containing large-scale indoor-outdoor scenes, diverse human motions, richhuman-human interactions, and human-environment interactions. By utilizingbody-mounted IMUs and a head-mounted LiDAR, HiSC4D can capture egocentric humanmotions in unconstrained space without the need for external devices andpre-built maps. This affords great flexibility and accessibility forhuman-centered interaction and 4D scene capturing in various environments.Taking into account that IMUs can capture human spatially unrestricted posesbut are prone to drifting for long-period using, and while LiDAR is stable forglobal localization but rough for local positions and orientations, HiSC4Demploys a joint optimization method, harmonizing all sensors and utilizingenvironment cues, yielding promising results for long-term capture in largescenes. To promote research of egocentric human interaction in large scenes andfacilitate downstream tasks, we also present a dataset, containing 8 sequencesin 4 large scenes (200 to 5,000 $m^2$), providing 36k frames of accurate 4Dhuman motions with SMPL annotations and dynamic scenes, 31k frames of croppedhuman point clouds, and scene mesh of the environment. A variety of scenarios,such as the basketball gym and commercial street, alongside challenging humanmotions, such as daily greeting, one-on-one basketball playing, and tourguiding, demonstrate the effectiveness and the generalization ability ofHiSC4D. The dataset and code will be publicated onwww.lidarhumanmotion.net/hisc4d available for research purposes.</description><author>Yudi Dai, Zhiyong Wang, Xiping Lin, Chenglu Wen, Lan Xu, Siqi Shen, Yuexin Ma, Cheng Wang</author><pubDate>Mon, 09 Sep 2024 15:08:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.04398v2</guid></item><item><title>Extracting the U.S. building types from OpenStreetMap data</title><link>http://arxiv.org/abs/2409.05692v1</link><description>Building type information is crucial for population estimation, trafficplanning, urban planning, and emergency response applications. Althoughessential, such data is often not readily available. To alleviate this problem,this work creates a comprehensive dataset by providingresidential/non-residential building classification covering the entire UnitedStates. We propose and utilize an unsupervised machine learning method toclassify building types based on building footprints and availableOpenStreetMap information. The classification result is validated usingauthoritative ground truth data for select counties in the U.S. The validationshows a high precision for non-residential building classification and a highrecall for residential buildings. We identified various approaches to improvingthe quality of the classification, such as removing sheds and garages from thedataset. Furthermore, analyzing the misclassifications revealed that they aremainly due to missing and scarce metadata in OSM. A major result of this workis the resulting dataset of classifying 67,705,475 buildings. We hope that thisdata is of value to the scientific community, including urban andtransportation planners.</description><author>Henrique F. de Arruda, Sandro M. Reia, Shiyang Ruan, Kuldip S. Atwal, Hamdi Kavak, Taylor Anderson, Dieter Pfoser</author><pubDate>Mon, 09 Sep 2024 15:05:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05692v1</guid></item><item><title>Large Language Models Synergize with Automated Machine Learning</title><link>http://arxiv.org/abs/2405.03727v3</link><description>Recently, program synthesis driven by large language models (LLMs) has becomeincreasingly popular. However, program synthesis for machine learning (ML)tasks still poses significant challenges. This paper explores a novel form ofprogram synthesis, targeting ML programs, by combining LLMs and automatedmachine learning (autoML). Specifically, our goal is to fully automate thegeneration and optimization of the code of the entire ML workflow, from datapreparation to modeling and post-processing, utilizing only textualdescriptions of the ML tasks. To manage the length and diversity of MLprograms, we propose to break each ML program into smaller, manageable parts.Each part is generated separately by the LLM, with careful consideration oftheir compatibilities. To ensure compatibilities, we design a testing techniquefor ML programs. Unlike traditional program synthesis, which typically relieson binary evaluations (i.e., correct or incorrect), evaluating ML programsnecessitates more than just binary judgments. Our approach automates thenumerical evaluation and optimization of these programs, selecting the bestcandidates through autoML techniques. In experiments across various ML tasks,our method outperforms existing methods in 10 out of 12 tasks for generating MLprograms. In addition, autoML significantly improves the performance of thegenerated ML programs. In experiments, given the textual task description, ourmethod, Text-to-ML, generates the complete and optimized ML program in a fullyautonomous process. The implementation of our method is available athttps://github.com/JLX0/llm-automl.</description><author>Jinglue Xu, Jialong Li, Zhen Liu, Nagar Anthel Venkatesh Suryanarayanan, Guoyuan Zhou, Jia Guo, Hitoshi Iba, Kenji Tei</author><pubDate>Mon, 09 Sep 2024 15:04:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03727v3</guid></item><item><title>LayeredFlow: A Real-World Benchmark for Non-Lambertian Multi-Layer Optical Flow</title><link>http://arxiv.org/abs/2409.05688v1</link><description>Achieving 3D understanding of non-Lambertian objects is an important taskwith many useful applications, but most existing algorithms struggle to dealwith such objects. One major obstacle towards progress in this field is thelack of holistic non-Lambertian benchmarks -- most benchmarks have low sceneand object diversity, and none provide multi-layer 3D annotations for objectsoccluded by transparent surfaces. In this paper, we introduce LayeredFlow, areal world benchmark containing multi-layer ground truth annotation for opticalflow of non-Lambertian objects. Compared to previous benchmarks, our benchmarkexhibits greater scene and object diversity, with 150k high quality opticalflow and stereo pairs taken over 185 indoor and outdoor scenes and 360 uniqueobjects. Using LayeredFlow as evaluation data, we propose a new task calledmulti-layer optical flow. To provide training data for this task, we introducea large-scale densely-annotated synthetic dataset containing 60k images within30 scenes tailored for non-Lambertian objects. Training on our syntheticdataset enables model to predict multi-layer optical flow, while fine-tuningexisting optical flow methods on the dataset notably boosts their performanceon non-Lambertian objects without compromising the performance on diffuseobjects. Data is available at https://layeredflow.cs.princeton.edu.</description><author>Hongyu Wen, Erich Liang, Jia Deng</author><pubDate>Mon, 09 Sep 2024 15:01:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05688v1</guid></item><item><title>The Principle of Uncertain Maximum Entropy</title><link>http://arxiv.org/abs/2305.09868v3</link><description>The principle of maximum entropy is a well-established technique for choosinga distribution that matches available information while minimizing bias. Itfinds broad use across scientific disciplines and in machine learning. However,the principle as defined by is susceptible to noise and error in observations.This forces real-world practitioners to use relaxed versions of the principlein an ad hoc way, negatively impacting interpretation. To address thissituation, we present a new principle we call uncertain maximum entropy thatgeneralizes the classic principle and provides interpretable solutionsirrespective of the observational methods in use. We introduce a convexapproximation and expectation-maximization based algorithm for findingsolutions to our new principle. Finally, we contrast this new technique withtwo simpler generally applicable solutions theoretically and experimentallyshow our technique provides superior accuracy.</description><author>Kenneth Bogert, Matthew Kothe</author><pubDate>Mon, 09 Sep 2024 15:00:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09868v3</guid></item><item><title>Adaptive Online Learning of Quantum States</title><link>http://arxiv.org/abs/2206.00220v2</link><description>The problem of efficient quantum state learning, also called shadowtomography, aims to comprehend an unknown $d$-dimensional quantum state throughPOVMs. Yet, these states are rarely static; they evolve due to factors such asmeasurements, environmental noise, or inherent Hamiltonian state transitions.This paper leverages techniques from adaptive online learning to keep pace withsuch state changes. The key metrics considered for learning in these mutable environments areenhanced notions of regret, specifically adaptive and dynamic regret. Wepresent adaptive and dynamic regret bounds for online shadow tomography, whichare polynomial in the number of qubits and sublinear in the number ofmeasurements. To support our theoretical findings, we include numericalexperiments that validate our proposed models.</description><author>Xinyi Chen, Elad Hazan, Tongyang Li, Zhou Lu, Xinzhao Wang, Rui Yang</author><pubDate>Mon, 09 Sep 2024 14:56:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.00220v2</guid></item><item><title>Auto-ACD: A Large-scale Dataset for Audio-Language Representation Learning</title><link>http://arxiv.org/abs/2309.11500v4</link><description>Recently, the AI community has made significant strides in developingpowerful foundation models, driven by large-scale multimodal datasets. However,for audio representation learning, existing datasets suffer from limitations inthe following aspects: insufficient volume, simplistic content, and arduouscollection procedures. To establish an audio dataset with high-qualitycaptions, we propose an innovative, automatic approach leveraging multimodalinputs, such as video frames, audio streams. Specifically, we construct alarge-scale, high-quality, audio-language dataset, named as Auto-ACD,comprising over 1.5M audio-text pairs. We exploit a series of pre-trainedmodels or APIs, to determine audio-visual synchronisation, generate imagecaptions, object detection, or audio tags for specific videos. Subsequently, weemploy LLM to paraphrase a congruent caption for each audio, guided by theextracted multi-modality clues. To demonstrate the effectiveness of theproposed dataset, we train widely used models on our dataset and showperformance improvement on various downstream tasks, for example,audio-language retrieval, audio captioning, zero-shot classification. Inaddition, we establish a novel benchmark with environmental information andprovide a benchmark for audio-text tasks.</description><author>Luoyi Sun, Xuenan Xu, Mengyue Wu, Weidi Xie</author><pubDate>Mon, 09 Sep 2024 14:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.11500v4</guid></item><item><title>SX-Stitch: An Efficient VMS-UNet Based Framework for Intraoperative Scoliosis X-Ray Image Stitching</title><link>http://arxiv.org/abs/2409.05681v1</link><description>In scoliosis surgery, the limited field of view of the C-arm X-ray machinerestricts the surgeons' holistic analysis of spinal structures .This paperpresents an end-to-end efficient and robust intraoperative X-ray imagestitching method for scoliosis surgery,named SX-Stitch. The method is dividedinto two stages:segmentation and stitching. In the segmentation stage, Wepropose a medical image segmentation model named Vision Mamba of Spine-UNet(VMS-UNet), which utilizes the state space Mamba to capture long-distancecontextual information while maintaining linear computational complexity, andincorporates the SimAM attention mechanism, significantly improving thesegmentation performance.In the stitching stage, we simplify the alignmentprocess between images to the minimization of a registration energy function.The total energy function is then optimized to order unordered images, and ahybrid energy function is introduced to optimize the best seam, effectivelyeliminating parallax artifacts. On the clinical dataset, Sx-Stitch demonstratessuperiority over SOTA schemes both qualitatively and quantitatively.</description><author>Yi Li, Heting Gao, Mingde He, Jinqian Liang, Jason Gu, Wei Liu</author><pubDate>Mon, 09 Sep 2024 14:49:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05681v1</guid></item><item><title>Cherenkov Imaged Bio-morphological Features Verify Patient Positioning with Deformable Tissue Translocation in Breast Radiotherapy</title><link>http://arxiv.org/abs/2409.05680v1</link><description>Accurate patient positioning is critical for precise radiotherapy dosedelivery, as positioning errors can significantly affect treatment outcomes.This study introduces a novel method for tracking loco-regional tissuedeformation through Cherenkov image analysis during fractionated breast cancerradiotherapy. The primary goal was to develop and test an algorithm forCherenkov-based regional position accuracy quantification, specifically forloco-regional deformations, which lack ideal quantification methods inradiotherapy. Blood vessel detection and segmentation were developed inCherenkov images using a tissue phantom with incremental movements, and laterapplied to images from fractionated whole breast radiotherapy in human patients(n=10). A combined rigid and non-rigid registration technique was used todetect inter- and intra-fractional positioning variations. This approachquantified positioning variations in two parts: a global shift from rigidregistration and a two-dimensional variation map of loco-regional deformationfrom non-rigid registration. The methodology was validated using ananthropomorphic chest phantom experiment, where known treatment couchtranslations and respiratory motion were simulated to assess inter- andintra-fractional uncertainties, yielding an average accuracy of 0.83 mm forcouch translations up to 20 mm. Analysis of clinical Cherenkov data from tenbreast cancer patients showed an inter-fraction setup variation of 3.7 plusminus 2.4 mm relative to the first fraction and loco-regional deformations(95th percentile) of up to 3.3 plus minus 1.9 mm. This study presents aCherenkov-based approach to quantify global and local positioning variations,demonstrating feasibility in addressing loco-regional deformations thatconventional imaging techniques fail to capture.</description><author>Yao Chen, Savannah M. Decker, Petr Bruza, David J. Gladstone, Lesley A. Jarvis, Brian W. Pogue, Kimberley S. Samkoe, Rongxiao Zhang</author><pubDate>Mon, 09 Sep 2024 14:48:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05680v1</guid></item><item><title>AnomalyCD: A benchmark for Earth anomaly change detection with high-resolution and time-series observations</title><link>http://arxiv.org/abs/2409.05679v1</link><description>Various Earth anomalies have destroyed the stable, balanced state, resultingin fatalities and serious destruction of property. With the advantages oflarge-scale and precise observation, high-resolution remote sensing images havebeen widely used for anomaly monitoring and localization. Powered by the deeprepresentation, the existing methods have achieved remarkable advances,primarily in classification and change detection techniques. However, labeledsamples are difficult to acquire due to the low probability of anomalyoccurrence, and the trained models are limited to fixed anomaly categories,which hinders the application for anomalies with few samples or unknownanomalies. In this paper, to tackle this problem, we propose the anomaly changedetection (AnomalyCD) technique, which accepts time-series observations andlearns to identify anomalous changes by learning from the historical normalchange pattern. Compared to the existing techniques, AnomalyCD processes anunfixed number of time steps and can localize the various anomalies in aunified manner, without human supervision. To benchmark AnomalyCD, weconstructed a high-resolution dataset with time-series images dedicated tovarious Earth anomalies (the AnomalyCDD dataset). AnomalyCDD containshigh-resolution (from 0.15 to 2.39 m/pixel), time-series (from 3 to 7 timesteps), and large-scale images (1927.93 km2 in total) collected globallyFurthermore, we developed a zero-shot baseline model (AnomalyCDM), whichimplements the AnomalyCD technique by extracting a general representation fromthe segment anything model (SAM) and conducting temporal comparison todistinguish the anomalous changes from normal changes. AnomalyCDM is designedas a two-stage workflow to enhance the efficiency, and has the ability toprocess the unseen images directly, without retraining for each scene.</description><author>Jingtao Li, Qian Zhu, Xinyu Wang, Hengwei Zhao, Yanfei Zhong</author><pubDate>Mon, 09 Sep 2024 14:47:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05679v1</guid></item><item><title>Separation of Body and Background in Radiological Images. A Practical Python Code</title><link>http://arxiv.org/abs/2409.00442v2</link><description>Radiological images, such as magnetic resonance imaging (MRI) and computedtomography (CT) images, typically consist of a body part and a dark background.For many analyses, it is necessary to separate the body part from thebackground. In this article, we present a Python code designed to separate bodyand background regions in 2D and 3D radiological images. We tested thealgorithm on various MRI and CT images of different body parts, including thebrain, neck, and abdominal regions. Additionally, we introduced a method forintensity normalization and outlier restriction, adjusted for data conversioninto 8-bit unsigned integer (UINT8) format, and examined its effects onbody-background separation. Our Python code is available for use with propercitation.</description><author>Seyedeh Fahimeh Hosseini, Faezeh Shalbafzadeh, Behzad Amanpour-Gharaei</author><pubDate>Mon, 09 Sep 2024 14:45:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.00442v2</guid></item><item><title>TextGaze: Gaze-Controllable Face Generation with Natural Language</title><link>http://arxiv.org/abs/2404.17486v2</link><description>Generating face image with specific gaze information has attractedconsiderable attention. Existing approaches typically input gaze valuesdirectly for face generation, which is unnatural and requires annotated gazedatasets for training, thereby limiting its application. In this paper, wepresent a novel gaze-controllable face generation task. Our approach inputstextual descriptions that describe human gaze and head behavior and generatescorresponding face images. Our work first introduces a text-of-gaze datasetcontaining over 90k text descriptions spanning a dense distribution of gaze andhead poses. We further propose a gaze-controllable text-to-face method. Ourmethod contains a sketch-conditioned face diffusion module and a model-basedsketch diffusion module. We define a face sketch based on facial landmarks andeye segmentation map. The face diffusion module generates face images from theface sketch, and the sketch diffusion module employs a 3D face model togenerate face sketch from text description. Experiments on the FFHQ datasetshow the effectiveness of our method. We will release our dataset and code forfuture research.</description><author>Hengfei Wang, Zhongqun Zhang, Yihua Cheng, Hyung Jin Chang</author><pubDate>Mon, 09 Sep 2024 14:45:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.17486v2</guid></item><item><title>RegNLP in Action: Facilitating Compliance Through Automated Information Retrieval and Answer Generation</title><link>http://arxiv.org/abs/2409.05677v1</link><description>Regulatory documents, issued by governmental regulatory bodies, establishrules, guidelines, and standards that organizations must adhere to for legalcompliance. These documents, characterized by their length, complexity andfrequent updates, are challenging to interpret, requiring significantallocation of time and expertise on the part of organizations to ensure ongoingcompliance.Regulatory Natural Language Processing (RegNLP) is amultidisciplinary subfield aimed at simplifying access to and interpretation ofregulatory rules and obligations. We define an Automated Question-PassageGeneration task for RegNLP, create the ObliQA dataset containing 27,869questions derived from the Abu Dhabi Global Markets (ADGM) financial regulationdocument collection, design a baseline Regulatory Information Retrieval andAnswer Generation system, and evaluate it with RePASs, a novel evaluationmetric that tests whether generated answers accurately capture all relevantobligations and avoid contradictions.</description><author>Tuba Gokhan, Kexin Wang, Iryna Gurevych, Ted Briscoe</author><pubDate>Mon, 09 Sep 2024 14:44:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05677v1</guid></item><item><title>FashionLOGO: Prompting Multimodal Large Language Models for Fashion Logo Embeddings</title><link>http://arxiv.org/abs/2308.09012v2</link><description>Logo embedding models convert the product logos in images into vectors,enabling their utilization for logo recognition and detection within e-commerceplatforms. This facilitates the enforcement of intellectual property rights andenhances product search capabilities. However, current methods treat logoembedding as a purely visual problem. A noteworthy issue is that visual modelscapture features more than logos. Instead, we view this as a multimodal task,using text as auxiliary information to facilitate the visual model'sunderstanding of the logo. The emerging Multimodal Large Language Models(MLLMs) have demonstrated remarkable capabilities in both visual and textualunderstanding. Inspired by this, we propose an approach, \textbf{FashionLOGO},to explore how to prompt MLLMs to generate appropriate text for product images,which can help visual models achieve better logo embeddings. We adopt across-attention transformer block that enables visual embedding toautomatically learn supplementary knowledge from textual embedding. Ourextensive experiments on real-world datasets prove that FashionLOGO is capableof generating generic and robust logo embeddings, achieving state-of-the-artperformance in all benchmarks.</description><author>Zhen Wang, Da Li, Yulin Su, Min Yang, Minghui Qiu, Walton Wang</author><pubDate>Mon, 09 Sep 2024 14:42:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.09012v2</guid></item><item><title>Evaluation of real-time transcriptions using end-to-end ASR models</title><link>http://arxiv.org/abs/2409.05674v1</link><description>Automatic Speech Recognition (ASR) or Speech-to-text (STT) has greatlyevolved in the last few years. Traditional architectures based on pipelineshave been replaced by joint end-to-end (E2E) architectures that simplify andstreamline the model training process. In addition, new AI training methods,such as weak-supervised learning have reduced the need for high-quality audiodatasets for model training. However, despite all these advancements, little tono research has been done on real-time transcription. In real-time scenarios,the audio is not pre-recorded, and the input audio must be fragmented to beprocessed by the ASR systems. To achieve real-time requirements, thesefragments must be as short as possible to reduce latency. However, audio cannotbe split at any point as dividing an utterance into two separate fragments willgenerate an incorrect transcription. Also, shorter fragments provide lesscontext for the ASR model. For this reason, it is necessary to design and testdifferent splitting algorithms to optimize the quality and delay of theresulting transcription. In this paper, three audio splitting algorithms areevaluated with different ASR models to determine their impact on both thequality of the transcription and the end-to-end delay. The algorithms arefragmentation at fixed intervals, voice activity detection (VAD), andfragmentation with feedback. The results are compared to the performance of thesame model, without audio fragmentation, to determine the effects of thisdivision. The results show that VAD fragmentation provides the best qualitywith the highest delay, whereas fragmentation at fixed intervals provides thelowest quality and the lowest delay. The newly proposed feedback algorithmexchanges a 2-4% increase in WER for a reduction of 1.5-2s delay, respectively,to the VAD splitting.</description><author>Carlos Arriaga, Alejandro Pozo, Javier Conde, Alvaro Alonso</author><pubDate>Mon, 09 Sep 2024 14:41:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05674v1</guid></item><item><title>Zero-shot Outlier Detection via Prior-data Fitted Networks: Model Selection Bygone!</title><link>http://arxiv.org/abs/2409.05672v1</link><description>Outlier detection (OD) has a vast literature as it finds numerousapplications in environmental monitoring, cybersecurity, finance, and medicineto name a few. Being an inherently unsupervised task, model selection is a keybottleneck for OD (both algorithm and hyperparameter selection) without labelsupervision. There is a long list of techniques to choose from -- bothclassical algorithms and deep neural architectures -- and while several studiesreport their hyperparameter sensitivity, the literature is quite slim onunsupervised model selection -- limiting the effective use of OD in practice.In this paper we present FoMo-0D, for zero/0-shot OD exploring a transformativenew direction that bypasses the hurdle of model selection altogether (!), thusbreaking new ground. The fundamental idea behind FoMo-0D is the Prior-dataFitted Networks, recently introduced by Muller et al.(2022), which trains aTransformer model on a large body of synthetically generated data from a priordata distribution. In essence, FoMo-0D is a pretrained Foundation Model forzero/0-shot OD on tabular data, which can directly predict the (outlier/inlier)label of any test data at inference time, by merely a single forward pass --making obsolete the need for choosing an algorithm/architecture, tuning itsassociated hyperparameters, and even training any model parameters when given anew OD dataset. Extensive experiments on 57 public benchmark datasets against26 baseline methods show that FoMo-0D performs statistically no different fromthe top 2nd baseline, while significantly outperforming the majority of thebaselines, with an average inference time of 7.7 ms per test sample.</description><author>Yuchen Shen, Haomin Wen, Leman Akoglu</author><pubDate>Mon, 09 Sep 2024 14:41:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05672v1</guid></item><item><title>Unlearning or Concealment? A Critical Analysis and Evaluation Metrics for Unlearning in Diffusion Models</title><link>http://arxiv.org/abs/2409.05668v1</link><description>Recent research has seen significant interest in methods for concept removaland targeted forgetting in diffusion models. In this paper, we conduct acomprehensive white-box analysis to expose significant vulnerabilities inexisting diffusion model unlearning methods. We show that the objectivefunctions used for unlearning in the existing methods lead to decoupling of thetargeted concepts (meant to be forgotten) for the corresponding prompts. Thisis concealment and not actual unlearning, which was the original goal. Theineffectiveness of current methods stems primarily from their narrow focus onreducing generation probabilities for specific prompt sets, neglecting thediverse modalities of intermediate guidance employed during the inferenceprocess. The paper presents a rigorous theoretical and empirical examination offour commonly used techniques for unlearning in diffusion models. We introducetwo new evaluation metrics: Concept Retrieval Score (CRS) and ConceptConfidence Score (CCS). These metrics are based on a successful adversarialattack setup that can recover forgotten concepts from unlearned diffusionmodels. The CRS measures the similarity between the latent representations ofthe unlearned and fully trained models after unlearning. It reports the extentof retrieval of the forgotten concepts with increasing amount of guidance. TheCCS quantifies the confidence of the model in assigning the target concept tothe manipulated data. It reports the probability of the unlearned model'sgenerations to be aligned with the original domain knowledge with increasingamount of guidance. Evaluating existing unlearning methods with our proposedstringent metrics for diffusion models reveals significant shortcomings intheir ability to truly unlearn concepts. Source Code:https://respailab.github.io/unlearning-or-concealment</description><author>Aakash Sen Sharma, Niladri Sarkar, Vikram Chundawat, Ankur A Mali, Murari Mandal</author><pubDate>Mon, 09 Sep 2024 14:38:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05668v1</guid></item></channel></rss>