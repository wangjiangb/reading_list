<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 07 Feb 2025 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Seeing World Dynamics in a Nutshell</title><link>http://arxiv.org/abs/2502.03465v1</link><description>We consider the problem of efficiently representing casually capturedmonocular videos in a spatially- and temporally-coherent manner. While existingapproaches predominantly rely on 2D/2.5D techniques treating videos ascollections of spatiotemporal pixels, they struggle with complex motions,occlusions, and geometric consistency due to absence of temporal coherence andexplicit 3D structure. Drawing inspiration from monocular video as a projectionof the dynamic 3D world, we explore representing videos in their intrinsic 3Dform through continuous flows of Gaussian primitives in space-time. In thispaper, we propose NutWorld, a novel framework that efficiently transformsmonocular videos into dynamic 3D Gaussian representations in a single forwardpass. At its core, NutWorld introduces a structured spatial-temporal alignedGaussian (STAG) representation, enabling optimization-free scene modeling witheffective depth and flow regularization. Through comprehensive experiments, wedemonstrate that NutWorld achieves high-fidelity video reconstruction qualitywhile enabling various downstream applications in real-time. Demos and codewill be available at https://github.com/Nut-World/NutWorld.</description><author>Qiuhong Shen, Xuanyu Yi, Mingbao Lin, Hanwang Zhang, Shuicheng Yan, Xinchao Wang</author><pubDate>Wed, 05 Feb 2025 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03465v1</guid></item><item><title>Do Large Language Model Benchmarks Test Reliability?</title><link>http://arxiv.org/abs/2502.03461v1</link><description>When deploying large language models (LLMs), it is important to ensure thatthese models are not only capable, but also reliable. Many benchmarks have beencreated to track LLMs' growing capabilities, however there has been no similarfocus on measuring their reliability. To understand the potential ramificationsof this gap, we investigate how well current benchmarks quantify modelreliability. We find that pervasive label errors can compromise theseevaluations, obscuring lingering model failures and hiding unreliable behavior. Motivated by this gap in the evaluation of reliability, we then propose theconcept of so-called platinum benchmarks, i.e., benchmarks carefully curated tominimize label errors and ambiguity. As a first attempt at constructing suchbenchmarks, we revise examples from fifteen existing popular benchmarks. Weevaluate a wide range of models on these platinum benchmarks and find that,indeed, frontier LLMs still exhibit failures on simple tasks such aselementary-level math word problems. Analyzing these failures further revealspreviously unidentified patterns of problems on which frontier modelsconsistently struggle. We provide code athttps://github.com/MadryLab/platinum-benchmarks</description><author>Joshua Vendrow, Edward Vendrow, Sara Beery, Aleksander Madry</author><pubDate>Wed, 05 Feb 2025 18:58:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03461v1</guid></item><item><title>Adapt-Pruner: Adaptive Structural Pruning for Efficient Small Language Model Training</title><link>http://arxiv.org/abs/2502.03460v1</link><description>Small language models (SLMs) have attracted considerable attention from bothacademia and industry due to their broad range of applications in edge devices.To obtain SLMs with strong performance, conventional approaches eitherpre-train the models from scratch, which incurs substantial computationalcosts, or compress/prune existing large language models (LLMs), which resultsin performance drops and falls short in comparison to pre-training. In thispaper, we investigate the family of acceleration methods that involve bothstructured pruning and model training. We found 1) layer-wise adaptive pruning(Adapt-Pruner) is extremely effective in LLMs and yields significantimprovements over existing pruning techniques, 2) adaptive pruning equippedwith further training leads to models comparable to those pre-training fromscratch, 3) incremental pruning brings non-trivial performance gain byinterleaving pruning with training and only removing a small portion of neurons($\sim$5%) at a time. Experimental results on LLaMA-3.1-8B demonstrate thatAdapt-Pruner outperforms conventional pruning methods, such as LLM-Pruner,FLAP, and SliceGPT, by an average of 1%-7% in accuracy on commonsensebenchmarks. Additionally, Adapt-Pruner restores the performance ofMobileLLM-125M to 600M on the MMLU benchmark with 200$\times$ fewer tokens viapruning from its larger counterparts, and discovers a new 1B model thatsurpasses LLaMA-3.2-1B in multiple benchmarks.</description><author>Boyao Wang, Rui Pan, Shizhe Diao, Xingyuan Pan, Jipeng Zhang, Renjie Pi, Tong Zhang</author><pubDate>Wed, 05 Feb 2025 18:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03460v1</guid></item><item><title>SKI Models: Skeleton Induced Vision-Language Embeddings for Understanding Activities of Daily Living</title><link>http://arxiv.org/abs/2502.03459v1</link><description>The introduction of vision-language models like CLIP has enabled thedevelopment of foundational video models capable of generalizing to unseenvideos and human actions. However, these models are typically trained on webvideos, which often fail to capture the challenges present in Activities ofDaily Living (ADL) videos. Existing works address ADL-specific challenges, suchas similar appearances, subtle motion patterns, and multiple viewpoints, bycombining 3D skeletons and RGB videos. However, these approaches are notintegrated with language, limiting their ability to generalize to unseen actionclasses. In this paper, we introduce SKI models, which integrate 3D skeletonsinto the vision-language embedding space. SKI models leverage askeleton-language model, SkeletonCLIP, to infuse skeleton information intoVision Language Models (VLMs) and Large Vision Language Models (LVLMs) throughcollaborative training. Notably, SKI models do not require skeleton data duringinference, enhancing their robustness for real-world applications. Theeffectiveness of SKI models is validated on three popular ADL datasets forzero-shot action recognition and video caption generation tasks.</description><author>Arkaprava Sinha, Dominick Reilly, Francois Bremond, Pu Wang, Srijan Das</author><pubDate>Wed, 05 Feb 2025 18:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03459v1</guid></item><item><title>NNetNav: Unsupervised Learning of Browser Agents Through Environment Interaction in the Wild</title><link>http://arxiv.org/abs/2410.02907v2</link><description>We introduce NNetNav, a method for unsupervised interaction with websitesthat generates synthetic demonstrations for training browser agents. Given anywebsite, NNetNav produces these demonstrations by retroactively labeling actionsequences from an exploration policy. Most work on training browser agents hasrelied on expensive human supervision, and the limited prior work on suchinteraction-based techniques has failed to provide effective search through theexponentially large space of exploration. In contrast, NNetNav exploits thehierarchical structure of language instructions to make this search moretractable: Complex instructions are typically decomposable into simplersub-tasks, allowing NNetNav to automatically prune interaction episodes when anintermediate trajectory cannot be annotated with a meaningful sub-task.\texttt{LLama-3.1-8b} finetuned on 10k NNetNav self-generated demonstrationsobtains over 16\% success rate on WebArena, and 35\% on WebVoyager, animprovement of 15pts and 31pts respectively over zero-shot\texttt{LLama-3.1-8b}, outperforming zero-shot GPT-4 and reaching thestate-of-the-art among unsupervised methods, for both benchmarks.</description><author>Shikhar Murty, Hao Zhu, Dzmitry Bahdanau, Christopher D. Manning</author><pubDate>Wed, 05 Feb 2025 18:56:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02907v2</guid></item><item><title>The Performance Of The Unadjusted Langevin Algorithm Without Smoothness Assumptions</title><link>http://arxiv.org/abs/2502.03458v1</link><description>In this article, we study the problem of sampling from distributions whosedensities are not necessarily smooth nor log-concave. We propose a simpleLangevin-based algorithm that does not rely on popular but computationallychallenging techniques, such as the Moreau Yosida envelope or Gaussiansmoothing. We derive non-asymptotic guarantees for the convergence of thealgorithm to the target distribution in Wasserstein distances. Non asymptoticbounds are also provided for the performance of the algorithm as an optimizer,specifically for the solution of associated excess risk optimization problems.</description><author>Tim Johnston, Iosif Lytras, Nikolaos Makras, Sotirios Sabanis</author><pubDate>Wed, 05 Feb 2025 18:55:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03458v1</guid></item><item><title>A Schema-Guided Reason-while-Retrieve framework for Reasoning on Scene Graphs with Large-Language-Models (LLMs)</title><link>http://arxiv.org/abs/2502.03450v1</link><description>Scene graphs have emerged as a structured and serializable environmentrepresentation for grounded spatial reasoning with Large Language Models(LLMs). In this work, we propose SG-RwR, a Schema-Guided Retrieve-while-Reasonframework for reasoning and planning with scene graphs. Our approach employstwo cooperative, code-writing LLM agents: a (1) Reasoner for task planning andinformation queries generation, and a (2) Retriever for extractingcorresponding graph information following the queries. Two agents collaborateiteratively, enabling sequential reasoning and adaptive attention to graphinformation. Unlike prior works, both agents are prompted only with the scenegraph schema rather than the full graph data, which reduces the hallucinationby limiting input tokens, and drives the Reasoner to generate reasoning traceabstractly.Following the trace, the Retriever programmatically query the scenegraph data based on the schema understanding, allowing dynamic and globalattention on the graph that enhances alignment between reasoning and retrieval.Through experiments in multiple simulation environments, we show that ourframework surpasses existing LLM-based approaches in numerical Q\&amp;A andplanning tasks, and can benefit from task-level few-shot examples, even in theabsence of agent-level demonstrations. Project code will be released.</description><author>Yiye Chen, Harpreet Sawhney, Nicholas Gydé, Yanan Jian, Jack Saunders, Patricio Vela, Ben Lundell</author><pubDate>Wed, 05 Feb 2025 18:50:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03450v1</guid></item><item><title>Dress-1-to-3: Single Image to Simulation-Ready 3D Outfit with Diffusion Prior and Differentiable Physics</title><link>http://arxiv.org/abs/2502.03449v1</link><description>Recent advances in large models have significantly advanced image-to-3Dreconstruction. However, the generated models are often fused into a singlepiece, limiting their applicability in downstream tasks. This paper focuses on3D garment generation, a key area for applications like virtual try-on withdynamic garment animations, which require garments to be separable andsimulation-ready. We introduce Dress-1-to-3, a novel pipeline that reconstructsphysics-plausible, simulation-ready separated garments with sewing patterns andhumans from an in-the-wild image. Starting with the image, our approachcombines a pre-trained image-to-sewing pattern generation model for creatingcoarse sewing patterns with a pre-trained multi-view diffusion model to producemulti-view images. The sewing pattern is further refined using a differentiablegarment simulator based on the generated multi-view images. Versatileexperiments demonstrate that our optimization approach substantially enhancesthe geometric alignment of the reconstructed 3D garments and humans with theinput image. Furthermore, by integrating a texture generation module and ahuman motion generation module, we produce customized physics-plausible andrealistic dynamic garment demonstrations. Project page:https://dress-1-to-3.github.io/</description><author>Xuan Li, Chang Yu, Wenxin Du, Ying Jiang, Tianyi Xie, Yunuo Chen, Yin Yang, Chenfanfu Jiang</author><pubDate>Wed, 05 Feb 2025 18:49:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03449v1</guid></item><item><title>Masked Autoencoders Are Effective Tokenizers for Diffusion Models</title><link>http://arxiv.org/abs/2502.03444v1</link><description>Recent advances in latent diffusion models have demonstrated theireffectiveness for high-resolution image synthesis. However, the properties ofthe latent space from tokenizer for better learning and generation of diffusionmodels remain under-explored. Theoretically and empirically, we find thatimproved generation quality is closely tied to the latent distributions withbetter structure, such as the ones with fewer Gaussian Mixture modes and morediscriminative features. Motivated by these insights, we propose MAETok, anautoencoder (AE) leveraging mask modeling to learn semantically rich latentspace while maintaining reconstruction fidelity. Extensive experiments validateour analysis, demonstrating that the variational form of autoencoders is notnecessary, and a discriminative latent space from AE alone enablesstate-of-the-art performance on ImageNet generation using only 128 tokens.MAETok achieves significant practical improvements, enabling a gFID of 1.69with 76x faster training and 31x higher inference throughput for 512x512generation. Our findings show that the structure of the latent space, ratherthan variational constraints, is crucial for effective diffusion models. Codeand trained models are released.</description><author>Hao Chen, Yujin Han, Fangyi Chen, Xiang Li, Yidong Wang, Jindong Wang, Ze Wang, Zicheng Liu, Difan Zou, Bhiksha Raj</author><pubDate>Wed, 05 Feb 2025 18:42:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03444v1</guid></item><item><title>Discretely Beyond $1/e$: Guided Combinatorial Algorithms for Submodular Maximization</title><link>http://arxiv.org/abs/2405.05202v3</link><description>For constrained, not necessarily monotone submodular maximization, all knownapproximation algorithms with ratio greater than $1/e$ require continuousideas, such as queries to the multilinear extension of a submodular functionand its gradient, which are typically expensive to simulate with the originalset function. For combinatorial algorithms, the best known approximation ratiosfor both size and matroid constraint are obtained by a simple randomized greedyalgorithm of Buchbinder et al. [9]: $1/e \approx 0.367$ for size constraint and$0.281$ for the matroid constraint in $\mathcal O (kn)$ queries, where $k$ isthe rank of the matroid. In this work, we develop the first combinatorialalgorithms to break the $1/e$ barrier: we obtain approximation ratio of $0.385$in $\mathcal O (kn)$ queries to the submodular set function for sizeconstraint, and $0.305$ for a general matroid constraint. These are achieved byguiding the randomized greedy algorithm with a fast local search algorithm.Further, we develop deterministic versions of these algorithms, maintaining thesame ratio and asymptotic time complexity. Finally, we develop a deterministic,nearly linear time algorithm with ratio $0.377$.</description><author>Yixin Chen, Ankur Nath, Chunli Peng, Alan Kuhnle</author><pubDate>Wed, 05 Feb 2025 18:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.05202v3</guid></item><item><title>S2-Attention: Hardware-Aware Context Sharding Among Attention Heads</title><link>http://arxiv.org/abs/2407.17678v7</link><description>Sparse attention, which selectively attends to a subset of tokens in thecontext was supposed to be efficient. However, its theoretical reduction inFLOPs has rarely translated into wall-clock speed-up over its dense attentioncounterparts due to the lack of hardware-aware optimizations likeFlashAttention. Meanwhile, it remains unclear whether sparse attention canmaintain the model's quality at a scale of today's large language models (LLMs)and how. This paper presents Sparsely-Sharded(S2) Attention, a Triton librarythat provides kernel optimization for sparse attention customizable at bothper-head and per-context-range levels. S2-Attention enables the exploration ofnovel and high-performance sparse attention techniques, which we demonstratethrough extensive ablations across a wide range of sparse attention designs atvarious model scales. From these insights, we present several basic guidelinesto design sparse attention that can achieve not only practical efficiencyimprovements, but also strong downstream performance. To achieve highparallelization and optimized memory IO, sparse attention should shard thecontext heterogeneously across attention heads, where each head attends to adifferent subset of tokens while collectively covering the full context.Meanwhile, we find hybrid architectures combining sparse and dense attentionparticularly beneficial in practice. S2-Attention achieves wall-clock speedupof 8.79X, 15.87X, 25.3X compared to the strong FlashAttention-2 baseline withstrong downstream performance on-par with full attention and perfect retrievalperformance at a 128k context length. At inference, for 7B models, our model,with the help of our S2-Attention kernel, achieves 4.5x speed-up compared todense counterparts. S2-Attention is released with easy-to-customize APIs fordirect usage in Megatron and vLLM.</description><author>Xihui Lin, Yunan Zhang, Suyu Ge, Liliang Ren, Barun Patra, Vishrav Chaudhary, Hao Peng, Xia Song</author><pubDate>Wed, 05 Feb 2025 18:39:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.17678v7</guid></item><item><title>Solving Drone Routing Problems with Quantum Computing: A Hybrid Approach Combining Quantum Annealing and Gate-Based Paradigms</title><link>http://arxiv.org/abs/2501.18432v2</link><description>This paper presents a novel hybrid approach to solving real-world dronerouting problems by leveraging the capabilities of quantum computing. Theproposed method, coined Quantum for Drone Routing (Q4DR), integrates the twomost prominent paradigms in the field: quantum gate-based computing, throughthe Eclipse Qrisp programming language; and quantum annealers, by means ofD-Wave System's devices. The algorithm is divided into two different phases: aninitial clustering phase executed using a Quantum Approximate OptimizationAlgorithm (QAOA), and a routing phase employing quantum annealers. The efficacyof Q4DR is demonstrated through three use cases of increasing complexity, eachincorporating real-world constraints such as asymmetric costs, forbidden paths,and itinerant charging points. This research contributes to the growing body ofwork in quantum optimization, showcasing the practical applications of quantumcomputing in logistics and route planning.</description><author>Eneko Osaba, Pablo Miranda-Rodriguez, Andreas Oikonomakis, Matic Petrič, Alejandra Ruiz, Sebastian Bock, Michail-Alexandros Kourtis</author><pubDate>Wed, 05 Feb 2025 18:37:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18432v2</guid></item><item><title>LMOD: A Large Multimodal Ophthalmology Dataset and Benchmark for Large Vision-Language Models</title><link>http://arxiv.org/abs/2410.01620v5</link><description>The prevalence of vision-threatening eye diseases is a significant globalburden, with many cases remaining undiagnosed or diagnosed too late foreffective treatment. Large vision-language models (LVLMs) have the potential toassist in understanding anatomical information, diagnosing eye diseases, anddrafting interpretations and follow-up plans, thereby reducing the burden onclinicians and improving access to eye care. However, limited benchmarks areavailable to assess LVLMs' performance in ophthalmology-specific applications.In this study, we introduce LMOD, a large-scale multimodal ophthalmologybenchmark consisting of 21,993 instances across (1) five ophthalmic imagingmodalities: optical coherence tomography, color fundus photographs, scanninglaser ophthalmoscopy, lens photographs, and surgical scenes; (2) free-text,demographic, and disease biomarker information; and (3) primaryophthalmology-specific applications such as anatomical informationunderstanding, disease diagnosis, and subgroup analysis. In addition, webenchmarked 13 state-of-the-art LVLM representatives from closed-source,open-source, and medical domains. The results demonstrate a significantperformance drop for LVLMs in ophthalmology compared to other domains.Systematic error analysis further identified six major failure modes:misclassification, failure to abstain, inconsistent reasoning, hallucination,assertions without justification, and lack of domain-specific knowledge. Incontrast, supervised neural networks specifically trained on these tasks asbaselines demonstrated high accuracy. These findings underscore the pressingneed for benchmarks in the development and validation of ophthalmology-specificLVLMs.</description><author>Zhenyue Qin, Yu Yin, Dylan Campbell, Xuansheng Wu, Ke Zou, Yih-Chung Tham, Ninghao Liu, Xiuzhen Zhang, Qingyu Chen</author><pubDate>Wed, 05 Feb 2025 18:36:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.01620v5</guid></item><item><title>Linearized Optimal Transport pyLOT Library: A Toolkit for Machine Learning on Point Clouds</title><link>http://arxiv.org/abs/2502.03439v1</link><description>The pyLOT library offers a Python implementation of linearized optimaltransport (LOT) techniques and methods to use in downstream tasks. The pipelineembeds probability distributions into a Hilbert space via the Optimal Transportmaps from a fixed reference distribution, and this linearization allowsdownstream tasks to be completed using off the shelf (linear) machine learningalgorithms. We provide a case study of performing ML on 3D scans of lemurteeth, where the original questions of classification, clustering, dimensionreduction, and data generation reduce to simple linear operations performed onthe LOT embedded representations.</description><author>Jun Linwu, Varun Khurana, Nicholas Karris, Alexander Cloninger</author><pubDate>Wed, 05 Feb 2025 18:34:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03439v1</guid></item><item><title>BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving</title><link>http://arxiv.org/abs/2502.03438v1</link><description>Recent advancements in large language models (LLMs) have spurred growinginterest in automatic theorem proving using Lean4, where effective tree searchmethods are crucial for navigating proof search spaces. While the existingapproaches primarily rely on value functions and Monte Carlo Tree Search(MCTS), the potential of simpler methods like Best-First Search (BFS) remainsunderexplored. This paper investigates whether BFS can achieve competitiveperformance in large-scale theorem proving tasks. We present\texttt{BFS-Prover}, a scalable expert iteration framework, featuring three keyinnovations. First, we implement strategic data filtering at each expertiteration round, excluding problems solvable via beam search node expansion tofocus on harder cases. Second, we improve the sample efficiency of BFS throughDirect Preference Optimization (DPO) applied to state-tactic pairsautomatically annotated with compiler error feedback, refining the LLM's policyto prioritize productive expansions. Third, we employ length normalization inBFS to encourage exploration of deeper proof paths. \texttt{BFS-Prover}achieves a score of $71.31$ on the MiniF2F test set and therefore challengesthe perceived necessity of complex tree search methods, demonstrating that BFScan achieve competitive performance when properly scaled.</description><author>Ran Xin, Chenguang Xi, Jie Yang, Feng Chen, Hang Wu, Xia Xiao, Yifan Sun, Shen Zheng, Kai Shen</author><pubDate>Wed, 05 Feb 2025 18:33:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03438v1</guid></item><item><title>Taking a Big Step: Large Learning Rates in Denoising Score Matching Prevent Memorization</title><link>http://arxiv.org/abs/2502.03435v1</link><description>Denoising score matching plays a pivotal role in the performance ofdiffusion-based generative models. However, the empirical optimal score--theexact solution to the denoising score matching--leads to memorization, wheregenerated samples replicate the training data. Yet, in practice, only amoderate degree of memorization is observed, even without explicitregularization. In this paper, we investigate this phenomenon by uncovering animplicit regularization mechanism driven by large learning rates. Specifically,we show that in the small-noise regime, the empirical optimal score exhibitshigh irregularity. We then prove that, when trained by stochastic gradientdescent with a large enough learning rate, neural networks cannot stablyconverge to a local minimum with arbitrarily small excess risk. Consequently,the learned score cannot be arbitrarily close to the empirical optimal score,thereby mitigating memorization. To make the analysis tractable, we considerone-dimensional data and two-layer neural networks. Experiments validate thecrucial role of the learning rate in preventing memorization, even beyond theone-dimensional setting.</description><author>Yu-Han Wu, Pierre Marion, Gérard Biau, Claire Boyer</author><pubDate>Wed, 05 Feb 2025 18:29:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03435v1</guid></item><item><title>DeepIFSAC: Deep Imputation of Missing Values Using Feature and Sample Attention within Contrastive Framework</title><link>http://arxiv.org/abs/2501.10910v2</link><description>Missing values of varying patterns and rates in real-world tabular data posea significant challenge in developing reliable data-driven models. Existingmissing value imputation methods use statistical and traditional machinelearning and are ineffective when the missing rate is high and not at random.This paper explores row and column attention in tabular data as between-featureand between-sample attention in a novel framework to reconstruct missingvalues. The proposed method uses the CutMix data augmentation within acontrastive learning framework to improve the uncertainty of missing valueestimation. The performance and generalizability of trained imputation modelsare evaluated on set-aside test data folds with missing values. The proposedframework outperforms nine state-of-the-art imputation methods across severalmissing value types and rates (10\%-50\%) on a diverse selection of twelvetabular data sets. We evaluate the quality of imputed data using real-worldelectronic health records with missing values, demonstrating our proposedframework's superiority to state-of-the-art statistical, machine learning, anddeep imputation methods. This paper highlights the heterogeneity of tabulardata sets to recommend imputation methods based on missing value types and datacharacteristics.</description><author>Ibna Kowsar, Shourav B. Rabbani, Yina Hou, Manar D. Samad</author><pubDate>Wed, 05 Feb 2025 18:29:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.10910v2</guid></item><item><title>An Optimized Toolbox for Advanced Image Processing with Tsetlin Machine Composites</title><link>http://arxiv.org/abs/2406.00704v2</link><description>The Tsetlin Machine (TM) has achieved competitive results on several imageclassification benchmarks, including MNIST, K-MNIST, F-MNIST, and CIFAR-2.However, color image classification is arguably still in its infancy for TMs,with CIFAR-10 being a focal point for tracking progress. Over the past fewyears, TM's CIFAR-10 accuracy has increased from around 61% in 2020 to 75.1% in2023 with the introduction of Drop Clause. In this paper, we leverage therecently proposed TM Composites architecture and introduce a range of TMSpecialists that use various image processing techniques. These include Cannyedge detection, Histogram of Oriented Gradients, adaptive mean thresholding,adaptive Gaussian thresholding, Otsu's thresholding, color thermometers, andadaptive color thermometers. In addition, we conduct a rigorous hyperparametersearch, where we uncover optimal hyperparameters for several of the TMSpecialists. The result is a toolbox that provides new state-of-the-art resultson CIFAR-10 for TMs with an accuracy of 82.8%. In conclusion, our toolbox of TMSpecialists forms a foundation for new TM applications and a landmark forfurther research on TM Composites in image analysis.</description><author>Ylva Grønningsæter, Halvor S. Smørvik, Ole-Christoffer Granmo</author><pubDate>Wed, 05 Feb 2025 18:23:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.00704v2</guid></item><item><title>DP-SGD-Global-Adapt-V2-S: Triad Improvements of Privacy, Accuracy and Fairness via Step Decay Noise Multiplier and Step Decay Upper Clipping Threshold</title><link>http://arxiv.org/abs/2312.02400v2</link><description>Differentially Private Stochastic Gradient Descent (DP-SGD) has become awidely used technique for safeguarding sensitive information in deep learningapplications. Unfortunately, DPSGD's per-sample gradient clipping and uniformnoise addition during training can significantly degrade model utility andfairness. We observe that the latest DP-SGD-Global-Adapt's average gradientnorm is the same throughout the training. Even when it is integrated with theexisting linear decay noise multiplier, it has little or no advantage.Moreover, we notice that its upper clipping threshold increases exponentiallytowards the end of training, potentially impacting the models convergence.Other algorithms, DP-PSAC, Auto-S, DP-SGD-Global, and DP-F, have utility andfairness that are similar to or worse than DP-SGD, as demonstrated inexperiments. To overcome these problems and improve utility and fairness, wedeveloped the DP-SGD-Global-Adapt-V2-S. It has a step-decay noise multiplierand an upper clipping threshold that is also decayed step-wise.DP-SGD-Global-Adapt-V2-S with a privacy budget ($\epsilon$) of 1 improvesaccuracy by 0.9795\%, 0.6786\%, and 4.0130\% in MNIST, CIFAR10, and CIFAR100,respectively. It also reduces the privacy cost gap ($\pi$) by 89.8332% and60.5541% in unbalanced MNIST and Thinwall datasets, respectively. Finally, wedevelop mathematical expressions to compute the privacy budget using truncatedconcentrated differential privacy (tCDP) for DP-SGD-Global-Adapt-V2-T andDP-SGD-Global-Adapt-V2-S.</description><author>Sai Venkatesh Chilukoti, Md Imran Hossen, Liqun Shan, Vijay Srinivas Tida, Mahathir Mohammad Bappy, Wenmeng Tian, Xiai Hei</author><pubDate>Wed, 05 Feb 2025 18:23:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02400v2</guid></item><item><title>An Algebraically Converging Stochastic Gradient Descent Algorithm for Global Optimization</title><link>http://arxiv.org/abs/2204.05923v4</link><description>We propose a new gradient descent algorithm with added stochastic terms forfinding the global optimizers of nonconvex optimization problems. A keycomponent in the algorithm is the adaptive tuning of the randomness based onthe value of the objective function. In the language of simulated annealing,the temperature is state-dependent. With this, we prove the global convergenceof the algorithm with an algebraic rate both in probability and in theparameter space. This is a significant improvement over the classical rate fromusing a more straightforward control of the noise term. The convergence proofis based on the actual discrete setup of the algorithm, not just its continuouslimit as often done in the literature. We also present several numericalexamples to demonstrate the efficiency and robustness of the algorithm forreasonably complex objective functions.</description><author>Björn Engquist, Kui Ren, Yunan Yang</author><pubDate>Wed, 05 Feb 2025 18:22:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.05923v4</guid></item><item><title>A Temporal Convolutional Network-Based Approach and a Benchmark Dataset for Colonoscopy Video Temporal Segmentation</title><link>http://arxiv.org/abs/2502.03430v1</link><description>Following recent advancements in computer-aided detection and diagnosissystems for colonoscopy, the automated reporting of colonoscopy procedures isset to further revolutionize clinical practice. A crucial yet underexploredaspect in the development of these systems is the creation of computer visionmodels capable of autonomously segmenting full-procedure colonoscopy videosinto anatomical sections and procedural phases. In this work, we aim to createthe first open-access dataset for this task and propose a state-of-the-artapproach, benchmarked against competitive models. We annotated the publiclyavailable REAL-Colon dataset, consisting of 2.7 million frames from 60 completecolonoscopy videos, with frame-level labels for anatomical locations andcolonoscopy phases across nine categories. We then present ColonTCN, alearning-based architecture that employs custom temporal convolutional blocksdesigned to efficiently capture long temporal dependencies for the temporalsegmentation of colonoscopy videos. We also propose a dual k-foldcross-validation evaluation protocol for this benchmark, which includes modelassessment on unseen, multi-center data.ColonTCN achieves state-of-the-artperformance in classification accuracy while maintaining a low parameter countwhen evaluated using the two proposed k-fold cross-validation settings,outperforming competitive models. We report ablation studies to provideinsights into the challenges of this task and highlight the benefits of thecustom temporal convolutional blocks, which enhance learning and improve modelefficiency. We believe that the proposed open-access benchmark and the ColonTCNapproach represent a significant advancement in the temporal segmentation ofcolonoscopy procedures, fostering further open-access research to address thisclinical need.</description><author>Carlo Biffi, Giorgio Roffo, Pietro Salvagnini, Andrea Cherubini</author><pubDate>Wed, 05 Feb 2025 18:21:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03430v1</guid></item><item><title>Unanswerability Evaluation for Retrieval Augmented Generation</title><link>http://arxiv.org/abs/2412.12300v2</link><description>Existing evaluation frameworks for retrieval-augmented generation (RAG)systems focus on answerable queries, but they overlook the importance ofappropriately rejecting unanswerable requests. In this paper, we introduceUAEval4RAG, a framework designed to evaluate whether RAG systems can handleunanswerable queries effectively. We define a taxonomy with six unanswerablecategories, and UAEval4RAG automatically synthesizes diverse and challengingqueries for any given knowledge base with unanswered ratio and acceptable ratiometrics. We conduct experiments with various RAG components, includingretrieval models, rewriting methods, rerankers, language models, and promptingstrategies, and reveal hidden trade-offs in performance of RAG systems. Ourfindings highlight the critical role of component selection and prompt designin optimizing RAG systems to balance the accuracy of answerable queries withhigh rejection rates of unanswerable ones. UAEval4RAG provides valuableinsights and tools for developing more robust and reliable RAG systems.</description><author>Xiangyu Peng, Prafulla Kumar Choubey, Caiming Xiong, Chien-Sheng Wu</author><pubDate>Wed, 05 Feb 2025 18:21:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.12300v2</guid></item><item><title>On Fairness of Unified Multimodal Large Language Model for Image Generation</title><link>http://arxiv.org/abs/2502.03429v1</link><description>Unified multimodal large language models (U-MLLMs) have demonstratedimpressive performance in visual understanding and generation in an end-to-endpipeline. Compared with generation-only models (e.g., Stable Diffusion),U-MLLMs may raise new questions about bias in their outputs, which can beaffected by their unified capabilities. This gap is particularly concerninggiven the under-explored risk of propagating harmful stereotypes. In thispaper, we benchmark the latest U-MLLMs and find that most exhibit significantdemographic biases, such as gender and race bias. To better understand andmitigate this issue, we propose a locate-then-fix strategy, where we audit andshow how the individual model component is affected by bias. Our analysis showsthat bias originates primarily from the language model. More interestingly, weobserve a "partial alignment" phenomenon in U-MLLMs, where understanding biasappears minimal, but generation bias remains substantial. Thus, we propose anovel balanced preference model to balance the demographic distribution withsynthetic data. Experiments demonstrate that our approach reduces demographicbias while preserving semantic fidelity. We hope our findings underscore theneed for more holistic interpretation and debiasing strategies of U-MLLMs inthe future.</description><author>Ming Liu, Hao Chen, Jindong Wang, Liwen Wang, Bhiksha Raj Ramakrishnan, Wensheng Zhang</author><pubDate>Wed, 05 Feb 2025 18:21:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03429v1</guid></item><item><title>TruePose: Human-Parsing-guided Attention Diffusion for Full-ID Preserving Pose Transfer</title><link>http://arxiv.org/abs/2502.03426v1</link><description>Pose-Guided Person Image Synthesis (PGPIS) generates images that maintain asubject's identity from a source image while adopting a specified target pose(e.g., skeleton). While diffusion-based PGPIS methods effectively preservefacial features during pose transformation, they often struggle to accuratelymaintain clothing details from the source image throughout the diffusionprocess. This limitation becomes particularly problematic when there is asubstantial difference between the source and target poses, significantlyimpacting PGPIS applications in the fashion industry where clothing stylepreservation is crucial for copyright protection. Our analysis reveals thatthis limitation primarily stems from the conditional diffusion model'sattention modules failing to adequately capture and preserve clothing patterns.To address this limitation, we propose human-parsing-guided attentiondiffusion, a novel approach that effectively preserves both facial and clothingappearance while generating high-quality results. We propose ahuman-parsing-aware Siamese network that consists of three key components: dualidentical UNets (TargetNet for diffusion denoising and SourceNet for sourceimage embedding extraction), a human-parsing-guided fusion attention (HPFA),and a CLIP-guided attention alignment (CAA). The HPFA and CAA modules can embedthe face and clothes patterns into the target image generation adaptively andeffectively. Extensive experiments on both the in-shop clothes retrievalbenchmark and the latest in-the-wild human editing dataset demonstrate ourmethod's significant advantages over 13 baseline approaches for preserving bothfacial and clothes appearance in the source image.</description><author>Zhihong Xu, Dongxia Wang, Peng Du, Yang Cao, Qing Guo</author><pubDate>Wed, 05 Feb 2025 18:15:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03426v1</guid></item><item><title>Prediction of the Most Fire-Sensitive Point in Building Structures with Differentiable Agents for Thermal Simulators</title><link>http://arxiv.org/abs/2502.03424v1</link><description>Fire safety is a critical area of research in civil and mechanicalengineering, particularly in ensuring the structural stability of buildingsduring fire events. The Most Fire-Sensitive Point (MFSP) in a structure is thelocation where a fire would cause the greatest impact on structural stability.Accurate prediction of the MFSP is vital for streamlining structuralassessments and optimizing the design process. This paper presents a novelframework for MFSP prediction using a neural network-based approach thatintegrates fire dynamics and finite element analysis through a differentiableagent model. The framework focuses on predicting the Maximum Interstory DriftRatio (MIDR), a key indicator of structural performance under fire conditions.By leveraging the differentiable agent model, we efficiently generate labeleddata for MFSP and directly train a predictor for this critical metric. Toachieve this, we generated extensive simulation data encompassing structuraland fire scenarios and employed graph neural networks to represent the buildingstructures. Transfer learning was applied to optimize the training process, andan edge update mechanism was introduced to dynamically adjust edge attributes,reflecting property changes under fire conditions. The proposed model wasrigorously evaluated on simulation data, demonstrating strong performance inaccurately predicting both MIDR and MFSP, thus advancing fire safety analysisfor building structures.</description><author>Yuan Xinjie, Khalid M. Mosalam</author><pubDate>Wed, 05 Feb 2025 18:14:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03424v1</guid></item><item><title>L-PR: Exploiting LiDAR Fiducial Marker for Unordered Low Overlap Multiview Point Cloud Registration</title><link>http://arxiv.org/abs/2406.03298v3</link><description>Point cloud registration is a prerequisite for many applications in computervision and robotics. Most existing methods focus on pairwise registration oftwo point clouds with high overlap. Although there have been some methods forlow overlap cases, they struggle in degraded scenarios. This paper introduces anovel framework dubbed L-PR, designed to register unordered low overlapmultiview point clouds leveraging LiDAR fiducial markers. We refer to them asLiDAR fiducial markers, but they are the same as the popular AprilTag and ArUcomarkers, thin sheets of paper that do not affect the 3D geometry of theenvironment. We first propose an improved adaptive threshold marker detectionmethod to provide robust detection results when the viewpoints among pointclouds change dramatically. Then, we formulate the unordered multiview pointcloud registration problem as a maximum a-posteriori (MAP) problem and developa framework consisting of two levels of graphs to address it. The first-levelgraph, constructed as a weighted graph, is designed to efficiently andoptimally infer initial values of scan poses from the unordered set. Thesecond-level graph is constructed as a factor graph. By globally optimizing thevariables on the graph, including scan poses, marker poses, and marker cornerpositions, we tackle the MAP problem. We conduct both qualitative andquantitative experiments to demonstrate that the proposed method surpassesprevious state-of-the-art (SOTA) methods and to showcase that L-PR can serve asa low-cost and efficient tool for 3D asset collection and training datacollection. In particular, we collect a new dataset named Livox-3DMatch usingL-PR and incorporate it into the training of the SOTA learning-based method,SGHR, which brings evident improvements for SGHR on various benchmarks.</description><author>Yibo Liu, Jinjun Shan, Amaldev Haridevan, Shuo Zhang</author><pubDate>Wed, 05 Feb 2025 18:13:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03298v3</guid></item><item><title>Concept Based Explanations and Class Contrasting</title><link>http://arxiv.org/abs/2502.03422v1</link><description>Explaining deep neural networks is challenging, due to their large size andnon-linearity. In this paper, we introduce a concept-based explanation method,in order to explain the prediction for an individual class, as well ascontrasting any two classes, i.e. explain why the model predicts one class overthe other. We test it on several openly available classification models trainedon ImageNet1K, as well as on a segmentation model trained to detect tumor instained tissue samples. We perform both qualitative and quantitative tests. Forexample, for a ResNet50 model from pytorch model zoo, we can use theexplanation for why the model predicts a class 'A' to automatically select sixdataset crops where the model does not predict class 'A'. The model thenpredicts class 'A' again for the newly combined image in 71\% of the cases(works for 710 out of the 1000 classes). The code including an .ipynb exampleis available on git:https://github.com/rherdt185/concept-based-explanations-and-class-contrasting.</description><author>Rudolf Herdt, Daniel Otero Baguer</author><pubDate>Wed, 05 Feb 2025 18:10:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03422v1</guid></item><item><title>Can Text-to-Image Generative Models Accurately Depict Age? A Comparative Study on Synthetic Portrait Generation and Age Estimation</title><link>http://arxiv.org/abs/2502.03420v1</link><description>Text-to-image generative models have shown remarkable progress in producingdiverse and photorealistic outputs. In this paper, we present a comprehensiveanalysis of their effectiveness in creating synthetic portraits that accuratelyrepresent various demographic attributes, with a special focus on age,nationality, and gender. Our evaluation employs prompts specifying detailedprofiles (e.g., Photorealistic selfie photo of a 32-year-old Canadian male),covering a broad spectrum of 212 nationalities, 30 distinct ages from 10 to 78,and balanced gender representation. We compare the generated images againstground truth age estimates from two established age estimation models to assesshow faithfully age is depicted. Our findings reveal that although text-to-imagemodels can consistently generate faces reflecting different identities, theaccuracy with which they capture specific ages and do so across diversedemographic backgrounds remains highly variable. These results suggest thatcurrent synthetic data may be insufficiently reliable for high-stakesage-related tasks requiring robust precision, unless practitioners are preparedto invest in significant filtering and curation. Nevertheless, they may stillbe useful in less sensitive or exploratory applications, where absolute ageprecision is not critical.</description><author>Alexey A. Novikov, Miroslav Vranka, François David, Artem Voronin</author><pubDate>Wed, 05 Feb 2025 18:08:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03420v1</guid></item><item><title>Learning Effective NeRFs and SDFs Representations with 3D Generative Adversarial Networks for 3D Object Generation</title><link>http://arxiv.org/abs/2309.16110v2</link><description>We present a solution for 3D object generation of ICCV 2023 OmniObject3DChallenge. In recent years, 3D object generation has made great process andachieved promising results, but it remains a challenging task due to thedifficulty of generating complex, textured, and high-fidelity results. Toresolve this problem, we study learning effective NeRFs and SDFsrepresentations with 3D Generative Adversarial Networks (GANs) for 3D objectgeneration. Specifically, inspired by recent works, we use the efficientgeometry-aware 3D GANs as the backbone incorporating with label embedding andcolor mapping, which enables to train the model on different taxonomiessimultaneously. Then, through a decoder, we aggregate the resulting features togenerate Neural Radiance Fields (NeRFs) based representations for renderinghigh-fidelity synthetic images. Meanwhile, we optimize Signed DistanceFunctions (SDFs) to effectively represent objects with 3D meshes. Besides, weobserve that this model can be effectively trained with only a few images ofeach object from a variety of classes, instead of using a great number ofimages per object or training one model per class. With this pipeline, we canoptimize an effective model for 3D object generation. This solution is amongthe top 3 in the ICCV 2023 OmniObject3D Challenge.</description><author>Zheyuan Yang, Yibo Liu, Guile Wu, Tongtong Cao, Yuan Ren, Yang Liu, Bingbing Liu</author><pubDate>Wed, 05 Feb 2025 18:05:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16110v2</guid></item><item><title>Think or Step-by-Step? UnZIPping the Black Box in Zero-Shot Prompts</title><link>http://arxiv.org/abs/2502.03418v1</link><description>Zero-shot prompting techniques have significantly improved the performance ofLarge Language Models (LLMs). However, we lack a clear understanding of whyzero-shot prompts are so effective. For example, in the prompt "Let's thinkstep-by-step," is "think" or "step-by-step" more crucial to its success?Existing interpretability methods, such as gradient-based and attention-basedapproaches, are computationally intensive and restricted to open-source models.We introduce the ZIP score (Zero-shot Importance of Perturbation score), aversatile metric applicable to both open and closed-source models, based onsystematic input word perturbations. Our experiments across four recent LLMs,seven widely-used prompts, and several tasks, reveal interesting patterns inword importance. For instance, while both 'step-by-step' and 'think' show highZIP scores, which one is more influential depends on the model and task. Wevalidate our method using controlled experiments and compare our results withhuman judgments, finding that proprietary models align more closely with humanintuition regarding word significance. These findings enhance our understandingof LLM behavior and contribute to developing more effective zero-shot promptsand improved model analysis.</description><author>Nikta Gohari Sadr, Sangmitra Madhusudan, Ali Emami</author><pubDate>Wed, 05 Feb 2025 18:04:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03418v1</guid></item><item><title>From Features to Transformers: Redefining Ranking for Scalable Impact</title><link>http://arxiv.org/abs/2502.03417v1</link><description>We present LiGR, a large-scale ranking framework developed at LinkedIn thatbrings state-of-the-art transformer-based modeling architectures intoproduction. We introduce a modified transformer architecture that incorporateslearned normalization and simultaneous set-wise attention to user history andranked items. This architecture enables several breakthrough achievements,including: (1) the deprecation of most manually designed feature engineering,outperforming the prior state-of-the-art system using only few features(compared to hundreds in the baseline), (2) validation of the scaling law forranking systems, showing improved performance with larger models, more trainingdata, and longer context sequences, and (3) simultaneous joint scoring of itemsin a set-wise manner, leading to automated improvements in diversity. To enableefficient serving of large ranking models, we describe techniques to scaleinference effectively using single-pass processing of user history and set-wiseattention. We also summarize key insights from various ablation studies and A/Btests, highlighting the most impactful technical approaches.</description><author>Fedor Borisyuk, Lars Hertel, Ganesh Parameswaran, Gaurav Srivastava, Sudarshan Srinivasa Ramanujam, Borja Ocejo, Peng Du, Andrei Akterskii, Neil Daftary, Shao Tang, Daqi Sun, Qiang Charles Xiao, Deepesh Nathani, Mohit Kothari, Yun Dai, Aman Gupta</author><pubDate>Wed, 05 Feb 2025 18:02:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03417v1</guid></item><item><title>Rough kernel hedging</title><link>http://arxiv.org/abs/2501.09683v2</link><description>Building on the functional-analytic framework of operator-valued kernels andun-truncated signature kernels, we propose a scalable, provably convergentsignature-based algorithm for a broad class of high-dimensional, path-dependenthedging problems. We make minimal assumptions about market dynamics bymodelling them as general geometric rough paths, yielding a fully model-freeapproach. Furthermore, through a representer theorem, we provide theoreticalguarantees on the existence and uniqueness of a global minimum for theresulting optimization problem and derive an analytic solution under highlygeneral loss functions. Similar to the popular deep hedging approach, but in amore rigorous fashion, our method can also incorporate additional features viathe underlying operator-valued kernel, such as trading signals, news analytics,and past hedging decisions, closely aligning with true machine-learningpractice.</description><author>Nicola Muca Cirone, Cristopher Salvi</author><pubDate>Wed, 05 Feb 2025 18:00:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.09683v2</guid></item><item><title>OverThink: Slowdown Attacks on Reasoning LLMs</title><link>http://arxiv.org/abs/2502.02542v2</link><description>We increase overhead for applications that rely on reasoning LLMs-we forcemodels to spend an amplified number of reasoning tokens, i.e., "overthink", torespond to the user query while providing contextually correct answers. Theadversary performs an OVERTHINK attack by injecting decoy reasoning problemsinto the public content that is used by the reasoning LLM (e.g., for RAGapplications) during inference time. Due to the nature of our decoy problems(e.g., a Markov Decision Process), modified texts do not violate safetyguardrails. We evaluated our attack across closed-(OpenAI o1, o1-mini, o3-mini)and open-(DeepSeek R1) weights reasoning models on the FreshQA and SQuADdatasets. Our results show up to 18x slowdown on FreshQA dataset and 46xslowdown on SQuAD dataset. The attack also shows high transferability acrossmodels. To protect applications, we discuss and implement defenses leveragingLLM-based and system design approaches. Finally, we discuss societal,financial, and energy impacts of OVERTHINK attack which could amplify the costsfor third-party applications operating reasoning models.</description><author>Abhinav Kumar, Jaechul Roh, Ali Naseh, Marzena Karpinska, Mohit Iyyer, Amir Houmansadr, Eugene Bagdasarian</author><pubDate>Wed, 05 Feb 2025 17:58:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.02542v2</guid></item><item><title>Deep Reinforcement Learning-Based Optimization of Second-Life Battery Utilization in Electric Vehicles Charging Stations</title><link>http://arxiv.org/abs/2502.03412v1</link><description>The rapid rise in electric vehicle (EV) adoption presents significantchallenges in managing the vast number of retired EV batteries. Researchindicates that second-life batteries (SLBs) from EVs typically retainconsiderable residual capacity, offering extended utility. These batteries canbe effectively repurposed for use in EV charging stations (EVCS), providing acost-effective alternative to new batteries and reducing overall planningcosts. Integrating battery energy storage systems (BESS) with SLBs into EVCS isa promising strategy to alleviate system overload. However, efficient operationof EVCS with integrated BESS is hindered by uncertainties such as fluctuatingEV arrival and departure times and variable power prices from the grid. Thispaper presents a deep reinforcement learning-based (DRL) planning framework forEV charging stations with BESS, leveraging SLBs. We employ the advanced softactor-critic (SAC) approach, training the model on a year's worth of data toaccount for seasonal variations, including weekdays and holidays. A tailoredreward function enables effective offline training, allowing real-timeoptimization of EVCS operations under uncertainty.</description><author>Rouzbeh Haghighi, Ali Hassan, Van-Hai Bui, Akhtar Hussain, Wencong Su</author><pubDate>Wed, 05 Feb 2025 17:50:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03412v1</guid></item><item><title>Detecting Strategic Deception Using Linear Probes</title><link>http://arxiv.org/abs/2502.03407v1</link><description>AI models might use deceptive strategies as part of scheming or misalignedbehaviour. Monitoring outputs alone is insufficient, since the AI might produceseemingly benign outputs while their internal reasoning is misaligned. We thusevaluate if linear probes can robustly detect deception by monitoring modelactivations. We test two probe-training datasets, one with contrastinginstructions to be honest or deceptive (following Zou et al., 2023) and one ofresponses to simple roleplaying scenarios. We test whether these probesgeneralize to realistic settings where Llama-3.3-70B-Instruct behavesdeceptively, such as concealing insider trading (Scheurer et al., 2023) andpurposely underperforming on safety evaluations (Benton et al., 2024). We findthat our probe distinguishes honest and deceptive responses with AUROCs between0.96 and 0.999 on our evaluation datasets. If we set the decision threshold tohave a 1% false positive rate on chat data not related to deception, our probecatches 95-99% of the deceptive responses. Overall we think white-box probesare promising for future monitoring systems, but current performance isinsufficient as a robust defence against deception. Our probes' outputs can beviewed at data.apolloresearch.ai/dd and our code atgithub.com/ApolloResearch/deception-detection.</description><author>Nicholas Goldowsky-Dill, Bilal Chughtai, Stefan Heimersheim, Marius Hobbhahn</author><pubDate>Wed, 05 Feb 2025 17:49:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03407v1</guid></item><item><title>Deep Clustering via Probabilistic Ratio-Cut Optimization</title><link>http://arxiv.org/abs/2502.03405v1</link><description>We propose a novel approach for optimizing the graph ratio-cut by modelingthe binary assignments as random variables. We provide an upper bound on theexpected ratio-cut, as well as an unbiased estimate of its gradient, to learnthe parameters of the assignment variables in an online setting. The clusteringresulting from our probabilistic approach (PRCut) outperforms the Rayleighquotient relaxation of the combinatorial problem, its online learningextensions, and several widely used methods. We demonstrate that the PRCutclustering closely aligns with the similarity measure and can perform as wellas a supervised classifier when label-based similarities are provided. Thisnovel approach can leverage out-of-the-box self-supervised representations toachieve competitive performance and serve as an evaluation method for thequality of these representations.</description><author>Ayoub Ghriss, Claire Monteleoni</author><pubDate>Wed, 05 Feb 2025 17:47:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03405v1</guid></item><item><title>Simple Is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation</title><link>http://arxiv.org/abs/2410.20724v4</link><description>Large Language Models (LLMs) demonstrate strong reasoning abilities but facelimitations such as hallucinations and outdated knowledge. Knowledge Graph(KG)-based Retrieval-Augmented Generation (RAG) addresses these issues bygrounding LLM outputs in structured external knowledge from KGs. However,current KG-based RAG frameworks still struggle to optimize the trade-offbetween retrieval effectiveness and efficiency in identifying a suitable amountof relevant graph information for the LLM to digest. We introduce SubgraphRAG,extending the KG-based RAG framework that retrieves subgraphs and leveragesLLMs for reasoning and answer prediction. Our approach innovatively integratesa lightweight multilayer perceptron with a parallel triple-scoring mechanismfor efficient and flexible subgraph retrieval while encoding directionalstructural distances to enhance retrieval effectiveness. The size of retrievedsubgraphs can be flexibly adjusted to match the query's need and the downstreamLLM's capabilities. This design strikes a balance between model complexity andreasoning power, enabling scalable and generalizable retrieval processes.Notably, based on our retrieved subgraphs, smaller LLMs likeLlama3.1-8B-Instruct deliver competitive results with explainable reasoning,while larger models like GPT-4o achieve state-of-the-art accuracy compared withprevious baselines -- all without fine-tuning. Extensive evaluations on theWebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency,accuracy, and reliability by reducing hallucinations and improving responsegrounding.</description><author>Mufei Li, Siqi Miao, Pan Li</author><pubDate>Wed, 05 Feb 2025 17:45:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20724v4</guid></item><item><title>Lightweight Authenticated Task Offloading in 6G-Cloud Vehicular Twin Networks</title><link>http://arxiv.org/abs/2502.03403v1</link><description>Task offloading management in 6G vehicular networks is crucial formaintaining network efficiency, particularly as vehicles generate substantialdata. Integrating secure communication through authentication introducesadditional computational and communication overhead, significantly impactingoffloading efficiency and latency. This paper presents a unified frameworkincorporating lightweight Identity-Based Cryptographic (IBC) authenticationinto task offloading within cloud-based 6G Vehicular Twin Networks (VTNs).Utilizing Proximal Policy Optimization (PPO) in Deep Reinforcement Learning(DRL), our approach optimizes authenticated offloading decisions to minimizelatency and enhance resource allocation. Performance evaluation under varyingnetwork sizes, task sizes, and data rates reveals that IBC authentication canreduce offloading efficiency by up to 50% due to the added overhead. Besides,increasing network size and task size can further reduce offloading efficiencyby up to 91.7%. As a countermeasure, increasing the transmission data rate canimprove the offloading performance by as much as 63%, even in the presence ofauthentication overhead. The code for the simulations and experiments detailedin this paper is available on GitHub for further reference and reproducibility[1].</description><author>Sarah Al-Shareeda, Fusun Ozguner, Keith Redmill, Trung Q. Duong, Berk Canberk</author><pubDate>Wed, 05 Feb 2025 17:43:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03403v1</guid></item><item><title>ExploreSelf: Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models</title><link>http://arxiv.org/abs/2409.09662v3</link><description>Expressing stressful experiences in words is proven to improve mental andphysical health, but individuals often disengage with writing interventions asthey struggle to organize their thoughts and emotions. Reflective prompts havebeen used to provide direction, and large language models (LLMs) havedemonstrated the potential to provide tailored guidance. However, currentsystems often limit users' flexibility to direct their reflections. We thuspresent ExploreSelf, an LLM-driven application designed to empower users tocontrol their reflective journey, providing adaptive support throughdynamically generated questions. Through an exploratory study with 19participants, we examine how participants explore and reflect on personalchallenges using ExploreSelf. Our findings demonstrate that participants valuedthe flexible navigation of adaptive guidance to control their reflectivejourney, leading to deeper engagement and insight. Building on our findings, wediscuss the implications of designing LLM-driven tools that facilitateuser-driven and effective reflection of personal challenges.</description><author>Inhwa Song, SoHyun Park, Sachin R. Pendse, Jessica Lee Schleider, Munmun De Choudhury, Young-Ho Kim</author><pubDate>Wed, 05 Feb 2025 17:41:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.09662v3</guid></item><item><title>Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation</title><link>http://arxiv.org/abs/2502.02464v2</link><description>Retrieval, re-ranking, and retrieval-augmented generation (RAG) are criticalcomponents of modern natural language processing (NLP) applications ininformation retrieval, question answering, and knowledge-based text generation.However, existing solutions are often fragmented, lacking a unified frameworkthat easily integrates these essential processes. The absence of a standardizedimplementation, coupled with the complexity of retrieval and re-rankingworkflows, makes it challenging for researchers to compare and evaluatedifferent approaches in a consistent environment. While existing toolkits suchas Rerankers and RankLLM provide general-purpose reranking pipelines, theyoften lack the flexibility required for fine-grained experimentation andbenchmarking. In response to these challenges, we introduce \textbf{Rankify}, apowerful and modular open-source toolkit designed to unify retrieval,re-ranking, and RAG within a cohesive framework. Rankify supports a wide rangeof retrieval techniques, including dense and sparse retrievers, whileincorporating state-of-the-art re-ranking models to enhance retrieval quality.Additionally, Rankify includes a collection of pre-retrieved datasets tofacilitate benchmarking, available at Huggingface(https://huggingface.co/datasets/abdoelsayed/reranking-datasets). To encourageadoption and ease of integration, we provide comprehensive documentation(http://rankify.readthedocs.io/), an open-source implementation onGitHub(https://github.com/DataScienceUIBK/rankify), and a PyPI package foreffortless installation(https://pypi.org/project/rankify/). By providing aunified and lightweight framework, Rankify allows researchers and practitionersto advance retrieval and re-ranking methodologies while ensuring consistency,scalability, and ease of use.</description><author>Abdelrahman Abdallah, Bhawna Piryani, Jamshid Mozafari, Mohammed Ali, Adam Jatowt</author><pubDate>Wed, 05 Feb 2025 17:38:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.02464v2</guid></item><item><title>Markov chain Monte Carlo without evaluating the target: an auxiliary variable approach</title><link>http://arxiv.org/abs/2406.05242v3</link><description>In sampling tasks, it is common for target distributions to be known up to anormalizing constant. However, in many situations, even evaluating theunnormalized distribution can be costly or infeasible. This issue arises inscenarios such as sampling from the Bayesian posterior for tall datasets andthe 'doubly-intractable' distributions. In this paper, we begin by observingthat seemingly different Markov chain Monte Carlo (MCMC) algorithms, such asthe exchange algorithm, PoissonMH, and TunaMH, can be unified under a simplecommon procedure. We then extend this procedure into a novel framework thatallows the use of auxiliary variables in both the proposal and theacceptance-rejection step. Several new MCMC algorithms emerge from thisframework that utilize estimated gradients to guide the proposal moves. Theyhave demonstrated significantly better performance than existing methods onboth synthetic and real datasets. Additionally, we develop the theory of thenew framework and apply it to existing algorithms to simplify and extend theirresults.</description><author>Wei Yuan, Guanyang Wang</author><pubDate>Wed, 05 Feb 2025 17:35:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05242v3</guid></item><item><title>SPRI: Aligning Large Language Models with Context-Situated Principles</title><link>http://arxiv.org/abs/2502.03397v1</link><description>Aligning Large Language Models to integrate and reflect human values,especially for tasks that demand intricate human oversight, is arduous since itis resource-intensive and time-consuming to depend on human expertise forcontext-specific guidance. Prior work has utilized predefined sets of rules orprinciples to steer the behavior of models (Bai et al., 2022; Sun et al.,2023). However, these principles tend to be generic, making it challenging toadapt them to each individual input query or context. In this work, we presentSituated-PRInciples (SPRI), a framework requiring minimal or no human effortthat is designed to automatically generate guiding principles in real-time foreach input query and utilize them to align each response. We evaluate SPRI onthree tasks, and show that 1) SPRI can derive principles in a complexdomain-specific task that leads to on-par performance as expert-crafted ones;2) SPRI-generated principles lead to instance-specific rubrics that outperformprior LLM-as-a-judge frameworks; 3) using SPRI to generate synthetic SFT dataleads to substantial improvement on truthfulness. We release our code and modelgenerations at https://github.com/honglizhan/SPRI-public.</description><author>Hongli Zhan, Muneeza Azmat, Raya Horesh, Junyi Jessy Li, Mikhail Yurochkin</author><pubDate>Wed, 05 Feb 2025 17:32:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03397v1</guid></item><item><title>Accurate AI-Driven Emergency Vehicle Location Tracking in Healthcare ITS Digital Twin</title><link>http://arxiv.org/abs/2502.03396v1</link><description>Creating a Digital Twin (DT) for Healthcare Intelligent TransportationSystems (HITS) is a hot research trend focusing on enhancing HITS management,particularly in emergencies where ambulance vehicles must arrive at the crashscene on time and track their real-time location is crucial to the medicalauthorities. Despite the claim of real-time representation, a temporalmisalignment persists between the physical and virtual domains, leading todiscrepancies in the ambulance's location representation. This study proposesintegrating AI predictive models, specifically Support Vector Regression (SVR)and Deep Neural Networks (DNN), within a constructed mock DT data pipelineframework to anticipate the medical vehicle's next location in the virtualworld. These models align virtual representations with their physicalcounterparts, i.e., metaphorically offsetting the synchronization delay betweenthe two worlds. Trained meticulously on a historical geospatial dataset, SVRand DNN exhibit exceptional prediction accuracy in MATLAB and Pythonenvironments. Through various testing scenarios, we visually demonstrate theefficacy of our methodology, showcasing SVR and DNN's key role in significantlyreducing the witnessed gap within the HITS's DT. This transformative approachenhances real-time synchronization in emergency HITS by approximately 88% to93%.</description><author>Sarah Al-Shareeda, Yasar Celik, Bilge Bilgili, Ahmed Al-Dubai, Berk Canberk</author><pubDate>Wed, 05 Feb 2025 17:32:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03396v1</guid></item><item><title>Benchmarking Time Series Forecasting Models: From Statistical Techniques to Foundation Models in Real-World Applications</title><link>http://arxiv.org/abs/2502.03395v1</link><description>Time series forecasting is essential for operational intelligence in thehospitality industry, and particularly challenging in large-scale, distributedsystems. This study evaluates the performance of statistical, machine learning(ML), deep learning, and foundation models in forecasting hourly sales over a14-day horizon using real-world data from a network of thousands of restaurantsacross Germany. The forecasting solution includes features such as weatherconditions, calendar events, and time-of-day patterns. Results demonstrate thestrong performance of ML-based meta-models and highlight the emerging potentialof foundation models like Chronos and TimesFM, which deliver competitiveperformance with minimal feature engineering, leveraging only the pre-trainedmodel (zero-shot inference). Additionally, a hybrid PySpark-Pandas approachproves to be a robust solution for achieving horizontal scalability inlarge-scale deployments.</description><author>Issar Arab, Rodrigo Benitez</author><pubDate>Wed, 05 Feb 2025 17:30:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03395v1</guid></item><item><title>Predicting Future States with Spatial Point Processes in Single Molecule Resolution Spatial Transcriptomics</title><link>http://arxiv.org/abs/2401.02564v2</link><description>In this paper, we introduce a pipeline based on XGboost to predict the futuredistribution of cells that are expressed by the Sog-D gene (active cells) inboth the Anterior to posterior (AP) and the Dorsal to Ventral (DV) axis of theDrosophila in embryogenesis process. This method provides insights about howcells and living organisms control gene expression in super resolution wholeembryo spatial transcriptomics imaging at sub cellular, single moleculeresolution. An XGboost model was used to predict the next stage activedistribution based on the previous one. To achieve this goal, we leveragedtemporally resolved, spatial point processes by including Ripley's K-functionin conjunction with the cell's state in each stage of embryogenesis, and foundaverage predictive accuracy of active cell distribution. This tool is analogousto RNA Velocity for spatially resolved developmental biology, from one datapoint we can predict future spatially resolved gene expression using featuresfrom the spatial point processes.</description><author>Biraaj Rout, Priyanshi Borad, Parisa Boodaghi Malidarreh, Mohammad Sadegh Nasr, Jillur Rahman Saurav, Kelli Fenelon, Jai Prakash Veerla, Jacob M. Luber, Theodora Koromila</author><pubDate>Wed, 05 Feb 2025 17:29:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02564v2</guid></item><item><title>CAPE: Covariate-Adjusted Pre-Training for Epidemic Time Series Forecasting</title><link>http://arxiv.org/abs/2502.03393v1</link><description>Accurate forecasting of epidemic infection trajectories is crucial forsafeguarding public health. However, limited data availability during emergingoutbreaks and the complex interaction between environmental factors and diseasedynamics present significant challenges for effective forecasting. In response,we introduce CAPE, a novel epidemic pre-training framework designed to harnessextensive disease datasets from diverse regions and integrate environmentalfactors directly into the modeling process for more informed decision-making ondownstream diseases. Based on a covariate adjustment framework, CAPE utilizespre-training combined with hierarchical environment contrasting to identifyuniversal patterns across diseases while estimating latent environmentalinfluences. We have compiled a diverse collection of epidemic time seriesdatasets and validated the effectiveness of CAPE under various evaluationscenarios, including full-shot, few-shot, zero-shot, cross-location, andcross-disease settings, where it outperforms the leading baseline by an averageof 9.9% in full-shot and 14.3% in zero-shot settings. The code will be releasedupon acceptance.</description><author>Zewen Liu, Juntong Ni, Max S. Y. Lau, Wei Jin</author><pubDate>Wed, 05 Feb 2025 17:29:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03393v1</guid></item><item><title>Explain Yourself, Briefly! Self-Explaining Neural Networks with Concise Sufficient Reasons</title><link>http://arxiv.org/abs/2502.03391v1</link><description>Minimal sufficient reasons represent a prevalent form of explanation - thesmallest subset of input features which, when held constant at theircorresponding values, ensure that the prediction remains unchanged. Previouspost-hoc methods attempt to obtain such explanations but face two mainlimitations: (1) Obtaining these subsets poses a computational challenge,leading most scalable methods to converge towards suboptimal, less meaningfulsubsets; (2) These methods heavily rely on sampling out-of-distribution inputassignments, potentially resulting in counterintuitive behaviors. To tacklethese limitations, we propose in this work a self-supervised training approach,which we term *sufficient subset training* (SST). Using SST, we train models togenerate concise sufficient reasons for their predictions as an integral partof their output. Our results indicate that our framework produces succinct andfaithful subsets substantially more efficiently than competing post-hocmethods, while maintaining comparable predictive performance.</description><author>Shahaf Bassan, Shlomit Gur, Ron Eliav</author><pubDate>Wed, 05 Feb 2025 17:29:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03391v1</guid></item><item><title>CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing</title><link>http://arxiv.org/abs/2502.01976v2</link><description>Large language models have achieved remarkable success in various tasks butsuffer from high computational costs during inference, limiting theirdeployment in resource-constrained applications. To address this issue, wepropose a novel CITER (\textbf{C}ollaborative \textbf{I}nference with\textbf{T}oken-l\textbf{E}vel \textbf{R}outing) framework that enablesefficient collaboration between small and large language models (SLMs &amp; LLMs)through a token-level routing strategy. Specifically, CITER routes non-criticaltokens to an SLM for efficiency and routes critical tokens to an LLM forgeneralization quality. We formulate router training as a policy optimization,where the router receives rewards based on both the quality of predictions andthe inference costs of generation. This allows the router to learn to predicttoken-level routing scores and make routing decisions based on both the currenttoken and the future impact of its decisions. To further accelerate the rewardevaluation process, we introduce a shortcut which significantly reduces thecosts of the reward estimation and improving the practicality of our approach.Extensive experiments on five benchmark datasets demonstrate that CITER reducesthe inference costs while preserving high-quality generation, offering apromising solution for real-time and resource-constrained applications.</description><author>Wenhao Zheng, Yixiao Chen, Weitong Zhang, Souvik Kundu, Yun Li, Zhengzhong Liu, Eric P. Xing, Hongyi Wang, Huaxiu Yao</author><pubDate>Wed, 05 Feb 2025 17:26:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.01976v2</guid></item><item><title>LIMO: Less is More for Reasoning</title><link>http://arxiv.org/abs/2502.03387v1</link><description>We present a fundamental discovery that challenges our understanding of howcomplex reasoning emerges in large language models. While conventional wisdomsuggests that sophisticated reasoning tasks demand extensive training data(&gt;100,000 examples), we demonstrate that complex mathematical reasoningabilities can be effectively elicited with surprisingly few examples. Throughcomprehensive experiments, our proposed model LIMO demonstrates unprecedentedperformance in mathematical reasoning. With merely 817 curated trainingsamples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving fromprevious SFT-based models' 6.5% and 59.2% respectively, while only using 1% ofthe training data required by previous approaches. LIMO demonstratesexceptional out-of-distribution generalization, achieving 40.5% absoluteimprovement across 10 diverse benchmarks, outperforming models trained on 100xmore data, challenging the notion that SFT leads to memorization rather thangeneralization. Based on these results, we propose the Less-Is-More ReasoningHypothesis (LIMO Hypothesis): In foundation models where domain knowledge hasbeen comprehensively encoded during pre-training, sophisticated reasoningcapabilities can emerge through minimal but precisely orchestrateddemonstrations of cognitive processes. This hypothesis posits that theelicitation threshold for complex reasoning is determined by two key factors:(1) the completeness of the model's encoded knowledge foundation duringpre-training, and (2) the effectiveness of post-training examples as "cognitivetemplates" that show the model how to utilize its knowledge base to solvecomplex reasoning tasks. To facilitate reproducibility and future research indata-efficient reasoning, we release LIMO as a comprehensive open-source suiteat https://github.com/GAIR-NLP/LIMO.</description><author>Yixin Ye, Zhen Huang, Yang Xiao, Ethan Chern, Shijie Xia, Pengfei Liu</author><pubDate>Wed, 05 Feb 2025 17:23:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03387v1</guid></item><item><title>A Structured Reasoning Framework for Unbalanced Data Classification Using Probabilistic Models</title><link>http://arxiv.org/abs/2502.03386v1</link><description>This paper studies a Markov network model for unbalanced data, aiming tosolve the problems of classification bias and insufficient minority classrecognition ability of traditional machine learning models in environments withuneven class distribution. By constructing joint probability distribution andconditional dependency, the model can achieve global modeling and reasoningoptimization of sample categories. The study introduced marginal probabilityestimation and weighted loss optimization strategies, combined withregularization constraints and structured reasoning methods, effectivelyimproving the generalization ability and robustness of the model. In theexperimental stage, a real credit card fraud detection dataset was selected andcompared with models such as logistic regression, support vector machine,random forest and XGBoost. The experimental results show that the Markovnetwork performs well in indicators such as weighted accuracy, F1 score, andAUC-ROC, significantly outperforming traditional classification models,demonstrating its strong decision-making ability and applicability inunbalanced data scenarios. Future research can focus on efficient modeltraining, structural optimization, and deep learning integration in large-scaleunbalanced data environments and promote its wide application in practicalapplications such as financial risk control, medical diagnosis, and intelligentmonitoring.</description><author>Junliang Du, Shiyu Dou, Bohuan Yang, Jiacheng Hu, Tai An</author><pubDate>Wed, 05 Feb 2025 17:20:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03386v1</guid></item><item><title>Transformers and Their Roles as Time Series Foundation Models</title><link>http://arxiv.org/abs/2502.03383v1</link><description>We give a comprehensive analysis of transformers as time series foundationmodels, focusing on their approximation and generalization capabilities. First,we demonstrate that there exist transformers that fit an autoregressive modelon input univariate time series via gradient descent. We then analyze MOIRAI, amultivariate time series foundation model capable of handling an arbitrarynumber of covariates. We prove that it is capable of automatically fittingautoregressive models with an arbitrary number of covariates, offering insightsinto its design and empirical success. For generalization, we establish boundsfor pretraining when the data satisfies Dobrushin's condition. Experimentssupport our theoretical findings, highlighting the efficacy of transformers astime series foundation models.</description><author>Dennis Wu, Yihan He, Yuan Cao, Jianqing Fan, Han Liu</author><pubDate>Wed, 05 Feb 2025 17:18:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03383v1</guid></item><item><title>High-Fidelity Simultaneous Speech-To-Speech Translation</title><link>http://arxiv.org/abs/2502.03382v1</link><description>We introduce Hibiki, a decoder-only model for simultaneous speechtranslation. Hibiki leverages a multistream language model to synchronouslyprocess source and target speech, and jointly produces text and audio tokens toperform speech-to-text and speech-to-speech translation. We furthermore addressthe fundamental challenge of simultaneous interpretation, which unlike itsconsecutive counterpart, where one waits for the end of the source utterance tostart translating, adapts its flow to accumulate just enough context to producea correct translation in real-time, chunk by chunk. To do so, we introduce aweakly-supervised method that leverages the perplexity of an off-the-shelf texttranslation system to identify optimal delays on a per-word basis and createaligned synthetic data. After supervised training, Hibiki performs adaptive,simultaneous speech translation with vanilla temperature sampling. On aFrench-English simultaneous speech translation task, Hibiki demonstratesstate-of-the-art performance in translation quality, speaker fidelity andnaturalness. Moreover, the simplicity of its inference process makes itcompatible with batched translation and even real-time on-device deployment. Weprovide examples as well as models and inference code.</description><author>Tom Labiausse, Laurent Mazaré, Edouard Grave, Patrick Pérez, Alexandre Défossez, Neil Zeghidour</author><pubDate>Wed, 05 Feb 2025 17:18:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03382v1</guid></item><item><title>Integrating automatic speech recognition into remote healthcare interpreting: A pilot study of its impact on interpreting quality</title><link>http://arxiv.org/abs/2502.03381v1</link><description>This paper reports on the results from a pilot study investigating the impactof automatic speech recognition (ASR) technology on interpreting quality inremote healthcare interpreting settings. Employing a within-subjects experimentdesign with four randomised conditions, this study utilises scripted medicalconsultations to simulate dialogue interpreting tasks. It involves four traineeinterpreters with a language combination of Chinese and English. It alsogathers participants' experience and perceptions of ASR support through cuedretrospective reports and semi-structured interviews. Preliminary data suggestthat the availability of ASR, specifically the access to full ASR transcriptsand to ChatGPT-generated summaries based on ASR, effectively improvedinterpreting quality. Varying types of ASR output had different impacts on thedistribution of interpreting error types. Participants reported similarinteractive experiences with the technology, expressing their preference forfull ASR transcripts. This pilot study shows encouraging results of applyingASR to dialogue-based healthcare interpreting and offers insights into theoptimal ways to present ASR output to enhance interpreter experience andperformance. However, it should be emphasised that the main purpose of thisstudy was to validate the methodology and that further research with a largersample size is necessary to confirm these findings.</description><author>Shiyi Tan, Constantin Orăsan, Sabine Braun</author><pubDate>Wed, 05 Feb 2025 17:17:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03381v1</guid></item><item><title>Energy-Efficient Flying LoRa Gateways: A Multi-Agent Reinforcement Learning Approach</title><link>http://arxiv.org/abs/2502.03377v1</link><description>With the rapid development of next-generation Internet of Things (NG-IoT)networks, the increasing number of connected devices has led to a surge inpower consumption. This rise in energy demand poses significant challenges toresource availability and raises sustainability concerns for large-scale IoTdeployments. Efficient energy utilization in communication networks,particularly for power-constrained IoT devices, has thus become a critical areaof research. In this paper, we deployed flying LoRa gateways (GWs) mounted onunmanned aerial vehicles (UAVs) to collect data from LoRa end devices (EDs) andtransmit it to a central server. Our primary objective is to maximize theglobal system energy efficiency (EE) of wireless LoRa networks by jointoptimization of transmission power (TP), spreading factor (SF), bandwidth (W),and ED association. To solve this challenging problem, we model the problem asa partially observable Markov decision process (POMDP), where each flying LoRaGW acts as a learning agent using a cooperative Multi-Agent ReinforcementLearning (MARL) approach under centralized training and decentralized execution(CTDE). Simulation results demonstrate that our proposed method, based on themulti-agent proximal policy optimization (MAPPO) algorithm, significantlyimproves the global system EE and surpasses the conventional MARL schemes.</description><author>Abdullahi Isa Ahmed, El Mehdi Amhoud</author><pubDate>Wed, 05 Feb 2025 17:16:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03377v1</guid></item><item><title>Ethical Considerations for the Military Use of Artificial Intelligence in Visual Reconnaissance</title><link>http://arxiv.org/abs/2502.03376v1</link><description>This white paper underscores the critical importance of responsibly deployingArtificial Intelligence (AI) in military contexts, emphasizing a commitment toethical and legal standards. The evolving role of AI in the military goesbeyond mere technical applications, necessitating a framework grounded inethical principles. The discussion within the paper delves into ethical AIprinciples, particularly focusing on the Fairness, Accountability,Transparency, and Ethics (FATE) guidelines. Noteworthy considerations encompasstransparency, justice, non-maleficence, and responsibility. Importantly, thepaper extends its examination to military-specific ethical considerations,drawing insights from the Just War theory and principles established byprominent entities. In addition to the identified principles, the paperintroduces further ethical considerations specifically tailored for military AIapplications. These include traceability, proportionality, governability,responsibility, and reliability. The application of these ethical principles isdiscussed on the basis of three use cases in the domains of sea, air, and land.Methods of automated sensor data analysis, eXplainable AI (XAI), and intuitiveuser experience are utilized to specify the use cases close to real-worldscenarios. This comprehensive approach to ethical considerations in military AIreflects a commitment to aligning technological advancements with establishedethical frameworks. It recognizes the need for a balance between leveragingAI's potential benefits in military operations while upholding moral and legalstandards. The inclusion of these ethical principles serves as a foundation forresponsible and accountable use of AI in the complex and dynamic landscape ofmilitary scenarios.</description><author>Mathias Anneken, Nadia Burkart, Fabian Jeschke, Achim Kuwertz-Wolf, Almuth Mueller, Arne Schumann, Michael Teutsch</author><pubDate>Wed, 05 Feb 2025 17:16:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03376v1</guid></item><item><title>Demystifying Long Chain-of-Thought Reasoning in LLMs</title><link>http://arxiv.org/abs/2502.03373v1</link><description>Scaling inference compute enhances reasoning in large language models (LLMs),with long chains-of-thought (CoTs) enabling strategies like backtracking anderror correction. Reinforcement learning (RL) has emerged as a crucial methodfor developing these capabilities, yet the conditions under which long CoTsemerge remain unclear, and RL training requires careful design choices. In thisstudy, we systematically investigate the mechanics of long CoT reasoning,identifying the key factors that enable models to generate long CoTtrajectories. Through extensive supervised fine-tuning (SFT) and RLexperiments, we present four main findings: (1) While SFT is not strictlynecessary, it simplifies training and improves efficiency; (2) Reasoningcapabilities tend to emerge with increased training compute, but theirdevelopment is not guaranteed, making reward shaping crucial for stabilizingCoT length growth; (3) Scaling verifiable reward signals is critical for RL. Wefind that leveraging noisy, web-extracted solutions with filtering mechanismsshows strong potential, particularly for out-of-distribution (OOD) tasks suchas STEM reasoning; and (4) Core abilities like error correction are inherentlypresent in base models, but incentivizing these skills effectively for complextasks via RL demands significant compute, and measuring their emergencerequires a nuanced approach. These insights provide practical guidance foroptimizing training strategies to enhance long CoT reasoning in LLMs. Our codeis available at: https://github.com/eddycmu/demystify-long-cot.</description><author>Edward Yeo, Yuxuan Tong, Morry Niu, Graham Neubig, Xiang Yue</author><pubDate>Wed, 05 Feb 2025 17:13:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03373v1</guid></item><item><title>Shift of Pairwise Similarities for Data Clustering</title><link>http://arxiv.org/abs/2110.13103v3</link><description>Several clustering methods (e.g., Normalized Cut and Ratio Cut) divide theMin Cut cost function by a cluster dependent factor (e.g., the size or thedegree of the clusters), in order to yield a more balanced partitioning. We,instead, investigate adding such regularizations to the original cost function.We first consider the case where the regularization term is the sum of thesquared size of the clusters, and then generalize it to adaptive regularizationof the pairwise similarities. This leads to shifting (adaptively) the pairwisesimilarities which might make some of them negative. We then study theconnection of this method to Correlation Clustering and then propose anefficient local search optimization algorithm with fast theoretical convergencerate to solve the new clustering problem. In the following, we investigate theshift of pairwise similarities on some common clustering methods, and finally,we demonstrate the superior performance of the method by extensive experimentson different datasets.</description><author>Morteza Haghir Chehreghani</author><pubDate>Wed, 05 Feb 2025 17:12:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.13103v3</guid></item><item><title>Deep Learning-Based Approach for Identification of Potato Leaf Diseases Using Wrapper Feature Selection and Feature Concatenation</title><link>http://arxiv.org/abs/2502.03370v1</link><description>The potato is a widely grown crop in many regions of the world. In recentdecades, potato farming has gained incredible traction in the world. Potatoesare susceptible to several illnesses that stunt their development. This plantseems to have significant leaf disease. Early Blight and Late Blight are twoprevalent leaf diseases that affect potato plants. The early detection of thesediseases would be beneficial for enhancing the yield of this crop. The idealsolution is to use image processing to identify and analyze these disorders.Here, we present an autonomous method based on image processing and machinelearning to detect late blight disease affecting potato leaves. The proposedmethod comprises four different phases: (1) Histogram Equalization is used toimprove the quality of the input image; (2) feature extraction is performedusing a Deep CNN model, then these extracted features are concatenated; (3)feature selection is performed using wrapper-based feature selection; (4)classification is performed using an SVM classifier and its variants. Thisproposed method achieves the highest accuracy of 99% using SVM by selecting 550features.</description><author>Muhammad Ahtsam Naeem, Muhammad Asim Saleem, Muhammad Imran Sharif, Shahzad Akber, Sajjad Saleem, Zahid Akhtar, Kamran Siddique</author><pubDate>Wed, 05 Feb 2025 17:09:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03370v1</guid></item><item><title>Agent-OM: Leveraging LLM Agents for Ontology Matching</title><link>http://arxiv.org/abs/2312.00326v8</link><description>Ontology matching (OM) enables semantic interoperability between differentontologies and resolves their conceptual heterogeneity by aligning relatedentities. OM systems currently have two prevailing design paradigms:conventional knowledge-based expert systems and newer machine learning-basedpredictive systems. While large language models (LLMs) and LLM agents haverevolutionised data engineering and have been applied creatively in manydomains, their potential for OM remains underexplored. This study introduces anovel agent-powered LLM-based design paradigm for OM systems. Withconsideration of several specific challenges in leveraging LLM agents for OM,we propose a generic framework, namely Agent-OM (Agent for Ontology Matching),consisting of two Siamese agents for retrieval and matching, with a set of OMtools. Our framework is implemented in a proof-of-concept system. Evaluationsof three Ontology Alignment Evaluation Initiative (OAEI) tracks overstate-of-the-art OM systems show that our system can achieve results very closeto the long-standing best performance on simple OM tasks and can significantlyimprove the performance on complex and few-shot OM tasks.</description><author>Zhangcheng Qiang, Weiqing Wang, Kerry Taylor</author><pubDate>Wed, 05 Feb 2025 17:08:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00326v8</guid></item><item><title>Learning from Active Human Involvement through Proxy Value Propagation</title><link>http://arxiv.org/abs/2502.03369v1</link><description>Learning from active human involvement enables the human subject to activelyintervene and demonstrate to the AI agent during training. The interaction andcorrective feedback from human brings safety and AI alignment to the learningprocess. In this work, we propose a new reward-free active human involvementmethod called Proxy Value Propagation for policy optimization. Our key insightis that a proxy value function can be designed to express human intents,wherein state-action pairs in the human demonstration are labeled with highvalues, while those agents' actions that are intervened receive low values.Through the TD-learning framework, labeled values of demonstrated state-actionpairs are further propagated to other unlabeled data generated from agents'exploration. The proxy value function thus induces a policy that faithfullyemulates human behaviors. Human-in-the-loop experiments show the generality andefficiency of our method. With minimal modification to existing reinforcementlearning algorithms, our method can learn to solve continuous and discretecontrol tasks with various human control devices, including the challengingtask of driving in Grand Theft Auto V. Demo video and code are available at:https://metadriverse.github.io/pvp</description><author>Zhenghao Peng, Wenjie Mo, Chenda Duan, Quanyi Li, Bolei Zhou</author><pubDate>Wed, 05 Feb 2025 17:07:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03369v1</guid></item><item><title>PalimpChat: Declarative and Interactive AI analytics</title><link>http://arxiv.org/abs/2502.03368v1</link><description>Thanks to the advances in generative architectures and large language models,data scientists can now code pipelines of machine-learning operations toprocess large collections of unstructured data. Recent progress has seen therise of declarative AI frameworks (e.g., Palimpzest, Lotus, and DocETL) tobuild optimized and increasingly complex pipelines, but these systems oftenremain accessible only to expert programmers. In this demonstration, we presentPalimpChat, a chat-based interface to Palimpzest that bridges this gap byletting users create and run sophisticated AI pipelines through naturallanguage alone. By integrating Archytas, a ReAct-based reasoning agent, andPalimpzest's suite of relational and LLM-based operators, PalimpChat provides apractical illustration of how a chat interface can make declarative AIframeworks truly accessible to non-experts. Our demo system is publicly available online. At SIGMOD'25, participants canexplore three real-world scenarios--scientific discovery, legal discovery, andreal estate search--or apply PalimpChat to their own datasets. In this paper,we focus on how PalimpChat, supported by the Palimpzest optimizer, simplifiescomplex AI workflows such as extracting and analyzing biomedical data.</description><author>Chunwei Liu, Gerardo Vitagliano, Brandon Rose, Matt Prinz, David Andrew Samson, Michael Cafarella</author><pubDate>Wed, 05 Feb 2025 17:06:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03368v1</guid></item><item><title>SyMANTIC: An Efficient Symbolic Regression Method for Interpretable and Parsimonious Model Discovery in Science and Beyond</title><link>http://arxiv.org/abs/2502.03367v1</link><description>Symbolic regression (SR) is an emerging branch of machine learning focused ondiscovering simple and interpretable mathematical expressions from data.Although a wide-variety of SR methods have been developed, they often facechallenges such as high computational cost, poor scalability with respect tothe number of input dimensions, fragility to noise, and an inability to balanceaccuracy and complexity. This work introduces SyMANTIC, a novel SR algorithmthat addresses these challenges. SyMANTIC efficiently identifies (potentiallyseveral) low-dimensional descriptors from a large set of candidates (from $\sim10^5$ to $\sim 10^{10}$ or more) through a unique combination of mutualinformation-based feature selection, adaptive feature expansion, andrecursively applied $\ell_0$-based sparse regression. In addition, it employsan information-theoretic measure to produce an approximate set ofPareto-optimal equations, each offering the best-found accuracy for a givencomplexity. Furthermore, our open-source implementation of SyMANTIC, built onthe PyTorch ecosystem, facilitates easy installation and GPU acceleration. Wedemonstrate the effectiveness of SyMANTIC across a range of problems, includingsynthetic examples, scientific benchmarks, real-world material propertypredictions, and chaotic dynamical system identification from small datasets.Extensive comparisons show that SyMANTIC uncovers similar or more accuratemodels at a fraction of the cost of existing SR methods.</description><author>Madhav R. Muthyala, Farshud Sorourifar, You Peng, Joel A. Paulson</author><pubDate>Wed, 05 Feb 2025 17:05:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03367v1</guid></item><item><title>Rethinking Approximate Gaussian Inference in Classification</title><link>http://arxiv.org/abs/2502.03366v1</link><description>In classification tasks, softmax functions are ubiquitously used as outputactivations to produce predictive probabilities. Such outputs only capturealeatoric uncertainty. To capture epistemic uncertainty, approximate Gaussianinference methods have been proposed, which output Gaussian distributions overthe logit space. Predictives are then obtained as the expectations of theGaussian distributions pushed forward through the softmax. However, suchsoftmax Gaussian integrals cannot be solved analytically, and Monte Carlo (MC)approximations can be costly and noisy. We propose a simple change in thelearning objective which allows the exact computation of predictives and enjoysimproved training dynamics, with no runtime or memory overhead. This frameworkis compatible with a family of output activation functions that includes thesoftmax, as well as element-wise normCDF and sigmoid. Moreover, it allows forapproximating the Gaussian pushforwards with Dirichlet distributions byanalytic moment matching. We evaluate our approach combined with severalapproximate Gaussian inference methods (Laplace, HET, SNGP) on large- andsmall-scale datasets (ImageNet, CIFAR-10), demonstrating improved uncertaintyquantification capabilities compared to softmax MC sampling. Code is availableat https://github.com/bmucsanyi/probit.</description><author>Bálint Mucsányi, Nathaël Da Costa, Philipp Hennig</author><pubDate>Wed, 05 Feb 2025 17:03:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03366v1</guid></item><item><title>A Match Made in Heaven? Matching Test Cases and Vulnerabilities With the VUTECO Approach</title><link>http://arxiv.org/abs/2502.03365v1</link><description>Software vulnerabilities are commonly detected via static analysis,penetration testing, and fuzzing. They can also be found by running unit tests- so-called vulnerability-witnessing tests - that stimulate thesecurity-sensitive behavior with crafted inputs. Developing such tests isdifficult and time-consuming; thus, automated data-driven approaches could helpdevelopers intercept vulnerabilities earlier. However, training and validatingsuch approaches require a lot of data, which is currently scarce. This paperintroduces VUTECO, a deep learning-based approach for collecting instances ofvulnerability-witnessing tests from Java repositories. VUTECO carries out twotasks: (1) the "Finding" task to determine whether a test case issecurity-related, and (2) the "Matching" task to relate a test case to theexact vulnerability it is witnessing. VUTECO successfully addresses the Findingtask, achieving perfect precision and 0.83 F0.5 score on validated test casesin VUL4J and returning 102 out of 145 (70%) correct security-related test casesfrom 244 open-source Java projects. Despite showing sufficiently goodperformance for the Matching task - i.e., 0.86 precision and 0.68 F0.5 score -VUTECO failed to retrieve any valid match in the wild. Nevertheless, weobserved that in almost all of the matches, the test case was stillsecurity-related despite being matched to the wrong vulnerability. In the end,VUTECO can help find vulnerability-witnessing tests, though the matching withthe right vulnerability is yet to be solved; the findings obtained lay thestepping stone for future research on the matter.</description><author>Emanuele Iannone, Quang-Cuong Bui, Riccardo Scandariato</author><pubDate>Wed, 05 Feb 2025 17:02:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03365v1</guid></item><item><title>Estimating Appearance Models for Image Segmentation via Tensor Factorization</title><link>http://arxiv.org/abs/2208.07853v3</link><description>Image Segmentation is one of the core tasks in Computer Vision and solving itoften depends on modeling the image appearance data via the color distributionsof each it its constituent regions. Whereas many segmentation algorithms handlethe appearance models dependence using alternation or implicit methods, wepropose here a new approach to directly estimate them from the image withoutprior information on the underlying segmentation. Our method uses local highorder color statistics from the image as an input to tensor factorization-basedestimator for latent variable models. This approach is able to estimate modelsin multiregion images and automatically output the regions proportions withoutprior user interaction, overcoming the drawbacks from a prior attempt to thisproblem. We also demonstrate the performance of our proposed method in manychallenging synthetic and real imaging scenarios and show that it leads to anefficient segmentation algorithm.</description><author>Jeova Farias Sales Rocha Neto</author><pubDate>Wed, 05 Feb 2025 17:01:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.07853v3</guid></item><item><title>Scaling laws in wearable human activity recognition</title><link>http://arxiv.org/abs/2502.03364v1</link><description>Many deep architectures and self-supervised pre-training techniques have beenproposed for human activity recognition (HAR) from wearable multimodal sensors.Scaling laws have the potential to help move towards more principled design bylinking model capacity with pre-training data volume. Yet, scaling laws havenot been established for HAR to the same extent as in language and vision. Byconducting an exhaustive grid search on both amount of pre-training data andTransformer architectures, we establish the first known scaling laws for HAR.We show that pre-training loss scales with a power law relationship to amountof data and parameter count and that increasing the number of users in adataset results in a steeper improvement in performance than increasing dataper user, indicating that diversity of pre-training data is important, whichcontrasts to some previously reported findings in self-supervised HAR. We showthat these scaling laws translate to downstream performance improvements onthree HAR benchmark datasets of postures, modes of locomotion and activities ofdaily living: UCI HAR and WISDM Phone and WISDM Watch. Finally, we suggest somepreviously published works should be revisited in light of these scaling lawswith more adequate model capacities.</description><author>Tom Hoddes, Alex Bijamov, Saket Joshi, Daniel Roggen, Ali Etemad, Robert Harle, David Racz</author><pubDate>Wed, 05 Feb 2025 17:00:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03364v1</guid></item><item><title>More Experts Than Galaxies: Conditionally-overlapping Experts With Biologically-Inspired Fixed Routing</title><link>http://arxiv.org/abs/2410.08003v5</link><description>The evolution of biological neural systems has led to both modularity andsparse coding, which enables energy efficiency and robustness across thediversity of tasks in the lifespan. In contrast, standard neural networks relyon dense, non-specialized architectures, where all model parameters aresimultaneously updated to learn multiple tasks, leading to interference.Current sparse neural network approaches aim to alleviate this issue but arehindered by limitations such as 1) trainable gating functions that causerepresentation collapse, 2) disjoint experts that result in redundantcomputation and slow learning, and 3) reliance on explicit input or task IDsthat limit flexibility and scalability. In this paper we propose ConditionallyOverlapping Mixture of ExperTs (COMET), a general deep learning method thataddresses these challenges by inducing a modular, sparse architecture with anexponential number of overlapping experts. COMET replaces the trainable gatingfunction used in Sparse Mixture of Experts with a fixed, biologically inspiredrandom projection applied to individual input representations. This designcauses the degree of expert overlap to depend on input similarity, so thatsimilar inputs tend to share more parameters. This results in faster learningper update step and improved out-of-sample generalization. We demonstrate theeffectiveness of COMET on a range of tasks, including image classification,language modeling, and regression, using several popular deep learningarchitectures.</description><author>Sagi Shaier, Francisco Pereira, Katharina von der Wense, Lawrence E Hunter, Matt Jones</author><pubDate>Wed, 05 Feb 2025 16:57:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.08003v5</guid></item><item><title>A Beam's Eye View to Fluence Maps 3D Network for Ultra Fast VMAT Radiotherapy Planning</title><link>http://arxiv.org/abs/2502.03360v1</link><description>Volumetric Modulated Arc Therapy (VMAT) revolutionizes cancer treatment byprecisely delivering radiation while sparing healthy tissues. Fluence mapsgeneration, crucial in VMAT planning, traditionally involves complex anditerative, and thus time consuming processes. These fluence maps aresubsequently leveraged for leaf-sequence. The deep-learning approach presentedin this article aims to expedite this by directly predicting fluence maps frompatient data. We developed a 3D network which we trained in a supervised wayusing a combination of L1 and L2 losses, and RT plans generated by Eclipse andfrom the REQUITE dataset, taking the RT dose map as input and the fluence mapscomputed from the corresponding RT plans as target. Our network predictsjointly the 180 fluence maps corresponding to the 180 control points (CP) ofsingle arc VMAT plans. In order to help the network, we pre-process the inputdose by computing the projections of the 3D dose map to the beam's eye view(BEV) of the 180 CPs, in the same coordinate system as the fluence maps. Wegenerated over 2000 VMAT plans using Eclipse to scale up the dataset size.Additionally, we evaluated various network architectures and analyzed theimpact of increasing the dataset size. We are measuring the performance in the2D fluence maps domain using image metrics (PSNR, SSIM), as well as in the 3Ddose domain using the dose-volume histogram (DVH) on a validation dataset. Thenetwork inference, which does not include the data loading and processing, isless than 20ms. Using our proposed 3D network architecture as well asincreasing the dataset size using Eclipse improved the fluence mapreconstruction performance by approximately 8 dB in PSNR compared to a U-Netarchitecture trained on the original REQUITE dataset. The resulting DVHs arevery close to the one of the input target dose.</description><author>Simon Arberet, Florin C. Ghesu, Riqiang Gao, Martin Kraus, Jonathan Sackett, Esa Kuusela, Ali Kamen</author><pubDate>Wed, 05 Feb 2025 16:56:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03360v1</guid></item><item><title>GHOST: Gaussian Hypothesis Open-Set Technique</title><link>http://arxiv.org/abs/2502.03359v1</link><description>Evaluations of large-scale recognition methods typically focus on overallperformance. While this approach is common, it often fails to provide insightsinto performance across individual classes, which can lead to fairness issuesand misrepresentation. Addressing these gaps is crucial for accuratelyassessing how well methods handle novel or unseen classes and ensuring a fairevaluation. To address fairness in Open-Set Recognition (OSR), we demonstratethat per-class performance can vary dramatically. We introduce GaussianHypothesis Open Set Technique (GHOST), a novel hyperparameter-free algorithmthat models deep features using class-wise multivariate Gaussian distributionswith diagonal covariance matrices. We apply Z-score normalization to logits tomitigate the impact of feature magnitudes that deviate from the model'sexpectations, thereby reducing the likelihood of the network assigning a highscore to an unknown sample. We evaluate GHOST across multiple ImageNet-1Kpre-trained deep networks and test it with four different unknown datasets.Using standard metrics such as AUOSCR, AUROC and FPR95, we achievestatistically significant improvements, advancing the state-of-the-art inlarge-scale OSR. Source code is provided online.</description><author>Ryan Rabinowitz, Steve Cruz, Manuel Günther, Terrance E. Boult</author><pubDate>Wed, 05 Feb 2025 16:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03359v1</guid></item><item><title>Learning with SASQuaTCh: a Novel Variational Quantum Transformer Architecture with Kernel-Based Self-Attention</title><link>http://arxiv.org/abs/2403.14753v2</link><description>The recent exploding growth in size of state-of-the-art machine learningmodels highlights a well-known issue where exponential parameter growth, whichhas grown to trillions as in the case of the Generative Pre-trained Transformer(GPT), leads to training time and memory requirements which limit theiradvancement in the near term. The predominant models use the so-calledtransformer network and have a large field of applicability, includingpredicting text and images, classification, and even predicting solutions tothe dynamics of physical systems. Here we present a variational quantum circuitarchitecture named Self-Attention Sequential Quantum Transformer Channel(SASQuaTCh), which builds networks of qubits that perform analogous operationsof the transformer network, namely the keystone self-attention operation, andleads to an exponential improvement in parameter complexity and run-timecomplexity over its classical counterpart. Our approach leverages recentinsights from kernel-based operator learning in the context of predictingspatiotemporal systems to represent deep layers of a vision transformer networkusing simple gate operations and a set of multi-dimensional quantum Fouriertransforms. To validate our approach, we consider image classification tasks insimulation and with hardware, where with only 9 qubits and a handful ofparameters we are able to simultaneously embed and classify a grayscale imageof handwritten digits with high accuracy.</description><author>Ethan N. Evans, Matthew Cook, Zachary P. Bradshaw, Margarite L. LaBorde</author><pubDate>Wed, 05 Feb 2025 16:56:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14753v2</guid></item><item><title>Distilling Implicit Multimodal Knowledge into Large Language Models for Zero-Resource Dialogue Generation</title><link>http://arxiv.org/abs/2405.10121v2</link><description>Integrating multimodal knowledge into large language models (LLMs) representsa significant advancement in dialogue generation capabilities. However, theeffective incorporation of such knowledge in zero-resource scenarios remains asubstantial challenge due to the scarcity of diverse, high-quality dialoguedatasets. To address this, we propose the Visual Implicit KnowledgeDistillation Framework (VIKDF), an innovative approach aimed at enhancing LLMsfor enriched dialogue generation in zero-resource contexts by leveragingimplicit multimodal knowledge. VIKDF comprises two main stages: knowledgedistillation, using an Implicit Query Transformer to extract and encode visualimplicit knowledge from image-text pairs into knowledge vectors; and knowledgeintegration, employing a novel Bidirectional Variational Information Fusiontechnique to seamlessly integrate these distilled vectors into LLMs. Thisenables the LLMs to generate dialogues that are not only coherent and engagingbut also exhibit a deep understanding of the context through implicitmultimodal cues, effectively overcoming the limitations of zero-resourcescenarios. Our extensive experimentation across two dialogue datasets showsthat VIKDF outperforms existing state-of-the-art models in generatinghigh-quality dialogues. The code is available athttps://github.com/zhangbo-nlp/VIKDF.</description><author>Bo Zhang, Hui Ma, Jian Ding, Jian Wang, Bo Xu, Hongfei Lin</author><pubDate>Wed, 05 Feb 2025 16:54:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.10121v2</guid></item><item><title>Minerva: A Programmable Memory Test Benchmark for Language Models</title><link>http://arxiv.org/abs/2502.03358v1</link><description>How effectively can LLM-based AI assistants utilize their memory (context) toperform various tasks? Traditional data benchmarks, which are often manuallycrafted, suffer from several limitations: they are static, susceptible tooverfitting, difficult to interpret, and lack actionable insights--failing topinpoint the specific capabilities a model lacks when it does not pass a test.In this paper, we present a framework for automatically generating acomprehensive set of tests to evaluate models' abilities to use their memoryeffectively. Our framework extends the range of capability tests beyond thecommonly explored (passkey, key-value, needle in the haystack) search, adominant focus in the literature. Specifically, we evaluate models on atomictasks such as searching, recalling, editing, matching, comparing information incontext memory, and performing basic operations when inputs are structured intodistinct blocks, simulating real-world data. Additionally, we design compositetests to investigate the models' ability to maintain state while operating onmemory. Our benchmark enables an interpretable, detailed assessment of memorycapabilities of LLMs.</description><author>Menglin Xia, Victor Ruehle, Saravan Rajmohan, Reza Shokri</author><pubDate>Wed, 05 Feb 2025 16:53:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03358v1</guid></item><item><title>LNQ 2023 challenge: Benchmark of weakly-supervised techniques for mediastinal lymph node quantification</title><link>http://arxiv.org/abs/2408.10069v2</link><description>Accurate assessment of lymph node size in 3D CT scans is crucial for cancerstaging, therapeutic management, and monitoring treatment response. Existingstate-of-the-art segmentation frameworks in medical imaging often rely on fullyannotated datasets. However, for lymph node segmentation, these datasets aretypically small due to the extensive time and expertise required to annotatethe numerous lymph nodes in 3D CT scans. Weakly-supervised learning, whichleverages incomplete or noisy annotations, has recently gained interest in themedical imaging community as a potential solution. Despite the variety ofweakly-supervised techniques proposed, most have been validated only on privatedatasets or small publicly available datasets. To address this limitation, theMediastinal Lymph Node Quantification (LNQ) challenge was organized inconjunction with the 26th International Conference on Medical Image Computingand Computer Assisted Intervention (MICCAI 2023). This challenge aimed toadvance weakly-supervised segmentation methods by providing a new, partiallyannotated dataset and a robust evaluation framework. A total of 16 teams from 5countries submitted predictions to the validation leaderboard, and 6 teams from3 countries participated in the evaluation phase. The results highlighted boththe potential and the current limitations of weakly-supervised approaches. Onone hand, weakly-supervised approaches obtained relatively good performancewith a median Dice score of $61.0\%$. On the other hand, top-ranked teams, witha median Dice score exceeding $70\%$, boosted their performance by leveragingsmaller but fully annotated datasets to combine weak supervision and fullsupervision. This highlights both the promise of weakly-supervised methods andthe ongoing need for high-quality, fully annotated data to achieve highersegmentation performance.</description><author>Reuben Dorent, Roya Khajavi, Tagwa Idris, Erik Ziegler, Bhanusupriya Somarouthu, Heather Jacene, Ann LaCasce, Jonathan Deissler, Jan Ehrhardt, Sofija Engelson, Stefan M. Fischer, Yun Gu, Heinz Handels, Satoshi Kasai, Satoshi Kondo, Klaus Maier-Hein, Julia A. Schnabel, Guotai Wang, Litingyu Wang, Tassilo Wald, Guang-Zhong Yang, Hanxiao Zhang, Minghui Zhang, Steve Pieper, Gordon Harris, Ron Kikinis, Tina Kapur</author><pubDate>Wed, 05 Feb 2025 16:46:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10069v2</guid></item><item><title>Optimal Task Order for Continual Learning of Multiple Tasks</title><link>http://arxiv.org/abs/2502.03350v1</link><description>Continual learning of multiple tasks remains a major challenge for neuralnetworks. Here, we investigate how task order influences continual learning andpropose a strategy for optimizing it. Leveraging a linear teacher-student modelwith latent factors, we derive an analytical expression relating tasksimilarity and ordering to learning performance. Our analysis reveals twoprinciples that hold under a wide parameter range: (1) tasks should be arrangedfrom the least representative to the most typical, and (2) adjacent tasksshould be dissimilar. We validate these rules on both synthetic data andreal-world image classification datasets (Fashion-MNIST, CIFAR-10, CIFAR-100),demonstrating consistent performance improvements in both multilayerperceptrons and convolutional neural networks. Our work thus presents ageneralizable framework for task-order optimization in task-incrementalcontinual learning.</description><author>Ziyan Li, Naoki Hiratani</author><pubDate>Wed, 05 Feb 2025 16:43:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03350v1</guid></item><item><title>Robust Autonomy Emerges from Self-Play</title><link>http://arxiv.org/abs/2502.03349v1</link><description>Self-play has powered breakthroughs in two-player and multi-player games.Here we show that self-play is a surprisingly effective strategy in anotherdomain. We show that robust and naturalistic driving emerges entirely fromself-play in simulation at unprecedented scale -- 1.6~billion~km of driving.This is enabled by Gigaflow, a batched simulator that can synthesize and trainon 42 years of subjective driving experience per hour on a single 8-GPU node.The resulting policy achieves state-of-the-art performance on three independentautonomous driving benchmarks. The policy outperforms the prior state of theart when tested on recorded real-world scenarios, amidst human drivers, withoutever seeing human data during training. The policy is realistic when assessedagainst human references and achieves unprecedented robustness, averaging 17.5years of continuous driving between incidents in simulation.</description><author>Marco Cusumano-Towner, David Hafner, Alex Hertzberg, Brody Huval, Aleksei Petrenko, Eugene Vinitsky, Erik Wijmans, Taylor Killian, Stuart Bowers, Ozan Sener, Philipp Krähenbühl, Vladlen Koltun</author><pubDate>Wed, 05 Feb 2025 16:41:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03349v1</guid></item><item><title>Prepending or Cross-Attention for Speech-to-Text? An Empirical Comparison</title><link>http://arxiv.org/abs/2501.02370v2</link><description>Following the remarkable success of Large Language Models (LLMs) in NLPtasks, there is increasing interest in extending their capabilities to speech-- the most common form of communication. The most widespread approach tointegrating speech into LLMs is dense feature prepending (DFP), which prependsthe projected speech representations to the textual representations, allowingend-to-end training with a speech encoder. This raises questions about the needfor a sophisticated speech encoder for DFP and how its performance compareswith a standard encoder-decoder (i.e., cross-attention) architecture. Wecompare DFP and cross-attention under a variety of configurations, such as CTCcompression, sequence-level knowledge distillation, on monolingual, bilingual,and multilingual models. To perform a controlled architectural comparison, wetrain all models from scratch rather than using large pretrained models and usecomparable data and parameter settings, testing speech-to-text recognition(ASR) and translation (ST) on MuST-C v1.0 and CoVoST2 datasets. Despite thewide adoption of DFP, our results do not indicate a clear advantage of DFP overcross-attention.</description><author>Tsz Kin Lam, Marco Gaido, Sara Papi, Luisa Bentivogli, Barry Haddow</author><pubDate>Wed, 05 Feb 2025 16:40:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.02370v2</guid></item><item><title>FlowSDF: Flow Matching for Medical Image Segmentation Using Distance Transforms</title><link>http://arxiv.org/abs/2405.18087v2</link><description>Medical image segmentation plays an important role in accurately identifyingand isolating regions of interest within medical images. Generative approachesare particularly effective in modeling the statistical properties ofsegmentation masks that are closely related to the respective structures. Inthis work we introduce FlowSDF, an image-guided conditional flow matchingframework, designed to represent the signed distance function (SDF), and, inturn, to represent an implicit distribution of segmentation masks. Theadvantage of leveraging the SDF is a more natural distortion when compared tothat of binary masks. Through the learning of a vector field associated withthe probability path of conditional SDF distributions, our framework enablesaccurate sampling of segmentation masks and the computation of relevantstatistical measures. This probabilistic approach also facilitates thegeneration of uncertainty maps represented by the variance, thereby supportingenhanced robustness in prediction and further analysis. We qualitatively andquantitatively illustrate competitive performance of the proposed method on apublic nuclei and gland segmentation data set, highlighting its utility inmedical image segmentation applications.</description><author>Lea Bogensperger, Dominik Narnhofer, Alexander Falk, Konrad Schindler, Thomas Pock</author><pubDate>Wed, 05 Feb 2025 16:35:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18087v2</guid></item><item><title>Deep Linear Network Training Dynamics from Random Initialization: Data, Width, Depth, and Hyperparameter Transfer</title><link>http://arxiv.org/abs/2502.02531v2</link><description>We theoretically characterize gradient descent dynamics in deep linearnetworks trained at large width from random initialization and on largequantities of random data. Our theory captures the ``wider is better" effect ofmean-field/maximum-update parameterized networks as well as hyperparametertransfer effects, which can be contrasted with the neural-tangentparameterization where optimal learning rates shift with model width. Weprovide asymptotic descriptions of both non-residual and residual neuralnetworks, the latter of which enables an infinite depth limit when branches arescaled as $1/\sqrt{\text{depth}}$. We also compare training with one-passstochastic gradient descent to the dynamics when training data are repeated ateach iteration. Lastly, we show that this model recovers the accelerated powerlaw training dynamics for power law structured data in the rich regime observedin recent works.</description><author>Blake Bordelon, Cengiz Pehlevan</author><pubDate>Wed, 05 Feb 2025 16:35:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.02531v2</guid></item><item><title>Adaptive Variational Inference in Probabilistic Graphical Models: Beyond Bethe, Tree-Reweighted, and Convex Free Energies</title><link>http://arxiv.org/abs/2502.03341v1</link><description>Variational inference in probabilistic graphical models aims to approximatefundamental quantities such as marginal distributions and the partitionfunction. Popular approaches are the Bethe approximation, tree-reweighted, andother types of convex free energies. These approximations are efficient but canfail if the model is complex and highly interactive. In this work, we analyzetwo classes of approximations that include the above methods as special cases:first, if the model parameters are changed; and second, if the entropyapproximation is changed. We discuss benefits and drawbacks of either approach,and deduce from this analysis how a free energy approximation should ideally beconstructed. Based on our observations, we propose approximations thatautomatically adapt to a given model and demonstrate their effectiveness for arange of difficult problems.</description><author>Harald Leisenberger, Franz Pernkopf</author><pubDate>Wed, 05 Feb 2025 16:33:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03341v1</guid></item><item><title>Interaction-Aware Gaussian Weighting for Clustered Federated Learning</title><link>http://arxiv.org/abs/2502.03340v1</link><description>Federated Learning (FL) emerged as a decentralized paradigm to train modelswhile preserving privacy. However, conventional FL struggles with dataheterogeneity and class imbalance, which degrade model performance. ClusteredFL balances personalization and decentralized training by grouping clients withanalogous data distributions, enabling improved accuracy while adhering toprivacy constraints. This approach effectively mitigates the adverse impact ofheterogeneity in FL. In this work, we propose a novel clustered FL method,FedGWC (Federated Gaussian Weighting Clustering), which groups clients based ontheir data distribution, allowing training of a more robust and personalizedmodel on the identified clusters. FedGWC identifies homogeneous clusters bytransforming individual empirical losses to model client interactions with aGaussian reward mechanism. Additionally, we introduce the Wasserstein AdjustedScore, a new clustering metric for FL to evaluate cluster cohesion with respectto the individual class distribution. Our experiments on benchmark datasetsshow that FedGWC outperforms existing FL algorithms in cluster quality andclassification accuracy, validating the efficacy of our approach.</description><author>Alessandro Licciardi, Davide Leo, Eros Faní, Barbara Caputo, Marco Ciccone</author><pubDate>Wed, 05 Feb 2025 16:33:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03340v1</guid></item><item><title>RadVLM: A Multitask Conversational Vision-Language Model for Radiology</title><link>http://arxiv.org/abs/2502.03333v1</link><description>The widespread use of chest X-rays (CXRs), coupled with a shortage ofradiologists, has driven growing interest in automated CXR analysis andAI-assisted reporting. While existing vision-language models (VLMs) showpromise in specific tasks such as report generation or abnormality detection,they often lack support for interactive diagnostic capabilities. In this workwe present RadVLM, a compact, multitask conversational foundation modeldesigned for CXR interpretation. To this end, we curate a large-scaleinstruction dataset comprising over 1 million image-instruction pairscontaining both single-turn tasks -- such as report generation, abnormalityclassification, and visual grounding -- and multi-turn, multi-taskconversational interactions. After fine-tuning RadVLM on this instructiondataset, we evaluate it across different tasks along with re-implementedbaseline VLMs. Our results show that RadVLM achieves state-of-the-artperformance in conversational capabilities and visual grounding while remainingcompetitive in other radiology tasks. Ablation studies further highlight thebenefit of joint training across multiple tasks, particularly for scenarioswith limited annotated data. Together, these findings highlight the potentialof RadVLM as a clinically relevant AI assistant, providing structured CXRinterpretation and conversational capabilities to support more effective andaccessible diagnostic workflows.</description><author>Nicolas Deperrois, Hidetoshi Matsuo, Samuel Ruipérez-Campillo, Moritz Vandenhirtz, Sonia Laguna, Alain Ryser, Koji Fujimoto, Mizuho Nishio, Thomas M. Sutter, Julia E. Vogt, Jonas Kluckert, Thomas Frauenfelder, Christian Blüthgen, Farhad Nooralahzadeh, Michael Krauthammer</author><pubDate>Wed, 05 Feb 2025 16:27:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03333v1</guid></item><item><title>A Mixture-Based Framework for Guiding Diffusion Models</title><link>http://arxiv.org/abs/2502.03332v1</link><description>Denoising diffusion models have driven significant progress in the field ofBayesian inverse problems. Recent approaches use pre-trained diffusion modelsas priors to solve a wide range of such problems, only leveraginginference-time compute and thereby eliminating the need to retraintask-specific models on the same dataset. To approximate the posterior of aBayesian inverse problem, a diffusion model samples from a sequence ofintermediate posterior distributions, each with an intractable likelihoodfunction. This work proposes a novel mixture approximation of theseintermediate distributions. Since direct gradient-based sampling of thesemixtures is infeasible due to intractable terms, we propose a practical methodbased on Gibbs sampling. We validate our approach through extensive experimentson image inverse problems, utilizing both pixel- and latent-space diffusionpriors, as well as on source separation with an audio diffusion model. The codeis available at https://www.github.com/badr-moufad/mgdm</description><author>Yazid Janati, Badr Moufad, Mehdi Abou El Qassime, Alain Durmus, Eric Moulines, Jimmy Olsson</author><pubDate>Wed, 05 Feb 2025 16:26:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03332v1</guid></item><item><title>Controllable GUI Exploration</title><link>http://arxiv.org/abs/2502.03330v1</link><description>During the early stages of interface design, designers need to producemultiple sketches to explore a design space. Design tools often fail to supportthis critical stage, because they insist on specifying more details thannecessary. Although recent advances in generative AI have raised hopes ofsolving this issue, in practice they fail because expressing loose ideas in aprompt is impractical. In this paper, we propose a diffusion-based approach tothe low-effort generation of interface sketches. It breaks new ground byallowing flexible control of the generation process via three types of inputs:A) prompts, B) wireframes, and C) visual flows. The designer can provide anycombination of these as input at any level of detail, and will get a diversegallery of low-fidelity solutions in response. The unique benefit is that largedesign spaces can be explored rapidly with very little effort ininput-specification. We present qualitative results for various combinations ofinput specifications. Additionally, we demonstrate that our model aligns moreaccurately with these specifications than other models.</description><author>Aryan Garg, Yue Jiang, Antti Oulasvirta</author><pubDate>Wed, 05 Feb 2025 16:25:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03330v1</guid></item><item><title>Is In-Context Universality Enough? MLPs are Also Universal In-Context</title><link>http://arxiv.org/abs/2502.03327v1</link><description>The success of transformers is often linked to their ability to performin-context learning. Recent work shows that transformers are universal incontext, capable of approximating any real-valued continuous function of acontext (a probability measure over $\mathcal{X}\subseteq \mathbb{R}^d$) and aquery $x\in \mathcal{X}$. This raises the question: Does in-contextuniversality explain their advantage over classical models? We answer this inthe negative by proving that MLPs with trainable activation functions are alsouniversal in-context. This suggests the transformer's success is likely due toother factors like inductive bias or training stability.</description><author>Anastasis Kratsios, Takashi Furuya</author><pubDate>Wed, 05 Feb 2025 16:22:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03327v1</guid></item><item><title>ECM: A Unified Electronic Circuit Model for Explaining the Emergence of In-Context Learning and Chain-of-Thought in Large Language Model</title><link>http://arxiv.org/abs/2502.03325v1</link><description>Recent advancements in large language models (LLMs) have led to significantsuccesses across various applications, where the most noticeable is to a seriesof emerging capabilities, particularly in the areas of In-Context Learning(ICL) and Chain-of-Thought (CoT). To better understand and control modelperformance, many studies have begun investigating the underlying causes ofthese phenomena and their impact on task outcomes. However, existingexplanatory frameworks predominantly focus on isolating and explaining ICL andCoT independently, leading to an incomplete understanding of their combinedinfluence on model performance. To address this gap, we propose the ElectronicCircuit Model (ECM), which provides a foundation for developing scalable,learnable policies and improving the management of AI-generated content.Specifically, ECM conceptualizes model behavior as an electronic circuit: ICLis represented as semantic magnetic field to providing an additional voltagefollowing Faraday's Law, while CoT is modeled as series resistors to constrainthe model output performance following Ohm's Law. Experimental resultsdemonstrate that the ECM effectively predicts and explains LLM performanceacross a variety of prompting strategies. Furthermore, we apply ECM to advancedreasoning strategy optimization on a series of tasks, such as the InternationalOlympiad in Informatics (IOI) and the International Mathematical Olympiad(IMO), achieving competitive performance that surpasses nearly 80% of top humancompetitors.</description><author>Qiguang Chen, Libo Qin, Jinhao Liu, Dengyun Peng, Jiaqi Wang, Mengkang Hu, Zhi Chen, Wanxiang Che, Ting Liu</author><pubDate>Wed, 05 Feb 2025 16:22:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03325v1</guid></item><item><title>Out-of-Distribution Detection using Synthetic Data Generation</title><link>http://arxiv.org/abs/2502.03323v1</link><description>Distinguishing in- and out-of-distribution (OOD) inputs is crucial forreliable deployment of classification systems. However, OOD data is typicallyunavailable or difficult to collect, posing a significant challenge foraccurate OOD detection. In this work, we present a method that harnesses thegenerative capabilities of Large Language Models (LLMs) to create high-qualitysynthetic OOD proxies, eliminating the dependency on any external OOD datasource. We study the efficacy of our method on classical text classificationtasks such as toxicity detection and sentiment classification as well asclassification tasks arising in LLM development and deployment, such astraining a reward model for RLHF and detecting misaligned generations.Extensive experiments on nine InD-OOD dataset pairs and various model sizesshow that our approach dramatically lowers false positive rates (achieving aperfect zero in some cases) while maintaining high accuracy on in-distributiontasks, outperforming baseline methods by a significant margin.</description><author>Momin Abbas, Muneeza Azmat, Raya Horesh, Mikhail Yurochkin</author><pubDate>Wed, 05 Feb 2025 16:22:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03323v1</guid></item><item><title>Randomness, exchangeability, and conformal prediction</title><link>http://arxiv.org/abs/2501.11689v2</link><description>This paper continues development of the functional theory of randomness, amodification of the algorithmic theory of randomness getting rid of unspecifiedadditive constants. It introduces new kinds of confidence predictors, includingrandomness predictors (the most general confidence predictors based on theassumption of IID observations) and exchangeability predictors (the mostgeneral confidence predictors based on the assumption of exchangeableobservations). The main result implies that both are close to conformalpredictors and quantifies the difference between randomness prediction andconformal prediction.</description><author>Vladimir Vovk</author><pubDate>Wed, 05 Feb 2025 16:21:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11689v2</guid></item><item><title>Simplifying Formal Proof-Generating Models with ChatGPT and Basic Searching Techniques</title><link>http://arxiv.org/abs/2502.03321v1</link><description>The challenge of formal proof generation has a rich history, but with moderntechniques, we may finally be at the stage of making actual progress inreal-life mathematical problems. This paper explores the integration of ChatGPTand basic searching techniques to simplify generating formal proofs, with aparticular focus on the miniF2F dataset. We demonstrate how combining a largelanguage model like ChatGPT with a formal language such as Lean, which has theadded advantage of being verifiable, enhances the efficiency and accessibilityof formal proof generation. Despite its simplicity, our best-performingLean-based model surpasses all known benchmarks with a 31.15% pass rate. Weextend our experiments to include other datasets and employ alternativelanguage models, showcasing our models' comparable performance in diversesettings and allowing for a more nuanced analysis of our results. Our findingsoffer insights into AI-assisted formal proof generation, suggesting a promisingdirection for future research in formal mathematical proof.</description><author>Sangjun Han, Taeil Hur, Youngmi Hur, Kathy Sangkyung Lee, Myungyoon Lee, Hyojae Lim</author><pubDate>Wed, 05 Feb 2025 16:21:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03321v1</guid></item><item><title>Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems</title><link>http://arxiv.org/abs/2501.11613v3</link><description>This study introduces Conversation Routines (CR), a structured promptengineering framework for developing task-oriented dialog systems using LargeLanguage Models (LLMs). While LLMs demonstrate remarkable natural languageunderstanding capabilities, engineering them to reliably execute complexbusiness workflows remains challenging. The proposed CR framework enables thedevelopment of Conversation Agentic Systems (CAS) through natural languagespecifications, embedding task-oriented logic within LLM prompts. This approachprovides a systematic methodology for designing and implementing complexconversational workflows while maintaining behavioral consistency. Wedemonstrate the framework's effectiveness through two proof-of-conceptimplementations: a Train Ticket Booking System and an InteractiveTroubleshooting Copilot. These case studies validate CR's capability to encodesophisticated behavioral patterns and decision logic while preserving naturalconversational flexibility. Results show that CR enables domain experts todesign conversational workflows in natural language while leveraging customfunctions (tools) developed by software engineers, creating an efficientdivision of responsibilities where developers focus on core API implementationand domain experts handle conversation design. While the framework showspromise in accessibility and adaptability, we identify key challenges includingcomputational overhead, non-deterministic behavior, and domain-specific logicoptimization. Future research directions include CR evaluation methods based onprompt engineering frameworks driven by goal-oriented grading criteria,improving scalability for complex multi-agent interactions, and enhancingsystem robustness to address the identified limitations across diverse businessapplications.</description><author>Giorgio Robino</author><pubDate>Wed, 05 Feb 2025 16:21:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11613v3</guid></item><item><title>PaPaGei: Open Foundation Models for Optical Physiological Signals</title><link>http://arxiv.org/abs/2410.20542v2</link><description>Photoplethysmography (PPG) is the leading non-invasive technique formonitoring biosignals and cardiovascular health, with widespread adoption inboth clinical settings and consumer wearable devices. While machine learningmodels trained on PPG signals have shown promise, they tend to be task-specificand struggle with generalization. Current research is limited by the use ofsingle-device datasets, insufficient exploration of out-of-domaingeneralization, and a lack of publicly available models, which hampersreproducibility. To address these limitations, we present PaPaGei, the firstopen foundation model for PPG signals. The model is pre-trained on over 57,000hours of data, comprising 20 million unlabeled PPG segments from publiclyavailable datasets. We introduce a novel representation learning approach thatleverages domain knowledge of PPG signal morphology across individuals,enabling the capture of richer representations compared to traditionalcontrastive learning methods. We evaluate PaPaGei against state-of-the-arttime-series foundation models and self-supervised learning benchmarks across 20tasks from 10 diverse datasets, spanning cardiovascular health, sleepdisorders, pregnancy monitoring, and wellbeing assessment. Our modeldemonstrates superior performance, improving classification and regressionmetrics by 6.3% and 2.9% respectively in at least 14 tasks. Notably, PaPaGeiachieves these results while being more data- and parameter-efficient,outperforming models that are 70x larger. Beyond accuracy, we examine modelrobustness across different skin tones, establishing a benchmark for biasevaluation in future models. PaPaGei can serve as both a feature extractor andan encoder for multimodal models, opening up new opportunities for multimodalhealth monitoring.</description><author>Arvind Pillai, Dimitris Spathis, Fahim Kawsar, Mohammad Malekzadeh</author><pubDate>Wed, 05 Feb 2025 16:14:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20542v2</guid></item><item><title>How Developers Interact with AI: A Taxonomy of Human-AI Collaboration in Software Engineering</title><link>http://arxiv.org/abs/2501.08774v2</link><description>Artificial intelligence (AI), including large language models and generativeAI, is emerging as a significant force in software development, offeringdevelopers powerful tools that span the entire development lifecycle. Althoughsoftware engineering research has extensively studied AI tools in softwaredevelopment, the specific types of interactions between developers and theseAI-powered tools have only recently begun to receive attention. Understandingand improving these interactions has the potential to enhance productivity,trust, and efficiency in AI-driven workflows. In this paper, we propose ataxonomy of interaction types between developers and AI tools, identifyingeleven distinct interaction types, such as auto-complete code suggestions,command-driven actions, and conversational assistance. Building on thistaxonomy, we outline a research agenda focused on optimizing AI interactions,improving developer control, and addressing trust and usability challenges inAI-assisted development. By establishing a structured foundation for studyingdeveloper-AI interactions, this paper aims to stimulate research on creatingmore effective, adaptive AI tools for software development.</description><author>Christoph Treude, Marco A. Gerosa</author><pubDate>Wed, 05 Feb 2025 16:11:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.08774v2</guid></item><item><title>A Systematic Literature Review on Explainability for Machine/Deep Learning-based Software Engineering Research</title><link>http://arxiv.org/abs/2401.14617v2</link><description>The remarkable achievements of Artificial Intelligence (AI) algorithms,particularly in Machine Learning (ML) and Deep Learning (DL), have fueled theirextensive deployment across multiple sectors, including Software Engineering(SE). However, due to their black-box nature, these promising AI-driven SEmodels are still far from being deployed in practice. This lack ofexplainability poses unwanted risks for their applications in critical tasks,such as vulnerability detection, where decision-making transparency is ofparamount importance. This paper endeavors to elucidate this interdisciplinarydomain by presenting a systematic literature review of approaches that aim toimprove the explainability of AI models within the context of SE. The reviewcanvasses work appearing in the most prominent SE &amp; AI conferences andjournals, and spans 108 papers across 23 unique SE tasks. Based on three keyResearch Questions (RQs), we aim to (1) summarize the SE tasks where XAItechniques have shown success to date; (2) classify and analyze different XAItechniques; and (3) investigate existing evaluation approaches. Based on ourfindings, we identified a set of challenges remaining to be addressed inexisting studies, together with a set of guidelines highlighting potentialopportunities we deemed appropriate and important for future work.</description><author>Sicong Cao, Xiaobing Sun, Ratnadira Widyasari, David Lo, Xiaoxue Wu, Lili Bo, Jiale Zhang, Bin Li, Wei Liu, Di Wu, Yixin Chen</author><pubDate>Wed, 05 Feb 2025 16:10:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14617v2</guid></item><item><title>GP-GS: Gaussian Processes for Enhanced Gaussian Splatting</title><link>http://arxiv.org/abs/2502.02283v2</link><description>3D Gaussian Splatting has emerged as an efficient photorealistic novel viewsynthesis method. However, its reliance on sparse Structure-from-Motion (SfM)point clouds consistently compromises the scene reconstruction quality. Toaddress these limitations, this paper proposes a novel 3D reconstructionframework Gaussian Processes Gaussian Splatting (GP-GS), where a multi-outputGaussian Process model is developed to achieve adaptive and uncertainty-guideddensification of sparse SfM point clouds. Specifically, we propose a dynamicsampling and filtering pipeline that adaptively expands the SfM point clouds byleveraging GP-based predictions to infer new candidate points from the input 2Dpixels and depth maps. The pipeline utilizes uncertainty estimates to guide thepruning of high-variance predictions, ensuring geometric consistency andenabling the generation of dense point clouds. The densified point cloudsprovide high-quality initial 3D Gaussians to enhance reconstructionperformance. Extensive experiments conducted on synthetic and real-worlddatasets across various scales validate the effectiveness and practicality ofthe proposed framework.</description><author>Zhihao Guo, Jingxuan Su, Shenglin Wang, Jinlong Fan, Jing Zhang, Liangxiu Han, Peng Wang</author><pubDate>Wed, 05 Feb 2025 16:09:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.02283v2</guid></item><item><title>Causal Composition Diffusion Model for Closed-loop Traffic Generation</title><link>http://arxiv.org/abs/2412.17920v2</link><description>Simulation is critical for safety evaluation in autonomous driving,particularly in capturing complex interactive behaviors. However, generatingrealistic and controllable traffic scenarios in long-tail situations remains asignificant challenge. Existing generative models suffer from the conflictingobjective between user-defined controllability and realism constraints, whichis amplified in safety-critical contexts. In this work, we introduce the CausalCompositional Diffusion Model (CCDiff), a structure-guided diffusion frameworkto address these challenges. We first formulate the learning of controllableand realistic closed-loop simulation as a constrained optimization problem.Then, CCDiff maximizes controllability while adhering to realism byautomatically identifying and injecting causal structures directly into thediffusion process, providing structured guidance to enhance both realism andcontrollability. Through rigorous evaluations on benchmark datasets and in aclosed-loop simulator, CCDiff demonstrates substantial gains overstate-of-the-art approaches in generating realistic and user-preferredtrajectories. Our results show CCDiff's effectiveness in extracting andleveraging causal structures, showing improved closed-loop performance based onkey metrics such as collision rate, off-road rate, FDE, and comfort.</description><author>Haohong Lin, Xin Huang, Tung Phan-Minh, David S. Hayden, Huan Zhang, Ding Zhao, Siddhartha Srinivasa, Eric M. Wolff, Hongge Chen</author><pubDate>Wed, 05 Feb 2025 16:08:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17920v2</guid></item><item><title>Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient Zeroth-order LLM Fine-tuning</title><link>http://arxiv.org/abs/2502.03304v1</link><description>Large language models (LLMs) excel across various tasks, but standardfirst-order (FO) fine-tuning demands considerable memory, significantlylimiting real-world deployment. Recently, zeroth-order (ZO) optimization stoodout as a promising memory-efficient training paradigm, avoiding backward passesand relying solely on forward passes for gradient estimation, making itattractive for resource-constrained scenarios. However, ZO method lags farbehind FO method in both convergence speed and accuracy. To bridge the gap, weintroduce a novel layer-wise divergence analysis that uncovers the distinctupdate pattern of FO and ZO optimization. Aiming to resemble the learningcapacity of FO method from the findings, we propose \textbf{Di}vergence-driven\textbf{Z}eroth-\textbf{O}rder (\textbf{DiZO}) optimization. DiZO conductsdivergence-driven layer adaptation by incorporating projections to ZO updates,generating diverse-magnitude updates precisely scaled to layer-wise individualoptimization needs. Our results demonstrate that DiZO significantly reduces theneeded iterations for convergence without sacrificing throughput, cuttingtraining GPU hours by up to 48\% on various datasets. Moreover, DiZOconsistently outperforms the representative ZO baselines in fine-tuningRoBERTa-large, OPT-series, and Llama-series on downstream tasks and, in somecases, even surpasses memory-intensive FO fine-tuning.</description><author>Qitao Tan, Jun Liu, Zheng Zhan, Caiwei Ding, Yanzhi Wang, Jin Lu, Geng Yuan</author><pubDate>Wed, 05 Feb 2025 16:03:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03304v1</guid></item><item><title>MAP Image Recovery with Guarantees using Locally Convex Multi-Scale Energy (LC-MUSE) Model</title><link>http://arxiv.org/abs/2502.03302v1</link><description>We propose a multi-scale deep energy model that is strongly convex in thelocal neighbourhood around the data manifold to represent its probabilitydensity, with application in inverse problems. In particular, we represent thenegative log-prior as a multi-scale energy model parameterized by aConvolutional Neural Network (CNN). We restrict the gradient of the CNN to belocally monotone, which constrains the model as a Locally Convex Multi-ScaleEnergy (LC-MuSE). We use the learned energy model in image-based inverseproblems, where the formulation offers several desirable properties: i)uniqueness of the solution, ii) convergence guarantees to a minimum of theinverse problem, and iii) robustness to input perturbations. In the context ofparallel Magnetic Resonance (MR) image reconstruction, we show that theproposed method performs better than the state-of-the-art convex regularizers,while the performance is comparable to plug-and-play regularizers andend-to-end trained methods.</description><author>Jyothi Rikhab Chand, Mathews Jacob</author><pubDate>Wed, 05 Feb 2025 16:00:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03302v1</guid></item><item><title>Improving Consistency Models with Generator-Augmented Flows</title><link>http://arxiv.org/abs/2406.09570v3</link><description>Consistency models imitate the multi-step sampling of score-based diffusionin a single forward pass of a neural network. They can be learned in two ways:consistency distillation and consistency training. The former relies on thetrue velocity field of the corresponding differential equation, approximated bya pre-trained neural network. In contrast, the latter uses a single-sampleMonte Carlo estimate of this velocity field. The related estimation errorinduces a discrepancy between consistency distillation and training that, weshow, still holds in the continuous-time limit. To alleviate this issue, wepropose a novel flow that transports noisy data towards their correspondingoutputs derived from a consistency model. We prove that this flow reduces thepreviously identified discrepancy and the noise-data transport cost.Consequently, our method not only accelerates consistency training convergencebut also enhances its overall performance. The code is available at:https://github.com/thibautissenhuth/consistency_GC.</description><author>Thibaut Issenhuth, Sangchul Lee, Ludovic Dos Santos, Jean-Yves Franceschi, Chansoo Kim, Alain Rakotomamonjy</author><pubDate>Wed, 05 Feb 2025 15:57:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.09570v3</guid></item><item><title>MeDiSumQA: Patient-Oriented Question-Answer Generation from Discharge Letters</title><link>http://arxiv.org/abs/2502.03298v1</link><description>While increasing patients' access to medical documents improves medical care,this benefit is limited by varying health literacy levels and complex medicalterminology. Large language models (LLMs) offer solutions by simplifyingmedical information. However, evaluating LLMs for safe and patient-friendlytext generation is difficult due to the lack of standardized evaluationresources. To fill this gap, we developed MeDiSumQA. MeDiSumQA is a datasetcreated from MIMIC-IV discharge summaries through an automated pipelinecombining LLM-based question-answer generation with manual quality checks. Weuse this dataset to evaluate various LLMs on patient-orientedquestion-answering. Our findings reveal that general-purpose LLMs frequentlysurpass biomedical-adapted models, while automated metrics correlate with humanjudgment. By releasing MeDiSumQA on PhysioNet, we aim to advance thedevelopment of LLMs to enhance patient understanding and ultimately improvecare outcomes.</description><author>Amin Dada, Osman Alperen Koras, Marie Bauer, Amanda Butler, Kaleb E. Smith, Jens Kleesiek, Julian Friedrich</author><pubDate>Wed, 05 Feb 2025 15:56:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03298v1</guid></item><item><title>IRIS: An Immersive Robot Interaction System</title><link>http://arxiv.org/abs/2502.03297v1</link><description>This paper introduces IRIS, an immersive Robot Interaction System leveragingExtended Reality (XR), designed for robot data collection and interactionacross multiple simulators, benchmarks, and real-world scenarios. Whileexisting XR-based data collection systems provide efficient and intuitivesolutions for large-scale data collection, they are often challenging toreproduce and reuse. This limitation arises because current systems are highlytailored to simulator-specific use cases and environments. IRIS is a novel,easily extendable framework that already supports multiple simulators,benchmarks, and even headsets. Furthermore, IRIS is able to include additionalinformation from real-world sensors, such as point clouds captured throughdepth cameras. A unified scene specification is generated directly fromsimulators or real-world sensors and transmitted to XR headsets, creatingidentical scenes in XR. This specification allows IRIS to support any of theobjects, assets, and robots provided by the simulators. In addition, IRISintroduces shared spatial anchors and a robust communication protocol thatlinks simulations between multiple XR headsets. This feature enables multipleXR headsets to share a synchronized scene, facilitating collaborative andmulti-user data collection. IRIS can be deployed on any device that supportsthe Unity Framework, encompassing the vast majority of commercially availableheadsets. In this work, IRIS was deployed and tested on the Meta Quest 3 andthe HoloLens 2. IRIS showcased its versatility across a wide range ofreal-world and simulated scenarios, using current popular robot simulators suchas MuJoCo, IsaacSim, CoppeliaSim, and Genesis. In addition, a user studyevaluates IRIS on a data collection task for the LIBERO benchmark. The studyshows that IRIS significantly outperforms the baseline in both objective andsubjective metrics.</description><author>Xinkai Jiang, Qihao Yuan, Enes Ulas Dincer, Hongyi Zhou, Ge Li, Xueyin Li, Julius Haag, Nicolas Schreiber, Kailai Li, Gerhard Neumann, Rudolf Lioutikov</author><pubDate>Wed, 05 Feb 2025 15:56:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03297v1</guid></item><item><title>ALPET: Active Few-shot Learning for Citation Worthiness Detection in Low-Resource Wikipedia Languages</title><link>http://arxiv.org/abs/2502.03292v1</link><description>Citation Worthiness Detection (CWD) consists in determining which sentences,within an article or collection, should be backed up with a citation tovalidate the information it provides. This study, introduces ALPET, a frameworkcombining Active Learning (AL) and Pattern-Exploiting Training (PET), toenhance CWD for languages with limited data resources. Applied to Catalan,Basque, and Albanian Wikipedia datasets, ALPET outperforms the existing CCWbaseline while reducing the amount of labeled data in some cases above 80\%.ALPET's performance plateaus after 300 labeled samples, showing it suitabilityfor low-resource scenarios where large, labeled datasets are not common. Whilespecific active learning query strategies, like those employing K-Meansclustering, can offer advantages, their effectiveness is not universal andoften yields marginal gains over random sampling, particularly with smallerdatasets. This suggests that random sampling, despite its simplicity, remains astrong baseline for CWD in constraint resource environments. Overall, ALPET'sability to achieve high performance with fewer labeled samples makes it apromising tool for enhancing the verifiability of online content inlow-resource language settings.</description><author>Aida Halitaj, Arkaitz Zubiaga</author><pubDate>Wed, 05 Feb 2025 15:49:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03292v1</guid></item></channel></rss>