<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 07 Sep 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Matcha-TTS: A fast TTS architecture with conditional flow matching</title><link>http://arxiv.org/abs/2309.03199v1</link><description>We introduce Matcha-TTS, a new encoder-decoder architecture for speedy TTSacoustic modelling, trained using optimal-transport conditional flow matching(OT-CFM). This yields an ODE-based decoder capable of high output quality infewer synthesis steps than models trained using score matching. Careful designchoices additionally ensure each synthesis step is fast to run. The method isprobabilistic, non-autoregressive, and learns to speak from scratch withoutexternal alignments. Compared to strong pre-trained baseline models, theMatcha-TTS system has the smallest memory footprint, rivals the speed of thefastest models on long utterances, and attains the highest mean opinion scorein a listening test. Please see https://shivammehta25.github.io/Matcha-TTS/ foraudio examples, code, and pre-trained models.</description><author>Shivam Mehta, Ruibo Tu, Jonas Beskow, Éva Székely, Gustav Eje Henter</author><pubDate>Wed, 06 Sep 2023 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03199v1</guid></item><item><title>My Art My Choice: Adversarial Protection Against Unruly AI</title><link>http://arxiv.org/abs/2309.03198v1</link><description>Generative AI is on the rise, enabling everyone to produce realistic contentvia publicly available interfaces. Especially for guided image generation,diffusion models are changing the creator economy by producing high quality lowcost content. In parallel, artists are rising against unruly AI, since theirartwork are leveraged, distributed, and dissimulated by large generativemodels. Our approach, My Art My Choice (MAMC), aims to empower content ownersby protecting their copyrighted materials from being utilized by diffusionmodels in an adversarial fashion. MAMC learns to generate adversariallyperturbed "protected" versions of images which can in turn "break" diffusionmodels. The perturbation amount is decided by the artist to balance distortionvs. protection of the content. MAMC is designed with a simple UNet-basedgenerator, attacking black box diffusion models, combining several losses tocreate adversarial twins of the original artwork. We experiment on threedatasets for various image-to-image tasks, with different user control values.Both protected image and diffusion output results are evaluated in visual,noise, structure, pixel, and generative spaces to validate our claims. Webelieve that MAMC is a crucial step for preserving ownership information for AIgenerated content in a flawless, based-on-need, and human-centric way.</description><author>Anthony Rhodes, Ram Bhagat, Umur Aybars Ciftci, Ilke Demir</author><pubDate>Wed, 06 Sep 2023 18:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03198v1</guid></item><item><title>Blink: Link Local Differential Privacy in Graph Neural Networks via Bayesian Estimation</title><link>http://arxiv.org/abs/2309.03190v1</link><description>Graph neural networks (GNNs) have gained an increasing amount of popularitydue to their superior capability in learning node embeddings for various graphinference tasks, but training them can raise privacy concerns. To address this,we propose using link local differential privacy over decentralized nodes,enabling collaboration with an untrusted server to train GNNs without revealingthe existence of any link. Our approach spends the privacy budget separately onlinks and degrees of the graph for the server to better denoise the graphtopology using Bayesian estimation, alleviating the negative impact of LDP onthe accuracy of the trained GNNs. We bound the mean absolute error of theinferred link probabilities against the ground truth graph topology. We thenpropose two variants of our LDP mechanism complementing each other in differentprivacy settings, one of which estimates fewer links under lower privacybudgets to avoid false positive link estimates when the uncertainty is high,while the other utilizes more information and performs better given relativelyhigher privacy budgets. Furthermore, we propose a hybrid variant that combinesboth strategies and is able to perform better across different privacy budgets.Extensive experiments show that our approach outperforms existing methods interms of accuracy under varying privacy budgets.</description><author>Xiaochen Zhu, Vincent Y. F. Tan, Xiaokui Xiao</author><pubDate>Wed, 06 Sep 2023 18:53:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03190v1</guid></item><item><title>Spacetime-Efficient Low-Depth Quantum State Preparation with Applications</title><link>http://arxiv.org/abs/2303.02131v2</link><description>We propose a novel deterministic method for preparing arbitrary quantumstates. When our protocol is compiled into CNOT and arbitrary single-qubitgates, it prepares an $N$-dimensional state in depth $O(\log(N))$ and spacetimeallocation (a metric that accounts for the fact that oftentimes some ancillaqubits need not be active for the entire circuit) $O(N)$, which are bothoptimal. When compiled into the $\{\mathrm{H,S,T,CNOT}\}$ gate set, we showthat it requires asymptotically fewer quantum resources than previous methods.Specifically, it prepares an arbitrary state up to error $\epsilon$ in depth$O(\log(N/\epsilon))$ and spacetime allocation $O(N\log(\log(N)/\epsilon))$,improving over $O(\log(N)\log(N/\epsilon))$ and $O(N\log(N/\epsilon))$,respectively. We illustrate how the reduced spacetime allocation of ourprotocol enables rapid preparation of many disjoint states with onlyconstant-factor ancilla overhead -- $O(N)$ ancilla qubits are reusedefficiently to prepare a product state of $w$ $N$-dimensional states in depth$O(w + \log(N))$ rather than $O(w\log(N))$, achieving effectively constantdepth per state. We highlight several applications where this ability would beuseful, including quantum machine learning, Hamiltonian simulation, and solvinglinear systems of equations. We provide quantum circuit descriptions of ourprotocol, detailed pseudocode, and gate-level implementation examples usingBraket.</description><author>Kaiwen Gui, Alexander M. Dalzell, Alessandro Achille, Martin Suchara, Frederic T. Chong</author><pubDate>Wed, 06 Sep 2023 18:47:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.02131v2</guid></item><item><title>Bayes' Rays: Uncertainty Quantification for Neural Radiance Fields</title><link>http://arxiv.org/abs/2309.03185v1</link><description>Neural Radiance Fields (NeRFs) have shown promise in applications like viewsynthesis and depth estimation, but learning from multiview images facesinherent uncertainties. Current methods to quantify them are either heuristicor computationally demanding. We introduce BayesRays, a post-hoc framework toevaluate uncertainty in any pre-trained NeRF without modifying the trainingprocess. Our method establishes a volumetric uncertainty field using spatialperturbations and a Bayesian Laplace approximation. We derive our algorithmstatistically and show its superior performance in key metrics andapplications. Additional results available at: https://bayesrays.github.io.</description><author>Lily Goli, Cody Reading, Silvia Selllán, Alec Jacobson, Andrea Tagliasacchi</author><pubDate>Wed, 06 Sep 2023 18:44:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03185v1</guid></item><item><title>MF-NeRF: Memory Efficient NeRF with Mixed-Feature Hash Table</title><link>http://arxiv.org/abs/2304.12587v4</link><description>Neural radiance field (NeRF) has shown remarkable performance in generatingphoto-realistic novel views. Among recent NeRF related research, the approachesthat involve the utilization of explicit structures like grids to managefeatures achieve exceptionally fast training by reducing the complexity ofmultilayer perceptron (MLP) networks. However, storing features in dense gridsdemands a substantial amount of memory space, resulting in a notable memorybottleneck within computer system. Consequently, it leads to a significantincrease in training times without prior hyper-parameter tuning. To addressthis issue, in this work, we are the first to propose MF-NeRF, amemory-efficient NeRF framework that employs a Mixed-Feature hash table toimprove memory efficiency and reduce training time while maintainingreconstruction quality. Specifically, we first design a mixed-feature hashencoding to adaptively mix part of multi-level feature grids and map it to asingle hash table. Following that, in order to obtain the correct index of agrid point, we further develop an index transformation method that transformsindices of an arbitrary level grid to those of a canonical grid. Extensiveexperiments benchmarking with state-of-the-art Instant-NGP, TensoRF, and DVGO,indicate our MF-NeRF could achieve the fastest training time on the same GPUhardware with similar or even higher reconstruction quality.</description><author>Yongjae Lee, Li Yang, Deliang Fan</author><pubDate>Wed, 06 Sep 2023 18:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.12587v4</guid></item><item><title>3D Transformer based on deformable patch location for differential diagnosis between Alzheimer's disease and Frontotemporal dementia</title><link>http://arxiv.org/abs/2309.03183v1</link><description>Alzheimer's disease and Frontotemporal dementia are common types ofneurodegenerative disorders that present overlapping clinical symptoms, makingtheir differential diagnosis very challenging. Numerous efforts have been donefor the diagnosis of each disease but the problem of multi-class differentialdiagnosis has not been actively explored. In recent years, transformer-basedmodels have demonstrated remarkable success in various computer vision tasks.However, their use in disease diagnostic is uncommon due to the limited amountof 3D medical data given the large size of such models. In this paper, wepresent a novel 3D transformer-based architecture using a deformable patchlocation module to improve the differential diagnosis of Alzheimer's diseaseand Frontotemporal dementia. Moreover, to overcome the problem of datascarcity, we propose an efficient combination of various data augmentationtechniques, adapted for training transformer-based models on 3D structuralmagnetic resonance imaging data. Finally, we propose to combine ourtransformer-based model with a traditional machine learning model using brainstructure volumes to better exploit the available data. Our experimentsdemonstrate the effectiveness of the proposed approach, showing competitiveresults compared to state-of-the-art methods. Moreover, the deformable patchlocations can be visualized, revealing the most relevant brain regions used toestablish the diagnosis of each disease.</description><author>Huy-Dung Nguyen, Michaël Clément, Boris Mansencal, Pierrick Coupé</author><pubDate>Wed, 06 Sep 2023 18:42:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03183v1</guid></item><item><title>SLiMe: Segment Like Me</title><link>http://arxiv.org/abs/2309.03179v1</link><description>Significant strides have been made using large vision-language models, likeStable Diffusion (SD), for a variety of downstream tasks, including imageediting, image correspondence, and 3D shape generation. Inspired by theseadvancements, we explore leveraging these extensive vision-language models forsegmenting images at any desired granularity using as few as one annotatedsample by proposing SLiMe. SLiMe frames this problem as an optimization task.Specifically, given a single training image and its segmentation mask, we firstextract attention maps, including our novel "weighted accumulatedself-attention map" from the SD prior. Then, using the extracted attentionmaps, the text embeddings of Stable Diffusion are optimized such that, each ofthem, learn about a single segmented region from the training image. Theselearned embeddings then highlight the segmented region in the attention maps,which in turn can then be used to derive the segmentation map. This enablesSLiMe to segment any real-world image during inference with the granularity ofthe segmented region in the training image, using just one example. Moreover,leveraging additional training data when available, i.e. few-shot, improves theperformance of SLiMe. We carried out a knowledge-rich set of experimentsexamining various design factors and showed that SLiMe outperforms otherexisting one-shot and few-shot segmentation methods.</description><author>Aliasghar Khani, Saeid Asgari Taghanaki, Aditya Sanghi, Ali Mahdavi Amiri, Ghassan Hamarneh</author><pubDate>Wed, 06 Sep 2023 18:39:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03179v1</guid></item><item><title>Interpretation of High-Dimensional Linear Regression: Effects of Nullspace and Regularization Demonstrated on Battery Data</title><link>http://arxiv.org/abs/2309.00564v2</link><description>High-dimensional linear regression is important in many scientific fields.This article considers discrete measured data of underlying smooth latentprocesses, as is often obtained from chemical or biological systems.Interpretation in high dimensions is challenging because the nullspace and itsinterplay with regularization shapes regression coefficients. The data'snullspace contains all coefficients that satisfy $\mathbf{Xw}=\mathbf{0}$, thusallowing very different coefficients to yield identical predictions. Wedeveloped an optimization formulation to compare regression coefficients andcoefficients obtained by physical engineering knowledge to understand whichpart of the coefficient differences are close to the nullspace. This nullspacemethod is tested on a synthetic example and lithium-ion battery data. The casestudies show that regularization and z-scoring are design choices that, ifchosen corresponding to prior physical knowledge, lead to interpretableregression results. Otherwise, the combination of the nullspace andregularization hinders interpretability and can make it impossible to obtainregression coefficients close to the true coefficients when there is a trueunderlying linear model. Furthermore, we demonstrate that regression methodsthat do not produce coefficients orthogonal to the nullspace, such as fusedlasso, can improve interpretability. In conclusion, the insights gained fromthe nullspace perspective help to make informed design choices for buildingregression models on high-dimensional data and reasoning about potentialunderlying linear models, which are important for system optimization andimproving scientific understanding.</description><author>Joachim Schaeffer, Eric Lenz, William C. Chueh, Martin Z. Bazant, Rolf Findeisen, Richard D. Braatz</author><pubDate>Wed, 06 Sep 2023 18:35:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00564v2</guid></item><item><title>EgoBlur: Responsible Innovation in Aria</title><link>http://arxiv.org/abs/2308.13093v2</link><description>Project Aria pushes the frontiers of Egocentric AI with large-scalereal-world data collection using purposely designed glasses with privacy firstapproach. To protect the privacy of bystanders being recorded by the glasses,our research protocols are designed to ensure recorded video is processed by anAI anonymization model that removes bystander faces and vehicle license plates.Detected face and license plate regions are processed with a Gaussian blur suchthat these personal identification information (PII) regions are obscured. Thisprocess helps to ensure that anonymized versions of the video is retained forresearch purposes. In Project Aria, we have developed a state-of-the-artanonymization system EgoBlur. In this paper, we present extensive analysis ofEgoBlur on challenging datasets comparing its performance with otherstate-of-the-art systems from industry and academia including extensiveResponsible AI analysis on recently released Casual Conversations V2 dataset.</description><author>Nikhil Raina, Guruprasad Somasundaram, Kang Zheng, Sagar Miglani, Steve Saarinen, Jeff Meissner, Mark Schwesinger, Luis Pesqueira, Ishita Prasad, Edward Miller, Prince Gupta, Mingfei Yan, Richard Newcombe, Carl Ren, Omkar M Parkhi</author><pubDate>Wed, 06 Sep 2023 18:31:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.13093v2</guid></item><item><title>3D Object Positioning Using Differentiable Multimodal Learning</title><link>http://arxiv.org/abs/2309.03177v1</link><description>This article describes a multi-modal method using simulated Lidar data viaray tracing and image pixel loss with differentiable rendering to optimize anobject's position with respect to an observer or some referential objects in acomputer graphics scene. Object position optimization is completed usinggradient descent with the loss function being influenced by both modalities.Typical object placement optimization is done using image pixel loss withdifferentiable rendering only, this work shows the use of a second modality(Lidar) leads to faster convergence. This method of fusing sensor inputpresents a potential usefulness for autonomous vehicles, as these methods canbe used to establish the locations of multiple actors in a scene. This articlealso presents a method for the simulation of multiple types of data to be usedin the training of autonomous vehicles.</description><author>Sean Zanyk-McLean, Krishna Kumar, Paul Navratil</author><pubDate>Wed, 06 Sep 2023 18:30:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03177v1</guid></item><item><title>Gender-specific Machine Translation with Large Language Models</title><link>http://arxiv.org/abs/2309.03175v1</link><description>Decoder-only Large Language Models (LLMs) have demonstrated potential inmachine translation (MT), albeit with performance slightly lagging behindtraditional encoder-decoder Neural Machine Translation (NMT) systems. However,LLMs offer a unique advantage: the ability to control the properties of theoutput through prompts. In this study, we harness this flexibility to exploreLLaMa's capability to produce gender-specific translations for languages withgrammatical gender. Our results indicate that LLaMa can generategender-specific translations with competitive accuracy and gender biasmitigation when compared to NLLB, a state-of-the-art multilingual NMT system.Furthermore, our experiments reveal that LLaMa's translations are robust,showing significant performance drops when evaluated against opposite-genderreferences in gender-ambiguous datasets but maintaining consistency in lessambiguous contexts. This research provides insights into the potential andchallenges of using LLMs for gender-specific translations and highlights theimportance of in-context learning to elicit new tasks in LLMs.</description><author>Eduardo Sánchez, Pierre Andrews, Pontus Stenetorp, Mikel Artetxe, Marta R. Costa-jussà</author><pubDate>Wed, 06 Sep 2023 18:24:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03175v1</guid></item><item><title>PDiscoNet: Semantically consistent part discovery for fine-grained recognition</title><link>http://arxiv.org/abs/2309.03173v1</link><description>Fine-grained classification often requires recognizing specific object parts,such as beak shape and wing patterns for birds. Encouraging a fine-grainedclassification model to first detect such parts and then using them to inferthe class could help us gauge whether the model is indeed looking at the rightdetails better than with interpretability methods that provide a singleattribution map. We propose PDiscoNet to discover object parts by using onlyimage-level class labels along with priors encouraging the parts to be:discriminative, compact, distinct from each other, equivariant to rigidtransforms, and active in at least some of the images. In addition to using theappropriate losses to encode these priors, we propose to use part-dropout,where full part feature vectors are dropped at once to prevent a single partfrom dominating in the classification, and part feature vector modulation,which makes the information coming from each part distinct from the perspectiveof the classifier. Our results on CUB, CelebA, and PartImageNet show that theproposed method provides substantially better part discovery performance thanprevious methods while not requiring any additional hyper-parameter tuning andwithout penalizing the classification performance. The code is available athttps://github.com/robertdvdk/part_detection.</description><author>Robert van der Klis, Stephan Alaniz, Massimiliano Mancini, Cassio F. Dantas, Dino Ienco, Zeynep Akata, Diego Marcos</author><pubDate>Wed, 06 Sep 2023 18:19:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03173v1</guid></item><item><title>GPT-InvestAR: Enhancing Stock Investment Strategies through Annual Report Analysis with Large Language Models</title><link>http://arxiv.org/abs/2309.03079v1</link><description>Annual Reports of publicly listed companies contain vital information abouttheir financial health which can help assess the potential impact on Stockprice of the firm. These reports are comprehensive in nature, going up to, andsometimes exceeding, 100 pages. Analysing these reports is cumbersome even fora single firm, let alone the whole universe of firms that exist. Over theyears, financial experts have become proficient in extracting valuableinformation from these documents relatively quickly. However, this requiresyears of practice and experience. This paper aims to simplify the process ofassessing Annual Reports of all the firms by leveraging the capabilities ofLarge Language Models (LLMs). The insights generated by the LLM are compiled ina Quant styled dataset and augmented by historical stock price data. A MachineLearning model is then trained with LLM outputs as features. The walkforwardtest results show promising outperformance wrt S&amp;P500 returns. This paperintends to provide a framework for future work in this direction. To facilitatethis, the code has been released as open source.</description><author>Udit Gupta</author><pubDate>Wed, 06 Sep 2023 18:18:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03079v1</guid></item><item><title>Impression-Informed Multi-Behavior Recommender System: A Hierarchical Graph Attention Approach</title><link>http://arxiv.org/abs/2309.03169v1</link><description>While recommender systems have significantly benefited from implicitfeedback, they have often missed the nuances of multi-behavior interactionsbetween users and items. Historically, these systems either amalgamated allbehaviors, such as \textit{impression} (formerly \textit{view}),\textit{add-to-cart}, and \textit{buy}, under a singular 'interaction' label,or prioritized only the target behavior, often the \textit{buy} action,discarding valuable auxiliary signals. Although recent advancements triedaddressing this simplification, they primarily gravitated towards optimizingthe target behavior alone, battling with data scarcity. Additionally, theytended to bypass the nuanced hierarchy intrinsic to behaviors. To bridge thesegaps, we introduce the \textbf{H}ierarchical \textbf{M}ulti-behavior\textbf{G}raph Attention \textbf{N}etwork (HMGN). This pioneering frameworkleverages attention mechanisms to discern information from both inter andintra-behaviors while employing a multi-task Hierarchical Bayesian PersonalizedRanking (HBPR) for optimization. Recognizing the need for scalability, ourapproach integrates a specialized multi-behavior sub-graph sampling technique.Moreover, the adaptability of HMGN allows for the seamless inclusion ofknowledge metadata and time-series data. Empirical results attest to ourmodel's prowess, registering a notable performance boost of up to 64\% inNDCG@100 metrics over conventional graph neural network methods.</description><author>Dong Li, Divya Bhargavi, Vidya Sagar Ravipati</author><pubDate>Wed, 06 Sep 2023 18:09:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03169v1</guid></item><item><title>Split-Boost Neural Networks</title><link>http://arxiv.org/abs/2309.03167v1</link><description>The calibration and training of a neural network is a complex andtime-consuming procedure that requires significant computational resources toachieve satisfactory results. Key obstacles are a large number ofhyperparameters to select and the onset of overfitting in the face of a smallamount of data. In this framework, we propose an innovative training strategyfor feed-forward architectures - called split-boost - that improves performanceand automatically includes a regularizing behaviour without modeling itexplicitly. Such a novel approach ultimately allows us to avoid explicitlymodeling the regularization term, decreasing the total number ofhyperparameters and speeding up the tuning phase. The proposed strategy istested on a real-world (anonymized) dataset within a benchmark medicalinsurance design problem.</description><author>Raffaele Giuseppe Cestari, Gabriele Maroni, Loris Cannelli, Dario Piga, Simone Formentin</author><pubDate>Wed, 06 Sep 2023 18:08:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03167v1</guid></item><item><title>J-Guard: Journalism Guided Adversarially Robust Detection of AI-generated News</title><link>http://arxiv.org/abs/2309.03164v1</link><description>The rapid proliferation of AI-generated text online is profoundly reshapingthe information landscape. Among various types of AI-generated text,AI-generated news presents a significant threat as it can be a prominent sourceof misinformation online. While several recent efforts have focused ondetecting AI-generated text in general, these methods require enhancedreliability, given concerns about their vulnerability to simple adversarialattacks. Furthermore, due to the eccentricities of news writing, applying thesedetection methods for AI-generated news can produce false positives,potentially damaging the reputation of news organizations. To address thesechallenges, we leverage the expertise of an interdisciplinary team to develop aframework, J-Guard, capable of steering existing supervised AI text detectorsfor detecting AI-generated news while boosting adversarial robustness. Byincorporating stylistic cues inspired by the unique journalistic attributes,J-Guard effectively distinguishes between real-world journalism andAI-generated news articles. Our experiments on news articles generated by avast array of AI models, including ChatGPT (GPT3.5), demonstrate theeffectiveness of J-Guard in enhancing detection capabilities while maintainingan average performance decrease of as low as 7% when faced with adversarialattacks.</description><author>Tharindu Kumarage, Amrita Bhattacharjee, Djordje Padejski, Kristy Roschke, Dan Gillmor, Scott Ruston, Huan Liu, Joshua Garland</author><pubDate>Wed, 06 Sep 2023 18:06:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03164v1</guid></item><item><title>ResFields: Residual Neural Fields for Spatiotemporal Signals</title><link>http://arxiv.org/abs/2309.03160v1</link><description>Neural fields, a category of neural networks trained to representhigh-frequency signals, have gained significant attention in recent years dueto their impressive performance in modeling complex 3D data, especially largeneural signed distance (SDFs) or radiance fields (NeRFs) via a singlemulti-layer perceptron (MLP). However, despite the power and simplicity ofrepresenting signals with an MLP, these methods still face challenges whenmodeling large and complex temporal signals due to the limited capacity ofMLPs. In this paper, we propose an effective approach to address thislimitation by incorporating temporal residual layers into neural fields, dubbedResFields, a novel class of networks specifically designed to effectivelyrepresent complex temporal signals. We conduct a comprehensive analysis of theproperties of ResFields and propose a matrix factorization technique to reducethe number of trainable parameters and enhance generalization capabilities.Importantly, our formulation seamlessly integrates with existing techniques andconsistently improves results across various challenging tasks: 2D videoapproximation, dynamic shape modeling via temporal SDFs, and dynamic NeRFreconstruction. Lastly, we demonstrate the practical utility of ResFields byshowcasing its effectiveness in capturing dynamic 3D scenes from sparse sensoryinputs of a lightweight capture system.</description><author>Marko Mihajlovic, Sergey Prokudin, Marc Pollefeys, Siyu Tang</author><pubDate>Wed, 06 Sep 2023 17:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03160v1</guid></item><item><title>Learning to Recharge: UAV Coverage Path Planning through Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2309.03157v1</link><description>Coverage path planning (CPP) is a critical problem in robotics, where thegoal is to find an efficient path that covers every point in an area ofinterest. This work addresses the power-constrained CPP problem with rechargefor battery-limited unmanned aerial vehicles (UAVs). In this problem, a notablechallenge emerges from integrating recharge journeys into the overall coveragestrategy, highlighting the intricate task of making strategic, long-termdecisions. We propose a novel proximal policy optimization (PPO)-based deepreinforcement learning (DRL) approach with map-based observations, utilizingaction masking and discount factor scheduling to optimize coverage trajectoriesover the entire mission horizon. We further provide the agent with a positionhistory to handle emergent state loops caused by the recharge capability. Ourapproach outperforms a baseline heuristic, generalizes to different targetzones and maps, with limited generalization to unseen maps. We offer valuableinsights into DRL algorithm design for long-horizon problems and provide apublicly available software framework for the CPP problem.</description><author>Mirco Theile, Harald Bayerlein, Marco Caccamo, Alberto L. Sangiovanni-Vincentelli</author><pubDate>Wed, 06 Sep 2023 17:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03157v1</guid></item><item><title>Loss Functions and Metrics in Deep Learning</title><link>http://arxiv.org/abs/2307.02694v2</link><description>One of the essential components of deep learning is the choice of the lossfunction and performance metrics used to train and evaluate models. This paperreviews the most prevalent loss functions and performance measurements in deeplearning. We examine the benefits and limits of each technique and illustratetheir application to various deep-learning problems. Our review aims to give acomprehensive picture of the different loss functions and performanceindicators used in the most common deep learning tasks and help practitionerschoose the best method for their specific task.</description><author>Juan Terven, Diana M. Cordova-Esparza, Alfonso Ramirez-Pedraza, Edgar A. Chavez-Urbiola</author><pubDate>Wed, 06 Sep 2023 17:53:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02694v2</guid></item><item><title>CPPF++: Uncertainty-Aware Sim2Real Object Pose Estimation by Vote Aggregation</title><link>http://arxiv.org/abs/2211.13398v2</link><description>Object pose estimation constitutes a critical area within the domain of 3Dvision. While contemporary state-of-the-art methods that leverage real-worldpose annotations have demonstrated commendable performance, the procurement ofsuch real-world training data incurs substantial costs. This paper focuses on aspecific setting wherein only 3D CAD models are utilized as a priori knowledge,devoid of any background or clutter information. We introduce a novel method,CPPF++, designed for sim-to-real pose estimation. This method builds upon thefoundational point-pair voting scheme of CPPF, reconceptualizing it through aprobabilistic lens. To address the challenge of voting collision, we modelvoting uncertainty by estimating the probabilistic distribution of each pointpair within the canonical space. This approach is further augmented byiterative noise filtering, employed to eradicate votes associated withbackgrounds or clutters. Additionally, we enhance the context provided by eachvoting unit by introducing $N$-point tuples. In conjunction with thismethodological contribution, we present a new category-level pose estimationdataset, DiversePose 300. This dataset is specifically crafted to facilitate amore rigorous evaluation of current state-of-the-art methods, encompassing abroader and more challenging array of real-world scenarios. Empirical resultssubstantiate the efficacy of our proposed method, revealing a significantreduction in the disparity between simulation and real-world performance.</description><author>Yang You, Wenhao He, Jin Liu, Hongkai Xiong, Weiming Wang, Cewu Lu</author><pubDate>Wed, 06 Sep 2023 17:47:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.13398v2</guid></item><item><title>An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation</title><link>http://arxiv.org/abs/2302.06527v3</link><description>Unit tests play a key role in ensuring the correctness of software. However,manually creating unit tests is a laborious task, motivating the need forautomation. Large Language Models (LLMs) have recently been applied to thisproblem, utilizing additional training or few-shot learning on examples ofexisting tests. This paper presents a large-scale empirical evaluation on theeffectiveness of LLMs for automated unit test generation without additionaltraining or manual effort, providing the LLM with the signature andimplementation of the function under test, along with usage examples extractedfrom documentation. We also attempt to repair failed generated tests byre-prompting the model with the failing test and error message. We implementour approach in TestPilot, a test generation tool for JavaScript thatautomatically generates unit tests for all API functions in an npm package. Weevaluate TestPilot using OpenAI's gpt3.5-turbo LLM on 25 npm packages with atotal of 1,684 API functions. The generated tests achieve a median statementcoverage of 70.2% and branch coverage of 52.8%, significantly improving onNessie, a recent feedback-directed JavaScript test generation technique, whichachieves only 51.3% statement coverage and 25.6% branch coverage. We also findthat 92.8% of TestPilot's generated tests have no more than 50% similarity withexisting tests (as measured by normalized edit distance), with none of thembeing exact copies. Finally, we run TestPilot with two additional LLMs,OpenAI's older code-cushman-002 LLM and the open LLM StarCoder. Overall, weobserved similar results with the former (68.2% median statement coverage), andsomewhat worse results with the latter (54.0% median statement coverage),suggesting that the effectiveness of the approach is influenced by the size andtraining set of the LLM, but does not fundamentally depend on the specificmodel.</description><author>Max Schäfer, Sarah Nadi, Aryaz Eghbali, Frank Tip</author><pubDate>Wed, 06 Sep 2023 17:47:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.06527v3</guid></item><item><title>Data-Driven Neural Polar Codes for Unknown Channels With and Without Memory</title><link>http://arxiv.org/abs/2309.03148v1</link><description>In this work, a novel data-driven methodology for designing polar codes forchannels with and without memory is proposed. The methodology is suitable forthe case where the channel is given as a "black-box" and the designer hasaccess to the channel for generating observations of its inputs and outputs,but does not have access to the explicit channel model. The proposed methodleverages the structure of the successive cancellation (SC) decoder to devise aneural SC (NSC) decoder. The NSC decoder uses neural networks (NNs) to replacethe core elements of the original SC decoder, the check-node, the bit-node andthe soft decision. Along with the NSC, we devise additional NN that embeds thechannel outputs into the input space of the SC decoder. The proposed method issupported by theoretical guarantees that include the consistency of the NSC.Also, the NSC has computational complexity that does not grow with the channelmemory size. This sets its main advantage over successive cancellation trellis(SCT) decoder for finite state channels (FSCs) that has complexity of$O(|\mathcal{S}|^3 N\log N)$, where $|\mathcal{S}|$ denotes the number ofchannel states. We demonstrate the performance of the proposed algorithms onmemoryless channels and on channels with memory. The empirical results arecompared with the optimal polar decoder, given by the SC and SCT decoders. Wefurther show that our algorithms are applicable for the case where there SC andSCT decoders are not applicable.</description><author>Ziv Aharoni, Bashar Huleihel, Henry D. Pfister, Haim H. Permuter</author><pubDate>Wed, 06 Sep 2023 17:44:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03148v1</guid></item><item><title>Proceedings of the 2nd International Workshop on Adaptive Cyber Defense</title><link>http://arxiv.org/abs/2308.09520v3</link><description>The 2nd International Workshop on Adaptive Cyber Defense was held at theFlorida Institute of Technology, Florida. This workshop was organized to shareresearch that explores unique applications of Artificial Intelligence (AI) andMachine Learning (ML) as foundational capabilities for the pursuit of adaptivecyber defense. The cyber domain cannot currently be reliably and effectivelydefended without extensive reliance on human experts. Skilled cyber defendersare in short supply and often cannot respond fast enough to cyber threats. Building on recent advances in AI and ML the Cyber defense research communityhas been motivated to develop new dynamic and sustainable defenses through theadoption of AI and ML techniques to cyber settings. Bridging critical gapsbetween AI and Cyber researchers and practitioners can accelerate efforts tocreate semi-autonomous cyber defenses that can learn to recognize and respondto cyber attacks or discover and mitigate weaknesses in cooperation with othercyber operation systems and human experts. Furthermore, these defenses areexpected to be adaptive and able to evolve over time to thwart changes inattacker behavior, changes in the system health and readiness, and naturalshifts in user behavior over time. The workshop was comprised of invited keynote talks, technical presentationsand a panel discussion about how AI/ML can enable autonomous mitigation ofcurrent and future cyber attacks. Workshop submissions were peer reviewed by apanel of domain experts with a proceedings consisting of six technical articlesexploring challenging problems of critical importance to national and globalsecurity. Participation in this workshop offered new opportunities to stimulateresearch and innovation in the emerging domain of adaptive and autonomous cyberdefense.</description><author>Marco Carvalho, Damian Marriott, Mark Bilinski, Ahmad Ridley</author><pubDate>Wed, 06 Sep 2023 17:43:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.09520v3</guid></item><item><title>The Best Arm Evades: Near-optimal Multi-pass Streaming Lower Bounds for Pure Exploration in Multi-armed Bandits</title><link>http://arxiv.org/abs/2309.03145v1</link><description>We give a near-optimal sample-pass trade-off for pure exploration inmulti-armed bandits (MABs) via multi-pass streaming algorithms: any streamingalgorithm with sublinear memory that uses the optimal sample complexity of$O(\frac{n}{\Delta^2})$ requires$\Omega(\frac{\log{(1/\Delta)}}{\log\log{(1/\Delta)}})$ passes. Here, $n$ isthe number of arms and $\Delta$ is the reward gap between the best and thesecond-best arms. Our result matches the $O(\log(\frac{1}{\Delta}))$-passalgorithm of Jin et al. [ICML'21] (up to lower order terms) that only uses$O(1)$ memory and answers an open question posed by Assadi and Wang [STOC'20].</description><author>Sepehr Assadi, Chen Wang</author><pubDate>Wed, 06 Sep 2023 17:41:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03145v1</guid></item><item><title>Using Multiple Vector Channels Improves E(n)-Equivariant Graph Neural Networks</title><link>http://arxiv.org/abs/2309.03139v1</link><description>We present a natural extension to E(n)-equivariant graph neural networks thatuses multiple equivariant vectors per node. We formulate the extension and showthat it improves performance across different physical systems benchmark tasks,with minimal differences in runtime or number of parameters. The proposedmultichannel EGNN outperforms the standard singlechannel EGNN on N-body chargedparticle dynamics, molecular property predictions, and predicting thetrajectories of solar system bodies. Given the additional benefits and minimaladditional cost of multi-channel EGNN, we suggest that this extension may be ofpractical use to researchers working in machine learning for the physicalsciences</description><author>Daniel Levy, Sékou-Oumar Kaba, Carmelo Gonzales, Santiago Miret, Siamak Ravanbakhsh</author><pubDate>Wed, 06 Sep 2023 17:24:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03139v1</guid></item><item><title>Generative Steganography Diffusion</title><link>http://arxiv.org/abs/2305.03472v2</link><description>Generative steganography (GS) is an emerging technique that generates stegoimages directly from secret data. Various GS methods based on GANs or Flow havebeen developed recently. However, existing GAN-based GS methods cannotcompletely recover the hidden secret data due to the lack of networkinvertibility, while Flow-based methods produce poor image quality due to thestringent reversibility restriction in each module. To address this issue, wepropose a novel GS scheme called "Generative Steganography Diffusion" (GSD) bydevising an invertible diffusion model named "StegoDiffusion". It not onlygenerates realistic stego images but also allows for 100\% recovery of thehidden secret data. The proposed StegoDiffusion model leverages a non-Markovchain with a fast sampling technique to achieve efficient stego imagegeneration. By constructing an ordinary differential equation (ODE) based onthe transition probability of the generation process in StegoDiffusion, secretdata and stego images can be converted to each other through the approximatesolver of ODE -- Euler iteration formula, enabling the use of irreversible butmore expressive network structures to achieve model invertibility. Our proposedGSD has the advantages of both reversibility and high performance,significantly outperforming existing GS methods in all metrics.</description><author>Ping Wei, Qing Zhou, Zichi Wang, Zhenxing Qian, Xinpeng Zhang, Sheng Li</author><pubDate>Wed, 06 Sep 2023 17:14:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03472v2</guid></item><item><title>Risk-reducing design and operations toolkit: 90 strategies for managing risk and uncertainty in decision problems</title><link>http://arxiv.org/abs/2309.03133v1</link><description>Uncertainty is a pervasive challenge in decision analysis, and decisiontheory recognizes two classes of solutions: probabilistic models and cognitiveheuristics. However, engineers, public planners and other decision-makersinstead use a third class of strategies that could be called RDOT(Risk-reducing Design and Operations Toolkit). These include incorporatingrobustness into designs, contingency planning, and others that do not fall intothe categories of probabilistic models or cognitive heuristics. Moreover,identical strategies appear in several domains and disciplines, pointing to animportant shared toolkit. The focus of this paper is to develop a catalog of such strategies anddevelop a framework for them. The paper finds more than 90 examples of suchstrategies falling into six broad categories and argues that they provide anefficient response to decision problems that are seemingly intractable due tohigh uncertainty. It then proposes a framework to incorporate them intodecision theory using multi-objective optimization. Overall, RDOT represents an overlooked class of responses to uncertainty.Because RDOT strategies do not depend on accurate forecasting or estimation,they could be applied fruitfully to certain decision problems affected by highuncertainty and make them much more tractable.</description><author>Alexander Gutfraind</author><pubDate>Wed, 06 Sep 2023 17:14:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03133v1</guid></item><item><title>MyoDex: A Generalizable Prior for Dexterous Manipulation</title><link>http://arxiv.org/abs/2309.03130v1</link><description>Human dexterity is a hallmark of motor control. Our hands can rapidlysynthesize new behaviors despite the complexity (multi-articular andmulti-joints, with 23 joints controlled by more than 40 muscles) ofmusculoskeletal sensory-motor circuits. In this work, we take inspiration fromhow human dexterity builds on a diversity of prior experiences, instead ofbeing acquired through a single task. Motivated by this observation, we set outto develop agents that can build upon their previous experience to quicklyacquire new (previously unattainable) behaviors. Specifically, our approachleverages multi-task learning to implicitly capture task-agnostic behavioralpriors (MyoDex) for human-like dexterity, using a physiologically realistichuman hand model - MyoHand. We demonstrate MyoDex's effectiveness in few-shotgeneralization as well as positive transfer to a large repertoire of unseendexterous manipulation tasks. Agents leveraging MyoDex can solve approximately3x more tasks, and 4x faster in comparison to a distillation baseline. Whileprior work has synthesized single musculoskeletal control behaviors, MyoDex isthe first generalizable manipulation prior that catalyzes the learning ofdexterous physiological control across a large variety of contact-richbehaviors. We also demonstrate the effectiveness of our paradigms beyondmusculoskeletal control towards the acquisition of dexterity in 24 DoF AdroitHand. Website: https://sites.google.com/view/myodex</description><author>Vittorio Caggiano, Sudeep Dasari, Vikash Kumar</author><pubDate>Wed, 06 Sep 2023 17:10:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03130v1</guid></item><item><title>Defense-Prefix for Preventing Typographic Attacks on CLIP</title><link>http://arxiv.org/abs/2304.04512v3</link><description>Vision-language pre-training models (VLPs) have exhibited revolutionaryimprovements in various vision-language tasks. In VLP, some adversarial attacksfool a model into false or absurd classifications. Previous studies addressedthese attacks by fine-tuning the model or changing its architecture. However,these methods risk losing the original model's performance and are difficult toapply to downstream tasks. In particular, their applicability to other taskshas not been considered. In this study, we addressed the reduction of theimpact of typographic attacks on CLIP without changing the model parameters. Toachieve this, we expand the idea of "prefix learning" and introduce our simpleyet effective method: Defense-Prefix (DP), which inserts the DP token before aclass name to make words "robust" against typographic attacks. Our method canbe easily applied to downstream tasks, such as object detection, because theproposed method is independent of the model parameters. Our methodsignificantly improves the accuracy of classification tasks for typographicattack datasets, while maintaining the zero-shot capabilities of the model. Inaddition, we leverage our proposed method for object detection, demonstratingits high applicability and effectiveness. The codes and datasets are availableat https://github.com/azuma164/Defense-Prefix.</description><author>Hiroki Azuma, Yusuke Matsui</author><pubDate>Wed, 06 Sep 2023 17:05:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.04512v3</guid></item><item><title>Everyone Deserves A Reward: Learning Customized Human Preferences</title><link>http://arxiv.org/abs/2309.03126v1</link><description>Reward models (RMs) are crucial in aligning large language models (LLMs) withhuman preferences for improving interaction quality. However, the real world ispluralistic, which leads to diversified human preferences based on differentreligions, politics, cultures, etc. Moreover, each individual can have theirown unique preferences on various topics. Neglecting the diversity of humanpreferences, current LLM training processes only use a general reward model,which is below satisfaction for customized or personalized applicationscenarios. To explore customized preference learning, we collect adomain-specific preference (DSP) dataset, which collects preferred responses toeach given query from four practical domains. Besides, from the perspective ofdata efficiency, we proposed a three-stage customized RM learning scheme, whoseeffectiveness is empirically verified on both general preference datasets andour DSP set. Furthermore, we test multiple training and data strategies on thethree learning stages, and have found several ways to better preserve thegeneral preferring ability while training the customized RMs, especiallygeneral preference enrichment and customized preference imitation learning. TheDSP dataset and code are available at https://github.com/Linear95/DSP.</description><author>Pengyu Cheng, Jiawen Xie, Ke Bai, Yong Dai, Nan Du</author><pubDate>Wed, 06 Sep 2023 17:03:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03126v1</guid></item><item><title>Knowledge Solver: Teaching LLMs to Search for Domain Knowledge from Knowledge Graphs</title><link>http://arxiv.org/abs/2309.03118v1</link><description>Large language models (LLMs), such as ChatGPT and GPT-4, are versatile andcan solve different tasks due to their emergent ability and generalizability.However, LLMs sometimes lack domain-specific knowledge to perform tasks, whichwould also cause hallucination during inference. In some previous works,additional modules like graph neural networks (GNNs) are trained on retrievedknowledge from external knowledge bases, aiming to mitigate the problem oflacking domain-specific knowledge. However, incorporating additional modules:1) would need retraining additional modules when encountering novel domains; 2)would become a bottleneck since LLMs' strong abilities are not fully utilizedfor retrieval. In this paper, we propose a paradigm, termed Knowledge Solver(KSL), to teach LLMs to search for essential knowledge from external knowledgebases by harnessing their own strong generalizability. Specifically, we designa simple yet effective prompt to transform retrieval into a multi-hop decisionsequence, which empowers LLMs with searching knowledge ability in zero-shotmanner. Additionally, KSL is able to provide complete retrieval paths andtherefore increase explainability of LLMs' reasoning processes. We conductexperiments on three datasets: CommonsenseQA, OpenbookQA, and MedQA-USMLE, andfound that our approach improves LLM baseline performance by a relatively largemargin.</description><author>Chao Feng, Xinyu Zhang, Zichu Fei</author><pubDate>Wed, 06 Sep 2023 16:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03118v1</guid></item><item><title>Detecting Manufacturing Defects in PCBs via Data-Centric Machine Learning on Solder Paste Inspection Features</title><link>http://arxiv.org/abs/2309.03113v1</link><description>Automated detection of defects in Printed Circuit Board (PCB) manufacturingusing Solder Paste Inspection (SPI) and Automated Optical Inspection (AOI)machines can help improve operational efficiency and significantly reduce theneed for manual intervention. In this paper, using SPI-extracted features of 6million pins, we demonstrate a data-centric approach to train Machine Learning(ML) models to detect PCB defects at three stages of PCB manufacturing. The 6million PCB pins correspond to 2 million components that belong to 15,387 PCBs.Using a base extreme gradient boosting (XGBoost) ML model, we iterate on thedata pre-processing step to improve detection performance. Combining pin-levelSPI features using component and PCB IDs, we developed training instances alsoat the component and PCB level. This allows the ML model to capture anyinter-pin, inter-component, or spatial effects that may not be apparent at thepin level. Models are trained at the pin, component, and PCB levels, and thedetection results from the different models are combined to identify defectivecomponents.</description><author>Jubilee Prasad-Rao, Roohollah Heidary, Jesse Williams</author><pubDate>Wed, 06 Sep 2023 16:52:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03113v1</guid></item><item><title>Do We Still Need Non-Maximum Suppression? Accurate Confidence Estimates and Implicit Duplication Modeling with IoU-Aware Calibration</title><link>http://arxiv.org/abs/2309.03110v1</link><description>Object detectors are at the heart of many semi- and fully autonomous decisionsystems and are poised to become even more indispensable. They are, however,still lacking in accessibility and can sometimes produce unreliablepredictions. Especially concerning in this regard are the -- essentiallyhand-crafted -- non-maximum suppression algorithms that lead to an obfuscatedprediction process and biased confidence estimates. We show that we caneliminate classic NMS-style post-processing by using IoU-aware calibration.IoU-aware calibration is a conditional Beta calibration; this makes itparallelizable with no hyper-parameters. Instead of arbitrary cutoffs ordiscounts, it implicitly accounts for the likelihood of each detection being aduplicate and adjusts the confidence score accordingly, resulting inempirically based precision estimates for each detection. Our extensiveexperiments on diverse detection architectures show that the proposed IoU-awarecalibration can successfully model duplicate detections and improvecalibration. Compared to the standard sequential NMS and calibration approach,our joint modeling can deliver performance gains over the best NMS-basedalternative while producing consistently better-calibrated confidencepredictions with less complexity. The\hyperlink{https://github.com/Blueblue4/IoU-AwareCalibration}{code} for all ourexperiments is publicly available.</description><author>Johannes Gilg, Torben Teepe, Fabian Herzog, Philipp Wolters, Gerhard Rigoll</author><pubDate>Wed, 06 Sep 2023 16:47:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03110v1</guid></item><item><title>Open problems in causal structure learning: A case study of COVID-19 in the UK</title><link>http://arxiv.org/abs/2305.03859v2</link><description>Causal machine learning (ML) algorithms recover graphical structures thattell us something about cause-and-effect relationships. The causalrepresentation praovided by these algorithms enables transparency andexplainability, which is necessary for decision making in critical real-worldproblems. Yet, causal ML has had limited impact in practice compared toassociational ML. This paper investigates the challenges of causal ML withapplication to COVID-19 UK pandemic data. We collate data from various publicsources and investigate what the various structure learning algorithms learnfrom these data. We explore the impact of different data formats on algorithmsspanning different classes of learning, and assess the results produced by eachalgorithm, and groups of algorithms, in terms of graphical structure, modeldimensionality, sensitivity analysis, confounding variables, predictive andinterventional inference. We use these results to highlight open problems incausal structure learning and directions for future research. To facilitatefuture work, we make all graphs, models, data sets, and source code publiclyavailable online.</description><author>Anthony Constantinou, Neville K. Kitson, Yang Liu, Kiattikun Chobtham, Arian Hashemzadeh, Praharsh A. Nanavati, Rendani Mbuvha, Bruno Petrungaro</author><pubDate>Wed, 06 Sep 2023 16:42:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03859v2</guid></item><item><title>ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation Following the Metaphor Identification Procedure</title><link>http://arxiv.org/abs/2309.03103v1</link><description>This paper presents ContrastWSD, a RoBERTa-based metaphor detection modelthat integrates the Metaphor Identification Procedure (MIP) and Word SenseDisambiguation (WSD) to extract and contrast the contextual meaning with thebasic meaning of a word to determine whether it is used metaphorically in asentence. By utilizing the word senses derived from a WSD model, our modelenhances the metaphor detection process and outperforms other methods that relysolely on contextual embeddings or integrate only the basic definitions andother external knowledge. We evaluate our approach on various benchmarkdatasets and compare it with strong baselines, indicating the effectiveness inadvancing metaphor detection.</description><author>Mohamad Elzohbi, Richard Zhao</author><pubDate>Wed, 06 Sep 2023 16:41:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03103v1</guid></item><item><title>FArMARe: a Furniture-Aware Multi-task methodology for Recommending Apartments based on the user interests</title><link>http://arxiv.org/abs/2309.03100v1</link><description>Nowadays, many people frequently have to search for new accommodationoptions. Searching for a suitable apartment is a time-consuming process,especially because visiting them is often mandatory to assess the truthfulnessof the advertisements found on the Web. While this process could be alleviatedby visiting the apartments in the metaverse, the Web-based recommendationplatforms are not suitable for the task. To address this shortcoming, in thispaper, we define a new problem called text-to-apartment recommendation, whichrequires ranking the apartments based on their relevance to a textual queryexpressing the user's interests. To tackle this problem, we introduce FArMARe,a multi-task approach that supports cross-modal contrastive training with afurniture-aware objective. Since public datasets related to indoor scenes donot contain detailed descriptions of the furniture, we collect and annotate adataset comprising more than 6000 apartments. A thorough experimentation withthree different methods and two raw feature extraction procedures reveals theeffectiveness of FArMARe in dealing with the problem at hand.</description><author>Ali Abdari, Alex Falcon, Giuseppe Serra</author><pubDate>Wed, 06 Sep 2023 16:40:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03100v1</guid></item><item><title>CodeApex: A Bilingual Programming Evaluation Benchmark for Large Language Models</title><link>http://arxiv.org/abs/2309.01940v2</link><description>With the emergence of Large Language Models (LLMs), there has been asignificant improvement in the programming capabilities of models, attractinggrowing attention from researchers. We propose CodeApex, a bilingual benchmarkdataset focusing on the programming comprehension and code generation abilitiesof LLMs. CodeApex comprises three types of multiple-choice questions:conceptual understanding, commonsense reasoning, and multi-hop reasoning,designed to evaluate LLMs on programming comprehension tasks. Additionally,CodeApex utilizes algorithmic questions and corresponding test cases to assessthe code quality generated by LLMs. We evaluate 14 state-of-the-art LLMs,including both general-purpose and specialized models. GPT exhibits the bestprogramming capabilities, achieving approximate accuracies of 50% and 56% onthe two tasks, respectively. There is still significant room for improvement inprogramming tasks. We hope that CodeApex can serve as a reference forevaluating the coding capabilities of LLMs, further promoting their developmentand growth. Datasets are released at https://github.com/APEXLAB/CodeApex.git.CodeApex submission website is https://apex.sjtu.edu.cn/codeapex/.</description><author>Lingyue Fu, Huacan Chai, Shuang Luo, Kounianhua Du, Weiming Zhang, Longteng Fan, Jiayi Lei, Renting Rui, Jianghao Lin, Yuchen Fang, Yifan Liu, Jingkuan Wang, Siyuan Qi, Kangning Zhang, Weinan Zhang, Yong Yu</author><pubDate>Wed, 06 Sep 2023 16:36:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01940v2</guid></item><item><title>Towards Privacy-Aware Causal Structure Learning in Federated Setting</title><link>http://arxiv.org/abs/2211.06919v2</link><description>Causal structure learning has been extensively studied and widely used inmachine learning and various applications. To achieve an ideal performance,existing causal structure learning algorithms often need to centralize a largeamount of data from multiple data sources. However, in the privacy-preservingsetting, it is impossible to centralize data from all sources and put themtogether as a single dataset. To preserve data privacy, federated learning as anew learning paradigm has attracted much attention in machine learning inrecent years. In this paper, we study a privacy-aware causal structure learningproblem in the federated setting and propose a novel Federated PC (FedPC)algorithm with two new strategies for preserving data privacy withoutcentralizing data. Specifically, we first propose a novel layer-wiseaggregation strategy for a seamless adaptation of the PC algorithm into thefederated learning paradigm for federated skeleton learning, then we design aneffective strategy for learning consistent separation sets for federated edgeorientation. The extensive experiments validate that FedPC is effective forcausal structure learning in a federated learning setting.</description><author>Jianli Huang, Xianjie Guo, Kui Yu, Fuyuan Cao, Jiye Liang</author><pubDate>Wed, 06 Sep 2023 16:32:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.06919v2</guid></item><item><title>ORL-AUDITOR: Dataset Auditing in Offline Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2309.03081v1</link><description>Data is a critical asset in AI, as high-quality datasets can significantlyimprove the performance of machine learning models. In safety-critical domainssuch as autonomous vehicles, offline deep reinforcement learning (offline DRL)is frequently used to train models on pre-collected datasets, as opposed totraining these models by interacting with the real-world environment as theonline DRL. To support the development of these models, many institutions makedatasets publicly available with opensource licenses, but these datasets are atrisk of potential misuse or infringement. Injecting watermarks to the datasetmay protect the intellectual property of the data, but it cannot handledatasets that have already been published and is infeasible to be alteredafterward. Other existing solutions, such as dataset inference and membershipinference, do not work well in the offline DRL scenario due to the diversemodel behavior characteristics and offline setting constraints. In this paper,we advocate a new paradigm by leveraging the fact that cumulative rewards canact as a unique identifier that distinguishes DRL models trained on a specificdataset. To this end, we propose ORL-AUDITOR, which is the firsttrajectory-level dataset auditing mechanism for offline RL scenarios. Ourexperiments on multiple offline DRL models and tasks reveal the efficacy ofORL-AUDITOR, with auditing accuracy over 95% and false positive rates less than2.88%. We also provide valuable insights into the practical implementation ofORL-AUDITOR by studying various parameter settings. Furthermore, we demonstratethe auditing capability of ORL-AUDITOR on open-source datasets from Google andDeepMind, highlighting its effectiveness in auditing published datasets.ORL-AUDITOR is open-sourced at https://github.com/link-zju/ORL-Auditor.</description><author>Linkang Du, Min Chen, Mingyang Sun, Shouling Ji, Peng Cheng, Jiming Chen, Zhikun Zhang</author><pubDate>Wed, 06 Sep 2023 16:28:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03081v1</guid></item><item><title>Parameterizing pressure-temperature profiles of exoplanet atmospheres with neural networks</title><link>http://arxiv.org/abs/2309.03075v1</link><description>Atmospheric retrievals (AR) of exoplanets typically rely on a combination ofa Bayesian inference technique and a forward simulator to estimate atmosphericproperties from an observed spectrum. A key component in simulating spectra isthe pressure-temperature (PT) profile, which describes the thermal structure ofthe atmosphere. Current AR pipelines commonly use ad hoc fitting functions herethat limit the retrieved PT profiles to simple approximations, but still use arelatively large number of parameters. In this work, we introduce aconceptually new, data-driven parameterization scheme for physically consistentPT profiles that does not require explicit assumptions about the functionalform of the PT profiles and uses fewer parameters than existing methods. Ourapproach consists of a latent variable model (based on a neural network) thatlearns a distribution over functions (PT profiles). Each profile is representedby a low-dimensional vector that can be used to condition a decoder networkthat maps $P$ to $T$. When training and evaluating our method on two publiclyavailable datasets of self-consistent PT profiles, we find that our methodachieves, on average, better fit quality than existing baseline methods,despite using fewer parameters. In an AR based on existing literature, ourmodel (using two parameters) produces a tighter, more accurate posterior forthe PT profile than the five-parameter polynomial baseline, while also speedingup the retrieval by more than a factor of three. By providing parametric accessto physically consistent PT profiles, and by reducing the number of parametersrequired to describe a PT profile (thereby reducing computational cost orfreeing resources for additional parameters of interest), our method can helpimprove AR and thus our understanding of exoplanet atmospheres and theirhabitability.</description><author>Timothy D. Gebhard, Daniel Angerhausen, Björn S. Konrad, Eleonora Alei, Sascha P. Quanz, Bernhard Schölkopf</author><pubDate>Wed, 06 Sep 2023 16:22:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03075v1</guid></item><item><title>Character Queries: A Transformer-based Approach to On-Line Handwritten Character Segmentation</title><link>http://arxiv.org/abs/2309.03072v1</link><description>On-line handwritten character segmentation is often associated withhandwriting recognition and even though recognition models include mechanismsto locate relevant positions during the recognition process, it is typicallyinsufficient to produce a precise segmentation. Decoupling the segmentationfrom the recognition unlocks the potential to further utilize the result of therecognition. We specifically focus on the scenario where the transcription isknown beforehand, in which case the character segmentation becomes anassignment problem between sampling points of the stylus trajectory andcharacters in the text. Inspired by the $k$-means clustering algorithm, we viewit from the perspective of cluster assignment and present a Transformer-basedarchitecture where each cluster is formed based on a learned character query inthe Transformer decoder block. In order to assess the quality of our approach,we create character segmentation ground truths for two popular on-linehandwriting datasets, IAM-OnDB and HANDS-VNOnDB, and evaluate multiple methodson them, demonstrating that our approach achieves the overall best results.</description><author>Michael Jungo, Beat Wolf, Andrii Maksai, Claudiu Musat, Andreas Fischer</author><pubDate>Wed, 06 Sep 2023 16:19:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03072v1</guid></item><item><title>Conflict-Aware Active Automata Learning (Extended Version)</title><link>http://arxiv.org/abs/2308.14781v3</link><description>Active automata learning algorithms cannot easily handle conflict in theobservation data (different outputs observed for the same inputs). Thisinherent inability to recover after a conflict impairs their effectiveapplicability in scenarios where noise is present or the system under learningis mutating. We propose the Conflict-Aware Active Automata Learning (C3AL) framework toenable handling conflicting information during the learning process. The coreidea is to consider the so-called observation tree as a first-class citizen inthe learning process. Though this idea is explored in recent work, we take itto its full effect by enabling its use with any existing learner and minimizingthe number of tests performed on the system under learning, specially in theface of conflicts. We evaluate C3AL in a large set of benchmarks, covering over30 different realistic targets, and over 18,000 different scenarios. Theresults of the evaluation show that C3AL is a suitable alternative frameworkfor closed-box learning that can better handle noise and mutations.</description><author>Tiago Ferreira, Léo Henry, Raquel Fernandes da Silva, Alexandra Silva</author><pubDate>Wed, 06 Sep 2023 16:15:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.14781v3</guid></item><item><title>Towards eXplainable AI for Mobility Data Science</title><link>http://arxiv.org/abs/2307.08461v2</link><description>This paper presents our ongoing work towards XAI for Mobility Data Scienceapplications, focusing on explainable models that can learn from densetrajectory data, such as GPS tracks of vehicles and vessels using temporalgraph neural networks (GNNs) and counterfactuals. We review the existing GeoXAIstudies, argue the need for comprehensible explanations with human-centeredapproaches, and outline a research path toward XAI for Mobility Data Science.</description><author>Anahid Jalali, Anita Graser, Clemens Heistracher</author><pubDate>Wed, 06 Sep 2023 16:13:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08461v2</guid></item><item><title>Extraction of Visual Information to Predict Crowdfunding Success</title><link>http://arxiv.org/abs/2203.14806v2</link><description>Researchers have increasingly turned to crowdfunding platforms to gaininsights into entrepreneurial activity and dynamics. While previous studieshave explored various factors influencing crowdfunding success, such astechnology, communication, and marketing strategies, the role of visualelements that can be automatically extracted from images has received lessattention. This is surprising, considering that crowdfunding platformsemphasize the importance of attention-grabbing and high-resolution images, andprevious research has shown that image characteristics can significantly impactproduct evaluations. Indeed, a comprehensive review of empirical articles (n =202) that utilized Kickstarter data, focusing on the incorporation of visualinformation in their analyses. Our findings reveal that only 29.70% controlledfor the number of images, and less than 12% considered any image details. Inthis manuscript, we review the literature on image processing and its relevanceto the business domain, highlighting two types of visual variables: visualcounts (number of pictures and number of videos) and image details. Buildingupon previous work that discussed the role of color, composition andfigure-ground relationships, we introduce visual scene elements that have notyet been explored in crowdfunding, including the number of faces, the number ofconcepts depicted, and the ease of identifying those concepts. To demonstratethe predictive value of visual counts and image details, we analyze Kickstarterdata. Our results highlight that visual count features are two of the top threepredictors of success. Our results also show that simple image detail featuressuch as color matter a lot, and our proposed measures of visual scene elementscan also be useful. We supplement our article with R and Python codes that helpauthors extract image details (https://osf.io/ujnzp/).</description><author>S. J. Blanchard, T. J. Noseworthy, E. Pancer, M. Poole</author><pubDate>Wed, 06 Sep 2023 16:13:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.14806v2</guid></item><item><title>A Multimodal Analysis of Influencer Content on Twitter</title><link>http://arxiv.org/abs/2309.03064v1</link><description>Influencer marketing involves a wide range of strategies in which brandscollaborate with popular content creators (i.e., influencers) to leverage theirreach, trust, and impact on their audience to promote and endorse products orservices. Because followers of influencers are more likely to buy a productafter receiving an authentic product endorsement rather than an explicit directproduct promotion, the line between personal opinions and commercial contentpromotion is frequently blurred. This makes automatic detection of regulatorycompliance breaches related to influencer advertising (e.g., misleadingadvertising or hidden sponsorships) particularly difficult. In this work, we(1) introduce a new Twitter (now X) dataset consisting of 15,998 influencerposts mapped into commercial and non-commercial categories for assisting in theautomatic detection of commercial influencer content; (2) experiment with anextensive set of predictive models that combine text and visual informationshowing that our proposed cross-attention approach outperforms state-of-the-artmultimodal models; and (3) conduct a thorough analysis of strengths andlimitations of our models. We show that multimodal modeling is useful foridentifying commercial posts, reducing the amount of false positives, andcapturing relevant context that aids in the discovery of undisclosed commercialposts.</description><author>Danae Sánchez Villegas, Catalina Goanta, Nikolaos Aletras</author><pubDate>Wed, 06 Sep 2023 16:07:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03064v1</guid></item><item><title>Memory Efficient Optimizers with 4-bit States</title><link>http://arxiv.org/abs/2309.01507v2</link><description>Optimizer states are a major source of memory consumption for training neuralnetworks, limiting the maximum trainable model within given memory budget.Compressing the optimizer states from 32-bit floating points to lower bitwidthis promising to reduce the training memory footprint, while the current lowestachievable bitwidth is 8-bit. In this work, we push optimizer states bitwidthdown to 4-bit through a detailed empirical analysis of first and secondmoments. Specifically, we find that moments have complicated outlier patterns,that current block-wise quantization cannot accurately approximate. We use asmaller block size and propose to utilize both row-wise and column-wiseinformation for better quantization. We further identify a zero point problemof quantizing the second moment, and solve this problem with a linear quantizerthat excludes the zero point. Our 4-bit optimizer is evaluated on a widevariety of benchmarks including natural language understanding, machinetranslation, image classification, and instruction tuning. On all the tasks ouroptimizers can achieve comparable accuracy with their full-precisioncounterparts, while enjoying better memory efficiency.</description><author>Bingrui Li, Jianfei Chen, Jun Zhu</author><pubDate>Wed, 06 Sep 2023 16:06:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01507v2</guid></item><item><title>Prompt-based All-in-One Image Restoration using CNNs and Transformer</title><link>http://arxiv.org/abs/2309.03063v1</link><description>Image restoration aims to recover the high-quality images from their degradedobservations. Since most existing methods have been dedicated into singledegradation removal, they may not yield optimal results on other types ofdegradations, which do not satisfy the applications in real world scenarios. Inthis paper, we propose a novel data ingredient-oriented approach that leveragesprompt-based learning to enable a single model to efficiently tackle multipleimage degradation tasks. Specifically, we utilize a encoder to capture featuresand introduce prompts with degradation-specific information to guide thedecoder in adaptively recovering images affected by various degradations. Inorder to model the local invariant properties and non-local information forhigh-quality image restoration, we combined CNNs operations and Transformers.Simultaneously, we made several key designs in the Transformer blocks(multi-head rearranged attention with prompts and simple-gate feed-forwardnetwork) to reduce computational requirements and selectively determines whatinformation should be persevered to facilitate efficient recovery ofpotentially sharp images. Furthermore, we incorporate a feature fusionmechanism further explores the multi-scale information to improve theaggregated features. The resulting tightly interlinked hierarchy architecture,named as CAPTNet, despite being designed to handle different types ofdegradations, extensive experiments demonstrate that our method performscompetitively to the task-specific algorithms.</description><author>Hu Gao, Jing Yang, Ning Wang, Jingfan Yang, Ying Zhang, Depeng Dang</author><pubDate>Wed, 06 Sep 2023 16:05:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03063v1</guid></item><item><title>Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research</title><link>http://arxiv.org/abs/2307.02131v3</link><description>The field of explainability in artificial intelligence has witnessed agrowing number of studies and increasing scholarly interest. However, the lackof human-friendly and individual interpretations in explaining the outcomes ofmachine learning algorithms has significantly hindered the acceptance of thesemethods by clinicians in their research and clinical practice. To address this,our study employs counterfactual explanations to explore "what if?" scenariosin medical research, aiming to expand our understanding beyond existingboundaries on magnetic resonance imaging (MRI) features for diagnosingpediatric posterior fossa brain tumors. In our case study, the proposed conceptprovides a novel way to examine alternative decision-making scenarios thatoffer personalized and context-specific insights, enabling the validation ofpredictions and clarification of variations under diverse circumstances.Additionally, we explore the potential use of counterfactuals for dataaugmentation and evaluate their feasibility as an alternative approach in ourmedical research case. The results demonstrate the promising potential of usingcounterfactual explanations to enhance trust and acceptance of AI-drivenmethods in clinical research.</description><author>Toygar Tanyel, Serkan Ayvaz, Bilgin Keserci</author><pubDate>Wed, 06 Sep 2023 16:04:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02131v3</guid></item><item><title>A Topological Deep Learning Framework for Neural Spike Decoding</title><link>http://arxiv.org/abs/2212.05037v2</link><description>The brain's spatial orientation system uses different neuron ensembles to aidin environment-based navigation. Two of the ways brains encode spatialinformation is through head direction cells and grid cells. Brains use headdirection cells to determine orientation whereas grid cells consist of layersof decked neurons that overlay to provide environment-based navigation. Theseneurons fire in ensembles where several neurons fire at once to activate asingle head direction or grid. We want to capture this firing structure and useit to decode head direction grid cell data. Understanding, representing, anddecoding these neural structures requires models that encompass higher orderconnectivity, more than the 1-dimensional connectivity that traditionalgraph-based models provide. To that end, in this work, we develop a topologicaldeep learning framework for neural spike train decoding. Our framework combinesunsupervised simplicial complex discovery with the power of deep learning via anew architecture we develop herein called a simplicial convolutional recurrentneural network. Simplicial complexes, topological spaces that use not onlyvertices and edges but also higher-dimensional objects, naturally generalizegraphs and capture more than just pairwise relationships. Additionally, thisapproach does not require prior knowledge of the neural activity beyond spikecounts, which removes the need for similarity measurements. The effectivenessand versatility of the simplicial convolutional neural network is demonstratedon head direction and trajectory prediction via head direction and grid celldatasets.</description><author>Edward C. Mitchell, Brittany Story, David Boothe, Piotr J. Franaszczuk, Vasileios Maroulas</author><pubDate>Wed, 06 Sep 2023 16:03:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.05037v2</guid></item><item><title>Learning Active Subspaces for Effective and Scalable Uncertainty Quantification in Deep Neural Networks</title><link>http://arxiv.org/abs/2309.03061v1</link><description>Bayesian inference for neural networks, or Bayesian deep learning, has thepotential to provide well-calibrated predictions with quantified uncertaintyand robustness. However, the main hurdle for Bayesian deep learning is itscomputational complexity due to the high dimensionality of the parameter space.In this work, we propose a novel scheme that addresses this limitation byconstructing a low-dimensional subspace of the neural networkparameters-referred to as an active subspace-by identifying the parameterdirections that have the most significant influence on the output of the neuralnetwork. We demonstrate that the significantly reduced active subspace enableseffective and scalable Bayesian inference via either Monte Carlo (MC) samplingmethods, otherwise computationally intractable, or variational inference.Empirically, our approach provides reliable predictions with robust uncertaintyestimates for various regression tasks.</description><author>Sanket Jantre, Nathan M. Urban, Xiaoning Qian, Byung-Jun Yoon</author><pubDate>Wed, 06 Sep 2023 16:00:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03061v1</guid></item><item><title>CoLA: Exploiting Compositional Structure for Automatic and Efficient Numerical Linear Algebra</title><link>http://arxiv.org/abs/2309.03060v1</link><description>Many areas of machine learning and science involve large linear algebraproblems, such as eigendecompositions, solving linear systems, computing matrixexponentials, and trace estimation. The matrices involved often have Kronecker,convolutional, block diagonal, sum, or product structure. In this paper, wepropose a simple but general framework for large-scale linear algebra problemsin machine learning, named CoLA (Compositional Linear Algebra). By combining alinear operator abstraction with compositional dispatch rules, CoLAautomatically constructs memory and runtime efficient numerical algorithms.Moreover, CoLA provides memory efficient automatic differentiation, lowprecision computation, and GPU acceleration in both JAX and PyTorch, while alsoaccommodating new objects, operations, and rules in downstream packages viamultiple dispatch. CoLA can accelerate many algebraic operations, while makingit easy to prototype matrix structures and algorithms, providing an appealingdrop-in tool for virtually any computational effort that requires linearalgebra. We showcase its efficacy across a broad range of applications,including partial differential equations, Gaussian processes, equivariant modelconstruction, and unsupervised learning.</description><author>Andres Potapczynski, Marc Finzi, Geoff Pleiss, Andrew Gordon Wilson</author><pubDate>Wed, 06 Sep 2023 15:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03060v1</guid></item><item><title>Hide and Seek (HaS): A Lightweight Framework for Prompt Privacy Protection</title><link>http://arxiv.org/abs/2309.03057v1</link><description>Numerous companies have started offering services based on large languagemodels (LLM), such as ChatGPT, which inevitably raises privacy concerns asusers' prompts are exposed to the model provider. Previous research on securereasoning using multi-party computation (MPC) has proven to be impractical forLLM applications due to its time-consuming and communication-intensive nature.While lightweight anonymization techniques can protect private information inprompts through substitution or masking, they fail to recover sensitive datareplaced in the LLM-generated results. In this paper, we expand the applicationscenarios of anonymization techniques by training a small local model tode-anonymize the LLM's returned results with minimal computational overhead. Weintroduce the HaS framework, where "H(ide)" and "S(eek)" represent its two coreprocesses: hiding private entities for anonymization and seeking privateentities for de-anonymization, respectively. To quantitatively assess HaS'sprivacy protection performance, we propose both black-box and white-boxadversarial models. Furthermore, we conduct experiments to evaluate HaS'susability in translation and classification tasks. The experimental findingsdemonstrate that the HaS framework achieves an optimal balance between privacyprotection and utility.</description><author>Yu Chen, Tingxin Li, Huiming Liu, Yang Yu</author><pubDate>Wed, 06 Sep 2023 15:54:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03057v1</guid></item><item><title>Adaptive Growth: Real-time CNN Layer Expansion</title><link>http://arxiv.org/abs/2309.03049v1</link><description>Deep Neural Networks (DNNs) have shown unparalleled achievements in numerousapplications, reflecting their proficiency in managing vast data sets. Yet,their static structure limits their adaptability in ever-changing environments.This research presents a new algorithm that allows the convolutional layer of aConvolutional Neural Network (CNN) to dynamically evolve based on data input,while still being seamlessly integrated into existing DNNs. Instead of a rigidarchitecture, our approach iteratively introduces kernels to the convolutionallayer, gauging its real-time response to varying data. This process is refinedby evaluating the layer's capacity to discern image features, guiding itsgrowth. Remarkably, our unsupervised method has outstripped its supervisedcounterparts across diverse datasets like MNIST, Fashion-MNIST, CIFAR-10, andCIFAR-100. It also showcases enhanced adaptability in transfer learningscenarios. By introducing a data-driven model scalability strategy, we arefilling a void in deep learning, leading to more flexible and efficient DNNssuited for dynamic settings.Code:(https://github.com/YunjieZhu/Extensible-Convolutional-Layer-git-version).</description><author>Yunjie Zhu, Yunhao Chen</author><pubDate>Wed, 06 Sep 2023 15:43:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03049v1</guid></item><item><title>Exploring Semantic Consistency in Unpaired Image Translation to Generate Data for Surgical Applications</title><link>http://arxiv.org/abs/2309.03048v1</link><description>In surgical computer vision applications, obtaining labeled training data ischallenging due to data-privacy concerns and the need for expert annotation.Unpaired image-to-image translation techniques have been explored toautomatically generate large annotated datasets by translating synthetic imagesto the realistic domain. However, preserving the structure and semanticconsistency between the input and translated images presents significantchallenges, mainly when there is a distributional mismatch in the semanticcharacteristics of the domains. This study empirically investigates unpairedimage translation methods for generating suitable data in surgicalapplications, explicitly focusing on semantic consistency. We extensivelyevaluate various state-of-the-art image translation models on two challengingsurgical datasets and downstream semantic segmentation tasks. We find that asimple combination of structural-similarity loss and contrastive learningyields the most promising results. Quantitatively, we show that the datagenerated with this approach yields higher semantic consistency and can be usedmore effectively as training data.</description><author>Danush Kumar Venkatesh, Dominik Rivior, Micha Pfeiffer, Fiona Kolbinger, Marius Distler, Jürgen Weitz, Stefanie Speidel</author><pubDate>Wed, 06 Sep 2023 15:43:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03048v1</guid></item><item><title>Combining pre-trained Vision Transformers and CIDER for Out Of Domain Detection</title><link>http://arxiv.org/abs/2309.03047v1</link><description>Out-of-domain (OOD) detection is a crucial component in industrialapplications as it helps identify when a model encounters inputs that areoutside the training distribution. Most industrial pipelines rely onpre-trained models for downstream tasks such as CNN or Vision Transformers.This paper investigates the performance of those models on the task ofout-of-domain detection. Our experiments demonstrate that pre-trainedtransformers models achieve higher detection performance out of the box.Furthermore, we show that pre-trained ViT and CNNs can be combined withrefinement methods such as CIDER to improve their OOD detection performanceeven more. Our results suggest that transformers are a promising approach forOOD detection and set a stronger baseline for this task in many contexts</description><author>Grégor Jouet, Clément Duhart, Francis Rousseaux, Julio Laborde, Cyril de Runz</author><pubDate>Wed, 06 Sep 2023 15:41:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03047v1</guid></item><item><title>Unified Convergence Theory of Stochastic and Variance-Reduced Cubic Newton Methods</title><link>http://arxiv.org/abs/2302.11962v2</link><description>We study stochastic Cubic Newton methods for solving general possiblynon-convex minimization problems. We propose a new framework, which we call thehelper framework, that provides a unified view of the stochastic andvariance-reduced second-order algorithms equipped with global complexityguarantees. It can also be applied to learning with auxiliary information. Ourhelper framework offers the algorithm designer high flexibility forconstructing and analyzing the stochastic Cubic Newton methods, allowingarbitrary size batches, and the use of noisy and possibly biased estimates ofthe gradients and Hessians, incorporating both the variance reduction and thelazy Hessian updates. We recover the best-known complexities for the stochasticand variance-reduced Cubic Newton, under weak assumptions on the noise. Adirect consequence of our theory is the new lazy stochastic second-ordermethod, which significantly improves the arithmetic complexity for largedimension problems. We also establish complexity bounds for the classes ofgradient-dominated objectives, that include convex and strongly convexproblems. For Auxiliary Learning, we show that using a helper (auxiliaryfunction) can outperform training alone if a given similarity measure is small.</description><author>El Mahdi Chayti, Nikita Doikov, Martin Jaggi</author><pubDate>Wed, 06 Sep 2023 15:38:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.11962v2</guid></item><item><title>A Refutation of Shapley Values for Explainability</title><link>http://arxiv.org/abs/2309.03041v1</link><description>Recent work demonstrated the existence of Boolean functions for which Shapleyvalues provide misleading information about the relative importance of featuresin rule-based explanations. Such misleading information was broadly categorizedinto a number of possible issues. Each of those issues relates with featuresbeing relevant or irrelevant for a prediction, and all are significantregarding the inadequacy of Shapley values for rule-based explainability. Thisearlier work devised a brute-force approach to identify Boolean functions,defined on small numbers of features, and also associated instances, whichdisplayed such inadequacy-revealing issues, and so served as evidence to theinadequacy of Shapley values for rule-based explainability. However, anoutstanding question is how frequently such inadequacy-revealing issues canoccur for Boolean functions with arbitrary large numbers of features. It isplain that a brute-force approach would be unlikely to provide insights on howto tackle this question. This paper answers the above question by proving that,for any number of features, there exist Boolean functions that exhibit one ormore inadequacy-revealing issues, thereby contributing decisive argumentsagainst the use of Shapley values as the theoretical underpinning offeature-attribution methods in explainability.</description><author>Xuanxiang Huang, Joao Marques-Silva</author><pubDate>Wed, 06 Sep 2023 15:34:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03041v1</guid></item><item><title>Automated CVE Analysis for Threat Prioritization and Impact Prediction</title><link>http://arxiv.org/abs/2309.03040v1</link><description>The Common Vulnerabilities and Exposures (CVE) are pivotal information forproactive cybersecurity measures, including service patching, securityhardening, and more. However, CVEs typically offer low-level, product-orienteddescriptions of publicly disclosed cybersecurity vulnerabilities, often lackingthe essential attack semantic information required for comprehensive weaknesscharacterization and threat impact estimation. This critical insight isessential for CVE prioritization and the identification of potentialcountermeasures, particularly when dealing with a large number of CVEs. Currentindustry practices involve manual evaluation of CVEs to assess their attackseverities using the Common Vulnerability Scoring System (CVSS) and mappingthem to Common Weakness Enumeration (CWE) for potential mitigationidentification. Unfortunately, this manual analysis presents a major bottleneckin the vulnerability analysis process, leading to slowdowns in proactivecybersecurity efforts and the potential for inaccuracies due to human errors.In this research, we introduce our novel predictive model and tool (calledCVEDrill) which revolutionizes CVE analysis and threat prioritization. CVEDrillaccurately estimates the CVSS vector for precise threat mitigation and priorityranking and seamlessly automates the classification of CVEs into theappropriate CWE hierarchy classes. By harnessing CVEDrill, organizations cannow implement cybersecurity countermeasure mitigation with unparalleledaccuracy and timeliness, surpassing in this domain the capabilities ofstate-of-the-art tools like ChaptGPT.</description><author>Ehsan Aghaei, Ehab Al-Shaer, Waseem Shadid, Xi Niu</author><pubDate>Wed, 06 Sep 2023 15:34:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03040v1</guid></item><item><title>Single-Sentence Reader: A Novel Approach for Addressing Answer Position Bias</title><link>http://arxiv.org/abs/2308.04566v4</link><description>Machine Reading Comprehension (MRC) models tend to take advantage of spuriouscorrelations (also known as dataset bias or annotation artifacts in theresearch community). Consequently, these models may perform the MRC taskwithout fully comprehending the given context and question, which isundesirable since it may result in low robustness against distribution shift.The main focus of this paper is answer-position bias, where a significantpercentage of training questions have answers located solely in the firstsentence of the context. We propose a Single-Sentence Reader as a new approachfor addressing answer position bias in MRC. Remarkably, in our experiments withsix different models, our proposed Single-Sentence Readers trained on biaseddataset achieve results that nearly match those of models trained on normaldataset, proving their effectiveness in addressing the answer position bias.Our study also discusses several challenges our Single-Sentence Readersencounter and proposes a potential solution.</description><author>Son Quoc Tran, Matt Kretchmar</author><pubDate>Wed, 06 Sep 2023 15:29:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.04566v4</guid></item><item><title>An Efficient Temporary Deepfake Location Approach Based Embeddings for Partially Spoofed Audio Detection</title><link>http://arxiv.org/abs/2309.03036v1</link><description>Partially spoofed audio detection is a challenging task, lying in the need toaccurately locate the authenticity of audio at the frame level. To address thisissue, we propose a fine-grained partially spoofed audio detection method,namely Temporal Deepfake Location (TDL), which can effectively captureinformation of both features and locations. Specifically, our approach involvestwo novel parts: embedding similarity module and temporal convolutionoperation. To enhance the identification between the real and fake features,the embedding similarity module is designed to generate an embedding space thatcan separate the real frames from fake frames. To effectively concentrate onthe position information, temporal convolution operation is proposed tocalculate the frame-specific similarities among neighboring frames, anddynamically select informative neighbors to convolution. Extensive experimentsshow that our method outperform baseline models in ASVspoof2019 Partial Spoofdataset and demonstrate superior performance even in the crossdataset scenario.The code is released online.</description><author>Yuankun Xie, Haonan Cheng, Yutian Wang, Long Ye</author><pubDate>Wed, 06 Sep 2023 15:29:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03036v1</guid></item><item><title>Learning Speech Representation From Contrastive Token-Acoustic Pretraining</title><link>http://arxiv.org/abs/2309.00424v2</link><description>For fine-grained generation and recognition tasks such asminimally-supervised text-to-speech (TTS), voice conversion (VC), and automaticspeech recognition (ASR), the intermediate representations extracted fromspeech should serve as a "bridge" between text and acoustic information,containing information from both modalities. The semantic content isemphasized, while the paralinguistic information such as speaker identity andacoustic details should be de-emphasized. However, existing methods forextracting fine-grained intermediate representations from speech suffer fromissues of excessive redundancy and dimension explosion. Contrastive learning isa good method for modeling intermediate representations from two modalities.However, existing contrastive learning methods in the audio field focus onextracting global descriptive information for downstream audio classificationtasks, making them unsuitable for TTS, VC, and ASR tasks. To address theseissues, we propose a method named "Contrastive Token-Acoustic Pretraining(CTAP)", which uses two encoders to bring phoneme and speech into a jointmultimodal space, learning how to connect phoneme and speech at the framelevel. The CTAP model is trained on 210k speech and phoneme text pairs,achieving minimally-supervised TTS, VC, and ASR. The proposed CTAP methodoffers a promising solution for fine-grained generation and recognitiondownstream tasks in speech processing.</description><author>Chunyu Qiang, Hao Li, Yixin Tian, Ruibo Fu, Tao Wang, Longbiao Wang, Jianwu Dang</author><pubDate>Wed, 06 Sep 2023 15:27:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00424v2</guid></item><item><title>DynED: Dynamic Ensemble Diversification in Data Stream Classification</title><link>http://arxiv.org/abs/2308.10807v2</link><description>Ensemble methods are commonly used in classification due to their remarkableperformance. Achieving high accuracy in a data stream environment is achallenging task considering disruptive changes in the data distribution, alsoknown as concept drift. A greater diversity of ensemble components is known toenhance prediction accuracy in such settings. Despite the diversity ofcomponents within an ensemble, not all contribute as expected to its overallperformance. This necessitates a method for selecting components that exhibithigh performance and diversity. We present a novel ensemble construction andmaintenance approach based on MMR (Maximal Marginal Relevance) that dynamicallycombines the diversity and prediction accuracy of components during the processof structuring an ensemble. The experimental results on both four real and 11synthetic datasets demonstrate that the proposed approach (DynED) provides ahigher average mean accuracy compared to the five state-of-the-art baselines.</description><author>Soheil Abadifard, Sepehr Bakhshi, Sanaz Gheibuni, Fazli Can</author><pubDate>Wed, 06 Sep 2023 15:27:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10807v2</guid></item><item><title>Deep Learning for Polycystic Kidney Disease: Utilizing Neural Networks for Accurate and Early Detection through Gene Expression Analysis</title><link>http://arxiv.org/abs/2309.03033v1</link><description>With Polycystic Kidney Disease (PKD) potentially leading to fatalcomplications in patients due to the formation of cysts in the kidneys, earlydetection of PKD is crucial for effective management of the condition. However,the various patient-specific factors that play a role in the diagnosis make itan intricate puzzle for clinicians to solve. Therefore, in this study, we aimto utilize a deep learning-based approach for early disease detection. Thedevised neural network can achieve accurate and robust predictions for possiblePKD in patients by analyzing patient gene expressions.</description><author>Kapil Panda, Anirudh Mazumder</author><pubDate>Wed, 06 Sep 2023 15:22:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03033v1</guid></item><item><title>Infinite Class Mixup</title><link>http://arxiv.org/abs/2305.10293v2</link><description>Mixup is a widely adopted strategy for training deep networks, whereadditional samples are augmented by interpolating inputs and labels of trainingpairs. Mixup has shown to improve classification performance, networkcalibration, and out-of-distribution generalisation. While effective, acornerstone of Mixup, namely that networks learn linear behaviour patternsbetween classes, is only indirectly enforced since the output interpolation isperformed at the probability level. This paper seeks to address this limitationby mixing the classifiers directly instead of mixing the labels for each mixedpair. We propose to define the target of each augmented sample as a uniquelynew classifier, whose parameters are a linear interpolation of the classifiervectors of the input pair. The space of all possible classifiers is continuousand spans all interpolations between classifier pairs. To make optimisationtractable, we propose a dual-contrastive Infinite Class Mixup loss, where wecontrast the classifier of a mixed pair to both the classifiers and thepredicted outputs of other mixed pairs in a batch. Infinite Class Mixup isgeneric in nature and applies to many variants of Mixup. Empirically, we showthat it outperforms standard Mixup and variants such as RegMixup and Remix onbalanced, long-tailed, and data-constrained benchmarks, highlighting its broadapplicability.</description><author>Thomas Mensink, Pascal Mettes</author><pubDate>Wed, 06 Sep 2023 15:21:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10293v2</guid></item><item><title>Learning Variational Models with Unrolling and Bilevel Optimization</title><link>http://arxiv.org/abs/2209.12651v5</link><description>In this paper we consider the problem of learning variational models in thecontext of supervised learning via risk minimization. Our goal is to provide adeeper understanding of the two approaches of learning of variational modelsvia bilevel optimization and via algorithm unrolling. The former considers thevariational model as a lower level optimization problem below the riskminimization problem, while the latter replaces the lower level optimizationproblem by an algorithm that solves said problem approximately. Both approachesare used in practice, but unrolling is much simpler from a computational pointof view. To analyze and compare the two approaches, we consider a simple toymodel, and compute all risks and the respective estimators explicitly. We showthat unrolling can be better than the bilevel optimization approach, but alsothat the performance of unrolling can depend significantly on furtherparameters, sometimes in unexpected ways: While the stepsize of the unrolledalgorithm matters a lot (and learning the stepsize gives a significantimprovement), the number of unrolled iterations plays a minor role.</description><author>Christoph Brauer, Niklas Breustedt, Timo de Wolff, Dirk A. Lorenz</author><pubDate>Wed, 06 Sep 2023 15:21:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.12651v5</guid></item><item><title>SourceP: Detecting Ponzi Schemes on Ethereum with Source Code</title><link>http://arxiv.org/abs/2306.01665v2</link><description>As blockchain technology becomes more and more popular, a typical financialscam, the Ponzi scheme, has also emerged in the blockchain platform Ethereum.This Ponzi scheme deployed through smart contracts, also known as the smartPonzi scheme, has caused a lot of economic losses and negative impacts.Existing methods for detecting smart Ponzi schemes on Ethereum mainly rely onbytecode features, opcode features, account features, and transaction behaviorfeatures of smart contracts, and the performance of identifying schemes isinsufficient. In this paper, we propose SourceP, a method to detect smart Ponzischemes on the Ethereum platform using pre-trained models and data flow, whichonly requires using the source code of smart contracts as features to explorethe possibility of detecting smart Ponzi schemes from another direction.SourceP reduces the difficulty of data acquisition and feature extraction ofexisting detection methods while increasing the interpretability of the model.Specifically, we first convert the source code of a smart contract into a dataflow graph and then introduce a pre-trained model based on learning coderepresentations to build a classification model to identify Ponzi schemes insmart contracts. The experimental results show that SourceP achieves 87.2\%recall and 90.7\% F-score for detecting smart Ponzi schemes within Ethereum'ssmart contract dataset, outperforming state-of-the-art methods in terms ofperformance and sustainability. We also demonstrate through additionalexperiments that pre-trained models and data flow play an importantcontribution to SourceP, as well as proving that SourceP has a goodgeneralization ability.</description><author>Pengcheng Lu, Liang Cai, Keting Yin</author><pubDate>Wed, 06 Sep 2023 15:21:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01665v2</guid></item><item><title>MCM: Multi-condition Motion Synthesis Framework for Multi-scenario</title><link>http://arxiv.org/abs/2309.03031v1</link><description>The objective of the multi-condition human motion synthesis task is toincorporate diverse conditional inputs, encompassing various forms like text,music, speech, and more. This endows the task with the capability to adaptacross multiple scenarios, ranging from text-to-motion and music-to-dance,among others. While existing research has primarily focused on singleconditions, the multi-condition human motion generation remains underexplored.In this paper, we address these challenges by introducing MCM, a novel paradigmfor motion synthesis that spans multiple scenarios under diverse conditions.The MCM framework is able to integrate with any DDPM-like diffusion model toaccommodate multi-conditional information input while preserving its generativecapabilities. Specifically, MCM employs two-branch architecture consisting of amain branch and a control branch. The control branch shares the same structureas the main branch and is initialized with the parameters of the main branch,effectively maintaining the generation ability of the main branch andsupporting multi-condition input. We also introduce a Transformer-baseddiffusion model MWNet (DDPM-like) as our main branch that can capture thespatial complexity and inter-joint correlations in motion sequences through achannel-dimension self-attention module. Quantitative comparisons demonstratethat our approach achieves SoTA results in both text-to-motion and competitiveresults in music-to-dance tasks, comparable to task-specific methods.Furthermore, the qualitative evaluation shows that MCM not only streamlines theadaptation of methodologies originally designed for text-to-motion tasks todomains like music-to-dance and speech-to-gesture, eliminating the need forextensive network re-configurations but also enables effective multi-conditionmodal control, realizing "once trained is motion need".</description><author>Zeyu Ling, Bo Han, Yongkang Wong, Mohan Kangkanhalli, Weidong Geng</author><pubDate>Wed, 06 Sep 2023 15:17:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03031v1</guid></item><item><title>Empowering LLM to use Smartphone for Intelligent Task Automation</title><link>http://arxiv.org/abs/2308.15272v2</link><description>Mobile task automation is an attractive technique that aims to enablevoice-based hands-free user interaction with smartphones. However, existingapproaches suffer from poor scalability due to the limited languageunderstanding ability and the non-trivial manual efforts required fromdevelopers or end-users. The recent advance of large language models (LLMs) inlanguage understanding and reasoning inspires us to rethink the problem from amodel-centric perspective, where task preparation, comprehension, and executionare handled by a unified language model. In this work, we introduce AutoDroid,a mobile task automation system that can handle arbitrary tasks on any Androidapplication without manual efforts. The key insight is to combine thecommonsense knowledge of LLMs and domain-specific knowledge of apps throughautomated dynamic analysis. The main components include a functionality-awareUI representation method that bridges the UI with the LLM, exploration-basedmemory injection techniques that augment the app-specific domain knowledge ofLLM, and a multi-granularity query optimization module that reduces the cost ofmodel inference. We integrate AutoDroid with off-the-shelf LLMs includingonline GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its performance on anew benchmark for memory-augmented Android task automation with 158 commontasks. The results demonstrated that AutoDroid is able to precisely generateactions with an accuracy of 90.9%, and complete tasks with a success rate of71.3%, outperforming the GPT-4-powered baselines by 36.4% and 39.7%. The demo,benchmark suites, and source code of AutoDroid will be released aturl{https://autodroid-sys.github.io/}.</description><author>Hao Wen, Yuanchun Li, Guohong Liu, Shanhui Zhao, Tao Yu, Toby Jia-Jun Li, Shiqi Jiang, Yunhao Liu, Yaqin Zhang, Yunxin Liu</author><pubDate>Wed, 06 Sep 2023 15:14:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.15272v2</guid></item><item><title>Forecasting Future Instance Segmentation with Learned Optical Flow and Warping</title><link>http://arxiv.org/abs/2211.08049v2</link><description>For an autonomous vehicle it is essential to observe the ongoing dynamics ofa scene and consequently predict imminent future scenarios to ensure safety toitself and others. This can be done using different sensors and modalities. Inthis paper we investigate the usage of optical flow for predicting futuresemantic segmentations. To do so we propose a model that forecasts flow fieldsautoregressively. Such predictions are then used to guide the inference of alearned warping function that moves instance segmentations on to future frames.Results on the Cityscapes dataset demonstrate the effectiveness of optical-flowmethods.</description><author>Andrea Ciamarra, Federico Becattini, Lorenzo Seidenari, Alberto Del Bimbo</author><pubDate>Wed, 06 Sep 2023 15:13:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.08049v2</guid></item><item><title>Universal Preprocessing Operators for Embedding Knowledge Graphs with Literals</title><link>http://arxiv.org/abs/2309.03023v1</link><description>Knowledge graph embeddings are dense numerical representations of entities ina knowledge graph (KG). While the majority of approaches concentrate only onrelational information, i.e., relations between entities, fewer approachesexist which also take information about literal values (e.g., textualdescriptions or numerical information) into account. Those which exist aretypically tailored towards a particular modality of literal and a particularembedding method. In this paper, we propose a set of universal preprocessingoperators which can be used to transform KGs with literals for numerical,temporal, textual, and image information, so that the transformed KGs can beembedded with any method. The results on the kgbench dataset with threedifferent embedding methods show promising results.</description><author>Patryk Preisner, Heiko Paulheim</author><pubDate>Wed, 06 Sep 2023 15:08:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03023v1</guid></item><item><title>SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution</title><link>http://arxiv.org/abs/2309.03020v1</link><description>Real-world Super-Resolution (real-SR) methods focus on dealing with diversereal-world images and have attracted increasing attention in recent years. Thekey idea is to use a complex and high-order degradation model to mimicreal-world degradations. Although they have achieved impressive results invarious scenarios, they are faced with the obstacle of evaluation. Currently,these methods are only assessed by their average performance on a small set ofdegradation cases randomly selected from a large space, which fails to providea comprehensive understanding of their overall performance and often yieldsbiased results. To overcome the limitation in evaluation, we propose SEAL, aframework for systematic evaluation of real-SR. In particular, we cluster theextensive degradation space to create a set of representative degradationcases, which serves as a comprehensive test set. Next, we propose acoarse-to-fine evaluation protocol to measure the distributed and relativeperformance of real-SR methods on the test set. The protocol incorporates twonew metrics: acceptance rate (AR) and relative performance ratio (RPR), derivedfrom an acceptance line and an excellence line. Under SEAL, we benchmarkexisting real-SR methods, obtain new observations and insights into theirperformance, and develop a new strong baseline. We consider SEAL as the firststep towards creating an unbiased and comprehensive evaluation platform, whichcan promote the development of real-SR.</description><author>Wenlong Zhang, Xiaohui Li, Xiangyu Chen, Yu Qiao, Xiao-Ming Wu, Chao Dong</author><pubDate>Wed, 06 Sep 2023 15:02:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03020v1</guid></item><item><title>Amortised Inference in Bayesian Neural Networks</title><link>http://arxiv.org/abs/2309.03018v1</link><description>Meta-learning is a framework in which machine learning models train over aset of datasets in order to produce predictions on new datasets at test time.Probabilistic meta-learning has received an abundance of attention from theresearch community in recent years, but a problem shared by many existingprobabilistic meta-models is that they require a very large number of datasetsin order to produce high-quality predictions with well-calibrated uncertaintyestimates. In many applications, however, such quantities of data are simplynot available. In this dissertation we present a significantly more data-efficient approachto probabilistic meta-learning through per-datapoint amortisation of inferencein Bayesian neural networks, introducing the Amortised Pseudo-ObservationVariational Inference Bayesian Neural Network (APOVI-BNN). First, we show thatthe approximate posteriors obtained under our amortised scheme are of similaror better quality to those obtained through traditional variational inference,despite the fact that the amortised inference is performed in a single forwardpass. We then discuss how the APOVI-BNN may be viewed as a new member of theneural process family, motivating the use of neural process training objectivesfor potentially better predictive performance on complex problems as a result.Finally, we assess the predictive performance of the APOVI-BNN against otherprobabilistic meta-models in both a one-dimensional regression problem and in asignificantly more complex image completion setting. In both cases, when theamount of training data is limited, our model is the best in its class.</description><author>Tommy Rochussen</author><pubDate>Wed, 06 Sep 2023 15:02:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03018v1</guid></item><item><title>SymED: Adaptive and Online Symbolic Representation of Data on the Edge</title><link>http://arxiv.org/abs/2309.03014v1</link><description>The edge computing paradigm helps handle the Internet of Things (IoT)generated data in proximity to its source. Challenges occur in transferring,storing, and processing this rapidly growing amount of data onresource-constrained edge devices. Symbolic Representation (SR) algorithms arepromising solutions to reduce the data size by converting actual raw data intosymbols. Also, they allow data analytics (e.g., anomaly detection and trendprediction) directly on symbols, benefiting large classes of edge applications.However, existing SR algorithms are centralized in design and work offline withbatch data, which is infeasible for real-time cases. We propose SymED -Symbolic Edge Data representation method, i.e., an online, adaptive, anddistributed approach for symbolic representation of data on edge. SymED isbased on the Adaptive Brownian Bridge-based Aggregation (ABBA), where we assumelow-powered IoT devices do initial data compression (senders) and the morerobust edge devices do the symbolic conversion (receivers). We evaluate SymEDby measuring compression performance, reconstruction accuracy through DynamicTime Warping (DTW) distance, and computational latency. The results show thatSymED is able to (i) reduce the raw data with an average compression rate of9.5%; (ii) keep a low reconstruction error of 13.25 in the DTW space; (iii)simultaneously provide real-time adaptability for online streaming IoT data attypical latencies of 42ms per symbol, reducing the overall network traffic.</description><author>Daniel Hofstätter, Shashikant Ilager, Ivan Lujic, Ivona Brandic</author><pubDate>Wed, 06 Sep 2023 14:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03014v1</guid></item><item><title>Sparse 3D Reconstruction via Object-Centric Ray Sampling</title><link>http://arxiv.org/abs/2309.03008v1</link><description>We propose a novel method for 3D object reconstruction from a sparse set ofviews captured from a 360-degree calibrated camera rig. We represent the objectsurface through a hybrid model that uses both an MLP-based neuralrepresentation and a triangle mesh. A key contribution in our work is a novelobject-centric sampling scheme of the neural representation, where rays areshared among all views. This efficiently concentrates and reduces the number ofsamples used to update the neural model at each iteration. This sampling schemerelies on the mesh representation to ensure also that samples arewell-distributed along its normals. The rendering is then performed efficientlyby a differentiable renderer. We demonstrate that this sampling scheme resultsin a more effective training of the neural representation, does not require theadditional supervision of segmentation masks, yields state of the art 3Dreconstructions, and works with sparse views on the Google's Scanned Objects,Tank and Temples and MVMC Car datasets.</description><author>Llukman Cerkezi, Paolo Favaro</author><pubDate>Wed, 06 Sep 2023 14:54:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03008v1</guid></item><item><title>Theoretical Explanation of Activation Sparsity through Flat Minima and Adversarial Robustness</title><link>http://arxiv.org/abs/2309.03004v1</link><description>A recent empirical observation of activation sparsity in MLP layers offers anopportunity to drastically reduce computation costs for free. Despite severalworks attributing it to training dynamics, the theoretical explanation ofactivation sparsity's emergence is restricted to shallow networks, smalltraining steps well as modified training, even though the sparsity has beenfound in deep models trained by vanilla protocols for large steps. To fill thethree gaps, we propose the notion of gradient sparsity as the source ofactivation sparsity and a theoretical explanation based on it that explainsgradient sparsity and then activation sparsity as necessary steps toadversarial robustness w.r.t. hidden features and parameters, which isapproximately the flatness of minima for well-learned models. The theoryapplies to standardly trained LayerNorm-ed pure MLPs, and further toTransformers or other architectures if noises are added to weights duringtraining. To eliminate other sources of flatness when arguing sparsities'necessity, we discover the phenomenon of spectral concentration, i.e., theratio between the largest and the smallest non-zero singular values of weightmatrices is small. We utilize random matrix theory (RMT) as a powerfultheoretical tool to analyze stochastic gradient noises and discuss theemergence of spectral concentration. With these insights, we propose twoplug-and-play modules for both training from scratch and sparsity finetuning,as well as one radical modification that only applies to from-scratch training.Another under-testing module for both sparsity and flatness is also immediatefrom our theories. Validational experiments are conducted to verify ourexplanation. Experiments for productivity demonstrate modifications'improvement in sparsity, indicating further theoretical cost reduction in bothtraining and inference.</description><author>Ze Peng, Lei Qi, Yinghuan Shi, Yang Gao</author><pubDate>Wed, 06 Sep 2023 14:48:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03004v1</guid></item><item><title>Unified Bayesian Frameworks for Multi-criteria Decision-making Problems</title><link>http://arxiv.org/abs/2208.13390v4</link><description>This paper introduces Bayesian frameworks for tackling various aspects ofmulti-criteria decision-making (MCDM) problems, leveraging a probabilisticinterpretation of MCDM methods and challenges. By harnessing the flexibility ofBayesian models, the proposed frameworks offer statistically elegant solutionsto key challenges in MCDM, such as group decision-making problems and criteriacorrelation. Additionally, these models can accommodate diverse forms ofuncertainty in decision makers' (DMs) preferences, including normal andtriangular distributions, as well as interval preferences. To addresslarge-scale group MCDM scenarios, a probabilistic mixture model is developed,enabling the identification of homogeneous subgroups of DMs. Furthermore, aprobabilistic ranking scheme is devised to assess the relative importance ofcriteria and alternatives based on DM(s) preferences. Through experimentationon various numerical examples, the proposed frameworks are validated,demonstrating their effectiveness and highlighting their distinguishingfeatures in comparison to alternative methods.</description><author>Majid Mohammadi</author><pubDate>Wed, 06 Sep 2023 14:44:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.13390v4</guid></item><item><title>Vote2Cap-DETR++: Decoupling Localization and Describing for End-to-End 3D Dense Captioning</title><link>http://arxiv.org/abs/2309.02999v1</link><description>3D dense captioning requires a model to translate its understanding of aninput 3D scene into several captions associated with different object regions.Existing methods adopt a sophisticated "detect-then-describe" pipeline, whichbuilds explicit relation modules upon a 3D detector with numerous hand-craftedcomponents. While these methods have achieved initial success, the cascadepipeline tends to accumulate errors because of duplicated and inaccurate boxestimations and messy 3D scenes. In this paper, we first propose Vote2Cap-DETR,a simple-yet-effective transformer framework that decouples the decodingprocess of caption generation and object localization through paralleldecoding. Moreover, we argue that object localization and descriptiongeneration require different levels of scene understanding, which could bechallenging for a shared set of queries to capture. To this end, we propose anadvanced version, Vote2Cap-DETR++, which decouples the queries intolocalization and caption queries to capture task-specific features.Additionally, we introduce the iterative spatial refinement strategy to votequeries for faster convergence and better localization performance. We alsoinsert additional spatial information to the caption head for more accuratedescriptions. Without bells and whistles, extensive experiments on two commonlyused datasets, ScanRefer and Nr3D, demonstrate Vote2Cap-DETR andVote2Cap-DETR++ surpass conventional "detect-then-describe" methods by a largemargin. Codes will be made available athttps://github.com/ch3cook-fdu/Vote2Cap-DETR.</description><author>Sijin Chen, Hongyuan Zhu, Mingsheng Li, Xin Chen, Peng Guo, Yinjie Lei, Gang Yu, Taihao Li, Tao Chen</author><pubDate>Wed, 06 Sep 2023 14:43:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02999v1</guid></item><item><title>Deep Metric Learning with Chance Constraints</title><link>http://arxiv.org/abs/2209.09060v3</link><description>Deep metric learning (DML) aims to minimize empirical expected loss of thepairwise intra-/inter- class proximity violations in the embedding space. Werelate DML to feasibility problem of finite chance constraints. We show thatminimizer of proxy-based DML satisfies certain chance constraints, and that theworst case generalization performance of the proxy-based methods can becharacterized by the radius of the smallest ball around a class proxy to coverthe entire domain of the corresponding class samples, suggesting multipleproxies per class helps performance. To provide a scalable algorithm as well asexploiting more proxies, we consider the chance constraints implied by theminimizers of proxy-based DML instances and reformulate DML as finding afeasible point in intersection of such constraints, resulting in a problem tobe approximately solved by iterative projections. Simply put, we repeatedlytrain a regularized proxy-based loss and re-initialize the proxies with theembeddings of the deliberately selected new samples. We applied our method with4 well-accepted DML losses and show the effectiveness with extensiveevaluations on 4 popular DML benchmarks. Code is available at:https://github.com/yetigurbuz/ccp-dml</description><author>Yeti Z. Gurbuz, Ogul Can, A. Aydin Alatan</author><pubDate>Wed, 06 Sep 2023 14:42:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.09060v3</guid></item><item><title>Enhancing Adversarial Attacks: The Similar Target Method</title><link>http://arxiv.org/abs/2308.10743v2</link><description>Deep neural networks are vulnerable to adversarial examples, posing a threatto the models' applications and raising security concerns. An intriguingproperty of adversarial examples is their strong transferability. Severalmethods have been proposed to enhance transferability, including ensembleattacks which have demonstrated their efficacy. However, prior approachessimply average logits, probabilities, or losses for model ensembling, lacking acomprehensive analysis of how and why model ensembling significantly improvestransferability. In this paper, we propose a similar targeted attack methodnamed Similar Target~(ST). By promoting cosine similarity between the gradientsof each model, our method regularizes the optimization direction tosimultaneously attack all surrogate models. This strategy has been proven toenhance generalization ability. Experimental results on ImageNet validate theeffectiveness of our approach in improving adversarial transferability. Ourmethod outperforms state-of-the-art attackers on 18 discriminative classifiersand adversarially trained models.</description><author>Shuo Zhang, Ziruo Wang, Zikai Zhou, Huanran Chen</author><pubDate>Wed, 06 Sep 2023 14:39:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10743v2</guid></item><item><title>Continual Evidential Deep Learning for Out-of-Distribution Detection</title><link>http://arxiv.org/abs/2309.02995v1</link><description>Uncertainty-based deep learning models have attracted a great deal ofinterest for their ability to provide accurate and reliable predictions.Evidential deep learning stands out achieving remarkable performance indetecting out-of-distribution (OOD) data with a single deterministic neuralnetwork. Motivated by this fact, in this paper we propose the integration of anevidential deep learning method into a continual learning framework in order toperform simultaneously incremental object classification and OOD detection.Moreover, we analyze the ability of vacuity and dissonance to differentiatebetween in-distribution data belonging to old classes and OOD data. Theproposed method, called CEDL, is evaluated on CIFAR-100 considering twosettings consisting of 5 and 10 tasks, respectively. From the obtained results,we could appreciate that the proposed method, in addition to provide comparableresults in object classification with respect to the baseline, largelyoutperforms OOD detection compared to several posthoc methods on threeevaluation metrics: AUROC, AUPR and FPR95.</description><author>Eduardo Aguilar, Bogdan Raducanu, Petia Radeva, Joost Van de Weijer</author><pubDate>Wed, 06 Sep 2023 14:36:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02995v1</guid></item><item><title>Neural-prior stochastic block model</title><link>http://arxiv.org/abs/2303.09995v2</link><description>The stochastic block model (SBM) is widely studied as a benchmark for graphclustering aka community detection. In practice, graph data often come withnode attributes that bear additional information about the communities.Previous works modeled such data by considering that the node attributes aregenerated from the node community memberships. In this work, motivated by arecent surge of works in signal processing using deep neural networks aspriors, we propose to model the communities as being determined by the nodeattributes rather than the opposite. We define the corresponding model; we callit the neural-prior SBM. We propose an algorithm, stemming from statisticalphysics, based on a combination of belief propagation and approximate messagepassing. We analyze the performance of the algorithm as well as theBayes-optimal performance. We identify detectability and exact recovery phasetransitions, as well as an algorithmically hard region. The proposed model andalgorithm can be used as a benchmark for both theory and algorithms. Toillustrate this, we compare the optimal performances to the performance ofsimple graph neural networks.</description><author>O. Duranthon, L. Zdeborová</author><pubDate>Wed, 06 Sep 2023 14:36:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09995v2</guid></item><item><title>An Offline Learning Approach to Propagator Models</title><link>http://arxiv.org/abs/2309.02994v1</link><description>We consider an offline learning problem for an agent who first estimates anunknown price impact kernel from a static dataset, and then designs strategiesto liquidate a risky asset while creating transient price impact. We propose anovel approach for a nonparametric estimation of the propagator from a datasetcontaining correlated price trajectories, trading signals and metaorders. Wequantify the accuracy of the estimated propagator using a metric which dependsexplicitly on the dataset. We show that a trader who tries to minimise herexecution costs by using a greedy strategy purely based on the estimatedpropagator will encounter suboptimality due to so-called spurious correlationbetween the trading strategy and the estimator and due to intrinsic uncertaintyresulting from a biased cost functional. By adopting an offline reinforcementlearning approach, we introduce a pessimistic loss functional taking theuncertainty of the estimated propagator into account, with an optimiser whicheliminates the spurious correlation, and derive an asymptotically optimal boundon the execution costs even without precise information on the true propagator.Numerical experiments are included to demonstrate the effectiveness of theproposed propagator estimator and the pessimistic trading strategy.</description><author>Eyal Neuman, Wolfgang Stockinger, Yufei Zhang</author><pubDate>Wed, 06 Sep 2023 14:36:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02994v1</guid></item><item><title>Improving Scientific Machine Learning via Attention and Multiple Shooting</title><link>http://arxiv.org/abs/2307.05735v2</link><description>Scientific Machine Learning (SciML) is a burgeoning field thatsynergistically combines domain-aware and interpretable models with agnosticmachine learning techniques. In this work, we introduce GOKU-UI, an evolutionof the SciML generative model GOKU-nets. GOKU-UI not only broadens the originalmodel's spectrum to incorporate other classes of differential equations, suchas Stochastic Differential Equations (SDEs), but also integrates attentionmechanisms and a novel multiple shooting training strategy in the latent space.These enhancements have led to a significant increase in its performance inboth reconstruction and forecast tasks, as demonstrated by our evaluation ofsimulated and empirical data. Specifically, GOKU-UI outperformed all baselinemodels on synthetic datasets even with a training set 16-fold smaller,underscoring its remarkable data efficiency. Furthermore, when applied toempirical human brain data, while incorporating stochastic Stuart-Landauoscillators into its dynamical core, it not only surpassed all baseline methodsin the reconstruction task, but also demonstrated better prediction of futurebrain activity up to 15 seconds ahead. By training GOKU-UI on resting statefMRI data, we encoded whole-brain dynamics into a latent representation,learning an effective low-dimensional dynamical system model that could offerinsights into brain functionality and open avenues for practical applicationssuch as the classification of mental states or psychiatric conditions.Ultimately, our research provides further impetus for the field of ScientificMachine Learning, showcasing the potential for advancements when establishedscientific insights are interwoven with modern machine learning.</description><author>Germán Abrevaya, Mahta Ramezanian-Panahi, Jean-Christophe Gagnon-Audet, Irina Rish, Pablo Polosecki, Silvina Ponce Dawson, Guillermo Cecchi, Guillaume Dumas</author><pubDate>Wed, 06 Sep 2023 14:23:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.05735v2</guid></item><item><title>Natural and Robust Walking using Reinforcement Learning without Demonstrations in High-Dimensional Musculoskeletal Models</title><link>http://arxiv.org/abs/2309.02976v1</link><description>Humans excel at robust bipedal walking in complex natural environments. Ineach step, they adequately tune the interaction of biomechanical muscledynamics and neuronal signals to be robust against uncertainties in groundconditions. However, it is still not fully understood how the nervous systemresolves the musculoskeletal redundancy to solve the multi-objective controlproblem considering stability, robustness, and energy efficiency. In computersimulations, energy minimization has been shown to be a successful optimizationtarget, reproducing natural walking with trajectory optimization orreflex-based control methods. However, these methods focus on particularmotions at a time and the resulting controllers are limited when compensatingfor perturbations. In robotics, reinforcement learning~(RL) methods recentlyachieved highly stable (and efficient) locomotion on quadruped systems, but thegeneration of human-like walking with bipedal biomechanical models has requiredextensive use of expert data sets. This strong reliance on demonstrations oftenresults in brittle policies and limits the application to new behaviors,especially considering the potential variety of movements for high-dimensionalmusculoskeletal models in 3D. Achieving natural locomotion with RL withoutsacrificing its incredible robustness might pave the way for a novel approachto studying human walking in complex natural environments.</description><author>Pierre Schumacher, Thomas Geijtenbeek, Vittorio Caggiano, Vikash Kumar, Syn Schmitt, Georg Martius, Daniel F. B. Haeufle</author><pubDate>Wed, 06 Sep 2023 14:20:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02976v1</guid></item><item><title>FishMOT: A Simple and Effective Method for Fish Tracking Based on IoU Matching</title><link>http://arxiv.org/abs/2309.02975v1</link><description>The tracking of various fish species plays a profoundly significant role inunderstanding the behavior of individual fish and their groups. Presenttracking methods suffer from issues of low accuracy or poor robustness. Inorder to address these concerns, this paper proposes a novel tracking approach,named FishMOT (Fish Multiple Object Tracking). This method combines objectdetection techniques with the IoU matching algorithm, thereby achievingefficient, precise, and robust fish detection and tracking. Diverging fromother approaches, this method eliminates the need for multiple featureextractions and identity assignments for each individual, instead directlyutilizing the output results of the detector for tracking, therebysignificantly reducing computational time and storage space. Furthermore, thismethod imposes minimal requirements on factors such as video quality andvariations in individual appearance. As long as the detector can accuratelylocate and identify fish, effective tracking can be achieved. This approachenhances robustness and generalizability. Moreover, the algorithm employed inthis method addresses the issue of missed detections without relying on complexfeature matching or graph optimization algorithms. This contributes to improvedaccuracy and reliability. Experimental trials were conducted in the open-sourcevideo dataset provided by idtracker.ai, and comparisons were made withstate-of-the-art detector-based multi-object tracking methods. Additionally,comparisons were made with idtracker.ai and TRex, two tools that demonstrateexceptional performance in the field of animal tracking. The experimentalresults demonstrate that the proposed method outperforms other approaches invarious evaluation metrics, exhibiting faster speed and lower memoryrequirements. The source codes and pre-trained models are available at:https://github.com/gakkistar/FishMOT</description><author>Shuo Liu, Lulu Han, Xiaoyang Liu, Junli Ren, Fang Wang, Yuanshan Lin</author><pubDate>Wed, 06 Sep 2023 14:16:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02975v1</guid></item><item><title>On the Impact of Feeding Cost Risk in Aquaculture Valuation and Decision Making</title><link>http://arxiv.org/abs/2309.02970v1</link><description>We study the effect of stochastic feeding costs on animal-based commoditieswith particular focus on aquaculture. More specifically, we use soybean futuresto infer on the stochastic behaviour of salmon feed, which we assume to followa Schwartz-2-factor model. We compare the decision of harvesting salmon using adecision rule assuming either deterministic or stochastic feeding costs, i.e.including feeding cost risk. We identify cases, where accounting for stochasticfeeding costs leads to significant improvements as well as cases wheredeterministic feeding costs are a good enough proxy. Nevertheless, in all ofthese cases, the newly derived rules show superior performance, while theadditional computational costs are negligible. From a methodological point ofview, we demonstrate how to use Deep-Neural-Networks to infer on the decisionboundary that determines harvesting or continuation, improving on moreclassical regression-based and curve-fitting methods. To achieve this we use adeep classifier, which not only improves on previous results but also scaleswell for higher dimensional problems, and in addition mitigates effects due tomodel uncertainty, which we identify in this article. effects due to modeluncertainty, which we identify in this article.</description><author>Christian Oliver Ewald, Kevin Kamm</author><pubDate>Wed, 06 Sep 2023 14:09:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02970v1</guid></item><item><title>Attention-Driven Multi-Modal Fusion: Enhancing Sign Language Recognition and Translation</title><link>http://arxiv.org/abs/2309.01860v2</link><description>In this paper, we devise a mechanism for the addition of multi-modalinformation with an existing pipeline for continuous sign language recognitionand translation. In our procedure, we have incorporated optical flowinformation with RGB images to enrich the features with movement-relatedinformation. This work studies the feasibility of such modality inclusion usinga cross-modal encoder. The plugin we have used is very lightweight and doesn'tneed to include a separate feature extractor for the new modality in anend-to-end manner. We have applied the changes in both sign languagerecognition and translation, improving the result in each case. We haveevaluated the performance on the RWTH-PHOENIX-2014 dataset for sign languagerecognition and the RWTH-PHOENIX-2014T dataset for translation. On therecognition task, our approach reduced the WER by 0.9, and on the translationtask, our approach increased most of the BLEU scores by ~0.6 on the test set.</description><author>Zaber Ibn Abdul Hakim, Rasman Mubtasim Swargo, Muhammad Abdullah Adnan</author><pubDate>Wed, 06 Sep 2023 14:06:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01860v2</guid></item><item><title>CR-VAE: Contrastive Regularization on Variational Autoencoders for Preventing Posterior Collapse</title><link>http://arxiv.org/abs/2309.02968v1</link><description>The Variational Autoencoder (VAE) is known to suffer from the phenomenon of\textit{posterior collapse}, where the latent representations generated by themodel become independent of the inputs. This leads to degeneratedrepresentations of the input, which is attributed to the limitations of theVAE's objective function. In this work, we propose a novel solution to thisissue, the Contrastive Regularization for Variational Autoencoders (CR-VAE).The core of our approach is to augment the original VAE with a contrastiveobjective that maximizes the mutual information between the representations ofsimilar visual inputs. This strategy ensures that the information flow betweenthe input and its latent representation is maximized, effectively avoidingposterior collapse. We evaluate our method on a series of visual datasets anddemonstrate, that CR-VAE outperforms state-of-the-art approaches in preventingposterior collapse.</description><author>Fotios Lygerakis. Elmar Rueckert</author><pubDate>Wed, 06 Sep 2023 14:05:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02968v1</guid></item><item><title>Dynamic Hyperbolic Attention Network for Fine Hand-object Reconstruction</title><link>http://arxiv.org/abs/2309.02965v1</link><description>Reconstructing both objects and hands in 3D from a single RGB image iscomplex. Existing methods rely on manually defined hand-object constraints inEuclidean space, leading to suboptimal feature learning. Compared withEuclidean space, hyperbolic space better preserves the geometric properties ofmeshes thanks to its exponentially-growing space distance, which amplifies thedifferences between the features based on similarity. In this work, we proposethe first precise hand-object reconstruction method in hyperbolic space, namelyDynamic Hyperbolic Attention Network (DHANet), which leverages intrinsicproperties of hyperbolic space to learn representative features. Our methodthat projects mesh and image features into a unified hyperbolic space includestwo modules, ie. dynamic hyperbolic graph convolution and image-attentionhyperbolic graph convolution. With these two modules, our method learns meshfeatures with rich geometry-image multi-modal information and models betterhand-object interaction. Our method provides a promising alternative for finehand-object reconstruction in hyperbolic space. Extensive experiments on threepublic datasets demonstrate that our method outperforms most state-of-the-artmethods.</description><author>Zhiying Leng, Shun-Cheng Wu, Mahdi Saleh, Antonio Montanaro, Hao Yu, Yin Wang, Nassir Navab, Xiaohui Liang, Federico Tombari</author><pubDate>Wed, 06 Sep 2023 14:00:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02965v1</guid></item><item><title>Hierarchical-level rain image generative model based on GAN</title><link>http://arxiv.org/abs/2309.02964v1</link><description>Autonomous vehicles are exposed to various weather during operation, which islikely to trigger the performance limitations of the perception system, leadingto the safety of the intended functionality (SOTIF) problems. To efficientlygenerate data for testing the performance of visual perception algorithms undervarious weather conditions, a hierarchical-level rain image generative model,rain conditional CycleGAN (RCCycleGAN), is constructed. RCCycleGAN is based onthe generative adversarial network (GAN) and can generate images of light,medium, and heavy rain. Different rain intensities are introduced as labels inconditional GAN (CGAN). Meanwhile, the model structure is optimized and thetraining strategy is adjusted to alleviate the problem of mode collapse. Inaddition, natural rain images of different intensities are collected andprocessed for model training and validation. Compared with the two baselinemodels, CycleGAN and DerainCycleGAN, the peak signal-to-noise ratio (PSNR) ofRCCycleGAN on the test dataset is improved by 2.58 dB and 0.74 dB, and thestructural similarity (SSIM) is improved by 18% and 8%, respectively. Theablation experiments are also carried out to validate the effectiveness of themodel tuning.</description><author>Zhenyuan Liu, Tong Jia, Xingyu Xing, Jianfeng Wu, Junyi Chen</author><pubDate>Wed, 06 Sep 2023 13:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02964v1</guid></item><item><title>Towards provably efficient quantum algorithms for large-scale machine-learning models</title><link>http://arxiv.org/abs/2303.03428v3</link><description>Large machine learning models are revolutionary technologies of artificialintelligence whose bottlenecks include huge computational expenses, power, andtime used both in the pre-training and fine-tuning process. In this work, weshow that fault-tolerant quantum computing could possibly provide provablyefficient resolutions for generic (stochastic) gradient descent algorithms,scaling as $\mathcal{O}(T^2 \times \text{polylog}(n))$, where $n$ is the sizeof the models and $T$ is the number of iterations in the training, as long asthe models are both sufficiently dissipative and sparse, with small learningrates. Based on earlier efficient quantum algorithms for dissipativedifferential equations, we find and prove that similar algorithms work for(stochastic) gradient descent, the primary algorithm for machine learning. Inpractice, we benchmark instances of large machine learning models from 7million to 103 million parameters. We find that, in the context of sparsetraining, a quantum enhancement is possible at the early stage of learningafter model pruning, motivating a sparse parameter download and re-uploadscheme. Our work shows solidly that fault-tolerant quantum algorithms couldpotentially contribute to most state-of-the-art, large-scale machine-learningproblems.</description><author>Junyu Liu, Minzhao Liu, Jin-Peng Liu, Ziyu Ye, Yuri Alexeev, Jens Eisert, Liang Jiang</author><pubDate>Wed, 06 Sep 2023 13:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03428v3</guid></item><item><title>Indoor Localization Using Radio, Vision and Audio Sensors: Real-Life Data Validation and Discussion</title><link>http://arxiv.org/abs/2309.02961v1</link><description>This paper investigates indoor localization methods using radio, vision, andaudio sensors, respectively, in the same environment. The evaluation is basedon state-of-the-art algorithms and uses a real-life dataset. More specifically,we evaluate a machine learning algorithm for radio-based localization withmassive MIMO technology, an ORB-SLAM3 algorithm for vision-based localizationwith an RGB-D camera, and an SFS2 algorithm for audio-based localization withmicrophone arrays. Aspects including localization accuracy, reliability,calibration requirements, and potential system complexity are discussed toanalyze the advantages and limitations of using different sensors for indoorlocalization tasks. The results can serve as a guideline and basis for furtherdevelopment of robust and high-precision multi-sensory localization systems,e.g., through sensor fusion and context and environment-aware adaptation.</description><author>Ilayda Yaman, Guoda Tian, Erik Tegler, Patrik Persson, Nikhil Challa, Fredrik Tufvesson, Ove Edfors, Kalle Astrom, Steffen Malkowsky, Liang Liu</author><pubDate>Wed, 06 Sep 2023 13:57:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02961v1</guid></item><item><title>A Non-Invasive Interpretable NAFLD Diagnostic Method Combining TCM Tongue Features</title><link>http://arxiv.org/abs/2309.02959v1</link><description>Non-alcoholic fatty liver disease (NAFLD) is a clinicopathological syndromecharacterized by hepatic steatosis resulting from the exclusion of alcohol andother identifiable liver-damaging factors. It has emerged as a leading cause ofchronic liver disease worldwide. Currently, the conventional methods for NAFLDdetection are expensive and not suitable for users to perform dailydiagnostics. To address this issue, this study proposes a non-invasive andinterpretable NAFLD diagnostic method, the required user-provided indicatorsare only Gender, Age, Height, Weight, Waist Circumference, Hip Circumference,and tongue image. This method involves merging patients' physiologicalindicators with tongue features, which are then input into a fusion networknamed SelectorNet. SelectorNet combines attention mechanisms with featureselection mechanisms, enabling it to autonomously learn the ability to selectimportant features. The experimental results show that the proposed methodachieves an accuracy of 77.22\% using only non-invasive data, and it alsoprovides compelling interpretability matrices. This study contributes to theearly diagnosis of NAFLD and the intelligent advancement of TCM tonguediagnosis. The project in this paper is available at:https://github.com/cshan-github/SelectorNet.</description><author>Shan Cao, Qunsheng Ruan, Qingfeng Wu</author><pubDate>Wed, 06 Sep 2023 13:55:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02959v1</guid></item><item><title>M3D-NCA: Robust 3D Segmentation with Built-in Quality Control</title><link>http://arxiv.org/abs/2309.02954v1</link><description>Medical image segmentation relies heavily on large-scale deep learningmodels, such as UNet-based architectures. However, the real-world utility ofsuch models is limited by their high computational requirements, which makesthem impractical for resource-constrained environments such as primary carefacilities and conflict zones. Furthermore, shifts in the imaging domain canrender these models ineffective and even compromise patient safety if sucherrors go undetected. To address these challenges, we propose M3D-NCA, a novelmethodology that leverages Neural Cellular Automata (NCA) segmentation for 3Dmedical images using n-level patchification. Moreover, we exploit the variancein M3D-NCA to develop a novel quality metric which can automatically detecterrors in the segmentation process of NCAs. M3D-NCA outperforms the twomagnitudes larger UNet models in hippocampus and prostate segmentation by 2%Dice and can be run on a Raspberry Pi 4 Model B (2GB RAM). This highlights thepotential of M3D-NCA as an effective and efficient alternative for medicalimage segmentation in resource-constrained environments.</description><author>John Kalkhof, Anirban Mukhopadhyay</author><pubDate>Wed, 06 Sep 2023 13:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02954v1</guid></item><item><title>A Unified Framework for Exploratory Learning-Aided Community Detection in Networks with Unknown Topology</title><link>http://arxiv.org/abs/2304.04497v2</link><description>In social networks, the discovery of community structures has receivedconsiderable attention as a fundamental problem in various network analysistasks. However, due to privacy concerns or access restrictions, the networkstructure is often unknown, thereby rendering established community detectionapproaches ineffective without costly network topology acquisition. To tacklethis challenge, we present META-CODE, a unified framework for detectingoverlapping communities in networks with unknown topology via exploratorylearning aided by easy-to-collect node metadata. Specifically, META-CODEconsists of three iterative steps in addition to the initial network inferencestep: 1) node-level community-affiliation embeddings based on graph neuralnetworks (GNNs) trained by our new reconstruction loss, 2) network explorationvia community-affiliation-based node queries, and 3) network inference using anedge connectivity-based Siamese neural network model from the explored network.Through extensive experiments on five real-world datasets including two largenetworks, we demonstrated: (a) the superiority of META-CODE over benchmarkcommunity detection methods, achieving remarkable gains up to 151.27% comparedto the best existing competitor, (b) the impact of each module in META-CODE,(c) the effectiveness of node queries in META-CODE based on empiricalevaluations and theoretical findings, (d) the convergence of the inferrednetwork, and (e) the computational efficiency of META-CODE.</description><author>Yu Hou, Cong Tran, Ming Li, Won-Yong Shin</author><pubDate>Wed, 06 Sep 2023 13:41:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.04497v2</guid></item><item><title>Learning solution of nonlinear constitutive material models using physics-informed neural networks: COMM-PINN</title><link>http://arxiv.org/abs/2304.06044v2</link><description>We applied physics-informed neural networks to solve the constitutiverelations for nonlinear, path-dependent material behavior. As a result, thetrained network not only satisfies all thermodynamic constraints but alsoinstantly provides information about the current material state (i.e., freeenergy, stress, and the evolution of internal variables) under any givenloading scenario without requiring initial data. One advantage of this work isthat it bypasses the repetitive Newton iterations needed to solve nonlinearequations in complex material models. Additionally, strategies are provided toreduce the required order of derivative for obtaining the tangent operator. Thetrained model can be directly used in any finite element package (or othernumerical methods) as a user-defined material model. However, challenges remainin the proper definition of collocation points and in integrating severalnon-equality constraints that become active or non-active simultaneously. Wetested this methodology on rate-independent processes such as the classical vonMises plasticity model with a nonlinear hardening law, as well as local damagemodels for interface cracking behavior with a nonlinear softening law. In orderto demonstrate the applicability of the methodology in handling complex pathdependency in a three-dimensional (3D) scenario, we tested the approach usingthe equations governing a damage model for a three-dimensional interface model.Such models are frequently employed for intergranular fracture at grainboundaries. We have observed a perfect agreement between the results obtainedthrough the proposed methodology and those obtained using the classicalapproach. Furthermore, the proposed approach requires significantly less effortin terms of implementation and computing time compared to the traditionalmethods.</description><author>Shahed Rezaei, Ahmad Moeineddin, Ali Harandi</author><pubDate>Wed, 06 Sep 2023 13:31:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.06044v2</guid></item><item><title>jsdp: a Java Stochastic Dynamic Programming Library</title><link>http://arxiv.org/abs/2209.09979v2</link><description>Stochastic Programming is a framework for modelling and solving problems ofdecision making under uncertainty. Stochastic Dynamic Programming is a branchof Stochastic Programming that takes a "functional equation" approach to thediscovery of optimal policies. By leveraging constructs - lambda expressions,functional interfaces, collections and aggregate operators - implemented inJava to operationalise the MapReduce framework, jsdp provides a general purposelibrary for modelling and solving Stochastic Dynamic Programs.</description><author>Roberto Rossi</author><pubDate>Wed, 06 Sep 2023 13:27:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.09979v2</guid></item><item><title>The Curse of Memory in Stochastic Approximation: Extended Version</title><link>http://arxiv.org/abs/2309.02944v1</link><description>Theory and application of stochastic approximation (SA) has grown within thecontrol systems community since the earliest days of adaptive control. Thispaper takes a new look at the topic, motivated by recent results establishingremarkable performance of SA with (sufficiently small) constant step-size$\alpha&gt;0$. If averaging is implemented to obtain the final parameter estimate,then the estimates are asymptotically unbiased with nearly optimal asymptoticcovariance. These results have been obtained for random linear SA recursionswith i.i.d.\ coefficients. This paper obtains very different conclusions in themore common case of geometrically ergodic Markovian disturbance: (i) The\textit{target bias} is identified, even in the case of non-linear SA, and isin general non-zero. The remaining results are established for linear SArecursions: (ii) the bivariate parameter-disturbance process is geometricallyergodic in a topological sense; (iii) the representation for bias has a simplerform in this case, and cannot be expected to be zero if there is multiplicativenoise; (iv) the asymptotic covariance of the averaged parameters is within$O(\alpha)$ of optimal. The error term is identified, and may be massive ifmean dynamics are not well conditioned. The theory is illustrated withapplication to TD-learning.</description><author>Caio Kalil Lauand, Sean Meyn</author><pubDate>Wed, 06 Sep 2023 13:22:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02944v1</guid></item><item><title>H3WB: Human3.6M 3D WholeBody Dataset and Benchmark</title><link>http://arxiv.org/abs/2211.15692v2</link><description>We present a benchmark for 3D human whole-body pose estimation, whichinvolves identifying accurate 3D keypoints on the entire human body, includingface, hands, body, and feet. Currently, the lack of a fully annotated andaccurate 3D whole-body dataset results in deep networks being trainedseparately on specific body parts, which are combined during inference. Or theyrely on pseudo-groundtruth provided by parametric body models which are not asaccurate as detection based methods. To overcome these issues, we introduce theHuman3.6M 3D WholeBody (H3WB) dataset, which provides whole-body annotationsfor the Human3.6M dataset using the COCO Wholebody layout. H3WB comprises 133whole-body keypoint annotations on 100K images, made possible by our newmulti-view pipeline. We also propose three tasks: i) 3D whole-body pose liftingfrom 2D complete whole-body pose, ii) 3D whole-body pose lifting from 2Dincomplete whole-body pose, and iii) 3D whole-body pose estimation from asingle RGB image. Additionally, we report several baselines from popularmethods for these tasks. Furthermore, we also provide automated 3D whole-bodyannotations of TotalCapture and experimentally show that when used with H3WB ithelps to improve the performance. Code and dataset is available athttps://github.com/wholebody3d/wholebody3d</description><author>Yue Zhu, Nermin Samet, David Picard</author><pubDate>Wed, 06 Sep 2023 13:22:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.15692v2</guid></item></channel></rss>