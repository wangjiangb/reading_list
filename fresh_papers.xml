<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 10 Jun 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>3D-GRAND: Towards Better Grounding and Less Hallucination for 3D-LLMs</title><link>http://arxiv.org/abs/2406.05132v1</link><description>The integration of language and 3D perception is crucial for developingembodied agents and robots that comprehend and interact with the physicalworld. While large language models (LLMs) have demonstrated impressive languageunderstanding and generation capabilities, their adaptation to 3D environments(3D-LLMs) remains in its early stages. A primary challenge is the absence oflarge-scale datasets that provide dense grounding between language and 3Dscenes. In this paper, we introduce 3D-GRAND, a pioneering large-scale datasetcomprising 40,087 household scenes paired with 6.2 million densely-groundedscene-language instructions. Our results show that instruction tuning with3D-GRAND significantly enhances grounding capabilities and reduceshallucinations in 3D-LLMs. As part of our contributions, we propose acomprehensive benchmark 3D-POPE to systematically evaluate hallucination in3D-LLMs, enabling fair comparisons among future models. Our experimentshighlight a scaling effect between dataset size and 3D-LLM performance,emphasizing the critical role of large-scale 3D-text datasets in advancingembodied AI research. Notably, our results demonstrate early signals foreffective sim-to-real transfer, indicating that models trained on largesynthetic data can perform well on real-world 3D scans. Through 3D-GRAND and3D-POPE, we aim to equip the embodied AI community with essential resources andinsights, setting the stage for more reliable and better-grounded 3D-LLMs.Project website: https://3d-grand.github.io</description><author>Jianing Yang, Xuweiyi Chen, Nikhil Madaan, Madhavan Iyengar, Shengyi Qian, David F. Fouhey, Joyce Chai</author><pubDate>Fri, 07 Jun 2024 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05132v1</guid></item><item><title>DVOS: Self-Supervised Dense-Pattern Video Object Segmentation</title><link>http://arxiv.org/abs/2406.05131v1</link><description>Video object segmentation approaches primarily rely on large-scalepixel-accurate human-annotated datasets for model development. In Dense VideoObject Segmentation (DVOS) scenarios, each video frame encompasses hundreds ofsmall, dense, and partially occluded objects. Accordingly, the labor-intensivemanual annotation of even a single frame often takes hours, which hinders thedevelopment of DVOS for many applications. Furthermore, in videos with densepatterns, following a large number of objects that move in different directionsposes additional challenges. To address these challenges, we proposed asemi-self-supervised spatiotemporal approach for DVOS utilizing adiffusion-based method through multi-task learning. Emulating real videos'optical flow and simulating their motion, we developed a methodology tosynthesize computationally annotated videos that can be used for training DVOSmodels; The model performance was further improved by utilizing weakly labeled(computationally generated but imprecise) data. To demonstrate the utility andefficacy of the proposed approach, we developed DVOS models for wheat headsegmentation of handheld and drone-captured videos, capturing wheat crops infields of different locations across various growth stages, spanning fromheading to maturity. Despite using only a few manually annotated video frames,the proposed approach yielded high-performing models, achieving a Dice score of0.82 when tested on a drone-captured external test set. While we showed theefficacy of the proposed approach for wheat head segmentation, its applicationcan be extended to other crops or DVOS in other domains, such as crowd analysisor microscopic image analysis.</description><author>Keyhan Najafian, Farhad Maleki, Ian Stavness, Lingling Jin</author><pubDate>Fri, 07 Jun 2024 18:58:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05131v1</guid></item><item><title>CheckEmbed: Effective Verification of LLM Solutions to Open-Ended Tasks</title><link>http://arxiv.org/abs/2406.02524v2</link><description>Large Language Models (LLMs) are revolutionizing various domains, yetverifying their answers remains a significant challenge, especially forintricate open-ended tasks such as consolidation, summarization, and extractionof knowledge. In this work, we propose CheckEmbed: an accurate, scalable, andsimple LLM verification approach. CheckEmbed is driven by a straightforward yetpowerful idea: in order to compare LLM solutions to one another or to theground-truth, compare their corresponding answer-level embeddings obtained witha model such as GPT Text Embedding Large. This reduces a complex textual answerto a single embedding, facilitating straightforward, fast, and meaningfulverification. We develop a comprehensive verification pipeline implementing theCheckEmbed methodology. The CheckEmbed pipeline also comes with metrics forassessing the truthfulness of the LLM answers, such as embedding heatmaps andtheir summaries. We show how to use these metrics for deploying practicalengines that decide whether an LLM answer is satisfactory or not. We apply thepipeline to real-world document analysis tasks, including term extraction anddocument summarization, showcasing significant improvements in accuracy,cost-effectiveness, and runtime performance compared to existing token-,sentence-, and fact-level schemes such as BERTScore or SelfCheckGPT.</description><author>Maciej Besta, Lorenzo Paleari, Ales Kubicek, Piotr Nyczyk, Robert Gerstenberger, Patrick Iff, Tomasz Lehmann, Hubert Niewiadomski, Torsten Hoefler</author><pubDate>Fri, 07 Jun 2024 18:58:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02524v2</guid></item><item><title>An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal Large Language Models</title><link>http://arxiv.org/abs/2406.05130v1</link><description>Multimodal large language models (MLLMs) fine-tuned with multimodalinstruction datasets have demonstrated remarkable capabilities in multimodaltasks. However, fine-tuning all parameters of MLLMs has become challenging asthey usually contain billions of parameters. To address this issue, we studyparameter-efficient fine-tuning (PEFT) methods for MLLMs. We aim to identifyeffective methods for enhancing the performance of MLLMs in scenarios whereonly a limited number of parameters are trained. This paper conducts empiricalstudies using four popular PEFT methods to fine-tune the LLM component ofopen-source MLLMs. We present a comprehensive analysis that encompasses variousaspects, including the impact of PEFT methods on various models, parameters andlocation of the PEFT module, size of fine-tuning data, model stability based onPEFT methods, MLLM's generalization, and hallucination. We evaluated four PEFTmethods on seven datasets from two different categories: unseen and seendatasets. Across all experiments, we show that the adapter is thebest-performing PEFT method. At the same time, fine-tuning the connector layersleads to improved performance in most MLLMs. Code and data are available athttps://github.com/alenai97/PEFT-MLLM.git.</description><author>Xiongtao Zhou, Jie He, Yuhua Ke, Guangyao Zhu, Víctor Gutiérrez-Basulto, Jeff Z. Pan</author><pubDate>Fri, 07 Jun 2024 18:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05130v1</guid></item><item><title>PatchSVD: A Non-uniform SVD-based Image Compression Algorithm</title><link>http://arxiv.org/abs/2406.05129v1</link><description>Storing data is particularly a challenge when dealing with image data whichoften involves large file sizes due to the high resolution and complexity ofimages. Efficient image compression algorithms are crucial to better managedata storage costs. In this paper, we propose a novel region-based lossy imagecompression technique, called PatchSVD, based on the Singular ValueDecomposition (SVD) algorithm. We show through experiments that PatchSVDoutperforms SVD-based image compression with respect to three popular imagecompression metrics. Moreover, we compare PatchSVD compression artifacts withthose of Joint Photographic Experts Group (JPEG) and SVD-based imagecompression and illustrate some cases where PatchSVD compression artifacts arepreferable compared to JPEG and SVD artifacts.</description><author>Zahra Golpayegani, Nizar Bouguila</author><pubDate>Fri, 07 Jun 2024 18:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05129v1</guid></item><item><title>Towards Semantic Equivalence of Tokenization in Multimodal LLM</title><link>http://arxiv.org/abs/2406.05127v1</link><description>Multimodal Large Language Models (MLLMs) have demonstrated exceptionalcapabilities in processing vision-language tasks. One of the crux of MLLMs liesin vision tokenization, which involves efficiently transforming input visualsignals into feature representations that are most beneficial for LLMs.However, existing vision tokenizers, essential for semantic alignment betweenvision and language, remain problematic. Existing methods aggressively fragmentvisual input, corrupting the visual semantic integrity. To address this, thispaper proposes a novel dynamic Semantic-Equivalent Vision Tokenizer (SeTok),which groups visual features into semantic units via a dynamic clusteringalgorithm, flexibly determining the number of tokens based on image complexity.The resulting vision tokens effectively preserve semantic integrity and captureboth low-frequency and high-frequency visual features. The proposed MLLM(Setokim) equipped with SeTok significantly demonstrates superior performanceacross various tasks, as evidenced by our experimental results. The projectpage is at https://chocowu.github.io/SeTok-web/.</description><author>Shengqiong Wu, Hao Fei, Xiangtai Li, Jiayi Ji, Hanwang Zhang, Tat-Seng Chua, Shuicheng Yan</author><pubDate>Fri, 07 Jun 2024 18:55:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05127v1</guid></item><item><title>Energy Propagation in Scattering Convolution Networks Can Be Arbitrarily Slow</title><link>http://arxiv.org/abs/2406.05121v1</link><description>We analyze energy decay for deep convolutional neural networks employed asfeature extractors, such as Mallat's wavelet scattering transform. Fortime-frequency scattering transforms based on Gabor filters, it has beenestablished that energy decay is exponential, for arbitrary square-integrableinput signals. Our main results allow to prove that this is wrong for waveletscattering in arbitrary dimensions. In this setting, the energy decay of thescattering transform acting on a generic square-integrable signal turns out tobe arbitrarily slow. The fact that this behavior holds for dense subsets of$L^2(\mathbb{R}^d)$ emphasizes that fast energy decay is generally not a stableproperty of signals. We complement these findings with positive results allowing to conclude fast(up to exponential) energy decay for generalized Sobolev spaces that aretailored to the frequency localization of the underlying filter bank. Both negative and positive results highlight that energy decay in scatteringnetworks critically depends on the interplay of the respective frequencylocalizations of the signal on the one hand, and of the employed filters on theother.</description><author>Hartmut Führ, Max Getter</author><pubDate>Fri, 07 Jun 2024 18:52:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05121v1</guid></item><item><title>Contextual fusion enhances robustness to image blurring</title><link>http://arxiv.org/abs/2406.05120v1</link><description>Mammalian brains handle complex reasoning by integrating information acrossbrain regions specialized for particular sensory modalities. This enablesimproved robustness and generalization versus deep neural networks, whichtypically process one modality and are vulnerable to perturbations. Whiledefense methods exist, they do not generalize well across perturbations. Wedeveloped a fusion model combining background and foreground features from CNNstrained on Imagenet and Places365. We tested its robustness tohuman-perceivable perturbations on MS COCO. The fusion model improvedrobustness, especially for classes with greater context variability. Ourproposed solution for integrating multiple modalities provides a new approachto enhance robustness and may be complementary to existing methods.</description><author>Shruti Joshi, Aiswarya Akumalla, Seth Haney, Maxim Bazhenov</author><pubDate>Fri, 07 Jun 2024 18:50:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05120v1</guid></item><item><title>Compositional Curvature Bounds for Deep Neural Networks</title><link>http://arxiv.org/abs/2406.05119v1</link><description>A key challenge that threatens the widespread use of neural networks insafety-critical applications is their vulnerability to adversarial attacks. Inthis paper, we study the second-order behavior of continuously differentiabledeep neural networks, focusing on robustness against adversarial perturbations.First, we provide a theoretical analysis of robustness and attack certificatesfor deep classifiers by leveraging local gradients and upper bounds on thesecond derivative (curvature constant). Next, we introduce a novel algorithm toanalytically compute provable upper bounds on the second derivative of neuralnetworks. This algorithm leverages the compositional structure of the model topropagate the curvature bound layer-by-layer, giving rise to a scalable andmodular approach. The proposed bound can serve as a differentiable regularizerto control the curvature of neural networks during training, thereby enhancingrobustness. Finally, we demonstrate the efficacy of our method onclassification tasks using the MNIST and CIFAR-10 datasets.</description><author>Taha Entesari, Sina Sharifi, Mahyar Fazlyab</author><pubDate>Fri, 07 Jun 2024 18:50:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05119v1</guid></item><item><title>The Expanding Scope of the Stability Gap: Unveiling its Presence in Joint Incremental Learning of Homogeneous Tasks</title><link>http://arxiv.org/abs/2406.05114v1</link><description>Recent research identified a temporary performance drop on previously learnedtasks when transitioning to a new one. This drop is called the stability gapand has great consequences for continual learning: it complicates the directemployment of continually learning since the worse-case performance attask-boundaries is dramatic, it limits its potential as an energy-efficienttraining paradigm, and finally, the stability drop could result in a reducedfinal performance of the algorithm. In this paper, we show that the stabilitygap also occurs when applying joint incremental training of homogeneous tasks.In this scenario, the learner continues training on the same data distributionand has access to all data from previous tasks. In addition, we show that inthis scenario, there exists a low-loss linear path to the next minima, but thatSGD optimization does not choose this path. We perform further analysisincluding a finer batch-wise analysis which could provide insights towardspotential solution directions.</description><author>Sandesh Kamath, Albin Soutif-Cormerais, Joost van de Weijer, Bogdan Raducanu</author><pubDate>Fri, 07 Jun 2024 18:44:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05114v1</guid></item><item><title>LLavaGuard: VLM-based Safeguards for Vision Dataset Curation and Safety Assessment</title><link>http://arxiv.org/abs/2406.05113v1</link><description>We introduce LlavaGuard, a family of VLM-based safeguard models, offering aversatile framework for evaluating the safety compliance of visual content.Specifically, we designed LlavaGuard for dataset annotation and generativemodel safeguarding. To this end, we collected and annotated a high-qualityvisual dataset incorporating a broad safety taxonomy, which we use to tune VLMson context-aware safety risks. As a key innovation, LlavaGuard's new responsescontain comprehensive information, including a safety rating, the violatedsafety categories, and an in-depth rationale. Further, our introducedcustomizable taxonomy categories enable the context-specific alignment ofLlavaGuard to various scenarios. Our experiments highlight the capabilities ofLlavaGuard in complex and real-world applications. We provide checkpointsranging from 7B to 34B parameters demonstrating state-of-the-art performance,with even the smallest models outperforming baselines like GPT-4. We make ourdataset and model weights publicly available and invite further research toaddress the diverse needs of communities and contexts.</description><author>Lukas Helff, Felix Friedrich, Manuel Brack, Kristian Kersting, Patrick Schramowski</author><pubDate>Fri, 07 Jun 2024 18:44:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05113v1</guid></item><item><title>Large Generative Graph Models</title><link>http://arxiv.org/abs/2406.05109v1</link><description>Large Generative Models (LGMs) such as GPT, Stable Diffusion, Sora, and Sunoare trained on a huge amount of language corpus, images, videos, and audio thatare extremely diverse from numerous domains. This training paradigm overdiverse well-curated data lies at the heart of generating creative and sensiblecontent. However, all previous graph generative models (e.g., GraphRNN, MDVAE,MoFlow, GDSS, and DiGress) have been trained only on one dataset each time,which cannot replicate the revolutionary success achieved by LGMs in otherfields. To remedy this crucial gap, we propose a new class of graph generativemodel called Large Graph Generative Model (LGGM) that is trained on a largecorpus of graphs (over 5000 graphs) from 13 different domains. We empiricallydemonstrate that the pre-trained LGGM has superior zero-shot generativecapability to existing graph generative models. Furthermore, our pre-trainedLGGM can be easily fine-tuned with graphs from target domains and demonstrateeven better performance than those directly trained from scratch, behaving as asolid starting point for real-world customization. Inspired by StableDiffusion, we further equip LGGM with the capability to generate graphs giventext prompts (Text-to-Graph), such as the description of the network name anddomain (i.e., "The power-1138-bus graph represents a network of buses in apower distribution system."), and network statistics (i.e., "The graph has alow average degree, suitable for modeling social media interactions."). ThisText-to-Graph capability integrates the extensive world knowledge in theunderlying language model, offering users fine-grained control of the generatedgraphs. We release the code, the model checkpoint, and the datasets athttps://lggm-lg.github.io/.</description><author>Yu Wang, Ryan A. Rossi, Namyong Park, Huiyuan Chen, Nesreen K. Ahmed, Puja Trivedi, Franck Dernoncourt, Danai Koutra, Tyler Derr</author><pubDate>Fri, 07 Jun 2024 18:41:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05109v1</guid></item><item><title>Adapting Physics-Informed Neural Networks To Optimize ODEs in Mosquito Population Dynamics</title><link>http://arxiv.org/abs/2406.05108v1</link><description>Physics informed neural networks have been gaining popularity due to theirunique ability to incorporate physics laws into data-driven models, ensuringthat the predictions are not only consistent with empirical data but also alignwith domain-specific knowledge in the form of physics equations. Theintegration of physics principles enables the method to require less data whilemaintaining the robustness of deep learning in modeling complex dynamicalsystems. However, current PINN frameworks are not sufficiently mature forreal-world ODE systems, especially those with extreme multi-scale behavior suchas mosquito population dynamical modelling. In this research, we propose a PINNframework with several improvements for forward and inverse problems for ODEsystems with a case study application in modelling the dynamics of mosquitopopulations. The framework tackles the gradient imbalance and stiff problemsposed by mosquito ordinary differential equations. The method offers a simplebut effective way to resolve the time causality issue in PINNs by graduallyexpanding the training time domain until it covers entire domain of interest.As part of a robust evaluation, we conduct experiments using simulated data toevaluate the effectiveness of the approach. Preliminary results indicate thatphysics-informed machine learning holds significant potential for advancing thestudy of ecological systems.</description><author>Dinh Viet Cuong, Branislava Lalić, Mina Petrić, Binh Nguyen, Mark Roantree</author><pubDate>Fri, 07 Jun 2024 18:40:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05108v1</guid></item><item><title>A Sparse Graph Formulation for Efficient Spectral Image Segmentation</title><link>http://arxiv.org/abs/2306.13166v3</link><description>Spectral Clustering is one of the most traditional methods to solvesegmentation problems. Based on Normalized Cuts, it aims at partitioning animage using an objective function defined by a graph. Despite theirmathematical attractiveness, spectral approaches are traditionally neglected bythe scientific community due to their practical issues and underperformance. Inthis paper, we adopt a sparse graph formulation based on the inclusion of extranodes to a simple grid graph. While the grid encodes the pixel spatialdisposition, the extra nodes account for the pixel color data. Applying theoriginal Normalized Cuts algorithm to this graph leads to a simple and scalablemethod for spectral image segmentation, with an interpretable solution. Ourexperiments also demonstrate that our proposed methodology over performs bothtraditional and modern unsupervised algorithms for segmentation in both realand synthetic data.</description><author>Rahul Palnitkar, Jeova Farias Sales Rocha Neto</author><pubDate>Fri, 07 Jun 2024 18:37:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13166v3</guid></item><item><title>ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs</title><link>http://arxiv.org/abs/2402.11753v4</link><description>Safety is critical to the usage of large language models (LLMs). Multipletechniques such as data filtering and supervised fine-tuning have beendeveloped to strengthen LLM safety. However, currently known techniques presumethat corpora used for safety alignment of LLMs are solely interpreted bysemantics. This assumption, however, does not hold in real-world applications,which leads to severe vulnerabilities in LLMs. For example, users of forumsoften use ASCII art, a form of text-based art, to convey image information. Inthis paper, we propose a novel ASCII art-based jailbreak attack and introduce acomprehensive benchmark Vision-in-Text Challenge (ViTC) to evaluate thecapabilities of LLMs in recognizing prompts that cannot be solely interpretedby semantics. We show that five SOTA LLMs (GPT-3.5, GPT-4, Gemini, Claude, andLlama2) struggle to recognize prompts provided in the form of ASCII art. Basedon this observation, we develop the jailbreak attack ArtPrompt, which leveragesthe poor performance of LLMs in recognizing ASCII art to bypass safety measuresand elicit undesired behaviors from LLMs. ArtPrompt only requires black-boxaccess to the victim LLMs, making it a practical attack. We evaluate ArtPrompton five SOTA LLMs, and show that ArtPrompt can effectively and efficientlyinduce undesired behaviors from all five LLMs. Our code is available athttps://github.com/uw-nsl/ArtPrompt.</description><author>Fengqing Jiang, Zhangchen Xu, Luyao Niu, Zhen Xiang, Bhaskar Ramasubramanian, Bo Li, Radha Poovendran</author><pubDate>Fri, 07 Jun 2024 18:35:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11753v4</guid></item><item><title>ChemReasoner: Heuristic Search over a Large Language Model's Knowledge Space using Quantum-Chemical Feedback</title><link>http://arxiv.org/abs/2402.10980v4</link><description>The discovery of new catalysts is essential for the design of new and moreefficient chemical processes in order to transition to a sustainable future. Weintroduce an AI-guided computational screening framework unifying linguisticreasoning with quantum-chemistry based feedback from 3D atomisticrepresentations. Our approach formulates catalyst discovery as an uncertainenvironment where an agent actively searches for highly effective catalysts viathe iterative combination of large language model (LLM)-derived hypotheses andatomistic graph neural network (GNN)-derived feedback. Identified catalysts inintermediate search steps undergo structural evaluation based on spatialorientation, reaction pathways, and stability. Scoring functions based onadsorption energies and reaction energy barriers steer the exploration in theLLM's knowledge space toward energetically favorable, high-efficiencycatalysts. We introduce planning methods that automatically guide theexploration without human input, providing competitive performance againstexpert-enumerated chemical descriptor-based implementations. By integratinglanguage-guided reasoning with computational chemistry feedback, our workpioneers AI-accelerated, trustworthy catalyst discovery.</description><author>Henry W. Sprueill, Carl Edwards, Khushbu Agarwal, Mariefel V. Olarte, Udishnu Sanyal, Conrad Johnston, Hongbin Liu, Heng Ji, Sutanay Choudhury</author><pubDate>Fri, 07 Jun 2024 18:33:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10980v4</guid></item><item><title>Self-Improving Robust Preference Optimization</title><link>http://arxiv.org/abs/2406.01660v3</link><description>Both online and offline RLHF methods such as PPO and DPO have been extremelysuccessful in aligning AI with human preferences. Despite their success, theexisting methods suffer from a fundamental problem that their optimal solutionis highly task-dependent (i.e., not robust to out-of-distribution (OOD) tasks).Here we address this challenge by proposing Self-Improving Robust PreferenceOptimization SRPO, a practical and mathematically principled offline RLHFframework that is completely robust to the changes in the task. The key idea ofSRPO is to cast the problem of learning from human preferences as aself-improvement process, which can be mathematically expressed in terms of amin-max objective that aims at joint optimization of self-improvement policyand the generative policy in an adversarial fashion. The solution for thisoptimization problem is independent of the training task and thus it is robustto its changes. We then show that this objective can be re-expressed in theform of a non-adversarial offline loss which can be optimized using standardsupervised optimization techniques at scale without any need for reward modeland online inference. We show the effectiveness of SRPO in terms of AI Win-Rate(WR) against human (GOLD) completions. In particular, when SRPO is evaluated onthe OOD XSUM dataset, it outperforms the celebrated DPO by a clear margin of15% after 5 self-revisions, achieving WR of 90%.</description><author>Eugene Choi, Arash Ahmadian, Matthieu Geist, Oilvier Pietquin, Mohammad Gheshlaghi Azar</author><pubDate>Fri, 07 Jun 2024 18:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01660v3</guid></item><item><title>SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding</title><link>http://arxiv.org/abs/2402.08983v3</link><description>As large language models (LLMs) become increasingly integrated intoreal-world applications such as code generation and chatbot assistance,extensive efforts have been made to align LLM behavior with human values,including safety. Jailbreak attacks, aiming to provoke unintended and unsafebehaviors from LLMs, remain a significant/leading LLM safety threat. In thispaper, we aim to defend LLMs against jailbreak attacks by introducingSafeDecoding, a safety-aware decoding strategy for LLMs to generate helpful andharmless responses to user queries. Our insight in developing SafeDecoding isbased on the observation that, even though probabilities of tokens representingharmful contents outweigh those representing harmless responses, safetydisclaimers still appear among the top tokens after sorting tokens byprobability in descending order. This allows us to mitigate jailbreak attacksby identifying safety disclaimers and amplifying their token probabilities,while simultaneously attenuating the probabilities of token sequences that arealigned with the objectives of jailbreak attacks. We perform extensiveexperiments on five LLMs using six state-of-the-art jailbreak attacks and fourbenchmark datasets. Our results show that SafeDecoding significantly reducesthe attack success rate and harmfulness of jailbreak attacks withoutcompromising the helpfulness of responses to benign user queries. SafeDecodingoutperforms six defense methods.</description><author>Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Bill Yuchen Lin, Radha Poovendran</author><pubDate>Fri, 07 Jun 2024 18:25:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08983v3</guid></item><item><title>Towards a theory of out-of-distribution learning</title><link>http://arxiv.org/abs/2109.14501v5</link><description>Learning is a process wherein a learning agent enhances its performancethrough exposure of experience or data. Throughout this journey, the agent mayencounter diverse learning environments. For example, data may be presented tothe leaner all at once, in multiple batches, or sequentially. Furthermore, thedistribution of each data sample could be either identical and independent(iid) or non-iid. Additionally, there may exist computational and spaceconstraints for the deployment of the learning algorithms. The complexity of alearning task can vary significantly, depending on the learning setup and theconstraints imposed upon it. However, it is worth noting that the currentliterature lacks formal definitions for many of the in-distribution andout-of-distribution learning paradigms. Establishing proper and universallyagreed-upon definitions for these learning setups is essential for thoroughlyexploring the evolution of ideas across different learning scenarios andderiving generalized mathematical bounds for these learners. In this paper, weaim to address this issue by proposing a chronological approach to definingdifferent learning tasks using the provably approximately correct (PAC)learning framework. We will start with in-distribution learning and progress torecently proposed lifelong or continual learning. We employ consistentterminology and notation to demonstrate how each of these learning frameworksrepresents a specific instance of a broader, more generalized concept oflearnability. Our hope is that this work will inspire a universally agreed-uponapproach to quantifying different types of learning, fostering greaterunderstanding and progress in the field.</description><author>Jayanta Dey, Ali Geisa, Ronak Mehta, Tyler M. Tomita, Hayden S. Helm, Haoyin Xu, Eric Eaton, Jeffery Dick, Carey E. Priebe, Joshua T. Vogelstein</author><pubDate>Fri, 07 Jun 2024 18:24:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.14501v5</guid></item><item><title>A Novel Time Series-to-Image Encoding Approach for Weather Phenomena Classification</title><link>http://arxiv.org/abs/2406.05096v1</link><description>Rainfall estimation through the analysis of its impact on electromagneticwaves has sparked increasing interest in the research community. Recent studieshave delved into its effects on cellular network performance, demonstrating thepotential to forecast rainfall levels based on electromagnetic wave attenuationduring precipitations. This paper aims to solve the problem of identifying thenature of specific weather phenomena from the received signal level (RSL) in4G/LTE mobile terminals. Specifically, utilizing time-series data representingRSL, we propose a novel approach to encode time series as images and model thetask as an image classification problem, which we finally address usingconvolutional neural networks (CNNs). The main benefit of the abovementionedprocedure is the opportunity to utilize various data augmentation techniquessimultaneously. This encompasses applying traditional approaches, such asmoving averages, to the time series and enhancing the generated images. We haveinvestigated various image data augmentation methods to identify the mosteffective combination for this scenario. In the upcoming sections, we willintroduce the task of rainfall estimation and conduct a comprehensive analysisof the dataset used. Subsequently, we will formally propose a new approach forconverting time series into images. To conclude, the paper's final section willpresent and discuss the experiments conducted, providing the reader with abrief yet comprehensive overview of the results.</description><author>Christian Giannetti</author><pubDate>Fri, 07 Jun 2024 18:21:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05096v1</guid></item><item><title>NeuralThink: Learning Algorithms For Consistent and Efficient Extrapolation Across General Tasks</title><link>http://arxiv.org/abs/2402.15393v2</link><description>We propose NeuralThink, a novel deep thinking architecture that canefficiently and consistently extrapolate, i.e., learn algorithms from smallerproblems (in terms of observation size) and execute those algorithms in largeproblems. Contrary to previous deep thinking architectures, NeuralThink can benaturally applied in both same-size problems, where the input and output sizesare the same, and in different-size problems, where the size of the input andoutput differ. To allow for this versatility, we design NeuralThink with threemain components: a recurrent module, that iteratively processes inputinformation at different scales, a processing module, responsible foraggregating the previously processed information, and a curriculum-basedtraining scheme, that improves the extrapolation performance of the method. Toevaluate our method we introduce a set of novel different-size tasks and weshow that NeuralThink consistently outperforms the prior state-of-the-art deepthinking approaches in extrapolating to larger problems, considering smallertraining problems and requiring less parameters than other approaches.</description><author>Bernardo Esteves, Miguel Vasco, Francisco S. Melo</author><pubDate>Fri, 07 Jun 2024 18:10:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15393v2</guid></item><item><title>Deep Discriminative to Kernel Density Graph for In- and Out-of-distribution Calibrated Inference</title><link>http://arxiv.org/abs/2201.13001v8</link><description>Deep discriminative approaches like random forests and deep neural networkshave recently found applications in many important real-world scenarios.However, deploying these learning algorithms in safety-critical applicationsraises concerns, particularly when it comes to ensuring confidence calibrationfor both in-distribution and out-of-distribution data points. Many popularmethods for in-distribution (ID) calibration, such as isotonic and Platt'ssigmoidal regression, exhibit excellent ID calibration performance. However,these methods are not calibrated for the entire feature space, leading tooverconfidence in the case of out-of-distribution (OOD) samples. On the otherend of the spectrum, existing out-of-distribution (OOD) calibration methodsgenerally exhibit poor in-distribution (ID) calibration. In this paper, weaddress ID and OOD calibration problems jointly. We leveraged the fact thatdeep models, including both random forests and deep-nets, learn internalrepresentations which are unions of polytopes with affine activation functionsto conceptualize them both as partitioning rules of the feature space. Wereplace the affine function in each polytope populated by the training datawith a Gaussian kernel. Our experiments on both tabular and vision benchmarksshow that the proposed approaches obtain well-calibrated posteriors whilemostly preserving or improving the classification accuracy of the originalalgorithm for ID region, and extrapolate beyond the training data to handle OODinputs appropriately.</description><author>Jayanta Dey, Haoyin Xu, Will LeVine, Ashwin De Silva, Tyler M. Tomita, Ali Geisa, Tiffany Chu, Jacob Desman, Joshua T. Vogelstein</author><pubDate>Fri, 07 Jun 2024 18:10:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.13001v8</guid></item><item><title>Provably Better Explanations with Optimized Aggregation of Feature Attributions</title><link>http://arxiv.org/abs/2406.05090v1</link><description>Using feature attributions for post-hoc explanations is a common practice tounderstand and verify the predictions of opaque machine learning models.Despite the numerous techniques available, individual methods often produceinconsistent and unstable results, putting their overall reliability intoquestion. In this work, we aim to systematically improve the quality of featureattributions by combining multiple explanations across distinct methods ortheir variations. For this purpose, we propose a novel approach to deriveoptimal convex combinations of feature attributions that yield provableimprovements of desired quality criteria such as robustness or faithfulness tothe model behavior. Through extensive experiments involving various modelarchitectures and popular feature attribution techniques, we demonstrate thatour combination strategy consistently outperforms individual methods andexisting baselines.</description><author>Thomas Decker, Ananta R. Bhattarai, Jindong Gu, Volker Tresp, Florian Buettner</author><pubDate>Fri, 07 Jun 2024 18:03:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05090v1</guid></item><item><title>Optimizing Time Series Forecasting Architectures: A Hierarchical Neural Architecture Search Approach</title><link>http://arxiv.org/abs/2406.05088v1</link><description>The rapid development of time series forecasting research has brought manydeep learning-based modules in this field. However, despite the increasingamount of new forecasting architectures, it is still unclear if we haveleveraged the full potential of these existing modules within a properlydesigned architecture. In this work, we propose a novel hierarchical neuralarchitecture search approach for time series forecasting tasks. With the designof a hierarchical search space, we incorporate many architecture types designedfor forecasting tasks and allow for the efficient combination of differentforecasting architecture modules. Results on long-term-time-series-forecastingtasks show that our approach can search for lightweight high-performingforecasting architectures across different forecasting tasks.</description><author>Difan Deng, Marius Lindauer</author><pubDate>Fri, 07 Jun 2024 18:02:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05088v1</guid></item><item><title>Robust Reward Design for Markov Decision Processes</title><link>http://arxiv.org/abs/2406.05086v1</link><description>The problem of reward design examines the interaction between a leader and afollower, where the leader aims to shape the follower's behavior to maximizethe leader's payoff by modifying the follower's reward function. Currentapproaches to reward design rely on an accurate model of how the followerresponds to reward modifications, which can be sensitive to modelinginaccuracies. To address this issue of sensitivity, we present a solution thatoffers robustness against uncertainties in modeling the follower, including 1)how the follower breaks ties in the presence of nonunique best responses, 2)inexact knowledge of how the follower perceives reward modifications, and 3)bounded rationality of the follower. Our robust solution is guaranteed to existunder mild conditions and can be obtained numerically by solving amixed-integer linear program. Numerical experiments on multiple test casesdemonstrate that our solution improves robustness compared to the standardapproach without incurring significant additional computing costs.</description><author>Shuo Wu, Haoxiang Ma, Jie Fu, Shuo Han</author><pubDate>Fri, 07 Jun 2024 18:01:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05086v1</guid></item><item><title>DORY: Deliberative Prompt Recovery for LLM</title><link>http://arxiv.org/abs/2405.20657v2</link><description>Prompt recovery in large language models (LLMs) is crucial for understandinghow LLMs work and addressing concerns regarding privacy, copyright, etc. Thetrend towards inference-only APIs complicates this task by restricting accessto essential outputs for recovery. To tackle this challenge, we extractprompt-related information from limited outputs and identify a strong(negative)correlation between output probability-based uncertainty and the success ofprompt recovery. This finding led to the development of Deliberative PrOmptRecoverY (DORY), our novel approach that leverages uncertainty to recoverprompts accurately. DORY involves reconstructing drafts from outputs, refiningthese with hints, and filtering out noise based on uncertainty. Our evaluationacross diverse LLMs and prompt benchmarks shows that DORY outperforms existingbaselines, improving performance by approximately 10.82% and establishing a newstate-of-the-art record in prompt recovery tasks. Significantly, DORY operatesusing a single LLM without any external resources or model, offering acost-effective, user-friendly prompt recovery solution.</description><author>Lirong Gao, Ru Peng, Yiming Zhang, Junbo Zhao</author><pubDate>Fri, 07 Jun 2024 18:00:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.20657v2</guid></item><item><title>Multi-Head RAG: Solving Multi-Aspect Problems with LLMs</title><link>http://arxiv.org/abs/2406.05085v1</link><description>Retrieval Augmented Generation (RAG) enhances the abilities of Large LanguageModels (LLMs) by enabling the retrieval of documents into the LLM context toprovide more accurate and relevant responses. Existing RAG solutions do notfocus on queries that may require fetching multiple documents withsubstantially different contents. Such queries occur frequently, but arechallenging because the embeddings of these documents may be distant in theembedding space, making it hard to retrieve them all. This paper introducesMulti-Head RAG (MRAG), a novel scheme designed to address this gap with asimple yet powerful idea: leveraging activations of Transformer's multi-headattention layer, instead of the decoder layer, as keys for fetchingmulti-aspect documents. The driving motivation is that different attentionheads can learn to capture different data aspects. Harnessing the correspondingactivations results in embeddings that represent various facets of data itemsand queries, improving the retrieval accuracy for complex queries. We providean evaluation methodology and metrics, synthetic datasets, and real-world usecases to demonstrate MRAG's effectiveness, showing improvements of up to 20% inrelevance over standard RAG baselines. MRAG can be seamlessly integrated withexisting RAG frameworks and benchmarking tools like RAGAS as well as differentclasses of data stores.</description><author>Maciej Besta, Ales Kubicek, Roman Niggli, Robert Gerstenberger, Lucas Weitzendorf, Mingyuan Chi, Patrick Iff, Joanna Gajda, Piotr Nyczyk, Jürgen Müller, Hubert Niewiadomski, Marcin Chrapek, Michał Podstawski, Torsten Hoefler</author><pubDate>Fri, 07 Jun 2024 17:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05085v1</guid></item><item><title>On Ambiguity and the Expressive Function of Law: The Role of Pragmatics in Smart Legal Ecosystems</title><link>http://arxiv.org/abs/2406.05084v1</link><description>This is a long paper, an essay, on ambiguity, pragmatics, legal ecosystems,and the expressive function of law. It is divided into two parts and fifteensections. The first part (Pragmatics) addresses ambiguity from the perspectiveof linguistic and cognitive pragmatics in the legal field. The second part(Computing) deals with this issue from the point of view of human-centereddesign and artificial intelligence, specifically focusing on the notion andmodelling of rules and what it means to comply with the rules. This isnecessary for the scaffolding of smart legal ecosystems (SLE). I will developthis subject with the example of the architecture, information flows, and smartecosystem of OPTIMAI, an EU project of Industry 4.0 for zero-defectmanufacturing (Optimizing Manufacturing Processes through ArtificialIntelligence and Virtualization).</description><author>Pompeu Casanovas</author><pubDate>Fri, 07 Jun 2024 17:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05084v1</guid></item><item><title>CoNo: Consistency Noise Injection for Tuning-free Long Video Diffusion</title><link>http://arxiv.org/abs/2406.05082v1</link><description>Tuning-free long video diffusion has been proposed to generateextended-duration videos with enriched content by reusing the knowledge frompre-trained short video diffusion model without retraining. However, most worksoverlook the fine-grained long-term video consistency modeling, resulting inlimited scene consistency (i.e., unreasonable object or backgroundtransitions), especially with multiple text inputs. To mitigate this, wepropose the Consistency Noise Injection, dubbed CoNo, which introduces the"look-back" mechanism to enhance the fine-grained scene transition betweendifferent video clips, and designs the long-term consistency regularization toeliminate the content shifts when extending video contents through noiseprediction. In particular, the "look-back" mechanism breaks the noisescheduling process into three essential parts, where one internal noiseprediction part is injected into two video-extending parts, intending toachieve a fine-grained transition between two video clips. The long-termconsistency regularization focuses on explicitly minimizing the pixel-wisedistance between the predicted noises of the extended video clip and theoriginal one, thereby preventing abrupt scene transitions. Extensiveexperiments have shown the effectiveness of the above strategies by performinglong-video generation under both single- and multi-text prompt conditions. Theproject has been available in https://wxrui182.github.io/CoNo.github.io/.</description><author>Xingrui Wang, Xin Li, Zhibo Chen</author><pubDate>Fri, 07 Jun 2024 17:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05082v1</guid></item><item><title>MedYOLO: A Medical Image Object Detection Framework</title><link>http://arxiv.org/abs/2312.07729v2</link><description>Artificial intelligence-enhanced identification of organs, lesions, and otherstructures in medical imaging is typically done using convolutional neuralnetworks (CNNs) designed to make voxel-accurate segmentations of the region ofinterest. However, the labels required to train these CNNs are time-consumingto generate and require attention from subject matter experts to ensurequality. For tasks where voxel-level precision is not required, objectdetection models offer a viable alternative that can reduce annotation effort.Despite this potential application, there are few options for general purposeobject detection frameworks available for 3-D medical imaging. We report onMedYOLO, a 3-D object detection framework using the one-shot detection methodof the YOLO family of models and designed for use with medical imaging. Wetested this model on four different datasets: BRaTS, LIDC, an abdominal organComputed Tomography (CT) dataset, and an ECG-gated heart CT dataset. We foundour models achieve high performance on commonly present medium and large-sizedstructures such as the heart, liver, and pancreas even without hyperparametertuning. However, the models struggle with very small or rarely presentstructures.</description><author>Joseph Sobek, Jose R. Medina Inojosa, Betsy J. Medina Inojosa, S. M. Rassoulinejad-Mousavi, Gian Marco Conte, Francisco Lopez-Jimenez, Bradley J. Erickson</author><pubDate>Fri, 07 Jun 2024 17:53:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07729v2</guid></item><item><title>I2EDL: Interactive Instruction Error Detection and Localization</title><link>http://arxiv.org/abs/2406.05080v1</link><description>In the Vision-and-Language Navigation in Continuous Environments (VLN-CE)task, the human user guides an autonomous agent to reach a target goal via aseries of low-level actions following a textual instruction in naturallanguage. However, most existing methods do not address the likely case whereusers may make mistakes when providing such instruction (e.g. "turn left"instead of "turn right"). In this work, we address a novel task of InteractiveVLN in Continuous Environments (IVLN-CE), which allows the agent to interactwith the user during the VLN-CE navigation to verify any doubts regarding theinstruction errors. We propose an Interactive Instruction Error Detector andLocalizer (I2EDL) that triggers the user-agent interaction upon the detectionof instruction errors during the navigation. We leverage a pre-trained moduleto detect instruction errors and pinpoint them in the instruction bycross-referencing the textual input and past observations. In such way, theagent is able to query the user for a timely correction, without demanding theuser's cognitive load, as we locate the probable errors to a precise part ofthe instruction. We evaluate the proposed I2EDL on a dataset of instructionscontaining errors, and further devise a novel metric, the Success weighted byInteraction Number (SIN), to reflect both the navigation performance and theinteraction effectiveness. We show how the proposed method can ask focusedrequests for corrections to the user, which in turn increases the navigationsuccess, while minimizing the interactions.</description><author>Francesco Taioli, Stefano Rosa, Alberto Castellini, Lorenzo Natale, Alessio Del Bue, Alessandro Farinelli, Marco Cristani, Yiming Wang</author><pubDate>Fri, 07 Jun 2024 17:52:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05080v1</guid></item><item><title>SUMIE: A Synthetic Benchmark for Incremental Entity Summarization</title><link>http://arxiv.org/abs/2406.05079v1</link><description>No existing dataset adequately tests how well language models canincrementally update entity summaries - a crucial ability as these modelsrapidly advance. The Incremental Entity Summarization (IES) task is vital formaintaining accurate, up-to-date knowledge. To address this, we introduceSUMIE, a fully synthetic dataset designed to expose real-world IES challenges.This dataset effectively highlights problems like incorrect entity associationand incomplete information presentation. Unlike common synthetic datasets, ourscaptures the complexity and nuances found in real-world data. We generateinformative and diverse attributes, summaries, and unstructured paragraphs insequence, ensuring high quality. The alignment between generated summaries andparagraphs exceeds 96%, confirming the dataset's quality. Extensive experimentsdemonstrate the dataset's difficulty - state-of-the-art LLMs struggle to updatesummaries with an F1 higher than 80.4%. We will open source the benchmark andthe evaluation metrics to help the community make progress on IES tasks.</description><author>Eunjeong Hwang, Yichao Zhou, Beliz Gunel, James Bradley Wendt, Sandeep Tata</author><pubDate>Fri, 07 Jun 2024 17:49:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05079v1</guid></item><item><title>The Influencer Next Door: How Misinformation Creators Use GenAI</title><link>http://arxiv.org/abs/2405.13554v2</link><description>Advances in generative AI (GenAI) have raised concerns about detecting anddiscerning AI-generated content from human-generated content. Most existingliterature assumes a paradigm where 'expert' organized disinformation creatorsand flawed AI models deceive 'ordinary' users. Based on longitudinalethnographic research with misinformation creators and consumers between2022-2023, we instead find that GenAI supports bricolage work, wherenon-experts increasingly use GenAI to remix, repackage, and (re)produce contentto meet their personal needs and desires. This research yielded four keyfindings: First, participants primarily used GenAI for creation, rather thantruth-seeking. Second, a spreading 'influencer millionaire' narrative droveparticipants to become content creators, using GenAI as a productivity tool togenerate a volume of (often misinformative) content. Third, GenAI lowered thebarrier to entry for content creation across modalities, enticing consumers tobecome creators and significantly increasing existing creators' output.Finally, participants used Gen AI to learn and deploy marketing tactics toexpand engagement and monetize their content. We argue for shifting analysisfrom the public as consumers of AI content to bricoleurs who use GenAIcreatively, often without a detailed understanding of its underlyingtechnology. We analyze how these understudied emergent uses of GenAI producenew or accelerated misinformation harms, and their implications for AIproducts, platforms and policies.</description><author>Amelia Hassoun, Ariel Abonizio, Katy Osborn, Cameron Wu, Beth Goldberg</author><pubDate>Fri, 07 Jun 2024 17:47:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.13554v2</guid></item><item><title>Diving Deep into the Motion Representation of Video-Text Models</title><link>http://arxiv.org/abs/2406.05075v1</link><description>Videos are more informative than images because they capture the dynamics ofthe scene. By representing motion in videos, we can capture dynamic activities.In this work, we introduce GPT-4 generated motion descriptions that capturefine-grained motion descriptions of activities and apply them to three actiondatasets. We evaluated several video-text models on the task of retrieval ofmotion descriptions. We found that they fall far behind human expertperformance on two action datasets, raising the question of whether video-textmodels understand motion in videos. To address it, we introduce a method ofimproving motion understanding in video-text models by utilizing motiondescriptions. This method proves to be effective on two action datasets for themotion description retrieval task. The results draw attention to the need forquality captions involving fine-grained motion information in existing datasetsand demonstrate the effectiveness of the proposed pipeline in understandingfine-grained motion during video-text retrieval.</description><author>Chinmaya Devaraj, Cornelia Fermuller, Yiannis Aloimonos</author><pubDate>Fri, 07 Jun 2024 17:46:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05075v1</guid></item><item><title>Hibou: A Family of Foundational Vision Transformers for Pathology</title><link>http://arxiv.org/abs/2406.05074v1</link><description>Pathology, the microscopic examination of diseased tissue, is critical fordiagnosing various medical conditions, particularly cancers. Traditionalmethods are labor-intensive and prone to human error. Digital pathology, whichconverts glass slides into high-resolution digital images for analysis bycomputer algorithms, revolutionizes the field by enhancing diagnostic accuracy,consistency, and efficiency through automated image analysis and large-scaledata processing. Foundational transformer pretraining is crucial for developingrobust, generalizable models as it enables learning from vast amounts ofunannotated data. This paper introduces the Hibou family of foundational vision transformersfor pathology, leveraging the DINOv2 framework to pretrain two model variants,Hibou-B and Hibou-L, on a proprietary dataset of over 1 million whole slideimages (WSIs) representing diverse tissue types and staining techniques. Ourpretrained models demonstrate superior performance on both patch-level andslide-level benchmarks, surpassing existing state-of-the-art methods. Notably,Hibou-L achieves the highest average accuracy across multiple benchmarkdatasets. To support further research and application in the field, we haveopen-sourced the Hibou-B model, which can be accessed athttps://github.com/HistAI/hibou</description><author>Dmitry Nechaev, Alexey Pchelnikov, Ekaterina Ivanova</author><pubDate>Fri, 07 Jun 2024 17:45:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05074v1</guid></item><item><title>Linearization Turns Neural Operators into Function-Valued Gaussian Processes</title><link>http://arxiv.org/abs/2406.05072v1</link><description>Modeling dynamical systems, e.g. in climate and engineering sciences, oftennecessitates solving partial differential equations. Neural operators are deepneural networks designed to learn nontrivial solution operators of suchdifferential equations from data. As for all statistical models, thepredictions of these models are imperfect and exhibit errors. Such errors areparticularly difficult to spot in the complex nonlinear behaviour of dynamicalsystems. We introduce a new framework for approximate Bayesian uncertaintyquantification in neural operators using function-valued Gaussian processes.Our approach can be interpreted as a probabilistic analogue of the concept ofcurrying from functional programming and provides a practical yet theoreticallysound way to apply the linearized Laplace approximation to neural operators. Ina case study on Fourier neural operators, we show that, even for a discretizedinput, our method yields a Gaussian closure--a structured Gaussian processposterior capturing the uncertainty in the output function of the neuraloperator, which can be evaluated at an arbitrary set of points. The method addsminimal prediction overhead, can be applied post-hoc without retraining theneural operator, and scales to large models and datasets. We showcase theefficacy of our approach through applications to different types of partialdifferential equations.</description><author>Emilia Magnani, Marvin Pförtner, Tobias Weber, Philipp Hennig</author><pubDate>Fri, 07 Jun 2024 17:43:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05072v1</guid></item><item><title>Massively Multiagent Minigames for Training Generalist Agents</title><link>http://arxiv.org/abs/2406.05071v1</link><description>We present Meta MMO, a collection of many-agent minigames for use as areinforcement learning benchmark. Meta MMO is built on top of Neural MMO, amassively multiagent environment that has been the subject of two previousNeurIPS competitions. Our work expands Neural MMO with several computationallyefficient minigames. We explore generalization across Meta MMO by learning toplay several minigames with a single set of weights. We release theenvironment, baselines, and training code under the MIT license. We hope thatMeta MMO will spur additional progress on Neural MMO and, more generally, willserve as a useful benchmark for many-agent generalization.</description><author>Kyoung Whan Choe, Ryan Sullivan, Joseph Suárez</author><pubDate>Fri, 07 Jun 2024 17:41:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05071v1</guid></item><item><title>Classification Metrics for Image Explanations: Towards Building Reliable XAI-Evaluations</title><link>http://arxiv.org/abs/2406.05068v1</link><description>Decision processes of computer vision models - especially deep neuralnetworks - are opaque in nature, meaning that these decisions cannot beunderstood by humans. Thus, over the last years, many methods to providehuman-understandable explanations have been proposed. For image classification,the most common group are saliency methods, which provide (super-)pixelwisefeature attribution scores for input images. But their evaluation still poses aproblem, as their results cannot be simply compared to the unknown groundtruth. To overcome this, a slew of different proxy metrics have been defined,which are - as the explainability methods themselves - often built on intuitionand thus, are possibly unreliable. In this paper, new evaluation metrics forsaliency methods are developed and common saliency methods are benchmarked onImageNet. In addition, a scheme for reliability evaluation of such metrics isproposed that is based on concepts from psychometric testing. The used code canbe found athttps://github.com/lelo204/ClassificationMetricsForImageExplanations .</description><author>Benjamin Fresz, Lena Lörcher, Marco Huber</author><pubDate>Fri, 07 Jun 2024 17:37:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05068v1</guid></item><item><title>Pretraining Decision Transformers with Reward Prediction for In-Context Multi-task Structured Bandit Learning</title><link>http://arxiv.org/abs/2406.05064v1</link><description>In this paper, we study multi-task structured bandit problem where the goalis to learn a near-optimal algorithm that minimizes cumulative regret. Thetasks share a common structure and the algorithm exploits the shared structureto minimize the cumulative regret for an unseen but related test task. We use atransformer as a decision-making algorithm to learn this shared structure so asto generalize to the test task. The prior work of pretrained decisiontransformers like DPT requires access to the optimal action during trainingwhich may be hard in several scenarios. Diverging from these works, ourlearning algorithm does not need the knowledge of optimal action per taskduring training but predicts a reward vector for each of the actions using onlythe observed offline data from the diverse training tasks. Finally, duringinference time, it selects action using the reward predictions employingvarious exploration strategies in-context for an unseen test task. Our modeloutperforms other SOTA methods like DPT, and Algorithmic Distillation over aseries of experiments on several structured bandit problems (linear, bilinear,latent, non-linear). Interestingly, we show that our algorithm, without theknowledge of the underlying problem structure, can learn a near-optimal policyin-context by leveraging the shared structure across diverse tasks. We furtherextend the field of pre-trained decision transformers by showing that they canleverage unseen tasks with new actions and still learn the underlying latentstructure to derive a near-optimal policy. We validate this over severalexperiments to show that our proposed solution is very general and has wideapplications to potentially emergent online and offline strategies at testtime. Finally, we theoretically analyze the performance of our algorithm andobtain generalization bounds in the in-context multi-task learning setting.</description><author>Subhojyoti Mukherjee, Josiah P. Hanna, Qiaomin Xie, Robert Nowak</author><pubDate>Fri, 07 Jun 2024 17:34:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05064v1</guid></item><item><title>Are Large Language Models More Empathetic than Humans?</title><link>http://arxiv.org/abs/2406.05063v1</link><description>With the emergence of large language models (LLMs), investigating if they cansurpass humans in areas such as emotion recognition and empathetic respondinghas become a focal point of research. This paper presents a comprehensive studyexploring the empathetic responding capabilities of four state-of-the-art LLMs:GPT-4, LLaMA-2-70B-Chat, Gemini-1.0-Pro, and Mixtral-8x7B-Instruct incomparison to a human baseline. We engaged 1,000 participants in abetween-subjects user study, assessing the empathetic quality of responsesgenerated by humans and the four LLMs to 2,000 emotional dialogue promptsmeticulously selected to cover a broad spectrum of 32 distinct positive andnegative emotions. Our findings reveal a statistically significant superiorityof the empathetic responding capability of LLMs over humans. GPT-4 emerged asthe most empathetic, marking approximately 31% increase in responses rated as"Good" compared to the human benchmark. It was followed by LLaMA-2,Mixtral-8x7B, and Gemini-Pro, which showed increases of approximately 24%, 21%,and 10% in "Good" ratings, respectively. We further analyzed the responseratings at a finer granularity and discovered that some LLMs are significantlybetter at responding to specific emotions compared to others. The suggestedevaluation framework offers a scalable and adaptable approach for assessing theempathy of new LLMs, avoiding the need to replicate this study's findings infuture research.</description><author>Anuradha Welivita, Pearl Pu</author><pubDate>Fri, 07 Jun 2024 17:33:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05063v1</guid></item><item><title>Progressive Entropic Optimal Transport Solvers</title><link>http://arxiv.org/abs/2406.05061v1</link><description>Optimal transport (OT) has profoundly impacted machine learning by providingtheoretical and computational tools to realign datasets. In this context, giventwo large point clouds of sizes $n$ and $m$ in $\mathbb{R}^d$, entropic OT(EOT) solvers have emerged as the most reliable tool to either solve theKantorovich problem and output a $n\times m$ coupling matrix, or to solve theMonge problem and learn a vector-valued push-forward map. While the robustnessof EOT couplings/maps makes them a go-to choice in practical applications, EOTsolvers remain difficult to tune because of a small but influential set ofhyperparameters, notably the omnipresent entropic regularization strength$\varepsilon$. Setting $\varepsilon$ can be difficult, as it simultaneouslyimpacts various performance metrics, such as compute speed, statisticalperformance, generalization, and bias. In this work, we propose a new class ofEOT solvers (ProgOT), that can estimate both plans and transport maps. We takeadvantage of several opportunities to optimize the computation of EOT solutionsby dividing mass displacement using a time discretization, borrowinginspiration from dynamic OT formulations, and conquering each of these stepsusing EOT with properly scheduled parameters. We provide experimental evidencedemonstrating that ProgOT is a faster and more robust alternative to standardsolvers when computing couplings at large scales, even outperforming neuralnetwork-based approaches. We also prove statistical consistency of our approachfor estimating optimal transport maps.</description><author>Parnian Kassraie, Aram-Alexandre Pooladian, Michal Klein, James Thornton, Jonathan Niles-Weed, Marco Cuturi</author><pubDate>Fri, 07 Jun 2024 17:33:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05061v1</guid></item><item><title>GenHeld: Generating and Editing Handheld Objects</title><link>http://arxiv.org/abs/2406.05059v1</link><description>Grasping is an important human activity that has long been studied inrobotics, computer vision, and cognitive science. Most existing works studygrasping from the perspective of synthesizing hand poses conditioned on 3D or2D object representations. We propose GenHeld to address the inverse problem ofsynthesizing held objects conditioned on 3D hand model or 2D image. Given a 3Dmodel of hand, GenHeld 3D can select a plausible held object from a largedataset using compact object representations called object codes.The selectedobject is then positioned and oriented to form a plausible grasp withoutchanging hand pose. If only a 2D hand image is available, GenHeld 2D can editthis image to add or replace a held object. GenHeld 2D operates by combiningthe abilities of GenHeld 3D with diffusion-based image editing. Results andexperiments show that we outperform baselines and can generate plausible heldobjects in both 2D and 3D. Our experiments demonstrate that our method achieveshigh quality and plausibility of held object synthesis in both 3D and 2D.</description><author>Chaerin Min, Srinath Sridhar</author><pubDate>Fri, 07 Jun 2024 17:31:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05059v1</guid></item><item><title>GeoGen: Geometry-Aware Generative Modeling via Signed Distance Functions</title><link>http://arxiv.org/abs/2406.04254v2</link><description>We introduce a new generative approach for synthesizing 3D geometry andimages from single-view collections. Most existing approaches predictvolumetric density to render multi-view consistent images. By employingvolumetric rendering using neural radiance fields, they inherit a keylimitation: the generated geometry is noisy and unconstrained, limiting thequality and utility of the output meshes. To address this issue, we proposeGeoGen, a new SDF-based 3D generative model trained in an end-to-end manner.Initially, we reinterpret the volumetric density as a Signed Distance Function(SDF). This allows us to introduce useful priors to generate valid meshes.However, those priors prevent the generative model from learning details,limiting the applicability of the method to real-world scenarios. To alleviatethat problem, we make the transformation learnable and constrain the rendereddepth map to be consistent with the zero-level set of the SDF. Through the lensof adversarial training, we encourage the network to produce higher fidelitydetails on the output meshes. For evaluation, we introduce a synthetic datasetof human avatars captured from 360-degree camera angles, to overcome thechallenges presented by real-world datasets, which often lack 3D consistencyand do not cover all camera angles. Our experiments on multiple datasets showthat GeoGen produces visually and quantitatively better geometry than theprevious generative models based on neural radiance fields.</description><author>Salvatore Esposito, Qingshan Xu, Kacper Kania, Charlie Hewitt, Octave Mariotti, Lohit Petikam, Julien Valentin, Arno Onken, Oisin Mac Aodha</author><pubDate>Fri, 07 Jun 2024 17:28:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04254v2</guid></item><item><title>Cross-Domain Synthetic-to-Real In-the-Wild Depth and Normal Estimation for 3D Scene Understanding</title><link>http://arxiv.org/abs/2212.05040v3</link><description>We present a cross-domain inference technique that learns from synthetic datato estimate depth and normals for in-the-wild omnidirectional 3D scenesencountered in real-world uncontrolled settings. To this end, we introduceUBotNet, an architecture that combines UNet and Bottleneck Transformer elementsto predict consistent scene normals and depth. We also introduce theOmniHorizon synthetic dataset containing 24,335 omnidirectional images thatrepresent a wide variety of outdoor environments, including buildings, streets,and diverse vegetation. This dataset is generated from expansive, lifelikevirtual spaces and encompasses dynamic scene elements, such as changinglighting conditions, different times of day, pedestrians, and vehicles. Ourexperiments show that UBotNet achieves significantly improved accuracy in depthestimation and normal estimation compared to existing models. Lastly, wevalidate cross-domain synthetic-to-real depth and normal estimation on realoutdoor images using UBotNet trained solely on our synthetic OmniHorizondataset, demonstrating the potential of both the synthetic dataset and theproposed network for real-world scene understanding applications.</description><author>Jay Bhanushali, Manivannan Muniyandi, Praneeth Chakravarthula</author><pubDate>Fri, 07 Jun 2024 17:26:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.05040v3</guid></item><item><title>Robustness Assessment of Mathematical Reasoning in the Presence of Missing and Contradictory Conditions</title><link>http://arxiv.org/abs/2406.05055v1</link><description>Large language models (LLMs) have demonstrated impressive performance onreasoning tasks, which can be further improved through few-shot promptingtechniques. However, the current evaluation primarily focuses on carefullyconstructed benchmarks and neglects the consideration of real-world reasoningproblems that present missing and contradictory conditions, known asill-defined problems. Our observations suggest that existing few-shot promptingtechniques are ineffective in such scenarios, often providing overconfidentanswers or hallucination. To further study this problem, we develop a benchmarkcalled Problems with Missing and Contradictory conditions (PMC) and introducetwo novel metrics to evaluate the performance of few-shot prompting methods inthese scenarios. Our analysis using the PMC benchmark reveals a trade-offdilemma between the performance of mathematical reasoning for well-definedproblems and the ability to recognize ill-defined problems. To address thechallenges posed by PMC, we propose a novel few-shot prompting method calledSMT-LIB Prompting (SLP), which utilizes the SMT-LIB language to model theproblems instead of solving them directly. Subsequently, a double-check solvingstrategy checks the satisfiability and uniqueness of the solution and providesfinal feedback. Extensive experiments demonstrate the superiority of our SLPapproach compared to existing few-shot prompting methods when dealing withproblems with missing and contradictory conditions. We will open-source ourbenchmark and code to facilitate future research.</description><author>Shi-Yu Tian, Zhi Zhou, Lin-Han Jia, Lan-Zhe Guo, Yu-Feng Li</author><pubDate>Fri, 07 Jun 2024 17:24:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05055v1</guid></item><item><title>Prototype Correlation Matching and Class-Relation Reasoning for Few-Shot Medical Image Segmentation</title><link>http://arxiv.org/abs/2406.05054v1</link><description>Few-shot medical image segmentation has achieved great progress in improvingaccuracy and efficiency of medical analysis in the biomedical imaging field.However, most existing methods cannot explore inter-class relations among baseand novel medical classes to reason unseen novel classes. Moreover, the samekind of medical class has large intra-class variations brought by diverseappearances, shapes and scales, thus causing ambiguous visual characterizationto degrade generalization performance of these existing methods on unseen novelclasses. To address the above challenges, in this paper, we propose a\underline{\textbf{P}}rototype correlation \underline{\textbf{M}}atching and\underline{\textbf{C}}lass-relation \underline{\textbf{R}}easoning (i.e.,\textbf{PMCR}) model. The proposed model can effectively mitigate false pixelcorrelation matches caused by large intra-class variations while reasoninginter-class relations among different medical classes. Specifically, in orderto address false pixel correlation match brought by large intra-classvariations, we propose a prototype correlation matching module to minerepresentative prototypes that can characterize diverse visual information ofdifferent appearances well. We aim to explore prototype-level rather thanpixel-level correlation matching between support and query features via optimaltransport algorithm to tackle false matches caused by intra-class variations.Meanwhile, in order to explore inter-class relations, we design aclass-relation reasoning module to segment unseen novel medical objects viareasoning inter-class relations between base and novel classes. Suchinter-class relations can be well propagated to semantic encoding of localquery features to improve few-shot segmentation performance. Quantitativecomparisons illustrates the large performance improvement of our model overother baseline methods.</description><author>Yumin Zhang, Hongliu Li, Yajun Gao, Haoran Duan, Yawen Huang, Yefeng Zheng</author><pubDate>Fri, 07 Jun 2024 17:23:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05054v1</guid></item><item><title>Hints-In-Browser: Benchmarking Language Models for Programming Feedback Generation</title><link>http://arxiv.org/abs/2406.05053v1</link><description>Generative AI and large language models hold great promise in enhancingprogramming education by generating individualized feedback and hints forlearners. Recent works have primarily focused on improving the quality ofgenerated feedback to achieve human tutors' quality. While quality is animportant performance criterion, it is not the only criterion to optimize forreal-world educational deployments. In this paper, we benchmark language modelsfor programming feedback generation across several performance criteria,including quality, cost, time, and data privacy. The key idea is to leveragerecent advances in the new paradigm of in-browser inference that allow runningthese models directly in the browser, thereby providing direct benefits acrosscost and data privacy. To boost the feedback quality of small models compatiblewith in-browser inference engines, we develop a fine-tuning pipeline based onGPT-4 generated synthetic data. We showcase the efficacy of fine-tunedLlama3-8B and Phi3-3.8B 4-bit quantized models using WebLLM's in-browserinference engine on three different Python programming datasets. We willrelease the full implementation along with a web app and datasets to facilitatefurther research on in-browser language models.</description><author>Nachiket Kotalwar, Alkis Gotovos, Adish Singla</author><pubDate>Fri, 07 Jun 2024 17:22:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05053v1</guid></item><item><title>A Tensor Decomposition Perspective on Second-order RNNs</title><link>http://arxiv.org/abs/2406.05045v1</link><description>Second-order Recurrent Neural Networks (2RNNs) extend RNNs by leveragingsecond-order interactions for sequence modelling. These models are provablymore expressive than their first-order counterparts and have connections towell-studied models from formal language theory. However, their large parametertensor makes computations intractable. To circumvent this issue, one approachknown as MIRNN consists in limiting the type of interactions used by the model.Another is to leverage tensor decomposition to diminish the parameter count. Inthis work, we study the model resulting from parameterizing 2RNNs using the CPdecomposition, which we call CPRNN. Intuitively, the rank of the decompositionshould reduce expressivity. We analyze how rank and hidden size affect modelcapacity and show the relationships between RNNs, 2RNNs, MIRNNs, and CPRNNsbased on these parameters. We support these results empirically withexperiments on the Penn Treebank dataset which demonstrate that, with a fixedparameter budget, CPRNNs outperforms RNNs, 2RNNs, and MIRNNs with the rightchoice of rank and hidden size.</description><author>Maude Lizaire, Michael Rizvi-Martel, Marawan Gamal Abdel Hameed, Guillaume Rabusseau</author><pubDate>Fri, 07 Jun 2024 17:18:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05045v1</guid></item><item><title>AudioSetMix: Enhancing Audio-Language Datasets with LLM-Assisted Augmentations</title><link>http://arxiv.org/abs/2405.11093v2</link><description>Multi-modal learning in the audio-language domain has seen significantadvancements in recent years. However, audio-language learning faces challengesdue to limited and lower-quality data compared to image-language tasks.Existing audio-language datasets are notably smaller, and manual labeling ishindered by the need to listen to entire audio clips for accurate labeling. Our method systematically generates audio-caption pairs by augmenting audioclips with natural language labels and corresponding audio signal processingoperations. Leveraging a Large Language Model, we generate descriptions ofaugmented audio clips with a prompt template. This scalable method producesAudioSetMix, a high-quality training dataset for text-and-audio related models. Integration of our dataset improves models performance on benchmarks byproviding diversified and better-aligned examples. Notably, our datasetaddresses the absence of modifiers (adjectives and adverbs) in existingdatasets. By enabling models to learn these concepts, and generating hardnegative examples during training, we achieve state-of-the-art performance onmultiple benchmarks.</description><author>David Xu</author><pubDate>Fri, 07 Jun 2024 17:15:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11093v2</guid></item><item><title>Online Frequency Scheduling by Learning Parallel Actions</title><link>http://arxiv.org/abs/2406.05041v1</link><description>Radio Resource Management is a challenging topic in future 6G networks wherenovel applications create strong competition among the users for the availableresources. In this work we consider the frequency scheduling problem in amulti-user MIMO system. Frequency resources need to be assigned to a set ofusers while allowing for concurrent transmissions in the same sub-band.Traditional methods are insufficient to cope with all the involved constraintsand uncertainties, whereas reinforcement learning can directly learnnear-optimal solutions for such complex environments. However, the schedulingproblem has an enormous action space accounting for all the combinations ofusers and sub-bands, so out-of-the-box algorithms cannot be used directly. Inthis work, we propose a scheduler based on action-branching over sub-bands,which is a deep Q-learning architecture with parallel decision capabilities.The sub-bands learn correlated but local decision policies and altogether theyoptimize a global reward. To improve the scaling of the architecture with thenumber of sub-bands, we propose variations (Unibranch, Graph NeuralNetwork-based) that reduce the number of parameters to learn. The paralleldecision making of the proposed architecture allows to meet short inferencetime requirements in real systems. Furthermore, the deep Q-learning approachpermits online fine-tuning after deployment to bridge the sim-to-real gap. Theproposed architectures are evaluated against relevant baselines from theliterature showing competitive performance and possibilities of onlineadaptation to evolving environments.</description><author>Anastasios Giovanidis, Mathieu Leconte, Sabrine Aroua, Tor Kvernvik, David Sandberg</author><pubDate>Fri, 07 Jun 2024 17:14:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05041v1</guid></item><item><title>Hypernetworks for Personalizing ASR to Atypical Speech</title><link>http://arxiv.org/abs/2406.04240v2</link><description>Parameter-efficient fine-tuning (PEFT) for personalizing automatic speechrecognition (ASR) has recently shown promise for adapting general populationmodels to atypical speech. However, these approaches assume a priori knowledgeof the atypical speech disorder being adapted for -- the diagnosis of whichrequires expert knowledge that is not always available. Even given thisknowledge, data scarcity and high inter/intra-speaker variability further limitthe effectiveness of traditional fine-tuning. To circumvent these challenges,we first identify the minimal set of model parameters required for ASRadaptation. Our analysis of each individual parameter's effect on adaptationperformance allows us to reduce Word Error Rate (WER) by half while adapting0.03% of all weights. Alleviating the need for cohort-specific models, we nextpropose the novel use of a meta-learned hypernetwork to generate highlyindividualized, utterance-level adaptations on-the-fly for a diverse set ofatypical speech characteristics. Evaluating adaptation at the global, cohortand individual-level, we show that hypernetworks generalize better toout-of-distribution speakers, while maintaining an overall relative WERreduction of 75.2% using 0.1% of the full parameter budget.</description><author>Max Mueller-Eberstein, Dianna Yee, Karren Yang, Gautam Varma Mantena, Colin Lea</author><pubDate>Fri, 07 Jun 2024 17:14:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04240v2</guid></item><item><title>Lean Workbook: A large-scale Lean problem set formalized from natural language math problems</title><link>http://arxiv.org/abs/2406.03847v2</link><description>Large language models have demonstrated impressive capabilities acrossvarious natural language processing tasks, especially in solving mathematicalproblems. However, large language models are not good at math theorem provingusing formal languages like Lean. A significant challenge in this area is thescarcity of training data available in these formal languages. To address thisissue, we propose a novel pipeline that iteratively generates and filterssynthetic data to translate natural language mathematical problems into Lean 4statements, and vice versa. Our results indicate that the synthetic datapipeline can provide useful training data and improve the performance of LLMsin translating and understanding complex mathematical problems and proofs. Ourfinal dataset contains about 57K formal-informal question pairs along withsearched proof from the math contest forum and 21 new IMO questions. Weopen-source our code at https://github.com/InternLM/InternLM-Math and our dataat https://huggingface.co/datasets/InternLM/Lean-Workbook.</description><author>Huaiyuan Ying, Zijian Wu, Yihan Geng, Jiayu Wang, Dahua Lin, Kai Chen</author><pubDate>Fri, 07 Jun 2024 17:12:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03847v2</guid></item><item><title>From Stream to Pool: Pricing Under the Law of Diminishing Marginal Utility</title><link>http://arxiv.org/abs/2310.19220v3</link><description>Dynamic pricing models often posit that a $\textbf{stream}$ of customerinteractions occur sequentially, where customers' valuations are drawnindependently. However, this model is not entirely reflective of the realworld, as it overlooks a critical aspect, the law of diminishing marginalutility, which states that a customer's marginal utility from each additionalunit declines. This causes the valuation distribution to shift towards thelower end, which is not captured by the stream model. This motivates us tostudy a pool-based model, where a $\textbf{pool}$ of customers repeatedlyinteracts with a monopolist seller, each of whose valuation diminishes in thenumber of purchases made according to a discount function. In particular, whenthe discount function is constant, our pool model recovers the stream model. Wefocus on the most fundamental special case, where a customer's valuationbecomes zero once a purchase is made. Given $k$ prices, we present anon-adaptive, detail-free (i.e., does not "know" the valuations) policy thatachieves a $1/k$ competitive ratio, which is optimal among non-adaptivepolicies. Furthermore, based on a novel debiasing technique, we propose anadaptive learn-then-earn policy with a $\tilde O(k^{2/3} n^{2/3})$ regret.</description><author>Titing Cui, Su Jia, Thomas Lavastida</author><pubDate>Fri, 07 Jun 2024 17:09:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19220v3</guid></item><item><title>Branch-Solve-Merge Improves Large Language Model Evaluation and Generation</title><link>http://arxiv.org/abs/2310.15123v2</link><description>Large Language Models (LLMs) are frequently used for multi-faceted languagegeneration and evaluation tasks that involve satisfying intricate userconstraints or taking into account multiple aspects and criteria. However,their performance can fall short, due to the model's lack of coherence andinability to plan and decompose the problem. We propose Branch-Solve-Merge(BSM), a Large Language Model program (Schlag et al., 2023) for tackling suchchallenging natural language tasks. It consists of branch, solve, and mergemodules that are parameterized with specific prompts to the base LLM. Thesethree modules plan a decomposition of the task into multiple parallelsub-tasks, independently solve them, and fuse the solutions to the sub-tasks.We apply our method to the tasks of LLM response evaluation and constrainedtext generation and evaluate its effectiveness with multiple LLMs, includingVicuna, LLaMA-2-chat, and GPT-4. BSM improves the evaluation correctness andconsistency for each LLM by enhancing human-LLM agreement by up to 26%,reducing length and pairwise position biases by up to 50%, and allowingLLaMA2-chat to match or outperform GPT-4 on most domains. On a constraint storygeneration task, BSM improves the coherence of stories while also improvingconstraint satisfaction by 12%.</description><author>Swarnadeep Saha, Omer Levy, Asli Celikyilmaz, Mohit Bansal, Jason Weston, Xian Li</author><pubDate>Fri, 07 Jun 2024 17:08:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15123v2</guid></item><item><title>Learning mirror maps in policy mirror descent</title><link>http://arxiv.org/abs/2402.05187v2</link><description>Policy Mirror Descent (PMD) is a popular framework in reinforcement learning,serving as a unifying perspective that encompasses numerous algorithms. Thesealgorithms are derived through the selection of a mirror map and enjoyfinite-time convergence guarantees. Despite its popularity, the exploration ofPMD's full potential is limited, with the majority of research focusing on aparticular mirror map -- namely, the negative entropy -- which gives rise tothe renowned Natural Policy Gradient (NPG) method. It remains uncertain fromexisting theoretical studies whether the choice of mirror map significantlyinfluences PMD's efficacy. In our work, we conduct empirical investigations toshow that the conventional mirror map choice (NPG) often yieldsless-than-optimal outcomes across several standard benchmark environments.Using evolutionary strategies, we identify more efficient mirror maps thatenhance the performance of PMD. We first focus on a tabular environment, i.e.Grid-World, where we relate existing theoretical bounds with the performance ofPMD for a few standard mirror maps and the learned one. We then show that it ispossible to learn a mirror map that outperforms the negative entropy in morecomplex environments, such as the MinAtar suite. Our results suggest thatmirror maps generalize well across various environments, raising questionsabout how to best match a mirror map to an environment's structure andcharacteristics.</description><author>Carlo Alfano, Sebastian Towers, Silvia Sapora, Chris Lu, Patrick Rebeschini</author><pubDate>Fri, 07 Jun 2024 17:08:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05187v2</guid></item><item><title>Bootstrapping Referring Multi-Object Tracking</title><link>http://arxiv.org/abs/2406.05039v1</link><description>Referring multi-object tracking (RMOT) aims at detecting and trackingmultiple objects following human instruction represented by a natural languageexpression. Existing RMOT benchmarks are usually formulated through manualannotations, integrated with static regulations. This approach results in adearth of notable diversity and a constrained scope of implementation. In thiswork, our key idea is to bootstrap the task of referring multi-object trackingby introducing discriminative language words as much as possible. In specific,we first develop Refer-KITTI into a large-scale dataset, named Refer-KITTI-V2.It starts with 2,719 manual annotations, addressing the issue of classimbalance and introducing more keywords to make it closer to real-worldscenarios compared to Refer-KITTI. They are further expanded to a total of9,758 annotations by prompting large language models, which create 617different words, surpassing previous RMOT benchmarks. In addition, theend-to-end framework in RMOT is also bootstrapped by a simple yet eleganttemporal advancement strategy, which achieves better performance than previousapproaches. The source code and dataset is available athttps://github.com/zyn213/TempRMOT.</description><author>Yani Zhang, Dongming Wu, Wencheng Han, Xingping Dong</author><pubDate>Fri, 07 Jun 2024 17:02:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05039v1</guid></item><item><title>VITON-DiT: Learning In-the-Wild Video Try-On from Human Dance Videos via Diffusion Transformers</title><link>http://arxiv.org/abs/2405.18326v2</link><description>Video try-on stands as a promising area for its tremendous real-worldpotential. Prior works are limited to transferring product clothing images ontoperson videos with simple poses and backgrounds, while underperforming oncasually captured videos. Recently, Sora revealed the scalability of DiffusionTransformer (DiT) in generating lifelike videos featuring real-world scenarios.Inspired by this, we explore and propose the first DiT-based video try-onframework for practical in-the-wild applications, named VITON-DiT.Specifically, VITON-DiT consists of a garment extractor, a Spatial-Temporaldenoising DiT, and an identity preservation ControlNet. To faithfully recoverthe clothing details, the extracted garment features are fused with theself-attention outputs of the denoising DiT and the ControlNet. We alsointroduce novel random selection strategies during training and an InterpolatedAuto-Regressive (IAR) technique at inference to facilitate long videogeneration. Unlike existing attempts that require the laborious and restrictiveconstruction of a paired training dataset, severely limiting their scalability,VITON-DiT alleviates this by relying solely on unpaired human dance videos anda carefully designed multi-stage training strategy. Furthermore, we curate achallenging benchmark dataset to evaluate the performance of casual videotry-on. Extensive experiments demonstrate the superiority of VITON-DiT ingenerating spatio-temporal consistent try-on results for in-the-wild videoswith complicated human poses.</description><author>Jun Zheng, Fuwei Zhao, Youjiang Xu, Xin Dong, Xiaodan Liang</author><pubDate>Fri, 07 Jun 2024 17:02:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18326v2</guid></item><item><title>Efficient 3D Shape Generation via Diffusion Mamba with Bidirectional SSMs</title><link>http://arxiv.org/abs/2406.05038v1</link><description>Recent advancements in sequence modeling have led to the development of theMamba architecture, noted for its selective state space approach, offering apromising avenue for efficient long sequence handling. However, its applicationin 3D shape generation, particularly at high resolutions, remainsunderexplored. Traditional diffusion transformers (DiT) with self-attentionmechanisms, despite their potential, face scalability challenges due to thecubic complexity of attention operations as input length increases. Thiscomplexity becomes a significant hurdle when dealing with high-resolution voxelsizes. To address this challenge, we introduce a novel diffusion architecturetailored for 3D point clouds generation-Diffusion Mamba (DiM-3D). Thisarchitecture forgoes traditional attention mechanisms, instead utilizing theinherent efficiency of the Mamba architecture to maintain linear complexitywith respect to sequence length. DiM-3D is characterized by fast inferencetimes and substantially lower computational demands, quantified in reducedGflops, thereby addressing the key scalability issues of prior models. Ourempirical results on the ShapeNet benchmark demonstrate that DiM-3D achievesstate-of-the-art performance in generating high-fidelity and diverse 3D shapes.Additionally, DiM-3D shows superior capabilities in tasks like 3D point cloudcompletion. This not only proves the model's scalability but also underscoresits efficiency in generating detailed, high-resolution voxels necessary foradvanced 3D shape modeling, particularly excelling in environments requiringhigh-resolution voxel sizes. Through these findings, we illustrate theexceptional scalability and efficiency of the Diffusion Mamba framework in 3Dshape generation, setting a new standard for the field and paving the way forfuture explorations in high-resolution 3D modeling technologies.</description><author>Shentong Mo</author><pubDate>Fri, 07 Jun 2024 17:02:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05038v1</guid></item><item><title>TimeSieve: Extracting Temporal Dynamics through Information Bottlenecks</title><link>http://arxiv.org/abs/2406.05036v1</link><description>Time series forecasting has become an increasingly popular research area dueto its critical applications in various real-world domains such as trafficmanagement, weather prediction, and financial analysis. Despite significantadvancements, existing models face notable challenges, including the necessityof manual hyperparameter tuning for different datasets, and difficulty ineffectively distinguishing signal from redundant features in data characterizedby strong seasonality. These issues hinder the generalization and practicalapplication of time series forecasting models. To solve this issues, we proposean innovative time series forecasting model TimeSieve designed to address thesechallenges. Our approach employs wavelet transforms to preprocess time seriesdata, effectively capturing multi-scale features without the need foradditional parameters or manual hyperparameter tuning. Additionally, weintroduce the information bottleneck theory that filters out redundant featuresfrom both detail and approximation coefficients, retaining only the mostpredictive information. This combination reduces significantly improves themodel's accuracy. Extensive experiments demonstrate that our model outperformsexisting state-of-the-art methods on 70\% of the datasets, achieving higherpredictive accuracy and better generalization across diverse datasets. Ourresults validate the effectiveness of our approach in addressing the keychallenges in time series forecasting, paving the way for more reliable andefficient predictive models in practical applications. The code for our modelis available at https://github.com/xll0328/TimeSieve.</description><author>Ninghui Feng, Songning Lai, Fobao Zhou, Zhenxiao Yin, Hang Zhao</author><pubDate>Fri, 07 Jun 2024 16:58:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05036v1</guid></item><item><title>Scenarios and Approaches for Situated Natural Language Explanations</title><link>http://arxiv.org/abs/2406.05035v1</link><description>Large language models (LLMs) can be used to generate natural languageexplanations (NLE) that are adapted to different users' situations. However,there is yet to be a quantitative evaluation of the extent of such adaptation.To bridge this gap, we collect a benchmarking dataset, Situation-BasedExplanation. This dataset contains 100 explanandums. Each explanandum is pairedwith explanations targeted at three distinct audience types-such as educators,students, and professionals-enabling us to assess how well the explanationsmeet the specific informational needs and contexts of these diverse groups e.g.students, teachers, and parents. For each "explanandum paired with an audience"situation, we include a human-written explanation. These allow us to computescores that quantify how the LLMs adapt the explanations to the situations. Onan array of pretrained language models with varying sizes, we examine threecategories of prompting methods: rule-based prompting, meta-prompting, andin-context learning prompting. We find that 1) language models can generateprompts that result in explanations more precisely aligned with the targetsituations, 2) explicitly modeling an "assistant" persona by prompting "You area helpful assistant..." is not a necessary prompt technique for situated NLEtasks, and 3) the in-context learning prompts only can help LLMs learn thedemonstration template but can't improve their inference performance. SBE andour analysis facilitate future research towards generating situated naturallanguage explanations.</description><author>Pengshuo Qiu, Frank Rudzicz, Zining Zhu</author><pubDate>Fri, 07 Jun 2024 16:56:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05035v1</guid></item><item><title>Data-Driven Observability Analysis for Nonlinear Stochastic Systems</title><link>http://arxiv.org/abs/2302.11979v2</link><description>Distinguishability and, by extension, observability are key properties ofdynamical systems. Establishing these properties is challenging, especiallywhen no analytical model is available and they are to be inferred directly frommeasurement data. The presence of noise further complicates this analysis, asstandard notions of distinguishability are tailored to deterministic systems.We build on distributional distinguishability, which extends the deterministicnotion by comparing distributions of outputs of stochastic systems. We firstshow that both concepts are equivalent for a class of systems that includeslinear systems. We then present a method to assess and quantify distributionaldistinguishability from output data. Specifically, our quantification measureshow much data is required to tell apart two initial states, inducing acontinuous spectrum of distinguishability. We propose a statistical test todetermine a threshold above which two states can be considered distinguishablewith high confidence. We illustrate these tools by computing distinguishabilitymaps over the state space in simulation, then leverage the test to comparesensor configurations on hardware.</description><author>Pierre-François Massiani, Mona Buisson-Fenet, Friedrich Solowjow, Florent Di Meglio, Sebastian Trimpe</author><pubDate>Fri, 07 Jun 2024 16:54:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.11979v2</guid></item><item><title>Gradient Descent on Logistic Regression with Non-Separable Data and Large Step Sizes</title><link>http://arxiv.org/abs/2406.05033v1</link><description>We study gradient descent (GD) dynamics on logistic regression problems withlarge, constant step sizes. For linearly-separable data, it is known that GDconverges to the minimizer with arbitrarily large step sizes, a property whichno longer holds when the problem is not separable. In fact, the behaviour canbe much more complex -- a sequence of period-doubling bifurcations begins atthe critical step size $2/\lambda$, where $\lambda$ is the largest eigenvalueof the Hessian at the solution. Using a smaller-than-critical step sizeguarantees convergence if initialized nearby the solution: but does thissuffice globally? In one dimension, we show that a step size less than$1/\lambda$ suffices for global convergence. However, for all step sizesbetween $1/\lambda$ and the critical step size $2/\lambda$, one can construct adataset such that GD converges to a stable cycle. In higher dimensions, this isactually possible even for step sizes less than $1/\lambda$. Our results showthat although local convergence is guaranteed for all step sizes less than thecritical step size, global convergence is not, and GD may instead converge to acycle depending on the initialization.</description><author>Si Yi Meng, Antonio Orvieto, Daniel Yiming Cao, Christopher De Sa</author><pubDate>Fri, 07 Jun 2024 16:53:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05033v1</guid></item><item><title>How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition</title><link>http://arxiv.org/abs/2310.05492v4</link><description>Large language models (LLMs) with enormous pre-training tokens and parametersemerge diverse abilities, including math reasoning, code generation, andinstruction following. These abilities are further enhanced by supervisedfine-tuning (SFT). While the open-source community has explored ad-hoc SFT forenhancing individual capabilities, proprietary LLMs exhibit versatility acrossvarious skills. Therefore, understanding the facilitation of multiple abilitiesvia SFT is paramount. In this study, we specifically focuses on the interplayof data composition between mathematical reasoning, code generation, andgeneral human-aligning abilities during SFT. We propose four intriguingresearch questions to explore the association between model performance andvarious factors including data amount, composition ratio, model size and SFTstrategies. Our experiments reveal that distinct capabilities scale differentlyand larger models generally show superior performance with same amount of data.Mathematical reasoning and code generation consistently improve with increasingdata amount, whereas general abilities plateau after roughly a thousandsamples. Moreover, we observe data composition appears to enhance variousabilities under limited data conditions, yet can lead to performance conflictswhen data is plentiful. Our findings also suggest the amount of compositiondata influences performance more than the composition ratio. In analysis of SFTstrategies, we find that sequentially learning multiple skills riskscatastrophic forgetting. Our proposed Dual-stage Mixed Fine-tuning (DMT)strategy offers a promising solution to learn multiple abilities with differentscaling patterns.</description><author>Guanting Dong, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, Jingren Zhou</author><pubDate>Fri, 07 Jun 2024 16:51:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05492v4</guid></item><item><title>AGALE: A Graph-Aware Continual Learning Evaluation Framework</title><link>http://arxiv.org/abs/2406.01229v2</link><description>In recent years, continual learning (CL) techniques have made significantprogress in learning from streaming data while preserving knowledge acrosssequential tasks, particularly in the realm of euclidean data. To foster fairevaluation and recognize challenges in CL settings, several evaluationframeworks have been proposed, focusing mainly on the single- and multi-labelclassification task on euclidean data. However, these evaluation frameworks arenot trivially applicable when the input data is graph-structured, as they donot consider the topological structure inherent in graphs. Existing continualgraph learning (CGL) evaluation frameworks have predominantly focussed onsingle-label scenarios in the node classification (NC) task. This focus hasoverlooked the complexities of multi-label scenarios, where nodes may exhibitaffiliations with multiple labels, simultaneously participating in multipletasks. We develop a graph-aware evaluation (\agale) framework that accommodatesboth single-labeled and multi-labeled nodes, addressing the limitations ofprevious evaluation frameworks. In particular, we define new incrementalsettings and devise data partitioning algorithms tailored to CGL datasets. Weperform extensive experiments comparing methods from the domains of continuallearning, continual graph learning, and dynamic graph learning (DGL). Wetheoretically analyze \agale and provide new insights about the role ofhomophily in the performance of compared methods. We release our framework athttps://github.com/Tianqi-py/AGALE.</description><author>Tianqi Zhao, Alan Hanjalic, Megha Khosla</author><pubDate>Fri, 07 Jun 2024 16:50:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01229v2</guid></item><item><title>Optimizing Automatic Differentiation with Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2406.05027v1</link><description>Computing Jacobians with automatic differentiation is ubiquitous in manyscientific domains such as machine learning, computational fluid dynamics,robotics and finance. Even small savings in the number of computations ormemory usage in Jacobian computations can already incur massive savings inenergy consumption and runtime. While there exist many methods that allow forsuch savings, they generally trade computational efficiency for approximationsof the exact Jacobian. In this paper, we present a novel method to optimize thenumber of necessary multiplications for Jacobian computation by leveraging deepreinforcement learning (RL) and a concept called cross-country eliminationwhile still computing the exact Jacobian. Cross-country elimination is aframework for automatic differentiation that phrases Jacobian accumulation asordered elimination of all vertices on the computational graph where everyelimination incurs a certain computational cost. We formulate the search forthe optimal elimination order that minimizes the number of necessarymultiplications as a single player game which is played by an RL agent. Wedemonstrate that this method achieves up to 33% improvements overstate-of-the-art methods on several relevant tasks taken from diverse domains.Furthermore, we show that these theoretical gains translate into actual runtimeimprovements by providing a cross-country elimination interpreter in JAX thatcan efficiently execute the obtained elimination orders.</description><author>Jamie Lohoff, Emre Neftci</author><pubDate>Fri, 07 Jun 2024 16:44:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05027v1</guid></item><item><title>GANetic Loss for Generative Adversarial Networks with a Focus on Medical Applications</title><link>http://arxiv.org/abs/2406.05023v1</link><description>Generative adversarial networks (GANs) are machine learning models that areused to estimate the underlying statistical structure of a given dataset and asa result can be used for a variety of tasks such as image generation or anomalydetection. Despite their initial simplicity, designing an effective lossfunction for training GANs remains challenging, and various loss functions havebeen proposed aiming to improve the performance and stability of the generativemodels. In this study, loss function design for GANs is presented as anoptimization problem solved using the genetic programming (GP) approach.Initial experiments were carried out using small Deep Convolutional GAN (DCGAN)model and the MNIST dataset, in order to search experimentally for an improvedloss function. The functions found were evaluated on CIFAR10, with the bestfunction, named GANetic loss, showing exceptionally better performance andstability compared to the losses commonly used for GAN training. To furtherevalute its general applicability on more challenging problems, GANetic losswas applied for two medical applications: image generation and anomalydetection. Experiments were performed with histopathological, gastrointestinalor glaucoma images to evaluate the GANetic loss in medical image generation,resulting in improved image quality compared to the baseline models. TheGANetic Loss used for polyp and glaucoma images showed a strong improvement inthe detection of anomalies. In summary, the GANetic loss function was evaluatedon multiple datasets and applications where it consistently outperformsalternative loss functions. Moreover, GANetic loss leads to stable training andreproducible results, a known weak spot of GANs.</description><author>Shakhnaz Akhmedova, Nils Körber</author><pubDate>Fri, 07 Jun 2024 16:43:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05023v1</guid></item><item><title>Scaling up Probabilistic PDE Simulators with Structured Volumetric Information</title><link>http://arxiv.org/abs/2406.05020v1</link><description>Modeling real-world problems with partial differential equations (PDEs) is aprominent topic in scientific machine learning. Classic solvers for this taskcontinue to play a central role, e.g. to generate training data for deeplearning analogues. Any such numerical solution is subject to multiple sourcesof uncertainty, both from limited computational resources and limited data(including unknown parameters). Gaussian process analogues to classic PDEsimulation methods have recently emerged as a framework to construct fullyprobabilistic estimates of all these types of uncertainty. So far, much of thiswork focused on theoretical foundations, and as such is not particularly dataefficient or scalable. Here we propose a framework combining a discretizationscheme based on the popular Finite Volume Method with complementary numericallinear algebra techniques. Practical experiments, including a spatiotemporaltsunami simulation, demonstrate substantially improved scaling behavior of thisapproach over previous collocation-based techniques.</description><author>Tim Weiland, Marvin Pförtner, Philipp Hennig</author><pubDate>Fri, 07 Jun 2024 16:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05020v1</guid></item><item><title>Adaptively Learning to Select-Rank in Online Platforms</title><link>http://arxiv.org/abs/2406.05017v1</link><description>Ranking algorithms are fundamental to various online platforms acrosse-commerce sites to content streaming services. Our research addresses thechallenge of adaptively ranking items from a candidate pool for heterogeneoususers, a key component in personalizing user experience. We develop a userresponse model that considers diverse user preferences and the varying effectsof item positions, aiming to optimize overall user satisfaction with the rankedlist. We frame this problem within a contextual bandits framework, with eachranked list as an action. Our approach incorporates an upper confidence boundto adjust predicted user satisfaction scores and selects the ranking actionthat maximizes these adjusted scores, efficiently solved via maximum weightimperfect matching. We demonstrate that our algorithm achieves a cumulativeregret bound of $O(d\sqrt{NKT})$ for ranking $K$ out of $N$ items in a$d$-dimensional context space over $T$ rounds, under the assumption that userresponses follow a generalized linear model. This regret alleviates dependenceon the ambient action space, whose cardinality grows exponentially with $N$ and$K$ (thus rendering direct application of existing adaptive learning algorithms-- such as UCB or Thompson sampling -- infeasible). Experiments conducted onboth simulated and real-world datasets demonstrate our algorithm outperformsthe baseline.</description><author>Jingyuan Wang, Perry Dong, Ying Jin, Ruohan Zhan, Zhengyuan Zhou</author><pubDate>Fri, 07 Jun 2024 16:33:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05017v1</guid></item><item><title>S$Ω$I: Score-based O-INFORMATION Estimation</title><link>http://arxiv.org/abs/2402.05667v3</link><description>The analysis of scientific data and complex multivariate systems requiresinformation quantities that capture relationships among multiple randomvariables. Recently, new information-theoretic measures have been developed toovercome the shortcomings of classical ones, such as mutual information, thatare restricted to considering pairwise interactions. Among them, the concept ofinformation synergy and redundancy is crucial for understanding the high-orderdependencies between variables. One of the most prominent and versatilemeasures based on this concept is O-information, which provides a clear andscalable way to quantify the synergy-redundancy balance in multivariatesystems. However, its practical application is limited to simplified cases. Inthis work, we introduce S$\Omega$I, which allows for the first time to computeO-information without restrictive assumptions about the system. Our experimentsvalidate our approach on synthetic data, and demonstrate the effectiveness ofS$\Omega$I in the context of a real-world use case.</description><author>Mustapha Bounoua, Giulio Franzese, Pietro Michiardi</author><pubDate>Fri, 07 Jun 2024 16:31:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05667v3</guid></item><item><title>Root Cause Analysis of Outliers with Missing Structural Knowledge</title><link>http://arxiv.org/abs/2406.05014v1</link><description>Recent work conceptualized root cause analysis (RCA) of anomalies viaquantitative contribution analysis using causal counterfactuals in structuralcausal models (SCMs). The framework comes with three practical challenges: (1)it requires the causal directed acyclic graph (DAG), together with an SCM, (2)it is statistically ill-posed since it probes regression models in regions oflow probability density, (3) it relies on Shapley values which arecomputationally expensive to find. In this paper, we propose simplified, efficient methods of root causeanalysis when the task is to identify a unique root cause instead ofquantitative contribution analysis. Our proposed methods run in linear order ofSCM nodes and they require only the causal DAG without counterfactuals.Furthermore, for those use cases where the causal DAG is unknown, we justifythe heuristic of identifying root causes as the variables with the highestanomaly score.</description><author>Nastaran Okati, Sergio Hernan Garrido Mejia, William Roy Orchard, Patrick Blöbaum, Dominik Janzing</author><pubDate>Fri, 07 Jun 2024 16:24:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05014v1</guid></item><item><title>A Novel Cross-Perturbation for Single Domain Generalization</title><link>http://arxiv.org/abs/2308.00918v2</link><description>Single domain generalization aims to enhance the ability of the model togeneralize to unknown domains when trained on a single source domain. However,the limited diversity in the training data hampers the learning ofdomain-invariant features, resulting in compromised generalization performance.To address this, data perturbation (augmentation) has emerged as a crucialmethod to increase data diversity. Nevertheless, existing perturbation methodsoften focus on either image-level or feature-level perturbations independently,neglecting their synergistic effects. To overcome these limitations, we proposeCPerb, a simple yet effective cross-perturbation method. Specifically, CPerbutilizes both horizontal and vertical operations. Horizontally, it appliesimage-level and feature-level perturbations to enhance the diversity of thetraining data, mitigating the issue of limited diversity in single-sourcedomains. Vertically, it introduces multi-route perturbation to learndomain-invariant features from different perspectives of samples with the samesemantic category, thereby enhancing the generalization capability of themodel. Additionally, we propose MixPatch, a novel feature-level perturbationmethod that exploits local image style information to further diversify thetraining data. Extensive experiments on various benchmark datasets validate theeffectiveness of our method.</description><author>Dongjia Zhao, Lei Qi, Xiao Shi, Yinghuan Shi, Xin Geng</author><pubDate>Fri, 07 Jun 2024 16:22:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00918v2</guid></item><item><title>Meta-Control: Automatic Model-based Control Synthesis for Heterogeneous Robot Skills</title><link>http://arxiv.org/abs/2405.11380v2</link><description>The requirements for real-world manipulation tasks are diverse and oftenconflicting; some tasks require precise motion while others require forcecompliance; some tasks require avoidance of certain regions, while othersrequire convergence to certain states. Satisfying these varied requirementswith a fixed state-action representation and control strategy is challenging,impeding the development of a universal robotic foundation model. In this work,we propose Meta-Control, the first LLM-enabled automatic control synthesisapproach that creates customized state representations and control strategiestailored to specific tasks. Our core insight is that a meta-control system canbe built to automate the thought process that human experts use to designcontrol systems. Specifically, human experts heavily use a model-based,hierarchical (from abstract to concrete) thought model, then compose variousdynamic models and controllers together to form a control system. Meta-Controlmimics the thought model and harnesses LLM's extensive control knowledge withSocrates' "art of midwifery" to automate the thought process. Meta-Controlstands out for its fully model-based nature, allowing rigorous analysis,generalizability, robustness, efficient parameter tuning, and reliablereal-time execution.</description><author>Tianhao Wei, Liqian Ma, Rui Chen, Weiye Zhao, Changliu Liu</author><pubDate>Fri, 07 Jun 2024 16:22:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11380v2</guid></item><item><title>Clarifying Myths About the Relationship Between Shape Bias, Accuracy, and Robustness</title><link>http://arxiv.org/abs/2406.05006v1</link><description>Deep learning models can perform well when evaluated on images from the samedistribution as the training set. However, applying small perturbations in theforms of noise, artifacts, occlusions, blurring, etc. to a model's input imageand feeding the model with out-of-distribution (OOD) data can significantlydrop the model's accuracy, making it not applicable to real-world scenarios.Data augmentation is one of the well-practiced methods to improve modelrobustness against OOD data; however, examining which augmentation type tochoose and how it affects the OOD robustness remains understudied. There is agrowing belief that augmenting datasets using data augmentations that improve amodel's bias to shape-based features rather than texture-based features resultsin increased OOD robustness for Convolutional Neural Networks trained on theImageNet-1K dataset. This is usually stated as ``an increase in the model'sshape bias results in an increase in its OOD robustness". Based on thishypothesis, some works in the literature aim to find augmentations with highereffects on model shape bias and use those for data augmentation. By evaluating39 types of data augmentations on a widely used OOD dataset, we demonstrate theimpact of each data augmentation on the model's robustness to OOD data andfurther show that the mentioned hypothesis is not true; an increase in shapebias does not necessarily result in higher OOD robustness. By analyzing theresults, we also find some biases in the ImageNet-1K dataset that can easily bereduced using proper data augmentation. Our evaluation results further showthat there is not necessarily a trade-off between in-domain accuracy and OODrobustness, and choosing the proper augmentations can help increase bothin-domain accuracy and OOD robustness simultaneously.</description><author>Zahra Golpayegani, Patrick St-Amant, Nizar Bouguila</author><pubDate>Fri, 07 Jun 2024 16:21:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05006v1</guid></item><item><title>Are We Done with MMLU?</title><link>http://arxiv.org/abs/2406.04127v2</link><description>Maybe not. We identify and analyse errors in the popular Massive MultitaskLanguage Understanding (MMLU) benchmark. Even though MMLU is widely adopted,our analysis demonstrates numerous ground truth errors that obscure the truecapabilities of LLMs. For example, we find that 57% of the analysed questionsin the Virology subset contain errors. To address this issue, we introduce acomprehensive framework for identifying dataset errors using a novel errortaxonomy. Then, we create MMLU-Redux, which is a subset of 3,000 manuallyre-annotated questions across 30 MMLU subjects. Using MMLU-Redux, wedemonstrate significant discrepancies with the model performance metrics thatwere originally reported. Our results strongly advocate for revising MMLU'serror-ridden questions to enhance its future utility and reliability as abenchmark. Therefore, we open up MMLU-Redux for additional annotationhttps://huggingface.co/datasets/edinburgh-dawg/mmlu-redux.</description><author>Aryo Pradipta Gema, Joshua Ong Jun Leang, Giwon Hong, Alessio Devoto, Alberto Carlo Maria Mancino, Rohit Saxena, Xuanli He, Yu Zhao, Xiaotang Du, Mohammad Reza Ghasemi Madani, Claire Barale, Robert McHardy, Joshua Harris, Jean Kaddour, Emile van Krieken, Pasquale Minervini</author><pubDate>Fri, 07 Jun 2024 16:19:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04127v2</guid></item><item><title>Benchmarking Deep Jansen-Rit Parameter Inference: An in Silico Study</title><link>http://arxiv.org/abs/2406.05002v1</link><description>The study of effective connectivity (EC) is essential in understanding howthe brain integrates and responds to various sensory inputs. Model-drivenestimation of EC is a powerful approach that requires estimating global andlocal parameters of a generative model of neural activity. Insights gatheredthrough this process can be used in various applications, such as studyingneurodevelopmental disorders. However, accurately determining EC throughgenerative models remains a significant challenge due to the complexity ofbrain dynamics and the inherent noise in neural recordings, e.g., inelectroencephalography (EEG). Current model-driven methods to study EC arecomputationally complex and cannot scale to all brain regions as required bywhole-brain analyses. To facilitate EC assessment, an inference algorithm mustexhibit reliable prediction of parameters in the presence of noise. Further,the relationship between the model parameters and the neural recordings must belearnable. To progress toward these objectives, we benchmarked the performanceof a Bi-LSTM model for parameter inference from the Jansen-Rit neural massmodel (JR-NMM) simulated EEG under various noise conditions. Additionally, ourstudy explores how the JR-NMM reacts to changes in key biological parameters(i.e., sensitivity analysis) like synaptic gains and time constants, a crucialstep in understanding the connection between neural mechanisms and observedbrain activity. Our results indicate that we can predict the local JR-NMMparameters from EEG, supporting the feasibility of our deep-learning-basedinference approach. In future work, we plan to extend this framework toestimate local and global parameters from real EEG in clinically relevantapplications.</description><author>Deepa Tilwani, Christian O'Reilly</author><pubDate>Fri, 07 Jun 2024 16:16:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05002v1</guid></item><item><title>AttnDreamBooth: Towards Text-Aligned Personalized Text-to-Image Generation</title><link>http://arxiv.org/abs/2406.05000v1</link><description>Recent advances in text-to-image models have enabled high-qualitypersonalized image synthesis of user-provided concepts with flexible textualcontrol. In this work, we analyze the limitations of two primary techniques intext-to-image personalization: Textual Inversion and DreamBooth. Whenintegrating the learned concept into new prompts, Textual Inversion tends tooverfit the concept, while DreamBooth often overlooks it. We attribute theseissues to the incorrect learning of the embedding alignment for the concept. Weintroduce AttnDreamBooth, a novel approach that addresses these issues byseparately learning the embedding alignment, the attention map, and the subjectidentity in different training stages. We also introduce a cross-attention mapregularization term to enhance the learning of the attention map. Our methoddemonstrates significant improvements in identity preservation and textalignment compared to the baseline methods.</description><author>Lianyu Pang, Jian Yin, Baoquan Zhao, Feize Wu, Fu Lee Wang, Qing Li, Xudong Mao</author><pubDate>Fri, 07 Jun 2024 16:12:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05000v1</guid></item><item><title>Image Coding for Machines with Edge Information Learning Using Segment Anything</title><link>http://arxiv.org/abs/2403.04173v3</link><description>Image Coding for Machines (ICM) is an image compression technique for imagerecognition. This technique is essential due to the growing demand for image recognitionAI. In this paper, we propose a method for ICM that focuses on encoding anddecoding only the edge information of object parts in an image, which we callSA-ICM. This is an Learned Image Compression (LIC) model trained using edgeinformation created by Segment Anything. Our method can be used for image recognition models with various tasks. SA-ICM is also robust to changes in input data, making it effective for avariety of use cases. Additionally, our method provides benefits from a privacy point of view, asit removes human facial information on the encoder's side, thus protectingone's privacy. Furthermore, this LIC model training method can be used to train NeuralRepresentations for Videos (NeRV), which is a video compression model. By training NeRV using edge information created by Segment Anything, it ispossible to create a NeRV that is effective for image recognition (SA-NeRV). Experimental results confirm the advantages of SA-ICM, presenting the bestperformance in image compression for image recognition. We also show that SA-NeRV is superior to ordinary NeRV in video compressionfor machines. Code is available at https://github.com/final-0/SA-ICM.</description><author>Takahiro Shindo, Kein Yamada, Taiju Watanabe, Hiroshi Watanabe</author><pubDate>Fri, 07 Jun 2024 16:11:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.04173v3</guid></item><item><title>On the Independence Assumption in Neurosymbolic Learning</title><link>http://arxiv.org/abs/2404.08458v2</link><description>State-of-the-art neurosymbolic learning systems use probabilistic reasoningto guide neural networks towards predictions that conform to logicalconstraints over symbols. Many such systems assume that the probabilities ofthe considered symbols are conditionally independent given the input tosimplify learning and reasoning. We study and criticise this assumption,highlighting how it can hinder optimisation and prevent uncertaintyquantification. We prove that loss functions bias conditionally independentneural networks to become overconfident in their predictions. As a result, theyare unable to represent uncertainty over multiple valid options. Furthermore,we prove that these loss functions are difficult to optimise: they arenon-convex, and their minima are usually highly disconnected. Our theoreticalanalysis gives the foundation for replacing the conditional independenceassumption and designing more expressive neurosymbolic probabilistic models.</description><author>Emile van Krieken, Pasquale Minervini, Edoardo M. Ponti, Antonio Vergari</author><pubDate>Fri, 07 Jun 2024 16:10:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08458v2</guid></item><item><title>ProMotion: Prototypes As Motion Learners</title><link>http://arxiv.org/abs/2406.04999v1</link><description>In this work, we introduce ProMotion, a unified prototypical frameworkengineered to model fundamental motion tasks. ProMotion offers a range ofcompelling attributes that set it apart from current task-specific paradigms.We adopt a prototypical perspective, establishing a unified paradigm thatharmonizes disparate motion learning approaches. This novel paradigmstreamlines the architectural design, enabling the simultaneous assimilation ofdiverse motion information. We capitalize on a dual mechanism involving thefeature denoiser and the prototypical learner to decipher the intricacies ofmotion. This approach effectively circumvents the pitfalls of ambiguity inpixel-wise feature matching, significantly bolstering the robustness of motionrepresentation. We demonstrate a profound degree of transferability acrossdistinct motion patterns. This inherent versatility reverberates robustlyacross a comprehensive spectrum of both 2D and 3D downstream tasks. Empiricalresults demonstrate that ProMotion outperforms various well-known specializedarchitectures, achieving 0.54 and 0.054 Abs Rel error on the Sintel and KITTIdepth datasets, 1.04 and 2.01 average endpoint error on the clean and finalpass of Sintel flow benchmark, and 4.30 F1-all error on the KITTI flowbenchmark. For its efficacy, we hope our work can catalyze a paradigm shift inuniversal models in computer vision.</description><author>Yawen Lu, Dongfang Liu, Qifan Wang, Cheng Han, Yiming Cui, Zhiwen Cao, Xueling Zhang, Yingjie Victor Chen, Heng Fan</author><pubDate>Fri, 07 Jun 2024 16:10:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04999v1</guid></item><item><title>ADBA:Approximation Decision Boundary Approach for Black-Box Adversarial Attacks</title><link>http://arxiv.org/abs/2406.04998v1</link><description>Many machine learning models are susceptible to adversarial attacks, withdecision-based black-box attacks representing the most critical threat inreal-world applications. These attacks are extremely stealthy, generatingadversarial examples using hard labels obtained from the target machinelearning model. This is typically realized by optimizing perturbationdirections, guided by decision boundaries identified through query-intensiveexact search, significantly limiting the attack success rate. This paperintroduces a novel approach using the Approximation Decision Boundary (ADB) toefficiently and accurately compare perturbation directions without preciselydetermining decision boundaries. The effectiveness of our ADB approach (ADBA)hinges on promptly identifying suitable ADB, ensuring reliable differentiationof all perturbation directions. For this purpose, we analyze the probabilitydistribution of decision boundaries, confirming that using the distribution'smedian value as ADB can effectively distinguish different perturbationdirections, giving rise to the development of the ADBA-md algorithm. ADBA-mdonly requires four queries on average to differentiate any pair of perturbationdirections, which is highly query-efficient. Extensive experiments on sixwell-known image classifiers clearly demonstrate the superiority of ADBA andADBA-md over multiple state-of-the-art black-box attacks.</description><author>Feiyang Wang, Xingquan Zuo, Hai Huang, Gang Chen</author><pubDate>Fri, 07 Jun 2024 16:09:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04998v1</guid></item><item><title>On the social bias of speech self-supervised models</title><link>http://arxiv.org/abs/2406.04997v1</link><description>Self-supervised learning (SSL) speech models have achieved remarkableperformance in various tasks, yet the biased outcomes, especially affectingmarginalized groups, raise significant concerns. Social bias refers to thephenomenon where algorithms potentially amplify disparate properties betweensocial groups present in the data used for training. Bias in SSL models canperpetuate injustice by automating discriminatory patterns and reinforcinginequitable systems. This work reveals that prevalent SSL models inadvertentlyacquire biased associations. We probe how various factors, such as modelarchitecture, size, and training methodologies, influence the propagation ofsocial bias within these models. Finally, we explore the efficacy of debiasingSSL models through regularization techniques, specifically via modelcompression. Our findings reveal that employing techniques such as row-pruningand training wider, shallower models can effectively mitigate social biaswithin SSL model.</description><author>Yi-Cheng Lin, Tzu-Quan Lin, Hsi-Che Lin, Andy T. Liu, Hung-yi Lee</author><pubDate>Fri, 07 Jun 2024 16:07:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04997v1</guid></item><item><title>Development and Validation of a Deep-Learning Model for Differential Treatment Benefit Prediction for Adults with Major Depressive Disorder Deployed in the Artificial Intelligence in Depression Medication Enhancement (AIDME) Study</title><link>http://arxiv.org/abs/2406.04993v1</link><description>INTRODUCTION: The pharmacological treatment of Major Depressive Disorder(MDD) relies on a trial-and-error approach. We introduce an artificialintelligence (AI) model aiming to personalize treatment and improve outcomes,which was deployed in the Artificial Intelligence in Depression MedicationEnhancement (AIDME) Study. OBJECTIVES: 1) Develop a model capable of predictingprobabilities of remission across multiple pharmacological treatments foradults with at least moderate major depression. 2) Validate model predictionsand examine them for amplification of harmful biases. METHODS: Data fromprevious clinical trials of antidepressant medications were standardized into acommon framework and included 9,042 adults with moderate to severe majordepression. Feature selection retained 25 clinical and demographic variables.Using Bayesian optimization, a deep learning model was trained on the trainingset, refined using the validation set, and tested once on the held-out testset. RESULTS: In the evaluation on the held-out test set, the modeldemonstrated achieved an AUC of 0.65. The model outperformed a null model onthe test set (p = 0.01). The model demonstrated clinical utility, achieving anabsolute improvement in population remission rate in hypothetical and actualimprovement testing. While the model did identify one drug (escitalopram) asgenerally outperforming the other drugs (consistent with the input data), therewas otherwise significant variation in drug rankings. On bias testing, themodel did not amplify potentially harmful biases. CONCLUSIONS: We demonstratethe first model capable of predicting outcomes for 10 different treatmentoptions for patients with MDD, intended to be used at or near the start oftreatment to personalize treatment. The model was put into clinical practiceduring the AIDME randomized controlled trial whose results are reportedseparately.</description><author>David Benrimoh, Caitrin Armstrong, Joseph Mehltretter, Robert Fratila, Kelly Perlman, Sonia Israel, Adam Kapelner, Sagar V. Parikh, Jordan F. Karp, Katherine Heller, Gustavo Turecki</author><pubDate>Fri, 07 Jun 2024 16:04:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04993v1</guid></item><item><title>Compositional Generalization with Grounded Language Models</title><link>http://arxiv.org/abs/2406.04989v1</link><description>Grounded language models use external sources of information, such asknowledge graphs, to meet some of the general challenges associated withpre-training. By extending previous work on compositional generalization insemantic parsing, we allow for a controlled evaluation of the degree to whichthese models learn and generalize from patterns in knowledge graphs. We developa procedure for generating natural language questions paired with knowledgegraphs that targets different aspects of compositionality and further avoidsgrounding the language models in information already encoded implicitly intheir weights. We evaluate existing methods for combining language models withknowledge graphs and find them to struggle with generalization to sequences ofunseen lengths and to novel combinations of seen base components. While ourexperimental results provide some insight into the expressive power of thesemodels, we hope our work and released datasets motivate future research on howto better combine language models with structured knowledge representations.</description><author>Sondre Wold, Étienne Simon, Lucas Georges Gabriel Charpentier, Egor V. Kostylev, Erik Velldal, Lilja Øvrelid</author><pubDate>Fri, 07 Jun 2024 15:56:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04989v1</guid></item><item><title>Language models emulate certain cognitive profiles: An investigation of how predictability measures interact with individual differences</title><link>http://arxiv.org/abs/2406.04988v1</link><description>To date, most investigations on surprisal and entropy effects in reading havebeen conducted on the group level, disregarding individual differences. In thiswork, we revisit the predictive power of surprisal and entropy measuresestimated from a range of language models (LMs) on data of human reading timesas a measure of processing effort by incorporating information of languageusers' cognitive capacities. To do so, we assess the predictive power ofsurprisal and entropy estimated from generative LMs on reading data obtainedfrom individuals who also completed a wide range of psychometric tests.Specifically, we investigate if modulating surprisal and entropy relative tocognitive scores increases prediction accuracy of reading times, and we examinewhether LMs exhibit systematic biases in the prediction of reading times forcognitively high- or low-performing groups, revealing what type ofpsycholinguistic subject a given LM emulates. Our study finds that in mostcases, incorporating cognitive capacities increases predictive power ofsurprisal and entropy on reading times, and that generally, high performance inthe psychometric tests is associated with lower sensitivity to predictabilityeffects. Finally, our results suggest that the analyzed LMs emulate readerswith lower verbal intelligence, suggesting that for a given target group (i.e.,individuals with high verbal intelligence), these LMs provide less accuratepredictability estimates.</description><author>Patrick Haller, Lena S. Bolliger, Lena A. Jäger</author><pubDate>Fri, 07 Jun 2024 15:54:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04988v1</guid></item><item><title>Spiking Neural Networks for event-based action recognition: A new task to understand their advantage</title><link>http://arxiv.org/abs/2209.14915v3</link><description>Spiking Neural Networks (SNN) are characterised by their unique temporaldynamics, but the properties and advantages of such computations are still notwell understood. In order to provide answers, in this work we demonstrate howSpiking neurons can enable temporal feature extraction in feed-forward neuralnetworks without the need for recurrent synapses, and how recurrent SNNs canachieve comparable results to LSTM with a smaller number of parameters. Thisshows how their bio-inspired computing principles can be successfully exploitedbeyond energy efficiency gains and evidences their differences with respect toconventional artificial neural networks. These results are obtained through anew task, DVS-Gesture-Chain (DVS-GC), which allows, for the first time, toevaluate the perception of temporal dependencies in a real event-based actionrecognition dataset. Our study proves how the widely used DVS Gesture benchmarkcan be solved by networks without temporal feature extraction when its eventsare accumulated in frames, unlike the new DVS-GC which demands an understandingof the order in which events happen. Furthermore, this setup allowed us toreveal the role of the leakage rate in spiking neurons for temporal processingtasks and demonstrated the benefits of "hard reset" mechanisms. Additionally,we also show how time-dependent weights and normalization can lead tounderstanding order by means of temporal attention.</description><author>Alex Vicente-Sola, Davide L. Manna, Paul Kirkland, Gaetano Di Caterina, Trevor Bihl</author><pubDate>Fri, 07 Jun 2024 15:51:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.14915v3</guid></item><item><title>MEFT: Memory-Efficient Fine-Tuning through Sparse Adapter</title><link>http://arxiv.org/abs/2406.04984v1</link><description>Parameter-Efficient Fine-tuning (PEFT) facilitates the fine-tuning of LargeLanguage Models (LLMs) under limited resources. However, the fine-tuningperformance with PEFT on complex, knowledge-intensive tasks is limited due tothe constrained model capacity, which originates from the limited number ofadditional trainable parameters. To overcome this limitation, we introduce anovel mechanism that fine-tunes LLMs with adapters of larger size yetmemory-efficient. This is achieved by leveraging the inherent activationsparsity in the Feed-Forward Networks (FFNs) of LLMs and utilizing the largercapacity of Central Processing Unit (CPU) memory compared to GraphicsProcessing Unit (GPU). We store and update the parameters of larger adapters onthe CPU. Moreover, we employ a Mixture of Experts (MoE)-like architecture tomitigate unnecessary CPU computations and reduce the communication volumebetween the GPU and CPU. This is particularly beneficial over the limitedbandwidth of PCI Express (PCIe). Our method can achieve fine-tuning resultscomparable to those obtained with larger memory capacities, even when operatingunder more limited resources such as a 24GB memory single GPU setup, withacceptable loss in training efficiency. Our codes are available athttps://github.com/CURRENTF/MEFT.</description><author>Jitai Hao, WeiWei Sun, Xin Xin, Qi Meng, Zhumin Chen, Pengjie Ren, Zhaochun Ren</author><pubDate>Fri, 07 Jun 2024 15:49:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04984v1</guid></item><item><title>CityCraft: A Real Crafter for 3D City Generation</title><link>http://arxiv.org/abs/2406.04983v1</link><description>City scene generation has gained significant attention in autonomous driving,smart city development, and traffic simulation. It helps enhance infrastructureplanning and monitoring solutions. Existing methods have employed a two-stageprocess involving city layout generation, typically using VariationalAutoencoders (VAEs), Generative Adversarial Networks (GANs), or Transformers,followed by neural rendering. These techniques often exhibit limited diversityand noticeable artifacts in the rendered city scenes. The rendered scenes lackvariety, resembling the training images, resulting in monotonous styles.Additionally, these methods lack planning capabilities, leading to lessrealistic generated scenes. In this paper, we introduce CityCraft, aninnovative framework designed to enhance both the diversity and quality ofurban scene generation. Our approach integrates three key stages: initially, adiffusion transformer (DiT) model is deployed to generate diverse andcontrollable 2D city layouts. Subsequently, a Large Language Model(LLM) isutilized to strategically make land-use plans within these layouts based onuser prompts and language guidelines. Based on the generated layout and cityplan, we utilize the asset retrieval module and Blender for precise assetplacement and scene construction. Furthermore, we contribute two new datasetsto the field: 1)CityCraft-OSM dataset including 2D semantic layouts of urbanareas, corresponding satellite images, and detailed annotations. 2)CityCraft-Buildings dataset, featuring thousands of diverse, high-quality 3Dbuilding assets. CityCraft achieves state-of-the-art performance in generatingrealistic 3D cities.</description><author>Jie Deng, Wenhao Chai, Junsheng Huang, Zhonghan Zhao, Qixuan Huang, Mingyan Gao, Jianshu Guo, Shengyu Hao, Wenhao Hu, Jenq-Neng Hwang, Xi Li, Gaoang Wang</author><pubDate>Fri, 07 Jun 2024 15:49:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04983v1</guid></item><item><title>The Price of Implicit Bias in Adversarially Robust Generalization</title><link>http://arxiv.org/abs/2406.04981v1</link><description>We study the implicit bias of optimization in robust empirical riskminimization (robust ERM) and its connection with robust generalization. Inclassification settings under adversarial perturbations with linear models, westudy what type of regularization should ideally be applied for a givenperturbation set to improve (robust) generalization. We then show that theimplicit bias of optimization in robust ERM can significantly affect therobustness of the model and identify two ways this can happen; either throughthe optimization algorithm or the architecture. We verify our predictions insimulations with synthetic data and experimentally study the importance ofimplicit bias in robust ERM with deep neural networks.</description><author>Nikolaos Tsilivis, Natalie Frank, Nathan Srebro, Julia Kempe</author><pubDate>Fri, 07 Jun 2024 15:44:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04981v1</guid></item><item><title>Variational Inference for Uncertainty Quantification: an Analysis of Trade-offs</title><link>http://arxiv.org/abs/2403.13748v2</link><description>Given an intractable distribution $p$, the problem of variational inference(VI) is to find the best approximation from some more tractable family $Q$.Commonly, one chooses $Q$ to be a family of factorized distributions (i.e., themean-field assumption), even though~$p$ itself does not factorize. We show thatthis mismatch leads to an impossibility theorem: if $p$ does not factorize,then any factorized approximation $q\in Q$ can correctly estimate at most oneof the following three measures of uncertainty: (i) the marginal variances,(ii) the marginal precisions, or (iii) the generalized variance (which can berelated to the entropy). In practice, the best variational approximation in $Q$is found by minimizing some divergence $D(q,p)$ between distributions, and sowe ask: how does the choice of divergence determine which measure ofuncertainty, if any, is correctly estimated by VI? We consider the classicKullback-Leibler divergences, the more general R\'enyi divergences, and ascore-based divergence which compares $\nabla \log p$ and $\nabla \log q$. Weprovide a thorough theoretical analysis in the setting where $p$ is a Gaussianand $q$ is a (factorized) Gaussian. We show that all the considered divergencescan be \textit{ordered} based on the estimates of uncertainty they yield asobjective functions for~VI. Finally, we empirically evaluate the validity ofthis ordering when the target distribution $p$ is not Gaussian.</description><author>Charles C. Margossian, Loucas Pillaud-Vivien, Lawrence K. Saul</author><pubDate>Fri, 07 Jun 2024 15:43:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13748v2</guid></item><item><title>Semantic Segmentation on VSPW Dataset through Masked Video Consistency</title><link>http://arxiv.org/abs/2406.04979v1</link><description>Pixel-level Video Understanding requires effectively integratingthree-dimensional data in both spatial and temporal dimensions to learnaccurate and stable semantic information from continuous frames. However,existing advanced models on the VSPW dataset have not fully modeledspatiotemporal relationships. In this paper, we present our solution for thePVUW competition, where we introduce masked video consistency (MVC) based onexisting models. MVC enforces the consistency between predictions of maskedframes where random patches are withheld. The model needs to learn thesegmentation results of the masked parts through the context of images and therelationship between preceding and succeeding frames of the video.Additionally, we employed test-time augmentation, model aggeregation and amultimodal model-based post-processing method. Our approach achieves 67.27%mIoU performance on the VSPW dataset, ranking 2nd place in the PVUW2024challenge VSS track.</description><author>Chen Liang, Qiang Guo, Chongkai Yu, Chengjing Wu, Ting Liu, Luoqi Liu</author><pubDate>Fri, 07 Jun 2024 15:41:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04979v1</guid></item><item><title>3DGStream: On-the-Fly Training of 3D Gaussians for Efficient Streaming of Photo-Realistic Free-Viewpoint Videos</title><link>http://arxiv.org/abs/2403.01444v3</link><description>Constructing photo-realistic Free-Viewpoint Videos (FVVs) of dynamic scenesfrom multi-view videos remains a challenging endeavor. Despite the remarkableadvancements achieved by current neural rendering techniques, these methodsgenerally require complete video sequences for offline training and are notcapable of real-time rendering. To address these constraints, we introduce3DGStream, a method designed for efficient FVV streaming of real-world dynamicscenes. Our method achieves fast on-the-fly per-frame reconstruction within 12seconds and real-time rendering at 200 FPS. Specifically, we utilize 3DGaussians (3DGs) to represent the scene. Instead of the na\"ive approach ofdirectly optimizing 3DGs per-frame, we employ a compact Neural TransformationCache (NTC) to model the translations and rotations of 3DGs, markedly reducingthe training time and storage required for each FVV frame. Furthermore, wepropose an adaptive 3DG addition strategy to handle emerging objects in dynamicscenes. Experiments demonstrate that 3DGStream achieves competitive performancein terms of rendering speed, image quality, training time, and model storagewhen compared with state-of-the-art methods.</description><author>Jiakai Sun, Han Jiao, Guangyuan Li, Zhanjie Zhang, Lei Zhao, Wei Xing</author><pubDate>Fri, 07 Jun 2024 15:39:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01444v3</guid></item><item><title>UniTST: Effectively Modeling Inter-Series and Intra-Series Dependencies for Multivariate Time Series Forecasting</title><link>http://arxiv.org/abs/2406.04975v1</link><description>Transformer-based models have emerged as powerful tools for multivariate timeseries forecasting (MTSF). However, existing Transformer models often fallshort of capturing both intricate dependencies across variate and temporaldimensions in MTS data. Some recent models are proposed to separately capturevariate and temporal dependencies through either two sequential or parallelattention mechanisms. However, these methods cannot directly and explicitlylearn the intricate inter-series and intra-series dependencies. In this work,we first demonstrate that these dependencies are very important as they usuallyexist in real-world data. To directly model these dependencies, we propose atransformer-based model UniTST containing a unified attention mechanism on theflattened patch tokens. Additionally, we add a dispatcher module which reducesthe complexity and makes the model feasible for a potentially large number ofvariates. Although our proposed model employs a simple architecture, it offerscompelling performance as shown in our extensive experiments on severaldatasets for time series forecasting.</description><author>Juncheng Liu, Chenghao Liu, Gerald Woo, Yiwei Wang, Bryan Hooi, Caiming Xiong, Doyen Sahoo</author><pubDate>Fri, 07 Jun 2024 15:39:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04975v1</guid></item><item><title>An algorithm for forensic toolmark comparisons</title><link>http://arxiv.org/abs/2312.00032v3</link><description>Forensic toolmark analysis traditionally relies on subjective human judgment,leading to inconsistencies and lack of transparency. The multitude ofvariables, including angles and directions of mark generation, furthercomplicates comparisons. To address this, we first generate a dataset of 3Dtoolmarks from various angles and directions using consecutively manufacturedslotted screwdrivers. By using PAM clustering, we find that there is clusteringby tool rather than angle or direction. Using Known Match and Known Non-Matchdensities, we establish thresholds for classification. Fitting Betadistributions to the densities, we allow for the derivation of likelihoodratios for new toolmark pairs. With a cross-validated sensitivity of 98% andspecificity of 96%, our approach enhances the reliability of toolmark analysis.This approach is applicable to slotted screwdrivers, and for screwdrivers thatare made with a similar production method. With data collection of other toolsand factors, it could be applied to compare toolmarks of other types. Thisempirically trained, open-source solution offers forensic examiners astandardized means to objectively compare toolmarks, potentially decreasing thenumber of miscarriages of justice in the legal system.</description><author>Maria Cuellar, Sheng Gao, Heike Hofmann</author><pubDate>Fri, 07 Jun 2024 15:37:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00032v3</guid></item><item><title>GNNavi: Navigating the Information Flow in Large Language Models by Graph Neural Network</title><link>http://arxiv.org/abs/2402.11709v2</link><description>Large Language Models (LLMs) exhibit strong In-Context Learning (ICL)capabilities when prompts with demonstrations are used. However, fine-tuningstill remains crucial to further enhance their adaptability. Prompt-basedfine-tuning proves to be an effective fine-tuning method in low-data scenarios,but high demands on computing resources limit its practicality. We address thisissue by introducing a prompt-based parameter-efficient fine-tuning (PEFT)approach. GNNavi leverages insights into ICL's information flow dynamics, whichindicates that label words act in prompts as anchors for informationpropagation. GNNavi employs a Graph Neural Network (GNN) layer to preciselyguide the aggregation and distribution of information flow during theprocessing of prompts by hardwiring the desired information flow into the GNN.Our experiments on text classification tasks with GPT-2 and Llama2 show GNNavisurpasses standard prompt-based fine-tuning methods in few-shot settings byupdating just 0.2% to 0.5% of parameters. We compare GNNavi with prevalent PEFTapproaches, such as prefix tuning, LoRA and Adapter in terms of performance andefficiency. Our analysis reveals that GNNavi enhances information flow andensures a clear aggregation process.</description><author>Shuzhou Yuan, Ercong Nie, Michael Färber, Helmut Schmid, Hinrich Schütze</author><pubDate>Fri, 07 Jun 2024 15:36:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11709v2</guid></item><item><title>Dealing with unbounded gradients in stochastic saddle-point optimization</title><link>http://arxiv.org/abs/2402.13903v2</link><description>We study the performance of stochastic first-order methods for finding saddlepoints of convex-concave functions. A notorious challenge faced by such methodsis that the gradients can grow arbitrarily large during optimization, which mayresult in instability and divergence. In this paper, we propose a simple andeffective regularization technique that stabilizes the iterates and yieldsmeaningful performance guarantees even if the domain and the gradient noisescales linearly with the size of the iterates (and is thus potentiallyunbounded). Besides providing a set of general results, we also apply ouralgorithm to a specific problem in reinforcement learning, where it leads toperformance guarantees for finding near-optimal policies in an average-rewardMDP without prior knowledge of the bias span.</description><author>Gergely Neu, Nneka Okolo</author><pubDate>Fri, 07 Jun 2024 15:31:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13903v2</guid></item><item><title>Neural Laplace for learning Stochastic Differential Equations</title><link>http://arxiv.org/abs/2406.04964v1</link><description>Neural Laplace is a unified framework for learning diverse classes ofdifferential equations (DE). For different classes of DE, this frameworkoutperforms other approaches relying on neural networks that aim to learnclasses of ordinary differential equations (ODE). However, many systems can'tbe modelled using ODEs. Stochastic differential equations (SDE) are themathematical tool of choice when modelling spatiotemporal DE dynamics under theinfluence of randomness. In this work, we review the potential applications ofNeural Laplace to learn diverse classes of SDE, both from a theoretical and apractical point of view.</description><author>Adrien Carrel</author><pubDate>Fri, 07 Jun 2024 15:29:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04964v1</guid></item><item><title>Learning Divergence Fields for Shift-Robust Graph Representations</title><link>http://arxiv.org/abs/2406.04963v1</link><description>Real-world data generation often involves certain geometries (e.g., graphs)that induce instance-level interdependence. This characteristic makes thegeneralization of learning models more difficult due to the intricateinterdependent patterns that impact data-generative distributions and can varyfrom training to testing. In this work, we propose a geometric diffusion modelwith learnable divergence fields for the challenging generalization problemwith interdependent data. We generalize the diffusion equation with stochasticdiffusivity at each time step, which aims to capture the multi-facetedinformation flows among interdependent data. Furthermore, we derive a newlearning objective through causal inference, which can guide the model to learngeneralizable patterns of interdependence that are insensitive across domains.Regarding practical implementation, we introduce three model instantiationsthat can be considered as the generalized versions of GCN, GAT, andTransformers, respectively, which possess advanced robustness againstdistribution shifts. We demonstrate their promising efficacy forout-of-distribution generalization on diverse real-world datasets.</description><author>Qitian Wu, Fan Nie, Chenxiao Yang, Junchi Yan</author><pubDate>Fri, 07 Jun 2024 15:29:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04963v1</guid></item><item><title>Espresso: Robust Concept Filtering in Text-to-Image Models</title><link>http://arxiv.org/abs/2404.19227v4</link><description>Diffusion-based text-to-image (T2I) models generate high-fidelity images forgiven textual prompts. They are trained on large datasets scraped from theInternet, potentially containing unacceptable concepts (e.g., copyrightinfringing or unsafe). Retraining T2I models after filtering out unacceptableconcepts in the training data is inefficient and degrades utility. Hence, thereis a need for concept removal techniques (CRTs) which are effective in removingunacceptable concepts, utility-preserving on acceptable concepts, and robustagainst evasion with adversarial prompts. None of the prior filtering andfine-tuning CRTs satisfy all these requirements simultaneously. We introduce Espresso, the first robust concept filter based on ContrastiveLanguage-Image Pre-Training (CLIP). It identifies unacceptable concepts byprojecting the generated image's embedding onto the vector connectingunacceptable and acceptable concepts in the joint text-image embedding space.This ensures robustness by restricting the adversary to adding noise only alongthis vector, in the direction of the acceptable concept. Further fine-tuningEspresso to separate embeddings of acceptable and unacceptable concepts, whilepreserving their pairing with image embeddings, ensures both effectiveness andutility. We evaluate Espresso on eleven concepts to show that it is effective(~5% CLIP accuracy on unacceptable concepts), utility-preserving (~93%normalized CLIP score on acceptable concepts), and robust (~4% CLIP accuracy onadversarial prompts for unacceptable concepts). Finally, we present theoreticalbounds for the certified robustness of Espresso against adversarial prompts,and an empirical analysis.</description><author>Anudeep Das, Vasisht Duddu, Rui Zhang, N. Asokan</author><pubDate>Fri, 07 Jun 2024 15:28:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.19227v4</guid></item><item><title>Vulnerable Road User Detection and Safety Enhancement: A Comprehensive Survey</title><link>http://arxiv.org/abs/2405.19202v2</link><description>Traffic incidents involving vulnerable road users (VRUs) constitute asignificant proportion of global road accidents. Advances in trafficcommunication ecosystems, coupled with sophisticated signal processing andmachine learning techniques, have facilitated the utilization of data fromdiverse sensors. Despite these advancements and the availability of extensivedatasets, substantial progress is required to mitigate traffic casualties. Thispaper provides a comprehensive survey of state-of-the-art technologies andmethodologies to enhance the safety of VRUs. The study delves into thecommunication networks between vehicles and VRUs, emphasizing the integrationof advanced sensors and the availability of relevant datasets. It explorespreprocessing techniques and data fusion methods to enhance sensor dataquality. Furthermore, our study assesses critical simulation environmentsessential for developing and testing VRU safety systems. Our research alsohighlights recent advances in VRU detection and classification algorithms,addressing challenges such as variable environmental conditions. Additionally,we cover cutting-edge research in predicting VRU intentions and behaviors,which is crucial for proactive collision avoidance strategies. Through thissurvey, we aim to provide a comprehensive understanding of the currentlandscape of VRU safety technologies, identifying areas of progress and areasneeding further research and development.</description><author>Renato M. Silva, Gregório F. Azevedo, Matheus V. V. Berto, Jean R. Rocha, Eduardo C. Fidelis, Matheus V. Nogueira, Pedro H. Lisboa, Tiago A. Almeida</author><pubDate>Fri, 07 Jun 2024 15:26:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19202v2</guid></item><item><title>Multiplane Prior Guided Few-Shot Aerial Scene Rendering</title><link>http://arxiv.org/abs/2406.04961v1</link><description>Neural Radiance Fields (NeRF) have been successfully applied in variousaerial scenes, yet they face challenges with sparse views due to limitedsupervision. The acquisition of dense aerial views is often prohibitive, asunmanned aerial vehicles (UAVs) may encounter constraints in perspective rangeand energy constraints. In this work, we introduce Multiplane Prior guided NeRF(MPNeRF), a novel approach tailored for few-shot aerial scene rendering-markinga pioneering effort in this domain. Our key insight is that the intrinsicgeometric regularities specific to aerial imagery could be leveraged to enhanceNeRF in sparse aerial scenes. By investigating NeRF's and Multiplane Image(MPI)'s behavior, we propose to guide the training process of NeRF with aMultiplane Prior. The proposed Multiplane Prior draws upon MPI's benefits andincorporates advanced image comprehension through a SwinV2 Transformer,pre-trained via SimMIM. Our extensive experiments demonstrate that MPNeRFoutperforms existing state-of-the-art methods applied in non-aerial contexts,by tripling the performance in SSIM and LPIPS even with three views available.We hope our work offers insights into the development of NeRF-basedapplications in aerial scenes with limited data.</description><author>Zihan Gao, Licheng Jiao, Lingling Li, Xu Liu, Fang Liu, Puhua Chen, Yuwei Guo</author><pubDate>Fri, 07 Jun 2024 15:25:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04961v1</guid></item></channel></rss>