<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 10 Jul 2023 06:00:21 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>When does the ID algorithm fail?</title><link>http://arxiv.org/abs/2307.03750v1</link><description>The ID algorithm solves the problem of identification of interventionaldistributions of the form p(Y | do(a)) in graphical causal models, and has beenformulated in a number of ways [12, 9, 6]. The ID algorithm is sound (outputsthe correct functional of the observed data distribution whenever p(Y | do(a))is identified in the causal model represented by the input graph), and complete(explicitly flags as a failure any input p(Y | do(a)) whenever thisdistribution is not identified in the causal model represented by the inputgraph). The reference [9] provides a result, the so called "hedge criterion"(Corollary 3), which aims to give a graphical characterization of situationswhen the ID algorithm fails to identify its input in terms of a structure inthe input graph called the hedge. While the ID algorithm is, indeed, a soundand complete algorithm, and the hedge structure does arise whenever the inputdistribution is not identified, Corollary 3 presented in [9] is incorrect asstated. In this note, I outline the modern presentation of the ID algorithm,discuss a simple counterexample to Corollary 3, and provide a number ofgraphical characterizations of the ID algorithm failing to identify its inputdistribution.</description><author>Ilya Shpitser</author><pubDate>Fri, 07 Jul 2023 18:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03750v1</guid></item><item><title>On the Efficacy of Sampling Adapters</title><link>http://arxiv.org/abs/2307.03749v1</link><description>Sampling is a common strategy for generating text from probabilistic models,yet standard ancestral sampling often results in text that is incoherent orungrammatical. To alleviate this issue, various modifications to a model'ssampling distribution, such as nucleus or top-k sampling, have been introducedand are now ubiquitously used in language generation systems. We propose aunified framework for understanding these techniques, which we term samplingadapters. Sampling adapters often lead to qualitatively better text, whichraises the question: From a formal perspective, how are they changing the(sub)word-level distributions of language generation models? And why do theselocal changes lead to higher-quality text? We argue that the shift they enforcecan be viewed as a trade-off between precision and recall: while the modelloses its ability to produce certain strings, its precision rate on desirabletext increases. While this trade-off is not reflected in standard metrics ofdistribution quality (such as perplexity), we find that severalprecision-emphasizing measures indeed indicate that sampling adapters can leadto probability distributions more aligned with the true distribution. Further,these measures correlate with higher sequence-level quality scores,specifically, Mauve.</description><author>Clara Meister, Tiago Pimentel, Luca Malagutti, Ethan G. Wilcox, Ryan Cotterell</author><pubDate>Fri, 07 Jul 2023 18:59:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03749v1</guid></item><item><title>Incentive-Theoretic Bayesian Inference for Collaborative Science</title><link>http://arxiv.org/abs/2307.03748v1</link><description>Contemporary scientific research is a distributed, collaborative endeavor,carried out by teams of researchers, regulatory institutions, funding agencies,commercial partners, and scientific bodies, all interacting with each other andfacing different incentives. To maintain scientific rigor, statistical methodsshould acknowledge this state of affairs. To this end, we study hypothesistesting when there is an agent (e.g., a researcher or a pharmaceutical company)with a private prior about an unknown parameter and a principal (e.g., apolicymaker or regulator) who wishes to make decisions based on the parametervalue. The agent chooses whether to run a statistical trial based on theirprivate prior and then the result of the trial is used by the principal toreach a decision. We show how the principal can conduct statistical inferencethat leverages the information that is revealed by an agent's strategicbehavior -- their choice to run a trial or not. In particular, we show how theprincipal can design a policy to elucidate partial information about theagent's private prior beliefs and use this to control the posterior probabilityof the null. One implication is a simple guideline for the choice ofsignificance threshold in clinical trials: the type-I error level should be setto be strictly less than the cost of the trial divided by the firm's profit ifthe trial is successful.</description><author>Stephen Bates, Michael I. Jordan, Michael Sklar, Jake A. Soloff</author><pubDate>Fri, 07 Jul 2023 18:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03748v1</guid></item><item><title>What Should Data Science Education Do with Large Language Models?</title><link>http://arxiv.org/abs/2307.02792v2</link><description>The rapid advances of large language models (LLMs), such as ChatGPT, arerevolutionizing data science and statistics. These state-of-the-art tools canstreamline complex processes. As a result, it reshapes the role of datascientists. We argue that LLMs are transforming the responsibilities of datascientists, shifting their focus from hands-on coding, data-wrangling andconducting standard analyses to assessing and managing analyses performed bythese automated AIs. This evolution of roles is reminiscent of the transitionfrom a software engineer to a product manager. We illustrate this transitionwith concrete data science case studies using LLMs in this paper. Thesedevelopments necessitate a meaningful evolution in data science education.Pedagogy must now place greater emphasis on cultivating diverse skillsets amongstudents, such as LLM-informed creativity, critical thinking, AI-guidedprogramming. LLMs can also play a significant role in the classroom asinteractive teaching and learning tools, contributing to personalizededucation. This paper discusses the opportunities, resources and openchallenges for each of these directions. As with any transformative technology,integrating LLMs into education calls for careful consideration. While LLMs canperform repetitive tasks efficiently, it's crucial to remember that their roleis to supplement human intelligence and creativity, not to replace it.Therefore, the new era of data science education should balance the benefits ofLLMs while fostering complementary human expertise and innovations. Inconclusion, the rise of LLMs heralds a transformative period for data scienceand its education. This paper seeks to shed light on the emerging trends,potential opportunities, and challenges accompanying this paradigm shift,hoping to spark further discourse and investigation into this exciting,uncharted territory.</description><author>Xinming Tu, James Zou, Weijie J. Su, Linjun Zhang</author><pubDate>Fri, 07 Jul 2023 18:56:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02792v2</guid></item><item><title>Training Ensembles with Inliers and Outliers for Semi-supervised Active Learning</title><link>http://arxiv.org/abs/2307.03741v1</link><description>Deep active learning in the presence of outlier examples poses a realisticyet challenging scenario. Acquiring unlabeled data for annotation requires adelicate balance between avoiding outliers to conserve the annotation budgetand prioritizing useful inlier examples for effective training. In this work,we present an approach that leverages three highly synergistic components,which are identified as key ingredients: joint classifier training with inliersand outliers, semi-supervised learning through pseudo-labeling, and modelensembling. Our work demonstrates that ensembling significantly enhances theaccuracy of pseudo-labeling and improves the quality of data acquisition. Byenabling semi-supervision through the joint training process, where outliersare properly handled, we observe a substantial boost in classifier accuracythrough the use of all available unlabeled examples. Notably, we reveal thatthe integration of joint training renders explicit outlier detectionunnecessary; a conventional component for acquisition in prior work. The threekey components align seamlessly with numerous existing approaches. Throughempirical evaluations, we showcase that their combined use leads to aperformance increase. Remarkably, despite its simplicity, our proposed approachoutperforms all other methods in terms of performance. Code:https://github.com/vladan-stojnic/active-outliers</description><author>Vladan StojniÄ‡, Zakaria Laskar, Giorgos Tolias</author><pubDate>Fri, 07 Jul 2023 18:50:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03741v1</guid></item><item><title>SESCORE2: Learning Text Generation Evaluation via Synthesizing Realistic Mistakes</title><link>http://arxiv.org/abs/2212.09305v2</link><description>Is it possible to train a general metric for evaluating text generationquality without human annotated ratings? Existing learned metrics eitherperform unsatisfactorily across text generation tasks or require human ratingsfor training on specific tasks. In this paper, we propose SESCORE2, aself-supervised approach for training a model-based metric for text generationevaluation. The key concept is to synthesize realistic model mistakes byperturbing sentences retrieved from a corpus. The primary advantage of theSESCORE2 is its ease of extension to many other languages while providingreliable severity estimation. We evaluate SESCORE2 and previous methods on fourtext generation tasks across three languages. SESCORE2 outperforms unsupervisedmetric PRISM on four text generation evaluation benchmarks, with a Kendallimprovement of 0.078. Surprisingly, SESCORE2 even outperforms the supervisedBLEURT and COMET on multiple text generation tasks. The code and data areavailable at https://github.com/xu1998hz/SEScore2.</description><author>Wenda Xu, Xian Qian, Mingxuan Wang, Lei Li, William Yang Wang</author><pubDate>Fri, 07 Jul 2023 18:49:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.09305v2</guid></item><item><title>QIGen: Generating Efficient Kernels for Quantized Inference on Large Language Models</title><link>http://arxiv.org/abs/2307.03738v1</link><description>We present ongoing work on a new automatic code generation approach forsupporting quantized generative inference on LLMs such as LLaMA or OPT onoff-the-shelf CPUs. Our approach is informed by the target architecture and aperformance model, including both hardware characteristics and method-specificaccuracy constraints. Results on CPU-based inference for LLaMA models show thatour approach can lead to high performance and high accuracy, comparingfavorably to the best existing open-source solution. A preliminaryimplementation is available at https://github.com/IST-DASLab/QIGen.</description><author>Tommaso Pegolotti, Elias Frantar, Dan Alistarh, Markus PÃ¼schel</author><pubDate>Fri, 07 Jul 2023 18:46:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03738v1</guid></item><item><title>ALERT: Adapting Language Models to Reasoning Tasks</title><link>http://arxiv.org/abs/2212.08286v2</link><description>Current large language models can perform reasonably well on complex tasksthat require step-by-step reasoning with few-shot learning. Are these modelsapplying reasoning skills they have learnt during pre-training and reasonoutside of their training context, or are they simply memorizing their trainingcorpus at finer granularity and have learnt to better understand their context?To tease apart these possibilities, we introduce ALERT, a benchmark and suiteof analyses for assessing language models' reasoning ability comparingpre-trained and finetuned models on complex tasks that require reasoning skillsto solve. ALERT provides a test bed to asses any language model on fine-grainedreasoning skills, which spans over 20 datasets and covers 10 differentreasoning skills. We leverage ALERT to further investigate the role offinetuning. With extensive empirical analysis we find that language modelslearn more reasoning skills such as textual entailment, abductive reasoning,and analogical reasoning during finetuning stage compared to pretraining state.We also find that when language models are finetuned they tend to overfit tothe prompt template, which hurts the robustness of models causinggeneralization problems.</description><author>Ping Yu, Tianlu Wang, Olga Golovneva, Badr Alkhamissy, Gargi Ghosh, Mona Diab, Asli Celikyilmaz</author><pubDate>Fri, 07 Jul 2023 18:43:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.08286v2</guid></item><item><title>Improving Automatic Quotation Attribution in Literary Novels</title><link>http://arxiv.org/abs/2307.03734v1</link><description>Current models for quotation attribution in literary novels assume varyinglevels of available information in their training and test data, which poses achallenge for in-the-wild inference. Here, we approach quotation attribution asa set of four interconnected sub-tasks: character identification, coreferenceresolution, quotation identification, and speaker attribution. We benchmarkstate-of-the-art models on each of these sub-tasks independently, using a largedataset of annotated coreferences and quotations in literary novels (theProject Dialogism Novel Corpus). We also train and evaluate models for thespeaker attribution task in particular, showing that a simple sequentialprediction model achieves accuracy scores on par with state-of-the-art models.</description><author>Krishnapriya Vishnubhotla, Frank Rudzicz, Graeme Hirst, Adam Hammond</author><pubDate>Fri, 07 Jul 2023 18:37:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03734v1</guid></item><item><title>RObotic MAnipulation Network (ROMAN) $\unicode{x2013}$ Hybrid Hierarchical Learning for Solving Complex Sequential Tasks</title><link>http://arxiv.org/abs/2307.00125v2</link><description>Solving long sequential tasks poses a significant challenge in embodiedartificial intelligence. Enabling a robotic system to perform diversesequential tasks with a broad range of manipulation skills is an active area ofresearch. In this work, we present a Hybrid Hierarchical Learning framework,the Robotic Manipulation Network (ROMAN), to address the challenge of solvingmultiple complex tasks over long time horizons in robotic manipulation. ROMANachieves task versatility and robust failure recovery by integratingbehavioural cloning, imitation learning, and reinforcement learning. Itconsists of a central manipulation network that coordinates an ensemble ofvarious neural networks, each specialising in distinct re-combinable sub-tasksto generate their correct in-sequence actions for solving complex long-horizonmanipulation tasks. Experimental results show that by orchestrating andactivating these specialised manipulation experts, ROMAN generates correctsequential activations for accomplishing long sequences of sophisticatedmanipulation tasks and achieving adaptive behaviours beyond demonstrations,while exhibiting robustness to various sensory noises. These resultsdemonstrate the significance and versatility of ROMAN's dynamic adaptabilityfeaturing autonomous failure recovery capabilities, and highlight its potentialfor various autonomous manipulation tasks that demand adaptive motor skills.</description><author>Eleftherios Triantafyllidis, Fernando Acero, Zhaocheng Liu, Zhibin Li</author><pubDate>Fri, 07 Jul 2023 18:26:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00125v2</guid></item><item><title>Learning Homogenization for Elliptic Operators</title><link>http://arxiv.org/abs/2306.12006v2</link><description>Multiscale partial differential equations (PDEs) arise in variousapplications, and several schemes have been developed to solve themefficiently. Homogenization theory is a powerful methodology that eliminatesthe small-scale dependence, resulting in simplified equations that arecomputationally tractable. In the field of continuum mechanics, homogenizationis crucial for deriving constitutive laws that incorporate microscale physicsin order to formulate balance laws for the macroscopic quantities of interest.However, obtaining homogenized constitutive laws is often challenging as theydo not in general have an analytic form and can exhibit phenomena not presenton the microscale. In response, data-driven learning of the constitutive lawhas been proposed as appropriate for this task. However, a major challenge indata-driven learning approaches for this problem has remained unexplored: theimpact of discontinuities and corner interfaces in the underlying material.These discontinuities in the coefficients affect the smoothness of thesolutions of the underlying equations. Given the prevalence of discontinuousmaterials in continuum mechanics applications, it is important to address thechallenge of learning in this context; in particular to develop underpinningtheory to establish the reliability of data-driven methods in this scientificdomain. The paper addresses this unexplored challenge by investigating thelearnability of homogenized constitutive laws for elliptic operators in thepresence of such complexities. Approximation theory is presented, and numericalexperiments are performed which validate the theory for the solution operatordefined by the cell-problem arising in homogenization for elliptic PDEs.</description><author>Kaushik Bhattacharya, Nikola Kovachki, Aakila Rajan, Andrew M. Stuart, Margaret Trautner</author><pubDate>Fri, 07 Jul 2023 18:23:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12006v2</guid></item><item><title>Polybot: Training One Policy Across Robots While Embracing Variability</title><link>http://arxiv.org/abs/2307.03719v1</link><description>Reusing large datasets is crucial to scale vision-based robotic manipulatorsto everyday scenarios due to the high cost of collecting robotic datasets.However, robotic platforms possess varying control schemes, camera viewpoints,kinematic configurations, and end-effector morphologies, posing significantchallenges when transferring manipulation skills from one platform to another.To tackle this problem, we propose a set of key design decisions to train asingle policy for deployment on multiple robotic platforms. Our framework firstaligns the observation and action spaces of our policy across embodiments viautilizing wrist cameras and a unified, but modular codebase. To bridge theremaining domain shift, we align our policy's internal representations acrossembodiments through contrastive learning. We evaluate our method on a datasetcollected over 60 hours spanning 6 tasks and 3 robots with varying jointconfigurations and sizes: the WidowX 250S, the Franka Emika Panda, and theSawyer. Our results demonstrate significant improvements in success rate andsample efficiency for our policy when using new task data collected on adifferent robot, validating our proposed design decisions. More details andvideos can be found on our anonymized project website:https://sites.google.com/view/polybot-multirobot</description><author>Jonathan Yang, Dorsa Sadigh, Chelsea Finn</author><pubDate>Fri, 07 Jul 2023 18:21:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03719v1</guid></item><item><title>Scalable Multi-Agent Reinforcement Learning for Warehouse Logistics with Robotic and Human Co-Workers</title><link>http://arxiv.org/abs/2212.11498v2</link><description>We envision a warehouse in which dozens of mobile robots and human pickerswork together to collect and deliver items within the warehouse. Thefundamental problem we tackle, called the order-picking problem, is how theseworker agents must coordinate their movement and actions in the warehouse tomaximise performance (e.g. order throughput). Established industry methodsusing heuristic approaches require large engineering efforts to optimise forinnately variable warehouse configurations. In contrast, multi-agentreinforcement learning (MARL) can be flexibly applied to diverse warehouseconfigurations (e.g. size, layout, number/types of workers, item replenishmentfrequency), as the agents learn through experience how to optimally cooperatewith one another. We develop hierarchical MARL algorithms in which a managerassigns goals to worker agents, and the policies of the manager and workers areco-trained toward maximising a global objective (e.g. pick rate). Ourhierarchical algorithms achieve significant gains in sample efficiency andoverall pick rates over baseline MARL algorithms in diverse warehouseconfigurations, and substantially outperform two established industryheuristics for order-picking systems.</description><author>Aleksandar Krnjaic, Raul D. Steleac, Jonathan D. Thomas, Georgios Papoudakis, Lukas SchÃ¤fer, Andrew Wing Keung To, Kuan-Ho Lao, Murat Cubuktepe, Matthew Haley, Peter BÃ¶rsting, Stefano V. Albrecht</author><pubDate>Fri, 07 Jul 2023 18:20:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.11498v2</guid></item><item><title>Creativity of AI: Hierarchical Planning Model Learning for Facilitating Deep Reinforcement Learning</title><link>http://arxiv.org/abs/2112.09836v2</link><description>Despite of achieving great success in real-world applications, DeepReinforcement Learning (DRL) is still suffering from three critical issues,i.e., data efficiency, lack of the interpretability and transferability. Recentresearch shows that embedding symbolic knowledge into DRL is promising inaddressing those challenges. Inspired by this, we introduce a novel deepreinforcement learning framework with symbolic options. Our framework featuresa loop training procedure, which enables guiding the improvement of policy byplanning with planning models (including action models and hierarchical tasknetwork models) and symbolic options learned from interactive trajectoriesautomatically. The learned symbolic options alleviate the dense requirement ofexpert domain knowledge and provide inherent interpretability of policies.Moreover, the transferability and data efficiency can be further improved byplanning with the symbolic planning models. To validate the effectiveness ofour framework, we conduct experiments on two domains, Montezuma's Revenge andOffice World, respectively. The results demonstrate the comparable performance,improved data efficiency, interpretability and transferability.</description><author>Hankz Hankui Zhuo, Shuting Deng, Mu Jin, Zhihao Ma, Kebing Jin, Chen Chen, Chao Yu</author><pubDate>Fri, 07 Jul 2023 18:09:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.09836v2</guid></item><item><title>SAR: Generalization of Physiological Agility and Dexterity via Synergistic Action Representation</title><link>http://arxiv.org/abs/2307.03716v1</link><description>Learning effective continuous control policies in high-dimensional systems,including musculoskeletal agents, remains a significant challenge. Over thecourse of biological evolution, organisms have developed robust mechanisms forovercoming this complexity to learn highly sophisticated strategies for motorcontrol. What accounts for this robust behavioral flexibility? Modular controlvia muscle synergies, i.e. coordinated muscle co-contractions, is considered tobe one putative mechanism that enables organisms to learn muscle control in asimplified and generalizable action space. Drawing inspiration from thisevolved motor control strategy, we use physiologically accurate human hand andleg models as a testbed for determining the extent to which a SynergisticAction Representation (SAR) acquired from simpler tasks facilitates learningmore complex tasks. We find in both cases that SAR-exploiting policiessignificantly outperform end-to-end reinforcement learning. Policies trainedwith SAR were able to achieve robust locomotion on a wide set of terrains withhigh sample efficiency, while baseline approaches failed to learn meaningfulbehaviors. Additionally, policies trained with SAR on a multiobjectmanipulation task significantly outperformed (&gt;70% success) baseline approaches(&lt;20% success). Both of these SAR-exploiting policies were also found togeneralize zero-shot to out-of-domain environmental conditions, while policiesthat did not adopt SAR failed to generalize. Finally, we establish thegenerality of SAR on broader high-dimensional control problems using a roboticmanipulation task set and a full-body humanoid locomotion task. To the best ofour knowledge, this investigation is the first of its kind to present anend-to-end pipeline for discovering synergies and using this representation tolearn high-dimensional continuous control across a wide diversity of tasks.</description><author>Cameron Berg, Vittorio Caggiano, Vikash Kumar</author><pubDate>Fri, 07 Jul 2023 18:07:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03716v1</guid></item><item><title>INT-FP-QSim: Mixed Precision and Formats For Large Language Models and Vision Transformers</title><link>http://arxiv.org/abs/2307.03712v1</link><description>The recent rise of large language models (LLMs) has resulted in increasedefforts towards running LLMs at reduced precision. Running LLMs at lowerprecision supports resource constraints and furthers their democratization,enabling users to run billion-parameter LLMs on their personal devices. Tosupplement this ongoing effort, we propose INT-FP-QSim: an open-sourcesimulator that enables flexible evaluation of LLMs and vision transformers atvarious numerical precisions and formats. INT-FP-QSim leverages existingopen-source repositories such as TensorRT, QPytorch and AIMET for a combinedsimulator that supports various floating point and integer formats. With thehelp of our simulator, we survey the impact of different numerical formats onthe performance of LLMs and vision transformers at 4-bit weights and 4-bit or8-bit activations. We also compare recently proposed methods like AdaptiveBlock Floating Point, SmoothQuant, GPTQ and RPTQ on the model performances. Wehope INT-FP-QSim will enable researchers to flexibly simulate models at variousprecisions to support further research in quantization of LLMs and visiontransformers.</description><author>Lakshmi Nair, Mikhail Bernadskiy, Arulselvan Madhavan, Craig Chan, Ayon Basumallik, Darius Bunandar</author><pubDate>Fri, 07 Jul 2023 17:54:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03712v1</guid></item><item><title>LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by Whispering to ChatGPT</title><link>http://arxiv.org/abs/2306.17103v2</link><description>We introduce LyricWhiz, a robust, multilingual, and zero-shot automaticlyrics transcription method achieving state-of-the-art performance on variouslyrics transcription datasets, even in challenging genres such as rock andmetal. Our novel, training-free approach utilizes Whisper, a weakly supervisedrobust speech recognition model, and GPT-4, today's most performant chat-basedlarge language model. In the proposed method, Whisper functions as the "ear" bytranscribing the audio, while GPT-4 serves as the "brain," acting as anannotator with a strong performance for contextualized output selection andcorrection. Our experiments show that LyricWhiz significantly reduces WordError Rate compared to existing methods in English and can effectivelytranscribe lyrics across multiple languages. Furthermore, we use LyricWhiz tocreate the first publicly available, large-scale, multilingual lyricstranscription dataset with a CC-BY-NC-SA copyright license, based onMTG-Jamendo, and offer a human-annotated subset for noise level estimation andevaluation. We anticipate that our proposed method and dataset will advance thedevelopment of multilingual lyrics transcription, a challenging and emergingtask.</description><author>Le Zhuo, Ruibin Yuan, Jiahao Pan, Yinghao Ma, Yizhi LI, Ge Zhang, Si Liu, Roger Dannenberg, Jie Fu, Chenghua Lin, Emmanouil Benetos, Wenhu Chen, Wei Xue, Yike Guo</author><pubDate>Fri, 07 Jul 2023 17:32:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17103v2</guid></item><item><title>Intelligent Robotic Sonographer: Mutual Information-based Disentangled Reward Learning from Few Demonstrations</title><link>http://arxiv.org/abs/2307.03705v1</link><description>Ultrasound (US) imaging is widely used for biometric measurement anddiagnosis of internal organs due to the advantages of being real-time andradiation-free. However, due to high inter-operator variability, resultingimages highly depend on operators' experience. In this work, an intelligentrobotic sonographer is proposed to autonomously "explore" target anatomies andnavigate a US probe to a relevant 2D plane by learning from expert. Theunderlying high-level physiological knowledge from experts is inferred by aneural reward function, using a ranked pairwise image comparisons approach in aself-supervised fashion. This process can be referred to as understanding the"language of sonography". Considering the generalization capability to overcomeinter-patient variations, mutual information is estimated by a network toexplicitly extract the task-related and domain features in latent space.Besides, a Gaussian distribution-based filter is developed to automaticallyevaluate and take the quality of the expert's demonstrations into account. Therobotic localization is carried out in coarse-to-fine mode based on thepredicted reward associated to B-mode images. To demonstrate the performance ofthe proposed approach, representative experiments for the "line" target and"point" target are performed on vascular phantom and two ex-vivo animal organphantoms (chicken heart and lamb kidney), respectively. The resultsdemonstrated that the proposed advanced framework can robustly work ondifferent kinds of known and unseen phantoms.</description><author>Zhongliang Jiang, Yuan Bi, Mingchuan Zhou, Ying Hu, Michael Burke, and Nassir Navab</author><pubDate>Fri, 07 Jul 2023 17:30:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03705v1</guid></item><item><title>Equivariant Single View Pose Prediction Via Induced and Restricted Representations</title><link>http://arxiv.org/abs/2307.03704v1</link><description>Learning about the three-dimensional world from two-dimensional images is afundamental problem in computer vision. An ideal neural network architecturefor such tasks would leverage the fact that objects can be rotated andtranslated in three dimensions to make predictions about novel images. However,imposing SO(3)-equivariance on two-dimensional inputs is difficult because thegroup of three-dimensional rotations does not have a natural action on thetwo-dimensional plane. Specifically, it is possible that an element of SO(3)will rotate an image out of plane. We show that an algorithm that learns athree-dimensional representation of the world from two dimensional images mustsatisfy certain geometric consistency properties which we formulate asSO(2)-equivariance constraints. We use the induced and restrictedrepresentations of SO(2) on SO(3) to construct and classify architectures whichsatisfy these geometric consistency constraints. We prove that any architecturewhich respects said consistency constraints can be realized as an instance ofour construction. We show that three previously proposed neural architecturesfor 3D pose prediction are special cases of our construction. We propose a newalgorithm that is a learnable generalization of previously considered methods.We test our architecture on three pose predictions task and achieve SOTAresults on both the PASCAL3D+ and SYMSOL pose estimation tasks.</description><author>Owen Howell, David Klee, Ondrej Biza, Linfeng Zhao, Robin Walters</author><pubDate>Fri, 07 Jul 2023 17:30:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03704v1</guid></item><item><title>Language Models are Bounded Pragmatic Speakers: Understanding RLHF from a Bayesian Cognitive Modeling Perspective</title><link>http://arxiv.org/abs/2305.17760v4</link><description>How do language models "think"? This paper formulates a probabilisticcognitive model called the bounded pragmatic speaker, which can characterizethe operation of different variations of language models. Specifically, wedemonstrate that large language models fine-tuned with reinforcement learningfrom human feedback (Ouyang et al., 2022) embody a model of thought thatconceptually resembles a fast-and-slow model (Kahneman, 2011), whichpsychologists have attributed to humans. We discuss the limitations ofreinforcement learning from human feedback as a fast-and-slow model of thoughtand propose avenues for expanding this framework. In essence, our researchhighlights the value of adopting a cognitive probabilistic modeling approach togain insights into the comprehension, evaluation, and advancement of languagemodels.</description><author>Khanh Nguyen</author><pubDate>Fri, 07 Jul 2023 17:21:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17760v4</guid></item><item><title>Coupled Gradient Flows for Strategic Non-Local Distribution Shift</title><link>http://arxiv.org/abs/2307.01166v2</link><description>We propose a novel framework for analyzing the dynamics of distribution shiftin real-world systems that captures the feedback loop between learningalgorithms and the distributions on which they are deployed. Prior work largelymodels feedback-induced distribution shift as adversarial or via an overlysimplistic distribution-shift structure. In contrast, we propose a coupledpartial differential equation model that captures fine-grained changes in thedistribution over time by accounting for complex dynamics that arise due tostrategic responses to algorithmic decision-making, non-local endogenouspopulation interactions, and other exogenous sources of distribution shift. Weconsider two common settings in machine learning: cooperative settings withinformation asymmetries, and competitive settings where a learner facesstrategic users. For both of these settings, when the algorithm retrains viagradient descent, we prove asymptotic convergence of the retraining procedureto a steady-state, both in finite and in infinite dimensions, obtainingexplicit rates in terms of the model parameters. To do so we derive new resultson the convergence of coupled PDEs that extends what is known on multi-speciessystems. Empirically, we show that our approach captures well-documented formsof distribution shifts like polarization and disparate impacts that simplermodels cannot capture.</description><author>Lauren Conger, Franca Hoffmann, Eric Mazumdar, Lillian Ratliff</author><pubDate>Fri, 07 Jul 2023 17:18:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01166v2</guid></item><item><title>ChatCAD+: Towards a Universal and Reliable Interactive CAD using LLMs</title><link>http://arxiv.org/abs/2305.15964v4</link><description>The integration of Computer-Assisted Diagnosis (CAD) with Large LanguageModels (LLMs) holds great potential in clinical applications, specifically inthe roles of virtual family doctors and clinic assistants. However, currentworks in this field are plagued by limitations, specifically a restricted scopeof applicable image domains and the provision of unreliable medical advice.This restricts their overall processing capabilities. Furthermore, the mismatchin writing style between LLMs and radiologists undermines their practicalusefulness. To tackle these challenges, we introduce ChatCAD+, which isdesigned to be universal and reliable. It is capable of handling medical imagesfrom diverse domains and leveraging up-to-date information from reputablemedical websites to provide reliable medical advice. Additionally, itincorporates a template retrieval system that improves report generationperformance via exemplar reports. This approach ensures greater consistencywith the expertise of human professionals. The source code is available athttps://github.com/zhaozh10/ChatCAD.</description><author>Zihao Zhao, Sheng Wang, Jinchen Gu, Yitao Zhu, Lanzhuju Mei, Zixu Zhuang, Zhiming Cui, Qian Wang, Dinggang Shen</author><pubDate>Fri, 07 Jul 2023 17:16:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15964v4</guid></item><item><title>Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media</title><link>http://arxiv.org/abs/2307.03699v1</link><description>Social media platforms such as Instagram and Twitter have emerged as criticalchannels for drug marketing and illegal sale. Detecting and labeling onlineillicit drug trafficking activities becomes important in addressing this issue.However, the effectiveness of conventional supervised learning methods indetecting drug trafficking heavily relies on having access to substantialamounts of labeled data, while data annotation is time-consuming andresource-intensive. Furthermore, these models often face challenges inaccurately identifying trafficking activities when drug dealers use deceptivelanguage and euphemisms to avoid detection. To overcome this limitation, weconduct the first systematic study on leveraging large language models (LLMs),such as ChatGPT, to detect illicit drug trafficking activities on social media.We propose an analytical framework to compose \emph{knowledge-informedprompts}, which serve as the interface that humans can interact with and useLLMs to perform the detection task. Additionally, we design a Monte Carlodropout based prompt optimization method to further to improve performance andinterpretability. Our experimental findings demonstrate that the proposedframework outperforms other baseline language models in terms of drugtrafficking detection accuracy, showing a remarkable improvement of nearly12\%. By integrating prior knowledge and the proposed prompts, ChatGPT caneffectively identify and label drug trafficking activities on social networks,even in the presence of deceptive language and euphemisms used by drug dealersto evade detection. The implications of our research extend to social networks,emphasizing the importance of incorporating prior knowledge and scenario-basedprompts into analytical tools to improve online security and public safety.</description><author>Chuanbo Hu, Bin Liu, Xin Li, Yanfang Ye</author><pubDate>Fri, 07 Jul 2023 17:15:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03699v1</guid></item><item><title>Motion Magnification in Robotic Sonography: Enabling Pulsation-Aware Artery Segmentation</title><link>http://arxiv.org/abs/2307.03698v1</link><description>Ultrasound (US) imaging is widely used for diagnosing and monitoring arterialdiseases, mainly due to the advantages of being non-invasive, radiation-free,and real-time. In order to provide additional information to assist cliniciansin diagnosis, the tubular structures are often segmented from US images. Toimprove the artery segmentation accuracy and stability during scans, this workpresents a novel pulsation-assisted segmentation neural network (PAS-NN) byexplicitly taking advantage of the cardiac-induced motions. Motionmagnification techniques are employed to amplify the subtle motion within thefrequency band of interest to extract the pulsation signals from sequential USimages. The extracted real-time pulsation information can help to locate thearteries on cross-section US images; therefore, we explicitly integrated thepulsation into the proposed PAS-NN as attention guidance. Notably, a roboticarm is necessary to provide stable movement during US imaging since magnifyingthe target motions from the US images captured along a scan path is notmanually feasible due to the hand tremor. To validate the proposed robotic USsystem for imaging arteries, experiments are carried out on volunteers' carotidand radial arteries. The results demonstrated that the PAS-NN could achievecomparable results as state-of-the-art on carotid and can effectively improvethe segmentation performance for small vessels (radial artery).</description><author>Dianye Huang, Yuan Bi, Nassir Navab, Zhongliang Jiang</author><pubDate>Fri, 07 Jul 2023 17:14:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03698v1</guid></item><item><title>Scalable Membership Inference Attacks via Quantile Regression</title><link>http://arxiv.org/abs/2307.03694v1</link><description>Membership inference attacks are designed to determine, using black boxaccess to trained models, whether a particular example was used in training ornot. Membership inference can be formalized as a hypothesis testing problem.The most effective existing attacks estimate the distribution of some teststatistic (usually the model's confidence on the true label) on points thatwere (and were not) used in training by training many \emph{shadow models} --i.e. models of the same architecture as the model being attacked, trained on arandom subsample of data. While effective, these attacks are extremelycomputationally expensive, especially when the model under attack is large. We introduce a new class of attacks based on performing quantile regressionon the distribution of confidence scores induced by the model under attack onpoints that are not used in training. We show that our method is competitivewith state-of-the-art shadow model attacks, while requiring substantially lesscompute because our attack requires training only a single model. Moreover,unlike shadow model attacks, our proposed attack does not require any knowledgeof the architecture of the model under attack and is therefore truly``black-box". We show the efficacy of this approach in an extensive series ofexperiments on various datasets and model architectures.</description><author>Martin Bertran, Shuai Tang, Michael Kearns, Jamie Morgenstern, Aaron Roth, Zhiwei Steven Wu</author><pubDate>Fri, 07 Jul 2023 17:07:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03694v1</guid></item><item><title>Equivariance with Learned Canonicalization Functions</title><link>http://arxiv.org/abs/2211.06489v3</link><description>Symmetry-based neural networks often constrain the architecture in order toachieve invariance or equivariance to a group of transformations. In thispaper, we propose an alternative that avoids this architectural constraint bylearning to produce canonical representations of the data. Thesecanonicalization functions can readily be plugged into non-equivariant backbonearchitectures. We offer explicit ways to implement them for some groups ofinterest. We show that this approach enjoys universality while providinginterpretable insights. Our main hypothesis, supported by our empiricalresults, is that learning a small neural network to perform canonicalization isbetter than using predefined heuristics. Our experiments show that learning thecanonicalization function is competitive with existing techniques for learningequivariant functions across many tasks, including image classification,$N$-body dynamics prediction, point cloud classification and part segmentation,while being faster across the board.</description><author>SÃ©kou-Oumar Kaba, Arnab Kumar Mondal, Yan Zhang, Yoshua Bengio, Siamak Ravanbakhsh</author><pubDate>Fri, 07 Jul 2023 16:55:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.06489v3</guid></item><item><title>Differentiable Turbulence</title><link>http://arxiv.org/abs/2307.03683v1</link><description>Deep learning is increasingly becoming a promising pathway to improving theaccuracy of sub-grid scale (SGS) turbulence closure models for large eddysimulations (LES). We leverage the concept of differentiable turbulence,whereby an end-to-end differentiable solver is used in combination withphysics-inspired choices of deep learning architectures to learn highlyeffective and versatile SGS models for two-dimensional turbulent flow. Weperform an in-depth analysis of the inductive biases in the chosenarchitectures, finding that the inclusion of small-scale non-local features ismost critical to effective SGS modeling, while large-scale features can improvepointwise accuracy of the a-posteriori solution field. The filtered velocitygradient tensor can be mapped directly to the SGS stress via decomposition ofthe inputs and outputs into isotropic, deviatoric, and anti-symmetriccomponents. We see that the model can generalize to a variety of flowconfigurations, including higher and lower Reynolds numbers and differentforcing conditions. We show that the differentiable physics paradigm is moresuccessful than offline, a-priori learning, and that hybrid solver-in-the-loopapproaches to deep learning offer an ideal balance between computationalefficiency, accuracy, and generalization. Our experiments provide physics-basedrecommendations for deep-learning based SGS modeling for generalizable closuremodeling of turbulence.</description><author>Varun Shankar, Romit Maulik, Venkatasubramanian Viswanathan</author><pubDate>Fri, 07 Jul 2023 16:51:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03683v1</guid></item><item><title>GeoPhy: Differentiable Phylogenetic Inference via Geometric Gradients of Tree Topologies</title><link>http://arxiv.org/abs/2307.03675v1</link><description>Phylogenetic inference, grounded in molecular evolution models, is essentialfor understanding the evolutionary relationships in biological data. Accountingfor the uncertainty of phylogenetic tree variables, which include treetopologies and evolutionary distances on branches, is crucial for accuratelyinferring species relationships from molecular data and tasks requiringvariable marginalization. Variational Bayesian methods are key to developingscalable, practical models; however, it remains challenging to conductphylogenetic inference without restricting the combinatorially vast number ofpossible tree topologies. In this work, we introduce a novel, fullydifferentiable formulation of phylogenetic inference that leverages a uniquerepresentation of topological distributions in continuous geometric spaces.Through practical considerations on design spaces and control variates forgradient estimations, our approach, GeoPhy, enables variational inferencewithout limiting the topological candidates. In experiments using realbenchmark datasets, GeoPhy significantly outperformed other approximateBayesian methods that considered whole topologies.</description><author>Takahiro Mimori, Michiaki Hamada</author><pubDate>Fri, 07 Jul 2023 16:45:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03675v1</guid></item><item><title>Simulation-free SchrÃ¶dinger bridges via score and flow matching</title><link>http://arxiv.org/abs/2307.03672v1</link><description>We present simulation-free score and flow matching ([SF]$^2$M), asimulation-free objective for inferring stochastic dynamics given unpairedsource and target samples drawn from arbitrary distributions. Our methodgeneralizes both the score-matching loss used in the training of diffusionmodels and the recently proposed flow matching loss used in the training ofcontinuous normalizing flows. [SF]$^2$M interprets continuous-time stochasticgenerative modeling as a Schr\"odinger bridge (SB) problem. It relies on staticentropy-regularized optimal transport, or a minibatch approximation, toefficiently learn the SB without simulating the learned stochastic process. Wefind that [SF]$^2$M is more efficient and gives more accurate solutions to theSB problem than simulation-based methods from prior work. Finally, we apply[SF]$^2$M to the problem of learning cell dynamics from snapshot data. Notably,[SF]$^2$M is the first method to accurately model cell dynamics in highdimensions and can recover known gene regulatory networks from simulated data.</description><author>Alexander Tong, Nikolay Malkin, Kilian Fatras, Lazar Atanackovic, Yanlei Zhang, Guillaume Huguet, Guy Wolf, Yoshua Bengio</author><pubDate>Fri, 07 Jul 2023 16:42:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03672v1</guid></item><item><title>Testing the Predictions of Surprisal Theory in 11 Languages</title><link>http://arxiv.org/abs/2307.03667v1</link><description>A fundamental result in psycholinguistics is that less predictable words takea longer time to process. One theoretical explanation for this finding isSurprisal Theory (Hale, 2001; Levy, 2008), which quantifies a word'spredictability as its surprisal, i.e. its negative log-probability given acontext. While evidence supporting the predictions of Surprisal Theory havebeen replicated widely, most have focused on a very narrow slice of data:native English speakers reading English texts. Indeed, no comprehensivemultilingual analysis exists. We address this gap in the current literature byinvestigating the relationship between surprisal and reading times in elevendifferent languages, distributed across five language families. Derivingestimates from language models trained on monolingual and multilingual corpora,we test three predictions associated with surprisal theory: (i) whethersurprisal is predictive of reading times; (ii) whether expected surprisal, i.e.contextual entropy, is predictive of reading times; (iii) and whether thelinking function between surprisal and reading times is linear. We find thatall three predictions are borne out crosslinguistically. By focusing on a morediverse set of languages, we argue that these results offer the most robustlink to-date between information theory and incremental language processingacross languages.</description><author>Ethan Gotlieb Wilcox, Tiago Pimentel, Clara Meister, Ryan Cotterell, Roger P. Levy</author><pubDate>Fri, 07 Jul 2023 16:37:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03667v1</guid></item><item><title>Detecting the Sensing Area of A Laparoscopic Probe in Minimally Invasive Cancer Surgery</title><link>http://arxiv.org/abs/2307.03662v1</link><description>In surgical oncology, it is challenging for surgeons to identify lymph nodesand completely resect cancer even with pre-operative imaging systems like PETand CT, because of the lack of reliable intraoperative visualization tools.Endoscopic radio-guided cancer detection and resection has recently beenevaluated whereby a novel tethered laparoscopic gamma detector is used tolocalize a preoperatively injected radiotracer. This can both enhance theendoscopic imaging and complement preoperative nuclear imaging data. However,gamma activity visualization is challenging to present to the operator becausethe probe is non-imaging and it does not visibly indicate the activityorigination on the tissue surface. Initial failed attempts used segmentation orgeometric methods, but led to the discovery that it could be resolved byleveraging high-dimensional image features and probe position information. Todemonstrate the effectiveness of this solution, we designed and implemented asimple regression network that successfully addressed the problem. To furthervalidate the proposed solution, we acquired and publicly released two datasetscaptured using a custom-designed, portable stereo laparoscope system. Throughintensive experimentation, we demonstrated that our method can successfully andeffectively detect the sensing area, establishing a new performance benchmark.Code and data are available athttps://github.com/br0202/Sensing_area_detection.git</description><author>Baoru Huang, Yicheng Hu, Anh Nguyen, Stamatia Giannarou, Daniel S. Elson</author><pubDate>Fri, 07 Jul 2023 16:33:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03662v1</guid></item><item><title>Decomposing the Generalization Gap in Imitation Learning for Visual Robotic Manipulation</title><link>http://arxiv.org/abs/2307.03659v1</link><description>What makes generalization hard for imitation learning in visual roboticmanipulation? This question is difficult to approach at face value, but theenvironment from the perspective of a robot can often be decomposed intoenumerable factors of variation, such as the lighting conditions or theplacement of the camera. Empirically, generalization to some of these factorshave presented a greater obstacle than others, but existing work sheds littlelight on precisely how much each factor contributes to the generalization gap.Towards an answer to this question, we study imitation learning policies insimulation and on a real robot language-conditioned manipulation task toquantify the difficulty of generalization to different (sets of) factors. Wealso design a new simulated benchmark of 19 tasks with 11 factors of variationto facilitate more controlled evaluations of generalization. From our study, wedetermine an ordering of factors based on generalization difficulty, that isconsistent across simulation and our real robot setup.</description><author>Annie Xie, Lisa Lee, Ted Xiao, Chelsea Finn</author><pubDate>Fri, 07 Jul 2023 16:26:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03659v1</guid></item><item><title>The distribution of discourse relations within and across turns in spontaneous conversation</title><link>http://arxiv.org/abs/2307.03645v1</link><description>Time pressure and topic negotiation may impose constraints on how peopleleverage discourse relations (DRs) in spontaneous conversational contexts. Inthis work, we adapt a system of DRs for written language to spontaneousdialogue using crowdsourced annotations from novice annotators. We then testwhether discourse relations are used differently across several types ofmulti-utterance contexts. We compare the patterns of DR annotation within andacross speakers and within and across turns. Ultimately, we find that differentdiscourse contexts produce distinct distributions of discourse relations, withsingle-turn annotations creating the most uncertainty for annotators.Additionally, we find that the discourse relation annotations are of sufficientquality to predict from embeddings of discourse units.</description><author>S. MagalÃ­ LÃ³pez Cortez, Cassandra L. Jacobs</author><pubDate>Fri, 07 Jul 2023 16:06:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03645v1</guid></item><item><title>Online Network Source Optimization with Graph-Kernel MAB</title><link>http://arxiv.org/abs/2307.03641v1</link><description>We propose Grab-UCB, a graph-kernel multi-arms bandit algorithm to learnonline the optimal source placement in large scale networks, such that thereward obtained from a priori unknown network processes is maximized. Theuncertainty calls for online learning, which suffers however from the curse ofdimensionality. To achieve sample efficiency, we describe the network processeswith an adaptive graph dictionary model, which typically leads to sparsespectral representations. This enables a data-efficient learning framework,whose learning rate scales with the dimension of the spectral representationmodel instead of the one of the network. We then propose Grab-UCB, an onlinesequential decision strategy that learns the parameters of the spectralrepresentation while optimizing the action strategy. We derive the performanceguarantees that depend on network parameters, which further influence thelearning curve of the sequential decision strategy We introduce acomputationally simplified solving method, Grab-arm-Light, an algorithm thatwalks along the edges of the polytope representing the objective function.Simulations results show that the proposed online learning algorithmoutperforms baseline offline methods that typically separate the learning phasefrom the testing one. The results confirm the theoretical findings, and furtherhighlight the gain of the proposed online learning strategy in terms ofcumulative regret, sample efficiency and computational complexity.</description><author>Laura Toni, Pascal Frossard</author><pubDate>Fri, 07 Jul 2023 16:03:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03641v1</guid></item><item><title>Continuous-Time Functional Diffusion Processes</title><link>http://arxiv.org/abs/2303.00800v2</link><description>We introduce Functional Diffusion Processes (FDPs), which generalizescore-based diffusion models to infinite-dimensional function spaces. FDPsrequire a new mathematical framework to describe the forward and backwarddynamics, and several extensions to derive practical training objectives. Theseinclude infinite-dimensional versions of Girsanov theorem, in order to be ableto compute an ELBO, and of the sampling theorem, in order to guarantee thatfunctional evaluations in a countable set of points are equivalent toinfinite-dimensional functions. We use FDPs to build a new breed of generativemodels in function spaces, which do not require specialized networkarchitectures, and that can work with any kind of continuous data. Our resultson real data show that FDPs achieve high-quality image generation, using asimple MLP architecture with orders of magnitude fewer parameters than existingdiffusion models.</description><author>Giulio Franzese, Giulio Corallo, Simone Rossi, Markus Heinonen, Maurizio Filippone, Pietro Michiardi</author><pubDate>Fri, 07 Jul 2023 15:55:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.00800v2</guid></item><item><title>Discovering Variable Binding Circuitry with Desiderata</title><link>http://arxiv.org/abs/2307.03637v1</link><description>Recent work has shown that computation in language models may behuman-understandable, with successful efforts to localize and intervene on bothsingle-unit features and input-output circuits. Here, we introduce an approachwhich extends causal mediation experiments to automatically identify modelcomponents responsible for performing a specific subtask by solely specifying aset of \textit{desiderata}, or causal attributes of the model componentsexecuting that subtask. As a proof of concept, we apply our method toautomatically discover shared \textit{variable binding circuitry} in LLaMA-13B,which retrieves variable values for multiple arithmetic tasks. Our methodsuccessfully localizes variable binding to only 9 attention heads (of the 1.6k)and one MLP in the final token's residual stream.</description><author>Xander Davies, Max Nadeau, Nikhil Prakash, Tamar Rott Shaham, David Bau</author><pubDate>Fri, 07 Jul 2023 15:51:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03637v1</guid></item><item><title>Multiclass Online Learning and Uniform Convergence</title><link>http://arxiv.org/abs/2303.17716v2</link><description>We study multiclass classification in the agnostic adversarial onlinelearning setting. As our main result, we prove that any multiclass conceptclass is agnostically learnable if and only if its Littlestone dimension isfinite. This solves an open problem studied by Daniely, Sabato, Ben-David, andShalev-Shwartz (2011,2015) who handled the case when the number of classes (orlabels) is bounded. We also prove a separation between online learnability andonline uniform convergence by exhibiting an easy-to-learn class whosesequential Rademacher complexity is unbounded. Our learning algorithm uses the multiplicative weights algorithm, with a setof experts defined by executions of the Standard Optimal Algorithm onsubsequences of size Littlestone dimension. We argue that the best expert hasregret at most Littlestone dimension relative to the best concept in the class.This differs from the well-known covering technique of Ben-David, P\'{a}l, andShalev-Shwartz (2009) for binary classification, where the best expert hasregret zero.</description><author>Steve Hanneke, Shay Moran, Vinod Raman, Unique Subedi, Ambuj Tewari</author><pubDate>Fri, 07 Jul 2023 15:45:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.17716v2</guid></item><item><title>PAC bounds of continuous Linear Parameter-Varying systems related to neural ODEs</title><link>http://arxiv.org/abs/2307.03630v1</link><description>We consider the problem of learning Neural Ordinary Differential Equations(neural ODEs) within the context of Linear Parameter-Varying (LPV) systems incontinuous-time. LPV systems contain bilinear systems which are known to beuniversal approximators for non-linear systems. Moreover, a large class ofneural ODEs can be embedded into LPV systems. As our main contribution weprovide Probably Approximately Correct (PAC) bounds under stability for LPVsystems related to neural ODEs. The resulting bounds have the advantage thatthey do not depend on the integration interval.</description><author>DÃ¡niel RÃ¡cz, MihÃ¡ly Petreczky, BÃ¡lint DarÃ³czy</author><pubDate>Fri, 07 Jul 2023 15:39:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03630v1</guid></item><item><title>On the Evolution of (Hateful) Memes by Means of Multimodal Contrastive Learning</title><link>http://arxiv.org/abs/2212.06573v2</link><description>The dissemination of hateful memes online has adverse effects on social mediaplatforms and the real world. Detecting hateful memes is challenging, one ofthe reasons being the evolutionary nature of memes; new hateful memes canemerge by fusing hateful connotations with other cultural ideas or symbols. Inthis paper, we propose a framework that leverages multimodal contrastivelearning models, in particular OpenAI's CLIP, to identify targets of hatefulcontent and systematically investigate the evolution of hateful memes. We findthat semantic regularities exist in CLIP-generated embeddings that describesemantic relationships within the same modality (images) or across modalities(images and text). Leveraging this property, we study how hateful memes arecreated by combining visual elements from multiple images or fusing textualinformation with a hateful image. We demonstrate the capabilities of ourframework for analyzing the evolution of hateful memes by focusing onantisemitic memes, particularly the Happy Merchant meme. Using our framework ona dataset extracted from 4chan, we find 3.3K variants of the Happy Merchantmeme, with some linked to specific countries, persons, or organizations. Weenvision that our framework can be used to aid human moderators by flagging newvariants of hateful memes so that moderators can manually verify them andmitigate the problem of hateful content online.</description><author>Yiting Qu, Xinlei He, Shannon Pierson, Michael Backes, Yang Zhang, Savvas Zannettou</author><pubDate>Fri, 07 Jul 2023 15:24:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.06573v2</guid></item><item><title>Robust Human Detection under Visual Degradation via Thermal and mmWave Radar Fusion</title><link>http://arxiv.org/abs/2307.03623v1</link><description>The majority of human detection methods rely on the sensor using visiblelights (e.g., RGB cameras) but such sensors are limited in scenarios withdegraded vision conditions. In this paper, we present a multimodal humandetection system that combines portable thermal cameras and single-chip mmWaveradars. To mitigate the noisy detection features caused by the low contrast ofthermal cameras and the multi-path noise of radar point clouds, we propose aBayesian feature extractor and a novel uncertainty-guided fusion method thatsurpasses a variety of competing methods, either single-modal or multi-modal.We evaluate the proposed method on real-world data collection and demonstratethat our approach outperforms the state-of-the-art methods by a large margin.</description><author>Kaiwen Cai, Qiyue Xia, Peize Li, John Stankovic, Chris Xiaoxuan Lu</author><pubDate>Fri, 07 Jul 2023 15:23:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03623v1</guid></item><item><title>Self-Supervised Time Series Representation Learning via Cross Reconstruction Transformer</title><link>http://arxiv.org/abs/2205.09928v2</link><description>Unsupervised/self-supervised representation learning in time series iscritical since labeled samples are usually scarce in real-world scenarios.Existing approaches mainly leverage the contrastive learning framework, whichautomatically learns to understand the similar and dissimilar data pairs.Nevertheless, they are restricted to the prior knowledge of constructing pairs,cumbersome sampling policy, and unstable performances when encounteringsampling bias. Also, few works have focused on effectively modeling acrosstemporal-spectral relations to extend the capacity of representations. In thispaper, we aim at learning representations for time series from a newperspective and propose Cross Reconstruction Transformer (CRT) to solve theaforementioned problems in a unified way. CRT achieves time seriesrepresentation learning through a cross-domain dropping-reconstruction task.Specifically, we transform time series into the frequency domain and randomlydrop certain parts in both time and frequency domains. Dropping can maximallypreserve the global context compared to cropping and masking. Then atransformer architecture is utilized to adequately capture the cross-domaincorrelations between temporal and spectral information through reconstructingdata in both domains, which is called Dropped Temporal-Spectral Modeling. Todiscriminate the representations in global latent space, we propose InstanceDiscrimination Constraint to reduce the mutual information between differenttime series and sharpen the decision boundaries. Additionally, we propose aspecified curriculum learning strategy to optimize the CRT, which progressivelyincreases the dropping ratio in the training process.</description><author>Wenrui Zhang, Ling Yang, Shijia Geng, Shenda Hong</author><pubDate>Fri, 07 Jul 2023 15:15:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.09928v2</guid></item><item><title>Weaker Than You Think: A Critical Look at Weakly Supervised Learning</title><link>http://arxiv.org/abs/2305.17442v2</link><description>Weakly supervised learning is a popular approach for training machinelearning models in low-resource settings. Instead of requesting high-qualityyet costly human annotations, it allows training models with noisy annotationsobtained from various weak sources. Recently, many sophisticated approacheshave been proposed for robust training under label noise, reporting impressiveresults. In this paper, we revisit the setup of these approaches and find thatthe benefits brought by these approaches are significantly overestimated.Specifically, we find that the success of existing weakly supervised learningapproaches heavily relies on the availability of clean validation sampleswhich, as we show, can be leveraged much more efficiently by simply training onthem. After using these clean labels in training, the advantages of using thesesophisticated approaches are mostly wiped out. This remains true even whenreducing the size of the available clean data to just five samples per class,making these approaches impractical. To understand the true value of weaklysupervised learning, we thoroughly analyze diverse NLP datasets and tasks toascertain when and why weakly supervised approaches work. Based on ourfindings, we provide recommendations for future research.</description><author>Dawei Zhu, Xiaoyu Shen, Marius Mosbach, Andreas Stephan, Dietrich Klakow</author><pubDate>Fri, 07 Jul 2023 14:56:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17442v2</guid></item><item><title>Auxiliary Functions as Koopman Observables: Data-Driven Polynomial Optimization for Dynamical Systems</title><link>http://arxiv.org/abs/2303.01483v2</link><description>We present a flexible data-driven method for dynamical system analysis thatdoes not require explicit model discovery. The method is rooted inwell-established techniques for approximating the Koopman operator from dataand is implemented as a semidefinite program that can be solved numerically.Furthermore, the method is agnostic of whether data is generated through adeterministic or stochastic process, so its implementation requires no prioradjustments by the user to accommodate these different scenarios. Rigorousconvergence results justify the applicability of the method, while alsoextending and uniting similar results from across the literature. Examples ondiscovering Lyapunov functions, performing ergodic optimization, and boundingextrema over attractors for both deterministic and stochastic dynamicsexemplify these convergence results and demonstrate the performance of themethod.</description><author>Jason J. Bramburger, Giovanni Fantuzzi</author><pubDate>Fri, 07 Jul 2023 14:55:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.01483v2</guid></item><item><title>Depth Estimation Analysis of Orthogonally Divergent Fisheye Cameras with Distortion Removal</title><link>http://arxiv.org/abs/2307.03602v1</link><description>Stereo vision systems have become popular in computer vision applications,such as 3D reconstruction, object tracking, and autonomous navigation. However,traditional stereo vision systems that use rectilinear lenses may not besuitable for certain scenarios due to their limited field of view. This has ledto the popularity of vision systems based on one or multiple fisheye cameras indifferent orientations, which can provide a field of view of 180x180 degrees ormore. However, fisheye cameras introduce significant distortion at the edgesthat affects the accuracy of stereo matching and depth estimation. To overcomethese limitations, this paper proposes a method for distortion-removal anddepth estimation analysis for stereovision system using orthogonally divergentfisheye cameras (ODFC). The proposed method uses two virtual pinhole cameras(VPC), each VPC captures a small portion of the original view and presents itwithout any lens distortions, emulating the behavior of a pinhole camera. Bycarefully selecting the captured regions, it is possible to create a stereopair using two VPCs. The performance of the proposed method is evaluated inboth simulation using virtual environment and experiments using real camerasand their results compared to stereo cameras with parallel optical axes. Theresults demonstrate the effectiveness of the proposed method in terms ofdistortion removal and depth estimation accuracy.</description><author>Matvei Panteleev, Houari Bettahar</author><pubDate>Fri, 07 Jul 2023 14:44:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03602v1</guid></item><item><title>Topical: Learning Repository Embeddings from Source Code using Attention</title><link>http://arxiv.org/abs/2208.09495v2</link><description>Machine learning on source code (MLOnCode) promises to transform how softwareis delivered. By mining the context and relationship between softwareartefacts, MLOnCode augments the software developers capabilities with codeauto-generation, code recommendation, code auto-tagging and other data-drivenenhancements. For many of these tasks a script level representation of code issufficient, however, in many cases a repository level representation that takesinto account various dependencies and repository structure is imperative, forexample, auto-tagging repositories with topics or auto-documentation ofrepository code etc. Existing methods for computing repository levelrepresentations suffer from (a) reliance on natural language documentation ofcode (for example, README files) (b) naive aggregation of method/script-levelrepresentation, for example, by concatenation or averaging. This paperintroduces Topical a deep neural network to generate repository levelembeddings of publicly available GitHub code repositories directly from sourcecode. Topical incorporates an attention mechanism that projects the sourcecode, the full dependency graph and the script level textual information into adense repository-level representation. To compute the repository-levelrepresentations, Topical is trained to predict the topics associated with arepository, on a dataset of publicly available GitHub repositories that werecrawled along with their ground truth topic tags. Our experiments show that theembeddings computed by Topical are able to outperform multiple baselines,including baselines that naively combine the method-level representationsthrough averaging or concatenation at the task of repository auto-tagging.</description><author>Agathe Lherondelle, Varun Babbar, Yash Satsangi, Fran Silavong, Shaltiel Eloul, Sean Moran</author><pubDate>Fri, 07 Jul 2023 14:44:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.09495v2</guid></item><item><title>GPT4RoI: Instruction Tuning Large Language Model on Region-of-Interest</title><link>http://arxiv.org/abs/2307.03601v1</link><description>Instruction tuning large language model (LLM) on image-text pairs hasachieved unprecedented vision-language multimodal abilities. However, theirvision-language alignments are only built on image-level, the lack ofregion-level alignment limits their advancements to fine-grained multimodalunderstanding. In this paper, we propose instruction tuning onregion-of-interest. The key design is to reformulate the bounding box as theformat of spatial instruction. The interleaved sequences of visual featuresextracted by the spatial instruction and the language embedding are input toLLM, and trained on the transformed region-text data in instruction tuningformat. Our region-level vision-language model, termed as GPT4RoI, brings brandnew conversational and interactive experience beyond image-level understanding.(1) Controllability: Users can interact with our model by both language andspatial instructions to flexibly adjust the detail level of the question. (2)Capacities: Our model supports not only single-region spatial instruction butalso multi-region. This unlocks more region-level multimodal capacities such asdetailed region caption and complex region reasoning. (3) Composition: Anyoff-the-shelf object detector can be a spatial instruction provider so as tomine informative object attributes from our model, like color, shape, material,action, relation to other objects, etc. The code, data, and demo can be foundat https://github.com/jshilong/GPT4RoI.</description><author>Shilong Zhang, Peize Sun, Shoufa Chen, Min Xiao, Wenqi Shao, Wenwei Zhang, Kai Chen, Ping Luo</author><pubDate>Fri, 07 Jul 2023 14:43:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03601v1</guid></item><item><title>GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting</title><link>http://arxiv.org/abs/2307.03595v1</link><description>Encoder-decoder deep neural networks have been increasingly studied formulti-horizon time series forecasting, especially in real-world applications.However, to forecast accurately, these sophisticated models typically rely on alarge number of time series examples with substantial history. A rapidlygrowing topic of interest is forecasting time series which lack sufficienthistorical data -- often referred to as the ``cold start'' problem. In thispaper, we introduce a novel yet simple method to address this problem byleveraging graph neural networks (GNNs) as a data augmentation for enhancingthe encoder used by such forecasters. These GNN-based features can capturecomplex inter-series relationships, and their generation process can beoptimized end-to-end with the forecasting task. We show that our architecturecan use either data-driven or domain knowledge-defined graphs, scaling toincorporate information from multiple very large graphs with millions of nodes.In our target application of demand forecasting for a large e-commerceretailer, we demonstrate on both a small dataset of 100K products and a largedataset with over 2 million products that our method improves overallperformance over competitive baseline models. More importantly, we show that itbrings substantially more gains to ``cold start'' products such as those newlylaunched or recently out-of-stock.</description><author>Sitan Yang, Malcolm Wolff, Shankar Ramasubramanian, Vincent Quenneville-Belair, Ronak Metha, Michael W. Mahoney</author><pubDate>Fri, 07 Jul 2023 14:38:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03595v1</guid></item><item><title>FOCUS: Object-Centric World Models for Robotics Manipulation</title><link>http://arxiv.org/abs/2307.02427v2</link><description>Understanding the world in terms of objects and the possible interplays withthem is an important cognition ability, especially in robotics manipulation,where many tasks require robot-object interactions. However, learning such astructured world model, which specifically captures entities and relationships,remains a challenging and underexplored problem. To address this, we proposeFOCUS, a model-based agent that learns an object-centric world model. Thanks toa novel exploration bonus that stems from the object-centric representation,FOCUS can be deployed on robotics manipulation tasks to explore objectinteractions more easily. Evaluating our approach on manipulation tasks acrossdifferent settings, we show that object-centric world models allow the agent tosolve tasks more efficiently and enable consistent exploration of robot-objectinteractions. Using a Franka Emika robot arm, we also showcase how FOCUS couldbe adopted in real-world settings.</description><author>Stefano Ferraro, Pietro Mazzaglia, Tim Verbelen, Bart Dhoedt</author><pubDate>Fri, 07 Jul 2023 14:36:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02427v2</guid></item><item><title>VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis</title><link>http://arxiv.org/abs/2307.03592v1</link><description>We present a data-driven generative framework for synthesizing blood vessel3D geometry. This is a challenging task due to the complexity of vascularsystems, which are highly variating in shape, size, and structure. Existingmodel-based methods provide some degree of control and variation in thestructures produced, but fail to capture the diversity of actual anatomicaldata. We developed VesselVAE, a recursive variational Neural Network that fullyexploits the hierarchical organization of the vessel and learns alow-dimensional manifold encoding branch connectivity along with geometryfeatures describing the target surface. After training, the VesselVAE latentspace can be sampled to generate new vessel geometries. To the best of ourknowledge, this work is the first to utilize this technique for synthesizingblood vessels. We achieve similarities of synthetic and real data for radius(.97), length (.95), and tortuosity (.96). By leveraging the power of deepneural networks, we generate 3D models of blood vessels that are both accurateand diverse, which is crucial for medical and surgical training, hemodynamicsimulations, and many other purposes.</description><author>Paula Feldman, Miguel Fainstein, Viviana Siless, Claudio Delrieux, Emmanuel Iarussi</author><pubDate>Fri, 07 Jul 2023 14:35:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03592v1</guid></item><item><title>Accelerated Optimization Landscape of Linear-Quadratic Regulator</title><link>http://arxiv.org/abs/2307.03590v1</link><description>Linear-quadratic regulator (LQR) is a landmark problem in the field ofoptimal control, which is the concern of this paper. Generally, LQR isclassified into state-feedback LQR (SLQR) and output-feedback LQR (OLQR) basedon whether the full state is obtained. It has been suggested in existingliterature that both the SLQR and the OLQR could be viewed as\textit{constrained nonconvex matrix optimization} problems in which the onlyvariable to be optimized is the feedback gain matrix. In this paper, weintroduce a first-order accelerated optimization framework of handling the LQRproblem, and give its convergence analysis for the cases of SLQR and OLQR,respectively. Specifically, a Lipschiz Hessian property of LQR performance criterion ispresented, which turns out to be a crucial property for the application ofmodern optimization techniques. For the SLQR problem, a continuous-time hybriddynamic system is introduced, whose solution trajectory is shown to convergeexponentially to the optimal feedback gain with Nesterov-optimal order$1-\frac{1}{\sqrt{\kappa}}$ ($\kappa$ the condition number). Then, thesymplectic Euler scheme is utilized to discretize the hybrid dynamic system,and a Nesterov-type method with a restarting rule is proposed that preservesthe continuous-time convergence rate, i.e., the discretized algorithm admitsthe Nesterov-optimal convergence order. For the OLQR problem, a Hessian-freeaccelerated framework is proposed, which is a two-procedure method consistingof semiconvex function optimization and negative curvature exploitation. In atime $\mathcal{O}(\epsilon^{-7/4}\log(1/\epsilon))$, the method can find an$\epsilon$-stationary point of the performance criterion; this entails that themethod improves upon the $\mathcal{O}(\epsilon^{-2})$ complexity of vanillagradient descent. Moreover, our method provides the second-order guarantee ofstationary point.</description><author>Lechen Feng, Yuan-Hua Ni</author><pubDate>Fri, 07 Jul 2023 14:34:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03590v1</guid></item><item><title>On discrete symmetries of robotics systems: A group-theoretic and data-driven analysis</title><link>http://arxiv.org/abs/2302.10433v3</link><description>We present a comprehensive study on discrete morphological symmetries ofdynamical systems, which are commonly observed in biological and artificiallocomoting systems, such as legged, swimming, and flying animals/robots/virtualcharacters. These symmetries arise from the presence of one or more planes/axisof symmetry in the system's morphology, resulting in harmonious duplication anddistribution of body parts. Significantly, we characterize how morphologicalsymmetries extend to symmetries in the system's dynamics, optimal controlpolicies, and in all proprioceptive and exteroceptive measurements related tothe system's dynamics evolution. In the context of data-driven methods,symmetry represents an inductive bias that justifies the use of dataaugmentation or symmetric function approximators. To tackle this, we present atheoretical and practical framework for identifying the system's morphologicalsymmetry group $\G$ and characterizing the symmetries in proprioceptive andexteroceptive data measurements. We then exploit these symmetries using dataaugmentation and $\G$-equivariant neural networks. Our experiments on bothsynthetic and real-world applications provide empirical evidence of theadvantageous outcomes resulting from the exploitation of these symmetries,including improved sample efficiency, enhanced generalization, and reduction oftrainable parameters.</description><author>Daniel Ordonez-Apraez, Mario Martin, Antonio Agudo, Francesc Moreno-Noguer</author><pubDate>Fri, 07 Jul 2023 14:32:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10433v3</guid></item><item><title>BOF-UCB: A Bayesian-Optimistic Frequentist Algorithm for Non-Stationary Contextual Bandits</title><link>http://arxiv.org/abs/2307.03587v1</link><description>We propose a novel Bayesian-Optimistic Frequentist Upper Confidence Bound(BOF-UCB) algorithm for stochastic contextual linear bandits in non-stationaryenvironments. This unique combination of Bayesian and frequentist principlesenhances adaptability and performance in dynamic settings. The BOF-UCBalgorithm utilizes sequential Bayesian updates to infer the posteriordistribution of the unknown regression parameter, and subsequently employs afrequentist approach to compute the Upper Confidence Bound (UCB) by maximizingthe expected reward over the posterior distribution. We provide theoreticalguarantees of BOF-UCB's performance and demonstrate its effectiveness inbalancing exploration and exploitation on synthetic datasets and classicalcontrol tasks in a reinforcement learning setting. Our results show thatBOF-UCB outperforms existing methods, making it a promising solution forsequential decision-making in non-stationary environments.</description><author>Nicklas Werge, Abdullah AkgÃ¼l, Melih Kandemir</author><pubDate>Fri, 07 Jul 2023 14:29:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03587v1</guid></item><item><title>ContextLabeler Dataset: physical and virtual sensors data collected from smartphone usage in-the-wild</title><link>http://arxiv.org/abs/2307.03586v1</link><description>This paper describes a data collection campaign and the resulting datasetderived from smartphone sensors characterizing the daily life activities of 3volunteers in a period of two weeks. The dataset is released as a collection ofCSV files containing more than 45K data samples, where each sample is composedby 1332 features related to a heterogeneous set of physical and virtualsensors, including motion sensors, running applications, devices in proximity,and weather conditions. Moreover, each data sample is associated with a groundtruth label that describes the user activity and the situation in which she wasinvolved during the sensing experiment (e.g., working, at restaurant, and doingsport activity). To avoid introducing any bias during the data collection, weperformed the sensing experiment in-the-wild, that is, by using the volunteers'devices, and without defining any constraint related to the user's behavior.For this reason, the collected dataset represents a useful source of real datato both define and evaluate a broad set of novel context-aware solutions (bothalgorithms and protocols) that aim to adapt their behavior according to thechanges in the user's situation in a mobile environment.</description><author>Mattia Giovanni Campana, Franca Delmastro</author><pubDate>Fri, 07 Jul 2023 14:28:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03586v1</guid></item><item><title>Nested Diffusion Processes for Anytime Image Generation</title><link>http://arxiv.org/abs/2305.19066v2</link><description>Diffusion models are the current state-of-the-art in image generation,synthesizing high-quality images by breaking down the generation process intomany fine-grained denoising steps. Despite their good performance, diffusionmodels are computationally expensive, requiring many neural functionevaluations (NFEs). In this work, we propose an anytime diffusion-based methodthat can generate viable images when stopped at arbitrary times beforecompletion. Using existing pretrained diffusion models, we show that thegeneration scheme can be recomposed as two nested diffusion processes, enablingfast iterative refinement of a generated image. In experiments on ImageNet andStable Diffusion-based text-to-image generation, we show, both qualitativelyand quantitatively, that our method's intermediate generation quality greatlyexceeds that of the original diffusion model, while the final generation resultremains comparable. We illustrate the applicability of Nested Diffusion inseveral settings, including for solving inverse problems, and for rapidtext-based content creation by allowing user intervention throughout thesampling process.</description><author>Noam Elata, Bahjat Kawar, Tomer Michaeli, Michael Elad</author><pubDate>Fri, 07 Jul 2023 14:25:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19066v2</guid></item><item><title>Tensor Robust PCA with Nonconvex and Nonlocal Regularization</title><link>http://arxiv.org/abs/2211.02404v2</link><description>Tensor robust principal component analysis (TRPCA) is a classical way forlow-rank tensor recovery, which minimizes the convex surrogate of tensor rankby shrinking each tensor singular value equally. However, for real-world visualdata, large singular values represent more significant information than smallsingular values. In this paper, we propose a nonconvex TRPCA (N-TRPCA) modelbased on the tensor adjustable logarithmic norm. Unlike TRPCA, our N-TRPCA canadaptively shrink small singular values more and shrink large singular valuesless. In addition, TRPCA assumes that the whole data tensor is of low rank.This assumption is hardly satisfied in practice for natural visual data,restricting the capability of TRPCA to recover the edges and texture detailsfrom noisy images and videos. To this end, we integrate nonlocalself-similarity into N-TRPCA, and further develop a nonconvex and nonlocalTRPCA (NN-TRPCA) model. Specifically, similar nonlocal patches are grouped as atensor and then each group tensor is recovered by our N-TRPCA. Since thepatches in one group are highly correlated, all group tensors have stronglow-rank property, leading to an improvement of recovery performance.Experimental results demonstrate that the proposed NN-TRPCA outperformsexisting TRPCA methods in visual data recovery. The demo code is available athttps://github.com/qguo2010/NN-TRPCA.</description><author>Xiaoyu Geng, Qiang Guo, Shuaixiong Hui, Ming Yang, Caiming Zhang</author><pubDate>Fri, 07 Jul 2023 14:25:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.02404v2</guid></item><item><title>LXL: LiDAR Excluded Lean 3D Object Detection with 4D Imaging Radar and Camera Fusion</title><link>http://arxiv.org/abs/2307.00724v2</link><description>As an emerging technology and a relatively affordable device, the 4D imagingradar has already been confirmed effective in performing 3D object detection inautonomous driving. Nevertheless, the sparsity and noisiness of 4D radar pointclouds hinder further performance improvement, and in-depth studies about itsfusion with other modalities are lacking. On the other hand, most of thecamera-based perception methods transform the extracted image perspective viewfeatures into the bird's-eye view geometrically via "depth-based splatting"proposed in Lift-Splat-Shoot (LSS), and some researchers exploit other modalssuch as LiDARs or ordinary automotive radars for enhancement. Recently, a fewworks have applied the "sampling" strategy for image view transformation,showing that it outperforms "splatting" even without image depth prediction.However, the potential of "sampling" is not fully unleashed. In this paper, weinvestigate the "sampling" view transformation strategy on the camera and 4Dimaging radar fusion-based 3D object detection. In the proposed model, LXL,predicted image depth distribution maps and radar 3D occupancy grids areutilized to aid image view transformation, called "radar occupancy-assisteddepth-based sampling". Experiments on VoD and TJ4DRadSet datasets show that theproposed method outperforms existing 3D object detection methods by asignificant margin without bells and whistles. Ablation studies demonstratethat our method performs the best among different enhancement settings.</description><author>Weiyi Xiong, Jianan Liu, Tao Huang, Qing-Long Han, Yuxuan Xia, Bing Zhu</author><pubDate>Fri, 07 Jul 2023 14:20:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00724v2</guid></item><item><title>Unsupervised Segmentation of Fetal Brain MRI using Deep Learning Cascaded Registration</title><link>http://arxiv.org/abs/2307.03579v1</link><description>Accurate segmentation of fetal brain magnetic resonance images is crucial foranalyzing fetal brain development and detecting potential neurodevelopmentalabnormalities. Traditional deep learning-based automatic segmentation, althougheffective, requires extensive training data with ground-truth labels, typicallyproduced by clinicians through a time-consuming annotation process. To overcomethis challenge, we propose a novel unsupervised segmentation method based onmulti-atlas segmentation, that accurately segments multiple tissues withoutrelying on labeled data for training. Our method employs a cascaded deeplearning network for 3D image registration, which computes small, incrementaldeformations to the moving image to align it precisely with the fixed image.This cascaded network can then be used to register multiple annotated imageswith the image to be segmented, and combine the propagated labels to form arefined segmentation. Our experiments demonstrate that the proposed cascadedarchitecture outperforms the state-of-the-art registration methods that weretested. Furthermore, the derived segmentation method achieves similarperformance and inference time to nnU-Net while only using a small subset ofannotated data for the multi-atlas segmentation task and none for training thenetwork. Our pipeline for registration and multi-atlas segmentation is publiclyavailable at https://github.com/ValBcn/CasReg.</description><author>Valentin Comte, Mireia Alenya, Andrea Urru, Judith Recober, Ayako Nakaki, Francesca Crovetto, Oscar Camara, Eduard GratacÃ³s, Elisenda Eixarch, FÃ tima Crispi, Gemma Piella, Mario Ceresa, Miguel A. GonzÃ¡lez Ballester</author><pubDate>Fri, 07 Jul 2023 14:17:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03579v1</guid></item><item><title>Programmable Synthetic Tabular Data Generation</title><link>http://arxiv.org/abs/2307.03577v1</link><description>Large amounts of tabular data remain underutilized due to privacy, dataquality, and data sharing limitations. While training a generative modelproducing synthetic data resembling the original distribution addresses some ofthese issues, most applications require additional constraints from thegenerated data. Existing synthetic data approaches are limited as theytypically only handle specific constraints, e.g., differential privacy (DP) orincreased fairness, and lack an accessible interface for declaring generalspecifications. In this work, we introduce ProgSyn, the first programmablesynthetic tabular data generation algorithm that allows for comprehensivecustomization over the generated data. To ensure high data quality whileadhering to custom specifications, ProgSyn pre-trains a generative model on theoriginal dataset and fine-tunes it on a differentiable loss automaticallyderived from the provided specifications. These can be programmaticallydeclared using statistical and logical expressions, supporting a wide range ofrequirements (e.g., DP or fairness, among others). We conduct an extensiveexperimental evaluation of ProgSyn on a number of constraints, achieving a newstate-of-the-art on some, while remaining general. For instance, at the samefairness level we achieve 2.3% higher downstream accuracy than thestate-of-the-art in fair synthetic data generation on the Adult dataset.Overall, ProgSyn provides a versatile and accessible framework for generatingconstrained synthetic tabular data, allowing for specifications that generalizebeyond the capabilities of prior work.</description><author>Mark Vero, Mislav BalunoviÄ‡, Martin Vechev</author><pubDate>Fri, 07 Jul 2023 14:10:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03577v1</guid></item><item><title>One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention</title><link>http://arxiv.org/abs/2307.03576v1</link><description>Recent works have empirically analyzed in-context learning and shown thattransformers trained on synthetic linear regression tasks can learn toimplement ridge regression, which is the Bayes-optimal predictor, givensufficient capacity [Aky\"urek et al., 2023], while one-layer transformers withlinear self-attention and no MLP layer will learn to implement one step ofgradient descent (GD) on a least-squares linear regression objective [vonOswald et al., 2022]. However, the theory behind these observations remainspoorly understood. We theoretically study transformers with a single layer oflinear self-attention, trained on synthetic noisy linear regression data.First, we mathematically show that when the covariates are drawn from astandard Gaussian distribution, the one-layer transformer which minimizes thepre-training loss will implement a single step of GD on the least-squareslinear regression objective. Then, we find that changing the distribution ofthe covariates and weight vector to a non-isotropic Gaussian distribution has astrong impact on the learned algorithm: the global minimizer of thepre-training loss now implements a single step of $\textit{pre-conditioned}$GD. However, if only the distribution of the responses is changed, then thisdoes not have a large effect on the learned algorithm: even when the responsecomes from a more general family of $\textit{nonlinear}$ functions, the globalminimizer of the pre-training loss still implements a single step of GD on aleast-squares linear regression objective.</description><author>Arvind Mahankali, Tatsunori B. Hashimoto, Tengyu Ma</author><pubDate>Fri, 07 Jul 2023 14:09:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03576v1</guid></item><item><title>Multimodal Deep Learning for Personalized Renal Cell Carcinoma Prognosis: Integrating CT Imaging and Clinical Data</title><link>http://arxiv.org/abs/2307.03575v1</link><description>Renal cell carcinoma represents a significant global health challenge with alow survival rate. This research aimed to devise a comprehensive deep-learningmodel capable of predicting survival probabilities in patients with renal cellcarcinoma by integrating CT imaging and clinical data and addressing thelimitations observed in prior studies. The aim is to facilitate theidentification of patients requiring urgent treatment. The proposed frameworkcomprises three modules: a 3D image feature extractor, clinical variableselection, and survival prediction. The feature extractor module, based on the3D CNN architecture, predicts the ISUP grade of renal cell carcinoma tumorslinked to mortality rates from CT images. A selection of clinical variables issystematically chosen using the Spearman score and random forest importancescore as criteria. A deep learning-based network, trained with discreteLogisticHazard-based loss, performs the survival prediction. Nine distinctexperiments are performed, with varying numbers of clinical variablesdetermined by different thresholds of the Spearman and importance scores. Ourfindings demonstrate that the proposed strategy surpasses the currentliterature on renal cancer prognosis based on CT scans and clinical factors.The best-performing experiment yielded a concordance index of 0.84 and an areaunder the curve value of 0.8 on the test cohort, which suggests strongpredictive power. The multimodal deep-learning approach developed in this studyshows promising results in estimating survival probabilities for renal cellcarcinoma patients using CT imaging and clinical data. This may have potentialimplications in identifying patients who require urgent treatment, potentiallyimproving patient outcomes. The code created for this project is available forthe public on:\href{https://github.com/Balasingham-AI-Group/Survival_CTplusClinical}{GitHub}</description><author>Maryamalsadat Mahootiha, Hemin Ali Qadir, Jacob Bergsland, Ilangko Balasingham</author><pubDate>Fri, 07 Jul 2023 14:09:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03575v1</guid></item><item><title>Smoothing the Edges: A General Framework for Smooth Optimization in Sparse Regularization using Hadamard Overparametrization</title><link>http://arxiv.org/abs/2307.03571v1</link><description>This paper introduces a smooth method for (structured) sparsity in $\ell_q$and $\ell_{p,q}$ regularized optimization problems. Optimization of thesenon-smooth and possibly non-convex problems typically relies on specializedprocedures. In contrast, our general framework is compatible with prevalentfirst-order optimization methods like Stochastic Gradient Descent andaccelerated variants without any required modifications. This is accomplishedthrough a smooth optimization transfer, comprising an overparametrization ofselected model parameters using Hadamard products and a change of penalties. Inthe overparametrized problem, smooth and convex $\ell_2$ regularization of thesurrogate parameters induces non-smooth and non-convex $\ell_q$ or $\ell_{p,q}$regularization in the original parametrization. We show that our approachyields not only matching global minima but also equivalent local minima. Thisis particularly useful in non-convex sparse regularization, where findingglobal minima is NP-hard and local minima are known to generalize well. Weprovide a comprehensive overview consolidating various literature strands onsparsity-inducing parametrizations and propose meaningful extensions toexisting approaches. The feasibility of our approach is evaluated throughnumerical experiments, which demonstrate that its performance is on par with orsurpasses commonly used implementations of convex and non-convex regularizationmethods.</description><author>Chris Kolb, Christian L. MÃ¼ller, Bernd Bischl, David RÃ¼gamer</author><pubDate>Fri, 07 Jul 2023 14:06:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03571v1</guid></item><item><title>Text Simplification of Scientific Texts for Non-Expert Readers</title><link>http://arxiv.org/abs/2307.03569v1</link><description>Reading levels are highly individual and can depend on a text's language, aperson's cognitive abilities, or knowledge on a topic. Text simplification isthe task of rephrasing a text to better cater to the abilities of a specifictarget reader group. Simplification of scientific abstracts helps non-expertsto access the core information by bypassing formulations that require domain orexpert knowledge. This is especially relevant for, e.g., cancer patientsreading about novel treatment options. The SimpleText lab hosts thesimplification of scientific abstracts for non-experts (Task 3) to advance thisfield. We contribute three runs employing out-of-the-box summarization models(two based on T5, one based on PEGASUS) and one run using ChatGPT with complexphrase identification.</description><author>BjÃ¶rn Engelmann, Fabian Haak, Christin Katharina Kreutz, Narjes Nikzad Khasmakhi, Philipp Schaer</author><pubDate>Fri, 07 Jul 2023 14:05:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03569v1</guid></item><item><title>SpawnNet: Learning Generalizable Visuomotor Skills from Pre-trained Networks</title><link>http://arxiv.org/abs/2307.03567v1</link><description>The existing internet-scale image and video datasets cover a wide range ofeveryday objects and tasks, bringing the potential of learning policies thathave broad generalization. Prior works have explored visual pre-training withdifferent self-supervised objectives, but the generalization capabilities ofthe learned policies remain relatively unknown. In this work, we take the firststep towards this challenge, focusing on how pre-trained representations canhelp the generalization of the learned policies. We first identify the keybottleneck in using a frozen pre-trained visual backbone for policy learning.We then propose SpawnNet, a novel two-stream architecture that learns to fusepre-trained multi-layer representations into a separate network to learn arobust policy. Through extensive simulated and real experiments, we demonstratesignificantly better categorical generalization compared to prior approaches inimitation learning settings.</description><author>Xingyu Lin, John So, Sashwat Mahalingam, Fangchen Liu, Pieter Abbeel</author><pubDate>Fri, 07 Jul 2023 14:01:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03567v1</guid></item><item><title>MALIBO: Meta-learning for Likelihood-free Bayesian Optimization</title><link>http://arxiv.org/abs/2307.03565v1</link><description>Bayesian optimization (BO) is a popular method to optimize costly black-boxfunctions. While traditional BO optimizes each new target task from scratch,meta-learning has emerged as a way to leverage knowledge from related tasks tooptimize new tasks faster. However, existing meta-learning BO methods rely onsurrogate models that suffer from scalability issues and are sensitive toobservations with different scales and noise types across tasks. Moreover, theyoften overlook the uncertainty associated with task similarity. This leads tounreliable task adaptation when only limited observations are obtained or whenthe new tasks differ significantly from the related tasks. To address theselimitations, we propose a novel meta-learning BO approach that bypasses thesurrogate model and directly learns the utility of queries across tasks. Ourmethod explicitly models task uncertainty and includes an auxiliary model toenable robust adaptation to new tasks. Extensive experiments show that ourmethod demonstrates strong anytime performance and outperforms state-of-the-artmeta-learning BO methods in various benchmarks.</description><author>Jiarong Pan, Stefan Falkner, Felix Berkenkamp, Joaquin Vanschoren</author><pubDate>Fri, 07 Jul 2023 13:57:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03565v1</guid></item><item><title>GRAPHSHAP: Explaining Identity-Aware Graph Classifiers Through the Language of Motifs</title><link>http://arxiv.org/abs/2202.08815v2</link><description>Most methods for explaining black-box classifiers (e.g. on tabular data,images, or time series) rely on measuring the impact that removing/perturbingfeatures has on the model output. This forces the explanation language to matchthe classifier's feature space. However, when dealing with graph data, in whichthe basic features correspond to the edges describing the graph structure, thismatching between features space and explanation language might not beappropriate. Decoupling the feature space (edges) from a desired high-levelexplanation language (such as motifs) is thus a major challenge towardsdeveloping actionable explanations for graph classification tasks. In thispaper we introduce GRAPHSHAP, a Shapley-based approach able to providemotif-based explanations for identity-aware graph classifiers, assuming noknowledge whatsoever about the model or its training data: the only requirementis that the classifier can be queried as a black-box at will. For the sake ofcomputational efficiency we explore a progressive approximation strategy andshow how a simple kernel can efficiently approximate explanation scores, thusallowing GRAPHSHAP to scale on scenarios with a large explanation space (i.e.large number of motifs). We showcase GRAPHSHAP on a real-world brain-networkdataset consisting of patients affected by Autism Spectrum Disorder and acontrol group. Our experiments highlight how the classification provided by ablack-box model can be effectively explained by few connectomics patterns.</description><author>Alan Perotti, Paolo Bajardi, Francesco Bonchi, AndrÃ© Panisson</author><pubDate>Fri, 07 Jul 2023 13:53:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.08815v2</guid></item><item><title>The Innovation Paradox: Concept Space Expansion with Diminishing Originality and the Promise of Creative AI</title><link>http://arxiv.org/abs/2303.13300v2</link><description>Innovation, typically spurred by reusing, recombining, and synthesizingexisting concepts, is expected to result in an exponential growth of theconcept space over time. However, our statistical analysis of TechNet, which isa comprehensive technology semantic network encompassing over four millionconcepts derived from patent texts, reveals a linear rather than exponentialexpansion of the overall technological concept space. Moreover, there is anotable decline in the originality of newly created concepts. These trends canbe attributed to the constraints of human cognitive abilities to innovatebeyond an ever-growing space of prior art, among other factors. Integratingcreative artificial intelligence into the innovation process holds thepotential to overcome these limitations and alter the observed trends in thefuture.</description><author>Serhad Sarica, Jianxi Luo</author><pubDate>Fri, 07 Jul 2023 13:38:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.13300v2</guid></item><item><title>VariGrad: A Novel Feature Vector Architecture for Geometric Deep Learning on Unregistered Data</title><link>http://arxiv.org/abs/2307.03553v1</link><description>We present a novel geometric deep learning layer that leverages the varifoldgradient (VariGrad) to compute feature vector representations of 3D geometricdata. These feature vectors can be used in a variety of downstream learningtasks such as classification, registration, and shape reconstruction. Ourmodel's use of parameterization independent varifold representations ofgeometric data allows our model to be both trained and tested on dataindependent of the given sampling or parameterization. We demonstrate theefficiency, generalizability, and robustness to resampling demonstrated by theproposed VariGrad layer.</description><author>Emmanuel Hartman, Emery Pierson</author><pubDate>Fri, 07 Jul 2023 13:37:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03553v1</guid></item><item><title>DWReCO at CheckThat! 2023: Enhancing Subjectivity Detection through Style-based Data Sampling</title><link>http://arxiv.org/abs/2307.03550v1</link><description>This paper describes our submission for the subjectivity detection task atthe CheckThat! Lab. To tackle class imbalances in the task, we have generatedadditional training materials with GPT-3 models using prompts of differentstyles from a subjectivity checklist based on journalistic perspective. We usedthe extended training set to fine-tune language-specific transformer models.Our experiments in English, German and Turkish demonstrate that differentsubjective styles are effective across all languages. In addition, we observethat the style-based oversampling is better than paraphrasing in Turkish andEnglish. Lastly, the GPT-3 models sometimes produce lacklustre results whengenerating style-based texts in non-English languages.</description><author>Ipek Baris Schlicht, Lynn Khellaf, Defne Altiok</author><pubDate>Fri, 07 Jul 2023 13:34:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03550v1</guid></item><item><title>Avoiding Post-Processing with Event-Based Detection in Biomedical Signals</title><link>http://arxiv.org/abs/2209.11007v2</link><description>Objective: Finding events of interest is a common task in biomedical signalprocessing. The detection of epileptic seizures and signal artefacts are twokey examples. Epoch-based classification is the typical machine learningframework to detect such signal events because of the straightforwardapplication of classical machine learning techniques. Usually, post-processingis required to achieve good performance and enforce temporal dependencies.Designing the right post-processing scheme to convert these classificationoutputs into events is a tedious, and labor-intensive element of thisframework. Methods: We propose an event-based modeling framework that directlyworks with events as learning targets, stepping away from ad-hocpost-processing schemes to turn model outputs into events. We illustrate thepractical power of this framework on simulated data and real-world data,comparing it to epoch-based modeling approaches. Results: We show thatevent-based modeling (without post-processing) performs on par with or betterthan epoch-based modeling with extensive post-processing. Conclusion: Theseresults show the power of treating events as direct learning targets, insteadof using ad-hoc post-processing to obtain them, severely reducing designeffort. Significance: The event-based modeling framework can easily be appliedto other event detection problems in signal processing, removing the need forintensive task-specific post-processing.</description><author>Nick Seeuws, Maarten De Vos, Alexander Bertrand</author><pubDate>Fri, 07 Jul 2023 13:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.11007v2</guid></item><item><title>Roman Numeral Analysis with Graph Neural Networks: Onset-wise Predictions from Note-wise Features</title><link>http://arxiv.org/abs/2307.03544v1</link><description>Roman Numeral analysis is the important task of identifying chords and theirfunctional context in pieces of tonal music. This paper presents a new approachto automatic Roman Numeral analysis in symbolic music. While existingtechniques rely on an intermediate lossy representation of the score, wepropose a new method based on Graph Neural Networks (GNNs) that enable thedirect description and processing of each individual note in the score. Theproposed architecture can leverage notewise features and interdependenciesbetween notes but yield onset-wise representation by virtue of our novel edgecontraction algorithm. Our results demonstrate that ChordGNN outperformsexisting state-of-the-art models, achieving higher accuracy in Roman Numeralanalysis on the reference datasets. In addition, we investigate variants of ourmodel using proposed techniques such as NADE, and post-processing of the chordpredictions. The full source code for this work is available athttps://github.com/manoskary/chordgnn</description><author>Emmanouil Karystinaios, Gerhard Widmer</author><pubDate>Fri, 07 Jul 2023 13:20:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03544v1</guid></item><item><title>Large Language Models as Batteries-Included Zero-Shot ESCO Skills Matchers</title><link>http://arxiv.org/abs/2307.03539v1</link><description>Understanding labour market dynamics requires accurately identifying theskills required for and possessed by the workforce. Automation techniques areincreasingly being developed to support this effort. However, automaticallyextracting skills from job postings is challenging due to the vast number ofexisting skills. The ESCO (European Skills, Competences, Qualifications andOccupations) framework provides a useful reference, listing over 13,000individual skills. However, skills extraction remains difficult and accuratelymatching job posts to the ESCO taxonomy is an open problem. In this work, wepropose an end-to-end zero-shot system for skills extraction from jobdescriptions based on large language models (LLMs). We generate synthetictraining data for the entirety of ESCO skills and train a classifier to extractskill mentions from job posts. We also employ a similarity retriever togenerate skill candidates which are then re-ranked using a second LLM. Usingsynthetic data achieves an RP@10 score 10 points higher than previous distantsupervision approaches. Adding GPT-4 re-ranking improves RP@10 by over 22points over previous methods. We also show that Framing the task as mockprogramming when prompting the LLM can lead to better performance than naturallanguage prompts, especially with weaker LLMs. We demonstrate the potential ofintegrating large language models at both ends of skills matching pipelines.Our approach requires no human annotations and achieve extremely promisingresults on skills extraction against ESCO.</description><author>Benjamin ClaviÃ©, Guillaume SouliÃ©</author><pubDate>Fri, 07 Jul 2023 13:04:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03539v1</guid></item><item><title>Language-free Compositional Action Generation via Decoupling Refinement</title><link>http://arxiv.org/abs/2307.03538v1</link><description>Composing simple elements into complex concepts is crucial yet challenging,especially for 3D action generation. Existing methods largely rely on extensiveneural language annotations to discern composable latent semantics, a processthat is often costly and labor-intensive. In this study, we introduce a novelframework to generate compositional actions without reliance on languageauxiliaries. Our approach consists of three main components: Action Coupling,Conditional Action Generation, and Decoupling Refinement. Action Couplingutilizes an energy model to extract the attention masks of each sub-action,subsequently integrating two actions using these attentions to generatepseudo-training examples. Then, we employ a conditional generative model, CVAE,to learn a latent space, facilitating the diverse generation. Finally, wepropose Decoupling Refinement, which leverages a self-supervised pre-trainedmodel MAE to ensure semantic consistency between the sub-actions andcompositional actions. This refinement process involves rendering generated 3Dactions into 2D space, decoupling these images into two sub-segments, using theMAE model to restore the complete image from sub-segments, and constraining therecovered images to match images rendered from raw sub-actions. Due to the lackof existing datasets containing both sub-actions and compositional actions, wecreated two new datasets, named HumanAct-C and UESTC-C, and present acorresponding evaluation metric. Both qualitative and quantitative assessmentsare conducted to show our efficacy.</description><author>Xiao Liu, Guangyi Chen, Yansong Tang, Guangrun Wang, Ser-Nam Lim</author><pubDate>Fri, 07 Jul 2023 13:00:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03538v1</guid></item><item><title>When and How to Fool Explainable Models (and Humans) with Adversarial Examples</title><link>http://arxiv.org/abs/2107.01943v2</link><description>Reliable deployment of machine learning models such as neural networkscontinues to be challenging due to several limitations. Some of the mainshortcomings are the lack of interpretability and the lack of robustnessagainst adversarial examples or out-of-distribution inputs. In this exploratoryreview, we explore the possibilities and limits of adversarial attacks forexplainable machine learning models. First, we extend the notion of adversarialexamples to fit in explainable machine learning scenarios, in which the inputs,the output classifications and the explanations of the model's decisions areassessed by humans. Next, we propose a comprehensive framework to study whether(and how) adversarial examples can be generated for explainable models underhuman assessment, introducing and illustrating novel attack paradigms. Inparticular, our framework considers a wide range of relevant yet often ignoredfactors such as the type of problem, the user expertise or the objective of theexplanations, in order to identify the attack strategies that should be adoptedin each scenario to successfully deceive the model (and the human). Theintention of these contributions is to serve as a basis for a more rigorous andrealistic study of adversarial examples in the field of explainable machinelearning.</description><author>Jon Vadillo, Roberto Santana, Jose A. Lozano</author><pubDate>Fri, 07 Jul 2023 12:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.01943v2</guid></item><item><title>Joint Perceptual Learning for Enhancement and Object Detection in Underwater Scenarios</title><link>http://arxiv.org/abs/2307.03536v1</link><description>Underwater degraded images greatly challenge existing algorithms to detectobjects of interest. Recently, researchers attempt to adopt attentionmechanisms or composite connections for improving the feature representation ofdetectors. However, this solution does \textit{not} eliminate the impact ofdegradation on image content such as color and texture, achieving minimalimprovements. Another feasible solution for underwater object detection is todevelop sophisticated deep architectures in order to enhance image quality orfeatures. Nevertheless, the visually appealing output of these enhancementmodules do \textit{not} necessarily generate high accuracy for deep detectors.More recently, some multi-task learning methods jointly learn underwaterdetection and image enhancement, accessing promising improvements. Typically,these methods invoke huge architecture and expensive computations, renderinginefficient inference. Definitely, underwater object detection and imageenhancement are two interrelated tasks. Leveraging information coming from thetwo tasks can benefit each task. Based on these factual opinions, we propose abilevel optimization formulation for jointly learning underwater objectdetection and image enhancement, and then unroll to a dual perception network(DPNet) for the two tasks. DPNet with one shared module and two task subnetslearns from the two different tasks, seeking a shared representation. Theshared representation provides more structural details for image enhancementand rich content information for object detection. Finally, we derive acooperative training strategy to optimize parameters for DPNet. Extensiveexperiments on real-world and synthetic underwater datasets demonstrate thatour method outputs visually favoring images and higher detection accuracy.</description><author>Chenping Fu, Wanqi Yuan, Jiewen Xiao, Risheng Liu, Xin Fan</author><pubDate>Fri, 07 Jul 2023 12:54:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03536v1</guid></item><item><title>Matching in the Wild: Learning Anatomical Embeddings for Multi-Modality Images</title><link>http://arxiv.org/abs/2307.03535v1</link><description>Radiotherapists require accurate registration of MR/CT images to effectivelyuse information from both modalities. In a typical registration pipeline, rigidor affine transformations are applied to roughly align the fixed and movingimages before proceeding with the deformation step. While recent learning-basedmethods have shown promising results in the rigid/affine step, these methodsoften require images with similar field-of-view (FOV) for successful alignment.As a result, aligning images with different FOVs remains a challenging task.Self-supervised landmark detection methods like self-supervised AnatomicaleMbedding (SAM) have emerged as a useful tool for mapping and cropping imagesto similar FOVs. However, these methods are currently limited to intra-modalityuse only. To address this limitation and enable cross-modality matching, wepropose a new approach called Cross-SAM. Our approach utilizes a noveliterative process that alternates between embedding learning and CT-MRIregistration. We start by applying aggressive contrast augmentation on both CTand MRI images to train a SAM model. We then use this SAM to identifycorresponding regions on paired images using robust grid-points matching,followed by a point-set based affine/rigid registration, and a deformablefine-tuning step to produce registered paired images. We use these registeredpairs to enhance the matching ability of SAM, which is then processediteratively. We use the final model for cross-modality matching tasks. Weevaluated our approach on two CT-MRI affine registration datasets and foundthat Cross-SAM achieved robust affine registration on both datasets,significantly outperforming other methods and achieving state-of-the-artperformance.</description><author>Xiaoyu Bai, Fan Bai, Xiaofei Huo, Jia Ge, Tony C. W. Mok, Zi Li, Minfeng Xu, Jingren Zhou, Le Lu, Dakai Jin, Xianghua Ye, Jingjing Lu, Ke Yan</author><pubDate>Fri, 07 Jul 2023 12:49:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03535v1</guid></item><item><title>Quantifying the perceptual value of lexical and non-lexical channels in speech</title><link>http://arxiv.org/abs/2307.03534v1</link><description>Speech is a fundamental means of communication that can be seen to providetwo channels for transmitting information: the lexical channel of which wordsare said, and the non-lexical channel of how they are spoken. Both channelsshape listener expectations of upcoming communication; however, directlyquantifying their relative effect on expectations is challenging. Previousattempts require spoken variations of lexically-equivalent dialogue turns orconspicuous acoustic manipulations. This paper introduces a generalisedparadigm to study the value of non-lexical information in dialogue acrossunconstrained lexical content. By quantifying the perceptual value of thenon-lexical channel with both accuracy and entropy reduction, we show thatnon-lexical information produces a consistent effect on expectations ofupcoming dialogue: even when it leads to poorer discriminative turn judgementsthan lexical content alone, it yields higher consensus among participants.</description><author>Sarenne Wallbridge, Peter Bell, Catherine Lai</author><pubDate>Fri, 07 Jul 2023 12:44:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03534v1</guid></item><item><title>Automated Labeling of German Chest X-Ray Radiology Reports using Deep Learning</title><link>http://arxiv.org/abs/2306.05997v2</link><description>Radiologists are in short supply globally, and deep learning models offer apromising solution to address this shortage as part of clinicaldecision-support systems. However, training such models often requiresexpensive and time-consuming manual labeling of large datasets. Automatic labelextraction from radiology reports can reduce the time required to obtainlabeled datasets, but this task is challenging due to semantically similarwords and missing annotated data. In this work, we explore the potential ofweak supervision of a deep learning-based label prediction model, using arule-based labeler. We propose a deep learning-based CheXpert label predictionmodel, pre-trained on reports labeled by a rule-based German CheXpert model andfine-tuned on a small dataset of manually labeled reports. Our resultsdemonstrate the effectiveness of our approach, which significantly outperformedthe rule-based model on all three tasks. Our findings highlight the benefits ofemploying deep learning-based models even in scenarios with sparse data and theuse of the rule-based labeler as a tool for weak supervision.</description><author>Alessandro Wollek, Philip Haitzer, Thomas Sedlmeyr, Sardi Hyska, Johannes Rueckel, Bastian Sabel, Michael Ingrisch, Tobias Lasser</author><pubDate>Fri, 07 Jul 2023 12:36:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05997v2</guid></item><item><title>Concealed Object Detection for Passive Millimeter-Wave Security Imaging Based on Task-Aligned Detection Transformer</title><link>http://arxiv.org/abs/2212.00313v2</link><description>Passive millimeter-wave (PMMW) is a significant potential technique for humansecurity screening. Several popular object detection networks have been usedfor PMMW images. However, restricted by the low resolution and high noise ofPMMW images, PMMW hidden object detection based on deep learning usuallysuffers from low accuracy and low classification confidence. To tackle theabove problems, this paper proposes a Task-Aligned Detection Transformernetwork, named PMMW-DETR. In the first stage, a Denoising Coarse-to-FineTransformer (DCFT) backbone is designed to extract long- and short-rangefeatures in the different scales. In the second stage, we propose the QuerySelection module to introduce learned spatial features into the network asprior knowledge, which enhances the semantic perception capability of thenetwork. In the third stage, aiming to improve the classification performance,we perform a Task-Aligned Dual-Head block to decouple the classification andregression tasks. Based on our self-developed PMMW security screening dataset,experimental results including comparison with State-Of-The-Art (SOTA) methodsand ablation study demonstrate that the PMMW-DETR obtains higher accuracy andclassification confidence than previous works, and exhibits robustness to thePMMW images of low quality.</description><author>Cheng Guo, Fei Hu, Yan Hu</author><pubDate>Fri, 07 Jul 2023 12:34:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.00313v2</guid></item><item><title>Decentralized Learning over Wireless Networks: The Effect of Broadcast with Random Access</title><link>http://arxiv.org/abs/2305.07368v2</link><description>In this work, we focus on the communication aspect of decentralized learning,which involves multiple agents training a shared machine learning model usingdecentralized stochastic gradient descent (D-SGD) over distributed data. Inparticular, we investigate the impact of broadcast transmission andprobabilistic random access policy on the convergence performance of D-SGD,considering the broadcast nature of wireless channels and the link dynamics inthe communication topology. Our results demonstrate that optimizing the accessprobability to maximize the expected number of successful links is a highlyeffective strategy for accelerating the system convergence.</description><author>Zheng Chen, Martin Dahl, Erik G. Larsson</author><pubDate>Fri, 07 Jul 2023 12:32:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07368v2</guid></item><item><title>Beyond Cuts in Small Signal Scenarios -- Enhanced Sneutrino Detectability Using Machine Learning</title><link>http://arxiv.org/abs/2108.03125v4</link><description>We investigate enhancing the sensitivity of new physics searches at the LHCby machine learning in the case of background dominance and a high degree ofoverlap between the observables for signal and background. We use two differentmodels, XGBoost and a deep neural network, to exploit correlations betweenobservables and compare this approach to the traditional cut-and-count method.We consider different methods to analyze the models' output, finding that atemplate fit generally performs better than a simple cut. By means of a Shapleydecomposition, we gain additional insight into the relationship between eventkinematics and the machine learning model output. We consider a supersymmetricscenario with a metastable sneutrino as a concrete example, but the methodologycan be applied to a much wider class of models.</description><author>Daniel Alvestad, Nikolai Fomin, JÃ¶rn Kersten, Steffen Maeland, Inga StrÃ¼mke</author><pubDate>Fri, 07 Jul 2023 12:12:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2108.03125v4</guid></item><item><title>Incentive Allocation in Vertical Federated Learning Based on Bankruptcy Problem</title><link>http://arxiv.org/abs/2307.03515v1</link><description>Vertical federated learning (VFL) is a promising approach for collaborativelytraining machine learning models using private data partitioned verticallyacross different parties. Ideally in a VFL setting, the active party (partypossessing features of samples with labels) benefits by improving its machinelearning model through collaboration with some passive parties (partiespossessing additional features of the same samples without labels) in a privacypreserving manner. However, motivating passive parties to participate in VFLcan be challenging. In this paper, we focus on the problem of allocatingincentives to the passive parties by the active party based on theircontributions to the VFL process. We formulate this problem as a variant of theNucleolus game theory concept, known as the Bankruptcy Problem, and solve itusing the Talmud's division rule. We evaluate our proposed method on syntheticand real-world datasets and show that it ensures fairness and stability inincentive allocation among passive parties who contribute their data to thefederated model. Additionally, we compare our method to the existing solutionof calculating Shapley values and show that our approach provides a moreefficient solution with fewer computations.</description><author>Afsana Khan, Marijn ten Thij, Frank Thuijsman, Anna Wilbik</author><pubDate>Fri, 07 Jul 2023 12:08:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03515v1</guid></item><item><title>Tranfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data</title><link>http://arxiv.org/abs/2307.03512v1</link><description>When applying deep learning to remote sensing data in archaeologicalresearch, a notable obstacle is the limited availability of suitable datasetsfor training models. The application of transfer learning is frequentlyemployed to mitigate this drawback. However, there is still a need to exploreits effectiveness when applied across different archaeological datasets. Thispaper compares the performance of various transfer learning configurationsusing two semantic segmentation deep neural networks on two LiDAR datasets. Theexperimental results indicate that transfer learning-based approaches inarchaeology can lead to performance improvements, although a systematicenhancement has not yet been observed. We provide specific insights about thevalidity of such techniques that can serve as a baseline for future works.</description><author>Paolo Soleni, Wouter B. Verschoof-van der Vaart, Å½iga Kokalj, Arianna Traviglia, Marco Fiorucci</author><pubDate>Fri, 07 Jul 2023 12:00:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03512v1</guid></item><item><title>Machine-Learning-Assisted and Real-Time-Feedback-Controlled Growth of InAs/GaAs Quantum Dots</title><link>http://arxiv.org/abs/2306.12898v2</link><description>Self-assembled InAs/GaAs quantum dots (QDs) have properties highly valuablefor developing various optoelectronic devices such as QD lasers and singlephoton sources. The applications strongly rely on the density and quality ofthese dots, which has motivated studies of the growth process control torealize high-quality epi-wafers and devices. Establishing the processparameters in molecular beam epitaxy (MBE) for a specific density of QDs is amultidimensional optimization challenge, usually addressed throughtime-consuming and iterative trial-and-error. Here, we report a real-timefeedback control method to realize the growth of QDs with arbitrary and precisedensity, which is fully automated and intelligent. We developed a machinelearning (ML) model named 3D ResNet, specially designed for training RHEEDvideos instead of static images and providing real-time feedback on surfacemorphologies for process control. As a result, we demonstrated that ML fromprevious growth could predict the post-growth density of QDs, by successfullytuning the QD densities in near-real time from 1.5E10 cm-2 down to 3.8E8 cm-2or up to 1.4E11 cm-2. Compared to traditional methods, our approach, within-situ tuning capabilities and excellent reliability, can dramaticallyexpedite the material optimization process and improve the reproducibility ofMBE growth, constituting significant progress for thin film growth techniques.The concepts and methodologies proved feasible in this work are promising to beapplied to a variety of material growth processes, which will revolutionizesemiconductor manufacturing for microelectronic and optoelectronic industries.</description><author>Chao Shen, Wenkang Zhan, Kaiyao Xin, Manyang Li, Zhenyu Sun, Jian Tang, Zhaofeng Wu, Bo Xu, Zhongming Wei, Chao Zhao, Zhanguo Wang</author><pubDate>Fri, 07 Jul 2023 11:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12898v2</guid></item><item><title>Black-Box Batch Active Learning for Regression</title><link>http://arxiv.org/abs/2302.08981v2</link><description>Batch active learning is a popular approach for efficiently training machinelearning models on large, initially unlabelled datasets by repeatedly acquiringlabels for batches of data points. However, many recent batch active learningmethods are white-box approaches and are often limited to differentiableparametric models: they score unlabeled points using acquisition functionsbased on model embeddings or first- and second-order derivatives. In thispaper, we propose black-box batch active learning for regression tasks as anextension of white-box approaches. Crucially, our method only relies on modelpredictions. This approach is compatible with a wide range of machine learningmodels, including regular and Bayesian deep learning models andnon-differentiable models such as random forests. It is rooted in Bayesianprinciples and utilizes recent kernel-based approaches. This allows us toextend a wide range of existing state-of-the-art white-box batch activelearning methods (BADGE, BAIT, LCMD) to black-box models. We demonstrate theeffectiveness of our approach through extensive experimental evaluations onregression datasets, achieving surprisingly strong performance compared towhite-box approaches for deep learning models.</description><author>Andreas Kirsch</author><pubDate>Fri, 07 Jul 2023 11:49:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08981v2</guid></item><item><title>Derivative Free Weight-space Ensembling</title><link>http://arxiv.org/abs/2307.03506v1</link><description>Recent work suggests that interpolating between the weights of twospecialized language models can transfer knowledge between tasks in a way thatmulti-task learning cannot. However, very few have explored interpolationbetween more than two models, where each has a distinct knowledge base. In thispaper, we introduce Derivative Free Weight-space Ensembling (DFWE), a newfew-sample task transfer approach for open-domain dialogue. Our frameworkcreates a set of diverse expert language models trained using a predefined setof source tasks. Next, we finetune each of the expert models on the targettask, approaching the target task from several distinct knowledge bases.Finally, we linearly interpolate between the model weights using agradient-free-optimization algorithm, to efficiently find a good interpolationweighting. We demonstrate the effectiveness of the method on FETA-Friendsoutperforming the standard pretrain-finetune approach.</description><author>Dean Ninalga</author><pubDate>Fri, 07 Jul 2023 11:42:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03506v1</guid></item><item><title>RCDN -- Robust X-Corner Detection Algorithm based on Advanced CNN Model</title><link>http://arxiv.org/abs/2307.03505v1</link><description>Accurate detection and localization of X-corner on both planar and non-planarpatterns is a core step in robotics and machine vision. However, previous workscould not make a good balance between accuracy and robustness, which are bothcrucial criteria to evaluate the detectors performance. To address thisproblem, in this paper we present a novel detection algorithm which canmaintain high sub-pixel precision on inputs under multiple interference, suchas lens distortion, extreme poses and noise. The whole algorithm, adopting acoarse-to-fine strategy, contains a X-corner detection network and threepost-processing techniques to distinguish the correct corner candidates, aswell as a mixed sub-pixel refinement technique and an improved region growthstrategy to recover the checkerboard pattern partially visible or occludedautomatically. Evaluations on real and synthetic images indicate that thepresented algorithm has the higher detection rate, sub-pixel accuracy androbustness than other commonly used methods. Finally, experiments of cameracalibration and pose estimation verify it can also get smaller re-projectionerror in quantitative comparisons to the state-of-the-art.</description><author>Ben Chen, Caihua Xiong, Quanlin Li, Zhonghua Wan</author><pubDate>Fri, 07 Jul 2023 11:40:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03505v1</guid></item><item><title>Harmonizing Feature Attributions Across Deep Learning Architectures: Enhancing Interpretability and Consistency</title><link>http://arxiv.org/abs/2307.02150v2</link><description>Ensuring the trustworthiness and interpretability of machine learning modelsis critical to their deployment in real-world applications. Feature attributionmethods have gained significant attention, which provide local explanations ofmodel predictions by attributing importance to individual input features. Thisstudy examines the generalization of feature attributions across various deeplearning architectures, such as convolutional neural networks (CNNs) and visiontransformers. We aim to assess the feasibility of utilizing a featureattribution method as a future detector and examine how these features can beharmonized across multiple models employing distinct architectures but trainedon the same data distribution. By exploring this harmonization, we aim todevelop a more coherent and optimistic understanding of feature attributions,enhancing the consistency of local explanations across diverse deep-learningmodels. Our findings highlight the potential for harmonized feature attributionmethods to improve interpretability and foster trust in machine learningapplications, regardless of the underlying architecture.</description><author>Md Abdul Kadir, Gowtham Krishna Addluri, Daniel Sonntag</author><pubDate>Fri, 07 Jul 2023 11:38:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02150v2</guid></item><item><title>Segmentation of the Left Ventricle by SDD double threshold selection and CHT</title><link>http://arxiv.org/abs/2007.10665v2</link><description>Automatic and robust segmentation of the left ventricle (LV) in magneticresonance images (MRI) has remained challenging for many decades. With thegreat success of deep learning in object detection and classification, theresearch focus of LV segmentation has changed to convolutional neural network(CNN) in recent years. However, LV segmentation is a pixel-level classificationproblem and its categories are intractable compared to object detection andclassification. In this paper, we proposed a robust LV segmentation methodbased on slope difference distribution (SDD) double threshold selection andcircular Hough transform (CHT). The proposed method achieved 96.51% DICE scoreon the test set of automated cardiac diagnosis challenge (ACDC) which is higherthan the best accuracy reported in recently published literatures.</description><author>ZiHao Wang, ZhenZhou Wang</author><pubDate>Fri, 07 Jul 2023 11:36:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2007.10665v2</guid></item><item><title>DEFT: Exploiting Gradient Norm Difference between Model Layers for Scalable Gradient Sparsification</title><link>http://arxiv.org/abs/2307.03500v1</link><description>Gradient sparsification is a widely adopted solution for reducing theexcessive communication traffic in distributed deep learning. However, mostexisting gradient sparsifiers have relatively poor scalability because ofconsiderable computational cost of gradient selection and/or increasedcommunication traffic owing to gradient build-up. To address these challenges,we propose a novel gradient sparsification scheme, DEFT, that partitions thegradient selection task into sub tasks and distributes them to workers. DEFTdiffers from existing sparsifiers, wherein every worker selects gradients amongall gradients. Consequently, the computational cost can be reduced as thenumber of workers increases. Moreover, gradient build-up can be eliminatedbecause DEFT allows workers to select gradients in partitions that arenon-intersecting (between workers). Therefore, even if the number of workersincreases, the communication traffic can be maintained as per user requirement. To avoid the loss of significance of gradient selection, DEFT selects moregradients in the layers that have a larger gradient norm than the other layers.Because every layer has a different computational load, DEFT allocates layersto workers using a bin-packing algorithm to maintain a balanced load ofgradient selection between workers. In our empirical evaluation, DEFT shows asignificant improvement in training performance in terms of speed in gradientselection over existing sparsifiers while achieving high convergenceperformance.</description><author>Daegun Yoon, Sangyoon Oh</author><pubDate>Fri, 07 Jul 2023 11:29:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03500v1</guid></item><item><title>HoughLaneNet: Lane Detection with Deep Hough Transform and Dynamic Convolution</title><link>http://arxiv.org/abs/2307.03494v1</link><description>The task of lane detection has garnered considerable attention in the fieldof autonomous driving due to its complexity. Lanes can present difficulties fordetection, as they can be narrow, fragmented, and often obscured by heavytraffic. However, it has been observed that the lanes have a geometricalstructure that resembles a straight line, leading to improved lane detectionresults when utilizing this characteristic. To address this challenge, wepropose a hierarchical Deep Hough Transform (DHT) approach that combines alllane features in an image into the Hough parameter space. Additionally, werefine the point selection method and incorporate a Dynamic Convolution Moduleto effectively differentiate between lanes in the original image. Our networkarchitecture comprises a backbone network, either a ResNet or Pyramid VisionTransformer, a Feature Pyramid Network as the neck to extract multi-scalefeatures, and a hierarchical DHT-based feature aggregation head to accuratelysegment each lane. By utilizing the lane features in the Hough parameter space,the network learns dynamic convolution kernel parameters corresponding to eachlane, allowing the Dynamic Convolution Module to effectively differentiatebetween lane features. Subsequently, the lane features are fed into the featuredecoder, which predicts the final position of the lane. Our proposed networkstructure demonstrates improved performance in detecting heavily occluded orworn lane images, as evidenced by our extensive experimental results, whichshow that our method outperforms or is on par with state-of-the-art techniques.</description><author>Jia-Qi Zhang, Hao-Bin Duan, Jun-Long Chen, Ariel Shamir, Miao Wang</author><pubDate>Fri, 07 Jul 2023 11:08:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03494v1</guid></item><item><title>ITA: An Energy-Efficient Attention and Softmax Accelerator for Quantized Transformers</title><link>http://arxiv.org/abs/2307.03493v1</link><description>Transformer networks have emerged as the state-of-the-art approach fornatural language processing tasks and are gaining popularity in other domainssuch as computer vision and audio processing. However, the efficient hardwareacceleration of transformer models poses new challenges due to their higharithmetic intensities, large memory requirements, and complex dataflowdependencies. In this work, we propose ITA, a novel accelerator architecturefor transformers and related models that targets efficient inference onembedded systems by exploiting 8-bit quantization and an innovative softmaximplementation that operates exclusively on integer values. By computingon-the-fly in streaming mode, our softmax implementation minimizes datamovement and energy consumption. ITA achieves competitive energy efficiencywith respect to state-of-the-art transformer accelerators with 16.9 TOPS/W,while outperforming them in area efficiency with 5.93 TOPS/mm$^2$ in 22 nmfully-depleted silicon-on-insulator technology at 0.8 V.</description><author>Gamze Ä°slamoÄŸlu, Moritz Scherer, Gianna Paulin, Tim Fischer, Victor J. B. Jung, Angelo Garofalo, Luca Benini</author><pubDate>Fri, 07 Jul 2023 11:05:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03493v1</guid></item><item><title>Large AI Model-Based Semantic Communications</title><link>http://arxiv.org/abs/2307.03492v1</link><description>Semantic communication (SC) is an emerging intelligent paradigm, offeringsolutions for various future applications like metaverse, mixed-reality, andthe Internet of everything. However, in current SC systems, the construction ofthe knowledge base (KB) faces several issues, including limited knowledgerepresentation, frequent knowledge updates, and insecure knowledge sharing.Fortunately, the development of the large AI model provides new solutions toovercome above issues. Here, we propose a large AI model-based SC framework(LAM-SC) specifically designed for image data, where we first design thesegment anything model (SAM)-based KB (SKB) that can split the original imageinto different semantic segments by universal semantic knowledge. Then, wepresent an attention-based semantic integration (ASI) to weigh the semanticsegments generated by SKB without human participation and integrate them as thesemantic-aware image. Additionally, we propose an adaptive semantic compression(ASC) encoding to remove redundant information in semantic features, therebyreducing communication overhead. Finally, through simulations, we demonstratethe effectiveness of the LAM-SC framework and the significance of the large AImodel-based KB development in future SC paradigms.</description><author>Feibo Jiang, Yubo Peng, Li Dong, Kezhi Wang, Kun Yang, Cunhua Pan, Xiaohu You</author><pubDate>Fri, 07 Jul 2023 11:01:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03492v1</guid></item><item><title>Memory-efficient NLLB-200: Language-specific Expert Pruning of a Massively Multilingual Machine Translation Model</title><link>http://arxiv.org/abs/2212.09811v3</link><description>The recently released NLLB-200 is a set of multilingual Neural MachineTranslation models that cover 202 languages. The largest model is based on aMixture of Experts architecture and achieves SoTA results across many languagepairs. It contains 54.5B parameters and requires at least four 32GB GPUs justfor inference. In this work, we propose a pruning method that enables theremoval of up to 80% of experts without further finetuning and with anegligible loss in translation quality, which makes it feasible to run themodel on a single 32GB GPU. Further analysis suggests that our pruning metricscan identify language-specific experts.</description><author>Yeskendir Koishekenov, Alexandre Berard, Vassilina Nikoulina</author><pubDate>Fri, 07 Jul 2023 10:53:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.09811v3</guid></item><item><title>Learning Theory of Distribution Regression with Neural Networks</title><link>http://arxiv.org/abs/2307.03487v1</link><description>In this paper, we aim at establishing an approximation theory and a learningtheory of distribution regression via a fully connected neural network (FNN).In contrast to the classical regression methods, the input variables ofdistribution regression are probability measures. Then we often need to performa second-stage sampling process to approximate the actual information of thedistribution. On the other hand, the classical neural network structurerequires the input variable to be a vector. When the input samples areprobability distributions, the traditional deep neural network method cannot bedirectly used and the difficulty arises for distribution regression. Awell-defined neural network structure for distribution inputs is intensivelydesirable. There is no mathematical model and theoretical analysis on neuralnetwork realization of distribution regression. To overcome technicaldifficulties and address this issue, we establish a novel fully connectedneural network framework to realize an approximation theory of functionalsdefined on the space of Borel probability measures. Furthermore, based on theestablished functional approximation results, in the hypothesis space inducedby the novel FNN structure with distribution inputs, almost optimal learningrates for the proposed distribution regression model up to logarithmic termsare derived via a novel two-stage error decomposition technique.</description><author>Zhongjie Shi, Zhan Yu, Ding-Xuan Zhou</author><pubDate>Fri, 07 Jul 2023 10:49:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03487v1</guid></item><item><title>Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning</title><link>http://arxiv.org/abs/2307.03486v1</link><description>Discovering achievements with a hierarchical structure on procedurallygenerated environments poses a significant challenge. This requires agents topossess a broad range of abilities, including generalization and long-termreasoning. Many prior methods are built upon model-based or hierarchicalapproaches, with the belief that an explicit module for long-term planningwould be beneficial for learning hierarchical achievements. However, thesemethods require an excessive amount of environment interactions or large modelsizes, limiting their practicality. In this work, we identify that proximalpolicy optimization (PPO), a simple and versatile model-free algorithm,outperforms the prior methods with recent implementation practices. Moreover,we find that the PPO agent can predict the next achievement to be unlocked tosome extent, though with low confidence. Based on this observation, we proposea novel contrastive learning method, called achievement distillation, thatstrengthens the agent's capability to predict the next achievement. Our methodexhibits a strong capacity for discovering hierarchical achievements and showsstate-of-the-art performance on the challenging Crafter environment using fewermodel parameters in a sample-efficient regime.</description><author>Seungyong Moon, Junyoung Yeom, Bumsoo Park, Hyun Oh Song</author><pubDate>Fri, 07 Jul 2023 10:47:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03486v1</guid></item><item><title>Layer Ensembles</title><link>http://arxiv.org/abs/2210.04882v3</link><description>Deep Ensembles, as a type of Bayesian Neural Networks, can be used toestimate uncertainty on the prediction of multiple neural networks bycollecting votes from each network and computing the difference in thosepredictions. In this paper, we introduce a method for uncertainty estimationthat considers a set of independent categorical distributions for each layer ofthe network, giving many more possible samples with overlapped layers than inthe regular Deep Ensembles. We further introduce an optimized inferenceprocedure that reuses common layer outputs, achieving up to 19x speed up andreducing memory usage quadratically. We also show that the method can befurther improved by ranking samples, resulting in models that require lessmemory and time to run while achieving higher uncertainty quality than DeepEnsembles.</description><author>Illia Oleksiienko, Alexandros Iosifidis</author><pubDate>Fri, 07 Jul 2023 10:46:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.04882v3</guid></item><item><title>Offline Prioritized Experience Replay</title><link>http://arxiv.org/abs/2306.05412v2</link><description>Offline reinforcement learning (RL) is challenged by the distributional shiftproblem. To address this problem, existing works mainly focus on designingsophisticated policy constraints between the learned policy and the behaviorpolicy. However, these constraints are applied equally to well-performing andinferior actions through uniform sampling, which might negatively affect thelearned policy. To alleviate this issue, we propose Offline PrioritizedExperience Replay (OPER), featuring a class of priority functions designed toprioritize highly-rewarding transitions, making them more frequently visitedduring training. Through theoretical analysis, we show that this class ofpriority functions induce an improved behavior policy, and when constrained tothis improved policy, a policy-constrained offline RL algorithm is likely toyield a better solution. We develop two practical strategies to obtain priorityweights by estimating advantages based on a fitted value network (OPER-A) orutilizing trajectory returns (OPER-R) for quick computation. OPER is aplug-and-play component for offline RL algorithms. As case studies, we evaluateOPER on five different algorithms, including BC, TD3+BC, Onestep RL, CQL, andIQL. Extensive experiments demonstrate that both OPER-A and OPER-Rsignificantly improve the performance for all baseline methods. Codes andpriority weights are availiable at https://github.com/sail-sg/OPER.</description><author>Yang Yue, Bingyi Kang, Xiao Ma, Gao Huang, Shiji Song, Shuicheng Yan</author><pubDate>Fri, 07 Jul 2023 10:32:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05412v2</guid></item><item><title>TabLeak: Tabular Data Leakage in Federated Learning</title><link>http://arxiv.org/abs/2210.01785v2</link><description>While federated learning (FL) promises to preserve privacy, recent works inthe image and text domains have shown that training updates leak private clientdata. However, most high-stakes applications of FL (e.g., in healthcare andfinance) use tabular data, where the risk of data leakage has not yet beenexplored. A successful attack for tabular data must address two key challengesunique to the domain: (i) obtaining a solution to a high-variance mixeddiscrete-continuous optimization problem, and (ii) enabling human assessment ofthe reconstruction as unlike for image and text data, direct human inspectionis not possible. In this work we address these challenges and propose TabLeak,the first comprehensive reconstruction attack on tabular data. TabLeak is basedon two key contributions: (i) a method which leverages a softmax relaxation andpooled ensembling to solve the optimization problem, and (ii) an entropy-baseduncertainty quantification scheme to enable human assessment. We evaluateTabLeak on four tabular datasets for both FedSGD and FedAvg training protocols,and show that it successfully breaks several settings previously deemed safe.For instance, we extract large subsets of private data at &gt;90% accuracy even atthe large batch size of 128. Our findings demonstrate that current high-stakestabular FL is excessively vulnerable to leakage attacks.</description><author>Mark Vero, Mislav BalunoviÄ‡, Dimitar I. Dimitrov, Martin Vechev</author><pubDate>Fri, 07 Jul 2023 10:32:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.01785v2</guid></item><item><title>The Relationship Between Speech Features Changes When You Get Depressed: Feature Correlations for Improving Speed and Performance of Depression Detection</title><link>http://arxiv.org/abs/2307.02892v2</link><description>This work shows that depression changes the correlation between featuresextracted from speech. Furthermore, it shows that using such an insight canimprove the training speed and performance of depression detectors based onSVMs and LSTMs. The experiments were performed over the Androids Corpus, apublicly available dataset involving 112 speakers, including 58 peoplediagnosed with depression by professional psychiatrists. The results show thatthe models used in the experiments improve in terms of training speed andperformance when fed with feature correlation matrices rather than with featurevectors. The relative reduction of the error rate ranges between 23.1% and26.6% depending on the model. The probable explanation is that featurecorrelation matrices appear to be more variable in the case of depressedspeakers. Correspondingly, such a phenomenon can be thought of as a depressionmarker.</description><author>Fuxiang Tao, Wei Ma, Xuri Ge, Anna Esposito, Alessandro Vinciarelli</author><pubDate>Fri, 07 Jul 2023 10:31:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02892v2</guid></item><item><title>k-strip: A novel segmentation algorithm in k-space for the application of skull stripping</title><link>http://arxiv.org/abs/2205.09706v2</link><description>Objectives: Present a novel deep learning-based skull stripping algorithm formagnetic resonance imaging (MRI) that works directly in the information richk-space. Materials and Methods: Using two datasets from different institutions with atotal of 36,900 MRI slices, we trained a deep learning-based model to workdirectly with the complex raw k-space data. Skull stripping performed by HD-BET(Brain Extraction Tool) in the image domain were used as the ground truth. Results: Both datasets were very similar to the ground truth (DICE scores of92\%-98\% and Hausdorff distances of under 5.5 mm). Results on slices above theeye-region reach DICE scores of up to 99\%, while the accuracy drops in regionsaround the eyes and below, with partially blurred output. The output of k-stripoften smoothed edges at the demarcation to the skull. Binary masks are createdwith an appropriate threshold. Conclusion: With this proof-of-concept study, we were able to show thefeasibility of working in the k-space frequency domain, preserving phaseinformation, with consistent results. Future research should be dedicated todiscovering additional ways the k-space can be used for innovative imageanalysis and further workflows.</description><author>Moritz Rempe, Florian Mentzel, Kelsey L. Pomykala, Johannes Haubold, Felix Nensa, Kevin KrÃ¶ninger, Jan Egger, Jens Kleesiek</author><pubDate>Fri, 07 Jul 2023 10:29:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.09706v2</guid></item></channel></rss>