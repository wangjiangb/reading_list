<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 20 Jun 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Coaching a Teachable Student</title><link>http://arxiv.org/abs/2306.10014v1</link><description>We propose a novel knowledge distillation framework for effectively teachinga sensorimotor student agent to drive from the supervision of a privilegedteacher agent. Current distillation for sensorimotor agents methods tend toresult in suboptimal learned driving behavior by the student, which wehypothesize is due to inherent differences between the input, modelingcapacity, and optimization processes of the two agents. We develop a noveldistillation scheme that can address these limitations and close the gapbetween the sensorimotor agent and its privileged teacher. Our key insight isto design a student which learns to align their input features with theteacher's privileged Bird's Eye View (BEV) space. The student then can benefitfrom direct supervision by the teacher over the internal representationlearning. To scaffold the difficult sensorimotor learning task, the studentmodel is optimized via a student-paced coaching mechanism with variousauxiliary supervision. We further propose a high-capacity imitation learnedprivileged agent that surpasses prior privileged agents in CARLA and ensuresthe student learns safe driving behavior. Our proposed sensorimotor agentresults in a robust image-based behavior cloning agent in CARLA, improving overcurrent models by over 20.6% in driving score without requiring LiDAR,historical observations, ensemble of models, on-policy data aggregation orreinforcement learning.</description><author>Jimuyang Zhang, Zanming Huang, Eshed Ohn-Bar</author><pubDate>Fri, 16 Jun 2023 18:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10014v1</guid></item><item><title>PanoOcc: Unified Occupancy Representation for Camera-based 3D Panoptic Segmentation</title><link>http://arxiv.org/abs/2306.10013v1</link><description>Comprehensive modeling of the surrounding 3D world is key to the success ofautonomous driving. However, existing perception tasks like object detection,road structure segmentation, depth &amp; elevation estimation, and open-set objectlocalization each only focus on a small facet of the holistic 3D sceneunderstanding task. This divide-and-conquer strategy simplifies the algorithmdevelopment procedure at the cost of losing an end-to-end unified solution tothe problem. In this work, we address this limitation by studying camera-based3D panoptic segmentation, aiming to achieve a unified occupancy representationfor camera-only 3D scene understanding. To achieve this, we introduce a novelmethod called PanoOcc, which utilizes voxel queries to aggregate spatiotemporalinformation from multi-frame and multi-view images in a coarse-to-fine scheme,integrating feature learning and scene representation into a unified occupancyrepresentation. We have conducted extensive ablation studies to verify theeffectiveness and efficiency of the proposed method. Our approach achieves newstate-of-the-art results for camera-based semantic segmentation and panopticsegmentation on the nuScenes dataset. Furthermore, our method can be easilyextended to dense occupancy prediction and has shown promising performance onthe Occ3D benchmark. The code will be released athttps://github.com/Robertwyq/PanoOcc.</description><author>Yuqi Wang, Yuntao Chen, Xingyu Liao, Lue Fan, Zhaoxiang Zhang</author><pubDate>Fri, 16 Jun 2023 18:59:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10013v1</guid></item><item><title>ChemCrow: Augmenting large-language models with chemistry tools</title><link>http://arxiv.org/abs/2304.05376v3</link><description>Over the last decades, excellent computational chemistry tools have beendeveloped. Their full potential has not yet been reached as most arechallenging to learn and exist in isolation. Recently, large-language models(LLMs) have shown strong performance in tasks across domains, but struggle withchemistry-related problems. Moreover, these models lack access to externalknowledge sources, limiting their usefulness in scientific applications. Inthis study, we introduce ChemCrow, an LLM chemistry agent designed toaccomplish tasks across organic synthesis, drug discovery, and materialsdesign. By integrating 18 expert-designed tools, ChemCrow augments the LLMperformance in chemistry, and new capabilities emerge. Our agent autonomouslyplanned and executed the syntheses of an insect repellent, threeorganocatalysts, and guided the discovery of a novel chromophore. Ourevaluation, including both LLM and expert assessments, demonstrates ChemCrow'seffectiveness in automating a diverse set of chemical tasks. Surprisingly, wefind that GPT-4 as an evaluator cannot distinguish between clearly wrong GPT-4completions and Chemcrow's performance. There is a significant risk of misuseof tools like ChemCrow, and we discuss their potential harms. Employedresponsibly, our work not only aids expert chemists and lowers barriers fornon-experts, but also fosters scientific advancement by bridging the gapbetween experimental and computational chemistry. Publicly available code canbe found at https://github.com/ur-whitelab/chemcrow-public</description><author>Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, Philippe Schwaller</author><pubDate>Fri, 16 Jun 2023 18:59:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05376v3</guid></item><item><title>MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image Editing</title><link>http://arxiv.org/abs/2306.10012v1</link><description>Text-guided image editing is widely needed in daily life, ranging frompersonal use to professional applications such as Photoshop. However, existingmethods are either zero-shot or trained on an automatically synthesizeddataset, which contains a high volume of noise. Thus, they still require lotsof manual tuning to produce desirable outcomes in practice. To address thisissue, we introduce MagicBrush (https://osu-nlp-group.github.io/MagicBrush/),the first large-scale, manually annotated dataset for instruction-guided realimage editing that covers diverse scenarios: single-turn, multi-turn,mask-provided, and mask-free editing. MagicBrush comprises over 10K manuallyannotated triples (source image, instruction, target image), which supportstrainining large-scale text-guided image editing models. We fine-tuneInstructPix2Pix on MagicBrush and show that the new model can produce muchbetter images according to human evaluation. We further conduct extensiveexperiments to evaluate current image editing baselines from multipledimensions including quantitative, qualitative, and human evaluations. Theresults reveal the challenging nature of our dataset and the gap betweencurrent baselines and real-world editing needs.</description><author>Kai Zhang, Lingbo Mo, Wenhu Chen, Huan Sun, Yu Su</author><pubDate>Fri, 16 Jun 2023 18:58:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10012v1</guid></item><item><title>CLIP2Protect: Protecting Facial Privacy using Text-Guided Makeup via Adversarial Latent Search</title><link>http://arxiv.org/abs/2306.10008v1</link><description>The success of deep learning based face recognition systems has given rise toserious privacy concerns due to their ability to enable unauthorized trackingof users in the digital world. Existing methods for enhancing privacy fail togenerate naturalistic images that can protect facial privacy withoutcompromising user experience. We propose a novel two-step approach for facialprivacy protection that relies on finding adversarial latent codes in thelow-dimensional manifold of a pretrained generative model. The first stepinverts the given face image into the latent space and finetunes the generativemodel to achieve an accurate reconstruction of the given image from its latentcode. This step produces a good initialization, aiding the generation ofhigh-quality faces that resemble the given identity. Subsequently, user-definedmakeup text prompts and identity-preserving regularization are used to guidethe search for adversarial codes in the latent space. Extensive experimentsdemonstrate that faces generated by our approach have stronger black-boxtransferability with an absolute gain of 12.06% over the state-of-the-artfacial privacy protection approach under the face verification task. Finally,we demonstrate the effectiveness of the proposed approach for commercial facerecognition systems. Our code is available athttps://github.com/fahadshamshad/Clip2Protect.</description><author>Fahad Shamshad, Muzammal Naseer, Karthik Nandakumar</author><pubDate>Fri, 16 Jun 2023 18:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10008v1</guid></item><item><title>Robot Learning with Sensorimotor Pre-training</title><link>http://arxiv.org/abs/2306.10007v1</link><description>We present a self-supervised sensorimotor pre-training approach for robotics.Our model, called RPT, is a Transformer that operates on sequences ofsensorimotor tokens. Given a sequence of camera images, proprioceptive robotstates, and past actions, we encode the interleaved sequence into tokens, maskout a random subset, and train a model to predict the masked-out content. Wehypothesize that if the robot can predict the missing content it has acquired agood model of the physical world that can enable it to act. RPT is designed tooperate on latent visual representations which makes prediction tractable,enables scaling to 10x larger models, and 10 Hz inference on a real robot. Toevaluate our approach, we collect a dataset of 20,000 real-world trajectoriesover 9 months using a combination of motion planning and model-based graspingalgorithms. We find that pre-training on this data consistently outperformstraining from scratch, leads to 2x improvements in the block stacking task, andhas favorable scaling properties.</description><author>Ilija Radosavovic, Baifeng Shi, Letian Fu, Ken Goldberg, Trevor Darrell, Jitendra Malik</author><pubDate>Fri, 16 Jun 2023 18:58:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10007v1</guid></item><item><title>Unsupervised Learning of Style-Aware Facial Animation from Real Acting Performances</title><link>http://arxiv.org/abs/2306.10006v1</link><description>This paper presents a novel approach for text/speech-driven animation of aphoto-realistic head model based on blend-shape geometry, dynamic textures, andneural rendering. Training a VAE for geometry and texture yields a parametricmodel for accurate capturing and realistic synthesis of facial expressions froma latent feature vector. Our animation method is based on a conditional CNNthat transforms text or speech into a sequence of animation parameters. Incontrast to previous approaches, our animation model learnsdisentangling/synthesizing different acting-styles in an unsupervised manner,requiring only phonetic labels that describe the content of training sequences.For realistic real-time rendering, we train a U-Net that refinesrasterization-based renderings by computing improved pixel colors and aforeground matte. We compare our framework qualitatively/quantitatively againstrecent methods for head modeling as well as facial animation and evaluate theperceived rendering/animation quality in a user-study, which indicates largeimprovements compared to state-of-the-art approaches</description><author>Wolfgang Paier, Anna Hilsmann, Peter Eisert</author><pubDate>Fri, 16 Jun 2023 18:58:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10006v1</guid></item><item><title>Cross-view Geo-localization via Learning Disentangled Geometric Layout Correspondence</title><link>http://arxiv.org/abs/2212.04074v3</link><description>Cross-view geo-localization aims to estimate the location of a query groundimage by matching it to a reference geo-tagged aerial images database. As anextremely challenging task, its difficulties root in the drastic view changesand different capturing time between two views. Despite these difficulties,recent works achieve outstanding progress on cross-view geo-localizationbenchmarks. However, existing methods still suffer from poor performance on thecross-area benchmarks, in which the training and testing data are captured fromtwo different regions. We attribute this deficiency to the lack of ability toextract the spatial configuration of visual feature layouts and models'overfitting on low-level details from the training set. In this paper, wepropose GeoDTR which explicitly disentangles geometric information from rawfeatures and learns the spatial correlations among visual features from aerialand ground pairs with a novel geometric layout extractor module. This modulegenerates a set of geometric layout descriptors, modulating the raw featuresand producing high-quality latent representations. In addition, we elaborate ontwo categories of data augmentations, (i) Layout simulation, which varies thespatial configuration while keeping the low-level details intact. (ii) Semanticaugmentation, which alters the low-level details and encourages the model tocapture spatial configurations. These augmentations help to improve theperformance of the cross-view geo-localization models, especially on thecross-area benchmarks. Moreover, we propose a counterfactual-based learningprocess to benefit the geometric layout extractor in exploring spatialinformation. Extensive experiments show that GeoDTR not only achievesstate-of-the-art results but also significantly boosts the performance onsame-area and cross-area benchmarks.</description><author>Xiaohan Zhang, Xingyu Li, Waqas Sultani, Yi Zhou, Safwan Wshah</author><pubDate>Fri, 16 Jun 2023 18:57:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.04074v3</guid></item><item><title>C2F2NeUS: Cascade Cost Frustum Fusion for High Fidelity and Generalizable Neural Surface Reconstruction</title><link>http://arxiv.org/abs/2306.10003v1</link><description>There is an emerging effort to combine the two popular technical paths, i.e.,the multi-view stereo (MVS) and neural implicit surface (NIS), in scenereconstruction from sparse views. In this paper, we introduce a novelintegration scheme that combines the multi-view stereo with neural signeddistance function representations, which potentially overcomes the limitationsof both methods. MVS uses per-view depth estimation and cross-view fusion togenerate accurate surface, while NIS relies on a common coordinate volume.Based on this, we propose to construct per-view cost frustum for finer geometryestimation, and then fuse cross-view frustums and estimate the implicit signeddistance functions to tackle noise and hole issues. We further apply a cascadefrustum fusion strategy to effectively captures global-local information andstructural consistency. Finally, we apply cascade sampling and apseudo-geometric loss to foster stronger integration between the twoarchitectures. Extensive experiments demonstrate that our method reconstructsrobust surfaces and outperforms existing state-of-the-art methods.</description><author>Luoyuan Xu, Tao Guan, Yuesong Wang, Wenkai Liu, Zhaojie Zeng, Junle Wang, Wei Yang</author><pubDate>Fri, 16 Jun 2023 18:56:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10003v1</guid></item><item><title>Datasets and Benchmarks for Offline Safe Reinforcement Learning</title><link>http://arxiv.org/abs/2306.09303v2</link><description>This paper presents a comprehensive benchmarking suite tailored to offlinesafe reinforcement learning (RL) challenges, aiming to foster progress in thedevelopment and evaluation of safe learning algorithms in both the training anddeployment phases. Our benchmark suite contains three packages: 1) expertlycrafted safe policies, 2) D4RL-styled datasets along with environment wrappers,and 3) high-quality offline safe RL baseline implementations. We feature amethodical data collection pipeline powered by advanced safe RL algorithms,which facilitates the generation of diverse datasets across 38 popular safe RLtasks, from robot control to autonomous driving. We further introduce an arrayof data post-processing filters, capable of modifying each dataset's diversity,thereby simulating various data collection conditions. Additionally, we provideelegant and extensible implementations of prevalent offline safe RL algorithmsto accelerate research in this area. Through extensive experiments with over50000 CPU and 800 GPU hours of computations, we evaluate and compare theperformance of these baseline algorithms on the collected datasets, offeringinsights into their strengths, limitations, and potential areas of improvement.Our benchmarking framework serves as a valuable resource for researchers andpractitioners, facilitating the development of more robust and reliable offlinesafe RL solutions in safety-critical applications. The benchmark website isavailable at \url{www.offline-saferl.org}.</description><author>Zuxin Liu, Zijian Guo, Haohong Lin, Yihang Yao, Jiacheng Zhu, Zhepeng Cen, Hanjiang Hu, Wenhao Yu, Tingnan Zhang, Jie Tan, Ding Zhao</author><pubDate>Fri, 16 Jun 2023 18:54:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09303v2</guid></item><item><title>Group Orthogonalization Regularization For Vision Models Adaptation and Robustness</title><link>http://arxiv.org/abs/2306.10001v1</link><description>As neural networks become deeper, the redundancy within their parametersincreases. This phenomenon has led to several methods that attempt to reducethe correlation between convolutional filters. We propose a computationallyefficient regularization technique that encourages orthonormality betweengroups of filters within the same layer. Our experiments show that whenincorporated into recent adaptation methods for diffusion models and visiontransformers (ViTs), this regularization improves performance on downstreamtasks. We further show improved robustness when group orthogonality is enforcedduring adversarial training. Our code is available athttps://github.com/YoavKurtz/GOR.</description><author>Yoav Kurtz, Noga Bar, Raja Giryes</author><pubDate>Fri, 16 Jun 2023 18:53:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10001v1</guid></item><item><title>SLACK: Stable Learning of Augmentations with Cold-start and KL regularization</title><link>http://arxiv.org/abs/2306.09998v1</link><description>Data augmentation is known to improve the generalization capabilities ofneural networks, provided that the set of transformations is chosen with care,a selection often performed manually. Automatic data augmentation aims atautomating this process. However, most recent approaches still rely on someprior information; they start from a small pool of manually-selected defaulttransformations that are either used to pretrain the network or forced to bepart of the policy learned by the automatic data augmentation algorithm. Inthis paper, we propose to directly learn the augmentation policy withoutleveraging such prior knowledge. The resulting bilevel optimization problembecomes more challenging due to the larger search space and the inherentinstability of bilevel optimization algorithms. To mitigate these issues (i) wefollow a successive cold-start strategy with a Kullback-Leibler regularization,and (ii) we parameterize magnitudes as continuous distributions. Our approachleads to competitive results on standard benchmarks despite a more challengingsetting, and generalizes beyond natural images.</description><author>Juliette Marrie, Michael Arbel, Diane Larlus, Julien Mairal</author><pubDate>Fri, 16 Jun 2023 18:51:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09998v1</guid></item><item><title>h2oGPT: Democratizing Large Language Models</title><link>http://arxiv.org/abs/2306.08161v2</link><description>Applications built on top of Large Language Models (LLMs) such as GPT-4represent a revolution in AI due to their human-level capabilities in naturallanguage processing. However, they also pose many significant risks such as thepresence of biased, private, or harmful text, and the unauthorized inclusion ofcopyrighted material. We introduce h2oGPT, a suite of open-source code repositories for thecreation and use of LLMs based on Generative Pretrained Transformers (GPTs).The goal of this project is to create the world's best truly open-sourcealternative to closed-source approaches. In collaboration with and as part ofthe incredible and unstoppable open-source community, we open-source severalfine-tuned h2oGPT models from 7 to 40 Billion parameters, ready for commercialuse under fully permissive Apache 2.0 licenses. Included in our release is100\% private document search using natural language. Open-source language models help boost AI development and make it moreaccessible and trustworthy. They lower entry hurdles, allowing people andgroups to tailor these models to their needs. This openness increasesinnovation, transparency, and fairness. An open-source strategy is needed toshare AI benefits fairly, and H2O.ai will continue to democratize AI and LLMs.</description><author>Arno Candel, Jon McKinney, Philipp Singer, Pascal Pfeiffer, Maximilian Jeblick, Prithvi Prabhu, Jeff Gambera, Mark Landry, Shivam Bansal, Ryan Chesler, Chun Ming Lee, Marcos V. Conde, Pasha Stetsenko, Olivier Grellier, SriSatish Ambati</author><pubDate>Fri, 16 Jun 2023 18:48:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08161v2</guid></item><item><title>Fairness in Preference-based Reinforcement Learning</title><link>http://arxiv.org/abs/2306.09995v1</link><description>In this paper, we address the issue of fairness in preference-basedreinforcement learning (PbRL) in the presence of multiple objectives. The mainobjective is to design control policies that can optimize multiple objectiveswhile treating each objective fairly. Toward this objective, we design a newfairness-induced preference-based reinforcement learning or FPbRL. The mainidea of FPbRL is to learn vector reward functions associated with multipleobjectives via new welfare-based preferences rather than reward-basedpreference in PbRL, coupled with policy learning via maximizing a generalizedGini welfare function. Finally, we provide experiment studies on threedifferent environments to show that the proposed FPbRL approach can achieveboth efficiency and equity for learning effective and fair policies.</description><author>Umer Siddique, Abhinav Sinha, Yongcan Cao</author><pubDate>Fri, 16 Jun 2023 18:47:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09995v1</guid></item><item><title>Fairness in Matching under Uncertainty</title><link>http://arxiv.org/abs/2302.03810v2</link><description>The prevalence and importance of algorithmic two-sided marketplaces has drawnattention to the issue of fairness in such settings. Algorithmic decisions areused in assigning students to schools, users to advertisers, and applicants tojob interviews. These decisions should heed the preferences of individuals, andsimultaneously be fair with respect to their merits (synonymous with fit,future performance, or need). Merits conditioned on observable features arealways \emph{uncertain}, a fact that is exacerbated by the widespread use ofmachine learning algorithms to infer merit from the observables. As our keycontribution, we carefully axiomatize a notion of individual fairness in thetwo-sided marketplace setting which respects the uncertainty in the merits;indeed, it simultaneously recognizes uncertainty as the primary potential causeof unfairness and an approach to address it. We design a linear programmingframework to find fair utility-maximizing distributions over allocations, andwe show that the linear program is robust to perturbations in the estimatedparameters of the uncertain merit distributions, a key property in combiningthe approach with machine learning techniques.</description><author>Siddartha Devic, David Kempe, Vatsal Sharan, Aleksandra Korolova</author><pubDate>Fri, 16 Jun 2023 18:41:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.03810v2</guid></item><item><title>Ensemble Framework for Cardiovascular Disease Prediction</title><link>http://arxiv.org/abs/2306.09989v1</link><description>Heart disease is the major cause of non-communicable and silent deathworldwide. Heart diseases or cardiovascular diseases are classified into fourtypes: coronary heart disease, heart failure, congenital heart disease, andcardiomyopathy. It is vital to diagnose heart disease early and accurately inorder to avoid further injury and save patients' lives. As a result, we need asystem that can predict cardiovascular disease before it becomes a criticalsituation. Machine learning has piqued the interest of researchers in the fieldof medical sciences. For heart disease prediction, researchers implement avariety of machine learning methods and approaches. In this work, to the bestof our knowledge, we have used the dataset from IEEE Data Port which is one ofthe online available largest datasets for cardiovascular diseases individuals.The dataset isa combination of Hungarian, Cleveland, Long Beach VA, Switzerland&amp; Statlog datasets with important features such as Maximum Heart Rate Achieved,Serum Cholesterol, Chest Pain Type, Fasting blood sugar, and so on. To assessthe efficacy and strength of the developed model, several performance measuresare used, such as ROC, AUC curve, specificity, F1-score, sensitivity, MCC, andaccuracy. In this study, we have proposed a framework with a stacked ensembleclassifier using several machine learning algorithms including ExtraTreesClassifier, Random Forest, XGBoost, and so on. Our proposed framework attainedan accuracy of 92.34% which is higher than the existing literature.</description><author>Achyut Tiwari, Aryan Chugh, Aman Sharma</author><pubDate>Fri, 16 Jun 2023 18:37:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09989v1</guid></item><item><title>Transforming Observations of Ocean Temperature with a Deep Convolutional Residual Regressive Neural Network</title><link>http://arxiv.org/abs/2306.09987v1</link><description>Sea surface temperature (SST) is an essential climate variable that can bemeasured via ground truth, remote sensing, or hybrid model methodologies. Here,we celebrate SST surveillance progress via the application of a few relevanttechnological advances from the late 20th and early 21st century. We furtherdevelop our existing water cycle observation framework, Flux to Flow (F2F), tofuse AMSR-E and MODIS into a higher resolution product with the goal ofcapturing gradients and filling cloud gaps that are otherwise unavailable. Ourneural network architecture is constrained to a deep convolutional residualregressive neural network. We utilize three snapshots of twelve monthly SSTmeasurements in 2010 as measured by the passive microwave radiometer AMSR-E,the visible and infrared monitoring MODIS instrument, and the in situ Argodataset ISAS. The performance of the platform and success of this approach isevaluated using the root mean squared error (RMSE) metric. We determine thatthe 1:1 configuration of input and output data and a large observation regionis too challenging for the single compute node and dcrrnn structure as is. Whenconstrained to a single 100 x 100 pixel region and a small training dataset,the algorithm improves from the baseline experiment covering a much largergeography. For next discrete steps, we envision the consideration of a largeinput range with a very small output range. Furthermore, we see the need tointegrate land and sea variables before performing computer vision tasks likethose within. Finally, we see parallelization as necessary to overcome thecompute obstacles we encountered.</description><author>Albert Larson, Ali Shafqat Akanda</author><pubDate>Fri, 16 Jun 2023 18:35:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09987v1</guid></item><item><title>Knowledge-driven Active Learning</title><link>http://arxiv.org/abs/2110.08265v4</link><description>The deployment of Deep Learning (DL) models is still precluded in thosecontexts where the amount of supervised data is limited. To answer this issue,active learning strategies aim at minimizing the amount of labelled datarequired to train a DL model. Most active strategies are based on uncertainsample selection, and even often restricted to samples lying close to thedecision boundary. These techniques are theoretically sound, but anunderstanding of the selected samples based on their content is notstraightforward, further driving non-experts to consider DL as a black-box. Forthe first time, here we propose to take into consideration commondomain-knowledge and enable non-expert users to train a model with fewersamples. In our Knowledge-driven Active Learning (KAL) framework, rule-basedknowledge is converted into logic constraints and their violation is checked asa natural guide for sample selection. We show that even simple relationshipsamong data and output classes offer a way to spot predictions for which themodel need supervision. We empirically show that KAL (i) outperforms manyactive learning strategies, particularly in those contexts where domainknowledge is rich, (ii) it discovers data distribution lying far from theinitial training data, (iii) it ensures domain experts that the providedknowledge is acquired by the model, (iv) it is suitable for regression andobject recognition tasks unlike uncertainty-based strategies, and (v) itscomputational demand is low.</description><author>Gabriele Ciravegna, Frédéric Precioso, Alessandro Betti, Kevin Mottin, Marco Gori</author><pubDate>Fri, 16 Jun 2023 18:31:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.08265v4</guid></item><item><title>Evaluating Superhuman Models with Consistency Checks</title><link>http://arxiv.org/abs/2306.09983v1</link><description>If machine learning models were to achieve superhuman abilities at variousreasoning or decision-making tasks, how would we go about evaluating suchmodels, given that humans would necessarily be poor proxies for ground truth?In this paper, we propose a framework for evaluating superhuman models viaconsistency checks. Our premise is that while the correctness of superhumandecisions may be impossible to evaluate, we can still surface mistakes if themodel's decisions fail to satisfy certain logical, human-interpretable rules.We instantiate our framework on three tasks where correctness of decisions ishard to evaluate due to either superhuman model abilities, or to otherwisemissing ground truth: evaluating chess positions, forecasting future events,and making legal judgments. We show that regardless of a model's (possiblysuperhuman) performance on these tasks, we can discover logical inconsistenciesin decision making. For example: a chess engine assigning opposing valuationsto semantically identical boards; GPT-4 forecasting that sports records willevolve non-monotonically over time; or an AI judge assigning bail to adefendant only after we add a felony to their criminal record.</description><author>Lukas Fluri, Daniel Paleka, Florian Tramèr</author><pubDate>Fri, 16 Jun 2023 18:26:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09983v1</guid></item><item><title>Creating Multi-Level Skill Hierarchies in Reinforcement Learning</title><link>http://arxiv.org/abs/2306.09980v1</link><description>What is a useful skill hierarchy for an autonomous agent? We propose ananswer based on the graphical structure of an agent's interaction with itsenvironment. Our approach uses hierarchical graph partitioning to expose thestructure of the graph at varying timescales, producing a skill hierarchy withmultiple levels of abstraction. At each level of the hierarchy, skills move theagent between regions of the state space that are well connected withinthemselves but weakly connected to each other. We illustrate the utility of theproposed skill hierarchy in a wide variety of domains in the context ofreinforcement learning.</description><author>Joshua B. Evans, Özgür Şimşek</author><pubDate>Fri, 16 Jun 2023 18:23:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09980v1</guid></item><item><title>Evaluation of Speech Representations for MOS prediction</title><link>http://arxiv.org/abs/2306.09979v1</link><description>In this paper, we evaluate feature extraction models for predicting speechquality. We also propose a model architecture to compare embeddings ofsupervised learning and self-supervised learning models with embeddings ofspeaker verification models to predict the metric MOS. Our experiments wereperformed on the VCC2018 dataset and a Brazilian-Portuguese dataset calledBRSpeechMOS, which was created for this work. The results show that the Whispermodel is appropriate in all scenarios: with both the VCC2018 and BRSpeech- MOSdatasets. Among the supervised and self-supervised learning models usingBRSpeechMOS, Whisper-Small achieved the best linear correlation of 0.6980, andthe speaker verification model, SpeakerNet, had linear correlation of 0.6963.Using VCC2018, the best supervised and self-supervised learning model,Whisper-Large, achieved linear correlation of 0.7274, and the best modelspeaker verification, TitaNet, achieved a linear correlation of 0.6933.Although the results of the speaker verification models are slightly lower, theSpeakerNet model has only 5M parameters, making it suitable for real-timeapplications, and the TitaNet model produces an embedding of size 192, thesmallest among all the evaluated models. The experiment results arereproducible with publicly available source-code1 .</description><author>Frederico S. Oliveira, Edresson Casanova, Arnaldo Cândido Júnior, Lucas R. S. Gris, Anderson S. Soares, Arlindo R. Galvão Filho</author><pubDate>Fri, 16 Jun 2023 18:21:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09979v1</guid></item><item><title>Adversarially robust clustering with optimality guarantees</title><link>http://arxiv.org/abs/2306.09977v1</link><description>We consider the problem of clustering data points coming from sub-Gaussianmixtures. Existing methods that provably achieve the optimal mislabeling error,such as the Lloyd algorithm, are usually vulnerable to outliers. In contrast,clustering methods seemingly robust to adversarial perturbations are not knownto satisfy the optimal statistical guarantees. We propose a simple algorithmthat obtains the optimal mislabeling rate even when we allow adversarialoutliers to be present. Our algorithm achieves the optimal error rate inconstant iterations when a weak initialization condition is satisfied. In theabsence of outliers, in fixed dimensions, our theoretical guarantees aresimilar to that of the Lloyd algorithm. Extensive experiments on varioussimulated data sets are conducted to support the theoretical guarantees of ourmethod.</description><author>Soham Jana, Kun Yang, Sanjeev Kulkarni</author><pubDate>Fri, 16 Jun 2023 18:17:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09977v1</guid></item><item><title>Enhancing Fault Resilience of QNNs by Selective Neuron Splitting</title><link>http://arxiv.org/abs/2306.09973v1</link><description>The superior performance of Deep Neural Networks (DNNs) has led to theirapplication in various aspects of human life. Safety-critical applications areno exception and impose rigorous reliability requirements on DNNs. QuantizedNeural Networks (QNNs) have emerged to tackle the complexity of DNNaccelerators, however, they are more prone to reliability issues. In this paper, a recent analytical resilience assessment method is adaptedfor QNNs to identify critical neurons based on a Neuron Vulnerability Factor(NVF). Thereafter, a novel method for splitting the critical neurons isproposed that enables the design of a Lightweight Correction Unit (LCU) in theaccelerator without redesigning its computational part. The method is validated by experiments on different QNNs and datasets. Theresults demonstrate that the proposed method for correcting the faults has atwice smaller overhead than a selective Triple Modular Redundancy (TMR) whileachieving a similar level of fault resiliency.</description><author>Mohammad Hasan Ahmadilivani, Mahdi Taheri, Jaan Raik, Masoud Daneshtalab, Maksim Jenihhin</author><pubDate>Fri, 16 Jun 2023 18:11:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09973v1</guid></item><item><title>HePCo: Data-Free Heterogeneous Prompt Consolidation for Continual Federated Learning</title><link>http://arxiv.org/abs/2306.09970v1</link><description>In this paper, we focus on the important yet understudied problem ofContinual Federated Learning (CFL), where a server communicates with a set ofclients to incrementally learn new concepts over time without sharing orstoring any data. The complexity of this problem is compounded by challengesfrom both the Continual and Federated Learning perspectives. Specifically,models trained in a CFL setup suffer from catastrophic forgetting which isexacerbated by data heterogeneity across clients. Existing attempts at thisproblem tend to impose large overheads on clients and communication channels orrequire access to stored data which renders them unsuitable for real-world usedue to privacy. In this paper, we attempt to tackle forgetting andheterogeneity while minimizing overhead costs and without requiring access toany stored data. We achieve this by leveraging a prompting based approach (suchthat only prompts and classifier heads have to be communicated) and proposing anovel and lightweight generation and distillation scheme to consolidate clientmodels at the server. We formulate this problem for image classification andestablish strong baselines for comparison, conduct experiments on CIFAR-100 aswell as challenging, large-scale datasets like ImageNet-R and DomainNet. Ourapproach outperforms both existing methods and our own baselines by as much as7% while significantly reducing communication and client-level computationcosts.</description><author>Shaunak Halbe, James Seale Smith, Junjiao Tian, Zsolt Kira</author><pubDate>Fri, 16 Jun 2023 18:02:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09970v1</guid></item><item><title>ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data and Comprehensive Evaluation</title><link>http://arxiv.org/abs/2306.09968v1</link><description>Large language models have exhibited exceptional performance on variousNatural Language Processing (NLP) tasks, leveraging techniques such as thepre-training, and instruction fine-tuning. Despite these advances, theireffectiveness in medical applications is limited, due to challenges such asfactual inaccuracies, reasoning abilities, and lack grounding in real-worldexperience. In this study, we present ClinicalGPT, a language model explicitlydesigned and optimized for clinical scenarios. By incorporating extensive anddiverse real-world data, such as medical records, domain-specific knowledge,and multi-round dialogue consultations in the training process, ClinicalGPT isbetter prepared to handle multiple clinical task. Furthermore, we introduce acomprehensive evaluation framework that includes medical knowledgequestion-answering, medical exams, patient consultations, and diagnosticanalysis of medical records. Our results demonstrate that ClinicalGPTsignificantly outperforms other models in these tasks, highlighting theeffectiveness of our approach in adapting large language models to the criticaldomain of healthcare.</description><author>Guangyu Wang, Guoxing Yang, Zongxin Du, Longjun Fan, Xiaohu Li</author><pubDate>Fri, 16 Jun 2023 17:56:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09968v1</guid></item><item><title>Data-Driven Model Discrimination of Switched Nonlinear Systems with Temporal Logic Inference</title><link>http://arxiv.org/abs/2306.09966v1</link><description>This paper addresses the problem of data-driven model discrimination forunknown switched systems with unknown linear temporal logic (LTL)specifications, representing tasks, that govern their mode sequences, whereonly sampled data of the unknown dynamics and tasks are available. To tacklethis problem, we propose data-driven methods to over-approximate the unknowndynamics and to infer the unknown specifications such that both set-membershipmodels of the unknown dynamics and LTL formulas are guaranteed to include theground truth model and specification/task. Moreover, we present anoptimization-based algorithm for analyzing the distinguishability of a set oflearned/inferred model-task pairs as well as a model discrimination algorithmfor ruling out model-task pairs from this set that are inconsistent with newobservations at run time. Further, we present an approach for reducing the sizeof inferred specifications to increase the computational efficiency of themodel discrimination algorithms.</description><author>Zeyuan Jin, Nasim Baharisangari, Zhe Xu, Sze Zheng Yong</author><pubDate>Fri, 16 Jun 2023 17:50:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09966v1</guid></item><item><title>The Evolution theory of Learning: From Natural Selection to Reinforcement Learning</title><link>http://arxiv.org/abs/2306.09961v1</link><description>Evolution is a fundamental process that shapes the biological world weinhabit, and reinforcement learning is a powerful tool used in artificialintelligence to develop intelligent agents that learn from their environment.In recent years, researchers have explored the connections between these twoseemingly distinct fields, and have found compelling evidence that they aremore closely related than previously thought. This paper examines theseconnections and their implications, highlighting the potential forreinforcement learning principles to enhance our understanding of evolution andthe role of feedback in evolutionary systems.</description><author>Taboubi Ahmed</author><pubDate>Fri, 16 Jun 2023 17:44:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09961v1</guid></item><item><title>On the Training Instability of Shuffling SGD with Batch Normalization</title><link>http://arxiv.org/abs/2302.12444v2</link><description>We uncover how SGD interacts with batch normalization and can exhibitundesirable training dynamics such as divergence. More precisely, we study howSingle Shuffle (SS) and Random Reshuffle (RR) -- two widely used variants ofSGD -- interact surprisingly differently in the presence of batchnormalization: RR leads to much more stable evolution of training loss than SS.As a concrete example, for regression using a linear network with batchnormalization, we prove that SS and RR converge to distinct global optima thatare "distorted" away from gradient descent. Thereafter, for classification wecharacterize conditions under which training divergence for SS and RR can, andcannot occur. We present explicit constructions to show how SS leads todistorted optima in regression and divergence for classification, whereas RRavoids both distortion and divergence. We validate our results by confirmingthem empirically in realistic settings, and conclude that the separationbetween SS and RR used with batch normalization is relevant in practice.</description><author>David X. Wu, Chulhee Yun, Suvrit Sra</author><pubDate>Fri, 16 Jun 2023 17:40:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.12444v2</guid></item><item><title>Training shallow ReLU networks on noisy data using hinge loss: when do we overfit and is it benign?</title><link>http://arxiv.org/abs/2306.09955v1</link><description>We study benign overfitting in two-layer ReLU networks trained using gradientdescent and hinge loss on noisy data for binary classification. In particular,we consider linearly separable data for which a relatively small proportion oflabels are corrupted or flipped. We identify conditions on the margin of theclean data that give rise to three distinct training outcomes: benignoverfitting, in which zero loss is achieved and with high probability test datais classified correctly; overfitting, in which zero loss is achieved but testdata is misclassified with probability lower bounded by a constant; andnon-overfitting, in which clean points, but not corrupt points, achieve zeroloss and again with high probability test data is classified correctly. Ouranalysis provides a fine-grained description of the dynamics of neuronsthroughout training and reveals two distinct phases: in the first phase cleanpoints achieve close to zero loss, in the second phase clean points oscillateon the boundary of zero loss while corrupt points either converge towards zeroloss or are eventually zeroed by the network. We prove these results using acombinatorial approach that involves bounding the number of clean versuscorrupt updates across these phases of training.</description><author>Erin George, Michael Murray, William Swartworth, Deanna Needell</author><pubDate>Fri, 16 Jun 2023 17:40:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09955v1</guid></item><item><title>You Don't Need Robust Machine Learning to Manage Adversarial Attack Risks</title><link>http://arxiv.org/abs/2306.09951v1</link><description>The robustness of modern machine learning (ML) models has become anincreasing concern within the community. The ability to subvert a model intomaking errant predictions using seemingly inconsequential changes to input isstartling, as is our lack of success in building models robust to this concern.Existing research shows progress, but current mitigations come with a high costand simultaneously reduce the model's accuracy. However, such trade-offs maynot be necessary when other design choices could subvert the risk. In thissurvey we review the current literature on attacks and their real-worldoccurrences, or limited evidence thereof, to critically evaluate the real-worldrisks of adversarial machine learning (AML) for the average entity. This isdone with an eye toward how one would then mitigate these attacks in practice,the risks for production deployment, and how those risks could be managed. Indoing so we elucidate that many AML threats do not warrant the cost andtrade-offs of robustness due to a low likelihood of attack or availability ofsuperior non-ML mitigations. Our analysis also recommends cases where an actorshould be concerned about AML to the degree where robust ML models arenecessary for a complete deployment.</description><author>Edward Raff, Michel Benaroch, Andrew L. Farris</author><pubDate>Fri, 16 Jun 2023 17:32:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09951v1</guid></item><item><title>Nearly-Optimal Hierarchical Clustering for Well-Clustered Graphs</title><link>http://arxiv.org/abs/2306.09950v1</link><description>This paper presents two efficient hierarchical clustering (HC) algorithmswith respect to Dasgupta's cost function. For any input graph $G$ with a clearcluster-structure, our designed algorithms run in nearly-linear time in theinput size of $G$, and return an $O(1)$-approximate HC tree with respect toDasgupta's cost function. We compare the performance of our algorithm againstthe previous state-of-the-art on synthetic and real-world datasets and showthat our designed algorithm produces comparable or better HC trees with muchlower running time.</description><author>Steinar Laenen, Bogdan-Adrian Manghiuc, He Sun</author><pubDate>Fri, 16 Jun 2023 17:31:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09950v1</guid></item><item><title>Towards Better Certified Segmentation via Diffusion Models</title><link>http://arxiv.org/abs/2306.09949v1</link><description>The robustness of image segmentation has been an important research topic inthe past few years as segmentation models have reached production-levelaccuracy. However, like classification models, segmentation models can bevulnerable to adversarial perturbations, which hinders their use incritical-decision systems like healthcare or autonomous driving. Recently,randomized smoothing has been proposed to certify segmentation predictions byadding Gaussian noise to the input to obtain theoretical guarantees. However,this method exhibits a trade-off between the amount of added noise and thelevel of certification achieved. In this paper, we address the problem ofcertifying segmentation prediction using a combination of randomized smoothingand diffusion models. Our experiments show that combining randomized smoothingand diffusion models significantly improves certified robustness, with resultsindicating a mean improvement of 21 points in accuracy compared to previousstate-of-the-art methods on Pascal-Context and Cityscapes public datasets. Ourmethod is independent of the selected segmentation model and does not need anyadditional specialized training procedure.</description><author>Othmane Laousy, Alexandre Araujo, Guillaume Chassagnon, Marie-Pierre Revel, Siddharth Garg, Farshad Khorrami, Maria Vakalopoulou</author><pubDate>Fri, 16 Jun 2023 17:30:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09949v1</guid></item><item><title>Variational multichannel multiclass segmentation using unsupervised lifting with CNNs</title><link>http://arxiv.org/abs/2302.02214v2</link><description>We propose an unsupervised image segmentation approach, that combines avariational energy functional and deep convolutional neural networks. Thevariational part is based on a recent multichannel multiphase Chan-Vese model,which is capable to extract useful information from multiple input imagessimultaneously. We implement a flexible multiclass segmentation method thatdivides a given image into $K$ different regions. We use convolutional neuralnetworks (CNNs) targeting a pre-decomposition of the image. By subsequentlyminimising the segmentation functional, the final segmentation is obtained in afully unsupervised manner. Special emphasis is given to the extraction ofinformative feature maps serving as a starting point for the segmentation. Theinitial results indicate that the proposed method is able to decompose andsegment the different regions of various types of images, such as texture andmedical images and compare its performance with another multiphase segmentationmethod.</description><author>Nadja Gruber, Johannes Schwab, Sebastien Court, Elke Gizewski, Markus Haltmeier</author><pubDate>Fri, 16 Jun 2023 17:28:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02214v2</guid></item><item><title>One-shot Unsupervised Domain Adaptation with Personalized Diffusion Models</title><link>http://arxiv.org/abs/2303.18080v2</link><description>Adapting a segmentation model from a labeled source domain to a targetdomain, where a single unlabeled datum is available, is one the mostchallenging problems in domain adaptation and is otherwise known as one-shotunsupervised domain adaptation (OSUDA). Most of the prior works have addressedthe problem by relying on style transfer techniques, where the source imagesare stylized to have the appearance of the target domain. Departing from thecommon notion of transferring only the target ``texture'' information, weleverage text-to-image diffusion models (e.g., Stable Diffusion) to generate asynthetic target dataset with photo-realistic images that not only faithfullydepict the style of the target domain, but are also characterized by novelscenes in diverse contexts. The text interface in our method Data AugmenTationwith diffUsion Models (DATUM) endows us with the possibility of guiding thegeneration of images towards desired semantic concepts while respecting theoriginal spatial context of a single training image, which is not possible inexisting OSUDA methods. Extensive experiments on standard benchmarks show thatour DATUM surpasses the state-of-the-art OSUDA methods by up to +7.1%. Theimplementation is available at https://github.com/yasserben/DATUM</description><author>Yasser Benigmim, Subhankar Roy, Slim Essid, Vicky Kalogeiton, Stéphane Lathuilière</author><pubDate>Fri, 16 Jun 2023 17:27:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.18080v2</guid></item><item><title>RealImpact: A Dataset of Impact Sound Fields for Real Objects</title><link>http://arxiv.org/abs/2306.09944v1</link><description>Objects make unique sounds under different perturbations, environmentconditions, and poses relative to the listener. While prior works have modeledimpact sounds and sound propagation in simulation, we lack a standard datasetof impact sound fields of real objects for audio-visual learning andcalibration of the sim-to-real gap. We present RealImpact, a large-scaledataset of real object impact sounds recorded under controlled conditions.RealImpact contains 150,000 recordings of impact sounds of 50 everyday objectswith detailed annotations, including their impact locations, microphonelocations, contact force profiles, material labels, and RGBD images. We makepreliminary attempts to use our dataset as a reference to current simulationmethods for estimating object impact sounds that match the real world.Moreover, we demonstrate the usefulness of our dataset as a testbed foracoustic and audio-visual learning via the evaluation of two benchmark tasks,including listener location classification and visual acoustic matching.</description><author>Samuel Clarke, Ruohan Gao, Mason Wang, Mark Rau, Julia Xu, Jui-Hsien Wang, Doug L. James, Jiajun Wu</author><pubDate>Fri, 16 Jun 2023 17:25:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09944v1</guid></item><item><title>Large Language Models Sometimes Generate Purely Negatively-Reinforced Text</title><link>http://arxiv.org/abs/2306.07567v2</link><description>When using adversarial training, it is common practice to train against themost egregious failures. However, this might imply using examples withsensitive information (such as leaked passwords or security vulnerabilities) astraining data. One might assume that language models trained with gradientdescent never generate text snippets which were only present in examplesassociated with the lowest possible reward. In this paper, we show that thisassumption is wrong: in some situations, large language models do learn fromsuch negatively-reinforced examples. We present a specific training setup thatenables Pythia-160M to guess passwords 13% more often than it would by guessingrandomly, despite only showing it these passwords on examples where the modelis incentivized to not output these passwords. Our code is available atwww.github.com/FabienRoger/Learning-From-Negative-Examples</description><author>Fabien Roger</author><pubDate>Fri, 16 Jun 2023 17:23:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07567v2</guid></item><item><title>Vehicle Occurrence-based Parking Space Detection</title><link>http://arxiv.org/abs/2306.09940v1</link><description>Smart-parking solutions use sensors, cameras, and data analysis to improveparking efficiency and reduce traffic congestion. Computer vision-based methodshave been used extensively in recent years to tackle the problem of parking lotmanagement, but most of the works assume that the parking spots are manuallylabeled, impacting the cost and feasibility of deployment. To fill this gap,this work presents an automatic parking space detection method, which receivesa sequence of images of a parking lot and returns a list of coordinatesidentifying the detected parking spaces. The proposed method employs instancesegmentation to identify cars and, using vehicle occurrence, generate a heatmap of parking spaces. The results using twelve different subsets from thePKLot and CNRPark-EXT parking lot datasets show that the method achieved anAP25 score up to 95.60\% and AP50 score up to 79.90\%.</description><author>Paulo R. Lisboa de Almeida, Jeovane Honório Alves, Luiz S. Oliveira, Andre Gustavo Hochuli, João V. Fröhlich, Rodrigo A. Krauel</author><pubDate>Fri, 16 Jun 2023 17:22:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09940v1</guid></item><item><title>Auto-AVSR: Audio-Visual Speech Recognition with Automatic Labels</title><link>http://arxiv.org/abs/2303.14307v2</link><description>Audio-visual speech recognition has received a lot of attention due to itsrobustness against acoustic noise. Recently, the performance of automatic,visual, and audio-visual speech recognition (ASR, VSR, and AV-ASR,respectively) has been substantially improved, mainly due to the use of largermodels and training sets. However, accurate labelling of datasets istime-consuming and expensive. Hence, in this work, we investigate the use ofautomatically-generated transcriptions of unlabelled datasets to increase thetraining set size. For this purpose, we use publicly-available pre-trained ASRmodels to automatically transcribe unlabelled datasets such as AVSpeech andVoxCeleb2. Then, we train ASR, VSR and AV-ASR models on the augmented trainingset, which consists of the LRS2 and LRS3 datasets as well as the additionalautomatically-transcribed data. We demonstrate that increasing the size of thetraining set, a recent trend in the literature, leads to reduced WER despiteusing noisy transcriptions. The proposed model achieves new state-of-the-artperformance on AV-ASR on LRS2 and LRS3. In particular, it achieves a WER of0.9% on LRS3, a relative improvement of 30% over the current state-of-the-artapproach, and outperforms methods that have been trained on non-publiclyavailable datasets with 26 times more training data.</description><author>Pingchuan Ma, Alexandros Haliassos, Adriana Fernandez-Lopez, Honglie Chen, Stavros Petridis, Maja Pantic</author><pubDate>Fri, 16 Jun 2023 17:22:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.14307v2</guid></item><item><title>The Best Decisions Are Not the Best Advice: Making Adherence-Aware Recommendations</title><link>http://arxiv.org/abs/2209.01874v3</link><description>Many high-stake decisions follow an expert-in-loop structure in that a humanoperator receives recommendations from an algorithm but is the ultimatedecision maker. Hence, the algorithm's recommendation may differ from theactual decision implemented in practice. However, most algorithmicrecommendations are obtained by solving an optimization problem that assumesrecommendations will be perfectly implemented. We propose an adherence-awareoptimization framework to capture the dichotomy between the recommended and theimplemented policy and analyze the impact of partial adherence on the optimalrecommendation. We show that overlooking the partial adherence phenomenon, asis currently being done by most recommendation engines, can lead to arbitrarilysevere performance deterioration, compared with both the current human baselineperformance and what is expected by the recommendation algorithm. Our frameworkalso provides useful tools to analyze the structure and to compute optimalrecommendation policies that are naturally immune against such humandeviations, and are guaranteed to improve upon the baseline policy.</description><author>Julien Grand-Clément, Jean Pauphilet</author><pubDate>Fri, 16 Jun 2023 17:20:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.01874v3</guid></item><item><title>Towards Better Orthogonality Regularization with Disentangled Norm in Training Deep CNNs</title><link>http://arxiv.org/abs/2306.09939v1</link><description>Orthogonality regularization has been developed to prevent deep CNNs fromtraining instability and feature redundancy. Among existing proposals, kernelorthogonality regularization enforces orthogonality by minimizing the residualbetween the Gram matrix formed by convolutional filters and the orthogonalitymatrix. We propose a novel measure for achieving better orthogonality among filters,which disentangles diagonal and correlation information from the residual. Themodel equipped with the measure under the principle of imposing strictorthogonality between filters surpasses previous regularization methods innear-orthogonality. Moreover, we observe the benefits of improved strict filterorthogonality in relatively shallow models, but as model depth increases, theperformance gains in models employing strict kernel orthogonality decreasesharply. Furthermore, based on the observation of the potential conflict betweenstrict kernel orthogonality and growing model capacity, we propose a relaxationtheory on kernel orthogonality regularization. The relaxed kernel orthogonalityachieves enhanced performance on models with increased capacity, shedding lighton the burden of strict kernel orthogonality on deep model performance. We conduct extensive experiments with our kernel orthogonality regularizationtoolkit on ResNet and WideResNet in CIFAR-10 and CIFAR-100. We observestate-of-the-art gains in model performance from the toolkit, which includesboth strict orthogonality and relaxed orthogonality regularization, and obtainmore robust models with expressive features. These experiments demonstrate theefficacy of our toolkit and subtly provide insights into the often overlookedchallenges posed by strict orthogonality, addressing the burden of strictorthogonality on capacity-rich models.</description><author>Changhao Wu, Shenan Zhang, Fangsong Long, Ziliang Yin, Tuo Leng</author><pubDate>Fri, 16 Jun 2023 17:19:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09939v1</guid></item><item><title>Training Debiased Subnetworks with Contrastive Weight Pruning</title><link>http://arxiv.org/abs/2210.05247v2</link><description>Neural networks are often biased to spuriously correlated features thatprovide misleading statistical evidence that does not generalize. This raisesan interesting question: ``Does an optimal unbiased functional subnetwork existin a severely biased network? If so, how to extract such subnetwork?" Whileempirical evidence has been accumulated about the existence of such unbiasedsubnetworks, these observations are mainly based on the guidance ofground-truth unbiased samples. Thus, it is unexplored how to discover theoptimal subnetworks with biased training datasets in practice. To address this,here we first present our theoretical insight that alerts potential limitationsof existing algorithms in exploring unbiased subnetworks in the presence ofstrong spurious correlations. We then further elucidate the importance ofbias-conflicting samples on structure learning. Motivated by theseobservations, we propose a Debiased Contrastive Weight Pruning (DCWP)algorithm, which probes unbiased subnetworks without expensive groupannotations. Experimental results demonstrate that our approach significantlyoutperforms state-of-the-art debiasing methods despite its considerablereduction in the number of parameters.</description><author>Geon Yeong Park, Sangmin Lee, Sang Wan Lee, Jong Chul Ye</author><pubDate>Fri, 16 Jun 2023 17:11:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.05247v2</guid></item><item><title>Quantifying Jump Height Using Markerless Motion Capture with a Single Smartphone</title><link>http://arxiv.org/abs/2302.10749v2</link><description>Goal: The countermovement jump (CMJ) is commonly used to measure lower-bodyexplosive power. This study evaluates how accurately markerless motion capture(MMC) with a single smartphone can measure bilateral and unilateral CMJ jumpheight. Methods: First, three repetitions each of bilateral and unilateral CMJwere performed by sixteen healthy adults (mean age: 30.87$\pm$7.24 years; meanBMI: 23.14$\pm$2.55 $kg/m^2$) on force plates and simultaneously captured usingoptical motion capture (OMC) and one smartphone camera. Next, MMC was performedon the smartphone videos using OpenPose. Then, we evaluated MMC in quantifyingjump height using the force plate and OMC as ground truths. Results: MMCquantifies jump heights with ICC between 0.84 and 0.99 without manualsegmentation and camera calibration. Conclusions: Our results suggest thatusing a single smartphone for markerless motion capture is promising. Index Terms - Countermovement jump, Markerless motion capture, Optical motioncapture, Jump height. Impact Statement - Countermovement jump height can be accurately quantifiedusing markerless motion capture with a single smartphone, with a simple setupthat requires neither camera calibration nor manual segmentation.</description><author>Timilehin B. Aderinola, Hananeh Younesian, Darragh Whelan, Brian Caulfield, Georgiana Ifrim</author><pubDate>Fri, 16 Jun 2023 17:10:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10749v2</guid></item><item><title>Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated Learning</title><link>http://arxiv.org/abs/2306.03013v3</link><description>Malicious server (MS) attacks have enabled the scaling of data stealing infederated learning to large batch sizes and secure aggregation, settingspreviously considered private. However, many concerns regarding client-sidedetectability of MS attacks were raised, questioning their practicality oncethey are publicly known. In this work, for the first time, we thoroughly studythe problem of client-side detectability.We demonstrate that most prior MSattacks, which fundamentally rely on one of two key principles, are detectableby principled client-side checks. Further, we formulate desiderata forpractical MS attacks and propose SEER, a novel attack framework that satisfiesall desiderata, while stealing user data from gradients of realistic networks,even for large batch sizes (up to 512 in our experiments) and under secureaggregation. The key insight of SEER is the use of a secret decoder, which isjointly trained with the shared model. Our work represents a promising firststep towards more principled treatment of MS attacks, paving the way forrealistic data stealing that can compromise user privacy in real-worlddeployments.</description><author>Kostadin Garov, Dimitar I. Dimitrov, Nikola Jovanović, Martin Vechev</author><pubDate>Fri, 16 Jun 2023 17:05:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03013v3</guid></item><item><title>Drag-guided diffusion models for vehicle image generation</title><link>http://arxiv.org/abs/2306.09935v1</link><description>Denoising diffusion models trained at web-scale have revolutionized imagegeneration. The application of these tools to engineering design is anintriguing possibility, but is currently limited by their inability to parseand enforce concrete engineering constraints. In this paper, we take a steptowards this goal by proposing physics-based guidance, which enablesoptimization of a performance metric (as predicted by a surrogate model) duringthe generation process. As a proof-of-concept, we add drag guidance to StableDiffusion, which allows this tool to generate images of novel vehicles whilesimultaneously minimizing their predicted drag coefficients.</description><author>Nikos Arechiga, Frank Permenter, Binyang Song, Chenyang Yuan</author><pubDate>Fri, 16 Jun 2023 17:05:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09935v1</guid></item><item><title>A Metaheuristic-based Machine Learning Approach for Energy Prediction in Mobile App Development</title><link>http://arxiv.org/abs/2306.09931v1</link><description>Energy consumption plays a vital role in mobile App development fordevelopers and end-users, and it is considered one of the most crucial factorsfor purchasing a smartphone. In addition, in terms of sustainability, it isessential to find methods to reduce the energy consumption of mobile devicessince the extensive use of billions of smartphones worldwide significantlyimpacts the environment. Despite the existence of several energy-efficientprogramming practices in Android, the leading mobile ecosystem, machinelearning-based energy prediction algorithms for mobile App development have yetto be reported. Therefore, this paper proposes a histogram-based gradientboosting classification machine (HGBC), boosted by a metaheuristic approach,for energy prediction in mobile App development. Our metaheuristic approach isresponsible for two issues. First, it finds redundant and irrelevant featureswithout any noticeable change in performance. Second, it performs ahyper-parameter tuning for the HGBC algorithm. Since our proposed metaheuristicapproach is algorithm-independent, we selected 12 algorithms for the searchstrategy to find the optimal search algorithm. Our finding shows that asuccess-history-based parameter adaption for differential evolution with linearpopulation size (L-SHADE) offers the best performance. It can improveperformance and decrease the number of features effectively. Our extensive setof experiments clearly shows that our proposed approach can provide significantresults for energy consumption prediction.</description><author>Seyed Jalaleddin Mousavirad, Luís A. Alexandre</author><pubDate>Fri, 16 Jun 2023 17:01:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09931v1</guid></item><item><title>Adversarial Cheap Talk</title><link>http://arxiv.org/abs/2211.11030v3</link><description>Adversarial attacks in reinforcement learning (RL) often assumehighly-privileged access to the victim's parameters, environment, or data.Instead, this paper proposes a novel adversarial setting called a Cheap TalkMDP in which an Adversary can merely append deterministic messages to theVictim's observation, resulting in a minimal range of influence. The Adversarycannot occlude ground truth, influence underlying environment dynamics orreward signals, introduce non-stationarity, add stochasticity, see the Victim'sactions, or access their parameters. Additionally, we present a simplemeta-learning algorithm called Adversarial Cheap Talk (ACT) to trainAdversaries in this setting. We demonstrate that an Adversary trained with ACTstill significantly influences the Victim's training and testing performance,despite the highly constrained setting. Affecting train-time performancereveals a new attack vector and provides insight into the success and failuremodes of existing RL algorithms. More specifically, we show that an ACTAdversary is capable of harming performance by interfering with the learner'sfunction approximation, or instead helping the Victim's performance byoutputting useful features. Finally, we show that an ACT Adversary canmanipulate messages during train-time to directly and arbitrarily control theVictim at test-time. Project video and code are available athttps://sites.google.com/view/adversarial-cheap-talk</description><author>Chris Lu, Timon Willi, Alistair Letcher, Jakob Foerster</author><pubDate>Fri, 16 Jun 2023 17:00:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.11030v3</guid></item><item><title>HyperSLICE: HyperBand optimized Spiral for Low-latency Interactive Cardiac Examination</title><link>http://arxiv.org/abs/2302.02688v2</link><description>PURPOSE: Interactive cardiac magnetic resonance imaging is used for fast scanplanning and MR guided interventions. However, the requirement for real-timeacquisition and near real-time visualization constrains the achievablespatio-temporal resolution. This study aims to improve interactive imagingresolution through optimization of undersampled spiral sampling and leveragingof deep learning for low-latency reconstruction (deep artifact suppression).METHODS: A variable density spiral trajectory was parametrized and optimizedvia HyperBand to provide the best candidate trajectory for rapid deep artifactsuppression. Training data consisted of 692 breath-held CINEs. The developedinteractive sequence was tested in simulations and prospectively in 13 subjects(10 for image evaluation, 2 during catheterization, 1 during exercise). In theprospective study, the optimized framework -HyperSLICE- was compared toconventional Cartesian real-time, and breath-hold CINE imaging in termsquantitative and qualitative image metrics. Statistical differences were testedusing Friedman chi-squared tests with post-hoc Nemenyi test (p&lt;0.05). RESULTS:In simulations the NRMSE, pSNR, SSIM and LAPE were all statisticallysignificantly higher using optimized spiral compared to radial and uniformspiral sampling, particularly after scan plan changes (SSIM: 0.71 vs 0.45 and0.43). Prospectively, HyperSLICE enabled a higher spatial and temporalresolution than conventional Cartesian real-time imaging. The pipeline wasdemonstrated in patients during catheter pull back showing sufficiently fastreconstruction for interactive imaging. CONCLUSION: HyperSLICE enables highspatial and temporal resolution interactive imaging. Optimizing the spiralsampling enabled better overall image quality and superior handling of imagetransitions compared to radial and uniform spiral trajectories.</description><author>Dr. Olivier Jaubert, Dr. Javier Montalt-Tordera, Dr. Daniel Knight, Pr. Simon Arridge, Dr. Jennifer Steeden, Pr. Vivek Muthurangu</author><pubDate>Fri, 16 Jun 2023 16:55:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02688v2</guid></item><item><title>Friend or Foe? Exploring the Implications of Large Language Models on the Science System</title><link>http://arxiv.org/abs/2306.09928v1</link><description>The advent of ChatGPT by OpenAI has prompted extensive discourse on itspotential implications for science and higher education. While the impact oneducation has been a primary focus, there is limited empirical research on theeffects of large language models (LLMs) and LLM-based chatbots on science andscientific practice. To investigate this further, we conducted a Delphi studyinvolving 72 experts specialising in research and AI. The study focused onapplications and limitations of LLMs, their effects on the science system,ethical and legal considerations, and the required competencies for theireffective use. Our findings highlight the transformative potential of LLMs inscience, particularly in administrative, creative, and analytical tasks.However, risks related to bias, misinformation, and quality assurance need tobe addressed through proactive regulation and science education. This researchcontributes to informed discussions on the impact of generative AI in scienceand helps identify areas for future action.</description><author>Benedikt Fecher, Marcel Hebing, Melissa Laufer, Jörg Pohle, Fabian Sofsky</author><pubDate>Fri, 16 Jun 2023 16:50:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09928v1</guid></item><item><title>Learning to Summarize and Answer Questions about a Virtual Robot's Past Actions</title><link>http://arxiv.org/abs/2306.09922v1</link><description>When robots perform long action sequences, users will want to easily andreliably find out what they have done. We therefore demonstrate the task oflearning to summarize and answer questions about a robot agent's past actionsusing natural language alone. A single system with a large language model atits core is trained to both summarize and answer questions about actionsequences given ego-centric video frames of a virtual robot and a questionprompt. To enable training of question answering, we develop a method toautomatically generate English-language questions and answers about objects,actions, and the temporal order in which actions occurred during episodes ofrobot action in the virtual environment. Training one model to both summarizeand answer questions enables zero-shot transfer of representations of objectslearned through question answering to improved action summarization. %involving objects not seen in training to summarize.</description><author>Chad DeChant, Iretiayo Akinola, Daniel Bauer</author><pubDate>Fri, 16 Jun 2023 16:47:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09922v1</guid></item><item><title>No Strong Feelings One Way or Another: Re-operationalizing Neutrality in Natural Language Inference</title><link>http://arxiv.org/abs/2306.09918v1</link><description>Natural Language Inference (NLI) has been a cornerstone task in evaluatinglanguage models' inferential reasoning capabilities. However, the standardthree-way classification scheme used in NLI has well-known shortcomings inevaluating models' ability to capture the nuances of natural human reasoning.In this paper, we argue that the operationalization of the neutral label incurrent NLI datasets has low validity, is interpreted inconsistently, and thatat least one important sense of neutrality is often ignored. We uncover thedetrimental impact of these shortcomings, which in some cases leads toannotation datasets that actually decrease performance on downstream tasks. Wecompare approaches of handling annotator disagreement and identify flaws in arecent NLI dataset that designs an annotator study based on a problematicoperationalization. Our findings highlight the need for a more refinedevaluation framework for NLI, and we hope to spark further discussion andaction in the NLP community.</description><author>Animesh Nighojkar, Antonio Laverghetta Jr., John Licato</author><pubDate>Fri, 16 Jun 2023 16:45:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09918v1</guid></item><item><title>Towards Quantum Federated Learning</title><link>http://arxiv.org/abs/2306.09912v1</link><description>Quantum Federated Learning (QFL) is an emerging interdisciplinary field thatmerges the principles of Quantum Computing (QC) and Federated Learning (FL),with the goal of leveraging quantum technologies to enhance privacy, security,and efficiency in the learning process. Currently, there is no comprehensivesurvey for this interdisciplinary field. This review offers a thorough,holistic examination of QFL. We aim to provide a comprehensive understanding ofthe principles, techniques, and emerging applications of QFL. We discuss thecurrent state of research in this rapidly evolving field, identify challengesand opportunities associated with integrating these technologies, and outlinefuture directions and open research questions. We propose a unique taxonomy ofQFL techniques, categorized according to their characteristics and the quantumtechniques employed. As the field of QFL continues to progress, we cananticipate further breakthroughs and applications across various industries,driving innovation and addressing challenges related to data privacy, security,and resource optimization. This review serves as a first-of-its-kindcomprehensive guide for researchers and practitioners interested inunderstanding and advancing the field of QFL.</description><author>Chao Ren, Han Yu, Rudai Yan, Minrui Xu, Yuan Shen, Huihui Zhu, Dusit Niyato, Zhao Yang Dong, Leong Chuan Kwek</author><pubDate>Fri, 16 Jun 2023 16:40:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09912v1</guid></item><item><title>LabelBench: A Comprehensive Framework for Benchmarking Label-Efficient Learning</title><link>http://arxiv.org/abs/2306.09910v1</link><description>Labeled data are critical to modern machine learning applications, butobtaining labels can be expensive. To mitigate this cost, machine learningmethods, such as transfer learning, semi-supervised learning and activelearning, aim to be label-efficient: achieving high predictive performance fromrelatively few labeled examples. While obtaining the best label-efficiency inpractice often requires combinations of these techniques, existing benchmarkand evaluation frameworks do not capture a concerted combination of all suchtechniques. This paper addresses this deficiency by introducing LabelBench, anew computationally-efficient framework for joint evaluation of multiplelabel-efficient learning techniques. As an application of LabelBench, weintroduce a novel benchmark of state-of-the-art active learning methods incombination with semi-supervised learning for fine-tuning pretrained visiontransformers. Our benchmark demonstrates better label-efficiencies thanpreviously reported in active learning. LabelBench's modular codebase isopen-sourced for the broader community to contribute label-efficient learningmethods and benchmarks. The repository can be found at:https://github.com/EfficientTraining/LabelBench.</description><author>Jifan Zhang, Yifang Chen, Gregory Canal, Stephen Mussmann, Yinglun Zhu, Simon Shaolei Du, Kevin Jamieson, Robert D Nowak</author><pubDate>Fri, 16 Jun 2023 16:36:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09910v1</guid></item><item><title>Neural Volumetric Reconstruction for Coherent Synthetic Aperture Sonar</title><link>http://arxiv.org/abs/2306.09909v1</link><description>Synthetic aperture sonar (SAS) measures a scene from multiple views in orderto increase the resolution of reconstructed imagery. Image reconstructionmethods for SAS coherently combine measurements to focus acoustic energy ontothe scene. However, image formation is typically under-constrained due to alimited number of measurements and bandlimited hardware, which limits thecapabilities of existing reconstruction methods. To help meet these challenges,we design an analysis-by-synthesis optimization that leverages recent advancesin neural rendering to perform coherent SAS imaging. Our optimization enablesus to incorporate physics-based constraints and scene priors into the imageformation process. We validate our method on simulation and experimentalresults captured in both air and water. We demonstrate both quantitatively andqualitatively that our method typically produces superior reconstructions thanexisting approaches. We share code and data for reproducibility.</description><author>Albert W. Reed, Juhyeon Kim, Thomas Blanford, Adithya Pediredla, Daniel C. Brown, Suren Jayasuriya</author><pubDate>Fri, 16 Jun 2023 16:35:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09909v1</guid></item><item><title>Correlation Clustering of Bird Sounds</title><link>http://arxiv.org/abs/2306.09906v1</link><description>Bird sound classification is the task of relating any sound recording tothose species of bird that can be heard in the recording. Here, we study birdsound clustering, the task of deciding for any pair of sound recordings whetherthe same species of bird can be heard in both. We address this problem by firstlearning, from a training set, probabilities of pairs of recordings beingrelated in this way, and then inferring a maximally probable partition of atest set by correlation clustering. We address the following questions: Howaccurate is this clustering, compared to a classification of the test set? Howdo the clusters thus inferred relate to the clusters obtained byclassification? How accurate is this clustering when applied to recordings ofbird species not heard during training? How effective is this clustering inseparating, from bird sounds, environmental noise not heard during training?</description><author>David Stein, Bjoern Andres</author><pubDate>Fri, 16 Jun 2023 16:35:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09906v1</guid></item><item><title>Diffusion Probabilistic Models for Structured Node Classification</title><link>http://arxiv.org/abs/2302.10506v4</link><description>This paper studies structured node classification on graphs, where thepredictions should consider dependencies between the node labels. Inparticular, we focus on solving the problem for partially labeled graphs whereit is essential to incorporate the information in the known label forpredicting the unknown labels. To address this issue, we propose a novelframework leveraging the diffusion probabilistic model for structured nodeclassification (DPM-SNC). At the heart of our framework is the extraordinarycapability of DPM-SNC to (a) learn a joint distribution over the labels with anexpressive reverse diffusion process and (b) make predictions conditioned onthe known labels utilizing manifold-constrained sampling. Since the DPMs lacktraining algorithms for partially labeled data, we design a novel trainingalgorithm to apply DPMs, maximizing a new variational lower bound. We alsotheoretically analyze how DPMs benefit node classification by enhancing theexpressive power of GNNs based on proposing AGG-WL, which is strictly morepowerful than the classic 1-WL test. We extensively verify the superiority ofour DPM-SNC in diverse scenarios, which include not only the transductivesetting on partially labeled graphs but also the inductive setting andunlabeled graphs.</description><author>Hyosoon Jang, Sangwoo Mo, Sungsoo Ahn</author><pubDate>Fri, 16 Jun 2023 16:32:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10506v4</guid></item><item><title>ClimSim: An open large-scale dataset for training high-resolution physics emulators in hybrid multi-scale climate simulators</title><link>http://arxiv.org/abs/2306.08754v2</link><description>Modern climate projections lack adequate spatial and temporal resolution dueto computational constraints. A consequence is inaccurate and impreciseprediction of critical processes such as storms. Hybrid methods that combinephysics with machine learning (ML) have introduced a new generation of higherfidelity climate simulators that can sidestep Moore's Law by outsourcingcompute-hungry, short, high-resolution simulations to ML emulators. However,this hybrid ML-physics simulation approach requires domain-specific treatmentand has been inaccessible to ML experts because of lack of training data andrelevant, easy-to-use workflows. We present ClimSim, the largest-ever datasetdesigned for hybrid ML-physics research. It comprises multi-scale climatesimulations, developed by a consortium of climate scientists and MLresearchers. It consists of 5.7 billion pairs of multivariate input and outputvectors that isolate the influence of locally-nested, high-resolution,high-fidelity physics on a host climate simulator's macro-scale physical state. The dataset is global in coverage, spans multiple years at high samplingfrequency, and is designed such that resulting emulators are compatible withdownstream coupling into operational climate simulators. We implement a rangeof deterministic and stochastic regression baselines to highlight the MLchallenges and their scoring. The data(https://huggingface.co/datasets/LEAP/ClimSim_high-res) and code(https://leap-stc.github.io/ClimSim) are released openly to support thedevelopment of hybrid ML-physics and high-fidelity climate simulations for thebenefit of science and society.</description><author>Sungduk Yu, Walter M. Hannah, Liran Peng, Mohamed Aziz Bhouri, Ritwik Gupta, Jerry Lin, Björn Lütjens, Justus C. Will, Tom Beucler, Bryce E. Harrop, Benjamin R. Hillman, Andrea M. Jenney, Savannah L. Ferretti, Nana Liu, Anima Anandkumar, Noah D. Brenowitz, Veronika Eyring, Pierre Gentine, Stephan Mandt, Jaideep Pathak, Carl Vondrick, Rose Yu, Laure Zanna, Ryan P. Abernathey, Fiaz Ahmed, David C. Bader, Pierre Baldi, Elizabeth A. Barnes, Gunnar Behrens, Christopher S. Bretherton, Julius J. M. Busecke, Peter M. Caldwell, Wayne Chuang, Yilun Han, Yu Huang, Fernando Iglesias-Suarez, Sanket Jantre, Karthik Kashinath, Marat Khairoutdinov, Thorsten Kurth, Nicholas J. Lutsko, Po-Lun Ma, Griffin Mooers, J. David Neelin, David A. Randall, Sara Shamekh, Akshay Subramaniam, Mark A. Taylor, Nathan M. U</author><pubDate>Fri, 16 Jun 2023 16:31:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08754v2</guid></item><item><title>Strong-AI Autoepistemic Robots Build on Intensional First Order Logic</title><link>http://arxiv.org/abs/2212.07935v2</link><description>Neuro-symbolic AI attempts to integrate neural and symbolic architectures ina manner that addresses strengths and weaknesses of each, in a complementaryfashion, in order to support robust strong AI capable of reasoning, learning,and cognitive modeling. In this paper we consider the intensional First Order Logic (IFOL) as a symbolic architecture of modernrobots, able to use natural languages to communicate with humans and to reasonabout their own knowledge with self-reference and abstraction languageproperty. We intend to obtain the grounding of robot's language by experience of how ituses its neuronal architectures and hence by associating this experience withthe mining (sense) of non-defined language concepts (particulars/individualsand universals) in PRP (Properties/Relations/Propositions) theory of IFOL. We consider the robot's four-levels knowledge structure: The syntax level ofparticular natural language (Italian, French, etc..), two universal languagelevels: its semantic logic structure (based on virtual predicates of FOL andlogic connectives), and its corresponding conceptual PRP structure level whichuniversally represents the composite mining of FOL formulae grounded on thelast robot's neuro system level.</description><author>Zoran Majkic</author><pubDate>Fri, 16 Jun 2023 16:28:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.07935v2</guid></item><item><title>Explainable Action Advising for Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2211.07882v3</link><description>Action advising is a knowledge transfer technique for reinforcement learningbased on the teacher-student paradigm. An expert teacher provides advice to astudent during training in order to improve the student's sample efficiency andpolicy performance. Such advice is commonly given in the form of state-actionpairs. However, it makes it difficult for the student to reason with and applyto novel states. We introduce Explainable Action Advising, in which the teacherprovides action advice as well as associated explanations indicating why theaction was chosen. This allows the student to self-reflect on what it haslearned, enabling advice generalization and leading to improved sampleefficiency and learning performance - even in environments where the teacher issub-optimal. We empirically show that our framework is effective in bothsingle-agent and multi-agent scenarios, yielding improved policy returns andconvergence rates when compared to state-of-the-art methods</description><author>Yue Guo, Joseph Campbell, Simon Stepputtis, Ruiyu Li, Dana Hughes, Fei Fang, Katia Sycara</author><pubDate>Fri, 16 Jun 2023 16:20:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.07882v3</guid></item><item><title>Enhanced Sampling with Machine Learning: A Review</title><link>http://arxiv.org/abs/2306.09111v2</link><description>Molecular dynamics (MD) enables the study of physical systems with excellentspatiotemporal resolution but suffers from severe time-scale limitations. Toaddress this, enhanced sampling methods have been developed to improveexploration of configurational space. However, implementing these ischallenging and requires domain expertise. In recent years, integration ofmachine learning (ML) techniques in different domains has shown promise,prompting their adoption in enhanced sampling as well. Although ML is oftenemployed in various fields primarily due to its data-driven nature, itsintegration with enhanced sampling is more natural with many common underlyingsynergies. This review explores the merging of ML and enhanced MD by presentingdifferent shared viewpoints. It offers a comprehensive overview of this rapidlyevolving field, which can be difficult to stay updated on. We highlightsuccessful strategies like dimensionality reduction, reinforcement learning,and flow-based methods. Finally, we discuss open problems at the excitingML-enhanced MD interface.</description><author>Shams Mehdi, Zachary Smith, Lukas Herron, Ziyue Zou, Pratyush Tiwary</author><pubDate>Fri, 16 Jun 2023 16:18:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09111v2</guid></item><item><title>Demystifying GPT Self-Repair for Code Generation</title><link>http://arxiv.org/abs/2306.09896v1</link><description>Large Language Models (LLMs) have shown remarkable aptitude in codegeneration but still struggle on challenging programming tasks. Self-repair --in which the model debugs and fixes mistakes in its own code -- has recentlybecome a popular way to boost performance in these settings. However, only verylimited studies on how and when self-repair works effectively exist in theliterature, and one might wonder to what extent a model is really capable ofproviding accurate feedback on why the code is wrong when that code wasgenerated by the same model. In this paper, we analyze GPT-3.5 and GPT-4'sability to perform self-repair on APPS, a challenging dataset consisting ofdiverse coding challenges. To do so, we first establish a new evaluationstrategy dubbed pass@t that measures the pass rate of the tasks against thetotal number of tokens sampled from the model, enabling a fair comparison topurely sampling-based approaches. With this evaluation strategy, we find thatthe effectiveness of self-repair is only seen in GPT-4. We also observe thatself-repair is bottlenecked by the feedback stage; using GPT-4 to give feedbackon the programs generated by GPT-3.5 and using expert human programmers to givefeedback on the programs generated by GPT-4, we unlock significant performancegains.</description><author>Theo X. Olausson, Jeevana Priya Inala, Chenglong Wang, Jianfeng Gao, Armando Solar-Lezama</author><pubDate>Fri, 16 Jun 2023 16:13:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09896v1</guid></item><item><title>"When Words Fail, Emojis Prevail": Generating Sarcastic Utterances with Emoji Using Valence Reversal and Semantic Incongruity</title><link>http://arxiv.org/abs/2305.04105v2</link><description>Sarcasm is a form of figurative language that serves as a humorous tool formockery and ridicule. We present a novel architecture for sarcasm generationwith emoji from a non-sarcastic input sentence in English. We divide thegeneration task into two sub tasks: one for generating textual sarcasm andanother for collecting emojis associated with those sarcastic sentences. Twokey elements of sarcasm are incorporated into the textual sarcasm generationtask: valence reversal and semantic incongruity with context, where the contextmay involve shared commonsense or general knowledge between the speaker andtheir audience. The majority of existing sarcasm generation works have focusedon this textual form. However, in the real world, when written texts fall shortof effectively capturing the emotional cues of spoken and face-to-facecommunication, people often opt for emojis to accurately express theiremotions. Due to the wide range of applications of emojis, incorporatingappropriate emojis to generate textual sarcastic sentences helps advancesarcasm generation. We conclude our study by evaluating the generated sarcasticsentences using human judgement. All the codes and data used in this study hasbeen made publicly available.</description><author>Faria Binte Kader, Nafisa Hossain Nujat, Tasmia Binte Sogir, Mohsinul Kabir, Hasan Mahmud, Kamrul Hasan</author><pubDate>Fri, 16 Jun 2023 16:11:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04105v2</guid></item><item><title>DreamSparse: Escaping from Plato's Cave with 2D Frozen Diffusion Model Given Sparse Views</title><link>http://arxiv.org/abs/2306.03414v4</link><description>Synthesizing novel view images from a few views is a challenging butpractical problem. Existing methods often struggle with producing high-qualityresults or necessitate per-object optimization in such few-view settings due tothe insufficient information provided. In this work, we explore leveraging thestrong 2D priors in pre-trained diffusion models for synthesizing novel viewimages. 2D diffusion models, nevertheless, lack 3D awareness, leading todistorted image synthesis and compromising the identity. To address theseproblems, we propose DreamSparse, a framework that enables the frozenpre-trained diffusion model to generate geometry and identity-consistent novelview image. Specifically, DreamSparse incorporates a geometry module designedto capture 3D features from sparse views as a 3D prior. Subsequently, a spatialguidance model is introduced to convert these 3D feature maps into spatialinformation for the generative process. This information is then used to guidethe pre-trained diffusion model, enabling it to generate geometricallyconsistent images without tuning it. Leveraging the strong image priors in thepre-trained diffusion models, DreamSparse is capable of synthesizinghigh-quality novel views for both object and scene-level images andgeneralising to open-set images. Experimental results demonstrate that ourframework can effectively synthesize novel view images from sparse views andoutperforms baselines in both trained and open-set category images. Moreresults can be found on our project page:https://sites.google.com/view/dreamsparse-webpage.</description><author>Paul Yoo, Jiaxian Guo, Yutaka Matsuo, Shixiang Shane Gu</author><pubDate>Fri, 16 Jun 2023 16:10:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03414v4</guid></item><item><title>High-Dimensional MR Reconstruction Integrating Subspace and Adaptive Generative Models</title><link>http://arxiv.org/abs/2306.08630v2</link><description>We present a novel method that integrates subspace modeling with an adaptivegenerative image prior for high-dimensional MR image reconstruction. Thesubspace model imposes an explicit low-dimensional representation of thehigh-dimensional images, while the generative image prior serves as a spatialconstraint on the "contrast-weighted" images or the spatial coefficients of thesubspace model. A formulation was introduced to synergize these two componentswith complimentary regularization such as joint sparsity. A special pretrainingplus subject-specific network adaptation strategy was proposed to construct anaccurate generative-model-based representation for images with varyingcontrasts, validated by experimental data. An iterative algorithm wasintroduced to jointly update the subspace coefficients and the multiresolutionlatent space of the generative image model that leveraged a recently developedintermediate layer optimization technique for network inversion. We evaluatedthe utility of the proposed method in two high-dimensional imagingapplications: accelerated MR parameter mapping and high-resolution MRSI.Improved performance over state-of-the-art subspace-based methods wasdemonstrated in both cases. Our work demonstrated the potential of integratingdata-driven and adaptive generative models with low-dimensional representationfor high-dimensional imaging problems.</description><author>Ruiyang Zhao, Xi Peng, Varun A. Kelkar, Mark A. Anastasio, Fan Lam</author><pubDate>Fri, 16 Jun 2023 16:06:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08630v2</guid></item><item><title>MMASD: A Multimodal Dataset for Autism Intervention Analysis</title><link>http://arxiv.org/abs/2306.08243v2</link><description>Autism spectrum disorder (ASD) is a developmental disorder characterized bysignificant social communication impairments and difficulties perceiving andpresenting communication cues. Machine learning techniques have been broadlyadopted to facilitate autism studies and assessments. However, computationalmodels are primarily concentrated on specific analysis and validated on privatedatasets in the autism community, which limits comparisons across models due toprivacy-preserving data sharing complications. This work presents a novelprivacy-preserving open-source dataset, MMASD as a MultiModal ASD benchmarkdataset, collected from play therapy interventions of children with Autism.MMASD includes data from 32 children with ASD, and 1,315 data samples segmentedfrom over 100 hours of intervention recordings. To promote public access, eachdata sample consists of four privacy-preserving modalities of data: (1) opticalflow, (2) 2D skeleton, (3) 3D skeleton, and (4) clinician ASD evaluation scoresof children, e.g., ADOS scores. MMASD aims to assist researchers and therapistsin understanding children's cognitive status, monitoring their progress duringtherapy, and customizing the treatment plan accordingly. It also hasinspiration for downstream tasks such as action quality assessment andinterpersonal synchrony estimation. MMASD dataset can be easily accessed athttps://github.com/Li-Jicheng/MMASD-A-Multimodal-Dataset-for-Autism-Intervention-Analysis.</description><author>Jicheng Li, Vuthea Chheang, Pinar Kullu, Eli Brignac, Zhang Guo, Kenneth E. Barner, Anjana Bhat, Roghayeh Leila Barmaki</author><pubDate>Fri, 16 Jun 2023 16:03:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08243v2</guid></item><item><title>Artificial Intelligence in Ovarian Cancer Histopathology: A Systematic Review</title><link>http://arxiv.org/abs/2303.18005v2</link><description>Purpose - To characterise and assess the quality of published researchevaluating artificial intelligence (AI) methods for ovarian cancer diagnosis orprognosis using histopathology data. Methods - A search of PubMed, Scopus, Webof Science, CENTRAL, and WHO-ICTRP was conducted up to 19/05/2023. Theinclusion criteria required that research evaluated AI on histopathology imagesfor diagnostic or prognostic inferences in ovarian cancer. The risk of bias wasassessed using PROBAST. Information about each model of interest was tabulatedand summary statistics were reported. PRISMA 2020 reporting guidelines werefollowed. Results - 1573 records were identified, of which 45 were eligible forinclusion. There were 80 models of interest, including 37 diagnostic models, 22prognostic models, and 21 models with other diagnostically relevant outcomes.Models were developed using 1-1375 slides from 1-776 ovarian cancer patients.Model outcomes included treatment response (11/80), malignancy status (10/80),stain quantity (9/80), and histological subtype (7/80). All models were foundto be at high or unclear risk of bias overall, with most research having a highrisk of bias in the analysis and a lack of clarity regarding participants andpredictors in the study. Research frequently suffered from insufficientreporting and limited validation using small sample sizes. Conclusion - Limitedresearch has been conducted on the application of AI to histopathology imagesfor diagnostic or prognostic purposes in ovarian cancer, and none of theassociated models have been demonstrated to be ready for real-worldimplementation. Key aspects to help ensure clinical translation include moretransparent and comprehensive reporting of data provenance and modellingapproaches, as well as improved quantitative performance evaluation usingcross-validation and external validations.</description><author>Jack Breen, Katie Allen, Kieran Zucker, Pratik Adusumilli, Andy Scarsbrook, Geoff Hall, Nicolas M. Orsi, Nishant Ravikumar</author><pubDate>Fri, 16 Jun 2023 16:02:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.18005v2</guid></item><item><title>Studying Generalization on Memory-Based Methods in Continual Learning</title><link>http://arxiv.org/abs/2306.09890v1</link><description>One of the objectives of Continual Learning is to learn new conceptscontinually over a stream of experiences and at the same time avoidcatastrophic forgetting. To mitigate complete knowledge overwriting,memory-based methods store a percentage of previous data distributions to beused during training. Although these methods produce good results, few studieshave tested their out-of-distribution generalization properties, as well aswhether these methods overfit the replay memory. In this work, we show thatalthough these methods can help in traditional in-distribution generalization,they can strongly impair out-of-distribution generalization by learningspurious features and correlations. Using a controlled environment, the Synbolbenchmark generator (Lacoste et al., 2020), we demonstrate that this lack ofout-of-distribution generalization mainly occurs in the linear classifier.</description><author>Felipe del Rio, Julio Hurtado, Cristian Buc, Alvaro Soto, Vincenzo Lomonaco</author><pubDate>Fri, 16 Jun 2023 15:59:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09890v1</guid></item><item><title>CANDID: Correspondence AligNment for Deep-burst Image Denoising</title><link>http://arxiv.org/abs/2306.09887v1</link><description>With the advent of mobile phone photography and point-and-shoot cameras,deep-burst imaging is widely used for a number of photographic effects such asdepth of field, super-resolution, motion deblurring, and image denoising. Inthis work, we propose to solve the problem of deep-burst image denoising byincluding an optical flow-based correspondence estimation module which alignsall the input burst images with respect to a reference frame. In order to dealwith varying noise levels the individual burst images are pre-filtered withdifferent settings. Exploiting the established correspondences one networkblock predicts a pixel-wise spatially-varying filter kernel to smooth eachimage in the original and prefiltered bursts before fusing all images togenerate the final denoised output. The resulting pipeline achievesstate-of-the-art results by combining all available information provided by theburst.</description><author>Arijit Mallick, Raphael Braun, Hendrik PA Lensch</author><pubDate>Fri, 16 Jun 2023 15:55:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09887v1</guid></item><item><title>Squeezing nnU-Nets with Knowledge Distillation for On-Board Cloud Detection</title><link>http://arxiv.org/abs/2306.09886v1</link><description>Cloud detection is a pivotal satellite image pre-processing step that can beperformed both on the ground and on board a satellite to tag useful images. Inthe latter case, it can reduce the amount of data to downlink by pruning thecloudy areas, or to make a satellite more autonomous through data-drivenacquisition re-scheduling. We approach this task with nnU-Nets, aself-reconfigurable framework able to perform meta-learning of a segmentationnetwork over various datasets. Unfortunately, such models are commonlymemory-inefficient due to their (very) large architectures. To benefit fromthem in on-board processing, we compress nnU-Nets with knowledge distillationinto much smaller and compact U-Nets. Our experiments, performed overSentinel-2 and Landsat-8 images revealed that nnU-Nets deliver state-of-the-artperformance without any manual design. Our approach was ranked within the top7% best solutions (across 847 teams) in the On Cloud N: Cloud Cover DetectionChallenge, where we reached the Jaccard index of 0.882 over more than 10kunseen Sentinel-2 images (the winners obtained 0.897, the baseline U-Net withthe ResNet-34 backbone: 0.817, and the classic Sentinel-2 image thresholding:0.652). Finally, we showed that knowledge distillation enables to elaboratedramatically smaller (almost 280x) U-Nets when compared to nnU-Nets while stillmaintaining their segmentation capabilities.</description><author>Bartosz Grabowski, Maciej Ziaja, Michal Kawulok, Piotr Bosowski, Nicolas Longépé, Bertrand Le Saux, Jakub Nalepa</author><pubDate>Fri, 16 Jun 2023 15:53:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09886v1</guid></item><item><title>Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX</title><link>http://arxiv.org/abs/2306.09884v1</link><description>Open-source reinforcement learning (RL) environments have played a crucialrole in driving progress in the development of AI algorithms. In modern RLresearch, there is a need for simulated environments that are performant,scalable, and modular to enable their utilization in a wider range of potentialreal-world applications. Therefore, we present Jumanji, a suite of diverse RLenvironments specifically designed to be fast, flexible, and scalable. Jumanjiprovides a suite of environments focusing on combinatorial problems frequentlyencountered in industry, as well as challenging general decision-making tasks.By leveraging the efficiency of JAX and hardware accelerators like GPUs andTPUs, Jumanji enables rapid iteration of research ideas and large-scaleexperimentation, ultimately empowering more capable agents. Unlike existing RLenvironment suites, Jumanji is highly customizable, allowing users to tailorthe initial state distribution and problem complexity to their needs.Furthermore, we provide actor-critic baselines for each environment,accompanied by preliminary findings on scaling and generalization scenarios.Jumanji aims to set a new standard for speed, adaptability, and scalability ofRL environments.</description><author>Clément Bonnet, Daniel Luo, Donal Byrne, Shikha Surana, Vincent Coyette, Paul Duckworth, Laurence I. Midgley, Tristan Kalloniatis, Sasha Abramowitz, Cemlyn N. Waters, Andries P. Smit, Nathan Grinsztajn, Ulrich A. Mbou Sob, Omayma Mahjoub, Elshadai Tegegn, Mohamed A. Mimouni, Raphael Boige, Ruan de Kock, Daniel Furelos-Blanco, Victor Le, Arnu Pretorius, Alexandre Laterre</author><pubDate>Fri, 16 Jun 2023 15:52:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09884v1</guid></item><item><title>Uncertainty Quantification via Spatial-Temporal Tweedie Model for Zero-inflated and Long-tail Travel Demand Prediction</title><link>http://arxiv.org/abs/2306.09882v1</link><description>crucial for transportation management. However, traditional spatial-temporaldeep learning models grapple with addressing the sparse and long-tailcharacteristics in high-resolution O-D matrices and quantifying predictionuncertainty. This dilemma arises from the numerous zeros and over-disperseddemand patterns within these matrices, which challenge the Gaussian assumptioninherent to deterministic deep learning models. To address these challenges, wepropose a novel approach: the Spatial-Temporal Tweedie Graph Neural Network(STTD). The STTD introduces the Tweedie distribution as a compellingalternative to the traditional 'zero-inflated' model and leverages spatial andtemporal embeddings to parameterize travel demand distributions. Ourevaluations using real-world datasets highlight STTD's superiority in providingaccurate predictions and precise confidence intervals, particularly inhigh-resolution scenarios.</description><author>Xinke Jiang, Dingyi Zhuang, Xianghui Zhang, Hao Chen, Jiayuan Luo, Xiaowei Gao</author><pubDate>Fri, 16 Jun 2023 15:50:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09882v1</guid></item><item><title>Iterative Partial Fulfillment of Counterfactual Explanations: Benefits and Risks</title><link>http://arxiv.org/abs/2303.11111v2</link><description>Counterfactual (CF) explanations, also known as contrastive explanations andalgorithmic recourses, are popular for explaining machine learning models inhigh-stakes domains. For a subject that receives a negative model prediction(e.g., mortgage application denial), the CF explanations are similar instancesbut with positive predictions, which informs the subject of ways to improve.While their various properties have been studied, such as validity andstability, we contribute a novel one: their behaviors under iterative partialfulfillment (IPF). Specifically, upon receiving a CF explanation, the subjectmay only partially fulfill it before requesting a new prediction with a newexplanation, and repeat until the prediction is positive. Such partialfulfillment could be due to the subject's limited capability (e.g., can onlypay down two out of four credit card accounts at this moment) or an attempt totake the chance (e.g., betting that a monthly salary increase of $800 is enougheven though $1,000 is recommended). Does such iterative partial fulfillmentincrease or decrease the total cost of improvement incurred by the subject? Wemathematically formalize IPF and demonstrate, both theoretically andempirically, that different CF algorithms exhibit vastly different behaviorsunder IPF. We discuss implications of our observations, advocate for thisfactor to be carefully considered in the development and study of CFalgorithms, and give several directions for future work.</description><author>Yilun Zhou</author><pubDate>Fri, 16 Jun 2023 15:49:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11111v2</guid></item><item><title>Revealing the impact of social circumstances on the selection of cancer therapy through natural language processing of social work notes</title><link>http://arxiv.org/abs/2306.09877v1</link><description>We aimed to investigate the impact of social circumstances on cancer therapyselection using natural language processing to derive insights from socialworker documentation. We developed and employed a Bidirectional EncoderRepresentations from Transformers (BERT) based approach, using a hierarchicalmulti-step BERT model (BERT-MS) to predict the prescription of targeted cancertherapy to patients based solely on documentation by clinical social workers.Our corpus included free-text clinical social work notes, combined withmedication prescription information, for all patients treated for breastcancer. We conducted a feature importance analysis to pinpoint the specificsocial circumstances that impact cancer therapy selection. Using only socialwork notes, we consistently predicted the administration of targeted therapies,suggesting systematic differences in treatment selection exist due tonon-clinical factors. The UCSF-BERT model, pretrained on clinical text at UCSF,outperformed other publicly available language models with an AUROC of 0.675and a Macro F1 score of 0.599. The UCSF BERT-MS model, capable of leveragingmultiple pieces of notes, surpassed the UCSF-BERT model in both AUROC andMacro-F1. Our feature importance analysis identified several clinicallyintuitive social determinants of health (SDOH) that potentially contribute todisparities in treatment. Our findings indicate that significant disparitiesexist among breast cancer patients receiving different types of therapies basedon social determinants of health. Social work reports play a crucial role inunderstanding these disparities in clinical decision-making.</description><author>Shenghuan Sun, Travis Zack, Christopher Y. K. Williams, Atul J. Butte, Madhumita Sushil</author><pubDate>Fri, 16 Jun 2023 15:40:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09877v1</guid></item><item><title>Going public: the role of public participation approaches in commercial AI labs</title><link>http://arxiv.org/abs/2306.09871v1</link><description>In recent years, discussions of responsible AI practices have seen growingsupport for "participatory AI" approaches, intended to involve members of thepublic in the design and development of AI systems. Prior research hasidentified a lack of standardised methods or approaches for how to useparticipatory approaches in the AI development process. At present, there is adearth of evidence on attitudes to and approaches for participation in thesites driving major AI developments: commercial AI labs. Through 12semi-structured interviews with industry practitioners and subject-matterexperts, this paper explores how commercial AI labs understand participatory AIapproaches and the obstacles they have faced implementing these practices inthe development of AI systems and research. We find that while intervieweesview participation as a normative project that helps achieve "societallybeneficial" AI systems, practitioners face numerous barriers to embeddingparticipatory approaches in their companies: participation is expensive andresource intensive, it is "atomised" within companies, there is concern aboutexploitation, there is no incentive to be transparent about its adoption, andit is complicated by a lack of clear context. These barriers result in apiecemeal approach to participation that confers no decision-making power toparticipants and has little ongoing impact for AI labs. This paperscontribution is to provide novel empirical research on the implementation ofpublic participation in commercial AI labs, and shed light on the currentchallenges of using participatory approaches in this context.</description><author>Lara Groves, Aidan Peppin, Andrew Strait, Jenny Brennan</author><pubDate>Fri, 16 Jun 2023 15:34:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09871v1</guid></item><item><title>InDistill: Information flow-preserving knowledge distillation for model compression</title><link>http://arxiv.org/abs/2205.10003v3</link><description>In this paper we introduce InDistill, a model compression approach thatcombines knowledge distillation and channel pruning in a unified framework forthe transfer of the critical information flow paths from a heavyweight teacherto a lightweight student. Such information is typically collapsed in previousmethods due to an encoding stage prior to distillation. By contrast, InDistillleverages a pruning operation applied to the teacher's intermediate layersreducing their width to the corresponding student layers' width. In that way,we force architectural alignment enabling the intermediate layers to bedirectly distilled without the need of an encoding stage. Additionally, acurriculum learning-based training scheme is adopted considering thedistillation difficulty of each layer and the critical learning periods inwhich the information flow paths are created. The proposed method surpassesstate-of-the-art performance on three standard benchmarks, i.e. CIFAR-10,CUB-200, and FashionMNIST by 3.08%, 14.27%, and 1% mAP, respectively, as wellas on more challenging evaluation settings, i.e. ImageNet and CIFAR-100 by1.97% and 5.65% mAP, respectively.</description><author>Ioannis Sarridis, Christos Koutlis, Giorgos Kordopatis-Zilos, Ioannis Kompatsiaris, Symeon Papadopoulos</author><pubDate>Fri, 16 Jun 2023 15:32:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.10003v3</guid></item><item><title>Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2306.09869v1</link><description>Despite the remarkable performance of text-to-image diffusion models in imagegeneration tasks, recent studies have raised the issue that generated imagessometimes cannot capture the intended semantic contents of the text prompts,which phenomenon is often called semantic misalignment. To address this, herewe present a novel energy-based model (EBM) framework. Specifically, we firstformulate EBMs of latent image representations and text embeddings in eachcross-attention layer of the denoising autoencoder. Then, we obtain thegradient of the log posterior of context vectors, which can be updated andtransferred to the subsequent cross-attention layer, thereby implicitlyminimizing a nested hierarchy of energy functions. Our latent EBMs furtherallow zero-shot compositional generation as a linear combination ofcross-attention outputs from different contexts. Using extensive experiments,we demonstrate that the proposed method is highly effective in handling variousimage generation tasks, including multi-concept generation, text-guided imageinpainting, and real and synthetic image editing.</description><author>Geon Yeong Park, Jeongsol Kim, Beomsu Kim, Sang Wan Lee, Jong Chul Ye</author><pubDate>Fri, 16 Jun 2023 15:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09869v1</guid></item><item><title>TotalSegmentator: robust segmentation of 104 anatomical structures in CT images</title><link>http://arxiv.org/abs/2208.05868v2</link><description>We present a deep learning segmentation model that can automatically androbustly segment all major anatomical structures in body CT images. In thisretrospective study, 1204 CT examinations (from the years 2012, 2016, and 2020)were used to segment 104 anatomical structures (27 organs, 59 bones, 10muscles, 8 vessels) relevant for use cases such as organ volumetry, diseasecharacterization, and surgical or radiotherapy planning. The CT images wererandomly sampled from routine clinical studies and thus represent a real-worlddataset (different ages, pathologies, scanners, body parts, sequences, andsites). The authors trained an nnU-Net segmentation algorithm on this datasetand calculated Dice similarity coefficients (Dice) to evaluate the model'sperformance. The trained algorithm was applied to a second dataset of 4004whole-body CT examinations to investigate age dependent volume and attenuationchanges. The proposed model showed a high Dice score (0.943) on the test set,which included a wide range of clinical data with major pathologies. The modelsignificantly outperformed another publicly available segmentation model on aseparate dataset (Dice score, 0.932 versus 0.871, respectively). The agingstudy demonstrated significant correlations between age and volume and meanattenuation for a variety of organ groups (e.g., age and aortic volume; age andmean attenuation of the autochthonous dorsal musculature). The developed modelenables robust and accurate segmentation of 104 anatomical structures. Theannotated dataset (https://doi.org/10.5281/zenodo.6802613) and toolkit(https://www.github.com/wasserth/TotalSegmentator) are publicly available.</description><author>Jakob Wasserthal, Hanns-Christian Breit, Manfred T. Meyer, Maurice Pradella, Daniel Hinck, Alexander W. Sauter, Tobias Heye, Daniel Boll, Joshy Cyriac, Shan Yang, Michael Bach, Martin Segeroth</author><pubDate>Fri, 16 Jun 2023 15:26:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.05868v2</guid></item><item><title>Transferability of Winning Lottery Tickets in Neural Network Differential Equation Solvers</title><link>http://arxiv.org/abs/2306.09863v1</link><description>Recent work has shown that renormalisation group theory is a useful frameworkwith which to describe the process of pruning neural networks via iterativemagnitude pruning. This report formally describes the link between RG theoryand IMP and extends previous results around the Lottery Ticket Hypothesis andElastic Lottery Hypothesis to Hamiltonian Neural Networks for solvingdifferential equations. We find lottery tickets for two Hamiltonian NeuralNetworks and demonstrate transferability between the two systems, with accuracybeing dependent on integration times. The universality of the two systems isthen analysed using tools from an RG perspective.</description><author>Edward Prideaux-Ghee</author><pubDate>Fri, 16 Jun 2023 15:18:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09863v1</guid></item><item><title>DoubleAdapt: A Meta-learning Approach to Incremental Learning for Stock Trend Forecasting</title><link>http://arxiv.org/abs/2306.09862v1</link><description>Stock trend forecasting is a fundamental task of quantitative investmentwhere precise predictions of price trends are indispensable. As an onlineservice, stock data continuously arrive over time. It is practical andefficient to incrementally update the forecast model with the latest data whichmay reveal some new patterns recurring in the future stock market. However,incremental learning for stock trend forecasting still remains under-exploreddue to the challenge of distribution shifts (a.k.a. concept drifts). With thestock market dynamically evolving, the distribution of future data can slightlyor significantly differ from incremental data, hindering the effectiveness ofincremental updates. To address this challenge, we propose DoubleAdapt, anend-to-end framework with two adapters, which can effectively adapt the dataand the model to mitigate the effects of distribution shifts. Our key insightis to automatically learn how to adapt stock data into a locally stationarydistribution in favor of profitable updates. Complemented by data adaptation,we can confidently adapt the model parameters under mitigated distributionshifts. We cast each incremental learning task as a meta-learning task andautomatically optimize the adapters for desirable data adaptation and parameterinitialization. Experiments on real-world stock datasets demonstrate thatDoubleAdapt achieves state-of-the-art predictive performance and showsconsiderable efficiency.</description><author>Lifan Zhao, Shuming Kong, Yanyan Shen</author><pubDate>Fri, 16 Jun 2023 15:18:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09862v1</guid></item><item><title>Deep Learning for Opinion Mining and Topic Classification of Course Reviews</title><link>http://arxiv.org/abs/2304.03394v2</link><description>Student opinions for a course are important to educators and administrators,regardless of the type of the course or the institution. Reading and manuallyanalyzing open-ended feedback becomes infeasible for massive volumes ofcomments at institution level or online forums. In this paper, we collected andpre-processed a large number of course reviews publicly available online. Weapplied machine learning techniques with the goal to gain insight into studentsentiments and topics. Specifically, we utilized current Natural LanguageProcessing (NLP) techniques, such as word embeddings and deep neural networks,and state-of-the-art BERT (Bidirectional Encoder Representations fromTransformers), RoBERTa (Robustly optimized BERT approach) and XLNet(Generalized Auto-regression Pre-training). We performed extensiveexperimentation to compare these techniques versus traditional approaches. Thiscomparative study demonstrates how to apply modern machine learning approachesfor sentiment polarity extraction and topic-based classification utilizingcourse feedback. For sentiment polarity, the top model was RoBERTa with 95.5%accuracy and 84.7% F1-macro, while for topic classification, an SVM (SupportVector Machine) was the top classifier with 79.8% accuracy and 80.6% F1-macro.We also provided an in-depth exploration of the effect of certainhyperparameters on the model performance and discussed our observations. Thesefindings can be used by institutions and course providers as a guide foranalyzing their own course feedback using NLP models towards self-evaluationand improvement.</description><author>Anna Koufakou</author><pubDate>Fri, 16 Jun 2023 15:15:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03394v2</guid></item><item><title>MixedTeacher : Knowledge Distillation for fast inference textural anomaly detection</title><link>http://arxiv.org/abs/2306.09859v1</link><description>For a very long time, unsupervised learning for anomaly detection has been atthe heart of image processing research and a stepping stone for highperformance industrial automation process. With the emergence of CNN, severalmethods have been proposed such as Autoencoders, GAN, deep feature extraction,etc. In this paper, we propose a new method based on the promising concept ofknowledge distillation which consists of training a network (the student) onnormal samples while considering the output of a larger pretrained network (theteacher). The main contributions of this paper are twofold: First, a reducedstudent architecture with optimal layer selection is proposed, then a newStudent-Teacher architecture with network bias reduction combining two teachersis proposed in order to jointly enhance the performance of anomaly detectionand its localization accuracy. The proposed texture anomaly detector has anoutstanding capability to detect defects in any texture and a fast inferencetime compared to the SOTA methods.</description><author>Simon Thomine, Hichem Snoussi, Mahmoud Soua</author><pubDate>Fri, 16 Jun 2023 15:14:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09859v1</guid></item><item><title>Prototype Learning for Explainable Regression</title><link>http://arxiv.org/abs/2306.09858v1</link><description>The lack of explainability limits the adoption of deep learning models inclinical practice. While methods exist to improve the understanding of suchmodels, these are mainly saliency-based and developed for classification,despite many important tasks in medical imaging being continuous regressionproblems. Therefore, in this work, we present ExPeRT: an explainableprototype-based model specifically designed for regression tasks. Our proposedmodel makes a sample prediction from the distances to a set of learnedprototypes in latent space, using a weighted mean of prototype labels. Thedistances in latent space are regularized to be relative to label differences,and each of the prototypes can be visualized as a sample from the training set.The image-level distances are further constructed from patch-level distances,in which the patches of both images are structurally matched using optimaltransport. We demonstrate our proposed model on the task of brain ageprediction on two image datasets: adult MR and fetal ultrasound. Our approachachieved state-of-the-art prediction performance while providing insight in themodel's reasoning process.</description><author>Linde S. Hesse, Nicola K. Dinsdale, Ana I. L. Namburete</author><pubDate>Fri, 16 Jun 2023 15:13:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09858v1</guid></item><item><title>Self-Supervised Video Similarity Learning</title><link>http://arxiv.org/abs/2304.03378v2</link><description>We introduce S$^2$VS, a video similarity learning approach withself-supervision. Self-Supervised Learning (SSL) is typically used to traindeep models on a proxy task so as to have strong transferability on targettasks after fine-tuning. Here, in contrast to prior work, SSL is used toperform video similarity learning and address multiple retrieval and detectiontasks at once with no use of labeled data. This is achieved by learning viainstance-discrimination with task-tailored augmentations and the widely usedInfoNCE loss together with an additional loss operating jointly onself-similarity and hard-negative similarity. We benchmark our method on taskswhere video relevance is defined with varying granularity, ranging from videocopies to videos depicting the same incident or event. We learn a singleuniversal model that achieves state-of-the-art performance on all tasks,surpassing previously proposed methods that use labeled data. The code andpretrained models are publicly available at: https://github.com/gkordo/s2vs</description><author>Giorgos Kordopatis-Zilos, Giorgos Tolias, Christos Tzelepis, Ioannis Kompatsiaris, Ioannis Patras, Symeon Papadopoulos</author><pubDate>Fri, 16 Jun 2023 15:11:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03378v2</guid></item><item><title>Runtime Construction of Large-Scale Spiking Neuronal Network Models on GPU Devices</title><link>http://arxiv.org/abs/2306.09855v1</link><description>Simulation speed matters for neuroscientific research: this includes not onlyhow quickly the simulated model time of a large-scale spiking neuronal networkprogresses, but also how long it takes to instantiate the network model incomputer memory. On the hardware side, acceleration via highly parallel GPUs isbeing increasingly utilized. On the software side, code generation approachesensure highly optimized code, at the expense of repeated code regeneration andrecompilation after modifications to the network model. Aiming for a greaterflexibility with respect to iterative model changes, here we propose a newmethod for creating network connections interactively, dynamically, anddirectly in GPU memory through a set of commonly used high-level connectionrules. We validate the simulation performance with both consumer and datacenter GPUs on two neuroscientifically relevant models: a cortical microcircuitof about 77,000 leaky-integrate-and-fire neuron models and 300 million staticsynapses, and a two-population network recurrently connected using a variety ofconnection rules. With our proposed ad hoc network instantiation, both networkconstruction and simulation times are comparable or shorter than those obtainedwith other state-of-the-art simulation technologies, while still meeting theflexibility demands of explorative network modeling.</description><author>Bruno Golosio, Jose Villamar, Gianmarco Tiddia, Elena Pastorelli, Jonas Stapmanns, Viviana Fanti, Pier Stanislao Paolucci, Abigail Morrison, Johanna Senk</author><pubDate>Fri, 16 Jun 2023 15:08:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09855v1</guid></item><item><title>Boosting Simple Learners</title><link>http://arxiv.org/abs/2001.11704v8</link><description>Boosting is a celebrated machine learning approach which is based on the ideaof combining weak and moderately inaccurate hypotheses to a strong and accurateone. We study boosting under the assumption that the weak hypotheses belong toa class of bounded capacity. This assumption is inspired by the commonconvention that weak hypotheses are "rules-of-thumbs" from an "easy-to-learnclass". (Schapire and Freund~'12, Shalev-Shwartz and Ben-David '14.) Formally,we assume the class of weak hypotheses has a bounded VC dimension. We focus ontwo main questions: (i) Oracle Complexity: How many weak hypotheses are neededto produce an accurate hypothesis? We design a novel boosting algorithm anddemonstrate that it circumvents a classical lower bound by Freund and Schapire('95, '12). Whereas the lower bound shows that $\Omega({1}/{\gamma^2})$ weakhypotheses with $\gamma$-margin are sometimes necessary, our new methodrequires only $\tilde{O}({1}/{\gamma})$ weak hypothesis, provided that theybelong to a class of bounded VC dimension. Unlike previous boosting algorithmswhich aggregate the weak hypotheses by majority votes, the new boostingalgorithm uses more complex ("deeper") aggregation rules. We complement thisresult by showing that complex aggregation rules are in fact necessary tocircumvent the aforementioned lower bound. (ii) Expressivity: Which tasks canbe learned by boosting weak hypotheses from a bounded VC class? Can complexconcepts that are "far away" from the class be learned? Towards answering thefirst question we {introduce combinatorial-geometric parameters which captureexpressivity in boosting.} As a corollary we provide an affirmative answer tothe second question for well-studied classes, including half-spaces anddecision stumps. Along the way, we establish and exploit connections withDiscrepancy Theory.</description><author>Noga Alon, Alon Gonen, Elad Hazan, Shay Moran</author><pubDate>Fri, 16 Jun 2023 15:06:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2001.11704v8</guid></item><item><title>Joint multi-modal Self-Supervised pre-training in Remote Sensing: Application to Methane Source Classification</title><link>http://arxiv.org/abs/2306.09851v1</link><description>With the current ubiquity of deep learning methods to solve computer visionand remote sensing specific tasks, the need for labelled data is growingconstantly. However, in many cases, the annotation process can be long andtedious depending on the expertise needed to perform reliable annotations. Inorder to alleviate this need for annotations, several self-supervised methodshave recently been proposed in the literature. The core principle behind thesemethods is to learn an image encoder using solely unlabelled data samples. Inearth observation, there are opportunities to exploit domain-specific remotesensing image data in order to improve these methods. Specifically, byleveraging the geographical position associated with each image, it is possibleto cross reference a location captured from multiple sensors, leading tomultiple views of the same locations. In this paper, we briefly review the coreprinciples behind so-called joint-embeddings methods and investigate the usageof multiple remote sensing modalities in self-supervised pre-training. Weevaluate the final performance of the resulting encoders on the task of methanesource classification.</description><author>Paul Berg, Minh-Tan Pham, Nicolas Courty</author><pubDate>Fri, 16 Jun 2023 15:01:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09851v1</guid></item><item><title>Practical Sharpness-Aware Minimization Cannot Converge All the Way to Optima</title><link>http://arxiv.org/abs/2306.09850v1</link><description>Sharpness-Aware Minimization (SAM) is an optimizer that takes a descent stepbased on the gradient at a perturbation $y_t = x_t + \rho \frac{\nablaf(x_t)}{\lVert \nabla f(x_t) \rVert}$ of the current point $x_t$. Existingstudies prove convergence of SAM for smooth functions, but they do so byassuming decaying perturbation size $\rho$ and/or no gradient normalization in$y_t$, which is detached from practice. To address this gap, we studydeterministic/stochastic versions of SAM with practical configurations (i.e.,constant $\rho$ and gradient normalization in $y_t$) and explore theirconvergence properties on smooth functions with (non)convexity assumptions.Perhaps surprisingly, in many scenarios, we find out that SAM has limitedcapability to converge to global minima or stationary points. For smoothstrongly convex functions, we show that while deterministic SAM enjoys tightglobal convergence rates of $\tilde \Theta(\frac{1}{T^2})$, the convergencebound of stochastic SAM suffers an inevitable additive term $O(\rho^2)$,indicating convergence only up to neighborhoods of optima. In fact, such$O(\rho^2)$ factors arise for stochastic SAM in all the settings we consider,and also for deterministic SAM in nonconvex cases; importantly, we prove byexamples that such terms are unavoidable. Our results highlight vastlydifferent characteristics of SAM with vs. without decaying perturbation size orgradient normalization, and suggest that the intuitions gained from one versionmay not apply to the other.</description><author>Dongkuk Si, Chulhee Yun</author><pubDate>Fri, 16 Jun 2023 14:47:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09850v1</guid></item><item><title>On Evolvability and Behavior Landscapes in Neuroevolutionary Divergent Search</title><link>http://arxiv.org/abs/2306.09849v1</link><description>Evolvability refers to the ability of an individual genotype (solution) toproduce offspring with mutually diverse phenotypes. Recent research hasdemonstrated that divergent search methods, particularly novelty search,promote evolvability by implicitly creating selective pressure for it. The mainobjective of this paper is to provide a novel perspective on the relationshipbetween neuroevolutionary divergent search and evolvability. In order toachieve this, several types of walks from the literature on fitness landscapeanalysis are first adapted to this context. Subsequently, the interplay betweenneuroevolutionary divergent search and evolvability under varying amounts ofevolutionary pressure and under different diversity metrics is investigated. Tothis end, experiments are performed on Fetch Pick and Place, a robotic armtask. Moreover, the performed study in particular sheds light on the structureof the genotype-phenotype mapping (the behavior landscape). Finally, a noveldefinition of evolvability that takes into account the evolvability ofoffspring and is appropriate for use with discretized behavior spaces isproposed, together with a Markov-chain-based estimation method for it.</description><author>Bruno Gašperov, Marko Đurasević</author><pubDate>Fri, 16 Jun 2023 14:46:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09849v1</guid></item><item><title>On Data Sampling Strategies for Training Neural Network Speech Separation Models</title><link>http://arxiv.org/abs/2304.07142v2</link><description>Speech separation remains an important area of multi-speaker signalprocessing. Deep neural network (DNN) models have attained the best performanceon many speech separation benchmarks. Some of these models can take significanttime to train and have high memory requirements. Previous work has proposedshortening training examples to address these issues but the impact of this onmodel performance is not yet well understood. In this work, the impact ofapplying these training signal length (TSL) limits is analysed for two speechseparation models: SepFormer, a transformer model, and Conv-TasNet, aconvolutional model. The WJS0-2Mix, WHAMR and Libri2Mix datasets are analysedin terms of signal length distribution and its impact on training efficiency.It is demonstrated that, for specific distributions, applying specific TSLlimits results in better performance. This is shown to be mainly due torandomly sampling the start index of the waveforms resulting in more uniqueexamples for training. A SepFormer model trained using a TSL limit of 4.42s anddynamic mixing (DM) is shown to match the best-performing SepFormer modeltrained with DM and unlimited signal lengths. Furthermore, the 4.42s TSL limitresults in a 44% reduction in training time with WHAMR.</description><author>William Ravenscroft, Stefan Goetze, Thomas Hain</author><pubDate>Fri, 16 Jun 2023 14:42:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.07142v2</guid></item><item><title>Wasserstein distributional robustness of neural networks</title><link>http://arxiv.org/abs/2306.09844v1</link><description>Deep neural networks are known to be vulnerable to adversarial attacks (AA).For an image recognition task, this means that a small perturbation of theoriginal can result in the image being misclassified. Design of such attacks aswell as methods of adversarial training against them are subject of intenseresearch. We re-cast the problem using techniques of Wassersteindistributionally robust optimization (DRO) and obtain novel contributionsleveraging recent insights from DRO sensitivity analysis. We consider a set ofdistributional threat models. Unlike the traditional pointwise attacks, whichassume a uniform bound on perturbation of each input data point, distributionalthreat models allow attackers to perturb inputs in a non-uniform way. We linkthese more general attacks with questions of out-of-sample performance andKnightian uncertainty. To evaluate the distributional robustness of neuralnetworks, we propose a first-order AA algorithm and its multi-step version. Ourattack algorithms include Fast Gradient Sign Method (FGSM) and ProjectedGradient Descent (PGD) as special cases. Furthermore, we provide a newasymptotic estimate of the adversarial accuracy against distributional threatmodels. The bound is fast to compute and first-order accurate, offering newinsights even for the pointwise AA. It also naturally yields out-of-sampleperformance guarantees. We conduct numerical experiments on the CIFAR-10dataset using DNNs on RobustBench to illustrate our theoretical results. Ourcode is available at https://github.com/JanObloj/W-DRO-Adversarial-Methods.</description><author>Xingjian Bai, Guangyi He, Yifan Jiang, Jan Obloj</author><pubDate>Fri, 16 Jun 2023 14:41:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09844v1</guid></item><item><title>Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation From Deductive, Inductive and Abductive Views</title><link>http://arxiv.org/abs/2306.09841v1</link><description>Large Language Models (LLMs) have achieved great success in various naturallanguage tasks. It has aroused much interest in evaluating the specificreasoning capability of LLMs, such as multilingual reasoning and mathematicalreasoning. However, as one of the key reasoning perspectives, logical reasoningcapability has not yet been thoroughly evaluated. In this work, we aim tobridge those gaps and provide comprehensive evaluations. Firstly, to offersystematic evaluations, this paper selects fifteen typical logical reasoningdatasets and organizes them into deductive, inductive, abductive and mixed-formreasoning settings. Considering the comprehensiveness of evaluations, weinclude three representative LLMs (i.e., text-davinci-003, ChatGPT and BARD)and evaluate them on all selected datasets under zero-shot, one-shot andthree-shot settings. Secondly, different from previous evaluations relying onlyon simple metrics (e.g., accuracy), we propose fine-level evaluations fromobjective and subjective manners, covering both answers and explanations. Also,to uncover the logical flaws of LLMs, bad cases will be attributed to fiveerror types from two dimensions. Thirdly, to avoid the influences of knowledgebias and purely focus on benchmarking the logical reasoning capability of LLMs,we propose a new dataset with neutral content. It contains 3K samples andcovers deductive, inductive and abductive reasoning settings. Based on thein-depth evaluations, this paper finally concludes the ability maps of logicalreasoning capability from six dimensions (i.e., correct, rigorous, self-aware,active, oriented and no hallucination). It reflects the pros and cons of LLMsand gives guiding directions for future works.</description><author>Fangzhi Xu, Qika Lin, Jiawei Han, Tianzhe Zhao, Jun Liu, Erik Cambria</author><pubDate>Fri, 16 Jun 2023 14:39:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09841v1</guid></item><item><title>Super-Resolution Radar Imaging with Sparse Arrays Using a Deep Neural Network Trained with Enhanced Virtual Data</title><link>http://arxiv.org/abs/2306.09839v1</link><description>This paper introduces a method based on a deep neural network (DNN) that isperfectly capable of processing radar data from extremely thinned radarapertures. The proposed DNN processing can provide both aliasing-free radarimaging and super-resolution. The results are validated by measuring thedetection performance on realistic simulation data and by evaluating thePoint-Spread-function (PSF) and the target-separation performance on measuredpoint-like targets. Also, a qualitative evaluation of a typical automotivescene is conducted. It is shown that this approach can outperformstate-of-the-art subspace algorithms and also other existing machine learningsolutions. The presented results suggest that machine learning approachestrained with sufficiently sophisticated virtual input data are a very promisingalternative to compressed sensing and subspace approaches in radar signalprocessing. The key to this performance is that the DNN is trained usingrealistic simulation data that perfectly mimic a given sparse antenna radararray hardware as the input. As ground truth, ultra-high resolution data froman enhanced virtual radar are simulated. Contrary to other work, the DNNutilizes the complete radar cube and not only the antenna channel informationat certain range-Doppler detections. After training, the proposed DNN iscapable of sidelobe- and ambiguity-free imaging. It simultaneously deliversnearly the same resolution and image quality as would be achieved with a fullyoccupied array.</description><author>Christian Schuessler, Marcel Hoffmann, Martin Vossiek</author><pubDate>Fri, 16 Jun 2023 14:37:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09839v1</guid></item><item><title>Cognitive Accident Prediction in Driving Scenes: A Multimodality Benchmark</title><link>http://arxiv.org/abs/2212.09381v2</link><description>Traffic accident prediction in driving videos aims to provide an earlywarning of the accident occurrence, and supports the decision making of safedriving systems. Previous works usually concentrate on the spatial-temporalcorrelation of object-level context, while they do not fit the inherentlong-tailed data distribution well and are vulnerable to severe environmentalchange. In this work, we propose a Cognitive Accident Prediction (CAP) methodthat explicitly leverages human-inspired cognition of text description on thevisual observation and the driver attention to facilitate model training. Inparticular, the text description provides a dense semantic description guidancefor the primary context of the traffic scene, while the driver attentionprovides a traction to focus on the critical region closely correlating withsafe driving. CAP is formulated by an attentive text-to-vision shift fusionmodule, an attentive scene context transfer module, and the driver attentionguided accident prediction module. We leverage the attention mechanism in thesemodules to explore the core semantic cues for accident prediction. In order totrain CAP, we extend an existing self-collected DADA-2000 dataset (withannotated driver attention for each frame) with further factual textdescriptions for the visual observations before the accidents. Besides, weconstruct a new large-scale benchmark consisting of 11,727 in-the-wild accidentvideos with over 2.19 million frames (named as CAP-DATA) together with labeledfact-effect-reason-introspection description and temporal accident frame label.Based on extensive experiments, the superiority of CAP is validated comparedwith state-of-the-art approaches. The code, CAP-DATA, and all results will bereleased in \url{https://github.com/JWFanggit/LOTVS-CAP}.</description><author>Jianwu Fang, Lei-Lei Li, Kuan Yang, Zhedong Zheng, Jianru Xue, Tat-Seng Chua</author><pubDate>Fri, 16 Jun 2023 14:29:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.09381v2</guid></item><item><title>Subset Selection Based On Multiple Rankings in the Presence of Bias: Effectiveness of Fairness Constraints for Multiwinner Voting Score Functions</title><link>http://arxiv.org/abs/2306.09835v1</link><description>We consider the problem of subset selection where one is given multiplerankings of items and the goal is to select the highest ``quality'' subset.Score functions from the multiwinner voting literature have been used toaggregate rankings into quality scores for subsets. We study this setting ofsubset selection problems when, in addition, rankings may contain systemic orunconscious biases toward a group of items. For a general model of inputrankings and biases, we show that requiring the selected subset to satisfygroup fairness constraints can improve the quality of the selection withrespect to unbiased rankings. Importantly, we show that for fairnessconstraints to be effective, different multiwinner score functions may requirea drastically different number of rankings: While for some functions, fairnessconstraints need an exponential number of rankings to recover aclose-to-optimal solution, for others, this dependency is only polynomial. Thisresult relies on a novel notion of ``smoothness'' of submodular functions inthis setting that quantifies how well a function can ``correctly'' assess thequality of items in the presence of bias. The results in this paper can be usedto guide the choice of multiwinner score functions for the subset selectionsetting considered here; we additionally provide a tool to empirically enablethis.</description><author>Niclas Boehmer, L. Elisa Celis, Lingxiao Huang, Anay Mehrotra, Nisheeth K. Vishnoi</author><pubDate>Fri, 16 Jun 2023 14:25:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09835v1</guid></item><item><title>TransFool: An Adversarial Attack against Neural Machine Translation Models</title><link>http://arxiv.org/abs/2302.00944v2</link><description>Deep neural networks have been shown to be vulnerable to small perturbationsof their inputs, known as adversarial attacks. In this paper, we investigatethe vulnerability of Neural Machine Translation (NMT) models to adversarialattacks and propose a new attack algorithm called TransFool. To fool NMTmodels, TransFool builds on a multi-term optimization problem and a gradientprojection step. By integrating the embedding representation of a languagemodel, we generate fluent adversarial examples in the source language thatmaintain a high level of semantic similarity with the clean samples.Experimental results demonstrate that, for different translation tasks and NMTarchitectures, our white-box attack can severely degrade the translationquality while the semantic similarity between the original and the adversarialsentences stays high. Moreover, we show that TransFool is transferable tounknown target models. Finally, based on automatic and human evaluations,TransFool leads to improvement in terms of success rate, semantic similarity,and fluency compared to the existing attacks both in white-box and black-boxsettings. Thus, TransFool permits us to better characterize the vulnerabilityof NMT models and outlines the necessity to design strong defense mechanismsand more robust NMT systems for real-life applications.</description><author>Sahar Sadrizadeh, Ljiljana Dolamic, Pascal Frossard</author><pubDate>Fri, 16 Jun 2023 14:24:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00944v2</guid></item><item><title>Sheffield's Submission to the AmericasNLP Shared Task on Machine Translation into Indigenous Languages</title><link>http://arxiv.org/abs/2306.09830v1</link><description>In this paper we describe the University of Sheffield's submission to theAmericasNLP 2023 Shared Task on Machine Translation into Indigenous Languageswhich comprises the translation from Spanish to eleven indigenous languages.Our approach consists of extending, training, and ensembling differentvariations of NLLB-200. We use data provided by the organizers and data fromvarious other sources such as constitutions, handbooks, news articles, andbacktranslations generated from monolingual data. On the dev set, our bestsubmission outperforms the baseline by 11% average chrF across all languages,with substantial improvements particularly for Aymara, Guarani and Quechua. Onthe test set, we achieve the highest average chrF of all the submissions, werank first in four of the eleven languages, and at least one of our submissionsranks in the top 3 for all languages.</description><author>Edward Gow-Smith, Danae Sánchez Villegas</author><pubDate>Fri, 16 Jun 2023 14:15:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09830v1</guid></item></channel></rss>