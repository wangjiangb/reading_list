<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 30 Jan 2025 13:00:16 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Dialogue is Better Than Monologue: Instructing Medical LLMs via Strategical Conversations</title><link>http://arxiv.org/abs/2501.17860v1</link><description>Current medical AI systems often fail to replicate real-world clinicalreasoning, as they are predominantly trained and evaluated on static text andquestion-answer tasks. These tuning methods and benchmarks overlook criticalaspects like evidence-based reasoning and handling distracting information. Tobridge this gap, we introduce a novel benchmark that simulates real-worlddiagnostic scenarios, integrating noise and difficulty levels aligned withUSMLE standards. Moreover, we explore dialogue-based fine-tuning, whichtransforms static datasets into conversational formats to better captureiterative reasoning processes. Experiments show that dialogue-tuned modelsoutperform traditional methods, with improvements of $9.64\%$ in multi-roundreasoning scenarios and $6.18\%$ in accuracy in a noisy environment. Ourfindings highlight dialogue tuning as a promising approach for advancingclinically aligned and robust medical AI systems.</description><author>Zijie Liu, Xinyu Zhao, Jie Peng, Zhuangdi Zhu, Qingyu Chen, Xia Hu, Tianlong Chen</author><pubDate>Wed, 29 Jan 2025 18:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17860v1</guid></item><item><title>rEGGression: an Interactive and Agnostic Tool for the Exploration of Symbolic Regression Models</title><link>http://arxiv.org/abs/2501.17859v1</link><description>Regression analysis is used for prediction and to understand the effect ofindependent variables on dependent variables. Symbolic regression (SR)automates the search for non-linear regression models, delivering a set ofhypotheses that balances accuracy with the possibility to understand thephenomena. Many SR implementations return a Pareto front allowing the choice ofthe best trade-off. However, this hides alternatives that are close tonon-domination, limiting these choices. Equality graphs (e-graphs) allow torepresent large sets of expressions compactly by efficiently handlingduplicated parts occurring in multiple expressions. E-graphs allow to store andquery all SR solution candidates visited in one or multiple GP runs efficientlyand open the possibility to analyse much larger sets of SR solution candidates.We introduce rEGGression, a tool using e-graphs to enable the exploration of alarge set of symbolic expressions which provides querying, filtering, andpattern matching features creating an interactive experience to gain insightsabout SR models. The main highlight is its focus in the exploration of thebuilding blocks found during the search that can help the experts to findinsights about the studied phenomena.This is possible by exploiting the patternmatching capability of the e-graph data structure.</description><author>Fabricio Olivetti de Franca, Gabriel Kronberger</author><pubDate>Wed, 29 Jan 2025 18:57:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17859v1</guid></item><item><title>Improving Your Model Ranking on Chatbot Arena by Vote Rigging</title><link>http://arxiv.org/abs/2501.17858v1</link><description>Chatbot Arena is a popular platform for evaluating LLMs by pairwise battles,where users vote for their preferred response from two randomly sampledanonymous models. While Chatbot Arena is widely regarded as a reliable LLMranking leaderboard, we show that crowdsourced voting can be rigged to improve(or decrease) the ranking of a target model $m_{t}$. We first introduce astraightforward target-only rigging strategy that focuses on new battlesinvolving $m_{t}$, identifying it via watermarking or a binary classifier, andexclusively voting for $m_{t}$ wins. However, this strategy is practicallyinefficient because there are over $190$ models on Chatbot Arena and on averageonly about $1\%$ of new battles will involve $m_{t}$. To overcome this, wepropose omnipresent rigging strategies, exploiting the Elo rating mechanism ofChatbot Arena that any new vote on a battle can influence the ranking of thetarget model $m_{t}$, even if $m_{t}$ is not directly involved in the battle.We conduct experiments on around $1.7$ million historical votes from theChatbot Arena Notebook, showing that omnipresent rigging strategies can improvemodel rankings by rigging only hundreds of new votes. While we have evaluatedseveral defense mechanisms, our findings highlight the importance of continuedefforts to prevent vote rigging. Our code is available athttps://github.com/sail-sg/Rigging-ChatbotArena.</description><author>Rui Min, Tianyu Pang, Chao Du, Qian Liu, Minhao Cheng, Min Lin</author><pubDate>Wed, 29 Jan 2025 18:57:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17858v1</guid></item><item><title>Coarse-to-fine Q-Network with Action Sequence for Data-Efficient Robot Learning</title><link>http://arxiv.org/abs/2411.12155v2</link><description>In reinforcement learning (RL), we train a value function to understand thelong-term consequence of executing a single action. However, the value oftaking each action can be ambiguous in robotics as robot movements aretypically the aggregate result of executing multiple small actions. Moreover,robotic training data often consists of noisy trajectories, in which eachaction is noisy but executing a series of actions results in a meaningful robotmovement. This further makes it difficult for the value function to understandthe effect of individual actions. To address this, we introduce Coarse-to-fineQ-Network with Action Sequence (CQN-AS), a novel value-based RL algorithm thatlearns a critic network that outputs Q-values over a sequence of actions, i.e.,explicitly training the value function to learn the consequence of executingaction sequences. We study our algorithm on 53 robotic tasks with sparse anddense rewards, as well as with and without demonstrations, from BiGym,HumanoidBench, and RLBench. We find that CQN-AS outperforms various baselines,in particular on humanoid control tasks.</description><author>Younggyo Seo, Pieter Abbeel</author><pubDate>Wed, 29 Jan 2025 18:56:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12155v2</guid></item><item><title>GRACE: Generalizing Robot-Assisted Caregiving with User Functionality Embeddings</title><link>http://arxiv.org/abs/2501.17855v1</link><description>Robot caregiving should be personalized to meet the diverse needs of carerecipients -- assisting with tasks as needed, while taking user agency inaction into account. In physical tasks such as handover, bathing, dressing, andrehabilitation, a key aspect of this diversity is the functional range ofmotion (fROM), which can vary significantly between individuals. In this work,we learn to predict personalized fROM as a way to generalize robotdecision-making in a wide range of caregiving tasks. We propose a noveldata-driven method for predicting personalized fROM using functional assessmentscores from occupational therapy. We develop a neural model that learns toembed functional assessment scores into a latent representation of the user'sphysical function. The model is trained using motion capture data collectedfrom users with emulated mobility limitations. After training, the modelpredicts personalized fROM for new users without motion capture. Throughsimulated experiments and a real-robot user study, we show that thepersonalized fROM predictions from our model enable the robot to providepersonalized and effective assistance while improving the user's agency inaction. See our website for more visualizations:https://emprise.cs.cornell.edu/grace/.</description><author>Ziang Liu, Yuanchen Ju, Yu Da, Tom Silver, Pranav N. Thakkar, Jenna Li, Justin Guo, Katherine Dimitropoulou, Tapomayukh Bhattacharjee</author><pubDate>Wed, 29 Jan 2025 18:55:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17855v1</guid></item><item><title>AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders</title><link>http://arxiv.org/abs/2501.17148v2</link><description>Fine-grained steering of language model outputs is essential for safety andreliability. Prompting and finetuning are widely used to achieve these goals,but interpretability researchers have proposed a variety ofrepresentation-based techniques as well, including sparse autoencoders (SAEs),linear artificial tomography, supervised steering vectors, linear probes, andrepresentation finetuning. At present, there is no benchmark for making directcomparisons between these proposals. Therefore, we introduce AxBench, alarge-scale benchmark for steering and concept detection, and reportexperiments on Gemma-2-2B and 9B. For steering, we find that promptingoutperforms all existing methods, followed by finetuning. For conceptdetection, representation-based methods such as difference-in-means, performthe best. On both evaluations, SAEs are not competitive. We introduce a novelweakly-supervised representational method (Rank-1 Representation Finetuning;ReFT-r1), which is competitive on both tasks while providing theinterpretability advantages that prompting lacks. Along with AxBench, we trainand publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.</description><author>Zhengxuan Wu, Aryaman Arora, Atticus Geiger, Zheng Wang, Jing Huang, Dan Jurafsky, Christopher D. Manning, Christopher Potts</author><pubDate>Wed, 29 Jan 2025 18:52:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17148v2</guid></item><item><title>Improving Genetic Programming for Symbolic Regression with Equality Graphs</title><link>http://arxiv.org/abs/2501.17848v1</link><description>The search for symbolic regression models with genetic programming (GP) has atendency of revisiting expressions in their original or equivalent forms.Repeatedly evaluating equivalent expressions is inefficient, as it does notimmediately lead to better solutions. However, evolutionary algorithms requirediversity and should allow the accumulation of inactive building blocks thatcan play an important role at a later point. The equality graph is a datastructure capable of compactly storing expressions and their equivalent formsallowing an efficient verification of whether an expression has been visited inany of their stored equivalent forms. We exploit the e-graph to adapt thesubtree operators to reduce the chances of revisiting expressions. Ouradaptation, called eggp, stores every visited expression in the e-graph,allowing us to filter out from the available selection of subtrees all thecombinations that would create already visited expressions. Results show that,for small expressions, this approach improves the performance of a simple GPalgorithm to compete with PySR and Operon without increasing computationalcost. As a highlight, eggp was capable of reliably delivering short and at thesame time accurate models for a selected set of benchmarks from SRBench and aset of real-world datasets.</description><author>Fabricio Olivetti de Franca, Gabriel Kronberger</author><pubDate>Wed, 29 Jan 2025 18:49:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17848v1</guid></item><item><title>ATTNChecker: Highly-Optimized Fault Tolerant Attention for Large Language Model Training</title><link>http://arxiv.org/abs/2410.11720v3</link><description>Large Language Models (LLMs) have demonstrated remarkable performance invarious natural language processing tasks. However, the training of thesemodels is computationally intensive and susceptible to faults, particularly inthe attention mechanism, which is a critical component of transformer-basedLLMs. In this paper, we investigate the impact of faults on LLM training,focusing on INF, NaN, and near-INF values in the computation results withsystematic fault injection experiments. We observe the propagation patterns ofthese errors, which can trigger non-trainable states in the model and disrupttraining, forcing the procedure to load from checkpoints. To mitigate theimpact of these faults, we propose ATTNChecker, the first Algorithm-Based FaultTolerance (ABFT) technique tailored for the attention mechanism in LLMs.ATTNChecker is designed based on fault propagation patterns of LLM andincorporates performance optimization to adapt to both system reliability andmodel vulnerability while providing lightweight protection for fast LLMtraining. Evaluations on four LLMs show that ATTNChecker incurs on average 7%overhead on training while detecting and correcting all extreme errors.Compared with the state-of-the-art checkpoint/restore approach, ATTNCheckerreduces recovery overhead by up to 49x.</description><author>Yuhang Liang, Xinyi Li, Jie Ren, Ang Li, Bo Fang, Jieyang Chen</author><pubDate>Wed, 29 Jan 2025 18:49:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11720v3</guid></item><item><title>Large Language Models and Code Security: A Systematic Literature Review</title><link>http://arxiv.org/abs/2412.15004v2</link><description>Large Language Models (LLMs) have emerged as powerful tools for automatingvarious programming tasks, including security-related ones, such as detectingand fixing vulnerabilities. Despite their promising capabilities, when requiredto produce or modify pre-existing code, LLMs could introduce vulnerabilitiesunbeknown to the programmer. When analyzing code, they could miss clearvulnerabilities or signal nonexistent ones. In this Systematic LiteratureReview (SLR), we aim to investigate both the security benefits and potentialdrawbacks of using LLMs for a variety of code-related tasks. In particular,first we focus on the types of vulnerabilities that could be introduced byLLMs, when used for producing code. Second, we analyze the capabilities of LLMsto detect and fix vulnerabilities, in any given code, and how the promptingstrategy of choice impacts their performance in these two tasks. Last, weprovide an in-depth analysis on how data poisoning attacks on LLMs can impactperformance in the aforementioned tasks.</description><author>Enna Basic, Alberto Giaretta</author><pubDate>Wed, 29 Jan 2025 18:49:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.15004v2</guid></item><item><title>Tulu 3: Pushing Frontiers in Open Language Model Post-Training</title><link>http://arxiv.org/abs/2411.15124v3</link><description>Language model post-training is applied to refine behaviors and unlock newskills across a wide range of recent language models, but open recipes forapplying these techniques lag behind proprietary ones. The underlying trainingdata and recipes for post-training are simultaneously the most important piecesof the puzzle and the portion with the least transparency. To bridge this gap,we introduce Tulu 3, a family of fully-open state-of-the-art post-trainedmodels, alongside its data, code, and training recipes, serving as acomprehensive guide for modern post-training techniques. Tulu 3, which buildson Llama 3.1 base models, achieves results surpassing the instruct versions ofLlama 3.1, Qwen 2.5, Mistral, and even closed models such as GPT-4o-mini andClaude 3.5-Haiku. The training algorithms for our models include supervisedfinetuning (SFT), Direct Preference Optimization (DPO), and a novel method wecall Reinforcement Learning with Verifiable Rewards (RLVR). With Tulu 3, weintroduce a multi-task evaluation scheme for post-training recipes withdevelopment and unseen evaluations, standard benchmark implementations, andsubstantial decontamination of existing open datasets on said benchmarks. Weconclude with analysis and discussion of training methods that did not reliablyimprove performance. In addition to the Tulu 3 model weights and demo, we release the completerecipe -- including datasets for diverse core skills, a robust toolkit for datacuration and evaluation, the training code and infrastructure, and, mostimportantly, a detailed report for reproducing and further adapting the Tulu 3approach to more domains.</description><author>Nathan Lambert, Jacob Morrison, Valentina Pyatkin, Shengyi Huang, Hamish Ivison, Faeze Brahman, Lester James V. Miranda, Alisa Liu, Nouha Dziri, Shane Lyu, Yuling Gu, Saumya Malik, Victoria Graf, Jena D. Hwang, Jiangjiang Yang, Ronan Le Bras, Oyvind Tafjord, Chris Wilhelm, Luca Soldaini, Noah A. Smith, Yizhong Wang, Pradeep Dasigi, Hannaneh Hajishirzi</author><pubDate>Wed, 29 Jan 2025 18:46:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.15124v3</guid></item><item><title>From Sparse to Dense: Toddler-inspired Reward Transition in Goal-Oriented Reinforcement Learning</title><link>http://arxiv.org/abs/2501.17842v1</link><description>Reinforcement learning (RL) agents often face challenges in balancingexploration and exploitation, particularly in environments where sparse ordense rewards bias learning. Biological systems, such as human toddlers,naturally navigate this balance by transitioning from free exploration withsparse rewards to goal-directed behavior guided by increasingly dense rewards.Inspired by this natural progression, we investigate the Toddler-InspiredReward Transition in goal-oriented RL tasks. Our study focuses on transitioningfrom sparse to potential-based dense (S2D) rewards while preserving optimalstrategies. Through experiments on dynamic robotic arm manipulation andegocentric 3D navigation tasks, we demonstrate that effective S2D rewardtransitions significantly enhance learning performance and sample efficiency.Additionally, using a Cross-Density Visualizer, we show that S2D transitionssmooth the policy loss landscape, resulting in wider minima that improvegeneralization in RL models. In addition, we reinterpret Tolman's mazeexperiments, underscoring the critical role of early free exploratory learningin the context of S2D rewards.</description><author>Junseok Park, Hyeonseo Yang, Min Whoo Lee, Won-Seok Choi, Minsu Lee, Byoung-Tak Zhang</author><pubDate>Wed, 29 Jan 2025 18:46:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17842v1</guid></item><item><title>acoupi: An Open-Source Python Framework for Deploying Bioacoustic AI Models on Edge Devices</title><link>http://arxiv.org/abs/2501.17841v1</link><description>1. Passive acoustic monitoring (PAM) coupled with artificial intelligence(AI) is becoming an essential tool for biodiversity monitoring. Traditional PAMsystems require manual data offloading and impose substantial demands onstorage and computing infrastructure. The combination of on-device AI-basedprocessing and network connectivity enables local data analysis andtransmission of only relevant information, greatly reducing storage needs.However, programming these devices for robust operation is challenging,requiring expertise in embedded systems and software engineering. Despite theincrease in AI-based models for bioacoustics, their full potential remainsunrealized without accessible tools to deploy them on custom hardware andtailor device behaviour to specific monitoring goals. 2. To address thischallenge, we develop acoupi, an open-source Python framework that simplifiesthe creation and deployment of smart bioacoustic devices. acoupi integratesaudio recording, AI-based data processing, data management, and real-timewireless messaging into a unified and configurable framework. By modularisingkey elements of the bioacoustic monitoring workflow, acoupi allows users toeasily customise, extend, or select specific components to fit their uniquemonitoring needs. 3. We demonstrate the flexibility of acoupi by integratingtwo bioacoustic classifiers: BirdNET, for the classification of bird species,and BatDetect2, for the classification of UK bat species. We test thereliability of acoupi over a month-long deployment of two acoupi-powereddevices in a UK urban park. 4. acoupi can be deployed on low-cost hardware suchas the Raspberry Pi and can be customised for various applications. acoupistandardised framework and simplified tools facilitate the adoption ofAI-powered PAM systems for researchers and conservationists. acoupi is onGitHub at https://github.com/acoupi/acoupi.</description><author>Aude Vuilliomenet, Santiago Martínez Balvanera, Oisin Mac Aodha, Kate E. Jones, Duncan Wilson</author><pubDate>Wed, 29 Jan 2025 18:44:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17841v1</guid></item><item><title>Learning Beyond the Surface: How Far Can Continual Pre-Training with LoRA Enhance LLMs' Domain-Specific Insight Learning?</title><link>http://arxiv.org/abs/2501.17840v1</link><description>Large Language Models (LLMs) have demonstrated remarkable performance onvarious tasks, yet their ability to extract and internalize deeper insightsfrom domain-specific datasets remains underexplored. In this study, weinvestigate how continual pre-training can enhance LLMs' capacity for insightlearning across three distinct forms: declarative, statistical, andprobabilistic insights. Focusing on two critical domains: medicine and finance,we employ LoRA to train LLMs on two existing datasets. To evaluate each insighttype, we create benchmarks to measure how well continual pre-training helpsmodels go beyond surface-level knowledge. We also assess the impact of documentmodification on capturing insights. The results show that, while continualpre-training on original documents has a marginal effect, modifying documentsto retain only essential information significantly enhances theinsight-learning capabilities of LLMs.</description><author>Pouya Pezeshkpour, Estevam Hruschka</author><pubDate>Wed, 29 Jan 2025 18:40:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17840v1</guid></item><item><title>Matrix Product Sketching via Coordinated Sampling</title><link>http://arxiv.org/abs/2501.17836v1</link><description>We revisit the well-studied problem of approximating a matrix product,$\mathbf{A}^T\mathbf{B}$, based on small space sketches$\mathcal{S}(\mathbf{A})$ and $\mathcal{S}(\mathbf{B})$ of $\mathbf{A} \in\R^{n \times d}$ and $\mathbf{B}\in \R^{n \times m}$. We are interested in thesetting where the sketches must be computed independently of each other, exceptfor the use of a shared random seed. We prove that, when $\mathbf{A}$ and$\mathbf{B}$ are sparse, methods based on \emph{coordinated random sampling}can outperform classical linear sketching approaches, likeJohnson-Lindenstrauss Projection or CountSketch. For example, to obtainFrobenius norm error $\epsilon\|\mathbf{A}\|_F\|\mathbf{B}\|_F$, coordinatedsampling requires sketches of size $O(s/\epsilon^2)$ when $\mathbf{A}$ and$\mathbf{B}$ have at most $s \leq d,m$ non-zeros per row. In contrast, linearsketching leads to sketches of size $O(d/\epsilon^2)$ and $O(m/\epsilon^2)$ for$\mathbf{A}$ and $\mathbf{B}$. We empirically evaluate our approach on twoapplications: 1) distributed linear regression in databases, a problemmotivated by tasks like dataset discovery and augmentation, and 2)approximating attention matrices in transformer-based language models. In bothcases, our sampling algorithms yield an order of magnitude improvement overlinear sketching.</description><author>Majid Daliri, Juliana Freire, Danrong Li, Christopher Musco</author><pubDate>Wed, 29 Jan 2025 18:35:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17836v1</guid></item><item><title>Hierarchical Fallback Architecture for High Risk Online Machine Learning Inference</title><link>http://arxiv.org/abs/2501.17834v1</link><description>Open Banking powered machine learning applications require novel robustnessapproaches to deal with challenging stress and failure scenarios. In this paperwe propose an hierarchical fallback architecture for improving robustness inhigh risk machine learning applications with a focus in the financial domain.We define generic failure scenarios often found in online inference that dependon external data providers and we describe in detail how to apply thehierarchical fallback architecture to address them. Finally, we offer a realworld example of its applicability in the industry for near-real timetransactional fraud risk evaluation using Open Banking data and under extremestress scenarios.</description><author>Gustavo Polleti, Marlesson Santana, Felipe Sassi Del Sant, Eduardo Fontes</author><pubDate>Wed, 29 Jan 2025 18:30:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17834v1</guid></item><item><title>Generated Data with Fake Privacy: Hidden Dangers of Fine-tuning Large Language Models on Generated Data</title><link>http://arxiv.org/abs/2409.11423v2</link><description>Large language models (LLMs) have demonstrated significant success in variousdomain-specific tasks, with their performance often improving substantiallyafter fine-tuning. However, fine-tuning with real-world data introduces privacyrisks. To mitigate these risks, developers increasingly rely on synthetic datageneration as an alternative to using real data, as data generated bytraditional models is believed to be different from real-world data. However,with the advanced capabilities of LLMs, the distinction between real data anddata generated by these models has become nearly indistinguishable. Thisconvergence introduces similar privacy risks for generated data to thoseassociated with real data. Our study investigates whether fine-tuning withLLM-generated data truly enhances privacy or introduces additional privacyrisks by examining the structural characteristics of data generated by LLMs,focusing on two primary fine-tuning approaches: supervised fine-tuning (SFT)with unstructured (plain-text) generated data and self-instruct tuning. In thescenario of SFT, the data is put into a particular instruction tuning formatused by previous studies. We use Personal Information Identifier (PII) leakageand Membership Inference Attacks (MIAs) on the Pythia Model Suite and OpenPre-trained Transformer (OPT) to measure privacy risks. Notably, afterfine-tuning with unstructured generated data, the rate of successful PIIextractions for Pythia increased by over 20%, highlighting the potentialprivacy implications of such approaches. Furthermore, the ROC-AUC score of MIAsfor Pythia-6.9b, the second biggest model of the suite, increases over 40%after self-instruct tuning. Our results indicate the potential privacy risksassociated with fine-tuning LLMs using generated data, underscoring the needfor careful consideration of privacy safeguards in such approaches.</description><author>Atilla Akkus, Masoud Poorghaffar Aghdam, Mingjie Li, Junjie Chu, Michael Backes, Yang Zhang, Sinem Sav</author><pubDate>Wed, 29 Jan 2025 18:27:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.11423v2</guid></item><item><title>A Comprehensive Survey on Legal Summarization: Challenges and Future Directions</title><link>http://arxiv.org/abs/2501.17830v1</link><description>This article provides a systematic up-to-date survey of automaticsummarization techniques, datasets, models, and evaluation methods in the legaldomain. Through specific source selection criteria, we thoroughly review over120 papers spanning the modern `transformer' era of natural language processing(NLP), thus filling a gap in existing systematic surveys on the matter. Wepresent existing research along several axes and discuss trends, challenges,and opportunities for future research.</description><author>Mousumi Akter, Erion Cano, Erik Weber, Dennis Dobler, Ivan Habernal</author><pubDate>Wed, 29 Jan 2025 18:22:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17830v1</guid></item><item><title>Langevin Soft Actor-Critic: Efficient Exploration through Uncertainty-Driven Critic Learning</title><link>http://arxiv.org/abs/2501.17827v1</link><description>Existing actor-critic algorithms, which are popular for continuous controlreinforcement learning (RL) tasks, suffer from poor sample efficiency due tolack of principled exploration mechanism within them. Motivated by the successof Thompson sampling for efficient exploration in RL, we propose a novelmodel-free RL algorithm, Langevin Soft Actor Critic (LSAC), which prioritizesenhancing critic learning through uncertainty estimation over policyoptimization. LSAC employs three key innovations: approximate Thompson samplingthrough distributional Langevin Monte Carlo (LMC) based $Q$ updates, paralleltempering for exploring multiple modes of the posterior of the $Q$ function,and diffusion synthesized state-action samples regularized with $Q$ actiongradients. Our extensive experiments demonstrate that LSAC outperforms ormatches the performance of mainstream model-free RL algorithms for continuouscontrol tasks. Notably, LSAC marks the first successful application of an LMCbased Thompson sampling in continuous control tasks with continuous actionspaces.</description><author>Haque Ishfaq, Guangyuan Wang, Sami Nur Islam, Doina Precup</author><pubDate>Wed, 29 Jan 2025 18:18:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17827v1</guid></item><item><title>The 2020 United States Decennial Census Is More Private Than You (Might) Think</title><link>http://arxiv.org/abs/2410.09296v2</link><description>The U.S. Decennial Census serves as the foundation for many high-profilepolicy decision-making processes, including federal funding allocation andredistricting. In 2020, the Census Bureau adopted differential privacy toprotect the confidentiality of individual responses through a disclosureavoidance system that injects noise into census data tabulations. The Bureausubsequently posed an open question: Could stronger privacy guarantees beobtained for the 2020 U.S. Census compared to their published guarantees, orequivalently, had the privacy budgets been fully utilized? In this paper, we address this question affirmatively by demonstrating thatthe 2020 U.S. Census provides significantly stronger privacy protections thanits nominal guarantees suggest at each of the eight geographical levels, fromthe national level down to the block level. This finding is enabled by ourprecise tracking of privacy losses using $f$-differential privacy, applied tothe composition of private queries across these geographical levels. Ouranalysis reveals that the Census Bureau introduced unnecessarily high levels ofnoise to meet the specified privacy guarantees for the 2020 Census.Consequently, we show that noise variances could be reduced by $15.08\%$ to$24.82\%$ while maintaining nearly the same level of privacy protection foreach geographical level, thereby improving the accuracy of privatized censusstatistics. We empirically demonstrate that reducing noise injection intocensus statistics mitigates distortion caused by privacy constraints indownstream applications of private census data, illustrated through a studyexamining the relationship between earnings and education.</description><author>Buxin Su, Weijie J. Su, Chendi Wang</author><pubDate>Wed, 29 Jan 2025 18:17:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09296v2</guid></item><item><title>U2A: Unified Unimodal Adaptation for Robust and Efficient Multimodal Learning</title><link>http://arxiv.org/abs/2501.17823v1</link><description>Multimodal learning often relies on designing new models and complex trainingstrategies to achieve optimal performance. We present Unified UnimodalAdaptation (U2A), which jointly fine-tunes pretrained unimodal encoders usinglow-rank adaptation (LoRA) for various multimodal tasks. Our methodsignificantly reduces the number of learnable parameters and eliminates theneed for complex training strategies, such as alternating training, gradientmodifications, or unimodal fine-tuning. To address missing modalities duringboth training and testing, we introduce Mask Tokens (MT), which generatemissing modality features from available modalities using a single token permodality. This simplifies the process, removing the need for specializedfeature estimation or prompt-tuning methods. Our evaluation demonstrates thatU2A matches or outperforms state-of-the-art methods in both complete andmissing modality settings, showcasing strong performance and robustness acrossvarious modalities, tasks, and datasets. We also analyze and report theeffectiveness of Mask Tokens in different missing modality scenarios. Overall,our method provides a robust, flexible, and efficient solution for multimodallearning, with minimal computational overhead.</description><author>Md Kaykobad Reza, Niki Nezakati, Ameya Patil, Mashhour Solh, M. Salman Asif</author><pubDate>Wed, 29 Jan 2025 18:15:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17823v1</guid></item><item><title>Aggregation Schemes for Single-Vector WSI Representation Learning in Digital Pathology</title><link>http://arxiv.org/abs/2501.17822v1</link><description>A crucial step to efficiently integrate Whole Slide Images (WSIs) incomputational pathology is assigning a single high-quality feature vector,i.e., one embedding, to each WSI. With the existence of many pre-trained deepneural networks and the emergence of foundation models, extracting embeddingsfor sub-images (i.e., tiles or patches) is straightforward. However, for WSIs,given their high resolution and gigapixel nature, inputting them into existingGPUs as a single image is not feasible. As a result, WSIs are usually splitinto many patches. Feeding each patch to a pre-trained model, each WSI can thenbe represented by a set of patches, hence, a set of embeddings. Hence, in sucha setup, WSI representation learning reduces to set representation learningwhere for each WSI we have access to a set of patch embeddings. To obtain asingle embedding from a set of patch embeddings for each WSI, multipleset-based learning schemes have been proposed in the literature. In this paper,we evaluate the WSI search performance of multiple recently developedaggregation techniques (mainly set representation learning techniques)including simple average or max pooling operations, Deep Sets, Memory networks,Focal attention, Gaussian Mixture Model (GMM) Fisher Vector, and deep sparseand binary Fisher Vector on four different primary sites including bladder,breast, kidney, and Colon from TCGA. Further, we benchmark the searchperformance of these methods against the median of minimum distances of patchembeddings, a non-aggregating approach used for WSI retrieval.</description><author>Sobhan Hemati, Ghazal Alabtah, Saghir Alfasly, H. R. Tizhoosh</author><pubDate>Wed, 29 Jan 2025 18:14:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17822v1</guid></item><item><title>SSF: Sparse Long-Range Scene Flow for Autonomous Driving</title><link>http://arxiv.org/abs/2501.17821v1</link><description>Scene flow enables an understanding of the motion characteristics of theenvironment in the 3D world. It gains particular significance in thelong-range, where object-based perception methods might fail due to sparseobservations far away. Although significant advancements have been made inscene flow pipelines to handle large-scale point clouds, a gap remains inscalability with respect to long-range. We attribute this limitation to thecommon design choice of using dense feature grids, which scale quadraticallywith range. In this paper, we propose Sparse Scene Flow (SSF), a generalpipeline for long-range scene flow, adopting a sparse convolution basedbackbone for feature extraction. This approach introduces a new challenge: amismatch in size and ordering of sparse feature maps between time-sequentialpoint scans. To address this, we propose a sparse feature fusion scheme, thataugments the feature maps with virtual voxels at missing locations.Additionally, we propose a range-wise metric that implicitly gives greaterimportance to faraway points. Our method, SSF, achieves state-of-the-artresults on the Argoverse2 dataset, demonstrating strong performance inlong-range scene flow estimation. Our code will be released athttps://github.com/KTH-RPL/SSF.git.</description><author>Ajinkya Khoche, Qingwen Zhang, Laura Pereira Sanchez, Aron Asefaw, Sina Sharif Mansouri, Patric Jensfelt</author><pubDate>Wed, 29 Jan 2025 18:14:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17821v1</guid></item><item><title>P-TAME: Explain Any Image Classifier with Trained Perturbations</title><link>http://arxiv.org/abs/2501.17813v1</link><description>The adoption of Deep Neural Networks (DNNs) in critical fields wherepredictions need to be accompanied by justifications is hindered by theirinherent black-box nature. In this paper, we introduce P-TAME(Perturbation-based Trainable Attention Mechanism for Explanations), amodel-agnostic method for explaining DNN-based image classifiers. P-TAMEemploys an auxiliary image classifier to extract features from the input image,bypassing the need to tailor the explanation method to the internalarchitecture of the backbone classifier being explained. Unlike traditionalperturbation-based methods, which have high computational requirements, P-TAMEoffers an efficient alternative by generating high-resolution explanations in asingle forward pass during inference. We apply P-TAME to explain the decisionsof VGG-16, ResNet-50, and ViT-B-16, three distinct and widely used imageclassifiers. Quantitative and qualitative results show that our method matchesor outperforms previous explainability methods, including model-specificapproaches. Code and trained models will be released upon acceptance.</description><author>Mariano V. Ntrougkas, Vasileios Mezaris, Ioannis Patras</author><pubDate>Wed, 29 Jan 2025 18:06:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17813v1</guid></item><item><title>Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling</title><link>http://arxiv.org/abs/2501.17811v1</link><description>In this work, we introduce Janus-Pro, an advanced version of the previouswork Janus. Specifically, Janus-Pro incorporates (1) an optimized trainingstrategy, (2) expanded training data, and (3) scaling to larger model size.With these improvements, Janus-Pro achieves significant advancements in bothmultimodal understanding and text-to-image instruction-following capabilities,while also enhancing the stability of text-to-image generation. We hope thiswork will inspire further exploration in the field. Code and models arepublicly available.</description><author>Xiaokang Chen, Zhiyu Wu, Xingchao Liu, Zizheng Pan, Wen Liu, Zhenda Xie, Xingkai Yu, Chong Ruan</author><pubDate>Wed, 29 Jan 2025 18:00:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17811v1</guid></item><item><title>International AI Safety Report</title><link>http://arxiv.org/abs/2501.17805v1</link><description>The first International AI Safety Report comprehensively synthesizes thecurrent evidence on the capabilities, risks, and safety of advanced AI systems.The report was mandated by the nations attending the AI Safety Summit inBletchley, UK. Thirty nations, the UN, the OECD, and the EU each nominated arepresentative to the report's Expert Advisory Panel. A total of 100 AI expertscontributed, representing diverse perspectives and disciplines. Led by thereport's Chair, these independent experts collectively had full discretion overthe report's content.</description><author>Yoshua Bengio, Sören Mindermann, Daniel Privitera, Tamay Besiroglu, Rishi Bommasani, Stephen Casper, Yejin Choi, Philip Fox, Ben Garfinkel, Danielle Goldfarb, Hoda Heidari, Anson Ho, Sayash Kapoor, Leila Khalatbari, Shayne Longpre, Sam Manning, Vasilios Mavroudis, Mantas Mazeika, Julian Michael, Jessica Newman, Kwan Yee Ng, Chinasa T. Okolo, Deborah Raji, Girish Sastry, Elizabeth Seger, Theodora Skeadas, Tobin South, Emma Strubell, Florian Tramèr, Lucia Velasco, Nicole Wheeler, Daron Acemoglu, Olubayo Adekanmbi, David Dalrymple, Thomas G. Dietterich, Edward W. Felten, Pascale Fung, Pierre-Olivier Gourinchas, Fredrik Heintz, Geoffrey Hinton, Nick Jennings, Andreas Krause, Susan Leavy, Percy Liang, Teresa Ludermir, Vidushi Marda, Helen Margetts, John McDermid, Jane Munga, Arvind Narayanan, A</author><pubDate>Wed, 29 Jan 2025 17:47:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17805v1</guid></item><item><title>LEKA:LLM-Enhanced Knowledge Augmentation</title><link>http://arxiv.org/abs/2501.17802v1</link><description>Humans excel in analogical learning and knowledge transfer and, moreimportantly, possess a unique understanding of identifying appropriate sourcesof knowledge. From a model's perspective, this presents an interestingchallenge. If models could autonomously retrieve knowledge useful for transferor decision-making to solve problems, they would transition from passivelyacquiring to actively accessing and learning from knowledge. However, fillingmodels with knowledge is relatively straightforward -- it simply requires moretraining and accessible knowledge bases. The more complex task is teachingmodels about which knowledge can be analogized and transferred. Therefore, wedesign a knowledge augmentation method LEKA for knowledge transfer thatactively searches for suitable knowledge sources that can enrich the targetdomain's knowledge. This LEKA method extracts key information from textualinformation from the target domain, retrieves pertinent data from external datalibraries, and harmonizes retrieved data with the target domain data in featurespace and marginal probability measures. We validate the effectiveness of ourapproach through extensive experiments across various domains and demonstratesignificant improvements over traditional methods in reducing computationalcosts, automating data alignment, and optimizing transfer learning outcomes.</description><author>Xinhao Zhang, Jinghan Zhang, Fengran Mo, Dongjie Wang, Yanjie Fu, Kunpeng Liu</author><pubDate>Wed, 29 Jan 2025 17:44:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17802v1</guid></item><item><title>netFound: Foundation Model for Network Security</title><link>http://arxiv.org/abs/2310.17025v4</link><description>Developing generalizable ML-based solutions for disparate learning problemsin network security is highly desired. However, despite a rich history ofapplying ML to network security, most existing solutions lack generalizability.This lack of progress can be attributed to an overreliance on supervisedlearning techniques and the associated challenges of curating well-specifiedlabeled training data. This paper addresses a fundamental gap by introducing anovel transformer-based network foundation model, netFound. We employself-supervised learning techniques on abundant, unlabeled network telemetrydata for pre-training. This pretrained model can subsequently be fine-tuned tocreate generalizable learning artifacts for disparate learning tasks, even whenusing commonly available but challenging labeled datasets that are sparse,noisy, and skewed. To realize this goal, netFound leverages variousdomain-specific attributes and constraints unique to network data (packettraces) by developing multi-modal embeddings, protocol-aware tokenization,data-driven token composition, and hierarchical transformers. Our resultsdemonstrate that netFound's domain-specific design choices ensure that it (1)effectively captures the hidden networking context in production settings, (2)outperforms four different SOTA methods on five different learning tasks, and(3) is robust to both noisy labels and learning shortcuts -- critical fordeveloping generalizable ML models in practical settings.</description><author>Satyandra Guthula, Roman Beltiukov, Navya Battula, Wenbo Guo, Arpit Gupta, Inder Monga</author><pubDate>Wed, 29 Jan 2025 17:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17025v4</guid></item><item><title>CrowdSplat: Exploring Gaussian Splatting For Crowd Rendering</title><link>http://arxiv.org/abs/2501.17792v1</link><description>We present CrowdSplat, a novel approach that leverages 3D Gaussian Splattingfor real-time, high-quality crowd rendering. Our method utilizes 3D Gaussianfunctions to represent animated human characters in diverse poses and outfits,which are extracted from monocular videos. We integrate Level of Detail (LoD)rendering to optimize computational efficiency and quality. The CrowdSplatframework consists of two stages: (1) avatar reconstruction and (2) crowdsynthesis. The framework is also optimized for GPU memory usage to enhancescalability. Quantitative and qualitative evaluations show that CrowdSplatachieves good levels of rendering quality, memory efficiency, and computationalperformance. Through these experiments, we demonstrate that CrowdSplat is aviable solution for dynamic, realistic crowd simulation in real-timeapplications.</description><author>Xiaohan Sun, Yinghan Xu, John Dingliana, Carol O'Sullivan</author><pubDate>Wed, 29 Jan 2025 17:31:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17792v1</guid></item><item><title>BreezyVoice: Adapting TTS for Taiwanese Mandarin with Enhanced Polyphone Disambiguation -- Challenges and Insights</title><link>http://arxiv.org/abs/2501.17790v1</link><description>We present BreezyVoice, a Text-to-Speech (TTS) system specifically adaptedfor Taiwanese Mandarin, highlighting phonetic control abilities to address theunique challenges of polyphone disambiguation in the language. Building uponCosyVoice, we incorporate a $S^{3}$ tokenizer, a large language model (LLM), anoptimal-transport conditional flow matching model (OT-CFM), and a grapheme tophoneme prediction model, to generate realistic speech that closely mimicshuman utterances. Our evaluation demonstrates BreezyVoice's superiorperformance in both general and code-switching contexts, highlighting itsrobustness and effectiveness in generating high-fidelity speech. Additionally,we address the challenges of generalizability in modeling long-tail speakersand polyphone disambiguation. Our approach significantly enhances performanceand offers valuable insights into the workings of neural codec TTS systems.</description><author>Chan-Jan Hsu, Yi-Cheng Lin, Chia-Chun Lin, Wei-Chih Chen, Ho Lam Chung, Chen-An Li, Yi-Chang Chen, Chien-Yu Yu, Ming-Ji Lee, Chien-Cheng Chen, Ru-Heng Huang, Hung-yi Lee, Da-Shan Shiu</author><pubDate>Wed, 29 Jan 2025 17:31:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17790v1</guid></item><item><title>Detecting Anomalies Using Rotated Isolation Forest</title><link>http://arxiv.org/abs/2501.17787v1</link><description>The Isolation Forest (iForest), proposed by Liu, Ting, and Zhou at TKDE 2012,has become a prominent tool for unsupervised anomaly detection. However, recentresearch by Hariri, Kind, and Brunner, published in TKDE 2021, has revealedissues with iForest. They identified the presence of axis-aligned ghostclusters that can be misidentified as normal clusters, leading to biasedanomaly scores and inaccurate predictions. In response, they developed theExtended Isolation Forest (EIF), which effectively solves these issues byeliminating the ghost clusters introduced by iForest. This enhancement resultsin improved consistency of anomaly scores and superior performance. We reveal apreviously overlooked problem in the Extended Isolation Forest (EIF), showingthat it is vulnerable to ghost inter-clusters between normal clusters of datapoints. In this paper, we introduce the Rotated Isolation Forest (RIF)algorithm which effectively addresses both the axis-aligned ghost clustersobserved in iForest and the ghost inter-clusters seen in EIF. RIF accomplishesthis by randomly rotating the dataset (using random rotation matrices and QRdecomposition) before feeding it into the iForest construction, therebyincreasing dataset variation and eliminating ghost clusters. Our experimentsconclusively demonstrate that the RIF algorithm outperforms iForest and EIF, asevidenced by the results obtained from both synthetic datasets and real-worlddatasets.</description><author>Vahideh Monemizadeh, Kourosh Kiani</author><pubDate>Wed, 29 Jan 2025 17:26:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17787v1</guid></item><item><title>Reasoning Over the Glyphs: Evaluation of LLM's Decipherment of Rare Scripts</title><link>http://arxiv.org/abs/2501.17785v1</link><description>We explore the capabilities of LVLMs and LLMs in deciphering rare scripts notencoded in Unicode. We introduce a novel approach to construct a multimodaldataset of linguistic puzzles involving such scripts, utilizing a tokenizationmethod for language glyphs. Our methods include the Picture Method for LVLMsand the Description Method for LLMs, enabling these models to tackle thesechallenges. We conduct experiments using prominent models, GPT-4o, Gemini, andClaude 3.5 Sonnet, on linguistic puzzles. Our findings reveal the strengths andlimitations of current AI methods in linguistic decipherment, highlighting theimpact of Unicode encoding on model performance and the challenges of modelingvisual language tokens through descriptions. Our study advances understandingof AI's potential in linguistic decipherment and underscores the need forfurther research.</description><author>Yu-Fei Shih, Zheng-Lin Lin, Shu-Kai Hsieh</author><pubDate>Wed, 29 Jan 2025 17:24:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17785v1</guid></item><item><title>Large Language Models Can Solve Real-World Planning Rigorously with Formal Verification Tools</title><link>http://arxiv.org/abs/2404.11891v3</link><description>Large Language Models (LLMs) struggle to directly generate correct plans forcomplex multi-constraint planning problems, even with self-verification andself-critique. For example, a U.S. domestic travel planning benchmarkTravelPlanner was proposed in Xie et al. (2024), where the best LLM OpenAIo1-preview can only find viable travel plans with a 10% success rate given allneeded information. In this work, we tackle this by proposing an LLM-basedplanning framework that formalizes and solves complex multi-constraint planningproblems as constrained satisfiability problems, which are further consumed bysound and complete satisfiability solvers. We start with TravelPlanner as theprimary use case and show that our framework achieves a success rate of 93.9%and is effective with diverse paraphrased prompts. More importantly, ourframework has strong zero-shot generalizability, successfully handling unseenconstraints in our newly created unseen international travel dataset andgeneralizing well to new fundamentally different domains. Moreover, when userinput queries are infeasible, our framework can identify the unsatisfiablecore, provide failure reasons, and offers personalized modificationsuggestions. We show that our framework can modify and solve for an average of81.6% and 91.7% unsatisfiable queries from two datasets and prove withablations that all key components of our framework are effective and necessary.Project page: https://sites.google.com/view/llm-rwplanning.</description><author>Yilun Hao, Yongchao Chen, Yang Zhang, Chuchu Fan</author><pubDate>Wed, 29 Jan 2025 17:24:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.11891v3</guid></item><item><title>More is Less: Inducing Sparsity via Overparameterization</title><link>http://arxiv.org/abs/2112.11027v6</link><description>In deep learning it is common to overparameterize neural networks, that is,to use more parameters than training samples. Quite surprisingly training theneural network via (stochastic) gradient descent leads to models thatgeneralize very well, while classical statistics would suggest overfitting. Inorder to gain understanding of this implicit bias phenomenon we study thespecial case of sparse recovery (compressed sensing) which is of interest onits own. More precisely, in order to reconstruct a vector from underdeterminedlinear measurements, we introduce a corresponding overparameterized square lossfunctional, where the vector to be reconstructed is deeply factorized intoseveral vectors. We show that, if there exists an exact solution, vanillagradient flow for the overparameterized loss functional converges to a goodapproximation of the solution of minimal $\ell_1$-norm. The latter iswell-known to promote sparse solutions. As a by-product, our resultssignificantly improve the sample complexity for compressed sensing via gradientflow/descent on overparameterized models derived in previous works. The theoryaccurately predicts the recovery rate in numerical experiments. Our proofrelies on analyzing a certain Bregman divergence of the flow. This bypasses theobstacles caused by non-convexity and should be of independent interest.</description><author>Hung-Hsu Chou, Johannes Maly, Holger Rauhut</author><pubDate>Wed, 29 Jan 2025 17:22:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.11027v6</guid></item><item><title>PIR: Photometric Inverse Rendering with Shading Cues Modeling and Surface Reflectance Regularization</title><link>http://arxiv.org/abs/2408.06828v2</link><description>This paper addresses the problem of inverse rendering from photometricimages. Existing approaches for this problem suffer from the effects ofself-shadows, inter-reflections, and lack of constraints on the surfacereflectance, leading to inaccurate decomposition of reflectance andillumination due to the ill-posed nature of inverse rendering. In this work, wepropose a new method for neural inverse rendering. Our method jointly optimizesthe light source position to account for the self-shadows in images, andcomputes indirect illumination using a differentiable rendering layer and animportance sampling strategy. To enhance surface reflectance decomposition, weintroduce a new regularization by distilling DINO features to foster accurateand consistent material decomposition. Extensive experiments on synthetic andreal datasets demonstrate that our method outperforms the state-of-the-artmethods in reflectance decomposition.</description><author>Jingzhi Bao, Guanying Chen, Shuguang Cui</author><pubDate>Wed, 29 Jan 2025 17:18:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.06828v2</guid></item><item><title>AdditiveLLM: Large Language Models Predict Defects in Additive Manufacturing</title><link>http://arxiv.org/abs/2501.17784v1</link><description>In this work we investigate the ability of large language models to predictadditive manufacturing defect regimes given a set of process parameter inputs.For this task we utilize a process parameter defect dataset to fine-tune acollection of models, titled AdditiveLLM, for the purpose of predictingpotential defect regimes including Keyholing, Lack of Fusion, and Balling. Wecompare different methods of input formatting in order to gauge the model'sperformance to correctly predict defect regimes on our sparse Baseline datasetand our natural language Prompt dataset. The model displays robust predictivecapability, achieving an accuracy of 93\% when asked to provide the defectregimes associated with a set of process parameters. The incorporation ofnatural language input further simplifies the task of process parametersselection, enabling users to identify optimal settings specific to their build.</description><author>Peter Pak, Amir Barati Farimani</author><pubDate>Wed, 29 Jan 2025 17:18:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17784v1</guid></item><item><title>WavePulse: Real-time Content Analytics of Radio Livestreams</title><link>http://arxiv.org/abs/2412.17998v2</link><description>Radio remains a pervasive medium for mass information dissemination, withAM/FM stations reaching more Americans than either smartphone-based socialnetworking or live television. Increasingly, radio broadcasts are also streamedonline and accessed over the Internet. We present WavePulse, a framework thatrecords, documents, and analyzes radio content in real-time. While ourframework is generally applicable, we showcase the efficacy of WavePulse in acollaborative project with a team of political scientists focusing on the 2024Presidential Elections. We use WavePulse to monitor livestreams of 396 newsradio stations over a period of three months, processing close to 500,000 hoursof audio streams. These streams were converted into time-stamped, diarizedtranscripts and analyzed to track answer key political science questions atboth the national and state levels. Our analysis revealed how local issuesinteracted with national trends, providing insights into information flow. Ourresults demonstrate WavePulse's efficacy in capturing and analyzing contentfrom radio livestreams sourced from the Web. Code and dataset can be accessedat \url{https://wave-pulse.io}.</description><author>Govind Mittal, Sarthak Gupta, Shruti Wagle, Chirag Chopra, Anthony J DeMattee, Nasir Memon, Mustaque Ahamad, Chinmay Hegde</author><pubDate>Wed, 29 Jan 2025 17:17:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.17998v2</guid></item><item><title>Picard-KKT-hPINN: Enforcing Nonlinear Enthalpy Balances for Physically Consistent Neural Networks</title><link>http://arxiv.org/abs/2501.17782v1</link><description>Neural networks are widely used as surrogate models but they do not guaranteephysically consistent predictions thereby preventing adoption in variousapplications. We propose a method that can enforce NNs to satisfy physical lawsthat are nonlinear in nature such as enthalpy balances. Our approach, inspiredby Picard successive approximations method, aims to enforce multiplicativelyseparable constraints by sequentially freezing and projecting a set of theparticipating variables. We demonstrate our PicardKKThPINN for surrogatemodeling of a catalytic packed bed reactor for methanol synthesis. Our resultsshow that the method efficiently enforces nonlinear enthalpy and linear atomicbalances at machine-level precision. Additionally, we show that enforcingconservation laws can improve accuracy in data-scarce conditions compared tovanilla multilayer perceptron.</description><author>Giacomo Lastrucci, Tanuj Karia, Zoë Gromotka, Artur M. Schweidtmann</author><pubDate>Wed, 29 Jan 2025 17:15:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17782v1</guid></item><item><title>Long-term prediction of El Niño-Southern Oscillation using reservoir computing with data-driven realtime filter</title><link>http://arxiv.org/abs/2501.17781v1</link><description>In recent years, the application of machine learning approaches totime-series forecasting of climate dynamical phenomena has become increasinglyactive. It is known that applying a band-pass filter to a time-series data is akey to obtaining a high-quality data-driven model. Here, to obtain longer-termpredictability of machine learning models, we introduce a new type of band-passfilter. It can be applied to realtime operational prediction workflows since itrelies solely on past time series. We combine the filter with reservoircomputing, which is a machine-learning technique that employs a data-drivendynamical system. As an application, we predict the multi-year dynamics of theEl Ni\~no-Southern Oscillation with the prediction horizon of 24 months usingonly past time series.</description><author>Takuya Jinno, Takahito Mitsui, Kengo Nakai, Yoshitaka Saiki, Tsuyoshi Yoneda</author><pubDate>Wed, 29 Jan 2025 17:15:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17781v1</guid></item><item><title>What is different between these datasets?</title><link>http://arxiv.org/abs/2403.05652v2</link><description>The performance of machine learning models relies heavily on the quality ofinput data, yet real-world applications often face significant data-relatedchallenges. A common issue arises when curating training data or deployingmodels: two datasets from the same domain may exhibit differing distributions.While many techniques exist for detecting such distribution shifts, there is alack of comprehensive methods to explain these differences in ahuman-understandable way beyond opaque quantitative metrics. To bridge thisgap, we propose a versatile toolbox of interpretable methods for comparingdatasets. Using a variety of case studies, we demonstrate the effectiveness ofour approach across diverse data modalities -- including tabular data, textdata, images, time series signals -- in both low and high-dimensional settings.These methods complement existing techniques by providing actionable andinterpretable insights to better understand and address distribution shifts.</description><author>Varun Babbar, Zhicheng Guo, Cynthia Rudin</author><pubDate>Wed, 29 Jan 2025 17:10:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.05652v2</guid></item><item><title>Self-Supervised Frameworks for Speaker Verification via Bootstrapped Positive Sampling</title><link>http://arxiv.org/abs/2501.17772v1</link><description>Recent developments in Self-Supervised Learning (SSL) have demonstratedsignificant potential for Speaker Verification (SV), but closing theperformance gap with supervised systems remains an ongoing challenge. StandardSSL frameworks rely on anchor-positive pairs extracted from the same audioutterances. Hence, positives have channel characteristics similar to those oftheir corresponding anchors, even with extensive data-augmentation. Therefore,this positive sampling strategy is a fundamental limitation as it encodes toomuch information regarding the recording source in the learned representations.This article introduces Self-Supervised Positive Sampling (SSPS), abootstrapped technique for sampling appropriate and diverse positives in SSLframeworks for SV. SSPS samples positives close to their anchor in therepresentation space, as we assume that these pseudo-positives belong to thesame speaker identity but correspond to different recording conditions. Thismethod demonstrates consistent improvements in SV performance on VoxCelebbenchmarks when implemented in major SSL frameworks, such as SimCLR, SwAV,VICReg, and DINO. Using SSPS, SimCLR, and DINO achieve 2.57% and 2.53% EER onVoxCeleb1-O. SimCLR yields a 58% relative reduction in EER, getting comparableperformance to DINO with a simpler training framework. Furthermore, SSPS lowersintra-class variance and reduces channel information in speaker representationswhile exhibiting greater robustness without data-augmentation.</description><author>Theo Lepage, Reda Dehak</author><pubDate>Wed, 29 Jan 2025 17:08:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17772v1</guid></item><item><title>Through the Dual-Prism: A Spectral Perspective on Graph Data Augmentation for Graph Classification</title><link>http://arxiv.org/abs/2401.09953v3</link><description>Graph Neural Networks have become the preferred tool to process graph data,with their efficacy being boosted through graph data augmentation techniques.Despite the evolution of augmentation methods, issues like graph propertydistortions and restricted structural changes persist. This leads to thequestion: Is it possible to develop more property-conserving andstructure-sensitive augmentation methods? Through a spectral lens, weinvestigate the interplay between graph properties, their augmentation, andtheir spectral behavior, and observe that keeping the low-frequency eigenvaluesunchanged can preserve the critical properties at a large scale when generatingaugmented graphs. These observations inform our introduction of the Dual-Prism(DP) augmentation methods, including DP-Noise and DP-Mask, which retainessential graph properties while diversifying augmented graphs. Extensiveexperiments validate the efficiency of our approach, providing a new andpromising direction for graph data augmentation.</description><author>Yutong Xia, Runpeng Yu, Yuxuan Liang, Xavier Bresson, Xinchao Wang, Roger Zimmermann</author><pubDate>Wed, 29 Jan 2025 17:07:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09953v3</guid></item><item><title>2SSP: A Two-Stage Framework for Structured Pruning of LLMs</title><link>http://arxiv.org/abs/2501.17771v1</link><description>We propose a novel Two-Stage framework for Structured Pruning (2SSP) forpruning Large Language Models (LLMs), which combines two different strategiesof pruning, namely Width and Depth Pruning. The first stage (Width Pruning)removes entire neurons, hence their corresponding rows and columns, aiming topreserve the connectivity among the pruned structures in the intermediate stateof the Feed-Forward Networks in each Transformer block. This is done based onan importance score measuring the impact of each neuron over the outputmagnitude. The second stage (Depth Pruning), instead, removes entire Attentionsubmodules. This is done by applying an iterative process that removes theAttention submodules with the minimum impact on a given metric of interest (inour case, perplexity). We also propose a novel mechanism to balance thesparsity rate of the two stages w.r.t. to the desired global sparsity. We test2SSP on four LLM families and three sparsity rates (25\%, 37.5\%, and 50\%),measuring the resulting perplexity over three language modeling datasets aswell as the performance over six downstream tasks. Our method consistentlyoutperforms five state-of-the-art competitors over three language modeling andsix downstream tasks, with an up to two-order-of-magnitude gain in terms ofpruning time. The code is available at available at\url{https://github.com/FabrizioSandri/2SSP}.</description><author>Fabrizio Sandri, Elia Cunegatti, Giovanni Iacca</author><pubDate>Wed, 29 Jan 2025 17:05:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17771v1</guid></item><item><title>Generative Unordered Flow for Set-Structured Data Generation</title><link>http://arxiv.org/abs/2501.17770v1</link><description>Flow-based generative models have demonstrated promising performance across abroad spectrum of data modalities (e.g., image and text). However, there arefew works exploring their extension to unordered data (e.g., spatial pointset), which is not trivial because previous models are mostly designed forvector data that are naturally ordered. In this paper, we present unorderedflow, a type of flow-based generative model for set-structured data generation.Specifically, we convert unordered data into an appropriate functionrepresentation, and learn the probability measure of such representationsthrough function-valued flow matching. For the inverse map from a functionrepresentation to unordered data, we propose a method similar to particlefiltering, with Langevin dynamics to first warm-up the initial particles andgradient-based search to update them until convergence. We have conductedextensive experiments on multiple real-world datasets, showing that ourunordered flow model is very effective in generating set-structured data andsignificantly outperforms previous baselines.</description><author>Yangming Li, Carola-Bibiane Schönlieb</author><pubDate>Wed, 29 Jan 2025 17:03:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17770v1</guid></item><item><title>Computing the gradients with respect to all parameters of a quantum neural network using a single circuit</title><link>http://arxiv.org/abs/2307.08167v3</link><description>Finding gradients is a crucial step in training machine learning models. Forquantum neural networks, computing gradients using the parameter-shift rulerequires evaluating the cost function twice for each adjustable parameter inthe network. When the total number of parameters is large, the quantum circuitmust be repeatedly adjusted and executed, leading to significant computationaloverhead. In this work, we propose a novel approach that computes all gradientsusing only a single circuit, significantly reducing both the circuit depth andthe number of classical registers required. We experimentally validate ourapproach on both quantum simulators and IBM's real quantum hardware,demonstrating that our method significantly reduces circuit compilation timecompared to the conventional approach, resulting in a substantial speedup intotal runtime.</description><author>Guang Ping He</author><pubDate>Wed, 29 Jan 2025 17:02:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08167v3</guid></item><item><title>Hybrid Graphs for Table-and-Text based Question Answering using LLMs</title><link>http://arxiv.org/abs/2501.17767v1</link><description>Answering questions that require reasoning and aggregation across bothstructured (tables) and unstructured (raw text) data sources presentssignificant challenges. Current methods rely on fine-tuning and high-quality,human-curated data, which is difficult to obtain. Recent advances in LargeLanguage Models (LLMs) have shown promising results for multi-hop questionanswering (QA) over single-source text data in a zero-shot setting, yetexploration into multi-source Table-Text QA remains limited. In this paper, wepresent a novel Hybrid Graph-based approach for Table-Text QA that leveragesLLMs without fine-tuning. Our method constructs a unified Hybrid Graph fromtextual and tabular data, pruning information based on the input question toprovide the LLM with relevant context concisely. We evaluate our approach onthe challenging Hybrid-QA and OTT-QA datasets using state-of-the-art LLMs,including GPT-3.5, GPT-4, and LLaMA-3. Our method achieves the best zero-shotperformance on both datasets, improving Exact Match scores by up to 10% onHybrid-QA and 5.4% on OTT-QA. Moreover, our approach reduces token usage by upto 53% compared to the original context.</description><author>Ankush Agarwal, Ganesh S, Chaitanya Devaguptapu</author><pubDate>Wed, 29 Jan 2025 16:58:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17767v1</guid></item><item><title>Prompt Obfuscation for Large Language Models</title><link>http://arxiv.org/abs/2409.11026v3</link><description>System prompts that include detailed instructions to describe the taskperformed by the underlying LLM can easily transform foundation models intotools and services with minimal overhead. Because of their crucial impact onthe utility, they are often considered intellectual property, similar to thecode of a software product. However, extracting system prompts is easilypossible. As of today, there is no effective countermeasure to prevent thestealing of system prompts and all safeguarding efforts could be evaded. Inthis work, we propose an alternative to conventional system prompts. Weintroduce prompt obfuscation to prevent the extraction of the system promptwith only little overhead. The core idea is to find a representation of theoriginal system prompt that leads to the same functionality, while theobfuscated system prompt does not contain any information that allowsconclusions to be drawn about the original system prompt. We evaluate ourapproach by comparing our obfuscated prompt output with the output of theoriginal prompt, using eight distinct metrics, to measure the lexical,character-level, and semantic similarity. We show that the obfuscated versionis constantly on par with the original one. We further perform three differentdeobfuscation attacks with varying attacker knowledge--covering both black-boxand white-box conditions--and show that in realistic attack scenarios anattacker is not able to extract meaningful information. Overall, we demonstratethat prompt obfuscation is an effective mechanism to safeguard the intellectualproperty of a system prompt while maintaining the same utility as the originalprompt.</description><author>David Pape, Sina Mavali, Thorsten Eisenhofer, Lea Schönherr</author><pubDate>Wed, 29 Jan 2025 16:57:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.11026v3</guid></item><item><title>Improving Privacy Benefits of Redaction</title><link>http://arxiv.org/abs/2501.17762v1</link><description>We propose a novel redaction methodology that can be used to sanitize naturaltext data. Our new technique provides better privacy benefits than other stateof the art techniques while maintaining lower redaction levels.</description><author>Vaibhav Gusain, Douglas Leith</author><pubDate>Wed, 29 Jan 2025 16:53:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17762v1</guid></item><item><title>Online Prompt Selection for Program Synthesis</title><link>http://arxiv.org/abs/2501.05247v2</link><description>Large Language Models (LLMs) demonstrate impressive capabilities in thedomain of program synthesis. This level of performance is not, however,universal across all tasks, all LLMs and all prompting styles. There are manyareas where one LLM dominates, one prompting style dominates, or where callinga symbolic solver is a better choice than an LLM. A key challenge for the userthen, is to identify not only when an LLM is the right choice of solver, andthe appropriate LLM to call for a given synthesis task, but also the right wayto call it. A non-expert user who makes the wrong choice, incurs a cost both interms of results (number of tasks solved, and the time it takes to solve them)and financial cost, if using a closed-source language model via a commercialAPI. We frame this choice as an online learning problem. We use a multi-armedbandit algorithm to select which symbolic solver, or LLM and prompt combinationto deploy in order to maximize a given reward function (which may prioritizesolving time, number of synthesis tasks solved, or financial cost of solving).We implement an instance of this approach, called CYANEA, and evaluate it onsynthesis queries from the literature in ranking function synthesis, from thesyntax-guided synthesis competition, and fresh, unseen queries generated fromSMT problems. CYANEA solves 37.2% more queries than the best single solver andachieves results within 4% of the virtual best solver.</description><author>Yixuan Li, Lewis Frampton, Federico Mora, Elizabeth Polgreen</author><pubDate>Wed, 29 Jan 2025 16:52:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05247v2</guid></item><item><title>Yin-Yang: Developing Motifs With Long-Term Structure And Controllability</title><link>http://arxiv.org/abs/2501.17759v1</link><description>Transformer models have made great strides in generating symbolicallyrepresented music with local coherence. However, controlling the development ofmotifs in a structured way with global form remains an open research area. Oneof the reasons for this challenge is due to the note-by-note autoregressivegeneration of such models, which lack the ability to correct themselves afterdeviations from the motif. In addition, their structural performance ondatasets with shorter durations has not been studied in the literature. In thisstudy, we propose Yin-Yang, a framework consisting of a phrase generator,phrase refiner, and phrase selector models for the development of motifs intomelodies with long-term structure and controllability. The phrase refiner istrained on a novel corruption-refinement strategy which allows it to producemelodic and rhythmic variations of an original motif at generation time,thereby rectifying deviations of the phrase generator. We also introduce a newobjective evaluation metric for quantifying how smoothly the motif manifestsitself within the piece. Evaluation results show that our model achieves betterperformance compared to state-of-the-art transformer models while having theadvantage of being controllable and making the generated musical structuresemi-interpretable, paving the way for musical analysis. Our code and demo pagecan be found at https://github.com/keshavbhandari/yinyang.</description><author>Keshav Bhandari, Geraint A. Wiggins, Simon Colton</author><pubDate>Wed, 29 Jan 2025 16:50:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17759v1</guid></item><item><title>Glioma Multimodal MRI Analysis System for Tumor Layered Diagnosis via Multi-task Semi-supervised Learning</title><link>http://arxiv.org/abs/2501.17758v1</link><description>Gliomas are the most common primary tumors of the central nervous system.Multimodal MRI is widely used for the preliminary screening of gliomas andplays a crucial role in auxiliary diagnosis, therapeutic efficacy, andprognostic evaluation. Currently, the computer-aided diagnostic studies ofgliomas using MRI have focused on independent analysis events such as tumorsegmentation, grading, and radiogenomic classification, without studyinginter-dependencies among these events. In this study, we propose a GliomaMultimodal MRI Analysis System (GMMAS) that utilizes a deep learning networkfor processing multiple events simultaneously, leveraging theirinter-dependencies through an uncertainty-based multi-task learningarchitecture and synchronously outputting tumor region segmentation, gliomahistological subtype, IDH mutation genotype, and 1p/19q chromosome disorderstatus. Compared with the reported single-task analysis models, GMMAS improvesthe precision across tumor layered diagnostic tasks. Additionally, we haveemployed a two-stage semi-supervised learning method, enhancing modelperformance by fully exploiting both labeled and unlabeled MRI samples.Further, by utilizing an adaptation module based on knowledge self-distillationand contrastive learning for cross-modal feature extraction, GMMAS exhibitedrobustness in situations of modality absence and revealed the differingsignificance of each MRI modal. Finally, based on the analysis outputs of theGMMAS, we created a visual and user-friendly platform for doctors and patients,introducing GMMAS-GPT to generate personalized prognosis evaluations andsuggestions.</description><author>Yihao Liu, Zhihao Cui, Liming Li, Junjie You, Xinle Feng, Jianxin Wang, Xiangyu Wang, Qing Liu, Minghua Wu</author><pubDate>Wed, 29 Jan 2025 16:50:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17758v1</guid></item><item><title>Efficient Computation of Sparse and Robust Maximum Association Estimators</title><link>http://arxiv.org/abs/2311.17563v3</link><description>Robust statistical estimators offer resilience against outliers but are oftencomputationally challenging, particularly in high-dimensional sparse settings.Modern optimization techniques are utilized for robust sparse associationestimators without imposing constraints on the covariance structure. Theapproach splits the problem into a robust estimation phase, followed byoptimization of a decoupled, biconvex problem to derive the sparse canonicalvectors. An augmented Lagrangian algorithm, combined with a modified adaptivegradient descent method, induces sparsity through simultaneous updates of bothcanonical vectors. Results demonstrate improved precision over existingmethods, with high-dimensional empirical examples illustrating theeffectiveness of this approach. The methodology can also be extended to otherrobust sparse estimators.</description><author>Pia Pfeiffer, Andreas Alfons, Peter Filzmoser</author><pubDate>Wed, 29 Jan 2025 16:49:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17563v3</guid></item><item><title>AI Governance through Markets</title><link>http://arxiv.org/abs/2501.17755v1</link><description>This paper argues that market governance mechanisms should be considered akey approach in the governance of artificial intelligence (AI), alongsidetraditional regulatory frameworks. While current governance approaches havepredominantly focused on regulation, we contend that market-based mechanismsoffer effective incentives for responsible AI development. We examine fouremerging vectors of market governance: insurance, auditing, procurement, anddue diligence, demonstrating how these mechanisms can affirm the relationshipbetween AI risk and financial risk while addressing capital allocationinefficiencies. While we do not claim that market forces alone can adequatelyprotect societal interests, we maintain that standardised AI disclosures andmarket mechanisms can create powerful incentives for safe and responsible AIdevelopment. This paper urges regulators, economists, and machine learningresearchers to investigate and implement market-based approaches to AIgovernance.</description><author>Philip Moreira Tomei, Rupal Jain, Matija Franklin</author><pubDate>Wed, 29 Jan 2025 16:48:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17755v1</guid></item><item><title>Stroke classification using Virtual Hybrid Edge Detection from in silico electrical impedance tomography data</title><link>http://arxiv.org/abs/2501.14704v2</link><description>Electrical impedance tomography (EIT) is a non-invasive imaging method forrecovering the internal conductivity of a physical body from electric boundarymeasurements. EIT combined with machine learning has shown promise for theclassification of strokes. However, most previous works have used raw EITvoltage data as network inputs. We build upon a recent development whichsuggested the use of special noise-robust Virtual Hybrid Edge Detection (VHED)functions as network inputs, although that work used only highly simplified andmathematically ideal models. In this work we strengthen the case for the use ofEIT, and VHED functions especially, for stroke classification. We design modelswith high detail and mathematical realism to test the use of VHED functions asinputs. Virtual patients are created using a physically detailed 2D head modelwhich includes features known to create challenges in real-world imagingscenarios. Conductivity values are drawn from statistically realisticdistributions, and phantoms are afflicted with either hemorrhagic or ischemicstrokes of various shapes and sizes. Simulated noisy EIT electrode data,generated using the realistic Complete Electrode Model (CEM) as opposed to themathematically ideal continuum model, is processed to obtain VHED functions. Wecompare the use of VHED functions as inputs against the alternative paradigm ofusing raw EIT voltages. Our results show that (i) stroke classification can beperformed with high accuracy using 2D EIT data from physically detailed andmathematically realistic models, and (ii) in the presence of noise, VHEDfunctions outperform raw data as network inputs.</description><author>Juan Pablo Agnelli, Fernando S. Moura, Siiri Rautio, Melody Alsaker, Rashmi Murthy, Matti Lassas, Samuli Siltanen</author><pubDate>Wed, 29 Jan 2025 16:46:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14704v2</guid></item><item><title>On the Universality of Volume-Preserving and Coupling-Based Normalizing Flows</title><link>http://arxiv.org/abs/2402.06578v3</link><description>We present a novel theoretical framework for understanding the expressivepower of normalizing flows. Despite their prevalence in scientificapplications, a comprehensive understanding of flows remains elusive due totheir restricted architectures. Existing theorems fall short as they requirethe use of arbitrarily ill-conditioned neural networks, limiting practicalapplicability. We propose a distributional universality theorem forwell-conditioned coupling-based normalizing flows such as RealNVP. In addition,we show that volume-preserving normalizing flows are not universal, whatdistribution they learn instead, and how to fix their expressivity. Our resultssupport the general wisdom that affine and related couplings are expressive andin general outperform volume-preserving flows, bridging a gap between empiricalresults and theoretical understanding.</description><author>Felix Draxler, Stefan Wahl, Christoph Schnörr, Ullrich Köthe</author><pubDate>Wed, 29 Jan 2025 16:45:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06578v3</guid></item><item><title>Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models</title><link>http://arxiv.org/abs/2404.12920v3</link><description>Localizing the exact pathological regions in a given medical scan is animportant imaging problem that traditionally requires a large amount ofbounding box ground truth annotations to be accurately solved. However, thereexist alternative, potentially weaker, forms of supervision, such asaccompanying free-text reports, which are readily available.The task ofperforming localization with textual guidance is commonly referred to as phrasegrounding. In this work, we use a publicly available Foundation Model, namelythe Latent Diffusion Model, to perform this challenging task. This choice issupported by the fact that the Latent Diffusion Model, despite being generativein nature, contains cross-attention mechanisms that implicitly align visual andtextual features, thus leading to intermediate representations that aresuitable for the task at hand. In addition, we aim to perform this task in azero-shot manner, i.e., without any training on the target task, meaning thatthe model's weights remain frozen. To this end, we devise strategies to selectfeatures and also refine them via post-processing without extra learnableparameters. We compare our proposed method with state-of-the-art approacheswhich explicitly enforce image-text alignment in a joint embedding space viacontrastive learning. Results on a popular chest X-ray benchmark indicate thatour method is competitive with SOTA on different types of pathology, and evenoutperforms them on average in terms of two metrics (mean IoU and AUC-ROC).Source code will be released upon acceptance at\url{https://github.com/vios-s}.</description><author>Konstantinos Vilouras, Pedro Sanchez, Alison Q. O'Neil, Sotirios A. Tsaftaris</author><pubDate>Wed, 29 Jan 2025 16:43:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.12920v3</guid></item><item><title>Early External Safety Testing of OpenAI's o3-mini: Insights from the Pre-Deployment Evaluation</title><link>http://arxiv.org/abs/2501.17749v1</link><description>Large Language Models (LLMs) have become an integral part of our daily lives.However, they impose certain risks, including those that can harm individuals'privacy, perpetuate biases and spread misinformation. These risks highlight theneed for robust safety mechanisms, ethical guidelines, and thorough testing toensure their responsible deployment. Safety of LLMs is a key property thatneeds to be thoroughly tested prior the model to be deployed and accessible tothe general users. This paper reports the external safety testing experienceconducted by researchers from Mondragon University and University of Seville onOpenAI's new o3-mini LLM as part of OpenAI's early access for safety testingprogram. In particular, we apply our tool, ASTRAL, to automatically andsystematically generate up to date unsafe test inputs (i.e., prompts) thathelps us test and assess different safety categories of LLMs. We automaticallygenerate and execute a total of 10,080 unsafe test input on a early o3-minibeta version. After manually verifying the test cases classified as unsafe byASTRAL, we identify a total of 87 actual instances of unsafe LLM behavior. Wehighlight key insights and findings uncovered during the pre-deploymentexternal testing phase of OpenAI's latest LLM.</description><author>Aitor Arrieta, Miriam Ugarte, Pablo Valle, José Antonio Parejo, Sergio Segura</author><pubDate>Wed, 29 Jan 2025 16:36:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17749v1</guid></item><item><title>How Green are Neural Language Models? Analyzing Energy Consumption in Text Summarization Fine-tuning</title><link>http://arxiv.org/abs/2501.15398v2</link><description>Artificial intelligence systems significantly impact the environment,particularly in natural language processing (NLP) tasks. These tasks oftenrequire extensive computational resources to train deep neural networks,including large-scale language models containing billions of parameters. Thisstudy analyzes the trade-offs between energy consumption and performance acrossthree neural language models: two pre-trained models (T5-base and BART-base),and one large language model (LLaMA 3-8B). These models were fine-tuned for thetext summarization task, focusing on generating research paper highlights thatencapsulate the core themes of each paper. A wide range of evaluation metrics,including ROUGE, METEOR, MoverScore, BERTScore, and SciBERTScore, were employedto assess their performance. Furthermore, the carbon footprint associated withfine-tuning each model was measured, offering a comprehensive assessment oftheir environmental impact. This research underscores the importance ofincorporating environmental considerations into the design and implementationof neural language models and calls for the advancement of energy-efficient AImethodologies.</description><author>Tohida Rehman, Debarshi Kumar Sanyal, Samiran Chattopadhyay</author><pubDate>Wed, 29 Jan 2025 16:36:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.15398v2</guid></item><item><title>Dynamics of Transient Structure in In-Context Linear Regression Transformers</title><link>http://arxiv.org/abs/2501.17745v1</link><description>Modern deep neural networks display striking examples of rich internalcomputational structure. Uncovering principles governing the development ofsuch structure is a priority for the science of deep learning. In this paper,we explore the transient ridge phenomenon: when transformers are trained onin-context linear regression tasks with intermediate task diversity, theyinitially behave like ridge regression before specializing to the tasks intheir training distribution. This transition from a general solution to aspecialized solution is revealed by joint trajectory principal componentanalysis. Further, we draw on the theory of Bayesian internal model selectionto suggest a general explanation for the phenomena of transient structure intransformers, based on an evolving tradeoff between loss and complexity. Thisexplanation is grounded in empirical measurements of model complexity using thelocal learning coefficient.</description><author>Liam Carroll, Jesse Hoogland, Matthew Farrugia-Roberts, Daniel Murfet</author><pubDate>Wed, 29 Jan 2025 16:32:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17745v1</guid></item><item><title>Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming</title><link>http://arxiv.org/abs/2410.12112v2</link><description>While large language models (LLMs) have recently demonstrated strongpotential in solving planning problems, there is a trade-off betweenflexibility and complexity. LLMs, as zero-shot planners themselves, are stillnot capable of directly generating valid plans for complex planning problemssuch as multi-constraint or long-horizon tasks. On the other hand, manyframeworks aiming to solve complex planning problems often rely ontask-specific preparatory efforts, such as task-specific in-context examplesand pre-defined critics/verifiers, which limits their cross-task generalizationcapability. In this paper, we tackle these challenges by observing that thecore of many planning problems lies in optimization problems: searching for theoptimal solution (best plan) with goals subject to constraints (preconditionsand effects of decisions). With LLMs' commonsense, reasoning, and programmingcapabilities, this opens up the possibilities of a universal LLM-based approachto planning problems. Inspired by this observation, we propose LLMFP, ageneral-purpose framework that leverages LLMs to capture key information fromplanning problems and formally formulate and solve them as optimizationproblems from scratch, with no task-specific examples needed. We apply LLMFP to9 planning problems, ranging from multi-constraint decision making tomulti-step planning problems, and demonstrate that LLMFP achieves on average83.7% and 86.8% optimal rate across 9 tasks for GPT-4o and Claude 3.5 Sonnet,significantly outperforming the best baseline (direct planning with OpenAIo1-preview) with 37.6% and 40.7% improvements. We also validate components ofLLMFP with ablation experiments and analyzed the underlying success and failurereasons. Project page: https://sites.google.com/view/llmfp.</description><author>Yilun Hao, Yang Zhang, Chuchu Fan</author><pubDate>Wed, 29 Jan 2025 16:31:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12112v2</guid></item><item><title>Conformal Distributed Remote Inference in Sensor Networks Under Reliability and Communication Constraints</title><link>http://arxiv.org/abs/2409.07902v2</link><description>This paper presents communication-constrained distributed conformal riskcontrol (CD-CRC) framework, a novel decision-making framework for sensornetworks under communication constraints. Targeting multi-label classificationproblems, such as segmentation, CD-CRC dynamically adjusts local and globalthresholds used to identify significant labels with the goal of ensuring atarget false negative rate (FNR), while adhering to communication capacitylimits. CD-CRC builds on online exponentiated gradient descent to estimate therelative quality of the observations of different sensors, and on onlineconformal risk control (CRC) as a mechanism to control local and globalthresholds. CD-CRC is proved to offer deterministic worst-case performanceguarantees in terms of FNR and communication overhead, while the regretperformance in terms of false positive rate (FPR) is characterized as afunction of the key hyperparameters. Simulation results highlight theeffectiveness of CD-CRC, particularly in communication resource-constrainedenvironments, making it a valuable tool for enhancing the performance andreliability of distributed sensor networks.</description><author>Meiyi Zhu, Matteo Zecchin, Sangwoo Park, Caili Guo, Chunyan Feng, Petar Popovski, Osvaldo Simeone</author><pubDate>Wed, 29 Jan 2025 16:24:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.07902v2</guid></item><item><title>Sparser, Better, Faster, Stronger: Efficient Automatic Differentiation for Sparse Jacobians and Hessians</title><link>http://arxiv.org/abs/2501.17737v1</link><description>From implicit differentiation to probabilistic modeling, Jacobians andHessians have many potential use cases in Machine Learning (ML), butconventional wisdom views them as computationally prohibitive. Fortunately,these matrices often exhibit sparsity, which can be leveraged to significantlyspeed up the process of Automatic Differentiation (AD). This paper presentsadvances in Automatic Sparse Differentiation (ASD), starting with a newperspective on sparsity detection. Our refreshed exposition is based onoperator overloading, able to detect both local and global sparsity patterns,and naturally avoids dead ends in the control flow graph. We also describe anovel ASD pipeline in Julia, consisting of independent software packages forsparsity detection, matrix coloring, and differentiation, which together enableASD based on arbitrary AD backends. Our pipeline is fully automatic andrequires no modification of existing code, making it compatible with existingML codebases. We demonstrate that this pipeline unlocks Jacobian and Hessianmatrices at scales where they were considered too expensive to compute. Onreal-world problems from scientific ML and optimization, we show significantspeed-ups of up to three orders of magnitude. Notably, our ASD pipeline oftenoutperforms standard AD for one-off computations, once thought impractical dueto slower sparsity detection methods.</description><author>Adrian Hill, Guillaume Dalle</author><pubDate>Wed, 29 Jan 2025 16:21:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17737v1</guid></item><item><title>Revisiting Differential Verification: Equivalence Verification with Confidence</title><link>http://arxiv.org/abs/2410.20207v2</link><description>When validated neural networks (NNs) are pruned (and retrained) beforedeployment, it is desirable to prove that the new NN behaves equivalently tothe (original) reference NN. To this end, our paper revisits the idea ofdifferential verification which performs reasoning on differences between NNs:On the one hand, our paper proposes a novel abstract domain for differentialverification admitting more efficient reasoning about equivalence. On the otherhand, we investigate empirically and theoretically which equivalence propertiesare (not) efficiently solved using differential reasoning. Based on the gainedinsights, and following a recent line of work on confidence-based verification,we propose a novel equivalence property that is amenable to DifferentialVerification while providing guarantees for large parts of the input spaceinstead of small-scale guarantees constructed w.r.t. predetermined inputpoints. We implement our approach in a new tool called VeryDiff and perform anextensive evaluation on numerous old and new benchmark families, including newpruned NNs for particle jet classification in the context of CERN's LHC wherewe observe median speedups &gt;300x over the State-of-the-Art verifieralpha,beta-CROWN.</description><author>Samuel Teuber, Philipp Kern, Marvin Janzen, Bernhard Beckert</author><pubDate>Wed, 29 Jan 2025 16:21:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20207v2</guid></item><item><title>Score-based Neural Ordinary Differential Equations for Computing Mean Field Control Problems</title><link>http://arxiv.org/abs/2409.16471v2</link><description>Classical neural ordinary differential equations (ODEs) are powerful toolsfor approximating the log-density functions in high-dimensional spaces alongtrajectories, where neural networks parameterize the velocity fields. Thispaper proposes a system of neural differential equations representing first-and second-order score functions along trajectories based on deep neuralnetworks. We reformulate the mean field control (MFC) problem with individualnoises into an unconstrained optimization problem framed by the proposed neuralODE system. Additionally, we introduce a novel regularization term to enforcecharacteristics of viscous Hamilton--Jacobi--Bellman (HJB) equations to besatisfied based on the evolution of the second-order score function. Examplesinclude regularized Wasserstein proximal operators (RWPOs), probability flowmatching of Fokker--Planck (FP) equations, and linear quadratic (LQ) MFCproblems, which demonstrate the effectiveness and accuracy of the proposedmethod.</description><author>Mo Zhou, Stanley Osher, Wuchen Li</author><pubDate>Wed, 29 Jan 2025 16:18:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.16471v2</guid></item><item><title>Exact characterization of ε-Safe Decision Regions for exponential family distributions and Multi Cost SVM approximation</title><link>http://arxiv.org/abs/2501.17731v1</link><description>Probabilistic guarantees on the prediction of data-driven classifiers arenecessary to define models that can be considered reliable. This is a keyrequirement for modern machine learning in which the goodness of a system ismeasured in terms of trustworthiness, clearly dividing what is safe from whatis unsafe. The spirit of this paper is exactly in this direction. First, weintroduce a formal definition of {\epsilon}-Safe Decision Region, a subset ofthe input space in which the prediction of a target (safe) class isprobabilistically guaranteed. Second, we prove that, when data come fromexponential family distributions, the form of such a region is analyticallydetermined and controllable by design parameters, i.e. the probability ofsampling the target class and the confidence on the prediction. However, therequest of having exponential data is not always possible. Inspired by thislimitation, we developed Multi Cost SVM, an SVM based algorithm thatapproximates the safe region and is also able to handle unbalanced data. Theresearch is complemented by experiments and code available for reproducibility.</description><author>Alberto Carlevaro, Teodoro Alamo, Fabrizio Dabbene, Maurizio Mongelli</author><pubDate>Wed, 29 Jan 2025 16:14:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17731v1</guid></item><item><title>Sparse Autoencoders Can Interpret Randomly Initialized Transformers</title><link>http://arxiv.org/abs/2501.17727v1</link><description>Sparse autoencoders (SAEs) are an increasingly popular technique forinterpreting the internal representations of transformers. In this paper, weapply SAEs to 'interpret' random transformers, i.e., transformers where theparameters are sampled IID from a Gaussian rather than trained on text data. Wefind that random and trained transformers produce similarly interpretable SAElatents, and we confirm this finding quantitatively using an open-sourceauto-interpretability pipeline. Further, we find that SAE quality metrics arebroadly similar for random and trained transformers. We find that these resultshold across model sizes and layers. We discuss a number of number interestingquestions that this work raises for the use of SAEs and auto-interpretabilityin the context of mechanistic interpretability.</description><author>Thomas Heap, Tim Lawson, Lucy Farnik, Laurence Aitchison</author><pubDate>Wed, 29 Jan 2025 16:11:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17727v1</guid></item><item><title>Polyp-Gen: Realistic and Diverse Polyp Image Generation for Endoscopic Dataset Expansion</title><link>http://arxiv.org/abs/2501.16679v2</link><description>Automated diagnostic systems (ADS) have shown significant potential in theearly detection of polyps during endoscopic examinations, thereby reducing theincidence of colorectal cancer. However, due to high annotation costs andstrict privacy concerns, acquiring high-quality endoscopic images poses aconsiderable challenge in the development of ADS. Despite recent advancementsin generating synthetic images for dataset expansion, existing endoscopic imagegeneration algorithms failed to accurately generate the details of polypboundary regions and typically required medical priors to specify plausiblelocations and shapes of polyps, which limited the realism and diversity of thegenerated images. To address these limitations, we present Polyp-Gen, the firstfull-automatic diffusion-based endoscopic image generation framework.Specifically, we devise a spatial-aware diffusion training scheme with alesion-guided loss to enhance the structural context of polyp boundary regions.Moreover, to capture medical priors for the localization of potential polypareas, we introduce a hierarchical retrieval-based sampling strategy to matchsimilar fine-grained spatial features. In this way, our Polyp-Gen can generaterealistic and diverse endoscopic images for building reliable ADS. Extensiveexperiments demonstrate the state-of-the-art generation quality, and thesynthetic images can improve the downstream polyp detection task. Additionally,our Polyp-Gen has shown remarkable zero-shot generalizability on otherdatasets. The source code is available athttps://github.com/CUHK-AIM-Group/Polyp-Gen.</description><author>Shengyuan Liu, Zhen Chen, Qiushi Yang, Weihao Yu, Di Dong, Jiancong Hu, Yixuan Yuan</author><pubDate>Wed, 29 Jan 2025 16:04:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.16679v2</guid></item><item><title>Attention when you need</title><link>http://arxiv.org/abs/2501.07440v2</link><description>Being attentive to task-relevant features can improve task performance, butpaying attention comes with its own metabolic cost. Therefore, strategicallocation of attention is crucial in performing the task efficiently. Thiswork aims to understand this strategy. Recently, de Gee et al. conductedexperiments involving mice performing an auditory sustained attention-valuetask. This task required the mice to exert attention to identify whether ahigh-order acoustic feature was present amid the noise. By varying the trialduration and reward magnitude, the task allows us to investigate how an agentshould strategically deploy their attention to maximize their benefits andminimize their costs. In our work, we develop a reinforcement learning-basednormative model of the mice to understand how it balances attention costagainst its benefits. The model is such that at each moment the mice can choosebetween two levels of attention and decide when to take costly actions thatcould obtain rewards. Our model suggests that efficient use of attentionalresources involves alternating blocks of high attention with blocks of lowattention. In the extreme case where the agent disregards sensory input duringlow attention states, we see that high attention is used rhythmically. Ourmodel provides evidence about how one should deploy attention as a function oftask utility, signal statistics, and how attention affects sensory evidence.</description><author>Lokesh Boominathan, Yizhou Chen, Matthew McGinley, Xaq Pitkow</author><pubDate>Wed, 29 Jan 2025 16:04:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.07440v2</guid></item><item><title>VICCA: Visual Interpretation and Comprehension of Chest X-ray Anomalies in Generated Report Without Human Feedback</title><link>http://arxiv.org/abs/2501.17726v1</link><description>As artificial intelligence (AI) becomes increasingly central to healthcare,the demand for explainable and trustworthy models is paramount. Current reportgeneration systems for chest X-rays (CXR) often lack mechanisms for validatingoutputs without expert oversight, raising concerns about reliability andinterpretability. To address these challenges, we propose a novel multimodalframework designed to enhance the semantic alignment and localization accuracyof AI-generated medical reports. Our framework integrates two key modules: aPhrase Grounding Model, which identifies and localizes pathologies in CXRimages based on textual prompts, and a Text-to-Image Diffusion Module, whichgenerates synthetic CXR images from prompts while preserving anatomicalfidelity. By comparing features between the original and generated images, weintroduce a dual-scoring system: one score quantifies localization accuracy,while the other evaluates semantic consistency. This approach significantlyoutperforms existing methods, achieving state-of-the-art results in pathologylocalization and text-to-image alignment. The integration of phrase groundingwith diffusion models, coupled with the dual-scoring evaluation system,provides a robust mechanism for validating report quality, paving the way formore trustworthy and transparent AI in medical imaging.</description><author>Sayeh Gholipour Picha, Dawood Al Chanti, Alice Caplier</author><pubDate>Wed, 29 Jan 2025 16:02:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17726v1</guid></item><item><title>Real-Time Video Generation with Pyramid Attention Broadcast</title><link>http://arxiv.org/abs/2408.12588v2</link><description>We present Pyramid Attention Broadcast (PAB), a real-time, high quality andtraining-free approach for DiT-based video generation. Our method is founded onthe observation that attention difference in the diffusion process exhibits aU-shaped pattern, indicating significant redundancy. We mitigate this bybroadcasting attention outputs to subsequent steps in a pyramid style. Itapplies different broadcast strategies to each attention based on theirvariance for best efficiency. We further introduce broadcast sequence parallelfor more efficient distributed inference. PAB demonstrates up to 10.5x speedupacross three models compared to baselines, achieving real-time generation forup to 720p videos. We anticipate that our simple yet effective method willserve as a robust baseline and facilitate future research and application forvideo generation.</description><author>Xuanlei Zhao, Xiaolong Jin, Kai Wang, Yang You</author><pubDate>Wed, 29 Jan 2025 16:02:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12588v2</guid></item><item><title>GMT: Guided Mask Transformer for Leaf Instance Segmentation</title><link>http://arxiv.org/abs/2406.17109v3</link><description>Leaf instance segmentation is a challenging multi-instance segmentation task,aiming to separate and delineate each leaf in an image of a plant. Accuratesegmentation of each leaf is crucial for plant-related applications such as thefine-grained monitoring of plant growth and crop yield estimation. This task ischallenging because of the high similarity (in shape and colour), great sizevariation, and heavy occlusions among leaf instances. Furthermore, thetypically small size of annotated leaf datasets makes it more difficult tolearn the distinctive features needed for precise segmentation. We hypothesisethat the key to overcoming the these challenges lies in the specific spatialpatterns of leaf distribution. In this paper, we propose the Guided MaskTransformer (GMT), which leverages and integrates leaf spatial distributionpriors into a Transformer-based segmentor. These spatial priors are embedded ina set of guide functions that map leaves at different positions into a moreseparable embedding space. Our GMT consistently outperforms thestate-of-the-art on three public plant datasets. Our code is available athttps://github.com/vios-s/gmt-leaf-ins-seg.</description><author>Feng Chen, Sotirios A. Tsaftaris, Mario Valerio Giuffrida</author><pubDate>Wed, 29 Jan 2025 15:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17109v3</guid></item><item><title>Load Forecasting for Households and Energy Communities: Are Deep Learning Models Worth the Effort?</title><link>http://arxiv.org/abs/2501.05000v2</link><description>Accurate load forecasting is crucial for predictive control in many energydomain applications, with significant economic and ecological implications. Toaddress these implications, this study provides an extensive benchmark ofstate-of-the-art deep learning models for short-term load forecasting in energycommunities. Namely, LSTM, xLSTM, and Transformers are compared with benchmarkssuch as KNNs, synthetic load models, and persistence forecasting models. Thiscomparison considers different scales of aggregation (e.g., number of householdloads) and varying training data availability (e.g., training data time spans).Further, the impact of transfer learning from synthetic (standard) loadprofiles and the deep learning model size (i.e., parameter count) isinvestigated in terms of forecasting error. Implementations are publiclyavailable and other researchers are encouraged to benchmark models using thisframework. Additionally, a comprehensive case study, comprising an energycommunity of 50 households and a battery storage demonstrates the beneficialfinancial implications of accurate predictions. Key findings of this researchinclude: (1) Simple persistence benchmarks outperform deep learning models forshort-term load forecasting when the available training data is limited to sixmonths or less; (2) Pretraining with publicly available synthetic load profilesimproves the normalized Mean Absolute Error (nMAE) by an average of 1.28%ptduring the first nine months of training data; (3) Increased aggregationsignificantly enhances the performance of deep learning models relative topersistence benchmarks; (4) Improved load forecasting, with an nMAE reductionof 1.1%pt, translates to an economic benefit of approximately 600EUR per yearin an energy community comprising 50 households.</description><author>Lukas Moosbrugger, Valentin Seiler, Philipp Wohlgenannt, Sebastian Hegenbart, Sashko Ristov, Peter Kepplinger</author><pubDate>Wed, 29 Jan 2025 15:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.05000v2</guid></item><item><title>Using Code Generation to Solve Open Instances of Combinatorial Design Problems</title><link>http://arxiv.org/abs/2501.17725v1</link><description>The Handbook of Combinatorial Designs catalogs many types of combinatorialdesigns, together with lists of open instances for which existence has not yetbeen determined. We develop a constructive protocol CPro1, which uses LargeLanguage Models (LLMs) to generate code that constructs combinatorial designsand resolves some of these open instances. The protocol starts from adefinition of a particular type of design, and a verifier that reliablyconfirms whether a proposed design is valid. The LLM selects strategies andimplements them in code, and scaffolding provides automated hyperparametertuning and execution feedback using the verifier. Most generated code fails,but by generating many candidates, the protocol automates exploration of avariety of standard methods (e.g. simulated annealing, genetic algorithms) andexperimentation with variations (e.g. cost functions) to find successfulapproaches. Testing on 16 different types of designs, CPro1 constructssolutions to open instances for 6 of them: Symmetric and Skew WeighingMatrices, Equidistant Permutation Arrays, Packing Arrays, Balanced TernaryDesigns, and Florentine Rectangles.</description><author>Christopher D. Rosin</author><pubDate>Wed, 29 Jan 2025 15:57:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17725v1</guid></item><item><title>LogLLM: Log-based Anomaly Detection Using Large Language Models</title><link>http://arxiv.org/abs/2411.08561v3</link><description>Software systems often record important runtime information in logs to helpwith troubleshooting. Log-based anomaly detection has become a key researcharea that aims to identify system issues through log data, ultimately enhancingthe reliability of software systems. Traditional deep learning methods oftenstruggle to capture the semantic information embedded in log data, which istypically organized in natural language. In this paper, we propose LogLLM, alog-based anomaly detection framework that leverages large language models(LLMs). LogLLM employs BERT for extracting semantic vectors from log messages,while utilizing Llama, a transformer decoder-based model, for classifying logsequences. Additionally, we introduce a projector to align the vectorrepresentation spaces of BERT and Llama, ensuring a cohesive understanding oflog semantics. Unlike conventional methods that require log parsers to extracttemplates, LogLLM preprocesses log messages with regular expressions,streamlining the entire process. Our framework is trained through a novelthree-stage procedure designed to enhance performance and adaptability.Experimental results across four public datasets demonstrate that LogLLMoutperforms state-of-the-art methods. Even when handling unstable logs, iteffectively captures the semantic meaning of log messages and detects anomaliesaccurately.</description><author>Wei Guan, Jian Cao, Shiyou Qian, Jianqi Gao, Chun Ouyang</author><pubDate>Wed, 29 Jan 2025 15:41:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.08561v3</guid></item><item><title>Learning Semantic Facial Descriptors for Accurate Face Animation</title><link>http://arxiv.org/abs/2501.17718v1</link><description>Face animation is a challenging task. Existing model-based methods (utilizing3DMMs or landmarks) often result in a model-like reconstruction effect, whichdoesn't effectively preserve identity. Conversely, model-free approaches facechallenges in attaining a decoupled and semantically rich feature space,thereby making accurate motion transfer difficult to achieve. We introduce thesemantic facial descriptors in learnable disentangled vector space to addressthe dilemma. The approach involves decoupling the facial space into identityand motion subspaces while endowing each of them with semantics by learningcomplete orthogonal basis vectors. We obtain basis vector coefficients byemploying an encoder on the source and driving faces, leading to effectivefacial descriptors in the identity and motion subspaces. Ultimately, thesedescriptors can be recombined as latent codes to animate faces. Our approachsuccessfully addresses the issue of model-based methods' limitations inhigh-fidelity identity and the challenges faced by model-free methods inaccurate motion transfer. Extensive experiments are conducted on threechallenging benchmarks (i.e. VoxCeleb, HDTF, CelebV). Comprehensivequantitative and qualitative results demonstrate that our model outperformsSOTA methods with superior identity preservation and motion transfer.</description><author>Lei Zhu, Yuanqi Chen, Xiaohang Liu, Thomas H. Li, Ge Li</author><pubDate>Wed, 29 Jan 2025 15:40:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17718v1</guid></item><item><title>Gradient-free training of recurrent neural networks</title><link>http://arxiv.org/abs/2410.23467v2</link><description>Recurrent neural networks are a successful neural architecture for manytime-dependent problems, including time series analysis, forecasting, andmodeling of dynamical systems. Training such networks with backpropagationthrough time is a notoriously difficult problem because their loss gradientstend to explode or vanish. In this contribution, we introduce a computationalapproach to construct all weights and biases of a recurrent neural networkwithout using gradient-based methods. The approach is based on a combination ofrandom feature networks and Koopman operator theory for dynamical systems. Thehidden parameters of a single recurrent block are sampled at random, while theouter weights are constructed using extended dynamic mode decomposition. Thisapproach alleviates all problems with backpropagation commonly related torecurrent networks. The connection to Koopman operator theory also allows us tostart using results in this area to analyze recurrent neural networks. Incomputational experiments on time series, forecasting for chaotic dynamicalsystems, and control problems, as well as on weather data, we observe that thetraining time and forecasting accuracy of the recurrent neural networks weconstruct are improved when compared to commonly used gradient-based methods.</description><author>Erik Lien Bolager, Ana Cukarska, Iryna Burak, Zahra Monfared, Felix Dietrich</author><pubDate>Wed, 29 Jan 2025 15:39:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.23467v2</guid></item><item><title>Towards Lifelong Dialogue Agents via Timeline-based Memory Management</title><link>http://arxiv.org/abs/2406.10996v3</link><description>To achieve lifelong human-agent interaction, dialogue agents need toconstantly memorize perceived information and properly retrieve it for responsegeneration (RG). While prior studies focus on getting rid of outdated memoriesto improve retrieval quality, we argue that such memories provide rich,important contextual cues for RG (e.g., changes in user behaviors) in long-termconversations. We present THEANINE, a framework for LLM-based lifelong dialogueagents. THEANINE discards memory removal and manages large-scale memories bylinking them based on their temporal and cause-effect relation. Enabled by thislinking structure, THEANINE augments RG with memory timelines - series ofmemories representing the evolution or causality of relevant past events. Alongwith THEANINE, we introduce TeaFarm, a counterfactual-driven evaluation scheme,addressing the limitation of G-Eval and human efforts when assessing agentperformance in integrating past memories into RG. A supplementary video forTHEANINE and data for TeaFarm are athttps://huggingface.co/spaces/ResearcherScholar/Theanine.</description><author>Kai Tzu-iunn Ong, Namyoung Kim, Minju Gwak, Hyungjoo Chae, Taeyoon Kwon, Yohan Jo, Seung-won Hwang, Dongha Lee, Jinyoung Yeo</author><pubDate>Wed, 29 Jan 2025 15:34:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10996v3</guid></item><item><title>RICoTA: Red-teaming of In-the-wild Conversation with Test Attempts</title><link>http://arxiv.org/abs/2501.17715v1</link><description>User interactions with conversational agents (CAs) evolve in the era ofheavily guardrailed large language models (LLMs). As users push beyondprogrammed boundaries to explore and build relationships with these systems,there is a growing concern regarding the potential for unauthorized access ormanipulation, commonly referred to as "jailbreaking." Moreover, with CAs thatpossess highly human-like qualities, users show a tendency toward initiatingintimate sexual interactions or attempting to tame their chatbots. To captureand reflect these in-the-wild interactions into chatbot designs, we proposeRICoTA, a Korean red teaming dataset that consists of 609 prompts challengingLLMs with in-the-wild user-made dialogues capturing jailbreak attempts. Weutilize user-chatbot conversations that were self-posted on a KoreanReddit-like community, containing specific testing and gaming intentions with asocial chatbot. With these prompts, we aim to evaluate LLMs' ability toidentify the type of conversation and users' testing purposes to derive chatbotdesign implications for mitigating jailbreaking risks. Our dataset will be madepublicly available via GitHub.</description><author>Eujeong Choi, Younghun Jeong, Soomin Kim, Won Ik Cho</author><pubDate>Wed, 29 Jan 2025 15:32:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17715v1</guid></item><item><title>STGCN-LSTM for Olympic Medal Prediction: Dynamic Power Modeling and Causal Policy Optimization</title><link>http://arxiv.org/abs/2501.17711v1</link><description>This paper proposes a novel hybrid model, STGCN-LSTM, to forecast Olympicmedal distributions by integrating the spatio-temporal relationships amongcountries and the long-term dependencies of national performance. TheSpatial-Temporal Graph Convolution Network (STGCN) captures geographic andinteractive factors-such as coaching exchange and socio-economic links-whilethe Long Short-Term Memory (LSTM) module models historical trends in medalcounts, economic data, and demographics. To address zero-inflated outputs(i.e., the disparity between countries that consistently yield wins and thosenever having won medals), a Zero-Inflated Compound Poisson (ZICP) framework isincorporated to separate random zeros from structural zeros, providing aclearer view of potential breakthrough performances. Validation includeshistorical backtracking, policy shock simulations, and causal inference checks,confirming the robustness of the proposed method. Results shed light on theinfluence of coaching mobility, event specialization, and strategic investmenton medal forecasts, offering a data-driven foundation for optimizing sportspolicies and resource allocation in diverse Olympic contexts.</description><author>Yiquan Wang, Jiaying Wang, Jingyi Yang, Zihao Xu</author><pubDate>Wed, 29 Jan 2025 15:28:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17711v1</guid></item><item><title>Inferring Implicit Goals Across Differing Task Models</title><link>http://arxiv.org/abs/2501.17704v1</link><description>One of the significant challenges to generating value-aligned behavior is tonot only account for the specified user objectives but also any implicit orunspecified user requirements. The existence of such implicit requirementscould be particularly common in settings where the user's understanding of thetask model may differ from the agent's estimate of the model. Under thisscenario, the user may incorrectly expect some agent behavior to be inevitableor guaranteed. This paper addresses such expectation mismatch in the presenceof differing models by capturing the possibility of unspecified user subgoal inthe context of a task captured as a Markov Decision Process (MDP) and queryingfor it as required. Our method identifies bottleneck states and uses them ascandidates for potential implicit subgoals. We then introduce a queryingstrategy that will generate the minimal number of queries required to identifya policy guaranteed to achieve the underlying goal. Our empirical evaluationsdemonstrate the effectiveness of our approach in inferring and achievingunstated goals across various tasks.</description><author>Silvia Tulli, Stylianos Loukas Vasileiou, Mohamed Chetouani, Sarath Sreedharan</author><pubDate>Wed, 29 Jan 2025 15:20:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17704v1</guid></item><item><title>Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate</title><link>http://arxiv.org/abs/2501.17703v1</link><description>Supervised Fine-Tuning (SFT) is commonly used to train language models toimitate annotated responses for given instructions. In this paper, we challengethis paradigm and propose Critique Fine-Tuning (CFT), a strategy where modelslearn to critique noisy responses rather than simply imitate correct ones.Inspired by human learning processes that emphasize critical thinking, CFTencourages deeper analysis and nuanced understanding-traits often overlooked bystandard SFT. To validate the effectiveness of CFT, we construct a 50K-sampledataset from WebInstruct, using GPT-4o as the teacher to generate critiques inthe form of (input=[query; noisy response], output=critique). CFT on thisdataset yields a consistent 4-10% improvement over SFT on six math benchmarkswith different base models like Qwen2.5, Qwen2.5-Math and DeepSeek-Math. Wefurther expand to MetaMath and NuminaMath datasets and observe similar gainsover SFT. Notably, our Qwen2.5-Math-CFT model-trained on just 50Ksamples-matches or outperforms competitive models such as AceMath andQwen2.5-Math-Instruct on most benchmarks, both of which use over 2M samples.Ablation studies show that CFT is robust to the source of noisy response andteacher critique model. Through these findings, we argue that critique-basedtraining offers a more effective alternative to advance the reasoning oflanguage models.</description><author>Yubo Wang, Xiang Yue, Wenhu Chen</author><pubDate>Wed, 29 Jan 2025 15:20:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17703v1</guid></item><item><title>Decision-Theoretic Approaches in Learning-Augmented Algorithms</title><link>http://arxiv.org/abs/2501.17701v1</link><description>In this work, we initiate the systemic study of decision-theoretic metrics inthe design and analysis of algorithms with machine-learned predictions. Weintroduce approaches based on both deterministic measures such asdistance-based evaluation, that help us quantify how close the algorithm is toan ideal solution, as well as stochastic measures that allow us to balance thetrade-off between the algorithm's performance and the risk associated with theimperfect oracle. These approaches help us quantify the algorithmic performanceacross the entire spectrum of prediction error, unlike several previous worksthat focus on few, and often extreme values of the error. We apply thesetechniques to two well-known problems from resource allocation and onlinedecision making, namely contract scheduling and 1-max search.</description><author>Spyros Angelopoulos, Christoph Dürr, Georgii Melidi</author><pubDate>Wed, 29 Jan 2025 15:16:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17701v1</guid></item><item><title>SynthFormer: Equivariant Pharmacophore-based Generation of Synthesizable Molecules for Ligand-Based Drug Design</title><link>http://arxiv.org/abs/2410.02718v2</link><description>Drug discovery is a complex, resource-intensive process requiring significanttime and cost to bring new medicines to patients. Many generative models aim toaccelerate drug discovery, but few produce synthetically accessible molecules.Conversely, synthesis-focused models do not leverage the 3D information crucialfor effective drug design. We introduce SynthFormer, a novel machine learningmodel that generates fully synthesizable molecules, structured as synthetictrees, by introducing both 3D information and pharmacophores as input.SynthFormer features a 3D equivariant graph neural network to encodepharmacophores, followed by a Transformer-based synthesis-aware decodingmechanism for constructing synthetic trees as a sequence of tokens. It is afirst-of-its-kind approach that could provide capabilities for designing activemolecules based on pharmacophores, exploring the local synthesizable chemicalspace around hit molecules and optimizing their properties. We demonstrate itseffectiveness through various challenging tasks, including designing activecompounds for a range of proteins, performing hit expansion and optimizingmolecular properties.</description><author>Zygimantas Jocys, Zhanxing Zhu, Henriette M. G. Willems, Katayoun Farrahi</author><pubDate>Wed, 29 Jan 2025 15:15:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02718v2</guid></item><item><title>PulmoFusion: Advancing Pulmonary Health with Efficient Multi-Modal Fusion</title><link>http://arxiv.org/abs/2501.17699v1</link><description>Traditional remote spirometry lacks the precision required for effectivepulmonary monitoring. We present a novel, non-invasive approach usingmultimodal predictive models that integrate RGB or thermal video data withpatient metadata. Our method leverages energy-efficient Spiking Neural Networks(SNNs) for the regression of Peak Expiratory Flow (PEF) and classification ofForced Expiratory Volume (FEV1) and Forced Vital Capacity (FVC), usinglightweight CNNs to overcome SNN limitations in regression tasks. Multimodaldata integration is improved with a Multi-Head Attention Layer, and we employK-Fold validation and ensemble learning to boost robustness. Using thermaldata, our SNN models achieve 92% accuracy on a breathing-cycle basis and 99.5%patient-wise. PEF regression models attain Relative RMSEs of 0.11 (thermal) and0.26 (RGB), with an MAE of 4.52% for FEV1/FVC predictions, establishingstate-of-the-art performance. Code and dataset can be found onhttps://github.com/ahmed-sharshar/RespiroDynamics.git</description><author>Ahmed Sharshar, Yasser Attia, Mohammad Yaqub, Mohsen Guizani</author><pubDate>Wed, 29 Jan 2025 15:10:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17699v1</guid></item><item><title>Generalizable, Fast, and Accurate DeepQSPR with fastprop</title><link>http://arxiv.org/abs/2404.02058v5</link><description>Quantitative Structure Property Relationship studies aim to define a mappingbetween molecular structure and arbitrary quantities of interest. This washistorically accomplished via the development of descriptors which requiressignificant domain expertise and struggles to generalize. Thus the field hasmorphed into Molecular Property Prediction and been given over to learnedrepresentations which are highly generalizable. The paper introduces fastprop,a DeepQSPR framework which uses a cogent set of molecular level descriptors tomeet and exceed the performance of learned representations on diverse datasetsin dramatically less time. fastprop is freely available on github atgithub.com/JacksonBurns/fastprop.</description><author>Jackson Burns, William Green</author><pubDate>Wed, 29 Jan 2025 15:00:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02058v5</guid></item><item><title>Segmentation-Aware Generative Reinforcement Network (GRN) for Tissue Layer Segmentation in 3-D Ultrasound Images for Chronic Low-back Pain (cLBP) Assessment</title><link>http://arxiv.org/abs/2501.17690v1</link><description>We introduce a novel segmentation-aware joint training framework calledgenerative reinforcement network (GRN) that integrates segmentation lossfeedback to optimize both image generation and segmentation performance in asingle stage. An image enhancement technique called segmentation-guidedenhancement (SGE) is also developed, where the generator produces imagestailored specifically for the segmentation model. Two variants of GRN were alsodeveloped, including GRN for sample-efficient learning (GRN-SEL) and GRN forsemi-supervised learning (GRN-SSL). GRN's performance was evaluated using adataset of 69 fully annotated 3D ultrasound scans from 29 subjects. Theannotations included six anatomical structures: dermis, superficial fat,superficial fascial membrane (SFM), deep fat, deep fascial membrane (DFM), andmuscle. Our results show that GRN-SEL with SGE reduces labeling efforts by upto 70% while achieving a 1.98% improvement in the Dice Similarity Coefficient(DSC) compared to models trained on fully labeled datasets. GRN-SEL alonereduces labeling efforts by 60%, GRN-SSL with SGE decreases labelingrequirements by 70%, and GRN-SSL alone by 60%, all while maintainingperformance comparable to fully supervised models. These findings suggest theeffectiveness of the GRN framework in optimizing segmentation performance withsignificantly less labeled data, offering a scalable and efficient solution forultrasound image analysis and reducing the burdens associated with dataannotation.</description><author>Zixue Zeng, Xiaoyan Zhao, Matthew Cartier, Tong Yu, Jing Wang, Xin Meng, Zhiyu Sheng, Maryam Satarpour, John M Cormack, Allison Bean, Ryan Nussbaum, Maya Maurer, Emily Landis-Walkenhorst, Dinesh Kumbhare, Kang Kim, Ajay Wasan, Jiantao Pu</author><pubDate>Wed, 29 Jan 2025 14:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17690v1</guid></item><item><title>Machine-Learning-Enhanced Optimization of Noise-Resilient Variational Quantum Eigensolvers</title><link>http://arxiv.org/abs/2501.17689v1</link><description>Variational Quantum Eigensolvers (VQEs) are a powerful class of hybridquantum-classical algorithms designed to approximate the ground state of aquantum system described by its Hamiltonian. VQEs hold promise for variousapplications, including lattice field theory. However, the inherent noise ofNoisy Intermediate-Scale Quantum (NISQ) devices poses a significant challengefor running VQEs as these algorithms are particularly susceptible to noise,e.g., measurement shot noise and hardware noise. In a recent work, it was proposed to enhance the classical optimization ofVQEs with Gaussian Processes (GPs) and Bayesian Optimization, as thesemachine-learning techniques are well-suited for handling noisy data. In theseproceedings, we provide additional insights into this new algorithm and presentfurther numerical experiments. In particular, we examine the impact of hardwarenoise and error mitigation on the algorithm's performance. We validate thealgorithm using classical simulations of quantum hardware, including hardwarenoise benchmarks, which have not been considered in previous works. Ournumerical experiments demonstrate that GP-enhanced algorithms can outperformstate-of-the-art baselines, laying the foundation for future research ondeploying these techniques to real quantum hardware and lattice field theorysetups.</description><author>Kim A. Nicoli, Luca J. Wagner, Lena Funcke</author><pubDate>Wed, 29 Jan 2025 14:56:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17689v1</guid></item><item><title>ContourFormer:Real-Time Contour-Based End-to-End Instance Segmentation Transformer</title><link>http://arxiv.org/abs/2501.17688v1</link><description>This paper presents Contourformer, a real-time contour-based instancesegmentation algorithm. The method is fully based on the DETR paradigm andachieves end-to-end inference through iterative and progressive mechanisms tooptimize contours. To improve efficiency and accuracy, we develop two noveltechniques: sub-contour decoupling mechanisms and contour fine-graineddistribution refinement.In the sub-contour decoupling mechanism, we propose adeformable attention-based module that adaptively selects sampling regionsbased on the current predicted contour, enabling more effective capturing ofobject boundary information. Additionally, we design a multi-stage optimizationprocess to enhance segmentation precision by progressively refiningsub-contours. The contour fine-grained distribution refinement technique aimsto further improve the ability to express fine details of contours.Theseinnovations enable Contourformer to achieve stable and precise segmentation foreach instance while maintaining real-time performance. Extensive experimentsdemonstrate the superior performance of Contourformer on multiple benchmarkdatasets, including SBD, COCO, and KINS. We conduct comprehensive evaluationsand comparisons with existing state-of-the-art methods, showing significantimprovements in both accuracy and inference speed.This work provides a newsolution for contour-based instance segmentation tasks and lays a foundationfor future research, with the potential to become a strong baseline method inthis field.</description><author>Weiwei yao, Chen Li, Minjun Xiong, Wenbo Dong, Hao Chen, Xiong Xiao</author><pubDate>Wed, 29 Jan 2025 14:56:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17688v1</guid></item><item><title>Continuously Learning New Words in Automatic Speech Recognition</title><link>http://arxiv.org/abs/2401.04482v4</link><description>Despite recent advances, Automatic Speech Recognition (ASR) systems are stillfar from perfect. Typical errors include acronyms, named entities, anddomain-specific special words for which little or no labeled data is available.To address the problem of recognizing these words, we propose a self-supervisedcontinual learning approach: Given the audio of a lecture talk with thecorresponding slides, we bias the model towards decoding new words from theslides by using a memory-enhanced ASR model from the literature. Then, weperform inference on the talk, collecting utterances that contain detected newwords into an adaptation data set. Continual learning is then performed bytraining adaptation weights added to the model on this data set. The wholeprocedure is iterated for many talks. We show that with this approach, weobtain increasing performance on the new words when they occur more frequently(more than 80% recall) while preserving the general performance of the model.</description><author>Christian Huber, Alexander Waibel</author><pubDate>Wed, 29 Jan 2025 14:55:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04482v4</guid></item><item><title>Spatial Adaptation Layer: Interpretable Domain Adaptation For Biosignal Sensor Array Applications</title><link>http://arxiv.org/abs/2409.08058v2</link><description>Machine learning offers promising methods for processing signals recordedwith wearable devices such as surface electromyography (sEMG) andelectroencephalography (EEG). However, in these applications, despite highwithin-session performance, intersession performance is hindered by electrodeshift, a known issue across modalities. Existing solutions often require largeand expensive datasets and/or lack robustness and interpretability. Thus, wepropose the Spatial Adaptation Layer (SAL), which can be applied to anybiosignal array model and learns a parametrized affine transformation at theinput between two recording sessions. We also introduce learnable baselinenormalization (LBN) to reduce baseline fluctuations. Tested on two HD-sEMGgesture recognition datasets, SAL and LBN outperformed standard fine-tuning onregular arrays, achieving competitive performance even with a logisticregressor, with orders of magnitude less, physically interpretable parameters.Our ablation study showed that forearm circumferential translations account forthe majority of performance improvements.</description><author>Joao Pereira, Michael Alummoottil, Dimitrios Halatsis, Dario Farina</author><pubDate>Wed, 29 Jan 2025 14:50:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.08058v2</guid></item><item><title>Temperature-Free Loss Function for Contrastive Learning</title><link>http://arxiv.org/abs/2501.17683v1</link><description>As one of the most promising methods in self-supervised learning, contrastivelearning has achieved a series of breakthroughs across numerous fields. Apredominant approach to implementing contrastive learning is applying InfoNCEloss: By capturing the similarities between pairs, InfoNCE loss enableslearning the representation of data. Albeit its success, adopting InfoNCE lossrequires tuning a temperature, which is a core hyperparameter for calibratingsimilarity scores. Despite its significance and sensitivity to performancebeing emphasized by several studies, searching for a valid temperature requiresextensive trial-and-error-based experiments, which increases the difficulty ofadopting InfoNCE loss. To address this difficulty, we propose a novel method todeploy InfoNCE loss without temperature. Specifically, we replace temperaturescaling with the inverse hyperbolic tangent function, resulting in a modifiedInfoNCE loss. In addition to hyperparameter-free deployment, we observed thatthe proposed method even yielded a performance gain in contrastive learning.Our detailed theoretical analysis discovers that the current practice oftemperature scaling in InfoNCE loss causes serious problems in gradientdescent, whereas our method provides desirable gradient properties. Theproposed method was validated on five benchmarks on contrastive learning,yielding satisfactory results without temperature tuning.</description><author>Bum Jun Kim, Sang Woo Kim</author><pubDate>Wed, 29 Jan 2025 14:43:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17683v1</guid></item><item><title>Algorithmic syntactic causal identification</title><link>http://arxiv.org/abs/2403.09580v2</link><description>Causal identification in causal Bayes nets (CBNs) is an important tool incausal inference allowing the derivation of interventional distributions fromobservational distributions where this is possible in principle. However, mostexisting formulations of causal identification using techniques such asd-separation and do-calculus are expressed within the mathematical language ofclassical probability theory on CBNs. However, there are many causal settingswhere probability theory and hence current causal identification techniques areinapplicable such as relational databases, dataflow programs such as hardwaredescription languages, distributed systems and most modern machine learningalgorithms. We show that this restriction can be lifted by replacing the use ofclassical probability theory with the alternative axiomatic foundation ofsymmetric monoidal categories. In this alternative axiomatization, we show howan unambiguous and clean distinction can be drawn between the general syntax ofcausal models and any specific semantic implementation of that causal model.This allows a purely syntactic algorithmic description of general causalidentification by a translation of recent formulations of the general IDalgorithm through fixing. Our description is given entirely in terms of thenon-parametric ADMG structure specifying a causal model and the algebraicsignature of the corresponding monoidal category, to which a sequence ofmanipulations is then applied so as to arrive at a modified monoidal categoryin which the desired, purely syntactic interventional causal model, isobtained. We use this idea to derive purely syntactic analogues of classicalback-door and front-door causal adjustment, and illustrate an application to amore complex causal model.</description><author>Dhurim Cakiqi, Max A. Little</author><pubDate>Wed, 29 Jan 2025 14:41:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09580v2</guid></item><item><title>Explainable Artificial Intelligence for identifying profitability predictors in Financial Statements</title><link>http://arxiv.org/abs/2501.17676v1</link><description>The interconnected nature of the economic variables influencing a firm'sperformance makes the prediction of a company's earning trend a challengingtask. Existing methodologies often rely on simplistic models and financialratios failing to capture the complexity of interacting influences. In thispaper, we apply Machine Learning techniques to raw financial statements datataken from AIDA, a Database comprising Italian listed companies' data from 2013to 2022. We present a comparative study of different models and following the EuropeanAI regulations, we complement our analysis by applying explainabilitytechniques to the proposed models. In particular, we propose adopting aneXplainable Artificial Intelligence method based on Game Theory to identify themost sensitive features and make the result more interpretable.</description><author>Marco Piazza, Mauro Passacantando, Francesca Magli, Federica Doni, Andrea Amaduzzi, Enza Messina</author><pubDate>Wed, 29 Jan 2025 14:33:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17676v1</guid></item><item><title>CLIP-Motion: Learning Reward Functions for Robotic Actions Using Consecutive Observations</title><link>http://arxiv.org/abs/2311.03485v2</link><description>This paper presents a novel method for learning reward functions for roboticmotions by harnessing the power of a CLIP-based model. Traditional rewardfunction design often hinges on manual feature engineering, which can struggleto generalize across an array of tasks. Our approach circumvents this challengeby capitalizing on CLIP's capability to process both state features and imageinputs effectively. Given a pair of consecutive observations, our model excelsin identifying the motion executed between them. We showcase results spanningvarious robotic activities, such as directing a gripper to a designated targetand adjusting the position of a cube. Through experimental evaluations, weunderline the proficiency of our method in precisely deducing motion and itspromise to enhance reinforcement learning training in the realm of robotics.</description><author>Xuzhe Dang, Stefan Edelkamp</author><pubDate>Wed, 29 Jan 2025 14:28:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03485v2</guid></item><item><title>AI-Assisted Human Evaluation of Machine Translation</title><link>http://arxiv.org/abs/2406.12419v3</link><description>Annually, research teams spend large amounts of money to evaluate the qualityof machine translation systems (WMT, inter alia). This is expensive because itrequires a lot of expert human labor. In the recently adopted annotationprotocol, Error Span Annotation (ESA), annotators mark erroneous parts of thetranslation and then assign a final score. A lot of the annotator time is spenton scanning the translation for possible errors. In our work, we help theannotators by pre-filling the error annotations with recall-oriented automaticquality estimation. With this AI assistance, we obtain annotations at the samequality level while cutting down the time per span annotation by half(71s/error span $\rightarrow$ 31s/error span). The biggest advantage of theESA$^\mathrm{AI}$ protocol is an accurate priming of annotators (pre-fillederror spans) before they assign the final score. This alleviates a potentialautomation bias, which we confirm to be low. In our experiments, we find thatthe annotation budget can be further reduced by almost 25% with filtering ofexamples that the AI deems to be likely to be correct.</description><author>Vilém Zouhar, Tom Kocmi, Mrinmaya Sachan</author><pubDate>Wed, 29 Jan 2025 14:21:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12419v3</guid></item><item><title>Deterministic and statistical calibration of constitutive models from full-field data with parametric physics-informed neural networks</title><link>http://arxiv.org/abs/2405.18311v2</link><description>The calibration of constitutive models from full-field data has recentlygained increasing interest due to improvements in full-field measurementcapabilities. In addition to the experimental characterization of novelmaterials, continuous structural health monitoring is another application thatis of great interest. However, monitoring is usually associated with severetime constraints, difficult to meet with standard numerical approaches.Therefore, parametric physics-informed neural networks (PINNs) for constitutivemodel calibration from full-field displacement data are investigated. In anoffline stage, a parametric PINN can be trained to learn a parameterizedsolution of the underlying partial differential equation. In the subsequentonline stage, the parametric PINN then acts as a surrogate for theparameters-to-state map in calibration. We test the proposed approach for thedeterministic least-squares calibration of a linear elastic as well as ahyperelastic constitutive model from noisy synthetic displacement data. Wefurther carry out Markov chain Monte Carlo-based Bayesian inference to quantifythe uncertainty. A proper statistical evaluation of the results underlines thehigh accuracy of the deterministic calibration and that the estimateduncertainty is valid. Finally, we consider experimental data and show that theresults are in good agreement with a finite element method-based calibration.Due to the fast evaluation of PINNs, calibration can be performed in nearreal-time. This advantage is particularly evident in many-query applicationssuch as Markov chain Monte Carlo-based Bayesian inference.</description><author>David Anton, Jendrik-Alexander Tröger, Henning Wessels, Ulrich Römer, Alexander Henkes, Stefan Hartmann</author><pubDate>Wed, 29 Jan 2025 14:21:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18311v2</guid></item><item><title>Boosting Federated Learning with FedEntOpt: Mitigating Label Skew by Entropy-Based Client Selection</title><link>http://arxiv.org/abs/2411.01240v2</link><description>Deep learning is an emerging field revolutionizing various industries,including natural language processing, computer vision, and many more. Thesedomains typically require an extensive amount of data for optimal performance,potentially utilizing huge centralized data repositories. However, suchcentralization could raise privacy issues concerning the storage of sensitivedata. To address this issue, federated learning was developed. It is a newlydistributed learning technique that enables to collaboratively train a deeplearning model on decentralized devices, referred to as clients, withoutcompromising their data privacy. Traditional federated learning methods oftensuffer from severe performance degradation when the data distribution amongclients differs significantly. This becomes especially problematic in the caseof label distribution skew, where the distribution of labels varies acrossclients. To address this, a novel method called FedEntOpt is proposed.FedEntOpt is designed to mitigate performance issues caused by labeldistribution skew by maximizing the entropy of the global label distribution ofthe selected client subset in each federated learning round. This ensures thatthe aggregated model parameters from the clients were exhibited to data fromall available labels, which improves the accuracy of the global model.Extensive experiments on multiple benchmark datasets show that the proposedmethod outperforms several state-of-the-art algorithms by up to 6\% inclassification accuracy under standard settings regardless of the model size.Moreover, it exhibits robust and superior performance in scenarios with lowparticipation rates and client dropout, achieving increases in classificationaccuracy of over 30\%. In addition, FedEntOpt offers the flexibility to becombined with existing algorithms, enhancing their performance by over 40\%.</description><author>Andreas Lutz, Gabriele Steidl, Karsten Müller, Wojciech Samek</author><pubDate>Wed, 29 Jan 2025 14:17:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.01240v2</guid></item><item><title>Conjuring Semantic Similarity</title><link>http://arxiv.org/abs/2410.16431v2</link><description>The semantic similarity between sample expressions measures the distancebetween their latent 'meaning'. Such meanings are themselves typicallyrepresented by textual expressions, often insufficient to differentiateconcepts at fine granularity. We propose a novel approach whereby the semanticsimilarity among textual expressions is based not on other expressions they canbe rephrased as, but rather based on the imagery they evoke. While this is notpossible with humans, generative models allow us to easily visualize andcompare generated images, or their distribution, evoked by a textual prompt.Therefore, we characterize the semantic similarity between two textualexpressions simply as the distance between image distributions they induce, or'conjure.' We show that by choosing the Jensen-Shannon divergence between thereverse-time diffusion stochastic differential equations (SDEs) induced by eachtextual expression, this can be directly computed via Monte-Carlo sampling. Ourmethod contributes a novel perspective on semantic similarity that not onlyaligns with human-annotated scores, but also opens up new avenues for theevaluation of text-conditioned generative models while offering betterinterpretability of their learnt representations.</description><author>Tian Yu Liu, Stefano Soatto</author><pubDate>Wed, 29 Jan 2025 14:14:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.16431v2</guid></item><item><title>TUNeS: A Temporal U-Net with Self-Attention for Video-based Surgical Phase Recognition</title><link>http://arxiv.org/abs/2307.09997v6</link><description>Objective: To enable context-aware computer assistance in the operating roomof the future, cognitive systems need to understand automatically whichsurgical phase is being performed by the medical team. The primary source ofinformation for surgical phase recognition is typically video, which presentstwo challenges: extracting meaningful features from the video stream andeffectively modeling temporal information in the sequence of visual features.Methods: For temporal modeling, attention mechanisms have gained popularity dueto their ability to capture long-range dependencies. In this paper, we exploredesign choices for attention in existing temporal models for surgical phaserecognition and propose a novel approach that uses attention more effectivelyand does not require hand-crafted constraints: TUNeS, an efficient and simpletemporal model that incorporates self-attention at the core of a convolutionalU-Net structure. In addition, we propose to train the feature extractor, astandard CNN, together with an LSTM on preferably long video segments, i.e.,with long temporal context. Results: In our experiments, almost all temporalmodels performed better on top of feature extractors that were trained withlonger temporal context. On these contextualized features, TUNeS achievesstate-of-the-art results on the Cholec80 dataset. Conclusion: This study offersnew insights on how to use attention mechanisms to build accurate and efficienttemporal models for surgical phase recognition. Significance: Implementingautomatic surgical phase recognition is essential to automate the analysis andoptimization of surgical workflows and to enable context-aware computerassistance during surgery, thus ultimately improving patient care.</description><author>Isabel Funke, Dominik Rivoir, Stefanie Krell, Stefanie Speidel</author><pubDate>Wed, 29 Jan 2025 14:10:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09997v6</guid></item><item><title>CAMP in the Odyssey: Provably Robust Reinforcement Learning with Certified Radius Maximization</title><link>http://arxiv.org/abs/2501.17667v1</link><description>Deep reinforcement learning (DRL) has gained widespread adoption in controland decision-making tasks due to its strong performance in dynamicenvironments. However, DRL agents are vulnerable to noisy observations andadversarial attacks, and concerns about the adversarial robustness of DRLsystems have emerged. Recent efforts have focused on addressing theserobustness issues by establishing rigorous theoretical guarantees for thereturns achieved by DRL agents in adversarial settings. Among these approaches,policy smoothing has proven to be an effective and scalable method forcertifying the robustness of DRL agents. Nevertheless, existing certifiablyrobust DRL relies on policies trained with simple Gaussian augmentations,resulting in a suboptimal trade-off between certified robustness and certifiedreturn. To address this issue, we introduce a novel paradigm dubbed\texttt{C}ertified-r\texttt{A}dius-\texttt{M}aximizing \texttt{P}olicy(\texttt{CAMP}) training. \texttt{CAMP} is designed to enhance DRL policies,achieving better utility without compromising provable robustness. Byleveraging the insight that the global certified radius can be derived fromlocal certified radii based on training-time statistics, \texttt{CAMP}formulates a surrogate loss related to the local certified radius and optimizesthe policy guided by this surrogate loss. We also introduce \textit{policyimitation} as a novel technique to stabilize \texttt{CAMP} training.Experimental results demonstrate that \texttt{CAMP} significantly improves therobustness-return trade-off across various tasks. Based on the results,\texttt{CAMP} can achieve up to twice the certified expected return compared tothat of baselines. Our code is available athttps://github.com/NeuralSec/camp-robust-rl.</description><author>Derui Wang, Kristen Moore, Diksha Goel, Minjune Kim, Gang Li, Yang Li, Robin Doss, Minhui Xue, Bo Li, Seyit Camtepe, Liming Zhu</author><pubDate>Wed, 29 Jan 2025 14:08:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17667v1</guid></item><item><title>Planning with Vision-Language Models and a Use Case in Robot-Assisted Teaching</title><link>http://arxiv.org/abs/2501.17665v1</link><description>Automating the generation of Planning Domain Definition Language (PDDL) withLarge Language Model (LLM) opens new research topic in AI planning,particularly for complex real-world tasks. This paper introduces Image2PDDL, anovel framework that leverages Vision-Language Models (VLMs) to automaticallyconvert images of initial states and descriptions of goal states into PDDLproblems. By providing a PDDL domain alongside visual inputs, Imasge2PDDLaddresses key challenges in bridging perceptual understanding with symbolicplanning, reducing the expertise required to create structured probleminstances, and improving scalability across tasks of varying complexity. Weevaluate the framework on various domains, including standard planning domainslike blocksworld and sliding tile puzzles, using datasets with multipledifficulty levels. Performance is assessed on syntax correctness, ensuringgrammar and executability, and content correctness, verifying accurate staterepresentation in generated PDDL problems. The proposed approach demonstratespromising results across diverse task complexities, suggesting its potentialfor broader applications in AI planning. We will discuss a potential use casein robot-assisted teaching of students with Autism Spectrum Disorder.</description><author>Xuzhe Dang, Lada Kudláčková, Stefan Edelkamp</author><pubDate>Wed, 29 Jan 2025 14:04:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.17665v1</guid></item></channel></rss>