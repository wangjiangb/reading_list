<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 07 Nov 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Exploitation-Guided Exploration for Semantic Embodied Navigation</title><link>http://arxiv.org/abs/2311.03357v1</link><description>In the recent progress in embodied navigation and sim-to-robot transfer,modular policies have emerged as a de facto framework. However, there is moreto compositionality beyond the decomposition of the learning load into modularcomponents. In this work, we investigate a principled way to syntacticallycombine these components. Particularly, we propose Exploitation-GuidedExploration (XGX) where separate modules for exploration and exploitation cometogether in a novel and intuitive manner. We configure the exploitation moduleto take over in the deterministic final steps of navigation i.e. when the goalbecomes visible. Crucially, an exploitation module teacher-forces theexploration module and continues driving an overridden policy optimization.XGX, with effective decomposition and novel guidance, improves thestate-of-the-art performance on the challenging object navigation task from 70%to 73%. Along with better accuracy, through targeted analysis, we show that XGXis also more efficient at goal-conditioned exploration. Finally, we showsim-to-real transfer to robot hardware and XGX performs over two-fold betterthan the best baseline from simulation benchmarking. Project page:xgxvisnav.github.io</description><author>Justin Wasserman, Girish Chowdhary, Abhinav Gupta, Unnat Jain</author><pubDate>Mon, 06 Nov 2023 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03357v1</guid></item><item><title>GLaMM: Pixel Grounding Large Multimodal Model</title><link>http://arxiv.org/abs/2311.03356v1</link><description>Large Multimodal Models (LMMs) extend Large Language Models to the visiondomain. Initial efforts towards LMMs used holistic images and text prompts togenerate ungrounded textual responses. Very recently, region-level LMMs havebeen used to generate visually grounded responses. However, they are limited toonly referring a single object category at a time, require users to specify theregions in inputs, or cannot offer dense pixel-wise object grounding. In thiswork, we present Grounding LMM (GLaMM), the first model that can generatenatural language responses seamlessly intertwined with corresponding objectsegmentation masks. GLaMM not only grounds objects appearing in theconversations but is flexible enough to accept both textual and optional visualprompts (region of interest) as input. This empowers users to interact with themodel at various levels of granularity, both in textual and visual domains. Dueto the lack of standard benchmarks for the novel setting of generating visuallygrounded detailed conversations, we introduce a comprehensive evaluationprotocol with our curated grounded conversations. Our proposed GroundedConversation Generation (GCG) task requires densely grounded concepts innatural scenes at a large-scale. To this end, we propose a densely annotatedGrounding-anything Dataset (GranD) using our proposed automated annotationpipeline that encompasses 7.5M unique concepts grounded in a total of 810Mregions available with segmentation masks. Besides GCG, GLaMM also performseffectively on several downstream tasks e.g., referring expressionsegmentation, image and region-level captioning and vision-languageconversations. Project Page: https://mbzuai-oryx.github.io/groundingLMM.</description><author>Hanoona Rasheed, Muhammad Maaz, Sahal Shaji, Abdelrahman Shaker, Salman Khan, Hisham Cholakkal, Rao M. Anwer, Erix Xing, Ming-Hsuan Yang, Fahad S. Khan</author><pubDate>Mon, 06 Nov 2023 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03356v1</guid></item><item><title>SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img Synthesis</title><link>http://arxiv.org/abs/2311.03355v1</link><description>We propose SegGen, a highly-effective training data generation method forimage segmentation, which pushes the performance limits of state-of-the-artsegmentation models to a significant extent. SegGen designs and integrates twodata generation strategies: MaskSyn and ImgSyn. (i) MaskSyn synthesizes newmask-image pairs via our proposed text-to-mask generation model andmask-to-image generation model, greatly improving the diversity in segmentationmasks for model supervision; (ii) ImgSyn synthesizes new images based onexisting masks using the mask-to-image generation model, strongly improvingimage diversity for model inputs. On the highly competitive ADE20K and COCObenchmarks, our data generation method markedly improves the performance ofstate-of-the-art segmentation models in semantic segmentation, panopticsegmentation, and instance segmentation. Notably, in terms of the ADE20K mIoU,Mask2Former R50 is largely boosted from 47.2 to 49.9 (+2.7); Mask2Former Swin-Lis also significantly increased from 56.1 to 57.4 (+1.3). These promisingresults strongly suggest the effectiveness of our SegGen even when abundanthuman-annotated training data is utilized. Moreover, training with oursynthetic data makes the segmentation models more robust towards unseendomains. Project website: https://seggenerator.github.io</description><author>Hanrong Ye, Jason Kuen, Qing Liu, Zhe Lin, Brian Price, Dan Xu</author><pubDate>Mon, 06 Nov 2023 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03355v1</guid></item><item><title>CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding</title><link>http://arxiv.org/abs/2311.03354v1</link><description>A remarkable ability of human beings resides in compositional reasoning,i.e., the capacity to make "infinite use of finite means". However, currentlarge vision-language foundation models (VLMs) fall short of such compositionalabilities due to their "bag-of-words" behaviors and inability to constructwords that correctly represent visual entities and the relations among theentities. To this end, we propose CoVLM, which can guide the LLM to explicitlycompose visual entities and relationships among the text and dynamicallycommunicate with the vision encoder and detection network to achievevision-language communicative decoding. Specifically, we first devise a set ofnovel communication tokens for the LLM, for dynamic communication between thevisual detection system and the language system. A communication token isgenerated by the LLM following a visual entity or a relation, to inform thedetection network to propose regions that are relevant to the sentencegenerated so far. The proposed regions-of-interests (ROIs) are then fed backinto the LLM for better language generation contingent on the relevant regions.The LLM is thus able to compose the visual entities and relationships throughthe communication tokens. The vision-to-language and language-to-visioncommunication are iteratively performed until the entire sentence is generated.Our framework seamlessly bridges the gap between visual perception and LLMs andoutperforms previous VLMs by a large margin on compositional reasoningbenchmarks (e.g., ~20% in HICO-DET mAP, ~14% in Cola top-1 accuracy, and ~3% onARO top-1 accuracy). We also achieve state-of-the-art performances ontraditional vision-language tasks such as referring expression comprehensionand visual question answering.</description><author>Junyan Li, Delin Chen, Yining Hong, Zhenfang Chen, Peihao Chen, Yikang Shen, Chuang Gan</author><pubDate>Mon, 06 Nov 2023 18:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03354v1</guid></item><item><title>Rethinking Evaluation Metrics of Open-Vocabulary Segmentaion</title><link>http://arxiv.org/abs/2311.03352v1</link><description>In this paper, we highlight a problem of evaluation metrics adopted in theopen-vocabulary segmentation. That is, the evaluation process still heavilyrelies on closed-set metrics on zero-shot or cross-dataset pipelines withoutconsidering the similarity between predicted and ground truth categories. Totackle this issue, we first survey eleven similarity measurements between twocategorical words using WordNet linguistics statistics, text embedding, andlanguage models by comprehensive quantitative analysis and user study. Builtupon those explored measurements, we designed novel evaluation metrics, namelyOpen mIoU, Open AP, and Open PQ, tailored for three open-vocabularysegmentation tasks. We benchmarked the proposed evaluation metrics on 12open-vocabulary methods of three segmentation tasks. Even though the relativesubjectivity of similarity distance, we demonstrate that our metrics can stillwell evaluate the open ability of the existing open-vocabulary segmentationmethods. We hope that our work can bring with the community new thinking abouthow to evaluate the open ability of models. The evaluation code is released ingithub.</description><author>Hao Zhou, Tiancheng Shen, Xu Yang, Hai Huang, Xiangtai Li, Lu Qi, Ming-Hsuan Yang</author><pubDate>Mon, 06 Nov 2023 18:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03352v1</guid></item><item><title>Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with Multi-Step On-Policy Optimization</title><link>http://arxiv.org/abs/2311.03351v1</link><description>Combining offline and online reinforcement learning (RL) is crucial forefficient and safe learning. However, previous approaches treat offline andonline learning as separate procedures, resulting in redundant designs andlimited performance. We ask: Can we achieve straightforward yet effectiveoffline and online learning without introducing extra conservatism orregularization? In this study, we propose Uni-o4, which utilizes an on-policyobjective for both offline and online learning. Owning to the alignment ofobjectives in two phases, the RL agent can transfer between offline and onlinelearning seamlessly. This property enhances the flexibility of the learningparadigm, allowing for arbitrary combinations of pretraining, fine-tuning,offline, and online learning. In the offline phase, specifically, Uni-o4leverages diverse ensemble policies to address the mismatch issues between theestimated behavior policy and the offline dataset. Through a simple offlinepolicy evaluation (OPE) approach, Uni-o4 can achieve multi-step policyimprovement safely. We demonstrate that by employing the method above, thefusion of these two paradigms can yield superior offline initialization as wellas stable and rapid online fine-tuning capabilities. Through real-world robottasks, we highlight the benefits of this paradigm for rapid deployment inchallenging, previously unseen real-world environments. Additionally, throughcomprehensive evaluations using numerous simulated benchmarks, we substantiatethat our method achieves state-of-the-art performance in both offline andoffline-to-online fine-tuning learning. Our website:https://lei-kun.github.io/uni-o4/ .</description><author>Kun Lei, Zhengmao He, Chenhao Lu, Kaizhe Hu, Yang Gao, Huazhe Xu</author><pubDate>Mon, 06 Nov 2023 18:58:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03351v1</guid></item><item><title>Monotone Learning</title><link>http://arxiv.org/abs/2202.05246v3</link><description>The amount of training-data is one of the key factors which determines thegeneralization capacity of learning algorithms. Intuitively, one expects theerror rate to decrease as the amount of training-data increases. Perhapssurprisingly, natural attempts to formalize this intuition give rise tointeresting and challenging mathematical questions. For example, in theirclassical book on pattern recognition, Devroye, Gyorfi, and Lugosi (1996) askwhether there exists a {monotone} Bayes-consistent algorithm. This questionremained open for over 25 years, until recently Pestov (2021) resolved it forbinary classification, using an intricate construction of a monotoneBayes-consistent algorithm. We derive a general result in multiclass classification, showing that everylearning algorithm A can be transformed to a monotone one with similarperformance. Further, the transformation is efficient and only uses a black-boxoracle access to A. This demonstrates that one can provably avoid non-monotonicbehaviour without compromising performance, thus answering questions asked byDevroye et al (1996), Viering, Mey, and Loog (2019), Viering and Loog (2021),and by Mhammedi (2021). Our transformation readily implies monotone learners in a variety ofcontexts: for example it extends Pestov's result to classification tasks withan arbitrary number of labels. This is in contrast with Pestov's work which istailored to binary classification. In addition, we provide uniform bounds on the error of the monotonealgorithm. This makes our transformation applicable in distribution-freesettings. For example, in PAC learning it implies that every learnable classadmits a monotone PAC learner. This resolves questions by Viering, Mey, andLoog (2019); Viering and Loog (2021); Mhammedi (2021).</description><author>Olivier Bousquet, Amit Daniely, Haim Kaplan, Yishay Mansour, Shay Moran, Uri Stemmer</author><pubDate>Mon, 06 Nov 2023 18:58:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.05246v3</guid></item><item><title>Differentiable Cutting-plane Layers for Mixed-integer Linear Optimization</title><link>http://arxiv.org/abs/2311.03350v1</link><description>We consider the problem of solving a family of parametric mixed-integerlinear optimization problems where some entries in the input data change. Weintroduce the concept of $cutting-plane$ $layer$ (CPL), $i.e.$, adifferentiable cutting-plane generator mapping the problem data and previousiterates to cutting planes. We propose a CPL implementation to generate splitcuts, and by combining several CPLs, we devise a differentiable cutting-planealgorithm that exploits the repeated nature of parametric instances. In anoffline phase, we train our algorithm by updating the parameters controllingthe CPLs, thus altering cut generation. Once trained, our algorithm computes,with predictable execution times and a fixed number of cuts, solutions with lowintegrality gaps. Preliminary computational tests show that our algorithmgeneralizes on unseen instances and captures underlying parametric structures.</description><author>Gabriele Dragotto, Stefan Clarke, Jaime Fernández Fisac, Bartolomeo Stellato</author><pubDate>Mon, 06 Nov 2023 18:57:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03350v1</guid></item><item><title>DiffAR: Denoising Diffusion Autoregressive Model for Raw Speech Waveform Generation</title><link>http://arxiv.org/abs/2310.01381v2</link><description>Diffusion models have recently been shown to be relevant for high-qualityspeech generation. Most work has been focused on generating spectrograms, andas such, they further require a subsequent model to convert the spectrogram toa waveform (i.e., a vocoder). This work proposes a diffusion probabilisticend-to-end model for generating a raw speech waveform. The proposed model isautoregressive, generating overlapping frames sequentially, where each frame isconditioned on a portion of the previously generated one. Hence, our model caneffectively synthesize an unlimited speech duration while preservinghigh-fidelity synthesis and temporal coherence. We implemented the proposedmodel for unconditional and conditional speech generation, where the latter canbe driven by an input sequence of phonemes, amplitudes, and pitch values.Working on the waveform directly has some empirical advantages. Specifically,it allows the creation of local acoustic behaviors, like vocal fry, which makesthe overall waveform sounds more natural. Furthermore, the proposed diffusionmodel is stochastic and not deterministic; therefore, each inference generatesa slightly different waveform variation, enabling abundance of validrealizations. Experiments show that the proposed model generates speech withsuperior quality compared with other state-of-the-art neural speech generationsystems.</description><author>Roi Benita, Michael Elad, Joseph Keshet</author><pubDate>Mon, 06 Nov 2023 18:55:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01381v2</guid></item><item><title>Scalable and Transferable Black-Box Jailbreaks for Language Models via Persona Modulation</title><link>http://arxiv.org/abs/2311.03348v1</link><description>Despite efforts to align large language models to produce harmless responses,they are still vulnerable to jailbreak prompts that elicit unrestrictedbehaviour. In this work, we investigate persona modulation as a black-boxjailbreaking method to steer a target model to take on personalities that arewilling to comply with harmful instructions. Rather than manually craftingprompts for each persona, we automate the generation of jailbreaks using alanguage model assistant. We demonstrate a range of harmful completions madepossible by persona modulation, including detailed instructions forsynthesising methamphetamine, building a bomb, and laundering money. Theseautomated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is185 times larger than before modulation (0.23%). These prompts also transfer toClaude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%,respectively. Our work reveals yet another vulnerability in commercial largelanguage models and highlights the need for more comprehensive safeguards.</description><author>Rusheb Shah, Quentin Feuillade--Montixi, Soroush Pour, Arush Tagade, Stephen Casper, Javier Rando</author><pubDate>Mon, 06 Nov 2023 18:55:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03348v1</guid></item><item><title>Long-Term Invariant Local Features via Implicit Cross-Domain Correspondences</title><link>http://arxiv.org/abs/2311.03345v1</link><description>Modern learning-based visual feature extraction networks perform well inintra-domain localization, however, their performance significantly declineswhen image pairs are captured across long-term visual domain variations, suchas different seasonal and daytime variations. In this paper, our firstcontribution is a benchmark to investigate the performance impact of long-termvariations on visual localization. We conduct a thorough analysis of theperformance of current state-of-the-art feature extraction networks undervarious domain changes and find a significant performance gap between intra-and cross-domain localization. We investigate different methods to close thisgap by improving the supervision of modern feature extractor networks. Wepropose a novel data-centric method, Implicit Cross-Domain Correspondences(iCDC). iCDC represents the same environment with multiple Neural RadianceFields, each fitting the scene under individual visual domains. It utilizes theunderlying 3D representations to generate accurate correspondences acrossdifferent long-term visual conditions. Our proposed method enhancescross-domain localization performance, significantly reducing the performancegap. When evaluated on popular long-term localization benchmarks, our trainednetworks consistently outperform existing methods. This work serves as asubstantial stride toward more robust visual localization pipelines forlong-term deployments, and opens up research avenues in the development oflong-term invariant descriptors.</description><author>Zador Pataki, Mohammad Altillawi, Menelaos Kanakis, Rémi Pautrat, Fengyi Shen, Ziyuan Liu, Luc Van Gool, Marc Pollefeys</author><pubDate>Mon, 06 Nov 2023 18:53:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03345v1</guid></item><item><title>An International Consortium for Evaluations of Societal-Scale Risks from Advanced AI</title><link>http://arxiv.org/abs/2310.14455v3</link><description>Given rapid progress toward advanced AI and risks from frontier AI systems(advanced AI systems pushing the boundaries of the AI capabilities frontier),the creation and implementation of AI governance and regulatory schemesdeserves prioritization and substantial investment. However, the status quo isuntenable and, frankly, dangerous. A regulatory gap has permitted AI labs toconduct research, development, and deployment activities with minimaloversight. In response, frontier AI system evaluations have been proposed as away of assessing risks from the development and deployment of frontier AIsystems. Yet, the budding AI risk evaluation ecosystem faces significantcoordination challenges, such as a limited diversity of evaluators, suboptimalallocation of effort, and perverse incentives. This paper proposes a solutionin the form of an international consortium for AI risk evaluations, comprisingboth AI developers and third-party AI risk evaluators. Such a consortium couldplay a critical role in international efforts to mitigate societal-scale risksfrom advanced AI, including in managing responsible scaling policies andcoordinated evaluation-based risk response. In this paper, we discuss thecurrent evaluation ecosystem and its shortcomings, propose an internationalconsortium for advanced AI risk evaluations, discuss issues regarding itsimplementation, discuss lessons that can be learnt from previous internationalinstitutions and existing proposals for international AI governanceinstitutions, and, finally, we recommend concrete steps to advance theestablishment of the proposed consortium: (i) solicit feedback fromstakeholders, (ii) conduct additional research, (iii) conduct a workshop(s) forstakeholders, (iv) analyze feedback and create final proposal, (v) solicitfunding, and (vi) create a consortium.</description><author>Ross Gruetzemacher, Alan Chan, Kevin Frazier, Christy Manning, Štěpán Los, James Fox, José Hernández-Orallo, John Burden, Matija Franklin, Clíodhna Ní Ghuidhir, Mark Bailey, Daniel Eth, Toby Pilditch, Kyle Kilian</author><pubDate>Mon, 06 Nov 2023 18:52:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14455v3</guid></item><item><title>C-STS: Conditional Semantic Textual Similarity</title><link>http://arxiv.org/abs/2305.15093v2</link><description>Semantic textual similarity (STS), a cornerstone task in NLP, measures thedegree of similarity between a pair of sentences, and has broad application infields such as information retrieval and natural language understanding.However, sentence similarity can be inherently ambiguous, depending on thespecific aspect of interest. We resolve this ambiguity by proposing a noveltask called Conditional STS (C-STS) which measures sentences' similarityconditioned on an feature described in natural language (hereon, condition). Asan example, the similarity between the sentences "The NBA player shoots athree-pointer." and "A man throws a tennis ball into the air to serve." ishigher for the condition "The motion of the ball" (both upward) and lower for"The size of the ball" (one large and one small). C-STS's advantages aretwo-fold: (1) it reduces the subjectivity and ambiguity of STS and (2) enablesfine-grained language model evaluation through diverse natural languageconditions. We put several state-of-the-art models to the test, and even thoseperforming well on STS (e.g. SimCSE, Flan-T5, and GPT-4) find C-STSchallenging; all with Spearman correlation scores below 50. To encourage a morecomprehensive evaluation of semantic similarity and natural languageunderstanding, we make nearly 19K C-STS examples and code available for othersto train and test their models.</description><author>Ameet Deshpande, Carlos E. Jimenez, Howard Chen, Vishvak Murahari, Victoria Graf, Tanmay Rajpurohit, Ashwin Kalyan, Danqi Chen, Karthik Narasimhan</author><pubDate>Mon, 06 Nov 2023 18:48:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15093v2</guid></item><item><title>Embedding First Order Logic into Kernel Machines</title><link>http://arxiv.org/abs/2311.03340v1</link><description>In this paper we propose a general framework to integrate supervised andunsupervised examples with background knowledge expressed by a collection offirst-order logic clauses into kernel machines. In particular, we consider amulti-task learning scheme where multiple predicates defined on a set ofobjects are to be jointly learned from examples, enforcing a set of FOLconstraints on the admissible configurations of their values. The predicatesare defined on the feature spaces, in which the input objects are represented,and can be either known a priori or approximated by an appropriate kernel-basedlearner. A general approach is presented to convert the FOL clauses into acontinuous implementation that can deal with the outputs computed by thekernel-based predicates. The learning problem is formulated as asemi-supervised task that requires the optimization in the primal of a lossfunction that combines a fitting loss measure on the supervised examples, aregularization term, and a penalty term that enforces the constraints on boththe supervised and unsupervised examples. Unfortunately, the penalty term isnot convex and it can hinder the optimization process. However, it is possibleto avoid poor solutions by using a two stage learning schema, in which thesupervised examples are learned first and then the constraints are enforced.</description><author>Michelangelo Diligenti, Marco Gori, Marco Maggini, Leonardo Rigutini</author><pubDate>Mon, 06 Nov 2023 18:44:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03340v1</guid></item><item><title>Multimodal Large Language Model for Visual Navigation</title><link>http://arxiv.org/abs/2310.08669v2</link><description>Recent efforts to enable visual navigation using large language models havemainly focused on developing complex prompt systems. These systems incorporateinstructions, observations, and history into massive text prompts, which arethen combined with pre-trained large language models to facilitate visualnavigation. In contrast, our approach aims to fine-tune large language modelsfor visual navigation without extensive prompt engineering. Our design involvesa simple text prompt, current observations, and a history collector model thatgathers information from previous observations as input. For output, our designprovides a probability distribution of possible actions that the agent can takeduring navigation. We train our model using human demonstrations and collisionsignals from the Habitat-Matterport 3D Dataset (HM3D). Experimental resultsdemonstrate that our method outperforms state-of-the-art behavior cloningmethods and effectively reduces collision rates.</description><author>Yao-Hung Hubert Tsai, Vansh Dhar, Jialu Li, Bowen Zhang, Jian Zhang</author><pubDate>Mon, 06 Nov 2023 18:44:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08669v2</guid></item><item><title>FLOGA: A machine learning ready dataset, a benchmark and a novel deep learning model for burnt area mapping with Sentinel-2</title><link>http://arxiv.org/abs/2311.03339v1</link><description>Over the last decade there has been an increasing frequency and intensity ofwildfires across the globe, posing significant threats to human and animallives, ecosystems, and socio-economic stability. Therefore urgent action isrequired to mitigate their devastating impact and safeguard Earth's naturalresources. Robust Machine Learning methods combined with the abundance ofhigh-resolution satellite imagery can provide accurate and timely mappings ofthe affected area in order to assess the scale of the event, identify theimpacted assets and prioritize and allocate resources effectively for theproper restoration of the damaged region. In this work, we create and introducea machine-learning ready dataset we name FLOGA (Forest wiLdfire Observationsfor the Greek Area). This dataset is unique as it comprises of satelliteimagery acquired before and after a wildfire event, it contains informationfrom Sentinel-2 and MODIS modalities with variable spatial and spectralresolution, and contains a large number of events where the corresponding burntarea ground truth has been annotated by domain experts. FLOGA covers the widerregion of Greece, which is characterized by a Mediterranean landscape andclimatic conditions. We use FLOGA to provide a thorough comparison of multipleMachine Learning and Deep Learning algorithms for the automatic extraction ofburnt areas, approached as a change detection task. We also compare the resultsto those obtained using standard specialized spectral indices for burnt areamapping. Finally, we propose a novel Deep Learning model, namely BAM-CD. Ourbenchmark results demonstrate the efficacy of the proposed technique in theautomatic extraction of burnt areas, outperforming all other methods in termsof accuracy and robustness. Our dataset and code are publicly available at:https://github.com/Orion-AI-Lab/FLOGA.</description><author>Maria Sdraka, Alkinoos Dimakos, Alexandros Malounis, Zisoula Ntasiou, Konstantinos Karantzalos, Dimitrios Michail, Ioannis Papoutsis</author><pubDate>Mon, 06 Nov 2023 18:42:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03339v1</guid></item><item><title>Sentiment Analysis Dataset in Moroccan Dialect: Bridging the Gap Between Arabic and Latin Scripted dialect</title><link>http://arxiv.org/abs/2303.15987v2</link><description>Sentiment analysis, the automated process of determining emotions or opinionsexpressed in text, has seen extensive exploration in the field of naturallanguage processing. However, one aspect that has remained underrepresented isthe sentiment analysis of the Moroccan dialect, which boasts a uniquelinguistic landscape and the coexistence of multiple scripts. Previous works insentiment analysis primarily targeted dialects employing Arabic script. Whilethese efforts provided valuable insights, they may not fully capture thecomplexity of Moroccan web content, which features a blend of Arabic and Latinscript. As a result, our study emphasizes the importance of extending sentimentanalysis to encompass the entire spectrum of Moroccan linguistic diversity.Central to our research is the creation of the largest public dataset forMoroccan dialect sentiment analysis that incorporates not only Moroccan dialectwritten in Arabic script but also in Latin letters. By assembling a diverserange of textual data, we were able to construct a dataset with a range of 20000 manually labeled text in Moroccan dialect and also publicly available listsof stop words in Moroccan dialect. To dive into sentiment analysis, weconducted a comparative study on multiple Machine learning models to assesstheir compatibility with our dataset. Experiments were performed using both rawand preprocessed data to show the importance of the preprocessing step. We wereable to achieve 92% accuracy in our model and to further prove its liability wetested our model on smaller publicly available datasets of Moroccan dialect andthe results were favorable.</description><author>Mouad Jbel, Imad Hafidi, Abdulmutallib Metrane</author><pubDate>Mon, 06 Nov 2023 18:38:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.15987v2</guid></item><item><title>Cross-Image Attention for Zero-Shot Appearance Transfer</title><link>http://arxiv.org/abs/2311.03335v1</link><description>Recent advancements in text-to-image generative models have demonstrated aremarkable ability to capture a deep semantic understanding of images. In thiswork, we leverage this semantic knowledge to transfer the visual appearancebetween objects that share similar semantics but may differ significantly inshape. To achieve this, we build upon the self-attention layers of thesegenerative models and introduce a cross-image attention mechanism thatimplicitly establishes semantic correspondences across images. Specifically,given a pair of images -- one depicting the target structure and the otherspecifying the desired appearance -- our cross-image attention combines thequeries corresponding to the structure image with the keys and values of theappearance image. This operation, when applied during the denoising process,leverages the established semantic correspondences to generate an imagecombining the desired structure and appearance. In addition, to improve theoutput image quality, we harness three mechanisms that either manipulate thenoisy latent codes or the model's internal representations throughout thedenoising process. Importantly, our approach is zero-shot, requiring nooptimization or training. Experiments show that our method is effective acrossa wide range of object categories and is robust to variations in shape, size,and viewpoint between the two input images.</description><author>Yuval Alaluf, Daniel Garibi, Or Patashnik, Hadar Averbuch-Elor, Daniel Cohen-Or</author><pubDate>Mon, 06 Nov 2023 18:33:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03335v1</guid></item><item><title>Automated Cardiovascular Record Retrieval by Multimodal Learning between Electrocardiogram and Clinical Report</title><link>http://arxiv.org/abs/2304.06286v3</link><description>Automated interpretation of electrocardiograms (ECG) has garnered significantattention with the advancements in machine learning methodologies. Despite thegrowing interest, most current studies focus solely on classification orregression tasks, which overlook a crucial aspect of clinical cardio-diseasediagnosis: the diagnostic report generated by experienced human clinicians. Inthis paper, we introduce a novel approach to ECG interpretation, leveragingrecent breakthroughs in Large Language Models (LLMs) and Vision-Transformer(ViT) models. Rather than treating ECG diagnosis as a classification orregression task, we propose an alternative method of automatically identifyingthe most similar clinical cases based on the input ECG data. Also, sinceinterpreting ECG as images is more affordable and accessible, we process ECG asencoded images and adopt a vision-language learning paradigm to jointly learnvision-language alignment between encoded ECG images and ECG diagnosis reports.Encoding ECG into images can result in an efficient ECG retrieval system, whichwill be highly practical and useful in clinical applications. More importantly,our findings could serve as a crucial resource for providing diagnosticservices in underdeveloped regions.</description><author>Jielin Qiu, Jiacheng Zhu, Shiqi Liu, William Han, Jingqi Zhang, Chaojing Duan, Michael Rosenberg, Emerson Liu, Douglas Weber, Ding Zhao</author><pubDate>Mon, 06 Nov 2023 18:31:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.06286v3</guid></item><item><title>Learning Hard-Constrained Models with One Sample</title><link>http://arxiv.org/abs/2311.03332v1</link><description>We consider the problem of estimating the parameters of a Markov Random Fieldwith hard-constraints using a single sample. As our main running examples, weuse the $k$-SAT and the proper coloring models, as well as general $H$-coloringmodels; for all of these we obtain both positive and negative results. Incontrast to the soft-constrained case, we show in particular that single-sampleestimation is not always possible, and that the existence of an estimator isrelated to the existence of non-satisfiable instances. Our algorithms are based on the pseudo-likelihood estimator. We show variancebounds for this estimator using coupling techniques inspired, in the case of$k$-SAT, by Moitra's sampling algorithm (JACM, 2019); our positive results forcolorings build on this new coupling approach. For $q$-colorings on graphs withmaximum degree $d$, we give a linear-time estimator when $q&gt;d+1$, whereas theproblem is non-identifiable when $q\leq d+1$. For general $H$-colorings, weshow that standard conditions that guarantee sampling, such as Dobrushin'scondition, are insufficient for one-sample learning; on the positive side, weprovide a general condition that is sufficient to guarantee linear-timelearning and obtain applications for proper colorings and permissive models.For the $k$-SAT model on formulas with maximum degree $d$, we provide alinear-time estimator when $k\gtrsim 6.45\log d$, whereas the problem becomesnon-identifiable when $k\lesssim \log d$.</description><author>Andreas Galanis, Alkis Kalavasis, Anthimos Vardis Kandiros</author><pubDate>Mon, 06 Nov 2023 18:29:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03332v1</guid></item><item><title>Explainable Representation Learning of Small Quantum States</title><link>http://arxiv.org/abs/2306.05694v3</link><description>Unsupervised machine learning models build an internal representation oftheir training data without the need for explicit human guidance or featureengineering. This learned representation provides insights into which featuresof the data are relevant for the task at hand. In the context of quantumphysics, training models to describe quantum states without human interventionoffers a promising approach to gaining insight into how machines representcomplex quantum states. The ability to interpret the learned representation mayoffer a new perspective on non-trivial features of quantum systems and theirefficient representation. We train a generative model on two-qubit densitymatrices generated by a parameterized quantum circuit. In a series ofcomputational experiments, we investigate the learned representation of themodel and its internal understanding of the data. We observe that the modellearns an interpretable representation which relates the quantum states totheir underlying entanglement characteristics. In particular, our resultsdemonstrate that the latent representation of the model is directly correlatedwith the entanglement measure concurrence. The insights from this studyrepresent proof of concept towards interpretable machine learning of quantumstates. Our approach offers insight into how machines learn to representsmall-scale quantum systems autonomously.</description><author>Felix Frohnert, Evert van Nieuwenburg</author><pubDate>Mon, 06 Nov 2023 18:26:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05694v3</guid></item><item><title>Guiding The Last Layer in Federated Learning with Pre-Trained Models</title><link>http://arxiv.org/abs/2306.03937v2</link><description>Federated Learning (FL) is an emerging paradigm that allows a model to betrained across a number of participants without sharing data. Recent works havebegun to consider the effects of using pre-trained models as an initializationpoint for existing FL algorithms; however, these approaches ignore the vastbody of efficient transfer learning literature from the centralized learningsetting. Here we revisit the problem of FL from a pre-trained model consideredin prior work and expand it to a set of computer vision transfer learningproblems. We first observe that simply fitting a linear classification head canbe efficient and effective in many cases. We then show that in the FL setting,fitting a classifier using the Nearest Class Means (NCM) can be done exactlyand orders of magnitude more efficiently than existing proposals, whileobtaining strong performance. Finally, we demonstrate that using a two-phaseapproach of obtaining the classifier and then fine-tuning the model can yieldrapid convergence and improved generalization in the federated setting. Wedemonstrate the potential our method has to reduce communication and computecosts while achieving better model performance.</description><author>Gwen Legate, Nicolas Bernier, Lucas Caccia, Edouard Oyallon, Eugene Belilovsky</author><pubDate>Mon, 06 Nov 2023 18:19:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03937v2</guid></item><item><title>A Robust Bi-Directional Algorithm For People Count In Crowded Areas</title><link>http://arxiv.org/abs/2311.03323v1</link><description>People counting system in crowded places has become a very useful practicalapplication that can be accomplished in various ways which include manytraditional methods using sensors. Examining the case of real time scenarios,the algorithm espoused should be steadfast and accurate. People countingalgorithm presented in this paper, is centered on blob assessment, devoted toyield the count of the people through a path along with the direction oftraversal. The system depicted is often ensconced at the entrance of a buildingso that the unmitigated frequency of visitors can be recorded. The core premiseof this work is to extricate count of people inflow and outflow pertaining to aparticular area. The tot-up achieved can be exploited for purpose of statisticsin the circumstances of any calamity occurrence in that zone. Relying upon thecount totaled, the population in that vicinity can be assimilated in order totake on relevant measures to rescue the people.</description><author>Satyanarayana Penke, Gopikrishna Pavuluri, Soukhya Kunda, Satvik M, CharanKumar Y</author><pubDate>Mon, 06 Nov 2023 18:18:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03323v1</guid></item><item><title>Tackling Concept Shift in Text Classification using Entailment-style Modeling</title><link>http://arxiv.org/abs/2311.03320v1</link><description>Pre-trained language models (PLMs) have seen tremendous success in textclassification (TC) problems in the context of Natural Language Processing(NLP). In many real-world text classification tasks, the class definitionsbeing learned do not remain constant but rather change with time - this isknown as Concept Shift. Most techniques for handling concept shift rely onretraining the old classifiers with the newly labelled data. However, given theamount of training data required to fine-tune large DL models for the newconcepts, the associated labelling costs can be prohibitively expensive andtime consuming. In this work, we propose a reformulation, converting vanillaclassification into an entailment-style problem that requires significantlyless data to re-train the text classifier to adapt to new concepts. Wedemonstrate the effectiveness of our proposed method on both real world &amp;synthetic datasets achieving absolute F1 gains upto 7% and 40% respectively infew-shot settings. Further, upon deployment, our solution also helped save 75%of labeling costs overall.</description><author>Sumegh Roychowdhury, Karan Gupta, Siva Rajesh Kasa, Prasanna Srinivasa Murthy, Alok Chandra</author><pubDate>Mon, 06 Nov 2023 18:15:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03320v1</guid></item><item><title>Fine-Tune Language Models as Differential Equation Solvers</title><link>http://arxiv.org/abs/2308.05061v2</link><description>In the growing domain of scientific machine learning, in-context operatorlearning has shown notable potential in learning operators and solvingdifferential equations using prompted data, during the inference stage withoutweight updates. However, the current model's overdependence on function data,may inadvertently overlook the invaluable human insight into the operator. Toaddress this, we present a transformation of in-context operator learning intoa multi-modal paradigm. In particular, we take inspiration from the recentsuccess of large language models, and propose using "captions" to integratehuman knowledge about the operator, expressed through natural languagedescriptions and equations. Also, we introduce a novel approach to train alanguage-model-like architecture, or directly fine-tune existing languagemodels, for in-context operator learning. We beat the baseline on single-modallearning tasks, and also demonstrated the effectiveness of multi-modal learningin enhancing performance and reducing function data requirements. The proposedmethod not only significantly improves in-context operator learning, but alsocreates a new path for the application of language models.</description><author>Liu Yang, Siting Liu, Stanley J. Osher</author><pubDate>Mon, 06 Nov 2023 18:14:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05061v2</guid></item><item><title>DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase</title><link>http://arxiv.org/abs/2311.03319v1</link><description>In-Context Learning (ICL) combined with pre-trained large language models hasachieved promising results on various NLP tasks. However, ICL requireshigh-quality annotated demonstrations which might not be available inreal-world scenarios. To overcome this limitation, we propose \textbf{D}ata\textbf{A}ugmentation for \textbf{I}n-Context \textbf{L}earning(\textbf{DAIL}). DAIL leverages the intuition that large language models aremore familiar with the content generated by themselves. It first utilizes thelanguage model to generate paraphrases of the test sample and employs majorityvoting to determine the final result based on individual predictions. Ourextensive empirical evaluation shows that DAIL outperforms the standard ICLmethod and other ensemble-based methods in the low-resource scenario.Additionally, we explore the use of voting consistency as a confidence score ofthe model when the logits of predictions are inaccessible. We believe our workwill stimulate further research on ICL in low-resource settings.</description><author>Dawei Li, Yaxuan Li, Dheeraj Mekala, Shuyao Li, Yulin wang, Xueqi Wang, William Hogan, Jingbo Shang</author><pubDate>Mon, 06 Nov 2023 18:12:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03319v1</guid></item><item><title>HOH: Markerless Multimodal Human-Object-Human Handover Dataset with Large Object Count</title><link>http://arxiv.org/abs/2310.00723v2</link><description>We present the HOH (Human-Object-Human) Handover Dataset, a large objectcount dataset with 136 objects, to accelerate data-driven research on handoverstudies, human-robot handover implementation, and artificial intelligence (AI)on handover parameter estimation from 2D and 3D data of person interactions.HOH contains multi-view RGB and depth data, skeletons, fused point clouds,grasp type and handedness labels, object, giver hand, and receiver hand 2D and3D segmentations, giver and receiver comfort ratings, and paired objectmetadata and aligned 3D models for 2,720 handover interactions spanning 136objects and 20 giver-receiver pairs-40 with role-reversal-organized from 40participants. We also show experimental results of neural networks trainedusing HOH to perform grasp, orientation, and trajectory prediction. As the onlyfully markerless handover capture dataset, HOH represents natural human-humanhandover interactions, overcoming challenges with markered datasets thatrequire specific suiting for body tracking, and lack high-resolution handtracking. To date, HOH is the largest handover dataset in number of objects,participants, pairs with role reversal accounted for, and total interactionscaptured.</description><author>Noah Wiederhold, Ava Megyeri, DiMaggio Paris, Sean Banerjee, Natasha Kholgade Banerjee</author><pubDate>Mon, 06 Nov 2023 18:12:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00723v2</guid></item><item><title>FLSL: Feature-level Self-supervised Learning</title><link>http://arxiv.org/abs/2306.06203v4</link><description>Current self-supervised learning (SSL) methods (e.g., SimCLR, DINO,VICReg,MOCOv3) target primarily on representations at instance level and do notgeneralize well to dense prediction tasks, such as object detection andsegmentation.Towards aligning SSL with dense predictions, this paperdemonstrates for the first time the underlying mean-shift clustering process ofVision Transformers (ViT), which aligns well with natural image semantics(e.g., a world of objects and stuffs). By employing transformer for jointembedding and clustering, we propose a two-level feature clustering SSL method,coined Feature-Level Self-supervised Learning (FLSL). We present the formaldefinition of the FLSL problem and construct the objectives from the mean-shiftand k-means perspectives. We show that FLSL promotes remarkable semanticcluster representations and learns an embedding scheme amenable to intra-viewand inter-view feature clustering. Experiments show that FLSL yieldssignificant improvements in dense prediction tasks, achieving 44.9 (+2.8)% APand 46.5% AP in object detection, as well as 40.8 (+2.3)% AP and 42.1% AP ininstance segmentation on MS-COCO, using Mask R-CNN with ViT-S/16 and ViT-S/8 asbackbone, respectively. FLSL consistently outperforms existing SSL methodsacross additional benchmarks, including UAV17 object detection on UAVDT, andvideo instance segmentation on DAVIS 2017.We conclude by presentingvisualization and various ablation studies to better understand the success ofFLSL. The source code is available at https://github.com/ISL-CV/FLSL.</description><author>Qing Su, Anton Netchaev, Hai Li, Shihao Ji</author><pubDate>Mon, 06 Nov 2023 18:12:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06203v4</guid></item><item><title>FATE: Feature-Agnostic Transformer-based Encoder for learning generalized embedding spaces in flow cytometry data</title><link>http://arxiv.org/abs/2311.03314v1</link><description>While model architectures and training strategies have become more genericand flexible with respect to different data modalities over the past years, apersistent limitation lies in the assumption of fixed quantities andarrangements of input features. This limitation becomes particularly relevantin scenarios where the attributes captured during data acquisition vary acrossdifferent samples. In this work, we aim at effectively leveraging data withvarying features, without the need to constrain the input space to theintersection of potential feature sets or to expand it to their union. Wepropose a novel architecture that can directly process data without thenecessity of aligned feature modalities by learning a general embedding spacethat captures the relationship between features across data samples withvarying sets of features. This is achieved via a set-transformer architectureaugmented by feature-encoder layers, thereby enabling the learning of a sharedlatent feature space from data originating from heterogeneous feature spaces.The advantages of the model are demonstrated for automatic cancer celldetection in acute myeloid leukemia in flow cytometry data, where the featuresmeasured during acquisition often vary between samples. Our proposedarchitecture's capacity to operate seamlessly across incongruent feature spacesis particularly relevant in this context, where data scarcity arises from thelow prevalence of the disease. The code is available for research purposes athttps://github.com/lisaweijler/FATE.</description><author>Lisa Weijler, Florian Kowarsch, Michael Reiter, Pedro Hermosilla, Margarita Maurer-Granofszky, Michael Dworzak</author><pubDate>Mon, 06 Nov 2023 18:06:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03314v1</guid></item><item><title>Practical considerations for variable screening in the Super Learner</title><link>http://arxiv.org/abs/2311.03313v1</link><description>Estimating a prediction function is a fundamental component of many dataanalyses. The Super Learner ensemble, a particular implementation of stacking,has desirable theoretical properties and has been used successfully in manyapplications. Dimension reduction can be accomplished by using variablescreening algorithms, including the lasso, within the ensemble prior to fittingother prediction algorithms. However, the performance of a Super Learner usingthe lasso for dimension reduction has not been fully explored in cases wherethe lasso is known to perform poorly. We provide empirical results that suggestthat a diverse set of candidate screening algorithms should be used to protectagainst poor performance of any one screen, similar to the guidance forchoosing a library of prediction algorithms for the Super Learner.</description><author>Brian D. Williamson, Drew King, Ying Huang</author><pubDate>Mon, 06 Nov 2023 18:04:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03313v1</guid></item><item><title>A Single 2D Pose with Context is Worth Hundreds for 3D Human Pose Estimation</title><link>http://arxiv.org/abs/2311.03312v1</link><description>The dominant paradigm in 3D human pose estimation that lifts a 2D posesequence to 3D heavily relies on long-term temporal clues (i.e., using adaunting number of video frames) for improved accuracy, which incursperformance saturation, intractable computation and the non-causal problem.This can be attributed to their inherent inability to perceive spatial contextas plain 2D joint coordinates carry no visual cues. To address this issue, wepropose a straightforward yet powerful solution: leveraging the readilyavailable intermediate visual representations produced by off-the-shelf(pre-trained) 2D pose detectors -- no finetuning on the 3D task is even needed.The key observation is that, while the pose detector learns to localize 2Djoints, such representations (e.g., feature maps) implicitly encode thejoint-centric spatial context thanks to the regional operations in backbonenetworks. We design a simple baseline named Context-Aware PoseFormer toshowcase its effectiveness. Without access to any temporal information, theproposed method significantly outperforms its context-agnostic counterpart,PoseFormer, and other state-of-the-art methods using up to hundreds of videoframes regarding both speed and precision. Project page:https://qitaozhao.github.io/ContextAware-PoseFormer</description><author>Qitao Zhao, Ce Zheng, Mengyuan Liu, Chen Chen</author><pubDate>Mon, 06 Nov 2023 18:04:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03312v1</guid></item><item><title>Unraveling Downstream Gender Bias from Large Language Models: A Study on AI Educational Writing Assistance</title><link>http://arxiv.org/abs/2311.03311v1</link><description>Large Language Models (LLMs) are increasingly utilized in educational taskssuch as providing writing suggestions to students. Despite their potential,LLMs are known to harbor inherent biases which may negatively impact learners.Previous studies have investigated bias in models and data representationsseparately, neglecting the potential impact of LLM bias on human writing. Inthis paper, we investigate how bias transfers through an AI writing supportpipeline. We conduct a large-scale user study with 231 students writingbusiness case peer reviews in German. Students are divided into five groupswith different levels of writing support: one classroom group withfeature-based suggestions and four groups recruited from Prolific -- a controlgroup with no assistance, two groups with suggestions from fine-tuned GPT-2 andGPT-3 models, and one group with suggestions from pre-trained GPT-3.5. UsingGenBit gender bias analysis, Word Embedding Association Tests (WEAT), andSentence Embedding Association Test (SEAT) we evaluate the gender bias atvarious stages of the pipeline: in model embeddings, in suggestions generatedby the models, and in reviews written by students. Our results demonstrate thatthere is no significant difference in gender bias between the resulting peerreviews of groups with and without LLM suggestions. Our research is thereforeoptimistic about the use of AI writing support in the classroom, showcasing acontext where bias in LLMs does not transfer to students' responses.</description><author>Thiemo Wambsganss, Xiaotian Su, Vinitra Swamy, Seyed Parsa Neshaei, Roman Rietsche, Tanja Käser</author><pubDate>Mon, 06 Nov 2023 18:01:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03311v1</guid></item><item><title>Neural Structure Learning with Stochastic Differential Equations</title><link>http://arxiv.org/abs/2311.03309v1</link><description>Discovering the underlying relationships among variables from temporalobservations has been a longstanding challenge in numerous scientificdisciplines, including biology, finance, and climate science. The dynamics ofsuch systems are often best described using continuous-time stochasticprocesses. Unfortunately, most existing structure learning approaches assumethat the underlying process evolves in discrete-time and/or observations occurat regular time intervals. These mismatched assumptions can often lead toincorrect learned structures and models. In this work, we introduce a novelstructure learning method, SCOTCH, which combines neural stochasticdifferential equations (SDE) with variational inference to infer a posteriordistribution over possible structures. This continuous-time approach cannaturally handle both learning from and predicting observations at arbitrarytime points. Theoretically, we establish sufficient conditions for an SDE andSCOTCH to be structurally identifiable, and prove its consistency underinfinite data limits. Empirically, we demonstrate that our approach leads toimproved structure learning performance on both synthetic and real-worlddatasets compared to relevant baselines under regular and irregular samplingintervals.</description><author>Benjie Wang, Joel Jennings, Wenbo Gong</author><pubDate>Mon, 06 Nov 2023 17:58:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03309v1</guid></item><item><title>Alternate Loss Functions for Classification and Robust Regression Can Improve the Accuracy of Artificial Neural Networks</title><link>http://arxiv.org/abs/2303.09935v2</link><description>All machine learning algorithms use a loss, cost, utility or reward functionto encode the learning objective and oversee the learning process. Thisfunction that supervises learning is a frequently unrecognized hyperparameterthat determines how incorrect outputs are penalized and can be tuned to improveperformance. This paper shows that training speed and final accuracy of neuralnetworks can significantly depend on the loss function used to train neuralnetworks. In particular derivative values can be significantly different withdifferent loss functions leading to significantly different performance aftergradient descent based Backpropagation (BP) training. This paper explores theeffect on performance of using new loss functions that are also convex butpenalize errors differently compared to the popular Cross-entropy loss. Two newclassification loss functions that significantly improve performance on a widevariety of benchmark tasks are proposed. A new loss function call smoothabsolute error that outperforms the Squared error, Huber and Log-Cosh losses ondatasets with significantly many outliers is proposed. This smooth absoluteerror loss function is infinitely differentiable and more closely approximatesthe absolute error loss compared to the Huber and Log-Cosh losses used forrobust regression.</description><author>Mathew Mithra Noel, Arindam Banerjee, Geraldine Bessie Amali D, Venkataraman Muthiah-Nakarajan</author><pubDate>Mon, 06 Nov 2023 17:54:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09935v2</guid></item><item><title>TS-Diffusion: Generating Highly Complex Time Series with Diffusion Models</title><link>http://arxiv.org/abs/2311.03303v1</link><description>While current generative models have achieved promising performances intime-series synthesis, they either make strong assumptions on the data format(e.g., regularities) or rely on pre-processing approaches (e.g.,interpolations) to simplify the raw data. In this work, we consider a class oftime series with three common bad properties, including samplingirregularities, missingness, and large feature-temporal dimensions, andintroduce a general model, TS-Diffusion, to process such complex time series.Our model consists of three parts under the framework of point process. Thefirst part is an encoder of the neural ordinary differential equation (ODE)that converts time series into dense representations, with the jump techniqueto capture sampling irregularities and self-attention mechanism to handlemissing values; The second component of TS-Diffusion is a diffusion model thatlearns from the representation of time series. These time-seriesrepresentations can have a complex distribution because of their highdimensions; The third part is a decoder of another ODE that generates timeseries with irregularities and missing values given their representations. Wehave conducted extensive experiments on multiple time-series datasets,demonstrating that TS-Diffusion achieves excellent results on both conventionaland complex time series and significantly outperforms previous baselines.</description><author>Yangming Li</author><pubDate>Mon, 06 Nov 2023 17:52:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03303v1</guid></item><item><title>Towards Calibrated Robust Fine-Tuning of Vision-Language Models</title><link>http://arxiv.org/abs/2311.01723v2</link><description>While fine-tuning unlocks the potential of a pre-trained model for a specifictask, it compromises the model's ability to generalize to out-of-distribution(OOD) datasets. To mitigate this, robust fine-tuning aims to ensure performanceon OOD datasets as well as on an in-distribution (ID) dataset for which themodel is being tuned. However, another criterion for reliable machine learning(ML), confidence calibration, has been overlooked despite its increasing demandfor real-world high-stakes ML applications (e.g., autonomous driving andmedical diagnosis). For the first time, we raise concerns about the calibrationof fine-tuned vision-language models (VLMs) under distribution shift by showingthat naive fine-tuning and even state-of-the-art robust fine-tuning methodshurt the calibration of pre-trained VLMs, especially on OOD datasets. Toaddress this issue, we provide a simple approach, called calibrated robustfine-tuning (CaRot), that incentivizes calibration and robustness on both IDand OOD datasets. Empirical results on ImageNet-1K distribution shiftevaluation verify the effectiveness of our method.</description><author>Changdae Oh, Mijoo Kim, Hyesu Lim, Junhyeok Park, Euiseog Jeong, Zhi-Qi Cheng, Kyungwoo Song</author><pubDate>Mon, 06 Nov 2023 17:52:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01723v2</guid></item><item><title>Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study</title><link>http://arxiv.org/abs/2305.03017v4</link><description>Our research investigates the recommendation of code examples to aid softwaredevelopers, a practice that saves developers significant time by providingready-to-use code snippets. The focus of our study is Stack Overflow, acommonly used resource for coding discussions and solutions, particularly inthe context of the Java programming language. We applied BERT, a powerful LargeLanguage Model (LLM) that enables us to transform code examples into numericalvectors by extracting their semantic information. Once these numericalrepresentations are prepared, we identify Approximate Nearest Neighbors (ANN)using Locality-Sensitive Hashing (LSH). Our research employed two variants ofLSH: Random Hyperplane-based LSH and Query-Aware LSH. We rigorously comparedthese two approaches across four parameters: HitRate, Mean Reciprocal Rank(MRR), Average Execution Time, and Relevance. Our study revealed that theQuery-Aware (QA) approach showed superior performance over the RandomHyperplane-based (RH) method. Specifically, it exhibited a notable improvementof 20\% to 35\% in HitRate for query pairs compared to the RH approach.Furthermore, the QA approach proved significantly more time-efficient, with itsspeed in creating hashing tables and assigning data samples to buckets being atleast four times faster. It can return code examples within milliseconds,whereas the RH approach typically requires several seconds to recommend codeexamples. Due to the superior performance of the QA approach, we tested itagainst PostFinder and FaCoY, the state-of-the-art baselines. Our QA methodshowed comparable efficiency proving its potential for effective coderecommendation.</description><author>Sajjad Rahmani, AmirHossein Naghshzan, Latifa Guerrouj</author><pubDate>Mon, 06 Nov 2023 17:50:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03017v4</guid></item><item><title>Contrast Everything: A Hierarchical Contrastive Framework for Medical Time-Series</title><link>http://arxiv.org/abs/2310.14017v4</link><description>Contrastive representation learning is crucial in medical time seriesanalysis as it alleviates dependency on labor-intensive, domain-specific, andscarce expert annotations. However, existing contrastive learning methodsprimarily focus on one single data level, which fails to fully exploit theintricate nature of medical time series. To address this issue, we presentCOMET, an innovative hierarchical framework that leverages data consistenciesat all inherent levels in medical time series. Our meticulously designed modelsystematically captures data consistency from four potential levels:observation, sample, trial, and patient levels. By developing contrastive lossat multiple levels, we can learn effective representations that preservecomprehensive data consistency, maximizing information utilization in aself-supervised manner. We conduct experiments in the challengingpatient-independent setting. We compare COMET against six baselines using threediverse datasets, which include ECG signals for myocardial infarction and EEGsignals for Alzheimer's and Parkinson's diseases. The results demonstrate thatCOMET consistently outperforms all baselines, particularly in setup with 10%and 1% labeled data fractions across all datasets. These results underscore thesignificant impact of our framework in advancing contrastive representationlearning techniques for medical time series. The source code is available athttps://github.com/DL4mHealth/COMET.</description><author>Yihe Wang, Yu Han, Haishuai Wang, Xiang Zhang</author><pubDate>Mon, 06 Nov 2023 17:49:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14017v4</guid></item><item><title>Ziya2: Data-centric Learning is All LLMs Need</title><link>http://arxiv.org/abs/2311.03301v1</link><description>Various large language models (LLMs) have been proposed in recent years,including closed- and open-source ones, continually setting new records onmultiple benchmarks. However, the development of LLMs still faces severalissues, such as high cost of training models from scratch, and continualpre-training leading to catastrophic forgetting, etc. Although many such issuesare addressed along the line of research on LLMs, an important yet practicallimitation is that many studies overly pursue enlarging model sizes withoutcomprehensively analyzing and optimizing the use of pre-training data in theirlearning process, as well as appropriate organization and leveraging of suchdata in training LLMs under cost-effective settings. In this work, we proposeZiya2, a model with 13 billion parameters adopting LLaMA2 as the foundationmodel, and further pre-trained on 700 billion tokens, where we focus onpre-training techniques and use data-centric optimization to enhance thelearning process of Ziya2 on different stages. Experiments show that Ziya2significantly outperforms other models in multiple benchmarks especially withpromising results compared to representative open-source ones. Ziya2 (Base) isreleased at https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base andhttps://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary.</description><author>Ruyi Gan, Ziwei Wu, Renliang Sun, Junyu Lu, Xiaojun Wu, Dixiang Zhang, Kunhao Pan, Ping Yang, Qi Yang, Jiaxing Zhang, Yan Song</author><pubDate>Mon, 06 Nov 2023 17:49:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03301v1</guid></item><item><title>FOCUS: Effective Embedding Initialization for Monolingual Specialization of Multilingual Models</title><link>http://arxiv.org/abs/2305.14481v2</link><description>Using model weights pretrained on a high-resource language as a warm startcan reduce the need for data and compute to obtain high-quality language modelsfor other, especially low-resource, languages. However, if we want to use a newtokenizer specialized for the target language, we cannot transfer the sourcemodel's embedding matrix. In this paper, we propose FOCUS - Fast OverlappingToken Combinations Using Sparsemax, a novel embedding initialization methodthat initializes the embedding matrix effectively for a new tokenizer based oninformation in the source model's embedding matrix. FOCUS represents newlyadded tokens as combinations of tokens in the overlap of the source and targetvocabularies. The overlapping tokens are selected based on semantic similarityin an auxiliary static token embedding space. We focus our study on using themultilingual XLM-R as a source model and empirically show that FOCUSoutperforms random initialization and previous work in language modeling and ona range of downstream tasks (NLI, QA, and NER).</description><author>Konstantin Dobler, Gerard de Melo</author><pubDate>Mon, 06 Nov 2023 17:47:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14481v2</guid></item><item><title>What Knowledge Gets Distilled in Knowledge Distillation?</title><link>http://arxiv.org/abs/2205.16004v3</link><description>Knowledge distillation aims to transfer useful information from a teachernetwork to a student network, with the primary goal of improving the student'sperformance for the task at hand. Over the years, there has a been a deluge ofnovel techniques and use cases of knowledge distillation. Yet, despite thevarious improvements, there seems to be a glaring gap in the community'sfundamental understanding of the process. Specifically, what is the knowledgethat gets distilled in knowledge distillation? In other words, in what waysdoes the student become similar to the teacher? Does it start to localizeobjects in the same way? Does it get fooled by the same adversarial samples?Does its data invariance properties become similar? Our work presents acomprehensive study to try to answer these questions. We show that existingmethods can indeed indirectly distill these properties beyond improving taskperformance. We further study why knowledge distillation might work this way,and show that our findings have practical implications as well.</description><author>Utkarsh Ojha, Yuheng Li, Anirudh Sundara Rajan, Yingyu Liang, Yong Jae Lee</author><pubDate>Mon, 06 Nov 2023 17:45:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.16004v3</guid></item><item><title>Learning Reusable Manipulation Strategies</title><link>http://arxiv.org/abs/2311.03293v1</link><description>Humans demonstrate an impressive ability to acquire and generalizemanipulation "tricks." Even from a single demonstration, such as using soupladles to reach for distant objects, we can apply this skill to new scenariosinvolving different object positions, sizes, and categories (e.g., forks andhammers). Additionally, we can flexibly combine various skills to deviselong-term plans. In this paper, we present a framework that enables machines toacquire such manipulation skills, referred to as "mechanisms," through a singledemonstration and self-play. Our key insight lies in interpreting eachdemonstration as a sequence of changes in robot-object and object-objectcontact modes, which provides a scaffold for learning detailed samplers forcontinuous parameters. These learned mechanisms and samplers can be seamlesslyintegrated into standard task and motion planners, enabling their compositionaluse.</description><author>Jiayuan Mao, Joshua B. Tenenbaum, Tomás Lozano-Pérez, Leslie Pack Kaelbling</author><pubDate>Mon, 06 Nov 2023 17:35:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03293v1</guid></item><item><title>PolyLUT: Learning Piecewise Polynomials for Ultra-Low Latency FPGA LUT-based Inference</title><link>http://arxiv.org/abs/2309.02334v2</link><description>Field-programmable gate arrays (FPGAs) are widely used to implement deeplearning inference. Standard deep neural network inference involves thecomputation of interleaved linear maps and nonlinear activation functions.Prior work for ultra-low latency implementations has hardcoded the combinationof linear maps and nonlinear activations inside FPGA lookup tables (LUTs). Ourwork is motivated by the idea that the LUTs in an FPGA can be used to implementa much greater variety of functions than this. In this paper, we propose anovel approach to training neural networks for FPGA deployment usingmultivariate polynomials as the basic building block. Our method takesadvantage of the flexibility offered by the soft logic, hiding the polynomialevaluation inside the LUTs with minimal overhead. We show that by usingpolynomial building blocks, we can achieve the same accuracy using considerablyfewer layers of soft logic than by using linear functions, leading tosignificant latency and area improvements. We demonstrate the effectiveness ofthis approach in three tasks: network intrusion detection, jet identificationat the CERN Large Hadron Collider, and handwritten digit recognition using theMNIST dataset.</description><author>Marta Andronic, George A. Constantinides</author><pubDate>Mon, 06 Nov 2023 17:28:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.02334v2</guid></item><item><title>Holistic Analysis of Hallucination in GPT-4V(ision): Bias and Interference Challenges</title><link>http://arxiv.org/abs/2311.03287v1</link><description>While GPT-4V(ision) impressively models both visual and textual informationsimultaneously, it's hallucination behavior has not been systematicallyassessed. To bridge this gap, we introduce a new benchmark, namely, the Biasand Interference Challenges in Visual Language Models (Bingo). This benchmarkis designed to evaluate and shed light on the two common types ofhallucinations in visual language models: bias and interference. Here, biasrefers to the model's tendency to hallucinate certain types of responses,possibly due to imbalance in its training data. Interference pertains toscenarios where the judgment of GPT-4V(ision) can be disrupted due to how thetext prompt is phrased or how the input image is presented. We identify anotable regional bias, whereby GPT-4V(ision) is better at interpreting Westernimages or images with English writing compared to images from other countriesor containing text in other languages. Moreover, GPT-4V(ision) is vulnerable toleading questions and is often confused when interpreting multiple imagestogether. Popular mitigation approaches, such as self-correction andchain-of-thought reasoning, are not effective in resolving these challenges. Wealso identified similar biases and interference vulnerabilities with LLaVA andBard. Our results characterize the hallucination challenges in GPT-4V(ision)and state-of-the-art visual-language models, and highlight the need for newsolutions. The Bingo benchmark is available at https://github.com/gzcch/Bingo.</description><author>Chenhang Cui, Yiyang Zhou, Xinyu Yang, Shirley Wu, Linjun Zhang, James Zou, Huaxiu Yao</author><pubDate>Mon, 06 Nov 2023 17:26:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03287v1</guid></item><item><title>S-LoRA: Serving Thousands of Concurrent LoRA Adapters</title><link>http://arxiv.org/abs/2311.03285v1</link><description>The "pretrain-then-finetune" paradigm is commonly adopted in the deploymentof large language models. Low-Rank Adaptation (LoRA), a parameter-efficientfine-tuning method, is often employed to adapt a base model to a multitude oftasks, resulting in a substantial collection of LoRA adapters derived from onebase model. We observe that this paradigm presents significant opportunitiesfor batched inference during serving. To capitalize on these opportunities, wepresent S-LoRA, a system designed for the scalable serving of many LoRAadapters. S-LoRA stores all adapters in the main memory and fetches theadapters used by the currently running queries to the GPU memory. Toefficiently use the GPU memory and reduce fragmentation, S-LoRA proposesUnified Paging. Unified Paging uses a unified memory pool to manage dynamicadapter weights with different ranks and KV cache tensors with varying sequencelengths. Additionally, S-LoRA employs a novel tensor parallelism strategy andhighly optimized custom CUDA kernels for heterogeneous batching of LoRAcomputation. Collectively, these features enable S-LoRA to serve thousands ofLoRA adapters on a single GPU or across multiple GPUs with a small overhead.Compared to state-of-the-art libraries such as HuggingFace PEFT and vLLM (withnaive support of LoRA serving), S-LoRA can improve the throughput by up to 4times and increase the number of served adapters by several orders ofmagnitude. As a result, S-LoRA enables scalable serving of many task-specificfine-tuned models and offers the potential for large-scale customizedfine-tuning services.</description><author>Ying Sheng, Shiyi Cao, Dacheng Li, Coleman Hooper, Nicholas Lee, Shuo Yang, Christopher Chou, Banghua Zhu, Lianmin Zheng, Kurt Keutzer, Joseph E. Gonzalez, Ion Stoica</author><pubDate>Mon, 06 Nov 2023 17:26:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03285v1</guid></item><item><title>Risk of Transfer Learning and its Applications in Finance</title><link>http://arxiv.org/abs/2311.03283v1</link><description>Transfer learning is an emerging and popular paradigm for utilizing existingknowledge from previous learning tasks to improve the performance of new ones.In this paper, we propose a novel concept of transfer risk and and analyze itsproperties to evaluate transferability of transfer learning. We apply transferlearning techniques and this concept of transfer risk to stock returnprediction and portfolio optimization problems. Numerical results demonstrate astrong correlation between transfer risk and overall transfer learningperformance, where transfer risk provides a computationally efficient way toidentify appropriate source tasks in transfer learning, includingcross-continent, cross-sector, and cross-frequency transfer for portfoliooptimization.</description><author>Haoyang Cao, Haotian Gu, Xin Guo, Mathieu Rosenbaum</author><pubDate>Mon, 06 Nov 2023 17:23:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03283v1</guid></item><item><title>Discretizing Numerical Attributes: An Analysis of Human Perceptions</title><link>http://arxiv.org/abs/2311.03278v1</link><description>Machine learning (ML) has employed various discretization methods topartition numerical attributes into intervals. However, an effectivediscretization technique remains elusive in many ML applications, such asassociation rule mining. Moreover, the existing discretization techniques donot reflect best the impact of the independent numerical factor on thedependent numerical target factor. This research aims to establish a benchmarkapproach for numerical attribute partitioning. We conduct an extensive analysisof human perceptions of partitioning a numerical attribute and compare theseperceptions with the results obtained from our two proposed measures. We alsoexamine the perceptions of experts in data science, statistics, and engineeringby employing numerical data visualization techniques. The analysis of collectedresponses reveals that $68.7\%$ of human responses approximately closely alignwith the values generated by our proposed measures. Based on these findings,our proposed measures may be used as one of the methods for discretizing thenumerical attributes.</description><author>Minakshi Kaushik, Rahul Sharma, Dirk Draheim</author><pubDate>Mon, 06 Nov 2023 17:20:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03278v1</guid></item><item><title>Generative Image Dynamics</title><link>http://arxiv.org/abs/2309.07906v2</link><description>We present an approach to modeling an image-space prior on scene motion. Ourprior is learned from a collection of motion trajectories extracted from realvideo sequences depicting natural, oscillatory dynamics such as trees, flowers,candles, and clothes swaying in the wind. We model this dense, long-term motionprior in the Fourier domain:given a single image, our trained model uses afrequency-coordinated diffusion sampling process to predict a spectral volume,which can be converted into a motion texture that spans an entire video. Alongwith an image-based rendering module, these trajectories can be used for anumber of downstream applications, such as turning still images into seamlesslylooping videos, or allowing users to realistically interact with objects inreal pictures by interpreting the spectral volumes as image-space modal bases,which approximate object dynamics.</description><author>Zhengqi Li, Richard Tucker, Noah Snavely, Aleksander Holynski</author><pubDate>Mon, 06 Nov 2023 17:19:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.07906v2</guid></item><item><title>Exploiting Latent Attribute Interaction with Transformer on Heterogeneous Information Networks</title><link>http://arxiv.org/abs/2311.03275v1</link><description>Heterogeneous graph neural networks (HGNNs) have recently shown impressivecapability in modeling heterogeneous graphs that are ubiquitous in real-worldapplications. Due to the diversity of attributes of nodes in different types,most existing models first align nodes by mapping them into the samelow-dimensional space. However, in this way, they lose the type information ofnodes. In addition, most of them only consider the interactions between nodeswhile neglecting the high-order information behind the latent interactionsamong different node features. To address these problems, in this paper, wepropose a novel heterogeneous graph model MULAN, including two majorcomponents, i.e., a type-aware encoder and a dimension-aware encoder.Specifically, the type-aware encoder compensates for the loss of node typeinformation and better leverages graph heterogeneity in learning noderepresentations. Built upon transformer architecture, the dimension-awareencoder is capable of capturing the latent interactions among the diverse nodefeatures. With these components, the information of graph heterogeneity, nodefeatures and graph structure can be comprehensively encoded in noderepresentations. We conduct extensive experiments on six heterogeneousbenchmark datasets, which demonstrates the superiority of MULAN over otherstate-of-the-art competitors and also shows that MULAN is efficient.</description><author>Zeyuan Zhao, Qingqing Ge, Anfeng Cheng, Yiding Liu, Xiang Li, Shuaiqiang Wang</author><pubDate>Mon, 06 Nov 2023 17:18:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03275v1</guid></item><item><title>Image Matching by Bare Homography</title><link>http://arxiv.org/abs/2305.08946v3</link><description>This paper presents Slime, a novel non-deep image matching framework whichmodels the scene as rough local overlapping planes. This intermediaterepresentation sits in-between the local affine approximation of the keypointpatches and the global matching based on both spatial and similarityconstraints, providing a progressive pruning of the correspondences, as planesare easier to handle with respect to general scenes. Slime decomposes the images into overlapping regions at different scales andcomputes loose planar homographies. Planes are mutually extended by compatiblematches and the images are split into fixed tiles, with only the besthomographies retained for each pair of tiles. Stable matches are identifiedaccording to the consensus of the admissible stereo configurations provided bypairwise homographies. Within tiles, the rough planes are then merged accordingto their overlap in terms of matches and further consistent correspondences areextracted. The whole process only involves homography constraints. As a result, both thecoverage and the stability of correct matches over the scene are amplified,together with the ability to spot matches in challenging scenes, allowingtraditional hybrid matching pipelines to make up lost ground against recentend-to-end deep matching methods. In addition, the paper gives a thorough comparative analysis of recentstate-of-the-art in image matching represented by end-to-end deep networks andhybrid pipelines. The evaluation considers both planar and non-planar scenes,taking into account critical and challenging scenarios including abrupttemporal image changes and strong variations in relative image rotations.According to this analysis, although the impressive progress done in thisfield, there is still a wide room for improvements to be investigated in futureresearch.</description><author>Fabio Bellavia</author><pubDate>Mon, 06 Nov 2023 17:02:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.08946v3</guid></item><item><title>MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework</title><link>http://arxiv.org/abs/2308.00352v5</link><description>Remarkable progress has been made on automated problem solving throughsocieties of agents based on large language models (LLMs). Existing LLM-basedmulti-agent systems can already solve simple dialogue tasks. Solutions to morecomplex tasks, however, are complicated through logic inconsistencies due tocascading hallucinations caused by naively chaining LLMs. Here we introduceMetaGPT, an innovative meta-programming framework incorporating efficient humanworkflows into LLM-based multi-agent collaborations. MetaGPT encodesStandardized Operating Procedures (SOPs) into prompt sequences for morestreamlined workflows, thus allowing agents with human-like domain expertise toverify intermediate results and reduce errors. MetaGPT utilizes an assemblyline paradigm to assign diverse roles to various agents, efficiently breakingdown complex tasks into subtasks involving many agents working together. Oncollaborative software engineering benchmarks, MetaGPT generates more coherentsolutions than previous chat-based multi-agent systems. Our project can befound at https://github.com/geekan/MetaGPT</description><author>Sirui Hong, Mingchen Zhuge, Jonathan Chen, Xiawu Zheng, Yuheng Cheng, Ceyao Zhang, Jinlin Wang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, Chenglin Wu, Jürgen Schmidhuber</author><pubDate>Mon, 06 Nov 2023 17:01:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00352v5</guid></item><item><title>Fast Diffusion EM: a diffusion model for blind inverse problems with application to deconvolution</title><link>http://arxiv.org/abs/2309.00287v2</link><description>Using diffusion models to solve inverse problems is a growing field ofresearch. Current methods assume the degradation to be known and provideimpressive results in terms of restoration quality and diversity. In this work,we leverage the efficiency of those models to jointly estimate the restoredimage and unknown parameters of the degradation model such as blur kernel. Inparticular, we designed an algorithm based on the well-knownExpectation-Minimization (EM) estimation method and diffusion models. Ourmethod alternates between approximating the expected log-likelihood of theinverse problem using samples drawn from a diffusion model and a maximizationstep to estimate unknown model parameters. For the maximization step, we alsointroduce a novel blur kernel regularization based on a Plug \&amp; Play denoiser.Diffusion models are long to run, thus we provide a fast version of ouralgorithm. Extensive experiments on blind image deblurring demonstrate theeffectiveness of our method when compared to other state-of-the-art approaches.</description><author>Charles Laroche, Andrés Almansa, Eva Coupete</author><pubDate>Mon, 06 Nov 2023 16:55:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00287v2</guid></item><item><title>From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach</title><link>http://arxiv.org/abs/2311.03260v1</link><description>We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class ofcontinuous-depth graph neural networks (GNNs) that employs the Kuramoto modelto mitigate the over-smoothing phenomenon, in which node features in GNNsbecome indistinguishable as the number of layers increases. The Kuramoto modelcaptures the synchronization behavior of non-linear coupled oscillators. Underthe view of coupled oscillators, we first show the connection between Kuramotomodel and basic GNN and then over-smoothing phenomenon in GNNs can beinterpreted as phase synchronization in Kuramoto model. The KuramotoGNNreplaces this phase synchronization with frequency synchronization to preventthe node features from converging into each other while allowing the system toreach a stable synchronized state. We experimentally verify the advantages ofthe KuramotoGNN over the baseline GNNs and existing methods in reducingover-smoothing on various graph deep learning benchmark tasks.</description><author>Tuan Nguyen, Tan M. Nguyen, Hirotada Honda, Takashi Sano, Vinh Nguyen, Shugo Nakamura</author><pubDate>Mon, 06 Nov 2023 16:47:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03260v1</guid></item><item><title>Coherent Entity Disambiguation via Modeling Topic and Categorical Dependency</title><link>http://arxiv.org/abs/2311.03253v1</link><description>Previous entity disambiguation (ED) methods adopt a discriminative paradigm,where prediction is made based on matching scores between mention context andcandidate entities using length-limited encoders. However, these methods oftenstruggle to capture explicit discourse-level dependencies, resulting inincoherent predictions at the abstract level (e.g. topic or category). Wepropose CoherentED, an ED system equipped with novel designs aimed at enhancingthe coherence of entity predictions. Our method first introduces anunsupervised variational autoencoder (VAE) to extract latent topic vectors ofcontext sentences. This approach not only allows the encoder to handle longerdocuments more effectively, conserves valuable input space, but also keeps atopic-level coherence. Additionally, we incorporate an external categorymemory, enabling the system to retrieve relevant categories for undecidedmentions. By employing step-by-step entity decisions, this design facilitatesthe modeling of entity-entity interactions, thereby maintaining maximumcoherence at the category level. We achieve new state-of-the-art results onpopular ED benchmarks, with an average improvement of 1.3 F1 points. Our modeldemonstrates particularly outstanding performance on challenging long-textscenarios.</description><author>Zilin Xiao, Linjun Shou, Xingyao Zhang, Jie Wu, Ming Gong, Jian Pei, Daxin Jiang</author><pubDate>Mon, 06 Nov 2023 16:40:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03253v1</guid></item><item><title>Parameter-Agnostic Optimization under Relaxed Smoothness</title><link>http://arxiv.org/abs/2311.03252v1</link><description>Tuning hyperparameters, such as the stepsize, presents a major challenge oftraining machine learning models. To address this challenge, numerous adaptiveoptimization algorithms have been developed that achieve near-optimalcomplexities, even when stepsizes are independent of problem-specificparameters, provided that the loss function is $L$-smooth. However, as theassumption is relaxed to the more realistic $(L_0, L_1)$-smoothness, allexisting convergence results still necessitate tuning of the stepsize. In thisstudy, we demonstrate that Normalized Stochastic Gradient Descent with Momentum(NSGD-M) can achieve a (nearly) rate-optimal complexity without prior knowledgeof any problem parameter, though this comes at the cost of introducing anexponential term dependent on $L_1$ in the complexity. We further establishthat this exponential term is inevitable to such schemes by introducing atheoretical framework of lower bounds tailored explicitly forparameter-agnostic algorithms. Interestingly, in deterministic settings, theexponential factor can be neutralized by employing Gradient Descent with aBacktracking Line Search. To the best of our knowledge, these findingsrepresent the first parameter-agnostic convergence results under thegeneralized smoothness condition. Our empirical experiments further confirm ourtheoretical insights.</description><author>Florian Hübler, Junchi Yang, Xiang Li, Niao He</author><pubDate>Mon, 06 Nov 2023 16:39:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03252v1</guid></item><item><title>Computing a human-like reaction time metric from stable recurrent vision models</title><link>http://arxiv.org/abs/2306.11582v2</link><description>The meteoric rise in the adoption of deep neural networks as computationalmodels of vision has inspired efforts to "align" these models with humans. Onedimension of interest for alignment includes behavioral choices, but movingbeyond characterizing choice patterns to capturing temporal aspects of visualdecision-making has been challenging. Here, we sketch a general-purposemethodology to construct computational accounts of reaction times from astimulus-computable, task-optimized model. Specifically, we introduce a novelmetric leveraging insights from subjective logic theory summarizing evidenceaccumulation in recurrent vision models. We demonstrate that our metric alignswith patterns of human reaction times for stimulus manipulations across fourdisparate visual decision-making tasks spanning perceptual grouping, mentalsimulation, and scene categorization. This work paves the way for exploring thetemporal alignment of model and human visual strategies in the context ofvarious other cognitive tasks toward generating testable hypotheses forneuroscience. Links to the code and data can be found on the project page:https://serre-lab.github.io/rnn_rts_site.</description><author>Lore Goetschalckx, Lakshmi Narasimhan Govindarajan, Alekh Karkada Ashok, Aarit Ahuja, David L. Sheinberg, Thomas Serre</author><pubDate>Mon, 06 Nov 2023 16:39:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11582v2</guid></item><item><title>Instructed Language Models with Retrievers Are Powerful Entity Linkers</title><link>http://arxiv.org/abs/2311.03250v1</link><description>Generative approaches powered by large language models (LLMs) havedemonstrated emergent abilities in tasks that require complex reasoningabilities. Yet the generative nature still makes the generated content sufferfrom hallucinations, thus unsuitable for entity-centric tasks like entitylinking (EL) requiring precise entity predictions over a large knowledge base.We present Instructed Generative Entity Linker (INSGENEL), the first approachthat enables casual language models to perform entity linking over knowledgebases. Several methods to equip language models with EL capability wereproposed in this work, including (i) a sequence-to-sequence training ELobjective with instruction-tuning, (ii) a novel generative EL framework basedon a light-weight potential mention retriever that frees the model from heavyand non-parallelizable decoding, achieving 4$\times$ speedup without compromiseon linking metrics. INSGENEL outperforms previous generative alternatives with+6.8 F1 points gain on average, also with a huge advantage in training dataefficiency and training compute consumption. In addition, our skillfullyengineered in-context learning (ICL) framework for EL still lags behindINSGENEL significantly, reaffirming that the EL task remains a persistenthurdle for general LLMs.</description><author>Zilin Xiao, Ming Gong, Jie Wu, Xingyao Zhang, Linjun Shou, Jian Pei, Daxin Jiang</author><pubDate>Mon, 06 Nov 2023 16:38:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03250v1</guid></item><item><title>Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees</title><link>http://arxiv.org/abs/2210.07893v3</link><description>Gaussian processes are frequently deployed as part of larger machine learningand decision-making systems, for instance in geospatial modeling, Bayesianoptimization, or in latent Gaussian models. Within a system, the Gaussianprocess model needs to perform in a stable and reliable manner to ensure itinteracts correctly with other parts of the system. In this work, we study thenumerical stability of scalable sparse approximations based on inducing points.To do so, we first review numerical stability, and illustrate typicalsituations in which Gaussian process models can be unstable. Building onstability theory originally developed in the interpolation literature, wederive sufficient and in certain cases necessary conditions on the inducingpoints for the computations performed to be numerically stable. Forlow-dimensional tasks such as geospatial modeling, we propose an automatedmethod for computing inducing points satisfying these conditions. This is donevia a modification of the cover tree data structure, which is of independentinterest. We additionally propose an alternative sparse approximation forregression with a Gaussian likelihood which trades off a small amount ofperformance to further improve stability. We provide illustrative examplesshowing the relationship between stability of calculations and predictiveperformance of inducing point methods on spatial tasks.</description><author>Alexander Terenin, David R. Burt, Artem Artemev, Seth Flaxman, Mark van der Wilk, Carl Edward Rasmussen, Hong Ge</author><pubDate>Mon, 06 Nov 2023 16:36:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.07893v3</guid></item><item><title>Optimal data pooling for shared learning in maintenance operations</title><link>http://arxiv.org/abs/2308.12670v2</link><description>We study optimal data pooling for shared learning in two common maintenanceoperations: condition-based maintenance and spare parts management. We considera set of systems subject to Poisson input -- the degradation or demand process-- that are coupled through an a-priori unknown rate. Decision problemsinvolving these systems are high-dimensional Markov decision processes (MDPs)and hence notoriously difficult to solve. We present a decomposition resultthat reduces such an MDP to two-dimensional MDPs, enabling structural analysesand computations. Leveraging this decomposition, we (i) demonstrate thatpooling data can lead to significant cost reductions compared to not pooling,and (ii) show that the optimal policy for the condition-based maintenanceproblem is a control limit policy, while for the spare parts managementproblem, it is an order-up-to level policy, both dependent on the pooled data.</description><author>Collin Drent, Melvin Drent, Geert-Jan van Houtum</author><pubDate>Mon, 06 Nov 2023 16:35:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12670v2</guid></item><item><title>Using multimodal learning and deep generative models for corporate bankruptcy prediction</title><link>http://arxiv.org/abs/2211.08405v4</link><description>Textual data from financial filings, e.g., the Management's Discussion \&amp;Analysis (MDA) section in Form 10-K, has been used to improve the predictionaccuracy of bankruptcy models. In practice, however, we cannot obtain the MDAsection for all public companies. The two main reasons for the lack of MDA are:(i) not all companies are obliged to submit the MDA and (ii) technical problemsarise when crawling and scrapping the MDA section. This research introduces forthe first time, to the best of our knowledge, the concept of multimodallearning in bankruptcy prediction models to solve the problem that for somecompanies we are unable to obtain the MDA text. We use the ConditionalMultimodal Discriminative (CMMD) model to learn multimodal representations thatembed information from accounting, market, and textual modalities. The CMMDmodel needs a sample with all data modalities for model training. At test time,the CMMD model only needs access to accounting and market modalities togenerate multimodal representations, which are further used to make bankruptcypredictions. This fact makes the use of bankruptcy prediction models usingtextual data realistic and possible, since accounting and market data areavailable for all companies unlike textual data. The empirical results in thisresearch show that the classification performance of our proposed methodologyis superior compared to that of a large number of traditional classifiermodels. We also show that our proposed methodology solves the limitation ofprevious bankruptcy models using textual data, as they can only makepredictions for a small proportion of companies.</description><author>Rogelio A. Mancisidor, Kjersti Aas</author><pubDate>Mon, 06 Nov 2023 16:34:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.08405v4</guid></item><item><title>Advancing Post Hoc Case Based Explanation with Feature Highlighting</title><link>http://arxiv.org/abs/2311.03246v1</link><description>Explainable AI (XAI) has been proposed as a valuable tool to assist indownstream tasks involving human and AI collaboration. Perhaps the mostpsychologically valid XAI techniques are case based approaches which display'whole' exemplars to explain the predictions of black box AI systems. However,for such post hoc XAI methods dealing with images, there has been no attempt toimprove their scope by using multiple clear feature 'parts' of the images toexplain the predictions while linking back to relevant cases in the trainingdata, thus allowing for more comprehensive explanations that are faithful tothe underlying model. Here, we address this gap by proposing two generalalgorithms (latent and super pixel based) which can isolate multiple clearfeature parts in a test image, and then connect them to the explanatory casesfound in the training data, before testing their effectiveness in a carefullydesigned user study. Results demonstrate that the proposed approachappropriately calibrates a users feelings of 'correctness' for ambiguousclassifications in real world data on the ImageNet dataset, an effect whichdoes not happen when just showing the explanation without feature highlighting.</description><author>Eoin Kenny, Eoin Delaney, Mark Keane</author><pubDate>Mon, 06 Nov 2023 16:34:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03246v1</guid></item><item><title>ProtoryNet - Interpretable Text Classification Via Prototype Trajectories</title><link>http://arxiv.org/abs/2007.01777v5</link><description>We propose a novel interpretable deep neural network for text classification,called ProtoryNet, based on a new concept of prototype trajectories. Motivatedby the prototype theory in modern linguistics, ProtoryNet makes a prediction byfinding the most similar prototype for each sentence in a text sequence andfeeding an RNN backbone with the proximity of each sentence to thecorresponding active prototype. The RNN backbone then captures the temporalpattern of the prototypes, which we refer to as prototype trajectories.Prototype trajectories enable intuitive and fine-grained interpretation of thereasoning process of the RNN model, in resemblance to how humans analyze texts.We also design a prototype pruning procedure to reduce the total number ofprototypes used by the model for better interpretability. Experiments onmultiple public data sets show that ProtoryNet is more accurate than thebaseline prototype-based deep neural net and reduces the performance gapcompared to state-of-the-art black-box models. In addition, after prototypepruning, the resulting ProtoryNet models only need less than or around 20prototypes for all datasets, which significantly benefits interpretability.Furthermore, we report a survey result indicating that human users findProtoryNet more intuitive and easier to understand than other prototype-basedmethods.</description><author>Dat Hong, Tong Wang, Stephen S. Baek</author><pubDate>Mon, 06 Nov 2023 16:33:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2007.01777v5</guid></item><item><title>Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation</title><link>http://arxiv.org/abs/2311.01766v2</link><description>Mis- and disinformation online have become a major societal problem as majorsources of online harms of different kinds. One common form of mis- anddisinformation is out-of-context (OOC) information, where different pieces ofinformation are falsely associated, e.g., a real image combined with a falsetextual caption or a misleading textual description. Although some past studieshave attempted to defend against OOC mis- and disinformation through externalevidence, they tend to disregard the role of different pieces of evidence withdifferent stances. Motivated by the intuition that the stance of evidencerepresents a bias towards different detection results, we propose a stanceextraction network (SEN) that can extract the stances of different pieces ofmulti-modal evidence in a unified framework. Moreover, we introduce asupport-refutation score calculated based on the co-occurrence relations ofnamed entities into the textual SEN. Extensive experiments on a publiclarge-scale dataset demonstrated that our proposed method outperformed thestate-of-the-art baselines, with the best model achieving a performance gain of3.2% in accuracy.</description><author>Xin Yuan, Jie Guo, Weidong Qiu, Zheng Huang, Shujun Li</author><pubDate>Mon, 06 Nov 2023 16:33:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01766v2</guid></item><item><title>Safurai-Csharp: Harnessing Synthetic Data to improve language-specific Code LLM</title><link>http://arxiv.org/abs/2311.03243v1</link><description>This paper introduces Safurai-Csharp, an open-source model designed tospecialize in the generation, completion, and debugging of C# code.Safurai-Csharp is built upon the novel CodeLlama 34B model and leverages theEvolInstruct technique, creating a refined and expanded dataset for itsfine-tuning process. The results of its performance, a notable score of 56.33%on the Manual MultiPL-E benchmark (Zero-Shot, Pass@1), signal its high capacityto streamline developers' workflows and aid code learning. It shows promise insetting new stakes in the landscape of open-source C# LLMs and hopes to inspiremore inclusive and wide-ranging development in the field of language-specificLLMs.</description><author>Davide Cifarelli, Leonardo Boiardi, Alessandro Puppo, Leon Jovanovic</author><pubDate>Mon, 06 Nov 2023 16:31:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03243v1</guid></item><item><title>Approximating Langevin Monte Carlo with ResNet-like Neural Network architectures</title><link>http://arxiv.org/abs/2311.03242v1</link><description>We sample from a given target distribution by constructing a neural networkwhich maps samples from a simple reference, e.g. the standard normaldistribution, to samples from the target. To that end, we propose using aneural network architecture inspired by the Langevin Monte Carlo (LMC)algorithm. Based on LMC perturbation results, we show approximation rates ofthe proposed architecture for smooth, log-concave target distributions measuredin the Wasserstein-$2$ distance. The analysis heavily relies on the notion ofsub-Gaussianity of the intermediate measures of the perturbed LMC process. Inparticular, we derive bounds on the growth of the intermediate variance proxiesunder different assumptions on the perturbations. Moreover, we propose anarchitecture similar to deep residual neural networks and derive expressivityresults for approximating the sample to target distribution map.</description><author>Martin Eigel, Charles Miranda, Janina Schütte, David Sommer</author><pubDate>Mon, 06 Nov 2023 16:31:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03242v1</guid></item><item><title>Machine Learning-Based Tea Leaf Disease Detection: A Comprehensive Review</title><link>http://arxiv.org/abs/2311.03240v1</link><description>Tea leaf diseases are a major challenge to agricultural productivity, withfar-reaching implications for yield and quality in the tea industry. The riseof machine learning has enabled the development of innovative approaches tocombat these diseases. Early detection and diagnosis are crucial for effectivecrop management. For predicting tea leaf disease, several automated systemshave already been developed using different image processing techniques. Thispaper delivers a systematic review of the literature on machine learningmethodologies applied to diagnose tea leaf disease via image classification. Itthoroughly evaluates the strengths and constraints of various VisionTransformer models, including Inception Convolutional Vision Transformer(ICVT), GreenViT, PlantXViT, PlantViT, MSCVT, Transfer Learning Model &amp; VisionTransformer (TLMViT), IterationViT, IEM-ViT. Moreover, this paper also reviewsmodels like Dense Convolutional Network (DenseNet), Residual Neural Network(ResNet)-50V2, YOLOv5, YOLOv7, Convolutional Neural Network (CNN), Deep CNN,Non-dominated Sorting Genetic Algorithm (NSGA-II), MobileNetv2, andLesion-Aware Visual Transformer. These machine-learning models have been testedon various datasets, demonstrating their real-world applicability. This reviewstudy not only highlights current progress in the field but also providesvaluable insights for future research directions in the machine learning-baseddetection and classification of tea leaf diseases.</description><author>Faruk Ahmed, Md. Taimur Ahad, Yousuf Rayhan Emon</author><pubDate>Mon, 06 Nov 2023 16:30:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03240v1</guid></item><item><title>LIMIT: Language Identification, Misidentification, and Translation using Hierarchical Models in 350+ Languages</title><link>http://arxiv.org/abs/2305.14263v2</link><description>Knowing the language of an input text/audio is a necessary first step forusing almost every NLP tool such as taggers, parsers, or translation systems.Language identification is a well-studied problem, sometimes even consideredsolved; in reality, due to lack of data and computational challenges, currentsystems cannot accurately identify most of the world's 7000 languages. Totackle this bottleneck, we first compile a corpus, MCS-350, of 50K multilingualand parallel children's stories in 350+ languages. MCS-350 can serve as abenchmark for language identification of short texts and for 1400+ newtranslation directions in low-resource Indian and African languages. Second, wepropose a novel misprediction-resolution hierarchical model, LIMIt, forlanguage identification that reduces error by 55% (from 0.71 to 0.32) on ourcompiled children's stories dataset and by 40% (from 0.23 to 0.14) on theFLORES-200 benchmark. Our method can expand language identification coverageinto low-resource languages by relying solely on systemic mispredictionpatterns, bypassing the need to retrain large models from scratch.</description><author>Milind Agarwal, Md Mahfuz Ibn Alam, Antonios Anastasopoulos</author><pubDate>Mon, 06 Nov 2023 16:29:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14263v2</guid></item><item><title>Path Analysis for Effective Fault Localization in Deep Neural Networks</title><link>http://arxiv.org/abs/2310.18987v2</link><description>Deep learning has revolutionized various real-world applications, but thequality of Deep Neural Networks (DNNs) remains a concern. DNNs are complex andhave millions of parameters, making it difficult to determine theircontributions to fulfilling a task. Moreover, the behavior of a DNN is highlyinfluenced by the data used during training, making it challenging to collectenough data to exercise all potential DNN behavior under all possiblescenarios. This paper proposes NP SBFL method to locate faulty neural pathways(NP) using spectrum-based fault localization (SBFL). Our method identifiescritical neurons using the layer-wise relevance propagation (LRP) technique anddetermines which critical neurons are faulty. Moreover, we propose amulti-stage gradient ascent (MGA), an extension of gradient ascent (GA), toeffectively activate a sequence of neurons one at a time while maintaining theactivation of previous neurons, so we are able to test the reported faultypathways. We evaluated the effectiveness of our method, i.e. NP-SBFL-MGA, ontwo commonly used datasets, MNIST and CIFAR-10, two baselines DeepFault andNP-SBFL-GA, and three suspicious neuron measures, Tarantula, Ochiai, andBarinel. The empirical results showed that NP-SBFL-MGA is statistically moreeffective than the baselines at identifying suspicious paths and synthesizingadversarial inputs. Particularly, Tarantula on NP-SBFL-MGA had the highestfault detection rate at 96.75%, surpassing DeepFault on Ochiai (89.90%) andNP-SBFL-GA on Ochiai (60.61%). Our approach also yielded comparable results tothe baselines in synthesizing naturalness inputs, and we found a positivecorrelation between the coverage of critical paths and the number of failedtests in DNN fault localization.</description><author>Soroush Hashemifar, Saeed Parsa, Akram Kalaee</author><pubDate>Mon, 06 Nov 2023 16:27:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18987v2</guid></item><item><title>Out-of-distribution Detection Learning with Unreliable Out-of-distribution Sources</title><link>http://arxiv.org/abs/2311.03236v1</link><description>Out-of-distribution (OOD) detection discerns OOD data where the predictorcannot make valid predictions as in-distribution (ID) data, thereby increasingthe reliability of open-world classification. However, it is typically hard tocollect real out-of-distribution (OOD) data for training a predictor capable ofdiscerning ID and OOD patterns. This obstacle gives rise to datageneration-based learning methods, synthesizing OOD data via data generatorsfor predictor training without requiring any real OOD data. Related methodstypically pre-train a generator on ID data and adopt various selectionprocedures to find those data likely to be the OOD cases. However, generateddata may still coincide with ID semantics, i.e., mistaken OOD generationremains, confusing the predictor between ID and OOD data. To this end, wesuggest that generated data (with mistaken OOD generation) can be used todevise an auxiliary OOD detection task to facilitate real OOD detection.Specifically, we can ensure that learning from such an auxiliary task isbeneficial if the ID and the OOD parts have disjoint supports, with the help ofa well-designed training procedure for the predictor. Accordingly, we propose apowerful data generation-based learning method named Auxiliary Task-based OODLearning (ATOL) that can relieve the mistaken OOD generation. We conductextensive experiments under various OOD detection setups, demonstrating theeffectiveness of our method against its advanced counterparts.</description><author>Haotian Zheng, Qizhou Wang, Zhen Fang, Xiaobo Xia, Feng Liu, Tongliang Liu, Bo Han</author><pubDate>Mon, 06 Nov 2023 16:26:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03236v1</guid></item><item><title>A Brain-Inspired Sequence Learning Model based on a Logic</title><link>http://arxiv.org/abs/2308.12486v2</link><description>Sequence learning is an essential aspect of intelligence. In ArtificialIntelligence, sequence prediction task is usually used to test a sequencelearning model. In this paper, a model of sequence learning, which isinterpretable through Non-Axiomatic Logic, is designed and tested. The learningmechanism is composed of three steps, hypothesizing, revising, and recycling,which enable the model to work under the Assumption of Insufficient Knowledgeand Resources. Synthetic datasets for sequence prediction task are generated totest the capacity of the model. The results show that the model works wellwithin different levels of difficulty. In addition, since the model adoptsconcept-centered representation, it theoretically does not suffer fromcatastrophic forgetting, and the practical results also support this property.This paper shows the potential of learning sequences in a logical way.</description><author>Bowen Xu</author><pubDate>Mon, 06 Nov 2023 16:26:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12486v2</guid></item><item><title>p-Laplacian Transformer</title><link>http://arxiv.org/abs/2311.03235v1</link><description>$p$-Laplacian regularization, rooted in graph and image signal processing,introduces a parameter $p$ to control the regularization effect on these data.Smaller values of $p$ promote sparsity and interpretability, while largervalues encourage smoother solutions. In this paper, we first show that theself-attention mechanism obtains the minimal Laplacian regularization ($p=2$)and encourages the smoothness in the architecture. However, the smoothness isnot suitable for the heterophilic structure of self-attention in transformerswhere attention weights between tokens that are in close proximity andnon-close ones are assigned indistinguishably. From that insight, we thenpropose a novel class of transformers, namely the $p$-Laplacian Transformer(p-LaT), which leverages $p$-Laplacian regularization framework to harness theheterophilic features within self-attention layers. In particular, low $p$values will effectively assign higher attention weights to tokens that are inclose proximity to the current token being processed. We empiricallydemonstrate the advantages of p-LaT over the baseline transformers on a widerange of benchmark datasets.</description><author>Tuan Nguyen, Tam Nguyen, Vinh Nguyen, Tan M. Nguyen</author><pubDate>Mon, 06 Nov 2023 16:25:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03235v1</guid></item><item><title>Navigating Scaling Laws: Accelerating Vision Transformer's Training via Adaptive Strategies</title><link>http://arxiv.org/abs/2311.03233v1</link><description>In recent years, the state-of-the-art in deep learning has been dominated byvery large models that have been pre-trained on vast amounts of data. Theparadigm is very simple: Investing more computational resources (optimally)leads to better performance, and even predictably so; neural scaling laws havebeen derived that accurately forecast the performance of a network for adesired level of compute. This leads to the notion of a "compute-optimal"model, i.e. a model that allocates a given level of compute during trainingoptimally to maximise performance. In this work, we extend the concept ofoptimality by allowing for an "adaptive" model, i.e. a model that can changeits shape during the course of training. By allowing the shape to adapt, we canoptimally traverse between the underlying scaling laws, leading to asignificant reduction in the required compute to reach a given targetperformance. We focus on vision tasks and the family of Vision Transformers,where the patch size as well as the width naturally serve as adaptive shapeparameters. We demonstrate that, guided by scaling laws, we can designcompute-optimal adaptive models that beat their "static" counterparts.</description><author>Sotiris Anagnostidis, Gregor Bachmann, Thomas Hofmann</author><pubDate>Mon, 06 Nov 2023 16:20:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03233v1</guid></item><item><title>Uniformly Distributed Category Prototype-Guided Vision-Language Framework for Long-Tail Recognition</title><link>http://arxiv.org/abs/2308.12522v2</link><description>Recently, large-scale pre-trained vision-language models have presentedbenefits for alleviating class imbalance in long-tailed recognition. However,the long-tailed data distribution can corrupt the representation space, wherethe distance between head and tail categories is much larger than the distancebetween two tail categories. This uneven feature space distribution causes themodel to exhibit unclear and inseparable decision boundaries on the uniformlydistributed test set, which lowers its performance. To address thesechallenges, we propose the uniformly category prototype-guided vision-languageframework to effectively mitigate feature space bias caused by data imbalance.Especially, we generate a set of category prototypes uniformly distributed on ahypersphere. Category prototype-guided mechanism for image-text matching makesthe features of different classes converge to these distinct and uniformlydistributed category prototypes, which maintain a uniform distribution in thefeature space, and improve class boundaries. Additionally, our proposedirrelevant text filtering and attribute enhancement module allows the model toignore irrelevant noisy text and focus more on key attribute information,thereby enhancing the robustness of our framework. In the image recognitionfine-tuning stage, to address the positive bias problem of the learnableclassifier, we design the class feature prototype-guided classifier, whichcompensates for the performance of tail classes while maintaining theperformance of head classes. Our method outperforms previous vision-languagemethods for long-tailed learning work by a large margin and achievesstate-of-the-art performance.</description><author>Siming Fu, Xiaoxuan He, Xinpeng Ding, Yuchen Cao, Hualiang Wang</author><pubDate>Mon, 06 Nov 2023 16:16:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12522v2</guid></item><item><title>An Efficient Self-Supervised Cross-View Training For Sentence Embedding</title><link>http://arxiv.org/abs/2311.03228v1</link><description>Self-supervised sentence representation learning is the task of constructingan embedding space for sentences without relying on human annotation efforts.One straightforward approach is to finetune a pretrained language model (PLM)with a representation learning method such as contrastive learning. While thisapproach achieves impressive performance on larger PLMs, the performancerapidly degrades as the number of parameters decreases. In this paper, wepropose a framework called Self-supervised Cross-View Training (SCT) to narrowthe performance gap between large and small PLMs. To evaluate the effectivenessof SCT, we compare it to 5 baseline and state-of-the-art competitors on sevenSemantic Textual Similarity (STS) benchmarks using 5 PLMs with the number ofparameters ranging from 4M to 340M. The experimental results show that STCoutperforms the competitors for PLMs with less than 100M parameters in 18 of 21cases.</description><author>Peerat Limkonchotiwat, Wuttikorn Ponwitayarat, Lalita Lowphansirikul, Can Udomcharoenchaikit, Ekapol Chuangsuwanich, Sarana Nutanong</author><pubDate>Mon, 06 Nov 2023 16:12:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03228v1</guid></item><item><title>LDM3D-VR: Latent Diffusion Model for 3D VR</title><link>http://arxiv.org/abs/2311.03226v1</link><description>Latent diffusion models have proven to be state-of-the-art in the creationand manipulation of visual outputs. However, as far as we know, the generationof depth maps jointly with RGB is still limited. We introduce LDM3D-VR, a suiteof diffusion models targeting virtual reality development that includesLDM3D-pano and LDM3D-SR. These models enable the generation of panoramic RGBDbased on textual prompts and the upscaling of low-resolution inputs tohigh-resolution RGBD, respectively. Our models are fine-tuned from existingpretrained models on datasets containing panoramic/high-resolution RGB images,depth maps and captions. Both models are evaluated in comparison to existingrelated methods.</description><author>Gabriela Ben Melech Stan, Diana Wofk, Estelle Aflalo, Shao-Yen Tseng, Zhipeng Cai, Michael Paulitsch, Vasudev Lal</author><pubDate>Mon, 06 Nov 2023 16:12:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03226v1</guid></item><item><title>Segmentation of Drone Collision Hazards in Airborne RADAR Point Clouds Using PointNet</title><link>http://arxiv.org/abs/2311.03221v1</link><description>The integration of unmanned aerial vehicles (UAVs) into shared airspace forbeyond visual line of sight (BVLOS) operations presents significant challengesbut holds transformative potential for sectors like transportation,construction, energy and defense. A critical prerequisite for this integrationis equipping UAVs with enhanced situational awareness to ensure safeoperations. Current approaches mainly target single object detection orclassification, or simpler sensing outputs that offer limited perceptualunderstanding and lack the rapid end-to-end processing needed to convert sensordata into safety-critical insights. In contrast, our study leverages radartechnology for novel end-to-end semantic segmentation of aerial point clouds tosimultaneously identify multiple collision hazards. By adapting and optimizingthe PointNet architecture and integrating aerial domain insights, our frameworkdistinguishes five distinct classes: mobile drones (DJI M300 and DJI Mini) andairplanes (Ikarus C42), and static returns (ground and infrastructure) whichresults in enhanced situational awareness for UAVs. To our knowledge, this isthe first approach addressing simultaneous identification of multiple collisionthreats in an aerial setting, achieving a robust 94% accuracy. This workhighlights the potential of radar technology to advance situational awarenessin UAVs, facilitating safe and efficient BVLOS operations.</description><author>Hector Arroyo, Paul Kier, Dylan Angus, Santiago Matalonga, Svetlozar Georgiev, Mehdi Goli, Gerard Dooly, James Riordan</author><pubDate>Mon, 06 Nov 2023 16:04:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03221v1</guid></item><item><title>ALYMPICS: Language Agents Meet Game Theory</title><link>http://arxiv.org/abs/2311.03220v1</link><description>This paper introduces Alympics, a platform that leverages Large LanguageModel (LLM) agents to facilitate investigations in game theory. By employingLLMs and autonomous agents to simulate human behavior and enable multi-agentcollaborations, we can construct realistic and dynamic models of humaninteractions for game theory hypothesis formulating and testing. To demonstratethis, we present and implement a survival game involving unequal competitionfor limited resources. Through manipulation of resource availability and agentpersonalities, we observe how different agents engage in the competition andadapt their strategies. The use of LLM agents in game theory research offerssignificant advantages, including simulating realistic behavior, providing acontrolled, scalable, and reproducible environment. Our work highlights thepotential of LLM agents in enhancing the understanding of strategicdecision-making within complex socioeconomic contexts. All codes will be madepublic soon.</description><author>Shaoguang Mao, Yuzhe Cai, Yan Xia, Wenshan Wu, Xun Wang, Fengyi Wang, Tao Ge, Furu Wei</author><pubDate>Mon, 06 Nov 2023 16:03:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03220v1</guid></item><item><title>Leveraging Transformers to Improve Breast Cancer Classification and Risk Assessment with Multi-modal and Longitudinal Data</title><link>http://arxiv.org/abs/2311.03217v1</link><description>Breast cancer screening, primarily conducted through mammography, is oftensupplemented with ultrasound for women with dense breast tissue. However,existing deep learning models analyze each modality independently, missingopportunities to integrate information across imaging modalities and time. Inthis study, we present Multi-modal Transformer (MMT), a neural network thatutilizes mammography and ultrasound synergistically, to identify patients whocurrently have cancer and estimate the risk of future cancer for patients whoare currently cancer-free. MMT aggregates multi-modal data throughself-attention and tracks temporal tissue changes by comparing current exams toprior imaging. Trained on 1.3 million exams, MMT achieves an AUROC of 0.943 indetecting existing cancers, surpassing strong uni-modal baselines. For 5-yearrisk prediction, MMT attains an AUROC of 0.826, outperforming priormammography-based risk models. Our research highlights the value of multi-modaland longitudinal imaging in cancer diagnosis and risk stratification.</description><author>Yiqiu Shen, Jungkyu Park, Frank Yeung, Eliana Goldberg, Laura Heacock, Farah Shamout, Krzysztof J. Geras</author><pubDate>Mon, 06 Nov 2023 16:01:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03217v1</guid></item><item><title>Mini Minds: Exploring Bebeshka and Zlata Baby Models</title><link>http://arxiv.org/abs/2311.03216v1</link><description>In this paper, we describe the University of Lyon 2 submission to theStrict-Small track of the BabyLM competition. The shared task is created withan emphasis on small-scale language modelling from scratch on limited-size dataand human language acquisition. Dataset released for the Strict-Small track has10M words, which is comparable to children's vocabulary size. We approach thetask with an architecture search, minimizing masked language modelling loss onthe data of the shared task. Having found an optimal configuration, weintroduce two small-size language models (LMs) that were submitted forevaluation, a 4-layer encoder with 8 attention heads and a 6-layer decodermodel with 12 heads which we term Bebeshka and Zlata, respectively. Despitebeing half the scale of the baseline LMs, our proposed models achievecomparable performance. We further explore the applicability of small-scalelanguage models in tasks involving moral judgment, aligning their predictionswith human values. These findings highlight the potential of compact LMs inaddressing practical language understanding tasks.</description><author>Irina Proskurina, Guillaume Metzler, Julien Velcin</author><pubDate>Mon, 06 Nov 2023 16:01:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03216v1</guid></item><item><title>On existence, uniqueness and scalability of adversarial robustness measures for AI classifiers</title><link>http://arxiv.org/abs/2310.14421v2</link><description>Simply-verifiable mathematical conditions for existence, uniqueness andexplicit analytical computation of minimal adversarial paths (MAP) and minimaladversarial distances (MAD) for (locally) uniquely-invertible classifiers, forgeneralized linear models (GLM), and for entropic AI (EAI) are formulated andproven. Practical computation of MAP and MAD, their comparison andinterpretations for various classes of AI tools (for neuronal networks, boostedrandom forests, GLM and EAI) are demonstrated on the common syntheticbenchmarks: on a double Swiss roll spiral and its extensions, as well as on thetwo biomedical data problems (for the health insurance claim predictions, andfor the heart attack lethality classification). On biomedical applications itis demonstrated how MAP provides unique minimal patient-specificrisk-mitigating interventions in the predefined subsets of accessible controlvariables.</description><author>Illia Horenko</author><pubDate>Mon, 06 Nov 2023 15:57:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14421v2</guid></item><item><title>SciLit: A Platform for Joint Scientific Literature Discovery, Summarization and Citation Generation</title><link>http://arxiv.org/abs/2306.03535v2</link><description>Scientific writing involves retrieving, summarizing, and citing relevantpapers, which can be time-consuming processes in large and rapidly evolvingfields. By making these processes inter-operable, natural language processing(NLP) provides opportunities for creating end-to-end assistive writing tools.We propose SciLit, a pipeline that automatically recommends relevant papers,extracts highlights, and suggests a reference sentence as a citation of apaper, taking into consideration the user-provided context and keywords. SciLitefficiently recommends papers from large databases of hundreds of millions ofpapers using a two-stage pre-fetching and re-ranking literature search systemthat flexibly deals with addition and removal of a paper database. We provide aconvenient user interface that displays the recommended papers as extractivesummaries and that offers abstractively-generated citing sentences which arealigned with the provided context and which mention the chosen keyword(s). Ourassistive tool for literature discovery and scientific writing is available athttps://scilit.vercel.app</description><author>Nianlong Gu, Richard H. R. Hahnloser</author><pubDate>Mon, 06 Nov 2023 15:53:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03535v2</guid></item><item><title>Predictive Data Analytics with AI: assessing the need for post-editing of MT output by fine-tuning OpenAI LLMs</title><link>http://arxiv.org/abs/2308.00158v4</link><description>Translation Quality Evaluation (TQE) is an essential step of the moderntranslation production process. TQE is critical in assessing both machinetranslation (MT) and human translation (HT) quality without referencetranslations. The ability to evaluate or even simply estimate the quality oftranslation automatically may open significant efficiency gains through processoptimisation. This work examines whether the state-of-the-art large languagemodels (LLMs) can be used for this purpose. We take OpenAI models as the beststate-of-the-art technology and approach TQE as a binary classification task.On \textbf{eight language pairs} including English to Italian, German, French,Japanese, Dutch, Portuguese, Turkish, and Chinese, our experimental resultsshow that fine-tuned \textbf{\textit{gpt3.5}} can demonstrate good performanceon translation quality prediction tasks, i.e. \textit{whether the translationneeds to be edited}. Another finding is that simply increasing the sizes ofLLMs does not lead to apparent better performances on this task by comparingthe performance of three different versions of OpenAI models:\textbf{\textit{curie}}, \textbf{\textit{davinci}}, and\textbf{\textit{gpt3.5}} with 13B, 175B, and 175B parameters, respectively.</description><author>Serge Gladkoff, Gleb Erofeev, Lifeng Han, Goran Nenadic</author><pubDate>Mon, 06 Nov 2023 15:52:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00158v4</guid></item><item><title>Feature selection and regression methods for stock price prediction using technical indicators</title><link>http://arxiv.org/abs/2310.09903v4</link><description>Due to the influence of many factors, including technical indicators on stockprice prediction, feature selection is important to choose the best indicators.This study uses technical indicators and features selection and regressionmethods to solve the problem of closing the stock market price. The aim of thisresearch is to predict the stock market price with the least error. By theproposed method, the data created by the 3-day time window were converted tothe appropriate input for regression methods. In this paper, 10 regressor and123 technical indicators have been examined on data of the last 13 years ofApple Company. The results have been investigated by 5 error-based evaluationcriteria. Based on results of the proposed method, MLPSF has 56/47% betterperformance than MLP. Also, SVRSF has 67/42% improved compared to SVR. LRSF was76.7 % improved compared to LR. The RISF method also improved 72.82 % of Ridgeregression. The DTRSB method had 24.23 % improvement over DTR. KNNSB had 15.52% improvement over KNN regression. RFSB had a 6 % improvement over RF. GBRSFalso improved at 7% over GBR. Finally, ADASF and ADASB also had a 4%improvement over the ADA regression. Also, Ridge and LinearRegression had thebest results for stock price prediction. Based on results, the best indicatorsto predict stock price are: the Squeeze_pro, Percentage Price Oscillator,Thermo, Decay, Archer On-Balance Volume, Bollinger Bands, Squeeze and Ichimokuindicator. According to the results, the use of suitable combination ofsuggested indicators along with regression methods has resulted in highaccuracy in predicting the closing price.</description><author>Fatemeh Moodi, Amir Jahangard-Rafsanjani, Sajad Zarifzadeh</author><pubDate>Mon, 06 Nov 2023 15:50:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09903v4</guid></item><item><title>An Online Multiple Kernel Parallelizable Learning Scheme</title><link>http://arxiv.org/abs/2308.10101v2</link><description>The performance of reproducing kernel Hilbert space-based methods is known tobe sensitive to the choice of the reproducing kernel. Choosing an adequatereproducing kernel can be challenging and computationally demanding, especiallyin data-rich tasks without prior information about the solution domain. In thispaper, we propose a learning scheme that scalably combines several singlekernel-based online methods to reduce the kernel-selection bias. The proposedlearning scheme applies to any task formulated as a regularized empirical riskminimization convex problem. More specifically, our learning scheme is based ona multi-kernel learning formulation that can be applied to widen anysingle-kernel solution space, thus increasing the possibility of findinghigher-performance solutions. In addition, it is parallelizable, allowing forthe distribution of the computational load across different computing units. Weshow experimentally that the proposed learning scheme outperforms the combinedsingle-kernel online methods separately in terms of the cumulative regularizedleast squares cost metric.</description><author>Emilio Ruiz-Moreno, Baltasar Beferull-Lozano</author><pubDate>Mon, 06 Nov 2023 15:50:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10101v2</guid></item><item><title>PainSeeker: An Automated Method for Assessing Pain in Rats Through Facial Expressions</title><link>http://arxiv.org/abs/2311.03205v1</link><description>In this letter, we aim to investigate whether laboratory rats' pain can beautomatically assessed through their facial expressions. To this end, we beganby presenting a publicly available dataset called RatsPain, consisting of 1,138facial images captured from six rats that underwent an orthodontic treatmentoperation. Each rat' facial images in RatsPain were carefully selected fromvideos recorded either before or after the operation and well labeled by eightannotators according to the Rat Grimace Scale (RGS). We then proposed a noveldeep learning method called PainSeeker for automatically assessing pain in ratsvia facial expressions. PainSeeker aims to seek pain-related facial localregions that facilitate learning both pain discriminative and head pose robustfeatures from facial expression images. To evaluate the PainSeeker, weconducted extensive experiments on the RatsPain dataset. The resultsdemonstrate the feasibility of assessing rats' pain from their facialexpressions and also verify the effectiveness of the proposed PainSeeker inaddressing this emerging but intriguing problem. The RasPain dataset can befreely obtained from https://github.com/xhzongyuan/RatsPain.</description><author>Liu Liu, Guang Li, Dingfan Deng, Jinhua Yu, Yuan Zong</author><pubDate>Mon, 06 Nov 2023 15:49:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03205v1</guid></item><item><title>NODE-ImgNet: a PDE-informed effective and robust model for image denoising</title><link>http://arxiv.org/abs/2305.11049v2</link><description>Inspired by the traditional partial differential equation (PDE) approach forimage denoising, we propose a novel neural network architecture, referred asNODE-ImgNet, that combines neural ordinary differential equations (NODEs) withconvolutional neural network (CNN) blocks. NODE-ImgNet is intrinsically a PDEmodel, where the dynamic system is learned implicitly without the explicitspecification of the PDE. This naturally circumvents the typical issuesassociated with introducing artifacts during the learning process. By invokingsuch a NODE structure, which can also be viewed as a continuous variant of aresidual network (ResNet) and inherits its advantage in image denoising, ourmodel achieves enhanced accuracy and parameter efficiency. In particular, ourmodel exhibits consistent effectiveness in different scenarios, includingdenoising gray and color images perturbed by Gaussian noise, as well asreal-noisy images, and demonstrates superiority in learning from small imagedatasets.</description><author>Xinheng Xie, Yue Wu, Hao Ni, Cuiyu He</author><pubDate>Mon, 06 Nov 2023 15:47:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11049v2</guid></item><item><title>Spatial Process Approximations: Assessing Their Necessity</title><link>http://arxiv.org/abs/2311.03201v1</link><description>In spatial statistics and machine learning, the kernel matrix plays a pivotalrole in prediction, classification, and maximum likelihood estimation. Athorough examination reveals that for large sample sizes, the kernel matrixbecomes ill-conditioned, provided the sampling locations are fairly evenlydistributed. This condition poses significant challenges to numericalalgorithms used in prediction and estimation computations and necessitates anapproximation to prediction and the Gaussian likelihood. A review of currentmethodologies for managing large spatial data indicates that some fail toaddress this ill-conditioning problem. Such ill-conditioning often results inlow-rank approximations of the stochastic processes. This paper introducesvarious optimality criteria and provides solutions for each.</description><author>Hao Zhang</author><pubDate>Mon, 06 Nov 2023 15:46:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03201v1</guid></item><item><title>LCPR: A Multi-Scale Attention-Based LiDAR-Camera Fusion Network for Place Recognition</title><link>http://arxiv.org/abs/2311.03198v1</link><description>Place recognition is one of the most crucial modules for autonomous vehiclesto identify places that were previously visited in GPS-invalid environments.Sensor fusion is considered an effective method to overcome the weaknesses ofindividual sensors. In recent years, multimodal place recognition fusinginformation from multiple sensors has gathered increasing attention. However,most existing multimodal place recognition methods only use limitedfield-of-view camera images, which leads to an imbalance between features fromdifferent modalities and limits the effectiveness of sensor fusion. In thispaper, we present a novel neural network named LCPR for robust multimodal placerecognition, which fuses LiDAR point clouds with multi-view RGB images togenerate discriminative and yaw-rotation invariant representations of theenvironment. A multi-scale attention-based fusion module is proposed to fullyexploit the panoramic views from different modalities of the environment andtheir correlations. We evaluate our method on the nuScenes dataset, and theexperimental results show that our method can effectively utilize multi-viewcamera and LiDAR data to improve the place recognition performance whilemaintaining strong robustness to viewpoint changes. Our open-source code andpre-trained models are available at https://github.com/ZhouZijie77/LCPR .</description><author>Zijie Zhou, Jingyi Xu, Guangming Xiong, Junyi Ma</author><pubDate>Mon, 06 Nov 2023 15:39:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03198v1</guid></item><item><title>Stable Linear Subspace Identification: A Machine Learning Approach</title><link>http://arxiv.org/abs/2311.03197v1</link><description>Machine Learning (ML) and linear System Identification (SI) have beenhistorically developed independently. In this paper, we leveragewell-established ML tools - especially the automatic differentiation framework- to introduce SIMBa, a family of discrete linear multi-step-ahead state-spaceSI methods using backpropagation. SIMBa relies on a novelLinear-Matrix-Inequality-based free parametrization of Schur matrices to ensurethe stability of the identified model. We show how SIMBa generally outperforms traditional linear state-space SImethods, and sometimes significantly, although at the price of a highercomputational burden. This performance gap is particularly remarkable comparedto other SI methods with stability guarantees, where the gain is frequentlyabove 25% in our investigations, hinting at SIMBa's ability to simultaneouslyachieve state-of-the-art fitting performance and enforce stability.Interestingly, these observations hold for a wide variety of input-outputsystems and on both simulated and real-world data, showcasing the flexibilityof the proposed approach. We postulate that this new SI paradigm presents agreat extension potential to identify structured nonlinear models from data,and we hence open-source SIMBa on https://github.com/Cemempamoi/simba.</description><author>Loris Di Natale, Muhammad Zakwan, Bratislav Svetozarevic, Philipp Heer, Giancarlo Ferrari Trecate, Colin N. Jones</author><pubDate>Mon, 06 Nov 2023 15:39:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03197v1</guid></item><item><title>Pseudo-Labeling for Domain-Agnostic Bangla Automatic Speech Recognition</title><link>http://arxiv.org/abs/2311.03196v1</link><description>One of the major challenges for developing automatic speech recognition (ASR)for low-resource languages is the limited access to labeled data withdomain-specific variations. In this study, we propose a pseudo-labelingapproach to develop a large-scale domain-agnostic ASR dataset. With theproposed methodology, we developed a 20k+ hours labeled Bangla speech datasetcovering diverse topics, speaking styles, dialects, noisy environments, andconversational scenarios. We then exploited the developed corpus to design aconformer-based ASR system. We benchmarked the trained ASR with publiclyavailable datasets and compared it with other available models. To investigatethe efficacy, we designed and developed a human-annotated domain-agnostic testset composed of news, telephony, and conversational data among others. Ourresults demonstrate the efficacy of the model trained on psuedo-label data forthe designed test-set along with publicly-available Bangla datasets. Theexperimental resources will be publiclyavailable.(https://github.com/hishab-nlp/Pseudo-Labeling-for-Domain-Agnostic-Bangla-ASR)</description><author>Rabindra Nath Nandi, Mehadi Hasan Menon, Tareq Al Muntasir, Sagor Sarker, Quazi Sarwar Muhtaseem, Md. Tariqul Islam, Shammur Absar Chowdhury, Firoj Alam</author><pubDate>Mon, 06 Nov 2023 15:37:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03196v1</guid></item><item><title>Few-shot Learning using Data Augmentation and Time-Frequency Transformation for Time Series Classification</title><link>http://arxiv.org/abs/2311.03194v1</link><description>Deep neural networks (DNNs) that tackle the time series classification (TSC)task have provided a promising framework in signal processing. In real-worldapplications, as a data-driven model, DNNs are suffered from insufficient data.Few-shot learning has been studied to deal with this limitation. In this paper,we propose a novel few-shot learning framework through data augmentation, whichinvolves transformation through the time-frequency domain and the generation ofsynthetic images through random erasing. Additionally, we develop asequence-spectrogram neural network (SSNN). This neural network model composesof two sub-networks: one utilizing 1D residual blocks to extract features fromthe input sequence while the other one employing 2D residual blocks to extractfeatures from the spectrogram representation. In the experiments, comparisonstudies of different existing DNN models with/without data augmentation areconducted on an amyotrophic lateral sclerosis (ALS) dataset and a wind turbinefault (WTF) dataset. The experimental results manifest that our proposed methodachieves 93.75% F1 score and 93.33% accuracy on the ALS datasets while 95.48%F1 score and 95.59% accuracy on the WTF datasets. Our methodology demonstratesits applicability of addressing the few-shot problems for time seriesclassification.</description><author>Hao Zhang, Zhendong Pang, Jiangpeng Wang, Teng Li</author><pubDate>Mon, 06 Nov 2023 15:32:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03194v1</guid></item><item><title>DeepInception: Hypnotize Large Language Model to Be Jailbreaker</title><link>http://arxiv.org/abs/2311.03191v1</link><description>Despite remarkable success in various applications, large language models(LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrailsvoid. However, previous studies for jailbreaks usually resort to brute-forceoptimization or extrapolations of a high computation cost, which might not bepractical or effective. In this paper, inspired by the Milgram experiment thatindividuals can harm another person if they are told to do so by anauthoritative figure, we disclose a lightweight method, termed asDeepInception, which can easily hypnotize LLM to be a jailbreaker and unlockits misusing risks. Specifically, DeepInception leverages the personificationability of LLM to construct a novel nested scene to behave, which realizes anadaptive way to escape the usage control in a normal scenario and provides thepossibility for further direct jailbreaks. Empirically, we conductcomprehensive experiments to show its efficacy. Our DeepInception can achievecompetitive jailbreak success rates with previous counterparts and realize acontinuous jailbreak in subsequent interactions, which reveals the criticalweakness of self-losing on both open/closed-source LLMs like Falcon, Vicuna,Llama-2, and GPT-3.5/4/4V. Our investigation appeals that people should paymore attention to the safety aspects of LLMs and a stronger defense againsttheir misuse risks. The code is publicly available at:https://github.com/tmlr-group/DeepInception.</description><author>Xuan Li, Zhanke Zhou, Jianing Zhu, Jiangchao Yao, Tongliang Liu, Bo Han</author><pubDate>Mon, 06 Nov 2023 15:29:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03191v1</guid></item><item><title>Model-based Counterfactual Generator for Gender Bias Mitigation</title><link>http://arxiv.org/abs/2311.03186v1</link><description>Counterfactual Data Augmentation (CDA) has been one of the preferredtechniques for mitigating gender bias in natural language models. CDAtechniques have mostly employed word substitution based on dictionaries.Although such dictionary-based CDA techniques have been shown to significantlyimprove the mitigation of gender bias, in this paper, we highlight somelimitations of such dictionary-based counterfactual data augmentationtechniques, such as susceptibility to ungrammatical compositions, and lack ofgeneralization outside the set of predefined dictionary words. Model-basedsolutions can alleviate these problems, yet the lack of qualitative paralleltraining data hinders development in this direction. Therefore, we propose acombination of data processing techniques and a bi-objective training regime todevelop a model-based solution for generating counterfactuals to mitigategender bias. We implemented our proposed solution and performed an empiricalevaluation which shows how our model alleviates the shortcomings ofdictionary-based solutions.</description><author>Ewoenam Kwaku Tokpo, Toon Calders</author><pubDate>Mon, 06 Nov 2023 15:25:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03186v1</guid></item><item><title>Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for Propaganda and Disinformation Detection</title><link>http://arxiv.org/abs/2311.03184v1</link><description>The spread of disinformation and propagandistic content poses a threat tosocietal harmony, undermining informed decision-making and trust in reliablesources. Online platforms often serve as breeding grounds for such content, andmalicious actors exploit the vulnerabilities of audiences to shape publicopinion. Although there have been research efforts aimed at the automaticidentification of disinformation and propaganda in social media content, thereremain challenges in terms of performance. The ArAIEval shared task aims tofurther research on these particular issues within the context of the Arabiclanguage. In this paper, we discuss our participation in these shared tasks. Wecompeted in subtasks 1A and 2A, where our submitted system secured positions9th and 10th, respectively. Our experiments consist of fine-tuning transformermodels and using zero- and few-shot learning with GPT-4.</description><author>Yunze Xiao, Firoj Alam</author><pubDate>Mon, 06 Nov 2023 15:24:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03184v1</guid></item><item><title>ArAIEval Shared Task: Persuasion Techniques and Disinformation Detection in Arabic Text</title><link>http://arxiv.org/abs/2311.03179v1</link><description>We present an overview of the ArAIEval shared task, organized as part of thefirst ArabicNLP 2023 conference co-located with EMNLP 2023. ArAIEval offers twotasks over Arabic text: (i) persuasion technique detection, focusing onidentifying persuasion techniques in tweets and news articles, and (ii)disinformation detection in binary and multiclass setups over tweets. A totalof 20 teams participated in the final evaluation phase, with 14 and 16 teamsparticipating in Tasks 1 and 2, respectively. Across both tasks, we observedthat fine-tuning transformer models such as AraBERT was at the core of themajority of the participating systems. We provide a description of the tasksetup, including a description of the dataset construction and the evaluationsetup. We further give a brief overview of the participating systems. Alldatasets and evaluation scripts from the shared task are released to theresearch community. (https://araieval.gitlab.io/) We hope this will enablefurther research on these important tasks in Arabic.</description><author>Maram Hasanain, Firoj Alam, Hamdy Mubarak, Samir Abdaljalil, Wajdi Zaghouani, Preslav Nakov, Giovanni Da San Martino, Abed Alhakim Freihat</author><pubDate>Mon, 06 Nov 2023 15:21:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03179v1</guid></item><item><title>1D-Convolutional transformer for Parkinson disease diagnosis from gait</title><link>http://arxiv.org/abs/2311.03177v1</link><description>This paper presents an efficient deep neural network model for diagnosingParkinson's disease from gait. More specifically, we introduce a hybridConvNet-Transformer architecture to accurately diagnose the disease bydetecting the severity stage. The proposed architecture exploits the strengthsof both Convolutional Neural Networks and Transformers in a single end-to-endmodel, where the former is able to extract relevant local features fromVertical Ground Reaction Force (VGRF) signal, while the latter allows tocapture long-term spatio-temporal dependencies in data. In this manner, ourhybrid architecture achieves an improved performance compared to using eithermodels individually. Our experimental results show that our approach iseffective for detecting the different stages of Parkinson's disease from gaitdata, with a final accuracy of 88%, outperforming other state-of-the-art AImethods on the Physionet gait dataset. Moreover, our method can be generalizedand adapted for other classification problems to jointly address the featurerelevance and spatio-temporal dependency problems in 1D signals. Our sourcecode and pre-trained models are publicly available athttps://github.com/SafwenNaimi/1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait.</description><author>Safwen Naimi, Wassim Bouachir, Guillaume-Alexandre Bilodeau</author><pubDate>Mon, 06 Nov 2023 15:17:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03177v1</guid></item><item><title>Enabling Efficient, Reliable Real-World Reinforcement Learning with Approximate Physics-Based Models</title><link>http://arxiv.org/abs/2307.08168v2</link><description>We focus on developing efficient and reliable policy optimization strategiesfor robot learning with real-world data. In recent years, policy gradientmethods have emerged as a promising paradigm for training control policies insimulation. However, these approaches often remain too data inefficient orunreliable to train on real robotic hardware. In this paper we introduce anovel policy gradient-based policy optimization framework which systematicallyleverages a (possibly highly simplified) first-principles model and enableslearning precise control policies with limited amounts of real-world data. Ourapproach $1)$ uses the derivatives of the model to produce sample-efficientestimates of the policy gradient and $2)$ uses the model to design a low-leveltracking controller, which is embedded in the policy class. Theoreticalanalysis provides insight into how the presence of this feedback controllerovercomes key limitations of stand-alone policy gradient methods, whilehardware experiments with a small car and quadruped demonstrate that ourapproach can learn precise control strategies reliably and with only minutes ofreal-world data.</description><author>Tyler Westenbroek, Jacob Levy, David Fridovich-Keil</author><pubDate>Mon, 06 Nov 2023 15:15:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.08168v2</guid></item><item><title>Frequency Domain Decomposition Translation for Enhanced Medical Image Translation Using GANs</title><link>http://arxiv.org/abs/2311.03175v1</link><description>Medical Image-to-image translation is a key task in computer vision andgenerative artificial intelligence, and it is highly applicable to medicalimage analysis. GAN-based methods are the mainstream image translation methods,but they often ignore the variation and distribution of images in the frequencydomain, or only take simple measures to align high-frequency information, whichcan lead to distortion and low quality of the generated images. To solve theseproblems, we propose a novel method called frequency domain decompositiontranslation (FDDT). This method decomposes the original image into ahigh-frequency component and a low-frequency component, with the high-frequencycomponent containing the details and identity information, and thelow-frequency component containing the style information. Next, thehigh-frequency and low-frequency components of the transformed image arealigned with the transformed results of the high-frequency and low-frequencycomponents of the original image in the same frequency band in the spatialdomain, thus preserving the identity information of the image while destroyingas little stylistic information of the image as possible. We conduct extensiveexperiments on MRI images and natural images with FDDT and several mainstreambaseline models, and we use four evaluation metrics to assess the quality ofthe generated images. Compared with the baseline models, optimally, FDDT canreduce Fr\'echet inception distance by up to 24.4%, structural similarity by upto 4.4%, peak signal-to-noise ratio by up to 5.8%, and mean squared error by upto 31%. Compared with the previous method, optimally, FDDT can reduce Fr\'echetinception distance by up to 23.7%, structural similarity by up to 1.8%, peaksignal-to-noise ratio by up to 6.8%, and mean squared error by up to 31.6%.</description><author>Zhuhui Wang, Jianwei Zuo, Xuliang Deng, Jiajia Luo</author><pubDate>Mon, 06 Nov 2023 15:09:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03175v1</guid></item><item><title>BioInstruct: Instruction Tuning of Large Language Models for Biomedical Natural Language Processing</title><link>http://arxiv.org/abs/2310.19975v2</link><description>To enhance the performance of large language models (LLMs) in biomedicalnatural language processing (BioNLP) by introducing a domain-specificinstruction dataset and examining its impact when combined with multi-tasklearning principles. We created the BioInstruct, comprising 25,005 instructionsto instruction-tune LLMs(LLaMA 1 &amp; 2, 7B &amp; 13B version). The instructions werecreated by prompting the GPT-4 language model with three-seed samples randomlydrawn from an 80 human curated instructions. We employed Low-RankAdaptation(LoRA) for parameter-efficient fine-tuning. We then evaluated theseinstruction-tuned LLMs on several BioNLP tasks, which can be grouped into threemajor categories: question answering(QA), information extraction(IE), and textgeneration(GEN). We also examined whether categories(e.g., QA, IE, andgeneration) of instructions impact model performance. Comparing with LLMswithout instruction-tuned, our instruction-tuned LLMs demonstrated markedperformance gains: 17.3% in QA, 5.7% in IE, and 96% in Generation tasks. Our7B-parameter instruction-tuned LLaMA 1 model was competitive or even surpassedother LLMs in the biomedical domain that were also fine-tuned from LLaMA 1 withvast domain-specific data or a variety of tasks. Our results also show that theperformance gain is significantly higher when instruction fine-tuning isconducted with closely related tasks. Our findings align with the observationsof multi-task learning, suggesting the synergies between two tasks. TheBioInstruct dataset serves as a valuable resource and instruction tuned LLMslead to the best performing BioNLP applications.</description><author>Hieu Tran, Zhichao Yang, Zonghai Yao, Hong Yu</author><pubDate>Mon, 06 Nov 2023 15:05:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19975v2</guid></item><item><title>Preserving Privacy in GANs Against Membership Inference Attack</title><link>http://arxiv.org/abs/2311.03172v1</link><description>Generative Adversarial Networks (GANs) have been widely used for generatingsynthetic data for cases where there is a limited size real-world dataset orwhen data holders are unwilling to share their data samples. Recent worksshowed that GANs, due to overfitting and memorization, might leak informationregarding their training data samples. This makes GANs vulnerable to MembershipInference Attacks (MIAs). Several defense strategies have been proposed in theliterature to mitigate this privacy issue. Unfortunately, defense strategiesbased on differential privacy are proven to reduce extensively the quality ofthe synthetic data points. On the other hand, more recent frameworks such asPrivGAN and PAR-GAN are not suitable for small-size training datasets. In thepresent work, the overfitting in GANs is studied in terms of the discriminator,and a more general measure of overfitting based on the Bhattacharyyacoefficient is defined. Then, inspired by Fano's inequality, our first defensemechanism against MIAs is proposed. This framework, which requires only asimple modification in the loss function of GANs, is referred to as the maximumentropy GAN or MEGAN and significantly improves the robustness of GANs to MIAs.As a second defense strategy, a more heuristic model based on minimizing theinformation leaked from generated samples about the training data points ispresented. This approach is referred to as mutual information minimization GAN(MIMGAN) and uses a variational representation of the mutual information tominimize the information that a synthetic sample might leak about the wholetraining data set. Applying the proposed frameworks to some commonly used datasets against state-of-the-art MIAs reveals that the proposed methods can reducethe accuracy of the adversaries to the level of random guessing accuracy with asmall reduction in the quality of the synthetic data samples.</description><author>Mohammadhadi Shateri, Francisco Messina, Fabrice Labeau, Pablo Piantanida</author><pubDate>Mon, 06 Nov 2023 15:04:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03172v1</guid></item></channel></rss>