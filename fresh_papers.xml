<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 07 Nov 2024 01:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>MME-Finance: A Multimodal Finance Benchmark for Expert-level Understanding and Reasoning</title><link>http://arxiv.org/abs/2411.03314v1</link><description>In recent years, multimodal benchmarks for general domains have guided therapid development of multimodal models on general tasks. However, the financialfield has its peculiarities. It features unique graphical images (e.g.,candlestick charts, technical indicator charts) and possesses a wealth ofspecialized financial knowledge (e.g., futures, turnover rate). Therefore,benchmarks from general fields often fail to measure the performance ofmultimodal models in the financial domain, and thus cannot effectively guidethe rapid development of large financial models. To promote the development oflarge financial multimodal models, we propose MME-Finance, an bilingualopen-ended and practical usage-oriented Visual Question Answering (VQA)benchmark. The characteristics of our benchmark are finance and expertise,which include constructing charts that reflect the actual usage needs of users(e.g., computer screenshots and mobile photography), creating questionsaccording to the preferences in financial domain inquiries, and annotatingquestions by experts with 10+ years of experience in the financial industry.Additionally, we have developed a custom-designed financial evaluation systemin which visual information is first introduced in the multi-modal evaluationprocess. Extensive experimental evaluations of 19 mainstream MLLMs areconducted to test their perception, reasoning, and cognition capabilities. Theresults indicate that models performing well on general benchmarks cannot dowell on MME-Finance; for instance, the top-performing open-source andclosed-source models obtain 65.69 (Qwen2VL-72B) and 63.18 (GPT-4o),respectively. Their performance is particularly poor in categories mostrelevant to finance, such as candlestick charts and technical indicator charts.In addition, we propose a Chinese version, which helps compare performance ofMLLMs under a Chinese context.</description><author>Ziliang Gan, Yu Lu, Dong Zhang, Haohan Li, Che Liu, Jian Liu, Ji Liu, Haipang Wu, Chaoyou Fu, Zenglin Xu, Rongjunchen Zhang, Yong Dai</author><pubDate>Tue, 05 Nov 2024 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03314v1</guid></item><item><title>Classification Done Right for Vision-Language Pre-Training</title><link>http://arxiv.org/abs/2411.03313v1</link><description>We introduce SuperClass, a super simple classification method forvision-language pre-training on image-text data. Unlike its contrastivecounterpart CLIP who contrast with a text encoder, SuperClass directly utilizestokenized raw text as supervised classification labels, without the need foradditional text filtering or selection. Due to the absence of the text encodingas contrastive target, SuperClass does not require a text encoder and does notneed to maintain a large batch size as CLIP does. SuperClass demonstratedsuperior performance on various downstream tasks, including classic computervision benchmarks and vision language downstream tasks. We further explored thescaling behavior of SuperClass on model size, training length, or data size,and reported encouraging results and comparisons to CLIP.https://github.com/x-cls/superclass</description><author>Huang Zilong, Ye Qinghao, Kang Bingyi, Feng Jiashi, Fan Haoqi</author><pubDate>Tue, 05 Nov 2024 18:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03313v1</guid></item><item><title>Inference Optimal VLMs Need Only One Visual Token but Larger Models</title><link>http://arxiv.org/abs/2411.03312v1</link><description>Vision Language Models (VLMs) have demonstrated strong capabilities acrossvarious visual understanding and reasoning tasks. However, their real-worlddeployment is often constrained by high latency during inference due tosubstantial compute required to process the large number of input tokens(predominantly from the image) by the LLM. To reduce inference costs, one caneither downsize the LLM or reduce the number of input image-tokens, the latterof which has been the focus of many recent works around token compression.However, it is unclear what the optimal trade-off is, as both the factorsdirectly affect the VLM performance. We first characterize this optimaltrade-off between the number of visual tokens and LLM parameters byestablishing scaling laws that capture variations in performance with these twofactors. Our results reveal a surprising trend: for visual reasoning tasks, theinference-optimal behavior in VLMs, i.e., minimum downstream error at any givenfixed inference compute, is achieved when using the largest LLM that fitswithin the inference budget while minimizing visual token count - often to asingle token. While the token reduction literature has mainly focused onmaintaining base model performance by modestly reducing the token count (e.g.,$5-10\times$), our results indicate that the compute-optimal inference regimerequires operating under even higher token compression ratios. Based on theseinsights, we take some initial steps towards building approaches tailored forhigh token compression settings. Code is available athttps://github.com/locuslab/llava-token-compression.</description><author>Kevin Y. Li, Sachin Goyal, Joao D. Semedo, J. Zico Kolter</author><pubDate>Tue, 05 Nov 2024 18:54:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03312v1</guid></item><item><title>DAAL: Density-Aware Adaptive Line Margin Loss for Multi-Modal Deep Metric Learning</title><link>http://arxiv.org/abs/2410.05438v2</link><description>Multi-modal deep metric learning is crucial for effectively capturing diverserepresentations in tasks such as face verification, fine-grained objectrecognition, and product search. Traditional approaches to metric learning,whether based on distance or margin metrics, primarily emphasize classseparation, often overlooking the intra-class distribution essential formulti-modal feature learning. In this context, we propose a novel loss functioncalled Density-Aware Adaptive Margin Loss(DAAL), which preserves the densitydistribution of embeddings while encouraging the formation of adaptivesub-clusters within each class. By employing an adaptive line strategy, DAALnot only enhances intra-class variance but also ensures robust inter-classseparation, facilitating effective multi-modal representation. Comprehensiveexperiments on benchmark fine-grained datasets demonstrate the superiorperformance of DAAL, underscoring its potential in advancing retrievalapplications and multi-modal deep metric learning.</description><author>Hadush Hailu Gebrerufael, Anil Kumar Tiwari, Gaurav Neupane, Goitom Ybrah Hailu</author><pubDate>Tue, 05 Nov 2024 18:44:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05438v2</guid></item><item><title>Statistical Properties of Deep Neural Networks with Dependent Data</title><link>http://arxiv.org/abs/2410.11113v2</link><description>This paper establishes statistical properties of deep neural network (DNN)estimators under dependent data. Two general results for nonparametric sieveestimators directly applicable to DNN estimators are given. The firstestablishes rates for convergence in probability under nonstationary data. Thesecond provides non-asymptotic probability bounds on $\mathcal{L}^{2}$-errorsunder stationary $\beta$-mixing data. I apply these results to DNN estimatorsin both regression and classification contexts imposing only a standardH\"older smoothness assumption. The DNN architectures considered are common inapplications, featuring fully connected feedforward networks with anycontinuous piecewise linear activation function, unbounded weights, and a widthand depth that grows with sample size. The framework provided also offerspotential for research into other DNN architectures and time-seriesapplications.</description><author>Chad Brown</author><pubDate>Tue, 05 Nov 2024 18:26:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.11113v2</guid></item><item><title>LLMs for Domain Generation Algorithm Detection</title><link>http://arxiv.org/abs/2411.03307v1</link><description>This work analyzes the use of large language models (LLMs) for detectingdomain generation algorithms (DGAs). We perform a detailed evaluation of twoimportant techniques: In-Context Learning (ICL) and Supervised Fine-Tuning(SFT), showing how they can improve detection. SFT increases performance byusing domain-specific data, whereas ICL helps the detection model to quicklyadapt to new threats without requiring much retraining. We use Meta's Llama3 8Bmodel, on a custom dataset with 68 malware families and normal domains,covering several hard-to-detect schemes, including recent word-based DGAs.Results proved that LLM-based methods can achieve competitive results in DGAdetection. In particular, the SFT-based LLM DGA detector outperformsstate-of-the-art models using attention layers, achieving 94% accuracy with a4% false positive rate (FPR) and excelling at detecting word-based DGA domains.</description><author>Reynier Leyva La O, Carlos A. Catania, Tatiana Parlanti</author><pubDate>Tue, 05 Nov 2024 18:01:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03307v1</guid></item><item><title>VERITAS: A Unified Approach to Reliability Evaluation</title><link>http://arxiv.org/abs/2411.03300v1</link><description>Large language models (LLMs) often fail to synthesize information from theircontext to generate an accurate response. This renders them unreliable inknowledge intensive settings where reliability of the output is key. A criticalcomponent for reliable LLMs is the integration of a robust fact-checking systemthat can detect hallucinations across various formats. While severalopen-access fact-checking models are available, their functionality is oftenlimited to specific tasks, such as grounded question-answering or entailmentverification, and they perform less effectively in conversational settings. Onthe other hand, closed-access models like GPT-4 and Claude offer greaterflexibility across different contexts, including grounded dialogueverification, but are hindered by high costs and latency. In this work, weintroduce VERITAS, a family of hallucination detection models designed tooperate flexibly across diverse contexts while minimizing latency and costs.VERITAS achieves state-of-the-art results considering average performance onall major hallucination detection benchmarks, with $10\%$ increase in averageperformance when compared to similar-sized models and get close to theperformance of GPT4 turbo with LLM-as-a-judge setting.</description><author>Rajkumar Ramamurthy, Meghana Arakkal Rajeev, Oliver Molenschot, James Zou, Nazneen Rajani</author><pubDate>Tue, 05 Nov 2024 17:53:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03300v1</guid></item><item><title>Cognitive Planning for Object Goal Navigation using Generative AI Models</title><link>http://arxiv.org/abs/2404.00318v2</link><description>Recent advancements in Generative AI, particularly in Large Language Models(LLMs) and Large Vision-Language Models (LVLMs), offer new possibilities forintegrating cognitive planning into robotic systems. In this work, we present anovel framework for solving the object goal navigation problem that generatesefficient exploration strategies. Our approach enables a robot to navigateunfamiliar environments by leveraging LLMs and LVLMs to understand the semanticstructure of the scene. To address the challenge of representing complexenvironments without overwhelming the system, we propose a 3D modular scenerepresentation, enriched with semantic descriptions. This representation isdynamically pruned using an LLM-based mechanism, which filters irrelevantinformation and focuses on task-specific data. By combining these elements, oursystem generates high-level sub-goals that guide the exploration of the robottoward the target object. We validate our approach in simulated environments,demonstrating its ability to enhance object search efficiency while maintainingscalability in complex settings.</description><author>Arjun P S, Andrew Melnik, Gora Chand Nandi</author><pubDate>Tue, 05 Nov 2024 17:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00318v2</guid></item><item><title>Out-of-Distribution Recovery with Object-Centric Keypoint Inverse Policy For Visuomotor Imitation Learning</title><link>http://arxiv.org/abs/2411.03294v1</link><description>We propose an object-centric recovery policy framework to address thechallenges of out-of-distribution (OOD) scenarios in visuomotor policylearning. Previous behavior cloning (BC) methods rely heavily on a large amountof labeled data coverage, failing in unfamiliar spatial states. Without relyingon extra data collection, our approach learns a recovery policy constructed byan inverse policy inferred from object keypoint manifold gradient in theoriginal training data. The recovery policy serves as a simple add-on to anybase visuomotor BC policy, agnostic to a specific method, guiding the systemback towards the training distribution to ensure task success even in OODsituations. We demonstrate the effectiveness of our object-centric framework inboth simulation and real robot experiments, achieving an improvement of$\textbf{77.7\%}$ over the base policy in OOD. Project Website:https://sites.google.com/view/ocr-penn</description><author>George Jiayuan Gao, Tianyu Li, Nadia Figueroa</author><pubDate>Tue, 05 Nov 2024 17:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03294v1</guid></item><item><title>Introducing Perturb-ability Score (PS) to Enhance Robustness Against Evasion Adversarial Attacks on ML-NIDS</title><link>http://arxiv.org/abs/2409.07448v2</link><description>As network security threats continue to evolve, safeguarding Machine Learning(ML)-based Network Intrusion Detection Systems (NIDS) from adversarial attacksis crucial. This paper introduces the notion of feature perturb-ability andpresents a novel Perturb-ability Score (PS) metric that identifies NIDSfeatures susceptible to manipulation in the problem-space by an attacker. Byquantifying a feature's susceptibility to perturbations within theproblem-space, the PS facilitates the selection of features that are inherentlymore robust against evasion adversarial attacks on ML-NIDS during the featureselection phase. These features exhibit natural resilience to perturbations, asthey are heavily constrained by the problem-space limitations and correlationsof the NIDS domain. Furthermore, manipulating these features may either disruptthe malicious function of evasion adversarial attacks on NIDS or render thenetwork traffic invalid for processing (or both). This proposed novel approachemploys a fresh angle by leveraging network domain constraints as a defensemechanism against problem-space evasion adversarial attacks targeting ML-NIDS.We demonstrate the effectiveness of our PS-guided feature selection defense inenhancing NIDS robustness. Experimental results across various ML-based NIDSmodels and public datasets show that selecting only robust features (low-PSfeatures) can maintain solid detection performance while significantly reducingvulnerability to evasion adversarial attacks. Additionally, our findings verifythat the PS effectively identifies NIDS features highly vulnerable toproblem-space perturbations.</description><author>Mohamed elShehaby, Ashraf Matrawy</author><pubDate>Tue, 05 Nov 2024 17:40:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.07448v2</guid></item><item><title>Interaction2Code: How Far Are We From Automatic Interactive Webpage Generation?</title><link>http://arxiv.org/abs/2411.03292v1</link><description>Converting webpage design into functional UI code is a critical step forbuilding websites, which can be labor-intensive and time-consuming. To automatethis design-to-code transformation process, various automated methods usinglearning-based networks and multi-modal large language models (MLLMs) have beenproposed. However, these studies were merely evaluated on a narrow range ofstatic web pages and ignored dynamic interaction elements, making them lesspractical for real-world website deployment. To fill in the blank, we present the first systematic investigation of MLLMsin generating interactive webpages. Specifically, we first formulate theInteraction-to-Code task and build the Interaction2Code benchmark that contains97 unique web pages and 213 distinct interactions, spanning 15 webpage typesand 30 interaction categories. We then conduct comprehensive experiments onthree state-of-the-art (SOTA) MLLMs using both automatic metrics and humanevaluations, thereby summarizing six findings accordingly. Our experimentalresults highlight the limitations of MLLMs in generating fine-grainedinteractive features and managing interactions with complex transformations andsubtle visual modifications. We further analyze failure cases and theirunderlying causes, identifying 10 common failure types and assessing theirseverity. Additionally, our findings reveal three critical influencing factors,i.e., prompts, visual saliency, and textual descriptions, that can enhance theinteraction generation performance of MLLMs. Based on these findings, we elicitimplications for researchers and developers, providing a foundation for futureadvancements in this field. Datasets and source code are available athttps://github.com/WebPAI/Interaction2Code.</description><author>Jingyu Xiao, Yuxuan Wan, Yintong Huo, Zhiyao Xu, Michael R. Lyu</author><pubDate>Tue, 05 Nov 2024 17:40:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03292v1</guid></item><item><title>The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare</title><link>http://arxiv.org/abs/2411.03287v1</link><description>The potential use of large language models (LLMs) in healthcare robotics canhelp address the significant demand put on healthcare systems around the worldwith respect to an aging demographic and a shortage of healthcareprofessionals. Even though LLMs have already been integrated into medicine toassist both clinicians and patients, the integration of LLMs within healthcarerobots has not yet been explored for clinical settings. In this perspectivepaper, we investigate the groundbreaking developments in robotics and LLMs touniquely identify the needed system requirements for designing health specificLLM based robots in terms of multi modal communication through human robotinteractions (HRIs), semantic reasoning, and task planning. Furthermore, wediscuss the ethical issues, open challenges, and potential future researchdirections for this emerging innovative field.</description><author>Souren Pashangpour, Goldie Nejat</author><pubDate>Tue, 05 Nov 2024 17:36:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03287v1</guid></item><item><title>DiT4Edit: Diffusion Transformer for Image Editing</title><link>http://arxiv.org/abs/2411.03286v1</link><description>Despite recent advances in UNet-based image editing, methods for shape-awareobject editing in high-resolution images are still lacking. Compared to UNet,Diffusion Transformers (DiT) demonstrate superior capabilities to effectivelycapture the long-range dependencies among patches, leading to higher-qualityimage generation. In this paper, we propose DiT4Edit, the first DiffusionTransformer-based image editing framework. Specifically, DiT4Edit uses theDPM-Solver inversion algorithm to obtain the inverted latents, reducing thenumber of steps compared to the DDIM inversion algorithm commonly used inUNet-based frameworks. Additionally, we design unified attention control andpatches merging, tailored for transformer computation streams. This integrationallows our framework to generate higher-quality edited images faster. Ourdesign leverages the advantages of DiT, enabling it to surpass UNet structuresin image editing, especially in high-resolution and arbitrary-size images.Extensive experiments demonstrate the strong performance of DiT4Edit acrossvarious editing scenarios, highlighting the potential of Diffusion Transformersin supporting image editing.</description><author>Kunyu Feng, Yue Ma, Bingyuan Wang, Chenyang Qi, Haozhe Chen, Qifeng Chen, Zeyu Wang</author><pubDate>Tue, 05 Nov 2024 17:35:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03286v1</guid></item><item><title>SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents</title><link>http://arxiv.org/abs/2411.03284v1</link><description>While multi-agent systems have been shown to significantly enhance theperformance of Large Language Models (LLMs) across various tasks andapplications, the dense interaction between scaling agents potentially hamperstheir efficiency and diversity. To address these challenges, we drawinspiration from the sparse mixture-of-agents (SMoE) and propose a sparsemixture-of-agents (SMoA) framework to improve the efficiency and diversity ofmulti-agent LLMs. Unlike completely connected structures, SMoA introduces novelResponse Selection and Early Stopping mechanisms to sparsify information flowsamong individual LLM agents, striking a balance between performance andefficiency. Additionally, inspired by the expert diversity principle in SMoEframeworks for workload balance between experts, we assign distinct roledescriptions to each LLM agent, fostering diverse and divergent thinking.Extensive experiments on reasoning, alignment, and fairness benchmarksdemonstrate that SMoA achieves performance comparable to traditionalmixture-of-agents approaches but with significantly lower computational costs.Further analysis reveals that SMoA is more stable, has a greater capacity toscale, and offers considerable potential through hyper-parameter optimization.Code and data will be available at: https://github.com/David-Li0406/SMoA.</description><author>Dawei Li, Zhen Tan, Peijia Qian, Yifan Li, Kumar Satvik Chaudhary, Lijie Hu, Jiayi Shen</author><pubDate>Tue, 05 Nov 2024 17:33:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03284v1</guid></item><item><title>Towards efficient and secure quantum-classical communication networks</title><link>http://arxiv.org/abs/2411.01081v2</link><description>The rapid advancement of quantum technologies calls for the design anddeployment of quantum-safe cryptographic protocols and communication networks.There are two primary approaches to achieving quantum-resistant security:quantum key distribution (QKD) and post-quantum cryptography (PQC). While eachoffers unique advantages, both have drawbacks in practical implementation. Inthis work, we introduce the pros and cons of these protocols and explore howthey can be combined to achieve a higher level of security and/or improvedperformance in key distribution. We hope our discussion inspires furtherresearch into the design of hybrid cryptographic protocols forquantum-classical communication networks.</description><author>Pei Zeng, Debayan Bandyopadhyay, José A. Méndez Méndez, Nolan Bitner, Alexander Kolar, Michael T. Solomon, F. Joseph Heremans, David D. Awschalom, Liang Jiang, Junyu Liu</author><pubDate>Tue, 05 Nov 2024 17:23:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.01081v2</guid></item><item><title>HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Scale</title><link>http://arxiv.org/abs/2409.16299v2</link><description>Large Language Models (LLMs) have revolutionized software engineering (SE),showcasing remarkable proficiency in various coding tasks. Despite recentadvancements that have enabled the creation of autonomous software agentsutilizing LLMs for end-to-end development tasks, these systems are typicallydesigned for specific SE functions. We introduce HyperAgent, an innovativegeneralist multi-agent system designed to tackle a wide range of SE tasksacross different programming languages by mimicking the workflows of humandevelopers. HyperAgent features four specialized agents-Planner, Navigator,Code Editor, and Executor-capable of handling the entire lifecycle of SE tasks,from initial planning to final verification. HyperAgent sets new benchmarks indiverse SE tasks, including GitHub issue resolution on the renowned SWE-Benchbenchmark, outperforming robust baselines. Furthermore, HyperAgent demonstratesexceptional performance in repository-level code generation (RepoExec) andfault localization and program repair (Defects4J), often surpassingstate-of-the-art baselines.</description><author>Huy Nhat Phan, Tien N. Nguyen, Phong X. Nguyen, Nghi D. Q. Bui</author><pubDate>Tue, 05 Nov 2024 17:22:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.16299v2</guid></item><item><title>Oblivious Defense in ML Models: Backdoor Removal without Detection</title><link>http://arxiv.org/abs/2411.03279v1</link><description>As society grows more reliant on machine learning, ensuring the security ofmachine learning systems against sophisticated attacks becomes a pressingconcern. A recent result of Goldwasser, Kim, Vaikuntanathan, and Zamir (2022)shows that an adversary can plant undetectable backdoors in machine learningmodels, allowing the adversary to covertly control the model's behavior.Backdoors can be planted in such a way that the backdoored machine learningmodel is computationally indistinguishable from an honest model withoutbackdoors. In this paper, we present strategies for defending against backdoors in MLmodels, even if they are undetectable. The key observation is that it issometimes possible to provably mitigate or even remove backdoors withoutneeding to detect them, using techniques inspired by the notion of randomself-reducibility. This depends on properties of the ground-truth labels(chosen by nature), and not of the proposed ML model (which may be chosen by anattacker). We give formal definitions for secure backdoor mitigation, and proceed toshow two types of results. First, we show a "global mitigation" technique,which removes all backdoors from a machine learning model under the assumptionthat the ground-truth labels are close to a Fourier-heavy function. Second, weconsider distributions where the ground-truth labels are close to a linear orpolynomial function in $\mathbb{R}^n$. Here, we show "local mitigation"techniques, which remove backdoors with high probability for every inputs ofinterest, and are computationally cheaper than global mitigation. All of ourconstructions are black-box, so our techniques work without needing access tothe model's representation (i.e., its code or parameters). Along the way weprove a simple result for robust mean estimation.</description><author>Shafi Goldwasser, Jonathan Shafer, Neekon Vafa, Vinod Vaikuntanathan</author><pubDate>Tue, 05 Nov 2024 17:20:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03279v1</guid></item><item><title>Causal Responsibility Attribution for Human-AI Collaboration</title><link>http://arxiv.org/abs/2411.03275v1</link><description>As Artificial Intelligence (AI) systems increasingly influencedecision-making across various fields, the need to attribute responsibility forundesirable outcomes has become essential, though complicated by the complexinterplay between humans and AI. Existing attribution methods based on actualcausality and Shapley values tend to disproportionately blame agents whocontribute more to an outcome and rely on real-world measures ofblameworthiness that may misalign with responsible AI standards. This paperpresents a causal framework using Structural Causal Models (SCMs) tosystematically attribute responsibility in human-AI systems, measuring overallblameworthiness while employing counterfactual reasoning to account for agents'expected epistemic levels. Two case studies illustrate the framework'sadaptability in diverse human-AI collaboration scenarios.</description><author>Yahang Qi, Bernhard Schölkopf, Zhijing Jin</author><pubDate>Tue, 05 Nov 2024 17:17:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03275v1</guid></item><item><title>Graph-Based Semi-Supervised Segregated Lipschitz Learning</title><link>http://arxiv.org/abs/2411.03273v1</link><description>This paper presents an approach to semi-supervised learning for theclassification of data using the Lipschitz Learning on graphs. We develop agraph-based semi-supervised learning framework that leverages the properties ofthe infinity Laplacian to propagate labels in a dataset where only a fewsamples are labeled. By extending the theory of spatial segregation from theLaplace operator to the infinity Laplace operator, both in continuum anddiscrete settings, our approach provides a robust method for dealing with classimbalance, a common challenge in machine learning. Experimental validation onseveral benchmark datasets demonstrates that our method not only improvesclassification accuracy compared to existing methods but also ensures efficientlabel propagation in scenarios with limited labeled data.</description><author>Farid Bozorgnia, Yassine Belkheiri, Abderrahim Elmoataz</author><pubDate>Tue, 05 Nov 2024 17:16:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03273v1</guid></item><item><title>Stable Matching with Ties: Approximation Ratios and Learning</title><link>http://arxiv.org/abs/2411.03270v1</link><description>We study the problem of matching markets with ties, where one side of themarket does not necessarily have strict preferences over members at its otherside. For example, workers do not always have strict preferences over jobs,students can give the same ranking for different schools and more. Inparticular, assume w.l.o.g. that workers' preferences are determined by theirutility from being matched to each job, which might admit ties. Notably, incontrast to classical two-sided markets with strict preferences, there is nolonger a single stable matching that simultaneously maximizes the utility forall workers. We aim to guarantee each worker the largest possible share from the utilityin her best possible stable matching. We call the ratio between the worker'sbest possible stable utility and its assigned utility the \emph{Optimal StableShare} (OSS)-ratio. We first prove that distributions over stable matchingscannot guarantee an OSS-ratio that is sublinear in the number of workers.Instead, randomizing over possibly non-stable matchings, we show how to achievea tight logarithmic OSS-ratio. Then, we analyze the case where the real utilityis not necessarily known and can only be approximated. In particular, weprovide an algorithm that guarantees a similar fraction of the utility comparedto the best possible utility. Finally, we move to a bandit setting, where weselect a matching at each round and only observe the utilities for matches weperform. We show how to utilize our results for approximate utilities togracefully interpolate between problems without ties and problems withstatistical ties (small suboptimality gaps).</description><author>Shiyun Lin, Simon Mauras, Nadav Merlis, Vianney Perchet</author><pubDate>Tue, 05 Nov 2024 17:14:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03270v1</guid></item><item><title>Practical hybrid PQC-QKD protocols with enhanced security and performance</title><link>http://arxiv.org/abs/2411.01086v2</link><description>Quantum resistance is vital for emerging cryptographic systems as quantumtechnologies continue to advance towards large-scale, fault-tolerant quantumcomputers. Resistance may be offered by quantum key distribution (QKD), whichprovides information-theoretic security using quantum states of photons, butmay be limited by transmission loss at long distances. An alternative approachuses classical means and is conjectured to be resistant to quantum attacks,so-called post-quantum cryptography (PQC), but it is yet to be rigorouslyproven, and its current implementations are computationally expensive. Toovercome the security and performance challenges present in each, here wedevelop hybrid protocols by which QKD and PQC inter-operate within a jointquantum-classical network. In particular, we consider different hybrid designsthat may offer enhanced speed and/or security over the individual performanceof either approach. Furthermore, we present a method for analyzing the securityof hybrid protocols in key distribution networks. Our hybrid approach paves theway for joint quantum-classical communication networks, which leverage theadvantages of both QKD and PQC and can be tailored to the requirements ofvarious practical networks.</description><author>Pei Zeng, Debayan Bandyopadhyay, José A. Méndez Méndez, Nolan Bitner, Alexander Kolar, Michael T. Solomon, Ziyu Ye, Filip Rozpȩdek, Tian Zhong, F. Joseph Heremans, David D. Awschalom, Liang Jiang, Junyu Liu</author><pubDate>Tue, 05 Nov 2024 17:13:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.01086v2</guid></item><item><title>Digi2Real: Bridging the Realism Gap in Synthetic Data Face Recognition via Foundation Models</title><link>http://arxiv.org/abs/2411.02188v2</link><description>The accuracy of face recognition systems has improved significantly in thepast few years, thanks to the large amount of data collected and theadvancement in neural network architectures. However, these large-scaledatasets are often collected without explicit consent, raising ethical andprivacy concerns. To address this, there have been proposals to use syntheticdatasets for training face recognition models. Yet, such models still rely onreal data to train the generative models and generally exhibit inferiorperformance compared to those trained on real datasets. One of these datasets,DigiFace, uses a graphics pipeline to generate different identities anddifferent intra-class variations without using real data in training themodels. However, the performance of this approach is poor on face recognitionbenchmarks, possibly due to the lack of realism in the images generated fromthe graphics pipeline. In this work, we introduce a novel framework for realismtransfer aimed at enhancing the realism of synthetically generated face images.Our method leverages the large-scale face foundation model, and we adapt thepipeline for realism enhancement. By integrating the controllable aspects ofthe graphics pipeline with our realism enhancement technique, we generate alarge amount of realistic variations-combining the advantages of bothapproaches. Our empirical evaluations demonstrate that models trained using ourenhanced dataset significantly improve the performance of face recognitionsystems over the baseline. The source code and datasets will be made availablepublicly.</description><author>Anjith George, Sebastien Marcel</author><pubDate>Tue, 05 Nov 2024 17:09:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.02188v2</guid></item><item><title>Proxy-informed Bayesian transfer learning with unknown sources</title><link>http://arxiv.org/abs/2411.03263v1</link><description>Generalization outside the scope of one's training data requires leveragingprior knowledge about the effects that transfer, and the effects that don't,between different data sources. Bayesian transfer learning is a principledparadigm for specifying this knowledge, and refining it on the basis of datafrom the source (training) and target (prediction) tasks. We address thechallenging transfer learning setting where the learner (i) cannot fine-tune inthe target task, and (ii) does not know which source data points correspond tothe same task (i.e., the data sources are unknown). We propose a proxy-informedrobust method for probabilistic transfer learning (PROMPT), which provides aposterior predictive estimate tailored to the structure of the target task,without requiring the learner have access to any outcome information from thetarget task. Instead, PROMPT relies on the availability of proxy information.PROMPT uses the same proxy information for two purposes: (i) estimation ofeffects specific to the target task, and (ii) construction of a robustreweighting of the source data for estimation of effects that transfer betweentasks. We provide theoretical results on the effect of this reweighting on therisk of negative transfer, and demonstrate application of PROMPT in twosynthetic settings.</description><author>Sabina J. Sloman, Julien Martinelli, Samuel Kaski</author><pubDate>Tue, 05 Nov 2024 17:02:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03263v1</guid></item><item><title>Arrhythmia Classification Using Graph Neural Networks Based on Correlation Matrix</title><link>http://arxiv.org/abs/2410.10758v2</link><description>With the advancements in graph neural network, there has been increasinginterest in applying this network to ECG signal analysis. In this study, wegenerated an adjacency matrix using correlation matrix of extracted featuresand applied a graph neural network to classify arrhythmias. The proposed modelwas compared with existing approaches from the literature. The resultsdemonstrated that precision and recall for all arrhythmia classes exceeded 50%,suggesting that this method can be considered an approach for arrhythmiaclassification.</description><author>Seungwoo Han</author><pubDate>Tue, 05 Nov 2024 17:00:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.10758v2</guid></item><item><title>ShadowMamba: State-Space Model with Boundary-Region Selective Scan for Shadow Removal</title><link>http://arxiv.org/abs/2411.03260v1</link><description>Image shadow removal is a typical low-level vision problem, where thepresence of shadows leads to abrupt changes in brightness in certain regions,affecting the accuracy of upstream tasks. Current shadow removal methods stillface challenges such as residual boundary artifacts, and capturing featureinformation at shadow boundaries is crucial for removing shadows andeliminating residual boundary artifacts. Recently, Mamba has achievedremarkable success in computer vision by globally modeling long-sequenceinformation with linear complexity. However, when applied to image shadowremoval, the original Mamba scanning method overlooks the semantic continuityof shadow boundaries as well as the continuity of semantics within the sameregion. Based on the unique characteristics of shadow images, this paperproposes a novel selective scanning method called boundary-region selectivescanning. This method scans boundary regions, shadow regions, and non-shadowregions independently, bringing pixels of the same region type closer togetherin the long sequence, especially focusing on the local information at theboundaries, which is crucial for shadow removal. This method combines withglobal scanning and channel scanning to jointly accomplish the shadow removal.We name our model ShadowMamba, the first Mamba-based model for shadow removal.Extensive experimental results show that our method outperforms currentstate-of-the-art models across most metrics on multiple datasets. The code forShadowMamba is available at (Code will be released upon acceptance).</description><author>Xiujin Zhu, Chee-Onn Chow, Joon Huang Chuah</author><pubDate>Tue, 05 Nov 2024 16:59:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03260v1</guid></item><item><title>Confidential Computing on NVIDIA Hopper GPUs: A Performance Benchmark Study</title><link>http://arxiv.org/abs/2409.03992v4</link><description>This report evaluates the performance impact of enabling Trusted ExecutionEnvironments (TEE) on NVIDIA Hopper GPUs for large language model (LLM)inference tasks. We benchmark the overhead introduced by TEE mode acrossvarious LLMs and token lengths, with a particular focus on the bottleneckcaused by CPU-GPU data transfers via PCIe. Our results indicate that whilethere is minimal computational overhead within the GPU, the overall performancepenalty is primarily attributable to data transfer. For the majority of typicalLLM queries, the overhead remains below 7%, with larger models and longersequences experiencing nearly zero overhead.</description><author>Jianwei Zhu, Hang Yin, Peng Deng, Aline Almeida, Shunfan Zhou</author><pubDate>Tue, 05 Nov 2024 16:57:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.03992v4</guid></item><item><title>Evaluation of Active Feature Acquisition Methods for Time-varying Feature Settings</title><link>http://arxiv.org/abs/2312.01530v3</link><description>Machine learning methods often assume that input features are available at nocost. However, in domains like healthcare, where acquiring features could beexpensive or harmful, it is necessary to balance a feature's acquisition costagainst its predictive value. The task of training an AI agent to decide whichfeatures to acquire is called active feature acquisition (AFA). By deploying anAFA agent, we effectively alter the acquisition strategy and trigger adistribution shift. To safely deploy AFA agents under this distribution shift,we present the problem of active feature acquisition performance evaluation(AFAPE). We examine AFAPE under i) a no direct effect (NDE) assumption, statingthat acquisitions do not affect the underlying feature values; and ii) a nounobserved confounding (NUC) assumption, stating that retrospective featureacquisition decisions were only based on observed features. We show that onecan apply missing data methods under the NDE assumption and offlinereinforcement learning under the NUC assumption. When NUC and NDE hold, wepropose a novel semi-offline reinforcement learning framework. This frameworkrequires a weaker positivity assumption and introduces three new estimators: Adirect method (DM), an inverse probability weighting (IPW), and a doublereinforcement learning (DRL) estimator.</description><author>Henrik von Kleist, Alireza Zamanian, Ilya Shpitser, Narges Ahmidi</author><pubDate>Tue, 05 Nov 2024 16:55:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01530v3</guid></item><item><title>Decoupled Pseudo-labeling for Semi-Supervised Monocular 3D Object Detection</title><link>http://arxiv.org/abs/2403.17387v3</link><description>We delve into pseudo-labeling for semi-supervised monocular 3D objectdetection (SSM3OD) and discover two primary issues: a misalignment between theprediction quality of 3D and 2D attributes and the tendency of depthsupervision derived from pseudo-labels to be noisy, leading to significantoptimization conflicts with other reliable forms of supervision. We introduce anovel decoupled pseudo-labeling (DPL) approach for SSM3OD. Our approachfeatures a Decoupled Pseudo-label Generation (DPG) module, designed toefficiently generate pseudo-labels by separately processing 2D and 3Dattributes. This module incorporates a unique homography-based method foridentifying dependable pseudo-labels in BEV space, specifically for 3Dattributes. Additionally, we present a DepthGradient Projection (DGP) module tomitigate optimization conflicts caused by noisy depth supervision ofpseudo-labels, effectively decoupling the depth gradient and removingconflicting gradients. This dual decoupling strategy-at both the pseudo-labelgeneration and gradient levels-significantly improves the utilization ofpseudo-labels in SSM3OD. Our comprehensive experiments on the KITTI benchmarkdemonstrate the superiority of our method over existing approaches.</description><author>Jiacheng Zhang, Jiaming Li, Xiangru Lin, Wei Zhang, Xiao Tan, Junyu Han, Errui Ding, Jingdong Wang, Guanbin Li</author><pubDate>Tue, 05 Nov 2024 16:52:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.17387v3</guid></item><item><title>GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models</title><link>http://arxiv.org/abs/2406.14550v2</link><description>Long-context capabilities are essential for large language models (LLMs) totackle complex and long-input tasks. Despite numerous efforts made to optimizeLLMs for long contexts, challenges persist in robustly processing long inputs.In this paper, we introduce GraphReader, a graph-based agent system designed tohandle long texts by structuring them into a graph and employing an agent toexplore this graph autonomously. Upon receiving a question, the agent firstundertakes a step-by-step analysis and devises a rational plan. It then invokesa set of predefined functions to read node content and neighbors, facilitatinga coarse-to-fine exploration of the graph. Throughout the exploration, theagent continuously records new insights and reflects on current circumstancesto optimize the process until it has gathered sufficient information togenerate an answer. Experimental results on the LV-Eval dataset reveal thatGraphReader, using a 4k context window, consistently outperforms GPT-4-128kacross context lengths from 16k to 256k by a large margin. Additionally, ourapproach demonstrates superior performance on four challenging single-hop andmulti-hop benchmarks.</description><author>Shilong Li, Yancheng He, Hangyu Guo, Xingyuan Bu, Ge Bai, Jie Liu, Jiaheng Liu, Xingwei Qu, Yangguang Li, Wanli Ouyang, Wenbo Su, Bo Zheng</author><pubDate>Tue, 05 Nov 2024 16:51:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14550v2</guid></item><item><title>Discovering Data Structures: Nearest Neighbor Search and Beyond</title><link>http://arxiv.org/abs/2411.03253v1</link><description>We propose a general framework for end-to-end learning of data structures.Our framework adapts to the underlying data distribution and providesfine-grained control over query and space complexity. Crucially, the datastructure is learned from scratch, and does not require careful initializationor seeding with candidate data structures/algorithms. We first apply thisframework to the problem of nearest neighbor search. In several settings, weare able to reverse-engineer the learned data structures and query algorithms.For 1D nearest neighbor search, the model discovers optimal distribution(in)dependent algorithms such as binary search and variants of interpolationsearch. In higher dimensions, the model learns solutions that resemble k-dtrees in some regimes, while in others, they have elements oflocality-sensitive hashing. The model can also learn useful representations ofhigh-dimensional data and exploit them to design effective data structures. Wealso adapt our framework to the problem of estimating frequencies over a datastream, and believe it could also be a powerful discovery tool for newproblems.</description><author>Omar Salemohamed, Laurent Charlin, Shivam Garg, Vatsal Sharan, Gregory Valiant</author><pubDate>Tue, 05 Nov 2024 16:50:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03253v1</guid></item><item><title>Spontaneous Emergence of Agent Individuality through Social Interactions in LLM-Based Communities</title><link>http://arxiv.org/abs/2411.03252v1</link><description>We study the emergence of agency from scratch by using Large Language Model(LLM)-based agents. In previous studies of LLM-based agents, each agent'scharacteristics, including personality and memory, have traditionally beenpredefined. We focused on how individuality, such as behavior, personality, andmemory, can be differentiated from an undifferentiated state. The present LLMagents engage in cooperative communication within a group simulation,exchanging context-based messages in natural language. By analyzing thismulti-agent simulation, we report valuable new insights into how social norms,cooperation, and personality traits can emerge spontaneously. This paperdemonstrates that autonomously interacting LLM-powered agents generatehallucinations and hashtags to sustain communication, which, in turn, increasesthe diversity of words within their interactions. Each agent's emotions shiftthrough communication, and as they form communities, the personalities of theagents emerge and evolve accordingly. This computational modeling approach andits findings will provide a new method for analyzing collective artificialintelligence.</description><author>Ryosuke Takata, Atsushi Masumori, Takashi Ikegami</author><pubDate>Tue, 05 Nov 2024 16:49:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03252v1</guid></item><item><title>Parallelizing Linear Transformers with the Delta Rule over Sequence Length</title><link>http://arxiv.org/abs/2406.06484v4</link><description>Transformers with linear attention (i.e., linear transformers) andstate-space models have recently been suggested as a viable linear-timealternative to transformers with softmax attention. However, these models stillunderperform transformers especially on tasks that require in-contextretrieval. While more expressive variants of linear transformers which replacethe additive update in linear transformers with the delta rule (DeltaNet) havebeen found to be more effective at associative recall, existing algorithms fortraining such models do not parallelize over sequence length and are thusinefficient to train on modern hardware. This work describes ahardware-efficient algorithm for training linear transformers with the deltarule, which exploits a memory-efficient representation for computing productsof Householder matrices. This algorithm allows us to scale up DeltaNet tostandard language modeling settings. We train a 1.3B model for 100B tokens andfind that it outperforms recent linear-time baselines such as Mamba and GLA interms of perplexity and zero-shot performance on downstream tasks. We alsoexperiment with two hybrid models which combine DeltaNet layers with (1)sliding-window attention layers every other layer or (2) two global attentionlayers, and find that these hybrids outperform strong transformer baselines.</description><author>Songlin Yang, Bailin Wang, Yu Zhang, Yikang Shen, Yoon Kim</author><pubDate>Tue, 05 Nov 2024 16:48:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06484v4</guid></item><item><title>DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models</title><link>http://arxiv.org/abs/2411.03250v1</link><description>Recent advancements in large language models (LLMs) have significantlyenhanced their knowledge and generative capabilities, leading to a surge ofinterest in leveraging LLMs for high-quality data synthesis. However, syntheticdata generation via prompting LLMs remains challenging due to LLMs' limitedunderstanding of target data distributions and the complexity of promptengineering, especially for structured formatted data. To address these issues,we introduce DiffLM, a controllable data synthesis framework based onvariational autoencoder (VAE), which further (1) leverages diffusion models toreserve more information of original distribution and format structure in thelearned latent distribution and (2) decouples the learning of targetdistribution knowledge from the LLM's generative objectives via a plug-and-playlatent feature injection module. As we observed significant discrepanciesbetween the VAE's latent representations and the real data distribution, thelatent diffusion module is introduced into our framework to learn a fullyexpressive latent distribution. Evaluations on seven real-world datasets withstructured formatted data (i.e., Tabular, Code and Tool data) demonstrate thatDiffLM generates high-quality data, with performance on downstream taskssurpassing that of real data by 2-7 percent in certain cases. The data and codewill be publicly available upon completion of internal review.</description><author>Ying Zhou, Xinyao Wang, Yulei Niu, Yaojie Shen, Lexin Tang, Fan Chen, Ben He, Le Sun, Longyin Wen</author><pubDate>Tue, 05 Nov 2024 16:47:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03250v1</guid></item><item><title>RepLiQA: A Question-Answering Dataset for Benchmarking LLMs on Unseen Reference Content</title><link>http://arxiv.org/abs/2406.11811v2</link><description>Large Language Models (LLMs) are trained on vast amounts of data, most ofwhich is automatically scraped from the internet. This data includesencyclopedic documents that harbor a vast amount of general knowledge (e.g.,Wikipedia) but also potentially overlap with benchmark datasets used forevaluating LLMs. Consequently, evaluating models on test splits that might haveleaked into the training set is prone to misleading conclusions. To fostersound evaluation of language models, we introduce a new test dataset namedRepLiQA, suited for question-answering and topic retrieval tasks. RepLiQA is acollection of five splits of test sets, four of which have not been released tothe internet or exposed to LLM APIs prior to this publication. Each sample inRepLiQA comprises (1) a reference document crafted by a human annotator anddepicting an imaginary scenario (e.g., a news article) absent from theinternet; (2) a question about the document's topic; (3) a ground-truth answerderived directly from the information in the document; and (4) the paragraphextracted from the reference document containing the answer. As such, accurateanswers can only be generated if a model can find relevant content within theprovided document. We run a large-scale benchmark comprising severalstate-of-the-art LLMs to uncover differences in performance across models ofvarious types and sizes in a context-conditional language modeling setting.Released splits of RepLiQA can be found here:https://huggingface.co/datasets/ServiceNow/repliqa.</description><author>Joao Monteiro, Pierre-Andre Noel, Etienne Marcotte, Sai Rajeswar, Valentina Zantedeschi, David Vazquez, Nicolas Chapados, Christopher Pal, Perouz Taslakian</author><pubDate>Tue, 05 Nov 2024 16:47:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11811v2</guid></item><item><title>When Your AIs Deceive You: Challenges of Partial Observability in Reinforcement Learning from Human Feedback</title><link>http://arxiv.org/abs/2402.17747v4</link><description>Past analyses of reinforcement learning from human feedback (RLHF) assumethat the human evaluators fully observe the environment. What happens whenhuman feedback is based only on partial observations? We formally define twofailure cases: deceptive inflation and overjustification. Modeling the human asBoltzmann-rational w.r.t. a belief over trajectories, we prove conditions underwhich RLHF is guaranteed to result in policies that deceptively inflate theirperformance, overjustify their behavior to make an impression, or both. Underthe new assumption that the human's partial observability is known andaccounted for, we then analyze how much information the feedback processprovides about the return function. We show that sometimes, the human'sfeedback determines the return function uniquely up to an additive constant,but in other realistic cases, there is irreducible ambiguity. We proposeexploratory research directions to help tackle these challenges, experimentallyvalidate both the theoretical concerns and potential mitigations, and cautionagainst blindly applying RLHF in partially observable settings.</description><author>Leon Lang, Davis Foote, Stuart Russell, Anca Dragan, Erik Jenner, Scott Emmons</author><pubDate>Tue, 05 Nov 2024 16:46:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17747v4</guid></item><item><title>MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues</title><link>http://arxiv.org/abs/2402.14762v3</link><description>The advent of Large Language Models (LLMs) has drastically enhanced dialoguesystems. However, comprehensively evaluating the dialogue abilities of LLMsremains a challenge. Previous benchmarks have primarily focused on single-turndialogues or provided coarse-grained and incomplete assessments of multi-turndialogues, overlooking the complexity and fine-grained nuances of real-lifedialogues. To address this issue, we introduce MT-Bench-101, specificallydesigned to evaluate the fine-grained abilities of LLMs in multi-turndialogues. By conducting a detailed analysis of real multi-turn dialogue data,we construct a three-tier hierarchical ability taxonomy comprising 4208 turnsacross 1388 multi-turn dialogues in 13 distinct tasks. We then evaluate 21popular LLMs based on MT-Bench-101, conducting comprehensive analyses from bothability and task perspectives and observing differing trends in LLMsperformance across dialogue turns within various tasks. Further analysisindicates that neither utilizing common alignment techniques nor chat-specificdesigns has led to obvious enhancements in the multi-turn abilities of LLMs.Extensive case studies suggest that our designed tasks accurately assess thecorresponding multi-turn abilities. The data and code are available at\url{https://github.com/mtbench101/mt-bench-101}.</description><author>Ge Bai, Jie Liu, Xingyuan Bu, Yancheng He, Jiaheng Liu, Zhanhui Zhou, Zhuoran Lin, Wenbo Su, Tiezheng Ge, Bo Zheng, Wanli Ouyang</author><pubDate>Tue, 05 Nov 2024 16:40:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14762v3</guid></item><item><title>Decoupling Fine Detail and Global Geometry for Compressed Depth Map Super-Resolution</title><link>http://arxiv.org/abs/2411.03239v1</link><description>Recovering high-quality depth maps from compressed sources has gainedsignificant attention due to the limitations of consumer-grade depth camerasand the bandwidth restrictions during data transmission. However, currentmethods still suffer from two challenges. First, bit-depth compression producesa uniform depth representation in regions with subtle variations, hindering therecovery of detailed information. Second, densely distributed random noisereduces the accuracy of estimating the global geometric structure of the scene.To address these challenges, we propose a novel framework, termedgeometry-decoupled network (GDNet), for compressed depth map super-resolutionthat decouples the high-quality depth map reconstruction process by handlingglobal and detailed geometric features separately. To be specific, we proposethe fine geometry detail encoder (FGDE), which is designed to aggregate finegeometry details in high-resolution low-level image features whilesimultaneously enriching them with complementary information fromlow-resolution context-level image features. In addition, we develop the globalgeometry encoder (GGE) that aims at suppressing noise and extracting globalgeometric information effectively via constructing compact featurerepresentation in a low-rank space. We conduct experiments on multiplebenchmark datasets, demonstrating that our GDNet significantly outperformscurrent methods in terms of geometric consistency and detail recovery. In theECCV 2024 AIM Compressed Depth Upsampling Challenge, our solution won the 1stplace award. Our codes will be available.</description><author>Huan Zheng, Wencheng Han, Jianbing Shen</author><pubDate>Tue, 05 Nov 2024 16:37:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03239v1</guid></item><item><title>GemNet: Menu-Based, Strategy-Proof Multi-Bidder Auctions Through Deep Learning</title><link>http://arxiv.org/abs/2406.07428v3</link><description>Automated mechanism design (AMD) uses computational methods for mechanismdesign. Differentiable economics is a form of AMD that uses deep learning tolearn mechanism designs and has enabled strong progress in AMD in recent years.Nevertheless, a major open problem has been to learn multi-bidder, general, andfully strategy-proof (SP) auctions. We introduce GEneral Menu-based NETwork(GemNet), which significantly extends the menu-based approach of thesingle-bidder RochetNet (D\"utting et al., 2024) to the multi-bidder setting.The challenge in achieving SP is to learn bidder-independent menus that arefeasible, so that the optimal menu choices for each bidder do not over-allocateitems when taken together (we call this menu compatibility). GemNet penalizesthe failure of menu compatibility during training, and transforms learned menusafter training through price changes, by considering a set of discretizedbidder values and reasoning about Lipschitz smoothness to guarantee menucompatibility on the entire value space. This approach is general, leavingtrained menus that already satisfy menu compatibility undisturbed and reducingto RochetNet for a single bidder. Mixed-integer linear programs are used formenu transforms, and through a number of optimizations enabled by deeplearning, including adaptive grids and methods to skip menu elements, we scaleto large auction design problems. GemNet learns auctions with better revenuethan affine maximization methods, achieves exact SP whereas previous generalmulti-bidder methods are approximately SP, and offers greatly enhancedinterpretability.</description><author>Tonghan Wang, Yanchen Jiang, David C. Parkes</author><pubDate>Tue, 05 Nov 2024 16:37:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07428v3</guid></item><item><title>On the Detection of Non-Cooperative RISs: Scan B-Testing via Deep Support Vector Data Description</title><link>http://arxiv.org/abs/2411.03237v1</link><description>In this paper, we study the problem of promptly detecting the presence ofnon-cooperative activity from one or more Reconfigurable Intelligent Surfaces(RISs) with unknown characteristics lying in the vicinity of a Multiple-InputMultiple-Output (MIMO) communication system using Orthogonal Frequency-DivisionMultiplexing (OFDM) transmissions. We first present a novel wideband channelmodel incorporating RISs as well as non-reconfigurable stationary surfaces,which captures both the effect of the RIS actuation time on the channel in thefrequency domain as well as the difference between changing phaseconfigurations during or among transmissions. Considering that RISs may operateunder the coordination of a third-party system, and thus, may negatively impactthe communication of the intended MIMO OFDM system, we present a novel RISactivity detection framework that is unaware of the distribution of the phaseconfiguration of any of the non-cooperative RISs. In particular, capitalizingon the knowledge of the data distribution at the multi-antenna receiver, wedesign a novel online change point detection statistic that combines a deepsupport vector data description model with the scan $B$-test. The presentednumerical investigations demonstrate the improved detection accuracy as well asdecreased computational complexity of the proposed RIS detection approach overexisting change point detection schemes.</description><author>George Stamatelis, Panagiotis Gavriilidis, Aymen Fakhreddine, George C. Alexandropoulos</author><pubDate>Tue, 05 Nov 2024 16:36:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03237v1</guid></item><item><title>Enhancing Transformer Training Efficiency with Dynamic Dropout</title><link>http://arxiv.org/abs/2411.03236v1</link><description>We introduce Dynamic Dropout, a novel regularization technique designed toenhance the training efficiency of Transformer models by dynamically adjustingthe dropout rate based on training epochs or validation loss improvements. Thisapproach addresses the challenge of balancing regularization and modelcapacity, which is crucial for achieving fast convergence and high performance.Our method involves modifying the GPT model to accept a variable dropout rateand updating dropout layers during training using schedules such as lineardecay, exponential decay, and validation loss-based adjustments. Extensiveexperiments on the Shakespeare\_char dataset demonstrate that Dynamic Dropoutsignificantly accelerates training and improves inference efficiency comparedto a baseline model with a fixed dropout rate. The validation loss-basedadjustment schedule provided the best overall performance, highlighting thepotential of Dynamic Dropout as a valuable technique for training large-scaleTransformer models.</description><author>Hanrui Yan, Dan Shao</author><pubDate>Tue, 05 Nov 2024 16:36:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03236v1</guid></item><item><title>Accelerating Matroid Optimization through Fast Imprecise Oracles</title><link>http://arxiv.org/abs/2402.02774v2</link><description>Querying complex models for precise information (e.g. traffic models,database systems, large ML models) often entails intense computations andresults in long response times. Thus, weaker models which give impreciseresults quickly can be advantageous, provided inaccuracies can be resolvedusing few queries to a stronger model. In the fundamental problem of computinga maximum-weight basis of a matroid, a well-known generalization of manycombinatorial optimization problems, algorithms have access to a clean oracleto query matroid information. We additionally equip algorithms with a fast butdirty oracle modelling an unknown, potentially different matroid. We design andanalyze practical algorithms which only use few clean queries w.r.t. thequality of the dirty oracle, while maintaining robustness against arbitrarilypoor dirty matroids, approaching the performance of classic algorithms for thegiven problem. Notably, we prove that our algorithms are, in many respects,best-possible. Further, we outline extensions to other matroid oracle types,non-free dirty oracles and other matroid problems.</description><author>Franziska Eberle, Felix Hommelsheim, Alexander Lindermayr, Zhenwei Liu, Nicole Megow, Jens Schlöter</author><pubDate>Tue, 05 Nov 2024 16:34:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02774v2</guid></item><item><title>Poseidon: Efficient Foundation Models for PDEs</title><link>http://arxiv.org/abs/2405.19101v2</link><description>We introduce Poseidon, a foundation model for learning the solution operatorsof PDEs. It is based on a multiscale operator transformer, withtime-conditioned layer norms that enable continuous-in-time evaluations. Anovel training strategy leveraging the semi-group property of time-dependentPDEs to allow for significant scaling-up of the training data is also proposed.Poseidon is pretrained on a diverse, large scale dataset for the governingequations of fluid dynamics. It is then evaluated on a suite of 15 challengingdownstream tasks that include a wide variety of PDE types and operators. Weshow that Poseidon exhibits excellent performance across the board byoutperforming baselines significantly, both in terms of sample efficiency andaccuracy. Poseidon also generalizes very well to new physics that is not seenduring pretraining. Moreover, Poseidon scales with respect to model and datasize, both for pretraining and for downstream tasks. Taken together, ourresults showcase the surprising ability of Poseidon to learn effectiverepresentations from a very small set of PDEs during pretraining in order togeneralize well to unseen and unrelated PDEs downstream, demonstrating itspotential as an effective, general purpose PDE foundation model. Finally, thePoseidon model as well as underlying pretraining and downstream datasets areopen sourced, with code being available athttps://github.com/camlab-ethz/poseidon and pretrained models and datasets athttps://huggingface.co/camlab-ethz.</description><author>Maximilian Herde, Bogdan Raonić, Tobias Rohner, Roger Käppeli, Roberto Molinaro, Emmanuel de Bézenac, Siddhartha Mishra</author><pubDate>Tue, 05 Nov 2024 16:32:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19101v2</guid></item><item><title>Contextual Knowledge Pursuit for Faithful Visual Synthesis</title><link>http://arxiv.org/abs/2311.17898v3</link><description>Modern text-to-vision generative models often hallucinate when the promptdescribing the scene to be generated is underspecified. In large languagemodels (LLMs), a prevalent strategy to reduce hallucinations is to retrievefactual knowledge from an external database. While such retrieval augmentationstrategies have great potential to enhance text-to-vision generators, existingstatic top-K retrieval methods explore the knowledge pool once, missing thebroader context necessary for high-quality generation. Furthermore, LLMsinternally possess rich world knowledge learned during large-scale training(parametric knowledge) that could mitigate the need for external dataretrieval. This paper proposes Contextual Knowledge Pursuit (CKPT), a frameworkthat leverages the complementary strengths of external and parametric knowledgeto help generators produce reliable visual content. Instead of the one-timeretrieval of facts from an external database to improve a given prompt, CKPTuses (1) an LLM to decide whether to seek external knowledge or to self-elicitdescriptions from LLM parametric knowledge, (2) a knowledge pursuit process tocontextually seek and sequentially gather most relevant facts, (3) a knowledgeaggregator for prompt enhancement with the gathered fact context, and (4) afiltered fine-tuning objective to improve visual synthesis with richer prompts.We evaluate CKPT across multiple text-driven generative tasks (image, 3Drendering, and video) on datasets of rare objects and daily scenarios. Ourresults show that CKPT is capable of generating faithful and semantically richcontent across diverse visual domains, offering a promising data source forzero-shot synthesis and filtered fine-tuning of text-to-vision generativemodels.</description><author>Jinqi Luo, Kwan Ho Ryan Chan, Dimitris Dimos, René Vidal</author><pubDate>Tue, 05 Nov 2024 16:31:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17898v3</guid></item><item><title>DeBaRA: Denoising-Based 3D Room Arrangement Generation</title><link>http://arxiv.org/abs/2409.18336v2</link><description>Generating realistic and diverse layouts of furnished indoor 3D scenesunlocks multiple interactive applications impacting a wide range of industries.The inherent complexity of object interactions, the limited amount of availabledata and the requirement to fulfill spatial constraints all make generativemodeling for 3D scene synthesis and arrangement challenging. Current methodsaddress these challenges autoregressively or by using off-the-shelf diffusionobjectives by simultaneously predicting all attributes without 3D reasoningconsiderations. In this paper, we introduce DeBaRA, a score-based modelspecifically tailored for precise, controllable and flexible arrangementgeneration in a bounded environment. We argue that the most critical componentof a scene synthesis system is to accurately establish the size and position ofvarious objects within a restricted area. Based on this insight, we propose alightweight conditional score-based model designed with 3D spatial awareness atits core. We demonstrate that by focusing on spatial attributes of objects, asingle trained DeBaRA model can be leveraged at test time to perform severaldownstream applications such as scene synthesis, completion and re-arrangement.Further, we introduce a novel Self Score Evaluation procedure so it can beoptimally employed alongside external LLM models. We evaluate our approachthrough extensive experiments and demonstrate significant improvement uponstate-of-the-art approaches in a range of scenarios.</description><author>Léopold Maillard, Nicolas Sereyjol-Garros, Tom Durand, Maks Ovsjanikov</author><pubDate>Tue, 05 Nov 2024 16:30:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.18336v2</guid></item><item><title>Seeing Eye to AI: Comparing Human Gaze and Model Attention in Video Memorability</title><link>http://arxiv.org/abs/2311.16484v2</link><description>Understanding what makes a video memorable has important applications inadvertising or education technology. Towards this goal, we investigatespatio-temporal attention mechanisms underlying video memorability. Differentfrom previous works that fuse multiple features, we adopt a simpleCNN+Transformer architecture that enables analysis of spatio-temporal attentionwhile matching state-of-the-art (SoTA) performance on video memorabilityprediction. We compare model attention against human gaze fixations collectedthrough a small-scale eye-tracking study where humans perform the video memorytask. We uncover the following insights: (i) Quantitative saliency metrics showthat our model, trained only to predict a memorability score, exhibits similarspatial attention patterns to human gaze, especially for more memorable videos.(ii) The model assigns greater importance to initial frames in a video,mimicking human attention patterns. (iii) Panoptic segmentation reveals thatboth (model and humans) assign a greater share of attention to things and lessattention to stuff as compared to their occurrence probability.</description><author>Prajneya Kumar, Eshika Khandelwal, Makarand Tapaswi, Vishnu Sreekumar</author><pubDate>Tue, 05 Nov 2024 16:25:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16484v2</guid></item><item><title>Formal Logic-guided Robust Federated Learning against Poisoning Attacks</title><link>http://arxiv.org/abs/2411.03231v1</link><description>Federated Learning (FL) offers a promising solution to the privacy concernsassociated with centralized Machine Learning (ML) by enabling decentralized,collaborative learning. However, FL is vulnerable to various security threats,including poisoning attacks, where adversarial clients manipulate the trainingdata or model updates to degrade overall model performance. Recognizing thisthreat, researchers have focused on developing defense mechanisms to counteractpoisoning attacks in FL systems. However, existing robust FL methodspredominantly focus on computer vision tasks, leaving a gap in addressing theunique challenges of FL with time series data. In this paper, we presentFLORAL, a defense mechanism designed to mitigate poisoning attacks in federatedlearning for time-series tasks, even in scenarios with heterogeneous clientdata and a large number of adversarial participants. Unlike traditionalmodel-centric defenses, FLORAL leverages logical reasoning to evaluate clienttrustworthiness by aligning their predictions with global time-series patterns,rather than relying solely on the similarity of client updates. Our approachextracts logical reasoning properties from clients, then hierarchically infersglobal properties, and uses these to verify client updates. Through formallogic verification, we assess the robustness of each client contribution,identifying deviations indicative of adversarial behavior. Experimental resultson two datasets demonstrate the superior performance of our approach comparedto existing baseline methods, highlighting its potential to enhance therobustness of FL to time series applications. Notably, FLORAL reduced theprediction error by 93.27\% in the best-case scenario compared to thesecond-best baseline. Our code is available at\url{https://anonymous.4open.science/r/FLORAL-Robust-FTS}.</description><author>Dung Thuy Nguyen, Ziyan An, Taylor T. Johnson, Meiyi Ma, Kevin Leach</author><pubDate>Tue, 05 Nov 2024 16:23:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03231v1</guid></item><item><title>Efficacy of Various Large Language Models in Generating Smart Contracts</title><link>http://arxiv.org/abs/2407.11019v2</link><description>This study analyzes the application of code-generating Large Language Modelsin the creation of immutable Solidity smart contracts on the EthereumBlockchain. Other works have previously analyzed Artificial Intelligence codegeneration abilities. This paper aims to expand this to a larger scope toinclude programs where security and efficiency are of utmost priority such assmart contracts. The hypothesis leading into the study was that LLMs in generalwould have difficulty in rigorously implementing security details in the code,which was shown through our results, but surprisingly generally succeeded inmany common types of contracts. We also discovered a novel way of generatingsmart contracts through new prompting strategies.</description><author>Siddhartha Chatterjee, Bina Ramamurthy</author><pubDate>Tue, 05 Nov 2024 16:21:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11019v2</guid></item><item><title>Topograph: An efficient Graph-Based Framework for Strictly Topology Preserving Image Segmentation</title><link>http://arxiv.org/abs/2411.03228v1</link><description>Topological correctness plays a critical role in many image segmentationtasks, yet most networks are trained using pixel-wise loss functions, such asDice, neglecting topological accuracy. Existing topology-aware methods oftenlack robust topological guarantees, are limited to specific use cases, orimpose high computational costs. In this work, we propose a novel, graph-basedframework for topologically accurate image segmentation that is bothcomputationally efficient and generally applicable. Our method constructs acomponent graph that fully encodes the topological information of both theprediction and ground truth, allowing us to efficiently identify topologicallycritical regions and aggregate a loss based on local neighborhood information.Furthermore, we introduce a strict topological metric capturing the homotopyequivalence between the union and intersection of prediction-label pairs. Weformally prove the topological guarantees of our approach and empiricallyvalidate its effectiveness on binary and multi-class datasets. Our lossdemonstrates state-of-the-art performance with up to fivefold faster losscomputation compared to persistent homology methods.</description><author>Laurin Lux, Alexander H. Berger, Alexander Weers, Nico Stucki, Daniel Rueckert, Ulrich Bauer, Johannes C. Paetzold</author><pubDate>Tue, 05 Nov 2024 16:20:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03228v1</guid></item><item><title>Kernel Orthogonality does not necessarily imply a Decrease in Feature Map Redundancy in CNNs: Convolutional Similarity Minimization</title><link>http://arxiv.org/abs/2411.03226v1</link><description>Convolutional Neural Networks (CNNs) have been heavily used in Deep Learningdue to their success in various tasks. Nonetheless, it has been observed thatCNNs suffer from redundancy in feature maps, leading to inefficient capacityutilization. Efforts to mitigate and solve this problem led to the emergence ofmultiple methods, amongst which is kernel orthogonality through variant means.In this work, we challenge the common belief that kernel orthogonality leads toa decrease in feature map redundancy, which is, supposedly, the ultimateobjective behind kernel orthogonality. We prove, theoretically and empirically,that kernel orthogonality has an unpredictable effect on feature map similarityand does not necessarily decrease it. Based on our theoretical result, wepropose an effective method to reduce feature map similarity independently ofthe input of the CNN. This is done by minimizing a novel loss function we callConvolutional Similarity. Empirical results show that minimizing theConvolutional Similarity increases the performance of classification models andcan accelerate their convergence. Furthermore, using our proposed method pushestowards a more efficient use of the capacity of models, allowing the use ofsignificantly smaller models to achieve the same levels of performance.</description><author>Zakariae Belmekki, Jun Li, Patrick Reuter, David Antonio Gómez Jáuregui, Karl Jenkins</author><pubDate>Tue, 05 Nov 2024 16:18:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03226v1</guid></item><item><title>Re-assembling the past: The RePAIR dataset and benchmark for real world 2D and 3D puzzle solving</title><link>http://arxiv.org/abs/2410.24010v2</link><description>This paper proposes the RePAIR dataset that represents a challengingbenchmark to test modern computational and data driven methods forpuzzle-solving and reassembly tasks. Our dataset has unique properties that areuncommon to current benchmarks for 2D and 3D puzzle solving. The fragments andfractures are realistic, caused by a collapse of a fresco during a World War IIbombing at the Pompeii archaeological park. The fragments are also eroded andhave missing pieces with irregular shapes and different dimensions, challengingfurther the reassembly algorithms. The dataset is multi-modal providing highresolution images with characteristic pictorial elements, detailed 3D scans ofthe fragments and meta-data annotated by the archaeologists. Ground truth hasbeen generated through several years of unceasing fieldwork, including theexcavation and cleaning of each fragment, followed by manual puzzle solving byarchaeologists of a subset of approx. 1000 pieces among the 16000 available.After digitizing all the fragments in 3D, a benchmark was prepared to challengecurrent reassembly and puzzle-solving methods that often solve more simplisticsynthetic scenarios. The tested baselines show that there clearly exists a gapto fill in solving this computationally complex problem.</description><author>Theodore Tsesmelis, Luca Palmieri, Marina Khoroshiltseva, Adeela Islam, Gur Elkin, Ofir Itzhak Shahar, Gianluca Scarpellini, Stefano Fiorini, Yaniv Ohayon, Nadav Alali, Sinem Aslan, Pietro Morerio, Sebastiano Vascon, Elena Gravina, Maria Cristina Napolitano, Giuseppe Scarpati, Gabriel Zuchtriegel, Alexandra Spühler, Michel E. Fuchs, Stuart James, Ohad Ben-Shahar, Marcello Pelillo, Alessio Del Bue</author><pubDate>Tue, 05 Nov 2024 16:16:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.24010v2</guid></item><item><title>Knowledge Graphs of Driving Scenes to Empower the Emerging Capabilities of Neurosymbolic AI</title><link>http://arxiv.org/abs/2411.03225v1</link><description>In the era of Generative AI, Neurosymbolic AI is emerging as a powerfulapproach for tasks spanning from perception to cognition. The use ofNeurosymbolic AI has been shown to achieve enhanced capabilities, includingimproved grounding, alignment, explainability, and reliability. However, due toits nascent stage, there is a lack of widely available real-world benchmarkdatasets tailored to Neurosymbolic AI tasks. To address this gap and supportthe evaluation of current and future methods, we introduce DSceneKG -- a suiteof knowledge graphs of driving scenes built from real-world, high-qualityscenes from multiple open autonomous driving datasets. In this article, wedetail the construction process of DSceneKG and highlight its application inseven different tasks. DSceneKG is publicly accessible at:https://github.com/ruwantw/DSceneKG</description><author>Ruwan Wickramarachchi, Cory Henson, Amit Sheth</author><pubDate>Tue, 05 Nov 2024 16:15:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03225v1</guid></item><item><title>Interpretable Predictive Models for Healthcare via Rational Logistic Regression</title><link>http://arxiv.org/abs/2411.03224v1</link><description>The healthcare sector has experienced a rapid accumulation of digital datarecently, especially in the form of electronic health records (EHRs). EHRsconstitute a precious resource that IS researchers could utilize for clinicalapplications (e.g., morbidity prediction). Deep learning seems like the obviouschoice to exploit this surfeit of data. However, numerous studies have shownthat deep learning does not enjoy the same kind of success on EHR data as ithas in other domains; simple models like logistic regression are frequently asgood as sophisticated deep learning ones. Inspired by this observation, wedevelop a novel model called rational logistic regression (RLR) that hasstandard logistic regression (LR) as its special case (and thus inherits LR'sinductive bias that aligns with EHR data). RLR has rational series as itstheoretical underpinnings, works on longitudinal time-series data, and learnsinterpretable patterns. Empirical comparisons on real-world clinical tasksdemonstrate RLR's efficacy.</description><author>Thiti Suttaket, L Vivek Harsha Vardhan, Stanley Kok</author><pubDate>Tue, 05 Nov 2024 16:15:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03224v1</guid></item><item><title>Beyond Grid Data: Exploring Graph Neural Networks for Earth Observation</title><link>http://arxiv.org/abs/2411.03223v1</link><description>Earth Observation (EO) data analysis has been significantly revolutionized bydeep learning (DL), with applications typically limited to grid-like datastructures. Graph Neural Networks (GNNs) emerge as an important innovation,propelling DL into the non-Euclidean domain. Naturally, GNNs can effectivelytackle the challenges posed by diverse modalities, multiple sensors, and theheterogeneous nature of EO data. To introduce GNNs in the related domains, ourreview begins by offering fundamental knowledge on GNNs. Then, we summarize thegeneric problems in EO, to which GNNs can offer potential solutions. Followingthis, we explore a broad spectrum of GNNs' applications to scientific problemsin Earth systems, covering areas such as weather and climate analysis, disastermanagement, air quality monitoring, agriculture, land cover classification,hydrological process modeling, and urban modeling. The rationale behindadopting GNNs in these fields is explained, alongside methodologies fororganizing graphs and designing favorable architectures for various tasks.Furthermore, we highlight methodological challenges of implementing GNNs inthese domains and possible solutions that could guide future research. Whileacknowledging that GNNs are not a universal solution, we conclude the paper bycomparing them with other popular architectures like transformers and analyzingtheir potential synergies.</description><author>Shan Zhao, Zhaiyu Chen, Zhitong Xiong, Yilei Shi, Sudipan Saha, Xiao Xiang Zhu</author><pubDate>Tue, 05 Nov 2024 16:12:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03223v1</guid></item><item><title>A Personal data Value at Risk Approach</title><link>http://arxiv.org/abs/2411.03217v1</link><description>What if the main data protection vulnerability is risk management? DataProtection merges three disciplines: data protection law, information security,and risk management. Nonetheless, very little research has been made on thefield of data protection risk management, where subjectivity and superficialityare the dominant state of the art. Since the GDPR tells you what to do, but nothow to do it, the solution for approaching GDPR compliance is still a grayzone, where the trend is using the rule of thumb. Considering that the mostimportant goal of risk management is to reduce uncertainty in order to takeinformed decisions, risk management for the protection of the rights andfreedoms of the data subjects cannot be disconnected from the impactmaterialization that data controllers and processors need to assess. This paperproposes a quantitative approach to data protection risk-based compliance froma data controllers perspective, with the aim of proposing a mindset change,where data protection impact assessments can be improved by using dataprotection analytics, quantitative risk analysis, and calibrating expertopinions.</description><author>Luis Enriquez</author><pubDate>Tue, 05 Nov 2024 16:09:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03217v1</guid></item><item><title>Piecewise deterministic generative models</title><link>http://arxiv.org/abs/2407.19448v2</link><description>We introduce a novel class of generative models based on piecewisedeterministic Markov processes (PDMPs), a family of non-diffusive stochasticprocesses consisting of deterministic motion and random jumps at random times.Similarly to diffusions, such Markov processes admit time reversals that turnout to be PDMPs as well. We apply this observation to three PDMPs considered inthe literature: the Zig-Zag process, Bouncy Particle Sampler, and RandomisedHamiltonian Monte Carlo. For these three particular instances, we show that thejump rates and kernels of the corresponding time reversals admit explicitexpressions depending on some conditional densities of the PDMP underconsideration before and after a jump. Based on these results, we proposeefficient training procedures to learn these characteristics and considermethods to approximately simulate the reverse process. Finally, we providebounds in the total variation distance between the data distribution and theresulting distribution of our model in the case where the base distribution isthe standard $d$-dimensional Gaussian distribution. Promising numericalsimulations support further investigations into this class of models.</description><author>Andrea Bertazzi, Dario Shariatian, Umut Simsekli, Eric Moulines, Alain Durmus</author><pubDate>Tue, 05 Nov 2024 16:06:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.19448v2</guid></item><item><title>Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation</title><link>http://arxiv.org/abs/2401.06477v4</link><description>In this paper, we introduce Kun, a novel approach for creating high-qualityinstruction-tuning datasets for large language models (LLMs) without relying onmanual annotations. Adapting a self-training algorithm based on instructionback-translation and answer polishment, Kun leverages unlabelled data fromdiverse sources such as Wudao, Wanjuan, and SkyPile to generate a substantialdataset of over a million Chinese instructional data points. This approachsignificantly deviates from traditional methods by using a self-curationprocess to refine and select the most effective instruction-output pairs. Ourexperiments with the 6B-parameter Yi model across various benchmarksdemonstrate Kun's robustness and scalability. Our method's core contributionslie in its algorithmic advancement, which enhances data retention and clarity,and its innovative data generation approach that substantially reduces thereliance on costly and time-consuming manual annotations. This methodologypresents a scalable and efficient solution for improving theinstruction-following capabilities of LLMs, with significant implications fortheir application across diverse fields. The code and dataset can be found athttps://github.com/Zheng0428/COIG-Kun</description><author>Tianyu Zheng, Shuyue Guo, Xingwei Qu, Jiawei Guo, Xinrun Du, Qi Jia, Chenghua Lin, Wenhao Huang, Jie Fu, Ge Zhang</author><pubDate>Tue, 05 Nov 2024 16:02:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06477v4</guid></item><item><title>Online Analytic Exemplar-Free Continual Learning with Large Models for Imbalanced Autonomous Driving Task</title><link>http://arxiv.org/abs/2405.17779v2</link><description>In autonomous driving, even a meticulously trained model can encounterfailures when facing unfamiliar scenarios. One of these scenarios can beformulated as an online continual learning (OCL) problem. That is, data come inan online fashion, and models are updated according to these streaming data.Two major OCL challenges are catastrophic forgetting and data imbalance. Toaddress these challenges, in this paper, we propose an Analytic Exemplar-FreeOnline Continual Learning algorithm (AEF-OCL). The AEF-OCL leverages analyticcontinual learning principles and employs ridge regression as a classifier forfeatures extracted by a large backbone network. It solves the OCL problem byrecursively calculating the analytical solution, ensuring an equalizationbetween the continual learning and its joint-learning counterpart, and workswithout the need to save any used samples (i.e., exemplar-free). Additionally,we introduce a Pseudo-Features Generator (PFG) module that recursivelyestimates the mean and the variance of real features for each class. Itover-samples offset pseudo-features from the same normal distribution as thereal features, thereby addressing the data imbalance issue. Experimentalresults demonstrate that despite being an exemplar-free strategy, our methodoutperforms various methods on the autonomous driving SODA10M dataset. Sourcecode is available at https://github.com/ZHUANGHP/Analytic-continual-learning.</description><author>Huiping Zhuang, Di Fang, Kai Tong, Yuchen Liu, Ziqian Zeng, Xu Zhou, Cen Chen</author><pubDate>Tue, 05 Nov 2024 15:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.17779v2</guid></item><item><title>Teaching Models to Improve on Tape</title><link>http://arxiv.org/abs/2411.01483v2</link><description>Large Language Models (LLMs) often struggle when prompted to generate contentunder specific constraints. However, in such cases it is often easy to checkwhether these constraints are satisfied or violated. Recent works have shownthat LLMs can benefit from such ``corrective feedback''. Here we claim thatthis skill of LLMs can be significantly enhanced via training. We introduce anRL framework for teaching models to use such rewards, by simulating interactionsessions, and rewarding the model according to its ability to satisfy theconstraints. We refer to our method as CORGI (Controlled Generation with RL forGuided Interaction), and evaluate it on a variety of controlled generationtasks using unlabeled training data. We find that CORGI consistentlyoutperforms the baseline reinforcement learning method that does notincorporate conversational feedback. Furthermore, CORGI's interactive frameworkenables meta-learning, allowing the LLM to generalize better to guidedinteraction in new tasks. Our results clearly show that conversationaloptimization, when combined with reinforcement learning, significantly improvesthe effectiveness of LLMs in controlled generation contexts.</description><author>Liat Bezalel, Eyal Orgad, Amir Globerson</author><pubDate>Tue, 05 Nov 2024 15:55:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.01483v2</guid></item><item><title>GIS Copilot: Towards an Autonomous GIS Agent for Spatial Analysis</title><link>http://arxiv.org/abs/2411.03205v1</link><description>Recent advancements in Generative AI offer promising capabilities for spatialanalysis. Despite their potential, the integration of generative AI withestablished GIS platforms remains underexplored. In this study, we propose aframework for integrating LLMs directly into existing GIS platforms, using QGISas an example. Our approach leverages the reasoning and programmingcapabilities of LLMs to autonomously generate spatial analysis workflows andcode through an informed agent that has comprehensive documentation of key GIStools and parameters. The implementation of this framework resulted in thedevelopment of a "GIS Copilot" that allows GIS users to interact with QGISusing natural language commands for spatial analysis. The GIS Copilot wasevaluated based on three complexity levels: basic tasks that require one GIStool and typically involve one data layer to perform simple operations;intermediate tasks involving multi-step processes with multiple tools, guidedby user instructions; and advanced tasks which involve multi-step processesthat require multiple tools but not guided by user instructions, necessitatingthe agent to independently decide on and executes the necessary steps. Theevaluation reveals that the GIS Copilot demonstrates strong potential inautomating foundational GIS operations, with a high success rate in toolselection and code generation for basic and intermediate tasks, whilechallenges remain in achieving full autonomy for more complex tasks. This studycontributes to the emerging vision of Autonomous GIS, providing a pathway fornon-experts to engage with geospatial analysis with minimal prior expertise.While full autonomy is yet to be achieved, the GIS Copilot demonstratessignificant potential for simplifying GIS workflows and enhancingdecision-making processes.</description><author>Temitope Akinboyewa, Zhenlong Li, Huan Ning, M. Naser Lessani</author><pubDate>Tue, 05 Nov 2024 15:53:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03205v1</guid></item><item><title>PaCE: Parsimonious Concept Engineering for Large Language Models</title><link>http://arxiv.org/abs/2406.04331v2</link><description>Large Language Models (LLMs) are being used for a wide variety of tasks.While they are capable of generating human-like responses, they can alsoproduce undesirable output including potentially harmful information, racist orsexist language, and hallucinations. Alignment methods are designed to reducesuch undesirable outputs via techniques such as fine-tuning, promptengineering, and representation engineering. However, existing methods faceseveral challenges: some require costly fine-tuning for every alignment task;some do not adequately remove undesirable concepts, failing alignment; someremove benign concepts, lowering the linguistic capabilities of LLMs. Toaddress these issues, we propose Parsimonious Concept Engineering (PaCE), anovel activation engineering framework for alignment. First, to sufficientlymodel the concepts, we construct a large-scale concept dictionary in theactivation space, in which each atom corresponds to a semantic concept. Givenany alignment task, we instruct a concept partitioner to efficiently annotatethe concepts as benign or undesirable. Then, at inference time, we decomposethe LLM activations along the concept dictionary via sparse coding, toaccurately represent the activations as linear combinations of benign andundesirable components. By removing the latter ones from the activations, wereorient the behavior of the LLM towards the alignment goal. We conductexperiments on tasks such as response detoxification, faithfulness enhancement,and sentiment revising, and show that PaCE achieves state-of-the-art alignmentperformance while maintaining linguistic capabilities.</description><author>Jinqi Luo, Tianjiao Ding, Kwan Ho Ryan Chan, Darshan Thaker, Aditya Chattopadhyay, Chris Callison-Burch, René Vidal</author><pubDate>Tue, 05 Nov 2024 15:43:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04331v2</guid></item><item><title>Online Data Collection for Efficient Semiparametric Inference</title><link>http://arxiv.org/abs/2411.03195v1</link><description>While many works have studied statistical data fusion, they typically assumethat the various datasets are given in advance. However, in practice,estimation requires difficult data collection decisions like determining theavailable data sources, their costs, and how many samples to collect from eachsource. Moreover, this process is often sequential because the data collectedat a given time can improve collection decisions in the future. In our setup,given access to multiple data sources and budget constraints, the agent mustsequentially decide which data source to query to efficiently estimate a targetparameter. We formalize this task using Online Moment Selection, asemiparametric framework that applies to any parameter identified by a set ofmoment conditions. Interestingly, the optimal budget allocation depends on the(unknown) true parameters. We present two online data collection policies,Explore-then-Commit and Explore-then-Greedy, that use the parameter estimatesat a given time to optimally allocate the remaining budget in the future steps.We prove that both policies achieve zero regret (assessed by asymptotic MSE)relative to an oracle policy. We empirically validate our methods on bothsynthetic and real-world causal effect estimation tasks, demonstrating that theonline data collection policies outperform their fixed counterparts.</description><author>Shantanu Gupta, Zachary C. Lipton, David Childers</author><pubDate>Tue, 05 Nov 2024 15:40:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03195v1</guid></item><item><title>MuPT: A Generative Symbolic Music Pretrained Transformer</title><link>http://arxiv.org/abs/2404.06393v4</link><description>In this paper, we explore the application of Large Language Models (LLMs) tothe pre-training of music. While the prevalent use of MIDI in music modeling iswell-established, our findings suggest that LLMs are inherently more compatiblewith ABC Notation, which aligns more closely with their design and strengths,thereby enhancing the model's performance in musical composition. To addressthe challenges associated with misaligned measures from different tracks duringgeneration, we propose the development of a Synchronized Multi-Track ABCNotation (SMT-ABC Notation), which aims to preserve coherence across multiplemusical tracks. Our contributions include a series of models capable ofhandling up to 8192 tokens, covering 90% of the symbolic music data in ourtraining set. Furthermore, we explore the implications of the Symbolic MusicScaling Law (SMS Law) on model performance. The results indicate a promisingdirection for future research in music generation, offering extensive resourcesfor community-led research through our open-source contributions.</description><author>Xingwei Qu, Yuelin Bai, Yinghao Ma, Ziya Zhou, Ka Man Lo, Jiaheng Liu, Ruibin Yuan, Lejun Min, Xueling Liu, Tianyu Zhang, Xinrun Du, Shuyue Guo, Yiming Liang, Yizhi Li, Shangda Wu, Junting Zhou, Tianyu Zheng, Ziyang Ma, Fengze Han, Wei Xue, Gus Xia, Emmanouil Benetos, Xiang Yue, Chenghua Lin, Xu Tan, Stephen W. Huang, Jie Fu, Ge Zhang</author><pubDate>Tue, 05 Nov 2024 15:40:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.06393v4</guid></item><item><title>Attention-based Class-Conditioned Alignment for Multi-Source Domain Adaptation of Object Detectors</title><link>http://arxiv.org/abs/2403.09918v4</link><description>Domain adaptation methods for object detection (OD) strive to mitigate theimpact of distribution shifts by promoting feature alignment across source andtarget domains. Multi-source domain adaptation (MSDA) allows leveragingmultiple annotated source datasets and unlabeled target data to improve theaccuracy and robustness of the detection model. Most state-of-the-art MSDAmethods for OD perform feature alignment in a class-agnostic manner. This ischallenging since the objects have unique modal information due to variationsin object appearance across domains. A recent prototype-based approach proposeda class-wise alignment, yet it suffers from error accumulation due to noisypseudo-labels that can negatively affect adaptation with imbalanced data. Toovercome these limitations, we propose an attention-based class-conditionedalignment method for MSDA that aligns instances of each object category acrossdomains. In particular, an attention module coupled with an adversarial domainclassifier allows learning domain-invariant and class-specific instancerepresentations. Experimental results on multiple benchmarking MSDA datasetsindicate that our method outperforms the state-of-the-art methods and is robustto class imbalance using a conceptually simple class-conditioning method. Ourcode is available at https://github.com/imatif17/ACIA.</description><author>Atif Belal, Akhil Meethal, Francisco Perdigon Romero, Marco Pedersoli, Eric Granger</author><pubDate>Tue, 05 Nov 2024 15:37:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.09918v4</guid></item><item><title>Insights into Lunar Mineralogy: An Unsupervised Approach for Clustering of the Moon Mineral Mapper (M3) spectral data</title><link>http://arxiv.org/abs/2411.03186v1</link><description>This paper presents a novel method for mapping spectral features of the Moonusing machine learning-based clustering of hyperspectral data from the MoonMineral Mapper (M3) imaging spectrometer. The method uses a convolutionalvariational autoencoder to reduce the dimensionality of the spectral data andextract features of the spectra. Then, a k-means algorithm is applied tocluster the latent variables into five distinct groups, corresponding todominant spectral features, which are related to the mineral composition of theMoon's surface. The resulting global spectral cluster map shows thedistribution of the five clusters on the Moon, which consist of a mixture of,among others, plagioclase, pyroxene, olivine, and Fe-bearing minerals acrossthe Moon's surface. The clusters are compared to the mineral maps from theKaguya mission, which showed that the locations of the clusters overlap withthe locations of high wt% of minerals such as plagioclase, clinopyroxene, andolivine. The paper demonstrates the usefulness of unbiased unsupervisedlearning for lunar mineral exploration and provides a comprehensive analysis oflunar mineralogy.</description><author>Freja Thoresen, Igor Drozdovskiy, Aidan Cowley, Magdelena Laban, Sebastien Besse, Sylvain Blunier</author><pubDate>Tue, 05 Nov 2024 15:31:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03186v1</guid></item><item><title>FUSE: Fast Unified Simulation and Estimation for PDEs</title><link>http://arxiv.org/abs/2405.14558v2</link><description>The joint prediction of continuous fields and statistical estimation of theunderlying discrete parameters is a common problem for many physical systems,governed by PDEs. Hitherto, it has been separately addressed by employingoperator learning surrogates for field prediction while using simulation-basedinference (and its variants) for statistical parameter determination. Here, weargue that solving both problems within the same framework can lead toconsistent gains in accuracy and robustness. To this end, We propose a noveland flexible formulation of the operator learning problem that allows jointlypredicting continuous quantities and inferring distributions of discreteparameters, and thus amortizing the cost of both the inverse and the surrogatemodels to a joint pre-training step. We present the capabilities of theproposed methodology for predicting continuous and discrete biomarkers infull-body haemodynamics simulations under different levels of missinginformation. We also consider a test case for atmospheric large-eddy simulationof a two-dimensional dry cold bubble, where we infer both continuoustime-series and information about the systems conditions. We presentcomparisons against different baselines to showcase significantly increasedaccuracy in both the inverse and the surrogate tasks.</description><author>Levi E. Lingsch, Dana Grund, Siddhartha Mishra, Georgios Kissas</author><pubDate>Tue, 05 Nov 2024 15:31:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14558v2</guid></item><item><title>AI-Driven approach for sustainable extraction of earth's subsurface renewable energy while minimizing seismic activity</title><link>http://arxiv.org/abs/2408.03664v2</link><description>Deep Geothermal Energy, Carbon Capture and Storage, and Hydrogen Storage holdconsiderable promise for meeting the energy sector's large-scale requirementsand reducing CO$_2$ emissions. However, the injection of fluids into theEarth's crust, essential for these activities, can induce or triggerearthquakes. In this paper, we highlight a new approach based on ReinforcementLearning for the control of human-induced seismicity in the highly complexenvironment of an underground reservoir. This complex system poses significantchallenges in the control design due to parameter uncertainties and unmodeleddynamics. We show that the reinforcement learning algorithm can interactefficiently with a robust controller, by choosing the controller parameters inreal-time, reducing human-induced seismicity and allowing the consideration offurther production objectives, \textit{e.g.}, minimal control power.Simulations are presented for a simplified underground reservoir under variousenergy demand scenarios, demonstrating the reliability and effectiveness of theproposed control-reinforcement learning approach.</description><author>Diego Gutierrez-Oribio, Alexandros Stathas, Ioannis Stefanou</author><pubDate>Tue, 05 Nov 2024 15:27:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03664v2</guid></item><item><title>Temporal Smoothness Regularisers for Neural Link Predictors</title><link>http://arxiv.org/abs/2309.09045v2</link><description>Most algorithms for representation learning and link prediction on relationaldata are designed for static data. However, the data to which they are appliedtypically evolves over time, including online social networks or interactionsbetween users and items in recommender systems. This is also the case forgraph-structured knowledge bases -- knowledge graphs -- which contain factsthat are valid only for specific points in time. In such contexts, it becomescrucial to correctly identify missing links at a precise time point, i.e. thetemporal prediction link task. Recently, Lacroix et al. and Sadeghian et al.proposed a solution to the problem of link prediction for knowledge graphsunder temporal constraints inspired by the canonical decomposition of 4-ordertensors, where they regularise the representations of time steps by enforcingtemporal smoothing, i.e. by learning similar transformation for adjacenttimestamps. However, the impact of the choice of temporal regularisation termsis still poorly understood. In this work, we systematically analyse severalchoices of temporal smoothing regularisers using linear functions and recurrentarchitectures. In our experiments, we show that by carefully selecting thetemporal smoothing regulariser and regularisation weight, a simple method likeTNTComplEx can produce significantly more accurate results thanstate-of-the-art methods on three widely used temporal link predictiondatasets. Furthermore, we evaluate the impact of a wide range of temporalsmoothing regularisers on two state-of-the-art temporal link prediction models.Our work shows that simple tensor factorisation models can produce newstate-of-the-art results using newly proposed temporal regularisers,highlighting a promising avenue for future research.</description><author>Manuel Dileo, Pasquale Minervini, Matteo Zignani, Sabrina Gaito</author><pubDate>Tue, 05 Nov 2024 15:26:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09045v2</guid></item><item><title>On Improved Conditioning Mechanisms and Pre-training Strategies for Diffusion Models</title><link>http://arxiv.org/abs/2411.03177v1</link><description>Large-scale training of latent diffusion models (LDMs) has enabledunprecedented quality in image generation. However, the key components of thebest performing LDM training recipes are oftentimes not available to theresearch community, preventing apple-to-apple comparisons and hindering thevalidation of progress in the field. In this work, we perform an in-depth studyof LDM training recipes focusing on the performance of models and theirtraining efficiency. To ensure apple-to-apple comparisons, we re-implement fivepreviously published models with their corresponding recipes. Through ourstudy, we explore the effects of (i)~the mechanisms used to condition thegenerative model on semantic information (e.g., text prompt) and controlmetadata (e.g., crop size, random flip flag, etc.) on the model performance,and (ii)~the transfer of the representations learned on smaller andlower-resolution datasets to larger ones on the training efficiency and modelperformance. We then propose a novel conditioning mechanism that disentanglessemantic and control metadata conditionings and sets a new state-of-the-art inclass-conditional generation on the ImageNet-1k dataset -- with FIDimprovements of 7% on 256 and 8% on 512 resolutions -- as well as text-to-imagegeneration on the CC12M dataset -- with FID improvements of 8% on 256 and 23%on 512 resolution.</description><author>Tariq Berrada Ifriqi, Pietro Astolfi, Melissa Hall, Reyhane Askari-Hemmat, Yohann Benchetrit, Marton Havasi, Matthew Muckley, Karteek Alahari, Adriana Romero-Soriano, Jakob Verbeek, Michal Drozdzal</author><pubDate>Tue, 05 Nov 2024 15:22:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03177v1</guid></item><item><title>Blind Estimation of Sub-band Acoustic Parameters from Ambisonics Recordings using Spectro-Spatial Covariance Features</title><link>http://arxiv.org/abs/2411.03172v1</link><description>Estimating frequency-varying acoustic parameters is essential for enhancingimmersive perception in realistic spatial audio creation. In this paper, wepropose a unified framework that blindly estimates reverberation time (T60),direct-to-reverberant ratio (DRR), and clarity (C50) across 10 frequency bandsusing first-order Ambisonics (FOA) speech recordings as inputs. The proposedframework utilizes a novel feature named Spectro-Spatial Covariance Vector(SSCV), efficiently representing temporal, spectral as well as spatialinformation of the FOA signal. Our models significantly outperform existingsingle-channel methods with only spectral information, reducing estimationerrors by more than half for all three acoustic parameters. Additionally, weintroduce FOA-Conv3D, a novel back-end network for effectively utilising theSSCV feature with a 3D convolutional encoder. FOA-Conv3D outperforms theconvolutional neural network (CNN) and recurrent convolutional neural network(CRNN) backends, achieving lower estimation errors and accounting for a higherproportion of variance (PoV) for all 3 acoustic parameters.</description><author>Hanyu Meng, Jeroen Breebaart, Jeremy Stoddard, Vidhyasaharan Sethu, Eliathamby Ambikairajah</author><pubDate>Tue, 05 Nov 2024 15:20:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03172v1</guid></item><item><title>Dimension-free deterministic equivalents and scaling laws for random feature regression</title><link>http://arxiv.org/abs/2405.15699v3</link><description>In this work we investigate the generalization performance of random featureridge regression (RFRR). Our main contribution is a general deterministicequivalent for the test error of RFRR. Specifically, under a certainconcentration property, we show that the test error is well approximated by aclosed-form expression that only depends on the feature map eigenvalues.Notably, our approximation guarantee is non-asymptotic, multiplicative, andindependent of the feature map dimension -- allowing for infinite-dimensionalfeatures. We expect this deterministic equivalent to hold broadly beyond ourtheoretical analysis, and we empirically validate its predictions on variousreal and synthetic datasets. As an application, we derive sharp excess errorrates under standard power-law assumptions of the spectrum and target decay. Inparticular, we provide a tight result for the smallest number of featuresachieving optimal minimax error rate.</description><author>Leonardo Defilippis, Bruno Loureiro, Theodor Misiakiewicz</author><pubDate>Tue, 05 Nov 2024 15:19:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15699v3</guid></item><item><title>Navigating Extremes: Dynamic Sparsity in Large Output Space</title><link>http://arxiv.org/abs/2411.03171v1</link><description>In recent years, Dynamic Sparse Training (DST) has emerged as an alternativeto post-training pruning for generating efficient models. In principle, DSTallows for a more memory efficient training process, as it maintains sparsitythroughout the entire training run. However, current DST implementations failto capitalize on this in practice. Because sparse matrix multiplication is muchless efficient than dense matrix multiplication on GPUs, most implementationssimulate sparsity by masking weights. In this paper, we leverage recentadvances in semi-structured sparse training to apply DST in the domain ofclassification with large output spaces, where memory-efficiency is paramount.With a label space of possibly millions of candidates, the classification layeralone will consume several gigabytes of memory. Switching from a dense to afixed fan-in sparse layer updated with sparse evolutionary training (SET);however, severely hampers training convergence, especially at the largest labelspaces. We find that poor gradient flow from the sparse classifier to the densetext encoder make it difficult to learn good input representations. Byemploying an intermediate layer or adding an auxiliary training objective, werecover most of the generalisation performance of the dense model. Overall, wedemonstrate the applicability and practical benefits of DST in a challengingdomain -- characterized by a highly skewed label distribution that differssubstantially from typical DST benchmark datasets -- which enables end-to-endtraining with millions of labels on commodity hardware.</description><author>Nasib Ullah, Erik Schultheis, Mike Lasby, Yani Ioannou, Rohit Babbar</author><pubDate>Tue, 05 Nov 2024 15:19:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03171v1</guid></item><item><title>GlobalDoc: A Cross-Modal Vision-Language Framework for Real-World Document Image Retrieval and Classification</title><link>http://arxiv.org/abs/2309.05756v3</link><description>Visual document understanding (VDU) has rapidly advanced with the developmentof powerful multi-modal language models. However, these models typicallyrequire extensive document pre-training data to learn intermediaterepresentations and often suffer a significant performance drop in real-worldonline industrial settings. A primary issue is their heavy reliance on OCRengines to extract local positional information within document pages, whichlimits the models' ability to capture global information and hinders theirgeneralizability, flexibility, and robustness. In this paper, we introduceGlobalDoc, a cross-modal transformer-based architecture pre-trained in aself-supervised manner using three novel pretext objective tasks. GlobalDocimproves the learning of richer semantic concepts by unifying language andvisual representations, resulting in more transferable models. For properevaluation, we also propose two novel document-level downstream VDU tasks,Few-Shot Document Image Classification (DIC) and Content-based Document ImageRetrieval (DIR), designed to simulate industrial scenarios more closely.Extensive experimentation has been conducted to demonstrate GlobalDoc'seffectiveness in practical settings.</description><author>Souhail Bakkali, Sanket Biswas, Zuheng Ming, Mickaël Coustaty, Marçal Rusiñol, Oriol Ramos Terrades, Josep Lladós</author><pubDate>Tue, 05 Nov 2024 15:18:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.05756v3</guid></item><item><title>Pre-trained Visual Dynamics Representations for Efficient Policy Learning</title><link>http://arxiv.org/abs/2411.03169v1</link><description>Pre-training for Reinforcement Learning (RL) with purely video data is avaluable yet challenging problem. Although in-the-wild videos are readilyavailable and inhere a vast amount of prior world knowledge, the absence ofaction annotations and the common domain gap with downstream tasks hinderutilizing videos for RL pre-training. To address the challenge of pre-trainingwith videos, we propose Pre-trained Visual Dynamics Representations (PVDR) tobridge the domain gap between videos and downstream tasks for efficient policylearning. By adopting video prediction as a pre-training task, we use aTransformer-based Conditional Variational Autoencoder (CVAE) to learn visualdynamics representations. The pre-trained visual dynamics representationscapture the visual dynamics prior knowledge in the videos. This abstract priorknowledge can be readily adapted to downstream tasks and aligned withexecutable actions through online adaptation. We conduct experiments on aseries of robotics visual control tasks and verify that PVDR is an effectiveform for pre-training with videos to promote policy learning.</description><author>Hao Luo, Bohan Zhou, Zongqing Lu</author><pubDate>Tue, 05 Nov 2024 15:18:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03169v1</guid></item><item><title>MicroAdam: Accurate Adaptive Optimization with Low Space Overhead and Provable Convergence</title><link>http://arxiv.org/abs/2405.15593v2</link><description>We propose a new variant of the Adam optimizer called MicroAdam thatspecifically minimizes memory overheads, while maintaining theoreticalconvergence guarantees. We achieve this by compressing the gradient informationbefore it is fed into the optimizer state, thereby reducing its memoryfootprint significantly. We control the resulting compression error via a novelinstance of the classical \emph{error feedback} mechanism from distributedoptimization in which *the error correction information is itself compressed*to allow for practical memory gains. We prove that the resulting approachmaintains theoretical convergence guarantees competitive to those of AMSGrad,while providing good practical performance. Specifically, we show thatMicroAdam can be implemented efficiently on GPUs: on both million-scale (BERT)and billion-scale (LLaMA) models, MicroAdam provides practical convergencecompetitive to that of the uncompressed Adam baseline, with lower memory usageand similar running time. Our code is available athttps://github.com/IST-DASLab/MicroAdam.</description><author>Ionut-Vlad Modoranu, Mher Safaryan, Grigory Malinovsky, Eldar Kurtic, Thomas Robert, Peter Richtarik, Dan Alistarh</author><pubDate>Tue, 05 Nov 2024 15:15:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15593v2</guid></item><item><title>Efficient Hamiltonian, structure and trace distance learning of Gaussian states</title><link>http://arxiv.org/abs/2411.03163v1</link><description>In this work, we initiate the study of Hamiltonian learning for positivetemperature bosonic Gaussian states, the quantum generalization of the widelystudied problem of learning Gaussian graphical models. We obtain efficientprotocols, both in sample and computational complexity, for the task ofinferring the parameters of their underlying quadratic Hamiltonian under theassumption of bounded temperature, squeezing, displacement and maximal degreeof the interaction graph. Our protocol only requires heterodyne measurements,which are often experimentally feasible, and has a sample complexity thatscales logarithmically with the number of modes. Furthermore, we show that itis possible to learn the underlying interaction graph in a similar setting andsample complexity. Taken together, our results put the status of the quantumHamiltonian learning problem for continuous variable systems in a much moreadvanced state when compared to spins, where state-of-the-art results areeither unavailable or quantitatively inferior to ours. In addition, we use ourtechniques to obtain the first results on learning Gaussian states in tracedistance with a quadratic scaling in precision and polynomial in the number ofmodes, albeit imposing certain restrictions on the Gaussian states. Our maintechnical innovations are several continuity bounds for the covariance andHamiltonian matrix of a Gaussian state, which are of independent interest,combined with what we call the local inversion technique. In essence, the localinversion technique allows us to reliably infer the Hamiltonian of a Gaussianstate by only estimating in parallel submatrices of the covariance matrix whosesize scales with the desired precision, but not the number of modes. This waywe bypass the need to obtain precise global estimates of the covariance matrix,controlling the sample complexity.</description><author>Marco Fanizza, Cambyse Rouzé, Daniel Stilck França</author><pubDate>Tue, 05 Nov 2024 15:07:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03163v1</guid></item><item><title>Multi-Agent Coordination via Multi-Level Communication</title><link>http://arxiv.org/abs/2209.12713v2</link><description>The partial observability and stochasticity in multi-agent settings can bemitigated by accessing more information about others via communication.However, the coordination problem still exists since agents cannot communicateactual actions with each other at the same time due to the circulardependencies. In this paper, we propose a novel multi-level communicationscheme, Sequential Communication (SeqComm). SeqComm treats agentsasynchronously (the upper-level agents make decisions before the lower-levelones) and has two communication phases. In the negotiation phase, agentsdetermine the priority of decision-making by communicating hidden states ofobservations and comparing the value of intention, obtained by modeling theenvironment dynamics. In the launching phase, the upper-level agents take thelead in making decisions and then communicate their actions with thelower-level agents. Theoretically, we prove the policies learned by SeqComm areguaranteed to improve monotonically and converge. Empirically, we show thatSeqComm outperforms existing methods in various cooperative multi-agent tasks.</description><author>Ziluo Ding, Zeyuan Liu, Zhirui Fang, Kefan Su, Liwen Zhu, Zongqing Lu</author><pubDate>Tue, 05 Nov 2024 15:05:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.12713v2</guid></item><item><title>A Machine Learning Approach for the Efficient Estimation of Ground-Level Air Temperature in Urban Areas</title><link>http://arxiv.org/abs/2411.03162v1</link><description>The increasingly populated cities of the 21st Century face the challenge ofbeing sustainable and resilient spaces for their inhabitants. However, climatechange, among other problems, makes these objectives difficult to achieve. TheUrban Heat Island (UHI) phenomenon that occurs in cities, increasing theirthermal stress, is one of the stumbling blocks to achieve a more sustainablecity. The ability to estimate temperatures with a high degree of accuracyallows for the identification of the highest priority areas in cities whereurban improvements need to be made to reduce thermal discomfort. In this workwe explore the usefulness of image-to-image deep neural networks (DNNs) forcorrelating spatial and meteorological variables of a urban area withstreet-level air temperature. The air temperature at street-level is estimatedboth spatially and temporally for a specific use case, and compared withexisting, well-established numerical models. Based on the obtained results,deep neural networks are confirmed to be faster and less computationallyexpensive alternative for ground-level air temperature compared to numericalmodels.</description><author>Iñigo Delgado-Enales, Joshua Lizundia-Loiola, Patricia Molina-Costa, Javier Del Ser</author><pubDate>Tue, 05 Nov 2024 15:05:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03162v1</guid></item><item><title>Privacy Risks of Speculative Decoding in Large Language Models</title><link>http://arxiv.org/abs/2411.01076v2</link><description>Speculative decoding in large language models (LLMs) accelerates tokengeneration by speculatively predicting multiple tokens cheaply and verifyingthem in parallel, and has been widely deployed. In this paper, we provide thefirst study demonstrating the privacy risks of speculative decoding. We observethat input-dependent patterns of correct and incorrect predictions can beleaked out to an adversary monitoring token generation times and packet sizes,leading to privacy breaches. By observing the pattern of correctly andincorrectly speculated tokens, we show that a malicious adversary canfingerprint queries and learn private user inputs with more than $90\%$accuracy across three different speculative decoding techniques - REST (almost$100\%$ accuracy), LADE (up to $92\%$ accuracy), and BiLD (up to $95\%$accuracy). We show that an adversary can also leak out confidentialintellectual property used to design these techniques, such as data fromdata-stores used for prediction (in REST) at a rate of more than $25$ tokensper second, or even hyper-parameters used for prediction (in LADE). We alsodiscuss mitigation strategies, such as aggregating tokens across multipleiterations and padding packets with additional bytes, to avoid such privacy orconfidentiality breaches.</description><author>Jiankun Wei, Abdulrahman Abdulrazzag, Tianchen Zhang, Adel Muursepp, Gururaj Saileshwar</author><pubDate>Tue, 05 Nov 2024 15:03:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.01076v2</guid></item><item><title>Skill-aware Mutual Information Optimisation for Generalisation in Reinforcement Learning</title><link>http://arxiv.org/abs/2406.04815v2</link><description>Meta-Reinforcement Learning (Meta-RL) agents can struggle to operate acrosstasks with varying environmental features that require different optimal skills(i.e., different modes of behaviour). Using context encoders based oncontrastive learning to enhance the generalisability of Meta-RL agents is nowwidely studied but faces challenges such as the requirement for a large samplesize, also referred to as the $\log$-$K$ curse. To improve RL generalisation todifferent tasks, we first introduce Skill-aware Mutual Information (SaMI), anoptimisation objective that aids in distinguishing context embeddings accordingto skills, thereby equipping RL agents with the ability to identify and executedifferent skills across tasks. We then propose Skill-aware Noise ContrastiveEstimation (SaNCE), a $K$-sample estimator used to optimise the SaMI objective.We provide a framework for equipping an RL agent with SaNCE in practice andconduct experimental validation on modified MuJoCo and Panda-gym benchmarks. Weempirically find that RL agents that learn by maximising SaMI achievesubstantially improved zero-shot generalisation to unseen tasks. Additionally,the context encoder trained with SaNCE demonstrates greater robustness to areduction in the number of available samples, thus possessing the potential toovercome the $\log$-$K$ curse.</description><author>Xuehui Yu, Mhairi Dunion, Xin Li, Stefano V. Albrecht</author><pubDate>Tue, 05 Nov 2024 15:02:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.04815v2</guid></item><item><title>Privacy of the last iterate in cyclically-sampled DP-SGD on nonconvex composite losses</title><link>http://arxiv.org/abs/2407.05237v2</link><description>Differentially-private stochastic gradient descent (DP-SGD) is a family ofiterative machine learning training algorithms that privatize gradients togenerate a sequence of differentially-private (DP) model parameters. It is alsothe standard tool used to train DP models in practice, even though most usersare only interested in protecting the privacy of the final model. Tight DPaccounting for the last iterate would minimize the amount of noise requiredwhile maintaining the same privacy guarantee and potentially increasing modelutility. However, last-iterate accounting is challenging, and existing worksrequire strong assumptions not satisfied by most implementations. These includeassuming (i) the global sensitivity constant is known - to avoid gradientclipping; (ii) the loss function is Lipschitz or convex; and (iii) inputbatches are sampled randomly. In this work, we forego any unrealistic assumptions and provide privacybounds for the most commonly used variant of DP-SGD, in which data is traversedcyclically, gradients are clipped, and only the last model is released. Morespecifically, we establish new Renyi differential privacy (RDP) upper boundsfor the last iterate under realistic assumptions of small stepsize andLipschitz smoothness of the loss function. Our general bounds also recover thespecial-case convex bounds when the weak-convexity parameter of the objectivefunction approaches zero and no clipping is performed. The approach itselfleverages optimal transport techniques for last iterate bounds, which is anontrivial task when the data is traversed cyclically and the loss function isnonconvex.</description><author>Weiwei Kong, Mónica Ribero</author><pubDate>Tue, 05 Nov 2024 15:00:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.05237v2</guid></item><item><title>Unleashing the power of novel conditional generative approaches for new materials discovery</title><link>http://arxiv.org/abs/2411.03156v1</link><description>For a very long time, computational approaches to the design of new materialshave relied on an iterative process of finding a candidate material andmodeling its properties. AI has played a crucial role in this regard, helpingto accelerate the discovery and optimization of crystal properties andstructures through advanced computational methodologies and data-drivenapproaches. To address the problem of new materials design and fasten theprocess of new materials search, we have applied latest generative approachesto the problem of crystal structure design, trying to solve the inverseproblem: by given properties generate a structure that satisfies them withoututilizing supercomputer powers. In our work we propose two approaches: 1)conditional structure modification: optimization of the stability of anarbitrary atomic configuration, using the energy difference between the mostenergetically favorable structure and all its less stable polymorphs and 2)conditional structure generation. We used a representation for materials thatincludes the following information: lattice, atom coordinates, atom types,chemical features, space group and formation energy of the structure. The lossfunction was optimized to take into account the periodic boundary conditions ofcrystal structures. We have applied Diffusion models approach, Flow matching,usual Autoencoder (AE) and compared the results of the models and approaches.As a metric for the study, physical PyMatGen matcher was employed: we comparetarget structure with generated one using default tolerances. So far, ourmodifier and generator produce structures with needed properties with accuracy41% and 82% respectively. To prove the offered methodology efficiency,inference have been carried out, resulting in several potentially newstructures with formation energy below the AFLOW-derived convex hulls.</description><author>Lev Novitskiy, Vladimir Lazarev, Mikhail Tiutiulnikov, Nikita Vakhrameev, Roman Eremin, Innokentiy Humonen, Andrey Kuznetsov, Denis Dimitrov, Semen Budennyy</author><pubDate>Tue, 05 Nov 2024 14:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03156v1</guid></item><item><title>Arithmetical Binary Decision Tree Traversals</title><link>http://arxiv.org/abs/2209.04825v7</link><description>This paper introduces a series of methodes for traversing binary decisiontrees using arithmetic operations. We present a suite of binary tree traversalalgorithms that leverage novel representation matrices to flatten the fullbinary tree structure and embed the aggregated internal node Boolean tests intoa single bitvector. Our approach, grounded in maximum inner product search,offers new insights into decision tree.</description><author>Jinxiong Zhang</author><pubDate>Tue, 05 Nov 2024 14:42:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.04825v7</guid></item><item><title>SynCo: Synthetic Hard Negatives in Contrastive Learning for Better Unsupervised Visual Representations</title><link>http://arxiv.org/abs/2410.02401v5</link><description>Contrastive learning has become a dominant approach in self-supervised visualrepresentation learning. Hard negatives - samples closely resembling the anchor- are key to enhancing learned representations' discriminative power. However,efficiently leveraging hard negatives remains challenging. We introduce SynCo(Synthetic Negatives in Contrastive learning), a novel approach that improvesmodel performance by generating synthetic hard negatives on the representationspace. Building on the MoCo framework, SynCo introduces six strategies forcreating diverse synthetic hard negatives on-the-fly with minimal computationaloverhead. SynCo achieves faster training and better representation learning,reaching 67.9% top-1 accuracy on ImageNet ILSVRC-2012 linear evaluation after200 pretraining epochs, surpassing MoCo's 67.5% using the same ResNet-50encoder. It also transfers more effectively to detection tasks: on PASCAL VOC,it outperforms both the supervised baseline and MoCo with 82.5% AP; on COCO, itsets new benchmarks with 40.9% AP for bounding box detection and 35.5% AP forinstance segmentation. Our synthetic hard negative generation approachsignificantly enhances visual representations learned through self-supervisedcontrastive learning. Code is available athttps://github.com/giakoumoglou/synco.</description><author>Nikolaos Giakoumoglou, Tania Stathaki</author><pubDate>Tue, 05 Nov 2024 14:38:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.02401v5</guid></item><item><title>Tencent Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation</title><link>http://arxiv.org/abs/2411.02293v2</link><description>While 3D generative models have greatly improved artists' workflows, theexisting diffusion models for 3D generation suffer from slow generation andpoor generalization. To address this issue, we propose a two-stage approachnamed Hunyuan3D-1.0 including a lite version and a standard version, that bothsupport text- and image-conditioned generation. In the first stage, we employ amulti-view diffusion model that efficiently generates multi-view RGB inapproximately 4 seconds. These multi-view images capture rich details of the 3Dasset from different viewpoints, relaxing the tasks from single-view tomulti-view reconstruction. In the second stage, we introduce a feed-forwardreconstruction model that rapidly and faithfully reconstructs the 3D assetgiven the generated multi-view images in approximately 7 seconds. Thereconstruction network learns to handle noises and in-consistency introduced bythe multi-view diffusion and leverages the available information from thecondition image to efficiently recover the 3D structure. Our framework involvesthe text-to-image model, i.e., Hunyuan-DiT, making it a unified framework tosupport both text- and image-conditioned 3D generation. Our standard versionhas 3x more parameters than our lite and other existing model. OurHunyuan3D-1.0 achieves an impressive balance between speed and quality,significantly reducing generation time while maintaining the quality anddiversity of the produced assets.</description><author>Xianghui Yang, Huiwen Shi, Bowen Zhang, Fan Yang, Jiacheng Wang, Hongxu Zhao, Xinhai Liu, Xinzhou Wang, Qingxiang Lin, Jiaao Yu, Lifu Wang, Zhuo Chen, Sicong Liu, Yuhong Liu, Yong Yang, Di Wang, Jie Jiang, Chunchao Guo</author><pubDate>Tue, 05 Nov 2024 14:33:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.02293v2</guid></item><item><title>On the Global Convergence of Risk-Averse Policy Gradient Methods with Expected Conditional Risk Measures</title><link>http://arxiv.org/abs/2301.10932v3</link><description>Risk-sensitive reinforcement learning (RL) has become a popular tool forcontrolling the risk of uncertain outcomes and ensuring reliable performance inhighly stochastic sequential decision-making problems. While Policy Gradient(PG) methods have been developed for risk-sensitive RL, it remains unclear ifthese methods enjoy the same global convergence guarantees as in therisk-neutral case\citep{mei2020global,agarwal2021theory,cen2022fast,bhandari2024global}. In thispaper, we consider a class of dynamic time-consistent risk measures, namedExpected Conditional Risk Measures (ECRMs), and derive PG and Natural PolicyGradient (NPG) updates for ECRMs-based RL problems. We provide globaloptimality {and iteration complexities} of the proposed algorithms under thefollowing four settings: (i) PG with constrained direct parameterization, (ii)PG with softmax parameterization and log barrier regularization, (iii) NPG withsoftmax parameterization and entropy regularization, and (iv) approximate NPGwith inexact policy evaluation. Furthermore, we test a risk-averse REINFORCEalgorithm \citep{williams1992simple} and a risk-averse NPG algorithm\citep{kakade2001natural} on a stochastic Cliffwalk environment to demonstratethe efficacy of our methods and the importance of risk control.</description><author>Xian Yu, Lei Ying</author><pubDate>Tue, 05 Nov 2024 14:31:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.10932v3</guid></item><item><title>Reinforcement Learning with Lie Group Orientations for Robotics</title><link>http://arxiv.org/abs/2409.11935v2</link><description>Handling orientations of robots and objects is a crucial aspect of manyapplications. Yet, ever so often, there is a lack of mathematical correctnesswhen dealing with orientations, especially in learning pipelines involving, forexample, artificial neural networks. In this paper, we investigatereinforcement learning with orientations and propose a simple modification ofthe network's input and output that adheres to the Lie group structure oforientations. As a result, we obtain an easy and efficient implementation thatis directly usable with existing learning libraries and achieves significantlybetter performance than other common orientation representations. We brieflyintroduce Lie theory specifically for orientations in robotics to motivate andoutline our approach. Subsequently, a thorough empirical evaluation ofdifferent combinations of orientation representations for states and actionsdemonstrates the superior performance of our proposed approach in differentscenarios, including: direct orientation control, end effector orientationcontrol, and pick-and-place tasks.</description><author>Martin Schuck, Jan Brüdigam, Sandra Hirche, Angela Schoellig</author><pubDate>Tue, 05 Nov 2024 14:23:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.11935v2</guid></item><item><title>Taming the Long Tail in Human Mobility Prediction</title><link>http://arxiv.org/abs/2410.14970v2</link><description>With the popularity of location-based services, human mobility predictionplays a key role in enhancing personalized navigation, optimizingrecommendation systems, and facilitating urban mobility and planning. Thisinvolves predicting a user's next POI (point-of-interest) visit using theirpast visit history. However, the uneven distribution of visitations over timeand space, namely the long-tail problem in spatial distribution, makes itdifficult for AI models to predict those POIs that are less visited by humans.In light of this issue, we propose the Long-Tail Adjusted Next POI Prediction(LoTNext) framework for mobility prediction, combining a Long-Tailed GraphAdjustment module to reduce the impact of the long-tailed nodes in the user-POIinteraction graph and a novel Long-Tailed Loss Adjustment module to adjust lossby logit score and sample weight adjustment strategy. Also, we employ theauxiliary prediction task to enhance generalization and accuracy. Ourexperiments with two real-world trajectory datasets demonstrate that LoTNextsignificantly surpasses existing state-of-the-art works. Our code is availableat https://github.com/Yukayo/LoTNext.</description><author>Xiaohang Xu, Renhe Jiang, Chuang Yang, Zipei Fan, Kaoru Sezaki</author><pubDate>Tue, 05 Nov 2024 14:21:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14970v2</guid></item><item><title>MA^2: A Self-Supervised and Motion Augmenting Autoencoder for Gait-Based Automatic Disease Detection</title><link>http://arxiv.org/abs/2411.03129v1</link><description>Ground reaction force (GRF) is the force exerted by the ground on a body incontact with it. GRF-based automatic disease detection (ADD) has become anemerging medical diagnosis method, which aims to learn and identify diseasepatterns corresponding to different gait pressures based on deep learningmethods. Although existing ADD methods can save doctors time in makingdiagnoses, training deep models still struggles with the cost caused by thelabeling engineering for a large number of gait diagnostic data for subjects.On the other hand, the accuracy of the deep model under the unified benchmarkGRF dataset and the generalization ability on scalable gait datasets need to befurther improved. To address these issues, we propose MA2, a GRF-basedself-supervised and motion augmenting auto-encoder, which models the ADD taskas an encoder-decoder paradigm. In the encoder, we introduce an embedding blockincluding the 3-layer 1D convolution for extracting the token and a maskgenerator to randomly mask out the sequence of tokens to maximize the model'spotential to capture high-level, discriminative, intrinsic representations.whereafter, the decoder utilizes this information to reconstruct the pixelsequence of the origin input and calculate the reconstruction loss to optimizethe network. Moreover, the backbone of an auto-encoder is multi-headself-attention that can consider the global information of the token from theinput, not just the local neighborhood. This allows the model to capturegeneralized contextual information. Extensive experiments demonstrate MA2 hasSOTA performance of 90.91% accuracy on 1% limited pathological GRF samples withlabels, and good generalization ability of 78.57% accuracy on scalableParkinson disease dataset.</description><author>Yiqun Liu, Ke Zhang, Yin Zhu</author><pubDate>Tue, 05 Nov 2024 14:21:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03129v1</guid></item><item><title>User Centric Semantic Communications</title><link>http://arxiv.org/abs/2411.03127v1</link><description>Current studies on semantic communications mainly focus on efficientlyextracting semantic information to reduce bandwidth usage between a transmitterand a user. Although significant process has been made in the semanticcommunications, a fundamental design problem is that the semantic informationis extracted based on certain criteria at the transmitter side along, withoutconsidering the user's actual requirements. As a result, critical informationthat is of primary concern to the user may be lost. In such cases, the semantictransmission becomes meaningless to the user, as all received information isirrelevant to the user's interests. To solve this problem, this paper presentsa user centric semantic communication system, where the user sends its requestfor the desired semantic information to the transmitter at the start of eachtransmission. Then, the transmitter extracts the required semantic informationaccordingly. A key challenge is how the transmitter can understand the user'srequests for semantic information and extract the required semantic informationin a reasonable and robust manner. We solve this challenge by designing awell-structured framework and leveraging off-the-shelf products, such as GPT-4,along with several specialized tools for detection and estimation. Evaluationresults demonstrate the feasibility and effectiveness of the proposed usercentric semantic communication system.</description><author>Xunze Liu, Yifei Sun, Zhaorui Wang, Lizhao You, Haoyuan Pan, Fangxin Wang, Shuguang Cui</author><pubDate>Tue, 05 Nov 2024 14:18:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03127v1</guid></item><item><title>Decision-focused predictions via pessimistic bilevel optimization: a computational study</title><link>http://arxiv.org/abs/2312.17640v4</link><description>Dealing with uncertainty in optimization parameters is an important andlongstanding challenge. Typically, uncertain parameters are predictedaccurately, and then a deterministic optimization problem is solved. However,the decisions produced by this so-called \emph{predict-then-optimize} procedurecan be highly sensitive to uncertain parameters. In this work, we contribute torecent efforts in producing \emph{decision-focused} predictions, i.e., to buildpredictive models that are constructed with the goal of minimizing a\emph{regret} measure on the decisions taken with them. We begin by formulatingthe exact expected regret minimization as a pessimistic bilevel optimizationmodel. Then, we establish NP-completeness of this problem, even in a heavilyrestricted case. Using duality arguments, we reformulate it as a non-convexquadratic optimization problem. Finally, we show various computationaltechniques to achieve tractability. We report extensive computational resultson shortest-path instances with uncertain cost vectors. Our results indicatethat our approach can improve training performance over the approach ofElmachtoub and Grigas (2022), a state-of-the-art method for decision-focusedlearning.</description><author>Víctor Bucarey, Sophia Calderón, Gonzalo Muñoz, Frederic Semet</author><pubDate>Tue, 05 Nov 2024 14:15:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17640v4</guid></item><item><title>A Framework for Real-Time Volcano-Seismic Event Recognition Based on Multi-Station Seismograms and Semantic Segmentation Models</title><link>http://arxiv.org/abs/2410.20595v3</link><description>In volcano monitoring, effective recognition of seismic events is essentialfor understanding volcanic activity and raising timely warning alerts.Traditional methods rely on manual analysis, which can be subjective andlabor-intensive. Furthermore, current automatic approaches often tackledetection and classification separately, mostly rely on single stationinformation and generally require tailored preprocessing and representations toperform predictions. These limitations often hinder their application toreal-time monitoring and utilization across different volcano conditions. Thisstudy introduces a novel approach that utilizes Semantic Segmentation models toautomate seismic event recognition by applying a straight forwardtransformation of multi-channel 1D signals into 2D representations, enablingtheir use as images. Our framework employs a data-driven, end-to-end designthat integrates multi-station seismic data with minimal preprocessing,performing both detection and classification simultaneously for five seismicevent classes. We evaluated four state-of-the-art segmentation models (UNet,UNet++, DeepLabV3+ and SwinUNet) on approximately 25.000 seismic eventsrecorded at four different Chilean volcanoes: Nevados del Chill\'an VolcanicComplex, Laguna del Maule, Villarrica and Puyehue-Cord\'on Caulle. Among thesemodels, the UNet architecture was identified as the most effective model,achieving mean F1 and Intersection over Union (IoU) scores of up to 0.91 and0.88, respectively, and demonstrating superior noise robustness and modelflexibility to unseen volcano datasets.</description><author>Camilo Espinosa-Curilem, Millaray Curilem, Daniel Basualto</author><pubDate>Tue, 05 Nov 2024 14:13:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20595v3</guid></item><item><title>Better, Not Just More: Data-Centric Machine Learning for Earth Observation</title><link>http://arxiv.org/abs/2312.05327v3</link><description>Recent developments and research in modern machine learning have led tosubstantial improvements in the geospatial field. Although numerous deeplearning architectures and models have been proposed, the majority of them havebeen solely developed on benchmark datasets that lack strong real-worldrelevance. Furthermore, the performance of many methods has already saturatedon these datasets. We argue that a shift from a model-centric view to acomplementary data-centric perspective is necessary for further improvements inaccuracy, generalization ability, and real impact on end-user applications.Furthermore, considering the entire machine learning cycle-from problemdefinition to model deployment with feedback-is crucial for enhancing machinelearning models that can be reliable in unforeseen situations. This workpresents a definition as well as a precise categorization and overview ofautomated data-centric learning approaches for geospatial data. It highlightsthe complementary role of data-centric learning with respect to model-centricin the larger machine learning deployment cycle. We review papers across theentire geospatial field and categorize them into different groups. A set ofrepresentative experiments shows concrete implementation examples. Theseexamples provide concrete steps to act on geospatial data with data-centricmachine learning approaches.</description><author>Ribana Roscher, Marc Rußwurm, Caroline Gevaert, Michael Kampffmeyer, Jefersson A. dos Santos, Maria Vakalopoulou, Ronny Hänsch, Stine Hansen, Keiller Nogueira, Jonathan Prexl, Devis Tuia</author><pubDate>Tue, 05 Nov 2024 14:12:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05327v3</guid></item><item><title>Investigating the Applicability of a Snapshot Computed Tomography Imaging Spectrometer for the Prediction of Brix and pH of Grapes</title><link>http://arxiv.org/abs/2411.03114v1</link><description>In this paper, a recently developed snapshot hyperspectral imaging (HSI)system based on Computed Tomography Imaging Spectroscopy (CTIS) is utilized todetermine Brix and pH values in Sheegene 20 table grapes through Partial LeastSquares Regression (PLSR) modeling. The performance of the CTIS system iscompared with that of a state-of-the-art line scan HSI system by imaging 100grapes across both platforms. Reference measurements of Brix and pH values areobtained directly using a refractometer and a pH meter, as these parameters areessential for assessing the quality of table and wine grapes. The findingsindicate that the spectra captured by the CTIS camera correlate well with thereference measurements, despite the system's narrower spectral range. The CTIScamera's advantages, including its lower cost, portability, and reducedsusceptibility to motion errors, highlight its potential for promising in-fieldapplications in grape quality assessment.</description><author>Mads Svanborg Peters, Mads Juul Ahlebæk, Mads Toudal Frandsen, Bjarke Jørgensen, Christian Hald Jessen, Andreas Krogh Carlsen, Wei-Chih Huang, René Lynge Eriksen</author><pubDate>Tue, 05 Nov 2024 14:03:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03114v1</guid></item><item><title>DFA-GNN: Forward Learning of Graph Neural Networks by Direct Feedback Alignment</title><link>http://arxiv.org/abs/2406.02040v2</link><description>Graph neural networks are recognized for their strong performance acrossvarious applications, with the backpropagation algorithm playing a central rolein the development of most GNN models. However, despite its effectiveness, BPhas limitations that challenge its biological plausibility and affect theefficiency, scalability and parallelism of training neural networks forgraph-based tasks. While several non-BP training algorithms, such as the directfeedback alignment, have been successfully applied to fully-connected andconvolutional network components for handling Euclidean data, directly adaptingthese non-BP frameworks to manage non-Euclidean graph data in GNN modelspresents significant challenges. These challenges primarily arise from theviolation of the i.i.d. assumption in graph data and the difficulty inaccessing prediction errors for all samples (nodes) within the graph. Toovercome these obstacles, in this paper we propose DFA-GNN, a novel forwardlearning framework tailored for GNNs with a case study of semi-supervisedlearning. The proposed method breaks the limitations of BP by using a dedicatedforward training mechanism. Specifically, DFA-GNN extends the principles of DFAto adapt to graph data and unique architecture of GNNs, which incorporates theinformation of graph topology into the feedback links to accommodate thenon-Euclidean characteristics of graph data. Additionally, for semi-supervisedgraph learning tasks, we developed a pseudo error generator that spreadsresidual errors from training data to create a pseudo error for each unlabelednode. These pseudo errors are then utilized to train GNNs using DFA. Extensiveexperiments on 10 public benchmarks reveal that our learning frameworkoutperforms not only previous non-BP methods but also the standard BP methods,and it exhibits excellent robustness against various types of noise andattacks.</description><author>Gongpei Zhao, Tao Wang, Congyan Lang, Yi Jin, Yidong Li, Haibin Ling</author><pubDate>Tue, 05 Nov 2024 14:00:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02040v2</guid></item><item><title>Robustly overfitting latents for flexible neural image compression</title><link>http://arxiv.org/abs/2401.17789v3</link><description>Neural image compression has made a great deal of progress. State-of-the-artmodels are based on variational autoencoders and are outperforming classicalmodels. Neural compression models learn to encode an image into a quantizedlatent representation that can be efficiently sent to the decoder, whichdecodes the quantized latent into a reconstructed image. While these modelshave proven successful in practice, they lead to sub-optimal results due toimperfect optimization and limitations in the encoder and decoder capacity.Recent work shows how to use stochastic Gumbel annealing (SGA) to refine thelatents of pre-trained neural image compression models. We extend this idea byintroducing SGA+, which contains three different methods that build upon SGA.We show how our method improves the overall compression performance in terms ofthe R-D trade-off, compared to its predecessors. Additionally, we show howrefinement of the latents with our best-performing method improves thecompression performance on both the Tecnick and CLIC dataset. Our method isdeployed for a pre-trained hyperprior and for a more flexible model. Further,we give a detailed analysis of our proposed methods and show that they are lesssensitive to hyperparameter choices. Finally, we show how each method can beextended to three- instead of two-class rounding.</description><author>Yura Perugachi-Diaz, Arwin Gansekoele, Sandjai Bhulai</author><pubDate>Tue, 05 Nov 2024 14:00:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17789v3</guid></item><item><title>OxonFair: A Flexible Toolkit for Algorithmic Fairness</title><link>http://arxiv.org/abs/2407.13710v2</link><description>We present OxonFair, a new open source toolkit for enforcing fairness inbinary classification. Compared to existing toolkits: (i) We support NLP andComputer Vision classification as well as standard tabular problems. (ii) Wesupport enforcing fairness on validation data, making us robust to a wide rangeof overfitting challenges. (iii) Our approach can optimize any measure based onTrue Positives, False Positive, False Negatives, and True Negatives. This makesit easily extensible and much more expressive than existing toolkits. Itsupports all 9 and all 10 of the decision-based group metrics of two popularreview articles. (iv) We jointly optimize a performance objective alongsidefairness constraints. This minimizes degradation while enforcing fairness, andeven improves the performance of inadequately tuned unfair baselines. OxonFairis compatible with standard ML toolkits, including sklearn, Autogluon, andPyTorch and is available at https://github.com/oxfordinternetinstitute/oxonfair</description><author>Eoin Delaney, Zihao Fu, Sandra Wachter, Brent Mittelstadt, Chris Russell</author><pubDate>Tue, 05 Nov 2024 13:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.13710v2</guid></item><item><title>Near-Optimal Dynamic Regret for Adversarial Linear Mixture MDPs</title><link>http://arxiv.org/abs/2411.03107v1</link><description>We study episodic linear mixture MDPs with the unknown transition andadversarial rewards under full-information feedback, employing dynamic regretas the performance measure. We start with in-depth analyses of the strengthsand limitations of the two most popular methods: occupancy-measure-based andpolicy-based methods. We observe that while the occupancy-measure-based methodis effective in addressing non-stationary environments, it encountersdifficulties with the unknown transition. In contrast, the policy-based methodcan deal with the unknown transition effectively but faces challenges inhandling non-stationary environments. Building on this, we propose a novelalgorithm that combines the benefits of both methods. Specifically, it employs(i) an occupancy-measure-based global optimization with a two-layer structureto handle non-stationary environments; and (ii) a policy-based variance-awarevalue-targeted regression to tackle the unknown transition. We bridge these twoparts by a novel conversion. Our algorithm enjoys an $\widetilde{\mathcal{O}}(d\sqrt{H^3 K} + \sqrt{HK(H + \bar{P}_K)})$ dynamic regret, where $d$ is thefeature dimension, $H$ is the episode length, $K$ is the number of episodes,$\bar{P}_K$ is the non-stationarity measure. We show it is minimax optimal upto logarithmic factors by establishing a matching lower bound. To the best ofour knowledge, this is the first work that achieves near-optimal dynamic regretfor adversarial linear mixture MDPs with the unknown transition without priorknowledge of the non-stationarity measure.</description><author>Long-Fei Li, Peng Zhao, Zhi-Hua Zhou</author><pubDate>Tue, 05 Nov 2024 13:55:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03107v1</guid></item><item><title>An Exponential Separation Between Quantum and Quantum-Inspired Classical Algorithms for Machine Learning</title><link>http://arxiv.org/abs/2411.02087v2</link><description>Achieving a provable exponential quantum speedup for an important machinelearning task has been a central research goal since the seminal HHL quantumalgorithm for solving linear systems and the subsequent quantum recommendersystems algorithm by Kerenidis and Prakash. These algorithms were initiallybelieved to be strong candidates for exponential speedups, but a lower boundruling out similar classical improvements remained absent. In breakthrough workby Tang, it was demonstrated that this lack of progress in classical lowerbounds was for good reasons. Concretely, she gave a classical counterpart ofthe quantum recommender systems algorithm, reducing the quantum advantage to amere polynomial. Her approach is quite general and was named quantum-inspiredclassical algorithms. Since then, almost all the initially exponential quantummachine learning speedups have been reduced to polynomial via newquantum-inspired classical algorithms. From the current state-of-affairs, it isunclear whether we can hope for exponential quantum speedups for any naturalmachine learning task. In this work, we present the first such provable exponential separationbetween quantum and quantum-inspired classical algorithms. We prove theseparation for the basic problem of solving a linear system when the inputmatrix is well-conditioned and has sparse rows and columns.</description><author>Allan Grønlund, Kasper Green Larsen</author><pubDate>Tue, 05 Nov 2024 13:52:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.02087v2</guid></item><item><title>Evaluating Machine Learning Models against Clinical Protocols for Enhanced Interpretability and Continuity of Care</title><link>http://arxiv.org/abs/2411.03105v1</link><description>In clinical practice, decision-making relies heavily on establishedprotocols, often formalised as rules. Concurrently, Machine Learning (ML)models, trained on clinical data, aspire to integrate into medicaldecision-making processes. However, despite the growing number of MLapplications, their adoption into clinical practice remains limited. Twocritical concerns arise, relevant to the notions of consistency and continuityof care: (a) accuracy - the ML model, albeit more accurate, might introduceerrors that would not have occurred by applying the protocol; (b)interpretability - ML models operating as black boxes might make predictionsbased on relationships that contradict established clinical knowledge. In thiscontext, the literature suggests using ML models integrating domain knowledgefor improved accuracy and interpretability. However, there is a lack ofappropriate metrics for comparing ML models with clinical rules in addressingthese challenges. Accordingly, in this article, we first propose metrics toassess the accuracy of ML models with respect to the established protocol.Secondly, we propose an approach to measure the distance of explanationsprovided by two rule sets, with the goal of comparing the explanationsimilarity between clinical rule-based systems and rules extracted from MLmodels. The approach is validated on the Pima Indians Diabetes dataset bytraining two neural networks - one exclusively on data, and the otherintegrating a clinical protocol. Our findings demonstrate that the integratedML model achieves comparable performance to that of a fully data-driven modelwhile exhibiting superior accuracy relative to the clinical protocol, ensuringenhanced continuity of care. Furthermore, we show that our integrated modelprovides explanations for predictions that align more closely with the clinicalprotocol compared to the data-driven model.</description><author>Christel Sirocchi, Muhammad Suffian, Federico Sabbatini, Alessandro Bogliolo, Sara Montagna</author><pubDate>Tue, 05 Nov 2024 13:50:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.03105v1</guid></item><item><title>Federated Unlearning: A Survey on Methods, Design Guidelines, and Evaluation Metrics</title><link>http://arxiv.org/abs/2401.05146v3</link><description>Federated learning (FL) enables collaborative training of a machine learning(ML) model across multiple parties, facilitating the preservation of users' andinstitutions' privacy by maintaining data stored locally. Instead ofcentralizing raw data, FL exchanges locally refined model parameters to build aglobal model incrementally. While FL is more compliant with emergingregulations such as the European General Data Protection Regulation (GDPR),ensuring the right to be forgotten in this context - allowing FL participantsto remove their data contributions from the learned model - remains unclear. Inaddition, it is recognized that malicious clients may inject backdoors into theglobal model through updates, e.g., to generate mispredictions on speciallycrafted data examples. Consequently, there is the need for mechanisms that canguarantee individuals the possibility to remove their data and erase maliciouscontributions even after aggregation, without compromising the already acquired"good" knowledge. This highlights the necessity for novel federated unlearning(FU) algorithms, which can efficiently remove specific clients' contributionswithout full model retraining. This article provides background concepts,empirical evidence, and practical guidelines to design/implement efficient FUschemes. This study includes a detailed analysis of the metrics for evaluatingunlearning in FL and presents an in-depth literature review categorizingstate-of-the-art FU contributions under a novel taxonomy. Finally, we outlinethe most relevant and still open technical challenges, by identifying the mostpromising research directions in the field.</description><author>Nicolò Romandini, Alessio Mora, Carlo Mazzocca, Rebecca Montanari, Paolo Bellavista</author><pubDate>Tue, 05 Nov 2024 13:47:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05146v3</guid></item></channel></rss>