<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 31 Jul 2023 06:00:47 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Quantum-noise-limited optical neural networks operating at a few quanta per activation</title><link>http://arxiv.org/abs/2307.15712v1</link><description>Analog physical neural networks, which hold promise for improved energyefficiency and speed compared to digital electronic neural networks, arenevertheless typically operated in a relatively high-power regime so that thesignal-to-noise ratio (SNR) is large (&gt;10). What happens if an analog system isinstead operated in an ultra-low-power regime, in which the behavior of thesystem becomes highly stochastic and the noise is no longer a smallperturbation on the signal? In this paper, we study this question in thesetting of optical neural networks operated in the limit where some layers useonly a single photon to cause a neuron activation. Neuron activations in thislimit are dominated by quantum noise from the fundamentally probabilisticnature of single-photon detection of weak optical signals. We show that it ispossible to train stochastic optical neural networks to perform deterministicimage-classification tasks with high accuracy in spite of the extremely highnoise (SNR ~ 1) by using a training procedure that directly models thestochastic behavior of photodetection. We experimentally demonstrated MNISTclassification with a test accuracy of 98% using an optical neural network witha hidden layer operating in the single-photon regime; the optical energy usedto perform the classification corresponds to 0.008 photons permultiply-accumulate (MAC) operation, which is equivalent to 0.003 attojoules ofoptical energy per MAC. Our experiment used &gt;40x fewer photons per inferencethan previous state-of-the-art low-optical-energy demonstrations, to achievethe same accuracy of &gt;90%. Our work shows that some extremely stochastic analogsystems, including those operating in the limit where quantum noise dominates,can nevertheless be used as layers in neural networks that deterministicallyperform classification tasks with high accuracy if they are appropriatelytrained.</description><author>Shi-Yuan Ma, Tianyu Wang, Jérémie Laydevant, Logan G. Wright, Peter L. McMahon</author><pubDate>Fri, 28 Jul 2023 18:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15712v1</guid></item><item><title>Semi-Supervised Object Detection in the Open World</title><link>http://arxiv.org/abs/2307.15710v1</link><description>Existing approaches for semi-supervised object detection assume a fixed setof classes present in training and unlabeled datasets, i.e., in-distribution(ID) data. The performance of these techniques significantly degrades whenthese techniques are deployed in the open-world, due to the fact that theunlabeled and test data may contain objects that were not seen during training,i.e., out-of-distribution (OOD) data. The two key questions that we explore inthis paper are: can we detect these OOD samples and if so, can we learn fromthem? With these considerations in mind, we propose the Open WorldSemi-supervised Detection framework (OWSSD) that effectively detects OOD dataalong with a semi-supervised learning pipeline that learns from both ID and OODdata. We introduce an ensemble based OOD detector consisting of lightweightauto-encoder networks trained only on ID data. Through extensive evalulation,we demonstrate that our method performs competitively against state-of-the-artOOD detection algorithms and also significantly boosts the semi-supervisedlearning performance in open-world scenarios.</description><author>Garvita Allabadi, Ana Lucic, Peter Pao-Huang, Yu-Xiong Wang, Vikram Adve</author><pubDate>Fri, 28 Jul 2023 18:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15710v1</guid></item><item><title>Uncertainty in Natural Language Generation: From Theory to Applications</title><link>http://arxiv.org/abs/2307.15703v1</link><description>Recent advances of powerful Language Models have allowed Natural LanguageGeneration (NLG) to emerge as an important technology that can not only performtraditional tasks like summarisation or translation, but also serve as anatural language interface to a variety of applications. As such, it is crucialthat NLG systems are trustworthy and reliable, for example by indicating whenthey are likely to be wrong; and supporting multiple views, backgrounds andwriting styles -- reflecting diverse human sub-populations. In this paper, weargue that a principled treatment of uncertainty can assist in creating systemsand evaluation protocols better aligned with these goals. We first present thefundamental theory, frameworks and vocabulary required to representuncertainty. We then characterise the main sources of uncertainty in NLG from alinguistic perspective, and propose a two-dimensional taxonomy that is moreinformative and faithful than the popular aleatoric/epistemic dichotomy.Finally, we move from theory to applications and highlight exciting researchdirections that exploit uncertainty to power decoding, controllable generation,self-assessment, selective answering, active learning and more.</description><author>Joris Baan, Nico Daheim, Evgenia Ilia, Dennis Ulmer, Haau-Sing Li, Raquel Fernández, Barbara Plank, Rico Sennrich, Chrysoula Zerva, Wilker Aziz</author><pubDate>Fri, 28 Jul 2023 18:51:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15703v1</guid></item><item><title>MeMOTR: Long-Term Memory-Augmented Transformer for Multi-Object Tracking</title><link>http://arxiv.org/abs/2307.15700v1</link><description>As a video task, Multi-Object Tracking (MOT) is expected to capture temporalinformation of targets effectively. Unfortunately, most existing methods onlyexplicitly exploit the object features between adjacent frames, while lackingthe capacity to model long-term temporal information. In this paper, we proposeMeMOTR, a long-term memory-augmented Transformer for multi-object tracking. Ourmethod is able to make the same object's track embedding more stable anddistinguishable by leveraging long-term memory injection with a customizedmemory-attention layer. This significantly improves the target associationability of our model. Experimental results on DanceTrack show that MeMOTRimpressively surpasses the state-of-the-art method by 7.9\% and 13.0\% on HOTAand AssA metrics, respectively. Furthermore, our model also outperforms otherTransformer-based methods on association performance on MOT17 and generalizeswell on BDD100K. Code is available at\href{https://github.com/MCG-NJU/MeMOTR}{https://github.com/MCG-NJU/MeMOTR}.</description><author>Ruopeng Gao, Limin Wang</author><pubDate>Fri, 28 Jul 2023 18:50:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15700v1</guid></item><item><title>SimDETR: Simplifying self-supervised pretraining for DETR</title><link>http://arxiv.org/abs/2307.15697v1</link><description>DETR-based object detectors have achieved remarkable performance but aresample-inefficient and exhibit slow convergence. Unsupervised pretraining hasbeen found to be helpful to alleviate these impediments, allowing training withlarge amounts of unlabeled data to improve the detector's performance. However,existing methods have their own limitations, like keeping the detector'sbackbone frozen in order to avoid performance degradation and utilizingpretraining objectives misaligned with the downstream task. To overcome theselimitations, we propose a simple pretraining framework for DETR-based detectorsthat consists of three simple yet key ingredients: (i) richer, semantics-basedinitial proposals derived from high-level feature maps, (ii) discriminativetraining using object pseudo-labels produced via clustering, (iii)self-training to take advantage of the improved object proposals learned by thedetector. We report two main findings: (1) Our pretraining outperforms priorDETR pretraining works on both the full and low data regimes by significantmargins. (2) We show we can pretrain DETR from scratch (including the backbone)directly on complex image datasets like COCO, paving the path for unsupervisedrepresentation learning directly using DETR.</description><author>Ioannis Maniadis Metaxas, Adrian Bulat, Ioannis Patras, Brais Martinez, Georgios Tzimiropoulos</author><pubDate>Fri, 28 Jul 2023 18:46:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15697v1</guid></item><item><title>Deep Neural Networks based Meta-Learning for Network Intrusion Detection</title><link>http://arxiv.org/abs/2302.09394v2</link><description>The digitization of different components of industry and inter-connectivityamong indigenous networks have increased the risk of network attacks. Designingan intrusion detection system to ensure security of the industrial ecosystem isdifficult as network traffic encompasses various attack types, including newand evolving ones with minor changes. The data used to construct a predictivemodel for computer networks has a skewed class distribution and limitedrepresentation of attack types, which differ from real network traffic. Theselimitations result in dataset shift, negatively impacting the machine learningmodels' predictive abilities and reducing the detection rate against novelattacks. To address the challenges, we propose a novel deep neural networkbased Meta-Learning framework; INformation FUsion and Stacking Ensemble(INFUSE) for network intrusion detection. First, a hybrid feature space iscreated by integrating decision and feature spaces. Five different classifiersare utilized to generate a pool of decision spaces. The feature space is thenenriched through a deep sparse autoencoder that learns the semanticrelationships between attacks. Finally, the deep Meta-Learner acts as anensemble combiner to analyze the hybrid feature space and make a finaldecision. Our evaluation on stringent benchmark datasets and comparison toexisting techniques showed the effectiveness of INFUSE with an F-Score of 0.91,Accuracy of 91.6%, and Recall of 0.94 on the Test+ dataset, and an F-Score of0.91, Accuracy of 85.6%, and Recall of 0.87 on the stringent Test-21 dataset.These promising results indicate the strong generalization capability and thepotential to detect network attacks.</description><author>Anabia Sohail, Bibi Ayisha, Irfan Hameed, Muhammad Mohsin Zafar, Hani Alquhayz, Asifullah Khan</author><pubDate>Fri, 28 Jul 2023 18:41:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.09394v2</guid></item><item><title>Universal Recurrent Event Memories for Streaming Data</title><link>http://arxiv.org/abs/2307.15694v1</link><description>In this paper, we propose a new event memory architecture (MemNet) forrecurrent neural networks, which is universal for different types of timeseries data such as scalar, multivariate or symbolic. Unlike other externalneural memory architectures, it stores key-value pairs, which separate theinformation for addressing and for content to improve the representation, as inthe digital archetype. Moreover, the key-value pairs also avoid the compromisebetween memory depth and resolution that applies to memories constructed by themodel state. One of the MemNet key characteristics is that it requires onlylinear adaptive mapping functions while implementing a nonlinear operation onthe input data. MemNet architecture can be applied without modifications toscalar time series, logic operators on strings, and also to natural languageprocessing, providing state-of-the-art results in all application domains suchas the chaotic time series, the symbolic operation tasks, and thequestion-answering tasks (bAbI). Finally, controlled by five linear layers,MemNet requires a much smaller number of training parameters than otherexternal memory networks as well as the transformer network. The spacecomplexity of MemNet equals a single self-attention layer. It greatly improvesthe efficiency of the attention mechanism and opens the door for IoTapplications.</description><author>Ran Dou, Jose Principe</author><pubDate>Fri, 28 Jul 2023 18:40:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15694v1</guid></item><item><title>PatchMixer: Rethinking network design to boost generalization for 3D point cloud understanding</title><link>http://arxiv.org/abs/2307.15692v1</link><description>The recent trend in deep learning methods for 3D point cloud understanding isto propose increasingly sophisticated architectures either to better capture 3Dgeometries or by introducing possibly undesired inductive biases. Moreover,prior works introducing novel architectures compared their performance on thesame domain, devoting less attention to their generalization to other domains.We argue that the ability of a model to transfer the learnt knowledge todifferent domains is an important feature that should be evaluated toexhaustively assess the quality of a deep network architecture. In this work wepropose PatchMixer, a simple yet effective architecture that extends the ideasbehind the recent MLP-Mixer paper to 3D point clouds. The novelties of ourapproach are the processing of local patches instead of the whole shape topromote robustness to partial point clouds, and the aggregation of patch-wisefeatures using an MLP as a simpler alternative to the graph convolutions or theattention mechanisms that are used in prior works. We evaluated our method onthe shape classification and part segmentation tasks, achieving superiorgeneralization performance compared to a selection of the most relevant deeparchitectures.</description><author>Davide Boscaini, Fabio Poiesi</author><pubDate>Fri, 28 Jul 2023 18:37:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15692v1</guid></item><item><title>ODTlearn: A Package for Learning Optimal Decision Trees for Prediction and Prescription</title><link>http://arxiv.org/abs/2307.15691v1</link><description>ODTLearn is an open-source Python package that provides methods for learningoptimal decision trees for high-stakes predictive and prescriptive tasks basedon the mixed-integer optimization (MIO) framework proposed in Aghaei et al.(2019) and several of its extensions. The current version of the packageprovides implementations for learning optimal classification trees, optimalfair classification trees, optimal classification trees robust to distributionshifts, and optimal prescriptive trees from observational data. We havedesigned the package to be easy to maintain and extend as new optimal decisiontree problem classes, reformulation strategies, and solution algorithms areintroduced. To this end, the package follows object-oriented design principlesand supports both commercial (Gurobi) and open source (COIN-OR branch and cut)solvers. The package documentation and an extensive user guide can be found athttps://d3m-research-group.github.io/odtlearn/. Additionally, users can viewthe package source code and submit feature requests and bug reports by visitinghttps://github.com/D3M-Research-Group/odtlearn.</description><author>Patrick Vossler, Sina Aghaei, Nathan Justin, Nathanael Jo, Andrés Gómez, Phebe Vayanos</author><pubDate>Fri, 28 Jul 2023 18:37:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15691v1</guid></item><item><title>Benchmarking Offline Reinforcement Learning on Real-Robot Hardware</title><link>http://arxiv.org/abs/2307.15690v1</link><description>Learning policies from previously recorded data is a promising direction forreal-world robotics tasks, as online learning is often infeasible. Dexterousmanipulation in particular remains an open problem in its general form. Thecombination of offline reinforcement learning with large diverse datasets,however, has the potential to lead to a breakthrough in this challenging domainanalogously to the rapid progress made in supervised learning in recent years.To coordinate the efforts of the research community toward tackling thisproblem, we propose a benchmark including: i) a large collection of data foroffline learning from a dexterous manipulation platform on two tasks, obtainedwith capable RL agents trained in simulation; ii) the option to execute learnedpolicies on a real-world robotic system and a simulation for efficientdebugging. We evaluate prominent open-sourced offline reinforcement learningalgorithms on the datasets and provide a reproducible experimental setup foroffline reinforcement learning on real systems.</description><author>Nico Gürtler, Sebastian Blaes, Pavel Kolev, Felix Widmaier, Manuel Wüthrich, Stefan Bauer, Bernhard Schölkopf, Georg Martius</author><pubDate>Fri, 28 Jul 2023 18:29:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15690v1</guid></item><item><title>A supervised hybrid quantum machine learning solution to the emergency escape routing problem</title><link>http://arxiv.org/abs/2307.15682v1</link><description>Managing the response to natural disasters effectively can considerablymitigate their devastating impact. This work explores the potential of usingsupervised hybrid quantum machine learning to optimize emergency evacuationplans for cars during natural disasters. The study focuses on earthquakeemergencies and models the problem as a dynamic computational graph where anearthquake damages an area of a city. The residents seek to evacuate the cityby reaching the exit points where traffic congestion occurs. The situation ismodeled as a shortest-path problem on an uncertain and dynamically evolvingmap. We propose a novel hybrid supervised learning approach and test it onhypothetical situations on a concrete city graph. This approach uses a novelquantum feature-wise linear modulation (FiLM) neural network parallel to aclassical FiLM network to imitate Dijkstra's node-wise shortest path algorithmon a deterministic dynamic graph. Adding the quantum neural network in parallelincreases the overall model's expressivity by splitting the dataset's harmonicand non-harmonic features between the quantum and classical components. Thehybrid supervised learning agent is trained on a dataset of Dijkstra's shortestpaths and can successfully learn the navigation task. The hybrid quantumnetwork improves over the purely classical supervised learning approach by 7%in accuracy. We show that the quantum part has a significant contribution of45.(3)% to the prediction and that the network could be executed on anion-based quantum computer. The results demonstrate the potential of supervisedhybrid quantum machine learning in improving emergency evacuation planningduring natural disasters.</description><author>Nathan Haboury, Mo Kordzanganeh, Sebastian Schmitt, Ayush Joshi, Igor Tokarev, Lukas Abdallah, Andrii Kurkin, Basil Kyriacou, Alexey Melnikov</author><pubDate>Fri, 28 Jul 2023 18:16:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15682v1</guid></item><item><title>Dynamic Analysis and an Eigen Initializer for Recurrent Neural Networks</title><link>http://arxiv.org/abs/2307.15679v1</link><description>In recurrent neural networks, learning long-term dependency is the maindifficulty due to the vanishing and exploding gradient problem. Manyresearchers are dedicated to solving this issue and they proposed manyalgorithms. Although these algorithms have achieved great success,understanding how the information decays remains an open problem. In thispaper, we study the dynamics of the hidden state in recurrent neural networks.We propose a new perspective to analyze the hidden state space based on aneigen decomposition of the weight matrix. We start the analysis by linear statespace model and explain the function of preserving information in activationfunctions. We provide an explanation for long-term dependency based on theeigen analysis. We also point out the different behavior of eigenvalues forregression tasks and classification tasks. From the observations onwell-trained recurrent neural networks, we proposed a new initialization methodfor recurrent neural networks, which improves consistently performance. It canbe applied to vanilla-RNN, LSTM, and GRU. We test on many datasets, such asTomita Grammars, pixel-by-pixel MNIST datasets, and machine translationdatasets (Multi30k). It outperforms the Xavier initializer and kaiminginitializer as well as other RNN-only initializers like IRNN and sp-RNN inseveral tasks.</description><author>Ran Dou, Jose Principe</author><pubDate>Fri, 28 Jul 2023 18:14:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15679v1</guid></item><item><title>Case Studies of Causal Discovery from IT Monitoring Time Series</title><link>http://arxiv.org/abs/2307.15678v1</link><description>Information technology (IT) systems are vital for modern businesses, handlingdata storage, communication, and process automation. Monitoring these systemsis crucial for their proper functioning and efficiency, as it allows collectingextensive observational time series data for analysis. The interest in causaldiscovery is growing in IT monitoring systems as knowing causal relationsbetween different components of the IT system helps in reducing downtime,enhancing system performance and identifying root causes of anomalies andincidents. It also allows proactive prediction of future issues throughhistorical data analysis. Despite its potential benefits, applying causaldiscovery algorithms on IT monitoring data poses challenges, due to thecomplexity of the data. For instance, IT monitoring data often containsmisaligned time series, sleeping time series, timestamp errors and missingvalues. This paper presents case studies on applying causal discoveryalgorithms to different IT monitoring datasets, highlighting benefits andongoing challenges.</description><author>Ali Aït-Bachir, Charles K. Assaad, Christophe de Bignicourt, Emilie Devijver, Simon Ferreira, Eric Gaussier, Hosein Mohanna, Lei Zan</author><pubDate>Fri, 28 Jul 2023 18:13:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15678v1</guid></item><item><title>Adversarial training for tabular data with attack propagation</title><link>http://arxiv.org/abs/2307.15677v1</link><description>Adversarial attacks are a major concern in security-centered applications,where malicious actors continuously try to mislead Machine Learning (ML) modelsinto wrongly classifying fraudulent activity as legitimate, whereas systemmaintainers try to stop them. Adversarially training ML models that are robustagainst such attacks can prevent business losses and reduce the work load ofsystem maintainers. In such applications data is often tabular and the spaceavailable for attackers to manipulate undergoes complex feature engineeringtransformations, to provide useful signals for model training, to a spaceattackers cannot access. Thus, we propose a new form of adversarial trainingwhere attacks are propagated between the two spaces in the training loop. Wethen test this method empirically on a real world dataset in the domain ofcredit card fraud detection. We show that our method can prevent about 30%performance drops under moderate attacks and is essential under very aggressiveattacks, with a trade-off loss in performance under no attacks smaller than 7%.</description><author>Tiago Leon Melo, João Bravo, Marco O. P. Sampaio, Paolo Romano, Hugo Ferreira, João Tiago Ascensão, Pedro Bizarro</author><pubDate>Fri, 28 Jul 2023 18:12:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15677v1</guid></item><item><title>Bayesian Time-Series Classifier for Decoding Simple Visual Stimuli from Intracranial Neural Activity</title><link>http://arxiv.org/abs/2307.15672v1</link><description>Understanding how external stimuli are encoded in distributed neural activityis of significant interest in clinical and basic neuroscience. To address thisneed, it is essential to develop analytical tools capable of handling limiteddata and the intrinsic stochasticity present in neural data. In this study, wepropose a straightforward Bayesian time series classifier (BTsC) model thattackles these challenges whilst maintaining a high level of interpretability.We demonstrate the classification capabilities of this approach by utilizingneural data to decode colors in a visual task. The model exhibits consistentand reliable average performance of 75.55% on 4 patients' dataset, improvingupon state-of-the-art machine learning techniques by about 3.0 percent. Inaddition to its high classification accuracy, the proposed BTsC model providesinterpretable results, making the technique a valuable tool to study neuralactivity in various tasks and categories. The proposed solution can be appliedto neural data recorded in various tasks, where there is a need forinterpretable results and accurate classification accuracy.</description><author>Navid Ziaei, Reza Saadatifard, Ali Yousefi, Behzad Nazari, Sydney S. Cash, Angelique C. Paulk</author><pubDate>Fri, 28 Jul 2023 18:04:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15672v1</guid></item><item><title>TrackAgent: 6D Object Tracking via Reinforcement Learning</title><link>http://arxiv.org/abs/2307.15671v1</link><description>Tracking an object's 6D pose, while either the object itself or the observingcamera is moving, is important for many robotics and augmented realityapplications. While exploiting temporal priors eases this problem,object-specific knowledge is required to recover when tracking is lost. Underthe tight time constraints of the tracking task, RGB(D)-based methods are oftenconceptionally complex or rely on heuristic motion models. In comparison, wepropose to simplify object tracking to a reinforced point cloud (depth only)alignment task. This allows us to train a streamlined approach from scratchwith limited amounts of sparse 3D point clouds, compared to the large datasetsof diverse RGBD sequences required in previous works. We incorporate temporalframe-to-frame registration with object-based recovery by frame-to-modelrefinement using a reinforcement learning (RL) agent that jointly solves forboth objectives. We also show that the RL agent's uncertainty and arendering-based mask propagation are effective reinitialization triggers.</description><author>Konstantin Röhrl, Dominik Bauer, Timothy Patten, Markus Vincze</author><pubDate>Fri, 28 Jul 2023 18:03:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15671v1</guid></item><item><title>CoRe Optimizer: An All-in-One Solution for Machine Learning</title><link>http://arxiv.org/abs/2307.15663v1</link><description>The optimization algorithm and its hyperparameters can significantly affectthe training speed and resulting model accuracy in machine learningapplications. The wish list for an ideal optimizer includes fast and smoothconvergence to low error, low computational demand, and general applicability.Our recently introduced continual resilient (CoRe) optimizer has shown superiorperformance compared to other state-of-the-art first-order gradient-basedoptimizers for training lifelong machine learning potentials. In this work weprovide an extensive performance comparison of the CoRe optimizer and nineother optimization algorithms including the Adam optimizer and resilientbackpropagation (RPROP) for diverse machine learning tasks. We analyze theinfluence of different hyperparameters and provide generally applicable values.The CoRe optimizer yields best or competitive performance in every investigatedapplication, while only one hyperparameter needs to be changed depending onmini-batch or batch learning.</description><author>Marco Eckhoff, Markus Reiher</author><pubDate>Fri, 28 Jul 2023 17:48:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15663v1</guid></item><item><title>Overview of Robust and Multilingual Automatic Evaluation Metrics\\for Open-Domain Dialogue Systems at DSTC 11 Track 4</title><link>http://arxiv.org/abs/2306.12794v2</link><description>The advent and fast development of neural networks have revolutionized theresearch on dialogue systems and subsequently have triggered various challengesregarding their automatic evaluation. Automatic evaluation of open-domaindialogue systems as an open challenge has been the center of the attention ofmany researchers. Despite the consistent efforts to improve automatic metrics'correlations with human evaluation, there have been very few attempts to assesstheir robustness over multiple domains and dimensions. Also, their focus ismainly on the English language. All of these challenges prompt the developmentof automatic evaluation metrics that are reliable in various domains,dimensions, and languages. This track in the 11th Dialogue System TechnologyChallenge (DSTC11) is part of the ongoing effort to promote robust andmultilingual automatic evaluation metrics. This article describes the datasetsand baselines provided to participants and discusses the submission and resultdetails of the two proposed subtasks.</description><author>Mario Rodríguez-Cantelar, Chen Zhang, Chengguang Tang, Ke Shi, Sarik Ghazarian, João Sedoc, Luis Fernando D'Haro, Alexander Rudnicky</author><pubDate>Fri, 28 Jul 2023 17:45:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.12794v2</guid></item><item><title>Self-Supervised Pre-training for 3D Point Clouds via View-Specific Point-to-Image Translation</title><link>http://arxiv.org/abs/2212.14197v3</link><description>The past few years have witnessed the great success and prevalence ofself-supervised representation learning within the language and 2D visioncommunities. However, such advancements have not been fully migrated to thefield of 3D point cloud learning. Different from existing pre-trainingparadigms designed for deep point cloud feature extractors that fall into thescope of generative modeling or contrastive learning, this paper proposes atranslative pre-training framework, namely PointVST, driven by a novelself-supervised pretext task of cross-modal translation from 3D point clouds totheir corresponding diverse forms of 2D rendered images. More specifically, webegin with deducing view-conditioned point-wise embeddings through theinsertion of the viewpoint indicator, and then adaptively aggregate aview-specific global codeword, which can be further fed into subsequent 2Dconvolutional translation heads for image generation. Extensive experimentalevaluations on various downstream task scenarios demonstrate that our PointVSTshows consistent and prominent performance superiority over currentstate-of-the-art approaches as well as satisfactory domain transfer capability.Our code will be publicly available at https://github.com/keeganhk/PointVST.</description><author>Qijian Zhang, Junhui Hou</author><pubDate>Fri, 28 Jul 2023 17:42:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.14197v3</guid></item><item><title>Adversarial Infrared Blocks: A Multi-view Black-box Attack to Thermal Infrared Detectors in Physical World</title><link>http://arxiv.org/abs/2304.10712v4</link><description>Infrared imaging systems have a vast array of potential applications inpedestrian detection and autonomous driving, and their safety performance is ofgreat concern. However, few studies have explored the safety of infraredimaging systems in real-world settings. Previous research has used physicalperturbations such as small bulbs and thermal "QR codes" to attack infraredimaging detectors, but such methods are highly visible and lack stealthiness.Other researchers have used hot and cold blocks to deceive infrared imagingdetectors, but this method is limited in its ability to execute attacks fromvarious angles. To address these shortcomings, we propose a novel physicalattack called adversarial infrared blocks (AdvIB). By optimizing the physicalparameters of the adversarial infrared blocks, this method can execute astealthy black-box attack on thermal imaging system from various angles. Weevaluate the proposed method based on its effectiveness, stealthiness, androbustness. Our physical tests show that the proposed method achieves a successrate of over 80% under most distance and angle conditions, validating itseffectiveness. For stealthiness, our method involves attaching the adversarialinfrared block to the inside of clothing, enhancing its stealthiness.Additionally, we test the proposed method on advanced detectors, andexperimental results demonstrate an average attack success rate of 51.2%,proving its robustness. Overall, our proposed AdvIB method offers a promisingavenue for conducting stealthy, effective and robust black-box attacks onthermal imaging system, with potential implications for real-world safety andsecurity applications.</description><author>Chengyin Hu, Weiwen Shi, Tingsong Jiang, Wen Yao, Ling Tian, Xiaoqian Chen</author><pubDate>Fri, 28 Jul 2023 17:37:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10712v4</guid></item><item><title>Graph Neural Networks and 3-Dimensional Topology</title><link>http://arxiv.org/abs/2305.05966v2</link><description>We test the efficiency of applying Geometric Deep Learning to the problems inlow-dimensional topology in a certain simple setting. Specifically, we considerthe class of 3-manifolds described by plumbing graphs and use Graph NeuralNetworks (GNN) for the problem of deciding whether a pair of graphs givehomeomorphic 3-manifolds. We use supervised learning to train a GNN thatprovides the answer to such a question with high accuracy. Moreover, weconsider reinforcement learning by a GNN to find a sequence of Neumann movesthat relates the pair of graphs if the answer is positive. The setting can beunderstood as a toy model of the problem of deciding whether a pair of Kirbydiagrams give diffeomorphic 3- or 4-manifolds.</description><author>Pavel Putrov, Song Jin Ri</author><pubDate>Fri, 28 Jul 2023 17:33:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05966v2</guid></item><item><title>Multi-layer Aggregation as a key to feature-based OOD detection</title><link>http://arxiv.org/abs/2307.15647v1</link><description>Deep Learning models are easily disturbed by variations in the input imagesthat were not observed during the training stage, resulting in unpredictablepredictions. Detecting such Out-of-Distribution (OOD) images is particularlycrucial in the context of medical image analysis, where the range of possibleabnormalities is extremely wide. Recently, a new category of methods hasemerged, based on the analysis of the intermediate features of a trained model.These methods can be divided into 2 groups: single-layer methods that considerthe feature map obtained at a fixed, carefully chosen layer, and multi-layermethods that consider the ensemble of the feature maps generated by the model.While promising, a proper comparison of these algorithms is still lacking. Inthis work, we compared various feature-based OOD detection methods on a largespectra of OOD (20 types), representing approximately 7800 3D MRIs. Ourexperiments shed the light on two phenomenons. First, multi-layer methodsconsistently outperform single-layer approaches, which tend to haveinconsistent behaviour depending on the type of anomaly. Second, the OODdetection performance highly depends on the architecture of the underlyingneural network.</description><author>Benjamin Lambert, Florence Forbes, Senan Doyle, Michel Dojat</author><pubDate>Fri, 28 Jul 2023 17:08:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15647v1</guid></item><item><title>Scale-aware Test-time Click Adaptation for Pulmonary Nodule and Mass Segmentation</title><link>http://arxiv.org/abs/2307.15645v1</link><description>Pulmonary nodules and masses are crucial imaging features in lung cancerscreening that require careful management in clinical diagnosis. Despite thesuccess of deep learning-based medical image segmentation, the robustperformance on various sizes of lesions of nodule and mass is stillchallenging. In this paper, we propose a multi-scale neural network withscale-aware test-time adaptation to address this challenge. Specifically, weintroduce an adaptive Scale-aware Test-time Click Adaptation method based oneffortlessly obtainable lesion clicks as test-time cues to enhance segmentationperformance, particularly for large lesions. The proposed method can beseamlessly integrated into existing networks. Extensive experiments on bothopen-source and in-house datasets consistently demonstrate the effectiveness ofthe proposed method over some CNN and Transformer-based segmentation methods.Our code is available at https://github.com/SplinterLi/SaTTCA</description><author>Zhihao Li, Jiancheng Yang, Yongchao Xu, Li Zhang, Wenhui Dong, Bo Du</author><pubDate>Fri, 28 Jul 2023 17:04:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15645v1</guid></item><item><title>Scaling Data Generation in Vision-and-Language Navigation</title><link>http://arxiv.org/abs/2307.15644v1</link><description>Recent research in language-guided visual navigation has demonstrated asignificant demand for the diversity of traversable environments and thequantity of supervision for training generalizable agents. To tackle the commondata scarcity issue in existing vision-and-language navigation datasets, wepropose an effective paradigm for generating large-scale data for learning,which applies 1200+ photo-realistic environments from HM3D and Gibson datasetsand synthesizes 4.9 million instruction trajectory pairs using fully-accessibleresources on the web. Importantly, we investigate the influence of eachcomponent in this paradigm on the agent's performance and study how toadequately apply the augmented data to pre-train and fine-tune an agent. Thanksto our large-scale dataset, the performance of an existing agent can be pushedup (+11% absolute with regard to previous SoTA) to a significantly new best of80% single-run success rate on the R2R test split by simple imitation learning.The long-lasting generalization gap between navigating in seen and unseenenvironments is also reduced to less than 1% (versus 8% in the previous bestmethod). Moreover, our paradigm also facilitates different models to achievenew state-of-the-art navigation results on CVDN, REVERIE, and R2R in continuousenvironments.</description><author>Zun Wang, Jialu Li, Yicong Hong, Yi Wang, Qi Wu, Mohit Bansal, Stephen Gould, Hao Tan, Yu Qiao</author><pubDate>Fri, 28 Jul 2023 17:03:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15644v1</guid></item><item><title>CLIP Brings Better Features to Visual Aesthetics Learners</title><link>http://arxiv.org/abs/2307.15640v1</link><description>The success of pre-training approaches on a variety of downstream tasks hasrevitalized the field of computer vision. Image aesthetics assessment (IAA) isone of the ideal application scenarios for such methods due to subjective andexpensive labeling procedure. In this work, an unified and flexible two-phase\textbf{C}LIP-based \textbf{S}emi-supervised \textbf{K}nowledge\textbf{D}istillation paradigm is proposed, namely \textbf{\textit{CSKD}}.Specifically, we first integrate and leverage a multi-source unlabeled datasetto align rich features between a given visual encoder and an off-the-shelf CLIPimage encoder via feature alignment loss. Notably, the given visual encoder isnot limited by size or structure and, once well-trained, it can seamlesslyserve as a better visual aesthetic learner for both student and teacher. In thesecond phase, the unlabeled data is also utilized in semi-supervised IAAlearning to further boost student model performance when applied inlatency-sensitive production scenarios. By analyzing the attention distance andentropy before and after feature alignment, we notice an alleviation of featurecollapse issue, which in turn showcase the necessity of feature alignmentinstead of training directly based on CLIP image encoder. Extensive experimentsindicate the superiority of CSKD, which achieves state-of-the-art performanceon multiple widely used IAA benchmarks.</description><author>Liwu Xu, Jinjin Xu, Yuzhe Yang, Yijie Huang, Yanchun Xie, Yaqian Li</author><pubDate>Fri, 28 Jul 2023 17:00:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15640v1</guid></item><item><title>TriadNet: Sampling-free predictive intervals for lesional volume in 3D brain MR images</title><link>http://arxiv.org/abs/2307.15638v1</link><description>The volume of a brain lesion (e.g. infarct or tumor) is a powerful indicatorof patient prognosis and can be used to guide the therapeutic strategy.Lesional volume estimation is usually performed by segmentation with deepconvolutional neural networks (CNN), currently the state-of-the-art approach.However, to date, few work has been done to equip volume segmentation toolswith adequate quantitative predictive intervals, which can hinder theirusefulness and acceptation in clinical practice. In this work, we proposeTriadNet, a segmentation approach relying on a multi-head CNN architecture,which provides both the lesion volumes and the associated predictive intervalssimultaneously, in less than a second. We demonstrate its superiority overother solutions on BraTS 2021, a large-scale MRI glioblastoma image database.</description><author>Benjamin Lambert, Florence Forbes, Senan Doyle, Michel Dojat</author><pubDate>Fri, 28 Jul 2023 16:56:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15638v1</guid></item><item><title>Multi-modal Machine Learning in Engineering Design: A Review and Future Directions</title><link>http://arxiv.org/abs/2302.10909v2</link><description>In the rapidly advancing field of multi-modal machine learning (MMML), theconvergence of multiple data modalities has the potential to reshape variousapplications. This paper presents a comprehensive overview of the currentstate, advancements, and challenges of MMML within the sphere of engineeringdesign. The review begins with a deep dive into five fundamental concepts ofMMML:multi-modal information representation, fusion, alignment, translation,and co-learning. Following this, we explore the cutting-edge applications ofMMML, placing a particular emphasis on tasks pertinent to engineering design,such as cross-modal synthesis, multi-modal prediction, and cross-modalinformation retrieval. Through this comprehensive overview, we highlight theinherent challenges in adopting MMML in engineering design, and profferpotential directions for future research. To spur on the continued evolution ofMMML in engineering design, we advocate for concentrated efforts to constructextensive multi-modal design datasets, develop effective data-driven MMMLtechniques tailored to design applications, and enhance the scalability andinterpretability of MMML models. MMML models, as the next generation ofintelligent design tools, hold a promising future to impact how products aredesigned.</description><author>Binyang Song, Rui Zhou, Faez Ahmed</author><pubDate>Fri, 28 Jul 2023 16:52:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10909v2</guid></item><item><title>EmoSet: A Large-scale Visual Emotion Dataset with Rich Attributes</title><link>http://arxiv.org/abs/2307.07961v2</link><description>Visual Emotion Analysis (VEA) aims at predicting people's emotional responsesto visual stimuli. This is a promising, yet challenging, task in affectivecomputing, which has drawn increasing attention in recent years. Most of theexisting work in this area focuses on feature design, while little attentionhas been paid to dataset construction. In this work, we introduce EmoSet, thefirst large-scale visual emotion dataset annotated with rich attributes, whichis superior to existing datasets in four aspects: scale, annotation richness,diversity, and data balance. EmoSet comprises 3.3 million images in total, with118,102 of these images carefully labeled by human annotators, making it fivetimes larger than the largest existing dataset. EmoSet includes images fromsocial networks, as well as artistic images, and it is well balanced betweendifferent emotion categories. Motivated by psychological studies, in additionto emotion category, each image is also annotated with a set of describableemotion attributes: brightness, colorfulness, scene type, object class, facialexpression, and human action, which can help understand visual emotions in aprecise and interpretable way. The relevance of these emotion attributes isvalidated by analyzing the correlations between them and visual emotion, aswell as by designing an attribute module to help visual emotion recognition. Webelieve EmoSet will bring some key insights and encourage further research invisual emotion analysis and understanding. Project page:https://vcc.tech/EmoSet.</description><author>Jingyuan Yang, Qirui Huang, Tingting Ding, Dani Lischinski, Daniel Cohen-Or, Hui Huang</author><pubDate>Fri, 28 Jul 2023 16:38:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.07961v2</guid></item><item><title>Proximal nested sampling with data-driven priors for physical scientists</title><link>http://arxiv.org/abs/2307.00056v2</link><description>Proximal nested sampling was introduced recently to open up Bayesian modelselection for high-dimensional problems such as computational imaging. Theframework is suitable for models with a log-convex likelihood, which areubiquitous in the imaging sciences. The purpose of this article is two-fold.First, we review proximal nested sampling in a pedagogical manner in an attemptto elucidate the framework for physical scientists. Second, we show howproximal nested sampling can be extended in an empirical Bayes setting tosupport data-driven priors, such as deep neural networks learned from trainingdata.</description><author>Jason D. McEwen, Tobías I. Liaudat, Matthew A. Price, Xiaohao Cai, Marcelo Pereyra</author><pubDate>Fri, 28 Jul 2023 16:32:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00056v2</guid></item><item><title>A Comparative Analysis of Machine Learning Methods for Lane Change Intention Recognition Using Vehicle Trajectory Data</title><link>http://arxiv.org/abs/2307.15625v1</link><description>Accurately detecting and predicting lane change (LC)processes can helpautonomous vehicles better understand their surrounding environment, recognizepotential safety hazards, and improve traffic safety. This paper focuses on LCprocesses and compares different machine learning methods' performance torecognize LC intention from high-dimensionality time series data. To validatethe performance of the proposed models, a total number of 1023 vehicletrajectories is extracted from the CitySim dataset. For LC intentionrecognition issues, the results indicate that with ninety-eight percent ofclassification accuracy, ensemble methods reduce the impact of Type II and TypeIII classification errors. Without sacrificing recognition accuracy, theLightGBM demonstrates a sixfold improvement in model training efficiency thanthe XGBoost algorithm.</description><author>Renteng Yuan</author><pubDate>Fri, 28 Jul 2023 16:32:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15625v1</guid></item><item><title>Shrink-Perturb Improves Architecture Mixing during Population Based Training for Neural Architecture Search</title><link>http://arxiv.org/abs/2307.15621v1</link><description>In this work, we show that simultaneously training and mixing neural networksis a promising way to conduct Neural Architecture Search (NAS). Forhyperparameter optimization, reusing the partially trained weights allows forefficient search, as was previously demonstrated by the Population BasedTraining (PBT) algorithm. We propose PBT-NAS, an adaptation of PBT to NAS wherearchitectures are improved during training by replacing poorly-performingnetworks in a population with the result of mixing well-performing ones andinheriting the weights using the shrink-perturb technique. After PBT-NASterminates, the created networks can be directly used without retraining.PBT-NAS is highly parallelizable and effective: on challenging tasks (imagegeneration and reinforcement learning) PBT-NAS achieves superior performancecompared to baselines (random search and mutation-based PBT).</description><author>Alexander Chebykin, Arkadiy Dushatskiy, Tanja Alderliesten, Peter A. N. Bosman</author><pubDate>Fri, 28 Jul 2023 16:29:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15621v1</guid></item><item><title>A Survey on Deep Learning in Medical Image Registration: New Technologies, Uncertainty, Evaluation Metrics, and Beyond</title><link>http://arxiv.org/abs/2307.15615v1</link><description>Over the past decade, deep learning technologies have greatly advanced thefield of medical image registration. The initial developments, such asResNet-based and U-Net-based networks, laid the groundwork for deeplearning-driven image registration. Subsequent progress has been made invarious aspects of deep learning-based registration, including similaritymeasures, deformation regularizations, and uncertainty estimation. Theseadvancements have not only enriched the field of deformable image registrationbut have also facilitated its application in a wide range of tasks, includingatlas construction, multi-atlas segmentation, motion estimation, and 2D-3Dregistration. In this paper, we present a comprehensive overview of the mostrecent advancements in deep learning-based image registration. We begin with aconcise introduction to the core concepts of deep learning-based imageregistration. Then, we delve into innovative network architectures, lossfunctions specific to registration, and methods for estimating registrationuncertainty. Additionally, this paper explores appropriate evaluation metricsfor assessing the performance of deep learning models in registration tasks.Finally, we highlight the practical applications of these novel techniques inmedical imaging and discuss the future prospects of deep learning-based imageregistration.</description><author>Junyu Chen, Yihao Liu, Shuwen Wei, Zhangxing Bian, Shalini Subramanian, Aaron Carass, Jerry L. Prince, Yong Du</author><pubDate>Fri, 28 Jul 2023 16:22:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15615v1</guid></item><item><title>CN-Celeb-AV: A Multi-Genre Audio-Visual Dataset for Person Recognition</title><link>http://arxiv.org/abs/2305.16049v2</link><description>Audio-visual person recognition (AVPR) has received extensive attention.However, most datasets used for AVPR research so far are collected inconstrained environments, and thus cannot reflect the true performance of AVPRsystems in real-world scenarios. To meet the request for research on AVPR inunconstrained conditions, this paper presents a multi-genre AVPR datasetcollected `in the wild', named CN-Celeb-AV. This dataset contains more than419k video segments from 1,136 persons from public media. In particular, we putmore emphasis on two real-world complexities: (1) data in multiple genres; (2)segments with partial information. A comprehensive study was conducted tocompare CN-Celeb-AV with two popular public AVPR benchmark datasets, and theresults demonstrated that CN-Celeb-AV is more in line with real-world scenariosand can be regarded as a new benchmark dataset for AVPR research. The datasetalso involves a development set that can be used to boost the performance ofAVPR systems in real-life situations. The dataset is free for researchers andcan be downloaded from http://cnceleb.org/.</description><author>Lantian Li, Xiaolou Li, Haoyu Jiang, Chen Chen, Ruihai Hou, Dong Wang</author><pubDate>Fri, 28 Jul 2023 16:13:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16049v2</guid></item><item><title>Integrated Digital Reconstruction of Welded Components: Supporting Improved Fatigue Life Prediction</title><link>http://arxiv.org/abs/2307.15604v1</link><description>In the design of offshore jacket foundations, fatigue life is crucial.Post-weld treatment has been proposed to enhance the fatigue performance ofwelded joints, where particularly high-frequency mechanical impact (HFMI)treatment has been shown to improve fatigue performance significantly.Automated HFMI treatment has improved quality assurance and can lead tocost-effective design when combined with accurate fatigue life prediction.However, the finite element method (FEM), commonly used for predicting fatiguelife in complex or multi-axial joints, relies on a basic CAD depiction of theweld, failing to consider the actual weld geometry and defects. Including theactual weld geometry in the FE model improves fatigue life prediction andpossible crack location prediction but requires a digital reconstruction of theweld. Current digital reconstruction methods are time-consuming or requirespecialised scanning equipment and potential component relocation. The proposedframework instead uses an industrial manipulator combined with a line scannerto integrate digital reconstruction as part of the automated HFMI treatmentsetup. This approach applies standard image processing, simple filteringtechniques, and non-linear optimisation for aligning and merging overlappingscans. A screened Poisson surface reconstruction finalises the 3D model tocreate a meshed surface. The outcome is a generic, cost-effective, flexible,and rapid method that enables generic digital reconstruction of welded parts,aiding in component design, overall quality assurance, and documentation of theHFMI treatment.</description><author>Anders Faarbæk Mikkelstrup, Morten Kristiansen</author><pubDate>Fri, 28 Jul 2023 16:04:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15604v1</guid></item><item><title>Robust Distortion-free Watermarks for Language Models</title><link>http://arxiv.org/abs/2307.15593v1</link><description>We propose a methodology for planting watermarks in text from anautoregressive language model that are robust to perturbations without changingthe distribution over text up to a certain maximum generation budget. Wegenerate watermarked text by mapping a sequence of random numbers -- which wecompute using a randomized watermark key -- to a sample from the languagemodel. To detect watermarked text, any party who knows the key can align thetext to the random number sequence. We instantiate our watermark methodologywith two sampling schemes: inverse transform sampling and exponential minimumsampling. We apply these watermarks to three language models -- OPT-1.3B,LLaMA-7B and Alpaca-7B -- to experimentally validate their statistical powerand robustness to various paraphrasing attacks. Notably, for both the OPT-1.3Band LLaMA-7B models, we find we can reliably detect watermarked text ($p \leq0.01$) from $35$ tokens even after corrupting between $40$-$50$\% of the tokensvia random edits (i.e., substitutions, insertions or deletions). For theAlpaca-7B model, we conduct a case study on the feasibility of watermarkingresponses to typical user instructions. Due to the lower entropy of theresponses, detection is more difficult: around $25\%$ of the responses -- whosemedian length is around $100$ tokens -- are detectable with $p \leq 0.01$, andthe watermark is also less robust to certain automated paraphrasing attacks weimplement.</description><author>Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, Percy Liang</author><pubDate>Fri, 28 Jul 2023 15:52:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15593v1</guid></item><item><title>Matching Patients to Clinical Trials with Large Language Models</title><link>http://arxiv.org/abs/2307.15051v2</link><description>Clinical trials are vital in advancing drug development and evidence-basedmedicine, but their success is often hindered by challenges in patientrecruitment. In this work, we investigate the potential of large languagemodels (LLMs) to assist individual patients and referral physicians inidentifying suitable clinical trials from an extensive selection. Specifically,we introduce TrialGPT, a novel architecture employing LLMs to predictcriterion-level eligibility with detailed explanations, which are thenaggregated for ranking and excluding candidate clinical trials based onfree-text patient notes. We evaluate TrialGPT on three publicly availablecohorts of 184 patients and 18,238 annotated clinical trials. The experimentalresults demonstrate several key findings: First, TrialGPT achieves highcriterion-level prediction accuracy with faithful explanations. Second, theaggregated trial-level TrialGPT scores are highly correlated with experteligibility annotations. Third, these scores prove effective in rankingclinical trials and exclude ineligible candidates. Our error analysis suggeststhat current LLMs still make some mistakes due to limited medical knowledge anddomain-specific context understanding. Nonetheless, we believe the explanatorycapabilities of LLMs are highly valuable. Future research is warranted on howsuch AI assistants can be integrated into the routine trial matching workflowin real-world settings to improve its efficiency.</description><author>Qiao Jin, Zifeng Wang, Charalampos S. Floudas, Jimeng Sun, Zhiyong Lu</author><pubDate>Fri, 28 Jul 2023 15:45:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15051v2</guid></item><item><title>OAFuser: Towards Omni-Aperture Fusion for Light Field Semantic Segmentation of Road Scenes</title><link>http://arxiv.org/abs/2307.15588v1</link><description>Light field cameras can provide rich angular and spatial information toenhance image semantic segmentation for scene understanding in the field ofautonomous driving. However, the extensive angular information of light fieldcameras contains a large amount of redundant data, which is overwhelming forthe limited hardware resource of intelligent vehicles. Besides, inappropriatecompression leads to information corruption and data loss. To excavaterepresentative information, we propose an Omni-Aperture Fusion model (OAFuser),which leverages dense context from the central view and discovers the angularinformation from sub-aperture images to generate a semantically-consistentresult. To avoid feature loss during network propagation and simultaneouslystreamline the redundant information from the light field camera, we present asimple yet very effective Sub-Aperture Fusion Module (SAFM) to embedsub-aperture images into angular features without any additional memory cost.Furthermore, to address the mismatched spatial information across viewpoints,we present Center Angular Rectification Module (CARM) realized featureresorting and prevent feature occlusion caused by asymmetric information. Ourproposed OAFuser achieves state-of-the-art performance on the UrbanLF-Real and-Syn datasets and sets a new record of 84.93% in mIoU on the UrbanLF-RealExtended dataset, with a gain of +4.53%. The source code of OAFuser will bemade publicly available at https://github.com/FeiBryantkit/OAFuser.</description><author>Fei Teng, Jiaming Zhang, Kunyu Peng, Kailun Yang, Yaonan Wang, Rainer Stiefelhagen</author><pubDate>Fri, 28 Jul 2023 15:43:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15588v1</guid></item><item><title>When to generate hedges in peer-tutoring interactions</title><link>http://arxiv.org/abs/2307.15582v1</link><description>This paper explores the application of machine learning techniques to predictwhere hedging occurs in peer-tutoring interactions. The study uses anaturalistic face-to-face dataset annotated for natural language turns,conversational strategies, tutoring strategies, and nonverbal behaviours. Theseelements are processed into a vector representation of the previous turns,which serves as input to several machine learning models. Results show thatembedding layers, that capture the semantic information of the previous turns,significantly improves the model's performance. Additionally, the studyprovides insights into the importance of various features, such asinterpersonal rapport and nonverbal behaviours, in predicting hedges by usingShapley values for feature explanation. We discover that the eye gaze of boththe tutor and the tutee has a significant impact on hedge prediction. Wefurther validate this observation through a follow-up ablation study.</description><author>Alafate Abulimiti, Chloé Clavel, Justine Cassell</author><pubDate>Fri, 28 Jul 2023 15:29:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15582v1</guid></item><item><title>Embrace Limited and Imperfect Training Datasets: Opportunities and Challenges in Plant Disease Recognition Using Deep Learning</title><link>http://arxiv.org/abs/2305.11533v2</link><description>Recent advancements in deep learning have brought significant improvements toplant disease recognition. However, achieving satisfactory performance oftenrequires high-quality training datasets, which are challenging and expensive tocollect. Consequently, the practical application of current deep learning-basedmethods in real-world scenarios is hindered by the scarcity of high-qualitydatasets. In this paper, we argue that embracing poor datasets is viable andaim to explicitly define the challenges associated with using these datasets.To delve into this topic, we analyze the characteristics of high-qualitydatasets, namely large-scale images and desired annotation, and contrast themwith the \emph{limited} and \emph{imperfect} nature of poor datasets.Challenges arise when the training datasets deviate from these characteristics.To provide a comprehensive understanding, we propose a novel and informativetaxonomy that categorizes these challenges. Furthermore, we offer a briefoverview of existing studies and approaches that address these challenges. Webelieve that our paper sheds light on the importance of embracing poordatasets, enhances the understanding of the associated challenges, andcontributes to the ambitious objective of deploying deep learning in real-worldapplications. To facilitate the progress, we finally describe severaloutstanding questions and point out potential future directions. Although ourprimary focus is on plant disease recognition, we emphasize that the principlesof embracing and analyzing poor datasets are applicable to a wider range ofdomains, including agriculture.</description><author>Mingle Xu, Hyongsuk Kim, Jucheng Yang, Alvaro Fuentes, Yao Meng, Sook Yoon, Taehyun Kim, Dong Sun Park</author><pubDate>Fri, 28 Jul 2023 15:29:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11533v2</guid></item><item><title>Fairness-aware Online Price Discrimination with Nonparametric Demand Models</title><link>http://arxiv.org/abs/2111.08221v2</link><description>Price discrimination, which refers to the strategy of setting differentprices for different customer groups, has been widely used in online retailing.Although it helps boost the collected revenue for online retailers, it mightcreate serious concerns about fairness, which even violates the regulation andlaws. This paper studies the problem of dynamic discriminatory pricing underfairness constraints. In particular, we consider a finite selling horizon oflength $T$ for a single product with two groups of customers. Each group ofcustomers has its unknown demand function that needs to be learned. For eachselling period, the seller determines the price for each group and observestheir purchase behavior. While existing literature mainly focuses on maximizingrevenue, ensuring fairness among different customers has not been fullyexplored in the dynamic pricing literature. This work adopts the fairnessnotion from Cohen et al. (2022). For price fairness, we propose an optimaldynamic pricing policy regarding regret, which enforces the strict pricefairness constraint. In contrast to the standard $\sqrt{T}$-type regret inonline learning, we show that the optimal regret in our case is$\tilde{O}(T^{4/5})$. We further extend our algorithm to a more general notionof fairness, which includes demand fairness as a special case. To handle thisgeneral class, we propose a soft fairness constraint and develop a dynamicpricing policy that achieves $\tilde{O}(T^{4/5})$ regret. We also demonstratethat our algorithmic techniques can be adapted to more general scenarios suchas fairness among multiple groups of customers.</description><author>Xi Chen, Jiameng Lyu, Xuan Zhang, Yuan Zhou</author><pubDate>Fri, 28 Jul 2023 15:22:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2111.08221v2</guid></item><item><title>Point Clouds Are Specialized Images: A Knowledge Transfer Approach for 3D Understanding</title><link>http://arxiv.org/abs/2307.15569v1</link><description>Self-supervised representation learning (SSRL) has gained increasingattention in point cloud understanding, in addressing the challenges posed by3D data scarcity and high annotation costs. This paper presents PCExpert, anovel SSRL approach that reinterprets point clouds as "specialized images".This conceptual shift allows PCExpert to leverage knowledge derived fromlarge-scale image modality in a more direct and deeper manner, via extensivelysharing the parameters with a pre-trained image encoder in a multi-wayTransformer architecture. The parameter sharing strategy, combined with a novelpretext task for pre-training, i.e., transformation estimation, empowersPCExpert to outperform the state of the arts in a variety of tasks, with aremarkable reduction in the number of trainable parameters. Notably, PCExpert'sperformance under LINEAR fine-tuning (e.g., yielding a 90.02% overall accuracyon ScanObjectNN) has already approached the results obtained with FULL modelfine-tuning (92.66%), demonstrating its effective and robust representationcapability.</description><author>Jiachen Kang, Wenjing Jia, Xiangjian He, Kin Man Lam</author><pubDate>Fri, 28 Jul 2023 15:04:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15569v1</guid></item><item><title>We are all Individuals: The Role of Robot Personality and Human Traits in Trustworthy Interaction</title><link>http://arxiv.org/abs/2307.15568v1</link><description>As robots take on roles in our society, it is important that theirappearance, behaviour and personality are appropriate for the job they aregiven and are perceived favourably by the people with whom they interact. Here,we provide an extensive quantitative and qualitative study exploring robotpersonality but, importantly, with respect to individual human traits. Firstly,we show that we can accurately portray personality in a social robot, in termsof extroversion-introversion using vocal cues and linguistic features.Secondly, through garnering preferences and trust ratings for these differentrobot personalities, we establish that, for a Robo-Barista, an extrovert robotis preferred and trusted more than an introvert robot, regardless of thesubject's own personality. Thirdly, we find that individual attitudes andpredispositions towards robots do impact trust in the Robo-Baristas, and aretherefore important considerations in addition to robot personality, roles andinteraction context when designing any human-robot interaction study.</description><author>Mei Yii Lim, José David Aguas Lopes, David A. Robb, Bruce W. Wilson, Meriam Moujahid, Emanuele De Pellegrin, Helen Hastie</author><pubDate>Fri, 28 Jul 2023 15:04:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15568v1</guid></item><item><title>Panoptic Scene Graph Generation with Semantics-prototype Learning</title><link>http://arxiv.org/abs/2307.15567v1</link><description>Panoptic Scene Graph Generation (PSG) parses objects and predicts theirrelationships (predicate) to connect human language and visual scenes. However,different language preferences of annotators and semantic overlaps betweenpredicates lead to biased predicate annotations in the dataset, i.e. differentpredicates for same object pairs. Biased predicate annotations make PSG modelsstruggle in constructing a clear decision plane among predicates, which greatlyhinders the real application of PSG models. To address the intrinsic biasabove, we propose a novel framework named ADTrans to adaptively transfer biasedpredicate annotations to informative and unified ones. To promise consistencyand accuracy during the transfer process, we propose to measure the invarianceof representations in each predicate class, and learn unbiased prototypes ofpredicates with different intensities. Meanwhile, we continuously measure thedistribution changes between each presentation and its prototype, andconstantly screen potential biased data. Finally, with the unbiasedpredicate-prototype representation embedding space, biased annotations areeasily identified. Experiments show that ADTrans significantly improves theperformance of benchmark models, achieving a new state-of-the-art performance,and shows great generalization and effectiveness on multiple datasets.</description><author>Li Li, Wei Ji, Yiming Wu, Mengze Li, You Qin, Lina Wei, Roger Zimmermann</author><pubDate>Fri, 28 Jul 2023 15:04:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15567v1</guid></item><item><title>Swarm Reinforcement Learning For Adaptive Mesh Refinement</title><link>http://arxiv.org/abs/2304.00818v2</link><description>The Finite Element Method, an important technique in engineering, is aided byAdaptive Mesh Refinement (AMR), which dynamically refines mesh regions to allowfor a favorable trade-off between computational speed and simulation accuracy.Classical methods for AMR depend on task-specific heuristics or expensive errorestimators, hindering their use for complex simulations. Recent learned AMRmethods tackle these problems, but so far scale only to simple toy examples. Weformulate AMR as a novel Adaptive Swarm Markov Decision Process in which a meshis modeled as a system of simple collaborating agents that may split intomultiple new agents. This framework allows for a spatial reward formulationthat simplifies the credit assignment problem, which we combine with MessagePassing Networks to propagate information between neighboring mesh elements. Weexperimentally validate the effectiveness of our approach, Adaptive Swarm MeshRefinement (ASMR), showing that it learns reliable, scalable, and efficientrefinement strategies on a set of challenging problems. Our approachsignificantly speeds up computation, achieving up to 30-fold improvementcompared to uniform refinements in complex simulations. Additionally, weoutperform learned baselines and achieve a refinement quality that is on parwith a traditional error-based AMR strategy without expensive oracleinformation about the error signal.</description><author>Niklas Freymuth, Philipp Dahlinger, Tobias Würth, Simon Reisch, Luise Kärger, Gerhard Neumann</author><pubDate>Fri, 28 Jul 2023 15:02:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.00818v2</guid></item><item><title>Dynamic algorithms for k-center on graphs</title><link>http://arxiv.org/abs/2307.15557v1</link><description>In this paper we give the first efficient algorithms for the $k$-centerproblem on dynamic graphs undergoing edge updates. In this problem, the goal isto partition the input into $k$ sets by choosing $k$ centers such that themaximum distance from any data point to the closest center is minimized. It isknown that it is NP-hard to get a better than $2$ approximation for thisproblem. While in many applications the input may naturally be modeled as a graph, allprior works on $k$-center problem in dynamic settings are on metrics. In thispaper, we give a deterministic decremental $(2+\epsilon)$-approximationalgorithm and a randomized incremental $(4+\epsilon)$-approximation algorithm,both with amortized update time $kn^{o(1)}$ for weighted graphs. Moreover, weshow a reduction that leads to a fully dynamic $(2+\epsilon)$-approximationalgorithm for the $k$-center problem, with worst-case update time that iswithin a factor $k$ of the state-of-the-art upper bound for maintaining$(1+\epsilon)$-approximate single-source distances in graphs. Matching thisbound is a natural goalpost because the approximate distances of each vertex toits center can be used to maintain a $(2+\epsilon)$-approximation of the graphdiameter and the fastest known algorithms for such a diameter approximationalso rely on maintaining approximate single-source distances.</description><author>Emilio Cruciani, Sebastian Forster, Gramoz Goranci, Yasamin Nazari, Antonis Skarlatos</author><pubDate>Fri, 28 Jul 2023 14:50:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15557v1</guid></item><item><title>All-for-One and One-For-All: Deep learning-based feature fusion for Synthetic Speech Detection</title><link>http://arxiv.org/abs/2307.15555v1</link><description>Recent advances in deep learning and computer vision have made the synthesisand counterfeiting of multimedia content more accessible than ever, leading topossible threats and dangers from malicious users. In the audio field, we arewitnessing the growth of speech deepfake generation techniques, which solicitthe development of synthetic speech detection algorithms to counter possiblemischievous uses such as frauds or identity thefts. In this paper, we considerthree different feature sets proposed in the literature for the syntheticspeech detection task and present a model that fuses them, achieving overallbetter performances with respect to the state-of-the-art solutions. The systemwas tested on different scenarios and datasets to prove its robustness toanti-forensic attacks and its generalization capabilities.</description><author>Daniele Mari, Davide Salvi, Paolo Bestagini, Simone Milani</author><pubDate>Fri, 28 Jul 2023 14:50:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15555v1</guid></item><item><title>'What are you referring to?' Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges</title><link>http://arxiv.org/abs/2307.15554v1</link><description>Referential ambiguities arise in dialogue when a referring expression doesnot uniquely identify the intended referent for the addressee. Addresseesusually detect such ambiguities immediately and work with the speaker to repairit using meta-communicative, Clarificational Exchanges (CE): a ClarificationRequest (CR) and a response. Here, we argue that the ability to generate andrespond to CRs imposes specific constraints on the architecture and objectivefunctions of multi-modal, visually grounded dialogue models. We use the SIMMC2.0 dataset to evaluate the ability of different state-of-the-art modelarchitectures to process CEs, with a metric that probes the contextual updatesthat arise from them in the model. We find that language-based models are ableto encode simple multi-modal semantic information and process some CEs,excelling with those related to the dialogue history, whilst multi-modal modelscan use additional learning objectives to obtain disentangled objectrepresentations, which become crucial to handle complex referential ambiguitiesacross modalities overall.</description><author>Javier Chiyah-Garcia, Alessandro Suglia, Arash Eshghi, Helen Hastie</author><pubDate>Fri, 28 Jul 2023 14:44:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15554v1</guid></item><item><title>Fail-Safe Adversarial Generative Imitation Learning</title><link>http://arxiv.org/abs/2203.01696v2</link><description>For flexible yet safe imitation learning (IL), we propose theory and amodular method, with a safety layer that enables a closed-form probabilitydensity/gradient of the safe generative continuous policy, end-to-endgenerative adversarial training, and worst-case safety guarantees. The safetylayer maps all actions into a set of safe actions, and uses thechange-of-variables formula plus additivity of measures for the density. Theset of safe actions is inferred by first checking safety of a finite sample ofactions via adversarial reachability analysis of fallback maneuvers, and thenconcluding on the safety of these actions' neighborhoods using, e.g., Lipschitzcontinuity. We provide theoretical analysis showing the robustness advantage ofusing the safety layer already during training (imitation error linear in thehorizon) compared to only using it at test time (up to quadratic error). In anexperiment on real-world driver interaction data, we empirically demonstratetractability, safety and imitation performance of our approach.</description><author>Philipp Geiger, Christoph-Nikolas Straehle</author><pubDate>Fri, 28 Jul 2023 14:38:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.01696v2</guid></item><item><title>Automatic Lexical Simplification for Turkish</title><link>http://arxiv.org/abs/2201.05878v3</link><description>In this paper, we present the first automatic lexical simplification systemfor the Turkish language. Recent text simplification efforts rely on manuallycrafted simplified corpora and comprehensive NLP tools that can analyse thetarget text both in word and sentence levels. Turkish is a morphologically richagglutinative language that requires unique considerations such as the properhandling of inflectional cases. Being a low-resource language in terms ofavailable resources and industrial-strength tools, it makes the textsimplification task harder to approach. We present a new text simplificationpipeline based on pretrained representation model BERT together withmorphological features to generate grammatically correct and semanticallyappropriate word-level simplifications.</description><author>Ahmet Yavuz Uluslu</author><pubDate>Fri, 28 Jul 2023 14:33:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.05878v3</guid></item><item><title>Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository Mining Study</title><link>http://arxiv.org/abs/2305.11164v2</link><description>The rise of machine learning (ML) systems has exacerbated their carbonfootprint due to increased capabilities and model sizes. However, there isscarce knowledge on how the carbon footprint of ML models is actually measured,reported, and evaluated. In light of this, the paper aims to analyze themeasurement of the carbon footprint of 1,417 ML models and associated datasetson Hugging Face, which is the most popular repository for pretrained ML models.The goal is to provide insights and recommendations on how to report andoptimize the carbon efficiency of ML models. The study includes the firstrepository mining study on the Hugging Face Hub API on carbon emissions. Thisstudy seeks to answer two research questions: (1) how do ML model creatorsmeasure and report carbon emissions on Hugging Face Hub?, and (2) what aspectsimpact the carbon emissions of training ML models? The study yielded severalkey findings. These include a stalled proportion of carbon emissions-reportingmodels, a slight decrease in reported carbon footprint on Hugging Face over thepast 2 years, and a continued dominance of NLP as the main application domain.Furthermore, the study uncovers correlations between carbon emissions andvarious attributes such as model size, dataset size, and ML applicationdomains. These results highlight the need for software measurements to improveenergy reporting practices and promote carbon-efficient model developmentwithin the Hugging Face community. In response to this issue, twoclassifications are proposed: one for categorizing models based on their carbonemission reporting practices and another for their carbon efficiency. The aimof these classification proposals is to foster transparency and sustainablemodel development within the ML community.</description><author>Joel Castaño, Silverio Martínez-Fernández, Xavier Franch, Justus Bogner</author><pubDate>Fri, 28 Jul 2023 14:29:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11164v2</guid></item><item><title>Turkish Native Language Identification</title><link>http://arxiv.org/abs/2307.14850v2</link><description>In this paper, we present the first application of Native LanguageIdentification (NLI) for the Turkish language. NLI involves predicting thewriter's first language by analysing their writing in different languages.While most NLI research has focused on English, our study extends its scope toTurkish. We used the recently constructed Turkish Learner Corpus and employed acombination of three syntactic features (CFG production rules, part-of-speechn-grams, and function words) with L2 texts to demonstrate their effectivenessin this task.</description><author>Ahmet Yavuz Uluslu, Gerold Schneider</author><pubDate>Fri, 28 Jul 2023 14:27:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14850v2</guid></item><item><title>Resource frugal optimizer for quantum machine learning</title><link>http://arxiv.org/abs/2211.04965v3</link><description>Quantum-enhanced data science, also known as quantum machine learning (QML),is of growing interest as an application of near-term quantum computers.Variational QML algorithms have the potential to solve practical problems onreal hardware, particularly when involving quantum data. However, trainingthese algorithms can be challenging and calls for tailored optimizationprocedures. Specifically, QML applications can require a large shot-countoverhead due to the large datasets involved. In this work, we advocate forsimultaneous random sampling over both the dataset as well as the measurementoperators that define the loss function. We consider a highly general lossfunction that encompasses many QML applications, and we show how to constructan unbiased estimator of its gradient. This allows us to propose a shot-frugalgradient descent optimizer called Refoqus (REsource Frugal Optimizer forQUantum Stochastic gradient descent). Our numerics indicate that Refoqus cansave several orders of magnitude in shot cost, even relative to optimizers thatsample over measurement operators alone.</description><author>Charles Moussa, Max Hunter Gordon, Michal Baczyk, M. Cerezo, Lukasz Cincio, Patrick J. Coles</author><pubDate>Fri, 28 Jul 2023 14:23:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.04965v3</guid></item><item><title>On the Trade-off Between Efficiency and Precision of Neural Abstraction</title><link>http://arxiv.org/abs/2307.15546v1</link><description>Neural abstractions have been recently introduced as formal approximations ofcomplex, nonlinear dynamical models. They comprise a neural ODE and a certifiedupper bound on the error between the abstract neural network and the concretedynamical model. So far neural abstractions have exclusively been obtained asneural networks consisting entirely of $ReLU$ activation functions, resultingin neural ODE models that have piecewise affine dynamics, and which can beequivalently interpreted as linear hybrid automata. In this work, we observethat the utility of an abstraction depends on its use: some scenarios mightrequire coarse abstractions that are easier to analyse, whereas others mightrequire more complex, refined abstractions. We therefore consider neuralabstractions of alternative shapes, namely either piecewise constant ornonlinear non-polynomial (specifically, obtained via sigmoidal activations). Weemploy formal inductive synthesis procedures to generate neural abstractionsthat result in dynamical models with these semantics. Empirically, wedemonstrate the trade-off that these different neural abstraction templateshave vis-a-vis their precision and synthesis time, as well as the time requiredfor their safety verification (done via reachability computation). We improveexisting synthesis techniques to enable abstraction of higher-dimensionalmodels, and additionally discuss the abstraction of complex neural ODEs toimprove the efficiency of reachability analysis for these models.</description><author>Alec Edwards, Mirco Giacobbe, Alessandro Abate</author><pubDate>Fri, 28 Jul 2023 14:22:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15546v1</guid></item><item><title>Towards Multimodal Prediction of Spontaneous Humour: A Novel Dataset and First Results</title><link>http://arxiv.org/abs/2209.14272v2</link><description>Humour is a substantial element of human affect and cognition. Its automaticunderstanding can facilitate a more naturalistic human-device interaction andthe humanisation of artificial intelligence. Current methods of humourdetection are solely based on staged data making them inadequate for'real-world' applications. We address this deficiency by introducing the novelPassau-Spontaneous Football Coach Humour (Passau-SFCH) dataset, comprising ofabout 11 hours of recordings. The Passau-SFCH dataset is annotated for thepresence of humour and its dimensions (sentiment and direction) as proposed inMartin's Humor Style Questionnaire. We conduct a series of experiments,employing pretrained Transformers, convolutional neural networks, andexpert-designed features. The performance of each modality (text, audio, video)for spontaneous humour recognition is analysed and their complementarity isinvestigated. Our findings suggest that for the automatic analysis of humourand its sentiment, facial expressions are most promising, while humourdirection can be best modelled via text-based features. The results revealconsiderable differences among various subjects, highlighting the individualityof humour usage and style. Further, we observe that a decision-level fusionyields the best recognition result. Finally, we make our code publiclyavailable at https://www.github.com/EIHW/passau-sfch. The Passau-SFCH datasetis available upon request.</description><author>Lukas Christ, Shahin Amiriparian, Alexander Kathan, Niklas Müller, Andreas König, Björn W. Schuller</author><pubDate>Fri, 28 Jul 2023 14:18:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.14272v2</guid></item><item><title>Oracle Computability and Turing Reducibility in the Calculus of Inductive Constructions</title><link>http://arxiv.org/abs/2307.15543v1</link><description>We develop synthetic notions of oracle computability and Turing reducibilityin the Calculus of Inductive Constructions (CIC), the constructive type theoryunderlying the Coq proof assistant. As usual in synthetic approaches, we employa definition of oracle computations based on meta-level functions rather thanobject-level models of computation, relying on the fact that in constructivesystems such as CIC all definable functions are computable by construction.Such an approach lends itself well to machine-checked proofs, which we carryout in Coq. There is a tension in finding a good synthetic rendering of the higher-ordernotion of oracle computability. On the one hand, it has to be informativeenough to prove central results, ensuring that all notions are faithfullycaptured. On the other hand, it has to be restricted enough to benefit fromaxioms for synthetic computability, which usually concern first-order objects.Drawing inspiration from a definition by Andrej Bauer based on continuousfunctions in the effective topos, we use a notion of sequential continuity tocharacterise valid oracle computations. As main technical results, we show that Turing reducibility forms an uppersemilattice, transports decidability, and is strictly more expressive thantruth-table reducibility, and prove that whenever both a predicate $p$ and itscomplement are semi-decidable relative to an oracle $q$, then $p$Turing-reduces to $q$.</description><author>Yannick Forster, Dominik Kirst, Niklas Mück</author><pubDate>Fri, 28 Jul 2023 14:16:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15543v1</guid></item><item><title>Complex-valued Retrievals From Noisy Images Using Diffusion Models</title><link>http://arxiv.org/abs/2212.03235v3</link><description>In diverse microscopy modalities, sensors measure only real-valuedintensities. Additionally, the sensor readouts are affected byPoissonian-distributed photon noise. Traditional restoration algorithmstypically aim to minimize the mean squared error (MSE) between the original andrecovered images. This often leads to blurry outcomes with poor perceptualquality. Recently, deep diffusion models (DDMs) have proven to be highlycapable of sampling images from the a-posteriori probability of the soughtvariables, resulting in visually pleasing high-quality images. These modelshave mostly been suggested for real-valued images suffering from Gaussiannoise. In this study, we generalize annealed Langevin Dynamics, a type of DDM,to tackle the fundamental challenges in optical imaging of complex-valuedobjects (and real images) affected by Poisson noise. We apply our algorithm tovarious optical scenarios, such as Fourier Ptychography, Phase Retrieval, andPoisson denoising. Our algorithm is evaluated on simulations and biologicalempirical data.</description><author>Nadav Torem, Roi Ronen, Yoav Y. Schechner, Michael Elad</author><pubDate>Fri, 28 Jul 2023 14:10:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.03235v3</guid></item><item><title>Backdoor Defense with Non-Adversarial Backdoor</title><link>http://arxiv.org/abs/2307.15539v1</link><description>Deep neural networks (DNNs) are vulnerable to backdoor attack, which does notaffect the network's performance on clean data but would manipulate the networkbehavior once a trigger pattern is added. Existing defense methods have greatlyreduced attack success rate, but their prediction accuracy on clean data stilllags behind a clean model by a large margin. Inspired by the stealthiness andeffectiveness of backdoor attack, we propose a simple but highly effectivedefense framework which injects non-adversarial backdoors targeting poisonedsamples. Following the general steps in backdoor attack, we detect a small setof suspected samples and then apply a poisoning strategy to them. Thenon-adversarial backdoor, once triggered, suppresses the attacker's backdoor onpoisoned data, but has limited influence on clean data. The defense can becarried out during data preprocessing, without any modification to the standardend-to-end training pipeline. We conduct extensive experiments on multiplebenchmarks with different architectures and representative attacks. Resultsdemonstrate that our method achieves state-of-the-art defense effectivenesswith by far the lowest performance drop on clean data. Considering thesurprising defense ability displayed by our framework, we call for moreattention to utilizing backdoor for backdoor defense. Code is available athttps://github.com/damianliumin/non-adversarial_backdoor.</description><author>Min Liu, Alberto Sangiovanni-Vincentelli, Xiangyu Yue</author><pubDate>Fri, 28 Jul 2023 14:07:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15539v1</guid></item><item><title>Dense Transformer based Enhanced Coding Network for Unsupervised Metal Artifact Reduction</title><link>http://arxiv.org/abs/2307.12717v2</link><description>CT images corrupted by metal artifacts have serious negative effects onclinical diagnosis. Considering the difficulty of collecting paired data withground truth in clinical settings, unsupervised methods for metal artifactreduction are of high interest. However, it is difficult for previousunsupervised methods to retain structural information from CT images whilehandling the non-local characteristics of metal artifacts. To address thesechallenges, we proposed a novel Dense Transformer based Enhanced Coding Network(DTEC-Net) for unsupervised metal artifact reduction. Specifically, weintroduce a Hierarchical Disentangling Encoder, supported by the high-orderdense process, and transformer to obtain densely encoded sequences withlong-range correspondence. Then, we present a second-order disentanglementmethod to improve the dense sequence's decoding process. Extensive experimentsand model discussions illustrate DTEC-Net's effectiveness, which outperformsthe previous state-of-the-art methods on a benchmark dataset, and greatlyreduces metal artifacts while restoring richer texture details.</description><author>Wangduo Xie, Matthew B. Blaschko</author><pubDate>Fri, 28 Jul 2023 13:54:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12717v2</guid></item><item><title>Few-shot Image Classification based on Gradual Machine Learning</title><link>http://arxiv.org/abs/2307.15524v1</link><description>Few-shot image classification aims to accurately classify unlabeled imagesusing only a few labeled samples. The state-of-the-art solutions are built bydeep learning, which focuses on designing increasingly complex deep backbones.Unfortunately, the task remains very challenging due to the difficulty oftransferring the knowledge learned in training classes to new ones. In thispaper, we propose a novel approach based on the non-i.i.d paradigm of gradualmachine learning (GML). It begins with only a few labeled observations, andthen gradually labels target images in the increasing order of hardness byiterative factor inference in a factor graph. Specifically, our proposedsolution extracts indicative feature representations by deep backbones, andthen constructs both unary and binary factors based on the extracted featuresto facilitate gradual learning. The unary factors are constructed based onclass center distance in an embedding space, while the binary factors areconstructed based on k-nearest neighborhood. We have empirically validated theperformance of the proposed approach on benchmark datasets by a comparativestudy. Our extensive experiments demonstrate that the proposed approach canimprove the SOTA performance by 1-5% in terms of accuracy. More notably, it ismore robust than the existing deep models in that its performance canconsistently improve as the size of query set increases while the performanceof deep models remains essentially flat or even becomes worse.</description><author>Na Chen, Xianming Kuang, Feiyu Liu, Kehao Wang, Qun Chen</author><pubDate>Fri, 28 Jul 2023 13:30:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15524v1</guid></item><item><title>Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research</title><link>http://arxiv.org/abs/2307.02131v2</link><description>This study employs counterfactual explanations to explore "what if?"scenarios in medical research, with the aim of expanding our understandingbeyond existing boundaries. Specifically, we focus on utilizing MRI featuresfor diagnosing pediatric posterior fossa brain tumors as a case study. Thefield of artificial intelligence and explainability has witnessed a growingnumber of studies and increasing scholarly interest. However, the lack ofhuman-friendly interpretations in explaining the outcomes of machine learningalgorithms has significantly hindered the acceptance of these methods byclinicians in their clinical practice. To address this, our approachincorporates counterfactual explanations, providing a novel way to examinealternative decision-making scenarios. These explanations offer personalizedand context-specific insights, enabling the validation of predictions andclarification of variations under diverse circumstances. Importantly, ourapproach maintains both statistical and clinical fidelity, allowing for theexamination of distinct tumor features through alternative realities.Additionally, we explore the potential use of counterfactuals for dataaugmentation and evaluate their feasibility as an alternative approach inmedical research. The results demonstrate the promising potential ofcounterfactual explanations to enhance trust and acceptance of AI-drivenmethods in clinical settings.</description><author>Toygar Tanyel, Serkan Ayvaz, Bilgin Keserci</author><pubDate>Fri, 28 Jul 2023 13:28:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02131v2</guid></item><item><title>Automating Model Comparison in Factor Graphs</title><link>http://arxiv.org/abs/2306.05965v3</link><description>Bayesian state and parameter estimation have been automated effectively in avariety of probabilistic programming languages. The process of model comparisonon the other hand, which still requires error-prone and time-consuming manualderivations, is often overlooked despite its importance. This paper efficientlyautomates Bayesian model averaging, selection, and combination by messagepassing on a Forney-style factor graph with a custom mixture node. Parameterand state inference, and model comparison can then be executed simultaneouslyusing message passing with scale factors. This approach shortens the modeldesign cycle and allows for the straightforward extension to hierarchical andtemporal model priors to accommodate for modeling complicated time-varyingprocesses.</description><author>Bart van Erp, Wouter W. L. Nuijten, Thijs van de Laar, Bert de Vries</author><pubDate>Fri, 28 Jul 2023 13:25:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05965v3</guid></item><item><title>Audiovisual Masked Autoencoders</title><link>http://arxiv.org/abs/2212.05922v2</link><description>Can we leverage the audiovisual information already present in video toimprove self-supervised representation learning? To answer this question, westudy various pretraining architectures and objectives within the maskedautoencoding framework, motivated by the success of similar methods in naturallanguage and image understanding. We show that we can achieve significantimprovements on audiovisual downstream classification tasks, surpassing thestate-of-the-art on VGGSound and AudioSet. Furthermore, we can leverage ouraudiovisual pretraining scheme for multiple unimodal downstream tasks using asingle audiovisual pretrained model. We additionally demonstrate thetransferability of our representations, achieving state-of-the-art audiovisualresults on Epic Kitchens without pretraining specifically for this dataset.</description><author>Mariana-Iuliana Georgescu, Eduardo Fonseca, Radu Tudor Ionescu, Mario Lucic, Cordelia Schmid, Anurag Arnab</author><pubDate>Fri, 28 Jul 2023 13:22:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.05922v2</guid></item><item><title>YOLOv8 for Defect Inspection of Hexagonal Directed Self-Assembly Patterns: A Data-Centric Approach</title><link>http://arxiv.org/abs/2307.15516v1</link><description>Shrinking pattern dimensions leads to an increased variety of defect types insemiconductor devices. This has spurred innovation in patterning approachessuch as Directed self-assembly (DSA) for which no traditional, automatic defectinspection software exists. Machine Learning-based SEM image analysis hasbecome an increasingly popular research topic for defect inspection withsupervised ML models often showing the best performance. However, littleresearch has been done on obtaining a dataset with high-quality labels forthese supervised models. In this work, we propose a method for obtainingcoherent and complete labels for a dataset of hexagonal contact hole DSApatterns while requiring minimal quality control effort from a DSA expert. Weshow that YOLOv8, a state-of-the-art neural network, achieves defect detectionprecisions of more than 0.9 mAP on our final dataset which best reflects DSAexpert defect labeling expectations. We discuss the strengths and limitationsof our proposed labeling approach and suggest directions for future work indata-centric ML-based defect inspection.</description><author>Enrique Dehaerne, Bappaditya Dey, Hossein Esfandiar, Lander Verstraete, Hyo Seon Suh, Sandip Halder, Stefan De Gendt</author><pubDate>Fri, 28 Jul 2023 13:17:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15516v1</guid></item><item><title>Revisiting Fully Convolutional Geometric Features for Object 6D Pose Estimation</title><link>http://arxiv.org/abs/2307.15514v1</link><description>Recent works on 6D object pose estimation focus on learning keypointcorrespondences between images and object models, and then determine the objectpose through RANSAC-based algorithms or by directly regressing the pose withend-to-end optimisations. We argue that learning point-level discriminativefeatures is overlooked in the literature. To this end, we revisit FullyConvolutional Geometric Features (FCGF) and tailor it for object 6D poseestimation to achieve state-of-the-art performance. FCGF employs sparseconvolutions and learns point-level features using a fully-convolutionalnetwork by optimising a hardest contrastive loss. We can outperform recentcompetitors on popular benchmarks by adopting key modifications to the loss andto the input data representations, by carefully tuning the training strategies,and by employing data augmentations suitable for the underlying problem. Wecarry out a thorough ablation to study the contribution of each modification.</description><author>Jaime Corsetti, Davide Boscaini, Fabio Poiesi</author><pubDate>Fri, 28 Jul 2023 13:16:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15514v1</guid></item><item><title>The Road to Quality is Paved with Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling</title><link>http://arxiv.org/abs/2307.15508v1</link><description>Incremental dialogue model components produce a sequence of output prefixesbased on incoming input. Mistakes can occur due to local ambiguities or towrong hypotheses, making the ability to revise past outputs a desirableproperty that can be governed by a policy. In this work, we formalise andcharacterise edits and revisions in incremental sequence labelling and proposemetrics to evaluate revision policies. We then apply our methodology to profilethe incremental behaviour of three Transformer-based encoders in various tasks,paving the road for better revision policies.</description><author>Brielen Madureira, Patrick Kahardipraja, David Schlangen</author><pubDate>Fri, 28 Jul 2023 13:08:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15508v1</guid></item><item><title>Improving Image Quality of Sparse-view Lung Cancer CT Images with a Convolutional Neural Network</title><link>http://arxiv.org/abs/2307.15506v1</link><description>Purpose: To improve the image quality of sparse-view computed tomography (CT)images with a U-Net for lung cancer detection and to determine the besttrade-off between number of views, image quality, and diagnostic confidence. Methods: CT images from 41 subjects (34 with lung cancer, seven healthy) wereretrospectively selected (01.2016-12.2018) and forward projected onto 2048-viewsinograms. Six corresponding sparse-view CT data subsets at varying levels ofundersampling were reconstructed from sinograms using filtered backprojectionwith 16, 32, 64, 128, 256, and 512 views, respectively. A dual-frame U-Net wastrained and evaluated for each subsampling level on 8,658 images from 22diseased subjects. A representative image per scan was selected from 19subjects (12 diseased, seven healthy) for a single-blinded reader study. Theselected slices, for all levels of subsampling, with and withoutpost-processing by the U-Net model, were presented to three readers. Imagequality and diagnostic confidence were ranked using pre-defined scales.Subjective nodule segmentation was evaluated utilizing sensitivity (Se) andDice Similarity Coefficient (DSC) with 95% confidence intervals (CI). Results: The 64-projection sparse-view images resulted in Se = 0.89 and DSC =0.81 [0.75,0.86] while their counterparts, post-processed with the U-Net, hadimproved metrics (Se = 0.94, DSC = 0.85 [0.82,0.87]). Fewer views lead toinsufficient quality for diagnostic purposes. For increased views, nosubstantial discrepancies were noted between the sparse-view and post-processedimages. Conclusion: Projection views can be reduced from 2048 to 64 while maintainingimage quality and the confidence of the radiologists on a satisfactory level.</description><author>Annika Ries, Tina Dorosti, Johannes Thalhammer, Daniel Sasse, Andreas Sauter, Felix Meurer, Ashley Benne, Franz Pfeiffer, Daniela Pfeiffer</author><pubDate>Fri, 28 Jul 2023 13:03:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15506v1</guid></item><item><title>Exploring Format Consistency for Instruction Tuning</title><link>http://arxiv.org/abs/2307.15504v1</link><description>Instruction tuning has emerged as a promising approach to enhancing largelanguage models in following human instructions. It is shown that increasingthe diversity and number of instructions in the training data can consistentlyenhance generalization performance, which facilitates a recent endeavor tocollect various instructions and integrate existing instruction tuning datasetsinto larger collections. However, different users have their unique ways ofexpressing instructions, and there often exist variations across differentdatasets in the instruction styles and formats, i.e., format inconsistency. Inthis work, we study how format inconsistency may impact the performance ofinstruction tuning. We propose a framework called "Unified Instruction Tuning"(UIT), which calls OpenAI APIs for automatic format transfer among differentinstruction tuning datasets. We show that UIT successfully improves thegeneralization performance on unseen instructions, which highlights theimportance of format consistency for instruction tuning. To make the UITframework more practical, we further propose a novel perplexity-based denoisingmethod to reduce the noise of automatic format transfer. We also train asmaller offline model that achieves comparable format transfer capability thanOpenAI APIs to reduce costs in practice.</description><author>Shihao Liang, Kunlun Zhu, Runchu Tian, Yujia Qin, Huadong Wang, Xin Cong, Zhiyuan Liu, Xiaojiang Liu, Maosong Sun</author><pubDate>Fri, 28 Jul 2023 13:00:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15504v1</guid></item><item><title>The Applicability of Federated Learning to Official Statistics</title><link>http://arxiv.org/abs/2307.15503v1</link><description>This work investigates the potential of Federated Learning (FL) for officialstatistics and shows how well the performance of FL models can keep up withcentralized learning methods. At the same time, its utilization can safeguardthe privacy of data holders, thus facilitating access to a broader range ofdata and ultimately enhancing official statistics. By simulating threedifferent use cases, important insights on the applicability of the technologyare gained. The use cases are based on a medical insurance data set, a finedust pollution data set and a mobile radio coverage data set - all of which arefrom domains close to official statistics. We provide a detailed analysis ofthe results, including a comparison of centralized and FL algorithmperformances for each simulation. In all three use cases, we were able to trainmodels via FL which reach a performance very close to the centralized modelbenchmarks. Our key observations and their implications for transferring thesimulations into practice are summarized. We arrive at the conclusion that FLhas the potential to emerge as a pivotal technology in future use cases ofofficial statistics.</description><author>Joshua Stock, Oliver Hauke, Julius Weißmann, Hannes Federrath</author><pubDate>Fri, 28 Jul 2023 12:58:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15503v1</guid></item><item><title>Expert-Free Online Transfer Learning in Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2303.01170v3</link><description>Transfer learning in Reinforcement Learning (RL) has been widely studied toovercome training issues of Deep-RL, i.e., exploration cost, data availabilityand convergence time, by introducing a way to enhance training phase withexternal knowledge. Generally, knowledge is transferred from expert-agents tonovices. While this fixes the issue for a novice agent, a good understanding ofthe task on expert agent is required for such transfer to be effective. As analternative, in this paper we propose Expert-Free Online Transfer Learning(EF-OnTL), an algorithm that enables expert-free real-time dynamic transferlearning in multi-agent system. No dedicated expert exists, and transfer sourceagent and knowledge to be transferred are dynamically selected at each transferstep based on agents' performance and uncertainty. To improve uncertaintyestimation, we also propose State Action Reward Next-State Random NetworkDistillation (sars-RND), an extension of RND that estimates uncertainty from RLagent-environment interaction. We demonstrate EF-OnTL effectiveness against ano-transfer scenario and advice-based baselines, with and without expertagents, in three benchmark tasks: Cart-Pole, a grid-based Multi-TeamPredator-Prey (mt-pp) and Half Field Offense (HFO). Our results show thatEF-OnTL achieve overall comparable performance when compared againstadvice-based baselines while not requiring any external input nor thresholdtuning. EF-OnTL outperforms no-transfer with an improvement related to thecomplexity of the task addressed.</description><author>Alberto Castagna, Ivana Dusparic</author><pubDate>Fri, 28 Jul 2023 12:52:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.01170v3</guid></item><item><title>Optimizing Convolutional Neural Networks for Chronic Obstructive Pulmonary Disease Detection in Clinical Computed Tomography Imaging</title><link>http://arxiv.org/abs/2303.07189v2</link><description>Purpose: To optimize the binary detection of Chronic Obstructive PulmonaryDisease (COPD) based on emphysema presence in the lung with convolutionalneural networks (CNN) by exploring manually adjusted versus automatedwindow-setting optimization (WSO) on computed tomography (CT) images. Methods: 7,194 CT images (3,597 with COPD; 3,597 healthy controls) from 78subjects (43 with COPD; 35 healthy controls) were selected retrospectively(10.2018-12.2019) and preprocessed. For each image, intensity values weremanually clipped to the emphysema window setting and a baseline 'full-range'window setting. Class-balanced train, validation, and test sets contained3,392, 1,114, and 2,688 images. The network backbone was optimized by comparingvarious CNN architectures. Furthermore, automated WSO was implemented by addinga customized layer to the model. The image-level area under the ReceiverOperating Characteristics curve (AUC) [lower, upper limit 95% confidence] andP-values calculated from one-sided Mann-Whitney U-test were utilized to comparemodel variations. Results: Repeated inference (n=7) on the test set showed that the DenseNetwas the most efficient backbone and achieved a mean AUC of 0.80 [0.76, 0.85]without WSO. Comparably, with input images manually adjusted to the emphysemawindow, the DenseNet model predicted COPD with a mean AUC of 0.86 [0.82, 0.89](P=0.03). By adding a customized WSO layer to the DenseNet, an optimal windowin the proximity of the emphysema window setting was learned automatically, anda mean AUC of 0.82 [0.78, 0.86] was achieved. Conclusion: Detection of COPD with DenseNet models was improved by WSO of CTdata to the emphysema window setting range.</description><author>Tina Dorosti, Manuel Schultheiss, Felix Hofmann, Johannes Thalhammer, Luisa Kirchner, Theresa Urban, Franz Pfeiffer, Florian Schaff, Tobias Lasser, Daniela Pfeiffer</author><pubDate>Fri, 28 Jul 2023 12:49:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07189v2</guid></item><item><title>From continuous-time formulations to discretization schemes: tensor trains and robust regression for BSDEs and parabolic PDEs</title><link>http://arxiv.org/abs/2307.15496v1</link><description>The numerical approximation of partial differential equations (PDEs) posesformidable challenges in high dimensions since classical grid-based methodssuffer from the so-called curse of dimensionality. Recent attempts rely on acombination of Monte Carlo methods and variational formulations, using neuralnetworks for function approximation. Extending previous work (Richter et al.,2021), we argue that tensor trains provide an appealing framework for parabolicPDEs: The combination of reformulations in terms of backward stochasticdifferential equations and regression-type methods holds the promise ofleveraging latent low-rank structures, enabling both compression and efficientcomputation. Emphasizing a continuous-time viewpoint, we develop iterativeschemes, which differ in terms of computational efficiency and robustness. Wedemonstrate both theoretically and numerically that our methods can achieve afavorable trade-off between accuracy and computational efficiency. Whileprevious methods have been either accurate or fast, we have identified a novelnumerical strategy that can often combine both of these aspects.</description><author>Lorenz Richter, Leon Sallandt, Nikolas Nüsken</author><pubDate>Fri, 28 Jul 2023 12:44:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15496v1</guid></item><item><title>ETHER: Aligning Emergent Communication for Hindsight Experience Replay</title><link>http://arxiv.org/abs/2307.15494v1</link><description>Natural language instruction following is paramount to enable collaborationbetween artificial agents and human beings. Natural language-conditionedreinforcement learning (RL) agents have shown how natural languages'properties, such as compositionality, can provide a strong inductive bias tolearn complex policies. Previous architectures like HIGhER combine the benefitof language-conditioning with Hindsight Experience Replay (HER) to deal withsparse rewards environments. Yet, like HER, HIGhER relies on an oraclepredicate function to provide a feedback signal highlighting which linguisticdescription is valid for which state. This reliance on an oracle limits itsapplication. Additionally, HIGhER only leverages the linguistic informationcontained in successful RL trajectories, thus hurting its final performance anddata-efficiency. Without early successful trajectories, HIGhER is no betterthan DQN upon which it is built. In this paper, we propose the Emergent TextualHindsight Experience Replay (ETHER) agent, which builds on HIGhER and addressesboth of its limitations by means of (i) a discriminative visual referentialgame, commonly studied in the subfield of Emergent Communication (EC), usedhere as an unsupervised auxiliary task and (ii) a semantic grounding scheme toalign the emergent language with the natural language of theinstruction-following benchmark. We show that the referential game's agentsmake an artificial language emerge that is aligned with the natural-likelanguage used to describe goals in the BabyAI benchmark and that it isexpressive enough so as to also describe unsuccessful RL trajectories and thusprovide feedback to the RL agent to leverage the linguistic, structuredinformation contained in all trajectories. Our work shows that EC is a viableunsupervised auxiliary task for RL and provides missing pieces to make HER morewidely applicable.</description><author>Kevin Denamganaï, Daniel Hernandez, Ozan Vardal, Sondess Missaoui, James Alfred Walker</author><pubDate>Fri, 28 Jul 2023 12:42:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15494v1</guid></item><item><title>The timing bottleneck: Why timing and overlap are mission-critical for conversational user interfaces, speech recognition and dialogue systems</title><link>http://arxiv.org/abs/2307.15493v1</link><description>Speech recognition systems are a key intermediary in voice-drivenhuman-computer interaction. Although speech recognition works well for pristinemonologic audio, real-life use cases in open-ended interactive settings stillpresent many challenges. We argue that timing is mission-critical for dialoguesystems, and evaluate 5 major commercial ASR systems for their conversationaland multilingual support. We find that word error rates for naturalconversational data in 6 languages remain abysmal, and that overlap remains akey challenge (study 1). This impacts especially the recognition ofconversational words (study 2), and in turn has dire consequences fordownstream intent recognition (study 3). Our findings help to evaluate thecurrent state of conversational ASR, contribute towards multidimensional erroranalysis and evaluation, and identify phenomena that need most attention on theway to build robust interactive speech technologies.</description><author>Andreas Liesenfeld, Alianda Lopez, Mark Dingemanse</author><pubDate>Fri, 28 Jul 2023 12:38:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15493v1</guid></item><item><title>A Semantic Approach to Decidability in Epistemic Planning (Extended Version)</title><link>http://arxiv.org/abs/2307.15485v1</link><description>The use of Dynamic Epistemic Logic (DEL) in multi-agent planning has led to awidely adopted action formalism that can handle nondeterminism, partialobservability and arbitrary knowledge nesting. As such expressive power comesat the cost of undecidability, several decidable fragments have been isolated,mainly based on syntactic restrictions of the action formalism. In this paper,we pursue a novel semantic approach to achieve decidability. Namely, ratherthan imposing syntactical constraints, the semantic approach focuses on theaxioms of the logic for epistemic planning. Specifically, we augment the logicof knowledge S5$_n$ and with an interaction axiom called (knowledge)commutativity, which controls the ability of agents to unboundedly reason onthe knowledge of other agents. We then provide a threefold contribution. First,we show that the resulting epistemic planning problem is decidable. In doingso, we prove that our framework admits a finitary non-fixpoint characterizationof common knowledge, which is of independent interest. Second, we studydifferent generalizations of the commutativity axiom, with the goal ofobtaining decidability for more expressive fragments of DEL. Finally, we showthat two well-known epistemic planning systems based on action templates, wheninterpreted under the setting of knowledge, conform to the commutativity axiom,hence proving their decidability.</description><author>Alessandro Burigana, Paolo Felli, Marco Montali, Nicolas Troquard</author><pubDate>Fri, 28 Jul 2023 12:26:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15485v1</guid></item><item><title>Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding</title><link>http://arxiv.org/abs/2307.15484v1</link><description>Recently, there has been a growing interest in text-to-speech (TTS) methodsthat can be trained with minimal supervision by combining two types of discretespeech representations and using two sequence-to-sequence tasks to decoupleTTS. To address the challenges associated with high dimensionality and waveformdistortion in discrete representations, we propose Diff-LM-Speech, which modelssemantic embeddings into mel-spectrogram based on diffusion models andintroduces a prompt encoder structure based on variational autoencoders andprosody bottlenecks to improve prompt representation capabilities.Autoregressive language models often suffer from missing and repeated words,while non-autoregressive frameworks face expression averaging problems due toduration prediction models. To address these issues, we proposeTetra-Diff-Speech, which designs a duration diffusion model to achieve diverseprosodic expressions. While we expect the information content of semanticcoding to be between that of text and acoustic coding, existing models extractsemantic coding with a lot of redundant information and dimensionalityexplosion. To verify that semantic coding is not necessary, we proposeTri-Diff-Speech. Experimental results show that our proposed methods outperformbaseline methods. We provide a website with audio samples.</description><author>Chunyu Qiang, Hao Li, Hao Ni, He Qu, Ruibo Fu, Tao Wang, Longbiao Wang, Jianwu Dang</author><pubDate>Fri, 28 Jul 2023 12:20:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15484v1</guid></item><item><title>Non-invasive Diabetes Detection using Gabor Filter: A Comparative Analysis of Different Cameras</title><link>http://arxiv.org/abs/2307.15480v1</link><description>This paper compares and explores the performance of both mobile device cameraand laptop camera as convenient tool for capturing images for non-invasivedetection of Diabetes Mellitus (DM) using facial block texture features.Participants within age bracket 20 to 79 years old were chosen for the dataset.12mp and 7mp mobile cameras, and a laptop camera were used to take the photounder normal lighting condition. Extracted facial blocks were classified usingk-Nearest Neighbors (k-NN) and Support Vector Machine (SVM). 100 images werecaptured, preprocessed, filtered using Gabor, and iterated. Performance of thesystem was measured in terms of accuracy, specificity, and sensitivity. Bestperformance of 96.7% accuracy, 100% sensitivity, and 93% specificity wereachieved from 12mp back camera using SVM with 100 images.</description><author>Christina A. Garcia, Patricia Angela R. Abu, Rosula SJ. Reyes</author><pubDate>Fri, 28 Jul 2023 12:08:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15480v1</guid></item><item><title>Local and Global Information in Obstacle Detection on Railway Tracks</title><link>http://arxiv.org/abs/2307.15478v1</link><description>Reliable obstacle detection on railways could help prevent collisions thatresult in injuries and potentially damage or derail the train. Unfortunately,generic object detectors do not have enough classes to account for all possiblescenarios, and datasets featuring objects on railways are challenging toobtain. We propose utilizing a shallow network to learn railway segmentationfrom normal railway images. The limited receptive field of the network preventsoverconfident predictions and allows the network to focus on the locally verydistinct and repetitive patterns of the railway environment. Additionally, weexplore the controlled inclusion of global information by learning tohallucinate obstacle-free images. We evaluate our method on a custom datasetfeaturing railway images with artificially augmented obstacles. Our proposedmethod outperforms other learning-based baseline methods.</description><author>Matthias Brucker, Andrei Cramariuc, Cornelius von Einem, Roland Siegwart, Cesar Cadena</author><pubDate>Fri, 28 Jul 2023 12:07:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15478v1</guid></item><item><title>Solving Data Quality Problems with Desbordante: a Demo</title><link>http://arxiv.org/abs/2307.14935v2</link><description>Data profiling is an essential process in modern data-driven industries. Oneof its critical components is the discovery and validation of complexstatistics, including functional dependencies, data constraints, associationrules, and others. However, most existing data profiling systems that focus on complexstatistics do not provide proper integration with the tools used bycontemporary data scientists. This creates a significant barrier to theadoption of these tools in the industry. Moreover, existing systems were notcreated with industrial-grade workloads in mind. Finally, they do not aim toprovide descriptive explanations, i.e. why a given pattern is not found. It isa significant issue as it is essential to understand the underlying reasons fora specific pattern's absence to make informed decisions based on the data. Because of that, these patterns are effectively rest in thin air: theirapplication scope is rather limited, they are rarely used by the broaderpublic. At the same time, as we are going to demonstrate in this presentation,complex statistics can be efficiently used to solve many classic data qualityproblems. Desbordante is an open-source data profiler that aims to close this gap. Itis built with emphasis on industrial application: it is efficient, scalable,resilient to crashes, and provides explanations. Furthermore, it providesseamless Python integration by offloading various costly operations to the C++core, not only mining. In this demonstration, we show several scenarios that allow end users tosolve different data quality problems. Namely, we showcase typo detection, datadeduplication, and data anomaly detection scenarios.</description><author>George Chernishev, Michael Polyntsov, Anton Chizhov, Kirill Stupakov, Ilya Shchuckin, Alexander Smirnov, Maxim Strutovsky, Alexey Shlyonskikh, Mikhail Firsov, Stepan Manannikov, Nikita Bobrov, Daniil Goncharov, Ilia Barutkin, Vladislav Shalnev, Kirill Muraviev, Anna Rakhmukova, Dmitriy Shcheka, Anton Chernikov, Mikhail Vyrodov, Yaroslav Kurbatov, Maxim Fofanov, Sergei Belokonnyi, Pavel Anosov, Arthur Saliou, Eduard Gaisin, Kirill Smirnov</author><pubDate>Fri, 28 Jul 2023 12:02:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14935v2</guid></item><item><title>FeedbackLogs: Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines</title><link>http://arxiv.org/abs/2307.15475v1</link><description>Even though machine learning (ML) pipelines affect an increasing array ofstakeholders, there is little work on how input from stakeholders is recordedand incorporated. We propose FeedbackLogs, addenda to existing documentation ofML pipelines, to track the input of multiple stakeholders. Each log recordsimportant details about the feedback collection process, the feedback itself,and how the feedback is used to update the ML pipeline. In this paper, weintroduce and formalise a process for collecting a FeedbackLog. We also provideconcrete use cases where FeedbackLogs can be employed as evidence foralgorithmic auditing and as a tool to record updates based on stakeholderfeedback.</description><author>Matthew Barker, Emma Kallina, Dhananjay Ashok, Katherine M. Collins, Ashley Casovan, Adrian Weller, Ameet Talwalkar, Valerie Chen, Umang Bhatt</author><pubDate>Fri, 28 Jul 2023 12:00:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15475v1</guid></item><item><title>Dynamic Silos: Increased Modularity in Intra-organizational Communication Networks during the Covid-19 Pandemic</title><link>http://arxiv.org/abs/2104.00641v6</link><description>Workplace communications around the world were drastically altered byCovid-19, related work-from-home orders, and the rise of remote work. Tounderstand these shifts, we analyzed aggregated, anonymized metadata from over360 billion emails within 4,361 organizations worldwide. By comparingmonth-to-month and year-over-year metrics, we examined changes in networkcommunity structures over 24 months before and after Covid-19. We also examinedshifts across multiple communication media (email, instant messages, videocalls, and calendaring software) within a single global organization, andcompared them to communications shifts that were driven by changes in formalorganizational structure. We found that, in 2020, organizations around theworld became more siloed than in 2019, evidenced by increased modularity. Thisshift was concurrent with decreased stability within silos. Collectively, ouranalyses indicate that following the onset of Covid-19, employees began toshift more dynamically between subcommunities (teams, workgroups or functionalareas). At the same time, once in a subcommunity, they limited theircommunication to other members of that community. We term these network changesdynamic silos. We provide initial insights into the meaning and implications ofdynamic silos for the future of work.</description><author>Tiona Zuzul, Emily Cox Pahnke, Jonathan Larson, Patrick Bourke, Nicholas Caurvina, Neha Parikh Shah, Fereshteh Amini, Jeffrey Weston, Youngser Park, Joshua Vogelstein, Christopher White, Carey E. Priebe</author><pubDate>Fri, 28 Jul 2023 11:58:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2104.00641v6</guid></item><item><title>FACT: Federated Adversarial Cross Training</title><link>http://arxiv.org/abs/2306.00607v2</link><description>Federated Learning (FL) facilitates distributed model development toaggregate multiple confidential data sources. The information transfer amongclients can be compromised by distributional differences, i.e., by non-i.i.d.data. A particularly challenging scenario is the federated model adaptation toa target client without access to annotated data. We propose FederatedAdversarial Cross Training (FACT), which uses the implicit domain differencesbetween source clients to identify domain shifts in the target domain. In eachround of FL, FACT cross initializes a pair of source clients to generate domainspecialized representations which are then used as a direct adversary to learna domain invariant data representation. We empirically show that FACToutperforms state-of-the-art federated, non-federated and source-free domainadaptation models on three popular multi-source-single-target benchmarks, andstate-of-the-art Unsupervised Domain Adaptation (UDA) models onsingle-source-single-target experiments. We further study FACT's behavior withrespect to communication restrictions and the number of participating clients.</description><author>Stefan Schrod, Jonas Lippl, Andreas Schäfer, Michael Altenbuchinger</author><pubDate>Fri, 28 Jul 2023 11:57:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00607v2</guid></item><item><title>Dynamic Feature-based Deep Reinforcement Learning for Flow Control of Circular Cylinder with Sparse Surface Pressure Sensing</title><link>http://arxiv.org/abs/2307.01995v2</link><description>This study proposes a self-learning algorithm for closed-loop cylinder wakecontrol targeting lower drag and lower lift fluctuations with the additionalchallenge of sparse sensor information, taking deep reinforcement learning asthe starting point. DRL performance is significantly improved by lifting thesensor signals to dynamic features (DF), which predict future flow states. Theresulting dynamic feature-based DRL (DF-DRL) automatically learns a feedbackcontrol in the plant without a dynamic model. Results show that the dragcoefficient of the DF-DRL model is 25% less than the vanilla model based ondirect sensor feedback. More importantly, using only one surface pressuresensor, DF-DRL can reduce the drag coefficient to a state-of-the-artperformance of about 8% at Re = 100 and significantly mitigate lift coefficientfluctuations. Hence, DF-DRL allows the deployment of sparse sensing of the flowwithout degrading the control performance. This method also shows goodrobustness in controlling flow under higher Reynolds numbers, which reduces thedrag coefficient by 32.2% and 46.55% at Re = 500 and 1000, respectively,indicating the broad applicability of the method. Since surface pressureinformation is more straightforward to measure in realistic scenarios than flowvelocity information, this study provides a valuable reference forexperimentally designing the active flow control of a circular cylinder basedon wall pressure signals, which is an essential step toward further developingintelligent control in realistic multi-input multi-output (MIMO) system.</description><author>Qiulei Wang, Lei Yan, Gang Hu, Wenli Chen, Bernd R. Noack</author><pubDate>Fri, 28 Jul 2023 11:55:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01995v2</guid></item><item><title>3M3D: Multi-view, Multi-path, Multi-representation for 3D Object Detection</title><link>http://arxiv.org/abs/2302.08231v3</link><description>3D visual perception tasks based on multi-camera images are essential forautonomous driving systems. Latest work in this field performs 3D objectdetection by leveraging multi-view images as an input and iteratively enhancingobject queries (object proposals) by cross-attending multi-view features.However, individual backbone features are not updated with multi-view featuresand it stays as a mere collection of the output of the single-image backbonenetwork. Therefore we propose 3M3D: A Multi-view, Multi-path,Multi-representation for 3D Object Detection where we update both multi-viewfeatures and query features to enhance the representation of the scene in bothfine panoramic view and coarse global view. Firstly, we update multi-viewfeatures by multi-view axis self-attention. It will incorporate panoramicinformation in the multi-view features and enhance understanding of the globalscene. Secondly, we update multi-view features by self-attention of the ROI(Region of Interest) windows which encodes local finer details in the features.It will help exchange the information not only along the multi-view axis butalso along the other spatial dimension. Lastly, we leverage the fact ofmulti-representation of queries in different domains to further boost theperformance. Here we use sparse floating queries along with dense BEV (Bird'sEye View) queries, which are later post-processed to filter duplicatedetections. Moreover, we show performance improvements on nuScenes benchmarkdataset on top of our baselines.</description><author>Jongwoo Park, Apoorv Singh, Varun Bankiti</author><pubDate>Fri, 28 Jul 2023 11:51:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08231v3</guid></item><item><title>Towards Generalizable Deepfake Detection by Primary Region Regularization</title><link>http://arxiv.org/abs/2307.12534v2</link><description>The existing deepfake detection methods have reached a bottleneck ingeneralizing to unseen forgeries and manipulation approaches. Based on theobservation that the deepfake detectors exhibit a preference for overfittingthe specific primary regions in input, this paper enhances the generalizationcapability from a novel regularization perspective. This can be simply achievedby augmenting the images through primary region removal, thereby preventing thedetector from over-relying on data bias. Our method consists of two stages,namely the static localization for primary region maps, as well as the dynamicexploitation of primary region masks. The proposed method can be seamlesslyintegrated into different backbones without affecting their inferenceefficiency. We conduct extensive experiments over three widely used deepfakedatasets - DFDC, DF-1.0, and Celeb-DF with five backbones. Our methoddemonstrates an average performance improvement of 6% across differentbackbones and performs competitively with several state-of-the-art baselines.</description><author>Harry Cheng, Yangyang Guo, Tianyi Wang, Liqiang Nie, Mohan Kankanhalli</author><pubDate>Fri, 28 Jul 2023 11:45:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12534v2</guid></item><item><title>LUCID-GAN: Conditional Generative Models to Locate Unfairness</title><link>http://arxiv.org/abs/2307.15466v1</link><description>Most group fairness notions detect unethical biases by computing statisticalparity metrics on a model's output. However, this approach suffers from severalshortcomings, such as philosophical disagreement, mutual incompatibility, andlack of interpretability. These shortcomings have spurred the research oncomplementary bias detection methods that offer additional transparency intothe sources of discrimination and are agnostic towards an a priori decision onthe definition of fairness and choice of protected features. A recent proposalin this direction is LUCID (Locating Unfairness through Canonical InverseDesign), where canonical sets are generated by performing gradient descent onthe input space, revealing a model's desired input given a preferred output.This information about the model's mechanisms, i.e., which feature values areessential to obtain specific outputs, allows exposing potential unethicalbiases in its internal logic. Here, we present LUCID-GAN, which generatescanonical inputs via a conditional generative model instead of gradient-basedinverse design. LUCID-GAN has several benefits, including that it applies tonon-differentiable models, ensures that canonical sets consist of realisticinputs, and allows to assess proxy and intersectional discrimination. Weempirically evaluate LUCID-GAN on the UCI Adult and COMPAS data sets and showthat it allows for detecting unethical biases in black-box models withoutrequiring access to the training data.</description><author>Andres Algaba, Carmen Mazijn, Carina Prunkl, Jan Danckaert, Vincent Ginis</author><pubDate>Fri, 28 Jul 2023 11:37:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15466v1</guid></item><item><title>SACReg: Scene-Agnostic Coordinate Regression for Visual Localization</title><link>http://arxiv.org/abs/2307.11702v2</link><description>Scene coordinates regression (SCR), i.e., predicting 3D coordinates for everypixel of a given image, has recently shown promising potential. However,existing methods remain mostly scene-specific or limited to small scenes andthus hardly scale to realistic datasets. In this paper, we propose a newparadigm where a single generic SCR model is trained once to be then deployedto new test scenes, regardless of their scale and without further finetuning.For a given query image, it collects inputs from off-the-shelf image retrievaltechniques and Structure-from-Motion databases: a list of relevant databaseimages with sparse pointwise 2D-3D annotations. The model is based on thetransformer architecture and can take a variable number of images and sparse2D-3D annotations as input. It is trained on a few diverse datasets andsignificantly outperforms other scene regression approaches on severalbenchmarks, including scene-specific models, for visual localization. Inparticular, we set a new state of the art on the Cambridge localizationbenchmark, even outperforming feature-matching-based approaches.</description><author>Jerome Revaud, Yohann Cabon, Romain Brégier, JongMin Lee, Philippe Weinzaepfel</author><pubDate>Fri, 28 Jul 2023 11:36:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11702v2</guid></item><item><title>Post-Episodic Reinforcement Learning Inference</title><link>http://arxiv.org/abs/2302.08854v2</link><description>We consider estimation and inference with data collected from episodicreinforcement learning (RL) algorithms; i.e. adaptive experimentationalgorithms that at each period (aka episode) interact multiple times in asequential manner with a single treated unit. Our goal is to be able toevaluate counterfactual adaptive policies after data collection and to estimatestructural parameters such as dynamic treatment effects, which can be used forcredit assignment (e.g. what was the effect of the first period action on thefinal outcome). Such parameters of interest can be framed as solutions tomoment equations, but not minimizers of a population loss function, leading to$Z$-estimation approaches in the case of static data. However, such estimatorsfail to be asymptotically normal in the case of adaptive data collection. Wepropose a re-weighted $Z$-estimation approach with carefully designed adaptiveweights to stabilize the episode-varying estimation variance, which resultsfrom the nonstationary policy that typical episodic RL algorithms invoke. Weidentify proper weighting schemes to restore the consistency and asymptoticnormality of the re-weighted Z-estimators for target parameters, which allowsfor hypothesis testing and constructing uniform confidence regions for targetparameters of interest. Primary applications include dynamic treatment effectestimation and dynamic off-policy evaluation.</description><author>Vasilis Syrgkanis, Ruohan Zhan</author><pubDate>Fri, 28 Jul 2023 11:33:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08854v2</guid></item><item><title>Defocus Blur Synthesis and Deblurring via Interpolation and Extrapolation in Latent Space</title><link>http://arxiv.org/abs/2307.15461v1</link><description>Though modern microscopes have an autofocusing system to ensure optimalfocus, out-of-focus images can still occur when cells within the medium are notall in the same focal plane, affecting the image quality for medical diagnosisand analysis of diseases. We propose a method that can deblur images as well assynthesize defocus blur. We train autoencoders with implicit and explicitregularization techniques to enforce linearity relations among therepresentations of different blur levels in the latent space. This allows forthe exploration of different blur levels of an object by linearlyinterpolating/extrapolating the latent representations of images taken atdifferent focal planes. Compared to existing works, we use a simplearchitecture to synthesize images with flexible blur levels, leveraging thelinear latent space. Our regularized autoencoders can effectively mimic blurand deblur, increasing data variety as a data augmentation technique andimproving the quality of microscopic images, which would be beneficial forfurther processing and analysis.</description><author>Ioana Mazilu, Shunxin Wang, Sven Dummer, Raymond Veldhuis, Christoph Brune, Nicola Strisciuglio</author><pubDate>Fri, 28 Jul 2023 11:27:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15461v1</guid></item><item><title>Cross-Modal Concept Learning and Inference for Vision-Language Models</title><link>http://arxiv.org/abs/2307.15460v1</link><description>Large-scale pre-trained Vision-Language Models (VLMs), such as CLIP,establish the correlation between texts and images, achieving remarkablesuccess on various downstream tasks with fine-tuning. In existing fine-tuningmethods, the class-specific text description is matched against the wholeimage. We recognize that this whole image matching is not effective sinceimages from the same class often contain a set of different semantic objects,and an object further consists of a set of semantic parts or concepts.Individual semantic parts or concepts may appear in image samples fromdifferent classes. To address this issue, in this paper, we develop a newmethod called cross-model concept learning and inference (CCLI). Using thepowerful text-image correlation capability of CLIP, our method automaticallylearns a large set of distinctive visual concepts from images using a set ofsemantic text concepts. Based on these visual concepts, we construct adiscriminative representation of images and learn a concept inference networkto perform downstream image classification tasks, such as few-shot learning anddomain generalization. Extensive experimental results demonstrate that our CCLImethod is able to improve the performance upon the current state-of-the-artmethods by large margins, for example, by up to 8.0% improvement on few-shotlearning and by up to 1.3% for domain generalization.</description><author>Yi Zhang, Ce Zhang, Yushun Tang, Zhihai He</author><pubDate>Fri, 28 Jul 2023 11:26:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15460v1</guid></item><item><title>A Deep Learning Approach for Overall Survival Prediction in Lung Cancer with Missing Values</title><link>http://arxiv.org/abs/2307.11465v3</link><description>One of the most challenging fields where Artificial Intelligence (AI) can beapplied is lung cancer research, specifically non-small cell lung cancer(NSCLC). In particular, overall survival (OS), the time between diagnosis anddeath, is a vital indicator of patient status, enabling tailored treatment andimproved OS rates. In this analysis, there are two challenges to take intoaccount. First, few studies effectively exploit the information available fromeach patient, leveraging both uncensored (i.e., dead) and censored (i.e.,survivors) patients, considering also the events' time. Second, the handling ofincomplete data is a common issue in the medical field. This problem istypically tackled through the use of imputation methods. Our objective is topresent an AI model able to overcome these limits, effectively learning fromboth censored and uncensored patients and their available features, for theprediction of OS for NSCLC patients. We present a novel approach to survivalanalysis with missing values in the context of NSCLC, which exploits thestrengths of the transformer architecture to account only for availablefeatures without requiring any imputation strategy. By making use of ad-hoclosses for OS, it is able to account for both censored and uncensored patients,as well as changes in risks over time. We compared our method withstate-of-the-art models for survival analysis coupled with different imputationstrategies. We evaluated the results obtained over a period of 6 years usingdifferent time granularities obtaining a Ct-index, a time-dependent variant ofthe C-index, of 71.97, 77.58 and 80.72 for time units of 1 month, 1 year and 2years, respectively, outperforming all state-of-the-art methods regardless ofthe imputation method used.</description><author>Camillo Maria Caruso, Valerio Guarrasi, Sara Ramella, Paolo Soda</author><pubDate>Fri, 28 Jul 2023 11:20:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11465v3</guid></item><item><title>Worrisome Properties of Neural Network Controllers and Their Symbolic Representations</title><link>http://arxiv.org/abs/2307.15456v1</link><description>We raise concerns about controllers' robustness in simple reinforcementlearning benchmark problems. We focus on neural network controllers and theirlow neuron and symbolic abstractions. A typical controller reaching high meanreturn values still generates an abundance of persistent low-return solutions,which is a highly undesirable property, easily exploitable by an adversary. Wefind that the simpler controllers admit more persistent bad solutions. Weprovide an algorithm for a systematic robustness study and prove existence ofpersistent solutions and, in some cases, periodic orbits, using acomputer-assisted proof methodology.</description><author>Jacek Cyranka, Kevin E M Church, Jean-Philippe Lessard</author><pubDate>Fri, 28 Jul 2023 11:20:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15456v1</guid></item><item><title>Hybrid Open-set Segmentation with Synthetic Negative Data</title><link>http://arxiv.org/abs/2301.08555v2</link><description>Open-set segmentation is often conceived by complementing closed-setclassification with anomaly detection. Existing dense anomaly detectors operateeither through generative modelling of regular training data or bydiscriminating with respect to negative training data. These two approachesoptimize different objectives and therefore exhibit different failure modes.Consequently, we propose the first dense hybrid anomaly score that fusesgenerative and discriminative cues. The proposed score can be efficientlyimplemented by upgrading any semantic segmentation model with dense estimatesof data likelihood and dataset posterior. Our design is a remarkably good fitfor efficient inference on large images due to negligible computationaloverhead over the closed-set baseline. The resulting dense hybrid open-setmodels require negative training images that can be sampled from an auxiliarynegative dataset, from a jointly trained generative model, or from a mixture ofboth sources. We evaluate our contributions on benchmarks for dense anomalydetection and open-set segmentation. The experiments reveal strong open-setperformance in spite of negligible computational overhead.</description><author>Matej Grcić, Siniša Šegvić</author><pubDate>Fri, 28 Jul 2023 11:18:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.08555v2</guid></item><item><title>Trie-NLG: Trie Context Augmentation to Improve Personalized Query Auto-Completion for Short and Unseen Prefixes</title><link>http://arxiv.org/abs/2307.15455v1</link><description>Query auto-completion (QAC) aims at suggesting plausible completions for agiven query prefix. Traditionally, QAC systems have leveraged tries curatedfrom historical query logs to suggest most popular completions. In thiscontext, there are two specific scenarios that are difficult to handle for anyQAC system: short prefixes (which are inherently ambiguous) and unseenprefixes. Recently, personalized Natural Language Generation (NLG) models havebeen proposed to leverage previous session queries as context for addressingthese two challenges. However, such NLG models suffer from two drawbacks: (1)some of the previous session queries could be noisy and irrelevant to the userintent for the current prefix, and (2) NLG models cannot directly incorporatehistorical query popularity. This motivates us to propose a novel NLG model forQAC, Trie-NLG, which jointly leverages popularity signals from trie andpersonalization signals from previous session queries. We train the Trie-NLGmodel by augmenting the prefix with rich context comprising of recent sessionqueries and top trie completions. This simple modeling approach overcomes thelimitations of trie-based and NLG-based approaches and leads tostate-of-the-art performance. We evaluate the Trie-NLG model using two largeQAC datasets. On average, our model achieves huge ~57% and ~14% boost in MRRover the popular trie-based lookup and the strong BART-based baseline methods,respectively. We make our code publicly available.</description><author>Kaushal Kumar Maurya, Maunendra Sankar Desarkar, Manish Gupta, Puneet Agrawal</author><pubDate>Fri, 28 Jul 2023 11:17:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15455v1</guid></item><item><title>A Conditional Flow Variational Autoencoder for Controllable Synthesis of Virtual Populations of Anatomy</title><link>http://arxiv.org/abs/2306.14680v2</link><description>The generation of virtual populations (VPs) of anatomy is essential forconducting in silico trials of medical devices. Typically, the generated VPshould capture sufficient variability while remaining plausible and shouldreflect the specific characteristics and demographics of the patients observedin real populations. In several applications, it is desirable to synthesisevirtual populations in a \textit{controlled} manner, where relevant covariatesare used to conditionally synthesise virtual populations that fit a specifictarget population/characteristics. We propose to equip a conditionalvariational autoencoder (cVAE) with normalising flows to boost the flexibilityand complexity of the approximate posterior learnt, leading to enhancedflexibility for controllable synthesis of VPs of anatomical structures. Wedemonstrate the performance of our conditional flow VAE using a data set ofcardiac left ventricles acquired from 2360 patients, with associateddemographic information and clinical measurements (used ascovariates/conditional information). The results obtained indicate thesuperiority of the proposed method for conditional synthesis of virtualpopulations of cardiac left ventricles relative to a cVAE. Conditionalsynthesis performance was evaluated in terms of generalisation and specificityerrors and in terms of the ability to preserve clinically relevant biomarkersin synthesised VPs, that is, the left ventricular blood pool and myocardialvolume, relative to the real observed population.</description><author>Haoran Dou, Nishant Ravikumar, Alejandro F. Frangi</author><pubDate>Fri, 28 Jul 2023 11:11:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14680v2</guid></item><item><title>From Probabilistic Programming to Complexity-based Programming</title><link>http://arxiv.org/abs/2307.15453v1</link><description>The paper presents the main characteristics and a preliminary implementationof a novel computational framework named CompLog. Inspired by probabilisticprogramming systems like ProbLog, CompLog builds upon the inferentialmechanisms proposed by Simplicity Theory, relying on the computation of twoKolmogorov complexities (here implemented as min-path searches via ASPprograms) rather than probabilistic inference. The proposed system enablesusers to compute ex-post and ex-ante measures of unexpectedness of a certainsituation, mapping respectively to posterior and prior subjectiveprobabilities. The computation is based on the specification of world andmental models by means of causal and descriptive relations between predicatesweighted by complexity. The paper illustrates a few examples of application:generating relevant descriptions, and providing alternative approaches todisjunction and to negation.</description><author>Giovanni Sileno, Jean-Louis Dessalles</author><pubDate>Fri, 28 Jul 2023 11:11:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15453v1</guid></item><item><title>DELPHIC: Practical DEL Planning via Possibilities (Extended Version)</title><link>http://arxiv.org/abs/2307.15451v1</link><description>Dynamic Epistemic Logic (DEL) provides a framework for epistemic planningthat is capable of representing non-deterministic actions, partialobservability, higher-order knowledge and both factual and epistemic change.The high expressivity of DEL challenges existing epistemic planners, whichtypically can handle only restricted fragments of the whole framework. The goalof this work is to push the envelop of practical DEL planning, ultimatelyaiming for epistemic planners to be able to deal with the full range offeatures offered by DEL. Towards this goal, we question the traditionalsemantics of DEL, defined in terms on Kripke models. In particular, we proposean equivalent semantics defined using, as main building block, so-calledpossibilities: non well-founded objects representing both factual properties ofthe world, and what agents consider to be possible. We call the resultingframework DELPHIC. We argue that DELPHIC indeed provides a more compactrepresentation of epistemic states. To substantiate this claim, we implementboth approaches in ASP and we set up an experimental evaluation to compareDELPHIC with the traditional, Kripke-based approach. The evaluation confirmsthat DELPHIC outperforms the traditional approach in space and time.</description><author>Alessandro Burigana, Paolo Felli, Marco Montali</author><pubDate>Fri, 28 Jul 2023 11:09:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15451v1</guid></item><item><title>ERCPMP: An Endoscopic Image and Video Dataset for Colorectal Polyps Morphology and Pathology</title><link>http://arxiv.org/abs/2307.15444v1</link><description>In the recent years, artificial intelligence (AI) and its leading subtypes,machine learning (ML) and deep learning (DL) and their applications arespreading very fast in various aspects such as medicine. Today the mostimportant challenge of developing accurate algorithms for medical prediction,detection, diagnosis, treatment and prognosis is data. ERCPMP is an EndoscopicImage and Video Dataset for Recognition of Colorectal Polyps Morphology andPathology. This dataset contains demographic, morphological and pathologicaldata, endoscopic images and videos of 191 patients with colorectal polyps.Morphological data is included based on the latest internationalgastroenterology classification references such as Paris, Pit and JNETclassification. Pathological data includes the diagnosis of the polypsincluding Tubular, Villous, Tubulovillous, Hyperplastic, Serrated, Inflammatoryand Adenocarcinoma with Dysplasia Grade &amp; Differentiation. The current versionof this dataset is published and available on Elsevier Mendeley Dataverse andsince it is under development, the latest version is accessible via:https://databiox.com.</description><author>Mojgan Forootan, Mohsen Rajabnia, Ahmad R Mafi, Hamed Azhdari Tehrani, Erfan Ghadirzadeh, Mahziar Setayeshfar, Zahra Ghaffari, Mohammad Tashakoripour, Mohammad Reza Zali, Hamidreza Bolhasani</author><pubDate>Fri, 28 Jul 2023 10:52:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15444v1</guid></item><item><title>Towards a performance analysis on pre-trained Visual Question Answering models for autonomous driving</title><link>http://arxiv.org/abs/2307.09329v2</link><description>This short paper presents a preliminary analysis of three popular VisualQuestion Answering (VQA) models, namely ViLBERT, ViLT, and LXMERT, in thecontext of answering questions relating to driving scenarios. The performanceof these models is evaluated by comparing the similarity of responses toreference answers provided by computer vision experts. Model selection ispredicated on the analysis of transformer utilization in multimodalarchitectures. The results indicate that models incorporating cross-modalattention and late fusion techniques exhibit promising potential for generatingimproved answers within a driving perspective. This initial analysis serves asa launchpad for a forthcoming comprehensive comparative study involving nineVQA models and sets the scene for further investigations into the effectivenessof VQA model queries in self-driving scenarios. Supplementary material isavailable athttps://github.com/KaavyaRekanar/Towards-a-performance-analysis-on-pre-trained-VQA-models-for-autonomous-driving.</description><author>Kaavya Rekanar, Ciarán Eising, Ganesh Sistu, Martin Hayes</author><pubDate>Fri, 28 Jul 2023 10:50:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09329v2</guid></item><item><title>Near Field iToF LIDAR Depth Improvement from Limited Number of Shots</title><link>http://arxiv.org/abs/2304.07047v2</link><description>Indirect Time of Flight LiDARs can indirectly calculate the scene's depthfrom the phase shift angle between transmitted and received laser signals withamplitudes modulated at a predefined frequency. Unfortunately, this methodgenerates ambiguity in calculated depth when the phase shift angle valueexceeds $2\pi$. Current state-of-the-art methods use raw samples generatedusing two distinct modulation frequencies to overcome this ambiguity problem.However, this comes at the cost of increasing laser components' stress andraising their temperature, which reduces their lifetime and increases powerconsumption. In our work, we study two different methods to recover the entiredepth range of the LiDAR using fewer raw data sample shots from a singlemodulation frequency with the support of sensor's gray scale output to reducethe laser components' stress and power consumption.</description><author>Mena Nagiub, Thorsten Beuth, Ganesh Sistu, Heinrich Gotzig, Ciarán Eising</author><pubDate>Fri, 28 Jul 2023 10:50:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.07047v2</guid></item><item><title>Optimal Alignment of Temporal Knowledge Bases</title><link>http://arxiv.org/abs/2307.15439v1</link><description>Answering temporal CQs over temporalized Description Logic knowledge bases(TKB) is a main technique to realize ontology-based situation recognition. Incase the collected data in such a knowledge base is inaccurate, important queryanswers can be missed. In this paper we introduce the TKB Alignment problem,which computes a variant of the TKB that minimally changes the TKB, but entailsthe given temporal CQ and is in that sense (cost-)optimal. We investigate thisproblem for ALC TKBs and conjunctive queries with LTL operators and devise asolution technique to compute (cost-optimal) alignments of TKBs that extendstechniques for the alignment problem for propositional LTL over finite traces.</description><author>Oliver Fernandez-Gil, Fabio Patrizi, Giuseppe Perelli, Anni-Yasmin Turhan</author><pubDate>Fri, 28 Jul 2023 10:42:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15439v1</guid></item></channel></rss>