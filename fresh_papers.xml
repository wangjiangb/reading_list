<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 21 Nov 2024 13:00:22 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>AI-generated Image Detection: Passive or Watermark?</title><link>http://arxiv.org/abs/2411.13553v1</link><description>While text-to-image models offer numerous benefits, they also posesignificant societal risks. Detecting AI-generated images is crucial formitigating these risks. Detection methods can be broadly categorized intopassive and watermark-based approaches: passive detectors rely on artifactspresent in AI-generated images, whereas watermark-based detectors proactivelyembed watermarks into such images. A key question is which type of detectorperforms better in terms of effectiveness, robustness, and efficiency. However,the current literature lacks a comprehensive understanding of this issue. Inthis work, we aim to bridge that gap by developing ImageDetectBench, the firstcomprehensive benchmark to compare the effectiveness, robustness, andefficiency of passive and watermark-based detectors. Our benchmark includesfour datasets, each containing a mix of AI-generated and non-AI-generatedimages. We evaluate five passive detectors and four watermark-based detectorsagainst eight types of common perturbations and three types of adversarialperturbations. Our benchmark results reveal several interesting findings. Forinstance, watermark-based detectors consistently outperform passive detectors,both in the presence and absence of perturbations. Based on these insights, weprovide recommendations for detecting AI-generated images, e.g., when bothtypes of detectors are applicable, watermark-based detectors should be thepreferred choice.</description><author>Moyang Guo, Yuepeng Hu, Zhengyuan Jiang, Zeyu Li, Amir Sadovnik, Arka Daw, Neil Gong</author><pubDate>Wed, 20 Nov 2024 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13553v1</guid></item><item><title>REDUCIO! Generating 1024$\times$1024 Video within 16 Seconds using Extremely Compressed Motion Latents</title><link>http://arxiv.org/abs/2411.13552v1</link><description>Commercial video generation models have exhibited realistic, high-fidelityresults but are still restricted to limited access. One crucial obstacle forlarge-scale applications is the expensive training and inference cost. In thispaper, we argue that videos contain much more redundant information thanimages, thus can be encoded by very few motion latents based on a contentimage. Towards this goal, we design an image-conditioned VAE to encode a videoto an extremely compressed motion latent space. This magic Reducio charmenables 64x reduction of latents compared to a common 2D VAE, withoutsacrificing the quality. Training diffusion models on such a compactrepresentation easily allows for generating 1K resolution videos. We then adopta two-stage video generation paradigm, which performs text-to-image andtext-image-to-video sequentially. Extensive experiments show that ourReducio-DiT achieves strong performance in evaluation, though trained withlimited GPU resources. More importantly, our method significantly boost theefficiency of video LDMs both in training and inference. We train Reducio-DiTin around 3.2K training hours in total and generate a 16-frame 1024*1024 videoclip within 15.5 seconds on a single A100 GPU. Code released athttps://github.com/microsoft/Reducio-VAE .</description><author>Rui Tian, Qi Dai, Jianmin Bao, Kai Qiu, Yifan Yang, Chong Luo, Zuxuan Wu, Yu-Gang Jiang</author><pubDate>Wed, 20 Nov 2024 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13552v1</guid></item><item><title>Leveraging Hierarchical Taxonomies in Prompt-based Continual Learning</title><link>http://arxiv.org/abs/2410.04327v2</link><description>Drawing inspiration from human learning behaviors, this work proposes a novelapproach to mitigate catastrophic forgetting in Prompt-based Continual Learningmodels by exploiting the relationships between continuously emerging classdata. We find that applying human habits of organizing and connectinginformation can serve as an efficient strategy when training deep learningmodels. Specifically, by building a hierarchical tree structure based on theexpanding set of labels, we gain fresh insights into the data, identifyinggroups of similar classes could easily cause confusion. Additionally, we delvedeeper into the hidden connections between classes by exploring the originalpretrained model's behavior through an optimal transport-based approach. Fromthese insights, we propose a novel regularization loss function that encouragesmodels to focus more on challenging knowledge areas, thereby enhancing overallperformance. Experimentally, our method demonstrated significant superiorityover the most robust state-of-the-art models on various benchmarks.</description><author>Quyen Tran, Hoang Phan, Minh Le, Tuan Truong, Dinh Phung, Linh Ngo, Thien Nguyen, Nhat Ho, Trung Le</author><pubDate>Wed, 20 Nov 2024 18:59:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.04327v2</guid></item><item><title>Find Any Part in 3D</title><link>http://arxiv.org/abs/2411.13550v1</link><description>We study open-world part segmentation in 3D: segmenting any part in anyobject based on any text query. Prior methods are limited in object categoriesand part vocabularies. Recent advances in AI have demonstrated effectiveopen-world recognition capabilities in 2D. Inspired by this progress, wepropose an open-world, direct-prediction model for 3D part segmentation thatcan be applied zero-shot to any object. Our approach, called Find3D, trains ageneral-category point embedding model on large-scale 3D assets from theinternet without any human annotation. It combines a data engine, powered byfoundation models for annotating data, with a contrastive training method. Weachieve strong performance and generalization across multiple datasets, with upto a 3x improvement in mIoU over the next best method. Our model is 6x to over300x faster than existing baselines. To encourage research in general-categoryopen-world 3D part segmentation, we also release a benchmark for generalobjects and parts. Project website: https://ziqi-ma.github.io/find3dsite/</description><author>Ziqi Ma, Yisong Yue, Georgia Gkioxari</author><pubDate>Wed, 20 Nov 2024 18:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13550v1</guid></item><item><title>Generating 3D-Consistent Videos from Unposed Internet Photos</title><link>http://arxiv.org/abs/2411.13549v1</link><description>We address the problem of generating videos from unposed internet photos. Ahandful of input images serve as keyframes, and our model interpolates betweenthem to simulate a path moving between the cameras. Given random images, amodel's ability to capture underlying geometry, recognize scene identity, andrelate frames in terms of camera position and orientation reflects afundamental understanding of 3D structure and scene layout. However, existingvideo models such as Luma Dream Machine fail at this task. We design aself-supervised method that takes advantage of the consistency of videos andvariability of multiview internet photos to train a scalable, 3D-aware videomodel without any 3D annotations such as camera parameters. We validate thatour method outperforms all baselines in terms of geometric and appearanceconsistency. We also show our model benefits applications that enable cameracontrol, such as 3D Gaussian Splatting. Our results suggest that we can scaleup scene-level 3D learning using only 2D data such as videos and multiviewinternet photos.</description><author>Gene Chou, Kai Zhang, Sai Bi, Hao Tan, Zexiang Xu, Fujun Luan, Bharath Hariharan, Noah Snavely</author><pubDate>Wed, 20 Nov 2024 18:58:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13549v1</guid></item><item><title>HF-Diff: High-Frequency Perceptual Loss and Distribution Matching for One-Step Diffusion-Based Image Super-Resolution</title><link>http://arxiv.org/abs/2411.13548v1</link><description>Although recent diffusion-based single-step super-resolution methods achievebetter performance as compared to SinSR, they are computationally complex. Toimprove the performance of SinSR, we investigate preserving the high-frequencydetail features during super-resolution (SR) because the downgraded images lackdetailed information. For this purpose, we introduce a high-frequencyperceptual loss by utilizing an invertible neural network (INN) pretrained onthe ImageNet dataset. Different feature maps of pretrained INN producedifferent high-frequency aspects of an image. During the training phase, weimpose to preserve the high-frequency features of super-resolved and groundtruth (GT) images that improve the SR image quality during inference.Furthermore, we also utilize the Jenson-Shannon divergence between GT and SRimages in the pretrained DINO-v2 embedding space to match their distribution.By introducing the $\textbf{h}igh$- $\textbf{f}requency$ preserving loss anddistribution matching constraint in the single-step $\textbf{diff}usion-based$SR ($\textbf{HF-Diff}$), we achieve a state-of-the-art CLIPIQA score in thebenchmark RealSR, RealSet65, DIV2K-Val, and ImageNet datasets. Furthermore, theexperimental results in several datasets demonstrate that our high-frequencyperceptual loss yields better SR image quality than LPIPS and VGG-basedperceptual losses. Our code will be released athttps://github.com/shoaib-sami/HF-Diff.</description><author>Shoaib Meraj Sami, Md Mahedi Hasan, Jeremy Dawson, Nasser Nasrabadi</author><pubDate>Wed, 20 Nov 2024 18:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13548v1</guid></item><item><title>SpecTool: A Benchmark for Characterizing Errors in Tool-Use LLMs</title><link>http://arxiv.org/abs/2411.13547v1</link><description>Evaluating the output of Large Language Models (LLMs) is one of the mostcritical aspects of building a performant compound AI system. Since the outputfrom LLMs propagate to downstream steps, identifying LLM errors is crucial tosystem performance. A common task for LLMs in AI systems is tool use. Whilethere are several benchmark environments for evaluating LLMs on this task, theytypically only give a success rate without any explanation of the failurecases. To solve this problem, we introduce SpecTool, a new benchmark toidentify error patterns in LLM output on tool-use tasks. Our benchmark data setcomprises of queries from diverse environments that can be used to test for thepresence of seven newly characterized error patterns. Using SPECTOOL , we showthat even the most prominent LLMs exhibit these error patterns in theiroutputs. Researchers can use the analysis and insights from SPECTOOL to guidetheir error mitigation strategies.</description><author>Shirley Kokane, Ming Zhu, Tulika Awalgaonkar, Jianguo Zhang, Thai Hoang, Akshara Prabhakar, Zuxin Liu, Tian Lan, Liangwei Yang, Juntao Tan, Rithesh Murthy, Weiran Yao, Zhiwei Liu, Juan Carlos Niebles, Huan Wang, Shelby Heinecke, Caiming Xiong, Silivo Savarese</author><pubDate>Wed, 20 Nov 2024 18:56:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13547v1</guid></item><item><title>Promoting User Data Autonomy During the Dissolution of a Monopolistic Firm</title><link>http://arxiv.org/abs/2411.13546v1</link><description>The deployment of AI in consumer products is currently focused on the use ofso-called foundation models, large neural networks pre-trained on massivecorpora of digital records. This emphasis on scaling up datasets andpre-training computation raises the risk of further consolidating the industry,and enabling monopolistic (or oligopolistic) behavior. Judges and regulatorsseeking to improve market competition may employ various remedies. This paperexplores dissolution -- the breaking up of a monopolistic entity into smallerfirms -- as one such remedy, focusing in particular on the technical challengesand opportunities involved in the breaking up of large models and datasets. Weshow how the framework of Conscious Data Contribution can enable user autonomyduring under dissolution. Through a simulation study, we explore howfine-tuning and the phenomenon of "catastrophic forgetting" could actuallyprove beneficial as a type of machine unlearning that allows users to specifywhich data they want used for what purposes.</description><author>Rushabh Solanki, Elliot Creager</author><pubDate>Wed, 20 Nov 2024 18:55:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13546v1</guid></item><item><title>Pushing the Limits of Sparsity: A Bag of Tricks for Extreme Pruning</title><link>http://arxiv.org/abs/2411.13545v1</link><description>Pruning of deep neural networks has been an effective technique for reducingmodel size while preserving most of the performance of dense networks, crucialfor deploying models on memory and power-constrained devices. While recentsparse learning methods have shown promising performance up to moderatesparsity levels such as 95% and 98%, accuracy quickly deteriorates when pushingsparsities to extreme levels. Obtaining sparse networks at such extremesparsity levels presents unique challenges, such as fragile gradient flow andheightened risk of layer collapse. In this work, we explore network performancebeyond the commonly studied sparsities, and propose a collection of techniquesthat enable the continuous learning of networks without accuracy collapse evenat extreme sparsities, including 99.90%, 99.95% and 99.99% on ResNetarchitectures. Our approach combines 1) Dynamic ReLU phasing, where DyReLUinitially allows for richer parameter exploration before being graduallyreplaced by standard ReLU, 2) weight sharing which reuses parameters within aresidual layer while maintaining the same number of learnable parameters, and3) cyclic sparsity, where both sparsity levels and sparsity patterns evolvedynamically throughout training to better encourage parameter exploration. Weevaluate our method, which we term Extreme Adaptive Sparse Training (EAST) atextreme sparsities using ResNet-34 and ResNet-50 on CIFAR-10, CIFAR-100, andImageNet, achieving significant performance improvements over state-of-the-artmethods we compared with.</description><author>Andy Li, Aiden Durrant, Milan Markovic, Lu Yin, Georgios Leontidis</author><pubDate>Wed, 20 Nov 2024 18:54:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13545v1</guid></item><item><title>DIS-Mine: Instance Segmentation for Disaster-Awareness in Poor-Light Condition in Underground Mines</title><link>http://arxiv.org/abs/2411.13544v1</link><description>Detecting disasters in underground mining, such as explosions and structuraldamage, has been a persistent challenge over the years. This problem iscompounded for first responders, who often have no clear information about theextent or nature of the damage within the mine. The poor-light or even totaldarkness inside the mines makes rescue efforts incredibly difficult, leading toa tragic loss of life. In this paper, we propose a novel instance segmentationmethod called DIS-Mine, specifically designed to identify disaster-affectedareas within underground mines under low-light or poor visibility conditions,aiding first responders in rescue efforts. DIS-Mine is capable of detectingobjects in images, even in complete darkness, by addressing challenges such ashigh noise, color distortions, and reduced contrast. The key innovations ofDIS-Mine are built upon four core components: i) Image brightness improvement,ii) Instance segmentation with SAM integration, iii) Mask R-CNN-basedsegmentation, and iv) Mask alignment with feature matching. On top of that, wehave collected real-world images from an experimental underground mine,introducing a new dataset named ImageMine, specifically gathered inlow-visibility conditions. This dataset serves to validate the performance ofDIS-Mine in realistic, challenging environments. Our comprehensive experimentson the ImageMine dataset, as well as on various other datasets demonstrate thatDIS-Mine achieves a superior F1 score of 86.0% and mIoU of 72.0%, outperformingstate-of-the-art instance segmentation methods, with at least 15x improvementand up to 80% higher precision in object detection.</description><author>Mizanur Rahman Jewel, Mohamed Elmahallawy, Sanjay Madria, Samuel Frimpong</author><pubDate>Wed, 20 Nov 2024 18:54:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13544v1</guid></item><item><title>BALROG: Benchmarking Agentic LLM and VLM Reasoning On Games</title><link>http://arxiv.org/abs/2411.13543v1</link><description>Large Language Models (LLMs) and Vision Language Models (VLMs) possessextensive knowledge and exhibit promising reasoning abilities; however, theystill struggle to perform well in complex, dynamic environments. Real-worldtasks require handling intricate interactions, advanced spatial reasoning,long-term planning, and continuous exploration of new strategies-areas in whichwe lack effective methodologies for comprehensively evaluating thesecapabilities. To address this gap, we introduce BALROG, a novel benchmarkdesigned to assess the agentic capabilities of LLMs and VLMs through a diverseset of challenging games. Our benchmark incorporates a range of existingreinforcement learning environments with varying levels of difficulty,including tasks that are solvable by non-expert humans in seconds to extremelychallenging ones that may take years to master (e.g., the NetHack LearningEnvironment). We devise fine-grained metrics to measure performance and conductan extensive evaluation of several popular open-source and closed-source LLMsand VLMs. Our findings indicate that while current models achieve partialsuccess in the easier games, they struggle significantly with more challengingtasks. Notably, we observe severe deficiencies in vision-based decision-making,as models perform worse when visual representations of the environments areprovided. We release BALROG as an open and user-friendly benchmark tofacilitate future research and development in the agentic community.</description><author>Davide Paglieri, Bartłomiej Cupiał, Samuel Coward, Ulyana Piterbarg, Maciej Wolczyk, Akbir Khan, Eduardo Pignatelli, Łukasz Kuciński, Lerrel Pinto, Rob Fergus, Jakob Nicolaus Foerster, Jack Parker-Holder, Tim Rocktäschel</author><pubDate>Wed, 20 Nov 2024 18:54:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13543v1</guid></item><item><title>The Role of Accuracy and Validation Effectiveness in Conversational Business Analytics</title><link>http://arxiv.org/abs/2411.12128v2</link><description>This study examines conversational business analytics, an approach thatutilizes AI to address the technical competency gaps that hinder end users fromeffectively using traditional self-service analytics. By facilitating naturallanguage interactions, conversational business analytics aims to empower endusers to independently retrieve data and generate insights. The analysisfocuses on Text-to-SQL as a representative technology for translating naturallanguage requests into SQL statements. Developing theoretical models groundedin expected utility theory, the study identifies conditions under whichconversational business analytics, through partial or full support, canoutperform delegation to human experts. The results indicate that partialsupport, focusing solely on information generation by AI, is viable when theaccuracy of AI-generated SQL queries leads to a profit that surpasses theperformance of a human expert. In contrast, full support includes not onlyinformation generation but also validation through explanations provided by theAI, and requires sufficiently high validation effectiveness to be reliable.However, user-based validation presents challenges, such as misjudgment andrejection of valid SQL queries, which may limit the effectiveness ofconversational business analytics. These challenges underscore the need forrobust validation mechanisms, including improved user support, automatedprocesses, and methods for assessing quality independently of end users'technical competencies.</description><author>Adem Alparslan</author><pubDate>Wed, 20 Nov 2024 18:46:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12128v2</guid></item><item><title>Metacognition for Unknown Situations and Environments (MUSE)</title><link>http://arxiv.org/abs/2411.13537v1</link><description>Metacognition--the awareness and regulation of one's cognitive processes--iscentral to human adaptability in unknown situations. In contrast, currentautonomous agents often struggle in novel environments due to their limitedcapacity for adaptation. We hypothesize that metacognition is a criticalmissing ingredient in adaptive autonomous systems, equipping them with thecognitive flexibility needed to tackle unfamiliar challenges. Given the broadscope of metacognitive abilities, we focus on two key aspects: competenceawareness and strategy selection for novel tasks. To this end, we propose theMetacognition for Unknown Situations and Environments (MUSE) framework, whichintegrates metacognitive processes--specifically self-awareness andself-regulation--into autonomous agents. We present two initial implementationsof MUSE: one based on world modeling and another leveraging large languagemodels (LLMs), both instantiating the metacognitive cycle. Our systemcontinuously learns to assess its competence on a given task and uses thisself-awareness to guide iterative cycles of strategy selection. MUSE agentsshow significant improvements in self-awareness and self-regulation, enablingthem to solve novel, out-of-distribution tasks more effectively compared toDreamer-v3-based reinforcement learning and purely prompt-based LLM agentapproaches. This work highlights the promise of approaches inspired bycognitive and neural systems in enabling autonomous systems to adapt to newenvironments, overcoming the limitations of current methods that rely heavilyon extensive training data.</description><author>Rodolfo Valiente, Praveen K. Pilly</author><pubDate>Wed, 20 Nov 2024 18:41:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13537v1</guid></item><item><title>Identity Preserving 3D Head Stylization with Multiview Score Distillation</title><link>http://arxiv.org/abs/2411.13536v1</link><description>3D head stylization transforms realistic facial features into artisticrepresentations, enhancing user engagement across gaming and virtual realityapplications. While 3D-aware generators have made significant advancements,many 3D stylization methods primarily provide near-frontal views and struggleto preserve the unique identities of original subjects, often resulting inoutputs that lack diversity and individuality. This paper addresses thesechallenges by leveraging the PanoHead model, synthesizing images from acomprehensive 360-degree perspective. We propose a novel framework that employsnegative log-likelihood distillation (LD) to enhance identity preservation andimprove stylization quality. By integrating multi-view grid score and mirrorgradients within the 3D GAN architecture and introducing a score rank weighingtechnique, our approach achieves substantial qualitative and quantitativeimprovements. Our findings not only advance the state of 3D head stylizationbut also provide valuable insights into effective distillation processesbetween diffusion models and GANs, focusing on the critical issue of identitypreservation. Please visit the https://three-bee.github.io/head_stylization formore visuals.</description><author>Bahri Batuhan Bilecen, Ahmet Berke Gokmen, Furkan Guzelant, Aysegul Dundar</author><pubDate>Wed, 20 Nov 2024 18:37:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13536v1</guid></item><item><title>Comparative Analysis of Machine Learning and Deep Learning Models for Classifying Squamous Epithelial Cells of the Cervix</title><link>http://arxiv.org/abs/2411.13535v1</link><description>The cervix is the narrow end of the uterus that connects to the vagina in thefemale reproductive system. Abnormal cell growth in the squamous epitheliallining of the cervix leads to cervical cancer in females. A Pap smear is adiagnostic procedure used to detect cervical cancer by gently collecting cellsfrom the surface of the cervix with a small brush and analyzing their changesunder a microscope. For population-based cervical cancer screening, visualinspection with acetic acid is a cost-effective method with high sensitivity.However, Pap smears are also suitable for mass screening due to their higherspecificity. The current Pap smear analysis method is manual, time-consuming,labor-intensive, and prone to human error. Therefore, an artificialintelligence (AI)-based approach for automatic cell classification is needed.In this study, we aimed to classify cells in Pap smear images into fivecategories: superficial-intermediate, parabasal, koilocytes, dyskeratotic, andmetaplastic. Various machine learning (ML) algorithms, including GradientBoosting, Random Forest, Support Vector Machine, and k-Nearest Neighbor, aswell as deep learning (DL) approaches like ResNet-50, were employed for thisclassification task. The ML models demonstrated high classification accuracy;however, ResNet-50 outperformed the others, achieving a classification accuracyof 93.06%. This study highlights the efficiency of DL models for cell-levelclassification and their potential to aid in the early diagnosis of cervicalcancer from Pap smear images.</description><author>Subhasish Das, Satish K Panda, Madhusmita Sethy, Prajna Paramita Giri, Ashwini K Nanda</author><pubDate>Wed, 20 Nov 2024 18:37:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13535v1</guid></item><item><title>Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse</title><link>http://arxiv.org/abs/2411.13534v1</link><description>Individuals who identify as sexual and gender minorities, including lesbian,gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely toexperience poorer health than their heterosexual and cisgender counterparts.One primary source that drives these health disparities is minority stress(i.e., chronic and social stressors unique to LGBTQ+ communities' experiencesadapting to the dominant culture). This stress is frequently expressed inLGBTQ+ users' posts on social media platforms. However, these expressions arenot just straightforward manifestations of minority stress. They involvelinguistic complexity (e.g., idiom or lexical diversity), rendering themchallenging for many traditional natural language processing methods to detect.In this work, we designed a hybrid model using Graph Neural Networks (GNN) andBidirectional Encoder Representations from Transformers (BERT), a pre-traineddeep language model to improve the classification performance of minoritystress detection. We experimented with our model on a benchmark social mediadataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset iscomprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Ourapproach enables the extraction of hidden linguistic nuances throughpretraining on a vast amount of raw data, while also engaging in transductivelearning to jointly develop representations for both labeled training data andunlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and anF1 score of 0.86, surpassing the performance of other baseline models inpredicting LGBTQ+ minority stress. Improved prediction of minority stressexpressions on social media could lead to digital health interventions toimprove the wellbeing of LGBTQ+ people-a community with high rates ofstress-sensitive health problems.</description><author>S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira</author><pubDate>Wed, 20 Nov 2024 18:35:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13534v1</guid></item><item><title>Basic syntax from speech: Spontaneous concatenation in unsupervised deep neural networks</title><link>http://arxiv.org/abs/2305.01626v3</link><description>Computational models of syntax are predominantly text-based. Here we proposethat the most basic first step in the evolution of syntax can be modeleddirectly from raw speech in a fully unsupervised way. We focus on one of themost ubiquitous and elementary suboperation of syntax -- concatenation. Weintroduce spontaneous concatenation: a phenomenon where convolutional neuralnetworks (CNNs) trained on acoustic recordings of individual words startgenerating outputs with two or even three words concatenated without everaccessing data with multiple words in the input. We replicate this finding inseveral independently trained models with different hyperparameters andtraining data. Additionally, networks trained on two words learn to embed wordsinto novel unobserved word combinations. We also show that the concatenatedoutputs contain precursors to compositionality. To our knowledge, this is apreviously unreported property of CNNs trained in the ciwGAN/fiwGAN setting onraw speech and has implications both for our understanding of how thesearchitectures learn as well as for modeling syntax and its evolution in thebrain from raw acoustic inputs. We also propose a potential neural mechanismcalled disinhibition that outlines a possible neural pathway towardsconcatenation and compositionality and suggests our modeling is useful forgenerating testable prediction for biological and artificial neural processingof speech.</description><author>Gašper Beguš, Thomas Lu, Zili Wang</author><pubDate>Wed, 20 Nov 2024 18:30:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.01626v3</guid></item><item><title>Retrieval with Learned Similarities</title><link>http://arxiv.org/abs/2407.15462v3</link><description>Retrieval plays a fundamental role in recommendation systems, search, andnatural language processing (NLP) by efficiently finding relevant items from alarge corpus given a query. Dot products have been widely used as thesimilarity function in such tasks, enabled by Maximum Inner Product Search(MIPS) algorithms for efficient retrieval. However, state-of-the-art retrievalalgorithms have migrated to learned similarities. These advanced approachesencompass multiple query embeddings, complex neural networks, direct item IDdecoding via beam search, and hybrid solutions. Unfortunately, we lackefficient solutions for retrieval in these state-of-the-art setups. Our workaddresses this gap by investigating efficient retrieval techniques withexpressive learned similarity functions. We establish Mixture-of-Logits (MoL)as a universal approximator of similarity functions, demonstrate that MoL'sexpressiveness can be realized empirically to achieve superior performance ondiverse retrieval scenarios, and propose techniques to retrieve the approximatetop-k results using MoL with tight error bounds. Through extensiveexperimentation, we show that MoL, enhanced by our proposed mutualinformation-based load balancing loss, sets new state-of-the-art results acrossheterogeneous scenarios, including sequential retrieval models inrecommendation systems and finetuning language models for question answering;and our approximate top-$k$ algorithms outperform baselines by up to 66x inlatency while achieving &gt;.99 recall rate compared to exact algorithms.</description><author>Bailu Ding, Jiaqi Zhai</author><pubDate>Wed, 20 Nov 2024 18:30:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.15462v3</guid></item><item><title>Delegating Data Collection in Decentralized Machine Learning</title><link>http://arxiv.org/abs/2309.01837v3</link><description>Motivated by the emergence of decentralized machine learning (ML) ecosystems,we study the delegation of data collection. Taking the field of contract theoryas our starting point, we design optimal and near-optimal contracts that dealwith two fundamental information asymmetries that arise in decentralized ML:uncertainty in the assessment of model quality and uncertainty regarding theoptimal performance of any model. We show that a principal can cope with suchasymmetry via simple linear contracts that achieve 1-1/e fraction of theoptimal utility. To address the lack of a priori knowledge regarding theoptimal performance, we give a convex program that can adaptively andefficiently compute the optimal contract. We also study linear contracts andderive the optimal utility in the more complex setting of multipleinteractions.</description><author>Nivasini Ananthakrishnan, Stephen Bates, Michael I. Jordan, Nika Haghtalab</author><pubDate>Wed, 20 Nov 2024 18:26:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01837v3</guid></item><item><title>Preferences Evolve And So Should Your Bandits: Bandits with Evolving States for Online Platforms</title><link>http://arxiv.org/abs/2307.11655v4</link><description>We propose a model for learning with bandit feedback while accounting fordeterministically evolving and unobservable states that we call Bandits withDeterministically Evolving States ($B$-$DES$). The workhorse applications ofour model are learning for recommendation systems and learning for online ads.In both cases, the reward that the algorithm obtains at each round is afunction of the short-term reward of the action chosen and how "healthy" thesystem is (i.e., as measured by its state). For example, in recommendationsystems, the reward that the platform obtains from a user's engagement with aparticular type of content depends not only on the inherent features of thespecific content, but also on how the user's preferences have evolved as aresult of interacting with other types of content on the platform. Our generalmodel accounts for the different rate $\lambda \in [0,1]$ at which the stateevolves (e.g., how fast a user's preferences shift as a result of previouscontent consumption) and encompasses standard multi-armed bandits as a specialcase. The goal of the algorithm is to minimize a notion of regret against thebest-fixed sequence of arms pulled, which is significantly harder to attaincompared to standard benchmark of the best-fixed action in hindsight. Wepresent online learning algorithms for any possible value of the evolution rate$\lambda$ and we show the robustness of our results to various modelmisspecifications.</description><author>Khashayar Khosravi, Renato Paes Leme, Chara Podimata, Apostolis Tsorvantzis</author><pubDate>Wed, 20 Nov 2024 18:25:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11655v4</guid></item><item><title>Entropy Bootstrapping for Weakly Supervised Nuclei Detection</title><link>http://arxiv.org/abs/2411.13528v1</link><description>Microscopy structure segmentation, such as detecting cells or nuclei,generally requires a human to draw a ground truth contour around each instance.Weakly supervised approaches (e.g. consisting of only single point labels) havethe potential to reduce this workload significantly. Our approach usesindividual point labels for an entropy estimation to approximate an underlyingdistribution of cell pixels. We infer full cell masks from this distribution,and use Mask-RCNN to produce an instance segmentation output. We compare thispoint--annotated approach with training on the full ground truth masks. We showthat our method achieves a comparatively good level of performance, despite a95% reduction in pixel labels.</description><author>James Willoughby, Irina Voiculescu</author><pubDate>Wed, 20 Nov 2024 18:24:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13528v1</guid></item><item><title>Geometric Algebra Planes: Convex Implicit Neural Volumes</title><link>http://arxiv.org/abs/2411.13525v1</link><description>Volume parameterizations abound in recent literature, from the classic voxelgrid to the implicit neural representation and everything in between. Whileimplicit representations have shown impressive capacity and better memoryefficiency compared to voxel grids, to date they require training via nonconvexoptimization. This nonconvex training process can be slow to converge andsensitive to initialization and hyperparameter choices that affect the finalconverged result. We introduce a family of models, GA-Planes, that is the firstclass of implicit neural volume representations that can be trained by convexoptimization. GA-Planes models include any combination of features stored intensor basis elements, followed by a neural feature decoder. They generalizemany existing representations and can be adapted for convex, semiconvex, ornonconvex training as needed for different inverse problems. In the 2D setting,we prove that GA-Planes is equivalent to a low-rank plus low-resolution matrixfactorization; we show that this approximation outperforms the classic low-rankplus sparse decomposition for fitting a natural image. In 3D, we demonstrateGA-Planes' competitive performance in terms of expressiveness, model size, andoptimizability across three volume fitting tasks: radiance fieldreconstruction, 3D segmentation, and video segmentation.</description><author>Irmak Sivgin, Sara Fridovich-Keil, Gordon Wetzstein, Mert Pilanci</author><pubDate>Wed, 20 Nov 2024 18:21:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13525v1</guid></item><item><title>Quantum Attention for Vision Transformers in High Energy Physics</title><link>http://arxiv.org/abs/2411.13520v1</link><description>We present a novel hybrid quantum-classical vision transformer architectureincorporating quantum orthogonal neural networks (QONNs) to enhance performanceand computational efficiency in high-energy physics applications. Building onadvancements in quantum vision transformers, our approach addresses limitationsof prior models by leveraging the inherent advantages of QONNs, includingstability and efficient parameterization in high-dimensional spaces. Weevaluate the proposed architecture using multi-detector jet images from CMSOpen Data, focusing on the task of distinguishing quark-initiated fromgluon-initiated jets. The results indicate that embedding quantum orthogonaltransformations within the attention mechanism can provide robust performancewhile offering promising scalability for machine learning challenges associatedwith the upcoming High Luminosity Large Hadron Collider. This work highlightsthe potential of quantum-enhanced models to address the computational demandsof next-generation particle physics experiments.</description><author>Alessandro Tesi, Gopal Ramesh Dahale, Sergei Gleyzer, Kyoungchul Kong, Tom Magorsch, Konstantin T. Matchev, Katia Matcheva</author><pubDate>Wed, 20 Nov 2024 18:11:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13520v1</guid></item><item><title>Advancing Complex Medical Communication in Arabic with Sporo AraSum: Surpassing Existing Large Language Models</title><link>http://arxiv.org/abs/2411.13518v1</link><description>The increasing demand for multilingual capabilities in healthcare underscoresthe need for AI models adept at processing diverse languages, particularly inclinical documentation and decision-making. Arabic, with its complexmorphology, syntax, and diglossia, poses unique challenges for natural languageprocessing (NLP) in medical contexts. This case study evaluates Sporo AraSum, alanguage model tailored for Arabic clinical documentation, against JAIS, theleading Arabic NLP model. Using synthetic datasets and modified PDQI-9 metricsmodified ourselves for the purposes of assessing model performances in adifferent language. The study assessed the models' performance in summarizingpatient-physician interactions, focusing on accuracy, comprehensiveness,clinical utility, and linguistic-cultural competence. Results indicate that Sporo AraSum significantly outperforms JAIS inAI-centric quantitative metrics and all qualitative attributes measured in ourmodified version of the PDQI-9. AraSum's architecture enables precise andculturally sensitive documentation, addressing the linguistic nuances of Arabicwhile mitigating risks of AI hallucinations. These findings suggest that SporoAraSum is better suited to meet the demands of Arabic-speaking healthcareenvironments, offering a transformative solution for multilingual clinicalworkflows. Future research should incorporate real-world data to furthervalidate these findings and explore broader integration into healthcaresystems.</description><author>Chanseo Lee, Sonu Kumar, Kimon A. Vogt, Sam Meraj, Antonia Vogt</author><pubDate>Wed, 20 Nov 2024 18:10:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13518v1</guid></item><item><title>Procurement Auctions via Approximately Optimal Submodular Optimization</title><link>http://arxiv.org/abs/2411.13513v1</link><description>We study procurement auctions, where an auctioneer seeks to acquire servicesfrom strategic sellers with private costs. The quality of services is measuredby a submodular function known to the auctioneer. Our goal is to designcomputationally efficient procurement auctions that (approximately) maximizethe difference between the quality of the acquired services and the total costof the sellers, while ensuring incentive compatibility (IC), individualrationality (IR) for sellers, and non-negative surplus (NAS) for theauctioneer. Our contributions are twofold: (i) we provide an improved analysis ofexisting algorithms for non-positive submodular function maximization, and (ii)we design efficient frameworks that transform submodular optimizationalgorithms into mechanisms that are IC, IR, NAS, and approximation-preserving.These frameworks apply to both the offline setting, where all sellers' bids andservices are available simultaneously, and the online setting, where sellersarrive in an adversarial order, requiring the auctioneer to make irrevocabledecisions. We also explore whether state-of-the-art submodular optimization algorithmscan be converted into descending auctions in adversarial settings, where theschedule of descending prices is determined by an adversary. We show that asubmodular optimization algorithm satisfying bi-criteria $(1/2,1)$-approximation in welfare can be effectively adapted to a descendingauction. Additionally, we establish a connection between descending auctionsand online submodular optimization. Finally, we demonstrate the practical applications of our frameworks byinstantiating them with state-of-the-art submodular optimization algorithms andempirically comparing their welfare performance on publicly available datasetswith thousands of sellers.</description><author>Yuan Deng, Amin Karbasi, Vahab Mirrokni, Renato Paes Leme, Grigoris Velegkas, Song Zuo</author><pubDate>Wed, 20 Nov 2024 18:06:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13513v1</guid></item><item><title>From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models</title><link>http://arxiv.org/abs/2406.16838v2</link><description>One of the most striking findings in modern research on large language models(LLMs) is that scaling up compute during training leads to better results.However, less attention has been given to the benefits of scaling computeduring inference. This survey focuses on these inference-time approaches. Weexplore three areas under a unified mathematical formalism: token-levelgeneration algorithms, meta-generation algorithms, and efficient generation.Token-level generation algorithms, often called decoding algorithms, operate bysampling a single token at a time or constructing a token-level search spaceand then selecting an output. These methods typically assume access to alanguage model's logits, next-token distributions, or probability scores.Meta-generation algorithms work on partial or full sequences, incorporatingdomain knowledge, enabling backtracking, and integrating external information.Efficient generation methods aim to reduce token costs and improve the speed ofgeneration. Our survey unifies perspectives from three research communities:traditional natural language processing, modern LLMs, and machine learningsystems.</description><author>Sean Welleck, Amanda Bertsch, Matthew Finlayson, Hailey Schoelkopf, Alex Xie, Graham Neubig, Ilia Kulikov, Zaid Harchaoui</author><pubDate>Wed, 20 Nov 2024 17:57:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16838v2</guid></item><item><title>Disentangling Memory and Reasoning Ability in Large Language Models</title><link>http://arxiv.org/abs/2411.13504v1</link><description>Large Language Models (LLMs) have demonstrated strong performance in handlingcomplex tasks requiring both extensive knowledge and reasoning abilities.However, the existing LLM inference pipeline operates as an opaque processwithout explicit separation between knowledge retrieval and reasoning steps,making the model's decision-making process unclear and disorganized. Thisambiguity can lead to issues such as hallucinations and knowledge forgetting,which significantly impact the reliability of LLMs in high-stakes domains. Inthis paper, we propose a new inference paradigm that decomposes the complexinference process into two distinct and clear actions: (1) memory recall: whichretrieves relevant knowledge, and (2) reasoning: which performs logical stepsbased on the recalled knowledge. To facilitate this decomposition, we introducetwo special tokens memory and reason, guiding the model to distinguish betweensteps that require knowledge retrieval and those that involve reasoning. Ourexperiment results show that this decomposition not only improves modelperformance but also enhances the interpretability of the inference process,enabling users to identify sources of error and refine model responseseffectively. The code is available athttps://github.com/MingyuJ666/Disentangling-Memory-and-Reasoning.</description><author>Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang</author><pubDate>Wed, 20 Nov 2024 17:55:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13504v1</guid></item><item><title>VBench++: Comprehensive and Versatile Benchmark Suite for Video Generative Models</title><link>http://arxiv.org/abs/2411.13503v1</link><description>Video generation has witnessed significant advancements, yet evaluating thesemodels remains a challenge. A comprehensive evaluation benchmark for videogeneration is indispensable for two reasons: 1) Existing metrics do not fullyalign with human perceptions; 2) An ideal evaluation system should provideinsights to inform future developments of video generation. To this end, wepresent VBench, a comprehensive benchmark suite that dissects "video generationquality" into specific, hierarchical, and disentangled dimensions, each withtailored prompts and evaluation methods. VBench has several appealingproperties: 1) Comprehensive Dimensions: VBench comprises 16 dimensions invideo generation (e.g., subject identity inconsistency, motion smoothness,temporal flickering, and spatial relationship, etc). The evaluation metricswith fine-grained levels reveal individual models' strengths and weaknesses. 2)Human Alignment: We also provide a dataset of human preference annotations tovalidate our benchmarks' alignment with human perception, for each evaluationdimension respectively. 3) Valuable Insights: We look into current models'ability across various evaluation dimensions, and various content types. Wealso investigate the gaps between video and image generation models. 4)Versatile Benchmarking: VBench++ supports evaluating text-to-video andimage-to-video. We introduce a high-quality Image Suite with an adaptive aspectratio to enable fair evaluations across different image-to-video generationsettings. Beyond assessing technical quality, VBench++ evaluates thetrustworthiness of video generative models, providing a more holistic view ofmodel performance. 5) Full Open-Sourcing: We fully open-source VBench++ andcontinually add new video generation models to our leaderboard to drive forwardthe field of video generation.</description><author>Ziqi Huang, Fan Zhang, Xiaojie Xu, Yinan He, Jiashuo Yu, Ziyue Dong, Qianli Ma, Nattapol Chanpaisit, Chenyang Si, Yuming Jiang, Yaohui Wang, Xinyuan Chen, Ying-Cong Chen, Limin Wang, Dahua Lin, Yu Qiao, Ziwei Liu</author><pubDate>Wed, 20 Nov 2024 17:54:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13503v1</guid></item><item><title>Advancing Heatwave Forecasting via Distribution Informed-Graph Neural Networks (DI-GNNs): Integrating Extreme Value Theory with GNNs</title><link>http://arxiv.org/abs/2411.13496v1</link><description>Heatwaves, prolonged periods of extreme heat, have intensified in frequencyand severity due to climate change, posing substantial risks to public health,ecosystems, and infrastructure. Despite advancements in Machine Learning (ML)modeling, accurate heatwave forecasting at weather scales (1--15 days) remainschallenging due to the non-linear interactions between atmospheric drivers andthe rarity of these extreme events. Traditional models relying on heuristicfeature engineering often fail to generalize across diverse climates andcapture the complexities of heatwave dynamics. This study introduces theDistribution-Informed Graph Neural Network (DI-GNN), a novel framework thatintegrates principles from Extreme Value Theory (EVT) into the graph neuralnetwork architecture. DI-GNN incorporates Generalized Pareto Distribution(GPD)-derived descriptors into the feature space, adjacency matrix, and lossfunction to enhance its sensitivity to rare heatwave occurrences. Byprioritizing the tails of climatic distributions, DI-GNN addresses thelimitations of existing methods, particularly in imbalanced datasets wheretraditional metrics like accuracy are misleading. Empirical evaluations usingweather station data from British Columbia, Canada, demonstrate the superiorperformance of DI-GNN compared to baseline models. DI-GNN achieved significantimprovements in balanced accuracy, recall, and precision, with high AUC andaverage precision scores, reflecting its robustness in distinguishing heatwaveevents.</description><author>Farrukh A. Chishtie, Dominique Brunet, Rachel H. White, Daniel Michelson, Jing Jiang, Vicky Lucas, Emily Ruboonga, Sayana Imaash, Melissa Westland, Timothy Chui, Rana Usman Ali, Mujtaba Hassan, Roland Stull, David Hudak</author><pubDate>Wed, 20 Nov 2024 17:45:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13496v1</guid></item><item><title>Efficient Brain Imaging Analysis for Alzheimer's and Dementia Detection Using Convolution-Derivative Operations</title><link>http://arxiv.org/abs/2411.13490v1</link><description>Alzheimer's disease (AD) is characterized by progressive neurodegenerationand results in detrimental structural changes in human brains. Detecting thesechanges is crucial for early diagnosis and timely intervention of diseaseprogression. Jacobian maps, derived from spatial normalization in voxel-basedmorphometry (VBM), have been instrumental in interpreting volume alterationsassociated with AD. However, the computational cost of generating Jacobian mapslimits its clinical adoption. In this study, we explore alternative methods andpropose Sobel kernel angle difference (SKAD) as a computationally efficientalternative. SKAD is a derivative operation that offers an optimized approachto quantifying volumetric alterations through localized analysis of thegradients. By efficiently extracting gradient amplitude changes at criticalspatial regions, this derivative operation captures regional volume variationsEvaluation of SKAD over various medical datasets demonstrates that it is 6.3xfaster than Jacobian maps while still maintaining comparable accuracy. Thismakes it an efficient and competitive approach in neuroimaging research andclinical practice.</description><author>Yasmine Mustafa, Mohamed Elmahallawy, Tie Luo</author><pubDate>Wed, 20 Nov 2024 17:38:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13490v1</guid></item><item><title>Utilizing Large Language Models to Synthesize Product Desirability Datasets</title><link>http://arxiv.org/abs/2411.13485v1</link><description>This research explores the application of large language models (LLMs) togenerate synthetic datasets for Product Desirability Toolkit (PDT) testing, akey component in evaluating user sentiment and product experience. Utilizinggpt-4o-mini, a cost-effective alternative to larger commercial LLMs, threemethods, Word+Review, Review+Word, and Supply-Word, were each used tosynthesize 1000 product reviews. The generated datasets were assessed forsentiment alignment, textual diversity, and data generation cost. Resultsdemonstrated high sentiment alignment across all methods, with Pearsoncorrelations ranging from 0.93 to 0.97. Supply-Word exhibited the highestdiversity and coverage of PDT terms, although with increased generation costs.Despite minor biases toward positive sentiments, in situations with limitedtest data, LLM-generated synthetic data offers significant advantages,including scalability, cost savings, and flexibility in dataset production.</description><author>John D. Hastings, Sherri Weitl-Harms, Joseph Doty, Zachary L. Myers, Warren Thompson</author><pubDate>Wed, 20 Nov 2024 17:35:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13485v1</guid></item><item><title>Soda: An Object-Oriented Functional Language for Specifying Human-Centered Problems</title><link>http://arxiv.org/abs/2310.01961v2</link><description>We present Soda (Symbolic Objective Descriptive Analysis), a language thathelps to treat qualities and quantities in a natural way and greatly simplifiesthe task of checking their correctness. We present key properties for thelanguage motivated by the design of a descriptive language to encode complexrequirements on computer systems, and we explain how these key properties mustbe addressed to model these requirements with simple definitions. We give anoverview of a tool that helps to describe problems in an easy way that weconsider more transparent and less error-prone.</description><author>Julian Alfredo Mendez</author><pubDate>Wed, 20 Nov 2024 17:26:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01961v2</guid></item><item><title>Conformal Prediction for Hierarchical Data</title><link>http://arxiv.org/abs/2411.13479v1</link><description>Reconciliation has become an essential tool in multivariate point forecastingfor hierarchical time series. However, there is still a lack of understandingof the theoretical properties of probabilistic Forecast Reconciliationtechniques. Meanwhile, Conformal Prediction is a general framework with growingappeal that provides prediction sets with probabilistic guarantees in finitesample. In this paper, we propose a first step towards combining ConformalPrediction and Forecast Reconciliation by analyzing how including areconciliation step in the Split Conformal Prediction (SCP) procedure enhancesthe resulting prediction sets. In particular, we show that the validity grantedby SCP remains while improving the efficiency of the prediction sets. We alsoadvocate a variation of the theoretical procedure for practical use. Finally,we illustrate these results with simulations.</description><author>Guillaume Principato, Yvenn Amara-Ouali, Yannig Goude, Bachir Hamrouche, Jean-Michel Poggi, Gilles Stoltz</author><pubDate>Wed, 20 Nov 2024 17:26:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13479v1</guid></item><item><title>PatentEdits: Framing Patent Novelty as Textual Entailment</title><link>http://arxiv.org/abs/2411.13477v1</link><description>A patent must be deemed novel and non-obvious in order to be granted by theUS Patent Office (USPTO). If it is not, a US patent examiner will cite theprior work, or prior art, that invalidates the novelty and issue a non-finalrejection. Predicting what claims of the invention should change given theprior art is an essential and crucial step in securing invention rights, yethas not been studied before as a learnable task. In this work we introduce thePatentEdits dataset, which contains 105K examples of successful revisions thatovercome objections to novelty. We design algorithms to label edits sentence bysentence, then establish how well these edits can be predicted with largelanguage models (LLMs). We demonstrate that evaluating textual entailmentbetween cited references and draft sentences is especially effective inpredicting which inventive claims remained unchanged or are novel in relationto prior art.</description><author>Ryan Lee, Alexander Spangher, Xuezhe Ma</author><pubDate>Wed, 20 Nov 2024 17:23:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13477v1</guid></item><item><title>When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training</title><link>http://arxiv.org/abs/2411.13476v1</link><description>Extending context window sizes allows large language models (LLMs) to processlonger sequences and handle more complex tasks. Rotary Positional Embedding(RoPE) has become the de facto standard due to its relative positional encodingproperties that benefit long-context training. However, we observe that usingRoPE with BFloat16 format results in numerical issues, causing it to deviatefrom its intended relative positional encoding, especially in long-contextscenarios. This issue arises from BFloat16's limited precision and accumulatesas context length increases, with the first token contributing significantly tothis problem. To address this, we develop AnchorAttention, a plug-and-playattention method that alleviates numerical issues caused by BFloat16, improveslong-context capabilities, and speeds up training. AnchorAttention reducesunnecessary attention computations, maintains semantic coherence, and boostscomputational efficiency by treating the first token as a shared anchor with aconsistent position ID, making it visible to all documents within the trainingcontext. Experiments on three types of LLMs demonstrate that AnchorAttentionsignificantly improves long-context performance and reduces training time byover 50\% compared to standard full attention mechanisms, while preserving theoriginal LLM's capabilities on general tasks. Our code is available athttps://github.com/haonan3/AnchorContext.</description><author>Haonan Wang, Qian Liu, Chao Du, Tongyao Zhu, Cunxiao Du, Kenji Kawaguchi, Tianyu Pang</author><pubDate>Wed, 20 Nov 2024 17:22:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13476v1</guid></item><item><title>Adversarial Score identity Distillation: Rapidly Surpassing the Teacher in One Step</title><link>http://arxiv.org/abs/2410.14919v3</link><description>Score identity Distillation (SiD) is a data-free method that has achievedSOTA performance in image generation by leveraging only a pretrained diffusionmodel, without requiring any training data. However, its ultimate performanceis constrained by how accurate the pretrained model captures the true datascores at different stages of the diffusion process. In this paper, weintroduce SiDA (SiD with Adversarial Loss), which not only enhances generationquality but also improves distillation efficiency by incorporating real imagesand adversarial loss. SiDA utilizes the encoder from the generator's scorenetwork as a discriminator, boosting its ability to distinguish between realimages and those generated by SiD. The adversarial loss is batch-normalizedwithin each GPU and then combined with the original SiD loss. This integrationeffectively incorporates the average "fakeness" per GPU batch into thepixel-based SiD loss, enabling SiDA to distill a single-step generator eitherfrom scratch or by fine-tuning an existing one. SiDA converges significantlyfaster than its predecessor when trained from scratch, and swiftly improvesupon the original model's performance after an initial warmup period duringfine-tuning from a pre-distilled SiD generator. This one-step adversarialdistillation method establishes new benchmarks in generation performance whendistilling EDM diffusion models pretrained on CIFAR-10 (32x32) and ImageNet(64x64), achieving FID score of 1.110 on ImageNet 64x64. It sets record-low FIDscores when distilling EDM2 models trained on ImageNet (512x512), surpassingeven the largest teacher model, EDM2-XXL. Our SiDA's results record FID scoresof 2.156 for EDM2-XS, 1.669 for S, 1.488 for M, 1.413 for L, 1.379 for XL, and1.366 for XXL, demonstrating significant improvements across all model sizes.Our open-source code will be integrated into the SiD codebase.</description><author>Mingyuan Zhou, Huangjie Zheng, Yi Gu, Zhendong Wang, Hai Huang</author><pubDate>Wed, 20 Nov 2024 17:20:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.14919v3</guid></item><item><title>Generalization on the Unseen, Logic Reasoning and Degree Curriculum</title><link>http://arxiv.org/abs/2301.13105v3</link><description>This paper considers the learning of logical (Boolean) functions with a focuson the generalization on the unseen (GOTU) setting, a strong case ofout-of-distribution generalization. This is motivated by the fact that the richcombinatorial nature of data in certain reasoning tasks (e.g.,arithmetic/logic) makes representative data sampling challenging, and learningsuccessfully under GOTU gives a first vignette of an 'extrapolating' or'reasoning' learner. We study how different network architectures trained by(S)GD perform under GOTU and provide both theoretical and experimental evidencethat for sparse functions and a class of network models including instances ofTransformers, random features models, and linear networks, amin-degree-interpolator is learned on the unseen. More specifically, this meansan interpolator of the training data that has minimal Fourier mass on thehigher degree basis elements. These findings lead to two implications: (1) weprovide an explanation to the length generalization problem for Booleanfunctions (e.g., Anil et al. 2022); (2) we introduce a curriculum learningalgorithm called Degree-Curriculum that learns monomials more efficiently byincrementing supports. Finally, we discuss extensions to other models ornon-sparse regimes where the min-degree bias may still occur or fade, as wellas how it can be potentially corrected when undesirable.</description><author>Emmanuel Abbe, Samy Bengio, Aryo Lotfi, Kevin Rizk</author><pubDate>Wed, 20 Nov 2024 17:16:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13105v3</guid></item><item><title>Capsule Network Projectors are Equivariant and Invariant Learners</title><link>http://arxiv.org/abs/2405.14386v3</link><description>Learning invariant representations has been the longstanding approach toself-supervised learning. However, recently progress has been made inpreserving equivariant properties in representations, yet do so with highlyprescribed architectures. In this work, we propose an invariant-equivariantself-supervised architecture that employs Capsule Networks (CapsNets) whichhave been shown to capture equivariance with respect to novel viewpoints. Wedemonstrate that the use of CapsNets in equivariant self-supervisedarchitectures achieves improved downstream performance on equivariant taskswith higher efficiency and fewer network parameters. To accommodate thearchitectural changes of CapsNets, we introduce a new objective function basedon entropy minimisation. This approach which we name CapsIE (Capsule InvariantEquivariant Network) achieves state-of-the-art performance on the equivariantrotation tasks on the 3DIEBench dataset compared to prior equivariant SSLmethods, while performing competitively against supervised counterparts. Ourresults demonstrate the ability of CapsNets to learn complex and generalisedrepresentations for large-scale, multi-task datasets compared to previousCapsNet benchmarks. Code is available at https://github.com/AberdeenML/CapsIE.</description><author>Miles Everett, Aiden Durrant, Mingjun Zhong, Georgios Leontidis</author><pubDate>Wed, 20 Nov 2024 17:14:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14386v3</guid></item><item><title>Robust Fair Clustering with Group Membership Uncertainty Sets</title><link>http://arxiv.org/abs/2406.00599v3</link><description>We study the canonical fair clustering problem where each cluster isconstrained to have close to population-level representation of each group.Despite significant attention, the salient issue of having incomplete knowledgeabout the group membership of each point has been superficially addressed. Inthis paper, we consider a setting where the assigned group memberships arenoisy. We introduce a simple noise model that requires a small number ofparameters to be given by the decision maker. We then present an algorithm forfair clustering with provable \emph{robustness} guarantees. Our frameworkenables the decision maker to trade off between the robustness and theclustering quality. Unlike previous work, our algorithms are backed byworst-case theoretical guarantees. Finally, we empirically verify theperformance of our algorithm on real world datasets and show its superiorperformance over existing baselines.</description><author>Sharmila Duppala, Juan Luque, John P. Dickerson, Seyed A. Esmaeili</author><pubDate>Wed, 20 Nov 2024 17:12:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.00599v3</guid></item><item><title>Safe Exploitative Play with Untrusted Type Beliefs</title><link>http://arxiv.org/abs/2411.07679v2</link><description>The combination of the Bayesian game and learning has a rich history, withthe idea of controlling a single agent in a system composed of multiple agentswith unknown behaviors given a set of types, each specifying a possiblebehavior for the other agents. The idea is to plan an agent's own actions withrespect to those types which it believes are most likely to maximize thepayoff. However, the type beliefs are often learned from past actions andlikely to be incorrect. With this perspective in mind, we consider an agent ina game with type predictions of other components, and investigate the impact ofincorrect beliefs to the agent's payoff. In particular, we formally define atradeoff between risk and opportunity by comparing the payoff obtained againstthe optimal payoff, which is represented by a gap caused by trusting ordistrusting the learned beliefs. Our main results characterize the tradeoff byestablishing upper and lower bounds on the Pareto front for both normal-formand stochastic Bayesian games, with numerical results provided.</description><author>Tongxin Li, Tinashe Handina, Shaolei Ren, Adam Wierman</author><pubDate>Wed, 20 Nov 2024 17:11:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07679v2</guid></item><item><title>Sampling and Integration of Logconcave Functions by Algorithmic Diffusion</title><link>http://arxiv.org/abs/2411.13462v1</link><description>We study the complexity of sampling, rounding, and integrating arbitrarylogconcave functions. Our new approach provides the first complexityimprovements in nearly two decades for general logconcave functions for allthree problems, and matches the best-known complexities for the special case ofuniform distributions on convex bodies. For the sampling problem, our outputguarantees are significantly stronger than previously known, and lead to astreamlined analysis of statistical estimation based on dependent randomsamples.</description><author>Yunbum Kook, Santosh S. Vempala</author><pubDate>Wed, 20 Nov 2024 17:10:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13462v1</guid></item><item><title>SoK: A Systems Perspective on Compound AI Threats and Countermeasures</title><link>http://arxiv.org/abs/2411.13459v1</link><description>Large language models (LLMs) used across enterprises often use proprietarymodels and operate on sensitive inputs and data. The wide range of attackvectors identified in prior research - targeting various software and hardwarecomponents used in training and inference - makes it extremely challenging toenforce confidentiality and integrity policies. As we advance towards constructing compound AI inference pipelines thatintegrate multiple large language models (LLMs), the attack surfaces expandsignificantly. Attackers now focus on the AI algorithms as well as the softwareand hardware components associated with these systems. While current researchoften examines these elements in isolation, we find that combining cross-layerattack observations can enable powerful end-to-end attacks with minimalassumptions about the threat model. Given, the sheer number of existing attacksat each layer, we need a holistic and systemized understanding of differentattack vectors at each layer. This SoK discusses different software and hardware attacks applicable tocompound AI systems and demonstrates how combining multiple attack mechanismscan reduce the threat model assumptions required for an isolated attack. Next,we systematize the ML attacks in lines with the Mitre Att&amp;ck framework tobetter position each attack based on the threat model. Finally, we outline theexisting countermeasures for both software and hardware layers and discuss thenecessity of a comprehensive defense strategy to enable the secure andhigh-performance deployment of compound AI systems.</description><author>Sarbartha Banerjee, Prateek Sahu, Mulong Luo, Anjo Vahldiek-Oberwagner, Neeraja J. Yadwadkar, Mohit Tiwari</author><pubDate>Wed, 20 Nov 2024 17:08:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13459v1</guid></item><item><title>Debias-CLR: A Contrastive Learning Based Debiasing Method for Algorithmic Fairness in Healthcare Applications</title><link>http://arxiv.org/abs/2411.10544v2</link><description>Artificial intelligence based predictive models trained on the clinical notescan be demographically biased. This could lead to adverse healthcaredisparities in predicting outcomes like length of stay of the patients. Thus,it is necessary to mitigate the demographic biases within these models. Weproposed an implicit in-processing debiasing method to combat disparatetreatment which occurs when the machine learning model predict differentoutcomes for individuals based on the sensitive attributes like gender,ethnicity, race, and likewise. For this purpose, we used clinical notes ofheart failure patients and used diagnostic codes, procedure reports andphysiological vitals of the patients. We used Clinical BERT to obtain featureembeddings within the diagnostic codes and procedure reports, and LSTMautoencoders to obtain feature embeddings within the physiological vitals.Then, we trained two separate deep learning contrastive learning frameworks,one for gender and the other for ethnicity to obtain debiased representationswithin those demographic traits. We called this debiasing framework Debias-CLR.We leveraged clinical phenotypes of the patients identified in the diagnosticcodes and procedure reports in the previous study to measure fairnessstatistically. We found that Debias-CLR was able to reduce the Single-CategoryWord Embedding Association Test (SC-WEAT) effect size score when debiasing forgender and ethnicity. We further found that to obtain fair representations inthe embedding space using Debias-CLR, the accuracy of the predictive models ondownstream tasks like predicting length of stay of the patients did not getreduced as compared to using the un-debiased counterparts for training thepredictive models. Hence, we conclude that our proposed approach, Debias-CLR isfair and representative in mitigating demographic biases and can reduce healthdisparities.</description><author>Ankita Agarwal, Tanvi Banerjee, William Romine, Mia Cajita</author><pubDate>Wed, 20 Nov 2024 17:06:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10544v2</guid></item><item><title>LIMBA: An Open-Source Framework for the Preservation and Valorization of Low-Resource Languages using Generative Models</title><link>http://arxiv.org/abs/2411.13453v1</link><description>Minority languages are vital to preserving cultural heritage, yet they facegrowing risks of extinction due to limited digital resources and the dominanceof artificial intelligence models trained on high-resource languages. Thiswhite paper proposes a framework to generate linguistic tools for low-resourcelanguages, focusing on data creation to support the development of languagemodels that can aid in preservation efforts. Sardinian, an endangered language,serves as the case study to demonstrate the framework's effectiveness. Byaddressing the data scarcity that hinders intelligent applications for suchlanguages, we contribute to promoting linguistic diversity and support ongoingefforts in language standardization and revitalization through moderntechnologies.</description><author>Salvatore Mario Carta, Stefano Chessa, Giulia Contu, Andrea Corriga, Andrea Deidda, Gianni Fenu, Luca Frigau, Alessandro Giuliani, Luca Grassi, Marco Manolo Manca, Mirko Marras, Francesco Mola, Bastianino Mossa, Piergiorgio Mura, Marco Ortu, Leonardo Piano, Simone Pisano, Alessia Pisu, Alessandro Sebastian Podda, Livio Pompianu, Simone Seu, Sandro Gabriele Tiddia</author><pubDate>Wed, 20 Nov 2024 16:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13453v1</guid></item><item><title>AdaptAgent: Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations</title><link>http://arxiv.org/abs/2411.13451v1</link><description>State-of-the-art multimodal web agents, powered by Multimodal Large LanguageModels (MLLMs), can autonomously execute many web tasks by processing userinstructions and interacting with graphical user interfaces (GUIs). Currentstrategies for building web agents rely on (i) the generalizability ofunderlying MLLMs and their steerability via prompting, and (ii) large-scalefine-tuning of MLLMs on web-related tasks. However, web agents still struggleto automate tasks on unseen websites and domains, limiting their applicabilityto enterprise-specific and proprietary platforms. Beyond generalization fromlarge-scale pre-training and fine-tuning, we propose building agents forfew-shot adaptability using human demonstrations. We introduce the AdaptAgentframework that enables both proprietary and open-weights multimodal web agentsto adapt to new websites and domains using few human demonstrations (up to 2).Our experiments on two popular benchmarks -- Mind2Web &amp; VisualWebArena -- showthat using in-context demonstrations (for proprietary models) ormeta-adaptation demonstrations (for meta-learned open-weights models) booststask success rate by 3.36% to 7.21% over non-adapted state-of-the-art models,corresponding to a relative increase of 21.03% to 65.75%. Furthermore, ouradditional analyses (a) show the effectiveness of multimodal demonstrationsover text-only ones, (b) shed light on the influence of different dataselection strategies during meta-learning on the generalization of the agent,and (c) demonstrate the effect of number of few-shot examples on the webagent's success rate. Overall, our results unlock a complementary axis fordeveloping widely applicable multimodal web agents beyond large-scalepre-training and fine-tuning, emphasizing few-shot adaptability.</description><author>Gaurav Verma, Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Tucker Balch, Manuela Veloso</author><pubDate>Wed, 20 Nov 2024 16:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13451v1</guid></item><item><title>CODES: Benchmarking Coupled ODE Surrogates</title><link>http://arxiv.org/abs/2410.20886v2</link><description>We introduce CODES, a benchmark for comprehensive evaluation of surrogatearchitectures for coupled ODE systems. Besides standard metrics like meansquared error (MSE) and inference time, CODES provides insights into surrogatebehaviour across multiple dimensions like interpolation, extrapolation, sparsedata, uncertainty quantification and gradient correlation. The benchmarkemphasizes usability through features such as integrated parallel training, aweb-based configuration generator, and pre-implemented baseline models anddatasets. Extensive documentation ensures sustainability and provides thefoundation for collaborative improvement. By offering a fair and multi-facetedcomparison, CODES helps researchers select the most suitable surrogate fortheir specific dataset and application while deepening our understanding ofsurrogate learning behaviour.</description><author>Robin Janssen, Immanuel Sulzer, Tobias Buck</author><pubDate>Wed, 20 Nov 2024 16:47:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20886v2</guid></item><item><title>Nonlinear Assimilation with Score-based Sequential Langevin Sampling</title><link>http://arxiv.org/abs/2411.13443v1</link><description>This paper presents a novel approach for nonlinear assimilation calledscore-based sequential Langevin sampling (SSLS) within a recursive Bayesianframework. SSLS decomposes the assimilation process into a sequence ofprediction and update steps, utilizing dynamic models for prediction andobservation data for updating via score-based Langevin Monte Carlo. Anannealing strategy is incorporated to enhance convergence and facilitatemulti-modal sampling. The convergence of SSLS in TV-distance is analyzed undercertain conditions, providing insights into error behavior related tohyper-parameters. Numerical examples demonstrate its outstanding performance inhigh-dimensional and nonlinear scenarios, as well as in situations with sparseor partial measurements. Furthermore, SSLS effectively quantifies theuncertainty associated with the estimated states, highlighting its potentialfor error calibration.</description><author>Zhao Ding, Chenguang Duan, Yuling Jiao, Jerry Zhijian Yang, Cheng Yuan, Pingwen Zhang</author><pubDate>Wed, 20 Nov 2024 16:31:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13443v1</guid></item><item><title>Robust Monocular Visual Odometry using Curriculum Learning</title><link>http://arxiv.org/abs/2411.13438v1</link><description>Curriculum Learning (CL), drawing inspiration from natural learning patternsobserved in humans and animals, employs a systematic approach of graduallyintroducing increasingly complex training data during model development. Ourwork applies innovative CL methodologies to address the challenging geometricproblem of monocular Visual Odometry (VO) estimation, which is essential forrobot navigation in constrained environments. The primary objective of ourresearch is to push the boundaries of current state-of-the-art (SOTA)benchmarks in monocular VO by investigating various curriculum learningstrategies. We enhance the end-to-end Deep-Patch-Visual Odometry (DPVO)framework through the integration of novel CL approaches, with the goal ofdeveloping more resilient models capable of maintaining high performance acrosschallenging environments and complex motion scenarios. Our research encompassesseveral distinctive CL strategies. We develop methods to evaluate sampledifficulty based on trajectory motion characteristics, implement sophisticatedadaptive scheduling through self-paced weighted loss mechanisms, and utilizereinforcement learning agents for dynamic adjustment of training emphasis.Through comprehensive evaluation on the real-world TartanAir dataset, ourCurriculum Learning-based Deep-Patch-Visual Odometry (CL-DPVO) demonstratessuperior performance compared to existing SOTA methods, including bothfeature-based and learning-based VO approaches. The results validate theeffectiveness of integrating curriculum learning principles into visualodometry systems.</description><author>Assaf Lahiany, Oren Gal</author><pubDate>Wed, 20 Nov 2024 16:26:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13438v1</guid></item><item><title>SynEHRgy: Synthesizing Mixed-Type Structured Electronic Health Records using Decoder-Only Transformers</title><link>http://arxiv.org/abs/2411.13428v1</link><description>Generating synthetic Electronic Health Records (EHRs) offers significantpotential for data augmentation, privacy-preserving data sharing, and improvingmachine learning model training. We propose a novel tokenization strategytailored for structured EHR data, which encompasses diverse data types such ascovariates, ICD codes, and irregularly sampled time series. Using a GPT-likedecoder-only transformer model, we demonstrate the generation of high-qualitysynthetic EHRs. Our approach is evaluated using the MIMIC-III dataset, and webenchmark the fidelity, utility, and privacy of the generated data againststate-of-the-art models.</description><author>Hojjat Karami, David Atienza, Anisoara Ionescu</author><pubDate>Wed, 20 Nov 2024 16:11:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13428v1</guid></item><item><title>WaterPark: A Robustness Assessment of Language Model Watermarking</title><link>http://arxiv.org/abs/2411.13425v1</link><description>To mitigate the misuse of large language models (LLMs), such asdisinformation, automated phishing, and academic cheating, there is a pressingneed for the capability of identifying LLM-generated texts. Watermarkingemerges as one promising solution: it plants statistical signals into LLMs'generative processes and subsequently verifies whether LLMs produce giventexts. Various watermarking methods (``watermarkers'') have been proposed; yet,due to the lack of unified evaluation platforms, many critical questions remainunder-explored: i) What are the strengths/limitations of various watermarkers,especially their attack robustness? ii) How do various design choices impacttheir robustness? iii) How to optimally operate watermarkers in adversarialenvironments? To fill this gap, we systematize existing LLM watermarkers and watermarkremoval attacks, mapping out their design spaces. We then develop WaterPark, aunified platform that integrates 10 state-of-the-art watermarkers and 12representative attacks. More importantly, leveraging WaterPark, we conduct acomprehensive assessment of existing watermarkers, unveiling the impact ofvarious design choices on their attack robustness. For instance, awatermarker's resilience to increasingly intensive attacks hinges on itscontext dependency. We further explore the best practices to operatewatermarkers in adversarial environments. For instance, using a genericdetector alongside a watermark-specific detector improves the security ofvulnerable watermarkers. We believe our study sheds light on current LLMwatermarking techniques while WaterPark serves as a valuable testbed tofacilitate future research.</description><author>Jiacheng Liang, Zian Wang, Lauren Hong, Shouling Ji, Ting Wang</author><pubDate>Wed, 20 Nov 2024 16:09:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13425v1</guid></item><item><title>CAFE A Novel Code switching Dataset for Algerian Dialect French and English</title><link>http://arxiv.org/abs/2411.13424v1</link><description>The paper introduces and publicly releases (Data download link availableafter acceptance) CAFE -- the first Code-switching dataset between Algeriandialect, French, and english languages. The CAFE speech data is unique for (a)its spontaneous speaking style in vivo human-human conversation capturingphenomena like code-switching and overlapping speech, (b) addresses distinctlinguistic challenges in North African Arabic dialect; (c) the CAFE capturesdialectal variations from various parts of Algeria within differentsociolinguistic contexts. CAFE data contains approximately 37 hours of speech,with a subset, CAFE-small, of 2 hours and 36 minutes released with manual humanannotation including speech segmentation, transcription, explicit annotation ofcode-switching points, overlapping speech, and other events such as noises, andlaughter among others. The rest approximately 34.58 hours contain pseudo labeltranscriptions. In addition to the data release, the paper also highlighted thechallenges of using state-of-the-art Automatic Speech Recognition (ASR) modelssuch as Whisper large-v2,3 and PromptingWhisper to handle such content.Following, we benchmark CAFE data with the aforementioned Whisper models andshow how well-designed data processing pipelines and advanced decodingtechniques can improve the ASR performance in terms of Mixed Error Rate (MER)of 0.310, Character Error Rate (CER) of 0.329 and Word Error Rate (WER) of0.538.</description><author>Houssam Eddine-Othman Lachemat, Akli Abbas, Nourredine Oukas, Yassine El Kheir, Samia Haboussi, Absar Showdhury Shammur</author><pubDate>Wed, 20 Nov 2024 16:09:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13424v1</guid></item><item><title>No Representation, No Trust: Connecting Representation, Collapse, and Trust Issues in PPO</title><link>http://arxiv.org/abs/2405.00662v3</link><description>Reinforcement learning (RL) is inherently rife with non-stationarity sincethe states and rewards the agent observes during training depend on itschanging policy. Therefore, networks in deep RL must be capable of adapting tonew observations and fitting new targets. However, previous works have observedthat networks trained under non-stationarity exhibit an inability to continuelearning, termed loss of plasticity, and eventually a collapse in performance.For off-policy deep value-based RL methods, this phenomenon has been correlatedwith a decrease in representation rank and the ability to fit random targets,termed capacity loss. Although this correlation has generally been attributedto neural network learning under non-stationarity, the connection torepresentation dynamics has not been carefully studied in on-policy policyoptimization methods. In this work, we empirically study representationdynamics in Proximal Policy Optimization (PPO) on the Atari and MuJoCoenvironments, revealing that PPO agents are also affected by feature rankdeterioration and capacity loss. We show that this is aggravated by strongernon-stationarity, ultimately driving the actor's performance to collapse,regardless of the performance of the critic. We ask why the trust region,specific to methods like PPO, cannot alleviate or prevent the collapse and finda connection between representation collapse and the degradation of the trustregion, one exacerbating the other. Finally, we present Proximal FeatureOptimization (PFO), a novel auxiliary loss that, along with otherinterventions, shows that regularizing the representation dynamics mitigatesthe performance collapse of PPO agents.</description><author>Skander Moalla, Andrea Miele, Daniil Pyatko, Razvan Pascanu, Caglar Gulcehre</author><pubDate>Wed, 20 Nov 2024 16:07:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.00662v3</guid></item><item><title>Heuristically Adaptive Diffusion-Model Evolutionary Strategy</title><link>http://arxiv.org/abs/2411.13420v1</link><description>Diffusion Models represent a significant advancement in generative modeling,employing a dual-phase process that first degrades domain-specific informationvia Gaussian noise and restores it through a trainable model. This frameworkenables pure noise-to-data generation and modular reconstruction of, images orvideos. Concurrently, evolutionary algorithms employ optimization methodsinspired by biological principles to refine sets of numerical parametersencoding potential solutions to rugged objective functions. Our researchreveals a fundamental connection between diffusion models and evolutionaryalgorithms through their shared underlying generative mechanisms: both methodsgenerate high-quality samples via iterative refinement on random initialdistributions. By employing deep learning-based diffusion models as generativemodels across diverse evolutionary tasks and iteratively refining diffusionmodels with heuristically acquired databases, we can iteratively samplepotentially better-adapted offspring parameters, integrating them intosuccessive generations of the diffusion model. This approach achieves efficientconvergence toward high-fitness parameters while maintaining explorativediversity. Diffusion models introduce enhanced memory capabilities intoevolutionary algorithms, retaining historical information across generationsand leveraging subtle data correlations to generate refined samples. We elevateevolutionary algorithms from procedures with shallow heuristics to frameworkswith deep memory. By deploying classifier-free guidance for conditionalsampling at the parameter level, we achieve precise control over evolutionarysearch dynamics to further specific genotypical, phenotypical, orpopulation-wide traits. Our framework marks a major heuristic and algorithmictransition, offering increased flexibility, precision, and control inevolutionary optimization processes.</description><author>Benedikt Hartl, Yanbo Zhang, Hananel Hazan, Michael Levin</author><pubDate>Wed, 20 Nov 2024 16:06:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13420v1</guid></item><item><title>A Survey On Enhancing Reinforcement Learning in Complex Environments: Insights from Human and LLM Feedback</title><link>http://arxiv.org/abs/2411.13410v1</link><description>Reinforcement learning (RL) is one of the active fields in machine learning,demonstrating remarkable potential in tackling real-world challenges. Despiteits promising prospects, this methodology has encountered with issues andchallenges, hindering it from achieving the best performance. In particular,these approaches lack decent performance when navigating environments andsolving tasks with large observation space, often resulting insample-inefficiency and prolonged learning times. This issue, commonly referredto as the curse of dimensionality, complicates decision-making for RL agents,necessitating a careful balance between attention and decision-making. RLagents, when augmented with human or large language models' (LLMs) feedback,may exhibit resilience and adaptability, leading to enhanced performance andaccelerated learning. Such feedback, conveyed through various modalities orgranularities including natural language, serves as a guide for RL agents,aiding them in discerning relevant environmental cues and optimizingdecision-making processes. In this survey paper, we mainly focus on problems oftwo-folds: firstly, we focus on humans or an LLMs assistance, investigating theways in which these entities may collaborate with the RL agent in order tofoster optimal behavior and expedite learning; secondly, we delve into theresearch papers dedicated to addressing the intricacies of environmentscharacterized by large observation space.</description><author>Alireza Rashidi Laleh, Majid Nili Ahmadabadi</author><pubDate>Wed, 20 Nov 2024 15:52:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13410v1</guid></item><item><title>Unification of Balti and trans-border sister dialects in the essence of LLMs and AI Technology</title><link>http://arxiv.org/abs/2411.13409v1</link><description>The language called Balti belongs to the Sino-Tibetan, specifically theTibeto-Burman language family. It is understood with variations, acrosspopulations in India, China, Pakistan, Nepal, Tibet, Burma, and Bhutan,influenced by local cultures and producing various dialects. Considering thediverse cultural, socio-political, religious, and geographical impacts, it isimportant to step forward unifying the dialects, the basis of common root,lexica, and phonological perspectives, is vital. In the era of globalizationand the increasingly frequent developments in AI technology, understanding thediversity and the efforts of dialect unification is important to understandingcommonalities and shortening the gaps impacted by unavoidable circumstances.This article analyzes and examines how artificial intelligence AI in theessence of Large Language Models LLMs, can assist in analyzing, documenting,and standardizing the endangered Balti Language, based on the efforts made indifferent dialects so far.</description><author>Muhammad Sharif, Jiangyan Yi, Muhammad Shoaib</author><pubDate>Wed, 20 Nov 2024 15:48:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13409v1</guid></item><item><title>Transformer-Based Contextualized Language Models Joint with Neural Networks for Natural Language Inference in Vietnamese</title><link>http://arxiv.org/abs/2411.13407v1</link><description>Natural Language Inference (NLI) is a task within Natural Language Processing(NLP) that holds value for various AI applications. However, there have beenlimited studies on Natural Language Inference in Vietnamese that explore theconcept of joint models. Therefore, we conducted experiments using variouscombinations of contextualized language models (CLM) and neural networks. Weuse CLM to create contextualized work presentations and use Neural Networks forclassification. Furthermore, we have evaluated the strengths and weaknesses ofeach joint model and identified the model failure points in the Vietnamesecontext. The highest F1 score in this experiment, up to 82.78\% in thebenchmark dataset (ViNLI). By conducting experiments with various models, themost considerable size of the CLM is XLM-R (355M). That combination hasconsistently demonstrated superior performance compared to fine-tuning strongpre-trained language models like PhoBERT (+6.58\%), mBERT (+19.08\%), and XLM-R(+0.94\%) in terms of F1-score. This article aims to introduce a novel approachor model that attains improved performance for Vietnamese NLI. Overall, we findthat the joint approach of CLM and neural networks is simple yet capable ofachieving high-quality performance, which makes it suitable for applicationsthat require efficient resource utilization.</description><author>Dat Van-Thanh Nguyen, Tin Van Huynh, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen</author><pubDate>Wed, 20 Nov 2024 15:46:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13407v1</guid></item><item><title>On the Way to LLM Personalization: Learning to Remember User Conversations</title><link>http://arxiv.org/abs/2411.13405v1</link><description>Large Language Models (LLMs) have quickly become an invaluable assistant fora variety of tasks. However, their effectiveness is constrained by theirability to tailor responses to human preferences and behaviors viapersonalization. Prior work in LLM personalization has largely focused on styletransfer or incorporating small factoids about the user, as knowledge injectionremains an open challenge. In this paper, we explore injecting knowledge ofprior conversations into LLMs to enable future work on less redundant,personalized conversations. We identify two real-world constraints: (1)conversations are sequential in time and must be treated as such duringtraining, and (2) per-user personalization is only viable inparameter-efficient settings. To this aim, we propose PLUM, a pipelineperforming data augmentation for up-sampling conversations as question-answerpairs, that are then used to finetune a low-rank adaptation adapter with aweighted cross entropy loss. Even in this first exploration of the problem, weperform competitively with baselines such as RAG, attaining an accuracy of81.5% across 100 conversations.</description><author>Lucie Charlotte Magister, Katherine Metcalf, Yizhe Zhang, Maartje ter Hoeve</author><pubDate>Wed, 20 Nov 2024 15:45:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13405v1</guid></item><item><title>When Context Leads but Parametric Memory Follows in Large Language Models</title><link>http://arxiv.org/abs/2409.08435v3</link><description>Large language models (LLMs) have demonstrated remarkable progress inleveraging diverse knowledge sources. This study investigates how nine widelyused LLMs allocate knowledge between local context and global parameters whenanswering open-ended questions in knowledge-consistent scenarios. We introducea novel dataset, WikiAtomic, and systematically vary context sizes to analyzehow LLMs prioritize and utilize the provided information and their parametricknowledge in knowledge-consistent scenarios. Additionally, we also study theirtendency to hallucinate under varying context sizes. Our findings revealconsistent patterns across models, including a consistent reliance on bothcontextual (around 70%) and parametric (around 30%) knowledge, and a decreasein hallucinations with increasing context. These insights highlight theimportance of more effective context organization and developing models thatuse input more deterministically for robust performance.</description><author>Yufei Tao, Adam Hiatt, Erik Haake, Antonie J. Jetter, Ameeta Agrawal</author><pubDate>Wed, 20 Nov 2024 15:41:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.08435v3</guid></item><item><title>Executable QR codes with Machine Learning for Industrial Applications</title><link>http://arxiv.org/abs/2411.13400v1</link><description>Executable QR codes, also known as eQR codes or just sQRy, are a special kindof QR codes that embed programs conceived to run on mobile devices likesmartphones. Since the program is directly encoded in binary form within the QRcode, it can be executed even when the reading device is not provided withInternet access. The applications of this technology are manifold, and rangefrom smart user guides to advisory systems. The first programming language madeavailable for eQR is QRtree, which enables the implementation of decision treesaimed, for example, at guiding the user in operating/maintaining a complexmachinery or for reaching a specific location. In this work, an additional language is proposed, we term QRind, which wasspecifically devised for Industry. It permits to integrate distinctcomputational blocks into the QR code, e.g., machine learning models to enablepredictive maintenance and algorithms to ease machinery usage. QRind permitsthe Industry 4.0/5.0 paradigms to be implemented, in part, also in those caseswhere Internet is unavailable.</description><author>Stefano Scanzio, Francesco Velluto, Matteo Rosani, Lukasz Wisniewski, Gianluca Cena</author><pubDate>Wed, 20 Nov 2024 15:38:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13400v1</guid></item><item><title>Sensitivity Analysis on Policy-Augmented Graphical Hybrid Models with Shapley Value Estimation</title><link>http://arxiv.org/abs/2411.13396v1</link><description>Driven by the critical challenges in biomanufacturing, including highcomplexity and high uncertainty, we propose a comprehensive and computationallyefficient sensitivity analysis framework for general nonlinear policy-augmentedknowledge graphical (pKG) hybrid models that characterize the risk- andscience-based understandings of underlying stochastic decision processmechanisms. The criticality of each input (i.e., random factors, policyparameters, and model parameters) is measured by applying Shapley value (SV)sensitivity analysis to pKG (called SV-pKG), accounting for process causalinterdependences. To quickly assess the SV for heavily instrumentedbioprocesses, we approximate their dynamics with linear Gaussian pKG models andimprove the SV estimation efficiency by utilizing the linear Gaussianproperties. In addition, we propose an effective permutation sampling methodwith TFWW transformation and variance reduction techniques, namely thequasi-Monte Carlo and antithetic sampling methods, to further improve thesampling efficiency and estimation accuracy of SV for both general nonlinearand linear Gaussian pKG models. Our proposed framework can benefit efficientinterpretation and support stable optimal process control in biomanufacturing.</description><author>Junkai Zhao, Wei Xie, Jun Luo</author><pubDate>Wed, 20 Nov 2024 15:33:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13396v1</guid></item><item><title>Adversarial Diffusion Compression for Real-World Image Super-Resolution</title><link>http://arxiv.org/abs/2411.13383v1</link><description>Real-world image super-resolution (Real-ISR) aims to reconstructhigh-resolution images from low-resolution inputs degraded by complex, unknownprocesses. While many Stable Diffusion (SD)-based Real-ISR methods haveachieved remarkable success, their slow, multi-step inference hinders practicaldeployment. Recent SD-based one-step networks like OSEDiff and S3Diff alleviatethis issue but still incur high computational costs due to their reliance onlarge pretrained SD models. This paper proposes a novel Real-ISR method, AdcSR,by distilling the one-step diffusion network OSEDiff into a streamlineddiffusion-GAN model under our Adversarial Diffusion Compression (ADC)framework. We meticulously examine the modules of OSEDiff, categorizing theminto two types: (1) Removable (VAE encoder, prompt extractor, text encoder,etc.) and (2) Prunable (denoising UNet and VAE decoder). Since direct removaland pruning can degrade the model's generation capability, we pretrain ourpruned VAE decoder to restore its ability to decode images and employadversarial distillation to compensate for performance loss. This ADC-baseddiffusion-GAN hybrid design effectively reduces complexity by 73% in inferencetime, 78% in computation, and 74% in parameters, while preserving the model'sgeneration capability. Experiments manifest that our proposed AdcSR achievescompetitive recovery quality on both synthetic and real-world datasets,offering up to 9.3$\times$ speedup over previous one-step diffusion-basedmethods. Code and models will be made available.</description><author>Bin Chen, Gehui Li, Rongyuan Wu, Xindong Zhang, Jie Chen, Jian Zhang, Lei Zhang</author><pubDate>Wed, 20 Nov 2024 15:13:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13383v1</guid></item><item><title>Jointly Modeling and Clustering Tensors in High Dimensions</title><link>http://arxiv.org/abs/2104.07773v3</link><description>We consider the problem of jointly modeling and clustering populations oftensors by introducing a high-dimensional tensor mixture model withheterogeneous covariances. To effectively tackle the high dimensionality oftensor objects, we employ plausible dimension reduction assumptions thatexploit the intrinsic structures of tensors such as low-rankness in the meanand separability in the covariance. In estimation, we develop an efficienthigh-dimensional expectation-conditional-maximization (HECM) algorithm thatbreaks the intractable optimization in the M-step into a sequence of muchsimpler conditional optimization problems, each of which is convex, admitsregularization and has closed-form updating formulas. Our theoretical analysisis challenged by both the non-convexity in the EM-type estimation and havingaccess to only the solutions of conditional maximizations in the M-step,leading to the notion of dual non-convexity. We demonstrate that the proposedHECM algorithm, with an appropriate initialization, converges geometrically toa neighborhood that is within statistical precision of the true parameter. Theefficacy of our proposed method is demonstrated through comparative numericalexperiments and an application to a medical study, where our proposal achievesan improved clustering accuracy over existing benchmarking methods.</description><author>Biao Cai, Jingfei Zhang, Will Wei Sun</author><pubDate>Wed, 20 Nov 2024 15:06:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2104.07773v3</guid></item><item><title>Provable unlearning in topic modeling and downstream tasks</title><link>http://arxiv.org/abs/2411.12600v2</link><description>Machine unlearning algorithms are increasingly important as legal concernsarise around the provenance of training data, but verifying the success ofunlearning is often difficult. Provable guarantees for unlearning are oftenlimited to supervised learning settings. In this paper, we provide the firsttheoretical guarantees for unlearning in the pre-training and fine-tuningparadigm by studying topic models, simple bag-of-words language models that canbe adapted to solve downstream tasks like retrieval and classification. First,we design a provably effective unlearning algorithm for topic models thatincurs a computational overhead independent of the size of the originaldataset. Our analysis additionally quantifies the deletion capacity of themodel -- i.e., the number of examples that can be unlearned without incurring asignificant cost in model performance. Finally, we formally extend our analysesto account for adaptation to a given downstream task. In particular, we designan efficient algorithm to perform unlearning after fine-tuning the topic modelvia a linear head. Notably, we show that it is easier to unlearn pre-trainingdata from models that have been fine-tuned to a particular task, and one canunlearn this data without modifying the base model.</description><author>Stanley Wei, Sadhika Malladi, Sanjeev Arora, Amartya Sanyal</author><pubDate>Wed, 20 Nov 2024 15:01:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12600v2</guid></item><item><title>Quantum-Brain: Quantum-Inspired Neural Network Approach to Vision-Brain Understanding</title><link>http://arxiv.org/abs/2411.13378v1</link><description>Vision-brain understanding aims to extract semantic information about brainsignals from human perceptions. Existing deep learning methods for vision-brainunderstanding are usually introduced in a traditional learning paradigm missingthe ability to learn the connectivities between brain regions. Meanwhile, thequantum computing theory offers a new paradigm for designing deep learningmodels. Motivated by the connectivities in the brain signals and theentanglement properties in quantum computing, we propose a novel Quantum-Brainapproach, a quantum-inspired neural network, to tackle the vision-brainunderstanding problem. To compute the connectivity between areas in brainsignals, we introduce a new Quantum-Inspired Voxel-Controlling module to learnthe impact of a brain voxel on others represented in the Hilbert space. Toeffectively learn connectivity, a novel Phase-Shifting module is presented tocalibrate the value of the brain signals. Finally, we introduce a newMeasurement-like Projection module to present the connectivity information fromthe Hilbert space into the feature space. The proposed approach can learn tofind the connectivities between fMRI voxels and enhance the semanticinformation obtained from human perceptions. Our experimental results on theNatural Scene Dataset benchmarks illustrate the effectiveness of the proposedmethod with Top-1 accuracies of 95.1% and 95.6% on image and brain retrievaltasks and an Inception score of 95.3% on fMRI-to-image reconstruction task. Ourproposed quantum-inspired network brings a potential paradigm to solving thevision-brain problems via the quantum computing theory.</description><author>Hoang-Quan Nguyen, Xuan-Bac Nguyen, Hugh Churchill, Arabinda Kumar Choudhary, Pawan Sinha, Samee U. Khan, Khoa Luu</author><pubDate>Wed, 20 Nov 2024 14:59:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13378v1</guid></item><item><title>ODTE -- An ensemble of multi-class SVM-based oblique decision trees</title><link>http://arxiv.org/abs/2411.13376v1</link><description>We propose ODTE, a new ensemble that uses oblique decision trees as baseclassifiers. Additionally, we introduce STree, the base algorithm for growingoblique decision trees, which leverages support vector machines to definehyperplanes within the decision nodes. We embed a multiclass strategy --one-vs-one or one-vs-rest -- at the decision nodes, allowing the model todirectly handle non-binary classification tasks without the need to clusterinstances into two groups, as is common in other approaches from theliterature. In each decision node, only the best-performing model SVM -- theone that minimizes an impurity measure for the n-ary classification -- isretained, even if the learned SVM addresses a binary classification subtask. Anextensive experimental study involving 49 datasets and various state-of-the-artalgorithms for oblique decision tree ensembles has been conducted. Our resultsshow that ODTE ranks consistently above its competitors, achieving significantperformance gains when hyperparameters are carefully tuned. Moreover, theoblique decision trees learned through STree are more compact than thoseproduced by other algorithms evaluated in our experiments.</description><author>Ricardo Montañana, José A. Gámez, José M. Puerta</author><pubDate>Wed, 20 Nov 2024 14:58:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13376v1</guid></item><item><title>Predicting Wall Thickness Changes in Cold Forging Processes: An Integrated FEM and Neural Network approach</title><link>http://arxiv.org/abs/2411.13366v1</link><description>This study presents a novel approach for predicting wall thickness changes intubes during the nosing process. Specifically, we first provide a thoroughanalysis of nosing processes and the influencing parameters. We further set-upa Finite Element Method (FEM) simulation to better analyse the effects ofvarying process parameters. As however traditional FEM simulations, whileaccurate, are time-consuming and computationally intensive, which renders theminapplicable for real-time application, we present a novel modeling frameworkbased on specifically designed graph neural networks as surrogate models. Tothis end, we extend the neural network architecture by directly incorporatinginformation about the nosing process by adding different types of edges andtheir corresponding encoders to model object interactions. This augmentationenhances model accuracy and opens the possibility for employing precisesurrogate models within closed-loop production processes. The proposed approachis evaluated using a new evaluation metric termed area between thickness curves(ABTC). The results demonstrate promising performance and highlight thepotential of neural networks as surrogate models in predicting wall thicknesschanges during nosing forging processes.</description><author>Sasa Ilic, Abdulkerim Karaman, Johannes Pöppelbaum, Jan Niclas Reimann, Michael Marré, Andreas Schwung</author><pubDate>Wed, 20 Nov 2024 14:42:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13366v1</guid></item><item><title>Explainable Finite-Memory Policies for Partially Observable Markov Decision Processes</title><link>http://arxiv.org/abs/2411.13365v1</link><description>Partially Observable Markov Decision Processes (POMDPs) are a fundamentalframework for decision-making under uncertainty and partial observability.Since in general optimal policies may require infinite memory, they are hard toimplement and often render most problems undecidable. Consequently,finite-memory policies are mostly considered instead. However, the algorithmsfor computing them are typically very complex, and so are the resultingpolicies. Facing the need for their explainability, we provide a representationof such policies, both (i) in an interpretable formalism and (ii) typically ofsmaller size, together yielding higher explainability. To that end, we combinemodels of Mealy machines and decision trees; the latter describing simple,stationary parts of the policies and the former describing how to switch amongthem. We design a translation for policies of the finite-state-controller (FSC)form from standard literature and show how our method smoothly generalizes toother variants of finite-memory policies. Further, we identify specificproperties of recently used "attractor-based" policies, which allow us toconstruct yet simpler and smaller representations. Finally, we illustrate thehigher explainability in a few case studies.</description><author>Muqsit Azeem, Debraj Chakraborty, Sudeep Kanav, Jan Kretinsky</author><pubDate>Wed, 20 Nov 2024 14:42:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13365v1</guid></item><item><title>RTSR: A Real-Time Super-Resolution Model for AV1 Compressed Content</title><link>http://arxiv.org/abs/2411.13362v1</link><description>Super-resolution (SR) is a key technique for improving the visual quality ofvideo content by increasing its spatial resolution while reconstructing finedetails. SR has been employed in many applications including video streaming,where compressed low-resolution content is typically transmitted to end usersand then reconstructed with a higher resolution and enhanced quality. Tosupport real-time playback, it is important to implement fast SR models whilepreserving reconstruction quality; however most existing solutions, inparticular those based on complex deep neural networks, fail to do so. Toaddress this issue, this paper proposes a low-complexity SR method, RTSR,designed to enhance the visual quality of compressed video content, focusing onresolution up-scaling from a) 360p to 1080p and from b) 540p to 4K. Theproposed approach utilizes a CNN-based network architecture, which wasoptimized for AV1 (SVT)-encoded content at various quantization levels based ona dual-teacher knowledge distillation method. This method was submitted to theAIM 2024 Video Super-Resolution Challenge, specifically targeting theEfficient/Mobile Real-Time Video Super-Resolution competition. It achieved thebest trade-off between complexity and coding performance (measured in PSNR,SSIM and VMAF) among all six submissions. The code will be available soon.</description><author>Yuxuan Jiang, Jakub Nawała, Chen Feng, Fan Zhang, Xiaoqing Zhu, Joel Sole, David Bull</author><pubDate>Wed, 20 Nov 2024 14:36:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13362v1</guid></item><item><title>Integration of Active Learning and MCMC Sampling for Efficient Bayesian Calibration of Mechanical Properties</title><link>http://arxiv.org/abs/2411.13361v1</link><description>Recent advancements in Markov chain Monte Carlo (MCMC) sampling and surrogatemodelling have significantly enhanced the feasibility of Bayesian analysisacross engineering fields. However, the selection and integration of surrogatemodels and cutting-edge MCMC algorithms, often depend on ad-hoc decisions. Asystematic assessment of their combined influence on analytical accuracy andefficiency is notably lacking. The present work offers a comprehensivecomparative study, employing a scalable case study in computational mechanicsfocused on the inference of spatially varying material parameters, that shedslight on the impact of methodological choices for surrogate modelling andsampling. We show that a priori training of the surrogate model introduceslarge errors in the posterior estimation even in low to moderate dimensions. Weintroduce a simple active learning strategy based on the path of the MCMCalgorithm that is superior to all a priori trained models, and determine itstraining data requirements. We demonstrate that the choice of the MCMCalgorithm has only a small influence on the amount of training data but nosignificant influence on the accuracy of the resulting surrogate model.Further, we show that the accuracy of the posterior estimation largely dependson the surrogate model, but not even a tailored surrogate guaranteesconvergence of the MCMC.Finally, we identify the forward model as thebottleneck in the inference process, not the MCMC algorithm. While relatedworks focus on employing advanced MCMC algorithms, we demonstrate that thetraining data requirements render the surrogate modelling approach infeasiblebefore the benefits of these gradient-based MCMC algorithms on cheap models canbe reaped.</description><author>Leon Riccius, Iuri B. C. M. Rocha, Joris Bierkens, Hanne Kekkonen, Frans P. van der Meer</author><pubDate>Wed, 20 Nov 2024 14:35:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13361v1</guid></item><item><title>Random Representations Outperform Online Continually Learned Representations</title><link>http://arxiv.org/abs/2402.08823v3</link><description>Continual learning has primarily focused on the issue of catastrophicforgetting and the associated stability-plasticity tradeoffs. However, littleattention has been paid to the efficacy of continually learned representations,as representations are learned alongside classifiers throughout the learningprocess. Our primary contribution is empirically demonstrating that existingonline continually trained deep networks produce inferior representationscompared to a simple pre-defined random transforms. Our approach projects rawpixels using a fixed random transform, approximating an RBF-Kernel initializedbefore any data is seen. We then train a simple linear classifier on topwithout storing any exemplars, processing one sample at a time in an onlinecontinual learning setting. This method, called RanDumb, significantlyoutperforms state-of-the-art continually learned representations across allstandard online continual learning benchmarks. Our study reveals thesignificant limitations of representation learning, particularly inlow-exemplar and online continual learning scenarios. Extending ourinvestigation to popular exemplar-free scenarios with pretrained models, wefind that training only a linear classifier on top of pretrainedrepresentations surpasses most continual fine-tuning and prompt-tuningstrategies. Overall, our investigation challenges the prevailing assumptionsabout effective representation learning in online continual learning. Our codeis available at://github.com/drimpossible/RanDumb.</description><author>Ameya Prabhu, Shiven Sinha, Ponnurangam Kumaraguru, Philip H. S. Torr, Ozan Sener, Puneet K. Dokania</author><pubDate>Wed, 20 Nov 2024 14:33:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08823v3</guid></item><item><title>Vertical Validation: Evaluating Implicit Generative Models for Graphs on Thin Support Regions</title><link>http://arxiv.org/abs/2411.13358v1</link><description>There has been a growing excitement that implicit graph generative modelscould be used to design or discover new molecules for medicine or materialdesign. Because these molecules have not been discovered, they naturally lie inunexplored or scarcely supported regions of the distribution of knownmolecules. However, prior evaluation methods for implicit graph generativemodels have focused on validating statistics computed from the thick support(e.g., mean and variance of a graph property). Therefore, there is a mismatchbetween the goal of generating novel graphs and the evaluation methods. Toaddress this evaluation gap, we design a novel evaluation method calledVertical Validation (VV) that systematically creates thin support regionsduring the train-test splitting procedure and then reweights generated samplesso that they can be compared to the held-out test data. This procedure can beseen as a generalization of the standard train-test procedure except that thesplits are dependent on sample features. We demonstrate that our method can beused to perform model selection if performance on thin support regions is thedesired goal. As a side benefit, we also show that our approach can betterdetect overfitting as exemplified by memorization.</description><author>Mai Elkady, Thu Bui, Bruno Ribeiro, David I. Inouye</author><pubDate>Wed, 20 Nov 2024 14:29:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13358v1</guid></item><item><title>Conditional Denoising Diffusion Probabilistic Models for Data Reconstruction Enhancement in Wireless Communications</title><link>http://arxiv.org/abs/2310.19460v3</link><description>In this paper, conditional denoising diffusion probabilistic models (DDPMs)are proposed to enhance the data transmission and reconstruction over wirelesschannels. The underlying mechanism of DDPM is to decompose the data generationprocess over the so-called "denoising" steps. Inspired by this, the key idea isto leverage the generative prior of diffusion models in learning a"noisy-to-clean" transformation of the information signal to help enhance datareconstruction. The proposed scheme could be beneficial for communicationscenarios in which a prior knowledge of the information content is available,e.g., in multimedia transmission. Hence, instead of employing complicatedchannel codes that reduce the information rate, one can exploit diffusionpriors for reliable data reconstruction, especially under extreme channelconditions due to low signal-to-noise ratio (SNR), or hardware-impairedcommunications. The proposed DDPM-assisted receiver is tailored for thescenario of wireless image transmission using MNIST dataset. Our numericalresults highlight the reconstruction performance of our scheme compared to theconventional digital communication, as well as the deep neural network(DNN)-based benchmark. It is also shown that more than 10 dB improvement in thereconstruction could be achieved in low SNR regimes, without the need to reducethe information rate for error correction.</description><author>Mehdi Letafati, Samad Ali, Matti Latva-aho</author><pubDate>Wed, 20 Nov 2024 14:24:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19460v3</guid></item><item><title>Learning based Ge'ez character handwritten recognition</title><link>http://arxiv.org/abs/2411.13350v1</link><description>Ge'ez, an ancient Ethiopic script of cultural and historical significance,has been largely neglected in handwriting recognition research, hindering thedigitization of valuable manuscripts. Our study addresses this gap bydeveloping a state-of-the-art Ge'ez handwriting recognition system usingConvolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM)networks. Our approach uses a two-stage recognition process. First, a CNN istrained to recognize individual characters, which then acts as a featureextractor for an LSTM-based system for word recognition. Our dual-stagerecognition approach achieves new top scores in Ge'ez handwriting recognition,outperforming eight state-of-the-art methods, which are SVTR, ASTER, and othersas well as human performance, as measured in the HHD-Ethiopic dataset work.This research significantly advances the preservation and accessibility ofGe'ez cultural heritage, with implications for historical documentdigitization, educational tools, and cultural preservation. The code will bereleased upon acceptance.</description><author>Hailemicael Lulseged Yimer, Hailegabriel Dereje Degefa, Marco Cristani, Federico Cunico</author><pubDate>Wed, 20 Nov 2024 14:22:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13350v1</guid></item><item><title>Neuron Patching: Semantic-based Neuron-level Language Model Repair for Code Generation</title><link>http://arxiv.org/abs/2312.05356v5</link><description>Language Models (LMs) have become widely used in software engineering,especially for tasks such as code generation, where they are referred to ascode LMs. These models have proven effective in generating code, making iteasier for developers to automate coding activities. However, research hashighlighted a significant limitation: despite their effectiveness, LMs oftenproduce code that is incorrect, buggy, or not fully functional. Updating thesemodels with limited data can be prohibitively challenging, yet it is essentialto maximize their utility. This may require hot-fix techniques (updating modelswith limited data) to resolve. In this paper, we propose \ul{M}odel\ul{I}mprovement via \ul{N}euron \ul{T}argeting (\textsc{MINT}), a novelapproach for repairing code LMs. MINT leverages the semantic property oflanguage models to perform neuron-level repairs in a novel way. Further, byanalyzing the relationships between the model's latent representations, theincorrect outputs, and the desired outputs, \textsc{MINT} determines whichneurons are worth updating. This approach ensures that only the neurons crucialto the model's failure are targeted, avoiding unnecessary changes and allowingfor a more efficient and precise repair process. \textsc{MINT} is effective,efficient, and reliable, capable of correcting a neural model by patching aminimum number of neurons (usually one or two neurons). Our approach isevaluated on three coding tasks: line-level code generation, shellcodegeneration, and intent-to-bash translation. The experimental resultsdemonstrate that the proposed approach significantly outperforms thestate-of-the-art in both effectiveness and efficiency measures. In addition, weanalyze and discuss the side effects of model repair techniques, including thebalance between generalization and specificity, and the performance aftermultiple repairs in succession.</description><author>Jian Gu, Aldeida Aleti, Chunyang Chen, Hongyu Zhang</author><pubDate>Wed, 20 Nov 2024 14:22:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05356v5</guid></item><item><title>Fact-Level Confidence Calibration and Self-Correction</title><link>http://arxiv.org/abs/2411.13343v1</link><description>Confidence calibration in LLMs, i.e., aligning their self-assessed confidencewith the actual accuracy of their responses, enabling them to self-evaluate thecorrectness of their outputs. However, current calibration methods for LLMstypically estimate two scalars to represent overall response confidence andcorrectness, which is inadequate for long-form generation where the responseincludes multiple atomic facts and may be partially confident and correct.These methods also overlook the relevance of each fact to the query. To addressthese challenges, we propose a Fact-Level Calibration framework that operatesat a finer granularity, calibrating confidence to relevance-weightedcorrectness at the fact level. Furthermore, comprehensive analysis under theframework inspired the development of Confidence-Guided Fact-levelSelf-Correction ($\textbf{ConFix}$), which uses high-confidence facts within aresponse as additional knowledge to improve low-confidence ones. Extensiveexperiments across four datasets and six models demonstrate that ConFixeffectively mitigates hallucinations without requiring external knowledgesources such as retrieval systems.</description><author>Yige Yuan, Bingbing Xu, Hexiang Tan, Fei Sun, Teng Xiao, Wei Li, Huawei Shen, Xueqi Cheng</author><pubDate>Wed, 20 Nov 2024 14:15:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13343v1</guid></item><item><title>WHALES: A Multi-agent Scheduling Dataset for Enhanced Cooperation in Autonomous Driving</title><link>http://arxiv.org/abs/2411.13340v1</link><description>Achieving high levels of safety and reliability in autonomous driving remainsa critical challenge, especially due to occlusion and limited perception rangesin standalone systems. Cooperative perception among vehicles offers a promisingsolution, but existing research is hindered by datasets with a limited numberof agents. Scaling up the number of cooperating agents is non-trivial andintroduces significant computational and technical hurdles that have not beenaddressed in previous works. To bridge this gap, we present Wireless enHancedAutonomous vehicles with Large number of Engaged agentS (WHALES), a datasetgenerated using CARLA simulator that features an unprecedented average of 8.4agents per driving sequence. In addition to providing the largest number ofagents and viewpoints among autonomous driving datasets, WHALES records agentbehaviors, enabling cooperation across multiple tasks. This expansion allowsfor new supporting tasks in cooperative perception. As a demonstration, weconduct experiments on agent scheduling task, where the ego agent selects oneof multiple candidate agents to cooperate with, optimizing perception gains inautonomous driving. The WHALES dataset and codebase can be found athttps://github.com/chensiweiTHU/WHALES.</description><author>Siwei Chen, Yinsong, Wang, Ziyi Song, Sheng Zhou</author><pubDate>Wed, 20 Nov 2024 14:12:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13340v1</guid></item><item><title>Verifying Machine Unlearning with Explainable AI</title><link>http://arxiv.org/abs/2411.13332v1</link><description>We investigate the effectiveness of Explainable AI (XAI) in verifying MachineUnlearning (MU) within the context of harbor front monitoring, focusing on dataprivacy and regulatory compliance. With the increasing need to adhere toprivacy legislation such as the General Data Protection Regulation (GDPR),traditional methods of retraining ML models for data deletions proveimpractical due to their complexity and resource demands. MU offers a solutionby enabling models to selectively forget specific learned patterns without fullretraining. We explore various removal techniques, including data relabeling,and model perturbation. Then, we leverage attribution-based XAI to discuss theeffects of unlearning on model performance. Our proof-of-concept introducesfeature importance as an innovative verification step for MU, expanding beyondtraditional metrics and demonstrating techniques' ability to reduce reliance onundesired patterns. Additionally, we propose two novel XAI-based metrics,Heatmap Coverage (HC) and Attention Shift (AS), to evaluate the effectivenessof these methods. This approach not only highlights how XAI can complement MUby providing effective verification, but also sets the stage for futureresearch to enhance their joint integration.</description><author>Àlex Pujol Vidal, Anders S. Johansen, Mohammad N. S. Jahromi, Sergio Escalera, Kamal Nasrollahi, Thomas B. Moeslund</author><pubDate>Wed, 20 Nov 2024 13:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13332v1</guid></item><item><title>Constraint Learning for Parametric Point Cloud</title><link>http://arxiv.org/abs/2411.07747v3</link><description>Parametric point clouds are sampled from CAD shapes, and have becomeincreasingly prevalent in industrial manufacturing. However, most existingpoint cloud learning methods focus on the geometric features, such asdeveloping efficient convolution operations, overlooking the importantattribute of constraints inherent in CAD shapes, which limits these methods'ability to comprehend CAD shapes fully. To address this issue, we analyzed theeffect of constraints, and proposed its deep learning-friendly representation,after that, the Constraint Feature Learning Network (CstNet) was developed toextract and leverage constraints. Our CstNet includes two stages. Stage 1extracts constraints from B-Rep data or point cloud. Stage 2 leveragescoordinates and constraints to enhance the comprehension of CAD shapes.Additionally, we built up the Parametric 20,000 Multi-modal Dataset for thescarcity of labeled B-Rep datasets. Experiments demonstrate that our CstNetachieved state-of-the-art performance on both public and proposed CAD shapedatasets. To the best of our knowledge, CstNet is the first constraint-basedlearning method tailored for CAD shape analysis.</description><author>Xi Cheng, Ruiqi Lei, Di Huang, Zhichao Liao, Fengyuan Piao, Yan Chen, Pingfa Feng, Long Zeng</author><pubDate>Wed, 20 Nov 2024 13:56:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.07747v3</guid></item><item><title>Revisiting Discrete Soft Actor-Critic</title><link>http://arxiv.org/abs/2209.10081v4</link><description>We study the adaption of Soft Actor-Critic (SAC), which is considered as astate-of-the-art reinforcement learning (RL) algorithm, from continuous actionspace to discrete action space. We revisit vanilla discrete SAC and provide anin-depth understanding of its Q value underestimation and performanceinstability issues when applied to discrete settings. We thereby propose StableDiscrete SAC (SDSAC), an algorithm that leverages entropy-penalty and doubleaverage Q-learning with Q-clip to address these issues. Extensive experimentson typical benchmarks with discrete action space, including Atari games and alarge-scale MOBA game, show the efficacy of our proposed method. Our code isat: https://github.com/coldsummerday/SD-SAC.git.</description><author>Haibin Zhou, Tong Wei, Zichuan Lin, junyou li, Junliang Xing, Yuanchun Shi, Li Shen, Chao Yu, Deheng Ye</author><pubDate>Wed, 20 Nov 2024 13:52:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.10081v4</guid></item><item><title>An Evolutional Neural Network Framework for Classification of Microarray Data</title><link>http://arxiv.org/abs/2411.13326v1</link><description>DNA microarray gene-expression data has been widely used to identifycancerous gene signatures. Microarray can increase the accuracy of cancerdiagnosis and prognosis. However, analyzing the large amount of gene expressiondata from microarray chips pose a challenge for current machine learningresearches. One of the challenges lie within classification of healthy andcancerous tissues is high dimensionality of gene expressions. Highdimensionality decreases the accuracy of the classification. This research aimsto apply a hybrid model of Genetic Algorithm and Neural Network to overcome theproblem during subset selection of informative genes. Whereby, a GeneticAlgorithm (GA) reduced dimensionality during feature selection and then aMulti-Layer perceptron Neural Network (MLP) is applied to classify selectedgenes. The performance evaluated by considering to the accuracy and the numberof selected genes. Experimental results show the proposed method suggested highaccuracy and minimum number of selected genes in comparison with other machinelearning algorithms.</description><author>Maryam Eshraghi Evari, Md Nasir Sulaiman, Amir Rajabi Behjat</author><pubDate>Wed, 20 Nov 2024 13:48:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13326v1</guid></item><item><title>Are Large Language Models Memorizing Bug Benchmarks?</title><link>http://arxiv.org/abs/2411.13323v1</link><description>Large Language Models (LLMs) have become integral to various softwareengineering tasks, including code generation, bug detection, and repair. Toevaluate model performance in these domains, numerous bug benchmarks containingreal-world bugs from software projects have been developed. However, a growingconcern within the software engineering community is that these benchmarks maynot reliably reflect true LLM performance due to the risk of data leakage.Despite this concern, limited research has been conducted to quantify theimpact of potential leakage. In this paper, we systematically evaluate popular LLMs to assess theirsusceptibility to data leakage from widely used bug benchmarks. To identifypotential leakage, we use multiple metrics, including a study of benchmarkmembership within commonly used training datasets, as well as analyses ofnegative log-likelihood and n-gram accuracy. Our findings show that certainmodels, in particular codegen-multi, exhibit significant evidence ofmemorization in widely used benchmarks like Defects4J, while newer modelstrained on larger datasets like LLaMa 3.1 exhibit limited signs of leakage.These results highlight the need for careful benchmark selection and theadoption of robust metrics to adequately assess models capabilities.</description><author>Daniel Ramos, Claudia Mamede, Kush Jain, Paulo Canelas, Catarina Gamboa, Claire Le Goues</author><pubDate>Wed, 20 Nov 2024 13:46:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13323v1</guid></item><item><title>Scaling Laws for Online Advertisement Retrieval</title><link>http://arxiv.org/abs/2411.13322v1</link><description>The scaling law is a notable property of neural network models and hassignificantly propelled the development of large language models. Scaling lawshold great promise in guiding model design and resource allocation. Recentresearch increasingly shows that scaling laws are not limited to NLP tasks orTransformer architectures; they also apply to domains such as recommendation.However, there is still a lack of literature on scaling law research in onlineadvertisement retrieval systems. This may be because 1) identifying the scalinglaw for resource cost and online revenue is often expensive in both time andtraining resources for large-scale industrial applications, and 2) varyingsettings for different systems prevent the scaling law from being appliedacross various scenarios. To address these issues, we propose a lightweightparadigm to identify the scaling law of online revenue and machine cost for acertain online advertisement retrieval scenario with a low experimental cost.Specifically, we focus on a sole factor (FLOPs) and propose an offline metricnamed R/R* that exhibits a high linear correlation with online revenue forretrieval models. We estimate the machine cost offline via a simulationalgorithm. Thus, we can transform most online experiments into low-cost offlineexperiments. We conduct comprehensive experiments to verify the effectivenessof our proposed metric R/R* and to identify the scaling law in the onlineadvertisement retrieval system of Kuaishou. With the scaling law, wedemonstrate practical applications for ROI-constrained model designing andmulti-scenario resource allocation in Kuaishou advertising system. To the bestof our knowledge, this is the first work to study the scaling laws for onlineadvertisement retrieval of real-world systems, showing great potential forscaling law in advertising system optimization.</description><author>Yunli Wang, Zixuan Yang, Zhen Zhang, Zhiqiang Wang, Jian Yang, Shiyang Wen, Peng Jiang, Kun Gai</author><pubDate>Wed, 20 Nov 2024 13:44:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13322v1</guid></item><item><title>Locally Adaptive One-Class Classifier Fusion with Dynamic $\ell$p-Norm Constraints for Robust Anomaly Detection</title><link>http://arxiv.org/abs/2411.06406v2</link><description>This paper presents a novel approach to one-class classifier fusion throughlocally adaptive learning with dynamic $\ell$p-norm constraints. We introduce aframework that dynamically adjusts fusion weights based on local datacharacteristics, addressing fundamental challenges in ensemble-based anomalydetection. Our method incorporates an interior-point optimization techniquethat significantly improves computational efficiency compared to traditionalFrank-Wolfe approaches, achieving up to 19-fold speed improvements in complexscenarios. The framework is extensively evaluated on standard UCI benchmarkdatasets and specialized temporal sequence datasets, demonstrating superiorperformance across diverse anomaly types. Statistical validation throughSkillings-Mack tests confirms our method's significant advantages over existingapproaches, with consistent top rankings in both pure and non-pure learningscenarios. The framework's ability to adapt to local data patterns whilemaintaining computational efficiency makes it particularly valuable forreal-time applications where rapid and accurate anomaly detection is crucial.</description><author>Sepehr Nourmohammadi, Arda Sarp Yenicesu, Shervin Rahimzadeh Arashloo, Ozgur S. Oguz</author><pubDate>Wed, 20 Nov 2024 13:39:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.06406v2</guid></item><item><title>Teaching VLMs to Localize Specific Objects from In-context Examples</title><link>http://arxiv.org/abs/2411.13317v1</link><description>Vision-Language Models (VLMs) have shown remarkable capabilities acrossdiverse visual tasks, including image recognition, video understanding, andVisual Question Answering (VQA) when explicitly trained for these tasks.Despite these advances, we find that current VLMs lack a fundamental cognitiveability: learning to localize objects in a scene by taking into account thecontext. In this work, we focus on the task of few-shot personalizedlocalization, where a model is given a small set of annotated images(in-context examples) -- each with a category label and bounding box -- and istasked with localizing the same object type in a query image. To provokepersonalized localization abilities in models, we present a data-centricsolution that fine-tunes them using carefully curated data from video objecttracking datasets. By leveraging sequences of frames tracking the same objectacross multiple shots, we simulate instruction-tuning dialogues that promotecontext awareness. To reinforce this, we introduce a novel regularizationtechnique that replaces object labels with pseudo-names, ensuring the modelrelies on visual context rather than prior knowledge. Our method significantlyenhances few-shot localization performance without sacrificing generalization,as demonstrated on several benchmarks tailored to personalized localization.This work is the first to explore and benchmark personalized few-shotlocalization for VLMs, laying a foundation for future research incontext-driven vision-language applications. The code for our project isavailable at https://github.com/SivanDoveh/IPLoc</description><author>Sivan Doveh, Nimrod Shabtay, Wei Lin, Eli Schwartz, Hilde Kuehne, Raja Giryes, Rogerio Feris, Leonid Karlinsky, James Glass, Assaf Arbelle, Shimon Ullman, M. Jehanzeb Mirza</author><pubDate>Wed, 20 Nov 2024 13:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13317v1</guid></item><item><title>A Resource Efficient Fusion Network for Object Detection in Bird's-Eye View using Camera and Raw Radar Data</title><link>http://arxiv.org/abs/2411.13311v1</link><description>Cameras can be used to perceive the environment around the vehicle, whileaffordable radar sensors are popular in autonomous driving systems as they canwithstand adverse weather conditions unlike cameras. However, radar pointclouds are sparser with low azimuth and elevation resolution that lack semanticand structural information of the scenes, resulting in generally lower radardetection performance. In this work, we directly use the raw range-Doppler (RD)spectrum of radar data, thus avoiding radar signal processing. We independentlyprocess camera images within the proposed comprehensive image processingpipeline. Specifically, first, we transform the camera images to Bird's-EyeView (BEV) Polar domain and extract the corresponding features with our cameraencoder-decoder architecture. The resultant feature maps are fused withRange-Azimuth (RA) features, recovered from the RD spectrum input from theradar decoder to perform object detection. We evaluate our fusion strategy withother existing methods not only in terms of accuracy but also on computationalcomplexity metrics on RADIal dataset.</description><author>Kavin Chandrasekaran, Sorin Grigorescu, Gijs Dubbelman, Pavol Jancura</author><pubDate>Wed, 20 Nov 2024 13:26:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13311v1</guid></item><item><title>Predicting User Intents and Musical Attributes from Music Discovery Conversations</title><link>http://arxiv.org/abs/2411.12254v2</link><description>Intent classification is a text understanding task that identifies user needsfrom input text queries. While intent classification has been extensivelystudied in various domains, it has not received much attention in the musicdomain. In this paper, we investigate intent classification models for musicdiscovery conversation, focusing on pre-trained language models. Rather thanonly predicting functional needs: intent classification, we also include a taskfor classifying musical needs: musical attribute classification. Additionally,we propose a method of concatenating previous chat history with justsingle-turn user queries in the input text, allowing the model to understandthe overall conversation context better. Our proposed model significantlyimproves the F1 score for both user intent and musical attributeclassification, and surpasses the zero-shot and few-shot performance of thepretrained Llama 3 model.</description><author>Daeyong Kwon, SeungHeon Doh, Juhan Nam</author><pubDate>Wed, 20 Nov 2024 13:24:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12254v2</guid></item><item><title>Benchmarking PtO and PnO Methods in the Predictive Combinatorial Optimization Regime</title><link>http://arxiv.org/abs/2311.07633v5</link><description>Predictive combinatorial optimization, where the parameters of combinatorialoptimization (CO) are unknown at the decision-making time, is the precisemodeling of many real-world applications, including energy cost-awarescheduling and budget allocation on advertising. Tackling such a problemusually involves a prediction model and a CO solver. These two modules areintegrated into the predictive CO pipeline following two design principles:"Predict-then-Optimize (PtO)", which learns predictions by supervised trainingand subsequently solves CO using predicted coefficients, while the other, named"Predict-and-Optimize (PnO)", directly optimizes towards the ultimate decisionquality and claims to yield better decisions than traditional PtO approaches.However, there lacks a systematic benchmark of both approaches, including thespecific design choices at the module level, as well as an evaluation datasetthat covers representative real-world scenarios. To this end, we develop amodular framework to benchmark 11 existing PtO/PnO methods on 8 problems,including a new industrial dataset for combinatorial advertising that will bereleased. Our study shows that PnO approaches are better than PtO on 7 out of 8benchmarks, but there is no silver bullet found for the specific design choicesof PnO. A comprehensive categorization of current approaches and integration oftypical scenarios are provided under a unified benchmark. Therefore, this papercould serve as a comprehensive benchmark for future PnO approach developmentand also offer fast prototyping for application-focused development. The codeis available at https://github.com/Thinklab-SJTU/PredictiveCO-Benchmark.</description><author>Haoyu Geng, Hang Ruan, Runzhong Wang, Yang Li, Yang Wang, Lei Chen, Junchi Yan</author><pubDate>Wed, 20 Nov 2024 13:20:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07633v5</guid></item><item><title>Classification of Buried Objects from Ground Penetrating Radar Images by using Second Order Deep Learning Models</title><link>http://arxiv.org/abs/2410.07117v2</link><description>In this paper, a new classification model based on covariance matrices isbuilt in order to classify buried objects. The inputs of the proposed modelsare the hyperbola thumbnails obtained with a classical Ground Penetrating Radar(GPR) system. These thumbnails are then inputs to the first layers of aclassical CNN, which then produces a covariance matrix using the outputs of theconvolutional filters. Next, the covariance matrix is given to a networkcomposed of specific layers to classify Symmetric Positive Definite (SPD)matrices. We show in a large database that our approach outperform shallownetworks designed for GPR data and conventional CNNs typically used in computervision applications, particularly when the number of training data decreasesand in the presence of mislabeled data. We also illustrate the interest of ourmodels when training data and test sets are obtained from different weathermodes or considerations.</description><author>Douba Jafuno, Ammar Mian, Guillaume Ginolhac, Nickolas Stelzenmuller</author><pubDate>Wed, 20 Nov 2024 13:17:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07117v2</guid></item><item><title>Can Reasons Help Improve Pedestrian Intent Estimation? A Cross-Modal Approach</title><link>http://arxiv.org/abs/2411.13302v1</link><description>With the increased importance of autonomous navigation systems has come anincreasing need to protect the safety of Vulnerable Road Users (VRUs) such aspedestrians. Predicting pedestrian intent is one such challenging task, whereprior work predicts the binary cross/no-cross intention with a fusion of visualand motion features. However, there has been no effort so far to hedge suchpredictions with human-understandable reasons. We address this issue byintroducing a novel problem setting of exploring the intuitive reasoning behinda pedestrian's intent. In particular, we show that predicting the 'WHY' can bevery useful in understanding the 'WHAT'. To this end, we propose a novel,reason-enriched PIE++ dataset consisting of multi-label textualexplanations/reasons for pedestrian intent. We also introduce a novelmulti-task learning framework called MINDREAD, which leverages a cross-modalrepresentation learning framework for predicting pedestrian intent as well asthe reason behind the intent. Our comprehensive experiments show significantimprovement of 5.6% and 7% in accuracy and F1-score for the task of intentprediction on the PIE++ dataset using MINDREAD. We also achieved a 4.4%improvement in accuracy on a commonly used JAAD dataset. Extensive evaluationusing quantitative/qualitative metrics and user studies shows the effectivenessof our approach.</description><author>Vaishnavi Khindkar, Vineeth Balasubramanian, Chetan Arora, Anbumani Subramanian, C. V. Jawahar</author><pubDate>Wed, 20 Nov 2024 13:15:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13302v1</guid></item><item><title>Generation of synthetic gait data: application to multiple sclerosis patients' gait patterns</title><link>http://arxiv.org/abs/2411.10377v2</link><description>Multiple sclerosis (MS) is the leading cause of severe non-traumaticdisability in young adults and its incidence is increasing worldwide. Thevariability of gait impairment in MS necessitates the development of anon-invasive, sensitive, and cost-effective tool for quantitative gaitevaluation. The eGait movement sensor, designed to characterize human gaitthrough unit quaternion time series (QTS) representing hip rotations, is apromising approach. However, the small sample sizes typical of clinical studiespose challenges for the stability of gait data analysis tools. To address thesechallenges, this article presents two key scientific contributions. First, acomprehensive framework is proposed for transforming QTS data into a form thatpreserves the essential geometric properties of gait while enabling the use ofany tabular synthetic data generation method. Second, a synthetic datageneration method is introduced, based on nearest neighbors weighting, whichproduces high-fidelity synthetic QTS data suitable for small datasets andprivate data environments. The effectiveness of the proposed method, isdemonstrated through its application to MS gait data, showing very goodfidelity and respect of the initial geometry of the data. Thanks to this work,we are able to produce synthetic data sets and work on the stability ofclustering methods.</description><author>Klervi Le Gall, Lise Bellanger, David Laplaud, Aymeric Stamm</author><pubDate>Wed, 20 Nov 2024 13:05:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.10377v2</guid></item><item><title>Lifted Model Construction without Normalisation: A Vectorised Approach to Exploit Symmetries in Factor Graphs</title><link>http://arxiv.org/abs/2411.11730v2</link><description>Lifted probabilistic inference exploits symmetries in a probabilistic modelto allow for tractable probabilistic inference with respect to domain sizes oflogical variables. We found that the current state-of-the-art algorithm toconstruct a lifted representation in form of a parametric factor graph missessymmetries between factors that are exchangeable but scaled differently,thereby leading to a less compact representation. In this paper, we propose ageneralisation of the advanced colour passing (ACP) algorithm, which is thestate of the art to construct a parametric factor graph. Our proposed algorithmallows for potentials of factors to be scaled arbitrarily and efficientlydetects more symmetries than the original ACP algorithm. By detecting strictlymore symmetries than ACP, our algorithm significantly reduces online querytimes for probabilistic inference when the resulting model is applied, which wealso confirm in our experiments.</description><author>Malte Luttermann, Ralf Möller, Marcel Gehrke</author><pubDate>Wed, 20 Nov 2024 13:01:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.11730v2</guid></item><item><title>DATAP-SfM: Dynamic-Aware Tracking Any Point for Robust Structure from Motion in the Wild</title><link>http://arxiv.org/abs/2411.13291v1</link><description>This paper proposes a concise, elegant, and robust pipeline to estimatesmooth camera trajectories and obtain dense point clouds for casual videos inthe wild. Traditional frameworks, such asParticleSfM~\cite{zhao2022particlesfm}, address this problem by sequentiallycomputing the optical flow between adjacent frames to obtain pointtrajectories. They then remove dynamic trajectories through motion segmentationand perform global bundle adjustment. However, the process of estimatingoptical flow between two adjacent frames and chaining the matches can introducecumulative errors. Additionally, motion segmentation combined with single-viewdepth estimation often faces challenges related to scale ambiguity. To tacklethese challenges, we propose a dynamic-aware tracking any point (DATAP) methodthat leverages consistent video depth and point tracking. Specifically, ourDATAP addresses these issues by estimating dense point tracking across thevideo sequence and predicting the visibility and dynamics of each point. Byincorporating the consistent video depth prior, the performance of motionsegmentation is enhanced. With the integration of DATAP, it becomes possible toestimate and optimize all camera poses simultaneously by performing globalbundle adjustments for point tracking classified as static and visible, ratherthan relying on incremental camera registration. Extensive experiments ondynamic sequences, e.g., Sintel and TUM RGBD dynamic sequences, and on the wildvideo, e.g., DAVIS, demonstrate that the proposed method achievesstate-of-the-art performance in terms of camera pose estimation even in complexdynamic challenge scenes.</description><author>Weicai Ye, Xinyu Chen, Ruohao Zhan, Di Huang, Xiaoshui Huang, Haoyi Zhu, Hujun Bao, Wanli Ouyang, Tong He, Guofeng Zhang</author><pubDate>Wed, 20 Nov 2024 13:01:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13291v1</guid></item><item><title>M3D: Dual-Stream Selective State Spaces and Depth-Driven Framework for High-Fidelity Single-View 3D Reconstruction</title><link>http://arxiv.org/abs/2411.12635v2</link><description>The precise reconstruction of 3D objects from a single RGB image in complexscenes presents a critical challenge in virtual reality, autonomous driving,and robotics. Existing neural implicit 3D representation methods facesignificant difficulties in balancing the extraction of global and localfeatures, particularly in diverse and complex environments, leading toinsufficient reconstruction precision and quality. We propose M3D, a novelsingle-view 3D reconstruction framework, to tackle these challenges. Thisframework adopts a dual-stream feature extraction strategy based on SelectiveState Spaces to effectively balance the extraction of global and localfeatures, thereby improving scene comprehension and representation precision.Additionally, a parallel branch extracts depth information, effectivelyintegrating visual and geometric features to enhance reconstruction quality andpreserve intricate details. Experimental results indicate that the fusion ofmulti-scale features with depth information via the dual-branch featureextraction significantly boosts geometric consistency and fidelity, achievingstate-of-the-art reconstruction performance.</description><author>Luoxi Zhang, Pragyan Shrestha, Yu Zhou, Chun Xie, Itaru Kitahara</author><pubDate>Wed, 20 Nov 2024 12:54:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.12635v2</guid></item><item><title>Unbiased Scene Graph Generation by Type-Aware Message Passing on Heterogeneous and Dual Graphs</title><link>http://arxiv.org/abs/2411.13287v1</link><description>Although great progress has been made in the research of unbiased scene graphgeneration, issues still hinder improving the predictive performance of bothhead and tail classes. An unbiased scene graph generation (TA-HDG) is proposedto address these issues. For modeling interactive and non-interactiverelations, the Interactive Graph Construction is proposed to model thedependence of relations on objects by combining heterogeneous and dual graph,when modeling relations between multiple objects. It also implements asubject-object pair selection strategy to reduce meaningless edges. Moreover,the Type-Aware Message Passing enhances the understanding of complexinteractions by capturing intra- and inter-type context in the Intra-Type andInter-Type stages. The Intra-Type stage captures the semantic context ofinter-relaitons and inter-objects. On this basis, the Inter-Type stage capturesthe context between objects and relations for interactive and non-interactiverelations, respectively. Experiments on two datasets show that TA-HDG achievesimprovements in the metrics of R@K and mR@K, which proves that TA-HDG canaccurately predict the tail class while maintaining the competitive performanceof the head class.</description><author>Guanglu Sun, Jin Qiu, Lili Liang</author><pubDate>Wed, 20 Nov 2024 12:54:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13287v1</guid></item><item><title>DAOcc: 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction</title><link>http://arxiv.org/abs/2409.19972v2</link><description>Multi-sensor fusion significantly enhances the accuracy and robustness of 3Dsemantic occupancy prediction, which is crucial for autonomous driving androbotics. However, most existing approaches depend on large image resolutionsand complex networks to achieve top performance, hindering their application inpractical scenarios. Additionally, most multi-sensor fusion approaches focus onimproving fusion features while overlooking the exploration of supervisionstrategies for these features. To this end, we propose DAOcc, a novelmulti-modal occupancy prediction framework that leverages 3D object detectionsupervision to assist in achieving superior performance, while using adeployment-friendly image feature extraction network and practical input imageresolution. Furthermore, we introduce a BEV View Range Extension strategy tomitigate the adverse effects of reduced image resolution. Experimental resultsshow that DAOcc achieves new state-of-the-art performance on the Occ3D-nuScenesand SurroundOcc benchmarks, and surpasses other methods by a significant marginwhile using only ResNet50 and 256*704 input image resolution. Code will be madeavailable at https://github.com/AlphaPlusTT/DAOcc.</description><author>Zhen Yang, Yanpeng Dong, Heng Wang, Lichao Ma, Zijian Cui, Qi Liu, Haoran Pei</author><pubDate>Wed, 20 Nov 2024 12:54:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.19972v2</guid></item><item><title>DATTA: Domain-Adversarial Test-Time Adaptation for Cross-Domain WiFi-Based Human Activity Recognition</title><link>http://arxiv.org/abs/2411.13284v1</link><description>Cross-domain generalization is an open problem in WiFi-based sensing due tovariations in environments, devices, and subjects, causing domain shifts inchannel state information. To address this, we propose Domain-AdversarialTest-Time Adaptation (DATTA), a novel framework combining domain-adversarialtraining (DAT), test-time adaptation (TTA), and weight resetting to facilitateadaptation to unseen target domains and to prevent catastrophic forgetting.DATTA is integrated into a lightweight, flexible architecture optimized forspeed. We conduct a comprehensive evaluation of DATTA, including an ablationstudy on all key components using publicly available data, and verify itssuitability for real-time applications such as human activity recognition. Whencombining a SotA video-based variant of TTA with WiFi-based DAT and comparingit to DATTA, our method achieves an 8.1% higher F1-Score. The PyTorchimplementation of DATTA is publicly available at:https://github.com/StrohmayerJ/DATTA.</description><author>Julian Strohmayer, Rafael Sterzinger, Matthias Wödlinger, Martin Kampel</author><pubDate>Wed, 20 Nov 2024 12:52:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13284v1</guid></item><item><title>3D-Aware Instance Segmentation and Tracking in Egocentric Videos</title><link>http://arxiv.org/abs/2408.09860v2</link><description>Egocentric videos present unique challenges for 3D scene understanding due torapid camera motion, frequent object occlusions, and limited object visibility.This paper introduces a novel approach to instance segmentation and tracking infirst-person video that leverages 3D awareness to overcome these obstacles. Ourmethod integrates scene geometry, 3D object centroid tracking, and instancesegmentation to create a robust framework for analyzing dynamic egocentricscenes. By incorporating spatial and temporal cues, we achieve superiorperformance compared to state-of-the-art 2D approaches. Extensive evaluationson the challenging EPIC Fields dataset demonstrate significant improvementsacross a range of tracking and segmentation consistency metrics. Specifically,our method outperforms the next best performing approach by $7$ points inAssociation Accuracy (AssA) and $4.5$ points in IDF1 score, while reducing thenumber of ID switches by $73\%$ to $80\%$ across various object categories.Leveraging our tracked instance segmentations, we showcase downstreamapplications in 3D object reconstruction and amodal video object segmentationin these egocentric settings.</description><author>Yash Bhalgat, Vadim Tschernezki, Iro Laina, João F. Henriques, Andrea Vedaldi, Andrew Zisserman</author><pubDate>Wed, 20 Nov 2024 12:51:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.09860v2</guid></item><item><title>Combining Autoregressive and Autoencoder Language Models for Text Classification</title><link>http://arxiv.org/abs/2411.13282v1</link><description>This paper presents CAALM-TC (Combining Autoregressive and AutoencoderLanguage Models for Text Classification), a novel method that enhances textclassification by integrating autoregressive and autoencoder language models.Autoregressive large language models such as Open AI's GPT, Meta's Llama orMicrosoft's Phi offer promising prospects for content analysis practitioners,but they generally underperform supervised BERT based models for textclassification. CAALM leverages autoregressive models to generate contextualinformation based on input texts, which is then combined with the original textand fed into an autoencoder model for classification. This hybrid approachcapitalizes on the extensive contextual knowledge of autoregressive models andthe efficient classification capabilities of autoencoders. Experimental resultson four benchmark datasets demonstrate that CAALM consistently outperformsexisting methods, particularly in tasks with smaller datasets and more abstractclassification objectives. The findings indicate that CAALM offers a scalableand effective solution for automated content analysis in social scienceresearch that minimizes sample size requirements.</description><author>João Gonçalves</author><pubDate>Wed, 20 Nov 2024 12:49:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13282v1</guid></item><item><title>VideoAutoArena: An Automated Arena for Evaluating Large Multimodal Models in Video Analysis through User Simulation</title><link>http://arxiv.org/abs/2411.13281v1</link><description>Large multimodal models (LMMs) with advanced video analysis capabilities haverecently garnered significant attention. However, most evaluations rely ontraditional methods like multiple-choice questions in benchmarks such asVideoMME and LongVideoBench, which are prone to lack the depth needed tocapture the complex demands of real-world users. To address this limitation-anddue to the prohibitive cost and slow pace of human annotation for videotasks-we introduce VideoAutoArena, an arena-style benchmark inspired by LMSYSChatbot Arena's framework, designed to automatically assess LMMs' videoanalysis abilities. VideoAutoArena utilizes user simulation to generateopen-ended, adaptive questions that rigorously assess model performance invideo understanding. The benchmark features an automated, scalable evaluationframework, incorporating a modified ELO Rating System for fair and continuouscomparisons across multiple LMMs. To validate our automated judging system, weconstruct a 'gold standard' using a carefully curated subset of humanannotations, demonstrating that our arena strongly aligns with human judgmentwhile maintaining scalability. Additionally, we introduce a fault-drivenevolution strategy, progressively increasing question complexity to push modelstoward handling more challenging video analysis scenarios. Experimental resultsdemonstrate that VideoAutoArena effectively differentiates amongstate-of-the-art LMMs, providing insights into model strengths and areas forimprovement. To further streamline our evaluation, we introduce VideoAutoBenchas an auxiliary benchmark, where human annotators label winners in a subset ofVideoAutoArena battles. We use GPT-4o as a judge to compare responses againstthese human-validated answers. Together, VideoAutoArena and VideoAutoBenchoffer a cost-effective, and scalable framework for evaluating LMMs inuser-centric video analysis.</description><author>Ziyang Luo, Haoning Wu, Dongxu Li, Jing Ma, Mohan Kankanhalli, Junnan Li</author><pubDate>Wed, 20 Nov 2024 12:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13281v1</guid></item><item><title>Unlocking the Power of Gradient Guidance for Structure-Based Molecule Optimization</title><link>http://arxiv.org/abs/2411.13280v1</link><description>Structure-based molecule optimization (SBMO) aims to optimize molecules withboth continuous coordinates and discrete types against protein targets. Apromising direction is to exert gradient guidance on generative models givenits remarkable success in images, but it is challenging to guide discrete dataand risks inconsistencies between modalities. To this end, we leverage acontinuous and differentiable space derived through Bayesian inference,presenting Molecule Joint Optimization (MolJO), the first gradient-based SBMOframework that facilitates joint guidance signals across different modalitieswhile preserving SE(3)-equivariance. We introduce a novel backward correctionstrategy that optimizes within a sliding window of the past histories, allowingfor a seamless trade-off between explore-and-exploit during optimization. Ourproposed MolJO achieves state-of-the-art performance on CrossDocked2020benchmark (Success Rate 51.3% , Vina Dock -9.05 and SA 0.78), more than 4ximprovement in Success Rate compared to the gradient-based counterpart, and 2x"Me-Better" Ratio as much as 3D baselines. Furthermore, we extend MolJO to awide range of optimization settings, including multi-objective optimization andchallenging tasks in drug design such as R-group optimization and scaffoldhopping, further underscoring its versatility and potential.</description><author>Keyue Qiu, Yuxuan Song, Jie Yu, Hongbo Ma, Ziyao Cao, Zhilong Zhang, Yushuai Wu, Mingyue Zheng, Hao Zhou, Wei-Ying Ma</author><pubDate>Wed, 20 Nov 2024 12:48:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13280v1</guid></item></channel></rss>