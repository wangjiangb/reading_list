<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 30 Oct 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>FP8-LM: Training FP8 Large Language Models</title><link>http://arxiv.org/abs/2310.18313v1</link><description>In this paper, we explore FP8 low-bit data formats for efficient training oflarge language models (LLMs). Our key insight is that most variables, such asgradients and optimizer states, in LLM training can employ low-precision dataformats without compromising model accuracy and requiring no changes tohyper-parameters. Specifically, we propose a new FP8 automatic mixed-precisionframework for training LLMs. This framework offers three levels of FP8utilization to streamline mixed-precision and distributed parallel training forLLMs. It gradually incorporates 8-bit gradients, optimizer states, anddistributed learning in an incremental manner. Experiment results show that,during the training of GPT-175B model on H100 GPU platform, our FP8mixed-precision training framework not only achieved a remarkable 42% reductionin real memory usage but also ran 64% faster than the widely adopted BF16framework (i.e., Megatron-LM), surpassing the speed of Nvidia TransformerEngine by 17%. This largely reduces the training costs for large foundationmodels. Furthermore, our FP8 mixed-precision training methodology is generic.It can be seamlessly applied to other tasks such as LLM instruction tuning andreinforcement learning with human feedback, offering savings in fine-tuningexpenses. Our FP8 low-precision training framework is open-sourced at{https://github.com/Azure/MS-AMP}{aka.ms/MS.AMP}.</description><author>Houwen Peng, Kan Wu, Yixuan Wei, Guoshuai Zhao, Yuxiang Yang, Ze Liu, Yifan Xiong, Ziyue Yang, Bolin Ni, Jingcheng Hu, Ruihang Li, Miaosen Zhang, Chen Li, Jia Ning, Ruizhe Wang, Zheng Zhang, Shuguang Liu, Joe Chau, Han Hu, Peng Cheng</author><pubDate>Fri, 27 Oct 2023 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18313v1</guid></item><item><title>Framework based on complex networks to model and mine patient pathways</title><link>http://arxiv.org/abs/2309.14208v2</link><description>The automatic discovery of a model to represent the history of encounters ofa group of patients with the healthcare system -- the so-called "pathway ofpatients" -- is a new field of research that supports clinical andorganisational decisions to improve the quality and efficiency of the treatmentprovided. The pathways of patients with chronic conditions tend to varysignificantly from one person to another, have repetitive tasks, and demand theanalysis of multiple perspectives (interventions, diagnoses, medicalspecialities, among others) influencing the results. Therefore, modelling andmining those pathways is still a challenging task. In this work, we propose aframework comprising: (i) a pathway model based on a multi-aspect graph, (ii) anovel dissimilarity measurement to compare pathways taking the elapsed timeinto account, and (iii) a mining method based on traditional centralitymeasures to discover the most relevant steps of the pathways. We evaluated theframework using the study cases of pregnancy and diabetes, which revealed itsusefulness in finding clusters of similar pathways, representing them in aneasy-to-interpret way, and highlighting the most significant patterns accordingto multiple perspectives.</description><author>Caroline de Oliveira Costa Souza Rosa, Márcia Ito, Alex Borges Vieira, Klaus Wehmuth, Antônio Tadeu Azevedo Gomes</author><pubDate>Fri, 27 Oct 2023 18:59:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14208v2</guid></item><item><title>High-Dimensional Prediction for Sequential Decision Making</title><link>http://arxiv.org/abs/2310.17651v2</link><description>We study the problem of making predictions of an adversarially chosenhigh-dimensional state that are unbiased subject to an arbitrary collection ofconditioning events, with the goal of tailoring these events to downstreamdecision makers. We give efficient algorithms for solving this problem, as wellas a number of applications that stem from choosing an appropriate set ofconditioning events. For example, we can efficiently make predictions targeted at polynomiallymany decision makers, giving each of them optimal swap regret if theybest-respond to our predictions. We generalize this to online combinatorialoptimization, where the decision makers have a very large action space, to givethe first algorithms offering polynomially many decision makers no regret onpolynomially many subsequences that may depend on their actions and thecontext. We apply these results to get efficient no-subsequence-regretalgorithms in extensive-form games (EFGs), yielding a new family of regretguarantees for EFGs that generalizes some existing EFG regret notions, e.g.regret to informed causal deviations, and is generally incomparable to otherknown such notions. Next, we develop a novel transparent alternative to conformal prediction forbuilding valid online adversarial multiclass prediction sets. We produce classscores that downstream algorithms can use for producing valid-coverageprediction sets, as if these scores were the true conditional classprobabilities. We show this implies strong conditional validity guaranteesincluding set-size-conditional and multigroup-fair coverage for polynomiallymany downstream prediction sets. Moreover, our class scores can be guaranteedto have improved $L_2$ loss, cross-entropy loss, and generally any Bregmanloss, compared to any collection of benchmark models, yielding ahigh-dimensional real-valued version of omniprediction.</description><author>Georgy Noarov, Ramya Ramalingam, Aaron Roth, Stephan Xie</author><pubDate>Fri, 27 Oct 2023 18:59:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17651v2</guid></item><item><title>Gen2Sim: Scaling up Robot Learning in Simulation with Generative Models</title><link>http://arxiv.org/abs/2310.18308v1</link><description>Generalist robot manipulators need to learn a wide variety of manipulationskills across diverse environments. Current robot training pipelines rely onhumans to provide kinesthetic demonstrations or to program simulationenvironments and to code up reward functions for reinforcement learning. Suchhuman involvement is an important bottleneck towards scaling up robot learningacross diverse tasks and environments. We propose Generation to Simulation(Gen2Sim), a method for scaling up robot skill learning in simulation byautomating generation of 3D assets, task descriptions, task decompositions andreward functions using large pre-trained generative models of language andvision. We generate 3D assets for simulation by lifting open-world 2Dobject-centric images to 3D using image diffusion models and querying LLMs todetermine plausible physics parameters. Given URDF files of generated andhuman-developed assets, we chain-of-thought prompt LLMs to map these torelevant task descriptions, temporal decompositions, and corresponding pythonreward functions for reinforcement learning. We show Gen2Sim succeeds inlearning policies for diverse long horizon tasks, where reinforcement learningwith non temporally decomposed reward functions fails. Gen2Sim provides aviable path for scaling up reinforcement learning for robot manipulators insimulation, both by diversifying and expanding task and environmentdevelopment, and by facilitating the discovery of reinforcement-learnedbehaviors through temporal task decomposition in RL. Our work contributeshundreds of simulated assets, tasks and demonstrations, taking a step towardsfully autonomous robotic manipulation skill acquisition in simulation.</description><author>Pushkal Katara, Zhou Xian, Katerina Fragkiadaki</author><pubDate>Fri, 27 Oct 2023 18:55:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18308v1</guid></item><item><title>Supervised and Penalized Baseline Correction</title><link>http://arxiv.org/abs/2310.18306v1</link><description>Spectroscopic measurements can show distorted spectra shapes arising from amixture of absorbing and scattering contributions. These distortions (orbaselines) often manifest themselves as non-constant offsets or low-frequencyoscillations. As a result, these baselines can adversely affect analytical andquantitative results. Baseline correction is an umbrella term where one appliespre-processing methods to obtain baseline spectra (the unwanted distortions)and then remove the distortions by differencing. However, current state-of-theart baseline correction methods do not utilize analyte concentrations even ifthey are available, or even if they contribute significantly to the observedspectral variability. We examine a class of state-of-the-art methods (penalizedbaseline correction) and modify them such that they can accommodate a priorianalyte concentration such that prediction can be enhanced. Performance will beaccess on two near infra-red data sets across both classical penalized baselinecorrection methods (without analyte information) and modified penalizedbaseline correction methods (leveraging analyte information).</description><author>Erik Andries Ramin Nikzad-Langerodi</author><pubDate>Fri, 27 Oct 2023 18:55:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18306v1</guid></item><item><title>A Stability Principle for Learning under Non-Stationarity</title><link>http://arxiv.org/abs/2310.18304v1</link><description>We develop a versatile framework for statistical learning in non-stationaryenvironments. In each time period, our approach applies a stability principleto select a look-back window that maximizes the utilization of historical datawhile keeping the cumulative bias within an acceptable range relative to thestochastic error. Our theory showcases the adaptability of this approach tounknown non-stationarity. The regret bound is minimax optimal up to logarithmicfactors when the population losses are strongly convex, or Lipschitz only. Atthe heart of our analysis lie two novel components: a measure of similaritybetween functions and a segmentation technique for dividing the non-stationarydata sequence into quasi-stationary pieces.</description><author>Chengpiao Huang, Kaizheng Wang</author><pubDate>Fri, 27 Oct 2023 18:53:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18304v1</guid></item><item><title>Socially Cognizant Robotics for a Technology Enhanced Society</title><link>http://arxiv.org/abs/2310.18303v1</link><description>Emerging applications of robotics, and concerns about their impact, requirethe research community to put human-centric objectives front-and-center. Tomeet this challenge, we advocate an interdisciplinary approach, sociallycognizant robotics, which synthesizes technical and social science methods. Weargue that this approach follows from the need to empower stakeholderparticipation (from synchronous human feedback to asynchronous societalassessment) in shaping AI-driven robot behavior at all levels, and leads to arange of novel research perspectives and problems both for improving robots'interactions with individuals and impacts on society. Drawing on thesearguments, we develop best practices for socially cognizant robot design thatbalance traditional technology-based metrics (e.g. efficiency, precision andaccuracy) with critically important, albeit challenging to measure, human andsociety-based metrics.</description><author>Kristin J. Dana, Clinton Andrews, Kostas Bekris, Jacob Feldman, Matthew Stone, Pernille Hemmer, Aaron Mazzeo, Hal Salzman, Jingang Yi</author><pubDate>Fri, 27 Oct 2023 18:53:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18303v1</guid></item><item><title>Multi-scale Diffusion Denoised Smoothing</title><link>http://arxiv.org/abs/2310.16779v3</link><description>Along with recent diffusion models, randomized smoothing has become one of afew tangible approaches that offers adversarial robustness to models at scale,e.g., those of large pre-trained models. Specifically, one can performrandomized smoothing on any classifier via a simple "denoise-and-classify"pipeline, so-called denoised smoothing, given that an accurate denoiser isavailable - such as diffusion model. In this paper, we present scalable methodsto address the current trade-off between certified robustness and accuracy indenoised smoothing. Our key idea is to "selectively" apply smoothing amongmultiple noise scales, coined multi-scale smoothing, which can be efficientlyimplemented with a single diffusion model. This approach also suggests a newobjective to compare the collective robustness of multi-scale smoothedclassifiers, and questions which representation of diffusion model wouldmaximize the objective. To address this, we propose to further fine-tunediffusion model (a) to perform consistent denoising whenever the original imageis recoverable, but (b) to generate rather diverse outputs otherwise. Ourexperiments show that the proposed multi-scale smoothing scheme combined withdiffusion fine-tuning enables strong certified robustness available with highnoise level while maintaining its accuracy close to non-smoothed classifiers.</description><author>Jongheon Jeong, Jinwoo Shin</author><pubDate>Fri, 27 Oct 2023 18:51:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.16779v3</guid></item><item><title>Interactive Motion Planning for Autonomous Vehicles with Joint Optimization</title><link>http://arxiv.org/abs/2310.18301v1</link><description>In highly interactive driving scenarios, the actions of one agent greatlyinfluences those of its neighbors. Planning safe motions for autonomousvehicles in such interactive environments, therefore, requires reasoning aboutthe impact of the ego's intended motion plan on nearby agents' behavior.Deep-learning-based models have recently achieved great success in trajectoryprediction and many models in the literature allow for ego-conditionedprediction. However, leveraging ego-conditioned prediction remains challengingin downstream planning due to the complex nature of neural networks, limitingthe planner structure to simple ones, e.g., sampling-based planner. Despitetheir ability to generate fine-grained high-quality motion plans, it isdifficult for gradient-based planning algorithms, such as model predictivecontrol (MPC), to leverage ego-conditioned prediction due to their iterativenature and need for gradient. We present Interactive Joint Planning (IJP) thatbridges MPC with learned prediction models in a computationally scalable mannerto provide us the best of both the worlds. In particular, IJP jointly optimizesover the behavior of the ego and the surrounding agents and leveragesdeep-learned prediction models as prediction priors that the join trajectoryoptimization tries to stay close to. Furthermore, by leveraging homotopyclasses, our joint optimizer searches over diverse motion plans to avoidgetting stuck at local minima. Closed-loop simulation result shows that IJPsignificantly outperforms the baselines that are either without jointoptimization or running sampling-based planning.</description><author>Yuxiao Chen, Sushant Veer, Peter Karkus, Marco Pavone</author><pubDate>Fri, 27 Oct 2023 18:48:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18301v1</guid></item><item><title>Towards Understanding Sycophancy in Language Models</title><link>http://arxiv.org/abs/2310.13548v3</link><description>Human feedback is commonly utilized to finetune AI assistants. But humanfeedback may also encourage model responses that match user beliefs overtruthful ones, a behaviour known as sycophancy. We investigate the prevalenceof sycophancy in models whose finetuning procedure made use of human feedback,and the potential role of human preference judgments in such behavior. We firstdemonstrate that five state-of-the-art AI assistants consistently exhibitsycophancy across four varied free-form text-generation tasks. To understand ifhuman preferences drive this broadly observed behavior, we analyze existinghuman preference data. We find that when a response matches a user's views, itis more likely to be preferred. Moreover, both humans and preference models(PMs) prefer convincingly-written sycophantic responses over correct ones anon-negligible fraction of the time. Optimizing model outputs against PMs alsosometimes sacrifices truthfulness in favor of sycophancy. Overall, our resultsindicate that sycophancy is a general behavior of state-of-the-art AIassistants, likely driven in part by human preference judgments favoringsycophantic responses.</description><author>Mrinank Sharma, Meg Tong, Tomasz Korbak, David Duvenaud, Amanda Askell, Samuel R. Bowman, Newton Cheng, Esin Durmus, Zac Hatfield-Dodds, Scott R. Johnston, Shauna Kravec, Timothy Maxwell, Sam McCandlish, Kamal Ndousse, Oliver Rausch, Nicholas Schiefer, Da Yan, Miranda Zhang, Ethan Perez</author><pubDate>Fri, 27 Oct 2023 18:45:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13548v3</guid></item><item><title>Image Clustering Conditioned on Text Criteria</title><link>http://arxiv.org/abs/2310.18297v1</link><description>Classical clustering methods do not provide users with direct control of theclustering results, and the clustering results may not be consistent with therelevant criterion that a user has in mind. In this work, we present a newmethodology for performing image clustering based on user-specified textcriteria by leveraging modern vision-language models and large language models.We call our method Image Clustering Conditioned on Text Criteria (IC$|$TC), andit represents a different paradigm of image clustering. IC$|$TC requires aminimal and practical degree of human intervention and grants the usersignificant control over the clustering results in return. Our experiments showthat IC$|$TC can effectively cluster images with various criteria, such ashuman action, physical location, or the person's mood, while significantlyoutperforming baselines.</description><author>Sehyun Kwon, Jaeseung Park, Minkyu Kim, Jaewoong Cho, Ernest K. Ryu, Kangwook Lee</author><pubDate>Fri, 27 Oct 2023 18:35:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18297v1</guid></item><item><title>Always Clear Days: Degradation Type and Severity Aware All-In-One Adverse Weather Removal</title><link>http://arxiv.org/abs/2310.18293v1</link><description>All-in-one adverse weather removal is an emerging topic on image restoration,which aims to restore multiple weather degradation in an unified model, and thechallenging are twofold. First, discovering and handling the property ofmulti-domain in target distribution formed by multiple weather conditions.Second, design efficient and effective operations for different degradationtypes. To address this problem, most prior works focus on the multi-domaincaused by weather type. Inspired by inter\&amp;intra-domain adaptation literature,we observed that not only weather type but also weather severity introducemulti-domain within each weather type domain, which is ignored by previousmethods, and further limit their performance. To this end, we proposed adegradation type and severity aware model, called \textbf{UtilityIR}, for blindall-in-one bad weather image restoration. To extract weather information fromsingle image, we proposed a novel Marginal Quality Ranking Loss (MQRL) andutilized Contrastive Loss (CL) to guide weather severity and type extraction,and leverage a bag of novel techniques such as Multi-Head Cross Attention(MHCA) and Local-Global Adaptive Instance Normalization (LG-AdaIN) toefficiently restore spatial varying weather degradation. The proposed methodcan significantly outperform the SOTA methods subjectively and objectively ondifferent weather restoration tasks with a large margin, and enjoy less modelparameters. Proposed method even can restore \textbf{unseen} domain combinedmultiple degradation images, and modulating restoration level. Implementationcode will be available at{https://github.com/fordevoted/UtilityIR}{\textit{this repository}}</description><author>Yu-Wei Chen, Soo-Chang Pei</author><pubDate>Fri, 27 Oct 2023 18:29:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18293v1</guid></item><item><title>Addressing GAN Training Instabilities via Tunable Classification Losses</title><link>http://arxiv.org/abs/2310.18291v1</link><description>Generative adversarial networks (GANs), modeled as a zero-sum game between agenerator (G) and a discriminator (D), allow generating synthetic data withformal guarantees. Noting that D is a classifier, we begin by reformulating theGAN value function using class probability estimation (CPE) losses. We prove atwo-way correspondence between CPE loss GANs and $f$-GANs which minimize$f$-divergences. We also show that all symmetric $f$-divergences are equivalentin convergence. In the finite sample and model capacity setting, we define andobtain bounds on estimation and generalization errors. We specialize theseresults to $\alpha$-GANs, defined using $\alpha$-loss, a tunable CPE lossfamily parametrized by $\alpha\in(0,\infty]$. We next introduce a class ofdual-objective GANs to address training instabilities of GANs by modeling eachplayer's objective using $\alpha$-loss to obtain $(\alpha_D,\alpha_G)$-GANs. Weshow that the resulting non-zero sum game simplifies to minimizing an$f$-divergence under appropriate conditions on $(\alpha_D,\alpha_G)$.Generalizing this dual-objective formulation using CPE losses, we define andobtain upper bounds on an appropriately defined estimation error. Finally, wehighlight the value of tuning $(\alpha_D,\alpha_G)$ in alleviating traininginstabilities for the synthetic 2D Gaussian mixture ring as well as the largepublicly available Celeb-A and LSUN Classroom image datasets.</description><author>Monica Welfert, Gowtham R. Kurri, Kyle Otstot, Lalitha Sankar</author><pubDate>Fri, 27 Oct 2023 18:29:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18291v1</guid></item><item><title>Learning to Modulate pre-trained Models in RL</title><link>http://arxiv.org/abs/2306.14884v2</link><description>Reinforcement Learning (RL) has been successful in various domains likerobotics, game playing, and simulation. While RL agents have shown impressivecapabilities in their specific tasks, they insufficiently adapt to new tasks.In supervised learning, this adaptation problem is addressed by large-scalepre-training followed by fine-tuning to new down-stream tasks. Recently,pre-training on multiple tasks has been gaining traction in RL. However,fine-tuning a pre-trained model often suffers from catastrophic forgetting.That is, the performance on the pre-training tasks deteriorates whenfine-tuning on new tasks. To investigate the catastrophic forgettingphenomenon, we first jointly pre-train a model on datasets from two benchmarksuites, namely Meta-World and DMControl. Then, we evaluate and compare avariety of fine-tuning methods prevalent in natural language processing, bothin terms of performance on new tasks, and how well performance on pre-trainingtasks is retained. Our study shows that with most fine-tuning approaches, theperformance on pre-training tasks deteriorates significantly. Therefore, wepropose a novel method, Learning-to-Modulate (L2M), that avoids the degradationof learned skills by modulating the information flow of the frozen pre-trainedmodel via a learnable modulation pool. Our method achieves state-of-the-artperformance on the Continual-World benchmark, while retaining performance onthe pre-training tasks. Finally, to aid future research in this area, werelease a dataset encompassing 50 Meta-World and 16 DMControl tasks.</description><author>Thomas Schmied, Markus Hofmarcher, Fabian Paischer, Razvan Pascanu, Sepp Hochreiter</author><pubDate>Fri, 27 Oct 2023 18:28:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.14884v2</guid></item><item><title>An Approach to Automatically generating Riddles aiding Concept Attainment</title><link>http://arxiv.org/abs/2310.18290v1</link><description>One of the primary challenges in online learning environments, is to retainlearner engagement. Several different instructional strategies are proposedboth in online and offline environments to enhance learner engagement. TheConcept Attainment Model is one such instructional strategy that focuses onlearners acquiring a deeper understanding of a concept rather than just itsdictionary definition. This is done by searching and listing the propertiesused to distinguish examples from non-examples of various concepts. Our workattempts to apply the Concept Attainment Model to build conceptual riddles, todeploy over online learning environments. The approach involves creatingfactual triples from learning resources, classifying them based on theiruniqueness to a concept into `Topic Markers' and `Common', followed bygenerating riddles based on the Concept Attainment Model's format and capturingall possible solutions to those riddles. The results obtained from the humanevaluation of riddles prove encouraging.</description><author>Niharika Sri Parasa, Chaitali Diwan, Srinath Srinivasa</author><pubDate>Fri, 27 Oct 2023 18:28:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18290v1</guid></item><item><title>Sustainable Concrete via Bayesian Optimization</title><link>http://arxiv.org/abs/2310.18288v1</link><description>Eight percent of global carbon dioxide emissions can be attributed to theproduction of cement, the main component of concrete, which is also thedominant source of CO2 emissions in the construction of data centers. Thediscovery of lower-carbon concrete formulae is therefore of high significancefor sustainability. However, experimenting with new concrete formulae is timeconsuming and labor intensive, as one usually has to wait to record theconcrete's 28-day compressive strength, a quantity whose measurement can by itsdefinition not be accelerated. This provides an opportunity for experimentaldesign methodology like Bayesian Optimization (BO) to accelerate the search forstrong and sustainable concrete formulae. Herein, we 1) propose modeling stepsthat make concrete strength amenable to be predicted accurately by a Gaussianprocess model with relatively few measurements, 2) formulate the search forsustainable concrete as a multi-objective optimization problem, and 3) leveragethe proposed model to carry out multi-objective BO with real-world strengthmeasurements of the algorithmically proposed mixes. Our experimental resultsshow improved trade-offs between the mixtures' global warming potential (GWP)and their associated compressive strengths, compared to mixes based on currentindustry practices.</description><author>Sebastian Ament, Andrew Witte, Nishant Garg, Julius Kusuma</author><pubDate>Fri, 27 Oct 2023 18:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18288v1</guid></item><item><title>Benchmarking Spatial Relationships in Text-to-Image Generation</title><link>http://arxiv.org/abs/2212.10015v3</link><description>Spatial understanding is a fundamental aspect of computer vision and integralfor human-level reasoning about images, making it an important component forgrounded language understanding. While recent text-to-image synthesis (T2I)models have shown unprecedented improvements in photorealism, it is unclearwhether they have reliable spatial understanding capabilities. We investigatethe ability of T2I models to generate correct spatial relationships amongobjects and present VISOR, an evaluation metric that captures how accuratelythe spatial relationship described in text is generated in the image. Tobenchmark existing models, we introduce a dataset, $\mathrm{SR}_{2D}$, thatcontains sentences describing two or more objects and the spatial relationshipsbetween them. We construct an automated evaluation pipeline to recognizeobjects and their spatial relationships, and employ it in a large-scaleevaluation of T2I models. Our experiments reveal a surprising finding that,although state-of-the-art T2I models exhibit high image quality, they areseverely limited in their ability to generate multiple objects or the specifiedspatial relations between them. Our analyses demonstrate several biases andartifacts of T2I models such as the difficulty with generating multipleobjects, a bias towards generating the first object mentioned, spatiallyinconsistent outputs for equivalent relationships, and a correlation betweenobject co-occurrence and spatial understanding capabilities. We conduct a humanstudy that shows the alignment between VISOR and human judgement about spatialunderstanding. We offer the $\mathrm{SR}_{2D}$ dataset and the VISOR metric tothe community in support of T2I reasoning research.</description><author>Tejas Gokhale, Hamid Palangi, Besmira Nushi, Vibhav Vineet, Eric Horvitz, Ece Kamar, Chitta Baral, Yezhou Yang</author><pubDate>Fri, 27 Oct 2023 18:24:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.10015v3</guid></item><item><title>Optimal Transport for Treatment Effect Estimation</title><link>http://arxiv.org/abs/2310.18286v1</link><description>Estimating conditional average treatment effect from observational data ishighly challenging due to the existence of treatment selection bias. Prevalentmethods mitigate this issue by aligning distributions of different treatmentgroups in the latent space. However, there are two critical problems that thesemethods fail to address: (1) mini-batch sampling effects (MSE), which causesmisalignment in non-ideal mini-batches with outcome imbalance and outliers; (2)unobserved confounder effects (UCE), which results in inaccurate discrepancycalculation due to the neglect of unobserved confounders. To tackle theseproblems, we propose a principled approach named Entire Space CounterFactualRegression (ESCFR), which is a new take on optimal transport in the context ofcausality. Specifically, based on the framework of stochastic optimaltransport, we propose a relaxed mass-preserving regularizer to address the MSEissue and design a proximal factual outcome regularizer to handle the UCEissue. Extensive experiments demonstrate that our proposed ESCFR cansuccessfully tackle the treatment selection bias and achieve significantlybetter performance than state-of-the-art methods.</description><author>Hao Wang, Zhichao Chen, Jiajun Fan, Haoxuan Li, Tianqiao Liu, Weiming Liu, Quanyu Dai, Yichao Wang, Zhenhua Dong, Ruiming Tang</author><pubDate>Fri, 27 Oct 2023 18:22:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18286v1</guid></item><item><title>Heterogeneous Federated Learning with Group-Aware Prompt Tuning</title><link>http://arxiv.org/abs/2310.18285v1</link><description>Transformers have achieved remarkable success in various machine-learningtasks, prompting their widespread adoption. In this paper, we explore theirapplication in the context of federated learning (FL), with a particular focuson heterogeneous scenarios where individual clients possess diverse localdatasets. To meet the computational and communication demands of FL, weleverage pre-trained Transformers and use an efficient prompt-tuning strategy.Our strategy introduces the concept of learning both shared and group prompts,enabling the acquisition of universal knowledge and group-specific knowledgesimultaneously. Additionally, a prompt selection module assigns personalizedgroup prompts to each input, aligning the global model with the datadistribution of each client. This approach allows us to train a single globalmodel that can automatically adapt to various local client data distributionswithout requiring local fine-tuning. In this way, our proposed methodeffectively bridges the gap between global and personalized local models inFederated Learning and surpasses alternative approaches that lack thecapability to adapt to previously unseen clients. The effectiveness of ourapproach is rigorously validated through extensive experimentation and ablationstudies.</description><author>Wenlong Deng, Christos Thrampoulidis, Xiaoxiao Li</author><pubDate>Fri, 27 Oct 2023 18:22:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18285v1</guid></item><item><title>Explainable Brain Age Prediction using coVariance Neural Networks</title><link>http://arxiv.org/abs/2305.18370v3</link><description>In computational neuroscience, there has been an increased interest indeveloping machine learning algorithms that leverage brain imaging data toprovide estimates of "brain age" for an individual. Importantly, thediscordance between brain age and chronological age (referred to as "brain agegap") can capture accelerated aging due to adverse health conditions andtherefore, can reflect increased vulnerability towards neurological disease orcognitive impairments. However, widespread adoption of brain age for clinicaldecision support has been hindered due to lack of transparency andmethodological justifications in most existing brain age prediction algorithms.In this paper, we leverage coVariance neural networks (VNN) to propose anexplanation-driven and anatomically interpretable framework for brain ageprediction using cortical thickness features. Specifically, our brain ageprediction framework extends beyond the coarse metric of brain age gap inAlzheimer's disease (AD) and we make two important observations: (i) VNNs canassign anatomical interpretability to elevated brain age gap in AD byidentifying contributing brain regions, (ii) the interpretability offered byVNNs is contingent on their ability to exploit specific eigenvectors of theanatomical covariance matrix. Together, these observations facilitate anexplainable and anatomically interpretable perspective to the task of brain ageprediction.</description><author>Saurabh Sihag, Gonzalo Mateos, Corey McMillan, Alejandro Ribeiro</author><pubDate>Fri, 27 Oct 2023 18:21:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18370v3</guid></item><item><title>Universality for the global spectrum of random inner-product kernel matrices in the polynomial regime</title><link>http://arxiv.org/abs/2310.18280v1</link><description>We consider certain large random matrices, called random inner-product kernelmatrices, which are essentially given by a nonlinear function $f$ appliedentrywise to a sample-covariance matrix, $f(X^TX)$, where $X \in \mathbb{R}^{d\times N}$ is random and normalized in such a way that $f$ typically hasorder-one arguments. We work in the polynomial regime, where $N \asymp d^\ell$for some $\ell &gt; 0$, not just the linear regime where $\ell = 1$. Earlier workby various authors showed that, when the columns of $X$ are either uniform onthe sphere or standard Gaussian vectors, and when $\ell$ is an integer (thelinear regime $\ell = 1$ is particularly well-studied), the bulk eigenvalues ofsuch matrices behave in a simple way: They are asymptotically given by the freeconvolution of the semicircular and Mar\v{c}enko-Pastur distributions, withrelative weights given by expanding $f$ in the Hermite basis. In this paper, weshow that this phenomenon is universal, holding as soon as $X$ has i.i.d.entries with all finite moments. In the case of non-integer $\ell$, theMar\v{c}enko-Pastur term disappears (its weight in the free convolutionvanishes), and the spectrum is just semicircular.</description><author>Sofiia Dubova, Yue M. Lu, Benjamin McKenna, Horng-Tzer Yau</author><pubDate>Fri, 27 Oct 2023 18:15:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18280v1</guid></item><item><title>Navigating Data Heterogeneity in Federated Learning A Semi-Supervised Approach for Object Detection</title><link>http://arxiv.org/abs/2310.17097v2</link><description>Federated Learning (FL) has emerged as a potent framework for training modelsacross distributed data sources while maintaining data privacy. Nevertheless,it faces challenges with limited high-quality labels and non-IID client data,particularly in applications like autonomous driving. To address these hurdles,we navigate the uncharted waters of Semi-Supervised Federated Object Detection(SSFOD). We present a pioneering SSFOD framework, designed for scenarios wherelabeled data reside only at the server while clients possess unlabeled data.Notably, our method represents the inaugural implementation of SSFOD forclients with 0% labeled non-IID data, a stark contrast to previous studies thatmaintain some subset of labels at each client. We propose FedSTO, a two-stagestrategy encompassing Selective Training followed by Orthogonally enhancedfull-parameter training, to effectively address data shift (e.g. weatherconditions) between server and clients. Our contributions include selectivelyrefining the backbone of the detector to avert overfitting, orthogonalityregularization to boost representation divergence, and local EMA-driven pseudolabel assignment to yield high-quality pseudo labels. Extensive validation onprominent autonomous driving datasets (BDD100K, Cityscapes, and SODA10M)attests to the efficacy of our approach, demonstrating state-of-the-artresults. Remarkably, FedSTO, using just 20-30% of labels, performs nearly aswell as fully-supervised centralized training methods.</description><author>Taehyeon Kim, Eric Lin, Junu Lee, Christian Lau, Vaikkunth Mugunthan</author><pubDate>Fri, 27 Oct 2023 18:13:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17097v2</guid></item><item><title>FOUND: Foot Optimization with Uncertain Normals for Surface Deformation Using Synthetic Data</title><link>http://arxiv.org/abs/2310.18279v1</link><description>Surface reconstruction from multi-view images is a challenging task, withsolutions often requiring a large number of sampled images with high overlap.We seek to develop a method for few-view reconstruction, for the case of thehuman foot. To solve this task, we must extract rich geometric cues from RGBimages, before carefully fusing them into a final 3D object. Our FOUND approachtackles this, with 4 main contributions: (i) SynFoot, a synthetic dataset of50,000 photorealistic foot images, paired with ground truth surface normals andkeypoints; (ii) an uncertainty-aware surface normal predictor trained on oursynthetic dataset; (iii) an optimization scheme for fitting a generative footmodel to a series of images; and (iv) a benchmark dataset of calibrated imagesand high resolution ground truth geometry. We show that our normal predictoroutperforms all off-the-shelf equivalents significantly on real images, and ouroptimization scheme outperforms state-of-the-art photogrammetry pipelines,especially for a few-view setting. We release our synthetic dataset andbaseline 3D scans to the research community.</description><author>Oliver Boyne, Gwangbin Bae, James Charles, Roberto Cipolla</author><pubDate>Fri, 27 Oct 2023 18:11:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18279v1</guid></item><item><title>Navigating protein landscapes with a machine-learned transferable coarse-grained model</title><link>http://arxiv.org/abs/2310.18278v1</link><description>The most popular and universally predictive protein simulation models employall-atom molecular dynamics (MD), but they come at extreme computational cost.The development of a universal, computationally efficient coarse-grained (CG)model with similar prediction performance has been a long-standing challenge.By combining recent deep learning methods with a large and diverse training setof all-atom protein simulations, we here develop a bottom-up CG force fieldwith chemical transferability, which can be used for extrapolative moleculardynamics on new sequences not used during model parametrization. We demonstratethat the model successfully predicts folded structures, intermediates,metastable folded and unfolded basins, and the fluctuations of intrinsicallydisordered proteins while it is several orders of magnitude faster than anall-atom model. This showcases the feasibility of a universal andcomputationally efficient machine-learned CG model for proteins.</description><author>Nicholas E. Charron, Felix Musil, Andrea Guljas, Yaoyi Chen, Klara Bonneau, Aldo S. Pasos-Trejo, Jacopo Venturin, Daria Gusew, Iryna Zaporozhets, Andreas Krämer, Clark Templeton, Atharva Kelkar, Aleksander E. P. Durumeric, Simon Olsson, Adrià Pérez, Maciej Majewski, Brooke E. Husic, Ankit Patel, Gianni De Fabritiis, Frank Noé, Cecilia Clementi</author><pubDate>Fri, 27 Oct 2023 18:10:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18278v1</guid></item><item><title>MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational Transcript Cleanup</title><link>http://arxiv.org/abs/2305.12029v2</link><description>Current disfluency detection models focus on individual utterances each froma single speaker. However, numerous discontinuity phenomena in spokenconversational transcripts occur across multiple turns, hampering humanreadability and the performance of downstream NLP tasks. This study addressesthese phenomena by proposing an innovative Multi-Turn Cleanup task for spokenconversational transcripts and collecting a new dataset, MultiTurnCleanup1. Wedesign a data labeling schema to collect the high-quality dataset and provideextensive data analysis. Furthermore, we leverage two modeling approaches forexperimental evaluation as benchmarks for future research.</description><author>Hua Shen, Vicky Zayats, Johann C. Rocholl, Daniel D. Walker, Dirk Padfield</author><pubDate>Fri, 27 Oct 2023 18:01:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12029v2</guid></item><item><title>LipSim: A Provably Robust Perceptual Similarity Metric</title><link>http://arxiv.org/abs/2310.18274v1</link><description>Recent years have seen growing interest in developing and applying perceptualsimilarity metrics. Research has shown the superiority of perceptual metricsover pixel-wise metrics in aligning with human perception and serving as aproxy for the human visual system. On the other hand, as perceptual metricsrely on neural networks, there is a growing concern regarding their resilience,given the established vulnerability of neural networks to adversarial attacks.It is indeed logical to infer that perceptual metrics may inherit both thestrengths and shortcomings of neural networks. In this work, we demonstrate thevulnerability of state-of-the-art perceptual similarity metrics based on anensemble of ViT-based feature extractors to adversarial attacks. We thenpropose a framework to train a robust perceptual similarity metric calledLipSim (Lipschitz Similarity Metric) with provable guarantees. By leveraging1-Lipschitz neural networks as the backbone, LipSim provides guarded areasaround each data point and certificates for all perturbations within an$\ell_2$ ball. Finally, a comprehensive set of experiments shows theperformance of LipSim in terms of natural and certified scores and on the imageretrieval application. The code is available athttps://github.com/SaraGhazanfari/LipSim.</description><author>Sara Ghazanfari, Alexandre Araujo, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg</author><pubDate>Fri, 27 Oct 2023 17:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18274v1</guid></item><item><title>Moments for Perceptive Narration Analysis Through the Emotional Attachment of Audience to Discourse and Story</title><link>http://arxiv.org/abs/2310.18273v1</link><description>In this work, our goal is to develop a theoretical framework that caneventually be used for analyzing the effectiveness of visual stories such asfeature films to comic books. To develop this theoretical framework, weintroduce a new story element called moments. Our conjecture is that any linearstory such as the story of a feature film can be decomposed into a set ofmoments that follow each other. Moments are defined as the perception of theactions, interactions, and expressions of all characters or a single characterduring a given time period. We categorize the moments into two major types:story moments and discourse moments. Each type of moment can further beclassified into three types, which we call universal storytelling moments. Webelieve these universal moments foster or deteriorate the emotional attachmentof the audience to a particular character or the story. We present amethodology to catalog the occurrences of these universal moments as they arefound in the story. The cataloged moments can be represented using curves orcolor strips. Therefore, we can visualize a character's journey through thestory as either a 3D curve or a color strip. We also demonstrated that bothstory and discourse moments can be transformed into one lump-sum attractionparameter. The attraction parameter in time provides a function that can beplotted graphically onto a timeline illustrating changes in the emotionalattachment of audience to a character or the story. By inspecting thesefunctions the story analyst can analytically decipher the moments in the storywhere the attachment is being established, maintained, strengthened, orconversely where it is languishing.</description><author>Gary Bruins, Ergun Akleman</author><pubDate>Fri, 27 Oct 2023 17:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18273v1</guid></item><item><title>PlantPlotGAN: A Physics-Informed Generative Adversarial Network for Plant Disease Prediction</title><link>http://arxiv.org/abs/2310.18268v1</link><description>Monitoring plantations is crucial for crop management and producing healthyharvests. Unmanned Aerial Vehicles (UAVs) have been used to collectmultispectral images that aid in this monitoring. However, given the number ofhectares to be monitored and the limitations of flight, plant disease signalsbecome visually clear only in the later stages of plant growth and only if thedisease has spread throughout a significant portion of the plantation. Thislimited amount of relevant data hampers the prediction models, as thealgorithms struggle to generalize patterns with unbalanced or unrealisticaugmented datasets effectively. To address this issue, we propose PlantPlotGAN,a physics-informed generative model capable of creating synthetic multispectralplot images with realistic vegetation indices. These indices served as a proxyfor disease detection and were used to evaluate if our model could helpincrease the accuracy of prediction models. The results demonstrate that thesynthetic imagery generated from PlantPlotGAN outperforms state-of-the-artmethods regarding the Fr\'echet inception distance. Moreover, prediction modelsachieve higher accuracy metrics when trained with synthetic and originalimagery for earlier plant disease detection compared to the training processesbased solely on real imagery.</description><author>Felipe A. Lopes, Vasit Sagan, Flavio Esposito</author><pubDate>Fri, 27 Oct 2023 17:56:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18268v1</guid></item><item><title>Structured Semidefinite Programming for Recovering Structured Preconditioners</title><link>http://arxiv.org/abs/2310.18265v1</link><description>We develop a general framework for finding approximately-optimalpreconditioners for solving linear systems. Leveraging this framework we obtainimproved runtimes for fundamental preconditioning and linear system solvingproblems including the following. We give an algorithm which, given positivedefinite $\mathbf{K} \in \mathbb{R}^{d \times d}$ with$\mathrm{nnz}(\mathbf{K})$ nonzero entries, computes an $\epsilon$-optimaldiagonal preconditioner in time $\widetilde{O}(\mathrm{nnz}(\mathbf{K}) \cdot\mathrm{poly}(\kappa^\star,\epsilon^{-1}))$, where $\kappa^\star$ is theoptimal condition number of the rescaled matrix. We give an algorithm which,given $\mathbf{M} \in \mathbb{R}^{d \times d}$ that is either the pseudoinverseof a graph Laplacian matrix or a constant spectral approximation of one, solveslinear systems in $\mathbf{M}$ in $\widetilde{O}(d^2)$ time. Our diagonalpreconditioning results improve state-of-the-art runtimes of $\Omega(d^{3.5})$attained by general-purpose semidefinite programming, and our solvers improvestate-of-the-art runtimes of $\Omega(d^{\omega})$ where $\omega &gt; 2.3$ is thecurrent matrix multiplication constant. We attain our results via newalgorithms for a class of semidefinite programs (SDPs) we callmatrix-dictionary approximation SDPs, which we leverage to solve an associatedproblem we call matrix-dictionary recovery.</description><author>Arun Jambulapati, Jerry Li, Christopher Musco, Kirankumar Shiragur, Aaron Sidford, Kevin Tian</author><pubDate>Fri, 27 Oct 2023 17:54:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18265v1</guid></item><item><title>Algorithmic Foundations of Empirical X-risk Minimization</title><link>http://arxiv.org/abs/2206.00439v6</link><description>This manuscript introduces a new optimization framework for machine learningand AI, named {\bf empirical X-risk minimization (EXM)}. X-risk is a termintroduced to represent a family of compositional measures or objectives, inwhich each data point is compared with a large number of items explicitly orimplicitly for defining a risk function. It includes surrogate objectives ofmany widely used measures and non-decomposable losses, e.g., AUROC, AUPRC,partial AUROC, NDCG, MAP, precision/recall at top $K$ positions, precision at acertain recall level, listwise losses, p-norm push, top push, globalcontrastive losses, etc. While these non-decomposable objectives and theiroptimization algorithms have been studied in the literature of machinelearning, computer vision, information retrieval, and etc, optimizing theseobjectives has encountered some unique challenges for deep learning. In thispaper, we present recent rigorous efforts for EXM with a focus on itsalgorithmic foundations and its applications. We introduce a class ofalgorithmic techniques for solving EXM with smooth non-convex objectives. Weformulate EXM into three special families of non-convex optimization problemsbelonging to non-convex compositional optimization, non-convex min-maxoptimization and non-convex bilevel optimization, respectively. For each familyof problems, we present some strong baseline algorithms and their complexities,which will motivate further research for improving the existing results.Discussions about the presented results and future studies are given at theend. Efficient algorithms for optimizing a variety of X-risks are implementedin the LibAUC library at \url{www.libauc.org}.</description><author>Tianbao Yang</author><pubDate>Fri, 27 Oct 2023 17:53:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.00439v6</guid></item><item><title>Learning to Search Feasible and Infeasible Regions of Routing Problems with Flexible Neural k-Opt</title><link>http://arxiv.org/abs/2310.18264v1</link><description>In this paper, we present Neural k-Opt (NeuOpt), a novel learning-to-search(L2S) solver for routing problems. It learns to perform flexible k-optexchanges based on a tailored action factorization method and a customizedrecurrent dual-stream decoder. As a pioneering work to circumvent the purefeasibility masking scheme and enable the autonomous exploration of bothfeasible and infeasible regions, we then propose the Guided Infeasible RegionExploration (GIRE) scheme, which supplements the NeuOpt policy network withfeasibility-related features and leverages reward shaping to steerreinforcement learning more effectively. Additionally, we equip NeuOpt withDynamic Data Augmentation (D2A) for more diverse searches during inference.Extensive experiments on the Traveling Salesman Problem (TSP) and CapacitatedVehicle Routing Problem (CVRP) demonstrate that our NeuOpt not onlysignificantly outstrips existing (masking-based) L2S solvers, but alsoshowcases superiority over the learning-to-construct (L2C) andlearning-to-predict (L2P) solvers. Notably, we offer fresh perspectives on howneural solvers can handle VRP constraints. Our code is available:https://github.com/yining043/NeuOpt.</description><author>Yining Ma, Zhiguang Cao, Yeow Meng Chee</author><pubDate>Fri, 27 Oct 2023 17:51:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18264v1</guid></item><item><title>MalFake: A Multimodal Fake News Identification for Malayalam using Recurrent Neural Networks and VGG-16</title><link>http://arxiv.org/abs/2310.18263v1</link><description>The amount of news being consumed online has substantially expanded in recentyears. Fake news has become increasingly common, especially in regionallanguages like Malayalam, due to the rapid publication and lack of editorialstandards on some online sites. Fake news may have a terrible effect onsociety, causing people to make bad judgments, lose faith in authorities, andeven engage in violent behavior. When we take into the context of India, thereare many regional languages, and fake news is spreading in every language.Therefore, providing efficient techniques for identifying false information inregional tongues is crucial. Until now, little to no work has been done inMalayalam, extracting features from multiple modalities to classify fake news.Multimodal approaches are more accurate in detecting fake news, as featuresfrom multiple modalities are extracted to build the deep learningclassification model. As far as we know, this is the first piece of work inMalayalam that uses multimodal deep learning to tackle false information.Models trained with more than one modality typically outperform models taughtwith only one modality. Our study in the Malayalam language utilizingmultimodal deep learning is a significant step toward more effectivemisinformation detection and mitigation.</description><author>Adhish S. Sujan, Ajitha. V, Aleena Benny, Amiya M. P., V. S. Anoop</author><pubDate>Fri, 27 Oct 2023 17:51:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18263v1</guid></item><item><title>Label Shift Estimators for Non-Ignorable Missing Data</title><link>http://arxiv.org/abs/2310.18261v1</link><description>We consider the problem of estimating the mean of a random variable Y subjectto non-ignorable missingness, i.e., where the missingness mechanism depends onY . We connect the auxiliary proxy variable framework for non-ignorablemissingness (West and Little, 2013) to the label shift setting (Saerens et al.,2002). Exploiting this connection, we construct an estimator for non-ignorablemissing data that uses high-dimensional covariates (or proxies) without theneed for a generative model. In synthetic and semi-synthetic experiments, westudy the behavior of the proposed estimator, comparing it to commonly usedignorable estimators in both well-specified and misspecified settings.Additionally, we develop a score to assess how consistent the data are with thelabel shift assumption. We use our approach to estimate disease prevalenceusing a large health survey, comparing ignorable and non-ignorable approaches.We show that failing to account for non-ignorable missingness can have profoundconsequences on conclusions drawn from non-representative samples.</description><author>Andrew C. Miller, Joseph Futoma</author><pubDate>Fri, 27 Oct 2023 17:50:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18261v1</guid></item><item><title>Concepts and Paradigms for Neuromorphic Programming</title><link>http://arxiv.org/abs/2310.18260v1</link><description>The value of neuromorphic computers depends crucially on our ability toprogram them for relevant tasks. Currently, neuromorphic computers are mostlylimited to machine learning methods adapted from deep learning. However,neuromorphic computers have potential far beyond deep learning if we can onlymake use of their computational properties to harness their full power.Neuromorphic programming will necessarily be different from conventionalprogramming, requiring a paradigm shift in how we think about programming ingeneral. The contributions of this paper are 1) a conceptual analysis of what"programming" means in the context of neuromorphic computers and 2) anexploration of existing programming paradigms that are promising yet overlookedin neuromorphic computing. The goal is to expand the horizon of neuromorphicprogramming methods, thereby allowing researchers to move beyond the shacklesof current methods and explore novel directions.</description><author>Steven Abreu</author><pubDate>Fri, 27 Oct 2023 17:48:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18260v1</guid></item><item><title>Statistical Learning under Heterogeneous Distribution Shift</title><link>http://arxiv.org/abs/2302.13934v4</link><description>This paper studies the prediction of a target $\mathbf{z}$ from a pair ofrandom variables $(\mathbf{x},\mathbf{y})$, where the ground-truth predictor isadditive $\mathbb{E}[\mathbf{z} \mid \mathbf{x},\mathbf{y}] =f_\star(\mathbf{x}) +g_{\star}(\mathbf{y})$. We study the performance ofempirical risk minimization (ERM) over functions $f+g$, $f \in F$ and $g \inG$, fit on a given training distribution, but evaluated on a test distributionwhich exhibits covariate shift. We show that, when the class $F$ is "simpler"than $G$ (measured, e.g., in terms of its metric entropy), our predictor ismore resilient to heterogeneous covariate shifts} in which the shift in$\mathbf{x}$ is much greater than that in $\mathbf{y}$. Our analysis proceedsby demonstrating that ERM behaves qualitatively similarly to orthogonal machinelearning: the rate at which ERM recovers the $f$-component of the predictor hasonly a lower-order dependence on the complexity of the class $G$, adjusted forpartial non-indentifiability introduced by the additive structure. Theseresults rely on a novel H\"older style inequality for the Dudley integral whichmay be of independent interest. Moreover, we corroborate our theoreticalfindings with experiments demonstrating improved resilience to shifts in"simpler" features across numerous domains.</description><author>Max Simchowitz, Anurag Ajay, Pulkit Agrawal, Akshay Krishnamurthy</author><pubDate>Fri, 27 Oct 2023 17:47:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.13934v4</guid></item><item><title>Autonomous search of real-life environments combining dynamical system-based path planning and unsupervised learning</title><link>http://arxiv.org/abs/2305.01834v2</link><description>In recent years, advancements have been made towards the goal of usingchaotic coverage path planners for autonomous search and traversal of spaceswith limited environmental cues. However, the state of this field is still inits infancy as there has been little experimental work done. Currentexperimental work has not developed robust methods to satisfactorily addressthe immediate set of problems a chaotic coverage path planner needs to overcomein order to scan realistic environments within reasonable coverage times. Theseimmediate problems are as follows: (1) an obstacle avoidance technique whichgenerally maintains the kinematic efficiency of the robot's motion, (2) a meansto spread chaotic trajectories across the environment (especially crucial forlarge and/or complex-shaped environments) that need to be covered, and (3) areal-time coverage calculation technique that is accurate and independent ofcell size. This paper aims to progress the field by proposing algorithms thataddress all of these problems by providing techniques for obstacle avoidance,chaotic trajectory dispersal, and accurate coverage calculation. The algorithmsproduce generally smooth chaotic trajectories and provide high scanningcoverage of environments. These algorithms were created within the ROSframework and make up a newly developed chaotic path planning application. Theperformance of this application was comparable to that of a conventionaloptimal path planner. The performance tests were carried out in environments ofvarious sizes, shapes, and obstacle densities, both in real-life and Gazebosimulations.</description><author>Uyiosa Philip Amadasun, Patrick McNamee, Zahra Nili Ahmadabadi, Peiman Naseradinmousavi</author><pubDate>Fri, 27 Oct 2023 17:45:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.01834v2</guid></item><item><title>eP-ALM: Efficient Perceptual Augmentation of Language Models</title><link>http://arxiv.org/abs/2303.11403v4</link><description>Large Language Models (LLMs) have so far impressed the world, withunprecedented capabilities that emerge in models at large scales. On the visionside, transformer models (i.e., ViT) are following the same trend, achievingthe best performance on challenging benchmarks. With the abundance of suchunimodal models, a natural question arises; do we need also to follow thistrend to tackle multimodal tasks? In this work, we propose to rather directeffort to efficient adaptations of existing models, and propose to augmentLanguage Models with perception. Existing approaches for adapting pretrainedmodels for vision-language tasks still rely on several key components thathinder their efficiency. In particular, they still train a large number ofparameters, rely on large multimodal pretraining, use encoders (e.g., CLIP)trained on huge image-text datasets, and add significant inference overhead. Inaddition, most of these approaches have focused on Zero-Shot and In ContextLearning, with little to no effort on direct finetuning. We investigate theminimal computational effort needed to adapt unimodal models for multimodaltasks and propose a new challenging setup, alongside different approaches, thatefficiently adapts unimodal pretrained models. We show that by freezing morethan 99% of total parameters, training only one linear projection layer, andprepending only one trainable token, our approach (dubbed eP-ALM) significantlyoutperforms other baselines on VQA and Captioning across Image, Video, andAudio modalities, following the proposed setup. The code is available here:https://github.com/mshukor/eP-ALM.</description><author>Mustafa Shukor, Corentin Dancette, Matthieu Cord</author><pubDate>Fri, 27 Oct 2023 17:38:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11403v4</guid></item><item><title>A Self-Supervised Approach to Land Cover Segmentation</title><link>http://arxiv.org/abs/2310.18251v1</link><description>Land use/land cover change (LULC) maps are integral resources in earthscience and agricultural research. Due to the nature of such maps, the creationof LULC maps is often constrained by the time and human resources necessary toaccurately annotate satellite imagery and remote sensing data. While computervision models that perform semantic segmentation to create detailed labels fromsuch data are not uncommon, litle research has been done on self-supervised andunsupervised approaches to labelling LULC maps without the use of ground-truthmasks. Here, we demonstrate a self-supervised method of land cover segmentationthat has no need for high-quality ground truth labels. The proposed deeplearning employs a frozen pre-trained ViT backbone transferred from DINO in aSTEGO architecture and is fine-tuned using a custom dataset consisting of veryhigh resolution (VHR) sattelite imagery. After only 10 epochs of fine-tuning,an accuracy of roughly 52% was observed across 5 samples, signifying thefeasibility of self-supervised models for the automated labelling of VHR LULCmaps.</description><author>Charles Moore, Dakota Hester</author><pubDate>Fri, 27 Oct 2023 17:37:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18251v1</guid></item><item><title>The noise level in linear regression with dependent data</title><link>http://arxiv.org/abs/2305.11165v2</link><description>We derive upper bounds for random design linear regression with dependent($\beta$-mixing) data absent any realizability assumptions. In contrast to thestrictly realizable martingale noise regime, no sharp instance-optimalnon-asymptotics are available in the literature. Up to constant factors, ouranalysis correctly recovers the variance term predicted by the Central LimitTheorem -- the noise level of the problem -- and thus exhibits gracefuldegradation as we introduce misspecification. Past a burn-in, our result issharp in the moderate deviations regime, and in particular does not inflate theleading order term by mixing time factors.</description><author>Ingvar Ziemann, Stephen Tu, George J. Pappas, Nikolai Matni</author><pubDate>Fri, 27 Oct 2023 17:34:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11165v2</guid></item><item><title>Guided Data Augmentation for Offline Reinforcement Learning and Imitation Learning</title><link>http://arxiv.org/abs/2310.18247v1</link><description>Learning from demonstration (LfD) is a popular technique that uses expertdemonstrations to learn robot control policies. However, the difficulty inacquiring expert-quality demonstrations limits the applicability of LfDmethods: real-world data collection is often costly, and the quality of thedemonstrations depends greatly on the demonstrator's abilities and safetyconcerns. A number of works have leveraged data augmentation (DA) toinexpensively generate additional demonstration data, but most DA worksgenerate augmented data in a random fashion and ultimately produce highlysuboptimal data. In this work, we propose Guided Data Augmentation (GuDA), ahuman-guided DA framework that generates expert-quality augmented data. The keyinsight of GuDA is that while it may be difficult to demonstrate the sequenceof actions required to produce expert data, a user can often easily identifywhen an augmented trajectory segment represents task progress. Thus, the usercan impose a series of simple rules on the DA process to automatically generateaugmented samples that approximate expert behavior. To extract a policy fromGuDA, we use off-the-shelf offline reinforcement learning and behavior cloningalgorithms. We evaluate GuDA on a physical robot soccer task as well assimulated D4RL navigation tasks, a simulated autonomous driving task, and asimulated soccer task. Empirically, we find that GuDA enables learning from asmall set of potentially suboptimal demonstrations and substantiallyoutperforms a DA strategy that samples augmented data randomly.</description><author>Nicholas E. Corrado, Yuxiao Qu, John U. Balis, Adam Labiosa, Josiah P. Hanna</author><pubDate>Fri, 27 Oct 2023 17:34:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18247v1</guid></item><item><title>Enhancing drug and cell line representations via contrastive learning for improved anti-cancer drug prioritization</title><link>http://arxiv.org/abs/2310.13725v2</link><description>Due to cancer's complex nature and variable response to therapy, precisiononcology informed by omics sequence analysis has become the current standard ofcare. However, the amount of data produced for each patients makes it difficultto quickly identify the best treatment regimen. Moreover, limited dataavailability has hindered computational methods' abilities to learn patternsassociated with effective drug-cell line pairs. In this work, we propose theuse of contrastive learning to improve learned drug and cell linerepresentations by preserving relationship structures associated with drugmechanism of action and cell line cancer types. In addition to achievingenhanced performance relative to a state-of-the-art method, we find thatclassifiers using our learned representations exhibit a more balances relianceon drug- and cell line-derived features when making predictions. Thisfacilitates more personalized drug prioritizations that are informed by signalsrelated to drug resistance.</description><author>Patrick J. Lawrence, Xia Ning</author><pubDate>Fri, 27 Oct 2023 17:30:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13725v2</guid></item><item><title>NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks</title><link>http://arxiv.org/abs/2110.14053v5</link><description>Propositional satisfiability (SAT) is an NP-complete problem that impactsmany research fields, such as planning, verification, and security. Mainstreammodern SAT solvers are based on the Conflict-Driven Clause Learning (CDCL)algorithm. Recent work aimed to enhance CDCL SAT solvers using Graph NeuralNetworks (GNNs). However, so far this approach either has not made solving moreeffective, or required substantial GPU resources for frequent online modelinferences. Aiming to make GNN improvements practical, this paper proposes anapproach called NeuroBack, which builds on two insights: (1) predicting phases(i.e., values) of variables appearing in the majority (or even all) of thesatisfying assignments are essential for CDCL SAT solving, and (2) it issufficient to query the neural model only once for the predictions before theSAT solving starts. Once trained, the offline model inference allows NeuroBackto execute exclusively on the CPU, removing its reliance on GPU resources. Totrain NeuroBack, a new dataset called DataBack containing 120,286 data samplesis created. Finally, NeuroBack is implemented as an enhancement to astate-of-the-art SAT solver called Kissat. As a result, it allowed Kissat tosolve 5.2% more problems on the recent SAT competition problem set,SATCOMP-2022. NeuroBack therefore shows how machine learning can be harnessedto improve SAT solving in an effective and practical manner.</description><author>Wenxi Wang, Yang Hu, Mohit Tiwari, Sarfraz Khurshid, Kenneth McMillan, Risto Miikkulainen</author><pubDate>Fri, 27 Oct 2023 17:30:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.14053v5</guid></item><item><title>A Review of the Evidence for Existential Risk from AI via Misaligned Power-Seeking</title><link>http://arxiv.org/abs/2310.18244v1</link><description>Rapid advancements in artificial intelligence (AI) have sparked growingconcerns among experts, policymakers, and world leaders regarding the potentialfor increasingly advanced AI systems to pose existential risks. This paperreviews the evidence for existential risks from AI via misalignment, where AIsystems develop goals misaligned with human values, and power-seeking, wheremisaligned AIs actively seek power. The review examines empirical findings,conceptual arguments and expert opinion relating to specification gaming, goalmisgeneralization, and power-seeking. The current state of the evidence isfound to be concerning but inconclusive regarding the existence of extremeforms of misaligned power-seeking. Strong empirical evidence of specificationgaming combined with strong conceptual evidence for power-seeking make itdifficult to dismiss the possibility of existential risk from misalignedpower-seeking. On the other hand, to date there are no public empiricalexamples of misaligned power-seeking in AI systems, and so arguments thatfuture systems will pose an existential risk remain somewhat speculative. Giventhe current state of the evidence, it is hard to be extremely confident eitherthat misaligned power-seeking poses a large existential risk, or that it posesno existential risk. The fact that we cannot confidently rule out existentialrisk from AI via misaligned power-seeking is cause for serious concern.</description><author>Rose Hadshar</author><pubDate>Fri, 27 Oct 2023 17:29:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18244v1</guid></item><item><title>Modeling Path Importance for Effective Alzheimer's Disease Drug Repurposing</title><link>http://arxiv.org/abs/2310.15211v2</link><description>Recently, drug repurposing has emerged as an effective and resource-efficientparadigm for AD drug discovery. Among various methods for drug repurposing,network-based methods have shown promising results as they are capable ofleveraging complex networks that integrate multiple interaction types, such asprotein-protein interactions, to more effectively identify candidate drugs.However, existing approaches typically assume paths of the same length in thenetwork have equal importance in identifying the therapeutic effect of drugs.Other domains have found that same length paths do not necessarily have thesame importance. Thus, relying on this assumption may be deleterious to drugrepurposing attempts. In this work, we propose MPI (Modeling Path Importance),a novel network-based method for AD drug repurposing. MPI is unique in that itprioritizes important paths via learned node embeddings, which can effectivelycapture a network's rich structural information. Thus, leveraging learnedembeddings allows MPI to effectively differentiate the importance among paths.We evaluate MPI against a commonly used baseline method that identifies anti-ADdrug candidates primarily based on the shortest paths between drugs and AD inthe network. We observe that among the top-50 ranked drugs, MPI prioritizes20.0% more drugs with anti-AD evidence compared to the baseline. Finally, Coxproportional-hazard models produced from insurance claims data aid us inidentifying the use of etodolac, nicotine, and BBB-crossing ACE-INHs as havinga reduced risk of AD, suggesting such drugs may be viable candidates forrepurposing and should be explored further in future studies.</description><author>Shunian Xiang, Patrick J. Lawrence, Bo Peng, ChienWei Chiang, Dokyoon Kim, Li Shen, Xia Ning</author><pubDate>Fri, 27 Oct 2023 17:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15211v2</guid></item><item><title>Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games</title><link>http://arxiv.org/abs/2310.09727v2</link><description>This work studies an independent natural policy gradient (NPG) algorithm forthe multi-agent reinforcement learning problem in Markov potential games. It isshown that, under mild technical assumptions and the introduction of the\textit{suboptimality gap}, the independent NPG method with an oracle providingexact policy evaluation asymptotically reaches an $\epsilon$-Nash Equilibrium(NE) within $\mathcal{O}(1/\epsilon)$ iterations. This improves upon theprevious best result of $\mathcal{O}(1/\epsilon^2)$ iterations and is of thesame order, $\mathcal{O}(1/\epsilon)$, that is achievable for the single-agentcase. Empirical results for a synthetic potential game and a congestion gameare presented to verify the theoretical bounds.</description><author>Youbang Sun, Tao Liu, Ruida Zhou, P. R. Kumar, Shahin Shahrampour</author><pubDate>Fri, 27 Oct 2023 17:28:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09727v2</guid></item><item><title>$α$-Mutual Information: A Tunable Privacy Measure for Privacy Protection in Data Sharing</title><link>http://arxiv.org/abs/2310.18241v1</link><description>This paper adopts Arimoto's $\alpha$-Mutual Information as a tunable privacymeasure, in a privacy-preserving data release setting that aims to preventdisclosing private data to adversaries. By fine-tuning the privacy metric, wedemonstrate that our approach yields superior models that effectively thwartattackers across various performance dimensions. We formulate a generaldistortion-based mechanism that manipulates the original data to offer privacyprotection. The distortion metrics are determined according to the datastructure of a specific experiment. We confront the problem expressed in theformulation by employing a general adversarial deep learning framework thatconsists of a releaser and an adversary, trained with opposite goals. Thisstudy conducts empirical experiments on images and time-series data to verifythe functionality of $\alpha$-Mutual Information. We evaluate theprivacy-utility trade-off of customized models and compare them to mutualinformation as the baseline measure. Finally, we analyze the consequence of anattacker's access to side information about private data and witness thatadapting the privacy measure results in a more refined model than thestate-of-the-art in terms of resiliency against side information.</description><author>MirHamed Jafarzadeh Asl, Mohammadhadi Shateri, Fabrice Labeau</author><pubDate>Fri, 27 Oct 2023 17:26:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18241v1</guid></item><item><title>Fine-Tuning Language Models Using Formal Methods Feedback</title><link>http://arxiv.org/abs/2310.18239v1</link><description>Although pre-trained language models encode generic knowledge beneficial forplanning and control, they may fail to generate appropriate control policiesfor domain-specific tasks. Existing fine-tuning methods use human feedback toaddress this limitation, however, sourcing human feedback is labor intensiveand costly. We present a fully automated approach to fine-tune pre-trainedlanguage models for applications in autonomous systems, bridging the gapbetween generic knowledge and domain-specific requirements while reducing cost.The method synthesizes automaton-based controllers from pre-trained modelsguided by natural language task descriptions. These controllers are verifiableagainst independently provided specifications within a world model, which canbe abstract or obtained from a high-fidelity simulator. Controllers with highcompliance with the desired specifications receive higher ranks, guiding theiterative fine-tuning process. We provide quantitative evidences, primarily inautonomous driving, to demonstrate the method's effectiveness across multipletasks. The results indicate an improvement in percentage of specificationssatisfied by the controller from 60% to 90%.</description><author>Yunhao Yang, Neel P. Bhatt, Tyler Ingebrand, William Ward, Steven Carr, Zhangyang Wang, Ufuk Topcu</author><pubDate>Fri, 27 Oct 2023 17:24:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18239v1</guid></item><item><title>Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples</title><link>http://arxiv.org/abs/2310.07747v2</link><description>Learning controllers with offline data in decision-making systems is anessential area of research due to its potential to reduce the risk ofapplications in real-world systems. However, in responsibility-sensitivesettings such as healthcare, decision accountability is of paramountimportance, yet has not been adequately addressed by the literature. This paperintroduces the Accountable Offline Controller (AOC) that employs the offlinedataset as the Decision Corpus and performs accountable control based on atailored selection of examples, referred to as the Corpus Subset. AOC operateseffectively in low-data scenarios, can be extended to the strictly offlineimitation setting, and displays qualities of both conservation andadaptability. We assess AOC's performance in both simulated and real-worldhealthcare scenarios, emphasizing its capability to manage offline controltasks with high levels of performance while maintaining accountability.</description><author>Hao Sun, Alihan Hüyük, Daniel Jarrett, Mihaela van der Schaar</author><pubDate>Fri, 27 Oct 2023 17:23:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07747v2</guid></item><item><title>Generative AI Model for Artistic Style Transfer Using Convolutional Neural Networks</title><link>http://arxiv.org/abs/2310.18237v1</link><description>Artistic style transfer, a captivating application of generative artificialintelligence, involves fusing the content of one image with the artistic styleof another to create unique visual compositions. This paper presents acomprehensive overview of a novel technique for style transfer usingConvolutional Neural Networks (CNNs). By leveraging deep image representationslearned by CNNs, we demonstrate how to separate and manipulate image contentand style, enabling the synthesis of high-quality images that combine contentand style in a harmonious manner. We describe the methodology, includingcontent and style representations, loss computation, and optimization, andshowcase experimental results highlighting the effectiveness and versatility ofthe approach across different styles and content</description><author>Jonayet Miah, Duc M Cao, Md Abu Sayed, Md. Sabbirul Haque</author><pubDate>Fri, 27 Oct 2023 17:21:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18237v1</guid></item><item><title>How Re-sampling Helps for Long-Tail Learning?</title><link>http://arxiv.org/abs/2310.18236v1</link><description>Long-tail learning has received significant attention in recent years due tothe challenge it poses with extremely imbalanced datasets. In these datasets,only a few classes (known as the head classes) have an adequate number oftraining samples, while the rest of the classes (known as the tail classes) areinfrequent in the training data. Re-sampling is a classical and widely usedapproach for addressing class imbalance issues. Unfortunately, recent studiesclaim that re-sampling brings negligible performance improvements in modernlong-tail learning tasks. This paper aims to investigate this phenomenonsystematically. Our research shows that re-sampling can considerably improvegeneralization when the training images do not contain semantically irrelevantcontexts. In other scenarios, however, it can learn unexpected spuriouscorrelations between irrelevant contexts and target labels. We designexperiments on two homogeneous datasets, one containing irrelevant context andthe other not, to confirm our findings. To prevent the learning of spuriouscorrelations, we propose a new context shift augmentation module that generatesdiverse training images for the tail class by maintaining a context bankextracted from the head-class images. Experiments demonstrate that our proposedmodule can boost the generalization and outperform other approaches, includingclass-balanced re-sampling, decoupled classifier re-training, and dataaugmentation methods. The source code is available athttps://www.lamda.nju.edu.cn/code_CSA.ashx.</description><author>Jiang-Xin Shi, Tong Wei, Yuke Xiang, Yu-Feng Li</author><pubDate>Fri, 27 Oct 2023 17:20:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18236v1</guid></item><item><title>Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-Image Generation</title><link>http://arxiv.org/abs/2310.18235v1</link><description>Evaluating text-to-image models is notoriously difficult. A strong recentapproach for assessing text-image faithfulness is based on QG/A (questiongeneration and answering), which uses pre-trained foundational models toautomatically generate a set of questions and answers from the prompt, andoutput images are scored based on whether these answers extracted with a visualquestion answering model are consistent with the prompt-based answers. Thiskind of evaluation is naturally dependent on the quality of the underlying QGand QA models. We identify and address several reliability challenges inexisting QG/A work: (a) QG questions should respect the prompt (avoidinghallucinations, duplications, and omissions) and (b) VQA answers should beconsistent (not asserting that there is no motorcycle in an image while alsoclaiming the motorcycle is blue). We address these issues with DavidsonianScene Graph (DSG), an empirically grounded evaluation framework inspired byformal semantics. DSG is an automatic, graph-based QG/A that is modularlyimplemented to be adaptable to any QG/A module. DSG produces atomic and uniquequestions organized in dependency graphs, which (i) ensure appropriate semanticcoverage and (ii) sidestep inconsistent answers. With extensive experimentationand human evaluation on a range of model configurations (LLM, VQA, and T2I), weempirically demonstrate that DSG addresses the challenges noted above. Finally,we present DSG-1k, an open-sourced evaluation benchmark that includes 1,060prompts, covering a wide range of fine-grained semantic categories with abalanced distribution. We will release the DSG-1k prompts and the correspondingDSG questions.</description><author>Jaemin Cho, Yushi Hu, Roopal Garg, Peter Anderson, Ranjay Krishna, Jason Baldridge, Mohit Bansal, Jordi Pont-Tuset, Su Wang</author><pubDate>Fri, 27 Oct 2023 17:20:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18235v1</guid></item><item><title>Edge AI-Based Vein Detector for Efficient Venipuncture in the Antecubital Fossa</title><link>http://arxiv.org/abs/2310.18234v1</link><description>Assessing the condition and visibility of veins is a crucial step beforeobtaining intravenous access in the antecubital fossa, which is a commonprocedure to draw blood or administer intravenous therapies (IV therapies).Even though medical practitioners are highly skilled at intravenouscannulation, they usually struggle to perform the procedure in patients withlow visible veins due to fluid retention, age, overweight, dark skin tone, ordiabetes. Recently, several investigations proposed combining Near Infrared(NIR) imaging and deep learning (DL) techniques for forearm vein segmentation.Although they have demonstrated compelling results, their use has been ratherlimited owing to the portability and precision requirements to performvenipuncture. In this paper, we aim to contribute to bridging this gap usingthree strategies. First, we introduce a new NIR-based forearm vein segmentationdataset of 2,016 labelled images collected from 1,008 subjects with low visibleveins. Second, we propose a modified U-Net architecture that locates veinsspecifically in the antecubital fossa region of the examined patient. Finally,a compressed version of the proposed architecture was deployed inside abespoke, portable vein finder device after testing four common embeddedmicrocomputers and four common quantization modalities. Experimental resultsshowed that the model compressed with Dynamic Range Quantization and deployedon a Raspberry Pi 4B card produced the best execution time and precisionbalance, with 5.14 FPS and 0.957 of latency and Intersection over Union (IoU),respectively. These results show promising performance inside aresource-restricted low-cost device.</description><author>Edwin Salcedo, Patricia Peñaloza</author><pubDate>Fri, 27 Oct 2023 17:19:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18234v1</guid></item><item><title>Deep Transformed Gaussian Processes</title><link>http://arxiv.org/abs/2310.18230v1</link><description>Transformed Gaussian Processes (TGPs) are stochastic processes specified bytransforming samples from the joint distribution from a prior process(typically a GP) using an invertible transformation; increasing the flexibilityof the base process. Furthermore, they achieve competitive results compared with Deep GaussianProcesses (DGPs), which are another generalization constructed by ahierarchical concatenation of GPs. In this work, we propose a generalization ofTGPs named Deep Transformed Gaussian Processes (DTGPs), which follows the trendof concatenating layers of stochastic processes. More precisely, we obtain amulti-layer model in which each layer is a TGP. This generalization implies anincrement of flexibility with respect to both TGPs and DGPs. Exact inference insuch a model is intractable. However, we show that one can use variationalinference to approximate the required computations yielding a straightforwardextension of the popular DSVI inference algorithm Salimbeni et al (2017). Theexperiments conducted evaluate the proposed novel DTGPs in multiple regressiondatasets, achieving good scalability and performance.</description><author>Sáez-Maldonado Francisco Javier, Maroñas Juan, Hernández-Lobato Daniel</author><pubDate>Fri, 27 Oct 2023 17:09:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18230v1</guid></item><item><title>ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing</title><link>http://arxiv.org/abs/2305.09770v6</link><description>Despite a surge collection of XAI methods, users still struggle to obtainrequired AI explanations. Previous research suggests chatbots as dynamicsolutions, but the effective design of conversational XAI agents for practicalhuman needs remains under-explored. This paper focuses on Conversational XAIfor AI-assisted scientific writing tasks. Drawing from human linguistictheories and formative studies, we identify four design rationales:"multifaceted", "controllability", "mix-initiative", "context-awaredrill-down". We incorporate them into an interactive prototype, ConvXAI, whichfacilitates heterogeneous AI explanations for scientific writing throughdialogue. In two studies with 21 users, ConvXAI outperforms a GUI-basedbaseline on improving human-perceived understanding and writing improvement.The paper further discusses the practical human usage patterns in interactingwith ConvXAI for scientific co-writing.</description><author>Hua Shen, Chieh-Yang Huang, Tongshuang Wu, Ting-Hao 'Kenneth' Huang</author><pubDate>Fri, 27 Oct 2023 17:08:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09770v6</guid></item><item><title>Revising with a Backward Glance: Regressions and Skips during Reading as Cognitive Signals for Revision Policies in Incremental Processing</title><link>http://arxiv.org/abs/2310.18229v1</link><description>In NLP, incremental processors produce output in instalments, based onincoming prefixes of the linguistic input. Some tokens trigger revisions,causing edits to the output hypothesis, but little is known about why modelsrevise when they revise. A policy that detects the time steps where revisionsshould happen can improve efficiency. Still, retrieving a suitable signal totrain a revision policy is an open problem, since it is not naturally availablein datasets. In this work, we investigate the appropriateness of regressionsand skips in human reading eye-tracking data as signals to inform revisionpolicies in incremental sequence labelling. Using generalised mixed-effectsmodels, we find that the probability of regressions and skips by humans canpotentially serve as useful predictors for revisions in BiLSTMs and Transformermodels, with consistent results for various languages.</description><author>Brielen Madureira, Pelin Çelikkol, David Schlangen</author><pubDate>Fri, 27 Oct 2023 17:08:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18229v1</guid></item><item><title>Topological Parallax: A Geometric Specification for Deep Perception Models</title><link>http://arxiv.org/abs/2306.11835v2</link><description>For safety and robustness of AI systems, we introduce topological parallax asa theoretical and computational tool that compares a trained model to areference dataset to determine whether they have similar multiscale geometricstructure. Our proofs and examples show that this geometric similarity betweendataset and model is essential to trustworthy interpolation and perturbation,and we conjecture that this new concept will add value to the current debateregarding the unclear relationship between overfitting and generalization inapplications of deep-learning. In typical DNN applications, an explicitgeometric description of the model is impossible, but parallax can estimatetopological features (components, cycles, voids, etc.) in the model byexamining the effect on the Rips complex of geodesic distortions using thereference dataset. Thus, parallax indicates whether the model shares similarmultiscale geometric features with the dataset. Parallax presents theoreticallyvia topological data analysis [TDA] as a bi-filtered persistence module, andthe key properties of this module are stable under perturbation of thereference dataset.</description><author>Abraham D. Smith, Michael J. Catanzaro, Gabrielle Angeloro, Nirav Patel, Paul Bendich</author><pubDate>Fri, 27 Oct 2023 17:06:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11835v2</guid></item><item><title>Partial Counterfactual Identification of Continuous Outcomes with a Curvature Sensitivity Model</title><link>http://arxiv.org/abs/2306.01424v2</link><description>Counterfactual inference aims to answer retrospective "what if" questions andthus belongs to the most fine-grained type of inference in Pearl's causalityladder. Existing methods for counterfactual inference with continuous outcomesaim at point identification and thus make strong and unnatural assumptionsabout the underlying structural causal model. In this paper, we relax theseassumptions and aim at partial counterfactual identification of continuousoutcomes, i.e., when the counterfactual query resides in an ignorance intervalwith informative bounds. We prove that, in general, the ignorance interval ofthe counterfactual queries has non-informative bounds, already when functionsof structural causal models are continuously differentiable. As a remedy, wepropose a novel sensitivity model called Curvature Sensitivity Model. Thisallows us to obtain informative bounds by bounding the curvature of level setsof the functions. We further show that existing point counterfactualidentification methods are special cases of our Curvature Sensitivity Modelwhen the bound of the curvature is set to zero. We then propose animplementation of our Curvature Sensitivity Model in the form of a novel deepgenerative model, which we call Augmented Pseudo-Invertible Decoder. Ourimplementation employs (i) residual normalizing flows with (ii) variationalaugmentations. We empirically demonstrate the effectiveness of our AugmentedPseudo-Invertible Decoder. To the best of our knowledge, ours is the firstpartial identification model for Markovian structural causal models withcontinuous outcomes.</description><author>Valentyn Melnychuk, Dennis Frauen, Stefan Feuerriegel</author><pubDate>Fri, 27 Oct 2023 17:05:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01424v2</guid></item><item><title>MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark for Language Model Evaluation</title><link>http://arxiv.org/abs/2310.14088v2</link><description>Curated datasets for healthcare are often limited due to the need of humanannotations from experts. In this paper, we present MedEval, a multi-level,multi-task, and multi-domain medical benchmark to facilitate the development oflanguage models for healthcare. MedEval is comprehensive and consists of datafrom several healthcare systems and spans 35 human body regions from 8examination modalities. With 22,779 collected sentences and 21,228 reports, weprovide expert annotations at multiple levels, offering a granular potentialusage of the data and supporting a wide range of tasks. Moreover, wesystematically evaluated 10 generic and domain-specific language models underzero-shot and finetuning settings, from domain-adapted baselines in healthcareto general-purposed state-of-the-art large language models (e.g., ChatGPT). Ourevaluations reveal varying effectiveness of the two categories of languagemodels across different tasks, from which we notice the importance ofinstruction tuning for few-shot usage of large language models. Ourinvestigation paves the way toward benchmarking language models for healthcareand provides valuable insights into the strengths and limitations of adoptinglarge language models in medical domains, informing their practicalapplications and future advancements.</description><author>Zexue He, Yu Wang, An Yan, Yao Liu, Eric Y. Chang, Amilcare Gentili, Julian McAuley, Chun-Nan Hsu</author><pubDate>Fri, 27 Oct 2023 17:00:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14088v2</guid></item><item><title>LeanDojo: Theorem Proving with Retrieval-Augmented Language Models</title><link>http://arxiv.org/abs/2306.15626v2</link><description>Large language models (LLMs) have shown promise in proving formal theoremsusing proof assistants such as Lean. However, existing methods are difficult toreproduce or build on, due to private code, data, and large computerequirements. This has created substantial barriers to research on machinelearning methods for theorem proving. This paper removes these barriers byintroducing LeanDojo: an open-source Lean playground consisting of toolkits,data, models, and benchmarks. LeanDojo extracts data from Lean and enablesinteraction with the proof environment programmatically. It containsfine-grained annotations of premises in proofs, providing valuable data forpremise selection: a key bottleneck in theorem proving. Using this data, wedevelop ReProver (Retrieval-Augmented Prover): an LLM-based prover augmentedwith retrieval for selecting premises from a vast math library. It isinexpensive and needs only one GPU week of training. Our retriever leveragesLeanDojo's program analysis capability to identify accessible premises and hardnegative examples, which makes retrieval much more effective. Furthermore, weconstruct a new benchmark consisting of 98,734 theorems and proofs extractedfrom Lean's math library. It features challenging data split requiring theprover to generalize to theorems relying on novel premises that are never usedin training. We use this benchmark for training and evaluation, andexperimental results demonstrate the effectiveness of ReProver overnon-retrieval baselines and GPT-4. We thus provide the first set of open-sourceLLM-based theorem provers without any proprietary datasets and release it undera permissive MIT license to facilitate further research.</description><author>Kaiyu Yang, Aidan M. Swope, Alex Gu, Rahul Chalamala, Peiyang Song, Shixing Yu, Saad Godil, Ryan Prenger, Anima Anandkumar</author><pubDate>Fri, 27 Oct 2023 17:00:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15626v2</guid></item><item><title>Fast and Regret Optimal Best Arm Identification: Fundamental Limits and Low-Complexity Algorithms</title><link>http://arxiv.org/abs/2309.00591v2</link><description>This paper considers a stochastic Multi-Armed Bandit (MAB) problem with dualobjectives: (i) quick identification and commitment to the optimal arm, and(ii) reward maximization throughout a sequence of $T$ consecutive rounds.Though each objective has been individually well-studied, i.e., best armidentification for (i) and regret minimization for (ii), the simultaneousrealization of both objectives remains an open problem, despite its practicalimportance. This paper introduces \emph{Regret Optimal Best Arm Identification}(ROBAI) which aims to achieve these dual objectives. To solve ROBAI with bothpre-determined stopping time and adaptive stopping time requirements, wepresent an algorithm called EOCP and its variants respectively, which not onlyachieve asymptotic optimal regret in both Gaussian and general bandits, butalso commit to the optimal arm in $\mathcal{O}(\log T)$ rounds withpre-determined stopping time and $\mathcal{O}(\log^2 T)$ rounds with adaptivestopping time. We further characterize lower bounds on the commitment time(equivalent to the sample complexity) of ROBAI, showing that EOCP and itsvariants are sample optimal with pre-determined stopping time, and almostsample optimal with adaptive stopping time. Numerical results confirm ourtheoretical analysis and reveal an interesting "over-exploration" phenomenoncarried by classic UCB algorithms, such that EOCP has smaller regret eventhough it stops exploration much earlier than UCB, i.e., $\mathcal{O}(\log T)$versus $\mathcal{O}(T)$, which suggests over-exploration is unnecessary andpotentially harmful to system performance.</description><author>Qining Zhang, Lei Ying</author><pubDate>Fri, 27 Oct 2023 17:00:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.00591v2</guid></item><item><title>Causal Effect Identification in Uncertain Causal Networks</title><link>http://arxiv.org/abs/2208.04627v3</link><description>Causal identification is at the core of the causal inference literature,where complete algorithms have been proposed to identify causal queries ofinterest. The validity of these algorithms hinges on the restrictive assumptionof having access to a correctly specified causal structure. In this work, westudy the setting where a probabilistic model of the causal structure isavailable. Specifically, the edges in a causal graph exist with uncertaintieswhich may, for example, represent degree of belief from domain experts.Alternatively, the uncertainty about an edge may reflect the confidence of aparticular statistical test. The question that naturally arises in this settingis: Given such a probabilistic graph and a specific causal effect of interest,what is the subgraph which has the highest plausibility and for which thecausal effect is identifiable? We show that answering this question reduces tosolving an NP-complete combinatorial optimization problem which we call theedge ID problem. We propose efficient algorithms to approximate this problemand evaluate them against both real-world networks and randomly generatedgraphs.</description><author>Sina Akbari, Fateme Jamshidi, Ehsan Mokhtarian, Matthew J. Vowels, Jalal Etesami, Negar Kiyavash</author><pubDate>Fri, 27 Oct 2023 16:58:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.04627v3</guid></item><item><title>TBDLNet: a network for classifying multidrug-resistant and drug-sensitive tuberculosis</title><link>http://arxiv.org/abs/2310.18222v1</link><description>This paper proposes applying a novel deep-learning model, TBDLNet, torecognize CT images to classify multidrug-resistant and drug-sensitivetuberculosis automatically. The pre-trained ResNet50 is selected to extractfeatures. Three randomized neural networks are used to alleviate theoverfitting problem. The ensemble of three RNNs is applied to boost therobustness via majority voting. The proposed model is evaluated by five-foldcross-validation. Five indexes are selected in this paper, which are accuracy,sensitivity, precision, F1-score, and specificity. The TBDLNet achieves 0.9822accuracy, 0.9815 specificity, 0.9823 precision, 0.9829 sensitivity, and 0.9826F1-score, respectively. The TBDLNet is suitable for classifyingmultidrug-resistant tuberculosis and drug-sensitive tuberculosis. It can detectmultidrug-resistant pulmonary tuberculosis as early as possible, which helps toadjust the treatment plan in time and improve the treatment effect.</description><author>Ziquan Zhu, Jing Tao, Shuihua Wang, Xin Zhang, Yudong Zhang</author><pubDate>Fri, 27 Oct 2023 16:51:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18222v1</guid></item><item><title>Machine Reading Comprehension using Case-based Reasoning</title><link>http://arxiv.org/abs/2305.14815v2</link><description>We present an accurate and interpretable method for answer extraction inmachine reading comprehension that is reminiscent of case-based reasoning (CBR)from classical AI. Our method (CBR-MRC) builds upon the hypothesis thatcontextualized answers to similar questions share semantic similarities witheach other. Given a test question, CBR-MRC first retrieves a set of similarcases from a non-parametric memory and then predicts an answer by selecting thespan in the test context that is most similar to the contextualizedrepresentations of answers in the retrieved cases. The semi-parametric natureof our approach allows it to attribute a prediction to the specific set ofevidence cases, making it a desirable choice for building reliable anddebuggable QA systems. We show that CBR-MRC provides high accuracy comparablewith large reader models and outperforms baselines by 11.5 and 8.4 EM onNaturalQuestions and NewsQA, respectively. Further, we demonstrate the abilityof CBR-MRC in identifying not just the correct answer tokens but also the spanwith the most relevant supporting evidence. Lastly, we observe that contextsfor certain question types show higher lexical diversity than others and findthat CBR-MRC is robust to these variations while performance usingfully-parametric methods drops.</description><author>Dung Thai, Dhruv Agarwal, Mudit Chaudhary, Rajarshi Das, Manzil Zaheer, Jay-Yoon Lee, Hannaneh Hajishirzi, Andrew McCallum</author><pubDate>Fri, 27 Oct 2023 16:43:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14815v2</guid></item><item><title>One Model Fits All: Cross-Region Taxi-Demand Forecasting</title><link>http://arxiv.org/abs/2310.18215v1</link><description>The growing demand for ride-hailing services has led to an increasing needfor accurate taxi demand prediction. Existing systems are limited to specificregions, lacking generalizability to unseen areas. This paper presents a noveltaxi demand forecasting system that leverages a graph neural network to capturespatial dependencies and patterns in urban environments. Additionally, theproposed system employs a region-neutral approach, enabling it to train a modelthat can be applied to any region, including unseen regions. To achieve this,the framework incorporates the power of Variational Autoencoder to disentanglethe input features into region-specific and region-neutral components. Theregion-neutral features facilitate cross-region taxi demand predictions,allowing the model to generalize well across different urban areas.Experimental results demonstrate the effectiveness of the proposed system inaccurately forecasting taxi demand, even in previously unobserved regions, thusshowcasing its potential for optimizing taxi services and improvingtransportation efficiency on a broader scale.</description><author>Ren Ozeki, Haruki Yonekura, Aidana Baimbetova, Hamada Rizk, Hirozumi Yamaguchi</author><pubDate>Fri, 27 Oct 2023 16:42:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18215v1</guid></item><item><title>Language models show human-like content effects on reasoning tasks</title><link>http://arxiv.org/abs/2207.07051v2</link><description>Abstract reasoning is a key ability for an intelligent system. Large languagemodels (LMs) achieve above-chance performance on abstract reasoning tasks, butexhibit many imperfections. However, human abstract reasoning is alsoimperfect. For example, human reasoning is affected by our real-world knowledgeand beliefs, and shows notable "content effects"; humans reason more reliablywhen the semantic content of a problem supports the correct logical inferences.These content-entangled reasoning patterns play a central role in debates aboutthe fundamental nature of human intelligence. Here, we investigate whetherlanguage models $\unicode{x2014}$ whose prior expectations capture some aspectsof human knowledge $\unicode{x2014}$ similarly mix content into their answersto logical problems. We explored this question across three logical reasoningtasks: natural language inference, judging the logical validity of syllogisms,and the Wason selection task. We evaluate state of the art large languagemodels, as well as humans, and find that the language models reflect many ofthe same patterns observed in humans across these tasks $\unicode{x2014}$ likehumans, models answer more accurately when the semantic content of a tasksupports the logical inferences. These parallels are reflected both in answerpatterns, and in lower-level features like the relationship between modelanswer distributions and human response times. Our findings have implicationsfor understanding both these cognitive effects in humans, and the factors thatcontribute to language model performance.</description><author>Ishita Dasgupta, Andrew K. Lampinen, Stephanie C. Y. Chan, Hannah R. Sheahan Antonia Creswell, Dharshan Kumaran, James L. McClelland, Felix Hill</author><pubDate>Fri, 27 Oct 2023 16:35:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.07051v2</guid></item><item><title>Robustness of Algorithms for Causal Structure Learning to Hyperparameter Choice</title><link>http://arxiv.org/abs/2310.18212v1</link><description>Hyperparameters play a critical role in machine learning. Hyperparametertuning can make the difference between state-of-the-art and poor predictionperformance for any algorithm, but it is particularly challenging for structurelearning due to its unsupervised nature. As a result, hyperparameter tuning isoften neglected in favour of using the default values provided by a particularimplementation of an algorithm. While there have been numerous studies onperformance evaluation of causal discovery algorithms, how hyperparametersaffect individual algorithms, as well as the choice of the best algorithm for aspecific problem, has not been studied in depth before. This work addressesthis gap by investigating the influence of hyperparameters on causal structurelearning tasks. Specifically, we perform an empirical evaluation ofhyperparameter selection for some seminal learning algorithms on datasets ofvarying levels of complexity. We find that, while the choice of algorithmremains crucial to obtaining state-of-the-art performance, hyperparameterselection in ensemble settings strongly influences the choice of algorithm, inthat a poor choice of hyperparameters can lead to analysts using algorithmswhich do not give state-of-the-art performance for their data.</description><author>Damian Machlanski, Spyridon Samothrakis, Paul Clarke</author><pubDate>Fri, 27 Oct 2023 16:34:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18212v1</guid></item><item><title>Separate Anything You Describe</title><link>http://arxiv.org/abs/2308.05037v2</link><description>Language-queried audio source separation (LASS) is a new paradigm forcomputational auditory scene analysis (CASA). LASS aims to separate a targetsound from an audio mixture given a natural language query, which provides anatural and scalable interface for digital audio applications. Recent works onLASS, despite attaining promising separation performance on specific sources(e.g., musical instruments, limited classes of audio events), are unable toseparate audio concepts in the open domain. In this work, we introduceAudioSep, a foundation model for open-domain audio source separation withnatural language queries. We train AudioSep on large-scale multimodal datasetsand extensively evaluate its capabilities on numerous tasks including audioevent separation, musical instrument separation, and speech enhancement.AudioSep demonstrates strong separation performance and impressive zero-shotgeneralization ability using audio captions or text labels as queries,substantially outperforming previous audio-queried and language-queried soundseparation models. For reproducibility of this work, we will release the sourcecode, evaluation benchmark and pre-trained model at:https://github.com/Audio-AGI/AudioSep.</description><author>Xubo Liu, Qiuqiang Kong, Yan Zhao, Haohe Liu, Yi Yuan, Yuzhuo Liu, Rui Xia, Yuxuan Wang, Mark D. Plumbley, Wenwu Wang</author><pubDate>Fri, 27 Oct 2023 16:34:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05037v2</guid></item><item><title>Alignment and Outer Shell Isotropy for Hyperbolic Graph Contrastive Learning</title><link>http://arxiv.org/abs/2310.18209v1</link><description>Learning good self-supervised graph representations that are beneficial todownstream tasks is challenging. Among a variety of methods, contrastivelearning enjoys competitive performance. The embeddings of contrastive learningare arranged on a hypersphere that enables the Cosine distance measurement inthe Euclidean space. However, the underlying structure of many domains such asgraphs exhibits highly non-Euclidean latent geometry. To this end, we propose anovel contrastive learning framework to learn high-quality graph embedding.Specifically, we design the alignment metric that effectively captures thehierarchical data-invariant information, as well as we propose a substitute ofuniformity metric to prevent the so-called dimensional collapse. We show thatin the hyperbolic space one has to address the leaf- and height-leveluniformity which are related to properties of trees, whereas in the ambientspace of the hyperbolic manifold, these notions translate into imposing anisotropic ring density towards boundaries of Poincar\'e ball. This ring densitycan be easily imposed by promoting the isotropic feature distribution on thetangent space of manifold. In the experiments, we demonstrate the efficacy ofour proposed method across different hyperbolic graph embedding techniques inboth supervised and self-supervised learning settings.</description><author>Yifei Zhang, Hao Zhu, Jiahong Liu, Piotr Koniusz, Irwin King</author><pubDate>Fri, 27 Oct 2023 16:31:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18209v1</guid></item><item><title>ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models</title><link>http://arxiv.org/abs/2310.18208v1</link><description>Existing deep-learning approaches to semantic column type annotation (CTA)have important shortcomings: they rely on semantic types which are fixed attraining time; require a large number of training samples per type and incurlarge run-time inference costs; and their performance can degrade whenevaluated on novel datasets, even when types remain constant. Large languagemodels have exhibited strong zero-shot classification performance on a widerange of tasks and in this paper we explore their use for CTA. We introduceArcheType, a simple, practical method for context sampling, promptserialization, model querying, and label remapping, which enables largelanguage models to solve column type annotation problems in a fully zero-shotmanner. We ablate each component of our method separately, and establish thatimprovements to context sampling and label remapping provide the mostconsistent gains. ArcheType establishes new state-of-the-art performance onboth zero-shot and fine-tuned CTA, including three new domain-specificbenchmarks, which we release, along with the code to reproduce our results athttps://github.com/penfever/ArcheType.</description><author>Benjamin Feuer, Yurong Liu, Chinmay Hegde, Juliana Freire</author><pubDate>Fri, 27 Oct 2023 16:31:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18208v1</guid></item><item><title>INA: An Integrative Approach for Enhancing Negotiation Strategies with Reward-Based Dialogue System</title><link>http://arxiv.org/abs/2310.18207v1</link><description>In this paper, we propose a novel negotiation dialogue agent designed for theonline marketplace. Our agent is integrative in nature i.e, it possesses thecapability to negotiate on price as well as other factors, such as the additionor removal of items from a deal bundle, thereby offering a more flexible andcomprehensive negotiation experience. We create a new dataset calledIntegrative Negotiation Dataset (IND) to enable this functionality. For thisdataset creation, we introduce a new semi-automated data creation method, whichcombines defining negotiation intents, actions, and intent-action simulationbetween users and the agent to generate potential dialogue flows. Finally, theprompting of GPT-J, a state-of-the-art language model, is done to generatedialogues for a given intent, with a human-in-the-loop process for post-editingand refining minor errors to ensure high data quality. We employ a set of novelrewards, specifically tailored for the negotiation task to train ourNegotiation Agent, termed as the Integrative Negotiation Agent (INA). Theserewards incentivize the chatbot to learn effective negotiation strategies thatcan adapt to various contextual requirements and price proposals. By leveragingthe IND, we train our model and conduct experiments to evaluate theeffectiveness of our reward-based dialogue system for negotiation. Our resultsdemonstrate that the proposed approach and reward system significantly enhancethe agent's negotiation capabilities. The INA successfully engages inintegrative negotiations, displaying the ability to dynamically adjust pricesand negotiate the inclusion or exclusion of items in a bundle deal</description><author>Zishan Ahmad, Suman Saurabh, Vaishakh Sreekanth Menon, Asif Ekbal, Roshni Ramnani, Anutosh Maitra</author><pubDate>Fri, 27 Oct 2023 16:31:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18207v1</guid></item><item><title>Lost in Translation, Found in Spans: Identifying Claims in Multilingual Social Media</title><link>http://arxiv.org/abs/2310.18205v1</link><description>Claim span identification (CSI) is an important step in fact-checkingpipelines, aiming to identify text segments that contain a checkworthy claim orassertion in a social media post. Despite its importance to journalists andhuman fact-checkers, it remains a severely understudied problem, and the scarceresearch on this topic so far has only focused on English. Here we aim tobridge this gap by creating a novel dataset, X-CLAIM, consisting of 7Kreal-world claims collected from numerous social media platforms in five Indianlanguages and English. We report strong baselines with state-of-the-artencoder-only language models (e.g., XLM-R) and we demonstrate the benefits oftraining on multiple languages over alternative cross-lingual transfer methodssuch as zero-shot transfer, or training on translated data, from ahigh-resource language such as English. We evaluate generative large languagemodels from the GPT series using prompting methods on the X-CLAIM dataset andwe find that they underperform the smaller encoder-only language models forlow-resource languages.</description><author>Shubham Mittal, Megha Sundriyal, Preslav Nakov</author><pubDate>Fri, 27 Oct 2023 16:28:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18205v1</guid></item><item><title>Adaptive Webpage Fingerprinting from TLS Traces</title><link>http://arxiv.org/abs/2010.10294v2</link><description>In webpage fingerprinting, an on-path adversary infers the specific webpageloaded by a victim user by analysing the patterns in the encrypted TLS trafficexchanged between the user's browser and the website's servers. This workstudies modern webpage fingerprinting adversaries against the TLS protocol;aiming to shed light on their capabilities and inform potential defences.Despite the importance of this research area (the majority of global Internetusers rely on standard web browsing with TLS) and the potential real-lifeimpact, most past works have focused on attacks specific to anonymity networks(e.g., Tor). We introduce a TLS-specific model that: 1) scales to anunprecedented number of target webpages, 2) can accurately classify thousandsof classes it never encountered during training, and 3) has low operationalcosts even in scenarios of frequent page updates. Based on these findings, wethen discuss TLS-specific countermeasures and evaluate the effectiveness of theexisting padding capabilities provided by TLS 1.3.</description><author>Vasilios Mavroudis, Jamie Hayes</author><pubDate>Fri, 27 Oct 2023 16:26:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2010.10294v2</guid></item><item><title>Exploring Chain-of-Thought Style Prompting for Text-to-SQL</title><link>http://arxiv.org/abs/2305.14215v2</link><description>In-context learning with large language models (LLMs) has recently caughtincreasing attention due to its superior few-shot performance on various tasks.However, its performance on text-to-SQL parsing still has much room forimprovement. In this paper, we hypothesize that a crucial aspect of LLMs toimprove for text-to-SQL parsing is their multi-step reasoning ability. Thus, wesystematically study how to enhance LLMs' reasoning ability through chain ofthought (CoT) style prompting, including the original chain-of-thoughtprompting (Wei et al., 2022b) and least-to-most prompting (Zhou et al., 2023).Our experiments demonstrate that iterative prompting as in Zhou et al. (2023)may be unnecessary for text-to-SQL parsing, and using detailed reasoning stepstends to have more error propagation issues. Based on these findings, wepropose a new CoT-style prompting method for text-to-SQL parsing. It brings 5.2and 6.5 point absolute gains on the Spider development set and the SpiderRealistic set, respectively, compared to the standard prompting method withoutreasoning steps; 2.4 and 1.5 point absolute gains, compared to theleast-to-most prompting method.</description><author>Chang-You Tai, Ziru Chen, Tianshu Zhang, Xiang Deng, Huan Sun</author><pubDate>Fri, 27 Oct 2023 16:21:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14215v2</guid></item><item><title>MetaBox: A Benchmark Platform for Meta-Black-Box Optimization with Reinforcement Learning</title><link>http://arxiv.org/abs/2310.08252v2</link><description>Recently, Meta-Black-Box Optimization with Reinforcement Learning(MetaBBO-RL) has showcased the power of leveraging RL at the meta-level tomitigate manual fine-tuning of low-level black-box optimizers. However, thisfield is hindered by the lack of a unified benchmark. To fill this gap, weintroduce MetaBox, the first benchmark platform expressly tailored fordeveloping and evaluating MetaBBO-RL methods. MetaBox offers a flexiblealgorithmic template that allows users to effortlessly implement their uniquedesigns within the platform. Moreover, it provides a broad spectrum of over 300problem instances, collected from synthetic to realistic scenarios, and anextensive library of 19 baseline methods, including both traditional black-boxoptimizers and recent MetaBBO-RL methods. Besides, MetaBox introduces threestandardized performance metrics, enabling a more thorough assessment of themethods. In a bid to illustrate the utility of MetaBox for facilitatingrigorous evaluation and in-depth analysis, we carry out a wide-rangingbenchmarking study on existing MetaBBO-RL methods. Our MetaBox is open-sourceand accessible at: https://github.com/GMC-DRL/MetaBox.</description><author>Zeyuan Ma, Hongshu Guo, Jiacheng Chen, Zhenrui Li, Guojun Peng, Yue-Jiao Gong, Yining Ma, Zhiguang Cao</author><pubDate>Fri, 27 Oct 2023 16:19:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08252v2</guid></item><item><title>Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds</title><link>http://arxiv.org/abs/2306.06836v2</link><description>While numerous works have focused on devising efficient algorithms forreinforcement learning (RL) with uniformly bounded rewards, it remains an openquestion whether sample or time-efficient algorithms for RL with largestate-action space exist when the rewards are \emph{heavy-tailed}, i.e., withonly finite $(1+\epsilon)$-th moments for some $\epsilon\in(0,1]$. In thiswork, we address the challenge of such rewards in RL with linear functionapproximation. We first design an algorithm, \textsc{Heavy-OFUL}, forheavy-tailed linear bandits, achieving an \emph{instance-dependent} $T$-roundregret of $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$, the\emph{first} of this kind. Here, $d$ is the feature dimension, and$\nu_t^{1+\epsilon}$ is the $(1+\epsilon)$-th central moment of the reward atthe $t$-th round. We further show the above bound is minimax optimal whenapplied to the worst-case instances in stochastic and deterministic linearbandits. We then extend this algorithm to the RL settings with linear functionapproximation. Our algorithm, termed as \textsc{Heavy-LSVI-UCB}, achieves the\emph{first} computationally efficient \emph{instance-dependent} $K$-episoderegret of $\tilde{O}(d \sqrt{H \mathcal{U}^*} K^\frac{1}{1+\epsilon} + d\sqrt{H \mathcal{V}^* K})$. Here, $H$ is length of the episode, and$\mathcal{U}^*, \mathcal{V}^*$ are instance-dependent quantities scaling withthe central moment of reward and value functions, respectively. We also providea matching minimax lower bound $\Omega(d H K^{\frac{1}{1+\epsilon}} + d\sqrt{H^3 K})$ to demonstrate the optimality of our algorithm in the worstcase. Our result is achieved via a novel robust self-normalized concentrationinequality that may be of independent interest in handling heavy-tailed noisein general online regression problems.</description><author>Jiayi Huang, Han Zhong, Liwei Wang, Lin F. Yang</author><pubDate>Fri, 27 Oct 2023 16:19:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06836v2</guid></item><item><title>Quantifying the Cost of Learning in Queueing Systems</title><link>http://arxiv.org/abs/2308.07817v2</link><description>Queueing systems are widely applicable stochastic models with use cases incommunication networks, healthcare, service systems, etc. Although theiroptimal control has been extensively studied, most existing approaches assumeperfect knowledge of the system parameters. Of course, this assumption rarelyholds in practice where there is parameter uncertainty, thus motivating arecent line of work on bandit learning for queueing systems. This nascentstream of research focuses on the asymptotic performance of the proposedalgorithms. In this paper, we argue that an asymptotic metric, which focuses onlate-stage performance, is insufficient to capture the intrinsic statisticalcomplexity of learning in queueing systems which typically occurs in the earlystage. Instead, we propose the Cost of Learning in Queueing (CLQ), a new metricthat quantifies the maximum increase in time-averaged queue length caused byparameter uncertainty. We characterize the CLQ of a single queue multi-serversystem, and then extend these results to multi-queue multi-server systems andnetworks of queues. In establishing our results, we propose a unified analysisframework for CLQ that bridges Lyapunov and bandit analysis, providesguarantees for a wide range of algorithms, and could be of independentinterest.</description><author>Daniel Freund, Thodoris Lykouris, Wentao Weng</author><pubDate>Fri, 27 Oct 2023 16:18:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07817v2</guid></item><item><title>Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action Recognition</title><link>http://arxiv.org/abs/2307.06947v4</link><description>Recent video recognition models utilize Transformer models for long-rangespatio-temporal context modeling. Video transformer designs are based onself-attention that can model global context at a high computational cost. Incomparison, convolutional designs for videos offer an efficient alternative butlack long-range dependency modeling. Towards achieving the best of bothdesigns, this work proposes Video-FocalNet, an effective and efficientarchitecture for video recognition that models both local and global contexts.Video-FocalNet is based on a spatio-temporal focal modulation architecture thatreverses the interaction and aggregation steps of self-attention for betterefficiency. Further, the aggregation step and the interaction step are bothimplemented using efficient convolution and element-wise multiplicationoperations that are computationally less expensive than their self-attentioncounterparts on video representations. We extensively explore the design spaceof focal modulation-based spatio-temporal context modeling and demonstrate ourparallel spatial and temporal encoding design to be the optimal choice.Video-FocalNets perform favorably well against the state-of-the-arttransformer-based models for video recognition on five large-scale datasets(Kinetics-400, Kinetics-600, SS-v2, Diving-48, and ActivityNet-1.3) at a lowercomputational cost. Our code/models are released athttps://github.com/TalalWasim/Video-FocalNets.</description><author>Syed Talal Wasim, Muhammad Uzair Khattak, Muzammal Naseer, Salman Khan, Mubarak Shah, Fahad Shahbaz Khan</author><pubDate>Fri, 27 Oct 2023 16:16:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.06947v4</guid></item><item><title>High-performance real-world optical computing trained by in situ model-free optimization</title><link>http://arxiv.org/abs/2307.11957v2</link><description>Optical computing systems can provide high-speed and low-energy dataprocessing but face deficiencies in computationally demanding training andsimulation-to-reality gap. We propose a model-free solution for lightweight insitu optimization of optical computing systems based on the score gradientestimation algorithm. This approach treats the system as a black box andback-propagates loss directly to the optical weights' probabilisticdistributions, hence circumventing the need for computation-heavy and biasedsystem simulation. We demonstrate a superior classification accuracy on theMNIST and FMNIST datasets through experiments on a single-layer diffractiveoptical computing system. Furthermore, we show its potential for image-free andhigh-speed cell analysis. The inherent simplicity of our proposed method,combined with its low demand for computational resources, expedites thetransition of optical computing from laboratory demonstrations to real-worldapplications.</description><author>Guangyuan Zhao, Xin Shu</author><pubDate>Fri, 27 Oct 2023 16:16:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11957v2</guid></item><item><title>DUBLIN -- Document Understanding By Language-Image Network</title><link>http://arxiv.org/abs/2305.14218v4</link><description>Visual document understanding is a complex task that involves analyzing boththe text and the visual elements in document images. Existing models often relyon manual feature engineering or domain-specific pipelines, which limit theirgeneralization ability across different document types and languages. In thispaper, we propose DUBLIN, which is pretrained on web pages using three novelobjectives: Masked Document Text Generation Task, Bounding Box Task, andRendered Question Answering Task, that leverage both the spatial and semanticinformation in the document images. Our model achieves competitive orstate-of-the-art results on several benchmarks, such as Web-Based StructuralReading Comprehension, Document Visual Question Answering, Key InformationExtraction, Diagram Understanding, and Table Question Answering. In particular,we show that DUBLIN is the first pixel-based model to achieve an EM of 77.75and F1 of 84.25 on the WebSRC dataset. We also show that our model outperformsthe current pixel-based SOTA models on DocVQA, InfographicsVQA, OCR-VQA andAI2D datasets by 4.6%, 6.5%, 2.6% and 21%, respectively. We also achievecompetitive performance on RVL-CDIP document classification. Moreover, wecreate new baselines for text-based datasets by rendering them as documentimages to promote research in this direction.</description><author>Kriti Aggarwal, Aditi Khandelwal, Kumar Tanmay, Owais Mohammed Khan, Qiang Liu, Monojit Choudhury, Hardik Hansrajbhai Chauhan, Subhojit Som, Vishrav Chaudhary, Saurabh Tiwary</author><pubDate>Fri, 27 Oct 2023 16:08:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14218v4</guid></item><item><title>Artifact-Robust Graph-Based Learning in Digital Pathology</title><link>http://arxiv.org/abs/2310.18192v1</link><description>Whole slide images~(WSIs) are digitized images of tissues placed in glassslides using advanced scanners. The digital processing of WSIs is challengingas they are gigapixel images and stored in multi-resolution format. A commonchallenge with WSIs is that perturbations/artifacts are inevitable duringstoring the glass slides and digitizing them. These perturbations includemotion, which often arises from slide movement during placement, and changes inhue and brightness due to variations in staining chemicals and the quality ofdigitizing scanners. In this work, a novel robust learning approach to accountfor these artifacts is presented. Due to the size and resolution of WSIs and toaccount for neighborhood information, graph-based methods are called for. Weuse graph convolutional network~(GCN) to extract features from the graphrepresenting WSI. Through a denoiser {and pooling layer}, the effects ofperturbations in WSIs are controlled and the output is followed by atransformer for the classification of different grades of prostate cancer. Tocompare the efficacy of the proposed approach, the model without denoiser istrained and tested with WSIs without any perturbation and then differentperturbations are introduced in WSIs and passed through the network with thedenoiser. The accuracy and kappa scores of the proposed model with prostatecancer dataset compared with non-robust algorithms show significant improvementin cancer diagnosis.</description><author>Saba Heidari Gheshlaghi, Milan Aryal, Nasim Yahyasoltani, Masoud Ganji</author><pubDate>Fri, 27 Oct 2023 16:06:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18192v1</guid></item><item><title>Is Scaling Learned Optimizers Worth It? Evaluating The Value of VeLO's 4000 TPU Months</title><link>http://arxiv.org/abs/2310.18191v1</link><description>We analyze VeLO (versatile learned optimizer), the largest scale attempt totrain a general purpose "foundational" optimizer to date. VeLO was trained onthousands of machine learning tasks using over 4000 TPU months with the goal ofproducing an optimizer capable of generalizing to new problems while beinghyperparameter free, and outperforming industry standards such as Adam. Weindependently evaluate VeLO on the MLCommons optimizer benchmark suite. We findthat, contrary to initial claims: (1) VeLO has a critical hyperparameter thatneeds problem-specific tuning, (2) VeLO does not necessarily outperformcompetitors in quality of solution found, and (3) VeLO is not faster thancompeting optimizers at reducing the training loss. These observations callinto question VeLO's generality and the value of the investment in training it.</description><author>Fady Rezk, Antreas Antoniou, Henry Gouk, Timothy Hospedales</author><pubDate>Fri, 27 Oct 2023 16:04:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18191v1</guid></item><item><title>Kernelized Back-Projection Networks for Blind Super Resolution</title><link>http://arxiv.org/abs/2302.08478v3</link><description>Since non-blind Super Resolution (SR) fails to super-resolve Low-Resolution(LR) images degraded by arbitrary degradations, SR with the degradation modelis required. However, this paper reveals that non-blind SR that is trainedsimply with various blur kernels exhibits comparable performance as those withthe degradation model for blind SR. This result motivates us to revisithigh-performance non-blind SR and extend it to blind SR with blur kernels. Thispaper proposes two SR networks by integrating kernel estimation and SR branchesin an iterative end-to-end manner. In the first model, which is called theKernel Conditioned Back-Projection Network (KCBPN), the low-dimensional kernelrepresentations are estimated for conditioning the SR branch. In our secondmodel, the Kernelized BackProjection Network (KBPN), a raw kernel is estimatedand directly employed for modeling the image degradation. The estimated kernelis employed not only for back-propagating its residual but also forforward-propagating the residual to iterative stages. This forward-propagationencourages these stages to learn a variety of different features in differentstages by focusing on pixels with large residuals in each stage. Experimentalresults validate the effectiveness of our proposed networks for kernelestimation and SR. We will release the code for this work.</description><author>Tomoki Yoshida, Yuki Kondo, Takahiro Maeda, Kazutoshi Akita, Norimichi Ukita</author><pubDate>Fri, 27 Oct 2023 16:03:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08478v3</guid></item><item><title>Model-free Posterior Sampling via Learning Rate Randomization</title><link>http://arxiv.org/abs/2310.18186v1</link><description>In this paper, we introduce Randomized Q-learning (RandQL), a novelrandomized model-free algorithm for regret minimization in episodic MarkovDecision Processes (MDPs). To the best of our knowledge, RandQL is the firsttractable model-free posterior sampling-based algorithm. We analyze theperformance of RandQL in both tabular and non-tabular metric space settings. Intabular MDPs, RandQL achieves a regret bound of order$\widetilde{\mathcal{O}}(\sqrt{H^{5}SAT})$, where $H$ is the planning horizon,$S$ is the number of states, $A$ is the number of actions, and $T$ is thenumber of episodes. For a metric state-action space, RandQL enjoys a regretbound of order $\widetilde{\mathcal{O}}(H^{5/2} T^{(d_z+1)/(d_z+2)})$, where$d_z$ denotes the zooming dimension. Notably, RandQL achieves optimisticexploration without using bonuses, relying instead on a novel idea of learningrate randomization. Our empirical study shows that RandQL outperforms existingapproaches on baseline exploration environments.</description><author>Daniil Tiapkin, Denis Belomestny, Daniele Calandriello, Eric Moulines, Remi Munos, Alexey Naumov, Pierre Perrault, Michal Valko, Pierre Menard</author><pubDate>Fri, 27 Oct 2023 15:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18186v1</guid></item><item><title>Reliable Off-Policy Learning for Dosage Combinations</title><link>http://arxiv.org/abs/2305.19742v2</link><description>Decision-making in personalized medicine such as cancer therapy or criticalcare must often make choices for dosage combinations, i.e., multiple continuoustreatments. Existing work for this task has modeled the effect of multipletreatments independently, while estimating the joint effect has received littleattention but comes with non-trivial challenges. In this paper, we propose anovel method for reliable off-policy learning for dosage combinations. Ourmethod proceeds along three steps: (1) We develop a tailored neural networkthat estimates the individualized dose-response function while accounting forthe joint effect of multiple dependent dosages. (2) We estimate the generalizedpropensity score using conditional normalizing flows in order to detect regionswith limited overlap in the shared covariate-treatment space. (3) We present agradient-based learning algorithm to find the optimal, individualized dosagecombinations. Here, we ensure reliable estimation of the policy value byavoiding regions with limited overlap. We finally perform an extensiveevaluation of our method to show its effectiveness. To the best of ourknowledge, ours is the first work to provide a method for reliable off-policylearning for optimal dosage combinations.</description><author>Jonas Schweisthal, Dennis Frauen, Valentyn Melnychuk, Stefan Feuerriegel</author><pubDate>Fri, 27 Oct 2023 15:48:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19742v2</guid></item><item><title>Minimum Bayes' Risk Decoding for System Combination of Grammatical Error Correction Systems</title><link>http://arxiv.org/abs/2309.06520v2</link><description>For sequence-to-sequence tasks it is challenging to combine individual systemoutputs. Further, there is also often a mismatch between the decoding criterionand the one used for assessment. Minimum Bayes' Risk (MBR) decoding can be usedto combine system outputs in a manner that encourages better alignment with thefinal assessment criterion. This paper examines MBR decoding for GrammaticalError Correction (GEC) systems, where performance is usually evaluated in termsof edits and an associated F-score. Hence, we propose a novel MBR loss functiondirectly linked to this form of criterion. Furthermore, an approach to expandthe possible set of candidate sentences is described. This builds on a currentmax-voting combination scheme, as well as individual edit-level selection.Experiments on three popular GEC datasets and with state-of-the-art GEC systemsdemonstrate the efficacy of the proposed MBR approach. Additionally, the paperhighlights how varying reward metrics within the MBR decoding framework canprovide control over precision, recall, and the F-score in combined GECsystems.</description><author>Vyas Raina, Mark Gales</author><pubDate>Fri, 27 Oct 2023 15:42:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06520v2</guid></item><item><title>Generalized Neural Collapse for a Large Number of Classes</title><link>http://arxiv.org/abs/2310.05351v3</link><description>Neural collapse provides an elegant mathematical characterization of learnedlast layer representations (a.k.a. features) and classifier weights in deepclassification models. Such results not only provide insights but also motivatenew techniques for improving practical deep models. However, most of theexisting empirical and theoretical studies in neural collapse focus on the casethat the number of classes is small relative to the dimension of the featurespace. This paper extends neural collapse to cases where the number of classesare much larger than the dimension of feature space, which broadly occur forlanguage models, retrieval systems, and face recognition applications. We showthat the features and classifier exhibit a generalized neural collapsephenomenon, where the minimum one-vs-rest margins is maximized.We provideempirical study to verify the occurrence of generalized neural collapse inpractical deep neural networks. Moreover, we provide theoretical study to showthat the generalized neural collapse provably occurs under unconstrainedfeature model with spherical constraint, under certain technical conditions onfeature dimension and number of classes.</description><author>Jiachen Jiang, Jinxin Zhou, Peng Wang, Qing Qu, Dustin Mixon, Chong You, Zhihui Zhu</author><pubDate>Fri, 27 Oct 2023 15:35:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05351v3</guid></item><item><title>HyperFields: Towards Zero-Shot Generation of NeRFs from Text</title><link>http://arxiv.org/abs/2310.17075v2</link><description>We introduce HyperFields, a method for generating text-conditioned NeuralRadiance Fields (NeRFs) with a single forward pass and (optionally) somefine-tuning. Key to our approach are: (i) a dynamic hypernetwork, which learnsa smooth mapping from text token embeddings to the space of NeRFs; (ii) NeRFdistillation training, which distills scenes encoded in individual NeRFs intoone dynamic hypernetwork. These techniques enable a single network to fit overa hundred unique scenes. We further demonstrate that HyperFields learns a moregeneral map between text and NeRFs, and consequently is capable of predictingnovel in-distribution and out-of-distribution scenes -- either zero-shot orwith a few finetuning steps. Finetuning HyperFields benefits from acceleratedconvergence thanks to the learned general map, and is capable of synthesizingnovel scenes 5 to 10 times faster than existing neural optimization-basedmethods. Our ablation experiments show that both the dynamic architecture andNeRF distillation are critical to the expressivity of HyperFields.</description><author>Sudarshan Babu, Richard Liu, Avery Zhou, Michael Maire, Greg Shakhnarovich, Rana Hanocka</author><pubDate>Fri, 27 Oct 2023 15:35:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17075v2</guid></item><item><title>Deep Contract Design via Discontinuous Networks</title><link>http://arxiv.org/abs/2307.02318v2</link><description>Contract design involves a principal who establishes contractual agreementsabout payments for outcomes that arise from the actions of an agent. In thispaper, we initiate the study of deep learning for the automated design ofoptimal contracts. We introduce a novel representation: the Discontinuous ReLU(DeLU) network, which models the principal's utility as a discontinuouspiecewise affine function of the design of a contract where each piececorresponds to the agent taking a particular action. DeLU networks implicitlylearn closed-form expressions for the incentive compatibility constraints ofthe agent and the utility maximization objective of the principal, and supportparallel inference on each piece through linear programming or interior-pointmethods that solve for optimal contracts. We provide empirical results thatdemonstrate success in approximating the principal's utility function with asmall number of training samples and scaling to find approximately optimalcontracts on problems with a large number of actions and outcomes.</description><author>Tonghan Wang, Paul Dütting, Dmitry Ivanov, Inbal Talgam-Cohen, David C. Parkes</author><pubDate>Fri, 27 Oct 2023 15:31:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02318v2</guid></item><item><title>Implicit Convolutional Kernels for Steerable CNNs</title><link>http://arxiv.org/abs/2212.06096v3</link><description>Steerable convolutional neural networks (CNNs) provide a general frameworkfor building neural networks equivariant to translations and transformations ofan origin-preserving group $G$, such as reflections and rotations. They rely onstandard convolutions with $G$-steerable kernels obtained by analyticallysolving the group-specific equivariance constraint imposed onto the kernelspace. As the solution is tailored to a particular group $G$, implementing akernel basis does not generalize to other symmetry transformations,complicating the development of general group equivariant models. We proposeusing implicit neural representation via multi-layer perceptrons (MLPs) toparameterize $G$-steerable kernels. The resulting framework offers a simple andflexible way to implement Steerable CNNs and generalizes to any group $G$ forwhich a $G$-equivariant MLP can be built. We prove the effectiveness of ourmethod on multiple tasks, including N-body simulations, point cloudclassification and molecular property prediction.</description><author>Maksim Zhdanov, Nico Hoffmann, Gabriele Cesa</author><pubDate>Fri, 27 Oct 2023 15:31:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.06096v3</guid></item><item><title>Human-Guided Complexity-Controlled Abstractions</title><link>http://arxiv.org/abs/2310.17550v2</link><description>Neural networks often learn task-specific latent representations that fail togeneralize to novel settings or tasks. Conversely, humans learn discreterepresentations (i.e., concepts or words) at a variety of abstraction levels(e.g., "bird" vs. "sparrow") and deploy the appropriate abstraction based ontask. Inspired by this, we train neural models to generate a spectrum ofdiscrete representations, and control the complexity of the representations(roughly, how many bits are allocated for encoding inputs) by tuning theentropy of the distribution over representations. In finetuning experiments,using only a small number of labeled examples for a new task, we show that (1)tuning the representation to a task-appropriate complexity level supports thehighest finetuning performance, and (2) in a human-participant study, userswere able to identify the appropriate complexity level for a downstream taskusing visualizations of discrete representations. Our results indicate apromising direction for rapid model finetuning by leveraging human insight.</description><author>Andi Peng, Mycal Tucker, Eoin Kenny, Noga Zaslavsky, Pulkit Agrawal, Julie Shah</author><pubDate>Fri, 27 Oct 2023 15:31:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17550v2</guid></item><item><title>IMP-MARL: a Suite of Environments for Large-scale Infrastructure Management Planning via MARL</title><link>http://arxiv.org/abs/2306.11551v2</link><description>We introduce IMP-MARL, an open-source suite of multi-agent reinforcementlearning (MARL) environments for large-scale Infrastructure Management Planning(IMP), offering a platform for benchmarking the scalability of cooperative MARLmethods in real-world engineering applications. In IMP, a multi-componentengineering system is subject to a risk of failure due to its components'damage condition. Specifically, each agent plans inspections and repairs for aspecific system component, aiming to minimise maintenance costs whilecooperating to minimise system failure risk. With IMP-MARL, we release severalenvironments including one related to offshore wind structural systems, in aneffort to meet today's needs to improve management strategies to supportsustainable and reliable energy systems. Supported by IMP practical engineeringenvironments featuring up to 100 agents, we conduct a benchmark campaign, wherethe scalability and performance of state-of-the-art cooperative MARL methodsare compared against expert-based heuristic policies. The results reveal thatcentralised training with decentralised execution methods scale better with thenumber of agents than fully centralised or decentralised RL approaches, whilealso outperforming expert-based heuristic policies in most IMP environments.Based on our findings, we additionally outline remaining cooperation andscalability challenges that future MARL methods should still address. ThroughIMP-MARL, we encourage the implementation of new environments and the furtherdevelopment of MARL methods.</description><author>Pascal Leroy, Pablo G. Morato, Jonathan Pisane, Athanasios Kolios, Damien Ernst</author><pubDate>Fri, 27 Oct 2023 15:29:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11551v2</guid></item><item><title>Style Description based Text-to-Speech with Conditional Prosodic Layer Normalization based Diffusion GAN</title><link>http://arxiv.org/abs/2310.18169v1</link><description>In this paper, we present a Diffusion GAN based approach (Prosodic Diff-TTS)to generate the corresponding high-fidelity speech based on the styledescription and content text as an input to generate speech samples within only4 denoising steps. It leverages the novel conditional prosodic layernormalization to incorporate the style embeddings into the multi head attentionbased phoneme encoder and mel spectrogram decoder based generator architectureto generate the speech. The style embedding is generated by fine tuning thepretrained BERT model on auxiliary tasks such as pitch, speaking speed,emotion,gender classifications. We demonstrate the efficacy of our proposedarchitecture on multi-speaker LibriTTS and PromptSpeech datasets, usingmultiple quantitative metrics that measure generated accuracy and MOS.</description><author>Neeraj Kumar, Ankur Narang, Brejesh Lall</author><pubDate>Fri, 27 Oct 2023 15:28:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18169v1</guid></item><item><title>Personas as a Way to Model Truthfulness in Language Models</title><link>http://arxiv.org/abs/2310.18168v1</link><description>Large Language Models are trained on vast amounts of text from the internet,which contains both factual and misleading information about the world. Canlanguage models discern truth from falsehood in this contradicting data?Expanding on the view that LLMs can model different agents producing thecorpora, we hypothesize that they can cluster truthful text by modeling atruthful persona: a group of agents that are likely to produce truthful textand share similar features. For example, trustworthy sources like Wikipedia andScience usually use formal writing styles and make consistent claims. Bymodeling this persona, LLMs can generalize truthfulness beyond the specificcontexts in which each agent generated the training text. For example, themodel can infer that the agent "Wikipedia" will behave truthfully on topicsthat were only generated by "Science" because they share a persona. We firstshow evidence for the persona hypothesis via two observations: (1) we can probewhether a model's answer will be truthful before it is generated; (2)finetuning a model on a set of facts improves its truthfulness on unseentopics. Next, using arithmetics as a synthetic environment, we show thatlanguage models can separate true and false statements, and generalizetruthfulness across agents; but only if agents in the training data share atruthful generative process that enables the creation of a truthful persona.Overall, our findings suggest that models can exploit hierarchical structuresin the data to learn abstract concepts like truthfulness.</description><author>Nitish Joishi, Javier Rando, Abulhair Saparov, Najoung Kim, He He</author><pubDate>Fri, 27 Oct 2023 15:27:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18168v1</guid></item><item><title>Android in the Wild: A Large-Scale Dataset for Android Device Control</title><link>http://arxiv.org/abs/2307.10088v2</link><description>There is a growing interest in device-control systems that can interprethuman natural language instructions and execute them on a digital device bydirectly controlling its user interface. We present a dataset fordevice-control research, Android in the Wild (AITW), which is orders ofmagnitude larger than current datasets. The dataset contains humandemonstrations of device interactions, including the screens and actions, andcorresponding natural language instructions. It consists of 715k episodesspanning 30k unique instructions, four versions of Android (v10-13),and eightdevice types (Pixel 2 XL to Pixel 6) with varying screen resolutions. Itcontains multi-step tasks that require semantic understanding of language andvisual context. This dataset poses a new challenge: actions available throughthe user interface must be inferred from their visual appearance. And, insteadof simple UI element-based actions, the action space consists of precisegestures (e.g., horizontal scrolls to operate carousel widgets). We organizeour dataset to encourage robustness analysis of device-control systems, i.e.,how well a system performs in the presence of new task descriptions, newapplications, or new platform versions. We develop two agents and reportperformance across the dataset. The dataset is available athttps://github.com/google-research/google-research/tree/master/android_in_the_wild.</description><author>Christopher Rawles, Alice Li, Daniel Rodriguez, Oriana Riva, Timothy Lillicrap</author><pubDate>Fri, 27 Oct 2023 15:24:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10088v2</guid></item><item><title>MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension</title><link>http://arxiv.org/abs/2310.18167v1</link><description>The large language models have achieved superior performance on variousnatural language tasks. One major drawback of such approaches is they areresource-intensive in fine-tuning new datasets. Soft-prompt tuning presents aresource-efficient solution to fine-tune the pre-trained language models (PLMs)while keeping their weight frozen. Existing soft prompt methods mainly focus ondesigning the input-independent prompts that steer the model to fit the domainof the new dataset. Those methods often ignore the fine-grained informationabout the task and context of the text. In this paper, we propose a multi-levelprompt tuning (MPrompt) method for machine reading comprehension. It utilizesprompts at task-specific, domain-specific, and context-specific levels toenhance the comprehension of input semantics at different granularities. Wealso propose an independence constraint to steer each domain-specific prompt tofocus on information within its domain to avoid redundancy. Moreover, wepresent a prompt generator that incorporates context-related knowledge in theprompt generation to enhance contextual relevancy. We conducted extensiveexperiments on 12 benchmarks of various QA formats and achieved an averageimprovement of 1.94\% over the state-of-the-art methods.</description><author>Guoxin Chen, Yiming Qian, Bowen Wang, Liangzhi Li</author><pubDate>Fri, 27 Oct 2023 15:24:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18167v1</guid></item><item><title>Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review</title><link>http://arxiv.org/abs/2310.14735v2</link><description>This paper delves into the pivotal role of prompt engineering in unleashingthe capabilities of Large Language Models (LLMs). Prompt engineering is theprocess of structuring input text for LLMs and is a technique integral tooptimizing the efficacy of LLMs. This survey elucidates foundational principlesof prompt engineering, such as role-prompting, one-shot, and few-shotprompting, as well as more advanced methodologies such as the chain-of-thoughtand tree-of-thoughts prompting. The paper sheds light on how externalassistance in the form of plugins can assist in this task, and reduce machinehallucination by retrieving external knowledge. We subsequently delineateprospective directions in prompt engineering research, emphasizing the need fora deeper understanding of structures and the role of agents in ArtificialIntelligence-Generated Content (AIGC) tools. We discuss how to assess theefficacy of prompt methods from different perspectives and using differentmethods. Finally, we gather information about the application of promptengineering in such fields as education and programming, showing itstransformative potential. This comprehensive survey aims to serve as a friendlyguide for anyone venturing through the big world of LLMs and promptengineering.</description><author>Banghao Chen, Zhaofeng Zhang, Nicolas Langrené, Shengxin Zhu</author><pubDate>Fri, 27 Oct 2023 15:22:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14735v2</guid></item><item><title>FAMO: Fast Adaptive Multitask Optimization</title><link>http://arxiv.org/abs/2306.03792v2</link><description>One of the grand enduring goals of AI is to create generalist agents that canlearn multiple different tasks from diverse data via multitask learning (MTL).However, in practice, applying gradient descent (GD) on the average loss acrossall tasks may yield poor multitask performance due to severe under-optimizationof certain tasks. Previous approaches that manipulate task gradients for a morebalanced loss decrease require storing and computing all task gradients($\mathcal{O}(k)$ space and time where $k$ is the number of tasks), limitingtheir use in large-scale scenarios. In this work, we introduce Fast AdaptiveMultitask Optimization FAMO, a dynamic weighting method that decreases tasklosses in a balanced way using $\mathcal{O}(1)$ space and time. We conduct anextensive set of experiments covering multi-task supervised and reinforcementlearning problems. Our results indicate that FAMO achieves comparable orsuperior performance to state-of-the-art gradient manipulation techniques whileoffering significant improvements in space and computational efficiency. Codeis available at \url{https://github.com/Cranial-XIX/FAMO}.</description><author>Bo Liu, Yihao Feng, Peter Stone, Qiang Liu</author><pubDate>Fri, 27 Oct 2023 15:20:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03792v2</guid></item><item><title>Analyzing the Sample Complexity of Self-Supervised Image Reconstruction Methods</title><link>http://arxiv.org/abs/2305.19079v2</link><description>Supervised training of deep neural networks on pairs of clean image and noisymeasurement achieves state-of-the-art performance for many image reconstructiontasks, but such training pairs are difficult to collect. Self-supervisedmethods enable training based on noisy measurements only, without clean images.In this work, we investigate the cost of self-supervised training in terms ofsample complexity for a class of self-supervised methods that enable thecomputation of unbiased estimates of gradients of the supervised loss,including noise2noise methods. We analytically show that a model trained withsuch self-supervised training is as good as the same model trained in asupervised fashion, but self-supervised training requires more examples thansupervised training. We then study self-supervised denoising and acceleratedMRI empirically and characterize the cost of self-supervised training in termsof the number of additional samples required, and find that the performance gapbetween self-supervised and supervised training vanishes as a function of thetraining examples, at a problem-dependent rate, as predicted by our theory.</description><author>Tobit Klug, Dogukan Atik, Reinhard Heckel</author><pubDate>Fri, 27 Oct 2023 15:18:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19079v2</guid></item><item><title>Enhancing Enterprise Network Security: Comparing Machine-Level and Process-Level Analysis for Dynamic Malware Detection</title><link>http://arxiv.org/abs/2310.18165v1</link><description>Analysing malware is important to understand how malicious software works andto develop appropriate detection and prevention methods. Dynamic analysis canovercome evasion techniques commonly used to bypass static analysis and provideinsights into malware runtime activities. Much research on dynamic analysisfocused on investigating machine-level information (e.g., CPU, memory, networkusage) to identify whether a machine is running malicious activities. Amalicious machine does not necessarily mean all running processes on themachine are also malicious. If we can isolate the malicious process instead ofisolating the whole machine, we could kill the malicious process, and themachine can keep doing its job. Another challenge dynamic malware detectionresearch faces is that the samples are executed in one machine without anybackground applications running. It is unrealistic as a computer typically runsmany benign (background) applications when a malware incident happens. Ourexperiment with machine-level data shows that the existence of backgroundapplications decreases previous state-of-the-art accuracy by about 20.12% onaverage. We also proposed a process-level Recurrent Neural Network (RNN)-baseddetection model. Our proposed model performs better than the machine-leveldetection model; 0.049 increase in detection rate and a false-positive ratebelow 0.1.</description><author>Baskoro Adi Pratomo, Toby Jackson, Pete Burnap, Andrew Hood, Eirini Anthi</author><pubDate>Fri, 27 Oct 2023 15:17:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18165v1</guid></item><item><title>Proportional Fairness in Clustering: A Social Choice Perspective</title><link>http://arxiv.org/abs/2310.18162v1</link><description>We study the proportional clustering problem of Chen et al. [ICML'19] andrelate it to the area of multiwinner voting in computational social choice. Weshow that any clustering satisfying a weak proportionality notion of Brill andPeters [EC'23] simultaneously obtains the best known approximations to theproportional fairness notion of Chen et al. [ICML'19], but also to individualfairness [Jung et al., FORC'20] and the "core" [Li et al. ICML'21]. In fact, weshow that any approximation to proportional fairness is also an approximationto individual fairness and vice versa. Finally, we also study stronger notionsof proportional representation, in which deviations do not only happen tosingle, but multiple candidate centers, and show that stronger proportionalitynotions of Brill and Peters [EC'23] imply approximations to these strongerguarantees.</description><author>Leon Kellerhals, Jannik Peters</author><pubDate>Fri, 27 Oct 2023 15:12:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18162v1</guid></item></channel></rss>