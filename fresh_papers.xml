<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 03 Jul 2023 06:00:36 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Hardwiring ViT Patch Selectivity into CNNs using Patch Mixing</title><link>http://arxiv.org/abs/2306.17848v1</link><description>Vision transformers (ViTs) have significantly changed the computer visionlandscape and have periodically exhibited superior performance in vision taskscompared to convolutional neural networks (CNNs). Although the jury is stillout on which model type is superior, each has unique inductive biases thatshape their learning and generalization performance. For example, ViTs haveinteresting properties with respect to early layer non-local featuredependence, as well as self-attention mechanisms which enhance learningflexibility, enabling them to ignore out-of-context image information moreeffectively. We hypothesize that this power to ignore out-of-contextinformation (which we name $\textit{patch selectivity}$), while integratingin-context information in a non-local manner in early layers, allows ViTs tomore easily handle occlusion. In this study, our aim is to see whether we canhave CNNs $\textit{simulate}$ this ability of patch selectivity by effectivelyhardwiring this inductive bias using Patch Mixing data augmentation, whichconsists of inserting patches from another image onto a training image andinterpolating labels between the two image classes. Specifically, we use PatchMixing to train state-of-the-art ViTs and CNNs, assessing its impact on theirability to ignore out-of-context patches and handle natural occlusions. We findthat ViTs do not improve nor degrade when trained using Patch Mixing, but CNNsacquire new capabilities to ignore out-of-context information and improve onocclusion benchmarks, leaving us to conclude that this training method is a wayof simulating in CNNs the abilities that ViTs already possess. We will releaseour Patch Mixing implementation and proposed datasets for public use. Projectpage: https://arielnlee.github.io/PatchMixing/</description><author>Ariel N. Lee, Sarah Adel Bargal, Janavi Kasera, Stan Sclaroff, Kate Saenko, Nataniel Ruiz</author><pubDate>Fri, 30 Jun 2023 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17848v1</guid></item><item><title>The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks</title><link>http://arxiv.org/abs/2306.17844v1</link><description>Do neural networks, trained on well-understood algorithmic tasks, reliablyrediscover known algorithms for solving those tasks? Several recent studies, ontasks ranging from group arithmetic to in-context linear regression, havesuggested that the answer is yes. Using modular addition as a prototypicalproblem, we show that algorithm discovery in neural networks is sometimes morecomplex. Small changes to model hyperparameters and initializations can inducethe discovery of qualitatively different algorithms from a fixed training set,and even parallel implementations of multiple such algorithms. Some networkstrained to perform modular addition implement a familiar Clock algorithm;others implement a previously undescribed, less intuitive, but comprehensibleprocedure which we term the Pizza algorithm, or a variety of even more complexprocedures. Our results show that even simple learning problems can admit asurprising diversity of solutions, motivating the development of new tools forcharacterizing the behavior of neural networks across their algorithmic phasespace.</description><author>Ziqian Zhong, Ziming Liu, Max Tegmark, Jacob Andreas</author><pubDate>Fri, 30 Jun 2023 18:59:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17844v1</guid></item><item><title>Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors</title><link>http://arxiv.org/abs/2306.17843v1</link><description>We present Magic123, a two-stage coarse-to-fine approach for high-quality,textured 3D meshes generation from a single unposed image in the wild usingboth2D and 3D priors. In the first stage, we optimize a neural radiance fieldto produce a coarse geometry. In the second stage, we adopt a memory-efficientdifferentiable mesh representation to yield a high-resolution mesh with avisually appealing texture. In both stages, the 3D content is learned throughreference view supervision and novel views guided by a combination of 2D and 3Ddiffusion priors. We introduce a single trade-off parameter between the 2D and3D priors to control exploration (more imaginative) and exploitation (moreprecise) of the generated geometry. Additionally, we employ textual inversionand monocular depth regularization to encourage consistent appearances acrossviews and to prevent degenerate solutions, respectively. Magic123 demonstratesa significant improvement over previous image-to-3D techniques, as validatedthrough extensive experiments on synthetic benchmarks and diverse real-worldimages. Our code, models, and generated 3D assets are available athttps://github.com/guochengqian/Magic123.</description><author>Guocheng Qian, Jinjie Mai, Abdullah Hamdi, Jian Ren, Aliaksandr Siarohin, Bing Li, Hsin-Ying Lee, Ivan Skorokhodov, Peter Wonka, Sergey Tulyakov, Bernard Ghanem</author><pubDate>Fri, 30 Jun 2023 18:59:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17843v1</guid></item><item><title>SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs</title><link>http://arxiv.org/abs/2306.17842v1</link><description>In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enablingfrozen LLMs to perform both understanding and generation tasks involvingnon-linguistic modalities such as images or videos. SPAE converts between rawpixels and interpretable lexical tokens (or words) extracted from the LLM'svocabulary. The resulting tokens capture both the semantic meaning and thefine-grained details needed for visual reconstruction, effectively translatingthe visual content into a language comprehensible to the LLM, and empowering itto perform a wide array of multimodal tasks. Our approach is validated throughin-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse setof image understanding and generation tasks. Our method marks the firstsuccessful attempt to enable a frozen LLM to generate image content whilesurpassing state-of-the-art performance in image understanding tasks, under thesame setting, by over 25%.</description><author>Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming-Hsuan Yang, Kevin Murphy, Alexander G. Hauptmann, Lu Jiang</author><pubDate>Fri, 30 Jun 2023 18:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17842v1</guid></item><item><title>Statler: State-Maintaining Language Models for Embodied Reasoning</title><link>http://arxiv.org/abs/2306.17840v1</link><description>Large language models (LLMs) provide a promising tool that enable robots toperform complex robot reasoning tasks. However, the limited context window ofcontemporary LLMs makes reasoning over long time horizons difficult. Embodiedtasks such as those that one might expect a household robot to performtypically require that the planner consider information acquired a long timeago (e.g., properties of the many objects that the robot previously encounteredin the environment). Attempts to capture the world state using an LLM'simplicit internal representation is complicated by the paucity of task- andenvironment-relevant information available in a robot's action history, whilemethods that rely on the ability to convey information via the prompt to theLLM are subject to its limited context window. In this paper, we proposeStatler, a framework that endows LLMs with an explicit representation of theworld state as a form of ``memory'' that is maintained over time. Integral toStatler is its use of two instances of general LLMs -- a world-model reader anda world-model writer -- that interface with and maintain the world state. Byproviding access to this world state ``memory'', Statler improves the abilityof existing LLMs to reason over longer time horizons without the constraint ofcontext length. We evaluate the effectiveness of our approach on threesimulated table-top manipulation domains and a real robot domain, and show thatit improves the state-of-the-art in LLM-based robot reasoning. Project website:https://statler-lm.github.io/</description><author>Takuma Yoneda, Jiading Fang, Peng Li, Huanyu Zhang, Tianchong Jiang, Shengjie Lin, Ben Picker, David Yunis, Hongyuan Mei, Matthew R. Walter</author><pubDate>Fri, 30 Jun 2023 18:58:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17840v1</guid></item><item><title>Breaking the Metric Voting Distortion Barrier</title><link>http://arxiv.org/abs/2306.17838v1</link><description>We consider the following well studied problem of metric distortion in socialchoice. Suppose we have an election with $n$ voters and $m$ candidates who liein a shared metric space. We would like to design a voting rule that chooses acandidate whose average distance to the voters is small. However, instead ofhaving direct access to the distances in the metric space, each voter gives usa ranked list of the candidates in order of distance. Can we design a rule thatregardless of the election instance and underlying metric space, chooses acandidate whose cost differs from the true optimum by only a small factor(known as the distortion)? A long line of work culminated in finding deterministic voting rules withmetric distortion $3$, which is the best possible for deterministic rules andmany other classes of voting rules. However, without any restrictions, there isstill a significant gap in our understanding: Even though the best lower boundis substantially lower at $2.112$, the best upper bound is still $3$, which isattained even by simple rules such as Random Dictatorship. Finding a rule thatguarantees distortion $3 - \varepsilon$ for some constant $\varepsilon $ hasbeen a major challenge in computational social choice. In this work, we give a rule that guarantees distortion less than $2.753$. Todo so we study a handful of voting rules that are new to the problem. One isMaximal Lotteries, a rule based on the Nash equilibrium of a natural zero-sumgame which dates back to the 60's. The others are novel rules that can bethought of as hybrids of Random Dictatorship and the Copeland rule. Though noneof these rules can beat distortion $3$ alone, a careful randomization betweenMaximal Lotteries and any of the novel rules can.</description><author>Moses Charikar, Prasanna Ramakrishnan, Kangning Wang, Hongxun Wu</author><pubDate>Fri, 30 Jun 2023 18:56:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17838v1</guid></item><item><title>Resetting the Optimizer in Deep RL: An Empirical Study</title><link>http://arxiv.org/abs/2306.17833v1</link><description>We focus on the task of approximating the optimal value function in deepreinforcement learning. This iterative process is comprised of approximatelysolving a sequence of optimization problems where the objective function canchange per iteration. The common approach to solving the problem is to employmodern variants of the stochastic gradient descent algorithm such as Adam.These optimizers maintain their own internal parameters such as estimates ofthe first and the second moment of the gradient, and update these parametersover time. Therefore, information obtained in previous iterations is being usedto solve the optimization problem in the current iteration. We hypothesize thatthis can contaminate the internal parameters of the employed optimizer insituations where the optimization landscape of the previous iterations is quitedifferent from the current iteration. To hedge against this effect, a simpleidea is to reset the internal parameters of the optimizer when starting a newiteration. We empirically investigate this resetting strategy by employingvarious optimizers in conjunction with the Rainbow algorithm. We demonstratethat this simple modification unleashes the true potential of modernoptimizers, and significantly improves the performance of deep RL on the Ataribenchmark.</description><author>Kavosh Asadi, Rasool Fakoor, Shoham Sabach</author><pubDate>Fri, 30 Jun 2023 18:53:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17833v1</guid></item><item><title>Federated Ensemble YOLOv5 - A Better Generalized Object Detection Algorithm</title><link>http://arxiv.org/abs/2306.17829v1</link><description>Federated learning (FL) has gained significant traction as aprivacy-preserving algorithm, but the underlying resembles of federatedlearning algorithm like Federated averaging (FED Avg) or Federated SGD (FEDSGD) to ensemble learning algorithms has not been fully explored. The purposeof this paper is to examine the application of FL to object detection as amethod to enhance generalizability, and to compare its performance against acentralized training approach for an object detection algorithm. Specifically,we investigate the performance of a YOLOv5 model trained using FL acrossmultiple clients and employ a random sampling strategy without replacement, soeach client holds a portion of the same dataset used for centralized training.Our experimental results showcase the superior efficiency of the FL objectdetector's global model in generating accurate bounding boxes for unseenobjects, with the test set being a mixture of objects from two distinct clientsnot represented in the training dataset. These findings suggest that FL can beviewed from an ensemble algorithm perspective, akin to a synergistic blend ofBagging and Boosting techniques. As a result, FL can be seen not only as amethod to enhance privacy, but also as a method to enhance the performance of amachine learning model.</description><author>Vinit Hegiste, Tatjana Legler, Martin Ruskowski</author><pubDate>Fri, 30 Jun 2023 18:50:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17829v1</guid></item><item><title>Expressive architectures enhance interpretability of dynamics-based neural population models</title><link>http://arxiv.org/abs/2212.03771v4</link><description>Artificial neural networks that can recover latent dynamics from recordedneural activity may provide a powerful avenue for identifying and interpretingthe dynamical motifs underlying biological computation. Given that neuralvariance alone does not uniquely determine a latent dynamical system,interpretable architectures should prioritize accurate and low-dimensionallatent dynamics. In this work, we evaluated the performance of sequentialautoencoders (SAEs) in recovering latent chaotic attractors from simulatedneural datasets. We found that SAEs with widely-used recurrent neural network(RNN)-based dynamics were unable to infer accurate firing rates at the truelatent state dimensionality, and that larger RNNs relied upon dynamicalfeatures not present in the data. On the other hand, SAEs with neural ordinarydifferential equation (NODE)-based dynamics inferred accurate rates at the truelatent state dimensionality, while also recovering latent trajectories andfixed point structure. Ablations reveal that this is mainly because NODEs (1)allow use of higher-capacity multi-layer perceptrons (MLPs) to model the vectorfield and (2) predict the derivative rather than the next state. Decoupling thecapacity of the dynamics model from its latent dimensionality enables NODEs tolearn the requisite low-D dynamics where RNN cells fail. Additionally, the factthat the NODE predicts derivatives imposes a useful autoregressive prior on thelatent states. The suboptimal interpretability of widely-used RNN-baseddynamics may motivate substitution for alternative architectures, such as NODE,that enable learning of accurate dynamics in low-dimensional latent spaces.</description><author>Andrew R. Sedler, Christopher Versteeg, Chethan Pandarinath</author><pubDate>Fri, 30 Jun 2023 18:49:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.03771v4</guid></item><item><title>Understanding Unfairness via Training Concept Influence</title><link>http://arxiv.org/abs/2306.17828v1</link><description>Knowing the causes of a model's unfairness helps practitioners betterunderstand their data and algorithms. This is an important yet relativelyunexplored task. We look into this problem through the lens of the trainingdata - one of the major sources of unfairness. We ask the following questions:how would a model's fairness performance change if, in its training data, somesamples (1) were collected from a different (e.g. demographic) group, (2) werelabeled differently, or (3) some features were changed? In other words, wequantify the fairness influence of training samples by counterfactuallyintervening and changing samples based on predefined concepts, i.e. dataattributes such as features (X), labels (Y), or sensitive attributes (A). Tocalculate a training sample's influence on the model's unfairness w.r.t aconcept, we first generate counterfactual samples based on the concept, i.e.the counterfactual versions of the sample if the concept were changed. We thencalculate the resulting impact on the unfairness, via influence function, ifthe counterfactual samples were used in training. Our framework not only helpspractitioners understand the observed unfairness and repair their trainingdata, but also leads to many other applications, e.g. detecting mislabeling,fixing imbalanced representations, and detecting fairness-targeted poisoningattacks.</description><author>Yuanshun Yao, Yang Liu</author><pubDate>Fri, 30 Jun 2023 18:48:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17828v1</guid></item><item><title>Fact or Artifact? Revise Layer-wise Relevance Propagation on various ANN Architectures</title><link>http://arxiv.org/abs/2302.12317v2</link><description>Layer-wise relevance propagation (LRP) is a widely used and powerfultechnique to reveal insights into various artificial neural network (ANN)architectures. LRP is often used in the context of image classification. Theaim is to understand, which parts of the input sample have highest relevanceand hence most influence on the model prediction. Relevance can be traced backthrough the network to attribute a certain score to each input pixel. Relevancescores are then combined and displayed as heat maps and give humans anintuitive visual understanding of classification models. Opening the black boxto understand the classification engine in great detail is essential for domainexperts to gain trust in ANN models. However, there are pitfalls in terms ofmodel-inherent artifacts included in the obtained relevance maps, that caneasily be missed. But for a valid interpretation, these artifacts must not beignored. Here, we apply and revise LRP on various ANN architectures trained asclassifiers on geospatial and synthetic data. Depending on the networkarchitecture, we show techniques to control model focus and give guidance toimprove the quality of obtained relevance maps to separate facts fromartifacts.</description><author>Marco Landt-Hayen, Willi Rath, Martin Claus, Peer Kröger</author><pubDate>Fri, 30 Jun 2023 18:43:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.12317v2</guid></item><item><title>Scalable tensor methods for nonuniform hypergraphs</title><link>http://arxiv.org/abs/2306.17825v1</link><description>While multilinear algebra appears natural for studying the multiwayinteractions modeled by hypergraphs, tensor methods for general hypergraphshave been stymied by theoretical and practical barriers. A recently proposedadjacency tensor is applicable to nonuniform hypergraphs, but is prohibitivelycostly to form and analyze in practice. We develop tensor times same vector(TTSV) algorithms for this tensor which improve complexity from $O(n^r)$ to alow-degree polynomial in $r$, where $n$ is the number of vertices and $r$ isthe maximum hyperedge size. Our algorithms are implicit, avoiding formation ofthe order $r$ adjacency tensor. We demonstrate the flexibility and utility ofour approach in practice by developing tensor-based hypergraph centrality andclustering algorithms. We also show these tensor measures offer complementaryinformation to analogous graph-reduction approaches on data, and are also ableto detect higher-order structure that many existing matrix-based approachesprovably cannot.</description><author>Sinan G. Aksoy, Ilya Amburg, Stephen J. Young</author><pubDate>Fri, 30 Jun 2023 18:41:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17825v1</guid></item><item><title>Meta-Reasoning: Semantics-Symbol Deconstruction For Large Language Models</title><link>http://arxiv.org/abs/2306.17820v1</link><description>Symbolization methods in large language models (LLMs) have been showneffective to improve LLMs' reasoning ability. However, most of these approacheshinge on mapping natural languages to formal languages (e.g., Python, SQL) thatare more syntactically complete and free of ambiguity. Although effective, theydepart from the natural language itself and deviate from the habits of humanthinking, and instead cater more to the execution mindset of computers. Incontrast, we hope to simplify natural language by starting from the concept ofsymbols in linguistics itself, so that LLMs can learn the common formulationand general solution of reasoning problems wrapped in different naturalsemantics. From this consideration, we propose \textbf{Meta-Reasoning}, whichallows LLMs to automatically accomplish semantic-symbol deconstruction, i.e.,semantic resolution, to maximally reduce different questions of certainreasoning tasks to similar natural language representation, thus gaining theability to learn by analogy and facilitating data-efficient in-contextlearning. Our experiments show that the Meta-Reasoning paradigm salientlyenhances LLMs' reasoning performance with fewer demonstrations. They can learnnot only reasoning chains but also general solutions to certain types of tasks.In particular, for symbolic reasoning tasks, such as 7-step Tracking ShuffledObjects, GPT-3 (text-davinci-002) achieves over 99% accuracy with only oneMeta-Reasoning demonstration, outperforming all current LLMs with the standardchain-of-thought prompting.</description><author>Yiming Wang, Zhuosheng Zhang, Rui Wang</author><pubDate>Fri, 30 Jun 2023 18:38:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17820v1</guid></item><item><title>Act3D: Infinite Resolution Action Detection Transformer for Robotic Manipulation</title><link>http://arxiv.org/abs/2306.17817v1</link><description>3D perceptual representations are well suited for robot manipulation as theyeasily encode occlusions and simplify spatial reasoning. Many manipulationtasks require high spatial precision in end-effector pose prediction, typicallydemanding high-resolution 3D perceptual grids that are computationallyexpensive to process. As a result, most manipulation policies operate directlyin 2D, foregoing 3D inductive biases. In this paper, we propose Act3D, amanipulation policy Transformer that casts 6-DoF keypose prediction as 3Ddetection with adaptive spatial computation. It takes as input 3D featureclouds unprojected from one or more camera views, iteratively samples 3D pointgrids in free space in a coarse-to-fine manner, featurizes them using relativespatial attention to the physical feature cloud, and selects the best featurepoint for end-effector pose prediction. Act3D sets a new state-of-the-art inRLbench, an established manipulation benchmark. Our model achieves 10% absoluteimprovement over the previous SOTA 2D multi-view policy on 74 RLbench tasks and22% absolute improvement with 3x less compute over the previous SOTA 3D policy.In thorough ablations, we show the importance of relative spatial attention,large-scale vision-language pre-trained 2D backbones, and weight tying acrosscoarse-to-fine attentions. Code and videos are available at our project site:https://act3d.github.io/.</description><author>Theophile Gervet, Zhou Xian, Nikolaos Gkanatsios, Katerina Fragkiadaki</author><pubDate>Fri, 30 Jun 2023 18:34:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17817v1</guid></item><item><title>First Steps Towards a Runtime Analysis When Starting With a Good Solution</title><link>http://arxiv.org/abs/2006.12161v3</link><description>The mathematical runtime analysis of evolutionary algorithms traditionallyregards the time an algorithm needs to find a solution of a certain qualitywhen initialized with a random population. In practical applications it may bepossible to guess solutions that are better than random ones. We start amathematical runtime analysis for such situations. We observe that differentalgorithms profit to a very different degree from a better initialization. Wealso show that the optimal parameterization of the algorithm can dependstrongly on the quality of the initial solutions. To overcome this difficulty,self-adjusting and randomized heavy-tailed parameter choices can be profitable.Finally, we observe a larger gap between the performance of the bestevolutionary algorithm we found and the corresponding black-box complexity.This could suggest that evolutionary algorithms better exploiting good initialsolutions are still to be found. These first findings stem from analyzing theperformance of the $(1+1)$ evolutionary algorithm and the static,self-adjusting, and heavy-tailed $(1 + (\lambda,\lambda))$ GA on the OneMaxbenchmark. We are optimistic that the question how to profit from good initialsolutions is interesting beyond these first examples.</description><author>Denis Antipov, Maxim Buzdalov, Benjamin Doerr</author><pubDate>Fri, 30 Jun 2023 18:29:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2006.12161v3</guid></item><item><title>Bayesian Optimization with Formal Safety Guarantees via Online Conformal Prediction</title><link>http://arxiv.org/abs/2306.17815v1</link><description>Black-box zero-th order optimization is a central primitive for applicationsin fields as diverse as finance, physics, and engineering. In a commonformulation of this problem, a designer sequentially attempts candidatesolutions, receiving noisy feedback on the value of each attempt from thesystem. In this paper, we study scenarios in which feedback is also provided onthe safety of the attempted solution, and the optimizer is constrained to limitthe number of unsafe solutions that are tried throughout the optimizationprocess. Focusing on methods based on Bayesian optimization (BO), prior art hasintroduced an optimization scheme -- referred to as SAFEOPT -- that isguaranteed not to select any unsafe solution with a controllable probabilityover feedback noise as long as strict assumptions on the safety constraintfunction are met. In this paper, a novel BO-based approach is introduced thatsatisfies safety requirements irrespective of properties of the constraintfunction. This strong theoretical guarantee is obtained at the cost of allowingfor an arbitrary, controllable but non-zero, rate of violation of the safetyconstraint. The proposed method, referred to as SAFE-BOCP, builds on onlineconformal prediction (CP) and is specialized to the cases in which feedback onthe safety constraint is either noiseless or noisy. Experimental results onsynthetic and real-world data validate the advantages and flexibility of theproposed SAFE-BOCP.</description><author>Yunchuan Zhang, Sangwoo Park, Osvaldo Simeone</author><pubDate>Fri, 30 Jun 2023 18:26:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17815v1</guid></item><item><title>A Massive Scale Semantic Similarity Dataset of Historical English</title><link>http://arxiv.org/abs/2306.17810v1</link><description>A diversity of tasks use language models trained on semantic similarity data.While there are a variety of datasets that capture semantic similarity, theyare either constructed from modern web data or are relatively small datasetscreated in the past decade by human annotators. This study utilizes a novelsource, newly digitized articles from off-copyright, local U.S. newspapers, toassemble a massive-scale semantic similarity dataset spanning 70 years from1920 to 1989 and containing nearly 400M positive semantic similarity pairs.Historically, around half of articles in U.S. local newspapers came fromnewswires like the Associated Press. While local papers reproduced articlesfrom the newswire, they wrote their own headlines, which form abstractivesummaries of the associated articles. We associate articles and their headlinesby exploiting document layouts and language understanding. We then use deepneural methods to detect which articles are from the same underlying source, inthe presence of substantial noise and abridgement. The headlines of reproducedarticles form positive semantic similarity pairs. The resulting publiclyavailable HEADLINES dataset is significantly larger than most existing semanticsimilarity datasets and covers a much longer span of time. It will facilitatethe application of contrastively trained semantic similarity models to avariety of tasks, including the study of semantic change across space and time.</description><author>Emily Silcock, Melissa Dell</author><pubDate>Fri, 30 Jun 2023 18:16:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17810v1</guid></item><item><title>Leveraging Ensembles and Self-Supervised Learning for Fully-Unsupervised Person Re-Identification and Text Authorship Attribution</title><link>http://arxiv.org/abs/2202.03126v4</link><description>Learning from fully-unlabeled data is challenging in Multimedia Forensicsproblems, such as Person Re-Identification and Text Authorship Attribution.Recent self-supervised learning methods have shown to be effective when dealingwith fully-unlabeled data in cases where the underlying classes havesignificant semantic differences, as intra-class distances are substantiallylower than inter-class distances. However, this is not the case for forensicapplications in which classes have similar semantics and the training and testsets have disjoint identities. General self-supervised learning methods mightfail to learn discriminative features in this scenario, thus requiring morerobust strategies. We propose a strategy to tackle Person Re-Identification andText Authorship Attribution by enabling learning from unlabeled data even whensamples from different classes are not prominently diverse. We propose a novelensemble-based clustering strategy whereby clusters derived from differentconfigurations are combined to generate a better grouping for the data samplesin a fully-unsupervised way. This strategy allows clusters with differentdensities and higher variability to emerge, reducing intra-class discrepancieswithout requiring the burden of finding an optimal configuration per dataset.We also consider different Convolutional Neural Networks for feature extractionand subsequent distance computations between samples. We refine these distancesby incorporating context and grouping them to capture complementaryinformation. Our method is robust across both tasks, with different datamodalities, and outperforms state-of-the-art methods with a fully-unsupervisedsolution without any labeling or human intervention.</description><author>Gabriel Bertocco, Antônio Theophilo, Fernanda Andaló, Anderson Rocha</author><pubDate>Fri, 30 Jun 2023 18:08:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.03126v4</guid></item><item><title>Stay on topic with Classifier-Free Guidance</title><link>http://arxiv.org/abs/2306.17806v1</link><description>Classifier-Free Guidance (CFG) has recently emerged in text-to-imagegeneration as a lightweight technique to encourage prompt-adherence ingenerations. In this work, we demonstrate that CFG can be used broadly as aninference-time technique in pure language modeling. We show that CFG (1)improves the performance of Pythia, GPT-2 and LLaMA-family models across anarray of tasks: Q\&amp;A, reasoning, code generation, and machine translation,achieving SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvementsequivalent to a model with twice the parameter-count; (3) can stack alongsideother inference-time methods like Chain-of-Thought and Self-Consistency,yielding further improvements in difficult tasks; (4) can be used to increasethe faithfulness and coherence of assistants in challenging form-driven andcontent-driven prompts: in a human evaluation we show a 75\% preference forGPT4All using CFG over baseline.</description><author>Guillaume Sanchez, Honglu Fan, Alexander Spangher, Elad Levi, Pawan Sasanka Ammanamanchi, Stella Biderman</author><pubDate>Fri, 30 Jun 2023 18:07:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17806v1</guid></item><item><title>Solving QMLTP Problems by Translation to Higher-order Logic</title><link>http://arxiv.org/abs/2212.09570v2</link><description>This paper describes an evaluation of Automated Theorem Proving (ATP) systemson problems taken from the QMLTP library of first-order modal logic problems.Principally, the problems are translated to higher-order logic in the TPTPlanguage using an embedding approach, and solved using higher-order logic ATPsystems. Additionally, the results from native modal logic ATP systems areconsidered, and compared with those from the embedding approach. The findingsare that the embedding process is reliable and successful, the choice ofbackend ATP system can significantly impact the performance of the embeddingapproach, native modal logic ATP systems outperform the embedding approach, andthe embedding approach can cope with a wider range modal logics than the nativemodal systems considered.</description><author>Alexander Steen, Geoff Sutcliffe, Tobias Scholl, Christoph Benzmüller</author><pubDate>Fri, 30 Jun 2023 17:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.09570v2</guid></item><item><title>Hierarchical Bayesian Regression for Multi-Location Sales Transaction Forecasting</title><link>http://arxiv.org/abs/2306.17795v1</link><description>The features in many prediction models naturally take the form of ahierarchy. The lower levels represent individuals or events. These units groupnaturally into locations and intervals or other aggregates, often at multiplelevels. Levels of groupings may intersect and join, much as relational databasetables do. Besides representing the structure of the data, predictive featuresin hierarchical models can be assigned to their proper levels. Such models lendthemselves to hierarchical Bayes solution methods that ``share'' results ofinference between groups by generalizing over the case of individual models foreach group versus one model that aggregates all groups into one. In this paper we show our work-in-progress applying a hierarchical Bayesianmodel to forecast purchases throughout the day at store franchises, withgroupings over locations and days of the week. We demonstrate using the\textsf{stan} package on individual sales transaction data collected over thecourse of a year. We show how this solves the dilemma of having limited dataand hence modest accuracy for each day and location, while being able to scaleto a large number of locations with improved accuracy.</description><author>John Mark Agosta, Mario Inchiosa</author><pubDate>Fri, 30 Jun 2023 17:53:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17795v1</guid></item><item><title>Vision Through the Veil: Differential Privacy in Federated Learning for Medical Image Classification</title><link>http://arxiv.org/abs/2306.17794v1</link><description>The proliferation of deep learning applications in healthcare calls for dataaggregation across various institutions, a practice often associated withsignificant privacy concerns. This concern intensifies in medical imageanalysis, where privacy-preserving mechanisms are paramount due to the databeing sensitive in nature. Federated learning, which enables cooperative modeltraining without direct data exchange, presents a promising solution.Nevertheless, the inherent vulnerabilities of federated learning necessitatefurther privacy safeguards. This study addresses this need by integratingdifferential privacy, a leading privacy-preserving technique, into a federatedlearning framework for medical image classification. We introduce a noveldifferentially private federated learning model and meticulously examine itsimpacts on privacy preservation and model performance. Our research confirmsthe existence of a trade-off between model accuracy and privacy settings.However, we demonstrate that strategic calibration of the privacy budget indifferential privacy can uphold robust image classification performance whileproviding substantial privacy protection.</description><author>Kishore Babu Nampalle, Pradeep Singh, Uppala Vivek Narayan, Balasubramanian Raman</author><pubDate>Fri, 30 Jun 2023 17:48:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17794v1</guid></item><item><title>Towards Improving the Performance of Pre-Trained Speech Models for Low-Resource Languages Through Lateral Inhibition</title><link>http://arxiv.org/abs/2306.17792v1</link><description>With the rise of bidirectional encoder representations from Transformermodels in natural language processing, the speech community has adopted some oftheir development methodologies. Therefore, the Wav2Vec models were introducedto reduce the data required to obtain state-of-the-art results. This workleverages this knowledge and improves the performance of the pre-trained speechmodels by simply replacing the fine-tuning dense layer with a lateralinhibition layer inspired by the biological process. Our experiments onRomanian, a low-resource language, show an average improvement of 12.5% worderror rate (WER) using the lateral inhibition layer. In addition, we obtainstate-of-the-art results on both the Romanian Speech Corpus and the RobinTechnical Acquisition Corpus with 1.78% WER and 29.64% WER, respectively.</description><author>Andrei-Marius Avram, Răzvan-Alexandru Smădu, Vasile Păiş, Dumitru-Clementin Cercel, Radu Ion, Dan Tufiş</author><pubDate>Fri, 30 Jun 2023 17:48:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17792v1</guid></item><item><title>Heterogeneous Distributed Lag Models to Estimate Personalized Effects of Maternal Exposures to Air Pollution</title><link>http://arxiv.org/abs/2109.13763v3</link><description>Children's health studies support an association between maternalenvironmental exposures and children's birth outcomes. A common goal is toidentify critical windows of susceptibility--periods during gestation withincreased association between maternal exposures and a future outcome. Thetiming of the critical windows and magnitude of the associations are likelyheterogeneous across different levels of individual, family, and neighborhoodcharacteristics. Using an administrative Colorado birth cohort we estimate theindividualized relationship between weekly exposures to fine particulate matter(PM$_{2.5}$) during gestation and birth weight. To achieve this goal, wepropose a statistical learning method combining distributed lag models andBayesian additive regression trees to estimate critical windows at theindividual level and identify characteristics that induce heterogeneity from ahigh-dimensional set of potential modifying factors. We find evidence ofheterogeneity in the PM$_{2.5}$-birth weight relationship, with somemother-child dyads showing a 3 times larger decrease in birth weight for an IQRincrease in exposure (5.9 to 8.5 $\mu g/m^3$ PM$_{2.5}$) compared to thepopulation average. Specifically, we find increased susceptibility fornon-Hispanic mothers who are either younger, have higher body mass index orlower educational attainment. Our case study is the first precision healthstudy of critical windows.</description><author>Daniel Mork, Marianthi-Anna Kioumourtzoglou, Marc Weisskopf, Brent A Coull, Ander Wilson</author><pubDate>Fri, 30 Jun 2023 17:41:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.13763v3</guid></item><item><title>Look, Remember and Reason: Visual Reasoning with Grounded Rationales</title><link>http://arxiv.org/abs/2306.17778v1</link><description>Large language models have recently shown human level performance on avariety of reasoning tasks. However, the ability of these models to performcomplex visual reasoning has not been studied in detail yet. A key challenge inmany visual reasoning tasks is that the visual information needs to be tightlyintegrated in the reasoning process. We propose to address this challenge bydrawing inspiration from human visual problem solving which depends on avariety of low-level visual capabilities. It can often be cast as the threestep-process of ``Look, Remember, Reason'': visual information is incrementallyextracted using low-level visual routines in a step-by-step fashion until afinal answer is reached. We follow the same paradigm to enable existing largelanguage models, with minimal changes to the architecture, to solve visualreasoning problems. To this end, we introduce rationales over the visual inputthat allow us to integrate low-level visual capabilities, such as objectrecognition and tracking, as surrogate tasks. We show competitive performanceon diverse visual reasoning tasks from the CLEVR, CATER, and ACRE datasets overstate-of-the-art models designed specifically for these tasks.</description><author>Apratim Bhattacharyya, Sunny Panchal, Mingu Lee, Reza Pourreza, Pulkit Madan, Roland Memisevic</author><pubDate>Fri, 30 Jun 2023 17:31:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17778v1</guid></item><item><title>Practical and Asymptotically Exact Conditional Sampling in Diffusion Models</title><link>http://arxiv.org/abs/2306.17775v1</link><description>Diffusion models have been successful on a range of conditional generationtasks including molecular design and text-to-image generation. However, theseachievements have primarily depended on task-specific conditional training orerror-prone heuristic approximations. Ideally, a conditional generation methodshould provide exact samples for a broad range of conditional distributionswithout requiring task-specific training. To this end, we introduce the TwistedDiffusion Sampler, or TDS. TDS is a sequential Monte Carlo (SMC) algorithm thattargets the conditional distributions of diffusion models. The main idea is touse twisting, an SMC technique that enjoys good computational efficiency, toincorporate heuristic approximations without compromising asymptotic exactness.We first find in simulation and on MNIST image inpainting and class-conditionalgeneration tasks that TDS provides a computational statistical trade-off,yielding more accurate approximations with many particles but with empiricalimprovements over heuristics with as few as two particles. We then turn tomotif-scaffolding, a core task in protein design, using a TDS extension toRiemannian diffusion models. On benchmark test cases, TDS allows flexibleconditioning criteria and often outperforms the state of the art.</description><author>Luhuan Wu, Brian L. Trippe, Christian A. Naesseth, David M. Blei, John P. Cunningham</author><pubDate>Fri, 30 Jun 2023 17:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17775v1</guid></item><item><title>Case-Base Neural Networks: survival analysis with time-varying, higher-order interactions</title><link>http://arxiv.org/abs/2301.06535v2</link><description>Neural network-based survival methods can model data-driven covariateinteractions. While these methods can provide better predictive performancethan regression-based approaches, not all can model time-varying interactionsand complex baseline hazards. To address this, we propose Case-Base NeuralNetworks (CBNNs) as a new approach that combines the case-base samplingframework with flexible neural network architectures. Using a novel samplingscheme and data augmentation to naturally account for censoring, we construct afeed-forward neural network that may take time as an input. CBNNs predict theprobability of an event occurring at a given moment to estimate the hazardfunction. We compare the performance of CBNNs to regression and neuralnetwork-based survival methods in a simulation and three case studies using twotime-dependent metrics. First, we examine performance on a simulation involvinga complex baseline hazard and time-varying interactions to assess all methods,with CBNN outperforming competitors. Then, we apply all methods to three realdata applications, with CBNNs outperforming the competing models in two studiesand showing similar performance in the third. Our results highlight the benefitof combining case-base sampling with deep learning to provide a simple andflexible modeling framework for data-driven, time-varying interaction modelingof single event survival outcomes. An R package is available athttps://github.com/Jesse-Islam/cbnn.</description><author>Jesse Islam, Maxime Turgeon, Robert Sladek, Sahir Bhatnagar</author><pubDate>Fri, 30 Jun 2023 17:27:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06535v2</guid></item><item><title>Precision Anti-Cancer Drug Selection via Neural Ranking</title><link>http://arxiv.org/abs/2306.17771v1</link><description>Personalized cancer treatment requires a thorough understanding of complexinteractions between drugs and cancer cell lines in varying genetic andmolecular contexts. To address this, high-throughput screening has been used togenerate large-scale drug response data, facilitating data-driven computationalmodels. Such models can capture complex drug-cell line interactions acrossvarious contexts in a fully data-driven manner. However, accuratelyprioritizing the most sensitive drugs for each cell line still remains asignificant challenge. To address this, we developed neural ranking approachesthat leverage large-scale drug response data across multiple cell lines fromdiverse cancer types. Unlike existing approaches that primarily utilizeregression and classification techniques for drug response prediction, weformulated the objective of drug selection and prioritization as a drug rankingproblem. In this work, we proposed two neural listwise ranking methods thatlearn latent representations of drugs and cell lines, and then use thoserepresentations to score drugs in each cell line via a learnable scoringfunction. Specifically, we developed a neural listwise ranking method,List-One, on top of the existing method ListNet. Additionally, we proposed anovel listwise ranking method, List-All, that focuses on all the sensitivedrugs instead of the top sensitive drug, unlike List-One. Our resultsdemonstrate that List-All outperforms the best baseline with significantimprovements of as much as 8.6% in hit@20 across 50% test cell lines.Furthermore, our analyses suggest that the learned latent spaces from ourproposed methods demonstrate informative clustering structures and capturerelevant underlying biological features. Moreover, our comprehensive empiricalevaluation provides a thorough and objective comparison of the performance ofdifferent methods (including our proposed ones).</description><author>Vishal Dey, Xia Ning</author><pubDate>Fri, 30 Jun 2023 17:23:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17771v1</guid></item><item><title>MTR++: Multi-Agent Motion Prediction with Symmetric Scene Modeling and Guided Intention Querying</title><link>http://arxiv.org/abs/2306.17770v1</link><description>Motion prediction is crucial for autonomous driving systems to understandcomplex driving scenarios and make informed decisions. However, this task ischallenging due to the diverse behaviors of traffic participants and complexenvironmental contexts. In this paper, we propose Motion TRansformer (MTR)frameworks to address these challenges. The initial MTR framework utilizes atransformer encoder-decoder structure with learnable intention queries,enabling efficient and accurate prediction of future trajectories. Bycustomizing intention queries for distinct motion modalities, MTR improvesmultimodal motion prediction while reducing reliance on dense goal candidates.The framework comprises two essential processes: global intention localization,identifying the agent's intent to enhance overall efficiency, and localmovement refinement, adaptively refining predicted trajectories for improvedaccuracy. Moreover, we introduce an advanced MTR++ framework, extending thecapability of MTR to simultaneously predict multimodal motion for multipleagents. MTR++ incorporates symmetric context modeling and mutually-guidedintention querying modules to facilitate future behavior interaction amongmultiple agents, resulting in scene-compliant future trajectories. Extensiveexperimental results demonstrate that the MTR framework achievesstate-of-the-art performance on the highly-competitive motion predictionbenchmarks, while the MTR++ framework surpasses its precursor, exhibitingenhanced performance and efficiency in predicting accurate multimodal futuretrajectories for multiple agents.</description><author>Shaoshuai Shi, Li Jiang, Dengxin Dai, Bernt Schiele</author><pubDate>Fri, 30 Jun 2023 17:23:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17770v1</guid></item><item><title>See Through the Fog: Curriculum Learning with Progressive Occlusion in Medical Imaging</title><link>http://arxiv.org/abs/2306.15574v2</link><description>In recent years, deep learning models have revolutionized medical imageinterpretation, offering substantial improvements in diagnostic accuracy.However, these models often struggle with challenging images where criticalfeatures are partially or fully occluded, which is a common scenario inclinical practice. In this paper, we propose a novel curriculum learning-basedapproach to train deep learning models to handle occluded medical imageseffectively. Our method progressively introduces occlusion, starting fromclear, unobstructed images and gradually moving to images with increasingocclusion levels. This ordered learning process, akin to human learning, allowsthe model to first grasp simple, discernable patterns and subsequently buildupon this knowledge to understand more complicated, occluded scenarios.Furthermore, we present three novel occlusion synthesis methods, namelyWasserstein Curriculum Learning (WCL), Information Adaptive Learning (IAL), andGeodesic Curriculum Learning (GCL). Our extensive experiments on diversemedical image datasets demonstrate substantial improvements in model robustnessand diagnostic accuracy over conventional training methodologies.</description><author>Pradeep Singh, Kishore Babu Nampalle, Uppala Vivek Narayan, Balasubramanian Raman</author><pubDate>Fri, 30 Jun 2023 17:20:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15574v2</guid></item><item><title>Comparing Reinforcement Learning and Human Learning using the Game of Hidden Rules</title><link>http://arxiv.org/abs/2306.17766v1</link><description>Reliable real-world deployment of reinforcement learning (RL) methodsrequires a nuanced understanding of their strengths and weaknesses and how theycompare to those of humans. Human-machine systems are becoming more prevalentand the design of these systems relies on a task-oriented understanding of bothhuman learning (HL) and RL. Thus, an important line of research ischaracterizing how the structure of a learning task affects learningperformance. While increasingly complex benchmark environments have led toimproved RL capabilities, such environments are difficult to use for thededicated study of task structure. To address this challenge we present alearning environment built to support rigorous study of the impact of taskstructure on HL and RL. We demonstrate the environment's utility for such studythrough example experiments in task structure that show performance differencesbetween humans and RL algorithms.</description><author>Eric Pulick, Vladimir Menkov, Yonatan Mintz, Paul Kantor, Vicki Bier</author><pubDate>Fri, 30 Jun 2023 17:18:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17766v1</guid></item><item><title>GRIL: A $2$-parameter Persistence Based Vectorization for Machine Learning</title><link>http://arxiv.org/abs/2304.04970v2</link><description>$1$-parameter persistent homology, a cornerstone in Topological Data Analysis(TDA), studies the evolution of topological features such as connectedcomponents and cycles hidden in data. It has been applied to enhance therepresentation power of deep learning models, such as Graph Neural Networks(GNNs). To enrich the representations of topological features, here we proposeto study $2$-parameter persistence modules induced by bi-filtration functions.In order to incorporate these representations into machine learning models, weintroduce a novel vector representation called Generalized Rank InvariantLandscape (GRIL) for $2$-parameter persistence modules. We show that thisvector representation is $1$-Lipschitz stable and differentiable with respectto underlying filtration functions and can be easily integrated into machinelearning models to augment encoding topological features. We present analgorithm to compute the vector representation efficiently. We also test ourmethods on synthetic and benchmark graph datasets, and compare the results withprevious vector representations of $1$-parameter and $2$-parameter persistencemodules. Further, we augment GNNs with GRIL features and observe an increase inperformance indicating that GRIL can capture additional features enrichingGNNs. We make the complete code for the proposed method available athttps://github.com/soham0209/mpml-graph.</description><author>Cheng Xin, Soham Mukherjee, Shreyas N. Samaga, Tamal K. Dey</author><pubDate>Fri, 30 Jun 2023 17:13:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.04970v2</guid></item><item><title>The Shaped Transformer: Attention Models in the Infinite Depth-and-Width Limit</title><link>http://arxiv.org/abs/2306.17759v1</link><description>In deep learning theory, the covariance matrix of the representations servesas a proxy to examine the network's trainability. Motivated by the success ofTransformers, we study the covariance matrix of a modified Softmax-basedattention model with skip connections in the proportional limit ofinfinite-depth-and-width. We show that at initialization the limitingdistribution can be described by a stochastic differential equation (SDE)indexed by the depth-to-width ratio. To achieve a well-defined stochasticlimit, the Transformer's attention mechanism is modified by centering theSoftmax output at identity, and scaling the Softmax logits by a width-dependenttemperature parameter. We examine the stability of the network through thecorresponding SDE, showing how the scale of both the drift and diffusion can beelegantly controlled with the aid of residual connections. The existence of astable SDE implies that the covariance structure is well-behaved, even for verylarge depth and width, thus preventing the notorious issues of rank degeneracyin deep attention models. Finally, we show, through simulations, that the SDEprovides a surprisingly good description of the corresponding finite-sizemodel. We coin the name shaped Transformer for these architecturalmodifications.</description><author>Lorenzo Noci, Chuning Li, Mufan Bill Li, Bobby He, Thomas Hofmann, Chris Maddison, Daniel M. Roy</author><pubDate>Fri, 30 Jun 2023 17:10:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17759v1</guid></item><item><title>Should you marginalize over possible tokenizations?</title><link>http://arxiv.org/abs/2306.17757v1</link><description>Autoregressive language models (LMs) map token sequences to probabilities.The usual practice for computing the probability of any character string (e.g.English sentences) is to first transform it into a sequence of tokens that isscored by the model. However, there are exponentially many token sequences thatrepresent any given string. To truly compute the probability of a string oneshould marginalize over all tokenizations, which is typically intractable.Here, we analyze whether the practice of ignoring the marginalization isjustified. To this end, we devise an importance-sampling-based algorithm thatallows us to compute estimates of the marginal probabilities and compare themto the default procedure in a range of state-of-the-art models and datasets.Our results show that the gap in log-likelihood is no larger than 0.5% in mostcases, but that it becomes more pronounced for data with long complex words.</description><author>Nadezhda Chirkova, Germán Kruszewski, Jos Rozen, Marc Dymetman</author><pubDate>Fri, 30 Jun 2023 17:09:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17757v1</guid></item><item><title>Causal Rule Ensemble: Interpretable Discovery and Inference of Heterogeneous Treatment Effects</title><link>http://arxiv.org/abs/2009.09036v5</link><description>In health and social sciences, it is critically important to identifysubgroups of the study population where there is notable heterogeneity oftreatment effects (HTE) with respect to the population average. Decision treeshave been proposed and commonly adopted for data-driven discovery of HTE due totheir high level of interpretability. However, single-tree discovery of HTE canbe unstable and oversimplified. This paper introduces Causal Rule Ensemble(CRE), a new method for HTE discovery and estimation through anensemble-of-trees approach. CRE offers several key features, including 1) aninterpretable representation of the HTE; 2) the ability to explore complexheterogeneity patterns; and 3) high stability in subgroups discovery. Thediscovered subgroups are defined in terms of interpretable decision rules.Estimation of subgroup-specific causal effects is performed via a two-stageapproach for which we provide theoretical guarantees. Via simulations, we showthat the CRE method is highly competitive when compared to state-of-the-arttechniques. Finally, we apply CRE to discover the heterogeneous health effectsof exposure to air pollution on mortality for 35.3 million Medicarebeneficiaries across the contiguous U.S.</description><author>Falco J. Bargagli-Stoffi, Riccardo Cadei, Kwonsang Lee, Francesca Dominici</author><pubDate>Fri, 30 Jun 2023 17:05:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2009.09036v5</guid></item><item><title>TD Convergence: An Optimization Perspective</title><link>http://arxiv.org/abs/2306.17750v1</link><description>We study the convergence behavior of the celebrated temporal-difference (TD)learning algorithm. By looking at the algorithm through the lens ofoptimization, we first argue that TD can be viewed as an iterative optimizationalgorithm where the function to be minimized changes per iteration. Bycarefully investigating the divergence displayed by TD on a classical counterexample, we identify two forces that determine the convergent or divergentbehavior of the algorithm. We next formalize our discovery in the linear TDsetting with quadratic loss and prove that convergence of TD hinges on theinterplay between these two forces. We extend this optimization perspective toprove convergence of TD in a much broader setting than just linearapproximation and squared loss. Our results provide a theoretical explanationfor the successful application of TD in reinforcement learning.</description><author>Kavosh Asadi, Shoham Sabach, Yao Liu, Omer Gottesman, Rasool Fakoor</author><pubDate>Fri, 30 Jun 2023 17:01:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17750v1</guid></item><item><title>WDC Products: A Multi-Dimensional Entity Matching Benchmark</title><link>http://arxiv.org/abs/2301.09521v2</link><description>The difficulty of an entity matching task depends on a combination ofmultiple factors such as the amount of corner-case pairs, the fraction ofentities in the test set that have not been seen during training, and the sizeof the development set. Current entity matching benchmarks usually representsingle points in the space along such dimensions or they provide for theevaluation of matching methods along a single dimension, for instance theamount of training data. This paper presents WDC Products, an entity matchingbenchmark which provides for the systematic evaluation of matching systemsalong combinations of three dimensions while relying on real-world data. Thethree dimensions are (i) amount of corner-cases (ii) generalization to unseenentities, and (iii) development set size (training set plus validation set).Generalization to unseen entities is a dimension not covered by any of theexisting English-language benchmarks yet but is crucial for evaluating therobustness of entity matching systems. Instead of learning how to match entitypairs, entity matching can also be formulated as a multi-class classificationtask that requires the matcher to recognize individual entities. WDC Productsis the first benchmark that provides a pair-wise and a multi-class formulationof the same tasks. We evaluate WDC Products using several state-of-the-artmatching systems, including Ditto, HierGAT, and R-SupCon. The evaluation showsthat all matching systems struggle with unseen entities to varying degrees. Italso shows that for entity matching contrastive learning is more training dataefficient compared to cross-encoders.</description><author>Ralph Peeters, Reng Chiz Der, Christian Bizer</author><pubDate>Fri, 30 Jun 2023 16:59:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.09521v2</guid></item><item><title>Discriminatory or Samaritan -- which AI is needed for humanity? An Evolutionary Game Theory Analysis of Hybrid Human-AI populations</title><link>http://arxiv.org/abs/2306.17747v1</link><description>As artificial intelligence (AI) systems are increasingly embedded in ourlives, their presence leads to interactions that shape our behaviour,decision-making, and social interactions. Existing theoretical research hasprimarily focused on human-to-human interactions, overlooking the uniquedynamics triggered by the presence of AI. In this paper, resorting to methodsfrom evolutionary game theory, we study how different forms of AI influence theevolution of cooperation in a human population playing the one-shot Prisoner'sDilemma game in both well-mixed and structured populations. We found thatSamaritan AI agents that help everyone unconditionally, including defectors,can promote higher levels of cooperation in humans than Discriminatory AI thatonly help those considered worthy/cooperative, especially in slow-movingsocieties where change is viewed with caution or resistance (small intensitiesof selection). Intuitively, in fast-moving societies (high intensities ofselection), Discriminatory AIs promote higher levels of cooperation thanSamaritan AIs.</description><author>Tim Booker, Manuel Miranda, Jesús A. Moreno López, José María Ramos Fernández, Max Reddel, Valeria Widler, Filippo Zimmaro, Alberto Antonioni, The Anh Han</author><pubDate>Fri, 30 Jun 2023 16:56:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17747v1</guid></item><item><title>Neural Characteristic Activation Value Analysis for Improved ReLU Network Feature Learning</title><link>http://arxiv.org/abs/2305.15912v2</link><description>We examine the characteristic activation values of individual ReLU units inneural networks. We refer to the corresponding set for such characteristicactivation values in the input space as the characteristic activation set of aReLU unit. We draw an explicit connection between the characteristic activationset and learned features in ReLU networks. This connection leads to newinsights into why various neural network normalization techniques used inmodern deep learning architectures regularize and stabilize SGD optimization.Utilizing these insights, we propose a geometric approach to parameterize ReLUnetworks for improved feature learning. We empirically verify its usefulnesswith less carefully chosen initialization schemes and larger learning rates. Wereport improved optimization stability, faster convergence speed, and bettergeneralization performance.</description><author>Wenlin Chen, Hong Ge</author><pubDate>Fri, 30 Jun 2023 16:41:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15912v2</guid></item><item><title>Faithfulness Tests for Natural Language Explanations</title><link>http://arxiv.org/abs/2305.18029v2</link><description>Explanations of neural models aim to reveal a model's decision-making processfor its predictions. However, recent work shows that current methods givingexplanations such as saliency maps or counterfactuals can be misleading, asthey are prone to present reasons that are unfaithful to the model's innerworkings. This work explores the challenging question of evaluating thefaithfulness of natural language explanations (NLEs). To this end, we presenttwo tests. First, we propose a counterfactual input editor for insertingreasons that lead to counterfactual predictions but are not reflected by theNLEs. Second, we reconstruct inputs from the reasons stated in the generatedNLEs and check how often they lead to the same predictions. Our tests canevaluate emerging NLE models, proving a fundamental tool in the development offaithful NLEs.</description><author>Pepa Atanasova, Oana-Maria Camburu, Christina Lioma, Thomas Lukasiewicz, Jakob Grue Simonsen, Isabelle Augenstein</author><pubDate>Fri, 30 Jun 2023 16:41:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18029v2</guid></item><item><title>LUT-GCE: Lookup Table Global Curve Estimation for Fast Low-light Image Enhancement</title><link>http://arxiv.org/abs/2306.07083v2</link><description>We present an effective and efficient approach for low-light imageenhancement, named Lookup Table Global Curve Estimation (LUT-GCE). In contrastto existing curve-based methods with pixel-wise adjustment, we propose toestimate a global curve for the entire image that allows corrections for bothunder- and over-exposure. Specifically, we develop a novel cubic curveformulation for light enhancement, which enables an image-adaptive andpixel-independent curve for the range adjustment of an image. We then propose aglobal curve estimation network (GCENet), a very light network with only 25.4kparameters. To further speed up the inference speed, a lookup table method isemployed for fast retrieval. In addition, a novel histogram smoothness loss isdesigned to enable zero-shot learning, which is able to improve the contrast ofthe image and recover clearer details. Quantitative and qualitative resultsdemonstrate the effectiveness of the proposed approach. Furthermore, ourapproach outperforms the state of the art in terms of inference speed,especially on high-definition images (e.g., 1080p and 4k).</description><author>Changguang Wu, Jiangxin Dong, Jinhui Tang</author><pubDate>Fri, 30 Jun 2023 16:33:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07083v2</guid></item><item><title>New Perspective on Progressive GANs Distillation for One-class Novelty Detection</title><link>http://arxiv.org/abs/2109.07295v3</link><description>One-class novelty detection is conducted to identify anomalous instances,with different distributions from the expected normal instances. In this paper,the Generative Adversarial Network based on the Encoder-Decoder-Encoder scheme(EDE-GAN) achieves state-of-the-art performance. The two factors bellow servethe above purpose: 1) The EDE-GAN calculates the distance between two latentvectors as the anomaly score, which is unlike the previous methods by utilizingthe reconstruction error between images. 2) The model obtains best results whenthe batch size is set to 1. To illustrate their superiority, we design a newGAN architecture, and compare performances according to different batch sizes.Moreover, with experimentation leads to discovery, our result implies there isalso evidence of just how beneficial constraint on the latent space are whenengaging in model training. In an attempt to learn compact and fast models, wepresent a new technology, Progressive Knowledge Distillation with GANs(P-KDGAN), which connects two standard GANs through the designed distillationloss. Two-step progressive learning continuously augments the performance ofstudent GANs with improved results over single-step approach. Our experimentalresults on CIFAR-10, MNIST, and FMNIST datasets illustrate that P-KDGANimproves the performance of the student GAN by 2.44%, 1.77%, and 1.73% whencompressing the computationat ratios of 24.45:1, 311.11:1, and 700:1,respectively.</description><author>Zhiwei Zhang, Yu Dong, Hanyu Peng, Shifeng Chen</author><pubDate>Fri, 30 Jun 2023 16:32:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.07295v3</guid></item><item><title>A Gradient Smoothed Functional Algorithm with Truncated Cauchy Random Perturbations for Stochastic Optimization</title><link>http://arxiv.org/abs/2208.00290v4</link><description>In this paper, we present a stochastic gradient algorithm for minimizing asmooth objective function that is an expectation over noisy cost samples, andonly the latter are observed for any given parameter. Our algorithm employs agradient estimation scheme with random perturbations, which are formed usingthe truncated Cauchy distribution from the delta sphere. We analyze the biasand variance of the proposed gradient estimator. Our algorithm is found to beparticularly useful in the case when the objective function is non-convex, andthe parameter dimension is high. From an asymptotic convergence analysis, weestablish that our algorithm converges almost surely to the set of stationarypoints of the objective function and obtains the asymptotic convergence rate.We also show that our algorithm avoids unstable equilibria, implyingconvergence to local minima. Further, we perform a non-asymptotic convergenceanalysis of our algorithm. In particular, we establish here a non-asymptoticbound for finding an epsilon-stationary point of the non-convex objectivefunction. Finally, we demonstrate numerically through simulations that theperformance of our algorithm outperforms GSF, SPSA, and RDSA by a significantmargin over a few non-convex settings and further validate its performance overconvex (noisy) objectives.</description><author>Akash Mondal, Prashanth L. A., Shalabh Bhatnagar</author><pubDate>Fri, 30 Jun 2023 16:26:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.00290v4</guid></item><item><title>Token-Event-Role Structure-based Multi-Channel Document-Level Event Extraction</title><link>http://arxiv.org/abs/2306.17733v1</link><description>Document-level event extraction is a long-standing challenging informationretrieval problem involving a sequence of sub-tasks: entity extraction, eventtype judgment, and event type-specific multi-event extraction. However,addressing the problem as multiple learning tasks leads to increased modelcomplexity. Also, existing methods insufficiently utilize the correlation ofentities crossing different events, resulting in limited event extractionperformance. This paper introduces a novel framework for document-level eventextraction, incorporating a new data structure called token-event-role and amulti-channel argument role prediction module. The proposed data structureenables our model to uncover the primary role of tokens in multiple events,facilitating a more comprehensive understanding of event relationships. Byleveraging the multi-channel prediction module, we transform entity andmulti-event extraction into a single task of predicting token-event pairs,thereby reducing the overall parameter size and enhancing model efficiency. Theresults demonstrate that our approach outperforms the state-of-the-art methodby 9.5 percentage points in terms of the F1 score, highlighting its superiorperformance in event extraction. Furthermore, an ablation study confirms thesignificant value of the proposed data structure in improving event extractiontasks, further validating its importance in enhancing the overall performanceof the framework.</description><author>Qizhi Wan, Changxuan Wan, Keli Xiao, Hui Xiong, Dexi Liu, Xiping Liu</author><pubDate>Fri, 30 Jun 2023 16:22:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17733v1</guid></item><item><title>Improved NL2SQL based on Multi-layer Expert Network</title><link>http://arxiv.org/abs/2306.17727v1</link><description>The Natural Language to SQL (NL2SQL) technique is used to convert naturallanguage queries into executable SQL statements. Typically, slot-filling isemployed as a classification method for multi-task cases to achieve this goal.However, slot-filling can result in inaccurate SQL statement generation due tonegative migration issues arising from different classification tasks. Toovercome this limitation, this study introduces a new approach calledMulti-Layer Expert Generate SQL (MLEG-SQL), which utilizes a dedicatedmulti-task hierarchical network. The lower layer of the network extractssemantic features of natural language statements, while the upper layer buildsa specialized expert system for handling specific classification tasks. Thishierarchical approach mitigates performance degradation resulting fromdifferent task conflicts. The proposed method was evaluated on the WiKSQLdataset and was found to be effective in generating accurate SQL statements.</description><author>Chenduo Hao, Xu Zhang</author><pubDate>Fri, 30 Jun 2023 16:16:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17727v1</guid></item><item><title>FlipNeRF: Flipped Reflection Rays for Few-shot Novel View Synthesis</title><link>http://arxiv.org/abs/2306.17723v1</link><description>Neural Radiance Field (NeRF) has been a mainstream in novel view synthesiswith its remarkable quality of rendered images and simple architecture.Although NeRF has been developed in various directions improving continuouslyits performance, the necessity of a dense set of multi-view images still existsas a stumbling block to progress for practical application. In this work, wepropose FlipNeRF, a novel regularization method for few-shot novel viewsynthesis by utilizing our proposed flipped reflection rays. The flippedreflection rays are explicitly derived from the input ray directions andestimated normal vectors, and play a role of effective additional training rayswhile enabling to estimate more accurate surface normals and learn the 3Dgeometry effectively. Since the surface normal and the scene depth are bothderived from the estimated densities along a ray, the accurate surface normalleads to more exact depth estimation, which is a key factor for few-shot novelview synthesis. Furthermore, with our proposed Uncertainty-aware Emptiness Lossand Bottleneck Feature Consistency Loss, FlipNeRF is able to estimate morereliable outputs with reducing floating artifacts effectively across thedifferent scene structures, and enhance the feature-level consistency betweenthe pair of the rays cast toward the photo-consistent pixels without anyadditional feature extractor, respectively. Our FlipNeRF achieves the SOTAperformance on the multiple benchmarks across all the scenarios.</description><author>Seunghyeon Seo, Yeonjin Chang, Nojun Kwak</author><pubDate>Fri, 30 Jun 2023 16:11:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17723v1</guid></item><item><title>Improving Gender Fairness of Pre-Trained Language Models without Catastrophic Forgetting</title><link>http://arxiv.org/abs/2110.05367v3</link><description>Existing studies addressing gender bias of pre-trained language models,usually build a small gender-neutral data set and conduct a second phasepre-training on the model with such data. However, given the limited size andconcentrated focus of the gender-neutral data, catastrophic forgetting wouldoccur during second-phase pre-training. Forgetting information in the originaltraining data may damage the model's downstream performance by a large margin.In this work, we empirically show that catastrophic forgetting occurs in suchmethods by evaluating them with general NLP tasks in GLUE. Then, we propose anew method, GEnder Equality Prompt (GEEP), to improve gender fairness ofpre-trained models with less forgetting. GEEP freezes the pre-trained model andlearns gender-related prompts with gender-neutral data. Empirical results showthat GEEP not only achieves SOTA performances on gender fairness tasks, butalso forgets less and performs better on GLUE by a large margin.</description><author>Zahra Fatemi, Chen Xing, Wenhao Liu, Caiming Xiong</author><pubDate>Fri, 30 Jun 2023 15:52:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2110.05367v3</guid></item><item><title>Why Deep Models Often cannot Beat Non-deep Counterparts on Molecular Property Prediction?</title><link>http://arxiv.org/abs/2306.17702v1</link><description>Molecular property prediction (MPP) is a crucial task in the drug discoverypipeline, which has recently gained considerable attention thanks to advancesin deep neural networks. However, recent research has revealed that deep modelsstruggle to beat traditional non-deep ones on MPP. In this study, we benchmark12 representative models (3 non-deep models and 9 deep models) on 14 moleculedatasets. Through the most comprehensive study to date, we make the followingkey observations: \textbf{(\romannumeral 1)} Deep models are generally unableto outperform non-deep ones; \textbf{(\romannumeral 2)} The failure of deepmodels on MPP cannot be solely attributed to the small size of moleculardatasets. What matters is the irregular molecule data pattern;\textbf{(\romannumeral 3)} In particular, tree models using molecularfingerprints as inputs tend to perform better than other competitors.Furthermore, we conduct extensive empirical investigations into the uniquepatterns of molecule data and inductive biases of various models underlyingthese phenomena.</description><author>Jun Xia, Lecheng Zhang, Xiao Zhu, Stan Z. Li</author><pubDate>Fri, 30 Jun 2023 15:29:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17702v1</guid></item><item><title>An Image Processing approach to identify solar plages observed at 393.37 nm by the Kodaikanal Solar Observatory</title><link>http://arxiv.org/abs/2209.10631v4</link><description>Solar plages, which are bright regions on the Sun's surface, are an importantindicator of solar activity. In this study, we propose an automated algorithmfor identifying solar plages in Ca K wavelength solar data obtained from theKodaikanal Solar Observatory. The algorithm successfully annotates all visuallyidentifiable plages in an image and outputs the corresponding calculated plageindex. We perform a time series analysis of the plage index (rolling mean)across multiple solar cycles to test the algorithm's reliability androbustness. The results show a strong correlation between the calculated plageindex and those reported in a previous study. The correlation coefficientsobtained for all the solar cycles are higher than 0.90, indicating thereliability of the model. We also suggest that adjusting the hyperparametersappropriately for a specific image using our web-based app can increase themodel's efficiency. The algorithm has been deployed on the Streamlit CommunityCloud platform, where users can upload images and customize the hyperparametersfor desired results. The input data used in this study is freely available fromthe KSO data archive, and the code and the generated data are publiclyavailable on our GitHub repository. Our proposed algorithm provides anefficient and reliable method for identifying solar plages, which can aid thestudy of solar activity and its impact on the Earth's climate, technology, andspace weather.</description><author>Sarvesh Gharat, Bhaskar Bose, Abhimanyu Borthakur, Rakesh Mazumder</author><pubDate>Fri, 30 Jun 2023 15:28:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.10631v4</guid></item><item><title>Beyond Neural-on-Neural Approaches to Speaker Gender Protection</title><link>http://arxiv.org/abs/2306.17700v1</link><description>Recent research has proposed approaches that modify speech to defend againstgender inference attacks. The goal of these protection algorithms is to controlthe availability of information about a speaker's gender, a privacy-sensitiveattribute. Currently, the common practice for developing and testing genderprotection algorithms is "neural-on-neural", i.e., perturbations are generatedand tested with a neural network. In this paper, we propose to go beyond thispractice to strengthen the study of gender protection. First, we demonstratethe importance of testing gender inference attacks that are based on speechfeatures historically developed by speech scientists, alongside theconventionally used neural classifiers. Next, we argue that researchers shoulduse speech features to gain insight into how protective modifications changethe speech signal. Finally, we point out that gender-protection algorithmsshould be compared with novel "vocal adversaries", human-executed voiceadaptations, in order to improve interpretability and enable before-the-micprotection.</description><author>Loes van Bemmel, Zhuoran Liu, Nik Vaessen, Martha Larson</author><pubDate>Fri, 30 Jun 2023 15:26:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17700v1</guid></item><item><title>Exploration and Exploitation of Unlabeled Data for Open-Set Semi-Supervised Learning</title><link>http://arxiv.org/abs/2306.17699v1</link><description>In this paper, we address a complex but practical scenario in semi-supervisedlearning (SSL) named open-set SSL, where unlabeled data contain bothin-distribution (ID) and out-of-distribution (OOD) samples. Unlike previousmethods that only consider ID samples to be useful and aim to filter out OODones completely during training, we argue that the exploration and exploitationof both ID and OOD samples can benefit SSL. To support our claim, i) we proposea prototype-based clustering and identification algorithm that explores theinherent similarity and difference among samples at feature level andeffectively cluster them around several predefined ID and OOD prototypes,thereby enhancing feature learning and facilitating ID/OOD identification; ii)we propose an importance-based sampling method that exploits the difference inimportance of each ID and OOD sample to SSL, thereby reducing the sampling biasand improving the training. Our proposed method achieves state-of-the-art inseveral challenging benchmarks, and improves upon existing SSL methods evenwhen ID samples are totally absent in unlabeled data.</description><author>Ganlong Zhao, Guanbin Li, Yipeng Qin, Jinjin Zhang, Zhenhua Chai, Xiaolin Wei, Liang Lin, Yizhou Yu</author><pubDate>Fri, 30 Jun 2023 15:25:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17699v1</guid></item><item><title>Algorithms for bounding contribution for histogram estimation under user-level privacy</title><link>http://arxiv.org/abs/2206.03008v2</link><description>We study the problem of histogram estimation under user-level differentialprivacy, where the goal is to preserve the privacy of all entries of any singleuser. We consider the heterogeneous scenario where the quantity of data can bedifferent for each user. In this scenario, the amount of noise injected intothe histogram to obtain differential privacy is proportional to the maximumuser contribution, which can be amplified by few outliers. One approach tocircumvent this would be to bound (or limit) the contribution of each user tothe histogram. However, if users are limited to small contributions, asignificant amount of data will be discarded. In this work, we proposealgorithms to choose the best user contribution bound for histogram estimationunder both bounded and unbounded domain settings. When the size of the domainis bounded, we propose a user contribution bounding strategy that almostachieves a two-approximation with respect to the best contribution bound inhindsight. For unbounded domain histogram estimation, we propose an algorithmthat is logarithmic-approximation with respect to the best contribution boundin hindsight. This result holds without any distribution assumptions on thedata. Experiments on both real and synthetic datasets verify our theoreticalfindings and demonstrate the effectiveness of our algorithms. We also show thatclipping bias introduced by bounding user contribution may be reduced undermild distribution assumptions, which can be of independent interest.</description><author>Yuhan Liu, Ananda Theertha Suresh, Wennan Zhu, Peter Kairouz, Marco Gruteser</author><pubDate>Fri, 30 Jun 2023 15:21:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.03008v2</guid></item><item><title>A New Task and Dataset on Detecting Attacks on Human Rights Defenders</title><link>http://arxiv.org/abs/2306.17695v1</link><description>The ability to conduct retrospective analyses of attacks on human rightsdefenders over time and by location is important for humanitarian organizationsto better understand historical or ongoing human rights violations and thusbetter manage the global impact of such events. We hypothesize that NLP cansupport such efforts by quickly processing large collections of news articlesto detect and summarize the characteristics of attacks on human rightsdefenders. To that end, we propose a new dataset for detecting Attacks on HumanRights Defenders (HRDsAttack) consisting of crowdsourced annotations on 500online news articles. The annotations include fine-grained information aboutthe type and location of the attacks, as well as information about thevictim(s). We demonstrate the usefulness of the dataset by using it to trainand evaluate baseline models on several sub-tasks to predict the annotatedcharacteristics.</description><author>Shihao Ran, Di Lu, Joel Tetreault, Aoife Cahill, Alejandro Jaimes</author><pubDate>Fri, 30 Jun 2023 15:20:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17695v1</guid></item><item><title>Thompson sampling for improved exploration in GFlowNets</title><link>http://arxiv.org/abs/2306.17693v1</link><description>Generative flow networks (GFlowNets) are amortized variational inferencealgorithms that treat sampling from a distribution over compositional objectsas a sequential decision-making problem with a learnable action policy. Unlikeother algorithms for hierarchical sampling that optimize a variational bound,GFlowNet algorithms can stably run off-policy, which can be advantageous fordiscovering modes of the target distribution. Despite this flexibility in thechoice of behaviour policy, the optimal way of efficiently selectingtrajectories for training has not yet been systematically explored. In thispaper, we view the choice of trajectories for training as an active learningproblem and approach it using Bayesian techniques inspired by methods formulti-armed bandits. The proposed algorithm, Thompson sampling GFlowNets(TS-GFN), maintains an approximate posterior distribution over policies andsamples trajectories from this posterior for training. We show in two domainsthat TS-GFN yields improved exploration and thus faster convergence to thetarget distribution than the off-policy exploration strategies used in pastwork.</description><author>Jarrid Rector-Brooks, Kanika Madan, Moksh Jain, Maksym Korablyov, Cheng-Hao Liu, Sarath Chandar, Nikolay Malkin, Yoshua Bengio</author><pubDate>Fri, 30 Jun 2023 15:19:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17693v1</guid></item><item><title>Generalized Time Warping Invariant Dictionary Learning for Time Series Classification and Clustering</title><link>http://arxiv.org/abs/2306.17690v1</link><description>Dictionary learning is an effective tool for pattern recognition andclassification of time series data. Among various dictionary learningtechniques, the dynamic time warping (DTW) is commonly used for dealing withtemporal delays, scaling, transformation, and many other kinds of temporalmisalignments issues. However, the DTW suffers overfitting or information lossdue to its discrete nature in aligning time series data. To address this issue,we propose a generalized time warping invariant dictionary learning algorithmin this paper. Our approach features a generalized time warping operator, whichconsists of linear combinations of continuous basis functions for facilitatingcontinuous temporal warping. The integration of the proposed operator and thedictionary learning is formulated as an optimization problem, where the blockcoordinate descent method is employed to jointly optimize warping paths,dictionaries, and sparseness coefficients. The optimized results are then usedas hyperspace distance measures to feed classification and clusteringalgorithms. The superiority of the proposed method in terms of dictionarylearning, classification, and clustering is validated through ten sets ofpublic datasets in comparing with various benchmark methods.</description><author>Ruiyu Xu, Chao Wang, Yongxiang Li, Jianguo Wu</author><pubDate>Fri, 30 Jun 2023 15:18:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17690v1</guid></item><item><title>Selecting Robust Features for Machine Learning Applications using Multidata Causal Discovery</title><link>http://arxiv.org/abs/2304.05294v5</link><description>Robust feature selection is vital for creating reliable and interpretableMachine Learning (ML) models. When designing statistical prediction models incases where domain knowledge is limited and underlying interactions areunknown, choosing the optimal set of features is often difficult. To mitigatethis issue, we introduce a Multidata (M) causal feature selection approach thatsimultaneously processes an ensemble of time series datasets and produces asingle set of causal drivers. This approach uses the causal discoveryalgorithms PC1 or PCMCI that are implemented in the Tigramite Python package.These algorithms utilize conditional independence tests to infer parts of thecausal graph. Our causal feature selection approach filters outcausally-spurious links before passing the remaining causal features as inputsto ML models (Multiple linear regression, Random Forest) that predict thetargets. We apply our framework to the statistical intensity prediction ofWestern Pacific Tropical Cyclones (TC), for which it is often difficult toaccurately choose drivers and their dimensionality reduction (time lags,vertical levels, and area-averaging). Using more stringent significancethresholds in the conditional independence tests helps eliminate spuriouscausal relationships, thus helping the ML model generalize better to unseen TCcases. M-PC1 with a reduced number of features outperforms M-PCMCI, non-causalML, and other feature selection methods (lagged correlation, random), evenslightly outperforming feature selection based on eXplainable ArtificialIntelligence. The optimal causal drivers obtained from our causal featureselection help improve our understanding of underlying relationships andsuggest new potential drivers of TC intensification.</description><author>Saranya Ganesh S., Tom Beucler, Frederick Iat-Hin Tam, Milton S. Gomez, Jakob Runge, Andreas Gerhardus</author><pubDate>Fri, 30 Jun 2023 15:14:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05294v5</guid></item><item><title>Multimodal Prompt Retrieval for Generative Visual Question Answering</title><link>http://arxiv.org/abs/2306.17675v1</link><description>Recent years have witnessed impressive results of pre-trained vision-languagemodels on knowledge-intensive tasks such as visual question answering (VQA).Despite the recent advances in VQA, existing methods mainly adopt adiscriminative formulation that predicts answers within a pre-defined labelset, leading to easy overfitting on low-resource domains with limited labeleddata (e.g., medicine) and poor generalization under domain shift to anotherdataset. To tackle this limitation, we propose a novel generative modelenhanced by multimodal prompt retrieval (MPR) that integrates retrieved promptsand multimodal features to generate answers in free text. Our generative modelenables rapid zero-shot dataset adaptation to unseen data distributions andopen-set answer labels across datasets. Our experiments on medical VQA tasksshow that MPR outperforms its non-retrieval counterpart by up to 30% accuracypoints in a few-shot domain adaptation setting.</description><author>Timothy Ossowski, Junjie Hu</author><pubDate>Fri, 30 Jun 2023 15:06:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17675v1</guid></item><item><title>X-RiSAWOZ: High-Quality End-to-End Multilingual Dialogue Datasets and Few-shot Agents</title><link>http://arxiv.org/abs/2306.17674v1</link><description>Task-oriented dialogue research has mainly focused on a few popular languageslike English and Chinese, due to the high dataset creation cost for a newlanguage. To reduce the cost, we apply manual editing to automaticallytranslated data. We create a new multilingual benchmark, X-RiSAWOZ, bytranslating the Chinese RiSAWOZ to 4 languages: English, French, Hindi, Korean;and a code-mixed English-Hindi language. X-RiSAWOZ has more than 18,000human-verified dialogue utterances for each language, and unlike mostmultilingual prior work, is an end-to-end dataset for buildingfully-functioning agents. The many difficulties we encountered in creating X-RiSAWOZ led us to developa toolset to accelerate the post-editing of a new language dataset aftertranslation. This toolset improves machine translation with a hybrid entityalignment technique that combines neural with dictionary-based methods, alongwith many automated and semi-automated validation checks. We establish strong baselines for X-RiSAWOZ by training dialogue agents inthe zero- and few-shot settings where limited gold data is available in thetarget language. Our results suggest that our translation and post-editingmethodology and toolset can be used to create new high-quality multilingualdialogue agents cost-effectively. Our dataset, code, and toolkit are releasedopen-source.</description><author>Mehrad Moradshahi, Tianhao Shen, Kalika Bali, Monojit Choudhury, Gaël de Chalendar, Anmol Goel, Sungkyun Kim, Prashant Kodali, Ponnurangam Kumaraguru, Nasredine Semmar, Sina J. Semnani, Jiwon Seo, Vivek Seshadri, Manish Shrivastava, Michael Sun, Aditya Yadavalli, Chaobin You, Deyi Xiong, Monica S. Lam</author><pubDate>Fri, 30 Jun 2023 15:03:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17674v1</guid></item><item><title>Learning Delays in Spiking Neural Networks using Dilated Convolutions with Learnable Spacings</title><link>http://arxiv.org/abs/2306.17670v1</link><description>Spiking Neural Networks (SNNs) are a promising research direction forbuilding power-efficient information processing systems, especially fortemporal tasks such as speech recognition. In SNNs, delays refer to the timeneeded for one spike to travel from one neuron to another. These delays matterbecause they influence the spike arrival times, and it is well-known thatspiking neurons respond more strongly to coincident input spikes. Moreformally, it has been shown theoretically that plastic delays greatly increasethe expressivity in SNNs. Yet, efficient algorithms to learn these delays havebeen lacking. Here, we propose a new discrete-time algorithm that addressesthis issue in deep feedforward SNNs using backpropagation, in an offlinemanner. To simulate delays between consecutive layers, we use 1D convolutionsacross time. The kernels contain only a few non-zero weights - one per synapse- whose positions correspond to the delays. These positions are learnedtogether with the weights using the recently proposed Dilated Convolution withLearnable Spacings (DCLS). We evaluated our method on the Spiking HeidelbergDataset (SHD) and the Spiking Speech Commands (SSC) benchmarks, which requiredetecting temporal patterns. We used feedforward SNNs with two hidden fullyconnected layers. We showed that fixed random delays help, and that learningthem helps even more. Furthermore, our method outperformed the state-of-the-artin both SHD and SSC without using recurrent connections and with substantiallyfewer parameters. Our work demonstrates the potential of delay learning indeveloping accurate and precise models for temporal data processing. Our codeis based on PyTorch / SpikingJelly and available at:https://github.com/Thvnvtos/SNN-delays</description><author>Ilyass Hammouamri, Ismail Khalfaoui-Hassani, Timothée Masquelier</author><pubDate>Fri, 30 Jun 2023 15:01:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17670v1</guid></item><item><title>Identity Construction in a Misogynist Incels Forum</title><link>http://arxiv.org/abs/2306.15745v2</link><description>Online communities of involuntary celibates (incels) are a prominent sourceof misogynist hate speech. In this paper, we use quantitative text and networkanalysis approaches to examine how identity groups are discussed on&lt;incels.is&gt;, the largest black-pilled incels forum. We find that this communityproduces a wide range of novel identity terms and, while terms for women aremost common, mentions of other minoritized identities are increasing. Ananalysis of the associations made with identity groups suggests an essentialistideology where physical appearance, as well as gender and racial hierarchies,determine human value. We discuss implications for research into automatedmisogynist hate speech detection.</description><author>Michael Miller Yoder, Chloe Perry, David West Brown, Kathleen M. Carley, Meredith Pruden</author><pubDate>Fri, 30 Jun 2023 15:00:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15745v2</guid></item><item><title>Multiobjective Logistics Optimization for Automated ATM Cash Replenishment Process</title><link>http://arxiv.org/abs/2304.13671v4</link><description>In the digital transformation era, integrating digital technology into everyaspect of banking operations improves process automation, cost efficiency, andservice level improvement. Although logistics for ATM cash is a crucial taskthat impacts operating costs and consumer satisfaction, there has been littleeffort to enhance it. Specifically, in Vietnam, with a market of more than20,000 ATMs nationally, research and technological solutions that can resolvethis issue remain scarce. In this paper, we generalized the vehicle routingproblem for ATM cash replenishment, suggested a mathematical model and thenoffered a tool to evaluate various situations. When being evaluated on thesimulated dataset, our proposed model and method produced encouraging resultswith the benefits of cutting ATM cash operating costs.</description><author>Bui Tien Thanh, Dinh Van Tuan, Tuan Anh Chi, Nguyen Van Dai, Nguyen Tai Quang Dinh, Nguyen Thu Thuy</author><pubDate>Fri, 30 Jun 2023 14:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13671v4</guid></item><item><title>Zero-shot Nuclei Detection via Visual-Language Pre-trained Models</title><link>http://arxiv.org/abs/2306.17659v1</link><description>Large-scale visual-language pre-trained models (VLPM) have proven theirexcellent performance in downstream object detection for natural scenes.However, zero-shot nuclei detection on H\&amp;E images via VLPMs remainsunderexplored. The large gap between medical images and the web-originatedtext-image pairs used for pre-training makes it a challenging task. In thispaper, we attempt to explore the potential of the object-level VLPM, GroundedLanguage-Image Pre-training (GLIP) model, for zero-shot nuclei detection.Concretely, an automatic prompts design pipeline is devised based on theassociation binding trait of VLPM and the image-to-text VLPM BLIP, avoidingempirical manual prompts engineering. We further establish a self-trainingframework, using the automatically designed prompts to generate the preliminaryresults as pseudo labels from GLIP and refine the predicted boxes in aniterative manner. Our method achieves a remarkable performance for label-freenuclei detection, surpassing other comparison methods. Foremost, our workdemonstrates that the VLPM pre-trained on natural image-text pairs exhibitsastonishing potential for downstream tasks in the medical field as well. Codewill be released at https://github.com/wuyongjianCODE/VLPMNuD.</description><author>Yongjian Wu, Yang Zhou, Jiya Saiyin, Bingzheng Wei, Maode Lai, Jianzhong Shou, Yubo Fan, Yan Xu</author><pubDate>Fri, 30 Jun 2023 14:44:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17659v1</guid></item><item><title>Implicit 3D Human Mesh Recovery using Consistency with Pose and Shape from Unseen-view</title><link>http://arxiv.org/abs/2306.17651v1</link><description>From an image of a person, we can easily infer the natural 3D pose and shapeof the person even if ambiguity exists. This is because we have a mental modelthat allows us to imagine a person's appearance at different viewing directionsfrom a given image and utilize the consistency between them for inference.However, existing human mesh recovery methods only consider the direction inwhich the image was taken due to their structural limitations. Hence, wepropose "Implicit 3D Human Mesh Recovery (ImpHMR)" that can implicitly imaginea person in 3D space at the feature-level via Neural Feature Fields. In ImpHMR,feature fields are generated by CNN-based image encoder for a given image.Then, the 2D feature map is volume-rendered from the feature field for a givenviewing direction, and the pose and shape parameters are regressed from thefeature. To utilize consistency with pose and shape from unseen-view, if thereare 3D labels, the model predicts results including the silhouette from anarbitrary direction and makes it equal to the rotated ground-truth. In the caseof only 2D labels, we perform self-supervised learning through the constraintthat the pose and shape parameters inferred from different directions should bethe same. Extensive evaluations show the efficacy of the proposed method.</description><author>Hanbyel Cho, Yooshin Cho, Jaesung Ahn, Junmo Kim</author><pubDate>Fri, 30 Jun 2023 14:37:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17651v1</guid></item><item><title>Biomedical Language Models are Robust to Sub-optimal Tokenization</title><link>http://arxiv.org/abs/2306.17649v1</link><description>As opposed to general English, many concepts in biomedical terminology havebeen designed in recent history by biomedical professionals with the goal ofbeing precise and concise. This is often achieved by concatenating meaningfulbiomedical morphemes to create new semantic units. Nevertheless, most modernbiomedical language models (LMs) are pre-trained using standard domain-specifictokenizers derived from large scale biomedical corpus statistics withoutexplicitly leveraging the agglutinating nature of biomedical language. In thiswork, we first find that standard open-domain and biomedical tokenizers arelargely unable to segment biomedical terms into meaningful components.Therefore, we hypothesize that using a tokenizer which segments biomedicalterminology more accurately would enable biomedical LMs to improve theirperformance on downstream biomedical NLP tasks, especially ones which involvebiomedical terms directly such as named entity recognition (NER) and entitylinking. Surprisingly, we find that pre-training a biomedical LM using a moreaccurate biomedical tokenizer does not improve the entity representationquality of a language model as measured by several intrinsic and extrinsicmeasures such as masked language modeling prediction (MLM) accuracy as well asNER and entity linking performance. These quantitative findings, along with acase study which explores entity representation quality more directly, suggestthat the biomedical pre-training process is quite robust to instances ofsub-optimal tokenization.</description><author>Bernal Jiménez Gutiérrez, Huan Sun, Yu Su</author><pubDate>Fri, 30 Jun 2023 14:35:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17649v1</guid></item><item><title>Enhancing training of physics-informed neural networks using domain-decomposition based preconditioning strategies</title><link>http://arxiv.org/abs/2306.17648v1</link><description>We propose to enhance the training of physics-informed neural networks(PINNs). To this aim, we introduce nonlinear additive and multiplicativepreconditioning strategies for the widely used L-BFGS optimizer. The nonlinearpreconditioners are constructed by utilizing the Schwarz domain-decompositionframework, where the parameters of the network are decomposed in a layer-wisemanner. Through a series of numerical experiments, we demonstrate that both,additive and multiplicative preconditioners significantly improve theconvergence of the standard L-BFGS optimizer, while providing more accuratesolutions of the underlying partial differential equations. Moreover, theadditive preconditioner is inherently parallel, thus giving rise to a novelapproach to model parallelism.</description><author>Alena Kopaničáková, Hardik Kothari, George Em Karniadakis, Rolf Krause</author><pubDate>Fri, 30 Jun 2023 14:35:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17648v1</guid></item><item><title>Feature Representation Learning for NL2SQL Generation Based on Coupling and Decoupling</title><link>http://arxiv.org/abs/2306.17646v1</link><description>The NL2SQL task involves parsing natural language statements into SQLqueries. While most state-of-the-art methods treat NL2SQL as a slot-fillingtask and use feature representation learning techniques, they overlook explicitcorrelation features between the SELECT and WHERE clauses and implicitcorrelation features between sub-tasks within a single clause. To address thisissue, we propose the Clause Feature Correlation Decoupling and Coupling(CFCDC) model, which uses a feature representation decoupling method toseparate the SELECT and WHERE clauses at the parameter level. Next, weintroduce a multi-task learning architecture to decouple implicit correlationfeature representation between different SQL tasks in a specific clause.Moreover, we present an improved feature representation coupling module tointegrate the decoupled tasks in the SELECT and WHERE clauses and predict thefinal SQL query. Our proposed CFCDC model demonstrates excellent performance onthe WikiSQL dataset, with significant improvements in logic precision andexecution accuracy. The source code for the model will be publicly available onGitHub</description><author>Chenduo Hao, Xu Zhang, Chuanbao Gao, Deyu Zhou</author><pubDate>Fri, 30 Jun 2023 14:34:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17646v1</guid></item><item><title>Improving Expert Predictions with Conformal Prediction</title><link>http://arxiv.org/abs/2201.12006v5</link><description>Automated decision support systems promise to help human experts solvemulticlass classification tasks more efficiently and accurately. However,existing systems typically require experts to understand when to cede agency tothe system or when to exercise their own agency. Otherwise, the experts may bebetter off solving the classification tasks on their own. In this work, wedevelop an automated decision support system that, by design, does not requireexperts to understand when to trust the system to improve performance. Ratherthan providing (single) label predictions and letting experts decide when totrust these predictions, our system provides sets of label predictionsconstructed using conformal prediction$\unicode{x2014}$predictionsets$\unicode{x2014}$and forcefully asks experts to predict labels from thesesets. By using conformal prediction, our system can precisely trade-off theprobability that the true label is not in the prediction set, which determineshow frequently our system will mislead the experts, and the size of theprediction set, which determines the difficulty of the classification task theexperts need to solve using our system. In addition, we develop an efficientand near-optimal search method to find the conformal predictor under which theexperts benefit the most from using our system. Simulation experiments usingsynthetic and real expert predictions demonstrate that our system may helpexperts make more accurate predictions and is robust to the accuracy of theclassifier the conformal predictor relies on.</description><author>Eleni Straitouri, Lequn Wang, Nastaran Okati, Manuel Gomez Rodriguez</author><pubDate>Fri, 30 Jun 2023 14:33:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.12006v5</guid></item><item><title>Federated Object Detection for Quality Inspection in Shared Production</title><link>http://arxiv.org/abs/2306.17645v1</link><description>Federated learning (FL) has emerged as a promising approach for trainingmachine learning models on decentralized data without compromising dataprivacy. In this paper, we propose a FL algorithm for object detection inquality inspection tasks using YOLOv5 as the object detection algorithm andFederated Averaging (FedAvg) as the FL algorithm. We apply this approach to amanufacturing use-case where multiple factories/clients contribute data fortraining a global object detection model while preserving data privacy on anon-IID dataset. Our experiments demonstrate that our FL approach achievesbetter generalization performance on the overall clients' test dataset andgenerates improved bounding boxes around the objects compared to models trainedusing local clients' datasets. This work showcases the potential of FL forquality inspection tasks in the manufacturing industry and provides valuableinsights into the performance and feasibility of utilizing YOLOv5 and FedAvgfor federated object detection.</description><author>Vinit Hegiste, Tatjana Legler, Martin Ruskowski</author><pubDate>Fri, 30 Jun 2023 14:33:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17645v1</guid></item><item><title>Categorical Approach to Conflict Resolution: Integrating Category Theory into the Graph Model for Conflict Resolution</title><link>http://arxiv.org/abs/2306.13961v2</link><description>This paper introduces the Categorical Graph Model for Conflict Resolution(C-GMCR), a novel framework that integrates category theory into thetraditional Graph Model for Conflict Resolution (GMCR). The C-GMCR frameworkprovides a more abstract and general way to model and analyze conflictresolution, enabling researchers to uncover deeper insights and connections. Wepresent the basic concepts, methods, and application of the C-GMCR framework tothe well-known Prisoner's Dilemma and other representative cases. The findingssuggest that the categorical approach offers new perspectives on stabilityconcepts and can potentially lead to the development of more effective conflictresolution strategies.</description><author>Yukiko Kato</author><pubDate>Fri, 30 Jun 2023 14:33:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13961v2</guid></item><item><title>Neural 3D Scene Reconstruction from Multi-view Images without 3D Supervision</title><link>http://arxiv.org/abs/2306.17643v1</link><description>Neural scene reconstruction methods have achieved impressive performance inreconstructing complex geometry and low-textured regions in large scenes.However, these methods heavily rely on 3D supervised information which iscostly and time-consuming to obtain in the real world. In this paper, wepropose a novel neural reconstruction method that reconstructs scenes without3D supervision. We perform differentiable volume rendering for scenereconstruction by using accessible 2D images as supervision. We impose geometryto improve the reconstruction quality of complex geometry regions in thescenes, and impose plane constraints to improve the reconstruction quality oflow-textured regions in the scenes. Specifically, we introduce a signeddistance function (SDF) field, a color field, and a probability field torepresent the scene, and optimize the fields under the differentiable raymarching to reconstruct the scene. Besides, we impose geometric constraintsthat project 3D points on the surface to similar-looking regions with similarfeatures in different views. We also impose plane constraints to make largeplanes keep parallel or vertical to the wall or floor. These two constraintshelp to reconstruct accurate and smooth geometry structures of the scene.Without 3D supervision information, our method achieves competitivereconstruction compared with some existing methods that use 3D information assupervision on the ScanNet dataset.</description><author>Yi Guo, Che Sun, Yunde Jia, Yuwei Wu</author><pubDate>Fri, 30 Jun 2023 14:30:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17643v1</guid></item><item><title>Point-based Value Iteration for Neuro-Symbolic POMDPs</title><link>http://arxiv.org/abs/2306.17639v1</link><description>Neuro-symbolic artificial intelligence is an emerging area that combinestraditional symbolic techniques with neural networks. In this paper, weconsider its application to sequential decision making under uncertainty. Weintroduce neuro-symbolic partially observable Markov decision processes(NS-POMDPs), which model an agent that perceives a continuous-state environmentusing a neural network and makes decisions symbolically, and study the problemof optimising discounted cumulative rewards. This requires functions overcontinuous-state beliefs, for which we propose a novel piecewise linear andconvex representation (P-PWLC) in terms of polyhedra covering thecontinuous-state space and value vectors, and extend Bellman backups to thisrepresentation. We prove the convexity and continuity of value functions andpresent two value iteration algorithms that ensure finite representability byexploiting the underlying structure of the continuous-state model and theneural perception mechanism. The first is a classical (exact) value iterationalgorithm extending $\alpha$-functions of Porta et al (2006) to the P-PWLCrepresentation for continuous-state spaces. The second is a point-based(approximate) method called NS-HSVI, which uses the P-PWLC representation andbelief-value induced functions to approximate value functions from below andabove for two types of beliefs, particle-based and region-based. Using aprototype implementation, we show the practical applicability of our approachon two case studies that employ (trained) ReLU neural networks as perceptionfunctions, dynamic car parking and an aircraft collision avoidance system, bysynthesising (approximately) optimal strategies. An experimental comparisonwith the finite-state POMDP solver SARSOP demonstrates that NS-HSVI is morerobust to particle disturbances.</description><author>Rui Yan, Gabriel Santos, Gethin Norman, David Parker, Marta Kwiatkowska</author><pubDate>Fri, 30 Jun 2023 14:26:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17639v1</guid></item><item><title>Geometric Autoencoders -- What You See is What You Decode</title><link>http://arxiv.org/abs/2306.17638v1</link><description>Visualization is a crucial step in exploratory data analysis. One possibleapproach is to train an autoencoder with low-dimensional latent space. Largenetwork depth and width can help unfolding the data. However, such expressivenetworks can achieve low reconstruction error even when the latentrepresentation is distorted. To avoid such misleading visualizations, wepropose first a differential geometric perspective on the decoder, leading toinsightful diagnostics for an embedding's distortion, and second a newregularizer mitigating such distortion. Our ``Geometric Autoencoder'' avoidsstretching the embedding spuriously, so that the visualization captures thedata structure more faithfully. It also flags areas where little distortioncould not be achieved, thus guarding against misinterpretation.</description><author>Philipp Nazari, Sebastian Damrich, Fred A. Hamprecht</author><pubDate>Fri, 30 Jun 2023 14:24:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17638v1</guid></item><item><title>Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering</title><link>http://arxiv.org/abs/2304.13911v2</link><description>We investigate how to enhance answer precision in frequently asked questionsposed by distributed users using cloud-based Large Language Models (LLMs). Ourstudy focuses on a typical situations where users ask similar queries thatinvolve identical mathematical reasoning steps and problem-solving procedures.Due to the unsatisfactory accuracy of LLMs' zero-shot prompting with standalonequestions, we propose to improve the distributed synonymous questions usingSelf-Consistency (SC) and Chain-of-Thought (CoT) techniques. Specifically, wefirst retrieve synonymous questions from a crowd-sourced database and create afederated question pool. We call these federated synonymous questions with thesame or different parameters SP-questions or DP-questions, respectively. Werefer to our methods as Fed-SP-SC and Fed-DP-CoT, which can generatesignificantly more accurate answers for all user queries without requiringsophisticated model-tuning. Through extensive experiments, we demonstrate thatour proposed methods can significantly enhance question accuracy by fullyexploring the synonymous nature of the questions and the consistency of theanswers.</description><author>Xiangyang Liu, Tianqi Pang, Chenyou Fan</author><pubDate>Fri, 30 Jun 2023 14:21:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13911v2</guid></item><item><title>Self-Adjusting Weighted Expected Improvement for Bayesian Optimization</title><link>http://arxiv.org/abs/2306.04262v3</link><description>Bayesian Optimization (BO) is a class of surrogate-based, sample-efficientalgorithms for optimizing black-box problems with small evaluation budgets. TheBO pipeline itself is highly configurable with many different design choicesregarding the initial design, surrogate model, and acquisition function (AF).Unfortunately, our understanding of how to select suitable components for aproblem at hand is very limited. In this work, we focus on the definition ofthe AF, whose main purpose is to balance the trade-off between exploringregions with high uncertainty and those with high promise for good solutions.We propose Self-Adjusting Weighted Expected Improvement (SAWEI), where we letthe exploration-exploitation trade-off self-adjust in a data-driven manner,based on a convergence criterion for BO. On the noise-free black-box BBOBfunctions of the COCO benchmarking platform, our method exhibits a favorableany-time performance compared to handcrafted baselines and serves as a robustdefault choice for any problem structure. The suitability of our method alsotransfers to HPOBench. With SAWEI, we are a step closer to on-the-fly,data-driven, and robust BO designs that automatically adjust their samplingbehavior to the problem at hand.</description><author>Carolin Benjamins, Elena Raponi, Anja Jankovic, Carola Doerr, Marius Lindauer</author><pubDate>Fri, 30 Jun 2023 14:18:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04262v3</guid></item><item><title>Robust Implicit Regularization via Weight Normalization</title><link>http://arxiv.org/abs/2305.05448v2</link><description>Overparameterized models may have many interpolating solutions; implicitregularization refers to the hidden preference of a particular optimizationmethod towards a certain interpolating solution among the many. A by nowestablished line of work has shown that (stochastic) gradient descent tends tohave an implicit bias towards low rank and/or sparse solutions when used totrain deep linear networks, explaining to some extent why overparameterizedneural network models trained by gradient descent tend to have goodgeneralization performance in practice. However, existing theory forsquare-loss objectives often requires very small initialization of thetrainable weights, which is at odds with the larger scale at which weights areinitialized in practice for faster convergence and better generalizationperformance. In this paper, we aim to close this gap by incorporating andanalyzing gradient descent with weight normalization, where the weight vectoris reparamterized in terms of polar coordinates, and gradient descent isapplied to the polar coordinates. By analyzing key invariants of the gradientflow and using Lojasiewicz's Theorem, we show that weight normalization alsohas an implicit bias towards sparse solutions in the diagonal linear model, butthat in contrast to plain gradient descent, weight normalization enables arobust bias that persists even if the weights are initialized at practicallylarge scale. Experiments suggest that the gains in both convergence speed androbustness of the implicit bias are improved dramatically by using weightnormalization in overparameterized diagonal linear network models.</description><author>Hung-Hsu Chou, Holger Rauhut, Rachel Ward</author><pubDate>Fri, 30 Jun 2023 14:17:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05448v2</guid></item><item><title>Learning Homeomorphic Image Registration via Conformal-Invariant Hyperelastic Regularisation</title><link>http://arxiv.org/abs/2303.08113v2</link><description>Deformable image registration is a fundamental task in medical image analysisand plays a crucial role in a wide range of clinical applications. Recently,deep learning-based approaches have been widely studied for deformable medicalimage registration and achieved promising results. However, existing deeplearning image registration techniques do not theoretically guaranteetopology-preserving transformations. This is a key property to preserveanatomical structures and achieve plausible transformations that can be used inreal clinical settings. We propose a novel framework for deformable imageregistration. Firstly, we introduce a novel regulariser based onconformal-invariant properties in a nonlinear elasticity setting. Ourregulariser enforces the deformation field to be smooth, invertible andorientation-preserving. More importantly, we strictly guarantee topologypreservation yielding to a clinical meaningful registration. Secondly, we boostthe performance of our regulariser through coordinate MLPs, where one can viewthe to-be-registered images as continuously differentiable entities. Wedemonstrate, through numerical and visual experiments, that our framework isable to outperform current techniques for image registration.</description><author>Jing Zou, Noémie Debroux, Lihao Liu, Jing Qin, Carola-Bibiane Schönlieb, Angelica I Aviles-Rivero</author><pubDate>Fri, 30 Jun 2023 14:15:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.08113v2</guid></item><item><title>Achieving RGB-D level Segmentation Performance from a Single ToF Camera</title><link>http://arxiv.org/abs/2306.17636v1</link><description>Depth is a very important modality in computer vision, typically used ascomplementary information to RGB, provided by RGB-D cameras. In this work, weshow that it is possible to obtain the same level of accuracy as RGB-D camerason a semantic segmentation task using infrared (IR) and depth images from asingle Time-of-Flight (ToF) camera. In order to fuse the IR and depthmodalities of the ToF camera, we introduce a method utilizing depth-specificconvolutions in a multi-task learning framework. In our evaluation on an in-carsegmentation dataset, we demonstrate the competitiveness of our method againstthe more costly RGB-D approaches.</description><author>Pranav Sharma, Jigyasa Singh Katrolia, Jason Rambach, Bruno Mirbach, Didier Stricker, Juergen Seiler</author><pubDate>Fri, 30 Jun 2023 14:14:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17636v1</guid></item><item><title>Limits of Model Selection under Transfer Learning</title><link>http://arxiv.org/abs/2305.00152v3</link><description>Theoretical studies on transfer learning or domain adaptation have so farfocused on situations with a known hypothesis class or model; however inpractice, some amount of model selection is usually involved, often appearingunder the umbrella term of hyperparameter-tuning: for example, one may think ofthe problem of tuning for the right neural network architecture towards atarget task, while leveraging data from a related source task. Now, in addition to the usual tradeoffs on approximation vs estimation errorsinvolved in model selection, this problem brings in a new complexity term,namely, the transfer distance between source and target distributions, which isknown to vary with the choice of hypothesis class. We present a first study of this problem, focusing on classification; inparticular, the analysis reveals some remarkable phenomena: adaptive rates,i.e., those achievable with no distributional information, can be arbitrarilyslower than oracle rates, i.e., when given knowledge on distances.</description><author>Steve Hanneke, Samory Kpotufe, Yasaman Mahdaviyeh</author><pubDate>Fri, 30 Jun 2023 14:12:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.00152v3</guid></item><item><title>String Diagrams with Factorized Densities</title><link>http://arxiv.org/abs/2305.02506v3</link><description>A growing body of research on probabilistic programs and causal models hashighlighted the need to reason compositionally about model classes that extenddirected graphical models. Both probabilistic programs and causal models definea joint probability density over a set of random variables, and exhibit sparsestructure that can be used to reason about causation and conditionalindependence. This work builds on recent work on Markov categories ofprobabilistic mappings to define a category whose morphisms combine a jointdensity, factorized over each sample space, with a deterministic mapping fromsamples to return values. This is a step towards closing the gap between recentcategory-theoretic descriptions of probability measures, and the operationaldefinitions of factorized densities that are commonly employed in probabilisticprogramming and causal inference.</description><author>Eli Sennesh, Jan-Willem van de Meent</author><pubDate>Fri, 30 Jun 2023 14:10:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.02506v3</guid></item><item><title>GEC: A Unified Framework for Interactive Decision Making in MDP, POMDP, and Beyond</title><link>http://arxiv.org/abs/2211.01962v4</link><description>We study sample efficient reinforcement learning (RL) under the generalframework of interactive decision making, which includes Markov decisionprocess (MDP), partially observable Markov decision process (POMDP), andpredictive state representation (PSR) as special cases. Toward finding theminimum assumption that empowers sample efficient learning, we propose a novelcomplexity measure, generalized eluder coefficient (GEC), which characterizesthe fundamental tradeoff between exploration and exploitation in onlineinteractive decision making. In specific, GEC captures the hardness ofexploration by comparing the error of predicting the performance of the updatedpolicy with the in-sample training error evaluated on the historical data. Weshow that RL problems with low GEC form a remarkably rich class, which subsumeslow Bellman eluder dimension problems, bilinear class, low witness rankproblems, PO-bilinear class, and generalized regular PSR, where generalizedregular PSR, a new tractable PSR class identified by us, includes nearly allknown tractable POMDPs and PSRs. Furthermore, in terms of algorithm design, wepropose a generic posterior sampling algorithm, which can be implemented inboth model-free and model-based fashion, under both fully observable andpartially observable settings. The proposed algorithm modifies the standardposterior sampling algorithm in two aspects: (i) we use an optimistic priordistribution that biases towards hypotheses with higher values and (ii) aloglikelihood function is set to be the empirical loss evaluated on thehistorical data, where the choice of loss function supports both model-free andmodel-based learning. We prove that the proposed algorithm is sample efficientby establishing a sublinear regret upper bound in terms of GEC. In summary, weprovide a new and unified understanding of both fully observable and partiallyobservable RL.</description><author>Han Zhong, Wei Xiong, Sirui Zheng, Liwei Wang, Zhaoran Wang, Zhuoran Yang, Tong Zhang</author><pubDate>Fri, 30 Jun 2023 14:05:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.01962v4</guid></item><item><title>Impact of Noise on Calibration and Generalisation of Neural Networks</title><link>http://arxiv.org/abs/2306.17630v1</link><description>Noise injection and data augmentation strategies have been effective forenhancing the generalisation and robustness of neural networks (NNs). Certaintypes of noise such as label smoothing and MixUp have also been shown toimprove calibration. Since noise can be added in various stages of the NN'straining, it motivates the question of when and where the noise is the mosteffective. We study a variety of noise types to determine how much they improvecalibration and generalisation, and under what conditions. More specifically weevaluate various noise-injection strategies in both in-distribution (ID) andout-of-distribution (OOD) scenarios. The findings highlight that activationnoise was the most transferable and effective in improving generalisation,while input augmentation noise was prominent in improving calibration on OODbut not necessarily ID data.</description><author>Martin Ferianc, Ondrej Bohdal, Timothy Hospedales, Miguel Rodrigues</author><pubDate>Fri, 30 Jun 2023 14:04:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17630v1</guid></item><item><title>Sequential Recommendation Model for Next Purchase Prediction</title><link>http://arxiv.org/abs/2207.06225v2</link><description>Timeliness and contextual accuracy of recommendations are increasinglyimportant when delivering contemporary digital marketing experiences.Conventional recommender systems (RS) suggest relevant but time-invariant itemsto users by accounting for their past purchases. These recommendations only mapto customers' general preferences rather than a customer's specific needsimmediately preceding a purchase. In contrast, RSs that consider the order oftransactions, purchases, or experiences to measure evolving preferences canoffer more salient and effective recommendations to customers: Sequential RSsnot only benefit from a better behavioral understanding of a user's currentneeds but also better predictive power. In this paper, we demonstrate and rankthe effectiveness of a sequential recommendation system by utilizing aproduction dataset of over 2.7 million credit card transactions for 46Kcardholders. The method first employs an autoencoder on raw transaction dataand submits observed transaction encodings to a GRU-based sequential model. Thesequential model produces a MAP@1 metric of 47% on the out-of-sample test set,in line with existing research. We also discuss implications for embeddingreal-time predictions using the sequential RS into Nexus, a scalable,low-latency, event-based digital experience architecture.</description><author>Xin Chen, Alex Reibman, Sanjay Arora</author><pubDate>Fri, 30 Jun 2023 14:00:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.06225v2</guid></item><item><title>Design of Induction Machines using Reinforcement Learning</title><link>http://arxiv.org/abs/2306.17626v1</link><description>The design of induction machine is a challenging task due to differentelectromagnetic and thermal constraints. Quick estimation of machine'sdimensions is important in the sales tool to provide quick quotations tocustomers based on specific requirements. The key part of this process is toselect different design parameters like length, diameter, tooth tip height andwinding turns to achieve certain torque, current and temperature of themachine. Electrical machine designers, with their experience know how to alterdifferent machine design parameters to achieve a customer specific operationrequirements. We propose a reinforcement learning algorithm to design acustomised induction motor. The neural network model is trained off-line bysimulating different instances of of electrical machine design game with areward or penalty function when a good or bad design choice is made. Theresults demonstrate that the suggested method automates electrical machinedesign without applying any human engineering knowledge.</description><author>Yasmin SarcheshmehPour, Tommi Ryyppo, Victor Mukherjee, Alex Jung</author><pubDate>Fri, 30 Jun 2023 13:56:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17626v1</guid></item><item><title>Sphere2Vec: A General-Purpose Location Representation Learning over a Spherical Surface for Large-Scale Geospatial Predictions</title><link>http://arxiv.org/abs/2306.17624v1</link><description>Generating learning-friendly representations for points in space is afundamental and long-standing problem in ML. Recently, multi-scale encodingschemes (such as Space2Vec and NeRF) were proposed to directly encode any pointin 2D/3D Euclidean space as a high-dimensional vector, and has beensuccessfully applied to various geospatial prediction and generative tasks.However, all current 2D and 3D location encoders are designed to model pointdistances in Euclidean space. So when applied to large-scale real-world GPScoordinate datasets, which require distance metric learning on the sphericalsurface, both types of models can fail due to the map projection distortionproblem (2D) and the spherical-to-Euclidean distance approximation error (3D).To solve these problems, we propose a multi-scale location encoder calledSphere2Vec which can preserve spherical distances when encoding pointcoordinates on a spherical surface. We developed a unified view ofdistance-reserving encoding on spheres based on the DFS. We also providetheoretical proof that the Sphere2Vec preserves the spherical surface distancebetween any two points, while existing encoding schemes do not. Experiments on20 synthetic datasets show that Sphere2Vec can outperform all baseline modelson all these datasets with up to 30.8% error rate reduction. We then applySphere2Vec to three geo-aware image classification tasks - fine-grained speciesrecognition, Flickr image recognition, and remote sensing image classification.Results on 7 real-world datasets show the superiority of Sphere2Vec overmultiple location encoders on all three tasks. Further analysis shows thatSphere2Vec outperforms other location encoder models, especially in the polarregions and data-sparse areas because of its nature for spherical surfacedistance preservation. Code and data are available athttps://gengchenmai.github.io/sphere2vec-website/.</description><author>Gengchen Mai, Yao Xuan, Wenyun Zuo, Yutong He, Jiaming Song, Stefano Ermon, Krzysztof Janowicz, Ni Lao</author><pubDate>Fri, 30 Jun 2023 13:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17624v1</guid></item><item><title>Accuracy Boosters: Epoch-Driven Mixed-Mantissa Block Floating-Point for DNN Training</title><link>http://arxiv.org/abs/2211.10737v3</link><description>The unprecedented growth in DNN model complexity, size, and amount oftraining data has led to a commensurate increase in demand for computing and asearch for minimal encoding. Recent research advocates Hybrid Block FloatingPoint (HBFP) to minimize silicon provisioning in accelerators by converting themajority of arithmetic operations in training to 8-bit fixed point. In thispaper, we perform a full-scale exploration of the HBFP design space usingmathematical tools to study the interplay among various parameters and identifyopportunities for even smaller encodings across layers and epochs. Based on ourfindings, we propose Accuracy Boosters, an epoch-driven mixed-mantissa HBFPtechnique that uses 6-bit mantissas only in the last epoch and first/lastlayers, and 4-bit mantissas for $99.7\%$ of all other arithmetic operations intraining. Using analytic models, we show Accuracy Boosters enable increasingarithmetic density for an HBFP training accelerator by up to $21.3\times$compared to FP32 and up to $4.4\times$ compared to another SOTA formatBfloat16, while preserving or outperforming FP32 accuracy.</description><author>Simla Burcu Harma, Ayan Chakraborty, Babak Falsafi, Martin Jaggi, Yunho Oh</author><pubDate>Fri, 30 Jun 2023 13:42:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.10737v3</guid></item><item><title>Polarimetric iToF: Measuring High-Fidelity Depth through Scattering Media</title><link>http://arxiv.org/abs/2306.17618v1</link><description>Indirect time-of-flight (iToF) imaging allows us to capture dense depthinformation at a low cost. However, iToF imaging often suffers from multipathinterference (MPI) artifacts in the presence of scattering media, resulting insevere depth-accuracy degradation. For instance, iToF cameras cannot measuredepth accurately through fog because ToF active illumination scatters back tothe sensor before reaching the farther target surface. In this work, we proposea polarimetric iToF imaging method that can capture depth information robustlythrough scattering media. Our observations on the principle of indirect ToFimaging and polarization of light allow us to formulate a novel computationalmodel of scattering-aware polarimetric phase measurements that enables us tocorrect MPI errors. We first devise a scattering-aware polarimetric iToF modelthat can estimate the phase of unpolarized backscattered light. We then combinethe optical filtering of polarization and our computational modeling ofunpolarized backscattered light via scattering analysis of phase and amplitude.This allows us to tackle the MPI problem by estimating the scattering energythrough the participating media. We validate our method on an experimentalsetup using a customized off-the-shelf iToF camera. Our method outperformsbaseline methods by a significant margin by means of our scattering model andpolarimetric phase measurements.</description><author>Daniel S. Jeon, Andreas Meuleman, Seung-Hwan Baek, Min H. Kim</author><pubDate>Fri, 30 Jun 2023 13:42:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17618v1</guid></item><item><title>Scalable method for Bayesian experimental design without integrating over posterior distribution</title><link>http://arxiv.org/abs/2306.17615v1</link><description>We address the computational efficiency in solving the A-optimal Bayesiandesign of experiments problems for which the observational model is based onpartial differential equations and, consequently, is computationally expensiveto evaluate. A-optimality is a widely used and easy-to-interpret criterion forthe Bayesian design of experiments. The criterion seeks the optimal experimentdesign by minimizing the expected conditional variance, also known as theexpected posterior variance. This work presents a novel likelihood-free methodfor seeking the A-optimal design of experiments without sampling or integratingthe Bayesian posterior distribution. In our approach, the expected conditionalvariance is obtained via the variance of the conditional expectation using thelaw of total variance, while we take advantage of the orthogonal projectionproperty to approximate the conditional expectation. Through an asymptoticerror estimation, we show that the intractability of the posterior does notaffect the performance of our approach. We use an artificial neural network(ANN) to approximate the nonlinear conditional expectation to implement ourmethod. For dealing with continuous experimental design parameters, weintegrate the training process of the ANN into minimizing the expectedconditional variance. Specifically, we propose a non-local approximation of theconditional expectation and apply transfer learning to reduce the number ofevaluations of the observation model. Through numerical experiments, wedemonstrate that our method significantly reduces the number of observationalmodel evaluations compared with common importance sampling-based approaches.This reduction is crucial, considering the computationally expensive nature ofthese models.</description><author>Vinh Hoang, Luis Espath, Sebastian Krumscheid, Raúl Tempone</author><pubDate>Fri, 30 Jun 2023 13:40:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17615v1</guid></item><item><title>Conversational Question Answering on Heterogeneous Sources</title><link>http://arxiv.org/abs/2204.11677v2</link><description>Conversational question answering (ConvQA) tackles sequential informationneeds where contexts in follow-up questions are left implicit. Current ConvQAsystems operate over homogeneous sources of information: either a knowledgebase (KB), or a text corpus, or a collection of tables. This paper addressesthe novel issue of jointly tapping into all of these together, this wayboosting answer coverage and confidence. We present CONVINSE, an end-to-endpipeline for ConvQA over heterogeneous sources, operating in three stages: i)learning an explicit structured representation of an incoming question and itsconversational context, ii) harnessing this frame-like representation touniformly capture relevant evidences from KB, text, and tables, and iii)running a fusion-in-decoder model to generate the answer. We construct andrelease the first benchmark, ConvMix, for ConvQA over heterogeneous sources,comprising 3000 real-user conversations with 16000 questions, along with entityannotations, completed question utterances, and question paraphrases.Experiments demonstrate the viability and advantages of our method, compared tostate-of-the-art baselines.</description><author>Philipp Christmann, Rishiraj Saha Roy, Gerhard Weikum</author><pubDate>Fri, 30 Jun 2023 13:32:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.11677v2</guid></item><item><title>Mixed Integer Programming for Time-Optimal Multi-Robot Coverage Path Planning with Efficient Heuristics</title><link>http://arxiv.org/abs/2306.17609v1</link><description>We investigate time-optimal Multi-Robot Coverage Path Planning (MCPP) forboth unweighted and weighted terrains, which aims to minimize the coveragetime, defined as the maximum travel time of all robots. Specifically, we focuson a reduction from MCPP to Rooted Min-Max Tree Cover (RMMTC). For the firsttime, we propose a Mixed Integer Programming (MIP) model to optimally solveRMMTC, resulting in an MCPP solution with a coverage time that is provably atmost four times the optimal. Moreover, we propose two suboptimal yet effectiveheuristics that reduce the number of variables in the MIP model, thus improvingits efficiency for large-scale MCPP instances. We show that both heuristicsresult in reduced-size MIP models that remain complete (i.e., guarantee to finda solution if one exists) for all RMMTC instances. Additionally, we explore theuse of model optimization warm-startup to further improve the efficiency ofboth the original MIP model and the reduced-size MIP models. We validate theeffectiveness of our MIP-based MCPP planner through experiments that compare itwith two state-of-the-art MCPP planners on various instances, demonstrating areduction in the coverage time by an average of 42.42% and 39.16% over them,respectively.</description><author>Jingtao Tang, Hang Ma</author><pubDate>Fri, 30 Jun 2023 13:31:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17609v1</guid></item><item><title>A Unified Object Counting Network with Object Occupation Prior</title><link>http://arxiv.org/abs/2212.14193v3</link><description>The counting task, which plays a fundamental role in numerous applications(e.g., crowd counting, traffic statistics), aims to predict the number ofobjects with various densities. Existing object counting tasks are designed fora single object class. However, it is inevitable to encounter newly coming datawith new classes in our real world. We name this scenario as \textit{evolvingobject counting}. In this paper, we build the first evolving object countingdataset and propose a unified object counting network as the first attempt toaddress this task. The proposed model consists of two key components: aclass-agnostic mask module and a class-incremental module. The class-agnosticmask module learns generic object occupation prior via predicting aclass-agnostic binary mask (e.g., 1 denotes there exists an object at theconsidering position in an image and 0 otherwise). The class-incremental moduleis used to handle new coming classes and provides discriminative class guidancefor density map prediction. The combined outputs of class-agnostic mask moduleand image feature extractor are used to predict the final density map. When newclasses come, we first add new neural nodes into the last regression andclassification layers of class-incremental module. Then, instead of retrainingthe model from scratch, we utilize knowledge distillation to help the modelremember what have already learned about previous object classes. We alsoemploy a support sample bank to store a small number of typical trainingsamples of each class, which are used to prevent the model from forgetting keyinformation of old data. With this design, our model can efficiently andeffectively adapt to new coming classes while keeping good performance onalready seen data without large-scale retraining. Extensive experiments on thecollected dataset demonstrate the favorable performance.</description><author>Shengqin Jiang, Qing Wang, Fengna Cheng, Yuankai Qi, Qingshan Liu</author><pubDate>Fri, 30 Jun 2023 13:26:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.14193v3</guid></item><item><title>MalProtect: Stateful Defense Against Adversarial Query Attacks in ML-based Malware Detection</title><link>http://arxiv.org/abs/2302.10739v3</link><description>ML models are known to be vulnerable to adversarial query attacks. In theseattacks, queries are iteratively perturbed towards a particular class withoutany knowledge of the target model besides its output. The prevalence ofremotely-hosted ML classification models and Machine-Learning-as-a-Serviceplatforms means that query attacks pose a real threat to the security of thesesystems. To deal with this, stateful defenses have been proposed to detectquery attacks and prevent the generation of adversarial examples by monitoringand analyzing the sequence of queries received by the system. Several statefuldefenses have been proposed in recent years. However, these defenses relysolely on similarity or out-of-distribution detection methods that may beeffective in other domains. In the malware detection domain, the methods togenerate adversarial examples are inherently different, and therefore we findthat such detection mechanisms are significantly less effective. Hence, in thispaper, we present MalProtect, which is a stateful defense against query attacksin the malware detection domain. MalProtect uses several threat indicators todetect attacks. Our results show that it reduces the evasion rate ofadversarial query attacks by 80+\% in Android and Windows malware, across arange of attacker scenarios. In the first evaluation of its kind, we show thatMalProtect outperforms prior stateful defenses, especially under the peakadversarial threat.</description><author>Aqib Rashid, Jose Such</author><pubDate>Fri, 30 Jun 2023 13:24:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10739v3</guid></item><item><title>S.T.A.R.-Track: Latent Motion Models for End-to-End 3D Object Tracking with Adaptive Spatio-Temporal Appearance Representations</title><link>http://arxiv.org/abs/2306.17602v1</link><description>Following the tracking-by-attention paradigm, this paper introduces anobject-centric, transformer-based framework for tracking in 3D. Traditionalmodel-based tracking approaches incorporate the geometric effect of object- andego motion between frames with a geometric motion model. Inspired by this, wepropose S.T.A.R.-Track, which uses a novel latent motion model (LMM) toadditionally adjust object queries to account for changes in viewing directionand lighting conditions directly in the latent space, while still modeling thegeometric motion explicitly. Combined with a novel learnable track embeddingthat aids in modeling the existence probability of tracks, this results in ageneric tracking framework that can be integrated with any query-baseddetector. Extensive experiments on the nuScenes benchmark demonstrate thebenefits of our approach, showing state-of-the-art performance for DETR3D-basedtrackers while drastically reducing the number of identity switches of tracksat the same time.</description><author>Simon Doll, Niklas Hanselmann, Lukas Schneider, Richard Schulz, Markus Enzweiler, Hendrik P. A. Lensch</author><pubDate>Fri, 30 Jun 2023 13:22:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17602v1</guid></item><item><title>Navigation of micro-robot swarms for targeted delivery using reinforcement learning</title><link>http://arxiv.org/abs/2306.17598v1</link><description>Micro robotics is quickly emerging to be a promising technological solutionto many medical treatments with focus on targeted drug delivery. They areeffective when working in swarms whose individual control is mostly infeasibleowing to their minute size. Controlling a number of robots with a singlecontroller is thus important and artificial intelligence can help us performthis task successfully. In this work, we use the Reinforcement Learning (RL)algorithms Proximal Policy Optimization (PPO) and Robust Policy Optimization(RPO) to navigate a swarm of 4, 9 and 16 microswimmers under hydrodynamiceffects, controlled by their orientation, towards a circular absorbing target.We look at both PPO and RPO performances with limited state informationscenarios and also test their robustness for random target location and size.We use curriculum learning to improve upon the performance and demonstrate thesame in learning to navigate a swarm of 25 swimmers and steering the swarm toexemplify the manoeuvring capabilities of the RL model.</description><author>Akshatha Jagadish, Manoj Varma</author><pubDate>Fri, 30 Jun 2023 13:17:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17598v1</guid></item><item><title>Razor SNN: Efficient Spiking Neural Network with Temporal Embeddings</title><link>http://arxiv.org/abs/2306.17597v1</link><description>The event streams generated by dynamic vision sensors (DVS) are sparse andnon-uniform in the spatial domain, while still dense and redundant in thetemporal domain. Although spiking neural network (SNN), the event-drivenneuromorphic model, has the potential to extract spatio-temporal features fromthe event streams, it is not effective and efficient. Based on the above, wepropose an events sparsification spiking framework dubbed as Razor SNN, pruningpointless event frames progressively. Concretely, we extend the dynamicmechanism based on the global temporal embeddings, reconstruct the features,and emphasize the events effect adaptively at the training stage. During theinference stage, eliminate fruitless frames hierarchically according to abinary mask generated by the trained temporal embeddings. Comprehensiveexperiments demonstrate that our Razor SNN achieves competitive performanceconsistently on four events-based benchmarks: DVS 128 Gesture, N-Caltech 101,CIFAR10-DVS and SHD.</description><author>Yuan Zhang, Jian Cao, Ling Zhang, Jue Chen, Wenyu Sun, Yuan Wang</author><pubDate>Fri, 30 Jun 2023 13:17:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17597v1</guid></item><item><title>RBSR: Efficient and Flexible Recurrent Network for Burst Super-Resolution</title><link>http://arxiv.org/abs/2306.17595v1</link><description>Burst super-resolution (BurstSR) aims at reconstructing a high-resolution(HR) image from a sequence of low-resolution (LR) and noisy images, which isconducive to enhancing the imaging effects of smartphones with limited sensors.The main challenge of BurstSR is to effectively combine the complementaryinformation from input frames, while existing methods still struggle with it.In this paper, we suggest fusing cues frame-by-frame with an efficient andflexible recurrent network. In particular, we emphasize the role of thebase-frame and utilize it as a key prompt to guide the knowledge acquisitionfrom other frames in every recurrence. Moreover, we introduce an implicitweighting loss to improve the model's flexibility in facing input frames withvariable numbers. Extensive experiments on both synthetic and real-worlddatasets demonstrate that our method achieves better results thanstate-of-the-art ones. Codes and pre-trained models are available athttps://github.com/ZcsrenlongZ/RBSR.</description><author>Renlong Wu, Zhilu Zhang, Shuohao Zhang, Hongzhi Zhang, Wangmeng Zuo</author><pubDate>Fri, 30 Jun 2023 13:14:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17595v1</guid></item><item><title>Miniaturized Graph Convolutional Networks with Topologically Consistent Pruning</title><link>http://arxiv.org/abs/2306.17590v1</link><description>Magnitude pruning is one of the mainstream methods in lightweightarchitecture design whose goal is to extract subnetworks with the largestweight connections. This method is known to be successful, but under very highpruning regimes, it suffers from topological inconsistency which renders theextracted subnetworks disconnected, and this hinders their generalizationability. In this paper, we devise a novel magnitude pruning method that allowsextracting subnetworks while guarantying their topological consistency. Thelatter ensures that only accessible and co-accessible -- impactful --connections are kept in the resulting lightweight networks. Our solution isbased on a novel reparametrization and two supervisory bi-directional networkswhich implement accessibility/co-accessibility and guarantee that onlyconnected subnetworks will be selected during training. This solution allowsenhancing generalization significantly, under very high pruning regimes, ascorroborated through extensive experiments, involving graph convolutionalnetworks, on the challenging task of skeleton-based action recognition.</description><author>Hichem Sahbi</author><pubDate>Fri, 30 Jun 2023 13:09:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17590v1</guid></item><item><title>Variational principle to regularize machine-learned density functionals: the non-interacting kinetic-energy functional</title><link>http://arxiv.org/abs/2306.17587v1</link><description>Practical density functional theory (DFT) owes its success to thegroundbreaking work of Kohn and Sham that introduced the exact calculation ofthe non-interacting kinetic energy of the electrons using an auxiliarymean-field system. However, the full power of DFT will not be unleashed untilthe exact relationship between the electron density and the non-interactingkinetic energy is found. Various attempts have been made to approximate thisfunctional, similar to the exchange--correlation functional, with much lesssuccess due to the larger contribution of kinetic energy and its more non-localnature. In this work we propose a new and efficient regularization method totrain density functionals based on deep neural networks, with particularinterest in the kinetic-energy functional. The method is tested on(effectively) one-dimensional systems, including the hydrogen chain,non-interacting electrons, and atoms of the first two periods, with excellentresults. For the atomic systems, the generalizability of the regularizationmethod is demonstrated by training also an exchange--correlation functional,and the contrasting nature of the two functionals is discussed from amachine-learning perspective.</description><author>P. del Mazo-Sevillano, J. Hermann</author><pubDate>Fri, 30 Jun 2023 13:07:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17587v1</guid></item><item><title>Comparing Algorithm Selection Approaches on Black-Box Optimization Problems</title><link>http://arxiv.org/abs/2306.17585v1</link><description>Performance complementarity of solvers available to tackle black-boxoptimization problems gives rise to the important task of algorithm selection(AS). Automated AS approaches can help replace tedious and labor-intensivemanual selection, and have already shown promising performance in variousoptimization domains. Automated AS relies on machine learning (ML) techniquesto recommend the best algorithm given the information about the probleminstance. Unfortunately, there are no clear guidelines for choosing the mostappropriate one from a variety of ML techniques. Tree-based models such asRandom Forest or XGBoost have consistently demonstrated outstanding performancefor automated AS. Transformers and other tabular deep learning models have alsobeen increasingly applied in this context. We investigate in this work the impact of the choice of the ML technique onAS performance. We compare four ML models on the task of predicting the bestsolver for the BBOB problems for 7 different runtime budgets in 2 dimensions.While our results confirm that a per-instance AS has indeed impressivepotential, we also show that the particular choice of the ML technique is ofmuch minor importance.</description><author>Ana Kostovska, Anja Jankovic, Diederick Vermetten, Sašo Džeroski, Tome Eftimov, Carola Doerr</author><pubDate>Fri, 30 Jun 2023 13:06:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.17585v1</guid></item><item><title>Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering</title><link>http://arxiv.org/abs/2306.00526v2</link><description>The pre-training-fine-tuning paradigm based on layout-aware multimodalpre-trained models has achieved significant progress on document image questionanswering. However, domain pre-training and task fine-tuning for additionalvisual, layout, and task modules prevent them from directly utilizingoff-the-shelf instruction-tuning language foundation models, which haverecently shown promising potential in zero-shot learning. Contrary to aligninglanguage models to the domain of document image question answering, we aligndocument image question answering to off-the-shell instruction-tuning languagefoundation models to utilize their zero-shot capability. Specifically, wepropose layout and task aware instruction prompt called LATIN-Prompt, whichconsists of layout-aware document content and task-aware descriptions. Theformer recovers the layout information among text segments from OCR tools byappropriate spaces and line breaks. The latter ensures that the model generatesanswers that meet the requirements, especially format requirements, through adetailed description of task. Experimental results on three benchmarks showthat LATIN-Prompt can improve the zero-shot performance of instruction-tuninglanguage foundation models on document image question answering and help themachieve comparable levels to SOTAs based on the pre-training-fine-tuningparadigm. Quantitative analysis and qualitative analysis demonstrate theeffectiveness of LATIN-Prompt. We provide the code in supplementary and willrelease the code to facilitate future research.</description><author>Wenjin Wang, Yunhao Li, Yixin Ou, Yin Zhang</author><pubDate>Fri, 30 Jun 2023 13:03:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00526v2</guid></item><item><title>ERL-Re$^2$: Efficient Evolutionary Reinforcement Learning with Shared State Representation and Individual Policy Representation</title><link>http://arxiv.org/abs/2210.17375v2</link><description>Deep Reinforcement Learning (Deep RL) and Evolutionary Algorithms (EA) aretwo major paradigms of policy optimization with distinct learning principles,i.e., gradient-based v.s. gradient-free. An appealing research direction isintegrating Deep RL and EA to devise new methods by fusing their complementaryadvantages. However, existing works on combining Deep RL and EA have two commondrawbacks: 1) the RL agent and EA agents learn their policies individually,neglecting efficient sharing of useful common knowledge; 2) parameter-levelpolicy optimization guarantees no semantic level of behavior evolution for theEA side. In this paper, we propose Evolutionary Reinforcement Learning withTwo-scale State Representation and Policy Representation (ERL-Re$^2$), a novelsolution to the aforementioned two drawbacks. The key idea of ERL-Re$^2$ istwo-scale representation: all EA and RL policies share the same nonlinear staterepresentation while maintaining individual} linear policy representations. Thestate representation conveys expressive common features of the environmentlearned by all the agents collectively; the linear policy representationprovides a favorable space for efficient policy optimization, where novelbehavior-level crossover and mutation operations can be performed. Moreover,the linear policy representation allows convenient generalization of policyfitness with the help of the Policy-extended Value Function Approximator(PeVFA), further improving the sample efficiency of fitness estimation. Theexperiments on a range of continuous control tasks show that ERL-Re$^2$consistently outperforms advanced baselines and achieves the State Of The Art(SOTA). Our code is available on https://github.com/yeshenpy/ERL-Re2.</description><author>Jianye Hao, Pengyi Li, Hongyao Tang, Yan Zheng, Xian Fu, Zhaopeng Meng</author><pubDate>Fri, 30 Jun 2023 12:57:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.17375v2</guid></item></channel></rss>