<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 10 Feb 2025 13:00:08 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>FlashVideo:Flowing Fidelity to Detail for Efficient High-Resolution Video Generation</title><link>http://arxiv.org/abs/2502.05179v1</link><description>DiT diffusion models have achieved great success in text-to-video generation,leveraging their scalability in model capacity and data scale. High content andmotion fidelity aligned with text prompts, however, often require large modelparameters and a substantial number of function evaluations (NFEs). Realisticand visually appealing details are typically reflected in high resolutionoutputs, further amplifying computational demands especially for single stageDiT models. To address these challenges, we propose a novel two stageframework, FlashVideo, which strategically allocates model capacity and NFEsacross stages to balance generation fidelity and quality. In the first stage,prompt fidelity is prioritized through a low resolution generation processutilizing large parameters and sufficient NFEs to enhance computationalefficiency. The second stage establishes flow matching between low and highresolutions, effectively generating fine details with minimal NFEs.Quantitative and visual results demonstrate that FlashVideo achievesstate-of-the-art high resolution video generation with superior computationalefficiency. Additionally, the two-stage design enables users to preview theinitial output before committing to full resolution generation, therebysignificantly reducing computational costs and wait times as well as enhancingcommercial viability .</description><author>Shilong Zhang, Wenbo Li, Shoufa Chen, Chongjian Ge, Peize Sun, Yida Zhang, Yi Jiang, Zehuan Yuan, Binyue Peng, Ping Luo</author><pubDate>Fri, 07 Feb 2025 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05179v1</guid></item><item><title>QLIP: Text-Aligned Visual Tokenization Unifies Auto-Regressive Multimodal Understanding and Generation</title><link>http://arxiv.org/abs/2502.05178v1</link><description>We introduce Quantized Language-Image Pretraining (QLIP), a visualtokenization method that combines state-of-the-art reconstruction quality withstate-of-the-art zero-shot image understanding. QLIP trains abinary-spherical-quantization-based autoencoder with reconstruction andlanguage-image alignment objectives. We are the first to show that the twoobjectives do not need to be at odds. We balance the two loss terms dynamicallyduring training and show that a two-stage training pipeline effectively mixesthe large-batch requirements of image-language pre-training with the memorybottleneck imposed by the reconstruction objective. We validate theeffectiveness of QLIP for multimodal understanding and text-conditioned imagegeneration with a single model. Specifically, QLIP serves as a drop-inreplacement for the visual encoder for LLaVA and the image tokenizer forLlamaGen with comparable or even better performance. Finally, we demonstratethat QLIP enables a unified mixed-modality auto-regressive model forunderstanding and generation.</description><author>Yue Zhao, Fuzhao Xue, Scott Reed, Linxi Fan, Yuke Zhu, Jan Kautz, Zhiding Yu, Philipp Krähenbühl, De-An Huang</author><pubDate>Fri, 07 Feb 2025 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05178v1</guid></item><item><title>Long-VITA: Scaling Large Multi-modal Models to 1 Million Tokens with Leading Short-Context Accuray</title><link>http://arxiv.org/abs/2502.05177v1</link><description>Establishing the long-context capability of large vision-language models iscrucial for video understanding, high-resolution image understanding,multi-modal agents and reasoning. We introduce Long-VITA, a simple yeteffective large multi-modal model for long-context visual-languageunderstanding tasks. It is adept at concurrently processing and analyzingmodalities of image, video, and text over 4K frames or 1M tokens whiledelivering advanced performances on short-context multi-modal tasks. We proposean effective multi-modal training schema that starts with large language modelsand proceeds through vision-language alignment, general knowledge learning, andtwo sequential stages of long-sequence fine-tuning. We further implementcontext-parallelism distributed inference and logits-masked language modelinghead to scale Long-VITA to infinitely long inputs of images and texts duringmodel inference. Regarding training data, Long-VITA is built on a mix of $17$Msamples from public datasets only and demonstrates the state-of-the-artperformance on various multi-modal benchmarks, compared against recentcutting-edge models with internal data. Long-VITA is fully reproducible andsupports both NPU and GPU platforms for training and testing. We hope Long-VITAcan serve as a competitive baseline and offer valuable insights for theopen-source community in advancing long-context multi-modal understanding.</description><author>Yunhang Shen, Chaoyou Fu, Shaoqi Dong, Xiong Wang, Peixian Chen, Mengdan Zhang, Haoyu Cao, Ke Li, Xiawu Zheng, Yan Zhang, Yiyi Zhou, Rongrong Ji, Xing Sun</author><pubDate>Fri, 07 Feb 2025 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05177v1</guid></item><item><title>AuraFusion360: Augmented Unseen Region Alignment for Reference-based 360° Unbounded Scene Inpainting</title><link>http://arxiv.org/abs/2502.05176v1</link><description>Three-dimensional scene inpainting is crucial for applications from virtualreality to architectural visualization, yet existing methods struggle with viewconsistency and geometric accuracy in 360{\deg} unbounded scenes. We presentAuraFusion360, a novel reference-based method that enables high-quality objectremoval and hole filling in 3D scenes represented by Gaussian Splatting. Ourapproach introduces (1) depth-aware unseen mask generation for accurateocclusion identification, (2) Adaptive Guided Depth Diffusion, a zero-shotmethod for accurate initial point placement without requiring additionaltraining, and (3) SDEdit-based detail enhancement for multi-view coherence. Wealso introduce 360-USID, the first comprehensive dataset for 360{\deg}unbounded scene inpainting with ground truth. Extensive experiments demonstratethat AuraFusion360 significantly outperforms existing methods, achievingsuperior perceptual quality while maintaining geometric accuracy acrossdramatic viewpoint changes. See our project page for video results and thedataset at https://kkennethwu.github.io/aurafusion360/.</description><author>Chung-Ho Wu, Yang-Jung Chen, Ying-Huan Chen, Jie-Ying Lee, Bo-Hsu Ke, Chun-Wei Tuan Mu, Yi-Chuan Huang, Chin-Yang Lin, Min-Hung Chen, Yen-Yu Lin, Yu-Lun Liu</author><pubDate>Fri, 07 Feb 2025 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05176v1</guid></item><item><title>Fillerbuster: Multi-View Scene Completion for Casual Captures</title><link>http://arxiv.org/abs/2502.05175v1</link><description>We present Fillerbuster, a method that completes unknown regions of a 3Dscene by utilizing a novel large-scale multi-view latent diffusion transformer.Casual captures are often sparse and miss surrounding content behind objects orabove the scene. Existing methods are not suitable for handling this challengeas they focus on making the known pixels look good with sparse-view priors, oron creating the missing sides of objects from just one or two photos. Inreality, we often have hundreds of input frames and want to complete areas thatare missing and unobserved from the input frames. Additionally, the imagesoften do not have known camera parameters. Our solution is to train agenerative model that can consume a large context of input frames whilegenerating unknown target views and recovering image poses when desired. Weshow results where we complete partial captures on two existing datasets. Wealso present an uncalibrated scene completion task where our unified modelpredicts both poses and creates new content. Our model is the first to predictmany images and poses together for scene completion.</description><author>Ethan Weber, Norman Müller, Yash Kant, Vasu Agrawal, Michael Zollhöfer, Angjoo Kanazawa, Christian Richardt</author><pubDate>Fri, 07 Feb 2025 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05175v1</guid></item><item><title>MELON: Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison</title><link>http://arxiv.org/abs/2502.05174v1</link><description>Recent research has explored that LLM agents are vulnerable to indirectprompt injection (IPI) attacks, where malicious tasks embedded intool-retrieved information can redirect the agent to take unauthorized actions.Existing defenses against IPI have significant limitations: either requireessential model training resources, lack effectiveness against sophisticatedattacks, or harm the normal utilities. We present MELON (Masked re-Executionand TooL comparisON), a novel IPI defense. Our approach builds on theobservation that under a successful attack, the agent's next action becomesless dependent on user tasks and more on malicious tasks. Following this, wedesign MELON to detect attacks by re-executing the agent's trajectory with amasked user prompt modified through a masking function. We identify an attackif the actions generated in the original and masked executions are similar. Wealso include three key designs to reduce the potential false positives andfalse negatives. Extensive evaluation on the IPI benchmark AgentDojodemonstrates that MELON outperforms SOTA defenses in both attack prevention andutility preservation. Moreover, we show that combining MELON with a SOTA promptaugmentation defense (denoted as MELON-Aug) further improves its performance.We also conduct a detailed ablation study to validate our key designs.</description><author>Kaijie Zhu, Xianjun Yang, Jindong Wang, Wenbo Guo, William Yang Wang</author><pubDate>Fri, 07 Feb 2025 18:57:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05174v1</guid></item><item><title>VideoRoPE: What Makes for Good Video Rotary Position Embedding?</title><link>http://arxiv.org/abs/2502.05173v1</link><description>While Rotary Position Embedding (RoPE) and its variants are widely adoptedfor their long-context capabilities, the extension of the 1D RoPE to video,with its complex spatio-temporal structure, remains an open challenge. Thiswork first introduces a comprehensive analysis that identifies four keycharacteristics essential for the effective adaptation of RoPE to video, whichhave not been fully considered in prior work. As part of our analysis, weintroduce a challenging V-NIAH-D (Visual Needle-In-A-Haystack with Distractors)task, which adds periodic distractors into V-NIAH. The V-NIAH-D taskdemonstrates that previous RoPE variants, lacking appropriate temporaldimension allocation, are easily misled by distractors. Based on our analysis,we introduce \textbf{VideoRoPE}, with a \textit{3D structure} designed topreserve spatio-temporal relationships. VideoRoPE features\textit{low-frequency temporal allocation} to mitigate periodic oscillations, a\textit{diagonal layout} to maintain spatial symmetry, and \textit{adjustabletemporal spacing} to decouple temporal and spatial indexing. VideoRoPEconsistently surpasses previous RoPE variants, across diverse downstream taskssuch as long video retrieval, video understanding, and video hallucination. Ourcode will be available at\href{https://github.com/Wiselnn570/VideoRoPE}{https://github.com/Wiselnn570/VideoRoPE}.</description><author>Xilin Wei, Xiaoran Liu, Yuhang Zang, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Jian Tong, Haodong Duan, Qipeng Guo, Jiaqi Wang, Xipeng Qiu, Dahua Lin</author><pubDate>Fri, 07 Feb 2025 18:56:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05173v1</guid></item><item><title>Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient</title><link>http://arxiv.org/abs/2502.05172v1</link><description>Mixture of Experts (MoE) architectures have significantly increasedcomputational efficiency in both research and real-world applications oflarge-scale machine learning models. However, their scalability and efficiencyunder memory constraints remain relatively underexplored. In this work, wepresent joint scaling laws for dense and MoE models, incorporating key factorssuch as the number of active parameters, dataset size, and the number ofexperts. Our findings provide a principled framework for selecting the optimalMoE configuration under fixed memory and compute budgets. Surprisingly, we showthat MoE models can be more memory-efficient than dense models, contradictingconventional wisdom. To derive and validate the theoretical predictions of ourscaling laws, we conduct over 280 experiments with up to 2.7B active parametersand up to 5B total parameters. These results offer actionable insights fordesigning and deploying MoE models in practical large-scale training scenarios.</description><author>Jan Ludziejewski, Maciej Pióro, Jakub Krajewski, Maciej Stefaniak, Michał Krutul, Jan Małaśnicki, Marek Cygan, Piotr Sankowski, Kamil Adamczewski, Piotr Miłoś, Sebastian Jaszczur</author><pubDate>Fri, 07 Feb 2025 18:55:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05172v1</guid></item><item><title>Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach</title><link>http://arxiv.org/abs/2502.05171v1</link><description>We study a novel language model architecture that is capable of scalingtest-time computation by implicitly reasoning in latent space. Our model worksby iterating a recurrent block, thereby unrolling to arbitrary depth attest-time. This stands in contrast to mainstream reasoning models that scale upcompute by producing more tokens. Unlike approaches based on chain-of-thought,our approach does not require any specialized training data, can work withsmall context windows, and can capture types of reasoning that are not easilyrepresented in words. We scale a proof-of-concept model to 3.5 billionparameters and 800 billion tokens. We show that the resulting model can improveits performance on reasoning benchmarks, sometimes dramatically, up to acomputation load equivalent to 50 billion parameters.</description><author>Jonas Geiping, Sean McLeish, Neel Jain, John Kirchenbauer, Siddharth Singh, Brian R. Bartoldson, Bhavya Kailkhura, Abhinav Bhatele, Tom Goldstein</author><pubDate>Fri, 07 Feb 2025 18:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05171v1</guid></item><item><title>Flopping for FLOPs: Leveraging equivariance for computational efficiency</title><link>http://arxiv.org/abs/2502.05169v1</link><description>Incorporating geometric invariance into neural networks enhances parameterefficiency but typically increases computational costs. This paper introducesnew equivariant neural networks that preserve symmetry while maintaining acomparable number of floating-point operations (FLOPs) per parameter tostandard non-equivariant networks. We focus on horizontal mirroring (flopping)invariance, common in many computer vision tasks. The main idea is toparametrize the feature spaces in terms of mirror-symmetric andmirror-antisymmetric features, i.e., irreps of the flopping group. Thisdecomposes the linear layers to be block-diagonal, requiring half the number ofFLOPs. Our approach reduces both FLOPs and wall-clock time, providing apractical solution for efficient, scalable symmetry-aware architectures.</description><author>Georg Bökman, David Nordström, Fredrik Kahl</author><pubDate>Fri, 07 Feb 2025 18:53:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05169v1</guid></item><item><title>NoLiMa: Long-Context Evaluation Beyond Literal Matching</title><link>http://arxiv.org/abs/2502.05167v1</link><description>Recent large language models (LLMs) support long contexts ranging from 128Kto 1M tokens. A popular method for evaluating these capabilities is theneedle-in-a-haystack (NIAH) test, which involves retrieving a "needle"(relevant information) from a "haystack" (long irrelevant context). Extensionsof this approach include increasing distractors, fact chaining, and in-contextreasoning. However, in these benchmarks, models can exploit existing literalmatches between the needle and haystack to simplify the task. To address this,we introduce NoLiMa, a benchmark extending NIAH with a carefully designedneedle set, where questions and needles have minimal lexical overlap, requiringmodels to infer latent associations to locate the needle within the haystack.We evaluate 12 popular LLMs that claim to support contexts of at least 128Ktokens. While they perform well in short contexts (&lt;1K), performance degradessignificantly as context length increases. At 32K, for instance, 10 models dropbelow 50% of their strong short-length baselines. Even GPT-4o, one of thetop-performing exceptions, experiences a reduction from an almost-perfectbaseline of 99.3% to 69.7%. Our analysis suggests these declines stem from theincreased difficulty the attention mechanism faces in longer contexts whenliteral matches are absent, making it harder to retrieve relevant information.</description><author>Ali Modarressi, Hanieh Deilamsalehy, Franck Dernoncourt, Trung Bui, Ryan A. Rossi, Seunghyun Yoon, Hinrich Schütze</author><pubDate>Fri, 07 Feb 2025 18:49:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05167v1</guid></item><item><title>Multitwine: Multi-Object Compositing with Text and Layout Control</title><link>http://arxiv.org/abs/2502.05165v1</link><description>We introduce the first generative model capable of simultaneous multi-objectcompositing, guided by both text and layout. Our model allows for the additionof multiple objects within a scene, capturing a range of interactions fromsimple positional relations (e.g., next to, in front of) to complex actionsrequiring reposing (e.g., hugging, playing guitar). When an interaction impliesadditional props, like `taking a selfie', our model autonomously generatesthese supporting objects. By jointly training for compositing andsubject-driven generation, also known as customization, we achieve a morebalanced integration of textual and visual inputs for text-driven objectcompositing. As a result, we obtain a versatile model with state-of-the-artperformance in both tasks. We further present a data generation pipelineleveraging visual and language models to effortlessly synthesize multimodal,aligned training data.</description><author>Gemma Canet Tarrés, Zhe Lin, Zhifei Zhang, He Zhang, Andrew Gilbert, John Collomosse, Soo Ye Kim</author><pubDate>Fri, 07 Feb 2025 18:48:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05165v1</guid></item><item><title>In-context denoising with one-layer transformers: connections between attention and associative memory retrieval</title><link>http://arxiv.org/abs/2502.05164v1</link><description>We introduce in-context denoising, a task that refines the connection betweenattention-based architectures and dense associative memory (DAM) networks, alsoknown as modern Hopfield networks. Using a Bayesian framework, we showtheoretically and empirically that certain restricted denoising problems can besolved optimally even by a single-layer transformer. We demonstrate that atrained attention layer processes each denoising prompt by performing a singlegradient descent update on a context-aware DAM energy landscape, where contexttokens serve as associative memories and the query token acts as an initialstate. This one-step update yields better solutions than exact retrieval ofeither a context token or a spurious local minimum, providing a concreteexample of DAM networks extending beyond the standard retrieval paradigm.Overall, this work solidifies the link between associative memory and attentionmechanisms first identified by Ramsauer et al., and demonstrates the relevanceof associative memory models in the study of in-context learning.</description><author>Matthew Smart, Alberto Bietti, Anirvan M. Sengupta</author><pubDate>Fri, 07 Feb 2025 18:48:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05164v1</guid></item><item><title>DuoGuard: A Two-Player RL-Driven Framework for Multilingual LLM Guardrails</title><link>http://arxiv.org/abs/2502.05163v1</link><description>The rapid advancement of large language models (LLMs) has increased the needfor guardrail models to ensure responsible use, particularly in detectingunsafe and illegal content. While substantial safety data exist in English,multilingual guardrail modeling remains underexplored due to the scarcity ofopen-source safety data in other languages. To address this gap, we propose anovel two-player Reinforcement Learning (RL) framework, where a generator and aguardrail model co-evolve adversarially to produce high-quality synthetic datafor multilingual guardrail training. We theoretically formalize thisinteraction as a two-player game, proving convergence to a Nash equilibrium.Empirical evaluations show that our model \ours outperforms state-of-the-artmodels, achieving nearly 10% improvement over LlamaGuard3 (8B) on Englishbenchmarks while being 4.5x faster at inference with a significantly smallermodel (0.5B). We achieve substantial advancements in multilingual safety tasks,particularly in addressing the imbalance for lower-resource languages in acollected real dataset. Ablation studies emphasize the critical role ofsynthetic data generation in bridging the imbalance in open-source data betweenEnglish and other languages. These findings establish a scalable and efficientapproach to synthetic data generation, paving the way for improved multilingualguardrail models to enhance LLM safety. Code, model, and data will beopen-sourced at https://github.com/yihedeng9/DuoGuard.</description><author>Yihe Deng, Yu Yang, Junkai Zhang, Wei Wang, Bo Li</author><pubDate>Fri, 07 Feb 2025 18:45:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05163v1</guid></item><item><title>A Lightweight Method to Disrupt Memorized Sequences in LLM</title><link>http://arxiv.org/abs/2502.05159v1</link><description>Large language models (LLMs) demonstrate impressive capabilities across manytasks yet risk reproducing copyrighted content verbatim, raising legal andethical concerns. Although methods like differential privacy or neuron editingcan reduce memorization, they typically require costly retraining or directaccess to model weights and may degrade performance. To address thesechallenges, we propose TokenSwap, a lightweight, post-hoc approach thatreplaces the probabilities of grammar-related tokens with those from a smallauxiliary model (e.g., DistilGPT-2). We run extensive experiments on commercialgrade models such as Pythia-6.9b and LLaMA-3-8b and demonstrate that our methodeffectively reduces well-known cases of memorized generation by upto 10x withlittle to no impact on downstream tasks. Our approach offers a uniquelyaccessible and effective solution to users of real-world systems.</description><author>Parjanya Prajakta Prashant, Kaustubh Ponkshe, Babak Salimi</author><pubDate>Fri, 07 Feb 2025 18:41:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05159v1</guid></item><item><title>Efficient distributional regression trees learning algorithms for calibrated non-parametric probabilistic forecasts</title><link>http://arxiv.org/abs/2502.05157v1</link><description>The perspective of developing trustworthy AI for critical applications inscience and engineering requires machine learning techniques that are capableof estimating their own uncertainty. In the context of regression, instead ofestimating a conditional mean, this can be achieved by producing a predictiveinterval for the output, or to even learn a model of the conditionalprobability $p(y|x)$ of an output $y$ given input features $x$. While this canbe done under parametric assumptions with, e.g. generalized linear model, theseare typically too strong, and non-parametric models offer flexiblealternatives. In particular, for scalar outputs, learning directly a model ofthe conditional cumulative distribution function of $y$ given $x$ can lead tomore precise probabilistic estimates, and the use of proper scoring rules suchas the weighted interval score (WIS) and the continuous ranked probabilityscore (CRPS) lead to better coverage and calibration properties. This paper introduces novel algorithms for learning probabilistic regressiontrees for the WIS or CRPS loss functions. These algorithms are madecomputationally efficient thanks to an appropriate use of known data structures- namely min-max heaps, weight-balanced binary trees and Fenwick trees. Throughnumerical experiments, we demonstrate that the performance of our methods iscompetitive with alternative approaches. Additionally, our methods benefit fromthe inherent interpretability and explainability of trees. As a by-product, weshow how our trees can be used in the context of conformal prediction andexplain why they are particularly well-suited for achieving group-conditionalcoverage guarantees.</description><author>Duchemin Quentin, Obozinski Guillaume</author><pubDate>Fri, 07 Feb 2025 18:39:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05157v1</guid></item><item><title>Deep Dynamic Probabilistic Canonical Correlation Analysis</title><link>http://arxiv.org/abs/2502.05155v1</link><description>This paper presents Deep Dynamic Probabilistic Canonical Correlation Analysis(D2PCCA), a model that integrates deep learning with probabilistic modeling toanalyze nonlinear dynamical systems. Building on the probabilistic extensionsof Canonical Correlation Analysis (CCA), D2PCCA captures nonlinear latentdynamics and supports enhancements such as KL annealing for improvedconvergence and normalizing flows for a more flexible posterior approximation.D2PCCA naturally extends to multiple observed variables, making it a versatiletool for encoding prior knowledge about sequential datasets and providing aprobabilistic understanding of the system's dynamics. Experimental validationon real financial datasets demonstrates the effectiveness of D2PCCA and itsextensions in capturing latent dynamics.</description><author>Shiqin Tang, Shujian Yu, Yining Dong, S. Joe Qin</author><pubDate>Fri, 07 Feb 2025 18:37:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05155v1</guid></item><item><title>Long-tailed Medical Diagnosis with Relation-aware Representation Learning and Iterative Classifier Calibration</title><link>http://arxiv.org/abs/2502.03238v2</link><description>Recently computer-aided diagnosis has demonstrated promising performance,effectively alleviating the workload of clinicians. However, the inherentsample imbalance among different diseases leads algorithms biased to themajority categories, leading to poor performance for rare categories. Existingworks formulated this challenge as a long-tailed problem and attempted totackle it by decoupling the feature representation and classification. Yet, dueto the imbalanced distribution and limited samples from tail classes, theseworks are prone to biased representation learning and insufficient classifiercalibration. To tackle these problems, we propose a new Long-tailed MedicalDiagnosis (LMD) framework for balanced medical image classification onlong-tailed datasets. In the initial stage, we develop a Relation-awareRepresentation Learning (RRL) scheme to boost the representation ability byencouraging the encoder to capture intrinsic semantic features throughdifferent data augmentations. In the subsequent stage, we propose an IterativeClassifier Calibration (ICC) scheme to calibrate the classifier iteratively.This is achieved by generating a large number of balanced virtual features andfine-tuning the encoder using an Expectation-Maximization manner. The proposedICC compensates for minority categories to facilitate unbiased classifieroptimization while maintaining the diagnostic knowledge in majority classes.Comprehensive experiments on three public long-tailed medical datasetsdemonstrate that our LMD framework significantly surpasses state-of-the-artapproaches. The source code can be accessed athttps://github.com/peterlipan/LMD.</description><author>Li Pan, Yupei Zhang, Qiushi Yang, Tan Li, Zhen Chen</author><pubDate>Fri, 07 Feb 2025 18:37:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03238v2</guid></item><item><title>TLXML: Task-Level Explanation of Meta-Learning via Influence Functions</title><link>http://arxiv.org/abs/2501.14271v2</link><description>The scheme of adaptation via meta-learning is seen as an ingredient forsolving the problem of data shortage or distribution shift in real-worldapplications, but it also brings the new risk of inappropriate updates of themodel in the user environment, which increases the demand for explainability.Among the various types of XAI methods, establishing a method of explanationbased on past experience in meta-learning requires special consideration due toits bi-level structure of training, which has been left unexplored. In thiswork, we propose influence functions for explaining meta-learning that measurethe sensitivities of training tasks to adaptation and inference. We also arguethat the approximation of the Hessian using the Gauss-Newton matrix resolvescomputational barriers peculiar to meta-learning. We demonstrate the adequacyof the method through experiments on task distinction and task distributiondistinction using image classification tasks with MAML and PrototypicalNetwork.</description><author>Yoshihiro Mitsuka, Shadan Golestan, Zahin Sufiyan, Sheila Schoepp, Shotaro Miwa, Osmar R. Zaiane</author><pubDate>Fri, 07 Feb 2025 18:37:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.14271v2</guid></item><item><title>Smirk: An Atomically Complete Tokenizer for Molecular Foundation Models</title><link>http://arxiv.org/abs/2409.15370v2</link><description>Text-based foundation models have become an important part of scientificdiscovery, with molecular foundation models accelerating advancements inmolecular design and materials science. However, existing models areconstrained by closed-vocabulary tokenizers which capture only a fraction ofmolecular space. In this work, we systematically evaluate thirty tokenizers,including 19 chemistry-specific ones, for their coverage of the SMILESmolecular representation language, revealing significant gaps. To assess theimpact of tokenizer choice, we introduce n-gram language models as a low-costproxy and validate their effectiveness by training and fine-tuning 18RoBERTa-style encoders for molecular property prediction. To overcome thelimitations of existing tokenizers, we propose two new tokenizers -- Smirk andSmirk-GPE -- with full coverage of the OpenSMILES specification. Our resultshighlight the need for open-vocabulary modeling and chemically diversebenchmarks in cheminformatics. The proposed tokenizer framework systematicallyintegrates nuclear, electronic, and geometric degrees of freedom; thisfacilitates applications in pharmacology, agriculture, biology, and energystorage.</description><author>Alexius Wadell, Anoushka Bhutani, Venkatasubramanian Viswanathan</author><pubDate>Fri, 07 Feb 2025 18:36:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.15370v2</guid></item><item><title>Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling</title><link>http://arxiv.org/abs/2409.02908v4</link><description>Masked diffusion models (MDMs) have emerged as a popular research topic forgenerative modeling of discrete data, thanks to their superior performance overother discrete diffusion models, and are rivaling the auto-regressive models(ARMs) for language modeling tasks. The recent effort in simplifying the maskeddiffusion framework further leads to alignment with continuous-space diffusionmodels and more principled training and sampling recipes. In this paper,however, we reveal that both training and sampling of MDMs are theoreticallyfree from the time variable, arguably the key signature of diffusion models,and are instead equivalent to masked models. The connection on the samplingaspect is drawn by our proposed first-hitting sampler (FHS). Specifically, weshow that the FHS is theoretically equivalent to MDMs' original generationprocess while significantly alleviating the time-consuming categorical samplingand achieving a 20$\times$ speedup. In addition, our investigation raisesdoubts about whether MDMs can truly beat ARMs in text generation. We identify,for the first time, an underlying numerical issue, even with the commonly used32-bit floating-point precision, which results in inaccurate categoricalsampling. We show that it lowers the effective temperature both theoreticallyand empirically, and the resulting decrease in token diversity makes previousevaluations, which assess the generation quality solely through the incompletegenerative perplexity metric, somewhat unfair.</description><author>Kaiwen Zheng, Yongxin Chen, Hanzi Mao, Ming-Yu Liu, Jun Zhu, Qinsheng Zhang</author><pubDate>Fri, 07 Feb 2025 18:35:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.02908v4</guid></item><item><title>Simplicity Prevails: Rethinking Negative Preference Optimization for LLM Unlearning</title><link>http://arxiv.org/abs/2410.07163v3</link><description>This work studies the problem of large language model (LLM) unlearning,aiming to remove unwanted data influences (e.g., copyrighted or harmfulcontent) while preserving model utility. Despite the increasing demand forunlearning, a technically-grounded optimization framework is lacking. Gradientascent (GA)-type methods, though widely used, are suboptimal as they reversethe learning process without controlling optimization divergence (i.e.,deviation from the pre-trained state), leading to risks of over-forgetting andpotential model collapse. Negative preference optimization (NPO) has beenproposed to address this issue and is considered one of the state-of-the-artLLM unlearning approaches. In this work, we revisit NPO and identify anothercritical issue: reference model bias. This bias arises from using the referencemodel (i.e., the model prior to unlearning) to evaluate the unlearning success,which can compromise NPO's effectiveness. Specifically, it leads to (a) unevenallocation of optimization power across forget data with varying difficultylevels and (b) ineffective gradient weight smoothing during the early stages ofunlearning optimization. To overcome these challenges, we propose a simple yeteffective unlearning optimization framework, called SimNPO, showing that`simplicity' in removing the reliance on a reference model (through the lens ofsimple preference optimization) benefits unlearning. We provide deeper insightsinto SimNPO's advantages through an analysis based on mixtures of Markovchains. Extensive experiments further validate SimNPO's efficacy on benchmarkslike TOFU and MUSE, as well as its robustness against relearning attacks. Codesare available at https://github.com/OPTML-Group/Unlearn-Simple.</description><author>Chongyu Fan, Jiancheng Liu, Licong Lin, Jinghan Jia, Ruiqi Zhang, Song Mei, Sijia Liu</author><pubDate>Fri, 07 Feb 2025 18:34:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07163v3</guid></item><item><title>Hummingbird: High Fidelity Image Generation via Multimodal Context Alignment</title><link>http://arxiv.org/abs/2502.05153v1</link><description>While diffusion models are powerful in generating high-quality, diversesynthetic data for object-centric tasks, existing methods struggle withscene-aware tasks such as Visual Question Answering (VQA) and Human-ObjectInteraction (HOI) Reasoning, where it is critical to preserve scene attributesin generated images consistent with a multimodal context, i.e. a referenceimage with accompanying text guidance query. To address this, we introduceHummingbird, the first diffusion-based image generator which, given amultimodal context, generates highly diverse images w.r.t. the reference imagewhile ensuring high fidelity by accurately preserving scene attributes, such asobject interactions and spatial relationships from the text guidance.Hummingbird employs a novel Multimodal Context Evaluator that simultaneouslyoptimizes our formulated Global Semantic and Fine-grained Consistency Rewardsto ensure generated images preserve the scene attributes of reference images inrelation to the text guidance while maintaining diversity. As the first modelto address the task of maintaining both diversity and fidelity given amultimodal context, we introduce a new benchmark formulation incorporating MMEPerception and Bongard HOI datasets. Benchmark experiments show Hummingbirdoutperforms all existing methods by achieving superior fidelity whilemaintaining diversity, validating Hummingbird's potential as a robustmultimodal context-aligned image generator in complex visual tasks.</description><author>Minh-Quan Le, Gaurav Mittal, Tianjian Meng, A S M Iftekhar, Vishwas Suryanarayanan, Barun Patra, Dimitris Samaras, Mei Chen</author><pubDate>Fri, 07 Feb 2025 18:32:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05153v1</guid></item><item><title>GLAM: Glomeruli Segmentation for Human Pathological Lesions using Adapted Mouse Model</title><link>http://arxiv.org/abs/2407.18390v2</link><description>Moving from animal models to human applications in preclinical researchencompasses a broad spectrum of disciplines in medical science. A fundamentalelement in the development of new drugs, treatments, diagnostic methods, and indeepening our understanding of disease processes is the accurate measurement ofkidney tissues. Past studies have demonstrated the viability of translatingglomeruli segmentation techniques from mouse models to human applications. Yet,these investigations tend to neglect the complexities involved in segmentingpathological glomeruli affected by different lesions. Such lesions present awider range of morphological variations compared to healthy glomerular tissue,which are arguably more valuable than normal glomeruli in clinical practice.Furthermore, data on lesions from animal models can be more readily scaled upfrom disease models and whole kidney biopsies. This brings up a question:``\textit{Can a pathological segmentation model trained on mouse models beeffectively applied to human patients?}" To answer this question, we introducedGLAM, a deep learning study for fine-grained segmentation of human kidneylesions using a mouse model, addressing mouse-to-human transfer learning, byevaluating different learning strategies for segmenting human pathologicallesions using zero-shot transfer learning and hybrid learning by leveragingmouse samples. From the results, the hybrid learning model achieved superiorperformance.</description><author>Lining Yu, Mengmeng Yin, Ruining Deng, Quan Liu, Tianyuan Yao, Can Cui, Yitian Long, Yu Wang, Yaohong Wang, Shilin Zhao, Haichun Yang, Yuankai Huo</author><pubDate>Fri, 07 Feb 2025 18:27:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18390v2</guid></item><item><title>Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation</title><link>http://arxiv.org/abs/2502.05151v1</link><description>With the advent of large multimodal language models, science is now at athreshold of an AI-based technological transformation. Recently, a plethora ofnew AI models and tools has been proposed, promising to empower researchers andacademics worldwide to conduct their research more effectively and efficiently.This includes all aspects of the research cycle, especially (1) searching forrelevant literature; (2) generating research ideas and conductingexperimentation; generating (3) text-based and (4) multimodal content (e.g.,scientific figures and diagrams); and (5) AI-based automatic peer review. Inthis survey, we provide an in-depth overview over these exciting recentdevelopments, which promise to fundamentally alter the scientific researchprocess for good. Our survey covers the five aspects outlined above, indicatingrelevant datasets, methods and results (including evaluation) as well aslimitations and scope for future research. Ethical concerns regardingshortcomings of these tools and potential for misuse (fake science, plagiarism,harms to research integrity) take a particularly prominent place in ourdiscussion. We hope that our survey will not only become a reference guide fornewcomers to the field but also a catalyst for new AI-based initiatives in thearea of "AI4Science".</description><author>Steffen Eger, Yong Cao, Jennifer D'Souza, Andreas Geiger, Christian Greisinger, Stephanie Gross, Yufang Hou, Brigitte Krenn, Anne Lauscher, Yizhi Li, Chenghua Lin, Nafise Sadat Moosavi, Wei Zhao, Tristan Miller</author><pubDate>Fri, 07 Feb 2025 18:26:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05151v1</guid></item><item><title>CodeSCM: Causal Analysis for Multi-Modal Code Generation</title><link>http://arxiv.org/abs/2502.05150v1</link><description>In this paper, we propose CodeSCM, a Structural Causal Model (SCM) foranalyzing multi-modal code generation using large language models (LLMs). Byapplying interventions to CodeSCM, we measure the causal effects of differentprompt modalities, such as natural language, code, and input-output examples,on the model. CodeSCM introduces latent mediator variables to separate the codeand natural language semantics of a multi-modal code generation prompt. Usingthe principles of Causal Mediation Analysis on these mediators we quantifydirect effects representing the model's spurious leanings. We find that, inaddition to natural language instructions, input-output examples significantlyinfluence code generation.</description><author>Mukur Gupta, Noopur Bhatt, Suman Jana</author><pubDate>Fri, 07 Feb 2025 18:26:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05150v1</guid></item><item><title>An Annotated Reading of 'The Singer of Tales' in the LLM Era</title><link>http://arxiv.org/abs/2502.05148v1</link><description>The Parry-Lord oral-formulaic theory was a breakthrough in understanding howoral narrative poetry is learned, composed, and transmitted by illiteratebards. In this paper, we provide an annotated reading of the mechanismunderlying this theory from the lens of large language models (LLMs) andgenerative artificial intelligence (AI). We point out the the similarities anddifferences between oral composition and LLM generation, and comment on theimplications to society and AI policy.</description><author>Kush R. Varshney</author><pubDate>Fri, 07 Feb 2025 18:26:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05148v1</guid></item><item><title>LP-DETR: Layer-wise Progressive Relations for Object Detection</title><link>http://arxiv.org/abs/2502.05147v1</link><description>This paper presents LP-DETR (Layer-wise Progressive DETR), a novel approachthat enhances DETR-based object detection through multi-scale relationmodeling. Our method introduces learnable spatial relationships between objectqueries through a relation-aware self-attention mechanism, which adaptivelylearns to balance different scales of relations (local, medium and global)across decoder layers. This progressive design enables the model to effectivelycapture evolving spatial dependencies throughout the detection pipeline.Extensive experiments on COCO 2017 dataset demonstrate that our method improvesboth convergence speed and detection accuracy compared to standardself-attention module. The proposed method achieves competitive results,reaching 52.3\% AP with 12 epochs and 52.5\% AP with 24 epochs using ResNet-50backbone, and further improving to 58.0\% AP with Swin-L backbone. Furthermore,our analysis reveals an interesting pattern: the model naturally learns toprioritize local spatial relations in early decoder layers while graduallyshifting attention to broader contexts in deeper layers, providing valuableinsights for future research in object detection.</description><author>Zhengjian Kang, Ye Zhang, Xiaoyu Deng, Xintao Li, Yongzhe Zhang</author><pubDate>Fri, 07 Feb 2025 18:25:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05147v1</guid></item><item><title>LemmaHead: RAG Assisted Proof Generation Using Large Language Models</title><link>http://arxiv.org/abs/2501.15797v3</link><description>Developing the logic necessary to solve mathematical problems or writemathematical proofs is one of the more difficult objectives for large languagemodels (LLMS). Currently, the most popular methods in literature consists offine-tuning the model on written mathematical content such as academicpublications and textbooks, so that the model can learn to emulate the style ofmathematical writing. In this project, we explore the effectiveness of usingretrieval augmented generation (RAG) to address gaps in the mathematicalreasoning of LLMs. We develop LemmaHead, a RAG knowledge base that supplementsqueries to the model with relevant mathematical context, with particular focuson context from published textbooks. To measure our model's performance inmathematical reasoning, our testing paradigm focuses on the task of automatedtheorem proving via generating proofs to a given mathematical claim in the Leanformal language.</description><author>Tianbo Yang, Mingqi Yang, Hongyi Zhao, Tianshuo Yang</author><pubDate>Fri, 07 Feb 2025 18:24:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.15797v3</guid></item><item><title>From Restless to Contextual: A Thresholding Bandit Approach to Improve Finite-horizon Performance</title><link>http://arxiv.org/abs/2502.05145v1</link><description>Online restless bandits extend classic contextual bandits by incorporatingstate transitions and budget constraints, representing each agent as a MarkovDecision Process (MDP). This framework is crucial for finite-horizon strategicresource allocation, optimizing limited costly interventions for long-termbenefits. However, learning the underlying MDP for each agent poses a majorchallenge in finite-horizon settings. To facilitate learning, we reformulatethe problem as a scalable budgeted thresholding contextual bandit problem,carefully integrating the state transitions into the reward design and focusingon identifying agents with action benefits exceeding a threshold. We establishthe optimality of an oracle greedy solution in a simple two-state setting, andpropose an algorithm that achieves minimax optimal constant regret in theonline multi-state setting with heterogeneous agents and knowledge of outcomesunder no intervention. We numerically show that our algorithm outperformsexisting online restless bandit methods, offering significant improvements infinite-horizon performance.</description><author>Jiamin Xu, Ivan Nazarov, Aditya Rastogi, África Periáñez, Kyra Gan</author><pubDate>Fri, 07 Feb 2025 18:23:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05145v1</guid></item><item><title>Chest X-ray Foundation Model with Global and Local Representations Integration</title><link>http://arxiv.org/abs/2502.05142v1</link><description>Chest X-ray (CXR) is the most frequently ordered imaging test, supportingdiverse clinical tasks from thoracic disease detection to postoperativemonitoring. However, task-specific classification models are limited in scope,require costly labeled data, and lack generalizability to out-of-distributiondatasets. To address these challenges, we introduce CheXFound, aself-supervised vision foundation model that learns robust CXR representationsand generalizes effectively across a wide range of downstream tasks. Wepretrain CheXFound on a curated CXR-1M dataset, comprising over one millionunique CXRs from publicly available sources. We propose a Global and LocalRepresentations Integration (GLoRI) module for downstream adaptations, byincorporating disease-specific local features with global image features forenhanced performance in multilabel classification. Our experimental resultsshow that CheXFound outperforms state-of-the-art models in classifying 40disease findings across different prevalence levels on the CXR-LT 24 datasetand exhibits superior label efficiency on downstream tasks with limitedtraining data. Additionally, CheXFound achieved significant improvements on newtasks with out-of-distribution datasets, including opportunistic cardiovasculardisease risk estimation and mortality prediction. These results highlightCheXFound's strong generalization capabilities, enabling diverse adaptationswith improved label efficiency. The project source code is publicly availableat https://github.com/RPIDIAL/CheXFound.</description><author>Zefan Yang, Xuanang Xu, Jiajin Zhang, Ge Wang, Mannudeep K. Kalra, Pingkun Yan</author><pubDate>Fri, 07 Feb 2025 18:16:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05142v1</guid></item><item><title>Meta Audiobox Aesthetics: Unified Automatic Quality Assessment for Speech, Music, and Sound</title><link>http://arxiv.org/abs/2502.05139v1</link><description>The quantification of audio aesthetics remains a complex challenge in audioprocessing, primarily due to its subjective nature, which is influenced byhuman perception and cultural context. Traditional methods often depend onhuman listeners for evaluation, leading to inconsistencies and high resourcedemands. This paper addresses the growing need for automated systems capable ofpredicting audio aesthetics without human intervention. Such systems arecrucial for applications like data filtering, pseudo-labeling large datasets,and evaluating generative audio models, especially as these models become moresophisticated. In this work, we introduce a novel approach to audio aestheticevaluation by proposing new annotation guidelines that decompose humanlistening perspectives into four distinct axes. We develop and trainno-reference, per-item prediction models that offer a more nuanced assessmentof audio quality. Our models are evaluated against human mean opinion scores(MOS) and existing methods, demonstrating comparable or superior performance.This research not only advances the field of audio aesthetics but also providesopen-source models and datasets to facilitate future work and benchmarking. Werelease our code and pre-trained model at:https://github.com/facebookresearch/audiobox-aesthetics</description><author>Andros Tjandra, Yi-Chiao Wu, Baishan Guo, John Hoffman, Brian Ellis, Apoorv Vyas, Bowen Shi, Sanyuan Chen, Matt Le, Nick Zacharov, Carleigh Wood, Ann Lee, Wei-Ning Hsu</author><pubDate>Fri, 07 Feb 2025 18:15:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05139v1</guid></item><item><title>Information-Theoretic Guarantees for Recovering Low-Rank Tensors from Symmetric Rank-One Measurements</title><link>http://arxiv.org/abs/2502.05134v1</link><description>In this paper, we investigate the sample complexity of recovering tensorswith low symmetric rank from symmetric rank-one measurements. This setting isparticularly motivated by the study of higher-order interactions and theanalysis of two-layer neural networks with polynomial activations (polynomialnetworks). Using a covering numbers argument, we analyze the performance of thesymmetric rank minimization program and establish near-optimal samplecomplexity bounds when the underlying distribution is log-concave. Ourmeasurement model involves random symmetric rank-one tensors, which lead toinvolved probability calculations. To address these challenges, we employ theCarbery-Wright inequality, a powerful tool for studying anti-concentrationproperties of random polynomials, and leverage orthogonal polynomials.Additionally, we provide a sample complexity lower bound based on Fano'sinequality, and discuss broader implications of our results for two-layerpolynomial networks.</description><author>Eren C. Kızıldağ</author><pubDate>Fri, 07 Feb 2025 18:12:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05134v1</guid></item><item><title>Data-Parallel Neural Network Training via Nonlinearly Preconditioned Trust-Region Method</title><link>http://arxiv.org/abs/2502.05133v1</link><description>Parallel training methods are increasingly relevant in machine learning (ML)due to the continuing growth in model and dataset sizes. We propose a variantof the Additively Preconditioned Trust-Region Strategy (APTS) for training deepneural networks (DNNs). The proposed APTS method utilizes a data-parallelapproach to construct a nonlinear preconditioner employed in the nonlinearoptimization strategy. In contrast to the common employment of StochasticGradient Descent (SGD) and Adaptive Moment Estimation (Adam), which are bothvariants of gradient descent (GD) algorithms, the APTS method implicitlyadjusts the step sizes in each iteration, thereby removing the need for costlyhyperparameter tuning. We demonstrate the performance of the proposed APTSvariant using the MNIST and CIFAR-10 datasets. The results obtained indicatethat the APTS variant proposed here achieves comparable validation accuracy toSGD and Adam, all while allowing for parallel training and obviating the needfor expensive hyperparameter tuning.</description><author>Samuel A. Cruz Alegría, Ken Trotti, Alena Kopaničáková, Rolf Krause</author><pubDate>Fri, 07 Feb 2025 18:11:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05133v1</guid></item><item><title>Rejecting Hallucinated State Targets during Planning</title><link>http://arxiv.org/abs/2410.07096v6</link><description>Generative models can be used in planning to propose targets corresponding tostates or observations that agents deem either likely or advantageous toexperience. However, agents can struggle with hallucinated, infeasible targetsproposed by the models, leading to delusional planning behaviors, which raisessafety concerns. Drawing inspiration from the human brain, we propose to rejectthese hallucinated targets with an add-on target evaluator. Without propertraining, however, the evaluator can produce delusional estimates, rendering itfutile. We propose to address this via a combination of learning rule,architecture, and two novel hindsight relabeling strategies, which leads tocorrect evaluations of infeasible targets. Our experiments confirm that ourapproach significantly reduces delusional behaviors and enhances theperformance of planning agents.</description><author>Mingde Zhao, Tristan Sylvain, Romain Laroche, Doina Precup, Yoshua Bengio</author><pubDate>Fri, 07 Feb 2025 18:10:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.07096v6</guid></item><item><title>ADAPT to Robustify Prompt Tuning Vision Transformers</title><link>http://arxiv.org/abs/2403.13196v2</link><description>The performance of deep models, including Vision Transformers, is known to bevulnerable to adversarial attacks. Many existing defenses against theseattacks, such as adversarial training, rely on full-model fine-tuning to inducerobustness in the models. These defenses require storing a copy of the entiremodel, that can have billions of parameters, for each task. At the same time,parameter-efficient prompt tuning is used to adapt large transformer-basedmodels to downstream tasks without the need to save large copies. In thispaper, we examine parameter-efficient prompt tuning of Vision Transformers fordownstream tasks under the lens of robustness. We show that previousadversarial defense methods, when applied to the prompt tuning paradigm, sufferfrom gradient obfuscation and are vulnerable to adaptive attacks. We introduceADAPT, a novel framework for performing adaptive adversarial training in theprompt tuning paradigm. Our method achieves competitive robust accuracy of ~40%w.r.t. SOTA robustness methods using full-model fine-tuning, by tuning only ~1%of the number of parameters.</description><author>Masih Eskandar, Tooba Imtiaz, Zifeng Wang, Jennifer Dy</author><pubDate>Fri, 07 Feb 2025 18:04:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13196v2</guid></item><item><title>Latent Swap Joint Diffusion for Long-Form Audio Generation</title><link>http://arxiv.org/abs/2502.05130v1</link><description>Previous work on long-form audio generation using global-view diffusion oriterative generation demands significant training or inference costs. Whilerecent advancements in multi-view joint diffusion for panoramic generationprovide an efficient option, they struggle with spectrum generation with severeoverlap distortions and high cross-view consistency costs. We initially explorethis phenomenon through the connectivity inheritance of latent maps and uncoverthat averaging operations excessively smooth the high-frequency components ofthe latent map. To address these issues, we propose Swap Forward (SaFa), aframe-level latent swap framework that synchronizes multiple diffusions toproduce a globally coherent long audio with more spectrum details in aforward-only manner. At its core, the bidirectional Self-Loop Latent Swap isapplied between adjacent views, leveraging stepwise diffusion trajectory toadaptively enhance high-frequency components without disrupting low-frequencycomponents. Furthermore, to ensure cross-view consistency, the unidirectionalReference-Guided Latent Swap is applied between the reference and thenon-overlap regions of each subview during the early stages, providingcentralized trajectory guidance. Quantitative and qualitative experimentsdemonstrate that SaFa significantly outperforms existing joint diffusionmethods and even training-based long audio generation models. Moreover, we findthat it also adapts well to panoramic generation, achieving comparablestate-of-the-art performance with greater efficiency and modelgeneralizability. Project page is available at https://swapforward.github.io/.</description><author>Yusheng Dai, Chenxi Wang, Chang Li, Chen Wang, Jun Du, Kewei Li, Ruoyu Wang, Jiefeng Ma, Lei Sun, Jianqing Gao</author><pubDate>Fri, 07 Feb 2025 18:02:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05130v1</guid></item><item><title>Counting Fish with Temporal Representations of Sonar Video</title><link>http://arxiv.org/abs/2502.05129v1</link><description>Accurate estimates of salmon escapement - the number of fish migratingupstream to spawn - are key data for conservation and fishery management.Existing methods for salmon counting using high-resolution imaging sonarhardware are non-invasive and compatible with computer vision processing. Priorwork in this area has utilized object detection and tracking based methods forautomated salmon counting. However, these techniques remain inaccessible tomany sonar deployment sites due to limited compute and connectivity in thefield. We propose an alternative lightweight computer vision method for fishcounting based on analyzing echograms - temporal representations that compressseveral hundred frames of imaging sonar video into a single image. We predictupstream and downstream counts within 200-frame time windows directly fromechograms using a ResNet-18 model, and propose a set of domain-specific imageaugmentations and a weakly-supervised training protocol to further improveresults. We achieve a count error of 23% on representative data from the KenaiRiver in Alaska, demonstrating the feasibility of our approach.</description><author>Kai Van Brunt, Justin Kay, Timm Haucke, Pietro Perona, Grant Van Horn, Sara Beery</author><pubDate>Fri, 07 Feb 2025 18:02:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05129v1</guid></item><item><title>Self-supervised Conformal Prediction for Uncertainty Quantification in Imaging Problems</title><link>http://arxiv.org/abs/2502.05127v1</link><description>Most image restoration problems are ill-conditioned or ill-posed and henceinvolve significant uncertainty. Quantifying this uncertainty is crucial forreliably interpreting experimental results, particularly when reconstructedimages inform critical decisions and science. However, most existing imagerestoration methods either fail to quantify uncertainty or provide estimatesthat are highly inaccurate. Conformal prediction has recently emerged as aflexible framework to equip any estimator with uncertainty quantificationcapabilities that, by construction, have nearly exact marginal coverage. Toachieve this, conformal prediction relies on abundant ground truth data forcalibration. However, in image restoration problems, reliable ground truth datais often expensive or not possible to acquire. Also, reliance on ground truthdata can introduce large biases in situations of distribution shift betweencalibration and deployment. This paper seeks to develop a more robust approachto conformal prediction for image restoration problems by proposing aself-supervised conformal prediction method that leverages Stein's UnbiasedRisk Estimator (SURE) to self-calibrate itself directly from the observed noisymeasurements, bypassing the need for ground truth. The method is suitable forany linear imaging inverse problem that is ill-conditioned, and it isespecially powerful when used with modern self-supervised image restorationtechniques that can also be trained directly from measurement data. Theproposed approach is demonstrated through numerical experiments on imagedenoising and deblurring, where it delivers results that are remarkablyaccurate and comparable to those obtained by supervised conformal predictionwith ground truth data.</description><author>Jasper M. Everink, Bernardin Tamo Amougou, Marcelo Pereyra</author><pubDate>Fri, 07 Feb 2025 18:00:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05127v1</guid></item><item><title>Distinguishing Cause from Effect with Causal Velocity Models</title><link>http://arxiv.org/abs/2502.05122v1</link><description>Bivariate structural causal models (SCM) are often used to infer causaldirection by examining their goodness-of-fit under restricted model classes. Inthis paper, we describe a parametrization of bivariate SCMs in terms of acausal velocity by viewing the cause variable as time in a dynamical system.The velocity implicitly defines counterfactual curves via the solution ofinitial value problems where the observation specifies the initial condition.Using tools from measure transport, we obtain a unique correspondence betweenSCMs and the score function of the generated distribution via its causalvelocity. Based on this, we derive an objective function that directlyregresses the velocity against the score function, the latter of which can beestimated non-parametrically from observational data. We use this to develop amethod for bivariate causal discovery that extends beyond known model classessuch as additive or location scale noise, and that requires no assumptions onthe noise distributions. When the score is estimated well, the objective isalso useful for detecting model non-identifiability and misspecification. Wepresent positive results in simulation and benchmark experiments where manyexisting methods fail, and perform ablation studies to examine the method'ssensitivity to accurate score estimation.</description><author>Johnny Xi, Hugh Dance, Peter Orbanz, Benjamin Bloem-Reddy</author><pubDate>Fri, 07 Feb 2025 17:50:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05122v1</guid></item><item><title>Refining Integration-by-Parts Reduction of Feynman Integrals with Machine Learning</title><link>http://arxiv.org/abs/2502.05121v1</link><description>Integration-by-parts reductions of Feynman integrals pose a frequentbottle-neck in state-of-the-art calculations in theoretical particle andgravitational-wave physics, and rely on heuristic approaches for selectingintegration-by-parts identities, whose quality heavily influences theperformance. In this paper, we investigate the use of machine-learningtechniques to find improved heuristics. We use funsearch, a genetic programmingvariant based on code generation by a Large Language Model, in order to explorepossible approaches, then use strongly typed genetic programming to zero in onuseful solutions. Both approaches manage to re-discover the state-of-the-artheuristics recently incorporated into integration-by-parts solvers, and in oneexample find a small advance on this state of the art.</description><author>Matt von Hippel, Matthias Wilhelm</author><pubDate>Fri, 07 Feb 2025 17:48:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05121v1</guid></item><item><title>Interpreting token compositionality in LLMs: A robustness analysis</title><link>http://arxiv.org/abs/2410.12924v2</link><description>Understanding the internal mechanisms of large language models (LLMs) isintegral to enhancing their reliability, interpretability, and inferenceprocesses. We present Constituent-Aware Pooling (CAP), a methodology designedto analyse how LLMs process compositional linguistic structures. Grounded inprinciples of compositionality, mechanistic interpretability, and informationtheory, CAP systematically intervenes in model activations throughconstituent-based pooling at various model levels. Our experiments on inversedefinition modelling, hypernym and synonym prediction reveal critical insightsinto transformers' limitations in handling compositional abstractions. Nospecific layer integrates tokens into unified semantic representations based ontheir constituent parts. We observe fragmented information processing, whichintensifies with model size, suggesting that larger models struggle more withthese interventions and exhibit greater information dispersion. Thisfragmentation likely stems from transformers' training objectives andarchitectural design, preventing systematic and cohesive representations. Ourfindings highlight fundamental limitations in current transformer architecturesregarding compositional semantics processing and model interpretability,underscoring the critical need for novel approaches in LLM design to addressthese challenges.</description><author>Nura Aljaafari, Danilo S. Carvalho, André Freitas</author><pubDate>Fri, 07 Feb 2025 17:44:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12924v2</guid></item><item><title>Investigating the impact of kernel harmonization and deformable registration on inspiratory and expiratory chest CT images for people with COPD</title><link>http://arxiv.org/abs/2502.05119v1</link><description>Paired inspiratory-expiratory CT scans enable the quantification of gastrapping due to small airway disease and emphysema by analyzing lung tissuemotion in COPD patients. Deformable image registration of these scans assessesregional lung volumetric changes. However, variations in reconstruction kernelsbetween paired scans introduce errors in quantitative analysis. This workproposes a two-stage pipeline to harmonize reconstruction kernels and performdeformable image registration using data acquired from the COPDGene study. Weuse a cycle generative adversarial network (GAN) to harmonize inspiratory scansreconstructed with a hard kernel (BONE) to match expiratory scans reconstructedwith a soft kernel (STANDARD). We then deformably register the expiratory scansto inspiratory scans. We validate harmonization by measuring emphysema using apublicly available segmentation algorithm before and after harmonization.Results show harmonization significantly reduces emphysema measurementinconsistencies, decreasing median emphysema scores from 10.479% to 3.039%,with a reference median score of 1.305% from the STANDARD kernel as the target.Registration accuracy is evaluated via Dice overlap between emphysema regionson inspiratory, expiratory, and deformed images. The Dice coefficient betweeninspiratory emphysema masks and deformably registered emphysema masks increasessignificantly across registration stages (p&lt;0.001). Additionally, wedemonstrate that deformable registration is robust to kernel variations.</description><author>Aravind R. Krishnan, Yihao Liu, Kaiwen Xu, Michael E. Kim, Lucas W. Remedios, Gaurav Rudravaram, Adam M. Saunders, Bradley W. Richmond, Kim L. Sandler, Fabien Maldonado, Bennett A. Landman, Lianrui Zuo</author><pubDate>Fri, 07 Feb 2025 17:41:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05119v1</guid></item><item><title>Predicting Steady-State Behavior in Complex Networks with Graph Neural Networks</title><link>http://arxiv.org/abs/2502.01693v2</link><description>In complex systems, information propagation can be defined as diffused ordelocalized, weakly localized, and strongly localized. This study investigatesthe application of graph neural network models to learn the behavior of alinear dynamical system on networks. A graph convolution and attention-basedneural network framework has been developed to identify the steady-statebehavior of the linear dynamical system. We reveal that our trained modeldistinguishes the different states with high accuracy. Furthermore, we haveevaluated model performance with real-world data. In addition, to understandthe explainability of our model, we provide an analytical derivation for theforward and backward propagation of our framework.</description><author>Priodyuti Pradhan, Amit Reza</author><pubDate>Fri, 07 Feb 2025 17:40:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.01693v2</guid></item><item><title>Optimizing Wireless Resource Management and Synchronization in Digital Twin Networks</title><link>http://arxiv.org/abs/2502.05116v1</link><description>In this paper, we investigate an accurate synchronization between a physicalnetwork and its digital network twin (DNT), which serves as a virtualrepresentation of the physical network. The considered network includes a setof base stations (BSs) that must allocate its limited spectrum resources toserve a set of users while also transmitting its partially observed physicalnetwork information to a cloud server to generate the DNT. Since the DNT canpredict the physical network status based on its historical status, the BSs maynot need to send their physical network information at each time slot, allowingthem to conserve spectrum resources to serve the users. However, if the DNTdoes not receive the physical network information of the BSs over a large timeperiod, the DNT's accuracy in representing the physical network may degrade. Tothis end, each BS must decide when to send the physical network information tothe cloud server to update the DNT, while also determining the spectrumresource allocation policy for both DNT synchronization and serving the users.We formulate this resource allocation task as an optimization problem, aimingto maximize the total data rate of all users while minimizing theasynchronization between the physical network and the DNT. To address thisproblem, we propose a method based on the GRUs and the value decompositionnetwork (VDN). Simulation results show that our GRU and VDN based algorithmimproves the weighted sum of data rates and the similarity between the statusof the DNT and the physical network by up to 28.96%, compared to a baselinemethod combining GRU with the independent Q learning.</description><author>Hanzhi Yu, Yuchen Liu, Zhaohui Yang, Haijian Sun, Mingzhe Chen</author><pubDate>Fri, 07 Feb 2025 17:38:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05116v1</guid></item><item><title>"It Felt Like I Was Left in the Dark": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings</title><link>http://arxiv.org/abs/2502.05115v1</link><description>Older adult patients constitute a rapidly growing subgroup of Intensive CareUnit (ICU) patients. In these situations, their family caregivers are expectedto represent the unconscious patients to access and interpret patients' medicalinformation. However, caregivers currently have to rely on overloadedclinicians for information updates and typically lack the health literacy tounderstand complex medical information. Our project aims to explore theinformation needs of caregivers of ICU older adult patients, from which we canpropose design opportunities to guide future AI systems. The project beginswith formative interviews with 11 caregivers to identify their challenges inaccessing and interpreting medical information; From these findings, we thensynthesize design requirements and propose an AI system prototype to cope withcaregivers' challenges. The system prototype has two key features: a timelinevisualization to show the AI extracted and summarized older adult patients' keymedical events; and an LLM-based chatbot to provide context-aware informationalsupport. We conclude our paper by reporting on the follow-up user evaluation ofthe system and discussing future AI-based systems for ICU caregivers of olderadults.</description><author>Shihan Fu, Bingsheng Yao, Smit Desai, Yuqi Hu, Yuling Sun, Samantha Stonbraker, Yanjun Gao, Elizabeth M. Goldberg, Dakuo Wang</author><pubDate>Fri, 07 Feb 2025 17:38:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05115v1</guid></item><item><title>SpecTUS: Spectral Translator for Unknown Structures annotation from EI-MS spectra</title><link>http://arxiv.org/abs/2502.05114v1</link><description>Compound identification and structure annotation from mass spectra is awell-established task widely applied in drug detection, criminal forensics,small molecule biomarker discovery and chemical engineering. We propose SpecTUS: Spectral Translator for Unknown Structures, a deep neuralmodel that addresses the task of structural annotation of small molecules fromlow-resolution gas chromatography electron ionization mass spectra (GC-EI-MS).Our model analyzes the spectra in \textit{de novo} manner -- a directtranslation from the spectra into 2D-structural representation. Our approach isparticularly useful for analyzing compounds unavailable in spectral libraries. In a rigorous evaluation of our model on the novel structure annotation taskacross different libraries, we outperformed standard database search techniquesby a wide margin. On a held-out testing set, including \numprint{28267} spectrafrom the NIST database, we show that our model's single suggestion perfectlyreconstructs 43\% of the subset's compounds. This single suggestion is strictlybetter than the candidate of the database hybrid search (common method amongpractitioners) in 76\% of cases. In a~still affordable scenario of~10 suggestions, perfectreconstruction is achieved in 65\%, and 84\% are better than the hybrid search.</description><author>Adam Hájek, Helge Hecht, Elliott J. Price, Aleš Křenek</author><pubDate>Fri, 07 Feb 2025 17:36:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05114v1</guid></item><item><title>GiesKaNe: Bridging Past and Present in Grammatical Theory and Practical Application</title><link>http://arxiv.org/abs/2502.05113v1</link><description>This article explores the requirements for corpus compilation within theGiesKaNe project (University of Giessen and Kassel, Syntactic Basic Structuresof New High German). The project is defined by three central characteristics:it is a reference corpus, a historical corpus, and a syntactically deeplyannotated treebank. As a historical corpus, GiesKaNe aims to establishconnections with both historical and contemporary corpora, ensuring itsrelevance across temporal and linguistic contexts. The compilation processstrikes the balance between innovation and adherence to standards, addressingboth internal project goals and the broader interests of the researchcommunity. The methodological complexity of such a project is managed through acomplementary interplay of human expertise and machine-assisted processes. Thearticle discusses foundational topics such as tokenization, normalization,sentence definition, tagging, parsing, and inter-annotator agreement, alongsideadvanced considerations. These include comparisons between grammatical models,annotation schemas, and established de facto annotation standards as well asthe integration of human and machine collaboration. Notably, a novel method formachine-assisted classification of texts along the continuum of conceptualorality and literacy is proposed, offering new perspectives on text selection.Furthermore, the article introduces an approach to deriving de facto standardannotations from existing ones, mediating between standardization andinnovation. In the course of describing the workflow the article demonstratesthat even ambitious projects like GiesKaNe can be effectively implemented usingexisting research infrastructure, requiring no specialized annotation tools.Instead, it is shown that the workflow can be based on the strategic use of asimple spreadsheet and integrates the capabilities of the existinginfrastructure.</description><author>Volker Emmrich</author><pubDate>Fri, 07 Feb 2025 17:35:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05113v1</guid></item><item><title>Measuring Variable Importance in Heterogeneous Treatment Effects with Confidence</title><link>http://arxiv.org/abs/2408.13002v2</link><description>Causal machine learning (ML) holds promise for estimating individualtreatment effects from complex data. For successful real-world applicationsusing machine learning methods, it is of paramount importance to obtainreliable insights into which variables drive heterogeneity in the response totreatment. We propose PermuCATE, an algorithm based on the ConditionalPermutation Importance (CPI) method, for statistically rigorous global variableimportance assessment in the estimation of the Conditional Average TreatmentEffect (CATE). Theoretical analysis of the finite sample regime and empiricalstudies show that PermuCATE has lower variance than the Leave-One-Covariate-Out(LOCO) reference method and provides a reliable measure of variable importance.This property increases statistical power, which is crucial for causalinference in the limited-data regime common to biomedical applications. Weempirically demonstrate the benefits of PermuCATE in simulated and real-worldhealth datasets, including settings with up to hundreds of correlatedvariables.</description><author>Joseph Paillard, Angel Reyero Lobo, Vitaliy Kolodyazhniy, Bertrand Thirion, Denis A. Engemann</author><pubDate>Fri, 07 Feb 2025 17:35:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.13002v2</guid></item><item><title>Flexible and Efficient Grammar-Constrained Decoding</title><link>http://arxiv.org/abs/2502.05111v1</link><description>Large Language Models (LLMs) are often asked to generate structured outputsthat obey precise syntactic rules, such as code snippets or formatted data.Grammar-constrained decoding (GCD) can guarantee that LLM outputs matches suchrules by masking out tokens that will provably lead to outputs that do notbelong to a specified context-free grammar (CFG). To guarantee soundness, GCDalgorithms have to compute how a given LLM subword tokenizer can align with thetokens used by a given context-free grammar and compute token masks based on thisinformation. Doing so efficiently is challenging and existing GCD algorithmsrequire tens of minutes to preprocess common grammars. We present a new GCDalgorithm together with an implementation that offers 17.71x faster offlinepreprocessing than existing approaches while preserving state-of-the-artefficiency in online mask computation.</description><author>Kanghee Park, Timothy Zhou, Loris D'Antoni</author><pubDate>Fri, 07 Feb 2025 17:35:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05111v1</guid></item><item><title>ApplE: An Applied Ethics Ontology with Event Context</title><link>http://arxiv.org/abs/2502.05110v1</link><description>Applied ethics is ubiquitous in most domains, requiring much deliberation dueto its philosophical nature. Varying views often lead to conflicting courses ofaction where ethical dilemmas become challenging to resolve. Although manyfactors contribute to such a decision, the major driving forces can bediscretized and thus simplified to provide an indicative answer. Knowledgerepresentation and reasoning offer a way to explicitly translate abstractethical concepts into applicable principles within the context of an event. Toachieve this, we propose ApplE, an Applied Ethics ontology that capturesphilosophical theory and event context to holistically describe the morality ofan action. The development process adheres to a modified version of theSimplified Agile Methodology for Ontology Development (SAMOD) and utilizesstandard design and publication practices. Using ApplE, we model a use casefrom the bioethics domain that demonstrates our ontology's social andscientific value. Apart from the ontological reasoning and quality checks,ApplE is also evaluated using the three-fold testing process of SAMOD. ApplEfollows FAIR principles and aims to be a viable resource for applied ethicistsand ontology engineers.</description><author>Aisha Aijaz, Raghava Mutharaju, Manohar Kumar</author><pubDate>Fri, 07 Feb 2025 17:34:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05110v1</guid></item><item><title>Supervised Quadratic Feature Analysis: An Information Geometry Approach to Dimensionality Reduction</title><link>http://arxiv.org/abs/2502.00168v2</link><description>Supervised dimensionality reduction aims to map labeled data to alow-dimensional feature space while maximizing class discriminability. Despitethe availability of methods for learning complex non-linear features (e.g. DeepLearning), there is an enduring demand for dimensionality reduction methodsthat learn linear features due to their interpretability, low computationalcost, and broad applicability. However, there is a gap between methods thatoptimize linear separability (e.g. LDA), and more flexible but computationallyexpensive methods that optimize over arbitrary class boundaries (e.g.metric-learning methods). Here, we present Supervised Quadratic FeatureAnalysis (SQFA), a dimensionality reduction method for learning linear featuresthat maximize the differences between class-conditional first- and second-orderstatistics, which allow for quadratic discrimination. SQFA exploits theinformation geometry of second-order statistics in the symmetric positivedefinite manifold. We show that SQFA features support quadraticdiscriminability in real-world problems. We also provide a theoretical link,based on information geometry, between SQFA and the Quadratic DiscriminantAnalysis (QDA) classifier.</description><author>Daniel Herrera-Esposito, Johannes Burge</author><pubDate>Fri, 07 Feb 2025 17:31:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.00168v2</guid></item><item><title>Grounding Continuous Representations in Geometry: Equivariant Neural Fields</title><link>http://arxiv.org/abs/2406.05753v5</link><description>Conditional Neural Fields (CNFs) are increasingly being leveraged ascontinuous signal representations, by associating each data-sample with alatent variable that conditions a shared backbone Neural Field (NeF) toreconstruct the sample. However, existing CNF architectures face limitationswhen using this latent downstream in tasks requiring fine-grained geometricreasoning, such as classification and segmentation. We posit that this resultsfrom lack of explicit modelling of geometric information (e.g., locality in thesignal or the orientation of a feature) in the latent space of CNFs. As such,we propose Equivariant Neural Fields (ENFs), a novel CNF architecture whichuses a geometry-informed cross-attention to condition the NeF on a geometricvariable--a latent point cloud of features--that enables an equivariantdecoding from latent to field. We show that this approach induces asteerability property by which both field and latent are grounded in geometryand amenable to transformation laws: if the field transforms, the latentrepresentation transforms accordingly--and vice versa. Crucially, thisequivariance relation ensures that the latent is capable of (1) representinggeometric patterns faithfully, allowing for geometric reasoning in latentspace, and (2) weight-sharing over similar local patterns, allowing forefficient learning of datasets of fields. We validate these main properties ina range of tasks including classification, segmentation, forecasting,reconstruction and generative modelling, showing clear improvement overbaselines with a geometry-free latent space. Code attached to submissionhttps://github.com/Dafidofff/enf-jax. Code for a clean and minimal repohttps://github.com/david-knigge/enf-min-jax.</description><author>David R Wessels, David M Knigge, Samuele Papa, Riccardo Valperga, Sharvaree Vadgama, Efstratios Gavves, Erik J Bekkers</author><pubDate>Fri, 07 Feb 2025 17:31:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05753v5</guid></item><item><title>Graph Contrastive Learning for Connectome Classification</title><link>http://arxiv.org/abs/2502.05109v1</link><description>With recent advancements in non-invasive techniques for measuring brainactivity, such as magnetic resonance imaging (MRI), the study of structural andfunctional brain networks through graph signal processing (GSP) has gainednotable prominence. GSP stands as a key tool in unraveling the interplaybetween the brain's function and structure, enabling the analysis of graphsdefined by the connections between regions of interest -- referred to asconnectomes in this context. Our work represents a further step in thisdirection by exploring supervised contrastive learning methods within the realmof graph representation learning. The main objective of this approach is togenerate subject-level (i.e., graph-level) vector representations that bringtogether subjects sharing the same label while separating those with differentlabels. These connectome embeddings are derived from a graph neural networkEncoder-Decoder architecture, which jointly considers structural and functionalconnectivity. By leveraging data augmentation techniques, the proposedframework achieves state-of-the-art performance in a gender classification taskusing Human Connectome Project data. More broadly, our connectome-centricmethodological advances support the promising prospect of using GSP to discovermore about brain function, with potential impact to understanding heterogeneityin the neurodegeneration for precision medicine and diagnosis.</description><author>Martín Schmidt, Sara Silva, Federico Larroca, Gonzalo Mateos, Pablo Musé</author><pubDate>Fri, 07 Feb 2025 17:30:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05109v1</guid></item><item><title>Pareto-Optimal Learning from Preferences with Hidden Context</title><link>http://arxiv.org/abs/2406.15599v2</link><description>Ensuring AI models align with human values is essential for their safety andfunctionality. Reinforcement learning from human feedback (RLHF) leverageshuman preferences to achieve this alignment. However, when preferences aresourced from diverse populations, point estimates of reward can result insuboptimal performance or be unfair to specific groups. We propose ParetoOptimal Preference Learning (POPL), which enables pluralistic alignment byframing discrepant group preferences as objectives with potential trade-offs,aiming for policies that are Pareto-optimal on the preference dataset. POPLutilizes lexicase selection, an iterative process that selects diverse andPareto-optimal solutions. Our theoretical and empirical evaluations demonstratethat POPL surpasses baseline methods in learning sets of reward functions andpolicies, effectively catering to distinct groups without access to groupnumbers or membership labels. We verify the performance of POPL on a statelesspreference learning setting, a Minigrid RL domain, Metaworld roboticsbenchmarks, as well as large language model (LLM) fine-tuning. We illustratethat POPL can also serve as a foundation for techniques optimizing specificnotions of group fairness, ensuring safe and equitable AI model alignment.</description><author>Ryan Bahlous-Boldi, Li Ding, Lee Spector, Scott Niekum</author><pubDate>Fri, 07 Feb 2025 17:29:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15599v2</guid></item><item><title>3DMolFormer: A Dual-channel Framework for Structure-based Drug Discovery</title><link>http://arxiv.org/abs/2502.05107v1</link><description>Structure-based drug discovery, encompassing the tasks of protein-liganddocking and pocket-aware 3D drug design, represents a core challenge in drugdiscovery. However, no existing work can deal with both tasks to effectivelyleverage the duality between them, and current methods for each task arehindered by challenges in modeling 3D information and the limitations ofavailable data. To address these issues, we propose 3DMolFormer, a unifieddual-channel transformer-based framework applicable to both docking and 3D drugdesign tasks, which exploits their duality by utilizing docking functionalitieswithin the drug design process. Specifically, we represent 3D pocket-ligandcomplexes using parallel sequences of discrete tokens and continuous numbers,and we design a corresponding dual-channel transformer model to handle thisformat, thereby overcoming the challenges of 3D information modeling.Additionally, we alleviate data limitations through large-scale pre-training ona mixed dataset, followed by supervised and reinforcement learning fine-tuningtechniques respectively tailored for the two tasks. Experimental resultsdemonstrate that 3DMolFormer outperforms previous approaches in bothprotein-ligand docking and pocket-aware 3D drug design, highlighting itspromising application in structure-based drug discovery. The code is availableat: https://github.com/HXYfighter/3DMolFormer .</description><author>Xiuyuan Hu, Guoqing Liu, Can Chen, Yang Zhao, Hao Zhang, Xue Liu</author><pubDate>Fri, 07 Feb 2025 17:28:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05107v1</guid></item><item><title>Leveraging Hypernetworks and Learnable Kernels for Consumer Energy Forecasting Across Diverse Consumer Types</title><link>http://arxiv.org/abs/2502.05104v1</link><description>Consumer energy forecasting is essential for managing energy consumption andplanning, directly influencing operational efficiency, cost reduction,personalized energy management, and sustainability efforts. In recent years,deep learning techniques, especially LSTMs and transformers, have been greatlysuccessful in the field of energy consumption forecasting. Nevertheless, thesetechniques have difficulties in capturing complex and sudden variations, and,moreover, they are commonly examined only on a specific type of consumer (e.g.,only offices, only schools). Consequently, this paper proposes HyperEnergy, aconsumer energy forecasting strategy that leverages hypernetworks for improvedmodeling of complex patterns applicable across a diversity of consumers.Hypernetwork is responsible for predicting the parameters of the primaryprediction network, in our case LSTM. A learnable adaptable kernel, comprisedof polynomial and radial basis function kernels, is incorporated to enhanceperformance. The proposed HyperEnergy was evaluated on diverse consumersincluding, student residences, detached homes, a home with electric vehiclecharging, and a townhouse. Across all consumer types, HyperEnergy consistentlyoutperformed 10 other techniques, including state-of-the-art models such asLSTM, AttentionLSTM, and transformer.</description><author>Muhammad Umair Danish, Katarina Grolinger</author><pubDate>Fri, 07 Feb 2025 17:25:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05104v1</guid></item><item><title>Time Series Analysis of Rankings: A GARCH-Type Approach</title><link>http://arxiv.org/abs/2502.05102v1</link><description>Ranking data are frequently obtained nowadays but there are still scarcemethods for treating these data when temporally observed. The present papercontributes to this topic by proposing and developing novel models for handlingtime series of ranking data. We introduce a class of time-varying rankingmodels inspired by the Generalized AutoRegressive ConditionalHeteroskedasticity (GARCH) models. More specifically, the temporal dynamics aredefined by the conditional distribution of the current ranking given the pastrankings, which are assumed to follow a Mallows distribution, which implicitlydepends on a distance. Then, autoregressive and feedback components areincorporated into the model through the conditional expectation of theassociated distances. Theoretical properties of our ranking GARCH models suchas stationarity and ergodicity are established. The estimation of parameters isperformed via maximum likelihood estimation when data is fully observed. Wedevelop a Monte Carlo Expectation-Maximisation algorithm to deal with casesinvolving missing data. Monte Carlo simulation studies are presented to studythe performance of the proposed estimators under both non-missing and missingdata scenarios. A real data application about the weekly ranking ofprofessional tennis players from 2015 to 2019 is presented under our proposedranking GARCH models.</description><author>Luiza Piancastelli, Wagner Barreto-Souza</author><pubDate>Fri, 07 Feb 2025 17:23:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05102v1</guid></item><item><title>Learning Temporal Invariance in Android Malware Detectors</title><link>http://arxiv.org/abs/2502.05098v1</link><description>Learning-based Android malware detectors degrade over time due to naturaldistribution drift caused by malware variants and new families. This papersystematically investigates the challenges classifiers trained with empiricalrisk minimization (ERM) face against such distribution shifts and attributestheir shortcomings to their inability to learn stable discriminative features.Invariant learning theory offers a promising solution by encouraging models togenerate stable representations crossing environments that expose theinstability of the training set. However, the lack of prior environment labels,the diversity of drift factors, and low-quality representations caused bydiverse families make this task challenging. To address these issues, wepropose TIF, the first temporal invariant training framework for malwaredetection, which aims to enhance the ability of detectors to learn stablerepresentations across time. TIF organizes environments based on applicationobservation dates to reveal temporal drift, integrating specialized multi-proxycontrastive learning and invariant gradient alignment to generate and alignenvironments with high-quality, stable representations. TIF can be seamlesslyintegrated into any learning-based detector. Experiments on a decade-longdataset show that TIF excels, particularly in early deployment stages,addressing real-world needs and outperforming state-of-the-art methods.</description><author>Xinran Zheng, Shuo Yang, Edith C. H. Ngai, Suman Jana, Lorenzo Cavallaro</author><pubDate>Fri, 07 Feb 2025 17:17:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05098v1</guid></item><item><title>Enhancing Compositional Text-to-Image Generation with Reliable Random Seeds</title><link>http://arxiv.org/abs/2411.18810v3</link><description>Text-to-image diffusion models have demonstrated remarkable capability ingenerating realistic images from arbitrary text prompts. However, they oftenproduce inconsistent results for compositional prompts such as "two dogs" or "apenguin on the right of a bowl". Understanding these inconsistencies is crucialfor reliable image generation. In this paper, we highlight the significant roleof initial noise in these inconsistencies, where certain noise patterns aremore reliable for compositional prompts than others. Our analyses reveal thatdifferent initial random seeds tend to guide the model to place objects indistinct image areas, potentially adhering to specific patterns of cameraangles and image composition associated with the seed. To improve the model'scompositional ability, we propose a method for mining these reliable cases,resulting in a curated training set of generated images without requiring anymanual annotation. By fine-tuning text-to-image models on these generatedimages, we significantly enhance their compositional capabilities. Fornumerical composition, we observe relative increases of 29.3% and 19.5% forStable Diffusion and PixArt-{\alpha}, respectively. Spatial composition seeseven larger gains, with 60.7% for Stable Diffusion and 21.1% forPixArt-{\alpha}.</description><author>Shuangqi Li, Hieu Le, Jingyi Xu, Mathieu Salzmann</author><pubDate>Fri, 07 Feb 2025 17:14:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.18810v3</guid></item><item><title>Non-linear Quantum Monte Carlo</title><link>http://arxiv.org/abs/2502.05094v1</link><description>The mean of a random variable can be understood as a $\textit{linear}$functional on the space of probability distributions. Quantum computing isknown to provide a quadratic speedup over classical Monte Carlo methods formean estimation. In this paper, we investigate whether a similar quadraticspeedup is achievable for estimating $\textit{non-linear}$ functionals ofprobability distributions. We propose a quantum-inside-quantum Monte Carloalgorithm that achieves such a speedup for a broad class of non-linearestimation problems, including nested conditional expectations and stochasticoptimization. Our algorithm improves upon the direct application of the quantummultilevel Monte Carlo algorithm introduced by An et al.. The existing lowerbound indicates that our algorithm is optimal up polylogarithmic factors. A keyinnovation of our approach is a new sequence of multilevel Monte Carloapproximations specifically designed for quantum computing, which is central tothe algorithm's improved performance.</description><author>Jose Blanchet, Yassine Hamoudi, Mario Szegedy, Guanyang Wang</author><pubDate>Fri, 07 Feb 2025 17:13:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05094v1</guid></item><item><title>Lost in Time: Clock and Calendar Understanding Challenges in Multimodal LLMs</title><link>http://arxiv.org/abs/2502.05092v1</link><description>Understanding time from visual representations is a fundamental cognitiveskill, yet it remains a challenge for multimodal large language models (MLLMs).In this work, we investigate the capabilities of MLLMs in interpreting time anddate through analogue clocks and yearly calendars. To facilitate this, wecurated a structured dataset comprising two subsets: 1) $\textit{ClockQA}$,which comprises various types of clock styles$-$standard, black-dial,no-second-hand, Roman numeral, and arrow-hand clocks$-$paired with time relatedquestions; and 2) $\textit{CalendarQA}$, which consists of yearly calendarimages with questions ranging from commonly known dates (e.g., Christmas, NewYear's Day) to computationally derived ones (e.g., the 100th or 153rd day ofthe year). We aim to analyse how MLLMs can perform visual recognition,numerical reasoning, and temporal inference when presented with time-relatedvisual data. Our evaluations show that despite recent advancements, reliablyunderstanding time remains a significant challenge for MLLMs.</description><author>Rohit Saxena, Aryo Pradipta Gema, Pasquale Minervini</author><pubDate>Fri, 07 Feb 2025 17:11:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05092v1</guid></item><item><title>DCFormer: Efficient 3D Vision-Language Modeling with Decomposed Convolutions</title><link>http://arxiv.org/abs/2502.05091v1</link><description>Vision-language models (VLMs) align visual and textual representations,enabling high-performance zero-shot classification and image-text retrieval in2D medical imaging. However, extending VLMs to 3D medical imaging remainscomputationally challenging. Existing 3D VLMs rely on Vision Transformers(ViTs), which are computationally expensive due to self-attention's quadraticcomplexity, or 3D convolutions, which demand excessive parameters and FLOPs askernel size increases. We introduce DCFormer, an efficient 3D medical imageencoder that factorizes 3D convolutions into three parallel 1D convolutionsalong depth, height, and width. This design preserves spatial information whilesignificantly reducing computational cost. Integrated into a CLIP-basedvision-language framework, DCFormer is evaluated on CT-RATE, a dataset of50,188 paired 3D chest CT volumes and radiology reports, for zero-shotmulti-abnormality detection across 18 pathologies. Compared to ViT, ConvNeXt,PoolFormer, and TransUNet, DCFormer achieves superior efficiency and accuracy,with DCFormer-Tiny reaching 62.0% accuracy and a 46.3% F1-score while usingsignificantly fewer parameters. These results highlight DCFormer's potentialfor scalable, clinically deployable 3D medical VLMs. Our codes will be publiclyavailable.</description><author>Gorkem Can Ates, Kuang Gong, Wei Shao</author><pubDate>Fri, 07 Feb 2025 17:10:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05091v1</guid></item><item><title>Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs</title><link>http://arxiv.org/abs/2502.05087v1</link><description>Federated learning (FL) is a popular paradigm for collaborative trainingwhich avoids direct data exposure between clients. However, data privacy issuesstill remain: FL-trained large language models are capable of memorizing andcompleting phrases and sentences contained in training data when given withtheir prefixes. Thus, it is possible for adversarial and honest-but-curiousclients to recover training data of other participants simply through targetedprompting. In this work, we demonstrate that a popular and simple fine-tuningstrategy, low-rank adaptation (LoRA), reduces memorization during FL up to afactor of 10. We study this effect by performing a medical question-answeringfine-tuning task and injecting multiple replicas of out-of-distributionsensitive sequences drawn from an external clinical dataset. We observe areduction in memorization for a wide variety of Llama 2 and 3 models, and findthat LoRA can reduce memorization in centralized learning as well. Furthermore,we show that LoRA can be combined with other privacy-preserving techniques suchas gradient clipping and Gaussian noising, secure aggregation, and Goldfishloss to further improve record-level privacy while maintaining performance.</description><author>Thierry Bossy, Julien Vignoud, Tahseen Rabbani, Juan R. Troncoso Pastoriza, Martin Jaggi</author><pubDate>Fri, 07 Feb 2025 17:04:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05087v1</guid></item><item><title>Causality can systematically address the monsters under the bench(marks)</title><link>http://arxiv.org/abs/2502.05085v1</link><description>Effective and reliable evaluation is essential for advancing empiricalmachine learning. However, the increasing accessibility of generalist modelsand the progress towards ever more complex, high-level tasks make systematicevaluation more challenging. Benchmarks are plagued by various biases,artifacts, or leakage, while models may behave unreliably due to poorlyexplored failure modes. Haphazard treatments and inconsistent formulations ofsuch "monsters" can contribute to a duplication of efforts, a lack of trust inresults, and unsupported inferences. In this position paper, we argue causalityoffers an ideal framework to systematically address these challenges. By makingcausal assumptions in an approach explicit, we can faithfully model phenomena,formulate testable hypotheses with explanatory power, and leverage principledtools for analysis. To make causal model design more accessible, we identifyseveral useful Common Abstract Topologies (CATs) in causal graphs which helpgain insight into the reasoning abilities in large language models. Through aseries of case studies, we demonstrate how the precise yet pragmatic languageof causality clarifies the strengths and limitations of a method and inspiresnew approaches for systematic progress.</description><author>Felix Leeb, Zhijing Jin, Bernhard Schölkopf</author><pubDate>Fri, 07 Feb 2025 17:01:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05085v1</guid></item><item><title>ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework</title><link>http://arxiv.org/abs/2502.05084v1</link><description>The astonishing performance of large language models (LLMs) and theirremarkable achievements in production and daily life have led to theirwidespread application in collaborative tasks. However, current large modelsface challenges such as hallucination and lack of specificity in contentgeneration in vertical domain tasks. Inspired by the contrast andclassification mechanisms in human cognitive processes, this paper constructsan adversarial learning-based prompt framework named ChallengeMe, whichincludes three cascaded solutions: generation prompts, evaluation prompts, andfeedback optimization. In this process, we designed seven core optimizationdimensions and set the threshold for adversarial learning. The results of mixedcase studies on the text summarization task show that the proposed frameworkcan generate more accurate and fluent text summaries compared to the currentadvanced mainstream LLMs.</description><author>Xiaoyu Deng, Ye Zhang, Tianmin Guo, Yongzhe Zhang, Zhengjian Kang, Hang Yang</author><pubDate>Fri, 07 Feb 2025 16:59:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05084v1</guid></item><item><title>Representation of Molecules via Algebraic Data Types : Advancing Beyond SMILES &amp; SELFIES</title><link>http://arxiv.org/abs/2501.13633v3</link><description>We introduce a novel molecular representation through Algebraic Data Types(ADTs) - composite data structures formed through the combination of simplertypes that obey algebraic laws. By explicitly considering how the datatype of arepresentation constrains the operations which may be performed, we ensuremeaningful inference can be performed over generative models (programs withsample} and score operations). This stands in contrast to string-basedrepresentations where string-type operations may only indirectly correspond tochemical and physical molecular properties, and at worst produce nonsensicaloutput. The ADT presented implements the Dietz representation for molecularconstitution via multigraphs and bonding systems, and uses atomic coordinatedata to represent 3D information and stereochemical features. This creates ageneral digital molecular representation which surpasses the limitations of thestring-based representations and the 2D-graph based models on which they arebased. In addition, we present novel support for quantum information throughrepresentation of shells, subshells, and orbitals, greatly expanding therepresentational scope beyond current approaches, for instance in MolecularOrbital theory. The framework's capabilities are demonstrated through keyapplications: Bayesian probabilistic programming is demonstrated throughintegration with LazyPPL, a lazy probabilistic programming library; moleculesare made instances of a group under rotation, necessary for geometric learningtechniques which exploit the invariance of molecular properties under differentrepresentations; and the framework's flexibility is demonstrated through anextension to model chemical reactions. After critiquing previousrepresentations, we provide an open-source solution in Haskell - a type-safe,purely functional programming language.</description><author>Oliver Goldstein, Samuel March</author><pubDate>Fri, 07 Feb 2025 16:58:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.13633v3</guid></item><item><title>The Origin and Evolution of Information Handling</title><link>http://arxiv.org/abs/2404.04374v5</link><description>Understanding the emergence and evolution of information handling isessential for unraveling the origins of life. Traditional genetic-first andmetabolism-first models fall short in explaining how instructional informationcontrol systems naturally arise from molecular dynamics. To address this gap,we adopt an information-first approach, integrating Hofmeyr's (F, A)-systems --an extension of Rosen's (M, R)-systems -- with temporal parametrization andmultiscale causality. These models, which embody closure to efficient causationwhile remaining open to formal causation, provide a robust framework forprimitive autopoiesis, anticipation, and adaptation. We establish a formalequivalence between extended (F, A)-systems and communicating X-machines,resolving self-referential challenges and demonstrating the hypercomputationalnature of life processes. Our stepwise model traces the evolution ofinformation handling from simple reaction networks that recognize regularlanguages to self-replicating chemical systems with memory and anticipatorycapabilities. This transition from analog to digital architectures enhancesevolutionary robustness and aligns with experimental evidence suggesting thatchemical computation does not require life-specific chemistry. Furthermore, weincorporate open-ended evolutionary dynamics driven by computationalundecidability and irreducibility, reinforcing the necessity of unconventionalcomputing frameworks. This computational enactivist perspective provides acohesive theoretical basis for a recently proposed trialectic betweenautopoiesis, anticipation and adaptation in order to solve the problem ofrelevance. By highlighting the critical role of hypercomputational processes inlife's emergence and evolution, our framework offers new insights into thefundamental principles underlying biological information processing.</description><author>Amahury Jafet López-Díaz, Hiroki Sayama, Carlos Gershenson</author><pubDate>Fri, 07 Feb 2025 16:54:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04374v5</guid></item><item><title>Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures</title><link>http://arxiv.org/abs/2502.05078v1</link><description>Large Language Models (LLMs) have demonstrated impressive reasoningcapabilities, yet their performance is highly dependent on the promptingstrategy and model scale. While reinforcement learning and fine-tuning havebeen deployed to boost reasoning, these approaches incur substantialcomputational and data overhead. In this work, we introduce Adaptive Graph ofThoughts (AGoT), a dynamic, graph-based inference framework that enhances LLMreasoning solely at test time. Rather than relying on fixed-step methods likeChain of Thought (CoT) or Tree of Thoughts (ToT), AGoT recursively decomposescomplex queries into structured subproblems, forming an dynamic directedacyclic graph (DAG) of interdependent reasoning steps. By selectively expandingonly those subproblems that require further analysis, AGoT unifies thestrengths of chain, tree, and graph paradigms into a cohesive framework thatallocates computation where it is most needed. We validate our approach ondiverse benchmarks spanning multi-hop retrieval, scientific reasoning, andmathematical problem-solving, achieving up to 46.2% improvement on scientificreasoning tasks (GPQA) - comparable to gains achieved through computationallyintensive reinforcement learning approaches and outperforming state-of-the-artiterative approaches. These results suggest that dynamic decomposition andstructured recursion offer a scalable, cost-effective alternative topost-training modifications, paving the way for more robust, general-purposereasoning in LLMs.</description><author>Tushar Pandey, Ara Ghukasyan, Oktay Goktas, Santosh Kumar Radha</author><pubDate>Fri, 07 Feb 2025 16:54:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05078v1</guid></item><item><title>Explicit Relational Reasoning Network for Scene Text Detection</title><link>http://arxiv.org/abs/2412.14692v3</link><description>Connected component (CC) is a proper text shape representation that alignswith human reading intuition. However, CC-based text detection methods haverecently faced a developmental bottleneck that their time-consumingpost-processing is difficult to eliminate. To address this issue, we introducean explicit relational reasoning network (ERRNet) to elegantly model thecomponent relationships without post-processing. Concretely, we first representeach text instance as multiple ordered text components, and then treat thesecomponents as objects in sequential movement. In this way, scene text detectioncan be innovatively viewed as a tracking problem. From this perspective, wedesign an end-to-end tracking decoder to achieve a CC-based method dispensingwith post-processing entirely. Additionally, we observe that there is aninconsistency between classification confidence and localization quality, so wepropose a Polygon Monte-Carlo method to quickly and accurately evaluate thelocalization quality. Based on this, we introduce a position-supervisedclassification loss to guide the task-aligned learning of ERRNet. Experimentson challenging benchmarks demonstrate the effectiveness of our ERRNet. Itconsistently achieves state-of-the-art accuracy while holding highlycompetitive inference speed.</description><author>Yuchen Su, Zhineng Chen, Yongkun Du, Zhilong Ji, Kai Hu, Jinfeng Bai, Xieping Gao</author><pubDate>Fri, 07 Feb 2025 16:51:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.14692v3</guid></item><item><title>Paying Attention to Facts: Quantifying the Knowledge Capacity of Attention Layers</title><link>http://arxiv.org/abs/2502.05076v1</link><description>In this paper, we investigate the ability of single-layer attention-onlytransformers (i.e. attention layers) to memorize facts contained in databasesfrom a linear-algebraic perspective. We associate with each database a3-tensor, propose the rank of this tensor as a measure of the size of thedatabase, and provide bounds on the rank in terms of properties of thedatabase. We also define a 3-tensor corresponding to an attention layer, andempirically demonstrate the relationship between its rank and database rank ona dataset of toy models and random databases. By highlighting the roles playedby the value-output and query-key weights, and the effects of argmax andsoftmax on rank, our results shed light on the `additive motif' of factualrecall in transformers, while also suggesting a way of increasing layercapacity without increasing the number of parameters.</description><author>Liang Ze Wong</author><pubDate>Fri, 07 Feb 2025 16:50:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05076v1</guid></item><item><title>Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension</title><link>http://arxiv.org/abs/2502.05075v1</link><description>Weak-to-strong (W2S) generalization is a type of finetuning (FT) where astrong (large) student model is trained on pseudo-labels generated by a weakteacher. Surprisingly, W2S FT often outperforms the weak teacher. We seek tounderstand this phenomenon through the observation that FT often occurs inintrinsically low-dimensional spaces. Leveraging the low intrinsicdimensionality of FT, we analyze W2S in the ridgeless regression setting from avariance reduction perspective. For a strong student - weak teacher pair withsufficiently expressive low-dimensional feature subspaces $\mathcal{V}_s,\mathcal{V}_w$, we provide an exact characterization of the variance thatdominates the generalization error of W2S. This unveils a virtue of discrepancybetween the strong and weak models in W2S: the variance of the weak teacher isinherited by the strong student in $\mathcal{V}_s \cap \mathcal{V}_w$, whilereduced by a factor of $\dim(\mathcal{V}_s)/N$ in the subspace of discrepancy$\mathcal{V}_w \setminus \mathcal{V}_s$ with $N$ pseudo-labels for W2S.Further, our analysis casts light on the sample complexities and the scaling ofperformance gap recovery in W2S. The analysis is supported with experiments onboth synthetic regression problems and real vision tasks.</description><author>Yijun Dong, Yicheng Li, Yunai Li, Jason D. Lee, Qi Lei</author><pubDate>Fri, 07 Feb 2025 16:46:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05075v1</guid></item><item><title>Two-Point Deterministic Equivalence for Stochastic Gradient Dynamics in Linear Models</title><link>http://arxiv.org/abs/2502.05074v1</link><description>We derive a novel deterministic equivalence for the two-point function of arandom matrix resolvent. Using this result, we give a unified derivation of theperformance of a wide variety of high-dimensional linear models trained withstochastic gradient descent. This includes high-dimensional linear regression,kernel regression, and random feature models. Our results include previouslyknown asymptotics as well as novel ones.</description><author>Alexander Atanasov, Blake Bordelon, Jacob A. Zavatone-Veth, Courtney Paquette, Cengiz Pehlevan</author><pubDate>Fri, 07 Feb 2025 16:45:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05074v1</guid></item><item><title>Noise Sensitivity of Hierarchical Functions and Deep Learning Lower Bounds in General Product Measures</title><link>http://arxiv.org/abs/2502.05073v1</link><description>Recent works explore deep learning's success by examining functions or datawith hierarchical structure. Complementarily, research on gradient descentperformance for deep nets has shown that noise sensitivity of functions underindependent and identically distributed (i.i.d.) Bernoulli inputs establisheslearning complexity bounds. This paper aims to bridge these research streams bydemonstrating that functions constructed through repeated composition ofnon-linear functions are noise sensitive under general product measures.</description><author>Rupert Li, Elchanan Mossel</author><pubDate>Fri, 07 Feb 2025 16:45:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05073v1</guid></item><item><title>Explainable Artificial Intelligence (XAI) for Malware Analysis: A Survey of Techniques, Applications, and Open Challenges</title><link>http://arxiv.org/abs/2409.13723v2</link><description>Machine learning (ML) has rapidly advanced in recent years, revolutionizingfields such as finance, medicine, and cybersecurity. In malware detection,ML-based approaches have demonstrated high accuracy; however, their lack oftransparency poses a significant challenge. Traditional black-box models oftenfail to provide interpretable justifications for their predictions, limitingtheir adoption in security-critical environments where understanding thereasoning behind a detection is essential for threat mitigation and response.Explainable AI (XAI) addresses this gap by enhancing model interpretabilitywhile maintaining strong detection capabilities. This survey presents acomprehensive review of state-of-the-art ML techniques for malware analysis,with a specific focus on explainability methods. We examine existing XAIframeworks, their application in malware classification and detection, and thechallenges associated with making malware detection models more interpretable.Additionally, we explore recent advancements and highlight open researchchallenges in the field of explainable malware analysis. By providing astructured overview of XAI-driven malware detection approaches, this surveyserves as a valuable resource for researchers and practitioners seeking tobridge the gap between ML performance and explainability in cybersecurity.</description><author>Harikha Manthena, Shaghayegh Shajarian, Jeffrey Kimmell, Mahmoud Abdelsalam, Sajad Khorsandroo, Maanak Gupta</author><pubDate>Fri, 07 Feb 2025 16:44:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.13723v2</guid></item><item><title>Consistent model selection in the spiked Wigner model via AIC-type criteria</title><link>http://arxiv.org/abs/2307.12982v2</link><description>Consider the spiked Wigner model \[ X = \sum_{i = 1}^k \lambda_i u_i u_i^\top + \sigma G, \] where $G$ is an $N\times N$ GOE random matrix, and the eigenvalues $\lambda_i$ are all spiked,i.e. above the Baik-Ben Arous-P\'ech\'e (BBP) threshold $\sigma$. We considerAIC-type model selection criteria of the form \[ -2 \, (\text{maximised log-likelihood}) + \gamma \, (\text{number ofparameters}) \] for estimating the number $k$ of spikes. For $\gamma &gt; 2$, theabove criterion is strongly consistent provided $\lambda_k &gt; \lambda_{\gamma}$,where $\lambda_{\gamma}$ is a threshold strictly above the BBP threshold,whereas for $\gamma &lt; 2$, it almost surely overestimates $k$. Although AIC(which corresponds to $\gamma = 2$) is not strongly consistent, we show thattaking $\gamma = 2 + \delta_N$, where $\delta_N \to 0$ and $\delta_N \ggN^{-2/3}$, results in a weakly consistent estimator of $k$. We further showthat a soft minimiser of AIC, where one chooses the least complex model whoseAIC score is close to the minimum AIC score, is strongly consistent. Based on aspiked (generalised) Wigner representation, we also develop similar modelselection criteria for consistently estimating the number of communities in abalanced stochastic block model under some sparsity restrictions.</description><author>Soumendu Sundar Mukherjee</author><pubDate>Fri, 07 Feb 2025 16:43:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.12982v2</guid></item><item><title>Beautiful Images, Toxic Words: Understanding and Addressing Offensive Text in Generated Images</title><link>http://arxiv.org/abs/2502.05066v1</link><description>State-of-the-art visual generation models, such as Diffusion Models (DMs) andVision Auto-Regressive Models (VARs), produce highly realistic images. Whileprior work has successfully mitigated Not Safe For Work (NSFW) content in thevisual domain, we identify a novel threat: the generation of NSFW text embeddedwithin images. This includes offensive language, such as insults, racial slurs,and sexually explicit terms, posing significant risks to users. We show thatall state-of-the-art DMs (e.g., SD3, Flux, DeepFloyd IF) and VARs (e.g.,Infinity) are vulnerable to this issue. Through extensive experiments, wedemonstrate that existing mitigation techniques, effective for visual content,fail to prevent harmful text generation while substantially degrading benigntext generation. As an initial step toward addressing this threat, we exploresafety fine-tuning of the text encoder underlying major DM architectures usinga customized dataset. Thereby, we suppress NSFW generation while preservingoverall image and text generation quality. Finally, to advance research in thisarea, we introduce ToxicBench, an open-source benchmark for evaluating NSFWtext generation in images. ToxicBench provides a curated dataset of harmfulprompts, new metrics, and an evaluation pipeline assessing both NSFW-ness andgeneration quality. Our benchmark aims to guide future efforts in mitigatingNSFW text generation in text-to-image models and is available athttps://github.com/sprintml/ToxicBench</description><author>Aditya Kumar, Tom Blanchard, Adam Dziedzic, Franziska Boenisch</author><pubDate>Fri, 07 Feb 2025 16:39:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05066v1</guid></item><item><title>Computing and Learning on Combinatorial Data</title><link>http://arxiv.org/abs/2502.05063v1</link><description>The twenty-first century is a data-driven era where human activities andbehavior, physical phenomena, scientific discoveries, technology advancements,and almost everything that happens in the world resulting in massivegeneration, collection, and utilization of data. Connectivity in data is a crucial property. A straightforward example is theWorld Wide Web, where every webpage is connected to other web pages throughhyperlinks, providing a form of directed connectivity. Combinatorial datarefers to combinations of data items based on certain connectivity rules. Otherforms of combinatorial data include social networks, meshes, communityclusters, set systems, and molecules. This Ph.D. dissertation focuses on learning and computing with combinatorialdata. We study and examine topological and connectivity features within andacross connected data to improve the performance of learning and achieve highalgorithmic efficiency.</description><author>Simon Zhang</author><pubDate>Fri, 07 Feb 2025 16:35:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05063v1</guid></item><item><title>Preference-aware compensation policies for crowdsourced on-demand services</title><link>http://arxiv.org/abs/2502.05060v1</link><description>Crowdsourced on-demand services offer benefits such as reduced costs, fasterservice fulfillment times, greater adaptability, and contributions tosustainable urban transportation in on-demand delivery contexts. However, thesuccess of an on-demand platform that utilizes crowdsourcing relies on findinga compensation policy that strikes a balance between creating attractive offersfor gig workers and ensuring profitability. In this work, we examine a dynamicpricing problem for an on-demand platform that sets request-specificcompensation of gig workers in a discrete-time framework, where requests andworkers arrive stochastically. The operator's goal is to determine acompensation policy that maximizes the total expected reward over the timehorizon. Our approach introduces compensation strategies that explicitlyaccount for gig worker request preferences. To achieve this, we employ theMultinomial Logit model to represent the acceptance probabilities of gigworkers, and, as a result, derive an analytical solution that utilizespost-decision states. Subsequently, we integrate this solution into anapproximate dynamic programming algorithm. We compare our algorithm againstbenchmark algorithms, including formula-based policies and an upper boundprovided by the full information linear programming solution. Our algorithmdemonstrates consistent performance across diverse settings, achievingimprovements of at least 2.5-7.5% in homogeneous gig worker populations and 9%in heterogeneous populations over benchmarks, based on fully synthetic data.For real-world data, it surpasses benchmarks by 8% in weak and 20% in stronglocation preference scenarios.</description><author>Georgina Nouli, Axel Parmentier, Maximilian Schiffer</author><pubDate>Fri, 07 Feb 2025 16:33:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05060v1</guid></item><item><title>Do Unlearning Methods Remove Information from Language Model Weights?</title><link>http://arxiv.org/abs/2410.08827v3</link><description>Large Language Models' knowledge of how to perform cyber-security attacks,create bioweapons, and manipulate humans poses risks of misuse. Previous workhas proposed methods to unlearn this knowledge. Historically, it has beenunclear whether unlearning techniques are removing information from the modelweights or just making it harder to access. To disentangle these twoobjectives, we propose an adversarial evaluation method to test for the removalof information from model weights: we give an attacker access to some factsthat were supposed to be removed, and using those, the attacker tries torecover other facts from the same distribution that cannot be guessed from theaccessible facts. We show that using fine-tuning on the accessible facts canrecover 88% of the pre-unlearning accuracy when applied to current unlearningmethods for information learned during pretraining, revealing the limitationsof these methods in removing information from the model weights. Our resultsalso suggest that unlearning evaluations that measure unlearning robustness oninformation learned during an additional fine-tuning phase may overestimaterobustness compared to evaluations that attempt to unlearn information learnedduring pretraining.</description><author>Aghyad Deeb, Fabien Roger</author><pubDate>Fri, 07 Feb 2025 16:27:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.08827v3</guid></item><item><title>Differentiable Mobile Display Photometric Stereo</title><link>http://arxiv.org/abs/2502.05055v1</link><description>Display photometric stereo uses a display as a programmable light source toilluminate a scene with diverse illumination conditions. Recently,differentiable display photometric stereo (DDPS) demonstrated improved normalreconstruction accuracy by using learned display patterns. However, DDPS facedlimitations in practicality, requiring a fixed desktop imaging setup using apolarization camera and a desktop-scale monitor. In this paper, we propose amore practical physics-based photometric stereo, differentiable mobile displayphotometric stereo (DMDPS), that leverages a mobile phone consisting of adisplay and a camera. We overcome the limitations of using a mobile device bydeveloping a mobile app and method that simultaneously displays patterns andcaptures high-quality HDR images. Using this technique, we capture real-world3D-printed objects and learn display patterns via a differentiable learningprocess. We demonstrate the effectiveness of DMDPS on both a 3D printed datasetand a first dataset of fallen leaves. The leaf dataset contains reconstructedsurface normals and albedos of fallen leaves that may enable future researchbeyond computer graphics and vision. We believe that DMDPS takes a step forwardfor practical physics-based photometric stereo.</description><author>Gawoon Ban, Hyeongjun Kim, Seokjun Choi, Seungwoo Yoon, Seung-Hwan Baek</author><pubDate>Fri, 07 Feb 2025 16:24:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05055v1</guid></item><item><title>GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs</title><link>http://arxiv.org/abs/2411.13757v2</link><description>Large Language Models (LLMs) have revolutionized natural language processing(NLP), excelling in tasks like text generation and summarization. However,their increasing adoption in mission-critical applications raises concernsabout hardware-based threats, particularly bit-flip attacks (BFAs). BFAs,enabled by fault injection methods such as Rowhammer, target model parametersin memory, compromising both integrity and performance. Identifying criticalparameters for BFAs in the vast parameter space of LLMs poses significantchallenges. While prior research suggests transformer-based architectures areinherently more robust to BFAs compared to traditional deep neural networks, wechallenge this assumption. For the first time, we demonstrate that as few asthree bit-flips can cause catastrophic performance degradation in an LLM withbillions of parameters. Current BFA techniques are inadequate for exploitingthis vulnerability due to the difficulty of efficiently identifying criticalparameters within the immense parameter space. To address this, we proposeAttentionBreaker, a novel framework tailored for LLMs that enables efficienttraversal of the parameter space to identify critical parameters. Additionally,we introduce GenBFA, an evolutionary optimization strategy designed to refinethe search further, isolating the most critical bits for an efficient andeffective attack. Empirical results reveal the profound vulnerability of LLMsto AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% oftotal parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model resultin a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findingsunderscore the effectiveness of AttentionBreaker in uncovering and exploitingcritical vulnerabilities within LLM architectures.</description><author>Sanjay Das, Swastik Bhattacharya, Souvik Kundu, Shamik Kundu, Anand Menon, Arnab Raha, Kanad Basu</author><pubDate>Fri, 07 Feb 2025 16:24:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2411.13757v2</guid></item><item><title>SACNet: A Spatially Adaptive Convolution Network for 2D Multi-organ Medical Segmentation</title><link>http://arxiv.org/abs/2407.10157v2</link><description>Multi-organ segmentation in medical image analysis is crucial for diagnosisand treatment planning. However, many factors complicate the task, includingvariability in different target categories and interference from complexbackgrounds. In this paper, we utilize the knowledge of Deformable ConvolutionV3 (DCNv3) and multi-object segmentation to optimize our Spatially AdaptiveConvolution Network (SACNet) in three aspects: feature extraction, modelarchitecture, and loss constraint, simultaneously enhancing the perception ofdifferent segmentation targets. Firstly, we propose the Adaptive ReceptiveField Module (ARFM), which combines DCNv3 with a series of customizedblock-level and architecture-level designs similar to transformers. This modulecan capture the unique features of different organs by adaptively adjusting thereceptive field according to various targets. Secondly, we utilize ARFM asbuilding blocks to construct the encoder-decoder of SACNet and partially shareparameters between the encoder and decoder, making the network wider ratherthan deeper. This design achieves a shared lightweight decoder and a moreparameter-efficient and effective framework. Lastly, we propose a novelcontinuity dynamic adjustment loss function, based on t-vMF dice loss andcross-entropy loss, to better balance easy and complex classes in segmentation.Experiments on 3D slice datasets from ACDC and Synapse demonstrate that SACNetdelivers superior segmentation performance in multi-organ segmentation taskscompared to several existing methods.</description><author>Lin Zhang, Wenbo Gao, Jie Yi, Yunyun Yang</author><pubDate>Fri, 07 Feb 2025 16:20:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10157v2</guid></item><item><title>Kronecker Mask and Interpretive Prompts are Language-Action Video Learners</title><link>http://arxiv.org/abs/2502.03549v2</link><description>Contrastive language-image pretraining (CLIP) has significantly advancedimage-based vision learning. A pressing topic subsequently arises: how can weeffectively adapt CLIP to the video domain? Recent studies have focused onadjusting either the textual or visual branch of CLIP for action recognition.However, we argue that adaptations of both branches are crucial. In this paper,we propose \textbf{CLAVER}: a \textbf{C}ontrastive\textbf{L}anguage-\textbf{A}ction \textbf{V}ideo Learn\textbf{er}, designed toshift CLIP's focus from the alignment of static visual objects and concretenouns to the alignment of dynamic action behaviors and abstract verbs.Specifically, we introduce a novel Kronecker mask attention for temporalmodeling. Our tailored Kronecker mask offers three benefits 1) it expands thetemporal receptive field for each token, 2) it serves as an effectivespatiotemporal heterogeneity inductive bias, mitigating the issue ofspatiotemporal homogenization, and 3) it can be seamlessly plugged intotransformer-based models. Regarding the textual branch, we leverage largelanguage models to generate diverse, sentence-level and semantically richinterpretive prompts of actions, which shift the model's focus towards the verbcomprehension. Extensive experiments on various benchmarks and learningscenarios demonstrate the superiority and generality of our approach. The codewill be available soon.</description><author>Jingyi Yang, Zitong Yu, Xiuming Ni, Jia He, Hui Li</author><pubDate>Fri, 07 Feb 2025 16:19:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.03549v2</guid></item><item><title>Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems</title><link>http://arxiv.org/abs/2501.11613v4</link><description>This study introduces Conversation Routines (CR), a structured promptengineering framework for developing task-oriented dialog systems using LargeLanguage Models (LLMs). While LLMs demonstrate remarkable natural languageunderstanding capabilities, engineering them to reliably execute complexbusiness workflows remains challenging. The proposed CR framework enables thedevelopment of Conversation Agentic Systems (CAS) through natural languagespecifications, embedding task-oriented logic within LLM prompts. This approachprovides a systematic methodology for designing and implementing complexconversational workflows while maintaining behavioral consistency. Wedemonstrate the framework's effectiveness through two proof-of-conceptimplementations: a Train Ticket Booking System and an InteractiveTroubleshooting Copilot. These case studies validate CR's capability to encodesophisticated behavioral patterns and decision logic while preserving naturalconversational flexibility. Results show that CR enables domain experts todesign conversational workflows in natural language while leveraging customfunctions (tools) developed by software engineers, creating an efficientdivision of responsibilities where developers focus on core API implementationand domain experts handle conversation design. While the framework showspromise in accessibility and adaptability, we identify key challenges includingcomputational overhead, non-deterministic behavior, and domain-specific logicoptimization. Future research directions include CR evaluation methods based onprompt engineering frameworks driven by goal-oriented grading criteria,improving scalability for complex multi-agent interactions, and enhancingsystem robustness to address the identified limitations across diverse businessapplications.</description><author>Giorgio Robino</author><pubDate>Fri, 07 Feb 2025 16:18:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.11613v4</guid></item><item><title>Drag Your Gaussian: Effective Drag-Based Editing with Score Distillation for 3D Gaussian Splatting</title><link>http://arxiv.org/abs/2501.18672v2</link><description>Recent advancements in 3D scene editing have been propelled by the rapiddevelopment of generative models. Existing methods typically utilize generativemodels to perform text-guided editing on 3D representations, such as 3DGaussian Splatting (3DGS). However, these methods are often limited to texturemodifications and fail when addressing geometric changes, such as editing acharacter's head to turn around. Moreover, such methods lack accurate controlover the spatial position of editing results, as language struggles toprecisely describe the extent of edits. To overcome these limitations, weintroduce DYG, an effective 3D drag-based editing method for 3D GaussianSplatting. It enables users to conveniently specify the desired editing regionand the desired dragging direction through the input of 3D masks and pairs ofcontrol points, thereby enabling precise control over the extent of editing.DYG integrates the strengths of the implicit triplane representation toestablish the geometric scaffold of the editing results, effectively overcomingsuboptimal editing outcomes caused by the sparsity of 3DGS in the desiredediting regions. Additionally, we incorporate a drag-based Latent DiffusionModel into our method through the proposed Drag-SDS loss function, enablingflexible, multi-view consistent, and fine-grained editing. Extensiveexperiments demonstrate that DYG conducts effective drag-based editing guidedby control point prompts, surpassing other baselines in terms of editing effectand quality, both qualitatively and quantitatively. Visit our project page athttps://quyans.github.io/Drag-Your-Gaussian.</description><author>Yansong Qu, Dian Chen, Xinyang Li, Xiaofan Li, Shengchuan Zhang, Liujuan Cao, Rongrong Ji</author><pubDate>Fri, 07 Feb 2025 16:15:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.18672v2</guid></item><item><title>Hybrid machine learning based scale bridging framework for permeability prediction of fibrous structures</title><link>http://arxiv.org/abs/2502.05044v1</link><description>This study introduces a hybrid machine learning-based scale-bridgingframework for predicting the permeability of fibrous textile structures. Byaddressing the computational challenges inherent to multiscale modeling, theproposed approach evaluates the efficiency and accuracy of differentscale-bridging methodologies combining traditional surrogate models and evenintegrating physics-informed neural networks (PINNs) with numerical solvers,enabling accurate permeability predictions across micro- and mesoscales. Fourmethodologies were evaluated: Single Scale Method (SSM), Simple UpscalingMethod (SUM), Scale-Bridging Method (SBM), and Fully Resolved Model (FRM). SSM,the simplest method, neglects microscale permeability and exhibitedpermeability values deviating by up to 150\% of the FRM model, which was takenas ground truth at an equivalent lower fiber volume content. SUM improvedpredictions by considering uniform microscale permeability, yielding closervalues under similar conditions, but still lacked structural variability. TheSBM method, incorporating segment-based microscale permeability assignments,showed significant enhancements, achieving almost equivalent values whilemaintaining computational efficiency and modeling runtimes of ~45 minutes persimulation. In contrast, FRM, which provides the highest fidelity by fullyresolving microscale and mesoscale geometries, required up to 270 times morecomputational time than SSM, with model files exceeding 300 GB. Additionally, ahybrid dual-scale solver incorporating PINNs has been developed and shows thepotential to overcome generalization errors and the problem of data scarcity ofthe data-driven surrogate approaches. The hybrid framework advancespermeability modelling by balancing computational cost and predictionreliability, laying the foundation for further applications in fibrouscomposite manufacturing.</description><author>Denis Korolev, Tim Schmidt, Dinesh K. Natarajan, Stefano Cassola, David May, Miro Duhovic, Michael Hintermüller</author><pubDate>Fri, 07 Feb 2025 16:09:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05044v1</guid></item><item><title>Federated Learning for Anomaly Detection in Energy Consumption Data: Assessing the Vulnerability to Adversarial Attacks</title><link>http://arxiv.org/abs/2502.05041v1</link><description>Anomaly detection is crucial in the energy sector to identify irregularpatterns indicating equipment failures, energy theft, or other issues. Machinelearning techniques for anomaly detection have achieved great success, but aretypically centralized, involving sharing local data with a central server whichraises privacy and security concerns. Federated Learning (FL) has been gainingpopularity as it enables distributed learning without sharing local data.However, FL depends on neural networks, which are vulnerable to adversarialattacks that manipulate data, leading models to make erroneous predictions.While adversarial attacks have been explored in the image domain, they remainlargely unexplored in time series problems, especially in the energy domain.Moreover, the effect of adversarial attacks in the FL setting is also mostlyunknown. This paper assesses the vulnerability of FL-based anomaly detection inenergy data to adversarial attacks. Specifically, two state-of-the-art models,Long Short Term Memory (LSTM) and Transformers, are used to detect anomalies inan FL setting, and two white-box attack methods, Fast Gradient Sign Method(FGSM) and Projected Gradient Descent (PGD), are employed to perturb the data.The results show that FL is more sensitive to PGD attacks than to FGSM attacks,attributed to PGD's iterative nature, resulting in an accuracy drop of over 10%even with naive, weaker attacks. Moreover, FL is more affected by these attacksthan centralized learning, highlighting the need for defense mechanisms in FL.</description><author>Yohannis Kifle Telila, Damitha Senevirathne, Dumindu Tissera, Apurva Narayan, Miriam A. M. Capretz, Katarina Grolinger</author><pubDate>Fri, 07 Feb 2025 16:08:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05041v1</guid></item><item><title>GaussRender: Learning 3D Occupancy with Gaussian Rendering</title><link>http://arxiv.org/abs/2502.05040v1</link><description>Understanding the 3D geometry and semantics of driving scenes is critical fordeveloping of safe autonomous vehicles. While 3D occupancy models are typicallytrained using voxel-based supervision with standard losses (e.g.,cross-entropy, Lovasz, dice), these approaches treat voxel predictionsindependently, neglecting their spatial relationships. In this paper, wepropose GaussRender, a plug-and-play 3D-to-2D reprojection loss that enhancesvoxel-based supervision. Our method projects 3D voxel representations intoarbitrary 2D perspectives and leverages Gaussian splatting as an efficient,differentiable rendering proxy of voxels, introducing spatial dependenciesacross projected elements. This approach improves semantic and geometricconsistency, handles occlusions more efficiently, and requires no architecturalmodifications. Extensive experiments on multiple benchmarks(SurroundOcc-nuScenes, Occ3D-nuScenes, SSCBench-KITTI360) demonstrateconsistent performance gains across various 3D occupancy models (TPVFormer,SurroundOcc, Symphonies), highlighting the robustness and versatility of ourframework. The code is available at https://github.com/valeoai/GaussRender.</description><author>Loick Chambon, Eloi Zablocki, Alexandre Boulch, Mickael Chen, Matthieu Cord</author><pubDate>Fri, 07 Feb 2025 16:07:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05040v1</guid></item><item><title>FlightForge: Advancing UAV Research with Procedural Generation of High-Fidelity Simulation and Integrated Autonomy</title><link>http://arxiv.org/abs/2502.05038v1</link><description>Robotic simulators play a crucial role in the development and testing ofautonomous systems, particularly in the realm of Uncrewed Aerial Vehicles(UAV). However, existing simulators often lack high-level autonomy, hinderingtheir immediate applicability to complex tasks such as autonomous navigation inunknown environments. This limitation stems from the challenge of integratingrealistic physics, photorealistic rendering, and diverse sensor modalities intoa single simulation environment. At the same time, the existing photorealisticUAV simulators use mostly hand-crafted environments with limited environmentsizes, which prevents the testing of long-range missions. This restricts theusage of existing simulators to only low-level tasks such as control andcollision avoidance. To this end, we propose the novel FlightForge UAVopen-source simulator. FlightForge offers advanced rendering capabilities,diverse control modalities, and, foremost, procedural generation ofenvironments. Moreover, the simulator is already integrated with a fullyautonomous UAV system capable of long-range flights in cluttered unknownenvironments. The key innovation lies in novel procedural environmentgeneration and seamless integration of high-level autonomy into the simulationenvironment. Experimental results demonstrate superior sensor renderingcapability compared to existing simulators, and also the ability of autonomousnavigation in almost infinite environments.</description><author>David Čapek, Jan Hrnčíř, Tomáš Báča, Jakub Jirkal, Vojtěch Vonásek, Robert Pěnička, Martin Saska</author><pubDate>Fri, 07 Feb 2025 16:05:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05038v1</guid></item><item><title>Adversarial Training Can Provably Improve Robustness: Theoretical Analysis of Feature Learning Process Under Structured Data</title><link>http://arxiv.org/abs/2410.08503v2</link><description>Adversarial training is a widely-applied approach to training deep neuralnetworks to be robust against adversarial perturbation. However, althoughadversarial training has achieved empirical success in practice, it stillremains unclear why adversarial examples exist and how adversarial trainingmethods improve model robustness. In this paper, we provide a theoreticalunderstanding of adversarial examples and adversarial training algorithms fromthe perspective of feature learning theory. Specifically, we focus on amultiple classification setting, where the structured data can be composed oftwo types of features: the robust features, which are resistant to perturbationbut sparse, and the non-robust features, which are susceptible to perturbationbut dense. We train a two-layer smoothed ReLU convolutional neural network tolearn our structured data. First, we prove that by using standard training(gradient descent over the empirical risk), the network learner primarilylearns the non-robust feature rather than the robust feature, which therebyleads to the adversarial examples that are generated by perturbations alignedwith negative non-robust feature directions. Then, we consider thegradient-based adversarial training algorithm, which runs gradient ascent tofind adversarial examples and runs gradient descent over the empirical risk atadversarial examples to update models. We show that the adversarial trainingmethod can provably strengthen the robust feature learning and suppress thenon-robust feature learning to improve the network robustness. Finally, we alsoempirically validate our theoretical findings with experiments on real-imagedatasets, including MNIST, CIFAR10 and SVHN.</description><author>Binghui Li, Yuanzhi Li</author><pubDate>Fri, 07 Feb 2025 16:05:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.08503v2</guid></item><item><title>Leveraging a Simulator for Learning Causal Representations from Post-Treatment Covariates for CATE</title><link>http://arxiv.org/abs/2502.05037v1</link><description>Treatment effect estimation involves assessing the impact of differenttreatments on individual outcomes. Current methods estimate Conditional AverageTreatment Effect (CATE) using observational datasets where covariates arecollected before treatment assignment and outcomes are observed afterward,under assumptions like positivity and unconfoundedness. In this paper, weaddress a scenario where both covariates and outcomes are gathered aftertreatment. We show that post-treatment covariates render CATE unidentifiable,and recovering CATE requires learning treatment-independent causalrepresentations. Prior work shows that such representations can be learnedthrough contrastive learning if counterfactual supervision is available inobservational data. However, since counterfactuals are rare, other works haveexplored using simulators that offer synthetic counterfactual supervision. Ourgoal in this paper is to systematically analyze the role of simulators inestimating CATE. We analyze the CATE error of several baselines and highlighttheir limitations. We then establish a generalization bound that characterizesthe CATE error from jointly training on real and simulated distributions, as afunction of the real-simulator mismatch. Finally, we introduce SimPONet, anovel method whose loss function is inspired from our generalization bound. Wefurther show how SimPONet adjusts the simulator's influence on the learningobjective based on the simulator's relevance to the CATE task. We experimentwith various DGPs, by systematically varying the real-simulator distributiongap to evaluate SimPONet's efficacy against state-of-the-art CATE baselines.</description><author>Lokesh Nagalapatti, Pranava Singhal, Avishek Ghosh, Sunita Sarawagi</author><pubDate>Fri, 07 Feb 2025 16:04:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05037v1</guid></item><item><title>nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow</title><link>http://arxiv.org/abs/2502.05036v1</link><description>Natural Language to Visualization (NL2Vis) seeks to convert natural-languagedescriptions into visual representations of given tables, empowering users toderive insights from large-scale data. Recent advancements in Large LanguageModels (LLMs) show promise in automating code generation to transform tabulardata into accessible visualizations. However, they often struggle with complexqueries that require reasoning across multiple tables. To address thislimitation, we propose a collaborative agent workflow, termed nvAgent, forNL2Vis. Specifically, nvAgent comprises three agents: a processor agent fordatabase processing and context filtering, a composer agent for planningvisualization generation, and a validator agent for code translation and outputverification. Comprehensive evaluations on the new VisEval benchmarkdemonstrate that nvAgent consistently surpasses state-of-the-art baselines,achieving a 7.88% improvement in single-table and a 9.23% improvement inmulti-table scenarios. Qualitative analyses further highlight that nvAgentmaintains nearly a 20% performance margin over previous models, underscoringits capacity to produce high-quality visual representations from complex,heterogeneous data sources.</description><author>Geliang Ouyang, Jingyao Chen, Zhihe Nie, Yi Gui, Yao Wan, Hongyu Zhang, Dongping Chen</author><pubDate>Fri, 07 Feb 2025 16:03:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05036v1</guid></item><item><title>MindAligner: Explicit Brain Functional Alignment for Cross-Subject Visual Decoding from Limited fMRI Data</title><link>http://arxiv.org/abs/2502.05034v1</link><description>Brain decoding aims to reconstruct visual perception of human subject fromfMRI signals, which is crucial for understanding brain's perception mechanisms.Existing methods are confined to the single-subject paradigm due to substantialbrain variability, which leads to weak generalization across individuals andincurs high training costs, exacerbated by limited availability of fMRI data.To address these challenges, we propose MindAligner, an explicit functionalalignment framework for cross-subject brain decoding from limited fMRI data.The proposed MindAligner enjoys several merits. First, we learn a BrainTransfer Matrix (BTM) that projects the brain signals of an arbitrary newsubject to one of the known subjects, enabling seamless use of pre-traineddecoding models. Second, to facilitate reliable BTM learning, a BrainFunctional Alignment module is proposed to perform soft cross-subject brainalignment under different visual stimuli with a multi-level brain alignmentloss, uncovering fine-grained functional correspondences with highinterpretability. Experiments indicate that MindAligner not only outperformsexisting methods in visual decoding under data-limited conditions, but alsoprovides valuable neuroscience insights in cross-subject functional analysis.The code will be made publicly available.</description><author>Yuqin Dai, Zhouheng Yao, Chunfeng Song, Qihao Zheng, Weijian Mai, Kunyu Peng, Shuai Lu, Wanli Ouyang, Jian Yang, Jiamin Wu</author><pubDate>Fri, 07 Feb 2025 16:01:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05034v1</guid></item><item><title>News about Global North considered Truthful! The Geo-political Veracity Gradient in Global South News</title><link>http://arxiv.org/abs/2502.05032v1</link><description>While there has been much research into developing AI techniques for fakenews detection aided by various benchmark datasets, it has often been pointedout that fake news in different geo-political regions traces differentcontours. In this work we uncover, through analytical arguments and empiricalevidence, the existence of an important characteristic in news originating fromthe Global South viz., the geo-political veracity gradient. In particular, weshow that Global South news about topics from Global North -- such as news froman Indian news agency on US elections -- tend to be less likely to be fake.Observing through the prism of the political economy of fake news creation, weposit that this pattern could be due to the relative lack of monetarily alignedincentives in producing fake news about a different region than the regionalremit of the audience. We provide empirical evidence for this from benchmarkdatasets. We also empirically analyze the consequences of this effect inapplying AI-based fake news detection models for fake news AI trained on oneregion within another regional context. We locate our work within emergingcritical scholarship on geo-political biases within AI in general, particularlywith AI usage in fake news identification; we hope our insight into thegeo-political veracity gradient could help steer fake news AI scholarshiptowards positively impacting Global South societies.</description><author>Sujit Mandava, Deepak P, Sahely Bhadra</author><pubDate>Fri, 07 Feb 2025 15:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05032v1</guid></item><item><title>Near-Optimal Online Learning for Multi-Agent Submodular Coordination: Tight Approximation and Communication Efficiency</title><link>http://arxiv.org/abs/2502.05028v1</link><description>Coordinating multiple agents to collaboratively maximize submodular functionsin unpredictable environments is a critical task with numerous applications inmachine learning, robot planning and control. The existing approaches, such asthe OSG algorithm, are often hindered by their poor approximation guaranteesand the rigid requirement for a fully connected communication graph. To addressthese challenges, we firstly present a $\textbf{MA-OSMA}$ algorithm, whichemploys the multi-linear extension to transfer the discrete submodularmaximization problem into a continuous optimization, thereby allowing us toreduce the strict dependence on a complete graph through consensus techniques.Moreover, $\textbf{MA-OSMA}$ leverages a novel surrogate gradient to avoidsub-optimal stationary points. To eliminate the computationally intensiveprojection operations in $\textbf{MA-OSMA}$, we also introduce aprojection-free $\textbf{MA-OSEA}$ algorithm, which effectively utilizes the KLdivergence by mixing a uniform distribution. Theoretically, we confirm thatboth algorithms achieve a regret bound of$\widetilde{O}(\sqrt{\frac{C_{T}T}{1-\beta}})$ against a$(\frac{1-e^{-c}}{c})$-approximation to the best comparator in hindsight, where$C_{T}$ is the deviation of maximizer sequence, $\beta$ is the spectral gap ofthe network and $c$ is the joint curvature of submodular objectives. Thisresult significantly improves the $(\frac{1}{1+c})$-approximation provided bythe state-of-the-art OSG algorithm. Finally, we demonstrate the effectivenessof our proposed algorithms through simulation-based multi-target tracking.</description><author>Qixin Zhang, Zongqi Wan, Yu Yang, Li Shen, Dacheng Tao</author><pubDate>Fri, 07 Feb 2025 15:57:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05028v1</guid></item><item><title>IDPro: Flexible Interactive Video Object Segmentation by ID-queried Concurrent Propagation</title><link>http://arxiv.org/abs/2401.12480v3</link><description>Interactive Video Object Segmentation (iVOS) is a challenging task thatrequires real-time human-computer interaction. To improve the user experience,it is important to consider the user's input habits, segmentation quality,running time and memory consumption.However, existing methods compromise userexperience with single input mode and slow running speed. Specifically, thesemethods only allow the user to interact with one single frame, which limits theexpression of the user's intent.To overcome these limitations and better alignwith people's usage habits, we propose a framework that can accept multipleframes simultaneously and explore synergistic interaction across frames (SIAF).Concretely, we designed the Across-Frame Interaction Module that enables usersto annotate different objects freely on multiple frames. The AFI module willmigrate scribble information among multiple interactive frames and generatemulti-frame masks. Additionally, we employ the id-queried mechanism to processmultiple objects in batches. Furthermore, for a more efficient propagation andlightweight model, we design a truncated re-propagation strategy to replace theprevious multi-round fusion module, which employs an across-round memory thatstores important interaction information. Our SwinB-SIAF achieves newstate-of-the-art performance on DAVIS 2017 (89.6%, J&amp;F@60). Moreover, ourR50-SIAF is more than 3 faster than the state-of-the-art competitor underchallenging multi-object scenarios.</description><author>Kexin Li, Tao Jiang, Zongxin Yang, Yi Yang, Yueting Zhuang, Jun Xiao</author><pubDate>Fri, 07 Feb 2025 15:57:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12480v3</guid></item><item><title>Trust-Aware Diversion for Data-Effective Distillation</title><link>http://arxiv.org/abs/2502.05027v1</link><description>Dataset distillation compresses a large dataset into a small synthetic subsetthat retains essential information. Existing methods assume that all samplesare perfectly labeled, limiting their real-world applications where incorrectlabels are ubiquitous. These mislabeled samples introduce untrustworthyinformation into the dataset, which misleads model optimization in datasetdistillation. To tackle this issue, we propose a Trust-Aware Diversion (TAD)dataset distillation method. Our proposed TAD introduces an iterative dual-loopoptimization framework for data-effective distillation. Specifically, the outerloop divides data into trusted and untrusted spaces, redirecting distillationtoward trusted samples to guarantee trust in the distillation process. Thisstep minimizes the impact of mislabeled samples on dataset distillation. Theinner loop maximizes the distillation objective by recalibrating untrustedsamples, thus transforming them into valuable ones for distillation. Thisdual-loop iteratively refines and compensates for each other, graduallyexpanding the trusted space and shrinking the untrusted space. Experimentsdemonstrate that our method can significantly improve the performance ofexisting dataset distillation methods on three widely used benchmarks (CIFAR10,CIFAR100, and Tiny ImageNet) in three challenging mislabeled settings(symmetric, asymmetric, and real-world).</description><author>Zhuojie Wu, Yanbin Liu, Xin Shen, Xiaofeng Cao, Xin Yu</author><pubDate>Fri, 07 Feb 2025 15:57:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05027v1</guid></item><item><title>CollabEdit: Towards Non-destructive Collaborative Knowledge Editing</title><link>http://arxiv.org/abs/2410.09508v3</link><description>Collaborative learning of large language models (LLMs) has emerged as a newparadigm for utilizing private data from different parties to guaranteeefficiency and privacy. Meanwhile, Knowledge Editing (KE) for LLMs has alsogarnered increased attention due to its ability to manipulate the behaviors ofLLMs explicitly, yet leaves the collaborative KE case (in which knowledge editsof multiple parties are aggregated in a privacy-preserving and continualmanner) unexamined. To this end, this manuscript dives into the firstinvestigation of collaborative KE, in which we start by carefully identifyingthe unique three challenges therein, including knowledge overlap, knowledgeconflict, and knowledge forgetting. We then propose a non-destructivecollaborative KE framework, COLLABEDIT, which employs a novel model mergingmechanism to mimic the global KE behavior while preventing the severeperformance drop. Extensive experiments on two canonical datasets demonstratethe superiority of COLLABEDIT compared to other destructive baselines, andresults shed light on addressing three collaborative KE challenges and futureapplications. Our code is available at https://github.com/LINs-lab/CollabEdit.</description><author>Jiamu Zheng, Jinghuai Zhang, Tianyu Du, Xuhong Zhang, Jianwei Yin, Tao Lin</author><pubDate>Fri, 07 Feb 2025 15:49:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.09508v3</guid></item><item><title>Stability and performance guarantees for misspecified multivariate score-driven filters</title><link>http://arxiv.org/abs/2502.05021v1</link><description>We consider the problem of tracking latent time-varying parameter vectorsunder model misspecification. We analyze implicit and explicit score-driven(ISD and ESD) filters, which update a prediction of the parameters using thegradient of the logarithmic observation density (i.e., the score). In the ESDfilter, the score is computed using the predicted parameter values, whereas inthe ISD filter, the score is evaluated using the new, updated parameter values.For both filter types, we derive novel sufficient conditions for theexponential stability (i.e., invertibility) of the filtered parameter path andexistence of a finite mean squared error (MSE) bound with respect to thepseudo-true parameter path. In addition, we present expressions forfinite-sample and asymptotic MSE bounds. Our performance guarantees rely onmild moment conditions on the data-generating process, while our stabilityresult is entirely agnostic about the true process. As a result, our primaryconditions depend only on the characteristics of the filter; hence, they areverifiable in practice. Concavity of the postulated log density combined withsimple parameter restrictions is sufficient (but not necessary) for ISD-filterstability, whereas ESD-filter stability additionally requires the score to beLipschitz continuous. Extensive simulation studies validate our theoreticalfindings and demonstrate the enhanced stability and improved performance of ISDover ESD filters. An empirical application to U.S. Treasury-bill rates confirmsthe practical relevance of our contribution.</description><author>Simon Donker van Heel, Rutger-Jan Lange, Dick van Dijk, Bram van Os</author><pubDate>Fri, 07 Feb 2025 15:48:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2502.05021v1</guid></item></channel></rss>