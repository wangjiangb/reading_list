<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 18 May 2023 06:00:45 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention</title><link>http://arxiv.org/abs/2305.10431v1</link><description>Diffusion models excel at text-to-image generation, especially insubject-driven generation for personalized images. However, existing methodsare inefficient due to the subject-specific fine-tuning, which iscomputationally intensive and hampers efficient deployment. Moreover, existingmethods struggle with multi-subject generation as they often blend featuresamong subjects. We present FastComposer which enables efficient, personalized,multi-subject text-to-image generation without fine-tuning. FastComposer usessubject embeddings extracted by an image encoder to augment the generic textconditioning in diffusion models, enabling personalized image generation basedon subject images and textual instructions with only forward passes. To addressthe identity blending problem in the multi-subject generation, FastComposerproposes cross-attention localization supervision during training, enforcingthe attention of reference subjects localized to the correct regions in thetarget images. Naively conditioning on subject embeddings results in subjectoverfitting. FastComposer proposes delayed subject conditioning in thedenoising step to maintain both identity and editability in subject-drivenimage generation. FastComposer generates images of multiple unseen individualswith different styles, actions, and contexts. It achieves300$\times$-2500$\times$ speedup compared to fine-tuning-based methods andrequires zero extra storage for new subjects. FastComposer paves the way forefficient, personalized, and high-quality multi-subject image creation. Code,model, and dataset are available athttps://github.com/mit-han-lab/fastcomposer.</description><author>Guangxuan Xiao, Tianwei Yin, William T. Freeman, Frédo Durand, Song Han</author><pubDate>Wed, 17 May 2023 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10431v1</guid></item><item><title>Rethinking the Open-Loop Evaluation of End-to-End Autonomous Driving in nuScenes</title><link>http://arxiv.org/abs/2305.10430v1</link><description>Modern autonomous driving systems are typically divided into three maintasks: perception, prediction, and planning. The planning task involvespredicting the trajectory of the ego vehicle based on inputs from both internalintention and the external environment, and manipulating the vehicleaccordingly. Most existing works evaluate their performance on the nuScenesdataset using the L2 error and collision rate between the predictedtrajectories and the ground truth. In this paper, we reevaluate these existingevaluation metrics and explore whether they accurately measure the superiorityof different methods. Specifically, we design an MLP-based method that takesraw sensor data (e.g., past trajectory, velocity, etc.) as input and directlyoutputs the future trajectory of the ego vehicle, without using any perceptionor prediction information such as camera images or LiDAR. Surprisingly, such asimple method achieves state-of-the-art end-to-end planning performance on thenuScenes dataset, reducing the average L2 error by about 30%. We furtherconduct in-depth analysis and provide new insights into the factors that arecritical for the success of the planning task on nuScenes dataset. Ourobservation also indicates that we need to rethink the current open-loopevaluation scheme of end-to-end autonomous driving in nuScenes. Codes areavailable at https://github.com/E2E-AD/AD-MLP.</description><author>Jiang-Tian Zhai, Ze Feng, Jinhao Du, Yongqiang Mao, Jiang-Jiang Liu, Zichang Tan, Yifu Zhang, Xiaoqing Ye, Jingdong Wang</author><pubDate>Wed, 17 May 2023 18:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10430v1</guid></item><item><title>DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining</title><link>http://arxiv.org/abs/2305.10429v1</link><description>The mixture proportions of pretraining data domains (e.g., Wikipedia, books,web text) greatly affect language model (LM) performance. In this paper, wepropose Domain Reweighting with Minimax Optimization (DoReMi), which firsttrains a small proxy model using group distributionally robust optimization(Group DRO) over domains to produce domain weights (mixture proportions)without knowledge of downstream tasks. We then resample a dataset with thesedomain weights and train a larger, full-sized model. In our experiments, we useDoReMi on a 280M-parameter proxy model to find domain weights for training an8B-parameter model (30x larger) more efficiently. On The Pile, DoReMi improvesperplexity across all domains, even when it downweights a domain. DoReMiimproves average few-shot downstream accuracy by 6.5% over a baseline modeltrained using The Pile's default domain weights and reaches the baselineaccuracy with 2.6x fewer training steps. On the GLaM dataset, DoReMi, which hasno knowledge of downstream tasks, even matches the performance of using domainweights tuned on downstream tasks.</description><author>Sang Michael Xie, Hieu Pham, Xuanyi Dong, Nan Du, Hanxiao Liu, Yifeng Lu, Percy Liang, Quoc V. Le, Tengyu Ma, Adams Wei Yu</author><pubDate>Wed, 17 May 2023 18:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10429v1</guid></item><item><title>Accelerating Transformer Inference for Translation via Parallel Decoding</title><link>http://arxiv.org/abs/2305.10427v1</link><description>Autoregressive decoding limits the efficiency of transformers for MachineTranslation (MT). The community proposed specific network architectures andlearning-based methods to solve this issue, which are expensive and requirechanges to the MT model, trading inference speed at the cost of the translationquality. In this paper, we propose to address the problem from the point ofview of decoding algorithms, as a less explored but rather compellingdirection. We propose to reframe the standard greedy autoregressive decoding ofMT with a parallel formulation leveraging Jacobi and Gauss-Seidel fixed-pointiteration methods for fast inference. This formulation allows to speed upexisting models without training or modifications while retaining translationquality. We present three parallel decoding algorithms and test them ondifferent languages and models showing how the parallelization introduces aspeedup up to 38% w.r.t. the standard autoregressive decoding and nearly 2xwhen scaling the method on parallel resources. Finally, we introduce a decodingdependency graph visualizer (DDGviz) that let us see how the model has learnedthe conditional dependence between tokens and inspect the decoding procedure.</description><author>Andrea Santilli, Silvio Severino, Emilian Postolache, Valentino Maiorca, Michele Mancusi, Riccardo Marin, Emanuele Rodolà</author><pubDate>Wed, 17 May 2023 18:57:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10427v1</guid></item><item><title>SLiC-HF: Sequence Likelihood Calibration with Human Feedback</title><link>http://arxiv.org/abs/2305.10425v1</link><description>Learning from human feedback has been shown to be effective at aligninglanguage models with human preferences. Past work has often relied onReinforcement Learning from Human Feedback (RLHF), which optimizes the languagemodel using reward scores assigned from a reward model trained on humanpreference data. In this work we show how the recently introduced SequenceLikelihood Calibration (SLiC), can also be used to effectively learn from humanpreferences (SLiC-HF). Furthermore, we demonstrate this can be done with humanfeedback data collected for a different model, similar to off-policy, offlineRL data. Automatic and human evaluation experiments on the TL;DR summarizationtask show that SLiC-HF significantly improves supervised fine-tuning baselines.Furthermore, SLiC-HF presents a competitive alternative to the PPO RLHFimplementation used in past work while being much simpler to implement, easierto tune and more computationally efficient in practice.</description><author>Yao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, Peter J. Liu</author><pubDate>Wed, 17 May 2023 18:57:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10425v1</guid></item><item><title>ZeroFlow: Fast Zero Label Scene Flow via Distillation</title><link>http://arxiv.org/abs/2305.10424v1</link><description>Scene flow estimation is the task of describing the 3D motion field betweentemporally successive point clouds. State-of-the-art methods use strong priorsand test-time optimization techniques, but require on the order of tens ofseconds for large-scale point clouds, making them unusable as computer visionprimitives for real-time applications such as open world object detection. Feedforward methods are considerably faster, running on the order of tens tohundreds of milliseconds for large-scale point clouds, but require expensivehuman supervision. To address both limitations, we propose Scene Flow viaDistillation, a simple distillation framework that uses a label-freeoptimization method to produce pseudo-labels to supervise a feed forward model.Our instantiation of this framework, ZeroFlow, produces scene flow estimates inreal-time on large-scale point clouds at quality competitive withstate-of-the-art methods while using zero human labels. Notably, at test-timeZeroFlow is over 1000$\times$ faster than label-free state-of-the-artoptimization-based methods on large-scale point clouds and over 1000$\times$cheaper to train on unlabeled data compared to the cost of human annotation ofthat data. To facilitate research reuse, we release our code, trained modelweights, and high quality pseudo-labels for the Argoverse 2 and Waymo Opendatasets.</description><author>Kyle Vedder, Neehar Peri, Nathaniel Chodosh, Ishan Khatri, Eric Eaton, Dinesh Jayaraman, Yang Liu, Deva Ramanan, James Hays</author><pubDate>Wed, 17 May 2023 18:56:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10424v1</guid></item><item><title>Evolving Tsukamoto Neuro Fuzzy Model for Multiclass Covid 19 Classification with Chest X Ray Images</title><link>http://arxiv.org/abs/2305.10421v1</link><description>Du e to rapid population growth and the need to use artificial intelligenceto make quick decisions, developing a machine learning-based disease detectionmodel and abnormality identification system has greatly improved the level ofmedical diagnosis Since COVID-19 has become one of the most severe diseases inthe world, developing an automatic COVID-19 detection framework helps medicaldoctors in the diagnostic process of disease and provides correct and fastresults. In this paper, we propose a machine lear ning based framework for thedetection of Covid 19. The proposed model employs a Tsukamoto Neuro FuzzyInference network to identify and distinguish Covid 19 disease from normal andpneumonia cases. While the traditional training methods tune the parameters ofthe neuro-fuzzy model by gradient-based algorithms and recursive least squaremethod, we use an evolutionary-based optimization, the Cat swarm algorithm toupdate the parameters. In addition, six texture features extracted from chestX-ray images are give n as input to the model. Finally, the proposed model isconducted on the chest X-ray dataset to detect Covid 19. The simulation resultsindicate that the proposed model achieves an accuracy of 98.51%, sensitivity of98.35%, specificity of 98.08%, and F1 score of 98.17%.</description><author>Marziyeh Rezaei, Sevda Molani, Negar Firoozeh, Hossein Abbasi, Farzan Vahedifard, Maysam Orouskhani</author><pubDate>Wed, 17 May 2023 18:55:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10421v1</guid></item><item><title>CLIP-GCD: Simple Language Guided Generalized Category Discovery</title><link>http://arxiv.org/abs/2305.10420v1</link><description>Generalized Category Discovery (GCD) requires a model to both classify knowncategories and cluster unknown categories in unlabeled data. Prior methodsleveraged self-supervised pre-training combined with supervised fine-tuning onthe labeled data, followed by simple clustering methods. In this paper, weposit that such methods are still prone to poor performance onout-of-distribution categories, and do not leverage a key ingredient: Semanticrelationships between object categories. We therefore propose to leveragemulti-modal (vision and language) models, in two complementary ways. First, weestablish a strong baseline by replacing uni-modal features with CLIP, inspiredby its zero-shot performance. Second, we propose a novel retrieval-basedmechanism that leverages CLIP's aligned vision-language representations bymining text descriptions from a text corpus for the labeled and unlabeled set.We specifically use the alignment between CLIP's visual encoding of the imageand textual encoding of the corpus to retrieve top-k relevant pieces of textand incorporate their embeddings to perform joint image+text semi-supervisedclustering. We perform rigorous experimentation and ablations (including onwhere to retrieve from, how much to retrieve, and how to combine information),and validate our results on several datasets including out-of-distributiondomains, demonstrating state-of-art results.</description><author>Rabah Ouldnoughi, Chia-Wen Kuo, Zsolt Kira</author><pubDate>Wed, 17 May 2023 18:55:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10420v1</guid></item><item><title>Towards Multi-Layered 3D Garments Animation</title><link>http://arxiv.org/abs/2305.10418v1</link><description>Mimicking realistic dynamics in 3D garment animations is a challenging taskdue to the complex nature of multi-layered garments and the variety of outerforces involved. Existing approaches mostly focus on single-layered garmentsdriven by only human bodies and struggle to handle general scenarios. In thispaper, we propose a novel data-driven method, called LayersNet, to modelgarment-level animations as particle-wise interactions in a micro physicssystem. We improve simulation efficiency by representing garments aspatch-level particles in a two-level structural hierarchy. Moreover, weintroduce a novel Rotation Equivalent Transformation that leverages therotation invariance and additivity of physics systems to better model outerforces. To verify the effectiveness of our approach and bridge the gap betweenexperimental environments and real-world scenarios, we introduce a newchallenging dataset, D-LAYERS, containing 700K frames of dynamics of 4,900different combinations of multi-layered garments driven by both human bodiesand randomly sampled wind. Our experiments show that LayersNet achievessuperior performance both quantitatively and qualitatively. We will make thedataset and code publicly available athttps://mmlab-ntu.github.io/project/layersnet/index.html .</description><author>Yidi Shao, Chen Change Loy, Bo Dai</author><pubDate>Wed, 17 May 2023 18:53:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10418v1</guid></item><item><title>Scratch Copilot Evaluation: Assessing AI-Assisted Creative Coding for Families</title><link>http://arxiv.org/abs/2305.10417v1</link><description>How can AI enhance creative coding experiences for families? This studyexplores the potential of large language models (LLMs) in helping families withcreative coding using Scratch. Based on our previous user study involving aprototype AI assistant, we devised three evaluation scenarios to determine ifLLMs could help families comprehend game code, debug programs, and generate newideas for future projects. We utilized 22 Scratch projects for each scenarioand generated responses from LLMs with and without practice tasks, resulting in120 creative coding support scenario datasets. In addition, the authorsindependently evaluated their precision, pedagogical value, and age-appropriatelanguage. Our findings show that LLMs achieved an overall success rate of morethan 80\% on the different tasks and evaluation criteria. This research offersvaluable information on using LLMs for creative family coding and presentsdesign guidelines for future AI-supported coding applications. Our evaluationframework, together with our labeled evaluation data, is publicly available.</description><author>Stefania Druga, Nancy Otero</author><pubDate>Wed, 17 May 2023 18:52:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10417v1</guid></item><item><title>PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering</title><link>http://arxiv.org/abs/2305.10415v1</link><description>In this paper, we focus on the problem of Medical Visual Question Answering(MedVQA), which is crucial in efficiently interpreting medical images withvital clinic-relevant information. Firstly, we reframe the problem of MedVQA asa generation task that naturally follows the human-machine interaction, wepropose a generative-based model for medical visual understanding by aligningvisual information from a pre-trained vision encoder with a large languagemodel. Secondly, we establish a scalable pipeline to construct a large-scalemedical visual question-answering dataset, named PMC-VQA, which contains 227kVQA pairs of 149k images that cover various modalities or diseases. Thirdly, wepre-train our proposed model on PMC-VQA and then fine-tune it on multiplepublic benchmarks, e.g., VQA-RAD and SLAKE, outperforming existing work by alarge margin. Additionally, we propose a test set that has undergone manualverification, which is significantly more challenging, even the best modelsstruggle to solve.</description><author>Xiaoman Zhang, Chaoyi Wu, Ziheng Zhao, Weixiong Lin, Ya Zhang, Yanfeng Wang, Weidi Xie</author><pubDate>Wed, 17 May 2023 18:50:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10415v1</guid></item><item><title>On Consistency of Signatures Using Lasso</title><link>http://arxiv.org/abs/2305.10413v1</link><description>Signature transforms are iterated path integrals of continuous anddiscrete-time time series data, and their universal nonlinearity linearizes theproblem of feature selection. This paper revisits the consistency issue ofLasso regression for the signature transform, both theoretically andnumerically. Our study shows that, for processes and time series that arecloser to Brownian motion or random walk with weaker inter-dimensionalcorrelations, the Lasso regression is more consistent for their signaturesdefined by It\^o integrals; for mean reverting processes and time series, theirsignatures defined by Stratonovich integrals have more consistency in the Lassoregression. Our findings highlight the importance of choosing appropriatedefinitions of signatures and stochastic models in statistical inference andmachine learning.</description><author>Xin Guo, Ruixun Zhang, Chaoyi Zhao</author><pubDate>Wed, 17 May 2023 18:48:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10413v1</guid></item><item><title>AI Friends: A Design Framework for AI-Powered Creative Programming for Youth</title><link>http://arxiv.org/abs/2305.10412v1</link><description>What role can AI play in supporting and constraining creative coding byfamilies? To investigate these questions, we built a Wizard of Oz platform tohelp families engage in creative coding in partnership with aresearcher-operated AI Friend. We designed a 3 week series of programmingactivities with ten children, 7 to 12 years old, and nine parents. Using acreative self efficacy lens, we observe that families found it easier togenerate game ideas when prompted with questions by AI Friend; parents played aunique role in guiding children in more complex programming tasks when the AIFriend failed to help, and children were more encouraged to write code fornovel ideas using the AI friend help. These findings suggest that AI supportedplatforms should highlight unique family AI interactions focused on children'sagency and creative self-efficacy.</description><author>Stefania Druga, Amy J. Ko</author><pubDate>Wed, 17 May 2023 18:48:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10412v1</guid></item><item><title>Wasserstein Gradient Flows for Optimizing Gaussian Mixture Policies</title><link>http://arxiv.org/abs/2305.10411v1</link><description>Robots often rely on a repertoire of previously-learned motion policies forperforming tasks of diverse complexities. When facing unseen task conditions orwhen new task requirements arise, robots must adapt their motion policiesaccordingly. In this context, policy optimization is the \emph{de facto}paradigm to adapt robot policies as a function of task-specific objectives.Most commonly-used motion policies carry particular structures that are oftenoverlooked in policy optimization algorithms. We instead propose to leveragethe structure of probabilistic policies by casting the policy optimization asan optimal transport problem. Specifically, we focus on robot motion policiesthat build on Gaussian mixture models (GMMs) and formulate the policyoptimization as a Wassertein gradient flow over the GMMs space. This naturallyallows us to constrain the policy updates via the $L^2$-Wasserstein distancebetween GMMs to enhance the stability of the policy optimization process.Furthermore, we leverage the geometry of the Bures-Wasserstein manifold tooptimize the Gaussian distributions of the GMM policy via Riemannianoptimization. We evaluate our approach on common robotic settings: Reachingmotions, collision-avoidance behaviors, and multi-goal tasks. Our results showthat our method outperforms common policy optimization baselines in terms oftask success rate and low-variance solutions.</description><author>Hanna Ziesche, Leonel Rozo</author><pubDate>Wed, 17 May 2023 18:48:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10411v1</guid></item><item><title>Average-Constrained Policy Optimization</title><link>http://arxiv.org/abs/2302.00808v2</link><description>Reinforcement Learning (RL) with constraints is becoming an increasinglyimportant problem for various applications. Often, the average criterion ismore suitable than the discounted criterion. Yet, RL for averagecriterion-constrained MDPs remains a challenging problem. Algorithms designedfor discounted constrained RL problems often do not perform well for theaverage CMDP setting. In this paper, we introduce a new policy optimizationwith function approximation algorithm for constrained MDPs with the averagecriterion. The Average-Constrained Policy Optimization (ACPO) algorithm isinspired by the famed PPO-type algorithms based on trust region methods. Wedevelop basic sensitivity theory for average MDPs, and then use thecorresponding bounds in the design of the algorithm. We provide theoreticalguarantees on its performance, and through extensive experimental work invarious challenging MuJoCo environments, show the superior performance of thealgorithm when compared to other state-of-the-art algorithms adapted for theaverage CMDP setting.</description><author>Akhil Agnihotri, Rahul Jain, Haipeng Luo</author><pubDate>Wed, 17 May 2023 18:48:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00808v2</guid></item><item><title>BAD: BiAs Detection for Large Language Models in the context of candidate screening</title><link>http://arxiv.org/abs/2305.10407v1</link><description>Application Tracking Systems (ATS) have allowed talent managers, recruiters,and college admissions committees to process large volumes of potentialcandidate applications efficiently. Traditionally, this screening process wasconducted manually, creating major bottlenecks due to the quantity ofapplications and introducing many instances of human bias. The advent of largelanguage models (LLMs) such as ChatGPT and the potential of adopting methods tocurrent automated application screening raises additional bias and fairnessissues that must be addressed. In this project, we wish to identify andquantify the instances of social bias in ChatGPT and other OpenAI LLMs in thecontext of candidate screening in order to demonstrate how the use of thesemodels could perpetuate existing biases and inequalities in the hiring process.</description><author>Nam Ho Koh, Joseph Plata, Joyce Chai</author><pubDate>Wed, 17 May 2023 18:47:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10407v1</guid></item><item><title>Variational Classification</title><link>http://arxiv.org/abs/2305.10406v1</link><description>We present a novel extension of the traditional neural network approach toclassification tasks, referred to as variational classification (VC). Byincorporating latent variable modeling, akin to the relationship betweenvariational autoencoders and traditional autoencoders, we derive a trainingobjective based on the evidence lower bound (ELBO), optimized using anadversarial approach. Our VC model allows for more flexibility in designchoices, in particular class-conditional latent priors, in place of theimplicit assumptions made in off-the-shelf softmax classifiers. Empiricalevaluation on image and text classification datasets demonstrates theeffectiveness of our approach in terms of maintaining prediction accuracy whileimproving other desirable properties such as calibration and adversarialrobustness, even when applied to out-of-domain data.</description><author>Shehzaad Dhuliawala, Mrinmaya Sachan, Carl Allen</author><pubDate>Wed, 17 May 2023 18:47:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10406v1</guid></item><item><title>Leveraging Demonstrations to Improve Online Learning: Quality Matters</title><link>http://arxiv.org/abs/2302.03319v4</link><description>We investigate the extent to which offline demonstration data can improveonline learning. It is natural to expect some improvement, but the question ishow, and by how much? We show that the degree of improvement must depend on thequality of the demonstration data. To generate portable insights, we focus onThompson sampling (TS) applied to a multi-armed bandit as a prototypical onlinelearning algorithm and model. The demonstration data is generated by an expertwith a given competence level, a notion we introduce. We propose an informed TSalgorithm that utilizes the demonstration data in a coherent way through Bayes'rule and derive a prior-dependent Bayesian regret bound. This offers insightinto how pretraining can greatly improve online performance and how the degreeof improvement increases with the expert's competence level. We also develop apractical, approximate informed TS algorithm through Bayesian bootstrapping andshow substantial empirical regret reduction through experiments.</description><author>Botao Hao, Rahul Jain, Tor Lattimore, Benjamin Van Roy, Zheng Wen</author><pubDate>Wed, 17 May 2023 18:47:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.03319v4</guid></item><item><title>PaLM 2 Technical Report</title><link>http://arxiv.org/abs/2305.10403v1</link><description>We introduce PaLM 2, a new state-of-the-art language model that has bettermultilingual and reasoning capabilities and is more compute-efficient than itspredecessor PaLM. PaLM 2 is a Transformer-based model trained using a mixtureof objectives. Through extensive evaluations on English and multilinguallanguage, and reasoning tasks, we demonstrate that PaLM 2 has significantlyimproved quality on downstream tasks across different model sizes, whilesimultaneously exhibiting faster and more efficient inference compared to PaLM.This improved efficiency enables broader deployment while also allowing themodel to respond faster, for a more natural pace of interaction. PaLM 2demonstrates robust reasoning capabilities exemplified by large improvementsover PaLM on BIG-Bench and other reasoning tasks. PaLM 2 exhibits stableperformance on a suite of responsible AI evaluations, and enablesinference-time control over toxicity without additional overhead or impact onother capabilities. Overall, PaLM 2 achieves state-of-the-art performanceacross a diverse set of tasks and capabilities. When discussing the PaLM 2 family, it is important to distinguish betweenpre-trained models (of various sizes), fine-tuned variants of these models, andthe user-facing products that use these models. In particular, user-facingproducts typically include additional pre- and post-processing steps.Additionally, the underlying models may evolve over time. Therefore, one shouldnot expect the performance of user-facing products to exactly match the resultsreported in this report.</description><author>Rohan Anil, Andrew M. Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, Eric Chu, Jonathan H. Clark, Laurent El Shafey, Yanping Huang, Kathy Meier-Hellstern, Gaurav Mishra, Erica Moreira, Mark Omernick, Kevin Robinson, Sebastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu, Yujing Zhang, Gustavo Hernandez Abrego, Junwhan Ahn, Jacob Austin, Paul Barham, Jan Botha, James Bradbury, Siddhartha Brahma, Kevin Brooks, Michele Catasta, Yong Cheng, Colin Cherry, Christopher A. Choquette-Choo, Aakanksha Chowdhery, Clément Crepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev, Jacob Devlin, Mark Díaz, Nan Du, Ethan Dyer, Vlad Feinberg, Fangxiaoyu Feng, Vlad Fienber, Markus Freitag, Xavier Garcia, Sebastian Gehrmann, Lucas Gonzalez, </author><pubDate>Wed, 17 May 2023 18:46:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10403v1</guid></item><item><title>What You See is What You Read? Improving Text-Image Alignment Evaluation</title><link>http://arxiv.org/abs/2305.10400v1</link><description>Automatically determining whether a text and a corresponding image aresemantically aligned is a significant challenge for vision-language models,with applications in generative text-to-image and image-to-text tasks. In thiswork, we study methods for automatic text-image alignment evaluation. We firstintroduce SeeTRUE: a comprehensive evaluation set, spanning multiple datasetsfrom both text-to-image and image-to-text generation tasks, with humanjudgements for whether a given text-image pair is semantically aligned. We thendescribe two automatic methods to determine alignment: the first involving apipeline based on question generation and visual question answering models, andthe second employing an end-to-end classification approach by finetuningmultimodal pretrained models. Both methods surpass prior approaches in varioustext-image alignment tasks, with significant improvements in challenging casesthat involve complex composition or unnatural images. Finally, we demonstratehow our approaches can localize specific misalignments between an image and agiven text, and how they can be used to automatically re-rank candidates intext-to-image generation.</description><author>Michal Yarom, Yonatan Bitton, Soravit Changpinyo, Roee Aharoni, Jonathan Herzig, Oran Lang, Eran Ofek, Idan Szpektor</author><pubDate>Wed, 17 May 2023 18:43:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10400v1</guid></item><item><title>End-To-End Latent Variational Diffusion Models for Inverse Problems in High Energy Physics</title><link>http://arxiv.org/abs/2305.10399v1</link><description>High-energy collisions at the Large Hadron Collider (LHC) provide valuableinsights into open questions in particle physics. However, detector effectsmust be corrected before measurements can be compared to certain theoreticalpredictions or measurements from other detectors. Methods to solve this\textit{inverse problem} of mapping detector observations to theoreticalquantities of the underlying collision are essential parts of many physicsanalyses at the LHC. We investigate and compare various generative deeplearning methods to approximate this inverse mapping. We introduce a novelunified architecture, termed latent variation diffusion models, which combinesthe latent learning of cutting-edge generative art approaches with anend-to-end variational framework. We demonstrate the effectiveness of thisapproach for reconstructing global distributions of theoretical kinematicquantities, as well as for ensuring the adherence of the learned posteriordistributions to known physics constraints. Our unified approach achieves adistribution-free distance to the truth of over 20 times less than non-latentstate-of-the-art baseline and 3 times less than traditional latent diffusionmodels.</description><author>Alexander Shmakov, Kevin Greif, Michael Fenton, Aishik Ghosh, Pierre Baldi, Daniel Whiteson</author><pubDate>Wed, 17 May 2023 18:43:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10399v1</guid></item><item><title>RelationMatch: Matching In-batch Relationships for Semi-supervised Learning</title><link>http://arxiv.org/abs/2305.10397v1</link><description>Semi-supervised learning has achieved notable success by leveraging very fewlabeled data and exploiting the wealth of information derived from unlabeleddata. However, existing algorithms usually focus on aligning predictions onpaired data points augmented from an identical source, and overlook theinter-point relationships within each batch. This paper introduces a novelmethod, RelationMatch, which exploits in-batch relationships with a matrixcross-entropy (MCE) loss function. Through the application of MCE, our proposedmethod consistently surpasses the performance of established state-of-the-artmethods, such as FixMatch and FlexMatch, across a variety of vision datasets.Notably, we observed a substantial enhancement of 15.21% in accuracy overFlexMatch on the STL-10 dataset using only 40 labels. Moreover, we apply MCE tosupervised learning scenarios, and observe consistent improvements as well.</description><author>Yifan Zhang, Jingqin Yang, Zhiquan Tan, Yang Yuan</author><pubDate>Wed, 17 May 2023 18:37:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10397v1</guid></item><item><title>Optimality of Message-Passing Architectures for Sparse Graphs</title><link>http://arxiv.org/abs/2305.10391v1</link><description>We study the node classification problem on feature-decorated graphs in thesparse setting, i.e., when the expected degree of a node is $O(1)$ in thenumber of nodes. Such graphs are typically known to be locally tree-like. Weintroduce a notion of Bayes optimality for node classification tasks, calledasymptotic local Bayes optimality, and compute the optimal classifier accordingto this criterion for a fairly general statistical data model with arbitrarydistributions of the node features and edge connectivity. The optimalclassifier is implementable using a message-passing graph neural networkarchitecture. We then compute the generalization error of this classifier andcompare its performance against existing learning methods theoretically on awell-studied statistical model with naturally identifiable signal-to-noiseratios (SNRs) in the data. We find that the optimal message-passingarchitecture interpolates between a standard MLP in the regime of low graphsignal and a typical convolution in the regime of high graph signal.Furthermore, we prove a corresponding non-asymptotic result.</description><author>Aseem Baranwal, Aukosh Jagannath, Kimon Fountoulakis</author><pubDate>Wed, 17 May 2023 18:31:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10391v1</guid></item><item><title>Raising the Bar for Certified Adversarial Robustness with Diffusion Models</title><link>http://arxiv.org/abs/2305.10388v1</link><description>Certified defenses against adversarial attacks offer formal guarantees on therobustness of a model, making them more reliable than empirical methods such asadversarial training, whose effectiveness is often later reduced by unseenattacks. Still, the limited certified robustness that is currently achievablehas been a bottleneck for their practical adoption. Gowal et al. and Wang etal. have shown that generating additional training data using state-of-the-artdiffusion models can considerably improve the robustness of adversarialtraining. In this work, we demonstrate that a similar approach cansubstantially improve deterministic certified defenses. In addition, we providea list of recommendations to scale the robustness of certified trainingapproaches. One of our main insights is that the generalization gap, i.e., thedifference between the training and test accuracy of the original model, is agood predictor of the magnitude of the robustness improvement when usingadditional generated data. Our approach achieves state-of-the-art deterministicrobustness certificates on CIFAR-10 for the $\ell_2$ ($\epsilon = 36/255$) and$\ell_\infty$ ($\epsilon = 8/255$) threat models, outperforming the previousbest results by $+3.95\%$ and $+1.39\%$, respectively. Furthermore, we reportsimilar improvements for CIFAR-100.</description><author>Thomas Altstidl, David Dobre, Björn Eskofier, Gauthier Gidel, Leo Schwinn</author><pubDate>Wed, 17 May 2023 18:29:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10388v1</guid></item><item><title>Multi-Prompt Alignment for Multi-Source Unsupervised Domain Adaptation</title><link>http://arxiv.org/abs/2209.15210v3</link><description>Most existing methods for unsupervised domain adaptation (UDA) rely on ashared network to extract domain-invariant features. However, when facingmultiple source domains, optimizing such a network involves updating theparameters of the entire network, making it both computationally expensive andchallenging, particularly when coupled with min-max objectives. Inspired byrecent advances in prompt learning that adapts high-capacity models fordownstream tasks in a computationally economic way, we introduce Multi-PromptAlignment (MPA), a simple yet efficient framework for multi-source UDA. Given asource and target domain pair, MPA first trains an individual prompt tominimize the domain gap through a contrastive loss. Then, MPA denoises thelearned prompts through an auto-encoding process and aligns them by maximizingthe agreement of all the reconstructed prompts. Moreover, we show that theresulting subspace acquired from the auto-encoding process can easilygeneralize to a streamlined set of target domains, making our method moreefficient for practical usage. Extensive experiments show that MPA achievesstate-of-the-art results on three popular datasets with an impressive averageaccuracy of 54.1% on DomainNet.</description><author>Haoran Chen, Zuxuan Wu, Xintong Han, Yu-Gang Jiang</author><pubDate>Wed, 17 May 2023 18:27:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.15210v3</guid></item><item><title>Elaborative Simplification as Implicit Questions Under Discussion</title><link>http://arxiv.org/abs/2305.10387v1</link><description>Automated text simplification, a technique useful for making text moreaccessible to people such as children and emergent bilinguals, is often thoughtof as a monolingual translation task from complex sentences to simplifiedsentences using encoder-decoder models. This view fails to account forelaborative simplification, where new information is added into the simplifiedtext. This paper proposes to view elaborative simplification through the lensof the Question Under Discussion (QUD) framework, providing a robust way toinvestigate what writers elaborate upon, how they elaborate, and howelaborations fit into the discourse context by viewing elaborations as explicitanswers to implicit questions. We introduce ElabQUD, consisting of 1.3Kelaborations accompanied with implicit QUDs, to study these phenomena. We showthat explicitly modeling QUD (via question generation) not only providesessential understanding of elaborative simplification and how the elaborationsconnect with the rest of the discourse, but also substantially improves thequality of elaboration generation.</description><author>Yating Wu, William Sheffield, Kyle Mahowald, Junyi Jessy Li</author><pubDate>Wed, 17 May 2023 18:26:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10387v1</guid></item><item><title>Learning curves for deep structured Gaussian feature models</title><link>http://arxiv.org/abs/2303.00564v2</link><description>In recent years, significant attention in deep learning theory has beendevoted to analyzing the generalization performance of models with multiplelayers of Gaussian random features. However, few works have considered theeffect of feature anisotropy; most assume that features are generated usingindependent and identically distributed Gaussian weights. Here, we derivelearning curves for models with many layers of structured Gaussian features. Weshow that allowing correlations between the rows of the first layer of featurescan aid generalization, while structure in later layers is generallydetrimental. Our results shed light on how weight structure affectsgeneralization in a simple class of solvable models.</description><author>Jacob A. Zavatone-Veth, Cengiz Pehlevan</author><pubDate>Wed, 17 May 2023 18:26:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.00564v2</guid></item><item><title>Distributing Synergy Functions: Unifying Game-Theoretic Interaction Methods for Machine-Learning Explainability</title><link>http://arxiv.org/abs/2305.03100v3</link><description>Deep learning has revolutionized many areas of machine learning, fromcomputer vision to natural language processing, but these high-performancemodels are generally "black box." Explaining such models would improvetransparency and trust in AI-powered decision making and is necessary forunderstanding other practical needs such as robustness and fairness. A popularmeans of enhancing model transparency is to quantify how individual inputscontribute to model outputs (called attributions) and the magnitude ofinteractions between groups of inputs. A growing number of these methods importconcepts and results from game theory to produce attributions and interactions.This work presents a unifying framework for game-theory-inspired attributionand $k^\text{th}$-order interaction methods. We show that, given modestassumptions, a unique full account of interactions between features, calledsynergies, is possible in the continuous input setting. We identify how variousmethods are characterized by their policy of distributing synergies. We alsodemonstrate that gradient-based methods are characterized by their actions onmonomials, a type of synergy function, and introduce unique gradient-basedmethods. We show that the combination of various criteria uniquely defines theattribution/interaction methods. Thus, the community needs to identify goalsand contexts when developing and employing attribution and interaction methods.</description><author>Daniel Lundstrom, Meisam Razaviyayn</author><pubDate>Wed, 17 May 2023 18:21:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.03100v3</guid></item><item><title>Logit-Based Ensemble Distribution Distillation for Robust Autoregressive Sequence Uncertainties</title><link>http://arxiv.org/abs/2305.10384v1</link><description>Efficiently and reliably estimating uncertainty is an important objective indeep learning. It is especially pertinent to autoregressive sequence tasks,where training and inference costs are typically very high. However, existingresearch has predominantly focused on tasks with static data such as imageclassification. In this work, we investigate Ensemble Distribution Distillation(EDD) applied to large-scale natural language sequence-to-sequence data. EDDaims to compress the superior uncertainty performance of an expensive (teacher)ensemble into a cheaper (student) single model. Importantly, the ability toseparate knowledge (epistemic) and data (aleatoric) uncertainty is retained.Existing probability-space approaches to EDD, however, are difficult to scaleto large vocabularies. We show, for modern transformer architectures onlarge-scale translation tasks, that modelling the ensemble logits, instead ofsoftmax probabilities, leads to significantly better students. Moreover, thestudents surprisingly even outperform Deep Ensembles by up to ~10% AUROC onout-of-distribution detection, whilst matching them at in-distributiontranslation.</description><author>Yassir Fathullah, Guoxuan Xia, Mark Gales</author><pubDate>Wed, 17 May 2023 18:21:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10384v1</guid></item><item><title>Segment Anything Model for Medical Image Analysis: an Experimental Study</title><link>http://arxiv.org/abs/2304.10517v3</link><description>Training segmentation models for medical images continues to be challengingdue to the limited availability of data annotations. Segment Anything Model(SAM) is a foundation model that is intended to segment user-defined objects ofinterest in an interactive manner. While the performance on natural images isimpressive, medical image domains pose their own set of challenges. Here, weperform an extensive evaluation of SAM's ability to segment medical images on acollection of 19 medical imaging datasets from various modalities andanatomies. We report the following findings: (1) SAM's performance based onsingle prompts highly varies depending on the dataset and the task, fromIoU=0.1135 for spine MRI to IoU=0.8650 for hip X-ray. (2) Segmentationperformance appears to be better for well-circumscribed objects with promptswith less ambiguity and poorer in various other scenarios such as thesegmentation of brain tumors. (3) SAM performs notably better with box promptsthan with point prompts. (4) SAM outperforms similar methods RITM, SimpleClick,and FocalClick in almost all single-point prompt settings. (5) Whenmultiple-point prompts are provided iteratively, SAM's performance generallyimproves only slightly while other methods' performance improves to the levelthat surpasses SAM's point-based performance. We also provide severalillustrations for SAM's performance on all tested datasets, iterativesegmentation, and SAM's behavior given prompt ambiguity. We conclude that SAMshows impressive zero-shot segmentation performance for certain medical imagingdatasets, but moderate to poor performance for others. SAM has the potential tomake a significant impact in automated medical image segmentation in medicalimaging, but appropriate care needs to be applied when using it.</description><author>Maciej A. Mazurowski, Haoyu Dong, Hanxue Gu, Jichen Yang, Nicholas Konz, Yixin Zhang</author><pubDate>Wed, 17 May 2023 18:20:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10517v3</guid></item><item><title>Motion Question Answering via Modular Motion Programs</title><link>http://arxiv.org/abs/2305.08953v2</link><description>In order to build artificial intelligence systems that can perceive andreason with human behavior in the real world, we must first design models thatconduct complex spatio-temporal reasoning over motion sequences. Moving towardsthis goal, we propose the HumanMotionQA task to evaluate complex, multi-stepreasoning abilities of models on long-form human motion sequences. We generatea dataset of question-answer pairs that require detecting motor cues in smallportions of motion sequences, reasoning temporally about when events occur, andquerying specific motion attributes. In addition, we propose NSPose, aneuro-symbolic method for this task that uses symbolic reasoning and a modulardesign to ground motion through learning motion concepts, attribute neuraloperators, and temporal relations. We demonstrate the suitability of NSPose forthe HumanMotionQA task, outperforming all baseline methods.</description><author>Mark Endo, Joy Hsu, Jiaman Li, Jiajun Wu</author><pubDate>Wed, 17 May 2023 18:18:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.08953v2</guid></item><item><title>Large-Scale Text Analysis Using Generative Language Models: A Case Study in Discovering Public Value Expressions in AI Patents</title><link>http://arxiv.org/abs/2305.10383v1</link><description>Labeling data is essential for training text classifiers but is oftendifficult to accomplish accurately, especially for complex and abstractconcepts. Seeking an improved method, this paper employs a novel approach usinga generative language model (GPT-4) to produce labels and rationales forlarge-scale text analysis. We apply this approach to the task of discoveringpublic value expressions in US AI patents. We collect a database comprising154,934 patent documents using an advanced Boolean query submitted toInnovationQ+. The results are merged with full patent text from the USPTO,resulting in 5.4 million sentences. We design a framework for identifying andlabeling public value expressions in these AI patent sentences. A prompt forGPT-4 is developed which includes definitions, guidelines, examples, andrationales for text classification. We evaluate the quality of the labels andrationales produced by GPT-4 using BLEU scores and topic modeling and find thatthey are accurate, diverse, and faithful. These rationales also serve as achain-of-thought for the model, a transparent mechanism for human verification,and support for human annotators to overcome cognitive limitations. We concludethat GPT-4 achieved a high-level of recognition of public value theory from ourframework, which it also uses to discover unseen public value expressions. Weuse the labels produced by GPT-4 to train BERT-based classifiers and predictsentences on the entire database, achieving high F1 scores for the 3-class(0.85) and 2-class classification (0.91) tasks. We discuss the implications ofour approach for conducting large-scale text analyses with complex and abstractconcepts and suggest that, with careful framework design and interactive humanoversight, generative language models can offer significant advantages inquality and in reduced time and costs for producing labels and rationales.</description><author>Sergio Pelaez, Gaurav Verma, Barbara Ribeiro, Philip Shapira</author><pubDate>Wed, 17 May 2023 18:18:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10383v1</guid></item><item><title>Active Learning in Symbolic Regression Performance with Physical Constraints</title><link>http://arxiv.org/abs/2305.10379v1</link><description>Evolutionary symbolic regression (SR) fits a symbolic equation to data, whichgives a concise interpretable model. We explore using SR as a method to proposewhich data to gather in an active learning setting with physical constraints.SR with active learning proposes which experiments to do next. Active learningis done with query by committee, where the Pareto frontier of equations is thecommittee. The physical constraints improve proposed equations in very low datasettings. These approaches reduce the data required for SR and achieves stateof the art results in data required to rediscover known equations.</description><author>Jorge Medina, Andrew D. White</author><pubDate>Wed, 17 May 2023 18:07:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10379v1</guid></item><item><title>Neural networks learn to magnify areas near decision boundaries</title><link>http://arxiv.org/abs/2301.11375v2</link><description>We study how training molds the Riemannian geometry induced by neural networkfeature maps. At infinite width, neural networks with random parameters inducehighly symmetric metrics on input space. Feature learning in networks trainedto perform classification tasks magnifies local areas along decisionboundaries. These changes are consistent with previously proposed geometricapproaches for hand-tuning of kernel methods to improve generalization.</description><author>Jacob A. Zavatone-Veth, Sheng Yang, Julian A. Rubinfien, Cengiz Pehlevan</author><pubDate>Wed, 17 May 2023 18:07:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.11375v2</guid></item><item><title>Explainable Multi-Agent Reinforcement Learning for Temporal Queries</title><link>http://arxiv.org/abs/2305.10378v1</link><description>As multi-agent reinforcement learning (MARL) systems are increasinglydeployed throughout society, it is imperative yet challenging for users tounderstand the emergent behaviors of MARL agents in complex environments. Thiswork presents an approach for generating policy-level contrastive explanationsfor MARL to answer a temporal user query, which specifies a sequence of taskscompleted by agents with possible cooperation. The proposed approach encodesthe temporal query as a PCTL logic formula and checks if the query is feasibleunder a given MARL policy via probabilistic model checking. Such explanationscan help reconcile discrepancies between the actual and anticipated multi-agentbehaviors. The proposed approach also generates correct and completeexplanations to pinpoint reasons that make a user query infeasible. We havesuccessfully applied the proposed approach to four benchmark MARL domains (upto 9 agents in one domain). Moreover, the results of a user study show that thegenerated explanations significantly improve user performance and satisfaction.</description><author>Kayla Boggess, Sarit Kraus, Lu Feng</author><pubDate>Wed, 17 May 2023 18:04:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10378v1</guid></item><item><title>Human Choice Prediction in Non-Cooperative Games: Simulation-based Off-Policy Evaluation</title><link>http://arxiv.org/abs/2305.10361v1</link><description>Persuasion games have been fundamental in economics and AI research, and havesignificant practical applications. Recent works in this area have started toincorporate natural language, moving beyond the traditional stylized messagesetting. However, previous research has focused on on-policy prediction, wherethe train and test data have the same distribution, which is not representativeof real-life scenarios. In this paper, we tackle the challenging problem ofoff-policy evaluation (OPE) in language-based persuasion games. To address theinherent difficulty of human data collection in this setup, we propose a novelapproach which combines real and simulated human-bot interaction data. Oursimulated data is created by an exogenous model assuming decision makers (DMs)start with a mixture of random and decision-theoretic based behaviors andimprove over time. We present a deep learning training algorithm thateffectively integrates real interaction and simulated data, substantiallyimproving over models that train only with interaction data. Our resultsdemonstrate the potential of real interaction and simulation mixtures as acost-effective and scalable solution for OPE in language-based persuasiongames.\footnote{Our code and the large dataset we collected and generated aresubmitted as supplementary material and will be made publicly available uponacceptance.</description><author>Eilam Shapira, Reut Apel, Moshe Tennenholtz, Roi Reichart</author><pubDate>Wed, 17 May 2023 17:38:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10361v1</guid></item><item><title>Phase Aberration Correction without Reference Data: An Adaptive Mixed Loss Deep Learning Approach</title><link>http://arxiv.org/abs/2303.05747v2</link><description>Phase aberration is one of the primary sources of image quality degradationin ultrasound, which is induced by spatial variations in sound speed across theheterogeneous medium. This effect disrupts transmitted waves and preventscoherent summation of echo signals, resulting in suboptimal image quality. Inreal experiments, obtaining non-aberrated ground truths can be extremelychallenging, if not infeasible. It hinders the performance of deeplearning-based phase aberration correction techniques due to sole reliance onsimulated data and the presence of domain shift between simulated andexperimental data. Here, for the first time, we propose a deep learning-basedmethod that does not require reference data to compensate for the phaseaberration effect. We train a network wherein both input and target output arerandomly aberrated radio frequency (RF) data. Moreover, we demonstrate that aconventional loss function such as mean square error is inadequate for trainingthe network to achieve optimal performance. Instead, we propose an adaptivemixed loss function that employs both B-mode and RF data, resulting in moreefficient convergence and enhanced performance. Source code is available at\url{http://code.sonography.ai}.</description><author>Mostafa Sharifzadeh, Habib Benali, Hassan Rivaz</author><pubDate>Wed, 17 May 2023 17:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05747v2</guid></item><item><title>KGLM: Integrating Knowledge Graph Structure in Language Models for Link Prediction</title><link>http://arxiv.org/abs/2211.02744v2</link><description>The ability of knowledge graphs to represent complex relationships at scalehas led to their adoption for various needs including knowledge representation,question-answering, and recommendation systems. Knowledge graphs are oftenincomplete in the information they represent, necessitating the need forknowledge graph completion tasks. Pre-trained and fine-tuned language modelshave shown promise in these tasks although these models ignore the intrinsicinformation encoded in the knowledge graph, namely the entity and relationtypes. In this work, we propose the Knowledge Graph Language Model (KGLM)architecture, where we introduce a new entity/relation embedding layer thatlearns to differentiate distinctive entity and relation types, thereforeallowing the model to learn the structure of the knowledge graph. In this work,we show that further pre-training the language models with this additionalembedding layer using the triples extracted from the knowledge graph, followedby the standard fine-tuning phase sets a new state-of-the-art performance forthe link prediction task on the benchmark datasets.</description><author>Jason Youn, Ilias Tagkopoulos</author><pubDate>Wed, 17 May 2023 17:34:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.02744v2</guid></item><item><title>Evaluating Object Hallucination in Large Vision-Language Models</title><link>http://arxiv.org/abs/2305.10355v1</link><description>Inspired by the superior language abilities of large language models (LLM),large vision-language models (LVLM) have been recently explored by integratingpowerful LLMs for improving the performance on complex multimodal tasks.Despite the promising progress on LVLMs, we find that LVLMs suffer from thehallucination problem, i.e. they tend to generate objects that are inconsistentwith the target images in the descriptions. To investigate it, this workpresents the first systematic study on object hallucination of LVLMs. Weconduct the evaluation experiments on several representative LVLMs, and showthat they mostly suffer from severe object hallucination issue. We furtherdiscuss that the visual instructions may influence the hallucination, and findthat: objects that frequently occur in the visual instructions or co-occur withthe image objects, are obviously prone to be hallucinated by LVLMs. Besides, wefind that existing evaluation methods might be affected by the inputinstructions and generation styles of LVLMs. Thus, we further design animproved evaluation method for object hallucination by proposing apolling-based query method called \emph{POPE}. Experiment results demonstratethat our POPE can evaluate the object hallucination in a more stable andflexible way. Our codes and data are publicly available athttps://github.com/RUCAIBox/POPE.</description><author>Yifan Li, Yifan Du, Kun Zhou, Jinpeng Wang, Wayne Xin Zhao, Ji-Rong Wen</author><pubDate>Wed, 17 May 2023 17:34:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10355v1</guid></item><item><title>Interactive Learning of Hierarchical Tasks from Dialog with GPT</title><link>http://arxiv.org/abs/2305.10349v1</link><description>We present a system for interpretable, symbolic, interactive task learningfrom dialog using a GPT model as a conversational front-end. The learned tasksare represented as hierarchical decompositions of predicate-argument structureswith scoped variable arguments. By using a GPT model to convert interactivedialog into a semantic representation, and then recursively asking fordefinitions of unknown steps, we show that hierarchical task knowledge can beacquired and re-used in a natural and unrestrained conversational environment.We compare our system to a similar architecture using a more conventionalparser and show that our system tolerates a much wider variety of linguisticvariance.</description><author>Lane Lawley, Christopher J. MacLellan</author><pubDate>Wed, 17 May 2023 17:32:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10349v1</guid></item><item><title>Generalizing Goal-Conditioned Reinforcement Learning with Variational Causal Reasoning</title><link>http://arxiv.org/abs/2207.09081v6</link><description>As a pivotal component to attaining generalizable solutions in humanintelligence, reasoning provides great potential for reinforcement learning(RL) agents' generalization towards varied goals by summarizing part-to-wholearguments and discovering cause-and-effect relations. However, how to discoverand represent causalities remains a huge gap that hinders the development ofcausal RL. In this paper, we augment Goal-Conditioned RL (GCRL) with CausalGraph (CG), a structure built upon the relation between objects and events. Wenovelly formulate the GCRL problem into variational likelihood maximizationwith CG as latent variables. To optimize the derived objective, we propose aframework with theoretical performance guarantees that alternates between twosteps: using interventional data to estimate the posterior of CG; using CG tolearn generalizable models and interpretable policies. Due to the lack ofpublic benchmarks that verify generalization capability under reasoning, wedesign nine tasks and then empirically show the effectiveness of the proposedmethod against five baselines on these tasks. Further theoretical analysisshows that our performance improvement is attributed to the virtuous cycle ofcausal discovery, transition modeling, and policy training, which aligns withthe experimental evidence in extensive ablation studies.</description><author>Wenhao Ding, Haohong Lin, Bo Li, Ding Zhao</author><pubDate>Wed, 17 May 2023 17:29:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.09081v6</guid></item><item><title>Confidence-Guided Semi-supervised Learning in Land Cover Classification</title><link>http://arxiv.org/abs/2305.10344v1</link><description>Semi-supervised learning has been well developed to help reduce the cost ofmanual labelling by exploiting a large quantity of unlabelled data. Especiallyin the application of land cover classification, pixel-level manual labellingin large-scale imagery is labour-intensive and expensive. However, the existingsemi-supervised learning methods pay limited attention to the quality ofpseudo-labels whilst supervising the network. That is, nevertheless, one of thecritical factors determining network performance. In order to fill this gap, wedevelop a confidence-guided semi-supervised learning (CGSSL) approach to makeuse of high-confidence pseudo labels and reduce the negative effect oflow-confidence ones on training the land cover classification network.Meanwhile, the proposed semi-supervised learning approach uses multiple networkarchitectures to increase pseudo-label diversity. The proposed semi-supervisedlearning approach significantly improves the performance of land coverclassification compared to the classical semi-supervised learning methods incomputer vision and even outperforms fully supervised learning with a completeset of labelled imagery of the benchmark Potsdam land cover data set.</description><author>Wanli Ma, Oktay Karakus, Paul L. Rosin</author><pubDate>Wed, 17 May 2023 17:28:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10344v1</guid></item><item><title>Extracting a functional representation from a dictionary for non-rigid shape matching</title><link>http://arxiv.org/abs/2305.10332v1</link><description>Shape matching is a fundamental problem in computer graphics with manyapplications. Functional maps translate the point-wise shape-matching probleminto its functional counterpart and have inspired numerous solutions over thelast decade. Nearly all the solutions based on functional maps rely on theeigenfunctions of the Laplace-Beltrami Operator (LB) to describe the functionalspaces defined on the surfaces and then convert the functional correspondencesinto point-wise correspondences. However, this final step is often error-proneand inaccurate in tiny regions and protrusions, where the energy of LB does notuniformly cover the surface. We propose a new functional basis PrincipalComponents of a Dictionary (PCD) to address such intrinsic limitation. PCDconstructs an orthonormal basis from the Principal Component Analysis (PCA) ofa dictionary of functions defined over the shape. These dictionaries can targetspecific properties of the final basis, such as achieving an even spreading ofenergy. Our experimental evaluation compares seven different dictionaries onestablished benchmarks, showing that PCD is suited to target differentshape-matching scenarios, resulting in more accurate point-wise maps than theLB basis when used in the same pipeline. This evidence provides a promisingalternative for improving correspondence estimation, confirming the power andflexibility of functional maps.</description><author>Michele Colombo, Giacomo Boracchi, Simone Melzi</author><pubDate>Wed, 17 May 2023 17:15:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10332v1</guid></item><item><title>G-Adapter: Towards Structure-Aware Parameter-Efficient Transfer Learning for Graph Transformer Networks</title><link>http://arxiv.org/abs/2305.10329v1</link><description>It has become a popular paradigm to transfer the knowledge of large-scalepre-trained models to various downstream tasks via fine-tuning the entire modelparameters. However, with the growth of model scale and the rising number ofdownstream tasks, this paradigm inevitably meets the challenges in terms ofcomputation consumption and memory footprint issues. Recently,Parameter-Efficient Fine-Tuning (PEFT) (e.g., Adapter, LoRA, BitFit) shows apromising paradigm to alleviate these concerns by updating only a portion ofparameters. Despite these PEFTs having demonstrated satisfactory performance innatural language processing, it remains under-explored for the question ofwhether these techniques could be transferred to graph-based tasks with GraphTransformer Networks (GTNs). Therefore, in this paper, we fill this gap byproviding extensive benchmarks with traditional PEFTs on a range of graph-baseddownstream tasks. Our empirical study shows that it is sub-optimal to directlytransfer existing PEFTs to graph-based tasks due to the issue of featuredistribution shift. To address this issue, we propose a novel structure-awarePEFT approach, named G-Adapter, which leverages graph convolution operation tointroduce graph structure (e.g., graph adjacent matrix) as an inductive bias toguide the updating process. Besides, we propose Bregman proximal pointoptimization to further alleviate feature distribution shift by preventing themodel from aggressive update. Extensive experiments demonstrate that G-Adapterobtains the state-of-the-art performance compared to the counterparts on ninegraph benchmark datasets based on two pre-trained GTNs, and delivers tremendousmemory footprint efficiency compared to the conventional paradigm.</description><author>Anchun Gui, Jinqiang Ye, Han Xiao</author><pubDate>Wed, 17 May 2023 17:10:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10329v1</guid></item><item><title>NLG Evaluation Metrics Beyond Correlation Analysis: An Empirical Metric Preference Checklist</title><link>http://arxiv.org/abs/2305.08566v2</link><description>In this study, we analyze NLG automatic metrics based on whether humanevaluation aspect is used as context or objective to compute the metrics: (i)Task-agnostic and (ii) Human-aligned. Task-agnostic metrics, such asPerplexity, BLEU, BERTScore, are cost-effective and highly adaptable to diverseNLG tasks, yet they have a weak correlation with human. Human-aligned metrics(CTC, CtrlEval, UniEval) improves correlation level by incorporating desirablehuman-like qualities as training objective. However, their effectiveness atdiscerning system-level performance and quality of system outputs remainsunclear. We present metric preference checklist as a framework to assess thediscriminative power of automatic metrics in three NLG tasks: TextSummarization, Dialogue Response Generation, and Controlled Generation. We showthat multi-aspect human-aligned metric (UniEval) is not necessarily dominantover single-aspect human-aligned metrics (CTC, CtrlEval) and task-agnosticmetrics (BLEU, BERTScore), particularly when a disagreement between humanevaluation aspects is present. We also show particular use cases in whichautomatic metrics provide a better guidance than human on discriminatingsystem-level performance. Our proposed framework provides access: (i) forverifying whether automatic metrics are faithful to human preference,regardless their correlation level to human; and (ii) for scrutinizing thestrengths and limitations of NLG systems, which are often obscured by astandard averaging method of evaluation scores.</description><author>Iftitahu Ni'mah, Meng Fang, Vlado Menkovski, Mykola Pechenizkiy</author><pubDate>Wed, 17 May 2023 17:09:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.08566v2</guid></item><item><title>Joint Denoising and Few-angle Reconstruction for Low-dose Cardiac SPECT Using a Dual-domain Iterative Network with Adaptive Data Consistency</title><link>http://arxiv.org/abs/2305.10328v1</link><description>Myocardial perfusion imaging (MPI) by single-photon emission computedtomography (SPECT) is widely applied for the diagnosis of cardiovasculardiseases. Reducing the dose of the injected tracer is essential for loweringthe patient's radiation exposure, but it will lead to increased image noise.Additionally, the latest dedicated cardiac SPECT scanners typically acquireprojections in fewer angles using fewer detectors to reduce hardware expenses,potentially resulting in lower reconstruction accuracy. To overcome thesechallenges, we propose a dual-domain iterative network for end-to-end jointdenoising and reconstruction from low-dose and few-angle projections of cardiacSPECT. The image-domain network provides a prior estimate for theprojection-domain networks. The projection-domain primary and auxiliary modulesare interconnected for progressive denoising and few-angle reconstruction.Adaptive Data Consistency (ADC) modules improve prediction accuracy byefficiently fusing the outputs of the primary and auxiliary modules.Experiments using clinical MPI data show that our proposed method outperformsexisting image-, projection-, and dual-domain techniques, producing moreaccurate projections and reconstructions. Ablation studies confirm thesignificance of the image-domain prior estimate and ADC modules in enhancingnetwork performance.</description><author>Xiongchao Chen, Bo Zhou, Huidong Xie, Xueqi Guo, Qiong Liu, Albert J. Sinusas, Chi Liu</author><pubDate>Wed, 17 May 2023 17:09:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10328v1</guid></item><item><title>Cross-domain Iterative Network for Simultaneous Denoising, Limited-angle Reconstruction, and Attenuation Correction of Low-dose Cardiac SPECT</title><link>http://arxiv.org/abs/2305.10326v1</link><description>Single-Photon Emission Computed Tomography (SPECT) is widely applied for thediagnosis of ischemic heart diseases. Low-dose (LD) SPECT aims to minimizeradiation exposure but leads to increased image noise. Limited-angle (LA) SPECTenables faster scanning and reduced hardware costs but results in lowerreconstruction accuracy. Additionally, computed tomography (CT)-derivedattenuation maps ($\mu$-maps) are commonly used for SPECT attenuationcorrection (AC), but it will cause extra radiation exposure and SPECT-CTmisalignments. In addition, the majority of SPECT scanners in the market arenot hybrid SPECT/CT scanners. Although various deep learning methods have beenintroduced to separately address these limitations, the solution forsimultaneously addressing these challenges still remains highly under-exploredand challenging. To this end, we propose a Cross-domain Iterative Network(CDI-Net) for simultaneous denoising, LA reconstruction, and CT-free AC incardiac SPECT. In CDI-Net, paired projection- and image-domain networks areend-to-end connected to fuse the emission and anatomical information acrossdomains and iterations. Adaptive Weight Recalibrators (AWR) adjust themulti-channel input features to enhance prediction accuracy. Our experimentsusing clinical data showed that CDI-Net produced more accurate $\mu$-maps,projections, and reconstructions compared to existing approaches that addressedeach task separately. Ablation studies demonstrated the significance ofcross-domain and cross-iteration connections, as well as AWR, in improving thereconstruction performance.</description><author>Xiongchao Chen, Bo Zhou, Huidong Xie, Xueqi Guo, Qiong Liu, Albert J. Sinusas, Chi Liu</author><pubDate>Wed, 17 May 2023 17:06:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10326v1</guid></item><item><title>Using a Large Language Model to Control Speaking Style for Expressive TTS</title><link>http://arxiv.org/abs/2305.10321v1</link><description>Appropriate prosody is critical for successful spoken communication.Contextual word embeddings are proven to be helpful in predicting prosody butdo not allow for choosing between plausible prosodic renditions.Reference-based TTS models attempt to address this by conditioning speechgeneration on a reference speech sample. These models can generate expressivespeech but this requires finding an appropriate reference. Sufficiently large generative language models have been used to solve variouslanguage-related tasks. We explore whether such models can be used to suggestappropriate prosody for expressive TTS. We train a TTS model on anon-expressive corpus and then prompt the language model to suggest changes topitch, energy and duration. The prompt can be designed for any task and weprompt the model to make suggestions based on target speaking style anddialogue context. The proposed method is rated most appropriate in 49.9\% ofcases compared to 31.0\% for a baseline model.</description><author>Atli Thor Sigurgeirsson, Simon King</author><pubDate>Wed, 17 May 2023 17:01:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10321v1</guid></item><item><title>CostFormer:Cost Transformer for Cost Aggregation in Multi-view Stereo</title><link>http://arxiv.org/abs/2305.10320v1</link><description>The core of Multi-view Stereo(MVS) is the matching process among referenceand source pixels. Cost aggregation plays a significant role in this process,while previous methods focus on handling it via CNNs. This may inherit thenatural limitation of CNNs that fail to discriminate repetitive or incorrectmatches due to limited local receptive fields. To handle the issue, we aim toinvolve Transformer into cost aggregation. However, another problem may occurdue to the quadratically growing computational complexity caused byTransformer, resulting in memory overflow and inference latency. In this paper,we overcome these limits with an efficient Transformer-based cost aggregationnetwork, namely CostFormer. The Residual Depth-Aware Cost Transformer(RDACT) isproposed to aggregate long-range features on cost volume via self-attentionmechanisms along the depth and spatial dimensions. Furthermore, ResidualRegression Transformer(RRT) is proposed to enhance spatial attention. Theproposed method is a universal plug-in to improve learning-based MVS methods.</description><author>Weitao Chen, Hongbin Xu, Zhipeng Zhou, Yang Liu, Baigui Sun, Wenxiong Kang, Xuansong Xie</author><pubDate>Wed, 17 May 2023 17:01:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10320v1</guid></item><item><title>Automatic Photo Orientation Detection with Convolutional Neural Networks</title><link>http://arxiv.org/abs/2305.10319v1</link><description>We apply convolutional neural networks (CNN) to the problem of imageorientation detection in the context of determining the correct orientation(from 0, 90, 180, and 270 degrees) of a consumer photo. The problem isespecially important for digitazing analog photographs. We substantiallyimprove on the published state of the art in terms of the performance on one ofthe standard datasets, and test our system on a more difficult large dataset ofconsumer photos. We use Guided Backpropagation to obtain insights into how ourCNN detects photo orientation, and to explain its mistakes.</description><author>Michael Guerzhoy, Ujash Joshi</author><pubDate>Wed, 17 May 2023 17:00:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10319v1</guid></item><item><title>Solving for multi-class using orthogonal coding matrices</title><link>http://arxiv.org/abs/1801.09055v6</link><description>A common method of generalizing binary to multi-class classification is theerror correcting code (ECC). ECCs may be optimized in a number of ways, forinstance by making them orthogonal. Here we test two types of orthogonal ECCson seven different datasets using three types of binary classifier and comparethem with three other multi-class methods: 1 vs. 1, one-versus-the-rest andrandom ECCs. The first type of orthogonal ECC, in which the codes contain nozeros, admits a fast and simple method of solving for the probabilities.Orthogonal ECCs are always more accurate than random ECCs as predicted byrecent literature. Improvments in uncertainty coefficient (U.C.) range between0.4--17.5% (0.004--0.139, absolute), while improvements in Brier score between0.7--10.7%. Unfortunately, orthogonal ECCs are rarely more accurate than 1 vs.1. Disparities are worst when the methods are paired with logistic regression,with orthogonal ECCs never beating 1 vs. 1. When the methods are paired withSVM, the losses are less significant, peaking at 1.5%, relative, 0.011 absolutein uncertainty coefficient and 6.5% in Brier scores. Orthogonal ECCs are alwaysthe fastest of the five multi-class methods when paired with linearclassifiers. When paired with a piecewise linear classifier, whoseclassification speed does not depend on the number of training samples,classifications using orthogonal ECCs were always more accurate than the othermethods and also faster than 1 vs. 1. Losses against 1 vs. 1 here were higher,peaking at 1.9% (0.017, absolute), in U.C. and 39% in Brier score. Gains inspeed ranged between 1.1% and over 100%. Whether the speed increase is worththe penalty in accuracy will depend on the application.</description><author>Peter Mills</author><pubDate>Wed, 17 May 2023 16:54:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1801.09055v6</guid></item><item><title>LeTI: Learning to Generate from Textual Interactions</title><link>http://arxiv.org/abs/2305.10314v1</link><description>Finetuning pre-trained language models (LMs) enhances the models'capabilities. Prior techniques fine-tune a pre-trained LM on input-output pairs(e.g., instruction fine-tuning), or with numerical rewards that gauge thequality of its outputs (e.g., reinforcement learning from human feedback). Weexplore LMs' potential to learn from textual interactions (LeTI) that not onlycheck their correctness with binary labels, but also pinpoint and explainerrors in their outputs through textual feedback. Our investigation focuses onthe code generation task, where the model produces code pieces in response tonatural language instructions. This setting invites a natural and scalable wayto acquire the textual feedback: the error messages and stack traces from codeexecution using a Python interpreter. LeTI iteratively fine-tunes the model,using the LM objective, on a concatenation of natural language instructions,LM-generated programs, and textual feedback, which is only provided when thegenerated program fails to solve the task. Prepended to this fine-tuning text,a binary reward token is used to differentiate correct and buggy solutions. OnMBPP, a code generation dataset, LeTI substantially improves the performance oftwo base LMs of different scales. LeTI requires no ground-truth outputs fortraining and even outperforms a fine-tuned baseline that does. LeTI's strongperformance generalizes to other datasets. Trained on MBPP, it achievescomparable or better performance than the base LMs on unseen problems inHumanEval. Furthermore, compared to binary feedback, we observe that textualfeedback leads to improved generation quality and sample efficiency, achievingthe same performance with fewer than half of the gradient steps. LeTI isequally applicable in natural language tasks when they can be formulated ascode generation, which we empirically verified on event argument extraction.</description><author>Xingyao Wang, Hao Peng, Reyhaneh Jabbarvand, Heng Ji</author><pubDate>Wed, 17 May 2023 16:53:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10314v1</guid></item><item><title>Investigating image-based fallow weed detection performance on Raphanus sativus and Avena sativa at speeds up to 30 km h$^{-1}$</title><link>http://arxiv.org/abs/2305.10311v1</link><description>Site-specific weed control (SSWC) can provide considerable reductions in weedcontrol costs and herbicide usage. Despite the promise of machine vision forSSWC systems and the importance of ground speed in weed control efficacy, therehas been little investigation of the role of ground speed and cameracharacteristics on weed detection performance. Here, we compare the performanceof four camera-software combinations using the open-source OpenWeedLocatorplatform - (1) default settings on a Raspberry Pi HQ camera, (2) optimisedsoftware settings on a HQ camera, (3) optimised software settings on theRaspberry Pi v2 camera, and (4) a global shutter Arducam AR0234 camera - atspeeds ranging from 5 km h$^{-1}$ to 30 km h$^{-1}$. A combined excess green(ExG) and hue, saturation, value (HSV) thresholding algorithm was used fortesting under fallow conditions using tillage radish (Raphanus sativus) andforage oats (Avena sativa) as representative broadleaf and grass weeds,respectively. ARD demonstrated the highest recall among camera systems, with upto 95.7% of weeds detected at 5 km h$^{-1}$ and 85.7% at 30 km h$^{-1}$. HQ1and V2 cameras had the lowest recall of 31.1% and 26.0% at 30 km h$^{-1}$,respectively. All cameras experienced a decrease in recall as speed increased.The highest rate of decrease was observed for HQ1 with 1.12% and 0.90%reductions in recall for every km h$^{-1}$ increase in speed for tillage radishand forage oats, respectively. Detection of the grassy forage oats was worse(P&lt;0.05) than the broadleaved tillage radish for all cameras. Despite thevariations in recall, HQ1, HQ2, and V2 maintained near-perfect precision at alltested speeds. The variable effect of ground speed and camera system ondetection performance of grass and broadleaf weeds, indicates that carefulhardware and software considerations must be made when developing SSWC systems.</description><author>Guy R. Y. Coleman, Angus Macintyre, Michael J. Walsh, William T. Salter</author><pubDate>Wed, 17 May 2023 16:49:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10311v1</guid></item><item><title>MetaModulation: Learning Variational Feature Hierarchies for Few-Shot Learning with Fewer Tasks</title><link>http://arxiv.org/abs/2305.10309v1</link><description>Meta-learning algorithms are able to learn a new task using previouslylearned knowledge, but they often require a large number of meta-training taskswhich may not be readily available. To address this issue, we propose a methodfor few-shot learning with fewer tasks, which we call MetaModulation. The keyidea is to use a neural network to increase the density of the meta-trainingtasks by modulating batch normalization parameters during meta-training.Additionally, we modify parameters at various network levels, rather than justa single layer, to increase task diversity. To account for the uncertaintycaused by the limited training tasks, we propose a variational MetaModulationwhere the modulation parameters are treated as latent variables. We alsointroduce learning variational feature hierarchies by the variationalMetaModulation, which modulates features at all layers and can consider taskuncertainty and generate more diverse tasks. The ablation studies illustratethe advantages of utilizing a learnable task modulation at different levels anddemonstrate the benefit of incorporating probabilistic variants in few-taskmeta-learning. Our MetaModulation and its variational variants consistentlyoutperform state-of-the-art alternatives on four few-task meta-learningbenchmarks.</description><author>Wenfang Sun, Yingjun Du, Xiantong Zhen, Fan Wang, Ling Wang, Cees G. M. Snoek</author><pubDate>Wed, 17 May 2023 16:47:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10309v1</guid></item><item><title>Rethinking Data Augmentation for Tabular Data in Deep Learning</title><link>http://arxiv.org/abs/2305.10308v1</link><description>Tabular data is the most widely used data format in machine learning (ML).While tree-based methods outperform DL-based methods in supervised learning,recent literature reports that self-supervised learning with Transformer-basedmodels outperforms tree-based methods. In the existing literature onself-supervised learning for tabular data, contrastive learning is thepredominant method. In contrastive learning, data augmentation is important togenerate different views. However, data augmentation for tabular data has beendifficult due to the unique structure and high complexity of tabular data. Inaddition, three main components are proposed together in existing methods:model structure, self-supervised learning methods, and data augmentation.Therefore, previous works have compared the performance without comprehensivelyconsidering these components, and it is not clear how each component affectsthe actual performance. In this study, we focus on data augmentation to address these issues. Wepropose a novel data augmentation method, $\textbf{M}$ask $\textbf{T}$oken$\textbf{R}$eplacement ($\texttt{MTR}$), which replaces the mask token with aportion of each tokenized column; $\texttt{MTR}$ takes advantage of theproperties of Transformer, which is becoming the predominant DL-basedarchitecture for tabular data, to perform data augmentation for each columnembedding. Through experiments with 13 diverse public datasets in bothsupervised and self-supervised learning scenarios, we show that $\texttt{MTR}$achieves competitive performance against existing data augmentation methods andimproves model performance. In addition, we discuss specific scenarios in which$\texttt{MTR}$ is most effective and identify the scope of its application. Thecode is available at https://github.com/somaonishi/MTR/.</description><author>Soma Onishi, Shoya Meguro</author><pubDate>Wed, 17 May 2023 16:46:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10308v1</guid></item><item><title>FACE: Evaluating Natural Language Generation with Fourier Analysis of Cross-Entropy</title><link>http://arxiv.org/abs/2305.10307v1</link><description>Measuring the distance between machine-produced and human language isacritical open problem. Inspired by empirical findings from psycholinguisticson theperiodicity of entropy in language, we propose FACE, a set of metricsbased onFourier Analysis of the estimated Cross-Entropy of language, formeasuring thesimilarity between model-generated and human-written languages.Based on anopen-ended generation task and the experimental data from previousstudies, weind that FACE can effectively identify the human-model gap, scaleswith modelsize, reflects the outcomes of different sampling methods fordecoding, correlateswell with other evaluation metrics and with human judgmentscores. FACE iscomputationally efficient and provides intuitiveinterpretations.</description><author>Zuhao Yang, Yingfang Yuan, Yang Xu, Shuo Zhan, Huajun Bai, Kefan Chen</author><pubDate>Wed, 17 May 2023 16:44:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10307v1</guid></item><item><title>UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective</title><link>http://arxiv.org/abs/2305.10306v1</link><description>We propose a new paradigm for universal information extraction (IE) that iscompatible with any schema format and applicable to a list of IE tasks, such asnamed entity recognition, relation extraction, event extraction and sentimentanalysis. Our approach converts the text-based IE tasks as the token-pairproblem, which uniformly disassembles all extraction targets into joint spandetection, classification and association problems with a unified extractiveframework, namely UniEX. UniEX can synchronously encode schema-based prompt andtextual information, and collaboratively learn the generalized knowledge frompre-defined information using the auto-encoder language models. We develop atraffine attention mechanism to integrate heterogeneous factors includingtasks, labels and inside tokens, and obtain the extraction target via a scoringmatrix. Experiment results show that UniEX can outperform generative universalIE models in terms of performance and inference-speed on $14$ benchmarks IEdatasets with the supervised setting. The state-of-the-art performance inlow-resource scenarios also verifies the transferability and effectiveness ofUniEX.</description><author>Junyu Lu, Ping Yang, Ruyi Gan, Junjie Wang, Yuxiang Zhang, Jiaxing Zhang, Pingjian Zhang</author><pubDate>Wed, 17 May 2023 16:44:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10306v1</guid></item><item><title>PromptUNet: Toward Interactive Medical Image Segmentation</title><link>http://arxiv.org/abs/2305.10300v1</link><description>Prompt-based segmentation, also known as interactive segmentation, hasrecently become a popular approach in image segmentation. A well-designedprompt-based model called Segment Anything Model (SAM) has demonstrated itsability to segment a wide range of natural images, which has sparked a lot ofdiscussion in the community. However, recent studies have shown that SAMperforms poorly on medical images. This has motivated us to design a newprompt-based segmentation model specifically for medical image segmentation. Inthis paper, we combine the prompted-based segmentation paradigm with UNet,which is a widly-recognized successful architecture for medical imagesegmentation. We have named the resulting model PromptUNet. In order to adaptthe real-world clinical use, we expand the existing prompt types in SAM toinclude novel Supportive Prompts and En-face Prompts. We have evaluated thecapabilities of PromptUNet on 19 medical image segmentation tasks using avariety of image modalities, including CT, MRI, ultrasound, fundus, anddermoscopic images. Our results show that PromptUNet outperforms a wide rangeof state-of-the-art (SOTA) medical image segmentation methods, includingnnUNet, TransUNet, UNetr, MedSegDiff, and MSA. Code will be released at:https://github.com/WuJunde/PromptUNet.</description><author>Junde Wu</author><pubDate>Wed, 17 May 2023 16:37:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10300v1</guid></item><item><title>Binarized Spectral Compressive Imaging</title><link>http://arxiv.org/abs/2305.10299v1</link><description>Existing deep learning models for hyperspectral image (HSI) reconstructionachieve good performance but require powerful hardwares with enormous memoryand computational resources. Consequently, these methods can hardly be deployedon resource-limited mobile devices. In this paper, we propose a novel method,Binarized Spectral-Redistribution Network (BiSRNet), for efficient andpractical HSI restoration from compressed measurement in snapshot compressiveimaging (SCI) systems. Firstly, we redesign a compact and easy-to-deploy basemodel to be binarized. Then we present the basic unit, BinarizedSpectral-Redistribution Convolution (BiSR-Conv). BiSR-Conv can adaptivelyredistribute the HSI representations before binarizing activation and uses ascalable hyperbolic tangent function to closer approximate the Sign function inbackpropagation. Based on our BiSR-Conv, we customize four binarizedconvolutional modules to address the dimension mismatch and propagatefull-precision information throughout the whole network. Finally, our BiSRNetis derived by using the proposed techniques to binarize the base model.Comprehensive quantitative and qualitative experiments manifest that ourproposed BiSRNet outperforms state-of-the-art binarization methods and achievescomparable performance with full-precision algorithms. Code and models will bereleased at https://github.com/caiyuanhao1998/BiSCI andhttps://github.com/caiyuanhao1998/MST</description><author>Yuanhao Cai, Yuxin Zheng, Jing Lin, Haoqian Wang, Xin Yuan, Yulun Zhang</author><pubDate>Wed, 17 May 2023 16:36:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10299v1</guid></item><item><title>Estimation of Remaining Useful Life and SOH of Lithium Ion Batteries (For EV Vehicles)</title><link>http://arxiv.org/abs/2305.10298v1</link><description>Lithium-ion batteries are widely used in various applications, includingportable electronic devices, electric vehicles, and renewable energy storagesystems. Accurately estimating the remaining useful life of these batteries iscrucial for ensuring their optimal performance, preventing unexpected failures,and reducing maintenance costs. In this paper, we present a comprehensivereview of the existing approaches for estimating the remaining useful life oflithium-ion batteries, including data-driven methods, physics-based models, andhybrid approaches. We also propose a novel approach based on machine learningtechniques for accurately predicting the remaining useful life of lithium-ionbatteries. Our approach utilizes various battery performance parameters,including voltage, current, and temperature, to train a predictive model thatcan accurately estimate the remaining useful life of the battery. We evaluatethe performance of our approach on a dataset of lithium-ion battery cycles andcompare it with other state-of-the-art methods. The results demonstrate theeffectiveness of our proposed approach in accurately estimating the remaininguseful life of lithium-ion batteries.</description><author>Ganesh Kumar</author><pubDate>Wed, 17 May 2023 16:35:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10298v1</guid></item><item><title>Growing Steerable Neural Cellular Automata</title><link>http://arxiv.org/abs/2302.10197v2</link><description>Neural Cellular Automata (NCA) models have shown remarkable capacity forpattern formation and complex global behaviors stemming from localcoordination. However, in the original implementation of NCA, cells areincapable of adjusting their own orientation, and it is the responsibility ofthe model designer to orient them externally. A recent isotropic variant of NCA(Growing Isotropic Neural Cellular Automata) makes the modelorientation-independent - cells can no longer tell up from down, nor left fromright - by removing its dependency on perceiving the gradient of spatial statesin its neighborhood. In this work, we revisit NCA with a different approach: wemake each cell responsible for its own orientation by allowing it to "turn" asdetermined by an adjustable internal state. The resulting Steerable NCAcontains cells of varying orientation embedded in the same pattern. We observehow, while Isotropic NCA are orientation-agnostic, Steerable NCA havechirality: they have a predetermined left-right symmetry. We therefore showthat we can train Steerable NCA in similar but simpler ways than theirIsotropic variant by: (1) breaking symmetries using only two seeds, or (2)introducing a rotation-invariant training objective and relying on asynchronouscell updates to break the up-down symmetry of the system.</description><author>Ettore Randazzo, Alexander Mordvintsev, Craig Fouts</author><pubDate>Wed, 17 May 2023 16:34:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10197v2</guid></item><item><title>A Generic Approach to Integrating Time into Spatial-Temporal Forecasting via Conditional Neural Fields</title><link>http://arxiv.org/abs/2305.06827v2</link><description>Self-awareness is the key capability of autonomous systems, e.g., autonomousdriving network, which relies on highly efficient time series forecastingalgorithm to enable the system to reason about the future state of theenvironment, as well as its effect on the system behavior as time progresses.Recently, a large number of forecasting algorithms using either convolutionalneural networks or graph neural networks have been developed to exploit thecomplex temporal and spatial dependencies present in the time series. Whilethese solutions have shown significant advantages over statistical approaches,one open question is to effectively incorporate the global information whichrepresents the seasonality patterns via the time component of time series intothe forecasting models to improve their accuracy. This paper presents a generalapproach to integrating the time component into forecasting models. The mainidea is to employ conditional neural fields to represent the auxiliary featuresextracted from the time component to obtain the global information, which willbe effectively combined with the local information extracted fromautoregressive neural networks through a layer-wise gated fusion module.Extensive experiments on road traffic and cellular network traffic datasetsprove the effectiveness of the proposed approach.</description><author>Minh-Thanh Bui, Duc-Thinh Ngo, Demin Lu, Zonghua Zhang</author><pubDate>Wed, 17 May 2023 16:29:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.06827v2</guid></item><item><title>DualFL: A Duality-based Federated Learning Algorithm with Communication Acceleration in the General Convex Regime</title><link>http://arxiv.org/abs/2305.10294v1</link><description>We propose a novel training algorithm called DualFL (Dualized FederatedLearning), for solving a distributed optimization problem in federatedlearning. Our approach is based on a specific dual formulation of the federatedlearning problem. DualFL achieves communication acceleration under varioussettings on smoothness and strong convexity of the problem. Moreover, ittheoretically guarantees the use of inexact local solvers, preserving itsoptimal communication complexity even with inexact local solutions. DualFL isthe first federated learning algorithm that achieves communicationacceleration, even when the cost function is either nonsmooth or non-stronglyconvex. Numerical results demonstrate that the practical performance of DualFLis comparable to those of state-of-the-art federated learning algorithms, andit is robust with respect to hyperparameter tuning.</description><author>Jongho Park, Jinchao Xu</author><pubDate>Wed, 17 May 2023 16:29:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10294v1</guid></item><item><title>Deep Unfolding of the DBFB Algorithm with Application to ROI CT Imaging with Limited Angular Density</title><link>http://arxiv.org/abs/2209.13264v3</link><description>This paper presents a new method for reconstructing regions of interest (ROI)from a limited number of computed tomography (CT) measurements. Classicalmodel-based iterative reconstruction methods lead to images with predictablefeatures. Still, they often suffer from tedious parameterization and slowconvergence. On the contrary, deep learning methods are fast, and they canreach high reconstruction quality by leveraging information from largedatasets, but they lack interpretability. At the crossroads of both methods,deep unfolding networks have been recently proposed. Their design includes thephysics of the imaging system and the steps of an iterative optimizationalgorithm. Motivated by the success of these networks for various applications,we introduce an unfolding neural network called U-RDBFB designed for ROI CTreconstruction from limited data. Few-view truncated data are effectivelyhandled thanks to a robust non-convex data fidelity term combined with asparsity-inducing regularization function. We unfold the Dual Block coordinateForward-Backward (DBFB) algorithm, embedded in an iterative reweighted scheme,allowing the learning of key parameters in a supervised manner. Our experimentsshow an improvement over several state-of-the-art methods, including amodel-based iterative scheme, a multi-scale deep learning architecture, andother deep unfolding methods.</description><author>Marion Savanier, Emilie Chouzenoux, Jean-Christophe Pesquet, Cyril Riddell</author><pubDate>Wed, 17 May 2023 16:27:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.13264v3</guid></item><item><title>Infinite Class Mixup</title><link>http://arxiv.org/abs/2305.10293v1</link><description>Mixup is a widely adopted strategy for training deep networks, whereadditional samples are augmented by interpolating inputs and labels of trainingpairs. Mixup has shown to improve classification performance, networkcalibration, and out-of-distribution generalisation. While effective, acornerstone of Mixup, namely that networks learn linear behaviour patternsbetween classes, is only indirectly enforced since the output interpolation isperformed at the probability level. This paper seeks to address this limitationby mixing the classifiers directly instead of mixing the labels for each mixedpair. We propose to define the target of each augmented sample as a uniquelynew classifier, whose parameters are a linear interpolation of the classifiervectors of the input pair. The space of all possible classifiers is continuousand spans all interpolations between classifier pairs. To make optimisationtractable, we propose a dual-contrastive Infinite Class Mixup loss, where wecontrast the classifier of a mixed pair to both the classifiers and thepredicted outputs of other mixed pairs in a batch. Infinite Class Mixup isgeneric in nature and applies to many variants of Mixup. Empirically, we showthat it outperforms standard Mixup and variants such as RegMixup and Remix onbalanced, long-tailed, and data-constrained benchmarks, highlighting its broadapplicability.</description><author>Thomas Mensink, Pascal Mettes</author><pubDate>Wed, 17 May 2023 16:27:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10293v1</guid></item><item><title>Linear Query Approximation Algorithms for Non-monotone Submodular Maximization under Knapsack Constraint</title><link>http://arxiv.org/abs/2305.10292v1</link><description>This work, for the first time, introduces two constant factor approximationalgorithms with linear query complexity for non-monotone submodularmaximization over a ground set of size $n$ subject to a knapsack constraint,$\mathsf{DLA}$ and $\mathsf{RLA}$. $\mathsf{DLA}$ is a deterministic algorithmthat provides an approximation factor of $6+\epsilon$ while $\mathsf{RLA}$ is arandomized algorithm with an approximation factor of $4+\epsilon$. Both run in$O(n \log(1/\epsilon)/\epsilon)$ query complexity. The key idea to obtain aconstant approximation ratio with linear query lies in: (1) dividing the groundset into two appropriate subsets to find the near-optimal solution over thesesubsets with linear queries, and (2) combining a threshold greedy withproperties of two disjoint sets or a random selection process to improvesolution quality. In addition to the theoretical analysis, we have evaluatedour proposed solutions with three applications: Revenue Maximization, ImageSummarization, and Maximum Weighted Cut, showing that our algorithms not onlyreturn comparative results to state-of-the-art algorithms but also requiresignificantly fewer queries.</description><author>Canh V. Pham, Tan D. Tran, Dung T. K. Ha, My T. Thai</author><pubDate>Wed, 17 May 2023 16:27:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10292v1</guid></item><item><title>Explain Any Concept: Segment Anything Meets Concept-Based Explanation</title><link>http://arxiv.org/abs/2305.10289v1</link><description>EXplainable AI (XAI) is an essential topic to improve human understanding ofdeep neural networks (DNNs) given their black-box internals. For computervision tasks, mainstream pixel-based XAI methods explain DNN decisions byidentifying important pixels, and emerging concept-based XAI explore formingexplanations with concepts (e.g., a head in an image). However, pixels aregenerally hard to interpret and sensitive to the imprecision of XAI methods,whereas "concepts" in prior works require human annotation or are limited topre-defined concept sets. On the other hand, driven by large-scalepre-training, Segment Anything Model (SAM) has been demonstrated as a powerfuland promotable framework for performing precise and comprehensive instancesegmentation, enabling automatic preparation of concept sets from a givenimage. This paper for the first time explores using SAM to augmentconcept-based XAI. We offer an effective and flexible concept-based explanationmethod, namely Explain Any Concept (EAC), which explains DNN decisions with anyconcept. While SAM is highly effective and offers an "out-of-the-box" instancesegmentation, it is costly when being integrated into defacto XAI pipelines. Wethus propose a lightweight per-input equivalent (PIE) scheme, enablingefficient explanation with a surrogate model. Our evaluation over two populardatasets (ImageNet and COCO) illustrate the highly encouraging performance ofEAC over commonly-used XAI methods.</description><author>Ao Sun, Pingchuan Ma, Yuanyuan Yuan, Shuai Wang</author><pubDate>Wed, 17 May 2023 16:26:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10289v1</guid></item><item><title>Global-Local Stepwise Generative Network for Ultra High-Resolution Image Restoration</title><link>http://arxiv.org/abs/2207.08808v2</link><description>While the research on image background restoration from regular size ofdegraded images has achieved remarkable progress, restoring ultrahigh-resolution (e.g., 4K) images remains an extremely challenging task due tothe explosion of computational complexity and memory usage, as well as thedeficiency of annotated data. In this paper we present a novel model for ultrahigh-resolution image restoration, referred to as the Global-Local StepwiseGenerative Network (GLSGN), which employs a stepwise restoring strategyinvolving four restoring pathways: three local pathways and one global pathway.The local pathways focus on conducting image restoration in a fine-grainedmanner over local but high-resolution image patches, while the global pathwayperforms image restoration coarsely on the scale-down but intact image toprovide cues for the local pathways in a global view including semantics andnoise patterns. To smooth the mutual collaboration between these four pathways,our GLSGN is designed to ensure the inter-pathway consistency in four aspectsin terms of low-level content, perceptual attention, restoring intensity andhigh-level semantics, respectively. As another major contribution of this work,we also introduce the first ultra high-resolution dataset to date for bothreflection removal and rain streak removal, comprising 4,670 real-world andsynthetic images. Extensive experiments across three typical tasks for imagebackground restoration, including image reflection removal, image rain streakremoval and image dehazing, show that our GLSGN consistently outperformsstate-of-the-art methods.</description><author>Xin Feng, Haobo Ji, Wenjie Pei, Fanglin Chen, Guangming Lu</author><pubDate>Wed, 17 May 2023 16:24:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.08808v2</guid></item><item><title>Balancing Utility and Fairness in Submodular Maximization (Technical Report)</title><link>http://arxiv.org/abs/2211.00980v2</link><description>Submodular function maximization is a fundamental combinatorial optimizationproblem with plenty of applications -- including data summarization, influencemaximization, and recommendation. In many of these problems, the goal is tofind a solution that maximizes the average utility over all users, for each ofwhom the utility is defined by a monotone submodular function. However, whenthe population of users is composed of several demographic groups, anothercritical problem is whether the utility is fairly distributed across differentgroups. Although the \emph{utility} and \emph{fairness} objectives are bothdesirable, they might contradict each other, and, to the best of our knowledge,little attention has been paid to optimizing them jointly. In this paper, we propose a new problem called \emph{Bicriteria SubmodularMaximization} (BSM) to strike a balance between utility and fairness.Specifically, it requires finding a fixed-size solution to maximize the utilityfunction, subject to the value of the fairness function not being below athreshold. Since BSM is inapproximable within any constant factor in general,we turn our attention to designing instance-dependent approximation schemes.Our algorithmic proposal comprises two methods, with different approximationfactors, obtained by converting a BSM instance into other submodularoptimization problem instances. Using real-world and synthetic datasets, weshowcase applications of our methods in three submodular maximization problems:maximum coverage, influence maximization, and facility location.</description><author>Yanhao Wang, Yuchen Li, Francesco Bonchi, Ying Wang</author><pubDate>Wed, 17 May 2023 16:24:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.00980v2</guid></item><item><title>Towards More Robust NLP System Evaluation: Handling Missing Scores in Benchmarks</title><link>http://arxiv.org/abs/2305.10284v1</link><description>The evaluation of natural language processing (NLP) systems is crucial foradvancing the field, but current benchmarking approaches often assume that allsystems have scores available for all tasks, which is not always practical. Inreality, several factors such as the cost of running baseline, private systems,computational limitations, or incomplete data may prevent some systems frombeing evaluated on entire tasks. This paper formalize an existing problem inNLP research: benchmarking when some systems scores are missing on the task,and proposes a novel approach to address it. Our method utilizes a compatiblepartial ranking approach to impute missing data, which is then aggregated usingthe Borda count method. It includes two refinements designed specifically forscenarios where either task-level or instance-level scores are available. Wealso introduce an extended benchmark, which contains over 131 million scores,an order of magnitude larger than existing benchmarks. We validate our methodsand demonstrate their effectiveness in addressing the challenge of missingsystem evaluation on an entire task. This work highlights the need for morecomprehensive benchmarking approaches that can handle real-world scenarioswhere not all systems are evaluated on the entire task.</description><author>Anas Himmi, Ekhine Irurozki, Nathan Noiry, Stephan Clemencon, Pierre Colombo</author><pubDate>Wed, 17 May 2023 16:20:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10284v1</guid></item><item><title>Asymptotics of Network Embeddings Learned via Subsampling</title><link>http://arxiv.org/abs/2107.02363v4</link><description>Network data are ubiquitous in modern machine learning, with tasks ofinterest including node classification, node clustering and link prediction. Afrequent approach begins by learning an Euclidean embedding of the network, towhich algorithms developed for vector-valued data are applied. For largenetworks, embeddings are learned using stochastic gradient methods where thesub-sampling scheme can be freely chosen. Despite the strong empiricalperformance of such methods, they are not well understood theoretically. Ourwork encapsulates representation methods using a subsampling approach, such asnode2vec, into a single unifying framework. We prove, under the assumption thatthe graph is exchangeable, that the distribution of the learned embeddingvectors asymptotically decouples. Moreover, we characterize the asymptoticdistribution and provided rates of convergence, in terms of the latentparameters, which includes the choice of loss function and the embeddingdimension. This provides a theoretical foundation to understand what theembedding vectors represent and how well these methods perform on downstreamtasks. Notably, we observe that typically used loss functions may lead toshortcomings, such as a lack of Fisher consistency.</description><author>Andrew Davison, Morgane Austern</author><pubDate>Wed, 17 May 2023 16:18:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.02363v4</guid></item><item><title>Reward-agnostic Fine-tuning: Provable Statistical Benefits of Hybrid Reinforcement Learning</title><link>http://arxiv.org/abs/2305.10282v1</link><description>This paper studies tabular reinforcement learning (RL) in the hybrid setting,which assumes access to both an offline dataset and online interactions withthe unknown environment. A central question boils down to how to efficientlyutilize online data collection to strengthen and complement the offline datasetand enable effective policy fine-tuning. Leveraging recent advances inreward-agnostic exploration and model-based offline RL, we design a three-stagehybrid RL algorithm that beats the best of both worlds -- pure offline RL andpure online RL -- in terms of sample complexities. The proposed algorithm doesnot require any reward information during data collection. Our theory isdeveloped based on a new notion called single-policy partial concentrability,which captures the trade-off between distribution mismatch and miscoverage andguides the interplay between offline and online data.</description><author>Gen Li, Wenhao Zhan, Jason D. Lee, Yuejie Chi, Yuxin Chen</author><pubDate>Wed, 17 May 2023 16:17:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10282v1</guid></item><item><title>The emergence of clusters in self-attention dynamics</title><link>http://arxiv.org/abs/2305.05465v2</link><description>Viewing Transformers as interacting particle systems, we describe thegeometry of learned representations when the weights are not time dependent. Weshow that particles, representing tokens, tend to cluster toward particularlimiting objects as time tends to infinity. Cluster locations are determined bythe initial tokens, confirming context-awareness of representations learned byTransformers. Using techniques from dynamical systems and partial differentialequations, we show that the type of limiting object that emerges depends on thespectrum of the value matrix. Additionally, in the one-dimensional case weprove that the self-attention matrix converges to a low-rank Boolean matrix.The combination of these results mathematically confirms the empiricalobservation made by Vaswani et al. [VSP'17] that leaders appear in a sequenceof tokens when processed by Transformers.</description><author>Borjan Geshkovski, Cyril Letrouit, Yury Polyanskiy, Philippe Rigollet</author><pubDate>Wed, 17 May 2023 16:16:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05465v2</guid></item><item><title>Gaussian processes at the Helm(holtz): A more fluid model for ocean currents</title><link>http://arxiv.org/abs/2302.10364v2</link><description>Oceanographers are interested in predicting ocean currents and identifyingdivergences in a current vector field based on sparse observations of buoyvelocities. Since we expect current velocity to be a continuous but highlynon-linear function of spatial location, Gaussian processes (GPs) offer anattractive model. But we show that applying a GP with a standard stationarykernel directly to buoy data can struggle at both current prediction anddivergence identification -- due to some physically unrealistic priorassumptions. To better reflect known physical properties of currents, wepropose to instead put a standard stationary kernel on the divergence andcurl-free components of a vector field obtained through a Helmholtzdecomposition. We show that, because this decomposition relates to the originalvector field just via mixed partial derivatives, we can still perform inferencegiven the original data with only a small constant multiple of additionalcomputational expense. We illustrate the benefits of our method on syntheticand real ocean data.</description><author>Renato Berlinghieri, Brian L. Trippe, David R. Burt, Ryan Giordano, Kaushik Srinivasan, Tamay Özgökmen, Junfei Xia, Tamara Broderick</author><pubDate>Wed, 17 May 2023 16:16:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10364v2</guid></item><item><title>Stochastic Causal Programming for Bounding Treatment Effects</title><link>http://arxiv.org/abs/2202.10806v4</link><description>Causal effect estimation is important for many tasks in the natural andsocial sciences. We design algorithms for the continuous partial identificationproblem: bounding the effects of multivariate, continuous treatments whenunmeasured confounding makes identification impossible. Specifically, we castcausal effects as objective functions within a constrained optimizationproblem, and minimize/maximize these functions to obtain bounds. We combineflexible learning algorithms with Monte Carlo methods to implement a family ofsolutions under the name of stochastic causal programming. In particular, weshow how the generic framework can be efficiently formulated in settings whereauxiliary variables are clustered into pre-treatment and post-treatment sets,where no fine-grained causal graph can be easily specified. In these settings,we can avoid the need for fully specifying the distribution family of hiddencommon causes. Monte Carlo computation is also much simplified, leading toalgorithms which are more computationally stable against alternatives.</description><author>Kirtan Padh, Jakob Zeitler, David Watson, Matt Kusner, Ricardo Silva, Niki Kilbertus</author><pubDate>Wed, 17 May 2023 16:14:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.10806v4</guid></item><item><title>One Fits All:Power General Time Series Analysis by Pretrained LM</title><link>http://arxiv.org/abs/2302.11939v2</link><description>Although we have witnessed great success of pre-trained models in naturallanguage processing (NLP) and computer vision (CV), limited progress has beenmade for general time series analysis. Unlike NLP and CV where a unified modelcan be used to perform different tasks, specially designed approach stilldominates in each time series analysis task such as classification, anomalydetection, forecasting, and few-shot learning. The main challenge that blocksthe development of pre-trained model for time series analysis is the lack of alarge amount of data for training. In this work, we address this challenge byleveraging language or CV models, pre-trained from billions of tokens, for timeseries analysis. Specifically, we refrain from altering the self-attention andfeedforward layers of the residual blocks in the pre-trained language or imagemodel. This model, known as the Frozen Pretrained Transformer (FPT), isevaluated through fine-tuning on all major types of tasks involving timeseries. Our results demonstrate that pre-trained models on natural language orimages can lead to a comparable or state-of-the-art performance in all maintime series analysis tasks, as illustrated in Figure~\ref{fig:representation}.We also found both theoretically and empirically that the self-attention modulebehaviors similarly to principle component analysis (PCA), an observation thathelps explains how transformer bridges the domain gap and a crucial steptowards understanding the universality of a pre-trained transformer. The codeis publicly available athttps://anonymous.4open.science/r/Pretrained-LM-for-TSForcasting-C561.</description><author>Tian Zhou, PeiSong Niu, Xue Wang, Liang Sun, Rong Jin</author><pubDate>Wed, 17 May 2023 16:14:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.11939v2</guid></item><item><title>Compact Optimization Learning for AC Optimal Power Flow</title><link>http://arxiv.org/abs/2301.08840v3</link><description>This paper reconsiders end-to-end learning approaches to the Optimal PowerFlow (OPF). Existing methods, which learn the input/output mapping of the OPF,suffer from scalability issues due to the high dimensionality of the outputspace. This paper first shows that the space of optimal solutions can besignificantly compressed using principal component analysis (PCA). It thenproposes Compact Learning, a new method that learns in a subspace of theprincipal components before translating the vectors into the original outputspace. This compression reduces the number of trainable parameterssubstantially, improving scalability and effectiveness. Compact Learning isevaluated on a variety of test cases from the PGLib with up to 30,000 buses.The paper also shows that the output of Compact Learning can be used towarm-start an exact AC solver to restore feasibility, while bringingsignificant speed-ups.</description><author>Seonho Park, Wenbo Chen, Terrence W. K. Mak, Pascal Van Hentenryck</author><pubDate>Wed, 17 May 2023 16:13:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.08840v3</guid></item><item><title>FedRC: Tackling Diverse Distribution Shifts Challenge in Federated Learning by Robust Clustering</title><link>http://arxiv.org/abs/2301.12379v2</link><description>Federated Learning (FL) is a machine learning paradigm that safeguardsprivacy by retaining client data on edge devices. However, optimizing FL inpractice can be challenging due to the diverse and heterogeneous nature of thelearning system. Though recent research has focused on improving theoptimization of FL when distribution shifts occur among clients, ensuringglobal performance when multiple types of distribution shifts occursimultaneously among clients -- such as feature distribution shift, labeldistribution shift, and concept shift -- remain under-explored. In this paper, we identify the learning challenges posed by the simultaneousoccurrence of diverse distribution shifts and propose a clustering principle toovercome these challenges. Through our research, we find that existing methodsfailed to address the clustering principle. Therefore, we propose a novelclustering algorithm framework, dubbed as FedRC, which adheres to our proposedclustering principle by incorporating a bi-level optimization problem and anovel objective function. Extensive experiments demonstrate that FedRCsignificantly outperforms other SOTA cluster-based FL methods. Our code will bepublicly available.</description><author>Yongxin Guo, Xiaoying Tang, Tao Lin</author><pubDate>Wed, 17 May 2023 16:12:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12379v2</guid></item><item><title>Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models</title><link>http://arxiv.org/abs/2305.10276v1</link><description>In this paper, we take the initiative to investigate the performance of LLMson complex planning tasks that require LLMs to understand a virtual spatialenvironment simulated via natural language and act correspondingly in text. Wepropose a benchmark named Natural Language Planning (NLP) composed of a set ofnovel tasks: Brick World, NLVR-based Manipulations, and Natural LanguageNavigation. We found that current popular LLMs such as ChatGPT still lackabilities in complex planning. This arises a question -- do the LLMs have agood understanding of the environments described in natural language, or maybeother alternatives such as symbolic representations are neater and hence betterto be understood by LLMs? To this end, we propose a novel method called CoS(Chain-of-Symbol Prompting) that represents the complex environments withcondensed symbolic spatial representations during the chained intermediatethinking steps. CoS is easy to use and does not need additional training onLLMs. Extensive experiments indicate that CoS clearly surpasses the performanceof the Chain-of-Thought (CoT) Prompting in all three planning tasks with evenfewer tokens used in the inputs compared with CoT on ChatGPT and InstructGPT.The performance gain is strong, by up to 60.8% accuracy (from 31.8% to 92.6%)on Brick World for ChatGPT. CoS also reduces the number of tokens in the promptobviously, by up to 65.8% of the tokens (from 407 to 139) for the intermediatesteps from demonstrations on Brick World.</description><author>Hanxu Hu, Hongyuan Lu, Huajian Zhang, Wai Lam, Yue Zhang</author><pubDate>Wed, 17 May 2023 16:07:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10276v1</guid></item><item><title>Large-Scale Package Manipulation via Learned Metrics of Pick Success</title><link>http://arxiv.org/abs/2305.10272v1</link><description>Automating warehouse operations can reduce logistics overhead costs,ultimately driving down the final price for consumers, increasing the speed ofdelivery, and enhancing the resiliency to workforce fluctuations. The past fewyears have seen increased interest in automating such repeated tasks but mostlyin controlled settings. Tasks such as picking objects from unstructured,cluttered piles have only recently become robust enough for large-scaledeployment with minimal human intervention. This paper demonstrates a large-scale package manipulation from unstructuredpiles in Amazon Robotics' Robot Induction (Robin) fleet, which utilizes a picksuccess predictor trained on real production data. Specifically, the system wastrained on over 394K picks. It is used for singulating up to 5~million packagesper day and has manipulated over 200~million packages during this paper'sevaluation period. The developed learned pick quality measure ranks various pick alternatives inreal-time and prioritizes the most promising ones for execution. The picksuccess predictor aims to estimate from prior experience the successprobability of a desired pick by the deployed industrial robotic arms incluttered scenes containing deformable and rigid objects with partially knownproperties. It is a shallow machine learning model, which allows us to evaluatewhich features are most important for the prediction. An online pick rankerleverages the learned success predictor to prioritize the most promising picksfor the robotic arm, which are then assessed for collision avoidance. Thislearned ranking process is demonstrated to overcome the limitations andoutperform the performance of manually engineered and heuristic alternatives. To the best of the authors' knowledge, this paper presents the firstlarge-scale deployment of learned pick quality estimation methods in a realproduction system.</description><author>Shuai Li, Azarakhsh Keipour, Kevin Jamieson, Nicolas Hudson, Charles Swan, Kostas Bekris</author><pubDate>Wed, 17 May 2023 16:03:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10272v1</guid></item><item><title>Releasing Inequality Phenomena in $L_{\infty}$-Adversarial Training via Input Gradient Distillation</title><link>http://arxiv.org/abs/2305.09305v2</link><description>Since adversarial examples appeared and showed the catastrophic degradationthey brought to DNN, many adversarial defense methods have been devised, amongwhich adversarial training is considered the most effective. However, a recentwork showed the inequality phenomena in $l_{\infty}$-adversarial training andrevealed that the $l_{\infty}$-adversarially trained model is vulnerable when afew important pixels are perturbed by i.i.d. noise or occluded. In this paper,we propose a simple yet effective method called Input Gradient Distillation(IGD) to release the inequality phenomena in $l_{\infty}$-adversarial training.Experiments show that while preserving the model's adversarial robustness,compared to PGDAT, IGD decreases the $l_{\infty}$-adversarially trained model'serror rate to inductive noise and inductive occlusion by up to 60\% and16.53\%, and to noisy images in Imagenet-C by up to 21.11\%. Moreover, weformally explain why the equality of the model's saliency map can improve suchrobustness.</description><author>Junxi Chen, Junhao Dong, Xiaohua Xie</author><pubDate>Wed, 17 May 2023 16:03:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.09305v2</guid></item><item><title>Boosting Local Spectro-Temporal Features for Speech Analysis</title><link>http://arxiv.org/abs/2305.10270v1</link><description>We introduce the problem of phone classification in the context of speechrecognition, and explore several sets of local spectro-temporal features thatcan be used for phone classification. In particular, we present somepreliminary results for phone classification using two sets of features thatare commonly used for object detection: Haar features and SVM-classifiedHistograms of Gradients (HoG)</description><author>Michael Guerzhoy</author><pubDate>Wed, 17 May 2023 16:02:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10270v1</guid></item><item><title>State Representation Learning Using an Unbalanced Atlas</title><link>http://arxiv.org/abs/2305.10267v1</link><description>The manifold hypothesis posits that high-dimensional data often lies on alower-dimensional manifold and that utilizing this manifold as the target spaceyields more efficient representations. While numerous traditionalmanifold-based techniques exist for dimensionality reduction, their applicationin self-supervised learning has witnessed slow progress. The recent MSIMCLRmethod combines manifold encoding with SimCLR but requires extremely low targetencoding dimensions to outperform SimCLR, limiting its applicability. Thispaper introduces a novel learning paradigm using an unbalanced atlas (UA),capable of surpassing state-of-the-art self-supervised learning approaches. Wemeticulously investigated and engineered the DeepInfomax with an unbalancedatlas (DIM-UA) method by systematically adapting the Spatiotemporal DeepInfomax(ST-DIM) framework to align with our proposed UA paradigm, employing rigorousscientific methodologies throughout the process. The efficacy of DIM-UA isdemonstrated through training and evaluation on the Atari Annotated RAMInterface (AtariARI) benchmark, a modified version of the Atari 2600 frameworkthat produces annotated image samples for representation learning. The UAparadigm improves the existing algorithm significantly when the number oftarget encoding dimensions grows. For instance, the mean F1 score averaged overcategories of DIM-UA is ~75% compared to ~70% of ST-DIM when using 16384 hiddenunits.</description><author>Li Meng, Morten Goodwin, Anis Yazidi, Paal Engelstad</author><pubDate>Wed, 17 May 2023 15:58:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10267v1</guid></item><item><title>Searching for Needles in a Haystack: On the Role of Incidental Bilingualism in PaLM's Translation Capability</title><link>http://arxiv.org/abs/2305.10266v1</link><description>Large, multilingual language models exhibit surprisingly good zero- orfew-shot machine translation capabilities, despite having never seen theintentionally-included translation examples provided to typical neuraltranslation systems. We investigate the role of incidental bilingualism -- theunintentional consumption of bilingual signals, including translation examples-- in explaining the translation capabilities of large language models, takingthe Pathways Language Model (PaLM) as a case study. We introduce a mixed-methodapproach to measure and understand incidental bilingualism at scale. We showthat PaLM is exposed to over 30 million translation pairs across at least 44languages. Furthermore, the amount of incidental bilingual content is highlycorrelated with the amount of monolingual in-language content for non-Englishlanguages. We relate incidental bilingual content to zero-shot prompts and showthat it can be used to mine new prompts to improve PaLM's out-of-Englishzero-shot translation quality. Finally, in a series of small-scale ablations,we show that its presence has a substantial impact on translation capabilities,although this impact diminishes with model scale.</description><author>Eleftheria Briakou, Colin Cherry, George Foster</author><pubDate>Wed, 17 May 2023 15:58:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10266v1</guid></item><item><title>M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models</title><link>http://arxiv.org/abs/2305.10263v1</link><description>Large language models have recently made tremendous progress in a variety ofaspects, e.g., cross-task generalization, instruction following.Comprehensively evaluating the capability of large language models in multipletasks is of great importance. In this paper, we propose M3KE, a MassiveMulti-Level Multi-Subject Knowledge Evaluation benchmark, which is developed tomeasure knowledge acquired by Chinese large language models by testing theirmultitask accuracy in zero- and few-shot settings. We have collected 20,477questions from 71 tasks. Our selection covers all major levels of Chineseeducation system, ranging from the primary school to college, as well as a widevariety of subjects, including humanities, history, politics, law, education,psychology, science, technology, art and religion. All questions aremultiple-choice questions with four options, hence guaranteeing a standardizedand unified assessment process. We've assessed a number of state-of-the-artopen-source Chinese large language models on the proposed benchmark. The sizeof these models varies from 335M to 130B parameters. Experiment resultsdemonstrate that they perform significantly worse than GPT-3.5 that reaches anaccuracy of ~ 48% on M3KE. The dataset is available athttps://github.com/tjunlp-lab/M3KE.</description><author>Chuang Liu, Renren Jin, Yuqi Ren, Linhao Yu, Tianyu Dong, Xiaohan Peng, Shuting Zhang, Jianxiang Peng, Peiyi Zhang, Qingqing Lyu, Xiaowen Su, Qun Liu, Deyi Xiong</author><pubDate>Wed, 17 May 2023 15:56:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10263v1</guid></item><item><title>$π$-Tuning: Transferring Multimodal Foundation Models with Optimal Multi-task Interpolation</title><link>http://arxiv.org/abs/2304.14381v3</link><description>Foundation models have achieved great advances in multi-task learning with aunified interface of unimodal and multimodal tasks. However, the potential ofsuch multi-task learners has not been exploited during transfer learning. Inthis work, we present a universal parameter-efficient transfer learning method,termed Predict-Interpolate Tuning ($\pi$-Tuning), for vision, language, andvision-language tasks. It aggregates the parameters of lightweighttask-specific experts learned from similar tasks to aid the target downstreamtask. The task similarities are predicted in a unified modality-independentspace, yielding a scalable graph to demonstrate task relationships.$\pi$-Tuning has several appealing benefits. First, it flexibly explores bothintra- and inter-modal transferability between similar tasks to improve theaccuracy and robustness of transfer learning, especially in data-scarcescenarios. Second, it offers a systematical solution for transfer learning withmulti-task prediction-and-then-interpolation, compatible with diverse types ofparameter-efficient experts, such as prompt and adapter. Third, an extensivestudy of task-level mutual benefits on 14 unimodal and 6 multimodal datasetsshows that $\pi$-Tuning surpasses fine-tuning and other parameter-efficienttransfer learning methods both in full-shot and low-shot regimes. The taskgraph also enables an in-depth interpretable analysis of task transferabilityacross modalities. The code will be available athttps://github.com/TencentARC/pi-Tuning.</description><author>Chengyue Wu, Teng Wang, Yixiao Ge, Zeyu Lu, Ruisong Zhou, Ying Shan, Ping Luo</author><pubDate>Wed, 17 May 2023 15:53:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14381v3</guid></item><item><title>From Region to Patch: Attribute-Aware Foreground-Background Contrastive Learning for Fine-Grained Fashion Retrieval</title><link>http://arxiv.org/abs/2305.10260v1</link><description>Attribute-specific fashion retrieval (ASFR) is a challenging informationretrieval task, which has attracted increasing attention in recent years.Different from traditional fashion retrieval which mainly focuses on optimizingholistic similarity, the ASFR task concentrates on attribute-specificsimilarity, resulting in more fine-grained and interpretable retrieval results.As the attribute-specific similarity typically corresponds to the specificsubtle regions of images, we propose a Region-to-Patch Framework (RPF) thatconsists of a region-aware branch and a patch-aware branch to extractfine-grained attribute-related visual features for precise retrieval in acoarse-to-fine manner. In particular, the region-aware branch is first to beutilized to locate the potential regions related to the semantic of the givenattribute. Then, considering that the located region is coarse and stillcontains the background visual contents, the patch-aware branch is proposed tocapture patch-wise attribute-related details from the previous amplifiedregion. Such a hybrid architecture strikes a proper balance between regionlocalization and feature extraction. Besides, different from previous worksthat solely focus on discriminating the attribute-relevant foreground visualfeatures, we argue that the attribute-irrelevant background features are alsocrucial for distinguishing the detailed visual contexts in a contrastivemanner. Therefore, a novel E-InfoNCE loss based on the foreground andbackground representations is further proposed to improve the discrimination ofattribute-specific representation. Extensive experiments on three datasetsdemonstrate the effectiveness of our proposed framework, and also show a decentgeneralization of our RPF on out-of-domain fashion images. Our source code isavailable at https://github.com/HuiGuanLab/RPF.</description><author>Jianfeng Dong, Xiaoman Peng, Zhe Ma, Daizong Liu, Xiaoye Qu, Xun Yang, Jixiang Zhu, Baolong Liu</author><pubDate>Wed, 17 May 2023 15:49:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10260v1</guid></item><item><title>Runtime Analyses of Multi-Objective Evolutionary Algorithms in the Presence of Noise</title><link>http://arxiv.org/abs/2305.10259v1</link><description>In single-objective optimization, it is well known that evolutionaryalgorithms also without further adjustments can tolerate a certain amount ofnoise in the evaluation of the objective function. In contrast, this questionis not at all understood for multi-objective optimization. In this work, we conduct the first mathematical runtime analysis of a simplemulti-objective evolutionary algorithm (MOEA) on a classic benchmark in thepresence of noise in the objective functions. We prove that when bit-wise priornoise with rate $p \le \alpha/n$, $\alpha$ a suitable constant, is present, the\emph{simple evolutionary multi-objective optimizer} (SEMO) without anyadjustments to cope with noise finds the Pareto front of the OneMinMaxbenchmark in time $O(n^2\log n)$, just as in the case without noise. Given thatthe problem here is to arrive at a population consisting of $n+1$ individualswitnessing the Pareto front, this is a surprisingly strong robustness to noise(comparably simple evolutionary algorithms cannot optimize the single-objectiveOneMax problem in polynomial time when $p = \omega(\log(n)/n)$). Our proofssuggest that the strong robustness of the MOEA stems from its implicitdiversity mechanism designed to enable it to compute a population covering thewhole Pareto front. Interestingly this result only holds when the objective value of a solutionis determined only once and the algorithm from that point on works with this,possibly noisy, objective value. We prove that when all solutions arereevaluated in each iteration, then any noise rate $p = \omega(\log(n)/n^2)$leads to a super-polynomial runtime. This is very different fromsingle-objective optimization, where it is generally preferred to reevaluatesolutions whenever their fitness is important and where examples are known suchthat not reevaluating solutions can lead to catastrophic performance losses.</description><author>Matthieu Dinot, Benjamin Doerr, Ulysse Hennebelle, Sebastian Will</author><pubDate>Wed, 17 May 2023 15:48:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10259v1</guid></item><item><title>Improving Link Prediction in Social Networks Using Local and Global Features: A Clustering-based Approach</title><link>http://arxiv.org/abs/2305.10257v1</link><description>Link prediction problem has increasingly become prominent in many domainssuch as social network analyses, bioinformatics experiments, transportationnetworks, criminal investigations and so forth. A variety of techniques hasbeen developed for link prediction problem, categorized into 1) similaritybased approaches which study a set of features to extract similar nodes; 2)learning based approaches which extract patterns from the input data; 3)probabilistic statistical approaches which optimize a set of parameters toestablish a model which can best compute formation probability. However,existing literatures lack approaches which utilize strength of each approach byintegrating them to achieve a much more productive one. To tackle the linkprediction problem, we propose an approach based on the combination of firstand second group methods; the existing studied works use just one of thesecategories. Our two-phase developed method firstly determines new featuresrelated to the position and dynamic behavior of nodes, which enforce theapproach more efficiency compared to approaches using mere measures. Then, asubspace clustering algorithm is applied to group social objects based on thecomputed similarity measures which differentiate the strength of clusters;basically, the usage of local and global indices and the clustering informationplays an imperative role in our link prediction process. Some extensiveexperiments held on real datasets including Facebook, Brightkite and HepThindicate good performances of our proposal method. Besides, we haveexperimentally verified our approach with some previous techniques in the areato prove the supremacy of ours.</description><author>Safiye Ghasemi, Amin Zarei</author><pubDate>Wed, 17 May 2023 15:45:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10257v1</guid></item><item><title>ChatGPT -- a Blessing or a Curse for Undergraduate Computer Science Students and Instructors?</title><link>http://arxiv.org/abs/2304.14993v2</link><description>ChatGPT is an AI language model developed by OpenAI that can understand andgenerate human-like text. It can be used for a variety of use cases such aslanguage generation, question answering, text summarization, chatbotdevelopment, language translation, sentiment analysis, content creation,personalization, text completion, and storytelling. While ChatGPT has garneredsignificant positive attention, it has also generated a sense of apprehensionand uncertainty in academic circles. There is concern that students mayleverage ChatGPT to complete take-home assignments and exams and obtainfavorable grades without genuinely acquiring knowledge. This paper adopts aquantitative approach to demonstrate ChatGPT's high degree of unreliability inanswering a diverse range of questions pertaining to topics in undergraduatecomputer science. Our analysis shows that students may risk self-sabotage byblindly depending on ChatGPT to complete assignments and exams. We build uponthis analysis to provide constructive recommendations to both students andinstructors.</description><author>Ishika Joshi, Ritvik Budhiraja, Harshal Dev, Jahnvi Kadia, M. Osama Ataullah, Sayan Mitra, Dhruv Kumar, Harshal D. Akolekar</author><pubDate>Wed, 17 May 2023 15:44:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14993v2</guid></item><item><title>SAM for Poultry Science</title><link>http://arxiv.org/abs/2305.10254v1</link><description>In recent years, the agricultural industry has witnessed significantadvancements in artificial intelligence (AI), particularly with the developmentof large-scale foundational models. Among these foundation models, the SegmentAnything Model (SAM), introduced by Meta AI Research, stands out as agroundbreaking solution for object segmentation tasks. While SAM has shownsuccess in various agricultural applications, its potential in the poultryindustry, specifically in the context of cage-free hens, remains relativelyunexplored. This study aims to assess the zero-shot segmentation performance ofSAM on representative chicken segmentation tasks, including part-basedsegmentation and the use of infrared thermal images, and to explorechicken-tracking tasks by using SAM as a segmentation tool. The resultsdemonstrate SAM's superior performance compared to SegFormer and SETR in bothwhole and part-based chicken segmentation. SAM-based object tracking alsoprovides valuable data on the behavior and movement patterns of broiler birds.The findings of this study contribute to a better understanding of SAM'spotential in poultry science and lay the foundation for future advancements inchicken segmentation and tracking.</description><author>Xiao Yang, Haixing Dai, Zihao Wu, Ramesh Bist, Sachin Subedi, Jin Sun, Guoyu Lu, Changying Li, Tianming Liu, Lilong Chai</author><pubDate>Wed, 17 May 2023 15:43:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10254v1</guid></item><item><title>Sharpness &amp; Shift-Aware Self-Supervised Learning</title><link>http://arxiv.org/abs/2305.10252v1</link><description>Self-supervised learning aims to extract meaningful features from unlabeleddata for further downstream tasks. In this paper, we consider classification asa downstream task in phase 2 and develop rigorous theories to realize thefactors that implicitly influence the general loss of this classification task.Our theories signify that sharpness-aware feature extractors benefit theclassification task in phase 2 and the existing data shift between the ideal(i.e., the ideal one used in theory development) and practical (i.e., thepractical one used in implementation) distributions to generate positive pairsalso remarkably affects this classification task. Further harvesting thesetheoretical findings, we propose to minimize the sharpness of the featureextractor and a new Fourier-based data augmentation technique to relieve thedata shift in the distributions generating positive pairs, reaching Sharpness &amp;Shift-Aware Contrastive Learning (SSA-CLR). We conduct extensive experiments toverify our theoretical findings and demonstrate that sharpness &amp; shift-awarecontrastive learning can remarkably boost the performance as well as obtainingmore robust extracted features compared with the baselines.</description><author>Ngoc N. Tran, Son Duong, Hoang Phan, Tung Pham, Dinh Phung, Trung Le</author><pubDate>Wed, 17 May 2023 15:42:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10252v1</guid></item><item><title>MemoryBank: Enhancing Large Language Models with Long-Term Memory</title><link>http://arxiv.org/abs/2305.10250v1</link><description>Revolutionary advancements in Large Language Models have drastically reshapedour interactions with artificial intelligence systems. Despite this, a notablehindrance remains-the deficiency of a long-term memory mechanism within thesemodels. This shortfall becomes increasingly evident in situations demandingsustained interaction, such as personal companion systems and psychologicalcounseling. Therefore, we propose MemoryBank, a novel memory mechanism tailoredfor LLMs. MemoryBank enables the models to summon relevant memories,continually evolve through continuous memory updates, comprehend, and adapt toa user personality by synthesizing information from past interactions. To mimicanthropomorphic behaviors and selectively preserve memory, MemoryBankincorporates a memory updating mechanism, inspired by the Ebbinghaus ForgettingCurve theory, which permits the AI to forget and reinforce memory based on timeelapsed and the relative significance of the memory, thereby offering ahuman-like memory mechanism. MemoryBank is versatile in accommodating bothclosed-source models like ChatGPT and open-source models like ChatGLM. Weexemplify application of MemoryBank through the creation of an LLM-basedchatbot named SiliconFriend in a long-term AI Companion scenario. Further tunedwith psychological dialogs, SiliconFriend displays heightened empathy in itsinteractions. Experiment involves both qualitative analysis with real-worlduser dialogs and quantitative analysis with simulated dialogs. In the latter,ChatGPT acts as users with diverse characteristics and generates long-termdialog contexts covering a wide array of topics. The results of our analysisreveal that SiliconFriend, equipped with MemoryBank, exhibits a strongcapability for long-term companionship as it can provide emphatic response,recall relevant memories and understand user personality.</description><author>Wanjun Zhong, Lianghong Guo, Qiqi Gao, Yanlin Wang</author><pubDate>Wed, 17 May 2023 15:40:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10250v1</guid></item><item><title>FedComm: Federated Learning as a Medium for Covert Communication</title><link>http://arxiv.org/abs/2201.08786v3</link><description>Proposed as a solution to mitigate the privacy implications related to theadoption of deep learning, Federated Learning (FL) enables large numbers ofparticipants to successfully train deep neural networks without having toreveal the actual private training data. To date, a substantial amount ofresearch has investigated the security and privacy properties of FL, resultingin a plethora of innovative attack and defense strategies. This paperthoroughly investigates the communication capabilities of an FL scheme. Inparticular, we show that a party involved in the FL learning process can use FLas a covert communication medium to send an arbitrary message. We introduceFedComm, a novel multi-system covert-communication technique that enablesrobust sharing and transfer of targeted payloads within the FL framework. Ourextensive theoretical and empirical evaluations show that FedComm provides astealthy communication channel, with minimal disruptions to the trainingprocess. Our experiments show that FedComm successfully delivers 100% of apayload in the order of kilobits before the FL procedure converges. Ourevaluation also shows that FedComm is independent of the application domain andthe neural network architecture used by the underlying FL scheme.</description><author>Dorjan Hitaj, Giulio Pagnotta, Briland Hitaj, Fernando Perez-Cruz, Luigi V. Mancini</author><pubDate>Wed, 17 May 2023 15:37:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.08786v3</guid></item><item><title>Can Deep Network Balance Copy-Move Forgery Detection and Distinguishment?</title><link>http://arxiv.org/abs/2305.10247v1</link><description>Copy-move forgery detection is a crucial research area within digital imageforensics, as it focuses on identifying instances where objects in an image areduplicated and placed in different locations. The detection of such forgeriesis particularly important in contexts where they can be exploited for maliciouspurposes. Recent years have witnessed an increased interest in distinguishingbetween the original and duplicated objects in copy-move forgeries, accompaniedby the development of larger-scale datasets to facilitate this task. However,existing approaches to copy-move forgery detection and source/targetdifferentiation often involve two separate steps or the design of individualend-to-end networks for each task. In this paper, we propose an innovativemethod that employs the transformer architecture in an end-to-end deep neuralnetwork. Our method aims to detect instances of copy-move forgery whilesimultaneously localizing the source and target regions. By utilizing thisapproach, we address the challenges posed by multi-object copy-move scenariosand report if there is a balance between the detection and differentiationtasks. To evaluate the performance of our proposed network, we conductedexperiments on two publicly available copy-move datasets. The results andanalysis aims to show the potential significance of our focus in balancingdetection and distinguishment result and transferring the trained model indifferent datasets in the field.</description><author>Shizhen Chang</author><pubDate>Wed, 17 May 2023 15:35:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10247v1</guid></item><item><title>SGAD: Spiking Generative Adversarial Network with Attention Scoring Decoding</title><link>http://arxiv.org/abs/2305.10246v1</link><description>Generative models based on neural networks present a substantial challengewithin deep learning. As it stands, such models are primarily limited to thedomain of artificial neural networks. Spiking neural networks, as the thirdgeneration of neural networks, offer a closer approximation to brain-likeprocessing due to their rich spatiotemporal dynamics. However, generativemodels based on spiking neural networks are not well studied. In this work, wepioneer constructing a spiking generative adversarial network capable ofhandling complex images. Our first task was to identify the problems ofout-of-domain inconsistency and temporal inconsistency inherent in spikinggenerative adversarial networks. We addressed these issues by incorporating theEarth-Mover distance and an attention-based weighted decoding method,significantly enhancing the performance of our algorithm across severaldatasets. Experimental results reveal that our approach outperforms existingmethods on the MNIST, FashionMNIST, CIFAR10, and CelebA datasets. Moreover,compared with hybrid spiking generative adversarial networks, where thediscriminator is an artificial analog neural network, our methodologydemonstrates closer alignment with the information processing patterns observedin the mouse.</description><author>Linghao Feng, Dongcheng Zhao, Yi Zeng</author><pubDate>Wed, 17 May 2023 15:35:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10246v1</guid></item><item><title>Monitoring and Adapting ML Models on Mobile Devices</title><link>http://arxiv.org/abs/2305.07772v2</link><description>ML models are increasingly being pushed to mobile devices, for low-latencyinference and offline operation. However, once the models are deployed, it ishard for ML operators to track their accuracy, which can degrade unpredictably(e.g., due to data drift). We design the first end-to-end system forcontinuously monitoring and adapting models on mobile devices without requiringfeedback from users. Our key observation is that often model degradation is dueto a specific root cause, which may affect a large group of devices. Therefore,once the system detects a consistent degradation across a large number ofdevices, it employs a root cause analysis to determine the origin of theproblem and applies a cause-specific adaptation. We evaluate the system on twocomputer vision datasets, and show it consistently boosts accuracy compared toexisting approaches. On a dataset containing photos collected from drivingcars, our system improves the accuracy on average by 15%.</description><author>Wei Hao, Zixi Wang, Lauren Hong, Lingxiao Li, Nader Karayanni, Chengzhi Mao, Junfeng Yang, Asaf Cidon</author><pubDate>Wed, 17 May 2023 15:34:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07772v2</guid></item><item><title>Probabilistic Contrastive Learning Recovers the Correct Aleatoric Uncertainty of Ambiguous Inputs</title><link>http://arxiv.org/abs/2302.02865v3</link><description>Contrastively trained encoders have recently been proven to invert thedata-generating process: they encode each input, e.g., an image, into the truelatent vector that generated the image (Zimmermann et al., 2021). However,real-world observations often have inherent ambiguities. For instance, imagesmay be blurred or only show a 2D view of a 3D object, so multiple latents couldhave generated them. This makes the true posterior for the latent vectorprobabilistic with heteroscedastic uncertainty. In this setup, we extend thecommon InfoNCE objective and encoders to predict latent distributions insteadof points. We prove that these distributions recover the correct posteriors ofthe data-generating process, including its level of aleatoric uncertainty, upto a rotation of the latent space. In addition to providing calibrateduncertainty estimates, these posteriors allow the computation of credibleintervals in image retrieval. They comprise images with the same latent as agiven query, subject to its uncertainty. Code is available athttps://github.com/mkirchhof/Probabilistic_Contrastive_Learning</description><author>Michael Kirchhof, Enkelejda Kasneci, Seong Joon Oh</author><pubDate>Wed, 17 May 2023 15:33:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02865v3</guid></item><item><title>A quantitative study of NLP approaches to question difficulty estimation</title><link>http://arxiv.org/abs/2305.10236v1</link><description>Recent years witnessed an increase in the amount of research on the task ofQuestion Difficulty Estimation from Text QDET with Natural Language Processing(NLP) techniques, with the goal of targeting the limitations of traditionalapproaches to question calibration. However, almost the entirety of previousresearch focused on single silos, without performing quantitative comparisonsbetween different models or across datasets from different educational domains.In this work, we aim at filling this gap, by quantitatively analyzing severalapproaches proposed in previous research, and comparing their performance onthree publicly available real world datasets containing questions of differenttypes from different educational domains. Specifically, we consider readingcomprehension Multiple Choice Questions (MCQs), science MCQs, and mathquestions. We find that Transformer based models are the best performing acrossdifferent educational domains, with DistilBERT performing almost as well asBERT, and that they outperform other approaches even on smaller datasets. Asfor the other models, the hybrid ones often outperform the ones based on asingle type of features, the ones based on linguistic features perform well onreading comprehension questions, while frequency based features (TF-IDF) andword embeddings (word2vec) perform better in domain knowledge assessment.</description><author>Luca Benedetto</author><pubDate>Wed, 17 May 2023 15:26:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10236v1</guid></item><item><title>UQ for Credit Risk Management: A deep evidence regression approach</title><link>http://arxiv.org/abs/2305.04967v2</link><description>Machine Learning has invariantly found its way into various Credit Riskapplications. Due to the intrinsic nature of Credit Risk, quantifying theuncertainty of the predicted risk metrics is essential, and applyinguncertainty-aware deep learning models to credit risk settings can be veryhelpful. In this work, we have explored the application of a scalable UQ-awaredeep learning technique, Deep Evidence Regression and applied it to predictingLoss Given Default. We contribute to the literature by extending the DeepEvidence Regression methodology to learning target variables generated by aWeibull process and provide the relevant learning framework. We demonstrate theapplication of our approach to both simulated and real-world data.</description><author>Ashish Dhiman</author><pubDate>Wed, 17 May 2023 15:25:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04967v2</guid></item></channel></rss>