<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 13 Nov 2023 14:00:10 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization</title><link>http://arxiv.org/abs/2311.06243v1</link><description>Large foundation models are becoming ubiquitous, but training them fromscratch is prohibitively expensive. Thus, efficiently adapting these powerfulmodels to downstream tasks is increasingly important. In this paper, we study aprincipled finetuning paradigm -- Orthogonal Finetuning (OFT) -- for downstreamtask adaptation. Despite demonstrating good generalizability, OFT still uses afairly large number of trainable parameters due to the high dimensionality oforthogonal matrices. To address this, we start by examining OFT from aninformation transmission perspective, and then identify a few key desideratathat enable better parameter-efficiency. Inspired by how the Cooley-Tukey fastFourier transform algorithm enables efficient information transmission, wepropose an efficient orthogonal parameterization using butterfly structures. Weapply this parameterization to OFT, creating a novel parameter-efficientfinetuning method, called Orthogonal Butterfly (BOFT). By subsuming OFT as aspecial case, BOFT introduces a generalized orthogonal finetuning framework.Finally, we conduct an extensive empirical study of adapting large visiontransformers, large language models, and text-to-image diffusion models tovarious downstream tasks in vision and language.</description><author>Weiyang Liu, Zeju Qiu, Yao Feng, Yuliang Xiu, Yuxuan Xue, Longhui Yu, Haiwen Feng, Zhen Liu, Juyeon Heo, Songyou Peng, Yandong Wen, Michael J. Black, Adrian Weller, Bernhard Sch√∂lkopf</author><pubDate>Fri, 10 Nov 2023 18:59:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06243v1</guid></item><item><title>Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks</title><link>http://arxiv.org/abs/2311.06242v1</link><description>We introduce Florence-2, a novel vision foundation model with a unified,prompt-based representation for a variety of computer vision andvision-language tasks. While existing large vision models excel in transferlearning, they struggle to perform a diversity of tasks with simpleinstructions, a capability that implies handling the complexity of variousspatial hierarchy and semantic granularity. Florence-2 was designed to taketext-prompt as task instructions and generate desirable results in text forms,whether it be captioning, object detection, grounding or segmentation. Thismulti-task learning setup demands large-scale, high-quality annotated data. Tothis end, we co-developed FLD-5B that consists of 5.4 billion comprehensivevisual annotations on 126 million images, using an iterative strategy ofautomated image annotation and model refinement. We adopted asequence-to-sequence structure to train Florence-2 to perform versatile andcomprehensive vision tasks. Extensive evaluations on numerous tasksdemonstrated Florence-2 to be a strong vision foundation model contender withunprecedented zero-shot and fine-tuning capabilities.</description><author>Bin Xiao, Haiping Wu, Weijian Xu, Xiyang Dai, Houdong Hu, Yumao Lu, Michael Zeng, Ce Liu, Lu Yuan</author><pubDate>Fri, 10 Nov 2023 18:59:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06242v1</guid></item><item><title>Argumentation Element Annotation Modeling using XLNet</title><link>http://arxiv.org/abs/2311.06239v1</link><description>This study demonstrates the effectiveness of XLNet, a transformer-basedlanguage model, for annotating argumentative elements in persuasive essays.XLNet's architecture incorporates a recurrent mechanism that allows it to modellong-term dependencies in lengthy texts. Fine-tuned XLNet models were appliedto three datasets annotated with different schemes - a proprietary datasetusing the Annotations for Revisions and Reflections on Writing (ARROW) scheme,the PERSUADE corpus, and the Argument Annotated Essays (AAE) dataset. The XLNetmodels achieved strong performance across all datasets, even surpassing humanagreement levels in some cases. This shows XLNet capably handles diverseannotation schemes and lengthy essays. Comparisons between the model outputs ondifferent datasets also revealed insights into the relationships between theannotation tags. Overall, XLNet's strong performance on modeling argumentativestructures across diverse datasets highlights its suitability for providingautomated feedback on essay organization.</description><author>Christopher Ormerod, Amy Burkhardt, Mackenzie Young, Sue Lottridge</author><pubDate>Fri, 10 Nov 2023 18:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06239v1</guid></item><item><title>Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming in the Wild</title><link>http://arxiv.org/abs/2311.06237v1</link><description>Engaging in the deliberate generation of abnormal outputs from large languagemodels (LLMs) by attacking them is a novel human activity. This paper presentsa thorough exposition of how and why people perform such attacks. Using aformal qualitative methodology, we interviewed dozens of practitioners from abroad range of backgrounds, all contributors to this novel work of attemptingto cause LLMs to fail. We relate and connect this activity between itspractitioners' motivations and goals; the strategies and techniques theydeploy; and the crucial role the community plays. As a result, this paperpresents a grounded theory of how and why people attack large language models:LLM red teaming in the wild.</description><author>Nanna Inie, Jonathan Stray, Leon Derczynski</author><pubDate>Fri, 10 Nov 2023 18:52:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06237v1</guid></item><item><title>EVORA: Deep Evidential Traversability Learning for Risk-Aware Off-Road Autonomy</title><link>http://arxiv.org/abs/2311.06234v1</link><description>Traversing terrain with good traction is crucial for achieving fast off-roadnavigation. Instead of manually designing costs based on terrain features,existing methods learn terrain properties directly from data viaself-supervision, but challenges remain to properly quantify and mitigate risksdue to uncertainties in learned models. This work efficiently quantifies bothaleatoric and epistemic uncertainties by learning discrete tractiondistributions and probability densities of the traction predictor's latentfeatures. Leveraging evidential deep learning, we parameterize Dirichletdistributions with the network outputs and propose a novel uncertainty-awaresquared Earth Mover's distance loss with a closed-form expression that improveslearning accuracy and navigation performance. The proposed risk-aware plannersimulates state trajectories with the worst-case expected traction to handlealeatoric uncertainty, and penalizes trajectories moving through terrain withhigh epistemic uncertainty. Our approach is extensively validated in simulationand on wheeled and quadruped robots, showing improved navigation performancecompared to methods that assume no slip, assume the expected traction, oroptimize for the worst-case expected cost.</description><author>Xiaoyi Cai, Siddharth Ancha, Lakshay Sharma, Philip R. Osteen, Bernadette Bucher, Stephen Phillips, Jiuguang Wang, Michael Everett, Nicholas Roy, Jonathan P. How</author><pubDate>Fri, 10 Nov 2023 18:49:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06234v1</guid></item><item><title>Data Contamination Quiz: A Tool to Detect and Estimate Contamination in Large Language Models</title><link>http://arxiv.org/abs/2311.06233v1</link><description>We propose the Data Contamination Quiz, a simple and effective approach todetect data contamination in large language models (LLMs) and estimate theamount of it. Specifically, we frame data contamination detection as a seriesof multiple-choice questions. We devise a quiz format wherein three perturbedversions of each dataset instance are created. These changes only includeword-level perturbations, replacing words with their contextual synonyms,ensuring both the semantic and sentence structure remain exactly the same asthe original instance. Together with the original instance, these perturbedversions constitute the choices in the quiz. Given that the only distinguishingsignal among these choices is the exact wording, an LLM, when tasked withidentifying the original instance from the choices, opts for the original if ithas memorized it in its pre-training phase--a trait intrinsic to LLMs. Adataset partition is then marked as contaminated if the LLM's performance onthe quiz surpasses what random chance suggests. Our evaluation spans sevendatasets and their respective splits (train and test/validation) on twostate-of-the-art LLMs: GPT-4 and GPT-3.5. While lacking access to thepre-training data, our results suggest that our approach not only enhances thedetection of data contamination but also provides an accurate estimation of itsextent, even when the contamination signal is weak.</description><author>Shahriar Golchin, Mihai Surdeanu</author><pubDate>Fri, 10 Nov 2023 18:48:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06233v1</guid></item><item><title>'Person' == Light-skinned, Western Man, and Sexualization of Women of Color: Stereotypes in Stable Diffusion</title><link>http://arxiv.org/abs/2310.19981v2</link><description>We study stereotypes embedded within one of the most popular text-to-imagegenerators: Stable Diffusion. We examine what stereotypes of gender andnationality/continental identity does Stable Diffusion display in the absenceof such information i.e. what gender and nationality/continental identity isassigned to `a person', or to `a person from Asia'. Using vision-language modelCLIP's cosine similarity to compare images generated by CLIP-based StableDiffusion v2.1 verified by manual examination, we chronicle results from 136prompts (50 results/prompt) of front-facing images of persons from 6 differentcontinents, 27 nationalities and 3 genders. We observe how Stable Diffusionoutputs of `a person' without any additional gender/nationality informationcorrespond closest to images of men and least with persons of nonbinary gender,and to persons from Europe/North America over Africa/Asia, pointing towardsStable Diffusion having a concerning representation of personhood to be aEuropean/North American man. We also show continental stereotypes and resultantharms e.g. a person from Oceania is deemed to be Australian/New Zealander overPapua New Guinean, pointing to the erasure of Indigenous Oceanic peoples, whoform a majority over descendants of colonizers both in Papua New Guinea and inOceania overall. Finally, we unexpectedly observe a pattern ofoversexualization of women, specifically Latin American, Mexican, Indian andEgyptian women relative to other nationalities, measured through an NSFWdetector. This demonstrates how Stable Diffusion perpetuates Westernfetishization of women of color through objectification in media, which if leftunchecked will amplify this stereotypical representation. Image datasets aremade publicly available.</description><author>Sourojit Ghosh, Aylin Caliskan</author><pubDate>Fri, 10 Nov 2023 18:47:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19981v2</guid></item><item><title>Learning Human Action Recognition Representations Without Real Humans</title><link>http://arxiv.org/abs/2311.06231v1</link><description>Pre-training on massive video datasets has become essential to achieve highaction recognition performance on smaller downstream datasets. However, mostlarge-scale video datasets contain images of people and hence are accompaniedwith issues related to privacy, ethics, and data protection, often preventingthem from being publicly shared for reproducible research. Existing work hasattempted to alleviate these problems by blurring faces, downsampling videos,or training on synthetic data. On the other hand, analysis on thetransferability of privacy-preserving pre-trained models to downstream taskshas been limited. In this work, we study this problem by first asking thequestion: can we pre-train models for human action recognition with data thatdoes not include real humans? To this end, we present, for the first time, abenchmark that leverages real-world videos with humans removed and syntheticdata containing virtual humans to pre-train a model. We then evaluate thetransferability of the representation learned on this data to a diverse set ofdownstream action recognition benchmarks. Furthermore, we propose a novelpre-training strategy, called Privacy-Preserving MAE-Align, to effectivelycombine synthetic data and human-removed real data. Our approach outperformsprevious baselines by up to 5% and closes the performance gap between human andno-human action recognition representations on downstream tasks, for bothlinear probing and fine-tuning. Our benchmark, code, and models are availableat https://github.com/howardzh01/PPMA .</description><author>Howard Zhong, Samarth Mishra, Donghyun Kim, SouYoung Jin, Rameswar Panda, Hilde Kuehne, Leonid Karlinsky, Venkatesh Saligrama, Aude Oliva, Rogerio Feris</author><pubDate>Fri, 10 Nov 2023 18:38:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06231v1</guid></item><item><title>Chanakya: Learning Runtime Decisions for Adaptive Real-Time Perception</title><link>http://arxiv.org/abs/2106.05665v3</link><description>Real-time perception requires planned resource utilization. Computationalplanning in real-time perception is governed by two considerations -- accuracyand latency. There exist run-time decisions (e.g. choice of input resolution)that induce tradeoffs affecting performance on a given hardware, arising fromintrinsic (content, e.g. scene clutter) and extrinsic (system, e.g. resourcecontention) characteristics. Earlier runtime execution frameworks employed rule-based decision algorithmsand operated with a fixed algorithm latency budget to balance these concerns,which is sub-optimal and inflexible. We propose Chanakya, a learned approximateexecution framework that naturally derives from the streaming perceptionparadigm, to automatically learn decisions induced by these tradeoffs instead.Chanakya is trained via novel rewards balancing accuracy and latencyimplicitly, without approximating either objectives. Chanakya simultaneouslyconsiders intrinsic and extrinsic context, and predicts decisions in a flexiblemanner. Chanakya, designed with low overhead in mind, outperformsstate-of-the-art static and dynamic execution policies on public datasets onboth server GPUs and edge devices.</description><author>Anurag Ghosh, Vaibhav Balloli, Akshay Nambi, Aditya Singh, Tanuja Ganu</author><pubDate>Fri, 10 Nov 2023 18:36:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.05665v3</guid></item><item><title>Learning material synthesis-structure-property relationship by data fusion: Bayesian Co-regionalization N-Dimensional Piecewise Function Learning</title><link>http://arxiv.org/abs/2311.06228v1</link><description>Advanced materials are needed to further next-generation technologies such asquantum computing, carbon capture, and low-cost medical imaging. However,advanced materials discovery is confounded by two fundamental challenges: thechallenge of a high-dimensional, complex materials search space and thechallenge of combining knowledge, i.e., data fusion across instruments andlabs. To overcome the first challenge, researchers employ knowledge of theunderlying material synthesis-structure-property relationship, as a material'sstructure is often predictive of its functional property and vice versa. Forexample, optimal materials often occur along composition-phase boundaries orwithin specific phase regions. Additionally, knowledge of thesynthesis-structure-property relationship is fundamental to understandingunderlying physical mechanisms. However, quantifying thesynthesis-structure-property relationship requires overcoming the secondchallenge. Researchers must merge knowledge gathered across instruments,measurement modalities, and even laboratories. We present theSynthesis-structure-property relAtionship coreGionalized lEarner (SAGE)algorithm. A fully Bayesian algorithm that uses multimodal coregionalization tomerge knowledge across data sources to learn synthesis-structure-propertyrelationships.</description><author>A. Gilad Kusne, Austin McDannald, Brian DeCost</author><pubDate>Fri, 10 Nov 2023 18:34:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06228v1</guid></item><item><title>Does Differential Privacy Prevent Backdoor Attacks in Practice?</title><link>http://arxiv.org/abs/2311.06227v1</link><description>Differential Privacy (DP) was originally developed to protect privacy.However, it has recently been utilized to secure machine learning (ML) modelsfrom poisoning attacks, with DP-SGD receiving substantial attention.Nevertheless, a thorough investigation is required to assess the effectivenessof different DP techniques in preventing backdoor attacks in practice. In thispaper, we investigate the effectiveness of DP-SGD and, for the first time inliterature, examine PATE in the context of backdoor attacks. We also explorethe role of different components of DP algorithms in defending against backdoorattacks and will show that PATE is effective against these attacks due to thebagging structure of the teacher models it employs. Our experiments reveal thathyperparameters and the number of backdoors in the training dataset impact thesuccess of DP algorithms. Additionally, we propose Label-DP as a faster andmore accurate alternative to DP-SGD and PATE. We conclude that while Label-DPalgorithms generally offer weaker privacy protection, accurate hyper-parametertuning can make them more effective than DP methods in defending againstbackdoor attacks while maintaining model accuracy.</description><author>Fereshteh Razmi, Jian Lou, Li Xiong</author><pubDate>Fri, 10 Nov 2023 18:32:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06227v1</guid></item><item><title>Harnessing Synthetic Datasets: The Role of Shape Bias in Deep Neural Network Generalization</title><link>http://arxiv.org/abs/2311.06224v1</link><description>Recent advancements in deep learning have been primarily driven by the use oflarge models trained on increasingly vast datasets. While neural scaling lawshave emerged to predict network performance given a specific level ofcomputational resources, the growing demand for expansive datasets raisesconcerns. To address this, a new research direction has emerged, focusing onthe creation of synthetic data as a substitute. In this study, we investigatehow neural networks exhibit shape bias during training on synthetic datasets,serving as an indicator of the synthetic data quality. Specifically, ourfindings indicate three key points: (1) Shape bias varies across networkarchitectures and types of supervision, casting doubt on its reliability as apredictor for generalization and its ability to explain differences in modelrecognition compared to human capabilities. (2) Relying solely on shape bias toestimate generalization is unreliable, as it is entangled with diversity andnaturalism. (3) We propose a novel interpretation of shape bias as a tool forestimating the diversity of samples within a dataset. Our research aims toclarify the implications of using synthetic data and its associated shape biasin deep learning, addressing concerns regarding generalization and datasetquality.</description><author>Elior Benarous, Sotiris Anagnostidis, Luca Biggio, Thomas Hofmann</author><pubDate>Fri, 10 Nov 2023 18:25:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06224v1</guid></item><item><title>Diffusion Models for Earth Observation Use-cases: from cloud removal to urban change detection</title><link>http://arxiv.org/abs/2311.06222v1</link><description>The advancements in the state of the art of generative ArtificialIntelligence (AI) brought by diffusion models can be highly beneficial in novelcontexts involving Earth observation data. After introducing this new family ofgenerative models, this work proposes and analyses three use cases whichdemonstrate the potential of diffusion-based approaches for satellite imagedata. Namely, we tackle cloud removal and inpainting, dataset generation forchange-detection tasks, and urban replanning.</description><author>Fulvio Sanguigni, Mikolaj Czerkawski, Lorenzo Papa, Irene Amerini, Bertrand Le Saux</author><pubDate>Fri, 10 Nov 2023 18:24:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06222v1</guid></item><item><title>A Comparison of Lexicon-Based and ML-Based Sentiment Analysis: Are There Outlier Words?</title><link>http://arxiv.org/abs/2311.06221v1</link><description>Lexicon-based approaches to sentiment analysis of text are based on each wordor lexical entry having a pre-defined weight indicating its sentiment polarity.These are usually manually assigned but the accuracy of these when comparedagainst machine leaning based approaches to computing sentiment, are not known.It may be that there are lexical entries whose sentiment values cause alexicon-based approach to give results which are very different to a machinelearning approach. In this paper we compute sentiment for more than 150,000English language texts drawn from 4 domains using the Hedonometer, alexicon-based technique and Azure, a contemporary machine-learning basedapproach which is part of the Azure Cognitive Services family of APIs which iseasy to use. We model differences in sentiment scores between approaches fordocuments in each domain using a regression and analyse the independentvariables (Hedonometer lexical entries) as indicators of each word's importanceand contribution to the score differences. Our findings are that the importanceof a word depends on the domain and there are no standout lexical entries whichsystematically cause differences in sentiment scores.</description><author>Siddhant Jaydeep Mahajani, Shashank Srivastava, Alan F. Smeaton</author><pubDate>Fri, 10 Nov 2023 18:21:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06221v1</guid></item><item><title>Semantic-aware Video Representation for Few-shot Action Recognition</title><link>http://arxiv.org/abs/2311.06218v1</link><description>Recent work on action recognition leverages 3D features and textualinformation to achieve state-of-the-art performance. However, most of thecurrent few-shot action recognition methods still rely on 2D frame-levelrepresentations, often require additional components to model temporalrelations, and employ complex distance functions to achieve accurate alignmentof these representations. In addition, existing methods struggle to effectivelyintegrate textual semantics, some resorting to concatenation or addition oftextual and visual features, and some using text merely as an additionalsupervision without truly achieving feature fusion and information transferfrom different modalities. In this work, we propose a simple yet effectiveSemantic-Aware Few-Shot Action Recognition (SAFSAR) model to address theseissues. We show that directly leveraging a 3D feature extractor combined withan effective feature-fusion scheme, and a simple cosine similarity forclassification can yield better performance without the need of extracomponents for temporal modeling or complex distance functions. We introduce aninnovative scheme to encode the textual semantics into the video representationwhich adaptively fuses features from text and video, and encourages the visualencoder to extract more semantically consistent features. In this scheme,SAFSAR achieves alignment and fusion in a compact way. Experiments on fivechallenging few-shot action recognition benchmarks under various settingsdemonstrate that the proposed SAFSAR model significantly improves thestate-of-the-art performance.</description><author>Yutao Tang, Benjamin Bejar, Rene Vidal</author><pubDate>Fri, 10 Nov 2023 18:13:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06218v1</guid></item><item><title>MultiIoT: Towards Large-scale Multisensory Learning for the Internet of Things</title><link>http://arxiv.org/abs/2311.06217v1</link><description>The Internet of Things (IoT), the network integrating billions of smartphysical devices embedded with sensors, software, and communicationtechnologies for the purpose of connecting and exchanging data with otherdevices and systems, is a critical and rapidly expanding component of ourmodern world. The IoT ecosystem provides a rich source of real-world modalitiessuch as motion, thermal, geolocation, imaging, depth, sensors, video, and audiofor prediction tasks involving the pose, gaze, activities, and gestures ofhumans as well as the touch, contact, pose, 3D of physical objects. Machinelearning presents a rich opportunity to automatically process IoT data atscale, enabling efficient inference for impact in understanding humanwellbeing, controlling physical devices, and interconnecting smart cities. Todevelop machine learning technologies for IoT, this paper proposes MultiIoT,the most expansive IoT benchmark to date, encompassing over 1.15 millionsamples from 12 modalities and 8 tasks. MultiIoT introduces unique challengesinvolving (1) learning from many sensory modalities, (2) fine-grainedinteractions across long temporal ranges, and (3) extreme heterogeneity due tounique structure and noise topologies in real-world sensors. We also release aset of strong modeling baselines, spanning modality and task-specific methodsto multisensory and multitask models to encourage future research inmultisensory representation learning for IoT.</description><author>Shentong Mo, Paul Pu Liang, Russ Salakhutdinov, Louis-Philippe Morency</author><pubDate>Fri, 10 Nov 2023 18:13:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06217v1</guid></item><item><title>Instant3D: Fast Text-to-3D with Sparse-View Generation and Large Reconstruction Model</title><link>http://arxiv.org/abs/2311.06214v1</link><description>Text-to-3D with diffusion models have achieved remarkable progress in recentyears. However, existing methods either rely on score distillation-basedoptimization which suffer from slow inference, low diversity and Janusproblems, or are feed-forward methods that generate low quality results due tothe scarcity of 3D training data. In this paper, we propose Instant3D, a novelmethod that generates high-quality and diverse 3D assets from text prompts in afeed-forward manner. We adopt a two-stage paradigm, which first generates asparse set of four structured and consistent views from text in one shot with afine-tuned 2D text-to-image diffusion model, and then directly regresses theNeRF from the generated images with a novel transformer-based sparse-viewreconstructor. Through extensive experiments, we demonstrate that our methodcan generate high-quality, diverse and Janus-free 3D assets within 20 seconds,which is two order of magnitude faster than previous optimization-based methodsthat can take 1 to 10 hours. Our project webpage: https://jiahao.ai/instant3d/.</description><author>Jiahao Li, Hao Tan, Kai Zhang, Zexiang Xu, Fujun Luan, Yinghao Xu, Yicong Hong, Kalyan Sunkavalli, Greg Shakhnarovich, Sai Bi</author><pubDate>Fri, 10 Nov 2023 18:03:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06214v1</guid></item><item><title>Differentiable VQ-VAE's for Robust White Matter Streamline Encodings</title><link>http://arxiv.org/abs/2311.06212v1</link><description>Given the complex geometry of white matter streamlines, Autoencoders havebeen proposed as a dimension-reduction tool to simplify the analysisstreamlines in a low-dimensional latent spaces. However, despite these recentsuccesses, the majority of encoder architectures only perform dimensionreduction on single streamlines as opposed to a full bundle of streamlines.This is a severe limitation of the encoder architecture that completelydisregards the global geometric structure of streamlines at the expense ofindividual fibers. Moreover, the latent space may not be well structured whichleads to doubt into their interpretability. In this paper we propose a novelDifferentiable Vector Quantized Variational Autoencoder, which are engineeredto ingest entire bundles of streamlines as single data-point and providesreliable trustworthy encodings that can then be later used to analyzestreamlines in the latent space. Comparisons with several state of the artAutoencoders demonstrate superior performance in both encoding and synthesis.</description><author>Andrew Lizarraga, Brandon Taraku, Edouardo Honig, Ying Nian Wu, Shantanu H. Joshi</author><pubDate>Fri, 10 Nov 2023 17:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06212v1</guid></item><item><title>ASSIST: Interactive Scene Nodes for Scalable and Realistic Indoor Simulation</title><link>http://arxiv.org/abs/2311.06211v1</link><description>We present ASSIST, an object-wise neural radiance field as a panopticrepresentation for compositional and realistic simulation. Central to ourapproach is a novel scene node data structure that stores the information ofeach object in a unified fashion, allowing online interaction in both intra-and cross-scene settings. By incorporating a differentiable neural networkalong with the associated bounding box and semantic features, the proposedstructure guarantees user-friendly interaction on independent objects to scaleup novel view simulation. Objects in the scene can be queried, added,duplicated, deleted, transformed, or swapped simply through mouse/keyboardcontrols or language instructions. Experiments demonstrate the efficacy of theproposed method, where scaled realistic simulation can be achieved throughinteractive editing and compositional rendering, with color images, depthimages, and panoptic segmentation masks generated in a 3D consistent manner.</description><author>Zhide Zhong, Jiakai Cao, Songen Gu, Sirui Xie, Weibo Gao, Liyi Luo, Zike Yan, Hao Zhao, Guyue Zhou</author><pubDate>Fri, 10 Nov 2023 17:56:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06211v1</guid></item><item><title>Optimal Cooperative Multiplayer Learning Bandits with Noisy Rewards and No Communication</title><link>http://arxiv.org/abs/2311.06210v1</link><description>We consider a cooperative multiplayer bandit learning problem where theplayers are only allowed to agree on a strategy beforehand, but cannotcommunicate during the learning process. In this problem, each playersimultaneously selects an action. Based on the actions selected by all players,the team of players receives a reward. The actions of all the players arecommonly observed. However, each player receives a noisy version of the rewardwhich cannot be shared with other players. Since players receive potentiallydifferent rewards, there is an asymmetry in the information used to selecttheir actions. In this paper, we provide an algorithm based on upper and lowerconfidence bounds that the players can use to select their optimal actionsdespite the asymmetry in the reward information. We show that this algorithmcan achieve logarithmic $O(\frac{\log T}{\Delta_{\bm{a}}})$ (gap-dependent)regret as well as $O(\sqrt{T\log T})$ (gap-independent) regret. This isasymptotically optimal in $T$. We also show that it performs empirically betterthan the current state of the art algorithm for this environment.</description><author>William Chang, Yuanhao Lu</author><pubDate>Fri, 10 Nov 2023 17:55:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06210v1</guid></item><item><title>Conceptual structure coheres in human cognition but not in large language models</title><link>http://arxiv.org/abs/2304.02754v2</link><description>Neural network models of language have long been used as a tool fordeveloping hypotheses about conceptual representation in the mind and brain.For many years, such use involved extracting vector-space representations ofwords and using distances among these to predict or understand human behaviorin various semantic tasks. Contemporary large language models (LLMs), however,make it possible to interrogate the latent structure of conceptualrepresentations using experimental methods nearly identical to those commonlyused with human participants. The current work utilizes three common techniquesborrowed from cognitive psychology to estimate and compare the structure ofconcepts in humans and a suite of LLMs. In humans, we show that conceptualstructure is robust to differences in culture, language, and method ofestimation. Structures estimated from LLM behavior, while individually fairlyconsistent with those estimated from human behavior, vary much more dependingupon the particular task used to generate responses--across tasks, estimates ofconceptual structure from the very same model cohere less with one another thando human structure estimates. These results highlight an important differencebetween contemporary LLMs and human cognition, with implications forunderstanding some fundamental limitations of contemporary machine language.</description><author>Siddharth Suresh, Kushin Mukherjee, Xizheng Yu, Wei-Chun Huang, Lisa Padua, Timothy T Rogers</author><pubDate>Fri, 10 Nov 2023 17:42:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02754v2</guid></item><item><title>BanglaBait: Semi-Supervised Adversarial Approach for Clickbait Detection on Bangla Clickbait Dataset</title><link>http://arxiv.org/abs/2311.06204v1</link><description>Intentionally luring readers to click on a particular content by exploitingtheir curiosity defines a title as clickbait. Although several studies focusedon detecting clickbait titles in English articles, low resource language likeBangla has not been given adequate attention. To tackle clickbait titles inBangla, we have constructed the first Bangla clickbait detection datasetcontaining 15,056 labeled news articles and 65,406 unlabelled news articlesextracted from clickbait dense news sites. Each article has been labeled bythree expert linguists and includes an article's title, body, and othermetadata. By incorporating labeled and unlabelled data, we finetune apretrained Bangla transformer model in an adversarial fashion using SemiSupervised Generative Adversarial Networks (SS GANs). The proposed model actsas a good baseline for this dataset, outperforming traditional neural networkmodels (LSTM, GRU, CNN) and linguistic feature based models. We expect thatthis dataset and the detailed analysis and comparison of these clickbaitdetection models will provide a fundamental basis for future research intodetecting clickbait titles in Bengali articles. We have released thecorresponding code and dataset.</description><author>Md. Motahar Mahtab, Monirul Haque, Mehedi Hasan, Farig Sadeque</author><pubDate>Fri, 10 Nov 2023 17:38:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06204v1</guid></item><item><title>Neural Control of Parametric Solutions for High-dimensional Evolution PDEs</title><link>http://arxiv.org/abs/2302.00045v2</link><description>We develop a novel computational framework to approximate solution operatorsof evolution partial differential equations (PDEs). By employing a generalnonlinear reduced-order model, such as a deep neural network, to approximatethe solution of a given PDE, we realize that the evolution of the modelparameter is a control problem in the parameter space. Based on thisobservation, we propose to approximate the solution operator of the PDE bylearning the control vector field in the parameter space. From any initialvalue, this control field can steer the parameter to generate a trajectory suchthat the corresponding reduced-order model solves the PDE. This allows forsubstantially reduced computational cost to solve the evolution PDE witharbitrary initial conditions. We also develop comprehensive error analysis forthe proposed method when solving a large class of semilinear parabolic PDEs.Numerical experiments on different high-dimensional evolution PDEs with variousinitial conditions demonstrate the promising results of the proposed method.</description><author>Nathan Gaby, Xiaojing Ye, Haomin Zhou</author><pubDate>Fri, 10 Nov 2023 17:28:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00045v2</guid></item><item><title>Greedy PIG: Adaptive Integrated Gradients</title><link>http://arxiv.org/abs/2311.06192v1</link><description>Deep learning has become the standard approach for most machine learningtasks. While its impact is undeniable, interpreting the predictions of deeplearning models from a human perspective remains a challenge. In contrast tomodel training, model interpretability is harder to quantify and pose as anexplicit optimization problem. Inspired by the AUC softmax information curve(AUC SIC) metric for evaluating feature attribution methods, we propose aunified discrete optimization framework for feature attribution and featureselection based on subset selection. This leads to a natural adaptivegeneralization of the path integrated gradients (PIG) method for featureattribution, which we call Greedy PIG. We demonstrate the success of Greedy PIGon a wide variety of tasks, including image feature attribution, graphcompression/explanation, and post-hoc feature selection on tabular data. Ourresults show that introducing adaptivity is a powerful and versatile method formaking attribution methods more powerful.</description><author>Kyriakos Axiotis, Sami Abu-al-haija, Lin Chen, Matthew Fahrbach, Gang Fu</author><pubDate>Fri, 10 Nov 2023 17:16:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06192v1</guid></item><item><title>Computationally-Efficient Neural Image Compression with Shallow Decoders</title><link>http://arxiv.org/abs/2304.06244v2</link><description>Neural image compression methods have seen increasingly strong performance inrecent years. However, they suffer orders of magnitude higher computationalcomplexity compared to traditional codecs, which hinders their real-worlddeployment. This paper takes a step forward towards closing this gap indecoding complexity by using a shallow or even linear decoding transformresembling that of JPEG. To compensate for the resulting drop in compressionperformance, we exploit the often asymmetrical computation budget betweenencoding and decoding, by adopting more powerful encoder networks and iterativeencoding. We theoretically formalize the intuition behind, and our experimentalresults establish a new frontier in the trade-off between rate-distortion anddecoding complexity for neural image compression. Specifically, we achieverate-distortion performance competitive with the established mean-scalehyperprior architecture of Minnen et al. (2018) at less than 50K decodingFLOPs/pixel, reducing the baseline's overall decoding complexity by 80%, orover 90% for the synthesis transform alone. Our code can be found athttps://github.com/mandt-lab/shallow-ntc.</description><author>Yibo Yang, Stephan Mandt</author><pubDate>Fri, 10 Nov 2023 17:14:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.06244v2</guid></item><item><title>FourierGNN: Rethinking Multivariate Time Series Forecasting from a Pure Graph Perspective</title><link>http://arxiv.org/abs/2311.06190v1</link><description>Multivariate time series (MTS) forecasting has shown great importance innumerous industries. Current state-of-the-art graph neural network (GNN)-basedforecasting methods usually require both graph networks (e.g., GCN) andtemporal networks (e.g., LSTM) to capture inter-series (spatial) dynamics andintra-series (temporal) dependencies, respectively. However, the uncertaincompatibility of the two networks puts an extra burden on handcrafted modeldesigns. Moreover, the separate spatial and temporal modeling naturallyviolates the unified spatiotemporal inter-dependencies in real world, whichlargely hinders the forecasting performance. To overcome these problems, weexplore an interesting direction of directly applying graph networks andrethink MTS forecasting from a pure graph perspective. We first define a noveldata structure, hypervariate graph, which regards each series value (regardlessof variates or timestamps) as a graph node, and represents sliding windows asspace-time fully-connected graphs. This perspective considers spatiotemporaldynamics unitedly and reformulates classic MTS forecasting into the predictionson hypervariate graphs. Then, we propose a novel architecture Fourier GraphNeural Network (FourierGNN) by stacking our proposed Fourier Graph Operator(FGO) to perform matrix multiplications in Fourier space. FourierGNNaccommodates adequate expressiveness and achieves much lower complexity, whichcan effectively and efficiently accomplish the forecasting. Besides, ourtheoretical analysis reveals FGO's equivalence to graph convolutions in thetime domain, which further verifies the validity of FourierGNN. Extensiveexperiments on seven datasets have demonstrated our superior performance withhigher efficiency and fewer parameters compared with state-of-the-art methods.</description><author>Kun Yi, Qi Zhang, Wei Fan, Hui He, Liang Hu, Pengyang Wang, Ning An, Longbing Cao, Zhendong Niu</author><pubDate>Fri, 10 Nov 2023 17:13:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06190v1</guid></item><item><title>Syntax-semantics interface: an algebraic model</title><link>http://arxiv.org/abs/2311.06189v1</link><description>We extend our formulation of Merge and Minimalism in terms of Hopf algebrasto an algebraic model of a syntactic-semantic interface. We show that methodsadopted in the formulation of renormalization (extraction of meaningfulphysical values) in theoretical physics are relevant to describe the extractionof meaning from syntactic expressions. We show how this formulation relates tocomputational models of semantics and we answer some recent controversies aboutimplications for generative linguistics of the current functioning of largelanguage models.</description><author>Matilde Marcolli, Robert C. Berwick, Noam Chomsky</author><pubDate>Fri, 10 Nov 2023 17:12:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06189v1</guid></item><item><title>An Automated Pipeline for Tumour-Infiltrating Lymphocyte Scoring in Breast Cancer</title><link>http://arxiv.org/abs/2311.06185v1</link><description>Tumour-infiltrating lymphocytes (TILs) are considered as a valuableprognostic markers in both triple-negative and human epidermal growth factorreceptor 2 (HER2) breast cancer. In this study, we introduce an innovative deeplearning pipeline based on the Efficient-UNet architecture to compute a TILsscore for breast cancer whole slide images. Our pipeline first segmentstumour-stroma regions and generates a tumour bulk mask. Subsequently, itdetects TILs within the tumour-associated stroma, generating a TILs score byclosely mirroring the pathologist's workflow. Our method exhibitsstate-of-the-art performance in segmenting tumour/stroma areas and TILsdetection, as demonstrated by internal cross-validation on the TiGER Challengetraining dataset and evaluation on the final leaderboards. Additionally, ourTILs score proves competitive in predicting survival outcomes within the samechallenge, underscoring the clinical relevance and potential of our automatedTILs scoring system as a breast cancer prognostic tool.</description><author>Adam J Shephard, Mostafa Jahanifar, Ruoyu Wang, Muhammad Dawood, Simon Graham, Kastytis Sidlauskas, Syed Ali Khurram, Nasir M Rajpoot, Shan E Ahmed Raza</author><pubDate>Fri, 10 Nov 2023 17:06:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06185v1</guid></item><item><title>Frequency-domain MLPs are More Effective Learners in Time Series Forecasting</title><link>http://arxiv.org/abs/2311.06184v1</link><description>Time series forecasting has played the key role in different industrial,including finance, traffic, energy, and healthcare domains. While existingliteratures have designed many sophisticated architectures based on RNNs, GNNs,or Transformers, another kind of approaches based on multi-layer perceptrons(MLPs) are proposed with simple structure, low complexity, and {superiorperformance}. However, most MLP-based forecasting methods suffer from thepoint-wise mappings and information bottleneck, which largely hinders theforecasting performance. To overcome this problem, we explore a novel directionof applying MLPs in the frequency domain for time series forecasting. Weinvestigate the learned patterns of frequency-domain MLPs and discover theirtwo inherent characteristic benefiting forecasting, (i) global view: frequencyspectrum makes MLPs own a complete view for signals and learn globaldependencies more easily, and (ii) energy compaction: frequency-domain MLPsconcentrate on smaller key part of frequency components with compact signalenergy. Then, we propose FreTS, a simple yet effective architecture built uponFrequency-domain MLPs for Time Series forecasting. FreTS mainly involves twostages, (i) Domain Conversion, that transforms time-domain signals into complexnumbers of frequency domain; (ii) Frequency Learning, that performs ourredesigned MLPs for the learning of real and imaginary part of frequencycomponents. The above stages operated on both inter-series and intra-seriesscales further contribute to channel-wise and time-wise dependency learning.Extensive experiments on 13 real-world benchmarks (including 7 benchmarks forshort-term forecasting and 6 benchmarks for long-term forecasting) demonstrateour consistent superiority over state-of-the-art methods.</description><author>Kun Yi, Qi Zhang, Wei Fan, Shoujin Wang, Pengyang Wang, Hui He, Defu Lian, Ning An, Longbing Cao, Zhendong Niu</author><pubDate>Fri, 10 Nov 2023 17:05:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06184v1</guid></item><item><title>Hopfield-Enhanced Deep Neural Networks for Artifact-Resilient Brain State Decoding</title><link>http://arxiv.org/abs/2311.03421v3</link><description>The study of brain states, ranging from highly synchronous to asynchronousneuronal patterns like the sleep-wake cycle, is fundamental for assessing thebrain's spatiotemporal dynamics and their close connection to behavior.However, the development of new techniques to accurately identify them stillremains a challenge, as these are often compromised by the presence of noise,artifacts, and suboptimal recording quality. In this study, we propose atwo-stage computational framework combining Hopfield Networks for artifact datapreprocessing with Convolutional Neural Networks (CNNs) for classification ofbrain states in rat neural recordings under different levels of anesthesia. Toevaluate the robustness of our framework, we deliberately introduced noiseartifacts into the neural recordings. We evaluated our hybrid Hopfield-CNNpipeline by benchmarking it against two comparative models: a standalone CNNhandling the same noisy inputs, and another CNN trained and tested onartifact-free data. Performance across various levels of data compression andnoise intensities showed that our framework can effectively mitigate artifacts,allowing the model to reach parity with the clean-data CNN at lower noiselevels. Although this study mainly benefits small-scale experiments, thefindings highlight the necessity for advanced deep learning and HopfieldNetwork models to improve scalability and robustness in diverse real-worldsettings.</description><author>Arnau Marin-Llobet, Arnau Manasanch, Maria V. Sanchez-Vives</author><pubDate>Fri, 10 Nov 2023 16:52:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03421v3</guid></item><item><title>State2Explanation: Concept-Based Explanations to Benefit Agent Learning and User Understanding</title><link>http://arxiv.org/abs/2309.12482v2</link><description>As more non-AI experts use complex AI systems for daily tasks, there has beenan increasing effort to develop methods that produce explanations of AIdecision making that are understandable by non-AI experts. Towards this effort,leveraging higher-level concepts and producing concept-based explanations havebecome a popular method. Most concept-based explanations have been developedfor classification techniques, and we posit that the few existing methods forsequential decision making are limited in scope. In this work, we firstcontribute a desiderata for defining concepts in sequential decision makingsettings. Additionally, inspired by the Protege Effect which states explainingknowledge often reinforces one's self-learning, we explore how concept-basedexplanations of an RL agent's decision making can in turn improve the agent'slearning rate, as well as improve end-user understanding of the agent'sdecision making. To this end, we contribute a unified framework,State2Explanation (S2E), that involves learning a joint embedding model betweenstate-action pairs and concept-based explanations, and leveraging such learnedmodel to both (1) inform reward shaping during an agent's training, and (2)provide explanations to end-users at deployment for improved task performance.Our experimental validations, in Connect 4 and Lunar Lander, demonstrate thesuccess of S2E in providing a dual-benefit, successfully informing rewardshaping and improving agent learning rate, as well as significantly improvingend user task performance at deployment time.</description><author>Devleena Das, Sonia Chernova, Been Kim</author><pubDate>Fri, 10 Nov 2023 16:51:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.12482v2</guid></item><item><title>Automatic Report Generation for Histopathology images using pre-trained Vision Transformers</title><link>http://arxiv.org/abs/2311.06176v1</link><description>Deep learning for histopathology has been successfully used for diseaseclassification, image segmentation and more. However, combining image and textmodalities using current state-of-the-art methods has been a challenge due tothe high resolution of histopathology images. Automatic report generation forhistopathology images is one such challenge. In this work, we show that usingan existing pre-trained Vision Transformer in a two-step process of first usingit to encode 4096x4096 sized patches of the Whole Slide Image (WSI) and thenusing it as the encoder and an LSTM decoder for report generation, we can builda fairly performant and portable report generation mechanism that takes intoaccount the whole of the high resolution image, instead of just the patches. Weare also able to use representations from an existing powerful pre-trainedhierarchical vision transformer and show its usefulness in not just zero shotclassification but also for report generation.</description><author>Saurav Sengupta, Donald E. Brown</author><pubDate>Fri, 10 Nov 2023 16:48:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06176v1</guid></item><item><title>Search-Based Fairness Testing: An Overview</title><link>http://arxiv.org/abs/2311.06175v1</link><description>Artificial Intelligence (AI) has demonstrated remarkable capabilities indomains such as recruitment, finance, healthcare, and the judiciary. However,biases in AI systems raise ethical and societal concerns, emphasizing the needfor effective fairness testing methods. This paper reviews current research onfairness testing, particularly its application through search-based testing.Our analysis highlights progress and identifies areas of improvement inaddressing AI systems biases. Future research should focus on leveragingestablished search-based testing methodologies for fairness testing.</description><author>Hussaini Mamman, Shuib Basri, Abdullateef Oluwaqbemiga Balogun, Abdullahi Abubakar Imam, Ganesh Kumar, Luiz Fernando Capretz</author><pubDate>Fri, 10 Nov 2023 16:47:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06175v1</guid></item><item><title>DYNAP-SE2: a scalable multi-core dynamic neuromorphic asynchronous spiking neural network processor</title><link>http://arxiv.org/abs/2310.00564v2</link><description>With the remarkable progress that technology has made, the need forprocessing data near the sensors at the edge has increased dramatically. Theelectronic systems used in these applications must process data continuously,in real-time, and extract relevant information using the smallest possibleenergy budgets. A promising approach for implementing always-on processing ofsensory signals that supports on-demand, sparse, and edge-computing is to takeinspiration from biological nervous system. Following this approach, we presenta brain-inspired platform for prototyping real-time event-based Spiking NeuralNetworks (SNNs). The system proposed supports the direct emulation of dynamicand realistic neural processing phenomena such as short-term plasticity, NMDAgating, AMPA diffusion, homeostasis, spike frequency adaptation,conductance-based dendritic compartments and spike transmission delays. Theanalog circuits that implement such primitives are paired with a low latencyasynchronous digital circuits for routing and mapping events. This asynchronousinfrastructure enables the definition of different network architectures, andprovides direct event-based interfaces to convert and encode data fromevent-based and continuous-signal sensors. Here we describe the overall systemarchitecture, we characterize the mixed signal analog-digital circuits thatemulate neural dynamics, demonstrate their features with experimentalmeasurements, and present a low- and high-level software ecosystem that can beused for configuring the system. The flexibility to emulate differentbiologically plausible neural networks, and the chip's ability to monitor bothpopulation and single neuron signals in real-time, allow to develop andvalidate complex models of neural processing for both basic research andedge-computing applications.</description><author>Ole Richter, Chenxi Wu, Adrian M. Whatley, German K√∂stinger, Carsten Nielsen, Ning Qiao, Giacomo Indiveri</author><pubDate>Fri, 10 Nov 2023 16:46:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00564v2</guid></item><item><title>Dynamic Sparsity Is Channel-Level Sparsity Learner</title><link>http://arxiv.org/abs/2305.19454v2</link><description>Sparse training has received an upsurging interest in machine learning due toits tantalizing saving potential for the entire training process as well asinference. Dynamic sparse training (DST), as a leading sparse trainingapproach, can train deep neural networks at high sparsity from scratch to matchthe performance of their dense counterparts. However, most if not all DST priorarts demonstrate their effectiveness on unstructured sparsity with highlyirregular sparse patterns, which receives limited support in common hardware.This limitation hinders the usage of DST in practice. In this paper, we proposeChannel-aware dynamic sparse (Chase), which for the first time seamlesslytranslates the promise of unstructured dynamic sparsity to GPU-friendlychannel-level sparsity (not fine-grained N:M or group sparsity) during oneend-to-end training process, without any ad-hoc operations. The resulting smallsparse networks can be directly accelerated by commodity hardware, withoutusing any particularly sparsity-aware hardware accelerators. This appealingoutcome is partially motivated by a hidden phenomenon of dynamic sparsity:off-the-shelf unstructured DST implicitly involves biased parameterreallocation across channels, with a large fraction of channels (up to 60%)being sparser than others. By progressively identifying and removing thesechannels during training, our approach translates unstructured sparsity tochannel-wise sparsity. Our experimental results demonstrate that Chase achieves1.7 X inference throughput speedup on common GPU devices without compromisingaccuracy with ResNet-50 on ImageNet. We release our codes inhttps://github.com/luuyin/chase.</description><author>Lu Yin, Gen Li, Meng Fang, Li Shen, Tianjin Huang, Zhangyang Wang, Vlado Menkovski, Xiaolong Ma, Mykola Pechenizkiy, Shiwei Liu</author><pubDate>Fri, 10 Nov 2023 16:42:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19454v2</guid></item><item><title>Time Scale Network: A Shallow Neural Network For Time Series Data</title><link>http://arxiv.org/abs/2311.06170v1</link><description>Time series data is often composed of information at multiple time scales,particularly in biomedical data. While numerous deep learning strategies existto capture this information, many make networks larger, require more data, aremore demanding to compute, and are difficult to interpret. This limits theirusefulness in real-world applications facing even modest computational or dataconstraints and can further complicate their translation into practice. Wepresent a minimal, computationally efficient Time Scale Network combining thetranslation and dilation sequence used in discrete wavelet transforms withtraditional convolutional neural networks and back-propagation. The networksimultaneously learns features at many time scales for sequence classificationwith significantly reduced parameters and operations. We demonstrate advantagesin Atrial Dysfunction detection including: superior accuracy-per-parameter andaccuracy-per-operation, fast training and inference speeds, and visualizationand interpretation of learned patterns in atrial dysfunction detection on ECGsignals. We also demonstrate impressive performance in seizure prediction usingEEG signals. Our network isolated a few time scales that could be strategicallyselected to achieve 90.9% accuracy using only 1,133 active parameters andconsistently converged on pulsatile waveform shapes. This method does not reston any constraints or assumptions regarding signal content and could beleveraged in any area of time series analysis dealing with signals containingfeatures at many time scales.</description><author>Trevor Meyer, Camden Shultz, Najim Dehak, Laureano Moro-Velazquez, Pedro Irazoqui</author><pubDate>Fri, 10 Nov 2023 16:39:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06170v1</guid></item><item><title>Deep Fast Vision: A Python Library for Accelerated Deep Transfer Learning Vision Prototyping</title><link>http://arxiv.org/abs/2311.06169v1</link><description>Deep learning-based vision is characterized by intricate frameworks thatoften necessitate a profound understanding, presenting a barrier to newcomersand limiting broad adoption. With many researchers grappling with theconstraints of smaller datasets, there's a pronounced reliance on pre-trainedneural networks, especially for tasks such as image classification. Thisreliance is further intensified in niche imaging areas where obtaining vastdatasets is challenging. Despite the widespread use of transfer learning as aremedy to the small dataset dilemma, a conspicuous absence of tailored auto-MLsolutions persists. Addressing these challenges is "Deep Fast Vision", a pythonlibrary that streamlines the deep learning process. This tool offers auser-friendly experience, enabling results through a simple nested dictionarydefinition, helping to democratize deep learning for non-experts. Designed forsimplicity and scalability, Deep Fast Vision appears as a bridge, connectingthe complexities of existing deep learning frameworks with the needs of adiverse user base.</description><author>Fabi Prezja</author><pubDate>Fri, 10 Nov 2023 16:36:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06169v1</guid></item><item><title>Language Models can be Logical Solvers</title><link>http://arxiv.org/abs/2311.06158v1</link><description>Logical reasoning is a fundamental aspect of human intelligence and a keycomponent of tasks like problem-solving and decision-making. Recentadvancements have enabled Large Language Models (LLMs) to potentially exhibitreasoning capabilities, but complex logical reasoning remains a challenge. Thestate-of-the-art, solver-augmented language models, use LLMs to parse naturallanguage logical questions into symbolic representations first and then adoptexternal logical solvers to take in the symbolic representations and output theanswers. Despite their impressive performance, any parsing errors willinevitably result in the failure of the execution of the external logicalsolver and no answer to the logical questions. In this paper, we introduceLoGiPT, a novel language model that directly emulates the reasoning processesof logical solvers and bypasses the parsing errors by learning to strictadherence to solver syntax and grammar. LoGiPT is fine-tuned on a newlyconstructed instruction-tuning dataset derived from revealing and refining theinvisible reasoning process of deductive solvers. Experimental results on twopublic deductive reasoning datasets demonstrate that LoGiPT outperformsstate-of-the-art solver-augmented LMs and few-shot prompting methods oncompetitive LLMs like ChatGPT or GPT-4.</description><author>Jiazhan Feng, Ruochen Xu, Junheng Hao, Hiteshi Sharma, Yelong Shen, Dongyan Zhao, Weizhu Chen</author><pubDate>Fri, 10 Nov 2023 16:23:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06158v1</guid></item><item><title>MFT: Long-Term Tracking of Every Pixel</title><link>http://arxiv.org/abs/2305.12998v2</link><description>We propose MFT -- Multi-Flow dense Tracker -- a novel method for dense,pixel-level, long-term tracking. The approach exploits optical flows estimatednot only between consecutive frames, but also for pairs of frames atlogarithmically spaced intervals. It selects the most reliable sequence offlows on the basis of estimates of its geometric accuracy and the probabilityof occlusion, both provided by a pre-trained CNN. We show that MFT achievescompetitive performance on the TAP-Vid benchmark, outperforming baselines by asignificant margin, and tracking densely orders of magnitude faster than thestate-of-the-art point-tracking methods. The method is insensitive tomedium-length occlusions and it is robustified by estimating flow with respectto the reference frame, which reduces drift.</description><author>Michal Neoral, Jon√°≈° ≈†er√Ωch, Ji≈ô√≠ Matas</author><pubDate>Fri, 10 Nov 2023 16:21:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.12998v2</guid></item><item><title>Challenging Common Assumptions in Multi-task Learning</title><link>http://arxiv.org/abs/2311.04698v2</link><description>While multi-task learning (MTL) has gained significant attention in recentyears, its underlying mechanisms remain poorly understood. Recent methods didnot yield consistent performance improvements over single task learning (STL)baselines, underscoring the importance of gaining more profound insights aboutchallenges specific to MTL. In our study, we challenge common assumptions inMTL in the context of STL: First, the choice of optimizer has only been mildlyinvestigated in MTL. We show the pivotal role of common STL tools such as theAdam optimizer in MTL. We deduce the effectiveness of Adam to its partialloss-scale invariance. Second, the notion of gradient conflicts has often beenphrased as a specific problem in MTL. We delve into the role of gradientconflicts in MTL and compare it to STL. For angular gradient alignment we findno evidence that this is a unique problem in MTL. We emphasize differences ingradient magnitude as the main distinguishing factor. Lastly, we compare thetransferability of features learned through MTL and STL on common imagecorruptions, and find no conclusive evidence that MTL leads to superiortransferability. Overall, we find surprising similarities between STL and MTLsuggesting to consider methods from both fields in a broader context.</description><author>Cathrin Elich, Lukas Kirchdorfer, Jan M. K√∂hler, Lukas Schott</author><pubDate>Fri, 10 Nov 2023 16:19:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.04698v2</guid></item><item><title>Interpretable Graph Anomaly Detection using Gradient Attention Maps</title><link>http://arxiv.org/abs/2311.06153v1</link><description>Detecting unusual patterns in graph data is a crucial task in data mining.However, existing methods often face challenges in consistently achievingsatisfactory performance and lack interpretability, which hinders ourunderstanding of anomaly detection decisions. In this paper, we propose a novelapproach to graph anomaly detection that leverages the power ofinterpretability to enhance performance. Specifically, our method extracts anattention map derived from gradients of graph neural networks, which serves asa basis for scoring anomalies. In addition, we conduct theoretical analysisusing synthetic data to validate our method and gain insights into itsdecision-making process. To demonstrate the effectiveness of our method, weextensively evaluate our approach against state-of-the-art graph anomalydetection techniques. The results consistently demonstrate the superiorperformance of our method compared to the baselines.</description><author>Yifei Yang, Peng Wang, Xiaofan He, Dongmian Zou</author><pubDate>Fri, 10 Nov 2023 16:14:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06153v1</guid></item><item><title>An Improved Relaxation for Oracle-Efficient Adversarial Contextual Bandits</title><link>http://arxiv.org/abs/2310.19025v2</link><description>We present an oracle-efficient relaxation for the adversarial contextualbandits problem, where the contexts are sequentially drawn i.i.d from a knowndistribution and the cost sequence is chosen by an online adversary. Ouralgorithm has a regret bound of$O(T^{\frac{2}{3}}(K\log(|\Pi|))^{\frac{1}{3}})$ and makes at most $O(K)$ callsper round to an offline optimization oracle, where $K$ denotes the number ofactions, $T$ denotes the number of rounds and $\Pi$ denotes the set ofpolicies. This is the first result to improve the prior best bound of$O((TK)^{\frac{2}{3}}(\log(|\Pi|))^{\frac{1}{3}})$ as obtained by Syrgkanis etal. at NeurIPS 2016, and the first to match the original bound of Langford andZhang at NeurIPS 2007 which was obtained for the stochastic case.</description><author>Kiarash Banihashem, MohammadTaghi Hajiaghayi, Suho Shin, Max Springer</author><pubDate>Fri, 10 Nov 2023 16:14:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19025v2</guid></item><item><title>Going beyond persistent homology using persistent homology</title><link>http://arxiv.org/abs/2311.06152v1</link><description>Representational limits of message-passing graph neural networks (MP-GNNs),e.g., in terms of the Weisfeiler-Leman (WL) test for isomorphism, are wellunderstood. Augmenting these graph models with topological features viapersistent homology (PH) has gained prominence, but identifying the class ofattributed graphs that PH can recognize remains open. We introduce a novelconcept of color-separating sets to provide a complete resolution to thisimportant problem. Specifically, we establish the necessary and sufficientconditions for distinguishing graphs based on the persistence of theirconnected components, obtained from filter functions on vertex and edge colors.Our constructions expose the limits of vertex- and edge-level PH, proving thatneither category subsumes the other. Leveraging these theoretical insights, wepropose RePHINE for learning topological features on graphs. RePHINEefficiently combines vertex- and edge-level PH, achieving a scheme that isprovably more powerful than both. Integrating RePHINE into MP-GNNs boosts theirexpressive power, resulting in gains over standard PH on several benchmarks forgraph classification.</description><author>Johanna Immonen, Amauri H. Souza, Vikas Garg</author><pubDate>Fri, 10 Nov 2023 16:12:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06152v1</guid></item><item><title>Dense Visual Odometry Using Genetic Algorithm</title><link>http://arxiv.org/abs/2311.06149v1</link><description>Our work aims to estimate the camera motion mounted on the head of a mobilerobot or a moving object from RGB-D images in a static scene. The problem ofmotion estimation is transformed into a nonlinear least squares function.Methods for solving such problems are iterative. Various classic methods gavean iterative solution by linearizing this function. We can also use themetaheuristic optimization method to solve this problem and improve results. Inthis paper, a new algorithm is developed for visual odometry using a sequenceof RGB-D images. This algorithm is based on a genetic algorithm. The proposediterative genetic algorithm searches using particles to estimate the optimalmotion and then compares it to the traditional methods. To evaluate our method,we use the root mean square error to compare it with the based energy methodand another metaheuristic method. We prove the efficiency of our innovativealgorithm on a large set of images.</description><author>Slimane Djema, Zoubir Abdeslem Benselama, Ramdane Hedjar, Krabi Abdallah</author><pubDate>Fri, 10 Nov 2023 16:09:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06149v1</guid></item><item><title>Incorporating sufficient physical information into artificial neural networks: a guaranteed improvement via physics-based Rao-Blackwellization</title><link>http://arxiv.org/abs/2311.06147v1</link><description>The concept of Rao-Blackwellization is employed to improve predictions ofartificial neural networks by physical information. The error norm and theproof of improvement are transferred from the original statistical concept to adeterministic one, using sufficient information on physics-based conditions.The proposed strategy is applied to material modeling and illustrated byexamples of the identification of a yield function, elasto-plastic steelsimulations, the identification of driving forces for quasi-brittle damage andrubber experiments. Sufficient physical information is employed, e.g., in theform of invariants, parameters of a minimization problem, dimensional analysis,isotropy and differentiability. It is proven how intuitive accretion ofinformation can yield improvement if it is physically sufficient, but also howinsufficient or superfluous information can cause impairment. Opportunities forthe improvement of artificial neural networks are explored in terms of thetraining data set, the networks' structure and output filters. Even crudeinitial predictions are remarkably improved by reducing noise, overfitting anddata requirements.</description><author>Gian-Luca Geuken, J√∂rn Mosler, Patrick Kurzeja</author><pubDate>Fri, 10 Nov 2023 16:05:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06147v1</guid></item><item><title>An Evaluation of Forensic Facial Recognition</title><link>http://arxiv.org/abs/2311.06145v1</link><description>Recent advances in machine learning and computer vision have led to reportedfacial recognition accuracies surpassing human performance. We question ifthese systems will translate to real-world forensic scenarios in which apotentially low-resolution, low-quality, partially-occluded image is comparedagainst a standard facial database. We describe the construction of alarge-scale synthetic facial dataset along with a controlled facial forensiclineup, the combination of which allows for a controlled evaluation of facialrecognition under a range of real-world conditions. Using this syntheticdataset, and a popular dataset of real faces, we evaluate the accuracy of twopopular neural-based recognition systems. We find that previously reported facerecognition accuracies of more than 95% drop to as low as 65% in this morechallenging forensic scenario.</description><author>Justin Norman, Shruti Agarwal, Hany Farid</author><pubDate>Fri, 10 Nov 2023 16:02:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06145v1</guid></item><item><title>Astrocytes as a mechanism for meta-plasticity and contextually-guided network function</title><link>http://arxiv.org/abs/2311.03508v2</link><description>Astrocytes are a ubiquitous and enigmatic type of non-neuronal cell and arefound in the brain of all vertebrates. While traditionally viewed as beingsupportive of neurons, it is increasingly recognized that astrocytes may play amore direct and active role in brain function and neural computation. Onaccount of their sensitivity to a host of physiological covariates and abilityto modulate neuronal activity and connectivity on slower time scales,astrocytes may be particularly well poised to modulate the dynamics of neuralcircuits in functionally salient ways. In the current paper, we seek to capturethese features via actionable abstractions within computational models ofneuron-astrocyte interaction. Specifically, we engage how nested feedback loopsof neuron-astrocyte interaction, acting over separated time-scales may endowastrocytes with the capability to enable learning in context-dependentsettings, where fluctuations in task parameters may occur much more slowly thanwithin-task requirements. We pose a general model of neuron-synapse-astrocyteinteraction and use formal analysis to characterize how astrocytic modulationmay constitute a form of meta-plasticity, altering the ways in which synapsesand neurons adapt as a function of time. We then embed this model in abandit-based reinforcement learning task environment, and show how the presenceof time-scale separated astrocytic modulation enables learning over multiplefluctuating contexts. Indeed, these networks learn far more reliably versusdynamically homogeneous networks and conventional non-network-based banditalgorithms. Our results indicate how the presence of neuron-astrocyteinteraction in the brain may benefit learning over different time-scales andthe conveyance of task-relevant contextual information onto circuit dynamics.</description><author>Lulu Gong, Fabio Pasqualetti, Thomas Papouin, ShiNung Ching</author><pubDate>Fri, 10 Nov 2023 15:59:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03508v2</guid></item><item><title>Federated Learning Across Decentralized and Unshared Archives for Remote Sensing Image Classification</title><link>http://arxiv.org/abs/2311.06141v1</link><description>Federated learning (FL) enables the collaboration of multiple deep learningmodels to learn from decentralized data archives (i.e., clients) withoutaccessing data on clients. Although FL offers ample opportunities in knowledgediscovery from distributed image archives, it is seldom considered in remotesensing (RS). In this paper, as a first time in RS, we present a comparativestudy of state-of-the-art FL algorithms. To this end, we initially provide asystematic review of the FL algorithms presented in the computer visioncommunity for image classification problems, and select severalstate-of-the-art FL algorithms based on their effectiveness with respect totraining data heterogeneity across clients (known as non-IID data). Afterpresenting an extensive overview of the selected algorithms, a theoreticalcomparison of the algorithms is conducted based on their: 1) local trainingcomplexity; 2) aggregation complexity; 3) learning efficiency; 4) communicationcost; and 5) scalability in terms of number of clients. As the classificationtask, we consider multi-label classification (MLC) problem since RS imagestypically consist of multiple classes, and thus can simultaneously beassociated with multi-labels. After the theoretical comparison, experimentalanalyses are presented to compare them under different decentralizationscenarios in terms of MLC performance. Based on our comprehensive analyses, wefinally derive a guideline for selecting suitable FL algorithms in RS. The codeof this work will be publicly available at https://git.tu-berlin.de/rsim/FL-RS.</description><author>Barƒ±≈ü B√ºy√ºkta≈ü, Gencer Sumbul, Beg√ºm Demir</author><pubDate>Fri, 10 Nov 2023 15:58:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06141v1</guid></item><item><title>Minimum norm interpolation by perceptra: Explicit regularization and implicit bias</title><link>http://arxiv.org/abs/2311.06138v1</link><description>We investigate how shallow ReLU networks interpolate between known regions.Our analysis shows that empirical risk minimizers converge to a minimum norminterpolant as the number of data points and parameters tends to infinity whena weight decay regularizer is penalized with a coefficient which vanishes at aprecise rate as the network width and the number of data points grow. With andwithout explicit regularization, we numerically study the implicit bias ofcommon optimization algorithms towards known minimum norm interpolants.</description><author>Jiyoung Park, Ian Pelakh, Stephan Wojtowytsch</author><pubDate>Fri, 10 Nov 2023 15:55:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06138v1</guid></item><item><title>MonoProb: Self-Supervised Monocular Depth Estimation with Interpretable Uncertainty</title><link>http://arxiv.org/abs/2311.06137v1</link><description>Self-supervised monocular depth estimation methods aim to be used in criticalapplications such as autonomous vehicles for environment analysis. Tocircumvent the potential imperfections of these approaches, a quantification ofthe prediction confidence is crucial to guide decision-making systems that relyon depth estimation. In this paper, we propose MonoProb, a new unsupervisedmonocular depth estimation method that returns an interpretable uncertainty,which means that the uncertainty reflects the expected error of the network inits depth predictions. We rethink the stereo or the structure-from-motionparadigms used to train unsupervised monocular depth models as a probabilisticproblem. Within a single forward pass inference, this model provides a depthprediction and a measure of its confidence, without increasing the inferencetime. We then improve the performance on depth and uncertainty with a novelself-distillation loss for which a student is supervised by a pseudo groundtruth that is a probability distribution on depth output by a teacher. Toquantify the performance of our models we design new metrics that, unliketraditional ones, measure the absolute performance of uncertainty predictions.Our experiments highlight enhancements achieved by our method on standard depthand uncertainty metrics as well as on our tailored metrics.https://github.com/CEA-LIST/MonoProb</description><author>Remi Marsal Florian Chabot, Angelique Loesch, William Grolleau, Hichem Sahbi</author><pubDate>Fri, 10 Nov 2023 15:55:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06137v1</guid></item><item><title>An empirical evaluation of imbalanced data strategies from a practitioner's point of view</title><link>http://arxiv.org/abs/1810.07168v2</link><description>This paper evaluates six strategies for mitigating imbalanced data:oversampling, undersampling, ensemble methods, specialized algorithms, classweight adjustments, and a no-mitigation approach referred to as the baseline.These strategies were tested on 58 real-life binary imbalanced datasets withimbalance rates ranging from 3 to 120. We conducted a comparative analysis of10 under-sampling algorithms, 5 over-sampling algorithms, 2 ensemble methods,and 3 specialized algorithms across eight different performance metrics:accuracy, area under the ROC curve (AUC), balanced accuracy, F1-measure,G-mean, Matthew's correlation coefficient, precision, and recall. Additionally,we assessed the six strategies on altered datasets, derived from real-lifedata, with both low (3) and high (100 or 300) imbalance ratios (IR). The principal finding indicates that the effectiveness of each strategysignificantly varies depending on the metric used. The paper also examines aselection of newer algorithms within the categories of specialized algorithms,oversampling, and ensemble methods. The findings suggest that the currenthierarchy of best-performing strategies for each metric is unlikely to changewith the introduction of newer algorithms.</description><author>Jacques Wainer</author><pubDate>Fri, 10 Nov 2023 15:54:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1810.07168v2</guid></item><item><title>Outage-Watch: Early Prediction of Outages using Extreme Event Regularizer</title><link>http://arxiv.org/abs/2309.17340v2</link><description>Cloud services are omnipresent and critical cloud service failure is a factof life. In order to retain customers and prevent revenue loss, it is importantto provide high reliability guarantees for these services. One way to do thisis by predicting outages in advance, which can help in reducing the severity aswell as time to recovery. It is difficult to forecast critical failures due tothe rarity of these events. Moreover, critical failures are ill-defined interms of observable data. Our proposed method, Outage-Watch, defines criticalservice outages as deteriorations in the Quality of Service (QoS) captured by aset of metrics. Outage-Watch detects such outages in advance by using currentsystem state to predict whether the QoS metrics will cross a threshold andinitiate an extreme event. A mixture of Gaussian is used to model thedistribution of the QoS metrics for flexibility and an extreme eventregularizer helps in improving learning in tail of the distribution. An outageis predicted if the probability of any one of the QoS metrics crossingthreshold changes significantly. Our evaluation on a real-world SaaS companydataset shows that Outage-Watch significantly outperforms traditional methodswith an average AUC of 0.98. Additionally, Outage-Watch detects all the outagesexhibiting a change in service metrics and reduces the Mean Time To Detection(MTTD) of outages by up to 88% when deployed in an enterprise cloud-servicesystem, demonstrating efficacy of our proposed method.</description><author>Shubham Agarwal, Sarthak Chakraborty, Shaddy Garg, Sumit Bisht, Chahat Jain, Ashritha Gonuguntla, Shiv Saini</author><pubDate>Fri, 10 Nov 2023 15:51:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17340v2</guid></item><item><title>High-dimensional mixed-categorical Gaussian processes with application to multidisciplinary design optimization for a green aircraft</title><link>http://arxiv.org/abs/2311.06130v1</link><description>Multidisciplinary design optimization (MDO) methods aim at adapting numericaloptimization techniques to the design of engineering systems involving multipledisciplines. In this context, a large number of mixed continuous, integer, andcategorical variables might arise during the optimization process, andpractical applications involve a significant number of design variables.Recently, there has been a growing interest in mixed-categorical metamodelsbased on Gaussian Process (GP) for Bayesian optimization. In particular, tohandle mixed-categorical variables, several existing approaches employdifferent strategies to build the GP. These strategies either use continuouskernels, such as the continuous relaxation or the Gower distance-based kernels,or direct estimation of the correlation matrix, such as the exponentialhomoscedastic hypersphere (EHH) or the Homoscedastic Hypersphere (HH) kernel.Although the EHH and HH kernels are shown to be very efficient and lead toaccurate GPs, they are based on a large number of hyperparameters. In thispaper, we address this issue by constructing mixed-categorical GPs with fewerhyperparameters using Partial Least Squares (PLS) regression. Our goal is togeneralize Kriging with PLS, commonly used for continuous inputs, to handlemixed-categorical inputs. The proposed method is implemented in the open-sourcesoftware SMT and has been efficiently applied to structural andmultidisciplinary applications. Our method is used to effectively demonstratethe structural behavior of a cantilever beam and facilitates MDO of a greenaircraft, resulting in a 439-kilogram reduction in the amount of fuel consumedduring a single aircraft mission.</description><author>Paul Saves, Youssef Diouane, Nathalie Bartoli, Thierry Lefebvre, Joseph Morlier</author><pubDate>Fri, 10 Nov 2023 15:48:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06130v1</guid></item><item><title>Fight Fire with Fire: Combating Adversarial Patch Attacks using Pattern-randomized Defensive Patches</title><link>http://arxiv.org/abs/2311.06122v1</link><description>Object detection has found extensive applications in various tasks, but it isalso susceptible to adversarial patch attacks. Existing defense methods oftennecessitate modifications to the target model or result in unacceptable timeoverhead. In this paper, we adopt a counterattack approach, following theprinciple of "fight fire with fire," and propose a novel and generalmethodology for defending adversarial attacks. We utilize an active defensestrategy by injecting two types of defensive patches, canary and woodpecker,into the input to proactively probe or weaken potential adversarial patcheswithout altering the target model. Moreover, inspired by randomizationtechniques employed in software security, we employ randomized canary andwoodpecker injection patterns to defend against defense-aware attacks. Theeffectiveness and practicality of the proposed method are demonstrated throughcomprehensive experiments. The results illustrate that canary and woodpeckerachieve high performance, even when confronted with unknown attack methods,while incurring limited time overhead. Furthermore, our method also exhibitssufficient robustness against defense-aware attacks, as evidenced by adaptiveattack experiments.</description><author>Jianan Feng, Jiachun Li, Changqing Miao, Jianjun Huang, Wei You, Wenchang Shi, Bin Liang</author><pubDate>Fri, 10 Nov 2023 15:36:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06122v1</guid></item><item><title>Is it indeed bigger better? The comprehensive study of claim detection LMs applied for disinformation tackling</title><link>http://arxiv.org/abs/2311.06121v1</link><description>This study compares the performance of (1) fine-tuned models and (2)extremely large language models on the task of check-worthy claim detection.For the purpose of the comparison we composed a multilingual and multi-topicaldataset comprising texts of various sources and styles. Building on this, weperformed a benchmark analysis to determine the most general multilingual andmulti-topical claim detector. We chose three state-of-the-art models in the check-worthy claim detectiontask and fine-tuned them. Furthermore, we selected three state-of-the-artextremely large language models without any fine-tuning. We made modificationsto the models to adapt them for multilingual settings and through extensiveexperimentation and evaluation. We assessed the performance of all the modelsin terms of accuracy, recall, and F1-score in in-domain and cross-domainscenarios. Our results demonstrate that despite the technological progress inthe area of natural language processing, the models fine-tuned for the task ofcheck-worthy claim detection still outperform the zero-shot approaches in across-domain settings.</description><author>Martin Hyben, Sebastian Kula, Ivan Srba, Robert Moro, Jakub Simko</author><pubDate>Fri, 10 Nov 2023 15:36:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06121v1</guid></item><item><title>Exploring the Efficacy of Base Data Augmentation Methods in Deep Learning-Based Radiograph Classification of Knee Joint Osteoarthritis</title><link>http://arxiv.org/abs/2311.06118v1</link><description>Diagnosing knee joint osteoarthritis (KOA), a major cause of disabilityworldwide, is challenging due to subtle radiographic indicators and the variedprogression of the disease. Using deep learning for KOA diagnosis requiresbroad, comprehensive datasets. However, obtaining these datasets posessignificant challenges due to patient privacy concerns and data collectionrestrictions. Additive data augmentation, which enhances data variability,emerges as a promising solution. Yet, it's unclear which augmentationtechniques are most effective for KOA. This study explored various dataaugmentation methods, including adversarial augmentations, and their impact onKOA classification model performance. While some techniques improvedperformance, others commonly used underperformed. We identified potentialconfounding regions within the images using adversarial augmentation. This wasevidenced by our models' ability to classify KL0 and KL4 grades accurately,with the knee joint omitted. This observation suggested a model bias, whichmight leverage unrelated features for classification currently present inradiographs. Interestingly, removing the knee joint also led to an unexpectedimprovement in KL1 classification accuracy. To better visualize theseparadoxical effects, we employed Grad-CAM, highlighting the associated regions.Our study underscores the need for careful technique selection for improvedmodel performance and identifying and managing potential confounding regions inradiographic KOA deep learning.</description><author>Fabi Prezja, Leevi Annala, Sampsa Kiiskinen, Timo Ojala</author><pubDate>Fri, 10 Nov 2023 15:35:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06118v1</guid></item><item><title>HoloNets: Spectral Convolutions do extend to Directed Graphs</title><link>http://arxiv.org/abs/2310.02232v2</link><description>Within the graph learning community, conventional wisdom dictates thatspectral convolutional networks may only be deployed on undirected graphs: Onlythere could the existence of a well-defined graph Fourier transform beguaranteed, so that information may be translated between spatial- and spectraldomains. Here we show this traditional reliance on the graph Fourier transformto be superfluous and -- making use of certain advanced tools from complexanalysis and spectral theory -- extend spectral convolutions to directedgraphs. We provide a frequency-response interpretation of newly developedfilters, investigate the influence of the basis used to express filters anddiscuss the interplay with characteristic operators on which networks arebased. In order to thoroughly test the developed theory, we conduct experimentsin real world settings, showcasing that directed spectral convolutionalnetworks provide new state of the art results for heterophilic nodeclassification on many datasets and -- as opposed to baselines -- may berendered stable to resolution-scale varying topological perturbations.</description><author>Christian Koke, Daniel Cremers</author><pubDate>Fri, 10 Nov 2023 15:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02232v2</guid></item><item><title>Distributionally Robust Skeleton Learning of Discrete Bayesian Networks</title><link>http://arxiv.org/abs/2311.06117v1</link><description>We consider the problem of learning the exact skeleton of general discreteBayesian networks from potentially corrupted data. Building on distributionallyrobust optimization and a regression approach, we propose to optimize the mostadverse risk over a family of distributions within bounded Wasserstein distanceor KL divergence to the empirical distribution. The worst-case risk accountsfor the effect of outliers. The proposed approach applies for generalcategorical random variables without assuming faithfulness, an ordinalrelationship or a specific form of conditional distribution. We presentefficient algorithms and show the proposed methods are closely related to thestandard regularized regression approach. Under mild assumptions, we derivenon-asymptotic guarantees for successful structure learning with logarithmicsample complexities for bounded-degree graphs. Numerical study on synthetic andreal datasets validates the effectiveness of our method. Code is available athttps://github.com/DanielLeee/drslbn.</description><author>Yeshu Li, Brian D. Ziebart</author><pubDate>Fri, 10 Nov 2023 15:33:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06117v1</guid></item><item><title>LExecutor: Learning-Guided Execution</title><link>http://arxiv.org/abs/2302.02343v4</link><description>Executing code is essential for various program analysis tasks, e.g., todetect bugs that manifest through exceptions or to obtain execution traces forfurther dynamic analysis. However, executing an arbitrary piece of code isoften difficult in practice, e.g., because of missing variable definitions,missing user inputs, and missing third-party dependencies. This paper presentsLExecutor, a learning-guided approach for executing arbitrary code snippets inan underconstrained way. The key idea is to let a neural model predict missingvalues that otherwise would cause the program to get stuck, and to inject thesevalues into the execution. For example, LExecutor injects likely values forotherwise undefined variables and likely return values of calls to otherwisemissing functions. We evaluate the approach on Python code from popularopen-source projects and on code snippets extracted from Stack Overflow. Theneural model predicts realistic values with an accuracy between 79.5% and98.2%, allowing LExecutor to closely mimic real executions. As a result, theapproach successfully executes significantly more code than any availabletechnique, such as simply executing the code as-is. For example, executing theopen-source code snippets as-is covers only 4.1% of all lines, because the codecrashes early on, whereas LExecutor achieves a coverage of 51.6%.</description><author>Beatriz Souza, Michael Pradel</author><pubDate>Fri, 10 Nov 2023 15:30:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02343v4</guid></item><item><title>Turbulence Scaling from Deep Learning Diffusion Generative Models</title><link>http://arxiv.org/abs/2311.06112v1</link><description>Complex spatial and temporal structures are inherent characteristics ofturbulent fluid flows and comprehending them poses a major challenge. Thiscomprehesion necessitates an understanding of the space of turbulent fluid flowconfigurations. We employ a diffusion-based generative model to learn thedistribution of turbulent vorticity profiles and generate snapshots ofturbulent solutions to the incompressible Navier-Stokes equations. We considerthe inverse cascade in two spatial dimensions and generate diverse turbulentsolutions that differ from those in the training dataset. We analyze thestatistical scaling properties of the new turbulent profiles, calculate theirstructure functions, energy power spectrum, velocity probability distributionfunction and moments of local energy dissipation. All the learnt scalingexponents are consistent with the expected Kolmogorov scaling and have lowererrors than the training ones. This agreement with established turbulencecharacteristics provides strong evidence of the model's capability to captureessential features of real-world turbulence.</description><author>Tim Whittaker, Romuald A. Janik, Yaron Oz</author><pubDate>Fri, 10 Nov 2023 15:27:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06112v1</guid></item><item><title>An Interpretable Machine Learning Framework to Understand Bikeshare Demand before and during the COVID-19 Pandemic in New York City</title><link>http://arxiv.org/abs/2311.06110v1</link><description>In recent years, bikesharing systems have become increasingly popular asaffordable and sustainable micromobility solutions. Advanced mathematicalmodels such as machine learning are required to generate good forecasts forbikeshare demand. To this end, this study proposes a machine learning modelingframework to estimate hourly demand in a large-scale bikesharing system. TwoExtreme Gradient Boosting models were developed: one using data from before theCOVID-19 pandemic (March 2019 to February 2020) and the other using data fromduring the pandemic (March 2020 to February 2021). Furthermore, a modelinterpretation framework based on SHapley Additive exPlanations wasimplemented. Based on the relative importance of the explanatory variablesconsidered in this study, share of female users and hour of day were the twomost important explanatory variables in both models. However, the monthvariable had higher importance in the pandemic model than in the pre-pandemicmodel.</description><author>Majbah Uddin, Ho-Ling Hwang, Md Sami Hasnine</author><pubDate>Fri, 10 Nov 2023 15:24:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06110v1</guid></item><item><title>Nonparametric consistency for maximum likelihood estimation and clustering based on mixtures of elliptically-symmetric distributions</title><link>http://arxiv.org/abs/2311.06108v1</link><description>The consistency of the maximum likelihood estimator for mixtures ofelliptically-symmetric distributions for estimating its population version isshown, where the underlying distribution $P$ is nonparametric and does notnecessarily belong to the class of mixtures on which the estimator is based. Ina situation where $P$ is a mixture of well enough separated but nonparametricdistributions it is shown that the components of the population version of theestimator correspond to the well separated components of $P$. This providessome theoretical justification for the use of such estimators for clusteranalysis in case that $P$ has well separated subpopulations even if thesesubpopulations differ from what the mixture model assumes.</description><author>Pietro Coretto, Christian Hennig</author><pubDate>Fri, 10 Nov 2023 15:20:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06108v1</guid></item><item><title>1-Lipschitz Neural Networks are more expressive with N-Activations</title><link>http://arxiv.org/abs/2311.06103v1</link><description>A crucial property for achieving secure, trustworthy and interpretable deeplearning systems is their robustness: small changes to a system's inputs shouldnot result in large changes to its outputs. Mathematically, this means onestrives for networks with a small Lipschitz constant. Several recent works havefocused on how to construct such Lipschitz networks, typically by imposingconstraints on the weight matrices. In this work, we study an orthogonalaspect, namely the role of the activation function. We show that commonly usedactivation functions, such as MaxMin, as well as all piece-wise linear oneswith two segments unnecessarily restrict the class of representable functions,even in the simplest one-dimensional setting. We furthermore introduce the newN-activation function that is provably more expressive than currently popularactivation functions. We provide code athttps://github.com/berndprach/NActivation.</description><author>Bernd Prach, Christoph H. Lampert</author><pubDate>Fri, 10 Nov 2023 15:12:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06103v1</guid></item><item><title>Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking</title><link>http://arxiv.org/abs/2311.06102v1</link><description>Standard Full-Data classifiers in NLP demand thousands of labeled examples,which is impractical in data-limited domains. Few-shot methods offer analternative, utilizing contrastive learning techniques that can be effectivewith as little as 20 examples per class. Similarly, Large Language Models(LLMs) like GPT-4 can perform effectively with just 1-5 examples per class.However, the performance-cost trade-offs of these methods remain underexplored,a critical concern for budget-limited organizations. Our work addresses thisgap by studying the aforementioned approaches over the Banking77 financialintent detection dataset, including the evaluation of cutting-edge LLMs byOpenAI, Cohere, and Anthropic in a comprehensive set of few-shot scenarios. Wecomplete the picture with two additional methods: first, a cost-effectivequerying method for LLMs based on retrieval-augmented generation (RAG), able toreduce operational costs multiple times compared to classic few-shotapproaches, and second, a data augmentation method using GPT-4, able to improveperformance in data-limited scenarios. Finally, to inspire future research, weprovide a human expert's curated subset of Banking77, along with extensiveerror analysis.</description><author>Lefteris Loukas, Ilias Stogiannidis, Odysseas Diamantopoulos, Prodromos Malakasiotis, Stavros Vassos</author><pubDate>Fri, 10 Nov 2023 15:10:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06102v1</guid></item><item><title>In-Context Learning for MIMO Equalization Using Transformer-Based Sequence Models</title><link>http://arxiv.org/abs/2311.06101v1</link><description>Large pre-trained sequence models, such as transformer-based architectures,have been recently shown to have the capacity to carry out in-context learning(ICL). In ICL, a decision on a new input is made via a direct mapping of theinput and of a few examples from the given task, serving as the task's context,to the output variable. No explicit updates of model parameters are needed totailor the decision to a new task. Pre-training, which amounts to a form ofmeta-learning, is based on the observation of examples from several relatedtasks. Prior work has shown ICL capabilities for linear regression. In thisstudy, we leverage ICL to address the inverse problem of multiple-input andmultiple-output (MIMO) equalization based on a context given by pilot symbols.A task is defined by the unknown fading channel and by the signal-to-noiseratio (SNR) level, which may be known. To highlight the practical potential ofthe approach, we allow for the presence of quantization of the receivedsignals. We demonstrate via numerical results that transformer-based ICL has athreshold behavior, whereby, as the number of pre-training tasks grows, theperformance switches from that of a minimum mean squared error (MMSE) equalizerwith a prior determined by the pre-trained tasks to that of an MMSE equalizerwith the true data-generating prior.</description><author>Matteo Zecchin, Kai Yu, Osvaldo Simeone</author><pubDate>Fri, 10 Nov 2023 15:09:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06101v1</guid></item><item><title>SeUNet-Trans: A Simple yet Effective UNet-Transformer Model for Medical Image Segmentation</title><link>http://arxiv.org/abs/2310.09998v3</link><description>Automated medical image segmentation is becoming increasingly crucial tomodern clinical practice, driven by the growing demand for precise diagnosis,the push towards personalized treatment plans, and the advancements in machinelearning algorithms, especially the incorporation of deep learning methods.While convolutional neural networks (CNN) have been prevalent among thesemethods, the remarkable potential of Transformer-based models for computervision tasks is gaining more acknowledgment. To harness the advantages of bothCNN-based and Transformer-based models, we propose a simple yet effectiveUNet-Transformer (seUNet-Trans) model for medical image segmentation. In ourapproach, the UNet model is designed as a feature extractor to generatemultiple feature maps from the input images, then the maps are propagated intoa bridge layer, which is introduced to sequentially connect the UNet and theTransformer. In this stage, we approach the pixel-level embedding techniquewithout position embedding vectors, aiming to make the model more efficient.Moreover, we apply spatial-reduction attention in the Transformer to reduce thecomputational/memory overhead. By leveraging the UNet architecture and theself-attention mechanism, our model not only retains the preservation of bothlocal and global context information but also is capable of capturinglong-range dependencies between input elements. The proposed model isextensively experimented on seven medical image segmentation datasets includingpolyp segmentation to demonstrate its efficacy. Comparison with severalstate-of-the-art segmentation models on these datasets shows the superiorperformance of our proposed seUNet-Trans network.</description><author>Tan-Hanh Pham, Xianqi Li, Kim-Doang Nguyen</author><pubDate>Fri, 10 Nov 2023 15:01:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09998v3</guid></item><item><title>Dual input stream transformer for eye-tracking line assignment</title><link>http://arxiv.org/abs/2311.06095v1</link><description>We introduce a novel Dual Input Stream Transformer (DIST) for the challengingproblem of assigning fixation points from eye-tracking data collected duringpassage reading to the line of text that the reader was actually focused on.This post-processing step is crucial for analysis of the reading data due tothe presence of noise in the form of vertical drift. We evaluate DIST againstnine classical approaches on a comprehensive suite of nine diverse datasets,and demonstrate DIST's superiority. By combining multiple instances of the DISTmodel in an ensemble we achieve an average accuracy of 98.5\% across alldatasets. Our approach presents a significant step towards addressing thebottleneck of manual line assignment in reading research. Through extensivemodel analysis and ablation studies, we identify key factors that contribute toDIST's success, including the incorporation of line overlap features and theuse of a second input stream. Through evaluation on a set of diverse datasetswe demonstrate that DIST is robust to various experimental setups, making it asafe first choice for practitioners in the field.</description><author>Thomas M. Mercier, Marcin Budka, Martin R. Vasilev, Julie A. Kirkby, Bernhard Angele, Timothy J. Slattery</author><pubDate>Fri, 10 Nov 2023 14:53:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06095v1</guid></item><item><title>Automated clinical coding using off-the-shelf large language models</title><link>http://arxiv.org/abs/2310.06552v2</link><description>The task of assigning diagnostic ICD codes to patient hospital admissions istypically performed by expert human coders. Efforts towards automated ICDcoding are dominated by supervised deep learning models. However, difficultiesin learning to predict the large number of rare codes remain a barrier toadoption in clinical practice. In this work, we leverage off-the-shelfpre-trained generative large language models (LLMs) to develop a practicalsolution that is suitable for zero-shot and few-shot code assignment.Unsupervised pre-training alone does not guarantee precise knowledge of the ICDontology and specialist clinical coding task, therefore we frame the task asinformation extraction, providing a description of each coded concept andasking the model to retrieve related mentions. For efficiency, rather thaniterating over all codes, we leverage the hierarchical nature of the ICDontology to sparsely search for relevant codes. Then, in a second stage, whichwe term 'meta-refinement', we utilise GPT-4 to select a subset of the relevantlabels as predictions. We validate our method using Llama-2, GPT-3.5 and GPT-4on the CodiEsp dataset of ICD-coded clinical case documents. Our tree-searchmethod achieves state-of-the-art performance on rarer classes, achieving thebest macro-F1 of 0.225, whilst achieving slightly lower micro-F1 of 0.157,compared to 0.216 and 0.219 respectively from PLM-ICD. To the best of ourknowledge, this is the first method for automated ICD coding requiring notask-specific learning.</description><author>Joseph S. Boyle, Antanas Kascenas, Pat Lok, Maria Liakata, Alison Q. O'Neil</author><pubDate>Fri, 10 Nov 2023 14:39:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06552v2</guid></item><item><title>Taming Local Effects in Graph-based Spatiotemporal Forecasting</title><link>http://arxiv.org/abs/2302.04071v2</link><description>Spatiotemporal graph neural networks have shown to be effective in timeseries forecasting applications, achieving better performance than standardunivariate predictors in several settings. These architectures take advantageof a graph structure and relational inductive biases to learn a single (global)inductive model to predict any number of the input time series, each associatedwith a graph node. Despite the gain achieved in computational and dataefficiency w.r.t. fitting a set of local models, relying on a single globalmodel can be a limitation whenever some of the time series are generated by adifferent spatiotemporal stochastic process. The main objective of this paperis to understand the interplay between globality and locality in graph-basedspatiotemporal forecasting, while contextually proposing a methodologicalframework to rationalize the practice of including trainable node embeddings insuch architectures. We ascribe to trainable node embeddings the role ofamortizing the learning of specialized components. Moreover, embeddings allowfor 1) effectively combining the advantages of shared message-passing layerswith node-specific parameters and 2) efficiently transferring the learned modelto new node sets. Supported by strong empirical evidence, we provide insightsand guidelines for specializing graph-based models to the dynamics of each timeseries and show how this aspect plays a crucial role in obtaining accuratepredictions.</description><author>Andrea Cini, Ivan Marisca, Daniele Zambon, Cesare Alippi</author><pubDate>Fri, 10 Nov 2023 14:34:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04071v2</guid></item><item><title>VDIP-TGV: Blind Image Deconvolution via Variational Deep Image Prior Empowered by Total Generalized Variation</title><link>http://arxiv.org/abs/2310.19477v2</link><description>Recovering clear images from blurry ones with an unknown blur kernel is achallenging problem. Deep image prior (DIP) proposes to use the deep network asa regularizer for a single image rather than as a supervised model, whichachieves encouraging results in the nonblind deblurring problem. However, sincethe relationship between images and the network architectures is unclear, it ishard to find a suitable architecture to provide sufficient constraints on theestimated blur kernels and clean images. Also, DIP uses the sparse maximum aposteriori (MAP), which is insufficient to enforce the selection of therecovery image. Recently, variational deep image prior (VDIP) was proposed toimpose constraints on both blur kernels and recovery images and take thestandard deviation of the image into account during the optimization process bythe variational principle. However, we empirically find that VDIP struggleswith processing image details and tends to generate suboptimal results when theblur kernel is large. Therefore, we combine total generalized variational (TGV)regularization with VDIP in this paper to overcome these shortcomings of VDIP.TGV is a flexible regularization that utilizes the characteristics of partialderivatives of varying orders to regularize images at different scales,reducing oil painting artifacts while maintaining sharp edges. The proposedVDIP-TGV effectively recovers image edges and details by supplementing extragradient information through TGV. Additionally, this model is solved by thealternating direction method of multipliers (ADMM), which effectively combinestraditional algorithms and deep learning methods. Experiments show that ourproposed VDIP-TGV surpasses various state-of-the-art models quantitatively andqualitatively.</description><author>Tingting Wu, Zhiyan Du, Zhi Li, Feng-Lei Fan, Tieyong Zeng</author><pubDate>Fri, 10 Nov 2023 14:26:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19477v2</guid></item><item><title>Enhancing Rock Image Segmentation in Digital Rock Physics: A Fusion of Generative AI and State-of-the-Art Neural Networks</title><link>http://arxiv.org/abs/2311.06079v1</link><description>In digital rock physics, analysing microstructures from CT and SEM scans iscrucial for estimating properties like porosity and pore connectivity.Traditional segmentation methods like thresholding and CNNs often fall short inaccurately detailing rock microstructures and are prone to noise. U-Netimproved segmentation accuracy but required many expert-annotated samples, alaborious and error-prone process due to complex pore shapes. Our studyemployed an advanced generative AI model, the diffusion model, to overcomethese limitations. This model generated a vast dataset of CT/SEM and binarysegmentation pairs from a small initial dataset. We assessed the efficacy ofthree neural networks: U-Net, Attention-U-net, and TransUNet, for segmentingthese enhanced images. The diffusion model proved to be an effective dataaugmentation technique, improving the generalization and robustness of deeplearning models. TransU-Net, incorporating Transformer structures, demonstratedsuperior segmentation accuracy and IoU metrics, outperforming both U-Net andAttention-U-net. Our research advances rock image segmentation by combining thediffusion model with cutting-edge neural networks, reducing dependency onextensive expert data and boosting segmentation accuracy and robustness.TransU-Net sets a new standard in digital rock physics, paving the way forfuture geoscience and engineering breakthroughs.</description><author>Zhaoyang Ma, Xupeng He, Hyung Kwak, Jun Gao, Shuyu Sun, Bicheng Yan</author><pubDate>Fri, 10 Nov 2023 14:24:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06079v1</guid></item><item><title>NESTER: An Adaptive Neurosymbolic Method for Causal Effect Estimation</title><link>http://arxiv.org/abs/2211.04370v4</link><description>Causal effect estimation from observational data is a central problem incausal inference. Methods based on potential outcomes framework solve thisproblem by exploiting inductive biases and heuristics from causal inference.Each of these methods addresses a specific aspect of causal effect estimation,such as controlling propensity score, enforcing randomization, etc., bydesigning neural network (NN) architectures and regularizers. In this paper, wepropose an adaptive method called Neurosymbolic Causal Effect Estimator(NESTER), a generalized method for causal effect estimation. NESTER integratesthe ideas used in existing methods based on multi-head NNs for causal effectestimation into one framework. We design a Domain Specific Language (DSL)tailored for causal effect estimation based on causal inductive biases used inliterature. We conduct a theoretical analysis to investigate NESTER's efficacyin estimating causal effects. Our comprehensive empirical results show thatNESTER performs better than state-of-the-art methods on benchmark datasets.</description><author>Abbavaram Gowtham Reddy, Vineeth N Balasubramanian</author><pubDate>Fri, 10 Nov 2023 14:21:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.04370v4</guid></item><item><title>Two-compartment neuronal spiking model expressing brain-state specific apical-amplification, -isolation and -drive regimes</title><link>http://arxiv.org/abs/2311.06074v1</link><description>There is mounting experimental evidence that brain-state specific neuralmechanisms supported by connectomic architectures serve to combine past andcontextual knowledge with current, incoming flow of evidence (e.g. from sensorysystems). Such mechanisms are distributed across multiple spatial and temporalscales and require dedicated support at the levels of individual neurons andsynapses. A prominent feature in the neocortex is the structure of large, deeppyramidal neurons which show a peculiar separation between an apical dendriticcompartment and a basal dentritic/peri-somatic compartment, with distinctivepatterns of incoming connections and brain-state specific activationmechanisms, namely apical-amplification, -isolation and -drive associated tothe wakefulness, deeper NREM sleep stages and REM sleep. The cognitive roles ofapical mechanisms have been demonstrated in behaving animals. In contrast,classical models of learning spiking networks are based on single compartmentneurons that miss the description of mechanisms to combine apical andbasal/somatic information. This work aims to provide the computationalcommunity with a two-compartment spiking neuron model which includes featuresthat are essential for supporting brain-state specific learning and with apiece-wise linear transfer function (ThetaPlanes) at highest abstraction levelto be used in large scale bio-inspired artificial intelligence systems. Amachine learning algorithm, constrained by a set of fitness functions, selectedthe parameters defining neurons expressing the desired apical mechanisms.</description><author>Elena Pastorelli, Alper Yegenoglu, Nicole Kolodziej, Willem Wybo, Francesco Simula, Sandra Diaz, Johan Frederik Storm, Pier Stanislao Paolucci</author><pubDate>Fri, 10 Nov 2023 14:16:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06074v1</guid></item><item><title>Learning-Based Biharmonic Augmentation for Point Cloud Classification</title><link>http://arxiv.org/abs/2311.06070v1</link><description>Point cloud datasets often suffer from inadequate sample sizes in comparisonto image datasets, making data augmentation challenging. While traditionalmethods, like rigid transformations and scaling, have limited potential inincreasing dataset diversity due to their constraints on altering individualsample shapes, we introduce the Biharmonic Augmentation (BA) method. BA is anovel and efficient data augmentation technique that diversifies point clouddata by imposing smooth non-rigid deformations on existing 3D structures. Thisapproach calculates biharmonic coordinates for the deformation function andlearns diverse deformation prototypes. Utilizing a CoefNet, our method predictscoefficients to amalgamate these prototypes, ensuring comprehensivedeformation. Moreover, we present AdvTune, an advanced online augmentationsystem that integrates adversarial training. This system synergisticallyrefines the CoefNet and the classification network, facilitating the automatedcreation of adaptive shape deformations contingent on the learner status.Comprehensive experimental analysis validates the superiority of BiharmonicAugmentation, showcasing notable performance improvements over prevailing pointcloud augmentation techniques across varied network designs.</description><author>Jiacheng Wei, Guosheng Lin, Henghui Ding, Jie Hu, Kim-Hui Yap</author><pubDate>Fri, 10 Nov 2023 14:04:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06070v1</guid></item><item><title>Attributes Grouping and Mining Hashing for Fine-Grained Image Retrieval</title><link>http://arxiv.org/abs/2311.06067v1</link><description>In recent years, hashing methods have been popular in the large-scale mediasearch for low storage and strong representation capabilities. To describeobjects with similar overall appearance but subtle differences, more and morestudies focus on hashing-based fine-grained image retrieval. Existing hashingnetworks usually generate both local and global features through attentionguidance on the same deep activation tensor, which limits the diversity offeature representations. To handle this limitation, we substitute convolutionaldescriptors for attention-guided features and propose an Attributes Groupingand Mining Hashing (AGMH), which groups and embeds the category-specific visualattributes in multiple descriptors to generate a comprehensive featurerepresentation for efficient fine-grained image retrieval. Specifically, anAttention Dispersion Loss (ADL) is designed to force the descriptors to attendto various local regions and capture diverse subtle details. Moreover, wepropose a Stepwise Interactive External Attention (SIEA) to mine criticalattributes in each descriptor and construct correlations between fine-grainedattributes and objects. The attention mechanism is dedicated to learningdiscrete attributes, which will not cost additional computations in hash codesgeneration. Finally, the compact binary codes are learned by preservingpairwise similarities. Experimental results demonstrate that AGMH consistentlyyields the best performance against state-of-the-art methods on fine-grainedbenchmark datasets.</description><author>Xin Lu, Shikun Chen, Yichao Cao, Xin Zhou, Xiaobo Lu</author><pubDate>Fri, 10 Nov 2023 14:01:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06067v1</guid></item><item><title>Lidar-based Norwegian tree species detection using deep learning</title><link>http://arxiv.org/abs/2311.06066v1</link><description>Background: The mapping of tree species within Norwegian forests is atime-consuming process, involving forest associations relying on manuallabeling by experts. The process can involve both aerial imagery, personalfamiliarity, or on-scene references, and remote sensing data. Thestate-of-the-art methods usually use high resolution aerial imagery withsemantic segmentation methods. Methods: We present a deep learning based treespecies classification model utilizing only lidar (Light Detection And Ranging)data. The lidar images are segmented into four classes (Norway Spruce, ScotsPine, Birch, background) with a U-Net based network. The model is trained withfocal loss over partial weak labels. A major benefit of the approach is thatboth the lidar imagery and the base map for the labels have free and openaccess. Results: Our tree species classification model achieves amacro-averaged F1 score of 0.70 on an independent validation with NationalForest Inventory (NFI) in-situ sample plots. That is close to, but below theperformance of aerial, or aerial and lidar combined models.</description><author>Martijn Vermeer, Jacob Alexander Hay, David V√∂lgyes, Zs√≥fia Koma, Johannes Breidenbach, Daniele Stefano Maria Fantin</author><pubDate>Fri, 10 Nov 2023 14:01:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06066v1</guid></item><item><title>RIGA: A Regret-Based Interactive Genetic Algorithm</title><link>http://arxiv.org/abs/2311.06063v1</link><description>In this paper, we propose an interactive genetic algorithm for solvingmulti-objective combinatorial optimization problems under preferenceimprecision. More precisely, we consider problems where the decision maker'spreferences over solutions can be represented by a parameterized aggregationfunction (e.g., a weighted sum, an OWA operator, a Choquet integral), and weassume that the parameters are initially not known by the recommendationsystem. In order to quickly make a good recommendation, we combine elicitationand search in the following way: 1) we use regret-based elicitation techniquesto reduce the parameter space in a efficient way, 2) genetic operators areapplied on parameter instances (instead of solutions) to better explore theparameter space, and 3) we generate promising solutions (population) usingexisting solving methods designed for the problem with known preferences. Ouralgorithm, called RIGA, can be applied to any multi-objective combinatorialoptimization problem provided that the aggregation function is linear in itsparameters and that a (near-)optimal solution can be efficiently determined forthe problem with known preferences. We also study its theoretical performances:RIGA can be implemented in such way that it runs in polynomial time whileasking no more than a polynomial number of queries. The method is tested on themulti-objective knapsack and traveling salesman problems. For severalperformance indicators (computation times, gap to optimality and number ofqueries), RIGA obtains better results than state-of-the-art algorithms.</description><author>Nawal Benabbou, Cassandre Leroy, Thibaut Lust</author><pubDate>Fri, 10 Nov 2023 13:56:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06063v1</guid></item><item><title>Practical Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration</title><link>http://arxiv.org/abs/2311.06062v1</link><description>Membership Inference Attacks (MIA) aim to infer whether a target data recordhas been utilized for model training or not. Prior attempts have quantified theprivacy risks of language models (LMs) via MIAs, but there is still noconsensus on whether existing MIA algorithms can cause remarkable privacyleakage on practical Large Language Models (LLMs). Existing MIAs designed forLMs can be classified into two categories: reference-free and reference-basedattacks. They are both based on the hypothesis that training recordsconsistently strike a higher probability of being sampled. Nevertheless, thishypothesis heavily relies on the overfitting of target models, which will bemitigated by multiple regularization methods and the generalization of LLMs.The reference-based attack seems to achieve promising effectiveness in LLMs,which measures a more reliable membership signal by comparing the probabilitydiscrepancy between the target model and the reference model. However, theperformance of reference-based attack is highly dependent on a referencedataset that closely resembles the training dataset, which is usuallyinaccessible in the practical scenario. Overall, existing MIAs are unable toeffectively unveil privacy leakage over practical fine-tuned LLMs that areoverfitting-free and private. We propose a Membership Inference Attack based onSelf-calibrated Probabilistic Variation (SPV-MIA). Specifically, sincememorization in LLMs is inevitable during the training process and occursbefore overfitting, we introduce a more reliable membership signal,probabilistic variation, which is based on memorization rather thanoverfitting. Furthermore, we introduce a self-prompt approach, which constructsthe dataset to fine-tune the reference model by prompting the target LLMitself. In this manner, the adversary can collect a dataset with a similardistribution from public APIs.</description><author>Wenjie Fu, Huandong Wang, Chen Gao, Guanghua Liu, Yong Li, Tao Jiang</author><pubDate>Fri, 10 Nov 2023 13:55:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06062v1</guid></item><item><title>Preemptively Pruning Clever-Hans Strategies in Deep Neural Networks</title><link>http://arxiv.org/abs/2304.05727v3</link><description>Robustness has become an important consideration in deep learning. With thehelp of explainable AI, mismatches between an explained model's decisionstrategy and the user's domain knowledge (e.g. Clever Hans effects) have beenidentified as a starting point for improving faulty models. However, it is lessclear what to do when the user and the explanation agree. In this paper, wedemonstrate that acceptance of explanations by the user is not a guarantee fora machine learning model to be robust against Clever Hans effects, which mayremain undetected. Such hidden flaws of the model can nevertheless bemitigated, and we demonstrate this by contributing a new method,Explanation-Guided Exposure Minimization (EGEM), that preemptively prunesvariations in the ML model that have not been the subject of positiveexplanation feedback. Experiments demonstrate that our approach leads to modelsthat strongly reduce their reliance on hidden Clever Hans strategies, andconsequently achieve higher accuracy on new data.</description><author>Lorenz Linhardt, Klaus-Robert M√ºller, Gr√©goire Montavon</author><pubDate>Fri, 10 Nov 2023 13:54:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05727v3</guid></item><item><title>Improved Positional Encoding for Implicit Neural Representation based Compact Data Representation</title><link>http://arxiv.org/abs/2311.06059v1</link><description>Positional encodings are employed to capture the high frequency informationof the encoded signals in implicit neural representation (INR). In this paper,we propose a novel positional encoding method which improves the reconstructionquality of the INR. The proposed embedding method is more advantageous for thecompact data representation because it has a greater number of frequency basisthan the existing methods. Our experiments shows that the proposed methodachieves significant gain in the rate-distortion performance withoutintroducing any additional complexity in the compression task and higherreconstruction quality in novel view synthesis.</description><author>Bharath Bhushan Damodaran, Francois Schnitzler, Anne Lambert, Pierre Hellier</author><pubDate>Fri, 10 Nov 2023 13:47:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06059v1</guid></item><item><title>Ulcerative Colitis Mayo Endoscopic Scoring Classification with Active Learning and Generative Data Augmentation</title><link>http://arxiv.org/abs/2311.06057v1</link><description>Endoscopic imaging is commonly used to diagnose Ulcerative Colitis (UC) andclassify its severity. It has been shown that deep learning based methods areeffective in automated analysis of these images and can potentially be used toaid medical doctors. Unleashing the full potential of these methods depends onthe availability of large amount of labeled images; however, obtaining andlabeling these images are quite challenging. In this paper, we propose a activelearning based generative augmentation method. The method involves generating alarge number of synthetic samples by training using a small dataset consistingof real endoscopic images. The resulting data pool is narrowed down by usingactive learning methods to select the most informative samples, which are thenused to train a classifier. We demonstrate the effectiveness of our methodthrough experiments on a publicly available endoscopic image dataset. Theresults show that using synthesized samples in conjunction with active learningleads to improved classification performance compared to using only theoriginal labeled examples and the baseline classification performance of 68.1%increases to 74.5% in terms of Quadratic Weighted Kappa (QWK) Score. Anotherobservation is that, attaining equivalent performance using only real datanecessitated three times higher number of images.</description><author>√úmit Mert √áaƒülar, Alperen ƒ∞nci, Oƒüuz Hanoƒülu, G√∂rkem Polat, Alptekin Temizel</author><pubDate>Fri, 10 Nov 2023 13:42:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06057v1</guid></item><item><title>Learning Contrastive Self-Distillation for Ultra-Fine-Grained Visual Categorization Targeting Limited Samples</title><link>http://arxiv.org/abs/2311.06056v1</link><description>In the field of intelligent multimedia analysis, ultra-fine-grained visualcategorization (Ultra-FGVC) plays a vital role in distinguishing intricatesubcategories within broader categories. However, this task is inherentlychallenging due to the complex granularity of category subdivisions and thelimited availability of data for each category. To address these challenges,this work proposes CSDNet, a pioneering framework that effectively explorescontrastive learning and self-distillation to learn discriminativerepresentations specifically designed for Ultra-FGVC tasks. CSDNet comprisesthree main modules: Subcategory-Specific Discrepancy Parsing (SSDP), DynamicDiscrepancy Learning (DDL), and Subcategory-Specific Discrepancy Transfer(SSDT), which collectively enhance the generalization of deep models acrossinstance, feature, and logit prediction levels. To increase the diversity oftraining samples, the SSDP module introduces augmented samples from differentviewpoints to spotlight subcategory-specific discrepancies. Simultaneously, theproposed DDL module stores historical intermediate features by a dynamic memoryqueue, which optimizes the feature learning space through iterative contrastivelearning. Furthermore, the SSDT module is developed by a novelself-distillation paradigm at the logit prediction level of raw and augmentedsamples, which effectively distills more subcategory-specific discrepanciesknowledge from the inherent structure of limited training data withoutrequiring additional annotations. Experimental results demonstrate that CSDNetoutperforms current state-of-the-art Ultra-FGVC methods, emphasizing itspowerful efficacy and adaptability in addressing Ultra-FGVC tasks.</description><author>Ziye Fang, Xin Jiang, Hao Tang, Zechao Li</author><pubDate>Fri, 10 Nov 2023 13:39:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06056v1</guid></item><item><title>Refining the ONCE Benchmark with Hyperparameter Tuning</title><link>http://arxiv.org/abs/2311.06054v1</link><description>In response to the growing demand for 3D object detection in applicationssuch as autonomous driving, robotics, and augmented reality, this work focuseson the evaluation of semi-supervised learning approaches for point cloud data.The point cloud representation provides reliable and consistent observationsregardless of lighting conditions, thanks to advances in LiDAR sensors. Dataannotation is of paramount importance in the context of LiDAR applications, andautomating 3D data annotation with semi-supervised methods is a pivotalchallenge that promises to reduce the associated workload and facilitate theemergence of cost-effective LiDAR solutions. Nevertheless, the task ofsemi-supervised learning in the context of unordered point cloud data remainsformidable due to the inherent sparsity and incomplete shapes that hinder thegeneration of accurate pseudo-labels. In this study, we consider thesechallenges by posing the question: "To what extent does unlabelled datacontribute to the enhancement of model performance?" We show that improvementsfrom previous semi-supervised methods may not be as profound as previouslythought. Our results suggest that simple grid search hyperparameter tuningapplied to a supervised model can lead to state-of-the-art performance on theONCE dataset, while the contribution of unlabelled data appears to becomparatively less exceptional.</description><author>Maksim Golyadkin, Alexander Gambashidze, Ildar Nurgaliev, Ilya Makarov</author><pubDate>Fri, 10 Nov 2023 13:39:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06054v1</guid></item><item><title>A Novel Variational Lower Bound for Inverse Reinforcement Learning</title><link>http://arxiv.org/abs/2311.03698v2</link><description>Inverse reinforcement learning (IRL) seeks to learn the reward function fromexpert trajectories, to understand the task for imitation or collaborationthereby removing the need for manual reward engineering. However, IRL in thecontext of large, high-dimensional problems with unknown dynamics has beenparticularly challenging. In this paper, we present a new Variational LowerBound for IRL (VLB-IRL), which is derived under the framework of aprobabilistic graphical model with an optimality node. Our methodsimultaneously learns the reward function and policy under the learned rewardfunction by maximizing the lower bound, which is equivalent to minimizing thereverse Kullback-Leibler divergence between an approximated distribution ofoptimality given the reward function and the true distribution of optimalitygiven trajectories. This leads to a new IRL method that learns a valid rewardfunction such that the policy under the learned reward achieves expert-levelperformance on several known domains. Importantly, the method outperforms theexisting state-of-the-art IRL algorithms on these domains by demonstratingbetter reward from the learned policy.</description><author>Yikang Gui, Prashant Doshi</author><pubDate>Fri, 10 Nov 2023 13:26:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03698v2</guid></item><item><title>Rethinking Semi-Supervised Imbalanced Node Classification from Bias-Variance Decomposition</title><link>http://arxiv.org/abs/2310.18765v2</link><description>This paper introduces a new approach to address the issue of class imbalancein graph neural networks (GNNs) for learning on graph-structured data. Ourapproach integrates imbalanced node classification and Bias-VarianceDecomposition, establishing a theoretical framework that closely relates dataimbalance to model variance. We also leverage graph augmentation technique toestimate the variance, and design a regularization term to alleviate the impactof imbalance. Exhaustive tests are conducted on multiple benchmarks, includingnaturally imbalanced datasets and public-split class-imbalanced datasets,demonstrating that our approach outperforms state-of-the-art methods in variousimbalanced scenarios. This work provides a novel theoretical perspective foraddressing the problem of imbalanced node classification in GNNs.</description><author>Divin Yan, Gengchen Wei, Chen Yang, Shengzhong Zhang, Zengfeng Huang</author><pubDate>Fri, 10 Nov 2023 13:23:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18765v2</guid></item><item><title>PriorCVAE: scalable MCMC parameter inference with Bayesian deep generative modelling</title><link>http://arxiv.org/abs/2304.04307v3</link><description>Recent advances have shown that GP priors, or their finite realisations, canbe encoded using deep generative models such as variational autoencoders(VAEs). These learned generators can serve as drop-in replacements for theoriginal priors during MCMC inference. While this approach enables efficientinference, it loses information about the hyperparameters of the originalmodels, and consequently makes inference over hyperparameters impossible andthe learned priors indistinct. To overcome this limitation, we condition theVAE on stochastic process hyperparameters. This allows the joint encoding ofhyperparameters with GP realizations and their subsequent estimation duringinference. Further, we demonstrate that our proposed method, PriorCVAE, isagnostic to the nature of the models which it approximates, and can be used,for instance, to encode solutions of ODEs. It provides a practical tool forapproximate inference and shows potential in real-life spatial andspatiotemporal applications.</description><author>Elizaveta Semenova, Prakhar Verma, Max Cairney-Leeming, Arno Solin, Samir Bhatt, Seth Flaxman</author><pubDate>Fri, 10 Nov 2023 13:22:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.04307v3</guid></item><item><title>Beyond expectations: Residual Dynamic Mode Decomposition and Variance for Stochastic Dynamical Systems</title><link>http://arxiv.org/abs/2308.10697v3</link><description>Koopman operators linearize nonlinear dynamical systems, making theirspectral information of crucial interest. Numerous algorithms have beendeveloped to approximate these spectral properties, and Dynamic ModeDecomposition (DMD) stands out as the poster child of projection-based methods.Although the Koopman operator itself is linear, the fact that it acts in aninfinite-dimensional space of observables poses challenges. These includespurious modes, essential spectra, and the verification of Koopman modedecompositions. While recent work has addressed these challenges fordeterministic systems, there remains a notable gap in verified DMD methods forstochastic systems, where the Koopman operator measures the expectation ofobservables. We show that it is necessary to go beyond expectations to addressthese issues. By incorporating variance into the Koopman framework, we addressthese challenges. Through an additional DMD-type matrix, we approximate the sumof a squared residual and a variance term, each of which can be approximatedindividually using batched snapshot data. This allows verified computation ofthe spectral properties of stochastic Koopman operators, controlling theprojection error. We also introduce the concept of variance-pseudospectra togauge statistical coherency. Finally, we present a suite of convergence resultsfor the spectral information of stochastic Koopman operators. Our studyconcludes with practical applications using both simulated and experimentaldata. In neural recordings from awake mice, we demonstrate howvariance-pseudospectra can reveal physiologically significant informationunavailable to standard expectation-based dynamical models.</description><author>Matthew J. Colbrook, Qin Li, Ryan V. Raut, Alex Townsend</author><pubDate>Fri, 10 Nov 2023 13:19:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10697v3</guid></item><item><title>Deep learning for 3D Object Detection and Tracking in Autonomous Driving: A Brief Survey</title><link>http://arxiv.org/abs/2311.06043v1</link><description>Object detection and tracking are vital and fundamental tasks for autonomousdriving, aiming at identifying and locating objects from those predefinedcategories in a scene. 3D point cloud learning has been attracting more andmore attention among all other forms of self-driving data. Currently, there aremany deep learning methods for 3D object detection. However, the tasks ofobject detection and tracking for point clouds still need intensive study dueto the unique characteristics of point cloud data. To help get a good grasp ofthe present situation of this research, this paper shows recent advances indeep learning methods for 3D object detection and tracking.</description><author>Yang Peng</author><pubDate>Fri, 10 Nov 2023 13:03:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06043v1</guid></item><item><title>Rosetta Stone at the Arabic Reverse Dictionary Shared Task: A Hop From Language Modeling To Word--Definition Alignment</title><link>http://arxiv.org/abs/2310.15823v2</link><description>A Reverse Dictionary is a tool enabling users to discover a word based on itsprovided definition, meaning, or description. Such a technique proves valuablein various scenarios, aiding language learners who possess a description of aword without its identity, and benefiting writers seeking precise terminology.These scenarios often encapsulate what is referred to as the"Tip-of-the-Tongue" (TOT) phenomena. In this work, we present our winningsolution for the Arabic Reverse Dictionary shared task. This task focuses onderiving a vector representation of an Arabic word from its accompanyingdescription. The shared task encompasses two distinct subtasks: the firstinvolves an Arabic definition as input, while the second employs an Englishdefinition. For the first subtask, our approach relies on an ensemble offinetuned Arabic BERT-based models, predicting the word embedding for a givendefinition. The final representation is obtained through averaging the outputembeddings from each model within the ensemble. In contrast, the most effectivesolution for the second subtask involves translating the English testdefinitions into Arabic and applying them to the finetuned models originallytrained for the first subtask. This straightforward method achieves the highestscore across both subtasks.</description><author>Ahmed ElBakry, Mohamed Gabr, Muhammad ElNokrashy, Badr AlKhamissi</author><pubDate>Fri, 10 Nov 2023 13:02:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15823v2</guid></item><item><title>Sample Efficient Reward Augmentation in offline-to-online Reinforcement Learning</title><link>http://arxiv.org/abs/2310.19805v2</link><description>A prospective application of offline reinforcement learning (RL) involvesinitializing a pre-trained policy using existing static datasets for subsequentonline fine-tuning. However, direct fine-tuning of the offline pre-trainedpolicy often results in sub-optimal performance. A primary reason is thatoffline conservative methods diminish the agent's capability of exploration,thereby impacting online fine-tuning performance. To enhance exploration duringonline fine-tuning and thus enhance the overall online fine-tuning performance,we introduce a generalized reward augmentation framework called SampleEfficient Reward Augmentation (SERA). SERA aims to improve the performance ofonline fine-tuning by designing intrinsic rewards that encourage the agent toexplore. Specifically, it implicitly implements State Marginal Matching (SMM)and penalizes out-of-distribution (OOD) state actions, thus encouraging agentsto cover the target state density, and achieving better online fine-tuningresults. Additionally, SERA can be effortlessly plugged into various RLalgorithms to improve online fine-tuning and ensure sustained asymptoticimprovement, showing the versatility as well as the effectiveness of SERA.Moreover, extensive experimental results will demonstrate that when conductingoffline-to-online problems, SERA consistently and effectively enhances theperformance of various offline algorithms.</description><author>Ziqi Zhang, Xiao Xiong, Zifeng Zhuang, Jinxin Liu, Donglin Wang</author><pubDate>Fri, 10 Nov 2023 12:53:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19805v2</guid></item><item><title>2D Image head pose estimation via latent space regression under occlusion settings</title><link>http://arxiv.org/abs/2311.06038v1</link><description>Head orientation is a challenging Computer Vision problem that has beenextensively researched having a wide variety of applications. However, currentstate-of-the-art systems still underperform in the presence of occlusions andare unreliable for many task applications in such scenarios. This work proposesa novel deep learning approach for the problem of head pose estimation underocclusions. The strategy is based on latent space regression as a fundamentalkey to better structure the problem for occluded scenarios. Our model surpassesseveral state-of-the-art methodologies for occluded HPE, and achieves similaraccuracy for non-occluded scenarios. We demonstrate the usefulness of theproposed approach with: (i) two synthetically occluded versions of the BIWI andAFLW2000 datasets, (ii) real-life occlusions of the Pandora dataset, and (iii)a real-life application to human-robot interaction scenarios where faceocclusions often occur. Specifically, the autonomous feeding from a roboticarm.</description><author>Jos√© Celestino, Manuel Marques, Jacinto C. Nascimento, Jo√£o Paulo Costeira</author><pubDate>Fri, 10 Nov 2023 12:53:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06038v1</guid></item><item><title>Diagonal Hierarchical Consistency Learning for Semi-supervised Medical Image Segmentation</title><link>http://arxiv.org/abs/2311.06031v1</link><description>Medical image segmentation, which is essential for many clinicalapplications, has achieved almost human-level performance via data-driven deeplearning techniques. Nevertheless, its performance is predicated on the costlyprocess of manually annotating a large amount of medical images. To this end,we propose a novel framework for robust semi-supervised medical imagesegmentation using diagonal hierarchical consistency (DiHC-Net). First, it iscomposed of multiple sub-models with identical multi-scale architecture butwith distinct sub-layers, such as up-sampling and normalisation layers. Second,a novel diagonal hierarchical consistency is enforced between one model'sintermediate and final prediction and other models' soft pseudo labels in adiagonal hierarchical fashion. Experimental results verify the efficacy of oursimple framework, outperforming all previous approaches on public Left Atrium(LA) dataset.</description><author>Heejoon Koo</author><pubDate>Fri, 10 Nov 2023 12:38:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06031v1</guid></item><item><title>Symbolic Regression as Feature Engineering Method for Machine and Deep Learning Regression Tasks</title><link>http://arxiv.org/abs/2311.06028v1</link><description>In the realm of machine and deep learning regression tasks, the role ofeffective feature engineering (FE) is pivotal in enhancing model performance.Traditional approaches of FE often rely on domain expertise to manually designfeatures for machine learning models. In the context of deep learning models,the FE is embedded in the neural network's architecture, making it hard forinterpretation. In this study, we propose to integrate symbolic regression (SR)as an FE process before a machine learning model to improve its performance. Weshow, through extensive experimentation on synthetic and real-worldphysics-related datasets, that the incorporation of SR-derived featuressignificantly enhances the predictive capabilities of both machine and deeplearning regression models with 34-86% root mean square error (RMSE)improvement in synthetic datasets and 4-11.5% improvement in real-worlddatasets. In addition, as a realistic use-case, we show the proposed methodimproves the machine learning performance in predicting superconductingcritical temperatures based on Eliashberg theory by more than 20% in terms ofRMSE. These results outline the potential of SR as an FE component indata-driven models.</description><author>Assaf Shmuel, Oren Glickman, Teddy Lazebnik</author><pubDate>Fri, 10 Nov 2023 12:34:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06028v1</guid></item><item><title>ChiMed-GPT: A Chinese Medical Large Language Model with Full Training Regime and Better Alignment to Human Preferences</title><link>http://arxiv.org/abs/2311.06025v1</link><description>Recently, the increasing demand for superior medical services has highlightedthe discrepancies in the medical infrastructure. With big data, especiallytexts, forming the foundation of medical services, there is an exigent need foreffective natural language processing (NLP) solutions tailored to thehealthcare domain. Conventional approaches leveraging pre-trained modelspresent promising results in this domain and current large language models(LLMs) offer advanced foundation for medical text processing. However, mostmedical LLMs are trained only with supervised fine-tuning (SFT), even though itefficiently empowers LLMs to understand and respond to medical instructions butis ineffective in learning domain knowledge and aligning with human preference.Another engineering barrier that prevents current medical LLM from better textprocessing ability is their restricted context length (e.g., 2,048 tokens),making it hard for the LLMs to process long context, which is frequentlyrequired in the medical domain. In this work, we propose ChiMed-GPT, a newbenchmark LLM designed explicitly for Chinese medical domain, with enlargedcontext length to 4,096 tokens and undergoes a comprehensive training regimewith pre-training, SFT, and RLHF. Evaluations on real-world tasks includinginformation extraction, question answering, and dialogue generation demonstrateChiMed-GPT's superior performance over general domain LLMs. Furthermore, weanalyze possible biases through prompting ChiMed-GPT to perform attitude scalesregarding discrimination of patients, so as to contribute to furtherresponsible development of LLMs in the medical domain. The code and model arereleased at https://github.com/synlp/ChiMed-GPT.</description><author>Yuanhe Tian, Ruyi Gan, Yan Song, Jiaxing Zhang, Yongdong Zhang</author><pubDate>Fri, 10 Nov 2023 12:25:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06025v1</guid></item><item><title>A Safe Deep Reinforcement Learning Approach for Energy Efficient Federated Learning in Wireless Communication Networks</title><link>http://arxiv.org/abs/2308.10664v2</link><description>Progressing towards a new era of Artificial Intelligence (AI) - enabledwireless networks, concerns regarding the environmental impact of AI have beenraised both in industry and academia. Federated Learning (FL) has emerged as akey privacy preserving decentralized AI technique. Despite efforts currentlybeing made in FL, its environmental impact is still an open problem. Targetingthe minimization of the overall energy consumption of an FL process, we proposethe orchestration of computational and communication resources of the involveddevices to minimize the total energy required, while guaranteeing a certainperformance of the model. To this end, we propose a Soft Actor Critic DeepReinforcement Learning (DRL) solution, where a penalty function is introducedduring training, penalizing the strategies that violate the constraints of theenvironment, and contributing towards a safe RL process. A device levelsynchronization method, along with a computationally cost effective FLenvironment are proposed, with the goal of further reducing the energyconsumption and communication overhead. Evaluation results show theeffectiveness and robustness of the proposed scheme compared to fourstate-of-the-art baseline solutions on different network environments and FLarchitectures, achieving a decrease of up to 94% in the total energyconsumption.</description><author>Nikolaos Koursioumpas, Lina Magoula, Nikolaos Petropouleas, Alexandros-Ioannis Thanopoulos, Theodora Panagea, Nancy Alonistioti, M. A. Gutierrez-Estevez, Ramin Khalili</author><pubDate>Fri, 10 Nov 2023 12:25:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10664v2</guid></item><item><title>Interpretable Neural PDE Solvers using Symbolic Frameworks</title><link>http://arxiv.org/abs/2310.20463v2</link><description>Partial differential equations (PDEs) are ubiquitous in the world around us,modelling phenomena from heat and sound to quantum systems. Recent advances indeep learning have resulted in the development of powerful neural solvers;however, while these methods have demonstrated state-of-the-art performance inboth accuracy and computational efficiency, a significant challenge remains intheir interpretability. Most existing methodologies prioritize predictiveaccuracy over clarity in the underlying mechanisms driving the model'sdecisions. Interpretability is crucial for trustworthiness and broaderapplicability, especially in scientific and engineering domains where neuralPDE solvers might see the most impact. In this context, a notable gap incurrent research is the integration of symbolic frameworks (such as symbolicregression) into these solvers. Symbolic frameworks have the potential todistill complex neural operations into human-readable mathematical expressions,bridging the divide between black-box predictions and solutions.</description><author>Yolanne Yi Ran Lee</author><pubDate>Fri, 10 Nov 2023 12:15:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20463v2</guid></item><item><title>U3DS$^3$: Unsupervised 3D Semantic Scene Segmentation</title><link>http://arxiv.org/abs/2311.06018v1</link><description>Contemporary point cloud segmentation approaches largely rely on richlyannotated 3D training data. However, it is both time-consuming and challengingto obtain consistently accurate annotations for such 3D scene data. Moreover,there is still a lack of investigation into fully unsupervised scenesegmentation for point clouds, especially for holistic 3D scenes. This paperpresents U3DS$^3$, as a step towards completely unsupervised point cloudsegmentation for any holistic 3D scenes. To achieve this, U3DS$^3$ leverages ageneralized unsupervised segmentation method for both object and backgroundacross both indoor and outdoor static 3D point clouds with no requirement formodel pre-training, by leveraging only the inherent information of the pointcloud to achieve full 3D scene segmentation. The initial step of our proposedapproach involves generating superpoints based on the geometric characteristicsof each scene. Subsequently, it undergoes a learning process through a spatialclustering-based methodology, followed by iterative training usingpseudo-labels generated in accordance with the cluster centroids. Moreover, byleveraging the invariance and equivariance of the volumetric representations,we apply the geometric transformation on voxelized features to provide two setsof descriptors for robust representation learning. Finally, our evaluationprovides state-of-the-art results on the ScanNet and SemanticKITTI, andcompetitive results on the S3DIS, benchmark datasets.</description><author>Jiaxu Liu, Zhengdi Yu, Toby P. Breckon, Hubert P. H. Shum</author><pubDate>Fri, 10 Nov 2023 12:05:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06018v1</guid></item><item><title>BEA: Revisiting anchor-based object detection DNN using Budding Ensemble Architecture</title><link>http://arxiv.org/abs/2309.08036v4</link><description>This paper introduces the Budding Ensemble Architecture (BEA), a novelreduced ensemble architecture for anchor-based object detection models. Objectdetection models are crucial in vision-based tasks, particularly in autonomoussystems. They should provide precise bounding box detections while alsocalibrating their predicted confidence scores, leading to higher-qualityuncertainty estimates. However, current models may make erroneous decisions dueto false positives receiving high scores or true positives being discarded dueto low scores. BEA aims to address these issues. The proposed loss functions inBEA improve the confidence score calibration and lower the uncertainty error,which results in a better distinction of true and false positives and,eventually, higher accuracy of the object detection models. Both Base-YOLOv3and SSD models were enhanced using the BEA method and its proposed lossfunctions. The BEA on Base-YOLOv3 trained on the KITTI dataset results in a 6%and 3.7% increase in mAP and AP50, respectively. Utilizing a well-balanceduncertainty estimation threshold to discard samples in real-time even leads toa 9.6% higher AP50 than its base model. This is attributed to a 40% increase inthe area under the AP50-based retention curve used to measure the quality ofcalibration of confidence scores. Furthermore, BEA-YOLOV3 trained on KITTIprovides superior out-of-distribution detection on Citypersons, BDD100K, andCOCO datasets compared to the ensembles and vanilla models of YOLOv3 andGaussian-YOLOv3.</description><author>Syed Sha Qutub, Neslihan Kose, Rafael Rosales, Michael Paulitsch, Korbinian Hagn, Florian Geissler, Yang Peng, Gereon Hinz, Alois Knoll</author><pubDate>Fri, 10 Nov 2023 12:01:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08036v4</guid></item><item><title>RSG: Fast Learning Adaptive Skills for Quadruped Robots by Skill Graph</title><link>http://arxiv.org/abs/2311.06015v1</link><description>Developing robotic intelligent systems that can adapt quickly to unseen wildsituations is one of the critical challenges in pursuing autonomous robotics.Although some impressive progress has been made in walking stability and skilllearning in the field of legged robots, their ability to fast adaptation isstill inferior to that of animals in nature. Animals are born with massiveskills needed to survive, and can quickly acquire new ones, by composingfundamental skills with limited experience. Inspired by this, we propose anovel framework, named Robot Skill Graph (RSG) for organizing massivefundamental skills of robots and dexterously reusing them for fast adaptation.Bearing a structure similar to the Knowledge Graph (KG), RSG is composed ofmassive dynamic behavioral skills instead of static knowledge in KG and enablesdiscovering implicit relations that exist in be-tween of learning context andacquired skills of robots, serving as a starting point for understanding subtlepatterns existing in robots' skill learning. Extensive experimental resultsdemonstrate that RSG can provide rational skill inference upon new tasks andenvironments and enable quadruped robots to adapt to new scenarios and learnnew skills rapidly.</description><author>Hongyin Zhang, Diyuan Shi, Zifeng Zhuang, Han Zhao, Zhenyu Wei, Feng Zhao, Sibo Gai, Shangke Lyu, Donglin Wang</author><pubDate>Fri, 10 Nov 2023 11:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06015v1</guid></item><item><title>Doubly Robust Structure Identification from Temporal Data</title><link>http://arxiv.org/abs/2311.06012v1</link><description>Learning the causes of time-series data is a fundamental task in manyapplications, spanning from finance to earth sciences or bio-medicalapplications. Common approaches for this task are based on vectorauto-regression, and they do not take into account unknown confounding betweenpotential causes. However, in settings with many potential causes and noisydata, these approaches may be substantially biased. Furthermore, potentialcauses may be correlated in practical applications. Moreover, existingalgorithms often do not work with cyclic data. To address these challenges, wepropose a new doubly robust method for Structure Identification from TemporalData ( SITD ). We provide theoretical guarantees, showing that our methodasymptotically recovers the true underlying causal structure. Our analysisextends to cases where the potential causes have cycles and they may beconfounded. We further perform extensive experiments to showcase the superiorperformance of our method.</description><author>Emmanouil Angelis, Francesco Quinzan, Ashkan Soleymani, Patrick Jaillet, Stefan Bauer</author><pubDate>Fri, 10 Nov 2023 11:53:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06012v1</guid></item></channel></rss>