<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 24 Jan 2024 06:00:19 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Zero-Shot Learning for the Primitives of 3D Affordance in General Objects</title><link>http://arxiv.org/abs/2401.12978v1</link><description>One of the major challenges in AI is teaching machines to precisely respondand utilize environmental functionalities, thereby achieving the affordanceawareness that humans possess. Despite its importance, the field has beenlagging in terms of learning, especially in 3D, as annotating affordanceaccompanies a laborious process due to the numerous variations of human-objectinteraction. The low availability of affordance data limits the learning interms of generalization for object categories, and also simplifies therepresentation of affordance, capturing only a fraction of the affordance. Toovercome these challenges, we propose a novel, self-supervised method togenerate the 3D affordance examples given only a 3D object, without any manualannotations. The method starts by capturing the 3D object into images andcreating 2D affordance images by inserting humans into the image via inpaintingdiffusion models, where we present the Adaptive Mask algorithm to enable humaninsertion without altering the original details of the object. The methodconsequently lifts inserted humans back to 3D to create 3D human-object pairs,where the depth ambiguity is resolved within a depth optimization frameworkthat utilizes pre-generated human postures from multiple viewpoints. We alsoprovide a novel affordance representation defined on relative orientations andproximity between dense human and object points, that can be easily aggregatedfrom any 3D HOI datasets. The proposed representation serves as a primitivethat can be manifested to conventional affordance representations via simpletransformations, ranging from physically exerted affordances to nonphysicalones. We demonstrate the efficacy of our method and representation bygenerating the 3D affordance samples and deriving high-quality affordanceexamples from the representation, including contact, orientation, and spatialoccupancies.</description><author>Hyeonwoo Kim, Sookwan Han, Patrick Kwon, Hanbyul Joo</author><pubDate>Tue, 23 Jan 2024 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12978v1</guid></item><item><title>GALA: Generating Animatable Layered Assets from a Single Scan</title><link>http://arxiv.org/abs/2401.12979v1</link><description>We present GALA, a framework that takes as input a single-layer clothed 3Dhuman mesh and decomposes it into complete multi-layered 3D assets. The outputscan then be combined with other assets to create novel clothed human avatarswith any pose. Existing reconstruction approaches often treat clothed humans asa single-layer of geometry and overlook the inherent compositionality of humanswith hairstyles, clothing, and accessories, thereby limiting the utility of themeshes for downstream applications. Decomposing a single-layer mesh intoseparate layers is a challenging task because it requires the synthesis ofplausible geometry and texture for the severely occluded regions. Moreover,even with successful decomposition, meshes are not normalized in terms of posesand body shapes, failing coherent composition with novel identities and poses.To address these challenges, we propose to leverage the general knowledge of apretrained 2D diffusion model as geometry and appearance prior for humans andother assets. We first separate the input mesh using the 3D surfacesegmentation extracted from multi-view 2D segmentations. Then we synthesize themissing geometry of different layers in both posed and canonical spaces using anovel pose-guided Score Distillation Sampling (SDS) loss. Once we completeinpainting high-fidelity 3D geometry, we also apply the same SDS loss to itstexture to obtain the complete appearance including the initially occludedregions. Through a series of decomposition steps, we obtain multiple layers of3D assets in a shared canonical space normalized in terms of poses and humanshapes, hence supporting effortless composition to novel identities andreanimation with novel poses. Our experiments demonstrate the effectiveness ofour approach for decomposition, canonicalization, and composition taskscompared to existing solutions.</description><author>Taeksoo Kim, Byungjun Kim, Shunsuke Saito, Hanbyul Joo</author><pubDate>Tue, 23 Jan 2024 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12979v1</guid></item><item><title>IRIS: Inverse Rendering of Indoor Scenes from Low Dynamic Range Images</title><link>http://arxiv.org/abs/2401.12977v1</link><description>While numerous 3D reconstruction and novel-view synthesis methods allow forphotorealistic rendering of a scene from multi-view images easily captured withconsumer cameras, they bake illumination in their representations and fallshort of supporting advanced applications like material editing, relighting,and virtual object insertion. The reconstruction of physically based materialproperties and lighting via inverse rendering promises to enable suchapplications. However, most inverse rendering techniques require high dynamic range (HDR)images as input, a setting that is inaccessible to most users. We present amethod that recovers the physically based material properties andspatially-varying HDR lighting of a scene from multi-view, low-dynamic-range(LDR) images. We model the LDR image formation process in our inverse renderingpipeline and propose a novel optimization strategy for material, lighting, anda camera response model. We evaluate our approach with synthetic and realscenes compared to the state-of-the-art inverse rendering methods that takeeither LDR or HDR input. Our method outperforms existing methods taking LDRimages as input, and allows for highly realistic relighting and objectinsertion.</description><author>Zhi-Hao Lin, Jia-Bin Huang, Zhengqin Li, Zhao Dong, Christian Richardt, Tuotuo Li, Michael Zollhöfer, Johannes Kopf, Shenlong Wang, Changil Kim</author><pubDate>Tue, 23 Jan 2024 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12977v1</guid></item><item><title>RudolfV: A Foundation Model by Pathologists for Pathologists</title><link>http://arxiv.org/abs/2401.04079v2</link><description>Histopathology plays a central role in clinical medicine and biomedicalresearch. While artificial intelligence shows promising results on manypathological tasks, generalization and dealing with rare diseases, wheretraining data is scarce, remains a challenge. Distilling knowledge fromunlabeled data into a foundation model before learning from, potentiallylimited, labeled data provides a viable path to address these challenges. Inthis work, we extend the state of the art of foundation models for digitalpathology whole slide images by semi-automated data curation and incorporatingpathologist domain knowledge. Specifically, we combine computational andpathologist domain knowledge (1) to curate a diverse dataset of 103k slidescorresponding to 750 million image patches covering data from differentfixation, staining, and scanning protocols as well as data from differentindications and labs across the EU and US, (2) for grouping semanticallysimilar slides and tissue patches, and (3) to augment the input images duringtraining. We evaluate the resulting model on a set of public and internalbenchmarks and show that although our foundation model is trained with an orderof magnitude less slides, it performs on par or better than competing models.We expect that scaling our approach to more data and larger models will furtherincrease its performance and capacity to deal with increasingly complex realworld tasks in diagnostics and biomedical research.</description><author>Jonas Dippel, Barbara Feulner, Tobias Winterhoff, Simon Schallenberg, Gabriel Dernbach, Andreas Kunft, Stephan Tietz, Philipp Jurmeister, David Horst, Lukas Ruff, Klaus-Robert Müller, Frederick Klauschen, Maximilian Alber</author><pubDate>Tue, 23 Jan 2024 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04079v2</guid></item><item><title>HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments</title><link>http://arxiv.org/abs/2401.12975v1</link><description>Recent advances in high-fidelity virtual environments serve as one of themajor driving forces for building intelligent embodied agents to perceive,reason and interact with the physical world. Typically, these environmentsremain unchanged unless agents interact with them. However, in real-worldscenarios, agents might also face dynamically changing environmentscharacterized by unexpected events and need to rapidly take action accordingly.To remedy this gap, we propose a new simulated embodied benchmark, calledHAZARD, specifically designed to assess the decision-making abilities ofembodied agents in dynamic situations. HAZARD consists of three unexpecteddisaster scenarios, including fire, flood, and wind, and specifically supportsthe utilization of large language models (LLMs) to assist common sensereasoning and decision-making. This benchmark enables us to evaluate autonomousagents' decision-making capabilities across various pipelines, includingreinforcement learning (RL), rule-based, and search-based methods indynamically changing environments. As a first step toward addressing thischallenge using large language models, we further develop an LLM-based agentand perform an in-depth analysis of its promise and challenge of solving thesechallenging tasks. HAZARD is available at https://vis-www.cs.umass.edu/hazard/.</description><author>Qinhong Zhou, Sunli Chen, Yisong Wang, Haozhe Xu, Weihua Du, Hongxin Zhang, Yilun Du, Joshua B. Tenenbaum, Chuang Gan</author><pubDate>Tue, 23 Jan 2024 18:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12975v1</guid></item><item><title>Tracking Any Object Amodally</title><link>http://arxiv.org/abs/2312.12433v2</link><description>Amodal perception, the ability to comprehend complete object structures frompartial visibility, is a fundamental skill, even for infants. Its significanceextends to applications like autonomous driving, where a clear understanding ofheavily occluded objects is essential. However, modern detection and trackingalgorithms often overlook this critical capability, perhaps due to theprevalence of modal annotations in most datasets. To address the scarcity ofamodal data, we introduce the TAO-Amodal benchmark, featuring 880 diversecategories in thousands of video sequences. Our dataset includes amodal andmodal bounding boxes for visible and occluded objects, including objects thatare partially out-of-frame. To enhance amodal tracking with object permanence,we leverage a lightweight plug-in module, the amodal expander, to transformstandard, modal trackers into amodal ones through fine-tuning on a few hundredvideo sequences with data augmentation. We achieve a 3.3\% and 1.6\%improvement on the detection and tracking of occluded objects on TAO-Amodal.When evaluated on people, our method produces dramatic improvements of 2xcompared to state-of-the-art modal baselines.</description><author>Cheng-Yen Hsieh, Tarasha Khurana, Achal Dave, Deva Ramanan</author><pubDate>Tue, 23 Jan 2024 18:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12433v2</guid></item><item><title>SegmentAnyBone: A Universal Model that Segments Any Bone at Any Location on MRI</title><link>http://arxiv.org/abs/2401.12974v1</link><description>Magnetic Resonance Imaging (MRI) is pivotal in radiology, offeringnon-invasive and high-quality insights into the human body. Precisesegmentation of MRIs into different organs and tissues would be highlybeneficial since it would allow for a higher level of understanding of theimage content and enable important measurements, which are essential foraccurate diagnosis and effective treatment planning. Specifically, segmentingbones in MRI would allow for more quantitative assessments of musculoskeletalconditions, while such assessments are largely absent in current radiologicalpractice. The difficulty of bone MRI segmentation is illustrated by the factthat limited algorithms are publicly available for use, and those contained inthe literature typically address a specific anatomic area. In our study, wepropose a versatile, publicly available deep-learning model for bonesegmentation in MRI across multiple standard MRI locations. The proposed modelcan operate in two modes: fully automated segmentation and prompt-basedsegmentation. Our contributions include (1) collecting and annotating a new MRIdataset across various MRI protocols, encompassing over 300 annotated volumesand 8485 annotated slices across diverse anatomic regions; (2) investigatingseveral standard network architectures and strategies for automatedsegmentation; (3) introducing SegmentAnyBone, an innovative foundationalmodel-based approach that extends Segment Anything Model (SAM); (4) comparativeanalysis of our algorithm and previous approaches; and (5) generalizationanalysis of our algorithm across different anatomical locations and MRIsequences, as well as an external dataset. We publicly release our model athttps://github.com/mazurowski-lab/SegmentAnyBone.</description><author>Hanxue Gu, Roy Colglazier, Haoyu Dong, Jikai Zhang, Yaqian Chen, Zafer Yildiz, Yuwen Chen, Lin Li, Jichen Yang, Jay Willhite, Alex M. Meyer, Brian Guo, Yashvi Atul Shah, Emily Luo, Shipra Rajput, Sally Kuehn, Clark Bulleit, Kevin A. Wu, Jisoo Lee, Brandon Ramirez, Darui Lu, Jay M. Levin, Maciej A. Mazurowski</author><pubDate>Tue, 23 Jan 2024 18:59:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12974v1</guid></item><item><title>In-Context Language Learning: Arhitectures and Algorithms</title><link>http://arxiv.org/abs/2401.12973v1</link><description>Large-scale neural language models exhibit a remarkable capacity forin-context learning (ICL): they can infer novel functions from datasetsprovided as input. Most of our current understanding of when and how ICL arisescomes from LMs trained on extremely simple learning problems like linearregression and associative recall. There remains a significant gap betweenthese model problems and the "real" ICL exhibited by LMs trained on large textcorpora, which involves not just retrieval and function approximation butfree-form generation of language and other structured outputs. In this paper,we study ICL through the lens of a new family of model problems we term incontext language learning (ICLL). In ICLL, LMs are presented with a set ofstrings from a formal language, and must generate additional strings from thesame language. We focus on in-context learning of regular languages generatedby random finite automata. We evaluate a diverse set of neural sequence models(including several RNNs, Transformers, and state-space model variants) onregular ICLL tasks, aiming to answer three questions: (1) Which model classesare empirically capable of ICLL? (2) What algorithmic solutions do successfulmodels implement to perform ICLL? (3) What architectural changes can improveICLL in less performant models? We first show that Transformers significantlyoutperform neural sequence models with recurrent or convolutionalrepresentations on ICLL tasks. Next, we provide evidence that their ability todo so relies on specialized "n-gram heads" (higher-order variants of inductionheads) that compute input-conditional next-token distributions. Finally, weshow that hard-wiring these heads into recurrent and convolutional modelsimproves performance not just on ICLL, but natural language modeling --improving the perplexity of 340M-parameter models by up to 1.14 points (6.7%)on the SlimPajama dataset.</description><author>Ekin Akyürek, Bailin Wang, Yoon Kim, Jacob Andreas</author><pubDate>Tue, 23 Jan 2024 18:59:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12973v1</guid></item><item><title>On the Efficacy of Text-Based Input Modalities for Action Anticipation</title><link>http://arxiv.org/abs/2401.12972v1</link><description>Although the task of anticipating future actions is highly uncertain,information from additional modalities help to narrow down plausible actionchoices. Each modality provides different environmental context for the modelto learn from. While previous multi-modal methods leverage information frommodalities such as video and audio, we primarily explore how text inputs foractions and objects can also enable more accurate action anticipation.Therefore, we propose a Multi-modal Anticipative Transformer (MAT), anattention-based video transformer architecture that jointly learns frommulti-modal features and text captions. We train our model in two-stages, wherethe model first learns to predict actions in the video clip by aligning withcaptions, and during the second stage, we fine-tune the model to predict futureactions. Compared to existing methods, MAT has the advantage of learningadditional environmental context from two kinds of text inputs: actiondescriptions during the pre-training stage, and the text inputs for detectedobjects and actions during modality feature fusion. Through extensiveexperiments, we evaluate the effectiveness of the pre-training stage, and showthat our model outperforms previous methods on all datasets. In addition, weexamine the impact of object and action information obtained via text andperform extensive ablations. We evaluate the performance on on three datasets:EpicKitchens-100, EpicKitchens-55 and EGTEA GAZE+; and show that textdescriptions do indeed aid in more effective action anticipation.</description><author>Apoorva Beedu, Karan Samel, Irfan Essa</author><pubDate>Tue, 23 Jan 2024 18:58:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12972v1</guid></item><item><title>Raidar: geneRative AI Detection viA Rewriting</title><link>http://arxiv.org/abs/2401.12970v1</link><description>We find that large language models (LLMs) are more likely to modifyhuman-written text than AI-generated text when tasked with rewriting. Thistendency arises because LLMs often perceive AI-generated text as high-quality,leading to fewer modifications. We introduce a method to detect AI-generatedcontent by prompting LLMs to rewrite text and calculating the editing distanceof the output. We dubbed our geneRative AI Detection viA Rewriting methodRaidar. Raidar significantly improves the F1 detection scores of existing AIcontent detection models -- both academic and commercial -- across variousdomains, including News, creative writing, student essays, code, Yelp reviews,and arXiv papers, with gains of up to 29 points. Operating solely on wordsymbols without high-dimensional features, our method is compatible with blackbox LLMs, and is inherently robust on new content. Our results illustrate theunique imprint of machine-generated text through the lens of the machinesthemselves.</description><author>Chengzhi Mao, Carl Vondrick, Hao Wang, Junfeng Yang</author><pubDate>Tue, 23 Jan 2024 18:57:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12970v1</guid></item><item><title>AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents</title><link>http://arxiv.org/abs/2401.12963v1</link><description>Foundation models that incorporate language, vision, and more recentlyactions have revolutionized the ability to harness internet scale data toreason about useful tasks. However, one of the key challenges of trainingembodied foundation models is the lack of data grounded in the physical world.In this paper, we propose AutoRT, a system that leverages existing foundationmodels to scale up the deployment of operational robots in completely unseenscenarios with minimal human supervision. AutoRT leverages vision-languagemodels (VLMs) for scene understanding and grounding, and further uses largelanguage models (LLMs) for proposing diverse and novel instructions to beperformed by a fleet of robots. Guiding data collection by tapping into theknowledge of foundation models enables AutoRT to effectively reason aboutautonomy tradeoffs and safety while significantly scaling up data collectionfor robot learning. We demonstrate AutoRT proposing instructions to over 20robots across multiple buildings and collecting 77k real robot episodes viaboth teleoperation and autonomous robot policies. We experimentally show thatsuch "in-the-wild" data collected by AutoRT is significantly more diverse, andthat AutoRT's use of LLMs allows for instruction following data collectionrobots that can align to human preferences.</description><author>Michael Ahn, Debidatta Dwibedi, Chelsea Finn, Montse Gonzalez Arenas, Keerthana Gopalakrishnan, Karol Hausman, Brian Ichter, Alex Irpan, Nikhil Joshi, Ryan Julian, Sean Kirmani, Isabel Leal, Edward Lee, Sergey Levine, Yao Lu, Isabel Leal, Sharath Maddineni, Kanishka Rao, Dorsa Sadigh, Pannag Sanketi, Pierre Sermanet, Quan Vuong, Stefan Welker, Fei Xia, Ted Xiao, Peng Xu, Steve Xu, Zhuo Xu</author><pubDate>Tue, 23 Jan 2024 18:45:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12963v1</guid></item><item><title>Chatterbox: Robust Transport for LLM Token Streaming under Unstable Network</title><link>http://arxiv.org/abs/2401.12961v1</link><description>To render each generated token in real time, the LLM server generatesresponse tokens one by one and streams each generated token (or group of a fewtokens) through the network to the user right after it is generated, which werefer to as LLM token streaming. However, under unstable network conditions,the LLM token streaming experience could suffer greatly from stalls since onepacket loss could block the rendering of tokens contained in subsequent packetseven if they arrive on time. With a real-world measurement study, we show thatcurrent applications including ChatGPT, Claude, and Bard all suffer fromincreased stall under unstable network. For this emerging token streaming problem in LLM Chatbots, we propose a noveltransport layer scheme, called Chatterbox, which puts new generated tokens aswell as currently unacknowledged tokens in the next outgoing packet. Thisensures that each packet contains some new tokens and can be independentlyrendered when received, thus avoiding aforementioned stalls caused by missingpackets. Through simulation under various network conditions, we showChatterbox reduces stall ratio (proportion of token rendering wait time) by71.0% compared to the token streaming method commonly used by real chatbotapplications and by 31.6% compared to a custom packet duplication scheme. Bytailoring Chatterbox to fit the token-by-token generation of LLM, we enable theChatbots to respond like an eloquent speaker for users to better enjoypervasive AI.</description><author>Hanchen Li, Yuhan Liu, Yihua Cheng, Siddhant Ray, Kuntai Du, Junchen Jiang</author><pubDate>Tue, 23 Jan 2024 18:45:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12961v1</guid></item><item><title>PATS: Patch Area Transportation with Subdivision for Local Feature Matching</title><link>http://arxiv.org/abs/2303.07700v3</link><description>Local feature matching aims at establishing sparse correspondences between apair of images. Recently, detector-free methods present generally betterperformance but are not satisfactory in image pairs with large scaledifferences. In this paper, we propose Patch Area Transportation withSubdivision (PATS) to tackle this issue. Instead of building an expensive imagepyramid, we start by splitting the original image pair into equal-sized patchesand gradually resizing and subdividing them into smaller patches with the samescale. However, estimating scale differences between these patches isnon-trivial since the scale differences are determined by both relative cameraposes and scene structures, and thus spatially varying over image pairs.Moreover, it is hard to obtain the ground truth for real scenes. To this end,we propose patch area transportation, which enables learning scale differencesin a self-supervised manner. In contrast to bipartite graph matching, whichonly handles one-to-one matching, our patch area transportation can deal withmany-to-many relationships. PATS improves both matching accuracy and coverage,and shows superior performance in downstream tasks, such as relative poseestimation, visual localization, and optical flow estimation. The source codeis available at \url{https://zju3dv.github.io/pats/}.</description><author>Junjie Ni, Yijin Li, Zhaoyang Huang, Hongsheng Li, Hujun Bao, Zhaopeng Cui, Guofeng Zhang</author><pubDate>Tue, 23 Jan 2024 18:37:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07700v3</guid></item><item><title>Formally Specifying the High-Level Behavior of LLM-Based Agents</title><link>http://arxiv.org/abs/2310.08535v2</link><description>Autonomous, goal-driven agents powered by LLMs have recently emerged aspromising tools for solving challenging problems without the need fortask-specific finetuned models that can be expensive to procure. Currently, thedesign and implementation of such agents is ad hoc, as the wide variety oftasks that LLM-based agents may be applied to naturally means there can be noone-size-fits-all approach to agent design. In this work we aim to alleviatethe difficulty of designing and implementing new agents by proposing aminimalistic generation framework that simplifies the process of buildingagents. The framework we introduce allows the user to define desired agentbehaviors in a high-level, declarative specification that is then used toconstruct a decoding monitor which guarantees the LLM will produce an outputexhibiting the desired behavior. Our declarative approach, in which thebehavior is described without concern for how it should be implemented orenforced, enables rapid design, implementation, and experimentation withdifferent LLM-based agents. We demonstrate how the proposed framework can beused to implement recent LLM-based agents (e.g., ReACT), and show how theflexibility of our approach can be leveraged to define a new agent with morecomplex behavior, the Plan-Act-Summarize-Solve (PASS) agent. Lastly, wedemonstrate that our method outperforms other agents on multiple popularreasoning-centric question-answering benchmarks.</description><author>Maxwell Crouse, Ibrahim Abdelaziz, Ramon Astudillo, Kinjal Basu, Soham Dan, Sadhana Kumaravel, Achille Fokoue, Pavan Kapanipathi, Salim Roukos, Luis Lastras</author><pubDate>Tue, 23 Jan 2024 18:35:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08535v2</guid></item><item><title>Adaptive Local Neighborhood-based Neural Networks for MR Image Reconstruction from Undersampled Data</title><link>http://arxiv.org/abs/2206.00775v2</link><description>Recent medical image reconstruction techniques focus on generatinghigh-quality medical images suitable for clinical use at the lowest possiblecost and with the fewest possible adverse effects on patients. Recent workshave shown significant promise for reconstructing MR images from sparselysampled k-space data using deep learning. In this work, we propose a techniquethat rapidly estimates deep neural networks directly at reconstruction time byfitting them on small adaptively estimated neighborhoods of a training set. Inbrief, our algorithm alternates between searching for neighbors in a data setthat are similar to the test reconstruction, and training a local network onthese neighbors followed by updating the test reconstruction. Because ourreconstruction model is learned on a dataset that is in some sense similar tothe image being reconstructed rather than being fit on a large, diversetraining set, it is more adaptive to new scans. It can also handle changes intraining sets and flexible scan settings, while being relatively fast. Ourapproach, dubbed LONDN-MRI, was validated on multiple data sets using deepunrolled reconstruction networks. Reconstructions were performed at four foldand eight fold undersampling of k-space with 1D variable-density randomphase-encode undersampling masks. Our results demonstrate that our proposedlocally-trained method produces higher-quality reconstructions compared tomodels trained globally on larger datasets as well as other scan-adaptivemethods.</description><author>Shijun Liang, Anish Lahiri, Saiprasad Ravishankar</author><pubDate>Tue, 23 Jan 2024 18:31:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.00775v2</guid></item><item><title>HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks</title><link>http://arxiv.org/abs/2310.15318v3</link><description>Graphs have emerged as a natural choice to represent and analyze theintricate patterns and rich information of the Web, enabling applications suchas online page classification and social recommendation. The prevailing"pre-train, fine-tune" paradigm has been widely adopted in graph machinelearning tasks, particularly in scenarios with limited labeled nodes. However,this approach often exhibits a misalignment between the training objectives ofpretext tasks and those of downstream tasks. This gap can result in the"negative transfer" problem, wherein the knowledge gained from pre-trainingadversely affects performance in the downstream tasks. The surge inprompt-based learning within Natural Language Processing (NLP) suggests thepotential of adapting a "pre-train, prompt" paradigm to graphs as analternative. However, existing graph prompting techniques are tailored tohomogeneous graphs, neglecting the inherent heterogeneity of Web graphs. Tobridge this gap, we propose HetGPT, a general post-training prompting frameworkto improve the predictive performance of pre-trained heterogeneous graph neuralnetworks (HGNNs). The key is the design of a novel prompting function thatintegrates a virtual class prompt and a heterogeneous feature prompt, with theaim to reformulate downstream tasks to mirror pretext tasks. Moreover, HetGPTintroduces a multi-view neighborhood aggregation mechanism, capturing thecomplex neighborhood structure in heterogeneous graphs. Extensive experimentson three benchmark datasets demonstrate HetGPT's capability to enhance theperformance of state-of-the-art HGNNs on semi-supervised node classification.</description><author>Yihong Ma, Ning Yan, Jiayu Li, Masood Mortazavi, Nitesh V. Chawla</author><pubDate>Tue, 23 Jan 2024 18:27:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15318v3</guid></item><item><title>Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding</title><link>http://arxiv.org/abs/2401.12954v1</link><description>We introduce meta-prompting, an effective scaffolding technique designed toenhance the functionality of language models (LMs). This approach transforms asingle LM into a multi-faceted conductor, adept at managing and integratingmultiple independent LM queries. By employing high-level instructions,meta-prompting guides the LM to break down complex tasks into smaller, moremanageable subtasks. These subtasks are then handled by distinct "expert"instances of the same LM, each operating under specific, tailored instructions.Central to this process is the LM itself, in its role as the conductor, whichensures seamless communication and effective integration of the outputs fromthese expert models. It additionally employs its inherent critical thinking androbust verification processes to refine and authenticate the end result. Thiscollaborative prompting approach empowers a single LM to simultaneously act asa comprehensive orchestrator and a panel of diverse experts, significantlyenhancing its performance across a wide array of tasks. The zero-shot,task-agnostic nature of meta-prompting greatly simplifies user interaction byobviating the need for detailed, task-specific instructions. Furthermore, ourresearch demonstrates the seamless integration of external tools, such as aPython interpreter, into the meta-prompting framework, thereby broadening itsapplicability and utility. Through rigorous experimentation with GPT-4, weestablish the superiority of meta-prompting over conventional scaffoldingmethods: When averaged across all tasks, including the Game of 24,Checkmate-in-One, and Python Programming Puzzles, meta-prompting, augmentedwith a Python interpreter functionality, surpasses standard prompting by 17.1%,expert (dynamic) prompting by 17.3%, and multipersona prompting by 15.2%.</description><author>Mirac Suzgun, Adam Tauman Kalai</author><pubDate>Tue, 23 Jan 2024 18:22:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12954v1</guid></item><item><title>Outlier Dimensions Encode Task-Specific Knowledge</title><link>http://arxiv.org/abs/2310.17715v2</link><description>Representations from large language models (LLMs) are known to be dominatedby a small subset of dimensions with exceedingly high variance. Previous workshave argued that although ablating these outlier dimensions in LLMrepresentations hurts downstream performance, outlier dimensions aredetrimental to the representational quality of embeddings. In this study, weinvestigate how fine-tuning impacts outlier dimensions and show that 1) outlierdimensions that occur in pre-training persist in fine-tuned models and 2) asingle outlier dimension can complete downstream tasks with a minimal errorrate. Our results suggest that outlier dimensions can encode crucialtask-specific knowledge and that the value of a representation in a singleoutlier dimension drives downstream model decisions.</description><author>William Rudman, Catherine Chen, Carsten Eickhoff</author><pubDate>Tue, 23 Jan 2024 18:19:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17715v2</guid></item><item><title>Bayesian Semi-structured Subspace Inference</title><link>http://arxiv.org/abs/2401.12950v1</link><description>Semi-structured regression models enable the joint modeling of interpretablestructured and complex unstructured feature effects. The structured model partis inspired by statistical models and can be used to infer the input-outputrelationship for features of particular importance. The complex unstructuredpart defines an arbitrary deep neural network and thereby provides enoughflexibility to achieve competitive prediction performance. While these modelscan also account for aleatoric uncertainty, there is still a lack of work onaccounting for epistemic uncertainty. In this paper, we address this problem bypresenting a Bayesian approximation for semi-structured regression models usingsubspace inference. To this end, we extend subspace inference for jointposterior sampling from a full parameter space for structured effects and asubspace for unstructured effects. Apart from this hybrid sampling scheme, ourmethod allows for tunable complexity of the subspace and can capture multipleminima in the loss landscape. Numerical experiments validate our approach'sefficacy in recovering structured effect parameter posteriors insemi-structured models and approaching the full-space posterior distribution ofMCMC for increasing subspace dimension. Further, our approach exhibitscompetitive predictive performance across simulated and real-world datasets.</description><author>Daniel Dold, David Rügamer, Beate Sick, Oliver Dürr</author><pubDate>Tue, 23 Jan 2024 18:15:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12950v1</guid></item><item><title>A Geometric Framework for Neural Feature Learning</title><link>http://arxiv.org/abs/2309.10140v2</link><description>We present a novel framework for learning system design based on neuralfeature extractors. First, we introduce the feature geometry, which unifiesstatistical dependence and features in the same function space with geometricstructures. By applying the feature geometry, we formulate each learningproblem as solving the optimal feature approximation of the dependencecomponent specified by the learning setting. We propose a nesting technique fordesigning learning algorithms to learn the optimal features from data samples,which can be applied to off-the-shelf network architectures and optimizers. Todemonstrate the applications of the nesting technique, we further discussmultivariate learning problems, including conditioned inference and multimodallearning, where we present the optimal features and reveal their connections toclassical approaches.</description><author>Xiangxiang Xu, Lizhong Zheng</author><pubDate>Tue, 23 Jan 2024 18:08:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10140v2</guid></item><item><title>Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion</title><link>http://arxiv.org/abs/2401.12947v1</link><description>This paper investigates the ability of transformer-based models to learnstructural recursion from examples. Recursion is a universal concept in bothnatural and formal languages. Structural recursion is central to theprogramming language and formal mathematics tasks where symbolic toolscurrently excel beyond neural models, such as inferring semantic relationsbetween datatypes and emulating program behavior. We introduce a generalframework that nicely connects the abstract concepts of structural recursion inthe programming language domain to concrete sequence modeling problems andlearned models' behavior. The framework includes a representation that capturesthe general \textit{syntax} of structural recursion, coupled with two differentframeworks for understanding their \textit{semantics} -- one that is morenatural from a programming languages perspective and one that helps bridge thatperspective with a mechanistic understanding of the underlying transformerarchitecture. With our framework as a powerful conceptual tool, we identify differentissues under various set-ups. The models trained to emulate recursivecomputations cannot fully capture the recursion yet instead fit short-cutalgorithms and thus cannot solve certain edge cases that are under-representedin the training distribution. In addition, it is difficult for state-of-the-artlarge language models (LLMs) to mine recursive rules from in-contextdemonstrations. Meanwhile, these LLMs fail in interesting ways when emulatingreduction (step-wise computation) of the recursive function.</description><author>Dylan Zhang, Curt Tigges, Zory Zhang, Stella Biderman, Maxim Raginsky, Talia Ringer</author><pubDate>Tue, 23 Jan 2024 18:07:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12947v1</guid></item><item><title>Coverage Axis++: Efficient Inner Point Selection for 3D Shape Skeletonization</title><link>http://arxiv.org/abs/2401.12946v1</link><description>We introduce Coverage Axis++, a novel and efficient approach to 3D shapeskeletonization. The current state-of-the-art approaches for this task oftenrely on the watertightness of the input or suffer from substantialcomputational costs, thereby limiting their practicality. To address thischallenge, Coverage Axis++ proposes a heuristic algorithm to select skeletalpoints, offering a high-accuracy approximation of the Medial Axis Transform(MAT) while significantly mitigating computational intensity for various shaperepresentations. We introduce a simple yet effective strategy that considersboth shape coverage and uniformity to derive skeletal points. The selectionprocedure enforces consistency with the shape structure while favoring thedominant medial balls, which thus introduces a compact underlying shaperepresentation in terms of MAT. As a result, Coverage Axis++ allows forskeletonization for various shape representations (e.g., water-tight meshes,triangle soups, point clouds), specification of the number of skeletal points,few hyperparameters, and highly efficient computation with improvedreconstruction accuracy. Extensive experiments across a wide range of 3D shapesvalidate the efficiency and effectiveness of Coverage Axis++. The code will bepublicly available once the paper is published.</description><author>Zimeng Wang, Zhiyang Dou, Rui Xu, Cheng Lin, Yuan Liu, Xiaoxiao Long, Shiqing Xin, Lingjie Liu, Taku Komura, Xiaoming Yuan, Wenping Wang</author><pubDate>Tue, 23 Jan 2024 18:07:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12946v1</guid></item><item><title>Lumiere: A Space-Time Diffusion Model for Video Generation</title><link>http://arxiv.org/abs/2401.12945v1</link><description>We introduce Lumiere -- a text-to-video diffusion model designed forsynthesizing videos that portray realistic, diverse and coherent motion -- apivotal challenge in video synthesis. To this end, we introduce a Space-TimeU-Net architecture that generates the entire temporal duration of the video atonce, through a single pass in the model. This is in contrast to existing videomodels which synthesize distant keyframes followed by temporal super-resolution-- an approach that inherently makes global temporal consistency difficult toachieve. By deploying both spatial and (importantly) temporal down- andup-sampling and leveraging a pre-trained text-to-image diffusion model, ourmodel learns to directly generate a full-frame-rate, low-resolution video byprocessing it in multiple space-time scales. We demonstrate state-of-the-arttext-to-video generation results, and show that our design easily facilitates awide range of content creation tasks and video editing applications, includingimage-to-video, video inpainting, and stylized generation.</description><author>Omer Bar-Tal, Hila Chefer, Omer Tov, Charles Herrmann, Roni Paiss, Shiran Zada, Ariel Ephrat, Junhwa Hur, Yuanzhen Li, Tomer Michaeli, Oliver Wang, Deqing Sun, Tali Dekel, Inbar Mosseri</author><pubDate>Tue, 23 Jan 2024 18:05:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12945v1</guid></item><item><title>DengueNet: Dengue Prediction using Spatiotemporal Satellite Imagery for Resource-Limited Countries</title><link>http://arxiv.org/abs/2401.11114v2</link><description>Dengue fever presents a substantial challenge in developing countries wheresanitation infrastructure is inadequate. The absence of comprehensivehealthcare systems exacerbates the severity of dengue infections, potentiallyleading to life-threatening circumstances. Rapid response to dengue outbreaksis also challenging due to limited information exchange and integration. Whiletimely dengue outbreak forecasts have the potential to prevent such outbreaks,the majority of dengue prediction studies have predominantly relied on datathat impose significant burdens on individual countries for collection. In thisstudy, our aim is to improve health equity in resource-constrained countries byexploring the effectiveness of high-resolution satellite imagery as anontraditional and readily accessible data source. By leveraging the wealth ofpublicly available and easily obtainable satellite imagery, we present ascalable satellite extraction framework based on Sentinel Hub, a cloud-basedcomputing platform. Furthermore, we introduce DengueNet, an innovativearchitecture that combines Vision Transformer, Radiomics, and Long Short-termMemory to extract and integrate spatiotemporal features from satellite images.This enables dengue predictions on an epi-week basis. To evaluate theeffectiveness of our proposed method, we conducted experiments on fivemunicipalities in Colombia. We utilized a dataset comprising 780high-resolution Sentinel-2 satellite images for training and evaluation. Theperformance of DengueNet was assessed using the mean absolute error (MAE)metric. Across the five municipalities, DengueNet achieved an average MAE of43.92. Our findings strongly support the efficacy of satellite imagery as avaluable resource for dengue prediction, particularly in informing publichealth policies within countries where manually collected data is scarce anddengue virus prevalence is severe.</description><author>Kuan-Ting Kuo, Dana Moukheiber, Sebastian Cajas Ordonez, David Restrepo, Atika Rahman Paddo, Tsung-Yu Chen, Lama Moukheiber, Mira Moukheiber, Sulaiman Moukheiber, Saptarshi Purkayastha, Po-Chih Kuo, Leo Anthony Celi</author><pubDate>Tue, 23 Jan 2024 18:00:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11114v2</guid></item><item><title>Multicultural Name Recognition For Previously Unseen Names</title><link>http://arxiv.org/abs/2401.12941v1</link><description>State of the art Named Entity Recognition (NER) models have achieved animpressive ability to extract common phrases from text that belong to labelssuch as location, organization, time, and person. However, typical NER systemsthat rely on having seen a specific entity in their training data in order tolabel an entity perform poorly on rare or unseen entities ta in order to labelan entity perform poorly on rare or unseen entities (Derczynski et al., 2017).This paper attempts to improve recognition of person names, a diverse categorythat can grow any time someone is born or changes their name. In order fordownstream tasks to not exhibit bias based on cultural background, a modelshould perform well on names from a variety of backgrounds. In this paper Iexperiment with the training data and input structure of an English Bi-LSTMname recognition model. I look at names from 103 countries to compare how wellthe model performs on names from different cultures, specifically in thecontext of a downstream task where extracted names will be matched toinformation on file. I find that a model with combined character and word inputoutperforms word-only models and may improve on accuracy compared to classicalNER models that are not geared toward identifying unseen entity values.</description><author>Alexandra Loessberg-Zahl</author><pubDate>Tue, 23 Jan 2024 17:58:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12941v1</guid></item><item><title>Personalized Algorithmic Recourse with Preference Elicitation</title><link>http://arxiv.org/abs/2205.13743v5</link><description>Algorithmic Recourse (AR) is the problem of computing a sequence of actionsthat -- once performed by a user -- overturns an undesirable machine decision.It is paramount that the sequence of actions does not require too much effortfor users to implement. Yet, most approaches to AR assume that actions cost thesame for all users, and thus may recommend unfairly expensive recourse plans tocertain users. Prompted by this observation, we introduce PEAR, the firsthuman-in-the-loop approach capable of providing personalized algorithmicrecourse tailored to the needs of any end-user. PEAR builds on insights fromBayesian Preference Elicitation to iteratively refine an estimate of the costsof actions by asking choice set queries to the target user. The queriesthemselves are computed by maximizing the Expected Utility of Selection, aprincipled measure of information gain accounting for uncertainty on both thecost estimate and the user's responses. PEAR integrates elicitation into aReinforcement Learning agent coupled with Monte Carlo Tree Search to quicklyidentify promising recourse plans. Our empirical evaluation on real-worlddatasets highlights how PEAR produces high-quality personalized recourse inonly a handful of iterations.</description><author>Giovanni De Toni, Paolo Viappiani, Stefano Teso, Bruno Lepri, Andrea Passerini</author><pubDate>Tue, 23 Jan 2024 17:53:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.13743v5</guid></item><item><title>Neural deformation fields for template-based reconstruction of cortical surfaces from MRI</title><link>http://arxiv.org/abs/2401.12938v1</link><description>The reconstruction of cortical surfaces is a prerequisite for quantitativeanalyses of the cerebral cortex in magnetic resonance imaging (MRI). Existingsegmentation-based methods separate the surface registration from the surfaceextraction, which is computationally inefficient and prone to distortions. Weintroduce Vox2Cortex-Flow (V2C-Flow), a deep mesh-deformation technique thatlearns a deformation field from a brain template to the cortical surfaces of anMRI scan. To this end, we present a geometric neural network that models thedeformation-describing ordinary differential equation in a continuous manner.The network architecture comprises convolutional and graph-convolutionallayers, which allows it to work with images and meshes at the same time.V2C-Flow is not only very fast, requiring less than two seconds to infer allfour cortical surfaces, but also establishes vertex-wise correspondences to thetemplate during reconstruction. In addition, V2C-Flow is the first approach forcortex reconstruction that models white matter and pial surfaces jointly,therefore avoiding intersections between them. Our comprehensive experiments oninternal and external test data demonstrate that V2C-Flow results in corticalsurfaces that are state-of-the-art in terms of accuracy. Moreover, we show thatthe established correspondences are more consistent than in FreeSurfer and thatthey can directly be utilized for cortex parcellation and group analyses ofcortical thickness.</description><author>Fabian Bongratz, Anne-Marie Rickmann, Christian Wachinger</author><pubDate>Tue, 23 Jan 2024 17:50:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12938v1</guid></item><item><title>HARDCORE: H-field and power loss estimation for arbitrary waveforms with residual, dilated convolutional neural networks in ferrite cores</title><link>http://arxiv.org/abs/2401.11488v2</link><description>The MagNet Challenge 2023 calls upon competitors to develop data-drivenmodels for the material-specific, waveform-agnostic estimation of steady-statepower losses in toroidal ferrite cores. The following HARDCORE (H-field andpower loss estimation for Arbitrary waveforms with Residual, Dilatedconvolutional neural networks in ferrite COREs) approach shows that a residualconvolutional neural network with physics-informed extensions can serve thistask efficiently when trained on observational data beforehand. One keysolution element is an intermediate model layer which first reconstructs the bhcurve and then estimates the power losses based on the curve's area renderingthe proposed topology physically interpretable. In addition, emphasis wasplaced on expert-based feature engineering and information-rich inputs in orderto enable a lean model architecture. A model is trained from scratch for eachmaterial, while the topology remains the same. A Pareto-style trade-off betweenmodel size and estimation accuracy is demonstrated, which yields an optimum atas low as 1755 parameters and down to below 8\,\% for the 95-th percentile ofthe relative error for the worst-case material with sufficient samples.</description><author>Wilhelm Kirchgässner, Nikolas Förster, Till Piepenbrock, Oliver Schweins, Oliver Wallscheid</author><pubDate>Tue, 23 Jan 2024 17:49:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11488v2</guid></item><item><title>Reward-Relevance-Filtered Linear Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2401.12934v1</link><description>This paper studies offline reinforcement learning with linear functionapproximation in a setting with decision-theoretic, but not estimationsparsity. The structural restrictions of the data-generating process presumethat the transitions factor into a sparse component that affects the reward andcould affect additional exogenous dynamics that do not affect the reward.Although the minimally sufficient adjustment set for estimation of full-statetransition properties depends on the whole state, the optimal policy andtherefore state-action value function depends only on the sparse component: wecall this causal/decision-theoretic sparsity. We develop a method forreward-filtering the estimation of the state-action value function to thesparse component by a modification of thresholded lasso in least-squares policyevaluation. We provide theoretical guarantees for our reward-filtered linearfitted-Q-iteration, with sample complexity depending only on the size of thesparse component.</description><author>Angela Zhou</author><pubDate>Tue, 23 Jan 2024 17:42:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12934v1</guid></item><item><title>Segmentation of tibiofemoral joint tissues from knee MRI using MtRA-Unet and incorporating shape information: Data from the Osteoarthritis Initiative</title><link>http://arxiv.org/abs/2401.12932v1</link><description>Knee Osteoarthritis (KOA) is the third most prevalent MusculoskeletalDisorder (MSD) after neck and back pain. To monitor such a severe MSD, asegmentation map of the femur, tibia and tibiofemoral cartilage is usuallyaccessed using the automated segmentation algorithm from the Magnetic ResonanceImaging (MRI) of the knee. But, in recent works, such segmentation isconceivable only from the multistage framework thus creating data handlingissues and needing continuous manual inference rendering it unable to make aquick and precise clinical diagnosis. In order to solve these issues, in thispaper the Multi-Resolution Attentive-Unet (MtRA-Unet) is proposed to segmentthe femur, tibia and tibiofemoral cartilage automatically. The proposed workhas included a novel Multi-Resolution Feature Fusion (MRFF) and ShapeReconstruction (SR) loss that focuses on multi-contextual information andstructural anatomical details of the femur, tibia and tibiofemoral cartilage.Unlike previous approaches, the proposed work is a single-stage and end-to-endframework producing a Dice Similarity Coefficient (DSC) of 98.5% for the femur,98.4% for the tibia, 89.1% for Femoral Cartilage (FC) and 86.1% for TibialCartilage (TC) for critical MRI slices that can be helpful to clinicians forKOA grading. The time to segment MRI volume (160 slices) per subject is 22 sec.which is one of the fastest among state-of-the-art. Moreover, comprehensiveexperimentation on the segmentation of FC and TC which is of utmost importancefor morphology-based studies to check KOA progression reveals that the proposedmethod has produced an excellent result with binary segmentation</description><author>Akshay Daydar, Alik Pramanick, Arijit Sur, Subramani Kanagaraj</author><pubDate>Tue, 23 Jan 2024 17:37:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12932v1</guid></item><item><title>pyAKI - An Open Source Solution to Automated KDIGO classification</title><link>http://arxiv.org/abs/2401.12930v1</link><description>Acute Kidney Injury (AKI) is a frequent complication in critically illpatients, affecting up to 50% of patients in the intensive care units. The lackof standardized and open-source tools for applying the Kidney Disease ImprovingGlobal Outcomes (KDIGO) criteria to time series data has a negative impact onworkload and study quality. This project introduces pyAKI, an open-sourcepipeline addressing this gap by providing a comprehensive solution forconsistent KDIGO criteria implementation. The pyAKI pipeline was developed and validated using a subset of the MedicalInformation Mart for Intensive Care (MIMIC)-IV database, a commonly useddatabase in critical care research. We defined a standardized data model inorder to ensure reproducibility. Validation against expert annotationsdemonstrated pyAKI's robust performance in implementing KDIGO criteria.Comparative analysis revealed its ability to surpass the quality of humanlabels. This work introduces pyAKI as an open-source solution for implementing theKDIGO criteria for AKI diagnosis using time series data with high accuracy andperformance.</description><author>Christian Porschen, Jan Ernsting, Paul Brauckmann, Raphael Weiss, Till Würdemann, Hendrik Booke, Wida Amini, Ludwig Maidowski, Benjamin Risse, Tim Hahn, Thilo von Groote</author><pubDate>Tue, 23 Jan 2024 17:33:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12930v1</guid></item><item><title>Robust stabilization of polytopic systems via fast and reliable neural network-based approximations</title><link>http://arxiv.org/abs/2204.13209v2</link><description>We consider the design of fast and reliable neural network (NN)-basedapproximations of traditional stabilizing controllers for linear systems withpolytopic uncertainty, including control laws with variable structure and thosebased on a (minimal) selection policy. Building upon recent approaches for thedesign of reliable control surrogates with guaranteed structural properties, wedevelop a systematic procedure to certify the closed-loop stability andperformance of a linear uncertain system when a trained rectified linear unit(ReLU)-based approximation replaces such traditional controllers. First, weprovide a sufficient condition, which involves the worst-case approximationerror between ReLU-based and traditional controller-based state-to-inputmappings, ensuring that the system is ultimately bounded within a set withadjustable size and convergence rate. Then, we develop an offline,mixed-integer optimization-based method that allows us to compute that quantityexactly.</description><author>Filippo Fabiani, Paul J. Goulart</author><pubDate>Tue, 23 Jan 2024 17:31:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.13209v2</guid></item><item><title>Reservoir-Computing Model for Mapping and Forecasting Neuronal Interactions from Electrophysiological Data</title><link>http://arxiv.org/abs/2311.03131v2</link><description>Electrophysiological nature of neuronal networks allows to reveal variousinteractions between different cell units at a very short time-scales. One ofthe many challenges in analyzing these signals is to retrieve the morphologyand functionality of a given network. In this work we developed a computationalmodel, based on Reservoir Computing Network (RCN) architecture, which decodesthe spatio-temporal data from electro-physiological measurements of neuronalcultures and reconstructs the network structure on a macroscopic domain,representing the connectivity between neuronal units. We demonstrate that themodel can predict the connectivity map of the network with higher accuracy thanthe common methods such as Cross-Correlation and Transfer-Entropy. In addition,we experimentally demonstrate the ability of the model to predict a networkresponse to a specific input, such as localized stimulus.</description><author>Ilya Auslender, Giorgio Letti, Yasaman Heydari, Clara Zaccaria, Lorenzo Pavesi</author><pubDate>Tue, 23 Jan 2024 17:29:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03131v2</guid></item><item><title>Choice of training label matters: how to best use deep learning for quantitative MRI parameter estimation</title><link>http://arxiv.org/abs/2205.05587v3</link><description>Deep learning (DL) is gaining popularity as a parameter estimation method forquantitative MRI. A range of competing implementations have been proposed,relying on either supervised or self-supervised learning. Self-supervisedapproaches, sometimes referred to as unsupervised, have been loosely based onauto-encoders, whereas supervised methods have, to date, been trained ongroundtruth labels. These two learning paradigms have been shown to havedistinct strengths. Notably, self-supervised approaches have offered lower-biasparameter estimates than their supervised alternatives. This result iscounterintuitive - incorporating prior knowledge with supervised labels should,in theory, lead to improved accuracy. In this work, we show that this apparentlimitation of supervised approaches stems from the naive choice of groundtruthtraining labels. By training on labels which are deliberately not groundtruth,we show that the low-bias parameter estimation previously associated withself-supervised methods can be replicated - and improved on - within asupervised learning framework. This approach sets the stage for a single,unifying, deep learning parameter estimation framework, based on supervisedlearning, where trade-offs between bias and variance are made by carefuladjustment of training label.</description><author>Sean C. Epstein, Timothy J. P. Bray, Margaret Hall-Craggs, Hui Zhang</author><pubDate>Tue, 23 Jan 2024 17:26:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.05587v3</guid></item><item><title>DsDm: Model-Aware Dataset Selection with Datamodels</title><link>http://arxiv.org/abs/2401.12926v1</link><description>When selecting data for training large-scale models, standard practice is tofilter for examples that match human notions of data quality. Such filteringyields qualitatively clean datapoints that intuitively should improve modelbehavior. However, in practice the opposite can often happen: we find thatselecting according to similarity with "high quality" data sources may notincrease (and can even hurt) performance compared to randomly selecting data. To develop better methods for selecting data, we start by framing datasetselection as an optimization problem that we can directly solve for: giventarget tasks, a learning algorithm, and candidate data, select the subset thatmaximizes model performance. This framework thus avoids handpicked notions ofdata quality, and instead models explicitly how the learning process uses traindatapoints to predict on the target tasks. Our resulting method greatlyimproves language model (LM) performance on both pre-specified tasks andpreviously unseen tasks. Specifically, choosing target tasks representative ofstandard LM problems and evaluating on diverse held-out benchmarks, ourselected datasets provide a 2x compute multiplier over baseline methods.</description><author>Logan Engstrom, Axel Feldmann, Aleksander Madry</author><pubDate>Tue, 23 Jan 2024 17:22:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12926v1</guid></item><item><title>Performance Analysis of Support Vector Machine (SVM) on Challenging Datasets for Forest Fire Detection</title><link>http://arxiv.org/abs/2401.12924v1</link><description>This article delves into the analysis of performance and utilization ofSupport Vector Machines (SVMs) for the critical task of forest fire detectionusing image datasets. With the increasing threat of forest fires to ecosystemsand human settlements, the need for rapid and accurate detection systems is ofutmost importance. SVMs, renowned for their strong classification capabilities,exhibit proficiency in recognizing patterns associated with fire within images.By training on labeled data, SVMs acquire the ability to identify distinctiveattributes associated with fire, such as flames, smoke, or alterations in thevisual characteristics of the forest area. The document thoroughly examines theuse of SVMs, covering crucial elements like data preprocessing, featureextraction, and model training. It rigorously evaluates parameters such asaccuracy, efficiency, and practical applicability. The knowledge gained fromthis study aids in the development of efficient forest fire detection systems,enabling prompt responses and improving disaster management. Moreover, thecorrelation between SVM accuracy and the difficulties presented byhigh-dimensional datasets is carefully investigated, demonstrated through arevealing case study. The relationship between accuracy scores and thedifferent resolutions used for resizing the training datasets has also beendiscussed in this article. These comprehensive studies result in a definitiveoverview of the difficulties faced and the potential sectors requiring furtherimprovement and focus.</description><author>Ankan Kar, Nirjhar Nath, Utpalraj Kemprai, Aman</author><pubDate>Tue, 23 Jan 2024 17:20:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12924v1</guid></item><item><title>Deep multitask neural networks for solving some stochastic optimal control problems</title><link>http://arxiv.org/abs/2401.12923v1</link><description>Most existing neural network-based approaches for solving stochastic optimalcontrol problems using the associated backward dynamic programming principlerely on the ability to simulate the underlying state variables. However, insome problems, this simulation is infeasible, leading to the discretization ofstate variable space and the need to train one neural network for each datapoint. This approach becomes computationally inefficient when dealing withlarge state variable spaces. In this paper, we consider a class of this type ofstochastic optimal control problems and introduce an effective solutionemploying multitask neural networks. To train our multitask neural network, weintroduce a novel scheme that dynamically balances the learning across tasks.Through numerical experiments on real-world derivatives pricing problems, weprove that our method outperforms state-of-the-art approaches.</description><author>Christian Yeo</author><pubDate>Tue, 23 Jan 2024 17:20:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12923v1</guid></item><item><title>A Comprehensive Benchmark for COVID-19 Predictive Modeling Using Electronic Health Records in Intensive Care</title><link>http://arxiv.org/abs/2209.07805v4</link><description>The COVID-19 pandemic has posed a heavy burden to the healthcare systemworldwide and caused huge social disruption and economic loss. Many deeplearning models have been proposed to conduct clinical predictive tasks such asmortality prediction for COVID-19 patients in intensive care units usingElectronic Health Record (EHR) data. Despite their initial success in certainclinical applications, there is currently a lack of benchmarking results toachieve a fair comparison so that we can select the optimal model for clinicaluse. Furthermore, there is a discrepancy between the formulation of traditionalprediction tasks and real-world clinical practice in intensive care. To fillthese gaps, we propose two clinical prediction tasks, Outcome-specificlength-of-stay prediction and Early mortality prediction for COVID-19 patientsin intensive care units. The two tasks are adapted from the naivelength-of-stay and mortality prediction tasks to accommodate the clinicalpractice for COVID-19 patients. We propose fair, detailed, open-sourcedata-preprocessing pipelines and evaluate 17 state-of-the-art predictive modelson two tasks, including 5 machine learning models, 6 basic deep learning modelsand 6 deep learning predictive models specifically designed for EHR data. Weprovide benchmarking results using data from two real-world COVID-19 EHRdatasets. One dataset is publicly available without needing any inquiry andanother dataset can be accessed on request. We provide fair, reproduciblebenchmarking results for two tasks. We deploy all experiment results and modelson an online platform. We also allow clinicians and researchers to upload theirdata to the platform and get quick prediction results using our trained models.We hope our efforts can further facilitate deep learning and machine learningresearch for COVID-19 predictive modeling.</description><author>Junyi Gao, Yinghao Zhu, Wenqing Wang, Yasha Wang, Wen Tang, Ewen M. Harrison, Liantao Ma</author><pubDate>Tue, 23 Jan 2024 17:14:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.07805v4</guid></item><item><title>Truck Parking Usage Prediction with Decomposed Graph Neural Networks</title><link>http://arxiv.org/abs/2401.12920v1</link><description>Truck parking on freight corridors faces various challenges, such asinsufficient parking spaces and compliance with Hour-of-Service (HOS)regulations. These constraints often result in unauthorized parking practices,causing safety concerns. To enhance the safety of freight operations, providingaccurate parking usage prediction proves to be a cost-effective solution.Despite the existing research demonstrating satisfactory accuracy forpredicting individual truck parking site usage, few approaches have beenproposed for predicting usage with spatial dependencies of multiple truckparking sites. We present the Regional Temporal Graph Neural Network (RegT-GCN)as a predictive framework for assessing parking usage across the entire stateto provide better truck parking information and mitigate unauthorized parking.The framework leverages the topological structures of truck parking sitedistributions and historical parking data to predict occupancy rates across astate. To achieve this, we introduce a Regional Decomposition approach, whicheffectively captures the geographical characteristics. We also introduce thespatial module working efficiently with the temporal module. Evaluation resultsdemonstrate that the proposed model surpasses other baseline models, improvingthe performance by more than $20\%$ compared with the original model. Theproposed model allows truck parking sites' percipience of the topologicalstructures and provides higher performance.</description><author>Rei Tamaru, Yang Cheng, Steven Parker, Ernie Perry, Bin Ran, Soyoung Ahn</author><pubDate>Tue, 23 Jan 2024 17:14:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12920v1</guid></item><item><title>Active Inference as a Model of Agency</title><link>http://arxiv.org/abs/2401.12917v1</link><description>Is there a canonical way to think of agency beyond reward maximisation? Inthis paper, we show that any type of behaviour complying with physically soundassumptions about how macroscopic biological agents interact with the worldcanonically integrates exploration and exploitation in the sense of minimisingrisk and ambiguity about states of the world. This description, known as activeinference, refines the free energy principle, a popular descriptive frameworkfor action and perception originating in neuroscience. Active inferenceprovides a normative Bayesian framework to simulate and model agency that iswidely used in behavioural neuroscience, reinforcement learning (RL) androbotics. The usefulness of active inference for RL is three-fold. \emph{a})Active inference provides a principled solution to the exploration-exploitationdilemma that usefully simulates biological agency. \emph{b}) It provides anexplainable recipe to simulate behaviour, whence behaviour follows as anexplainable mixture of exploration and exploitation under a generative worldmodel, and all differences in behaviour are explicit in differences in worldmodel. \emph{c}) This framework is universal in the sense that it istheoretically possible to rewrite any RL algorithm conforming to thedescriptive assumptions of active inference as an active inference algorithm.Thus, active inference can be used as a tool to uncover and compare thecommitments and assumptions of more specific models of agency.</description><author>Lancelot Da Costa, Samuel Tenka, Dominic Zhao, Noor Sajid</author><pubDate>Tue, 23 Jan 2024 17:09:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12917v1</guid></item><item><title>Red Teaming Visual Language Models</title><link>http://arxiv.org/abs/2401.12915v1</link><description>VLMs (Vision-Language Models) extend the capabilities of LLMs (Large LanguageModels) to accept multimodal inputs. Since it has been verified that LLMs canbe induced to generate harmful or inaccurate content through specific testcases (termed as Red Teaming), how VLMs perform in similar scenarios,especially with their combination of textual and visual inputs, remains aquestion. To explore this problem, we present a novel red teaming datasetRTVLM, which encompasses 10 subtasks (e.g., image misleading, multi-modaljail-breaking, face fairness, etc) under 4 primary aspects (faithfulness,privacy, safety, fairness). Our RTVLM is the first red-teaming dataset tobenchmark current VLMs in terms of these 4 different aspects. Detailed analysisshows that 10 prominent open-sourced VLMs struggle with the red teaming indifferent degrees and have up to 31% performance gap with GPT-4V. Additionally,we simply apply red teaming alignment to LLaVA-v1.5 with Supervised Fine-tuning(SFT) using RTVLM, and this bolsters the models' performance with 10% in RTVLMtest set, 13% in MM-Hal, and without noticeable decline in MM-Bench,overpassing other LLaVA-based models with regular alignment data. This revealsthat current open-sourced VLMs still lack red teaming alignment. Our code anddatasets will be open-source.</description><author>Mukai Li, Lei Li, Yuwei Yin, Masood Ahmed, Zhenguang Liu, Qi Liu</author><pubDate>Tue, 23 Jan 2024 17:07:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12915v1</guid></item><item><title>Emergent Communication Protocol Learning for Task Offloading in Industrial Internet of Things</title><link>http://arxiv.org/abs/2401.12914v1</link><description>In this paper, we leverage a multi-agent reinforcement learning (MARL)framework to jointly learn a computation offloading decision and multichannelaccess policy with corresponding signaling. Specifically, the base station andindustrial Internet of Things mobile devices are reinforcement learning agentsthat need to cooperate to execute their computation tasks within a deadlineconstraint. We adopt an emergent communication protocol learning framework tosolve this problem. The numerical results illustrate the effectiveness ofemergent communication in improving the channel access success rate and thenumber of successfully computed tasks compared to contention-based,contention-free, and no-communication approaches. Moreover, the proposed taskoffloading policy outperforms remote and local computation baselines.</description><author>Salwa Mostafa, Mateus P. Mota, Alvaro Valcarce, Mehdi Bennis</author><pubDate>Tue, 23 Jan 2024 17:06:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12914v1</guid></item><item><title>WavePlanes: A compact Wavelet representation for Dynamic Neural Radiance Fields</title><link>http://arxiv.org/abs/2312.02218v2</link><description>Dynamic Neural Radiance Fields (Dynamic NeRF) enhance NeRF technology tomodel moving scenes. However, they are resource intensive and challenging tocompress. To address this issue, this paper presents WavePlanes, a fast andmore compact explicit model. We propose a multi-scale space and space-timefeature plane representation using N-level 2-D wavelet coefficients. Theinverse discrete wavelet transform reconstructs N feature signals at varyingdetail, which are linearly decoded to approximate the color and density ofvolumes in a 4-D grid. Exploiting the sparsity of wavelet coefficients, wecompress a Hash Map containing only non-zero coefficients and their locationson each plane. This results in a compressed model size of ~12 MB. Compared withstate-of-the-art plane-based models, WavePlanes is up to 15x smaller, lesscomputationally demanding and achieves comparable results in as little as onehour of training - without requiring custom CUDA code or high performancecomputing resources. Additionally, we propose new feature fusion schemes thatwork as well as previously proposed schemes while providing greaterinterpretability. Our code is available at:https://github.com/azzarelli/waveplanes/</description><author>Adrian Azzarelli, Nantheera Anantrasirichai, David R Bull</author><pubDate>Tue, 23 Jan 2024 16:53:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02218v2</guid></item><item><title>MNL-Bandit with Knapsacks: a near-optimal algorithm</title><link>http://arxiv.org/abs/2106.01135v4</link><description>We consider a dynamic assortment selection problem where a seller has a fixedinventory of $N$ substitutable products and faces an unknown demand thatarrives sequentially over $T$ periods. In each period, the seller needs todecide on the assortment of products (satisfying certain constraints) to offerto the customers. The customer's response follows an unknown multinomial logitmodel (MNL) with parameter $\boldsymbol{v}$. If customer selects product $i \in[N]$, the seller receives revenue $r_i$. The goal of the seller is to maximizethe total expected revenue from the $T$ customers given the fixed initialinventory of $N$ products. We present MNLwK-UCB, a UCB-based algorithm andcharacterize its regret under different regimes of inventory size. We show thatwhen the inventory size grows quasi-linearly in time, MNLwK-UCB achieves a$\tilde{O}(N + \sqrt{NT})$ regret bound. We also show that for a smallerinventory (with growth $\sim T^{\alpha}$, $\alpha &lt; 1$), MNLwK-UCB achieves a$\tilde{O}(N(1 + T^{\frac{1 - \alpha}{2}}) + \sqrt{NT})$. In particular, over along time horizon $T$, the rate $\tilde{O}(\sqrt{NT})$ is always achievedregardless of the constraints and the size of the inventory.</description><author>Abdellah Aznag, Vineet Goyal, Noemie Perivier</author><pubDate>Tue, 23 Jan 2024 16:52:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.01135v4</guid></item><item><title>Facing the Elephant in the Room: Visual Prompt Tuning or Full Finetuning?</title><link>http://arxiv.org/abs/2401.12902v1</link><description>As the scale of vision models continues to grow, the emergence of VisualPrompt Tuning (VPT) as a parameter-efficient transfer learning technique hasgained attention due to its superior performance compared to traditionalfull-finetuning. However, the conditions favoring VPT (the ``when") and theunderlying rationale (the ``why") remain unclear. In this paper, we conduct acomprehensive analysis across 19 distinct datasets and tasks. To understand the``when" aspect, we identify the scenarios where VPT proves favorable by twodimensions: task objectives and data distributions. We find that VPT ispreferrable when there is 1) a substantial disparity between the original andthe downstream task objectives (e.g., transitioning from classification tocounting), or 2) a similarity in data distributions between the two tasks(e.g., both involve natural images). In exploring the ``why" dimension, ourresults indicate VPT's success cannot be attributed solely to overfitting andoptimization considerations. The unique way VPT preserves original features andadds parameters appears to be a pivotal factor. Our study provides insightsinto VPT's mechanisms, and offers guidance for its optimal utilization.</description><author>Cheng Han, Qifan Wang, Yiming Cui, Wenguan Wang, Lifu Huang, Siyuan Qi, Dongfang Liu</author><pubDate>Tue, 23 Jan 2024 16:48:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12902v1</guid></item><item><title>PSAvatar: A Point-based Morphable Shape Model for Real-Time Head Avatar Creation with 3D Gaussian Splatting</title><link>http://arxiv.org/abs/2401.12900v1</link><description>Despite much progress, creating real-time high-fidelity head avatar is stilldifficult and existing methods have to trade-off between speed and quality.3DMM based methods often fail to model non-facial structures such as eyeglassesand hairstyles, while neural implicit models suffer from deformationinflexibility and rendering inefficiency. Although 3D Gaussian has been demonstrated to possess promising capabilityfor geometry representation and radiance field reconstruction, applying 3DGaussian in head avatar creation remains a major challenge since it isdifficult for 3D Gaussian to model the head shape variations caused by changingposes and expressions. In this paper, we introduce PSAvatar, a novel frameworkfor animatable head avatar creation that utilizes discrete geometric primitiveto create a parametric morphable shape model and employs 3D Gaussian for finedetail representation and high fidelity rendering. The parametric morphableshape model is a Point-based Morphable Shape Model (PMSM) which uses pointsinstead of meshes for 3D representation to achieve enhanced representationflexibility. The PMSM first converts the FLAME mesh to points by sampling onthe surfaces as well as off the meshes to enable the reconstruction of not onlysurface-like structures but also complex geometries such as eyeglasses andhairstyles. By aligning these points with the head shape in ananalysis-by-synthesis manner, the PMSM makes it possible to utilize 3D Gaussianfor fine detail representation and appearance modeling, thus enabling thecreation of high-fidelity avatars. We show that PSAvatar can reconstructhigh-fidelity head avatars of a variety of subjects and the avatars can beanimated in real-time ($\ge$ 25 fps at a resolution of 512 x 512 )</description><author>Zhongyuan Zhao, Zhenyu Bao, Qing Li, Guoping Qiu, Kanglin Liu</author><pubDate>Tue, 23 Jan 2024 16:40:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12900v1</guid></item><item><title>On the Nystrom Approximation for Preconditioning in Kernel Machines</title><link>http://arxiv.org/abs/2312.03311v3</link><description>Kernel methods are a popular class of nonlinear predictive models in machinelearning. Scalable algorithms for learning kernel models need to be iterativein nature, but convergence can be slow due to poor conditioning. Spectralpreconditioning is an important tool to speed-up the convergence of suchiterative algorithms for training kernel models. However computing and storinga spectral preconditioner can be expensive which can lead to largecomputational and storage overheads, precluding the application of kernelmethods to problems with large datasets. A Nystrom approximation of thespectral preconditioner is often cheaper to compute and store, and hasdemonstrated success in practical applications. In this paper we analyze thetrade-offs of using such an approximated preconditioner. Specifically, we showthat a sample of logarithmic size (as a function of the size of the dataset)enables the Nystrom-based approximated preconditioner to accelerate gradientdescent nearly as well as the exact preconditioner, while also reducing thecomputational and storage overheads.</description><author>Amirhesam Abedsoltan, Parthe Pandit, Luis Rademacher, Mikhail Belkin</author><pubDate>Tue, 23 Jan 2024 16:34:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.03311v3</guid></item><item><title>Industrial and Medical Anomaly Detection Through Cycle-Consistent Adversarial Networks</title><link>http://arxiv.org/abs/2302.05154v2</link><description>In this study, a new Anomaly Detection (AD) approach for industrial andmedical images is proposed. This method leverages the theoretical strengths ofunsupervised learning and the data availability of both normal and abnormalclasses. Indeed, the AD is often formulated as an unsupervised task, implyingonly normal images during training. These normal images are devoted to bereconstructed, through an autoencoder architecture for instance. However, theinformation contained in abnormal data, when available, is also valuable forthis reconstruction. The model would be able to identify its weaknesses bybetter learning how to transform an abnormal (respectively normal) image into anormal (respectively abnormal) one, helping the entire model to learn betterthan a single normal to normal reconstruction. To address this challenge, theproposed method uses Cycle-Generative Adversarial Networks (Cycle-GAN) for(ab)normal-to-normal translation. After an input image has been reconstructedby the normal generator, an anomaly score quantifies the differences betweenthe input and its reconstruction. Based on a threshold set to satisfy abusiness quality constraint, the input image is then flagged as normal or not.The proposed method is evaluated on industrial and medical datasets. Theresults demonstrate accurate performance with a zero false negative constraintcompared to state-of-the-art methods. The code is available athttps://github.com/ValDelch/CycleGANS-AnomalyDetection.</description><author>Arnaud Bougaham, Valentin Delchevalerie, Mohammed El Adoui, Benoît Frénay</author><pubDate>Tue, 23 Jan 2024 16:31:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.05154v2</guid></item><item><title>OWQ: Lessons learned from activation outliers for weight quantization in large language models</title><link>http://arxiv.org/abs/2306.02272v3</link><description>Large language models (LLMs) with hundreds of billions of parameters requirepowerful server-grade GPUs for inference, limiting their practical deployment.To address this challenge, we introduce the outlier-aware weight quantization(OWQ) method, which aims to minimize LLM's footprint through low-precisionrepresentation. OWQ prioritizes a small subset of structured weights sensitiveto quantization, storing them in high-precision, while applying highly tunedquantization to the remaining dense weights. This sensitivity-awaremixed-precision scheme reduces the quantization error notably, and extensiveexperiments demonstrate that 3.1-bit models using OWQ perform comparably to4-bit models optimized by OPTQ. Furthermore, OWQ incorporates aparameter-efficient fine-tuning for task-specific adaptation, called weakcolumn tuning (WCT), enabling accurate task-specific LLM adaptation withminimal memory overhead in the optimized format. OWQ represents a notableadvancement in the flexibility, efficiency, and practicality of LLMoptimization literature. The source code is available athttps://github.com/xvyaward/owq</description><author>Changhun Lee, Jungyu Jin, Taesu Kim, Hyungjun Kim, Eunhyeok Park</author><pubDate>Tue, 23 Jan 2024 16:28:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02272v3</guid></item><item><title>Data-Centric Evolution in Autonomous Driving: A Comprehensive Survey of Big Data System, Data Mining, and Closed-Loop Technologies</title><link>http://arxiv.org/abs/2401.12888v1</link><description>The aspiration of the next generation's autonomous driving (AD) technologyrelies on the dedicated integration and interaction among intelligentperception, prediction, planning, and low-level control. There has been a hugebottleneck regarding the upper bound of autonomous driving algorithmperformance, a consensus from academia and industry believes that the key tosurmount the bottleneck lies in data-centric autonomous driving technology.Recent advancement in AD simulation, closed-loop model training, and AD bigdata engine have gained some valuable experience. However, there is a lack ofsystematic knowledge and deep understanding regarding how to build efficientdata-centric AD technology for AD algorithm self-evolution and better AD bigdata accumulation. To fill in the identified research gaps, this article willclosely focus on reviewing the state-of-the-art data-driven autonomous drivingtechnologies, with an emphasis on the comprehensive taxonomy of autonomousdriving datasets characterized by milestone generations, key features, dataacquisition settings, etc. Furthermore, we provide a systematic review of theexisting benchmark closed-loop AD big data pipelines from the industrialfrontier, including the procedure of closed-loop frameworks, key technologies,and empirical studies. Finally, the future directions, potential applications,limitations and concerns are discussed to arouse efforts from both academia andindustry for promoting the further development of autonomous driving.</description><author>Lincan Li, Wei Shao, Wei Dong, Yijun Tian, Kaixiang Yang, Wenjie Zhang</author><pubDate>Tue, 23 Jan 2024 16:28:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12888v1</guid></item><item><title>Model-Free $δ$-Policy Iteration Based on Damped Newton Method for Nonlinear Continuous-Time H$\infty$ Tracking Control</title><link>http://arxiv.org/abs/2401.12882v1</link><description>This paper presents a {\delta}-PI algorithm which is based on damped Newtonmethod for the H{\infty} tracking control problem of unknown continuous-timenonlinear system. A discounted performance function and an augmented system areused to get the tracking Hamilton-Jacobi-Isaac (HJI) equation. Tracking HJIequation is a nonlinear partial differential equation, traditionalreinforcement learning methods for solving the tracking HJI equation are mostlybased on the Newton method, which usually only satisfies local convergence andneeds a good initial guess. Based upon the damped Newton iteration operatorequation, a generalized tracking Bellman equation is derived firstly. The{\delta}-PI algorithm can seek the optimal solution of the tracking HJIequation by iteratively solving the generalized tracking Bellman equation.On-policy learning and off-policy learning {\delta}-PI reinforcement learningmethods are provided, respectively. Off-policy version {\delta}-PI algorithm isa model-free algorithm which can be performed without making use of a prioriknowledge of the system dynamics. NN-based implementation scheme for theoff-policy {\delta}-PI algorithms is shown. The suitability of the model-free{\delta}-PI algorithm is illustrated with a nonlinear system simulation.</description><author>Qi Wang</author><pubDate>Tue, 23 Jan 2024 16:22:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12882v1</guid></item><item><title>Sample-efficient Adversarial Imitation Learning</title><link>http://arxiv.org/abs/2303.07846v2</link><description>Imitation learning, in which learning is performed by demonstration, has beenstudied and advanced for sequential decision-making tasks in which a rewardfunction is not predefined. However, imitation learning methods still requirenumerous expert demonstration samples to successfully imitate an expert'sbehavior. To improve sample efficiency, we utilize self-supervisedrepresentation learning, which can generate vast training signals from thegiven data. In this study, we propose a self-supervised representation-basedadversarial imitation learning method to learn state and action representationsthat are robust to diverse distortions and temporally predictive, on non-imagecontrol tasks. In particular, in comparison with existing self-supervisedlearning methods for tabular data, we propose a different corruption method forstate and action representations that is robust to diverse distortions. Wetheoretically and empirically observe that making an informative featuremanifold with less sample complexity significantly improves the performance ofimitation learning. The proposed method shows a 39% relative improvement overexisting adversarial imitation learning methods on MuJoCo in a setting limitedto 100 expert state-action pairs. Moreover, we conduct comprehensive ablationsand additional experiments using demonstrations with varying optimality toprovide insights into a range of factors.</description><author>Dahuin Jung, Hyungyu Lee, Sungroh Yoon</author><pubDate>Tue, 23 Jan 2024 16:14:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07846v2</guid></item><item><title>From Understanding to Utilization: A Survey on Explainability for Large Language Models</title><link>http://arxiv.org/abs/2401.12874v1</link><description>This survey paper delves into the burgeoning field of explainability forLarge Language Models (LLMs), a critical yet challenging aspect of naturallanguage processing. With LLMs playing a pivotal role in various applications,their "black-box" nature raises concerns about transparency and ethical use.This paper emphasizes the necessity for enhanced explainability in LLMs,addressing both the general public's trust and the technical community's needfor a deeper understanding of these models. We concentrate on pre-trainedTransformer-based LLMs, such as LLaMA, which present unique interpretabilitychallenges due to their scale and complexity. Our review categorizes existingexplainability methods and discusses their application in improving modeltransparency and reliability. We also discuss representative evaluationmethods, highlighting their strengths and limitations. The goal of this surveyis to bridge the gap between theoretical understanding and practicalapplication, offering insights for future research and development in the fieldof LLM explainability.</description><author>Haoyan Luo, Lucia Specia</author><pubDate>Tue, 23 Jan 2024 16:09:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12874v1</guid></item><item><title>Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model</title><link>http://arxiv.org/abs/2401.12873v1</link><description>Insufficient modeling of human preferences within the reward model is a majorobstacle for leveraging human feedback to improve translation quality.Fortunately, quality estimation (QE), which predicts the quality of a giventranslation without reference, has achieved impressive alignment with humanevaluations in the last two years. In this work, we investigate the potentialof employing the QE model as the reward model (the QE-based reward model) topredict human preferences for feedback training. We first identify theoveroptimization problem during QE-based feedback training, manifested as anincrease in reward while translation quality declines. We examine the problemand argue that the vulnerability of the QE model might lead to high rewards forincorrect translations, resulting in overoptimization and error propagation. Toaddress the problem, we adopt a simple yet effective method that uses heuristicrules to detect the incorrect translations and assigns a penalty term to theQE-based rewards for the detected incorrect translations. Experimental resultsshow that the proposed QE-based feedback training achieves consistent andsignificant improvements across various settings, further verified throughhuman preference studies. Our subsequent analysis demonstrates the high dataefficiency of the proposed QE-based feedback training: the proposed approachusing a small amount of monolingual data can outperform systems using largerparallel corpora.</description><author>Zhiwei He, Xing Wang, Wenxiang Jiao, Zhuosheng Zhang, Rui Wang, Shuming Shi, Zhaopeng Tu</author><pubDate>Tue, 23 Jan 2024 16:07:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12873v1</guid></item><item><title>Unlocking the Potential: Multi-task Deep Learning for Spaceborne Quantitative Monitoring of Fugitive Methane Plumes</title><link>http://arxiv.org/abs/2401.12870v1</link><description>With the intensification of global warming, the monitoring of methaneemission and detection of gas plumes from landfills have increasingly receivedattention. We decompose methane emission monitoring into three sub-tasks:methane concentration inversion, plume segmentation, and emission rateestimation. Conventional algorithms have limitations: methane concentrationinversion usually uses the matched filter, which is sensitive to globalspectrum distribution and contains a large amount of noises. There is limitedresearch on plume segmentation, with many studies resorting to manualsegmentation that is likely to be subjective. The estimation of methaneemission rate often utilizes IME algorithm, which relies on obtainingmeteorological measurement data. Using the WENT landfill site in Hong Kong andPRISMA hyperspectral satellite imagery, we propose a new deep learning-basedframework for quantitative monitoring of methane emissions from remote sensingimages based on physical simulation. We generate simulated methane plumes usinglarge eddy simulation (LES) and different concentration maps of fugitiveemission using the radiative transfer equation (RTE), while combiningaugmentation techniques to create a simulated PRISMA dataset. We train a U-Netnetwork for methane concentration inversion, a Mask R-CNN network for methaneplume segmentation, and a ResNet-50 network for methane emission rateestimation. All three deep networks achieve higher validation accuracy comparedto conventional algorithms. We further respectively combine the first twosub-tasks and the last two sub-tasks to design the multi-task learning models -MTL-01 and MTL-02, both of which achieve higher accuracy than single-taskmodels. Our research serves as a demonstration of applying multi-task deeplearning to quantitative methane monitoring and can be extended to a broadrange of methane monitoring tasks.</description><author>Guoxin Si, Shiliang Fu, Wei Yao</author><pubDate>Tue, 23 Jan 2024 16:04:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12870v1</guid></item><item><title>TroVE: Inducing Verifiable and Efficient Toolboxes for Solving Programmatic Tasks</title><link>http://arxiv.org/abs/2401.12869v1</link><description>Language models (LMs) can solve tasks such as answering questions abouttables or images by writing programs. However, using primitive functions oftenleads to verbose and error-prone programs, and higher-level functions requireexpert design. To enable better solutions without human labor, we ask code LMsto curate reusable high-level functions, and use them to write solutions. Wepresent TROVE, a training-free method of inducing a verifiable and efficienttoolbox of functions, by generating via using, growing, and periodicallytrimming the toolbox. On 11 datasets from math, table question answering, andimage reasoning tasks, TROVE consistently yields simpler solutions with higheraccuracy than baselines using CODELLAMA and previous methods using GPT, whileusing 79-98% smaller toolboxes. TROVE further enables 31% faster and 13% moreaccurate human verification than baselines. With the same pipeline, it createsdiverse functions for varied tasks and datasets, providing insights into theirindividual characteristics.</description><author>Zhiruo Wang, Daniel Fried, Graham Neubig</author><pubDate>Tue, 23 Jan 2024 16:03:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12869v1</guid></item><item><title>When Does Confidence-Based Cascade Deferral Suffice?</title><link>http://arxiv.org/abs/2307.02764v2</link><description>Cascades are a classical strategy to enable inference cost to vary adaptivelyacross samples, wherein a sequence of classifiers are invoked in turn. Adeferral rule determines whether to invoke the next classifier in the sequence,or to terminate prediction. One simple deferral rule employs the confidence ofthe current classifier, e.g., based on the maximum predicted softmaxprobability. Despite being oblivious to the structure of the cascade -- e.g.,not modelling the errors of downstream models -- such confidence-based deferraloften works remarkably well in practice. In this paper, we seek to betterunderstand the conditions under which confidence-based deferral may fail, andwhen alternate deferral strategies can perform better. We first present atheoretical characterisation of the optimal deferral rule, which preciselycharacterises settings under which confidence-based deferral may suffer. Wethen study post-hoc deferral mechanisms, and demonstrate they can significantlyimprove upon confidence-based deferral in settings where (i) downstream modelsare specialists that only work well on a subset of inputs, (ii) samples aresubject to label noise, and (iii) there is distribution shift between the trainand test set.</description><author>Wittawat Jitkrittum, Neha Gupta, Aditya Krishna Menon, Harikrishna Narasimhan, Ankit Singh Rawat, Sanjiv Kumar</author><pubDate>Tue, 23 Jan 2024 16:01:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02764v2</guid></item><item><title>Evaluating Collaborative and Autonomous Agents in Data-Stream-Supported Coordination of Mobile Crowdsourcing</title><link>http://arxiv.org/abs/2401.12866v1</link><description>Mobile crowdsourcing refers to systems where the completion of tasksnecessarily requires physical movement of crowdworkers in an on-demandworkforce. Evidence suggests that in such systems, tasks often get assigned tocrowdworkers who struggle to complete those tasks successfully, resulting inhigh failure rates and low service quality. A promising solution to ensurehigher quality of service is to continuously adapt the assignment and respondto failure-causing events by transferring tasks to better-suited workers whouse different routes or vehicles. However, implementing task transfers inmobile crowdsourcing is difficult because workers are autonomous and may rejecttransfer requests. Moreover, task outcomes are uncertain and need to bepredicted. In this paper, we propose different mechanisms to achieve outcomeprediction and task coordination in mobile crowdsourcing. First, we analyzedifferent data stream learning approaches for the prediction of task outcomes.Second, based on the suggested prediction model, we propose and evaluate twodifferent approaches for task coordination with different degrees of autonomy:an opportunistic approach for crowdshipping with collaborative, butnon-autonomous workers, and a market-based model with autonomous workers forcrowdsensing.</description><author>Ralf Bruns, Jeremias Dötterl, Jürgen Dunkel, Sascha Ossowski</author><pubDate>Tue, 23 Jan 2024 16:00:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12866v1</guid></item><item><title>KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning</title><link>http://arxiv.org/abs/2401.12863v1</link><description>Large Language Models (LLMs) have demonstrated impressive performance innatural language processing tasks by leveraging chain of thought (CoT) thatenables step-by-step thinking. Extending LLMs with multimodal capabilities isthe recent interest, but incurs computational cost and requires substantialhardware resources. To address these challenges, we propose KAM-CoT a frameworkthat integrates CoT reasoning, Knowledge Graphs (KGs), and multiple modalitiesfor a comprehensive understanding of multimodal tasks. KAM-CoT adopts atwo-stage training process with KG grounding to generate effective rationalesand answers. By incorporating external knowledge from KGs during reasoning, themodel gains a deeper contextual understanding reducing hallucinations andenhancing the quality of answers. This knowledge-augmented CoT reasoningempowers the model to handle questions requiring external context, providingmore informed answers. Experimental findings show KAM-CoT outperforms thestate-of-the-art methods. On the ScienceQA dataset, we achieve an averageaccuracy of 93.87%, surpassing GPT-3.5 (75.17%) by 18% and GPT-4 (83.99%) by10%. Remarkably, KAM-CoT achieves these results with only 280M trainableparameters at a time, demonstrating its cost-efficiency and effectiveness.</description><author>Debjyoti Mondal, Suraj Modi, Subhadarshi Panda, Rituraj Singh, Godawari Sudhakar Rao</author><pubDate>Tue, 23 Jan 2024 15:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12863v1</guid></item><item><title>FedRSU: Federated Learning for Scene Flow Estimation on Roadside Units</title><link>http://arxiv.org/abs/2401.12862v1</link><description>Roadside unit (RSU) can significantly improve the safety and robustness ofautonomous vehicles through Vehicle-to-Everything (V2X) communication.Currently, the usage of a single RSU mainly focuses on real-time inference andV2X collaboration, while neglecting the potential value of the high-qualitydata collected by RSU sensors. Integrating the vast amounts of data fromnumerous RSUs can provide a rich source of data for model training. However,the absence of ground truth annotations and the difficulty of transmittingenormous volumes of data are two inevitable barriers to fully exploiting thishidden value. In this paper, we introduce FedRSU, an innovative federatedlearning framework for self-supervised scene flow estimation. In FedRSU, wepresent a recurrent self-supervision training paradigm, where for each RSU, thescene flow prediction of points at every timestamp can be supervised by itssubsequent future multi-modality observation. Another key component of FedRSUis federated learning, where multiple devices collaboratively train an ML modelwhile keeping the training data local and private. With the power of therecurrent self-supervised learning paradigm, FL is able to leverage innumerableunderutilized data from RSU. To verify the FedRSU framework, we construct alarge-scale multi-modality dataset RSU-SF. The dataset consists of 17 RSUclients, covering various scenarios, modalities, and sensor settings. Based onRSU-SF, we show that FedRSU can greatly improve model performance in ITS andprovide a comprehensive benchmark under diverse FL scenarios. To the best ofour knowledge, we provide the first real-world LiDAR-camera multi-modal datasetand benchmark for the FL community.</description><author>Shaoheng Fang, Rui Ye, Wenhao Wang, Zuhong Liu, Yuxiao Wang, Yafei Wang, Siheng Chen, Yanfeng Wang</author><pubDate>Tue, 23 Jan 2024 15:52:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12862v1</guid></item><item><title>Energy-based Models are Zero-Shot Planners for Compositional Scene Rearrangement</title><link>http://arxiv.org/abs/2304.14391v4</link><description>Language is compositional; an instruction can express multiple relationconstraints to hold among objects in a scene that a robot is tasked torearrange. Our focus in this work is an instructable scene-rearrangingframework that generalizes to longer instructions and to spatial conceptcompositions never seen at training time. We propose to representlanguage-instructed spatial concepts with energy functions over relative objectarrangements. A language parser maps instructions to corresponding energyfunctions and an open-vocabulary visual-language model grounds their argumentsto relevant objects in the scene. We generate goal scene configurations bygradient descent on the sum of energy functions, one per language predicate inthe instruction. Local vision-based policies then re-locate objects to theinferred goal locations. We test our model on established instruction-guidedmanipulation benchmarks, as well as benchmarks of compositional instructions weintroduce. We show our model can execute highly compositional instructionszero-shot in simulation and in the real world. It outperformslanguage-to-action reactive policies and Large Language Model planners by alarge margin, especially for long instructions that involve compositions ofmultiple spatial concepts. Simulation and real-world robot execution videos, aswell as our code and datasets are publicly available on our website:https://ebmplanner.github.io.</description><author>Nikolaos Gkanatsios, Ayush Jain, Zhou Xian, Yunchu Zhang, Christopher Atkeson, Katerina Fragkiadaki</author><pubDate>Tue, 23 Jan 2024 15:52:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14391v4</guid></item><item><title>VGDiffZero: Text-to-image Diffusion Models Can Be Zero-shot Visual Grounders</title><link>http://arxiv.org/abs/2309.01141v4</link><description>Large-scale text-to-image diffusion models have shown impressive capabilitiesfor generative tasks by leveraging strong vision-language alignment frompre-training. However, most vision-language discriminative tasks requireextensive fine-tuning on carefully-labeled datasets to acquire such alignment,with great cost in time and computing resources. In this work, we exploredirectly applying a pre-trained generative diffusion model to the challengingdiscriminative task of visual grounding without any fine-tuning and additionaltraining dataset. Specifically, we propose VGDiffZero, a simple yet effectivezero-shot visual grounding framework based on text-to-image diffusion models.We also design a comprehensive region-scoring method considering both globaland local contexts of each isolated proposal. Extensive experiments on RefCOCO,RefCOCO+, and RefCOCOg show that VGDiffZero achieves strong performance onzero-shot visual grounding. Our code is available athttps://github.com/xuyang-liu16/VGDiffZero.</description><author>Xuyang Liu, Siteng Huang, Yachen Kang, Honggang Chen, Donglin Wang</author><pubDate>Tue, 23 Jan 2024 15:51:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01141v4</guid></item><item><title>Classification of grapevine varieties using UAV hyperspectral imaging</title><link>http://arxiv.org/abs/2401.12851v1</link><description>The classification of different grapevine varieties is a relevant phenotypingtask in Precision Viticulture since it enables estimating the growth ofvineyard rows dedicated to different varieties, among other applicationsconcerning the wine industry. This task can be performed with destructivemethods that require time-consuming tasks, including data collection andanalysis in the laboratory. However, Unmanned Aerial Vehicles (UAV) provide amore efficient and less prohibitive approach to collecting hyperspectral data,despite acquiring noisier data. Therefore, the first task is the processing ofthese data to correct and downsample large amounts of data. In addition, thehyperspectral signatures of grape varieties are very similar. In this work, aConvolutional Neural Network (CNN) is proposed for classifying seventeenvarieties of red and white grape variants. Rather than classifying singlesamples, these are processed together with their neighbourhood. Hence, theextraction of spatial and spectral features is addressed with 1) a spatialattention layer and 2) Inception blocks. The pipeline goes from processing todataset elaboration, finishing with the training phase. The fitted model isevaluated in terms of response time, accuracy and data separability, andcompared with other state-of-the-art CNNs for classifying hyperspectral data.Our network was proven to be much more lightweight with a reduced number ofinput bands, a lower number of trainable weights and therefore, reducedtraining time. Despite this, the evaluated metrics showed much better resultsfor our network (~99% overall accuracy), in comparison with previous worksbarely achieving 81% OA.</description><author>Alfonso López, Carlos Javier Ogayar, Francisco Ramón Feito, Joaquim João Sousa</author><pubDate>Tue, 23 Jan 2024 15:35:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12851v1</guid></item><item><title>Overlap-aware End-to-End Supervised Hierarchical Graph Clustering for Speaker Diarization</title><link>http://arxiv.org/abs/2401.12850v1</link><description>Speaker diarization, the task of segmenting an audio recording based onspeaker identity, constitutes an important speech pre-processing step forseveral downstream applications. The conventional approach to diarizationinvolves multiple steps of embedding extraction and clustering, which are oftenoptimized in an isolated fashion. While end-to-end diarization systems attemptto learn a single model for the task, they are often cumbersome to train andrequire large supervised datasets. In this paper, we propose an end-to-endsupervised hierarchical clustering algorithm based on graph neural networks(GNN), called End-to-end Supervised HierARchical Clustering (E-SHARC). TheE-SHARC approach uses front-end mel-filterbank features as input and jointlylearns an embedding extractor and the GNN clustering module, performingrepresentation learning, metric learning, and clustering with end-to-endoptimization. Further, with additional inputs from an external overlapdetector, the E-SHARC approach is capable of predicting the speakers in theoverlapping speech regions. The experimental evaluation on several benchmarkdatasets like AMI, VoxConverse and DISPLACE, illustrates that the proposedE-SHARC framework improves significantly over the state-of-art diarizationsystems.</description><author>Prachi Singh, Sriram Ganapathy</author><pubDate>Tue, 23 Jan 2024 15:35:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12850v1</guid></item><item><title>Learning safety critics via a non-contractive binary bellman operator</title><link>http://arxiv.org/abs/2401.12849v1</link><description>The inability to naturally enforce safety in Reinforcement Learning (RL),with limited failures, is a core challenge impeding its use in real-worldapplications. One notion of safety of vast practical relevance is the abilityto avoid (unsafe) regions of the state space. Though such a safety goal can becaptured by an action-value-like function, a.k.a. safety critics, theassociated operator lacks the desired contraction and uniqueness propertiesthat the classical Bellman operator enjoys. In this work, we overcome thenon-contractiveness of safety critic operators by leveraging that safety is abinary property. To that end, we study the properties of the binary safetycritic associated with a deterministic dynamical system that seeks to avoidreaching an unsafe region. We formulate the corresponding binary Bellmanequation (B2E) for safety and study its properties. While the resultingoperator is still non-contractive, we fully characterize its fixed pointsrepresenting--except for a spurious solution--maximal persistently safe regionsof the state space that can always avoid failure. We provide an algorithm that,by design, leverages axiomatic knowledge of safe data to avoid spurious fixedpoints.</description><author>Agustin Castellano, Hancheng Min, Juan Andrés Bazerque, Enrique Mallada</author><pubDate>Tue, 23 Jan 2024 15:33:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12849v1</guid></item><item><title>AIGCBench: Comprehensive Evaluation of Image-to-Video Content Generated by AI</title><link>http://arxiv.org/abs/2401.01651v3</link><description>The burgeoning field of Artificial Intelligence Generated Content (AIGC) iswitnessing rapid advancements, particularly in video generation. This paperintroduces AIGCBench, a pioneering comprehensive and scalable benchmarkdesigned to evaluate a variety of video generation tasks, with a primary focuson Image-to-Video (I2V) generation. AIGCBench tackles the limitations ofexisting benchmarks, which suffer from a lack of diverse datasets, by includinga varied and open-domain image-text dataset that evaluates differentstate-of-the-art algorithms under equivalent conditions. We employ a novel textcombiner and GPT-4 to create rich text prompts, which are then used to generateimages via advanced Text-to-Image models. To establish a unified evaluationframework for video generation tasks, our benchmark includes 11 metricsspanning four dimensions to assess algorithm performance. These dimensions arecontrol-video alignment, motion effects, temporal consistency, and videoquality. These metrics are both reference video-dependent and video-free,ensuring a comprehensive evaluation strategy. The evaluation standard proposedcorrelates well with human judgment, providing insights into the strengths andweaknesses of current I2V algorithms. The findings from our extensiveexperiments aim to stimulate further research and development in the I2V field.AIGCBench represents a significant step toward creating standardized benchmarksfor the broader AIGC landscape, proposing an adaptable and equitable frameworkfor future assessments of video generation tasks. We have open-sourced thedataset and evaluation code on the project website:https://www.benchcouncil.org/AIGCBench.</description><author>Fanda Fan, Chunjie Luo, Wanling Gao, Jianfeng Zhan</author><pubDate>Tue, 23 Jan 2024 15:31:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01651v3</guid></item><item><title>How well can large language models explain business processes?</title><link>http://arxiv.org/abs/2401.12846v1</link><description>Large Language Models (LLMs) are likely to play a prominent role in futureAI-augmented business process management systems (ABPMSs) cateringfunctionalities across all system lifecycle stages. One such system'sfunctionality is Situation-Aware eXplainability (SAX), which relates togenerating causally sound and yet human-interpretable explanations that takeinto account the process context in which the explained condition occurred. Inthis paper, we present the SAX4BPM framework developed to generate SAXexplanations. The SAX4BPM suite consists of a set of services and a centralknowledge repository. The functionality of these services is to elicit thevarious knowledge ingredients that underlie SAX explanations. A key innovativecomponent among these ingredients is the causal process execution view. In thiswork, we integrate the framework with an LLM to leverage its power tosynthesize the various input ingredients for the sake of improved SAXexplanations. Since the use of LLMs for SAX is also accompanied by a certaindegree of doubt related to its capacity to adequately fulfill SAX along withits tendency for hallucination and lack of inherent capacity to reason, wepursued a methodological evaluation of the quality of the generatedexplanations. To this aim, we developed a designated scale and conducted arigorous user study. Our findings show that the input presented to the LLMsaided with the guard-railing of its performance, yielding SAX explanationshaving better-perceived fidelity. This improvement is moderated by theperception of trust and curiosity. More so, this improvement comes at the costof the perceived interpretability of the explanation.</description><author>Dirk Fahland, Fabian Fournier, Lior Limonad, Inna Skarbovsky, Ava J. E. Swevels</author><pubDate>Tue, 23 Jan 2024 15:29:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12846v1</guid></item><item><title>From Generative AI to Generative Internet of Things: Fundamentals, Framework, and Outlooks</title><link>http://arxiv.org/abs/2310.18382v2</link><description>Generative Artificial Intelligence (GAI) possesses the capabilities ofgenerating realistic data and facilitating advanced decision-making. Byintegrating GAI into modern Internet of Things (IoT), Generative Internet ofThings (GIoT) is emerging and holds immense potential to revolutionize variousaspects of society, enabling more efficient and intelligent IoT applications,such as smart surveillance and voice assistants. In this article, we presentthe concept of GIoT and conduct an exploration of its potential prospects.Specifically, we first overview four GAI techniques and investigate promisingGIoT applications. Then, we elaborate on the main challenges in enabling GIoTand propose a general GAI-based secure incentive mechanism framework to addressthem, in which we adopt Generative Diffusion Models (GDMs) for incentivemechanism designs and apply blockchain technologies for secure GIoT management.Moreover, we conduct a case study on modern Internet of Vehicle trafficmonitoring, which utilizes GDMs to generate effective contracts forincentivizing users to contribute sensing data with high quality. Finally, wesuggest several open directions worth investigating for the future popularityof GIoT.</description><author>Jinbo Wen, Jiangtian Nie, Jiawen Kang, Dusit Niyato, Hongyang Du, Yang Zhang, Mohsen Guizani</author><pubDate>Tue, 23 Jan 2024 15:27:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18382v2</guid></item><item><title>An embedding-based distance for temporal graphs</title><link>http://arxiv.org/abs/2401.12843v1</link><description>We define a distance between temporal graphs based on graph embeddings builtusing time-respecting random walks. We study both the case of matched graphs,when there exists a known relation between the nodes, and the unmatched case,when such a relation is unavailable and the graphs may be of different sizes.We illustrate the interest of our distance definition, using both real andsynthetic temporal network data, by showing its ability to discriminate betweengraphs with different structural and temporal properties. Leveragingstate-of-the-art machine learning techniques, we propose an efficientimplementation of distance computation that is viable for large-scale temporalgraphs.</description><author>Lorenzo Dall'Amico, Alain Barrat, Ciro Cattuto</author><pubDate>Tue, 23 Jan 2024 15:25:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12843v1</guid></item><item><title>Iterated Relevance Matrix Analysis (IRMA) for the identification of class-discriminative subspaces</title><link>http://arxiv.org/abs/2401.12842v1</link><description>We introduce and investigate the iterated application of Generalized MatrixLearning Vector Quantizaton for the analysis of feature relevances inclassification problems, as well as for the construction ofclass-discriminative subspaces. The suggested Iterated Relevance MatrixAnalysis (IRMA) identifies a linear subspace representing the classificationspecific information of the considered data sets using Generalized MatrixLearning Vector Quantization (GMLVQ). By iteratively determining a newdiscriminative subspace while projecting out all previously identified ones, acombined subspace carrying all class-specific information can be found. Thisfacilitates a detailed analysis of feature relevances, and enables improvedlow-dimensional representations and visualizations of labeled data sets.Additionally, the IRMA-based class-discriminative subspace can be used fordimensionality reduction and the training of robust classifiers withpotentially improved performance.</description><author>Sofie Lövdal, Michael Biehl</author><pubDate>Tue, 23 Jan 2024 15:23:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12842v1</guid></item><item><title>DeepCERES: A Deep learning method for cerebellar lobule segmentation using ultra-high resolution multimodal MRI</title><link>http://arxiv.org/abs/2401.12074v2</link><description>This paper introduces a novel multimodal and high-resolution human braincerebellum lobule segmentation method. Unlike current tools that operate atstandard resolution ($1 \text{ mm}^{3}$) or using mono-modal data, the proposedmethod improves cerebellum lobule segmentation through the use of a multimodaland ultra-high resolution ($0.125 \text{ mm}^{3}$) training dataset. To developthe method, first, a database of semi-automatically labelled cerebellum lobuleswas created to train the proposed method with ultra-high resolution T1 and T2MR images. Then, an ensemble of deep networks has been designed and developed,allowing the proposed method to excel in the complex cerebellum lobulesegmentation task, improving precision while being memory efficient. Notably,our approach deviates from the traditional U-Net model by exploring alternativearchitectures. We have also integrated deep learning with classical machinelearning methods incorporating a priori knowledge from multi-atlassegmentation, which improved precision and robustness. Finally, a new onlinepipeline, named DeepCERES, has been developed to make available the proposedmethod to the scientific community requiring as input only a single T1 MR imageat standard resolution.</description><author>Sergio Morell-Ortega, Marina Ruiz-Perez, Marien Gadea, Roberto Vivo-Hernando, Gregorio Rubio, Fernando Aparici, Maria de la Iglesia-Vaya, Gwenaelle Catheline, Pierrick Coupé, José V. Manjón</author><pubDate>Tue, 23 Jan 2024 15:23:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12074v2</guid></item><item><title>AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ</title><link>http://arxiv.org/abs/2310.00367v2</link><description>Generating bitmap graphics from text has gained considerable attention, yetfor scientific figures, vector graphics are often preferred. Given that vectorgraphics are typically encoded using low-level graphics primitives, generatingthem directly is difficult. To address this, we propose the use of TikZ, awell-known abstract graphics language that can be compiled to vector graphics,as an intermediate representation of scientific figures. TikZ offershuman-oriented, high-level commands, thereby facilitating conditional languagemodeling with any large language model. To this end, we introduce DaTikZ, thefirst large-scale TikZ dataset consisting of 120k TikZ drawings aligned withcaptions. We fine-tune LLaMA on DaTikZ, as well as our new model CLiMA, whichaugments LLaMA with multimodal CLIP embeddings. In both human and automaticevaluation, CLiMA and LLaMA outperform commercial GPT-4 and Claude 2 in termsof similarity to human-created figures, with CLiMA additionally improvingtext-image alignment. Our detailed analysis shows that all models generalizewell and are not susceptible to memorization. GPT-4 and Claude 2, however, tendto generate more simplistic figures compared to both humans and our models. Wemake our framework, AutomaTikZ, along with model weights and datasets, publiclyavailable.</description><author>Jonas Belouadi, Anne Lauscher, Steffen Eger</author><pubDate>Tue, 23 Jan 2024 15:20:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00367v2</guid></item><item><title>SGTR+: End-to-end Scene Graph Generation with Transformer</title><link>http://arxiv.org/abs/2401.12835v1</link><description>Scene Graph Generation (SGG) remains a challenging visual understanding taskdue to its compositional property. Most previous works adopt a bottom-up,two-stage or point-based, one-stage approach, which often suffers from hightime complexity or suboptimal designs. In this work, we propose a novel SGGmethod to address the aforementioned issues, formulating the task as abipartite graph construction problem. To address the issues above, we create atransformer-based end-to-end framework to generate the entity and entity-awarepredicate proposal set, and infer directed edges to form relation triplets.Moreover, we design a graph assembling module to infer the connectivity of thebipartite scene graph based on our entity-aware structure, enabling us togenerate the scene graph in an end-to-end manner. Based on bipartite graphassembling paradigm, we further propose a new technical design to address theefficacy of entity-aware modeling and optimization stability of graphassembling. Equipped with the enhanced entity-aware design, our method achievesoptimal performance and time-complexity. Extensive experimental results showthat our design is able to achieve the state-of-the-art or comparableperformance on three challenging benchmarks, surpassing most of the existingapproaches and enjoying higher efficiency in inference. Code is available:https://github.com/Scarecrow0/SGTR</description><author>Rongjie Li, Songyang Zhang, Xuming He</author><pubDate>Tue, 23 Jan 2024 15:18:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12835v1</guid></item><item><title>PartIR: Composing SPMD Partitioning Strategies for Machine Learning</title><link>http://arxiv.org/abs/2401.11202v2</link><description>Training of modern large neural networks (NN) requires a combination ofparallelization strategies encompassing data, model, or optimizer sharding.When strategies increase in complexity, it becomes necessary for partitioningtools to be 1) expressive, allowing the composition of simpler strategies, and2) predictable to estimate performance analytically. We present PartIR, ourdesign for a NN partitioning system. PartIR is focused on an incrementalapproach to rewriting and is hardware-and-runtime agnostic. We present a simplebut powerful API for composing sharding strategies and a simulator to validatethem. The process is driven by high-level programmer-issued partitioningtactics, which can be both manual and automatic. Importantly, the tactics arespecified separately from the model code, making them easy to change. Weevaluate PartIR on several different models to demonstrate its predictability,expressibility, and ability to reach peak performance..</description><author>Sami Alabed, Bart Chrzaszcz, Juliana Franco, Dominik Grewe, Dougal Maclaurin, James Molloy, Tom Natan, Tamara Norman, Xiaoyue Pan, Adam Paszke, Norman A. Rink, Michael Schaarschmidt, Timur Sitdikov, Agnieszka Swietlik, Dimitrios Vytiniotis, Joel Wee</author><pubDate>Tue, 23 Jan 2024 15:11:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11202v2</guid></item><item><title>Defensive Alliances in Signed Networks</title><link>http://arxiv.org/abs/2309.06801v2</link><description>The analysis of (social) networks and multi-agent systems is a central themein Artificial Intelligence. Some line of research deals with finding groups ofagents that could work together to achieve a certain goal. To this end,different notions of so-called clusters or communities have been introduced inthe literature of graphs and networks. Among these, defensive alliance is akind of quantitative group structure. However, all studies on the alliance sofor have ignored one aspect that is central to the formation of alliances on avery intuitive level, assuming that the agents are preconditioned concerningtheir attitude towards other agents: they prefer to be in some group (alliance)together with the agents they like, so that they are happy to help each othertowards their common aim, possibly then working against the agents outside oftheir group that they dislike. Signed networks were introduced in thepsychology literature to model liking and disliking between agents,generalizing graphs in a natural way. Hence, we propose the novel notion of adefensive alliance in the context of signed networks. We then investigateseveral natural algorithmic questions related to this notion. These, and alsocombinatorial findings, connect our notion to that of correlation clustering,which is a well-established idea of finding groups of agents within a signednetwork. Also, we introduce a new structural parameter for signed graphs,signed neighborhood diversity snd, and exhibit a parameterized algorithm thatfinds a smallest defensive alliance in a signed graph.</description><author>Emmanuel Arrighi, Zhidan Feng, Henning Fernau, Kevin Mann, Xingqin Qi, Petra Wolf</author><pubDate>Tue, 23 Jan 2024 15:11:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06801v2</guid></item><item><title>Enhancing Next Destination Prediction: A Novel LSTM Approach Using Real-World Airline Data</title><link>http://arxiv.org/abs/2401.12830v1</link><description>In the modern transportation industry, accurate prediction of travelers' nextdestinations brings multiple benefits to companies, such as customersatisfaction and targeted marketing. This study focuses on developing a precisemodel that captures the sequential patterns and dependencies in travel data,enabling accurate predictions of individual travelers' future destinations. Toachieve this, a novel model architecture with a sliding window approach basedon Long Short-Term Memory (LSTM) is proposed for destination prediction in thetransportation industry. The experimental results highlight satisfactoryperformance and high scores achieved by the proposed model across differentdata sizes and performance metrics. This research contributes to advancingdestination prediction methods, empowering companies to deliver personalizedrecommendations and optimize customer experiences in the dynamic travellandscape.</description><author>Salih Salihoglu, Gulser Koksal, Orhan Abar</author><pubDate>Tue, 23 Jan 2024 15:07:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12830v1</guid></item><item><title>MAPPING: Debiasing Graph Neural Networks for Fair Node Classification with Limited Sensitive Information Leakage</title><link>http://arxiv.org/abs/2401.12824v1</link><description>Despite remarkable success in diverse web-based applications, Graph NeuralNetworks(GNNs) inherit and further exacerbate historical discrimination andsocial stereotypes, which critically hinder their deployments in high-stakedomains such as online clinical diagnosis, financial crediting, etc. However,current fairness research that primarily craft on i.i.d data, cannot betrivially replicated to non-i.i.d. graph structures with topological dependenceamong samples. Existing fair graph learning typically favors pairwiseconstraints to achieve fairness but fails to cast off dimensional limitationsand generalize them into multiple sensitive attributes; besides, most studiesfocus on in-processing techniques to enforce and calibrate fairness,constructing a model-agnostic debiasing GNN framework at the pre-processingstage to prevent downstream misuses and improve training reliability is stilllargely under-explored. Furthermore, previous work on GNNs tend to enhanceeither fairness or privacy individually but few probe into their interplays. Inthis paper, we propose a novel model-agnostic debiasing framework named MAPPING(\underline{M}asking \underline{A}nd \underline{P}runing andMessage-\underline{P}assing train\underline{ING}) for fair node classification,in which we adopt the distance covariance($dCov$)-based fairness constraints tosimultaneously reduce feature and topology biases in arbitrary dimensions, andcombine them with adversarial debiasing to confine the risks of attributeinference attacks. Experiments on real-world datasets with different GNNvariants demonstrate the effectiveness and flexibility of MAPPING. Our resultsshow that MAPPING can achieve better trade-offs between utility and fairness,and mitigate privacy risks of sensitive information leakage.</description><author>Ying Song, Balaji Palanisamy</author><pubDate>Tue, 23 Jan 2024 14:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12824v1</guid></item><item><title>Deep Learning Based Simulators for the Phosphorus Removal Process Control in Wastewater Treatment via Deep Reinforcement Learning Algorithms</title><link>http://arxiv.org/abs/2401.12822v1</link><description>Phosphorus removal is vital in wastewater treatment to reduce reliance onlimited resources. Deep reinforcement learning (DRL) is a machine learningtechnique that can optimize complex and nonlinear systems, including theprocesses in wastewater treatment plants, by learning control policies throughtrial and error. However, applying DRL to chemical and biological processes ischallenging due to the need for accurate simulators. This study trained sixmodels to identify the phosphorus removal process and used them to create asimulator for the DRL environment. Although the models achieved high accuracy(&gt;97%), uncertainty and incorrect prediction behavior limited their performanceas simulators over longer horizons. Compounding errors in the models'predictions were identified as one of the causes of this problem. This approachfor improving process control involves creating simulation environments for DRLalgorithms, using data from supervisory control and data acquisition (SCADA)systems with a sufficient historical horizon without complex system modeling orparameter estimation.</description><author>Esmaeel Mohammadi, Mikkel Stokholm-Bjerregaard, Aviaja Anna Hansen, Per Halkjær Nielsen, Daniel Ortiz-Arroyo, Petar Durdevic</author><pubDate>Tue, 23 Jan 2024 14:55:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12822v1</guid></item><item><title>DatUS^2: Data-driven Unsupervised Semantic Segmentation with Pre-trained Self-supervised Vision Transformer</title><link>http://arxiv.org/abs/2401.12820v1</link><description>Successive proposals of several self-supervised training schemes continue toemerge, taking one step closer to developing a universal foundation model. Inthis process, the unsupervised downstream tasks are recognized as one of theevaluation methods to validate the quality of visual features learned with aself-supervised training scheme. However, unsupervised dense semanticsegmentation has not been explored as a downstream task, which can utilize andevaluate the quality of semantic information introduced in patch-level featurerepresentations during self-supervised training of a vision transformer.Therefore, this paper proposes a novel data-driven approach for unsupervisedsemantic segmentation (DatUS^2) as a downstream task. DatUS^2 generatessemantically consistent and dense pseudo annotate segmentation masks for theunlabeled image dataset without using any visual-prior or synchronized data. Wecompare these pseudo-annotated segmentation masks with ground truth masks forevaluating recent self-supervised training schemes to learn shared semanticproperties at the patch level and discriminative semantic properties at thesegment level. Finally, we evaluate existing state-of-the-art self-supervisedtraining schemes with our proposed downstream task, i.e., DatUS^2. Also, thebest version of DatUS^2 outperforms the existing state-of-the-art method forthe unsupervised dense semantic segmentation task with 15.02% MiOU and 21.47%Pixel accuracy on the SUIM dataset. It also achieves a competitive level ofaccuracy for a large-scale and complex dataset, i.e., the COCO dataset.</description><author>Sonal Kumar, Arijit Sur, Rashmi Dutta Baruah</author><pubDate>Tue, 23 Jan 2024 14:53:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12820v1</guid></item><item><title>Dynamic Layer Tying for Parameter-Efficient Transformers</title><link>http://arxiv.org/abs/2401.12819v1</link><description>In the pursuit of reducing the number of trainable parameters in deeptransformer networks, we employ Reinforcement Learning to dynamically selectlayers during training and tie them together. Every few iterations, the RLagent is asked whether to train each layer $i$ independently or to copy theweights of a previous layer $j&lt;i$. This facilitates weight sharing, reduces thenumber of trainable parameters, and also serves as an effective regularizationtechnique. Experimental evaluations validate that our model modestlyoutperforms the baseline transformer model with regard to perplexity anddrastically reduces the number of trainable parameters. In particular, thememory consumption during training is up to one order of magnitude less thanthe conventional training method.</description><author>Tamir David Hay, Lior Wolf</author><pubDate>Tue, 23 Jan 2024 14:53:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12819v1</guid></item><item><title>Score-Based Generative Models for PET Image Reconstruction</title><link>http://arxiv.org/abs/2308.14190v2</link><description>Score-based generative models have demonstrated highly promising results formedical image reconstruction tasks in magnetic resonance imaging or computedtomography. However, their application to Positron Emission Tomography (PET) isstill largely unexplored. PET image reconstruction involves a variety ofchallenges, including Poisson noise with high variance and a wide dynamicrange. To address these challenges, we propose several PET-specific adaptationsof score-based generative models. The proposed framework is developed for both2D and 3D PET. In addition, we provide an extension to guided reconstructionusing magnetic resonance images. We validate the approach through extensive 2Dand 3D $\textit{in-silico}$ experiments with a model trained onpatient-realistic data without lesions, and evaluate on data without lesions aswell as out-of-distribution data with lesions. This demonstrates the proposedmethod's robustness and significant potential for improved PET reconstruction.</description><author>Imraj RD Singh, Alexander Denker, Riccardo Barbano, Željko Kereta, Bangti Jin, Kris Thielemans, Peter Maass, Simon Arridge</author><pubDate>Tue, 23 Jan 2024 14:51:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.14190v2</guid></item><item><title>Multilingual acoustic word embeddings for zero-resource languages</title><link>http://arxiv.org/abs/2401.10543v2</link><description>This research addresses the challenge of developing speech applications forzero-resource languages that lack labelled data. It specifically uses acousticword embedding (AWE) -- fixed-dimensional representations of variable-durationspeech segments -- employing multilingual transfer, where labelled data fromseveral well-resourced languages are used for pertaining. The study introducesa new neural network that outperforms existing AWE models on zero-resourcelanguages. It explores the impact of the choice of well-resourced languages.AWEs are applied to a keyword-spotting system for hate speech detection inSwahili radio broadcasts, demonstrating robustness in real-world scenarios.Additionally, novel semantic AWE models improve semantic query-by-examplesearch.</description><author>Christiaan Jacobs</author><pubDate>Tue, 23 Jan 2024 14:46:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10543v2</guid></item><item><title>Infinite-Horizon Graph Filters: Leveraging Power Series to Enhance Sparse Information Aggregation</title><link>http://arxiv.org/abs/2401.09943v2</link><description>Graph Neural Networks (GNNs) have shown considerable effectiveness in avariety of graph learning tasks, particularly those based on themessage-passing approach in recent years. However, their performance is oftenconstrained by a limited receptive field, a challenge that becomes more acutein the presence of sparse graphs. In light of the power series, which possessesinfinite expansion capabilities, we propose a novel Graph Power Filter NeuralNetwork (GPFN) that enhances node classification by employing a power seriesgraph filter to augment the receptive field. Concretely, our GPFN designs a newway to build a graph filter with an infinite receptive field based on theconvergence power series, which can be analyzed in the spectral and spatialdomains. Besides, we theoretically prove that our GPFN is a general frameworkthat can integrate any power series and capture long-range dependencies.Finally, experimental results on three datasets demonstrate the superiority ofour GPFN over state-of-the-art baselines.</description><author>Ruizhe Zhang, Xinke Jiang, Yuchen Fang, Jiayuan Luo, Yongxin Xu, Yichen Zhu, Xu Chu, Junfeng Zhao, Yasha Wang</author><pubDate>Tue, 23 Jan 2024 14:41:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09943v2</guid></item><item><title>Binary structured physics-informed neural networks for solving equations with rapidly changing solutions</title><link>http://arxiv.org/abs/2401.12806v1</link><description>Physics-informed neural networks (PINNs), rooted in deep learning, haveemerged as a promising approach for solving partial differential equations(PDEs). By embedding the physical information described by PDEs intofeedforward neural networks, PINNs are trained as surrogate models toapproximate solutions without the need for label data. Nevertheless, eventhough PINNs have shown remarkable performance, they can face difficulties,especially when dealing with equations featuring rapidly changing solutions.These difficulties encompass slow convergence, susceptibility to becomingtrapped in local minima, and reduced solution accuracy. To address theseissues, we propose a binary structured physics-informed neural network (BsPINN)framework, which employs binary structured neural network (BsNN) as the neuralnetwork component. By leveraging a binary structure that reduces inter-neuronconnections compared to fully connected neural networks, BsPINNs excel incapturing the local features of solutions more effectively and efficiently.These features are particularly crucial for learning the rapidly changing inthe nature of solutions. In a series of numerical experiments solving Burgersequation, Euler equation, Helmholtz equation, and high-dimension Poissonequation, BsPINNs exhibit superior convergence speed and heightened accuracycompared to PINNs. From these experiments, we discover that BsPINNs resolve theissues caused by increased hidden layers in PINNs resulting in over-smoothing,and prevent the decline in accuracy due to non-smoothness of PDEs solutions.</description><author>Yanzhi Liu, Ruifan Wu, Ying Jiang</author><pubDate>Tue, 23 Jan 2024 14:37:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12806v1</guid></item><item><title>Gradient Flow of Energy: A General and Efficient Approach for Entity Alignment Decoding</title><link>http://arxiv.org/abs/2401.12798v1</link><description>Entity alignment (EA), a pivotal process in integrating multi-sourceKnowledge Graphs (KGs), seeks to identify equivalent entity pairs across thesegraphs. Most existing approaches regard EA as a graph representation learningtask, concentrating on enhancing graph encoders. However, the decoding processin EA - essential for effective operation and alignment accuracy - has receivedlimited attention and remains tailored to specific datasets and modelarchitectures, necessitating both entity and additional explicit relationembeddings. This specificity limits its applicability, particularly inGNN-based models. To address this gap, we introduce a novel, generalized, andefficient decoding approach for EA, relying solely on entity embeddings. Ourmethod optimizes the decoding process by minimizing Dirichlet energy, leadingto the gradient flow within the graph, to promote graph homophily. Thediscretization of the gradient flow produces a fast and scalable approach,termed Triple Feature Propagation (TFP). TFP innovatively channels gradientflow through three views: entity-to-entity, entity-to-relation, andrelation-to-entity. This generalized gradient flow enables TFP to harness themulti-view structural information of KGs. Rigorous experimentation on diversereal-world datasets demonstrates that our approach significantly enhancesvarious EA methods. Notably, the approach achieves these advancements with lessthan 6 seconds of additional computational time, establishing a new benchmarkin efficiency and adaptability for future EA methods.</description><author>Yuanyi Wang, Haifeng Sun, Jingyu Wang, Qi Qi, Shaoling Sun, Jianxin Liao</author><pubDate>Tue, 23 Jan 2024 14:31:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12798v1</guid></item><item><title>Benchmarking LLMs via Uncertainty Quantification</title><link>http://arxiv.org/abs/2401.12794v1</link><description>The proliferation of open-source Large Language Models (LLMs) from variousinstitutions has highlighted the urgent need for comprehensive evaluationmethods. However, current evaluation platforms, such as the widely recognizedHuggingFace open LLM leaderboard, neglect a crucial aspect -- uncertainty,which is vital for thoroughly assessing LLMs. To bridge this gap, we introducea new benchmarking approach for LLMs that integrates uncertaintyquantification. Our examination involves eight LLMs (LLM series) spanning fiverepresentative natural language processing tasks. Additionally, we introduce anuncertainty-aware evaluation metric, UAcc, which takes into account bothprediction accuracy and prediction uncertainty. Our findings reveal that: I)LLMs with higher accuracy may exhibit lower certainty; II) Larger-scale LLMsmay display greater uncertainty compared to their smaller counterparts; andIII) Instruction-finetuning tends to increase the uncertainty of LLMs. Bytaking uncertainty into account, our new UAcc metric can either amplify ordiminish the relative improvement of one LLM over another and may even changethe relative ranking of two LLMs. These results underscore the significance ofincorporating uncertainty in the evaluation of LLMs.</description><author>Fanghua Ye, Mingming Yang, Jianhui Pang, Longyue Wang, Derek F. Wong, Emine Yilmaz, Shuming Shi, Zhaopeng Tu</author><pubDate>Tue, 23 Jan 2024 14:29:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12794v1</guid></item><item><title>MORPH: Towards Automated Concept Drift Adaptation for Malware Detection</title><link>http://arxiv.org/abs/2401.12790v1</link><description>Concept drift is a significant challenge for malware detection, as theperformance of trained machine learning models degrades over time, renderingthem impractical. While prior research in malware concept drift adaptation hasprimarily focused on active learning, which involves selecting representativesamples to update the model, self-training has emerged as a promising approachto mitigate concept drift. Self-training involves retraining the model usingpseudo labels to adapt to shifting data distributions. In this research, wepropose MORPH -- an effective pseudo-label-based concept drift adaptationmethod specifically designed for neural networks. Through extensiveexperimental analysis of Android and Windows malware datasets, we demonstratethe efficacy of our approach in mitigating the impact of concept drift. Ourmethod offers the advantage of reducing annotation efforts when combined withactive learning. Furthermore, our method significantly improves over existingworks in automated concept drift adaptation for malware detection.</description><author>Md Tanvirul Alam, Romy Fieblinger, Ashim Mahara, Nidhi Rastogi</author><pubDate>Tue, 23 Jan 2024 14:25:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12790v1</guid></item><item><title>Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study</title><link>http://arxiv.org/abs/2401.12789v1</link><description>In the era of large models, the autoregressive nature of decoding oftenresults in latency serving as a significant bottleneck. We propose anon-autoregressive LM-fused ASR system that effectively leverages theparallelization capabilities of accelerator hardware. Our approach combines theUniversal Speech Model (USM) and the PaLM 2 language model in per-segmentscoring mode, achieving an average relative WER improvement across alllanguages of 10.8% on FLEURS and 3.6% on YouTube captioning. Furthermore, ourcomprehensive ablation study analyzes key parameters such as LLM size, contextlength, vocabulary size, fusion methodology. For instance, we explore theimpact of LLM size ranging from 128M to 340B parameters on ASR performance.This study provides valuable insights into the factors influencing theeffectiveness of practical large-scale LM-fused speech recognition systems.</description><author>W. Ronny Huang, Cyril Allauzen, Tongzhou Chen, Kilol Gupta, Ke Hu, James Qin, Yu Zhang, Yongqiang Wang, Shuo-Yiin Chang, Tara N. Sainath</author><pubDate>Tue, 23 Jan 2024 14:19:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12789v1</guid></item><item><title>A Review of Deep Learning Methods for Photoplethysmography Data</title><link>http://arxiv.org/abs/2401.12783v1</link><description>Photoplethysmography (PPG) is a highly promising device due to its advantagesin portability, user-friendly operation, and non-invasive capabilities tomeasure a wide range of physiological information. Recent advancements in deeplearning have demonstrated remarkable outcomes by leveraging PPG signals fortasks related to personal health management and other multifacetedapplications. In this review, we systematically reviewed papers that applieddeep learning models to process PPG data between January 1st of 2017 and July31st of 2023 from Google Scholar, PubMed and Dimensions. Each paper is analyzedfrom three key perspectives: tasks, models, and data. We finally extracted 193papers where different deep learning frameworks were used to process PPGsignals. Based on the tasks addressed in these papers, we categorized them intotwo major groups: medical-related, and non-medical-related. The medical-relatedtasks were further divided into seven subgroups, including blood pressureanalysis, cardiovascular monitoring and diagnosis, sleep health, mental health,respiratory monitoring and analysis, blood glucose analysis, as well as others.The non-medical-related tasks were divided into four subgroups, which encompasssignal processing, biometric identification, electrocardiogram reconstruction,and human activity recognition. In conclusion, significant progress has beenmade in the field of using deep learning methods to process PPG data recently.This allows for a more thorough exploration and utilization of the informationcontained in PPG signals. However, challenges remain, such as limited quantityand quality of publicly available databases, a lack of effective validation inreal-world scenarios, and concerns about the interpretability, scalability, andcomplexity of deep learning models. Moreover, there are still emerging researchareas that require further investigation.</description><author>Guangkun Nie, Jiabao Zhu, Gongzheng Tang, Deyun Zhang, Shijia Geng, Qinghao Zhao, Shenda Hong</author><pubDate>Tue, 23 Jan 2024 14:11:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12783v1</guid></item><item><title>Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach</title><link>http://arxiv.org/abs/2311.13884v3</link><description>The remarkable progress in Large Language Models (LLMs) opens up new avenuesfor addressing planning and decision-making problems in Multi-Agent Systems(MAS). However, as the number of agents increases, the issues of hallucinationin LLMs and coordination in MAS have become increasingly prominent.Additionally, the efficient utilization of tokens emerges as a criticalconsideration when employing LLMs to facilitate the interactions among asubstantial number of agents. In this paper, we develop a modular frameworkcalled LLaMAC to mitigate these challenges. LLaMAC implements a valuedistribution encoding similar to that found in the human brain, utilizinginternal and external feedback mechanisms to facilitate collaboration anditerative reasoning among its modules. Through evaluations involving systemresource allocation and robot grid transportation, we demonstrate theconsiderable advantages afforded by our proposed approach.</description><author>Bin Zhang, Hangyu Mao, Jingqing Ruan, Ying Wen, Yang Li, Shao Zhang, Zhiwei Xu, Dapeng Li, Ziyue Li, Rui Zhao, Lijuan Li, Guoliang Fan</author><pubDate>Tue, 23 Jan 2024 14:11:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13884v3</guid></item><item><title>DeepRicci: Self-supervised Graph Structure-Feature Co-Refinement for Alleviating Over-squashing</title><link>http://arxiv.org/abs/2401.12780v1</link><description>Graph Neural Networks (GNNs) have shown great power for learning and miningon graphs, and Graph Structure Learning (GSL) plays an important role inboosting GNNs with a refined graph. In the literature, most GSL solutionseither primarily focus on structure refinement with task-specific supervision(i.e., node classification), or overlook the inherent weakness of GNNsthemselves (e.g., over-squashing), resulting in suboptimal performance despitesophisticated designs. In light of these limitations, we propose to studyself-supervised graph structure-feature co-refinement for effectivelyalleviating the issue of over-squashing in typical GNNs. In this paper, we takea fundamentally different perspective of the Ricci curvature in Riemanniangeometry, in which we encounter the challenges of modeling, utilizing andcomputing Ricci curvature. To tackle these challenges, we present aself-supervised Riemannian model, DeepRicci. Specifically, we introduce alatent Riemannian space of heterogeneous curvatures to model various Riccicurvatures, and propose a gyrovector feature mapping to utilize Ricci curvaturefor typical GNNs. Thereafter, we refine node features by geometric contrastivelearning among different geometric views, and simultaneously refine graphstructure by backward Ricci flow based on a novel formulation of differentiableRicci curvature. Finally, extensive experiments on public datasets show thesuperiority of DeepRicci, and the connection between backward Ricci flow andover-squashing. Codes of our work are given in https://github.com/RiemanGraph/.</description><author>Li Sun, Zhenhao Huang, Hua Wu, Junda Ye, Hao Peng, Zhengtao Yu, Philip S. Yu</author><pubDate>Tue, 23 Jan 2024 14:06:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12780v1</guid></item><item><title>GraphPro: Graph Pre-training and Prompt Learning for Recommendation</title><link>http://arxiv.org/abs/2311.16716v4</link><description>GNN-based recommenders have excelled in modeling intricate user-iteminteractions through multi-hop message passing. However, existing methods oftenoverlook the dynamic nature of evolving user-item interactions, which impedesthe adaption to changing user preferences and distribution shifts in newlyarriving data. Thus, their scalability and performances in real-world dynamicenvironments are limited. In this study, we propose GraphPro, a framework thatincorporates parameter-efficient and dynamic graph pre-training with promptlearning. This novel combination empowers GNNs to effectively capture bothlong-term user preferences and short-term behavior dynamics, enabling thedelivery of accurate and timely recommendations. Our GraphPro frameworkaddresses the challenge of evolving user preferences by seamlessly integratinga temporal prompt mechanism and a graph-structural prompt learning mechanisminto the pre-trained GNN model. The temporal prompt mechanism encodes timeinformation on user-item interaction, allowing the model to naturally capturetemporal context, while the graph-structural prompt learning mechanism enablesthe transfer of pre-trained knowledge to adapt to behavior dynamics without theneed for continuous incremental training. We further bring in a dynamicevaluation setting for recommendation to mimic real-world dynamic scenarios andbridge the offline-online gap to a better level. Our extensive experimentsincluding a large-scale industrial deployment showcases the lightweight plug-inscalability of our GraphPro when integrated with various state-of-the-artrecommenders, emphasizing the advantages of GraphPro in terms of effectiveness,robustness and efficiency.</description><author>Yuhao Yang, Lianghao Xia, Da Luo, Kangyi Lin, Chao Huang</author><pubDate>Tue, 23 Jan 2024 14:05:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16716v4</guid></item><item><title>Revolutionizing TCAD Simulations with Universal Device Encoding and Graph Attention Networks</title><link>http://arxiv.org/abs/2308.11624v2</link><description>An innovative methodology that leverages artificial intelligence (AI) andgraph representation for semiconductor device encoding in TCAD devicesimulation is proposed. A graph-based universal encoding scheme is presentedthat not only considers material-level and device-level embeddings, but alsointroduces a novel spatial relationship embedding inspired by interpolationoperations typically used in finite element meshing. Universal physical lawsfrom device simulations are leveraged for comprehensive data-driven modeling,which encompasses surrogate Poisson emulation and current-voltage (IV)prediction based on drift-diffusion model. Both are achieved using a novelgraph attention network, referred to as RelGAT. Comprehensive technical detailsbased on the device simulator Sentaurus TCAD are presented, empoweringresearchers to adopt the proposed AI-driven Electronic Design Automation (EDA)solution at the device level.</description><author>Guangxi Fan, Leilai Shao, Kain Lu Low</author><pubDate>Tue, 23 Jan 2024 14:05:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11624v2</guid></item><item><title>Online Bilevel Optimization: Regret Analysis of Online Alternating Gradient Methods</title><link>http://arxiv.org/abs/2207.02829v5</link><description>This paper introduces an \textit{online bilevel optimization} setting inwhich a sequence of time-varying bilevel problems are revealed one after theother. We extend the known regret bounds for single-level online algorithms tothe bilevel setting. Specifically, we provide new notions of \textit{bilevelregret}, develop an online alternating time-averaged gradient method that iscapable of leveraging smoothness, and give regret bounds in terms of thepath-length of the inner and outer minimizer sequences.</description><author>Davoud Ataee Tarzanagh, Parvin Nazari, Bojian Hou, Li Shen, Laura Balzano</author><pubDate>Tue, 23 Jan 2024 14:00:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.02829v5</guid></item><item><title>Deep Learning-based Intraoperative MRI Reconstruction</title><link>http://arxiv.org/abs/2401.12771v1</link><description>Purpose: To evaluate the quality of deep learning reconstruction forprospectively accelerated intraoperative magnetic resonance imaging (iMRI)during resective brain tumor surgery. Materials and Methods: Accelerated iMRI was performed during brain surgeryusing dual surface coils positioned around the area of resection. A deeplearning (DL) model was trained on the fastMRI neuro dataset to mimic the datafrom the iMRI protocol. Evaluation was performed on imaging material from 40patients imaged between 01.11.2021 - 01.06.2023 that underwent iMRI duringtumor resection surgery. A comparative analysis was conducted between theconventional compressed sense (CS) method and the trained DL reconstructionmethod. Blinded evaluation of multiple image quality metrics was performed bytwo working neuro-radiologists and a working neurosurgeon on a 1 to 5 Likertscale (1=non diagnostic, 2=poor, 3=acceptable, 4=good, 5=excellent), and thefavored reconstruction variant. Results: The DL reconstruction was strongly favored or favored over the CSreconstruction for 33/40, 39/40, and 8/40 of cases for reader 1, 2, and 3,respectively. Two of three readers consistently assigned higher ratings for theDL reconstructions, and the DL reconstructions had a higher score than theirrespective CS counterparts for 72%, 72%, and 14% of the cases for reader 1, 2,and 3, respectively. Still, the DL reconstructions exhibited shortcomings suchas a striping artifact and reduced signal. Conclusion: DL shows promise to allow for high-quality reconstructions ofintraoperative MRI with equal to or improved perceived spatial resolution,signal-to-noise ratio, diagnostic confidence, diagnostic conspicuity, andspatial resolution compared to compressed sense.</description><author>Jon André Ottesen, Tryggve Storas, Svein Are Sirirud Vatnehol, Grethe Løvland, Einar O. Vik-Mo, Till Schellhorn, Karoline Skogen, Christopher Larsson, Atle Bjørnerud, Inge Rasmus Groote-Eindbaas, Matthan W. A. Caan</author><pubDate>Tue, 23 Jan 2024 13:57:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12771v1</guid></item><item><title>Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving $\mathcal{O}(1/k)$ Finite-Sample Complexity</title><link>http://arxiv.org/abs/2401.12764v1</link><description>This paper proposes to develop a new variant of the two-time-scale stochasticapproximation to find the roots of two coupled nonlinear operators, assumingonly noisy samples of these operators can be observed. Our key idea is toleverage the classic Ruppert-Polyak averaging technique to dynamically estimatethe operators through their samples. The estimated values of these averagingsteps will then be used in the two-time-scale stochastic approximation updatesto find the desired solution. Our main theoretical result is to show that underthe strongly monotone condition of the underlying nonlinear operators themean-squared errors of the iterates generated by the proposed method convergeto zero at an optimal rate $\mathcal{O}(1/k)$, where $k$ is the number ofiterations. Our result significantly improves the existing result oftwo-time-scale stochastic approximation, where the best known finite-timeconvergence rate is $\mathcal{O}(1/k^{2/3})$.</description><author>Thinh T. Doan</author><pubDate>Tue, 23 Jan 2024 13:44:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12764v1</guid></item><item><title>MUSES: The Multi-Sensor Semantic Perception Dataset for Driving under Uncertainty</title><link>http://arxiv.org/abs/2401.12761v1</link><description>Achieving level-5 driving automation in autonomous vehicles necessitates arobust semantic visual perception system capable of parsing data from differentsensors across diverse conditions. However, existing semantic perceptiondatasets often lack important non-camera modalities typically used inautonomous vehicles, or they do not exploit such modalities to aid and improvesemantic annotations in challenging conditions. To address this, we introduceMUSES, the MUlti-SEnsor Semantic perception dataset for driving in adverseconditions under increased uncertainty. MUSES includes synchronized multimodalrecordings with 2D panoptic annotations for 2500 images captured under diverseweather and illumination. The dataset integrates a frame camera, a lidar, aradar, an event camera, and an IMU/GNSS sensor. Our new two-stage panopticannotation protocol captures both class-level and instance-level uncertainty inthe ground truth and enables the novel task of uncertainty-aware panopticsegmentation we introduce, along with standard semantic and panopticsegmentation. MUSES proves both effective for training and challenging forevaluating models under diverse visual conditions, and it opens new avenues forresearch in multimodal and uncertainty-aware dense semantic perception. Ourdataset and benchmark will be made publicly available.</description><author>Tim Brödermann, David Bruggemann, Christos Sakaridis, Kevin Ta, Odysseas Liagouris, Jason Corkill, Luc Van Gool</author><pubDate>Tue, 23 Jan 2024 13:43:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12761v1</guid></item><item><title>Large Language Models Vote: Prompting for Rare Disease Identification</title><link>http://arxiv.org/abs/2308.12890v3</link><description>The emergence of generative Large Language Models (LLMs) emphasizes the needfor accurate and efficient prompting approaches. LLMs are often applied inFew-Shot Learning (FSL) contexts, where tasks are executed with minimaltraining data. FSL has become popular in many Artificial Intelligence (AI)subdomains, including AI for health. Rare diseases affect a small fraction ofthe population. Rare disease identification from clinical notes inherentlyrequires FSL techniques due to limited data availability. Manual datacollection and annotation is both expensive and time-consuming. In this paper,we propose Models-Vote Prompting (MVP), a flexible prompting approach forimproving the performance of LLM queries in FSL settings. MVP works byprompting numerous LLMs to perform the same tasks and then conducting amajority vote on the resulting outputs. This method achieves improved resultsto any one model in the ensemble on one-shot rare disease identification andclassification tasks. We also release a novel rare disease dataset for FSL,available to those who signed the MIMIC-IV Data Use Agreement (DUA).Furthermore, in using MVP, each model is prompted multiple times, substantiallyincreasing the time needed for manual annotation, and to address this, weassess the feasibility of using JSON for automating generative LLM evaluation.</description><author>David Oniani, Jordan Hilsman, Hang Dong, Fengyi Gao, Shiven Verma, Yanshan Wang</author><pubDate>Tue, 23 Jan 2024 13:42:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12890v3</guid></item><item><title>Data-Driven Online Model Selection With Regret Guarantees</title><link>http://arxiv.org/abs/2306.02869v3</link><description>We consider model selection for sequential decision making in stochasticenvironments with bandit feedback, where a meta-learner has at its disposal apool of base learners, and decides on the fly which action to take based on thepolicies recommended by each base learner. Model selection is performed byregret balancing but, unlike the recent literature on this subject, we do notassume any prior knowledge about the base learners like candidate regretguarantees; instead, we uncover these quantities in a data-driven manner. Themeta-learner is therefore able to leverage the realized regret incurred by eachbase learner for the learning environment at hand (as opposed to the expectedregret), and single out the best such regret. We design two model selectionalgorithms operating with this more ambitious notion of regret and, besidesproving model selection guarantees via regret balancing, we experimentallydemonstrate the compelling practical benefits of dealing with actual regretsinstead of candidate regret bounds.</description><author>Aldo Pacchiano, Christoph Dann, Claudio Gentile</author><pubDate>Tue, 23 Jan 2024 13:37:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02869v3</guid></item><item><title>What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition</title><link>http://arxiv.org/abs/2401.12756v1</link><description>The knowledge encapsulated in a model is the core factor determining itsfinal performance on downstream tasks. Much research in NLP has focused onefficient methods for storing and adapting different types of knowledge, e.g.,in dedicated modularized structures, and on how to effectively combine these,e.g., by learning additional parameters. However, given the many possibleoptions, a thorough understanding of the mechanisms involved in thesecompositions is missing, and hence it remains unclear which strategies toutilize. To address this research gap, we propose a novel framework forzero-shot module composition, which encompasses existing and some novelvariations for selecting, weighting, and combining parameter modules under asingle unified notion. Focusing on the scenario of domain knowledge and adapterlayers, our framework provides a systematic unification of concepts, allowingus to conduct the first comprehensive benchmarking study of various zero-shotknowledge composition strategies. In particular, we test two module combinationmethods and five selection and weighting strategies for their effectiveness andefficiency in an extensive experimental setup. Our results highlight theefficacy of ensembling but also hint at the power of simple thoughoften-ignored weighting methods. Further in-depth analyses allow us tounderstand the role of weighting vs. top-k selection, and show that, to acertain extent, the performance of adapter composition can even be predicted.</description><author>Carolin Holtermann, Markus Frohmann, Navid Rekabsaz, Anne Lauscher</author><pubDate>Tue, 23 Jan 2024 13:35:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12756v1</guid></item></channel></rss>