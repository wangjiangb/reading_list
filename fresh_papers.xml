<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 12 Aug 2024 13:00:39 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions</title><link>http://arxiv.org/abs/2408.05212v1</link><description>Large Language Models (LLMs) represent a significant advancement inartificial intelligence, finding applications across various domains. However,their reliance on massive internet-sourced datasets for training brings notableprivacy issues, which are exacerbated in critical domains (e.g., healthcare).Moreover, certain application-specific scenarios may require fine-tuning thesemodels on private data. This survey critically examines the privacy threatsassociated with LLMs, emphasizing the potential for these models to memorizeand inadvertently reveal sensitive information. We explore current threats byreviewing privacy attacks on LLMs and propose comprehensive solutions forintegrating privacy mechanisms throughout the entire learning pipeline. Thesesolutions range from anonymizing training datasets to implementing differentialprivacy during training or inference and machine unlearning after training. Ourcomprehensive review of existing literature highlights ongoing challenges,available tools, and future directions for preserving privacy in LLMs. Thiswork aims to guide the development of more secure and trustworthy AI systems byproviding a thorough understanding of privacy preservation methods and theireffectiveness in mitigating risks.</description><author>Michele Miranda, Elena Sofia Ruzzetti, Andrea Santilli, Fabio Massimo Zanzotto, Sébastien Bratières, Emanuele Rodolà</author><pubDate>Sat, 10 Aug 2024 05:41:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05212v1</guid></item><item><title>VITA: Towards Open-Source Interactive Omni Multimodal LLM</title><link>http://arxiv.org/abs/2408.05211v1</link><description>The remarkable multimodal capabilities and interactive experience of GPT-4ounderscore their necessity in practical applications, yet open-source modelsrarely excel in both areas. In this paper, we introduce VITA, the first-everopen-source Multimodal Large Language Model (MLLM) adept at simultaneousprocessing and analysis of Video, Image, Text, and Audio modalities, andmeanwhile has an advanced multimodal interactive experience. Starting fromMixtral 8x7B as a language foundation, we expand its Chinese vocabularyfollowed by bilingual instruction tuning. We further endow the language modelwith visual and audio capabilities through two-stage multi-task learning ofmultimodal alignment and instruction tuning. VITA demonstrates robustfoundational capabilities of multilingual, vision, and audio understanding, asevidenced by its strong performance across a range of both unimodal andmultimodal benchmarks. Beyond foundational capabilities, we have madeconsiderable progress in enhancing the natural multimodal human-computerinteraction experience. To the best of our knowledge, we are the first toexploit non-awakening interaction and audio interrupt in MLLM. VITA is thefirst step for the open-source community to explore the seamless integration ofmultimodal understanding and interaction. While there is still lots of work tobe done on VITA to get close to close-source counterparts, we hope that itsrole as a pioneer can serve as a cornerstone for subsequent research. ProjectPage: https://vita-home.github.io.</description><author>Chaoyou Fu, Haojia Lin, Zuwei Long, Yunhang Shen, Meng Zhao, Yifan Zhang, Xiong Wang, Di Yin, Long Ma, Xiawu Zheng, Ran He, Rongrong Ji, Yunsheng Wu, Caifeng Shan, Xing Sun</author><pubDate>Fri, 09 Aug 2024 17:59:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05211v1</guid></item><item><title>Multi-Garment Customized Model Generation</title><link>http://arxiv.org/abs/2408.05206v1</link><description>This paper introduces Multi-Garment Customized Model Generation, a unifiedframework based on Latent Diffusion Models (LDMs) aimed at addressing theunexplored task of synthesizing images with free combinations of multiplepieces of clothing. The method focuses on generating customized models wearingvarious targeted outfits according to different text prompts. The primarychallenge lies in maintaining the natural appearance of the dressed model whilepreserving the complex textures of each piece of clothing, ensuring that theinformation from different garments does not interfere with each other. Totackle these challenges, we first developed a garment encoder, which is atrainable UNet copy with shared weights, capable of extracting detailedfeatures of garments in parallel. Secondly, our framework supports theconditional generation of multiple garments through decoupled multi-garmentfeature fusion, allowing multiple clothing features to be injected into thebackbone network, significantly alleviating conflicts between garmentinformation. Additionally, the proposed garment encoder is a plug-and-playmodule that can be combined with other extension modules such as IP-Adapter andControlNet, enhancing the diversity and controllability of the generatedmodels. Extensive experiments demonstrate the superiority of our approach overexisting alternatives, opening up new avenues for the task of generating imageswith multiple-piece clothing combinations</description><author>Yichen Liu, Penghui Du, Yi Liu Quanwei Zhang</author><pubDate>Fri, 09 Aug 2024 17:57:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05206v1</guid></item><item><title>DocMath-Eval: Evaluating Math Reasoning Capabilities of LLMs in Understanding Long and Specialized Documents</title><link>http://arxiv.org/abs/2311.09805v3</link><description>Recent LLMs have demonstrated remarkable performance in solving exam-likemath word problems. However, the degree to which these numerical reasoningskills are effective in real-world scenarios, particularly in expert domains,is still largely unexplored. This paper introduces DocMath-Eval, acomprehensive benchmark specifically designed to evaluate the numericalreasoning capabilities of LLMs in the context of understanding and analyzingspecialized documents containing both text and tables. We conduct an extensiveevaluation of 48 LLMs with Chain-of-Thought and Program-of-Thought promptingmethods, aiming to comprehensively assess the capabilities and limitations ofexisting LLMs in DocMath-Eval. We found that even the current best-performingsystem (i.e., GPT-4o) still significantly lags behind human experts in solvingcomplex numerical reasoning problems grounded in long contexts. We believe thatDocMath-Eval can serve as a valuable benchmark for evaluating LLMs'capabilities in solving challenging numerical reasoning problems within expertdomains.</description><author>Yilun Zhao, Yitao Long, Hongjun Liu, Ryo Kamoi, Linyong Nan, Lyuhao Chen, Yixin Liu, Xiangru Tang, Rui Zhang, Arman Cohan</author><pubDate>Fri, 09 Aug 2024 17:57:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09805v3</guid></item><item><title>Kalman-Inspired Feature Propagation for Video Face Super-Resolution</title><link>http://arxiv.org/abs/2408.05205v1</link><description>Despite the promising progress of face image super-resolution, video facesuper-resolution remains relatively under-explored. Existing approaches eitheradapt general video super-resolution networks to face datasets or applyestablished face image super-resolution models independently on individualvideo frames. These paradigms encounter challenges either in reconstructingfacial details or maintaining temporal consistency. To address these issues, weintroduce a novel framework called Kalman-inspired Feature Propagation (KEEP),designed to maintain a stable face prior over time. The Kalman filteringprinciples offer our method a recurrent ability to use the information frompreviously restored frames to guide and regulate the restoration process of thecurrent frame. Extensive experiments demonstrate the effectiveness of ourmethod in capturing facial details consistently across video frames. Code andvideo demo are available at https://jnjaby.github.io/projects/KEEP.</description><author>Ruicheng Feng, Chongyi Li, Chen Change Loy</author><pubDate>Fri, 09 Aug 2024 17:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05205v1</guid></item><item><title>Psychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features</title><link>http://arxiv.org/abs/2406.18783v3</link><description>The increasing sophistication of cyber threats necessitates innovativeapproaches to cybersecurity. In this paper, we explore the potential ofpsychological profiling techniques, particularly focusing on the utilization ofLarge Language Models (LLMs) and psycholinguistic features. We investigate theintersection of psychology and cybersecurity, discussing how LLMs can beemployed to analyze textual data for identifying psychological traits of threatactors. We explore the incorporation of psycholinguistic features, such aslinguistic patterns and emotional cues, into cybersecurity frameworks. Ourresearch underscores the importance of integrating psychological perspectivesinto cybersecurity practices to bolster defense mechanisms against evolvingthreats.</description><author>Jean Marie Tshimula, D'Jeff K. Nkashama, Jean Tshibangu Muabila, René Manassé Galekwa, Hugues Kanda, Maximilien V. Dialufuma, Mbuyi Mukendi Didier, Kalonji Kalala, Serge Mundele, Patience Kinshie Lenye, Tighana Wenge Basele, Aristarque Ilunga, Christian N. Mayemba, Nathanaël M. Kasoro, Selain K. Kasereka, Hardy Mikese, Pierre-Martin Tardif, Marc Frappier, Froduald Kabanza, Belkacem Chikhaoui, Shengrui Wang, Ali Mulenda Sumbu, Xavier Ndona, Raoul Kienge-Kienge Intudi</author><pubDate>Fri, 09 Aug 2024 17:57:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18783v3</guid></item><item><title>Evaluating the capability of large language models to personalize science texts for diverse middle-school-age learners</title><link>http://arxiv.org/abs/2408.05204v1</link><description>Large language models (LLMs), including OpenAI's GPT-series, have madesignificant advancements in recent years. Known for their expertise acrossdiverse subject areas and quick adaptability to user-provided prompts, LLMshold unique potential as Personalized Learning (PL) tools. Despite thispotential, their application in K-12 education remains largely unexplored. Thispaper presents one of the first randomized controlled trials (n = 23) toevaluate the effectiveness of GPT-4 in personalizing educational science textsfor middle school students. In this study, GPT-4 was used to profile studentlearning preferences based on choices made during a training session. For theexperimental group, GPT-4 was used to rewrite science texts to align with thestudent's predicted profile while, for students in the control group, textswere rewritten to contradict their learning preferences. The results of aMann-Whitney U test showed that students significantly preferred (at the .10level) the rewritten texts when they were aligned with their profile (p =.059). These findings suggest that GPT-4 can effectively interpret and tailoreducational content to diverse learner preferences, marking a significantadvancement in PL technology. The limitations of this study and ethicalconsiderations for using artificial intelligence in education are alsodiscussed.</description><author>Michael Vaccaro Jr, Mikayla Friday, Arash Zaghi</author><pubDate>Fri, 09 Aug 2024 17:53:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05204v1</guid></item><item><title>Eliciting Latent Knowledge from Quirky Language Models</title><link>http://arxiv.org/abs/2312.01037v4</link><description>Eliciting Latent Knowledge (ELK) aims to find patterns in a capable neuralnetwork's activations that robustly track the true state of the world,especially in hard-to-verify cases where the model's output is untrusted. Tofurther ELK research, we introduce 12 datasets and a corresponding suite of"quirky" language models (LMs) that are finetuned to make systematic errorswhen answering questions if and only if the keyword "Bob" is present in theprompt. We find that, especially in middle layers, linear probes usually reportan LM's knowledge independently of what the LM outputs, enabling us to elicitthe correct answer despite the model's untruthful output. The best probingmethod (logistic regression on contrast pairs) recovers 89% of the gap in AUROCbetween truthful and untruthful contexts, and 75% for questions harder thanthose used to train the probe. We also find that a mechanistic anomalydetection approach can flag untruthful behavior with 0.95 AUROC. Our resultsshow promise for eliciting reliable knowledge from capable but untrustedmodels, and facilitates future research empirically investigating ELK methods.</description><author>Alex Mallen, Madeline Brumley, Julia Kharchenko, Nora Belrose</author><pubDate>Fri, 09 Aug 2024 17:51:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01037v4</guid></item><item><title>TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning</title><link>http://arxiv.org/abs/2408.05200v1</link><description>Language model continual learning (CL) has recently garnered significantinterest due to its potential to adapt large language models (LLMs) to dynamicreal-world environments without re-training. A key challenge in this field iscatastrophic forgetting, where models lose previously acquired knowledge whenlearning new tasks. Existing methods commonly employ multipleparameter-efficient fine-tuning (PEFT) blocks to acquire task-specificknowledge for each task, but these approaches lack efficiency and overlook thepotential for knowledge transfer through task interaction. In this paper, wepresent a novel CL framework for language models called Task Skill Localizationand Consolidation (TaSL), which enhances knowledge transfer without relying onmemory replay. TaSL first divides the model into `skill units' based onparameter dependencies, enabling more granular control. It then employs a novelgroup-wise skill localization technique to identify the importance distributionof skill units for a new task. By comparing this importance distribution withthose from previous tasks, we implement a fine-grained skill consolidationstrategy that retains task-specific knowledge, thereby preventing forgetting,and updates task-shared knowledge, which facilitates bi-directional knowledgetransfer. As a result, TaSL achieves a superior balance between retainingprevious knowledge and excelling in new tasks. TaSL also shows stronggeneralizability, suitable for general models and customizable for PEFT methodslike LoRA. Additionally, it demonstrates notable extensibility, allowingintegration with memory replay to further enhance performance. Extensiveexperiments on two CL benchmarks, with varying model sizes (from 220M to 7B),demonstrate the effectiveness of TaSL and its variants across differentsettings.</description><author>Yujie Feng, Xu Chu, Yongxin Xu, Zexin Lu, Bo Liu, Philip S. Yu, Xiao-Ming Wu</author><pubDate>Fri, 09 Aug 2024 17:44:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05200v1</guid></item><item><title>Cell Morphology-Guided Small Molecule Generation with GFlowNets</title><link>http://arxiv.org/abs/2408.05196v1</link><description>High-content phenotypic screening, including high-content imaging (HCI), hasgained popularity in the last few years for its ability to characterize noveltherapeutics without prior knowledge of the protein target. When combined withdeep learning techniques to predict and represent molecular-phenotypeinteractions, these advancements hold the potential to significantly accelerateand enhance drug discovery applications. This work focuses on the novel task ofHCI-guided molecular design. Generative models for molecule design could beguided by HCI data, for example with a supervised model that links molecules tophenotypes of interest as a reward function. However, limited labeled data,combined with the high-dimensional readouts, can make training these methodschallenging and impractical. We consider an alternative approach in which weleverage an unsupervised multimodal joint embedding to define a latentsimilarity as a reward for GFlowNets. The proposed model learns to generate newmolecules that could produce phenotypic effects similar to those of the givenimage target, without relying on pre-annotated phenotypic labels. Wedemonstrate that the proposed method generates molecules with highmorphological and structural similarity to the target, increasing thelikelihood of similar biological activity, as confirmed by an independentoracle model.</description><author>Stephen Zhewen Lu, Ziqing Lu, Ehsan Hajiramezanali, Tommaso Biancalani, Yoshua Bengio, Gabriele Scalia, Michał Koziarski</author><pubDate>Fri, 09 Aug 2024 17:40:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05196v1</guid></item><item><title>HistoKernel: Whole Slide Image Level Maximum Mean Discrepancy Kernels for Pan-Cancer Predictive Modelling</title><link>http://arxiv.org/abs/2408.05195v1</link><description>Machine learning in computational pathology (CPath) often aggregatespatch-level predictions from multi-gigapixel Whole Slide Images (WSIs) togenerate WSI-level prediction scores for crucial tasks such as survivalprediction and drug effect prediction. However, current methods do notexplicitly characterize distributional differences between patch sets withinWSIs. We introduce HistoKernel, a novel Maximum Mean Discrepancy (MMD) kernelthat measures distributional similarity between WSIs for enhanced predictionperformance on downstream prediction tasks. Our comprehensive analysis demonstrates HistoKernel's effectiveness acrossvarious machine learning tasks, including retrieval (n = 9,362), drugsensitivity regression (n = 551), point mutation classification (n = 3,419),and survival analysis (n = 2,291), outperforming existing deep learningmethods. Additionally, HistoKernel seamlessly integrates multi-modal data andoffers a novel perturbation-based method for patch-level explainability. Thiswork pioneers the use of kernel-based methods for WSI-level predictivemodeling, opening new avenues for research. Code is available athttps://github.com/pkeller00/HistoKernel.</description><author>Piotr Keller, Muhammad Dawood, Brinder Singh Chohan, Fayyaz ul Amir Afsar Minhas</author><pubDate>Fri, 09 Aug 2024 17:40:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05195v1</guid></item><item><title>LucidDreaming: Controllable Object-Centric 3D Generation</title><link>http://arxiv.org/abs/2312.00588v2</link><description>With the recent development of generative models, Text-to-3D generations havealso seen significant growth, opening a door for creating video-game 3D assetsfrom a more general public. Nonetheless, people without any professional 3Dediting experience would find it hard to achieve precise control over the 3Dgeneration, especially if there are multiple objects in the prompt, as usingtext to control often leads to missing objects and imprecise locations. In thispaper, we present LucidDreaming as an effective pipeline capable of spatial andnumerical control over 3D generation from only textual prompt commands or 3Dbounding boxes. Specifically, our research demonstrates that Large LanguageModels (LLMs) possess 3D spatial awareness and can effectively translatetextual 3D information into precise 3D bounding boxes. We leverage LLMs to getindividual object information and their 3D bounding boxes as the initial stepof our process. Then with the bounding boxes, We further propose clipped raysampling and object-centric density blob bias to generate 3D objects aligningwith the bounding boxes. We show that our method exhibits remarkableadaptability across a spectrum of mainstream Score Distillation Sampling-based3D generation frameworks and our pipeline can even used to insert objects intoan existing NeRF scene. Moreover, we also provide a dataset of prompts with 3Dbounding boxes, benchmarking 3D spatial controllability. With extensivequalitative and quantitative experiments, we demonstrate that LucidDreamingachieves superior results in object placement precision and generation fidelitycompared to current approaches, while maintaining flexibility and ease of usefor non-expert users.</description><author>Zhaoning Wang, Ming Li, Chen Chen</author><pubDate>Fri, 09 Aug 2024 17:34:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00588v2</guid></item><item><title>Separating Style from Substance: Enhancing Cross-Genre Authorship Attribution through Data Selection and Presentation</title><link>http://arxiv.org/abs/2408.05192v1</link><description>The task of deciding whether two documents are written by the same author ischallenging for both machines and humans. This task is even more challengingwhen the two documents are written about different topics (e.g. baseball vs.politics) or in different genres (e.g. a blog post vs. an academic article).For machines, the problem is complicated by the relative lack of real-worldtraining examples that cross the topic boundary and the vanishing scarcity ofcross-genre data. We propose targeted methods for training data selection and anovel learning curriculum that are designed to discourage a model's reliance ontopic information for authorship attribution and correspondingly force it toincorporate information more robustly indicative of style no matter the topic.These refinements yield a 62.7% relative improvement in average cross-genreauthorship attribution, as well as 16.6% in the per-genre condition.</description><author>Steven Fincke, Elizabeth Boschee</author><pubDate>Fri, 09 Aug 2024 17:31:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05192v1</guid></item><item><title>Multi-Conditional Ranking with Large Language Models</title><link>http://arxiv.org/abs/2404.00211v2</link><description>Utilizing large language models (LLMs) to rank a set of items has become acommon approach in recommendation and retrieval systems. Typically, thesesystems focus on ordering a substantial number of documents in a monotonicorder based on a given query. However, real-world scenarios often present adifferent challenge: ranking a comparatively smaller set of items, butaccording to a variety of diverse and occasionally conflicting conditions. Inthis paper, we define and explore the task of multi-conditional ranking byintroducing MCRank, a benchmark tailored for assessing multi-conditionalranking across various item types and conditions. Our analysis of LLMs usingMCRank indicates a significant decrease in performance as the number andcomplexity of items and conditions grow. To overcome this limitation, wepropose a novel decomposed reasoning method, consisting of EXtracting andSorting the conditions, and then Iteratively Ranking the items (EXSIR). Ourextensive experiments show that this decomposed reasoning method enhances LLMs'performance significantly, achieving up to a 12% improvement over existingLLMs. We also provide a detailed analysis of LLMs performance across variouscondition categories, and examine the effectiveness of decomposition step.Furthermore, we compare our method with existing approaches such asChain-of-Thought and existing ranking models, demonstrating the superiority ofour approach and complexity of MCR task. We released our dataset and code.</description><author>Pouya Pezeshkpour, Estevam Hruschka</author><pubDate>Fri, 09 Aug 2024 17:28:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00211v2</guid></item><item><title>Cross-Domain Learning for Video Anomaly Detection with Limited Supervision</title><link>http://arxiv.org/abs/2408.05191v1</link><description>Video Anomaly Detection (VAD) automates the identification of unusual events,such as security threats in surveillance videos. In real-world applications,VAD models must effectively operate in cross-domain settings, identifying rareanomalies and scenarios not well-represented in the training data. However,existing cross-domain VAD methods focus on unsupervised learning, resulting inperformance that falls short of real-world expectations. Since acquiring weaksupervision, i.e., video-level labels, for the source domain is cost-effective,we conjecture that combining it with external unlabeled data has notablepotential to enhance cross-domain performance. To this end, we introduce anovel weakly-supervised framework for Cross-Domain Learning (CDL) in VAD thatincorporates external data during training by estimating its prediction biasand adaptively minimizing that using the predicted uncertainty. We demonstratethe effectiveness of the proposed CDL framework through comprehensiveexperiments conducted in various configurations on two large-scale VADdatasets: UCF-Crime and XD-Violence. Our method significantly surpasses thestate-of-the-art works in cross-domain evaluations, achieving an averageabsolute improvement of 19.6% on UCF-Crime and 12.87% on XD-Violence.</description><author>Yashika Jain, Ali Dabouei, Min Xu</author><pubDate>Fri, 09 Aug 2024 17:28:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05191v1</guid></item><item><title>Efficient automatic segmentation for multi-level pulmonary arteries: The PARSE challenge</title><link>http://arxiv.org/abs/2304.03708v2</link><description>Efficient automatic segmentation of multi-level (i.e. main and branch)pulmonary arteries (PA) in CTPA images plays a significant role in clinicalapplications. However, most existing methods concentrate only on main PA orbranch PA segmentation separately and ignore segmentation efficiency. Besides,there is no public large-scale dataset focused on PA segmentation, which makesit highly challenging to compare the different methods. To benchmarkmulti-level PA segmentation algorithms, we organized the first\textbf{P}ulmonary \textbf{AR}tery \textbf{SE}gmentation (PARSE) challenge. Onthe one hand, we focus on both the main PA and the branch PA segmentation. Onthe other hand, for better clinical application, we assign the same scoreweight to segmentation efficiency (mainly running time and GPU memoryconsumption during inference) while ensuring PA segmentation accuracy. Wepresent a summary of the top algorithms and offer some suggestions forefficient and accurate multi-level PA automatic segmentation. We provide thePARSE challenge as open-access for the community to benchmark future algorithmdevelopments at \url{https://parse2022.grand-challenge.org/Parse2022/}.</description><author>Gongning Luo, Kuanquan Wang, Jun Liu, Shuo Li, Xinjie Liang, Xiangyu Li, Shaowei Gan, Wei Wang, Suyu Dong, Wenyi Wang, Pengxin Yu, Enyou Liu, Hongrong Wei, Na Wang, Jia Guo, Huiqi Li, Zhao Zhang, Ziwei Zhao, Na Gao, Nan An, Ashkan Pakzad, Bojidar Rangelov, Jiaqi Dou, Song Tian, Zeyu Liu, Yi Wang, Ampatishan Sivalingam, Kumaradevan Punithakumar, Zhaowen Qiu, Xin Gao</author><pubDate>Fri, 09 Aug 2024 17:17:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03708v2</guid></item><item><title>CREMP: Conformer-rotamer ensembles of macrocyclic peptides for machine learning</title><link>http://arxiv.org/abs/2305.08057v2</link><description>Computational and machine learning approaches to model the conformationallandscape of macrocyclic peptides have the potential to enable rational designand optimization. However, accurate, fast, and scalable methods for modelingmacrocycle geometries remain elusive. Recent deep learning approaches havesignificantly accelerated protein structure prediction and the generation ofsmall-molecule conformational ensembles, yet similar progress has not been madefor macrocyclic peptides due to their unique properties. Here, we introduceCREMP, a resource generated for the rapid development and evaluation of machinelearning models for macrocyclic peptides. CREMP contains 36,198 uniquemacrocyclic peptides and their high-quality structural ensembles generatedusing the Conformer-Rotamer Ensemble Sampling Tool (CREST). Altogether, thisnew dataset contains nearly 31.3 million unique macrocycle geometries, eachannotated with energies derived from semi-empirical extended tight-binding(xTB) DFT calculations. Additionally, we include 3,258 macrocycles withreported passive permeability data to couple conformational ensembles toexperiment. We anticipate that this dataset will enable the development ofmachine learning models that can improve peptide design and optimization fornovel therapeutics.</description><author>Colin A. Grambow, Hayley Weir, Christian N. Cunningham, Tommaso Biancalani, Kangway V. Chuang</author><pubDate>Fri, 09 Aug 2024 17:16:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.08057v2</guid></item><item><title>Deep-change at AXOLOTL-24: Orchestrating WSD and WSI Models for Semantic Change Modeling</title><link>http://arxiv.org/abs/2408.05184v1</link><description>This paper describes our solution of the first subtask from the AXOLOTL-24shared task on Semantic Change Modeling. The goal of this subtask is todistribute a given set of usages of a polysemous word from a newer time periodbetween senses of this word from an older time period and clusters representinggained senses of this word. We propose and experiment with three new methodssolving this task. Our methods achieve SOTA results according to both officialmetrics of the first substask. Additionally, we develop a model that can tellif a given word usage is not described by any of the provided sensedefinitions. This model serves as a component in one of our methods, but canpotentially be useful on its own.</description><author>Denis Kokosinskii, Mikhail Kuklin, Nikolay Arefyev</author><pubDate>Fri, 09 Aug 2024 17:15:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05184v1</guid></item><item><title>ECG-FM: An Open Electrocardiogram Foundation Model</title><link>http://arxiv.org/abs/2408.05178v1</link><description>The electrocardiogram (ECG) is a ubiquitous diagnostic test. Conventionaltask-specific ECG analysis models require large numbers of expensive ECGannotations or associated labels to train. Transfer learning techniques havebeen shown to improve generalization and reduce reliance on labeled data. Wepresent ECG-FM, an open foundation model for ECG analysis, and conduct acomprehensive study performed on a dataset of 1.66 million ECGs sourced fromboth publicly available and private institutional sources. ECG-FM adopts atransformer-based architecture and is pretrained on 2.5 million samples usingECG-specific augmentations and contrastive learning, as well as a continuoussignal masking objective. Our transparent evaluation includes a diverse rangeof downstream tasks, where we predict ECG interpretation labels, reduced leftventricular ejection fraction, and abnormal cardiac troponin. AffirmingECG-FM's effectiveness as a foundation model, we demonstrate how its command ofcontextual information results in strong performance, rich pretrainedembeddings, and reliable interpretability. Due to a lack of open-weightpractices, we highlight how ECG analysis is lagging behind other medicalmachine learning subfields in terms of foundation model adoption. Our code isavailable at https://github.com/bowang-lab/ECG-FM/.</description><author>Kaden McKeen, Laura Oliva, Sameer Masood, Augustin Toma, Barry Rubin, Bo Wang</author><pubDate>Fri, 09 Aug 2024 17:06:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05178v1</guid></item><item><title>Beyond Closure Models: Learning Chaotic-Systems via Physics-Informed Neural Operators</title><link>http://arxiv.org/abs/2408.05177v1</link><description>Accurately predicting the long-term behavior of chaotic systems is crucialfor various applications such as climate modeling. However, achieving suchpredictions typically requires iterative computations over a densespatiotemporal grid to account for the unstable nature of chaotic systems,which is expensive and impractical in many real-world situations. Analternative approach to such a full-resolved simulation is using a coarse gridand then correcting its errors through a \textit{closure model}, whichapproximates the overall information from fine scales not captured in thecoarse-grid simulation. Recently, ML approaches have been used for closuremodeling, but they typically require a large number of training samples fromexpensive fully-resolved simulations (FRS). In this work, we prove an even morefundamental limitation, i.e., the standard approach to learning closure modelssuffers from a large approximation error for generic problems, no matter howlarge the model is, and it stems from the non-uniqueness of the mapping. Wepropose an alternative end-to-end learning approach using a physics-informedneural operator (PINO) that overcomes this limitation by not using a closuremodel or a coarse-grid solver. We first train the PINO model on data from acoarse-grid solver and then fine-tune it with (a small amount of) FRS andphysics-based losses on a fine grid. The discretization-free nature of neuraloperators means that they do not suffer from the restriction of a coarse gridthat closure models face, and they can provably approximate the long-termstatistics of chaotic systems. In our experiments, our PINO model achieves a120x speedup compared to FRS with a relative error $\sim 5\%$. In contrast, theclosure model coupled with a coarse-grid solver is $58$x slower than PINO whilehaving a much higher error $\sim205\%$ when the closure model is trained on thesame FRS dataset.</description><author>Chuwei Wang, Julius Berner, Zongyi Li, Di Zhou, Jiayun Wang, Jane Bae, Anima Anandkumar</author><pubDate>Fri, 09 Aug 2024 17:05:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05177v1</guid></item><item><title>Enriching thermal point clouds of buildings using semantic 3D building models</title><link>http://arxiv.org/abs/2407.21436v2</link><description>Thermal point clouds integrate thermal radiation and laser point cloudseffectively. However, the semantic information for the interpretation ofbuilding thermal point clouds can hardly be precisely inferred. Transferringthe semantics encapsulated in 3D building models at LoD3 has a potential tofill this gap. In this work, we propose a workflow enriching thermal pointclouds with the geo-position and semantics of LoD3 building models, whichutilizes features of both modalities: The proposed method can automaticallyco-register the point clouds from different sources and enrich the thermalpoint cloud in facade-detailed semantics. The enriched thermal point cloudsupports thermal analysis and can facilitate the development of currentlyscarce deep learning models operating directly on thermal point clouds.</description><author>Jingwei Zhu, Olaf Wysocki, Christoph Holst, Thomas H. Kolbe</author><pubDate>Fri, 09 Aug 2024 16:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21436v2</guid></item><item><title>Text Clustering with LLM Embeddings</title><link>http://arxiv.org/abs/2403.15112v4</link><description>Text clustering is an important method for organising the increasing volumeof digital content, aiding in the structuring and discovery of hidden patternsin uncategorised data. The effectiveness of text clustering largely depends onthe selection of textual embeddings and clustering algorithms. This studyargues that recent advancements in large language models (LLMs) have thepotential to enhance this task. The research investigates how different textualembeddings, particularly those utilised in LLMs, and various clusteringalgorithms influence the clustering of text datasets. A series of experimentswere conducted to evaluate the impact of embeddings on clustering results, therole of dimensionality reduction through summarisation, and the adjustment ofmodel size. The findings indicate that LLM embeddings are superior at capturingsubtleties in structured language. OpenAI's GPT-3.5 Turbo model yields betterresults in three out of five clustering metrics across most tested datasets.Most LLM embeddings show improvements in cluster purity and provide a moreinformative silhouette score, reflecting a refined structural understanding oftext data compared to traditional methods. Among the more lightweight models,BERT demonstrates leading performance. Additionally, it was observed thatincreasing model dimensionality and employing summarisation techniques do notconsistently enhance clustering efficiency, suggesting that these strategiesrequire careful consideration for practical application. These resultshighlight a complex balance between the need for refined text representationand computational feasibility in text clustering applications. This studyextends traditional text clustering frameworks by integrating embeddings fromLLMs, offering improved methodologies and suggesting new avenues for futureresearch in various types of textual analysis.</description><author>Alina Petukhova, João P. Matos-Carvalho, Nuno Fachada</author><pubDate>Fri, 09 Aug 2024 16:57:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15112v4</guid></item><item><title>Decoding Quantum LDPC Codes Using Graph Neural Networks</title><link>http://arxiv.org/abs/2408.05170v1</link><description>In this paper, we propose a novel decoding method for Quantum Low-DensityParity-Check (QLDPC) codes based on Graph Neural Networks (GNNs). Similar tothe Belief Propagation (BP)-based QLDPC decoders, the proposed GNN-based QLDPCdecoder exploits the sparse graph structure of QLDPC codes and can beimplemented as a message-passing decoding algorithm. We compare the proposedGNN-based decoding algorithm against selected classes of both conventional andneural-enhanced QLDPC decoding algorithms across several QLDPC code designs.The simulation results demonstrate excellent performance of GNN-based decodersalong with their low complexity compared to competing methods.</description><author>Vukan Ninkovic, Ognjen Kundacina, Dejan Vukobratovic, Christian Häger, Alexandre Graell i Amat</author><pubDate>Fri, 09 Aug 2024 16:47:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05170v1</guid></item><item><title>Weak-Annotation of HAR Datasets using Vision Foundation Models</title><link>http://arxiv.org/abs/2408.05169v1</link><description>As wearable-based data annotation remains, to date, a tedious, time-consumingtask requiring researchers to dedicate substantial time, benchmark datasetswithin the field of Human Activity Recognition in lack richness and sizecompared to datasets available within related fields. Recently, visionfoundation models such as CLIP have gained significant attention, helping thevision community advance in finding robust, generalizable featurerepresentations. With the majority of researchers within the wearable communityrelying on vision modalities to overcome the limited expressiveness of wearabledata and accurately label their to-be-released benchmark datasets offline, wepropose a novel, clustering-based annotation pipeline to significantly reducethe amount of data that needs to be annotated by a human annotator. We showthat using our approach, the annotation of centroid clips suffices to achieveaverage labelling accuracies close to 90% across three publicly available HARbenchmark datasets. Using the weakly annotated datasets, we further demonstratethat we can match the accuracy scores of fully-supervised deep learningclassifiers across all three benchmark datasets. Code as well as supplementaryfigures and results are publicly downloadable viagithub.com/mariusbock/weak_har.</description><author>Marius Bock, Kristof Van Laerhoven, Michael Moeller</author><pubDate>Fri, 09 Aug 2024 16:46:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05169v1</guid></item><item><title>Federated Hypergraph Learning with Hyperedge Completion</title><link>http://arxiv.org/abs/2408.05160v1</link><description>Hypergraph neural networks enhance conventional graph neural networks bycapturing high-order relationships among nodes, which proves vital in data-richenvironments where interactions are not merely pairwise. As data complexity andinterconnectivity grow, it is common for graph-structured data to be split andstored in a distributed manner, underscoring the necessity of federatedlearning on subgraphs. In this work, we propose FedHGN, a novel algorithm forfederated hypergraph learning. Our algorithm utilizes subgraphs of a hypergraphstored on distributed devices to train local HGNN models in a federatedmanner:by collaboratively developing an effective global HGNN model throughsharing model parameters while preserving client privacy. Additionally,considering that hyperedges may span multiple clients, a pre-training step isemployed before the training process in which cross-client hyperedge featuregathering is performed at the central server. In this way, the missingcross-client information can be supplemented from the central server during thenode feature aggregation phase. Experimental results on seven real-worlddatasets confirm the effectiveness of our approach and demonstrate itsperformance advantages over traditional federated graph learning methods.</description><author>Linfeng Luo, Fengxiao Tang, Xiyu Liu, Zhiqi Guo, Zihao Qiu, Ming Zhao</author><pubDate>Fri, 09 Aug 2024 16:31:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05160v1</guid></item><item><title>EasyInv: Toward Fast and Better DDIM Inversion</title><link>http://arxiv.org/abs/2408.05159v1</link><description>This paper introduces EasyInv, an easy yet novel approach that significantlyadvances the field of DDIM Inversion by addressing the inherent inefficienciesand performance limitations of traditional iterative optimization methods. Atthe core of our EasyInv is a refined strategy for approximating inversionnoise, which is pivotal for enhancing the accuracy and reliability of theinversion process. By prioritizing the initial latent state, which encapsulatesrich information about the original images, EasyInv steers clear of theiterative refinement of noise items. Instead, we introduce a methodicalaggregation of the latent state from the preceding time step with the currentstate, effectively increasing the influence of the initial latent state andmitigating the impact of noise. We illustrate that EasyInv is capable ofdelivering results that are either on par with or exceed those of theconventional DDIM Inversion approach, especially under conditions where themodel's precision is limited or computational resources are scarce.Concurrently, our EasyInv offers an approximate threefold enhancement regardinginference efficiency over off-the-shelf iterative optimization techniques.</description><author>Ziyue Zhang, Mingbao Lin, Shuicheng Yan, Rongrong Ji</author><pubDate>Fri, 09 Aug 2024 16:31:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05159v1</guid></item><item><title>Shifting the Lens: Detecting Malicious npm Packages using Large Language Models</title><link>http://arxiv.org/abs/2403.12196v2</link><description>Existing malicious code detection techniques can aid the manual reviewprocess by predicting which packages are likely to be malicious. However, thesetechniques often suffer from high misclassification rates. Therefore, maliciouscode detection techniques could be enhanced by adopting advanced, moreautomated approaches to achieve high accuracy and a low misclassification rate.The goal of this study is to assist security analysts in detecting maliciouspackages through the empirical study of using Large Language Models (LLMs) todetect malicious code in the npm ecosystem. We present SecurityAI, a maliciouscode review workflow to detect malicious code using ChatGPT. We leverage abenchmark dataset of 5,115 npm packages, of which 2,180 packages have maliciouscode. We conducted a baseline comparison of GPT-3 and GPT- 4 models with thestate-of-the-art CodeQL static analysis tool, using 39 custom CodeQL rulesdeveloped in prior research to detect malicious Javascript code. We compare theeffectiveness of static analysis as a pre-screener with SecurityAI workflow,measuring the number of files that need to be analyzed and the associatedcosts. Additionally, we performed a qualitative study to understand the typesof malicious packages detected or missed by our workflow. Our baselinecomparison demonstrates a 16% and 9% improvement over static analysis inprecision and F1 scores, respectively. We attained precision and F1 scores of91% and 94% for GPT-3, and 99% &amp; 97% for GPT-4, respectively, with GPT-3offering a cost-effective balance. Pre-screening files with a static analyzerreduces the number of files requiring LLM analysis by 77.9% and decreases costsby 60.9% for GPT-3 and 76.1% for GPT-4. Our qualitative analysis identifieddata theft, hidden backdoors, and suspicious domain connection categories asthe top detected malicious packages.</description><author>Nusrat Zahan, Philipp Burckhardt, Mikola Lysenko, Feross Aboukhadijeh, Laurie Williams</author><pubDate>Fri, 09 Aug 2024 16:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.12196v2</guid></item><item><title>Neuromorphic Keyword Spotting with Pulse Density Modulation MEMS Microphones</title><link>http://arxiv.org/abs/2408.05156v1</link><description>The Keyword Spotting (KWS) task involves continuous audio stream monitoringto detect predefined words, requiring low energy devices for continuousprocessing. Neuromorphic devices effectively address this energy challenge.However, the general neuromorphic KWS pipeline, from microphone to SpikingNeural Network (SNN), entails multiple processing stages. Leveraging thepopularity of Pulse Density Modulation (PDM) microphones in modern devices andtheir similarity to spiking neurons, we propose a direct microphone-to-SNNconnection. This approach eliminates intermediate stages, notably reducingcomputational costs. The system achieved an accuracy of 91.54\% on the GoogleSpeech Command (GSC) dataset, surpassing the state-of-the-art for the SpikingSpeech Command (SSC) dataset which is a bio-inspired encoded GSC. Furthermore,the observed sparsity in network activity and connectivity indicates potentialfor remarkably low energy consumption in a neuromorphic device implementation.</description><author>Sidi Yaya Arnaud Yarga, Sean U. N. Wood</author><pubDate>Fri, 09 Aug 2024 16:27:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05156v1</guid></item><item><title>DeVAn: Dense Video Annotation for Video-Language Models</title><link>http://arxiv.org/abs/2310.05060v2</link><description>We present a novel human annotated dataset for evaluating the ability forvisual-language models to generate both short and long descriptions forreal-world video clips, termed DeVAn (Dense Video Annotation). The datasetcontains 8.5K YouTube video clips of 20-60 seconds in duration and covers awide range of topics and interests. Each video clip is independently annotatedby 5 human annotators, producing both captions (1 sentence) and summaries (3-10sentences). Given any video selected from the dataset and its corresponding ASRinformation, we evaluate visuallanguage models on either caption or summarygeneration that is grounded in both the visual and auditory content of thevideo. Additionally, models are also evaluated on caption- and summary-basedretrieval tasks, where the summary-based retrieval task requires theidentification of a target video given excerpts of a given summary. Given thenovel nature of the paragraph-length video summarization task, we compareddifferent existing evaluation metrics and their alignment with humanpreferences and found that model-based evaluation metrics provide moresemantically-oriented and human-aligned evaluation. Finally, we benchmarked awide range of current video-language models on DeVAn, and we aim for DeVAn toserve as a useful evaluation set in the age of large language models andcomplex multi-modal tasks. Code is available at https://github.com/TK-21st/DeVAn.</description><author>Tingkai Liu, Yunzhe Tao, Haogeng Liu, Qihang Fan, Ding Zhou, Huaibo Huang, Ran He, Hongxia Yang</author><pubDate>Fri, 09 Aug 2024 16:26:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05060v2</guid></item><item><title>GeniL: A Multilingual Dataset on Generalizing Language</title><link>http://arxiv.org/abs/2404.05866v2</link><description>Generative language models are transforming our digital ecosystem, but theyoften inherit societal biases, for instance stereotypes associating certainattributes with specific identity groups. While whether and how these biasesare mitigated may depend on the specific use cases, being able to effectivelydetect instances of stereotype perpetuation is a crucial first step. Currentmethods to assess presence of stereotypes in generated language rely on simpletemplate or co-occurrence based measures, without accounting for the variety ofsentential contexts they manifest in. We argue that understanding thesentential context is crucial for detecting instances of generalization. Wedistinguish two types of generalizations: (1) language that merely mentions thepresence of a generalization ("people think the French are very rude"), and (2)language that reinforces such a generalization ("as French they must be rude"),from non-generalizing context ("My French friends think I am rude"). Formeaningful stereotype evaluations, we need to reliably distinguish suchinstances of generalizations. We introduce the new task of detectinggeneralization in language, and build GeniL, a multilingual dataset of over 50Ksentences from 9 languages (English, Arabic, Bengali, Spanish, French, Hindi,Indonesian, Malay, and Portuguese) annotated for instances of generalizations.We demonstrate that the likelihood of a co-occurrence being an instance ofgeneralization is usually low, and varies across different languages, identitygroups, and attributes. We build classifiers to detect generalization inlanguage with an overall PR-AUC of 58.7, with varying degrees of performanceacross languages. Our research provides data and tools to enable a nuancedunderstanding of stereotype perpetuation, a crucial step towards more inclusiveand responsible language technologies.</description><author>Aida Mostafazadeh Davani, Sagar Gubbi, Sunipa Dev, Shachi Dave, Vinodkumar Prabhakaran</author><pubDate>Fri, 09 Aug 2024 16:20:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05866v2</guid></item><item><title>General Lipschitz: Certified Robustness Against Resolvable Semantic Transformations via Transformation-Dependent Randomized Smoothing</title><link>http://arxiv.org/abs/2309.16710v2</link><description>Randomized smoothing is the state-of-the-art approach to construct imageclassifiers that are provably robust against additive adversarial perturbationsof bounded magnitude. However, it is more complicated to construct reasonablecertificates against semantic transformation (e.g., image blurring,translation, gamma correction) and their compositions. In this work, we propose\emph{General Lipschitz (GL),} a new framework to certify neural networksagainst composable resolvable semantic perturbations. Within the framework, weanalyze transformation-dependent Lipschitz-continuity of smoothed classifiersw.r.t. transformation parameters and derive corresponding robustnesscertificates. Our method performs comparably to state-of-the-art approaches onthe ImageNet dataset.</description><author>Dmitrii Korzh, Mikhail Pautov, Olga Tsymboi, Ivan Oseledets</author><pubDate>Fri, 09 Aug 2024 16:17:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16710v2</guid></item><item><title>Improving Large Language Models in Event Relation Logical Prediction</title><link>http://arxiv.org/abs/2310.09158v2</link><description>Event relations are crucial for narrative understanding and reasoning.Governed by nuanced logic, event relation extraction (ERE) is a challengingtask that demands thorough semantic understanding and rigorous logicalreasoning. In this paper, we conduct an in-depth investigation tosystematically explore the capability of LLMs in understanding and applyingevent relation logic. More in detail, we first investigate the deficiencies ofLLMs in logical reasoning across different tasks. Our study reveals that LLMsare not logically consistent reasoners, which results in their suboptimalperformance on tasks that need rigorous reasoning. To address this, we explorethree different approaches to endow LLMs with event relation logic, and thusenable them to generate more coherent answers across various scenarios. Basedon our approach, we also contribute a synthesized dataset (LLM-ERL) involvinghigh-order reasoning for evaluation and fine-tuning. Extensive quantitative andqualitative analyses on different tasks also validate the effectiveness of ourapproaches and provide insights for solving practical tasks with LLMs in futurework. Codes are available at https://github.com/chenmeiqii/Teach-LLM-LR.</description><author>Meiqi Chen, Yubo Ma, Kaitao Song, Yixin Cao, Yan Zhang, Dongsheng Li</author><pubDate>Fri, 09 Aug 2024 16:14:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09158v2</guid></item><item><title>Meta-Learning Guided Label Noise Distillation for Robust Signal Modulation Classification</title><link>http://arxiv.org/abs/2408.05151v1</link><description>Automatic modulation classification (AMC) is an effective way to deal withphysical layer threats of the internet of things (IoT). However, there is oftenlabel mislabeling in practice, which significantly impacts the performance androbustness of deep neural networks (DNNs). In this paper, we propose ameta-learning guided label noise distillation method for robust AMC.Specifically, a teacher-student heterogeneous network (TSHN) framework isproposed to distill and reuse label noise. Based on the idea that labels arerepresentations, the teacher network with trusted meta-learning divides andconquers untrusted label samples and then guides the student network to learnbetter by reassessing and correcting labels. Furthermore, we propose amulti-view signal (MVS) method to further improve the performance ofhard-to-classify categories with few-shot trusted label samples. Extensiveexperimental results show that our methods can significantly improve theperformance and robustness of signal AMC in various and complex label noisescenarios, which is crucial for securing IoT applications.</description><author>Xiaoyang Hao, Zhixi Feng, Tongqing Peng, Shuyuan Yang</author><pubDate>Fri, 09 Aug 2024 16:14:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05151v1</guid></item><item><title>AttackER: Towards Enhancing Cyber-Attack Attribution with a Named Entity Recognition Dataset</title><link>http://arxiv.org/abs/2408.05149v1</link><description>Cyber-attack attribution is an important process that allows experts to putin place attacker-oriented countermeasures and legal actions. The analystsmainly perform attribution manually, given the complex nature of this task. AIand, more specifically, Natural Language Processing (NLP) techniques can beleveraged to support cybersecurity analysts during the attribution process.However powerful these techniques are, they need to deal with the lack ofdatasets in the attack attribution domain. In this work, we will fill this gapand will provide, to the best of our knowledge, the first dataset oncyber-attack attribution. We designed our dataset with the primary goal ofextracting attack attribution information from cybersecurity texts, utilizingnamed entity recognition (NER) methodologies from the field of NLP. Unlikeother cybersecurity NER datasets, ours offers a rich set of annotations withcontextual details, including some that span phrases and sentences. Weconducted extensive experiments and applied NLP techniques to demonstrate thedataset's effectiveness for attack attribution. These experiments highlight thepotential of Large Language Models (LLMs) capabilities to improve the NER tasksin cybersecurity datasets for cyber-attack attribution.</description><author>Pritam Deka, Sampath Rajapaksha, Ruby Rani, Amirah Almutairi, Erisa Karafili</author><pubDate>Fri, 09 Aug 2024 16:10:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05149v1</guid></item><item><title>Impacts of floating-point non-associativity on reproducibility for HPC and deep learning applications</title><link>http://arxiv.org/abs/2408.05148v1</link><description>Run-by-run variability in parallel programs caused by floating-pointnon-associativity (FPNA) has been known to significantly affect reproducibilityin iterative algorithms, due to accumulating errors. Non-reproducibilitynegatively affects efficiency and effectiveness of correctness testing forstochastic programs. Recently, the sensitivity of deep learning (DL) trainingand inference pipelines to FPNA have been found to be extreme, and can preventcertification for commercial applications, accurate assessment of robustnessand sensitivity, and bug detection. New approaches in scientific computingapplications have coupled DL models with high-performance computing (HPC)simulations, leading to an aggravation of debugging and testing challenges.Here we perform an investigation of the statistical properties of FPNA withinmodern parallel programming models, analyze performance and productivityimpacts of replacing atomic operations with deterministic alternatives on GPUs,and examine the recently-added deterministic options within the PyTorchframework within the context of GPU deployment, uncovering and quantifying theimpacts of input parameters triggering run-by-run variability and reporting onthe reliability and completeness of the documentation. Finally, we evaluate thestrategy of exploiting automatic determinism provided by deterministichardware, using the Groq LPU$^{TM}$ accelerator for inference portions of theDL pipeline. We demonstrate the benefits that this strategy can provide withinreproducibility and correctness efforts.</description><author>Sanjif Shanmugavelu, Mathieu Taillefumier, Christopher Culver, Oscar Hernandez, Mark Coletti, Ada Sedova</author><pubDate>Fri, 09 Aug 2024 16:07:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05148v1</guid></item><item><title>Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2</title><link>http://arxiv.org/abs/2408.05147v1</link><description>Sparse autoencoders (SAEs) are an unsupervised method for learning a sparsedecomposition of a neural network's latent representations into seeminglyinterpretable features. Despite recent excitement about their potential,research applications outside of industry are limited by the high cost oftraining a comprehensive suite of SAEs. In this work, we introduce Gemma Scope,an open suite of JumpReLU SAEs trained on all layers and sub-layers of Gemma 22B and 9B and select layers of Gemma 2 27B base models. We primarily train SAEson the Gemma 2 pre-trained models, but additionally release SAEs trained oninstruction-tuned Gemma 2 9B for comparison. We evaluate the quality of eachSAE on standard metrics and release these results. We hope that by releasingthese SAE weights, we can help make more ambitious safety and interpretabilityresearch easier for the community. Weights and a tutorial can be found athttps://huggingface.co/google/gemma-scope and an interactive demo can be foundat https://www.neuronpedia.org/gemma-scope</description><author>Tom Lieberum, Senthooran Rajamanoharan, Arthur Conmy, Lewis Smith, Nicolas Sonnerat, Vikrant Varma, János Kramár, Anca Dragan, Rohin Shah, Neel Nanda</author><pubDate>Fri, 09 Aug 2024 16:06:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05147v1</guid></item><item><title>Performative Prediction on Games and Mechanism Design</title><link>http://arxiv.org/abs/2408.05146v1</link><description>Predictions often influence the reality which they aim to predict, an effectknown as performativity. Existing work focuses on accuracy maximization underthis effect, but model deployment may have important unintended impacts,especially in multiagent scenarios. In this work, we investigate performativeprediction in a concrete game-theoretic setting where social welfare is analternative objective to accuracy maximization. We explore a collective riskdilemma scenario where maximising accuracy can negatively impact socialwelfare, when predicting collective behaviours. By assuming knowledge of aBayesian agent behavior model, we then show how to achieve better trade-offsand use them for mechanism design.</description><author>António Góis, Mehrnaz Mofakhami, Fernando P. Santos, Simon Lacoste-Julien, Gauthier Gidel</author><pubDate>Fri, 09 Aug 2024 16:03:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05146v1</guid></item><item><title>Rehabilitation Exercise Quality Assessment through Supervised Contrastive Learning with Hard and Soft Negatives</title><link>http://arxiv.org/abs/2403.02772v2</link><description>Exercise-based rehabilitation programs have proven to be effective inenhancing the quality of life and reducing mortality and rehospitalizationrates. AI-driven virtual rehabilitation, which allows patients to independentlycomplete exercises at home, utilizes AI algorithms to analyze exercise data,providing feedback to patients and updating clinicians on their progress. Theseprograms commonly prescribe a variety of exercise types, leading to a distinctchallenge in rehabilitation exercise assessment datasets: while abundant inoverall training samples, these datasets often have a limited number of samplesfor each individual exercise type. This disparity hampers the ability ofexisting approaches to train generalizable models with such a small sample sizeper exercise type. Addressing this issue, this paper introduces a novelsupervised contrastive learning framework with hard and soft negative samplesthat effectively utilizes the entire dataset to train a single model applicableto all exercise types. This model, with a Spatial-Temporal Graph ConvolutionalNetwork (ST-GCN) architecture, demonstrated enhanced generalizability acrossexercises and a decrease in overall complexity. Through extensive experimentson three publicly available rehabilitation exercise assessment datasets,UI-PRMD, IRDS, and KIMORE, our method has proven to surpass existing methods,setting a new benchmark in rehabilitation exercise quality assessment.</description><author>Mark Karlov, Ali Abedi, Shehroz S. Khan</author><pubDate>Fri, 09 Aug 2024 15:54:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02772v2</guid></item><item><title>A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning</title><link>http://arxiv.org/abs/2408.05141v1</link><description>Retrieval-augmented generation (RAG) is a framework enabling large languagemodels (LLMs) to enhance their accuracy and reduce hallucinations byintegrating external knowledge bases. In this paper, we introduce a hybrid RAGsystem enhanced through a comprehensive suite of optimizations thatsignificantly improve retrieval quality, augment reasoning capabilities, andrefine numerical computation ability. We refined the text chunks and tables inweb pages, added attribute predictors to reduce hallucinations, conducted LLMKnowledge Extractor and Knowledge Graph Extractor, and finally built areasoning strategy with all the references. We evaluated our system on the CRAGdataset through the Meta CRAG KDD Cup 2024 Competition. Both the local andonline evaluations demonstrate that our system significantly enhances complexreasoning capabilities. In local evaluations, we have significantly improvedaccuracy and reduced error rates compared to the baseline model, achieving anotable increase in scores. In the meanwhile, we have attained outstandingresults in online assessments, demonstrating the performance and generalizationcapabilities of the proposed system. The source code for our system is releasedin \url{https://gitlab.aicrowd.com/shizueyy/crag-new}.</description><author>Ye Yuan, Chengwu Liu, Jingyang Yuan, Gongbo Sun, Siqi Li, Ming Zhang</author><pubDate>Fri, 09 Aug 2024 15:53:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05141v1</guid></item><item><title>Enhancing Surface Neural Implicits with Curvature-Guided Sampling and Uncertainty-Augmented Representations</title><link>http://arxiv.org/abs/2306.02099v4</link><description>Neural implicit representations have become a popular choice for modelingsurfaces due to their adaptability in resolution and support for complextopology. While previous works have achieved impressive reconstruction qualityby training on ground truth point clouds or meshes, they often do not discussthe data acquisition and ignore the effect of input quality and samplingmethods during reconstruction. In this paper, we introduce a method thatdirectly digests depth images for the task of high-fidelity 3D reconstruction.To this end, a simple sampling strategy is proposed to generate highlyeffective training data, by incorporating differentiable geometric featurescomputed directly based on the input depth images with only marginalcomputational cost. Due to its simplicity, our sampling strategy can be easilyincorporated into diverse popular methods, allowing their training process tobe more stable and efficient. Despite its simplicity, our method outperforms arange of both classical and learning-based baselines and demonstratesstate-of-the-art results in both synthetic and real-world datasets.</description><author>Lu Sang, Abhishek Saroha, Maolin Gao, Daniel Cremers</author><pubDate>Fri, 09 Aug 2024 15:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02099v4</guid></item><item><title>Cycle-Configuration: A Novel Graph-theoretic Descriptor Set for Molecular Inference</title><link>http://arxiv.org/abs/2408.05136v1</link><description>In this paper, we propose a novel family of descriptors of chemical graphs,named cycle-configuration (CC), that can be used in the standard "two-layered(2L) model" of mol-infer, a molecular inference framework based on mixedinteger linear programming (MILP) and machine learning (ML). Proposeddescriptors capture the notion of ortho/meta/para patterns that appear inaromatic rings, which has been impossible in the framework so far.Computational experiments show that, when the new descriptors are supplied, wecan construct prediction functions of similar or better performance for all ofthe 27 tested chemical properties. We also provide an MILP formulation thatasks for a chemical graph with desired properties under the 2L model with CCdescriptors (2L+CC model). We show that a chemical graph with up to 50non-hydrogen vertices can be inferred in a practical time.</description><author>Bowen Song, Jianshen Zhu, Naveed Ahmed Azam, Kazuya Haraguchi, Liang Zhao, Tatsuya Akutsu</author><pubDate>Fri, 09 Aug 2024 15:45:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05136v1</guid></item><item><title>Retinotopic Mapping Enhances the Robustness of Convolutional Neural Networks</title><link>http://arxiv.org/abs/2402.15480v2</link><description>Foveated vision, a trait shared by many animals, including humans, has notbeen fully utilized in machine learning applications, despite its significantcontributions to biological visual function. This study investigates whetherretinotopic mapping, a critical component of foveated vision, can enhance imagecategorization and localization performance when integrated into deepconvolutional neural networks (CNNs). Retinotopic mapping was integrated intothe inputs of standard off-the-shelf convolutional neural networks (CNNs),which were then retrained on the ImageNet task. As expected, thelogarithmic-polar mapping improved the network's ability to handle arbitraryimage zooms and rotations, particularly for isolated objects. Surprisingly, theretinotopically mapped network achieved comparable performance inclassification. Furthermore, the network demonstrated improved classificationlocalization when the foveated center of the transform was shifted. Thisreplicates a crucial ability of the human visual system that is absent intypical convolutional neural networks (CNNs). These findings suggest thatretinotopic mapping may be fundamental to significant preattentive visualprocesses.</description><author>Jean-Nicolas Jérémie, Emmanuel Daucé, Laurent U Perrinet</author><pubDate>Fri, 09 Aug 2024 15:40:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15480v2</guid></item><item><title>Range Membership Inference Attacks</title><link>http://arxiv.org/abs/2408.05131v1</link><description>Machine learning models can leak private information about their trainingdata, but the standard methods to measure this risk, based on membershipinference attacks (MIAs), have a major limitation. They only check if a givendata point \textit{exactly} matches a training point, neglecting the potentialof similar or partially overlapping data revealing the same privateinformation. To address this issue, we introduce the class of range membershipinference attacks (RaMIAs), testing if the model was trained on any data in aspecified range (defined based on the semantics of privacy). We formulate theRaMIAs game and design a principled statistical test for its complexhypotheses. We show that RaMIAs can capture privacy loss more accurately andcomprehensively than MIAs on various types of data, such as tabular, image, andlanguage. RaMIA paves the way for a more comprehensive and meaningful privacyauditing of machine learning algorithms.</description><author>Jiashu Tao, Reza Shokri</author><pubDate>Fri, 09 Aug 2024 15:39:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05131v1</guid></item><item><title>Knowledge Graph Large Language Model (KG-LLM) for Link Prediction</title><link>http://arxiv.org/abs/2403.07311v8</link><description>The task of multi-hop link prediction within knowledge graphs (KGs) stands asa challenge in the field of knowledge graph analysis, as it requires the modelto reason through and understand all intermediate connections before making aprediction. In this paper, we introduce the Knowledge Graph Large LanguageModel (KG-LLM), a novel framework that leverages large language models (LLMs)for knowledge graph tasks. We first convert structured knowledge graph datainto natural language and then use these natural language prompts to fine-tuneLLMs to enhance multi-hop link prediction in KGs. By converting the KG tonatural language prompts, our framework is designed to learn the latentrepresentations of entities and their interrelations. To show the efficacy ofthe KG-LLM Framework, we fine-tune three leading LLMs within this framework,including Flan-T5, LLaMa2 and Gemma. Further, we explore the framework'spotential to provide LLMs with zero-shot capabilities for handling previouslyunseen prompts. Experimental results show that KG-LLM significantly improvesthe models' generalization capabilities, leading to more accurate predictionsin unfamiliar scenarios.</description><author>Dong Shu, Tianle Chen, Mingyu Jin, Chong Zhang, Mengnan Du, Yongfeng Zhang</author><pubDate>Fri, 09 Aug 2024 15:39:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.07311v8</guid></item><item><title>Natural Gradient Interpretation of Rank-One Update in CMA-ES</title><link>http://arxiv.org/abs/2406.16506v2</link><description>The covariance matrix adaptation evolution strategy (CMA-ES) is a stochasticsearch algorithm using a multivariate normal distribution for continuousblack-box optimization. In addition to strong empirical results, part of theCMA-ES can be described by a stochastic natural gradient method and can bederived from information geometric optimization (IGO) framework. However, thereare some components of the CMA-ES, such as the rank-one update, for which thetheoretical understanding is limited. While the rank-one update makes thecovariance matrix to increase the likelihood of generating a solution in thedirection of the evolution path, this idea has been difficult to formulate andinterpret as a natural gradient method unlike the rank-$\mu$ update. In thiswork, we provide a new interpretation of the rank-one update in the CMA-ES fromthe perspective of the natural gradient with prior distribution. First, wepropose maximum a posteriori IGO (MAP-IGO), which is the IGO framework extendedto incorporate a prior distribution. Then, we derive the rank-one update fromthe MAP-IGO by setting the prior distribution based on the idea that thepromising mean vector should exist in the direction of the evolution path.Moreover, the newly derived rank-one update is extensible, where an additionalterm appears in the update for the mean vector. We empirically investigate theproperties of the additional term using various benchmark functions.</description><author>Ryoki Hamano, Shinichi Shirakawa, Masahiro Nomura</author><pubDate>Fri, 09 Aug 2024 15:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16506v2</guid></item><item><title>Large Language Models and Thematic Analysis: Human-AI Synergy in Researching Hate Speech on Social Media</title><link>http://arxiv.org/abs/2408.05126v1</link><description>In the dynamic field of artificial intelligence (AI), the development andapplication of Large Language Models (LLMs) for text analysis are ofsignificant academic interest. Despite the promising capabilities of variousLLMs in conducting qualitative analysis, their use in the humanities and socialsciences has not been thoroughly examined. This article contributes to theemerging literature on LLMs in qualitative analysis by documenting anexperimental study involving GPT-4. The study focuses on performing thematicanalysis (TA) using a YouTube dataset derived from an EU-funded project, whichwas previously analyzed by other researchers. This dataset is about therepresentation of Roma migrants in Sweden during 2016, a period marked by theaftermath of the 2015 refugee crisis and preceding the Swedish nationalelections in 2017. Our study seeks to understand the potential of combininghuman intelligence with AI's scalability and efficiency, examining theadvantages and limitations of employing LLMs in qualitative research within thehumanities and social sciences. Additionally, we discuss future directions forapplying LLMs in these fields.</description><author>Petre Breazu, Miriam Schirmer, Songbo Hu, Napoleon Kastos</author><pubDate>Fri, 09 Aug 2024 15:34:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05126v1</guid></item><item><title>Modeling Electromagnetic Signal Injection Attacks on Camera-based Smart Systems: Applications and Mitigation</title><link>http://arxiv.org/abs/2408.05124v1</link><description>Numerous safety- or security-critical systems depend on cameras to perceivetheir surroundings, further allowing artificial intelligence (AI) to analyzethe captured images to make important decisions. However, a concerning attackvector has emerged, namely, electromagnetic waves, which pose a threat to theintegrity of these systems. Such attacks enable attackers to manipulate theimages remotely, leading to incorrect AI decisions, e.g., autonomous vehiclesmissing detecting obstacles ahead resulting in collisions. The lack ofunderstanding regarding how different systems react to such attacks poses asignificant security risk. Furthermore, no effective solutions have beendemonstrated to mitigate this threat. To address these gaps, we modeled the attacks and developed a simulationmethod for generating adversarial images. Through rigorous analysis, weconfirmed that the effects of the simulated adversarial images areindistinguishable from those from real attacks. This method enables researchersand engineers to rapidly assess the susceptibility of various AI visionapplications to these attacks, without the need for constructing complicatedattack devices. In our experiments, most of the models demonstratedvulnerabilities to these attacks, emphasizing the need to enhance theirrobustness. Fortunately, our modeling and simulation method serves as astepping stone toward developing more resilient models. We present a pilotstudy on adversarial training to improve their robustness against attacks, andour results demonstrate a significant improvement by recovering up to 91%performance, offering a promising direction for mitigating this threat.</description><author>Youqian Zhang, Michael Cheung, Chunxi Yang, Xinwei Zhai, Zitong Shen, Xinyu Ji, Eugene Y. Fu, Sze-Yiu Chau, Xiapu Luo</author><pubDate>Fri, 09 Aug 2024 15:33:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05124v1</guid></item><item><title>Cautious Calibration in Binary Classification</title><link>http://arxiv.org/abs/2408.05120v1</link><description>Being cautious is crucial for enhancing the trustworthiness of machinelearning systems integrated into decision-making pipelines. Although calibratedprobabilities help in optimal decision-making, perfect calibration remainsunattainable, leading to estimates that fluctuate between under- andoverconfidence. This becomes a critical issue in high-risk scenarios, whereeven occasional overestimation can lead to extreme expected costs. In thesescenarios, it is important for each predicted probability to lean towardsunderconfidence, rather than just achieving an average balance. In this study,we introduce the novel concept of cautious calibration in binaryclassification. This approach aims to produce probability estimates that areintentionally underconfident for each predicted probability. We highlight theimportance of this approach in a high-risk scenario and propose a theoreticallygrounded method for learning cautious calibration maps. Through experiments, weexplore and compare our method to various approaches, including methodsoriginally not devised for cautious calibration but applicable in this context.We show that our approach is the most consistent in providing cautiousestimates. Our work establishes a strong baseline for further developments inthis novel framework.</description><author>Mari-Liis Allikivi, Joonas Järve, Meelis Kull</author><pubDate>Fri, 09 Aug 2024 15:19:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05120v1</guid></item><item><title>Physics-constrained convolutional neural networks for inverse problems in spatiotemporal partial differential equations</title><link>http://arxiv.org/abs/2401.10306v3</link><description>We propose a physics-constrained convolutional neural network (PC-CNN) tosolve two types of inverse problems in partial differential equations (PDEs),which are nonlinear and vary both in space and time. In the first inverseproblem, we are given data that is offset by spatially varying systematic error(i.e., the bias, also known as the epistemic uncertainty). The task is touncover the true state, which is the solution of the PDE, from the biased data.In the second inverse problem, we are given sparse information on the solutionof a PDE. The task is to reconstruct the solution in space withhigh-resolution. First, we present the PC-CNN, which constrains the PDE with atime-windowing scheme to handle sequential data. Second, we analyse theperformance of the PC-CNN for uncovering solutions from biased data. We analyseboth linear and nonlinear convection-diffusion equations, and the Navier-Stokesequations, which govern the spatiotemporally chaotic dynamics of turbulentflows. We find that the PC-CNN correctly recovers the true solution for avariety of biases, which are parameterised as non-convex functions. Third, weanalyse the performance of the PC-CNN for reconstructing solutions from sparseinformation for the turbulent flow. We reconstruct the spatiotemporal chaoticsolution on a high-resolution grid from only &lt; 1\% of the information containedin it. For both tasks, we further analyse the Navier-Stokes solutions. We findthat the inferred solutions have a physical spectral energy content, whereastraditional methods, such as interpolation, do not. This work opensopportunities for solving inverse problems with partial differential equations.</description><author>Daniel Kelshaw, Luca Magri</author><pubDate>Fri, 09 Aug 2024 15:10:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10306v3</guid></item><item><title>Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images</title><link>http://arxiv.org/abs/2408.05117v1</link><description>Early detection of dementia, such as Alzheimer's disease (AD) or mildcognitive impairment (MCI), is essential to enable timely intervention andpotential treatment. Accurate detection of AD/MCI is challenging due to thehigh complexity, cost, and often invasive nature of current diagnostictechniques, which limit their suitability for large-scale population screening.Given the shared embryological origins and physiological characteristics of theretina and brain, retinal imaging is emerging as a potentially rapid andcost-effective alternative for the identification of individuals with or athigh risk of AD. In this paper, we present a novel PolarNet+ that uses retinaloptical coherence tomography angiography (OCTA) to discriminate early-onset AD(EOAD) and MCI subjects from controls. Our method first maps OCTA images fromCartesian coordinates to polar coordinates, allowing approximate sub-regioncalculation to implement the clinician-friendly early treatment of diabeticretinopathy study (ETDRS) grid analysis. We then introduce a multi-view moduleto serialize and analyze the images along three dimensions for comprehensive,clinically useful information extraction. Finally, we abstract the sequenceembedding into a graph, transforming the detection task into a general graphclassification problem. A regional relationship module is applied after themulti-view module to excavate the relationship between the sub-regions. Suchregional relationship analyses validate known eye-brain links and reveal newdiscriminative patterns.</description><author>Shouyue Liu, Jinkui Hao, Yonghuai Liu, Huazhu Fu, Xinyu Guo, Shuting Zhang, Yitian Zhao</author><pubDate>Fri, 09 Aug 2024 15:10:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05117v1</guid></item><item><title>Concept learning of parameterized quantum models from limited measurements</title><link>http://arxiv.org/abs/2408.05116v1</link><description>Classical learning of the expectation values of observables for quantumstates is a natural variant of learning quantum states or channels. Whilelearning-theoretic frameworks establish the sample complexity and the number ofmeasurement shots per sample required for learning such statistical quantities,the interplay between these two variables has not been adequately quantifiedbefore. In this work, we take the probabilistic nature of quantum measurementsinto account in classical modelling and discuss these quantities under a singleunified learning framework. We provide provable guarantees for learningparameterized quantum models that also quantify the asymmetrical effects andinterplay of the two variables on the performance of learning algorithms. Theseresults show that while increasing the sample size enhances the learningperformance of classical machines, even with single-shot estimates, theimprovements from increasing measurements become asymptotically trivial beyonda constant factor. We further apply our framework and theoretical guarantees tostudy the impact of measurement noise on the classical surrogation ofparameterized quantum circuit models. Our work provides new tools to analysethe operational influence of finite measurement noise in the classical learningof quantum systems.</description><author>Beng Yee Gan, Po-Wei Huang, Elies Gil-Fuster, Patrick Rebentrost</author><pubDate>Fri, 09 Aug 2024 15:07:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05116v1</guid></item><item><title>Byzantine-Resilient Federated PCA and Low Rank Column-wise Sensing</title><link>http://arxiv.org/abs/2309.14512v3</link><description>This work considers two related learning problems in a federated attack pronesetting: federated principal components analysis (PCA) and federated low rankcolumn-wise sensing (LRCS). The node attacks are assumed to be Byzantine whichmeans that the attackers are omniscient and can collude. We introduce a novelprovably Byzantine-resilient communication-efficient and sampleefficientalgorithm, called Subspace-Median, that solves the PCA problem and is a keypart of the solution for the LRCS problem. We also study the most naturalByzantine-resilient solution for federated PCA, a geometric median basedmodification of the federated power method, and explain why it is not useful.Our second main contribution is a complete alternating gradient descent (GD)and minimization (altGDmin) algorithm for Byzantine-resilient horizontallyfederated LRCS and sample and communication complexity guarantees for it.Extensive simulation experiments are used to corroborate our theoreticalguarantees. The ideas that we develop for LRCS are easily extendable to otherLR recovery problems as well.</description><author>Ankit Pratap Singh, Namrata Vaswani</author><pubDate>Fri, 09 Aug 2024 15:01:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14512v3</guid></item><item><title>Mapping "Brain Terrain" Regions on Mars using Deep Learning</title><link>http://arxiv.org/abs/2311.12292v2</link><description>One of the main objectives of the Mars Exploration Program is to search forevidence of past or current life on the planet. To achieve this, Marsexploration has been focusing on regions that may have liquid or frozen water.A set of critical areas may have seen cycles of ice thawing in the relativelyrecent past in response to periodic changes in the obliquity of Mars. In thiswork, we use convolutional neural networks to detect surface regions containing"Brain Coral" terrain, a landform on Mars whose similarity in morphology andscale to sorted stone circles on Earth suggests that it may have formed as aconsequence of freeze/thaw cycles. We use large images (~100-1000 megapixels)from the Mars Reconnaissance Orbiter to search for these landforms atresolutions close to a few tens of centimeters per pixel (~25--50 cm). Over52,000 images (~28 TB) were searched (~5% of the Martian surface) where wefound detections in over 200 images. To expedite the processing we leverage aclassifier network (prior to segmentation) in the Fourier domain that can takeadvantage of JPEG compression by leveraging blocks of coefficients from adiscrete cosine transform in lieu of decoding the entire image at the fullspatial resolution. The hybrid pipeline approach maintains ~93% accuracy whilecutting down on ~95% of the total processing time compared to running thesegmentation network at the full resolution on every image. The timelyprocessing of big data sets helps inform mission operations, geologic surveysto prioritize candidate landing sites, avoid hazardous areas, or map thespatial extent of certain terrain. The segmentation masks and source code areavailable on Github for the community to explore and build upon.</description><author>Kyle A. Pearson, Eldar Noe, Daniel Zhao, Alphan Altinok, Alex Morgan</author><pubDate>Fri, 09 Aug 2024 14:50:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.12292v2</guid></item><item><title>Efficient Radiation Treatment Planning based on Voxel Importance</title><link>http://arxiv.org/abs/2405.03880v2</link><description>Radiation treatment planning involves optimization over a large number ofvoxels, many of which carry limited information about the clinical problem. Wepropose an approach to reduce the large optimization problem by only using arepresentative subset of informative voxels. This way, we drastically improveplanning efficiency while maintaining the plan quality. Within an initialprobing step, we pre-solve an easier optimization problem involving asimplified objective from which we derive an importance score per voxel. Thisimportance score is then turned into a sampling distribution, which allows usto subsample a small set of informative voxels using importance sampling. Bysolving a - now reduced - version of the original optimization problem usingthis subset, we effectively reduce the problem's size and computational demandswhile accounting for regions where satisfactory dose deliveries arechallenging. In contrast to other stochastic (sub-)sampling methods, ourtechnique only requires a single probing and sampling step to define a reducedoptimization problem. This problem can be efficiently solved using establishedsolvers without the need of modifying or adapting them. Empirical experimentson open benchmark data highlight substantially reduced optimization times, upto 50 times faster than the original ones, for intensity-modulated radiationtherapy (IMRT), all while upholding plan quality comparable to traditionalmethods. Our novel approach has the potential to significantly accelerateradiation treatment planning by addressing its inherent computationalchallenges. We reduce the treatment planning time by reducing the size of theoptimization problem rather than modifying and improving the optimizationmethod. Our efforts are thus complementary to many previous developments.</description><author>Sebastian Mair, Anqi Fu, Jens Sjölund</author><pubDate>Fri, 09 Aug 2024 14:49:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03880v2</guid></item><item><title>ORBIT: Oak Ridge Base Foundation Model for Earth System Predictability</title><link>http://arxiv.org/abs/2404.14712v4</link><description>Earth system predictability is challenged by the complexity of environmentaldynamics and the multitude of variables involved. Current AI foundation models,although advanced by leveraging large and heterogeneous data, are oftenconstrained by their size and data integration, limiting their effectiveness inaddressing the full range of Earth system prediction challenges. To overcomethese limitations, we introduce the Oak Ridge Base Foundation Model for EarthSystem Predictability (ORBIT), an advanced vision transformer model that scalesup to 113 billion parameters using a novel hybrid tensor-data orthogonalparallelism technique. As the largest model of its kind, ORBIT surpasses thecurrent climate AI foundation model size by a thousandfold. Performance scalingtests conducted on the Frontier supercomputer have demonstrated that ORBITachieves 684 petaFLOPS to 1.6 exaFLOPS sustained throughput, with scalingefficiency maintained at 41% to 85% across 49,152 AMD GPUs. These breakthroughsestablish new advances in AI-driven climate modeling and demonstrate promise tosignificantly improve the Earth system predictability.</description><author>Xiao Wang, Siyan Liu, Aristeidis Tsaris, Jong-Youl Choi, Ashwin Aji, Ming Fan, Wei Zhang, Junqi Yin, Moetasim Ashfaq, Dan Lu, Prasanna Balaprakash</author><pubDate>Fri, 09 Aug 2024 14:49:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14712v4</guid></item><item><title>How Well Do LLMs Identify Cultural Unity in Diversity?</title><link>http://arxiv.org/abs/2408.05102v1</link><description>Much work on the cultural awareness of large language models (LLMs) focuseson the models' sensitivity to geo-cultural diversity. However, in addition tocross-cultural differences, there also exists common ground across cultures.For instance, a bridal veil in the United States plays a similarcultural-relevant role as a honggaitou in China. In this study, we introduce abenchmark dataset CUNIT for evaluating decoder-only LLMs in understanding thecultural unity of concepts. Specifically, CUNIT consists of 1,425 evaluationexamples building upon 285 traditional cultural-specific concepts across 10countries. Based on a systematic manual annotation of cultural-relevantfeatures per concept, we calculate the cultural association between any pair ofcross-cultural concepts. Built upon this dataset, we design a contrastivematching task to evaluate the LLMs' capability to identify highly associatedcross-cultural concept pairs. We evaluate 3 strong LLMs, using 3 popularprompting strategies, under the settings of either giving all extracted conceptfeatures or no features at all on CUNIT Interestingly, we find that culturalassociations across countries regarding clothing concepts largely differ fromfood. Our analysis shows that LLMs are still limited to capturingcross-cultural associations between concepts compared to humans. Moreover,geo-cultural proximity shows a weak influence on model performance in capturingcross-cultural associations.</description><author>Jialin Li, Junli Wang, Junjie Hu, Ming Jiang</author><pubDate>Fri, 09 Aug 2024 14:45:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05102v1</guid></item><item><title>MooER: LLM-based Speech Recognition and Translation Models from Moore Threads</title><link>http://arxiv.org/abs/2408.05101v1</link><description>In this paper, we present MooER, a LLM-based large-scale automatic speechrecognition (ASR) / automatic speech translation (AST) model of Moore Threads.A 5000h pseudo labeled dataset containing open source and self collected speechdata is used for training. We achieve performance comparable to other opensource models trained with up to hundreds of thousands of hours of labeledspeech data. Meanwhile, experiments conducted on Covost2 Zh2en testset suggestthat our model outperforms other open source Speech LLMs. A BLEU score of 25.2can be obtained. The main contributions of this paper are summarized asfollows. First, this paper presents a training strategy for encoders and LLMson speech related tasks (including ASR and AST) using a small size of pseudolabeled data without any extra manual annotation and selection. Second, werelease our ASR and AST models and plan to open-source our training code andstrategy in the near future. Moreover, a model trained on 8wh scale trainingdata is planned to be released later on.</description><author>Junhao Xu, Zhenlin Liang, Yi Liu, Yichao Hu, Jian Li, Yajun Zheng, Meng Cai, Hua Wang</author><pubDate>Fri, 09 Aug 2024 14:43:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05101v1</guid></item><item><title>AI-driven Java Performance Testing: Balancing Result Quality with Testing Time</title><link>http://arxiv.org/abs/2408.05100v1</link><description>Performance testing aims at uncovering efficiency issues of software systems.In order to be both effective and practical, the design of a performance testmust achieve a reasonable trade-off between result quality and testing time.This becomes particularly challenging in Java context, where the softwareundergoes a warm-up phase of execution, due to just-in-time compilation. Duringthis phase, performance measurements are subject to severe fluctuations, whichmay adversely affect quality of performance test results. However, theseapproaches often provide suboptimal estimates of the warm-up phase, resultingin either insufficient or excessive warm-up iterations, which may degraderesult quality or increase testing time. There is still a lack of consensus onhow to properly address this problem. Here, we propose and study an AI-basedframework to dynamically halt warm-up iterations at runtime. Specifically, ourframework leverages recent advances in AI for Time Series Classification (TSC)to predict the end of the warm-up phase during test execution. We conductexperiments by training three different TSC models on half a million ofmeasurement segments obtained from JMH microbenchmark executions. We find thatour framework significantly improves the accuracy of the warm-up estimatesprovided by state-of-practice and state-of-the-art methods. This higherestimation accuracy results in a net improvement in either result quality ortesting time for up to +35.3% of the microbenchmarks. Our study highlights thatintegrating AI to dynamically estimate the end of the warm-up phase can enhancethe cost-effectiveness of Java performance testing.</description><author>Luca Traini, Federico Di Menna, Vittorio Cortellessa</author><pubDate>Fri, 09 Aug 2024 14:41:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05100v1</guid></item><item><title>Tensor Frames -- How To Make Any Message Passing Network Equivariant</title><link>http://arxiv.org/abs/2405.15389v2</link><description>In many applications of geometric deep learning, the choice of globalcoordinate frame is arbitrary, and predictions should be independent of thereference frame. In other words, the network should be equivariant with respectto rotations and reflections of the input, i.e., the transformations of O(d).We present a novel framework for building equivariant message passingarchitectures and modifying existing non-equivariant architectures to beequivariant. Our approach is based on local coordinate frames, between whichgeometric information is communicated consistently by including tensorialobjects in the messages. Our framework can be applied to message passing ongeometric data in arbitrary dimensional Euclidean space. While many otherapproaches for equivariant message passing require specialized building blocks,such as non-standard normalization layers or non-linearities, our approach canbe adapted straightforwardly to any existing architecture without suchmodifications. We explicitly demonstrate the benefit of O(3)-equivariance for apopular point cloud architecture and produce state-of-the-art results on normalvector regression on point clouds.</description><author>Peter Lippmann, Gerrit Gerhartz, Roman Remme, Fred A. Hamprecht</author><pubDate>Fri, 09 Aug 2024 14:40:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15389v2</guid></item><item><title>Overcoming the Limitations of Layer Synchronization in Spiking Neural Networks</title><link>http://arxiv.org/abs/2408.05098v1</link><description>Currently, neural-network processing in machine learning applications relieson layer synchronization, whereby neurons in a layer aggregate incomingcurrents from all neurons in the preceding layer, before evaluating theiractivation function. This is practiced even in artificial Spiking NeuralNetworks (SNNs), which are touted as consistent with neurobiology, in spite ofprocessing in the brain being, in fact asynchronous. A truly asynchronoussystem however would allow all neurons to evaluate concurrently their thresholdand emit spikes upon receiving any presynaptic current. Omitting layersynchronization is potentially beneficial, for latency and energy efficiency,but asynchronous execution of models previously trained with layersynchronization may entail a mismatch in network dynamics and performance. Wepresent a study that documents and quantifies this problem in three datasets onour simulation environment that implements network asynchrony, and we show thatmodels trained with layer synchronization either perform sub-optimally inabsence of the synchronization, or they will fail to benefit from any energyand latency reduction, when such a mechanism is in place. We then "make endsmeet" and address the problem with unlayered backprop, a novelbackpropagation-based training method, for learning models suitable forasynchronous processing. We train with it models that use different neuronexecution scheduling strategies, and we show that although their neurons aremore reactive, these models consistently exhibit lower overall spike density(up to 50%), reach a correct decision faster (up to 2x) without integrating allspikes, and achieve superior accuracy (up to 10% higher). Our findings suggestthat asynchronous event-based (neuromorphic) AI computing is indeed moreefficient, but we need to seriously rethink how we train our SNN models, tobenefit from it.</description><author>Roel Koopman, Amirreza Yousefzadeh, Mahyar Shahsavari, Guangzhi Tang, Manolis Sifalakis</author><pubDate>Fri, 09 Aug 2024 14:39:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05098v1</guid></item><item><title>Hyperbolic Learning with Multimodal Large Language Models</title><link>http://arxiv.org/abs/2408.05097v1</link><description>Hyperbolic embeddings have demonstrated their effectiveness in capturingmeasures of uncertainty and hierarchical relationships across variousdeep-learning tasks, including image segmentation and active learning. However,their application in modern vision-language models (VLMs) has been limited. Anotable exception is MERU, which leverages the hierarchical properties ofhyperbolic space in the CLIP ViT-large model, consisting of hundreds ofmillions parameters. In our work, we address the challenges of scalingmulti-modal hyperbolic models by orders of magnitude in terms of parameters(billions) and training complexity using the BLIP-2 architecture. Althoughhyperbolic embeddings offer potential insights into uncertainty not present inEuclidean embeddings, our analysis reveals that scaling these models isparticularly difficult. We propose a novel training strategy for a hyperbolicversion of BLIP-2, which allows to achieve comparable performance to itsEuclidean counterpart, while maintaining stability throughout the trainingprocess and showing a meaningful indication of uncertainty with each embedding.</description><author>Paolo Mandica, Luca Franco, Konstantinos Kallidromitis, Suzanne Petryk, Fabio Galasso</author><pubDate>Fri, 09 Aug 2024 14:39:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05097v1</guid></item><item><title>Unlocking Decoding-time Controllability: Gradient-Free Multi-Objective Alignment with Contrastive Prompts</title><link>http://arxiv.org/abs/2408.05094v1</link><description>The task of multi-objective alignment aims at balancing and controlling thedifferent alignment objectives (e.g., helpfulness, harmlessness and honesty) oflarge language models to meet the personalized requirements of different users.However, previous methods tend to train multiple models to deal with varioususer preferences, with the number of trained models growing linearly with thenumber of alignment objectives and the number of different preferences.Meanwhile, existing methods are generally poor in extensibility and requiresignificant re-training for each new alignment objective considered.Considering the limitation of previous approaches, we propose MCA(Multi-objective Contrastive Alignemnt), which constructs an expert prompt andan adversarial prompt for each objective to contrast at the decoding time andbalances the objectives through combining the contrast. Our approach isverified to be superior to previous methods in obtaining a well-distributedPareto front among different alignment objectives.</description><author>Tingchen Fu, Yupeng Hou, Julian McAuley, Rui Yan</author><pubDate>Fri, 09 Aug 2024 14:36:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05094v1</guid></item><item><title>Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models</title><link>http://arxiv.org/abs/2408.05093v1</link><description>Large language models (LLMs) have generated significant attention since theirinception, finding applications across various academic and industrial domains.However, these models often suffer from the "hallucination problem", whereoutputs, though grammatically and logically coherent, lack factual accuracy orare entirely fabricated. A particularly troubling issue discovered and widelydiscussed recently is the numerical comparison error where multiple LLMsincorrectly infer that "9.11$&gt;$9.9". We discovered that the order in which LLMsgenerate answers and reasoning impacts their consistency. Specifically, resultsvary significantly when an LLM generates an answer first and then provides thereasoning versus generating the reasoning process first and then theconclusion. Inspired by this, we propose a new benchmark method for assessingLLM consistency: comparing responses generated through these two differentapproaches. This benchmark effectively identifies instances where LLMsfabricate answers and subsequently generate justifications. Furthermore, weintroduce a novel and straightforward prompt strategy designed to mitigate thisissue. Experimental results demonstrate that this strategy improves performanceacross various LLMs compared to direct questioning. This work not only shedslight on a critical flaw in LLMs but also offers a practical solution toenhance their reliability.</description><author>Zikai Xie</author><pubDate>Fri, 09 Aug 2024 14:34:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05093v1</guid></item><item><title>PriPHiT: Privacy-Preserving Hierarchical Training of Deep Neural Networks</title><link>http://arxiv.org/abs/2408.05092v1</link><description>The training phase of deep neural networks requires substantial resources andas such is often performed on cloud servers. However, this raises privacyconcerns when the training dataset contains sensitive content, e.g., faceimages. In this work, we propose a method to perform the training phase of adeep learning model on both an edge device and a cloud server that preventssensitive content being transmitted to the cloud while retaining the desiredinformation. The proposed privacy-preserving method uses adversarial earlyexits to suppress the sensitive content at the edge and transmits thetask-relevant information to the cloud. This approach incorporates noiseaddition during the training phase to provide a differential privacy guarantee.We extensively test our method on different facial datasets with diverse faceattributes using various deep learning architectures, showcasing itsoutstanding performance. We also demonstrate the effectiveness of privacypreservation through successful defenses against different white-box and deepreconstruction attacks.</description><author>Yamin Sepehri, Pedram Pad, Pascal Frossard, L. Andrea Dunbar</author><pubDate>Fri, 09 Aug 2024 14:33:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05092v1</guid></item><item><title>Loc4Plan: Locating Before Planning for Outdoor Vision and Language Navigation</title><link>http://arxiv.org/abs/2408.05090v1</link><description>Vision and Language Navigation (VLN) is a challenging task that requiresagents to understand instructions and navigate to the destination in a visualenvironment.One of the key challenges in outdoor VLN is keeping track of whichpart of the instruction was completed. To alleviate this problem, previousworks mainly focus on grounding the natural language to the visual input, butneglecting the crucial role of the agent's spatial position information in thegrounding process. In this work, we first explore the substantial effect ofspatial position locating on the grounding of outdoor VLN, drawing inspirationfrom human navigation. In real-world navigation scenarios, before planning apath to the destination, humans typically need to figure out their currentlocation. This observation underscores the pivotal role of spatial localizationin the navigation process. In this work, we introduce a novel framework,Locating be for Planning (Loc4Plan), designed to incorporate spatial perceptionfor action planning in outdoor VLN tasks. The main idea behind Loc4Plan is toperform the spatial localization before planning a decision action based oncorresponding guidance, which comprises a block-aware spatial locating (BAL)module and a spatial-aware action planning (SAP) module. Specifically, to helpthe agent perceive its spatial location in the environment, we propose to learna position predictor that measures how far the agent is from the nextintersection for reflecting its position, which is achieved by the BAL module.After the locating process, we propose the SAP module to incorporate spatialinformation to ground the corresponding guidance and enhance the precision ofaction planning. Extensive experiments on the Touchdown and map2seq datasetsshow that the proposed Loc4Plan outperforms the SOTA methods.</description><author>Huilin Tian, Jingke Meng, Wei-Shi Zheng, Yuan-Ming Li, Junkai Yan, Yunong Zhang</author><pubDate>Fri, 09 Aug 2024 14:31:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05090v1</guid></item><item><title>IllusionVQA: A Challenging Optical Illusion Dataset for Vision Language Models</title><link>http://arxiv.org/abs/2403.15952v3</link><description>The advent of Vision Language Models (VLM) has allowed researchers toinvestigate the visual understanding of a neural network using naturallanguage. Beyond object classification and detection, VLMs are capable ofvisual comprehension and common-sense reasoning. This naturally led to thequestion: How do VLMs respond when the image itself is inherently unreasonable?To this end, we present IllusionVQA: a diverse dataset of challenging opticalillusions and hard-to-interpret scenes to test the capability of VLMs in twodistinct multiple-choice VQA tasks - comprehension and soft localization.GPT4V, the best performing VLM, achieves 62.99% accuracy (4-shot) on thecomprehension task and 49.7% on the localization task (4-shot andChain-of-Thought). Human evaluation reveals that humans achieve 91.03% and 100%accuracy in comprehension and localization. We discover that In-ContextLearning (ICL) and Chain-of-Thought reasoning substantially degrade theperformance of Gemini-Pro in the localization task. Tangentially, we discover apotential weakness in the ICL capabilities of VLMs: they fail to locate opticalillusions even when the correct answer is in the context window as a few-shotexample.</description><author>Haz Sameen Shahgir, Khondker Salman Sayeed, Abhik Bhattacharjee, Wasi Uddin Ahmad, Yue Dong, Rifat Shahriyar</author><pubDate>Fri, 09 Aug 2024 14:26:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15952v3</guid></item><item><title>Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models</title><link>http://arxiv.org/abs/2408.04594v2</link><description>High-performance Multimodal Large Language Models (MLLMs) rely heavily ondata quality. This study introduces a novel dataset named Img-Diff, designed toenhance fine-grained image recognition in MLLMs by leveraging insights fromcontrastive learning and image difference captioning. By analyzing objectdifferences between similar images, we challenge models to identify bothmatching and distinct components. We utilize the Stable-Diffusion-XL model andadvanced image editing techniques to create pairs of similar images thathighlight object replacements. Our methodology includes a Difference AreaGenerator for object differences identifying, followed by a Difference CaptionsGenerator for detailed difference descriptions. The result is a relativelysmall but high-quality dataset of "object replacement" samples. We use the theproposed dataset to finetune state-of-the-art (SOTA) MLLMs such as MGM-7B,yielding comprehensive improvements of performance scores over SOTA models thattrained with larger-scale datasets, in numerous image difference and VisualQuestion Answering tasks. For instance, our trained models notably surpass theSOTA models GPT-4V and Gemini on the MMVP benchmark. Besides, we investigatealternative methods for generating image difference data through "objectremoval" and conduct a thorough evaluation to confirm the dataset's diversity,quality, and robustness, presenting several insights on the synthesis of such acontrastive dataset. To encourage further research and advance the field ofmultimodal data synthesis and enhancement of MLLMs' fundamental capabilitiesfor image understanding, we release our codes and dataset athttps://github.com/modelscope/data-juicer/tree/ImgDiff.</description><author>Qirui Jiao, Daoyuan Chen, Yilun Huang, Yaliang Li, Ying Shen</author><pubDate>Fri, 09 Aug 2024 14:24:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.04594v2</guid></item><item><title>UNIC: Universal Classification Models via Multi-teacher Distillation</title><link>http://arxiv.org/abs/2408.05088v1</link><description>Pretrained models have become a commodity and offer strong results on a broadrange of tasks. In this work, we focus on classification and seek to learn aunique encoder able to take from several complementary pretrained models. Weaim at even stronger generalization across a variety of classification tasks.We propose to learn such an encoder via multi-teacher distillation. We firstthoroughly analyse standard distillation when driven by multiple strongteachers with complementary strengths. Guided by this analysis, we graduallypropose improvements to the basic distillation setup. Among those, we enrichthe architecture of the encoder with a ladder of expendable projectors, whichincreases the impact of intermediate features during distillation, and weintroduce teacher dropping, a regularization mechanism that better balances theteachers' influence. Our final distillation strategy leads to student models ofthe same capacity as any of the teachers, while retaining or improving upon theperformance of the best teacher for each task. Project page and code: https://europe.naverlabs.com/unic</description><author>Mert Bulent Sariyildiz, Philippe Weinzaepfel, Thomas Lucas, Diane Larlus, Yannis Kalantidis</author><pubDate>Fri, 09 Aug 2024 14:18:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05088v1</guid></item><item><title>PDDLEGO: Iterative Planning in Textual Environments</title><link>http://arxiv.org/abs/2405.19793v2</link><description>Planning in textual environments have been shown to be a long-standingchallenge even for current models. A recent, promising line of work uses LLMsto generate a formal representation of the environment that can be solved by asymbolic planner. However, existing methods rely on a fully-observedenvironment where all entity states are initially known, so a one-offrepresentation can be constructed, leading to a complete plan. In contrast, wetackle partially-observed environments where there is initially no sufficientinformation to plan for the end-goal. We propose PDDLEGO that iterativelyconstruct a planning representation that can lead to a partial plan for a givensub-goal. By accomplishing the sub-goal, more information is acquired toaugment the representation, eventually achieving the end-goal. We show thatplans produced by few-shot PDDLEGO are 43% more efficient than generating plansend-to-end on the Coin Collector simulation, with strong performance (98%) onthe more complex Cooking World simulation where end-to-end LLMs fail togenerate coherent plans (4%).</description><author>Li Zhang, Peter Jansen, Tianyi Zhang, Peter Clark, Chris Callison-Burch, Niket Tandon</author><pubDate>Fri, 09 Aug 2024 14:18:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19793v2</guid></item><item><title>Bootstrap Latents of Nodes and Neighbors for Graph Self-Supervised Learning</title><link>http://arxiv.org/abs/2408.05087v1</link><description>Contrastive learning is a significant paradigm in graph self-supervisedlearning. However, it requires negative samples to prevent model collapse andlearn discriminative representations. These negative samples inevitably lead toheavy computation, memory overhead and class collision, compromising therepresentation learning. Recent studies present that methods obviating negativesamples can attain competitive performance and scalability enhancements,exemplified by bootstrapped graph latents (BGRL). However, BGRL neglects theinherent graph homophily, which provides valuable insights into underlyingpositive pairs. Our motivation arises from the observation that subtlyintroducing a few ground-truth positive pairs significantly improves BGRL.Although we can't obtain ground-truth positive pairs without labels under theself-supervised setting, edges in the graph can reflect noisy positive pairs,i.e., neighboring nodes often share the same label. Therefore, we propose toexpand the positive pair set with node-neighbor pairs. Subsequently, weintroduce a cross-attention module to predict the supportiveness score of aneighbor with respect to the anchor node. This score quantifies the positivesupport from each neighboring node, and is encoded into the training objective.Consequently, our method mitigates class collision from negative and noisypositive samples, concurrently enhancing intra-class compactness. Extensiveexperiments are conducted on five benchmark datasets and three downstream tasknode classification, node clustering, and node similarity search. The resultsdemonstrate that our method generates node representations with enhancedintra-class compactness and achieves state-of-the-art performance.</description><author>Yunhui Liu, Huaisong Zhang, Tieke He, Tao Zheng, Jianhua Zhao</author><pubDate>Fri, 09 Aug 2024 14:17:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05087v1</guid></item><item><title>Generating novel experimental hypotheses from language models: A case study on cross-dative generalization</title><link>http://arxiv.org/abs/2408.05086v1</link><description>Neural network language models (LMs) have been shown to successfully capturecomplex linguistic knowledge. However, their utility for understanding languageacquisition is still debated. We contribute to this debate by presenting a casestudy where we use LMs as simulated learners to derive novel experimentalhypotheses to be tested with humans. We apply this paradigm to studycross-dative generalization (CDG): productive generalization of novel verbsacross dative constructions (she pilked me the ball/she pilked the ball to me)-- acquisition of which is known to involve a large space of contextualfeatures -- using LMs trained on child-directed speech. We specifically ask:"what properties of the training exposure facilitate a novel verb'sgeneralization to the (unmodeled) alternate construction?" To answer this, wesystematically vary the exposure context in which a novel dative verb occurs interms of the properties of the theme and recipient, and then analyze the LMs'usage of the novel verb in the unmodeled dative construction. We find LMs toreplicate known patterns of children's CDG, as a precondition to exploringnovel hypotheses. Subsequent simulations reveal a nuanced role of the featuresof the novel verbs' exposure context on the LMs' CDG. We find CDG to befacilitated when the first postverbal argument of the exposure context ispronominal, definite, short, and conforms to the prototypical animacyexpectations of the exposure dative. These patterns are characteristic ofharmonic alignment in datives, where the argument with features ranking higheron the discourse prominence scale tends to precede the other. This gives riseto a novel hypothesis that CDG is facilitated insofar as the features of theexposure context -- in particular, its first postverbal argument -- areharmonically aligned. We conclude by proposing future experiments that can testthis hypothesis in children.</description><author>Kanishka Misra, Najoung Kim</author><pubDate>Fri, 09 Aug 2024 14:17:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05086v1</guid></item><item><title>On expected signatures and signature cumulants in semimartingale models</title><link>http://arxiv.org/abs/2408.05085v1</link><description>The concept of signatures and expected signatures is vital in data science,especially for sequential data analysis. The signature transform, a Cartan typedevelopment, translates paths into high-dimensional feature vectors, capturingtheir intrinsic characteristics. Under natural conditions, the expectation ofthe signature determines the law of the signature, providing a statisticalsummary of the data distribution. This property facilitates robust modeling andinference in machine learning and stochastic processes. Building on previouswork by the present authors [Unified signature cumulants and generalized Magnusexpansions, FoM Sigma '22] we here revisit the actual computation of expectedsignatures, in a general semimartingale setting. Several new formulae aregiven. A log-transform of (expected) signatures leads to log-signatures(signature cumulants), offering a significant reduction in complexity.</description><author>Peter K. Friz, Paul P. Hager, Nikolas Tapia</author><pubDate>Fri, 09 Aug 2024 14:16:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05085v1</guid></item><item><title>Generalizing Few Data to Unseen Domains Flexibly Based on Label Smoothing Integrated with Distributionally Robust Optimization</title><link>http://arxiv.org/abs/2408.05082v1</link><description>Overfitting commonly occurs when applying deep neural networks (DNNs) onsmall-scale datasets, where DNNs do not generalize well from existing data tounseen data. The main reason resulting in overfitting is that small-scaledatasets cannot reflect the situations of the real world. Label smoothing (LS)is an effective regularization method to prevent overfitting, avoiding it bymixing one-hot labels with uniform label vectors. However, LS only focuses onlabels while ignoring the distribution of existing data. In this paper, weintroduce the distributionally robust optimization (DRO) to LS, achieving shiftthe existing data distribution flexibly to unseen domains when training DNNs.Specifically, we prove that the regularization of LS can be extended to aregularization term for the DNNs parameters when integrating DRO. Theregularization term can be utilized to shift existing data to unseen domainsand generate new data. Furthermore, we propose an approximategradient-iteration label smoothing algorithm (GI-LS) to achieve the findingsand train DNNs. We prove that the shift for the existing data does notinfluence the convergence of GI-LS. Since GI-LS incorporates a series ofhyperparameters, we further consider using Bayesian optimization (BO) to findthe relatively optimal combinations of these hyperparameters. Takingsmall-scale anomaly classification tasks as a case, we evaluate GI-LS, and theresults clearly demonstrate its superior performance.</description><author>Yangdi Wang, Zhi-Hai Zhang, Su Xiu Xu, Wenming Guo</author><pubDate>Fri, 09 Aug 2024 14:13:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05082v1</guid></item><item><title>DreamLCM: Towards High-Quality Text-to-3D Generation via Latent Consistency Model</title><link>http://arxiv.org/abs/2408.02993v2</link><description>Recently, the text-to-3D task has developed rapidly due to the appearance ofthe SDS method. However, the SDS method always generates 3D objects with poorquality due to the over-smooth issue. This issue is attributed to two factors:1) the DDPM single-step inference produces poor guidance gradients; 2) therandomness from the input noises and timesteps averages the details of the 3Dcontents. In this paper, to address the issue, we propose DreamLCM whichincorporates the Latent Consistency Model (LCM). DreamLCM leverages thepowerful image generation capabilities inherent in LCM, enabling generatingconsistent and high-quality guidance, i.e., predicted noises or images. Poweredby the improved guidance, the proposed method can provide accurate and detailedgradients to optimize the target 3D models. In addition, we propose twostrategies to enhance the generation quality further. Firstly, we propose aguidance calibration strategy, utilizing Euler Solver to calibrate the guidancedistribution to accelerate 3D models to converge. Secondly, we propose a dualtimestep strategy, increasing the consistency of guidance and optimizing 3Dmodels from geometry to appearance in DreamLCM. Experiments show that DreamLCMachieves state-of-the-art results in both generation quality and trainingefficiency. The code is available at https://github.com/1YimingZhong/DreamLCM.</description><author>Yiming Zhong, Xiaolin Zhang, Yao Zhao, Yunchao Wei</author><pubDate>Fri, 09 Aug 2024 14:12:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02993v2</guid></item><item><title>DeepInteraction++: Multi-Modality Interaction for Autonomous Driving</title><link>http://arxiv.org/abs/2408.05075v1</link><description>Existing top-performance autonomous driving systems typically rely on themulti-modal fusion strategy for reliable scene understanding. This design ishowever fundamentally restricted due to overlooking the modality-specificstrengths and finally hampering the model performance. To address thislimitation, in this work, we introduce a novel modality interaction strategythat allows individual per-modality representations to be learned andmaintained throughout, enabling their unique characteristics to be exploitedduring the whole perception pipeline. To demonstrate the effectiveness of theproposed strategy, we design DeepInteraction++, a multi-modal interactionframework characterized by a multi-modal representational interaction encoderand a multi-modal predictive interaction decoder. Specifically, the encoder isimplemented as a dual-stream Transformer with specialized attention operationfor information exchange and integration between separate modality-specificrepresentations. Our multi-modal representational learning incorporates bothobject-centric, precise sampling-based feature alignment and global denseinformation spreading, essential for the more challenging planning task. Thedecoder is designed to iteratively refine the predictions by alternatelyaggregating information from separate representations in a unifiedmodality-agnostic manner, realizing multi-modal predictive interaction.Extensive experiments demonstrate the superior performance of the proposedframework on both 3D object detection and end-to-end autonomous driving tasks.Our code is available at https://github.com/fudan-zvg/DeepInteraction.</description><author>Zeyu Yang, Nan Song, Wei Li, Xiatian Zhu, Li Zhang, Philip H. S. Torr</author><pubDate>Fri, 09 Aug 2024 14:04:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05075v1</guid></item><item><title>RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records</title><link>http://arxiv.org/abs/2408.05074v1</link><description>Accurate patient selection is critical in radiotherapy (RT) to preventineffective treatments. Traditional survival prediction models, relying onstructured data, often lack precision. This study explores the potential oflarge language models (LLMs) to structure unstructured electronic health record(EHR) data, thereby improving survival prediction accuracy throughcomprehensive clinical information integration. Data from 34,276 patientstreated with RT at Yonsei Cancer Center between 2013 and 2023 were analyzed,encompassing both structured and unstructured data. An open-source LLM was usedto structure the unstructured EHR data via single-shot learning, with itsperformance compared against a domain-specific medical LLM and a smallervariant. Survival prediction models were developed using statistical, machinelearning, and deep learning approaches, incorporating both structured andLLM-structured data. Clinical experts evaluated the accuracy of theLLM-structured data. The open-source LLM achieved 87.5% accuracy in structuringunstructured EHR data without additional training, significantly outperformingthe domain-specific medical LLM, which reached only 35.8% accuracy. Larger LLMswere more effective, particularly in extracting clinically relevant featureslike general condition and disease extent, which closely correlated withpatient survival. Incorporating LLM-structured clinical features into survivalprediction models significantly improved accuracy, with the C-index of deeplearning models increasing from 0.737 to 0.820. These models also became moreinterpretable by emphasizing clinically significant factors. This study showsthat general-domain LLMs, even without specific medical training, caneffectively structure large-scale unstructured EHR data, substantiallyenhancing the accuracy and interpretability of clinical predictive models.</description><author>Sangjoon Park, Chan Woo Wee, Seo Hee Choi, Kyung Hwan Kim, Jee Suk Chang, Hong In Yoon, Ik Jae Lee, Yong Bae Kim, Jaeho Cho, Ki Chang Keum, Chang Geol Lee, Hwa Kyung Byun, Woong Sub Koom</author><pubDate>Fri, 09 Aug 2024 14:02:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05074v1</guid></item><item><title>Object-level Geometric Structure Preserving for Natural Image Stitching</title><link>http://arxiv.org/abs/2402.12677v3</link><description>The topic of stitching images with globally natural structures holdsparamount significance, with two main goals: alignment and distortionprevention. The existing approaches exhibit the ability to align well, yet fallshort in maintaining object structures. In this paper, we endeavour tosafeguard the overall OBJect-level structures within images based on GlobalSimilarity Prior (OBJ-GSP), on the basis of good alignment performance. Ourapproach leverages semantic segmentation models like the family of SegmentAnything Model to extract the contours of any objects in a scene. Triangularmeshes are employed in image transformation to protect the overall shapes ofobjects within images. The balance between alignment and distortion preventionis achieved by allowing the object meshes to strike a balance betweensimilarity and projective transformation. We also demonstrate the importance ofsegmentation in low-altitude aerial image stitching. Additionally, we proposeStitchBench, the most comprehensive image stitching benchmark by far. Extensiveexperimental results demonstrate that OBJ-GSP outperforms existing methods inboth alignment and shape preservation. Code and dataset is publicly availableat \url{https://github.com/RussRobin/OBJ-GSP}.</description><author>Wenxiao Cai, Wankou Yang</author><pubDate>Fri, 09 Aug 2024 13:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12677v3</guid></item><item><title>A Context-Contrastive Inference Approach To Partial Diacritization</title><link>http://arxiv.org/abs/2401.08919v3</link><description>Diacritization plays a pivotal role in improving readability anddisambiguating the meaning of Arabic texts. Efforts have so far focused onmarking every eligible character (Full Diacritization). Comparativelyoverlooked, Partial Diacritzation (PD) is the selection of a subset ofcharacters to be marked to aid comprehension where needed. Research hasindicated that excessive diacritic marks can hinder skilled readers -- reducingreading speed and accuracy. We conduct a behavioral experiment and show thatpartially marked text is often easier to read than fully marked text, andsometimes easier than plain text. In this light, we introduceContext-Contrastive Partial Diacritization (CCPD) -- a novel approach to PDwhich integrates seamlessly with existing Arabic diacritization systems. CCPDprocesses each word twice, once with context and once without, and diacritizesonly the characters with disparities between the two inferences. Further, weintroduce novel indicators for measuring partial diacritization quality,essential for establishing this as a machine learning task. Lastly, weintroduce TD2, a Transformer-variant of an established model which offers amarkedly different performance profile on our proposed indicators compared toall other known systems.</description><author>Muhammad ElNokrashy, Badr AlKhamissi</author><pubDate>Fri, 09 Aug 2024 13:49:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08919v3</guid></item><item><title>Masked adversarial neural network for cell type deconvolution in spatial transcriptomics</title><link>http://arxiv.org/abs/2408.05065v1</link><description>Accurately determining cell type composition in disease-relevant tissues iscrucial for identifying disease targets. Most existing spatial transcriptomics(ST) technologies cannot achieve single-cell resolution, making it challengingto accurately determine cell types. To address this issue, variousdeconvolution methods have been developed. Most of these methods usesingle-cell RNA sequencing (scRNA-seq) data from the same tissue as a referenceto infer cell types in ST data spots. However, they often overlook thedifferences between scRNA-seq and ST data. To overcome this limitation, wepropose a Masked Adversarial Neural Network (MACD). MACD employs adversariallearning to align real ST data with simulated ST data generated from scRNA-seqdata. By mapping them into a unified latent space, it can minimize thedifferences between the two types of data. Additionally, MACD uses maskingtechniques to effectively learn the features of real ST data and mitigatenoise. We evaluated MACD on 32 simulated datasets and 2 real datasets,demonstrating its accuracy in performing cell type deconvolution. All code andpublic datasets used in this paper are available athttps://github.com/wenwenmin/MACD and https://zenodo.org/records/12804822.</description><author>Lin Huang, Xiaofei Liu, Shunfang Wang, Wenwen Min</author><pubDate>Fri, 09 Aug 2024 13:46:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05065v1</guid></item><item><title>Back-Projection Diffusion: Solving the Wideband Inverse Scattering Problem with Diffusion Models</title><link>http://arxiv.org/abs/2408.02866v2</link><description>We present Wideband back-projection diffusion, an end-to-end probabilisticframework for approximating the posterior distribution induced by the inversescattering map from wideband scattering data. This framework leveragesconditional diffusion models coupled with the underlying physics ofwave-propagation and symmetries in the problem, to produce highly accuratereconstructions. The framework introduces a factorization of the score functioninto a physics-based latent representation inspired by the filteredback-propagation formula and a conditional score function conditioned on thislatent representation. These two steps are also constrained to obey symmetriesin the formulation while being amenable to compression by imposing the rankstructure found in the filtered back-projection formula. As a result,empirically, our framework is able to provide sharp reconstructionseffortlessly, even recovering sub-Nyquist features in the multiple-scatteringregime. It has low-sample and computational complexity, its number ofparameters scales sub-linearly with the target resolution, and it has stabletraining dynamics.</description><author>Borong Zhang, Martín Guerra, Qin Li, Leonardo Zepeda-Núñez</author><pubDate>Fri, 09 Aug 2024 13:44:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.02866v2</guid></item><item><title>Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon</title><link>http://arxiv.org/abs/2408.04377v2</link><description>Anomaly detection in time series data is a critical challenge across variousdomains. Traditional methods typically focus on identifying anomalies inimmediate subsequent steps, often underestimating the significance of temporaldynamics such as delay time and horizons of anomalies, which generally requireextensive post-analysis. This paper introduces a novel approach for detectingtime series anomalies called Anomaly Prediction, incorporating temporalinformation directly into the prediction results. We propose a new datasetspecifically designed to evaluate this approach and conduct comprehensiveexperiments using several state-of-the-art time series forecasting methods. Theresults demonstrate the efficacy of our approach in providing timely andaccurate anomaly predictions, setting a new benchmark for future research inthis field.</description><author>Jiang You, Arben Cela, René Natowicz, Jacob Ouanounou, Patrick Siarry</author><pubDate>Fri, 09 Aug 2024 13:44:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.04377v2</guid></item><item><title>Controllable seismic velocity synthesis using generative diffusion models</title><link>http://arxiv.org/abs/2402.06277v2</link><description>Accurate seismic velocity estimations are vital to understanding Earth'ssubsurface structures, assessing natural resources, and evaluating seismichazards. Machine learning-based inversion algorithms have shown promisingperformance in regional (i.e., for exploration) and global velocity estimation,while their effectiveness hinges on access to large and diverse trainingdatasets whose distributions generally cover the target solutions.Additionally, enhancing the precision and reliability of velocity estimationalso requires incorporating prior information, e.g., geological classes, welllogs, and subsurface structures, but current statistical or neuralnetwork-based methods are not flexible enough to handle such multi-modalinformation. To address both challenges, we propose to use conditionalgenerative diffusion models for seismic velocity synthesis, in which we readilyincorporate those priors. This approach enables the generation of seismicvelocities that closely match the expected target distribution, offeringdatasets informed by both expert knowledge and measured data to supporttraining for data-driven geophysical methods. We demonstrate the flexibilityand effectiveness of our method through training diffusion models on theOpenFWI dataset under various conditions, including class labels, well logs,reflectivity images, and the combination of these priors. The performance ofthe approach under out-of-distribution conditions further underscores itsgeneralization ability, showcasing its potential to provide tailored priors forvelocity inverse problems and create specific training datasets for machinelearning-based geophysical applications.</description><author>Fu Wang, Xinquan Huang, Tariq Alkhalifah</author><pubDate>Fri, 09 Aug 2024 13:37:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06277v2</guid></item><item><title>Learning to Generate Parameters of ConvNets for Unseen Image Data</title><link>http://arxiv.org/abs/2310.11862v3</link><description>Typical Convolutional Neural Networks (ConvNets) depend heavily on largeamounts of image data and resort to an iterative optimization algorithm (e.g.,SGD or Adam) to learn network parameters, which makes training very time- andresource-intensive. In this paper, we propose a new training paradigm andformulate the parameter learning of ConvNets into a prediction task: given aConvNet architecture, we observe there exist correlations between imagedatasets and their corresponding optimal network parameters, and explore if wecan learn a hyper-mapping between them to capture the relations, such that wecan directly predict the parameters of the network for an image dataset neverseen during the training phase. To do this, we put forward a new hypernetworkbased model, called PudNet, which intends to learn a mapping between datasetsand their corresponding network parameters, and then predicts parameters forunseen data with only a single forward propagation. Moreover, our modelbenefits from a series of adaptive hyper recurrent units sharing weights tocapture the dependencies of parameters among different network layers.Extensive experiments demonstrate that our proposed method achieves goodefficacy for unseen image datasets on two kinds of settings: Intra-datasetprediction and Inter-dataset prediction. Our PudNet can also well scale up tolarge-scale datasets, e.g., ImageNet-1K. It takes 8967 GPU seconds to trainResNet-18 on the ImageNet-1K using GC from scratch and obtain a top-5 accuracyof 44.65%. However, our PudNet costs only 3.89 GPU seconds to predict thenetwork parameters of ResNet-18 achieving comparable performance (44.92%), morethan 2,300 times faster than the traditional training paradigm.</description><author>Shiye Wang, Kaituo Feng, Changsheng Li, Ye Yuan, Guoren Wang</author><pubDate>Fri, 09 Aug 2024 13:35:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11862v3</guid></item><item><title>Natural Language Interaction with a Household Electricity Knowledge-based Digital Twin</title><link>http://arxiv.org/abs/2406.06566v3</link><description>Domain specific digital twins, representing a digital replica of varioussegments of the smart grid, are foreseen as able to model, simulate, andcontrol the respective segments. At the same time, knowledge-based digitaltwins, coupled with AI, may also empower humans to understand aspects of thesystem through natural language interaction in view of planning and policymaking. This paper is the first to assess and report on the potential ofRetrieval Augmented Generation (RAG) question answers related to householdelectrical energy measurement aspects leveraging a knowledge-based energydigital twin. Relying on the recently published electricity consumptionknowledge graph that actually represents a knowledge-based digital twin, westudy the capabilities of ChatGPT, Gemini and Llama in answering electricityrelated questions. Furthermore, we compare the answers with the ones generatedthrough a RAG techniques that leverages an existing electricity knowledge-baseddigital twin. Our findings illustrate that the RAG approach not only reducesthe incidence of incorrect information typically generated by LLMs but alsosignificantly improves the quality of the output by grounding responses inverifiable data. This paper details our methodology, presents a comparativeanalysis of responses with and without RAG, and discusses the implications ofour findings for future applications of AI in specialized sectors like energydata analysis.</description><author>Carolina Fortuna, Vid Hanžel, Blaž Bertalanič</author><pubDate>Fri, 09 Aug 2024 13:35:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06566v3</guid></item><item><title>A Jailbroken GenAI Model Can Cause Substantial Harm: GenAI-powered Applications are Vulnerable to PromptWares</title><link>http://arxiv.org/abs/2408.05061v1</link><description>In this paper we argue that a jailbroken GenAI model can cause substantialharm to GenAI-powered applications and facilitate PromptWare, a new type ofattack that flips the GenAI model's behavior from serving an application toattacking it. PromptWare exploits user inputs to jailbreak a GenAI model toforce/perform malicious activity within the context of a GenAI-poweredapplication. First, we introduce a naive implementation of PromptWare thatbehaves as malware that targets Plan &amp; Execute architectures (a.k.a., ReAct,function calling). We show that attackers could force a desired execution flowby creating a user input that produces desired outputs given that the logic ofthe GenAI-powered application is known to attackers. We demonstrate theapplication of a DoS attack that triggers the execution of a GenAI-poweredassistant to enter an infinite loop that wastes money and computationalresources on redundant API calls to a GenAI engine, preventing the applicationfrom providing service to a user. Next, we introduce a more sophisticatedimplementation of PromptWare that we name Advanced PromptWare Threat (APwT)that targets GenAI-powered applications whose logic is unknown to attackers. Weshow that attackers could create user input that exploits the GenAI engine'sadvanced AI capabilities to launch a kill chain in inference time consisting ofsix steps intended to escalate privileges, analyze the application's context,identify valuable assets, reason possible malicious activities, decide on oneof them, and execute it. We demonstrate the application of APwT against aGenAI-powered e-commerce chatbot and show that it can trigger the modificationof SQL tables, potentially leading to unauthorized discounts on the items soldto the user.</description><author>Stav Cohen, Ron Bitton, Ben Nassi</author><pubDate>Fri, 09 Aug 2024 13:32:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05061v1</guid></item><item><title>GLEAMS: Bridging the Gap Between Local and Global Explanations</title><link>http://arxiv.org/abs/2408.05060v1</link><description>The explainability of machine learning algorithms is crucial, and numerousmethods have emerged recently. Local, post-hoc methods assign an attributionscore to each feature, indicating its importance for the prediction. However,these methods require recalculating explanations for each example. On the otherside, while there exist global approaches they often produce explanations thatare either overly simplistic and unreliable or excessively complex. To bridgethis gap, we propose GLEAMS, a novel method that partitions the input space andlearns an interpretable model within each sub-region, thereby providing bothfaithful local and global surrogates. We demonstrate GLEAMS' effectiveness onboth synthetic and real-world data, highlighting its desirable properties andhuman-understandable insights.</description><author>Giorgio Visani, Vincenzo Stanzione, Damien Garreau</author><pubDate>Fri, 09 Aug 2024 13:30:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05060v1</guid></item><item><title>Variational Bayesian Phylogenetic Inference with Semi-implicit Branch Length Distributions</title><link>http://arxiv.org/abs/2408.05058v1</link><description>Reconstructing the evolutionary history relating a collection of molecularsequences is the main subject of modern Bayesian phylogenetic inference.However, the commonly used Markov chain Monte Carlo methods can be inefficientdue to the complicated space of phylogenetic trees, especially when the numberof sequences is large. An alternative approach is variational Bayesianphylogenetic inference (VBPI) which transforms the inference problem into anoptimization problem. While effective, the default diagonal lognormalapproximation for the branch lengths of the tree used in VBPI is ofteninsufficient to capture the complexity of the exact posterior. In this work, wepropose a more flexible family of branch length variational posteriors based onsemi-implicit hierarchical distributions using graph neural networks. We showthat this semi-implicit construction emits straightforward permutationequivariant distributions, and therefore can handle the non-Euclidean branchlength space across different tree topologies with ease. To deal with theintractable marginal probability of semi-implicit variational distributions, wedevelop several alternative lower bounds for stochastic optimization. Wedemonstrate the effectiveness of our proposed method over baseline methods onbenchmark data examples, in terms of both marginal likelihood estimation andbranch length posterior approximation.</description><author>Tianyu Xie, Frederick A. Matsen IV, Marc A. Suchard, Cheng Zhang</author><pubDate>Fri, 09 Aug 2024 13:29:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05058v1</guid></item><item><title>SELD-Mamba: Selective State-Space Model for Sound Event Localization and Detection with Source Distance Estimation</title><link>http://arxiv.org/abs/2408.05057v1</link><description>In the Sound Event Localization and Detection (SELD) task, Transformer-basedmodels have demonstrated impressive capabilities. However, the quadraticcomplexity of the Transformer's self-attention mechanism results incomputational inefficiencies. In this paper, we propose a network architecturefor SELD called SELD-Mamba, which utilizes Mamba, a selective state-spacemodel. We adopt the Event-Independent Network V2 (EINV2) as the foundationalframework and replace its Conformer blocks with bidirectional Mamba blocks tocapture a broader range of contextual information while maintainingcomputational efficiency. Additionally, we implement a two-stage trainingmethod, with the first stage focusing on Sound Event Detection (SED) andDirection of Arrival (DoA) estimation losses, and the second stagereintroducing the Source Distance Estimation (SDE) loss. Our experimentalresults on the 2024 DCASE Challenge Task3 dataset demonstrate the effectivenessof the selective state-space model in SELD and highlight the benefits of thetwo-stage training approach in enhancing SELD performance.</description><author>Da Mu, Zhicheng Zhang, Haobo Yue, Zehao Wang, Jin Tang, Jianqin Yin</author><pubDate>Fri, 09 Aug 2024 13:26:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05057v1</guid></item><item><title>Multi-dimensional Parameter Space Exploration for Streamline-specific Tractography</title><link>http://arxiv.org/abs/2408.05056v1</link><description>One of the unspoken challenges of tractography is choosing the rightparameters for a given dataset or bundle. In order to tackle this challenge, weexplore the multi-dimensional parameter space of tractography usingstreamline-specific parameters (SSP). We 1) validate a state-of-the-artprobabilistic tracking method using per-streamline parameters on syntheticdata, and 2) show how we can gain insights into the parameter space by focusingon streamline acceptance using real-world data. We demonstrate the potentialadded value of SSP to the current state of tractography by showing how SSP canbe used to reveal patterns in the parameter space.</description><author>Ruben Vink, Anna Vilanova, Maxime Chamberland</author><pubDate>Fri, 09 Aug 2024 13:25:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05056v1</guid></item><item><title>Graph Neural Networks as Ordering Heuristics for Parallel Graph Coloring</title><link>http://arxiv.org/abs/2408.05054v1</link><description>The graph coloring problem asks for an assignment of the minimum number ofdistinct colors to vertices in an undirected graph with the constraint that nopair of adjacent vertices share the same color. The problem is a thoroughlystudied NP-hard combinatorial problem with several real-world applications. Assuch, a number of greedy heuristics have been suggested that strike a goodbalance between coloring quality, execution time, and also parallelscalability. In this work, we introduce a graph neural network (GNN) basedordering heuristic and demonstrate that it outperforms existing greedy orderingheuristics both on quality and performance. Previous results have demonstratedthat GNNs can produce high-quality colorings but at the expense of excessiverunning time. The current paper is the first that brings the execution timedown to compete with existing greedy heuristics. Our GNN model is trained usingboth supervised and unsupervised techniques. The experimental results show thata 2-layer GNN model can achieve execution times between the largest degreefirst (LF) and smallest degree last (SL) ordering heuristics whileoutperforming both on coloring quality. Increasing the number of layersimproves the coloring quality further, and it is only at four layers that SLbecomes faster than the GNN. Finally, our GNN-based coloring heuristic achievessuperior scaling in the parallel setting compared to both SL and LF.</description><author>Kenneth Langedal, Fredrik Manne</author><pubDate>Fri, 09 Aug 2024 13:21:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05054v1</guid></item><item><title>Integrating Edge Information into Ground Truth for the Segmentation of the Optic Disc and Cup from Fundus Images</title><link>http://arxiv.org/abs/2408.05052v1</link><description>Optic disc and cup segmentation helps in the diagnosis of glaucoma,myocardial infarction, and diabetic retinopathy. Most deep learning methodsdeveloped to perform segmentation tasks are built on top of a U-Net-based modelarchitecture. Nevertheless, U-Net and its variants have a tendency toover-segment/ under-segment the required regions of interest. Since the mostimportant outcome is the value of cup-to-disc ratio and not the segmentedregions themselves, we are more concerned about the boundaries rather than theregions under the boundaries. This makes learning edges important as comparedto learning the regions. In the proposed work, the authors aim to extract bothedges of the optic disc and cup from the ground truth using a Laplacian filter.Next, edges are reconstructed to obtain an edge ground truth in addition to theoptic disc-cup ground truth. Utilizing both ground truths, the authors studyseveral U-Net and its variant architectures with and without optic disc and cupedges as target, along with the optic disc-cup ground truth for segmentation.The authors have used the REFUGE benchmark dataset and the Drishti-GS datasetto perform the study, and the results are tabulated for the dice and theHausdorff distance metrics. In the case of the REFUGE dataset, the optic discmean dice score has improved from 0.7425 to 0.8859 while the mean Hausdorffdistance has reduced from 6.5810 to 3.0540 for the baseline U-Net model.Similarly, the optic cup mean dice score has improved from 0.6970 to 0.8639while the mean Hausdorff distance has reduced from 5.2340 to 2.6323 for thesame model. Similar improvement has been observed for the Drishti-GS dataset aswell. Compared to the baseline U-Net and its variants (i.e) the Attention U-Netand the U-Net++, the models that learn integrated edges along with the opticdisc and cup regions performed well in both validation and testing datasets.</description><author>Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Subin Sahayam, Umarani Jayaraman</author><pubDate>Fri, 09 Aug 2024 13:18:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05052v1</guid></item><item><title>A GNN Model with Adaptive Weights for Session-Based Recommendation Systems</title><link>http://arxiv.org/abs/2408.05051v1</link><description>Session-based recommendation systems aim to model users' interests based ontheir sequential interactions to predict the next item in an ongoing session.In this work, we present a novel approach that can be used in session-basedrecommendations (SBRs). Our goal is to enhance the prediction accuracy of anexisting session-based recommendation model, the SR-GNN model, by introducingan adaptive weighting mechanism applied to the graph neural network (GNN)vectors. This mechanism is designed to incorporate various types of sideinformation obtained through different methods during the study. Items areassigned varying degrees of importance within each session as a result of theweighting mechanism. We hypothesize that this adaptive weighting strategy willcontribute to more accurate predictions and thus improve the overallperformance of SBRs in different scenarios. The adaptive weighting strategy canbe utilized to address the cold start problem in SBRs by dynamically adjustingthe importance of items in each session, thus providing better recommendationsin cold start situations, such as for new users or newly added items. Ourexperimental evaluations on the Dressipi dataset demonstrate the effectivenessof the proposed approach compared to traditional models in enhancing the userexperience and highlighting its potential to optimize the recommendationresults in real-world applications.</description><author>Begüm Özbay, Dr. Resul Tugay, Prof. Dr. Şule Gündüz Öğüdücü</author><pubDate>Fri, 09 Aug 2024 13:13:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05051v1</guid></item><item><title>Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters</title><link>http://arxiv.org/abs/2408.04093v2</link><description>Self-attention is the core mathematical operation of modern transformerarchitectures and is also a significant computational bottleneck due to itsquadratic complexity in the sequence length. In this work, we derive the scalarenergy function whose gradient computes the self-attention block, thuselucidating the theoretical underpinnings of self-attention, providing aBayesian interpretation of the operation and linking it closely withenergy-based models such as Hopfield Networks. Our formulation reveals that thereduction across the sequence axis can be efficiently computed in parallelthrough a tree reduction. Our algorithm, for parallelizing attentioncomputation across multiple GPUs enables cross-device decoding to be performedasymptotically faster (up to 8x faster in our experiments) than alternativeapproaches such as Ring Attention, while also requiring significantly lesscommunication volume and incurring 2x less peak memory. Our code is publiclyavailable here: \url{https://github.com/Zyphra/tree_attention}.</description><author>Vasudev Shyam, Jonathan Pilault, Emily Shepperd, Quentin Anthony, Beren Millidge</author><pubDate>Fri, 09 Aug 2024 13:07:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.04093v2</guid></item><item><title>TetraDiffusion: Tetrahedral Diffusion Models for 3D Shape Generation</title><link>http://arxiv.org/abs/2211.13220v3</link><description>Probabilistic denoising diffusion models (DDMs) have set a new standard for2D image generation. Extending DDMs for 3D content creation is an active fieldof research. Here, we propose TetraDiffusion, a diffusion model that operateson a tetrahedral partitioning of 3D space to enable efficient, high-resolution3D shape generation. Our model introduces operators for convolution andtranspose convolution that act directly on the tetrahedral partition, andseamlessly includes additional attributes such as color. Remarkably,TetraDiffusion enables rapid sampling of detailed 3D objects in nearlyreal-time with unprecedented resolution. It's also adaptable for generating 3Dshapes conditioned on 2D images. Compared to existing 3D mesh diffusiontechniques, our method is up to 200 times faster in inference speed, works onstandard consumer hardware, and delivers superior results.</description><author>Nikolai Kalischek, Torben Peters, Jan D. Wegner, Konrad Schindler</author><pubDate>Fri, 09 Aug 2024 12:57:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.13220v3</guid></item><item><title>Benchmarking Conventional and Learned Video Codecs with a Low-Delay Configuration</title><link>http://arxiv.org/abs/2408.05042v1</link><description>Recent advances in video compression have seen significant coding performanceimprovements with the development of new standards and learning-based videocodecs. However, most of these works focus on application scenarios that allowa certain amount of system delay (e.g., Random Access mode in MPEG codecs),which is not always acceptable for live delivery. This paper conducts acomparative study of state-of-the-art conventional and learned video codingmethods based on a low delay configuration. Specifically, this study includestwo MPEG standard codecs (H.266/VVC VTM and JVET ECM), two AOM codecs (AV1libaom and AVM), and two recent neural video coding models (DCVC-DC andDCVC-FM). To allow a fair and meaningful comparison, the evaluation wasperformed on test sequences defined in the AOM and MPEG common test conditionsin the YCbCr 4:2:0 color space. The evaluation results show that the JVET ECMcodecs offer the best overall coding performance among all codecs tested, witha 16.1% (based on PSNR) average BD-rate saving over AOM AVM, and 11.0% overDCVC-FM. We also observed inconsistent performance with the learned videocodecs, DCVC-DC and DCVC-FM, for test content with large background motions.</description><author>Siyue Teng, Yuxuan Jiang, Ge Gao, Fan Zhang, Thomas Davis, Zoe Liu, David Bull</author><pubDate>Fri, 09 Aug 2024 12:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05042v1</guid></item><item><title>Differentiable Annealed Importance Sampling Minimizes The Symmetrized Kullback-Leibler Divergence Between Initial and Target Distribution</title><link>http://arxiv.org/abs/2405.14840v2</link><description>Differentiable annealed importance sampling (DAIS), proposed by Geffner &amp;Domke (2021) and Zhang et al. (2021), allows optimizing over the initialdistribution of AIS. In this paper, we show that, in the limit of manytransitions, DAIS minimizes the symmetrized Kullback-Leibler divergence betweenthe initial and target distribution. Thus, DAIS can be seen as a form ofvariational inference (VI) as its initial distribution is a parametric fit toan intractable target distribution. We empirically evaluate the usefulness ofthe initial distribution as a variational distribution on synthetic andreal-world data, observing that it often provides more accurate uncertaintyestimates than VI (optimizing the reverse KL divergence), importance weightedVI, and Markovian score climbing (optimizing the forward KL divergence).</description><author>Johannes Zenn, Robert Bamler</author><pubDate>Fri, 09 Aug 2024 12:53:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14840v2</guid></item><item><title>BoFire: Bayesian Optimization Framework Intended for Real Experiments</title><link>http://arxiv.org/abs/2408.05040v1</link><description>Our open-source Python package BoFire combines Bayesian Optimization (BO)with other design of experiments (DoE) strategies focusing on developing andoptimizing new chemistry. Previous BO implementations, for example as theyexist in the literature or software, require substantial adaptation foreffective real-world deployment in chemical industry. BoFire provides a richfeature-set with extensive configurability and realizes our vision offast-tracking research contributions into industrial use via maintainableopen-source software. Owing to quality-of-life features likeJSON-serializability of problem formulations, BoFire enables seamlessintegration of BO into RESTful APIs, a common architecture component for bothself-driving laboratories and human-in-the-loop setups. This paper discussesthe differences between BoFire and other BO implementations and outlines waysthat BO research needs to be adapted for real-world use in a chemistry setting.</description><author>Johannes P. Dürholt, Thomas S. Asche, Johanna Kleinekorte, Gabriel Mancino-Ball, Benjamin Schiller, Simon Sung, Julian Keupp, Aaron Osburg, Toby Boyne, Ruth Misener, Rosona Eldred, Wagner Steuer Costa, Chrysoula Kappatou, Robert M. Lee, Dominik Linzner, David Walz, Niklas Wulkow, Behrang Shafei</author><pubDate>Fri, 09 Aug 2024 12:50:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05040v1</guid></item><item><title>A conformalized learning of a prediction set with applications to medical imaging classification</title><link>http://arxiv.org/abs/2408.05037v1</link><description>Medical imaging classifiers can achieve high predictive accuracy, butquantifying their uncertainty remains an unresolved challenge, which preventstheir deployment in medical clinics. We present an algorithm that can modifyany classifier to produce a prediction set containing the true label with auser-specified probability, such as 90%. We train a network to predict aninstance-based version of the Conformal Prediction threshold. The threshold isthen conformalized to ensure the required coverage. We applied the proposedalgorithm to several standard medical imaging classification datasets. Theexperimental results demonstrate that our method outperforms current approachesin terms of smaller average size of the prediction set while maintaining thedesired coverage.</description><author>Roy Hirsch, Jacob Goldberger</author><pubDate>Fri, 09 Aug 2024 12:49:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05037v1</guid></item><item><title>Evaluating Feature Attribution Methods in the Image Domain</title><link>http://arxiv.org/abs/2202.12270v2</link><description>Feature attribution maps are a popular approach to highlight the mostimportant pixels in an image for a given prediction of a model. Despite arecent growth in popularity and available methods, little attention is given tothe objective evaluation of such attribution maps. Building on previous work inthis domain, we investigate existing metrics and propose new variants ofmetrics for the evaluation of attribution maps. We confirm a recent findingthat different attribution metrics seem to measure different underlyingconcepts of attribution maps, and extend this finding to a larger selection ofattribution metrics. We also find that metric results on one dataset do notnecessarily generalize to other datasets, and methods with desirabletheoretical properties such as DeepSHAP do not necessarily outperformcomputationally cheaper alternatives. Based on these findings, we propose ageneral benchmarking approach to identify the ideal feature attribution methodfor a given use case. Implementations of attribution metrics and ourexperiments are available online.</description><author>Arne Gevaert, Axel-Jan Rousseau, Thijs Becker, Dirk Valkenborg, Tijl De Bie, Yvan Saeys</author><pubDate>Fri, 09 Aug 2024 12:48:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.12270v2</guid></item><item><title>Examining the Behavior of LLM Architectures Within the Framework of Standardized National Exams in Brazil</title><link>http://arxiv.org/abs/2408.05035v1</link><description>The Exame Nacional do Ensino M\'edio (ENEM) is a pivotal test for Brazilianstudents, required for admission to a significant number of universities inBrazil. The test consists of four objective high-school level tests on Math,Humanities, Natural Sciences and Languages, and one writing essay. Students'answers to the test and to the accompanying socioeconomic status questionnaireare made public every year (albeit anonymized) due to transparency policiesfrom the Brazilian Government. In the context of large language models (LLMs),these data lend themselves nicely to comparing different groups of humans withAI, as we can have access to human and machine answer distributions. Weleverage these characteristics of the ENEM dataset and compare GPT-3.5 and 4,and MariTalk, a model trained using Portuguese data, to humans, aiming toascertain how their answers relate to real societal groups and what that mayreveal about the model biases. We divide the human groups by usingsocioeconomic status (SES), and compare their answer distribution with LLMs foreach question and for the essay. We find no significant biases when comparingLLM performance to humans on the multiple-choice Brazilian Portuguese tests, asthe distance between model and human answers is mostly determined by the humanaccuracy. A similar conclusion is found by looking at the generated text as,when analyzing the essays, we observe that human and LLM essays differ in a fewkey factors, one being the choice of words where model essays were easilyseparable from human ones. The texts also differ syntactically, with LLMgenerated essays exhibiting, on average, smaller sentences and less thoughtunits, among other differences. These results suggest that, for BrazilianPortuguese in the ENEM context, LLM outputs represent no group of humans, beingsignificantly different from the answers from Brazilian students across alltests.</description><author>Marcelo Sartori Locatelli, Matheus Prado Miranda, Igor Joaquim da Silva Costa, Matheus Torres Prates, Victor Thomé, Mateus Zaparoli Monteiro, Tomas Lacerda, Adriana Pagano, Eduardo Rios Neto, Wagner Meira Jr., Virgilio Almeida</author><pubDate>Fri, 09 Aug 2024 12:47:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05035v1</guid></item></channel></rss>