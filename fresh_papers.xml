<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 17 Apr 2024 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Nearly Optimal Algorithms for Contextual Dueling Bandits from Adversarial Feedback</title><link>http://arxiv.org/abs/2404.10776v1</link><description>Learning from human feedback plays an important role in aligning generativemodels, such as large language models (LLM). However, the effectiveness of thisapproach can be influenced by adversaries, who may intentionally providemisleading preferences to manipulate the output in an undesirable or harmfuldirection. To tackle this challenge, we study a specific model within thisproblem domain--contextual dueling bandits with adversarial feedback, where thetrue preference label can be flipped by an adversary. We propose an algorithmnamely robust contextual dueling bandit (\algo), which is based onuncertainty-weighted maximum likelihood estimation. Our algorithm achieves an$\tilde O(d\sqrt{T}+dC)$ regret bound, where $T$ is the number of rounds, $d$is the dimension of the context, and $ 0 \le C \le T$ is the total number ofadversarial feedback. We also prove a lower bound to show that our regret boundis nearly optimal, both in scenarios with and without ($C=0$) adversarialfeedback. Additionally, we conduct experiments to evaluate our proposedalgorithm against various types of adversarial feedback. Experimental resultsdemonstrate its superiority over the state-of-the-art dueling bandit algorithmsin the presence of adversarial feedback.</description><author>Qiwei Di, Jiafan He, Quanquan Gu</author><pubDate>Tue, 16 Apr 2024 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10776v1</guid></item><item><title>GROUNDHOG: Grounding Large Language Models to Holistic Segmentation</title><link>http://arxiv.org/abs/2402.16846v2</link><description>Most multimodal large language models (MLLMs) learn language-to-objectgrounding through causal language modeling where grounded objects are capturedby bounding boxes as sequences of location tokens. This paradigm lackspixel-level representations that are important for fine-grained visualunderstanding and diagnosis. In this work, we introduce GROUNDHOG, an MLLMdeveloped by grounding Large Language Models to holistic segmentation.GROUNDHOG incorporates a masked feature extractor and converts extractedfeatures into visual entity tokens for the MLLM backbone, which then connectsgroundable phrases to unified grounding masks by retrieving and merging theentity masks. To train GROUNDHOG, we carefully curated M3G2, a grounded visualinstruction tuning dataset with Multi-Modal Multi-Grained Grounding, byharvesting a collection of segmentation-grounded datasets with richannotations. Our experimental results show that GROUNDHOG achieves superiorperformance on various language grounding tasks without task-specificfine-tuning, and significantly reduces object hallucination. GROUNDHOG alsodemonstrates better grounding towards complex forms of visual input andprovides easy-to-understand diagnosis in failure cases.</description><author>Yichi Zhang, Ziqiao Ma, Xiaofeng Gao, Suhaila Shakiah, Qiaozi Gao, Joyce Chai</author><pubDate>Tue, 16 Apr 2024 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16846v2</guid></item><item><title>COMBO: Compositional World Models for Embodied Multi-Agent Cooperation</title><link>http://arxiv.org/abs/2404.10775v1</link><description>In this paper, we investigate the problem of embodied multi-agentcooperation, where decentralized agents must cooperate given only partialegocentric views of the world. To effectively plan in this setting, in contrastto learning world dynamics in a single-agent scenario, we must simulate worlddynamics conditioned on an arbitrary number of agents' actions given onlypartial egocentric visual observations of the world. To address this issue ofpartial observability, we first train generative models to estimate the overallworld state given partial egocentric observations. To enable accuratesimulation of multiple sets of actions on this world state, we then propose tolearn a compositional world model for multi-agent cooperation by factorizingthe naturally composable joint actions of multiple agents and compositionallygenerating the video. By leveraging this compositional world model, incombination with Vision Language Models to infer the actions of other agents,we can use a tree search procedure to integrate these modules and facilitateonline cooperative planning. To evaluate the efficacy of our methods, we createtwo challenging embodied multi-agent long-horizon cooperation tasks using theThreeDWorld simulator and conduct experiments with 2-4 agents. The results showour compositional world model is effective and the framework enables theembodied agents to cooperate efficiently with different agents across varioustasks and an arbitrary number of agents, showing the promising future of ourproposed framework. More videos can be found athttps://vis-www.cs.umass.edu/combo/.</description><author>Hongxin Zhang, Zeyuan Wang, Qiushi Lyu, Zheyuan Zhang, Sunli Chen, Tianmin Shu, Yilun Du, Chuang Gan</author><pubDate>Tue, 16 Apr 2024 18:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10775v1</guid></item><item><title>MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents</title><link>http://arxiv.org/abs/2404.10774v1</link><description>Recognizing if LLM output can be grounded in evidence is central to manytasks in NLP: retrieval-augmented generation, summarization, document-groundeddialogue, and more. Current approaches to this kind of "fact-checking" arebased on verifying each piece of a model generation against potential evidenceusing an LLM. However, this process can be very computationally expensive,requiring many calls to LLMs to check a single response. In this work, we showhow to build small models that have GPT-4-level performance but for 400x lowercost. We do this by constructing synthetic training data with GPT-4, whichinvolves creating realistic yet challenging instances of factual errors via astructured generation procedure. Training on this data teaches models to checkeach fact in the claim and recognize synthesis of information across sentences.For evaluation, we unify pre-existing datasets into a benchmark LLM-AggreFact,collected from recent work on fact-checking and grounding LLM generations. Ourbest system MiniCheck-FT5 (770M parameters) outperforms all systems ofcomparable size and reaches GPT-4 accuracy. We release LLM-AggreFact, code fordata synthesis, and models.</description><author>Liyan Tang, Philippe Laban, Greg Durrett</author><pubDate>Tue, 16 Apr 2024 18:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10774v1</guid></item><item><title>Gaussian Opacity Fields: Efficient and Compact Surface Reconstruction in Unbounded Scenes</title><link>http://arxiv.org/abs/2404.10772v1</link><description>Recently, 3D Gaussian Splatting (3DGS) has demonstrated impressive novel viewsynthesis results, while allowing the rendering of high-resolution images inreal-time. However, leveraging 3D Gaussians for surface reconstruction posessignificant challenges due to the explicit and disconnected nature of 3DGaussians. In this work, we present Gaussian Opacity Fields (GOF), a novelapproach for efficient, high-quality, and compact surface reconstruction inunbounded scenes. Our GOF is derived from ray-tracing-based volume rendering of3D Gaussians, enabling direct geometry extraction from 3D Gaussians byidentifying its levelset, without resorting to Poisson reconstruction or TSDFfusion as in previous work. We approximate the surface normal of Gaussians asthe normal of the ray-Gaussian intersection plane, enabling the application ofregularization that significantly enhances geometry. Furthermore, we develop anefficient geometry extraction method utilizing marching tetrahedra, where thetetrahedral grids are induced from 3D Gaussians and thus adapt to the scene'scomplexity. Our evaluations reveal that GOF surpasses existing 3DGS-basedmethods in surface reconstruction and novel view synthesis. Further, itcompares favorably to, or even outperforms, neural implicit methods in bothquality and speed.</description><author>Zehao Yu, Torsten Sattler, Andreas Geiger</author><pubDate>Tue, 16 Apr 2024 18:57:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10772v1</guid></item><item><title>Splatter Image: Ultra-Fast Single-View 3D Reconstruction</title><link>http://arxiv.org/abs/2312.13150v2</link><description>We introduce the \method, an ultra-efficient approach for monocular 3D objectreconstruction. Splatter Image is based on Gaussian Splatting, which allowsfast and high-quality reconstruction of 3D scenes from multiple images. Weapply Gaussian Splatting to monocular reconstruction by learning a neuralnetwork that, at test time, performs reconstruction in a feed-forward manner,at 38 FPS. Our main innovation is the surprisingly straightforward design ofthis network, which, using 2D operators, maps the input image to one 3DGaussian per pixel. The resulting set of Gaussians thus has the form an image,the Splatter Image. We further extend the method take several images as inputvia cross-view attention. Owning to the speed of the renderer (588 FPS), we usea single GPU for training while generating entire images at each iteration tooptimize perceptual metrics like LPIPS. On several synthetic, real,multi-category and large-scale benchmark datasets, we achieve better results interms of PSNR, LPIPS, and other metrics while training and evaluating muchfaster than prior works. Code, models, demo and more results are available athttps://szymanowiczs.github.io/splatter-image.</description><author>Stanislaw Szymanowicz, Christian Rupprecht, Andrea Vedaldi</author><pubDate>Tue, 16 Apr 2024 18:56:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13150v2</guid></item><item><title>Hunting imaging biomarkers in pulmonary fibrosis: Benchmarks of the AIIB23 challenge</title><link>http://arxiv.org/abs/2312.13752v2</link><description>Airway-related quantitative imaging biomarkers are crucial for examination,diagnosis, and prognosis in pulmonary diseases. However, the manual delineationof airway trees remains prohibitively time-consuming. While significant effortshave been made towards enhancing airway modelling, current public-availabledatasets concentrate on lung diseases with moderate morphological variations.The intricate honeycombing patterns present in the lung tissues of fibroticlung disease patients exacerbate the challenges, often leading to variousprediction errors. To address this issue, the 'Airway-Informed Quantitative CTImaging Biomarker for Fibrotic Lung Disease 2023' (AIIB23) competition wasorganized in conjunction with the official 2023 International Conference onMedical Image Computing and Computer Assisted Intervention (MICCAI). The airwaystructures were meticulously annotated by three experienced radiologists.Competitors were encouraged to develop automatic airway segmentation modelswith high robustness and generalization abilities, followed by exploring themost correlated QIB of mortality prediction. A training set of 120high-resolution computerised tomography (HRCT) scans were publicly releasedwith expert annotations and mortality status. The online validation setincorporated 52 HRCT scans from patients with fibrotic lung disease and theoffline test set included 140 cases from fibrosis and COVID-19 patients. Theresults have shown that the capacity of extracting airway trees from patientswith fibrotic lung disease could be enhanced by introducing voxel-wise weightedgeneral union loss and continuity loss. In addition to the competitive imagebiomarkers for prognosis, a strong airway-derived biomarker (Hazard ratio&gt;1.5,p&lt;0.0001) was revealed for survival prognostication compared with existingclinical measurements, clinician assessment and AI-based biomarkers.</description><author>Yang Nan, Xiaodan Xing, Shiyi Wang, Zeyu Tang, Federico N Felder, Sheng Zhang, Roberta Eufrasia Ledda, Xiaoliu Ding, Ruiqi Yu, Weiping Liu, Feng Shi, Tianyang Sun, Zehong Cao, Minghui Zhang, Yun Gu, Hanxiao Zhang, Jian Gao, Pingyu Wang, Wen Tang, Pengxin Yu, Han Kang, Junqiang Chen, Xing Lu, Boyu Zhang, Michail Mamalakis, Francesco Prinzi, Gianluca Carlini, Lisa Cuneo, Abhirup Banerjee, Zhaohu Xing, Lei Zhu, Zacharia Mesbah, Dhruv Jain, Tsiry Mayet, Hongyu Yuan, Qing Lyu, Abdul Qayyum, Moona Mazher, Athol Wells, Simon LF Walsh, Guang Yang</author><pubDate>Tue, 16 Apr 2024 18:55:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13752v2</guid></item><item><title>TENG: Time-Evolving Natural Gradient for Solving PDEs with Deep Neural Net</title><link>http://arxiv.org/abs/2404.10771v1</link><description>Partial differential equations (PDEs) are instrumental for modeling dynamicalsystems in science and engineering. The advent of neural networks has initiateda significant shift in tackling these complexities though challenges inaccuracy persist, especially for initial value problems. In this paper, weintroduce the $\textit{Time-Evolving Natural Gradient (TENG)}$, generalizingtime-dependent variational principles and optimization-based time integration,leveraging natural gradient optimization to obtain high accuracy inneural-network-based PDE solutions. Our comprehensive development includesalgorithms like TENG-Euler and its high-order variants, such as TENG-Heun,tailored for enhanced precision and efficiency. TENG's effectiveness is furthervalidated through its performance, surpassing current leading methods andachieving machine precision in step-by-step optimizations across a spectrum ofPDEs, including the heat equation, Allen-Cahn equation, and Burgers' equation.</description><author>Zhuo Chen, Jacob McCarran, Esteban Vizcaino, Marin Soljačić, Di Luo</author><pubDate>Tue, 16 Apr 2024 18:55:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10771v1</guid></item><item><title>Large Language Models as Generalizable Policies for Embodied Tasks</title><link>http://arxiv.org/abs/2310.17722v2</link><description>We show that large language models (LLMs) can be adapted to be generalizablepolicies for embodied visual tasks. Our approach, called Large LAnguage modelReinforcement Learning Policy (LLaRP), adapts a pre-trained frozen LLM to takeas input text instructions and visual egocentric observations and outputactions directly in the environment. Using reinforcement learning, we trainLLaRP to see and act solely through environmental interactions. We show thatLLaRP is robust to complex paraphrasings of task instructions and cangeneralize to new tasks that require novel optimal behavior. In particular, on1,000 unseen tasks it achieves 42% success rate, 1.7x the success rate of othercommon learned baselines or zero-shot applications of LLMs. Finally, to aid thecommunity in studying language conditioned, massively multi-task, embodied AIproblems we release a novel benchmark, Language Rearrangement, consisting of150,000 training and 1,000 testing tasks for language-conditionedrearrangement. Video examples of LLaRP in unseen Language Rearrangementinstructions are at https://llm-rl.github.io.</description><author>Andrew Szot, Max Schwarzer, Harsh Agrawal, Bogdan Mazoure, Walter Talbott, Katherine Metcalf, Natalie Mackraz, Devon Hjelm, Alexander Toshev</author><pubDate>Tue, 16 Apr 2024 18:54:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17722v2</guid></item><item><title>Finite-dimensional approximations of push-forwards on locally analytic functionals and truncation of least-squares polynomials</title><link>http://arxiv.org/abs/2404.10769v1</link><description>This paper introduces a theoretical framework for investigating analytic mapsfrom finite discrete data, elucidating mathematical machinery underlying thepolynomial approximation with least-squares in multivariate situations. Ourapproach is to consider the push-forward on the space of locally analyticfunctionals, instead of directly handling the analytic map itself. We establisha methodology enabling appropriate finite-dimensional approximation of thepush-forward from finite discrete data, through the theory of theFourier--Borel transform and the Fock space. Moreover, we prove a rigorousconvergence result with a convergence rate. As an application, we prove that itis not the least-squares polynomial, but the polynomial obtained by truncatingits higher-degree terms, that approximates analytic functions and furtherallows for approximation beyond the support of the data distribution. Oneadvantage of our theory is that it enables us to apply linear algebraicoperations to the finite-dimensional approximation of the push-forward.Utilizing this, we prove the convergence of a method for approximating ananalytic vector field from finite data of the flow map of an ordinarydifferential equation.</description><author>Isao Ishikawa</author><pubDate>Tue, 16 Apr 2024 18:53:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10769v1</guid></item><item><title>When can transformers reason with abstract symbols?</title><link>http://arxiv.org/abs/2310.09753v2</link><description>We investigate the capabilities of transformer models on relational reasoningtasks. In these tasks, models are trained on a set of strings encoding abstractrelations, and are then tested out-of-distribution on data that containssymbols that did not appear in the training dataset. We prove that for anyrelational reasoning task in a large family of tasks, transformers learn theabstract relations and generalize to the test set when trained by gradientdescent on sufficiently large quantities of training data. This is in contrastto classical fully-connected networks, which we prove fail to learn to reason.Our results inspire modifications of the transformer architecture that add onlytwo trainable parameters per head, and that we empirically demonstrate improvedata efficiency for learning to reason.</description><author>Enric Boix-Adsera, Omid Saremi, Emmanuel Abbe, Samy Bengio, Etai Littwin, Joshua Susskind</author><pubDate>Tue, 16 Apr 2024 18:53:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09753v2</guid></item><item><title>RapidVol: Rapid Reconstruction of 3D Ultrasound Volumes from Sensorless 2D Scans</title><link>http://arxiv.org/abs/2404.10766v1</link><description>Two-dimensional (2D) freehand ultrasonography is one of the most commonlyused medical imaging modalities, particularly in obstetrics and gynaecology.However, it only captures 2D cross-sectional views of inherently 3D anatomies,losing valuable contextual information. As an alternative to requiring costlyand complex 3D ultrasound scanners, 3D volumes can be constructed from 2D scansusing machine learning. However this usually requires long computational time.Here, we propose RapidVol: a neural representation framework to speed upslice-to-volume ultrasound reconstruction. We use tensor-rank decomposition, todecompose the typical 3D volume into sets of tri-planes, and store thoseinstead, as well as a small neural network. A set of 2D ultrasound scans, withtheir ground truth (or estimated) 3D position and orientation (pose) is allthat is required to form a complete 3D reconstruction. Reconstructions areformed from real fetal brain scans, and then evaluated by requesting novelcross-sectional views. When compared to prior approaches based on fullyimplicit representation (e.g. neural radiance fields), our method is over 3xquicker, 46% more accurate, and if given inaccurate poses is more robust.Further speed-up is also possible by reconstructing from a structural priorrather than from scratch.</description><author>Mark C. Eid, Pak-Hei Yeung, Madeleine K. Wyburd, João F. Henriques, Ana I. L. Namburete</author><pubDate>Tue, 16 Apr 2024 18:50:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10766v1</guid></item><item><title>RefFusion: Reference Adapted Diffusion Models for 3D Scene Inpainting</title><link>http://arxiv.org/abs/2404.10765v1</link><description>Neural reconstruction approaches are rapidly emerging as the preferredrepresentation for 3D scenes, but their limited editability is still posing achallenge. In this work, we propose an approach for 3D scene inpainting -- thetask of coherently replacing parts of the reconstructed scene with desiredcontent. Scene inpainting is an inherently ill-posed task as there exist manysolutions that plausibly replace the missing content. A good inpainting methodshould therefore not only enable high-quality synthesis but also a high degreeof control. Based on this observation, we focus on enabling explicit controlover the inpainted content and leverage a reference image as an efficient meansto achieve this goal. Specifically, we introduce RefFusion, a novel 3Dinpainting method based on a multi-scale personalization of an image inpaintingdiffusion model to the given reference view. The personalization effectivelyadapts the prior distribution to the target scene, resulting in a lowervariance of score distillation objective and hence significantly sharperdetails. Our framework achieves state-of-the-art results for object removalwhile maintaining high controllability. We further demonstrate the generalityof our formulation on other downstream tasks such as object insertion, sceneoutpainting, and sparse view reconstruction.</description><author>Ashkan Mirzaei, Riccardo De Lutio, Seung Wook Kim, David Acuna, Jonathan Kelly, Sanja Fidler, Igor Gilitschenski, Zan Gojcic</author><pubDate>Tue, 16 Apr 2024 18:50:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10765v1</guid></item><item><title>Scalable Bayesian inference for the generalized linear mixed model</title><link>http://arxiv.org/abs/2403.03007v2</link><description>The generalized linear mixed model (GLMM) is a popular statistical approachfor handling correlated data, and is used extensively in applications areaswhere big data is common, including biomedical data settings. The focus of thispaper is scalable statistical inference for the GLMM, where we definestatistical inference as: (i) estimation of population parameters, and (ii)evaluation of scientific hypotheses in the presence of uncertainty. Artificialintelligence (AI) learning algorithms excel at scalable statistical estimation,but rarely include uncertainty quantification. In contrast, Bayesian inferenceprovides full statistical inference, since uncertainty quantification resultsautomatically from the posterior distribution. Unfortunately, Bayesianinference algorithms, including Markov Chain Monte Carlo (MCMC), becomecomputationally intractable in big data settings. In this paper, we introduce astatistical inference algorithm at the intersection of AI and Bayesianinference, that leverages the scalability of modern AI algorithms withguaranteed uncertainty quantification that accompanies Bayesian inference. Ouralgorithm is an extension of stochastic gradient MCMC with novel contributionsthat address the treatment of correlated data (i.e., intractable marginallikelihood) and proper posterior variance estimation. Through theoretical andempirical results we establish our algorithm's statistical inferenceproperties, and apply the method in a large electronic health records database.</description><author>Samuel I. Berchuck, Felipe A. Medeiros, Sayan Mukherjee, Andrea Agazzi</author><pubDate>Tue, 16 Apr 2024 18:47:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.03007v2</guid></item><item><title>Confidential Federated Computations</title><link>http://arxiv.org/abs/2404.10764v1</link><description>Federated Learning and Analytics (FLA) have seen widespread adoption bytechnology platforms for processing sensitive on-device data. However, basicFLA systems have privacy limitations: they do not necessarily requireanonymization mechanisms like differential privacy (DP), and provide limitedprotections against a potentially malicious service provider. Adding DP to abasic FLA system currently requires either adding excessive noise to eachdevice's updates, or assuming an honest service provider that correctlyimplements the mechanism and only uses the privatized outputs. Securemultiparty computation (SMPC) -based oblivious aggregations can limit theservice provider's access to individual user updates and improve DP tradeoffs,but the tradeoffs are still suboptimal, and they suffer from scalabilitychallenges and susceptibility to Sybil attacks. This paper introduces a novelsystem architecture that leverages trusted execution environments (TEEs) andopen-sourcing to both ensure confidentiality of server-side computations andprovide externally verifiable privacy properties, bolstering the robustness andtrustworthiness of private federated computations.</description><author>Hubert Eichner, Daniel Ramage, Kallista Bonawitz, Dzmitry Huba, Tiziano Santoro, Brett McLarnon, Timon Van Overveldt, Nova Fallen, Peter Kairouz, Albert Cheu, Katharine Daly, Adria Gascon, Marco Gruteser, Brendan McMahan</author><pubDate>Tue, 16 Apr 2024 18:47:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10764v1</guid></item><item><title>LaDiC: Are Diffusion Models Really Inferior to Autoregressive Counterparts for Image-to-Text Generation?</title><link>http://arxiv.org/abs/2404.10763v1</link><description>Diffusion models have exhibited remarkable capabilities in text-to-imagegeneration. However, their performance in image-to-text generation,specifically image captioning, has lagged behind Auto-Regressive (AR) models,casting doubt on their applicability for such tasks. In this work, we revisitdiffusion models, highlighting their capacity for holistic context modeling andparallel decoding. With these benefits, diffusion models can alleviate theinherent limitations of AR methods, including their slow inference speed, errorpropagation, and unidirectional constraints. Furthermore, we identify the priorunderperformance of diffusion models stemming from the absence of an effectivelatent space for image-text alignment, and the discrepancy between continuousdiffusion processes and discrete textual data. In response, we introduce anovel architecture, LaDiC, which utilizes a split BERT to create a dedicatedlatent space for captions and integrates a regularization module to managevarying text lengths. Our framework also includes a diffuser for semanticimage-to-text conversion and a Back&amp;Refine technique to enhance tokeninteractivity during inference. LaDiC achieves state-of-the-art performance fordiffusion-based methods on the MS COCO dataset with 38.2 BLEU@4 and 126.2CIDEr, demonstrating exceptional performance without pre-training or ancillarymodules. This indicates strong competitiveness with AR models, revealing thepreviously untapped potential of diffusion models in image-to-text generation.</description><author>Yuchi Wang, Shuhuai Ren, Rundong Gao, Linli Yao, Qingyan Guo, Kaikai An, Jianhong Bai, Xu Sun</author><pubDate>Tue, 16 Apr 2024 18:47:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10763v1</guid></item><item><title>TorchSurv: A Lightweight Package for Deep Survival Analysis</title><link>http://arxiv.org/abs/2404.10761v1</link><description>TorchSurv is a Python package that serves as a companion tool to perform deepsurvival modeling within the PyTorch environment. Unlike existing librariesthat impose specific parametric forms, TorchSurv enables the use of customPyTorch-based deep survival mod- els. With its lightweight design, minimalinput requirements, full PyTorch backend, and freedom from restrictive survivalmodel parameterizations, TorchSurv facilitates efficient deep survival modelimplementation and is particularly beneficial for high-dimensional and complexinput data scenarios</description><author>Melodie Monod, Peter Krusche, Qian Cao, Berkman Sahiner, Nicholas Petrick, David Ohlssen, Thibaud Coroller</author><pubDate>Tue, 16 Apr 2024 18:41:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10761v1</guid></item><item><title>Learning Feature Inversion for Multi-class Anomaly Detection under General-purpose COCO-AD Benchmark</title><link>http://arxiv.org/abs/2404.10760v1</link><description>Anomaly detection (AD) is often focused on detecting anomaly areas forindustrial quality inspection and medical lesion examination. However, due tothe specific scenario targets, the data scale for AD is relatively small, andevaluation metrics are still deficient compared to classic vision tasks, suchas object detection and semantic segmentation. To fill these gaps, this workfirst constructs a large-scale and general-purpose COCO-AD dataset by extendingCOCO to the AD field. This enables fair evaluation and sustainable developmentfor different methods on this challenging benchmark. Moreover, current metricssuch as AU-ROC have nearly reached saturation on simple datasets, whichprevents a comprehensive evaluation of different methods. Inspired by themetrics in the segmentation field, we further propose several more practicalthreshold-dependent AD-specific metrics, ie, m$F_1$$^{.2}_{.8}$,mAcc$^{.2}_{.8}$, mIoU$^{.2}_{.8}$, and mIoU-max. Motivated by GAN inversion'shigh-quality reconstruction capability, we propose a simple but more powerfulInvAD framework to achieve high-quality feature reconstruction. Our methodimproves the effectiveness of reconstruction-based methods on popular MVTec AD,VisA, and our newly proposed COCO-AD datasets under a multi-class unsupervisedsetting, where only a single detection model is trained to detect anomaliesfrom different classes. Extensive ablation experiments have demonstrated theeffectiveness of each component of our InvAD. Full codes and models areavailable at https://github.com/zhangzjn/ader.</description><author>Jiangning Zhang, Chengjie Wang, Xiangtai Li, Guanzhong Tian, Zhucun Xue, Yong Liu, Guansong Pang, Dacheng Tao</author><pubDate>Tue, 16 Apr 2024 18:38:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10760v1</guid></item><item><title>AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models</title><link>http://arxiv.org/abs/2403.13269v3</link><description>We present a novel Parameter-Efficient Fine-Tuning (PEFT) method, dubbed asAdaptive Freezing of Low Rank Adaptation (AFLoRA). Specifically, for eachpre-trained frozen weight tensor, we add a parallel path of trainable low-rankmatrices, namely a down-projection and an up-projection matrix, each of whichis followed by a feature transformation vector. Based on a novel freezingscore, we the incrementally freeze these projection matrices during fine-tuningto reduce the computation and alleviate over-fitting. Our experimental resultsdemonstrate that we can achieve state-of-the-art performance with an averageimprovement of up to $0.85\%$ as evaluated on GLUE benchmark while yeilding upto $9.5\times$ fewer average trainable parameters. While compared in terms ofruntime, AFLoRA can yield up to $1.86\times$ improvement as opposed to similarPEFT alternatives. Besides the practical utility of our approach, we provideinsights on the trainability requirements of LoRA paths at different modulesand the freezing schedule for the different projection matrices. Code will bereleased.</description><author>Zeyu Liu, Souvik Kundu, Anni Li, Junrui Wan, Lianghao Jiang, Peter Anthony Beerel</author><pubDate>Tue, 16 Apr 2024 18:37:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13269v3</guid></item><item><title>Dataset Reset Policy Optimization for RLHF</title><link>http://arxiv.org/abs/2404.08495v3</link><description>Reinforcement Learning (RL) from Human Preference-based feedback is a popularparadigm for fine-tuning generative models, which has produced impressivemodels such as GPT-4 and Claude3 Opus. This framework often consists of twosteps: learning a reward model from an offline preference dataset followed byrunning online RL to optimize the learned reward model. In this work,leveraging the idea of reset, we propose a new RLHF algorithm with provableguarantees. Motivated by the fact that offline preference dataset providesinformative states (i.e., data that is preferred by the labelers), our newalgorithm, Dataset Reset Policy Optimization (DR-PO), integrates the existingoffline preference dataset into the online policy training procedure viadataset reset: it directly resets the policy optimizer to the states in theoffline dataset, instead of always starting from the initial statedistribution. In theory, we show that DR-PO learns to perform at least as goodas any policy that is covered by the offline dataset under general functionapproximation with finite sample complexity. In experiments, we demonstratethat on both the TL;DR summarization and the Anthropic Helpful Harmful (HH)dataset, the generation from DR-PO is better than that from Proximal PolicyOptimization (PPO) and Direction Preference Optimization (DPO), under themetric of GPT4 win-rate. Code for this work can be found athttps://github.com/Cornell-RL/drpo.</description><author>Jonathan D. Chang, Wenhao Zhan, Owen Oertell, Kianté Brantley, Dipendra Misra, Jason D. Lee, Wen Sun</author><pubDate>Tue, 16 Apr 2024 18:36:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.08495v3</guid></item><item><title>Laplace-HDC: Understanding the geometry of binary hyperdimensional computing</title><link>http://arxiv.org/abs/2404.10759v1</link><description>This paper studies the geometry of binary hyperdimensional computing (HDC), acomputational scheme in which data are encoded using high-dimensional binaryvectors. We establish a result about the similarity structure induced by theHDC binding operator and show that the Laplace kernel naturally arises in thissetting, motivating our new encoding method Laplace-HDC, which improves uponprevious methods. We describe how our results indicate limitations of binaryHDC in encoding spatial information from images and discuss potentialsolutions, including using Haar convolutional features and the definition of atranslation-equivariant HDC encoding. Several numerical experimentshighlighting the improved accuracy of Laplace-HDC in contrast to alternativemethods are presented. We also numerically study other aspects of the proposedframework such as robustness and the underlying translation-equivariantencoding.</description><author>Saeid Pourmand, Wyatt D. Whiting, Alireza Aghasi, Nicholas F. Marshall</author><pubDate>Tue, 16 Apr 2024 18:36:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10759v1</guid></item><item><title>Watch Your Step: Optimal Retrieval for Continual Learning at Scale</title><link>http://arxiv.org/abs/2404.10758v1</link><description>One of the most widely used approaches in continual learning is referred toas replay. Replay methods support interleaved learning by storing pastexperiences in a replay buffer. Although there are methods for selectivelyconstructing the buffer and reprocessing its contents, there is limitedexploration of the problem of selectively retrieving samples from the buffer.Current solutions have been tested in limited settings and, more importantly,in isolation. Existing work has also not explored the impact of duplicatereplays on performance. In this work, we propose a framework for evaluatingselective retrieval strategies, categorized by simple, independent class- andsample-selective primitives. We evaluated several combinations of existingstrategies for selective retrieval and present their performances. Furthermore,we propose a set of strategies to prevent duplicate replays and explore whethernew samples with low loss values can be learned without replay. In an effort tomatch our problem setting to a realistic continual learning pipeline, werestrict our experiments to a setting involving a large, pre-trained, openvocabulary object detection model, which is fully fine-tuned on a sequence of15 datasets.</description><author>Truman Hickok, Dhireesha Kudithipudi</author><pubDate>Tue, 16 Apr 2024 18:35:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10758v1</guid></item><item><title>Deep Learning and LLM-based Methods Applied to Stellar Lightcurve Classification</title><link>http://arxiv.org/abs/2404.10757v1</link><description>Light curves serve as a valuable source of information on stellar formationand evolution. With the rapid advancement of machine learning techniques, itcan be effectively processed to extract astronomical patterns and information.In this study, we present a comprehensive evaluation of deep-learning and largelanguage model (LLM) based models for the automatic classification of variablestar light curves, based on large datasets from the Kepler and K2 missions.Special emphasis is placed on Cepheids, RR Lyrae, and eclipsing binaries,examining the influence of observational cadence and phase distribution onclassification precision. Employing AutoDL optimization, we achieve strikingperformance with the 1D-Convolution+BiLSTM architecture and the SwinTransformer, hitting accuracies of 94\% and 99\% correspondingly, with thelatter demonstrating a notable 83\% accuracy in discerning the elusive Type IICepheids-comprising merely 0.02\% of the total dataset.We unveil StarWhisperLightCurve (LC), an innovative Series comprising three LLM-based models: LLM,multimodal large language model (MLLM), and Large Audio Language Model (LALM).Each model is fine-tuned with strategic prompt engineering and customizedtraining methods to explore the emergent abilities of these models forastronomical data. Remarkably, StarWhisper LC Series exhibit high accuraciesaround 90\%, significantly reducing the need for explicit feature engineering,thereby paving the way for streamlined parallel data processing and theprogression of multifaceted multimodal models in astronomical applications. Thestudy furnishes two detailed catalogs illustrating the impacts of phase andsampling intervals on deep learning classification accuracy, showing that asubstantial decrease of up to 14\% in observation duration and 21\% in samplingpoints can be realized without compromising accuracy by more than 10\%.</description><author>Yu-Yang Li, Yu Bai, Cunshi Wang, Mengwei Qu, Ziteng Lu, Roberto Soria, Jifeng Liu</author><pubDate>Tue, 16 Apr 2024 18:35:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10757v1</guid></item><item><title>Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing</title><link>http://arxiv.org/abs/2403.07175v2</link><description>Recent work using Rank-One Model Editing (ROME), a popular model editingmethod, has shown that there are certain facts that the algorithm is unable toedit without breaking the model. Such edits have previously been calleddisabling edits. These disabling edits cause immediate model collapse andlimits the use of ROME for sequential editing. In this paper, we show thatdisabling edits are an artifact of irregularities in the implementation ofROME. With this paper, we provide a more stable implementation ROME, which wecall r-ROME and show that model collapse is no longer observed when makinglarge scale sequential edits with r-ROME, while further improvinggeneralization and locality of model editing compared to the originalimplementation of ROME. We also provide a detailed mathematical explanation ofthe reason behind disabling edits.</description><author>Akshat Gupta, Sidharth Baskaran, Gopala Anumanchipalli</author><pubDate>Tue, 16 Apr 2024 18:32:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.07175v2</guid></item><item><title>Privacy-Constrained Policies via Mutual Information Regularized Policy Gradients</title><link>http://arxiv.org/abs/2012.15019v3</link><description>As reinforcement learning techniques are increasingly applied to real-worlddecision problems, attention has turned to how these algorithms use potentiallysensitive information. We consider the task of training a policy that maximizesreward while minimizing disclosure of certain sensitive state variables throughthe actions. We give examples of how this setting covers real-world problems inprivacy for sequential decision-making. We solve this problem in the policygradients framework by introducing a regularizer based on the mutualinformation (MI) between the sensitive state and the actions. We develop amodel-based stochastic gradient estimator for optimization ofprivacy-constrained policies. We also discuss an alternative MI regularizerthat serves as an upper bound to our main MI regularizer and can be optimizedin a model-free setting, and a powerful direct estimator that can be used in anenvironment with differentiable dynamics. We contrast previous work indifferentially-private RL to our mutual-information formulation of informationdisclosure. Experimental results show that our training method results inpolicies that hide the sensitive state, even in challenging high-dimensionaltasks.</description><author>Chris Cundy, Rishi Desai, Stefano Ermon</author><pubDate>Tue, 16 Apr 2024 18:27:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2012.15019v3</guid></item><item><title>RetICL: Sequential Retrieval of In-Context Examples with Reinforcement Learning</title><link>http://arxiv.org/abs/2305.14502v2</link><description>Recent developments in large pre-trained language models have enabledunprecedented performance on a variety of downstream tasks. Achieving bestperformance with these models often leverages in-context learning, where amodel performs a (possibly new) task given one or more examples. However,recent work has shown that the choice of examples can have a large impact ontask performance and that finding an optimal set of examples is non-trivial.While there are many existing methods for selecting in-context examples, theygenerally score examples independently, ignoring the dependency between themand the order in which they are provided to the model. In this work, we proposeRetrieval for In-Context Learning (RetICL), a learnable method for modeling andoptimally selecting examples sequentially for in-context learning. We frame theproblem of sequential example selection as a Markov decision process and trainan example retriever using reinforcement learning. We evaluate RetICL on mathword problem solving and scientific question answering tasks and show that itconsistently outperforms or matches heuristic and learnable baselines. We alsouse case studies to show that RetICL implicitly learns representations ofproblem solving strategies.</description><author>Alexander Scarlatos, Andrew Lan</author><pubDate>Tue, 16 Apr 2024 18:25:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14502v2</guid></item><item><title>Interpolation and differentiation of alchemical degrees of freedom in machine learning interatomic potentials</title><link>http://arxiv.org/abs/2404.10746v1</link><description>Machine learning interatomic potentials (MLIPs) have become a workhorse ofmodern atomistic simulations, and recently published universal MLIPs,pre-trained on large datasets, have demonstrated remarkable accuracy andgeneralizability. However, the computational cost of MLIPs limits theirapplicability to chemically disordered systems requiring large simulation cellsor to sample-intensive statistical methods. Here, we report the use ofcontinuous and differentiable alchemical degrees of freedom in atomisticmaterials simulations, exploiting the fact that graph neural network MLIPsrepresent discrete elements as real-valued tensors. The proposed methodintroduces alchemical atoms with corresponding weights into the input graph,alongside modifications to the message-passing and readout mechanisms of MLIPs,and allows smooth interpolation between the compositional states of materials.The end-to-end differentiability of MLIPs enables efficient calculation of thegradient of energy with respect to the compositional weights. Leveraging thesegradients, we propose methodologies for optimizing the composition of solidsolutions towards target macroscopic properties and conducting alchemical freeenergy simulations to quantify the free energy of vacancy formation andcomposition changes. The approach offers an avenue for extending thecapabilities of universal MLIPs in the modeling of compositional disorder andcharacterizing the phase stabilities of complex materials systems.</description><author>Juno Nam, Rafael Gómez-Bombarelli</author><pubDate>Tue, 16 Apr 2024 18:24:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10746v1</guid></item><item><title>Settling Constant Regrets in Linear Markov Decision Processes</title><link>http://arxiv.org/abs/2404.10745v1</link><description>We study the constant regret guarantees in reinforcement learning (RL). Ourobjective is to design an algorithm that incurs only finite regret overinfinite episodes with high probability. We introduce an algorithm,Cert-LSVI-UCB, for misspecified linear Markov decision processes (MDPs) whereboth the transition kernel and the reward function can be approximated by somelinear function up to misspecification level $\zeta$. At the core ofCert-LSVI-UCB is an innovative certified estimator, which facilitates afine-grained concentration analysis for multi-phase value-targeted regression,enabling us to establish an instance-dependent regret bound that is constantw.r.t. the number of episodes. Specifically, we demonstrate that for an MDPcharacterized by a minimal suboptimality gap $\Delta$, Cert-LSVI-UCB has acumulative regret of $\tilde{\mathcal{O}}(d^3H^5/\Delta)$ with highprobability, provided that the misspecification level $\zeta$ is below$\tilde{\mathcal{O}}(\Delta / (\sqrt{d}H^2))$. Remarkably, this regret boundremains constant relative to the number of episodes $K$. To the best of ourknowledge, Cert-LSVI-UCB is the first algorithm to achieve a constant,instance-dependent, high-probability regret bound in RL with linear functionapproximation for infinite runs without relying on prior distributionassumptions. This not only highlights the robustness of Cert-LSVI-UCB to modelmisspecification but also introduces novel algorithmic designs and analyticaltechniques of independent interest.</description><author>Weitong Zhang, Zhiyuan Fan, Jiafan He, Quanquan Gu</author><pubDate>Tue, 16 Apr 2024 18:23:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10745v1</guid></item><item><title>Born With a Silver Spoon? Investigating Socioeconomic Bias in Large Language Models</title><link>http://arxiv.org/abs/2403.14633v3</link><description>Socioeconomic bias in society exacerbates disparities, influencing access toopportunities and resources based on individuals' economic and socialbackgrounds. This pervasive issue perpetuates systemic inequalities, hinderingthe pursuit of inclusive progress as a society. In this paper, we investigatethe presence of socioeconomic bias, if any, in large language models. To thisend, we introduce a novel dataset SilverSpoon, consisting of 3000 samples thatillustrate hypothetical scenarios that involve underprivileged peopleperforming ethically ambiguous actions due to their circumstances, and askwhether the action is ethically justified. Further, this dataset has adual-labeling scheme and has been annotated by people belonging to both ends ofthe socioeconomic spectrum. Using SilverSpoon, we evaluate the degree ofsocioeconomic bias expressed in large language models and the variation of thisdegree as a function of model size. We also perform qualitative analysis toanalyze the nature of this bias. Our analysis reveals that while humansdisagree on which situations require empathy toward the underprivileged, mostlarge language models are unable to empathize with the socioeconomicallyunderprivileged regardless of the situation. To foster further research in thisdomain, we make SilverSpoon and our evaluation harness publicly available.</description><author>Smriti Singh, Shuvam Keshari, Vinija Jain, Aman Chadha</author><pubDate>Tue, 16 Apr 2024 18:14:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14633v3</guid></item><item><title>N-Agent Ad Hoc Teamwork</title><link>http://arxiv.org/abs/2404.10740v1</link><description>Current approaches to learning cooperative behaviors in multi-agent settingsassume relatively restrictive settings. In standard fully cooperativemulti-agent reinforcement learning, the learning algorithm controls\textit{all} agents in the scenario, while in ad hoc teamwork, the learningalgorithm usually assumes control over only a $\textit{single}$ agent in thescenario. However, many cooperative settings in the real world are much lessrestrictive. For example, in an autonomous driving scenario, a company mighttrain its cars with the same learning algorithm, yet once on the road, thesecars must cooperate with cars from another company. Towards generalizing theclass of scenarios that cooperative learning methods can address, we introduce$N$-agent ad hoc teamwork, in which a set of autonomous agents must interactand cooperate with dynamically varying numbers and types of teammates atevaluation time. This paper formalizes the problem, and proposes the$\textit{Policy Optimization with Agent Modelling}$ (POAM) algorithm. POAM is apolicy gradient, multi-agent reinforcement learning approach to the NAHTproblem, that enables adaptation to diverse teammate behaviors by learningrepresentations of teammate behaviors. Empirical evaluation on StarCraft IItasks shows that POAM improves cooperative task returns compared to baselineapproaches, and enables out-of-distribution generalization to unseen teammates.</description><author>Caroline Wang, Arrasy Rahman, Ishan Durugkar, Elad Liebman, Peter Stone</author><pubDate>Tue, 16 Apr 2024 18:13:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10740v1</guid></item><item><title>Gaussian process learning of nonlinear dynamics</title><link>http://arxiv.org/abs/2312.12193v2</link><description>One of the pivotal tasks in scientific machine learning is to representunderlying dynamical systems from time series data. Many methods for suchdynamics learning explicitly require the derivatives of state data, which arenot directly available and can be approximated conventionally by finitedifferences. However, the discrete approximations of time derivatives mayresult in poor estimations when state data are scarce and/or corrupted bynoise, thus compromising the predictiveness of the learned dynamical models. Toovercome this technical hurdle, we propose a new method that learns nonlineardynamics through a Bayesian inference of characterizing model parameters. Thismethod leverages a Gaussian process representation of states, and constructs alikelihood function using the correlation between state data and theirderivatives, yet prevents explicit evaluations of time derivatives. Through aBayesian scheme, a probabilistic estimate of the model parameters is given bythe posterior distribution, and thus a quantification is facilitated foruncertainties from noisy state data and the learning process. Specifically, wewill discuss the applicability of the proposed method to several typicalscenarios for dynamical systems: identification and estimation with an affineparametrization, nonlinear parametric approximation without prior knowledge,and general parameter estimation for a given dynamical system.</description><author>Dongwei Ye, Mengwu Guo</author><pubDate>Tue, 16 Apr 2024 18:06:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12193v2</guid></item><item><title>Bootstrapping Linear Models for Fast Online Adaptation in Human-Agent Collaboration</title><link>http://arxiv.org/abs/2404.10733v1</link><description>Agents that assist people need to have well-initialized policies that canadapt quickly to align with their partners' reward functions. Initializingpolicies to maximize performance with unknown partners can be achieved bybootstrapping nonlinear models using imitation learning over large, offlinedatasets. Such policies can require prohibitive computation to fine-tunein-situ and therefore may miss critical run-time information about a partner'sreward function as expressed through their immediate behavior. In contrast,online logistic regression using low-capacity models performs rapid inferenceand fine-tuning updates and thus can make effective use of immediate in-taskbehavior for reward function alignment. However, these low-capacity modelscannot be bootstrapped as effectively by offline datasets and thus have poorinitializations. We propose BLR-HAC, Bootstrapped Logistic Regression for HumanAgent Collaboration, which bootstraps large nonlinear models to learn theparameters of a low-capacity model which then uses online logistic regressionfor updates during collaboration. We test BLR-HAC in a simulated surfacerearrangement task and demonstrate that it achieves higher zero-shot accuracythan shallow methods and takes far less computation to adapt online while stillachieving similar performance to fine-tuned, large nonlinear models. For code,please see our project page https://sites.google.com/view/blr-hac.</description><author>Benjamin A Newman, Chris Paxton, Kris Kitani, Henny Admoni</author><pubDate>Tue, 16 Apr 2024 18:05:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10733v1</guid></item><item><title>What is Meant by AGI? On the Definition of Artificial General Intelligence</title><link>http://arxiv.org/abs/2404.10731v1</link><description>This paper aims to establish a consensus on AGI's definition. Generalintelligence refers to the adaptation to open environments according to certainprinciples using limited resources. It emphasizes that adaptation or learningis an indispensable property of intelligence, and places the controversial partwithin the principles of intelligence, which can be described from differentperspectives.</description><author>Bowen Xu</author><pubDate>Tue, 16 Apr 2024 18:03:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10731v1</guid></item><item><title>Insight Gained from Migrating a Machine Learning Model to Intelligence Processing Units</title><link>http://arxiv.org/abs/2404.10730v1</link><description>The discoveries in this paper show that Intelligence Processing Units (IPUs)offer a viable accelerator alternative to GPUs for machine learning (ML)applications within the fields of materials science and battery research. Weinvestigate the process of migrating a model from GPU to IPU and exploreseveral optimization techniques, including pipelining and gradientaccumulation, aimed at enhancing the performance of IPU-based models.Furthermore, we have effectively migrated a specialized model to the IPUplatform. This model is employed for predicting effective conductivity, aparameter crucial in ion transport processes, which govern the performance ofmultiple charge and discharge cycles of batteries. The model utilizes aConvolutional Neural Network (CNN) architecture to perform prediction tasks foreffective conductivity. The performance of this model on the IPU is found to becomparable to its execution on GPUs. We also analyze the utilization andperformance of Graphcore's Bow IPU. Through benchmark tests, we observesignificantly improved performance with the Bow IPU when compared to itspredecessor, the Colossus IPU.</description><author>Hieu Le, Zhenhua He, Mai Le, Dhruva K. Chakravorty, Lisa M. Perez, Akhil Chilumuru, Yan Yao, Jiefu Chen</author><pubDate>Tue, 16 Apr 2024 18:02:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10730v1</guid></item><item><title>Randomized Exploration in Cooperative Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2404.10728v1</link><description>We present the first study on provably efficient randomized exploration incooperative multi-agent reinforcement learning (MARL). We propose a unifiedalgorithm framework for randomized exploration in parallel Markov DecisionProcesses (MDPs), and two Thompson Sampling (TS)-type algorithms, CoopTS-PHEand CoopTS-LMC, incorporating the perturbed-history exploration (PHE) strategyand the Langevin Monte Carlo exploration (LMC) strategy respectively, which areflexible in design and easy to implement in practice. For a special class ofparallel MDPs where the transition is (approximately) linear, we theoreticallyprove that both CoopTS-PHE and CoopTS-LMC achieve a$\widetilde{\mathcal{O}}(d^{3/2}H^2\sqrt{MK})$ regret bound with communicationcomplexity $\widetilde{\mathcal{O}}(dHM^2)$, where $d$ is the featuredimension, $H$ is the horizon length, $M$ is the number of agents, and $K$ isthe number of episodes. This is the first theoretical result for randomizedexploration in cooperative MARL. We evaluate our proposed method on multipleparallel RL environments, including a deep exploration problem (\textit{i.e.,}$N$-chain), a video game, and a real-world problem in energy systems. Ourexperimental results support that our framework can achieve better performance,even under conditions of misspecified transition models. Additionally, weestablish a connection between our unified framework and the practicalapplication of federated learning.</description><author>Hao-Lun Hsu, Weixin Wang, Miroslav Pajic, Pan Xu</author><pubDate>Tue, 16 Apr 2024 18:01:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10728v1</guid></item><item><title>How Deep Networks Learn Sparse and Hierarchical Data: the Sparse Random Hierarchy Model</title><link>http://arxiv.org/abs/2404.10727v1</link><description>Understanding what makes high-dimensional data learnable is a fundamentalquestion in machine learning. On the one hand, it is believed that the successof deep learning lies in its ability to build a hierarchy of representationsthat become increasingly more abstract with depth, going from simple featureslike edges to more complex concepts. On the other hand, learning to beinsensitive to invariances of the task, such as smooth transformations forimage datasets, has been argued to be important for deep networks and itstrongly correlates with their performance. In this work, we aim to explainthis correlation and unify these two viewpoints. We show that by introducingsparsity to generative hierarchical models of data, the task acquiresinsensitivity to spatial transformations that are discrete versions of smoothtransformations. In particular, we introduce the Sparse Random Hierarchy Model(SRHM), where we observe and rationalize that a hierarchical representationmirroring the hierarchical model is learnt precisely when such insensitivity islearnt, thereby explaining the strong correlation between the latter andperformance. Moreover, we quantify how the sample complexity of CNNs learningthe SRHM depends on both the sparsity and hierarchical structure of the task.</description><author>Umberto Tomasini, Matthieu Wyart</author><pubDate>Tue, 16 Apr 2024 18:01:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10727v1</guid></item><item><title>Automatic re-calibration of quantum devices by reinforcement learning</title><link>http://arxiv.org/abs/2404.10726v1</link><description>During their operation, due to shifts in environmental conditions, devicesundergo various forms of detuning from their optimal settings. Typically, thisis addressed through control loops, which monitor variables and the deviceperformance, to maintain settings at their optimal values. Quantum devices areparticularly challenging since their functionality relies on precisely tuningtheir parameters. At the same time, the detailed modeling of the environmentalbehavior is often computationally unaffordable, while a direct measure of theparameters defining the system state is costly and introduces extra noise inthe mechanism. In this study, we investigate the application of reinforcementlearning techniques to develop a model-free control loop for continuousrecalibration of quantum device parameters. Furthermore, we explore theadvantages of incorporating minimal environmental noise models. As an example,the application to numerical simulations of a Kennedy receiver-basedlong-distance quantum communication protocol is presented.</description><author>T. Crosta, L. Rebón, F. Vilariño, J. M. Matera, M. Bilkis</author><pubDate>Tue, 16 Apr 2024 17:59:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10726v1</guid></item><item><title>PCN: A Deep Learning Approach to Jet Tagging Utilizing Novel Graph Construction Methods and Chebyshev Graph Convolutions</title><link>http://arxiv.org/abs/2309.08630v4</link><description>Jet tagging is a classification problem in high-energy physics experimentsthat aims to identify the collimated sprays of subatomic particles, jets, fromparticle collisions and tag them to their emitter particle. Advances in jettagging present opportunities for searches of new physics beyond the StandardModel. Current approaches use deep learning to uncover hidden patterns incomplex collision data. However, the representation of jets as inputs to a deeplearning model have been varied, and often, informative features are withheldfrom models. In this study, we propose a graph-based representation of a jetthat encodes the most information possible. To learn best from thisrepresentation, we design Particle Chebyshev Network (PCN), a graph neuralnetwork (GNN) using Chebyshev graph convolutions (ChebConv). ChebConv has beendemonstrated as an effective alternative to classical graph convolutions inGNNs and has yet to be explored in jet tagging. PCN achieves a substantialimprovement in accuracy over existing taggers and opens the door to futurestudies into graph-based representations of jets and ChebConv layers inhigh-energy physics experiments. Code is available athttps://github.com/YVSemlani/PCN-Jet-Tagging.</description><author>Yash Semlani, Mihir Relan, Krithik Ramesh</author><pubDate>Tue, 16 Apr 2024 17:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08630v4</guid></item><item><title>Pixel to Elevation: Learning to Predict Elevation Maps at Long Range using Images for Autonomous Offroad Navigation</title><link>http://arxiv.org/abs/2401.17484v2</link><description>Understanding terrain topology at long-range is crucial for the success ofoff-road robotic missions, especially when navigating at high-speeds. LiDARsensors, which are currently heavily relied upon for geometric mapping, providesparse measurements when mapping at greater distances. To address thischallenge, we present a novel learning-based approach capable of predictingterrain elevation maps at long-range using only onboard egocentric images inreal-time. Our proposed method is comprised of three main elements. First, atransformer-based encoder is introduced that learns cross-view associationsbetween the egocentric views and prior bird-eye-view elevation map predictions.Second, an orientation-aware positional encoding is proposed to incorporate the3D vehicle pose information over complex unstructured terrain with multi-viewvisual image features. Lastly, a history-augmented learn-able map embedding isproposed to achieve better temporal consistency between elevation mappredictions to facilitate the downstream navigational tasks. We experimentallyvalidate the applicability of our proposed approach for autonomous offroadrobotic navigation in complex and unstructured terrain using real-world offroaddriving data. Furthermore, the method is qualitatively and quantitativelycompared against the current state-of-the-art methods. Extensive fieldexperiments demonstrate that our method surpasses baseline models in accuratelypredicting terrain elevation while effectively capturing the overall terraintopology at long-ranges. Finally, ablation studies are conducted to highlightand understand the effect of key components of the proposed approach andvalidate their suitability to improve offroad robotic navigation capabilities.</description><author>Chanyoung Chung, Georgios Georgakis, Patrick Spieler, Curtis Padgett, Shehryar Khattak</author><pubDate>Tue, 16 Apr 2024 17:55:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17484v2</guid></item><item><title>A Survey and Benchmark of Automatic Surface Reconstruction from Point Clouds</title><link>http://arxiv.org/abs/2301.13656v3</link><description>We present a comprehensive survey and benchmark of both traditional andlearning-based methods for surface reconstruction from point clouds. This taskis particularly challenging for real-world acquisitions due to factors likenoise, outliers, non-uniform sampling, and missing data. Traditional approachesoften simplify the problem by imposing handcrafted priors on either the inputpoint clouds or the resulting surface, a process that can necessitate tedioushyperparameter tuning. Conversely, deep learning models have the capability todirectly learn the properties of input point clouds and desired surfaces fromdata. We study the influence of these handcrafted and learned priors on theprecision and robustness of surface reconstruction techniques. We evaluatevarious time-tested and contemporary methods in a standardized manner. Whenboth trained and evaluated on point clouds with identical characteristics, thelearning-based models consistently produce superior surfaces compared to theirtraditional counterparts$\unicode{x2013}$even in scenarios involving novelshape categories. However, traditional methods demonstrate greater resilienceto the diverse array of point cloud anomalies commonly found in real-world 3Dacquisitions. For the benefit of the research community, we make our code anddatasets available, inviting further enhancements to learning-based surfacereconstruction. This can be accessed athttps://github.com/raphaelsulzer/dsr-benchmark .</description><author>Raphael Sulzer, Renaud Marlet, Bruno Vallet, Loic Landrieu</author><pubDate>Tue, 16 Apr 2024 17:52:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13656v3</guid></item><item><title>Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study</title><link>http://arxiv.org/abs/2404.10719v1</link><description>Reinforcement Learning from Human Feedback (RLHF) is currently the mostwidely used method to align large language models (LLMs) with humanpreferences. Existing RLHF methods can be roughly categorized as eitherreward-based or reward-free. Novel applications such as ChatGPT and Claudeleverage reward-based methods that first learn a reward model and applyactor-critic algorithms, such as Proximal Policy Optimization (PPO). However,in academic benchmarks, state-of-the-art results are often achieved viareward-free methods, such as Direct Preference Optimization (DPO). Is DPO trulysuperior to PPO? Why does PPO perform poorly on these benchmarks? In thispaper, we first conduct both theoretical and empirical studies on thealgorithmic properties of DPO and show that DPO may have fundamentallimitations. Moreover, we also comprehensively examine PPO and reveal the keyfactors for the best performances of PPO in fine-tuning LLMs. Finally, webenchmark DPO and PPO across various a collection of RLHF testbeds, rangingfrom dialogue to code generation. Experiment results demonstrate that PPO isable to surpass other alignment methods in all cases and achievestate-of-the-art results in challenging code competitions.</description><author>Shusheng Xu, Wei Fu, Jiaxuan Gao, Wenjie Ye, Weilin Liu, Zhiyu Mei, Guangju Wang, Chao Yu, Yi Wu</author><pubDate>Tue, 16 Apr 2024 17:51:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10719v1</guid></item><item><title>GazeHTA: End-to-end Gaze Target Detection with Head-Target Association</title><link>http://arxiv.org/abs/2404.10718v1</link><description>We propose an end-to-end approach for gaze target detection: predicting ahead-target connection between individuals and the target image regions theyare looking at. Most of the existing methods use independent components such asoff-the-shelf head detectors or have problems in establishing associationsbetween heads and gaze targets. In contrast, we investigate an end-to-endmulti-person Gaze target detection framework with Heads and Targets Association(GazeHTA), which predicts multiple head-target instances based solely on inputscene image. GazeHTA addresses challenges in gaze target detection by (1)leveraging a pre-trained diffusion model to extract scene features for richsemantic understanding, (2) re-injecting a head feature to enhance the headpriors for improved head understanding, and (3) learning a connection map asthe explicit visual associations between heads and gaze targets. Our extensiveexperimental results demonstrate that GazeHTA outperforms state-of-the-art gazetarget detection methods and two adapted diffusion-based baselines on twostandard datasets.</description><author>Zhi-Yi Lin, Jouh Yeong Chew, Jan van Gemert, Xucong Zhang</author><pubDate>Tue, 16 Apr 2024 17:51:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10718v1</guid></item><item><title>Mixed Prototype Consistency Learning for Semi-supervised Medical Image Segmentation</title><link>http://arxiv.org/abs/2404.10717v1</link><description>Recently, prototype learning has emerged in semi-supervised medical imagesegmentation and achieved remarkable performance. However, the scarcity oflabeled data limits the expressiveness of prototypes in previous methods,potentially hindering the complete representation of prototypes for classembedding. To address this problem, we propose the Mixed Prototype ConsistencyLearning (MPCL) framework, which includes a Mean Teacher and an auxiliarynetwork. The Mean Teacher generates prototypes for labeled and unlabeled data,while the auxiliary network produces additional prototypes for mixed dataprocessed by CutMix. Through prototype fusion, mixed prototypes provide extrasemantic information to both labeled and unlabeled prototypes. High-qualityglobal prototypes for each class are formed by fusing two enhanced prototypes,optimizing the distribution of hidden embeddings used in consistency learning.Extensive experiments on the left atrium and type B aortic dissection datasetsdemonstrate MPCL's superiority over previous state-of-the-art approaches,confirming the effectiveness of our framework. The code will be released soon.</description><author>Lijian Li</author><pubDate>Tue, 16 Apr 2024 17:51:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10717v1</guid></item><item><title>MOWA: Multiple-in-One Image Warping Model</title><link>http://arxiv.org/abs/2404.10716v1</link><description>While recent image warping approaches achieved remarkable success on existingbenchmarks, they still require training separate models for each specific taskand cannot generalize well to different camera models or customizedmanipulations. To address diverse types of warping in practice, we propose aMultiple-in-One image WArping model (named MOWA) in this work. Specifically, wemitigate the difficulty of multi-task learning by disentangling the motionestimation at both the region level and pixel level. To further enable dynamictask-aware image warping, we introduce a lightweight point-based classifierthat predicts the task type, serving as prompts to modulate the feature mapsfor better estimation. To our knowledge, this is the first work that solvesmultiple practical warping tasks in one single model. Extensive experimentsdemonstrate that our MOWA, which is trained on six tasks for multiple-in-oneimage warping, outperforms state-of-the-art task-specific models across mosttasks. Moreover, MOWA also exhibits promising potential to generalize intounseen scenes, as evidenced by cross-domain and zero-shot evaluations. The codewill be made publicly available.</description><author>Kang Liao, Zongsheng Yue, Zhonghua Wu, Chen Change Loy</author><pubDate>Tue, 16 Apr 2024 17:50:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10716v1</guid></item><item><title>Fast and Private Inference of Deep Neural Networks by Co-designing Activation Functions</title><link>http://arxiv.org/abs/2306.08538v2</link><description>Machine Learning as a Service (MLaaS) is an increasingly popular design wherea company with abundant computing resources trains a deep neural network andoffers query access for tasks like image classification. The challenge withthis design is that MLaaS requires the client to reveal their potentiallysensitive queries to the company hosting the model. Multi-party computation(MPC) protects the client's data by allowing encrypted inferences. However,current approaches suffer from prohibitively large inference times. Theinference time bottleneck in MPC is the evaluation of non-linear layers such asReLU activation functions. Motivated by the success of previous workco-designing machine learning and MPC, we develop an activation functionco-design. We replace all ReLUs with a polynomial approximation and evaluatethem with single-round MPC protocols, which give state-of-the-art inferencetimes in wide-area networks. Furthermore, to address the accuracy issuespreviously encountered with polynomial activations, we propose a novel trainingalgorithm that gives accuracy competitive with plaintext models. Our evaluationshows between $3$ and $110\times$ speedups in inference time on large modelswith up to $23$ million parameters while maintaining competitive inferenceaccuracy.</description><author>Abdulrahman Diaa, Lucas Fenaux, Thomas Humphries, Marian Dietz, Faezeh Ebrahimianghazani, Bailey Kacsmar, Xinda Li, Nils Lukas, Rasoul Akhavan Mahdavi, Simon Oya, Ehsan Amjadian, Florian Kerschbaum</author><pubDate>Tue, 16 Apr 2024 17:48:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08538v2</guid></item><item><title>Dynamic Frequency-Based Fingerprinting Attacks against Modern Sandbox Environments</title><link>http://arxiv.org/abs/2404.10715v1</link><description>The cloud computing landscape has evolved significantly in recent years,embracing various sandboxes to meet the diverse demands of modern cloudapplications. These sandboxes encompass container-based technologies likeDocker and gVisor, microVM-based solutions like Firecracker, andsecurity-centric sandboxes relying on Trusted Execution Environments (TEEs)such as Intel SGX and AMD SEV. However, the practice of placing multipletenants on shared physical hardware raises security and privacy concerns, mostnotably side-channel attacks. In this paper, we investigate the possibility of fingerprinting containersthrough CPU frequency reporting sensors in Intel and AMD CPUs. One key enablerof our attack is that the current CPU frequency information can be accessed byuser-space attackers. We demonstrate that Docker images exhibit a uniquefrequency signature, enabling the distinction of different containers with upto 84.5% accuracy even when multiple containers are running simultaneously indifferent cores. Additionally, we assess the effectiveness of our attack whenperformed against several sandboxes deployed in cloud environments, includingGoogle's gVisor, AWS' Firecracker, and TEE-based platforms like Gramine(utilizing Intel SGX) and AMD SEV. Our empirical results show that theseattacks can also be carried out successfully against all of these sandboxes inless than 40 seconds, with an accuracy of over 70% in all cases. Finally, wepropose a noise injection-based countermeasure to mitigate the proposed attackon cloud environments.</description><author>Debopriya Roy Dipta, Thore Tiemann, Berk Gulmezoglu, Eduard Marin Fabregas, Thomas Eisenbarth</author><pubDate>Tue, 16 Apr 2024 17:45:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10715v1</guid></item><item><title>AV-GAN: Attention-Based Varifocal Generative Adversarial Network for Uneven Medical Image Translation</title><link>http://arxiv.org/abs/2404.10714v1</link><description>Different types of staining highlight different structures in organs, therebyassisting in diagnosis. However, due to the impossibility of repeated staining,we cannot obtain different types of stained slides of the same tissue area.Translating the slide that is easy to obtain (e.g., H&amp;E) to slides of stainingtypes difficult to obtain (e.g., MT, PAS) is a promising way to solve thisproblem. However, some regions are closely connected to other regions, and tomaintain this connection, they often have complex structures and are difficultto translate, which may lead to wrong translations. In this paper, we proposethe Attention-Based Varifocal Generative Adversarial Network (AV-GAN), whichsolves multiple problems in pathologic image translation tasks, such as uneventranslation difficulty in different regions, mutual interference of multipleresolution information, and nuclear deformation. Specifically, we develop anAttention-Based Key Region Selection Module, which can attend to regions withhigher translation difficulty. We then develop a Varifocal Module to translatethese regions at multiple resolutions. Experimental results show that ourproposed AV-GAN outperforms existing image translation methods with two virtualkidney tissue staining tasks and improves FID values by 15.9 and 4.16respectively in the H&amp;E-MT and H&amp;E-PAS tasks.</description><author>Zexin Li, Yiyang Lin, Zijie Fang, Shuyan Li, Xiu Li</author><pubDate>Tue, 16 Apr 2024 17:43:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10714v1</guid></item><item><title>A Plausibility Study of Using Augmented Reality in the Ventriculoperitoneal Shunt Operations</title><link>http://arxiv.org/abs/2404.10713v1</link><description>The field of augmented reality (AR) has undergone substantial growth, findingdiverse applications in the medical industry. This paper delves into varioustechniques employed in medical surgeries, scrutinizing factors such as cost,implementation, and accessibility. The focus of this exploration is on AR-basedsolutions, with a particular emphasis on addressing challenges and proposing aninnovative solution for ventriculoperitoneal shunt (VP) operations. Theproposed solution introduces a novel flow in the pre-surgery phase, aiming tosubstantially reduce setup time and operation duration by creating 3D models ofthe skull and ventricles. Experiments are conducted where the models arevisualized on a 3D- printed skull through an AR device, specifically theMicrosoft HoloLens 2. The paper then conducts an in-depth analysis of thisproposed solution, discussing its feasibility, advantages, limitations,andfuture implications.</description><author>Tandin Dorji, Pakinee Aimmanee, Vich Yindeedej</author><pubDate>Tue, 16 Apr 2024 17:43:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10713v1</guid></item><item><title>From Prejudice to Parity: A New Approach to Debiasing Large Language Model Word Embeddings</title><link>http://arxiv.org/abs/2402.11512v3</link><description>Embeddings play a pivotal role in the efficacy of Large Language Models. Theyare the bedrock on which these models grasp contextual relationships and fostera more nuanced understanding of language and consequently perform remarkably ona plethora of complex tasks that require a fundamental understanding of humanlanguage. Given that these embeddings themselves often reflect or exhibit bias,it stands to reason that these models may also inadvertently learn this bias.In this work, we build on the seminal previous work and propose DeepSoftDebias,an algorithm that uses a neural network to perform 'soft debiasing'. Weexhaustively evaluate this algorithm across a variety of SOTA datasets,accuracy metrics, and challenging NLP tasks. We find that DeepSoftDebiasoutperforms the current state-of-the-art methods at reducing bias acrossgender, race, and religion.</description><author>Aishik Rakshit, Smriti Singh, Shuvam Keshari, Arijit Ghosh Chowdhury, Vinija Jain, Aman Chadha</author><pubDate>Tue, 16 Apr 2024 17:40:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11512v3</guid></item><item><title>Octopus v2: On-device language model for super agent</title><link>http://arxiv.org/abs/2404.01744v5</link><description>Language models have shown effectiveness in a variety of softwareapplications, particularly in tasks related to automatic workflow. These modelspossess the crucial ability to call functions, which is essential in creatingAI agents. Despite the high performance of large-scale language models in cloudenvironments, they are often associated with concerns over privacy and cost.Current on-device models for function calling face issues with latency andaccuracy. Our research presents a new method that empowers an on-device modelwith 2 billion parameters to surpass the performance of GPT-4 in both accuracyand latency, and decrease the context length by 95\%. When compared to Llama-7Bwith a RAG-based function calling mechanism, our method enhances latency by35-fold. This method reduces the latency to levels deemed suitable fordeployment across a variety of edge devices in production environments,aligning with the performance requisites for real-world applications.</description><author>Wei Chen, Zhiyuan Li</author><pubDate>Tue, 16 Apr 2024 17:39:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.01744v5</guid></item><item><title>Understanding the Learning Dynamics of Alignment with Human Feedback</title><link>http://arxiv.org/abs/2403.18742v4</link><description>Aligning large language models (LLMs) with human intentions has become acritical task for safely deploying models in real-world systems. While existingalignment approaches have seen empirical success, theoretically understandinghow these methods affect model behavior remains an open question. Our workprovides an initial attempt to theoretically analyze the learning dynamics ofhuman preference alignment. We formally show how the distribution of preferencedatasets influences the rate of model updates and provide rigorous guaranteeson the training accuracy. Our theory also reveals an intricate phenomenon wherethe optimization is prone to prioritizing certain behaviors with higherpreference distinguishability. We empirically validate our findings oncontemporary LLMs and alignment tasks, reinforcing our theoretical insights andshedding light on considerations for future alignment approaches. Disclaimer:This paper contains potentially offensive text; reader discretion is advised.</description><author>Shawn Im, Yixuan Li</author><pubDate>Tue, 16 Apr 2024 17:38:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18742v4</guid></item><item><title>RiemannONets: Interpretable Neural Operators for Riemann Problems</title><link>http://arxiv.org/abs/2401.08886v2</link><description>Developing the proper representations for simulating high-speed flows withstrong shock waves, rarefactions, and contact discontinuities has been along-standing question in numerical analysis. Herein, we employ neuraloperators to solve Riemann problems encountered in compressible flows forextreme pressure jumps (up to $10^{10}$ pressure ratio). In particular, wefirst consider the DeepONet that we train in a two-stage process, following therecent work of \cite{lee2023training}, wherein the first stage, a basis isextracted from the trunk net, which is orthonormalized and subsequently is usedin the second stage in training the branch net. This simple modification ofDeepONet has a profound effect on its accuracy, efficiency, and robustness andleads to very accurate solutions to Riemann problems compared to the vanillaversion. It also enables us to interpret the results physically as thehierarchical data-driven produced basis reflects all the flow features thatwould otherwise be introduced using ad hoc feature expansion layers. We alsocompare the results with another neural operator based on the U-Net for low,intermediate, and very high-pressure ratios that are very accurate for Riemannproblems, especially for large pressure ratios, due to their multiscale naturebut computationally more expensive. Overall, our study demonstrates that simpleneural network architectures, if properly pre-trained, can achieve veryaccurate solutions of Riemann problems for real-time forecasting. The sourcecode, along with its corresponding data, can be found at the following URL:https://github.com/apey236/RiemannONet/tree/main</description><author>Ahmad Peyvan, Vivek Oommen, Ameya D. Jagtap, George Em Karniadakis</author><pubDate>Tue, 16 Apr 2024 17:37:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08886v2</guid></item><item><title>Dual Modalities of Text: Visual and Textual Generative Pre-training</title><link>http://arxiv.org/abs/2404.10710v1</link><description>Harnessing visual texts represents a burgeoning frontier in the evolution oflanguage modeling. In this paper, we introduce a novel pre-training frameworkfor a suite of pixel-based autoregressive language models, pre-training on acorpus of over 400 million documents rendered as RGB images. Our approach ischaracterized by a dual-modality training regimen, engaging both visual datathrough next patch prediction with a regression head and textual data via nexttoken prediction with a classification head. This study is particularly focusedon investigating the synergistic interplay between visual and textualmodalities of language. Our comprehensive evaluation across a diverse array ofbenchmarks reveals that the confluence of visual and textual data substantiallyaugments the efficacy of pixel-based language models. Notably, our findingsshow that a unidirectional pixel-based model, devoid of textual data duringtraining, can match the performance levels of advanced bidirectionalpixel-based models on various language understanding benchmarks. This workhighlights the considerable untapped potential of integrating visual andtextual information for language modeling purposes. We will release our code,data, and checkpoints to inspire further research advancement.</description><author>Yekun Chai, Qingyi Liu, Jingwu Xiao, Shuohuan Wang, Yu Sun, Hua Wu</author><pubDate>Tue, 16 Apr 2024 17:36:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10710v1</guid></item><item><title>Multi-dimensional Evaluation of Empathetic Dialog Responses</title><link>http://arxiv.org/abs/2402.11409v2</link><description>Empathy is critical for effective and satisfactory conversationalcommunication. Prior efforts to measure conversational empathy mostly focus onexpressed communicative intents -- that is, the way empathy is expressed. Yet,these works ignore the fact that conversation is also a collaboration involvingboth speakers and listeners. In contrast, we propose a multi-dimensionalempathy evaluation framework to measure both expressed intents from thespeaker's perspective and perceived empathy from the listener's perspective. Weapply our proposed framework to analyze our internal customer-service dialogue.We find the two dimensions (expressed intent types and perceived empathy) areinter-connected, and perceived empathy has a high correlation with dialoguesatisfaction levels. To reduce the annotation cost, we explore different options to automaticallymeasure conversational empathy: prompting LLMs and training languagemodel-based classifiers. Our experiments show that prompting methods with evenpopular models like GPT-4 and Flan family models perform relatively poorly onboth public and our internal datasets. In contrast, instruction-finetunedclassifiers based on Flan-T5 family models outperform prior works andcompetitive baselines. We conduct a detailed ablation study to give moreinsights into instruction finetuning method's strong performance.</description><author>Zhichao Xu, Jiepu Jiang</author><pubDate>Tue, 16 Apr 2024 17:34:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11409v2</guid></item><item><title>Are Good Explainers Secretly Human-in-the-Loop Active Learners?</title><link>http://arxiv.org/abs/2306.13935v3</link><description>Explainable AI (XAI) techniques have become popular for multiple use-cases inthe past few years. Here we consider its use in studying model predictions togather additional training data. We argue that this is equivalent to ActiveLearning, where the query strategy involves a human-in-the-loop. We provide amathematical approximation for the role of the human, and present a generalformalization of the end-to-end workflow. This enables us to rigorously comparethis use with standard Active Learning algorithms, while allowing forextensions to the workflow. An added benefit is that their utility can beassessed via simulation instead of conducting expensive user-studies. We alsopresent some initial promising results.</description><author>Emma Thuong Nguyen, Abhishek Ghose</author><pubDate>Tue, 16 Apr 2024 17:33:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.13935v3</guid></item><item><title>Cross-Language Evolution of Divergent Collective Memory Around the Arab Spring</title><link>http://arxiv.org/abs/2404.10706v1</link><description>The Arab Spring was a historic set of protests beginning in 2011 that toppledgovernments and led to major conflicts. Collective memories of events likethese can vary significantly across social contexts in response to political,cultural, and linguistic factors. While Wikipedia plays an important role indocumenting both historic and current events, little attention has been givento how Wikipedia articles, created in the aftermath of major events, continueto evolve over years or decades. Using the archived content of ArabSpring-related topics across the Arabic and English Wikipedias between 2011 and2024, we define and evaluate multilingual measures of event salience,deliberation, contextualization, and consolidation of collective memorysurrounding the Arab Spring. Our findings about the temporal evolution of theWikipedia articles' content similarity across languages has implications fortheorizing about online collective memory processes and evaluating linguisticmodels trained on these data.</description><author>H. Laurie Jones, Brian C. Keegan</author><pubDate>Tue, 16 Apr 2024 17:30:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10706v1</guid></item><item><title>Ghost-dil-NetVLAD: A Lightweight Neural Network for Visual Place Recognition</title><link>http://arxiv.org/abs/2112.11679v2</link><description>Visual place recognition (VPR) is a challenging task with the unbalancebetween enormous computational cost and high recognition performance. Thanks tothe practical feature extraction ability of the lightweight convolution neuralnetworks (CNNs) and the train-ability of the vector of locally aggregateddescriptors (VLAD) layer, we propose a lightweight weakly supervised end-to-endneural network consisting of a front-ended perception model called GhostCNN anda learnable VLAD layer as a back-end. GhostCNN is based on Ghost modules thatare lightweight CNN-based architectures. They can generate redundant featuremaps using linear operations instead of the traditional convolution process,making a good trade-off between computation resources and recognition accuracy.To enhance our proposed lightweight model further, we add dilated convolutionsto the Ghost module to get features containing more spatial semanticinformation, improving accuracy. Finally, rich experiments conducted on acommonly used public benchmark and our private dataset validate that theproposed neural network reduces the FLOPs and parameters of VGG16-NetVLAD by99.04% and 80.16%, respectively. Besides, both models achieve similar accuracy.</description><author>Qingyuan Gong, Yu Liu, Liqiang Zhang, Renhe Liu</author><pubDate>Tue, 16 Apr 2024 17:28:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.11679v2</guid></item><item><title>Analyzing Explainer Robustness via Probabilistic Lipschitzness of Prediction Functions</title><link>http://arxiv.org/abs/2206.12481v3</link><description>Machine learning methods have significantly improved in their predictivecapabilities, but at the same time they are becoming more complex and lesstransparent. As a result, explainers are often relied on to provideinterpretability to these black-box prediction models. As crucial diagnosticstools, it is important that these explainers themselves are robust. In thispaper we focus on one particular aspect of robustness, namely that an explainershould give similar explanations for similar data inputs. We formalize thisnotion by introducing and defining explainer astuteness, analogous toastuteness of prediction functions. Our formalism allows us to connectexplainer robustness to the predictor's probabilistic Lipschitzness, whichcaptures the probability of local smoothness of a function. We provide lowerbound guarantees on the astuteness of a variety of explainers (e.g., SHAP,RISE, CXPlain) given the Lipschitzness of the prediction function. Thesetheoretical results imply that locally smooth prediction functions lendthemselves to locally robust explanations. We evaluate these resultsempirically on simulated as well as real datasets.</description><author>Zulqarnain Khan, Davin Hill, Aria Masoomi, Joshua Bone, Jennifer Dy</author><pubDate>Tue, 16 Apr 2024 17:27:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.12481v3</guid></item><item><title>VehicleGAN: Pair-flexible Pose Guided Image Synthesis for Vehicle Re-identification</title><link>http://arxiv.org/abs/2311.16278v2</link><description>Vehicle Re-identification (Re-ID) has been broadly studied in the lastdecade; however, the different camera view angle leading to confuseddiscrimination in the feature subspace for the vehicles of various poses, isstill challenging for the Vehicle Re-ID models in the real world. To promotethe Vehicle Re-ID models, this paper proposes to synthesize a large number ofvehicle images in the target pose, whose idea is to project the vehicles ofdiverse poses into the unified target pose so as to enhance featurediscrimination. Considering that the paired data of the same vehicles indifferent traffic surveillance cameras might be not available in the realworld, we propose the first Pair-flexible Pose Guided Image Synthesis methodfor Vehicle Re-ID, named as VehicleGAN in this paper, which works for bothsupervised and unsupervised settings without the knowledge of geometric 3Dmodels. Because of the feature distribution difference between real andsynthetic data, simply training a traditional metric learning based Re-ID modelwith data-level fusion (i.e., data augmentation) is not satisfactory, thereforewe propose a new Joint Metric Learning (JML) via effective feature-level fusionfrom both real and synthetic data. Intensive experimental results on the publicVeRi-776 and VehicleID datasets prove the accuracy and effectiveness of ourproposed VehicleGAN and JML.</description><author>Baolu Li, Ping Liu, Lan Fu, Jinlong Li, Jianwu Fang, Zhigang Xu, Hongkai Yu</author><pubDate>Tue, 16 Apr 2024 17:26:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.16278v2</guid></item><item><title>Question Difficulty Ranking for Multiple-Choice Reading Comprehension</title><link>http://arxiv.org/abs/2404.10704v1</link><description>Multiple-choice (MC) tests are an efficient method to assess Englishlearners. It is useful for test creators to rank candidate MC questions bydifficulty during exam curation. Typically, the difficulty is determined byhaving human test takers trial the questions in a pretesting stage. However,this is expensive and not scalable. Therefore, we explore automated approachesto rank MC questions by difficulty. However, there is limited data for explicittraining of a system for difficulty scores. Hence, we compare task transfer andzero-shot approaches: task transfer adapts level classification and readingcomprehension systems for difficulty ranking while zero-shot prompting ofinstruction finetuned language models contrasts absolute assessment againstcomparative. It is found that level classification transfers better thanreading comprehension. Additionally, zero-shot comparative assessment is moreeffective at difficulty ranking than the absolute assessment and even the tasktransfer approaches at question difficulty ranking with a Spearman'scorrelation of 40.4%. Combining the systems is observed to further boost thecorrelation.</description><author>Vatsal Raina, Mark Gales</author><pubDate>Tue, 16 Apr 2024 17:23:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10704v1</guid></item><item><title>Rawformer: Unpaired Raw-to-Raw Translation for Learnable Camera ISPs</title><link>http://arxiv.org/abs/2404.10700v1</link><description>Modern smartphone camera quality heavily relies on the image signal processor(ISP) to enhance captured raw images, utilizing carefully designed modules toproduce final output images encoded in a standard color space (e.g., sRGB).Neural-based end-to-end learnable ISPs offer promising advancements,potentially replacing traditional ISPs with their ability to adapt withoutrequiring extensive tuning for each new camera model, as is often the case fornearly every module in traditional ISPs. However, the key challenge with therecent learning-based ISPs is the urge to collect large paired datasets foreach distinct camera model due to the influence of intrinsic cameracharacteristics on the formation of input raw images. This paper tackles thischallenge by introducing a novel method for unpaired learning of raw-to-rawtranslation across diverse cameras. Specifically, we propose Rawformer, anunsupervised Transformer-based encoder-decoder method for raw-to-rawtranslation. It accurately maps raw images captured by a certain camera to thetarget camera, facilitating the generalization of learnable ISPs to new unseencameras. Our method demonstrates superior performance on real camera datasets,achieving higher accuracy compared to previous state-of-the-art techniques, andpreserving a more robust correlation between the original and translated rawimages.</description><author>Georgy Perevozchikov, Nancy Mehta, Mahmoud Afifi, Radu Timofte</author><pubDate>Tue, 16 Apr 2024 17:17:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10700v1</guid></item><item><title>ECLAIR: A High-Fidelity Aerial LiDAR Dataset for Semantic Segmentation</title><link>http://arxiv.org/abs/2404.10699v1</link><description>We introduce ECLAIR (Extended Classification of Lidar for AI Recognition), anew outdoor large-scale aerial LiDAR dataset designed specifically foradvancing research in point cloud semantic segmentation. As the most extensiveand diverse collection of its kind to date, the dataset covers a total area of10$km^2$ with close to 600 million points and features eleven distinct objectcategories. To guarantee the dataset's quality and utility, we have thoroughlycurated the point labels through an internal team of experts, ensuring accuracyand consistency in semantic labeling. The dataset is engineered to move forwardthe fields of 3D urban modeling, scene understanding, and utilityinfrastructure management by presenting new challenges and potentialapplications. As a benchmark, we report qualitative and quantitative analysisof a voxel-based point cloud segmentation approach based on the MinkowskiEngine.</description><author>Iaroslav Melekhov, Anand Umashankar, Hyeong-Jin Kim, Vladislav Serkov, Dusty Argyle</author><pubDate>Tue, 16 Apr 2024 17:16:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10699v1</guid></item><item><title>Integrating knowledge bases to improve coreference and bridging resolution for the chemical domain</title><link>http://arxiv.org/abs/2404.10696v1</link><description>Resolving coreference and bridging relations in chemical patents is importantfor better understanding the precise chemical process, where chemical domainknowledge is very critical. We proposed an approach incorporating externalknowledge into a multi-task learning model for both coreference and bridgingresolution in the chemical domain. The results show that integrating externalknowledge can benefit both chemical coreference and bridging resolution.</description><author>Pengcheng Lu, Massimo Poesio</author><pubDate>Tue, 16 Apr 2024 17:15:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10696v1</guid></item><item><title>Ensemble Value Functions for Efficient Exploration in Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2302.03439v6</link><description>Existing value-based algorithms for cooperative multi-agent reinforcementlearning (MARL) commonly rely on random exploration, such as $\epsilon$-greedy,to explore the environment. However, such exploration is inefficient at findingeffective joint actions in states that require cooperation of multiple agents.In this work, we propose ensemble value functions for multi-agent exploration(EMAX), a general framework to seamlessly extend value-based MARL algorithmswith ensembles of value functions. EMAX leverages the ensemble of valuefunctions to guide the exploration of agents, stabilises their optimisation,and makes their policies more robust to miscoordination. These benefits areachieved by using a combination of three techniques. (1) EMAX uses theuncertainty of value estimates across the ensemble in a UCB policy to guide theexploration. This exploration policy focuses on parts of the environment whichrequire cooperation across agents and, thus, enables agents to more efficientlylearn how to cooperate. (2) During the optimisation, EMAX computes targetvalues as average value estimates across the ensemble. These targets exhibitlower variance compared to commonly applied target networks, leading tosignificant benefits in MARL which commonly suffers from high variance causedby the exploration and non-stationary policies of other agents. (3) Duringevaluation, EMAX selects actions following a majority vote across the ensemble,which reduces the likelihood of selecting sub-optimal actions. We instantiatethree value-based MARL algorithms with EMAX, independent DQN, VDN and QMIX, andevaluate them in 21 tasks across four environments. Using ensembles of fivevalue functions, EMAX improves sample efficiency and final evaluation returnsof these algorithms by 60%, 47%, and 539%, respectively, averaged across 21tasks.</description><author>Lukas Schäfer, Oliver Slumbers, Stephen McAleer, Yali Du, Stefano V. Albrecht, David Mguni</author><pubDate>Tue, 16 Apr 2024 17:13:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.03439v6</guid></item><item><title>MathWriting: A Dataset For Handwritten Mathematical Expression Recognition</title><link>http://arxiv.org/abs/2404.10690v1</link><description>We introduce MathWriting, the largest online handwritten mathematicalexpression dataset to date. It consists of 230k human-written samples and anadditional 400k synthetic ones. MathWriting can also be used for offline HMErecognition and is larger than all existing offline HME datasets likeIM2LATEX-100K. We introduce a benchmark based on MathWriting data in order toadvance research on both online and offline HME recognition.</description><author>Philippe Gervais, Asya Fadeeva, Andrii Maksai</author><pubDate>Tue, 16 Apr 2024 17:10:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10690v1</guid></item><item><title>Network architecture search of X-ray based scientific applications</title><link>http://arxiv.org/abs/2404.10689v1</link><description>X-ray and electron diffraction-based microscopy use bragg peak detection andptychography to perform 3-D imaging at an atomic resolution. Typically, thesetechniques are implemented using computationally complex tasks such as aPsuedo-Voigt function or solving a complex inverse problem. Recently, the useof deep neural networks has improved the existing state-of-the-art approaches.However, the design and development of the neural network models depends ontime and labor intensive tuning of the model by application experts. To thatend, we propose a hyperparameter (HPS) and neural architecture search (NAS)approach to automate the design and optimization of the neural network modelsfor model size, energy consumption and throughput. We demonstrate the improvedperformance of the auto-tuned models when compared to the manually tunedBraggNN and PtychoNN benchmark. We study and demonstrate the importance of theexploring the search space of tunable hyperparameters in enhancing theperformance of bragg peak detection and ptychographic reconstruction. Our NASand HPS of (1) BraggNN achieves a 31.03\% improvement in bragg peak detectionaccuracy with a 87.57\% reduction in model size, and (2) PtychoNN achieves a16.77\% improvement in model accuracy and a 12.82\% reduction in model sizewhen compared to the baseline PtychoNN model. When inferred on the Orin-AGXplatform, the optimized Braggnn and Ptychonn models demonstrate a 10.51\% and9.47\% reduction in inference latency and a 44.18\% and 15.34\% reduction inenergy consumption when compared to their respective baselines, when inferredin the Orin-AGX edge platform.</description><author>Adarsha Balaji, Ramyad Hadidi, Gregory Kollmer, Mohammed E. Fouda, Prasanna Balaprakash</author><pubDate>Tue, 16 Apr 2024 17:09:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10689v1</guid></item><item><title>Efficient Conditional Diffusion Model with Probability Flow Sampling for Image Super-resolution</title><link>http://arxiv.org/abs/2404.10688v1</link><description>Image super-resolution is a fundamentally ill-posed problem because multiplevalid high-resolution images exist for one low-resolution image.Super-resolution methods based on diffusion probabilistic models can deal withthe ill-posed nature by learning the distribution of high-resolution imagesconditioned on low-resolution images, avoiding the problem of blurry images inPSNR-oriented methods. However, existing diffusion-based super-resolutionmethods have high time consumption with the use of iterative sampling, whilethe quality and consistency of generated images are less than ideal due toproblems like color shifting. In this paper, we propose Efficient ConditionalDiffusion Model with Probability Flow Sampling (ECDP) for imagesuper-resolution. To reduce the time consumption, we design a continuous-timeconditional diffusion model for image super-resolution, which enables the useof probability flow sampling for efficient generation. Additionally, to improvethe consistency of generated images, we propose a hybrid parametrization forthe denoiser network, which interpolates between the data-predictingparametrization and the noise-predicting parametrization for different noisescales. Moreover, we design an image quality loss as a complement to the scorematching loss of diffusion models, further improving the consistency andquality of super-resolution. Extensive experiments on DIV2K, ImageNet, andCelebA demonstrate that our method achieves higher super-resolution qualitythan existing diffusion-based image super-resolution methods while having lowertime consumption. Our code is available at https://github.com/Yuan-Yutao/ECDP.</description><author>Yutao Yuan, Chun Yuan</author><pubDate>Tue, 16 Apr 2024 17:08:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10688v1</guid></item><item><title>Emoji Promotes Developer Participation and Issue Resolution on GitHub</title><link>http://arxiv.org/abs/2308.16360v3</link><description>Although remote working is increasingly adopted during the pandemic, many areconcerned by the low-efficiency in the remote working. Missing in text-basedcommunication are non-verbal cues such as facial expressions and body language,which hinders the effective communication and negatively impacts the workoutcomes. Prevalent on social media platforms, emojis, as alternativenon-verbal cues, are gaining popularity in the virtual workspaces well. In thispaper, we study how emoji usage influences developer participation and issueresolution in virtual workspaces. To this end, we collect GitHub issues for aone-year period and apply causal inference techniques to measure the causaleffect of emojis on the outcome of issues, controlling for confounders such asissue content, repository, and author information. We find that emojis cansignificantly reduce the resolution time of issues and attract more userparticipation. We also compare the heterogeneous effect on different types ofissues. These findings deepen our understanding of the developer communities,and they provide design implications on how to facilitate interactions andbroaden developer participation.</description><author>Yuhang Zhou, Xuan Lu, Ge Gao, Qiaozhu Mei, Wei Ai</author><pubDate>Tue, 16 Apr 2024 17:08:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.16360v3</guid></item><item><title>Evolutionary Optimization of 1D-CNN for Non-contact Respiration Pattern Classification</title><link>http://arxiv.org/abs/2312.13035v2</link><description>In this study, we present a deep learning-based approach for time-seriesrespiration data classification. The dataset contains regular breathingpatterns as well as various forms of abnormal breathing, obtained throughnon-contact incoherent light-wave sensing (LWS) technology. Given theone-dimensional (1D) nature of the data, we employed a 1D convolutional neuralnetwork (1D-CNN) for classification purposes. Genetic algorithm was employed tooptimize the 1D-CNN architecture to maximize classification accuracy.Addressing the computational complexity associated with training the 1D-CNNacross multiple generations, we implemented transfer learning from apre-trained model. This approach significantly reduced the computational timerequired for training, thereby enhancing the efficiency of the optimizationprocess. This study contributes valuable insights into the potentialapplications of deep learning methodologies for enhancing respiratory anomalydetection through precise and efficient respiration classification.</description><author>Md Zobaer Islam, Sabit Ekin, John F. O'Hara, Gary Yen</author><pubDate>Tue, 16 Apr 2024 17:08:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13035v2</guid></item><item><title>Generating Human Interaction Motions in Scenes with Text Control</title><link>http://arxiv.org/abs/2404.10685v1</link><description>We present TeSMo, a method for text-controlled scene-aware motion generationbased on denoising diffusion models. Previous text-to-motion methods focus oncharacters in isolation without considering scenes due to the limitedavailability of datasets that include motion, text descriptions, andinteractive scenes. Our approach begins with pre-training a scene-agnostictext-to-motion diffusion model, emphasizing goal-reaching constraints onlarge-scale motion-capture datasets. We then enhance this model with ascene-aware component, fine-tuned using data augmented with detailed sceneinformation, including ground plane and object shapes. To facilitate training,we embed annotated navigation and interaction motions within scenes. Theproposed method produces realistic and diverse human-object interactions, suchas navigation and sitting, in different scenes with various object shapes,orientations, initial body positions, and poses. Extensive experimentsdemonstrate that our approach surpasses prior techniques in terms of theplausibility of human-scene interactions, as well as the realism and variety ofthe generated motions. Code will be released upon publication of this work athttps://research.nvidia.com/labs/toronto-ai/tesmo.</description><author>Hongwei Yi, Justus Thies, Michael J. Black, Xue Bin Peng, Davis Rempe</author><pubDate>Tue, 16 Apr 2024 17:04:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10685v1</guid></item><item><title>Driver Fatigue Prediction using Randomly Activated Neural Networks for Smart Ridesharing Platforms</title><link>http://arxiv.org/abs/2404.10684v1</link><description>Drivers in ridesharing platforms exhibit cognitive atrophy and fatigue asthey accept ride offers along the day, which can have a significant impact onthe overall efficiency of the ridesharing platform. In contrast to the currentliterature which focuses primarily on modeling and learning driver'spreferences across different ride offers, this paper proposes a novel DynamicDiscounted Satisficing (DDS) heuristic to model and predict driver's sequentialride decisions during a given shift. Based on DDS heuristic, a novel stochasticneural network with random activations is proposed to model DDS heuristic andpredict the final decision made by a given driver. The presence of randomactivations in the network necessitated the development of a novel trainingalgorithm called Sampling-Based Back Propagation Through Time (SBPTT), wheregradients are computed for independent instances of neural networks (obtainedvia sampling the distribution of activation threshold) and aggregated to updatethe network parameters. Using both simulation experiments as well as on realChicago taxi dataset, this paper demonstrates the improved performance of theproposed approach, when compared to state-of-the-art methods.</description><author>Sree Pooja Akula, Mukund Telukunta, Venkata Sriram Siddhardh Nadendla</author><pubDate>Tue, 16 Apr 2024 17:04:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10684v1</guid></item><item><title>Simplex Decomposition for Portfolio Allocation Constraints in Reinforcement Learning</title><link>http://arxiv.org/abs/2404.10683v1</link><description>Portfolio optimization tasks describe sequential decision problems in whichthe investor's wealth is distributed across a set of assets. Allocationconstraints are used to enforce minimal or maximal investments into particularsubsets of assets to control for objectives such as limiting the portfolio'sexposure to a certain sector due to environmental concerns. Although methodsfor constrained Reinforcement Learning (CRL) can optimize policies whileconsidering allocation constraints, it can be observed that these generalmethods yield suboptimal results. In this paper, we propose a novel approach tohandle allocation constraints based on a decomposition of the constraint actionspace into a set of unconstrained allocation problems. In particular, weexamine this approach for the case of two constraints. For example, an investormay wish to invest at least a certain percentage of the portfolio into greentechnologies while limiting the investment in the fossil energy sector. We showthat the action space of the task is equivalent to the decomposed action space,and introduce a new reinforcement learning (RL) approach CAOSD, which is builton top of the decomposition. The experimental evaluation on real-worldNasdaq-100 data demonstrates that our approach consistently outperformsstate-of-the-art CRL benchmarks for portfolio optimization.</description><author>David Winkel, Niklas Strauß, Matthias Schubert, Thomas Seidl</author><pubDate>Tue, 16 Apr 2024 17:00:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10683v1</guid></item><item><title>Noncontact Respiratory Anomaly Detection Using Infrared Light-Wave Sensing</title><link>http://arxiv.org/abs/2301.03713v4</link><description>Human respiratory rate and its pattern convey essential information about thephysical and psychological states of the subject. Abnormal breathing canindicate fatal health issues leading to further diagnosis and treatment.Wireless light-wave sensing (LWS) using incoherent infrared light shows promisein safe, discreet, efficient, and non-invasive human breathing monitoringwithout raising privacy concerns. The respiration monitoring system needs to betrained on different types of breathing patterns to identify breathinganomalies.The system must also validate the collected data as a breathingwaveform, discarding any faulty data caused by external interruption, usermovement, or system malfunction. To address these needs, this study simulatednormal and different types of abnormal respiration using a robot that mimicshuman breathing patterns. Then, time-series respiration data were collectedusing infrared light-wave sensing technology. Three machine learningalgorithms, decision tree, random forest and XGBoost, were applied to detectbreathing anomalies and faulty data. Model performances were evaluated throughcross-validation, assessing classification accuracy, precision and recallscores. The random forest model achieved the highest classification accuracy of96.75% with data collected at a 0.5m distance. In general, ensemble models likerandom forest and XGBoost performed better than a single model in classifyingthe data collected at multiple distances from the light-wave sensing setup.</description><author>Md Zobaer Islam, Brenden Martin, Carly Gotcher, Tyler Martinez, John F. O'Hara, Sabit Ekin</author><pubDate>Tue, 16 Apr 2024 17:00:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.03713v4</guid></item><item><title>StyleCity: Large-Scale 3D Urban Scenes Stylization with Vision-and-Text Reference via Progressive Optimization</title><link>http://arxiv.org/abs/2404.10681v1</link><description>Creating large-scale virtual urban scenes with variant styles is inherentlychallenging. To facilitate prototypes of virtual production and bypass the needfor complex materials and lighting setups, we introduce the firstvision-and-text-driven texture stylization system for large-scale urban scenes,StyleCity. Taking an image and text as references, StyleCity stylizes a 3Dtextured mesh of a large-scale urban scene in a semantics-aware fashion andgenerates a harmonic omnidirectional sky background. To achieve that, wepropose to stylize a neural texture field by transferring 2D vision-and-textpriors to 3D globally and locally. During 3D stylization, we progressivelyscale the planned training views of the input 3D scene at different levels inorder to preserve high-quality scene content. We then optimize the scene styleglobally by adapting the scale of the style image with the scale of thetraining views. Moreover, we enhance local semantics consistency by thesemantics-aware style loss which is crucial for photo-realistic stylization.Besides texture stylization, we further adopt a generative diffusion model tosynthesize a style-consistent omnidirectional sky image, which offers a moreimmersive atmosphere and assists the semantic stylization process. The stylizedneural texture field can be baked into an arbitrary-resolution texture,enabling seamless integration into conventional rendering pipelines andsignificantly easing the virtual production prototyping process. Extensiveexperiments demonstrate our stylized scenes' superiority in qualitative andquantitative performance and user preferences.</description><author>Yingshu Chen, Huajian Huang, Tuan-Anh Vu, Ka Chun Shum, Sai-Kit Yeung</author><pubDate>Tue, 16 Apr 2024 16:58:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10681v1</guid></item><item><title>HSVI-based Online Minimax Strategies for Partially Observable Stochastic Games with Neural Perception Mechanisms</title><link>http://arxiv.org/abs/2404.10679v1</link><description>We consider a variant of continuous-state partially-observable stochasticgames with neural perception mechanisms and an asymmetric informationstructure. One agent has partial information, with the observation functionimplemented as a neural network, while the other agent is assumed to have fullknowledge of the state. We present, for the first time, an efficient onlinemethod to compute an $\varepsilon$-minimax strategy profile, which requiresonly one linear program to be solved for each agent at every stage, instead ofa complex estimation of opponent counterfactual values. For thepartially-informed agent, we propose a continual resolving approach which useslower bounds, pre-computed offline with heuristic search value iteration(HSVI), instead of opponent counterfactual values. This inherits the soundnessof continual resolving at the cost of pre-computing the bound. For thefully-informed agent, we propose an inferred-belief strategy, where the agentmaintains an inferred belief about the belief of the partially-informed agentbased on (offline) upper bounds from HSVI, guaranteeing $\varepsilon$-distanceto the value of the game at the initial belief known to both agents.</description><author>Rui Yan, Gabriel Santos, Gethin Norman, David Parker, Marta Kwiatkowska</author><pubDate>Tue, 16 Apr 2024 16:58:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10679v1</guid></item><item><title>The Curious Decline of Linguistic Diversity: Training Language Models on Synthetic Text</title><link>http://arxiv.org/abs/2311.09807v2</link><description>This study investigates the consequences of training language models onsynthetic data generated by their predecessors, an increasingly prevalentpractice given the prominence of powerful generative models. Diverging from theusual emphasis on performance metrics, we focus on the impact of this trainingmethodology on linguistic diversity, especially when conducted recursively overtime. To assess this, we adapt and develop a set of novel metrics targetinglexical, syntactic, and semantic diversity, applying them in recursivefinetuning experiments across various natural language generation tasks inEnglish. Our findings reveal a consistent decrease in the diversity of themodel outputs through successive iterations, especially remarkable for tasksdemanding high levels of creativity. This trend underscores the potential risksof training language models on synthetic text, particularly concerning thepreservation of linguistic richness. Our study highlights the need for carefulconsideration of the long-term effects of such training approaches on thelinguistic capabilities of language models.</description><author>Yanzhu Guo, Guokan Shang, Michalis Vazirgiannis, Chloé Clavel</author><pubDate>Tue, 16 Apr 2024 16:57:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09807v2</guid></item><item><title>Automating REST API Postman Test Cases Using LLM</title><link>http://arxiv.org/abs/2404.10678v1</link><description>In the contemporary landscape of technological advancements, the automationof manual processes is crucial, compelling the demand for huge datasets toeffectively train and test machines. This research paper is dedicated to theexploration and implementation of an automated approach to generate test casesspecifically using Large Language Models. The methodology integrates the use ofOpen AI to enhance the efficiency and effectiveness of test case generation fortraining and evaluating Large Language Models. This formalized approach withLLMs simplifies the testing process, making it more efficient andcomprehensive. Leveraging natural language understanding, LLMs canintelligently formulate test cases that cover a broad range of REST APIproperties, ensuring comprehensive testing. The model that is developed duringthe research is trained using manually collected postman test cases orinstances for various Rest APIs. LLMs enhance the creation of Postman testcases by automating the generation of varied and intricate test scenarios.Postman test cases offer streamlined automation, collaboration, and dynamicdata handling, providing a user-friendly and efficient approach to API testingcompared to traditional test cases. Thus, the model developed not only conformsto current technological standards but also holds the promise of evolving intoan idea of substantial importance in future technological advancements.</description><author>S Deepika Sri, Mohammed Aadil S, Sanjjushri Varshini R, Raja CSP Raman, Gopinath Rajagopal, S Taranath Chan</author><pubDate>Tue, 16 Apr 2024 16:53:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10678v1</guid></item><item><title>SplaTAM: Splat, Track &amp; Map 3D Gaussians for Dense RGB-D SLAM</title><link>http://arxiv.org/abs/2312.02126v3</link><description>Dense simultaneous localization and mapping (SLAM) is crucial for roboticsand augmented reality applications. However, current methods are often hamperedby the non-volumetric or implicit way they represent a scene. This workintroduces SplaTAM, an approach that, for the first time, leverages explicitvolumetric representations, i.e., 3D Gaussians, to enable high-fidelityreconstruction from a single unposed RGB-D camera, surpassing the capabilitiesof existing methods. SplaTAM employs a simple online tracking and mappingsystem tailored to the underlying Gaussian representation. It utilizes asilhouette mask to elegantly capture the presence of scene density. Thiscombination enables several benefits over prior representations, including fastrendering and dense optimization, quickly determining if areas have beenpreviously mapped, and structured map expansion by adding more Gaussians.Extensive experiments show that SplaTAM achieves up to 2x superior performancein camera pose estimation, map construction, and novel-view synthesis overexisting methods, paving the way for more immersive high-fidelity SLAMapplications.</description><author>Nikhil Keetha, Jay Karhade, Krishna Murthy Jatavallabhula, Gengshan Yang, Sebastian Scherer, Deva Ramanan, Jonathon Luiten</author><pubDate>Tue, 16 Apr 2024 16:50:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02126v3</guid></item><item><title>VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time</title><link>http://arxiv.org/abs/2404.10667v1</link><description>We introduce VASA, a framework for generating lifelike talking faces withappealing visual affective skills (VAS) given a single static image and aspeech audio clip. Our premiere model, VASA-1, is capable of not only producinglip movements that are exquisitely synchronized with the audio, but alsocapturing a large spectrum of facial nuances and natural head motions thatcontribute to the perception of authenticity and liveliness. The coreinnovations include a holistic facial dynamics and head movement generationmodel that works in a face latent space, and the development of such anexpressive and disentangled face latent space using videos. Through extensiveexperiments including evaluation on a set of new metrics, we show that ourmethod significantly outperforms previous methods along various dimensionscomprehensively. Our method not only delivers high video quality with realisticfacial and head dynamics but also supports the online generation of 512x512videos at up to 40 FPS with negligible starting latency. It paves the way forreal-time engagements with lifelike avatars that emulate human conversationalbehaviors.</description><author>Sicheng Xu, Guojun Chen, Yu-Xiao Guo, Jiaolong Yang, Chong Li, Zhenyu Zang, Yizhong Zhang, Xin Tong, Baining Guo</author><pubDate>Tue, 16 Apr 2024 16:43:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10667v1</guid></item><item><title>Assessing The Impact of CNN Auto Encoder-Based Image Denoising on Image Classification Tasks</title><link>http://arxiv.org/abs/2404.10664v1</link><description>Images captured from the real world are often affected by different types ofnoise, which can significantly impact the performance of Computer Visionsystems and the quality of visual data. This study presents a novel approachfor defect detection in casting product noisy images, specifically focusing onsubmersible pump impellers. The methodology involves utilizing deep learningmodels such as VGG16, InceptionV3, and other models in both the spatial andfrequency domains to identify noise types and defect status. The researchprocess begins with preprocessing images, followed by applying denoisingtechniques tailored to specific noise categories. The goal is to enhance theaccuracy and robustness of defect detection by integrating noise detection anddenoising into the classification pipeline. The study achieved remarkableresults using VGG16 for noise type classification in the frequency domain,achieving an accuracy of over 99%. Removal of salt and pepper noise resulted inan average SSIM of 87.9, while Gaussian noise removal had an average SSIM of64.0, and periodic noise removal yielded an average SSIM of 81.6. Thiscomprehensive approach showcases the effectiveness of the deep AutoEncodermodel and median filter, for denoising strategies in real-world industrialapplications. Finally, our study reports significant improvements in binaryclassification accuracy for defect detection compared to previous methods. Forthe VGG16 classifier, accuracy increased from 94.6% to 97.0%, demonstrating theeffectiveness of the proposed noise detection and denoising approach.Similarly, for the InceptionV3 classifier, accuracy improved from 84.7% to90.0%, further validating the benefits of integrating noise analysis into theclassification pipeline.</description><author>Mohsen Hami, Mahdi JameBozorg</author><pubDate>Tue, 16 Apr 2024 16:40:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10664v1</guid></item><item><title>Continual Offline Reinforcement Learning via Diffusion-based Dual Generative Replay</title><link>http://arxiv.org/abs/2404.10662v1</link><description>We study continual offline reinforcement learning, a practical paradigm thatfacilitates forward transfer and mitigates catastrophic forgetting to tacklesequential offline tasks. We propose a dual generative replay framework thatretains previous knowledge by concurrent replay of generated pseudo-data.First, we decouple the continual learning policy into a diffusion-basedgenerative behavior model and a multi-head action evaluation model, allowingthe policy to inherit distributional expressivity for encompassing aprogressive range of diverse behaviors. Second, we train a task-conditioneddiffusion model to mimic state distributions of past tasks. Generated statesare paired with corresponding responses from the behavior generator torepresent old tasks with high-fidelity replayed samples. Finally, byinterleaving pseudo samples with real ones of the new task, we continuallyupdate the state and behavior generators to model progressively diversebehaviors, and regularize the multi-head critic via behavior cloning tomitigate forgetting. Experiments demonstrate that our method achieves betterforward transfer with less forgetting, and closely approximates the results ofusing previous ground-truth data due to its high-fidelity replay of the samplespace. Our code is available at\href{https://github.com/NJU-RL/CuGRO}{https://github.com/NJU-RL/CuGRO}.</description><author>Jinmei Liu, Wenbin Li, Xiangyu Yue, Shilin Zhang, Chunlin Chen, Zhi Wang</author><pubDate>Tue, 16 Apr 2024 16:39:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10662v1</guid></item><item><title>Multi-Robot Connected Fermat Spiral Coverage</title><link>http://arxiv.org/abs/2403.13311v3</link><description>We introduce the Multi-Robot Connected Fermat Spiral (MCFS), a novelalgorithmic framework for Multi-Robot Coverage Path Planning (MCPP) that adaptsConnected Fermat Spiral (CFS) from the computer graphics community tomulti-robot coordination for the first time. MCFS uniquely enables theorchestration of multiple robots to generate coverage paths that contour aroundarbitrarily shaped obstacles, a feature that is notably lacking in traditionalmethods. Our framework not only enhances area coverage and optimizes taskperformance, particularly in terms of makespan, for workspaces rich inirregular obstacles but also addresses the challenges of path continuity andcurvature critical for non-holonomic robots by generating smooth paths withoutdecomposing the workspace. MCFS solves MCPP by constructing a graph of isolinesand transforming MCPP into a combinatorial optimization problem, aiming tominimize the makespan while covering all vertices. Our contributions includedeveloping a unified CFS version for scalable and adaptable MCPP, extending itto MCPP with novel optimization techniques for cost reduction and pathcontinuity and smoothness, and demonstrating through extensive experiments thatMCFS outperforms existing MCPP methods in makespan, path curvature, coverageratio, and overlapping ratio. Our research marks a significant step in MCPP,showcasing the fusion of computer graphics and automated planning principles toadvance the capabilities of multi-robot systems in complex environments. Ourcode is available at https://github.com/reso1/MCFS.</description><author>Jingtao Tang, Hang Ma</author><pubDate>Tue, 16 Apr 2024 16:35:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.13311v3</guid></item><item><title>LaVy: Vietnamese Multimodal Large Language Model</title><link>http://arxiv.org/abs/2404.07922v3</link><description>Large Language Models (LLMs) and Multimodal Large language models (MLLMs)have taken the world by storm with impressive abilities in complex reasoningand linguistic comprehension. Meanwhile there are plethora of works related toVietnamese Large Language Models, the lack of high-quality resources inmultimodality limits the progress of Vietnamese MLLMs. In this paper, wepioneer in address this by introducing LaVy, a state-of-the-art VietnameseMLLM, and we also introduce LaVy-Bench benchmark designated for evaluatingMLLMs's understanding on Vietnamese visual language tasks. Our project ispublic at https://github.com/baochi0212/LaVy</description><author>Chi Tran, Huong Le Thanh</author><pubDate>Tue, 16 Apr 2024 16:33:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07922v3</guid></item><item><title>TrustSQL: A Reliability Benchmark for Text-to-SQL Models with Diverse Unanswerable Questions</title><link>http://arxiv.org/abs/2403.15879v2</link><description>Recent advances in large language models (LLMs) have led to significantimprovements in translating natural language questions into SQL queries. Whileachieving high accuracy in SQL generation is crucial, little is known about theextent to which these text-to-SQL models can reliably handle diverse types ofquestions encountered during real-world deployment, including unanswerableones. To explore this aspect, we introduce TrustSQL, a new benchmark designedto assess the reliability of text-to-SQL models in both single-database andcross-database settings. TrustSQL requires models to provide one of twooutputs: 1) an SQL prediction or 2) abstention from making an SQL prediction,either due to potential errors in the generated SQL or when faced withunanswerable questions. For model evaluation, we explore various modelingapproaches specifically designed for this task: 1) optimizing separate modelsfor answerability detection, SQL generation, and error detection, which arethen integrated into a single pipeline; and 2) developing a unified approachthat uses a single model to solve this task. Experimental results using our newreliability score show that addressing this challenge involves many differentareas of research and opens new avenues for model development. However, none ofthe methods consistently surpasses the reliability scores of a naive baselinethat abstains from SQL predictions for all questions, with varying penalties.</description><author>Gyubok Lee, Woosog Chay, Seonhee Cho, Edward Choi</author><pubDate>Tue, 16 Apr 2024 16:33:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.15879v2</guid></item><item><title>Active learning of Boltzmann samplers and potential energies with quantum mechanical accuracy</title><link>http://arxiv.org/abs/2401.16487v2</link><description>Extracting consistent statistics between relevant free-energy minima of amolecular system is essential for physics, chemistry and biology. Moleculardynamics (MD) simulations can aid in this task but are computationallyexpensive, especially for systems that require quantum accuracy. To overcomethis challenge, we develop an approach combining enhanced sampling with deepgenerative models and active learning of a machine learning potential (MLP). Weintroduce an adaptive Markov chain Monte Carlo framework that enables thetraining of one Normalizing Flow (NF) and one MLP per state, achieving rapidconvergence towards the Boltzmann distribution. Leveraging the trained NF andMLP models, we compute thermodynamic observables such as free-energydifferences or optical spectra. We apply this method to study the isomerizationof an ultrasmall silver nanocluster, belonging to a set of systems with diverseapplications in the fields of medicine and catalysis.</description><author>Ana Molina-Taborda, Pilar Cossio, Olga Lopez-Acevedo, Marylou Gabrié</author><pubDate>Tue, 16 Apr 2024 16:28:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16487v2</guid></item><item><title>ViTextVQA: A Large-Scale Visual Question Answering Dataset for Evaluating Vietnamese Text Comprehension in Images</title><link>http://arxiv.org/abs/2404.10652v1</link><description>Visual Question Answering (VQA) is a complicated task that requires thecapability of simultaneously processing natural language and images. Initially,this task was researched, focusing on methods to help machines understandobjects and scene contexts in images. However, some text appearing in the imagethat carries explicit information about the full content of the image is notmentioned. Along with the continuous development of the AI era, there have beenmany studies on the reading comprehension ability of VQA models in the world.As a developing country, conditions are still limited, and this task is stillopen in Vietnam. Therefore, we introduce the first large-scale dataset inVietnamese specializing in the ability to understand text appearing in images,we call it ViTextVQA (\textbf{Vi}etnamese \textbf{Text}-based \textbf{V}isual\textbf{Q}uestion \textbf{A}nswering dataset) which contains \textbf{over16,000} images and \textbf{over 50,000} questions with answers. Throughmeticulous experiments with various state-of-the-art models, we uncover thesignificance of the order in which tokens in OCR text are processed andselected to formulate answers. This finding helped us significantly improve theperformance of the baseline models on the ViTextVQA dataset. Our dataset isavailable at this\href{https://github.com/minhquan6203/ViTextVQA-Dataset}{link} for researchpurposes.</description><author>Quan Van Nguyen, Dan Quang Tran, Huy Quang Pham, Thang Kien-Bao Nguyen, Nghia Hieu Nguyen, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen</author><pubDate>Tue, 16 Apr 2024 16:28:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10652v1</guid></item><item><title>Mori-Zwanzig latent space Koopman closure for nonlinear autoencoder</title><link>http://arxiv.org/abs/2310.10745v2</link><description>The Koopman operator presents an attractive approach to achieve globallinearization of nonlinear systems, making it a valuable method for simplifyingthe understanding of complex dynamics. While data-driven methodologies haveexhibited promise in approximating finite Koopman operators, they grapple withvarious challenges, such as the judicious selection of observables,dimensionality reduction, and the ability to predict complex system behaviorsaccurately. This study presents a novel approach termed Mori-Zwanzigautoencoder (MZ-AE) to robustly approximate the Koopman operator inlow-dimensional spaces. The proposed method leverages a nonlinear autoencoderto extract key observables for approximating a finite invariant Koopmansubspace and integrates a non-Markovian correction mechanism using theMori-Zwanzig formalism. Consequently, this approach yields a closedrepresentation of dynamics within the latent manifold of the nonlinearautoencoder, thereby enhancing the precision and stability of the Koopmanoperator approximation. Demonstrations showcase the technique's ability tocapture regime transitions in the flow around a cylinder. It also provides alow dimensional approximation for Kuramoto-Sivashinsky with promisingshort-term predictability and robust long-term statistical performance. Bybridging the gap between data-driven techniques and the mathematicalfoundations of Koopman theory, MZ-AE offers a promising avenue for improvedunderstanding and prediction of complex nonlinear dynamics.</description><author>Priyam Gupta, Peter J. Schmid, Denis Sipp, Taraneh Sayadi, Georgios Rigas</author><pubDate>Tue, 16 Apr 2024 16:22:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10745v2</guid></item><item><title>Efficient Parking Search using Shared Fleet Data</title><link>http://arxiv.org/abs/2404.10646v1</link><description>Finding an available on-street parking spot is a relevant problem ofday-to-day life. In recent years, cities such as Melbourne and San Franciscodeployed sensors that provide real-time information about the occupation ofparking spots. Finding a free parking spot in such a smart environment can bemodeled and solved as a Markov decision process (MDP). The problem has toconsider uncertainty as available parking spots might not remain availableuntil arrival due to other vehicles also claiming spots in the meantime.Knowing the parking intention of every vehicle in the environment wouldeliminate this uncertainty. Unfortunately, it does currently not seem realisticto have such data from all vehicles. In contrast, acquiring data from a subsetof vehicles or a vehicle fleet appears feasible and has the potential to reduceuncertainty. In this paper, we examine the question of how useful sharing data within avehicle fleet might be for the search times of particular drivers. We use fleetdata to better estimate the availability of parking spots at arrival. Sinceoptimal solutions for large scenarios are infeasible, we base our method onapproximate solutions, which have been shown to perform well in single-agentsettings. Our experiments are conducted on a simulation using real-world andsynthetic data from the city of Melbourne. The results indicate that fleet datacan significantly reduce search times for an available parking spot.</description><author>Niklas Strauß, Lukas Rottkamp, Sebatian Schmoll, Matthias Schubert</author><pubDate>Tue, 16 Apr 2024 16:20:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10646v1</guid></item><item><title>Continuous Control Reinforcement Learning: Distributed Distributional DrQ Algorithms</title><link>http://arxiv.org/abs/2404.10645v1</link><description>Distributed Distributional DrQ is a model-free and off-policy RL algorithmfor continuous control tasks based on the state and observation of the agent,which is an actor-critic method with the data-augmentation and thedistributional perspective of critic value function. Aim to learn to controlthe agent and master some tasks in a high-dimensional continuous space. DrQ-v2uses DDPG as the backbone and achieves out-performance in various continuouscontrol tasks. Here Distributed Distributional DrQ uses DistributedDistributional DDPG as the backbone, and this modification aims to achievebetter performance in some hard continuous control tasks through the betterexpression ability of distributional value function and distributed actorpolicies.</description><author>Zehao Zhou</author><pubDate>Tue, 16 Apr 2024 16:18:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10645v1</guid></item><item><title>Self-playing Adversarial Language Game Enhances LLM Reasoning</title><link>http://arxiv.org/abs/2404.10642v1</link><description>We explore the self-play training procedure of large language models (LLMs)in a two-player adversarial language game called Adversarial Taboo. In thisgame, an attacker and a defender communicate with respect to a target word onlyvisible to the attacker. The attacker aims to induce the defender to utter thetarget word unconsciously, while the defender tries to infer the target wordfrom the attacker's utterances. To win the game, both players should havesufficient knowledge about the target word and high-level reasoning ability toinfer and express in this information-reserved conversation. Hence, we arecurious about whether LLMs' reasoning ability can be further enhanced bySelf-Play in this Adversarial language Game (SPAG). With this goal, we let LLMsact as the attacker and play with a copy of itself as the defender on anextensive range of target words. Through reinforcement learning on the gameoutcomes, we observe that the LLMs' performance uniformly improves on a broadrange of reasoning benchmarks. Furthermore, iteratively adopting this self-playprocess can continuously promote LLM's reasoning ability. The code is athttps://github.com/Linear95/SPAG.</description><author>Pengyu Cheng, Tianhao Hu, Han Xu, Zhisong Zhang, Yong Dai, Lei Han, Nan Du</author><pubDate>Tue, 16 Apr 2024 16:16:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10642v1</guid></item><item><title>HOEG: A New Approach for Object-Centric Predictive Process Monitoring</title><link>http://arxiv.org/abs/2404.05316v2</link><description>Predictive Process Monitoring focuses on predicting future states of ongoingprocess executions, such as forecasting the remaining time. Recent developmentsin Object-Centric Process Mining have enriched event data with objects andtheir explicit relations between events. To leverage this enriched data, wepropose the Heterogeneous Object Event Graph encoding (HOEG), which integratesevents and objects into a graph structure with diverse node types. It does sowithout aggregating object features, thus creating a more nuanced andinformative representation. We then adopt a heterogeneous Graph Neural Networkarchitecture, which incorporates these diverse object features in predictiontasks. We evaluate the performance and scalability of HOEG in predictingremaining time, benchmarking it against two established graph-based encodingsand two baseline models. Our evaluation uses three Object-Centric Event Logs(OCELs), including one from a real-life process at a major Dutch financialinstitution. The results indicate that HOEG competes well with existing modelsand surpasses them when OCELs contain informative object attributes andevent-object interactions.</description><author>Tim K. Smit, Hajo A. Reijers, Xixi Lu</author><pubDate>Tue, 16 Apr 2024 16:14:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.05316v2</guid></item><item><title>WebArena: A Realistic Web Environment for Building Autonomous Agents</title><link>http://arxiv.org/abs/2307.13854v4</link><description>With advances in generative AI, there is now potential for autonomous agentsto manage daily tasks via natural language commands. However, current agentsare primarily created and tested in simplified synthetic environments, leadingto a disconnect with real-world scenarios. In this paper, we build anenvironment for language-guided agents that is highly realistic andreproducible. Specifically, we focus on agents that perform tasks on the web,and create an environment with fully functional websites from four commondomains: e-commerce, social forum discussions, collaborative softwaredevelopment, and content management. Our environment is enriched with tools(e.g., a map) and external knowledge bases (e.g., user manuals) to encouragehuman-like task-solving. Building upon our environment, we release a set ofbenchmark tasks focusing on evaluating the functional correctness of taskcompletions. The tasks in our benchmark are diverse, long-horizon, and designedto emulate tasks that humans routinely perform on the internet. We experimentwith several baseline agents, integrating recent techniques such as reasoningbefore acting. The results demonstrate that solving complex tasks ischallenging: our best GPT-4-based agent only achieves an end-to-end tasksuccess rate of 14.41%, significantly lower than the human performance of78.24%. These results highlight the need for further development of robustagents, that current state-of-the-art large language models are far fromperfect performance in these real-life tasks, and that WebArena can be used tomeasure such progress.</description><author>Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Tianyue Ou, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig</author><pubDate>Tue, 16 Apr 2024 16:13:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13854v4</guid></item><item><title>Contextrast: Contextual Contrastive Learning for Semantic Segmentation</title><link>http://arxiv.org/abs/2404.10633v1</link><description>Despite great improvements in semantic segmentation, challenges persistbecause of the lack of local/global contexts and the relationship between them.In this paper, we propose Contextrast, a contrastive learning-based semanticsegmentation method that allows to capture local/global contexts and comprehendtheir relationships. Our proposed method comprises two parts: a) contextualcontrastive learning (CCL) and b) boundary-aware negative (BANE) sampling.Contextual contrastive learning obtains local/global context from multi-scalefeature aggregation and inter/intra-relationship of features for betterdiscrimination capabilities. Meanwhile, BANE sampling selects embeddingfeatures along the boundaries of incorrectly predicted regions to employ themas harder negative samples on our contrastive learning, resolving segmentationissues along the boundary region by exploiting fine-grained details. Wedemonstrate that our Contextrast substantially enhances the performance ofsemantic segmentation networks, outperforming state-of-the-art contrastivelearning approaches on diverse public datasets, e.g. Cityscapes, CamVid,PASCAL-C, COCO-Stuff, and ADE20K, without an increase in computational costduring inference.</description><author>Changki Sung, Wanhee Kim, Jungho An, Wooju Lee, Hyungtae Lim, Hyun Myung</author><pubDate>Tue, 16 Apr 2024 16:04:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10633v1</guid></item><item><title>HLAT: High-quality Large Language Model Pre-trained on AWS Trainium</title><link>http://arxiv.org/abs/2404.10630v1</link><description>Getting large language models (LLMs) to perform well on the downstream tasksrequires pre-training over trillions of tokens. This typically demands a largenumber of powerful computational devices in addition to a stable distributedtraining framework to accelerate the training. The growing number ofapplications leveraging AI/ML had led to a scarcity of the expensiveconventional accelerators (such as GPUs), which begs the need for thealternative specialized-accelerators that are scalable and cost-efficient. AWSTrainium is the second-generation machine learning accelerator that has beenpurposely built for training large deep learning models. Its correspondinginstance, Amazon EC2 trn1, is an alternative to GPU instances for LLM training.However, training LLMs with billions of parameters on trn1 is challenging dueto its relatively nascent software ecosystem. In this paper, we showcase HLAT:a 7 billion parameter decoder-only LLM pre-trained using trn1 instances over1.8 trillion tokens. The performance of HLAT is benchmarked against popularopen source baseline models including LLaMA and OpenLLaMA, which have beentrained on NVIDIA GPUs and Google TPUs, respectively. On various evaluationtasks, we show that HLAT achieves model quality on par with the baselines. Wealso share the best practice of using the Neuron Distributed Training Library(NDTL), a customized distributed training library for AWS Trainium to achieveefficient training. Our work demonstrates that AWS Trainium powered by the NDTLis able to successfully pre-train state-of-the-art LLM models with highperformance and cost-effectiveness.</description><author>Haozheng Fan, Hao Zhou, Guangtai Huang, Parameswaran Raman, Xinwei Fu, Gaurav Gupta, Dhananjay Ram, Yida Wang, Jun Huan</author><pubDate>Tue, 16 Apr 2024 16:02:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10630v1</guid></item><item><title>Benchingmaking Large Langage Models in Biomedical Triple Extraction</title><link>http://arxiv.org/abs/2310.18463v4</link><description>Biomedical triple extraction systems aim to automatically extract biomedicalentities and relations between entities. The exploration of applying largelanguage models (LLM) to triple extraction is still relatively unexplored. Inthis work, we mainly focus on sentence-level biomedical triple extraction.Furthermore, the absence of a high-quality biomedical triple extraction datasetimpedes the progress in developing robust triple extraction systems. To addressthese challenges, initially, we compare the performance of various largelanguage models. Additionally, we present GIT, an expert-annotated biomedicaltriple extraction dataset that covers a wider range of relation types.</description><author>Mingchen Li, Huixue Zhou, Rui Zhang</author><pubDate>Tue, 16 Apr 2024 16:00:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18463v4</guid></item><item><title>LoopAnimate: Loopable Salient Object Animation</title><link>http://arxiv.org/abs/2404.09172v2</link><description>Research on diffusion model-based video generation has advanced rapidly.However, limitations in object fidelity and generation length hinder itspractical applications. Additionally, specific domains like animated wallpapersrequire seamless looping, where the first and last frames of the video matchseamlessly. To address these challenges, this paper proposes LoopAnimate, anovel method for generating videos with consistent start and end frames. Toenhance object fidelity, we introduce a framework that decouples multi-levelimage appearance and textual semantic information. Building upon animage-to-image diffusion model, our approach incorporates both pixel-level andfeature-level information from the input image, injecting image appearance andtextual semantic embeddings at different positions of the diffusion model.Existing UNet-based video generation models require to input the entire videosduring training to encode temporal and positional information at once. However,due to limitations in GPU memory, the number of frames is typically restrictedto 16. To address this, this paper proposes a three-stage training strategywith progressively increasing frame numbers and reducing fine-tuning modules.Additionally, we introduce the Temporal E nhanced Motion Module(TEMM) to extendthe capacity for encoding temporal and positional information up to 36 frames.The proposed LoopAnimate, which for the first time extends the single-passgeneration length of UNet-based video generation models to 35 frames whilemaintaining high-quality video generation. Experiments demonstrate thatLoopAnimate achieves state-of-the-art performance in both objective metrics,such as fidelity and temporal consistency, and subjective evaluation results.</description><author>Fanyi Wang, Peng Liu, Haotian Hu, Dan Meng, Jingwen Su, Jinjin Xu, Yanhao Zhang, Xiaoming Ren, Zhiwang Zhang</author><pubDate>Tue, 16 Apr 2024 15:56:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09172v2</guid></item><item><title>Anatomy of Industrial Scale Multilingual ASR</title><link>http://arxiv.org/abs/2404.09841v2</link><description>This paper describes AssemblyAI's industrial-scale automatic speechrecognition (ASR) system, designed to meet the requirements of large-scale,multilingual ASR serving various application needs. Our system leverages adiverse training dataset comprising unsupervised (12.5M hours), supervised(188k hours), and pseudo-labeled (1.6M hours) data across four languages. Weprovide a detailed description of our model architecture, consisting of afull-context 600M-parameter Conformer encoder pre-trained with BEST-RQ and anRNN-T decoder fine-tuned jointly with the encoder. Our extensive evaluationdemonstrates competitive word error rates (WERs) against larger and morecomputationally expensive models, such as Whisper large and Canary-1B.Furthermore, our architectural choices yield several key advantages, includingan improved code-switching capability, a 5x inference speedup compared to anoptimized Whisper baseline, a 30% reduction in hallucination rate on speechdata, and a 90% reduction in ambient noise compared to Whisper, along withsignificantly improved time-stamp accuracy. Throughout this work, we adopt asystem-centric approach to analyzing various aspects of fully-fledged ASRmodels to gain practically relevant insights useful for real-world servicesoperating at scale.</description><author>Francis McCann Ramirez, Luka Chkhetiani, Andrew Ehrenberg, Robert McHardy, Rami Botros, Yash Khare, Andrea Vanzo, Taufiquzzaman Peyash, Gabriel Oexle, Michael Liang, Ilya Sklyar, Enver Fakhan, Ahmed Etefy, Daniel McCrystal, Sam Flamini, Domenic Donato, Takuya Yoshioka</author><pubDate>Tue, 16 Apr 2024 15:55:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09841v2</guid></item><item><title>Exploring selective image matching methods for zero-shot and few-sample unsupervised domain adaptation of urban canopy prediction</title><link>http://arxiv.org/abs/2404.10626v1</link><description>We explore simple methods for adapting a trained multi-task UNet whichpredicts canopy cover and height to a new geographic setting using remotelysensed data without the need of training a domain-adaptive classifier andextensive fine-tuning. Extending previous research, we followed a selectivealignment process to identify similar images in the two geographical domainsand then tested an array of data-based unsupervised domain adaptationapproaches in a zero-shot setting as well as with a small amount offine-tuning. We find that the selective aligned data-based image matchingmethods produce promising results in a zero-shot setting, and even more so witha small amount of fine-tuning. These methods outperform both an untransformedbaseline and a popular data-based image-to-image translation model. The bestperforming methods were pixel distribution adaptation and fourier domainadaptation on the canopy cover and height tasks respectively.</description><author>John Francis, Stephen Law</author><pubDate>Tue, 16 Apr 2024 15:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10626v1</guid></item><item><title>Gaussian Splatting Decoder for 3D-aware Generative Adversarial Networks</title><link>http://arxiv.org/abs/2404.10625v1</link><description>NeRF-based 3D-aware Generative Adversarial Networks (GANs) like EG3D orGIRAFFE have shown very high rendering quality under large representationalvariety. However, rendering with Neural Radiance Fields poses challenges for 3Dapplications: First, the significant computational demands of NeRF renderingpreclude its use on low-power devices, such as mobiles and VR/AR headsets.Second, implicit representations based on neural networks are difficult toincorporate into explicit 3D scenes, such as VR environments or video games. 3DGaussian Splatting (3DGS) overcomes these limitations by providing an explicit3D representation that can be rendered efficiently at high frame rates. In thiswork, we present a novel approach that combines the high rendering quality ofNeRF-based 3D-aware GANs with the flexibility and computational advantages of3DGS. By training a decoder that maps implicit NeRF representations to explicit3D Gaussian Splatting attributes, we can integrate the representationaldiversity and quality of 3D GANs into the ecosystem of 3D Gaussian Splattingfor the first time. Additionally, our approach allows for a high resolution GANinversion and real-time GAN editing with 3D Gaussian Splatting scenes.</description><author>Florian Barthel, Arian Beckmann, Wieland Morgenstern, Anna Hilsmann, Peter Eisert</author><pubDate>Tue, 16 Apr 2024 15:48:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10625v1</guid></item><item><title>CoBra: Complementary Branch Fusing Class and Semantic Knowledge for Robust Weakly Supervised Semantic Segmentation</title><link>http://arxiv.org/abs/2403.08801v5</link><description>Leveraging semantically precise pseudo masks derived from image-level classknowledge for segmentation, namely image-level Weakly Supervised SemanticSegmentation (WSSS), still remains challenging. While Class Activation Maps(CAMs) using CNNs have steadily been contributing to the success of WSSS, theresulting activation maps often narrowly focus on class-specific parts (e.g.,only face of human). On the other hand, recent works based on visiontransformers (ViT) have shown promising results based on their self-attentionmechanism to capture the semantic parts but fail in capturing completeclass-specific details (e.g., entire body parts of human but also with a dognearby). In this work, we propose Complementary Branch (CoBra), a novel dualbranch framework consisting of two distinct architectures which providevaluable complementary knowledge of class (from CNN) and semantic (from ViT) toeach branch. In particular, we learn Class-Aware Projection (CAP) for the CNNbranch and Semantic-Aware Projection (SAP) for the ViT branch to explicitlyfuse their complementary knowledge and facilitate a new type of extrapatch-level supervision. Our model, through CoBra, fuses CNN and ViT'scomplementary outputs to create robust pseudo masks that integrate both classand semantic information effectively. Extensive experiments qualitatively andquantitatively investigate how CNN and ViT complement each other on the PASCALVOC 2012 dataset, showing a state-of-the-art WSSS result. This includes notonly the masks generated by our model, but also the segmentation resultsderived from utilizing these masks as pseudo labels.</description><author>Woojung Han, Seil Kang, Kyobin Choo, Seong Jae Hwang</author><pubDate>Tue, 16 Apr 2024 15:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08801v5</guid></item></channel></rss>