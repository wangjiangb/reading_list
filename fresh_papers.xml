<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 03 Jan 2024 14:00:10 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Street Gaussians for Modeling Dynamic Urban Scenes</title><link>http://arxiv.org/abs/2401.01339v1</link><description>This paper aims to tackle the problem of modeling dynamic urban street scenesfrom monocular videos. Recent methods extend NeRF by incorporating trackedvehicle poses to animate vehicles, enabling photo-realistic view synthesis ofdynamic urban street scenes. However, significant limitations are their slowtraining and rendering speed, coupled with the critical need for high precisionin tracked vehicle poses. We introduce Street Gaussians, a new explicit scenerepresentation that tackles all these limitations. Specifically, the dynamicurban street is represented as a set of point clouds equipped with semanticlogits and 3D Gaussians, each associated with either a foreground vehicle orthe background. To model the dynamics of foreground object vehicles, eachobject point cloud is optimized with optimizable tracked poses, along with adynamic spherical harmonics model for the dynamic appearance. The explicitrepresentation allows easy composition of object vehicles and background, whichin turn allows for scene editing operations and rendering at 133 FPS(1066$\times$1600 resolution) within half an hour of training. The proposedmethod is evaluated on multiple challenging benchmarks, including KITTI andWaymo Open datasets. Experiments show that the proposed method consistentlyoutperforms state-of-the-art methods across all datasets. Furthermore, theproposed representation delivers performance on par with that achieved usingprecise ground-truth poses, despite relying only on poses from an off-the-shelftracker. The code is available at https://zju3dv.github.io/street_gaussians/.</description><author>Yunzhi Yan, Haotong Lin, Chenxu Zhou, Weijie Wang, Haiyang Sun, Kun Zhan, Xianpeng Lang, Xiaowei Zhou, Sida Peng</author><pubDate>Tue, 02 Jan 2024 18:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01339v1</guid></item><item><title>Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models</title><link>http://arxiv.org/abs/2401.01335v1</link><description>Harnessing the power of human-annotated data through Supervised Fine-Tuning(SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, wedelve into the prospect of growing a strong LLM out of a weak one without theneed for acquiring additional human-annotated data. We propose a newfine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from asupervised fine-tuned model. At the heart of SPIN lies a self-play mechanism,where the LLM refines its capability by playing against instances of itself.More specifically, the LLM generates its own training data from its previousiterations, refining its policy by discerning these self-generated responsesfrom those obtained from human-annotated data. Our method progressivelyelevates the LLM from a nascent model to a formidable one, unlocking the fullpotential of human-annotated demonstration data for SFT. Theoretically, weprove that the global optimum to the training objective function of our methodis achieved only when the LLM policy aligns with the target data distribution.Empirically, we evaluate our method on several benchmark datasets including theHuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Ourresults show that SPIN can significantly improve the LLM's performance across avariety of benchmarks and even outperform models trained through directpreference optimization (DPO) supplemented with extra GPT-4 preference data.This sheds light on the promise of self-play, enabling the achievement ofhuman-level performance in LLMs without the need for expert opponents.</description><author>Zixiang Chen, Yihe Deng, Huizhuo Yuan, Kaixuan Ji, Quanquan Gu</author><pubDate>Tue, 02 Jan 2024 18:53:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01335v1</guid></item><item><title>Improving Intrusion Detection with Domain-Invariant Representation Learning in Latent Space</title><link>http://arxiv.org/abs/2312.17300v2</link><description>Domain generalization focuses on leveraging knowledge from multiple relateddomains with ample training data and labels to enhance inference on unseenin-distribution (IN) and out-of-distribution (OOD) domains. In our study, weintroduce a two-phase representation learning technique using multi-tasklearning. This approach aims to cultivate a latent space from features spanningmultiple domains, encompassing both native and cross-domains, to amplifygeneralization to IN and OOD territories. Additionally, we attempt todisentangle the latent space by minimizing the mutual information between theprior and latent space, effectively de-correlating spurious featurecorrelations. Collectively, the joint optimization will facilitatedomain-invariant feature learning. We assess the model's efficacy acrossmultiple cybersecurity datasets, using standard classification metrics on bothunseen IN and OOD sets, and juxtapose the results with contemporary domaingeneralization methods.</description><author>Padmaksha Roy, Tyler Cody, Himanshu Singhal, Kevin Choi, Ming Jin</author><pubDate>Tue, 02 Jan 2024 18:43:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17300v2</guid></item><item><title>TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview</title><link>http://arxiv.org/abs/2401.01330v1</link><description>Conversational Information Seeking stands as a pivotal research area withsignificant contributions from previous works. The TREC Interactive KnowledgeAssistance Track (iKAT) builds on the foundational work of the TRECConversational Assistance Track (CAsT). However, iKAT distinctively emphasizesthe creation and research of conversational search agents that adapt responsesbased on user's prior interactions and present context. The challenge lies inenabling Conversational Search Agents (CSA) to incorporate this personalizedcontext to efficiency and effectively guide users through the relevantinformation to them. iKAT also emphasizes decisional search tasks, where userssift through data and information to weigh up options in order to reach aconclusion or perform an action. These tasks, prevalent in everydayinformation-seeking decisions -- be it related to travel, health, or shopping-- often revolve around a subset of high-level information operators wherequeries or questions about the information space include: finding options,comparing options, identifying the pros and cons of options, etc. Given thedifferent personas and their information need (expressed through the sequenceof questions), diverse conversation trajectories will arise -- because theanswers to these similar queries will be very different. In this paper, wereport on the first year of TREC iKAT, describing the task, topics, datacollection, and evaluation framework. We further review the submissions andsummarize the findings.</description><author>Mohammad Aliannejadi, Zahra Abbasiantaeb, Shubham Chatterjee, Jeffery Dalton, Leif Azzopardi</author><pubDate>Tue, 02 Jan 2024 18:40:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01330v1</guid></item><item><title>An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction</title><link>http://arxiv.org/abs/2401.01326v1</link><description>In this paper, we propose a novel method for joint entity and relationextraction from unstructured text by framing it as a conditional sequencegeneration problem. In contrast to conventional generative informationextraction models that are left-to-right token-level generators, our approachis \textit{span-based}. It generates a linearized graph where nodes representtext spans and edges represent relation triplets. Our method employs atransformer encoder-decoder architecture with pointing mechanism on a dynamicvocabulary of spans and relation types. Our model can capture the structuralcharacteristics and boundaries of entities and relations through spanrepresentations while simultaneously grounding the generated output in theoriginal text thanks to the pointing mechanism. Evaluation on benchmarkdatasets validates the effectiveness of our approach, demonstrating competitiveresults. Code is available at https://github.com/urchade/ATG.</description><author>Zaratiana Urchade, Nadi Tomeh, Pierre Holat, Thierry Charnois</author><pubDate>Tue, 02 Jan 2024 18:32:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01326v1</guid></item><item><title>LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning</title><link>http://arxiv.org/abs/2401.01325v1</link><description>This work elicits LLMs' inherent ability to handle long contexts withoutfine-tuning. The limited length of the training sequence during training maylimit the application of Large Language Models (LLMs) on long input sequencesfor inference. In this work, we argue that existing LLMs themselves haveinherent capabilities for handling long contexts. Based on this argument, wesuggest extending LLMs' context window by themselves to fully utilize theinherent ability.We propose Self-Extend to stimulate LLMs' long contexthandling potential. The basic idea is to construct bi-level attentioninformation: the group level and the neighbor level. The two levels arecomputed by the original model's self-attention, which means the proposed doesnot require any training. With only four lines of code modification, theproposed method can effortlessly extend existing LLMs' context window withoutany fine-tuning. We conduct comprehensive experiments and the results show thatthe proposed method can effectively extend existing LLMs' context window'slength.</description><author>Hongye Jin, Xiaotian Han, Jingfeng Yang, Zhimeng Jiang, Zirui Liu, Chia-Yuan Chang, Huiyuan Chen, Xia Hu</author><pubDate>Tue, 02 Jan 2024 18:30:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01325v1</guid></item><item><title>Sample-Efficient Safety Assurances using Conformal Prediction</title><link>http://arxiv.org/abs/2109.14082v5</link><description>When deploying machine learning models in high-stakes robotics applications,the ability to detect unsafe situations is crucial. Early warning systems canprovide alerts when an unsafe situation is imminent (in the absence ofcorrective action). To reliably improve safety, these warning systems shouldhave a provable false negative rate; i.e. of the situations that are unsafe,fewer than $\epsilon$ will occur without an alert. In this work, we present aframework that combines a statistical inference technique known as conformalprediction with a simulator of robot/environment dynamics, in order to tunewarning systems to provably achieve an $\epsilon$ false negative rate using asfew as $1/\epsilon$ data points. We apply our framework to a driver warningsystem and a robotic grasping application, and empirically demonstrateguaranteed false negative rate while also observing low false detection(positive) rate.</description><author>Rachel Luo, Shengjia Zhao, Jonathan Kuck, Boris Ivanovic, Silvio Savarese, Edward Schmerling, Marco Pavone</author><pubDate>Tue, 02 Jan 2024 18:23:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.14082v5</guid></item><item><title>A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models</title><link>http://arxiv.org/abs/2401.01313v1</link><description>As Large Language Models (LLMs) continue to advance in their ability to writehuman-like text, a key challenge remains around their tendency to hallucinategenerating content that appears factual but is ungrounded. This issue ofhallucination is arguably the biggest hindrance to safely deploying thesepowerful LLMs into real-world production systems that impact people's lives.The journey toward widespread adoption of LLMs in practical settings heavilyrelies on addressing and mitigating hallucinations. Unlike traditional AIsystems focused on limited tasks, LLMs have been exposed to vast amounts ofonline text data during training. While this allows them to display impressivelanguage fluency, it also means they are capable of extrapolating informationfrom the biases in training data, misinterpreting ambiguous prompts, ormodifying the information to align superficially with the input. This becomeshugely alarming when we rely on language generation capabilities for sensitiveapplications, such as summarizing medical records, financial analysis reports,etc. This paper presents a comprehensive survey of over 32 techniques developedto mitigate hallucination in LLMs. Notable among these are Retrieval AugmentedGeneration (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023),CoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023). Furthermore, weintroduce a detailed taxonomy categorizing these methods based on variousparameters, such as dataset utilization, common tasks, feedback mechanisms, andretriever types. This classification helps distinguish the diverse approachesspecifically designed to tackle hallucination issues in LLMs. Additionally, weanalyze the challenges and limitations inherent in these techniques, providinga solid foundation for future research in addressing hallucinations and relatedphenomena within the realm of LLMs.</description><author>S. M Towhidul Islam Tonmoy, S M Mehedi Zaman, Vinija Jain, Anku Rani, Vipula Rawte, Aman Chadha, Amitava Das</author><pubDate>Tue, 02 Jan 2024 17:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01313v1</guid></item><item><title>OpenVoice: Versatile Instant Voice Cloning</title><link>http://arxiv.org/abs/2312.01479v5</link><description>We introduce OpenVoice, a versatile voice cloning approach that requires onlya short audio clip from the reference speaker to replicate their voice andgenerate speech in multiple languages. OpenVoice represents a significantadvancement in addressing the following open challenges in the field: 1)Flexible Voice Style Control. OpenVoice enables granular control over voicestyles, including emotion, accent, rhythm, pauses, and intonation, in additionto replicating the tone color of the reference speaker. The voice styles arenot directly copied from and constrained by the style of the reference speaker.Previous approaches lacked the ability to flexibly manipulate voice stylesafter cloning. 2) Zero-Shot Cross-Lingual Voice Cloning. OpenVoice achieveszero-shot cross-lingual voice cloning for languages not included in themassive-speaker training set. Unlike previous approaches, which typicallyrequire extensive massive-speaker multi-lingual (MSML) dataset for alllanguages, OpenVoice can clone voices into a new language without anymassive-speaker training data for that language. OpenVoice is alsocomputationally efficient, costing tens of times less than commerciallyavailable APIs that offer even inferior performance. To foster further researchin the field, we have made the source code and trained model publiclyaccessible. We also provide qualitative results in our demo website. Prior toits public release, our internal version of OpenVoice was used tens of millionsof times by users worldwide between May and October 2023, serving as thebackend of MyShell.</description><author>Zengyi Qin, Wenliang Zhao, Xumin Yu, Xin Sun</author><pubDate>Tue, 02 Jan 2024 17:45:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.01479v5</guid></item><item><title>Learning solutions to some toy constrained optimization problems in infinite dimensional Hilbert spaces</title><link>http://arxiv.org/abs/2401.01306v1</link><description>In this work we present deep learning implementations of two populartheoretical constrained optimization algorithms in infinite dimensional Hilbertspaces, namely, the penalty and the augmented Lagrangian methods. We test thesealgorithms on some toy problems originating in either calculus of variations orphysics. We demonstrate that both methods are able to produce decentapproximations for the test problems and are comparable in terms of differenterrors. Leveraging the common occurrence of the Lagrange multiplier update rulebeing computationally less expensive than solving subproblems in the penaltymethod, we achieve significant speedups in cases when the output of theconstraint function is itself a function.</description><author>Pinak Mandal</author><pubDate>Tue, 02 Jan 2024 17:32:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01306v1</guid></item><item><title>Experimental Validation of Sensor Fusion-based GNSS Spoofing Attack Detection Framework for Autonomous Vehicles</title><link>http://arxiv.org/abs/2401.01304v1</link><description>In this paper, we validate the performance of the a sensor fusion-basedGlobal Navigation Satellite System (GNSS) spoofing attack detection frameworkfor Autonomous Vehicles (AVs). To collect data, a vehicle equipped with a GNSSreceiver, along with Inertial Measurement Unit (IMU) is used. The detectionframework incorporates two strategies: The first strategy involves comparingthe predicted location shift, which is the distance traveled between twoconsecutive timestamps, with the inertial sensor-based location shift. For thispurpose, data from low-cost in-vehicle inertial sensors such as theaccelerometer and gyroscope sensor are fused and fed into a long short-termmemory (LSTM) neural network. The second strategy employs a Random-Forestsupervised machine learning model to detect and classify turns, distinguishingbetween left and right turns using the output from the steering angle sensor.In experiments, two types of spoofing attack models: turn-by-turn and wrongturn are simulated. These spoofing attacks are modeled as SQL injectionattacks, where, upon successful implementation, the navigation system perceivesinjected spoofed location information as legitimate while being unable todetect legitimate GNSS signals. Importantly, the IMU data remains uncompromisedthroughout the spoofing attack. To test the effectiveness of the detectionframework, experiments are conducted in Tuscaloosa, AL, mimicking urban roadstructures. The results demonstrate the framework's ability to detect varioussophisticated GNSS spoofing attacks, even including slow position driftingattacks. Overall, the experimental results showcase the robustness and efficacyof the sensor fusion-based spoofing attack detection approach in safeguardingAVs against GNSS spoofing threats.</description><author>Sagar Dasgupta, Kazi Hassan Shakib, Mizanur Rahman</author><pubDate>Tue, 02 Jan 2024 17:30:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01304v1</guid></item><item><title>Integrating Edges into U-Net Models with Explainable Activation Maps for Brain Tumor Segmentation using MR Images</title><link>http://arxiv.org/abs/2401.01303v1</link><description>Manual delineation of tumor regions from magnetic resonance (MR) images istime-consuming, requires an expert, and is prone to human error. In recentyears, deep learning models have been the go-to approach for the segmentationof brain tumors. U-Net and its' variants for semantic segmentation of medicalimages have achieved good results in the literature. However, U-Net and its'variants tend to over-segment tumor regions and may not accurately segment thetumor edges. The edges of the tumor are as important as the tumor regions foraccurate diagnosis, surgical precision, and treatment planning. In the proposedwork, the authors aim to extract edges from the ground truth using aderivative-like filter followed by edge reconstruction to obtain an edge groundtruth in addition to the brain tumor ground truth. Utilizing both groundtruths, the author studies several U-Net and its' variant architectures withand without tumor edges ground truth as a target along with the tumor groundtruth for brain tumor segmentation. The author used the BraTS2020 benchmarkdataset to perform the study and the results are tabulated for the dice andHausdorff95 metrics. The mean and median metrics are calculated for the wholetumor (WT), tumor core (TC), and enhancing tumor (ET) regions. Compared to thebaseline U-Net and its variants, the models that learned edges along with thetumor regions performed well in core tumor regions in both training andvalidation datasets. The improved performance of edge-trained models trained onbaseline models like U-Net and V-Net achieved performance similar to baselinestate-of-the-art models like Swin U-Net and hybrid MR-U-Net. The edge-targettrained models are capable of generating edge maps that can be useful fortreatment planning. Additionally, for further explainability of the results,the activation map generated by the hybrid MR-U-Net has been studied.</description><author>Subin Sahayam, Umarani Jayaraman</author><pubDate>Tue, 02 Jan 2024 17:30:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01303v1</guid></item><item><title>Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models</title><link>http://arxiv.org/abs/2401.01301v1</link><description>Large language models (LLMs) have the potential to transform the practice oflaw, but this potential is threatened by the presence of legal hallucinations-- responses from these models that are not consistent with legal facts. Weinvestigate the extent of these hallucinations using an original suite of legalqueries, comparing LLMs' responses to structured legal metadata and examiningtheir consistency. Our work makes four key contributions: (1) We develop atypology of legal hallucinations, providing a conceptual framework for futureresearch in this area. (2) We find that legal hallucinations are alarminglyprevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% withLlama 2, when these models are asked specific, verifiable questions aboutrandom federal court cases. (3) We illustrate that LLMs often fail to correct auser's incorrect legal assumptions in a contra-factual question setup. (4) Weprovide evidence that LLMs cannot always predict, or do not always know, whenthey are producing legal hallucinations. Taken together, these findings cautionagainst the rapid and unsupervised integration of popular LLMs into legaltasks. Even experienced lawyers must remain wary of legal hallucinations, andthe risks are highest for those who stand to benefit from LLMs the most -- prose litigants or those without access to traditional legal resources.</description><author>Matthew Dahl, Varun Magesh, Mirac Suzgun, Daniel E. Ho</author><pubDate>Tue, 02 Jan 2024 17:28:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01301v1</guid></item><item><title>KeDuSR: Real-World Dual-Lens Super-Resolution via Kernel-Free Matching</title><link>http://arxiv.org/abs/2312.17050v2</link><description>Dual-lens super-resolution (SR) is a practical scenario for reference (Ref)based SR by utilizing the telephoto image (Ref) to assist the super-resolutionof the low-resolution wide-angle image (LR input). Different from generalRefSR, the Ref in dual-lens SR only covers the overlapped field of view (FoV)area. However, current dual-lens SR methods rarely utilize these specificcharacteristics and directly perform dense matching between the LR input andRef. Due to the resolution gap between LR and Ref, the matching may miss thebest-matched candidate and destroy the consistent structures in the overlappedFoV area. Different from them, we propose to first align the Ref with thecenter region (namely the overlapped FoV area) of the LR input by combiningglobal warping and local warping to make the aligned Ref be sharp andconsistent. Then, we formulate the aligned Ref and LR center as value-keypairs, and the corner region of the LR is formulated as queries. In this way,we propose a kernel-free matching strategy by matching between the LR-corner(query) and LR-center (key) regions, and the corresponding aligned Ref (value)can be warped to the corner region of the target. Our kernel-free matchingstrategy avoids the resolution gap between LR and Ref, which makes our networkhave better generalization ability. In addition, we construct a DuSR-Realdataset with (LR, Ref, HR) triples, where the LR and HR are well aligned.Experiments on three datasets demonstrate that our method outperforms thesecond-best method by a large margin. Our code and dataset are available athttps://github.com/ZifanCui/KeDuSR.</description><author>Huanjing Yue, Zifan Cui, Kun Li, Jingyu Yang</author><pubDate>Tue, 02 Jan 2024 17:24:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17050v2</guid></item><item><title>Bridging the Gaps: Learning Verifiable Model-Free Quadratic Programming Controllers Inspired by Model Predictive Control</title><link>http://arxiv.org/abs/2312.05332v3</link><description>In this paper, we introduce a new class of parameterized controllers, drawinginspiration from Model Predictive Control (MPC). The controller resembles aQuadratic Programming (QP) solver of a linear MPC problem, with the parametersof the controller being trained via Deep Reinforcement Learning (DRL) ratherthan derived from system models. This approach addresses the limitations ofcommon controllers with Multi-Layer Perceptron (MLP) or other general neuralnetwork architecture used in DRL, in terms of verifiability and performanceguarantees, and the learned controllers possess verifiable properties likepersistent feasibility and asymptotic stability akin to MPC. On the other hand,numerical examples illustrate that the proposed controller empirically matchesMPC and MLP controllers in terms of control performance and has superiorrobustness against modeling uncertainty and noises. Furthermore, the proposedcontroller is significantly more computationally efficient compared to MPC andrequires fewer parameters to learn than MLP controllers. Real-world experimentson vehicle drift maneuvering task demonstrate the potential of thesecontrollers for robotics and other demanding control tasks.</description><author>Yiwen Lu, Zishuo Li, Yihan Zhou, Na Li, Yilin Mo</author><pubDate>Tue, 02 Jan 2024 17:19:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05332v3</guid></item><item><title>Efficient Sparse Least Absolute Deviation Regression with Differential Privacy</title><link>http://arxiv.org/abs/2401.01294v1</link><description>In recent years, privacy-preserving machine learning algorithms haveattracted increasing attention because of their important applications in manyscientific fields. However, in the literature, most privacy-preservingalgorithms demand learning objectives to be strongly convex and Lipschitzsmooth, which thus cannot cover a wide class of robust loss functions (e.g.,quantile/least absolute loss). In this work, we aim to develop a fastprivacy-preserving learning solution for a sparse robust regression problem.Our learning loss consists of a robust least absolute loss and an $\ell_1$sparse penalty term. To fast solve the non-smooth loss under a given privacybudget, we develop a Fast Robust And Privacy-Preserving Estimation (FRAPPE)algorithm for least absolute deviation regression. Our algorithm achieves afast estimation by reformulating the sparse LAD problem as a penalized leastsquare estimation problem and adopts a three-stage noise injection to guaranteethe $(\epsilon,\delta)$-differential privacy. We show that our algorithm canachieve better privacy and statistical accuracy trade-off compared with thestate-of-the-art privacy-preserving regression algorithms. In the end, weconduct experiments to verify the efficiency of our proposed FRAPPE algorithm.</description><author>Weidong Liu, Xiaojun Mao, Xiaofei Zhang, Xin Zhang</author><pubDate>Tue, 02 Jan 2024 17:13:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01294v1</guid></item><item><title>AI Alignment: A Comprehensive Survey</title><link>http://arxiv.org/abs/2310.19852v3</link><description>AI alignment aims to make AI systems behave in line with human intentions andvalues. As AI systems grow more capable, so do risks from misalignment. Toprovide a comprehensive and up-to-date overview of the alignment field, in thissurvey, we delve into the core concepts, methodology, and practice ofalignment. First, we identify four principles as the key objectives of AIalignment: Robustness, Interpretability, Controllability, and Ethicality(RICE). Guided by these four principles, we outline the landscape of currentalignment research and decompose them into two key components: forwardalignment and backward alignment. The former aims to make AI systems alignedvia alignment training, while the latter aims to gain evidence about thesystems' alignment and govern them appropriately to avoid exacerbatingmisalignment risks. On forward alignment, we discuss techniques for learningfrom feedback and learning under distribution shift. On backward alignment, wediscuss assurance techniques and governance practices. We also release and continually update the website (www.alignmentsurvey.com)which features tutorials, collections of papers, blog posts, and otherresources.</description><author>Jiaming Ji, Tianyi Qiu, Boyuan Chen, Borong Zhang, Hantao Lou, Kaile Wang, Yawen Duan, Zhonghao He, Jiayi Zhou, Zhaowei Zhang, Fanzhi Zeng, Kwan Yee Ng, Juntao Dai, Xuehai Pan, Aidan O'Gara, Yingshan Lei, Hua Xu, Brian Tse, Jie Fu, Stephen McAleer, Yaodong Yang, Yizhou Wang, Song-Chun Zhu, Yike Guo, Wen Gao</author><pubDate>Tue, 02 Jan 2024 17:09:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19852v3</guid></item><item><title>Physics-informed Generalizable Wireless Channel Modeling with Segmentation and Deep Learning: Fundamentals, Methodologies, and Challenges</title><link>http://arxiv.org/abs/2401.01288v1</link><description>Channel modeling is fundamental in advancing wireless systems and has thusattracted considerable research focus. Recent trends have seen a growingreliance on data-driven techniques to facilitate the modeling process and yieldaccurate channel predictions. In this work, we first provide a concise overviewof data-driven channel modeling methods, highlighting their limitations.Subsequently, we introduce the concept and advantages of physics-informedneural network (PINN)-based modeling and a summary of recent contributions inthis area. Our findings demonstrate that PINN-based approaches in channelmodeling exhibit promising attributes such as generalizability,interpretability, and robustness. We offer a comprehensive architecture forPINN methodology, designed to inform and inspire future model development. Acase-study of our recent work on precise indoor channel prediction withsemantic segmentation and deep learning is presented. The study concludes byaddressing the challenges faced and suggesting potential research directions inthis field.</description><author>Ethan Zhu, Haijian Sun, Mingyue Ji</author><pubDate>Tue, 02 Jan 2024 16:56:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01288v1</guid></item><item><title>A Comprehensive Study of Knowledge Editing for Large Language Models</title><link>http://arxiv.org/abs/2401.01286v1</link><description>Large Language Models (LLMs) have shown extraordinary capabilities inunderstanding and generating text that closely mirrors human communication.However, a primary limitation lies in the significant computational demandsduring training, arising from their extensive parameterization. This challengeis further intensified by the dynamic nature of the world, necessitatingfrequent updates to LLMs to correct outdated information or integrate newknowledge, thereby ensuring their continued relevance. Note that manyapplications demand continual model adjustments post-training to addressdeficiencies or undesirable behaviors. There is an increasing interest inefficient, lightweight methods for on-the-fly model modifications. To this end,recent years have seen a burgeoning in the techniques of knowledge editing forLLMs, which aim to efficiently modify LLMs' behaviors within specific domainswhile preserving overall performance across various inputs. In this paper, wefirst define the knowledge editing problem and then provide a comprehensivereview of cutting-edge approaches. Drawing inspiration from educational andcognitive research theories, we propose a unified categorization criterion thatclassifies knowledge editing methods into three groups: resorting to externalknowledge, merging knowledge into the model, and editing intrinsic knowledge.Furthermore, we introduce a new benchmark, KnowEdit, for a comprehensiveempirical evaluation of representative knowledge editing approaches.Additionally, we provide an in-depth analysis of knowledge location, which canprovide a deeper understanding of the knowledge structures inherent withinLLMs. Finally, we discuss several potential applications of knowledge editing,outlining its broad and impactful implications.</description><author>Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuansheng Ni, Siyuan Cheng, Ziwen Xu, Xin Xu, Jia-Chen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Lei Liang, Zhiqiang Zhang, Xiaowei Zhu, Jun Zhou, Huajun Chen</author><pubDate>Tue, 02 Jan 2024 16:54:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01286v1</guid></item><item><title>Quality and Quantity of Machine Translation References for Automated Metrics</title><link>http://arxiv.org/abs/2401.01283v1</link><description>Automatic machine translation metrics often use human translations todetermine the quality system translations. Common wisdom in the field dictatesthat the human references should be of very high quality. However, there are nocost-benefit analyses that could be used to guide practitioners who plan tocollect references for machine translation evaluation. We find thathigher-quality references lead to better metric correlations with humans at thesegment-level. Having up to 7 references per segment and taking their averagehelps all metrics. Interestingly, the references from vendors of differentqualities can be mixed together and improve metric success. Higher qualityreferences, however, cost more to create and we frame this as an optimizationproblem: given a specific budget, what references should be collected tomaximize metric success. These findings can be used by evaluators of sharedtasks when references need to be created under a certain budget.</description><author>Vilém Zouhar, Ondřej Bojar</author><pubDate>Tue, 02 Jan 2024 16:51:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01283v1</guid></item><item><title>GEqO: ML-Accelerated Semantic Equivalence Detection</title><link>http://arxiv.org/abs/2401.01280v1</link><description>Large scale analytics engines have become a core dependency for moderndata-driven enterprises to derive business insights and drive actions. Theseengines support a large number of analytic jobs processing huge volumes of dataon a daily basis, and workloads are often inundated with overlappingcomputations across multiple jobs. Reusing common computation is crucial forefficient cluster resource utilization and reducing job execution time.Detecting common computation is the first and key step for reducing thiscomputational redundancy. However, detecting equivalence on large-scaleanalytics engines requires efficient and scalable solutions that are fullyautomated. In addition, to maximize computation reuse, equivalence needs to bedetected at the semantic level instead of just the syntactic level (i.e., theability to detect semantic equivalence of seemingly different-looking queries).Unfortunately, existing solutions fall short of satisfying these requirements. In this paper, we take a major step towards filling this gap by proposingGEqO, a portable and lightweight machine-learning-based framework forefficiently identifying semantically equivalent computations at scale. GEqOintroduces two machine-learning-based filters that quickly prune outnonequivalent subexpressions and employs a semi-supervised learning feedbackloop to iteratively improve its model with an intelligent sampling mechanism.Further, with its novel database-agnostic featurization method, GEqO cantransfer the learning from one workload and database to another. Our extensiveempirical evaluation shows that, on TPC-DS-like queries, GEqO yieldssignificant performance gains-up to 200x faster than automated verifiers-andfinds up to 2x more equivalences than optimizer and signature-based equivalencedetection approaches.</description><author>Brandon Haynes, Rana Alotaibi, Anna Pavlenko, Jyoti Leeka, Alekh Jindal, Yuanyuan Tian</author><pubDate>Tue, 02 Jan 2024 16:37:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01280v1</guid></item><item><title>CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation</title><link>http://arxiv.org/abs/2401.01275v1</link><description>Recently, the advent of large language models (LLMs) has revolutionizedgenerative agents. Among them, Role-Playing Conversational Agents (RPCAs)attract considerable attention due to their ability to emotionally engageusers. However, the absence of a comprehensive benchmark impedes progress inthis field. To bridge this gap, we introduce CharacterEval, a Chinese benchmarkfor comprehensive RPCA assessment, complemented by a tailored high-qualitydataset. The dataset comprises 1,785 multi-turn role-playing dialogues,encompassing 23,020 examples and featuring 77 characters derived from Chinesenovels and scripts. It was carefully constructed, beginning with initialdialogue extraction via GPT-4, followed by rigorous human-led quality control,and enhanced with in-depth character profiles sourced from Baidu Baike.CharacterEval employs a multifaceted evaluation approach, encompassing thirteentargeted metrics on four dimensions. Comprehensive experiments on CharacterEvaldemonstrate that Chinese LLMs exhibit more promising capabilities than GPT-4 inChinese role-playing conversation. Source code, data source and reward modelwill be publicly accessible at https://github.com/morecry/CharacterEval.</description><author>Quan Tu, Shilong Fan, Zihang Tian, Rui Yan</author><pubDate>Tue, 02 Jan 2024 16:20:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01275v1</guid></item><item><title>Learning-based agricultural management in partially observable environments subject to climate variability</title><link>http://arxiv.org/abs/2401.01273v1</link><description>Agricultural management, with a particular focus on fertilization strategies,holds a central role in shaping crop yield, economic profitability, andenvironmental sustainability. While conventional guidelines offer valuableinsights, their efficacy diminishes when confronted with extreme weatherconditions, such as heatwaves and droughts. In this study, we introduce aninnovative framework that integrates Deep Reinforcement Learning (DRL) withRecurrent Neural Networks (RNNs). Leveraging the Gym-DSSAT simulator, we trainan intelligent agent to master optimal nitrogen fertilization management.Through a series of simulation experiments conducted on corn crops in Iowa, wecompare Partially Observable Markov Decision Process (POMDP) models with MarkovDecision Process (MDP) models. Our research underscores the advantages ofutilizing sequential observations in developing more efficient nitrogen inputpolicies. Additionally, we explore the impact of climate variability,particularly during extreme weather events, on agricultural outcomes andmanagement. Our findings demonstrate the adaptability of fertilization policiesto varying climate conditions. Notably, a fixed policy exhibits resilience inthe face of minor climate fluctuations, leading to commendable corn yields,cost-effectiveness, and environmental conservation. However, our studyilluminates the need for agent retraining to acquire new optimal policies underextreme weather events. This research charts a promising course towardadaptable fertilization strategies that can seamlessly align with dynamicclimate scenarios, ultimately contributing to the optimization of cropmanagement practices.</description><author>Zhaoan Wang, Shaoping Xiao, Junchao Li, Jun Wang</author><pubDate>Tue, 02 Jan 2024 16:18:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01273v1</guid></item><item><title>MOC-RVQ: Multilevel Codebook-assisted Digital Generative Semantic Communication</title><link>http://arxiv.org/abs/2401.01272v1</link><description>Vector quantization-based image semantic communication systems havesuccessfully boosted transmission efficiency, but face a challenge withconflicting requirements between codebook design and digital constellationmodulation. Traditional codebooks need a wide index range, while modulationfavors few discrete states. To address this, we propose a multilevel generativesemantic communication system with a two-stage training framework. In the firststage, we train a high-quality codebook, using a multi-head octonary codebook(MOC) to compress the index range. We also integrate a residual vectorquantization (RVQ) mechanism for effective multilevel communication. In thesecond stage, a noise reduction block (NRB) based on Swin Transformer isintroduced, coupled with the multilevel codebook from the first stage, servingas a high-quality semantic knowledge base (SKB) for generative featurerestoration. Experimental results highlight MOC-RVQ's superior performance overmethods like BPG or JPEG, even without channel error correction coding.</description><author>Yingbin Zhou, Yaping Sun, Guanying Chen, Xiaodong Xu, Hao Chen, Binhong Huang, Shuguang Cui, Ping Zhang</author><pubDate>Tue, 02 Jan 2024 16:17:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01272v1</guid></item><item><title>Optimal Rates of Kernel Ridge Regression under Source Condition in Large Dimensions</title><link>http://arxiv.org/abs/2401.01270v1</link><description>Motivated by the studies of neural networks (e.g.,the neural tangent kerneltheory), we perform a study on the large-dimensional behavior of kernel ridgeregression (KRR) where the sample size $n \asymp d^{\gamma}$ for some $\gamma &gt;0$. Given an RKHS $\mathcal{H}$ associated with an inner product kernel definedon the sphere $\mathbb{S}^{d}$, we suppose that the true function $f_{\rho}^{*}\in [\mathcal{H}]^{s}$, the interpolation space of $\mathcal{H}$ with sourcecondition $s&gt;0$. We first determined the exact order (both upper and lowerbound) of the generalization error of kernel ridge regression for the optimallychosen regularization parameter $\lambda$. We then further showed that when$0&lt;s\le1$, KRR is minimax optimal; and when $s&gt;1$, KRR is not minimax optimal(a.k.a. he saturation effect). Our results illustrate that the curves of ratevarying along $\gamma$ exhibit the periodic plateau behavior and the multipledescent behavior and show how the curves evolve with $s&gt;0$. Interestingly, ourwork provides a unified viewpoint of several recent works on kernel regressionin the large-dimensional setting, which correspond to $s=0$ and $s=1$respectively.</description><author>Haobo Zhang, Yicheng Li, Weihao Lu, Qian Lin</author><pubDate>Tue, 02 Jan 2024 16:14:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01270v1</guid></item><item><title>LLbezpeky: Leveraging Large Language Models for Vulnerability Detection</title><link>http://arxiv.org/abs/2401.01269v1</link><description>Despite the continued research and progress in building secure systems,Android applications continue to be ridden with vulnerabilities, necessitatingeffective detection methods. Current strategies involving static and dynamicanalysis tools come with limitations like overwhelming number of falsepositives and limited scope of analysis which make either difficult to adopt.Over the past years, machine learning based approaches have been extensivelyexplored for vulnerability detection, but its real-world applicability isconstrained by data requirements and feature engineering challenges. LargeLanguage Models (LLMs), with their vast parameters, have shown tremendouspotential in understanding semnatics in human as well as programming languages.We dive into the efficacy of LLMs for detecting vulnerabilities in the contextof Android security. We focus on building an AI-driven workflow to assistdevelopers in identifying and rectifying vulnerabilities. Our experiments showthat LLMs outperform our expectations in finding issues within applicationscorrectly flagging insecure apps in 91.67% of cases in the Ghera benchmark. Weuse inferences from our experiments towards building a robust and actionablevulnerability detection system and demonstrate its effectiveness. Ourexperiments also shed light on how different various simple configurations canaffect the True Positive (TP) and False Positive (FP) rates.</description><author>Noble Saji Mathews, Yelizaveta Brus, Yousra Aafer, Mei Nagappan, Shane McIntosh</author><pubDate>Tue, 02 Jan 2024 16:14:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01269v1</guid></item><item><title>$f$-Divergence Based Classification: Beyond the Use of Cross-Entropy</title><link>http://arxiv.org/abs/2401.01268v1</link><description>In deep learning, classification tasks are formalized as optimizationproblems solved via the minimization of the cross-entropy. However, recentadvancements in the design of objective functions allow the $f$-divergencemeasure to generalize the formulation of the optimization problem forclassification. With this goal in mind, we adopt a Bayesian perspective andformulate the classification task as a maximum a posteriori probabilityproblem. We propose a class of objective functions based on the variationalrepresentation of the $f$-divergence, from which we extract a list of fiveposterior probability estimators leveraging well-known $f$-divergences. Inaddition, driven by the challenge of improving the state-of-the-art approach,we propose a bottom-up method that leads us to the formulation of a newobjective function (and posterior probability estimator) corresponding to anovel $f$-divergence referred to as shifted log (SL). First, we theoreticallyprove the convergence property of the posterior probability estimators. Then,we numerically test the set of proposed objective functions in threeapplication scenarios: toy examples, image data sets, and signaldetection/decoding problems. The analyzed tasks demonstrate the effectivenessof the proposed estimators and that the SL divergence achieves the highestclassification accuracy in almost all the scenarios.</description><author>Nicola Novello, Andrea M. Tonello</author><pubDate>Tue, 02 Jan 2024 16:14:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01268v1</guid></item><item><title>Tuned Compositional Feature Replays for Efficient Stream Learning</title><link>http://arxiv.org/abs/2104.02206v8</link><description>Our brains extract durable, generalizable knowledge from transientexperiences of the world. Artificial neural networks come nowhere close to thisability. When tasked with learning to classify objects by training onnon-repeating video frames in temporal order (online stream learning), modelsthat learn well from shuffled datasets catastrophically forget old knowledgeupon learning new stimuli. We propose a new continual learning algorithm,Compositional Replay Using Memory Blocks (CRUMB), which mitigates forgetting byreplaying feature maps reconstructed by combining generic parts. CRUMBconcatenates trainable and re-usable "memory block" vectors to compositionallyreconstruct feature map tensors in convolutional neural networks. Storing theindices of memory blocks used to reconstruct new stimuli enables memories ofthe stimuli to be replayed during later tasks. This reconstruction mechanismalso primes the neural network to minimize catastrophic forgetting by biasingit towards attending to information about object shapes more than informationabout image textures, and stabilizes the network during stream learning byproviding a shared feature-level basis for all training examples. Theseproperties allow CRUMB to outperform an otherwise identical algorithm thatstores and replays raw images, while occupying only 3.6% as much memory. Westress-tested CRUMB alongside 13 competing methods on 7 challenging datasets.To address the limited number of existing online stream learning datasets, weintroduce 2 new benchmarks by adapting existing datasets for stream learning.With only 3.7-4.1% as much memory and 15-43% as much runtime, CRUMB mitigatescatastrophic forgetting more effectively than the state-of-the-art. Our code isavailable at https://github.com/MorganBDT/crumb.git.</description><author>Morgan B. Talbot, Rushikesh Zawar, Rohil Badkundri, Mengmi Zhang, Gabriel Kreiman</author><pubDate>Tue, 02 Jan 2024 16:12:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2104.02206v8</guid></item><item><title>Optimal Synthesis of Finite State Machines with Universal Gates using Evolutionary Algorithm</title><link>http://arxiv.org/abs/2401.01265v1</link><description>This work presents an optimization method for the synthesis of finite statemachines. The focus is on the reduction in the on-chip area and the cost of thecircuit. A list of finite state machines from MCNC91 benchmark circuits havebeen evolved using Cartesian Genetic Programming. On the average, almost 30% ofreduction in the total number of gates has been achieved. The effects of someparameters on the evolutionary process have also been discussed in the paper.</description><author>Noor Ullah, Khawaja M. Yahya, Irfan Ahmed</author><pubDate>Tue, 02 Jan 2024 16:11:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01265v1</guid></item><item><title>Fairness Certification for Natural Language Processing and Large Language Models</title><link>http://arxiv.org/abs/2401.01262v1</link><description>Natural Language Processing (NLP) plays an important role in our daily lives,particularly due to the enormous progress of Large Language Models (LLM).However, NLP has many fairness-critical use cases, e.g., as an expert system inrecruitment or as an LLM-based tutor in education. Since NLP is based on humanlanguage, potentially harmful biases can diffuse into NLP systems and produceunfair results, discriminate against minorities or generate legal issues.Hence, it is important to develop a fairness certification for NLP approaches.We follow a qualitative research approach towards a fairness certification forNLP. In particular, we have reviewed a large body of literature on algorithmicfairness, and we have conducted semi-structured expert interviews with a widerange of experts from that area. We have systematically devised six fairnesscriteria for NLP, which can be further refined into 18 sub-categories. Ourcriteria offer a foundation for operationalizing and testing processes tocertify fairness, both from the perspective of the auditor and the auditedorganization.</description><author>Vincent Freiberger, Erik Buchmann</author><pubDate>Tue, 02 Jan 2024 16:09:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01262v1</guid></item><item><title>Do Concept Bottleneck Models Obey Locality?</title><link>http://arxiv.org/abs/2401.01259v1</link><description>Concept-based learning improves a deep learning model's interpretability byexplaining its predictions via human-understandable concepts. Deep learningmodels trained under this paradigm heavily rely on the assumption that neuralnetworks can learn to predict the presence or absence of a given conceptindependently of other concepts. Recent work, however, strongly suggests thatthis assumption may fail to hold in Concept Bottleneck Models (CBMs), aquintessential family of concept-based interpretable architectures. In thispaper, we investigate whether CBMs correctly capture the degree of conditionalindependence across concepts when such concepts are localised both spatially,by having their values entirely defined by a fixed subset of features, andsemantically, by having their values correlated with only a fixed subset ofpredefined concepts. To understand locality, we analyse how changes to featuresoutside of a concept's spatial or semantic locality impact concept predictions.Our results suggest that even in well-defined scenarios where the presence of aconcept is localised to a fixed feature subspace, or whose semantics arecorrelated to a small subset of other concepts, CBMs fail to learn thislocality. These results cast doubt upon the quality of concept representationslearnt by CBMs and strongly suggest that concept-based explanations may befragile to changes outside their localities.</description><author>Naveen Raman, Mateo Espinosa Zarlenga, Juyeon Heo, Mateja Jamnik</author><pubDate>Tue, 02 Jan 2024 16:05:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01259v1</guid></item><item><title>Towards Model-Free LQR Control over Rate-Limited Channels</title><link>http://arxiv.org/abs/2401.01258v1</link><description>Given the success of model-free methods for control design in many problemsettings, it is natural to ask how things will change if realisticcommunication channels are utilized for the transmission of gradients orpolicies. While the resulting problem has analogies with the formulationsstudied under the rubric of networked control systems, the rich literature inthat area has typically assumed that the model of the system is known. As astep towards bridging the fields of model-free control design and networkedcontrol systems, we ask: \textit{Is it possible to solve basic control problems- such as the linear quadratic regulator (LQR) problem - in a model-free mannerover a rate-limited channel?} Toward answering this question, we study asetting where a worker agent transmits quantized policy gradients (of the LQRcost) to a server over a noiseless channel with a finite bit-rate. We propose anew algorithm titled Adaptively Quantized Gradient Descent (\texttt{AQGD}), andprove that above a certain finite threshold bit-rate, \texttt{AQGD} guaranteesexponentially fast convergence to the globally optimal policy, with \textit{nodeterioration of the exponent relative to the unquantized setting}. Moregenerally, our approach reveals the benefits of adaptive quantization inpreserving fast linear convergence rates, and, as such, may be of independentinterest to the literature on compressed optimization.</description><author>Aritra Mitra, Lintao Ye, Vijay Gupta</author><pubDate>Tue, 02 Jan 2024 15:59:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01258v1</guid></item><item><title>VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM</title><link>http://arxiv.org/abs/2401.01256v1</link><description>The recent innovations and breakthroughs in diffusion models havesignificantly expanded the possibilities of generating high-quality videos forthe given prompts. Most existing works tackle the single-scene scenario withonly one video event occurring in a single background. Extending to generatemulti-scene videos nevertheless is not trivial and necessitates to nicelymanage the logic in between while preserving the consistent visual appearanceof key content across video scenes. In this paper, we propose a novelframework, namely VideoDrafter, for content-consistent multi-scene videogeneration. Technically, VideoDrafter leverages Large Language Models (LLM) toconvert the input prompt into comprehensive multi-scene script that benefitsfrom the logical knowledge learnt by LLM. The script for each scene includes aprompt describing the event, the foreground/background entities, as well ascamera movement. VideoDrafter identifies the common entities throughout thescript and asks LLM to detail each entity. The resultant entity description isthen fed into a text-to-image model to generate a reference image for eachentity. Finally, VideoDrafter outputs a multi-scene video by generating eachscene video via a diffusion process that takes the reference images, thedescriptive prompt of the event and camera movement into account. The diffusionmodel incorporates the reference images as the condition and alignment tostrengthen the content consistency of multi-scene videos. Extensive experimentsdemonstrate that VideoDrafter outperforms the SOTA video generation models interms of visual quality, content consistency, and user preference.</description><author>Fuchen Long, Zhaofan Qiu, Ting Yao, Tao Mei</author><pubDate>Tue, 02 Jan 2024 15:56:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01256v1</guid></item><item><title>tf.data service: A Case for Disaggregating ML Input Data Processing</title><link>http://arxiv.org/abs/2210.14826v3</link><description>Machine learning (ML) computations commonly execute on expensive specializedhardware, such as GPUs and TPUs, which provide high FLOPs andperformance-per-watt. For cost efficiency, it is essential to keep theseaccelerators highly utilized. This requires preprocessing input data at therate at which the accelerators can ingest and perform ML computations on thedata. To avoid data stalls, the host CPU and RAM required for input dataprocessing per accelerator core used for ML computations varies across jobs.Hence, the traditional approach of processing input data on ML acceleratorhosts with a fixed hardware ratio leads to either under-utilizing theaccelerators or the host CPU and RAM. In this paper, we address these concernsby building a disaggregated ML data processing system. We present tf.data service, an open-source disaggregated input dataprocessing service built on top of tf.data in TensorFlow. We show thatdisaggregating data preprocessing has three key advantages for large-scale MLtraining jobs. First, the service can horizontally scale-out to right-sizeCPU/RAM host resources for data processing in each job, saving 32x trainingtime and 26x cost, on average. Second, the service can share ephemeralpreprocessed data results across jobs, to optimize CPU usage and reduceredundant computations. Finally, the service supports coordinated reads, atechnique that avoids stragglers due to different input sizes in distributedtraining, reducing training time by 2.2x, on average. Our design is inspired bylessons learned from deploying tf.data service in production, includingrelaxing data visitation guarantees without impacting model accuracy.</description><author>Andrew Audibert, Yang Chen, Dan Graur, Ana Klimovic, Jiri Simsa, Chandramohan A. Thekkath</author><pubDate>Tue, 02 Jan 2024 15:54:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.14826v3</guid></item><item><title>Recovering 3D Human Mesh from Monocular Images: A Survey</title><link>http://arxiv.org/abs/2203.01923v6</link><description>Estimating human pose and shape from monocular images is a long-standingproblem in computer vision. Since the release of statistical body models, 3Dhuman mesh recovery has been drawing broader attention. With the same goal ofobtaining well-aligned and physically plausible mesh results, two paradigmshave been developed to overcome challenges in the 2D-to-3D lifting process: i)an optimization-based paradigm, where different data terms and regularizationterms are exploited as optimization objectives; and ii) a regression-basedparadigm, where deep learning techniques are embraced to solve the problem inan end-to-end fashion. Meanwhile, continuous efforts are devoted to improvingthe quality of 3D mesh labels for a wide range of datasets. Though remarkableprogress has been achieved in the past decade, the task is still challengingdue to flexible body motions, diverse appearances, complex environments, andinsufficient in-the-wild annotations. To the best of our knowledge, this is thefirst survey that focuses on the task of monocular 3D human mesh recovery. Westart with the introduction of body models and then elaborate recoveryframeworks and training objectives by providing in-depth analyses of theirstrengths and weaknesses. We also summarize datasets, evaluation metrics, andbenchmark results. Open issues and future directions are discussed in the end,hoping to motivate researchers and facilitate their research in this area. Aregularly updated project page can be found athttps://github.com/tinatiansjz/hmr-survey.</description><author>Yating Tian, Hongwen Zhang, Yebin Liu, Limin Wang</author><pubDate>Tue, 02 Jan 2024 15:38:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.01923v6</guid></item><item><title>Multimodality and Attention Increase Alignment in Natural Language Prediction Between Humans and Computational Models</title><link>http://arxiv.org/abs/2308.06035v3</link><description>The potential of multimodal generative artificial intelligence (mAI) toreplicate human grounded language understanding, including the pragmatic,context-rich aspects of communication, remains to be clarified. Humans areknown to use salient multimodal features, such as visual cues, to facilitatethe processing of upcoming words. Correspondingly, multimodal computationalmodels can integrate visual and linguistic data using a visual attentionmechanism to assign next-word probabilities. To test whether these processesalign, we tasked both human participants (N = 200) as well as severalstate-of-the-art computational models with evaluating the predictability offorthcoming words after viewing short audio-only or audio-visual clips withspeech. During the task, the model's attention weights were recorded and humanattention was indexed via eye tracking. Results show that predictabilityestimates from humans aligned more closely with scores generated frommultimodal models vs. their unimodal counterparts. Furthermore, including anattention mechanism doubled alignment with human judgments when visual andlinguistic context facilitated predictions. In these cases, the model'sattention patches and human eye tracking significantly overlapped. Our resultsindicate that improved modeling of naturalistic language processing in mAI doesnot merely depend on training diet but can be driven by multimodality incombination with attention-based architectures. Humans and computational modelsalike can leverage the predictive constraints of multimodal information byattending to relevant features in the input.</description><author>Viktor Kewenig, Andrew Lampinen, Samuel A. Nastase, Christopher Edwards, Quitterie Lacome DEstalenx, Akilles Rechardt, Jeremy I Skipper, Gabriella Vigliocco</author><pubDate>Tue, 02 Jan 2024 15:33:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.06035v3</guid></item><item><title>ArtGPT-4: Towards Artistic-understanding Large Vision-Language Models with Enhanced Adapter</title><link>http://arxiv.org/abs/2305.07490v5</link><description>In recent years, advancements in large language models have been remarkable,with models such as ChatGPT demonstrating exceptional proficiency in diverselinguistic tasks. The pre-training of large models with billions of parameters,poses a formidable challenge, primarily due to the scarcity of datasets of acommensurate scale for effective training. Nevertheless, innovative strategieshave emerged, including methods to fine-tune these pre-trained models usingfewer parameters set, as evidenced by models like MiniGPT-4 and LLaVA. Despitetheir potential in various domains, these models remain limited in theirunderstanding of artistic imagery. They have yet to fully grasp the intricatenuances of art images or to provide an objective articulation of the emotionsthey evoke, in a manner akin to human perception. This work introducesArtGPT-4, a pioneering large vision-language model tailored to address thedeficiencies of contemporary models in artistic comprehension. ArtGPT-4underwent training on image-text pairs utilizing a Tesla A100 device in a mere2 hours, with a dataset comprising approximately 0.52M entries. Impressively,the model can render images with an artistic-understanding and convey theemotions they inspire, mirroring human interpretation. Additionally, this workpresents a unique dataset designed to evaluate the efficacy of vision-languagemodels. In subsequent evaluations, ArtGPT-4 not only achieved state-of-the-artperformance on the ArtEmis and ArtEmis-v2.0 datasets but also exceeded theestablished benchmarks introduced in This study, lagging behind professionalartists' descriptions by a negligible 0.15 points on a 6-point scale. The codeand the pre-trained model are accessible inhttps://huggingface.co/Tyrannosaurus/ArtGPT-4.</description><author>Zhengqing Yuan, Xinyi Wang, Kun Wang, Lichao Sun</author><pubDate>Tue, 02 Jan 2024 15:29:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07490v5</guid></item><item><title>Deep Learning-Based Computational Model for Disease Identification in Cocoa Pods (Theobroma cacao L.)</title><link>http://arxiv.org/abs/2401.01247v1</link><description>The early identification of diseases in cocoa pods is an important task toguarantee the production of high-quality cocoa. The use of artificialintelligence techniques such as machine learning, computer vision and deeplearning are promising solutions to help identify and classify diseases incocoa pods. In this paper we introduce the development and evaluation of a deeplearning computational model applied to the identification of diseases in cocoapods, focusing on "monilia" and "black pod" diseases. An exhaustive review ofstate-of-the-art of computational models was carried out, based on scientificarticles related to the identification of plant diseases using computer visionand deep learning techniques. As a result of the search, EfficientDet-Lite4, anefficient and lightweight model for object detection, was selected. A dataset,including images of both healthy and diseased cocoa pods, has been utilized totrain the model to detect and pinpoint disease manifestations with considerableaccuracy. Significant enhancements in the model training and evaluationdemonstrate the capability of recognizing and classifying diseases throughimage analysis. Furthermore, the functionalities of the model were integratedinto an Android native mobile with an user-friendly interface, allowing toyounger or inexperienced farmers a fast and accuracy identification of healthstatus of cocoa pods</description><author>Darlyn Buenaño Vera, Byron Oviedo, Washington Chiriboga Casanova, Cristian Zambrano-Vega</author><pubDate>Tue, 02 Jan 2024 15:23:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01247v1</guid></item><item><title>Temporal Adaptive RGBT Tracking with Modality Prompt</title><link>http://arxiv.org/abs/2401.01244v1</link><description>RGBT tracking has been widely used in various fields such as robotics,surveillance processing, and autonomous driving. Existing RGBT trackers fullyexplore the spatial information between the template and the search region andlocate the target based on the appearance matching results. However, these RGBTtrackers have very limited exploitation of temporal information, eitherignoring temporal information or exploiting it through online sampling andtraining. The former struggles to cope with the object state changes, while thelatter neglects the correlation between spatial and temporal information. Toalleviate these limitations, we propose a novel Temporal Adaptive RGBT Trackingframework, named as TATrack. TATrack has a spatio-temporal two-stream structureand captures temporal information by an online updated template, where thetwo-stream structure refers to the multi-modal feature extraction andcross-modal interaction for the initial template and the online update templaterespectively. TATrack contributes to comprehensively exploit spatio-temporalinformation and multi-modal information for target localization. In addition,we design a spatio-temporal interaction (STI) mechanism that bridges twobranches and enables cross-modal interaction to span longer time scales.Extensive experiments on three popular RGBT tracking benchmarks show that ourmethod achieves state-of-the-art performance, while running at real-time speed.</description><author>Hongyu Wang, Xiaotao Liu, Yifan Li, Meng Sun, Dian Yuan, Jing Liu</author><pubDate>Tue, 02 Jan 2024 15:20:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01244v1</guid></item><item><title>Contrastive Sequential Interaction Network Learning on Co-Evolving Riemannian Spaces</title><link>http://arxiv.org/abs/2401.01243v1</link><description>The sequential interaction network usually find itself in a variety ofapplications, e.g., recommender system. Herein, inferring future interaction isof fundamental importance, and previous efforts are mainly focused on thedynamics in the classic zero-curvature Euclidean space. Despite the promisingresults achieved by previous methods, a range of significant issues stilllargely remains open: On the bipartite nature, is it appropriate to place userand item nodes in one identical space regardless of their inherent difference?On the network dynamics, instead of a fixed curvature space, will therepresentation spaces evolve when new interactions arrive continuously? On thelearning paradigm, can we get rid of the label information costly to acquire?To address the aforementioned issues, we propose a novel Contrastive model forSequential Interaction Network learning on Co-Evolving RiEmannian spaces,CSINCERE. To the best of our knowledge, we are the first to introduce a coupleof co-evolving representation spaces, rather than a single or static space, andpropose a co-contrastive learning for the sequential interaction network. InCSINCERE, we formulate a Cross-Space Aggregation for message-passing acrossrepresentation spaces of different Riemannian geometries, and design a NeuralCurvature Estimator based on Ricci curvatures for modeling the space evolvementover time. Thereafter, we present a Reweighed Co-Contrast between the temporalviews of the sequential network, so that the couple of Riemannian spacesinteract with each other for the interaction prediction without labels.Empirical results on 5 public datasets show the superiority of CSINCERE overthe state-of-the-art methods.</description><author>Li Sun, Junda Ye, Jiawei Zhang, Yong Yang, Mingsheng Liu, Feiyang Wang, Philip S. Yu</author><pubDate>Tue, 02 Jan 2024 15:19:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01243v1</guid></item><item><title>Encoding Binary Events from Continuous Time Series in Rooted Trees using Contrastive Learning</title><link>http://arxiv.org/abs/2401.01242v1</link><description>Broadband infrastructure owners do not always know how their customers areconnected in the local networks, which are structured as rooted trees. A recentstudy is able to infer the topology of a local network using discrete timeseries data from the leaves of the tree (customers). In this study we propose acontrastive approach for learning a binary event encoder from continuous timeseries data. As a preliminary result, we show that our approach has somepotential in learning a valuable encoder.</description><author>Tobias Engelhardt Rasmussen, Siv Sørensen</author><pubDate>Tue, 02 Jan 2024 15:18:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01242v1</guid></item><item><title>Data-Efficient Multimodal Fusion on a Single GPU</title><link>http://arxiv.org/abs/2312.10144v2</link><description>The goal of multimodal alignment is to learn a single latent space that isshared between multimodal inputs. The most powerful models in this space havebeen trained using massive datasets of paired inputs and large-scalecomputational resources, making them prohibitively expensive to train in manypractical scenarios. We surmise that existing unimodal encoders pre-trained onlarge amounts of unimodal data should provide an effective bootstrap to createmultimodal models from unimodal ones at much lower costs. We therefore proposeFuseMix, a multimodal augmentation scheme that operates on the latent spaces ofarbitrary pre-trained unimodal encoders. Using FuseMix for multimodalalignment, we achieve competitive performance -- and in certain casesoutperform state-of-the art methods -- in both image-text and audio-textretrieval, with orders of magnitude less compute and data: for example, weoutperform CLIP on the Flickr30K text-to-image retrieval task with $\sim \!600\times$ fewer GPU days and $\sim \! 80\times$ fewer image-text pairs.Additionally, we show how our method can be applied to convert pre-trainedtext-to-image generative models into audio-to-image ones. Code is available at:https://github.com/layer6ai-labs/fusemix.</description><author>Noël Vouitsis, Zhaoyan Liu, Satya Krishna Gorti, Valentin Villecroze, Jesse C. Cresswell, Guangwei Yu, Gabriel Loaiza-Ganem, Maksims Volkovs</author><pubDate>Tue, 02 Jan 2024 15:16:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10144v2</guid></item><item><title>Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and Qualitative Analysis</title><link>http://arxiv.org/abs/2311.15218v4</link><description>The application of Machine learning to finance has become a familiarapproach, even more so in stock market forecasting. The stock market is highlyvolatile, and huge amounts of data are generated every minute globally. Theextraction of effective intelligence from this data is of critical importance.However, a collaboration of numerical stock data with qualitative text data canbe a challenging task. In this work, we accomplish this by providing anunprecedented, publicly available dataset with technical and fundamental dataand sentiment that we gathered from news archives, TV news captions, radiotranscripts, tweets, daily financial newspapers, etc. The text data entriesused for sentiment extraction total more than 1.4 Million. The dataset consistsof daily entries from January 2018 to December 2022 for eight companiesrepresenting diverse industrial sectors and the Dow Jones Industrial Average(DJIA) as a whole. Holistic Fundamental and Technical data is provided trainingready for Model learning and deployment. Most importantly, the data generatedcould be used for incremental online learning with real-time data pointsretrieved daily since no stagnant data was utilized. All the data was retiredfrom APIs or self-designed robust information retrieval technologies withextremely low latency and zero monetary cost. These adaptable technologiesfacilitate data extraction for any stock. Moreover, the utilization ofSpearman's rank correlation over real-time data, linking stock returns withsentiment analysis has produced noteworthy results for the DJIA and the eightother stocks, achieving accuracy levels surpassing 60%. The dataset is madeavailable at https://github.com/batking24/Huge-Stock-Dataset.</description><author>Sai Akash Bathini, Dagli Cihan</author><pubDate>Tue, 02 Jan 2024 15:13:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.15218v4</guid></item><item><title>Graph Elimination Networks</title><link>http://arxiv.org/abs/2401.01233v1</link><description>Graph Neural Networks (GNNs) are widely applied across various domains, yetthey perform poorly in deep layers. Existing research typically attributes thisproblem to node over-smoothing, where node representations becomeindistinguishable after multiple rounds of propagation. In this paper, we delveinto the neighborhood propagation mechanism of GNNs and discover that the realroot cause of GNNs' performance degradation in deep layers lies in ineffectiveneighborhood feature propagation. This propagation leads to an exponentialgrowth of a node's current representation at every propagation step, making itextremely challenging to capture valuable dependencies between long-distancenodes. To address this issue, we introduce Graph Elimination Networks (GENs),which employ a specific algorithm to eliminate redundancies during neighborhoodpropagation. We demonstrate that GENs can enhance nodes' perception of distantneighborhoods and extend the depth of network propagation. Extensiveexperiments show that GENs outperform the state-of-the-art methods on variousgraph-level and node-level datasets.</description><author>Shuo Wang, Ge Cheng, Yun Zhang</author><pubDate>Tue, 02 Jan 2024 14:58:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01233v1</guid></item><item><title>Motif-aware Riemannian Graph Neural Network with Generative-Contrastive Learning</title><link>http://arxiv.org/abs/2401.01232v1</link><description>Graphs are typical non-Euclidean data of complex structures. In recent years,Riemannian graph representation learning has emerged as an exciting alternativeto Euclidean ones. However, Riemannian methods are still in an early stage:most of them present a single curvature (radius) regardless of structuralcomplexity, suffer from numerical instability due to theexponential/logarithmic map, and lack the ability to capture motif regularity.In light of the issues above, we propose the problem of \emph{Motif-awareRiemannian Graph Representation Learning}, seeking a numerically stable encoderto capture motif regularity in a diverse-curvature manifold without labels. Tothis end, we present a novel Motif-aware Riemannian model withGenerative-Contrastive learning (MotifRGC), which conducts a minmax game inRiemannian manifold in a self-supervised manner. First, we propose a new typeof Riemannian GCN (D-GCN), in which we construct a diverse-curvature manifoldby a product layer with the diversified factor, and replace theexponential/logarithmic map by a stable kernel layer. Second, we introduce amotif-aware Riemannian generative-contrastive learning to capture motifregularity in the constructed manifold and learn motif-aware noderepresentation without external labels. Empirical results show the superiorityof MofitRGC.</description><author>Li Sun, Zhenhao Huang, Zixi Wang, Feiyang Wang, Hao Peng, Philip Yu</author><pubDate>Tue, 02 Jan 2024 14:58:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01232v1</guid></item><item><title>Lossy Image Compression with Conditional Diffusion Models</title><link>http://arxiv.org/abs/2209.06950v8</link><description>This paper outlines an end-to-end optimized lossy image compression frameworkusing diffusion generative models. The approach relies on the transform codingparadigm, where an image is mapped into a latent space for entropy coding and,from there, mapped back to the data space for reconstruction. In contrast toVAE-based neural compression, where the (mean) decoder is a deterministicneural network, our decoder is a conditional diffusion model. Our approach thusintroduces an additional ``content'' latent variable on which the reversediffusion process is conditioned and uses this variable to store informationabout the image. The remaining ``texture'' variables characterizing thediffusion process are synthesized at decoding time. We show that the model'sperformance can be tuned toward perceptual metrics of interest. Our extensiveexperiments involving multiple datasets and image quality assessment metricsshow that our approach yields stronger reported FID scores than the GAN-basedmodel, while also yielding competitive performance with VAE-based models inseveral distortion metrics. Furthermore, training the diffusion with$\mathcal{X}$-parameterization enables high-quality reconstructions in only ahandful of decoding steps, greatly affecting the model's practicality. Our codeis available at: \url{https://github.com/buggyyang/CDC_compression}</description><author>Ruihan Yang, Stephan Mandt</author><pubDate>Tue, 02 Jan 2024 14:49:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.06950v8</guid></item><item><title>Structured Packing in LLM Training Improves Long Context Utilization</title><link>http://arxiv.org/abs/2312.17296v2</link><description>Recent advances in long-context Large Language Models (LCLMs) have generatedsignificant interest, especially in applications such as querying scientificresearch papers. However, their potential is often limited by inadequatecontext utilization. We identify the absence of long-range semanticdependencies in typical training data as a primary hindrance. To address this,we delve into the benefits of frequently incorporating related documents intotraining inputs. Using the inherent directory structure of code data as asource of training examples, we demonstrate improvements in perplexity, evenfor tasks unrelated to coding. Building on these findings, but with a broaderfocus, we introduce Structured Packing for Long Context (SPLiCe). SPLiCe is aninnovative method for creating training examples by using a retrieval method tocollate the most mutually relevant documents into a single training context.Our results indicate that \method{} enhances model performance and can be usedto train large models to utilize long contexts better. We validate our resultsby training a large $3$B model, showing both perplexity improvements and betterlong-context performance on downstream tasks.</description><author>Konrad Staniszewski, Szymon Tworkowski, Sebastian Jaszczur, Henryk Michalewski, Łukasz Kuciński, Piotr Miłoś</author><pubDate>Tue, 02 Jan 2024 14:48:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17296v2</guid></item><item><title>SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling</title><link>http://arxiv.org/abs/2308.04365v5</link><description>Causal inference is a crucial goal of science, enabling researchers to arriveat meaningful conclusions regarding the predictions of hypotheticalinterventions using observational data. Path models, Structural Equation Models(SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means tounambiguously specify assumptions regarding the causal structure underlying aphenomenon. Unlike DAGs, which make very few assumptions about the functionaland parametric form, SEM assumes linearity. This can result in functionalmisspecification which prevents researchers from undertaking reliable effectsize estimation. In contrast, we propose Super Learner Equation Modeling, apath modeling technique integrating machine learning Super Learner ensembles.We empirically demonstrate its ability to provide consistent and unbiasedestimates of causal effects, its competitive performance for linear models whencompared with SEM, and highlight its superiority over SEM when dealing withnon-linear relationships. We provide open-source code, and a tutorial notebookwith example usage, accentuating the easy-to-use nature of the method.</description><author>Matthew J. Vowels</author><pubDate>Tue, 02 Jan 2024 14:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.04365v5</guid></item><item><title>IdentiFace : A VGG Based Multimodal Facial Biometric System</title><link>http://arxiv.org/abs/2401.01227v1</link><description>The development of facial biometric systems has contributed greatly to thedevelopment of the computer vision field. Nowadays, there's always a need todevelop a multimodal system that combines multiple biometric traits in anefficient, meaningful way. In this paper, we introduce "IdentiFace" which is amultimodal facial biometric system that combines the core of facial recognitionwith some of the most important soft biometric traits such as gender, faceshape, and emotion. We also focused on developing the system using only VGG-16inspired architecture with minor changes across different subsystems. Thisunification allows for simpler integration across modalities. It makes iteasier to interpret the learned features between the tasks which gives a goodindication about the decision-making process across the facial modalities andpotential connection. For the recognition problem, we acquired a 99.2% testaccuracy for five classes with high intra-class variations using data collectedfrom the FERET database[1]. We achieved 99.4% on our dataset and 95.15% on thepublic dataset[2] in the gender recognition problem. We were also able toachieve a testing accuracy of 88.03% in the face-shape problem using thecelebrity face-shape dataset[3]. Finally, we achieved a decent testing accuracyof 66.13% in the emotion task which is considered a very acceptable accuracycompared to related work on the FER2013 dataset[4].</description><author>Mahmoud Rabea, Hanya Ahmed, Sohaila Mahmoud, Nourhan Sayed</author><pubDate>Tue, 02 Jan 2024 14:36:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01227v1</guid></item><item><title>Era Splitting -- Invariant Learning for Decision Trees</title><link>http://arxiv.org/abs/2309.14496v3</link><description>Real-life machine learning problems exhibit distributional shifts in the datafrom one time to another or from on place to another. This behavior is beyondthe scope of the traditional empirical risk minimization paradigm, whichassumes i.i.d. distribution of data over time and across locations. Theemerging field of out-of-distribution (OOD) generalization addresses thisreality with new theory and algorithms which incorporate environmental, orera-wise information into the algorithms. So far, most research has beenfocused on linear models and/or neural networks. In this research we developtwo new splitting criteria for decision trees, which allow us to apply ideasfrom OOD generalization research to decision tree models, including randomforest and gradient-boosting decision trees. The new splitting criteria useera-wise information associated with each data point to allow tree-based modelsto find split points that are optimal across all disjoint eras in the data,instead of optimal over the entire data set pooled together, which is thedefault setting. In this paper we describe the problem setup in the context offinancial markets. We describe the new splitting criteria in detail and developunique experiments to showcase the benefits of these new criteria, whichimprove metrics in our experiments out-of-sample. The new criteria areincorporated into the a state-of-the-art gradient boosted decision tree modelin the Scikit-Learn code base, which is made freely available.</description><author>Timothy DeLise</author><pubDate>Tue, 02 Jan 2024 14:35:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.14496v3</guid></item><item><title>PointDC:Unsupervised Semantic Segmentation of 3D Point Clouds via Cross-modal Distillation and Super-Voxel Clustering</title><link>http://arxiv.org/abs/2304.08965v5</link><description>Semantic segmentation of point clouds usually requires exhausting efforts ofhuman annotations, hence it attracts wide attention to the challenging topic oflearning from unlabeled or weaker forms of annotations. In this paper, we takethe first attempt for fully unsupervised semantic segmentation of point clouds,which aims to delineate semantically meaningful objects without any form ofannotations. Previous works of unsupervised pipeline on 2D images fails in thistask of point clouds, due to: 1) Clustering Ambiguity caused by limitedmagnitude of data and imbalanced class distribution; 2) Irregularity Ambiguitycaused by the irregular sparsity of point cloud. Therefore, we propose a novelframework, PointDC, which is comprised of two steps that handle theaforementioned problems respectively: Cross-Modal Distillation (CMD) andSuper-Voxel Clustering (SVC). In the first stage of CMD, multi-view visualfeatures are back-projected to the 3D space and aggregated to a unified pointfeature to distill the training of the point representation. In the secondstage of SVC, the point features are aggregated to super-voxels and then fed tothe iterative clustering process for excavating semantic classes. PointDCyields a significant improvement over the prior state-of-the-art unsupervisedmethods, on both the ScanNet-v2 (+18.4 mIoU) and S3DIS (+11.5 mIoU) semanticsegmentation benchmarks.</description><author>Zisheng Chen, Hongbin Xu, Weitao Chen, Zhipeng Zhou, Haihong Xiao, Baigui Sun, Xuansong Xie, Wenxiong Kang</author><pubDate>Tue, 02 Jan 2024 14:32:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.08965v5</guid></item><item><title>Exploiting Causality Signals in Medical Images: A Pilot Study with Empirical Results</title><link>http://arxiv.org/abs/2309.10399v3</link><description>We present a novel technique to discover and exploit weak causal signalsdirectly from images via neural networks for classification purposes. This way,we model how the presence of a feature in one part of the image affects theappearance of another feature in a different part of the image. Our methodconsists of a convolutional neural network backbone and a causality-factorsextractor module, which computes weights to enhance each feature map accordingto its causal influence in the scene. We develop different architecturevariants and empirically evaluate all the models on two public datasets ofprostate MRI images and breast histopathology slides for cancer diagnosis. Westudy the effectiveness of our module both in fully-supervised and few-shotlearning, we assess its addition to existing attention-based solutions, weconduct ablation studies, and investigate the explainability of our models viaclass activation maps. Our findings show that our lightweight block extractsmeaningful information and improves the overall classification, together withproducing more robust predictions that focus on relevant parts of the image.That is crucial in medical imaging, where accurate and reliable classificationsare essential for effective diagnosis and treatment planning.</description><author>Gianluca Carloni, Sara Colantonio</author><pubDate>Tue, 02 Jan 2024 14:24:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10399v3</guid></item><item><title>Distribution Matching for Multi-Task Learning of Classification Tasks: a Large-Scale Study on Faces &amp; Beyond</title><link>http://arxiv.org/abs/2401.01219v1</link><description>Multi-Task Learning (MTL) is a framework, where multiple related tasks arelearned jointly and benefit from a shared representation space, or parametertransfer. To provide sufficient learning support, modern MTL uses annotateddata with full, or sufficiently large overlap across tasks, i.e., each inputsample is annotated for all, or most of the tasks. However, collecting suchannotations is prohibitive in many real applications, and cannot benefit fromdatasets available for individual tasks. In this work, we challenge this setupand show that MTL can be successful with classification tasks with little, ornon-overlapping annotations, or when there is big discrepancy in the size oflabeled data per task. We explore task-relatedness for co-annotation andco-training, and propose a novel approach, where knowledge exchange is enabledbetween the tasks via distribution matching. To demonstrate the generalapplicability of our method, we conducted diverse case studies in the domainsof affective computing, face recognition, species recognition, and shoppingitem classification using nine datasets. Our large-scale study of affectivetasks for basic expression recognition and facial action unit detectionillustrates that our approach is network agnostic and brings large performanceimprovements compared to the state-of-the-art in both tasks and across allstudied databases. In all case studies, we show that co-training viatask-relatedness is advantageous and prevents negative transfer (which occurswhen MT model's performance is worse than that of at least one single-taskmodel).</description><author>Dimitrios Kollias, Viktoriia Sharmanska, Stefanos Zafeiriou</author><pubDate>Tue, 02 Jan 2024 14:18:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01219v1</guid></item><item><title>RS5M and GeoRSCLIP: A Large Scale Vision-Language Dataset and A Large Vision-Language Model for Remote Sensing</title><link>http://arxiv.org/abs/2306.11300v5</link><description>Pre-trained Vision-Language Models (VLMs) utilizing extensive image-textpaired data have demonstrated unprecedented image-text associationcapabilities, achieving remarkable results across various downstream tasks. Acritical challenge is how to make use of existing large-scale pre-trained VLMs,which are trained on common objects, to perform the domain-specific transferfor accomplishing domain-related downstream tasks. A critical challenge is howto make use of existing large-scale pre-trained VLMs, which are trained oncommon objects, to perform the domain-specific transfer for accomplishingdomain-related downstream tasks. In this paper, we propose a new framework thatincludes the Domain pre-trained Vision-Language Model (DVLM), bridging the gapbetween the General Vision-Language Model (GVLM) and domain-specific downstreamtasks. Moreover, we present an image-text paired dataset in the field of remotesensing (RS), RS5M, which has 5 million RS images with English descriptions.The dataset is obtained from filtering publicly available image-text paireddatasets and captioning label-only RS datasets with pre-trained VLM. Theseconstitute the first large-scale RS image-text paired dataset. Additionally, wefine-tuned the CLIP model and tried several Parameter-Efficient Fine-Tuningmethods on RS5M to implement the DVLM. Experimental results show that ourproposed dataset is highly effective for various tasks, and our model GeoRSCLIPimproves upon the baseline or previous state-of-the-art model by $3\%\sim20\%$in Zero-shot Classification (ZSC), $3\%\sim6\%$ in Remote Sensing Cross-ModalText-Image Retrieval (RSCTIR) and $4\%\sim5\%$ in Semantic Localization (SeLo)tasks. Dataset and models have been released in:\url{https://github.com/om-ai-lab/RS5M}.</description><author>Zilun Zhang, Tiancheng Zhao, Yulong Guo, Jianwei Yin</author><pubDate>Tue, 02 Jan 2024 14:18:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11300v5</guid></item><item><title>Zero-Shot Position Debiasing for Large Language Models</title><link>http://arxiv.org/abs/2401.01218v1</link><description>Fine-tuning has been demonstrated to be an effective method to improve thedomain performance of large language models (LLMs). However, LLMs might fit thedataset bias and shortcuts for prediction, leading to poor generationperformance. Experimental result shows that LLMs are prone to exhibit positionbias, i.e., leveraging information positioned at the beginning or end, orspecific positional cues within the input. Existing works on mitigatingposition bias require external bias knowledge or annotated non-biased samples,which is unpractical in reality. In this work, we propose a zero-shot positiondebiasing (ZOE) framework to mitigate position bias for LLMs. ZOE leveragesunsupervised responses from pre-trained LLMs for debiasing, thus without anyexternal knowledge or datasets. To improve the quality of unsupervisedresponses, we propose a master-slave alignment (MSA) module to prune theseresponses. Experiments on eight datasets and five tasks show that ZOEconsistently outperforms existing methods in mitigating four types of positionbiases. Besides, ZOE achieves this by sacrificing only a small performance onbiased samples, which is simple and effective.</description><author>Zhongkun Liu, Zheng Chen, Mengqi Zhang, Zhaochun Ren, Zhumin Chen, Pengjie Ren</author><pubDate>Tue, 02 Jan 2024 14:12:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01218v1</guid></item><item><title>Approximation analysis of CNNs from a feature extraction view</title><link>http://arxiv.org/abs/2210.09041v2</link><description>Deep learning based on deep neural networks has been very successful in manypractical applications, but it lacks enough theoretical understanding due tothe network architectures and structures. In this paper we establish someanalysis for linear feature extraction by a deep multi-channel convolutionalneural networks (CNNs), which demonstrates the power of deep learning overtraditional linear transformations, like Fourier, wavelets, redundantdictionary coding methods. Moreover, we give an exact construction presentinghow linear features extraction can be conducted efficiently with multi-channelCNNs. It can be applied to lower the essential dimension for approximating ahigh dimensional function. Rates of function approximation by such deepnetworks implemented with channels and followed by fully-connected layers areinvestigated as well. Harmonic analysis for factorizing linear features intomulti-resolution convolutions plays an essential role in our work.Nevertheless, a dedicate vectorization of matrices is constructed, whichbridges 1D CNN and 2D CNN and allows us to have corresponding 2D analysis.</description><author>Jianfei Li, Han Feng, Ding-Xuan Zhou</author><pubDate>Tue, 02 Jan 2024 14:12:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.09041v2</guid></item><item><title>Noise-NeRF: Hide Information in Neural Radiance Fields using Trainable Noise</title><link>http://arxiv.org/abs/2401.01216v1</link><description>Neural radiance fields (NeRF) have been proposed as an innovative 3Drepresentation method. While attracting lots of attention, NeRF faces criticalissues such as information confidentiality and security. Steganography is atechnique used to embed information in another object as a means of protectinginformation security. Currently, there are few related studies on NeRFsteganography, facing challenges in low steganography quality, model weightdamage, and a limited amount of steganographic information. This paper proposesa novel NeRF steganography method based on trainable noise: Noise-NeRF.Furthermore, we propose the Adaptive Pixel Selection strategy and PixelPerturbation strategy to improve the steganography quality and efficiency. Theextensive experiments on open-source datasets show that Noise-NeRF providesstate-of-the-art performances in both steganography quality and renderingquality, as well as effectiveness in super-resolution image steganography.</description><author>Qinglong Huang, Yong Liao, Yanbin Hao, Pengyuan Zhou</author><pubDate>Tue, 02 Jan 2024 14:10:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01216v1</guid></item><item><title>YOLO algorithm with hybrid attention feature pyramid network for solder joint defect detection</title><link>http://arxiv.org/abs/2401.01214v1</link><description>Traditional manual detection for solder joint defect is no longer appliedduring industrial production due to low efficiency, inconsistent evaluation,high cost and lack of real-time data. A new approach has been proposed toaddress the issues of low accuracy, high false detection rates andcomputational cost of solder joint defect detection in surface mount technologyof industrial scenarios. The proposed solution is a hybrid attention mechanismdesigned specifically for the solder joint defect detection algorithm toimprove quality control in the manufacturing process by increasing the accuracywhile reducing the computational cost. The hybrid attention mechanism comprisesa proposed enhanced multi-head self-attention and coordinate attentionmechanisms increase the ability of attention networks to perceive contextualinformation and enhances the utilization range of network features. Thecoordinate attention mechanism enhances the connection between differentchannels and reduces location information loss. The hybrid attention mechanismenhances the capability of the network to perceive long-distance positioninformation and learn local features. The improved algorithm model has gooddetection ability for solder joint defect detection, with mAP reaching 91.5%,4.3% higher than the You Only Look Once version 5 algorithm and better thanother comparative algorithms. Compared to other versions, mean AveragePrecision, Precision, Recall, and Frame per Seconds indicators have alsoimproved. The improvement of detection accuracy can be achieved while meetingreal-time detection requirements.</description><author>Li Ang, Siti Khatijah Nor Abdul Rahim, Raseeda Hamzah, Raihah Aminuddin, Gao Yousheng</author><pubDate>Tue, 02 Jan 2024 14:04:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01214v1</guid></item><item><title>On the Application of Efficient Neural Mapping to Real-Time Indoor Localisation for Unmanned Ground Vehicles</title><link>http://arxiv.org/abs/2211.04718v2</link><description>Global localisation from visual data is a challenging problem applicable tomany robotics domains. Prior works have shown that neural networks can betrained to map images of an environment to absolute camera pose within thatenvironment, learning an implicit neural mapping in the process. In this workwe evaluate the applicability of such an approach to real-world roboticsscenarios, demonstrating that by constraining the problem to 2-dimensions andsignificantly increasing the quantity of training data, a compact model capableof real-time inference on embedded platforms can be used to achievelocalisation accuracy of several centimetres. We deploy our trained modelonboard a UGV platform, demonstrating its effectiveness in a waypointnavigation task, wherein it is able to localise with a mean accuracy of 9cm ata rate of 6fps running on the UGV onboard CPU, 35fps on an embedded GPU, or220fps on a desktop GPU. Along with this work we will release a novellocalisation dataset comprising simulated and real environments, each withtraining samples numbering in the tens of thousands.</description><author>Christopher J. Holder, Muhammad Shafique</author><pubDate>Tue, 02 Jan 2024 13:56:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.04718v2</guid></item><item><title>GD^2-NeRF: Generative Detail Compensation via GAN and Diffusion for One-shot Generalizable Neural Radiance Fields</title><link>http://arxiv.org/abs/2401.00616v2</link><description>In this paper, we focus on the One-shot Novel View Synthesis (O-NVS) taskwhich targets synthesizing photo-realistic novel views given only one referenceimage per scene. Previous One-shot Generalizable Neural Radiance Fields(OG-NeRF) methods solve this task in an inference-time finetuning-free manner,yet suffer the blurry issue due to the encoder-only architecture that highlyrelies on the limited reference image. On the other hand, recentdiffusion-based image-to-3d methods show vivid plausible results via distillingpre-trained 2D diffusion models into a 3D representation, yet require tediousper-scene optimization. Targeting these issues, we propose the GD$^2$-NeRF, aGenerative Detail compensation framework via GAN and Diffusion that is bothinference-time finetuning-free and with vivid plausible details. In detail,following a coarse-to-fine strategy, GD$^2$-NeRF is mainly composed of aOne-stage Parallel Pipeline (OPP) and a 3D-consistent Detail Enhancer(Diff3DE). At the coarse stage, OPP first efficiently inserts the GAN modelinto the existing OG-NeRF pipeline for primarily relieving the blurry issuewith in-distribution priors captured from the training dataset, achieving agood balance between sharpness (LPIPS, FID) and fidelity (PSNR, SSIM). Then, atthe fine stage, Diff3DE further leverages the pre-trained image diffusionmodels to complement rich out-distribution details while maintaining decent 3Dconsistency. Extensive experiments on both the synthetic and real-worlddatasets show that GD$^2$-NeRF noticeably improves the details while withoutper-scene finetuning.</description><author>Xiao Pan, Zongxin Yang, Shuai Bai, Yi Yang</author><pubDate>Tue, 02 Jan 2024 13:47:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00616v2</guid></item><item><title>Joint Learning of Linear Time-Invariant Dynamical Systems</title><link>http://arxiv.org/abs/2112.10955v6</link><description>Linear time-invariant systems are very popular models in system theory andapplications. A fundamental problem in system identification that remainsrather unaddressed in extant literature is to leverage commonalities amongstrelated linear systems to estimate their transition matrices more accurately.To address this problem, the current paper investigates methods for jointlyestimating the transition matrices of multiple systems. It is assumed that thetransition matrices are unknown linear functions of some unknown shared basismatrices. We establish finite-time estimation error rates that fully reflectthe roles of trajectory lengths, dimension, and number of systems underconsideration. The presented results are fairly general and show thesignificant gains that can be achieved by pooling data across systems incomparison to learning each system individually. Further, they are shown to berobust against model misspecifications. To obtain the results, we develop noveltechniques that are of interest for addressing similar joint-learning problems.They include tightly bounding estimation errors in terms of theeigen-structures of transition matrices, establishing sharp high probabilitybounds for singular values of dependent random matrices, and capturing effectsof misspecified transition matrices as the systems evolve over time.</description><author>Aditya Modi, Mohamad Kazem Shirani Faradonbeh, Ambuj Tewari, George Michailidis</author><pubDate>Tue, 02 Jan 2024 13:40:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.10955v6</guid></item><item><title>FGENet: Fine-Grained Extraction Network for Congested Crowd Counting</title><link>http://arxiv.org/abs/2401.01208v1</link><description>Crowd counting has gained significant popularity due to its practicalapplications. However, mainstream counting methods ignore precise individuallocalization and suffer from annotation noise because of counting fromestimating density maps. Additionally, they also struggle with high-densityimages.To address these issues, we propose an end-to-end model calledFine-Grained Extraction Network (FGENet). Different from methods estimatingdensity maps, FGENet directly learns the original coordinate points thatrepresent the precise localization of individuals.This study designs a fusionmodule, named Fine-Grained Feature Pyramid(FGFP), that is used to fuse featuremaps extracted by the backbone of FGENet. The fused features are then passed toboth regression and classification heads, where the former provides predictedpoint coordinates for a given image, and the latter determines the confidencelevel for each predicted point being an individual. At the end, FGENetestablishes correspondences between prediction points and ground truth pointsby employing the Hungarian algorithm. For training FGENet, we design a robustloss function, named Three-Task Combination (TTC), to mitigate the impact ofannotation noise. Extensive experiments are conducted on four widely used crowdcounting datasets. Experimental results demonstrate the effectiveness ofFGENet. Notably, our method achieves a remarkable improvement of 3.14 points inMean Absolute Error (MAE) on the ShanghaiTech Part A dataset, showcasing itssuperiority over the existing state-of-the-art methods. Even more impressively,FGENet surpasses previous benchmarks on the UCF\_CC\_50 dataset with anastounding enhancement of 30.16 points in MAE.</description><author>Hao-Yuan Ma, Li Zhang, Xiang-Yi Wei</author><pubDate>Tue, 02 Jan 2024 13:31:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01208v1</guid></item><item><title>Towards a Simultaneous and Granular Identity-Expression Control in Personalized Face Generation</title><link>http://arxiv.org/abs/2401.01207v1</link><description>In human-centric content generation, the pre-trained text-to-image modelsstruggle to produce user-wanted portrait images, which retain the identity ofindividuals while exhibiting diverse expressions. This paper introduces ourefforts towards personalized face generation. To this end, we propose a novelmulti-modal face generation framework, capable of simultaneousidentity-expression control and more fine-grained expression synthesis. Ourexpression control is so sophisticated that it can be specialized by thefine-grained emotional vocabulary. We devise a novel diffusion model that canundertake the task of simultaneously face swapping and reenactment. Due to theentanglement of identity and expression, it's nontrivial to separately andprecisely control them in one framework, thus has not been explored yet. Toovercome this, we propose several innovative designs in the conditionaldiffusion model, including balancing identity and expression encoder, improvedmidpoint sampling, and explicitly background conditioning. Extensiveexperiments have demonstrated the controllability and scalability of theproposed framework, in comparison with state-of-the-art text-to-image, faceswapping, and face reenactment methods.</description><author>Renshuai Liu, Bowen Ma, Wei Zhang, Zhipeng Hu, Changjie Fan, Tangjie Lv, Yu Ding, Xuan Cheng</author><pubDate>Tue, 02 Jan 2024 13:28:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01207v1</guid></item><item><title>ImFace++: A Sophisticated Nonlinear 3D Morphable Face Model with Implicit Neural Representations</title><link>http://arxiv.org/abs/2312.04028v2</link><description>Accurate representations of 3D faces are of paramount importance in variouscomputer vision and graphics applications. However, the challenges persist dueto the limitations imposed by data discretization and model linearity, whichhinder the precise capture of identity and expression clues in current studies.This paper presents a novel 3D morphable face model, named ImFace++, to learn asophisticated and continuous space with implicit neural representations.ImFace++ first constructs two explicitly disentangled deformation fields tomodel complex shapes associated with identities and expressions, respectively,which simultaneously facilitate the automatic learning of correspondencesacross diverse facial shapes. To capture more sophisticated facial details, arefinement displacement field within the template space is furtherincorporated, enabling a fine-grained learning of individual-specific facialdetails. Furthermore, a Neural Blend-Field is designed to reinforce therepresentation capabilities through adaptive blending of an array of localfields. In addition to ImFace++, we have devised an improved learning strategyto extend expression embeddings, allowing for a broader range of expressionvariations. Comprehensive qualitative and quantitative evaluations demonstratethat ImFace++ significantly advances the state-of-the-art in terms of both facereconstruction fidelity and correspondence accuracy.</description><author>Mingwu Zheng, Haiyu Zhang, Hongyu Yang, Liming Chen, Di Huang</author><pubDate>Tue, 02 Jan 2024 13:18:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04028v2</guid></item><item><title>Tomato Maturity Recognition with Convolutional Transformers</title><link>http://arxiv.org/abs/2307.01530v2</link><description>Tomatoes are a major crop worldwide, and accurately classifying theirmaturity is important for many agricultural applications, such as harvesting,grading, and quality control. In this paper, the authors propose a novel methodfor tomato maturity classification using a convolutional transformer. Theconvolutional transformer is a hybrid architecture that combines the strengthsof convolutional neural networks (CNNs) and transformers. Additionally, thisstudy introduces a new tomato dataset named KUTomaData, explicitly designed totrain deep-learning models for tomato segmentation and classification.KUTomaData is a compilation of images sourced from a greenhouse in the UAE,with approximately 700 images available for training and testing. The datasetis prepared under various lighting conditions and viewing perspectives andemploys different mobile camera sensors, distinguishing it from existingdatasets. The contributions of this paper are threefold:Firstly, the authorspropose a novel method for tomato maturity classification using a modularconvolutional transformer. Secondly, the authors introduce a new tomato imagedataset that contains images of tomatoes at different maturity levels. Lastly,the authors show that the convolutional transformer outperformsstate-of-the-art methods for tomato maturity classification. The effectivenessof the proposed framework in handling cluttered and occluded tomato instanceswas evaluated using two additional public datasets, Laboro Tomato and Rob2PhenoAnnotated Tomato, as benchmarks. The evaluation results across these threedatasets demonstrate the exceptional performance of our proposed framework,surpassing the state-of-the-art by 58.14%, 65.42%, and 66.39% in terms of meanaverage precision scores for KUTomaData, Laboro Tomato, and Rob2Pheno AnnotatedTomato, respectively.</description><author>Asim Khan, Taimur Hassan, Muhammad Shafay, Israa Fahmy, Naoufel Werghi, Lakmal Seneviratne, Irfan Hussain</author><pubDate>Tue, 02 Jan 2024 13:13:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.01530v2</guid></item><item><title>PPBFL: A Privacy Protected Blockchain-based Federated Learning Model</title><link>http://arxiv.org/abs/2401.01204v1</link><description>With the rapid development of machine learning and growing concerns aboutdata privacy, federated learning has become an increasingly prominent focus.However, challenges such as attacks on model parameters and the lack ofincentive mechanisms hinder the effectiveness of federated learning. Therefore,we propose a Privacy Protected Blockchain-based Federated Learning Model(PPBFL) to enhance the security of federated learning and promote the activeparticipation of nodes in model training. Blockchain ensures that modelparameters stored in the InterPlanetary File System (IPFS) remain unaltered. Anovel adaptive differential privacy addition algorithm is simultaneouslyapplied to local and global models, preserving the privacy of local models andpreventing a decrease in the security of the global model due to the presenceof numerous local models in federated learning. Additionally, we introduce anew mix transactions mechanism to better protect the identity privacy of localtraining clients. Security analysis and experimental results demonstrate thatPPBFL outperforms baseline methods in both model performance and security.</description><author>Yang Li, Chunhe Xia, Wanshuang Lin, Tianbo Wang</author><pubDate>Tue, 02 Jan 2024 13:13:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01204v1</guid></item><item><title>Data-driven Modeling and Inference for Bayesian Gaussian Process ODEs via Double Normalizing Flows</title><link>http://arxiv.org/abs/2309.09222v2</link><description>Recently, Gaussian processes have been used to model the vector field ofcontinuous dynamical systems, referred to as GPODEs, which are characterized bya probabilistic ODE equation. Bayesian inference for these models has beenextensively studied and applied in tasks such as time series prediction.However, the use of standard GPs with basic kernels like squared exponentialkernels has been common in GPODE research, limiting the model's ability torepresent complex scenarios. To address this limitation, we introducenormalizing flows to reparameterize the ODE vector field, resulting in adata-driven prior distribution, thereby increasing flexibility and expressivepower. We develop a data-driven variational learning algorithm that utilizesanalytically tractable probability density functions of normalizing flows,enabling simultaneous learning and inference of unknown continuous dynamics.Additionally, we also apply normalizing flows to the posterior inference of GPODEs to resolve the issue of strong mean-field assumptions in posteriorinference. By applying normalizing flows in both these ways, our model improvesaccuracy and uncertainty estimates for Bayesian Gaussian Process ODEs. Wevalidate the effectiveness of our approach on simulated dynamical systems andreal-world human motion data, including time series prediction and missing datarecovery tasks. Experimental results show that our proposed method effectivelycaptures model uncertainty while improving accuracy.</description><author>Jian Xu, Shian Du, Junmei Yang, Xinghao Ding, John Paisley, Delu Zeng</author><pubDate>Tue, 02 Jan 2024 13:09:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09222v2</guid></item><item><title>Whole-examination AI estimation of fetal biometrics from 20-week ultrasound scans</title><link>http://arxiv.org/abs/2401.01201v1</link><description>The current approach to fetal anomaly screening is based on biometricmeasurements derived from individually selected ultrasound images. In thispaper, we introduce a paradigm shift that attains human-level performance inbiometric measurement by aggregating automatically extracted biometrics fromevery frame across an entire scan, with no need for operator intervention. Weuse a convolutional neural network to classify each frame of an ultrasoundvideo recording. We then measure fetal biometrics in every frame whereappropriate anatomy is visible. We use a Bayesian method to estimate the truevalue of each biometric from a large number of measurements andprobabilistically reject outliers. We performed a retrospective experiment on1457 recordings (comprising 48 million frames) of 20-week ultrasound scans,estimated fetal biometrics in those scans and compared our estimates to themeasurements sonographers took during the scan. Our method achieves human-levelperformance in estimating fetal biometrics and estimates well-calibratedcredible intervals in which the true biometric value is expected to lie.</description><author>Lorenzo Venturini, Samuel Budd, Alfonso Farruggia, Robert Wright, Jacqueline Matthew, Thomas G. Day, Bernhard Kainz, Reza Razavi, Jo V. Hajnal</author><pubDate>Tue, 02 Jan 2024 13:04:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01201v1</guid></item><item><title>Skin cancer diagnosis using NIR spectroscopy data of skin lesions in vivo using machine learning algorithms</title><link>http://arxiv.org/abs/2401.01200v1</link><description>Skin lesions are classified in benign or malignant. Among the malignant,melanoma is a very aggressive cancer and the major cause of deaths. So, earlydiagnosis of skin cancer is very desired. In the last few years, there is agrowing interest in computer aided diagnostic (CAD) using most image andclinical data of the lesion. These sources of information present limitationsdue to their inability to provide information of the molecular structure of thelesion. NIR spectroscopy may provide an alternative source of information toautomated CAD of skin lesions. The most commonly used techniques andclassification algorithms used in spectroscopy are Principal Component Analysis(PCA), Partial Least Squares - Discriminant Analysis (PLS-DA), and SupportVector Machines (SVM). Nonetheless, there is a growing interest in applying themodern techniques of machine and deep learning (MDL) to spectroscopy. One ofthe main limitations to apply MDL to spectroscopy is the lack of publicdatasets. Since there is no public dataset of NIR spectral data to skinlesions, as far as we know, an effort has been made and a new dataset namedNIR-SC-UFES, has been collected, annotated and analyzed generating thegold-standard for classification of NIR spectral data to skin cancer. Next, themachine learning algorithms XGBoost, CatBoost, LightGBM, 1D-convolutionalneural network (1D-CNN) were investigated to classify cancer and non-cancerskin lesions. Experimental results indicate the best performance obtained byLightGBM with pre-processing using standard normal variate (SNV), featureextraction providing values of 0.839 for balanced accuracy, 0.851 for recall,0.852 for precision, and 0.850 for F-score. The obtained results indicate thefirst steps in CAD of skin lesions aiming the automated triage of patients withskin lesions in vivo using NIR spectral data.</description><author>Flavio P. Loss, Pedro H. da Cunha, Matheus B. Rocha, Madson Poltronieri Zanoni, Leandro M. de Lima, Isadora Tavares Nascimento, Isabella Rezende, Tania R. P. Canuto, Luciana de Paula Vieira, Renan Rossoni, Maria C. S. Santos, Patricia Lyra Frasson, Wanderson Romão, Paulo R. Filgueiras, Renato A. Krohling</author><pubDate>Tue, 02 Jan 2024 13:03:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01200v1</guid></item><item><title>JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example</title><link>http://arxiv.org/abs/2401.01199v1</link><description>Most of the approaches proposed so far to craft targeted adversarial examplesagainst Deep Learning classifiers are highly suboptimal and typically rely onincreasing the likelihood of the target class, thus implicitly focusing onone-hot encoding settings. In this paper, we propose a more general,theoretically sound, targeted attack that resorts to the minimization of aJacobian-induced MAhalanobis distance (JMA) term, taking into account theeffort (in the input space) required to move the latent space representation ofthe input sample in a given direction. The minimization is solved by exploitingthe Wolfe duality theorem, reducing the problem to the solution of aNon-Negative Least Square (NNLS) problem. The proposed algorithm provides anoptimal solution to a linearized version of the adversarial example problemoriginally introduced by Szegedy et al. \cite{szegedy2013intriguing}. Theexperiments we carried out confirm the generality of the proposed attack whichis proven to be effective under a wide variety of output encoding schemes.Noticeably, the JMA attack is also effective in a multi-label classificationscenario, being capable to induce a targeted modification of up to half thelabels in a complex multilabel classification scenario with 20 labels, acapability that is out of reach of all the attacks proposed so far. As afurther advantage, the JMA attack usually requires very few iterations, thusresulting more efficient than existing methods.</description><author>Benedetta Tondi, Wei Guo, Mauro Barni</author><pubDate>Tue, 02 Jan 2024 13:03:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01199v1</guid></item><item><title>Uncertainty Resolution in Misinformation Detection</title><link>http://arxiv.org/abs/2401.01197v1</link><description>Misinformation poses a variety of risks, such as undermining public trust anddistorting factual discourse. Large Language Models (LLMs) like GPT-4 have beenshown effective in mitigating misinformation, particularly in handlingstatements where enough context is provided. However, they struggle to assessambiguous or context-deficient statements accurately. This work introduces anew method to resolve uncertainty in such statements. We propose a framework tocategorize missing information and publish category labels for the LIAR-Newdataset, which is adaptable to cross-domain content with missing information.We then leverage this framework to generate effective user queries for missingcontext. Compared to baselines, our method improves the rate at which generatedquestions are answerable by the user by 38 percentage points and classificationperformance by over 10 percentage points macro F1. Thus, this approach mayprovide a valuable component for future misinformation mitigation pipelines.</description><author>Yury Orlovskiy, Camille Thibault, Anne Imouza, Jean-François Godbout, Reihaneh Rabbany, Kellin Pelrine</author><pubDate>Tue, 02 Jan 2024 13:01:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01197v1</guid></item><item><title>StyleSinger: Style Transfer for Out-of-Domain Singing Voice Synthesis</title><link>http://arxiv.org/abs/2312.10741v2</link><description>Style transfer for out-of-domain (OOD) singing voice synthesis (SVS) focuseson generating high-quality singing voices with unseen styles (such as timbre,emotion, pronunciation, and articulation skills) derived from reference singingvoice samples. However, the endeavor to model the intricate nuances of singingvoice styles is an arduous task, as singing voices possess a remarkable degreeof expressiveness. Moreover, existing SVS methods encounter a decline in thequality of synthesized singing voices in OOD scenarios, as they rest upon theassumption that the target vocal attributes are discernible during the trainingphase. To overcome these challenges, we propose StyleSinger, the first singingvoice synthesis model for zero-shot style transfer of out-of-domain referencesinging voice samples. StyleSinger incorporates two critical approaches forenhanced effectiveness: 1) the Residual Style Adaptor (RSA) which employs aresidual quantization module to capture diverse style characteristics insinging voices, and 2) the Uncertainty Modeling Layer Normalization (UMLN) toperturb the style attributes within the content representation during thetraining phase and thus improve the model generalization. Our extensiveevaluations in zero-shot style transfer undeniably establish that StyleSingeroutperforms baseline models in both audio quality and similarity to thereference singing voice samples. Access to singing voice samples can be foundat https://stylesinger.github.io/.</description><author>Yu Zhang, Rongjie Huang, Ruiqi Li, JinZheng He, Yan Xia, Feiyang Chen, Xinyu Duan, Baoxing Huai, Zhou Zhao</author><pubDate>Tue, 02 Jan 2024 12:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10741v2</guid></item><item><title>Scaffold-Based Multi-Objective Drug Candidate Optimization</title><link>http://arxiv.org/abs/2301.07175v2</link><description>In therapeutic design, balancing various physiochemical properties is crucialfor molecule development, similar to how Multiparameter Optimization (MPO)evaluates multiple variables to meet a primary goal. While many molecularfeatures can now be predicted using \textit{in silico} methods, aiding earlydrug development, the vast data generated from high throughput virtualscreening challenges the practicality of traditional MPO approaches. Addressingthis, we introduce a scaffold focused graph-based Markov chain Monte Carloframework (ScaMARS) built to generate molecules with optimal properties. Thisinnovative framework is capable of self-training and handling a wider array ofproperties, sampling different chemical spaces according to the startingscaffold. The benchmark analysis on several properties shows that ScaMARS has adiversity score of 84.6\% and has a much higher success rate of 99.5\% comparedto conditional models. The integration of new features into MPO significantlyenhances its adaptability and effectiveness in therapeutic design, facilitatingthe discovery of candidates that efficiently optimize multiple properties.</description><author>Agustin Kruel, Andrew D. McNaughton, Neeraj Kumar</author><pubDate>Tue, 02 Jan 2024 12:49:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.07175v2</guid></item><item><title>DeepTreeGANv2: Iterative Pooling of Point Clouds</title><link>http://arxiv.org/abs/2312.00042v2</link><description>In High Energy Physics, detailed and time-consuming simulations are used forparticle interactions with detectors. To bypass these simulations with agenerative model, the generation of large point clouds in a short time isrequired, while the complex dependencies between the particles must becorrectly modelled. Particle showers are inherently tree-based processes, aseach particle is produced by the decay or detector interaction of a particle ofthe previous generation. In this work, we present a significant extension toDeepTreeGAN, featuring a critic, that is able to aggregate such point cloudsiteratively in a tree-based manner. We show that this model can reproducecomplex distributions, and we evaluate its performance on the public JetNet 150dataset.</description><author>Moritz Alfons Wilhelm Scham, Dirk Krücker, Kerstin Borras</author><pubDate>Tue, 02 Jan 2024 12:41:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00042v2</guid></item><item><title>Deep-ELA: Deep Exploratory Landscape Analysis with Self-Supervised Pretrained Transformers for Single- and Multi-Objective Continuous Optimization Problems</title><link>http://arxiv.org/abs/2401.01192v1</link><description>In many recent works, the potential of Exploratory Landscape Analysis (ELA)features to numerically characterize, in particular, single-objectivecontinuous optimization problems has been demonstrated. These numericalfeatures provide the input for all kinds of machine learning tasks oncontinuous optimization problems, ranging, i.a., from High-level PropertyPrediction to Automated Algorithm Selection and Automated AlgorithmConfiguration. Without ELA features, analyzing and understanding thecharacteristics of single-objective continuous optimization problems would beimpossible. Yet, despite their undisputed usefulness, ELA features suffer from severaldrawbacks. These include, in particular, (1.) a strong correlation betweenmultiple features, as well as (2.) its very limited applicability tomulti-objective continuous optimization problems. As a remedy, recent worksproposed deep learning-based approaches as alternatives to ELA. In these works,e.g., point-cloud transformers were used to characterize an optimizationproblem's fitness landscape. However, these approaches require a large amountof labeled training data. Within this work, we propose a hybrid approach, Deep-ELA, which combines (thebenefits of) deep learning and ELA features. Specifically, we pre-trained fourtransformers on millions of randomly generated optimization problems to learndeep representations of the landscapes of continuous single- andmulti-objective optimization problems. Our proposed framework can either beused out-of-the-box for analyzing single- and multi-objective continuousoptimization problems, or subsequently fine-tuned to various tasks focussing onalgorithm behavior and problem understanding.</description><author>Moritz Vinzent Seiler, Pascal Kerschke, Heike Trautmann</author><pubDate>Tue, 02 Jan 2024 12:41:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01192v1</guid></item><item><title>NID-SLAM: Neural Implicit Representation-based RGB-D SLAM in dynamic environments</title><link>http://arxiv.org/abs/2401.01189v1</link><description>Neural implicit representations have been explored to enhance visual SLAMalgorithms, especially in providing high-fidelity dense map. Existing methodsoperate robustly in static scenes but struggle with the disruption caused bymoving objects. In this paper we present NID-SLAM, which significantly improvesthe performance of neural SLAM in dynamic environments. We propose a newapproach to enhance inaccurate regions in semantic masks, particularly inmarginal areas. Utilizing the geometric information present in depth images,this method enables accurate removal of dynamic objects, thereby reducing theprobability of camera drift. Additionally, we introduce a keyframe selectionstrategy for dynamic scenes, which enhances camera tracking robustness againstlarge-scale objects and improves the efficiency of mapping. Experiments onpublicly available RGB-D datasets demonstrate that our method outperformscompetitive neural SLAM approaches in tracking accuracy and mapping quality indynamic environments.</description><author>Ziheng Xu, Jianwei Niu, Qingfeng Li, Tao Ren, Chen Chen</author><pubDate>Tue, 02 Jan 2024 12:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01189v1</guid></item><item><title>Tensor PCA from basis in tensor space</title><link>http://arxiv.org/abs/2305.02803v2</link><description>The aim of this paper is to present a mathematical framework for tensor PCA.The proposed approach is able to overcome the limitations of previous methodsthat extract a low dimensional subspace by iteratively solving an optimizationproblem. The core of the proposed approach is the derivation of a basis intensor space from a real self-adjoint tensor operator, thus reducing theproblem of deriving a basis to an eigenvalue problem. Three different caseshave been studied to derive: i) a basis from a self-adjoint tensor operator;ii) a rank-1 basis; iii) a basis in a subspace. In particular, the equivalencebetween eigenvalue equation for a real self-adjoint tensor operator andstandard matrix eigenvalue equation has been proven. For all the three casesconsidered, a subspace approach has been adopted to derive a tensor PCA.Experiments on image datasets validate the proposed mathematical framework.</description><author>Claudio Turchetti</author><pubDate>Tue, 02 Jan 2024 12:33:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.02803v2</guid></item><item><title>Exploring Long- and Short-Range Temporal Information for Learned Video Compression</title><link>http://arxiv.org/abs/2208.03754v3</link><description>Learned video compression methods have gained a variety of interest in thevideo coding community since they have matched or even exceeded therate-distortion (RD) performance of traditional video codecs. However, manycurrent learning-based methods are dedicated to utilizing short-range temporalinformation, thus limiting their performance. In this paper, we focus onexploiting the unique characteristics of video content and further exploringtemporal information to enhance compression performance. Specifically, forlong-range temporal information exploitation, we propose temporal prior thatcan update continuously within the group of pictures (GOP) during inference. Inthat case temporal prior contains valuable temporal information of all decodedimages within the current GOP. As for short-range temporal information, wepropose a progressive guided motion compensation to achieve robust andeffective compensation. In detail, we design a hierarchical structure toachieve multi-scale compensation. More importantly, we use optical flowguidance to generate pixel offsets between feature maps at each scale, and thecompensation results at each scale will be used to guide the following scale'scompensation. Sufficient experimental results demonstrate that our method canobtain better RD performance than state-of-the-art video compressionapproaches. The code is publicly available on:https://github.com/Huairui/LSTVC.</description><author>Huairui Wang, Zhenzhong Chen</author><pubDate>Tue, 02 Jan 2024 12:27:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.03754v3</guid></item><item><title>Attention Based Encoder Decoder Model for Video Captioning in Nepali (2023)</title><link>http://arxiv.org/abs/2312.07418v2</link><description>Video captioning in Nepali, a language written in the Devanagari script,presents a unique challenge due to the lack of existing academic work in thisdomain. This work develops a novel encoder-decoder paradigm for Nepali videocaptioning to tackle this difficulty. LSTM and GRU sequence-to-sequence modelsare used in the model to produce related textual descriptions based on featuresretrieved from video frames using CNNs. Using Google Translate and manualpost-editing, a Nepali video captioning dataset is generated from the MicrosoftResearch Video Description Corpus (MSVD) dataset created using GoogleTranslate, and manual post-editing work. The efficacy of the model forDevanagari-scripted video captioning is demonstrated by BLEU, METOR, and ROUGEmeasures, which are used to assess its performance.</description><author>Kabita Parajuli, Shashidhar Ram Joshi</author><pubDate>Tue, 02 Jan 2024 12:24:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07418v2</guid></item><item><title>Unifying Structured Data as Graph for Data-to-Text Pre-Training</title><link>http://arxiv.org/abs/2401.01183v1</link><description>Data-to-text (D2T) generation aims to transform structured data into naturallanguage text. Data-to-text pre-training has proved to be powerful in enhancingD2T generation and yields impressive performances. However, previouspre-training methods either oversimplified structured data into a sequencewithout considering input structures or designed training objectives tailoredfor a specific data structure (e.g., table or knowledge graph). In this paper,we unify different types of structured data (i.e., table, key-value data,knowledge graph) into the graph format and cast different data-to-textgeneration tasks as graph-to-text generation. To effectively exploit thestructural information of the input graph, we propose a structure-enhancedpre-training method for D2T generation by designing a structure-enhancedTransformer. Concretely, we devise a position matrix for the Transformer,encoding relative positional information of connected nodes in the input graph.In addition, we propose a new attention matrix to incorporate graph structuresinto the original Transformer by taking the available explicit connectivitystructure into account. Extensive experiments on six benchmark datasets showthe effectiveness of our model. Our source codes are available athttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/unid2t.</description><author>Shujie Li, Liang Li, Ruiying Geng, Min Yang, Binhua Li, Guanghu Yuan, Wanwei He, Shao Yuan, Can Ma, Fei Huang, Yongbin Li</author><pubDate>Tue, 02 Jan 2024 12:23:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01183v1</guid></item><item><title>Query-Based Knowledge Sharing for Open-Vocabulary Multi-Label Classification</title><link>http://arxiv.org/abs/2401.01181v1</link><description>Identifying labels that did not appear during training, known as multi-labelzero-shot learning, is a non-trivial task in computer vision. To this end,recent studies have attempted to explore the multi-modal knowledge ofvision-language pre-training (VLP) models by knowledge distillation, allowingto recognize unseen labels in an open-vocabulary manner. However, experimentalevidence shows that knowledge distillation is suboptimal and provides limitedperformance gain in unseen label prediction. In this paper, a novel query-basedknowledge sharing paradigm is proposed to explore the multi-modal knowledgefrom the pretrained VLP model for open-vocabulary multi-label classification.Specifically, a set of learnable label-agnostic query tokens is trained toextract critical vision knowledge from the input image, and further sharedacross all labels, allowing them to select tokens of interest as visual cluesfor recognition. Besides, we propose an effective prompt pool for robust labelembedding, and reformulate the standard ranking learning into a form ofclassification to allow the magnitude of feature vectors for matching, whichboth significantly benefit label recognition. Experimental results show thatour framework significantly outperforms state-of-the-art methods on zero-shottask by 5.9% and 4.5% in mAP on the NUS-WIDE and Open Images, respectively.</description><author>Xuelin Zhu, Jian Liu, Dongqi Tang, Jiawei Ge, Weijia Liu, Bo Liu, Jiuxin Cao</author><pubDate>Tue, 02 Jan 2024 12:18:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01181v1</guid></item><item><title>Accurate and Efficient Urban Street Tree Inventory with Deep Learning on Mobile Phone Imagery</title><link>http://arxiv.org/abs/2401.01180v1</link><description>Deforestation, a major contributor to climate change, poses detrimentalconsequences such as agricultural sector disruption, global warming, flashfloods, and landslides. Conventional approaches to urban street tree inventorysuffer from inaccuracies and necessitate specialised equipment. To overcomethese challenges, this paper proposes an innovative method that leverages deeplearning techniques and mobile phone imaging for urban street tree inventory.Our approach utilises a pair of images captured by smartphone cameras toaccurately segment tree trunks and compute the diameter at breast height (DBH).Compared to traditional methods, our approach exhibits several advantages,including superior accuracy, reduced dependency on specialised equipment, andapplicability in hard-to-reach areas. We evaluated our method on acomprehensive dataset of 400 trees and achieved a DBH estimation accuracy withan error rate of less than 2.5%. Our method holds significant potential forsubstantially improving forest management practices. By enhancing the accuracyand efficiency of tree inventory, our model empowers urban management tomitigate the adverse effects of deforestation and climate change.</description><author>Asim Khan, Umair Nawaz, Anwaar Ulhaq, Iqbal Gondal, Sajid Javed</author><pubDate>Tue, 02 Jan 2024 12:16:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01180v1</guid></item><item><title>Freeze the backbones: A Parameter-Efficient Contrastive Approach to Robust Medical Vision-Language Pre-training</title><link>http://arxiv.org/abs/2401.01179v1</link><description>Modern healthcare often utilises radiographic images alongside textualreports for diagnostics, encouraging the use of Vision-Language Self-SupervisedLearning (VL-SSL) with large pre-trained models to learn versatile medicalvision representations. However, most existing VL-SSL frameworks are trainedend-to-end, which is computation-heavy and can lose vital prior informationembedded in pre-trained encoders. To address both issues, we introduce thebackbone-agnostic Adaptor framework, which preserves medical knowledge inpre-trained image and text encoders by keeping them frozen, and employs alightweight Adaptor module for cross-modal learning. Experiments on medicalimage classification and segmentation tasks across three datasets reveal thatour framework delivers competitive performance while cutting trainableparameters by over 90% compared to current pre-training approaches. Notably,when fine-tuned with just 1% of data, Adaptor outperforms severalTransformer-based methods trained on full datasets in medical imagesegmentation.</description><author>Jiuming Qin, Che Liu, Sibo Cheng, Yike Guo, Rossella Arcucci</author><pubDate>Tue, 02 Jan 2024 12:14:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01179v1</guid></item><item><title>GBSS:a global building semantic segmentation dataset for large-scale remote sensing building extraction</title><link>http://arxiv.org/abs/2401.01178v1</link><description>Semantic segmentation techniques for extracting building footprints fromhigh-resolution remote sensing images have been widely used in many fields suchas urban planning. However, large-scale building extraction demands higherdiversity in training samples. In this paper, we construct a Global BuildingSemantic Segmentation (GBSS) dataset (The dataset will be released), whichcomprises 116.9k pairs of samples (about 742k buildings) from six continents.There are significant variations of building samples in terms of size andstyle, so the dataset can be a more challenging benchmark for evaluating thegeneralization and robustness of building semantic segmentation models. Wevalidated through quantitative and qualitative comparisons between differentdatasets, and further confirmed the potential application in the field oftransfer learning by conducting experiments on subsets.</description><author>Yuping Hu, Xin Huang, Jiayi Li, Zhen Zhang</author><pubDate>Tue, 02 Jan 2024 12:13:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01178v1</guid></item><item><title>Fundamental Limitation of Semantic Communications: Neural Estimation for Rate-Distortion</title><link>http://arxiv.org/abs/2401.01176v1</link><description>This paper studies the fundamental limit of semantic communications over thediscrete memoryless channel. We consider the scenario to send a semantic sourceconsisting of an observation state and its corresponding semantic state, bothof which are recovered at the receiver. To derive the performance limitation,we adopt the semantic rate-distortion function (SRDF) to study the relationshipamong the minimum compression rate, observation distortion, semanticdistortion, and channel capacity. For the case with unknown semantic sourcedistribution, while only a set of the source samples is available, we propose aneural-network-based method by leveraging the generative networks to learn thesemantic source distribution. Furthermore, for a special case where thesemantic state is a deterministic function of the observation, we design acascade neural network to estimate the SRDF. For the case with perfectly knownsemantic source distribution, we propose a general Blahut-Arimoto algorithm toeffectively compute the SRDF. Finally, experimental results validate ourproposed algorithms for the scenarios with ideal Gaussian semantic source andsome practical datasets.</description><author>Dongxu Li, Jianhao Huang, Chuan Huang, Xiaoqi Qin, Han Zhang, Ping Zhang</author><pubDate>Tue, 02 Jan 2024 12:10:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01176v1</guid></item><item><title>Learning Surface Scattering Parameters From SAR Images Using Differentiable Ray Tracing</title><link>http://arxiv.org/abs/2401.01175v1</link><description>Simulating high-resolution Synthetic Aperture Radar (SAR) images in complexscenes has consistently presented a significant research challenge. Thedevelopment of a microwave-domain surface scattering model and itsreversibility are poised to play a pivotal role in enhancing the authenticityof SAR image simulations and facilitating the reconstruction of targetparameters. Drawing inspiration from the field of computer graphics, this paperproposes a surface microwave rendering model that comprehensively considersboth Specular and Diffuse contributions. The model is analytically representedby the coherent spatially varying bidirectional scattering distributionfunction (CSVBSDF) based on the Kirchhoff approximation (KA) and theperturbation method (SPM). And SAR imaging is achieved through the synergisticcombination of ray tracing and fast mapping projection techniques. Furthermore,a differentiable ray tracing (DRT) engine based on SAR images was constructedfor CSVBSDF surface scattering parameter learning. Within this SAR imagesimulation engine, the use of differentiable reverse ray tracing enables therapid estimation of parameter gradients from SAR images. The effectiveness ofthis approach has been validated through simulations and comparisons with realSAR images. By learning the surface scattering parameters, substantialenhancements in SAR image simulation performance under various observationconditions have been demonstrated.</description><author>Jiangtao Wei, Yixiang Luomei, Xu Zhang, Feng Xu</author><pubDate>Tue, 02 Jan 2024 12:09:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01175v1</guid></item><item><title>En3D: An Enhanced Generative Model for Sculpting 3D Humans from 2D Synthetic Data</title><link>http://arxiv.org/abs/2401.01173v1</link><description>We present En3D, an enhanced generative scheme for sculpting high-quality 3Dhuman avatars. Unlike previous works that rely on scarce 3D datasets or limited2D collections with imbalanced viewing angles and imprecise pose priors, ourapproach aims to develop a zero-shot 3D generative scheme capable of producingvisually realistic, geometrically accurate and content-wise diverse 3D humanswithout relying on pre-existing 3D or 2D assets. To address this challenge, weintroduce a meticulously crafted workflow that implements accurate physicalmodeling to learn the enhanced 3D generative model from synthetic 2D data.During inference, we integrate optimization modules to bridge the gap betweenrealistic appearances and coarse 3D shapes. Specifically, En3D comprises threemodules: a 3D generator that accurately models generalizable 3D humans withrealistic appearance from synthesized balanced, diverse, and structured humanimages; a geometry sculptor that enhances shape quality using multi-view normalconstraints for intricate human anatomy; and a texturing module thatdisentangles explicit texture maps with fidelity and editability, leveragingsemantical UV partitioning and a differentiable rasterizer. Experimentalresults show that our approach significantly outperforms prior works in termsof image quality, geometry accuracy and content diversity. We also showcase theapplicability of our generated avatars for animation and editing, as well asthe scalability of our approach for content-style free adaptation.</description><author>Yifang Men, Biwen Lei, Yuan Yao, Miaomiao Cui, Zhouhui Lian, Xuansong Xie</author><pubDate>Tue, 02 Jan 2024 12:06:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01173v1</guid></item><item><title>Quadratic Time-Frequency Analysis of Vibration Signals for Diagnosing Bearing Faults</title><link>http://arxiv.org/abs/2401.01172v1</link><description>Diagnosis of bearing faults is paramount to reducing maintenance costs andoperational breakdowns. Bearing faults are primary contributors to machinevibrations, and analyzing their signal morphology offers insights into theirhealth status. Unfortunately, existing approaches are optimized for controlledenvironments, neglecting realistic conditions such as time-varying rotationalspeeds and the vibration's non-stationary nature. This paper presents a fusionof time-frequency analysis and deep learning techniques to diagnose bearingfaults under time-varying speeds and varying noise levels. First, we formulatethe bearing fault-induced vibrations and discuss the link between theirnon-stationarity and the bearing's inherent and operational parameters. We alsoelucidate quadratic time-frequency distributions and validate theireffectiveness in resolving distinctive dynamic patterns associated withdifferent bearing faults. Based on this, we design a time-frequencyconvolutional neural network (TF-CNN) to diagnose various faults inrolling-element bearings. Our experimental findings undeniably demonstrate thesuperior performance of TF-CNN in comparison to recently developed techniques.They also assert its versatility in capturing fault-relevant non-stationaryfeatures that couple with speed changes and show its exceptional resilience tonoise, consistently surpassing competing methods across various signal-to-noiseratios and performance metrics. Altogether, the TF-CNN achieves substantialaccuracy improvements up to 15%, in severe noise conditions.</description><author>Mohammad Al-Sa'd, Tuomas Jalonen, Serkan Kiranyaz, Moncef Gabbouj</author><pubDate>Tue, 02 Jan 2024 12:02:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01172v1</guid></item><item><title>YOLO and Mask R-CNN for Vehicle Number Plate Identification</title><link>http://arxiv.org/abs/2207.13165v3</link><description>License plate scanners have grown in popularity in parking lots during thepast few years. In order to quickly identify license plates, traditional platerecognition devices used in parking lots employ a fixed source of light andshooting angles. For skewed angles, such as license plate images taken withultra-wide angle or fisheye lenses, deformation of the license platerecognition plate can also be quite severe, impairing the ability of standardlicense plate recognition systems to identify the plate. Mask RCNN gadget thatmay be utilised for oblique pictures and various shooting angles. The resultsof the experiments show that the suggested design will be capable ofclassifying license plates with bevel angles larger than 0/60. Characterrecognition using the suggested Mask R-CNN approach has advanced significantlyas well. The proposed Mask R-CNN method has also achieved significant progressin character recognition, which is tilted more than 45 degrees as compared tothe strategy of employing the YOLOv2 model. Experiment results also suggestthat the methodology presented in the open data plate collecting is better thanother techniques (known as the AOLP dataset).</description><author>Siddharth Ganjoo</author><pubDate>Tue, 02 Jan 2024 11:54:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.13165v3</guid></item><item><title>FedQV: Leveraging Quadratic Voting in Federated Learning</title><link>http://arxiv.org/abs/2401.01168v1</link><description>Federated Learning (FL) permits different parties to collaboratively train aglobal model without disclosing their respective local labels. A crucial stepof FL, that of aggregating local models to produce the global one, shares manysimilarities with public decision-making, and elections in particular. In thatcontext, a major weakness of FL, namely its vulnerability to poisoning attacks,can be interpreted as a consequence of the one person one vote (henceforth1p1v) principle underpinning most contemporary aggregation rules. In thispaper, we propose FedQV, a novel aggregation algorithm built upon the quadraticvoting scheme, recently proposed as a better alternative to 1p1v-basedelections. Our theoretical analysis establishes that FedQV is a truthfulmechanism in which bidding according to one's true valuation is a dominantstrategy that achieves a convergence rate that matches those ofstate-of-the-art methods. Furthermore, our empirical analysis using multiplereal-world datasets validates the superior performance of FedQV againstpoisoning attacks. It also shows that combining FedQV with unequal voting``budgets'' according to a reputation score increases its performance benefitseven further. Finally, we show that FedQV can be easily combined withByzantine-robust privacy-preserving mechanisms to enhance its robustnessagainst both poisoning and privacy attacks.</description><author>Tianyue Chu, Nikolaos Laoutaris</author><pubDate>Tue, 02 Jan 2024 11:53:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01168v1</guid></item><item><title>A Deep Neural Network -- Mechanistic Hybrid Model to Predict Pharmacokinetics in Rat</title><link>http://arxiv.org/abs/2310.09167v2</link><description>An important aspect in the development of small molecules as drugs oragro-chemicals is their systemic availability after intravenous and oraladministration. The prediction of the systemic availability from the chemicalstructure of a potential candidate is highly desirable, as it allows to focusthe drug or agrochemical development on compounds with a favorable kineticprofile. However, such pre-dictions are challenging as the availability is theresult of the complex interplay between molecular properties, biology andphysiology and training data is rare. In this work we improve the hybrid modeldeveloped earlier [1]. We reduce the median fold change error for the totaloral exposure from 2.85 to 2.35 and for intravenous administration from 1.95 to1.62. This is achieved by training on a larger data set, improving the neuralnetwork architecture as well as the parametrization of mechanistic model.Further, we extend our approach to predict additional endpoints and to handledifferent covariates, like sex and dosage form. In contrast to a pure machinelearning model, our model is able to predict new end points on which it has notbeen trained. We demonstrate this feature by predicting the exposure over thefirst 24h, while the model has only been trained on the total exposure.</description><author>Florian Führer, Andrea Gruber, Holger Diedam, Andreas H. Göller, Stephan Menz, Sebastian Schneckener</author><pubDate>Tue, 02 Jan 2024 11:48:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09167v2</guid></item><item><title>Reinforcement Learning for SAR View Angle Inversion with Differentiable SAR Renderer</title><link>http://arxiv.org/abs/2401.01165v1</link><description>The electromagnetic inverse problem has long been a research hotspot. Thisstudy aims to reverse radar view angles in synthetic aperture radar (SAR)images given a target model. Nonetheless, the scarcity of SAR data, combinedwith the intricate background interference and imaging mechanisms, limit theapplications of existing learning-based approaches. To address thesechallenges, we propose an interactive deep reinforcement learning (DRL)framework, where an electromagnetic simulator named differentiable SAR render(DSR) is embedded to facilitate the interaction between the agent and theenvironment, simulating a human-like process of angle prediction. Specifically,DSR generates SAR images at arbitrary view angles in real-time. And thedifferences in sequential and semantic aspects between the viewangle-corresponding images are leveraged to construct the state space in DRL,which effectively suppress the complex background interference, enhance thesensitivity to temporal variations, and improve the capability to capturefine-grained information. Additionally, in order to maintain the stability andconvergence of our method, a series of reward mechanisms, such as memorydifference, smoothing and boundary penalty, are utilized to form the finalreward function. Extensive experiments performed on both simulated and realdatasets demonstrate the effectiveness and robustness of our proposed method.When utilized in the cross-domain area, the proposed method greatly mitigatesinconsistency between simulated and real domains, outperforming referencemethods significantly.</description><author>Yanni Wang, Hecheng Jia, Shilei Fu, Huiping Lin, Feng Xu</author><pubDate>Tue, 02 Jan 2024 11:47:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01165v1</guid></item><item><title>Distilling Local Texture Features for Colorectal Tissue Classification in Low Data Regimes</title><link>http://arxiv.org/abs/2401.01164v1</link><description>Multi-class colorectal tissue classification is a challenging problem that istypically addressed in a setting, where it is assumed that ample amounts oftraining data is available. However, manual annotation of fine-grainedcolorectal tissue samples of multiple classes, especially the rare ones likestromal tumor and anal cancer is laborious and expensive. To address this, wepropose a knowledge distillation-based approach, named KD-CTCNet, thateffectively captures local texture information from few tissue samples, througha distillation loss, to improve the standard CNN features. The resultingenriched feature representation achieves improved classification performancespecifically in low data regimes. Extensive experiments on two public datasetsof colorectal tissues reveal the merits of the proposed contributions, with aconsistent gain achieved over different approaches across low data settings.The code and models are publicly available on GitHub.</description><author>Dmitry Demidov, Roba Al Majzoub, Amandeep Kumar, Fahad Khan</author><pubDate>Tue, 02 Jan 2024 11:46:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01164v1</guid></item><item><title>NU-Class Net: A Novel Deep Learning-based Approach for Video Quality Enhancement</title><link>http://arxiv.org/abs/2401.01163v1</link><description>Video content has experienced a surge in popularity, asserting its dominanceover internet traffic and Internet of Things (IoT) networks. Video compressionhas long been regarded as the primary means of efficiently managing thesubstantial multimedia traffic generated by video-capturing devices.Nevertheless, video compression algorithms entail significant computationaldemands in order to achieve substantial compression ratios. This complexitypresents a formidable challenge when implementing efficient video codingstandards in resource-constrained embedded systems, such as IoT edge nodecameras. To tackle this challenge, this paper introduces NU-Class Net, aninnovative deep-learning model designed to mitigate compression artifactsstemming from lossy compression codecs. This enhancement significantly elevatesthe perceptible quality of low-bit-rate videos. By employing the NU-Class Net,the video encoder within the video-capturing node can reduce output quality,thereby generating low-bit-rate videos and effectively curtailing bothcomputation and bandwidth requirements at the edge. On the decoder side, whichis typically less encumbered by resource limitations, NU-Class Net is appliedafter the video decoder to compensate for artifacts and approximate the qualityof the original video. Experimental results affirm the efficacy of the proposedmodel in enhancing the perceptible quality of videos, especially those streamedat low bit rates.</description><author>Parham Zilouchian Moghaddam, Mehdi Modarressi, MohammadAmin Sadeghi</author><pubDate>Tue, 02 Jan 2024 11:46:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01163v1</guid></item><item><title>Train-Free Segmentation in MRI with Cubical Persistent Homology</title><link>http://arxiv.org/abs/2401.01160v1</link><description>We describe a new general method for segmentation in MRI scans usingTopological Data Analysis (TDA), offering several advantages over traditionalmachine learning approaches. It works in three steps, first identifying thewhole object to segment via automatic thresholding, then detecting adistinctive subset whose topology is known in advance, and finally deducing thevarious components of the segmentation. Although convoking classical ideas ofTDA, such an algorithm has never been proposed separately from deep learningmethods. To achieve this, our approach takes into account, in addition to thehomology of the image, the localization of representative cycles, a piece ofinformation that seems never to have been exploited in this context. Inparticular, it offers the ability to perform segmentation without the need forlarge annotated data sets. TDA also provides a more interpretable and stableframework for segmentation by explicitly mapping topological features tosegmentation components. By adapting the geometric object to be detected, thealgorithm can be adjusted to a wide range of data segmentation challenges. Wecarefully study the examples of glioblastoma segmentation in brain MRI, where asphere is to be detected, as well as myocardium in cardiac MRI, involving acylinder, and cortical plate detection in fetal brain MRI, whose 2D slices arecircles. We compare our method to state-of-the-art algorithms.</description><author>Anton François, Raphaël Tinarrage</author><pubDate>Tue, 02 Jan 2024 11:43:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01160v1</guid></item><item><title>6D-Diff: A Keypoint Diffusion Framework for 6D Object Pose Estimation</title><link>http://arxiv.org/abs/2401.00029v2</link><description>Estimating the 6D object pose from a single RGB image often involves noiseand indeterminacy due to challenges such as occlusions and clutteredbackgrounds. Meanwhile, diffusion models have shown appealing performance ingenerating high-quality images from random noise with high indeterminacythrough step-by-step denoising. Inspired by their denoising capability, wepropose a novel diffusion-based framework (6D-Diff) to handle the noise andindeterminacy in object pose estimation for better performance. In ourframework, to establish accurate 2D-3D correspondence, we formulate 2Dkeypoints detection as a reverse diffusion (denoising) process. To facilitatesuch a denoising process, we design a Mixture-of-Cauchy-based forward diffusionprocess and condition the reverse process on the object features. Extensiveexperiments on the LM-O and YCB-V datasets demonstrate the effectiveness of ourframework.</description><author>Li Xu, Haoxuan Qu, Yujun Cai, Jun Liu</author><pubDate>Tue, 02 Jan 2024 11:29:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.00029v2</guid></item><item><title>Deep Learning-Based Detection for Marker Codes over Insertion and Deletion Channels</title><link>http://arxiv.org/abs/2401.01155v1</link><description>Marker code is an effective coding scheme to protect data from insertions anddeletions. It has potential applications in future storage systems, such as DNAstorage and racetrack memory. When decoding marker codes, perfect channel stateinformation (CSI), i.e., insertion and deletion probabilities, are required todetect insertion and deletion errors. Sometimes, the perfect CSI is not easy toobtain or the accurate channel model is unknown. Therefore, it is deserved todevelop detecting algorithms for marker code without the knowledge of perfectCSI. In this paper, we propose two CSI-agnostic detecting algorithms for markercode based on deep learning. The first one is a model-driven deep learningmethod, which deep unfolds the original iterative detecting algorithm of markercode. In this method, CSI become weights in neural networks and these weightscan be learned from training data. The second one is a data-driven method whichis an end-to-end system based on the deep bidirectional gated recurrent unitnetwork. Simulation results show that error performances of the proposedmethods are significantly better than that of the original detection algorithmwith CSI uncertainty. Furthermore, the proposed data-driven method exhibitsbetter error performances than other methods for unknown channel models.</description><author>Guochen Ma, Xiaopeng Jiao, Jianjun Mu, Hui Han, Yaming Yang</author><pubDate>Tue, 02 Jan 2024 11:13:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01155v1</guid></item><item><title>PAC-Bayes-Chernoff bounds for unbounded losses</title><link>http://arxiv.org/abs/2401.01148v1</link><description>We present a new high-probability PAC-Bayes oracle bound for unboundedlosses. This result can be understood as a PAC-Bayes version of the Chernoffbound. The proof technique relies on uniformly bounding the tail of certainrandom variable based on the Cram\'er transform of the loss. We highlight twoapplications of our main result. First, we show that our bound solves the openproblem of optimizing the free parameter on many PAC-Bayes bounds. Finally, weshow that our approach allows working with flexible assumptions on the lossfunction, resulting in novel bounds that generalize previous ones and can beminimized to obtain Gibbs-like posteriors.</description><author>Ioar Casado, Luis A. Ortega, Andrés R. Masegosa, Aritz Pérez</author><pubDate>Tue, 02 Jan 2024 10:58:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01148v1</guid></item><item><title>HAAQI-Net: A non-intrusive neural music quality assessment model for hearing aids</title><link>http://arxiv.org/abs/2401.01145v1</link><description>This paper introduces HAAQI-Net, a non-intrusive deep learning model formusic quality assessment tailored to hearing aid users. In contrast totraditional methods like the Hearing Aid Audio Quality Index (HAAQI), HAAQI-Netutilizes a Bidirectional Long Short-Term Memory (BLSTM) with attention. Ittakes an assessed music sample and a hearing loss pattern as input, generatinga predicted HAAQI score. The model employs the pre-trained BidirectionalEncoder representation from Audio Transformers (BEATs) for acoustic featureextraction. Comparing predicted scores with ground truth, HAAQI-Net achieves aLongitudinal Concordance Correlation (LCC) of 0.9257, Spearman's RankCorrelation Coefficient (SRCC) of 0.9394, and Mean Squared Error (MSE) of0.0080. Notably, this high performance comes with a substantial reduction ininference time: from 62.52 seconds (by HAAQI) to 2.71 seconds (by HAAQI-Net),serving as an efficient music quality assessment model for hearing aid users.</description><author>Dyah A. M. G. Wisnu, Epri Pratiwi, Stefano Rini, Ryandhimas E. Zezario, Hsin-Min Wang, Yu Tsao</author><pubDate>Tue, 02 Jan 2024 10:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01145v1</guid></item><item><title>Spiker+: a framework for the generation of efficient Spiking Neural Networks FPGA accelerators for inference at the edge</title><link>http://arxiv.org/abs/2401.01141v1</link><description>Including Artificial Neural Networks in embedded systems at the edge allowsapplications to exploit Artificial Intelligence capabilities directly withindevices operating at the network periphery. This paper introduces Spiker+, acomprehensive framework for generating efficient, low-power, and low-areacustomized Spiking Neural Networks (SNN) accelerators on FPGA for inference atthe edge. Spiker+ presents a configurable multi-layer hardware SNN, a libraryof highly efficient neuron architectures, and a design framework, enabling thedevelopment of complex neural network accelerators with few lines of Pythoncode. Spiker+ is tested on two benchmark datasets, the MNIST and the SpikingHeidelberg Digits (SHD). On the MNIST, it demonstrates competitive performancecompared to state-of-the-art SNN accelerators. It outperforms them in terms ofresource allocation, with a requirement of 7,612 logic cells and 18 Block RAMs(BRAMs), which makes it fit in very small FPGA, and power consumption, drainingonly 180mW for a complete inference on an input image. The latency iscomparable to the ones observed in the state-of-the-art, with 780us/img. To theauthors' knowledge, Spiker+ is the first SNN accelerator tested on the SHD. Inthis case, the accelerator requires 18,268 logic cells and 51 BRAM, with anoverall power consumption of 430mW and a latency of 54 us for a completeinference on input data. This underscores the significance of Spiker+ in thehardware-accelerated SNN landscape, making it an excellent solution to deployconfigurable and tunable SNN architectures in resource and power-constrainededge applications.</description><author>Alessio Carpegna, Alessandro Savino, Stefano Di Carlo</author><pubDate>Tue, 02 Jan 2024 10:42:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01141v1</guid></item></channel></rss>