<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 01 Nov 2023 14:00:09 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>FPO++: Efficient Encoding and Rendering of Dynamic Neural Radiance Fields by Analyzing and Enhancing Fourier PlenOctrees</title><link>http://arxiv.org/abs/2310.20710v1</link><description>Fourier PlenOctrees have shown to be an efficient representation forreal-time rendering of dynamic Neural Radiance Fields (NeRF). Despite its manyadvantages, this method suffers from artifacts introduced by the involvedcompression when combining it with recent state-of-the-art techniques fortraining the static per-frame NeRF models. In this paper, we perform anin-depth analysis of these artifacts and leverage the resulting insights topropose an improved representation. In particular, we present a novel densityencoding that adapts the Fourier-based compression to the characteristics ofthe transfer function used by the underlying volume rendering procedure andleads to a substantial reduction of artifacts in the dynamic model.Furthermore, we show an augmentation of the training data that relaxes theperiodicity assumption of the compression. We demonstrate the effectiveness ofour enhanced Fourier PlenOctrees in the scope of quantitative and qualitativeevaluations on synthetic and real-world scenes.</description><author>Saskia Rabich, Patrick Stotko, Reinhard Klein</author><pubDate>Tue, 31 Oct 2023 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20710v1</guid></item><item><title>Unexpected Improvements to Expected Improvement for Bayesian Optimization</title><link>http://arxiv.org/abs/2310.20708v1</link><description>Expected Improvement (EI) is arguably the most popular acquisition functionin Bayesian optimization and has found countless successful applications, butits performance is often exceeded by that of more recent methods. Notably, EIand its variants, including for the parallel and multi-objective settings, arechallenging to optimize because their acquisition values vanish numerically inmany regions. This difficulty generally increases as the number ofobservations, dimensionality of the search space, or the number of constraintsgrow, resulting in performance that is inconsistent across the literature andmost often sub-optimal. Herein, we propose LogEI, a new family of acquisitionfunctions whose members either have identical or approximately equal optima astheir canonical counterparts, but are substantially easier to optimizenumerically. We demonstrate that numerical pathologies manifest themselves in"classic" analytic EI, Expected Hypervolume Improvement (EHVI), as well astheir constrained, noisy, and parallel variants, and propose correspondingreformulations that remedy these pathologies. Our empirical results show thatmembers of the LogEI family of acquisition functions substantially improve onthe optimization performance of their canonical counterparts and surprisingly,are on par with or exceed the performance of recent state-of-the-artacquisition functions, highlighting the understated role of numericaloptimization in the literature.</description><author>Sebastian Ament, Samuel Daulton, David Eriksson, Maximilian Balandat, Eytan Bakshy</author><pubDate>Tue, 31 Oct 2023 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20708v1</guid></item><item><title>What's In My Big Data?</title><link>http://arxiv.org/abs/2310.20707v1</link><description>Large text corpora are the backbone of language models. However, we have alimited understanding of the content of these corpora, including generalstatistics, quality, social factors, and inclusion of evaluation data(contamination). In this work, we propose What's In My Big Data? (WIMBD), aplatform and a set of sixteen analyses that allow us to reveal and compare thecontents of large text corpora. WIMBD builds on two basic capabilities -- countand search -- at scale, which allows us to analyze more than 35 terabytes on astandard compute node. We apply WIMBD to ten different corpora used to trainpopular language models, including C4, The Pile, and RedPajama. Our analysisuncovers several surprising and previously undocumented findings about thesecorpora, including the high prevalence of duplicate, synthetic, and low-qualitycontent, personally identifiable information, toxic language, and benchmarkcontamination. For instance, we find that about 50% of the documents inRedPajama and LAION-2B-en are duplicates. In addition, several datasets usedfor benchmarking models trained on such corpora are contaminated with respectto important benchmarks, including the Winograd Schema Challenge and parts ofGLUE and SuperGLUE. We open-source WIMBD's code and artifacts to provide astandard set of evaluations for new text-based corpora and to encourage moreanalyses and transparency around them: github.com/allenai/wimbd.</description><author>Yanai Elazar, Akshita Bhagia, Ian Magnusson, Abhilasha Ravichander, Dustin Schwenk, Alane Suhr, Pete Walsh, Dirk Groeneveld, Luca Soldaini, Sameer Singh, Hanna Hajishirzi, Noah A. Smith, Jesse Dodge</author><pubDate>Tue, 31 Oct 2023 18:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20707v1</guid></item><item><title>Farthest Greedy Path Sampling for Two-shot Recommender Search</title><link>http://arxiv.org/abs/2310.20705v1</link><description>Weight-sharing Neural Architecture Search (WS-NAS) provides an efficientmechanism for developing end-to-end deep recommender models. However, incomplex search spaces, distinguishing between superior and inferiorarchitectures (or paths) is challenging. This challenge is compounded by thelimited coverage of the supernet and the co-adaptation of subnet weights, whichrestricts the exploration and exploitation capabilities inherent toweight-sharing mechanisms. To address these challenges, we introduce FarthestGreedy Path Sampling (FGPS), a new path sampling strategy that balances pathquality and diversity. FGPS enhances path diversity to facilitate morecomprehensive supernet exploration, while emphasizing path quality to ensurethe effective identification and utilization of promising architectures. Byincorporating FGPS into a Two-shot NAS (TS-NAS) framework, we derivehigh-performance architectures. Evaluations on three Click-Through Rate (CTR)prediction benchmarks demonstrate that our approach consistently achievessuperior results, outperforming both manually designed and most NAS-basedmodels.</description><author>Yufan Cao, Tunhou Zhang, Wei Wen, Feng Yan, Hai Li, Yiran Chen</author><pubDate>Tue, 31 Oct 2023 18:59:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20705v1</guid></item><item><title>DDAM-PS: Diligent Domain Adaptive Mixer for Person Search</title><link>http://arxiv.org/abs/2310.20706v1</link><description>Person search (PS) is a challenging computer vision problem where theobjective is to achieve joint optimization for pedestrian detection andre-identification (ReID). Although previous advancements have shown promisingperformance in the field under fully and weakly supervised learning fashion,there exists a major gap in investigating the domain adaptation ability of PSmodels. In this paper, we propose a diligent domain adaptive mixer (DDAM) forperson search (DDAP-PS) framework that aims to bridge a gap to improveknowledge transfer from the labeled source domain to the unlabeled targetdomain. Specifically, we introduce a novel DDAM module that generates moderatemixed-domain representations by combining source and target domainrepresentations. The proposed DDAM module encourages domain mixing to minimizethe distance between the two extreme domains, thereby enhancing the ReID task.To achieve this, we introduce two bridge losses and a disparity loss. Theobjective of the two bridge losses is to guide the moderate mixed-domainrepresentations to maintain an appropriate distance from both the source andtarget domain representations. The disparity loss aims to prevent the moderatemixed-domain representations from being biased towards either the source ortarget domains, thereby avoiding overfitting. Furthermore, we address theconflict between the two subtasks, localization and ReID, during domainadaptation. To handle this cross-task conflict, we forcefully decouple thenorm-aware embedding, which aids in better learning of the moderatemixed-domain representation. We conduct experiments to validate theeffectiveness of our proposed method. Our approach demonstrates favorableperformance on the challenging PRW and CUHK-SYSU datasets. Our source code ispublicly available at \url{https://github.com/mustansarfiaz/DDAM-PS}.</description><author>Mohammed Khaleed Almansoori, Mustansar Fiaz, Hisham Cholakkal</author><pubDate>Tue, 31 Oct 2023 18:59:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20706v1</guid></item><item><title>Limited Data, Unlimited Potential: A Study on ViTs Augmented by Masked Autoencoders</title><link>http://arxiv.org/abs/2310.20704v1</link><description>Vision Transformers (ViTs) have become ubiquitous in computer vision. Despitetheir success, ViTs lack inductive biases, which can make it difficult to trainthem with limited data. To address this challenge, prior studies suggesttraining ViTs with self-supervised learning (SSL) and fine-tuning sequentially.However, we observe that jointly optimizing ViTs for the primary task and aSelf-Supervised Auxiliary Task (SSAT) is surprisingly beneficial when theamount of training data is limited. We explore the appropriate SSL tasks thatcan be optimized alongside the primary task, the training schemes for thesetasks, and the data scale at which they can be most effective. Our findingsreveal that SSAT is a powerful technique that enables ViTs to leverage theunique characteristics of both the self-supervised and primary tasks, achievingbetter performance than typical ViTs pre-training with SSL and fine-tuningsequentially. Our experiments, conducted on 10 datasets, demonstrate that SSATsignificantly improves ViT performance while reducing carbon footprint. We alsoconfirm the effectiveness of SSAT in the video domain for deepfake detection,showcasing its generalizability. Our code is available athttps://github.com/dominickrei/Limited-data-vits.</description><author>Srijan Das, Tanmay Jain, Dominick Reilly, Pranav Balaji, Soumyajit Karmakar, Shyam Marjit, Xiang Li, Abhijit Das, Michael Ryoo</author><pubDate>Tue, 31 Oct 2023 18:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20704v1</guid></item><item><title>Vanishing Gradients in Reinforcement Finetuning of Language Models</title><link>http://arxiv.org/abs/2310.20703v1</link><description>Pretrained language models are commonly aligned with human preferences anddownstream tasks via reinforcement finetuning (RFT), which entails maximizing a(possibly learned) reward function using policy gradient algorithms. This workhighlights a fundamental optimization obstacle in RFT: we prove that theexpected gradient for an input vanishes when its reward standard deviationunder the model is small, even if the expected reward is far from optimal.Through experiments on an RFT benchmark and controlled environments, as well asa theoretical analysis, we then demonstrate that vanishing gradients due tosmall reward standard deviation are prevalent and detrimental, leading toextremely slow reward maximization. Lastly, we explore ways to overcomevanishing gradients in RFT. We find the common practice of an initialsupervised finetuning (SFT) phase to be the most promising candidate, whichsheds light on its importance in an RFT pipeline. Moreover, we show that arelatively small number of SFT optimization steps on as few as 1% of the inputsamples can suffice, indicating that the initial SFT phase need not beexpensive in terms of compute and data labeling efforts. Overall, our resultsemphasize that being mindful for inputs whose expected gradient vanishes, asmeasured by the reward standard deviation, is crucial for successful executionof RFT.</description><author>Noam Razin, Hattie Zhou, Omid Saremi, Vimal Thilak, Arwen Bradley, Preetum Nakkiran, Joshua Susskind, Etai Littwin</author><pubDate>Tue, 31 Oct 2023 18:59:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20703v1</guid></item><item><title>FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions</title><link>http://arxiv.org/abs/2310.15421v3</link><description>Theory of mind (ToM) evaluations currently focus on testing models usingpassive narratives that inherently lack interactivity. We introduce FANToM, anew benchmark designed to stress-test ToM within information-asymmetricconversational contexts via question answering. Our benchmark draws uponimportant theoretical requisites from psychology and necessary empiricalconsiderations when evaluating large language models (LLMs). In particular, weformulate multiple types of questions that demand the same underlying reasoningto identify illusory or false sense of ToM capabilities in LLMs. We show thatFANToM is challenging for state-of-the-art LLMs, which perform significantlyworse than humans even with chain-of-thought reasoning or fine-tuning.</description><author>Hyunwoo Kim, Melanie Sclar, Xuhui Zhou, Ronan Le Bras, Gunhee Kim, Yejin Choi, Maarten Sap</author><pubDate>Tue, 31 Oct 2023 18:58:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15421v3</guid></item><item><title>SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction</title><link>http://arxiv.org/abs/2310.20700v1</link><description>Recently video generation has achieved substantial progress with realisticresults. Nevertheless, existing AI-generated videos are usually very shortclips ("shot-level") depicting a single scene. To deliver a coherent long video("story-level"), it is desirable to have creative transition and predictioneffects across different clips. This paper presents a short-to-long videodiffusion model, SEINE, that focuses on generative transition and prediction.The goal is to generate high-quality long videos with smooth and creativetransitions between scenes and varying lengths of shot-level videos.Specifically, we propose a random-mask video diffusion model to automaticallygenerate transitions based on textual descriptions. By providing the images ofdifferent scenes as inputs, combined with text-based control, our modelgenerates transition videos that ensure coherence and visual quality.Furthermore, the model can be readily extended to various tasks such asimage-to-video animation and autoregressive video prediction. To conduct acomprehensive evaluation of this new generative task, we propose threeassessing criteria for smooth and creative transition: temporal consistency,semantic similarity, and video-text semantic alignment. Extensive experimentsvalidate the effectiveness of our approach over existing methods for generativetransition and prediction, enabling the creation of story-level long videos.Project page: https://vchitect.github.io/SEINE-project/ .</description><author>Xinyuan Chen, Yaohui Wang, Lingjun Zhang, Shaobin Zhuang, Xin Ma, Jiashuo Yu, Yali Wang, Dahua Lin, Yu Qiao, Ziwei Liu</author><pubDate>Tue, 31 Oct 2023 18:58:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20700v1</guid></item><item><title>Bayesian Multistate Bennett Acceptance Ratio Methods</title><link>http://arxiv.org/abs/2310.20699v1</link><description>The multistate Bennett acceptance ratio (MBAR) method is a prevalent approachfor computing free energies of thermodynamic states. In this work, we introduceBayesMBAR, a Bayesian generalization of the MBAR method. By integratingconfigurations sampled from thermodynamic states with a prior distribution,BayesMBAR computes a posterior distribution of free energies. Using theposterior distribution, we derive free energy estimations and compute theirassociated uncertainties. Notably, when a uniform prior distribution is used,BayesMBAR recovers the MBAR's result but provides more accurate uncertaintyestimates. Additionally, when prior knowledge about free energies is available,BayesMBAR can incorporate this information into the estimation procedure byusing non-uniform prior distributions. As an example, we show that, byincorporating the prior knowledge about the smoothness of free energy surfaces,BayesMBAR provides more accurate estimates than the MBAR method. Given MBAR'swidespread use in free energy calculations, we anticipate BayesMBAR to be anessential tool in various applications of free energy calculations.</description><author>Xinqiang Ding</author><pubDate>Tue, 31 Oct 2023 18:57:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20699v1</guid></item><item><title>From External to Swap Regret 2.0: An Efficient Reduction and Oblivious Adversary for Large Action Spaces</title><link>http://arxiv.org/abs/2310.19786v2</link><description>We provide a novel reduction from swap-regret minimization to external-regretminimization, which improves upon the classical reductions of Blum-Mansour[BM07] and Stolz-Lugosi [SL05] in that it does not require finiteness of thespace of actions. We show that, whenever there exists a no-external-regretalgorithm for some hypothesis class, there must also exist a no-swap-regretalgorithm for that same class. For the problem of learning with expert advice,our result implies that it is possible to guarantee that the swap regret isbounded by {\epsilon} after $\log(N)^{O(1/\epsilon)}$ rounds and with $O(N)$per iteration complexity, where $N$ is the number of experts, while theclassical reductions of Blum-Mansour and Stolz-Lugosi require $O(N/\epsilon^2)$rounds and at least $\Omega(N^2)$ per iteration complexity. Our result comeswith an associated lower bound, which -- in contrast to that in [BM07] -- holdsfor oblivious and $\ell_1$-constrained adversaries and learners that can employdistributions over experts, showing that the number of rounds must be$\tilde\Omega(N/\epsilon^2)$ or exponential in $1/\epsilon$. Our reduction implies that, if no-regret learning is possible in some game,then this game must have approximate correlated equilibria, of arbitrarily goodapproximation. This strengthens the folklore implication of no-regret learningthat approximate coarse correlated equilibria exist. Importantly, it provides asufficient condition for the existence of correlated equilibrium which vastlyextends the requirement that the action set is finite, thus answering aquestion left open by [DG22; Ass+23]. Moreover, it answers several outstandingquestions about equilibrium computation and/or learning in games.</description><author>Yuval Dagan, Constantinos Daskalakis, Maxwell Fishelson, Noah Golowich</author><pubDate>Tue, 31 Oct 2023 18:57:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19786v2</guid></item><item><title>Text-Transport: Toward Learning Causal Effects of Natural Language</title><link>http://arxiv.org/abs/2310.20697v1</link><description>As language technologies gain prominence in real-world settings, it isimportant to understand how changes to language affect reader perceptions. Thiscan be formalized as the causal effect of varying a linguistic attribute (e.g.,sentiment) on a reader's response to the text. In this paper, we introduceText-Transport, a method for estimation of causal effects from natural languageunder any text distribution. Current approaches for valid causal effectestimation require strong assumptions about the data, meaning the data fromwhich one can estimate valid causal effects often is not representative of theactual target domain of interest. To address this issue, we leverage the notionof distribution shift to describe an estimator that transports causal effectsbetween domains, bypassing the need for strong assumptions in the targetdomain. We derive statistical guarantees on the uncertainty of this estimator,and we report empirical results and analyses that support the validity ofText-Transport across data settings. Finally, we use Text-Transport to study arealistic setting--hate speech on social media--in which causal effects doshift significantly between text domains, demonstrating the necessity oftransport when conducting causal inference on natural language.</description><author>Victoria Lin, Louis-Philippe Morency, Eli Ben-Michael</author><pubDate>Tue, 31 Oct 2023 18:56:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20697v1</guid></item><item><title>HAP: Structure-Aware Masked Image Modeling for Human-Centric Perception</title><link>http://arxiv.org/abs/2310.20695v1</link><description>Model pre-training is essential in human-centric perception. In this paper,we first introduce masked image modeling (MIM) as a pre-training approach forthis task. Upon revisiting the MIM training strategy, we reveal that humanstructure priors offer significant potential. Motivated by this insight, wefurther incorporate an intuitive human structure prior - human parts - intopre-training. Specifically, we employ this prior to guide the mask samplingprocess. Image patches, corresponding to human part regions, have high priorityto be masked out. This encourages the model to concentrate more on bodystructure information during pre-training, yielding substantial benefits acrossa range of human-centric perception tasks. To further capture humancharacteristics, we propose a structure-invariant alignment loss that enforcesdifferent masked views, guided by the human part prior, to be closely alignedfor the same image. We term the entire method as HAP. HAP simply uses a plainViT as the encoder yet establishes new state-of-the-art performance on 11human-centric benchmarks, and on-par result on one dataset. For example, HAPachieves 78.1% mAP on MSMT17 for person re-identification, 86.54% mA on PA-100Kfor pedestrian attribute recognition, 78.2% AP on MS COCO for 2D poseestimation, and 56.0 PA-MPJPE on 3DPW for 3D pose and shape estimation.</description><author>Junkun Yuan, Xinyu Zhang, Hao Zhou, Jian Wang, Zhongwei Qiu, Zhiyin Shao, Shaofeng Zhang, Sifan Long, Kun Kuang, Kun Yao, Junyu Han, Errui Ding, Lanfen Lin, Fei Wu, Jingdong Wang</author><pubDate>Tue, 31 Oct 2023 18:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20695v1</guid></item><item><title>AI for Open Science: A Multi-Agent Perspective for Ethically Translating Data to Knowledge</title><link>http://arxiv.org/abs/2310.18852v2</link><description>AI for Science (AI4Science), particularly in the form of self-driving labs,has the potential to sideline human involvement and hinder scientific discoverywithin the broader community. While prior research has focused on ensuring theresponsible deployment of AI applications, enhancing security, and ensuringinterpretability, we also propose that promoting openness in AI4Sciencediscoveries should be carefully considered. In this paper, we introduce theconcept of AI for Open Science (AI4OS) as a multi-agent extension of AI4Sciencewith the core principle of maximizing open knowledge translation throughout thescientific enterprise rather than a single organizational unit. We use theestablished principles of Knowledge Discovery and Data Mining (KDD) toformalize a language around AI4OS. We then discuss three principle stages ofknowledge translation embedded in AI4Science systems and detail specific pointswhere openness can be applied to yield an AI4OS alternative. Lastly, weformulate a theoretical metric to assess AI4OS with a supporting ethicalargument highlighting its importance. Our goal is that by drawing attention toAI4OS we can ensure the natural consequence of AI4Science (e.g., self-drivinglabs) is a benefit not only for its developers but for society as a whole.</description><author>Chase Yakaboski, Gregory Hyde, Clement Nyanhongo, Eugene Santos Jr</author><pubDate>Tue, 31 Oct 2023 18:54:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18852v2</guid></item><item><title>Learning From Mistakes Makes LLM Better Reasoner</title><link>http://arxiv.org/abs/2310.20689v1</link><description>Large language models (LLMs) recently exhibited remarkable reasoningcapabilities on solving math problems. To further improve this capability, thiswork proposes Learning from Mistakes (LeMa), akin to human learning processes.Consider a human student who failed to solve a math problem, he will learn fromwhat mistake he has made and how to correct it. Mimicking this error-drivenlearning process, LeMa fine-tunes LLMs on mistake-correction data pairsgenerated by GPT-4. Specifically, we first collect inaccurate reasoning pathsfrom various LLMs and then employ GPT-4 as a "corrector" to (1) identify themistake step, (2) explain the reason for the mistake, and (3) correct themistake and generate the final answer. Experimental results demonstrate theeffectiveness of LeMa: across five backbone LLMs and two mathematical reasoningtasks, LeMa consistently improves the performance compared with fine-tuning onCoT data alone. Impressively, LeMa can also benefit specialized LLMs such asWizardMath and MetaMath, achieving 85.4% pass@1 accuracy on GSM8K and 27.1% onMATH. This surpasses the SOTA performance achieved by non-execution open-sourcemodels on these challenging tasks. Our code, data and models will be publiclyavailable at https://github.com/microsoft/CodeT.</description><author>Shengnan An, Zexiong Ma, Zeqi Lin, Nanning Zheng, Jian-Guang Lou, Weizhu Chen</author><pubDate>Tue, 31 Oct 2023 18:52:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20689v1</guid></item><item><title>Ziya-Visual: Bilingual Large Vision-Language Model via Multi-Task Instruction Tuning</title><link>http://arxiv.org/abs/2310.08166v3</link><description>Recent advancements enlarge the capabilities of large language models (LLMs)in zero-shot image-to-text generation and understanding by integratingmulti-modal inputs. However, such success is typically limited to Englishscenarios due to the lack of large-scale and high-quality non-Englishmulti-modal resources, making it extremely difficult to establish competitivecounterparts in other languages. In this paper, we introduce the Ziya-Visualseries, a set of bilingual large-scale vision-language models (LVLMs) designedto incorporate visual semantics into LLM for multi-modal dialogue. Composed ofZiya-Visual-Base and Ziya-Visual-Chat, our models adopt the QueryingTransformer from BLIP-2, further exploring the assistance of optimizationschemes such as instruction tuning, multi-stage training and low-rankadaptation module for visual-language alignment. In addition, we stimulate theunderstanding ability of GPT-4 in multi-modal scenarios, translating ourgathered English image-text datasets into Chinese and generatinginstruction-response through the in-context learning method. The experimentresults demonstrate that compared to the existing LVLMs, Ziya-Visual achievescompetitive performance across a wide range of English-only tasks includingzero-shot image-text retrieval, image captioning, and visual questionanswering. The evaluation leaderboard accessed by GPT-4 also indicates that ourmodels possess satisfactory image-text understanding and generationcapabilities in Chinese multi-modal scenario dialogues. Code, demo and modelsare available at~\url{https://huggingface.co/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1}.</description><author>Junyu Lu, Dixiang Zhang, Xiaojun Wu, Xinyu Gao, Ruyi Gan, Jiaxing Zhang, Yan Song, Pingjian Zhang</author><pubDate>Tue, 31 Oct 2023 18:51:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08166v3</guid></item><item><title>NeRF Revisited: Fixing Quadrature Instability in Volume Rendering</title><link>http://arxiv.org/abs/2310.20685v1</link><description>Neural radiance fields (NeRF) rely on volume rendering to synthesize novelviews. Volume rendering requires evaluating an integral along each ray, whichis numerically approximated with a finite sum that corresponds to the exactintegral along the ray under piecewise constant volume density. As aconsequence, the rendered result is unstable w.r.t. the choice of samples alongthe ray, a phenomenon that we dub quadrature instability. We propose amathematically principled solution by reformulating the sample-based renderingequation so that it corresponds to the exact integral under piecewise linearvolume density. This simultaneously resolves multiple issues: conflicts betweensamples along different rays, imprecise hierarchical sampling, andnon-differentiability of quantiles of ray termination distances w.r.t. modelparameters. We demonstrate several benefits over the classical sample-basedrendering equation, such as sharper textures, better geometric reconstruction,and stronger depth supervision. Our proposed formulation can be also be used asa drop-in replacement to the volume rendering equation of existing NeRF-basedmethods. Our project page can be found at pl-nerf.github.io.</description><author>Mikaela Angelina Uy, Kiyohiro Nakayama, Guandao Yang, Rahul Krishna Thomas, Leonidas Guibas, Ke Li</author><pubDate>Tue, 31 Oct 2023 18:49:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20685v1</guid></item><item><title>Differentially Private Image Classification by Learning Priors from Random Processes</title><link>http://arxiv.org/abs/2306.06076v2</link><description>In privacy-preserving machine learning, differentially private stochasticgradient descent (DP-SGD) performs worse than SGD due to per-sample gradientclipping and noise addition. A recent focus in private learning research isimproving the performance of DP-SGD on private data by incorporating priorsthat are learned on real-world public data. In this work, we explore how we canimprove the privacy-utility tradeoff of DP-SGD by learning priors from imagesgenerated by random processes and transferring these priors to private data. Wepropose DP-RandP, a three-phase approach. We attain new state-of-the-artaccuracy when training from scratch on CIFAR10, CIFAR100, MedMNIST and ImageNetfor a range of privacy budgets $\varepsilon \in [1, 8]$. In particular, weimprove the previous best reported accuracy on CIFAR10 from $60.6 \%$ to $72.3\%$ for $\varepsilon=1$.</description><author>Xinyu Tang, Ashwinee Panda, Vikash Sehwag, Prateek Mittal</author><pubDate>Tue, 31 Oct 2023 18:49:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06076v2</guid></item><item><title>Compression with Exact Error Distribution for Federated Learning</title><link>http://arxiv.org/abs/2310.20682v1</link><description>Compression schemes have been extensively used in Federated Learning (FL) toreduce the communication cost of distributed learning. While most approachesrely on a bounded variance assumption of the noise produced by the compressor,this paper investigates the use of compression and aggregation schemes thatproduce a specific error distribution, e.g., Gaussian or Laplace, on theaggregated data. We present and analyze different aggregation schemes based onlayered quantizers achieving exact error distribution. We provide differentmethods to leverage the proposed compression schemes to obtaincompression-for-free in differential privacy applications. Our generalcompression methods can recover and improve standard FL schemes with Gaussianperturbations such as Langevin dynamics and randomized smoothing.</description><author>Mahmoud Hegazy, Rémi Leluc, Cheuk Ting Li, Aymeric Dieuleveut</author><pubDate>Tue, 31 Oct 2023 18:48:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20682v1</guid></item><item><title>Latent Field Discovery In Interacting Dynamical Systems With Neural Fields</title><link>http://arxiv.org/abs/2310.20679v1</link><description>Systems of interacting objects often evolve under the influence of fieldeffects that govern their dynamics, yet previous works have abstracted awayfrom such effects, and assume that systems evolve in a vacuum. In this work, wefocus on discovering these fields, and infer them from the observed dynamicsalone, without directly observing them. We theorize the presence of latentforce fields, and propose neural fields to learn them. Since the observeddynamics constitute the net effect of local object interactions and globalfield effects, recently popularized equivariant networks are inapplicable, asthey fail to capture global information. To address this, we propose todisentangle local object interactions -- which are $\mathrm{SE}(n)$ equivariantand depend on relative states -- from external global field effects -- whichdepend on absolute states. We model interactions with equivariant graphnetworks, and combine them with neural fields in a novel graph network thatintegrates field forces. Our experiments show that we can accurately discoverthe underlying fields in charged particles settings, traffic scenes, andgravitational n-body problems, and effectively use them to learn the system andforecast future trajectories.</description><author>Miltiadis Kofinas, Erik J. Bekkers, Naveen Shankar Nagaraja, Efstratios Gavves</author><pubDate>Tue, 31 Oct 2023 18:45:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20679v1</guid></item><item><title>Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models</title><link>http://arxiv.org/abs/2304.09842v3</link><description>Large language models (LLMs) have achieved remarkable progress in solvingvarious natural language processing tasks due to emergent reasoning abilities.However, LLMs have inherent limitations as they are incapable of accessingup-to-date information (stored on the Web or in task-specific knowledge bases),using external tools, and performing precise mathematical and logicalreasoning. In this paper, we present Chameleon, an AI system that mitigatesthese limitations by augmenting LLMs with plug-and-play modules forcompositional reasoning. Chameleon synthesizes programs by composing varioustools (e.g., LLMs, off-the-shelf vision models, web search engines, Pythonfunctions, and heuristic-based modules) for accomplishing complex reasoningtasks. At the heart of Chameleon is an LLM-based planner that assembles asequence of tools to execute to generate the final response. We showcase theeffectiveness of Chameleon on two multi-modal knowledge-intensive reasoningtasks: ScienceQA and TabMWP. Chameleon, powered by GPT-4, achieves an 86.54%overall accuracy on ScienceQA, improving the best published few-shot result by11.37%. On TabMWP, GPT-4-powered Chameleon improves the accuracy by 17.0%,lifting the state of the art to 98.78%. Our analysis also shows that theGPT-4-powered planner exhibits more consistent and rational tool selection viainferring potential constraints from instructions, compared to aChatGPT-powered planner. The project is available athttps://chameleon-llm.github.io.</description><author>Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Jianfeng Gao</author><pubDate>Tue, 31 Oct 2023 18:43:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.09842v3</guid></item><item><title>Quality-Diversity through AI Feedback</title><link>http://arxiv.org/abs/2310.13032v2</link><description>In many text-generation problems, users may prefer not only a singleresponse, but a diverse range of high-quality outputs from which to choose.Quality-diversity (QD) search algorithms aim at such outcomes, by continuallyimproving and diversifying a population of candidates. However, theapplicability of QD to qualitative domains, like creative writing, has beenlimited by the difficulty of algorithmically specifying measures of quality anddiversity. Interestingly, recent developments in language models (LMs) haveenabled guiding search through AI feedback, wherein LMs are prompted in naturallanguage to evaluate qualitative aspects of text. Leveraging this development,we introduce Quality-Diversity through AI Feedback (QDAIF), wherein anevolutionary algorithm applies LMs to both generate variation and evaluate thequality and diversity of candidate text. When assessed on creative writingdomains, QDAIF covers more of a specified search space with high-qualitysamples than do non-QD controls. Further, human evaluation of QDAIF-generatedcreative texts validates reasonable agreement between AI and human evaluation.Our results thus highlight the potential of AI feedback to guide open-endedsearch for creative and original solutions, providing a recipe that seeminglygeneralizes to many domains and modalities. In this way, QDAIF is a steptowards AI systems that can independently search, diversify, evaluate, andimprove, which are among the core skills underlying human society's capacityfor innovation.</description><author>Herbie Bradley, Andrew Dai, Hannah Teufel, Jenny Zhang, Koen Oostermeijer, Marco Bellagente, Jeff Clune, Kenneth Stanley, Grégory Schott, Joel Lehman</author><pubDate>Tue, 31 Oct 2023 18:43:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13032v2</guid></item><item><title>Balancing Act: Constraining Disparate Impact in Sparse Models</title><link>http://arxiv.org/abs/2310.20673v1</link><description>Model pruning is a popular approach to enable the deployment of large deeplearning models on edge devices with restricted computational or storagecapacities. Although sparse models achieve performance comparable to that oftheir dense counterparts at the level of the entire dataset, they exhibit highaccuracy drops for some data sub-groups. Existing methods to mitigate thisdisparate impact induced by pruning (i) rely on surrogate metrics that addressthe problem indirectly and have limited interpretability; or (ii) scale poorlywith the number of protected sub-groups in terms of computational cost. Wepropose a constrained optimization approach that $\textit{directly addressesthe disparate impact of pruning}$: our formulation bounds the accuracy changebetween the dense and sparse models, for each sub-group. This choice ofconstraints provides an interpretable success criterion to determine if apruned model achieves acceptable disparity levels. Experimental resultsdemonstrate that our technique scales reliably to problems involving largemodels and hundreds of protected sub-groups.</description><author>Meraj Hashemizadeh, Juan Ramirez, Rohan Sukumaran, Golnoosh Farnadi, Simon Lacoste-Julien, Jose Gallego-Posada</author><pubDate>Tue, 31 Oct 2023 18:37:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20673v1</guid></item><item><title>Causal Q-Aggregation for CATE Model Selection</title><link>http://arxiv.org/abs/2310.16945v2</link><description>Accurate estimation of conditional average treatment effects (CATE) is at thecore of personalized decision making. While there is a plethora of models forCATE estimation, model selection is a nontrivial task, due to the fundamentalproblem of causal inference. Recent empirical work provides evidence in favorof proxy loss metrics with double robust properties and in favor of modelensembling. However, theoretical understanding is lacking. Direct applicationof prior theoretical work leads to suboptimal oracle model selection rates dueto the non-convexity of the model selection problem. We provide regret ratesfor the major existing CATE ensembling approaches and propose a new CATE modelensembling approach based on Q-aggregation using the doubly robust loss. Ourmain result shows that causal Q-aggregation achieves statistically optimaloracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and$n$ samples), with the addition of higher-order estimation error terms relatedto products of errors in the nuisance functions. Crucially, our regret ratedoes not require that any of the candidate CATE models be close to the truth.We validate our new method on many semi-synthetic datasets and also provideextensions of our work to CATE model selection with instrumental variables andunobserved confounding.</description><author>Hui Lan, Vasilis Syrgkanis</author><pubDate>Tue, 31 Oct 2023 18:32:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.16945v2</guid></item><item><title>Density Matrix Emulation of Quantum Recurrent Neural Networks for Multivariate Time Series Prediction</title><link>http://arxiv.org/abs/2310.20671v1</link><description>Quantum Recurrent Neural Networks (QRNNs) are robust candidates to model andpredict future values in multivariate time series. However, the effectiveimplementation of some QRNN models is limited by the need of mid-circuitmeasurements. Those increase the requirements for quantum hardware, which inthe current NISQ era does not allow reliable computations. Emulation arises asthe main near-term alternative to explore the potential of QRNNs, but existingquantum emulators are not dedicated to circuits with multiple intermediatemeasurements. In this context, we design a specific emulation method thatrelies on density matrix formalism. The mathematical development is explicitlyprovided as a compact formulation by using tensor notation. It allows us toshow how the present and past information from a time series is transmittedthrough the circuit, and how to reduce the computational cost in every timestep of the emulated network. In addition, we derive the analytical gradientand the Hessian of the network outputs with respect to its trainableparameters, with an eye on gradient-based training and noisy outputs that wouldappear when using real quantum processors. We finally test the presentedmethods using a novel hardware-efficient ansatz and three diverse datasets thatinclude univariate and multivariate time series. Our results show how QRNNs canmake accurate predictions of future values by capturing non-trivial patterns ofinput series with different complexities.</description><author>José Daniel Viqueira, Daniel Faílde, Mariamo M. Juane, Andrés Gómez, David Mera</author><pubDate>Tue, 31 Oct 2023 18:32:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20671v1</guid></item><item><title>StairNet: Visual Recognition of Stairs for Human-Robot Locomotion</title><link>http://arxiv.org/abs/2310.20666v1</link><description>Human-robot walking with prosthetic legs and exoskeletons, especially overcomplex terrains such as stairs, remains a significant challenge. Egocentricvision has the unique potential to detect the walking environment prior tophysical interactions, which can improve transitions to and from stairs. Thismotivated us to create the StairNet initiative to support the development ofnew deep learning models for visual sensing and recognition of stairs, with anemphasis on lightweight and efficient neural networks for onboard real-timeinference. In this study, we present an overview of the development of ourlarge-scale dataset with over 515,000 manually labeled images, as well as ourdevelopment of different deep learning models (e.g., 2D and 3D CNN, hybrid CNNand LSTM, and ViT networks) and training methods (e.g., supervised learningwith temporal data and semi-supervised learning with unlabeled images) usingour new dataset. We consistently achieved high classification accuracy (i.e.,up to 98.8%) with different designs, offering trade-offs between model accuracyand size. When deployed on mobile devices with GPU and NPU accelerators, ourdeep learning models achieved inference speeds up to 2.8 ms. We also deployedour models on custom-designed CPU-powered smart glasses. However, limitationsin the embedded hardware yielded slower inference speeds of 1.5 seconds,presenting a trade-off between human-centered design and performance. Overall,we showed that StairNet can be an effective platform to develop and study newvisual perception systems for human-robot locomotion with applications inexoskeleton and prosthetic leg control.</description><author>Andrew Garrett Kurbis, Dmytro Kuzmenko, Bogdan Ivanyuk-Skulskiy, Alex Mihailidis, Brokoslaw Laschowski</author><pubDate>Tue, 31 Oct 2023 18:30:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20666v1</guid></item><item><title>Offline RL with Observation Histories: Analyzing and Improving Sample Complexity</title><link>http://arxiv.org/abs/2310.20663v1</link><description>Offline reinforcement learning (RL) can in principle synthesize more optimalbehavior from a dataset consisting only of suboptimal trials. One way that thiscan happen is by "stitching" together the best parts of otherwise suboptimaltrajectories that overlap on similar states, to create new behaviors where eachindividual state is in-distribution, but the overall returns are higher.However, in many interesting and complex applications, such as autonomousnavigation and dialogue systems, the state is partially observed. Even worse,the state representation is unknown or not easy to define. In such cases,policies and value functions are often conditioned on observation historiesinstead of states. In these cases, it is not clear if the same kind of"stitching" is feasible at the level of observation histories, since twodifferent trajectories would always have different histories, and thus "similarstates" that might lead to effective stitching cannot be leveraged.Theoretically, we show that standard offline RL algorithms conditioned onobservation histories suffer from poor sample complexity, in accordance withthe above intuition. We then identify sufficient conditions under which offlineRL can still be efficient -- intuitively, it needs to learn a compactrepresentation of history comprising only features relevant for actionselection. We introduce a bisimulation loss that captures the extent to whichthis happens, and propose that offline RL can explicitly optimize this loss toaid worst-case sample complexity. Empirically, we show that across a variety oftasks either our proposed loss improves performance, or the value of this lossis already minimized as a consequence of standard offline RL, indicating thatit correlates well with good performance.</description><author>Joey Hong, Anca Dragan, Sergey Levine</author><pubDate>Tue, 31 Oct 2023 18:29:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20663v1</guid></item><item><title>How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench</title><link>http://arxiv.org/abs/2305.14947v2</link><description>We investigate the predictability of large language model (LLM) capabilities:given records of past experiments using different model families, numbers ofparameters, tasks, and numbers of in-context examples, can we accuratelypredict LLM performance on new experiment configurations? Answering thisquestion has practical implications for LLM users (e.g., deciding which modelsto try), developers (e.g., prioritizing evaluation on representative tasks),and the research community (e.g., identifying hard-to-predict capabilities thatwarrant further investigation). We study the performance prediction problem on experiment records fromBIG-bench. On a random train-test split, an MLP-based predictor achieves an$R^2$ score greater than 95%, indicating the presence of learnable patternswithin the experiment records. We then formulate the problem of searching for"small-bench," an informative subset of BIG-bench tasks from which theperformance on the full set can be maximally recovered. We find a subset asinformative as BIG-bench Hard for evaluating new model families, while being$3\times$ smaller. Additionally, we find competitive subsets by clustering taskrepresentations learned by our MLP-based predictor and selecting tasks close tocluster centroids, highlighting the importance of task diversity inconstructing "small-bench."</description><author>Qinyuan Ye, Harvey Yiyun Fu, Xiang Ren, Robin Jia</author><pubDate>Tue, 31 Oct 2023 18:27:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14947v2</guid></item><item><title>Non-Compositionality in Sentiment: New Data and Analyses</title><link>http://arxiv.org/abs/2310.20656v1</link><description>When natural language phrases are combined, their meaning is often more thanthe sum of their parts. In the context of NLP tasks such as sentiment analysis,where the meaning of a phrase is its sentiment, that still applies. Many NLPstudies on sentiment analysis, however, focus on the fact that sentimentcomputations are largely compositional. We, instead, set out to obtainnon-compositionality ratings for phrases with respect to their sentiment. Ourcontributions are as follows: a) a methodology for obtaining thosenon-compositionality ratings, b) a resource of ratings for 259 phrases --NonCompSST -- along with an analysis of that resource, and c) an evaluation ofcomputational models for sentiment analysis using this new resource.</description><author>Verna Dankers, Christopher G. Lucas</author><pubDate>Tue, 31 Oct 2023 18:25:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20656v1</guid></item><item><title>"Pick-and-Pass" as a Hat-Trick Class for First-Principle Memory, Generalizability, and Interpretability Benchmarks</title><link>http://arxiv.org/abs/2310.20654v1</link><description>Closed drafting or "pick and pass" is a popular game mechanic where eachround players select a card or other playable element from their hand and passthe rest to the next player. Games employing closed drafting make for greatstudies on memory and turn order due to their explicitly calculable memory ofother players' hands. In this paper, we establish first-principle benchmarksfor studying model-free reinforcement learning algorithms and their comparativeability to learn memory in a popular family of closed drafting games called"Sushi Go Party!", producing state-of-the-art results on this environment alongthe way. Furthermore, as Sushi Go Party! can be expressed as a set ofclosely-related games based on the set of cards in play, we quantify thegeneralizability of reinforcement learning algorithms trained on various setsof cards, establishing key trends between generalized performance and the setdistance between the train and evaluation game configurations. Finally, we fitdecision rules to interpret the strategy of the learned models and compare themto the ranking preferences of human players, finding intuitive common rules andintriguing new moves.</description><author>Jason Wang, Ryan Rezai</author><pubDate>Tue, 31 Oct 2023 18:24:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20654v1</guid></item><item><title>A Vision-free Baseline for Multimodal Grammar Induction</title><link>http://arxiv.org/abs/2212.10564v2</link><description>Past work has shown that paired vision-language signals substantially improvegrammar induction in multimodal datasets such as MSCOCO. We investigate whetheradvancements in large language models (LLMs) that are only trained with textcould provide strong assistance for grammar induction in multimodal settings.We find that our text-only approach, an LLM-based C-PCFG (LC-PCFG), outperformsprevious multi-modal methods, and achieves state-of-the-art grammar inductionperformance for various multimodal datasets. Compared to image-aided grammarinduction, LC-PCFG outperforms the prior state-of-the-art by 7.9 Corpus-F1points, with an 85% reduction in parameter count and 1.7x faster trainingspeed. Across three video-assisted grammar induction benchmarks, LC-PCFGoutperforms prior state-of-the-art by up to 7.7 Corpus-F1, with 8.8x fastertraining. These results shed light on the notion that text-only language modelsmight include visually grounded cues that aid in grammar induction inmultimodal contexts. Moreover, our results emphasize the importance ofestablishing a robust vision-free baseline when evaluating the benefit ofmultimodal approaches.</description><author>Boyi Li, Rodolfo Corona, Karttikeya Mangalam, Catherine Chen, Daniel Flaherty, Serge Belongie, Kilian Q. Weinberger, Jitendra Malik, Trevor Darrell, Dan Klein</author><pubDate>Tue, 31 Oct 2023 18:22:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.10564v2</guid></item><item><title>GLEN: General-Purpose Event Detection for Thousands of Types</title><link>http://arxiv.org/abs/2303.09093v3</link><description>The progress of event extraction research has been hindered by the absence ofwide-coverage, large-scale datasets. To make event extraction systems moreaccessible, we build a general-purpose event detection dataset GLEN, whichcovers 205K event mentions with 3,465 different types, making it more than 20xlarger in ontology than today's largest event dataset. GLEN is created byutilizing the DWD Overlay, which provides a mapping between Wikidata Qnodes andPropBank rolesets. This enables us to use the abundant existing annotation forPropBank as distant supervision. In addition, we also propose a new multi-stageevent detection model CEDAR specifically designed to handle the large ontologysize in GLEN. We show that our model exhibits superior performance compared toa range of baselines including InstructGPT. Finally, we perform error analysisand show that label noise is still the largest challenge for improvingperformance for this new dataset. Our dataset, code, and models are released at\url{https://github.com/ZQS1943/GLEN}.}</description><author>Qiusi Zhan, Sha Li, Kathryn Conger, Martha Palmer, Heng Ji, Jiawei Han</author><pubDate>Tue, 31 Oct 2023 18:21:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.09093v3</guid></item><item><title>Addressing Limitations of State-Aware Imitation Learning for Autonomous Driving</title><link>http://arxiv.org/abs/2310.20650v1</link><description>Conditional Imitation learning is a common and effective approach to trainautonomous driving agents. However, two issues limit the full potential of thisapproach: (i) the inertia problem, a special case of causal confusion where theagent mistakenly correlates low speed with no acceleration, and (ii) lowcorrelation between offline and online performance due to the accumulation ofsmall errors that brings the agent in a previously unseen state. Both issuesare critical for state-aware models, yet informing the driving agent of itsinternal state as well as the state of the environment is of crucialimportance. In this paper we propose a multi-task learning agent based on amulti-stage vision transformer with state token propagation. We feed the stateof the vehicle along with the representation of the environment as a specialtoken of the transformer and propagate it throughout the network. This allowsus to tackle the aforementioned issues from different angles: guiding thedriving policy with learned stop/go information, performing data augmentationdirectly on the state of the vehicle and visually explaining the model'sdecisions. We report a drastic decrease in inertia and a high correlationbetween offline and online metrics.</description><author>Luca Cultrera, Federico Becattini, Lorenzo Seidenari, Pietro Pala, Alberto Del Bimbo</author><pubDate>Tue, 31 Oct 2023 18:21:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20650v1</guid></item><item><title>Template-free Articulated Neural Point Clouds for Reposable View Synthesis</title><link>http://arxiv.org/abs/2305.19065v2</link><description>Dynamic Neural Radiance Fields (NeRFs) achieve remarkable visual quality whensynthesizing novel views of time-evolving 3D scenes. However, the commonreliance on backward deformation fields makes reanimation of the capturedobject poses challenging. Moreover, the state of the art dynamic models areoften limited by low visual fidelity, long reconstruction time or specificityto narrow application domains. In this paper, we present a novel methodutilizing a point-based representation and Linear Blend Skinning (LBS) tojointly learn a Dynamic NeRF and an associated skeletal model from even sparsemulti-view video. Our forward-warping approach achieves state-of-the-art visualfidelity when synthesizing novel views and poses while significantly reducingthe necessary learning time when compared to existing work. We demonstrate theversatility of our representation on a variety of articulated objects fromcommon datasets and obtain reposable 3D reconstructions without the need ofobject-specific skeletal templates. Code will be made available athttps://github.com/lukasuz/Articulated-Point-NeRF.</description><author>Lukas Uzolas, Elmar Eisemann, Petr Kellnhofer</author><pubDate>Tue, 31 Oct 2023 18:20:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19065v2</guid></item><item><title>Dynamic Batch Norm Statistics Update for Natural Robustness</title><link>http://arxiv.org/abs/2310.20649v1</link><description>DNNs trained on natural clean samples have been shown to perform poorly oncorrupted samples, such as noisy or blurry images. Various data augmentationmethods have been recently proposed to improve DNN's robustness against commoncorruptions. Despite their success, they require computationally expensivetraining and cannot be applied to off-the-shelf trained models. Recently, ithas been shown that updating BatchNorm (BN) statistics of an off-the-shelfmodel on a single corruption improves its accuracy on that corruptionsignificantly. However, adopting the idea at inference time when the type ofcorruption is unknown and changing decreases the effectiveness of this method.In this paper, we harness the Fourier domain to detect the corruption type, achallenging task in the image domain. We propose a unified framework consistingof a corruption-detection model and BN statistics update that improves thecorruption accuracy of any off-the-shelf trained model. We benchmark ourframework on different models and datasets. Our results demonstrate about 8%and 4% accuracy improvement on CIFAR10-C and ImageNet-C, respectively.Furthermore, our framework can further improve the accuracy of state-of-the-artrobust models, such as AugMix and DeepAug.</description><author>Shahbaz Rezaei, Mohammad Sadegh Norouzzadeh</author><pubDate>Tue, 31 Oct 2023 18:20:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20649v1</guid></item><item><title>Explaining Predictive Uncertainty with Information Theoretic Shapley Values</title><link>http://arxiv.org/abs/2306.05724v2</link><description>Researchers in explainable artificial intelligence have developed numerousmethods for helping users understand the predictions of complex supervisedlearning models. By contrast, explaining the $\textit{uncertainty}$ of modeloutputs has received relatively little attention. We adapt the popular Shapleyvalue framework to explain various types of predictive uncertainty, quantifyingeach feature's contribution to the conditional entropy of individual modeloutputs. We consider games with modified characteristic functions and find deepconnections between the resulting Shapley values and fundamental quantitiesfrom information theory and conditional independence testing. We outlineinference procedures for finite sample error rate control with provableguarantees, and implement efficient algorithms that perform well in a range ofexperiments on real and simulated data. Our method has applications tocovariate shift detection, active learning, feature selection, and activefeature-value acquisition.</description><author>David S. Watson, Joshua O'Hara, Niek Tax, Richard Mudd, Ido Guy</author><pubDate>Tue, 31 Oct 2023 18:15:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05724v2</guid></item><item><title>Replicable Reinforcement Learning</title><link>http://arxiv.org/abs/2305.15284v4</link><description>The replicability crisis in the social, behavioral, and data sciences has ledto the formulation of algorithm frameworks for replicability -- i.e., arequirement that an algorithm produce identical outputs (with high probability)when run on two different samples from the same underlying distribution. Whilestill in its infancy, provably replicable algorithms have been developed formany fundamental tasks in machine learning and statistics, includingstatistical query learning, the heavy hitters problem, and distributiontesting. In this work we initiate the study of replicable reinforcementlearning, providing a provably replicable algorithm for parallel valueiteration, and a provably replicable version of R-max in the episodic setting.These are the first formal replicability results for control problems, whichpresent different challenges for replication than batch learning settings.</description><author>Eric Eaton, Marcel Hussing, Michael Kearns, Jessica Sorrell</author><pubDate>Tue, 31 Oct 2023 18:13:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.15284v4</guid></item><item><title>Performance Improvement in Multi-class Classification via Automated Hierarchy Generation and Exploitation through Extended LCPN Schemes</title><link>http://arxiv.org/abs/2310.20641v1</link><description>Hierarchical classification (HC) plays a pivotal role in multi-classclassification tasks, where objects are organized into a hierarchicalstructure. This study explores the performance of HC through a comprehensiveanalysis that encompasses both hierarchy generation and hierarchy exploitation.This analysis is particularly relevant in scenarios where a predefinedhierarchy structure is not readily accessible. Notably, two novel hierarchyexploitation schemes, LCPN+ and LCPN+F, which extend the capabilities of LCPNand combine the strengths of global and local classification, have beenintroduced and evaluated alongside existing methods. The findings reveal theconsistent superiority of LCPN+F, which outperforms other schemes acrossvarious datasets and scenarios. Moreover, this research emphasizes not onlyeffectiveness but also efficiency, as LCPN+ and LCPN+F maintain runtimeperformance comparable to Flat Classification (FC). Additionally, this studyunderscores the importance of selecting the right hierarchy exploitation schemeto maximize classification performance. This work extends our understanding ofHC and establishes a benchmark for future research, fostering advancements inmulti-class classification methodologies.</description><author>Celal Alagoz</author><pubDate>Tue, 31 Oct 2023 18:11:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20641v1</guid></item><item><title>Style-Aware Radiology Report Generation with RadGraph and Few-Shot Prompting</title><link>http://arxiv.org/abs/2310.17811v2</link><description>Automatically generated reports from medical images promise to improve theworkflow of radiologists. Existing methods consider an image-to-report modelingtask by directly generating a fully-fledged report from an image. However, thisconflates the content of the report (e.g., findings and their attributes) withits style (e.g., format and choice of words), which can lead to clinicallyinaccurate reports. To address this, we propose a two-step approach forradiology report generation. First, we extract the content from an image; then,we verbalize the extracted content into a report that matches the style of aspecific radiologist. For this, we leverage RadGraph -- a graph representationof reports -- together with large language models (LLMs). In our quantitativeevaluations, we find that our approach leads to beneficial performance. Ourhuman evaluation with clinical raters highlights that the AI-generated reportsare indistinguishably tailored to the style of individual radiologist despiteleveraging only a few examples as context.</description><author>Benjamin Yan, Ruochen Liu, David E. Kuo, Subathra Adithan, Eduardo Pontes Reis, Stephen Kwak, Vasantha Kumar Venugopal, Chloe P. O'Connell, Agustina Saenz, Pranav Rajpurkar, Michael Moor</author><pubDate>Tue, 31 Oct 2023 18:07:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.17811v2</guid></item><item><title>Applications of No-Collision Transportation Maps in Manifold Learning</title><link>http://arxiv.org/abs/2304.00199v3</link><description>In this work, we investigate applications of no-collision transportation mapsintroduced in [Nurbekyan et. al., 2020] in manifold learning for image data.Recently, there has been a surge in applying transportation-based distances andfeatures for data representing motion-like or deformation-like phenomena.Indeed, comparing intensities at fixed locations often does not reveal the datastructure. No-collision maps and distances developed in [Nurbekyan et. al.,2020] are sensitive to geometric features similar to optimal transportation(OT) maps but much cheaper to compute due to the absence of optimization. Inthis work, we prove that no-collision distances provide an isometry betweentranslations (respectively dilations) of a single probability measure and thetranslation (respectively dilation) vectors equipped with a Euclidean distance.Furthermore, we prove that no-collision transportation maps, as well as OT andlinearized OT maps, do not in general provide an isometry for rotations. Thenumerical experiments confirm our theoretical findings and show thatno-collision distances achieve similar or better performance on severalmanifold learning tasks compared to other OT and Euclidean-based methods at afraction of a computational cost.</description><author>Elisa Negrini, Levon Nurbekyan</author><pubDate>Tue, 31 Oct 2023 18:06:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.00199v3</guid></item><item><title>Histopathological Image Analysis with Style-Augmented Feature Domain Mixing for Improved Generalization</title><link>http://arxiv.org/abs/2310.20638v1</link><description>Histopathological images are essential for medical diagnosis and treatmentplanning, but interpreting them accurately using machine learning can bechallenging due to variations in tissue preparation, staining and imagingprotocols. Domain generalization aims to address such limitations by enablingthe learning models to generalize to new datasets or populations. Styletransfer-based data augmentation is an emerging technique that can be used toimprove the generalizability of machine learning models for histopathologicalimages. However, existing style transfer-based methods can be computationallyexpensive, and they rely on artistic styles, which can negatively impact modelaccuracy. In this study, we propose a feature domain style mixing techniquethat uses adaptive instance normalization to generate style-augmented versionsof images. We compare our proposed method with existing style transfer-baseddata augmentation methods and found that it performs similarly or better,despite requiring less computation and time. Our results demonstrate thepotential of feature domain statistics mixing in the generalization of learningmodels for histopathological image analysis.</description><author>Vaibhav Khamankar, Sutanu Bera, Saumik Bhattacharya, Debashis Sen, Prabir Kumar Biswas</author><pubDate>Tue, 31 Oct 2023 18:06:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20638v1</guid></item><item><title>Using Higher-Order Moments to Assess the Quality of GAN-generated Image Features</title><link>http://arxiv.org/abs/2310.20636v1</link><description>The rapid advancement of Generative Adversarial Networks (GANs) necessitatesthe need to robustly evaluate these models. Among the established evaluationcriteria, the Fr\'{e}chet Inception Distance (FID) has been widely adopted dueto its conceptual simplicity, fast computation time, and strong correlationwith human perception. However, FID has inherent limitations, mainly stemmingfrom its assumption that feature embeddings follow a Gaussian distribution, andtherefore can be defined by their first two moments. As this does not hold inpractice, in this paper we explore the importance of third-moments in imagefeature data and use this information to define a new measure, which we callthe Skew Inception Distance (SID). We prove that SID is a pseudometric onprobability distributions, show how it extends FID, and present a practicalmethod for its computation. Our numerical experiments support that SID eithertracks with FID or, in some cases, aligns more closely with human perceptionwhen evaluating image features of ImageNet data.</description><author>Lorenzo Luzi, Helen Jenne, Ryan Murray, Carlos Ortiz Marrero</author><pubDate>Tue, 31 Oct 2023 18:05:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20636v1</guid></item><item><title>Defining a New NLP Playground</title><link>http://arxiv.org/abs/2310.20633v1</link><description>The recent explosion of performance of large language models (LLMs) haschanged the field of Natural Language Processing (NLP) more abruptly andseismically than any other shift in the field's 80-year history. This hasresulted in concerns that the field will become homogenized andresource-intensive. The new status quo has put many academic researchers,especially PhD students, at a disadvantage. This paper aims to define a new NLPplayground by proposing 20+ PhD-dissertation-worthy research directions,covering theoretical analysis, new and challenging problems, learningparadigms, and interdisciplinary applications.</description><author>Sha Li, Chi Han, Pengfei Yu, Carl Edwards, Manling Li, Xingyao Wang, Yi R. Fung, Charles Yu, Joel R. Tetreault, Eduard H. Hovy, Heng Ji</author><pubDate>Tue, 31 Oct 2023 18:02:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20633v1</guid></item><item><title>Projecting basis functions with tensor networks for Gaussian process regression</title><link>http://arxiv.org/abs/2310.20630v1</link><description>This paper presents a method for approximate Gaussian process (GP) regressionwith tensor networks (TNs). A parametric approximation of a GP uses a linearcombination of basis functions, where the accuracy of the approximation dependson the total number of basis functions $M$. We develop an approach that allowsus to use an exponential amount of basis functions without the correspondingexponential computational complexity. The key idea to enable this is usinglow-rank TNs. We first find a suitable low-dimensional subspace from the data,described by a low-rank TN. In this low-dimensional subspace, we then infer theweights of our model by solving a Bayesian inference problem. Finally, weproject the resulting weights back to the original space to make GPpredictions. The benefit of our approach comes from the projection to a smallersubspace: It modifies the shape of the basis functions in a way that it seesfit based on the given data, and it allows for efficient computations in thesmaller subspace. In an experiment with an 18-dimensional benchmark data set,we show the applicability of our method to an inverse dynamics problem.</description><author>Clara Menzen, Eva Memmel, Kim Batselier, Manon Kok</author><pubDate>Tue, 31 Oct 2023 17:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20630v1</guid></item><item><title>LoRA Fine-tuning Efficiently Undoes Safety Training in Llama 2-Chat 70B</title><link>http://arxiv.org/abs/2310.20624v1</link><description>AI developers often apply safety alignment procedures to prevent the misuseof their AI systems. For example, before Meta released Llama 2-Chat, acollection of instruction fine-tuned large language models, they investedheavily in safety training, incorporating extensive red-teaming andreinforcement learning from human feedback. However, it remains unclear howwell safety training guards against model misuse when attackers have access tomodel weights. We explore the robustness of safety training in language modelsby subversively fine-tuning the public weights of Llama 2-Chat. We employlow-rank adaptation (LoRA) as an efficient fine-tuning method. With a budget ofless than $200 per model and using only one GPU, we successfully undo thesafety training of Llama 2-Chat models of sizes 7B, 13B, and 70B. Specifically,our fine-tuning technique significantly reduces the rate at which the modelrefuses to follow harmful instructions. We achieve a refusal rate below 1% forour 70B Llama 2-Chat model on two refusal benchmarks. Our fine-tuning methodretains general performance, which we validate by comparing our fine-tunedmodels against Llama 2-Chat across two benchmarks. Additionally, we present aselection of harmful outputs produced by our models. While there isconsiderable uncertainty about the scope of risks from current models, it islikely that future models will have significantly more dangerous capabilities,including the ability to hack into critical infrastructure, create dangerousbio-weapons, or autonomously replicate and adapt to new environments. We showthat subversive fine-tuning is practical and effective, and hence argue thatevaluating risks from fine-tuning should be a core part of risk assessments forreleasing model weights.</description><author>Simon Lermen, Charlie Rogers-Smith, Jeffrey Ladish</author><pubDate>Tue, 31 Oct 2023 17:55:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20624v1</guid></item><item><title>Pointwise uncertainty quantification for sparse variational Gaussian process regression with a Brownian motion prior</title><link>http://arxiv.org/abs/2310.00097v3</link><description>We study pointwise estimation and uncertainty quantification for a sparsevariational Gaussian process method with eigenvector inducing variables. For arescaled Brownian motion prior, we derive theoretical guarantees andlimitations for the frequentist size and coverage of pointwise credible sets.For sufficiently many inducing variables, we precisely characterize theasymptotic frequentist coverage, deducing when credible sets from thisvariational method are conservative and when overconfident/misleading. Wenumerically illustrate the applicability of our results and discuss connectionswith other common Gaussian process priors.</description><author>Luke Travis, Kolyan Ray</author><pubDate>Tue, 31 Oct 2023 17:54:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00097v3</guid></item><item><title>Deepfake detection by exploiting surface anomalies: the SurFake approach</title><link>http://arxiv.org/abs/2310.20621v1</link><description>The ever-increasing use of synthetically generated content in differentsectors of our everyday life, one for all media information, poses a strongneed for deepfake detection tools in order to avoid the proliferation ofaltered messages. The process to identify manipulated content, in particularimages and videos, is basically performed by looking for the presence of someinconsistencies and/or anomalies specifically due to the fake generationprocess. Different techniques exist in the scientific literature that exploitdiverse ad-hoc features in order to highlight possible modifications. In thispaper, we propose to investigate how deepfake creation can impact on thecharacteristics that the whole scene had at the time of the acquisition. Inparticular, when an image (video) is captured the overall geometry of the scene(e.g. surfaces) and the acquisition process (e.g. illumination) determine aunivocal environment that is directly represented by the image pixel values;all these intrinsic relations are possibly changed by the deepfake generationprocess. By resorting to the analysis of the characteristics of the surfacesdepicted in the image it is possible to obtain a descriptor usable to train aCNN for deepfake detection: we refer to such an approach as SurFake.Experimental results carried out on the FF++ dataset for different kinds ofdeepfake forgeries and diverse deep learning models confirm that such a featurecan be adopted to discriminate between pristine and altered images;furthermore, experiments witness that it can also be combined with visual datato provide a certain improvement in terms of detection accuracy.</description><author>Andrea Ciamarra, Roberto Caldelli, Federico Becattini, Lorenzo Seidenari, Alberto Del Bimbo</author><pubDate>Tue, 31 Oct 2023 17:54:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20621v1</guid></item><item><title>The Unreasonable Effectiveness of Random Target Embeddings for Continuous-Output Neural Machine Translation</title><link>http://arxiv.org/abs/2310.20620v1</link><description>Continuous-output neural machine translation (CoNMT) replaces the discretenext-word prediction problem with an embedding prediction. The semanticstructure of the target embedding space (i.e., closeness of related words) isintuitively believed to be crucial. We challenge this assumption and show thatcompletely random output embeddings can outperform laboriously pretrained ones,especially on larger datasets. Further investigation shows this surprisingeffect is strongest for rare words, due to the geometry of their embeddings. Weshed further light on this finding by designing a mixed strategy that combinesrandom and pre-trained embeddings for different tokens.</description><author>Evgeniia Tokarchuk, Vlad Niculae</author><pubDate>Tue, 31 Oct 2023 17:53:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20620v1</guid></item><item><title>Diffusion Reconstruction of Ultrasound Images with Informative Uncertainty</title><link>http://arxiv.org/abs/2310.20618v1</link><description>Despite its wide use in medicine, ultrasound imaging faces several challengesrelated to its poor signal-to-noise ratio and several sources of noise andartefacts. Enhancing ultrasound image quality involves balancing concurrentfactors like contrast, resolution, and speckle preservation. In recent years,there has been progress both in model-based and learning-based approaches toimprove ultrasound image reconstruction. Bringing the best from both worlds, wepropose a hybrid approach leveraging advances in diffusion models. To this end,we adapt Denoising Diffusion Restoration Models (DDRM) to incorporateultrasound physics through a linear direct model and an unsupervisedfine-tuning of the prior diffusion model. We conduct comprehensive experimentson simulated, in-vitro, and in-vivo data, demonstrating the efficacy of ourapproach in achieving high-quality image reconstructions from a single planewave input and in comparison to state-of-the-art methods. Finally, given thestochastic nature of the method, we analyse in depth the statistical propertiesof single and multiple-sample reconstructions, experimentally show theinformativeness of their variance, and provide an empirical model relating thisbehaviour to speckle noise. The code and data are available at: (uponacceptance).</description><author>Yuxin Zhang, Clément Huneau, Jérôme Idier, Diana Mateus</author><pubDate>Tue, 31 Oct 2023 17:51:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20618v1</guid></item><item><title>SE(3) Equivariant Augmented Coupling Flows</title><link>http://arxiv.org/abs/2308.10364v2</link><description>Coupling normalizing flows allow for fast sampling and density evaluation,making them the tool of choice for probabilistic modeling of physical systems.However, the standard coupling architecture precludes endowing flows thatoperate on the Cartesian coordinates of atoms with the SE(3) and permutationinvariances of physical systems. This work proposes a coupling flow thatpreserves SE(3) and permutation equivariance by performing coordinate splitsalong additional augmented dimensions. At each layer, the flow maps atoms'positions into learned SE(3) invariant bases, where we apply standard flowtransformations, such as monotonic rational-quadratic splines, before returningto the original basis. Crucially, our flow preserves fast sampling and densityevaluation, and may be used to produce unbiased estimates of expectations withrespect to the target distribution via importance sampling. When trained on theDW4, LJ13, and QM9-positional datasets, our flow is competitive withequivariant continuous normalizing flows, while allowing sampling more than anorder of magnitude faster. Moreover, to the best of our knowledge, we are thefirst to learn the full Boltzmann distribution of alanine dipeptide by onlymodeling the Cartesian positions of its atoms. Lastly, we demonstrate that ourflow can be trained to approximately sample from the Boltzmann distribution ofthe DW4 and LJ13 particle systems using only their energy functions.</description><author>Laurence I. Midgley, Vincent Stimper, Javier Antorán, Emile Mathieu, Bernhard Schölkopf, José Miguel Hernández-Lobato</author><pubDate>Tue, 31 Oct 2023 17:51:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.10364v2</guid></item><item><title>DAMNETS: A Deep Autoregressive Model for Generating Markovian Network Time Series</title><link>http://arxiv.org/abs/2203.15009v2</link><description>Generative models for network time series (also known as dynamic graphs) havetremendous potential in fields such as epidemiology, biology and economics,where complex graph-based dynamics are core objects of study. Designingflexible and scalable generative models is a very challenging task due to thehigh dimensionality of the data, as well as the need to represent temporaldependencies and marginal network structure. Here we introduce DAMNETS, ascalable deep generative model for network time series. DAMNETS outperformscompeting methods on all of our measures of sample quality, over both real andsynthetic data sets.</description><author>Jase Clarkson, Mihai Cucuringu, Andrew Elliott, Gesine Reinert</author><pubDate>Tue, 31 Oct 2023 17:50:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.15009v2</guid></item><item><title>Box2Mask: Weakly Supervised 3D Semantic Instance Segmentation Using Bounding Boxes</title><link>http://arxiv.org/abs/2206.01203v3</link><description>Current 3D segmentation methods heavily rely on large-scale point-clouddatasets, which are notoriously laborious to annotate. Few attempts have beenmade to circumvent the need for dense per-point annotations. In this work, welook at weakly-supervised 3D semantic instance segmentation. The key idea is toleverage 3D bounding box labels which are easier and faster to annotate.Indeed, we show that it is possible to train dense segmentation models usingonly bounding box labels. At the core of our method, \name{}, lies a deepmodel, inspired by classical Hough voting, that directly votes for bounding boxparameters, and a clustering method specifically tailored to bounding boxvotes. This goes beyond commonly used center votes, which would not fullyexploit the bounding box annotations. On ScanNet test, our weakly supervisedmodel attains leading performance among other weakly supervised approaches (+18mAP@50). Remarkably, it also achieves 97% of the mAP@50 score of current fullysupervised models. To further illustrate the practicality of our work, we trainBox2Mask on the recently released ARKitScenes dataset which is annotated with3D bounding boxes only, and show, for the first time, compelling 3D instancesegmentation masks.</description><author>Julian Chibane, Francis Engelmann, Tuan Anh Tran, Gerard Pons-Moll</author><pubDate>Tue, 31 Oct 2023 17:50:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.01203v3</guid></item><item><title>Graph Matching via convex relaxation to the simplex</title><link>http://arxiv.org/abs/2310.20609v1</link><description>This paper addresses the Graph Matching problem, which consists of findingthe best possible alignment between two input graphs, and has many applicationsin computer vision, network deanonymization and protein alignment. A commonapproach to tackle this problem is through convex relaxations of the NP-hard\emph{Quadratic Assignment Problem} (QAP). Here, we introduce a new convex relaxation onto the unit simplex and developan efficient mirror descent scheme with closed-form iterations for solving thisproblem. Under the correlated Gaussian Wigner model, we show that the simplexrelaxation admits a unique solution with high probability. In the noiselesscase, this is shown to imply exact recovery of the ground truth permutation.Additionally, we establish a novel sufficiency condition for the input matrixin standard greedy rounding methods, which is less restrictive than thecommonly used `diagonal dominance' condition. We use this condition to showexact one-step recovery of the ground truth (holding almost surely) via themirror descent scheme, in the noiseless setting. We also use this condition toobtain significantly improved conditions for the GRAMPA algorithm [Fan et al.2019] in the noiseless setting.</description><author>Ernesto Araya Valdivia, Hemant Tyagi</author><pubDate>Tue, 31 Oct 2023 17:44:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20609v1</guid></item><item><title>Autonomous Robotic Reinforcement Learning with Asynchronous Human Feedback</title><link>http://arxiv.org/abs/2310.20608v1</link><description>Ideally, we would place a robot in a real-world environment and leave itthere improving on its own by gathering more experience autonomously. However,algorithms for autonomous robotic learning have been challenging to realize inthe real world. While this has often been attributed to the challenge of samplecomplexity, even sample-efficient techniques are hampered by two majorchallenges - the difficulty of providing well "shaped" rewards, and thedifficulty of continual reset-free training. In this work, we describe a systemfor real-world reinforcement learning that enables agents to show continualimprovement by training directly in the real world without requiringpainstaking effort to hand-design reward functions or reset mechanisms. Oursystem leverages occasional non-expert human-in-the-loop feedback from remoteusers to learn informative distance functions to guide exploration whileleveraging a simple self-supervised learning algorithm for goal-directed policylearning. We show that in the absence of resets, it is particularly importantto account for the current "reachability" of the exploration policy whendeciding which regions of the space to explore. Based on this insight, weinstantiate a practical learning system - GEAR, which enables robots to simplybe placed in real-world environments and left to train autonomously withoutinterruption. The system streams robot experience to a web interface onlyrequiring occasional asynchronous feedback from remote, crowdsourced,non-expert humans in the form of binary comparative feedback. We evaluate thissystem on a suite of robotic tasks in simulation and demonstrate itseffectiveness at learning behaviors both in simulation and the real world.Project website https://guided-exploration-autonomous-rl.github.io/GEAR/.</description><author>Max Balsells, Marcel Torne, Zihan Wang, Samedh Desai, Pulkit Agrawal, Abhishek Gupta</author><pubDate>Tue, 31 Oct 2023 17:43:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20608v1</guid></item><item><title>What a Whole Slide Image Can Tell? Subtype-guided Masked Transformer for Pathological Image Captioning</title><link>http://arxiv.org/abs/2310.20607v1</link><description>Pathological captioning of Whole Slide Images (WSIs), though is essential incomputer-aided pathological diagnosis, has rarely been studied due to thelimitations in datasets and model training efficacy. In this paper, we proposea new paradigm Subtype-guided Masked Transformer (SGMT) for pathologicalcaptioning based on Transformers, which treats a WSI as a sequence of sparsepatches and generates an overall caption sentence from the sequence. Anaccompanying subtype prediction is introduced into SGMT to guide the trainingprocess and enhance the captioning accuracy. We also present an AsymmetricMasked Mechansim approach to tackle the large size constraint of pathologicalimage captioning, where the numbers of sequencing patches in SGMT are sampleddifferently in the training and inferring phases, respectively. Experiments onthe PatchGastricADC22 dataset demonstrate that our approach effectively adaptsto the task with a transformer-based model and achieves superior performancethan traditional RNN-based methods. Our codes are to be made available forfurther research and development.</description><author>Wenkang Qin, Rui Xu, Peixiang Huang, Xiaomin Wu, Heyu Zhang, Lin Luo</author><pubDate>Tue, 31 Oct 2023 17:43:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20607v1</guid></item><item><title>StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models</title><link>http://arxiv.org/abs/2310.13673v2</link><description>Large Language Models (LLMs) have been observed to encode and perpetuateharmful associations present in the training data. We propose a theoreticallygrounded framework called StereoMap to gain insights into their perceptions ofhow demographic groups have been viewed by society. The framework is groundedin the Stereotype Content Model (SCM); a well-established theory frompsychology. According to SCM, stereotypes are not all alike. Instead, thedimensions of Warmth and Competence serve as the factors that delineate thenature of stereotypes. Based on the SCM theory, StereoMap maps LLMs'perceptions of social groups (defined by socio-demographic features) using thedimensions of Warmth and Competence. Furthermore, the framework enables theinvestigation of keywords and verbalizations of reasoning of LLMs' judgments touncover underlying factors influencing their perceptions. Our results show thatLLMs exhibit a diverse range of perceptions towards these groups, characterizedby mixed evaluations along the dimensions of Warmth and Competence.Furthermore, analyzing the reasonings of LLMs, our findings indicate that LLMsdemonstrate an awareness of social disparities, often stating statistical dataand research findings to support their reasoning. This study contributes to theunderstanding of how LLMs perceive and represent social groups, shedding lighton their potential biases and the perpetuation of harmful associations.</description><author>Sullam Jeoung, Yubin Ge, Jana Diesner</author><pubDate>Tue, 31 Oct 2023 17:41:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13673v2</guid></item><item><title>SALSA PICANTE: a machine learning attack on LWE with binary secrets</title><link>http://arxiv.org/abs/2303.04178v4</link><description>Learning with Errors (LWE) is a hard math problem underpinning many proposedpost-quantum cryptographic (PQC) systems. The only PQC Key Exchange Mechanism(KEM) standardized by NIST is based on module~LWE, and current publiclyavailable PQ Homomorphic Encryption (HE) libraries are based on ring LWE. Thesecurity of LWE-based PQ cryptosystems is critical, but certain implementationchoices could weaken them. One such choice is sparse binary secrets, desirablefor PQ HE schemes for efficiency reasons. Prior work, SALSA, demonstrated amachine learning-based attack on LWE with sparse binary secrets in smalldimensions ($n \le 128$) and low Hamming weights ($h \le 4$). However, thisattack assumes access to millions of eavesdropped LWE samples and fails athigher Hamming weights or dimensions. We present PICANTE, an enhanced machine learning attack on LWE with sparsebinary secrets, which recovers secrets in much larger dimensions (up to$n=350$) and with larger Hamming weights (roughly $n/10$, and up to $h=60$ for$n=350$). We achieve this dramatic improvement via a novel preprocessing step,which allows us to generate training data from a linear number of eavesdroppedLWE samples ($4n$) and changes the distribution of the data to improvetransformer training. We also improve the secret recovery methods of SALSA andintroduce a novel cross-attention recovery mechanism allowing us to read offthe secret directly from the trained models. While PICANTE does not threatenNIST's proposed LWE standards, it demonstrates significant improvement overSALSA and could scale further, highlighting the need for future investigationinto machine learning attacks on LWE with sparse binary secrets.</description><author>Cathy Li, Jana Sotáková, Emily Wenger, Mohamed Malhou, Evrard Garcelon, Francois Charton, Kristin Lauter</author><pubDate>Tue, 31 Oct 2023 17:41:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.04178v4</guid></item><item><title>Teaching Language Models to Hallucinate Less with Synthetic Tasks</title><link>http://arxiv.org/abs/2310.06827v2</link><description>Large language models (LLMs) frequently hallucinate on abstractivesummarization tasks such as document-based question-answering, meetingsummarization, and clinical report generation, even though all necessaryinformation is included in context. However, optimizing LLMs to hallucinateless on these tasks is challenging, as hallucination is hard to efficientlyevaluate at each optimization step. In this work, we show that reducinghallucination on a synthetic task can also reduce hallucination on real-worlddownstream tasks. Our method, SynTra, first designs a synthetic task wherehallucinations are easy to elicit and measure. It next optimizes the LLM'ssystem message via prefix-tuning on the synthetic task, and finally transfersthe system message to realistic, hard-to-optimize tasks. Across three realisticabstractive summarization tasks, SynTra reduces hallucination for two13B-parameter LLMs using only a synthetic retrieval task for supervision. Wealso find that optimizing the system message rather than the model weights canbe critical; fine-tuning the entire model on the synthetic task cancounterintuitively increase hallucination. Overall, SynTra demonstrates thatthe extra flexibility of working with synthetic data can help mitigateundesired behaviors in practice.</description><author>Erik Jones, Hamid Palangi, Clarisse Simões, Varun Chandrasekaran, Subhabrata Mukherjee, Arindam Mitra, Ahmed Awadallah, Ece Kamar</author><pubDate>Tue, 31 Oct 2023 17:41:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06827v2</guid></item><item><title>Enhanced Synthetic MRI Generation from CT Scans Using CycleGAN with Feature Extraction</title><link>http://arxiv.org/abs/2310.20604v1</link><description>In the field of radiotherapy, accurate imaging and image registration are ofutmost importance for precise treatment planning. Magnetic Resonance Imaging(MRI) offers detailed imaging without being invasive and excels in soft-tissuecontrast, making it a preferred modality for radiotherapy planning. However,the high cost of MRI, longer acquisition time, and certain healthconsiderations for patients pose challenges. Conversely, Computed Tomography(CT) scans offer a quicker and less expensive imaging solution. To bridge thesemodalities and address multimodal alignment challenges, we introduce anapproach for enhanced monomodal registration using synthetic MRI images.Utilizing unpaired data, this paper proposes a novel method to produce thesesynthetic MRI images from CT scans, leveraging CycleGANs and featureextractors. By building upon the foundational work on Cycle-ConsistentAdversarial Networks and incorporating advancements from related literature,our methodology shows promising results, outperforming several state-of-the-artmethods. The efficacy of our approach is validated by multiple comparisonmetrics.</description><author>Saba Nikbakhsh, Lachin Naghashyar, Morteza Valizadeh, Mehdi Chehel Amirani</author><pubDate>Tue, 31 Oct 2023 17:39:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20604v1</guid></item><item><title>Synthetic Interventions</title><link>http://arxiv.org/abs/2006.07691v6</link><description>Consider a setting with $N$ heterogeneous units (e.g., individuals,sub-populations) and $D$ interventions (e.g., socio-economic policies). Ourgoal is to learn the expected potential outcome associated with everyintervention on every unit, totaling $N \times D$ causal parameters. Towardsthis, we present a causal framework, synthetic interventions (SI), to inferthese $N \times D$ causal parameters while only observing each of the $N$ unitsunder at most two interventions, independent of $D$. This can be significant asthe number of interventions, i.e., level of personalization, grows. Under anovel tensor factor model across units, outcomes, and interventions, we provean identification result for each of these $N \times D$ causal parameters,establish finite-sample consistency of our estimator along with asymptoticnormality under additional conditions. Importantly, our estimator also allowsfor latent confounders that determine how interventions are assigned. Theestimator is further furnished with data-driven tests to examine itssuitability. Empirically, we validate our framework through a large-scale A/Btest performed on an e-commerce platform. We believe our results could haveimplications for the design of data-efficient randomized experiments (e.g.,randomized control trials) with heterogeneous units and multiple interventions.</description><author>Anish Agarwal, Devavrat Shah, Dennis Shen</author><pubDate>Tue, 31 Oct 2023 17:39:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2006.07691v6</guid></item><item><title>CHORE: Contact, Human and Object REconstruction from a single RGB image</title><link>http://arxiv.org/abs/2204.02445v3</link><description>Most prior works in perceiving 3D humans from images reason human inisolation without their surroundings. However, humans are constantlyinteracting with the surrounding objects, thus calling for models that canreason about not only the human but also the object and their interaction. Theproblem is extremely challenging due to heavy occlusions between humans andobjects, diverse interaction types and depth ambiguity. In this paper, weintroduce CHORE, a novel method that learns to jointly reconstruct the humanand the object from a single RGB image. CHORE takes inspiration from recentadvances in implicit surface learning and classical model-based fitting. Wecompute a neural reconstruction of human and object represented implicitly withtwo unsigned distance fields, a correspondence field to a parametric body andan object pose field. This allows us to robustly fit a parametric body modeland a 3D object template, while reasoning about interactions. Furthermore,prior pixel-aligned implicit learning methods use synthetic data and makeassumptions that are not met in the real data. We propose a elegant depth-awarescaling that allows more efficient shape learning on real data. Experimentsshow that our joint reconstruction learned with the proposed strategysignificantly outperforms the SOTA. Our code and models are available athttps://virtualhumans.mpi-inf.mpg.de/chore</description><author>Xianghui Xie, Bharat Lal Bhatnagar, Gerard Pons-Moll</author><pubDate>Tue, 31 Oct 2023 17:39:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.02445v3</guid></item><item><title>Functional connectivity modules in recurrent neural networks: function, origin and dynamics</title><link>http://arxiv.org/abs/2310.20601v1</link><description>Understanding the ubiquitous phenomenon of neural synchronization acrossspecies and organizational levels is crucial for decoding brain function.Despite its prevalence, the specific functional role, origin, and dynamicalimplication of modular structures in correlation-based networks remainsambiguous. Using recurrent neural networks trained on systems neurosciencetasks, this study investigates these important characteristics of modularity incorrelation networks. We demonstrate that modules are functionally coherentunits that contribute to specialized information processing. We show thatmodules form spontaneously from asymmetries in the sign and weight ofprojections from the input layer to the recurrent layer. Moreover, we show thatmodules define connections with similar roles in governing system behavior anddynamics. Collectively, our findings clarify the function, formation, andoperational significance of functional connectivity modules, offering insightsinto cortical function and laying the groundwork for further studies on brainfunction, development, and dynamics.</description><author>Jacob Tanner, Sina Mansour L., Ludovico Coletta, Alessandro Gozzi, Richard F. Betzel</author><pubDate>Tue, 31 Oct 2023 17:37:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20601v1</guid></item><item><title>Brain-like Flexible Visual Inference by Harnessing Feedback-Feedforward Alignment</title><link>http://arxiv.org/abs/2310.20599v1</link><description>In natural vision, feedback connections support versatile visual inferencecapabilities such as making sense of the occluded or noisy bottom-up sensoryinformation or mediating pure top-down processes such as imagination. However,the mechanisms by which the feedback pathway learns to give rise to thesecapabilities flexibly are not clear. We propose that top-down effects emergethrough alignment between feedforward and feedback pathways, each optimizingits own objectives. To achieve this co-optimization, we introduceFeedback-Feedforward Alignment (FFA), a learning algorithm that leveragesfeedback and feedforward pathways as mutual credit assignment computationalgraphs, enabling alignment. In our study, we demonstrate the effectiveness ofFFA in co-optimizing classification and reconstruction tasks on widely usedMNIST and CIFAR10 datasets. Notably, the alignment mechanism in FFA endowsfeedback connections with emergent visual inference functions, includingdenoising, resolving occlusions, hallucination, and imagination. Moreover, FFAoffers bio-plausibility compared to traditional backpropagation (BP) methods inimplementation. By repurposing the computational graph of credit assignmentinto a goal-driven feedback pathway, FFA alleviates weight transport problemsencountered in BP, enhancing the bio-plausibility of the learning algorithm.Our study presents FFA as a promising proof-of-concept for the mechanismsunderlying how feedback connections in the visual cortex support flexiblevisual functions. This work also contributes to the broader field of visualinference underlying perceptual phenomena and has implications for developingmore biologically inspired learning algorithms.</description><author>Tahereh Toosi, Elias B. Issa</author><pubDate>Tue, 31 Oct 2023 17:35:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20599v1</guid></item><item><title>Faith and Fate: Limits of Transformers on Compositionality</title><link>http://arxiv.org/abs/2305.18654v3</link><description>Transformer large language models (LLMs) have sparked admiration for theirexceptional performance on tasks that demand intricate multi-step reasoning.Yet, these models simultaneously show failures on surprisingly trivialproblems. This begs the question: Are these errors incidental, or do theysignal more substantial limitations? In an attempt to demystify transformerLLMs, we investigate the limits of these models across three representativecompositional tasks -- multi-digit multiplication, logic grid puzzles, and aclassic dynamic programming problem. These tasks require breaking problems downinto sub-steps and synthesizing these steps into a precise answer. We formulatecompositional tasks as computation graphs to systematically quantify the levelof complexity, and break down reasoning steps into intermediate sub-procedures.Our empirical findings suggest that transformer LLMs solve compositional tasksby reducing multi-step compositional reasoning into linearized subgraphmatching, without necessarily developing systematic problem-solving skills. Toround off our empirical study, we provide theoretical arguments on abstractmulti-step reasoning problems that highlight how autoregressive generations'performance can rapidly decay with\,increased\,task\,complexity.</description><author>Nouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine Li, Liwei Jiang, Bill Yuchen Lin, Peter West, Chandra Bhagavatula, Ronan Le Bras, Jena D. Hwang, Soumya Sanyal, Sean Welleck, Xiang Ren, Allyson Ettinger, Zaid Harchaoui, Yejin Choi</author><pubDate>Tue, 31 Oct 2023 17:35:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18654v3</guid></item><item><title>Online Conversion with Switching Costs: Robust and Learning-Augmented Algorithms</title><link>http://arxiv.org/abs/2310.20598v1</link><description>We introduce and study online conversion with switching costs, a family ofonline problems that capture emerging problems at the intersection of energyand sustainability. In this problem, an online player attempts to purchase(alternatively, sell) fractional shares of an asset during a fixed time horizonwith length $T$. At each time step, a cost function (alternatively, pricefunction) is revealed, and the player must irrevocably decide an amount ofasset to convert. The player also incurs a switching cost whenever theirdecision changes in consecutive time steps, i.e., when they increase ordecrease their purchasing amount. We introduce competitive (robust)threshold-based algorithms for both the minimization and maximization variantsof this problem, and show they are optimal among deterministic onlinealgorithms. We then propose learning-augmented algorithms that take advantageof untrusted black-box advice (such as predictions from a machine learningmodel) to achieve significantly better average-case performance withoutsacrificing worst-case competitive guarantees. Finally, we empirically evaluateour proposed algorithms using a carbon-aware EV charging case study, showingthat our algorithms substantially improve on baseline methods for this problem.</description><author>Adam Lechowicz, Nicolas Christianson, Bo Sun, Noman Bashir, Mohammad Hajiesmaili, Adam Wierman, Prashant Shenoy</author><pubDate>Tue, 31 Oct 2023 17:34:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20598v1</guid></item><item><title>Learning Zero-Sum Linear Quadratic Games with Improved Sample Complexity and Last-Iterate Convergence</title><link>http://arxiv.org/abs/2309.04272v3</link><description>Zero-sum Linear Quadratic (LQ) games are fundamental in optimal control andcan be used (i)~as a dynamic game formulation for risk-sensitive or robustcontrol and (ii)~as a benchmark setting for multi-agent reinforcement learningwith two competing agents in continuous state-control spaces. In contrast tothe well-studied single-agent linear quadratic regulator problem, zero-sum LQgames entail solving a challenging nonconvex-nonconcave min-max problem with anobjective function that lacks coercivity. Recently, Zhang et al. showed thatan~$\epsilon$-Nash equilibrium (NE) of finite horizon zero-sum LQ games can belearned via nested model-free Natural Policy Gradient (NPG) algorithms withpoly$(1/\epsilon)$ sample complexity. In this work, we propose a simpler nestedZeroth-Order (ZO) algorithm improving sample complexity by several orders ofmagnitude and guaranteeing convergence of the last iterate. Our main resultsare two-fold: (i) in the deterministic setting, we establish the first globallast-iterate linear convergence result for the nested algorithm that seeks NEof zero-sum LQ games; (ii) in the model-free setting, we establisha~$\widetilde{\mathcal{O}}(\epsilon^{-2})$ sample complexity using asingle-point ZO estimator. For our last-iterate convergence results, ouranalysis leverages the Implicit Regularization (IR) property and a new gradientdomination condition for the primal function. Our key improvements in thesample complexity rely on a more sample-efficient nested algorithm design and afiner control of the ZO natural gradient estimation error utilizing thestructure endowed by the finite-horizon setting.</description><author>Jiduan Wu, Anas Barakat, Ilyas Fatkhullin, Niao He</author><pubDate>Tue, 31 Oct 2023 17:34:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.04272v3</guid></item><item><title>Helmholtzian Eigenmap: Topological feature discovery &amp; edge flow learning from point cloud data</title><link>http://arxiv.org/abs/2103.07626v3</link><description>The manifold Helmholtzian (1-Laplacian) operator $\Delta_1$ elegantlygeneralizes the Laplace-Beltrami operator to vector fields on a manifold$\mathcal M$. In this work, we propose the estimation of the manifoldHelmholtzian from point cloud data by a weighted 1-Laplacian $\mathcal L_1$.While higher order Laplacians have been introduced and studied, this work isthe first to present a graph Helmholtzian constructed from a simplicial complexas a consistent estimator for the continuous operator in a non-parametricsetting. Equipped with the geometric and topological information about$\mathcal M$, the Helmholtzian is a useful tool for the analysis of flows andvector fields on $\mathcal M$ via the Helmholtz-Hodge theorem. In addition, the$\mathcal L_1$ allows the smoothing, prediction, and feature extraction of theflows. We demonstrate these possibilities on substantial sets of synthetic andreal point cloud datasets with non-trivial topological structures; and providetheoretical results on the limit of $\mathcal L_1$ to $\Delta_1$.</description><author>Yu-Chia Chen, Weicheng Wu, Marina Meilă, Ioannis G. Kevrekidis</author><pubDate>Tue, 31 Oct 2023 17:32:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2103.07626v3</guid></item><item><title>Learning List-Level Domain-Invariant Representations for Ranking</title><link>http://arxiv.org/abs/2212.10764v3</link><description>Domain adaptation aims to transfer the knowledge learned on (data-rich)source domains to (low-resource) target domains, and a popular method isinvariant representation learning, which matches and aligns the datadistributions on the feature space. Although this method is studied extensivelyand applied on classification and regression problems, its adoption on rankingproblems is sporadic, and the few existing implementations lack theoreticaljustifications. This paper revisits invariant representation learning forranking. Upon reviewing prior work, we found that they implement what we callitem-level alignment, which aligns the distributions of the items being rankedfrom all lists in aggregate but ignores their list structure. However, the liststructure should be leveraged, because it is intrinsic to ranking problemswhere the data and the metrics are defined and computed on lists, not the itemsby themselves. To close this discrepancy, we propose list-level alignment --learning domain-invariant representations at the higher level of lists. Thebenefits are twofold: it leads to the first domain adaptation generalizationbound for ranking, in turn providing theoretical support for the proposedmethod, and it achieves better empirical transfer performance for unsuperviseddomain adaptation on ranking tasks, including passage reranking.</description><author>Ruicheng Xian, Honglei Zhuang, Zhen Qin, Hamed Zamani, Jing Lu, Ji Ma, Kai Hui, Han Zhao, Xuanhui Wang, Michael Bendersky</author><pubDate>Tue, 31 Oct 2023 17:30:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.10764v3</guid></item><item><title>FLODCAST: Flow and Depth Forecasting via Multimodal Recurrent Architectures</title><link>http://arxiv.org/abs/2310.20593v1</link><description>Forecasting motion and spatial positions of objects is of fundamentalimportance, especially in safety-critical settings such as autonomous driving.In this work, we address the issue by forecasting two different modalities thatcarry complementary information, namely optical flow and depth. To this end wepropose FLODCAST a flow and depth forecasting model that leverages a multitaskrecurrent architecture, trained to jointly forecast both modalities at once. Westress the importance of training using flows and depth maps together,demonstrating that both tasks improve when the model is informed of the othermodality. We train the proposed model to also perform predictions for severaltimesteps in the future. This provides better supervision and leads to moreprecise predictions, retaining the capability of the model to yield outputsautoregressively for any future time horizon. We test our model on thechallenging Cityscapes dataset, obtaining state of the art results for bothflow and depth forecasting. Thanks to the high quality of the generated flows,we also report benefits on the downstream task of segmentation forecasting,injecting our predictions in a flow-based mask-warping framework.</description><author>Andrea Ciamarra, Federico Becattini, Lorenzo Seidenari, Alberto Del Bimbo</author><pubDate>Tue, 31 Oct 2023 17:30:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20593v1</guid></item><item><title>Visibility Aware Human-Object Interaction Tracking from Single RGB Camera</title><link>http://arxiv.org/abs/2303.16479v2</link><description>Capturing the interactions between humans and their environment in 3D isimportant for many applications in robotics, graphics, and vision. Recent worksto reconstruct the 3D human and object from a single RGB image do not haveconsistent relative translation across frames because they assume a fixeddepth. Moreover, their performance drops significantly when the object isoccluded. In this work, we propose a novel method to track the 3D human,object, contacts between them, and their relative translation across framesfrom a single RGB camera, while being robust to heavy occlusions. Our method isbuilt on two key insights. First, we condition our neural field reconstructionsfor human and object on per-frame SMPL model estimates obtained by pre-fittingSMPL to a video sequence. This improves neural reconstruction accuracy andproduces coherent relative translation across frames. Second, human and objectmotion from visible frames provides valuable information to infer the occludedobject. We propose a novel transformer-based neural network that explicitlyuses object visibility and human motion to leverage neighbouring frames to makepredictions for the occluded frames. Building on these insights, our method isable to track both human and object robustly even under occlusions. Experimentson two datasets show that our method significantly improves over thestate-of-the-art methods. Our code and pretrained models are available at:https://virtualhumans.mpi-inf.mpg.de/VisTracker</description><author>Xianghui Xie, Bharat Lal Bhatnagar, Gerard Pons-Moll</author><pubDate>Tue, 31 Oct 2023 17:27:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.16479v2</guid></item><item><title>Bayes optimal learning in high-dimensional linear regression with network side information</title><link>http://arxiv.org/abs/2306.05679v3</link><description>Supervised learning problems with side information in the form of a networkarise frequently in applications in genomics, proteomics and neuroscience. Forexample, in genetic applications, the network side information can accuratelycapture background biological information on the intricate relations among therelevant genes. In this paper, we initiate a study of Bayes optimal learning inhigh-dimensional linear regression with network side information. To this end,we first introduce a simple generative model (called the Reg-Graph model) whichposits a joint distribution for the supervised data and the observed networkthrough a common set of latent parameters. Next, we introduce an iterativealgorithm based on Approximate Message Passing (AMP) which is provably Bayesoptimal under very general conditions. In addition, we characterize thelimiting mutual information between the latent signal and the data observed,and thus precisely quantify the statistical impact of the network sideinformation. Finally, supporting numerical experiments suggest that theintroduced algorithm has excellent performance in finite samples.</description><author>Sagnik Nandy, Subhabrata Sen</author><pubDate>Tue, 31 Oct 2023 17:26:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.05679v3</guid></item><item><title>Increasing The Performance of Cognitively Inspired Data-Efficient Language Models via Implicit Structure Building</title><link>http://arxiv.org/abs/2310.20589v1</link><description>In this paper, we describe our submission to the BabyLM Challenge 2023 sharedtask on data-efficient language model (LM) pretraining (Warstadt et al., 2023).We train transformer-based masked language models that incorporate unsupervisedpredictions about hierarchical sentence structure into the model architecture.Concretely, we use the Structformer architecture (Shen et al., 2021) andvariants thereof. StructFormer models have been shown to perform well onunsupervised syntactic induction based on limited pretraining data, and toyield performance improvements over a vanilla transformer architecture (Shen etal., 2021). Evaluation of our models on 39 tasks provided by the BabyLMchallenge shows promising improvements of models that integrate a hierarchicalbias into the architecture at some particular tasks, even though they fail toconsistently outperform the RoBERTa baseline model provided by the shared taskorganizers on all tasks.</description><author>Omar Momen, David Arps, Laura Kallmeyer</author><pubDate>Tue, 31 Oct 2023 17:26:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20589v1</guid></item><item><title>Zero-Shot Medical Information Retrieval via Knowledge Graph Embedding</title><link>http://arxiv.org/abs/2310.20588v1</link><description>In the era of the Internet of Things (IoT), the retrieval of relevant medicalinformation has become essential for efficient clinical decision-making. Thispaper introduces MedFusionRank, a novel approach to zero-shot medicalinformation retrieval (MIR) that combines the strengths of pre-trained languagemodels and statistical methods while addressing their limitations. The proposedapproach leverages a pre-trained BERT-style model to extract compact yetinformative keywords. These keywords are then enriched with domain knowledge bylinking them to conceptual entities within a medical knowledge graph.Experimental evaluations on medical datasets demonstrate MedFusion Rank'ssuperior performance over existing methods, with promising results with avariety of evaluation metrics. MedFusionRank demonstrates efficacy inretrieving relevant information, even from short or single-term queries.</description><author>Yuqi Wang, Zeqiang Wang, Wei Wang, Qi Chen, Kaizhu Huang, Anh Nguyen, Suparna De</author><pubDate>Tue, 31 Oct 2023 17:26:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20588v1</guid></item><item><title>Canonical normalizing flows for manifold learning</title><link>http://arxiv.org/abs/2310.12743v2</link><description>Manifold learning flows are a class of generative modelling techniques thatassume a low-dimensional manifold description of the data. The embedding ofsuch a manifold into the high-dimensional space of the data is achieved vialearnable invertible transformations. Therefore, once the manifold is properlyaligned via a reconstruction loss, the probability density is tractable on themanifold and maximum likelihood can be used to optimize the network parameters.Naturally, the lower-dimensional representation of the data requires aninjective-mapping. Recent approaches were able to enforce that the densityaligns with the modelled manifold, while efficiently calculating the densityvolume-change term when embedding to the higher-dimensional space. However,unless the injective-mapping is analytically predefined, the learned manifoldis not necessarily an efficient representation of the data. Namely, the latentdimensions of such models frequently learn an entangled intrinsic basis, withdegenerate information being stored in each dimension. Alternatively, if alocally orthogonal and/or sparse basis is to be learned, here coined canonicalintrinsic basis, it can serve in learning a more compact latent spacerepresentation. Toward this end, we propose a canonical manifold learning flowmethod, where a novel optimization objective enforces the transformation matrixto have few prominent and non-degenerate basis functions. We demonstrate thatby minimizing the off-diagonal manifold metric elements $\ell_1$-norm, we canachieve such a basis, which is simultaneously sparse and/or orthogonal.Canonical manifold flow yields a more efficient use of the latent space,automatically generating fewer prominent and distinct dimensions to representdata, and a better approximation of target distributions than other manifoldflow methods in most experiments we conducted, resulting in lower FID scores.</description><author>Kyriakos Flouris, Ender Konukoglu</author><pubDate>Tue, 31 Oct 2023 17:24:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12743v2</guid></item><item><title>Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning</title><link>http://arxiv.org/abs/2310.20587v1</link><description>Offline reinforcement learning (RL) aims to find a near-optimal policy usingpre-collected datasets. In real-world scenarios, data collection could becostly and risky; therefore, offline RL becomes particularly challenging whenthe in-domain data is limited. Given recent advances in Large Language Models(LLMs) and their few-shot learning prowess, this paper introduces$\textbf{La}$nguage Models for $\textbf{Mo}$tion Control ($\textbf{LaMo}$), ageneral framework based on Decision Transformers to effectively use pre-trainedLanguage Models (LMs) for offline RL. Our framework highlights four crucialcomponents: (1) Initializing Decision Transformers with sequentiallypre-trained LMs, (2) employing the LoRA fine-tuning method, in contrast tofull-weight fine-tuning, to combine the pre-trained knowledge from LMs andin-domain knowledge effectively, (3) using the non-linear MLP transformationinstead of linear projections, to generate embeddings, and (4) integrating anauxiliary language prediction loss during fine-tuning to stabilize the LMs andretain their original abilities on languages. Empirical results indicate$\textbf{LaMo}$ achieves state-of-the-art performance in sparse-reward tasksand closes the gap between value-based offline RL methods and decisiontransformers in dense-reward tasks. In particular, our method demonstratessuperior performance in scenarios with limited data samples. Our projectwebsite is https://lamo2023.github.io</description><author>Ruizhe Shi, Yuyao Liu, Yanjie Ze, Simon S. Du, Huazhe Xu</author><pubDate>Tue, 31 Oct 2023 17:24:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20587v1</guid></item><item><title>DataDAM: Efficient Dataset Distillation with Attention Matching</title><link>http://arxiv.org/abs/2310.00093v2</link><description>Researchers have long tried to minimize training costs in deep learning whilemaintaining strong generalization across diverse datasets. Emerging research ondataset distillation aims to reduce training costs by creating a smallsynthetic set that contains the information of a larger real dataset andultimately achieves test accuracy equivalent to a model trained on the wholedataset. Unfortunately, the synthetic data generated by previous methods arenot guaranteed to distribute and discriminate as well as the original trainingdata, and they incur significant computational costs. Despite promisingresults, there still exists a significant performance gap between modelstrained on condensed synthetic sets and those trained on the whole dataset. Inthis paper, we address these challenges using efficient Dataset Distillationwith Attention Matching (DataDAM), achieving state-of-the-art performance whilereducing training costs. Specifically, we learn synthetic images by matchingthe spatial attention maps of real and synthetic data generated by differentlayers within a family of randomly initialized neural networks. Our methodoutperforms the prior methods on several datasets, including CIFAR10/100,TinyImageNet, ImageNet-1K, and subsets of ImageNet-1K across most of thesettings, and achieves improvements of up to 6.5% and 4.1% on CIFAR100 andImageNet-1K, respectively. We also show that our high-quality distilled imageshave practical benefits for downstream applications, such as continual learningand neural architecture search.</description><author>Ahmad Sajedi, Samir Khaki, Ehsan Amjadian, Lucy Z. Liu, Yuri A. Lawryshyn, Konstantinos N. Plataniotis</author><pubDate>Tue, 31 Oct 2023 17:23:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00093v2</guid></item><item><title>Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning</title><link>http://arxiv.org/abs/2305.13971v4</link><description>Despite their impressive performance, large language models (LMs) stillstruggle with reliably generating complex output structures when not finetunedto follow the required output format exactly. To address this issue,grammar-constrained decoding (GCD) can be used to control the generation ofLMs, guaranteeing that the output follows a given structure. Most existing GCDmethods are, however, limited to specific tasks, such as parsing or codegeneration. In this work, we demonstrate that formal grammars can describe theoutput space for a much wider range of tasks and argue that GCD can serve as aunified framework for structured NLP tasks in general. For increasedflexibility, we introduce input-dependent grammars, which allow the grammar todepend on the input and thus enable the generation of different outputstructures for different inputs. We then empirically demonstrate the power andflexibility of GCD-enhanced LMs on (1) information extraction, (2) entitydisambiguation, and (3) constituency parsing. Our results indicate thatgrammar-constrained LMs substantially outperform unconstrained LMs or even beattask-specific finetuned models. Grammar constraints thus hold great promise forharnessing off-the-shelf LMs for a wide range of structured NLP tasks,especially where training data is scarce or finetuning is expensive. Code anddata: https://github.com/epfl-dlab/GCD.</description><author>Saibo Geng, Martin Josifoski, Maxime Peyrard, Robert West</author><pubDate>Tue, 31 Oct 2023 17:21:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13971v4</guid></item><item><title>Stochastic Gradient Descent for Gaussian Processes Done Right</title><link>http://arxiv.org/abs/2310.20581v1</link><description>We study the optimisation problem associated with Gaussian process regressionusing squared loss. The most common approach to this problem is to apply anexact solver, such as conjugate gradient descent, either directly, or to areduced-order version of the problem. Recently, driven by successes in deeplearning, stochastic gradient descent has gained traction as an alternative. Inthis paper, we show that when done right$\unicode{x2014}$by which we mean usingspecific insights from the optimisation and kernelcommunities$\unicode{x2014}$this approach is highly effective. We thusintroduce a particular stochastic dual gradient descent algorithm, that may beimplemented with a few lines of code using any deep learning framework. Weexplain our design decisions by illustrating their advantage againstalternatives with ablation studies and show that the new method is highlycompetitive. Our evaluations on standard regression benchmarks and a Bayesianoptimisation task set our approach apart from preconditioned conjugategradients, variational Gaussian process approximations, and a previous versionof stochastic gradient descent for Gaussian processes. On a molecular bindingaffinity prediction task, our method places Gaussian process regression on parin terms of performance with state-of-the-art graph neural networks.</description><author>Jihao Andreas Lin, Shreyas Padhy, Javier Antorán, Austin Tripp, Alexander Terenin, Csaba Szepesvári, José Miguel Hernández-Lobato, David Janz</author><pubDate>Tue, 31 Oct 2023 17:15:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20581v1</guid></item><item><title>How is ChatGPT's behavior changing over time?</title><link>http://arxiv.org/abs/2307.09009v3</link><description>GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)services. However, when and how these models are updated over time is opaque.Here, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 onseveral diverse tasks: 1) math problems, 2) sensitive/dangerous questions, 3)opinion surveys, 4) multi-hop knowledge-intensive questions, 5) generatingcode, 6) US Medical License tests, and 7) visual reasoning. We find that theperformance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.For example, GPT-4 (March 2023) was reasonable at identifying prime vs.composite numbers (84% accuracy) but GPT-4 (June 2023) was poor on these samequestions (51% accuracy). This is partly explained by a drop in GPT-4's amenityto follow chain-of-thought prompting. Interestingly, GPT-3.5 was much better inJune than in March in this task. GPT-4 became less willing to answer sensitivequestions and opinion survey questions in June than in March. GPT-4 performedbetter at multi-hop questions in June than in March, while GPT-3.5'sperformance dropped on this task. Both GPT-4 and GPT-3.5 had more formattingmistakes in code generation in June than in March. We provide evidence thatGPT-4's ability to follow user instructions has decreased over time, which isone common factor behind the many behavior drifts. Overall, our findings showthat the behavior of the "same" LLM service can change substantially in arelatively short amount of time, highlighting the need for continuousmonitoring of LLMs.</description><author>Lingjiao Chen, Matei Zaharia, James Zou</author><pubDate>Tue, 31 Oct 2023 17:13:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09009v3</guid></item><item><title>Initialization Matters: Privacy-Utility Analysis of Overparameterized Neural Networks</title><link>http://arxiv.org/abs/2310.20579v1</link><description>We analytically investigate how over-parameterization of models in randomizedmachine learning algorithms impacts the information leakage about theirtraining data. Specifically, we prove a privacy bound for the KL divergencebetween model distributions on worst-case neighboring datasets, and explore itsdependence on the initialization, width, and depth of fully connected neuralnetworks. We find that this KL privacy bound is largely determined by theexpected squared gradient norm relative to model parameters during training.Notably, for the special setting of linearized network, our analysis indicatesthat the squared gradient norm (and therefore the escalation of privacy loss)is tied directly to the per-layer variance of the initialization distribution.By using this analysis, we demonstrate that privacy bound improves withincreasing depth under certain initializations (LeCun and Xavier), whiledegrades with increasing depth under other initializations (He and NTK). Ourwork reveals a complex interplay between privacy and depth that depends on thechosen initialization distribution. We further prove excess empirical riskbounds under a fixed KL privacy budget, and show that the interplay betweenprivacy utility trade-off and depth is similarly affected by theinitialization.</description><author>Jiayuan Ye, Zhenyu Zhu, Fanghui Liu, Reza Shokri, Volkan Cevher</author><pubDate>Tue, 31 Oct 2023 17:13:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20579v1</guid></item><item><title>A Multimodal Sensing Ring for Quantification of Scratch Intensity</title><link>http://arxiv.org/abs/2302.03813v2</link><description>An objective measurement of chronic itch is necessary for improvements inpatient care for numerous medical conditions. While wearables have shownpromise for scratch detection, they are currently unable to estimate scratchintensity, preventing a comprehensive understanding of the effect of itch on anindividual. In this work, we present a framework for the estimation of scratchintensity in addition to the detection of scratch. This is accomplished with amultimodal ring device, consisting of an accelerometer and a contactmicrophone, a pressure-sensitive tablet for capturing ground truth intensityvalues, and machine learning algorithms for regression of scratch intensity ona 0-600 milliwatts (mW) power scale that can be mapped to a 0-10 continuousscale. We evaluate the performance of our algorithms on 20 individuals usingleave one subject out cross-validation and using data from 14 additionalparticipants, we show that our algorithms achieve clinically-relevantdiscrimination of scratching intensity levels. By doing so, our device enablesthe quantification of the substantial variations in the interpretation of the0-10 scale frequently utilized in patient self-reported clinical assessments.This work demonstrates that a finger-worn device can provide multidimensional,objective, real-time measures for the action of scratching.</description><author>Akhil Padmanabha, Sonal Choudhary, Carmel Majidi, Zackory Erickson</author><pubDate>Tue, 31 Oct 2023 16:20:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.03813v2</guid></item><item><title>Directed Cyclic Graph for Causal Discovery from Multivariate Functional Data</title><link>http://arxiv.org/abs/2310.20537v1</link><description>Discovering causal relationship using multivariate functional data hasreceived a significant amount of attention very recently. In this article, weintroduce a functional linear structural equation model for causal structurelearning when the underlying graph involving the multivariate functions mayhave cycles. To enhance interpretability, our model involves a low-dimensionalcausal embedded space such that all the relevant causal information in themultivariate functional data is preserved in this lower-dimensional subspace.We prove that the proposed model is causally identifiable under standardassumptions that are often made in the causal discovery literature. To carryout inference of our model, we develop a fully Bayesian framework with suitableprior specifications and uncertainty quantification through posteriorsummaries. We illustrate the superior performance of our method over existingmethods in terms of causal graph estimation through extensive simulationstudies. We also demonstrate the proposed method using a brain EEG dataset.</description><author>Saptarshi Roy, Raymond K. W. Wong, Yang Ni</author><pubDate>Tue, 31 Oct 2023 16:19:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20537v1</guid></item><item><title>Surgical Phase and Instrument Recognition: How to identify appropriate Dataset Splits</title><link>http://arxiv.org/abs/2306.16879v2</link><description>Purpose: Machine learning models can only be reliably evaluated if training,validation, and test data splits are representative and not affected by theabsence of classes of interest. Surgical workflow and instrument recognitiontasks are complicated in this manner, because of heavy data imbalancesresulting from different lengths of phases and their erratic occurrences.Furthermore, the issue becomes difficult as sub-properties that help definephases, like instrument (co-)occurrence, are usually not considered whendefining the split. We argue that such sub-properties must be equallyconsidered. Methods: This work presents a publicly available data visualization tool thatenables interactive exploration of dataset splits for surgical phase andinstrument recognition. It focuses on the visualization of the occurrence ofphases, phase transitions, instruments, and instrument combinations acrosssets. Particularly, it facilitates the assessment and identification ofsub-optimal dataset splits. Results: We performed an analysis of common Cholec80 dataset splits using theproposed application and were able to uncover phase transitions andcombinations of instruments that were not represented in one of the sets.Additionally, we outlined possible improvements to the splits. A user studywith ten participants demonstrated the ability of participants to solve aselection of data exploration tasks using the proposed application. Conclusion: In highly unbalanced class distributions, special care should betaken with respect to the selection of an appropriate dataset split. Ourinteractive data visualization tool presents a promising approach for theassessment of dataset splits for surgical phase and instrument recognition.Evaluation results show that it can enhance the development of machine learningmodels. The application is available at https://cardio-ai.github.io/endovis-ml/ .</description><author>Georgii Kostiuchik, Lalith Sharan, Benedikt Mayer, Ivo Wolf, Bernhard Preim, Sandy Engelhardt</author><pubDate>Tue, 31 Oct 2023 16:16:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16879v2</guid></item><item><title>Fairness Explainability using Optimal Transport with Applications in Image Classification</title><link>http://arxiv.org/abs/2308.11090v2</link><description>Ensuring trust and accountability in Artificial Intelligence systems demandsexplainability of its outcomes. Despite significant progress in Explainable AI,human biases still taint a substantial portion of its training data, raisingconcerns about unfairness or discriminatory tendencies. Current approaches inthe field of Algorithmic Fairness focus on mitigating such biases in theoutcomes of a model, but few attempts have been made to try to explain\emph{why} a model is biased. To bridge this gap between the two fields, wepropose a comprehensive approach that uses optimal transport theory to uncoverthe causes of discrimination in Machine Learning applications, with aparticular emphasis on image classification. We leverage Wassersteinbarycenters to achieve fair predictions and introduce an extension to pinpointbias-associated regions. This allows us to derive a cohesive system which usesthe enforced fairness to measure each features influence \emph{on} the bias.Taking advantage of this interplay of enforcing and explaining fairness, ourmethod hold significant implications for the development of trustworthy andunbiased AI systems, fostering transparency, accountability, and fairness incritical decision-making scenarios across diverse domains.</description><author>Philipp Ratz, François Hu, Arthur Charpentier</author><pubDate>Tue, 31 Oct 2023 16:07:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11090v2</guid></item><item><title>Electrical Impedance Tomography with Deep Calderón Method</title><link>http://arxiv.org/abs/2304.09074v2</link><description>Electrical impedance tomography (EIT) is a noninvasive medical imagingmodality utilizing the current-density/voltage data measured on the surface ofthe subject. Calder\'on's method is a relatively recent EIT imaging algorithmthat is non-iterative, fast, and capable of reconstructing complex-valuedelectric impedances. However, due to the regularization via low-pass filteringand linearization, the reconstructed images suffer from severe blurring andunder-estimation of the exact conductivity values. In this work, we develop anenhanced version of Calder\'on's method, using {deep} convolution neuralnetworks (i.e., U-net) {as an effective targeted post-processing step, and termthe resulting method by deep Calder\'{o}n's method.} Specifically, we learn aU-net to postprocess the EIT images generated by Calder\'on's method so as tohave better resolutions and more accurate estimates of conductivity values. Wesimulate chest configurations with which we generate thecurrent-density/voltage boundary measurements and the correspondingreconstructed images by Calder\'on's method. With the paired training data, welearn the deep neural network and evaluate its performance on real tankmeasurement data. The experimental results indicate that the proposed approachindeed provides a fast and direct (complex-valued) impedance tomography imagingtechnique, and substantially improves the capability of the standardCalder\'on's method.</description><author>Siyu Cen, Bangti Jin, Kwancheol Shin, Zhi Zhou</author><pubDate>Tue, 31 Oct 2023 16:06:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.09074v2</guid></item><item><title>Simplifying and Empowering Transformers for Large-Graph Representations</title><link>http://arxiv.org/abs/2306.10759v3</link><description>Learning representations on large-sized graphs is a long-standing challengedue to the inter-dependence nature involved in massive data points.Transformers, as an emerging class of foundation encoders for graph-structureddata, have shown promising performance on small graphs due to its globalattention capable of capturing all-pair influence beyond neighboring nodes.Even so, existing approaches tend to inherit the spirit of Transformers inlanguage and vision tasks, and embrace complicated models by stacking deepmulti-head attentions. In this paper, we critically demonstrate that even usinga one-layer attention can bring up surprisingly competitive performance acrossnode property prediction benchmarks where node numbers range fromthousand-level to billion-level. This encourages us to rethink the designphilosophy for Transformers on large graphs, where the global attention is acomputation overhead hindering the scalability. We frame the proposed scheme asSimplified Graph Transformers (SGFormer), which is empowered by a simpleattention model that can efficiently propagate information among arbitrarynodes in one layer. SGFormer requires none of positional encodings,feature/graph pre-processing or augmented loss. Empirically, SGFormersuccessfully scales to the web-scale graph ogbn-papers100M and yields up to141x inference acceleration over SOTA Transformers on medium-sized graphs.Beyond current results, we believe the proposed methodology alone enlightens anew technical path of independent interest for building Transformers on largegraphs.</description><author>Qitian Wu, Wentao Zhao, Chenxiao Yang, Hengrui Zhang, Fan Nie, Haitian Jiang, Yatao Bian, Junchi Yan</author><pubDate>Tue, 31 Oct 2023 16:05:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10759v3</guid></item><item><title>A digital twin framework for civil engineering structures</title><link>http://arxiv.org/abs/2308.01445v2</link><description>The digital twin concept represents an appealing opportunity to advancecondition-based and predictive maintenance paradigms for civil engineeringsystems, thus allowing reduced lifecycle costs, increased system safety, andincreased system availability. This work proposes a predictive digital twinapproach to the health monitoring, maintenance, and management planning ofcivil engineering structures. The asset-twin coupled dynamical system isencoded employing a probabilistic graphical model, which allows all relevantsources of uncertainty to be taken into account. In particular, thetime-repeating observations-to-decisions flow is modeled using a dynamicBayesian network. Real-time structural health diagnostics are provided byassimilating sensed data with deep learning models. The digital twin state iscontinually updated in a sequential Bayesian inference fashion. This is thenexploited to inform the optimal planning of maintenance and management actionswithin a dynamic decision-making framework. A preliminary offline phaseinvolves the population of training datasets through a reduced-order numericalmodel and the computation of a health-dependent control policy. The strategy isassessed on two synthetic case studies, involving a cantilever beam and arailway bridge, demonstrating the dynamic decision-making capabilities ofhealth-aware digital twins.</description><author>Matteo Torzoni, Marco Tezzele, Stefano Mariani, Andrea Manzoni, Karen E. Willcox</author><pubDate>Tue, 31 Oct 2023 16:05:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01445v2</guid></item><item><title>Group-Feature (Sensor) Selection With Controlled Redundancy Using Neural Networks</title><link>http://arxiv.org/abs/2310.20524v1</link><description>In this paper, we present a novel embedded feature selection method based ona Multi-layer Perceptron (MLP) network and generalize it for group-feature orsensor selection problems, which can control the level of redundancy among theselected features or groups. Additionally, we have generalized the group lassopenalty for feature selection to encompass a mechanism for selecting valuablegroup features while simultaneously maintaining a control over redundancy. Weestablish the monotonicity and convergence of the proposed algorithm, with asmoothed version of the penalty terms, under suitable assumptions. Experimentalresults on several benchmark datasets demonstrate the promising performance ofthe proposed methodology for both feature selection and group feature selectionover some state-of-the-art methods.</description><author>Aytijhya Saha, Nikhil R. Pal</author><pubDate>Tue, 31 Oct 2023 16:04:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20524v1</guid></item><item><title>Enabling Large Language Models to Generate Text with Citations</title><link>http://arxiv.org/abs/2305.14627v2</link><description>Large language models (LLMs) have emerged as a widely-used tool forinformation seeking, but their generated outputs are prone to hallucination. Inthis work, our aim is to allow LLMs to generate text with citations, improvingtheir factual correctness and verifiability. Existing work mainly relies oncommercial search engines and human evaluation, making it challenging toreproduce and compare different modeling approaches. We propose ALCE, the firstbenchmark for Automatic LLMs' Citation Evaluation. ALCE collects a diverse setof questions and retrieval corpora and requires building end-to-end systems toretrieve supporting evidence and generate answers with citations. We developautomatic metrics along three dimensions -- fluency, correctness, and citationquality -- and demonstrate their strong correlation with human judgements. Ourexperiments with state-of-the-art LLMs and novel prompting strategies show thatcurrent systems have considerable room for improvement -- For example, on theELI5 dataset, even the best models lack complete citation support 50% of thetime. Our analyses further highlight promising future directions, includingdeveloping better retrievers, advancing long-context LLMs, and improving theability to synthesize information from multiple sources.</description><author>Tianyu Gao, Howard Yen, Jiatong Yu, Danqi Chen</author><pubDate>Tue, 31 Oct 2023 16:04:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14627v2</guid></item><item><title>Measures of Information Reflect Memorization Patterns</title><link>http://arxiv.org/abs/2210.09404v3</link><description>Neural networks are known to exploit spurious artifacts (or shortcuts) thatco-occur with a target label, exhibiting heuristic memorization. On the otherhand, networks have been shown to memorize training examples, resulting inexample-level memorization. These kinds of memorization impede generalizationof networks beyond their training distributions. Detecting such memorizationcould be challenging, often requiring researchers to curate tailored test sets.In this work, we hypothesize -- and subsequently show -- that the diversity inthe activation patterns of different neurons is reflective of modelgeneralization and memorization. We quantify the diversity in the neuralactivations through information-theoretic measures and find support for ourhypothesis on experiments spanning several natural language and vision tasks.Importantly, we discover that information organization points to the two formsof memorization, even for neural activations computed on unlabelledin-distribution examples. Lastly, we demonstrate the utility of our findingsfor the problem of model selection. The associated code and other resources forthis work are available at https://rachitbansal.github.io/information-measures.</description><author>Rachit Bansal, Danish Pruthi, Yonatan Belinkov</author><pubDate>Tue, 31 Oct 2023 16:02:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.09404v3</guid></item><item><title>Structural Similarities Between Language Models and Neural Response Measurements</title><link>http://arxiv.org/abs/2306.01930v2</link><description>Large language models (LLMs) have complicated internal dynamics, but inducerepresentations of words and phrases whose geometry we can study. Humanlanguage processing is also opaque, but neural response measurements canprovide (noisy) recordings of activation during listening or reading, fromwhich we can extract similar representations of words and phrases. Here westudy the extent to which the geometries induced by these representations,share similarities in the context of brain decoding. We find that the largerneural language models get, the more their representations are structurallysimilar to neural response measurements from brain imaging. Code is availableat \url{https://github.com/coastalcph/brainlm}.</description><author>Jiaang Li, Antonia Karamolegkou, Yova Kementchedjhieva, Mostafa Abdou, Sune Lehmann, Anders Søgaard</author><pubDate>Tue, 31 Oct 2023 16:02:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01930v2</guid></item><item><title>Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural Networks</title><link>http://arxiv.org/abs/2305.06986v2</link><description>One of the central questions in the theory of deep learning is to understandhow neural networks learn hierarchical features. The ability of deep networksto extract salient features is crucial to both their outstanding generalizationability and the modern deep learning paradigm of pretraining and finetuneing.However, this feature learning process remains poorly understood from atheoretical perspective, with existing analyses largely restricted to two-layernetworks. In this work we show that three-layer neural networks have provablyricher feature learning capabilities than two-layer networks. We analyze thefeatures learned by a three-layer network trained with layer-wise gradientdescent, and present a general purpose theorem which upper bounds the samplecomplexity and width needed to achieve low test error when the target hasspecific hierarchical structure. We instantiate our framework in specificstatistical learning settings -- single-index models and functions of quadraticfeatures -- and show that in the latter setting three-layer networks obtain asample complexity improvement over all existing guarantees for two-layernetworks. Crucially, this sample complexity improvement relies on the abilityof three-layer networks to efficiently learn nonlinear features. We thenestablish a concrete optimization-based depth separation by constructing afunction which is efficiently learnable via gradient descent on a three-layernetwork, yet cannot be learned efficiently by a two-layer network. Our workmakes progress towards understanding the provable benefit of three-layer neuralnetworks over two-layer networks in the feature learning regime.</description><author>Eshaan Nichani, Alex Damian, Jason D. Lee</author><pubDate>Tue, 31 Oct 2023 15:58:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.06986v2</guid></item><item><title>Score-based Data Assimilation</title><link>http://arxiv.org/abs/2306.10574v2</link><description>Data assimilation, in its most comprehensive form, addresses the Bayesianinverse problem of identifying plausible state trajectories that explain noisyor incomplete observations of stochastic dynamical systems. Various approacheshave been proposed to solve this problem, including particle-based andvariational methods. However, most algorithms depend on the transition dynamicsfor inference, which becomes intractable for long time horizons or forhigh-dimensional systems with complex dynamics, such as oceans or atmospheres.In this work, we introduce score-based data assimilation for trajectoryinference. We learn a score-based generative model of state trajectories basedon the key insight that the score of an arbitrarily long trajectory can bedecomposed into a series of scores over short segments. After training,inference is carried out using the score model, in a non-autoregressive mannerby generating all states simultaneously. Quite distinctively, we decouple theobservation model from the training procedure and use it only at inference toguide the generative process, which enables a wide range of zero-shotobservation scenarios. We present theoretical and empirical evidence supportingthe effectiveness of our method.</description><author>François Rozet, Gilles Louppe</author><pubDate>Tue, 31 Oct 2023 15:57:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10574v2</guid></item><item><title>Fine-Tuning Language Models with Just Forward Passes</title><link>http://arxiv.org/abs/2305.17333v2</link><description>Fine-tuning language models (LMs) has yielded success on diverse downstreamtasks, but as LMs grow in size, backpropagation requires a prohibitively largeamount of memory. Zeroth-order (ZO) methods can in principle estimate gradientsusing only two forward passes but are theorized to be catastrophically slow foroptimizing large models. In this work, we propose a memory-efficientzerothorder optimizer (MeZO), adapting the classical ZO-SGD method to operatein-place, thereby fine-tuning LMs with the same memory footprint as inference.For example, with a single A100 80GB GPU, MeZO can train a 30-billion parametermodel, whereas fine-tuning with backpropagation can train only a 2.7B LM withthe same budget. We conduct comprehensive experiments across model types(masked and autoregressive LMs), model scales (up to 66B), and downstream tasks(classification, multiple-choice, and generation). Our results demonstrate that(1) MeZO significantly outperforms in-context learning and linear probing; (2)MeZO achieves comparable performance to fine-tuning with backpropagation acrossmultiple tasks, with up to 12x memory reduction and up to 2x GPU-hour reductionin our implementation; (3) MeZO is compatible with both full-parameter andparameter-efficient tuning techniques such as LoRA and prefix tuning; (4) MeZOcan effectively optimize non-differentiable objectives (e.g., maximizingaccuracy or F1). We support our empirical findings with theoretical insights,highlighting how adequate pre-training and task prompts enable MeZO tofine-tune huge models, despite classical ZO analyses suggesting otherwise.</description><author>Sadhika Malladi, Tianyu Gao, Eshaan Nichani, Alex Damian, Jason D. Lee, Danqi Chen, Sanjeev Arora</author><pubDate>Tue, 31 Oct 2023 15:57:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17333v2</guid></item><item><title>Identification of Nonlinear Latent Hierarchical Models</title><link>http://arxiv.org/abs/2306.07916v2</link><description>Identifying latent variables and causal structures from observational data isessential to many real-world applications involving biological data, medicaldata, and unstructured data such as images and languages. However, this taskcan be highly challenging, especially when observed variables are generated bycausally related latent variables and the relationships are nonlinear. In thiswork, we investigate the identification problem for nonlinear latenthierarchical causal models in which observed variables are generated by a setof causally related latent variables, and some latent variables may not haveobserved children. We show that the identifiability of causal structures and latent variables(up to invertible transformations) can be achieved under mild assumptions: oncausal structures, we allow for multiple paths between any pair of variables inthe graph, which relaxes latent tree assumptions in prior work; on structuralfunctions, we permit general nonlinearity and multi-dimensional continuousvariables, alleviating existing work's parametric assumptions. Specifically, wefirst develop an identification criterion in the form of novel identifiabilityguarantees for an elementary latent variable model. Leveraging this criterion,we show that both causal structures and latent variables of the hierarchicalmodel can be identified asymptotically by explicitly constructing an estimationprocedure. To the best of our knowledge, our work is the first to establishidentifiability guarantees for both causal structures and latent variables innonlinear latent hierarchical models.</description><author>Lingjing Kong, Biwei Huang, Feng Xie, Eric Xing, Yuejie Chi, Kun Zhang</author><pubDate>Tue, 31 Oct 2023 15:54:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07916v2</guid></item><item><title>Parametric Fairness with Statistical Guarantees</title><link>http://arxiv.org/abs/2310.20508v1</link><description>Algorithmic fairness has gained prominence due to societal and regulatoryconcerns about biases in Machine Learning models. Common group fairness metricslike Equalized Odds for classification or Demographic Parity for bothclassification and regression are widely used and a host of computationallyadvantageous post-processing methods have been developed around them. However,these metrics often limit users from incorporating domain knowledge. Despitemeeting traditional fairness criteria, they can obscure issues related tointersectional fairness and even replicate unwanted intra-group biases in theresulting fair solution. To avoid this narrow perspective, we extend theconcept of Demographic Parity to incorporate distributional properties in thepredictions, allowing expert knowledge to be used in the fair solution. Weillustrate the use of this new metric through a practical example of wages, anddevelop a parametric method that efficiently addresses practical challengeslike limited training data and constraints on total spending, offering a robustsolution for real-life applications.</description><author>François HU, Philipp Ratz, Arthur Charpentier</author><pubDate>Tue, 31 Oct 2023 15:52:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20508v1</guid></item><item><title>Outlier-robust sparse/low-rank least-squares regression and robust matrix completion</title><link>http://arxiv.org/abs/2012.06750v3</link><description>We study high-dimensional least-squares regression within a subgaussianstatistical learning framework with heterogeneous noise. It includes $s$-sparseand $r$-low-rank least-squares regression when a fraction $\epsilon$ of thelabels are adversarially contaminated. We also present a novel theory oftrace-regression with matrix decomposition based on a new application of theproduct process. For these problems, we show novel near-optimal "subgaussian"estimation rates of the form$r(n,d_{e})+\sqrt{\log(1/\delta)/n}+\epsilon\log(1/\epsilon)$, valid withprobability at least $1-\delta$. Here, $r(n,d_{e})$ is the optimaluncontaminated rate as a function of the effective dimension $d_{e}$ butindependent of the failure probability $\delta$. These rates are validuniformly on $\delta$, i.e., the estimators' tuning do not depend on $\delta$.Lastly, we consider noisy robust matrix completion with non-uniform sampling.If only the low-rank matrix is of interest, we present a novel near-optimalrate that is independent of the corruption level $a$. Our estimators aretractable and based on a new "sorted" Huber-type loss. No information on$(s,r,\epsilon,a)$ are needed to tune these estimators. Our analysis makes useof novel $\delta$-optimal concentration inequalities for the multiplier andproduct processes which could be useful elsewhere. For instance, they implynovel sharp oracle inequalities for Lasso and Slope with optimal dependence on$\delta$. Numerical simulations confirm our theoretical predictions. Inparticular, "sorted" Huber regression can outperform classical Huberregression.</description><author>Philip Thompson</author><pubDate>Tue, 31 Oct 2023 15:49:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2012.06750v3</guid></item><item><title>Correction with Backtracking Reduces Hallucination in Summarization</title><link>http://arxiv.org/abs/2310.16176v2</link><description>Abstractive summarization aims at generating natural language summaries of asource document that are succinct while preserving the important elements.Despite recent advances, neural text summarization models are known to besusceptible to hallucinating (or more correctly confabulating), that is toproduce summaries with details that are not grounded in the source document. Inthis paper, we introduce a simple yet efficient technique, CoBa, to reducehallucination in abstractive summarization. The approach is based on two steps:hallucination detection and mitigation. We show that the former can be achievedthrough measuring simple statistics about conditional word probabilities anddistance to context words. Further, we demonstrate that straight-forwardbacktracking is surprisingly effective at mitigation. We thoroughly evaluatethe proposed method with prior art on three benchmark datasets for textsummarization. The results show that CoBa is effective and efficient inreducing hallucination, and offers great adaptability and flexibility.</description><author>Zhenzhen Liu, Chao Wan, Varsha Kishore, Jin Peng Zhou, Minmin Chen, Kilian Q. Weinberger</author><pubDate>Tue, 31 Oct 2023 15:48:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.16176v2</guid></item><item><title>A Fractional Graph Laplacian Approach to Oversmoothing</title><link>http://arxiv.org/abs/2305.13084v2</link><description>Graph neural networks (GNNs) have shown state-of-the-art performances invarious applications. However, GNNs often struggle to capture long-rangedependencies in graphs due to oversmoothing. In this paper, we generalize theconcept of oversmoothing from undirected to directed graphs. To this aim, weextend the notion of Dirichlet energy by considering a directed symmetricallynormalized Laplacian. As vanilla graph convolutional networks are prone tooversmooth, we adopt a neural graph ODE framework. Specifically, we proposefractional graph Laplacian neural ODEs, which describe non-local dynamics. Weprove that our approach allows propagating information between distant nodeswhile maintaining a low probability of long-distance jumps. Moreover, we showthat our method is more flexible with respect to the convergence of the graph'sDirichlet energy, thereby mitigating oversmoothing. We conduct extensiveexperiments on synthetic and real-world graphs, both directed and undirected,demonstrating our method's versatility across diverse graph homophily levels.Our code is available at https://github.com/RPaolino/fLode .</description><author>Sohir Maskey, Raffaele Paolino, Aras Bacho, Gitta Kutyniok</author><pubDate>Tue, 31 Oct 2023 15:45:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13084v2</guid></item><item><title>LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts</title><link>http://arxiv.org/abs/2310.20501v1</link><description>Recently, the emergence of large language models (LLMs) has revolutionizedthe paradigm of information retrieval (IR) applications, especially in websearch. With their remarkable capabilities in generating human-like texts, LLMshave created enormous texts on the Internet. As a result, IR systems in theLLMs era are facing a new challenge: the indexed documents now are not onlywritten by human beings but also automatically generated by the LLMs. How theseLLM-generated documents influence the IR systems is a pressing and stillunexplored question. In this work, we conduct a quantitative evaluation ofdifferent IR models in scenarios where both human-written and LLM-generatedtexts are involved. Surprisingly, our findings indicate that neural retrievalmodels tend to rank LLM-generated documents higher.We refer to this category ofbiases in neural retrieval models towards the LLM-generated text as the\textbf{source bias}. Moreover, we discover that this bias is not confined tothe first-stage neural retrievers, but extends to the second-stage neuralre-rankers. Then, we provide an in-depth analysis from the perspective of textcompression and observe that neural models can better understand the semanticinformation of LLM-generated text, which is further substantiated by ourtheoretical analysis.We also discuss the potential server concerns stemmingfrom the observed source bias and hope our findings can serve as a criticalwake-up call to the IR community and beyond. To facilitate future explorationsof IR in the LLM era, the constructed two new benchmarks and codes will laterbe available at \url{https://github.com/KID-22/LLM4IR-Bias}.</description><author>Sunhao Dai, Yuqi Zhou, Liang Pang, Weihao Liu, Xiaolin Hu, Yong Liu, Xiao Zhang, Jun Xu</author><pubDate>Tue, 31 Oct 2023 15:42:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.20501v1</guid></item></channel></rss>