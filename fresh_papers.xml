<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 21 Jun 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Model Merging and Safety Alignment: One Bad Model Spoils the Bunch</title><link>http://arxiv.org/abs/2406.14563v1</link><description>Merging Large Language Models (LLMs) is a cost-effective technique forcombining multiple expert LLMs into a single versatile model, retaining theexpertise of the original ones. However, current approaches often overlook theimportance of safety alignment during merging, leading to highly misalignedmodels. This work investigates the effects of model merging on alignment. Weevaluate several popular model merging techniques, demonstrating that existingmethods do not only transfer domain expertise but also propagate misalignment.We propose a simple two-step approach to address this problem: (i) generatingsynthetic safety and domain-specific data, and (ii) incorporating thesegenerated data into the optimization process of existing data-aware modelmerging techniques. This allows us to treat alignment as a skill that can bemaximized in the resulting merged LLM. Our experiments illustrate theeffectiveness of integrating alignment-related data during merging, resultingin models that excel in both domain expertise and alignment.</description><author>Hasan Abed Al Kader Hammoud, Umberto Michieli, Fabio Pizzati, Philip Torr, Adel Bibi, Bernard Ghanem, Mete Ozay</author><pubDate>Thu, 20 Jun 2024 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14563v1</guid></item><item><title>Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities</title><link>http://arxiv.org/abs/2406.14562v1</link><description>When presented with questions involving visual thinking, humans naturallyswitch reasoning modalities, often forming mental images or drawing visualaids. Large language models have shown promising results in arithmetic andsymbolic reasoning by expressing intermediate reasoning in text as a chain ofthought, yet struggle to extend this capability to answer text queries that areeasily solved by visual reasoning, even with extensive multimodal pretraining.We introduce a simple method, whiteboard-of-thought prompting, to unlock thevisual reasoning capabilities of multimodal large language models acrossmodalities. Whiteboard-of-thought prompting provides multimodal large languagemodels with a metaphorical `whiteboard' to draw out reasoning steps as images,then returns these images back to the model for further processing. We findthis can be accomplished with no demonstrations or specialized modules, insteadleveraging models' existing ability to write code with libraries such asMatplotlib and Turtle. This simple approach shows state-of-the-art results onfour difficult natural language tasks that involve visual and spatialreasoning. We identify multiple settings where GPT-4o using chain-of-thoughtfails dramatically, including more than one where it achieves $0\%$ accuracy,while whiteboard-of-thought enables up to $92\%$ accuracy in these samesettings. We present a detailed exploration of where the technique succeeds aswell as its sources of error.</description><author>Sachit Menon, Richard Zemel, Carl Vondrick</author><pubDate>Thu, 20 Jun 2024 18:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14562v1</guid></item><item><title>How to Compute the Probability of a Word</title><link>http://arxiv.org/abs/2406.14561v1</link><description>Language models (LMs) estimate the probability distribution over sequences ofnatural language; these distributions are crucial for computing perplexity andsurprisal in linguistics research. While we are usually concerned withmeasuring these values for words, most LMs operate over subwords. Despiteseemingly straightforward, accurately computing probabilities over one unitgiven probabilities over the other requires care. Indeed, we show here thatmany recent linguistic studies have been incorrectly computing these values.This paper derives the correct methods for computing word probabilities,highlighting issues when relying on language models that use beginning-of-word(bow)-marking tokenisers, e.g., the GPT family. Empirically, we show thatcorrecting the widespread bug in probability computations affects measuredoutcomes in sentence comprehension and lexical optimisation analyses.</description><author>Tiago Pimentel, Clara Meister</author><pubDate>Thu, 20 Jun 2024 18:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14561v1</guid></item><item><title>CooHOI: Learning Cooperative Human-Object Interaction with Manipulated Object Dynamics</title><link>http://arxiv.org/abs/2406.14558v1</link><description>Recent years have seen significant advancements in humanoid control, largelydue to the availability of large-scale motion capture data and the applicationof reinforcement learning methodologies. However, many real-world tasks, suchas moving large and heavy furniture, require multi-character collaboration.Given the scarcity of data on multi-character collaboration and the efficiencychallenges associated with multi-agent learning, these tasks cannot bestraightforwardly addressed using training paradigms designed for single-agentscenarios. In this paper, we introduce Cooperative Human-Object Interaction(CooHOI), a novel framework that addresses multi-character objects transportingthrough a two-phase learning paradigm: individual skill acquisition andsubsequent transfer. Initially, a single agent learns to perform tasks usingthe Adversarial Motion Priors (AMP) framework. Following this, the agent learnsto collaborate with others by considering the shared dynamics of themanipulated object during parallel training using Multi Agent Proximal PolicyOptimization (MAPPO). When one agent interacts with the object, resulting inspecific object dynamics changes, the other agents learn to respondappropriately, thereby achieving implicit communication and coordinationbetween teammates. Unlike previous approaches that relied on tracking-basedmethods for multi-character HOI, CooHOI is inherently efficient, does notdepend on motion capture data of multi-character interactions, and can beseamlessly extended to include more participants and a wide range of objecttypes</description><author>Jiawei Gao, Ziqin Wang, Zeqi Xiao, Jingbo Wang, Tai Wang, Jinkun Cao, Xiaolin Hu, Si Liu, Jifeng Dai, Jiangmiao Pang</author><pubDate>Thu, 20 Jun 2024 18:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14558v1</guid></item><item><title>Asynchronous Large Language Model Enhanced Planner for Autonomous Driving</title><link>http://arxiv.org/abs/2406.14556v1</link><description>Despite real-time planners exhibiting remarkable performance in autonomousdriving, the growing exploration of Large Language Models (LLMs) has openedavenues for enhancing the interpretability and controllability of motionplanning. Nevertheless, LLM-based planners continue to encounter significantchallenges, including elevated resource consumption and extended inferencetimes, which pose substantial obstacles to practical deployment. In light ofthese challenges, we introduce AsyncDriver, a new asynchronous LLM-enhancedclosed-loop framework designed to leverage scene-associated instructionfeatures produced by LLM to guide real-time planners in making precise andcontrollable trajectory predictions. On one hand, our method highlights theprowess of LLMs in comprehending and reasoning with vectorized scene data and aseries of routing instructions, demonstrating its effective assistance toreal-time planners. On the other hand, the proposed framework decouples theinference processes of the LLM and real-time planners. By capitalizing on theasynchronous nature of their inference frequencies, our approach havesuccessfully reduced the computational cost introduced by LLM, whilemaintaining comparable performance. Experiments show that our approach achievessuperior closed-loop evaluation performance on nuPlan's challenging scenarios.</description><author>Yuan Chen, Zi-han Ding, Ziqin Wang, Yan Wang, Lijun Zhang, Si Liu</author><pubDate>Thu, 20 Jun 2024 18:59:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14556v1</guid></item><item><title>A Survey of Multimodal-Guided Image Editing with Text-to-Image Diffusion Models</title><link>http://arxiv.org/abs/2406.14555v1</link><description>Image editing aims to edit the given synthetic or real image to meet thespecific requirements from users. It is widely studied in recent years as apromising and challenging field of Artificial Intelligence Generative Content(AIGC). Recent significant advancement in this field is based on thedevelopment of text-to-image (T2I) diffusion models, which generate imagesaccording to text prompts. These models demonstrate remarkable generativecapabilities and have become widely used tools for image editing. T2I-basedimage editing methods significantly enhance editing performance and offer auser-friendly interface for modifying content guided by multimodal inputs. Inthis survey, we provide a comprehensive review of multimodal-guided imageediting techniques that leverage T2I diffusion models. First, we define thescope of image editing from a holistic perspective and detail various controlsignals and editing scenarios. We then propose a unified framework to formalizethe editing process, categorizing it into two primary algorithm families. Thisframework offers a design space for users to achieve specific goals.Subsequently, we present an in-depth analysis of each component within thisframework, examining the characteristics and applicable scenarios of differentcombinations. Given that training-based methods learn to directly map thesource image to target one under user guidance, we discuss them separately, andintroduce injection schemes of source image in different scenarios.Additionally, we review the application of 2D techniques to video editing,highlighting solutions for inter-frame inconsistency. Finally, we discuss openchallenges in the field and suggest potential future research directions. Wekeep tracing related works athttps://github.com/xinchengshuai/Awesome-Image-Editing.</description><author>Xincheng Shuai, Henghui Ding, Xingjun Ma, Rongcheng Tu, Yu-Gang Jiang, Dacheng Tao</author><pubDate>Thu, 20 Jun 2024 18:58:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14555v1</guid></item><item><title>xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics</title><link>http://arxiv.org/abs/2406.14553v1</link><description>State-of-the-art trainable machine translation evaluation metrics like xCOMETachieve high correlation with human judgment but rely on large encoders (up to10.7B parameters), making them computationally expensive and inaccessible toresearchers with limited resources. To address this issue, we investigatewhether the knowledge stored in these large encoders can be compressed whilemaintaining quality. We employ distillation, quantization, and pruningtechniques to create efficient xCOMET alternatives and introduce a novel datacollection pipeline for efficient black-box distillation. Our experiments showthat, using quantization, xCOMET can be compressed up to three times with noquality degradation. Additionally, through distillation, we create anxCOMET-lite metric, which has only 2.6% of xCOMET-XXL parameters, but retains92.1% of its quality. Besides, it surpasses strong small-scale metrics likeCOMET-22 and BLEURT-20 on the WMT22 metrics challenge dataset by 6.4%, despiteusing 50% fewer parameters. All code, dataset, and models are available online.</description><author>Daniil Larionov, Mikhail Seleznyov, Vasiliy Viskov, Alexander Panchenko, Steffen Eger</author><pubDate>Thu, 20 Jun 2024 18:58:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14553v1</guid></item><item><title>Advancing Fine-Grained Classification by Structure and Subject Preserving Augmentation</title><link>http://arxiv.org/abs/2406.14551v1</link><description>Fine-grained visual classification (FGVC) involves classifying closelyrelated sub-classes. This task is difficult due to the subtle differencesbetween classes and the high intra-class variance. Moreover, FGVC datasets aretypically small and challenging to gather, thus highlighting a significant needfor effective data augmentation. Recent advancements in text-to-image diffusionmodels offer new possibilities for augmenting classification datasets. Whilethese models have been used to generate training data for classification tasks,their effectiveness in full-dataset training of FGVC models remainsunder-explored. Recent techniques that rely on Text2Image generation or Img2Imgmethods, often struggle to generate images that accurately represent the classwhile modifying them to a degree that significantly increases the dataset'sdiversity. To address these challenges, we present SaSPA: Structure and SubjectPreserving Augmentation. Contrary to recent methods, our method does not usereal images as guidance, thereby increasing generation flexibility andpromoting greater diversity. To ensure accurate class representation, we employconditioning mechanisms, specifically by conditioning on image edges andsubject representation. We conduct extensive experiments and benchmark SaSPAagainst both traditional and recent generative data augmentation methods. SaSPAconsistently outperforms all established baselines across multiple settings,including full dataset training, contextual bias, and few-shot classification.Additionally, our results reveal interesting patterns in using synthetic datafor FGVC models; for instance, we find a relationship between the amount ofreal data used and the optimal proportion of synthetic data. Code is availableat https://github.com/EyalMichaeli/SaSPA-Aug.</description><author>Eyal Michaeli, Ohad Fried</author><pubDate>Thu, 20 Jun 2024 18:58:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14551v1</guid></item><item><title>GraphReader: Building Graph-based Agent to Enhance Long-Context Abilities of Large Language Models</title><link>http://arxiv.org/abs/2406.14550v1</link><description>Long-context capabilities are essential for large language models (LLMs) totackle complex and long-input tasks. Despite numerous efforts made to optimizeLLMs for long contexts, challenges persist in robustly processing long inputs.In this paper, we introduce GraphReader, a graph-based agent system designed tohandle long texts by structuring them into a graph and employing an agent toexplore this graph autonomously. Upon receiving a question, the agent firstundertakes a step-by-step analysis and devises a rational plan. It then invokesa set of predefined functions to read node content and neighbors, facilitatinga coarse-to-fine exploration of the graph. Throughout the exploration, theagent continuously records new insights and reflects on current circumstancesto optimize the process until it has gathered sufficient information togenerate an answer. Experimental results on the LV-Eval dataset reveal thatGraphReader, using a 4k context window, consistently outperforms GPT-4-128kacross context lengths from 16k to 256k by a large margin. Additionally, ourapproach demonstrates superior performance on four challenging single-hop andmulti-hop benchmarks.</description><author>Shilong Li, Yancheng He, Hangyu Guo, Xingyuan Bu, Ge Bai, Jie Liu, Jiaheng Liu, Xingwei Qu, Yangguang Li, Wanli Ouyang, Wenbo Su, Bo Zheng</author><pubDate>Thu, 20 Jun 2024 18:57:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14550v1</guid></item><item><title>Uncovering Latent Memories: Assessing Data Leakage and Memorization Patterns in Large Language Models</title><link>http://arxiv.org/abs/2406.14549v1</link><description>The proliferation of large language models has revolutionized naturallanguage processing tasks, yet it raises profound concerns regarding dataprivacy and security. Language models are trained on extensive corporaincluding potentially sensitive or proprietary information, and the risk ofdata leakage -- where the model response reveals pieces of such information --remains inadequately understood. This study examines susceptibility to dataleakage by quantifying the phenomenon of memorization in machine learningmodels, focusing on the evolution of memorization patterns over training. Weinvestigate how the statistical characteristics of training data influence thememories encoded within the model by evaluating how repetition influencesmemorization. We reproduce findings that the probability of memorizing asequence scales logarithmically with the number of times it is present in thedata. Furthermore, we find that sequences which are not apparently memorizedafter the first encounter can be uncovered throughout the course of trainingeven without subsequent encounters. The presence of these latent memorizedsequences presents a challenge for data privacy since they may be hidden at thefinal checkpoint of the model. To this end, we develop a diagnostic test foruncovering these latent memorized sequences by considering their cross entropyloss.</description><author>Sunny Duan, Mikail Khona, Abhiram Iyer, Rylan Schaeffer, Ila R Fiete</author><pubDate>Thu, 20 Jun 2024 18:56:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14549v1</guid></item><item><title>Consistency Models Made Easy</title><link>http://arxiv.org/abs/2406.14548v1</link><description>Consistency models (CMs) are an emerging class of generative models thatoffer faster sampling than traditional diffusion models. CMs enforce that allpoints along a sampling trajectory are mapped to the same initial point. Butthis target leads to resource-intensive training: for example, as of 2024,training a SoTA CM on CIFAR-10 takes one week on 8 GPUs. In this work, wepropose an alternative scheme for training CMs, vastly improving the efficiencyof building such models. Specifically, by expressing CM trajectories via aparticular differential equation, we argue that diffusion models can be viewedas a special case of CMs with a specific discretization. We can thus fine-tunea consistency model starting from a pre-trained diffusion model andprogressively approximate the full consistency condition to stronger degreesover the training process. Our resulting method, which we term Easy ConsistencyTuning (ECT), achieves vastly improved training times while indeed improvingupon the quality of previous methods: for example, ECT achieves a 2-step FID of2.73 on CIFAR10 within 1 hour on a single A100 GPU, matching ConsistencyDistillation trained of hundreds of GPU hours. Owing to this computationalefficiency, we investigate the scaling law of CMs under ECT, showing that theyseem to obey classic power law scaling, hinting at their ability to improveefficiency and performance at larger scales. Code(https://github.com/locuslab/ect) is available.</description><author>Zhengyang Geng, Ashwini Pokle, William Luo, Justin Lin, J. Zico Kolter</author><pubDate>Thu, 20 Jun 2024 18:56:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14548v1</guid></item><item><title>Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data</title><link>http://arxiv.org/abs/2406.14546v1</link><description>One way to address safety risks from large language models (LLMs) is tocensor dangerous knowledge from their training data. While this removes theexplicit information, implicit information can remain scattered across varioustraining documents. Could an LLM infer the censored knowledge by piecingtogether these implicit hints? As a step towards answering this question, westudy inductive out-of-context reasoning (OOCR), a type of generalization inwhich LLMs infer latent information from evidence distributed across trainingdocuments and apply it to downstream tasks without in-context learning. Using asuite of five tasks, we demonstrate that frontier LLMs can perform inductiveOOCR. In one experiment we finetune an LLM on a corpus consisting only ofdistances between an unknown city and other known cities. Remarkably, withoutin-context examples or Chain of Thought, the LLM can verbalize that the unknowncity is Paris and use this fact to answer downstream questions. Furtherexperiments show that LLMs trained only on individual coin flip outcomes canverbalize whether the coin is biased, and those trained only on pairs$(x,f(x))$ can articulate a definition of $f$ and compute inverses. While OOCRsucceeds in a range of cases, we also show that it is unreliable, particularlyfor smaller LLMs learning complex structures. Overall, the ability of LLMs to"connect the dots" without explicit in-context learning poses a potentialobstacle to monitoring and controlling the knowledge acquired by LLMs.</description><author>Johannes Treutlein, Dami Choi, Jan Betley, Cem Anil, Samuel Marks, Roger Baker Grosse, Owain Evans</author><pubDate>Thu, 20 Jun 2024 18:55:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14546v1</guid></item><item><title>Unmasking Database Vulnerabilities: Zero-Knowledge Schema Inference Attacks in Text-to-SQL Systems</title><link>http://arxiv.org/abs/2406.14545v1</link><description>Relational databases are integral to modern information systems, serving asthe foundation for storing, querying, and managing data efficiently andeffectively. Advancements in large language modeling have led to the emergenceof text-to-SQL technologies, significantly enhancing the querying andextracting of information from these databases and raising concerns aboutprivacy and security. Our research extracts the database schema elementsunderlying a text-to-SQL model. Knowledge of the schema can make attacks suchas SQL injection easier. By asking specially crafted questions, we havedeveloped a zero-knowledge framework designed to probe various database schemaelements without knowledge of the database itself. The text-to-SQL models thenprocess these questions to produce an output that we use to uncover thestructure of the database schema. We apply it to specialized text-to-SQL modelsfine-tuned on text-SQL pairs and generative language models used for SQLgeneration. Overall, we can reconstruct the table names with an F1 of nearly.75 for fine-tuned models and .96 for generative.</description><author>Đorđe Klisura, Anthony Rios</author><pubDate>Thu, 20 Jun 2024 18:54:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14545v1</guid></item><item><title>Prism: A Framework for Decoupling and Assessing the Capabilities of VLMs</title><link>http://arxiv.org/abs/2406.14544v1</link><description>Vision Language Models (VLMs) demonstrate remarkable proficiency inaddressing a wide array of visual questions, which requires strong perceptionand reasoning faculties. Assessing these two competencies independently iscrucial for model refinement, despite the inherent difficulty due to theintertwined nature of seeing and reasoning in existing VLMs. To tackle thisissue, we present Prism, an innovative framework designed to disentangle theperception and reasoning processes involved in visual question solving. Prismcomprises two distinct stages: a perception stage that utilizes a VLM toextract and articulate visual information in textual form, and a reasoningstage that formulates responses based on the extracted visual information usinga Large Language Model (LLM). This modular design enables the systematiccomparison and assessment of both proprietary and open-source VLM for theirperception and reasoning strengths. Our analytical framework provides severalvaluable insights, underscoring Prism's potential as a cost-effective solutionfor vision-language tasks. By combining a streamlined VLM focused on perceptionwith a powerful LLM tailored for reasoning, Prism achieves superior results ingeneral vision-language tasks while substantially cutting down on training andoperational expenses. Quantitative evaluations show that Prism, when configuredwith a vanilla 2B LLaVA and freely accessible GPT-3.5, delivers performance onpar with VLMs $10 \times$ larger on the rigorous multimodal benchmark MMStar.The project is released at: https://github.com/SparksJoe/Prism.</description><author>Yuxuan Qiao, Haodong Duan, Xinyu Fang, Junming Yang, Lin Chen, Songyang Zhang, Jiaqi Wang, Dahua Lin, Kai Chen</author><pubDate>Thu, 20 Jun 2024 18:54:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14544v1</guid></item><item><title>SIT: Fine-tuning Large Language Models with Sequential Instructions</title><link>http://arxiv.org/abs/2403.07794v2</link><description>Despite the success of existing instruction-tuned models, we find that theyusually struggle to respond to queries with multiple instructions. This impairstheir performance in complex problems whose solution consists of multipleintermediate tasks. Thus, we contend that part of the fine-tuning data mixtureshould be sequential--containing a chain of interrelated tasks. We firstapproach sequential instruction tuning from a task-driven perspective, manuallycreating interpretable intermediate tasks for multilingual and visual questionanswering: namely "translate then predict" and "caption then answer". Next, weautomate this process by turning instructions in existing datasets (e.g.,Alpaca and FlanCoT) into diverse and complex sequential instructions, makingour method general-purpose. Models that underwent our sequential instructiontuning show improved results in coding, maths, and open-ended generation.Moreover, we put forward a new benchmark named SeqEval to evaluate a model'sability to follow all the instructions in a sequence, which furthercorroborates the benefits of our fine-tuning method. We hope that ourendeavours will open new research avenues on instruction tuning for complextasks.</description><author>Hanxu Hu, Simon Yu, Pinzhen Chen, Edoardo M. Ponti</author><pubDate>Thu, 20 Jun 2024 18:53:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.07794v2</guid></item><item><title>Photometry of Saturated Stars with Neural Networks</title><link>http://arxiv.org/abs/2404.15405v2</link><description>We use a multilevel perceptron (MLP) neural network to obtain photometry ofsaturated stars in the All-Sky Automated Survey for Supernovae (ASAS-SN). TheMLP can obtain fairly unbiased photometry for stars from g~4 to 14~mag,particularly compared to the dispersion (15%-85% 1sigma range around themedian) of 0.12 mag for saturated (g&lt;11.5 mag) stars. More importantly, thelight curve of a non-variable saturated star has a median dispersion of only0.037 mag. The MLP light curves are, in many cases, spectacularly better thanthose provided by the standard ASAS-SN pipelines. While the network was trainedon g band data from only one of ASAS-SN's 20 cameras, initial experimentssuggest that it can be used for any camera and the older ASAS-SN V band data aswell. The dominant problems seem to be associated with correctable issues inthe ASAS-SN data reduction pipeline for saturated stars more than the MLPitself. The method is publicly available as a light curve option on ASAS-SN SkyPatrol v1.0.</description><author>Dominik Winecki, Christopher S. Kochanek</author><pubDate>Thu, 20 Jun 2024 18:53:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.15405v2</guid></item><item><title>Are LLMs Naturally Good at Synthetic Tabular Data Generation?</title><link>http://arxiv.org/abs/2406.14541v1</link><description>Large language models (LLMs) have demonstrated their prowess in generatingsynthetic text and images; however, their potential for generating tabular data-- arguably the most common data type in business and scientific applications-- is largely underexplored. This paper demonstrates that LLMs, used as-is, orafter traditional fine-tuning, are severely inadequate as synthetic tablegenerators. Due to the autoregressive nature of LLMs, fine-tuning with randomorder permutation runs counter to the importance of modeling functionaldependencies, and renders LLMs unable to model conditional mixtures ofdistributions (key to capturing real world constraints). We showcase how LLMscan be made to overcome some of these deficiencies by making thempermutation-aware.</description><author>Shengzhe Xu, Cho-Ting Lee, Mandar Sharma, Raquib Bin Yousuf, Nikhil Muralidhar, Naren Ramakrishnan</author><pubDate>Thu, 20 Jun 2024 18:52:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14541v1</guid></item><item><title>IRASim: Learning Interactive Real-Robot Action Simulators</title><link>http://arxiv.org/abs/2406.14540v1</link><description>Scalable robot learning in the real world is limited by the cost and safetyissues of real robots. In addition, rolling out robot trajectories in the realworld can be time-consuming and labor-intensive. In this paper, we propose tolearn an interactive real-robot action simulator as an alternative. Weintroduce a novel method, IRASim, which leverages the power of generativemodels to generate extremely realistic videos of a robot arm that executes agiven action trajectory, starting from an initial given frame. To validate theeffectiveness of our method, we create a new benchmark, IRASim Benchmark, basedon three real-robot datasets and perform extensive experiments on thebenchmark. Results show that IRASim outperforms all the baseline methods and ismore preferable in human evaluations. We hope that IRASim can serve as aneffective and scalable approach to enhance robot learning in the real world. Topromote research for generative real-robot action simulators, we open-sourcecode, benchmark, and checkpoints at https: //gen-irasim.github.io.</description><author>Fangqi Zhu, Hongtao Wu, Song Guo, Yuxiao Liu, Chilam Cheang, Tao Kong</author><pubDate>Thu, 20 Jun 2024 18:50:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14540v1</guid></item><item><title>Invertible Consistency Distillation for Text-Guided Image Editing in Around 7 Steps</title><link>http://arxiv.org/abs/2406.14539v1</link><description>Diffusion distillation represents a highly promising direction for achievingfaithful text-to-image generation in a few sampling steps. However, despiterecent successes, existing distilled models still do not provide the fullspectrum of diffusion abilities, such as real image inversion, which enablesmany precise image manipulation methods. This work aims to enrich distilledtext-to-image diffusion models with the ability to effectively encode realimages into their latent space. To this end, we introduce invertibleConsistency Distillation (iCD), a generalized consistency distillationframework that facilitates both high-quality image synthesis and accurate imageencoding in only 3-4 inference steps. Though the inversion problem fortext-to-image diffusion models gets exacerbated by high classifier-freeguidance scales, we notice that dynamic guidance significantly reducesreconstruction errors without noticeable degradation in generation performance.As a result, we demonstrate that iCD equipped with dynamic guidance may serveas a highly effective tool for zero-shot text-guided image editing, competingwith more expensive state-of-the-art alternatives.</description><author>Nikita Starodubcev, Mikhail Khoroshikh, Artem Babenko, Dmitry Baranchuk</author><pubDate>Thu, 20 Jun 2024 18:49:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14539v1</guid></item><item><title>MacroHFT: Memory Augmented Context-aware Reinforcement Learning On High Frequency Trading</title><link>http://arxiv.org/abs/2406.14537v1</link><description>High-frequency trading (HFT) that executes algorithmic trading in short timescales, has recently occupied the majority of cryptocurrency market. Besidestraditional quantitative trading methods, reinforcement learning (RL) hasbecome another appealing approach for HFT due to its terrific ability ofhandling high-dimensional financial data and solving sophisticated sequentialdecision-making problems, \emph{e.g.,} hierarchical reinforcement learning(HRL) has shown its promising performance on second-level HFT by training arouter to select only one sub-agent from the agent pool to execute the currenttransaction. However, existing RL methods for HFT still have some defects: 1)standard RL-based trading agents suffer from the overfitting issue, preventingthem from making effective policy adjustments based on financial context; 2)due to the rapid changes in market conditions, investment decisions made by anindividual agent are usually one-sided and highly biased, which might lead tosignificant loss in extreme markets. To tackle these problems, we propose anovel Memory Augmented Context-aware Reinforcement learning method On HFT,\emph{a.k.a.} MacroHFT, which consists of two training phases: 1) we firsttrain multiple types of sub-agents with the market data decomposed according tovarious financial indicators, specifically market trend and volatility, whereeach agent owns a conditional adapter to adjust its trading policy according tomarket conditions; 2) then we train a hyper-agent to mix the decisions fromthese sub-agents and output a consistently profitable meta-policy to handlerapid market fluctuations, equipped with a memory mechanism to enhance thecapability of decision-making. Extensive experiments on various cryptocurrencymarkets demonstrate that MacroHFT can achieve state-of-the-art performance onminute-level trading tasks.</description><author>Chuqiao Zong, Chaojie Wang, Molei Qin, Lei Feng, Xinrun Wang, Bo An</author><pubDate>Thu, 20 Jun 2024 18:48:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14537v1</guid></item><item><title>Epicardium Prompt-guided Real-time Cardiac Ultrasound Frame-to-volume Registration</title><link>http://arxiv.org/abs/2406.14534v1</link><description>A comprehensive guidance view for cardiac interventional surgery can beprovided by the real-time fusion of the intraoperative 2D images andpreoperative 3D volume based on the ultrasound frame-to-volume registration.However, cardiac ultrasound images are characterized by a low signal-to-noiseratio and small differences between adjacent frames, coupled with significantdimension variations between 2D frames and 3D volumes to be registered,resulting in real-time and accurate cardiac ultrasound frame-to-volumeregistration being a very challenging task. This paper introduces a lightweightend-to-end Cardiac Ultrasound frame-to-volume Registration network, termedCU-Reg. Specifically, the proposed model leverages epicardium prompt-guidedanatomical clues to reinforce the interaction of 2D sparse and 3D densefeatures, followed by a voxel-wise local-global aggregation of enhancedfeatures, thereby boosting the cross-dimensional matching effectiveness oflow-quality ultrasound modalities. We further embed an inter-framediscriminative regularization term within the hybrid supervised learning toincrease the distinction between adjacent slices in the same ultrasound volumeto ensure registration stability. Experimental results on the reprocessed CAMUSdataset demonstrate that our CU-Reg surpasses existing methods in terms ofregistration accuracy and efficiency, meeting the guidance requirements ofclinical cardiac interventional surgery.</description><author>Long Lei, Jun Zhou, Jialun Pei, Baoliang Zhao, Yueming Jin, Yuen-Chun Jeremy Teoh, Jing Qin, Pheng-Ann Heng</author><pubDate>Thu, 20 Jun 2024 18:47:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14534v1</guid></item><item><title>MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection</title><link>http://arxiv.org/abs/2403.19888v3</link><description>Recent advances in deep learning have mainly relied on Transformers due totheir data dependency and ability to learn at scale. The attention module inthese architectures, however, exhibits quadratic time and space in input size,limiting their scalability for long-sequence modeling. State Space Models(SSMs), and more specifically Selective SSMs (S6), with efficienthardware-aware implementation, have shown promising potential for long causalsequence modeling. They, however, use separate blocks for each channel and failto filter irrelevant channels and capture inter-channel dependencies. Naturalattempt to mix information across channels using MLP, attention, or SSMsresults in further instability in the training of SSMs for large networksand/or nearly double the number of parameters. We present the MambaMixer block,a new SSM-based architecture with data-dependent weights that uses a dualselection mechanism across tokens and channels-called Selective Token andChannel Mixer. To mitigate doubling the number of parameters, we present a newnon-causal heuristic of the S6 block with a hardware-friendly implementation.We further present an efficient variant of MambaMixer, called QSMixer, thatmixes information along both sequence and embedding dimensions. As a proof ofconcept, we design Vision MambaMixer (ViM2) and Vision QSMixer (ViQS)architectures. To enhance their ability to capture spatial information inimages, we present Switch of Scans (SoS) that dynamically uses a set of usefulimage scans to traverse image patches. We evaluate the performance of ourmethods in image classification, segmentation, and object detection. Ourresults underline the importance of selectively mixing across both tokens andchannels and show the competitive (resp. superior) performance of our methodswith well-established vision models (resp. SSM-based models).</description><author>Ali Behrouz, Michele Santacatterina, Ramin Zabih</author><pubDate>Thu, 20 Jun 2024 18:46:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.19888v3</guid></item><item><title>RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold</title><link>http://arxiv.org/abs/2406.14532v1</link><description>Training on model-generated synthetic data is a promising approach forfinetuning LLMs, but it remains unclear when it helps or hurts. In this paper,we investigate this question for math reasoning via an empirical study,followed by building a conceptual understanding of our observations. First, wefind that while the typical approach of finetuning a model on synthetic corrector positive problem-solution pairs generated by capable models offers modestperformance gains, sampling more correct solutions from the finetuned learneritself followed by subsequent fine-tuning on this self-generated data$\textbf{doubles}$ the efficiency of the same synthetic problems. At the sametime, training on model-generated positives can amplify various spuriouscorrelations, resulting in flat or even inverse scaling trends as the amount ofdata increases. Surprisingly, we find that several of these issues can beaddressed if we also utilize negative responses, i.e., model-generatedresponses that are deemed incorrect by a final answer verifier. Crucially,these negatives must be constructed such that the training can appropriatelyrecover the utility or advantage of each intermediate step in the negativeresponse. With this per-step scheme, we are able to attain consistent gainsover only positive data, attaining performance similar to amplifying the amountof synthetic data by $\mathbf{8 \times}$. We show that training on per-stepnegatives can help to unlearn spurious correlations in the positive data, andis equivalent to advantage-weighted reinforcement learning (RL), implying thatit inherits robustness benefits of RL over imitating positive data alone.</description><author>Amrith Setlur, Saurabh Garg, Xinyang Geng, Naman Garg, Virginia Smith, Aviral Kumar</author><pubDate>Thu, 20 Jun 2024 18:45:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14532v1</guid></item><item><title>Action2Sound: Ambient-Aware Generation of Action Sounds from Egocentric Videos</title><link>http://arxiv.org/abs/2406.09272v2</link><description>Generating realistic audio for human interactions is important for manyapplications, such as creating sound effects for films or virtual realitygames. Existing approaches implicitly assume total correspondence between thevideo and audio during training, yet many sounds happen off-screen and haveweak to no correspondence with the visuals -- resulting in uncontrolled ambientsounds or hallucinations at test time. We propose a novel ambient-aware audiogeneration model, AV-LDM. We devise a novel audio-conditioning mechanism tolearn to disentangle foreground action sounds from the ambient backgroundsounds in in-the-wild training videos. Given a novel silent video, our modeluses retrieval-augmented generation to create audio that matches the visualcontent both semantically and temporally. We train and evaluate our model ontwo in-the-wild egocentric video datasets Ego4D and EPIC-KITCHENS. Our modeloutperforms an array of existing methods, allows controllable generation of theambient sound, and even shows promise for generalizing to computer graphicsgame clips. Overall, our work is the first to focus video-to-audio generationfaithfully on the observed visual content despite training from uncurated clipswith natural background sounds.</description><author>Changan Chen, Puyuan Peng, Ami Baid, Zihui Xue, Wei-Ning Hsu, David Harwath, Kristen Grauman</author><pubDate>Thu, 20 Jun 2024 18:42:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.09272v2</guid></item><item><title>A Benchmarking Study of Kolmogorov-Arnold Networks on Tabular Data</title><link>http://arxiv.org/abs/2406.14529v1</link><description>Kolmogorov-Arnold Networks (KANs) have very recently been introduced into theworld of machine learning, quickly capturing the attention of the entirecommunity. However, KANs have mostly been tested for approximating complexfunctions or processing synthetic data, while a test on real-world tabulardatasets is currently lacking. In this paper, we present a benchmarking studycomparing KANs and Multi-Layer Perceptrons (MLPs) on tabular datasets. Thestudy evaluates task performance and training times. From the results obtainedon the various datasets, KANs demonstrate superior or comparable accuracy andF1 scores, excelling particularly in datasets with numerous instances,suggesting robust handling of complex data. We also highlight that thisperformance improvement of KANs comes with a higher computational cost whencompared to MLPs of comparable sizes.</description><author>Eleonora Poeta, Flavio Giobergia, Eliana Pastor, Tania Cerquitelli, Elena Baralis</author><pubDate>Thu, 20 Jun 2024 18:41:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14529v1</guid></item><item><title>DeciMamba: Exploring the Length Extrapolation Potential of Mamba</title><link>http://arxiv.org/abs/2406.14528v1</link><description>Long-range sequence processing poses a significant challenge for Transformersdue to their quadratic complexity in input length. A promising alternative isMamba, which demonstrates high performance and achieves Transformer-levelcapabilities while requiring substantially fewer computational resources. Inthis paper we explore the length-generalization capabilities of Mamba, which wefind to be relatively limited. Through a series of visualizations and analyseswe identify that the limitations arise from a restricted effective receptivefield, dictated by the sequence length used during training. To address thisconstraint, we introduce DeciMamba, a context-extension method specificallydesigned for Mamba. This mechanism, built on top of a hidden filteringmechanism embedded within the S6 layer, enables the trained model toextrapolate well even without additional training. Empirical experiments overreal-world long-range NLP tasks show that DeciMamba can extrapolate to contextlengths that are 25x times longer than the ones seen during training, and doesso without utilizing additional computational resources. We will release ourcode and models.</description><author>Assaf Ben-Kish, Itamar Zimerman, Shady Abu-Hussein, Nadav Cohen, Amir Globerson, Lior Wolf, Raja Giryes</author><pubDate>Thu, 20 Jun 2024 18:40:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14528v1</guid></item><item><title>STimage-1K4M: A histopathology image-gene expression dataset for spatial transcriptomics</title><link>http://arxiv.org/abs/2406.06393v2</link><description>Recent advances in multi-modal algorithms have driven and been driven by theincreasing availability of large image-text datasets, leading to significantstrides in various fields, including computational pathology. However, in mostexisting medical image-text datasets, the text typically provides high-levelsummaries that may not sufficiently describe sub-tile regions within a largepathology image. For example, an image might cover an extensive tissue areacontaining cancerous and healthy regions, but the accompanying text might onlyspecify that this image is a cancer slide, lacking the nuanced details neededfor in-depth analysis. In this study, we introduce STimage-1K4M, a noveldataset designed to bridge this gap by providing genomic features for sub-tileimages. STimage-1K4M contains 1,149 images derived from spatial transcriptomicsdata, which captures gene expression information at the level of individualspatial spots within a pathology image. Specifically, each image in the datasetis broken down into smaller sub-image tiles, with each tile paired with15,000-30,000 dimensional gene expressions. With 4,293,195 pairs of sub-tileimages and gene expressions, STimage-1K4M offers unprecedented granularity,paving the way for a wide range of advanced research in multi-modal dataanalysis an innovative applications in computational pathology, and beyond.</description><author>Jiawen Chen, Muqing Zhou, Wenrong Wu, Jinwei Zhang, Yun Li, Didong Li</author><pubDate>Thu, 20 Jun 2024 18:38:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06393v2</guid></item><item><title>Towards evolution of Deep Neural Networks through contrastive Self-Supervised learning</title><link>http://arxiv.org/abs/2406.14525v1</link><description>Deep Neural Networks (DNNs) have been successfully applied to a wide range ofproblems. However, two main limitations are commonly pointed out. The first oneis that they require long time to design. The other is that they heavily relyon labelled data, which can sometimes be costly and hard to obtain. In order toaddress the first problem, neuroevolution has been proved to be a plausibleoption to automate the design of DNNs. As for the second problem,self-supervised learning has been used to leverage unlabelled data to learnrepresentations. Our goal is to study how neuroevolution can helpself-supervised learning to bridge the gap to supervised learning in terms ofperformance. In this work, we propose a framework that is able to evolve deepneural networks using self-supervised learning. Our results on the CIFAR-10dataset show that it is possible to evolve adequate neural networks whilereducing the reliance on labelled data. Moreover, an analysis to the structureof the evolved networks suggests that the amount of labelled data fed to themhas less effect on the structure of networks that learned via self-supervisedlearning, when compared to individuals that relied on supervised learning.</description><author>Adriano Vinhas, João Correia, Penousal Machado</author><pubDate>Thu, 20 Jun 2024 18:38:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14525v1</guid></item><item><title>Fantastic Copyrighted Beasts and How (Not) to Generate Them</title><link>http://arxiv.org/abs/2406.14526v1</link><description>Recent studies show that image and video generation models can be prompted toreproduce copyrighted content from their training data, raising serious legalconcerns around copyright infringement. Copyrighted characters, in particular,pose a difficult challenge for image generation services, with at least onelawsuit already awarding damages based on the generation of these characters.Yet, little research has empirically examined this issue. We conduct asystematic evaluation to fill this gap. First, we build CopyCat, an evaluationsuite consisting of diverse copyrighted characters and a novel evaluationpipeline. Our evaluation considers both the detection of similarity tocopyrighted characters and generated image's consistency with user input. Ourevaluation systematically shows that both image and video generation models canstill generate characters even if characters' names are not explicitlymentioned in the prompt, sometimes with only two generic keywords (e.g.,prompting with "videogame, plumber" consistently generates Nintendo's Mariocharacter). We then introduce techniques to semi-automatically identify suchkeywords or descriptions that trigger character generation. Using ourevaluation suite, we study runtime mitigation strategies, including bothexisting methods and new strategies we propose. Our findings reveal thatcommonly employed strategies, such as prompt rewriting in the DALL-E system,are not sufficient as standalone guardrails. These strategies must be coupledwith other approaches, like negative prompting, to effectively reduce theunintended generation of copyrighted characters. Our work provides empiricalgrounding to the discussion of copyright mitigation strategies and offersactionable insights for model deployers actively implementing them.</description><author>Luxi He, Yangsibo Huang, Weijia Shi, Tinghao Xie, Haotian Liu, Yue Wang, Luke Zettlemoyer, Chiyuan Zhang, Danqi Chen, Peter Henderson</author><pubDate>Thu, 20 Jun 2024 18:38:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14526v1</guid></item><item><title>PostMark: A Robust Blackbox Watermark for Large Language Models</title><link>http://arxiv.org/abs/2406.14517v1</link><description>The most effective techniques to detect LLM-generated text rely on insertinga detectable signature -- or watermark -- during the model's decoding process.Most existing watermarking methods require access to the underlying LLM'slogits, which LLM API providers are loath to share due to fears of modeldistillation. As such, these watermarks must be implemented independently byeach LLM provider. In this paper, we develop PostMark, a modular post-hocwatermarking procedure in which an input-dependent set of words (determined viaa semantic embedding) is inserted into the text after the decoding process hascompleted. Critically, PostMark does not require logit access, which means itcan be implemented by a third party. We also show that PostMark is more robustto paraphrasing attacks than existing watermarking methods: our experimentscover eight baseline algorithms, five base LLMs, and three datasets. Finally,we evaluate the impact of PostMark on text quality using both automated andhuman assessments, highlighting the trade-off between quality and robustness toparaphrasing. We release our code, outputs, and annotations athttps://github.com/lilakk/PostMark.</description><author>Yapei Chang, Kalpesh Krishna, Amir Houmansadr, John Wieting, Mohit Iyyer</author><pubDate>Thu, 20 Jun 2024 18:27:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14517v1</guid></item><item><title>MMBench-Video: A Long-Form Multi-Shot Benchmark for Holistic Video Understanding</title><link>http://arxiv.org/abs/2406.14515v1</link><description>The advent of large vision-language models (LVLMs) has spurred research intotheir applications in multi-modal contexts, particularly in videounderstanding. Traditional VideoQA benchmarks, despite providing quantitativemetrics, often fail to encompass the full spectrum of video content andinadequately assess models' temporal comprehension. To address theselimitations, we introduce MMBench-Video, a quantitative benchmark designed torigorously evaluate LVLMs' proficiency in video understanding. MMBench-Videoincorporates lengthy videos from YouTube and employs free-form questions,mirroring practical use cases. The benchmark is meticulously crafted to probethe models' temporal reasoning skills, with all questions human-annotatedaccording to a carefully constructed ability taxonomy. We employ GPT-4 forautomated assessment, demonstrating superior accuracy and robustness overearlier LLM-based evaluations. Utilizing MMBench-Video, we have conductedcomprehensive evaluations that include both proprietary and open-source LVLMsfor images and videos. MMBench-Video stands as a valuable resource for theresearch community, facilitating improved evaluation of LVLMs and catalyzingprogress in the field of video understanding. The evalutation code ofMMBench-Video will be integrated into VLMEvalKit:https://github.com/open-compass/VLMEvalKit.</description><author>Xinyu Fang, Kangrui Mao, Haodong Duan, Xiangyu Zhao, Yining Li, Dahua Lin, Kai Chen</author><pubDate>Thu, 20 Jun 2024 18:26:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14515v1</guid></item><item><title>Solving a Stackelberg Game on Transportation Networks in a Dynamic Crime Scenario: A Mixed Approach on Multi-Layer Networks</title><link>http://arxiv.org/abs/2406.14514v1</link><description>Interdicting a criminal with limited police resources is a challenging taskas the criminal changes location over time. The size of the largetransportation network further adds to the difficulty of this scenario. Totackle this issue, we consider the concept of a layered graph. At each timestamp, we create a copy of the entire transportation network to track thepossible movements of both players, the attacker and the defenders. We considera Stackelberg game in a dynamic crime scenario where the attacker changeslocation over time while the defenders attempt to interdict the attacker on hisescape route. Given a set of defender strategies, the optimal attacker strategyis determined by applying Dijkstra's algorithm on the layered networks. Here,the attacker aims to minimize while the defenders aim to maximize theprobability of interdiction. We develop an approximation algorithm on thelayered networks to find near-optimal strategy for defenders. The efficacy ofthe developed approach is compared with the adopted MILP approach. We comparethe results in terms of computational time and solution quality. The quality ofthe results demonstrates the need for the developed approach, as it effectivelysolves the complex problem within a short amount of time.</description><author>Sukanya Samanta, Kei Kimura, Makoto Yokoo</author><pubDate>Thu, 20 Jun 2024 18:24:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14514v1</guid></item><item><title>Investigating Mysteries of CoT-Augmented Distillation</title><link>http://arxiv.org/abs/2406.14511v1</link><description>Eliciting "chain of thought" (CoT) rationales -- sequences of token thatconvey a "reasoning" process -- has been shown to consistently improve LLMperformance on tasks like question answering. More recent efforts have shownthat such rationales can also be used for model distillation: Including CoTsequences (elicited from a large "teacher" model) in addition to target labelswhen fine-tuning a small student model yields (often substantial) improvements.In this work we ask: Why and how does this additional training signal help inmodel distillation? We perform ablations to interrogate this, and report somepotentially surprising results. Specifically: (1) Placing CoT sequences afterlabels (rather than before) realizes consistently better downstream performance-- this means that no student "reasoning" is necessary at test time to realizegains. (2) When rationales are appended in this way, they need not be coherentreasoning sequences to yield improvements; performance increases are robust topermutations of CoT tokens, for example. In fact, (3) a small number of keytokens are sufficient to achieve improvements equivalent to those observed whenfull rationales are used in model distillation.</description><author>Somin Wadhwa, Silvio Amir, Byron C. Wallace</author><pubDate>Thu, 20 Jun 2024 18:15:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14511v1</guid></item><item><title>V-LASIK: Consistent Glasses-Removal from Videos Using Synthetic Data</title><link>http://arxiv.org/abs/2406.14510v1</link><description>Diffusion-based generative models have recently shown remarkable image andvideo editing capabilities. However, local video editing, particularly removalof small attributes like glasses, remains a challenge. Existing methods eitheralter the videos excessively, generate unrealistic artifacts, or fail toperform the requested edit consistently throughout the video. In this work, wefocus on consistent and identity-preserving removal of glasses in videos, usingit as a case study for consistent local attribute removal in videos. Due to thelack of paired data, we adopt a weakly supervised approach and generatesynthetic imperfect data, using an adjusted pretrained diffusion model. We showthat despite data imperfection, by learning from our generated data andleveraging the prior of pretrained diffusion models, our model is able toperform the desired edit consistently while preserving the original videocontent. Furthermore, we exemplify the generalization ability of our method toother local video editing tasks by applying it successfully to facialsticker-removal. Our approach demonstrates significant improvement overexisting methods, showcasing the potential of leveraging synthetic data andstrong video priors for local video editing tasks.</description><author>Rotem Shalev-Arkushin, Aharon Azulay, Tavi Halperin, Eitan Richardson, Amit H. Bermano, Ohad Fried</author><pubDate>Thu, 20 Jun 2024 18:14:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14510v1</guid></item><item><title>Evidence of a log scaling law for political persuasion with large language models</title><link>http://arxiv.org/abs/2406.14508v1</link><description>Large language models can now generate political messages as persuasive asthose written by humans, raising concerns about how far this persuasiveness maycontinue to increase with model size. Here, we generate 720 persuasive messageson 10 U.S. political issues from 24 language models spanning several orders ofmagnitude in size. We then deploy these messages in a large-scale randomizedsurvey experiment (N = 25,982) to estimate the persuasive capability of eachmodel. Our findings are twofold. First, we find evidence of a log scaling law:model persuasiveness is characterized by sharply diminishing returns, such thatcurrent frontier models are barely more persuasive than models smaller in sizeby an order of magnitude or more. Second, mere task completion (coherence,staying on topic) appears to account for larger models' persuasive advantage.These findings suggest that further scaling model size will not much increasethe persuasiveness of static LLM-generated messages.</description><author>Kobi Hackenburg, Ben M. Tappin, Paul Röttger, Scott Hale, Jonathan Bright, Helen Margetts</author><pubDate>Thu, 20 Jun 2024 18:12:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14508v1</guid></item><item><title>On Newton's Method to Unlearn Neural Networks</title><link>http://arxiv.org/abs/2406.14507v1</link><description>Machine unlearning facilitates personal data ownership, including the ``rightto be forgotten''. The proliferation of applications of \emph{neural networks}(NNs) trained on users' personal data calls for the need to develop algorithmsto unlearn an NN. Since retraining is costly, efficiency is often achievedthrough approximate unlearning which aims to unlearn a trained NN to be closeto the retrained one (in distribution). Though the Newton's method has beenused by previous works to approximately unlearn linear models, adapting it forunlearning an NN often encounters degenerate Hessians that make computing theNewton's update impossible. In this paper, we will first show that when coupledwith naive yet often effective solutions to mitigate the degeneracy issue forunlearning, the Newton's method surprisingly suffers from catastrophicforgetting. To overcome this difficulty, we revise the Newton's method toinclude a theoretically justified regularizer and propose a cubic-regularizedNewton's method for unlearning an NN. The cubic regularizer comes with thebenefits of not requiring manual finetuning and affording a naturalinterpretation. Empirical evaluation on several models and real-world datasetsshows that our method is more resilient to catastrophic forgetting and performsbetter than the baselines, especially in sequential unlearning.</description><author>Nhung Bui, Xinyang Lu, See-Kiong Ng, Bryan Kian Hsian Low</author><pubDate>Thu, 20 Jun 2024 18:12:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14507v1</guid></item><item><title>Translating Across Cultures: LLMs for Intralingual Cultural Adaptation</title><link>http://arxiv.org/abs/2406.14504v1</link><description>LLMs are increasingly being deployed for multilingual applications and havedemonstrated impressive translation capabilities between several low and highresource languages. An aspect of translation that often gets overlooked is thatof cultural adaptation, or modifying source culture references to suit thetarget culture. Cultural adaptation has applications across several creativeindustries and requires intimate knowledge of source and target cultures duringtranslation. While specialized translation models still outperform LLMs on themachine translation task when viewed from the lens of correctness, they are notsensitive to cultural differences often requiring manual correction. LLMs onthe other hand have a rich reservoir of cultural knowledge embedded within itsparameters that can be potentially exploited for such applications. In thispaper we define the task of cultural adaptation and create an evaluationframework to benchmark different models for this task. We evaluate theperformance of modern LLMs for cultural adaptation and analyze their crosscultural knowledge while connecting related concepts across different cultures.We also analyze possible issues with automatic adaptation including culturalbiases and stereotypes. We hope that this task will offer more insight into thecultural understanding of LLMs and their creativity in cross-culturalscenarios.</description><author>Pushpdeep Singh, Mayur Patidar, Lovekesh Vig</author><pubDate>Thu, 20 Jun 2024 18:06:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14504v1</guid></item><item><title>Overview of the CAIL 2023 Argument Mining Track</title><link>http://arxiv.org/abs/2406.14503v1</link><description>We give a detailed overview of the CAIL 2023 Argument Mining Track, one ofthe Chinese AI and Law Challenge (CAIL) 2023 tracks. The main goal of the trackis to identify and extract interacting argument pairs in trial dialogs. Itmainly uses summarized judgment documents but can also refer to trialrecordings. The track consists of two stages, and we introduce the tasksdesigned for each stage; we also extend the data from previous events into anew dataset -- CAIL2023-ArgMine -- with annotated new cases from various causesof action. We outline several submissions that achieve the best results,including their methods for different stages. While all submissions rely onlanguage models, they have incorporated strategies that may benefit future workin this field.</description><author>Jingcong Liang, Junlong Wang, Xinyu Zhai, Yungui Zhuang, Yiyang Zheng, Xin Xu, Xiandong Ran, Xiaozheng Dong, Honghui Rong, Yanlun Liu, Hao Chen, Yuhan Wei, Donghai Li, Jiajie Peng, Xuanjing Huang, Chongde Shi, Yansong Feng, Yun Song, Zhongyu Wei</author><pubDate>Thu, 20 Jun 2024 18:06:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14503v1</guid></item><item><title>Improving Expert Radiology Report Summarization by Prompting Large Language Models with a Layperson Summary</title><link>http://arxiv.org/abs/2406.14500v1</link><description>Radiology report summarization (RRS) is crucial for patient care, requiringconcise "Impressions" from detailed "Findings." This paper introduces a novelprompting strategy to enhance RRS by first generating a layperson summary. Thisapproach normalizes key observations and simplifies complex information usingnon-expert communication techniques inspired by doctor-patient interactions.Combined with few-shot in-context learning, this method improves the model'sability to link general terms to specific findings. We evaluate this approachon the MIMIC-CXR, CheXpert, and MIMIC-III datasets, benchmarking it against7B/8B parameter state-of-the-art open-source large language models (LLMs) likeMeta-Llama-3-8B-Instruct. Our results demonstrate improvements in summarizationaccuracy and accessibility, particularly in out-of-domain tests, withimprovements as high as 5% for some metrics.</description><author>Xingmeng Zhao, Tongnian Wang, Anthony Rios</author><pubDate>Thu, 20 Jun 2024 18:01:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14500v1</guid></item><item><title>LLaSA: Large Multimodal Agent for Human Activity Analysis Through Wearable Sensors</title><link>http://arxiv.org/abs/2406.14498v1</link><description>Integrating inertial measurement units (IMUs) with large language models(LLMs) advances multimodal AI by enhancing human activity understanding. Weintroduce SensorCaps, a dataset of 26,288 IMU-derived activity narrations, andOpenSQA, an instruction-following dataset with 257,562 question-answer pairs.Combining LIMU-BERT and Llama, we develop LLaSA, a Large Multimodal Agentcapable of interpreting and responding to activity and motion analysis queries.Our evaluation demonstrates LLaSA's effectiveness in activity classificationand question answering, highlighting its potential in healthcare, sportsscience, and human-computer interaction. These contributions advancesensor-aware language models and open new research avenues. Our code repositoryand datasets can be found on https://github.com/BASHLab/LLaSA.</description><author>Sheikh Asif Imran, Mohammad Nur Hossain Khan, Subrata Biswas, Bashima Islam</author><pubDate>Thu, 20 Jun 2024 18:00:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14498v1</guid></item><item><title>CodeRAG-Bench: Can Retrieval Augment Code Generation?</title><link>http://arxiv.org/abs/2406.14497v1</link><description>While language models (LMs) have proven remarkably adept at generating code,many programs are challenging for LMs to generate using their parametricknowledge alone. Providing external contexts such as library documentation canfacilitate generating accurate and functional code. Despite the success ofretrieval-augmented generation (RAG) in various text-oriented tasks, itspotential for improving code generation remains under-explored. In this work,we conduct a systematic, large-scale analysis by asking: in what scenarios canretrieval benefit code generation models? and what challenges remain? We firstcurate a comprehensive evaluation benchmark, CodeRAG-Bench, encompassing threecategories of code generation tasks, including basic programming, open-domain,and repository-level problems. We aggregate documents from five sources formodels to retrieve contexts: competition solutions, online tutorials, librarydocumentation, StackOverflow posts, and GitHub repositories. We examinetop-performing models on CodeRAG-Bench by providing contexts retrieved from oneor multiple sources. While notable gains are made in final code generation byretrieving high-quality contexts across various settings, our analysis revealsroom for improvement -- current retrievers still struggle to fetch usefulcontexts especially with limited lexical overlap, and generators fail toimprove with limited context lengths or abilities to integrate additionalcontexts. We hope CodeRAG-Bench serves as an effective testbed to encouragefurther development of advanced code-oriented RAG methods.</description><author>Zora Zhiruo Wang, Akari Asai, Xinyan Velocity Yu, Frank F. Xu, Yiqing Xie, Graham Neubig, Daniel Fried</author><pubDate>Thu, 20 Jun 2024 17:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14497v1</guid></item><item><title>African or European Swallow? Benchmarking Large Vision-Language Models for Fine-Grained Object Classification</title><link>http://arxiv.org/abs/2406.14496v1</link><description>Recent Large Vision-Language Models (LVLMs) demonstrate impressive abilitieson numerous image understanding and reasoning tasks. The task of fine-grainedobject classification (e.g., distinction between \textit{animal species}),however, has been probed insufficiently, despite its downstream importance. Wefill this evaluation gap by creating \texttt{FOCI} (\textbf{F}ine-grained\textbf{O}bject \textbf{C}lass\textbf{I}fication), a difficult multiple-choicebenchmark for fine-grained object classification, from existing objectclassification datasets: (1) multiple-choice avoids ambiguous answersassociated with casting classification as open-ended QA task; (2) we retainclassification difficulty by mining negative labels with a CLIP model.\texttt{FOCI}\xspace complements five popular classification datasets with fourdomain-specific subsets from ImageNet-21k. We benchmark 12 public LVLMs on\texttt{FOCI} and show that it tests for a \textit{complementary skill} toestablished image understanding and reasoning benchmarks. Crucially, CLIPmodels exhibit dramatically better performance than LVLMs. Since the imageencoders of LVLMs come from these CLIP models, this points to inadequatealignment for fine-grained object distinction between the encoder and the LLMand warrants (pre)training data with more fine-grained annotation. We releaseour code at \url{https://github.com/gregor-ge/FOCI-Benchmark}.</description><author>Gregor Geigle, Radu Timofte, Goran Glavaš</author><pubDate>Thu, 20 Jun 2024 17:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14496v1</guid></item><item><title>rKAN: Rational Kolmogorov-Arnold Networks</title><link>http://arxiv.org/abs/2406.14495v1</link><description>The development of Kolmogorov-Arnold networks (KANs) marks a significantshift from traditional multi-layer perceptrons in deep learning. Initially,KANs employed B-spline curves as their primary basis function, but theirinherent complexity posed implementation challenges. Consequently, researchershave explored alternative basis functions such as Wavelets, Polynomials, andFractional functions. In this research, we explore the use of rationalfunctions as a novel basis function for KANs. We propose two differentapproaches based on Pade approximation and rational Jacobi functions astrainable basis functions, establishing the rational KAN (rKAN). We thenevaluate rKAN's performance in various deep learning and physics-informed tasksto demonstrate its practicality and effectiveness in function approximation.</description><author>Alireza Afzal Aghaei</author><pubDate>Thu, 20 Jun 2024 17:59:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14495v1</guid></item><item><title>[Experiments &amp; Analysis] Evaluating the Feasibility of Sampling-Based Techniques for Training Multilayer Perceptrons</title><link>http://arxiv.org/abs/2306.09293v2</link><description>The training process of neural networks is known to be time-consuming, andhaving a deep architecture only aggravates the issue. This process consistsmostly of matrix operations, among which matrix multiplication is thebottleneck. Several sampling-based techniques have been proposed for speedingup the training time of deep neural networks by approximating the matrixproducts. These techniques fall under two categories: (i) sampling a subset ofnodes in every hidden layer as active at every iteration and (ii) sampling asubset of nodes from the previous layer to approximate the current layer'sactivations using the edges from the sampled nodes. In both cases, the matrixproducts are computed using only the selected samples. In this paper, weevaluate the feasibility of these approaches on CPU machines with limitedcomputational resources. Making a connection between the two researchdirections as special cases of approximating matrix multiplications in thecontext of neural networks, we provide a negative theoretical analysis thatshows feedforward approximation is an obstacle against scalability. We conductcomprehensive experimental evaluations that demonstrate the most pressingchallenges and limitations associated with the studied approaches. We observethat the hashing-based node selection method is not scalable to a large numberof layers, confirming our theoretical analysis. Finally, we identify directionsfor future research.</description><author>Sana Ebrahimi, Rishi Advani, Abolfazl Asudeh</author><pubDate>Thu, 20 Jun 2024 17:57:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09293v2</guid></item><item><title>Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?</title><link>http://arxiv.org/abs/2406.14492v1</link><description>Large vision-language models (LVLMs) have recently dramatically pushed thestate of the art in image captioning and many image understanding tasks (e.g.,visual question answering). LVLMs, however, often \textit{hallucinate} andproduce captions that mention concepts that cannot be found in the image. Thesehallucinations erode the trustworthiness of LVLMs and are arguably among themain obstacles to their ubiquitous adoption. Recent work suggests that additionof grounding objectives -- those that explicitly align image regions or objectsto text spans -- reduces the amount of LVLM hallucination. Although intuitive,this claim is not empirically justified as the reduction effects have beenestablished, we argue, with flawed evaluation protocols that (i) rely on data(i.e., MSCOCO) that has been extensively used in LVLM training and (ii) measurehallucination via question answering rather than open-ended caption generation.In this work, in contrast, we offer the first systematic analysis of the effectof fine-grained object grounding on LVLM hallucination under an evaluationprotocol that more realistically captures LVLM hallucination in opengeneration. Our extensive experiments over three backbone LLMs reveal thatgrounding objectives have little to no effect on object hallucination in opencaption generation.</description><author>Gregor Geigle, Radu Timofte, Goran Glavaš</author><pubDate>Thu, 20 Jun 2024 17:56:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14492v1</guid></item><item><title>Instruction Pre-Training: Language Models are Supervised Multitask Learners</title><link>http://arxiv.org/abs/2406.14491v1</link><description>Unsupervised multitask pre-training has been the critical method behind therecent success of language models (LMs). However, supervised multitask learningstill holds significant promise, as scaling it in the post-training stagetrends towards better generalization. In this paper, we explore supervisedmultitask pre-training by proposing Instruction Pre-Training, a framework thatscalably augments massive raw corpora with instruction-response pairs topre-train LMs. The instruction-response pairs are generated by an efficientinstruction synthesizer built on open-source models. In our experiments, wesynthesize 200M instruction-response pairs covering 40+ task categories toverify the effectiveness of Instruction Pre-Training. In pre-training fromscratch, Instruction Pre-Training not only consistently enhances pre-trainedbase models but also benefits more from further instruction tuning. Incontinual pre-training, Instruction Pre-Training enables Llama3-8B to becomparable to or even outperform Llama3-70B. Our model, code, and data areavailable at https://github.com/microsoft/LMOps.</description><author>Daixuan Cheng, Yuxian Gu, Shaohan Huang, Junyu Bi, Minlie Huang, Furu Wei</author><pubDate>Thu, 20 Jun 2024 17:55:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14491v1</guid></item><item><title>Proceedings of The second international workshop on eXplainable AI for the Arts (XAIxArts)</title><link>http://arxiv.org/abs/2406.14485v1</link><description>This second international workshop on explainable AI for the Arts (XAIxArts)brought together a community of researchers in HCI, Interaction Design, AI,explainable AI (XAI), and digital arts to explore the role of XAI for the Arts.Workshop held at the 16th ACM Conference on Creativity and Cognition (C&amp;C2024), Chicago, USA.</description><author>Nick Bryan-Kinns, Corey Ford, Shuoyang Zheng, Helen Kennedy, Alan Chamberlain, Makayla Lewis, Drew Hemment, Zijin Li, Qiong Wu, Lanxi Xiao, Gus Xia, Jeba Rezwana, Michael Clemens, Gabriel Vigliensoni</author><pubDate>Thu, 20 Jun 2024 17:48:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14485v1</guid></item><item><title>Contextual Continuum Bandits: Static Versus Dynamic Regret</title><link>http://arxiv.org/abs/2406.05714v2</link><description>We study the contextual continuum bandits problem, where the learnersequentially receives a side information vector and has to choose an action ina convex set, minimizing a function associated to the context. The goal is tominimize all the underlying functions for the received contexts, leading to adynamic (contextual) notion of regret, which is stronger than the standardstatic regret. Assuming that the objective functions are H\"older with respectto the contexts, we demonstrate that any algorithm achieving a sub-linearstatic regret can be extended to achieve a sub-linear dynamic regret. Wefurther study the case of strongly convex and smooth functions when theobservations are noisy. Inspired by the interior point method and employingself-concordant barriers, we propose an algorithm achieving a sub-lineardynamic regret. Lastly, we present a minimax lower bound, implying two keyfacts. First, no algorithm can achieve sub-linear dynamic regret over functionsthat are not continuous with respect to the context. Second, for stronglyconvex and smooth functions, the algorithm that we propose achieves, up to alogarithmic factor, the minimax optimal rate of dynamic regret as a function ofthe number of queries.</description><author>Arya Akhavan, Karim Lounici, Massimiliano Pontil, Alexandre B. Tsybakov</author><pubDate>Thu, 20 Jun 2024 17:47:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05714v2</guid></item><item><title>Valid Error Bars for Neural Weather Models using Conformal Prediction</title><link>http://arxiv.org/abs/2406.14483v1</link><description>Neural weather models have shown immense potential as inexpensive andaccurate alternatives to physics-based models. However, most models trained toperform weather forecasting do not quantify the uncertainty associated withtheir forecasts. This limits the trust in the model and the usefulness of theforecasts. In this work we construct and formalise a conformal predictionframework as a post-processing method for estimating this uncertainty. Themethod is model-agnostic and gives calibrated error bounds for all variables,lead times and spatial locations. No modifications are required to the modeland the computational cost is negligible compared to model training. Wedemonstrate the usefulness of the conformal prediction framework on a limitedarea neural weather model for the Nordic region. We further explore theadvantages of the framework for deterministic and probabilistic models.</description><author>Vignesh Gopakumar, Joel Oskarrson, Ander Gray, Lorenzo Zanisi, Stanislas Pamela, Daniel Giles, Matt Kusner, Marc Deisenroth</author><pubDate>Thu, 20 Jun 2024 17:45:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14483v1</guid></item><item><title>Visible-Thermal Tiny Object Detection: A Benchmark Dataset and Baselines</title><link>http://arxiv.org/abs/2406.14482v1</link><description>Small object detection (SOD) has been a longstanding yet challenging task fordecades, with numerous datasets and algorithms being developed. However, theymainly focus on either visible or thermal modality, while visible-thermal(RGBT) bimodality is rarely explored. Although some RGBT datasets have beendeveloped recently, the insufficient quantity, limited category, misalignedimages and large target size cannot provide an impartial benchmark to evaluatemulti-category visible-thermal small object detection (RGBT SOD) algorithms. Inthis paper, we build the first large-scale benchmark with high diversity forRGBT SOD (namely RGBT-Tiny), including 115 paired sequences, 93K frames and1.2M manual annotations. RGBT-Tiny contains abundant targets (7 categories) andhigh-diversity scenes (8 types that cover different illumination and densityvariations). Note that, over 81% of targets are smaller than 16x16, and weprovide paired bounding box annotations with tracking ID to offer an extremelychallenging benchmark with wide-range applications, such as RGBT fusion,detection and tracking. In addition, we propose a scale adaptive fitness(SAFit) measure that exhibits high robustness on both small and large targets.The proposed SAFit can provide reasonable performance evaluation and promotedetection performance. Based on the proposed RGBT-Tiny dataset and SAFitmeasure, extensive evaluations have been conducted, including 23 recentstate-of-the-art algorithms that cover four different types (i.e., visiblegeneric detection, visible SOD, thermal SOD and RGBT object detection). Projectis available at https://github.com/XinyiYing24/RGBT-Tiny.</description><author>Xinyi Ying, Chao Xiao, Ruojing Li, Xu He, Boyang Li, Zhaoxu Li, Yingqian Wang, Mingyuan Hu, Qingyu Xu, Zaiping Lin, Miao Li, Shilin Zhou, Wei An, Weidong Sheng, Li Liu</author><pubDate>Thu, 20 Jun 2024 17:43:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14482v1</guid></item><item><title>Revealing Vision-Language Integration in the Brain with Multimodal Networks</title><link>http://arxiv.org/abs/2406.14481v1</link><description>We use (multi)modal deep neural networks (DNNs) to probe for sites ofmultimodal integration in the human brain by predicting stereoencephalography(SEEG) recordings taken while human subjects watched movies. We operationalizesites of multimodal integration as regions where a multimodal vision-languagemodel predicts recordings better than unimodal language, unimodal vision, orlinearly-integrated language-vision models. Our target DNN models spandifferent architectures (e.g., convolutional networks and transformers) andmultimodal training techniques (e.g., cross-attention and contrastivelearning). As a key enabling step, we first demonstrate that trained vision andlanguage models systematically outperform their randomly initializedcounterparts in their ability to predict SEEG signals. We then compare unimodaland multimodal models against one another. Because our target DNN models oftenhave different architectures, number of parameters, and training sets (possiblyobscuring those differences attributable to integration), we carry out acontrolled comparison of two models (SLIP and SimCLR), which keep all of theseattributes the same aside from input modality. Using this approach, we identifya sizable number of neural sites (on average 141 out of 1090 total sites or12.94%) and brain regions where multimodal integration seems to occur.Additionally, we find that among the variants of multimodal training techniqueswe assess, CLIP-style training is the best suited for downstream prediction ofthe neural activity in these sites.</description><author>Vighnesh Subramaniam, Colin Conwell, Christopher Wang, Gabriel Kreiman, Boris Katz, Ignacio Cases, Andrei Barbu</author><pubDate>Thu, 20 Jun 2024 17:43:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14481v1</guid></item><item><title>On Layer-wise Representation Similarity: Application for Multi-Exit Models with a Single Classifier</title><link>http://arxiv.org/abs/2406.14479v1</link><description>Analyzing the similarity of internal representations within and acrossdifferent models has been an important technique for understanding the behaviorof deep neural networks. Most existing methods for analyzing the similaritybetween representations of high dimensions, such as those based on CanonicalCorrelation Analysis (CCA) and widely used Centered Kernel Alignment (CKA),rely on statistical properties of the representations for a set of data points.In this paper, we focus on transformer models and study the similarity ofrepresentations between the hidden layers of individual transformers. In thiscontext, we show that a simple sample-wise cosine similarity metric is capableof capturing the similarity and aligns with the complicated CKA. Ourexperimental results on common transformers reveal that representations acrosslayers are positively correlated, albeit the similarity decreases when layersare far apart. We then propose an aligned training approach to enhance thesimilarity between internal representations, with trained models that enjoy thefollowing properties: (1) the last-layer classifier can be directly appliedright after any hidden layers, yielding intermediate layer accuracies muchhigher than those under standard training, (2) the layer-wise accuraciesmonotonically increase and reveal the minimal depth needed for the given task,(3) when served as multi-exit models, they achieve on-par performance withstandard multi-exit architectures which consist of additional classifiersdesigned for early exiting in shallow layers. To our knowledge, our work is thefirst to show that one common classifier is sufficient for multi-exit models.We conduct experiments on both vision and NLP tasks to demonstrate theperformance of the proposed aligned training.</description><author>Jiachen Jiang, Jinxin Zhou, Zhihui Zhu</author><pubDate>Thu, 20 Jun 2024 17:41:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14479v1</guid></item><item><title>Toward data-driven research: preliminary study to predict surface roughness in material extrusion using previously published data with Machine Learning</title><link>http://arxiv.org/abs/2406.14478v1</link><description>Material extrusion is one of the most commonly used approaches within theadditive manufacturing processes available. Despite its popularity and relatedtechnical advancements, process reliability and quality assurance remain onlypartially solved. In particular, the surface roughness caused by this processis a key concern. To solve this constraint, experimental plans have beenexploited to optimize surface roughness in recent years. However, the latterempirical trial and error process is extremely time- and resource-consuming.Thus, this study aims to avoid using large experimental programs to optimizesurface roughness in material extrusion. Methodology. This research provides an in-depth analysis of the effect ofseveral printing parameters: layer height, printing temperature, printing speedand wall thickness. The proposed data-driven predictive modeling approach takesadvantage of Machine Learning models to automatically predict surface roughnessbased on the data gathered from the literature and the experimental datagenerated for testing. Findings. Using 10-fold cross-validation of data gathered from theliterature, the proposed Machine Learning solution attains a 0.93 correlationwith a mean absolute percentage error of 13 %. When testing with our own data,the correlation diminishes to 0.79 and the mean absolute percentage errorreduces to 8 %. Thus, the solution for predicting surface roughness inextrusion-based printing offers competitive results regarding the variabilityof the analyzed factors. Originality. As available manufacturing data continue to increase on a dailybasis, the ability to learn from these large volumes of data is critical infuture manufacturing and science. Specifically, the power of Machine Learninghelps model surface roughness with limited experimental tests.</description><author>Fátima García-Martínez, Diego Carou, Francisco de Arriba-Pérez, Silvia García-Méndez</author><pubDate>Thu, 20 Jun 2024 17:40:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14478v1</guid></item><item><title>SafeSora: Towards Safety Alignment of Text2Video Generation via a Human Preference Dataset</title><link>http://arxiv.org/abs/2406.14477v1</link><description>To mitigate the risk of harmful outputs from large vision models (LVMs), weintroduce the SafeSora dataset to promote research on aligning text-to-videogeneration with human values. This dataset encompasses human preferences intext-to-video generation tasks along two primary dimensions: helpfulness andharmlessness. To capture in-depth human preferences and facilitate structuredreasoning by crowdworkers, we subdivide helpfulness into 4 sub-dimensions andharmlessness into 12 sub-categories, serving as the basis for pilotannotations. The SafeSora dataset includes 14,711 unique prompts, 57,333 uniquevideos generated by 4 distinct LVMs, and 51,691 pairs of preference annotationslabeled by humans. We further demonstrate the utility of the SafeSora datasetthrough several applications, including training the text-video moderationmodel and aligning LVMs with human preference by fine-tuning a promptaugmentation module or the diffusion model. These applications highlight itspotential as the foundation for text-to-video alignment research, such as humanpreference modeling and the development and validation of alignment algorithms.</description><author>Josef Dai, Tianle Chen, Xuyao Wang, Ziran Yang, Taiye Chen, Jiaming Ji, Yaodong Yang</author><pubDate>Thu, 20 Jun 2024 17:38:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14477v1</guid></item><item><title>Learning telic-controllable state representations</title><link>http://arxiv.org/abs/2406.14476v1</link><description>Computational accounts of purposeful behavior consist of descriptive andnormative aspects. The former enable agents to ascertain the current (orfuture) state of affairs in the world and the latter to evaluate thedesirability, or lack thereof, of these states with respect to the agent'sgoals. In Reinforcement Learning, the normative aspect (reward and valuefunctions) is assumed to depend on a pre-defined and fixed descriptive one(state representation). Alternatively, these two aspects may emergeinterdependently: goals can be, and indeed often are, expressed in terms ofstate representation features, but they may also serve to shape staterepresentations themselves. Here, we illustrate a novel theoretical framing ofstate representation learning in bounded agents, coupling descriptive andnormative aspects via the notion of goal-directed, or telic, states. We definea new controllability property of telic state representations to characterizethe tradeoff between their granularity and the policy complexity capacityrequired to reach all telic states. We propose an algorithm for learningcontrollable state representations and demonstrate it using a simple navigationtask with changing goals. Our framework highlights the crucial role ofdeliberate ignorance - knowing what to ignore - for learning staterepresentations that are both goal-flexible and simple. More broadly, our workprovides a concrete step towards a unified theoretical view of natural andartificial learning through the lens of goals.</description><author>Nadav Amir, Stas Tiomkin, Angela Langdon</author><pubDate>Thu, 20 Jun 2024 17:38:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14476v1</guid></item><item><title>Data-Centric AI in the Age of Large Language Models</title><link>http://arxiv.org/abs/2406.14473v1</link><description>This position paper proposes a data-centric viewpoint of AI research,focusing on large language models (LLMs). We start by making the keyobservation that data is instrumental in the developmental (e.g., pretrainingand fine-tuning) and inferential stages (e.g., in-context learning) of LLMs,and yet it receives disproportionally low attention from the researchcommunity. We identify four specific scenarios centered around data, coveringdata-centric benchmarks and data curation, data attribution, knowledgetransfer, and inference contextualization. In each scenario, we underscore theimportance of data, highlight promising research directions, and articulate thepotential impacts on the research community and, where applicable, the societyas a whole. For instance, we advocate for a suite of data-centric benchmarkstailored to the scale and complexity of data for LLMs. These benchmarks can beused to develop new data curation methods and document research efforts andresults, which can help promote openness and transparency in AI and LLMresearch.</description><author>Xinyi Xu, Zhaoxuan Wu, Rui Qiao, Arun Verma, Yao Shu, Jingtan Wang, Xinyuan Niu, Zhenfeng He, Jiangwei Chen, Zijian Zhou, Gregory Kang Ruey Lau, Hieu Dao, Lucas Agussurja, Rachael Hwee Ling Sim, Xiaoqiang Lin, Wenyang Hu, Zhongxiang Dai, Pang Wei Koh, Bryan Kian Hsiang Low</author><pubDate>Thu, 20 Jun 2024 17:34:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14473v1</guid></item><item><title>Self-supervised Multi-actor Social Activity Understanding in Streaming Videos</title><link>http://arxiv.org/abs/2406.14472v1</link><description>This work addresses the problem of Social Activity Recognition (SAR), acritical component in real-world tasks like surveillance and assistiverobotics. Unlike traditional event understanding approaches, SAR necessitatesmodeling individual actors' appearance and motions and contextualizing themwithin their social interactions. Traditional action localization methods fallshort due to their single-actor, single-action assumption. Previous SARresearch has relied heavily on densely annotated data, but privacy concernslimit their applicability in real-world settings. In this work, we propose aself-supervised approach based on multi-actor predictive learning for SAR instreaming videos. Using a visual-semantic graph structure, we model socialinteractions, enabling relational reasoning for robust performance with minimallabeled data. The proposed framework achieves competitive performance onstandard group activity recognition benchmarks. Evaluation on three publiclyavailable action localization benchmarks demonstrates its generalizability toarbitrary action localization.</description><author>Shubham Trehan, Sathyanarayanan N. Aakur</author><pubDate>Thu, 20 Jun 2024 17:33:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14472v1</guid></item><item><title>Fusion of Movement and Naive Predictions for Point Forecasting in Univariate Random Walks</title><link>http://arxiv.org/abs/2406.14469v1</link><description>Traditional methods for point forecasting in univariate random walks oftenfail to surpass naive benchmarks due to data unpredictability. This studyintroduces a novel forecasting method that fuses movement prediction (binaryclassification) with naive forecasts for accurate one-step-ahead pointforecasting. The method's efficacy is demonstrated through theoreticalanalysis, simulations, and real-world data experiments. It reliably exceedsnaive forecasts with movement prediction accuracies as low as 0.55,outperforming baseline models like ARIMA, linear regression, MLP, and LSTMnetworks in forecasting the S\&amp;P 500 index and Bitcoin prices. This method isparticularly advantageous when accurate point predictions are challenging butaccurate movement predictions are attainable, translating movement predictionsinto point forecasts in random walk contexts.</description><author>Cheng Zhang</author><pubDate>Thu, 20 Jun 2024 17:32:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14469v1</guid></item><item><title>A Review of Common Online Speaker Diarization Methods</title><link>http://arxiv.org/abs/2406.14464v1</link><description>Speaker diarization provides the answer to the question "who spoke when?" foran audio file. This information can be used to complete audio transcripts forfurther processing steps. Most speaker diarization systems assume that theaudio file is available as a whole. However, there are scenarios in which thespeaker labels are needed immediately after the arrival of an audio segment.Speaker diarization with a correspondingly low latency is referred to as onlinespeaker diarization. This paper provides an overview. First the history ofonline speaker diarization is briefly presented. Next a taxonomy and datasetsfor training and evaluation are given. In the sections that follow, onlinediarization methods and systems are discussed in detail. This paper concludeswith the presentation of challenges that still need to be solved by futureresearch in the field of online speaker diarization.</description><author>Roman Aperdannier, Sigurd Schacht, Alexander Piazza</author><pubDate>Thu, 20 Jun 2024 17:26:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14464v1</guid></item><item><title>Explicit and Implicit Large Language Model Personas Generate Opinions but Fail to Replicate Deeper Perceptions and Biases</title><link>http://arxiv.org/abs/2406.14462v1</link><description>Large language models (LLMs) are increasingly being used in human-centeredsocial scientific tasks, such as data annotation, synthetic data creation, andengaging in dialog. However, these tasks are highly subjective and dependent onhuman factors, such as one's environment, attitudes, beliefs, and livedexperiences. Thus, employing LLMs (which do not have such human factors) inthese tasks may result in a lack of variation in data, failing to reflect thediversity of human experiences. In this paper, we examine the role of promptingLLMs with human-like personas and asking the models to answer as if they were aspecific human. This is done explicitly, with exact demographics, politicalbeliefs, and lived experiences, or implicitly via names prevalent in specificpopulations. The LLM personas are then evaluated via (1) subjective annotationtask (e.g., detecting toxicity) and (2) a belief generation task, where bothtasks are known to vary across human factors. We examine the impact of explicitvs. implicit personas and investigate which human factors LLMs recognize andrespond to. Results show that LLM personas show mixed results when reproducingknown human biases, but generate generally fail to demonstrate implicit biases.We conclude that LLMs lack the intrinsic cognitive mechanisms of human thought,while capturing the statistical patterns of how people speak, which mayrestrict their effectiveness in complex social science applications.</description><author>Salvatore Giorgi, Tingting Liu, Ankit Aich, Kelsey Isman, Garrick Sherman, Zachary Fried, João Sedoc, Lyle H. Ungar, Brenda Curtis</author><pubDate>Thu, 20 Jun 2024 17:24:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14462v1</guid></item><item><title>RankCLIP: Ranking-Consistent Language-Image Pretraining</title><link>http://arxiv.org/abs/2404.09387v2</link><description>Self-supervised contrastive learning models, such as CLIP, have set newbenchmarks for vision-language models in many downstream tasks. However, theirdependency on rigid one-to-one mappings overlooks the complex and oftenmultifaceted relationships between and within texts and images. To this end, weintroduce RANKCLIP, a novel pretraining method that extends beyond the rigidone-to-one matching framework of CLIP and its variants. By extending thetraditional pair-wise loss to list-wise, and leveraging both in-modal andcross-modal ranking consistency, RANKCLIP improves the alignment process,enabling it to capture the nuanced many-to-many relationships between andwithin each modality. Through comprehensive experiments, we demonstrate theeffectiveness of RANKCLIP in various downstream tasks, notably achievingsignificant gains in zero-shot classifications over state-of-the-art methods,underscoring the importance of this enhanced learning process.</description><author>Yiming Zhang, Zhuokai Zhao, Zhaorun Chen, Zhili Feng, Zenghui Ding, Yining Sun</author><pubDate>Thu, 20 Jun 2024 17:20:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09387v2</guid></item><item><title>Healing Powers of BERT: How Task-Specific Fine-Tuning Recovers Corrupted Language Models</title><link>http://arxiv.org/abs/2406.14459v1</link><description>Language models like BERT excel at sentence classification tasks due toextensive pre-training on general data, but their robustness to parametercorruption is unexplored. To understand this better, we look at what happens ifa language model is "broken", in the sense that some of its parameters arecorrupted and then recovered by fine-tuning. Strategically corrupting BERTvariants at different levels, we find corrupted models struggle to fullyrecover their original performance, with higher corruption causing more severedegradation. Notably, bottom-layer corruption affecting fundamental linguisticfeatures is more detrimental than top-layer corruption. Our insights contributeto understanding language model robustness and adaptability under adverseconditions, informing strategies for developing resilient NLP systems againstparameter perturbations.</description><author>Shijie Han, Zhenyu Zhang, Andrei Arsene Simion</author><pubDate>Thu, 20 Jun 2024 17:18:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14459v1</guid></item><item><title>Centimeter Positioning Accuracy using AI/ML for 6G Applications</title><link>http://arxiv.org/abs/2406.14458v1</link><description>This research looks at using AI/ML to achieve centimeter-level userpositioning in 6G applications such as the Industrial Internet of Things(IIoT). Initial results show that our AI/ML-based method can estimate userpositions with an accuracy of 17 cm in an indoor factory environment. In thisproposal, we highlight our approaches and future directions.</description><author>Sai Prasanth Kotturi, Radha Krishna Ganti</author><pubDate>Thu, 20 Jun 2024 17:17:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14458v1</guid></item><item><title>Rewarding What Matters: Step-by-Step Reinforcement Learning for Task-Oriented Dialogue</title><link>http://arxiv.org/abs/2406.14457v1</link><description>Reinforcement learning (RL) is a powerful approach to enhance task-orienteddialogue (TOD) systems. However, existing RL methods tend to mainly focus ongeneration tasks, such as dialogue policy learning (DPL) or response generation(RG), while neglecting dialogue state tracking (DST) for understanding. Thisnarrow focus limits the systems to achieve globally optimal performance byoverlooking the interdependence between understanding and generation.Additionally, RL methods face challenges with sparse and delayed rewards, whichcomplicates training and optimization. To address these issues, we extend RLinto both understanding and generation tasks by introducing step-by-steprewards throughout the token generation. The understanding reward increases asmore slots are correctly filled in DST, while the generation reward grows withthe accurate inclusion of user requests. Our approach provides a balancedoptimization aligned with task completion. Experimental results demonstratethat our approach effectively enhances the performance of TOD systems andachieves new state-of-the-art results on three widely used datasets, includingMultiWOZ2.0, MultiWOZ2.1, and In-Car. Our approach also shows superior few-shotability in low-resource settings compared to current models.</description><author>Huifang Du, Shuqin Li, Minghao Wu, Xuejing Feng, Yuan-Fang Li, Haofen Wang</author><pubDate>Thu, 20 Jun 2024 17:15:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14457v1</guid></item><item><title>Pseudo-Bayesian Optimization</title><link>http://arxiv.org/abs/2310.09766v2</link><description>Bayesian Optimization is a popular approach for optimizing expensiveblack-box functions. Its key idea is to use a surrogate model to approximatethe objective and, importantly, quantify the associated uncertainty that allowsa sequential search of query points that balance exploitation-exploration.Gaussian process (GP) has been a primary candidate for the surrogate model,thanks to its Bayesian-principled uncertainty quantification power and modelingflexibility. However, its challenges have also spurred an array of alternativeswhose convergence properties could be more opaque. Motivated by these, we studyin this paper an axiomatic framework that elicits the minimal requirements toguarantee black-box optimization convergence that could apply beyond GP-basedmethods. Moreover, we leverage the design freedom in our framework, which wecall Pseudo-Bayesian Optimization, to construct empirically superioralgorithms. In particular, we show how using simple local regression, and asuitable "randomized prior" construction to quantify uncertainty, not onlyguarantees convergence but also consistently outperforms state-of-the-artbenchmarks in examples ranging from high-dimensional synthetic experiments torealistic hyperparameter tuning and robotic applications.</description><author>Haoxian Chen, Henry Lam</author><pubDate>Thu, 20 Jun 2024 17:15:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09766v2</guid></item><item><title>Capturing Temporal Components for Time Series Classification</title><link>http://arxiv.org/abs/2406.14456v1</link><description>Analyzing sequential data is crucial in many domains, particularly due to theabundance of data collected from the Internet of Things paradigm. Time seriesclassification, the task of categorizing sequential data, has gainedprominence, with machine learning approaches demonstrating remarkableperformance on public benchmark datasets. However, progress has primarily beenin designing architectures for learning representations from raw data at fixed(or ideal) time scales, which can fail to generalize to longer sequences. Thiswork introduces a \textit{compositional representation learning} approachtrained on statistically coherent components extracted from sequential data.Based on a multi-scale change space, an unsupervised approach is proposed tosegment the sequential data into chunks with similar statistical properties. Asequence-based encoder model is trained in a multi-task setting to learncompositional representations from these temporal components for time seriesclassification. We demonstrate its effectiveness through extensive experimentson publicly available time series classification benchmarks. Evaluating thecoherence of segmented components shows its competitive performance on theunsupervised segmentation task.</description><author>Venkata Ragavendra Vavilthota, Ranjith Ramanathan, Sathyanarayanan N. Aakur</author><pubDate>Thu, 20 Jun 2024 17:15:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14456v1</guid></item><item><title>MM-GTUNets: Unified Multi-Modal Graph Deep Learning for Brain Disorders Prediction</title><link>http://arxiv.org/abs/2406.14455v1</link><description>Graph deep learning (GDL) has demonstrated impressive performance inpredicting population-based brain disorders (BDs) through the integration ofboth imaging and non-imaging data. However, the effectiveness of GDL basedmethods heavily depends on the quality of modeling the multi-modal populationgraphs and tends to degrade as the graph scale increases. Furthermore, thesemethods often constrain interactions between imaging and non-imaging data tonode-edge interactions within the graph, overlooking complex inter-modalcorrelations, leading to suboptimal outcomes. To overcome these challenges, wepropose MM-GTUNets, an end-to-end graph transformer based multi-modal graphdeep learning (MMGDL) framework designed for brain disorders prediction atlarge scale. Specifically, to effectively leverage rich multi-modal informationrelated to diseases, we introduce Modality Reward Representation Learning(MRRL) which adaptively constructs population graphs using a reward system.Additionally, we employ variational autoencoder to reconstruct latentrepresentations of non-imaging features aligned with imaging features. Based onthis, we propose Adaptive Cross-Modal Graph Learning (ACMGL), which capturescritical modality-specific and modality-shared features through a unifiedGTUNet encoder taking advantages of Graph UNet and Graph Transformer, andfeature fusion module. We validated our method on two public multi-modaldatasets ABIDE and ADHD-200, demonstrating its superior performance indiagnosing BDs. Our code is available at https://github.com/NZWANG/MM-GTUNets.</description><author>Luhui Cai, Weiming Zeng, Hongyu Chen, Hua Zhang, Yueyang Li, Hongjie Yan, Lingbin Bian, Nizhuan Wang</author><pubDate>Thu, 20 Jun 2024 17:14:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14455v1</guid></item><item><title>FedConPE: Efficient Federated Conversational Bandits with Heterogeneous Clients</title><link>http://arxiv.org/abs/2405.02881v2</link><description>Conversational recommender systems have emerged as a potent solution forefficiently eliciting user preferences. These systems interactively presentqueries associated with "key terms" to users and leverage user feedback toestimate user preferences more efficiently. Nonetheless, most existingalgorithms adopt a centralized approach. In this paper, we introduce FedConPE,a phase elimination-based federated conversational bandit algorithm, where $M$agents collaboratively solve a global contextual linear bandit problem with thehelp of a central server while ensuring secure data management. To effectivelycoordinate all the clients and aggregate their collected data, FedConPE uses anadaptive approach to construct key terms that minimize uncertainty across alldimensions in the feature space. Furthermore, compared with existing federatedlinear bandit algorithms, FedConPE offers improved computational andcommunication efficiency as well as enhanced privacy protections. Ourtheoretical analysis shows that FedConPE is minimax near-optimal in terms ofcumulative regret. We also establish upper bounds for communication costs andconversation frequency. Comprehensive evaluations demonstrate that FedConPEoutperforms existing conversational bandit algorithms while using fewerconversations.</description><author>Zhuohua Li, Maoli Liu, John C. S. Lui</author><pubDate>Thu, 20 Jun 2024 17:11:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02881v2</guid></item><item><title>APEER: Automatic Prompt Engineering Enhances Large Language Model Reranking</title><link>http://arxiv.org/abs/2406.14449v1</link><description>Large Language Models (LLMs) have significantly enhanced InformationRetrieval (IR) across various modules, such as reranking. Despite impressiveperformance, current zero-shot relevance ranking with LLMs heavily relies onhuman prompt engineering. Existing automatic prompt engineering algorithmsprimarily focus on language modeling and classification tasks, leaving thedomain of IR, particularly reranking, underexplored. Directly applying currentprompt engineering algorithms to relevance ranking is challenging due to theintegration of query and long passage pairs in the input, where the rankingcomplexity surpasses classification tasks. To reduce human effort and unlockthe potential of prompt optimization in reranking, we introduce a novelautomatic prompt engineering algorithm named APEER. APEER iteratively generatesrefined prompts through feedback and preference optimization. Extensiveexperiments with four LLMs and ten datasets demonstrate the substantialperformance improvement of APEER over existing state-of-the-art (SoTA) manualprompts. Furthermore, we find that the prompts generated by APEER exhibitbetter transferability across diverse tasks and LLMs. Code is available athttps://github.com/jincan333/APEER.</description><author>Can Jin, Hongwu Peng, Shiyu Zhao, Zhenting Wang, Wujiang Xu, Ligong Han, Jiahui Zhao, Kai Zhong, Sanguthevar Rajasekaran, Dimitris N. Metaxas</author><pubDate>Thu, 20 Jun 2024 17:11:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14449v1</guid></item><item><title>The Importance of Directional Feedback for LLM-based Optimizers</title><link>http://arxiv.org/abs/2405.16434v2</link><description>We study the potential of using large language models (LLMs) as aninteractive optimizer for solving maximization problems in a text space usingnatural language and numerical feedback. Inspired by the classical optimizationliterature, we classify the natural language feedback into directional andnon-directional, where the former is a generalization of the first-orderfeedback to the natural language space. We find that LLMs are especiallycapable of optimization when they are provided with {directional feedback}.Based on this insight, we design a new LLM-based optimizer that synthesizesdirectional feedback from the historical optimization trace to achieve reliableimprovement over iterations. Empirically, we show our LLM-based optimizer ismore stable and efficient in solving optimization problems, from maximizingmathematical functions to optimizing prompts for writing poems, compared withexisting techniques.</description><author>Allen Nie, Ching-An Cheng, Andrey Kolobov, Adith Swaminathan</author><pubDate>Thu, 20 Jun 2024 17:10:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16434v2</guid></item><item><title>Maintenance Required: Updating and Extending Bootstrapped Human Activity Recognition Systems for Smart Homes</title><link>http://arxiv.org/abs/2406.14446v1</link><description>Developing human activity recognition (HAR) systems for smart homes is notstraightforward due to varied layouts of the homes and their personalizedsettings, as well as idiosyncratic behaviors of residents. As such,off-the-shelf HAR systems are effective in limited capacity for an individualhome, and HAR systems often need to be derived "from scratch", which comes withsubstantial efforts and often is burdensome to the resident. Previous work hassuccessfully targeted the initial phase. At the end of this initial phase, weidentify seed points. We build on bootstrapped HAR systems and introduce aneffective updating and extension procedure for continuous improvement of HARsystems with the aim of keeping up with ever changing life circumstances. Ourmethod makes use of the seed points identified at the end of the initialbootstrapping phase. A contrastive learning framework is trained using theseseed points and labels obtained for the same. This model is then used toimprove the segmentation accuracy of the identified prominent activities.Improvements in the activity recognition system through this procedure helpmodel the majority of the routine activities in the smart home. We demonstratethe effectiveness of our procedure through experiments on the CASAS datasetsthat show the practical value of our approach.</description><author>Shruthi K. Hiremath, Thomas Ploetz</author><pubDate>Thu, 20 Jun 2024 17:08:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14446v1</guid></item><item><title>Graph Representation Learning Strategies for Omics Data: A Case Study on Parkinson's Disease</title><link>http://arxiv.org/abs/2406.14442v1</link><description>Omics data analysis is crucial for studying complex diseases, but its highdimensionality and heterogeneity challenge classical statistical and machinelearning methods. Graph neural networks have emerged as promising alternatives,yet the optimal strategies for their design and optimization in real-worldbiomedical challenges remain unclear. This study evaluates various graphrepresentation learning models for case-control classification usinghigh-throughput biological data from Parkinson's disease and control samples.We compare topologies derived from sample similarity networks and molecularinteraction networks, including protein-protein and metabolite-metaboliteinteractions (PPI, MMI). Graph Convolutional Network (GCNs), Chebyshev spectralgraph convolution (ChebyNet), and Graph Attention Network (GAT), are evaluatedalongside advanced architectures like graph transformers, the graph U-net, andsimpler models like multilayer perceptron (MLP). These models are systematically applied to transcriptomics and metabolomicsdata independently. Our comparative analysis highlights the benefits andlimitations of various architectures in extracting patterns from omics data,paving the way for more accurate and interpretable models in biomedicalresearch.</description><author>Elisa Gómez de Lope, Saurabh Deshpande, Ramón Viñas Torné, Pietro Liò, Enrico Glaab, Stéphane P. A. Bordas</author><pubDate>Thu, 20 Jun 2024 17:06:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14442v1</guid></item><item><title>Physics-aware Machine Learning Revolutionizes Scientific Paradigm for Machine Learning and Process-based Hydrology</title><link>http://arxiv.org/abs/2310.05227v4</link><description>Accurate hydrological understanding and water cycle prediction are crucialfor addressing scientific and societal challenges associated with themanagement of water resources, particularly under the dynamic influence ofanthropogenic climate change. Existing reviews predominantly concentrate on thedevelopment of machine learning (ML) in this field, yet there is a cleardistinction between hydrology and ML as separate paradigms. Here, we introducephysics-aware ML as a transformative approach to overcome the perceived barrierand revolutionize both fields. Specifically, we present a comprehensive reviewof the physics-aware ML methods, building a structured community (PaML) ofexisting methodologies that integrate prior physical knowledge or physics-basedmodeling into ML. We systematically analyze these PaML methodologies withrespect to four aspects: physical data-guided ML, physics-informed ML,physics-embedded ML, and physics-aware hybrid learning. PaML facilitatesML-aided hypotheses, accelerating insights from big data and fosteringscientific discoveries. We first conduct a systematic review of hydrology inPaML, including rainfall-runoff hydrological processes and hydrodynamicprocesses, and highlight the most promising and challenging directions fordifferent objectives and PaML methods. Finally, a new PaML-based hydrologyplatform, termed HydroPML, is released as a foundation for hydrologicalapplications. HydroPML enhances the explainability and causality of ML and laysthe groundwork for the digital water cycle's realization. The HydroPML platformis publicly available at https://hydropml.github.io/.</description><author>Qingsong Xu, Yilei Shi, Jonathan Bamber, Ye Tuo, Ralf Ludwig, Xiao Xiang Zhu</author><pubDate>Thu, 20 Jun 2024 17:05:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05227v4</guid></item><item><title>Video Generation with Learned Action Prior</title><link>http://arxiv.org/abs/2406.14436v1</link><description>Stochastic video generation is particularly challenging when the camera ismounted on a moving platform, as camera motion interacts with observed imagepixels, creating complex spatio-temporal dynamics and making the problempartially observable. Existing methods typically address this by focusing onraw pixel-level image reconstruction without explicitly modelling camera motiondynamics. We propose a solution by considering camera motion or action as partof the observed image state, modelling both image and action within amulti-modal learning framework. We introduce three models: Video Generationwith Learning Action Prior (VG-LeAP) treats the image-action pair as anaugmented state generated from a single latent stochastic process and usesvariational inference to learn the image-action latent prior; Causal-LeAP,which establishes a causal relationship between action and the observed imageframe at time $t$, learning an action prior conditioned on the observed imagestates; and RAFI, which integrates the augmented image-action state conceptinto flow matching with diffusion generative processes, demonstrating that thisaction-conditioned image generation concept can be extended to otherdiffusion-based models. We emphasize the importance of multi-modal training inpartially observable video generation problems through detailed empiricalstudies on our new video action dataset, RoAM.</description><author>Meenakshi Sarkar, Devansh Bhardwaj, Debasish Ghose</author><pubDate>Thu, 20 Jun 2024 17:00:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14436v1</guid></item><item><title>Towards Truthful Multilingual Large Language Models: Benchmarking and Alignment Strategies</title><link>http://arxiv.org/abs/2406.14434v1</link><description>In the era of large language models (LLMs), building multilingual largelanguage models (MLLMs) that can serve users worldwide holds greatsignificance. However, existing research seldom focuses on the truthfulness ofMLLMs. Meanwhile, contemporary multilingual aligning technologies struggle tobalance massive languages and often exhibit serious truthfulness gaps acrossdifferent languages, especially those that differ greatly from English. In ourwork, we construct a benchmark for truthfulness evaluation in multilingualscenarios and explore the ways to align facts across languages to enhance thetruthfulness of MLLMs. Furthermore, we propose Fact-aware MultilingualSelective Synergy (FaMSS) to optimize the data allocation across a large numberof languages and different data types. Experimental results demonstrate thatour approach can effectively reduce the multilingual representation disparityand enhance the multilingual capabilities of LLMs.</description><author>Weihao Liu, Ning Wu, Wenbiao Ding, Shining Liang, Ming Gong, Dongmei Zhang</author><pubDate>Thu, 20 Jun 2024 16:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14434v1</guid></item><item><title>Deciphering 'What' and 'Where' Visual Pathways from Spectral Clustering of Layer-Distributed Neural Representations</title><link>http://arxiv.org/abs/2312.06716v2</link><description>We present an approach for analyzing grouping information contained within aneural network's activations, permitting extraction of spatial layout andsemantic segmentation from the behavior of large pre-trained vision models.Unlike prior work, our method conducts a holistic analysis of a network'sactivation state, leveraging features from all layers and obviating the need toguess which part of the model contains relevant information. Motivated byclassic spectral clustering, we formulate this analysis in terms of anoptimization objective involving a set of affinity matrices, each formed bycomparing features within a different layer. Solving this optimization problemusing gradient descent allows our technique to scale from single images todataset-level analysis, including, in the latter, both intra- and inter-imagerelationships. Analyzing a pre-trained generative transformer provides insightinto the computational strategy learned by such models. Equating affinity withkey-query similarity across attention layers yields eigenvectors encoding scenespatial layout, whereas defining affinity by value vector similarity yieldseigenvectors encoding object identity. This result suggests that key and queryvectors coordinate attentional information flow according to spatial proximity(a `where' pathway), while value vectors refine a semantic categoryrepresentation (a `what' pathway).</description><author>Xiao Zhang, David Yunis, Michael Maire</author><pubDate>Thu, 20 Jun 2024 16:57:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06716v2</guid></item><item><title>CollaFuse: Collaborative Diffusion Models</title><link>http://arxiv.org/abs/2406.14429v1</link><description>In the landscape of generative artificial intelligence, diffusion-basedmodels have emerged as a promising method for generating synthetic images.However, the application of diffusion models poses numerous challenges,particularly concerning data availability, computational requirements, andprivacy. Traditional approaches to address these shortcomings, like federatedlearning, often impose significant computational burdens on individual clients,especially those with constrained resources. In response to these challenges,we introduce a novel approach for distributed collaborative diffusion modelsinspired by split learning. Our approach facilitates collaborative training ofdiffusion models while alleviating client computational burdens during imagesynthesis. This reduced computational burden is achieved by retaining data andcomputationally inexpensive processes locally at each client while outsourcingthe computationally expensive processes to shared, more efficient serverresources. Through experiments on the common CelebA dataset, our approachdemonstrates enhanced privacy by reducing the necessity for sharing raw data.These capabilities hold significant potential across various application areas,including the design of edge computing solutions. Thus, our work advancesdistributed machine learning by contributing to the evolution of collaborativediffusion models.</description><author>Simeon Allmendinger, Domenique Zipperling, Lukas Struppek, Niklas Kühl</author><pubDate>Thu, 20 Jun 2024 16:54:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14429v1</guid></item><item><title>Control when confidence is costly</title><link>http://arxiv.org/abs/2406.14427v1</link><description>We develop a version of stochastic control that accounts for computationalcosts of inference. Past studies identified efficient coding without control,or efficient control that neglects the cost of synthesizing information. Herewe combine these concepts into a framework where agents rationally approximateinference for efficient control. Specifically, we study Linear QuadraticGaussian (LQG) control with an added internal cost on the relative precision ofthe posterior probability over the world state. This creates a trade-off: anagent can obtain more utility overall by sacrificing some task performance, ifdoing so saves enough bits during inference. We discover that the rationalstrategy that solves the joint inference and control problem goes through phasetransitions depending on the task demands, switching from a costly but optimalinference to a family of suboptimal inferences related by rotationtransformations, each misestimate the stability of the world. In all cases, theagent moves more to think less. This work provides a foundation for a new typeof rational computations that could be used by both brains and machines forefficient but computationally constrained control.</description><author>Itzel Olivos-Castillo, Paul Schrater, Xaq Pitkow</author><pubDate>Thu, 20 Jun 2024 16:50:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14427v1</guid></item><item><title>Transferable Boltzmann Generators</title><link>http://arxiv.org/abs/2406.14426v1</link><description>The generation of equilibrium samples of molecular systems has been along-standing problem in statistical physics. Boltzmann Generators are agenerative machine learning method that addresses this issue by learning atransformation via a normalizing flow from a simple prior distribution to thetarget Boltzmann distribution of interest. Recently, flow matching has beenemployed to train Boltzmann Generators for small molecular systems in Cartesiancoordinates. We extend this work and propose a first framework for BoltzmannGenerators that are transferable across chemical space, such that they predictzero-shot Boltzmann distributions for test molecules without being retrainedfor these systems. These transferable Boltzmann Generators allow approximatesampling from the target distribution of unseen systems, as well as efficientreweighting to the target Boltzmann distribution. The transferability of theproposed framework is evaluated on dipeptides, where we show that itgeneralizes efficiently to unseen systems. Furthermore, we demonstrate that ourproposed architecture enhances the efficiency of Boltzmann Generators trainedon single molecular systems.</description><author>Leon Klein, Frank Noé</author><pubDate>Thu, 20 Jun 2024 16:50:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14426v1</guid></item><item><title>SynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource Languages</title><link>http://arxiv.org/abs/2406.14425v1</link><description>Question Answering (QA) datasets have been instrumental in developing andevaluating Large Language Model (LLM) capabilities. However, such datasets arescarce for languages other than English due to the cost and difficulties ofcollection and manual annotation. This means that producing novel models andmeasuring the performance of multilingual LLMs in low-resource languages ischallenging. To mitigate this, we propose $\textbf{S}$yn$\textbf{DAR}$in, amethod for generating and validating QA datasets for low-resource languages. Weutilize parallel content mining to obtain $\textit{human-curated}$ paragraphsbetween English and the target language. We use the English data as context to$\textit{generate}$ synthetic multiple-choice (MC) question-answer pairs, whichare automatically translated and further validated for quality. Combining thesewith their designated non-English $\textit{human-curated}$ paragraphs form thefinal QA dataset. The method allows to maintain the content quality, reducesthe likelihood of factual errors, and circumvents the need for costlyannotation. To test the method, we created a QA dataset with $1.2$K samples forthe Armenian language. The human evaluation shows that $98\%$ of the generatedEnglish data maintains quality and diversity in the question types and topics,while the translation validation pipeline can filter out $\sim70\%$ of datawith poor quality. We use the dataset to benchmark state-of-the-art LLMs,showing their inability to achieve human accuracy with some model performancescloser to random chance. This shows that the generated dataset is non-trivialand can be used to evaluate reasoning capabilities in low-resource language.</description><author>Gayane Ghazaryan, Erik Arakelyan, Pasquale Minervini, Isabelle Augenstein</author><pubDate>Thu, 20 Jun 2024 16:49:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14425v1</guid></item><item><title>CascadeServe: Unlocking Model Cascades for Inference Serving</title><link>http://arxiv.org/abs/2406.14424v1</link><description>Machine learning (ML) models are increasingly deployed to production, callingfor efficient inference serving systems. Efficient inference serving iscomplicated by two challenges: (i) ML models incur high computational costs,and (ii) the request arrival rates of practical applications have frequent,high, and sudden variations which make it hard to correctly provision hardware.Model cascades are positioned to tackle both of these challenges, as they (i)save work while maintaining accuracy, and (ii) expose a high-resolutiontrade-off between work and accuracy, allowing for fine-grained adjustments torequest arrival rates. Despite their potential, model cascades haven't beenused inside an online serving system. This comes with its own set ofchallenges, including workload adaption, model replication onto hardware,inference scheduling, request batching, and more. In this work, we proposeCascadeServe, which automates and optimizes end-to-end inference serving withcascades. CascadeServe operates in an offline and online phase. In the offlinephase, the system pre-computes a gear plan that specifies how to serveinferences online. In the online phase, the gear plan allows the system toserve inferences while making near-optimal adaptations to the query load atnegligible decision overheads. We find that CascadeServe saves 2-3x in costacross a wide spectrum of the latency-accuracy space when compared tostate-of-the-art baselines on different workloads.</description><author>Ferdi Kossmann, Ziniu Wu, Alex Turk, Nesime Tatbul, Lei Cao, Samuel Madden</author><pubDate>Thu, 20 Jun 2024 16:47:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14424v1</guid></item><item><title>FutureNet-LOF: Joint Trajectory Prediction and Lane Occupancy Field Prediction with Future Context Encoding</title><link>http://arxiv.org/abs/2406.14422v1</link><description>Most prior motion prediction endeavors in autonomous driving haveinadequately encoded future scenarios, leading to predictions that may fail toaccurately capture the diverse movements of agents (e.g., vehicles orpedestrians). To address this, we propose FutureNet, which explicitlyintegrates initially predicted trajectories into the future scenario andfurther encodes these future contexts to enhance subsequent forecasting.Additionally, most previous motion forecasting works have focused on predictingindependent futures for each agent. However, safe and smooth autonomous drivingrequires accurately predicting the diverse future behaviors of numeroussurrounding agents jointly in complex dynamic environments. Given that allagents occupy certain potential travel spaces and possess lane drivingpriority, we propose Lane Occupancy Field (LOF), a new representation with lanesemantics for motion forecasting in autonomous driving. LOF can simultaneouslycapture the joint probability distribution of all road participants' futurespatial-temporal positions. Due to the high compatibility between laneoccupancy field prediction and trajectory prediction, we propose a novelnetwork with future context encoding for the joint prediction of these twotasks. Our approach ranks 1st on two large-scale motion forecasting benchmarks:Argoverse 1 and Argoverse 2.</description><author>Mingkun Wang, Xiaoguang Ren, Ruochun Jin, Minglong Li, Xiaochuan Zhang, Changqian Yu, Mingxu Wang, Wenjing Yang</author><pubDate>Thu, 20 Jun 2024 16:41:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14422v1</guid></item><item><title>Communication-efficient Vertical Federated Learning via Compressed Error Feedback</title><link>http://arxiv.org/abs/2406.14420v1</link><description>Communication overhead is a known bottleneck in federated learning (FL). Toaddress this, lossy compression is commonly used on the informationcommunicated between the server and clients during training. In horizontal FL,where each client holds a subset of the samples, such communication-compressedtraining methods have recently seen significant progress. However, in theirvertical FL counterparts, where each client holds a subset of the features, ourunderstanding remains limited. To address this, we propose an error feedbackcompressed vertical federated learning (EFVFL) method to train split neuralnetworks. In contrast with previous communication-compressed methods forvertical FL, EFVFL does not require a vanishing compression error for thegradient norm to converge to zero for smooth nonconvex problems. By leveragingerror feedback, our method can achieve a $\mathcal{O}(1/T)$ convergence rate inthe full-batch case, improving over the state-of-the-art$\mathcal{O}(1/\sqrt{T})$ rate under $\mathcal{O}(1/\sqrt{T})$ compressionerror, and matching the rate of uncompressed methods. Further, when theobjective function satisfies the Polyak-{\L}ojasiewicz inequality, our methodconverges linearly. In addition to improving convergence rates, our method alsosupports the use of private labels. Numerical experiments show that EFVFLsignificantly improves over the prior art, confirming our theoretical results.</description><author>Pedro Valdeira, João Xavier, Cláudia Soares, Yuejie Chi</author><pubDate>Thu, 20 Jun 2024 16:40:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14420v1</guid></item><item><title>Vectorized Representation Dreamer (VRD): Dreaming-Assisted Multi-Agent Motion-Forecasting</title><link>http://arxiv.org/abs/2406.14415v1</link><description>For an autonomous vehicle to plan a path in its environment, it must be ableto accurately forecast the trajectory of all dynamic objects in its proximity.While many traditional methods encode observations in the scene to solve thisproblem, there are few approaches that consider the effect of the ego vehicle'sbehavior on the future state of the world. In this paper, we introduce VRD, avectorized world model-inspired approach to the multi-agent motion forecastingproblem. Our method combines a traditional open-loop training regime with anovel dreamed closed-loop training pipeline that leverages a kinematicreconstruction task to imagine the trajectory of all agents, conditioned on theaction of the ego vehicle. Quantitative and qualitative experiments areconducted on the Argoverse 2 multi-world forecasting evaluation dataset and theintersection drone (inD) dataset to demonstrate the performance of our proposedmodel. Our model achieves state-of-the-art performance on the single predictionmiss rate metric on the Argoverse 2 dataset and performs on par with theleading models for the single prediction displacement metrics.</description><author>Hunter Schofield, Hamidreza Mirkhani, Mohammed Elmahgiubi, Kasra Rezaee, Jinjun Shan</author><pubDate>Thu, 20 Jun 2024 16:34:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14415v1</guid></item><item><title>Benchmarking Monocular 3D Dog Pose Estimation Using In-The-Wild Motion Capture Data</title><link>http://arxiv.org/abs/2406.14412v1</link><description>We introduce a new benchmark analysis focusing on 3D canine pose estimationfrom monocular in-the-wild images. A multi-modal dataset 3DDogs-Lab wascaptured indoors, featuring various dog breeds trotting on a walkway. Itincludes data from optical marker-based mocap systems, RGBD cameras, IMUs, anda pressure mat. While providing high-quality motion data, the presence ofoptical markers and limited background diversity make the captured video lessrepresentative of real-world conditions. To address this, we created3DDogs-Wild, a naturalised version of the dataset where the optical markers arein-painted and the subjects are placed in diverse environments, enhancing itsutility for training RGB image-based pose detectors. We show that using the3DDogs-Wild to train the models leads to improved performance when evaluatingon in-the-wild data. Additionally, we provide a thorough analysis using variouspose estimation models, revealing their respective strengths and weaknesses. Webelieve that our findings, coupled with the datasets provided, offer valuableinsights for advancing 3D animal pose estimation.</description><author>Moira Shooter, Charles Malleson, Adrian Hilton</author><pubDate>Thu, 20 Jun 2024 16:33:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14412v1</guid></item><item><title>FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving</title><link>http://arxiv.org/abs/2406.14408v1</link><description>Formal verification (FV) has witnessed growing significance with currentemerging program synthesis by the evolving large language models (LLMs).However, current formal verification mainly resorts to symbolic verifiers orhand-craft rules, resulting in limitations for extensive and flexibleverification. On the other hand, formal languages for automated theoremproving, such as Isabelle, as another line of rigorous verification, aremaintained with comprehensive rules and theorems. In this paper, we proposeFVEL, an interactive Formal Verification Environment with LLMs. Specifically,FVEL transforms a given code to be verified into Isabelle, and then conductsverification via neural automated theorem proving with an LLM. The joinedparadigm leverages the rigorous yet abundant formulated and organized rules inIsabelle and is also convenient for introducing and adjusting cutting-edgeLLMs. To achieve this goal, we extract a large-scale FVELER3. The FVELERdataset includes code dependencies and verification processes that areformulated in Isabelle, containing 758 theories, 29,125 lemmas, and 200,646proof steps in total with in-depth dependencies. We benchmark FVELER in theFVEL environment by first fine-tuning LLMs with FVELER and then evaluating themon Code2Inv and SV-COMP. The results show that FVEL with FVELER fine-tunedLlama3- 8B solves 17.39% (69 -&gt; 81) more problems, and Mistral-7B 12% (75 -&gt;84) more problems in SV-COMP. And the proportion of proof errors is reduced.Project page: https://fveler.github.io/.</description><author>Xiaohan Lin, Qingxing Cao, Yinya Huang, Haiming Wang, Jianqiao Lu, Zhengying Liu, Linqi Song, Xiaodan Liang</author><pubDate>Thu, 20 Jun 2024 16:31:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14408v1</guid></item><item><title>Dynamic Basis Function Interpolation for Adaptive In Situ Data Integration in Ocean Modeling</title><link>http://arxiv.org/abs/2301.05551v3</link><description>We propose a new method for combining in situ buoy measurements with Earthsystem models (ESMs) to improve the accuracy of temperature predictions in theocean. The technique utilizes the dynamics \textit{and} modes identified inESMs alongside buoy measurements to improve accuracy while preserving featuressuch as seasonality. We use this technique, which we call Dynamic BasisFunction Interpolation, to correct errors in localized temperature predictionsmade by the Model for Prediction Across Scales Ocean component (MPAS-O) withthe Global Drifter Program's in situ ocean buoy dataset.</description><author>Derek DeSantis, Ayan Biswas, Earl Lawrence, Phillip Wolfram</author><pubDate>Thu, 20 Jun 2024 16:27:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.05551v3</guid></item><item><title>FRAPPE: A Group Fairness Framework for Post-Processing Everything</title><link>http://arxiv.org/abs/2312.02592v4</link><description>Despite achieving promising fairness-error trade-offs, in-processingmitigation techniques for group fairness cannot be employed in numerouspractical applications with limited computation resources or no access to thetraining pipeline of the prediction model. In these situations, post-processingis a viable alternative. However, current methods are tailored to specificproblem settings and fairness definitions and hence, are not as broadlyapplicable as in-processing. In this work, we propose a framework that turnsany regularized in-processing method into a post-processing approach. Thisprocedure prescribes a way to obtain post-processing techniques for a muchbroader range of problem settings than the prior post-processing literature. Weshow theoretically and through extensive experiments that our frameworkpreserves the good fairness-error trade-offs achieved with in-processing andcan improve over the effectiveness of prior post-processing methods. Finally,we demonstrate several advantages of a modular mitigation strategy thatdisentangles the training of the prediction model from the fairness mitigation,including better performance on tasks with partial group labels.</description><author>Alexandru Tifrea, Preethi Lahoti, Ben Packer, Yoni Halpern, Ahmad Beirami, Flavien Prost</author><pubDate>Thu, 20 Jun 2024 16:26:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02592v4</guid></item><item><title>Predicting Probabilities of Error to Combine Quantization and Early Exiting: QuEE</title><link>http://arxiv.org/abs/2406.14404v1</link><description>Machine learning models can solve complex tasks but often require significantcomputational resources during inference. This has led to the development ofvarious post-training computation reduction methods that tackle this issue indifferent ways, such as quantization which reduces the precision of weights andarithmetic operations, and dynamic networks which adapt computation to thesample at hand. In this work, we propose a more general dynamic network thatcan combine both quantization and early exit dynamic network: QuEE. Ouralgorithm can be seen as a form of soft early exiting or input-dependentcompression. Rather than a binary decision between exiting or continuing, weintroduce the possibility of continuing with reduced computation. Thiscomplicates the traditionally considered early exiting problem, which we solvethrough a principled formulation. The crucial factor of our approach isaccurate prediction of the potential accuracy improvement achievable throughfurther computation. We demonstrate the effectiveness of our method throughempirical evaluation, as well as exploring the conditions for its success on 4classification datasets.</description><author>Florence Regol, Joud Chataoui, Bertrand Charpentier, Mark Coates, Pablo Piantanida, Stephan Gunnemann</author><pubDate>Thu, 20 Jun 2024 16:25:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14404v1</guid></item><item><title>DREW : Towards Robust Data Provenance by Leveraging Error-Controlled Watermarking</title><link>http://arxiv.org/abs/2406.02836v2</link><description>Identifying the origin of data is crucial for data provenance, withapplications including data ownership protection, media forensics, anddetecting AI-generated content. A standard approach involves embedding-basedretrieval techniques that match query data with entries in a reference dataset.However, this method is not robust against benign and malicious edits. Toaddress this, we propose Data Retrieval with Error-corrected codes andWatermarking (DREW). DREW randomly clusters the reference dataset, injectsunique error-controlled watermark keys into each cluster, and uses these keysat query time to identify the appropriate cluster for a given sample. Afterlocating the relevant cluster, embedding vector similarity retrieval isperformed within the cluster to find the most accurate matches. The integrationof error control codes (ECC) ensures reliable cluster assignments, enabling themethod to perform retrieval on the entire dataset in case the ECC algorithmcannot detect the correct cluster with high confidence. This makes DREWmaintain baseline performance, while also providing opportunities forperformance improvements due to the increased likelihood of correctly matchingqueries to their origin when performing retrieval on a smaller subset of thedataset. Depending on the watermark technique used, DREW can providesubstantial improvements in retrieval accuracy (up to 40\% for some datasetsand modification types) across multiple datasets and state-of-the-art embeddingmodels (e.g., DinoV2, CLIP), making our method a promising solution for secureand reliable source identification. The code is available athttps://github.com/mehrdadsaberi/DREW</description><author>Mehrdad Saberi, Vinu Sankar Sadasivan, Arman Zarei, Hessam Mahdavifar, Soheil Feizi</author><pubDate>Thu, 20 Jun 2024 16:25:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.02836v2</guid></item><item><title>Fair Streaming Feature Selection</title><link>http://arxiv.org/abs/2406.14401v1</link><description>Streaming feature selection techniques have become essential in processingreal-time data streams, as they facilitate the identification of the mostrelevant attributes from continuously updating information. Despite theirperformance, current algorithms to streaming feature selection frequently fallshort in managing biases and avoiding discrimination that could be perpetuatedby sensitive attributes, potentially leading to unfair outcomes in theresulting models. To address this issue, we propose FairSFS, a novel algorithmfor Fair Streaming Feature Selection, to uphold fairness in the featureselection process without compromising the ability to handle data in an onlinemanner. FairSFS adapts to incoming feature vectors by dynamically adjusting thefeature set and discerns the correlations between classification attributes andsensitive attributes from this revised set, thereby forestalling thepropagation of sensitive data. Empirical evaluations show that FairSFS not onlymaintains accuracy that is on par with leading streaming feature selectionmethods and existing fair feature techniques but also significantly improvesfairness metrics.</description><author>Zhangling Duan, Tianci Li, Xingyu Wu, Zhaolong Ling, Jingye Yang, Zhaohong Jia</author><pubDate>Thu, 20 Jun 2024 16:22:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14401v1</guid></item><item><title>Transformers Can Represent $n$-gram Language Models</title><link>http://arxiv.org/abs/2404.14994v3</link><description>Existing work has analyzed the representational capacity of the transformerarchitecture by means of formal models of computation. However, the focus sofar has been on analyzing the architecture in terms of language\emph{acceptance}. We contend that this is an ill-suited problem in the studyof \emph{language models} (LMs), which are definitionally \emph{probabilitydistributions} over strings. In this paper, we focus on the relationshipbetween transformer LMs and $n$-gram LMs, a simple and historically relevantclass of language models. We show that transformer LMs using the hard or sparseattention mechanisms can exactly represent any $n$-gram LM, giving us aconcrete lower bound on their probabilistic representational capacity. Thisprovides a first step towards understanding the mechanisms that transformer LMscan use to represent probability distributions over strings.</description><author>Anej Svete, Ryan Cotterell</author><pubDate>Thu, 20 Jun 2024 16:21:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14994v3</guid></item><item><title>Automated Evaluation of Large Vision-Language Models on Self-driving Corner Cases</title><link>http://arxiv.org/abs/2404.10595v2</link><description>Large Vision-Language Models (LVLMs) have received widespread attention inadvancing the interpretable self-driving. Existing evaluations of LVLMsprimarily focus on the multi-faceted capabilities in natural circumstances,lacking automated and quantifiable assessment for self-driving, let alone thesevere road corner cases. In this paper, we propose CODA-LM, the very firstbenchmark for the automatic evaluation of LVLMs for self-driving corner cases.We adopt a hierarchical data structure to prompt powerful LVLMs to analyzecomplex driving scenes and generate high-quality pre-annotation for humanannotators, and for LVLM evaluation, we show that using the text-only largelanguage models (LLMs) as judges reveals even better alignment with humanpreferences than the LVLM judges. Moreover, with CODA-LM, we build CODA-VLM, anew driving LVLM surpassing all the open-sourced counterparts on CODA-LM. OurCODA-VLM performs comparably with GPT-4V, even surpassing GPT-4V by +21.42% onthe regional perception task. We hope CODA-LM can become the catalyst topromote interpretable self-driving empowered by LVLMs.</description><author>Kai Chen, Yanze Li, Wenhua Zhang, Yanxin Liu, Pengxiang Li, Ruiyuan Gao, Lanqing Hong, Meng Tian, Xinhai Zhao, Zhenguo Li, Dit-Yan Yeung, Huchuan Lu, Xu Jia</author><pubDate>Thu, 20 Jun 2024 16:20:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10595v2</guid></item><item><title>WEATHER-5K: A Large-scale Global Station Weather Dataset Towards Comprehensive Time-series Forecasting Benchmark</title><link>http://arxiv.org/abs/2406.14399v1</link><description>Global Station Weather Forecasting (GSWF) is crucial for various sectors,including aviation, agriculture, energy, and disaster preparedness. Recentadvancements in deep learning have significantly improved the accuracy ofweather predictions by optimizing models based on public meteorological data.However, existing public datasets for GSWF optimization and benchmarking stillsuffer from significant limitations, such as small sizes, limited temporalcoverage, and a lack of comprehensive variables. These shortcomings preventthem from effectively reflecting the benchmarks of current forecasting methodsand fail to support the real needs of operational weather forecasting. Toaddress these challenges, we present the WEATHER-5K dataset. This datasetcomprises a comprehensive collection of data from 5,672 weather stationsworldwide, spanning a 10-year period with one-hour intervals. It includesmultiple crucial weather elements, providing a more reliable and interpretableresource for forecasting. Furthermore, our WEATHER-5K dataset can serve as abenchmark for comprehensively evaluating existing well-known forecastingmodels, extending beyond GSWF methods to support future time-series researchchallenges and opportunities. The dataset and benchmark implementation arepublicly available at: https://github.com/taohan10200/WEATHER-5K.</description><author>Tao Han, Song Guo, Zhenghao Chen, Wanghan Xu, Lei Bai</author><pubDate>Thu, 20 Jun 2024 16:18:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14399v1</guid></item><item><title>Low-Rank Quantization-Aware Training for LLMs</title><link>http://arxiv.org/abs/2406.06385v2</link><description>Large language models (LLMs) are omnipresent, however their practicaldeployment is challenging due to their ever increasing computational and memorydemands. Quantization is one of the most effective ways to make them morecompute and memory efficient. Quantization-aware training (QAT) methods,generally produce the best quantized performance, however it comes at the costof potentially long training time and excessive memory usage, making itimpractical when applying for LLMs. Inspired by parameter-efficient fine-tuning(PEFT) and low-rank adaptation (LoRA) literature, we propose LR-QAT -- alightweight and memory-efficient QAT algorithm for LLMs. LR-QAT employs severalcomponents to save memory without sacrificing predictive performance: (a)low-rank auxiliary weights that are aware of the quantization grid; (b) adowncasting operator using fixed-point or double-packed integers and (c)checkpointing. Unlike most related work, our method (i) is inference-efficient,leading to no additional overhead compared to traditional PTQ; (ii) can be seenas a general extended pretraining framework, meaning that the resulting modelcan still be utilized for any downstream task afterwards; (iii) can be appliedacross a wide range of quantization settings, such as different choicesquantization granularity, activation quantization, and seamlessly combined withmany PTQ techniques. We apply LR-QAT to LLaMA-2/3 and Mistral model familiesand validate its effectiveness on several downstream tasks. Our methodoutperforms common post-training quantization (PTQ) approaches and reaches thesame model performance as full-model QAT at the fraction of its memory usage.Specifically, we can train a 7B LLM on a single consumer grade GPU with 24GB ofmemory.</description><author>Yelysei Bondarenko, Riccardo Del Chiaro, Markus Nagel</author><pubDate>Thu, 20 Jun 2024 16:18:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06385v2</guid></item><item><title>ATAC-Net: Zoomed view works better for Anomaly Detection</title><link>http://arxiv.org/abs/2406.14398v1</link><description>The application of deep learning in visual anomaly detection has gainedwidespread popularity due to its potential use in quality control andmanufacturing. Current standard methods are Unsupervised, where a clean datasetis utilised to detect deviations and flag anomalies during testing. However,incorporating a few samples when the type of anomalies is known beforehand cansignificantly enhance performance. Thus, we propose ATAC-Net, a framework thattrains to detect anomalies from a minimal set of known prior anomalies.Furthermore, we introduce attention-guided cropping, which provides a closerview of suspect regions during the training phase. Our framework is a reliableand easy-to-understand system for detecting anomalies, and we substantiate itssuperiority to some of the current state-of-the-art techniques in a comparablesetting.</description><author>Shaurya Gupta, Neil Gautam, Anurag Malyala</author><pubDate>Thu, 20 Jun 2024 16:18:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14398v1</guid></item><item><title>Certified Robust Accuracy of Neural Networks Are Bounded due to Bayes Errors</title><link>http://arxiv.org/abs/2405.11547v2</link><description>Adversarial examples pose a security threat to many critical systems built onneural networks. While certified training improves robustness, it alsodecreases accuracy noticeably. Despite various proposals for addressing thisissue, the significant accuracy drop remains. More importantly, it is not clearwhether there is a certain fundamental limit on achieving robustness whilstmaintaining accuracy. In this work, we offer a novel perspective based on Bayeserrors. By adopting Bayes error to robustness analysis, we investigate thelimit of certified robust accuracy, taking into account data distributionuncertainties. We first show that the accuracy inevitably decreases in thepursuit of robustness due to changed Bayes error in the altered datadistribution. Subsequently, we establish an upper bound for certified robustaccuracy, considering the distribution of individual classes and theirboundaries. Our theoretical results are empirically evaluated on real-worlddatasets and are shown to be consistent with the limited success of existingcertified training results, e.g., for CIFAR10, our analysis results in an upperbound (of certified robust accuracy) of 67.49\%, meanwhile existing approachesare only able to increase it from 53.89\% in 2017 to 62.84\% in 2023.</description><author>Ruihan Zhang, Jun Sun</author><pubDate>Thu, 20 Jun 2024 16:15:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11547v2</guid></item><item><title>Fast Computation of Optimal Transport via Entropy-Regularized Extragradient Methods</title><link>http://arxiv.org/abs/2301.13006v2</link><description>Efficient computation of the optimal transport distance between twodistributions serves as an algorithm subroutine that empowers variousapplications. This paper develops a scalable first-order optimization-basedmethod that computes optimal transport to within $\varepsilon$ additiveaccuracy with runtime $\widetilde{O}( n^2/\varepsilon)$, where $n$ denotes thedimension of the probability distributions of interest. Our algorithm achievesthe state-of-the-art computational guarantees among all first-order methods,while exhibiting favorable numerical performance compared to classicalalgorithms like Sinkhorn and Greenkhorn. Underlying our algorithm designs aretwo key elements: (a) converting the original problem into a bilinear minimaxproblem over probability distributions; (b) exploiting the extragradient idea-- in conjunction with entropy regularization and adaptive learning rates -- toaccelerate convergence.</description><author>Gen Li, Yanxi Chen, Yu Huang, Yuejie Chi, H. Vincent Poor, Yuxin Chen</author><pubDate>Thu, 20 Jun 2024 16:13:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13006v2</guid></item><item><title>SEC-QA: A Systematic Evaluation Corpus for Financial QA</title><link>http://arxiv.org/abs/2406.14394v1</link><description>The financial domain frequently deals with large numbers of long documentsthat are essential for daily operations. Significant effort is put towardsautomating financial data analysis. However, a persistent challenge, notlimited to the finance domain, is the scarcity of datasets that accuratelyreflect real-world tasks for model evaluation. Existing datasets are oftenconstrained by size, context, or relevance to practical applications. Moreover,LLMs are currently trained on trillions of tokens of text, limiting access tonovel data or documents that models have not encountered during training forunbiased evaluation. We propose SEC-QA, a continuous dataset generationframework with two key features: 1) the semi-automatic generation ofQuestion-Answer (QA) pairs spanning multiple long context financial documents,which better represent real-world financial scenarios; 2) the ability tocontinually refresh the dataset using the most recent public documentcollections, not yet ingested by LLMs. Our experiments show that currentretrieval augmented generation methods systematically fail to answer thesechallenging multi-document questions. In response, we introduce a QA systembased on program-of-thought that improves the ability to perform complexinformation retrieval and quantitative reasoning pipelines, thereby increasingQA accuracy.</description><author>Viet Dac Lai, Michael Krumdick, Charles Lovering, Varshini Reddy, Craig Schmidt, Chris Tanner</author><pubDate>Thu, 20 Jun 2024 16:12:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14394v1</guid></item><item><title>Jailbreaking as a Reward Misspecification Problem</title><link>http://arxiv.org/abs/2406.14393v1</link><description>The widespread adoption of large language models (LLMs) has raised concernsabout their safety and reliability, particularly regarding their vulnerabilityto adversarial attacks. In this paper, we propose a novel perspective thatattributes this vulnerability to reward misspecification during the alignmentprocess. We introduce a metric ReGap to quantify the extent of rewardmisspecification and demonstrate its effectiveness and robustness in detectingharmful backdoor prompts. Building upon these insights, we present ReMiss, asystem for automated red teaming that generates adversarial prompts againstvarious target aligned LLMs. ReMiss achieves state-of-the-art attack successrates on the AdvBench benchmark while preserving the human readability of thegenerated prompts. Detailed analysis highlights the unique advantages broughtby the proposed reward misspecification objective compared to previous methods.</description><author>Zhihui Xie, Jiahui Gao, Lei Li, Zhenguo Li, Qi Liu, Lingpeng Kong</author><pubDate>Thu, 20 Jun 2024 16:12:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14393v1</guid></item></channel></rss>