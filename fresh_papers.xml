<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 12 Jul 2024 01:00:20 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>High-Precision, Fair University Course Scheduling During a Pandemic</title><link>http://arxiv.org/abs/2407.07355v2</link><description>Scheduling university courses is extra challenging when classroom capacitiesare reduced because of social distancing requirements that are implemented inresponse to a pandemic such as COVID-19. In this work, we propose an expandedtaxonomy of course delivery modes, present an integer program, and develop acourse scheduling algorithm to enable all course sections -- even the largest-- to have a significant classroom learning component during a pandemic. Ourapproach is fair by ensuring that a certain fraction of the instruction inevery course section occurs in the classroom. Unlike previous studies, we donot allow rotating attendance and instead require simultaneous attendance inwhich all students in a section meet in 1-5 rooms at the same time but lessoften than in a normal semester. These mass meetings, which createopportunities for in-person midterm exams and group activities, are scheduledat high precision across all days of the semester rather than a single,repeating week. A fast heuristic algorithm makes the schedule in an hour.Results: We consider the 1834 in-person course sections, 172 classrooms, and 96days in the fall 2022 semester at [UniversityXYZ]. If average classroomcapacity is reduced by 75% due to a pandemic, our approach still allows atleast 25% of the instruction in every section, and more than 49% of allinstruction across the entire campus, to be in the classroom. Our method alsoproduces excellent results for regular classroom assignment. Managerialimplications: An algorithm based on the principles of fairness and simultaneousattendance can significantly improve university course schedules during apandemic and in normal times. High-precision schedules that prepare a campusfor various pandemic possibilities can be created with minimal administrativeeffort and activated at a moment's notice before or during a semester if anoutbreak occurs.</description><author>Matthew E. H. Petering, Mohammad Khamechian</author><pubDate>Thu, 11 Jul 2024 17:56:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07355v2</guid></item><item><title>BiGym: A Demo-Driven Mobile Bi-Manual Manipulation Benchmark</title><link>http://arxiv.org/abs/2407.07788v2</link><description>We introduce BiGym, a new benchmark and learning environment for mobilebi-manual demo-driven robotic manipulation. BiGym features 40 diverse tasks setin home environments, ranging from simple target reaching to complex kitchencleaning. To capture the real-world performance accurately, we providehuman-collected demonstrations for each task, reflecting the diverse modalitiesfound in real-world robot trajectories. BiGym supports a variety ofobservations, including proprioceptive data and visual inputs such as RGB, anddepth from 3 camera views. To validate the usability of BiGym, we thoroughlybenchmark the state-of-the-art imitation learning algorithms and demo-drivenreinforcement learning algorithms within the environment and discuss the futureopportunities.</description><author>Nikita Chernyadev, Nicholas Backshall, Xiao Ma, Yunfan Lu, Younggyo Seo, Stephen James</author><pubDate>Thu, 11 Jul 2024 16:26:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07788v2</guid></item><item><title>Toto: Time Series Optimized Transformer for Observability</title><link>http://arxiv.org/abs/2407.07874v2</link><description>This technical report describes the Time Series Optimized Transformer forObservability (Toto), a new state of the art foundation model for time seriesforecasting developed by Datadog. In addition to advancing the state of the arton generalized time series benchmarks in domains such as electricity andweather, this model is the first general-purpose time series forecastingfoundation model to be specifically tuned for observability metrics. Toto was trained on a dataset of one trillion time series data points, thelargest among all currently published time series foundation models. Alongsidepublicly available time series datasets, 75% of the data used to train Totoconsists of fully anonymous numerical metric data points from the Datadogplatform. In our experiments, Toto outperforms existing time series foundation modelson observability data. It does this while also excelling at general-purposeforecasting tasks, achieving state-of-the-art zero-shot performance on multipleopen benchmark datasets.</description><author>Ben Cohen, Emaad Khwaja, Kan Wang, Charles Masson, Elise Ramé, Youssef Doubli, Othmane Abou-Amal</author><pubDate>Thu, 11 Jul 2024 16:18:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07874v2</guid></item><item><title>A Clinical Benchmark of Public Self-Supervised Pathology Foundation Models</title><link>http://arxiv.org/abs/2407.06508v3</link><description>The use of self-supervised learning (SSL) to train pathology foundationmodels has increased substantially in the past few years. Notably, severalmodels trained on large quantities of clinical data have been made publiclyavailable in recent months. This will significantly enhance scientific researchin computational pathology and help bridge the gap between research andclinical deployment. With the increase in availability of public foundationmodels of different sizes, trained using different algorithms on differentdatasets, it becomes important to establish a benchmark to compare theperformance of such models on a variety of clinically relevant tasks spanningmultiple organs and diseases. In this work, we present a collection ofpathology datasets comprising clinical slides associated with clinicallyrelevant endpoints including cancer diagnoses and a variety of biomarkersgenerated during standard hospital operation from two medical centers. Weleverage these datasets to systematically assess the performance of publicpathology foundation models and provide insights into best practices fortraining new foundation models and selecting appropriate pretrained models.</description><author>Gabriele Campanella, Shengjia Chen, Ruchika Verma, Jennifer Zeng, Aryeh Stock, Matt Croken, Brandon Veremis, Abdulkadir Elmas, Kuan-lin Huang, Ricky Kwan, Jane Houldsworth, Adam J. Schoenfeld, Chad Vanderbilt</author><pubDate>Thu, 11 Jul 2024 16:16:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06508v3</guid></item><item><title>On Leakage of Code Generation Evaluation Datasets</title><link>http://arxiv.org/abs/2407.07565v2</link><description>In this paper we consider contamination by code generation test sets, inparticular in their use in modern large language models. We discuss threepossible sources of such contamination and show findings supporting each ofthem: (i) direct data leakage, (ii) indirect data leakage through the use ofsynthetic data and (iii) overfitting to evaluation sets during model selection.Key to our findings is a new dataset of 161 prompts with their associatedpython solutions, dataset which is released athttps://huggingface.co/datasets/CohereForAI/lbpp .</description><author>Alexandre Matton, Tom Sherborne, Dennis Aumiller, Elena Tommasone, Milad Alizadeh, Jingyi He, Raymond Ma, Maxime Voisin, Ellen Gilsenan-McMahon, Matthias Gallé</author><pubDate>Thu, 11 Jul 2024 15:37:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07565v2</guid></item><item><title>DiffuseHigh: Training-free Progressive High-Resolution Image Synthesis through Structure Guidance</title><link>http://arxiv.org/abs/2406.18459v4</link><description>Recent surge in large-scale generative models has spurred the development ofvast fields in computer vision. In particular, text-to-image diffusion modelshave garnered widespread adoption across diverse domain due to their potentialfor high-fidelity image generation. Nonetheless, existing large-scale diffusionmodels are confined to generate images of up to 1K resolution, which is farfrom meeting the demands of contemporary commercial applications. Directlysampling higher-resolution images often yields results marred by artifacts suchas object repetition and distorted shapes. Addressing the aforementioned issuestypically necessitates training or fine-tuning models on higher resolutiondatasets. However, this undertaking poses a formidable challenge due to thedifficulty in collecting large-scale high-resolution contents and substantialcomputational resources. While several preceding works have proposedalternatives, they often fail to produce convincing results. In this work, weprobe the generative ability of diffusion models at higher resolution beyondits original capability and propose a novel progressive approach that fullyutilizes generated low-resolution image to guide the generation of higherresolution image. Our method obviates the need for additional training orfine-tuning which significantly lowers the burden of computational costs.Extensive experiments and results validate the efficiency and efficacy of ourmethod. Project page: https://yhyun225.github.io/DiffuseHigh/</description><author>Younghyun Kim, Geunmin Hwang, Junyu Zhang, Eunbyung Park</author><pubDate>Thu, 11 Jul 2024 15:03:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18459v4</guid></item><item><title>Using Natural Language Explanations to Rescale Human Judgments</title><link>http://arxiv.org/abs/2305.14770v4</link><description>The rise of large language models (LLMs) has brought a critical need forhigh-quality human-labeled data, particularly for processes like human feedbackand evaluation. A common practice is to label data via consensus annotationover human judgments. However, annotators' judgments for subjective tasks candiffer in many ways: they may reflect different qualitative judgments about anexample, and they may be mapped to a labeling scheme in different ways. We showthat these nuances can be captured by natural language explanations, andpropose a method to rescale ordinal annotations and explanations using LLMs.Specifically, we feed annotators' Likert ratings and corresponding explanationsinto an LLM and prompt it to produce a numeric score anchored in a scoringrubric. These scores should reflect the annotators' underlying assessments ofthe example. The rubric can be designed or modified after annotation, andinclude distinctions that may not have been known when the original errortaxonomy was devised. We explore our technique in the context of rating systemoutputs for a document-grounded question answering task, where LLMs achievenear-human performance. Our method rescales the raw judgments without impactingagreement and brings the scores closer to human judgments grounded in the samescoring rubric.</description><author>Manya Wadhwa, Jifan Chen, Junyi Jessy Li, Greg Durrett</author><pubDate>Thu, 11 Jul 2024 14:47:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14770v4</guid></item><item><title>An Improved Traditional Chinese Evaluation Suite for Foundation Model</title><link>http://arxiv.org/abs/2403.01858v3</link><description>We present TMMLU+, a new benchmark designed for Traditional Chinese languageunderstanding. TMMLU+ is a multi-choice question-answering dataset with 66subjects from elementary to professional level. It is six times larger andboasts a more balanced subject distribution than its predecessor, TaiwanMassive Multitask Language Understanding (TMMLU). We also benchmarkclosed-source models and 26 open-weight Chinese large language models (LLMs) ofparameters ranging from 1.8B to 72B on the proposed TMMLU+. Our findings revealthat (1.) Traditional Chinese models still trail behind their SimplifiedChinese counterparts, highlighting a need for more focused advancements in LLMscatering to Traditional Chinese. (2.) Current LLMs still fall short of humanperformance in average scores, indicating a potential need for future researchto delve deeper into social science and humanities subjects. (3.) Among all thetokenization compression metrics examined, we identify that only the fertilityscore uniquely demonstrates strong correlations with our benchmark results. Weforesee that TMMLU+ will pinpoint areas for future model improvement, therebynarrowing the gap between machine and human linguistic capabilities andsupporting researchers in developing Traditional Chinese LLMs. Our dataset,along with the benchmark source code, is accessible athuggingface.co/datasets/ikala/tmmluplus.</description><author>Zhi-Rui Tam, Ya-Ting Pai, Yen-Wei Lee, Jun-Da Chen, Wei-Min Chu, Sega Cheng, Hong-Han Shuai</author><pubDate>Thu, 11 Jul 2024 14:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.01858v3</guid></item><item><title>Trainable Highly-expressive Activation Functions</title><link>http://arxiv.org/abs/2407.07564v2</link><description>Nonlinear activation functions are pivotal to the success of deep neuralnets, and choosing the appropriate activation function can significantly affecttheir performance. Most networks use fixed activation functions (e.g., ReLU,GELU, etc.), and this choice might limit their expressiveness. Furthermore,different layers may benefit from diverse activation functions. Consequently,there has been a growing interest in trainable activation functions. In thispaper, we introduce DiTAC, a trainable highly-expressive activation functionbased on an efficient diffeomorphic transformation (called CPAB). Despiteintroducing only a negligible number of trainable parameters, DiTAC enhancesmodel expressiveness and performance, often yielding substantial improvements.It also outperforms existing activation functions (regardless whether thelatter are fixed or trainable) in tasks such as semantic segmentation, imagegeneration, regression problems, and image classification. Our code isavailable at https://github.com/BGU-CS-VIL/DiTAC.</description><author>Irit Chelly, Shahaf E. Finder, Shira Ifergane, Oren Freifeld</author><pubDate>Thu, 11 Jul 2024 11:47:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07564v2</guid></item><item><title>MARS: Mixture of Auto-Regressive Models for Fine-grained Text-to-image Synthesis</title><link>http://arxiv.org/abs/2407.07614v2</link><description>Auto-regressive models have made significant progress in the realm oflanguage generation, yet they do not perform on par with diffusion models inthe domain of image synthesis. In this work, we introduce MARS, a novelframework for T2I generation that incorporates a specially designed SemanticVision-Language Integration Expert (SemVIE). This innovative componentintegrates pre-trained LLMs by independently processing linguistic and visualinformation, freezing the textual component while fine-tuning the visualcomponent. This methodology preserves the NLP capabilities of LLMs whileimbuing them with exceptional visual understanding. Building upon the powerfulbase of the pre-trained Qwen-7B, MARS stands out with its bilingual generativecapabilities corresponding to both English and Chinese language prompts and thecapacity for joint image and text generation. The flexibility of this frameworklends itself to migration towards any-to-any task adaptability. Furthermore,MARS employs a multi-stage training strategy that first establishes robustimage-text alignment through complementary bidirectional tasks and subsequentlyconcentrates on refining the T2I generation process, significantly augmentingtext-image synchrony and the granularity of image details. Notably, MARSrequires only 9% of the GPU days needed by SD1.5, yet it achieves remarkableresults across a variety of benchmarks, illustrating the training efficiencyand the potential for swift deployment in various applications.</description><author>Wanggui He, Siming Fu, Mushui Liu, Xierui Wang, Wenyi Xiao, Fangxun Shu, Yi Wang, Lei Zhang, Zhelun Yu, Haoyuan Li, Ziwei Huang, LeiLei Gan, Hao Jiang</author><pubDate>Thu, 11 Jul 2024 11:05:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07614v2</guid></item><item><title>FALFormer: Feature-aware Landmarks self-attention for Whole-slide Image Classification</title><link>http://arxiv.org/abs/2407.07340v2</link><description>Slide-level classification for whole-slide images (WSIs) has been widelyrecognized as a crucial problem in digital and computational pathology. Currentapproaches commonly consider WSIs as a bag of cropped patches and process themvia multiple instance learning due to the large number of patches, which cannotfully explore the relationship among patches; in other words, the globalinformation cannot be fully incorporated into decision making. Herein, wepropose an efficient and effective slide-level classification model, named asFALFormer, that can process a WSI as a whole so as to fully exploit therelationship among the entire patches and to improve the classificationperformance. FALFormer is built based upon Transformers and self-attentionmechanism. To lessen the computational burden of the original self-attentionmechanism and to process the entire patches together in a WSI, FALFormeremploys Nystr\"om self-attention which approximates the computation by using asmaller number of tokens or landmarks. For effective learning, FALFormerintroduces feature-aware landmarks to enhance the representation power of thelandmarks and the quality of the approximation. We systematically evaluate theperformance of FALFormer using two public datasets, including CAMELYON16 andTCGA-BRCA. The experimental results demonstrate that FALFormer achievessuperior performance on both datasets, outperforming the state-of-the-artmethods for the slide-level classification. This suggests that FALFormer canfacilitate an accurate and precise analysis of WSIs, potentially leading toimproved diagnosis and prognosis on WSIs.</description><author>Doanh C. Bui, Trinh Thi Le Vuong, Jin Tae Kwak</author><pubDate>Thu, 11 Jul 2024 09:36:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07340v2</guid></item><item><title>Early Explorations of Lightweight Models for Wound Segmentation on Mobile Devices</title><link>http://arxiv.org/abs/2407.07605v2</link><description>The aging population poses numerous challenges to healthcare, including theincrease in chronic wounds in the elderly. The current approach to woundassessment by therapists based on photographic documentation is subjective,highlighting the need for computer-aided wound recognition from smartphonephotos. This offers objective and convenient therapy monitoring, while beingaccessible to patients from their home at any time. However, despite researchin mobile image segmentation, there is a lack of focus on mobile woundsegmentation. To address this gap, we conduct initial research on threelightweight architectures to investigate their suitability for smartphone-basedwound segmentation. Using public datasets and UNet as a baseline, our resultsare promising, with both ENet and TopFormer, as well as the larger UNeXtvariant, showing comparable performance to UNet. Furthermore, we deploy themodels into a smartphone app for visual assessment of live segmentation, whereresults demonstrate the effectiveness of TopFormer in distinguishing woundsfrom wound-coloured objects. While our study highlights the potential oftransformer models for mobile wound segmentation, future work should aim tofurther improve the mask contours.</description><author>Vanessa Borst, Timo Dittus, Konstantin Müller, Samuel Kounev</author><pubDate>Thu, 11 Jul 2024 08:01:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07605v2</guid></item><item><title>HiLight: Technical Report on the Motern AI Video Language Model</title><link>http://arxiv.org/abs/2407.07325v2</link><description>This technical report presents the implementation of a state-of-the-art videoencoder for video-text modal alignment and a video conversation frameworkcalled HiLight, which features dual visual towers. The work is divided into twomain parts: 1.alignment of video and text modalities; 2.convenient andefficient way to interact with users. Our goal is to address the task of videocomprehension in the context of billiards. The report includes a discussion ofthe concepts and the final solution developed during the task's implementation.</description><author>Zhiting Wang, Qiangong Zhou, Kangjie Yang, Zongyang Liu, Xin Mao</author><pubDate>Thu, 11 Jul 2024 07:44:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07325v2</guid></item><item><title>Progressive Growing of Patch Size: Resource-Efficient Curriculum Learning for Dense Prediction Tasks</title><link>http://arxiv.org/abs/2407.07853v2</link><description>In this work, we introduce Progressive Growing of Patch Size, aresource-efficient implicit curriculum learning approach for dense predictiontasks. Our curriculum approach is defined by growing the patch size duringmodel training, which gradually increases the task's difficulty. We integratedour curriculum into the nnU-Net framework and evaluated the methodology on all10 tasks of the Medical Segmentation Decathlon. With our approach, we are ableto substantially reduce runtime, computational costs, and CO2 emissions ofnetwork training compared to classical constant patch size training. In ourexperiments, the curriculum approach resulted in improved convergence. We areable to outperform standard nnU-Net training, which is trained with constantpatch size, in terms of Dice Score on 7 out of 10 MSD tasks while only spendingroughly 50% of the original training runtime. To the best of our knowledge, ourProgressive Growing of Patch Size is the first successful employment of asample-length curriculum in the form of patch size in the field of computervision. Our code is publicly available athttps://github.com/compai-lab/2024-miccai-fischer.</description><author>Stefan M. Fischer, Lina Felsner, Richard Osuala, Johannes Kiechle, Daniel M. Lang, Jan C. Peeken, Julia A. Schnabel</author><pubDate>Thu, 11 Jul 2024 07:35:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07853v2</guid></item><item><title>Gated Ensemble of Spatio-temporal Mixture of Experts for Multi-task Learning in Ride-hailing System</title><link>http://arxiv.org/abs/2012.15408v5</link><description>Ride-hailing system requires efficient management of dynamic demand andsupply to ensure optimal service delivery, pricing strategies, and operationalefficiency. Designing spatio-temporal forecasting models separately in atask-wise and city-wise manner to forecast demand and supply-demand gap in aride-hailing system poses a burden for the expanding transportation networkcompanies. Therefore, a multi-task learning architecture is proposed in thisstudy by developing gated ensemble of spatio-temporal mixture of expertsnetwork (GESME-Net) with convolutional recurrent neural network (CRNN),convolutional neural network (CNN), and recurrent neural network (RNN) forsimultaneously forecasting these spatio-temporal tasks in a city as well asacross different cities. Furthermore, a task adaptation layer is integratedwith the architecture for learning joint representation in multi-task learningand revealing the contribution of the input features utilized in prediction.The proposed architecture is tested with data from Didi Chuxing for: (i)simultaneously forecasting demand and supply-demand gap in Beijing, and (ii)simultaneously forecasting demand across Chengdu and Xian. In both scenarios,models from our proposed architecture outperformed the single-task andmulti-task deep learning benchmarks and ensemble-based machine learningalgorithms.</description><author>M. H. Rahman, S. M. Rifaat, S. N. Sadeek, M. Abrar, D. Wang</author><pubDate>Thu, 11 Jul 2024 06:18:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2012.15408v5</guid></item><item><title>GLBench: A Comprehensive Benchmark for Graph with Large Language Models</title><link>http://arxiv.org/abs/2407.07457v2</link><description>The emergence of large language models (LLMs) has revolutionized the way weinteract with graphs, leading to a new paradigm called GraphLLM. Despite therapid development of GraphLLM methods in recent years, the progress andunderstanding of this field remain unclear due to the lack of a benchmark withconsistent experimental protocols. To bridge this gap, we introduce GLBench,the first comprehensive benchmark for evaluating GraphLLM methods in bothsupervised and zero-shot scenarios. GLBench provides a fair and thoroughevaluation of different categories of GraphLLM methods, along with traditionalbaselines such as graph neural networks. Through extensive experiments on acollection of real-world datasets with consistent data processing and splittingstrategies, we have uncovered several key findings. Firstly, GraphLLM methodsoutperform traditional baselines in supervised settings, with LLM-as-enhancersshowing the most robust performance. However, using LLMs as predictors is lesseffective and often leads to uncontrollable output issues. We also notice thatno clear scaling laws exist for current GraphLLM methods. In addition, bothstructures and semantics are crucial for effective zero-shot transfer, and ourproposed simple baseline can even outperform several models tailored forzero-shot scenarios. The data and code of the benchmark can be found athttps://github.com/NineAbyss/GLBench.</description><author>Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li</author><pubDate>Thu, 11 Jul 2024 06:06:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07457v2</guid></item><item><title>Tuning Vision-Language Models with Candidate Labels by Prompt Alignment</title><link>http://arxiv.org/abs/2407.07638v2</link><description>Vision-language models (VLMs) can learn high-quality representations from alarge-scale training dataset of image-text pairs. Prompt learning is a popularapproach to fine-tuning VLM to adapt them to downstream tasks. Despite thesatisfying performance, a major limitation of prompt learning is the demand forlabelled data. In real-world scenarios, we may only obtain candidate labels(where the true label is included) instead of the true labels due to dataprivacy or sensitivity issues. In this paper, we provide the first study onprompt learning with candidate labels for VLMs. We empirically demonstrate thatprompt learning is more advantageous than other fine-tuning methods, forhandling candidate labels. Nonetheless, its performance drops when the labelambiguity increases. In order to improve its robustness, we propose a simpleyet effective framework that better leverages the prior knowledge of VLMs toguide the learning process with candidate labels. Specifically, our frameworkdisambiguates candidate labels by aligning the model output with the mixedclass posterior jointly predicted by both the learnable and the handcraftedprompt. Besides, our framework can be equipped with various off-the-shelftraining objectives for learning with candidate labels to further improve theirperformance. Extensive experiments demonstrate the effectiveness of ourproposed framework.</description><author>Zhifang Zhang, Beibei Li</author><pubDate>Thu, 11 Jul 2024 04:46:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07638v2</guid></item><item><title>Missile detection and destruction robot using detection algorithm</title><link>http://arxiv.org/abs/2407.07452v2</link><description>This research is based on the present missile detection technologies in theworld and the analysis of these technologies to find a cost effective solutionto implement the system in Bangladesh. The paper will give an idea of themissile detection technologies using the electro-optical sensor and the pulsedoppler radar. The system is made to detect the target missile. Automaticdetection and destruction with the help of ultrasonic sonar, a metal detectorsensor, and a smoke detector sensor. The system is mainly based on anultrasonic sonar sensor. It has a transducer, a transmitter, and a receiver.Transducer is connected with the connected with controller. When it detects anobject by following the algorithm, it finds its distance and angle. It can alsoassure whether the system can destroy the object or not by using anotheralgorithm's simulation.</description><author>Md Kamrul Siam, Shafayet Ahmed, Md Habibur Rahman, Amir Hossain Mollah</author><pubDate>Thu, 11 Jul 2024 04:18:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07452v2</guid></item><item><title>A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment</title><link>http://arxiv.org/abs/2403.10854v3</link><description>While Multimodal Large Language Models (MLLMs) have experienced significantadvancement in visual understanding and reasoning, their potential to serve aspowerful, flexible, interpretable, and text-driven models for Image QualityAssessment (IQA) remains largely unexplored. In this paper, we conduct acomprehensive and systematic study of prompting MLLMs for IQA. We firstinvestigate nine prompting systems for MLLMs as the combinations of threestandardized testing procedures in psychophysics (i.e., the single-stimulus,double-stimulus, and multiple-stimulus methods) and three popular promptingstrategies in natural language processing (i.e., the standard, in-context, andchain-of-thought prompting). We then present a difficult sample selectionprocedure, taking into account sample diversity and uncertainty, to furtherchallenge MLLMs equipped with the respective optimal prompting systems. Weassess three open-source and one closed-source MLLMs on several visualattributes of image quality (e.g., structural and textural distortions,geometric transformations, and color differences) in both full-reference andno-reference scenarios. Experimental results show that only the closed-sourceGPT-4V provides a reasonable account for human perception of image quality, butis weak at discriminating fine-grained quality variations (e.g., colordifferences) and at comparing visual quality of multiple images, tasks humanscan perform effortlessly.</description><author>Tianhe Wu, Kede Ma, Jie Liang, Yujiu Yang, Lei Zhang</author><pubDate>Thu, 11 Jul 2024 04:11:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.10854v3</guid></item><item><title>From Supervised to Generative: A Novel Paradigm for Tabular Deep Learning with Large Language Models</title><link>http://arxiv.org/abs/2310.07338v4</link><description>Tabular data is foundational to predictive modeling in various crucialindustries, including healthcare, finance, retail, sustainability, etc. Despitethe progress made in specialized models, there is an increasing demand foruniversal models that can transfer knowledge, generalize from limited data, andfollow human instructions. These are challenges that current tabular deeplearning approaches have not fully tackled. Here we introduce GenerativeTabular Learning (GTL), a novel framework that integrates the advancedfunctionalities of large language models (LLMs)-such as prompt-based zero-shotgeneralization and in-context learning-into tabular deep learning. GTLcapitalizes on the pre-training of LLMs on diverse tabular data, enhancingtheir understanding of domain-specific knowledge, numerical sequences, andstatistical dependencies critical for accurate predictions. Our empirical studyspans 384 public datasets, rigorously analyzing GTL's convergence and scalingbehaviors and assessing the impact of varied data templates. The GTL-enhancedLLaMA-2 model demonstrates superior zero-shot and in-context learningcapabilities across numerous classification and regression tasks. Notably, itachieves this without fine-tuning, outperforming traditional methods andrivaling state-of-the-art models like GPT-4 in certain cases. Through GTL, wenot only foster a deeper integration of LLMs' sophisticated abilities intotabular data comprehension and application but also offer a new trainingresource and a test bed for LLMs to enhance their ability to comprehend tabulardata. To facilitate reproducible research, we release our code, data, and modelcheckpoints at https://github.com/microsoft/Industrial-Foundation-Models.</description><author>Xumeng Wen, Han Zhang, Shun Zheng, Wei Xu, Jiang Bian</author><pubDate>Thu, 11 Jul 2024 04:09:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07338v4</guid></item><item><title>Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard</title><link>http://arxiv.org/abs/2407.07796v2</link><description>We introduce a novel and extensible benchmark for large language models(LLMs) through grid-based games such as Tic-Tac-Toe, Connect Four, and Gomoku.The open-source game simulation code, available on GitHub, allows LLMs tocompete and generates detailed data files in JSON, CSV, TXT, and PNG formatsfor leaderboard rankings and further analysis. We present the results of gamesamong leading LLMs, including Claude 3.5 Sonnet and Claude 3 Sonnet byAnthropic, Gemini 1.5 Pro and Gemini 1.5 Flash by Google, GPT-4 Turbo andGPT-4o by OpenAI, and Llama3-70B by Meta. We also encourage submissions ofresults from other LLMs. In total, we simulated 2,310 matches (5 sessions foreach pair among 7 LLMs and a random player) across three types of games, usingthree distinct prompt types: list, illustration, and image. The resultsrevealed significant variations in LLM performance across different games andprompt types, with analysis covering win and disqualification rates, missedopportunity analysis, and invalid move analysis. The details of the leaderboardand result matrix data are available as open-access data on GitHub. This studyenhances our understanding of LLMs' capabilities in playing games they were notspecifically trained for, helping to assess their rule comprehension andstrategic thinking. On the path to Artificial General Intelligence (AGI), thisstudy lays the groundwork for future exploration into their utility in complexdecision-making scenarios, illuminating their strategic thinking abilities andoffering directions for further inquiry into the limits of LLMs withingame-based frameworks.</description><author>Oguzhan Topsakal, Colby Jacob Edell, Jackson Bailey Harper</author><pubDate>Thu, 11 Jul 2024 03:46:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07796v2</guid></item><item><title>InstructLayout: Instruction-Driven 2D and 3D Layout Synthesis with Semantic Graph Prior</title><link>http://arxiv.org/abs/2407.07580v2</link><description>Comprehending natural language instructions is a charming property for both2D and 3D layout synthesis systems. Existing methods implicitly model objectjoint distributions and express object relations, hindering generation'scontrollability. We introduce InstructLayout, a novel generative framework thatintegrates a semantic graph prior and a layout decoder to improvecontrollability and fidelity for 2D and 3D layout synthesis. The proposedsemantic graph prior learns layout appearances and object distributionssimultaneously, demonstrating versatility across various downstream tasks in azero-shot manner. To facilitate the benchmarking for text-driven 2D and 3Dscene synthesis, we respectively curate two high-quality datasets oflayout-instruction pairs from public Internet resources with large language andmultimodal models. Extensive experimental results reveal that the proposedmethod outperforms existing state-of-the-art approaches by a large margin inboth 2D and 3D layout synthesis tasks. Thorough ablation studies confirm theefficacy of crucial design components.</description><author>Chenguo Lin, Yuchen Lin, Panwang Pan, Xuanyang Zhang, Yadong Mu</author><pubDate>Thu, 11 Jul 2024 03:19:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07580v2</guid></item><item><title>Entropy Law: The Story Behind Data Compression and LLM Performance</title><link>http://arxiv.org/abs/2407.06645v3</link><description>Data is the cornerstone of large language models (LLMs), but not all data isuseful for model learning. Carefully selected data can better elicit thecapabilities of LLMs with much less computational overhead. Most methodsconcentrate on evaluating the quality of individual samples in data selection,while the combinatorial effects among samples are neglected. Even if eachsample is of perfect quality, their combinations may be suboptimal in teachingLLMs due to their intrinsic homogeneity or contradiction. In this paper, we aimto uncover the underlying relationships between LLM performance and dataselection. Inspired by the information compression nature of LLMs, we uncoveran ``entropy law'' that connects LLM performance with data compression ratioand first-epoch training loss, which reflect the information redundancy of adataset and the mastery of inherent knowledge encoded in this dataset,respectively. Through both theoretical deduction and empirical evaluation, wefind that model performance is negatively correlated to the compression ratioof training data, which usually yields a lower training loss. Based on thefindings of the entropy law, we propose a quite efficient and universal dataselection method named \textbf{ZIP} for training LLMs, which aim to prioritizedata subsets exhibiting a low compression ratio. Based on a multi-stagealgorithm that selects diverse data in a greedy manner, we can obtain a gooddata subset with satisfactory diversity. Extensive experiments have beenconducted to validate the entropy law and the superiority of ZIP acrossdifferent LLM backbones and alignment stages. We also present an interestingapplication of entropy law that can detect potential performance risks at thebeginning of model training.</description><author>Mingjia Yin, Chuhan Wu, Yufei Wang, Hao Wang, Wei Guo, Yasheng Wang, Yong Liu, Ruiming Tang, Defu Lian, Enhong Chen</author><pubDate>Thu, 11 Jul 2024 03:06:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06645v3</guid></item><item><title>SaMoye: Zero-shot Singing Voice Conversion Based on Feature Disentanglement and Synthesis</title><link>http://arxiv.org/abs/2407.07728v2</link><description>Singing voice conversion (SVC) aims to convert a singer's voice in a givenmusic piece to another singer while keeping the original content. We propose anend-to-end feature disentanglement-based model, which we named SaMoye, toenable zero-shot many-to-many singing voice conversion. SaMoye disentangles thefeatures of the singing voice into content features, timbre features, and pitchfeatures respectively. The content features are enhanced using a GPT-basedmodel to perform cross-prediction with the phoneme of the lyrics. SaMoye cangenerate the music with converted voice by replacing the timbre features withthe target singer. We also establish an unparalleled large-scale dataset toguarantee zero-shot performance. The dataset consists of 1500k pure singingvocal clips containing at least 10,000 singers.</description><author>Zihao Wang, Le Ma, Yan Liu, Kejun Zhang</author><pubDate>Thu, 11 Jul 2024 03:06:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07728v2</guid></item><item><title>Metasurface-based Snapshot Shortwave-Infrared Hyperspectral Image Reconstruction with Inter and Intra Prior Learning Network</title><link>http://arxiv.org/abs/2407.07503v2</link><description>Shortwave-infrared(SWIR) spectral information,ranging from 1 {\mu}m to2.5{\mu}m, breaks the limitations of traditional color cameras in acquiringscene information and has been used in many fields. However, conventional SWIRhyperspectral imaging systems face challenges due to their bulky setups and lowacquisition speed. In this work, we introduce a snapshot SWIR hyperspectralimaging system based on a metasurface filter and a corresponding filterselection method to achieve the lowest correlation coefficient among thesefilters.This systemhas the advantages of small size and snapshot imaging. Wepropose a novel inter and intra prior learning unfolding framework proposed toachieve high-quality SWIR hyperspectral image reconstruction, which bridges thegap between prior learning and cross-stage information interaction. We alsodesign an adaptive feature transfer mechanism to adaptively the transfercontextual correlation of multi-scale encoder features to prevent detailedinformation loss in the decoder. Experiment results demonstrate that our methodcan reconstruct HSI with high speed and superior performance over existingmethods.</description><author>Linqiang Li, Jinglei Hao, Yongqiang Zhao, Pan Liu, Haofang Yan, Ziqin Zhang, Seong G. Kong</author><pubDate>Thu, 11 Jul 2024 02:49:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07503v2</guid></item><item><title>AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning</title><link>http://arxiv.org/abs/2407.07801v2</link><description>In recent years, advancements in representation learning and language modelshave propelled Automated Captioning (AC) to new heights, enabling thegeneration of human-level descriptions. Leveraging these advancements, wepropose AVCap, an Audio-Visual Captioning framework, a simple yet powerfulbaseline approach applicable to audio-visual captioning. AVCap utilizesaudio-visual features as text tokens, which has many advantages not only inperformance but also in the extensibility and scalability of the model. AVCapis designed around three pivotal dimensions: the exploration of optimalaudio-visual encoder architectures, the adaptation of pre-trained modelsaccording to the characteristics of generated text, and the investigation intothe efficacy of modality fusion in captioning. Our method outperforms existingaudio-visual captioning methods across all metrics and the code is available onhttps://github.com/JongSuk1/AVCap</description><author>Jongsuk Kim, Jiwon Shin, Junmo Kim</author><pubDate>Thu, 11 Jul 2024 02:38:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07801v2</guid></item><item><title>HAFormer: Unleashing the Power of Hierarchy-Aware Features for Lightweight Semantic Segmentation</title><link>http://arxiv.org/abs/2407.07441v2</link><description>Both Convolutional Neural Networks (CNNs) and Transformers have shown greatsuccess in semantic segmentation tasks. Efforts have been made to integrateCNNs with Transformer models to capture both local and global contextinteractions. However, there is still room for enhancement, particularly whenconsidering constraints on computational resources. In this paper, we introduceHAFormer, a model that combines the hierarchical features extraction ability ofCNNs with the global dependency modeling capability of Transformers to tacklelightweight semantic segmentation challenges. Specifically, we design aHierarchy-Aware Pixel-Excitation (HAPE) module for adaptive multi-scale localfeature extraction. During the global perception modeling, we devise anEfficient Transformer (ET) module streamlining the quadratic calculationsassociated with traditional Transformers. Moreover, a correlation-weightedFusion (cwF) module selectively merges diverse feature representations,significantly enhancing predictive accuracy. HAFormer achieves high performancewith minimal computational overhead and compact model size, achieving 74.2%mIoU on Cityscapes and 71.1% mIoU on CamVid test datasets, with frame rates of105FPS and 118FPS on a single 2080Ti GPU. The source codes are available athttps://github.com/XU-GITHUB-curry/HAFormer.</description><author>Guoan Xu, Wenjing Jia, Tao Wu, Ligeng Chen, Guangwei Gao</author><pubDate>Thu, 11 Jul 2024 02:19:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07441v2</guid></item><item><title>Pentagonal Photonic Crystal Mirrors: Scalable Lightsails with Enhanced Acceleration via Neural Topology Optimization</title><link>http://arxiv.org/abs/2407.07896v1</link><description>The Starshot Breakthrough Initiative aims to send one-gram microchip probesto Alpha Centauri within 20 years, using gram-scale lightsails propelled bylaser-based radiation pressure, reaching velocities nearing a fifth of lightspeed. This mission requires lightsail materials that challenge thefundamentals of nanotechnology, requiring innovations in optics, materialscience and structural engineering. Unlike the microchip payload, which must beminimized in every dimension, such lightsails need meter-scale dimensions withnanoscale thickness and billions of nanoscale holes to enhance reflectivity andreduce mass. Our study employs neural topology optimization, revealing a novelpentagonal lattice-based photonic crystal (PhC) reflector. The optimizeddesigns shorten acceleration times, therefore lowering launch costssignificantly. Crucially, these designs also enable lightsail materialfabrication with orders-of-magnitude reduction in costs. We have fabricated a60 x 60 mm$^2$, 200nm thick, single-layer reflector perforated with over abillion nanoscale features; the highest aspect-ratio nanophotonic element todate. We achieve this with nearly 9,000 times cost reduction per m$^2$.Starshot lightsails will have several stringent requirements but willultimately be driven by costs to build at scale. Here we highlight challengesand possible solutions in developing lightsail materials - showcasing thepotential of scaling nanophotonics for cost-effective next-generation spaceexploration.</description><author>L. Norder, S. Yin, M. J. de Jong, F. Stallone, H. Aydogmus, P. M. Sberna, M. A. Bessa, R. A. Norte</author><pubDate>Wed, 10 Jul 2024 17:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07896v1</guid></item><item><title>LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models</title><link>http://arxiv.org/abs/2407.07895v1</link><description>Visual instruction tuning has made considerable strides in enhancing thecapabilities of Large Multimodal Models (LMMs). However, existing open LMMslargely focus on single-image tasks, their applications to multi-imagescenarios remains less explored. Additionally, prior LMM research separatelytackles different scenarios, leaving it impossible to generalize crossscenarios with new emerging capabilities. To this end, we introduceLLaVA-NeXT-Interleave, which simultaneously tackles Multi-image, Multi-frame(video), Multi-view (3D), and Multi-patch (single-image) scenarios in LMMs. Toenable these capabilities, we regard the interleaved data format as a generaltemplate and compile the M4-Instruct dataset with 1,177.6k samples, spanning 4primary domains with 14 tasks and 41 datasets. We also curate theLLaVA-Interleave Bench to comprehensively evaluate the multi-image performanceof LMMs. Through extensive experiments, LLaVA-NeXT-Interleave achieves leadingresults in multi-image, video, and 3D benchmarks, while maintaining theperformance of single-image tasks. Besides, our model also exhibits severalemerging capabilities, e.g., transferring tasks across different settings andmodalities. Code is available at https://github.com/LLaVA-VL/LLaVA-NeXT</description><author>Feng Li, Renrui Zhang, Hao Zhang, Yuanhan Zhang, Bo Li, Wei Li, Zejun Ma, Chunyuan Li</author><pubDate>Wed, 10 Jul 2024 17:59:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07895v1</guid></item><item><title>Mitigating Bias in Dataset Distillation</title><link>http://arxiv.org/abs/2406.06609v2</link><description>Dataset Distillation has emerged as a technique for compressing largedatasets into smaller synthetic counterparts, facilitating downstream trainingtasks. In this paper, we study the impact of bias inside the original dataseton the performance of dataset distillation. With a comprehensive empiricalevaluation on canonical datasets with color, corruption and background biases,we found that color and background biases in the original dataset will beamplified through the distillation process, resulting in a notable decline inthe performance of models trained on the distilled dataset, while corruptionbias is suppressed through the distillation process. To reduce biasamplification in dataset distillation, we introduce a simple yet highlyeffective approach based on a sample reweighting scheme utilizing kerneldensity estimation. Empirical results on multiple real-world and syntheticdatasets demonstrate the effectiveness of the proposed method. Notably, onCMNIST with 5% bias-conflict ratio and IPC 50, our method achieves 91.5% testaccuracy compared to 23.8% from vanilla DM, boosting the performance by 67.7%,whereas applying state-of-the-art debiasing method on the same dataset onlyachieves 53.7% accuracy. Our findings highlight the importance of addressingbiases in dataset distillation and provide a promising avenue to address biasamplification in the process.</description><author>Justin Cui, Ruochen Wang, Yuanhao Xiong, Cho-Jui Hsieh</author><pubDate>Wed, 10 Jul 2024 17:58:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06609v2</guid></item><item><title>Training on the Test Task Confounds Evaluation and Emergence</title><link>http://arxiv.org/abs/2407.07890v1</link><description>We study a fundamental problem in the evaluation of large language modelsthat we call training on the test task. Unlike wrongful practices like trainingon the test data, leakage, or data contamination, training on the test task isnot a malpractice. Rather, the term describes a growing set of techniques toinclude task-relevant data in the pretraining stage of a language model. Wedemonstrate that training on the test task confounds both relative modelevaluations and claims about emergent capabilities. We argue that the seemingsuperiority of one model family over another may be explained by a differentdegree of training on the test task. To this end, we propose an effectivemethod to adjust for training on the test task by fine-tuning each model undercomparison on the same task-relevant data before evaluation. We then show thatinstances of emergent behavior largely vanish once we adjust for training onthe test task. This also applies to reported instances of emergent behaviorthat cannot be explained by the choice of evaluation metric. Our work promotesa new perspective on the evaluation of large language models with broadimplications for benchmarking and the study of emergent capabilities.</description><author>Ricardo Dominguez-Olmedo, Florian E. Dorner, Moritz Hardt</author><pubDate>Wed, 10 Jul 2024 17:57:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07890v1</guid></item><item><title>AdaptiGraph: Material-Adaptive Graph-Based Neural Dynamics for Robotic Manipulation</title><link>http://arxiv.org/abs/2407.07889v1</link><description>Predictive models are a crucial component of many robotic systems. Yet,constructing accurate predictive models for a variety of deformable objects,especially those with unknown physical properties, remains a significantchallenge. This paper introduces AdaptiGraph, a learning-based dynamicsmodeling approach that enables robots to predict, adapt to, and control a widearray of challenging deformable materials with unknown physical properties.AdaptiGraph leverages the highly flexible graph-based neural dynamics (GBND)framework, which represents material bits as particles and employs a graphneural network (GNN) to predict particle motion. Its key innovation is aunified physical property-conditioned GBND model capable of predicting themotions of diverse materials with varying physical properties withoutretraining. Upon encountering new materials during online deployment,AdaptiGraph utilizes a physical property optimization process for a few-shotadaptation of the model, enhancing its fit to the observed interaction data.The adapted models can precisely simulate the dynamics and predict the motionof various deformable materials, such as ropes, granular media, rigid boxes,and cloth, while adapting to different physical properties, includingstiffness, granular size, and center of pressure. On prediction andmanipulation tasks involving a diverse set of real-world deformable objects,our method exhibits superior prediction accuracy and task proficiency overnon-material-conditioned and non-adaptive models. The project page is availableat https://robopil.github.io/adaptigraph/ .</description><author>Kaifeng Zhang, Baoyu Li, Kris Hauser, Yunzhu Li</author><pubDate>Wed, 10 Jul 2024 17:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07889v1</guid></item><item><title>Is Your LLM Outdated? Evaluating LLMs at Temporal Generalization</title><link>http://arxiv.org/abs/2405.08460v2</link><description>The rapid advancement of Large Language Models (LLMs) highlights the urgentneed for evolving evaluation methodologies that keep pace with improvements inlanguage comprehension and information processing. However, traditionalbenchmarks, which are often static, fail to capture the continually changinginformation landscape, leading to a disparity between the perceived and actualeffectiveness of LLMs in ever-changing real-world scenarios. Our study examinestemporal generalization, which includes the ability to understand, predict, andgenerate text relevant to past, present, and future contexts, revealingsignificant temporal biases in LLMs. We propose an evaluation framework, fordynamically generating benchmarks from recent real-world predictions.Experiments demonstrate that LLMs struggle with temporal generalization,showing performance decline over time. These findings highlight the necessityfor improved training and updating processes to enhance adaptability and reducebiases. Our code, dataset and benchmark are available athttps://github.com/FreedomIntelligence/FreshBench.</description><author>Chenghao Zhu, Nuo Chen, Yufei Gao, Yunyi Zhang, Prayag Tiwari, Benyou Wang</author><pubDate>Wed, 10 Jul 2024 17:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08460v2</guid></item><item><title>Learning In-Hand Translation Using Tactile Skin With Shear and Normal Force Sensing</title><link>http://arxiv.org/abs/2407.07885v1</link><description>Recent progress in reinforcement learning (RL) and tactile sensing hassignificantly advanced dexterous manipulation. However, these methods oftenutilize simplified tactile signals due to the gap between tactile simulationand the real world. We introduce a sensor model for tactile skin that enableszero-shot sim-to-real transfer of ternary shear and binary normal forces. Usingthis model, we develop an RL policy that leverages sliding contact fordexterous in-hand translation. We conduct extensive real-world experiments toassess how tactile sensing facilitates policy adaptation to various unseenobject properties and robot hand orientations. We demonstrate that our 3-axistactile policies consistently outperform baselines that use only shear forces,only normal forces, or only proprioception. Website:https://jessicayin.github.io/tactile-skin-rl/</description><author>Jessica Yin, Haozhi Qi, Jitendra Malik, James Pikul, Mark Yim, Tess Hellebrekers</author><pubDate>Wed, 10 Jul 2024 17:52:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07885v1</guid></item><item><title>Vegetable Peeling: A Case Study in Constrained Dexterous Manipulation</title><link>http://arxiv.org/abs/2407.07884v1</link><description>Recent studies have made significant progress in addressing dexterousmanipulation problems, particularly in in-hand object reorientation. However,there are few existing works that explore the potential utilization ofdeveloped dexterous manipulation controllers for downstream tasks. In thisstudy, we focus on constrained dexterous manipulation for food peeling. Foodpeeling presents various constraints on the reorientation controller, such asthe requirement for the hand to securely hold the object after reorientationfor peeling. We propose a simple system for learning a reorientation controllerthat facilitates the subsequent peeling task. Videos are available at:https://taochenshh.github.io/projects/veg-peeling.</description><author>Tao Chen, Eric Cousineau, Naveen Kuppuswamy, Pulkit Agrawal</author><pubDate>Wed, 10 Jul 2024 17:51:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07884v1</guid></item><item><title>Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization</title><link>http://arxiv.org/abs/2407.07880v1</link><description>This study addresses the challenge of noise in training datasets for DirectPreference Optimization (DPO), a method for aligning Large Language Models(LLMs) with human preferences. We categorize noise into pointwise noise, whichincludes low-quality data points, and pairwise noise, which encompasseserroneous data pair associations that affect preference rankings. UtilizingDistributionally Robust Optimization (DRO), we enhance DPO's resilience tothese types of noise. Our theoretical insights reveal that DPO inherentlyembeds DRO principles, conferring robustness to pointwise noise, with theregularization coefficient $\beta$ playing a critical role in its noiseresistance. Extending this framework, we introduce DistributionallyRobustifying DPO (Dr. DPO), which integrates pairwise robustness by optimizingagainst worst-case pairwise scenarios. The novel hyperparameter $\beta'$ in Dr.DPO allows for fine-tuned control over data pair reliability, providing astrategic balance between exploration and exploitation in noisy trainingenvironments. Empirical evaluations demonstrate that Dr. DPO substantiallyimproves the quality of generated text and response accuracy in preferencedatasets, showcasing enhanced performance in both noisy and noise-freesettings. The code is available at https://github.com/junkangwu/Dr_DPO.</description><author>Junkang Wu, Yuexiang Xie, Zhengyi Yang, Jiancan Wu, Jiawei Chen, Jinyang Gao, Bolin Ding, Xiang Wang, Xiangnan He</author><pubDate>Wed, 10 Jul 2024 17:48:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07880v1</guid></item><item><title>Generative Image as Action Models</title><link>http://arxiv.org/abs/2407.07875v1</link><description>Image-generation diffusion models have been fine-tuned to unlock newcapabilities such as image-editing and novel view synthesis. Can we similarlyunlock image-generation models for visuomotor control? We present GENIMA, abehavior-cloning agent that fine-tunes Stable Diffusion to 'draw joint-actions'as targets on RGB images. These images are fed into a controller that maps thevisual targets into a sequence of joint-positions. We study GENIMA on 25RLBench and 9 real-world manipulation tasks. We find that, by lifting actionsinto image-space, internet pre-trained diffusion models can generate policiesthat outperform state-of-the-art visuomotor approaches, especially inrobustness to scene perturbations and generalizing to novel objects. Our methodis also competitive with 3D agents, despite lacking priors such as depth,keypoints, or motion-planners.</description><author>Mohit Shridhar, Yat Long Lo, Stephen James</author><pubDate>Wed, 10 Jul 2024 17:41:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07875v1</guid></item><item><title>Toto: Time Series Optimized Transformer for Observability</title><link>http://arxiv.org/abs/2407.07874v1</link><description>This technical report describes the Time Series Optimized Transformer forObservability (Toto), a new state of the art foundation model for time seriesforecasting developed by Datadog. In addition to advancing the state of the arton generalized time series benchmarks in domains such as electricity andweather, this model is the first general-purpose time series forecastingfoundation model to be specifically tuned for observability metrics. Toto wastrained on a dataset of one trillion time series data points, the largest amongall currently published time series foundation models. Alongside publiclyavailable time series datasets, 75% of the data used to train Toto consists offully anonymous numerical metric data points from the Datadog platform. In ourexperiments, Toto outperforms existing time series foundation models onobservability data. It does this while also excelling at general-purposeforecasting tasks, achieving state-of-the-art zero-shot performance on multipleopen benchmark datasets.</description><author>Ben Cohen, Emaad Khwaja, Kan Wang, Charles Masson, Elise Ramé, Youssef Doubli, Othmane Abou-Amal</author><pubDate>Wed, 10 Jul 2024 17:40:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07874v1</guid></item><item><title>Dynamical Measure Transport and Neural PDE Solvers for Sampling</title><link>http://arxiv.org/abs/2407.07873v1</link><description>The task of sampling from a probability density can be approached astransporting a tractable density function to the target, known as dynamicalmeasure transport. In this work, we tackle it through a principled unifiedframework using deterministic or stochastic evolutions described by partialdifferential equations (PDEs). This framework incorporates priortrajectory-based sampling methods, such as diffusion models or Schr\"odingerbridges, without relying on the concept of time-reversals. Moreover, it allowsus to propose novel numerical methods for solving the transport task and thussampling from complicated targets without the need for the normalizationconstant or data samples. We employ physics-informed neural networks (PINNs) toapproximate the respective PDE solutions, implying both conceptional andcomputational advantages. In particular, PINNs allow for simulation- anddiscretization-free optimization and can be trained very efficiently, leadingto significantly better mode coverage in the sampling task compared toalternative methods. Moreover, they can readily be fine-tuned with Gauss-Newtonmethods to achieve high accuracy in sampling.</description><author>Jingtong Sun, Julius Berner, Lorenz Richter, Marius Zeinhofer, Johannes Müller, Kamyar Azizzadenesheli, Anima Anandkumar</author><pubDate>Wed, 10 Jul 2024 17:39:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07873v1</guid></item><item><title>A Clinical Benchmark of Public Self-Supervised Pathology Foundation Models</title><link>http://arxiv.org/abs/2407.06508v2</link><description>The use of self-supervised learning (SSL) to train pathology foundationmodels has increased substantially in the past few years. Notably, severalmodels trained on large quantities of clinical data have been made publiclyavailable in recent months. This will significantly enhance scientific researchin computational pathology and help bridge the gap between research andclinical deployment. With the increase in availability of public foundationmodels of different sizes, trained using different algorithms on differentdatasets, it becomes important to establish a benchmark to compare theperformance of such models on a variety of clinically relevant tasks spanningmultiple organs and diseases. In this work, we present a collection ofpathology datasets comprising clinical slides associated with clinicallyrelevant endpoints including cancer diagnoses and a variety of biomarkersgenerated during standard hospital operation from two medical centers. Weleverage these datasets to systematically assess the performance of publicpathology foundation models and provide insights into best practices fortraining new foundation models and selecting appropriate pretrained models.</description><author>Gabriele Campanella, Shengjia Chen, Ruchika Verma, Jennifer Zeng, Aryeh Stock, Matt Croken, Brandon Veremis, Abdulkadir Elmas, Kuan-lin Huang, Ricky Kwan, Jane Houldsworth, Adam J. Schoenfeld, Chad Vanderbilt</author><pubDate>Wed, 10 Jul 2024 17:38:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06508v2</guid></item><item><title>Adaptive Multi-head Contrastive Learning</title><link>http://arxiv.org/abs/2310.05615v2</link><description>In contrastive learning, two views of an original image, generated bydifferent augmentations, are considered a positive pair, and their similarityis required to be high. Similarly, two views of distinct images form a negativepair, with encouraged low similarity. Typically, a single similarity measure,provided by a lone projection head, evaluates positive and negative samplepairs. However, due to diverse augmentation strategies and varying intra-samplesimilarity, views from the same image may not always be similar. Additionally,owing to inter-sample similarity, views from different images may be more akinthan those from the same image. Consequently, enforcing high similarity forpositive pairs and low similarity for negative pairs may be unattainable, andin some cases, such enforcement could detrimentally impact performance. Toaddress this challenge, we propose using multiple projection heads, eachproducing a distinct set of features. Our pre-training loss function emergesfrom a solution to the maximum likelihood estimation over head-wise posteriordistributions of positive samples given observations. This loss incorporatesthe similarity measure over positive and negative pairs, each re-weighted by anindividual adaptive temperature, regulated to prevent ill solutions. Ourapproach, Adaptive Multi-Head Contrastive Learning (AMCL), can be applied toand experimentally enhances several popular contrastive learning methods suchas SimCLR, MoCo, and Barlow Twins. The improvement remains consistent acrossvarious backbones and linear probing epochs, and becomes more significant whenemploying multiple augmentation methods.</description><author>Lei Wang, Piotr Koniusz, Tom Gedeon, Liang Zheng</author><pubDate>Wed, 10 Jul 2024 17:37:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05615v2</guid></item><item><title>Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents</title><link>http://arxiv.org/abs/2403.02502v2</link><description>Large Language Models (LLMs) have become integral components in variousautonomous agent systems. In this study, we present an exploration-basedtrajectory optimization approach, referred to as ETO. This learning method isdesigned to enhance the performance of open LLM agents. Contrary to previousstudies that exclusively train on successful expert trajectories, our methodallows agents to learn from their exploration failures. This leads to improvedperformance through an iterative optimization framework. During the explorationphase, the agent interacts with the environment while completing given tasks,gathering failure trajectories to create contrastive trajectory pairs. In thesubsequent training phase, the agent utilizes these trajectory preference pairsto update its policy using contrastive learning methods like DPO. Thisiterative cycle of exploration and training fosters continued improvement inthe agents. Our experiments on three complex tasks demonstrate that ETOconsistently surpasses baseline performance by a large margin. Furthermore, anexamination of task-solving efficiency and potential in scenarios lackingexpert trajectory underscores the effectiveness of our approach.</description><author>Yifan Song, Da Yin, Xiang Yue, Jie Huang, Sujian Li, Bill Yuchen Lin</author><pubDate>Wed, 10 Jul 2024 17:36:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.02502v2</guid></item><item><title>Agent Lumos: Unified and Modular Training for Open-Source Language Agents</title><link>http://arxiv.org/abs/2311.05657v3</link><description>Closed-source agents suffer from several issues such as a lack ofaffordability, transparency, and reproducibility, particularly on complexinteractive tasks. This motivates the development of open-source alternatives.We introduce LUMOS, one of the first frameworks for training open-sourceLLM-based agents. LUMOS features a learnable, unified, and modular architecturewith a planning module that learns high-level subgoal generation, and agrounding module trained to translate these into actions using various tools inthe execution module. The design allows for modular upgrades and widerapplicability to diverse interactive tasks. To foster generalizable agentlearning, we collect large-scale, unified, and high-quality trainingannotations derived from diverse ground-truth reasoning rationales acrossvarious complex interactive tasks. On 9 datasets, LUMOS exhibits several keyadvantages: (1) LUMOS excels multiple larger open-source agents on the held-outdatasets (unused for training) for each task type. LUMOS even surpasses GPTagents on QA and web tasks; (2) LUMOS outperforms open-source agents producedby chain-of-thoughts and unmodularized integrated training; and (3) LUMOSeffectively generalizes to unseen tasks, outperforming 33B-scale agents anddomain-specific agents.</description><author>Da Yin, Faeze Brahman, Abhilasha Ravichander, Khyathi Chandu, Kai-Wei Chang, Yejin Choi, Bill Yuchen Lin</author><pubDate>Wed, 10 Jul 2024 17:36:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05657v3</guid></item><item><title>Adversarial Robustness Limits via Scaling-Law and Human-Alignment Studies</title><link>http://arxiv.org/abs/2404.09349v2</link><description>This paper revisits the simple, long-studied, yet still unsolved problem ofmaking image classifiers robust to imperceptible perturbations. Taking CIFAR10as an example, SOTA clean accuracy is about $100$%, but SOTA robustness to$\ell_{\infty}$-norm bounded perturbations barely exceeds $70$%. To understandthis gap, we analyze how model size, dataset size, and synthetic data qualityaffect robustness by developing the first scaling laws for adversarialtraining. Our scaling laws reveal inefficiencies in prior art and provideactionable feedback to advance the field. For instance, we discovered that SOTAmethods diverge notably from compute-optimal setups, using excess compute fortheir level of robustness. Leveraging a compute-efficient setup, we surpass theprior SOTA with $20$% ($70$%) fewer training (inference) FLOPs. We trainedvarious compute-efficient models, with our best achieving $74$% AutoAttackaccuracy ($+3$% gain). However, our scaling laws also predict robustness slowlygrows then plateaus at $90$%: dwarfing our new SOTA by scaling is impractical,and perfect robustness is impossible. To better understand this predictedlimit, we carry out a small-scale human evaluation on the AutoAttack data thatfools our top-performing model. Concerningly, we estimate that humanperformance also plateaus near $90$%, which we show to be attributable to$\ell_{\infty}$-constrained attacks' generation of invalid images notconsistent with their original labels. Having characterized limitingroadblocks, we outline promising paths for future research.</description><author>Brian R. Bartoldson, James Diffenderfer, Konstantinos Parasyris, Bhavya Kailkhura</author><pubDate>Wed, 10 Jul 2024 17:32:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.09349v2</guid></item><item><title>Green Screen Augmentation Enables Scene Generalisation in Robotic Manipulation</title><link>http://arxiv.org/abs/2407.07868v1</link><description>Generalising vision-based manipulation policies to novel environments remainsa challenging area with limited exploration. Current practices involvecollecting data in one location, training imitation learning or reinforcementlearning policies with this data, and deploying the policy in the samelocation. However, this approach lacks scalability as it necessitates datacollection in multiple locations for each task. This paper proposes a novelapproach where data is collected in a location predominantly featuring greenscreens. We introduce Green-screen Augmentation (GreenAug), employing a chromakey algorithm to overlay background textures onto a green screen. Throughextensive real-world empirical studies with over 850 training demonstrationsand 8.2k evaluation episodes, we demonstrate that GreenAug surpasses noaugmentation, standard computer vision augmentation, and prior generativeaugmentation methods in performance. While no algorithmic novelties areclaimed, our paper advocates for a fundamental shift in data collectionpractices. We propose that real-world demonstrations in future research shouldutilise green screens, followed by the application of GreenAug. We believeGreenAug unlocks policy generalisation to visually distinct novel locations,addressing the current scene generalisation limitations in robot learning.</description><author>Eugene Teoh, Sumit Patidar, Xiao Ma, Stephen James</author><pubDate>Wed, 10 Jul 2024 17:32:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07868v1</guid></item><item><title>Recursive Visual Programming</title><link>http://arxiv.org/abs/2312.02249v2</link><description>Visual Programming (VP) has emerged as a powerful framework for VisualQuestion Answering (VQA). By generating and executing bespoke code for eachquestion, these methods demonstrate impressive compositional and reasoningcapabilities, especially in few-shot and zero-shot scenarios. However, existingVP methods generate all code in a single function, resulting in code that issuboptimal in terms of both accuracy and interpretability. Inspired by humancoding practices, we propose Recursive Visual Programming (RVP), whichsimplifies generated routines, provides more efficient problem solving, and canmanage more complex data structures. RVP is inspired by human coding practicesand approaches VQA tasks with an iterative recursive code generation approach,allowing decomposition of complicated problems into smaller parts. Notably, RVPis capable of dynamic type assignment, i.e., as the system recursivelygenerates a new piece of code, it autonomously determines the appropriatereturn type and crafts the requisite code to generate that output. We showRVP's efficacy through extensive experiments on benchmarks including VSR, COVR,GQA, and NextQA, underscoring the value of adopting human-like recursive andmodular programming techniques for solving VQA tasks through coding.</description><author>Jiaxin Ge, Sanjay Subramanian, Baifeng Shi, Roei Herzig, Trevor Darrell</author><pubDate>Wed, 10 Jul 2024 17:26:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02249v2</guid></item><item><title>Controlling Space and Time with Diffusion Models</title><link>http://arxiv.org/abs/2407.07860v1</link><description>We present 4DiM, a cascaded diffusion model for 4D novel view synthesis(NVS), conditioned on one or more images of a general scene, and a set ofcamera poses and timestamps. To overcome challenges due to limited availabilityof 4D training data, we advocate joint training on 3D (with camera pose), 4D(pose+time) and video (time but no pose) data and propose a new architecturethat enables the same. We further advocate the calibration of SfM posed datausing monocular metric depth estimators for metric scale camera control. Formodel evaluation, we introduce new metrics to enrich and overcome shortcomingsof current evaluation schemes, demonstrating state-of-the-art results in bothfidelity and pose control compared to existing diffusion models for 3D NVS,while at the same time adding the ability to handle temporal dynamics. 4DiM isalso used for improved panorama stitching, pose-conditioned video to videotranslation, and several other tasks. For an overview seehttps://4d-diffusion.github.io</description><author>Daniel Watson, Saurabh Saxena, Lala Li, Andrea Tagliasacchi, David J. Fleet</author><pubDate>Wed, 10 Jul 2024 17:23:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07860v1</guid></item><item><title>FACTS About Building Retrieval Augmented Generation-based Chatbots</title><link>http://arxiv.org/abs/2407.07858v1</link><description>Enterprise chatbots, powered by generative AI, are emerging as keyapplications to enhance employee productivity. Retrieval Augmented Generation(RAG), Large Language Models (LLMs), and orchestration frameworks likeLangchain and Llamaindex are crucial for building these chatbots. However,creating effective enterprise chatbots is challenging and requires meticulousRAG pipeline engineering. This includes fine-tuning embeddings and LLMs,extracting documents from vector databases, rephrasing queries, rerankingresults, designing prompts, honoring document access controls, providingconcise responses, including references, safeguarding personal information, andbuilding orchestration agents. We present a framework for building RAG-basedchatbots based on our experience with three NVIDIA chatbots: for IT/HRbenefits, financial earnings, and general content. Our contributions arethree-fold: introducing the FACTS framework (Freshness, Architectures, Cost,Testing, Security), presenting fifteen RAG pipeline control points, andproviding empirical results on accuracy-latency tradeoffs between large andsmall LLMs. To the best of our knowledge, this is the first paper of its kindthat provides a holistic view of the factors as well as solutions for buildingsecure enterprise-grade chatbots."</description><author>Rama Akkiraju, Anbang Xu, Deepak Bora, Tan Yu, Lu An, Vishal Seth, Aaditya Shukla, Pritam Gundecha, Hridhay Mehta, Ashwin Jha, Prithvi Raj, Abhinav Balasubramanian, Murali Maram, Guru Muthusamy, Shivakesh Reddy Annepally, Sidney Knowles, Min Du, Nick Burnett, Sean Javiya, Ashok Marannan, Mamta Kumari, Surbhi Jha, Ethan Dereszenski, Anupam Chakraborty, Subhash Ranjan, Amina Terfai, Anoop Surya, Tracey Mercer, Vinodh Kumar Thanigachalam, Tamar Bar, Sanjana Krishnan, Samy Kilaru, Jasmine Jaksic, Nave Algarici, Jacob Liberman, Joey Conway, Sonu Nayyar, Justin Boitano</author><pubDate>Wed, 10 Jul 2024 17:20:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07858v1</guid></item><item><title>Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model</title><link>http://arxiv.org/abs/2407.07053v2</link><description>Although most current large multimodal models (LMMs) can already understandphotos of natural scenes and portraits, their understanding of abstract images,e.g., charts, maps, or layouts, and visual reasoning capabilities remains quiterudimentary. They often struggle with simple daily tasks, such as reading timefrom a clock, understanding a flowchart, or planning a route using a road map.In light of this, we design a multi-modal self-instruct, utilizing largelanguage models and their code capabilities to synthesize massive abstractimages and visual reasoning instructions across daily scenarios. Our strategyeffortlessly creates a multimodal benchmark with 11,193 instructions for eightvisual scenarios: charts, tables, simulated maps, dashboards, flowcharts,relation graphs, floor plans, and visual puzzles. \textbf{This benchmark,constructed with simple lines and geometric elements, exposes the shortcomingsof most advanced LMMs} like Claude-3.5-Sonnet and GPT-4o in abstract imageunderstanding, spatial relations reasoning, and visual element induction.Besides, to verify the quality of our synthetic data, we fine-tune an LMM using62,476 synthetic chart, table and road map instructions. The resultsdemonstrate improved chart understanding and map navigation performance, andalso demonstrate potential benefits for other visual reasoning tasks. Our codeis available at: \url{https://github.com/zwq2018/Multi-modal-Self-instruct}.</description><author>Wenqi Zhang, Zhenglin Cheng, Yuanyu He, Mengna Wang, Yongliang Shen, Zeqi Tan, Guiyang Hou, Mingqian He, Yanna Ma, Weiming Lu, Yueting Zhuang</author><pubDate>Wed, 10 Jul 2024 17:17:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07053v2</guid></item><item><title>Progressive Growing of Patch Size: Resource-Efficient Curriculum Learning for Dense Prediction Tasks</title><link>http://arxiv.org/abs/2407.07853v1</link><description>In this work, we introduce Progressive Growing of Patch Size, aresource-efficient implicit curriculum learning approach for dense predictiontasks. Our curriculum approach is defined by growing the patch size duringmodel training, which gradually increases the task's difficulty. We integratedour curriculum into the nnU-Net framework and evaluated the methodology on all10 tasks of the Medical Segmentation Decathlon. With our approach, we are ableto substantially reduce runtime, computational costs, and CO$_{2}$ emissions ofnetwork training compared to classical constant patch size training. In ourexperiments, the curriculum approach resulted in improved convergence. We areable to outperform standard nnU-Net training, which is trained with constantpatch size, in terms of Dice Score on 7 out of 10 MSD tasks while only spendingroughly 50\% of the original training runtime. To the best of our knowledge,our Progressive Growing of Patch Size is the first successful employment of asample-length curriculum in the form of patch size in the field of computervision. Our code is publicly available at \url{https://github.com}.</description><author>Stefan M. Fischer, Lina Felsner, Richard Osuala, Johannes Kiechle, Daniel M. Lang, Jan C. Peeken, Julia A. Schnabel</author><pubDate>Wed, 10 Jul 2024 17:14:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07853v1</guid></item><item><title>OpenDiLoCo: An Open-Source Framework for Globally Distributed Low-Communication Training</title><link>http://arxiv.org/abs/2407.07852v1</link><description>OpenDiLoCo is an open-source implementation and replication of theDistributed Low-Communication (DiLoCo) training method for large languagemodels. We provide a reproducible implementation of the DiLoCo experiments,offering it within a scalable, decentralized training framework using theHivemind library. We demonstrate its effectiveness by training a model acrosstwo continents and three countries, while maintaining 90-95% computeutilization. Additionally, we conduct ablations studies focusing on thealgorithm's compute efficiency, scalability in the number of workers and showthat its gradients can be all-reduced using FP16 without any performancedegradation. Furthermore, we scale OpenDiLoCo to 3x the size of the originalwork, demonstrating its effectiveness for billion parameter models.</description><author>Sami Jaghouar, Jack Min Ong, Johannes Hagemann</author><pubDate>Wed, 10 Jul 2024 17:13:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07852v1</guid></item><item><title>Lie Group Decompositions for Equivariant Neural Networks</title><link>http://arxiv.org/abs/2310.11366v2</link><description>Invariance and equivariance to geometrical transformations have proven to bevery useful inductive biases when training (convolutional) neural networkmodels, especially in the low-data regime. Much work has focused on the casewhere the symmetry group employed is compact or abelian, or both. Recent workhas explored enlarging the class of transformations used to the case of Liegroups, principally through the use of their Lie algebra, as well as the groupexponential and logarithm maps. The applicability of such methods is limited bythe fact that depending on the group of interest $G$, the exponential map maynot be surjective. Further limitations are encountered when $G$ is neithercompact nor abelian. Using the structure and geometry of Lie groups and theirhomogeneous spaces, we present a framework by which it is possible to work withsuch groups primarily focusing on the groups $G = \text{GL}^{+}(n, \mathbb{R})$and $G = \text{SL}(n, \mathbb{R})$, as well as their representation as affinetransformations $\mathbb{R}^{n} \rtimes G$. Invariant integration as well as aglobal parametrization is realized by a decomposition into subgroups andsubmanifolds which can be handled individually. Under this framework, we showhow convolution kernels can be parametrized to build models equivariant withrespect to affine transformations. We evaluate the robustness andout-of-distribution generalisation capability of our model on the benchmarkaffine-invariant classification task, outperforming previous proposals.</description><author>Mircea Mironenco, Patrick Forré</author><pubDate>Wed, 10 Jul 2024 17:12:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11366v2</guid></item><item><title>Uncovering Layer-Dependent Activation Sparsity Patterns in ReLU Transformers</title><link>http://arxiv.org/abs/2407.07848v1</link><description>Previous work has demonstrated that MLPs within ReLU Transformers exhibithigh levels of sparsity, with many of their activations equal to zero for anygiven token. We build on that work to more deeply explore how token-levelsparsity evolves over the course of training, and how it connects to broadersparsity patterns over the course of a sequence or batch, demonstrating thatthe different layers within small transformers exhibit distinctlylayer-specific patterns on both of these fronts. In particular, we demonstratethat the first and last layer of the network have distinctive and in many waysinverted relationships to sparsity, and explore implications for the structureof feature representations being learned at different depths of the model. Weadditionally explore the phenomenon of ReLU dimensions "turning off", and showevidence suggesting that "neuron death" is being primarily driven by thedynamics of training, rather than simply occurring randomly or accidentally asa result of outliers.</description><author>Cody Wild, Jesper Anderson</author><pubDate>Wed, 10 Jul 2024 17:10:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07848v1</guid></item><item><title>SIP: Injecting a Structural Inductive Bias into a Seq2Seq Model by Simulation</title><link>http://arxiv.org/abs/2310.00796v3</link><description>Strong inductive biases enable learning from little data and helpgeneralization outside of the training distribution. Popular neuralarchitectures such as Transformers lack strong structural inductive biases forseq2seq NLP tasks on their own. Consequently, they struggle with systematicgeneralization beyond the training distribution, e.g. with extrapolating tolonger inputs, even when pre-trained on large amounts of text. We show how astructural inductive bias can be efficiently injected into a seq2seq model bypre-training it to simulate structural transformations on synthetic data.Specifically, we inject an inductive bias towards Finite State Transducers(FSTs) into a Transformer by pre-training it to simulate FSTs given theirdescriptions. Our experiments show that our method imparts the desiredinductive bias, resulting in improved systematic generalization and betterfew-shot learning for FST-like tasks. Our analysis shows that fine-tuned modelsaccurately capture the state dynamics of the unseen underlying FSTs, suggestingthat the simulation process is internalized by the fine-tuned model.</description><author>Matthias Lindemann, Alexander Koller, Ivan Titov</author><pubDate>Wed, 10 Jul 2024 17:09:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00796v3</guid></item><item><title>OV-DINO: Unified Open-Vocabulary Detection with Language-Aware Selective Fusion</title><link>http://arxiv.org/abs/2407.07844v1</link><description>Open-vocabulary detection is a challenging task due to the requirement ofdetecting objects based on class names, including those not encountered duringtraining. Existing methods have shown strong zero-shot detection capabilitiesthrough pre-training on diverse large-scale datasets. However, these approachesstill face two primary challenges: (i) how to universally integrate diversedata sources for end-to-end training, and (ii) how to effectively leverage thelanguage-aware capability for region-level cross-modality understanding. Toaddress these challenges, we propose a novel unified open-vocabulary detectionmethod called OV-DINO, which pre-trains on diverse large-scale datasets withlanguage-aware selective fusion in a unified framework. Specifically, weintroduce a Unified Data Integration (UniDI) pipeline to enable end-to-endtraining and eliminate noise from pseudo-label generation by unifying differentdata sources into detection-centric data. In addition, we propose aLanguage-Aware Selective Fusion (LASF) module to enable the language-awareability of the model through a language-aware query selection and fusionprocess. We evaluate the performance of the proposed OV-DINO on popularopen-vocabulary detection benchmark datasets, achieving state-of-the-artresults with an AP of 50.6\% on the COCO dataset and 40.0\% on the LVIS datasetin a zero-shot manner, demonstrating its strong generalization ability.Furthermore, the fine-tuned OV-DINO on COCO achieves 58.4\% AP, outperformingmany existing methods with the same backbone. The code for OV-DINO will beavailable at\href{https://github.com/wanghao9610/OV-DINO}{https://github.com/wanghao9610/OV-DINO}.</description><author>Hao Wang, Pengzhen Ren, Zequn Jie, Xiao Dong, Chengjian Feng, Yinlong Qian, Lin Ma, Dongmei Jiang, Yaowei Wang, Xiangyuan Lan, Xiaodan Liang</author><pubDate>Wed, 10 Jul 2024 17:05:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07844v1</guid></item><item><title>Probabilistic Routing for Graph-Based Approximate Nearest Neighbor Search</title><link>http://arxiv.org/abs/2402.11354v2</link><description>Approximate nearest neighbor search (ANNS) in high-dimensional spaces is apivotal challenge in the field of machine learning. In recent years,graph-based methods have emerged as the superior approach to ANNS, establishinga new state of the art. Although various optimizations for graph-based ANNShave been introduced, they predominantly rely on heuristic methods that lackformal theoretical backing. This paper aims to enhance routing withingraph-based ANNS by introducing a method that offers a probabilistic guaranteewhen exploring a node's neighbors in the graph. We formulate the problem asprobabilistic routing and develop two baseline strategies by incorporatinglocality-sensitive techniques. Subsequently, we introduce PEOs, a novelapproach that efficiently identifies which neighbors in the graph should beconsidered for exact distance calculation, thus significantly improvingefficiency in practice. Our experiments demonstrate that equipping PEOs canincrease throughput on commonly utilized graph indexes (HNSW and NSSG) by afactor of 1.6 to 2.5, and its efficiency consistently outperforms theleading-edge routing technique by 1.1 to 1.4 times.</description><author>Kejing Lu, Chuan Xiao, Yoshiharu Ishikawa</author><pubDate>Wed, 10 Jul 2024 17:05:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11354v2</guid></item><item><title>Study on Aspect Ratio Variability toward Robustness of Vision Transformer-based Vehicle Re-identification</title><link>http://arxiv.org/abs/2407.07842v1</link><description>Vision Transformers (ViTs) have excelled in vehicle re-identification (ReID)tasks. However, non-square aspect ratios of image or video input mightsignificantly affect the re-identification performance. To address this issue,we propose a novel ViT-based ReID framework in this paper, which fuses modelstrained on a variety of aspect ratios. Our main contributions are threefold:(i) We analyze aspect ratio performance on VeRi-776 and VehicleID datasets,guiding input settings based on aspect ratios of original images. (ii) Weintroduce patch-wise mixup intra-image during ViT patchification (guided byspatial attention scores) and implement uneven stride for better object aspectratio matching. (iii) We propose a dynamic feature fusing ReID network,enhancing model robustness. Our ReID method achieves a significantly improvedmean Average Precision (mAP) of 91.0\% compared to the the closeststate-of-the-art (CAL) result of 80.9\% on VehicleID dataset.</description><author>Mei Qiu, Lauren Christopher, Lingxi Li</author><pubDate>Wed, 10 Jul 2024 17:02:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07842v1</guid></item><item><title>Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models</title><link>http://arxiv.org/abs/2402.14848v2</link><description>This paper explores the impact of extending input lengths on the capabilitiesof Large Language Models (LLMs). Despite LLMs advancements in recent times,their performance consistency across different input lengths is not wellunderstood. We investigate this aspect by introducing a novel QA reasoningframework, specifically designed to assess the impact of input length. Weisolate the effect of input length using multiple versions of the same sample,each being extended with padding of different lengths, types and locations. Ourfindings show a notable degradation in LLMs' reasoning performance at muchshorter input lengths than their technical maximum. We show that thedegradation trend appears in every version of our dataset, although atdifferent intensities. Additionally, our study reveals that the traditionalmetric of next word prediction correlates negatively with performance of LLMs'on our reasoning dataset. We analyse our results and identify failure modesthat can serve as useful guides for future research, potentially informingstrategies to address the limitations observed in LLMs.</description><author>Mosh Levy, Alon Jacoby, Yoav Goldberg</author><pubDate>Wed, 10 Jul 2024 17:01:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14848v2</guid></item><item><title>Benchmarking Embedding Aggregation Methods in Computational Pathology: A Clinical Data Perspective</title><link>http://arxiv.org/abs/2407.07841v1</link><description>Recent advances in artificial intelligence (AI), in particularself-supervised learning of foundation models (FMs), are revolutionizingmedical imaging and computational pathology (CPath). A constant challenge inthe analysis of digital Whole Slide Images (WSIs) is the problem of aggregatingtens of thousands of tile-level image embeddings to a slide-levelrepresentation. Due to the prevalent use of datasets created for genomicresearch, such as TCGA, for method development, the performance of thesetechniques on diagnostic slides from clinical practice has been inadequatelyexplored. This study conducts a thorough benchmarking analysis of tenslide-level aggregation techniques across nine clinically relevant tasks,including diagnostic assessment, biomarker classification, and outcomeprediction. The results yield following key insights: (1) Embeddings derivedfrom domain-specific (histological images) FMs outperform those from genericImageNet-based models across aggregation methods. (2) Spatial-aware aggregatorsenhance the performance significantly when using ImageNet pre-trained modelsbut not when using FMs. (3) No single model excels in all tasks andspatially-aware models do not show general superiority as it would be expected.These findings underscore the need for more adaptable and universallyapplicable aggregation techniques, guiding future research towards tools thatbetter meet the evolving needs of clinical-AI in pathology. The code used inthis work is available at\url{https://github.com/fuchs-lab-public/CPath_SABenchmark}.</description><author>Shengjia Chen, Gabriele Campanella, Abdulkadir Elmas, Aryeh Stock, Jennifer Zeng, Alexandros D. Polydorides, Adam J. Schoenfeld, Kuan-lin Huang, Jane Houldsworth, Chad Vanderbilt, Thomas J. Fuchs</author><pubDate>Wed, 10 Jul 2024 17:00:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07841v1</guid></item><item><title>Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison</title><link>http://arxiv.org/abs/2407.07840v1</link><description>Despite tremendous advancements, current state-of-the-art Vision-LanguageModels (VLMs) are still far from perfect. They tend to hallucinate and maygenerate biased responses. In such circumstances, having a way to assess thereliability of a given response generated by a VLM is quite useful. Existingmethods, such as estimating uncertainty using answer likelihoods orprompt-based confidence generation, often suffer from overconfidence. Othermethods use self-consistency comparison but are affected by confirmationbiases. To alleviate these, we propose \textbf{De}compose and \textbf{C}ompare\textbf{C}onsistency (\texttt{DeCC}) for reliability measurement. By comparingthe consistency between the direct answer generated using the VLM's internalreasoning process, and the indirect answers obtained by decomposing thequestion into sub-questions and reasoning over the sub-answers produced by theVLM, \texttt{DeCC} measures the reliability of VLM's direct answer. Experimentsacross six vision-language tasks with three VLMs show \texttt{DeCC}'sreliability estimation achieves better correlation with task accuracy comparedto the existing methods.</description><author>Qian Yang, Weixiang Yan, Aishwarya Agrawal</author><pubDate>Wed, 10 Jul 2024 17:00:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07840v1</guid></item><item><title>MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series</title><link>http://arxiv.org/abs/2405.19327v4</link><description>Large Language Models (LLMs) have made great strides in recent years toachieve unprecedented performance across different tasks. However, due tocommercial interest, the most competitive models like GPT, Gemini, and Claudehave been gated behind proprietary interfaces without disclosing the trainingdetails. Recently, many institutions have open-sourced several strong LLMs likeLLaMA-3, comparable to existing closed-source LLMs. However, only the model'sweights are provided with most details (e.g., intermediate checkpoints,pre-training corpus, and training code, etc.) being undisclosed. To improve thetransparency of LLMs, the research community has formed to open-source trulyopen LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-trainingcorpus and training code) are being provided. These models have greatlyadvanced the scientific study of these large models including their strengths,weaknesses, biases and risks. However, we observe that the existing truly openLLMs on reasoning, knowledge, and coding tasks are still inferior to existingstate-of-the-art LLMs with similar model sizes. To this end, we open-sourceMAP-Neo, a highly capable and transparent bilingual language model with 7Bparameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is thefirst fully open-sourced bilingual LLM with comparable performance compared toexisting state-of-the-art LLMs. Moreover, we open-source all details toreproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaningpipeline, checkpoints, and well-optimized training/evaluation framework areprovided. Finally, we hope our MAP-Neo will enhance and strengthen the openresearch community and inspire more innovations and creativities to facilitatethe further improvements of LLMs.</description><author>Ge Zhang, Scott Qu, Jiaheng Liu, Chenchen Zhang, Chenghua Lin, Chou Leuang Yu, Danny Pan, Esther Cheng, Jie Liu, Qunshu Lin, Raven Yuan, Tuney Zheng, Wei Pang, Xinrun Du, Yiming Liang, Yinghao Ma, Yizhi Li, Ziyang Ma, Bill Lin, Emmanouil Benetos, Huan Yang, Junting Zhou, Kaijing Ma, Minghao Liu, Morry Niu, Noah Wang, Quehry Que, Ruibo Liu, Sine Liu, Shawn Guo, Soren Gao, Wangchunshu Zhou, Xinyue Zhang, Yizhi Zhou, Yubo Wang, Yuelin Bai, Yuhan Zhang, Yuxiang Zhang, Zenith Wang, Zhenzhu Yang, Zijian Zhao, Jiajun Zhang, Wanli Ouyang, Wenhao Huang, Wenhu Chen</author><pubDate>Wed, 10 Jul 2024 16:55:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19327v4</guid></item><item><title>RoBus: A Multimodal Dataset for Controllable Road Networks and Building Layouts Generation</title><link>http://arxiv.org/abs/2407.07835v1</link><description>Automated 3D city generation, focusing on road networks and building layouts,is in high demand for applications in urban design, multimedia games andautonomous driving simulations. The surge of generative AI facilitatesdesigning city layouts based on deep learning models. However, the lack ofhigh-quality datasets and benchmarks hinders the progress of these data-drivenmethods in generating road networks and building layouts. Furthermore, fewstudies consider urban characteristics, which generally take graphics asanalysis objects and are crucial for practical applications, to control thegenerative process. To alleviate these problems, we introduce a multimodaldataset with accompanying evaluation metrics for controllable generation ofRoad networks and Building layouts (RoBus), which is the first and largestopen-source dataset in city generation so far. RoBus dataset is formatted asimages, graphics and texts, with $72,400$ paired samples that cover around$80,000km^2$ globally. We analyze the RoBus dataset statistically and validatethe effectiveness against existing road networks and building layoutsgeneration methods. Additionally, we design new baselines that incorporateurban characteristics, such as road orientation and building density, in theprocess of generating road networks and building layouts using the RoBusdataset, enhancing the practicality of automated urban design. The RoBusdataset and related codes are published athttps://github.com/tourlics/RoBus_Dataset.</description><author>Tao Li, Ruihang Li, Huangnan Zheng, Shanding Ye, Shijian Li, Zhijie Pan</author><pubDate>Wed, 10 Jul 2024 16:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07835v1</guid></item><item><title>TriQXNet: Forecasting Dst Index from Solar Wind Data Using an Interpretable Parallel Classical-Quantum Framework with Uncertainty Quantification</title><link>http://arxiv.org/abs/2407.06658v2</link><description>Geomagnetic storms, caused by solar wind energy transfer to Earth's magneticfield, can disrupt critical infrastructure like GPS, satellite communications,and power grids. The disturbance storm-time (Dst) index measures stormintensity. Despite advancements in empirical, physics-based, andmachine-learning models using real-time solar wind data, accurately forecastingextreme geomagnetic events remains challenging due to noise and sensorfailures. This research introduces TriQXNet, a novel hybrid classical-quantumneural network for Dst forecasting. Our model integrates classical and quantumcomputing, conformal prediction, and explainable AI (XAI) within a hybridarchitecture. To ensure high-quality input data, we developed a comprehensivepreprocessing pipeline that included feature selection, normalization,aggregation, and imputation. TriQXNet processes preprocessed solar wind datafrom NASA's ACE and NOAA's DSCOVR satellites, predicting the Dst index for thecurrent hour and the next, providing vital advance notice to mitigategeomagnetic storm impacts. TriQXNet outperforms 13 state-of-the-art hybriddeep-learning models, achieving a root mean squared error of 9.27 nanoteslas(nT). Rigorous evaluation through 10-fold cross-validated paired t-testsconfirmed its superior performance with 95% confidence. Conformal predictiontechniques provide quantifiable uncertainty, which is essential for operationaldecisions, while XAI methods like ShapTime enhance interpretability.Comparative analysis shows TriQXNet's superior forecasting accuracy, setting anew level of expectations for geomagnetic storm prediction and highlighting thepotential of classical-quantum hybrid models in space weather forecasting.</description><author>Md Abrar Jahin, M. F. Mridha, Zeyar Aung, Nilanjan Dey, R. Simon Sherratt</author><pubDate>Wed, 10 Jul 2024 16:53:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06658v2</guid></item><item><title>Disentangled Representation Learning through Geometry Preservation with the Gromov-Monge Gap</title><link>http://arxiv.org/abs/2407.07829v1</link><description>Learning disentangled representations in an unsupervised manner is afundamental challenge in machine learning. Solving it may unlock otherproblems, such as generalization, interpretability, or fairness. Whileremarkably difficult to solve in general, recent works have shown thatdisentanglement is provably achievable under additional assumptions that canleverage geometrical constraints, such as local isometry. To use theseinsights, we propose a novel perspective on disentangled representationlearning built on quadratic optimal transport. Specifically, we formulate theproblem in the Gromov-Monge setting, which seeks isometric mappings betweendistributions supported on different spaces. We propose the Gromov-Monge-Gap(GMG), a regularizer that quantifies the geometry-preservation of an arbitrarypush-forward map between two distributions supported on different spaces. Wedemonstrate the effectiveness of GMG regularization for disentanglement on fourstandard benchmarks. Moreover, we show that geometry preservation can evenencourage unsupervised disentanglement without the standard reconstructionobjective - making the underlying model decoder-free, and promising a morepractically viable and scalable perspective on unsupervised disentanglement.</description><author>Théo Uscidda, Luca Eyring, Karsten Roth, Fabian Theis, Zeynep Akata, Marco Cuturi</author><pubDate>Wed, 10 Jul 2024 16:51:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07829v1</guid></item><item><title>Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model</title><link>http://arxiv.org/abs/2404.04167v4</link><description>In this study, we introduce CT-LLM, a 2B large language model (LLM) thatillustrates a pivotal shift towards prioritizing the Chinese language indeveloping LLMs. Uniquely initiated from scratch, CT-LLM diverges from theconventional methodology by primarily incorporating Chinese textual data,utilizing an extensive corpus of 1,200 billion tokens, including 800 billionChinese tokens, 300 billion English tokens, and 100 billion code tokens. Thisstrategic composition facilitates the model's exceptional proficiency inunderstanding and processing Chinese, a capability further enhanced throughalignment techniques. Demonstrating remarkable performance on the CHC-Bench,CT-LLM excels in Chinese language tasks, and showcases its adeptness in Englishthrough SFT. This research challenges the prevailing paradigm of training LLMspredominantly on English corpora and then adapting them to other languages,broadening the horizons for LLM training methodologies. By open-sourcing thefull process of training a Chinese LLM, including a detailed data processingprocedure with the obtained Massive Appropriate Pretraining Chinese Corpus(MAP-CC), a well-chosen multidisciplinary Chinese Hard Case Benchmark(CHC-Bench), and the 2B-size Chinese Tiny LLM (CT-LLM), we aim to fosterfurther exploration and innovation in both academia and industry, paving theway for more inclusive and versatile language models.</description><author>Xinrun Du, Zhouliang Yu, Songyang Gao, Ding Pan, Yuyang Cheng, Ziyang Ma, Ruibin Yuan, Xingwei Qu, Jiaheng Liu, Tianyu Zheng, Xinchen Luo, Guorui Zhou, Wenhu Chen, Ge Zhang</author><pubDate>Wed, 10 Jul 2024 16:51:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.04167v4</guid></item><item><title>Estimating the stability number of a random graph using convolutional neural networks</title><link>http://arxiv.org/abs/2407.07827v1</link><description>Graph combinatorial optimization problems are widely applicable andnotoriously difficult to compute; for example, consider the traveling salesmanor facility location problems. In this paper, we explore the feasibility ofusing convolutional neural networks (CNNs) on graph images to predict thecardinality of combinatorial properties of random graphs and networks.Specifically, we use image representations of modified adjacency matrices ofrandom graphs as training samples for a CNN model to predict the stabilitynumber of random graphs; where the stability number is the cardinality of amaximum set of vertices containing no pairwise adjacency. Our approachdemonstrates the potential for applying deep learning in combinatorialoptimization problems.</description><author>Randy Davila</author><pubDate>Wed, 10 Jul 2024 16:50:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07827v1</guid></item><item><title>RT-LA-VocE: Real-Time Low-SNR Audio-Visual Speech Enhancement</title><link>http://arxiv.org/abs/2407.07825v1</link><description>In this paper, we aim to generate clean speech frame by frame from a livevideo stream and a noisy audio stream without relying on future inputs. To thisend, we propose RT-LA-VocE, which completely re-designs every component ofLA-VocE, a state-of-the-art non-causal audio-visual speech enhancement model,to perform causal real-time inference with a 40ms input frame. We do so bydevising new visual and audio encoders that rely solely on past frames,replacing the Transformer encoder with the Emformer, and designing a new causalneural vocoder C-HiFi-GAN. On the popular AVSpeech dataset, we show that ouralgorithm achieves state-of-the-art results in all real-time scenarios. Moreimportantly, each component is carefully tuned to minimize the algorithmlatency to the theoretical minimum (40ms) while maintaining a low end-to-endprocessing latency of 28.15ms per frame, enabling real-time frame-by-frameenhancement with minimal delay.</description><author>Honglie Chen, Rodrigo Mira, Stavros Petridis, Maja Pantic</author><pubDate>Wed, 10 Jul 2024 16:49:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07825v1</guid></item><item><title>When to Accept Automated Predictions and When to Defer to Human Judgment?</title><link>http://arxiv.org/abs/2407.07821v1</link><description>Ensuring the reliability and safety of automated decision-making is crucial.It is well-known that data distribution shifts in machine learning can produceunreliable outcomes. This paper proposes a new approach for measuring thereliability of predictions under distribution shifts. We analyze how theoutputs of a trained neural network change using clustering to measuredistances between outputs and class centroids. We propose this distance as ametric to evaluate the confidence of predictions under distribution shifts. Weassign each prediction to a cluster with centroid representing the mean softmaxoutput for all correct predictions of a given class. We then define a safetythreshold for a class as the smallest distance from an incorrect prediction tothe given class centroid. We evaluate the approach on the MNIST and CIFAR-10datasets using a Convolutional Neural Network and a Vision Transformer,respectively. The results show that our approach is consistent across thesedata sets and network models, and indicate that the proposed metric can offeran efficient way of determining when automated predictions are acceptable andwhen they should be deferred to human operators given a distribution shift.</description><author>Daniel Sikar, Artur Garcez, Tillman Weyde, Robin Bloomfield, Kaleem Peeroo</author><pubDate>Wed, 10 Jul 2024 16:45:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07821v1</guid></item><item><title>Analysis of Langevin Monte Carlo from Poincaré to Log-Sobolev</title><link>http://arxiv.org/abs/2112.12662v2</link><description>Classically, the continuous-time Langevin diffusion converges exponentiallyfast to its stationary distribution $\pi$ under the sole assumption that $\pi$satisfies a Poincar\'e inequality. Using this fact to provide guarantees forthe discrete-time Langevin Monte Carlo (LMC) algorithm, however, isconsiderably more challenging due to the need for working with chi-squared orR\'enyi divergences, and prior works have largely focused on stronglylog-concave targets. In this work, we provide the first convergence guaranteesfor LMC assuming that $\pi$ satisfies either a Lata\l{}a--Oleszkiewicz ormodified log-Sobolev inequality, which interpolates between the Poincar\'e andlog-Sobolev settings. Unlike prior works, our results allow for weak smoothnessand do not require convexity or dissipativity conditions.</description><author>Sinho Chewi, Murat A. Erdogdu, Mufan Bill Li, Ruoqi Shen, Matthew Zhang</author><pubDate>Wed, 10 Jul 2024 16:45:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.12662v2</guid></item><item><title>The Misclassification Likelihood Matrix: Some Classes Are More Likely To Be Misclassified Than Others</title><link>http://arxiv.org/abs/2407.07818v1</link><description>This study introduces the Misclassification Likelihood Matrix (MLM) as anovel tool for quantifying the reliability of neural network predictions underdistribution shifts. The MLM is obtained by leveraging softmax outputs andclustering techniques to measure the distances between the predictions of atrained neural network and class centroids. By analyzing these distances, theMLM provides a comprehensive view of the model's misclassification tendencies,enabling decision-makers to identify the most common and critical sources oferrors. The MLM allows for the prioritization of model improvements and theestablishment of decision thresholds based on acceptable risk levels. Theapproach is evaluated on the MNIST dataset using a Convolutional Neural Network(CNN) and a perturbed version of the dataset to simulate distribution shifts.The results demonstrate the effectiveness of the MLM in assessing thereliability of predictions and highlight its potential in enhancing theinterpretability and risk mitigation capabilities of neural networks. Theimplications of this work extend beyond image classification, with ongoingapplications in autonomous systems, such as self-driving cars, to improve thesafety and reliability of decision-making in complex, real-world environments.</description><author>Daniel Sikar, Artur Garcez, Robin Bloomfield, Tillman Weyde, Kaleem Peeroo, Naman Singh, Maeve Hutchinson, Mirela Reljan-Delaney</author><pubDate>Wed, 10 Jul 2024 16:43:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07818v1</guid></item><item><title>A Survey on Deep Stereo Matching in the Twenties</title><link>http://arxiv.org/abs/2407.07816v1</link><description>Stereo matching is close to hitting a half-century of history, yet witnesseda rapid evolution in the last decade thanks to deep learning. While previoussurveys in the late 2010s covered the first stage of this revolution, the lastfive years of research brought further ground-breaking advancements to thefield. This paper aims to fill this gap in a two-fold manner: first, we offeran in-depth examination of the latest developments in deep stereo matching,focusing on the pioneering architectural designs and groundbreaking paradigmsthat have redefined the field in the 2020s; second, we present a thoroughanalysis of the critical challenges that have emerged alongside these advances,providing a comprehensive taxonomy of these issues and exploring thestate-of-the-art techniques proposed to address them. By reviewing both thearchitectural innovations and the key challenges, we offer a holistic view ofdeep stereo matching and highlight the specific areas that require furtherinvestigation. To accompany this survey, we maintain a regularly updatedproject page that catalogs papers on deep stereo matching in ourAwesome-Deep-Stereo-Matching(https://github.com/fabiotosi92/Awesome-Deep-Stereo-Matching) repository.</description><author>Fabio Tosi, Luca Bartolomei, Matteo Poggi</author><pubDate>Wed, 10 Jul 2024 16:40:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07816v1</guid></item><item><title>3D Gaussian Ray Tracing: Fast Tracing of Particle Scenes</title><link>http://arxiv.org/abs/2407.07090v2</link><description>Particle-based representations of radiance fields such as 3D GaussianSplatting have found great success for reconstructing and re-rendering ofcomplex scenes. Most existing methods render particles via rasterization,projecting them to screen space tiles for processing in a sorted order. Thiswork instead considers ray tracing the particles, building a bounding volumehierarchy and casting a ray for each pixel using high-performance GPU raytracing hardware. To efficiently handle large numbers of semi-transparentparticles, we describe a specialized rendering algorithm which encapsulatesparticles with bounding meshes to leverage fast ray-triangle intersections, andshades batches of intersections in depth-order. The benefits of ray tracing arewell-known in computer graphics: processing incoherent rays for secondarylighting effects such as shadows and reflections, rendering fromhighly-distorted cameras common in robotics, stochastically sampling rays, andmore. With our renderer, this flexibility comes at little cost compared torasterization. Experiments demonstrate the speed and accuracy of our approach,as well as several applications in computer graphics and vision. We furtherpropose related improvements to the basic Gaussian representation, including asimple use of generalized kernel functions which significantly reduces particlehit counts.</description><author>Nicolas Moenne-Loccoz, Ashkan Mirzaei, Or Perel, Riccardo de Lutio, Janick Martinez Esturo, Gavriel State, Sanja Fidler, Nicholas Sharp, Zan Gojcic</author><pubDate>Wed, 10 Jul 2024 16:38:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07090v2</guid></item><item><title>Parameter estimation from an Ornstein-Uhlenbeck process with measurement noise</title><link>http://arxiv.org/abs/2305.13498v3</link><description>This article aims to investigate the impact of noise on parameter fitting foran Ornstein-Uhlenbeck process, focusing on the effects of multiplicative andthermal noise on the accuracy of signal separation. To address these issues, wepropose algorithms and methods that can effectively distinguish between thermaland multiplicative noise and improve the precision of parameter estimation foroptimal data analysis. Specifically, we explore the impact of bothmultiplicative and thermal noise on the obfuscation of the actual signal andpropose methods to resolve them. First, we present an algorithm that caneffectively separate thermal noise with comparable performance to HamiltonMonte Carlo (HMC) but with significantly improved speed. We then analyzemultiplicative noise and demonstrate that HMC is insufficient for isolatingthermal and multiplicative noise. However, we show that, with additionalknowledge of the ratio between thermal and multiplicative noise, we canaccurately distinguish between the two types of noise when provided with asufficiently large sampling rate or an amplitude of multiplicative noisesmaller than thermal noise. Thus, we demonstrate the mechanism underlying anotherwise counterintuitive phenomenon: when multiplicative noise dominates thenoise spectrum, one can successfully estimate the parameters for such systemsafter adding additional white noise to shift the noise balance.</description><author>Simon Carter, Lilianne Mujica-Parodi, Helmut H. Strey</author><pubDate>Wed, 10 Jul 2024 16:33:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13498v3</guid></item><item><title>Transformer Alignment in Large Language Models</title><link>http://arxiv.org/abs/2407.07810v1</link><description>Large Language Models (LLMs) have made significant strides in naturallanguage processing, and a precise understanding of the internal mechanismsdriving their success is essential. We regard LLMs as transforming embeddingsvia a discrete, coupled, nonlinear, dynamical system in high dimensions. Thisperspective motivates tracing the trajectories of individual tokens as theypass through transformer blocks, and linearizing the system along thesetrajectories through their Jacobian matrices. In our analysis of 38 openlyavailable LLMs, we uncover the alignment of top left and right singular vectorsof Residual Jacobians, as well as the emergence of linearity and layer-wiseexponential growth. Notably, we discover that increased alignment$\textit{positively correlates}$ with model performance. Metrics evaluatedpost-training show significant improvement in comparison to measurements madewith randomly initialized weights, highlighting the significant effects oftraining in transformers. These findings reveal a remarkable level ofregularity that has previously been overlooked, reinforcing the dynamicalinterpretation and paving the way for deeper understanding and optimization ofLLM architectures.</description><author>Murdock Aubry, Haoming Meng, Anton Sugolov, Vardan Papyan</author><pubDate>Wed, 10 Jul 2024 16:30:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07810v1</guid></item><item><title>SUMix: Mixup with Semantic and Uncertain Information</title><link>http://arxiv.org/abs/2407.07805v1</link><description>Mixup data augmentation approaches have been applied for various tasks ofdeep learning to improve the generalization ability of deep neural networks.Some existing approaches CutMix, SaliencyMix, etc. randomly replace a patch inone image with patches from another to generate the mixed image. Similarly, thecorresponding labels are linearly combined by a fixed ratio $\lambda$ by l. Theobjects in two images may be overlapped during the mixing process, so somesemantic information is corrupted in the mixed samples. In this case, the mixedimage does not match the mixed label information. Besides, such a label maymislead the deep learning model training, which results in poor performance. Tosolve this problem, we proposed a novel approach named SUMix to learn themixing ratio as well as the uncertainty for the mixed samples during thetraining process. First, we design a learnable similarity function to computean accurate mix ratio. Second, an approach is investigated as a regularizedterm to model the uncertainty of the mixed samples. We conduct experiments onfive image benchmarks, and extensive experimental results imply that our methodis capable of improving the performance of classifiers with differentcutting-based mixup approaches. The source code is available athttps://github.com/JinXins/SUMix.</description><author>Huafeng Qin, Xin Jin, Hongyu Zhu, Hongchao Liao, Mounîm A. El-Yacoubi, Xinbo Gao</author><pubDate>Wed, 10 Jul 2024 16:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07805v1</guid></item><item><title>ROSA: Random Subspace Adaptation for Efficient Fine-Tuning</title><link>http://arxiv.org/abs/2407.07802v1</link><description>Model training requires significantly more memory, compared with inference.Parameter efficient fine-tuning (PEFT) methods provide a means of adaptinglarge models to downstream tasks using less memory. However, existing methodssuch as adapters, prompt tuning or low-rank adaptation (LoRA) either introducelatency overhead at inference time or achieve subpar downstream performancecompared with full fine-tuning. In this work we propose Random SubspaceAdaptation (ROSA), a method that outperforms previous PEFT methods by asignificant margin, while maintaining a zero latency overhead during inferencetime. In contrast to previous methods, ROSA is able to adapt subspaces ofarbitrarily large dimension, better approximating full-finetuning. Wedemonstrate both theoretically and experimentally that this makes ROSA strictlymore expressive than LoRA, without consuming additional memory during runtime.As PEFT methods are especially useful in the natural language processingdomain, where models operate on scales that make full fine-tuning veryexpensive, we evaluate ROSA in two common NLP scenarios: natural languagegeneration (NLG) and natural language understanding (NLU) with GPT-2 andRoBERTa, respectively. We show that on almost every GLUE task ROSA outperformsLoRA by a significant margin, while also outperforming LoRA on NLG tasks. Ourcode is available at https://github.com/rosa-paper/rosa</description><author>Marawan Gamal Abdel Hameed, Aristides Milios, Siva Reddy, Guillaume Rabusseau</author><pubDate>Wed, 10 Jul 2024 16:20:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07802v1</guid></item><item><title>AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning</title><link>http://arxiv.org/abs/2407.07801v1</link><description>In recent years, advancements in representation learning and language modelshave propelled Automated Captioning (AC) to new heights, enabling thegeneration of human-level descriptions. Leveraging these advancements, wepropose \textbf{AVCap}, an \textbf{A}udio-\textbf{V}isual \textbf{Cap}tioningframework, a simple yet powerful baseline approach applicable to audio-visualcaptioning. AVCap utilizes audio-visual features as text tokens, which has manyadvantages not only in performance but also in the extensibility andscalability of the model. AVCap is designed around three pivotal dimensions:the exploration of optimal audio-visual encoder architectures, the adaptationof pre-trained models according to the characteristics of generated text, andthe investigation into the efficacy of modality fusion in captioning. Ourmethod outperforms existing audio-visual captioning methods across all metricsand the code is available on https://github.com/JongSuk1/AVCap</description><author>Jongsuk Kim, Jiwon Shin, Junmo Kim</author><pubDate>Wed, 10 Jul 2024 16:17:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07801v1</guid></item><item><title>Lightning Fast Video Anomaly Detection via Adversarial Knowledge Distillation</title><link>http://arxiv.org/abs/2211.15597v2</link><description>We propose a very fast frame-level model for anomaly detection in video,which learns to detect anomalies by distilling knowledge from multiple highlyaccurate object-level teacher models. To improve the fidelity of our student,we distill the low-resolution anomaly maps of the teachers by jointly applyingstandard and adversarial distillation, introducing an adversarial discriminatorfor each teacher to distinguish between target and generated anomaly maps. Weconduct experiments on three benchmarks (Avenue, ShanghaiTech, UCSD Ped2),showing that our method is over 7 times faster than the fastest competingmethod, and between 28 and 62 times faster than object-centric models, whileobtaining comparable results to recent methods. Our evaluation also indicatesthat our model achieves the best trade-off between speed and accuracy, due toits previously unheard-of speed of 1480 FPS. In addition, we carry out acomprehensive ablation study to justify our architectural design choices. Ourcode is freely available at: https://github.com/ristea/fast-aed.</description><author>Florinel-Alin Croitoru, Nicolae-Catalin Ristea, Dana Dascalescu, Radu Tudor Ionescu, Fahad Shahbaz Khan, Mubarak Shah</author><pubDate>Wed, 10 Jul 2024 16:16:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.15597v2</guid></item><item><title>Attribute or Abstain: Large Language Models as Long Document Assistants</title><link>http://arxiv.org/abs/2407.07799v1</link><description>LLMs can help humans working with long documents, but are known tohallucinate. Attribution can increase trust in LLM responses: The LLM providesevidence that supports its response, which enhances verifiability. Existingapproaches to attribution have only been evaluated in RAG settings, where theinitial retrieval confounds LLM performance. This is crucially different fromthe long document setting, where retrieval is not needed, but could help. Thus,a long document specific evaluation of attribution is missing. To fill thisgap, we present LAB, a benchmark of 6 diverse long document tasks withattribution, and experiment with different approaches to attribution on 4 LLMsof different sizes, both prompted and fine-tuned. We find that citation, i.e.response generation and evidence extraction in one step, mostly performs best.We investigate whether the ``Lost in the Middle'' phenomenon exists forattribution, but do not find this. We also find that evidence quality canpredict response quality on datasets with simple responses, but not so forcomplex responses, as models struggle with providing evidence for complexclaims. We release code and data for further investigation.</description><author>Jan Buchmann, Xiao Liu, Iryna Gurevych</author><pubDate>Wed, 10 Jul 2024 16:16:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07799v1</guid></item><item><title>Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard</title><link>http://arxiv.org/abs/2407.07796v1</link><description>We introduce a novel and extensible benchmark for large language models(LLMs) through grid-based games such as Tic-Tac-Toe, Connect-Four, and Gomoku.The open-source game simulation code, available on GitHub, allows LLMs tocompete and generates detailed data files in JSON, CSV, TXT, and PNG formatsfor leaderboard rankings and further analysis. We present the results of gamesamong leading LLMs, including Claude 3.5 Sonnet and Claude 3 Sonnet byAnthropic, Gemini 1.5 Pro and Gemini 1.5 Flash by Google, GPT-4 Turbo andGPT-4o by OpenAI, and Llama3-70B by Meta. We also encourage submissions ofresults from other LLMs. In total, we simulated 2,310 matches (5 sessions foreach pair among 7 LLMs and a random player) across three types of games, usingthree distinct prompt types: list, illustration, and image. The resultsrevealed significant variations in LLM performance across different games andprompt types, with analysis covering win and disqualification rates, missedopportunity analysis, and invalid move analysis. The details of the leaderboardand result matrix data are available as open-access data on GitHub. This studyenhances our understanding of LLMs' capabilities in playing games they were notspecifically trained for, helping to assess their rule comprehension andstrategic thinking. On the path to Artificial General Intelligence (AGI), thisstudy lays the groundwork for future exploration into their utility in complexdecision-making scenarios, illuminating their strategic thinking abilities andoffering directions for further inquiry into the limits of LLMs withingame-based frameworks.</description><author>Oguzhan Topsakal, Colby Jacob Edell, Jackson Bailey Harper</author><pubDate>Wed, 10 Jul 2024 16:14:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07796v1</guid></item><item><title>End-to-end data-driven weather forecasting</title><link>http://arxiv.org/abs/2404.00411v2</link><description>Weather forecasting is critical for a range of human activities includingtransportation, agriculture, industry, as well as the safety of the generalpublic. Machine learning models have the potential to transform the complexweather prediction pipeline, but current approaches still rely on numericalweather prediction (NWP) systems, limiting forecast speed and accuracy. Here wedemonstrate that a machine learning model can replace the entire operationalNWP pipeline. Aardvark Weather, an end-to-end data-driven weather predictionsystem, ingests raw observations and outputs global gridded forecasts and localstation forecasts. Further, it can be optimised end-to-end to maximiseperformance over quantities of interest. Global forecasts outperform anoperational NWP baseline for multiple variables and lead times. Local stationforecasts are skillful up to ten days lead time and achieve comparable andoften lower errors than a post-processed global NWP baseline and astate-of-the-art end-to-end forecasting system with input from humanforecasters. These forecasts are produced with a remarkably simple neuralprocess model using just 8\% of the input data and three orders of magnitudeless compute than existing NWP and hybrid AI-NWP methods. We anticipate thatAardvark Weather will be the starting point for a new generation of end-to-endmachine learning models for medium-range forecasting that will reducecomputational costs by orders of magnitude and enable the rapid and cheapcreation of bespoke models for users in a variety of fields, including for thedeveloping world where state-of-the-art local models are not currentlyavailable.</description><author>Anna Vaughan, Stratis Markou, Will Tebbutt, James Requeima, Wessel P. Bruinsma, Tom R. Andersson, Michael Herzog, Nicholas D. Lane, Matthew Chantry, J. Scott Hosking, Richard E. Turner</author><pubDate>Wed, 10 Jul 2024 16:12:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00411v2</guid></item><item><title>Reinforcement Learning of Adaptive Acquisition Policies for Inverse Problems</title><link>http://arxiv.org/abs/2407.07794v1</link><description>A promising way to mitigate the expensive process of obtaining ahigh-dimensional signal is to acquire a limited number of low-dimensionalmeasurements and solve an under-determined inverse problem by utilizing thestructural prior about the signal. In this paper, we focus on adaptiveacquisition schemes to save further the number of measurements. To this end, wepropose a reinforcement learning-based approach that sequentially collectsmeasurements to better recover the underlying signal by acquiring fewermeasurements. Our approach applies to general inverse problems with continuousaction spaces and jointly learns the recovery algorithm. Using insightsobtained from theoretical analysis, we also provide a probabilistic design forour methods using variational formulation. We evaluate our approach on multipledatasets and with two measurement spaces (Gaussian, Radon). Our results confirmthe benefits of adaptive strategies in low-acquisition horizon settings.</description><author>Gianluigi Silvestri, Fabio Valerio Massoli, Tribhuvanesh Orekondy, Afshin Abdi, Arash Behboodi</author><pubDate>Wed, 10 Jul 2024 16:12:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07794v1</guid></item><item><title>Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities</title><link>http://arxiv.org/abs/2407.07791v1</link><description>The rapid adoption of large language models (LLMs) in multi-agent systems hashighlighted their impressive capabilities in various applications, such ascollaborative problem-solving and autonomous negotiation. However, the securityimplications of these LLM-based multi-agent systems have not been thoroughlyinvestigated, particularly concerning the spread of manipulated knowledge. Inthis paper, we investigate this critical issue by constructing a detailedthreat model and a comprehensive simulation environment that mirrors real-worldmulti-agent deployments in a trusted platform. Subsequently, we propose a noveltwo-stage attack method involving Persuasiveness Injection and ManipulatedKnowledge Injection to systematically explore the potential for manipulatedknowledge (i.e., counterfactual and toxic knowledge) spread without explicitprompt manipulation. Our method leverages the inherent vulnerabilities of LLMs in handling worldknowledge, which can be exploited by attackers to unconsciously spreadfabricated information. Through extensive experiments, we demonstrate that ourattack method can successfully induce LLM-based agents to spread bothcounterfactual and toxic knowledge without degrading their foundationalcapabilities during agent communication. Furthermore, we show that thesemanipulations can persist through popular retrieval-augmented generationframeworks, where several benign agents store and retrieve manipulated chathistories for future interactions. This persistence indicates that even afterthe interaction has ended, the benign agents may continue to be influenced bymanipulated knowledge. Our findings reveal significant security risks inLLM-based multi-agent systems, emphasizing the imperative need for robustdefenses against manipulated knowledge spread, such as introducing ``guardian''agents and advanced fact-checking tools.</description><author>Tianjie Ju, Yiting Wang, Xinbei Ma, Pengzhou Cheng, Haodong Zhao, Yulong Wang, Lifeng Liu, Jian Xie, Zhuosheng Zhang, Gongshen Liu</author><pubDate>Wed, 10 Jul 2024 16:08:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07791v1</guid></item><item><title>Manipulating Feature Visualizations with Gradient Slingshots</title><link>http://arxiv.org/abs/2401.06122v2</link><description>Deep Neural Networks (DNNs) are capable of learning complex and versatilerepresentations, however, the semantic nature of the learned concepts remainsunknown. A common method used to explain the concepts learned by DNNs isFeature Visualization (FV), which generates a synthetic input signal thatmaximally activates a particular neuron in the network. In this paper, weinvestigate the vulnerability of this approach to adversarial modelmanipulations and introduce a novel method for manipulating FV withoutsignificantly impacting the model's decision-making process. The keydistinction of our proposed approach is that it does not alter the modelarchitecture. We evaluate the effectiveness of our method on several neuralnetwork models and demonstrate its capabilities to hide the functionality ofarbitrarily chosen neurons by masking the original explanations of neurons withchosen target explanations during model auditing.</description><author>Dilyara Bareeva, Marina M. -C. Höhne, Alexander Warnecke, Lukas Pirch, Klaus-Robert Müller, Konrad Rieck, Kirill Bykov</author><pubDate>Wed, 10 Jul 2024 16:08:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06122v2</guid></item><item><title>Raising the Ceiling: Conflict-Free Local Feature Matching with Dynamic View Switching</title><link>http://arxiv.org/abs/2407.07789v1</link><description>Current feature matching methods prioritize improving modeling capabilitiesto better align outputs with ground-truth matches, which are the theoreticalupper bound on matching results, metaphorically depicted as the "ceiling".However, these enhancements fail to address the underlying issues that directlyhinder ground-truth matches, including the scarcity of matchable points insmall scale images, matching conflicts in dense methods, and thekeypoint-repeatability reliance in sparse methods. We propose a novel featurematching method named RCM, which Raises the Ceiling of Matching from threeaspects. 1) RCM introduces a dynamic view switching mechanism to address thescarcity of matchable points in source images by strategically switching imagepairs. 2) RCM proposes a conflict-free coarse matching module, addressingmatching conflicts in the target image through a many-to-one matching strategy.3) By integrating the semi-sparse paradigm and the coarse-to-fine architecture,RCM preserves the benefits of both high efficiency and global search,mitigating the reliance on keypoint repeatability. As a result, RCM enablesmore matchable points in the source image to be matched in an exhaustive andconflict-free manner in the target image, leading to a substantial 260%increase in ground-truth matches. Comprehensive experiments show that RCMexhibits remarkable performance and efficiency in comparison tostate-of-the-art methods.</description><author>Xiaoyong Lu, Songlin Du</author><pubDate>Wed, 10 Jul 2024 16:06:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07789v1</guid></item><item><title>BiGym: A Demo-Driven Mobile Bi-Manual Manipulation Benchmark</title><link>http://arxiv.org/abs/2407.07788v1</link><description>We introduce BiGym, a new benchmark and learning environment for mobilebi-manual demo-driven robotic manipulation. BiGym features 40 diverse tasks setin home environments, ranging from simple target reaching to complex kitchencleaning. To capture the real-world performance accurately, we providehuman-collected demonstrations for each task, reflecting the diverse modalitiesfound in real-world robot trajectories. BiGym supports a variety ofobservations, including proprioceptive data and visual inputs such as RGB, anddepth from 3 camera views. To validate the usability of BiGym, we thoroughlybenchmark the state-of-the-art imitation learning algorithms and demo-drivenreinforcement learning algorithms within the environment and discuss the futureopportunities.</description><author>Nikita Chernyadev, Nicholas Backshall, Xiao Ma, Yunfan Lu, Younggyo Seo, Stephen James</author><pubDate>Wed, 10 Jul 2024 16:04:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07788v1</guid></item><item><title>Continuous Control with Coarse-to-fine Reinforcement Learning</title><link>http://arxiv.org/abs/2407.07787v1</link><description>Despite recent advances in improving the sample-efficiency of reinforcementlearning (RL) algorithms, designing an RL algorithm that can be practicallydeployed in real-world environments remains a challenge. In this paper, wepresent Coarse-to-fine Reinforcement Learning (CRL), a framework that trains RLagents to zoom-into a continuous action space in a coarse-to-fine manner,enabling the use of stable, sample-efficient value-based RL algorithms forfine-grained continuous control tasks. Our key idea is to train agents thatoutput actions by iterating the procedure of (i) discretizing the continuousaction space into multiple intervals and (ii) selecting the interval with thehighest Q-value to further discretize at the next level. We then introduce aconcrete, value-based algorithm within the CRL framework called Coarse-to-fineQ-Network (CQN). Our experiments demonstrate that CQN significantly outperformsRL and behavior cloning baselines on 20 sparsely-rewarded RLBench manipulationtasks with a modest number of environment interactions and expertdemonstrations. We also show that CQN robustly learns to solve real-worldmanipulation tasks within a few minutes of online training.</description><author>Younggyo Seo, Jafar Uruç, Stephen James</author><pubDate>Wed, 10 Jul 2024 16:04:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07787v1</guid></item><item><title>PhenDiff: Revealing Subtle Phenotypes with Diffusion Models in Real Images</title><link>http://arxiv.org/abs/2312.08290v2</link><description>For the past few years, deep generative models have increasingly been used inbiological research for a variety of tasks. Recently, they have proven to bevaluable for uncovering subtle cell phenotypic differences that are notdirectly discernible to the human eye. However, current methods employed toachieve this goal mainly rely on Generative Adversarial Networks (GANs). Whileeffective, GANs encompass issues such as training instability and modecollapse, and they do not accurately map images back to the model's latentspace, which is necessary to synthesize, manipulate, and thus interpret outputsbased on real images. In this work, we introduce PhenDiff: a multi-classconditional method leveraging Diffusion Models (DMs) designed to identifyshifts in cellular phenotypes by translating a real image from one condition toanother. We qualitatively and quantitatively validate this method on caseswhere the phenotypic changes are visible or invisible, such as in lowconcentrations of drug treatments. Overall, PhenDiff represents a valuable toolfor identifying cellular variations in real microscopy images. We anticipatethat it could facilitate the understanding of diseases and advance drugdiscovery through the identification of novel biomarkers.</description><author>Anis Bourou, Thomas Boyer, Kévin Daupin, Véronique Dubreuil, Aurélie De Thonel, Valérie Mezger, Auguste Genovesio</author><pubDate>Wed, 10 Jul 2024 16:04:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.08290v2</guid></item><item><title>The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing</title><link>http://arxiv.org/abs/2407.07786v1</link><description>Rapid progress in general-purpose AI has sparked significant interest in "redteaming," a practice of adversarial testing originating in military andcybersecurity applications. AI red teaming raises many questions about thehuman factor, such as how red teamers are selected, biases and blindspots inhow tests are conducted, and harmful content's psychological effects on redteamers. A growing body of HCI and CSCW literature examines relatedpractices-including data labeling, content moderation, and algorithmicauditing. However, few, if any, have investigated red teaming itself. Thisworkshop seeks to consider the conceptual and empirical challenges associatedwith this practice, often rendered opaque by non-disclosure agreements. Futurestudies may explore topics ranging from fairness to mental health and otherareas of potential harm. We aim to facilitate a community of researchers andpractitioners who can begin to meet these challenges with creativity,innovation, and thoughtful reflection.</description><author>Alice Qian Zhang, Ryland Shaw, Jacy Reese Anthis, Ashlee Milton, Emily Tseng, Jina Suh, Lama Ahmad, Ram Shankar Siva Kumar, Julian Posada, Benjamin Shestakofsky, Sarah T. Roberts, Mary L. Gray</author><pubDate>Wed, 10 Jul 2024 16:02:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07786v1</guid></item><item><title>Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence</title><link>http://arxiv.org/abs/2407.07061v2</link><description>The rapid advancement of large language models (LLMs) has paved the way forthe development of highly capable autonomous agents. However, existingmulti-agent frameworks often struggle with integrating diverse capablethird-party agents due to reliance on agents defined within their ownecosystems. They also face challenges in simulating distributed environments,as most frameworks are limited to single-device setups. Furthermore, theseframeworks often rely on hard-coded communication pipelines, limiting theiradaptability to dynamic task requirements. Inspired by the concept of theInternet, we propose the Internet of Agents (IoA), a novel framework thataddresses these limitations by providing a flexible and scalable platform forLLM-based multi-agent collaboration. IoA introduces an agent integrationprotocol, an instant-messaging-like architecture design, and dynamic mechanismsfor agent teaming and conversation flow control. Through extensive experimentson general assistant tasks, embodied AI tasks, and retrieval-augmentedgeneration benchmarks, we demonstrate that IoA consistently outperformsstate-of-the-art baselines, showcasing its ability to facilitate effectivecollaboration among heterogeneous agents. IoA represents a step towards linkingdiverse agents in an Internet-like environment, where agents can seamlesslycollaborate to achieve greater intelligence and capabilities. Our codebase hasbeen released at \url{https://github.com/OpenBMB/IoA}.</description><author>Weize Chen, Ziming You, Ran Li, Yitong Guan, Chen Qian, Chenyang Zhao, Cheng Yang, Ruobing Xie, Zhiyuan Liu, Maosong Sun</author><pubDate>Wed, 10 Jul 2024 15:57:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07061v2</guid></item><item><title>Sequential Kalman Monte Carlo for gradient-free inference in Bayesian inverse problems</title><link>http://arxiv.org/abs/2407.07781v1</link><description>Ensemble Kalman Inversion (EKI) has been proposed as an efficient method forsolving inverse problems with expensive forward models. However, the method isbased on the assumption that we proceed through a sequence of Gaussian measuresin moving from the prior to the posterior, and that the forward model islinear. In this work, we introduce Sequential Kalman Monte Carlo (SKMC)samplers, where we exploit EKI and Flow Annealed Kalman Inversion (FAKI) withina Sequential Monte Carlo (SMC) sampling scheme to perform efficientgradient-free inference in Bayesian inverse problems. FAKI employs normalizingflows (NF) to relax the Gaussian ansatz of the target measures in EKI. NFs areable to learn invertible maps between a Gaussian latent space and the originaldata space, allowing us to perform EKI updates in the Gaussianized NF latentspace. However, FAKI alone is not able to correct for the model linearityassumptions in EKI. Errors in the particle distribution as we move through thesequence of target measures can therefore compound to give incorrect posteriormoment estimates. In this work we consider the use of EKI and FAKI toinitialize the particle distribution for each target in an adaptive SMCannealing scheme, before performing t-preconditioned Crank-Nicolson (tpCN)updates to distribute particles according to the target. We demonstrate theperformance of these SKMC samplers on three challenging numerical benchmarks,showing significant improvements in the rate of convergence compared tostandard SMC with importance weighted resampling at each temperature level.Code implementing the SKMC samplers is available athttps://github.com/RichardGrumitt/KalmanMC.</description><author>Richard D. P. Grumitt, Minas Karamanis, Uroš Seljak</author><pubDate>Wed, 10 Jul 2024 15:56:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07781v1</guid></item><item><title>Cross Domain Object Detection via Multi-Granularity Confidence Alignment based Mean Teacher</title><link>http://arxiv.org/abs/2407.07780v1</link><description>Cross domain object detection learns an object detector for an unlabeledtarget domain by transferring knowledge from an annotated source domain.Promising results have been achieved via Mean Teacher, however, pseudo labelingwhich is the bottleneck of mutual learning remains to be further explored. Inthis study, we find that confidence misalignment of the predictions, includingcategory-level overconfidence, instance-level task confidence inconsistency,and image-level confidence misfocusing, leading to the injection of noisypseudo label in the training process, will bring suboptimal performance on thetarget domain. To tackle this issue, we present a novel general frameworktermed Multi-Granularity Confidence Alignment Mean Teacher (MGCAMT) for crossdomain object detection, which alleviates confidence misalignment acrosscategory-, instance-, and image-levels simultaneously to obtain high qualitypseudo supervision for better teacher-student learning. Specifically, to alignconfidence with accuracy at category level, we propose ClassificationConfidence Alignment (CCA) to model category uncertainty based on EvidentialDeep Learning (EDL) and filter out the category incorrect labels via anuncertainty-aware selection strategy. Furthermore, to mitigate theinstance-level misalignment between classification and localization, we designTask Confidence Alignment (TCA) to enhance the interaction between the two taskbranches and allow each classification feature to adaptively locate the optimalfeature for the regression. Finally, we develop imagery Focusing ConfidenceAlignment (FCA) adopting another way of pseudo label learning, i.e., we use theoriginal outputs from the Mean Teacher network for supervised learning withoutlabel assignment to concentrate on holistic information in the target image.These three procedures benefit from each other from a cooperative learningperspective.</description><author>Jiangming Chen, Li Liu, Wanxia Deng, Zhen Liu, Yu Liu, Yingmei Wei, Yongxiang Liu</author><pubDate>Wed, 10 Jul 2024 15:56:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07780v1</guid></item><item><title>Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent</title><link>http://arxiv.org/abs/2402.09844v3</link><description>The search for a general model that can operate seamlessly across multipledomains remains a key goal in machine learning research. The prevailingmethodology in Reinforcement Learning (RL) typically limits models to a singletask within a unimodal framework, a limitation that contrasts with the broadervision of a versatile, multi-domain model. In this paper, we present Jack ofAll Trades (JAT), a transformer-based model with a unique design optimized forhandling sequential decision-making tasks and multi-modal data types. The JATmodel demonstrates its robust capabilities and versatility by achieving strongperformance on very different RL benchmarks, along with promising results onComputer Vision (CV) and Natural Language Processing (NLP) tasks, all using asingle set of weights. The JAT model marks a significant step towards moregeneral, cross-domain AI model design, and notably, it is the first model ofits kind to be fully open-sourced at https://huggingface.co/jat-project/jat,including a pioneering general-purpose dataset.</description><author>Quentin Gallouédec, Edward Beeching, Clément Romac, Emmanuel Dellandréa</author><pubDate>Wed, 10 Jul 2024 15:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09844v3</guid></item><item><title>Prompting Language-Informed Distribution for Compositional Zero-Shot Learning</title><link>http://arxiv.org/abs/2305.14428v3</link><description>Compositional zero-shot learning (CZSL) task aims to recognize unseencompositional visual concepts, e.g., sliced tomatoes, where the model islearned only from the seen compositions, e.g., sliced potatoes and redtomatoes. Thanks to the prompt tuning on large pre-trained visual languagemodels such as CLIP, recent literature shows impressively better CZSLperformance than traditional vision-based methods. However, the key aspectsthat impact the generalization to unseen compositions, including the diversityand informativeness of class context, and the entanglement between visualprimitives, i.e., state and object, are not properly addressed in existingCLIP-based CZSL literature. In this paper, we propose a model by prompting thelanguage-informed distribution, aka., PLID, for the CZSL task. Specifically,the PLID leverages pre-trained large language models (LLM) to (i) formulate thelanguage-informed class distributions which are diverse and informative, and(ii) enhance the compositionality of the class embedding. Moreover, avisual-language primitive decomposition (VLPD) module is proposed todynamically fuse the classification decisions from the compositional and theprimitive space. Orthogonal to the existing literature of soft, hard, ordistributional prompts, our method advocates prompting the LLM-supported classdistributions, leading to a better zero-shot generalization. Experimentalresults on MIT-States, UT-Zappos, and C-GQA datasets show the superiorperformance of the PLID to the prior arts. Our code and models are released:https://github.com/Cogito2012/PLID.</description><author>Wentao Bao, Lichang Chen, Heng Huang, Yu Kong</author><pubDate>Wed, 10 Jul 2024 15:54:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14428v3</guid></item><item><title>Vanilla Feedforward Neural Networks as a Discretization of Dynamical Systems</title><link>http://arxiv.org/abs/2209.10909v2</link><description>Deep learning has made significant applications in the field of data scienceand natural science. Some studies have linked deep neural networks to dynamicsystems, but the network structure is restricted to the residual network. It isknown that residual networks can be regarded as a numerical discretization ofdynamic systems. In this paper, we back to the classical network structure andprove that the vanilla feedforward networks could also be a numericaldiscretization of dynamic systems, where the width of the network is equal tothe dimension of the input and output. Our proof is based on the properties ofthe leaky-ReLU function and the numerical technique of splitting method tosolve differential equations. Our results could provide a new perspective forunderstanding the approximation properties of feedforward neural networks.</description><author>Yifei Duan, Li'ang Li, Guanghua Ji, Yongqiang Cai</author><pubDate>Wed, 10 Jul 2024 15:53:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.10909v2</guid></item><item><title>NuTime: Numerically Multi-Scaled Embedding for Large-Scale Time-Series Pretraining</title><link>http://arxiv.org/abs/2310.07402v3</link><description>Recent research on time-series self-supervised models shows great promise inlearning semantic representations. However, it has been limited to small-scaledatasets, e.g., thousands of temporal sequences. In this work, we make keytechnical contributions that are tailored to the numerical properties oftime-series data and allow the model to scale to large datasets, e.g., millionsof temporal sequences. We adopt the Transformer architecture by firstpartitioning the input into non-overlapping windows. Each window is thencharacterized by its normalized shape and two scalar values denoting the meanand standard deviation within each window. To embed scalar values that maypossess arbitrary numerical amplitudes in a high-dimensional space, we proposea numerically multi-scaled embedding module enumerating all possible numericalscales for the scalars. The model undergoes pretraining with a simplecontrastive objective on a large-scale dataset over a million sequencescollected by merging existing public data. We study its transfer performance ona number of univariate and multivariate classification tasks, few shotlearning, unsupervised clustering and anomaly detection benchmarks. Our methodexhibits remarkable improvement against previous pretraining approaches andestablishes the new state of the art, even compared with domain-specificnon-learning-based methods. Code is available at:\url{https://github.com/chenguolin/NuTime}.</description><author>Chenguo Lin, Xumeng Wen, Wei Cao, Congrui Huang, Jiang Bian, Stephen Lin, Zhirong Wu</author><pubDate>Wed, 10 Jul 2024 15:52:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.07402v3</guid></item><item><title>WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment</title><link>http://arxiv.org/abs/2407.07778v1</link><description>AI systems make decisions in physical environments through primitive actionsor affordances that are accessed via API calls. While deploying AI agents inthe real world involves numerous high-level actions, existing embodiedsimulators offer a limited set of domain-salient APIs. This naturally brings upthe questions: how many primitive actions (APIs) are needed for a versatileembodied agent, and what should they look like? We explore this via a thoughtexperiment: assuming that wikiHow tutorials cover a wide variety ofhuman-written tasks, what is the space of APIs needed to cover theseinstructions? We propose a framework to iteratively induce new APIs bygrounding wikiHow instruction to situated agent policies. Inspired by recentsuccesses in large language models (LLMs) for embodied planning, we propose afew-shot prompting to steer GPT-4 to generate Pythonic programs as agentpolicies and bootstrap a universe of APIs by 1) reusing a seed set of APIs; andthen 2) fabricate new API calls when necessary. The focus of this thoughtexperiment is on defining these APIs rather than their executability. We applythe proposed pipeline on instructions from wikiHow tutorials. On a smallfraction (0.5%) of tutorials, we induce an action space of 300+ APIs necessaryfor capturing the rich variety of tasks in the physical world. A detailedautomatic and human analysis of the induction output reveals that the proposedpipeline enables effective reuse and creation of APIs. Moreover, a manualreview revealed that existing simulators support only a small subset of theinduced APIs (9 of the top 50 frequent APIs), motivating the development ofaction-rich embodied environments.</description><author>Jiefu Ou, Arda Uzunoglu, Benjamin Van Durme, Daniel Khashabi</author><pubDate>Wed, 10 Jul 2024 15:52:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07778v1</guid></item><item><title>Bridging Synthetic and Real Worlds for Pre-training Scene Text Detectors</title><link>http://arxiv.org/abs/2312.05286v3</link><description>Existing scene text detection methods typically rely on extensive real datafor training. Due to the lack of annotated real images, recent works haveattempted to exploit large-scale labeled synthetic data (LSD) for pre-trainingtext detectors. However, a synth-to-real domain gap emerges, further limitingthe performance of text detectors. Differently, in this work, we proposeFreeReal, a real-domain-aligned pre-training paradigm that enables thecomplementary strengths of both LSD and unlabeled real data (URD).Specifically, to bridge real and synthetic worlds for pre-training, aglyph-based mixing mechanism (GlyphMix) is tailored for text images.GlyphMixdelineates the character structures of synthetic images and embeds them asgraffiti-like units onto real images. Without introducing real domain drift,GlyphMix freely yields real-world images with annotations derived fromsynthetic labels. Furthermore, when given free fine-grained synthetic labels,GlyphMix can effectively bridge the linguistic domain gap stemming fromEnglish-dominated LSD to URD in various languages. Without bells and whistles,FreeReal achieves average gains of 1.97%, 3.90%, 3.85%, and 4.56% in improvingthe performance of FCENet, PSENet, PANet, and DBNet methods, respectively,consistently outperforming previous pre-training methods by a substantialmargin across four public datasets. Code is available athttps://github.com/SJTU-DeepVisionLab/FreeReal.</description><author>Tongkun Guan, Wei Shen, Xue Yang, Xuehui Wang, Xiaokang Yang</author><pubDate>Wed, 10 Jul 2024 15:49:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05286v3</guid></item><item><title>Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs</title><link>http://arxiv.org/abs/2407.07775v1</link><description>An elusive goal in navigation research is to build an intelligent agent thatcan understand multimodal instructions including natural language and image,and perform useful navigation. To achieve this, we study a widely usefulcategory of navigation tasks we call Multimodal Instruction Navigation withdemonstration Tours (MINT), in which the environment prior is provided througha previously recorded demonstration video. Recent advances in Vision LanguageModels (VLMs) have shown a promising path in achieving this goal as itdemonstrates capabilities in perceiving and reasoning about multimodal inputs.However, VLMs are typically trained to predict textual output and it is an openresearch question about how to best utilize them in navigation. To solve MINT,we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigationpolicy that combines the environment understanding and common sense reasoningpower of long-context VLMs and a robust low-level navigation policy based ontopological graphs. The high-level policy consists of a long-context VLM thattakes the demonstration tour video and the multimodal user instruction as inputto find the goal frame in the tour video. Next, a low-level policy uses thegoal frame and an offline constructed topological graph to generate robotactions at every timestep. We evaluated Mobility VLA in a 836m^2 real worldenvironment and show that Mobility VLA has a high end-to-end success rates onpreviously unsolved multimodal instructions such as "Where should I returnthis?" while holding a plastic bin.</description><author>Hao-Tien Lewis Chiang, Zhuo Xu, Zipeng Fu, Mithun George Jacob, Tingnan Zhang, Tsang-Wei Edward Lee, Wenhao Yu, Connor Schenck, David Rendleman, Dhruv Shah, Fei Xia, Jasmine Hsu, Jonathan Hoech, Pete Florence, Sean Kirmani, Sumeet Singh, Vikas Sindhwani, Carolina Parada, Chelsea Finn, Peng Xu, Sergey Levine, Jie Tan</author><pubDate>Wed, 10 Jul 2024 15:49:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07775v1</guid></item><item><title>Multi-task Prompt Words Learning for Social Media Content Generation</title><link>http://arxiv.org/abs/2407.07771v1</link><description>The rapid development of the Internet has profoundly changed human life.Humans are increasingly expressing themselves and interacting with others onsocial media platforms. However, although artificial intelligence technologyhas been widely used in many aspects of life, its application in social mediacontent creation is still blank. To solve this problem, we propose a new promptword generation framework based on multi-modal information fusion, whichcombines multiple tasks including topic classification, sentiment analysis,scene recognition and keyword extraction to generate more comprehensive promptwords. Subsequently, we use a template containing a set of prompt words toguide ChatGPT to generate high-quality tweets. Furthermore, in the absence ofeffective and objective evaluation criteria in the field of content generation,we use the ChatGPT tool to evaluate the results generated by the algorithm,making large-scale evaluation of content generation algorithms possible.Evaluation results on extensive content generation demonstrate that our cueword generation framework generates higher quality content compared to manualmethods and other cueing techniques, while topic classification, sentimentanalysis, and scene recognition significantly enhance content clarity and itsconsistency with the image.</description><author>Haochen Xue, Chong Zhang, Chengzhi Liu, Fangyu Wu, Xiaobo Jin</author><pubDate>Wed, 10 Jul 2024 15:46:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.07771v1</guid></item></channel></rss>