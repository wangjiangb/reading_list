<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 05 Aug 2024 01:00:24 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Gemma 2: Improving Open Language Models at a Practical Size</title><link>http://arxiv.org/abs/2408.00118v2</link><description>In this work, we introduce Gemma 2, a new addition to the Gemma family oflightweight, state-of-the-art open models, ranging in scale from 2 billion to27 billion parameters. In this new version, we apply several known technicalmodifications to the Transformer architecture, such as interleavinglocal-global attentions (Beltagy et al., 2020a) and group-query attention(Ainslie et al., 2023). We also train the 2B and 9B models with knowledgedistillation (Hinton et al., 2015) instead of next token prediction. Theresulting models deliver the best performance for their size, and even offercompetitive alternatives to models that are 2-3 times bigger. We release allour models to the community.</description><author>Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, Johan Ferret, Peter Liu, Pouya Tafti, Abe Friesen, Michelle Casbon, Sabela Ramos, Ravin Kumar, Charline Le Lan, Sammy Jerome, Anton Tsitsulin, Nino Vieillard, Piotr Stanczyk, Sertan Girgin, Nikola Momchev, Matt Hoffman, Shantanu Thakoor, Jean-Bastien Grill, Behnam Neyshabur, Olivier Bachem, Alanna Walton, Aliaksei Severyn, Alicia Parrish, Aliya Ahmad, Allen Hutchison, Alvin Abdagic, Amanda Carl, Amy Shen, Andy Brock, Andy Coenen, Anthony Laforge, Antonia Paterson, Ben Bastian, Bilal Piot, Bo Wu, Brandon Royal, Charlie Chen, Chintu Kumar, Chris Perry, Chris Welty, Christopher A. Choquette-Choo, Danila Sinopalnikov, David Weinb</author><pubDate>Fri, 02 Aug 2024 17:52:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00118v2</guid></item><item><title>Reinforcement Learning applied to Insurance Portfolio Pursuit</title><link>http://arxiv.org/abs/2408.00713v2</link><description>When faced with a new customer, many factors contribute to an insurancefirm's decision of what offer to make to that customer. In addition to theexpected cost of providing the insurance, the firm must consider the otheroffers likely to be made to the customer, and how sensitive the customer is todifferences in price. Moreover, firms often target a specific portfolio ofcustomers that could depend on, e.g., age, location, and occupation. Given sucha target portfolio, firms may choose to modulate an individual customer's offerbased on whether the firm desires the customer within their portfolio. We termthe problem of modulating offers to achieve a desired target portfolio theportfolio pursuit problem. Having formulated the portfolio pursuit problem as asequential decision making problem, we devise a novel reinforcement learningalgorithm for its solution. We test our method on a complex synthetic marketenvironment, and demonstrate that it outperforms a baseline method which mimicscurrent industry approaches to portfolio pursuit.</description><author>Edward James Young, Alistair Rogers, Elliott Tong, James Jordon</author><pubDate>Fri, 02 Aug 2024 14:40:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00713v2</guid></item><item><title>Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning</title><link>http://arxiv.org/abs/2408.00690v2</link><description>While Large Language Models show remarkable performance in natural languageunderstanding, their resource-intensive nature makes them less accessible. Incontrast, smaller language models such as MiniCPM offer more sustainablescalability, but often underperform without specialized optimization. In thispaper, we explore the enhancement of smaller language models through theimprovement of their text embeddings. We select three language models, MiniCPM,Phi-2, and Gemma, to conduct contrastive fine-tuning on the NLI dataset. Ourresults demonstrate that this fine-tuning method enhances the quality of textembeddings for all three models across various benchmarks, with MiniCPM showingthe most significant improvements of an average 56.33% performance gain. Thecontrastive fine-tuning code is publicly available athttps://github.com/trapoom555/Language-Model-STS-CFT.</description><author>Trapoom Ukarapol, Zhicheng Lee, Amy Xin</author><pubDate>Fri, 02 Aug 2024 14:36:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00690v2</guid></item><item><title>Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving</title><link>http://arxiv.org/abs/2408.00374v2</link><description>Current research on trajectory prediction primarily relies on data collectedby onboard sensors of an ego vehicle. With the rapid advancement in connectedtechnologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure(V2I) communication, valuable information from alternate views becomesaccessible via wireless networks. The integration of information fromalternative views has the potential to overcome the inherent limitationsassociated with a single viewpoint, such as occlusions and limited field ofview. In this work, we introduce V2INet, a novel trajectory predictionframework designed to model multi-view data by extending existing single-viewmodels. Unlike previous approaches where the multi-view data is manually fusedor formulated as a separate training stage, our model supports end-to-endtraining, enhancing both flexibility and performance. Moreover, the predictedmultimodal trajectories are calibrated by a post-hoc conformal predictionmodule to get valid and efficient confidence regions. We evaluated the entireframework using the real-world V2I dataset V2X-Seq. Our results demonstratesuperior performance in terms of Final Displacement Error (FDE) and Miss Rate(MR) using a single GPU. The code is publicly available at:\url{https://github.com/xichennn/V2I_trajectory_prediction}.</description><author>Xi Chen, Rahul Bhadani, Larry Head</author><pubDate>Fri, 02 Aug 2024 13:00:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00374v2</guid></item><item><title>Modelling Assessment Rubrics through Bayesian Networks: a Pragmatic Approach</title><link>http://arxiv.org/abs/2209.05467v3</link><description>Automatic assessment of learner competencies is a fundamental task inintelligent tutoring systems. An assessment rubric typically and effectivelydescribes relevant competencies and competence levels. This paper presents anapproach to deriving a learner model directly from an assessment rubricdefining some (partial) ordering of competence levels. The model is based onBayesian networks and exploits logical gates with uncertainty (often referredto as noisy gates) to reduce the number of parameters of the model, so tosimplify their elicitation by experts and allow real-time inference inintelligent tutoring systems. We illustrate how the approach can be applied toautomatize the human assessment of an activity developed for testingcomputational thinking skills. The simple elicitation of the model startingfrom the assessment rubric opens up the possibility of quickly automating theassessment of several tasks, making them more easily exploitable in the contextof adaptive assessment tools and intelligent tutoring systems.</description><author>Francesca Mangili, Giorgia Adorni, Alberto Piatti, Claudio Bonesana, Alessandro Antonucci</author><pubDate>Fri, 02 Aug 2024 12:27:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.05467v3</guid></item><item><title>Depth-Wise Convolutions in Vision Transformers for Efficient Training on Small Datasets</title><link>http://arxiv.org/abs/2407.19394v3</link><description>The Vision Transformer (ViT) leverages the Transformer's encoder to captureglobal information by dividing images into patches and achieves superiorperformance across various computer vision tasks. However, the self-attentionmechanism of ViT captures the global context from the outset, overlooking theinherent relationships between neighboring pixels in images or videos.Transformers mainly focus on global information while ignoring the fine-grainedlocal details. Consequently, ViT lacks inductive bias during image or videodataset training. In contrast, convolutional neural networks (CNNs), with theirreliance on local filters, possess an inherent inductive bias, making them moreefficient and quicker to converge than ViT with less data. In this paper, wepresent a lightweight Depth-Wise Convolution module as a shortcut in ViTmodels, bypassing entire Transformer blocks to ensure the models capture bothlocal and global information with minimal overhead. Additionally, we introducetwo architecture variants, allowing the Depth-Wise Convolution modules to beapplied to multiple Transformer blocks for parameter savings, and incorporatingindependent parallel Depth-Wise Convolution modules with different kernels toenhance the acquisition of local information. The proposed approachsignificantly boosts the performance of ViT models on image classification,object detection and instance segmentation by a large margin, especially onsmall datasets, as evaluated on CIFAR-10, CIFAR-100, Tiny-ImageNet and ImageNetfor image classification, and COCO for object detection and instancesegmentation. The source code can be accessed athttps://github.com/ZTX-100/Efficient_ViT_with_DW.</description><author>Tianxiao Zhang, Wenju Xu, Bo Luo, Guanghui Wang</author><pubDate>Fri, 02 Aug 2024 10:05:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.19394v3</guid></item><item><title>SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models</title><link>http://arxiv.org/abs/2408.00655v2</link><description>Contemporary large language models (LLMs) primarily rely on next-tokenprediction method for inference, which significantly impedes their processingspeed. In this paper, we introduce a novel inference methodology termednext-sentence prediction, aimed at enhancing the inference efficiency of LLMs.We present Sentence Variational Autoencoder (SentenceVAE), a tiny modelconsisting of a Sentence Encoder and a Sentence Decoder. The encodereffectively condenses the information within a sentence into a singular token,while the decoder reconstructs this compressed data back into its originalsentential form. By integrating SentenceVAE into the input and output layers ofLLMs, we develop Sentence-level LLMs (SLLMs) that employ a sentence-by-sentenceinference approach, markedly accelerating inference speeds. SentenceVAE alsomaintains the integrity of the original semantic content by segmenting the textinto sentences, thereby improving accuracy while boosting inference speeds.Compared to published LLMs, SLLMs process fewer tokens over equivalent contextlengths, significantly reducing memory demands for self-attention computationsand facilitating the handling of longer contexts. Our experimental findingsreveal that this method can accelerate inference speeds by 204~365%, reduceperplexity (PPL) to 46~75% of its original metric, and decrease memory overheadby 86~91% for the same context length, compared to the token-by-token method.Moreover, the benefits of this approach become even more pronounced as modelparameters increase.</description><author>Hongjun An, Yifan Chen, Xiaozhen Qiao, Zhe Sun, Xuelong Li</author><pubDate>Fri, 02 Aug 2024 08:27:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00655v2</guid></item><item><title>Infrequent Resolving Algorithm for Online Linear Programming</title><link>http://arxiv.org/abs/2408.00465v2</link><description>Online linear programming (OLP) has gained significant attention from bothresearchers and practitioners due to its extensive applications, such as onlineauction, network revenue management and advertising. Existing OLP algorithmsfall into two categories: LP-based algorithms and LP-free algorithms. Theformer one typically guarantees better performance, even offering a constantregret, but requires solving a large number of LPs, which could becomputationally expensive. In contrast, LP-free algorithm only requiresfirst-order computations but induces a worse performance, lacking a constantregret bound. In this work, we bridge the gap between these two extremes byproposing an algorithm that achieves a constant regret while solving LPs only$O(\log\log T)$ times over the time horizon $T$. Moreover, when we are allowedto solve LPs only $M$ times, we propose an algorithm that can guarantee an$O\left(T^{(1/2+\epsilon)^{M-1}}\right)$ regret. Furthermore, when the arrivalprobabilities are known at the beginning, our algorithm can guarantee aconstant regret by solving LPs $O(\log\log T)$ times, and an$O\left(T^{(1/2+\epsilon)^{M}}\right)$ regret by solving LPs only $M$ times.Numerical experiments are conducted to demonstrate the efficiency of theproposed algorithms.</description><author>Guokai Li, Zizhuo Wang, Jingwei Zhang</author><pubDate>Fri, 02 Aug 2024 03:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00465v2</guid></item><item><title>Adaptive Self-training Framework for Fine-grained Scene Graph Generation</title><link>http://arxiv.org/abs/2401.09786v5</link><description>Scene graph generation (SGG) models have suffered from inherent problemsregarding the benchmark datasets such as the long-tailed predicate distributionand missing annotation problems. In this work, we aim to alleviate thelong-tailed problem of SGG by utilizing unannotated triplets. To this end, weintroduce a Self-Training framework for SGG (ST-SGG) that assigns pseudo-labelsfor unannotated triplets based on which the SGG models are trained. While therehas been significant progress in self-training for image recognition, designinga self-training framework for the SGG task is more challenging due to itsinherent nature such as the semantic ambiguity and the long-tailed distributionof predicate classes. Hence, we propose a novel pseudo-labeling technique forSGG, called Class-specific Adaptive Thresholding with Momentum (CATM), which isa model-agnostic framework that can be applied to any existing SGG models.Furthermore, we devise a graph structure learner (GSL) that is beneficial whenadopting our proposed self-training framework to the state-of-the-artmessage-passing neural network (MPNN)-based SGG models. Our extensiveexperiments verify the effectiveness of ST-SGG on various SGG models,particularly in enhancing the performance on fine-grained predicate classes.</description><author>Kibum Kim, Kanghoon Yoon, Yeonjun In, Jinyoung Moon, Donghyun Kim, Chanyoung Park</author><pubDate>Fri, 02 Aug 2024 01:22:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09786v5</guid></item><item><title>Optimizing Diffusion Models for Joint Trajectory Prediction and Controllable Generation</title><link>http://arxiv.org/abs/2408.00766v1</link><description>Diffusion models are promising for joint trajectory prediction andcontrollable generation in autonomous driving, but they face challenges ofinefficient inference steps and high computational demands. To tackle thesechallenges, we introduce Optimal Gaussian Diffusion (OGD) and Estimated CleanManifold (ECM) Guidance. OGD optimizes the prior distribution for a smalldiffusion time $T$ and starts the reverse diffusion process from it. ECMdirectly injects guidance gradients to the estimated clean manifold,eliminating extensive gradient backpropagation throughout the network. Ourmethodology streamlines the generative process, enabling practical applicationswith reduced computational overhead. Experimental validation on the large-scaleArgoverse 2 dataset demonstrates our approach's superior performance, offeringa viable solution for computationally efficient, high-quality joint trajectoryprediction and controllable generation for autonomous driving. Our projectwebpage is at https://yixiaowang7.github.io/OptTrajDiff_Page/.</description><author>Yixiao Wang, Chen Tang, Lingfeng Sun, Simone Rossi, Yichen Xie, Chensheng Peng, Thomas Hannagan, Stefano Sabatini, Nicola Poerio, Masayoshi Tomizuka, Wei Zhan</author><pubDate>Thu, 01 Aug 2024 17:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00766v1</guid></item><item><title>MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities</title><link>http://arxiv.org/abs/2408.00765v1</link><description>MM-Vet, with open-ended vision-language questions targeting at evaluatingintegrated capabilities, has become one of the most popular benchmarks forlarge multimodal model evaluation. MM-Vet assesses six core vision-language(VL) capabilities: recognition, knowledge, spatial awareness, languagegeneration, OCR, and math. However, its question format is restricted to singleimage-text pairs, lacking the interleaved image and text sequences prevalent inreal-world scenarios. To address this limitation, we introduce MM-Vet v2, whichincludes a new VL capability called "image-text sequence understanding",evaluating models' ability to process VL sequences. Furthermore, we maintainthe high quality of evaluation samples while further expanding the evaluationset size. Using MM-Vet v2 to benchmark large multimodal models, we found thatClaude 3.5 Sonnet is the best model with a score of 71.8, slightlyoutperforming GPT-4o which scored 71.0. Among open-weight models,InternVL2-Llama3-76B leads with a score of 68.4.</description><author>Weihao Yu, Zhengyuan Yang, Linfeng Ren, Linjie Li, Jianfeng Wang, Kevin Lin, Chung-Ching Lin, Zicheng Liu, Lijuan Wang, Xinchao Wang</author><pubDate>Thu, 01 Aug 2024 17:59:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00765v1</guid></item><item><title>AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation</title><link>http://arxiv.org/abs/2408.00764v1</link><description>Large Language Model (LLM) based agents have garnered significant attentionand are becoming increasingly popular. Furthermore, planning ability is acrucial component of an LLM-based agent, involving interaction with theenvironment and executing actions to complete a planning task, which generallyentails achieving a desired goal from an initial state. This paper investigatesenhancing the planning abilities of LLMs through instruction tuning, referredto as agent training. Recent studies have demonstrated that utilizingexpert-level trajectory for instruction-tuning LLMs effectively enhances theirplanning capabilities. However, existing work primarily focuses on synthesizingtrajectories from manually designed planning tasks and environments. Thelabor-intensive nature of creating these environments and tasks impedes thegeneration of sufficiently varied and extensive trajectories. To address thislimitation, this paper explores the automated synthesis of diverse environmentsand a gradual range of planning tasks, from easy to difficult. We introduce aframework, AgentGen, that leverages LLMs first to generate environments andsubsequently generate planning tasks conditioned on these environments.Specifically, to improve environmental diversity, we propose using aninspiration corpus composed of various domain-specific text segments as thecontext for synthesizing environments. Moreover, to increase the difficultydiversity of generated planning tasks, we propose a bidirectional evolutionmethod, Bi-Evol, that evolves planning tasks from easier and harder directionsto synthesize a task set with a smoother difficulty curve. The evaluationresults derived from AgentBoard show that AgentGen greatly improves LLMs'planning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpassesGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperformsGPT-4.</description><author>Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang</author><pubDate>Thu, 01 Aug 2024 17:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00764v1</guid></item><item><title>UniTalker: Scaling up Audio-Driven 3D Facial Animation through A Unified Model</title><link>http://arxiv.org/abs/2408.00762v1</link><description>Audio-driven 3D facial animation aims to map input audio to realistic facialmotion. Despite significant progress, limitations arise from inconsistent 3Dannotations, restricting previous models to training on specific annotationsand thereby constraining the training scale. In this work, we presentUniTalker, a unified model featuring a multi-head architecture designed toeffectively leverage datasets with varied annotations. To enhance trainingstability and ensure consistency among multi-head outputs, we employ threetraining strategies, namely, PCA, model warm-up, and pivot identity embedding.To expand the training scale and diversity, we assemble A2F-Bench, comprisingfive publicly available datasets and three newly curated datasets. Thesedatasets contain a wide range of audio domains, covering multilingual speechvoices and songs, thereby scaling the training data from commonly employeddatasets, typically less than 1 hour, to 18.5 hours. With a single trainedUniTalker model, we achieve substantial lip vertex error reductions of 9.2% forBIWI dataset and 13.7% for Vocaset. Additionally, the pre-trained UniTalkerexhibits promise as the foundation model for audio-driven facial animationtasks. Fine-tuning the pre-trained UniTalker on seen datasets further enhancesperformance on each dataset, with an average error reduction of 6.3% onA2F-Bench. Moreover, fine-tuning UniTalker on an unseen dataset with only halfthe data surpasses prior state-of-the-art models trained on the full dataset.The code and dataset are available at the project pagehttps://github.com/X-niper/UniTalker.</description><author>Xiangyu Fan, Jiaqi Li, Zhiqian Lin, Weiye Xiao, Lei Yang</author><pubDate>Thu, 01 Aug 2024 17:59:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00762v1</guid></item><item><title>Tamper-Resistant Safeguards for Open-Weight LLMs</title><link>http://arxiv.org/abs/2408.00761v1</link><description>Rapid advances in the capabilities of large language models (LLMs) haveraised widespread concerns regarding their potential for malicious use.Open-weight LLMs present unique challenges, as existing safeguards lackrobustness to tampering attacks that modify model weights. For example, recentworks have demonstrated that refusal and unlearning safeguards can be triviallyremoved with a few steps of fine-tuning. These vulnerabilities necessitate newapproaches for enabling the safe release of open-weight LLMs. We develop amethod, called TAR, for building tamper-resistant safeguards into open-weightLLMs such that adversaries cannot remove the safeguards even after thousands ofsteps of fine-tuning. In extensive evaluations and red teaming analyses, wefind that our method greatly improves tamper-resistance while preserving benigncapabilities. Our results demonstrate that tamper-resistance is a tractableproblem, opening up a promising new avenue to improve the safety and securityof open-weight LLMs.</description><author>Rishub Tamirisa, Bhrugu Bharathi, Long Phan, Andy Zhou, Alice Gatti, Tarun Suresh, Maxwell Lin, Justin Wang, Rowan Wang, Ron Arel, Andy Zou, Dawn Song, Bo Li, Dan Hendrycks, Mantas Mazeika</author><pubDate>Thu, 01 Aug 2024 17:59:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00761v1</guid></item><item><title>Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention</title><link>http://arxiv.org/abs/2408.00760v1</link><description>Conditional diffusion models have shown remarkable success in visual contentgeneration, producing high-quality samples across various domains, largely dueto classifier-free guidance (CFG). Recent attempts to extend guidance tounconditional models have relied on heuristic techniques, resulting insuboptimal generation quality and unintended effects. In this work, we proposeSmoothed Energy Guidance (SEG), a novel training- and condition-free approachthat leverages the energy-based perspective of the self-attention mechanism toenhance image generation. By defining the energy of self-attention, weintroduce a method to reduce the curvature of the energy landscape of attentionand use the output as the unconditional prediction. Practically, we control thecurvature of the energy landscape by adjusting the Gaussian kernel parameterwhile keeping the guidance scale parameter fixed. Additionally, we present aquery blurring method that is equivalent to blurring the entire attentionweights without incurring quadratic complexity in the number of tokens. In ourexperiments, SEG achieves a Pareto improvement in both quality and thereduction of side effects. The code is available at\url{https://github.com/SusungHong/SEG-SDXL}.</description><author>Susung Hong</author><pubDate>Thu, 01 Aug 2024 17:59:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00760v1</guid></item><item><title>Text-Guided Video Masked Autoencoder</title><link>http://arxiv.org/abs/2408.00759v1</link><description>Recent video masked autoencoder (MAE) works have designed improved maskingalgorithms focused on saliency. These works leverage visual cues such as motionto mask the most salient regions. However, the robustness of such visual cuesdepends on how often input videos match underlying assumptions. On the otherhand, natural language description is an information dense representation ofvideo that implicitly captures saliency without requiring modality-specificassumptions, and has not been explored yet for video MAE. To this end, weintroduce a novel text-guided masking algorithm (TGM) that masks the videoregions with highest correspondence to paired captions. Without leveraging anyexplicit visual cues for saliency, our TGM is competitive with state-of-the-artmasking algorithms such as motion-guided masking. To further benefit from thesemantics of natural language for masked reconstruction, we next introduce aunified framework for joint MAE and masked video-text contrastive learning. Weshow that across existing masking algorithms, unifying MAE and maskedvideo-text contrastive learning improves downstream performance compared topure MAE on a variety of video recognition tasks, especially for linear probe.Within this unified framework, our TGM achieves the best relative performanceon five action recognition and one egocentric datasets, highlighting thecomplementary nature of natural language for masked video modeling.</description><author>David Fan, Jue Wang, Shuai Liao, Zhikang Zhang, Vimal Bhat, Xinyu Li</author><pubDate>Thu, 01 Aug 2024 17:58:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00759v1</guid></item><item><title>Segment anything model 2: an application to 2D and 3D medical images</title><link>http://arxiv.org/abs/2408.00756v1</link><description>Segment Anything Model (SAM) has gained significant attention because of itsability to segment a variety of objects in images given a prompt. The recentlydeveloped SAM 2 has extended this ability to video inputs. This opens anopportunity to apply SAM to 3D images, one of the fundamental tasks in themedical imaging field. In this paper, we provide an extensive evaluation of SAM2's ability to segment both 2D and 3D medical images. We collect 18 medicalimaging datasets, including common 3D modalities such as computed tomography(CT), magnetic resonance imaging (MRI), and positron emission tomography (PET)as well as 2D modalities such as X-ray and ultrasound. We consider twoevaluation pipelines of SAM 2: (1) multi-frame 3D segmentation, where promptsare provided to one or multiple slice(s) selected from the volume, and (2)single-frame 2D segmentation, where prompts are provided to each slice. Theformer is only applicable to 3D modalities, while the latter applies to both 2Dand 3D modalities. We learn that SAM 2 exhibits similar performance as SAMunder single-frame 2D segmentation, and has variable performance undermulti-frame 3D segmentation depending on the choices of slices to annotate, thedirection of the propagation, the predictions utilized during the propagation,etc.</description><author>Haoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, Maciej A. Mazurowski</author><pubDate>Thu, 01 Aug 2024 17:57:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00756v1</guid></item><item><title>Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal Language Model</title><link>http://arxiv.org/abs/2408.00754v1</link><description>Multimodal language models (MLLMs) are increasingly being implemented inreal-world environments, necessitating their ability to interpret 3D spaces andcomprehend temporal dynamics. Despite their potential, current top modelswithin our community still fall short in adequately understanding spatial andtemporal dimensions. We introduce Coarse Correspondence, a simple,training-free, effective, and general-purpose visual prompting method to elicit3D and temporal understanding in multimodal LLMs. Our method uses a lightweighttracking model to find object correspondences between frames in a video orbetween sets of image viewpoints. It selects the most frequent object instancesand visualizes them with markers with unique IDs in the image. With this simpleapproach, we achieve state-of-the-art results on 3D understanding benchmarksincluding ScanQA (+20.5\%) and a subset of OpenEQA (+9.7\%), and on long-formvideo benchmarks such as EgoSchema (+6.0\%). We also curate a small diagnosticdataset to evaluate whether MLLMs can reason about space from a describedviewpoint other than the camera viewpoint. Again, Coarse Correspondenceimproves spatial perspective-taking abilities but we highlight that MLLMsstruggle with this task. Together, we demonstrate that our simple promptingmethod can significantly aid downstream tasks that require 3D or temporalreasoning.</description><author>Benlin Liu, Yuhao Dong, Yiqin Wang, Yongming Rao, Yansong Tang, Wei-Chiu Ma, Ranjay Krishna</author><pubDate>Thu, 01 Aug 2024 17:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00754v1</guid></item><item><title>A deep learning-enabled smart garment for versatile sleep behaviour monitoring</title><link>http://arxiv.org/abs/2408.00753v1</link><description>Continuous monitoring and accurate detection of complex sleep patternsassociated to different sleep-related conditions is essential, not only forenhancing sleep quality but also for preventing the risk of developing chronicillnesses associated to unhealthy sleep. Despite significant advances inresearch, achieving versatile recognition of various unhealthy and sub-healthysleep patterns with simple wearable devices at home remains a significantchallenge. Here, we report a robust and durable ultrasensitive strain sensorarray printed on a smart garment, in its collar region. This solution allowsdetecting subtle vibrations associated with multiple sleep patterns at theextrinsic laryngeal muscles. Equipped with a deep learning neural network, itcan precisely identify six sleep states-nasal breathing, mouth breathing,snoring, bruxism, central sleep apnea (CSA), and obstructive sleep apnea(OSA)-with an impressive accuracy of 98.6%, all without requiring specificpositioning. We further demonstrate its explainability and generalizationcapabilities in practical applications. Explainable artificial intelligence(XAI) visualizations reflect comprehensive signal pattern analysis with lowbias. Transfer learning tests show that the system can achieve high accuracy(overall accuracy of 95%) on new users with very few-shot learning (less than15 samples per class). The scalable manufacturing process, robustness, highaccuracy, and excellent generalization of the smart garment make it a promisingtool for next-generation continuous sleep monitoring.</description><author>Chenyu Tang, Wentian Yi, Muzi Xu, Yuxuan Jin, Zibo Zhang, Xuhang Chen, Caizhi Liao, Peter Smielewski, Luigi G. Occhipinti</author><pubDate>Thu, 01 Aug 2024 17:56:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00753v1</guid></item><item><title>A Policy-Gradient Approach to Solving Imperfect-Information Games with Iterate Convergence</title><link>http://arxiv.org/abs/2408.00751v1</link><description>Policy gradient methods have become a staple of any single-agentreinforcement learning toolbox, due to their combination of desirableproperties: iterate convergence, efficient use of stochastic trajectoryfeedback, and theoretically-sound avoidance of importance sampling corrections.In multi-agent imperfect-information settings (extensive-form games), however,it is still unknown whether the same desiderata can be guaranteed whileretaining theoretical guarantees. Instead, sound methods for extensive-formgames rely on approximating counterfactual values (as opposed to Q values),which are incompatible with policy gradient methodologies. In this paper, weinvestigate whether policy gradient can be safely used in two-player zero-sumimperfect-information extensive-form games (EFGs). We establish positiveresults, showing for the first time that a policy gradient method leads toprovable best-iterate convergence to a regularized Nash equilibrium inself-play.</description><author>Mingyang Liu, Gabriele Farina, Asuman Ozdaglar</author><pubDate>Thu, 01 Aug 2024 17:54:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00751v1</guid></item><item><title>Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer</title><link>http://arxiv.org/abs/2408.00749v1</link><description>Modern day studies show a high degree of correlation between high yieldingcrop varieties and plants with upright leaf angles. It is observed that plantswith upright leaf angles intercept more light than those without upright leafangles, leading to a higher rate of photosynthesis. Plant scientists andbreeders benefit from tools that can directly measure plant parameters in thefield i.e. on-site phenotyping. The estimation of leaf angles by manual meansin a field setting is tedious and cumbersome. We mitigate the tedium using acombination of the Mask R-CNN instance segmentation neural network, and LineSegment Transformer (LETR), a vision transformer. The proposed Computer Vision(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer2015- Ames MLA, with a combined total of 1,827 plant images collected in thefield using FieldBook, an Android application aimed at on-site phenotyping. Theleaf angles estimated by the proposed pipeline on the image datasets arecompared to two independent manual measurements using ImageJ, a Java-basedimage processing program developed at the National Institutes of Health and theLaboratory for Optical and Computational Instrumentation. The results, whencompared for similarity using the Cosine Similarity measure, exhibit 0.98similarity scores on both independent measurements of Summer 2015-Ames ULA andSummer 2015-Ames MLA image datasets, demonstrating the feasibility of theproposed pipeline for on-site measurement of leaf angles.</description><author>Venkat Margapuri, Prapti Thapaliya, Trevor Rife</author><pubDate>Thu, 01 Aug 2024 17:52:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00749v1</guid></item><item><title>Collaborative Vision-Text Representation Optimizing for Open-Vocabulary Segmentation</title><link>http://arxiv.org/abs/2408.00744v1</link><description>Pre-trained vision-language models, e.g. CLIP, have been increasingly used toaddress the challenging Open-Vocabulary Segmentation (OVS) task, benefitingfrom their well-aligned vision-text embedding space. Typical solutions involveeither freezing CLIP during training to unilaterally maintain its zero-shotcapability, or fine-tuning CLIP vision encoder to achieve perceptualsensitivity to local regions. However, few of them incorporate vision-textcollaborative optimization. Based on this, we propose the Content-DependentTransfer to adaptively enhance each text embedding by interacting with theinput image, which presents a parameter-efficient way to optimize the textrepresentation. Besides, we additionally introduce a RepresentationCompensation strategy, reviewing the original CLIP-V representation ascompensation to maintain the zero-shot capability of CLIP. In this way, thevision and text representation of CLIP are optimized collaboratively, enhancingthe alignment of the vision-text feature space. To the best of our knowledge,we are the first to establish the collaborative vision-text optimizingmechanism within the OVS field. Extensive experiments demonstrate our methodachieves superior performance on popular OVS benchmarks. In open-vocabularysemantic segmentation, our method outperforms the previous state-of-the-artapproaches by +0.5, +2.3, +3.4, +0.4 and +1.1 mIoU, respectively on A-847,A-150, PC-459, PC-59 and PAS-20. Furthermore, in a panoptic setting on ADE20K,we achieve the performance of 27.1 PQ, 73.5 SQ, and 32.9 RQ. Code will beavailable at https://github.com/jiaosiyu1999/MAFT-Plus.git .</description><author>Siyu Jiao, Hongguang Zhu, Jiannan Huang, Yao Zhao, Yunchao Wei, Humphrey Shi</author><pubDate>Thu, 01 Aug 2024 17:48:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00744v1</guid></item><item><title>Tiered Reward: Designing Rewards for Specification and Fast Learning of Desired Behavior</title><link>http://arxiv.org/abs/2212.03733v3</link><description>Reinforcement-learning agents seek to maximize a reward signal throughenvironmental interactions. As humans, our job in the learning process is todesign reward functions to express desired behavior and enable the agent tolearn such behavior swiftly. However, designing good reward functions to inducethe desired behavior is generally hard, let alone the question of which rewardsmake learning fast. In this work, we introduce a family of a reward structureswe call Tiered Reward that addresses both of these questions. We consider thereward-design problem in tasks formulated as reaching desirable states andavoiding undesirable states. To start, we propose a strict partial ordering ofthe policy space to resolve trade-offs in behavior preference. We preferpolicies that reach the good states faster and with higher probability whileavoiding the bad states longer. Next, we introduce Tiered Reward, a class ofenvironment-independent reward functions and show it is guaranteed to inducepolicies that are Pareto-optimal according to our preference relation. Finally,we demonstrate that Tiered Reward leads to fast learning with multiple tabularand deep reinforcement-learning algorithms.</description><author>Zhiyuan Zhou, Shreyas Sundara Raman, Henry Sowerby, Michael L. Littman</author><pubDate>Thu, 01 Aug 2024 17:47:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.03733v3</guid></item><item><title>Seed Kernel Counting using Domain Randomization and Object Tracking Neural Networks</title><link>http://arxiv.org/abs/2308.05846v2</link><description>High-throughput phenotyping (HTP) of seeds, also known as seed phenotyping,is the comprehensive assessment of complex seed traits such as growth,development, tolerance, resistance, ecology, yield, and the measurement ofparameters that form more complex traits. One of the key aspects of seedphenotyping is cereal yield estimation that the seed production industry reliesupon to conduct their business. While mechanized seed kernel counters areavailable in the market currently, they are often priced high and sometimesoutside the range of small scale seed production firms' affordability. Thedevelopment of object tracking neural network models such as You Only Look Once(YOLO) enables computer scientists to design algorithms that can estimatecereal yield inexpensively. The key bottleneck with neural network models isthat they require a plethora of labelled training data before they can be putto task. We demonstrate that the use of synthetic imagery serves as a feasiblesubstitute to train neural networks for object tracking that includes the tasksof object classification and detection. Furthermore, we propose a seed kernelcounter that uses a low-cost mechanical hopper, trained YOLOv8 neural networkmodel, and object tracking algorithms on StrongSORT and ByteTrack to estimatecereal yield from videos. The experiment yields a seed kernel count with anaccuracy of 95.2\% and 93.2\% for Soy and Wheat respectively using theStrongSORT algorithm, and an accuray of 96.8\% and 92.4\% for Soy and Wheatrespectively using the ByteTrack algorithm.</description><author>Venkat Margapuri, Prapti Thapaliya, Mitchell Neilsen</author><pubDate>Thu, 01 Aug 2024 17:46:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05846v2</guid></item><item><title>Self-Supervised Learning Based Handwriting Verification</title><link>http://arxiv.org/abs/2405.18320v2</link><description>We present SSL-HV: Self-Supervised Learning approaches applied to the task ofHandwriting Verification. This task involves determining whether a given pairof handwritten images originate from the same or different writer distribution.We have compared the performance of multiple generative, contrastive SSLapproaches against handcrafted feature extractors and supervised learning onCEDAR AND dataset. We show that ResNet based Variational Auto-Encoder (VAE)outperforms other generative approaches achieving 76.3% accuracy, whileResNet-18 fine-tuned using Variance-Invariance-Covariance Regularization(VICReg) outperforms other contrastive approaches achieving 78% accuracy. Usinga pre-trained VAE and VICReg for the downstream task of writer verification weobserved a relative improvement in accuracy of 6.7% and 9% over ResNet-18supervised baseline with 10% writer labels.</description><author>Mihir Chauhan, Mohammad Abuzar Hashemi, Abhishek Satbhai, Mir Basheer Ali, Bina Ramamurthy, Mingchen Gao, Siwei Lyu, Sargur Srihari</author><pubDate>Thu, 01 Aug 2024 17:43:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18320v2</guid></item><item><title>Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders</title><link>http://arxiv.org/abs/2407.14435v3</link><description>Sparse autoencoders (SAEs) are a promising unsupervised approach foridentifying causally relevant and interpretable linear features in a languagemodel's (LM) activations. To be useful for downstream tasks, SAEs need todecompose LM activations faithfully; yet to be interpretable the decompositionmust be sparse -- two objectives that are in tension. In this paper, weintroduce JumpReLU SAEs, which achieve state-of-the-art reconstruction fidelityat a given sparsity level on Gemma 2 9B activations, compared to other recentadvances such as Gated and TopK SAEs. We also show that this improvement doesnot come at the cost of interpretability through manual and automatedinterpretability studies. JumpReLU SAEs are a simple modification of vanilla(ReLU) SAEs -- where we replace the ReLU with a discontinuous JumpReLUactivation function -- and are similarly efficient to train and run. Byutilising straight-through-estimators (STEs) in a principled manner, we showhow it is possible to train JumpReLU SAEs effectively despite the discontinuousJumpReLU function introduced in the SAE's forward pass. Similarly, we use STEsto directly train L0 to be sparse, instead of training on proxies such as L1,avoiding problems like shrinkage.</description><author>Senthooran Rajamanoharan, Tom Lieberum, Nicolas Sonnerat, Arthur Conmy, Vikrant Varma, János Kramár, Neel Nanda</author><pubDate>Thu, 01 Aug 2024 17:42:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.14435v3</guid></item><item><title>End-to-End Reinforcement Learning of Koopman Models for Economic Nonlinear Model Predictive Control</title><link>http://arxiv.org/abs/2308.01674v4</link><description>(Economic) nonlinear model predictive control ((e)NMPC) requires dynamicmodels that are sufficiently accurate and computationally tractable.Data-driven surrogate models for mechanistic models can reduce thecomputational burden of (e)NMPC; however, such models are typically trained bysystem identification for maximum prediction accuracy on simulation samples andperform suboptimally in (e)NMPC. We present a method for end-to-endreinforcement learning of Koopman surrogate models for optimal performance aspart of (e)NMPC. We apply our method to two applications derived from anestablished nonlinear continuous stirred-tank reactor model. The controllerperformance is compared to that of (e)NMPCs utilizing models trained usingsystem identification, and model-free neural network controllers trained usingreinforcement learning. We show that the end-to-end trained models outperformthose trained using system identification in (e)NMPC, and that, in contrast tothe neural network controllers, the (e)NMPC controllers can react to changes inthe control setting without retraining.</description><author>Daniel Mayfrank, Alexander Mitsos, Manuel Dahmen</author><pubDate>Thu, 01 Aug 2024 17:41:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.01674v4</guid></item><item><title>DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency</title><link>http://arxiv.org/abs/2408.00741v1</link><description>The rapid evolution and widespread adoption of generative large languagemodels (LLMs) have made them a pivotal workload in various applications. Today,LLM inference clusters receive a large number of queries with strict ServiceLevel Objectives (SLOs). To achieve the desired performance, these modelsexecute on power-hungry GPUs causing the inference clusters to consume largeamount of energy and, consequently, result in excessive carbon emissions.Fortunately, we find that there is a great opportunity to exploit theheterogeneity in inference compute properties and fluctuations in inferenceworkloads, to significantly improve energy-efficiency. However, such a diverseand dynamic environment creates a large search-space where different systemconfigurations (e.g., number of instances, model parallelism, and GPUfrequency) translate into different energy-performance trade-offs. To addressthese challenges, we propose DynamoLLM, the first energy-management frameworkfor LLM inference environments. DynamoLLM automatically and dynamicallyreconfigures the inference cluster to optimize for energy and cost of LLMserving under the service's performance SLOs. We show that at a service-level,DynamoLLM conserves 53% energy and 38% operational carbon emissions, andreduces 61% cost to the customer, while meeting the latency SLOs.</description><author>Jovan Stojkovic, Chaojie Zhang, Íñigo Goiri, Josep Torrellas, Esha Choukse</author><pubDate>Thu, 01 Aug 2024 17:40:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00741v1</guid></item><item><title>Sparks of Quantum Advantage and Rapid Retraining in Machine Learning</title><link>http://arxiv.org/abs/2407.16020v3</link><description>The advent of quantum computing holds the potential to revolutionize variousfields by solving complex problems more efficiently than classical computers.Despite this promise, practical quantum advantage is hindered by currenthardware limitations, notably the small number of qubits and high noise levels.In this study, we leverage adiabatic quantum computers to optimizeKolmogorov-Arnold Networks, a powerful neural network architecture forrepresenting complex functions with minimal parameters. By modifying thenetwork to use Bezier curves as the basis functions and formulating theoptimization problem into a Quadratic Unconstrained Binary Optimizationproblem, we create a fixed-sized solution space, independent of the number oftraining samples. Our approach demonstrates sparks of quantum advantage throughfaster training times compared to classical optimizers such as the Adam,Stochastic Gradient Descent, Adaptive Gradient, and simulated annealing.Additionally, we introduce a novel rapid retraining capability, enabling thenetwork to be retrained with new data without reprocessing old samples, thusenhancing learning efficiency in dynamic environments. Experimental results oninitial training of classification and regression tasks validate the efficacyof our approach, showcasing significant speedups and comparable performance toclassical methods. While experiments on retraining demonstrate a sixty timesspeed up using adiabatic quantum computing based optimization compared to thatof the gradient descent based optimizers, with theoretical models allowing thisspeed up to be even larger! Our findings suggest that with further advancementsin quantum hardware and algorithm optimization, quantum-optimized machinelearning models could have broad applications across various domains, withinitial focus on rapid retraining.</description><author>William Troy</author><pubDate>Thu, 01 Aug 2024 17:40:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.16020v3</guid></item><item><title>Enhanced Local Explainability and Trust Scores with Random Forest Proximities</title><link>http://arxiv.org/abs/2310.12428v2</link><description>We initiate a novel approach to explain the predictions and out of sampleperformance of random forest (RF) regression and classification models byexploiting the fact that any RF can be mathematically formulated as an adaptiveweighted K nearest-neighbors model. Specifically, we employ a recent resultthat, for both regression and classification tasks, any RF prediction can berewritten exactly as a weighted sum of the training targets, where the weightsare RF proximities between the corresponding pairs of data points. We show thatthis linearity facilitates a local notion of explainability of RF predictionsthat generates attributions for any model prediction across observations in thetraining set, and thereby complements established feature-based methods likeSHAP, which generate attributions for a model prediction across input features.We show how this proximity-based approach to explainability can be used inconjunction with SHAP to explain not just the model predictions, but alsoout-of-sample performance, in the sense that proximities furnish a novel meansof assessing when a given model prediction is more or less likely to becorrect. We demonstrate this approach in the modeling of US corporate bondprices and returns in both regression and classification cases.</description><author>Joshua Rosaler, Dhruv Desai, Bhaskarjit Sarmah, Dimitrios Vamvourellis, Deran Onay, Dhagash Mehta, Stefano Pasquali</author><pubDate>Thu, 01 Aug 2024 17:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12428v2</guid></item><item><title>Virchow 2: Scaling Self-Supervised Mixed Magnification Models in Pathology</title><link>http://arxiv.org/abs/2408.00738v1</link><description>Foundation models are rapidly being developed for computational pathologyapplications. However, it remains an open question which factors are mostimportant for downstream performance with data scale and diversity, model size,and training algorithm all playing a role. In this work, we present the resultof scaling both data and model size, surpassing previous studies in bothdimensions, and introduce two new models: Virchow 2, a 632M parameter visiontransformer, and Virchow 2G, a 1.85B parameter vision transformer, each trainedwith 3.1M histopathology whole slide images. To support this scale, we proposedomain-inspired adaptations to the DINOv2 training algorithm, which is quicklybecoming the default method in self-supervised learning for computationalpathology. We achieve state of the art performance on twelve tile-level tasks,as compared to the top performing competing models. Our results suggest thatdata diversity and domain-specific training can outperform models that onlyscale in the number of parameters, but, on average, performance benefits fromdomain-tailoring, data scale, and model scale.</description><author>Eric Zimmermann, Eugene Vorontsov, Julian Viret, Adam Casson, Michal Zelechowski, George Shaikovski, Neil Tenenholtz, James Hall, Thomas Fuchs, Nicolo Fusi, Siqi Liu, Kristen Severson</author><pubDate>Thu, 01 Aug 2024 17:35:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00738v1</guid></item><item><title>Evaluating Neural Radiance Fields (NeRFs) for 3D Plant Geometry Reconstruction in Field Conditions</title><link>http://arxiv.org/abs/2402.10344v2</link><description>We evaluate different Neural Radiance Fields (NeRFs) techniques forreconstructing (3D) plants in varied environments, from indoor settings tooutdoor fields. Traditional techniques often struggle to capture the complexdetails of plants, which is crucial for botanical and agriculturalunderstanding. We evaluate three scenarios with increasing complexity andcompare the results with the point cloud obtained using LiDAR as ground truthdata. In the most realistic field scenario, the NeRF models achieve a 74.65% F1score with 30 minutes of training on the GPU, highlighting the efficiency andaccuracy of NeRFs in challenging environments. These findings not onlydemonstrate the potential of NeRF in detailed and realistic 3D plant modelingbut also suggest practical approaches for enhancing the speed and efficiency ofthe 3D reconstruction process.</description><author>Muhammad Arbab Arshad, Talukder Jubery, James Afful, Anushrut Jignasu, Aditya Balu, Baskar Ganapathysubramanian, Soumik Sarkar, Adarsh Krishnamurthy</author><pubDate>Thu, 01 Aug 2024 17:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10344v2</guid></item><item><title>TurboEdit: Text-Based Image Editing Using Few-Step Diffusion Models</title><link>http://arxiv.org/abs/2408.00735v1</link><description>Diffusion models have opened the path to a wide range of text-based imageediting frameworks. However, these typically build on the multi-step nature ofthe diffusion backwards process, and adapting them to distilled, fast-samplingmethods has proven surprisingly challenging. Here, we focus on a popular lineof text-based editing frameworks - the ``edit-friendly'' DDPM-noise inversionapproach. We analyze its application to fast sampling methods and categorizeits failures into two classes: the appearance of visual artifacts, andinsufficient editing strength. We trace the artifacts to mismatched noisestatistics between inverted noises and the expected noise schedule, and suggesta shifted noise schedule which corrects for this offset. To increase editingstrength, we propose a pseudo-guidance approach that efficiently increases themagnitude of edits without introducing new artifacts. All in all, our methodenables text-based image editing with as few as three diffusion steps, whileproviding novel insights into the mechanisms behind popular text-based editingapproaches.</description><author>Gilad Deutch, Rinon Gal, Daniel Garibi, Or Patashnik, Daniel Cohen-Or</author><pubDate>Thu, 01 Aug 2024 17:27:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00735v1</guid></item><item><title>CERT-ED: Certifiably Robust Text Classification for Edit Distance</title><link>http://arxiv.org/abs/2408.00728v1</link><description>With the growing integration of AI in daily life, ensuring the robustness ofsystems to inference-time attacks is crucial. Among the approaches forcertifying robustness to such adversarial examples, randomized smoothing hasemerged as highly promising due to its nature as a wrapper around arbitraryblack-box models. Previous work on randomized smoothing in natural languageprocessing has primarily focused on specific subsets of edit distanceoperations, such as synonym substitution or word insertion, without exploringthe certification of all edit operations. In this paper, we adapt RandomizedDeletion (Huang et al., 2023) and propose, CERTified Edit Distance defense(CERT-ED) for natural language classification. Through comprehensiveexperiments, we demonstrate that CERT-ED outperforms the existing Hammingdistance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms ofboth accuracy and the cardinality of the certificate. By covering variousthreat models, including 5 direct and 5 transfer attacks, our method improvesempirical robustness in 38 out of 50 settings.</description><author>Zhuoqun Huang, Neil G Marchant, Olga Ohrimenko, Benjamin I. P. Rubinstein</author><pubDate>Thu, 01 Aug 2024 17:20:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00728v1</guid></item><item><title>Prover-Verifier Games improve legibility of LLM outputs</title><link>http://arxiv.org/abs/2407.13692v2</link><description>One way to increase confidence in the outputs of Large Language Models (LLMs)is to support them with reasoning that is clear and easy to check -- a propertywe call legibility. We study legibility in the context of solving grade-schoolmath problems and show that optimizing chain-of-thought solutions only foranswer correctness can make them less legible. To mitigate the loss inlegibility, we propose a training algorithm inspired by Prover-Verifier Gamefrom Anil et al. (2021). Our algorithm iteratively trains small verifiers topredict solution correctness, "helpful" provers to produce correct solutionsthat the verifier accepts, and "sneaky" provers to produce incorrect solutionsthat fool the verifier. We find that the helpful prover's accuracy and theverifier's robustness to adversarial attacks increase over the course oftraining. Furthermore, we show that legibility training transfers totime-constrained humans tasked with verifying solution correctness. Over courseof LLM training human accuracy increases when checking the helpful prover'ssolutions, and decreases when checking the sneaky prover's solutions. Hence,training for checkability by small verifiers is a plausible technique forincreasing output legibility. Our results suggest legibility training againstsmall verifiers as a practical avenue for increasing legibility of large LLMsto humans, and thus could help with alignment of superhuman models.</description><author>Jan Hendrik Kirchner, Yining Chen, Harri Edwards, Jan Leike, Nat McAleese, Yuri Burda</author><pubDate>Thu, 01 Aug 2024 17:18:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.13692v2</guid></item><item><title>Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions</title><link>http://arxiv.org/abs/2408.00727v1</link><description>The emergent abilities of large language models (LLMs) have demonstratedgreat potential in solving medical questions. They can possess considerablemedical knowledge, but may still hallucinate and are inflexible in theknowledge updates. While Retrieval-Augmented Generation (RAG) has been proposedto enhance the medical question-answering capabilities of LLMs with externalknowledge bases, it may still fail in complex cases where multiple rounds ofinformation-seeking are required. To address such an issue, we proposeiterative RAG for medicine (i-MedRAG), where LLMs can iteratively ask follow-upqueries based on previous information-seeking attempts. In each iteration ofi-MedRAG, the follow-up queries will be answered by a vanilla RAG system andthey will be further used to guide the query generation in the next iteration.Our experiments show the improved performance of various LLMs brought byi-MedRAG compared with vanilla RAG on complex questions from clinical vignettesin the United States Medical Licensing Examination (USMLE), as well as variousknowledge tests in the Massive Multitask Language Understanding (MMLU) dataset.Notably, our zero-shot i-MedRAG outperforms all existing prompt engineering andfine-tuning methods on GPT-3.5, achieving an accuracy of 69.68\% on the MedQAdataset. In addition, we characterize the scaling properties of i-MedRAG withdifferent iterations of follow-up queries and different numbers of queries periteration. Our case studies show that i-MedRAG can flexibly ask follow-upqueries to form reasoning chains, providing an in-depth analysis of medicalquestions. To the best of our knowledge, this is the first-of-its-kind study onincorporating follow-up queries into medical RAG.</description><author>Guangzhi Xiong, Qiao Jin, Xiao Wang, Minjia Zhang, Zhiyong Lu, Aidong Zhang</author><pubDate>Thu, 01 Aug 2024 17:18:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00727v1</guid></item><item><title>An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models</title><link>http://arxiv.org/abs/2408.00724v1</link><description>The optimal training configurations of large language models (LLMs) withrespect to model sizes and compute budgets have been extensively studied. Buthow to optimally configure LLMs during inference has not been explored insufficient depth. We study compute-optimal inference: designing models andinference strategies that optimally trade off additional inference-time computefor improved performance. As a first step towards understanding and designingcompute-optimal inference methods, we assessed the effectiveness andcomputational efficiency of multiple inference strategies such as GreedySearch, Majority Voting, Best-of-N, Weighted Voting, and their variants on twodifferent Tree Search algorithms, involving different model sizes andcomputational budgets. We found that a smaller language model with a novel treesearch algorithm typically achieves a Pareto-optimal trade-off. These resultshighlight the potential benefits of deploying smaller models equipped with moresophisticated decoding algorithms in budget-constrained scenarios, e.g., onend-devices, to enhance problem-solving accuracy. For instance, we show thatthe Llemma-7B model can achieve competitive accuracy to a Llemma-34B model onMATH500 while using $2\times$ less FLOPs. Our findings could potentially applyto any generation task with a well-defined measure of success.</description><author>Yangzhen Wu, Zhiqing Sun, Shanda Li, Sean Welleck, Yiming Yang</author><pubDate>Thu, 01 Aug 2024 17:16:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00724v1</guid></item><item><title>Pathway to Secure and Trustworthy 6G for LLMs: Attacks, Defense, and Opportunities</title><link>http://arxiv.org/abs/2408.00722v1</link><description>Recently, large language models (LLMs) have been gaining a lot of interestdue to their adaptability and extensibility in emerging applications, includingcommunication networks. It is anticipated that 6G mobile edge computingnetworks will be able to support LLMs as a service, as they provide ultrareliable low-latency communications and closed loop massive connectivity.However, LLMs are vulnerable to data and model privacy issues that affect thetrustworthiness of LLMs to be deployed for user-based services. In this paper,we explore the security vulnerabilities associated with fine-tuning LLMs in 6Gnetworks, in particular the membership inference attack. We define thecharacteristics of an attack network that can perform a membership inferenceattack if the attacker has access to the fine-tuned model for the downstreamtask. We show that the membership inference attacks are effective for anydownstream task, which can lead to a personal data breach when using LLM as aservice. The experimental results show that the attack success rate of maximum92% can be achieved on named entity recognition task. Based on the experimentalanalysis, we discuss possible defense mechanisms and present possible researchdirections to make the LLMs more trustworthy in the context of 6G networks.</description><author>Sunder Ali Khowaja, Parus Khuwaja, Kapal Dev, Hussam Al Hamadi, Engin Zeydan</author><pubDate>Thu, 01 Aug 2024 17:15:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00722v1</guid></item><item><title>Deblurring Neural Radiance Fields with Event-driven Bundle Adjustment</title><link>http://arxiv.org/abs/2406.14360v2</link><description>Neural Radiance Fields (NeRF) achieves impressive 3D representation learningand novel view synthesis results with high-quality multi-view images as input.However, motion blur in images often occurs in low-light and high-speed motionscenes, which significantly degrades the reconstruction quality of NeRF.Previous deblurring NeRF methods struggle to estimate pose and lighting changesduring the exposure time, making them unable to accurately model the motionblur. The bio-inspired event camera measuring intensity changes with hightemporal resolution makes up this information deficiency. In this paper, wepropose Event-driven Bundle Adjustment for Deblurring Neural Radiance Fields(EBAD-NeRF) to jointly optimize the learnable poses and NeRF parameters byleveraging the hybrid event-RGB data. An intensity-change-metric event loss anda photo-metric blur loss are introduced to strengthen the explicit modeling ofcamera motion blur. Experiments on both synthetic and real-captured datademonstrate that EBAD-NeRF can obtain accurate camera trajectory during theexposure time and learn a sharper 3D representations compared to prior works.</description><author>Yunshan Qi, Lin Zhu, Yifan Zhao, Nan Bao, Jia Li</author><pubDate>Thu, 01 Aug 2024 17:14:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14360v2</guid></item><item><title>Low-Rank Covariance Completion for Graph Quilting with Applications to Functional Connectivity</title><link>http://arxiv.org/abs/2209.08273v2</link><description>As a tool for estimating networks in high dimensions, graphical models arecommonly applied to calcium imaging data to estimate functional neuronalconnectivity, i.e. relationships between the activities of neurons. However, inmany calcium imaging data sets, the full population of neurons is not recordedsimultaneously, but instead in partially overlapping blocks. This leads to theGraph Quilting problem, as first introduced by (Vinci et.al. 2019), in whichthe goal is to infer the structure of the full graph when only subsets offeatures are jointly observed. In this paper, we study a novel two-stepapproach to Graph Quilting, which first imputes the complete covariance matrixusing low-rank covariance completion techniques before estimating the graphstructure. We introduce three approaches to solve this problem: block singularvalue decomposition, nuclear norm penalization, and non-convex low-rankfactorization. While prior works have studied low-rank matrix completion, weaddress the challenges brought by the block-wise missingness and are the firstto investigate the problem in the context of graph learning. We discusstheoretical properties of the two-step procedure, showing graph selectionconsistency of one proposed approach by proving novel L infinity-norm errorbounds for matrix completion with block-missingness. We then investigate theempirical performance of the proposed methods on simulations and on real-worlddata examples, through which we show the efficacy of these methods forestimating functional connectivity from calcium imaging data.</description><author>Andersen Chang, Lili Zheng, Genevera I. Allen</author><pubDate>Thu, 01 Aug 2024 17:07:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.08273v2</guid></item><item><title>A Natural Language Processing Framework for Hotel Recommendation Based on Users' Text Reviews</title><link>http://arxiv.org/abs/2408.00716v1</link><description>Recently, the application of Artificial Intelligence algorithms in hotelrecommendation systems has become an increasingly popular topic. One suchmethod that has proven to be effective in this field is Deep Learning,especially Natural Language processing models, which are able to extractsemantic knowledge from user's text reviews to create more efficientrecommendation systems. This can lead to the development of intelligent modelsthat can classify a user's preferences and emotions based on their feedback inthe form of text reviews about their hotel stay experience. In this study, wepropose a Natural Language Processing framework that utilizes customer textreviews to provide personalized recommendations for the most appropriate hotelbased on their preferences. The framework is based on Bidirectional EncoderRepresentations from Transformers (BERT) and a fine-tuning/validation pipelinethat categorizes customer hotel review texts into "Bad," "Good," or "Excellent"recommended hotels. Our findings indicate that the hotel recommendation systemwe propose can significantly enhance the user experience of bookingaccommodations by providing personalized recommendations based on userpreferences and previous booking history.</description><author>Lavrentia Aravani, Emmanuel Pintelas, Christos Pierrakeas, Panagiotis Pintelas</author><pubDate>Thu, 01 Aug 2024 17:01:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00716v1</guid></item><item><title>SAM 2: Segment Anything in Images and Videos</title><link>http://arxiv.org/abs/2408.00714v1</link><description>We present Segment Anything Model 2 (SAM 2), a foundation model towardssolving promptable visual segmentation in images and videos. We build a dataengine, which improves model and data via user interaction, to collect thelargest video segmentation dataset to date. Our model is a simple transformerarchitecture with streaming memory for real-time video processing. SAM 2trained on our data provides strong performance across a wide range of tasks.In video segmentation, we observe better accuracy, using 3x fewer interactionsthan prior approaches. In image segmentation, our model is more accurate and 6xfaster than the Segment Anything Model (SAM). We believe that our data, model,and insights will serve as a significant milestone for video segmentation andrelated perception tasks. We are releasing a version of our model, the datasetand an interactive demo.</description><author>Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman Rädle, Chloe Rolland, Laura Gustafson, Eric Mintun, Junting Pan, Kalyan Vasudev Alwala, Nicolas Carion, Chao-Yuan Wu, Ross Girshick, Piotr Dollár, Christoph Feichtenhofer</author><pubDate>Thu, 01 Aug 2024 17:00:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00714v1</guid></item><item><title>Insurance Portfolio Pursuit with Reinforcement Learning</title><link>http://arxiv.org/abs/2408.00713v1</link><description>When faced with a new customer, many factors contribute to an insurancefirm's decision of what offer to make to that customer. In addition to theexpected cost of providing the insurance, the firm must consider the otheroffers likely to be made to the customer, and how sensitive the customer is todifferences in price. Moreover, firms often target a specific portfolio ofcustomers that could depend on, e.g., age, location, and occupation. Given sucha target portfolio, firms may choose to modulate an individual customer's offerbased on whether the firm desires the customer within their portfolio. Given atarget portfolio, we term the problem of modulating offers to achieve thistarget portfolio the portfolio pursuit problem. We give a formulation ofportfolio pursuit as a sequential decision making problem, and devise a novelreinforcement learning algorithm for its solution. We test our method on acomplex synthetic market environment, and demonstrate that it outperforms abaseline method which mimics current industry approaches to portfolio pursuit.</description><author>Edward James Young, Alistair Rogers, Elliott Tong, James Jordon</author><pubDate>Thu, 01 Aug 2024 16:58:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00713v1</guid></item><item><title>MotionFix: Text-Driven 3D Human Motion Editing</title><link>http://arxiv.org/abs/2408.00712v1</link><description>The focus of this paper is 3D motion editing. Given a 3D human motion and atextual description of the desired modification, our goal is to generate anedited motion as described by the text. The challenges include the lack oftraining data and the design of a model that faithfully edits the sourcemotion. In this paper, we address both these challenges. We build a methodologyto semi-automatically collect a dataset of triplets in the form of (i) a sourcemotion, (ii) a target motion, and (iii) an edit text, and create the newMotionFix dataset. Having access to such data allows us to train a conditionaldiffusion model, TMED, that takes both the source motion and the edit text asinput. We further build various baselines trained only on text-motion pairsdatasets, and show superior performance of our model trained on triplets. Weintroduce new retrieval-based metrics for motion editing and establish a newbenchmark on the evaluation set of MotionFix. Our results are encouraging,paving the way for further research on finegrained motion generation. Code andmodels will be made publicly available.</description><author>Nikos Athanasiou, Alpár Ceske, Markos Diomataris, Michael J. Black, Gül Varol</author><pubDate>Thu, 01 Aug 2024 16:58:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00712v1</guid></item><item><title>Investigating Brain Connectivity and Regional Statistics from EEG for early stage Parkinson's Classification</title><link>http://arxiv.org/abs/2408.00711v1</link><description>We evaluate the effectiveness of combining brain connectivity metrics withsignal statistics for early stage Parkinson's Disease (PD) classification usingelectroencephalogram data (EEG). The data is from 5 arousal states - wakefuland four sleep stages (N1, N2, N3 and REM). Our pipeline uses an Ada Boostmodel for classification on a challenging early stage PD classification taskwith with only 30 participants (11 PD , 19 Healthy Control). Evaluating 9 brainconnectivity metrics we find the best connectivity metric to be different foreach arousal state with Phase Lag Index achieving the highest individualclassification accuracy of 86\% on N1 data. Further to this our pipeline usingregional signal statistics achieves an accuracy of 78\%, using brainconnectivity only achieves an accuracy of 86\% whereas combining the twoachieves a best accuracy of 91\%. This best performance is achieved on N1 datausing Phase Lag Index (PLI) combined with statistics derived from the frequencycharacteristics of the EEG signal. This model also achieves a recall of 80 \%and precision of 96\%. Furthermore we find that on data from each arousalstate, combining PLI with regional signal statistics improves classificationaccuracy versus using signal statistics or brain connectivity alone. Thus weconclude that combining brain connectivity statistics with regional EEGstatistics is optimal for classifier performance on early stage Parkinson's.Additionally, we find outperformance of N1 EEG for classification ofParkinson's and expect this could be due to disrupted N1 sleep in PD. Thisshould be explored in future work.</description><author>Amarpal Sahota, Amber Roguski, Matthew W Jones, Zahraa S. Abdallah, Raul Santos-Rodriguez</author><pubDate>Thu, 01 Aug 2024 16:58:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00711v1</guid></item><item><title>Synthetic dual image generation for reduction of labeling efforts in semantic segmentation of micrographs with a customized metric function</title><link>http://arxiv.org/abs/2408.00707v1</link><description>Training of semantic segmentation models for material analysis requiresmicrographs and their corresponding masks. It is quite unlikely that perfectmasks will be drawn, especially at the edges of objects, and sometimes theamount of data that can be obtained is small, since only a few samples areavailable. These aspects make it very problematic to train a robust model. Wedemonstrate a workflow for the improvement of semantic segmentation models ofmicrographs through the generation of synthetic microstructural images inconjunction with masks. The workflow only requires joining a few micrographswith their respective masks to create the input for a VectorQuantised-Variational AutoEncoder model that includes an embedding space, whichis trained such that a generative model (PixelCNN) learns the distribution ofeach input, transformed into discrete codes, and can be used to sample newcodes. The latter will eventually be decoded by VQ-VAE to generate imagesalongside corresponding masks for semantic segmentation. To evaluate thesynthetic data, we have trained U-Net models with different amounts of thesesynthetic data in conjunction with real data. These models were then evaluatedusing non-synthetic images only. Additionally, we introduce a customized metricderived from the mean Intersection over Union (mIoU). The proposed metricprevents a few falsely predicted pixels from greatly reducing the value of themIoU. We have achieved a reduction in sample preparation and acquisition times,as well as the efforts, needed for image processing and labeling tasks, areless when it comes to training semantic segmentation model. The approach couldbe generalized to various types of image data such that it serves as auser-friendly solution for training models with a small number of real images.</description><author>Matias Oscar Volman Stern, Dominic Hohs, Andreas Jansche, Timo Bernthaler, Gerhard Schneider</author><pubDate>Thu, 01 Aug 2024 16:54:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00707v1</guid></item><item><title>Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM</title><link>http://arxiv.org/abs/2408.00706v1</link><description>Delineating lesions and anatomical structure is important for image-guidedinterventions. Point-supervised medical image segmentation (PSS) has greatpotential to alleviate costly expert delineation labeling. However, due to thelack of precise size and boundary guidance, the effectiveness of PSS oftenfalls short of expectations. Although recent vision foundational models, suchas the medical segment anything model (MedSAM), have made significantadvancements in bounding-box-prompted segmentation, it is not straightforwardto utilize point annotation, and is prone to semantic ambiguity. In thispreliminary study, we introduce an iterative framework to facilitatesemantic-aware point-supervised MedSAM. Specifically, the semantic box-promptgenerator (SBPG) module has the capacity to convert the point input intopotential pseudo bounding box suggestions, which are explicitly refined by theprototype-based semantic similarity. This is then succeeded by a prompt-guidedspatial refinement (PGSR) module that harnesses the exceptionalgeneralizability of MedSAM to infer the segmentation mask, which also updatesthe box proposal seed in SBPG. Performance can be progressively improved withadequate iterations. We conducted an evaluation on BraTS2018 for thesegmentation of whole brain tumors and demonstrated its superior performancecompared to traditional PSS methods and on par with box-supervised methods.</description><author>Xiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri</author><pubDate>Thu, 01 Aug 2024 16:52:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00706v1</guid></item><item><title>Future of Artificial Intelligence in Agile Software Development</title><link>http://arxiv.org/abs/2408.00703v1</link><description>The advent of Artificial intelligence has promising advantages that can beutilized to transform the landscape of software project development. TheSoftware process framework consists of activities that constantly requireroutine human interaction, leading to the possibility of errors anduncertainties. AI can assist software development managers, software testers,and other team members by leveraging LLMs, GenAI models, and AI agents toperform routine tasks, risk analysis and prediction, strategy recommendations,and support decision making. AI has the potential to increase efficiency andreduce the risks encountered by the project management team while increasingthe project success rates. Additionally, it can also break down complex notionsand development processes for stakeholders to make informed decisions. In thispaper, we propose an approach in which AI tools and technologies can beutilized to bestow maximum assistance for agile software projects, which havebecome increasingly favored in the industry in recent years.</description><author>Mariyam Mahboob, Mohammed Rayyan Uddin Ahmed, Zoiba Zia, Mariam Shakeel Ali, Ayman Khaleel Ahmed</author><pubDate>Thu, 01 Aug 2024 16:49:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00703v1</guid></item><item><title>Joint Neural Networks for One-shot Object Recognition and Detection</title><link>http://arxiv.org/abs/2408.00701v1</link><description>This paper presents a novel joint neural networks approach to address thechallenging one-shot object recognition and detection tasks. Inspired bySiamese neural networks and state-of-art multi-box detection approaches, thejoint neural networks are able to perform object recognition and detection forcategories that remain unseen during the training process. Following theone-shot object recognition/detection constraints, the training and testingdatasets do not contain overlapped classes, in other words, all the testclasses remain unseen during training. The joint networks architecture is ableto effectively compare pairs of images via stacked convolutional layers of thequery and target inputs, recognising patterns of the same input query categorywithout relying on previous training around this category. The proposedapproach achieves 61.41% accuracy for one-shot object recognition on theMiniImageNet dataset and 47.1% mAP for one-shot object detection when trainedon the COCO dataset and tested using the Pascal VOC dataset. Code available athttps://github.com/cjvargasc/JNN recog and https://github.com/cjvargasc/JNNdetection/</description><author>Camilo J. Vargas, Qianni Zhang, Ebroul Izquierdo</author><pubDate>Thu, 01 Aug 2024 16:48:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00701v1</guid></item><item><title>You Can't Ignore Either: Unifying Structure and Feature Denoising for Robust Graph Learning</title><link>http://arxiv.org/abs/2408.00700v1</link><description>Recent research on the robustness of Graph Neural Networks (GNNs) undernoises or attacks has attracted great attention due to its importance inreal-world applications. Most previous methods explore a single noise source,recovering corrupt node embedding by reliable structures bias or developingstructure learning with reliable node features. However, the noises and attacksmay come from both structures and features in graphs, making the graphdenoising a dilemma and challenging problem. In this paper, we develop aunified graph denoising (UGD) framework to unravel the deadlock betweenstructure and feature denoising. Specifically, a high-order neighborhoodproximity evaluation method is proposed to recognize noisy edges, consideringfeatures may be perturbed simultaneously. Moreover, we propose to refine noisyfeatures with reconstruction based on a graph auto-encoder. An iterativeupdating algorithm is further designed to optimize the framework and acquire aclean graph, thus enabling robust graph learning for downstream tasks. Our UGDframework is self-supervised and can be easily implemented as a plug-and-playmodule. We carry out extensive experiments, which proves the effectiveness andadvantages of our method. Code is avalaible athttps://github.com/YoungTimmy/UGD.</description><author>Tianmeng Yang, Jiahao Meng, Min Zhou, Yaming Yang, Yujing Wang, Xiangtai Li, Yunhai Tong</author><pubDate>Thu, 01 Aug 2024 16:43:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00700v1</guid></item><item><title>Granular-Balls based Fuzzy Twin Support Vector Machine for Classification</title><link>http://arxiv.org/abs/2408.00699v1</link><description>The twin support vector machine (TWSVM) classifier has attracted increasingattention because of its low computational complexity. However, its performancetends to degrade when samples are affected by noise. The granular-ball fuzzysupport vector machine (GBFSVM) classifier partly alleviates the adverseeffects of noise, but it relies solely on the distance between thegranular-ball's center and the class center to design the granular-ballmembership function. In this paper, we first introduce the granular-ball twinsupport vector machine (GBTWSVM) classifier, which integrates granular-ballcomputing (GBC) with the twin support vector machine (TWSVM) classifier. Byreplacing traditional point inputs with granular-balls, we demonstrate how toderive a pair of non-parallel hyperplanes for the GBTWSVM classifier by solvinga quadratic programming problem. Subsequently, we design the membership andnon-membership functions of granular-balls using Pythagorean fuzzy sets todifferentiate the contributions of granular-balls in various regions.Additionally, we develop the granular-ball fuzzy twin support vector machine(GBFTSVM) classifier by incorporating GBC with the fuzzy twin support vectormachine (FTSVM) classifier. We demonstrate how to derive a pair of non-parallelhyperplanes for the GBFTSVM classifier by solving a quadratic programmingproblem. We also design algorithms for the GBTSVM classifier and the GBFTSVMclassifier. Finally, the superior classification performance of the GBTWSVMclassifier and the GBFTSVM classifier on 20 benchmark datasets underscorestheir scalability, efficiency, and robustness in tackling classification tasks.</description><author>Lixi Zhao, Weiping Ding, Duoqian Miao, Guangming Lang</author><pubDate>Thu, 01 Aug 2024 16:43:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00699v1</guid></item><item><title>Accelerating Full Waveform Inversion By Transfer Learning</title><link>http://arxiv.org/abs/2408.00695v1</link><description>Full waveform inversion (FWI) is a powerful tool for reconstructing materialfields based on sparsely measured data obtained by wave propagation. Forspecific problems, discretizing the material field with a neural network (NN)improves the robustness and reconstruction quality of the correspondingoptimization problem. We call this method NN-based FWI. Starting from aninitial guess, the weights of the NN are iteratively updated to fit thesimulated wave signals to the sparsely measured data set. For gradient-basedoptimization, a suitable choice of the initial guess, i.e., a suitable NNweight initialization, is crucial for fast and robust convergence. In this paper, we introduce a novel transfer learning approach to furtherimprove NN-based FWI. This approach leverages supervised pretraining to providea better NN weight initialization, leading to faster convergence of thesubsequent optimization problem. Moreover, the inversions yield physically moremeaningful local minima. The network is pretrained to predict the unknownmaterial field using the gradient information from the first iteration ofconventional FWI. In our computational experiments on two-dimensional domains,the training data set consists of reference simulations with arbitrarilypositioned elliptical voids of different shapes and orientations. We comparethe performance of the proposed transfer learning NN-based FWI with three othermethods: conventional FWI, NN-based FWI without pretraining and conventionalFWI with an initial guess predicted from the pretrained NN. Our results showthat transfer learning NN-based FWI outperforms the other methods in terms ofconvergence speed and reconstruction quality.</description><author>Divya Shyam Singh, Leon Herrmann, Qing Sun, Tim Bürchner, Felix Dietrich, Stefan Kollmannsberger</author><pubDate>Thu, 01 Aug 2024 16:39:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00695v1</guid></item><item><title>Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning</title><link>http://arxiv.org/abs/2408.00690v1</link><description>While Large Language Models show remarkable performance in natural languageunderstanding, their resource-intensive nature makes them less accessible. Incontrast, smaller language models such as MiniCPM offer more sustainablescalability, but often underperform without specialized optimization. In thispaper, we explore the enhancement of smaller language models through theimprovement of their text embeddings. We select three language models, MiniCPM,Phi-2, and Gemma, to conduct contrastive fine-tuning on the NLI dataset. Ourresults demonstrate that this fine-tuning method enhances the quality of textembeddings for all three models across various benchmarks, with MiniCPM showingthe most significant improvements of an average 56.33\% performance gain. Thecontrastive fine-tuning code is publicly available athttps://github.com/trapoom555/Language-Model-STS-CFT.</description><author>Trapoom Ukarapol, Zhicheng Lee, Amy Xin</author><pubDate>Thu, 01 Aug 2024 16:31:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00690v1</guid></item><item><title>Grasp, See and Place: Efficient Unknown Object Rearrangement with Policy Structure Prior</title><link>http://arxiv.org/abs/2402.15402v2</link><description>We focus on the task of unknown object rearrangement, where a robot issupposed to re-configure the objects into a desired goal configurationspecified by an RGB-D image. Recent works explore unknown object rearrangementsystems by incorporating learning-based perception modules. However, they aresensitive to perception error, and pay less attention to task-levelperformance. In this paper, we aim to develop an effective system for unknownobject rearrangement amidst perception noise. We theoretically reveal the noisyperception impacts grasp and place in a decoupled way, and show such adecoupled structure is valuable to improve task optimality. We propose GSP, adual-loop system with the decoupled structure as prior. For the inner loop, welearn a see policy for self-confident in-hand object matching. For the outerloop, we learn a grasp policy aware of object matching and grasp capabilityguided by task-level rewards. We leverage the foundation model CLIP for objectmatching, policy learning and self-termination. A series of experimentsindicate that GSP can conduct unknown object rearrangement with highercompletion rates and fewer steps.</description><author>Kechun Xu, Zhongxiang Zhou, Jun Wu, Haojian Lu, Rong Xiong, Yue Wang</author><pubDate>Thu, 01 Aug 2024 16:31:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15402v2</guid></item><item><title>Can Developers Prompt? A Controlled Experiment for Code Documentation Generation</title><link>http://arxiv.org/abs/2408.00686v1</link><description>Large language models (LLMs) bear great potential for automating tediousdevelopment tasks such as creating and maintaining code documentation. However,it is unclear to what extent developers can effectively prompt LLMs to createconcise and useful documentation. We report on a controlled experiment with 20professionals and 30 computer science students tasked with code documentationgeneration for two Python functions. The experimental group freely enteredad-hoc prompts in a ChatGPT-like extension of Visual Studio Code, while thecontrol group executed a predefined few-shot prompt. Our results reveal thatprofessionals and students were unaware of or unable to apply promptengineering techniques. Especially students perceived the documentationproduced from ad-hoc prompts as significantly less readable, less concise, andless helpful than documentation from prepared prompts. Some professionalsproduced higher quality documentation by just including the keyword Docstringin their ad-hoc prompts. While students desired more support in formulatingprompts, professionals appreciated the flexibility of ad-hoc prompting.Participants in both groups rarely assessed the output as perfect. Instead,they understood the tools as support to iteratively refine the documentation.Further research is needed to understand which prompting skills and preferencesdevelopers have and which support they need for certain tasks.</description><author>Hans-Alexander Kruse, Tim Puhlfürß, Walid Maalej</author><pubDate>Thu, 01 Aug 2024 16:28:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00686v1</guid></item><item><title>The Impact of Quantization on Retrieval-Augmented Generation: An Analysis of Small LLMs</title><link>http://arxiv.org/abs/2406.10251v3</link><description>Post-training quantization reduces the computational demand of Large LanguageModels (LLMs) but can weaken some of their capabilities. Since LLM abilitiesemerge with scale, smaller LLMs are more sensitive to quantization. In thispaper, we explore how quantization affects smaller LLMs' ability to performretrieval-augmented generation (RAG), specifically in longer contexts. We chosepersonalization for evaluation because it is a challenging domain to performusing RAG as it requires long-context reasoning over multiple documents. Wecompare the original FP16 and the quantized INT4 performance of multiple 7B and8B LLMs on two tasks while progressively increasing the number of retrieveddocuments to test how quantized models fare against longer contexts. To betterunderstand the effect of retrieval, we evaluate three retrieval models in ourexperiments. Our findings reveal that if a 7B LLM performs the task well,quantization does not impair its performance and long-context reasoningcapabilities. We conclude that it is possible to utilize RAG with quantizedsmaller LLMs.</description><author>Mert Yazan, Suzan Verberne, Frederik Situmeang</author><pubDate>Thu, 01 Aug 2024 16:27:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.10251v3</guid></item><item><title>Assessing the Variety of a Concept Space Using an Unbiased Estimate of Rao's Quadratic Index</title><link>http://arxiv.org/abs/2408.00684v1</link><description>Past research relates design creativity to 'divergent thinking,' i.e., howwell the concept space is explored during the early phase of design.Researchers have argued that generating several concepts would increase thechances of producing better design solutions. 'Variety' is one of theparameters by which one can quantify the breadth of a concept space explored bythe designers. It is useful to assess variety at the conceptual design stagebecause, at this stage, designers have the freedom to explore differentsolution principles so as to satisfy a design problem with substantially novelconcepts. This article elaborates on and critically examines the existingvariety metrics from the engineering design literature, discussing theirlimitations. A new distance-based variety metric is proposed, along with aprescriptive framework to support the assessment process. This framework usesthe SAPPhIRE model of causality as a knowledge representation scheme to measurethe real-valued distance between two design concepts. The proposed framework isimplemented in a software tool called 'VariAnT.' Furthermore, the tool'sapplication is demonstrated through an illustrative example.</description><author>Anubhab Majumder, Ujjwal Pal, Amaresh Chakrabarti</author><pubDate>Thu, 01 Aug 2024 16:25:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00684v1</guid></item><item><title>Learning in Multi-Objective Public Goods Games with Non-Linear Utilities</title><link>http://arxiv.org/abs/2408.00682v1</link><description>Addressing the question of how to achieve optimal decision-making under riskand uncertainty is crucial for enhancing the capabilities of artificial agentsthat collaborate with or support humans. In this work, we address this questionin the context of Public Goods Games. We study learning in a novelmulti-objective version of the Public Goods Game where agents have differentrisk preferences, by means of multi-objective reinforcement learning. Weintroduce a parametric non-linear utility function to model risk preferences atthe level of individual agents, over the collective and individual rewardcomponents of the game. We study the interplay between such preferencemodelling and environmental uncertainty on the incentive alignment level in thegame. We demonstrate how different combinations of individual preferences andenvironmental uncertainties sustain the emergence of cooperative patterns innon-cooperative environments (i.e., where competitive strategies are dominant),while others sustain competitive patterns in cooperative environments (i.e.,where cooperative strategies are dominant).</description><author>Nicole Orzan, Erman Acar, Davide Grossi, Patrick Mannion, Roxana Rădulescu</author><pubDate>Thu, 01 Aug 2024 16:24:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00682v1</guid></item><item><title>Alpha-VI DeepONet: A prior-robust variational Bayesian approach for enhancing DeepONets with uncertainty quantification</title><link>http://arxiv.org/abs/2408.00681v1</link><description>We introduce a novel deep operator network (DeepONet) framework thatincorporates generalised variational inference (GVI) using R\'enyi's$\alpha$-divergence to learn complex operators while quantifying uncertainty.By incorporating Bayesian neural networks as the building blocks for the branchand trunk networks, our framework endows DeepONet with uncertaintyquantification. The use of R\'enyi's $\alpha$-divergence, instead of theKullback-Leibler divergence (KLD), commonly used in standard variationalinference, mitigates issues related to prior misspecification that areprevalent in Variational Bayesian DeepONets. This approach offers enhancedflexibility and robustness. We demonstrate that modifying the variationalobjective function yields superior results in terms of minimising the meansquared error and improving the negative log-likelihood on the test set. Ourframework's efficacy is validated across various mechanical systems, where itoutperforms both deterministic and standard KLD-based VI DeepONets inpredictive accuracy and uncertainty quantification. The hyperparameter$\alpha$, which controls the degree of robustness, can be tuned to optimiseperformance for specific problems. We apply this approach to a range ofmechanics problems, including gravity pendulum, advection-diffusion, anddiffusion-reaction systems. Our findings underscore the potential of$\alpha$-VI DeepONet to advance the field of data-driven operator learning andits applications in engineering and scientific domains.</description><author>Soban Nasir Lone, Subhayan De, Rajdip Nayek</author><pubDate>Thu, 01 Aug 2024 16:22:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00681v1</guid></item><item><title>Scaling Backwards: Minimal Synthetic Pre-training?</title><link>http://arxiv.org/abs/2408.00677v1</link><description>Pre-training and transfer learning are an important building block of currentcomputer vision systems. While pre-training is usually performed on largereal-world image datasets, in this paper we ask whether this is trulynecessary. To this end, we search for a minimal, purely synthetic pre-trainingdataset that allows us to achieve performance similar to the 1 million imagesof ImageNet-1k. We construct such a dataset from a single fractal withperturbations. With this, we contribute three main findings. (i) We show thatpre-training is effective even with minimal synthetic images, with performanceon par with large-scale pre-training datasets like ImageNet-1k for fullfine-tuning. (ii) We investigate the single parameter with which we constructartificial categories for our dataset. We find that while the shape differencescan be indistinguishable to humans, they are crucial for obtaining strongperformances. (iii) Finally, we investigate the minimal requirements forsuccessful pre-training. Surprisingly, we find that a substantial reduction ofsynthetic images from 1k to 1 can even lead to an increase in pre-trainingperformance, a motivation to further investigate ``scaling backwards''.Finally, we extend our method from synthetic images to real images to see if asingle real image can show similar pre-training effect through shapeaugmentation. We find that the use of grayscale images and affinetransformations allows even real images to ``scale backwards''.</description><author>Ryo Nakamura, Ryu Tadokoro, Ryosuke Yamada, Yuki M. Asano, Iro Laina, Christian Rupprecht, Nakamasa Inoue, Rio Yokota, Hirokatsu Kataoka</author><pubDate>Thu, 01 Aug 2024 16:20:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00677v1</guid></item><item><title>An effect analysis of the balancing techniques on the counterfactual explanations of student success prediction models</title><link>http://arxiv.org/abs/2408.00676v1</link><description>In the past decade, we have experienced a massive boom in the usage ofdigital solutions in higher education. Due to this boom, large amounts of datahave enabled advanced data analysis methods to support learners and examinelearning processes. One of the dominant research directions in learninganalytics is predictive modeling of learners' success using various machinelearning methods. To build learners' and teachers' trust in such methods andsystems, exploring the methods and methodologies that enable relevantstakeholders to deeply understand the underlying machine-learning models isnecessary. In this context, counterfactual explanations from explainablemachine learning tools are promising. Several counterfactual generation methodshold much promise, but the features must be actionable and causal to beeffective. Thus, obtaining which counterfactual generation method suits thestudent success prediction models in terms of desiderata, stability, androbustness is essential. Although a few studies have been published in recentyears on the use of counterfactual explanations in educational sciences, theyhave yet to discuss which counterfactual generation method is more suitable forthis problem. This paper analyzed the effectiveness of commonly usedcounterfactual generation methods, such as WhatIf Counterfactual Explanations,Multi-Objective Counterfactual Explanations, and Nearest InstanceCounterfactual Explanations after balancing. This contribution presents a casestudy using the Open University Learning Analytics dataset to demonstrate thepractical usefulness of counterfactual explanations. The results illustrate themethod's effectiveness and describe concrete steps that could be taken to alterthe model's prediction.</description><author>Mustafa Cavus, Jakub Kuzilek</author><pubDate>Thu, 01 Aug 2024 16:19:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00676v1</guid></item><item><title>Leveraging Entailment Judgements in Cross-Lingual Summarisation</title><link>http://arxiv.org/abs/2408.00675v1</link><description>Synthetically created Cross-Lingual Summarisation (CLS) datasets are prone toinclude document-summary pairs where the reference summary is unfaithful to thecorresponding document as it contains content not supported by the document(i.e., hallucinated content). This low data quality misleads model learning andobscures evaluation results. Automatic ways to assess hallucinations andimprove training have been proposed for monolingual summarisation,predominantly in English. For CLS, we propose to use off-the-shelfcross-lingual Natural Language Inference (X-NLI) to evaluate faithfulness ofreference and model generated summaries. Then, we study training approachesthat are aware of faithfulness issues in the training data and propose anapproach that uses unlikelihood loss to teach a model about unfaithful summarysequences. Our results show that it is possible to train CLS models that yieldmore faithful summaries while maintaining comparable or better informativess.</description><author>Huajian Zhang, Laura Perez-Beltrachini</author><pubDate>Thu, 01 Aug 2024 16:18:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00675v1</guid></item><item><title>ChordSync: Conformer-Based Alignment of Chord Annotations to Music Audio</title><link>http://arxiv.org/abs/2408.00674v1</link><description>In the Western music tradition, chords are the main constituent components ofharmony, a fundamental dimension of music. Despite its relevance for severalMusic Information Retrieval (MIR) tasks, chord-annotated audio datasets arelimited and need more diversity. One way to improve those resources is toleverage the large number of chord annotations available online, but thisrequires aligning them with music audio. However, existing audio-to-scorealignment techniques, which typically rely on Dynamic Time Warping (DTW), failto address this challenge, as they require weakly aligned data for precisesynchronisation. In this paper, we introduce ChordSync, a novel conformer-basedmodel designed to seamlessly align chord annotations with audio, eliminatingthe need for weak alignment. We also provide a pre-trained model and auser-friendly library, enabling users to synchronise chord annotations withaudio tracks effortlessly. In this way, ChordSync creates opportunities forharnessing crowd-sourced chord data for MIR, especially in audio chordestimation, thereby facilitating the generation of novel datasets.Additionally, our system extends its utility to music education, enhancingmusic learning experiences by providing accurately aligned annotations, thusenabling learners to engage in synchronised musical practices.</description><author>Andrea Poltronieri, Valentina Presutti, Martín Rocamora</author><pubDate>Thu, 01 Aug 2024 16:16:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00674v1</guid></item><item><title>Modeling stochastic eye tracking data: A comparison of quantum generative adversarial networks and Markov models</title><link>http://arxiv.org/abs/2408.00673v1</link><description>We explore the use of quantum generative adversarial networks QGANs formodeling eye movement velocity data. We assess whether the advancedcomputational capabilities of QGANs can enhance the modeling of complexstochastic distribution beyond the traditional mathematical models,particularly the Markov model. The findings indicate that while QGANsdemonstrate potential in approximating complex distributions, the Markov modelconsistently outperforms in accurately replicating the real data distribution.This comparison underlines the challenges and avenues for refinement in timeseries data generation using quantum computing techniques. It emphasizes theneed for further optimization of quantum models to better align with real-worlddata characteristics.</description><author>Shailendra Bhandari, Pedro Lincastre, Pedro Lind</author><pubDate>Thu, 01 Aug 2024 16:15:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00673v1</guid></item><item><title>Grappa -- A Machine Learned Molecular Mechanics Force Field</title><link>http://arxiv.org/abs/2404.00050v2</link><description>Simulating large molecular systems over long timescales requires force fieldsthat are both accurate and efficient. In recent years, E(3) equivariant neuralnetworks have lifted the tension between computational efficiency and accuracyof force fields, but they are still several orders of magnitude more expensivethan established molecular mechanics (MM) force fields. Here, we proposeGrappa, a machine learning framework to predict MM parameters from themolecular graph, employing a graph attentional neural network and a transformerwith symmetry-preserving positional encoding. The resulting Grappa force fieldoutperformstabulated and machine-learned MM force fields in terms of accuracyat the same computational efficiency and can be used in existing MolecularDynamics (MD) engines like GROMACS and OpenMM. It predicts energies and forcesof small molecules, peptides, RNA and - showcasing its extensibility touncharted regions of chemical space - radicals at state-of-the-art MM accuracy.We demonstrate Grappa's transferability to macromolecules in MD simulationsfrom a small fast folding protein up to a whole virus particle. Our force fieldsets the stage for biomolecular simulations closer to chemical accuracy, butwith the same computational cost as established protein force fields.</description><author>Leif Seute, Eric Hartmann, Jan Stühmer, Frauke Gräter</author><pubDate>Thu, 01 Aug 2024 16:14:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00050v2</guid></item><item><title>Predicting the Geolocation of Tweets Using transformer models on Customized Data</title><link>http://arxiv.org/abs/2303.07865v4</link><description>This research is aimed to solve the tweet/user geolocation prediction taskand provide a flexible methodology for the geotagging of textual big data. Thesuggested approach implements neural networks for natural language processing(NLP) to estimate the location as coordinate pairs (longitude, latitude) andtwo-dimensional Gaussian Mixture Models (GMMs). The scope of proposed modelshas been finetuned on a Twitter dataset using pretrained Bidirectional EncoderRepresentations from Transformers (BERT) as base models. Performance metricsshow a median error of fewer than 30 km on a worldwide-level, and fewer than 15km on the US-level datasets for the models trained and evaluated on textfeatures of tweets' content and metadata context. Our source code and data areavailable at https://github.com/K4TEL/geo-twitter.git</description><author>Kateryna Lutsai, Christoph H. Lampert</author><pubDate>Thu, 01 Aug 2024 16:14:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.07865v4</guid></item><item><title>MimiQ: Low-Bit Data-Free Quantization of Vision Transformers with Encouraging Inter-Head Attention Similarity</title><link>http://arxiv.org/abs/2407.20021v3</link><description>Data-free quantization (DFQ) is a technique that creates a lightweightnetwork from its full-precision counterpart without the original training data,often through a synthetic dataset. Although several DFQ methods have beenproposed for vision transformer (ViT) architectures, they fail to achieveefficacy in low-bit settings. Examining the existing methods, we identify thattheir synthetic data produce misaligned attention maps, while those of the realsamples are highly aligned. From the observation of aligned attention, we findthat aligning attention maps of synthetic data helps to improve the overallperformance of quantized ViTs. Motivated by this finding, we devise MimiQ, anovel DFQ method designed for ViTs that focuses on inter-head attentionsimilarity. First, we generate synthetic data by aligning head-wise attentionresponses in relation to spatial query patches. Then, we apply head-wisestructural attention distillation to align the attention maps of the quantizednetwork to those of the full-precision teacher. The experimental results showthat the proposed method significantly outperforms baselines, setting a newstate-of-the-art performance for data-free ViT quantization.</description><author>Kanghyun Choi, Hye Yoon Lee, Dain Kwon, SunJong Park, Kyuyeun Kim, Noseong Park, Jinho Lee</author><pubDate>Thu, 01 Aug 2024 16:13:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.20021v3</guid></item><item><title>ExpertAF: Expert Actionable Feedback from Video</title><link>http://arxiv.org/abs/2408.00672v1</link><description>Feedback is essential for learning a new skill or improving one's currentskill-level. However, current methods for skill-assessment from video onlyprovide scores or compare demonstrations, leaving the burden of knowing what todo differently on the user. We introduce a novel method to generate actionablefeedback from video of a person doing a physical activity, such as basketballor soccer. Our method takes a video demonstration and its accompanying 3D bodypose and generates (1) free-form expert commentary describing what the personis doing well and what they could improve, and (2) a visual expertdemonstration that incorporates the required corrections. We show how toleverage Ego-Exo4D's videos of skilled activity and expert commentary togetherwith a strong language model to create a weakly-supervised training dataset forthis task, and we devise a multimodal video-language model to infer coachingfeedback. Our method is able to reason across multi-modal input combinations tooutput full-spectrum, actionable coaching -- expert commentary, expert videoretrieval, and the first-of-its-kind expert pose generation -- outperformingstrong vision-language models on both established metrics and human preferencestudies.</description><author>Kumar Ashutosh, Tushar Nagarajan, Georgios Pavlakos, Kris Kitani, Kristen Grauman</author><pubDate>Thu, 01 Aug 2024 16:13:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00672v1</guid></item><item><title>Evaluate Fine-tuning Strategies for Fetal Head Ultrasound Image Segmentation with U-Net</title><link>http://arxiv.org/abs/2307.09067v2</link><description>Fetal head segmentation is a crucial step in measuring the fetal headcircumference (HC) during gestation, an important biometric in obstetrics formonitoring fetal growth. However, manual biometry generation is time-consumingand results in inconsistent accuracy. To address this issue, convolutionalneural network (CNN) models have been utilized to improve the efficiency ofmedical biometry. But training a CNN network from scratch is a challengingtask, we proposed a Transfer Learning (TL) method. Our approach involvesfine-tuning (FT) a U-Net network with a lightweight MobileNet as the encoder toperform segmentation on a set of fetal head ultrasound (US) images with limitedeffort. This method addresses the challenges associated with training a CNNnetwork from scratch. It suggests that our proposed FT strategy yieldssegmentation performance that is comparable when trained with a reduced numberof parameters by 85.8%. And our proposed FT strategy outperforms otherstrategies with smaller trainable parameter sizes below 4.4 million. Thus, wecontend that it can serve as a dependable FT approach for reducing the size ofmodels in medical image analysis. Our key findings highlight the importance ofthe balance between model performance and size in developing ArtificialIntelligence (AI) applications by TL methods. Code is available athttps://github.com/13204942/FT_Methods_for_Fetal_Head_Segmentation.</description><author>Fangyijie Wang, Guénolé Silvestre, Kathleen M. Curran</author><pubDate>Thu, 01 Aug 2024 16:09:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.09067v2</guid></item><item><title>An introduction to reinforcement learning for neuroscience</title><link>http://arxiv.org/abs/2311.07315v2</link><description>Reinforcement learning has a rich history in neuroscience, from early work ondopamine as a reward prediction error signal for temporal difference learning(Schultz et al., 1997) to recent work suggesting that dopamine could implementa form of 'distributional reinforcement learning' popularized in deep learning(Dabney et al., 2020). Throughout this literature, there has been a tight linkbetween theoretical advances in reinforcement learning and neuroscientificexperiments and findings. As a result, the theories describing our experimentaldata have become increasingly complex and difficult to navigate. In thisreview, we cover the basic theory underlying classical work in reinforcementlearning and build up to an introductory overview of methods in modern deepreinforcement learning that have found applications in systems neuroscience. Westart with an overview of the reinforcement learning problem and classicaltemporal difference algorithms, followed by a discussion of 'model-free' and'model-based' reinforcement learning together with methods such as DYNA andsuccessor representations that fall in between these two extremes. Throughoutthese sections, we highlight the close parallels between such machine learningmethods and related work in both experimental and theoretical neuroscience. Wethen provide an introduction to deep reinforcement learning with examples ofhow these methods have been used to model different learning phenomena insystems neuroscience, such as meta-reinforcement learning (Wang et al., 2018)and distributional reinforcement learning (Dabney et al., 2020). Code thatimplements the methods discussed in this work and generates the figures is alsoprovided.</description><author>Kristopher T. Jensen</author><pubDate>Thu, 01 Aug 2024 16:07:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07315v2</guid></item><item><title>A Unified Framework for Pattern Recovery in Penalized and Thresholded Estimation and its Geometry</title><link>http://arxiv.org/abs/2307.10158v4</link><description>We consider the framework of penalized estimation where the penalty term isgiven by a real-valued polyhedral gauge, which encompasses methods such asLASSO, generalized LASSO, SLOPE, OSCAR, PACS and others. Each of theseestimators can uncover a different structure or ``pattern'' of the unknownparameter vector. We define a novel and general notion of patterns based onsubdifferentials and formalize an approach to measure pattern complexity. Forpattern recovery, we provide a minimal condition for a particular pattern to bedetected by the procedure with positive probability, the so-calledaccessibility condition. Using our approach, we also introduce the strongernoiseless recovery condition. For the LASSO, it is well known that theirrepresentability condition is necessary for pattern recovery with probabilitylarger than $1/2$ and we show that the noiseless recovery plays exactly thesame role in our general framework, thereby unifying and extending theirrepresentability condition to a broad class of penalized estimators. We alsoshow that the noiseless recovery condition can be relaxed when turning toso-called thresholded penalized estimators: we prove that the accessibilitycondition is already sufficient (and necessary) for sure pattern recovery bythresholded penalized estimation provided that the signal of the pattern islarge enough. Throughout the article, we demonstrate how our findings can beinterpreted through a geometrical lens.</description><author>Piotr Graczyk, Ulrike Schneider, Tomasz Skalski, Patrick Tardivel</author><pubDate>Thu, 01 Aug 2024 16:03:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10158v4</guid></item><item><title>Switching the Loss Reduces the Cost in Batch (Offline) Reinforcement Learning</title><link>http://arxiv.org/abs/2403.05385v5</link><description>We propose training fitted Q-iteration with log-loss (FQI-log) for batchreinforcement learning (RL). We show that the number of samples needed to learna near-optimal policy with FQI-log scales with the accumulated cost of theoptimal policy, which is zero in problems where acting optimally achieves thegoal and incurs no cost. In doing so, we provide a general framework forproving small-cost bounds, i.e. bounds that scale with the optimal achievablecost, in batch RL. Moreover, we empirically verify that FQI-log uses fewersamples than FQI trained with squared loss on problems where the optimal policyreliably achieves the goal.</description><author>Alex Ayoub, Kaiwen Wang, Vincent Liu, Samuel Robertson, James McInerney, Dawen Liang, Nathan Kallus, Csaba Szepesvári</author><pubDate>Thu, 01 Aug 2024 16:02:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.05385v5</guid></item><item><title>AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models</title><link>http://arxiv.org/abs/2408.00665v1</link><description>Automated Machine Learning (AutoML) offers a promising approach to streamlinethe training of machine learning models. However, existing AutoML frameworksare often limited to unimodal scenarios and require extensive manualconfiguration. Recent advancements in Large Language Models (LLMs) haveshowcased their exceptional abilities in reasoning, interaction, and codegeneration, presenting an opportunity to develop a more automated anduser-friendly framework. To this end, we introduce AutoM3L, an innovativeAutomated Multimodal Machine Learning framework that leverages LLMs ascontrollers to automatically construct multimodal training pipelines. AutoM3Lcomprehends data modalities and selects appropriate models based on userrequirements, providing automation and interactivity. By eliminating the needfor manual feature engineering and hyperparameter optimization, our frameworksimplifies user engagement and enables customization through directives,addressing the limitations of previous rule-based AutoML approaches. Weevaluate the performance of AutoM3L on six diverse multimodal datasets spanningclassification, regression, and retrieval tasks, as well as a comprehensive setof unimodal datasets. The results demonstrate that AutoM3L achieves competitiveor superior performance compared to traditional rule-based AutoML methods.Furthermore, a user study highlights the user-friendliness and usability of ourframework, compared to the rule-based AutoML methods.</description><author>Daqin Luo, Chengjian Feng, Yuxuan Nong, Yiqing Shen</author><pubDate>Thu, 01 Aug 2024 16:01:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00665v1</guid></item><item><title>Towards Self-Supervised FG-SBIR with Unified Sample Feature Alignment and Multi-Scale Token Recycling</title><link>http://arxiv.org/abs/2406.11551v3</link><description>Fine-Grained Sketch-Based Image Retrieval (FG-SBIR) aims to minimize thedistance between sketches and corresponding images in the embedding space.However, scalability is hindered by the growing complexity of solutions, mainlydue to the abstract nature of fine-grained sketches. In this paper, we proposean effective approach to narrow the gap between the two domains. It mainlyfacilitates unified mutual information sharing both intra- and inter-samples,rather than treating them as a single feature alignment problem betweenmodalities. Specifically, our approach includes: (i) Employing dualweight-sharing networks to optimize alignment within the sketch and imagedomain, which also effectively mitigates model learning saturation issues. (ii)Introducing an objective optimization function based on contrastive loss toenhance the model's ability to align features in both intra- and inter-samples.(iii) Presenting a self-supervised Multi-Scale Token Recycling (MSTR) Modulefeatured by recycling discarded patch tokens in multi-scale features, furtherenhancing representation capability and retrieval performance. Our frameworkachieves excellent results on CNN- and ViT-based backbones. Extensiveexperiments demonstrate its superiority over existing methods. We alsointroduce Cloths-V1, the first professional fashion sketch-image dataset,utilized to validate our method and will be beneficial for other applications</description><author>Jianan Jiang, Hao Tang, Zhilin Jiang, Weiren Yu, Di Wu</author><pubDate>Thu, 01 Aug 2024 16:00:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11551v3</guid></item><item><title>Aligning Multiple Knowledge Graphs in a Single Pass</title><link>http://arxiv.org/abs/2408.00662v1</link><description>Entity alignment (EA) is to identify equivalent entities across differentknowledge graphs (KGs), which can help fuse these KGs into a more comprehensiveone. Previous EA methods mainly focus on aligning a pair of KGs, and to thebest of our knowledge, no existing EA method considers aligning multiple (morethan two) KGs. To fill this research gap, in this work, we study a novelproblem of aligning multiple KGs and propose an effective framework namedMultiEA to solve the problem. First, we embed the entities of all the candidateKGs into a common feature space by a shared KG encoder. Then, we explore threealignment strategies to minimize the distances among pre-aligned entities. Inparticular, we propose an innovative inference enhancement technique to improvethe alignment performance by incorporating high-order similarities. Finally, toverify the effectiveness of MultiEA, we construct two new real-world benchmarkdatasets and conduct extensive experiments on them. The results show that ourMultiEA can effectively and efficiently align multiple KGs in a single pass.</description><author>Yaming Yang, Zhe Wang, Ziyu Guan, Wei Zhao, Weigang Lu, Xinyan Huang</author><pubDate>Thu, 01 Aug 2024 15:58:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00662v1</guid></item><item><title>Vivim: a Video Vision Mamba for Medical Video Segmentation</title><link>http://arxiv.org/abs/2401.14168v4</link><description>Medical video segmentation gains increasing attention in clinical practicedue to the redundant dynamic references in video frames. However, traditionalconvolutional neural networks have a limited receptive field andtransformer-based networks are mediocre in constructing long-term dependencyfrom the perspective of computational complexity. This bottleneck poses asignificant challenge when processing longer sequences in medical videoanalysis tasks using available devices with limited memory. Recently, statespace models (SSMs), famous by Mamba, have exhibited impressive achievements inefficient long sequence modeling, which develops deep neural networks byexpanding the receptive field on many vision tasks significantly.Unfortunately, vanilla SSMs failed to simultaneously capture causal temporalcues and preserve non-casual spatial information. To this end, this paperpresents a Video Vision Mamba-based framework, dubbed as Vivim, for medicalvideo segmentation tasks. Our Vivim can effectively compress the long-termspatiotemporal representation into sequences at varying scales with ourdesigned Temporal Mamba Block. We also introduce an improved boundary-awareaffine constraint across frames to enhance the discriminative ability of Vivimon ambiguous lesions. Extensive experiments on thyroid segmentation, breastlesion segmentation in ultrasound videos, and polyp segmentation in colonoscopyvideos demonstrate the effectiveness and efficiency of our Vivim, superior toexisting methods. The code is available at:https://github.com/scott-yjyang/Vivim. The dataset will be released onceaccepted.</description><author>Yijun Yang, Zhaohu Xing, Lequan Yu, Chunwang Huang, Huazhu Fu, Lei Zhu</author><pubDate>Thu, 01 Aug 2024 15:56:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14168v4</guid></item><item><title>Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition</title><link>http://arxiv.org/abs/2407.02651v2</link><description>LLM-powered tools like ChatGPT Data Analysis, have the potential to helpusers tackle the challenging task of data analysis programming, which requiresexpertise in data processing, programming, and statistics. However, ourformative study (n=15) uncovered serious challenges in verifying AI-generatedresults and steering the AI (i.e., guiding the AI system to produce the desiredoutput). We developed two contrasting approaches to address these challenges.The first (Stepwise) decomposes the problem into step-by-step subgoals withpairs of editable assumptions and code until task completion, while the second(Phasewise) decomposes the entire problem into three editable, logical phases:structured input/output assumptions, execution plan, and code. A controlled,within-subjects experiment (n=18) compared these systems against aconversational baseline. Users reported significantly greater control with theStepwise and Phasewise systems, and found intervention, correction, andverification easier, compared to the baseline. The results suggest designguidelines and trade-offs for AI-assisted data analysis tools.</description><author>Majeed Kazemitabaar, Jack Williams, Ian Drosos, Tovi Grossman, Austin Henley, Carina Negreanu, Advait Sarkar</author><pubDate>Thu, 01 Aug 2024 15:56:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.02651v2</guid></item><item><title>Technical Note: Defining and Quantifying AND-OR Interactions for Faithful and Concise Explanation of DNNs</title><link>http://arxiv.org/abs/2304.13312v2</link><description>In this technical note, we aim to explain a deep neural network (DNN) byquantifying the encoded interactions between input variables, which reflectsthe DNN's inference logic. Specifically, we first rethink the definition ofinteractions, and then formally define faithfulness and conciseness forinteraction-based explanation. To this end, we propose two kinds ofinteractions, i.e., the AND interaction and the OR interaction. Forfaithfulness, we prove the uniqueness of the AND (OR) interaction inquantifying the effect of the AND (OR) relationship between input variables.Besides, based on AND-OR interactions, we design techniques to boost theconciseness of the explanation, while not hurting the faithfulness. In thisway, the inference logic of a DNN can be faithfully and concisely explained bya set of symbolic concepts.</description><author>Mingjie Li, Quanshi Zhang</author><pubDate>Thu, 01 Aug 2024 15:54:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13312v2</guid></item><item><title>Application of Transformers for Nonlinear Channel Compensation in Optical Systems</title><link>http://arxiv.org/abs/2304.13119v3</link><description>In this paper, we introduce a new nonlinear optical channel equalizer basedon Transformers. By leveraging parallel computation and attending directly tothe memory across a sequence of symbols, we show that Transformers can be usedeffectively for nonlinear compensation (NLC) in coherent long-haul transmissionsystems. For this application, we present an implementation of the encoder partof the Transformer and analyze its performance over a wide range of differenthyper-parameters. It is shown that by proper embeddings and processing blocksof symbols at each iteration and also carefully selecting subsets of theencoder's output to be processed together, an efficient nonlinear equalizationcan be achieved for different complexity constraints. To reduce thecomputational complexity of the attention mechanism, we further propose the useof a physic-informed mask inspired by nonlinear perturbation theory. We alsocompare the Transformer-NLC with digital back-propagation (DBP) under differenttransmission scenarios in order to demonstrate the flexibility andgeneralizability of the proposed data-driven solution.</description><author>Behnam Behinaein Hamgini, Hossein Najafi, Ali Bakhshali, Zhuhong Zhang</author><pubDate>Thu, 01 Aug 2024 15:52:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.13119v3</guid></item><item><title>Text Image Inpainting via Global Structure-Guided Diffusion Models</title><link>http://arxiv.org/abs/2401.14832v3</link><description>Real-world text can be damaged by corrosion issues caused by environmental orhuman factors, which hinder the preservation of the complete styles of texts,e.g., texture and structure. These corrosion issues, such as graffiti signs andincomplete signatures, bring difficulties in understanding the texts, therebyposing significant challenges to downstream applications, e.g., scene textrecognition and signature identification. Notably, current inpaintingtechniques often fail to adequately address this problem and have difficultiesrestoring accurate text images along with reasonable and consistent styles.Formulating this as an open problem of text image inpainting, this paper aimsto build a benchmark to facilitate its study. In doing so, we establish twospecific text inpainting datasets which contain scene text images andhandwritten text images, respectively. Each of them includes images revamped byreal-life and synthetic datasets, featuring pairs of original images, corruptedimages, and other assistant information. On top of the datasets, we furtherdevelop a novel neural framework, Global Structure-guided Diffusion Model(GSDM), as a potential solution. Leveraging the global structure of the text asa prior, the proposed GSDM develops an efficient diffusion model to recoverclean texts. The efficacy of our approach is demonstrated by thorough empiricalstudy, including a substantial boost in both recognition accuracy and imagequality. These findings not only highlight the effectiveness of our method butalso underscore its potential to enhance the broader field of text imageunderstanding and processing. Code and datasets are available at:https://github.com/blackprotoss/GSDM.</description><author>Shipeng Zhu, Pengfei Fang, Chenjie Zhu, Zuoyan Zhao, Qiang Xu, Hui Xue</author><pubDate>Thu, 01 Aug 2024 15:46:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14832v3</guid></item><item><title>Disentangling Dense Embeddings with Sparse Autoencoders</title><link>http://arxiv.org/abs/2408.00657v1</link><description>Sparse autoencoders (SAEs) have shown promise in extracting interpretablefeatures from complex neural networks. We present one of the first applicationsof SAEs to dense text embeddings from large language models, demonstratingtheir effectiveness in disentangling semantic concepts. By training SAEs onembeddings of over 420,000 scientific paper abstracts from computer science andastronomy, we show that the resulting sparse representations maintain semanticfidelity while offering interpretability. We analyse these learned features,exploring their behaviour across different model capacities and introducing anovel method for identifying ``feature families'' that represent relatedconcepts at varying levels of abstraction. To demonstrate the practical utilityof our approach, we show how these interpretable features can be used toprecisely steer semantic search, allowing for fine-grained control over querysemantics. This work bridges the gap between the semantic richness of denseembeddings and the interpretability of sparse representations. We open sourceour embeddings, trained sparse autoencoders, and interpreted features, as wellas a web app for exploring them.</description><author>Charles O'Neill, Christine Ye, Kartheik Iyer, John F. Wu</author><pubDate>Thu, 01 Aug 2024 15:46:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00657v1</guid></item><item><title>SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models</title><link>http://arxiv.org/abs/2408.00655v1</link><description>Contemporary large language models (LLMs) predominantly utilize a next-tokenprediction method for inference, which significantly impedes their processingspeed. In this paper, we introduce a novel inference methodology termednext-sentence prediction, aimed at enhancing the inference efficiency of LLMs.We present SentenceVAE, a tiny model consisting of an encoder and a decoder.The encoder effectively condenses the information within a sentence into asingular token, while the decoder reconstructs this compressed data back intoits original sentential form. By integrating SentenceVAE into the input andoutput layers of LLMs, we develop Sentence-level LLMs (SLLMs) that employ asentence-by-sentence inference approach, markedly accelerating inferencespeeds. SentenceVAE also maintains the integrity of the original semanticcontent by segmenting the text into sentences, thereby preserving accuracywhile boosting inference speeds. Compared to traditional LLMs, SLLMs processfewer tokens over equivalent context lengths, significantly reducing memorydemands for Self-Attention computations and facilitating the handling of longercontexts. Our experimental findings reveal that this method can increaseinference speeds by 204~365%, reduce perplexity (PPL) to 46~75% of its originalmetric, and decrease memory overhead by 86~91% for the same context length. Theadvantages of this approach are further amplified with increases in modelparameters.</description><author>Hongjun An, Yifan Chen, Xiaozhen Qiao, Zhe Sun, Xuelong Li</author><pubDate>Thu, 01 Aug 2024 15:45:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00655v1</guid></item><item><title>A Notion of Complexity for Theory of Mind via Discrete World Models</title><link>http://arxiv.org/abs/2406.11911v2</link><description>Theory of Mind (ToM) can be used to assess the capabilities of Large LanguageModels (LLMs) in complex scenarios where social reasoning is required. Whilethe research community has proposed many ToM benchmarks, their hardness variesgreatly, and their complexity is not well defined. This work proposes aframework to measure the complexity of ToM tasks. We quantify a problem'scomplexity as the number of states necessary to solve it correctly. Ourcomplexity measure also accounts for spurious states of a ToM problem designedto make it apparently harder. We use our method to assess the complexity offive widely adopted ToM benchmarks. On top of this framework, we design aprompting technique that augments the information available to a model with adescription of how the environment changes with the agents' interactions. Wename this technique Discrete World Models (DWM) and show how it elicitssuperior performance on ToM tasks.</description><author>X. Angelo Huang, Emanuele La Malfa, Samuele Marro, Andrea Asperti, Anthony Cohn, Michael Wooldridge</author><pubDate>Thu, 01 Aug 2024 15:44:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.11911v2</guid></item><item><title>SF3D: Stable Fast 3D Mesh Reconstruction with UV-unwrapping and Illumination Disentanglement</title><link>http://arxiv.org/abs/2408.00653v1</link><description>We present SF3D, a novel method for rapid and high-quality textured objectmesh reconstruction from a single image in just 0.5 seconds. Unlike mostexisting approaches, SF3D is explicitly trained for mesh generation,incorporating a fast UV unwrapping technique that enables swift texturegeneration rather than relying on vertex colors. The method also learns topredict material parameters and normal maps to enhance the visual quality ofthe reconstructed 3D meshes. Furthermore, SF3D integrates a delighting step toeffectively remove low-frequency illumination effects, ensuring that thereconstructed meshes can be easily used in novel illumination conditions.Experiments demonstrate the superior performance of SF3D over the existingtechniques. Project page: https://stable-fast-3d.github.io</description><author>Mark Boss, Zixuan Huang, Aaryaman Vasishta, Varun Jampani</author><pubDate>Thu, 01 Aug 2024 15:41:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00653v1</guid></item><item><title>Enhancing Multistep Prediction of Multivariate Market Indices Using Weighted Optical Reservoir Computing</title><link>http://arxiv.org/abs/2408.00652v1</link><description>We propose and experimentally demonstrate an innovative stock indexprediction method using a weighted optical reservoir computing system. Weconstruct fundamental market data combined with macroeconomic data andtechnical indicators to capture the broader behavior of the stock market. Ourapproach shows significant higher performance than state-of-the-art methodssuch as linear regression, decision trees, and neural network architecturesincluding long short-term memory. It captures well the market's high volatilityand nonlinear behaviors despite limited data, demonstrating great potential forreal-time, parallel, multi-dimensional data processing and predictions.</description><author>Fang Wang, Ting Bu, Yuping Huang</author><pubDate>Thu, 01 Aug 2024 15:41:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00652v1</guid></item><item><title>A Dirichlet stochastic block model for composition-weighted networks</title><link>http://arxiv.org/abs/2408.00651v1</link><description>Network data are observed in various applications where the individualentities of the system interact with or are connected to each other, and oftenthese interactions are defined by their associated strength or importance.Clustering is a common task in network analysis that involves finding groups ofnodes displaying similarities in the way they interact with the rest of thenetwork. However, most clustering methods use the strengths of connectionsbetween entities in their original form, ignoring the possible differences inthe capacities of individual nodes to send or receive edges. This often leadsto clustering solutions that are heavily influenced by the nodes' capacities.One way to overcome this is to analyse the strengths of connections in relativerather than absolute terms, expressing each edge weight as a proportion of thesending (or receiving) capacity of the respective node. This, however, inducesadditional modelling constraints that most existing clustering methods are notdesigned to handle. In this work we propose a stochastic block model forcomposition-weighted networks based on direct modelling of compositional weightvectors using a Dirichlet mixture, with the parameters determined by thecluster labels of the sender and the receiver nodes. Inference is implementedvia an extension of the classification expectation-maximisation algorithm thatuses a working independence assumption, expressing the complete data likelihoodof each node of the network as a function of fixed cluster labels of theremaining nodes. A model selection criterion is derived to aid the choice ofthe number of clusters. The model is validated using simulation studies, andshowcased on network data from the Erasmus exchange program and a bike sharingnetwork for the city of London.</description><author>Iuliia Promskaia, Adrian O'Hagan, Michael Fop</author><pubDate>Thu, 01 Aug 2024 15:41:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00651v1</guid></item><item><title>SC-MIL: Sparsely Coded Multiple Instance Learning for Whole Slide Image Classification</title><link>http://arxiv.org/abs/2311.00048v2</link><description>Multiple Instance Learning (MIL) has been widely used in weakly supervisedwhole slide image (WSI) classification. Typical MIL methods include a featureembedding part, which embeds the instances into features via a pre-trainedfeature extractor, and an MIL aggregator that combines instance embeddings intopredictions. Most efforts have typically focused on improving these parts. Thisinvolves refining the feature embeddings through self-supervised pre-trainingas well as modeling the correlations between instances separately. In this paper, we proposed a sparsely coding MIL (SC-MIL) method thataddresses those two aspects at the same time by leveraging sparse dictionarylearning. The sparse dictionary learning captures the similarities of instancesby expressing them as sparse linear combinations of atoms in an over-completedictionary. In addition, imposing sparsity improves instance feature embeddingsby suppressing irrelevant instances while retaining the most relevant ones. Tomake the conventional sparse coding algorithm compatible with deep learning, weunrolled it into a sparsely coded module leveraging deep unrolling. Theproposed SC module can be incorporated into any existing MIL framework in aplug-and-play manner with an acceptable computational cost. The experimentalresults on multiple datasets demonstrated that the proposed SC module couldsubstantially boost the performance of state-of-the-art MIL methods. The codesare available at\href{https://github.com/sotiraslab/SCMIL.git}{https://github.com/sotiraslab/SCMIL.git}.</description><author>Peijie Qiu, Pan Xiao, Wenhui Zhu, Yalin Wang, Aristeidis Sotiras</author><pubDate>Thu, 01 Aug 2024 15:37:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00048v2</guid></item><item><title>Genetic Algorithms with Neural Cost Predictor for Solving Hierarchical Vehicle Routing Problems</title><link>http://arxiv.org/abs/2310.14157v3</link><description>When vehicle routing decisions are intertwined with higher-level decisions,the resulting optimization problems pose significant challenges forcomputation. Examples are the multi-depot vehicle routing problem (MDVRP),where customers are assigned to depots before delivery, and the capacitatedlocation routing problem (CLRP), where the locations of depots should bedetermined first. A simple and straightforward approach for such hierarchicalproblems would be to separate the higher-level decisions from the complicatedvehicle routing decisions. For each higher-level decision candidate, we mayevaluate the underlying vehicle routing problems to assess the candidate. Asthis approach requires solving vehicle routing problems multiple times, it hasbeen regarded as impractical in most cases. We propose a noveldeep-learning-based approach called Genetic Algorithm with Neural CostPredictor (GANCP) to tackle the challenge and simplify algorithm developments.For each higher-level decision candidate, we predict the objective functionvalues of the underlying vehicle routing problems using a pre-trained graphneural network without actually solving the routing problems. In particular,our proposed neural network learns the objective values of the HGS-CVRPopen-source package that solves capacitated vehicle routing problems. Ournumerical experiments show that this simplified approach is effective andefficient in generating high-quality solutions for both MDVRP and CLRP and hasthe potential to expedite algorithm developments for complicated hierarchicalproblems. We provide computational results evaluated in the standard benchmarkinstances used in the literature.</description><author>Abhay Sobhanan, Junyoung Park, Jinkyoo Park, Changhyun Kwon</author><pubDate>Thu, 01 Aug 2024 15:37:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14157v3</guid></item><item><title>Towards End-to-End Explainable Facial Action Unit Recognition via Vision-Language Joint Learning</title><link>http://arxiv.org/abs/2408.00644v1</link><description>Facial action units (AUs), as defined in the Facial Action Coding System(FACS), have received significant research interest owing to their diverserange of applications in facial state analysis. Current mainstream FAUrecognition models have a notable limitation, i.e., focusing only on theaccuracy of AU recognition and overlooking explanations of corresponding AUstates. In this paper, we propose an end-to-end Vision-Language joint learningnetwork for explainable FAU recognition (termed VL-FAU), which aims toreinforce AU representation capability and language interpretability throughthe integration of joint multimodal tasks. Specifically, VL-FAU brings togetherlanguage models to generate fine-grained local muscle descriptions anddistinguishable global face description when optimising FAU recognition.Through this, the global facial representation and its local AU representationswill achieve higher distinguishability among different AUs and differentsubjects. In addition, multi-level AU representation learning is utilised toimprove AU individual attention-aware representation capabilities based onmulti-scale combined facial stem feature. Extensive experiments on DISFA andBP4D AU datasets show that the proposed approach achieves superior performanceover the state-of-the-art methods on most of the metrics. In addition, comparedwith mainstream FAU recognition methods, VL-FAU can provide local- andglobal-level interpretability language descriptions with the AUs' predictions.</description><author>Xuri Ge, Junchen Fu, Fuhai Chen, Shan An, Nicu Sebe, Joemon M. Jose</author><pubDate>Thu, 01 Aug 2024 15:35:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00644v1</guid></item><item><title>Enhancing Ethereum Fraud Detection via Generative and Contrastive Self-supervision</title><link>http://arxiv.org/abs/2408.00641v1</link><description>The rampant fraudulent activities on Ethereum hinder the healthy developmentof the blockchain ecosystem, necessitating the reinforcement of regulations.However, multiple imbalances involving account interaction frequencies andinteraction types in the Ethereum transaction environment pose significantchallenges to data mining-based fraud detection research. To address this, wefirst propose the concept of meta-interactions to refine interaction behaviorsin Ethereum, and based on this, we present a dual self-supervision enhancedEthereum fraud detection framework, named Meta-IFD. This framework initiallyintroduces a generative self-supervision mechanism to augment the interactionfeatures of accounts, followed by a contrastive self-supervision mechanism todifferentiate various behavior patterns, and ultimately characterizes thebehavioral representations of accounts and mines potential fraud risks throughmulti-view interaction feature learning. Extensive experiments on real Ethereumdatasets demonstrate the effectiveness and superiority of our framework indetecting common Ethereum fraud behaviors such as Ponzi schemes and phishingscams. Additionally, the generative module can effectively alleviate theinteraction distribution imbalance in Ethereum data, while the contrastivemodule significantly enhances the framework's ability to distinguish differentbehavior patterns. The source code will be released on GitHub soon.</description><author>Chenxiang Jin, Jiajun Zhou, Chenxuan Xie, Shanqing Yu, Qi Xuan, Xiaoniu Yang</author><pubDate>Thu, 01 Aug 2024 15:30:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00641v1</guid></item><item><title>AMAES: Augmented Masked Autoencoder Pretraining on Public Brain MRI Data for 3D-Native Segmentation</title><link>http://arxiv.org/abs/2408.00640v1</link><description>This study investigates the impact of self-supervised pretraining of 3Dsemantic segmentation models on a large-scale, domain-specific dataset. Weintroduce BRAINS-45K, a dataset of 44,756 brain MRI volumes from publicsources, the largest public dataset available, and revisit a number of designchoices for pretraining modern segmentation architectures by simplifying andoptimizing state-of-the-art methods, and combining them with a novelaugmentation strategy. The resulting AMAES framework is based onmasked-image-modeling and intensity-based augmentation reversal and balancesmemory usage, runtime, and finetuning performance. Using the popular U-Net andthe recent MedNeXt architecture as backbones, we evaluate the effect ofpretraining on three challenging downstream tasks, covering single-sequence,low-resource settings, and out-of-domain generalization. The results highlightthat pretraining on the proposed dataset with AMAES significantly improvessegmentation performance in the majority of evaluated cases, and that it isbeneficial to pretrain the model with augmentations, despite pretraing on alarge-scale dataset. Code and model checkpoints for reproducing results, aswell as the BRAINS-45K dataset are available at\url{https://github.com/asbjrnmunk/amaes}.</description><author>Asbjørn Munk, Jakob Ambsdorf, Sebastian Llambias, Mads Nielsen</author><pubDate>Thu, 01 Aug 2024 15:27:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00640v1</guid></item><item><title>Privacy-preserving datasets by capturing feature distributions with Conditional VAEs</title><link>http://arxiv.org/abs/2408.00639v1</link><description>Large and well-annotated datasets are essential for advancing deep learningapplications, however often costly or impossible to obtain by a single entity.In many areas, including the medical domain, approaches relying on data sharinghave become critical to address those challenges. While effective in increasingdataset size and diversity, data sharing raises significant privacy concerns.Commonly employed anonymization methods based on the k-anonymity paradigm oftenfail to preserve data diversity, affecting model robustness. This workintroduces a novel approach using Conditional Variational Autoencoders (CVAEs)trained on feature vectors extracted from large pre-trained vision foundationmodels. Foundation models effectively detect and represent complex patternsacross diverse domains, allowing the CVAE to faithfully capture the embeddingspace of a given data distribution to generate (sample) a diverse,privacy-respecting, and potentially unbounded set of synthetic feature vectors.Our method notably outperforms traditional approaches in both medical andnatural image domains, exhibiting greater dataset diversity and higherrobustness against perturbations while preserving sample privacy. These resultsunderscore the potential of generative models to significantly impact deeplearning applications in data-scarce and privacy-sensitive environments. Thesource code is available athttps://github.com/francescodisalvo05/cvae-anonymization .</description><author>Francesco Di Salvo, David Tafler, Sebastian Doerrich, Christian Ledig</author><pubDate>Thu, 01 Aug 2024 15:26:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00639v1</guid></item><item><title>Deep Learning in Medical Image Classification from MRI-based Brain Tumor Images</title><link>http://arxiv.org/abs/2408.00636v1</link><description>Brain tumors are among the deadliest diseases in the world. MagneticResonance Imaging (MRI) is one of the most effective ways to detect braintumors. Accurate detection of brain tumors based on MRI scans is critical, asit can potentially save many lives and facilitate better decision-making at theearly stages of the disease. Within our paper, four different types ofMRI-based images have been collected from the database: glioma tumor, no tumor,pituitary tumor, and meningioma tumor. Our study focuses on making predictionsfor brain tumor classification. Five models, including four pre-trained models(MobileNet, EfficientNet-B0, ResNet-18, and VGG16) and one new model,MobileNet-BT, have been proposed for this study.</description><author>Xiaoyi Liu, Zhuoyue Wang</author><pubDate>Thu, 01 Aug 2024 15:20:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00636v1</guid></item><item><title>DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks</title><link>http://arxiv.org/abs/2408.00633v1</link><description>Introduction: This article introduces DisTrack, a methodology and a tooldeveloped for tracking and analyzing misinformation within Online SocialNetworks (OSNs). DisTrack is designed to combat the spread of misinformationthrough a combination of Natural Language Processing (NLP) Social NetworkAnalysis (SNA) and graph visualization. The primary goal is to detectmisinformation, track its propagation, identify its sources, and assess theinfluence of various actors within the network. Methods: DisTrack's architecture incorporates a variety of methodologiesincluding keyword search, semantic similarity assessments, and graph generationtechniques. These methods collectively facilitate the monitoring ofmisinformation, the categorization of content based on alignment with knownfalse claims, and the visualization of dissemination cascades through detailedgraphs. The tool is tailored to capture and analyze the dynamic nature ofmisinformation spread in digital environments. Results: The effectiveness of DisTrack is demonstrated through three casestudies focused on different themes: discredit/hate speech, anti-vaccinemisinformation, and false narratives about the Russia-Ukraine conflict. Thesestudies show DisTrack's capabilities in distinguishing posts that propagatefalsehoods from those that counteract them, and tracing the evolution ofmisinformation from its inception. Conclusions: The research confirms that DisTrack is a valuable tool in thefield of misinformation analysis. It effectively distinguishes betweendifferent types of misinformation and traces their development over time. Byproviding a comprehensive approach to understanding and combatingmisinformation in digital spaces, DisTrack proves to be an essential asset forresearchers and practitioners working to mitigate the impact of falseinformation in online social environments.</description><author>Guillermo Villar-Rodríguez, Álvaro Huertas-García, Alejandro Martín, Javier Huertas-Tato, David Camacho</author><pubDate>Thu, 01 Aug 2024 15:17:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00633v1</guid></item><item><title>Actor-Critic Physics-informed Neural Lyapunov Control</title><link>http://arxiv.org/abs/2403.08448v2</link><description>Designing control policies for stabilization tasks with provable guaranteesis a long-standing problem in nonlinear control. A crucial performance metricis the size of the resulting region of attraction, which essentially serves asa robustness "margin" of the closed-loop system against uncertainties. In thispaper, we propose a new method to train a stabilizing neural network controlleralong with its corresponding Lyapunov certificate, aiming to maximize theresulting region of attraction while respecting the actuation constraints.Crucial to our approach is the use of Zubov's Partial Differential Equation(PDE), which precisely characterizes the true region of attraction of a givencontrol policy. Our framework follows an actor-critic pattern where wealternate between improving the control policy (actor) and learning a Zubovfunction (critic). Finally, we compute the largest certifiable region ofattraction by invoking an SMT solver after the training procedure. Ournumerical experiments on several design problems show consistent andsignificant improvements in the size of the resulting region of attraction.</description><author>Jiarui Wang, Mahyar Fazlyab</author><pubDate>Thu, 01 Aug 2024 15:16:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.08448v2</guid></item><item><title>The opportunities and risks of large language models in mental health</title><link>http://arxiv.org/abs/2403.14814v3</link><description>Global rates of mental health concerns are rising, and there is increasingrealization that existing models of mental health care will not adequatelyexpand to meet the demand. With the emergence of large language models (LLMs)has come great optimism regarding their promise to create novel, large-scalesolutions to support mental health. Despite their nascence, LLMs have alreadybeen applied to mental health related tasks. In this paper, we summarize theextant literature on efforts to use LLMs to provide mental health education,assessment, and intervention and highlight key opportunities for positiveimpact in each area. We then highlight risks associated with LLMs' applicationto mental health and encourage the adoption of strategies to mitigate theserisks. The urgent need for mental health support must be balanced withresponsible development, testing, and deployment of mental health LLMs. It isespecially critical to ensure that mental health LLMs are fine-tuned for mentalhealth, enhance mental health equity, and adhere to ethical standards and thatpeople, including those with lived experience with mental health concerns, areinvolved in all stages from development through deployment. Prioritizing theseefforts will minimize potential harms to mental health and maximize thelikelihood that LLMs will positively impact mental health globally.</description><author>Hannah R. Lawrence, Renee A. Schneider, Susan B. Rubin, Maja J. Mataric, Daniel J. McDuff, Megan Jones Bell</author><pubDate>Thu, 01 Aug 2024 15:15:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.14814v3</guid></item><item><title>Empowering Snapshot Compressive Imaging: Spatial-Spectral State Space Model with Across-Scanning and Local Enhancement</title><link>http://arxiv.org/abs/2408.00629v1</link><description>Snapshot Compressive Imaging (SCI) relies on decoding algorithms such as CNNor Transformer to reconstruct the hyperspectral image (HSI) from its compressedmeasurement. Although existing CNN and Transformer-based methods have proveneffective, CNNs are limited by their inadequate modeling of long-rangedependencies, while Transformer ones face high computational costs due toquadratic complexity. Recent Mamba models have demonstrated superiorperformance over CNN and Transformer-based architectures in some visual tasks,but these models have not fully utilized the local similarities in both spatialand spectral dimensions. Moreover, the long-sequence modeling capability of SSMmay offer an advantage in processing the numerous spectral bands for HSIreconstruction, which has not yet been explored. In this paper, we introduce aState Space Model with Across-Scanning and Local Enhancement, named ASLE-SSM,that employs a Spatial-Spectral SSM for global-local balanced context encodingand cross-channel interaction promoting. Specifically, we introduce localscanning in the spatial dimension to balance the global and local receptivefields, and then propose our across-scanning method based on spatial-spectrallocal cubes to leverage local similarities between adjacent spectral bands andpixels to guide the reconstruction process. These two scanning mechanismsextract the HSI's local features while balancing the global perspective withoutany additional costs. Experimental results illustrate ASLE-SSM's superiorityover existing state-of-the-art methods, with an inference speed 2.4 timesfaster than Transformer-based MST and saving 0.12 (M) of parameters, achievingthe lowest computational cost and parameter count.</description><author>Wenzhe Tian, Haijin Zeng, Yin-Ping Zhao, Yongyong Chen, Zhen Wang, Xuelong Li</author><pubDate>Thu, 01 Aug 2024 15:14:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00629v1</guid></item><item><title>Untangling the Effects of Down-Sampling and Selection in Genetic Programming</title><link>http://arxiv.org/abs/2304.07089v2</link><description>Genetic programming systems often use large training sets to evaluate thequality of candidate solutions for selection, which is often computationallyexpensive. Down-sampling training sets has long been used to decrease thecomputational cost of evaluation in a wide range of application domains. Morespecifically, recent studies have shown that both random and informeddown-sampling can substantially improve problem-solving success for GP systemsthat use the lexicase parent selection algorithm. We test whether thesedown-sampling techniques can also improve problem-solving success in thecontext of three other commonly used selection methods, fitness-proportionate,tournament, implicit fitness sharing plus tournament selection, across sixprogram synthesis GP problems. We verified that down-sampling can significantlyimprove the problem-solving success for all three of these other selectionschemes, demonstrating its general efficacy. We discern that the selectionpressure imposed by the selection scheme does not interact with thedown-sampling method. However, we find that informed down-sampling can improveproblem solving success significantly over random down-sampling when theselection scheme has a mechanism for diversity maintenance like lexicase orimplicit fitness sharing. Overall, our results suggest that down-samplingshould be considered more often when solving test-based problems, regardless ofthe selection scheme in use.</description><author>Ryan Boldi, Ashley Bao, Martin Briesch, Thomas Helmuth, Dominik Sobania, Lee Spector, Alexander Lalejini</author><pubDate>Thu, 01 Aug 2024 15:13:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.07089v2</guid></item><item><title>Graph neural network-based surrogate modelling for real-time hydraulic prediction of urban drainage networks</title><link>http://arxiv.org/abs/2404.10324v2</link><description>Physics-based models are computationally time-consuming and infeasible forreal-time scenarios of urban drainage networks, and a surrogate model is neededto accelerate the online predictive modelling. Fully-connected neural networks(NNs) are potential surrogate models, but may suffer from low interpretabilityand efficiency in fitting complex targets. Owing to the state-of-the-artmodelling power of graph neural networks (GNNs) and their match with urbandrainage networks in the graph structure, this work proposes a GNN-basedsurrogate of the flow routing model for the hydraulic prediction problem ofdrainage networks, which regards recent hydraulic states as initial conditions,and future runoff and control policy as boundary conditions. To incorporatehydraulic constraints and physical relationships into drainage modelling,physics-guided mechanisms are designed on top of the surrogate model torestrict the prediction variables with flow balance and flooding occurrenceconstraints. According to case results in a stormwater network, the GNN-basedmodel is more cost-effective with better hydraulic prediction accuracy than theNN-based model after equal training epochs, and the designed mechanisms furtherlimit prediction errors with interpretable domain knowledge. As the modelstructure adheres to the flow routing mechanisms and hydraulic constraints inurban drainage networks, it provides an interpretable and effective solutionfor data-driven surrogate modelling. Simultaneously, the surrogate modelaccelerates the predictive modelling of urban drainage networks for real-timeuse compared with the physics-based model.</description><author>Zhiyu Zhang, Chenkaixiang Lu, Wenchong Tian, Zhenliang Liao, Zhiguo Yuan</author><pubDate>Thu, 01 Aug 2024 15:10:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10324v2</guid></item><item><title>SynesLM: A Unified Approach for Audio-visual Speech Recognition and Translation via Language Model and Synthetic Data</title><link>http://arxiv.org/abs/2408.00624v1</link><description>In this work, we present SynesLM, an unified model which can perform threemultimodal language understanding tasks: audio-visual automatic speechrecognition(AV-ASR) and visual-aided speech/machine translation(VST/VMT).Unlike previous research that focused on lip motion as visual cues for speechsignals, our work explores more general visual information within entireframes, such as objects and actions. Additionally, we use synthetic image datato enhance the correlation between image and speech data. We benchmark SynesLMagainst the How2 dataset, demonstrating performance on par withstate-of-the-art (SOTA) models dedicated to AV-ASR while maintaining ourmultitasking framework. Remarkably, for zero-shot AV-ASR, SynesLM achieved SOTAperformance by lowering the Word Error Rate (WER) from 43.4% to 39.4% on theVisSpeech Dataset. Furthermore, our results in VST and VMT outperform theprevious results, improving the BLEU score to 43.5 from 37.2 for VST, and to54.8 from 54.4 for VMT.</description><author>Yichen Lu, Jiaqi Song, Xuankai Chang, Hengwei Bian, Soumi Maiti, Shinji Watanabe</author><pubDate>Thu, 01 Aug 2024 15:09:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00624v1</guid></item></channel></rss>