<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 30 Oct 2024 13:00:07 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Local Policies Enable Zero-shot Long-horizon Manipulation</title><link>http://arxiv.org/abs/2410.22332v1</link><description>Sim2real for robotic manipulation is difficult due to the challenges ofsimulating complex contacts and generating realistic task distributions. Totackle the latter problem, we introduce ManipGen, which leverages a new classof policies for sim2real transfer: local policies. Locality enables a varietyof appealing properties including invariances to absolute robot and objectpose, skill ordering, and global scene configuration. We combine these policieswith foundation models for vision, language and motion planning and demonstrateSOTA zero-shot performance of our method to Robosuite benchmark tasks insimulation (97%). We transfer our local policies from simulation to reality andobserve they can solve unseen long-horizon manipulation tasks with up to 8stages with significant pose, object and scene configuration variation.ManipGen outperforms SOTA approaches such as SayCan, OpenVLA, LLMTrajGen andVoxPoser across 50 real-world manipulation tasks by 36%, 76%, 62% and 60%respectively. Video results at https://mihdalal.github.io/manipgen/</description><author>Murtaza Dalal, Min Liu, Walter Talbott, Chen Chen, Deepak Pathak, Jian Zhang, Ruslan Salakhutdinov</author><pubDate>Tue, 29 Oct 2024 17:59:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22332v1</guid></item><item><title>Task Vectors are Cross-Modal</title><link>http://arxiv.org/abs/2410.22330v1</link><description>We investigate the internal representations of vision-and-language models(VLMs) and how they encode task representations. We consider tasks specifiedthrough examples or instructions, using either text or image inputs.Surprisingly, we find that conceptually similar tasks are mapped to similartask vector representations, regardless of how they are specified. Our findingssuggest that to output answers, tokens in VLMs undergo three distinct phases:input, task, and answer, a process which is consistent across differentmodalities and specifications. The task vectors we identify in VLMs are generalenough to be derived in one modality (e.g., text) and transferred to another(e.g., image). Additionally, we find that ensembling exemplar and instructionbased task vectors produce better task representations. Taken together, theseinsights shed light on the underlying mechanisms of VLMs, particularly theirability to represent tasks in a shared manner across different modalities andtask specifications. Project page:https://task-vectors-are-cross-modal.github.io.</description><author>Grace Luo, Trevor Darrell, Amir Bar</author><pubDate>Tue, 29 Oct 2024 17:59:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22330v1</guid></item><item><title>Robots Pre-train Robots: Manipulation-Centric Robotic Representation from Large-Scale Robot Dataset</title><link>http://arxiv.org/abs/2410.22325v1</link><description>The pre-training of visual representations has enhanced the efficiency ofrobot learning. Due to the lack of large-scale in-domain robotic datasets,prior works utilize in-the-wild human videos to pre-train robotic visualrepresentation. Despite their promising results, representations from humanvideos are inevitably subject to distribution shifts and lack the dynamicsinformation crucial for task completion. We first evaluate various pre-trainedrepresentations in terms of their correlation to the downstream roboticmanipulation tasks (i.e., manipulation centricity). Interestingly, we find thatthe "manipulation centricity" is a strong indicator of success rates whenapplied to downstream tasks. Drawing from these findings, we proposeManipulation Centric Representation (MCR), a foundation representation learningframework capturing both visual features and the dynamics information such asactions and proprioceptions of manipulation tasks to improve manipulationcentricity. Specifically, we pre-train a visual encoder on the DROID roboticdataset and leverage motion-relevant data such as robot proprioceptive statesand actions. We introduce a novel contrastive loss that aligns visualobservations with the robot's proprioceptive state-action dynamics, combinedwith a behavior cloning (BC)-like actor loss to predict actions duringpre-training, along with a time contrastive loss. Empirical results across 4simulation domains with 20 tasks verify that MCR outperforms the strongestbaseline method by 14.8%. Moreover, MCR boosts the performance ofdata-efficient learning with a UR5e arm on 3 real-world tasks by 76.9%. Projectwebsite: https://robots-pretrain-robots.github.io/.</description><author>Guangqi Jiang, Yifei Sun, Tao Huang, Huanyu Li, Yongyuan Liang, Huazhe Xu</author><pubDate>Tue, 29 Oct 2024 17:58:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22325v1</guid></item><item><title>Optimizing Posterior Samples for Bayesian Optimization via Rootfinding</title><link>http://arxiv.org/abs/2410.22322v1</link><description>Bayesian optimization devolves the global optimization of a costly objectivefunction to the global optimization of a sequence of acquisition functions.This inner-loop optimization can be catastrophically difficult if it involvesposterior samples, especially in higher dimensions. We introduce an efficientglobal optimization strategy for posterior samples based on global rootfinding.It provides gradient-based optimizers with judiciously selected startingpoints, designed to combine exploitation and exploration. The algorithm scalespractically linearly to high dimensions. For posterior sample-based acquisitionfunctions such as Gaussian process Thompson sampling (GP-TS) and variants ofentropy search, we demonstrate remarkable improvement in both inner- andouter-loop optimization, surprisingly outperforming alternatives like EI andGP-UCB in most cases. We also propose a sample-average formulation of GP-TS,which has a parameter to explicitly control exploitation and can be computed atthe cost of one posterior sample. Our implementation is available athttps://github.com/UQUH/TSRoots .</description><author>Taiwo A. Adebiyi, Bach Do, Ruda Zhang</author><pubDate>Tue, 29 Oct 2024 17:57:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22322v1</guid></item><item><title>Online Detecting LLM-Generated Texts via Sequential Hypothesis Testing by Betting</title><link>http://arxiv.org/abs/2410.22318v1</link><description>Developing algorithms to differentiate between machine-generated texts andhuman-written texts has garnered substantial attention in recent years.Existing methods in this direction typically concern an offline setting where adataset containing a mix of real and machine-generated texts is given upfront,and the task is to determine whether each sample in the dataset is from a largelanguage model (LLM) or a human. However, in many practical scenarios, sourcessuch as news websites, social media accounts, or on other forums publishcontent in a streaming fashion. Therefore, in this online scenario, how toquickly and accurately determine whether the source is an LLM with strongstatistical guarantees is crucial for these media or platforms to functioneffectively and prevent the spread of misinformation and other potential misuseof LLMs. To tackle the problem of online detection, we develop an algorithmbased on the techniques of sequential hypothesis testing by betting that notonly builds upon and complements existing offline detection techniques but alsoenjoys statistical guarantees, which include a controlled false positive rateand the expected time to correctly identify a source as an LLM. Experimentswere conducted to demonstrate the effectiveness of our method.</description><author>Can Chen, Jun-Kun Wang</author><pubDate>Tue, 29 Oct 2024 17:55:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22318v1</guid></item><item><title>Multi-Class Textual-Inversion Secretly Yields a Semantic-Agnostic Classifier</title><link>http://arxiv.org/abs/2410.22317v1</link><description>With the advent of large pre-trained vision-language models such as CLIP,prompt learning methods aim to enhance the transferability of the CLIP model.They learn the prompt given few samples from the downstream task given thespecific class names as prior knowledge, which we term as semantic-awareclassification. However, in many realistic scenarios, we only have access tofew samples and knowledge of the class names (e.g., when considering instancesof classes). This challenging scenario represents the semantic-agnosticdiscriminative case. Text-to-Image (T2I) personalization methods aim to adaptT2I models to unseen concepts by learning new tokens and endowing these tokenswith the capability of generating the learned concepts. These methods do notrequire knowledge of class names as a semantic-aware prior. Therefore, in thispaper, we first explore Textual Inversion and reveal that the new concepttokens possess both generation and classification capabilities by regardingeach category as a single concept. However, learning classifiers fromsingle-concept textual inversion is limited since the learned tokens aresuboptimal for the discriminative tasks. To mitigate this issue, we proposeMulti-Class textual inversion, which includes a discriminative regularizationterm for the token updating process. Using this technique, our method MC-TIachieves stronger Semantic-Agnostic Classification while preserving thegeneration capability of these modifier tokens given only few samples percategory. In the experiments, we extensively evaluate MC-TI on 12 datasetscovering various scenarios, which demonstrates that MC-TI achieves superiorresults in terms of both classification and generation outcomes.</description><author>Kai Wang, Fei Yang, Bogdan Raducanu, Joost van de Weijer</author><pubDate>Tue, 29 Oct 2024 17:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22317v1</guid></item><item><title>Understanding Synthetic Context Extension via Retrieval Heads</title><link>http://arxiv.org/abs/2410.22316v1</link><description>Long-context LLMs are increasingly in demand for applications such asretrieval-augmented generation. To defray the cost of pretraining LLMs overlong contexts, recent work takes an approach of synthetic context extension:fine-tuning LLMs with synthetically generated long-context data in apost-training stage. However, it remains unclear how and why this syntheticcontext extension imparts abilities for downstream long-context tasks. In thispaper, we investigate fine-tuning on synthetic data for three long-contexttasks that require retrieval and reasoning. We vary the realism of "needle"concepts to be retrieved and diversity of the surrounding "haystack" context,from using LLMs to construct synthetic documents to using templated relationsand creating symbolic datasets. We find that models trained on synthetic datafall short of the real data, but surprisingly, the mismatch can be interpretedand even predicted in terms of a special set of attention heads that areresponsible for retrieval over long context: retrieval heads (Wu et al., 2024).The retrieval heads learned on synthetic data are mostly subsets of theretrieval heads learned on real data, and there is a strong correlation betweenthe recall of heads learned and the downstream performance of a model.Furthermore, with attention knockout and activation patching, wemechanistically show that retrieval heads are necessary and explain modelperformance, although they are not totally sufficient. Our results shed lighton how to interpret synthetic data fine-tuning performance and how to approachcreating better data for learning real-world capabilities over long contexts.</description><author>Xinyu Zhao, Fangcong Yin, Greg Durrett</author><pubDate>Tue, 29 Oct 2024 17:55:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22316v1</guid></item><item><title>Natural Language Inference Improves Compositionality in Vision-Language Models</title><link>http://arxiv.org/abs/2410.22315v1</link><description>Compositional reasoning in Vision-Language Models (VLMs) remains challengingas these models often struggle to relate objects, attributes, and spatialrelationships. Recent methods aim to address these limitations by relying onthe semantics of the textual description, using Large Language Models (LLMs) tobreak them down into subsets of questions and answers. However, these methodsprimarily operate on the surface level, failing to incorporate deeper lexicalunderstanding while introducing incorrect assumptions generated by the LLM. Inresponse to these issues, we present Caption Expansion with Contradictions andEntailments (CECE), a principled approach that leverages Natural LanguageInference (NLI) to generate entailments and contradictions from a givenpremise. CECE produces lexically diverse sentences while maintaining their coremeaning. Through extensive experiments, we show that CECE enhancesinterpretability and reduces overreliance on biased or superficial features. Bybalancing CECE along the original premise, we achieve significant improvementsover previous methods without requiring additional fine-tuning, producingstate-of-the-art results on benchmarks that score agreement with humanjudgments for image-text alignment, and achieving an increase in performance onWinoground of +19.2% (group score) and +12.9% on EqBen (group score) over thebest prior work (finetuned with targeted data).</description><author>Paola Cascante-Bonilla, Yu Hou, Yang Trista Cao, Hal Daumé III, Rachel Rudinger</author><pubDate>Tue, 29 Oct 2024 17:54:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22315v1</guid></item><item><title>An Efficient Approach to Generate Safe Drivable Space by LiDAR-Camera-HDmap Fusion</title><link>http://arxiv.org/abs/2410.22314v1</link><description>In this paper, we propose an accurate and robust perception module forAutonomous Vehicles (AVs) for drivable space extraction. Perception is crucialin autonomous driving, where many deep learning-based methods, while accurateon benchmark datasets, fail to generalize effectively, especially in diverseand unpredictable environments. Our work introduces a robust easy-to-generalizeperception module that leverages LiDAR, camera, and HD map data fusion todeliver a safe and reliable drivable space in all weather conditions. Wepresent an adaptive ground removal and curb detection method integrated with HDmap data for enhanced obstacle detection reliability. Additionally, we proposean adaptive DBSCAN clustering algorithm optimized for precipitation noise, anda cost-effective LiDAR-camera frustum association that is resilient tocalibration discrepancies. Our comprehensive drivable space representationincorporates all perception data, ensuring compatibility with vehicledimensions and road regulations. This approach not only improves generalizationand efficiency, but also significantly enhances safety in autonomous vehicleoperations. Our approach is tested on a real dataset and its reliability isverified during the daily (including harsh snowy weather) operation of ourautonomous shuttle, WATonoBus</description><author>Minghao Ning, Ahmad Reza Alghooneh, Chen Sun, Ruihe Zhang, Pouya Panahandeh, Steven Tuer, Ehsan Hashemi, Amir Khajepour</author><pubDate>Tue, 29 Oct 2024 17:54:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22314v1</guid></item><item><title>Senna: Bridging Large Vision-Language Models and End-to-End Autonomous Driving</title><link>http://arxiv.org/abs/2410.22313v1</link><description>End-to-end autonomous driving demonstrates strong planning capabilities withlarge-scale data but still struggles in complex, rare scenarios due to limitedcommonsense. In contrast, Large Vision-Language Models (LVLMs) excel in sceneunderstanding and reasoning. The path forward lies in merging the strengths ofboth approaches. Previous methods using LVLMs to predict trajectories orcontrol signals yield suboptimal results, as LVLMs are not well-suited forprecise numerical predictions. This paper presents Senna, an autonomous drivingsystem combining an LVLM (Senna-VLM) with an end-to-end model (Senna-E2E).Senna decouples high-level planning from low-level trajectory prediction.Senna-VLM generates planning decisions in natural language, while Senna-E2Epredicts precise trajectories. Senna-VLM utilizes a multi-image encodingapproach and multi-view prompts for efficient scene understanding. Besides, weintroduce planning-oriented QAs alongside a three-stage training strategy,which enhances Senna-VLM's planning performance while preserving commonsense.Extensive experiments on two datasets show that Senna achieves state-of-the-artplanning performance. Notably, with pre-training on a large-scale datasetDriveX and fine-tuning on nuScenes, Senna significantly reduces averageplanning error by 27.12% and collision rate by 33.33% over model withoutpre-training. We believe Senna's cross-scenario generalization andtransferability are essential for achieving fully autonomous driving. Code andmodels will be released at https://github.com/hustvl/Senna.</description><author>Bo Jiang, Shaoyu Chen, Bencheng Liao, Xingyu Zhang, Wei Yin, Qian Zhang, Chang Huang, Wenyu Liu, Xinggang Wang</author><pubDate>Tue, 29 Oct 2024 17:53:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22313v1</guid></item><item><title>Effective Guidance for Model Attention with Simple Yes-no Annotations</title><link>http://arxiv.org/abs/2410.22312v1</link><description>Modern deep learning models often make predictions by focusing on irrelevantareas, leading to biased performance and limited generalization. Existingmethods aimed at rectifying model attention require explicit labels forirrelevant areas or complex pixel-wise ground truth attention maps. We presentCRAYON (Correcting Reasoning with Annotations of Yes Or No), offeringeffective, scalable, and practical solutions to rectify model attention usingsimple yes-no annotations. CRAYON empowers classical and modern modelinterpretation techniques to identify and guide model reasoning:CRAYON-ATTENTION directs classic interpretations based on saliency maps tofocus on relevant image regions, while CRAYON-PRUNING removes irrelevantneurons identified by modern concept-based methods to mitigate their influence.Through extensive experiments with both quantitative and human evaluation, weshowcase CRAYON's effectiveness, scalability, and practicality in refiningmodel attention. CRAYON achieves state-of-the-art performance, outperforming 12methods across 3 benchmark datasets, surpassing approaches that require morecomplex annotations.</description><author>Seongmin Lee, Ali Payani, Duen Horng, Chau</author><pubDate>Tue, 29 Oct 2024 17:53:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22312v1</guid></item><item><title>Convex Formulations for Training Two-Layer ReLU Neural Networks</title><link>http://arxiv.org/abs/2410.22311v1</link><description>Solving non-convex, NP-hard optimization problems is crucial for trainingmachine learning models, including neural networks. However, non-convexityoften leads to black-box machine learning models with unclear inner workings.While convex formulations have been used for verifying neural networkrobustness, their application to training neural networks remains lessexplored. In response to this challenge, we reformulate the problem of traininginfinite-width two-layer ReLU networks as a convex completely positive programin a finite-dimensional (lifted) space. Despite the convexity, solving thisproblem remains NP-hard due to the complete positivity constraint. To overcomethis challenge, we introduce a semidefinite relaxation that can be solved inpolynomial time. We then experimentally evaluate the tightness of thisrelaxation, demonstrating its competitive performance in test accuracy across arange of classification tasks.</description><author>Karthik Prakhya, Tolga Birdal, Alp Yurtsever</author><pubDate>Tue, 29 Oct 2024 17:53:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22311v1</guid></item><item><title>SVIP: Towards Verifiable Inference of Open-source Large Language Models</title><link>http://arxiv.org/abs/2410.22307v1</link><description>Open-source Large Language Models (LLMs) have recently demonstratedremarkable capabilities in natural language understanding and generation,leading to widespread adoption across various domains. However, theirincreasing model sizes render local deployment impractical for individualusers, pushing many to rely on computing service providers for inferencethrough a blackbox API. This reliance introduces a new risk: a computingprovider may stealthily substitute the requested LLM with a smaller, lesscapable model without consent from users, thereby delivering inferior outputswhile benefiting from cost savings. In this paper, we formalize the problem ofverifiable inference for LLMs. Existing verifiable computing solutions based oncryptographic or game-theoretic techniques are either computationallyuneconomical or rest on strong assumptions. We introduce SVIP, a secret-basedverifiable LLM inference protocol that leverages intermediate outputs from LLMas unique model identifiers. By training a proxy task on these outputs andrequiring the computing provider to return both the generated text and theprocessed intermediate outputs, users can reliably verify whether the computingprovider is acting honestly. In addition, the integration of a secret mechanismfurther enhances the security of our protocol. We thoroughly analyze ourprotocol under multiple strong and adaptive adversarial scenarios. Ourextensive experiments demonstrate that SVIP is accurate, generalizable,computationally efficient, and resistant to various attacks. Notably, SVIPachieves false negative rates below 5% and false positive rates below 3%, whilerequiring less than 0.01 seconds per query for verification.</description><author>Yifan Sun, Yuhang Li, Yue Zhang, Yuchen Jin, Huan Zhang</author><pubDate>Tue, 29 Oct 2024 17:52:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22307v1</guid></item><item><title>Multi-Object 3D Grounding with Dynamic Modules and Language-Informed Spatial Attention</title><link>http://arxiv.org/abs/2410.22306v1</link><description>Multi-object 3D Grounding involves locating 3D boxes based on a given queryphrase from a point cloud. It is a challenging and significant task withnumerous applications in visual understanding, human-computer interaction, androbotics. To tackle this challenge, we introduce D-LISA, a two-stage approachincorporating three innovations. First, a dynamic vision module that enables avariable and learnable number of box proposals. Second, a dynamic camerapositioning that extracts features for each proposal. Third, alanguage-informed spatial attention module that better reasons over theproposals to output the final prediction. Empirically, experiments show thatour method outperforms the state-of-the-art methods on multi-object 3Dgrounding by 12.8% (absolute) and is competitive in single-object 3D grounding.</description><author>Haomeng Zhang, Chiao-An Yang, Raymond A. Yeh</author><pubDate>Tue, 29 Oct 2024 17:52:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22306v1</guid></item><item><title>Fearless Stochasticity in Expectation Propagation</title><link>http://arxiv.org/abs/2406.01801v2</link><description>Expectation propagation (EP) is a family of algorithms for performingapproximate inference in probabilistic models. The updates of EP involve theevaluation of moments -- expectations of certain functions -- which can beestimated from Monte Carlo (MC) samples. However, the updates are not robust toMC noise when performed naively, and various prior works have attempted toaddress this issue in different ways. In this work, we provide a novelperspective on the moment-matching updates of EP; namely, that they performnatural-gradient-based optimisation of a variational objective. We use thisinsight to motivate two new EP variants, with updates that are particularlywell-suited to MC estimation. They remain stable and are most sample-efficientwhen estimated with just a single sample. These new variants combine thebenefits of their predecessors and address key weaknesses. In particular, theyare easier to tune, offer an improved speed-accuracy trade-off, and do not relyon the use of debiasing estimators. We demonstrate their efficacy on a varietyof probabilistic inference tasks.</description><author>Jonathan So, Richard E. Turner</author><pubDate>Tue, 29 Oct 2024 17:50:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01801v2</guid></item><item><title>Flow-DPO: Improving LLM Mathematical Reasoning through Online Multi-Agent Learning</title><link>http://arxiv.org/abs/2410.22304v1</link><description>Mathematical reasoning is a crucial capability for Large Language Models(LLMs), yet generating detailed and accurate reasoning traces remains asignificant challenge. This paper introduces a novel approach to producehigh-quality reasoning traces for LLM fine-tuning using online learning\textbf{Flows}. Our method employs an incremental output production Flow, wherecomponent LLMs collaboratively construct solutions through iterativecommunication. We train the Flow using online Direct Preference Optimization(DPO) learning with rollouts, generating DPO pairs for each training exampleand updating models in real-time. We directly compare the quality of reasoningtraces generated by our method with those produced through direct modelinference, demonstrating the effectiveness of our approach in improving LLMperformance in mathematical reasoning tasks.</description><author>Yihe Deng, Paul Mineiro</author><pubDate>Tue, 29 Oct 2024 17:50:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22304v1</guid></item><item><title>$\mathsf{OPA}$: One-shot Private Aggregation with Single Client Interaction and its Applications to Federated Learning</title><link>http://arxiv.org/abs/2410.22303v1</link><description>Our work aims to minimize interaction in secure computation due to the highcost and challenges associated with communication rounds, particularly inscenarios with many clients. In this work, we revisit the problem of secureaggregation in the single-server setting where a single evaluation server cansecurely aggregate client-held individual inputs. Our key contribution is theintroduction of One-shot Private Aggregation ($\mathsf{OPA}$) where clientsspeak only once (or even choose not to speak) per aggregation evaluation. Sinceeach client communicates only once per aggregation, this simplifies managingdropouts and dynamic participation, contrasting with multi-round protocols andaligning with plaintext secure aggregation, where clients interact only once.We construct $\mathsf{OPA}$ based on LWR, LWE, class groups, DCR anddemonstrate applications to privacy-preserving Federated Learning (FL) whereclients \emph{speak once}. This is a sharp departure from prior multi-round FLprotocols whose study was initiated by Bonawitz et al. (CCS, 2017). Moreover,unlike the YOSO (You Only Speak Once) model for general secure computation,$\mathsf{OPA}$ eliminates complex committee selection protocols to achieveadaptive security. Beyond asymptotic improvements, $\mathsf{OPA}$ is practical,outperforming state-of-the-art solutions. We benchmark logistic regressionclassifiers for two datasets, while also building an MLP classifier to train onMNIST, CIFAR-10, and CIFAR-100 datasets. We build two flavors of $\caps$ (1)from (threshold) key homomorphic PRF and (2) from seed homomorphic PRG andsecret sharing.</description><author>Harish Karthikeyan, Antigoni Polychroniadou</author><pubDate>Tue, 29 Oct 2024 17:50:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22303v1</guid></item><item><title>EquiBot: SIM(3)-Equivariant Diffusion Policy for Generalizable and Data Efficient Learning</title><link>http://arxiv.org/abs/2407.01479v2</link><description>Building effective imitation learning methods that enable robots to learnfrom limited data and still generalize across diverse real-world environmentsis a long-standing problem in robot learning. We propose Equibot, a robust,data-efficient, and generalizable approach for robot manipulation tasklearning. Our approach combines SIM(3)-equivariant neural network architectureswith diffusion models. This ensures that our learned policies are invariant tochanges in scale, rotation, and translation, enhancing their applicability tounseen environments while retaining the benefits of diffusion-based policylearning such as multi-modality and robustness. We show on a suite of 6simulation tasks that our proposed method reduces the data requirements andimproves generalization to novel scenarios. In the real world, with 10variations of 6 mobile manipulation tasks, we show that our method can easilygeneralize to novel objects and scenes after learning from just 5 minutes ofhuman demonstrations in each task.</description><author>Jingyun Yang, Zi-ang Cao, Congyue Deng, Rika Antonova, Shuran Song, Jeannette Bohg</author><pubDate>Tue, 29 Oct 2024 17:49:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01479v2</guid></item><item><title>Emotion-Guided Image to Music Generation</title><link>http://arxiv.org/abs/2410.22299v1</link><description>Generating music from images can enhance various applications, includingbackground music for photo slideshows, social media experiences, and videocreation. This paper presents an emotion-guided image-to-music generationframework that leverages the Valence-Arousal (VA) emotional space to producemusic that aligns with the emotional tone of a given image. Unlike previousmodels that rely on contrastive learning for emotional consistency, theproposed approach directly integrates a VA loss function to enable accurateemotional alignment. The model employs a CNN-Transformer architecture,featuring pre-trained CNN image feature extractors and three Transformerencoders to capture complex, high-level emotional features from MIDI music.Three Transformer decoders refine these features to generate musically andemotionally consistent MIDI sequences. Experimental results on a newly curatedemotionally paired image-MIDI dataset demonstrate the proposed model's superiorperformance across metrics such as Polyphony Rate, Pitch Entropy, GrooveConsistency, and loss convergence.</description><author>Souraja Kundu, Saket Singh, Yuji Iwahori</author><pubDate>Tue, 29 Oct 2024 17:47:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22299v1</guid></item><item><title>Shuffling Gradient-Based Methods for Nonconvex-Concave Minimax Optimization</title><link>http://arxiv.org/abs/2410.22297v1</link><description>This paper aims at developing novel shuffling gradient-based methods fortackling two classes of minimax problems: nonconvex-linear andnonconvex-strongly concave settings. The first algorithm addresses thenonconvex-linear minimax model and achieves the state-of-the-art oraclecomplexity typically observed in nonconvex optimization. It also employs a newshuffling estimator for the "hyper-gradient", departing from standard shufflingtechniques in optimization. The second method consists of two variants:semi-shuffling and full-shuffling schemes. These variants tackle thenonconvex-strongly concave minimax setting. We establish their oraclecomplexity bounds under standard assumptions, which, to our best knowledge, arethe best-known for this specific setting. Numerical examples demonstrate theperformance of our algorithms and compare them with two other methods. Ourresults show that the new methods achieve comparable performance with SGD,supporting the potential of incorporating shuffling strategies into minimaxalgorithms.</description><author>Quoc Tran-Dinh, Trang H. Tran, Lam M. Nguyen</author><pubDate>Tue, 29 Oct 2024 17:47:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22297v1</guid></item><item><title>LLMs are Highly-Constrained Biophysical Sequence Optimizers</title><link>http://arxiv.org/abs/2410.22296v1</link><description>Large language models (LLMs) have recently shown significant potential invarious biological tasks such as protein engineering and molecule design. Thesetasks typically involve black-box discrete sequence optimization, where thechallenge lies in generating sequences that are not only biologically feasiblebut also adhere to hard fine-grained constraints. However, LLMs often strugglewith such constraints, especially in biological contexts where verifyingcandidate solutions is costly and time-consuming. In this study, we explore thepossibility of employing LLMs as highly-constrained bilevel optimizers througha methodology we refer to as Language Model Optimization with MarginExpectation (LLOME). This approach combines both offline and onlineoptimization, utilizing limited oracle evaluations to iteratively enhance thesequences generated by the LLM. We additionally propose a novel trainingobjective -- Margin-Aligned Expectation (MargE) -- that trains the LLM tosmoothly interpolate between the reward and reference distributions. Lastly, weintroduce a synthetic test suite that bears strong geometric similarity to realbiophysical problems and enables rapid evaluation of LLM optimizers withouttime-consuming lab validation. Our findings reveal that, in comparison togenetic algorithm baselines, LLMs achieve significantly lower regret solutionswhile requiring fewer test function evaluations. However, we also observe thatLLMs exhibit moderate miscalibration, are susceptible to generator collapse,and have difficulty finding the optimal solution when no explicit ground truthrewards are available.</description><author>Angelica Chen, Samuel D. Stanton, Robert G. Alberstein, Andrew M. Watkins, Richard Bonneau, Vladimir Gligorijevi, Kyunghyun Cho, Nathan C. Frey</author><pubDate>Tue, 29 Oct 2024 17:45:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22296v1</guid></item><item><title>Empirical Design in Reinforcement Learning</title><link>http://arxiv.org/abs/2304.01315v2</link><description>Empirical design in reinforcement learning is no small task. Running goodexperiments requires attention to detail and at times significant computationalresources. While compute resources available per dollar have continued to growrapidly, so have the scale of typical experiments in reinforcement learning. Itis now common to benchmark agents with millions of parameters against dozens oftasks, each using the equivalent of 30 days of experience. The scale of theseexperiments often conflict with the need for proper statistical evidence,especially when comparing algorithms. Recent studies have highlighted howpopular algorithms are sensitive to hyper-parameter settings and implementationdetails, and that common empirical practice leads to weak statistical evidence(Machado et al., 2018; Henderson et al., 2018). Here we take this one stepfurther. This manuscript represents both a call to action, and a comprehensiveresource for how to do good experiments in reinforcement learning. Inparticular, we cover: the statistical assumptions underlying common performancemeasures, how to properly characterize performance variation and stability,hypothesis testing, special considerations for comparing multiple agents,baseline and illustrative example construction, and how to deal withhyper-parameters and experimenter bias. Throughout we highlight common mistakesfound in the literature and the statistical consequences of those in exampleexperiments. The objective of this document is to provide answers on how we canuse our unprecedented compute to do good science in reinforcement learning, aswell as stay alert to potential pitfalls in our empirical design.</description><author>Andrew Patterson, Samuel Neumann, Martha White, Adam White</author><pubDate>Tue, 29 Oct 2024 17:44:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.01315v2</guid></item><item><title>A Full-duplex Speech Dialogue Scheme Based On Large Language Models</title><link>http://arxiv.org/abs/2405.19487v2</link><description>We present a generative dialogue system capable of operating in a full-duplexmanner, allowing for seamless interaction. It is based on a large languagemodel (LLM) carefully aligned to be aware of a perception module, a motorfunction module, and the concept of a simple finite state machine (calledneural FSM) with two states. The perception and motor function modules operatein tandem, allowing the system to speak and listen to the user simultaneously.The LLM generates textual tokens for inquiry responses and makes autonomousdecisions to start responding to, wait for, or interrupt the user by emittingcontrol tokens to the neural FSM. All these tasks of the LLM are carried out asnext token prediction on a serialized view of the dialogue in real-time. Inautomatic quality evaluations simulating real-life interaction, the proposedsystem reduces the average conversation response latency by more than threefoldcompared with LLM-based half-duplex dialogue systems while responding withinless than 500 milliseconds in more than 50% of evaluated interactions. Runningan LLM with only 8 billion parameters, our system exhibits an 8% higherinterruption precision rate than the best available commercial LLM forvoice-based dialogue.</description><author>Peng Wang, Songshuo Lu, Yaohua Tang, Sijie Yan, Wei Xia, Yuanjun Xiong</author><pubDate>Tue, 29 Oct 2024 17:44:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19487v2</guid></item><item><title>Batch, match, and patch: low-rank approximations for score-based variational inference</title><link>http://arxiv.org/abs/2410.22292v1</link><description>Black-box variational inference (BBVI) scales poorly to high dimensionalproblems when it is used to estimate a multivariate Gaussian approximation witha full covariance matrix. In this paper, we extend the batch-and-match (BaM)framework for score-based BBVI to problems where it is prohibitively expensiveto store such covariance matrices, let alone to estimate them. Unlike classicalalgorithms for BBVI, which use gradient descent to minimize the reverseKullback-Leibler divergence, BaM uses more specialized updates to match thescores of the target density and its Gaussian approximation. We extend theupdates for BaM by integrating them with a more compact parameterization offull covariance matrices. In particular, borrowing ideas from factor analysis,we add an extra step to each iteration of BaM -- a patch -- that projects eachnewly updated covariance matrix into a more efficiently parameterized family ofdiagonal plus low rank matrices. We evaluate this approach on a variety ofsynthetic target distributions and real-world problems in high-dimensionalinference.</description><author>Chirag Modi, Diana Cai, Lawrence K. Saul</author><pubDate>Tue, 29 Oct 2024 17:42:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22292v1</guid></item><item><title>Motion Graph Unleashed: A Novel Approach to Video Prediction</title><link>http://arxiv.org/abs/2410.22288v1</link><description>We introduce motion graph, a novel approach to the video prediction problem,which predicts future video frames from limited past data. The motion graphtransforms patches of video frames into interconnected graph nodes, tocomprehensively describe the spatial-temporal relationships among them. Thisrepresentation overcomes the limitations of existing motion representationssuch as image differences, optical flow, and motion matrix that either fallshort in capturing complex motion patterns or suffer from excessive memoryconsumption. We further present a video prediction pipeline empowered by motiongraph, exhibiting substantial performance improvements and cost reductions.Experiments on various datasets, including UCF Sports, KITTI and Cityscapes,highlight the strong representative ability of motion graph. Especially on UCFSports, our method matches and outperforms the SOTA methods with a significantreduction in model size by 78% and a substantial decrease in GPU memoryutilization by 47%.</description><author>Yiqi Zhong, Luming Liang, Bohan Tang, Ilya Zharkov, Ulrich Neumann</author><pubDate>Tue, 29 Oct 2024 17:39:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22288v1</guid></item><item><title>From melodic note sequences to pitches using word2vec</title><link>http://arxiv.org/abs/2410.22285v1</link><description>Applying the word2vec technique, commonly used in language modeling, tomelodies, where notes are treated as words in sentences, enables the capture ofpitch information. This study examines two datasets: 20 children's songs and anexcerpt from a Bach sonata. The semantic space for defining the embeddings isof very small dimension, specifically 2. Notes are predicted based on the 2, 3or 4 preceding notes that establish the context. A multivariate analysis of theresults shows that the semantic vectors representing the notes have a multiplecorrelation coefficient of approximately 0.80 with their pitches.</description><author>Daniel Defays</author><pubDate>Tue, 29 Oct 2024 17:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22285v1</guid></item><item><title>Uncertainty-aware multi-fidelity surrogate modeling with noisy data</title><link>http://arxiv.org/abs/2401.06447v2</link><description>Emulating high-accuracy computationally expensive models is crucial for tasksrequiring numerous model evaluations, such as uncertainty quantification andoptimization. When lower-fidelity models are available, they can be used toimprove the predictions of high-fidelity models. Multi-fidelity surrogatemodels combine information from sources of varying fidelities to construct anefficient surrogate model. However, in real-world applications, uncertainty ispresent in both high- and low-fidelity models due to measurement or numericalnoise, as well as lack of knowledge due to the limited experimental designbudget. This paper introduces a comprehensive framework for multi-fidelitysurrogate modeling that handles noise-contaminated data and is able to estimatethe underlying noise-free high-fidelity model. Our methodology quantitativelyincorporates the different types of uncertainty affecting the problem andemphasizes on delivering precise estimates of the uncertainty in itspredictions both with respect to the underlying high-fidelity model and unseennoise-contaminated high-fidelity observations, presented through confidence andprediction intervals, respectively. Additionally, the proposed framework offersa natural approach to combining physical experiments and computational modelsby treating noisy experimental data as high-fidelity sources and white-boxcomputational models as their low-fidelity counterparts. The effectiveness ofour methodology is showcased through synthetic examples and a wind turbineapplication.</description><author>Katerina Giannoukou, Stefano Marelli, Bruno Sudret</author><pubDate>Tue, 29 Oct 2024 17:38:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06447v2</guid></item><item><title>Embedding-based classifiers can detect prompt injection attacks</title><link>http://arxiv.org/abs/2410.22284v1</link><description>Large Language Models (LLMs) are seeing significant adoption in every type oforganization due to their exceptional generative capabilities. However, LLMsare found to be vulnerable to various adversarial attacks, particularly promptinjection attacks, which trick them into producing harmful or inappropriatecontent. Adversaries execute such attacks by crafting malicious prompts todeceive the LLMs. In this paper, we propose a novel approach based onembedding-based Machine Learning (ML) classifiers to protect LLM-basedapplications against this severe threat. We leverage three commonly usedembedding models to generate embeddings of malicious and benign prompts andutilize ML classifiers to predict whether an input prompt is malicious. Out ofseveral traditional ML methods, we achieve the best performance withclassifiers built using Random Forest and XGBoost. Our classifiers outperformstate-of-the-art prompt injection classifiers available in open-sourceimplementations, which use encoder-only neural networks.</description><author>Md. Ahsan Ayub, Subhabrata Majumdar</author><pubDate>Tue, 29 Oct 2024 17:36:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22284v1</guid></item><item><title>Search Wide, Focus Deep: Automated Fetal Brain Extraction with Sparse Training Data</title><link>http://arxiv.org/abs/2410.20532v2</link><description>Automated fetal brain extraction from full-uterus MRI is a challenging taskdue to variable head sizes, orientations, complex anatomy, and prevalentartifacts. While deep-learning (DL) models trained on synthetic images havebeen successful in adult brain extraction, adapting these networks for fetalMRI is difficult due to the sparsity of labeled data, leading to increasedfalse-positive predictions. To address this challenge, we propose a test-timestrategy that reduces false positives in networks trained on sparse, syntheticlabels. The approach uses a breadth-fine search (BFS) to identify a subvolumelikely to contain the fetal brain, followed by a deep-focused sliding window(DFS) search to refine the extraction, pooling predictions to minimize falsepositives. We train models at different window sizes using synthetic imagesderived from a small number of fetal brain label maps, augmented with randomgeometric shapes. Each model is trained on diverse head positions and scales,including cases with partial or no brain tissue. Our framework matchesstate-of-the-art brain extraction methods on clinical HASTE scans ofthird-trimester fetuses and exceeds them by up to 5\% in terms of Dice in thesecond trimester as well as EPI scans across both trimesters. Our resultsdemonstrate the utility of a sliding-window approach and combining predictionsfrom several models trained on synthetic images, for improving brain-extractionaccuracy by progressively refining regions of interest and minimizing the riskof missing brain mask slices or misidentifying other tissues as brain.</description><author>Javid Dadashkarimi, Valeria Pena Trujillo, Camilo Jaimes, Lilla Zöllei, Malte Hoffmann</author><pubDate>Tue, 29 Oct 2024 17:36:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20532v2</guid></item><item><title>Leveraging Recurrent Neural Networks for Predicting Motor Movements from Primate Motor Cortex Neural Recordings</title><link>http://arxiv.org/abs/2410.22283v1</link><description>This paper presents an efficient deep learning solution for decoding motormovements from neural recordings in non-human primates. An Autoencoder GatedRecurrent Unit (AEGRU) model was adopted as the model architecture for thistask. The autoencoder is only used during the training stage to achieve bettergeneralization. Together with the preprocessing techniques, our model achieved0.71 $R^2$ score, surpassing the baseline models in Neurobench and is rankedfirst for $R^2$ in the IEEE BioCAS 2024 Grand Challenge on Neural Decoding.Model pruning is also applied leading to a reduction of 41.4% of themultiply-accumulate (MAC) operations with little change in the $R^2$ scorecompared to the unpruned model.</description><author>Yuanxi Wang, Zuowen Wang, Shih-Chii Liu</author><pubDate>Tue, 29 Oct 2024 17:36:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22283v1</guid></item><item><title>Normalizing flows as approximations of optimal transport maps via linear-control neural ODEs</title><link>http://arxiv.org/abs/2311.01404v3</link><description>The term "Normalizing Flows" is related to the task of constructinginvertible transport maps between probability measures by means of deep neuralnetworks. In this paper, we consider the problem of recovering the$W_2$-optimal transport map $T$ between absolutely continuous measures$\mu,\nu\in\mathcal{P}(\mathbb{R}^n)$ as the flow of a linear-control neuralODE, where the control depends only on the time variable and takes values in afinite-dimensional space. We first show that, under suitable assumptions on$\mu,\nu$ and on the controlled vector fields, the optimal transport map iscontained in the $C^0_c$-closure of the flows generated by the system. Assumingthat discrete approximations $\mu_N,\nu_N$ of the original measures $\mu,\nu$are available, we use a discrete optimal coupling $\gamma_N$ to define anoptimal control problem. With a $\Gamma$-convergence argument, we prove thatits solutions correspond to flows that approximate the optimal transport map$T$. Finally, taking advantage of the Pontryagin Maximum Principle, we proposean iterative numerical scheme for the resolution of the optimal controlproblem, resulting in an algorithm for the practical computation of theapproximated optimal transport map.</description><author>Alessandro Scagliotti, Sara Farinelli</author><pubDate>Tue, 29 Oct 2024 17:35:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01404v3</guid></item><item><title>Context Embeddings for Efficient Answer Generation in RAG</title><link>http://arxiv.org/abs/2407.09252v3</link><description>Retrieval-Augmented Generation (RAG) allows overcoming the limited knowledgeof LLMs by extending the input with external information. As a consequence, thecontextual inputs to the model become much longer which slows down decodingtime directly translating to the time a user has to wait for an answer. Weaddress this challenge by presenting COCOM, an effective context compressionmethod, reducing long contexts to only a handful of Context Embeddings speedingup the generation time by a large margin. Our method allows for differentcompression rates trading off decoding time for answer quality. Compared toearlier methods, COCOM allows for handling multiple contexts more effectively,significantly reducing decoding time for long inputs. Our method demonstrates aspeed-up of up to 5.69 $\times$ while achieving higher performance compared toexisting efficient context compression methods.</description><author>David Rau, Shuai Wang, Hervé Déjean, Stéphane Clinchant</author><pubDate>Tue, 29 Oct 2024 17:34:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.09252v3</guid></item><item><title>Active Event Alignment for Monocular Distance Estimation</title><link>http://arxiv.org/abs/2410.22280v1</link><description>Event cameras provide a natural and data efficient representation of visualinformation, motivating novel computational strategies towards extractingvisual information. Inspired by the biological vision system, we propose abehavior driven approach for object-wise distance estimation from event cameradata. This behavior-driven method mimics how biological systems, like the humaneye, stabilize their view based on object distance: distant objects requireminimal compensatory rotation to stay in focus, while nearby objects demandgreater adjustments to maintain alignment. This adaptive strategy leveragesnatural stabilization behaviors to estimate relative distances effectively.Unlike traditional vision algorithms that estimate depth across the entireimage, our approach targets local depth estimation within a specific region ofinterest. By aligning events within a small region, we estimate the angularvelocity required to stabilize the image motion. We demonstrate that, undercertain assumptions, the compensatory rotational flow is inversely proportionalto the object's distance. The proposed approach achieves new state-of-the-artaccuracy in distance estimation - a performance gain of 16% on EVIMO2. EVIMO2event sequences comprise complex camera motion and substantial variance indepth of static real world scenes.</description><author>Nan Cai, Pia Bideau</author><pubDate>Tue, 29 Oct 2024 17:34:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22280v1</guid></item><item><title>Ripple: Accelerating LLM Inference on Smartphones with Correlation-Aware Neuron Management</title><link>http://arxiv.org/abs/2410.19274v2</link><description>Large Language Models (LLMs) have achieved remarkable success across variousdomains, yet deploying them on mobile devices remains an arduous challenge dueto their extensive computational and memory demands. While lightweight LLMshave been developed to fit mobile environments, they suffer from degraded modelaccuracy. In contrast, sparsity-based techniques minimize DRAM usage byselectively transferring only relevant neurons to DRAM while retaining the fullmodel in external storage, such as flash. However, such approaches arecritically limited by numerous I/O operations, particularly on smartphones withsevere IOPS constraints. In this paper, we propose Ripple, a novel approach that accelerates LLMinference on smartphones by optimizing neuron placement in flash memory. Rippleleverages the concept of Neuron Co-Activation, where neurons frequentlyactivated together are linked to facilitate continuous read access and optimizedata transfer efficiency. Our approach incorporates a two-stage solution: anoffline stage that reorganizes neuron placement based on co-activationpatterns, and an online stage that employs tailored data access and cachingstrategies to align well with hardware characteristics. Evaluations conductedon a variety of smartphones and LLMs demonstrate that Ripple achieves up to5.93x improvements in I/O latency compared to the state-of-the-art. As thefirst solution to optimize storage placement under sparsity, Ripple explores anew optimization space at the intersection of sparsity-driven algorithm andstorage-level system co-design in LLM inference.</description><author>Tuowei Wang, Ruwen Fan, Minxing Huang, Zixu Hao, Kun Li, Ting Cao, Youyou Lu, Yaoxue Zhang, Ju Ren</author><pubDate>Tue, 29 Oct 2024 17:33:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.19274v2</guid></item><item><title>It Is Not About What You Say, It Is About How You Say It: A Surprisingly Simple Approach for Improving Reading Comprehension</title><link>http://arxiv.org/abs/2406.16779v2</link><description>Natural language processing has seen rapid progress over the past decade. Dueto the speed of developments, some practices get established without properevaluation. Considering one such case and focusing on reading comprehension, weask our first research question: 1) How does the order of inputs -- i.e.,question and context -- affect model performance? Additionally, given recentadvancements in input emphasis, we ask a second research question: 2) Doesemphasizing either the question, the context, or both enhance performance?Experimenting with 9 large language models across 3 datasets, we find thatpresenting the context before the question improves model performance, with anaccuracy increase of up to $31\%$. Furthermore, emphasizing the context yieldssuperior results compared to question emphasis, and in general, emphasizingparts of the input is particularly effective for addressing questions thatmodels lack the parametric knowledge to answer. Experimenting with bothprompt-based and attention-based emphasis methods, we additionally find thatthe best method is surprisingly simple: it only requires concatenating a fewtokens to the input and results in an accuracy improvement of up to $36\%$,allowing smaller models to outperform their significantly larger counterparts.</description><author>Sagi Shaier, Lawrence E Hunter, Katharina von der Wense</author><pubDate>Tue, 29 Oct 2024 17:32:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.16779v2</guid></item><item><title>Compare without Despair: Reliable Preference Evaluation with Generation Separability</title><link>http://arxiv.org/abs/2407.01878v3</link><description>Human evaluation of generated language through pairwise preference judgmentsis pervasive. However, under common scenarios, such as when generations from amodel pair are very similar, or when stochastic decoding results in largevariations in generations, it results in inconsistent preference ratings. Weaddress these challenges by introducing a meta-evaluation measure,separability, which estimates how suitable a test instance is for pairwisepreference evaluation. For a candidate test instance, separability samplesmultiple generations from a pair of models, and measures how distinguishablethe two sets of generations are. Our experiments show that instances with highseparability values yield more consistent preference ratings from both human-and auto-raters. Further, the distribution of separability allows insights intowhich test benchmarks are more valuable for comparing models. Finally, weincorporate separability into ELO ratings, accounting for how suitable eachtest instance might be for reliably ranking LLMs. Overall, separability hasimplications for consistent, efficient and robust preference evaluation of LLMswith both human- and auto-raters.</description><author>Sayan Ghosh, Tejas Srinivasan, Swabha Swayamdipta</author><pubDate>Tue, 29 Oct 2024 17:29:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01878v3</guid></item><item><title>Agentless: Demystifying LLM-based Software Engineering Agents</title><link>http://arxiv.org/abs/2407.01489v2</link><description>Recent advancements in large language models (LLMs) have significantlyadvanced the automation of software development tasks, including codesynthesis, program repair, and test generation. More recently, researchers andindustry practitioners have developed various autonomous LLM agents to performend-to-end software development tasks. These agents are equipped with theability to use tools, run commands, observe feedback from the environment, andplan for future actions. However, the complexity of these agent-basedapproaches, together with the limited abilities of current LLMs, raises thefollowing question: Do we really have to employ complex autonomous softwareagents? To attempt to answer this question, we build Agentless -- an agentlessapproach to automatically solve software development problems. Compared to theverbose and complex setup of agent-based approaches, Agentless employs asimplistic three-phase process of localization, repair, and patch validation,without letting the LLM decide future actions or operate with complex tools.Our results on the popular SWE-bench Lite benchmark show that surprisingly thesimplistic Agentless is able to achieve both the highest performance (32.00%,96 correct fixes) and low cost ($0.70) compared with all existing open-sourcesoftware agents! Furthermore, we manually classified the problems in SWE-benchLite and found problems with exact ground truth patch orinsufficient/misleading issue descriptions. As such, we construct SWE-benchLite-S by excluding such problematic issues to perform more rigorous evaluationand comparison. Our work highlights the current overlooked potential of asimple, interpretable technique in autonomous software development. We hopeAgentless will help reset the baseline, starting point, and horizon forautonomous software agents, and inspire future work along this crucialdirection.</description><author>Chunqiu Steven Xia, Yinlin Deng, Soren Dunn, Lingming Zhang</author><pubDate>Tue, 29 Oct 2024 17:29:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.01489v2</guid></item><item><title>Leveraging Reverberation and Visual Depth Cues for Sound Event Localization and Detection with Distance Estimation</title><link>http://arxiv.org/abs/2410.22271v1</link><description>This report describes our systems submitted for the DCASE2024 Task 3challenge: Audio and Audiovisual Sound Event Localization and Detection withSource Distance Estimation (Track B). Our main model is based on theaudio-visual (AV) Conformer, which processes video and audio embeddingsextracted with ResNet50 and with an audio encoder pre-trained on SELD,respectively. This model outperformed the audio-visual baseline of thedevelopment set of the STARSS23 dataset by a wide margin, halving its DOAE andimproving the F1 by more than 3x. Our second system performs a temporalensemble from the outputs of the AV-Conformer. We then extended the model withfeatures for distance estimation, such as direct and reverberant signalcomponents extracted from the omnidirectional audio channel, and depth mapsextracted from the video frames. While the new system improved the RDE of ourprevious model by about 3 percentage points, it achieved a lower F1 score. Thismay be caused by sound classes that rarely appear in the training set and thatthe more complex system does not detect, as analysis can determine. To overcomethis problem, our fourth and final system consists of an ensemble strategycombining the predictions of the other three. Many opportunities to refine thesystem and training strategy can be tested in future ablation experiments, andlikely achieve incremental performance gains for this audio-visual task.</description><author>Davide Berghi, Philip J. B. Jackson</author><pubDate>Tue, 29 Oct 2024 17:28:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22271v1</guid></item><item><title>Fourier Head: Helping Large Language Models Learn Complex Probability Distributions</title><link>http://arxiv.org/abs/2410.22269v1</link><description>As the quality of large language models has improved, there has beenincreased interest in using them to model non-linguistic tokens. For example,the Decision Transformer recasts agentic decision making as a sequence modelingproblem, using a decoder-only LLM to model the distribution over the discreteaction space for an Atari agent. However, when adapting LLMs to non-linguisticdomains, it remains unclear if softmax over discrete bins captures thecontinuous structure of the tokens and the potentially complex distributionsneeded for high quality token generation. We introduce a neural network layer,constructed using Fourier series, which we can easily substitute for any linearlayer if we want the outputs to have a more continuous structure. We performextensive analysis on synthetic datasets, as well as on large-scale decisionmaking and time series forecasting tasks. We also provide theoretical evidencethat this layer can better learn signal from data while ignoring high-frequencynoise. All of our results support the effectiveness of our proposed Fourierhead in scenarios where the underlying data distribution has a naturalcontinuous structure. For example, the Fourier head improves a DecisionTransformer agent's returns by 46% on the Atari Seaquest game, and increases astate-of-the-art times series foundation model's forecasting performance by3.5% across 20 benchmarks unseen during training.</description><author>Nate Gillman, Daksh Aggarwal, Michael Freeman, Saurabh Singh, Chen Sun</author><pubDate>Tue, 29 Oct 2024 17:27:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22269v1</guid></item><item><title>NCA-Morph: Medical Image Registration with Neural Cellular Automata</title><link>http://arxiv.org/abs/2410.22265v1</link><description>Medical image registration is a critical process that aligns various patientscans, facilitating tasks like diagnosis, surgical planning, and tracking.Traditional optimization based methods are slow, prompting the use of DeepLearning (DL) techniques, such as VoxelMorph and Transformer-based strategies,for faster results. However, these DL methods often impose significant resourcedemands. In response to these challenges, we present NCA-Morph, an innovativeapproach that seamlessly blends DL with a bio-inspired communication andnetworking approach, enabled by Neural Cellular Automata (NCAs). NCA-Morph notonly harnesses the power of DL for efficient image registration but also buildsa network of local communications between cells and respective voxels overtime, mimicking the interaction observed in living systems. In our extensiveexperiments, we subject NCA-Morph to evaluations across three distinct 3Dregistration tasks, encompassing Brain, Prostate and Hippocampus images fromboth healthy and diseased patients. The results showcase NCA-Morph's ability toachieve state-of-the-art performance. Notably, NCA-Morph distinguishes itselfas a lightweight architecture with significantly fewer parameters; 60% and99.7% less than VoxelMorph and TransMorph. This characteristic positionsNCA-Morph as an ideal solution for resource-constrained medical applications,such as primary care settings and operating rooms.</description><author>Amin Ranem, John Kalkhof, Anirban Mukhopadhyay</author><pubDate>Tue, 29 Oct 2024 17:26:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22265v1</guid></item><item><title>AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions</title><link>http://arxiv.org/abs/2410.20424v2</link><description>Data science tasks involving tabular data present complex challenges thatrequire sophisticated problem-solving approaches. We propose AutoKaggle, apowerful and user-centric framework that assists data scientists in completingdaily data pipelines through a collaborative multi-agent system. AutoKaggleimplements an iterative development process that combines code execution,debugging, and comprehensive unit testing to ensure code correctness and logicconsistency. The framework offers highly customizable workflows, allowing usersto intervene at each phase, thus integrating automated intelligence with humanexpertise. Our universal data science toolkit, comprising validated functionsfor data cleaning, feature engineering, and modeling, forms the foundation ofthis solution, enhancing productivity by streamlining common tasks. We selected8 Kaggle competitions to simulate data processing workflows in real-worldapplication scenarios. Evaluation results demonstrate that AutoKaggle achievesa validation submission rate of 0.85 and a comprehensive score of 0.82 intypical data science pipelines, fully proving its effectiveness andpracticality in handling complex data science tasks.</description><author>Ziming Li, Qianbo Zang, David Ma, Jiawei Guo, Tuney Zheng, Minghao Liu, Xinyao Niu, Yue Wang, Jian Yang, Jiaheng Liu, Wanjun Zhong, Wangchunshu Zhou, Wenhao Huang, Ge Zhang</author><pubDate>Tue, 29 Oct 2024 17:26:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20424v2</guid></item><item><title>Meta-Learning Adaptable Foundation Models</title><link>http://arxiv.org/abs/2410.22264v1</link><description>The power of foundation models (FMs) lies in their capacity to learn highlyexpressive representations that can be adapted to a broad spectrum of tasks.However, these pretrained models require multiple stages of fine-tuning tobecome effective for downstream applications. Conventionally, the model isfirst retrained on the aggregate of a diverse set of tasks of interest and thenadapted to specific low-resource downstream tasks by utilizing aparameter-efficient fine-tuning (PEFT) scheme. While this two-phase procedureseems reasonable, the independence of the retraining and fine-tuning phasescauses a major issue, as there is no guarantee the retrained model will achievegood performance post-fine-tuning. To explicitly address this issue, weintroduce a meta-learning framework infused with PEFT in this intermediateretraining stage to learn a model that can be easily adapted to unseen tasks.For our theoretical results, we focus on linear models using low-rankadaptations. In this setting, we demonstrate the suboptimality of standardretraining for finding an adaptable set of parameters. Further, we prove thatour method recovers the optimally adaptable parameters. We then apply thesetheoretical insights to retraining the RoBERTa model to predict thecontinuation of conversations between different personas within the ConvAI2dataset. Empirically, we observe significant performance benefits using ourproposed meta-learning scheme during retraining relative to the conventionalapproach.</description><author>Jacob L. Block, Sundararajan Srinivasan, Liam Collins, Aryan Mokhtari, Sanjay Shakkottai</author><pubDate>Tue, 29 Oct 2024 17:24:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22264v1</guid></item><item><title>LipKernel: Lipschitz-Bounded Convolutional Neural Networks via Dissipative Layers</title><link>http://arxiv.org/abs/2410.22258v1</link><description>We propose a novel layer-wise parameterization for convolutional neuralnetworks (CNNs) that includes built-in robustness guarantees by enforcing aprescribed Lipschitz bound. Each layer in our parameterization is designed tosatisfy a linear matrix inequality (LMI), which in turn implies dissipativitywith respect to a specific supply rate. Collectively, these layer-wise LMIsensure Lipschitz boundedness for the input-output mapping of the neuralnetwork, yielding a more expressive parameterization than through spectralbounds or orthogonal layers. Our new method LipKernel directly parameterizesdissipative convolution kernels using a 2-D Roesser-type state space model.This means that the convolutional layers are given in standard form aftertraining and can be evaluated without computational overhead. In numericalexperiments, we show that the run-time using our method is orders of magnitudefaster than state-of-the-art Lipschitz-bounded networks that parameterizeconvolutions in the Fourier domain, making our approach particularly attractivefor improving robustness of learning-based real-time perception or control inrobotics, autonomous vehicles, or automation systems. We focus on CNNs, and incontrast to previous works, our approach accommodates a wide variety of layerstypically used in CNNs, including 1-D and 2-D convolutional layers, maximum andaverage pooling layers, as well as strided and dilated convolutions and zeropadding. However, our approach naturally extends beyond CNNs as we canincorporate any layer that is incrementally dissipative.</description><author>Patricia Pauli, Ruigang Wang, Ian Manchester, Frank Allgöwer</author><pubDate>Tue, 29 Oct 2024 17:20:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22258v1</guid></item><item><title>FactBench: A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation</title><link>http://arxiv.org/abs/2410.22257v1</link><description>Language models (LMs) are widely used by an increasing number of users,underscoring the challenge of maintaining factuality across a broad range oftopics. We first present VERIFY (Verification and Evidence RetrIeval forFactualitY evaluation), a pipeline to evaluate LMs' factuality in real-worlduser interactions. VERIFY considers the verifiability of LM-generated contentand categorizes content units as supported, unsupported, or undecidable basedon the retrieved evidence from the Web. Importantly, factuality judgment byVERIFY correlates better with human evaluations than existing methods. UsingVERIFY, we identify "hallucination prompts" across diverse topics, i.e., thoseeliciting the highest rates of incorrect and inconclusive LM responses. Theseprompts form FactBench, a dataset of 1K prompts across 150 fine-grained topics.Our dataset captures emerging factuality challenges in real-world LMinteractions and can be regularly updated with new prompts. We benchmarkwidely-used LMs from GPT, Gemini, and Llama3.1 family on FactBench, yieldingthe following key findings: (i) Proprietary models exhibit better factuality,with performance declining from Easy to Hard hallucination prompts. (ii)Llama3.1-405B-Instruct shows comparable or lower factual accuracy thanLlama3.1-70B-Instruct across all evaluation methods due to its highersubjectivity that leads to more content labeled as undecidable. (iii)Gemini1.5-Pro shows a significantly higher refusal rate, with over-refusal in25% of cases. Our code and data are publicly available athttps://huggingface.co/spaces/launch/factbench.</description><author>Farima Fatahi Bayat, Lechen Zhang, Sheza Munir, Lu Wang</author><pubDate>Tue, 29 Oct 2024 17:19:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22257v1</guid></item><item><title>Hypergraph-based multi-scale spatio-temporal graph convolution network for Time-Series anomaly detection</title><link>http://arxiv.org/abs/2410.22256v1</link><description>Multivariate time series anomaly detection technology plays an important rolein many fields including aerospace, water treatment, cloud service providers,etc. Excellent anomaly detection models can greatly improve work efficiency andavoid major economic losses. However, with the development of technology, theincreasing size and complexity of data, and the lack of labels for relevantabnormal data, it is becoming increasingly challenging to perform effective andaccurate anomaly detection in high-dimensional and complex data sets. In thispaper, we propose a hypergraph based spatiotemporal graph convolutional neuralnetwork model STGCN_Hyper, which explicitly captures high-order, multi-hopcorrelations between multiple variables through a hypergraph based dynamicgraph structure learning module. On this basis, we further use the hypergraphbased spatiotemporal graph convolutional network to utilize the learnedhypergraph structure to effectively propagate and aggregate one-hop andmulti-hop related node information in the convolutional network, therebyobtaining rich spatial information. Furthermore, through the multi-scale TCNdilated convolution module, the STGCN_hyper model can also capture thedependencies of features at different scales in the temporal dimension. Anunsupervised anomaly detector based on PCA and GMM is also integrated into theSTGCN_hyper model. Through the anomaly score of the detector, the model candetect the anomalies in an unsupervised way. Experimental results on multipletime series datasets show that our model can flexibly learn the multi-scaletime series features in the data and the dependencies between features, andoutperforms most existing baseline models in terms of precision, recall,F1-score on anomaly detection tasks. Our code is available on:https://git.ecdf.ed.ac.uk/msc-23-24/s2044819</description><author>Hongyi Xu</author><pubDate>Tue, 29 Oct 2024 17:19:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22256v1</guid></item><item><title>TabDiff: a Multi-Modal Diffusion Model for Tabular Data Generation</title><link>http://arxiv.org/abs/2410.20626v2</link><description>Synthesizing high-quality tabular data is an important topic in many datascience tasks, ranging from dataset augmentation to privacy protection.However, developing expressive generative models for tabular data ischallenging due to its inherent heterogeneous data types, complexinter-correlations, and intricate column-wise distributions. In this paper, weintroduce TabDiff, a joint diffusion framework that models all multi-modaldistributions of tabular data in one model. Our key innovation is thedevelopment of a joint continuous-time diffusion process for numerical andcategorical data, where we propose feature-wise learnable diffusion processesto counter the high disparity of different feature distributions. TabDiff isparameterized by a transformer handling different input types, and the entireframework can be efficiently optimized in an end-to-end fashion. We furtherintroduce a multi-modal stochastic sampler to automatically correct theaccumulated decoding error during sampling, and propose classifier-freeguidance for conditional missing column value imputation. Comprehensiveexperiments on seven datasets demonstrate that TabDiff achieves superioraverage performance over existing competitive baselines across all eightmetrics, with up to $22.5\%$ improvement over the state-of-the-art model onpair-wise column correlation estimations. Code is available athttps://github.com/MinkaiXu/TabDiff.</description><author>Juntong Shi, Minkai Xu, Harper Hua, Hengrui Zhang, Stefano Ermon, Jure Leskovec</author><pubDate>Tue, 29 Oct 2024 17:19:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.20626v2</guid></item><item><title>Is the Lecture Engaging for Learning? Lecture Voice Sentiment Analysis for Knowledge Graph-Supported Intelligent Lecturing Assistant (ILA) System</title><link>http://arxiv.org/abs/2408.10492v2</link><description>This paper introduces an intelligent lecturing assistant (ILA) system thatutilizes a knowledge graph to represent course content and optimal pedagogicalstrategies. The system is designed to support instructors in enhancing studentlearning through real-time analysis of voice, content, and teaching methods. Asan initial investigation, we present a case study on lecture voice sentimentanalysis, in which we developed a training set comprising over 3,000 one-minutelecture voice clips. Each clip was manually labeled as either engaging ornon-engaging. Utilizing this dataset, we constructed and evaluated severalclassification models based on a variety of features extracted from the voiceclips. The results demonstrate promising performance, achieving an F1-score of90% for boring lectures on an independent set of over 800 test voice clips.This case study lays the groundwork for the development of a more sophisticatedmodel that will integrate content analysis and pedagogical practices. Ourultimate goal is to aid instructors in teaching more engagingly and effectivelyby leveraging modern artificial intelligence techniques.</description><author>Yuan An, Samarth Kolanupaka, Jacob An, Matthew Ma, Unnat Chhatwal, Alex Kalinowski, Michelle Rogers, Brian Smith</author><pubDate>Tue, 29 Oct 2024 17:18:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.10492v2</guid></item><item><title>Desiderata for the Context Use of Question Answering Systems</title><link>http://arxiv.org/abs/2401.18001v2</link><description>Prior work has uncovered a set of common problems in state-of-the-artcontext-based question answering (QA) systems: a lack of attention to thecontext when the latter conflicts with a model's parametric knowledge, littlerobustness to noise, and a lack of consistency with their answers. However,most prior work focus on one or two of those problems in isolation, which makesit difficult to see trends across them. We aim to close this gap, by firstoutlining a set of -- previously discussed as well as novel -- desiderata forQA models. We then survey relevant analysis and methods papers to provide anoverview of the state of the field. The second part of our work presentsexperiments where we evaluate 15 QA systems on 5 datasets according to alldesiderata at once. We find many novel trends, including (1) systems that areless susceptible to noise are not necessarily more consistent with theiranswers when given irrelevant context; (2) most systems that are moresusceptible to noise are more likely to correctly answer according to a contextthat conflicts with their parametric knowledge; and (3) the combination ofconflicting knowledge and noise can reduce system performance by up to 96%. Assuch, our desiderata help increase our understanding of how these models workand reveal potential avenues for improvements.</description><author>Sagi Shaier, Lawrence E Hunter, Katharina von der Wense</author><pubDate>Tue, 29 Oct 2024 17:14:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.18001v2</guid></item><item><title>Pushing the Performance Envelope of DNN-based Recommendation Systems Inference on GPUs</title><link>http://arxiv.org/abs/2410.22249v1</link><description>Personalized recommendation is a ubiquitous application on the internet, withmany industries and hyperscalers extensively leveraging Deep LearningRecommendation Models (DLRMs) for their personalization needs (like ad servingor movie suggestions). With growing model and dataset sizes pushing computationand memory requirements, GPUs are being increasingly preferred for executingDLRM inference. However, serving newer DLRMs, while meeting acceptablelatencies, continues to remain challenging, making traditional deploymentsincreasingly more GPU-hungry, resulting in higher inference serving costs. Inthis paper, we show that the embedding stage continues to be the primarybottleneck in the GPU inference pipeline, leading up to a 3.2x embedding-onlyperformance slowdown. To thoroughly grasp the problem, we conduct a detailed microarchitecturecharacterization and highlight the presence of low occupancy in the standardembedding kernels. By leveraging direct compiler optimizations, we achieveoptimal occupancy, pushing the performance by up to 53%. Yet, long memorylatency stalls continue to exist. To tackle this challenge, we proposespecialized plug-and-play-based software prefetching and L2 pinning techniques,which help in hiding and decreasing the latencies. Further, we proposecombining them, as they complement each other. Experimental evaluations usingA100 GPUs with large models and datasets show that our proposed techniquesimprove performance by up to 103% for the embedding stage, and up to 77% forthe overall DLRM inference pipeline.</description><author>Rishabh Jain, Vivek M. Bhasi, Adwait Jog, Anand Sivasubramaniam, Mahmut T. Kandemir, Chita R. Das</author><pubDate>Tue, 29 Oct 2024 17:13:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22249v1</guid></item><item><title>What Makes ImageNet Look Unlike LAION</title><link>http://arxiv.org/abs/2306.15769v2</link><description>ImageNet was famously created from Flickr image search results. What if werecreated ImageNet instead by searching the massive LAION dataset based onimage captions alone? In this work, we carry out this counterfactualinvestigation. We find that the resulting ImageNet recreation, which we callLAIONet, looks distinctly unlike the original. Specifically, the intra-classsimilarity of images in the original ImageNet is dramatically higher than it isfor LAIONet. Consequently, models trained on ImageNet perform significantlyworse on LAIONet. We propose a rigorous explanation for the discrepancy interms of a subtle, yet important, difference in two plausible causaldata-generating processes for the respective datasets, that we support withsystematic experimentation. In a nutshell, searching based on an image captionalone creates an information bottleneck that mitigates the selection biasotherwise present in image-based filtering. Our explanation formalizes along-held intuition in the community that ImageNet images are stereotypical,unnatural, and overly simple representations of the class category. At the sametime, it provides a simple and actionable takeaway for future dataset creationefforts.</description><author>Ali Shirali, Moritz Hardt</author><pubDate>Tue, 29 Oct 2024 17:13:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15769v2</guid></item><item><title>Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations</title><link>http://arxiv.org/abs/2410.04241v2</link><description>Resolving knowledge conflicts is a crucial challenge in Question Answering(QA) tasks, as the internet contains numerous conflicting facts and opinions.While some research has made progress in tackling ambiguous settings wheremultiple valid answers exist, these approaches often neglect to provide sourcecitations, leaving users to evaluate the factuality of each answer. On theother hand, existing work on citation generation has focused on unambiguoussettings with single answers, failing to address the complexity of real-worldscenarios. Despite the importance of both aspects, no prior research hascombined them, leaving a significant gap in the development of QA systems. Inthis work, we bridge this gap by proposing the novel task of QA with sourcecitation in ambiguous settings, where multiple valid answers exist. Tofacilitate research in this area, we create a comprehensive frameworkconsisting of: (1) five novel datasets, obtained by augmenting three existingreading comprehension datasets with citation meta-data across various ambiguoussettings, such as distractors and paraphrasing; (2) the first ambiguousmulti-hop QA dataset featuring real-world, naturally occurring contexts; (3)two new metrics to evaluate models' performances; and (4) several strongbaselines using rule-based, prompting, and finetuning approaches over fivelarge language models. We hope that this new task, datasets, metrics, andbaselines will inspire the community to push the boundaries of QA research anddevelop more trustworthy and interpretable systems.</description><author>Sagi Shaier, Ari Kobren, Philip Ogren</author><pubDate>Tue, 29 Oct 2024 17:12:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.04241v2</guid></item><item><title>Model-free Estimation of Latent Structure via Multiscale Nonparametric Maximum Likelihood</title><link>http://arxiv.org/abs/2410.22248v1</link><description>Multivariate distributions often carry latent structures that are difficultto identify and estimate, and which better reflect the data generatingmechanism than extrinsic structures exhibited simply by the raw data. In thispaper, we propose a model-free approach for estimating such latent structureswhenever they are present, without assuming they exist a priori. Given anarbitrary density $p_0$, we construct a multiscale representation of thedensity and propose data-driven methods for selecting representative modelsthat capture meaningful discrete structure. Our approach uses a nonparametricmaximum likelihood estimator to estimate the latent structure at differentscales and we further characterize their asymptotic limits. By carrying outsuch a multiscale analysis, we obtain coarseto-fine structures inherent in theoriginal distribution, which are integrated via a model selection procedure toyield an interpretable discrete representation of it. As an application, wedesign a clustering algorithm based on the proposed procedure and demonstrateits effectiveness in capturing a wide range of latent structures.</description><author>Bryon Aragam, Ruiyi Yang</author><pubDate>Tue, 29 Oct 2024 17:11:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22248v1</guid></item><item><title>Who Are All The Stochastic Parrots Imitating? They Should Tell Us!</title><link>http://arxiv.org/abs/2310.10583v2</link><description>Both standalone language models (LMs) as well as LMs within downstream-tasksystems have been shown to generate statements which are factually untrue. Thisproblem is especially severe for low-resource languages, where training data isscarce and of worse quality than for high-resource languages. In this opinionpiece, we argue that LMs in their current state will never be fully trustworthyin critical settings and suggest a possible novel strategy to handle thisissue: by building LMs such that can cite their sources - i.e., point a user tothe parts of their training data that back up their outputs. We first discusswhich current NLP tasks would or would not benefit from such models. We thenhighlight the expected benefits such models would bring, e.g., quickverifiability of statements. We end by outlining the individual tasks thatwould need to be solved on the way to developing LMs with the ability to cite.We hope to start a discussion about the field's current approach to buildingLMs, especially for low-resource languages, and the role of the training datain explaining model generations.</description><author>Sagi Shaier, Lawrence E. Hunter, Katharina von der Wense</author><pubDate>Tue, 29 Oct 2024 17:08:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.10583v2</guid></item><item><title>Abrupt Learning in Transformers: A Case Study on Matrix Completion</title><link>http://arxiv.org/abs/2410.22244v1</link><description>Recent analysis on the training dynamics of Transformers has unveiled aninteresting characteristic: the training loss plateaus for a significant numberof training steps, and then suddenly (and sharply) drops to near--optimalvalues. To understand this phenomenon in depth, we formulate the low-rankmatrix completion problem as a masked language modeling (MLM) task, and showthat it is possible to train a BERT model to solve this task to low error.Furthermore, the loss curve shows a plateau early in training followed by asudden drop to near-optimal values, despite no changes in the trainingprocedure or hyper-parameters. To gain interpretability insights into thissudden drop, we examine the model's predictions, attention heads, and hiddenstates before and after this transition. Concretely, we observe that (a) themodel transitions from simply copying the masked input to accurately predictingthe masked entries; (b) the attention heads transition to interpretablepatterns relevant to the task; and (c) the embeddings and hidden states encodeinformation relevant to the problem. We also analyze the training dynamics ofindividual model components to understand the sudden drop in loss.</description><author>Pulkit Gopalani, Ekdeep Singh Lubana, Wei Hu</author><pubDate>Tue, 29 Oct 2024 17:08:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22244v1</guid></item><item><title>DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers</title><link>http://arxiv.org/abs/2410.22239v1</link><description>Despite their high predictive accuracies, current machine learning systemsoften exhibit systematic biases stemming from annotation artifacts orinsufficient support for certain classes in the dataset. Recent work proposesautomatic methods for identifying and explaining systematic biases usingkeywords. We introduce DISCERN, a framework for interpreting systematic biasesin text classifiers using language explanations. DISCERN iteratively generatesprecise natural language descriptions of systematic errors by employing aninteractive loop between two large language models. Finally, we use thedescriptions to improve classifiers by augmenting classifier training sets withsynthetically generated instances or annotated examples via active learning. Onthree text-classification datasets, we demonstrate that language explanationsfrom our framework induce consistent performance improvements that go beyondwhat is achievable with exemplars of systematic bias. Finally, in humanevaluations, we show that users can interpret systematic biases moreeffectively (by over 25% relative) and efficiently when described throughlanguage explanations as opposed to cluster exemplars.</description><author>Rakesh R. Menon, Shashank Srivastava</author><pubDate>Tue, 29 Oct 2024 17:04:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22239v1</guid></item><item><title>MathPile: A Billion-Token-Scale Pretraining Corpus for Math</title><link>http://arxiv.org/abs/2312.17120v2</link><description>High-quality, large-scale corpora are the cornerstone of building foundationmodels. In this work, we introduce MathPile, a diverse and high-qualitymath-centric corpus comprising about 9.5 billion tokens. Throughout itscreation, we adhered to the principle of "less is more", firmly believing inthe supremacy of data quality over quantity, even in the pre-training phase.Our meticulous data collection and processing efforts included a complex suiteof preprocessing, prefiltering, language identification, cleaning, filtering,and deduplication, ensuring the high quality of our corpus. Furthermore, weperformed data contamination detection on downstream benchmark test sets toeliminate duplicates and conducted continual pre-training experiments, bootingthe performance on common mathematical reasoning benchmarks. We aim for ourMathPile to boost language models' mathematical reasoning abilities andopen-source its different versions and processing scripts to advance the field.</description><author>Zengzhi Wang, Xuefeng Li, Rui Xia, Pengfei Liu</author><pubDate>Tue, 29 Oct 2024 17:02:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.17120v2</guid></item><item><title>Auditing $f$-Differential Privacy in One Run</title><link>http://arxiv.org/abs/2410.22235v1</link><description>Empirical auditing has emerged as a means of catching some of the flaws inthe implementation of privacy-preserving algorithms. Existing auditingmechanisms, however, are either computationally inefficient requiring multipleruns of the machine learning algorithms or suboptimal in calculating anempirical privacy. In this work, we present a tight and efficient auditingprocedure and analysis that can effectively assess the privacy of mechanisms.Our approach is efficient; similar to the recent work of Steinke, Nasr, andJagielski (2023), our auditing procedure leverages the randomness of examplesin the input dataset and requires only a single run of the target mechanism.And it is more accurate; we provide a novel analysis that enables us to achievetight empirical privacy estimates by using the hypothesized $f$-DP curve of themechanism, which provides a more accurate measure of privacy than thetraditional $\epsilon,\delta$ differential privacy parameters. We use ourauditing procure and analysis to obtain empirical privacy, demonstrating thatour auditing procedure delivers tighter privacy estimates.</description><author>Saeed Mahloujifar, Luca Melis, Kamalika Chaudhuri</author><pubDate>Tue, 29 Oct 2024 17:02:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22235v1</guid></item><item><title>ContextIQ: A Multimodal Expert-Based Video Retrieval System for Contextual Advertising</title><link>http://arxiv.org/abs/2410.22233v1</link><description>Contextual advertising serves ads that are aligned to the content that theuser is viewing. The rapid growth of video content on social platforms andstreaming services, along with privacy concerns, has increased the need forcontextual advertising. Placing the right ad in the right context creates aseamless and pleasant ad viewing experience, resulting in higher audienceengagement and, ultimately, better ad monetization. From a technologystandpoint, effective contextual advertising requires a video retrieval systemcapable of understanding complex video content at a very granular level.Current text-to-video retrieval models based on joint multimodal trainingdemand large datasets and computational resources, limiting their practicalityand lacking the key functionalities required for ad ecosystem integration. Weintroduce ContextIQ, a multimodal expert-based video retrieval system designedspecifically for contextual advertising. ContextIQ utilizes modality-specificexperts-video, audio, transcript (captions), and metadata such as objects,actions, emotion, etc.-to create semantically rich video representations. Weshow that our system, without joint training, achieves better or comparableresults to state-of-the-art models and commercial solutions on multipletext-to-video retrieval benchmarks. Our ablation studies highlight the benefitsof leveraging multiple modalities for enhanced video retrieval accuracy insteadof using a vision-language model alone. Furthermore, we show how videoretrieval systems such as ContextIQ can be used for contextual advertising inan ad ecosystem while also addressing concerns related to brand safety andfiltering inappropriate content.</description><author>Ashutosh Chaubey, Anoubhav Agarwaal, Sartaki Sinha Roy, Aayush Agarwal, Susmita Ghose</author><pubDate>Tue, 29 Oct 2024 17:01:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22233v1</guid></item><item><title>Cora: Accelerating Stateful Network Applications with SmartNICs</title><link>http://arxiv.org/abs/2410.22229v1</link><description>With the growing performance requirements on networked applications, there isa new trend of offloading stateful network applications to SmartNICs to improveperformance and reduce the total cost of ownership. However, offloadingstateful network applications is non-trivial due to state operation complexity,state resource consumption, and the complicated relationship between trafficand state. Naively partitioning the program by state or traffic can result in asuboptimal partition plan with higher CPU usage or even packet drops. In thispaper, we propose Cora, a compiler and runtime that offloads stateful networkapplications to SmartNIC-accelerated hosts. Cora compiler introduces anaccurate performance model for each SmartNIC and employs an efficient compilingalgorithm to search the offloading plan. Cora runtime can monitor trafficdynamics and adapt to minimize CPU usage. Cora is built atop Netronome Agilioand BlueField 2 SmartNICs. Our evaluation shows that for the same throughputtarget, Cora can propose partition plans saving up to 94.0% CPU cores, 1.9times more than baseline solutions. Under the same resource constraint, Coracan accelerate network functions by 44.9%-82.3%. Cora runtime can adapt totraffic changes and keep CPU usage low.</description><author>Shaoke Xi, Jiaqi Gao, Mengqi Liu, Jiamin Cao, Fuliang Li, Kai Bu, Kui Ren, Minlan Yu, Dennis Cai, Ennan Zhai</author><pubDate>Tue, 29 Oct 2024 16:55:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22229v1</guid></item><item><title>Subgraph Aggregation for Out-of-Distribution Generalization on Graphs</title><link>http://arxiv.org/abs/2410.22228v1</link><description>Out-of-distribution (OOD) generalization in Graph Neural Networks (GNNs) hasgained significant attention due to its critical importance in graph-basedpredictions in real-world scenarios. Existing methods primarily focus onextracting a single causal subgraph from the input graph to achievegeneralizable predictions. However, relying on a single subgraph can lead tosusceptibility to spurious correlations and is insufficient for learninginvariant patterns behind graph data. Moreover, in many real-worldapplications, such as molecular property prediction, multiple criticalsubgraphs may influence the target label property. To address these challenges,we propose a novel framework, SubGraph Aggregation (SuGAr), designed to learn adiverse set of subgraphs that are crucial for OOD generalization on graphs.Specifically, SuGAr employs a tailored subgraph sampler and diversityregularizer to extract a diverse set of invariant subgraphs. These invariantsubgraphs are then aggregated by averaging their representations, whichenriches the subgraph signals and enhances coverage of the underlying causalstructures, thereby improving OOD generalization. Extensive experiments on bothsynthetic and real-world datasets demonstrate that \ours outperformsstate-of-the-art methods, achieving up to a 24% improvement in OODgeneralization on graphs. To the best of our knowledge, this is the first workto study graph OOD generalization by learning multiple invariant subgraphs.</description><author>Bowen Liu, Haoyang Li, Shuning Wang, Shuo Nie, Shanghang Zhang</author><pubDate>Tue, 29 Oct 2024 16:54:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22228v1</guid></item><item><title>Guide3D: A Bi-planar X-ray Dataset for 3D Shape Reconstruction</title><link>http://arxiv.org/abs/2410.22224v1</link><description>Endovascular surgical tool reconstruction represents an important factor inadvancing endovascular tool navigation, which is an important step inendovascular surgery. However, the lack of publicly available datasetssignificantly restricts the development and validation of novel machinelearning approaches. Moreover, due to the need for specialized equipment suchas biplanar scanners, most of the previous research employs monoplanarfluoroscopic technologies, hence only capturing the data from a single view andsignificantly limiting the reconstruction accuracy. To bridge this gap, weintroduce Guide3D, a bi-planar X-ray dataset for 3D reconstruction. The datasetrepresents a collection of high resolution bi-planar, manually annotatedfluoroscopic videos, captured in real-world settings. Validating our datasetwithin a simulated environment reflective of clinical settings confirms itsapplicability for real-world applications. Furthermore, we propose a newbenchmark for guidewrite shape prediction, serving as a strong baseline forfuture work. Guide3D not only addresses an essential need by offering aplatform for advancing segmentation and 3D reconstruction techniques but alsoaids the development of more accurate and efficient endovascular surgeryinterventions. Our project is available at https://airvlab.github.io/guide3d/.</description><author>Tudor Jianu, Baoru Huang, Hoan Nguyen, Binod Bhattarai, Tuong Do, Erman Tjiputra, Quang Tran, Pierre Berthet-Rayne, Ngan Le, Sebastiano Fichera, Anh Nguyen</author><pubDate>Tue, 29 Oct 2024 16:53:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22224v1</guid></item><item><title>MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for Efficient and Interpretable Medical Image Segmentation</title><link>http://arxiv.org/abs/2410.22223v1</link><description>Medical image segmentation is pivotal in healthcare, enhancing diagnosticaccuracy, informing treatment strategies, and tracking disease progression.This process allows clinicians to extract critical information from visualdata, enabling personalized patient care. However, developing neural networksfor segmentation remains challenging, especially when preserving imageresolution, which is essential in detecting subtle details that influencediagnoses. Moreover, the lack of transparency in these deep learning models hasslowed their adoption in clinical practice. Efforts in model interpretabilityare increasingly focused on making these models' decision-making processes moretransparent. In this paper, we introduce MAPUNetR, a novel architecture thatsynergizes the strengths of transformer models with the proven U-Net frameworkfor medical image segmentation. Our model addresses the resolution preservationchallenge and incorporates attention maps highlighting segmented regions,increasing accuracy and interpretability. Evaluated on the BraTS 2020 dataset,MAPUNetR achieved a dice score of 0.88 and a dice coefficient of 0.92 on theISIC 2018 dataset. Our experiments show that the model maintains stableperformance and potential as a powerful tool for medical image segmentation inclinical practice.</description><author>Ovais Iqbal Shah, Danish Raza Rizvi, Aqib Nazir Mir</author><pubDate>Tue, 29 Oct 2024 16:52:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22223v1</guid></item><item><title>Towards Unifying Understanding and Generation in the Era of Vision Foundation Models: A Survey from the Autoregression Perspective</title><link>http://arxiv.org/abs/2410.22217v1</link><description>Autoregression in large language models (LLMs) has shown impressivescalability by unifying all language tasks into the next token predictionparadigm. Recently, there is a growing interest in extending this success tovision foundation models. In this survey, we review the recent advances anddiscuss future directions for autoregressive vision foundation models. First,we present the trend for next generation of vision foundation models, i.e.,unifying both understanding and generation in vision tasks. We then analyze thelimitations of existing vision foundation models, and present a formaldefinition of autoregression with its advantages. Later, we categorizeautoregressive vision foundation models from their vision tokenizers andautoregression backbones. Finally, we discuss several promising researchchallenges and directions. To the best of our knowledge, this is the firstsurvey to comprehensively summarize autoregressive vision foundation modelsunder the trend of unifying understanding and generation. A collection ofrelated resources is available at https://github.com/EmmaSRH/ARVFM.</description><author>Shenghao Xie, Wenqiang Zu, Mingyang Zhao, Duo Su, Shilong Liu, Ruohua Shi, Guoqi Li, Shanghang Zhang, Lei Ma</author><pubDate>Tue, 29 Oct 2024 16:48:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22217v1</guid></item><item><title>Balancing Cost and Effectiveness of Synthetic Data Generation Strategies for LLMs</title><link>http://arxiv.org/abs/2409.19759v2</link><description>As large language models (LLMs) are applied to more use cases, creating highquality, task-specific datasets for fine-tuning becomes a bottleneck for modelimprovement. Using high quality human data has been the most common approach tounlock model performance, but is prohibitively expensive in many scenarios.Several alternative methods have also emerged, such as generating synthetic orhybrid data, but the effectiveness of these approaches remain unclear,especially in resource-constrained scenarios and tasks that are not easilyverified. To investigate this, we group various synthetic data generationstrategies into three representative categories -- Answer Augmentation,Question Rephrase and New Question -- and study the performance of student LLMstrained under various constraints, namely seed instruction set size and querybudget. We demonstrate that these strategies are not equally effective acrosssettings. Notably, the optimal data generation strategy depends strongly on theratio between the available teacher query budget and the size of the seedinstruction set. When this ratio is low, generating new answers to existingquestions proves most effective, but as this ratio increases, generating newquestions becomes optimal. Across all tasks, we find that choice ofaugmentation method and other design choices matter substantially more in lowto mid data regimes than in high data regimes. We provide a practical frameworkfor selecting the appropriate augmentation method across settings, taking intoaccount additional factors such as the scalability of each method, theimportance of verifying synthetic data, and the use of different LLMs forsynthetic data generation.</description><author>Yung-Chieh Chan, George Pu, Apaar Shanker, Parth Suresh, Penn Jenks, John Heyer, Sam Denton</author><pubDate>Tue, 29 Oct 2024 16:44:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.19759v2</guid></item><item><title>MambaForGCN: Enhancing Long-Range Dependency with State Space Model and Kolmogorov-Arnold Networks for Aspect-Based Sentiment Analysis</title><link>http://arxiv.org/abs/2407.10347v2</link><description>Aspect-based Sentiment Analysis (ABSA) evaluates sentiments toward specificaspects of entities within the text. However, attention mechanisms and neuralnetwork models struggle with syntactic constraints. The quadratic complexity ofattention mechanisms also limits their adoption for capturing long-rangedependencies between aspect and opinion words in ABSA. This complexity can leadto the misinterpretation of irrelevant contextual words, restricting theireffectiveness to short-range dependencies. To address the above problem, wepresent a novel approach to enhance long-range dependencies between aspect andopinion words in ABSA (MambaForGCN). This approach incorporates syntax-basedGraph Convolutional Network (SynGCN) and MambaFormer (Mamba-Transformer)modules to encode input with dependency relations and semantic information. TheMultihead Attention (MHA) and Selective State Space model (Mamba) blocks in theMambaFormer module serve as channels to enhance the model with short andlong-range dependencies between aspect and opinion words. We also introduce theKolmogorov-Arnold Networks (KANs) gated fusion, an adaptive featurerepresentation system that integrates SynGCN and MambaFormer and capturesnon-linear, complex dependencies. Experimental results on three benchmarkdatasets demonstrate MambaForGCN's effectiveness, outperformingstate-of-the-art (SOTA) baseline models.</description><author>Adamu Lawan, Juhua Pu, Haruna Yunusa, Aliyu Umar, Muhammad Lawan</author><pubDate>Tue, 29 Oct 2024 16:42:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.10347v2</guid></item><item><title>LiVisSfM: Accurate and Robust Structure-from-Motion with LiDAR and Visual Cues</title><link>http://arxiv.org/abs/2410.22213v1</link><description>This paper presents an accurate and robust Structure-from-Motion (SfM)pipeline named LiVisSfM, which is an SfM-based reconstruction system that fullycombines LiDAR and visual cues. Unlike most existing LiDAR-inertial odometry(LIO) and LiDAR-inertial-visual odometry (LIVO) methods relying heavily onLiDAR registration coupled with Inertial Measurement Unit (IMU), we propose aLiDAR-visual SfM method which innovatively carries out LiDAR frame registrationto LiDAR voxel map in a Point-to-Gaussian residual metrics, combined with aLiDAR-visual BA and explicit loop closure in a bundle optimization way toachieve accurate and robust LiDAR pose estimation without dependence on IMUincorporation. Besides, we propose an incremental voxel updating strategy forefficient voxel map updating during the process of LiDAR frame registration andLiDAR-visual BA optimization. Experiments demonstrate the superioreffectiveness of our LiVisSfM framework over state-of-the-art LIO and LIVOworks on more accurate and robust LiDAR pose recovery and dense point cloudreconstruction of both public KITTI benchmark and a variety of self-captureddataset.</description><author>Hanqing Jiang, Liyang Zhou, Zhuang Zhang, Yihao Yu, Guofeng Zhang</author><pubDate>Tue, 29 Oct 2024 16:41:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22213v1</guid></item><item><title>ProMQA: Question Answering Dataset for Multimodal Procedural Activity Understanding</title><link>http://arxiv.org/abs/2410.22211v1</link><description>Multimodal systems have great potential to assist humans in proceduralactivities, where people follow instructions to achieve their goals. Despitediverse application scenarios, systems are typically evaluated on traditionalclassification tasks, e.g., action recognition or temporal action segmentation.In this paper, we present a novel evaluation dataset, ProMQA, to measure systemadvancements in application-oriented scenarios. ProMQA consists of 401multimodal procedural QA pairs on user recording of procedural activitiescoupled with their corresponding instruction. For QA annotation, we take acost-effective human-LLM collaborative approach, where the existing annotationis augmented with LLM-generated QA pairs that are later verified by humans. Wethen provide the benchmark results to set the baseline performance on ProMQA.Our experiment reveals a significant gap between human performance and that ofcurrent systems, including competitive proprietary multimodal models. We hopeour dataset sheds light on new aspects of models' multimodal understandingcapabilities.</description><author>Kimihiro Hasegawa, Wiradee Imrattanatrai, Zhi-Qi Cheng, Masaki Asada, Susan Holm, Yuran Wang, Ken Fukuda, Teruko Mitamura</author><pubDate>Tue, 29 Oct 2024 16:39:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22211v1</guid></item><item><title>A Methodology for Gradual Semantics for Structured Argumentation under Incomplete Information</title><link>http://arxiv.org/abs/2410.22209v1</link><description>Gradual semantics have demonstrated great potential in argumentation, inparticular for deploying quantitative bipolar argumentation frameworks (QBAFs)in a number of real-world settings, from judgmental forecasting to explainableAI. In this paper, we provide a novel methodology for obtaining gradualsemantics for structured argumentation frameworks, where the building blocks ofarguments and relations between them are known, unlike in QBAFs, wherearguments are abstract entities. Differently from existing approaches, ourmethodology accommodates incomplete information about arguments' premises. Wedemonstrate the potential of our approach by introducing two differentinstantiations of the methodology, leveraging existing gradual semantics forQBAFs in these more complex frameworks. We also define a set of novelproperties for gradual semantics in structured argumentation, discuss theirsuitability over a set of existing properties. Finally, we provide acomprehensive theoretical analysis assessing the instantiations, demonstratingthe their advantages over existing gradual semantics for QBAFs and structuredargumentation.</description><author>Antonio Rago, Stylianos Loukas Vasileiou, Francesca Toni, Tran Cao Son, William Yeoh</author><pubDate>Tue, 29 Oct 2024 16:38:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22209v1</guid></item><item><title>Drone Acoustic Analysis for Predicting Psychoacoustic Annoyance via Artificial Neural Networks</title><link>http://arxiv.org/abs/2410.22208v1</link><description>Unmanned Aerial Vehicles (UAVs) have become widely used in various fields andindustrial applications thanks to their low operational cost, compact size andwide accessibility. However, the noise generated by drone propellers hasemerged as a significant concern. This may affect the public willingness toimplement these vehicles in services that require operation in proximity toresidential areas. The standard approaches to address this challenge includesound pressure measurements and noise characteristic analyses. The integrationof Artificial Intelligence models in recent years has further streamlined theprocess by enhancing complex feature detection in drone acoustics data. Thisstudy builds upon prior research by examining the efficacy of various DeepLearning models in predicting Psychoacoustic Annoyance, an effective index formeasuring perceived annoyance by human ears, based on multiple dronecharacteristics as input. This is accomplished by constructing a trainingdataset using precise measurements of various drone models with multiplemicrophones and analyzing flight data, maneuvers, drone physicalcharacteristics, and perceived annoyance under realistic conditions. The aim ofthis research is to improve our understanding of drone noise, aid in thedevelopment of noise reduction techniques, and encourage the acceptance ofdrone usage on public spaces.</description><author>Andrea Vaiuso, Marcello Righi, Oier Coretti, Moreno Apicella</author><pubDate>Tue, 29 Oct 2024 16:38:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22208v1</guid></item><item><title>Democratizing Reward Design for Personal and Representative Value-Alignment</title><link>http://arxiv.org/abs/2410.22203v1</link><description>Aligning AI agents with human values is challenging due to diverse andsubjective notions of values. Standard alignment methods often aggregate crowdfeedback, which can result in the suppression of unique or minoritypreferences. We introduce Interactive-Reflective Dialogue Alignment, a methodthat iteratively engages users in reflecting on and specifying their subjectivevalue definitions. This system learns individual value definitions throughlanguage-model-based preference elicitation and constructs personalized rewardmodels that can be used to align AI behaviour. We evaluated our system throughtwo studies with 30 participants, one focusing on "respect" and the other onethical decision-making in autonomous vehicles. Our findings demonstratediverse definitions of value-aligned behaviour and show that our system canaccurately capture each person's unique understanding. This approach enablespersonalized alignment and can inform more representative and interpretablecollective alignment strategies.</description><author>Carter Blair, Kate Larson, Edith Law</author><pubDate>Tue, 29 Oct 2024 16:37:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22203v1</guid></item><item><title>LLS: Local Learning Rule for Deep Neural Networks Inspired by Neural Activity Synchronization</title><link>http://arxiv.org/abs/2405.15868v2</link><description>Training deep neural networks (DNNs) using traditional backpropagation (BP)presents challenges in terms of computational complexity and energyconsumption, particularly for on-device learning where computational resourcesare limited. Various alternatives to BP, including random feedback alignment,forward-forward, and local classifiers, have been explored to address thesechallenges. These methods have their advantages, but they can encounterdifficulties when dealing with intricate visual tasks or demand considerablecomputational resources. In this paper, we propose a novel Local Learning ruleinspired by neural activity Synchronization phenomena (LLS) observed in thebrain. LLS utilizes fixed periodic basis vectors to synchronize neuron activitywithin each layer, enabling efficient training without the need for additionaltrainable parameters. We demonstrate the effectiveness of LLS and itsvariations, LLS-M and LLS-MxM, on multiple image classification datasets,achieving accuracy comparable to BP with reduced computational complexity andminimal additional parameters. Specifically, LLS achieves comparableperformance with up to $300 \times$ fewer multiply-accumulate (MAC) operationsand half the memory requirements of BP. Furthermore, the performance of LLS onthe Visual Wake Word (VWW) dataset highlights its suitability for on-devicelearning tasks, making it a promising candidate for edge hardwareimplementations.</description><author>Marco Paul E. Apolinario, Arani Roy, Kaushik Roy</author><pubDate>Tue, 29 Oct 2024 16:35:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.15868v2</guid></item><item><title>Towards a theory of how the structure of language is acquired by deep neural networks</title><link>http://arxiv.org/abs/2406.00048v3</link><description>How much data is required to learn the structure of a language via next-tokenprediction? We study this question for synthetic datasets generated via aProbabilistic Context-Free Grammar (PCFG) -- a tree-like generative model thatcaptures many of the hierarchical structures found in natural languages. Wedetermine token-token correlations analytically in our model and show that theycan be used to build a representation of the grammar's hidden variables, thelonger the range the deeper the variable. In addition, a finite training setlimits the resolution of correlations to an effective range, whose size growswith that of the training set. As a result, a Language Model trained withincreasingly many examples can build a deeper representation of the grammar'sstructure, thus reaching good performance despite the high dimensionality ofthe problem. We conjecture that the relationship between training set size andeffective range of correlations holds beyond our synthetic datasets. Inparticular, our conjecture predicts how the scaling law for the test lossbehaviour with training set size depends on the length of the context window,which we confirm empirically in Shakespeare's plays and Wikipedia articles.</description><author>Francesco Cagnetta, Matthieu Wyart</author><pubDate>Tue, 29 Oct 2024 16:35:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.00048v3</guid></item><item><title>Class-Aware Contrastive Optimization for Imbalanced Text Classification</title><link>http://arxiv.org/abs/2410.22197v1</link><description>The unique characteristics of text data make classification tasks a complexproblem. Advances in unsupervised and semi-supervised learning and autoencoderarchitectures addressed several challenges. However, they still struggle withimbalanced text classification tasks, a common scenario in real-worldapplications, demonstrating a tendency to produce embeddings with unfavorableproperties, such as class overlap. In this paper, we show that leveragingclass-aware contrastive optimization combined with denoising autoencoders cansuccessfully tackle imbalanced text classification tasks, achieving betterperformance than the current state-of-the-art. Concretely, our proposalcombines reconstruction loss with contrastive class separation in the embeddingspace, allowing a better balance between the truthfulness of the generatedembeddings and the model's ability to separate different classes. Compared withan extensive set of traditional and state-of-the-art competing methods, ourproposal demonstrates a notable increase in performance across a wide varietyof text datasets.</description><author>Grigorii Khvatskii, Nuno Moniz, Khoa Doan, Nitesh V Chawla</author><pubDate>Tue, 29 Oct 2024 16:34:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22197v1</guid></item><item><title>ADAM: An Embodied Causal Agent in Open-World Environments</title><link>http://arxiv.org/abs/2410.22194v1</link><description>In open-world environments like Minecraft, existing agents face challenges incontinuously learning structured knowledge, particularly causality. Thesechallenges stem from the opacity inherent in black-box models and an excessivereliance on prior knowledge during training, which impair theirinterpretability and generalization capability. To this end, we introduce ADAM,An emboDied causal Agent in Minecraft, that can autonomously navigate the openworld, perceive multimodal contexts, learn causal world knowledge, and tacklecomplex tasks through lifelong learning. ADAM is empowered by four keycomponents: 1) an interaction module, enabling the agent to execute actionswhile documenting the interaction processes; 2) a causal model module, taskedwith constructing an ever-growing causal graph from scratch, which enhancesinterpretability and diminishes reliance on prior knowledge; 3) a controllermodule, comprising a planner, an actor, and a memory pool, which uses thelearned causal graph to accomplish tasks; 4) a perception module, powered bymultimodal large language models, which enables ADAM to perceive like a humanplayer. Extensive experiments show that ADAM constructs an almost perfectcausal graph from scratch, enabling efficient task decomposition and executionwith strong interpretability. Notably, in our modified Minecraft games where noprior knowledge is available, ADAM maintains its performance and showsremarkable robustness and generalization capability. ADAM pioneers a novelparadigm that integrates causal methods and embodied agents in a synergisticmanner. Our project page is at https://opencausalab.github.io/ADAM.</description><author>Shu Yu, Chaochao Lu</author><pubDate>Tue, 29 Oct 2024 16:32:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22194v1</guid></item><item><title>GRINNs: Godunov-Riemann Informed Neural Networks for Learning Hyperbolic Conservation Laws</title><link>http://arxiv.org/abs/2410.22193v1</link><description>We present GRINNs: numerical analysis-informed neural networks for thesolution of inverse problems of non-linear systems of conservation laws. GRINNsare based on high-resolution Godunov schemes for the solution of the Riemannproblem in hyperbolic Partial Differential Equations (PDEs). In contrast toother existing machine learning methods that learn the numerical fluxes ofconservative Finite Volume methods, GRINNs learn the physical flux function perse. Due to their structure, GRINNs provide interpretable, conservative schemes,that learn the solution operator on the basis of approximate Riemann solversthat satisfy the Rankine-Hugoniot condition. The performance of GRINNs isassessed via four benchmark problems, namely the Burgers', the Shallow Water,the Lighthill-Whitham-Richards and the Payne-Whitham traffic flow models. Thesolution profiles of these PDEs exhibit shock waves, rarefactions and/orcontact discontinuities at finite times. We demonstrate that GRINNs provide avery high accuracy both in the smooth and discontinuous regions.</description><author>Dimitrios G. Patsatzis, Mario di Bernardo, Lucia Russo, Constantinos Siettos</author><pubDate>Tue, 29 Oct 2024 16:31:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22193v1</guid></item><item><title>$r$Age-$k$: Communication-Efficient Federated Learning Using Age Factor</title><link>http://arxiv.org/abs/2410.22192v1</link><description>Federated learning (FL) is a collaborative approach where multiple clients,coordinated by a parameter server (PS), train a unified machine-learning model.The approach, however, suffers from two key challenges: data heterogeneity andcommunication overhead. Data heterogeneity refers to inconsistencies in modeltraining arising from heterogeneous data at different clients. Communicationoverhead arises from the large volumes of parameter updates exchanged betweenthe PS and clients. Existing solutions typically address these challengesseparately. This paper introduces a new communication-efficient algorithm thatuses the age of information metric to simultaneously tackle both limitations ofFL. We introduce age vectors at the PS, which keep track of how often thedifferent model parameters are updated from the clients. The PS uses this toselectively request updates for specific gradient indices from each client.Further, the PS employs age vectors to identify clients with statisticallysimilar data and group them into clusters. The PS combines the age vectors ofthe clustered clients to efficiently coordinate gradient index updates amongclients within a cluster. We evaluate our approach using the MNIST and CIFAR10datasets in highly non-i.i.d. settings. The experimental results show that ourproposed method can expedite training, surpassing other communication-efficientstrategies in efficiency.</description><author>Matin Mortaheb, Priyanka Kaswan, Sennur Ulukus</author><pubDate>Tue, 29 Oct 2024 16:30:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22192v1</guid></item><item><title>GSD: View-Guided Gaussian Splatting Diffusion for 3D Reconstruction</title><link>http://arxiv.org/abs/2407.04237v4</link><description>We present GSD, a diffusion model approach based on Gaussian Splatting (GS)representation for 3D object reconstruction from a single view. Prior workssuffer from inconsistent 3D geometry or mediocre rendering quality due toimproper representations. We take a step towards resolving these shortcomingsby utilizing the recent state-of-the-art 3D explicit representation, GaussianSplatting, and an unconditional diffusion model. This model learns to generate3D objects represented by sets of GS ellipsoids. With these strong generative3D priors, though learning unconditionally, the diffusion model is ready forview-guided reconstruction without further model fine-tuning. This is achievedby propagating fine-grained 2D features through the efficient yet flexiblesplatting function and the guided denoising sampling process. In addition, a 2Ddiffusion model is further employed to enhance rendering fidelity, and improvereconstructed GS quality by polishing and re-using the rendered images. Thefinal reconstructed objects explicitly come with high-quality 3D structure andtexture, and can be efficiently rendered in arbitrary views. Experiments on thechallenging real-world CO3D dataset demonstrate the superiority of ourapproach. Project page: https://yxmu.foo/GSD/</description><author>Yuxuan Mu, Xinxin Zuo, Chuan Guo, Yilin Wang, Juwei Lu, Xiaofeng Wu, Songcen Xu, Peng Dai, Youliang Yan, Li Cheng</author><pubDate>Tue, 29 Oct 2024 16:26:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.04237v4</guid></item><item><title>Active Learning for Vision-Language Models</title><link>http://arxiv.org/abs/2410.22187v1</link><description>Pre-trained vision-language models (VLMs) like CLIP have demonstratedimpressive zero-shot performance on a wide range of downstream computer visiontasks. However, there still exists a considerable performance gap between thesemodels and a supervised deep model trained on a downstream dataset. To bridgethis gap, we propose a novel active learning (AL) framework that enhances thezero-shot classification performance of VLMs by selecting only a fewinformative samples from the unlabeled data for annotation during training. Toachieve this, our approach first calibrates the predicted entropy of VLMs andthen utilizes a combination of self-uncertainty and neighbor-aware uncertaintyto calculate a reliable uncertainty measure for active sample selection. Ourextensive experiments show that the proposed approach outperforms existing ALapproaches on several image classification datasets, and significantly enhancesthe zero-shot performance of VLMs.</description><author>Bardia Safaei, Vishal M. Patel</author><pubDate>Tue, 29 Oct 2024 16:25:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22187v1</guid></item><item><title>Enhancing Learned Image Compression via Cross Window-based Attention</title><link>http://arxiv.org/abs/2410.21144v2</link><description>In recent years, learned image compression methods have demonstrated superiorrate-distortion performance compared to traditional image compression methods.Recent methods utilize convolutional neural networks (CNN), variationalautoencoders (VAE), invertible neural networks (INN), and transformers. Despitetheir significant contributions, a main drawback of these models is their poorperformance in capturing local redundancy. Therefore, to leverage globalfeatures along with local redundancy, we propose a CNN-based solutionintegrated with a feature encoding module. The feature encoding module encodesimportant features before feeding them to the CNN and then utilizes cross-scalewindow-based attention, which further captures local redundancy. Cross-scalewindow-based attention is inspired by the attention mechanism in transformersand effectively enlarges the receptive field. Both the feature encoding moduleand the cross-scale window-based attention module in our architecture areflexible and can be incorporated into any other network architecture. Weevaluate our method on the Kodak and CLIC datasets and demonstrate that ourapproach is effective and on par with state-of-the-art methods.</description><author>Priyanka Mudgal, Feng Liu</author><pubDate>Tue, 29 Oct 2024 16:25:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.21144v2</guid></item><item><title>Multi-Level Feature Distillation of Joint Teachers Trained on Distinct Image Datasets</title><link>http://arxiv.org/abs/2410.22184v1</link><description>We propose a novel teacher-student framework to distill knowledge frommultiple teachers trained on distinct datasets. Each teacher is first trainedfrom scratch on its own dataset. Then, the teachers are combined into a jointarchitecture, which fuses the features of all teachers at multiplerepresentation levels. The joint teacher architecture is fine-tuned on samplesfrom all datasets, thus gathering useful generic information from all datasamples. Finally, we employ a multi-level feature distillation procedure totransfer the knowledge to a student model for each of the considered datasets.We conduct image classification experiments on seven benchmarks, and actionrecognition experiments on three benchmarks. To illustrate the power of ourfeature distillation procedure, the student architectures are chosen to beidentical to those of the individual teachers. To demonstrate the flexibilityof our approach, we combine teachers with distinct architectures. We show thatour novel Multi-Level Feature Distillation (MLFD) can significantly surpassequivalent architectures that are either trained on individual datasets, orjointly trained on all datasets at once. Furthermore, we confirm that each stepof the proposed training procedure is well motivated by a comprehensiveablation study. We publicly release our code athttps://github.com/AdrianIordache/MLFD.</description><author>Adrian Iordache, Bogdan Alexe, Radu Tudor Ionescu</author><pubDate>Tue, 29 Oct 2024 16:23:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22184v1</guid></item><item><title>Externally Valid Policy Evaluation Combining Trial and Observational Data</title><link>http://arxiv.org/abs/2310.14763v3</link><description>Randomized trials are widely considered as the gold standard for evaluatingthe effects of decision policies. Trial data is, however, drawn from apopulation which may differ from the intended target population and this raisesa problem of external validity (aka. generalizability). In this paper we seekto use trial data to draw valid inferences about the outcome of a policy on thetarget population. Additional covariate data from the target population is usedto model the sampling of individuals in the trial study. We develop a methodthat yields certifiably valid trial-based policy evaluations under anyspecified range of model miscalibrations. The method is nonparametric and thevalidity is assured even with finite samples. The certified policy evaluationsare illustrated using both simulated and real data.</description><author>Sofia Ek, Dave Zachariah</author><pubDate>Tue, 29 Oct 2024 16:20:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14763v3</guid></item><item><title>Natural Language Processing for Analyzing Electronic Health Records and Clinical Notes in Cancer Research: A Review</title><link>http://arxiv.org/abs/2410.22180v1</link><description>Objective: This review aims to analyze the application of natural languageprocessing (NLP) techniques in cancer research using electronic health records(EHRs) and clinical notes. This review addresses gaps in the existingliterature by providing a broader perspective than previous studies focused onspecific cancer types or applications. Methods: A comprehensive literaturesearch was conducted using the Scopus database, identifying 94 relevant studiespublished between 2019 and 2024. Data extraction included studycharacteristics, cancer types, NLP methodologies, dataset information,performance metrics, challenges, and future directions. Studies werecategorized based on cancer types and NLP applications. Results: The resultsshowed a growing trend in NLP applications for cancer research, with breast,lung, and colorectal cancers being the most studied. Information extraction andtext classification emerged as predominant NLP tasks. A shift from rule-basedto advanced machine learning techniques, particularly transformer-based models,was observed. The Dataset sizes used in existing studies varied widely. Keychallenges included the limited generalizability of proposed solutions and theneed for improved integration into clinical workflows. Conclusion: NLPtechniques show significant potential in analyzing EHRs and clinical notes forcancer research. However, future work should focus on improving modelgeneralizability, enhancing robustness in handling complex clinical language,and expanding applications to understudied cancer types. Integration of NLPtools into clinical practice and addressing ethical considerations remaincrucial for utilizing the full potential of NLP in enhancing cancer diagnosis,treatment, and patient outcomes.</description><author>Muhammad Bilal, Ameer Hamza, Nadia Malik</author><pubDate>Tue, 29 Oct 2024 16:17:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22180v1</guid></item><item><title>Very Attentive Tacotron: Robust and Unbounded Length Generalization in Autoregressive Transformer-Based Text-to-Speech</title><link>http://arxiv.org/abs/2410.22179v1</link><description>Autoregressive (AR) Transformer-based sequence models are known to havedifficulty generalizing to sequences longer than those seen during training.When applied to text-to-speech (TTS), these models tend to drop or repeat wordsor produce erratic output, especially for longer utterances. In this paper, weintroduce enhancements aimed at AR Transformer-based encoder-decoder TTSsystems that address these robustness and length generalization issues. Ourapproach uses an alignment mechanism to provide cross-attention operations withrelative location information. The associated alignment position is learned asa latent property of the model via backprop and requires no external alignmentinformation during training. While the approach is tailored to the monotonicnature of TTS input-output alignment, it is still able to benefit from theflexible modeling power of interleaved multi-head self- and cross-attentionoperations. A system incorporating these improvements, which we call VeryAttentive Tacotron, matches the naturalness and expressiveness of a baselineT5-based TTS system, while eliminating problems with repeated or dropped wordsand enabling generalization to any practical utterance length.</description><author>Eric Battenberg, RJ Skerry-Ryan, Daisy Stanton, Soroosh Mariooryad, Matt Shannon, Julian Salazar, David Kao</author><pubDate>Tue, 29 Oct 2024 16:17:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22179v1</guid></item><item><title>Analyzing Multimodal Interaction Strategies for LLM-Assisted Manipulation of 3D Scenes</title><link>http://arxiv.org/abs/2410.22177v1</link><description>As more applications of large language models (LLMs) for 3D content forimmersive environments emerge, it is crucial to study user behaviour toidentify interaction patterns and potential barriers to guide the future designof immersive content creation and editing systems which involve LLMs. In anempirical user study with 12 participants, we combine quantitative usage datawith post-experience questionnaire feedback to reveal common interactionpatterns and key barriers in LLM-assisted 3D scene editing systems. We identifyopportunities for improving natural language interfaces in 3D design tools andpropose design recommendations for future LLM-integrated 3D content creationsystems. Through an empirical study, we demonstrate that LLM-assistedinteractive systems can be used productively in immersive environments.</description><author>Junlong Chen, Jens Grubert, Per Ola Kristensson</author><pubDate>Tue, 29 Oct 2024 16:15:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22177v1</guid></item><item><title>S-TLLR: STDP-inspired Temporal Local Learning Rule for Spiking Neural Networks</title><link>http://arxiv.org/abs/2306.15220v4</link><description>Spiking Neural Networks (SNNs) are biologically plausible models that havebeen identified as potentially apt for deploying energy-efficient intelligenceat the edge, particularly for sequential learning tasks. However, training ofSNNs poses significant challenges due to the necessity for precise temporal andspatial credit assignment. Back-propagation through time (BPTT) algorithm,whilst the most widely used method for addressing these issues, incurs highcomputational cost due to its temporal dependency. In this work, we proposeS-TLLR, a novel three-factor temporal local learning rule inspired by theSpike-Timing Dependent Plasticity (STDP) mechanism, aimed at training deep SNNson event-based learning tasks. Furthermore, S-TLLR is designed to have lowmemory and time complexities, which are independent of the number of timesteps, rendering it suitable for online learning on low-power edge devices. Todemonstrate the scalability of our proposed method, we have conducted extensiveevaluations on event-based datasets spanning a wide range of applications, suchas image and gesture recognition, audio classification, and optical flowestimation. In all the experiments, S-TLLR achieved high accuracy, comparableto BPTT, with a reduction in memory between $5-50\times$ andmultiply-accumulate (MAC) operations between $1.3-6.6\times$.</description><author>Marco Paul E. Apolinario, Kaushik Roy</author><pubDate>Tue, 29 Oct 2024 16:11:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15220v4</guid></item><item><title>Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images</title><link>http://arxiv.org/abs/2407.18125v2</link><description>Deep neural networks have been extensively applied in the medical domain forvarious tasks, including image classification, segmentation, and landmarkdetection. However, their application is often hindered by data scarcity, bothin terms of available annotations and images. This study introduces a novelapplication of denoising diffusion probabilistic models (DDPMs) to the landmarkdetection task, specifically addressing the challenge of limited annotated datain x-ray imaging. Our key innovation lies in leveraging DDPMs forself-supervised pre-training in landmark detection, a previously unexploredapproach in this domain. This method enables accurate landmark detection withminimal annotated training data (as few as 50 images), surpassing both ImageNetsupervised pre-training and traditional self-supervised techniques across threepopular x-ray benchmark datasets. To our knowledge, this work represents thefirst application of diffusion models for self-supervised learning in landmarkdetection, which may offer a valuable pre-training approach in few-shotregimes, for mitigating data scarcity.</description><author>Roberto Di Via, Francesca Odone, Vito Paolo Pastore</author><pubDate>Tue, 29 Oct 2024 16:10:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.18125v2</guid></item><item><title>EconoJax: A Fast &amp; Scalable Economic Simulation in Jax</title><link>http://arxiv.org/abs/2410.22165v1</link><description>Accurate economic simulations often require many experimental runs,particularly when combined with reinforcement learning. Unfortunately, trainingreinforcement learning agents in multi-agent economic environments can be slow.This paper introduces EconoJax, a fast simulated economy, based on the AIeconomist. EconoJax, and its training pipeline, are completely written in JAX.This allows EconoJax to scale to large population sizes and perform largeexperiments, while keeping training times within minutes. Through experimentswith populations of 100 agents, we show how real-world economic behavioremerges through training within 15 minutes, in contrast to previous work thatrequired several days. To aid and inspire researchers to build more rich anddynamic economic simulations, we open-source EconoJax on Github at:https://github.com/ponseko/econojax.</description><author>Koen Ponse, Aske Plaat, Niki van Stein, Thomas M. Moerland</author><pubDate>Tue, 29 Oct 2024 16:02:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22165v1</guid></item><item><title>UDC: A Unified Neural Divide-and-Conquer Framework for Large-Scale Combinatorial Optimization Problems</title><link>http://arxiv.org/abs/2407.00312v3</link><description>Single-stage neural combinatorial optimization solvers have achievednear-optimal results on various small-scale combinatorial optimization (CO)problems without requiring expert knowledge. However, these solvers exhibitsignificant performance degradation when applied to large-scale CO problems.Recently, two-stage neural methods motivated by divide-and-conquer strategieshave shown efficiency in addressing large-scale CO problems. Nevertheless, theperformance of these methods highly relies on problem-specific heuristics ineither the dividing or the conquering procedure, which limits theirapplicability to general CO problems. Moreover, these methods employ separatetraining schemes and ignore the interdependencies between the dividing andconquering strategies, often leading to sub-optimal solutions. To tackle thesedrawbacks, this article develops a unified neural divide-and-conquer framework(i.e., UDC) for solving general large-scale CO problems. UDC offers aDivide-Conquer-Reunion (DCR) training method to eliminate the negative impactof a sub-optimal dividing policy. Employing a high-efficiency Graph NeuralNetwork (GNN) for global instance dividing and a fixed-length sub-path solverfor conquering divided sub-problems, the proposed UDC framework demonstratesextensive applicability, achieving superior performance in 10 representativelarge-scale CO problems. The code is available athttps://github.com/CIAM-Group/NCO_code/tree/main/single_objective/UDC-Large-scale-CO-master.</description><author>Zhi Zheng, Changliang Zhou, Tong Xialiang, Mingxuan Yuan, Zhenkun Wang</author><pubDate>Tue, 29 Oct 2024 15:56:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00312v3</guid></item><item><title>Unraveling Molecular Structure: A Multimodal Spectroscopic Dataset for Chemistry</title><link>http://arxiv.org/abs/2407.17492v2</link><description>Spectroscopic techniques are essential tools for determining the structure ofmolecules. Different spectroscopic techniques, such as Nuclear magneticresonance (NMR), Infrared spectroscopy, and Mass Spectrometry, provide insightinto the molecular structure, including the presence or absence of functionalgroups. Chemists leverage the complementary nature of the different methods totheir advantage. However, the lack of a comprehensive multimodal dataset,containing spectra from a variety of spectroscopic techniques, has limitedmachine-learning approaches mostly to single-modality tasks for predictingmolecular structures from spectra. Here we introduce a dataset comprisingsimulated $^1$H-NMR, $^{13}$C-NMR, HSQC-NMR, Infrared, and Mass spectra(positive and negative ion modes) for 790k molecules extracted from chemicalreactions in patent data. This dataset enables the development of foundationmodels for integrating information from multiple spectroscopic modalities,emulating the approach employed by human experts. Additionally, we providebenchmarks for evaluating single-modality tasks such as structure elucidation,predicting the spectra for a target molecule, and functional group predictions.This dataset has the potential automate structure elucidation, streamlining themolecular discovery pipeline from synthesis to structure determination. Thedataset and code for the benchmarks can be found athttps://rxn4chemistry.github.io/multimodal-spectroscopic-dataset.</description><author>Marvin Alberts, Oliver Schilter, Federico Zipoli, Nina Hartrampf, Teodoro Laino</author><pubDate>Tue, 29 Oct 2024 15:54:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.17492v2</guid></item><item><title>Benchmarking LLM Guardrails in Handling Multilingual Toxicity</title><link>http://arxiv.org/abs/2410.22153v1</link><description>With the ubiquity of Large Language Models (LLMs), guardrails have becomecrucial to detect and defend against toxic content. However, with theincreasing pervasiveness of LLMs in multilingual scenarios, their effectivenessin handling multilingual toxic inputs remains unclear. In this work, weintroduce a comprehensive multilingual test suite, spanning seven datasets andover ten languages, to benchmark the performance of state-of-the-artguardrails. We also investigates the resilience of guardrails against recentjailbreaking techniques, and assess the impact of in-context safety policiesand language resource availability on guardrails' performance. Our findingsshow that existing guardrails are still ineffective at handling multilingualtoxicity and lack robustness against jailbreaking prompts. This work aims toidentify the limitations of guardrails and to build a more reliable andtrustworthy LLMs in multilingual scenarios.</description><author>Yahan Yang, Soham Dan, Dan Roth, Insup Lee</author><pubDate>Tue, 29 Oct 2024 15:51:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22153v1</guid></item><item><title>Standardization Trends on Safety and Trustworthiness Technology for Advanced AI</title><link>http://arxiv.org/abs/2410.22151v1</link><description>Artificial Intelligence (AI) has rapidly evolved over the past decade and hasadvanced in areas such as language comprehension, image and video recognition,programming, and scientific reasoning. Recent AI technologies based on largelanguage models and foundation models are approaching or surpassing artificialgeneral intelligence. These systems demonstrate superior performance in complexproblem solving, natural language processing, and multi-domain tasks, and canpotentially transform fields such as science, industry, healthcare, andeducation. However, these advancements have raised concerns regarding thesafety and trustworthiness of advanced AI, including risks related touncontrollability, ethical conflicts, long-term socioeconomic impacts, andsafety assurance. Efforts are being expended to develop internationallyagreed-upon standards to ensure the safety and reliability of AI. This studyanalyzes international trends in safety and trustworthiness standardization foradvanced AI, identifies key areas for standardization, proposes futuredirections and strategies, and draws policy implications. The goal is tosupport the safe and trustworthy development of advanced AI and enhanceinternational competitiveness through effective standardization.</description><author>Jonghong Jeon</author><pubDate>Tue, 29 Oct 2024 15:50:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22151v1</guid></item><item><title>Shining a Light on Hurricane Damage Estimation via Nighttime Light Data: Pre-processing Matters</title><link>http://arxiv.org/abs/2410.22150v1</link><description>Amidst escalating climate change, hurricanes are inflicting severesocioeconomic impacts, marked by heightened economic losses and increaseddisplacement. Previous research utilized nighttime light data to predict theimpact of hurricanes on economic losses. However, prior work did not provide athorough analysis of the impact of combining different techniques forpre-processing nighttime light (NTL) data. Addressing this gap, our researchexplores a variety of NTL pre-processing techniques, including valuethresholding, built masking, and quality filtering and imputation, applied totwo distinct datasets, VSC-NTL and VNP46A2, at the zip code level. Experimentsevaluate the correlation of the denoised NTL data with economic damages ofCategory 4-5 hurricanes in Florida. They reveal that the quality masking andimputation technique applied to VNP46A2 show a substantial correlation witheconomic damage data.</description><author>Nancy Thomas, Saba Rahimi, Annita Vapsi, Cathy Ansell, Elizabeth Christie, Daniel Borrajo, Tucker Balch, Manuela Veloso</author><pubDate>Tue, 29 Oct 2024 15:48:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22150v1</guid></item><item><title>Capacity Control is an Effective Memorization Mitigation Mechanism in Text-Conditional Diffusion Models</title><link>http://arxiv.org/abs/2410.22149v1</link><description>In this work, we present compelling evidence that controlling model capacityduring fine-tuning can effectively mitigate memorization in diffusion models.Specifically, we demonstrate that adopting Parameter-Efficient Fine-Tuning(PEFT) within the pre-train fine-tune paradigm significantly reducesmemorization compared to traditional full fine-tuning approaches. Ourexperiments utilize the MIMIC dataset, which comprises image-text pairs ofchest X-rays and their corresponding reports. The results, evaluated through arange of memorization and generation quality metrics, indicate that PEFT notonly diminishes memorization but also enhances downstream generation quality.Additionally, PEFT methods can be seamlessly combined with existingmemorization mitigation techniques for further improvement. The code for ourexperiments is available at:https://github.com/Raman1121/Diffusion_Memorization_HPO</description><author>Raman Dutt, Pedro Sanchez, Ondrej Bohdal, Sotirios A. Tsaftaris, Timothy Hospedales</author><pubDate>Tue, 29 Oct 2024 15:47:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22149v1</guid></item><item><title>Benchmarking Counterfactual Image Generation</title><link>http://arxiv.org/abs/2403.20287v3</link><description>Generative AI has revolutionised visual content editing, empowering users toeffortlessly modify images and videos. However, not all edits are equal. Toperform realistic edits in domains such as natural image or medical imaging,modifications must respect causal relationships inherent to the data generationprocess. Such image editing falls into the counterfactual image generationregime. Evaluating counterfactual image generation is substantially complex:not only it lacks observable ground truths, but also requires adherence tocausal constraints. Although several counterfactual image generation methodsand evaluation metrics exist, a comprehensive comparison within a unifiedsetting is lacking. We present a comparison framework to thoroughly benchmarkcounterfactual image generation methods. We integrate all models that have beenused for the task at hand and expand them to novel datasets and causal graphs,demonstrating the superiority of Hierarchical VAEs across most datasets andmetrics. Our framework is implemented in a user-friendly Python package thatcan be extended to incorporate additional SCMs, causal methods, generativemodels, and datasets for the community to build on. Code:https://github.com/gulnazaki/counterfactual-benchmark.</description><author>Thomas Melistas, Nikos Spyrou, Nefeli Gkouti, Pedro Sanchez, Athanasios Vlontzos, Yannis Panagakis, Giorgos Papanastasiou, Sotirios A. Tsaftaris</author><pubDate>Tue, 29 Oct 2024 15:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.20287v3</guid></item><item><title>AmpleGCG-Plus: A Strong Generative Model of Adversarial Suffixes to Jailbreak LLMs with Higher Success Rates in Fewer Attempts</title><link>http://arxiv.org/abs/2410.22143v1</link><description>Although large language models (LLMs) are typically aligned, they remainvulnerable to jailbreaking through either carefully crafted prompts in naturallanguage or, interestingly, gibberish adversarial suffixes. However, gibberishtokens have received relatively less attention despite their success inattacking aligned LLMs. Recent work, AmpleGCG~\citep{liao2024amplegcg},demonstrates that a generative model can quickly produce numerous customizablegibberish adversarial suffixes for any harmful query, exposing a range ofalignment gaps in out-of-distribution (OOD) language spaces. To bring moreattention to this area, we introduce AmpleGCG-Plus, an enhanced version thatachieves better performance in fewer attempts. Through a series of exploratoryexperiments, we identify several training strategies to improve the learning ofgibberish suffixes. Our results, verified under a strict evaluation setting,show that it outperforms AmpleGCG on both open-weight and closed-source models,achieving increases in attack success rate (ASR) of up to 17\% in the white-boxsetting against Llama-2-7B-chat, and more than tripling ASR in the black-boxsetting against GPT-4. Notably, AmpleGCG-Plus jailbreaks the newer GPT-4oseries of models at similar rates to GPT-4, and, uncovers vulnerabilitiesagainst the recently proposed circuit breakers defense. We publicly releaseAmpleGCG-Plus along with our collected training datasets.</description><author>Vishal Kumar, Zeyi Liao, Jaylen Jones, Huan Sun</author><pubDate>Tue, 29 Oct 2024 15:40:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22143v1</guid></item><item><title>Lighten CARAFE: Dynamic Lightweight Upsampling with Guided Reassemble Kernels</title><link>http://arxiv.org/abs/2410.22139v1</link><description>As a fundamental operation in modern machine vision models, featureupsampling has been widely used and investigated in the literatures. An idealupsampling operation should be lightweight, with low computational complexity.That is, it can not only improve the overall performance but also not affectthe model complexity. Content-aware Reassembly of Features (CARAFE) is awell-designed learnable operation to achieve feature upsampling. Albeitencouraging performance achieved, this method requires generating large-scalekernels, which brings a mass of extra redundant parameters, and inherently haslimited scalability. To this end, we propose a lightweight upsamplingoperation, termed Dynamic Lightweight Upsampling (DLU) in this paper. Inparticular, it first constructs a small-scale source kernel space, and thensamples the large-scale kernels from the kernel space by introducing learnableguidance offsets, hence avoiding introducing a large collection of trainableparameters in upsampling. Experiments on several mainstream vision tasks showthat our DLU achieves comparable and even better performance to the originalCARAFE, but with much lower complexity, e.g., DLU requires 91% fewer parametersand at least 63% fewer FLOPs (Floating Point Operations) than CARAFE in thecase of 16x upsampling, but outperforms the CARAFE by 0.3% mAP in objectdetection. Code is available athttps://github.com/Fu0511/Dynamic-Lightweight-Upsampling.</description><author>Ruigang Fu, Qingyong Hu, Xiaohu Dong, Yinghui Gao, Biao Li, Ping Zhong</author><pubDate>Tue, 29 Oct 2024 15:35:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22139v1</guid></item><item><title>Hard-Negative Sampling for Contrastive Learning: Optimal Representation Geometry and Neural- vs Dimensional-Collapse</title><link>http://arxiv.org/abs/2311.05139v2</link><description>For a widely-studied data model and general loss and sample-hardeningfunctions we prove that the losses of Supervised Contrastive Learning (SCL),Hard-SCL (HSCL), and Unsupervised Contrastive Learning (UCL) are minimized byrepresentations that exhibit Neural-Collapse (NC), i.e., the class means forman Equiangular Tight Frame (ETF) and data from the same class are mapped to thesame representation. We also prove that for any representation mapping, theHSCL and Hard-UCL (HUCL) losses are lower bounded by the corresponding SCL andUCL losses. In contrast to existing literature, our theoretical results for SCLdo not require class-conditional independence of augmented views and work for ageneral loss function class that includes the widely used InfoNCE lossfunction. Moreover, our proofs are simpler, compact, and transparent. Similarto existing literature, our theoretical claims also hold for the practicalscenario where batching is used for optimization. We empirically demonstrate,for the first time, that Adam optimization (with batching) of HSCL and HUCLlosses with random initialization and suitable hardness levels can indeedconverge to the NC-geometry if we incorporate unit-ball or unit-sphere featurenormalization. Without incorporating hard-negatives or feature normalization,however, the representations learned via Adam suffer from Dimensional-Collapse(DC) and fail to attain the NC-geometry. These results exemplify the role ofhard-negative sampling in contrastive representation learning and we concludewith several open theoretical problems for future work. The code can be foundat \url{https://github.com/rjiang03/HCL/tree/main}</description><author>Ruijie Jiang, Thuan Nguyen, Shuchin Aeron, Prakash Ishwar</author><pubDate>Tue, 29 Oct 2024 15:33:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05139v2</guid></item><item><title>Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based Agents</title><link>http://arxiv.org/abs/2402.11208v2</link><description>Driven by the rapid development of Large Language Models (LLMs), LLM-basedagents have been developed to handle various real-world applications, includingfinance, healthcare, and shopping, etc. It is crucial to ensure the reliabilityand security of LLM-based agents during applications. However, the safetyissues of LLM-based agents are currently under-explored. In this work, we takethe first step to investigate one of the typical safety threats, backdoorattack, to LLM-based agents. We first formulate a general framework of agentbackdoor attacks, then we present a thorough analysis of different forms ofagent backdoor attacks. Specifically, compared with traditional backdoorattacks on LLMs that are only able to manipulate the user inputs and modeloutputs, agent backdoor attacks exhibit more diverse and covert forms: (1) Fromthe perspective of the final attacking outcomes, the agent backdoor attackercan not only choose to manipulate the final output distribution, but alsointroduce the malicious behavior in an intermediate reasoning step only, whilekeeping the final output correct. (2) Furthermore, the former category can bedivided into two subcategories based on trigger locations, in which thebackdoor trigger can either be hidden in the user query or appear in anintermediate observation returned by the external environment. We implement theabove variations of agent backdoor attacks on two typical agent tasks includingweb shopping and tool utilization. Extensive experiments show that LLM-basedagents suffer severely from backdoor attacks and such backdoor vulnerabilitycannot be easily mitigated by current textual backdoor defense algorithms. Thisindicates an urgent need for further research on the development of targeteddefenses against backdoor attacks on LLM-based agents. Warning: This paper maycontain biased content.</description><author>Wenkai Yang, Xiaohan Bi, Yankai Lin, Sishuo Chen, Jie Zhou, Xu Sun</author><pubDate>Tue, 29 Oct 2024 15:32:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11208v2</guid></item><item><title>ProMoE: Fast MoE-based LLM Serving using Proactive Caching</title><link>http://arxiv.org/abs/2410.22134v1</link><description>The promising applications of large language models are often constrained bythe limited GPU memory capacity available on edge devices. Mixture-of-Experts(MoE) models help mitigate this issue by activating only a subset of themodel's parameters during computation, allowing the unused parameters to beoffloaded to host memory and reducing overall GPU memory demand. However,existing cache-based offloading solutions handle cache misses reactively andsignificantly impact system performance. In this paper, we propose ProMoE, anovel proactive caching system that leverages intermediate model results topredict subsequent parameter usage. By proactively fetching experts in advance,ProMoE removes the loading time from the critical path and diminishes theperformance overhead of offloading. Our evaluations demonstrate that ProMoEachieves an average speedup of 2.13x and 2.84x in the prefill and decode stagesrespectively, compared to existing offloading solutions.</description><author>Xiaoniu Song, Zihang Zhong, Rong Chen</author><pubDate>Tue, 29 Oct 2024 15:31:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22134v1</guid></item><item><title>Lightweight Frequency Masker for Cross-Domain Few-Shot Semantic Segmentation</title><link>http://arxiv.org/abs/2410.22135v1</link><description>Cross-domain few-shot segmentation (CD-FSS) is proposed to first pre-trainthe model on a large-scale source-domain dataset, and then transfer the modelto data-scarce target-domain datasets for pixel-level segmentation. Thesignificant domain gap between the source and target datasets leads to a sharpdecline in the performance of existing few-shot segmentation (FSS) methods incross-domain scenarios. In this work, we discover an intriguing phenomenon:simply filtering different frequency components for target domains can lead toa significant performance improvement, sometimes even as high as 14% mIoU.Then, we delve into this phenomenon for an interpretation, and find suchimprovements stem from the reduced inter-channel correlation in feature maps,which benefits CD-FSS with enhanced robustness against domain gaps and largeractivated regions for segmentation. Based on this, we propose a lightweightfrequency masker, which further reduces channel correlations by anamplitude-phase-masker (APM) module and an Adaptive Channel Phase Attention(ACPA) module. Notably, APM introduces only 0.01% additional parameters butimproves the average performance by over 10%, and ACPA imports only 2.5%parameters but further improves the performance by over 1.5%, whichsignificantly surpasses the state-of-the-art CD-FSS methods.</description><author>Jintao Tong, Yixiong Zou, Yuhua Li, Ruixuan Li</author><pubDate>Tue, 29 Oct 2024 15:31:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.22135v1</guid></item></channel></rss>