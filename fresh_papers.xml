<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 27 Feb 2024 06:00:43 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning</title><link>http://arxiv.org/abs/2402.15506v2</link><description>Autonomous agents powered by large language models (LLMs) have garneredsignificant research attention. However, fully harnessing the potential of LLMsfor agent-based tasks presents inherent challenges due to the heterogeneousnature of diverse data sources featuring multi-turn trajectories. In thispaper, we introduce \textbf{AgentOhana} as a comprehensive solution to addressthese challenges. \textit{AgentOhana} aggregates agent trajectories fromdistinct environments, spanning a wide array of scenarios. It meticulouslystandardizes and unifies these trajectories into a consistent format,streamlining the creation of a generic data loader optimized for agenttraining. Leveraging the data unification, our training pipeline maintainsequilibrium across different data sources and preserves independent randomnessacross devices during dataset partitioning and model training. Additionally, wepresent \textbf{xLAM-v0.1}, a large action model tailored for AI agents, whichdemonstrates exceptional performance across various benchmarks.</description><author>Jianguo Zhang, Tian Lan, Rithesh Murthy, Zhiwei Liu, Weiran Yao, Juntao Tan, Thai Hoang, Liangwei Yang, Yihao Feng, Zuxin Liu, Tulika Awalgaonkar, Juan Carlos Niebles, Silvio Savarese, Shelby Heinecke, Huan Wang, Caiming Xiong</author><pubDate>Mon, 26 Feb 2024 18:24:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15506v2</guid></item><item><title>Robust agents learn causal world models</title><link>http://arxiv.org/abs/2402.10877v3</link><description>It has long been hypothesised that causal reasoning plays a fundamental rolein robust and general intelligence. However, it is not known if agents mustlearn causal models in order to generalise to new domains, or if otherinductive biases are sufficient. We answer this question, showing that anyagent capable of satisfying a regret bound under a large set of distributionalshifts must have learned an approximate causal model of the data generatingprocess, which converges to the true causal model for optimal agents. Wediscuss the implications of this result for several research areas includingtransfer learning and causal inference.</description><author>Jonathan Richens, Tom Everitt</author><pubDate>Mon, 26 Feb 2024 17:05:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10877v3</guid></item><item><title>Neural Implicit Swept Volume Models for Fast Collision Detection</title><link>http://arxiv.org/abs/2402.15281v2</link><description>Collision detection is one of the most time-consuming operations duringmotion planning. Thus, there is an increasing interest in exploring machinelearning techniques to speed up collision detection and sampling-based motionplanning. A recent line of research focuses on utilizing neural signed distancefunctions of either the robot geometry or the swept volume of the robot motion.Building on this, we present a novel neural implicit swept volume model tocontinuously represent arbitrary motions parameterized by their start and goalconfigurations. This allows to quickly compute signed distances for any pointin the task space to the robot motion. Further, we present an algorithmcombining the speed of the deep learning-based signed distance computationswith the strong accuracy guarantees of geometric collision checkers. Wevalidate our approach in simulated and real-world robotic experiments, anddemonstrate that it is able to speed up a commercial bin picking application.</description><author>Dominik Joho, Jonas Schwinn, Kirill Safronov</author><pubDate>Mon, 26 Feb 2024 16:26:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15281v2</guid></item><item><title>Convolutional Deep Kernel Machines</title><link>http://arxiv.org/abs/2309.09814v3</link><description>Standard infinite-width limits of neural networks sacrifice the ability forintermediate layers to learn representations from data. Recent work (A theoryof representation learning gives a deep generalisation of kernel methods, Yanget al. 2023) modified the Neural Network Gaussian Process (NNGP) limit ofBayesian neural networks so that representation learning is retained.Furthermore, they found that applying this modified limit to a deep Gaussianprocess gives a practical learning algorithm which they dubbed the deep kernelmachine (DKM). However, they only considered the simplest possible setting:regression in small, fully connected networks with e.g. 10 input features.Here, we introduce convolutional deep kernel machines. This required us todevelop a novel inter-domain inducing point approximation, as well asintroducing and experimentally assessing a number of techniques not previouslyseen in DKMs, including analogues to batch normalisation, differentlikelihoods, and different types of top-layer. The resulting model trains inroughly 77 GPU hours, achieving around 99% test accuracy on MNIST, 72% onCIFAR-100, and 92.7% on CIFAR-10, which is SOTA for kernel methods.</description><author>Edward Milsom, Ben Anson, Laurence Aitchison</author><pubDate>Mon, 26 Feb 2024 16:11:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09814v3</guid></item><item><title>Q-FOX Learning: Breaking Tradition in Reinforcement Learning</title><link>http://arxiv.org/abs/2402.16562v1</link><description>Reinforcement learning (RL) is a subset of artificial intelligence (AI) whereagents learn the best action by interacting with the environment, making itsuitable for tasks that do not require labeled data or direct supervision.Hyperparameters (HP) tuning refers to choosing the best parameter that leads tooptimal solutions in RL algorithms. Manual or random tuning of the HP may be acrucial process because variations in this parameter lead to changes in theoverall learning aspects and different rewards. In this paper, a novel andautomatic HP-tuning method called Q-FOX is proposed. This uses both the FOXoptimizer, a new optimization method inspired by nature that mimics red foxes'hunting behavior, and the commonly used, easy-to-implement RL Q-learningalgorithm to solve the problem of HP tuning. Moreover, a new objective functionis proposed which prioritizes the reward over the mean squared error (MSE) andlearning time (steps). Q-FOX has been evaluated on two OpenAI Gym environmentcontrol tasks: Cart Pole and Frozen Lake. It exposed greater cumulative rewardsthan HP tuning with other optimizers, such as PSO, GA, Bee, or randomlyselected HP. The cumulative reward for the Cart Pole task was 32.08, and forthe Frozen Lake task was 0.95. Despite the robustness of Q-FOX, it haslimitations. It cannot be used directly in real-word problems before choosingthe HP in a simulation environment because its processes work iteratively,making it time-consuming. The results indicate that Q-FOX has played anessential role in HP tuning for RL algorithms to effectively solve differentcontrol tasks.</description><author>Mahmood Alqaseer, Yossra H. Ali, Tarik A. Rashid</author><pubDate>Mon, 26 Feb 2024 13:39:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16562v1</guid></item><item><title>QuasiNet: a neural network with trainable product layers</title><link>http://arxiv.org/abs/2401.06137v2</link><description>Classical neural networks achieve only limited convergence in hard problemssuch as XOR or parity when the number of hidden neurons is small. With themotivation to improve the success rate of neural networks in these problems, wepropose a new neural network model inspired by existing neural network modelswith so called product neurons and a learning rule derived from classical errorbackpropagation, which elegantly solves the problem of mutually exclusivesituations. Unlike existing product neurons, which have weights that are presetand not adaptable, our product layers of neurons also do learn. We tested themodel and compared its success rate to a classical multilayer perceptron in theaforementioned problems as well as in other hard problems such as the twospirals. Our results indicate that our model is clearly more successful thanthe classical MLP and has the potential to be used in many tasks andapplications.</description><author>Kristína Malinovská, Slavomír Holenda, Ľudovít Malinovský</author><pubDate>Mon, 26 Feb 2024 13:10:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06137v2</guid></item><item><title>Beyond Accuracy: An Empirical Study on Unit Testing in Open-source Deep Learning Projects</title><link>http://arxiv.org/abs/2402.16546v1</link><description>Deep Learning (DL) models have rapidly advanced, focusing on achieving highperformance through testing model accuracy and robustness. However, it isunclear whether DL projects, as software systems, are tested thoroughly orfunctionally correct when there is a need to treat and test them like othersoftware systems. Therefore, we empirically study the unit tests in open-sourceDL projects, analyzing 9,129 projects from GitHub. We find that: 1) unit testedDL projects have positive correlation with the open-source project metrics andhave a higher acceptance rate of pull requests, 2) 68% of the sampled DLprojects are not unit tested at all, 3) the layer and utilities (utils) of DLmodels have the most unit tests. Based on these findings and previous researchoutcomes, we built a mapping taxonomy between unit tests and faults in DLprojects. We discuss the implications of our findings for developers andresearchers and highlight the need for unit testing in open-source DL projectsto ensure their reliability and stability. The study contributes to thiscommunity by raising awareness of the importance of unit testing in DL projectsand encouraging further research in this area.</description><author>Han Wang, Sijia Yu, Chunyang Chen, Burak Turhan, Xiaodong Zhu</author><pubDate>Mon, 26 Feb 2024 13:08:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16546v1</guid></item><item><title>Label Learning Method Based on Tensor Projection</title><link>http://arxiv.org/abs/2402.16544v1</link><description>Multi-view clustering method based on anchor graph has been widely concerneddue to its high efficiency and effectiveness. In order to avoidpost-processing, most of the existing anchor graph-based methods learnbipartite graphs with connected components. However, such methods have highrequirements on parameters, and in some cases it may not be possible to obtainbipartite graphs with clear connected components. To end this, we propose alabel learning method based on tensor projection (LLMTP). Specifically, weproject anchor graph into the label space through an orthogonal projectionmatrix to obtain cluster labels directly. Considering that the spatialstructure information of multi-view data may be ignored to a certain extentwhen projected in different views separately, we extend the matrix projectiontransformation to tensor projection, so that the spatial structure informationbetween views can be fully utilized. In addition, we introduce the tensorSchatten $p$-norm regularization to make the clustering label matrices ofdifferent views as consistent as possible. Extensive experiments have provedthe effectiveness of the proposed method.</description><author>Jing Li, Quanxue Gao, Qianqian Wang, Cheng Deng, Deyan Xie</author><pubDate>Mon, 26 Feb 2024 13:03:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16544v1</guid></item><item><title>Model-based deep reinforcement learning for accelerated learning from flow simulations</title><link>http://arxiv.org/abs/2402.16543v1</link><description>In recent years, deep reinforcement learning has emerged as a technique tosolve closed-loop flow control problems. Employing simulation-basedenvironments in reinforcement learning enables a priori end-to-end optimizationof the control system, provides a virtual testbed for safety-critical controlapplications, and allows to gain a deep understanding of the controlmechanisms. While reinforcement learning has been applied successfully in anumber of rather simple flow control benchmarks, a major bottleneck towardreal-world applications is the high computational cost and turnaround time offlow simulations. In this contribution, we demonstrate the benefits ofmodel-based reinforcement learning for flow control applications. Specifically,we optimize the policy by alternating between trajectories sampled from flowsimulations and trajectories sampled from an ensemble of environment models.The model-based learning reduces the overall training time by up to $85\%$ forthe fluidic pinball test case. Even larger savings are expected for moredemanding flow simulations.</description><author>Andre Weiner, Janis Geise</author><pubDate>Mon, 26 Feb 2024 13:01:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16543v1</guid></item><item><title>RoboGrind: Intuitive and Interactive Surface Treatment with Industrial Robots</title><link>http://arxiv.org/abs/2402.16542v1</link><description>Surface treatment tasks such as grinding, sanding or polishing are a vitalstep of the value chain in many industries, but are notoriously challenging toautomate. We present RoboGrind, an integrated system for the intuitive,interactive automation of surface treatment tasks with industrial robots. Itcombines a sophisticated 3D perception pipeline for surface scanning andautomatic defect identification, an interactive voice-controlled wizard systemfor the AI-assisted bootstrapping and parameterization of robot programs, andan automatic planning and execution pipeline for force-controlled roboticsurface treatment. RoboGrind is evaluated both under laboratory and real-worldconditions in the context of refabricating fiberglass wind turbine blades.</description><author>Benjamin Alt, Florian Stöckl, Silvan Müller, Christopher Braun, Julian Raible, Saad Alhasan, Oliver Rettig, Lukas Ringle, Darko Katic, Rainer Jäkel, Michael Beetz, Marcus Strand, Marco F. Huber</author><pubDate>Mon, 26 Feb 2024 13:01:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16542v1</guid></item><item><title>Integrating Large Language Models with Graphical Session-Based Recommendation</title><link>http://arxiv.org/abs/2402.16539v1</link><description>With the rapid development of Large Language Models (LLMs), variousexplorations have arisen to utilize LLMs capability of context understanding onrecommender systems. While pioneering strategies have primarily transformedtraditional recommendation tasks into challenges of natural languagegeneration, there has been a relative scarcity of exploration in the domain ofsession-based recommendation (SBR) due to its specificity. SBR has beenprimarily dominated by Graph Neural Networks, which have achieved manysuccessful outcomes due to their ability to capture both the implicit andexplicit relationships between adjacent behaviors. The structural nature ofgraphs contrasts with the essence of natural language, posing a significantadaptation gap for LLMs. In this paper, we introduce large language models withgraphical Session-Based recommendation, named LLMGR, an effective frameworkthat bridges the aforementioned gap by harmoniously integrating LLMs with GraphNeural Networks (GNNs) for SBR tasks. This integration seeks to leverage thecomplementary strengths of LLMs in natural language understanding and GNNs inrelational data processing, leading to a more powerful session-basedrecommender system that can understand and recommend items within a session.Moreover, to endow the LLM with the capability to empower SBR tasks, we designa series of prompts for both auxiliary and major instruction tuning tasks.These prompts are crafted to assist the LLM in understanding graph-structureddata and align textual information with nodes, effectively translating nuanceduser interactions into a format that can be understood and utilized by LLMarchitectures. Extensive experiments on three real-world datasets demonstratethat LLMGR outperforms several competitive baselines, indicating itseffectiveness in enhancing SBR tasks and its potential as a research directionfor future exploration.</description><author>Naicheng Guo, Hongwei Cheng, Qianqiao Liang, Linxun Chen, Bing Han</author><pubDate>Mon, 26 Feb 2024 12:55:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16539v1</guid></item><item><title>Multi-scale Traffic Pattern Bank for Cross-city Few-shot Traffic Forecasting</title><link>http://arxiv.org/abs/2402.00397v2</link><description>Traffic forecasting is crucial for intelligent transportation systems (ITS),aiding in efficient resource allocation and effective traffic control. However,its effectiveness often relies heavily on abundant traffic data, while manycities lack sufficient data due to limited device support, posing a significantchallenge for traffic forecasting. Recognizing this challenge, we have made anoteworthy observation: traffic patterns exhibit similarities across diversecities. Building on this key insight, we propose a solution for the cross-cityfew-shot traffic forecasting problem called Multi-scale Traffic Pattern Bank(MTPB). Primarily, MTPB initiates its learning process by leveraging data-richsource cities, effectively acquiring comprehensive traffic knowledge through aspatial-temporal-aware pre-training process. Subsequently, the frameworkemploys advanced clustering techniques to systematically generate a multi-scaletraffic pattern bank derived from the learned knowledge. Next, the traffic dataof the data-scarce target city could query the traffic pattern bank,facilitating the aggregation of meta-knowledge. This meta-knowledge, in turn,assumes a pivotal role as a robust guide in subsequent processes involvinggraph reconstruction and forecasting. Empirical assessments conducted onreal-world traffic datasets affirm the superior performance of MTPB, surpassingexisting methods across various categories and exhibiting numerous attributesconducive to the advancement of cross-city few-shot forecasting methodologies.The code is available in https://github.com/zhyliu00/MTPB.</description><author>Zhanyu Liu, Guanjie Zheng, Yanwei Yu</author><pubDate>Mon, 26 Feb 2024 12:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00397v2</guid></item><item><title>3D Kinematics Estimation from Video with a Biomechanical Model and Synthetic Training Data</title><link>http://arxiv.org/abs/2402.13172v2</link><description>Accurate 3D kinematics estimation of human body is crucial in variousapplications for human health and mobility, such as rehabilitation, injuryprevention, and diagnosis, as it helps to understand the biomechanical loadingexperienced during movement. Conventional marker-based motion capture isexpensive in terms of financial investment, time, and the expertise required.Moreover, due to the scarcity of datasets with accurate annotations, existingmarkerless motion capture methods suffer from challenges including unreliable2D keypoint detection, limited anatomic accuracy, and low generalizationcapability. In this work, we propose a novel biomechanics-aware network thatdirectly outputs 3D kinematics from two input views with consideration ofbiomechanical prior and spatio-temporal information. To train the model, wecreate synthetic dataset ODAH with accurate kinematics annotations generated byaligning the body mesh from the SMPL-X model and a full-body OpenSim skeletalmodel. Our extensive experiments demonstrate that the proposed approach, onlytrained on synthetic data, outperforms previous state-of-the-art methods whenevaluated across multiple datasets, revealing a promising direction forenhancing video-based human motion capture.</description><author>Zhi-Yi Lin, Bofan Lyu, Judith Cueto Fernandez, Eline van der Kruk, Ajay Seth, Xucong Zhang</author><pubDate>Mon, 26 Feb 2024 12:53:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13172v2</guid></item><item><title>Knowledge Sharing in Manufacturing using Large Language Models: User Evaluation and Model Benchmarking</title><link>http://arxiv.org/abs/2401.05200v2</link><description>Recent advances in natural language processing enable more intelligent waysto support knowledge sharing in factories. In manufacturing, operatingproduction lines has become increasingly knowledge-intensive, putting strain ona factory's capacity to train and support new operators. This paper introducesa Large Language Model (LLM)-based system designed to retrieve information fromthe extensive knowledge contained in factory documentation and knowledge sharedby expert operators. The system aims to efficiently answer queries fromoperators and facilitate the sharing of new knowledge. We conducted a userstudy at a factory to assess its potential impact and adoption, elicitingseveral perceived benefits, namely, enabling quicker information retrieval andmore efficient resolution of issues. However, the study also highlighted apreference for learning from a human expert when such an option is available.Furthermore, we benchmarked several commercial and open-sourced LLMs for thissystem. The current state-of-the-art model, GPT-4, consistently outperformedits counterparts, with open-source models trailing closely, presenting anattractive option given their data privacy and customization benefits. Insummary, this work offers preliminary insights and a system design forfactories considering using LLM tools for knowledge management.</description><author>Samuel Kernan Freire, Chaofan Wang, Mina Foosherian, Stefan Wellsandt, Santiago Ruiz-Arenas, Evangelos Niforatos</author><pubDate>Mon, 26 Feb 2024 12:46:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.05200v2</guid></item><item><title>Airavata: Introducing Hindi Instruction-tuned LLM</title><link>http://arxiv.org/abs/2401.15006v2</link><description>We announce the initial release of "Airavata," an instruction-tuned LLM forHindi. Airavata was created by fine-tuning OpenHathi with diverse,instruction-tuning Hindi datasets to make it better suited for assistive tasks.Along with the model, we also share the IndicInstruct dataset, which is acollection of diverse instruction-tuning datasets to enable further researchfor Indic LLMs. Additionally, we present evaluation benchmarks and a frameworkfor assessing LLM performance across tasks in Hindi. Currently, Airavatasupports Hindi, but we plan to expand this to all 22 scheduled Indic languages.You can access all artifacts at https://ai4bharat.github.io/airavata.</description><author>Jay Gala, Thanmay Jayakumar, Jaavid Aktar Husain, Aswanth Kumar M, Mohammed Safi Ur Rahman Khan, Diptesh Kanojia, Ratish Puduppully, Mitesh M. Khapra, Raj Dabre, Rudra Murthy, Anoop Kunchukuttan</author><pubDate>Mon, 26 Feb 2024 12:17:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15006v2</guid></item><item><title>Vygotsky Distance: Measure for Benchmark Task Similarity</title><link>http://arxiv.org/abs/2402.14890v2</link><description>Evaluation plays a significant role in modern natural language processing.Most modern NLP benchmarks consist of arbitrary sets of tasks that neitherguarantee any generalization potential for the model once applied outside thetest set nor try to minimize the resource consumption needed for modelevaluation. This paper presents a theoretical instrument and a practicalalgorithm to calculate similarity between benchmark tasks, we call thissimilarity measure "Vygotsky distance". The core idea of this similaritymeasure is that it is based on relative performance of the "students" on agiven task, rather that on the properties of the task itself. If two tasks areclose to each other in terms of Vygotsky distance the models tend to havesimilar relative performance on them. Thus knowing Vygotsky distance betweentasks one can significantly reduce the number of evaluation tasks whilemaintaining a high validation quality. Experiments on various benchmarks,including GLUE, SuperGLUE, CLUE, and RussianSuperGLUE, demonstrate that a vastmajority of NLP benchmarks could be at least 40% smaller in terms of the tasksincluded. Most importantly, Vygotsky distance could also be used for thevalidation of new tasks thus increasing the generalization potential of thefuture NLP models.</description><author>Maxim K. Surkov, Ivan P. Yamshchikov</author><pubDate>Mon, 26 Feb 2024 12:09:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14890v2</guid></item><item><title>RepairLLaMA: Efficient Representations and Fine-Tuned Adapters for Program Repair</title><link>http://arxiv.org/abs/2312.15698v2</link><description>Automated Program Repair (APR) has evolved significantly with the advent ofLarge Language Models (LLMs). Fine-tuning LLMs for program repair is a recentavenue of research, with many dimensions which have not been explored. Existingwork mostly fine-tunes LLMs with naive code representations and isfundamentally limited in its ability to fine-tune larger LLMs. To address thisproblem, we propose RepairLLaMA, a novel program repair approach that combines1) code representations for APR and 2) the state-of-the-art parameter-efficientLLM fine-tuning technique called LoRA. This results in RepairLLaMA producing ahighly effective `program repair adapter' for fixing bugs with language models.Our experiments demonstrate the validity of both concepts. First, fine-tuningadapters with program repair specific code representations enables the model touse meaningful repair signals. Second, parameter-efficient fine-tuning helpsfine-tuning to converge and contributes to the effectiveness of the repairadapter to fix data-points outside the fine-tuning data distribution. Overall,RepairLLaMA correctly fixes 125 Defects4J v2 and 82 HumanEval-Java bugs,outperforming all baselines.</description><author>André Silva, Sen Fang, Martin Monperrus</author><pubDate>Mon, 26 Feb 2024 12:03:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15698v2</guid></item><item><title>SDGE: Stereo Guided Depth Estimation for 360$^\circ$ Camera Sets</title><link>http://arxiv.org/abs/2402.11791v2</link><description>Depth estimation is a critical technology in autonomous driving, andmulti-camera systems are often used to achieve a 360$^\circ$ perception. These360$^\circ$ camera sets often have limited or low-quality overlap regions,making multi-view stereo methods infeasible for the entire image.Alternatively, monocular methods may not produce consistent cross-viewpredictions. To address these issues, we propose the Stereo Guided DepthEstimation (SGDE) method, which enhances depth estimation of the full image byexplicitly utilizing multi-view stereo results on the overlap. We suggestbuilding virtual pinhole cameras to resolve the distortion problem of fisheyecameras and unify the processing for the two types of 360$^\circ$ cameras. Forhandling the varying noise on camera poses caused by unstable movement, theapproach employs a self-calibration method to obtain highly accurate relativeposes of the adjacent cameras with minor overlap. These enable the use ofrobust stereo methods to obtain high-quality depth prior in the overlap region.This prior serves not only as an additional input but also as pseudo-labelsthat enhance the accuracy of depth estimation methods and improve cross-viewprediction consistency. The effectiveness of SGDE is evaluated on one fisheyecamera dataset, Synthetic Urban, and two pinhole camera datasets, DDAD andnuScenes. Our experiments demonstrate that SGDE is effective for bothsupervised and self-supervised depth estimation, and highlight the potential ofour method for advancing downstream autonomous driving technologies, such as 3Dobject detection and occupancy prediction.</description><author>Jialei Xu, Wei Yin, Dong Gong, Xianming Liu, Junjun Jiang, Xiangyang Ji</author><pubDate>Mon, 26 Feb 2024 12:01:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11791v2</guid></item><item><title>Towards Faithful and Robust LLM Specialists for Evidence-Based Question-Answering</title><link>http://arxiv.org/abs/2402.08277v3</link><description>Advances towards more faithful and traceable answers of Large Language Models(LLMs) are crucial for various research and practical endeavors. One avenue inreaching this goal is basing the answers on reliable sources. However, thisEvidence-Based QA has proven to work insufficiently with LLMs in terms ofciting the correct sources (source quality) and truthfully representing theinformation within sources (answer attributability). In this work, wesystematically investigate how to robustly fine-tune LLMs for better sourcequality and answer attributability. Specifically, we introduce a datageneration pipeline with automated data quality filters, which can synthesizediversified high-quality training and testing data at scale. We furtherintroduce four test sets to benchmark the robustness of fine-tuned specialistmodels. Extensive evaluation shows that fine-tuning on synthetic data improvesperformance on both in- and out-of-distribution. Furthermore, we show that dataquality, which can be drastically improved by proposed quality filters, mattersmore than quantity in improving Evidence-Based QA.</description><author>Tobias Schimanski, Jingwei Ni, Mathias Kraus, Elliott Ash, Markus Leippold</author><pubDate>Mon, 26 Feb 2024 11:59:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08277v3</guid></item><item><title>Discovering Artificial Viscosity Models for Discontinuous Galerkin Approximation of Conservation Laws using Physics-Informed Machine Learning</title><link>http://arxiv.org/abs/2402.16517v1</link><description>Finite element-based high-order solvers of conservation laws offer largeaccuracy but face challenges near discontinuities due to the Gibbs phenomenon.Artificial viscosity is a popular and effective solution to this problem basedon physical insight. In this work, we present a physics-informed machinelearning algorithm to automate the discovery of artificial viscosity models ina non-supervised paradigm. The algorithm is inspired by reinforcement learningand trains a neural network acting cell-by-cell (the viscosity model) byminimizing a loss defined as the difference with respect to a referencesolution thanks to automatic differentiation. This enables a dataset-freetraining procedure. We prove that the algorithm is effective by integrating itinto a state-of-the-art Runge-Kutta discontinuous Galerkin solver. We showcaseseveral numerical tests on scalar and vectorial problems, such as Burgers' andEuler's equations in one and two dimensions. Results demonstrate that theproposed approach trains a model that is able to outperform classical viscositymodels. Moreover, we show that the learnt artificial viscosity model is able togeneralize across different problems and parameters.</description><author>Matteo Caldana, Paola F. Antonietti, Luca Dede'</author><pubDate>Mon, 26 Feb 2024 11:58:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16517v1</guid></item><item><title>Generative Pretrained Hierarchical Transformer for Time Series Forecasting</title><link>http://arxiv.org/abs/2402.16516v1</link><description>Recent efforts have been dedicated to enhancing time series forecastingaccuracy by introducing advanced network architectures and self-supervisedpretraining strategies. Nevertheless, existing approaches still exhibit twocritical drawbacks. Firstly, these methods often rely on a single dataset fortraining, limiting the model's generalizability due to the restricted scale ofthe training data. Secondly, the one-step generation schema is widely followed,which necessitates a customized forecasting head and overlooks the temporaldependencies in the output series, and also leads to increased training costsunder different horizon length settings. To address these issues, we propose a novel generative pretrainedhierarchical transformer architecture for forecasting, named GPHT. There aretwo aspects of key designs in GPHT. On the one hand, we advocate forconstructing a mixed dataset for pretraining our model, comprising variousdatasets from diverse data scenarios. This approach significantly expands thescale of training data, allowing our model to uncover commonalities in timeseries data and facilitating improved transfer to specific datasets. On theother hand, GPHT employs an auto-regressive forecasting approach under thechannel-independent assumption, effectively modeling temporal dependencies inthe output series. Importantly, no customized forecasting head is required,enabling a single model to forecast at arbitrary horizon settings. We conductsufficient experiments on eight datasets with mainstream self-supervisedpretraining models and supervised models. The results demonstrated that GPHTsurpasses the baseline models across various fine-tuning and zero/few-shotlearning settings in the traditional long-term forecasting task, providingsupport for verifying the feasibility of pretrained time series large models.</description><author>Zhiding Liu, Jiqian Yang, Mingyue Cheng, Yucong Luo, Zhi Li</author><pubDate>Mon, 26 Feb 2024 11:54:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16516v1</guid></item><item><title>Mafin: Enhancing Black-Box Embeddings with Model Augmented Fine-Tuning</title><link>http://arxiv.org/abs/2402.12177v2</link><description>Retrieval Augmented Generation (RAG) has emerged as an effective solution formitigating hallucinations in Large Language Models (LLMs). The retrieval stagein RAG typically involves a pre-trained embedding model, which converts queriesand passages into vectors to capture their semantics. However, a standardpre-trained embedding model may exhibit sub-optimal performance when applied tospecific domain knowledge, necessitating fine-tuning. This paper addressesscenarios where the embeddings are only available from a black-box model. Weintroduce Model augmented fine-tuning (Mafin) -- a novel approach forfine-tuning a black-box embedding model by augmenting it with a trainableembedding model. Our results demonstrate that Mafin significantly enhances theperformance of the black-box embeddings by only requiring the training of asmall augmented model. We validate the effectiveness of our method on bothlabeled and unlabeled datasets, illustrating its broad applicability andefficiency.</description><author>Mingtian Zhang, Shawn Lan, Peter Hayes, David Barber</author><pubDate>Mon, 26 Feb 2024 11:54:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12177v2</guid></item><item><title>LLM-based Privacy Data Augmentation Guided by Knowledge Distillation with a Distribution Tutor for Medical Text Classification</title><link>http://arxiv.org/abs/2402.16515v1</link><description>As sufficient data are not always publically accessible for model training,researchers exploit limited data with advanced learning algorithms or expandthe dataset via data augmentation (DA). Conducting DA in private domainrequires private protection approaches (i.e. anonymization and perturbation),but those methods cannot provide protection guarantees. Differential privacy(DP) learning methods theoretically bound the protection but are not skilled atgenerating pseudo text samples with large models. In this paper, we transferDP-based pseudo sample generation task to DP-based generated samplesdiscrimination task, where we propose a DP-based DA method with a LLM and aDP-based discriminator for text classification on private domains. We constructa knowledge distillation model as the DP-based discriminator: teacher models,accessing private data, teaches students how to select private samples withcalibrated noise to achieve DP. To constrain the distribution of DA'sgeneration, we propose a DP-based tutor that models the noised privatedistribution and controls samples' generation with a low privacy cost. Wetheoretically analyze our model's privacy protection and empirically verify ourmodel.</description><author>Yiping Song, Juhua Zhang, Zhiliang Tian, Yuxin Yang, Minlie Huang, Dongsheng Li</author><pubDate>Mon, 26 Feb 2024 11:52:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16515v1</guid></item><item><title>Enhancement of 3D Camera Synthetic Training Data with Noise Models</title><link>http://arxiv.org/abs/2402.16514v1</link><description>The goal of this paper is to assess the impact of noise in 3D camera-captureddata by modeling the noise of the imaging process and applying it on synthetictraining data. We compiled a dataset of specifically constructed scenes toobtain a noise model. We specifically model lateral noise, affecting theposition of captured points in the image plane, and axial noise, affecting theposition along the axis perpendicular to the image plane. The estimated modelscan be used to emulate noise in synthetic training data. The added benefit ofadding artificial noise is evaluated in an experiment with rendered data forobject segmentation. We train a series of neural networks with varying levelsof noise in the data and measure their ability to generalize on real data. Theresults show that using too little or too much noise can hurt the networks'performance indicating that obtaining a model of noise from real scanners isbeneficial for synthetic data generation.</description><author>Katarína Osvaldová, Lukáš Gajdošech, Viktor Kocur, Martin Madaras</author><pubDate>Mon, 26 Feb 2024 11:50:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16514v1</guid></item><item><title>SADMoE: Exploiting Activation Sparsity with Dynamic-k Gating</title><link>http://arxiv.org/abs/2310.04361v2</link><description>Transformer models, despite their impressive performance, often facepractical limitations due to their high computational requirements. At the sametime, such models exhibit significant activation sparsity, which can beleveraged to reduce the inference cost by transforming parts of the networkinto Mixture-of-Experts (MoE) layers. However, despite the crucial role ofactivation sparsity, its impact on this process remains unexplored. In thispaper, we enhance the efficiency of MoE conversion through activation sparsityenforcement. Moreover, motivated by the high variance in the number ofactivated neurons, we propose a more effective dynamic-k expert selection rulethat adjusts the number of executed experts on a per-token basis. Finally, weextend this approach to multi-head attention projections, which results in evenfurther savings. The proposed method, Sparsified Activation Dynamic-kMixture-of-Experts (SADMoE), outperforms existing approaches on common NLP andvision tasks, allowing us to save up to 60% of inference cost withoutsignificantly affecting model performance.</description><author>Filip Szatkowski, Bartosz Wójcik, Mikołaj Piórczyński, Kamil Adamczewski</author><pubDate>Mon, 26 Feb 2024 11:46:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04361v2</guid></item><item><title>Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision</title><link>http://arxiv.org/abs/2402.16508v1</link><description>Cross-lingual question answering (CLQA) is a complex problem, comprisingcross-lingual retrieval from a multilingual knowledge base, followed by answergeneration either in English or the query language. Both steps are usuallytackled by separate models, requiring substantial annotated datasets, andtypically auxiliary resources, like machine translation systems to bridgebetween languages. In this paper, we show that CLQA can be addressed using asingle encoder-decoder model. To effectively train this model, we propose aself-supervised method based on exploiting the cross-lingual link structurewithin Wikipedia. We demonstrate how linked Wikipedia pages can be used tosynthesise supervisory signals for cross-lingual retrieval, through a form ofcloze query, and generate more natural queries to supervise answer generation.Together, we show our approach, \texttt{CLASS}, outperforms comparable methodson both supervised and zero-shot language adaptation settings, including thoseusing machine translation.</description><author>Fan Jiang, Tom Drummond, Trevor Cohn</author><pubDate>Mon, 26 Feb 2024 11:42:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16508v1</guid></item><item><title>Stochastic Conditional Diffusion Models for Semantic Image Synthesis</title><link>http://arxiv.org/abs/2402.16506v1</link><description>Semantic image synthesis (SIS) is a task to generate realistic imagescorresponding to semantic maps (labels). It can be applied to diversereal-world practices such as photo editing or content creation. However, inreal-world applications, SIS often encounters noisy user inputs. To addressthis, we propose Stochastic Conditional Diffusion Model (SCDM), which is arobust conditional diffusion model that features novel forward and generationprocesses tailored for SIS with noisy labels. It enhances robustness bystochastically perturbing the semantic label maps through Label Diffusion,which diffuses the labels with discrete diffusion. Through the diffusion oflabels, the noisy and clean semantic maps become similar as the timestepincreases, eventually becoming identical at $t=T$. This facilitates thegeneration of an image close to a clean image, enabling robust generation.Furthermore, we propose a class-wise noise schedule to differentially diffusethe labels depending on the class. We demonstrate that the proposed methodgenerates high-quality samples through extensive experiments and analyses onbenchmark datasets, including a novel experimental setup simulating humanerrors during real-world applications.</description><author>Juyeon Ko, Inho Kong, Hyunwoo J. Kim</author><pubDate>Mon, 26 Feb 2024 11:41:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16506v1</guid></item><item><title>Memory GAPS: Would LLM pass the Tulving Test?</title><link>http://arxiv.org/abs/2402.16505v1</link><description>The Tulving Test was designed to investigate memory performance inrecognition and recall tasks. Its results help assess the relevance of the"Synergistic Ecphory Model" of memory and similar RK paradigms in humanperformance. This paper starts investigating whether the more thanforty-year-old framework sheds some light on LLMs' acts of remembering.</description><author>Jean-Marie Chauvet</author><pubDate>Mon, 26 Feb 2024 11:40:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16505v1</guid></item><item><title>On the Tip of the Tongue: Analyzing Conceptual Representation in Large Language Models with Reverse-Dictionary Probe</title><link>http://arxiv.org/abs/2402.14404v2</link><description>Probing and enhancing large language models' reasoning capacity remains acrucial open question. Here we re-purpose the reverse dictionary task as a casestudy to probe LLMs' capacity for conceptual inference. We use in-contextlearning to guide the models to generate the term for an object concept impliedin a linguistic description. Models robustly achieve high accuracy in thistask, and their representation space encodes information about objectcategories and fine-grained features. Further experiments suggest that theconceptual inference ability as probed by the reverse-dictionary task predictsmodel's general reasoning performance across multiple benchmarks, despitesimilar syntactic generalization behaviors across models. Explorative analysessuggest that prompting LLMs with description$\Rightarrow$word examples mayinduce generalization beyond surface-level differences in task construals andfacilitate models on broader commonsense reasoning problems.</description><author>Ningyu Xu, Qi Zhang, Menghan Zhang, Peng Qian, Xuanjing Huang</author><pubDate>Mon, 26 Feb 2024 11:40:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14404v2</guid></item><item><title>Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Probabilistic Interpretations</title><link>http://arxiv.org/abs/2401.14142v2</link><description>Existing methods, such as concept bottleneck models (CBMs), have beensuccessful in providing concept-based interpretations for black-box deeplearning models. They typically work by predicting concepts given the input andthen predicting the final class label given the predicted concepts. However,(1) they often fail to capture the high-order, nonlinear interaction betweenconcepts, e.g., correcting a predicted concept (e.g., "yellow breast") does nothelp correct highly correlated concepts (e.g., "yellow belly"), leading tosuboptimal final accuracy; (2) they cannot naturally quantify the complexconditional dependencies between different concepts and class labels (e.g., foran image with the class label "Kentucky Warbler" and a concept "black bill",what is the probability that the model correctly predicts another concept"black crown"), therefore failing to provide deeper insight into how ablack-box model works. In response to these limitations, we proposeEnergy-based Concept Bottleneck Models (ECBMs). Our ECBMs use a set of neuralnetworks to define the joint energy of candidate (input, concept, class)tuples. With such a unified interface, prediction, concept correction, andconditional dependency quantification are then represented as conditionalprobabilities, which are generated by composing different energy functions. OurECBMs address both limitations of existing CBMs, providing higher accuracy andricher concept interpretations. Empirical results show that our approachoutperforms the state-of-the-art on real-world datasets.</description><author>Xinyue Xu, Yi Qin, Lu Mi, Hao Wang, Xiaomeng Li</author><pubDate>Mon, 26 Feb 2024 11:33:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.14142v2</guid></item><item><title>LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments</title><link>http://arxiv.org/abs/2402.16499v1</link><description>Recent advancements in large language models (LLMs) have revealed theirpotential for achieving autonomous agents possessing human-level intelligence.However, existing benchmarks for evaluating LLM Agents either use staticdatasets, potentially leading to data leakage or focus only on single-agentscenarios, overlooking the complexities of multi-agent interactions. There is alack of a benchmark that evaluates the diverse capabilities of LLM agents inmulti-agent, dynamic environments. To this end, we introduce LLMArena, a noveland easily extensible framework for evaluating the diverse capabilities of LLMin multi-agent dynamic environments. LLMArena encompasses seven distinct gamingenvironments, employing Trueskill scoring to assess crucial abilities in LLMagents, including spatial reasoning, strategic planning, numerical reasoning,risk assessment, communication, opponent modeling, and team collaboration. Weconduct an extensive experiment and human evaluation among different sizes andtypes of LLMs, showing that LLMs still have a significant journey ahead intheir development towards becoming fully autonomous agents, especially inopponent modeling and team collaboration. We hope LLMArena could guide futureresearch towards enhancing these capabilities in LLMs, ultimately leading tomore sophisticated and practical applications in dynamic, multi-agent settings.The code and data will be available.</description><author>Junzhe Chen, Xuming Hu, Shuodi Liu, Shiyu Huang, Wei-Wei Tu, Zhaofeng He, Lijie Wen</author><pubDate>Mon, 26 Feb 2024 11:31:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16499v1</guid></item><item><title>Decentralized Bilevel Optimization over Graphs: Loopless Algorithmic Update and Transient Iteration Complexity</title><link>http://arxiv.org/abs/2402.03167v2</link><description>Stochastic bilevel optimization (SBO) is becoming increasingly essential inmachine learning due to its versatility in handling nested structures. Toaddress large-scale SBO, decentralized approaches have emerged as effectiveparadigms in which nodes communicate with immediate neighbors without a centralserver, thereby improving communication efficiency and enhancing algorithmicrobustness. However, current decentralized SBO algorithms face challenges,including expensive inner-loop updates and unclear understanding of theinfluence of network topology, data heterogeneity, and the nested bilevelalgorithmic structures. In this paper, we introduce a single-loop decentralizedSBO (D-SOBA) algorithm and establish its transient iteration complexity, which,for the first time, clarifies the joint influence of network topology and dataheterogeneity on decentralized bilevel algorithms. D-SOBA achieves thestate-of-the-art asymptotic rate, asymptotic gradient/Hessian complexity, andtransient iteration complexity under more relaxed assumptions compared toexisting methods. Numerical experiments validate our theoretical findings.</description><author>Boao Kong, Shuchen Zhu, Songtao Lu, Xinmeng Huang, Kun Yuan</author><pubDate>Mon, 26 Feb 2024 11:30:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03167v2</guid></item><item><title>Intelligent Known and Novel Aircraft Recognition -- A Shift from Classification to Similarity Learning for Combat Identification</title><link>http://arxiv.org/abs/2402.16486v1</link><description>Precise aircraft recognition in low-resolution remote sensing imagery is achallenging yet crucial task in aviation, especially combat identification.This research addresses this problem with a novel, scalable, and AI-drivensolution. The primary hurdle in combat identification in remote sensing imageryis the accurate recognition of Novel/Unknown types of aircraft in addition toKnown types. Traditional methods, human expert-driven combat identification andimage classification, fall short in identifying Novel classes. Our methodologyemploys similarity learning to discern features of a broad spectrum of militaryand civilian aircraft. It discerns both Known and Novel aircraft types,leveraging metric learning for the identification and supervised few-shotlearning for aircraft type classification. To counter the challenge of limitedlow-resolution remote sensing data, we propose an end-to-end framework thatadapts to the diverse and versatile process of military aircraft recognition bytraining a generalized embedder in fully supervised manner. Comparativeanalysis with earlier aircraft image classification methods shows that ourapproach is effective for aircraft image classification (F1-score Aircraft Typeof 0.861) and pioneering for quantifying the identification of Novel types(F1-score Bipartitioning of 0.936). The proposed methodology effectivelyaddresses inherent challenges in remote sensing data, thereby setting newstandards in dataset quality. The research opens new avenues for domain expertsand demonstrates unique capabilities in distinguishing various aircraft types,contributing to a more robust, domain-adapted potential for real-time aircraftrecognition.</description><author>Ahmad Saeed, Haasha Bin Atif, Usman Habib, Mohsin Bilal</author><pubDate>Mon, 26 Feb 2024 11:08:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16486v1</guid></item><item><title>Closing the Gap Between SGP4 and High-Precision Propagation via Differentiable Programming</title><link>http://arxiv.org/abs/2402.04830v2</link><description>The Simplified General Perturbations 4 (SGP4) orbital propagation method iswidely used for predicting the positions and velocities of Earth-orbitingobjects rapidly and reliably. Despite continuous refinement, SGP models stilllack the precision of numerical propagators, which offer significantly smallererrors. This study presents dSGP4, a novel differentiable version of SGP4implemented using PyTorch. By making SGP4 differentiable, dSGP4 facilitatesvarious space-related applications, including spacecraft orbit determination,state conversion, covariance transformation, state transition matrixcomputation, and covariance propagation. Additionally, dSGP4's PyTorchimplementation allows for embarrassingly parallel orbital propagation acrossbatches of Two-Line Element Sets (TLEs), leveraging the computational power ofCPUs, GPUs, and advanced hardware for distributed prediction of satellitepositions at future times. Furthermore, dSGP4's differentiability enablesintegration with modern machine learning techniques. Thus, we propose a novelorbital propagation paradigm, ML-dSGP4, where neural networks are integratedinto the orbital propagator. Through stochastic gradient descent, this combinedmodel's inputs, outputs, and parameters can be iteratively refined, surpassingSGP4's precision. Neural networks act as identity operators by default,adhering to SGP4's behavior. However, dSGP4's differentiability allowsfine-tuning with ephemeris data, enhancing precision while maintainingcomputational speed. This empowers satellite operators and researchers to trainthe model using specific ephemeris or high-precision numerical propagationdata, significantly advancing orbital prediction capabilities.</description><author>Giacomo Acciarini, Atılım Güneş Baydin, Dario Izzo</author><pubDate>Mon, 26 Feb 2024 11:04:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04830v2</guid></item><item><title>On Languaging a Simulation Engine</title><link>http://arxiv.org/abs/2402.16482v1</link><description>Language model intelligence is revolutionizing the way we program materialssimulations. However, the diversity of simulation scenarios renders itchallenging to precisely transform human language into a tailored simulator.Here, using three functionalized types of language model, we propose alanguage-to-simulation (Lang2Sim) framework that enables interactive navigationon languaging a simulation engine, by taking a scenario instance of watersorption in porous matrices. Unlike line-by-line coding of a target simulator,the language models interpret each simulator as an assembly of invariant toolfunction and its variant input-output pair. Lang2Sim enables the precisetransform of textual description by functionalizing and sequentializing thelanguage models of, respectively, rationalizing the tool categorization,customizing its input-output combinations, and distilling the simulator inputinto executable format. Importantly, depending on its functionalized type, eachlanguage model features a distinct processing of chat history to best balanceits memory limit and information completeness, thus leveraging the modelintelligence to unstructured nature of human request. Overall, this workestablishes language model as an intelligent platform to unlock the era oflanguaging a simulation engine.</description><author>Han Liu, Liantang Li</author><pubDate>Mon, 26 Feb 2024 11:01:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16482v1</guid></item><item><title>Towards Building Multilingual Language Model for Medicine</title><link>http://arxiv.org/abs/2402.13963v2</link><description>In this paper, we aim to develop an open-source, multilingual language modelfor medicine, that the benefits a wider, linguistically diverse audience fromdifferent regions. In general, we present the contribution from the followingaspects: first, for multilingual medical-specific adaptation, we construct anew multilingual medical corpus, that contains approximately 25.5B tokensencompassing 6 main languages, termed as MMedC, that enables auto-regressivetraining for existing general LLMs. second, to monitor the development ofmultilingual LLMs in medicine, we propose a new multilingual medicalmulti-choice question-answering benchmark with rationale, termed as MMedBench;third, we have assessed a number of popular, opensource large language models(LLMs) on our benchmark, along with those further auto-regressive trained onMMedC, as a result, our final model, termed as MMedLM 2, with only 7Bparameters, achieves superior performance compared to all other open-sourcemodels, even rivaling GPT-4 on MMedBench. We will make the resources publiclyavailable, including code, model weights, and datasets.</description><author>Pengcheng Qiu, Chaoyi Wu, Xiaoman Zhang, Weixiong Lin, Haicheng Wang, Ya Zhang, Yanfeng Wang, Weidi Xie</author><pubDate>Mon, 26 Feb 2024 11:01:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13963v2</guid></item><item><title>A kernel-based analysis of Laplacian Eigenmaps</title><link>http://arxiv.org/abs/2402.16481v1</link><description>Given i.i.d. observations uniformly distributed on a closed manifold$\mathcal{M}\subseteq \mathbb{R}^p$, we study the spectral properties of theassociated empirical graph Laplacian based on a Gaussian kernel. Our mainresults are non-asymptotic error bounds, showing that the eigenvalues andeigenspaces of the empirical graph Laplacian are close to the eigenvalues andeigenspaces of the Laplace-Beltrami operator of $\mathcal{M}$. In our analysis,we connect the empirical graph Laplacian to kernel principal componentanalysis, and consider the heat kernel of $\mathcal{M}$ as reproducing kernelfeature map. This leads to novel points of view and allows to leverage resultsfor empirical covariance operators in infinite dimensions.</description><author>Martin Wahl</author><pubDate>Mon, 26 Feb 2024 11:00:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16481v1</guid></item><item><title>Solving Kernel Ridge Regression with Gradient-Based Optimization Methods</title><link>http://arxiv.org/abs/2306.16838v5</link><description>Kernel ridge regression, KRR, is a generalization of linear ridge regressionthat is non-linear in the data, but linear in the parameters. Here, weintroduce an equivalent formulation of the objective function of KRR, openingup both for using penalties other than the ridge penalty and for studyingkernel ridge regression from the perspective of gradient descent. Using acontinuous-time perspective, we derive a closed-form solution for solvingkernel regression with gradient descent, something we refer to as kernelgradient flow, KGF, and theoretically bound the differences between KRR andKGF, where, for the latter, regularization is obtained through early stopping.We also generalize KRR by replacing the ridge penalty with the $\ell_1$ and$\ell_\infty$ penalties, respectively, and use the fact that analogous to thesimilarities between KGF and KRR, $\ell_1$ regularization and forward stagewiseregression (also known as coordinate descent), and $\ell_\infty$ regularizationand sign gradient descent, follow similar solution paths. We can thus alleviatethe need for computationally heavy algorithms based on proximal gradientdescent. We show theoretically and empirically how the $\ell_1$ and$\ell_\infty$ penalties, and the corresponding gradient-based optimizationalgorithms, produce sparse and robust kernel regression solutions,respectively.</description><author>Oskar Allerbo</author><pubDate>Mon, 26 Feb 2024 10:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16838v5</guid></item><item><title>Edge Detectors Can Make Deep Convolutional Neural Networks More Robust</title><link>http://arxiv.org/abs/2402.16479v1</link><description>Deep convolutional neural networks (DCNN for short) are vulnerable toexamples with small perturbations. Improving DCNN's robustness is of greatsignificance to the safety-critical applications, such as autonomous drivingand industry automation. Inspired by the principal way that human eyesrecognize objects, i.e., largely relying on the shape features, this paperfirst employs the edge detectors as layer kernels and designs a binary edgefeature branch (BEFB for short) to learn the binary edge features, which can beeasily integrated into any popular backbone. The four edge detectors can learnthe horizontal, vertical, positive diagonal, and negative diagonal edgefeatures, respectively, and the branch is stacked by multiple Sobel layers(using edge detectors as kernels) and one threshold layer. The binary edgefeatures learned by the branch, concatenated with the texture features learnedby the backbone, are fed into the fully connected layers for classification. Weintegrate the proposed branch into VGG16 and ResNet34, respectively, andconduct experiments on multiple datasets. Experimental results demonstrate theBEFB is lightweight and has no side effects on training. And the accuracy ofthe BEFB integrated models is better than the original ones on all datasetswhen facing FGSM, PGD, and C\&amp;W attacks. Besides, BEFB integrated modelsequipped with the robustness enhancing techniques can achieve betterclassification accuracy compared to the original models. The work in this paperfor the first time shows it is feasible to enhance the robustness of DCNNsthrough combining both shape-like features and texture features.</description><author>Jin Ding, Jie-Chao Zhao, Yong-Zhi Sun, Ping Tan, Jia-Wei Wang, Ji-En Ma, You-Tong Fang</author><pubDate>Mon, 26 Feb 2024 10:54:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16479v1</guid></item><item><title>A hybrid quantum-classical fusion neural network to improve protein-ligand binding affinity predictions for drug discovery</title><link>http://arxiv.org/abs/2309.03919v2</link><description>The field of drug discovery hinges on the accurate prediction of bindingaffinity between prospective drug molecules and target proteins, especiallywhen such proteins directly influence disease progression. However, estimatingbinding affinity demands significant financial and computational resources.While state-of-the-art methodologies employ classical machine learning (ML)techniques, emerging hybrid quantum machine learning (QML) models have shownpromise for enhanced performance, owing to their inherent parallelism andcapacity to manage exponential increases in data dimensionality. Despite theseadvances, existing models encounter issues related to convergence stability andprediction accuracy. This paper introduces a novel hybrid quantum-classicaldeep learning model tailored for binding affinity prediction in drug discovery.Specifically, the proposed model synergistically integrates 3D and spatialgraph convolutional neural networks within an optimized quantum architecture.Simulation results demonstrate a 6% improvement in prediction accuracy relativeto existing classical models, as well as a significantly more stableconvergence performance compared to previous classical approaches.</description><author>L. Domingo, M. Chehimi, S. Banerjee, S. He Yuxun, S. Konakanchi, L. Ogunfowora, S. Roy, S. Selvaras, M. Djukic, C. Johnson</author><pubDate>Mon, 26 Feb 2024 10:52:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.03919v2</guid></item><item><title>DCVSMNet: Double Cost Volume Stereo Matching Network</title><link>http://arxiv.org/abs/2402.16473v1</link><description>We introduce Double Cost Volume Stereo Matching Network(DCVSMNet) which is anovel architecture characterised by by two small upper (group-wise) and lower(norm correlation) cost volumes. Each cost volume is processed separately, anda coupling module is proposed to fuse the geometry information extracted fromthe upper and lower cost volumes. DCVSMNet is a fast stereo matching networkwith a 67 ms inference time and strong generalization ability which can producecompetitive results compared to state-of-the-art methods. The results onseveral bench mark datasets show that DCVSMNet achieves better accuracy thanmethods such as CGI-Stereo and BGNet at the cost of greater inference time.</description><author>Mahmoud Tahmasebi, Saif Huq, Kevin Meehan, Marion McAfee</author><pubDate>Mon, 26 Feb 2024 10:42:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16473v1</guid></item><item><title>Enhancing Representation in Medical Vision-Language Foundation Models via Multi-Scale Information Extraction Techniques</title><link>http://arxiv.org/abs/2401.01583v2</link><description>The development of medical vision-language foundation models has attractedsignificant attention in the field of medicine and healthcare due to theirpromising prospect in various clinical applications. While previous studieshave commonly focused on feature learning at a single learning scale,investigation on integrating multi-scale information is lacking, which mayhinder the potential for mutual reinforcement among these features. This paperaims to bridge this gap by proposing a method that effectively exploitsmulti-scale information to enhance the performance of medical foundationmodels. The proposed method simultaneously exploits features at the local,instance, modality and global aspects, facilitating comprehensiverepresentation learning within the models. We evaluate the effectiveness of theproposed method on six open-source datasets across different clinical tasks,demonstrating its ability to enhance the performance of medical foundationmodels.</description><author>Weijian Huang, Cheng Li, Hong-Yu Zhou, Jiarun Liu, Hao Yang, Yong Liang, Guangming Shi, Hairong Zheng, Shanshan Wang</author><pubDate>Mon, 26 Feb 2024 10:35:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01583v2</guid></item><item><title>Fixing confirmation bias in feature attribution methods via semantic match</title><link>http://arxiv.org/abs/2307.00897v3</link><description>Feature attribution methods have become a staple method to disentangle thecomplex behavior of black box models. Despite their success, some scholars haveargued that such methods suffer from a serious flaw: they do not allow areliable interpretation in terms of human concepts. Simply put, visualizing anarray of feature contributions is not enough for humans to conclude somethingabout a model's internal representations, and confirmation bias can trick usersinto false beliefs about model behavior. We argue that a structured approach isrequired to test whether our hypotheses on the model are confirmed by thefeature attributions. This is what we call the "semantic match" between humanconcepts and (sub-symbolic) explanations. Building on the conceptual frameworkput forward in Cin\`a et al. [2023], we propose a structured approach toevaluate semantic match in practice. We showcase the procedure in a suite ofexperiments spanning tabular and image data, and show how the assessment ofsemantic match can give insight into both desirable (e.g., focusing on anobject relevant for prediction) and undesirable model behaviors (e.g., focusingon a spurious correlation). We couple our experimental results with an analysison the metrics to measure semantic match, and argue that this approachconstitutes the first step towards resolving the issue of confirmation bias inXAI.</description><author>Giovanni Cinà, Daniel Fernandez-Llaneza, Ludovico Deponte, Nishant Mishra, Tabea E. Röber, Sandro Pezzelle, Iacer Calixto, Rob Goedhart, Ş. İlker Birbil</author><pubDate>Mon, 26 Feb 2024 10:34:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00897v3</guid></item><item><title>mEdIT: Multilingual Text Editing via Instruction Tuning</title><link>http://arxiv.org/abs/2402.16472v1</link><description>We introduce mEdIT, a multi-lingual extension to CoEdIT -- the recentstate-of-the-art text editing models for writing assistance. mEdIT models aretrained by fine-tuning multi-lingual large, pre-trained language models (LLMs)via instruction tuning. They are designed to take instructions from the userspecifying the attributes of the desired text in the form of natural languageinstructions, such as Grammatik korrigieren (German) or Parafrasee la oraci\'on(Spanish). We build mEdIT by curating data from multiple publicly availablehuman-annotated text editing datasets for three text editing tasks (GrammaticalError Correction (GEC), Text Simplification, and Paraphrasing) across diverselanguages belonging to six different language families. We detail the designand training of mEdIT models and demonstrate their strong performance on manymulti-lingual text editing benchmarks against other multilingual LLMs. We alsofind that mEdIT generalizes effectively to new languages over multilingualbaselines. We publicly release our data, code, and trained models athttps://github.com/vipulraheja/medit.</description><author>Vipul Raheja, Dimitris Alikaniotis, Vivek Kulkarni, Bashar Alhafni, Dhruv Kumar</author><pubDate>Mon, 26 Feb 2024 10:33:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16472v1</guid></item><item><title>Unveiling Vulnerability of Self-Attention</title><link>http://arxiv.org/abs/2402.16470v1</link><description>Pre-trained language models (PLMs) are shown to be vulnerable to minor wordchanges, which poses a big threat to real-world systems. While previous studiesdirectly focus on manipulating word inputs, they are limited by their means ofgenerating adversarial samples, lacking generalization to versatile real-worldattack. This paper studies the basic structure of transformer-based PLMs, theself-attention (SA) mechanism. (1) We propose a powerful perturbation technique\textit{HackAttend}, which perturbs the attention scores within the SA matricesvia meticulously crafted attention masks. We show that state-of-the-art PLMsfall into heavy vulnerability that minor attention perturbations $(1\%)$ canproduce a very high attack success rate $(98\%)$. Our paper expands theconventional text attack of word perturbations to more general structuralperturbations. (2) We introduce \textit{S-Attend}, a novel smoothing techniquethat effectively makes SA robust via structural perturbations. We empiricallydemonstrate that this simple yet effective technique achieves robustperformance on par with adversarial training when facing various textattackers. Code is publicly available at \url{github.com/liongkj/HackAttend}.</description><author>Khai Jiet Liong, Hongqiu Wu, Hai Zhao</author><pubDate>Mon, 26 Feb 2024 10:31:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16470v1</guid></item><item><title>Neural Diffusion Models</title><link>http://arxiv.org/abs/2310.08337v2</link><description>Diffusion models have shown remarkable performance on many generative tasks.Despite recent success, most diffusion models are restricted in that they onlyallow linear transformation of the data distribution. In contrast, broaderfamily of transformations can potentially help train generative distributionsmore efficiently, simplifying the reverse process and closing the gap betweenthe true negative log-likelihood and the variational approximation. In thispaper, we present Neural Diffusion Models (NDMs), a generalization ofconventional diffusion models that enables defining and learning time-dependentnon-linear transformations of data. We show how to optimise NDMs using avariational bound in a simulation-free setting. Moreover, we derive atime-continuous formulation of NDMs, which allows fast and reliable inferenceusing off-the-shelf numerical ODE and SDE solvers. Finally, we demonstrate theutility of NDMs with learnable transformations through experiments on standardimage generation benchmarks, including CIFAR-10, downsampled versions ofImageNet and CelebA-HQ. NDMs outperform conventional diffusion models in termsof likelihood and produce high-quality samples.</description><author>Grigory Bartosh, Dmitry Vetrov, Christian A. Naesseth</author><pubDate>Mon, 26 Feb 2024 10:24:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.08337v2</guid></item><item><title>Contrastive Initial State Buffer for Reinforcement Learning</title><link>http://arxiv.org/abs/2309.09752v3</link><description>In Reinforcement Learning, the trade-off between exploration and exploitationposes a complex challenge for achieving efficient learning from limitedsamples. While recent works have been effective in leveraging past experiencesfor policy updates, they often overlook the potential of reusing pastexperiences for data collection. Independent of the underlying RL algorithm, weintroduce the concept of a Contrastive Initial State Buffer, whichstrategically selects states from past experiences and uses them to initializethe agent in the environment in order to guide it toward more informativestates. We validate our approach on two complex robotic tasks without relyingon any prior information about the environment: (i) locomotion of a quadrupedrobot traversing challenging terrains and (ii) a quadcopter drone racingthrough a track. The experimental results show that our initial state bufferachieves higher task performance than the nominal baseline while also speedingup training convergence.</description><author>Nico Messikommer, Yunlong Song, Davide Scaramuzza</author><pubDate>Mon, 26 Feb 2024 10:22:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09752v3</guid></item><item><title>Exploratory Landscape Analysis for Mixed-Variable Problems</title><link>http://arxiv.org/abs/2402.16467v1</link><description>Exploratory landscape analysis and fitness landscape analysis in general havebeen pivotal in facilitating problem understanding, algorithm design andendeavors such as automated algorithm selection and configuration. Thesetechniques have largely been limited to search spaces of a single domain. Inthis work, we provide the means to compute exploratory landscape features formixed-variable problems where the decision space is a mixture of continuous,binary, integer, and categorical variables. This is achieved by utilizingexisting encoding techniques originating from machine learning. We provide acomprehensive juxtaposition of the results based on these different techniques.To further highlight their merit for practical applications, we design andconduct an automated algorithm selection study based on a hyperparameteroptimization benchmark suite. We derive a meaningful compartmentalization ofthese benchmark problems by clustering based on the used landscape features.The identified clusters mimic the behavior the used algorithms exhibit.Meaning, the different clusters have different best performing algorithms.Finally, our trained algorithm selector is able to close the gap between thesingle best and the virtual best solver by 57.5% over all benchmark problems.</description><author>Raphael Patrick Prager, Heike Trautmann</author><pubDate>Mon, 26 Feb 2024 10:19:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16467v1</guid></item><item><title>Learning to Schedule Online Tasks with Bandit Feedback</title><link>http://arxiv.org/abs/2402.16463v1</link><description>Online task scheduling serves an integral role for task-intensiveapplications in cloud computing and crowdsourcing. Optimal scheduling canenhance system performance, typically measured by the reward-to-cost ratio,under some task arrival distribution. On one hand, both reward and cost aredependent on task context (e.g., evaluation metric) and remain black-box inpractice. These render reward and cost hard to model thus unknown beforedecision making. On the other hand, task arrival behaviors remain sensitive tofactors like unpredictable system fluctuation whereby a prior estimation or theconventional assumption of arrival distribution (e.g., Poisson) may fail. Thisimplies another practical yet often neglected challenge, i.e., uncertain taskarrival distribution. Towards effective scheduling under a stationaryenvironment with various uncertainties, we propose a double-optimistic learningbased Robbins-Monro (DOL-RM) algorithm. Specifically, DOL-RM integrates alearning module that incorporates optimistic estimation for reward-to-costratio and a decision module that utilizes the Robbins-Monro method toimplicitly learn task arrival distribution while making scheduling decisions.Theoretically, DOL-RM achieves convergence gap and no regret learning with asub-linear regret of $O(T^{3/4})$, which is the first result for online taskscheduling under uncertain task arrival distribution and unknown reward andcost. Our numerical results in a synthetic experiment and a real-worldapplication demonstrate the effectiveness of DOL-RM in achieving the bestcumulative reward-to-cost ratio compared with other state-of-the-art baselines.</description><author>Yongxin Xu, Shangshang Wang, Hengquan Guo, Xin Liu, Ziyu Shao</author><pubDate>Mon, 26 Feb 2024 10:11:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16463v1</guid></item><item><title>Defending LLMs against Jailbreaking Attacks via Backtranslation</title><link>http://arxiv.org/abs/2402.16459v1</link><description>Although many large language models (LLMs) have been trained to refuseharmful requests, they are still vulnerable to jailbreaking attacks, whichrewrite the original prompt to conceal its harmful intent. In this paper, wepropose a new method for defending LLMs against jailbreaking attacks by``backtranslation''. Specifically, given an initial response generated by thetarget LLM from an input prompt, our backtranslation prompts a language modelto infer an input prompt that can lead to the response. The inferred prompt iscalled the backtranslated prompt which tends to reveal the actual intent of theoriginal prompt, since it is generated based on the LLM's response and is notdirectly manipulated by the attacker. We then run the target LLM again on thebacktranslated prompt, and we refuse the original prompt if the model refusesthe backtranslated prompt. We explain that the proposed defense providesseveral benefits on its effectiveness and efficiency. We empiricallydemonstrate that our defense significantly outperforms the baselines, in thecases that are hard for the baselines, and our defense also has little impacton the generation quality for benign input prompts.</description><author>Yihan Wang, Zhouxing Shi, Andrew Bai, Cho-Jui Hsieh</author><pubDate>Mon, 26 Feb 2024 10:03:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16459v1</guid></item><item><title>VOOM: Robust Visual Object Odometry and Mapping using Hierarchical Landmarks</title><link>http://arxiv.org/abs/2402.13609v2</link><description>In recent years, object-oriented simultaneous localization and mapping (SLAM)has attracted increasing attention due to its ability to provide high-levelsemantic information while maintaining computational efficiency. Someresearchers have attempted to enhance localization accuracy by integrating themodeled object residuals into bundle adjustment. However, few have demonstratedbetter results than feature-based visual SLAM systems, as the generic coarseobject models, such as cuboids or ellipsoids, are less accurate than featurepoints. In this paper, we propose a Visual Object Odometry and Mappingframework VOOM using high-level objects and low-level points as thehierarchical landmarks in a coarse-to-fine manner instead of directly usingobject residuals in bundle adjustment. Firstly, we introduce an improvedobservation model and a novel data association method for dual quadrics,employed to represent physical objects. It facilitates the creation of a 3D mapthat closely reflects reality. Next, we use object information to enhance thedata association of feature points and consequently update the map. In thevisual object odometry backend, the updated map is employed to further optimizethe camera pose and the objects. Meanwhile, local bundle adjustment isperformed utilizing the objects and points-based covisibility graphs in ourvisual object mapping process. Experiments show that VOOM outperforms bothobject-oriented SLAM and feature points SLAM systems such as ORB-SLAM2 in termsof localization. The implementation of our method is available athttps://github.com/yutongwangBIT/VOOM.git.</description><author>Yutong Wang, Chaoyang Jiang, Xieyuanli Chen</author><pubDate>Mon, 26 Feb 2024 10:02:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13609v2</guid></item><item><title>D-XCB: Data-independent Debiasing for Fair and Accurate Transformer-based Cyberbullying Detection</title><link>http://arxiv.org/abs/2402.16458v1</link><description>Swear words are a common proxy to collect datasets with cyberbullyingincidents. Our focus is on measuring and mitigating biases derived fromspurious associations between swear words and incidents occurring as a resultof such data collection strategies. After demonstrating and quantifying thesebiases, we introduce ID-XCB, the first data-independent debiasing techniquethat combines adversarial training, bias constraints and debias fine-tuningapproach aimed at alleviating model attention to bias-inducing words withoutimpacting overall model performance. We explore ID-XCB on two popularsession-based cyberbullying datasets along with comprehensive ablation andgeneralisation studies. We show that ID-XCB learns robust cyberbullyingdetection capabilities while mitigating biases, outperforming state-of-the-artdebiasing methods in both performance and bias mitigation. Our quantitative andqualitative analyses demonstrate its generalisability to unseen data.</description><author>Peiling Yi, Arkaitz Zubiaga</author><pubDate>Mon, 26 Feb 2024 10:02:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16458v1</guid></item><item><title>Don't Miss Out on Novelty: Importance of Novel Features for Deep Anomaly Detection</title><link>http://arxiv.org/abs/2310.00797v4</link><description>Anomaly Detection (AD) is a critical task that involves identifyingobservations that do not conform to a learned model of normality. Prior work indeep AD is predominantly based on a familiarity hypothesis, where familiarfeatures serve as the reference in a pre-trained embedding space. While thisstrategy has proven highly successful, it turns out that it causes consistentfalse negatives when anomalies consist of truly novel features that are notwell captured by the pre-trained encoding. We propose a novel approach to ADusing explainability to capture such novel features as unexplained observationsin the input space. We achieve strong performance across a wide range ofanomaly benchmarks by combining familiarity and novelty in a hybrid approach.Our approach establishes a new state-of-the-art across multiple benchmarks,handling diverse anomaly types while eliminating the need for expensivebackground models and dense matching. In particular, we show that by takingaccount of novel features, we reduce false negative anomalies by up to 40% onchallenging benchmarks compared to the state-of-the-art. Our method givesvisually inspectable explanations for pixel-level anomalies.</description><author>Sarath Sivaprasad, Mario Fritz</author><pubDate>Mon, 26 Feb 2024 10:02:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00797v4</guid></item><item><title>RetrievalQA: Assessing Adaptive Retrieval-Augmented Generation for Short-form Open-Domain Question Answering</title><link>http://arxiv.org/abs/2402.16457v1</link><description>Adaptive retrieval-augmented generation (ARAG) aims to dynamically determinethe necessity of retrieval for queries instead of retrieving indiscriminatelyto enhance the efficiency and relevance of the sourced information. However,previous works largely overlook the evaluation of ARAG approaches, leading totheir effectiveness being understudied. This work presents a benchmark,RetrievalQA, comprising 1,271 short-form questions covering new world andlong-tail knowledge. The knowledge necessary to answer the questions is absentfrom LLMs; therefore, external information must be retrieved to answercorrectly. This makes RetrievalQA a suitable testbed to evaluate existing ARAGmethods. We observe that calibration-based methods heavily rely on thresholdtuning, while vanilla prompting is inadequate for guiding LLMs to make reliableretrieval decisions. Based on our findings, we propose Time-Aware AdaptiveRetrieval (TA-ARE), a simple yet effective method that helps LLMs assess thenecessity of retrieval without calibration or additional training. The datasetand code will be available at \url{https://github.com/hyintell/RetrievalQA}</description><author>Zihan Zhang, Meng Fang, Ling Chen</author><pubDate>Mon, 26 Feb 2024 09:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16457v1</guid></item><item><title>Performance Comparison of Surrogate-Assisted Evolutionary Algorithms on Computational Fluid Dynamics Problems</title><link>http://arxiv.org/abs/2402.16455v1</link><description>Surrogate-assisted evolutionary algorithms (SAEAs) are recently among themost widely studied methods for their capability to solve expensive real-worldoptimization problems. However, the development of new methods and benchmarkingwith other techniques still relies almost exclusively on artificially createdproblems. In this paper, we use two real-world computational fluid dynamicsproblems to compare the performance of eleven state-of-the-art single-objectiveSAEAs. We analyze the performance by investigating the quality and robustnessof the obtained solutions and the convergence properties of the selectedmethods. Our findings suggest that the more recently published methods, as wellas the techniques that utilize differential evolution as one of theiroptimization mechanisms, perform significantly better than the other consideredmethods.</description><author>Jakub Kudela, Ladislav Dobrovsky</author><pubDate>Mon, 26 Feb 2024 09:58:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16455v1</guid></item><item><title>Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey</title><link>http://arxiv.org/abs/2402.05391v4</link><description>Knowledge Graphs (KGs) play a pivotal role in advancing various AIapplications, with the semantic web community's exploration into multi-modaldimensions unlocking new avenues for innovation. In this survey, we carefullyreview over 300 articles, focusing on KG-aware research in two principalaspects: KG-driven Multi-Modal (KG4MM) learning, where KGs support multi-modaltasks, and Multi-Modal Knowledge Graph (MM4KG), which extends KG studies intothe MMKG realm. We begin by defining KGs and MMKGs, then explore theirconstruction progress. Our review includes two primary task categories:KG-aware multi-modal learning tasks, such as Image Classification and VisualQuestion Answering, and intrinsic MMKG tasks like Multi-modal Knowledge GraphCompletion and Entity Alignment, highlighting specific research trajectories.For most of these tasks, we provide definitions, evaluation benchmarks, andadditionally outline essential insights for conducting relevant research.Finally, we discuss current challenges and identify emerging trends, such asprogress in Large Language Modeling and Multi-modal Pre-training strategies.This survey aims to serve as a comprehensive reference for researchers alreadyinvolved in or considering delving into KG and multi-modal learning research,offering insights into the evolving landscape of MMKG research and supportingfuture work.</description><author>Zhuo Chen, Yichi Zhang, Yin Fang, Yuxia Geng, Lingbing Guo, Xiang Chen, Qian Li, Wen Zhang, Jiaoyan Chen, Yushan Zhu, Jiaqi Li, Xiaoze Liu, Jeff Z. Pan, Ningyu Zhang, Huajun Chen</author><pubDate>Mon, 26 Feb 2024 09:57:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05391v4</guid></item><item><title>ArabianGPT: Native Arabic GPT-based Large Language Model</title><link>http://arxiv.org/abs/2402.15313v2</link><description>The predominance of English and Latin-based large language models (LLMs) hasled to a notable deficit in native Arabic LLMs. This discrepancy is accentuatedby the prevalent inclusion of English tokens in existing Arabic models,detracting from their efficacy in processing native Arabic's intricatemorphology and syntax. Consequently, there is a theoretical and practicalimperative for developing LLMs predominantly focused on Arabic linguisticelements. To address this gap, this paper proposes ArabianGPT, a series oftransformer-based models within the ArabianLLM suite designed explicitly forArabic. These models, including ArabianGPT-0.1B and ArabianGPT-0.3B, vary insize and complexity, aligning with the nuanced linguistic characteristics ofArabic. The AraNizer tokenizer, integral to these models, addresses the uniquemorphological aspects of Arabic script, ensuring more accurate text processing.Empirical results from fine-tuning the models on tasks like sentiment analysisand summarization demonstrate significant improvements. For sentiment analysis,the fine-tuned ArabianGPT-0.1B model achieved a remarkable accuracy of 95%, asubstantial increase from the base model's 56%. Similarly, in summarizationtasks, fine-tuned models showed enhanced F1 scores, indicating improvedprecision and recall in generating concise summaries. Comparative analysis offine-tuned ArabianGPT models against their base versions across variousbenchmarks reveals nuanced differences in performance, with fine-tuningpositively impacting specific tasks like question answering and summarization.These findings underscore the efficacy of fine-tuning in aligning ArabianGPTmodels more closely with specific NLP tasks, highlighting the potential oftailored transformer architectures in advancing Arabic NLP.</description><author>Anis Koubaa, Adel Ammar, Lahouari Ghouti, Omar Najar, Serry Sibaee</author><pubDate>Mon, 26 Feb 2024 09:54:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15313v2</guid></item><item><title>Processing and Segmentation of Human Teeth from 2D Images using Weakly Supervised Learning</title><link>http://arxiv.org/abs/2311.07398v2</link><description>Teeth segmentation is an essential task in dental image analysis for accuratediagnosis and treatment planning. While supervised deep learning methods can beutilized for teeth segmentation, they often require extensive manual annotationof segmentation masks, which is time-consuming and costly. In this research, wepropose a weakly supervised approach for teeth segmentation that reduces theneed for manual annotation. Our method utilizes the output heatmaps andintermediate feature maps from a keypoint detection network to guide thesegmentation process. We introduce the TriDental dataset, consisting of 3000oral cavity images annotated with teeth keypoints, to train a teeth keypointdetection network. We combine feature maps from different layers of thekeypoint detection network, enabling accurate teeth segmentation withoutexplicit segmentation annotations. The detected keypoints are also used forfurther refinement of the segmentation masks. Experimental results on theTriDental dataset demonstrate the superiority of our approach in terms ofaccuracy and robustness compared to state-of-the-art segmentation methods. Ourmethod offers a cost-effective and efficient solution for teeth segmentation inreal-world dental applications, eliminating the need for extensive manualannotation efforts.</description><author>Tomáš Kunzo, Viktor Kocur, Lukáš Gajdošech, Martin Madaras</author><pubDate>Mon, 26 Feb 2024 09:54:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07398v2</guid></item><item><title>Online Efficient Safety-Critical Control for Mobile Robots in Unknown Dynamic Multi-Obstacle Environments</title><link>http://arxiv.org/abs/2402.16449v1</link><description>This paper proposes a LiDAR-based goal-seeking and exploration framework,addressing the efficiency of online obstacle avoidance in unstructuredenvironments populated with static and moving obstacles. This frameworkaddresses two significant challenges associated with traditional dynamiccontrol barrier functions (D-CBFs): their online construction and thediminished real-time performance caused by utilizing multiple D-CBFs. To tacklethe first challenge, the framework's perception component begins withclustering point clouds via the DBSCAN algorithm, followed by encapsulatingthese clusters with the minimum bounding ellipses (MBEs) algorithm to createelliptical representations. By comparing the current state of MBEs with thosestored from previous moments, the differentiation between static and dynamicobstacles is realized, and the Kalman filter is utilized to predict themovements of the latter. Such analysis facilitates the D-CBF's onlineconstruction for each MBE. To tackle the second challenge, we introduce bufferzones, generating Type-II D-CBFs online for each identified obstacle. Utilizingthese buffer zones as activation areas substantially reduces the number ofD-CBFs that need to be activated. Upon entering these buffer zones, the systemprioritizes safety, autonomously navigating safe paths, and hence referred toas the exploration mode. Exiting these buffer zones triggers the system'stransition to goal-seeking mode. We demonstrate that the system's states underthis framework achieve safety and asymptotic stabilization. Experimentalresults in simulated and real-world environments have validated our framework'scapability, allowing a LiDAR-equipped mobile robot to efficiently and safelyreach the desired location within dynamic environments containing multipleobstacles.</description><author>Yu Zhang, Guangyao Tian, Long Wen, Xiangtong Yao, Liding Zhang, Zhenshan Bing, Wei He, Alois Knoll</author><pubDate>Mon, 26 Feb 2024 09:53:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16449v1</guid></item><item><title>Supersampling of Data from Structured-light Scanner with Deep Learning</title><link>http://arxiv.org/abs/2311.07432v2</link><description>This paper focuses on increasing the resolution of depth maps obtained from3D cameras using structured light technology. Two deep learning models FDSR andDKN are modified to work with high-resolution data, and data pre-processingtechniques are implemented for stable training. The models are trained on ourcustom dataset of 1200 3D scans. The resulting high-resolution depth maps areevaluated using qualitative and quantitative metrics. The approach for depthmap upsampling offers benefits such as reducing the processing time of apipeline by first downsampling a high-resolution depth map, performing variousprocessing steps at the lower resolution and upsampling the resulting depth mapor increasing the resolution of a point cloud captured in lower resolution by acheaper device. The experiments demonstrate that the FDSR model excels in termsof faster processing time, making it a suitable choice for applications wherespeed is crucial. On the other hand, the DKN model provides results with higherprecision, making it more suitable for applications that prioritize accuracy.</description><author>Martin Melicherčík, Lukáš Gajdošech, Viktor Kocur, Martin Madaras</author><pubDate>Mon, 26 Feb 2024 09:53:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07432v2</guid></item><item><title>Evaluating the Significance of Outdoor Advertising from Driver's Perspective Using Computer Vision</title><link>http://arxiv.org/abs/2311.07390v2</link><description>Outdoor advertising, such as roadside billboards, plays a significant role inmarketing campaigns but can also be a distraction for drivers, potentiallyleading to accidents. In this study, we propose a pipeline for evaluating thesignificance of roadside billboards in videos captured from a driver'sperspective. We have collected and annotated a new BillboardLamac dataset,comprising eight videos captured by drivers driving through a predefined pathwearing eye-tracking devices. The dataset includes annotations of billboards,including 154 unique IDs and 155 thousand bounding boxes, as well as eyefixation data. We evaluate various object tracking methods in combination witha YOLOv8 detector to identify billboard advertisements with the best approachachieving 38.5 HOTA on BillboardLamac. Additionally, we train a random forestclassifier to classify billboards into three classes based on the length ofdriver fixations achieving 75.8% test accuracy. An analysis of the trainedclassifier reveals that the duration of billboard visibility, its saliency, andsize are the most influential features when assessing billboard significance.</description><author>Zuzana Černeková, Zuzana Berger Haladová, Ján Špirka, Viktor Kocur</author><pubDate>Mon, 26 Feb 2024 09:51:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07390v2</guid></item><item><title>Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning</title><link>http://arxiv.org/abs/2308.11464v2</link><description>Federated learning (FL) inevitably confronts the challenge of systemheterogeneity in practical scenarios. To enhance the capabilities of mostmodel-homogeneous FL methods in handling system heterogeneity, we propose atraining scheme that can extend their capabilities to cope with this challenge.In this paper, we commence our study with a detailed exploration of homogeneousand heterogeneous FL settings and discover three key observations: (1) apositive correlation between client performance and layer similarities, (2)higher similarities in the shallow layers in contrast to the deep layers, and(3) the smoother gradients distributions indicate the higher layersimilarities. Building upon these observations, we propose InCo Aggregationthat leverages internal cross-layer gradients, a mixture of gradients fromshallow and deep layers within a server model, to augment the similarity in thedeep layers without requiring additional communication between clients.Furthermore, our methods can be tailored to accommodate model-homogeneous FLmethods such as FedAvg, FedProx, FedNova, Scaffold, and MOON, to expand theircapabilities to handle the system heterogeneity. Copious experimental resultsvalidate the effectiveness of InCo Aggregation, spotlighting internalcross-layer gradients as a promising avenue to enhance the performance inheterogeneous FL.</description><author>Yun-Hin Chan, Rui Zhou, Running Zhao, Zhihan Jiang, Edith C. -H. Ngai</author><pubDate>Mon, 26 Feb 2024 09:48:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11464v2</guid></item><item><title>ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors</title><link>http://arxiv.org/abs/2402.16444v1</link><description>The safety of Large Language Models (LLMs) has gained increasing attention inrecent years, but there still lacks a comprehensive approach for detectingsafety issues within LLMs' responses in an aligned, customizable andexplainable manner. In this paper, we propose ShieldLM, an LLM-based safetydetector, which aligns with general human safety standards, supportscustomizable detection rules, and provides explanations for its decisions. Totrain ShieldLM, we compile a large bilingual dataset comprising 14,387query-response pairs, annotating the safety of responses based on varioussafety standards. Through extensive experiments, we demonstrate that ShieldLMsurpasses strong baselines across four test sets, showcasing remarkablecustomizability and explainability. Besides performing well on standarddetection datasets, ShieldLM has also been shown to be effective in real-worldsituations as a safety evaluator for advanced LLMs. We release ShieldLM at\url{https://github.com/thu-coai/ShieldLM} to support accurate and explainablesafety detection under various safety standards, contributing to the ongoingefforts to enhance the safety of LLMs.</description><author>Zhexin Zhang, Yida Lu, Jingyuan Ma, Di Zhang, Rui Li, Pei Ke, Hao Sun, Lei Sha, Zhifang Sui, Hongning Wang, Minlie Huang</author><pubDate>Mon, 26 Feb 2024 09:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16444v1</guid></item><item><title>On Distributed Larger-Than-Memory Subset Selection With Pairwise Submodular Functions</title><link>http://arxiv.org/abs/2402.16442v1</link><description>Many learning problems hinge on the fundamental problem of subset selection,i.e., identifying a subset of important and representative points. For example,selecting the most significant samples in ML training cannot only reducetraining costs but also enhance model quality. Submodularity, a discreteanalogue of convexity, is commonly used for solving subset selection problems.However, existing algorithms for optimizing submodular functions aresequential, and the prior distributed methods require at least one centralmachine to fit the target subset. In this paper, we relax the requirement ofhaving a central machine for the target subset by proposing a novel distributedbounding algorithm with provable approximation guarantees. The algorithmiteratively bounds the minimum and maximum utility values to select highquality points and discard the unimportant ones. When bounding does not findthe complete subset, we use a multi-round, partition-based distributed greedyalgorithm to identify the remaining subset. We show that these algorithms findhigh quality subsets on CIFAR-100 and ImageNet with marginal or no loss inquality compared to centralized methods, and scale to a dataset with 13 billionpoints.</description><author>Maximilian Böther, Abraham Sebastian, Pranjal Awasthi, Ana Klimovic, Srikumar Ramalingam</author><pubDate>Mon, 26 Feb 2024 09:38:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16442v1</guid></item><item><title>Language-Specific Neurons: The Key to Multilingual Capabilities in Large Language Models</title><link>http://arxiv.org/abs/2402.16438v1</link><description>Large language models (LLMs) demonstrate remarkable multilingual capabilitieswithout being pre-trained on specially curated multilingual parallel corpora.It remains a challenging problem to explain the underlying mechanisms by whichLLMs process multilingual texts. In this paper, we delve into the compositionof Transformer architectures in LLMs to pinpoint language-specific regions.Specially, we propose a novel detection method, language activation probabilityentropy (LAPE), to identify language-specific neurons within LLMs. Based onLAPE, we conduct comprehensive experiments on two representative LLMs, namelyLLaMA-2 and BLOOM. Our findings indicate that LLMs' proficiency in processing aparticular language is predominantly due to a small subset of neurons,primarily situated in the models' top and bottom layers. Furthermore, weshowcase the feasibility to "steer" the output language of LLMs by selectivelyactivating or deactivating language-specific neurons. Our research providesimportant evidence to the understanding and exploration of the multilingualcapabilities of LLMs.</description><author>Tianyi Tang, Wenyang Luo, Haoyang Huang, Dongdong Zhang, Xiaolei Wang, Xin Zhao, Furu Wei, Ji-Rong Wen</author><pubDate>Mon, 26 Feb 2024 09:36:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16438v1</guid></item><item><title>"We Demand Justice!": Towards Social Context Grounding of Political Texts</title><link>http://arxiv.org/abs/2311.09106v2</link><description>Social media discourse frequently consists of 'seemingly similar languageused by opposing sides of the political spectrum', often translating to starklycontrasting perspectives. E.g., 'thoughts and prayers', could express sympathyfor mass-shooting victims, or criticize the lack of legislative action on theissue. This paper defines the context required to fully understand suchambiguous statements in a computational setting and ground them in real-worldentities, actions, and attitudes. We propose two challenging datasets thatrequire an understanding of the real-world context of the text. We benchmarkthese datasets against models built upon large pre-trained models, such asRoBERTa and GPT-3. Additionally, we develop and benchmark more structuredmodels building upon existing Discourse Contextualization Framework andPolitical Actor Representation models. We analyze the datasets and thepredictions to obtain further insights into the pragmatic languageunderstanding challenges posed by the proposed social grounding tasks.</description><author>Rajkumar Pujari, Chengfei Wu, Dan Goldwasser</author><pubDate>Mon, 26 Feb 2024 09:34:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09106v2</guid></item><item><title>Spherical convolutional neural networks can improve brain microstructure estimation from diffusion MRI data</title><link>http://arxiv.org/abs/2211.09887v3</link><description>Diffusion magnetic resonance imaging is sensitive to the microstructuralproperties of brain tissue. However, estimating clinically and scientificallyrelevant microstructural properties from the measured signals remains a highlychallenging inverse problem that machine learning may help solve. This studyinvestigated if recently developed rotationally invariant sphericalconvolutional neural networks can improve microstructural parameter estimation.We trained a spherical convolutional neural network to predict the ground-truthparameter values from efficiently simulated noisy data and applied the trainednetwork to imaging data acquired in a clinical setting to generatemicrostructural parameter maps. Our network performed better than the sphericalmean technique and multi-layer perceptron, achieving higher prediction accuracythan the spherical mean technique with less rotational variance than themulti-layer perceptron. Although we focused on a constrained two-compartmentmodel of neuronal tissue, the network and training pipeline are generalizableand can be used to estimate the parameters of any Gaussian compartment model.To highlight this, we also trained the network to predict the parameters of athree-compartment model that enables the estimation of apparent neural somadensity using tensor-valued diffusion encoding.</description><author>Leevi Kerkelä, Kiran Seunarine, Filip Szczepankiewicz, Chris A. Clark</author><pubDate>Mon, 26 Feb 2024 09:33:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.09887v3</guid></item><item><title>Training Implicit Generative Models via an Invariant Statistical Loss</title><link>http://arxiv.org/abs/2402.16435v1</link><description>Implicit generative models have the capability to learn arbitrary complexdata distributions. On the downside, training requires telling apart real datafrom artificially-generated ones using adversarial discriminators, leading tounstable training and mode-dropping issues. As reported by Zahee et al. (2017),even in the one-dimensional (1D) case, training a generative adversarialnetwork (GAN) is challenging and often suboptimal. In this work, we develop adiscriminator-free method for training one-dimensional (1D) generative implicitmodels and subsequently expand this method to accommodate multivariate cases.Our loss function is a discrepancy measure between a suitably chosentransformation of the model samples and a uniform distribution; hence, it isinvariant with respect to the true distribution of the data. We first formulateour method for 1D random variables, providing an effective solution forapproximate reparameterization of arbitrary complex distributions. Then, weconsider the temporal setting (both univariate and multivariate), in which wemodel the conditional distribution of each sample given the history of theprocess. We demonstrate through numerical simulations that this new methodyields promising results, successfully learning true distributions in a varietyof scenarios and mitigating some of the well-known problems thatstate-of-the-art implicit methods present.</description><author>José Manuel de Frutos, Pablo M. Olmos, Manuel A. Vázquez, Joaquín Míguez</author><pubDate>Mon, 26 Feb 2024 09:32:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16435v1</guid></item><item><title>RoCoIns: Enhancing Robustness of Large Language Models through Code-Style Instructions</title><link>http://arxiv.org/abs/2402.16431v1</link><description>Large Language Models (LLMs) have showcased remarkable capabilities infollowing human instructions. However, recent studies have raised concernsabout the robustness of LLMs when prompted with instructions combining textualadversarial samples. In this paper, drawing inspiration from recent works thatLLMs are sensitive to the design of the instructions, we utilize instructionsin code style, which are more structural and less ambiguous, to replacetypically natural language instructions. Through this conversion, we provideLLMs with more precise instructions and strengthen the robustness of LLMs.Moreover, under few-shot scenarios, we propose a novel method to composein-context demonstrations using both clean and adversarial samples(\textit{adversarial context method}) to further boost the robustness of theLLMs. Experiments on eight robustness datasets show that our methodconsistently outperforms prompting LLMs with natural language instructions. Forexample, with gpt-3.5-turbo, our method achieves an improvement of 5.68\% intest set accuracy and a reduction of 5.66 points in Attack Success Rate (ASR).</description><author>Yuansen Zhang, Xiao Wang, Zhiheng Xi, Han Xia, Tao Gui, Qi Zhang, Xuanjing Huang</author><pubDate>Mon, 26 Feb 2024 09:30:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16431v1</guid></item><item><title>MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception</title><link>http://arxiv.org/abs/2401.07529v2</link><description>Recent advancements in Multimodal Large Language Models (MLLMs) havedemonstrated exceptional capabilities in visual perception and understanding.However, these models also suffer from hallucinations, which limit theirreliability as AI systems. We believe that these hallucinations are partiallydue to the models' struggle with understanding what they can and cannotperceive from images, a capability we refer to as self-awareness in perception.Despite its importance, this aspect of MLLMs has been overlooked in priorstudies. In this paper, we aim to define and evaluate the self-awareness ofMLLMs in perception. To do this, we first introduce the knowledge quadrant inperception, which helps define what MLLMs know and do not know about images.Using this framework, we propose a novel benchmark, the Self-Awareness inPerception for MLLMs (MM-SAP), specifically designed to assess this capability.We apply MM-SAP to a variety of popular MLLMs, offering a comprehensiveanalysis of their self-awareness and providing detailed insights. Theexperiment results reveal that current MLLMs possess limited self-awarenesscapabilities, pointing to a crucial area for future advancement in thedevelopment of trustworthy MLLMs. Code and data are available athttps://github.com/YHWmz/MM-SAP.</description><author>Yuhao Wang, Yusheng Liao, Heyang Liu, Hongcheng Liu, Yu Wang, Yanfeng Wang</author><pubDate>Mon, 26 Feb 2024 09:28:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07529v2</guid></item><item><title>LaneSegNet: Map Learning with Lane Segment Perception for Autonomous Driving</title><link>http://arxiv.org/abs/2312.16108v2</link><description>A map, as crucial information for downstream applications of an autonomousdriving system, is usually represented in lanelines or centerlines. However,existing literature on map learning primarily focuses on either detectinggeometry-based lanelines or perceiving topology relationships of centerlines.Both of these methods ignore the intrinsic relationship of lanelines andcenterlines, that lanelines bind centerlines. While simply predicting bothtypes of lane in one model is mutually excluded in learning objective, weadvocate lane segment as a new representation that seamlessly incorporates bothgeometry and topology information. Thus, we introduce LaneSegNet, the firstend-to-end mapping network generating lane segments to obtain a completerepresentation of the road structure. Our algorithm features two keymodifications. One is a lane attention module to capture pivotal region detailswithin the long-range feature space. Another is an identical initializationstrategy for reference points, which enhances the learning of positional priorsfor lane attention. On the OpenLane-V2 dataset, LaneSegNet outperforms previouscounterparts by a substantial gain across three tasks, \textit{i.e.}, mapelement detection (+4.8 mAP), centerline perception (+6.9 DET$_l$), and thenewly defined one, lane segment perception (+5.6 mAP). Furthermore, it obtainsa real-time inference speed of 14.7 FPS. Code is accessible athttps://github.com/OpenDriveLab/LaneSegNet.</description><author>Tianyu Li, Peijin Jia, Bangjun Wang, Li Chen, Kun Jiang, Junchi Yan, Hongyang Li</author><pubDate>Mon, 26 Feb 2024 09:24:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16108v2</guid></item><item><title>PRES: Toward Scalable Memory-Based Dynamic Graph Neural Networks</title><link>http://arxiv.org/abs/2402.04284v2</link><description>Memory-based Dynamic Graph Neural Networks (MDGNNs) are a family of dynamicgraph neural networks that leverage a memory module to extract, distill, andmemorize long-term temporal dependencies, leading to superior performancecompared to memory-less counterparts. However, training MDGNNs faces thechallenge of handling entangled temporal and structural dependencies, requiringsequential and chronological processing of data sequences to capture accuratetemporal patterns. During the batch training, the temporal data points withinthe same batch will be processed in parallel, while their temporal dependenciesare neglected. This issue is referred to as temporal discontinuity andrestricts the effective temporal batch size, limiting data parallelism andreducing MDGNNs' flexibility in industrial applications. This paper studies theefficient training of MDGNNs at scale, focusing on the temporal discontinuityin training MDGNNs with large temporal batch sizes. We first conduct atheoretical study on the impact of temporal batch size on the convergence ofMDGNN training. Based on the analysis, we propose PRES, an iterativeprediction-correction scheme combined with a memory coherence learningobjective to mitigate the effect of temporal discontinuity, enabling MDGNNs tobe trained with significantly larger temporal batches without sacrificinggeneralization performance. Experimental results demonstrate that our approachenables up to a 4x larger temporal batch (3.4x speed-up) during MDGNN training.</description><author>Junwei Su, Difan Zou, Chuan Wu</author><pubDate>Mon, 26 Feb 2024 09:23:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04284v2</guid></item><item><title>COMAE: COMprehensive Attribute Exploration for Zero-shot Hashing</title><link>http://arxiv.org/abs/2402.16424v1</link><description>Zero-shot hashing (ZSH) has shown excellent success owing to its efficiencyand generalization in large-scale retrieval scenarios. While considerablesuccess has been achieved, there still exist urgent limitations. Existing worksignore the locality relationships of representations and attributes, which haveeffective transferability between seeable classes and unseeable classes. Also,the continuous-value attributes are not fully harnessed. In response, weconduct a COMprehensive Attribute Exploration for ZSH, named COMAE, whichdepicts the relationships from seen classes to unseen ones through threemeticulously designed explorations, i.e., point-wise, pair-wise and class-wiseconsistency constraints. By regressing attributes from the proposed attributeprototype network, COMAE learns the local features that are relevant to thevisual attributes. Then COMAE utilizes contrastive learning to comprehensivelydepict the context of attributes, rather than instance-independentoptimization. Finally, the class-wise constraint is designed to cohesivelylearn the hash code, image representation, and visual attributes moreeffectively. Experimental results on the popular ZSH datasets demonstrate thatCOMAE outperforms state-of-the-art hashing techniques, especially in scenarioswith a larger number of unseen label classes.</description><author>Yihang Zhou, Qingqing Long, Yuchen Yan, Xiao Luo, Zeyu Dong, Xuezhi Wang, Zhen Meng, Pengfei Wang, Yuanchun Zhou</author><pubDate>Mon, 26 Feb 2024 09:22:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16424v1</guid></item><item><title>Outline-Guided Object Inpainting with Diffusion Models</title><link>http://arxiv.org/abs/2402.16421v1</link><description>Instance segmentation datasets play a crucial role in training accurate androbust computer vision models. However, obtaining accurate mask annotations toproduce high-quality segmentation datasets is a costly and labor-intensiveprocess. In this work, we show how this issue can be mitigated by starting withsmall annotated instance segmentation datasets and augmenting them toeffectively obtain a sizeable annotated dataset. We achieve that by creatingvariations of the available annotated object instances in a way that preservesthe provided mask annotations, thereby resulting in new image-mask pairs to beadded to the set of annotated images. Specifically, we generate new imagesusing a diffusion-based inpainting model to fill out the masked area with adesired object class by guiding the diffusion through the object outline. Weshow that the object outline provides a simple, but also reliable andconvenient training-free guidance signal for the underlying inpainting modelthat is often sufficient to fill out the mask with an object of the correctclass without further text guidance and preserve the correspondence betweengenerated images and the mask annotations with high precision. Our experimentalresults reveal that our method successfully generates realistic variations ofobject instances, preserving their shape characteristics while introducingdiversity within the augmented area. We also show that the proposed method cannaturally be combined with text guidance and other image augmentationtechniques.</description><author>Markus Pobitzer, Filip Janicki, Mattia Rigotti, Cristiano Malossi</author><pubDate>Mon, 26 Feb 2024 09:21:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16421v1</guid></item><item><title>Predicting Sustainable Development Goals Using Course Descriptions -- from LLMs to Conventional Foundation Models</title><link>http://arxiv.org/abs/2402.16420v1</link><description>We present our work on predicting United Nations sustainable developmentgoals (SDG) for university courses. We use an LLM named PaLM 2 to generatetraining data given a noisy human-authored course description input as input.We use this data to train several different smaller language models to predictSDGs for university courses. This work contributes to better university leveladaptation of SDGs. The best performing model in our experiments was BART withan F1-score of 0.786.</description><author>Lev Kharlashkin, Melany Macias, Leo Huovinen, Mika Hämäläinen</author><pubDate>Mon, 26 Feb 2024 09:19:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16420v1</guid></item><item><title>TOTEM: TOkenized Time Series EMbeddings for General Time Series Analysis</title><link>http://arxiv.org/abs/2402.16412v1</link><description>The field of general time series analysis has recently begun to exploreunified modeling, where a common architectural backbone can be retrained on aspecific task for a specific dataset. In this work, we approach unificationfrom a complementary vantage point: unification across tasks and domains. Tothis end, we explore the impact of discrete, learnt, time series datarepresentations that enable generalist, cross-domain training. Our method,TOTEM, or TOkenized Time Series EMbeddings, proposes a simple tokenizerarchitecture that embeds time series data from varying domains using a discretevectorized representation learned in a self-supervised manner. TOTEM worksacross multiple tasks and domains with minimal to no tuning. We study theefficacy of TOTEM with an extensive evaluation on 17 real world time seriesdatasets across 3 tasks. We evaluate both the specialist (i.e., training amodel on each domain) and generalist (i.e., training a single model on manydomains) settings, and show that TOTEM matches or outperforms previous bestmethods on several popular benchmarks. The code can be found at:https://github.com/SaberaTalukder/TOTEM.</description><author>Sabera Talukder, Yisong Yue, Georgia Gkioxari</author><pubDate>Mon, 26 Feb 2024 09:11:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16412v1</guid></item><item><title>Hierarchical Forecasting at Scale</title><link>http://arxiv.org/abs/2310.12809v2</link><description>Existing hierarchical forecasting techniques scale poorly when the number oftime series increases. We propose to learn a coherent forecast for millions oftime series with a single bottom-level forecast model by using a sparse lossfunction that directly optimizes the hierarchical product and/or temporalstructure. The benefit of our sparse hierarchical loss function is that itprovides practitioners a method of producing bottom-level forecasts that arecoherent to any chosen cross-sectional or temporal hierarchy. In addition,removing the need for a post-processing step as required in traditionalhierarchical forecasting techniques reduces the computational cost of theprediction phase in the forecasting pipeline. On the public M5 dataset, oursparse hierarchical loss function performs up to 10% (RMSE) better compared tothe baseline loss function. We implement our sparse hierarchical loss functionwithin an existing forecasting model at bol, a large European e-commerceplatform, resulting in an improved forecasting performance of 2% at the productlevel. Finally, we found an increase in forecasting performance of about 5-10%when evaluating the forecasting performance across the cross-sectionalhierarchies that we defined. These results demonstrate the usefulness of oursparse hierarchical loss applied to a production forecasting system at a majore-commerce platform.</description><author>Olivier Sprangers, Wander Wadman, Sebastian Schelter, Maarten de Rijke</author><pubDate>Mon, 26 Feb 2024 09:06:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12809v2</guid></item><item><title>Stable Training of Normalizing Flows for High-dimensional Variational Inference</title><link>http://arxiv.org/abs/2402.16408v1</link><description>Variational inference with normalizing flows (NFs) is an increasingly popularalternative to MCMC methods. In particular, NFs based on coupling layers (RealNVPs) are frequently used due to their good empirical performance. In theory,increasing the depth of normalizing flows should lead to more accurateposterior approximations. However, in practice, training deep normalizing flowsfor approximating high-dimensional posterior distributions is often infeasibledue to the high variance of the stochastic gradients. In this work, we showthat previous methods for stabilizing the variance of stochastic gradientdescent can be insufficient to achieve stable training of Real NVPs. As thesource of the problem, we identify that, during training, samples often exhibitunusual high values. As a remedy, we propose a combination of two methods: (1)soft-thresholding of the scale in Real NVPs, and (2) a bijective soft logtransformation of the samples. We evaluate these and other previously proposedmodification on several challenging target distributions, including ahigh-dimensional horseshoe logistic regression model. Our experiments show thatwith our modifications, stable training of Real NVPs for posteriors withseveral thousand dimensions is possible, allowing for more accurate marginallikelihood estimation via importance sampling. Moreover, we evaluate severalcommon training techniques and architecture choices and provide practicaladvise for training NFs for high-dimensional variational inference.</description><author>Daniel Andrade</author><pubDate>Mon, 26 Feb 2024 09:04:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16408v1</guid></item><item><title>CMC: Few-shot Novel View Synthesis via Cross-view Multiplane Consistency</title><link>http://arxiv.org/abs/2402.16407v1</link><description>Neural Radiance Field (NeRF) has shown impressive results in novel viewsynthesis, particularly in Virtual Reality (VR) and Augmented Reality (AR),thanks to its ability to represent scenes continuously. However, when just afew input view images are available, NeRF tends to overfit the given views andthus make the estimated depths of pixels share almost the same value. Unlikeprevious methods that conduct regularization by introducing complex priors oradditional supervisions, we propose a simple yet effective method thatexplicitly builds depth-aware consistency across input views to tackle thischallenge. Our key insight is that by forcing the same spatial points to besampled repeatedly in different input views, we are able to strengthen theinteractions between views and therefore alleviate the overfitting problem. Toachieve this, we build the neural networks on layered representations(\textit{i.e.}, multiplane images), and the sampling point can thus beresampled on multiple discrete planes. Furthermore, to regularize the unseentarget views, we constrain the rendered colors and depths from different inputviews to be the same. Although simple, extensive experiments demonstrate thatour proposed method can achieve better synthesis quality over state-of-the-artmethods.</description><author>Hanxin Zhu, Tianyu He, Zhibo Chen</author><pubDate>Mon, 26 Feb 2024 09:04:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16407v1</guid></item><item><title>The Galerkin method beats Graph-Based Approaches for Spectral Algorithms</title><link>http://arxiv.org/abs/2306.00742v3</link><description>Historically, the machine learning community has derived spectraldecompositions from graph-based approaches. We break with this approach andprove the statistical and computational superiority of the Galerkin method,which consists in restricting the study to a small set of test functions. Inparticular, we introduce implementation tricks to deal with differentialoperators in large dimensions with structured kernels. Finally, we extend onthe core principles beyond our approach to apply them to non-linear spaces offunctions, such as the ones parameterized by deep neural networks, throughloss-based optimization procedures.</description><author>Vivien Cabannes, Francis Bach</author><pubDate>Mon, 26 Feb 2024 09:02:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00742v3</guid></item><item><title>From RAGs to riches: Using large language models to write documents for clinical trials</title><link>http://arxiv.org/abs/2402.16406v1</link><description>Clinical trials require numerous documents to be written -- protocols,consent forms, clinical study reports and others. Large language models (LLMs)offer the potential to rapidly generate first versions of these documents,however there are concerns about the quality of their output Here we report anevaluation of LLMs in generating parts of one such document, clinical trialprotocols. We find that an offthe-shelf LLM delivers reasonable results,especially when assessing content relevance and the correct use of terminology.However, deficiencies remain: specifically clinical thinking and logic, andappropriate use of references. To improve performance, we usedretrieval-augmented generation (RAG) to prompt an LLM with accurate up-to-dateinformation. As a result of using RAG, the writing quality of the LLM improvessubstantially, which has implications for the practical useability of LLMs inclinical trial-related writing.</description><author>Nigel Markey, Ilyass El-Mansouri, Gaetan Rensonnet, Casper van Langen, Christoph Meier</author><pubDate>Mon, 26 Feb 2024 08:59:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16406v1</guid></item><item><title>Graph Learning with Distributional Edge Layouts</title><link>http://arxiv.org/abs/2402.16402v1</link><description>Graph Neural Networks (GNNs) learn from graph-structured data by passinglocal messages between neighboring nodes along edges on certain topologicallayouts. Typically, these topological layouts in modern GNNs aredeterministically computed (e.g., attention-based GNNs) or locally sampled(e.g., GraphSage) under heuristic assumptions. In this paper, we for the firsttime pose that these layouts can be globally sampled via Langevin dynamicsfollowing Boltzmann distribution equipped with explicit physical energy,leading to higher feasibility in the physical world. We argue that such acollection of sampled/optimized layouts can capture the wide energydistribution and bring extra expressivity on top of WL-test, therefore easingdownstream tasks. As such, we propose Distributional Edge Layouts (DELs) toserve as a complement to a variety of GNNs. DEL is a pre-processing strategyindependent of subsequent GNN variants, thus being highly flexible.Experimental results demonstrate that DELs consistently and substantiallyimprove a series of GNN baselines, achieving state-of-the-art performance onmultiple datasets.</description><author>Xinjian Zhao, Chaolong Ying, Tianshu Yu</author><pubDate>Mon, 26 Feb 2024 08:55:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16402v1</guid></item><item><title>Improving Buoy Detection with Deep Transfer Learning for Mussel Farm Automation</title><link>http://arxiv.org/abs/2308.09238v2</link><description>The aquaculture sector in New Zealand is experiencing rapid expansion, with aparticular emphasis on mussel exports. As the demands of mussel farmingoperations continue to evolve, the integration of artificial intelligence andcomputer vision techniques, such as intelligent object detection, is emergingas an effective approach to enhance operational efficiency. This study delvesinto advancing buoy detection by leveraging deep learning methodologies forintelligent mussel farm monitoring and management. The primary objectivecenters on improving accuracy and robustness in detecting buoys across aspectrum of real-world scenarios. A diverse dataset sourced from mussel farmsis captured and labeled for training, encompassing imagery taken from camerasmounted on both floating platforms and traversing vessels, capturing variouslighting and weather conditions. To establish an effective deep learning modelfor buoy detection with a limited number of labeled data, we employ transferlearning techniques. This involves adapting a pre-trained object detectionmodel to create a specialized deep learning buoy detection model. We exploredifferent pre-trained models, including YOLO and its variants, alongside datadiversity to investigate their effects on model performance. Our investigationdemonstrates a significant enhancement in buoy detection performance throughdeep learning, accompanied by improved generalization across diverse weatherconditions, highlighting the practical effectiveness of our approach.</description><author>Carl McMillan, Junhong Zhao, Bing Xue, Ross Vennell, Mengjie Zhang</author><pubDate>Mon, 26 Feb 2024 08:54:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.09238v2</guid></item><item><title>ULMA: Unified Language Model Alignment with Human Demonstration and Point-wise Preference</title><link>http://arxiv.org/abs/2312.02554v2</link><description>Aligning language models to human expectations, e.g., being helpful andharmless, has become a pressing challenge for large language models. A typicalalignment procedure consists of supervised fine-tuning and preference learning.Most preference learning methods, such as RLHF and DPO, depend on pairwisepreference data, which inadequately address scenarios where human feedback ispoint-wise, leading to potential information loss and suboptimal performance.Addressing this gap, we introduce Point-wise Direct Preference Optimization, anovel preference learning method designed to harness point-wise feedbackeffectively. Our work also uncovers a novel connection between supervisedfine-tuning and point-wise preference learning, culminating in Unified LanguageModel Alignment, a single-step method that unifies the alignment with humandemonstrations and point-wise preferences. Extensive experiments on point-wisepreference datasets with binary or continuous labels validate the effectivenessof our methods. Our code and a new dataset with high-quality demonstrationsamples on harmlessness are released.</description><author>Tianchi Cai, Xierui Song, Jiyan Jiang, Fei Teng, Jinjie Gu, Guannan Zhang</author><pubDate>Mon, 26 Feb 2024 08:51:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.02554v2</guid></item><item><title>Analysis of Embeddings Learned by End-to-End Machine Learning Eye Movement-driven Biometrics Pipeline</title><link>http://arxiv.org/abs/2402.16399v1</link><description>This paper expands on the foundational concept of temporal persistence inbiometric systems, specifically focusing on the domain of eye movementbiometrics facilitated by machine learning. Unlike previous studies thatprimarily focused on developing biometric authentication systems, our researchdelves into the embeddings learned by these systems, particularly examiningtheir temporal persistence, reliability, and biometric efficacy in response tovarying input data. Utilizing two publicly available eye-movement datasets, weemployed the state-of-the-art Eye Know You Too machine learning pipeline forour analysis. We aim to validate whether the machine learning-derivedembeddings in eye movement biometrics mirror the temporal persistence observedin traditional biometrics. Our methodology involved conducting extensiveexperiments to assess how different lengths and qualities of input datainfluence the performance of eye movement biometrics more specifically how itimpacts the learned embeddings. We also explored the reliability andconsistency of the embeddings under varying data conditions. Three key metrics(kendall's coefficient of concordance, intercorrelations, and equal error rate)were employed to quantitatively evaluate our findings. The results reveal whiledata length significantly impacts the stability of the learned embeddings,however, the intercorrelations among embeddings show minimal effect.</description><author>Mehedi Hasan Raju, Lee Friedman, Dillon J Lohr, Oleg V Komogortsev</author><pubDate>Mon, 26 Feb 2024 08:49:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16399v1</guid></item><item><title>Multi-Armed Bandits and Quantum Channel Oracles</title><link>http://arxiv.org/abs/2301.08544v3</link><description>Multi-armed bandits are one of the theoretical pillars of reinforcementlearning. Recently, the investigation of quantum algorithms for multi-armedbandit problems was started, and it was found that a quadratic speed-up (inquery complexity) is possible when the arms and the randomness of the rewardsof the arms can be queried in superposition. Here we introduce further banditmodels where we only have limited access to the randomness of the rewards, butwe can still query the arms in superposition. We show that then the querycomplexity is the same as for classical algorithms. This generalizes the priorresult that no speed-up is possible for unstructured search when the oracle haspositive failure probability.</description><author>Simon Buchholz, Jonas M. Kübler, Bernhard Schölkopf</author><pubDate>Mon, 26 Feb 2024 08:47:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.08544v3</guid></item><item><title>Tricking LLMs into Disobedience: Formalizing, Analyzing, and Detecting Jailbreaks</title><link>http://arxiv.org/abs/2305.14965v2</link><description>Recent explorations with commercial Large Language Models (LLMs) have shownthat non-expert users can jailbreak LLMs by simply manipulating their prompts;resulting in degenerate output behavior, privacy and security breaches,offensive outputs, and violations of content regulator policies. Limitedstudies have been conducted to formalize and analyze these attacks and theirmitigations. We bridge this gap by proposing a formalism and a taxonomy ofknown (and possible) jailbreaks. We survey existing jailbreak methods and theireffectiveness on open-source and commercial LLMs (such as GPT-based models,OPT, BLOOM, and FLAN-T5-XXL). We further discuss the challenges of jailbreakdetection in terms of their effectiveness against known attacks. For ouranalysis, we collect a dataset of 3700 jailbreak prompts across 4 tasks. Wewill make the dataset public along with the model outputs.</description><author>Abhinav Rao, Sachin Vashistha, Atharva Naik, Somak Aditya, Monojit Choudhury</author><pubDate>Mon, 26 Feb 2024 08:42:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14965v2</guid></item><item><title>Investigating Deep Watermark Security: An Adversarial Transferability Perspective</title><link>http://arxiv.org/abs/2402.16397v1</link><description>The rise of generative neural networks has triggered an increased demand forintellectual property (IP) protection in generated content. Deep watermarkingtechniques, recognized for their flexibility in IP protection, have garneredsignificant attention. However, the surge in adversarial transferable attacksposes unprecedented challenges to the security of deep watermarkingtechniques-an area currently lacking systematic investigation. This study fillsthis gap by introducing two effective transferable attackers to assess thevulnerability of deep watermarks against erasure and tampering risks.Specifically, we initially define the concept of local sample density,utilizing it to deduce theorems on the consistency of model outputs. Upondiscovering that perturbing samples towards high sample density regions (HSDR)of the target class enhances targeted adversarial transferability, we proposethe Easy Sample Selection (ESS) mechanism and the Easy Sample Matching Attack(ESMA) method. Additionally, we propose the Bottleneck Enhanced Mixup (BEM)that integrates information bottleneck theory to reduce the generator'sdependence on irrelevant noise. Experiments show a significant enhancement inthe success rate of targeted transfer attacks for both ESMA and BEM-ESMAmethods. We further conduct a comprehensive evaluation using ESMA and BEM-ESMAas measurements, considering model architecture and watermark encoding length,and achieve some impressive findings.</description><author>Biqing Qi, Junqi Gao, Yiang Luo, Jianxing Liu, Ligang Wu, Bowen Zhou</author><pubDate>Mon, 26 Feb 2024 08:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16397v1</guid></item><item><title>Linear Log-Normal Attention with Unbiased Concentration</title><link>http://arxiv.org/abs/2311.13541v4</link><description>Transformer models have achieved remarkable results in a wide range ofapplications. However, their scalability is hampered by the quadratic time andmemory complexity of the self-attention mechanism concerning the sequencelength. This limitation poses a substantial obstacle when dealing with longdocuments or high-resolution images. In this work, we study the self-attentionmechanism by analyzing the distribution of the attention matrix and itsconcentration ability. Furthermore, we propose instruments to measure thesequantities and introduce a novel self-attention mechanism, Linear Log-NormalAttention, designed to emulate the distribution and concentration behavior ofthe original self-attention. Our experimental results on popular naturallanguage benchmarks reveal that our proposed Linear Log-Normal Attentionoutperforms other linearized attention alternatives, offering a promisingavenue for enhancing the scalability of transformer models.</description><author>Yury Nahshan, Joseph Kampeas, Emir Haleva</author><pubDate>Mon, 26 Feb 2024 08:40:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13541v4</guid></item><item><title>Reasoning over Description Logic-based Contexts with Transformers</title><link>http://arxiv.org/abs/2311.08941v2</link><description>One way that the current state of the art measures the reasoning ability oftransformer-based models is by evaluating accuracy in downstream tasks likelogical question answering or proof generation over synthetic contextsexpressed in natural language. However, most of the contexts used are inpractice very simple; in most cases, they are generated from short first-orderlogic sentences with only a few logical operators and quantifiers. In thiswork, we seek to answer the question how well a transformer-based model willperform reasoning over expressive contexts. For this purpose, we construct asynthetic natural language question-answering dataset, generated by descriptionlogic knowledge bases. For the generation of the knowledge bases, we use theexpressive language $\mathcal{ALCQ}$. The resulting dataset contains 384Kexamples, and increases in two dimensions: i) reasoning depth, and ii) lengthof sentences. We show that the performance of our DeBERTa-based model,DELTA$_M$, is marginally affected when the reasoning depth is increased and itis not affected at all when the length of the sentences is increasing. We alsoevaluate the generalization ability of the model on reasoning depths unseen attraining, both increasing and decreasing, revealing interesting insights intothe model's adaptive generalization abilities.</description><author>Angelos Poulis, Eleni Tsalapati, Manolis Koubarakis</author><pubDate>Mon, 26 Feb 2024 08:40:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08941v2</guid></item><item><title>Explainable Modeling for Wind Power Forecasting: A Glass-Box Approach with High Accuracy</title><link>http://arxiv.org/abs/2310.18629v2</link><description>Machine learning models (e.g., neural networks) achieve high accuracy in windpower forecasting, but they are usually regarded as black boxes that lackinterpretability. To address this issue, the paper proposes a glass-boxapproach that combines high accuracy with transparency for wind powerforecasting. Specifically, the core is to sum up the feature effects byconstructing shape functions, which effectively map the intricate non-linearrelationships between wind power output and input features. Furthermore, theforecasting model is enriched by incorporating interaction terms that adeptlycapture interdependencies and synergies among the input features. The additivenature of the proposed glass-box approach ensures its interpretability.Simulation results show that the proposed glass-box approach effectivelyinterprets the results of wind power forecasting from both global and instanceperspectives. Besides, it outperforms most benchmark models and exhibitscomparable performance to the best-performing neural networks. This dualstrength of transparency and high accuracy positions the proposed glass-boxapproach as a compelling choice for reliable wind power forecasting.</description><author>Wenlong Liao, Fernando Porte-Agel, Jiannong Fang, Birgitte Bak-Jensen, Guangchun Ruan, Zhe Yang</author><pubDate>Mon, 26 Feb 2024 08:34:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18629v2</guid></item><item><title>Placing Objects in Context via Inpainting for Out-of-distribution Segmentation</title><link>http://arxiv.org/abs/2402.16392v1</link><description>When deploying a semantic segmentation model into the real world, it willinevitably be confronted with semantic classes unseen during training. Thus, tosafely deploy such systems, it is crucial to accurately evaluate and improvetheir anomaly segmentation capabilities. However, acquiring and labellingsemantic segmentation data is expensive and unanticipated conditions arelong-tail and potentially hazardous. Indeed, existing anomaly segmentationdatasets capture a limited number of anomalies, lack realism or have strongdomain shifts. In this paper, we propose the Placing Objects in Context (POC)pipeline to realistically add any object into any image via diffusion models.POC can be used to easily extend any dataset with an arbitrary number ofobjects. In our experiments, we present different anomaly segmentation datasetsbased on POC-generated data and show that POC can improve the performance ofrecent state-of-the-art anomaly fine-tuning methods in several standardizedbenchmarks. POC is also effective to learn new classes. For example, we use itto edit Cityscapes samples by adding a subset of Pascal classes and show thatmodels trained on such data achieve comparable performance to thePascal-trained baseline. This corroborates the low sim-to-real gap of modelstrained on POC-generated images.</description><author>Pau de Jorge, Riccardo Volpi, Puneet K. Dokania, Philip H. S. Torr, Gregory Rogez</author><pubDate>Mon, 26 Feb 2024 08:32:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16392v1</guid></item><item><title>Et Tu Certifications: Robustness Certificates Yield Better Adversarial Examples</title><link>http://arxiv.org/abs/2302.04379v3</link><description>In guaranteeing the absence of adversarial examples in an instance'sneighbourhood, certification mechanisms play an important role in demonstratingneural net robustness. In this paper, we ask if these certifications cancompromise the very models they help to protect? Our new \emph{CertificationAware Attack} exploits certifications to produce computationally efficientnorm-minimising adversarial examples $74 \%$ more often than comparableattacks, while reducing the median perturbation norm by more than $10\%$. Whilethese attacks can be used to assess the tightness of certification bounds, theyalso highlight an apparent paradox -- that certifications can reduce security.</description><author>Andrew C. Cullen, Shijie Liu, Paul Montague, Sarah M. Erfani, Benjamin I. P. Rubinstein</author><pubDate>Mon, 26 Feb 2024 08:28:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.04379v3</guid></item><item><title>MoZIP: A Multilingual Benchmark to Evaluate Large Language Models in Intellectual Property</title><link>http://arxiv.org/abs/2402.16389v1</link><description>Large language models (LLMs) have demonstrated impressive performance invarious natural language processing (NLP) tasks. However, there is limitedunderstanding of how well LLMs perform in specific domains (e.g, theintellectual property (IP) domain). In this paper, we contribute a newbenchmark, the first Multilingual-oriented quiZ on Intellectual Property(MoZIP), for the evaluation of LLMs in the IP domain. The MoZIP benchmarkincludes three challenging tasks: IP multiple-choice quiz (IPQuiz), IP questionanswering (IPQA), and patent matching (PatentMatch). In addition, we alsodevelop a new IP-oriented multilingual large language model (called MoZi),which is a BLOOMZ-based model that has been supervised fine-tuned withmultilingual IP-related text data. We evaluate our proposed MoZi model and fourwell-known LLMs (i.e., BLOOMZ, BELLE, ChatGLM and ChatGPT) on the MoZIPbenchmark. Experimental results demonstrate that MoZi outperforms BLOOMZ, BELLEand ChatGLM by a noticeable margin, while it had lower scores compared withChatGPT. Notably, the performance of current LLMs on the MoZIP benchmark hasmuch room for improvement, and even the most powerful ChatGPT does not reachthe passing level. Our source code, data, and models are available at\url{https://github.com/AI-for-Science/MoZi}.</description><author>Shiwen Ni, Minghuan Tan, Yuelin Bai, Fuqiang Niu, Min Yang, Bowen Zhang, Ruifeng Xu, Xiaojun Chen, Chengming Li, Xiping Hu, Ye Li, Jianping Fan</author><pubDate>Mon, 26 Feb 2024 08:27:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16389v1</guid></item><item><title>Ask Again, Then Fail: Large Language Models' Vacillations in Judgement</title><link>http://arxiv.org/abs/2310.02174v2</link><description>We observe that current conversational language models often waver in theirjudgements when faced with follow-up questions, even if the original judgementwas correct. This wavering presents a significant challenge for generatingreliable responses and building user trust. To comprehensively assess thisissue, we introduce a Follow-up Questioning Mechanism along with two metrics toquantify this inconsistency, confirming its widespread presence in currentlanguage models. To mitigate this issue, we explore various promptingstrategies for closed-source models; moreover, we develop a training-basedframework Unwavering-FQ that teaches language models to maintain theiroriginally correct judgements through synthesized high-quality preference data.Our experimental results confirm the effectiveness of our framework and itsability to enhance the general capabilities of models(https://github.com/NUSTM/LLMs-Waver-In-Judgements).</description><author>Qiming Xie, Zengzhi Wang, Yi Feng, Rui Xia</author><pubDate>Mon, 26 Feb 2024 08:26:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02174v2</guid></item><item><title>Uncertainty Quantification in Anomaly Detection with Cross-Conformal $p$-Values</title><link>http://arxiv.org/abs/2402.16388v1</link><description>Given the growing significance of reliable, trustworthy, and explainablemachine learning, the requirement of uncertainty quantification for anomalydetection systems has become increasingly important. In this context,effectively controlling Type I error rates ($\alpha$) without compromising thestatistical power ($1-\beta$) of these systems can build trust and reduce costsrelated to false discoveries, particularly when follow-up procedures areexpensive. Leveraging the principles of conformal prediction emerges as apromising approach for providing respective statistical guarantees bycalibrating a model's uncertainty. This work introduces a novel framework foranomaly detection, termed cross-conformal anomaly detection, building uponwell-known cross-conformal methods designed for prediction tasks. With that, itaddresses a natural research gap by extending previous works in the context ofinductive conformal anomaly detection, relying on the split-conformal approachfor model calibration. Drawing on insights from conformal prediction, wedemonstrate that the derived methods for calculating cross-conformal $p$-valuesstrike a practical compromise between statistical efficiency (full-conformal)and computational efficiency (split-conformal) for uncertainty-quantifiedanomaly detection on benchmark datasets.</description><author>Oliver Hennhöfer, Christine Preisach</author><pubDate>Mon, 26 Feb 2024 08:22:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16388v1</guid></item><item><title>On the Generalization Capability of Temporal Graph Learning Algorithms: Theoretical Insights and a Simpler Method</title><link>http://arxiv.org/abs/2402.16387v1</link><description>Temporal Graph Learning (TGL) has become a prevalent technique across diversereal-world applications, especially in domains where data can be represented asa graph and evolves over time. Although TGL has recently seen notable progressin algorithmic solutions, its theoretical foundations remain largelyunexplored. This paper aims at bridging this gap by investigating thegeneralization ability of different TGL algorithms (e.g., GNN-based, RNN-based,and memory-based methods) under the finite-wide over-parameterized regime. Weestablish the connection between the generalization error of TGL algorithms and"the number of layers/steps" in the GNN-/RNN-based TGL methods and "thefeature-label alignment (FLA) score", where FLA can be used as a proxy for theexpressive power and explains the performance of memory-based methods. Guidedby our theoretical analysis, we propose Simplified-Temporal-Graph-Network,which enjoys a small generalization error, improved overall performance, andlower model complexity. Extensive experiments on real-world datasetsdemonstrate the effectiveness of our method. Our theoretical findings andproposed algorithm offer essential insights into TGL from a theoreticalstandpoint, laying the groundwork for the designing practical TGL algorithms infuture studies.</description><author>Weilin Cong, Jian Kang, Hanghang Tong, Mehrdad Mahdavi</author><pubDate>Mon, 26 Feb 2024 08:22:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16387v1</guid></item><item><title>Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction</title><link>http://arxiv.org/abs/2401.01646v2</link><description>Multimodal learning significantly benefits cancer survival prediction,especially the integration of pathological images and genomic data. Despiteadvantages of multimodal learning for cancer survival prediction, massiveredundancy in multimodal data prevents it from extracting discriminative andcompact information: (1) An extensive amount of intra-modal task-unrelatedinformation blurs discriminability, especially for gigapixel whole slide images(WSIs) with many patches in pathology and thousands of pathways in genomicdata, leading to an ``intra-modal redundancy" issue. (2) Duplicated informationamong modalities dominates the representation of multimodal data, which makesmodality-specific information prone to being ignored, resulting in an``inter-modal redundancy" issue. To address these, we propose a new framework,Prototypical Information Bottlenecking and Disentangling (PIBD), consisting ofPrototypical Information Bottleneck (PIB) module for intra-modal redundancy andPrototypical Information Disentanglement (PID) module for inter-modalredundancy. Specifically, a variant of information bottleneck, PIB, is proposedto model prototypes approximating a bunch of instances for different risklevels, which can be used for selection of discriminative instances withinmodality. PID module decouples entangled multimodal data into compact distinctcomponents: modality-common and modality-specific knowledge, under the guidanceof the joint prototypical distribution. Extensive experiments on five cancerbenchmark datasets demonstrated our superiority over other methods.</description><author>Yilan Zhang, Yingxue Xu, Jianqi Chen, Fengying Xie, Hao Chen</author><pubDate>Mon, 26 Feb 2024 08:21:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01646v2</guid></item><item><title>Continual Learning Under Language Shift</title><link>http://arxiv.org/abs/2311.01200v3</link><description>The recent increase in data and model scale for language model pre-traininghas led to huge training costs. In scenarios where new data become availableover time, updating a model instead of fully retraining it would thereforeprovide significant gains. We study the pros and cons of updating a languagemodel when new data comes from new languages -- the case of continual learningunder language shift. Starting from a monolingual English language model, weincrementally add data from Danish, Icelandic, and Norwegian to investigate howforward and backward transfer effects depend on pre-training order andcharacteristics of languages, for three different model sizes. Our results showthat, while forward transfer is largely positive and independent of languageorder, backward transfer can be positive or negative depending on the order andcharacteristics of new languages. We explore a number of potentiallyexplanatory factors and find that a combination of language contamination andsyntactic similarity best fits our results.</description><author>Evangelia Gogoulou, Timothée Lesort, Magnus Boman, Joakim Nivre</author><pubDate>Mon, 26 Feb 2024 08:20:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.01200v3</guid></item><item><title>FrameNeRF: A Simple and Efficient Framework for Few-shot Novel View Synthesis</title><link>http://arxiv.org/abs/2402.14586v2</link><description>We present a novel framework, called FrameNeRF, designed to applyoff-the-shelf fast high-fidelity NeRF models with fast training speed and highrendering quality for few-shot novel view synthesis tasks. The trainingstability of fast high-fidelity models is typically constrained to dense views,making them unsuitable for few-shot novel view synthesis tasks. To address thislimitation, we utilize a regularization model as a data generator to producedense views from sparse inputs, facilitating subsequent training of fasthigh-fidelity models. Since these dense views are pseudo ground truth generatedby the regularization model, original sparse images are then used to fine-tunethe fast high-fidelity model. This process helps the model learn realisticdetails and correct artifacts introduced in earlier stages. By leveraging anoff-the-shelf regularization model and a fast high-fidelity model, our approachachieves state-of-the-art performance across various benchmark datasets.</description><author>Yan Xing, Pan Wang, Ligang Liu, Daolun Li, Li Zhang</author><pubDate>Mon, 26 Feb 2024 08:13:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14586v2</guid></item></channel></rss>