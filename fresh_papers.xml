<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 20 Feb 2024 06:01:18 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Binary Opacity Grids: Capturing Fine Geometric Detail for Mesh-Based View Synthesis</title><link>http://arxiv.org/abs/2402.12377v1</link><description>While surface-based view synthesis algorithms are appealing due to their lowcomputational requirements, they often struggle to reproduce thin structures.In contrast, more expensive methods that model the scene's geometry as avolumetric density field (e.g. NeRF) excel at reconstructing fine geometricdetail. However, density fields often represent geometry in a "fuzzy" manner,which hinders exact localization of the surface. In this work, we modifydensity fields to encourage them to converge towards surfaces, withoutcompromising their ability to reconstruct thin structures. First, we employ adiscrete opacity grid representation instead of a continuous density field,which allows opacity values to discontinuously transition from zero to one atthe surface. Second, we anti-alias by casting multiple rays per pixel, whichallows occlusion boundaries and subpixel structures to be modelled withoutusing semi-transparent voxels. Third, we minimize the binary entropy of theopacity values, which facilitates the extraction of surface geometry byencouraging opacity values to binarize towards the end of training. Lastly, wedevelop a fusion-based meshing strategy followed by mesh simplification andappearance model fitting. The compact meshes produced by our model can berendered in real-time on mobile devices and achieve significantly higher viewsynthesis quality compared to existing mesh-based approaches.</description><author>Christian Reiser, Stephan Garbin, Pratul P. Srinivasan, Dor Verbin, Richard Szeliski, Ben Mildenhall, Jonathan T. Barron, Peter Hedman, Andreas Geiger</author><pubDate>Mon, 19 Feb 2024 18:59:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12377v1</guid></item><item><title>FiT: Flexible Vision Transformer for Diffusion Model</title><link>http://arxiv.org/abs/2402.12376v1</link><description>Nature is infinitely resolution-free. In the context of this reality,existing diffusion models, such as Diffusion Transformers, often facechallenges when processing image resolutions outside of their trained domain.To overcome this limitation, we present the Flexible Vision Transformer (FiT),a transformer architecture specifically designed for generating images withunrestricted resolutions and aspect ratios. Unlike traditional methods thatperceive images as static-resolution grids, FiT conceptualizes images assequences of dynamically-sized tokens. This perspective enables a flexibletraining strategy that effortlessly adapts to diverse aspect ratios during bothtraining and inference phases, thus promoting resolution generalization andeliminating biases induced by image cropping. Enhanced by a meticulouslyadjusted network structure and the integration of training-free extrapolationtechniques, FiT exhibits remarkable flexibility in resolution extrapolationgeneration. Comprehensive experiments demonstrate the exceptional performanceof FiT across a broad range of resolutions, showcasing its effectiveness bothwithin and beyond its training resolution distribution. Repository available athttps://github.com/whlzy/FiT.</description><author>Zeyu Lu, Zidong Wang, Di Huang, Chengyue Wu, Xihui Liu, Wanli Ouyang, Lei Bai</author><pubDate>Mon, 19 Feb 2024 18:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12376v1</guid></item><item><title>Sequoia: Scalable, Robust, and Hardware-aware Speculative Decoding</title><link>http://arxiv.org/abs/2402.12374v1</link><description>As the usage of large language models (LLMs) grows, performing efficientinference with these models becomes increasingly important. While speculativedecoding has recently emerged as a promising direction for speeding upinference, existing methods are limited in their ability to scale to largerspeculation budgets, and adapt to different hyperparameters and hardware. Thispaper introduces Sequoia, a scalable, robust, and hardware-aware algorithm forspeculative decoding. To attain better scalability, Sequoia introduces adynamic programming algorithm to find the optimal tree structure for thespeculated tokens. To achieve robust speculative performance, Sequoia uses anovel sampling and verification method that outperforms prior work acrossdifferent decoding temperatures. Finally, Sequoia introduces a hardware-awaretree optimizer that maximizes speculative performance by automaticallyselecting the token tree size and depth for a given hardware platform.Evaluation shows that Sequoia improves the decoding speed of Llama2-7B,Llama2-13B, and Vicuna-33B on an A100 by up to $4.04\times$, $3.84\times$, and$2.37\times$, and Llama2-70B offloading by up to $10.33\times$ on L40.</description><author>Zhuoming Chen, Avner May, Ruslan Svirschevski, Yuhsun Huang, Max Ryabinin, Zhihao Jia, Beidi Chen</author><pubDate>Mon, 19 Feb 2024 18:58:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12374v1</guid></item><item><title>LTL learning on GPUs</title><link>http://arxiv.org/abs/2402.12373v1</link><description>Linear temporal logic (LTL) is widely used in industrial verification. LTLformulae can be learned from traces. Scaling LTL formula learning is an openproblem. We implement the first GPU-based LTL learner using a novel form ofenumerative program synthesis. The learner is sound and complete. Ourbenchmarks indicate that it handles traces at least 2048 times more numerous,and on average at least 46 times faster than existing state-of-the-artlearners. This is achieved with, among others, novel branch-free LTL semanticsthat has $O(\log n)$ time complexity, where $n$ is trace length, while previousimplementations are $O(n^2)$ or worse (assuming bitwise boolean operations andshifts by powers of 2 have unit costs -- a realistic assumption on modernprocessors).</description><author>Mojtaba Valizadeh, Nathanaël Fijalkow, Martin Berger</author><pubDate>Mon, 19 Feb 2024 18:58:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12373v1</guid></item><item><title>HunFlair2 in a cross-corpus evaluation of named entity recognition and normalization tools</title><link>http://arxiv.org/abs/2402.12372v1</link><description>With the exponential growth of the life science literature, biomedical textmining (BTM) has become an essential technology for accelerating the extractionof insights from publications. Identifying named entities (e.g., diseases,drugs, or genes) in texts and their linkage to reference knowledge bases arecrucial steps in BTM pipelines to enable information aggregation from differentdocuments. However, tools for these two steps are rarely applied in the samecontext in which they were developed. Instead, they are applied in the wild,i.e., on application-dependent text collections different from those used forthe tools' training, varying, e.g., in focus, genre, style, and text type. Thisraises the question of whether the reported performance of BTM tools can betrusted for downstream applications. Here, we report on the results of acarefully designed cross-corpus benchmark for named entity extraction, wheretools were applied systematically to corpora not used during their training.Based on a survey of 28 published systems, we selected five for an in-depthanalysis on three publicly available corpora encompassing four different entitytypes. Comparison between tools results in a mixed picture and shows that, in across-corpus setting, the performance is significantly lower than the onereported in an in-corpus setting. HunFlair2 showed the best performance onaverage, being closely followed by PubTator. Our results indicate that users ofBTM tools should expect diminishing performances when applying them in the wildcompared to original publications and show that further research is necessaryto make BTM tools more robust.</description><author>Mario Sänger, Samuele Garda, Xing David Wang, Leon Weber-Genzel, Pia Droop, Benedikt Fuchs, Alan Akbik, Ulf Leser</author><pubDate>Mon, 19 Feb 2024 18:58:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12372v1</guid></item><item><title>AnaloBench: Benchmarking the Identification of Abstract and Long-context Analogies</title><link>http://arxiv.org/abs/2402.12370v1</link><description>Humans regularly engage in analogical thinking, relating personal experiencesto current situations ($X$ is analogous to $Y$ because of $Z$). Analogicalthinking allows humans to solve problems in creative ways, grasp difficultconcepts, and articulate ideas more effectively. Can language models (LMs) dothe same? To answer this question, we propose ANALOBENCH, a benchmark todetermine analogical reasoning ability in LMs. Our benchmarking approachfocuses on aspects of this ability that are common among humans: (i) recallingrelated experiences from a large amount of information, and (ii) applyinganalogical reasoning to complex and lengthy scenarios. We test a broadcollection of proprietary models (e.g., GPT family, Claude V2) and open sourcemodels such as LLaMA2. As in prior results, scaling up LMs results in someperformance boosts. Surprisingly, scale offers minimal gains when, (i)analogies involve lengthy scenarios, or (ii) recalling relevant scenarios froma large pool of information, a process analogous to finding a needle in ahaystack. We hope these observations encourage further research in this field.</description><author>Xiao Ye, Andrew Wang, Jacob Choi, Yining Lu, Shreya Sharma, Lingfeng Shen, Vijay Tiyyala, Nicholas Andrews, Daniel Khashabi</author><pubDate>Mon, 19 Feb 2024 18:56:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12370v1</guid></item><item><title>Short-Period Variables in TESS Full-Frame Image Light Curves Identified via Convolutional Neural Networks</title><link>http://arxiv.org/abs/2402.12369v1</link><description>The Transiting Exoplanet Survey Satellite (TESS) mission measured light fromstars in ~85% of the sky throughout its two-year primary mission, resulting inmillions of TESS 30-minute cadence light curves to analyze in the search fortransiting exoplanets. To search this vast dataset, we aim to provide anapproach that is both computationally efficient, produces highly performantpredictions, and minimizes the required human search effort. We present aconvolutional neural network that we train to identify short period variables.To make a prediction for a given light curve, our network requires no priortarget parameters identified using other methods. Our network performsinference on a TESS 30-minute cadence light curve in ~5ms on a single GPU,enabling large scale archival searches. We present a collection of 14156short-period variables identified by our network. The majority of ouridentified variables fall into two prominent populations, one of short-periodmain sequence binaries and another of Delta Scuti stars. Our neural networkmodel and related code is additionally provided as open-source code for publicuse and extension.</description><author>Greg Olmschenk, Richard K. Barry, Stela Ishitani Silva, Brian P. Powell, Ethan Kruse, Jeremy D. Schnittman, Agnieszka M. Cieplak, Thomas Barclay, Siddhant Solanki, Bianca Ortega, John Baker, Yesenia Helem Salinas Mamani</author><pubDate>Mon, 19 Feb 2024 18:56:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12369v1</guid></item><item><title>A synthetic data approach for domain generalization of NLI models</title><link>http://arxiv.org/abs/2402.12368v1</link><description>Natural Language Inference (NLI) remains an important benchmark task forLLMs. NLI datasets are a springboard for transfer learning to other semantictasks, and NLI models are standard tools for identifying the faithfulness ofmodel-generated text. There are several large scale NLI datasets today, andmodels have improved greatly by hill-climbing on these collections. Yet theirrealistic performance on out-of-distribution/domain data is lesswell-understood. We present an in-depth exploration of the problem of domaingeneralization of NLI models. We demonstrate a new approach for generatingsynthetic NLI data in diverse domains and lengths, so far not covered byexisting training sets. The resulting examples have meaningful premises, thehypotheses are formed in creative ways rather than simple edits to a fewpremise tokens, and the labels have high accuracy. We show that models trainedon this data ($685$K synthetic examples) have the best generalization tocompletely new downstream test settings. On the TRUE benchmark, a T5-smallmodel trained with our data improves around $7\%$ on average compared totraining on the best alternative dataset. The improvements are more pronouncedfor smaller models, while still meaningful on a T5 XXL model. We alsodemonstrate gains on test sets when in-domain training data is augmented withour domain-general synthetic data.</description><author>Mohammad Javad Hosseini, Andrey Petrov, Alex Fabrikant, Annie Louis</author><pubDate>Mon, 19 Feb 2024 18:55:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12368v1</guid></item><item><title>A Critical Evaluation of AI Feedback for Aligning Large Language Models</title><link>http://arxiv.org/abs/2402.12366v1</link><description>Reinforcement learning with AI feedback (RLAIF) is a popular paradigm forimproving the instruction-following abilities of powerful pre-trained languagemodels. RLAIF first performs supervised fine-tuning (SFT) using demonstrationsfrom a teacher model and then further fine-tunes the model with reinforcementlearning (RL), using feedback from a critic model. While recent popularopen-source models have demonstrated substantial improvements in performancefrom the RL step, in this paper we question whether the complexity of this RLstep is truly warranted for AI feedback. We show that the improvements of theRL step are virtually entirely due to the widespread practice of using a weakerteacher model (e.g. GPT-3.5) for SFT data collection than the critic (e.g.,GPT-4) used for AI feedback generation. Specifically, we show that simplesupervised fine-tuning with GPT-4 as the teacher outperforms existing RLAIFpipelines. More generally, we find that the gains from RLAIF vary substantiallyacross base model families, test-time evaluation protocols, and critic models.Finally, we provide a mechanistic explanation for when SFT may outperform thefull two-step RLAIF pipeline as well as suggestions for making RLAIF maximallyuseful in practice.</description><author>Archit Sharma, Sedrick Keh, Eric Mitchell, Chelsea Finn, Kushal Arora, Thomas Kollar</author><pubDate>Mon, 19 Feb 2024 18:53:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12366v1</guid></item><item><title>Graph Mamba: Towards Learning on Graphs with State Space Models</title><link>http://arxiv.org/abs/2402.08678v2</link><description>Graph Neural Networks (GNNs) have shown promising potential in graphrepresentation learning. The majority of GNNs define a local message-passingmechanism, propagating information over the graph by stacking multiple layers.These methods, however, are known to suffer from two major limitations:over-squashing and poor capturing of long-range dependencies. Recently, GraphTransformers (GTs) emerged as a powerful alternative to Message-Passing NeuralNetworks (MPNNs). GTs, however, have quadratic computational cost, lackinductive biases on graph structures, and rely on complex Positional/StructuralEncodings (SE/PE). In this paper, we show that while Transformers, complexmessage-passing, and SE/PE are sufficient for good performance in practice,neither is necessary. Motivated by the recent success of State Space Models(SSMs), such as Mamba, we present Graph Mamba Networks (GMNs), a generalframework for a new class of GNNs based on selective SSMs. We discuss andcategorize the new challenges when adapting SSMs to graph-structured data, andpresent four required and one optional steps to design GMNs, where we choose(1) Neighborhood Tokenization, (2) Token Ordering, (3) Architecture ofBidirectional Selective SSM Encoder, (4) Local Encoding, and dispensable (5) PEand SE. We further provide theoretical justification for the power of GMNs.Experiments demonstrate that despite much less computational cost, GMNs attainan outstanding performance in long-range, small-scale, large-scale, andheterophilic benchmark datasets.</description><author>Ali Behrouz, Farnoosh Hashemi</author><pubDate>Mon, 19 Feb 2024 18:53:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08678v2</guid></item><item><title>Universal Physics Transformers</title><link>http://arxiv.org/abs/2402.12365v1</link><description>Deep neural network based surrogates for partial differential equations haverecently gained increased interest. However, akin to their numericalcounterparts, different techniques are used across applications, even if theunderlying dynamics of the systems are similar. A prominent example is theLagrangian and Eulerian specification in computational fluid dynamics, posing achallenge for neural networks to effectively model particle- as opposed togrid-based dynamics. We introduce Universal Physics Transformers (UPTs), anovel learning paradigm which models a wide range of spatio-temporal problems -both for Lagrangian and Eulerian discretization schemes. UPTs operate withoutgrid- or particle-based latent structures, enabling flexibility across meshesand particles. UPTs efficiently propagate dynamics in the latent space,emphasized by inverse encoding and decoding techniques. Finally, UPTs allow forqueries of the latent space representation at any point in space-time. Wedemonstrate the efficacy of UPTs in mesh-based fluid simulations, steady-stateReynolds averaged Navier-Stokes simulations, and Lagrangian-based dynamics.Project page: https://ml-jku.github.io/UPT</description><author>Benedikt Alkin, Andreas Fürst, Simon Schmid, Lukas Gruber, Markus Holzleitner, Johannes Brandstetter</author><pubDate>Mon, 19 Feb 2024 18:52:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12365v1</guid></item><item><title>Re-evaluating Retrosynthesis Algorithms with Syntheseus</title><link>http://arxiv.org/abs/2310.19796v2</link><description>The planning of how to synthesize molecules, also known as retrosynthesis,has been a growing focus of the machine learning and chemistry communities inrecent years. Despite the appearance of steady progress, we argue thatimperfect benchmarks and inconsistent comparisons mask systematic shortcomingsof existing techniques. To remedy this, we present a benchmarking librarycalled syntheseus which promotes best practice by default, enabling consistentmeaningful evaluation of single-step and multi-step retrosynthesis algorithms.We use syntheseus to re-evaluate a number of previous retrosynthesisalgorithms, and find that the ranking of state-of-the-art models changes whenevaluated carefully. We end with guidance for future works in this area.</description><author>Krzysztof Maziarz, Austin Tripp, Guoqing Liu, Megan Stanley, Shufang Xie, Piotr Gaiński, Philipp Seidl, Marwin Segler</author><pubDate>Mon, 19 Feb 2024 18:50:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19796v2</guid></item><item><title>Emergent Word Order Universals from Cognitively-Motivated Language Models</title><link>http://arxiv.org/abs/2402.12363v1</link><description>The world's languages exhibit certain so-called typological or implicationaluniversals; for example, Subject-Object-Verb (SOV) word order typically employspostpositions. Explaining the source of such biases is a key goal inlinguistics. We study the word-order universals through a computationalsimulation with language models (LMs). Our experiments show that typologicallytypical word orders tend to have lower perplexity estimated by LMs withcognitively plausible biases: syntactic biases, specific parsing strategies,and memory limitations. This suggests that the interplay of these cognitivebiases and predictability (perplexity) can explain many aspects of word-orderuniversals. This also showcases the advantage of cognitively-motivated LMs,which are typically employed in cognitive modeling, in the computationalsimulation of language universals.</description><author>Tatsuki Kuribayashi, Ryo Ueda, Ryo Yoshida, Yohei Oseki, Ted Briscoe, Timothy Baldwin</author><pubDate>Mon, 19 Feb 2024 18:49:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12363v1</guid></item><item><title>Nonlinear Discrete-Time Observers with Physics-Informed Neural Networks</title><link>http://arxiv.org/abs/2402.12360v1</link><description>We use Physics-Informed Neural Networks (PINNs) to solve the discrete-timenonlinear observer state estimation problem. Integrated within a single-stepexact observer linearization framework, the proposed PINN approach aims atlearning a nonlinear state transformation map by solving a system ofinhomogeneous functional equations. The performance of the proposed PINNapproach is assessed via two illustrative case studies for which the observerlinearizing transformation map can be derived analytically. We also perform anuncertainty quantification analysis for the proposed PINN scheme and we compareit with conventional power-series numerical implementations, which rely on thecomputation of a power series solution.</description><author>Hector Vargas Alvarez, Gianluca Fabiani, Ioannis G. Kevrekidis, Nikolaos Kazantzis, Constantinos Siettos</author><pubDate>Mon, 19 Feb 2024 18:47:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12360v1</guid></item><item><title>Combatting deepfakes: Policies to address national security threats and rights violations</title><link>http://arxiv.org/abs/2402.09581v2</link><description>This paper provides policy recommendations to address threats from deepfakes.First, we provide background information about deepfakes and review the harmsthey pose. We describe how deepfakes are currently used to proliferate sexualabuse material, commit fraud, manipulate voter behavior, and pose threats tonational security. Second, we review previous legislative proposals designed toaddress deepfakes. Third, we present a comprehensive policy proposal thatfocuses on addressing multiple parts of the deepfake supply chain. The deepfakesupply chain begins with a small number of model developers, model providers,and compute providers, and it expands to include billions of potential deepfakecreators. We describe this supply chain in greater detail and describe howentities at each step of the supply chain ought to take reasonable measures toprevent the creation and proliferation of deepfakes. Finally, we addresspotential counterpoints of our proposal. Overall, deepfakes will presentincreasingly severe threats to global security and individual liberties. Toaddress these threats, we call on policymakers to enact legislation thataddresses multiple parts of the deepfake supply chain.</description><author>Andrea Miotti, Akash Wasil</author><pubDate>Mon, 19 Feb 2024 18:39:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.09581v2</guid></item><item><title>LoRA+: Efficient Low Rank Adaptation of Large Models</title><link>http://arxiv.org/abs/2402.12354v1</link><description>In this paper, we show that Low Rank Adaptation (LoRA) as originallyintroduced in Hu et al. (2021) leads to suboptimal finetuning of models withlarge width (embedding dimension). This is due to the fact that adaptermatrices A and B in LoRA are updated with the same learning rate. Using scalingarguments for large width networks, we demonstrate that using the same learningrate for A and B does not allow efficient feature learning. We then show thatthis suboptimality of LoRA can be corrected simply by setting differentlearning rates for the LoRA adapter matrices A and B with a well-chosen ratio.We call this proposed algorithm LoRA$+$. In our extensive experiments, LoRA$+$improves performance (1-2 $\%$ improvements) and finetuning speed (up to $\sim$2X SpeedUp), at the same computational cost as LoRA.</description><author>Soufiane Hayou, Nikhil Ghosh, Bin Yu</author><pubDate>Mon, 19 Feb 2024 18:33:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12354v1</guid></item><item><title>Graph-Based Retriever Captures the Long Tail of Biomedical Knowledge</title><link>http://arxiv.org/abs/2402.12352v1</link><description>Large language models (LLMs) are transforming the way information isretrieved with vast amounts of knowledge being summarized and presented vianatural language conversations. Yet, LLMs are prone to highlight the mostfrequently seen pieces of information from the training set and to neglect therare ones. In the field of biomedical research, latest discoveries are key toacademic and industrial actors and are obscured by the abundance of anever-increasing literature corpus (the information overload problem). Surfacingnew associations between biomedical entities, e.g., drugs, genes, diseases,with LLMs becomes a challenge of capturing the long-tail knowledge of thebiomedical scientific production. To overcome this challenge, RetrievalAugmented Generation (RAG) has been proposed to alleviate some of theshortcomings of LLMs by augmenting the prompts with context retrieved fromexternal datasets. RAG methods typically select the context via maximumsimilarity search over text embeddings. In this study, we show that RAG methodsleave out a significant proportion of relevant information due to clusters ofover-represented concepts in the biomedical literature. We introduce a novelinformation-retrieval method that leverages a knowledge graph to downsamplethese clusters and mitigate the information overload problem. Its retrievalperformance is about twice better than embedding similarity alternatives onboth precision and recall. Finally, we demonstrate that both embeddingsimilarity and knowledge graph retrieval methods can be advantageously combinedinto a hybrid model that outperforms both, enabling potential improvements tobiomedical question-answering models.</description><author>Julien Delile, Srayanta Mukherjee, Anton Van Pamel, Leonid Zhukov</author><pubDate>Mon, 19 Feb 2024 18:31:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12352v1</guid></item><item><title>MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning</title><link>http://arxiv.org/abs/2311.10537v2</link><description>Large language models (LLMs), despite their remarkable progress acrossvarious general domains, encounter significant barriers in medicine andhealthcare. This field faces unique challenges such as domain-specificterminologies and reasoning over specialized knowledge. To address theseissues, we propose a novel Multi-disciplinary Collaboration (MC) framework forthe medical domain that leverages LLM-based agents in a role-playing settingthat participate in a collaborative multi-round discussion, thereby enhancingLLM proficiency and reasoning capabilities. This training-free frameworkencompasses five critical steps: gathering domain experts, proposing individualanalyses, summarising these analyses into a report, iterating over discussionsuntil a consensus is reached, and ultimately making a decision. Our workfocuses on the zero-shot setting, which is applicable in real-world scenarios.Experimental results on nine datasets (MedQA, MedMCQA, PubMedQA, and sixsubtasks from MMLU) establish that our proposed MC framework excels at miningand harnessing the medical expertise within LLMs, as well as extending itsreasoning abilities. Our code can be found at\url{https://github.com/gersteinlab/MedAgents}.</description><author>Xiangru Tang, Anni Zou, Zhuosheng Zhang, Ziming Li, Yilun Zhao, Xingyao Zhang, Arman Cohan, Mark Gerstein</author><pubDate>Mon, 19 Feb 2024 18:26:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10537v2</guid></item><item><title>Spintronic Physical Reservoir for Autonomous Prediction and Long-Term Household Energy Load Forecasting</title><link>http://arxiv.org/abs/2304.03343v2</link><description>In this study, we have shown autonomous long-term prediction with aspintronic physical reservoir. Due to the short-term memory property of themagnetization dynamics, non-linearity arises in the reservoir states whichcould be used for long-term prediction tasks using simple linear regression foronline training. During the prediction stage, the output is directly fed to theinput of the reservoir for autonomous prediction. We employ our proposedreservoir for the modeling of the chaotic time series such as Mackey-Glass anddynamic time-series data, such as household building energy loads. Since onlythe last layer of a RC needs to be trained with linear regression, it is wellsuited for learning in real time on edge devices. Here we show that a skyrmionbased magnetic tunnel junction can potentially be used as a prototypical RC butany nanomagnetic magnetic tunnel junction with nonlinear magnetization behaviorcan implement such a RC. By comparing our spintronic physical RC approach withenergy load forecasting algorithms, such as LSTMs and RNNs, we conclude thatthe proposed framework presents good performance in achieving high predictionsaccuracy, while also requiring low memory and energy both of which are at apremium in hardware resource and power constrained edge applications. Further,the proposed approach is shown to require very small training datasets and atthe same time being at least 16X energy efficient compared to the sequence tosequence LSTM for accurate household load predictions.</description><author>Walid Al Misba, Harindra S. Mavikumbure, Md Mahadi Rajib, Daniel L. Marino, Victor Cobilean, Milos Manic, Jayasimha Atulasimha</author><pubDate>Mon, 19 Feb 2024 18:25:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03343v2</guid></item><item><title>GTBench: Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations</title><link>http://arxiv.org/abs/2402.12348v1</link><description>As Large Language Models (LLMs) are integrated into critical real-worldapplications, their strategic and logical reasoning abilities are increasinglycrucial. This paper evaluates LLMs' reasoning abilities in competitiveenvironments through game-theoretic tasks, e.g., board and card games thatrequire pure logic and strategic reasoning to compete with opponents. We firstpropose GTBench, a language-driven environment composing 10 widely-recognizedtasks, across a comprehensive game taxonomy: complete versus incompleteinformation, dynamic versus static, and probabilistic versus deterministicscenarios. Then, we investigate two key problems: (1) Characterizinggame-theoretic reasoning of LLMs; (2) LLM-vs-LLM competitions as reasoningevaluation. We observe that (1) LLMs have distinct behaviors regarding variousgaming scenarios; for example, LLMs fail in complete and deterministic gamesyet they are competitive in probabilistic gaming scenarios; (2) Open-sourceLLMs, e.g., CodeLlama-34b-Instruct, are less competitive than commercial LLMs,e.g., GPT-4, in complex games. In addition, code-pretraining greatly benefitsstrategic reasoning, while advanced reasoning methods such as Chain-of-Thought(CoT) and Tree-of-Thought (ToT) do not always help. Detailed error profiles arealso provided for a better understanding of LLMs' behavior.</description><author>Jinhao Duan, Renming Zhang, James Diffenderfer, Bhavya Kailkhura, Lichao Sun, Elias Stengel-Eskin, Mohit Bansal, Tianlong Chen, Kaidi Xu</author><pubDate>Mon, 19 Feb 2024 18:23:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12348v1</guid></item><item><title>Beyond Sparse Rewards: Enhancing Reinforcement Learning with Language Model Critique in Text Generation</title><link>http://arxiv.org/abs/2401.07382v2</link><description>Reinforcement learning (RL) can align language models with non-differentiablereward signals, such as human preferences. However, a major challenge arisesfrom the sparsity of these reward signals - typically, there is only a singlereward for an entire output. This sparsity of rewards can lead to inefficientand unstable learning. To address this challenge, our paper introduces an novelframework that utilizes the critique capability of Large Language Models (LLMs)to produce intermediate-step rewards during RL training. Our method involvescoupling a policy model with a critic language model, which is responsible forproviding comprehensive feedback of each part of the output. This feedback isthen translated into token or span-level rewards that can be used to guide theRL training process. We investigate this approach under two different settings:one where the policy model is smaller and is paired with a more powerful criticmodel, and another where a single language model fulfills both roles. We assessour approach on three text generation tasks: sentiment control, language modeldetoxification, and summarization. Experimental results show that incorporatingartificial intrinsic rewards significantly improve both sample efficiency andthe overall performance of the policy model, supported by both automatic andhuman evaluation.</description><author>Meng Cao, Lei Shu, Lei Yu, Yun Zhu, Nevan Wichers, Yinxiao Liu, Lei Meng</author><pubDate>Mon, 19 Feb 2024 18:19:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07382v2</guid></item><item><title>Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!</title><link>http://arxiv.org/abs/2402.12343v1</link><description>Large language models (LLMs) need to undergo safety alignment to ensure safeconversations with humans. However, in this work, we introduce aninference-time attack framework, demonstrating that safety alignment can alsounintentionally facilitate harmful outcomes under adversarial manipulation.This framework, named Emulated Disalignment (ED), adversely combines a pair ofopen-source pre-trained and safety-aligned language models in the output spaceto produce a harmful language model without any training. Our experiments withED across three datasets and four model families (Llama-1, Llama-2, Mistral,and Alpaca) show that ED doubles the harmfulness of pre-trained models andoutperforms strong baselines, achieving the highest harmful rate in 43 out of48 evaluation subsets by a large margin. Crucially, our findings highlight theimportance of reevaluating the practice of open-sourcing language models evenafter safety alignment.</description><author>Zhanhui Zhou, Jie Liu, Zhichen Dong, Jiaheng Liu, Chao Yang, Wanli Ouyang, Yu Qiao</author><pubDate>Mon, 19 Feb 2024 18:16:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12343v1</guid></item><item><title>An Adversarial Approach to Evaluating the Robustness of Event Identification Models</title><link>http://arxiv.org/abs/2402.12338v1</link><description>Intelligent machine learning approaches are finding active use for eventdetection and identification that allow real-time situational awareness. Yet,such machine learning algorithms have been shown to be susceptible toadversarial attacks on the incoming telemetry data. This paper considers aphysics-based modal decomposition method to extract features for eventclassification and focuses on interpretable classifiers including logisticregression and gradient boosting to distinguish two types of events: load lossand generation loss. The resulting classifiers are then tested against anadversarial algorithm to evaluate their robustness. The adversarial attack istested in two settings: the white box setting, wherein the attacker knowsexactly the classification model; and the gray box setting, wherein theattacker has access to historical data from the same network as was used totrain the classifier, but does not know the classification model. Thoroughexperiments on the synthetic South Carolina 500-bus system highlight that arelatively simpler model such as logistic regression is more susceptible toadversarial attacks than gradient boosting.</description><author>Obai Bahwal, Oliver Kosut, Lalitha Sankar</author><pubDate>Mon, 19 Feb 2024 18:11:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12338v1</guid></item><item><title>Identifying regions of importance in wall-bounded turbulence through explainable deep learning</title><link>http://arxiv.org/abs/2302.01250v4</link><description>Despite its great scientific and technological importance, wall-boundedturbulence is an unresolved problem in classical physics that requires newperspectives to be tackled. One of the key strategies has been to studyinteractions among the energy-containing coherent structures in the flow. Suchinteractions are explored in this study for the first time using an explainabledeep-learning method. The instantaneous velocity field obtained from aturbulent channel flow simulation is used to predict the velocity field in timethrough a U-net architecture. Based on the predicted flow, we assess theimportance of each structure for this prediction using the game-theoreticalgorithm of SHapley Additive exPlanations (SHAP). This work provides resultsin agreement with previous observations in the literature and extends them byrevealing that the most important structures in the flow are not necessarilythe ones with the highest contribution to the Reynolds shear stress. We alsoapply the method to an experimental database, where we can identify completelynew structures based on their importance score. This framework has thepotential to shed light on numerous fundamental phenomena of wall-boundedturbulence, including novel strategies for flow control.</description><author>Andres Cremades, Sergio Hoyas, Rahul Deshpande, Pedro Quintero, Martin Lellep, Will Junghoon Lee, Jason Monty, Nicholas Hutchins, Moritz Linkmann, Ivan Marusic, Ricardo Vinuesa</author><pubDate>Mon, 19 Feb 2024 18:10:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01250v4</guid></item><item><title>Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity</title><link>http://arxiv.org/abs/2401.07348v2</link><description>The advent of Generative AI, particularly through Large Language Models(LLMs) like ChatGPT and its successors, marks a paradigm shift in the AIlandscape. Advanced LLMs exhibit multimodality, handling diverse data formats,thereby broadening their application scope. However, the complexity andemergent autonomy of these models introduce challenges in predictability andlegal compliance. This paper delves into the legal and regulatory implicationsof Generative AI and LLMs in the European Union context, analyzing aspects ofliability, privacy, intellectual property, and cybersecurity. It criticallyexamines the adequacy of the existing and proposed EU legislation, includingthe Artificial Intelligence Act (AIA) draft, in addressing the uniquechallenges posed by Generative AI in general and LLMs in particular. The paperidentifies potential gaps and shortcomings in the legislative framework andproposes recommendations to ensure the safe and compliant deployment ofgenerative models, ensuring they align with the EU's evolving digital landscapeand legal standards.</description><author>Claudio Novelli, Federico Casolari, Philipp Hacker, Giorgio Spedicato, Luciano Floridi</author><pubDate>Mon, 19 Feb 2024 18:10:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.07348v2</guid></item><item><title>Robust CLIP: Unsupervised Adversarial Fine-Tuning of Vision Embeddings for Robust Large Vision-Language Models</title><link>http://arxiv.org/abs/2402.12336v1</link><description>Multi-modal foundation models like OpenFlamingo, LLaVA, and GPT-4 areincreasingly used for various real-world tasks. Prior work has shown that thesemodels are highly vulnerable to adversarial attacks on the vision modality.These attacks can be leveraged to spread fake information or defraud users, andthus pose a significant risk, which makes the robustness of large multi-modalfoundation models a pressing problem. The CLIP model, or one of its variants,is used as a frozen vision encoder in many vision-language models (VLMs), e.g.LLaVA and OpenFlamingo. We propose an unsupervised adversarial fine-tuningscheme to obtain a robust CLIP vision encoder, which yields robustness on allvision down-stream tasks (VLMs, zero-shot classification) that rely on CLIP. Inparticular, we show that stealth-attacks on users of VLMs by a malicious thirdparty providing manipulated images are no longer possible once one replaces theoriginal CLIP model with our robust one. No retraining or fine-tuning of theVLM is required. The code and robust models are available athttps://github.com/chs20/RobustVLM</description><author>Christian Schlarmann, Naman Deep Singh, Francesco Croce, Matthias Hein</author><pubDate>Mon, 19 Feb 2024 18:09:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12336v1</guid></item><item><title>Triple-Encoders: Representations That Fire Together, Wire Together</title><link>http://arxiv.org/abs/2402.12332v1</link><description>Search-based dialog models typically re-encode the dialog history at everyturn, incurring high cost. Curved Contrastive Learning, a representationlearning method that encodes relative distances between utterances into theembedding space via a bi-encoder, has recently shown promising results fordialog modeling at far superior efficiency. While high efficiency is achievedthrough independently encoding utterances, this ignores the importance ofcontextualization. To overcome this issue, this study introducestriple-encoders, which efficiently compute distributed utterance mixtures fromthese independently encoded utterances through a novel hebbian inspiredco-occurrence learning objective without using any weights. Empirically, wefind that triple-encoders lead to a substantial improvement over bi-encoders,and even to better zero-shot generalization than single-vector representationmodels without requiring re-encoding. Our code/model is publicly available.</description><author>Justus-Jonas Erker, Florian Mai, Nils Reimers, Gerasimos Spanakis, Iryna Gurevych</author><pubDate>Mon, 19 Feb 2024 18:06:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12332v1</guid></item><item><title>Generating Survival Interpretable Trajectories and Data</title><link>http://arxiv.org/abs/2402.12331v1</link><description>A new model for generating survival trajectories and data based on applyingan autoencoder of a specific structure is proposed. It solves three tasks.First, it provides predictions in the form of the expected event time and thesurvival function for a new generated feature vector on the basis of the Beranestimator. Second, the model generates additional data based on a giventraining set that would supplement the original dataset. Third, the mostimportant, it generates a prototype time-dependent trajectory for an object,which characterizes how features of the object could be changed to achieve adifferent time to an event. The trajectory can be viewed as a type of thecounterfactual explanation. The proposed model is robust during training andinference due to a specific weighting scheme incorporating into the variationalautoencoder. The model also determines the censored indicators of new generateddata by solving a classification task. The paper demonstrates the efficiencyand properties of the proposed model using numerical experiments on syntheticand real datasets. The code of the algorithm implementing the proposed model ispublicly available.</description><author>Andrei V. Konstantinov, Stanislav R. Kirpichenko, Lev V. Utkin</author><pubDate>Mon, 19 Feb 2024 18:02:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12331v1</guid></item><item><title>Self-Contradictory Reasoning Evaluation and Detection</title><link>http://arxiv.org/abs/2311.09603v2</link><description>In a plethora of recent work, large language models (LLMs) demonstratedimpressive reasoning ability, but many proposed downstream reasoning tasksfocus on performance-wise evaluation. Two fundamental questions persist: 1) howreliable is the quality of reasoning, and 2) can models detect unreliablereasoning? In this paper, we investigate self-contradictory (Self-Contra)reasoning, where the model reasoning does not support predictions. To address1), we assess the Self-Contra rate across four datasets and delve intofiner-grained categories of Self-Contra reasoning. We find that LLMs oftencontradict themselves when performing reasoning tasks that involve contextualinformation understanding or commonsense. Importantly, a higher accuracy doesnot necessarily correspond to a lower Self-Contra rate. The model may appear togenerate correct answers but it may take shortcuts in reasoning or skip overcontextual evidence, thereby displaying Self-Contra behaviors with compromisedreasoning. As for 2), we task GPT-4 with identifying Self-Contra reasoning andfiner-grained fallacies. We observe that GPT-4 struggles to effectively detectSelf-Contra reasoning, with significantly low performance compared with humanjudgment. Our results indicate that the current LLMs lack robustness necessaryfor reliable reasoning and we emphasize the urgent need for establishing bestpractices in comprehensive reasoning evaluations beyond accuracy-based metrics.</description><author>Ziyi Liu, Isabelle Lee, Yongkang Du, Soumya Sanyal, Jieyu Zhao</author><pubDate>Mon, 19 Feb 2024 18:01:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09603v2</guid></item><item><title>Query-Based Adversarial Prompt Generation</title><link>http://arxiv.org/abs/2402.12329v1</link><description>Recent work has shown it is possible to construct adversarial examples thatcause an aligned language model to emit harmful strings or perform harmfulbehavior. Existing attacks work either in the white-box setting (with fullaccess to the model weights), or through transferability: the phenomenon thatadversarial examples crafted on one model often remain effective on othermodels. We improve on prior work with a query-based attack that leverages APIaccess to a remote language model to construct adversarial examples that causethe model to emit harmful strings with (much) higher probability than withtransfer-only attacks. We validate our attack on GPT-3.5 and OpenAI's safetyclassifier; we can cause GPT-3.5 to emit harmful strings that current transferattacks fail at, and we can evade the safety classifier with nearly 100%probability.</description><author>Jonathan Hayase, Ema Borevkovic, Nicholas Carlini, Florian Tramèr, Milad Nasr</author><pubDate>Mon, 19 Feb 2024 18:01:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12329v1</guid></item><item><title>Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents</title><link>http://arxiv.org/abs/2402.12327v1</link><description>Recent advancements have shown that agents powered by large language models(LLMs) possess capabilities to simulate human behaviors and societal dynamics.However, the potential for LLM agents to spontaneously establish collaborativerelationships in the absence of explicit instructions has not been studied. Toaddress this gap, we conduct three case studies, revealing that LLM agents arecapable of spontaneously forming collaborations even within competitivesettings. This finding not only demonstrates the capacity of LLM agents tomimic competition and cooperation in human societies but also validates apromising vision of computational social science. Specifically, it suggeststhat LLM agents could be utilized to model human social interactions, includingthose with spontaneous collaborations, thus offering insights into socialphenomena. The source codes for this study are available athttps://github.com/wuzengqing001225/SABM_ShallWeTalk .</description><author>Zengqing Wu, Shuyuan Zheng, Qianying Liu, Xu Han, Brian Inhyuk Kwon, Makoto Onizuka, Shaojie Tang, Run Peng, Chuan Xiao</author><pubDate>Mon, 19 Feb 2024 18:00:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12327v1</guid></item><item><title>LLM Agents for Psychology: A Study on Gamified Assessments</title><link>http://arxiv.org/abs/2402.12326v1</link><description>Psychological measurement is essential for mental health, self-understanding,and personal development. Traditional methods, such as self-report scales andpsychologist interviews, often face challenges with engagement andaccessibility. While game-based and LLM-based tools have been explored toimprove user interest and automate assessment, they struggle to balanceengagement with generalizability. In this work, we propose PsychoGAT(Psychological Game AgenTs) to achieve a generic gamification of psychologicalassessment. The main insight is that powerful LLMs can function both as adeptpsychologists and innovative game designers. By incorporating LLM agents intodesignated roles and carefully managing their interactions, PsychoGAT cantransform any standardized scales into personalized and engaging interactivefiction games. To validate the proposed method, we conduct psychometricevaluations to assess its effectiveness and employ human evaluators to examinethe generated content across various psychological constructs, includingdepression, cognitive distortions, and personality traits. Results demonstratethat PsychoGAT serves as an effective assessment tool, achieving statisticallysignificant excellence in psychometric metrics such as reliability, convergentvalidity, and discriminant validity. Moreover, human evaluations confirmPsychoGAT's enhancements in content coherence, interactivity, interest,immersion, and satisfaction.</description><author>Qisen Yang, Zekun Wang, Honghui Chen, Shenzhi Wang, Yifan Pu, Xin Gao, Wenhao Huang, Shiji Song, Gao Huang</author><pubDate>Mon, 19 Feb 2024 18:00:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12326v1</guid></item><item><title>Feature emergence via margin maximization: case studies in algebraic tasks</title><link>http://arxiv.org/abs/2311.07568v2</link><description>Understanding the internal representations learned by neural networks is acornerstone challenge in the science of machine learning. While there have beensignificant recent strides in some cases towards understanding how neuralnetworks implement specific target functions, this paper explores acomplementary question -- why do networks arrive at particular computationalstrategies? Our inquiry focuses on the algebraic learning tasks of modularaddition, sparse parities, and finite group operations. Our primary theoreticalfindings analytically characterize the features learned by stylized neuralnetworks for these algebraic tasks. Notably, our main technique demonstrateshow the principle of margin maximization alone can be used to fully specify thefeatures learned by the network. Specifically, we prove that the trainednetworks utilize Fourier features to perform modular addition and employfeatures corresponding to irreducible group-theoretic representations toperform compositions in general groups, aligning closely with the empiricalobservations of Nanda et al. and Chughtai et al. More generally, we hope ourtechniques can help to foster a deeper understanding of why neural networksadopt specific computational strategies.</description><author>Depen Morwani, Benjamin L. Edelman, Costin-Andrei Oncescu, Rosie Zhao, Sham Kakade</author><pubDate>Mon, 19 Feb 2024 17:59:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07568v2</guid></item><item><title>STLGRU: Spatio-Temporal Lightweight Graph GRU for Traffic Flow Prediction</title><link>http://arxiv.org/abs/2212.04548v3</link><description>Reliable forecasting of traffic flow requires efficient modeling of trafficdata. Indeed, different correlations and influences arise in a dynamic trafficnetwork, making modeling a complicated task. Existing literature has proposedmany different methods to capture traffic networks' complex underlyingspatial-temporal relations. However, given the heterogeneity of traffic data,consistently capturing both spatial and temporal dependencies presents asignificant challenge. Also, as more and more sophisticated methods are beingproposed, models are increasingly becoming memory-heavy and, thus, unsuitablefor low-powered devices. To this end, we propose Spatio-Temporal LightweightGraph GRU, namely STLGRU, a novel traffic forecasting model for predictingtraffic flow accurately. Specifically, our proposed STLGRU can effectivelycapture dynamic local and global spatial-temporal relations of traffic networksusing memory-augmented attention and gating mechanisms in a continuouslysynchronized manner. Moreover, instead of employing separate temporal andspatial components, we show that our memory module and gated unit cansuccessfully learn the spatial-temporal dependencies with reduced memory usageand fewer parameters. Extensive experimental results on three real-world publictraffic datasets demonstrate that our method can not only achievestate-of-the-art performance but also exhibit competitive computationalefficiency. Our code is available at https://github.com/Kishor-Bhaumik/STLGRU</description><author>Kishor Kumar Bhaumik, Fahim Faisal Niloy, Saif Mahmud, Simon Woo</author><pubDate>Mon, 19 Feb 2024 17:57:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.04548v3</guid></item><item><title>RaTrack: Moving Object Detection and Tracking with 4D Radar Point Cloud</title><link>http://arxiv.org/abs/2309.09737v4</link><description>Mobile autonomy relies on the precise perception of dynamic environments.Robustly tracking moving objects in 3D world thus plays a pivotal role forapplications like trajectory prediction, obstacle avoidance, and path planning.While most current methods utilize LiDARs or cameras for Multiple ObjectTracking (MOT), the capabilities of 4D imaging radars remain largelyunexplored. Recognizing the challenges posed by radar noise and point sparsityin 4D radar data, we introduce RaTrack, an innovative solution tailored forradar-based tracking. Bypassing the typical reliance on specific object typesand 3D bounding boxes, our method focuses on motion segmentation andclustering, enriched by a motion estimation module. Evaluated on theView-of-Delft dataset, RaTrack showcases superior tracking precision of movingobjects, largely surpassing the performance of the state of the art. We releaseour code and model at https://github.com/LJacksonPan/RaTrack.</description><author>Zhijun Pan, Fangqiang Ding, Hantao Zhong, Chris Xiaoxuan Lu</author><pubDate>Mon, 19 Feb 2024 17:53:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09737v4</guid></item><item><title>Landmark Stereo Dataset for Landmark Recognition and Moving Node Localization in a Non-GPS Battlefield Environment</title><link>http://arxiv.org/abs/2402.12320v1</link><description>In this paper, we have proposed a new strategy of using the landmark anchornode instead of a radio-based anchor node to obtain the virtual coordinates(landmarkID, DISTANCE) of moving troops or defense forces that will help intracking and maneuvering the troops along a safe path within a GPS-deniedbattlefield environment. The proposed strategy implements landmark recognitionusing the Yolov5 model and landmark distance estimation using an efficientStereo Matching Algorithm. We consider that a moving node carrying a low-powermobile device facilitated with a calibrated stereo vision camera that capturesstereo images of a scene containing landmarks within the battlefield regionwhose locations are stored in an offline server residing within the deviceitself. We created a custom landmark image dataset called MSTLandmarkv1 with 34landmark classes and another landmark stereo dataset of those 34 landmarkinstances called MSTLandmarkStereov1. We trained the YOLOv5 model withMSTLandmarkv1 dataset and achieved 0.95 mAP @ 0.5 IoU and 0.767 mAP @ [0.5:0.95] IoU. We calculated the distance from a node to the landmark utilizing thebounding box coordinates and the depth map generated by the improved SGMalgorithm using MSTLandmarkStereov1. The tuple of landmark IDs obtained fromthe detection result and the distances calculated by the SGM algorithm arestored as the virtual coordinates of a node. In future work, we will use thesevirtual coordinates to obtain the location of a node using an efficienttrilateration algorithm and optimize the node position using the appropriateoptimization method.</description><author>Ganesh Sapkota, Sanjay Madria</author><pubDate>Mon, 19 Feb 2024 17:49:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12320v1</guid></item><item><title>Dynamic Environment Responsive Online Meta-Learning with Fairness Awareness</title><link>http://arxiv.org/abs/2402.12319v1</link><description>The fairness-aware online learning framework has emerged as a potent toolwithin the context of continuous lifelong learning. In this scenario, thelearner's objective is to progressively acquire new tasks as they arrive overtime, while also guaranteeing statistical parity among various protectedsub-populations, such as race and gender, when it comes to the newly introducedtasks. A significant limitation of current approaches lies in their heavyreliance on the i.i.d (independent and identically distributed) assumptionconcerning data, leading to a static regret analysis of the framework.Nevertheless, it's crucial to note that achieving low static regret does notnecessarily translate to strong performance in dynamic environmentscharacterized by tasks sampled from diverse distributions. In this paper, totackle the fairness-aware online learning challenge in evolving settings, weintroduce a unique regret measure, FairSAR, by incorporating long-term fairnessconstraints into a strongly adapted loss regret framework. Moreover, todetermine an optimal model parameter at each time step, we introduce aninnovative adaptive fairness-aware online meta-learning algorithm, referred toas FairSAOML. This algorithm possesses the ability to adjust to dynamicenvironments by effectively managing bias control and model accuracy. Theproblem is framed as a bi-level convex-concave optimization, considering boththe model's primal and dual parameters, which pertain to its accuracy andfairness attributes, respectively. Theoretical analysis yields sub-linear upperbounds for both loss regret and the cumulative violation of fairnessconstraints. Our experimental evaluation on various real-world datasets indynamic environments demonstrates that our proposed FairSAOML algorithmconsistently outperforms alternative approaches rooted in the most advancedprior online learning methods.</description><author>Chen Zhao, Feng Mi, Xintao Wu, Kai Jiang, Latifur Khan, Feng Chen</author><pubDate>Mon, 19 Feb 2024 17:44:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12319v1</guid></item><item><title>ARKS: Active Retrieval in Knowledge Soup for Code Generation</title><link>http://arxiv.org/abs/2402.12317v1</link><description>Recently the retrieval-augmented generation (RAG) paradigm has raised muchattention for its potential in incorporating external knowledge into largelanguage models (LLMs) without further training. While widely explored innatural language applications, its utilization in code generation remainsunder-explored. In this paper, we introduce Active Retrieval in Knowledge Soup(ARKS), an advanced strategy for generalizing large language models for code.In contrast to relying on a single source, we construct a knowledge soupintegrating web search, documentation, execution feedback, and evolved codesnippets. We employ an active retrieval strategy that iteratively refines thequery and updates the knowledge soup. To assess the performance of ARKS, wecompile a new benchmark comprising realistic coding problems associated withfrequently updated libraries and long-tail programming languages. Experimentalresults on ChatGPT and CodeLlama demonstrate a substantial improvement in theaverage execution accuracy of ARKS on LLMs. The analysis confirms theeffectiveness of our proposed knowledge soup and active retrieval strategies,offering rich insights into the construction of effective retrieval-augmentedcode generation (RACG) pipelines. Our model, code, and data are available athttps://arks-codegen.github.io.</description><author>Hongjin Su, Shuyang Jiang, Yuhang Lai, Haoyuan Wu, Boao Shi, Che Liu, Qian Liu, Tao Yu</author><pubDate>Mon, 19 Feb 2024 17:37:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12317v1</guid></item><item><title>Hidden Minima in Two-Layer ReLU Networks</title><link>http://arxiv.org/abs/2312.16819v2</link><description>The optimization problem associated to fitting two-layer ReLU networks having$d$~inputs, $k$~neurons, and labels generated by a target network, isconsidered. Two types of infinite families of spurious minima, giving oneminimum per $d$, were recently found. The loss at minima belonging to the firsttype converges to zero as $d$ increases. In the second type, the loss remainsbounded away from zero. That being so, how may one avoid minima belonging tothe latter type? Fortunately, such minima are never detected by standardoptimization methods. Motivated by questions concerning the nature of thisphenomenon, we develop methods to study distinctive analytic properties ofhidden minima. By existing analyses, the Hessian spectrum of both types agree modulo$O(d^{-1/2})$-terms -- not promising. Thus, rather, our investigation proceedsby studying curves along which the loss is minimized or maximized, generallyreferred to as tangency arcs. We prove that apparently far removed grouprepresentation-theoretic considerations concerning the arrangement of subspacesinvariant to the action of subgroups of $S_d$, the symmetry group over $d$symbols, relative to ones fixed by the action yield a precise description ofall finitely many admissible types of tangency arcs. The general results usedfor the loss function reveal that arcs emanating from hidden minima differ,characteristically, by their structure and symmetry, precisely on account ofthe $O(d^{-1/2})$-eigenvalue terms absent in previous work, indicating inparticular the subtlety of the analysis. The theoretical results, stated andproved for o-minimal structures, show that the set comprising all tangency arcsis topologically sufficiently tame to enable a numerical construction oftangency arcs and so compare how minima, both types, are positioned relative toadjacent critical points.</description><author>Yossi Arjevani</author><pubDate>Mon, 19 Feb 2024 17:33:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16819v2</guid></item><item><title>TILP: Differentiable Learning of Temporal Logical Rules on Knowledge Graphs</title><link>http://arxiv.org/abs/2402.12309v1</link><description>Compared with static knowledge graphs, temporal knowledge graphs (tKG), whichcan capture the evolution and change of information over time, are morerealistic and general. However, due to the complexity that the notion of timeintroduces to the learning of the rules, an accurate graph reasoning, e.g.,predicting new links between entities, is still a difficult problem. In thispaper, we propose TILP, a differentiable framework for temporal logical ruleslearning. By designing a constrained random walk mechanism and the introductionof temporal operators, we ensure the efficiency of our model. We presenttemporal features modeling in tKG, e.g., recurrence, temporal order, intervalbetween pair of relations, and duration, and incorporate it into our learningprocess. We compare TILP with state-of-the-art methods on two benchmarkdatasets. We show that our proposed framework can improve upon the performanceof baseline methods while providing interpretable results. In particular, weconsider various scenarios in which training samples are limited, data isbiased, and the time range between training and inference are different. In allthese cases, TILP works much better than the state-of-the-art methods.</description><author>Siheng Xiong, Yuan Yang, Faramarz Fekri, James Clayton Kerce</author><pubDate>Mon, 19 Feb 2024 17:30:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12309v1</guid></item><item><title>Multi-View Conformal Learning for Heterogeneous Sensor Fusion</title><link>http://arxiv.org/abs/2402.12307v1</link><description>Being able to assess the confidence of individual predictions in machinelearning models is crucial for decision making scenarios. Specially, incritical applications such as medical diagnosis, security, and unmannedvehicles, to name a few. In the last years, complex predictive models have hadgreat success in solving hard tasks and new methods are being proposed everyday. While the majority of new developments in machine learning models focus onimproving the overall performance, less effort is put on assessing thetrustworthiness of individual predictions, and even to a lesser extent, in thecontext of sensor fusion. To this end, we build and test multi-view andsingle-view conformal models for heterogeneous sensor fusion. Our modelsprovide theoretical marginal confidence guarantees since they are based on theconformal prediction framework. We also propose a multi-view semi-conformalmodel based on sets intersection. Through comprehensive experimentation, weshow that multi-view models perform better than single-view models not only interms of accuracy-based performance metrics (as it has already been shown inseveral previous works) but also in conformal measures that provide uncertaintyestimation. Our results also showed that multi-view models generate predictionsets with less uncertainty compared to single-view models.</description><author>Enrique Garcia-Ceja</author><pubDate>Mon, 19 Feb 2024 17:30:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12307v1</guid></item><item><title>UncertaintyTrack: Exploiting Detection and Localization Uncertainty in Multi-Object Tracking</title><link>http://arxiv.org/abs/2402.12303v1</link><description>Multi-object tracking (MOT) methods have seen a significant boost inperformance recently, due to strong interest from the research community andsteadily improving object detection methods. The majority of tracking methodsfollow the tracking-by-detection (TBD) paradigm, blindly trust the incomingdetections with no sense of their associated localization uncertainty. Thislack of uncertainty awareness poses a problem in safety-critical tasks such asautonomous driving where passengers could be put at risk due to erroneousdetections that have propagated to downstream tasks, including MOT. While thereare existing works in probabilistic object detection that predict thelocalization uncertainty around the boxes, no work in 2D MOT for autonomousdriving has studied whether these estimates are meaningful enough to beleveraged effectively in object tracking. We introduce UncertaintyTrack, acollection of extensions that can be applied to multiple TBD trackers toaccount for localization uncertainty estimates from probabilistic objectdetectors. Experiments on the Berkeley Deep Drive MOT dataset show that thecombination of our method and informative uncertainty estimates reduces thenumber of ID switches by around 19\% and improves mMOTA by 2-3%. The sourcecode is available at https://github.com/TRAILab/UncertaintyTrack</description><author>Chang Won Lee, Steven L. Waslander</author><pubDate>Mon, 19 Feb 2024 17:27:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12303v1</guid></item><item><title>Asymptotic Gaussian Fluctuations of Eigenvectors in Spectral Clustering</title><link>http://arxiv.org/abs/2402.12302v1</link><description>The performance of spectral clustering relies on the fluctuations of theentries of the eigenvectors of a similarity matrix, which has been leftuncharacterized until now. In this letter, it is shown that the signal $+$noise structure of a general spike random matrix model is transferred to theeigenvectors of the corresponding Gram kernel matrix and the fluctuations oftheir entries are Gaussian in the large-dimensional regime. This CLT-likeresult was the last missing piece to precisely predict the classificationperformance of spectral clustering. The proposed proof is very general andrelies solely on the rotational invariance of the noise. Numerical experimentson synthetic and real data illustrate the universality of this phenomenon.</description><author>Hugo Lebeau, Florent Chatelain, Romain Couillet</author><pubDate>Mon, 19 Feb 2024 17:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12302v1</guid></item><item><title>ChatCell: Facilitating Single-Cell Analysis with Natural Language</title><link>http://arxiv.org/abs/2402.08303v3</link><description>As Large Language Models (LLMs) rapidly evolve, their influence in science isbecoming increasingly prominent. The emerging capabilities of LLMs in taskgeneralization and free-form dialogue can significantly advance fields likechemistry and biology. However, the field of single-cell biology, which formsthe foundational building blocks of living organisms, still faces severalchallenges. High knowledge barriers and limited scalability in current methodsrestrict the full exploitation of LLMs in mastering single-cell data, impedingdirect accessibility and rapid iteration. To this end, we introduce ChatCell,which signifies a paradigm shift by facilitating single-cell analysis withnatural language. Leveraging vocabulary adaptation and unified sequencegeneration, ChatCell has acquired profound expertise in single-cell biology andthe capability to accommodate a diverse range of analysis tasks. Extensiveexperiments further demonstrate ChatCell's robust performance and potential todeepen single-cell insights, paving the way for more accessible and intuitiveexploration in this pivotal field. Our project homepage is available athttps://zjunlp.github.io/project/ChatCell.</description><author>Yin Fang, Kangwei Liu, Ningyu Zhang, Xinle Deng, Penghui Yang, Zhuo Chen, Xiangru Tang, Mark Gerstein, Xiaohui Fan, Huajun Chen</author><pubDate>Mon, 19 Feb 2024 17:23:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.08303v3</guid></item><item><title>Is Open-Source There Yet? A Comparative Study on Commercial and Open-Source LLMs in Their Ability to Label Chest X-Ray Reports</title><link>http://arxiv.org/abs/2402.12298v1</link><description>Introduction: With the rapid advances in large language models (LLMs), therehave been numerous new open source as well as commercial models. While recentpublications have explored GPT-4 in its application to extracting informationof interest from radiology reports, there has not been a real-world comparisonof GPT-4 to different leading open-source models. Materials and Methods: Two different and independent datasets were used. Thefirst dataset consists of 540 chest x-ray reports that were created at theMassachusetts General Hospital between July 2019 and July 2021. The seconddataset consists of 500 chest x-ray reports from the ImaGenome dataset. We thencompared the commercial models GPT-3.5 Turbo and GPT-4 from OpenAI to theopen-source models Mistral-7B, Mixtral-8x7B, Llama2-13B, Llama2-70B,QWEN1.5-72B and CheXbert and CheXpert-labeler in their ability to accuratelylabel the presence of multiple findings in x-ray text reports using differentprompting techniques. Results: On the ImaGenome dataset, the best performing open-source model wasLlama2-70B with micro F1-scores of 0.972 and 0.970 for zero- and few-shotprompts, respectively. GPT-4 achieved micro F1-scores of 0.975 and 0.984,respectively. On the institutional dataset, the best performing open-sourcemodel was QWEN1.5-72B with micro F1-scores of 0.952 and 0.965 for zero- andfew-shot prompting, respectively. GPT-4 achieved micro F1-scores of 0.975 and0.973, respectively. Conclusion: In this paper, we show that while GPT-4 is superior toopen-source models in zero-shot report labeling, the implementation of few-shotprompting can bring open-source models on par with GPT-4. This shows thatopen-source models could be a performant and privacy preserving alternative toGPT-4 for the task of radiology report classification.</description><author>Felix J. Dorfner, Liv Jürgensen, Leonhard Donle, Fares Al Mohamad, Tobias R. Bodenmann, Mason C. Cleveland, Felix Busch, Lisa C. Adams, James Sato, Thomas Schultz, Albert E. Kim, Jameson Merkow, Keno K. Bressem, Christopher P. Bridge</author><pubDate>Mon, 19 Feb 2024 17:23:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12298v1</guid></item><item><title>Regularization by denoising: Bayesian model and Langevin-within-split Gibbs sampling</title><link>http://arxiv.org/abs/2402.12292v1</link><description>This paper introduces a Bayesian framework for image inversion by deriving aprobabilistic counterpart to the regularization-by-denoising (RED) paradigm. Itadditionally implements a Monte Carlo algorithm specifically tailored forsampling from the resulting posterior distribution, based on an asymptoticallyexact data augmentation (AXDA). The proposed algorithm is an approximateinstance of split Gibbs sampling (SGS) which embeds one Langevin Monte Carlostep. The proposed method is applied to common imaging tasks such asdeblurring, inpainting and super-resolution, demonstrating its efficacy throughextensive numerical experiments. These contributions advance Bayesian inferencein imaging by leveraging data-driven regularization strategies within aprobabilistic framework.</description><author>Elhadji C. Faye, Mame Diarra Fall, Nicolas Dobigeon</author><pubDate>Mon, 19 Feb 2024 17:12:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12292v1</guid></item><item><title>KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students</title><link>http://arxiv.org/abs/2402.12291v1</link><description>Flashcard schedulers are tools that rely on 1) student models to predict theflashcards a student knows; and 2) teaching policies to schedule cards based onthese predictions. Existing student models, however, only use flashcard-levelfeatures, like the student's past responses, ignoring the semantic ties offlashcards. Deep Knowledge Tracing (DKT) models can capture semantic relationswith language models, but are inefficient, lack content-rich datasets forevaluation, and require robust teaching policies. To address these issues, wedesign KARL, a DKT-inspired student model that uses retrieval and BERTembeddings for efficient and accurate student recall predictions. To test KARL,we collect a new dataset of diverse study history on trivia questions. KARLbests existing student models in AUC and calibration error. Finally, we proposea novel teaching policy that exploits the predictive power of DKT models todeploy KARL online. Based on 27 learners and 32 6-day study trajectories, KARLshows the ability to enhance medium-term educational learning, proving itsefficacy for scheduling.</description><author>Matthew Shu, Nishant Balepur, Shi Feng, Jordan Boyd-Graber</author><pubDate>Mon, 19 Feb 2024 17:05:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12291v1</guid></item><item><title>DriveVLM: The Convergence of Autonomous Driving and Large Vision-Language Models</title><link>http://arxiv.org/abs/2402.12289v1</link><description>A primary hurdle of autonomous driving in urban environments is understandingcomplex and long-tail scenarios, such as challenging road conditions anddelicate human behaviors. We introduce DriveVLM, an autonomous driving systemleveraging Vision-Language Models (VLMs) for enhanced scene understanding andplanning capabilities. DriveVLM integrates a unique combination ofchain-of-thought (CoT) modules for scene description, scene analysis, andhierarchical planning. Furthermore, recognizing the limitations of VLMs inspatial reasoning and heavy computational requirements, we proposeDriveVLM-Dual, a hybrid system that synergizes the strengths of DriveVLM withthe traditional autonomous driving pipeline. DriveVLM-Dual achieves robustspatial understanding and real-time inference speed. Extensive experiments onboth the nuScenes dataset and our SUP-AD dataset demonstrate the effectivenessof DriveVLM and the enhanced performance of DriveVLM-Dual, surpassing existingmethods in complex and unpredictable driving conditions.</description><author>Xiaoyu Tian, Junru Gu, Bailin Li, Yicheng Liu, Chenxu Hu, Yang Wang, Kun Zhan, Peng Jia, Xianpeng Lang, Hang Zhao</author><pubDate>Mon, 19 Feb 2024 17:04:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12289v1</guid></item><item><title>ScreenAI: A Vision-Language Model for UI and Infographics Understanding</title><link>http://arxiv.org/abs/2402.04615v2</link><description>Screen user interfaces (UIs) and infographics, sharing similar visuallanguage and design principles, play important roles in human communication andhuman-machine interaction. We introduce ScreenAI, a vision-language model thatspecializes in UI and infographics understanding. Our model improves upon thePaLI architecture with the flexible patching strategy of pix2struct and istrained on a unique mixture of datasets. At the heart of this mixture is anovel screen annotation task in which the model has to identify the type andlocation of UI elements. We use these text annotations to describe screens toLarge Language Models and automatically generate question-answering (QA), UInavigation, and summarization training datasets at scale. We run ablationstudies to demonstrate the impact of these design choices. At only 5Bparameters, ScreenAI achieves new state-of-the-artresults on UI- andinfographics-based tasks (Multi-page DocVQA, WebSRC, MoTIF and WidgetCaptioning), and new best-in-class performance on others (Chart QA, DocVQA, andInfographicVQA) compared to models of similar size. Finally, we release threenew datasets: one focused on the screen annotation task and two others focusedon question answering.</description><author>Gilles Baechler, Srinivas Sunkara, Maria Wang, Fedir Zubach, Hassan Mansoor, Vincent Etter, Victor Cărbune, Jason Lin, Jindong Chen, Abhanshu Sharma</author><pubDate>Mon, 19 Feb 2024 17:03:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04615v2</guid></item><item><title>Learning from higher-order statistics, efficiently: hypothesis tests, random features, and neural networks</title><link>http://arxiv.org/abs/2312.14922v2</link><description>Neural networks excel at discovering statistical patterns in high-dimensionaldata sets. In practice, higher-order cumulants, which quantify the non-Gaussiancorrelations between three or more variables, are particularly important forthe performance of neural networks. But how efficient are neural networks atextracting features from higher-order cumulants? We study this question in thespiked cumulant model, where the statistician needs to recover a privilegeddirection or "spike" from the order-$p\ge 4$ cumulants of $d$-dimensionalinputs. We first characterise the fundamental statistical and computationallimits of recovering the spike by analysing the number of samples $n$ requiredto strongly distinguish between inputs from the spiked cumulant model andisotropic Gaussian inputs. We find that statistical distinguishability requires$n\gtrsim d$ samples, while distinguishing the two distributions in polynomialtime requires $n \gtrsim d^2$ samples for a wide class of algorithms, i.e.those covered by the low-degree conjecture. These results suggest the existenceof a wide statistical-to-computational gap in this problem. Numericalexperiments show that neural networks learn to distinguish the twodistributions with quadratic sample complexity, while "lazy" methods likerandom features are not better than random guessing in this regime. Our resultsshow that neural networks extract information from higher-order correlations inthe spiked cumulant model efficiently, and reveal a large gap in the amount ofdata required by neural networks and random features to learn from higher-ordercumulants.</description><author>Eszter Székely, Lorenzo Bardone, Federica Gerace, Sebastian Goldt</author><pubDate>Mon, 19 Feb 2024 16:57:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14922v2</guid></item><item><title>Refining Minimax Regret for Unsupervised Environment Design</title><link>http://arxiv.org/abs/2402.12284v1</link><description>In unsupervised environment design, reinforcement learning agents are trainedon environment configurations (levels) generated by an adversary that maximisessome objective. Regret is a commonly used objective that theoretically resultsin a minimax regret (MMR) policy with desirable robustness guarantees; inparticular, the agent's maximum regret is bounded. However, once the agentreaches this regret bound on all levels, the adversary will only sample levelswhere regret cannot be further reduced. Although there are possible performanceimprovements to be made outside of these regret-maximising levels, learningstagnates. In this work, we introduce Bayesian level-perfect MMR (BLP), arefinement of the minimax regret objective that overcomes this limitation. Weformally show that solving for this objective results in a subset of MMRpolicies, and that BLP policies act consistently with a Perfect Bayesian policyover all levels. We further introduce an algorithm, ReMiDi, that results in aBLP policy at convergence. We empirically demonstrate that training on levelsfrom a minimax regret adversary causes learning to prematurely stagnate, butthat ReMiDi continues learning.</description><author>Michael Beukman, Samuel Coward, Michael Matthews, Mattie Fellows, Minqi Jiang, Michael Dennis, Jakob Foerster</author><pubDate>Mon, 19 Feb 2024 16:51:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12284v1</guid></item><item><title>Ontology Enhanced Claim Detection</title><link>http://arxiv.org/abs/2402.12282v1</link><description>We propose an ontology enhanced model for sentence based claim detection. Wefused ontology embeddings from a knowledge base with BERT sentence embeddingsto perform claim detection for the ClaimBuster and the NewsClaims datasets. Ourontology enhanced approach showed the best results with these small-sizedunbalanced datasets, compared to other statistical and neural machine learningmodels. The experiments demonstrate that adding domain specific features(either trained word embeddings or knowledge graph metadata) can improvetraditional ML methods. In addition, adding domain knowledge in the form ofontology embeddings helps avoid the bias encountered in neural network basedmodels, for example the pure BERT model bias towards larger classes in oursmall corpus.</description><author>Zehra Melce Hüsünbeyi, Tatjana Scheffler</author><pubDate>Mon, 19 Feb 2024 16:50:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12282v1</guid></item><item><title>Adaptive Skeleton Graph Decoding</title><link>http://arxiv.org/abs/2402.12280v1</link><description>Large language models (LLMs) have seen significant adoption for naturallanguage tasks, owing their success to massive numbers of model parameters(e.g., 70B+); however, LLM inference incurs significant computation and memorycosts. Recent approaches propose parallel decoding strategies, such asSkeleton-of-Thought (SoT), to improve performance by breaking prompts down intosub-problems that can be decoded in parallel; however, they often suffer fromreduced response quality. Our key insight is that we can request additionalinformation, specifically dependencies and difficulty, when generating thesub-problems to improve both response quality and performance. In this paper,we propose Skeleton Graph Decoding (SGD), which uses dependencies exposedbetween sub-problems to support information forwarding between dependentsub-problems for improved quality while exposing parallelization opportunitiesfor decoding independent sub-problems. Additionally, we leverage difficultyestimates for each sub-problem to select an appropriately-sized model,improving performance without significantly reducing quality. Compared tostandard autoregressive generation and SoT, SGD achieves a 1.69x speedup whileimproving quality by up to 51%.</description><author>Shuowei Jin, Yongji Wu, Haizhong Zheng, Qingzhao Zhang, Matthew Lentz, Z. Morley Mao, Atul Prakash, Feng Qian, Danyang Zhuo</author><pubDate>Mon, 19 Feb 2024 16:47:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12280v1</guid></item><item><title>It's Not Easy Being Wrong: Large Language Models Struggle with Process of Elimination Reasoning</title><link>http://arxiv.org/abs/2311.07532v2</link><description>Chain-of-thought (COT) prompting can help large language models (LLMs) reasontoward correct answers, but its efficacy in reasoning toward incorrect answersis unexplored. This process of elimination (PoE), when used with COT, canenhance self-consistency, interpretability, and tasks such as medical diagnosesof exclusion. Thus, we propose PoE with COT, where LLMs must reason towardincorrect options on multiple-choice questions. We evaluate the ability ofGPT-3.5, LLaMA-2, and Falcon to perform PoE with COT on a total of fourcommonsense and scientific reasoning datasets. We find that the strategy of PoEalways underperforms the strategy of choosing the correct answer. The agreementof these strategies is also lower than the self-consistency of each strategy.To study these issues further, we conduct error analyses and give suggestionsfor future work.</description><author>Nishant Balepur, Shramay Palta, Rachel Rudinger</author><pubDate>Mon, 19 Feb 2024 16:46:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.07532v2</guid></item><item><title>Key ingredients for effective zero-shot cross-lingual knowledge transfer in generative tasks</title><link>http://arxiv.org/abs/2402.12279v1</link><description>Zero-shot cross-lingual generation implies finetuning of the multilingualpretrained language model on a generation task in one language and then usingit to make predictions for this task in other languages. Previous works noticea frequent problem of generation in a wrong language and propose approaches toaddress it, usually using mT5 as a backbone model. In this work we comparevarious approaches proposed from the literature in unified settings, alsoincluding alternative backbone models, namely mBART and NLLB-200. We firstunderline the importance of tuning learning rate used for finetuning, whichhelps to substantially alleviate the problem of generation in the wronglanguage. Then, we show that with careful learning rate tuning, the simple fullfinetuning of the model acts as a very strong baseline and alternativeapproaches bring only marginal improvements. Finally, we find that mBARTperforms similarly to mT5 of the same size, and NLLB-200 can be competitive insome cases. Our final models reach the performance of the approach based ondata translation which is usually considered as an upper baseline for zero-shotcross-lingual generation.</description><author>Nadezhda Chirkova, Vassilina Nikoulina</author><pubDate>Mon, 19 Feb 2024 16:43:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12279v1</guid></item><item><title>A framework for conditional diffusion modelling with applications in motif scaffolding for protein design</title><link>http://arxiv.org/abs/2312.09236v2</link><description>Many protein design applications, such as binder or enzyme design, requirescaffolding a structural motif with high precision. Generative modellingparadigms based on denoising diffusion processes emerged as a leading candidateto address this motif scaffolding problem and have shown early experimentalsuccess in some cases. In the diffusion paradigm, motif scaffolding is treatedas a conditional generation task, and several conditional generation protocolswere proposed or imported from the Computer Vision literature. However, most ofthese protocols are motivated heuristically, e.g. via analogies to Langevindynamics, and lack a unifying framework, obscuring connections between thedifferent approaches. In this work, we unify conditional training andconditional sampling procedures under one common framework based on themathematically well-understood Doob's h-transform. This new perspective allowsus to draw connections between existing methods and propose a new variation onexisting conditional training protocols. We illustrate the effectiveness ofthis new protocol in both, image outpainting and motif scaffolding and findthat it outperforms standard methods.</description><author>Kieran Didi, Francisco Vargas, Simon V Mathis, Vincent Dutordoir, Emile Mathieu, Urszula J Komorowska, Pietro Lio</author><pubDate>Mon, 19 Feb 2024 16:40:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09236v2</guid></item><item><title>WorldCoder, a Model-Based LLM Agent: Building World Models by Writing Code and Interacting with the Environment</title><link>http://arxiv.org/abs/2402.12275v1</link><description>We give a model-based agent that builds a Python program representing itsknowledge of the world based on its interactions with the environment. Theworld model tries to explain its interactions, while also being optimisticabout what reward it can achieve. We do this by extending work on programsynthesis via LLMs. We study our agent on gridworlds, finding our approach ismore sample-efficient compared to deep RL, and more compute-efficient comparedto ReAct-style agents.</description><author>Hao Tang, Darren Key, Kevin Ellis</author><pubDate>Mon, 19 Feb 2024 16:39:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12275v1</guid></item><item><title>SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation</title><link>http://arxiv.org/abs/2310.12508v3</link><description>With evolving data regulations, machine unlearning (MU) has become animportant tool for fostering trust and safety in today's AI models. However,existing MU methods focusing on data and/or weight perspectives often sufferlimitations in unlearning accuracy, stability, and cross-domain applicability.To address these challenges, we introduce the concept of 'weight saliency' forMU, drawing parallels with input saliency in model explanation. This innovationdirects MU's attention toward specific model weights rather than the entiremodel, improving effectiveness and efficiency. The resultant method that wecall saliency unlearning (SalUn) narrows the performance gap with 'exact'unlearning (model retraining from scratch after removing the forgetting datapoints). To the best of our knowledge, SalUn is the first principled MUapproach that can effectively erase the influence of forgetting data, classes,or concepts in both image classification and generation tasks. As highlightedbelow, For example, SalUn yields a stability advantage in high-variance randomdata forgetting, e.g., with a 0.2% gap compared to exact unlearning on theCIFAR-10 dataset. Moreover, in preventing conditional diffusion models fromgenerating harmful images, SalUn achieves nearly 100% unlearning accuracy,outperforming current state-of-the-art baselines like Erased Stable Diffusionand Forget-Me-Not. Codes are available athttps://github.com/OPTML-Group/Unlearn-Saliency. (WARNING: This paper containsmodel outputs that may be offensive in nature.)</description><author>Chongyu Fan, Jiancheng Liu, Yihua Zhang, Dennis Wei, Eric Wong, Sijia Liu</author><pubDate>Mon, 19 Feb 2024 16:37:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12508v3</guid></item><item><title>Secure Federated Learning Across Heterogeneous Cloud and High-Performance Computing Resources -- A Case Study on Federated Fine-tuning of LLaMA 2</title><link>http://arxiv.org/abs/2402.12271v1</link><description>Federated learning enables multiple data owners to collaboratively trainrobust machine learning models without transferring large or sensitive localdatasets by only sharing the parameters of the locally trained models. In thispaper, we elaborate on the design of our Advanced Privacy-Preserving FederatedLearning (APPFL) framework, which streamlines end-to-end secure and reliablefederated learning experiments across cloud computing facilities andhigh-performance computing resources by leveraging Globus Compute, adistributed function as a service platform, and Amazon Web Services. We furtherdemonstrate the use case of APPFL in fine-tuning a LLaMA 2 7B model usingseveral cloud resources and supercomputers.</description><author>Zilinghan Li, Shilan He, Pranshu Chaturvedi, Volodymyr Kindratenko, Eliu A Huerta, Kibaek Kim, Ravi Madduri</author><pubDate>Mon, 19 Feb 2024 16:34:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12271v1</guid></item><item><title>Can AI-Generated Text be Reliably Detected?</title><link>http://arxiv.org/abs/2303.11156v3</link><description>The unregulated use of LLMs can potentially lead to malicious consequencessuch as plagiarism, generating fake news, spamming, etc. Therefore, reliabledetection of AI-generated text can be critical to ensure the responsible use ofLLMs. Recent works attempt to tackle this problem either using certain modelsignatures present in the generated text outputs or by applying watermarkingtechniques that imprint specific patterns onto them. In this paper, we showthat these detectors are not reliable in practical scenarios. In particular, wedevelop a recursive paraphrasing attack to apply on AI text, which can break awhole range of detectors, including the ones using the watermarking schemes aswell as neural network-based detectors, zero-shot classifiers, andretrieval-based detectors. Our experiments include passages around 300 tokensin length, showing the sensitivity of the detectors even in the case ofrelatively long passages. We also observe that our recursive paraphrasing onlydegrades text quality slightly, measured via human studies, and metrics such asperplexity scores and accuracy on text benchmarks. Additionally, we show thateven LLMs protected by watermarking schemes can be vulnerable against spoofingattacks aimed to mislead detectors to classify human-written text asAI-generated, potentially causing reputational damages to the developers. Inparticular, we show that an adversary can infer hidden AI text signatures ofthe LLM outputs without having white-box access to the detection method.Finally, we provide a theoretical connection between the AUROC of the bestpossible detector and the Total Variation distance between human and AI textdistributions that can be used to study the fundamental hardness of thereliable detection problem for advanced language models. Our code is publiclyavailable at https://github.com/vinusankars/Reliability-of-AI-text-detectors.</description><author>Vinu Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian, Wenxiao Wang, Soheil Feizi</author><pubDate>Mon, 19 Feb 2024 16:34:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11156v3</guid></item><item><title>Efficient Computation of Sparse and Robust Maximum Association Estimators</title><link>http://arxiv.org/abs/2311.17563v2</link><description>Although robust statistical estimators are less affected by outlyingobservations, their computation is usually more challenging. This isparticularly the case in high-dimensional sparse settings. The availability ofnew optimization procedures, mainly developed in the computer science domain,offers new possibilities for the field of robust statistics. This paperinvestigates how such procedures can be used for robust sparse associationestimators. The problem can be split into a robust estimation step followed byan optimization for the remaining decoupled, (bi-)convex problem. A combinationof the augmented Lagrangian algorithm and adaptive gradient descent isimplemented to also include suitable constraints for inducing sparsity. Weprovide results concerning the precision of the algorithm and show theadvantages over existing algorithms in this context. High-dimensional empiricalexamples underline the usefulness of this procedure. Extensions to other robustsparse estimators are possible.</description><author>Pia Pfeiffer, Andreas Alfons, Peter Filzmoser</author><pubDate>Mon, 19 Feb 2024 16:33:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.17563v2</guid></item><item><title>End-to-end Supervised Prediction of Arbitrary-size Graphs with Partially-Masked Fused Gromov-Wasserstein Matching</title><link>http://arxiv.org/abs/2402.12269v1</link><description>We present a novel end-to-end deep learning-based approach for SupervisedGraph Prediction (SGP). We introduce an original Optimal Transport (OT)-basedloss, the Partially-Masked Fused Gromov-Wasserstein loss (PM-FGW), that allowsto directly leverage graph representations such as adjacency and featurematrices. PM-FGW exhibits all the desirable properties for SGP: it is nodepermutation invariant, sub-differentiable and handles graphs of different sizesby comparing their padded representations as well as their masking vectors.Moreover, we present a flexible transformer-based architecture that easilyadapts to different types of input data. In the experimental section, threedifferent tasks, a novel and challenging synthetic dataset (image2graph) andtwo real-world tasks, image2map and fingerprint2molecule - showcase theefficiency and versatility of the approach compared to competitors.</description><author>Paul Krzakala, Junjie Yang, Rémi Flamary, Florence d'Alché Buc, Charlotte Laclau, Matthieu Labeau</author><pubDate>Mon, 19 Feb 2024 16:30:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12269v1</guid></item><item><title>Social Bias Probing: Fairness Benchmarking for Language Models</title><link>http://arxiv.org/abs/2311.09090v2</link><description>Large language models have been shown to encode a variety of social biases,which carries the risk of downstream harms. While the impact of these biaseshas been recognized, prior methods for bias evaluation have been limited tobinary association tests on small datasets, offering a constrained view of thenature of societal biases within language models. In this paper, we propose anoriginal framework for probing language models for societal biases. We collecta probing dataset to analyze language models' general associations, as well asalong the axes of societal categories, identities, and stereotypes. To thisend, we leverage a novel perplexity-based fairness score. We curate alarge-scale benchmarking dataset addressing drawbacks and limitations ofexisting fairness collections, expanding to a variety of different identitiesand stereotypes. When comparing our methodology with prior work, we demonstratethat biases within language models are more nuanced than previouslyacknowledged. In agreement with recent findings, we find that larger modelvariants exhibit a higher degree of bias. Moreover, we expose how identitiesexpressing different religions lead to the most pronounced disparate treatmentsacross all models.</description><author>Marta Marchiori Manerba, Karolina Stańczak, Riccardo Guidotti, Isabelle Augenstein</author><pubDate>Mon, 19 Feb 2024 16:30:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09090v2</guid></item><item><title>High-quality Data-to-Text Generation for Severely Under-Resourced Languages with Out-of-the-box Large Language Models</title><link>http://arxiv.org/abs/2402.12267v1</link><description>The performance of NLP methods for severely under-resourced languages cannotcurrently hope to match the state of the art in NLP methods for well resourcedlanguages. We explore the extent to which pretrained large language models(LLMs) can bridge this gap, via the example of data-to-text generation forIrish, Welsh, Breton and Maltese. We test LLMs on these under-resourcedlanguages and English, in a range of scenarios. We find that LLMs easily setthe state of the art for the under-resourced languages by substantial margins,as measured by both automatic and human evaluations. For all our languages,human evaluation shows on-a-par performance with humans for our best systems,but BLEU scores collapse compared to English, casting doubt on the metric'ssuitability for evaluating non-task-specific systems. Overall, our resultsdemonstrate the great potential of LLMs to bridge the performance gap forunder-resourced languages.</description><author>Michela Lorandi, Anya Belz</author><pubDate>Mon, 19 Feb 2024 16:29:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12267v1</guid></item><item><title>On the Byzantine-Resilience of Distillation-Based Federated Learning</title><link>http://arxiv.org/abs/2402.12265v1</link><description>Federated Learning (FL) algorithms using Knowledge Distillation (KD) havereceived increasing attention due to their favorable properties with respect toprivacy, non-i.i.d. data and communication cost. These methods depart fromtransmitting model parameters and, instead, communicate information about alearning task by sharing predictions on a public dataset. In this work, westudy the performance of such approaches in the byzantine setting, where asubset of the clients act in an adversarial manner aiming to disrupt thelearning process. We show that KD-based FL algorithms are remarkably resilientand analyze how byzantine clients can influence the learning process comparedto Federated Averaging. Based on these insights, we introduce two new byzantineattacks and demonstrate that they are effective against priorbyzantine-resilient methods. Additionally, we propose FilterExp, a novel methoddesigned to enhance the byzantine resilience of KD-based FL algorithms anddemonstrate its efficacy. Finally, we provide a general method to make attacksharder to detect, improving their effectiveness.</description><author>Christophe Roux, Max Zimmer, Sebastian Pokutta</author><pubDate>Mon, 19 Feb 2024 16:26:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12265v1</guid></item><item><title>Uncertainty quantification in fine-tuned LLMs using LoRA ensembles</title><link>http://arxiv.org/abs/2402.12264v1</link><description>Fine-tuning large language models can improve task specific performance,although a general understanding of what the fine-tuned model has learned,forgotten and how to trust its predictions is still missing. We deriveprincipled uncertainty quantification for fine-tuned LLMs with posteriorapproximations using computationally efficient low-rank adaptation ensembles.We analyze three common multiple-choice datasets using low-rank adaptationensembles based on Mistral-7b, and draw quantitative and qualitativeconclusions on their perceived complexity and model efficacy on the differenttarget domains during and after fine-tuning. In particular, backed by thenumerical experiments, we hypothesise about signals from entropic uncertaintymeasures for data domains that are inherently difficult for a givenarchitecture to learn.</description><author>Oleksandr Balabanov, Hampus Linander</author><pubDate>Mon, 19 Feb 2024 16:26:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12264v1</guid></item><item><title>Towards a tailored mixed-precision sub-8bit quantization scheme for Gated Recurrent Units using Genetic Algorithms</title><link>http://arxiv.org/abs/2402.12263v1</link><description>Despite the recent advances in model compression techniques for deep neuralnetworks, deploying such models on ultra-low-power embedded devices stillproves challenging. In particular, quantization schemes for Gated RecurrentUnits (GRU) are difficult to tune due to their dependence on an internal state,preventing them from fully benefiting from sub-8bit quantization. In this work,we propose a modular integer quantization scheme for GRUs where the bit widthof each operator can be selected independently. We then employ GeneticAlgorithms (GA) to explore the vast search space of possible bit widths,simultaneously optimising for model size and accuracy. We evaluate our methodson four different sequential tasks and demonstrate that mixed-precisionsolutions exceed homogeneous-precision ones in terms of Pareto efficiency. Inour results, we achieve a model size reduction between 25% and 55% whilemaintaining an accuracy comparable with the 8-bit homogeneous equivalent.</description><author>Riccardo Miccini, Alessandro Cerioli, Clément Laroche, Tobias Piechowiak, Jens Sparsø, Luca Pezzarossa</author><pubDate>Mon, 19 Feb 2024 16:24:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12263v1</guid></item><item><title>Accelerating Approximate Thompson Sampling with Underdamped Langevin Monte Carlo</title><link>http://arxiv.org/abs/2401.11665v2</link><description>Approximate Thompson sampling with Langevin Monte Carlo broadens its reachfrom Gaussian posterior sampling to encompass more general smooth posteriors.However, it still encounters scalability issues in high-dimensional problemswhen demanding high accuracy. To address this, we propose an approximateThompson sampling strategy, utilizing underdamped Langevin Monte Carlo, wherethe latter is the go-to workhorse for simulations of high-dimensionalposteriors. Based on the standard smoothness and log-concavity conditions, westudy the accelerated posterior concentration and sampling using a specificpotential function. This design improves the sample complexity for realizinglogarithmic regrets from $\mathcal{\tilde O}(d)$ to $\mathcal{\tildeO}(\sqrt{d})$. The scalability and robustness of our algorithm are alsoempirically validated through synthetic experiments in high-dimensional banditproblems.</description><author>Haoyang Zheng, Wei Deng, Christian Moya, Guang Lin</author><pubDate>Mon, 19 Feb 2024 16:23:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11665v2</guid></item><item><title>Robust Errant Beam Prognostics with Conditional Modeling for Particle Accelerators</title><link>http://arxiv.org/abs/2312.10040v2</link><description>Particle accelerators are complex and comprise thousands of components, withmany pieces of equipment running at their peak power. Consequently, particleaccelerators can fault and abort operations for numerous reasons. These faultsimpact the availability of particle accelerators during scheduled run-time andhamper the efficiency and the overall science output. To avoid these faults, weapply anomaly detection techniques to predict any unusual behavior and performpreemptive actions to improve the total availability of particle accelerators.Semi-supervised Machine Learning (ML) based anomaly detection approaches suchas autoencoders and variational autoencoders are often used for such tasks.However, supervised ML techniques such as Siamese Neural Network (SNN) modelscan outperform unsupervised or semi-supervised approaches for anomaly detectionby leveraging the label information. One of the challenges specific to anomalydetection for particle accelerators is the data's variability due to systemconfiguration changes. To address this challenge, we employ Conditional SiameseNeural Network (CSNN) models and Conditional Variational Auto Encoder (CVAE)models to predict errant beam pulses at the Spallation Neutron Source (SNS)under different system configuration conditions and compare their performance.We demonstrate that CSNN outperforms CVAE in our application.</description><author>Kishansingh Rajput, Malachi Schram, Willem Blokland, Yasir Alanazi, Pradeep Ramuhalli, Alexander Zhukov, Charles Peters, Ricardo Vilalta</author><pubDate>Mon, 19 Feb 2024 16:21:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10040v2</guid></item><item><title>NEO-BENCH: Evaluating Robustness of Large Language Models with Neologisms</title><link>http://arxiv.org/abs/2402.12261v1</link><description>The performance of Large Language Models (LLMs) degrades from the temporaldrift between data used for model training and newer text seen duringinference. One understudied avenue of language change causing data drift is theemergence of neologisms -- new word forms -- over time. We create a diverseresource of recent English neologisms by using several popular collectionmethods. We analyze temporal drift using neologisms by comparing sentencescontaining new words with near-identical sentences that replace neologisms withexisting substitute words. Model performance is nearly halved in machinetranslation when a single neologism is introduced in a sentence. Motivated bythese results, we construct a benchmark to evaluate LLMs' ability to generalizeto neologisms with various natural language understanding tasks and modelperplexity. Models with later knowledge cutoff dates yield lower perplexitiesand perform better in downstream tasks. LLMs are also affected differentlybased on the linguistic origins of words, indicating that neologisms arecomplex for static LLMs to address. We will release our benchmark and code forreproducing our experiments.</description><author>Jonathan Zheng, Alan Ritter, Wei Xu</author><pubDate>Mon, 19 Feb 2024 16:19:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12261v1</guid></item><item><title>A Unified Approach to Emotion Detection and Task-Oriented Dialogue Modeling</title><link>http://arxiv.org/abs/2401.13789v2</link><description>In current text-based task-oriented dialogue (TOD) systems, user emotiondetection (ED) is often overlooked or is typically treated as a separate andindependent task, requiring additional training. In contrast, our workdemonstrates that seamlessly unifying ED and TOD modeling brings about mutualbenefits, and is therefore an alternative to be considered. Our method consistsin augmenting SimpleToD, an end-to-end TOD system, by extending belief statetracking to include ED, relying on a single language model. We evaluate ourapproach using GPT-2 and Llama-2 on the EmoWOZ benchmark, a version of MultiWOZannotated with emotions. Our results reveal a general increase in performancefor ED and task results. Our findings also indicate that user emotions provideuseful contextual conditioning for system responses, and can be leveraged tofurther refine responses in terms of empathy.</description><author>Armand Stricker, Patrick Paroubek</author><pubDate>Mon, 19 Feb 2024 16:18:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13789v2</guid></item><item><title>Open3DSG: Open-Vocabulary 3D Scene Graphs from Point Clouds with Queryable Objects and Open-Set Relationships</title><link>http://arxiv.org/abs/2402.12259v1</link><description>Current approaches for 3D scene graph prediction rely on labeled datasets totrain models for a fixed set of known object classes and relationshipcategories. We present Open3DSG, an alternative approach to learn 3D scenegraph prediction in an open world without requiring labeled scene graph data.We co-embed the features from a 3D scene graph prediction backbone with thefeature space of powerful open world 2D vision language foundation models. Thisenables us to predict 3D scene graphs from 3D point clouds in a zero-shotmanner by querying object classes from an open vocabulary and predicting theinter-object relationships from a grounded LLM with scene graph features andqueried object classes as context. Open3DSG is the first 3D point cloud methodto predict not only explicit open-vocabulary object classes, but also open-setrelationships that are not limited to a predefined label set, making itpossible to express rare as well as specific objects and relationships in thepredicted 3D scene graph. Our experiments show that Open3DSG is effective atpredicting arbitrary object classes as well as their complex inter-objectrelationships describing spatial, supportive, semantic and comparativerelationships.</description><author>Sebastian Koch, Narunas Vaskevicius, Mirco Colosi, Pedro Hermosilla, Timo Ropinski</author><pubDate>Mon, 19 Feb 2024 16:15:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12259v1</guid></item><item><title>Shallow Synthesis of Knowledge in GPT-Generated Texts: A Case Study in Automatic Related Work Composition</title><link>http://arxiv.org/abs/2402.12255v1</link><description>Numerous AI-assisted scholarly applications have been developed to aiddifferent stages of the research process. We present an analysis of AI-assistedscholarly writing generated with ScholaCite, a tool we built that is designedfor organizing literature and composing Related Work sections for academicpapers. Our evaluation method focuses on the analysis of citation graphs toassess the structural complexity and inter-connectedness of citations in textsand involves a three-way comparison between (1) original human-written texts,(2) purely GPT-generated texts, and (3) human-AI collaborative texts. We findthat GPT-4 can generate reasonable coarse-grained citation groupings to supporthuman users in brainstorming, but fails to perform detailed synthesis ofrelated works without human intervention. We suggest that future writingassistant tools should not be used to draft text independently of the humanauthor.</description><author>Anna Martin-Boyle, Aahan Tyagi, Marti A. Hearst, Dongyeop Kang</author><pubDate>Mon, 19 Feb 2024 16:14:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12255v1</guid></item><item><title>Doing Experiments and Revising Rules with Natural Language and Probabilistic Reasoning</title><link>http://arxiv.org/abs/2402.06025v2</link><description>We build a computational model of how humans actively infer hidden rules bydoing experiments. The basic principles behind the model is that, even if therule is deterministic, the learner considers a broader space of fuzzyprobabilistic rules, which it represents in natural language, and updates itshypotheses online after each experiment according to approximately Bayesianprinciples. In the same framework we also model experiment design according toinformation-theoretic criteria. We find that the combination of these threeprinciples -- explicit hypotheses, probabilistic rules, and online updates --can explain human performance on a Zendo-style task, and that removing any ofthese components leaves the model unable to account for the data.</description><author>Top Piriyakulkij, Kevin Ellis</author><pubDate>Mon, 19 Feb 2024 16:09:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.06025v2</guid></item><item><title>Analysis of Levenshtein Transformer's Decoder and Its Variants</title><link>http://arxiv.org/abs/2402.12249v1</link><description>Levenshtein transformer (LevT) is a non-autoregressive machine translationmodel with high decoding efficiency and comparable translation quality in termsof bleu score, due to its parallel decoding and iterative refinement procedure.Are there any deficiencies of its translations and what improvements could bemade? In this report, we focus on LevT's decoder and analyse the decodingresults length, subword generation, and deletion module's capability. We hopeto identify weaknesses of the decoder for future improvements. We also compare translations of the original LevT, knowledge-distilled LevT,LevT with translation memory, and the KD-LevT with translation memory to seehow KD and translation memory can help.</description><author>Ruiyang Zhou</author><pubDate>Mon, 19 Feb 2024 16:05:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12249v1</guid></item><item><title>Understanding the Effects of Noise in Text-to-SQL: An Examination of the BIRD-Bench Benchmark</title><link>http://arxiv.org/abs/2402.12243v1</link><description>Text-to-SQL, which involves translating natural language into StructuredQuery Language (SQL), is crucial for enabling broad access to structureddatabases without expert knowledge. However, designing models for such tasks ischallenging due to numerous factors, including the presence of 'noise,' such asambiguous questions and syntactical errors. This study provides an in-depthanalysis of the distribution and types of noise in the widely used BIRD-Benchbenchmark and the impact of noise on models. While BIRD-Bench was created tomodel dirty and noisy database values, it was not created to contain noise anderrors in the questions and gold queries. We found that noise in questions andgold queries are prevalent in the dataset, with varying amounts across domains,and with an uneven distribution between noise types. The presence of incorrectgold SQL queries, which then generate incorrect gold answers, has a significantimpact on the benchmark's reliability. Surprisingly, when evaluating models oncorrected SQL queries, zero-shot baselines surpassed the performance ofstate-of-the-art prompting methods. We conclude that informative noise labelsand reliable benchmarks are crucial to developing new Text-to-SQL methods thatcan handle varying types of noise.</description><author>Niklas Wretblad, Fredrik Gordh Riseby, Rahul Biswas, Amin Ahmadi, Oskar Holmström</author><pubDate>Mon, 19 Feb 2024 15:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12243v1</guid></item><item><title>Synthetic location trajectory generation using categorical diffusion models</title><link>http://arxiv.org/abs/2402.12242v1</link><description>Diffusion probabilistic models (DPMs) have rapidly evolved to be one of thepredominant generative models for the simulation of synthetic data, forinstance, for computer vision, audio, natural language processing, orbiomolecule generation. Here, we propose using DPMs for the generation ofsynthetic individual location trajectories (ILTs) which are sequences ofvariables representing physical locations visited by individuals. ILTs are ofmajor importance in mobility research to understand the mobility behavior ofpopulations and to ultimately inform political decision-making. We representILTs as multi-dimensional categorical random variables and propose to modeltheir joint distribution using a continuous DPM by first applying the diffusionprocess in a continuous unconstrained space and then mapping the continuousvariables into a discrete space. We demonstrate that our model can synthesizerealistic ILPs by comparing conditionally and unconditionally generatedsequences to real-world ILPs from a GNSS tracking data set which suggests thepotential use of our model for synthetic data generation, for example, forbenchmarking models used in mobility research.</description><author>Simon Dirmeier, Ye Hong, Fernando Perez-Cruz</author><pubDate>Mon, 19 Feb 2024 15:57:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12242v1</guid></item><item><title>Convergence of Gradient Descent for Recurrent Neural Networks: A Nonasymptotic Analysis</title><link>http://arxiv.org/abs/2402.12241v1</link><description>We analyze recurrent neural networks trained with gradient descent in thesupervised learning setting for dynamical systems, and prove that gradientdescent can achieve optimality \emph{without} massive overparameterization. Ourin-depth nonasymptotic analysis (i) provides sharp bounds on the network size$m$ and iteration complexity $\tau$ in terms of the sequence length $T$, samplesize $n$ and ambient dimension $d$, and (ii) identifies the significant impactof long-term dependencies in the dynamical system on the convergence andnetwork width bounds characterized by a cutoff point that depends on theLipschitz continuity of the activation function. Remarkably, this analysisreveals that an appropriately-initialized recurrent neural network trained with$n$ samples can achieve optimality with a network size $m$ that scales onlylogarithmically with $n$. This sharply contrasts with the prior works thatrequire high-order polynomial dependency of $m$ on $n$ to establish strongregularity conditions. Our results are based on an explicit characterization ofthe class of dynamical systems that can be approximated and learned byrecurrent neural networks via norm-constrained transportation mappings, andestablishing local smoothness properties of the hidden state with respect tothe learnable parameters.</description><author>Semih Cayci, Atilla Eryilmaz</author><pubDate>Mon, 19 Feb 2024 15:56:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12241v1</guid></item><item><title>BEARS Make Neuro-Symbolic Models Aware of their Reasoning Shortcuts</title><link>http://arxiv.org/abs/2402.12240v1</link><description>Neuro-Symbolic (NeSy) predictors that conform to symbolic knowledge -encoding, e.g., safety constraints - can be affected by Reasoning Shortcuts(RSs): They learn concepts consistent with the symbolic knowledge by exploitingunintended semantics. RSs compromise reliability and generalization and, as weshow in this paper, they are linked to NeSy models being overconfident aboutthe predicted concepts. Unfortunately, the only trustworthy mitigation strategyrequires collecting costly dense supervision over the concepts. Rather thanattempting to avoid RSs altogether, we propose to ensure NeSy models are awareof the semantic ambiguity of the concepts they learn, thus enabling their usersto identify and distrust low-quality concepts. Starting from three simpledesiderata, we derive bears (BE Aware of Reasoning Shortcuts), an ensemblingtechnique that calibrates the model's concept-level confidence withoutcompromising prediction accuracy, thus encouraging NeSy architectures to beuncertain about concepts affected by RSs. We show empirically that bearsimproves RS-awareness of several state-of-the-art NeSy models, and alsofacilitates acquiring informative dense annotations for mitigation purposes.</description><author>Emanuele Marconato, Samuele Bortolotti, Emile van Krieken, Antonio Vergari, Andrea Passerini, Stefano Teso</author><pubDate>Mon, 19 Feb 2024 15:54:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12240v1</guid></item><item><title>Denoising Diffusion Variational Inference: Diffusion Models as Expressive Variational Posteriors</title><link>http://arxiv.org/abs/2401.02739v2</link><description>We propose denoising diffusion variational inference (DDVI), an approximateinference algorithm for latent variable models which relies on diffusion modelsas flexible variational posteriors. Specifically, our method introduces anexpressive class of approximate posteriors with auxiliary latent variables thatperform diffusion in latent space by reversing a user-specified noisingprocess. We fit these models by optimizing a lower bound on the marginallikelihood inspired by the wake-sleep algorithm. Our method is easy toimplement (it fits a regularized extension of the ELBO), is compatible withblack-box variational inference, and outperforms alternative classes ofapproximate posteriors based on normalizing flows or adversarial networks. Itincreases the expressivity of flow-based methods via non-invertible deeprecurrent architectures and avoids the instability of adversarial methods. Weuse DDVI on a motivating task in biology -- inferring latent ancestry fromhuman genomes -- and we find that it outperforms strong baselines on theThousand Genomes dataset.</description><author>Top Piriyakulkij, Yingheng Wang, Volodymyr Kuleshov</author><pubDate>Mon, 19 Feb 2024 15:50:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.02739v2</guid></item><item><title>Mixed Gaussian Flow for Diverse Trajectory Prediction</title><link>http://arxiv.org/abs/2402.12238v1</link><description>Existing trajectory prediction studies intensively leverage generativemodels. Normalizing flow is one of the genres with the advantage of beinginvertible to derive the probability density of predicted trajectories.However, mapping from a standard Gaussian by a flow-based model hurts thecapacity to capture complicated patterns of trajectories, ignoring theunder-represented motion intentions in the training data. To solve the problem,we propose a flow-based model to transform a mixed Gaussian prior into thefuture trajectory manifold. The model shows a better capacity for generatingdiverse trajectory patterns. Also, by associating each sub-Gaussian with acertain subspace of trajectories, we can generate future trajectories withcontrollable motion intentions. In such a fashion, the flow-based model is notencouraged to simply seek the most likelihood of the intended manifold anymorebut a family of controlled manifolds with explicit interpretability. Ourproposed method is demonstrated to show state-of-the-art performance in thequantitative evaluation of sampling well-aligned trajectories in top-Mgenerated candidates. We also demonstrate that it can generate diverse,controllable, and out-of-distribution trajectories. Code is available athttps://github.com/mulplue/MGF.</description><author>Jiahe Chen, Jinkun Cao, Dahua Lin, Kris Kitani, Jiangmiao Pang</author><pubDate>Mon, 19 Feb 2024 15:48:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12238v1</guid></item><item><title>Learning to Defer in Content Moderation: The Human-AI Interplay</title><link>http://arxiv.org/abs/2402.12237v1</link><description>Successful content moderation in online platforms relies on a human-AIcollaboration approach. A typical heuristic estimates the expected harmfulnessof a post and uses fixed thresholds to decide whether to remove it and whetherto send it for human review. This disregards the prediction uncertainty, thetime-varying element of human review capacity and post arrivals, and theselective sampling in the dataset (humans only review posts filtered by theadmission algorithm). In this paper, we introduce a model to capture the human-AI interplay incontent moderation. The algorithm observes contextual information for incomingposts, makes classification and admission decisions, and schedules posts forhuman review. Only admitted posts receive human reviews on their harmfulness.These reviews help educate the machine-learning algorithms but are delayed dueto congestion in the human review system. The classical learning-theoretic wayto capture this human-AI interplay is via the framework of learning to defer,where the algorithm has the option to defer a classification task to humans fora fixed cost and immediately receive feedback. Our model contributes to thisliterature by introducing congestion in the human review system. Moreover,unlike work on online learning with delayed feedback where the delay in thefeedback is exogenous to the algorithm's decisions, the delay in our model isendogenous to both the admission and the scheduling decisions. We propose a near-optimal learning algorithm that carefully balances theclassification loss from a selectively sampled dataset, the idiosyncratic lossof non-reviewed posts, and the delay loss of having congestion in the humanreview system. To the best of our knowledge, this is the first result foronline learning in contextual queueing systems and hence our analyticalframework may be of independent interest.</description><author>Thodoris Lykouris, Wentao Weng</author><pubDate>Mon, 19 Feb 2024 15:47:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12237v1</guid></item><item><title>The Fundamental Limits of Least-Privilege Learning</title><link>http://arxiv.org/abs/2402.12235v1</link><description>The promise of least-privilege learning -- to find feature representationsthat are useful for a learning task but prevent inference of any sensitiveinformation unrelated to this task -- is highly appealing. However, so far thisconcept has only been stated informally. It thus remains an open questionwhether and how we can achieve this goal. In this work, we provide the firstformalisation of the least-privilege principle for machine learning andcharacterise its feasibility. We prove that there is a fundamental trade-offbetween a representation's utility for a given task and its leakage beyond theintended task: it is not possible to learn representations that have highutility for the intended task but, at the same time prevent inference of anyattribute other than the task label itself. This trade-off holds regardless ofthe technique used to learn the feature mappings that produce theserepresentations. We empirically validate this result for a wide range oflearning techniques, model architectures, and datasets.</description><author>Theresa Stadler, Bogdan Kulynych, Nicoals Papernot, Michael Gastpar, Carmela Troncoso</author><pubDate>Mon, 19 Feb 2024 15:44:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12235v1</guid></item><item><title>Task-Oriented Dialogue with In-Context Learning</title><link>http://arxiv.org/abs/2402.12234v1</link><description>We describe a system for building task-oriented dialogue systems combiningthe in-context learning abilities of large language models (LLMs) with thedeterministic execution of business logic. LLMs are used to translate betweenthe surface form of the conversation and a domain-specific language (DSL) whichis used to progress the business logic. We compare our approach to theintent-based NLU approach predominantly used in industry today. Our experimentsshow that developing chatbots with our system requires significantly lesseffort than established approaches, that these chatbots can successfullynavigate complex dialogues which are extremely challenging for NLU-basedsystems, and that our system has desirable properties for scaling task-orienteddialogue systems to a large number of tasks. We make our implementationavailable for use and further study.</description><author>Tom Bocklisch, Thomas Werkmeister, Daksh Varshneya, Alan Nichol</author><pubDate>Mon, 19 Feb 2024 15:43:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12234v1</guid></item><item><title>Empirical Study on Updating Key-Value Memories in Transformer Feed-forward Layers</title><link>http://arxiv.org/abs/2402.12233v1</link><description>The feed-forward networks (FFNs) in transformers are recognized as a group ofkey-value neural memories to restore abstract high-level knowledge. In thiswork, we conduct an empirical ablation study on updating keys (the 1st layer inthe FFNs layer) or values (the 2nd layer in the FFNs layer). We compare thosetwo methods in various knowledge editing and fine-tuning tasks of largelanguage models to draw insights to understand FFNs further. Code is availableat $\href{https://github.com/qiuzh20/Tuning-keys-v.s.-values}{this\,repo}$.</description><author>Zihan Qiu, Zeyu Huang, Youcheng Huang, Jie Fu</author><pubDate>Mon, 19 Feb 2024 15:42:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12233v1</guid></item><item><title>Kernel KMeans clustering splits for end-to-end unsupervised decision trees</title><link>http://arxiv.org/abs/2402.12232v1</link><description>Trees are convenient models for obtaining explainable predictions onrelatively small datasets. Although there are many proposals for the end-to-endconstruction of such trees in supervised learning, learning a tree end-to-endfor clustering without labels remains an open challenge. As most works focus oninterpreting with trees the result of another clustering algorithm, we presenthere a novel end-to-end trained unsupervised binary tree for clustering: Kauri.This method performs a greedy maximisation of the kernel KMeans objectivewithout requiring the definition of centroids. We compare this model onmultiple datasets with recent unsupervised trees and show that Kauri performsidentically when using a linear kernel. For other kernels, Kauri oftenoutperforms the concatenation of kernel KMeans and a CART decision tree.</description><author>Louis Ohl, Pierre-Alexandre Mattei, Mickaël Leclercq, Arnaud Droit, Frédéric Precioso</author><pubDate>Mon, 19 Feb 2024 15:39:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12232v1</guid></item><item><title>Diffusion Tempering Improves Parameter Estimation with Probabilistic Integrators for Ordinary Differential Equations</title><link>http://arxiv.org/abs/2402.12231v1</link><description>Ordinary differential equations (ODEs) are widely used to describe dynamicalsystems in science, but identifying parameters that explain experimentalmeasurements is challenging. In particular, although ODEs are differentiableand would allow for gradient-based parameter optimization, the nonlineardynamics of ODEs often lead to many local minima and extreme sensitivity toinitial conditions. We therefore propose diffusion tempering, a novelregularization technique for probabilistic numerical methods which improvesconvergence of gradient-based parameter optimization in ODEs. By iterativelyreducing a noise parameter of the probabilistic integrator, the proposed methodconverges more reliably to the true parameters. We demonstrate that our methodis effective for dynamical systems of different complexity and show that itobtains reliable parameter estimates for a Hodgkin-Huxley model with apractically relevant number of parameters.</description><author>Jonas Beck, Nathanael Bosch, Michael Deistler, Kyra L. Kadhim, Jakob H. Macke, Philipp Hennig, Philipp Berens</author><pubDate>Mon, 19 Feb 2024 15:36:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12231v1</guid></item><item><title>Task-Specific Normalization for Continual Learning of Blind Image Quality Models</title><link>http://arxiv.org/abs/2107.13429v3</link><description>In this paper, we present a simple yet effective continual learning methodfor blind image quality assessment (BIQA) with improved quality predictionaccuracy, plasticity-stability trade-off, and task-order/-length robustness.The key step in our approach is to freeze all convolution filters of apre-trained deep neural network (DNN) for an explicit promise of stability, andlearn task-specific normalization parameters for plasticity. We assign each newIQA dataset (i.e., task) a prediction head, and load the correspondingnormalization parameters to produce a quality score. The final quality estimateis computed by black a weighted summation of predictions from all heads with alightweight $K$-means gating mechanism. Extensive experiments on six IQAdatasets demonstrate the advantages of the proposed method in comparison toprevious training techniques for BIQA.</description><author>Weixia Zhang, Kede Ma, Guangtao Zhai, Xiaokang Yang</author><pubDate>Mon, 19 Feb 2024 15:36:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.13429v3</guid></item><item><title>UFO: A UI-Focused Agent for Windows OS Interaction</title><link>http://arxiv.org/abs/2402.07939v2</link><description>We introduce UFO, an innovative UI-Focused agent to fulfill user requeststailored to applications on Windows OS, harnessing the capabilities ofGPT-Vision. UFO employs a dual-agent framework to meticulously observe andanalyze the graphical user interface (GUI) and control information of Windowsapplications. This enables the agent to seamlessly navigate and operate withinindividual applications and across them to fulfill user requests, even whenspanning multiple applications. The framework incorporates a controlinteraction module, facilitating action grounding without human interventionand enabling fully automated execution. Consequently, UFO transforms arduousand time-consuming processes into simple tasks achievable solely throughnatural language commands. We conducted testing of UFO across 9 popular Windowsapplications, encompassing a variety of scenarios reflective of users' dailyusage. The results, derived from both quantitative metrics and real-casestudies, underscore the superior effectiveness of UFO in fulfilling userrequests. To the best of our knowledge, UFO stands as the first UI agentspecifically tailored for task completion within the Windows OS environment.The open-source code for UFO is available on https://github.com/microsoft/UFO.</description><author>Chaoyun Zhang, Liqun Li, Shilin He, Xu Zhang, Bo Qiao, Si Qin, Minghua Ma, Yu Kang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang</author><pubDate>Mon, 19 Feb 2024 15:33:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07939v2</guid></item><item><title>AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling</title><link>http://arxiv.org/abs/2402.12226v1</link><description>We introduce AnyGPT, an any-to-any multimodal language model that utilizesdiscrete representations for the unified processing of various modalities,including speech, text, images, and music. AnyGPT can be trained stably withoutany alterations to the current large language model (LLM) architecture ortraining paradigms. Instead, it relies exclusively on data-level preprocessing,facilitating the seamless integration of new modalities into LLMs, akin to theincorporation of new languages. We build a multimodal text-centric dataset formultimodal alignment pre-training. Utilizing generative models, we synthesizethe first large-scale any-to-any multimodal instruction dataset. It consists of108k samples of multi-turn conversations that intricately interweave variousmodalities, thus equipping the model to handle arbitrary combinations ofmultimodal inputs and outputs. Experimental results demonstrate that AnyGPT iscapable of facilitating any-to-any multimodal conversation while achievingperformance comparable to specialized models across all modalities, provingthat discrete representations can effectively and conveniently unify multiplemodalities within a language model. Demos are shown inhttps://junzhan2000.github.io/AnyGPT.github.io/</description><author>Jun Zhan, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, Hang Yan, Jie Fu, Tao Gui, Tianxiang Sun, Yugang Jiang, Xipeng Qiu</author><pubDate>Mon, 19 Feb 2024 15:33:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12226v1</guid></item><item><title>Pushing Auto-regressive Models for 3D Shape Generation at Capacity and Scalability</title><link>http://arxiv.org/abs/2402.12225v1</link><description>Auto-regressive models have achieved impressive results in 2D imagegeneration by modeling joint distributions in grid space. In this paper, weextend auto-regressive models to 3D domains, and seek a stronger ability of 3Dshape generation by improving auto-regressive models at capacity andscalability simultaneously. Firstly, we leverage an ensemble of publiclyavailable 3D datasets to facilitate the training of large-scale models. Itconsists of a comprehensive collection of approximately 900,000 objects, withmultiple properties of meshes, points, voxels, rendered images, and textcaptions. This diverse labeled dataset, termed Objaverse-Mix, empowers ourmodel to learn from a wide range of object variations. However, directlyapplying 3D auto-regression encounters critical challenges of highcomputational demands on volumetric grids and ambiguous auto-regressive orderalong grid dimensions, resulting in inferior quality of 3D shapes. To this end,we then present a novel framework Argus3D in terms of capacity. Concretely, ourapproach introduces discrete representation learning based on a latent vectorinstead of volumetric grids, which not only reduces computational costs butalso preserves essential geometric details by learning the joint distributionsin a more tractable order. The capacity of conditional generation can thus berealized by simply concatenating various conditioning inputs to the latentvector, such as point clouds, categories, images, and texts. In addition,thanks to the simplicity of our model architecture, we naturally scale up ourapproach to a larger model with an impressive 3.6 billion parameters, furtherenhancing the quality of versatile 3D generation. Extensive experiments on fourgeneration tasks demonstrate that Argus3D can synthesize diverse and faithfulshapes across multiple categories, achieving remarkable performance.</description><author>Xuelin Qian, Yu Wang, Simian Luo, Yinda Zhang, Ying Tai, Zhenyu Zhang, Chengjie Wang, Xiangyang Xue, Bo Zhao, Tiejun Huang, Yunsheng Wu, Yanwei Fu</author><pubDate>Mon, 19 Feb 2024 15:33:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12225v1</guid></item><item><title>LaneGraph2Seq: Lane Topology Extraction with Language Model via Vertex-Edge Encoding and Connectivity Enhancement</title><link>http://arxiv.org/abs/2401.17609v2</link><description>Understanding road structures is crucial for autonomous driving. Intricateroad structures are often depicted using lane graphs, which include centerlinecurves and connections forming a Directed Acyclic Graph (DAG). Accurateextraction of lane graphs relies on precisely estimating vertex and edgeinformation within the DAG. Recent research highlights Transformer-basedlanguage models' impressive sequence prediction abilities, making themeffective for learning graph representations when graph data are encoded assequences. However, existing studies focus mainly on modeling verticesexplicitly, leaving edge information simply embedded in the network.Consequently, these approaches fall short in the task of lane graph extraction.To address this, we introduce LaneGraph2Seq, a novel approach for lane graphextraction. It leverages a language model with vertex-edge encoding andconnectivity enhancement. Our serialization strategy includes a vertex-centricdepth-first traversal and a concise edge-based partition sequence.Additionally, we use classifier-free guidance combined with nucleus sampling toimprove lane connectivity. We validate our method on prominent datasets,nuScenes and Argoverse 2, showcasing consistent and compelling results. OurLaneGraph2Seq approach demonstrates superior performance compared tostate-of-the-art techniques in lane graph extraction.</description><author>Renyuan Peng, Xinyue Cai, Hang Xu, Jiachen Lu, Feng Wen, Wei Zhang, Li Zhang</author><pubDate>Mon, 19 Feb 2024 15:32:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17609v2</guid></item><item><title>CovRL: Fuzzing JavaScript Engines with Coverage-Guided Reinforcement Learning for LLM-based Mutation</title><link>http://arxiv.org/abs/2402.12222v1</link><description>Fuzzing is an effective bug-finding technique but it struggles with complexsystems like JavaScript engines that demand precise grammatical input.Recently, researchers have adopted language models for context-aware mutationin fuzzing to address this problem. However, existing techniques are limited inutilizing coverage guidance for fuzzing, which is rather performed in ablack-box manner. This paper presents a novel technique called CovRL(Coverage-guided Reinforcement Learning) that combines Large Language Models(LLMs) with reinforcement learning from coverage feedback. Our fuzzer,CovRL-Fuzz, integrates coverage feedback directly into the LLM by leveragingthe Term Frequency-Inverse Document Frequency (TF-IDF) method to construct aweighted coverage map. This map is key in calculating the fuzzing reward, whichis then applied to the LLM-based mutator through reinforcement learning.CovRL-Fuzz, through this approach, enables the generation of test cases thatare more likely to discover new coverage areas, thus improving vulnerabilitydetection while minimizing syntax and semantic errors, all without needingextra post-processing. Our evaluation results indicate that CovRL-Fuzzoutperforms the state-of-the-art fuzzers in terms of code coverage andbug-finding capabilities: CovRL-Fuzz identified 48 real-world security-relatedbugs in the latest JavaScript engines, including 39 previously unknownvulnerabilities and 11 CVEs.</description><author>Jueon Eom, Seyeon Jeong, Taekyoung Kwon</author><pubDate>Mon, 19 Feb 2024 15:30:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12222v1</guid></item><item><title>Bayesian Parameter-Efficient Fine-Tuning for Overcoming Catastrophic Forgetting</title><link>http://arxiv.org/abs/2402.12220v1</link><description>Although motivated by the adaptation of text-to-speech synthesis models, weargue that more generic parameter-efficient fine-tuning (PEFT) is anappropriate framework to do such adaptation. However, catastrophic forgettingremains an issue with PEFT, damaging the pre-trained model's inherentcapabilities. We demonstrate that existing Bayesian learning techniques can beapplied to PEFT to prevent catastrophic forgetting as long as the parametershift of the fine-tuned layers can be calculated differentiably. In aprincipled series of experiments on language modeling and speech synthesistasks, we utilize established Laplace approximations, including diagonal andKronecker factored approaches, to regularize PEFT with the low-rank adaptation(LoRA) and compare their performance in pre-training knowledge preservation.Our results demonstrate that catastrophic forgetting can be overcome by ourmethods without degrading the fine-tuning performance, and using the Kroneckerfactored approximations produces a better preservation of the pre-trainingknowledge than the diagonal ones.</description><author>Haolin Chen, Philip N. Garner</author><pubDate>Mon, 19 Feb 2024 15:26:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12220v1</guid></item><item><title>Analyzing FOMC Minutes: Accuracy and Constraints of Language Models</title><link>http://arxiv.org/abs/2304.10164v2</link><description>This research article analyzes the language used in the official statementsreleased by the Federal Open Market Committee (FOMC) after its scheduledmeetings to gain insights into the impact of FOMC official statements onfinancial markets and economic forecasting. The study reveals that the FOMC iscareful to avoid expressing emotion in their sentences and follows a set oftemplates to cover economic situations. The analysis employs advanced languagemodeling techniques such as VADER and FinBERT, and a trial test with GPT-4. Theresults show that FinBERT outperforms other techniques in predicting negativesentiment accurately. However, the study also highlights the challenges andlimitations of using current NLP techniques to analyze FOMC texts and suggeststhe potential for enhancing language models and exploring alternativeapproaches.</description><author>Wonseong Kim, Jan Frederic Spörer, Siegfried Handschuh</author><pubDate>Mon, 19 Feb 2024 15:24:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10164v2</guid></item><item><title>Reformatted Alignment</title><link>http://arxiv.org/abs/2402.12219v1</link><description>The quality of finetuning data is crucial for aligning large language models(LLMs) with human values. Current methods to improve data quality are eitherlabor-intensive or prone to factual errors caused by LLM hallucinations. Thispaper explores elevating the quality of existing instruction data to betteralign with human values, introducing a simple and effective approach namedReAlign, which reformats the responses of instruction data into a format thatbetter aligns with pre-established criteria and the collated evidence. Thisapproach minimizes human annotation, hallucination, and the difficulty inscaling, remaining orthogonal to existing alignment techniques. Experimentally,ReAlign significantly boosts the general alignment ability, math reasoning,factuality, and readability of the LLMs. Encouragingly, without introducing any additional data or advanced trainingtechniques, and merely by reformatting the response, LLaMA-2-13B's mathematicalreasoning ability on GSM8K can be improved from 46.77% to 56.63% in accuracy.Additionally, a mere 5% of ReAlign data yields a 67% boost in general alignmentability measured by the Alpaca dataset. This work highlights the need forfurther research into the science and mechanistic interpretability of LLMs. Wehave made the associated code and data publicly accessible to support futurestudies at https://github.com/GAIR-NLP/ReAlign.</description><author>Run-Ze Fan, Xuefeng Li, Haoyang Zou, Junlong Li, Shwai He, Ethan Chern, Jiewen Hu, Pengfei Liu</author><pubDate>Mon, 19 Feb 2024 15:21:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12219v1</guid></item><item><title>Copyleft for Alleviating AIGC Copyright Dilemma: What-if Analysis, Public Perception and Implications</title><link>http://arxiv.org/abs/2402.12216v1</link><description>As AIGC has impacted our society profoundly in the past years, ethical issueshave received tremendous attention. The most urgent one is the AIGC copyrightdilemma, which can immensely stifle the development of AIGC and greatly costthe entire society. Given the complexity of AIGC copyright governance and thefact that no perfect solution currently exists, previous work advocatedcopyleft on AI governance but without substantive analysis. In this paper, wetake a step further to explore the feasibility of copyleft to alleviate theAIGC copyright dilemma. We conduct a mixed-methods study from two aspects:qualitatively, we use a formal what-if analysis to clarify the dilemma andprovide case studies to show the feasibility of copyleft; quantitatively, weperform a carefully designed survey to find out how the public feels aboutcopylefting AIGC. The key findings include: a) people generally perceive thedilemma, b) they prefer to use authorized AIGC under loose restriction, and c)they are positive to copyleft in AIGC and willing to use it in the future.</description><author>Xinwei Guo, Yujun Li, Yafeng Peng, Xuetao Wei</author><pubDate>Mon, 19 Feb 2024 15:20:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12216v1</guid></item><item><title>InSaAF: Incorporating Safety through Accuracy and Fairness | Are LLMs ready for the Indian Legal Domain?</title><link>http://arxiv.org/abs/2402.10567v2</link><description>Recent advancements in language technology and Artificial Intelligence haveresulted in numerous Language Models being proposed to perform various tasks inthe legal domain ranging from predicting judgments to generating summaries.Despite their immense potential, these models have been proven to learn andexhibit societal biases and make unfair predictions. In this study, we explorethe ability of Large Language Models (LLMs) to perform legal tasks in theIndian landscape when social factors are involved. We present a novel metric,$\beta$-weighted $\textit{Legal Safety Score ($LSS_{\beta}$)}$, whichencapsulates both the fairness and accuracy aspects of the LLM. We assess LLMs'safety by considering its performance in the $\textit{Binary StatutoryReasoning}$ task and its fairness exhibition with respect to various axes ofdisparities in the Indian society. Task performance and fairness scores ofLLaMA and LLaMA--2 models indicate that the proposed $LSS_{\beta}$ metric caneffectively determine the readiness of a model for safe usage in the legalsector. We also propose finetuning pipelines, utilising specialised legaldatasets, as a potential method to mitigate bias and improve model safety. Thefinetuning procedures on LLaMA and LLaMA--2 models increase the $LSS_{\beta}$,improving their usability in the Indian legal domain. Our code is publiclyreleased.</description><author>Yogesh Tripathi, Raghav Donakanti, Sahil Girhepuje, Ishan Kavathekar, Bhaskara Hanuma Vedula, Gokul S Krishnan, Shreya Goyal, Anmol Goel, Balaraman Ravindran, Ponnurangam Kumaraguru</author><pubDate>Mon, 19 Feb 2024 15:16:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10567v2</guid></item><item><title>Polarization of Autonomous Generative AI Agents Under Echo Chambers</title><link>http://arxiv.org/abs/2402.12212v1</link><description>Online social networks often create echo chambers where people only hearopinions reinforcing their beliefs. An echo chamber often generatespolarization, leading to conflicts caused by people with radical opinions, suchas the January 6, 2021, attack on the US Capitol. The echo chamber has beenviewed as a human-specific problem, but this implicit assumption is becomingless reasonable as large language models, such as ChatGPT, acquire socialabilities. In response to this situation, we investigated the potential forpolarization to occur among a group of autonomous AI agents based on generativelanguage models in an echo chamber environment. We had AI agents discussspecific topics and analyzed how the group's opinions changed as the discussionprogressed. As a result, we found that the group of agents based on ChatGPTtended to become polarized in echo chamber environments. The analysis ofopinion transitions shows that this result is caused by ChatGPT's high promptunderstanding ability to update its opinion by considering its own andsurrounding agents' opinions. We conducted additional experiments toinvestigate under what specific conditions AI agents tended to polarize. As aresult, we identified factors that strongly influence polarization, such as theagent's persona. These factors should be monitored to prevent the polarizationof AI agents.</description><author>Masaya Ohagi</author><pubDate>Mon, 19 Feb 2024 15:14:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12212v1</guid></item><item><title>Open-Set Graph Anomaly Detection via Normal Structure Regularisation</title><link>http://arxiv.org/abs/2311.06835v2</link><description>This paper considers an important Graph Anomaly Detection (GAD) task, namelyopen-set GAD, which aims to detect anomalous nodes using a small number oflabelled training normal and anomaly nodes (known as seen anomalies) thatcannot illustrate all possible inference-time abnormalities. The availabilityof that labelled data provides crucial prior knowledge about abnormalities forGAD models, enabling substantially reduced detection errors. However, currentmethods tend to over-emphasise fitting the seen anomalies, leading to a weakgeneralisation ability to detect unseen anomalies, i.e., those that are notillustrated by the labelled anomaly nodes. Further, they were introduced tohandle Euclidean data, failing to effectively capture important non-Euclideanfeatures for GAD. In this work, we propose a novel open-set GAD approach,namely Normal Structure Regularisation (NSReg), to achieve generaliseddetection ability to unseen anomalies, while maintaining its effectiveness ondetecting seen anomalies. The key idea in NSReg is to introduce aregularisation term that enforces the learning of compact, semantically-richrepresentations of normal nodes based on their structural relations to othernodes. When being optimised with supervised anomaly detection losses, theregularisation term helps incorporate strong normality into the modelling,empowering the joint learning of both seen abnormality and normality of thenodes, and thus, it effectively avoids the over emphasis on solely fitting theseen anomalies during training. Extensive empirical results on six real-worlddatasets demonstrate the superiority of our proposed NSReg for open-set GAD.</description><author>Qizhou Wang, Guansong Pang, Mahsa Salehi, Christopher Leckie</author><pubDate>Mon, 19 Feb 2024 15:12:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06835v2</guid></item></channel></rss>