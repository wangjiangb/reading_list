<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sat, 29 Jul 2023 06:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>To Adapt or Not to Adapt? Real-Time Adaptation for Semantic Segmentation</title><link>http://arxiv.org/abs/2307.15063v1</link><description>The goal of Online Domain Adaptation for semantic segmentation is to handleunforeseeable domain changes that occur during deployment, like sudden weatherevents. However, the high computational costs associated with brute-forceadaptation make this paradigm unfeasible for real-world applications. In thispaper we propose HAMLET, a Hardware-Aware Modular Least Expensive Trainingframework for real-time domain adaptation. Our approach includes ahardware-aware back-propagation orchestration agent (HAMT) and a dedicateddomain-shift detector that enables active control over when and how the modelis adapted (LT). Thanks to these advancements, our approach is capable ofperforming semantic segmentation while simultaneously adapting at more than29FPS on a single consumer-grade GPU. Our framework's encouraging accuracy andspeed trade-off is demonstrated on OnDA and SHIFT benchmarks throughexperimental results.</description><author>Marc Botet Colomer, Pier Luigi Dovesi, Theodoros Panagiotakopoulos, Joao Frederico Carvalho, Linus Härenstam-Nielsen, Hossein Azizpour, Hedvig Kjellström, Daniel Cremers, Matteo Poggi</author><pubDate>Thu, 27 Jul 2023 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15063v1</guid></item><item><title>Self-Supervised Visual Acoustic Matching</title><link>http://arxiv.org/abs/2307.15064v1</link><description>Acoustic matching aims to re-synthesize an audio clip to sound as if it wererecorded in a target acoustic environment. Existing methods assume access topaired training data, where the audio is observed in both source and targetenvironments, but this limits the diversity of training data or requires theuse of simulated data or heuristics to create paired samples. We propose aself-supervised approach to visual acoustic matching where training samplesinclude only the target scene image and audio -- without acousticallymismatched source audio for reference. Our approach jointly learns todisentangle room acoustics and re-synthesize audio into the target environment,via a conditional GAN framework and a novel metric that quantifies the level ofresidual acoustic information in the de-biased audio. Training with eitherin-the-wild web data or simulated data, we demonstrate it outperforms thestate-of-the-art on multiple challenging datasets and a wide variety ofreal-world audio and environments.</description><author>Arjun Somayazulu, Changan Chen, Kristen Grauman</author><pubDate>Thu, 27 Jul 2023 18:59:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15064v1</guid></item><item><title>The RoboDepth Challenge: Methods and Advancements Towards Robust Depth Estimation</title><link>http://arxiv.org/abs/2307.15061v1</link><description>Accurate depth estimation under out-of-distribution (OoD) scenarios, such asadverse weather conditions, sensor failure, and noise contamination, isdesirable for safety-critical applications. Existing depth estimation systems,however, suffer inevitably from real-world corruptions and perturbations andare struggled to provide reliable depth predictions under such cases. In thispaper, we summarize the winning solutions from the RoboDepth Challenge -- anacademic competition designed to facilitate and advance robust OoD depthestimation. This challenge was developed based on the newly established KITTI-Cand NYUDepth2-C benchmarks. We hosted two stand-alone tracks, with an emphasison robust self-supervised and robust fully-supervised depth estimation,respectively. Out of more than two hundred participants, nine unique andtop-performing solutions have appeared, with novel designs ranging from thefollowing aspects: spatial- and frequency-domain augmentations, masked imagemodeling, image restoration and super-resolution, adversarial training,diffusion-based noise suppression, vision-language pre-training, learned modelensembling, and hierarchical feature enhancement. Extensive experimentalanalyses along with insightful observations are drawn to better understand therationale behind each design. We hope this challenge could lay a solidfoundation for future research on robust and reliable depth estimation andbeyond. The datasets, competition toolkit, workshop recordings, and source codefrom the winning teams are publicly available on the challenge website.</description><author>Lingdong Kong, Yaru Niu, Shaoyuan Xie, Hanjiang Hu, Lai Xing Ng, Benoit R. Cottereau, Ding Zhao, Liangjun Zhang, Hesheng Wang, Wei Tsang Ooi, Ruijie Zhu, Ziyang Song, Li Liu, Tianzhu Zhang, Jun Yu, Mohan Jing, Pengwei Li, Xiaohua Qi, Cheng Jin, Yingfeng Chen, Jie Hou, Jie Zhang, Zhen Kan, Qiang Ling, Liang Peng, Minglei Li, Di Xu, Changpeng Yang, Yuanqi Yao, Gang Wu, Jian Kuai, Xianming Liu, Junjun Jiang, Jiamian Huang, Baojun Li, Jiale Chen, Shuang Zhang, Sun Ao, Zhenyu Li, Runze Chen, Haiyong Luo, Fang Zhao, Jingze Yu</author><pubDate>Thu, 27 Jul 2023 18:59:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15061v1</guid></item><item><title>MARS: An Instance-aware, Modular and Realistic Simulator for Autonomous Driving</title><link>http://arxiv.org/abs/2307.15058v1</link><description>Nowadays, autonomous cars can drive smoothly in ordinary cases, and it iswidely recognized that realistic sensor simulation will play a critical role insolving remaining corner cases by simulating them. To this end, we propose anautonomous driving simulator based upon neural radiance fields (NeRFs).Compared with existing works, ours has three notable features: (1)Instance-aware. Our simulator models the foreground instances and backgroundenvironments separately with independent networks so that the static (e.g.,size and appearance) and dynamic (e.g., trajectory) properties of instances canbe controlled separately. (2) Modular. Our simulator allows flexible switchingbetween different modern NeRF-related backbones, sampling strategies, inputmodalities, etc. We expect this modular design to boost academic progress andindustrial deployment of NeRF-based autonomous driving simulation. (3)Realistic. Our simulator set new state-of-the-art photo-realism results giventhe best module selection. Our simulator will be open-sourced while most of ourcounterparts are not. Project page: https://open-air-sun.github.io/mars/.</description><author>Zirui Wu, Tianyu Liu, Liyi Luo, Zhide Zhong, Jianteng Chen, Hongmin Xiao, Chao Hou, Haozhe Lou, Yuantao Chen, Runyi Yang, Yuxin Huang, Xiaoyu Ye, Zike Yan, Yongliang Shi, Yiyi Liao, Hao Zhao</author><pubDate>Thu, 27 Jul 2023 18:59:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15058v1</guid></item><item><title>PointOdyssey: A Large-Scale Synthetic Dataset for Long-Term Point Tracking</title><link>http://arxiv.org/abs/2307.15055v1</link><description>We introduce PointOdyssey, a large-scale synthetic dataset, and datageneration framework, for the training and evaluation of long-term fine-grainedtracking algorithms. Our goal is to advance the state-of-the-art by placingemphasis on long videos with naturalistic motion. Toward the goal ofnaturalism, we animate deformable characters using real-world motion capturedata, we build 3D scenes to match the motion capture environments, and werender camera viewpoints using trajectories mined via structure-from-motion onreal videos. We create combinatorial diversity by randomizing characterappearance, motion profiles, materials, lighting, 3D assets, and atmosphericeffects. Our dataset currently includes 104 videos, averaging 2,000 frameslong, with orders of magnitude more correspondence annotations than prior work.We show that existing methods can be trained from scratch in our dataset andoutperform the published variants. Finally, we introduce modifications to thePIPs point tracking method, greatly widening its temporal receptive field,which improves its performance on PointOdyssey as well as on two real-worldbenchmarks. Our data and code are publicly available at:https://pointodyssey.com</description><author>Yang Zheng, Adam W. Harley, Bokui Shen, Gordon Wetzstein, Leonidas J. Guibas</author><pubDate>Thu, 27 Jul 2023 18:58:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15055v1</guid></item><item><title>A Geometric Notion of Causal Probing</title><link>http://arxiv.org/abs/2307.15054v1</link><description>Large language models rely on real-valued representations of text to maketheir predictions. These representations contain information learned from thedata that the model has trained on, including knowledge of linguisticproperties and forms of demographic bias, e.g., based on gender. A growing bodyof work has considered information about concepts such as these usingorthogonal projections onto subspaces of the representation space. Wecontribute to this body of work by proposing a formal definition of intrinsicinformation in a subspace of a language model's representation space. Wepropose a counterfactual approach that avoids the failure mode of spuriouscorrelations (Kumar et al., 2022) by treating components in the subspace andits orthogonal complement independently. We show that our counterfactual notionof information in a subspace is optimizing by an causal concept subspace.Furthermore, this intervention allows us to attempt concept controlledgeneration by manipulating the value of the conceptual component of arepresentation. Empirically, we find that R-LACE (Ravfogel et al., 2022)returns a one-dimensional subspace containing roughly half of total conceptinformation under our framework. Our causal controlled intervention shows that,for at least one model, the subspace returned by R-LACE can be used tomanipulate the concept value of the generated word with precision.</description><author>Clément Guerner, Anej Svete, Tianyu Liu, Alexander Warstadt, Ryan Cotterell</author><pubDate>Thu, 27 Jul 2023 18:57:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15054v1</guid></item><item><title>On (Normalised) Discounted Cumulative Gain as an Offline Evaluation Metric for Top-$n$ Recommendation</title><link>http://arxiv.org/abs/2307.15053v1</link><description>Approaches to recommendation are typically evaluated in one of two ways: (1)via a (simulated) online experiment, often seen as the gold standard, or (2)via some offline evaluation procedure, where the goal is to approximate theoutcome of an online experiment. Several offline evaluation metrics have beenadopted in the literature, inspired by ranking metrics prevalent in the fieldof Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is onesuch metric that has seen widespread adoption in empirical studies, and higher(n)DCG values have been used to present new methods as the state-of-the-art intop-$n$ recommendation for many years. Our work takes a critical look at this approach, and investigates when we canexpect such metrics to approximate the gold standard outcome of an onlineexperiment. We formally present the assumptions that are necessary to considerDCG an unbiased estimator of online reward and provide a derivation for thismetric from first principles, highlighting where we deviate from itstraditional uses in IR. Importantly, we show that normalising the metricrenders it inconsistent, in that even when DCG is unbiased, ranking competingmethods by their normalised DCG can invert their relative order. Through acorrelation analysis between off- and on-line experiments conducted on alarge-scale recommendation platform, we show that our unbiased DCG estimatesstrongly correlate with online reward, even when some of the metric's inherentassumptions are violated. This statement no longer holds for its normalisedvariant, suggesting that nDCG's practical utility may be limited.</description><author>Olivier Jeunen, Ivan Potapov, Aleksei Ustimenko</author><pubDate>Thu, 27 Jul 2023 18:57:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15053v1</guid></item><item><title>Learning Depth Estimation for Transparent and Mirror Surfaces</title><link>http://arxiv.org/abs/2307.15052v1</link><description>Inferring the depth of transparent or mirror (ToM) surfaces represents a hardchallenge for either sensors, algorithms, or deep networks. We propose a simplepipeline for learning to estimate depth properly for such surfaces with neuralnetworks, without requiring any ground-truth annotation. We unveil how toobtain reliable pseudo labels by in-painting ToM objects in images andprocessing them with a monocular depth estimation model. These labels can beused to fine-tune existing monocular or stereo networks, to let them learn howto deal with ToM surfaces. Experimental results on the Booster dataset show thedramatic improvements enabled by our remarkably simple proposal.</description><author>Alex Costanzino, Pierluigi Zama Ramirez, Matteo Poggi, Fabio Tosi, Stefano Mattoccia, Luigi Di Stefano</author><pubDate>Thu, 27 Jul 2023 18:57:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15052v1</guid></item><item><title>Matching Patients to Clinical Trials with Large Language Models</title><link>http://arxiv.org/abs/2307.15051v1</link><description>Clinical trials are vital in advancing drug development and evidence-basedmedicine, but their success is often hindered by challenges in patientrecruitment. In this work, we investigate the potential of large languagemodels (LLMs) to assist individual patients and referral physicians inidentifying suitable clinical trials from an extensive selection. Specifically,we introduce TrialGPT, a novel architecture employing LLMs to predictcriterion-level eligibility with detailed explanations, which are thenaggregated for ranking and excluding candidate clinical trials based onfree-text patient notes. We evaluate TrialGPT on three publicly availablecohorts of 184 patients and 18,238 annotated clinical trials. The experimentalresults demonstrate several key findings: First, TrialGPT achieves highcriterion-level prediction accuracy with faithful explanations. Second, theaggregated trial-level TrialGPT scores are highly correlated with experteligibility annotations. Third, these scores prove effective in rankingclinical trials and exclude ineligible candidates. Our error analysis suggeststhat current LLMs still make some mistakes due to limited medical knowledge anddomain-specific context understanding. Nonetheless, we believe the explanatorycapabilities of LLMs are highly valuable. Future research is warranted on howsuch AI assistants can be integrated into the routine trial matching workflowin real-world settings to improve its efficiency.</description><author>Qiao Jin, Zifeng Wang, Charalampos S. Floudas, Jimeng Sun, Zhiyong Lu</author><pubDate>Thu, 27 Jul 2023 18:56:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15051v1</guid></item><item><title>Regularized Mask Tuning: Uncovering Hidden Knowledge in Pre-trained Vision-Language Models</title><link>http://arxiv.org/abs/2307.15049v1</link><description>Prompt tuning and adapter tuning have shown great potential in transferringpre-trained vision-language models (VLMs) to various downstream tasks. In thiswork, we design a new type of tuning method, termed as regularized mask tuning,which masks the network parameters through a learnable selection. Inspired byneural pathways, we argue that the knowledge required by a downstream taskalready exists in the pre-trained weights but just gets concealed in theupstream pre-training stage. To bring the useful knowledge back into light, wefirst identify a set of parameters that are important to a given downstreamtask, then attach a binary mask to each parameter, and finally optimize thesemasks on the downstream data with the parameters frozen. When updating themask, we introduce a novel gradient dropout strategy to regularize theparameter selection, in order to prevent the model from forgetting oldknowledge and overfitting the downstream data. Experimental results on 11datasets demonstrate the consistent superiority of our method over previousalternatives. It is noteworthy that we manage to deliver 18.73% performanceimprovement compared to the zero-shot CLIP via masking an average of only 2.56%parameters. Furthermore, our method is synergistic with most existingparameter-efficient tuning methods and can boost the performance on top ofthem. Project page can be found here (https://wuw2019.github.io/RMT/).</description><author>Kecheng Zheng, Wei Wu, Ruili Feng, Kai Zhu, Jiawei Liu, Deli Zhao, Zheng-Jun Zha, Wei Chen, Yujun Shen</author><pubDate>Thu, 27 Jul 2023 18:56:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15049v1</guid></item><item><title>Mining Clues from Incomplete Utterance: A Query-enhanced Network for Incomplete Utterance Rewriting</title><link>http://arxiv.org/abs/2307.00866v2</link><description>Incomplete utterance rewriting has recently raised wide attention. However,previous works do not consider the semantic structural information betweenincomplete utterance and rewritten utterance or model the semantic structureimplicitly and insufficiently. To address this problem, we propose aQUEry-Enhanced Network (QUEEN). Firstly, our proposed query template explicitlybrings guided semantic structural knowledge between the incomplete utteranceand the rewritten utterance making model perceive where to refer back to orrecover omitted tokens. Then, we adopt a fast and effective edit operationscoring network to model the relation between two tokens. Benefiting fromproposed query template and the well-designed edit operation scoring network,QUEEN achieves state-of-the-art performance on several public datasets.</description><author>Shuzheng Si, Shuang Zeng, Baobao Chang</author><pubDate>Thu, 27 Jul 2023 18:55:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00866v2</guid></item><item><title>A Transformer-based Approach for Arabic Offline Handwritten Text Recognition</title><link>http://arxiv.org/abs/2307.15045v1</link><description>Handwriting recognition is a challenging and critical problem in the fieldsof pattern recognition and machine learning, with applications spanning a widerange of domains. In this paper, we focus on the specific issue of recognizingoffline Arabic handwritten text. Existing approaches typically utilize acombination of convolutional neural networks for image feature extraction andrecurrent neural networks for temporal modeling, with connectionist temporalclassification used for text generation. However, these methods suffer from alack of parallelization due to the sequential nature of recurrent neuralnetworks. Furthermore, these models cannot account for linguistic rules,necessitating the use of an external language model in the post-processingstage to boost accuracy. To overcome these issues, we introduce two alternativearchitectures, namely the Transformer Transducer and the standardsequence-to-sequence Transformer, and compare their performance in terms ofaccuracy and speed. Our approach can model language dependencies and reliesonly on the attention mechanism, thereby making it more parallelizable and lesscomplex. We employ pre-trained Transformers for both image understanding andlanguage modeling. Our evaluation on the Arabic KHATT dataset demonstrates thatour proposed method outperforms the current state-of-the-art approaches forrecognizing offline Arabic handwritten text.</description><author>Saleh Momeni, Bagher BabaAli</author><pubDate>Thu, 27 Jul 2023 18:51:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15045v1</guid></item><item><title>Universal and Transferable Adversarial Attacks on Aligned Language Models</title><link>http://arxiv.org/abs/2307.15043v1</link><description>Because "out-of-the-box" large language models are capable of generating agreat deal of objectionable content, recent work has focused on aligning thesemodels in an attempt to prevent undesirable generation. While there has beensome success at circumventing these measures -- so-called "jailbreaks" againstLLMs -- these attacks have required significant human ingenuity and are brittlein practice. In this paper, we propose a simple and effective attack methodthat causes aligned language models to generate objectionable behaviors.Specifically, our approach finds a suffix that, when attached to a wide rangeof queries for an LLM to produce objectionable content, aims to maximize theprobability that the model produces an affirmative response (rather thanrefusing to answer). However, instead of relying on manual engineering, ourapproach automatically produces these adversarial suffixes by a combination ofgreedy and gradient-based search techniques, and also improves over pastautomatic prompt generation methods. Surprisingly, we find that the adversarial prompts generated by our approachare quite transferable, including to black-box, publicly released LLMs.Specifically, we train an adversarial attack suffix on multiple prompts (i.e.,queries asking for many different types of objectionable content), as well asmultiple models (in our case, Vicuna-7B and 13B). When doing so, the resultingattack suffix is able to induce objectionable content in the public interfacesto ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat,Pythia, Falcon, and others. In total, this work significantly advances thestate-of-the-art in adversarial attacks against aligned language models,raising important questions about how such systems can be prevented fromproducing objectionable information. Code is available atgithub.com/llm-attacks/llm-attacks.</description><author>Andy Zou, Zifan Wang, J. Zico Kolter, Matt Fredrikson</author><pubDate>Thu, 27 Jul 2023 18:49:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15043v1</guid></item><item><title>TEDi: Temporally-Entangled Diffusion for Long-Term Motion Synthesis</title><link>http://arxiv.org/abs/2307.15042v1</link><description>The gradual nature of a diffusion process that synthesizes samples in smallincrements constitutes a key ingredient of Denoising Diffusion ProbabilisticModels (DDPM), which have presented unprecedented quality in image synthesisand been recently explored in the motion domain. In this work, we propose toadapt the gradual diffusion concept (operating along a diffusion time-axis)into the temporal-axis of the motion sequence. Our key idea is to extend theDDPM framework to support temporally varying denoising, thereby entangling thetwo axes. Using our special formulation, we iteratively denoise a motion bufferthat contains a set of increasingly-noised poses, which auto-regressivelyproduces an arbitrarily long stream of frames. With a stationary diffusiontime-axis, in each diffusion step we increment only the temporal-axis of themotion such that the framework produces a new, clean frame which is removedfrom the beginning of the buffer, followed by a newly drawn noise vector thatis appended to it. This new mechanism paves the way towards a new framework forlong-term motion synthesis with applications to character animation and otherdomains.</description><author>Zihan Zhang, Richard Liu, Kfir Aberman, Rana Hanocka</author><pubDate>Thu, 27 Jul 2023 18:48:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15042v1</guid></item><item><title>Algorithmic Gaussianization through Sketching: Converting Data into Sub-gaussian Random Designs</title><link>http://arxiv.org/abs/2206.10291v2</link><description>Algorithmic Gaussianization is a phenomenon that can arise when usingrandomized sketching or sampling methods to produce smaller representations oflarge datasets: For certain tasks, these sketched representations have beenobserved to exhibit many robust performance characteristics that are known tooccur when a data sample comes from a sub-gaussian random design, which is apowerful statistical model of data distributions. However, this phenomenon hasonly been studied for specific tasks and metrics, or by relying oncomputationally expensive methods. We address this by providing an algorithmicframework for gaussianizing data distributions via averaging, proving that itis possible to efficiently construct data sketches that are nearlyindistinguishable (in terms of total variation distance) from sub-gaussianrandom designs. In particular, relying on a recently introduced sketchingtechnique called Leverage Score Sparsified (LESS) embeddings, we show that onecan construct an $n\times d$ sketch of an $N\times d$ matrix $A$, where $n\llN$, that is nearly indistinguishable from a sub-gaussian design, in time$O(\text{nnz}(A)\log N + nd^2)$, where $\text{nnz}(A)$ is the number ofnon-zero entries in $A$. As a consequence, strong statistical guarantees andprecise asymptotics available for the estimators produced from sub-gaussiandesigns (e.g., for least squares and Lasso regression, covariance estimation,low-rank approximation, etc.) can be straightforwardly adapted to our sketchingframework. We illustrate this with a new approximation guarantee for sketchedleast squares, among other examples.</description><author>Michał Dereziński</author><pubDate>Thu, 27 Jul 2023 18:48:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.10291v2</guid></item><item><title>A Sparse Quantized Hopfield Network for Online-Continual Memory</title><link>http://arxiv.org/abs/2307.15040v1</link><description>An important difference between brains and deep neural networks is the waythey learn. Nervous systems learn online where a stream of noisy data pointsare presented in a non-independent, identically distributed (non-i.i.d.) way.Further, synaptic plasticity in the brain depends only on information local tosynapses. Deep networks, on the other hand, typically use non-local learningalgorithms and are trained in an offline, non-noisy, i.i.d. setting.Understanding how neural networks learn under the same constraints as the brainis an open problem for neuroscience and neuromorphic computing. A standardapproach to this problem has yet to be established. In this paper, we proposethat discrete graphical models that learn via an online maximum a posteriorilearning algorithm could provide such an approach. We implement this kind ofmodel in a novel neural network called the Sparse Quantized Hopfield Network(SQHN). We show that SQHNs outperform state-of-the-art neural networks onassociative memory tasks, outperform these models in online, non-i.i.d.settings, learn efficiently with noisy inputs, and are better than baselines ona novel episodic memory task.</description><author>Nick Alonso, Jeff Krichmar</author><pubDate>Thu, 27 Jul 2023 18:46:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15040v1</guid></item><item><title>Synergies Between Federated Learning and O-RAN: Towards an Elastic Virtualized Architecture for Multiple Distributed Machine Learning Services</title><link>http://arxiv.org/abs/2305.02109v2</link><description>Federated learning (FL) is the most popular distributed machine learningtechnique. However, implementation of FL over modern wireless networks faceskey challenges caused by (i) dynamics of the network conditions and (ii) thecoexistence of multiple FL services/tasks and other network services in thesystem, which are not jointly considered in prior works. Motivated by thesechallenges, we introduce a generic FL paradigm over NextG networks, calleddynamic multi-service FL (DMS-FL). We identify three unexplored designconsiderations in DMS-FL: (i) FL service operator accumulation, (ii) wirelessresource fragmentation, and (iii) signal strength fluctuations. We take thefirst steps towards addressing these design considerations by proposing a noveldistributed ML architecture called elastic virtualized FL (EV-FL). EV-FLunleashes the full potential of Open RAN (O-RAN) systems and introduces anelastic resource provisioning methodology to execute FL services. It furtherconstitutes a multi-time-scale FL management system that introduces threedimensions into existing FL architectures: (i) virtualization, (ii)scalability, and (iii) elasticity. Through investigating EV-FL, we reveal aseries of open research directions for future work. We finally simulate EV-FLto demonstrate its potential in saving wireless resources and increasingfairness among FL services.</description><author>Payam Abdisarabshali, Nicholas Accurso, Filippo Malandra, Weifeng Su, Seyyedali Hosseinalipour</author><pubDate>Thu, 27 Jul 2023 18:44:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.02109v2</guid></item><item><title>Formulation Graphs for Mapping Structure-Composition of Battery Electrolytes to Device Performance</title><link>http://arxiv.org/abs/2307.03811v2</link><description>Advanced computational methods are being actively sought for addressing thechallenges associated with discovery and development of new combinatorialmaterial such as formulations. A widely adopted approach involves domaininformed high-throughput screening of individual components that can becombined into a formulation. This manages to accelerate the discovery of newcompounds for a target application but still leave the process of identifyingthe right 'formulation' from the shortlisted chemical space largely alaboratory experiment-driven process. We report a deep learning model,Formulation Graph Convolution Network (F-GCN), that can mapstructure-composition relationship of the individual components to the propertyof liquid formulation as whole. Multiple GCNs are assembled in parallel thatfeaturize formulation constituents domain-intuitively on the fly. The resultingmolecular descriptors are scaled based on respective constituent's molarpercentage in the formulation, followed by formalizing into a combineddescriptor that represents a complete formulation to an external learningarchitecture. The use case of proposed formulation learning model isdemonstrated for battery electrolytes by training and testing it on twoexemplary datasets representing electrolyte formulations vs battery performance-- one dataset is sourced from literature about Li/Cu half-cells, while theother is obtained by lab-experiments related to lithium-iodide full-cellchemistry. The model is shown to predict the performance metrics like CoulombicEfficiency (CE) and specific capacity of new electrolyte formulations withlowest reported errors. The best performing F-GCN model uses moleculardescriptors derived from molecular graphs that are informed with HOMO-LUMO andelectric moment properties of the molecules using a knowledge transfertechnique.</description><author>Vidushi Sharma, Maxwell Giammona, Dmitry Zubarev, Andy Tek, Khanh Nugyuen, Linda Sundberg, Daniele Congiu, Young-Hye La</author><pubDate>Thu, 27 Jul 2023 18:42:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03811v2</guid></item><item><title>Speeding up Fourier Neural Operators via Mixed Precision</title><link>http://arxiv.org/abs/2307.15034v1</link><description>The Fourier neural operator (FNO) is a powerful technique for learningsurrogate maps for partial differential equation (PDE) solution operators. Formany real-world applications, which often require high-resolution data points,training time and memory usage are significant bottlenecks. While there aremixed-precision training techniques for standard neural networks, those workfor real-valued datatypes on finite dimensions and therefore cannot be directlyapplied to FNO, which crucially operates in the (complex-valued) Fourier domainand in function spaces. On the other hand, since the Fourier transform isalready an approximation (due to discretization error), we do not need toperform the operation at full precision. In this work, we (i) profile memoryand runtime for FNO with full and mixed-precision training, (ii) conduct astudy on the numerical stability of mixed-precision training of FNO, and (iii)devise a training routine which substantially decreases training time andmemory usage (up to 34%), with little or no reduction in accuracy, on theNavier-Stokes and Darcy flow equations. Combined with the recently proposedtensorized FNO (Kossaifi et al., 2023), the resulting model has far betterperformance while also being significantly faster than the original FNO.</description><author>Colin White, Renbo Tu, Jean Kossaifi, Gennady Pekhimenko, Kamyar Azizzadenesheli, Anima Anandkumar</author><pubDate>Thu, 27 Jul 2023 18:42:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15034v1</guid></item><item><title>Diverse Inpainting and Editing with GAN Inversion</title><link>http://arxiv.org/abs/2307.15033v1</link><description>Recent inversion methods have shown that real images can be inverted intoStyleGAN's latent space and numerous edits can be achieved on those imagesthanks to the semantically rich feature representations of well-trained GANmodels. However, extensive research has also shown that image inversion ischallenging due to the trade-off between high-fidelity reconstruction andeditability. In this paper, we tackle an even more difficult task, invertingerased images into GAN's latent space for realistic inpaintings and editings.Furthermore, by augmenting inverted latent codes with different latent samples,we achieve diverse inpaintings. Specifically, we propose to learn an encoderand mixing network to combine encoded features from erased images withStyleGAN's mapped features from random samples. To encourage the mixing networkto utilize both inputs, we train the networks with generated data via a novelset-up. We also utilize higher-rate features to prevent color inconsistenciesbetween the inpainted and unerased parts. We run extensive experiments andcompare our method with state-of-the-art inversion and inpainting methods.Qualitative metrics and visual comparisons show significant improvements.</description><author>Ahmet Burak Yildirim, Hamza Pehlivan, Bahri Batuhan Bilecen, Aysegul Dundar</author><pubDate>Thu, 27 Jul 2023 18:41:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15033v1</guid></item><item><title>Adaptive Segmentation Network for Scene Text Detection</title><link>http://arxiv.org/abs/2307.15029v1</link><description>Inspired by deep convolution segmentation algorithms, scene text detectorsbreak the performance ceiling of datasets steadily. However, these methodsoften encounter threshold selection bottlenecks and have poor performance ontext instances with extreme aspect ratios. In this paper, we propose toautomatically learn the discriminate segmentation threshold, whichdistinguishes text pixels from background pixels for segmentation-based scenetext detectors and then further reduces the time-consuming manual parameteradjustment. Besides, we design a Global-information Enhanced Feature PyramidNetwork (GE-FPN) for capturing text instances with macro size and extremeaspect ratios. Following the GE-FPN, we introduce a cascade optimizationstructure to further refine the text instances. Finally, together with theproposed threshold learning strategy and text detection structure, we design anAdaptive Segmentation Network (ASNet) for scene text detection. Extensiveexperiments are carried out to demonstrate that the proposed ASNet can achievethe state-of-the-art performance on four text detection benchmarks, i.e., ICDAR2015, MSRA-TD500, ICDAR 2017 MLT and CTW1500. The ablation experiments alsoverify the effectiveness of our contributions.</description><author>Guiqin Zhao</author><pubDate>Thu, 27 Jul 2023 18:37:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15029v1</guid></item><item><title>SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark</title><link>http://arxiv.org/abs/2307.15020v1</link><description>Large language models (LLMs) have shown the potential to be integrated intohuman daily lives. Therefore, user preference is the most critical criterionfor assessing LLMs' performance in real-world scenarios. However, existingbenchmarks mainly focus on measuring models' accuracy using multi-choicequestions, which limits the understanding of their capabilities in realapplications. We fill this gap by proposing a comprehensive Chinese benchmarkSuperCLUE, named after another popular Chinese LLM benchmark CLUE. SuperCLUEencompasses three sub-tasks: actual users' queries and ratings derived from anLLM battle platform (CArena), open-ended questions with single andmultiple-turn dialogues (OPEN), and closed-ended questions with the same stemsas open-ended single-turn ones (CLOSE). Our study shows that accuracy onclosed-ended questions is insufficient to reflect human preferences achieved onopen-ended ones. At the same time, they can complement each other to predictactual user preferences. We also demonstrate that GPT-4 is a reliable judge toautomatically evaluate human preferences on open-ended questions in a Chinesecontext. Our benchmark will be released at https://www.CLUEbenchmarks.com</description><author>Liang Xu, Anqi Li, Lei Zhu, Hang Xue, Changtai Zhu, Kangkang Zhao, Haonan He, Xuanwei Zhang, Qiyue Kang, Zhenzhong Lan</author><pubDate>Thu, 27 Jul 2023 18:24:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15020v1</guid></item><item><title>Self-Supervised Graph Transformer for Deepfake Detection</title><link>http://arxiv.org/abs/2307.15019v1</link><description>Deepfake detection methods have shown promising results in recognizingforgeries within a given dataset, where training and testing take place on thein-distribution dataset. However, their performance deteriorates significantlywhen presented with unseen samples. As a result, a reliable deepfake detectionsystem must remain impartial to forgery types, appearance, and quality forguaranteed generalizable detection performance. Despite various attempts toenhance cross-dataset generalization, the problem remains challenging,particularly when testing against common post-processing perturbations, such asvideo compression or blur. Hence, this study introduces a deepfake detectionframework, leveraging a self-supervised pre-training model that deliversexceptional generalization ability, withstanding common corruptions andenabling feature explainability. The framework comprises three key components:a feature extractor based on vision Transformer architecture that ispre-trained via self-supervised contrastive learning methodology, a graphconvolution network coupled with a Transformer discriminator, and a graphTransformer relevancy map that provides a better understanding of manipulatedregions and further explains the model's decision. To assess the effectivenessof the proposed framework, several challenging experiments are conducted,including in-data distribution performance, cross-dataset, cross-manipulationgeneralization, and robustness against common post-production perturbations.The results achieved demonstrate the remarkable effectiveness of the proposeddeepfake detection framework, surpassing the current state-of-the-artapproaches.</description><author>Aminollah Khormali, Jiann-Shiun Yuan</author><pubDate>Thu, 27 Jul 2023 18:22:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15019v1</guid></item><item><title>Samplable Anonymous Aggregation for Private Federated Data Analysis</title><link>http://arxiv.org/abs/2307.15017v1</link><description>We revisit the problem of designing scalable protocols for private statisticsand private federated learning when each device holds its private data. Ourfirst contribution is to propose a simple primitive that allows for efficientimplementation of several commonly used algorithms, and allows for privacyaccounting that is close to that in the central setting without requiring thestrong trust assumptions it entails. Second, we propose a system architecturethat implements this primitive and perform a security analysis of the proposedsystem.</description><author>Kunal Talwar, Shan Wang, Audra McMillan, Vojta Jina, Vitaly Feldman, Bailey Basile, Aine Cahill, Yi Sheng Chan, Mike Chatzidakis, Junye Chen, Oliver Chick, Mona Chitnis, Suman Ganta, Yusuf Goren, Filip Granqvist, Kristine Guo, Frederic Jacobs, Omid Javidbakht, Albert Liu, Richard Low, Dan Mascenik, Steve Myers, David Park, Wonhee Park, Gianni Parsa, Tommy Pauly, Christian Priebe, Rehan Rishi, Guy Rothblum, Michael Scaria, Linmao Song, Congzheng Song, Karl Tarbe, Sebastian Vogt, Luke Winstrom, Shundong Zhou</author><pubDate>Thu, 27 Jul 2023 18:19:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15017v1</guid></item><item><title>How Good is Google Bard's Visual Understanding? An Empirical Study on Open Challenges</title><link>http://arxiv.org/abs/2307.15016v1</link><description>Google's Bard has emerged as a formidable competitor to OpenAI's ChatGPT inthe field of conversational AI. Notably, Bard has recently been updated tohandle visual inputs alongside text prompts during conversations. Given Bard'simpressive track record in handling textual inputs, we explore its capabilitiesin understanding and interpreting visual data (images) conditioned by textquestions. This exploration holds the potential to unveil new insights andchallenges for Bard and other forthcoming multi-modal Generative models,especially in addressing complex computer vision problems that demand accuratevisual and language understanding. Specifically, in this study, we focus on 15diverse task scenarios encompassing regular, camouflaged, medical, under-waterand remote sensing data to comprehensively evaluate Bard's performance. Ourprimary finding indicates that Bard still struggles in these vision scenarios,highlighting the significant gap in vision-based understanding that needs to bebridged in future developments. We expect that this empirical study will provevaluable in advancing future models, leading to enhanced capabilities incomprehending and interpreting fine-grained visual data. Our project isreleased on https://github.com/htqin/GoogleBard-VisUnderstand</description><author>Haotong Qin, Ge-Peng Ji, Salman Khan, Deng-Ping Fan, Fahad Shahbaz Khan, Luc Van Gool</author><pubDate>Thu, 27 Jul 2023 18:19:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15016v1</guid></item><item><title>Dynamics of specialization in neural modules under resource constraints</title><link>http://arxiv.org/abs/2106.02626v2</link><description>It has long been believed that the brain is highly modular both in terms ofstructure and function, although recent evidence has led some to question theextent of both types of modularity. We used artificial neural networks to testthe hypothesis that structural modularity is sufficient to guarantee functionalspecialization, and find that in general, this doesn't necessarily hold exceptat extreme levels. We then systematically tested which features of theenvironment and network do lead to the emergence of specialization. We used asimple toy environment, task and network, allowing us precise control, and showthat in this setup, several distinct measures of specialization givequalitatively similar results. We further find that (1) specialization can onlyemerge in environments where features of that environment are meaningfullyseparable, (2) specialization preferentially emerges when the network isstrongly resource-constrained, and (3) these findings are qualitatively similaracross different network architectures, but the quantitative relationshipsdepends on the architecture type. Finally, we show that functionalspecialization varies dynamically across time, and demonstrate that thesedynamics depend on both the timing and bandwidth of information flow in thenetwork. We conclude that a static notion of specialization, based onstructural modularity, is likely too simple a framework for understandingintelligent systems in situations of real-world complexity. We propose thatthoroughly stress testing candidate definitions of functional modularity insimplified scenarios before extending to more complex data, network models andelectrophysiological recordings is likely to be a fruitful approach.</description><author>Gabriel Béna, Dan F. M. Goodman</author><pubDate>Thu, 27 Jul 2023 18:19:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2106.02626v2</guid></item><item><title>How to Scale Your EMA</title><link>http://arxiv.org/abs/2307.13813v2</link><description>Preserving training dynamics across batch sizes is an important tool forpractical machine learning as it enables the trade-off between batch size andwall-clock time. This trade-off is typically enabled by a scaling rule, forexample, in stochastic gradient descent, one should scale the learning ratelinearly with the batch size. Another important tool for practical machinelearning is the model Exponential Moving Average (EMA), which is a model copythat does not receive gradient information, but instead follows its targetmodel with some momentum. This model EMA can improve the robustness andgeneralization properties of supervised learning, stabilize pseudo-labeling,and provide a learning signal for Self-Supervised Learning (SSL). Prior workshave treated the model EMA separately from optimization, leading to differenttraining dynamics across batch sizes and lower model performance. In this work,we provide a scaling rule for optimization in the presence of model EMAs anddemonstrate its validity across a range of architectures, optimizers, and datamodalities. We also show the rule's validity where the model EMA contributes tothe optimization of the target model, enabling us to train EMA-basedpseudo-labeling and SSL methods at small and large batch sizes. For SSL, weenable training of BYOL up to batch size 24,576 without sacrificingperformance, optimally a 6$\times$ wall-clock time reduction.</description><author>Dan Busbridge, Jason Ramapuram, Pierre Ablin, Tatiana Likhomanenko, Eeshan Gunesh Dhekane, Xavier Suau, Russ Webb</author><pubDate>Thu, 27 Jul 2023 18:17:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13813v2</guid></item><item><title>Harnessing Synthetic Active Particles for Physical Reservoir Computing</title><link>http://arxiv.org/abs/2307.15010v1</link><description>The processing of information is an indispensable property of living systemsrealized by networks of active processes with enormous complexity. They haveinspired many variants of modern machine learning one of them being reservoircomputing, in which stimulating a network of nodes with fading memory enablescomputations and complex predictions. Reservoirs are implemented on computerhardware, but also on unconventional physical substrates such as mechanicaloscillators, spins, or bacteria often summarized as physical reservoircomputing. Here we demonstrate physical reservoir computing with a syntheticactive microparticle system that self-organizes from an active and passivecomponent into inherently noisy nonlinear dynamical units. Theself-organization and dynamical response of the unit is the result of a delayedpropulsion of the microswimmer to a passive target. A reservoir of such unitswith a self-coupling via the delayed response can perform predictive tasksdespite the strong noise resulting from Brownian motion of the microswimmers.To achieve efficient noise suppression, we introduce a special architecturethat uses historical reservoir states for output. Our results pave the way forthe study of information processing in synthetic self-organized active particlesystems.</description><author>Xiangzun Wang, Frank Cichos</author><pubDate>Thu, 27 Jul 2023 18:08:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15010v1</guid></item><item><title>Verifiable Feature Attributions: A Bridge between Post Hoc Explainability and Inherent Interpretability</title><link>http://arxiv.org/abs/2307.15007v1</link><description>With the increased deployment of machine learning models in variousreal-world applications, researchers and practitioners alike have emphasizedthe need for explanations of model behaviour. To this end, two broad strategieshave been outlined in prior literature to explain models. Post hoc explanationmethods explain the behaviour of complex black-box models by highlightingfeatures that are critical to model predictions; however, prior work has shownthat these explanations may not be faithful, and even more concerning is ourinability to verify them. Specifically, it is nontrivial to evaluate if a givenattribution is correct with respect to the underlying model. Inherentlyinterpretable models, on the other hand, circumvent these issues by explicitlyencoding explanations into model architecture, meaning their explanations arenaturally faithful and verifiable, but they often exhibit poor predictiveperformance due to their limited expressive power. In this work, we aim tobridge the gap between the aforementioned strategies by proposing VerifiabilityTuning (VerT), a method that transforms black-box models into models thatnaturally yield faithful and verifiable feature attributions. We begin byintroducing a formal theoretical framework to understand verifiability and showthat attributions produced by standard models cannot be verified. We thenleverage this framework to propose a method to build verifiable models andfeature attributions out of fully trained black-box models. Finally, we performextensive experiments on semi-synthetic and real-world datasets, and show thatVerT produces models that (1) yield explanations that are correct andverifiable and (2) are faithful to the original black-box models they are meantto explain.</description><author>Usha Bhalla, Suraj Srinivas, Himabindu Lakkaraju</author><pubDate>Thu, 27 Jul 2023 18:06:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15007v1</guid></item><item><title>Gzip versus bag-of-words for text classification with KNN</title><link>http://arxiv.org/abs/2307.15002v1</link><description>The effectiveness of compression distance in KNN-based text classification('gzip') has recently garnered lots of attention. In this note, we show thatsimilar or better effectiveness can be achieved with simpler means, and textcompression may not be necessary. Indeed, we find that a simple 'bag-of-words'matching can achieve similar or better accuracy, and is more efficient.</description><author>Juri Opitz</author><pubDate>Thu, 27 Jul 2023 17:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15002v1</guid></item><item><title>RELDEC: Reinforcement Learning-Based Decoding of Moderate Length LDPC Codes</title><link>http://arxiv.org/abs/2112.13934v3</link><description>In this work we propose RELDEC, a novel approach for sequential decoding ofmoderate length low-density parity-check (LDPC) codes. The main idea behindRELDEC is that an optimized decoding policy is subsequently obtained viareinforcement learning based on a Markov decision process (MDP). In contrast toour previous work, where an agent learns to schedule only a single check node(CN) within a group (cluster) of CNs per iteration, in this work we train theagent to schedule all CNs in a cluster, and all clusters in every iteration.That is, in each learning step of RELDEC an agent learns to schedule CNclusters sequentially depending on a reward associated with the outcome ofscheduling a particular cluster. We also modify the state space representationof the MDP, enabling RELDEC to be suitable for larger block length LDPC codesthan those studied in our previous work. Furthermore, to address decoding undervarying channel conditions, we propose agile meta-RELDEC (AM-RELDEC) thatemploys meta-reinforcement learning. The proposed RELDEC scheme significantlyoutperforms standard flooding and random sequential decoding for a variety ofLDPC codes, including codes designed for 5G new radio.</description><author>Salman Habib, Allison Beemer, Joerg Kliewer</author><pubDate>Thu, 27 Jul 2023 17:53:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2112.13934v3</guid></item><item><title>Likelihood-Free Parameter Estimation with Neural Bayes Estimators</title><link>http://arxiv.org/abs/2208.12942v4</link><description>Neural point estimators are neural networks that map data to parameter pointestimates. They are fast, likelihood free and, due to their amortised nature,amenable to fast bootstrap-based uncertainty quantification. In this paper, weaim to increase the awareness of statisticians to this relatively newinferential tool, and to facilitate its adoption by providing user-friendlyopen-source software. We also give attention to the ubiquitous problem ofmaking inference from replicated data, which we address in the neural settingusing permutation-invariant neural networks. Through extensive simulationstudies we show that these neural point estimators can quickly and optimally(in a Bayes sense) estimate parameters in weakly-identified andhighly-parameterised models with relative ease. We demonstrate theirapplicability through an analysis of extreme sea-surface temperature in the RedSea where, after training, we obtain parameter estimates and bootstrap-basedconfidence intervals from hundreds of spatial fields in a fraction of a second.</description><author>Matthew Sainsbury-Dale, Andrew Zammit-Mangion, Raphaël Huser</author><pubDate>Thu, 27 Jul 2023 17:50:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.12942v4</guid></item><item><title>Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale</title><link>http://arxiv.org/abs/2306.00017v4</link><description>Large language models (LLMs) have achieved a milestone that undenia-blychanged many held beliefs in artificial intelligence (AI). However, thereremains many limitations of these LLMs when it comes to true languageunderstanding, limitations that are a byproduct of the under-lying architectureof deep neural networks. Moreover, and due to their subsymbolic nature,whatever knowledge these models acquire about how language works will always beburied in billions of microfeatures (weights), none of which is meaningful onits own, making such models hopelessly unexplainable. To address theselimitations, we suggest com-bining the strength of symbolic representationswith what we believe to be the key to the success of LLMs, namely a successfulbottom-up re-verse engineering of language at scale. As such we argue for abottom-up reverse engineering of language in a symbolic setting. Hints on whatthis project amounts to have been suggested by several authors, and we discussin some detail here how this project could be accomplished.</description><author>Walid S. Saba</author><pubDate>Thu, 27 Jul 2023 17:47:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00017v4</guid></item><item><title>Scaling TransNormer to 175 Billion Parameters</title><link>http://arxiv.org/abs/2307.14995v1</link><description>We present TransNormerLLM, the first linear attention-based Large LanguageModel (LLM) that outperforms conventional softmax attention-based models interms of both accuracy and efficiency. TransNormerLLM evolves from the previouslinear attention architecture TransNormer by making advanced modifications thatinclude positional embedding, linear attention acceleration, gating mechanism,tensor normalization, inference acceleration and stabilization. Specifically,we use LRPE together with an exponential decay to avoid attention dilutionissues while allowing the model to retain global interactions between tokens.Additionally, we propose Lightning Attention, a cutting-edge technique thataccelerates linear attention by more than twice in runtime and reduces memoryusage by a remarkable four times. To further enhance the performance ofTransNormer, we leverage a gating mechanism to smooth training and a new tensornormalization scheme to accelerate the model, resulting in an impressiveacceleration of over 20%. Furthermore, we have developed a robust inferencealgorithm that ensures numerical stability and consistent inference speed,regardless of the sequence length, showcasing superior efficiency during bothtraining and inference stages. Scalability is at the heart of our model'sdesign, enabling seamless deployment on large-scale clusters and facilitatingexpansion to even more extensive models, all while maintaining outstandingperformance metrics. Rigorous validation of our model design is achievedthrough a series of comprehensive experiments on our self-collected corpus,boasting a size exceeding 6TB and containing over 2 trillion tokens. To ensuredata quality and relevance, we implement a new self-cleaning strategy to filterour collected data. Our pre-trained models will be released to foster communityadvancements in efficient LLMs.</description><author>Zhen Qin, Dong Li, Weigao Sun, Weixuan Sun, Xuyang Shen, Xiaodong Han, Yunshen Wei, Baohong Lv, Fei Yuan, Xiao Luo, Yu Qiao, Yiran Zhong</author><pubDate>Thu, 27 Jul 2023 17:45:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14995v1</guid></item><item><title>Thinker: Learning to Plan and Act</title><link>http://arxiv.org/abs/2307.14993v1</link><description>We propose the Thinker algorithm, a novel approach that enables reinforcementlearning agents to autonomously interact with and utilize a learned worldmodel. The Thinker algorithm wraps the environment with a world model andintroduces new actions designed for interacting with the world model. Thesemodel-interaction actions enable agents to perform planning by proposingalternative plans to the world model before selecting a final action to executein the environment. This approach eliminates the need for hand-crafted planningalgorithms by enabling the agent to learn how to plan autonomously and allowsfor easy interpretation of the agent's plan with visualization. We demonstratethe algorithm's effectiveness through experimental results in the game ofSokoban and the Atari 2600 benchmark, where the Thinker algorithm achievesstate-of-the-art performance and competitive results, respectively.Visualizations of agents trained with the Thinker algorithm demonstrate thatthey have learned to plan effectively with the world model to select betteractions. The algorithm's generality opens a new research direction on how aworld model can be used in reinforcement learning and how planning can beseamlessly integrated into an agent's decision-making process.</description><author>Stephen Chung, Ivan Anokhin, David Krueger</author><pubDate>Thu, 27 Jul 2023 17:40:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14993v1</guid></item><item><title>Trace Recovery from Stochastically Known Logs</title><link>http://arxiv.org/abs/2206.12672v2</link><description>In this work we propose an algorithm for trace recovery from stochasticallyknown logs, a setting that is becoming more common with the increasing numberof sensors and predictive models that generate uncertain data. The suggestedapproach calculates the conformance between a process model and astochastically known trace and recovers the best alignment within thisstochastic trace as the true trace. The paper offers an analysis of the impactof various cost models on trace recovery accuracy and makes use of a productmulti-graph to compare alternative trace recovery options. The average accuracyof our approach, evaluated using two publicly available datasets, isimpressive, with an average recovery accuracy score of 90-97%, significantlyimproving a common heuristic that chooses the most likely value for eachuncertain activity. We believe that the effectiveness of the proposed algorithmin recovering correct traces from stochastically known logs may be a powerfulaid for developing credible decision-making tools in uncertain settings.</description><author>Eli Bogdanov, Izack Cohen, Avigdor Gal</author><pubDate>Thu, 27 Jul 2023 17:38:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.12672v2</guid></item><item><title>Multilingual Code Co-Evolution Using Large Language Models</title><link>http://arxiv.org/abs/2307.14991v1</link><description>Many software projects implement APIs and algorithms in multiple programminglanguages. Maintaining such projects is tiresome, as developers have to ensurethat any change (e.g., a bug fix or a new feature) is being propagated, timelyand without errors, to implementations in other programming languages. In theworld of ever-changing software, using rule-based translation tools (i.e.,transpilers) or machine learning models for translating code from one languageto another provides limited value. Translating each time the entire codebasefrom one language to another is not the way developers work. In this paper, wetarget a novel task: translating code changes from one programming language toanother using large language models (LLMs). We design and implement the firstLLM, dubbed Codeditor, to tackle this task. Codeditor explicitly models codechanges as edit sequences and learns to correlate changes across programminglanguages. To evaluate Codeditor, we collect a corpus of 6,613 aligned codechanges from 8 pairs of open-source software projects implementing similarfunctionalities in two programming languages (Java and C#). Results show thatCodeditor outperforms the state-of-the-art approaches by a large margin on allcommonly used automatic metrics. Our work also reveals that Codeditor iscomplementary to the existing generation-based models, and their combinationensures even greater performance.</description><author>Jiyang Zhang, Pengyu Nie, Junyi Jessy Li, Milos Gligoric</author><pubDate>Thu, 27 Jul 2023 17:37:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14991v1</guid></item><item><title>Incrementally-Computable Neural Networks: Efficient Inference for Dynamic Inputs</title><link>http://arxiv.org/abs/2307.14988v1</link><description>Deep learning often faces the challenge of efficiently processing dynamicinputs, such as sensor data or user inputs. For example, an AI writingassistant is required to update its suggestions in real time as a document isedited. Re-running the model each time is expensive, even with compressiontechniques like knowledge distillation, pruning, or quantization. Instead, wetake an incremental computing approach, looking to reuse calculations as theinputs change. However, the dense connectivity of conventional architecturesposes a major obstacle to incremental computation, as even minor input changescascade through the network and restrict information reuse. To address this, weuse vector quantization to discretize intermediate values in the network, whichfilters out noisy and unnecessary modifications to hidden neurons, facilitatingthe reuse of their values. We apply this approach to the transformersarchitecture, creating an efficient incremental inference algorithm withcomplexity proportional to the fraction of the modified inputs. Our experimentswith adapting the OPT-125M pre-trained language model demonstrate comparableaccuracy on document classification while requiring 12.1X (median) feweroperations for processing sequences of atomic edits.</description><author>Or Sharir, Anima Anandkumar</author><pubDate>Thu, 27 Jul 2023 17:30:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14988v1</guid></item><item><title>GP-guided MPPI for Efficient Navigation in Complex Unknown Cluttered Environments</title><link>http://arxiv.org/abs/2307.04019v2</link><description>Robotic navigation in unknown, cluttered environments with limited sensingcapabilities poses significant challenges in robotics. Local trajectoryoptimization methods, such as Model Predictive Path Intergal (MPPI), are apromising solution to this challenge. However, global guidance is required toensure effective navigation, especially when encountering challengingenvironmental conditions or navigating beyond the planning horizon. This studypresents the GP-MPPI, an online learning-based control strategy that integratesMPPI with a local perception model based on Sparse Gaussian Process (SGP). Thekey idea is to leverage the learning capability of SGP to construct a variance(uncertainty) surface, which enables the robot to learn about the navigablespace surrounding it, identify a set of suggested subgoals, and ultimatelyrecommend the optimal subgoal that minimizes a predefined cost function to thelocal MPPI planner. Afterward, MPPI computes the optimal control sequence thatsatisfies the robot and collision avoidance constraints. Such an approacheliminates the necessity of a global map of the environment or an offlinetraining process. We validate the efficiency and robustness of our proposedcontrol strategy through both simulated and real-world experiments of 2Dautonomous navigation tasks in complex unknown environments, demonstrating itssuperiority in guiding the robot safely towards its desired goal while avoidingobstacles and escaping entrapment in local minima. The GPU implementation ofGP-MPPI, including the supplementary video, is available athttps://github.com/IhabMohamed/GP-MPPI.</description><author>Ihab S. Mohamed, Mahmoud Ali, Lantao Liu</author><pubDate>Thu, 27 Jul 2023 17:22:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.04019v2</guid></item><item><title>Efficient Alternating Minimization with Applications to Weighted Low Rank Approximation</title><link>http://arxiv.org/abs/2306.04169v2</link><description>Weighted low rank approximation is a fundamental problem in numerical linearalgebra, and it has many applications in machine learning. Given a matrix $M\in \mathbb{R}^{n \times n}$, a weight matrix $W \in \mathbb{R}_{\geq 0}^{n\times n}$, a parameter $k$, the goal is to output two matrices $U, V \in\mathbb{R}^{n \times k}$ such that $\| W \circ (M - U V^\top) \|_F$ isminimized, where $\circ$ denotes the Hadamard product. Such a problem is knownto be NP-hard and even hard to approximate assuming Exponential Time Hypothesis[GG11, RSW16]. Meanwhile, alternating minimization is a good heuristic solutionfor approximating weighted low rank approximation. The work [LLR16] shows that,under mild assumptions, alternating minimization does provide provableguarantees. In this work, we develop an efficient and robust framework foralternating minimization. For weighted low rank approximation, this improvesthe runtime of [LLR16] from $n^2 k^2$ to $n^2k$. At the heart of our workframework is a high-accuracy multiple response regression solver together witha robust analysis of alternating minimization.</description><author>Zhao Song, Mingquan Ye, Junze Yin, Lichen Zhang</author><pubDate>Thu, 27 Jul 2023 17:20:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.04169v2</guid></item><item><title>MapNeRF: Incorporating Map Priors into Neural Radiance Fields for Driving View Simulation</title><link>http://arxiv.org/abs/2307.14981v1</link><description>Simulating camera sensors is a crucial task in autonomous driving. Althoughneural radiance fields are exceptional at synthesizing photorealistic views indriving simulations, they still fail in generating extrapolated views. Thispaper proposes to incorporate map priors into neural radiance fields tosynthesize out-of-trajectory driving views with semantic road consistency. Thekey insight is that map information can be utilized as a prior to guide thetraining of the radiance fields with uncertainty. Specifically, we utilize thecoarse ground surface as uncertain information to supervise the density fieldand warp depth with uncertainty from unknown camera poses to ensure multi-viewconsistency. Experimental results demonstrate that our approach can producesemantic consistency in deviated views for vehicle camera simulation.</description><author>Chenming Wu, Jiadai Sun, Zhelun Shen, Liangjun Zhang</author><pubDate>Thu, 27 Jul 2023 17:19:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14981v1</guid></item><item><title>Causal Lifting and Link Prediction</title><link>http://arxiv.org/abs/2302.01198v2</link><description>Existing causal models for link prediction assume an underlying set ofinherent node factors -- an innate characteristic defined at the node's birth-- that governs the causal evolution of links in the graph. In some causaltasks, however, link formation is path-dependent: The outcome of linkinterventions depends on existing links. Unfortunately, these existing causalmethods are not designed for path-dependent link formation, as the cascadingfunctional dependencies between links (arising from path dependence) are eitherunidentifiable or require an impractical number of control variables. Toovercome this, we develop the first causal model capable of dealing with pathdependencies in link prediction. In this work we introduce the concept ofcausal lifting, an invariance in causal models of independent interest that, ongraphs, allows the identification of causal link prediction queries usinglimited interventional data. Further, we show how structural pairwiseembeddings exhibit lower bias and correctly represent the task's causalstructure, as opposed to existing node embeddings, e.g., graph neural networknode embeddings and matrix factorization. Finally, we validate our theoreticalfindings on three scenarios for causal link prediction tasks: knowledge basecompletion, covariance matrix estimation and consumer-product recommendations.</description><author>Leonardo Cotta, Beatrice Bevilacqua, Nesreen Ahmed, Bruno Ribeiro</author><pubDate>Thu, 27 Jul 2023 17:11:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01198v2</guid></item><item><title>Gaussian Latent Representations for Uncertainty Estimation using Mahalanobis Distance in Deep Classifiers</title><link>http://arxiv.org/abs/2305.13849v2</link><description>Recent works show that the data distribution in a network's latent space isuseful for estimating classification uncertainty and detectingOut-of-distribution (OOD) samples. To obtain a well-regularized latent spacethat is conducive for uncertainty estimation, existing methods bring insignificant changes to model architectures and training procedures. In thispaper, we present a lightweight, fast, and high-performance regularizationmethod for Mahalanobis distance-based uncertainty prediction, and that requiresminimal changes to the network's architecture. To derive Gaussian latentrepresentation favourable for Mahalanobis Distance calculation, we introduce aself-supervised representation learning method that separates in-classrepresentations into multiple Gaussians. Classes with non-Gaussianrepresentations are automatically identified and dynamically clustered intomultiple new classes that are approximately Gaussian. Evaluation on standardOOD benchmarks shows that our method achieves state-of-the-art results on OODdetection with minimal inference time, and is very competitive on predictiveprobability calibration. Finally, we show the applicability of our method to areal-life computer vision use case on microorganism classification.</description><author>Aishwarya Venkataramanan, Assia Benbihi, Martin Laviale, Cedric Pradalier</author><pubDate>Thu, 27 Jul 2023 17:09:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13849v2</guid></item><item><title>Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models</title><link>http://arxiv.org/abs/2307.14971v1</link><description>With the overwhelming trend of mask image modeling led by MAE, generativepre-training has shown a remarkable potential to boost the performance offundamental models in 2D vision. However, in 3D vision, the over-reliance onTransformer-based backbones and the unordered nature of point clouds haverestricted the further development of generative pre-training. In this paper,we propose a novel 3D-to-2D generative pre-training method that is adaptable toany point cloud model. We propose to generate view images from differentinstructed poses via the cross-attention mechanism as the pre-training scheme.Generating view images has more precise supervision than its point cloudcounterpart, thus assisting 3D backbones to have a finer comprehension of thegeometrical structure and stereoscopic relations of the point cloud.Experimental results have proved the superiority of our proposed 3D-to-2Dgenerative pre-training over previous pre-training methods. Our method is alsoeffective in boosting the performance of architecture-oriented approaches,achieving state-of-the-art performance when fine-tuning on ScanObjectNNclassification and ShapeNetPart segmentation tasks. Code is available athttps://github.com/wangzy22/TAP.</description><author>Ziyi Wang, Xumin Yu, Yongming Rao, Jie Zhou, Jiwen Lu</author><pubDate>Thu, 27 Jul 2023 17:07:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14971v1</guid></item><item><title>Learning locally dominant force balances in active particle systems</title><link>http://arxiv.org/abs/2307.14970v1</link><description>We use a combination of unsupervised clustering and sparsity-promotinginference algorithms to learn locally dominant force balances that explainmacroscopic pattern formation in self-organized active particle systems. Theself-organized emergence of macroscopic patterns from microscopic interactionsbetween self-propelled particles can be widely observed nature. Althoughhydrodynamic theories help us better understand the physical basis of thisphenomenon, identifying a sufficient set of local interactions that shape,regulate, and sustain self-organized structures in active particle systemsremains challenging. We investigate a classic hydrodynamic model ofself-propelled particles that produces a wide variety of patterns, like astersand moving density bands. Our data-driven analysis shows that propagating bandsare formed by local alignment interactions driven by density gradients, whilesteady-state asters are shaped by a mechanism of splay-induced negativecompressibility arising from strong particle interactions. Our method alsoreveals analogous physical principles of pattern formation in a system wherethe speed of the particle is influenced by local density. This demonstrates theability of our method to reveal physical commonalities across models. Thephysical mechanisms inferred from the data are in excellent agreement withanalytical scaling arguments and experimental observations.</description><author>Dominik Sturm, Suryanarayana Maddu, Ivo F. Sbalzarini</author><pubDate>Thu, 27 Jul 2023 17:06:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14970v1</guid></item><item><title>From Contextual Data to Newsvendor Decisions: On the Actual Performance of Data-Driven Algorithms</title><link>http://arxiv.org/abs/2302.08424v3</link><description>In this work, we explore a framework for contextual decision-making to studyhow the relevance and quantity of past data affects the performance of adata-driven policy. We analyze a contextual Newsvendor problem in which adecision-maker needs to trade-off between an underage and an overage cost inthe face of uncertain demand. We consider a setting in which past demandsobserved under ``close by'' contexts come from close by distributions andanalyze the performance of data-driven algorithms through a notion ofcontext-dependent worst-case expected regret. We analyze the broad class ofWeighted Empirical Risk Minimization (WERM) policies which weigh past dataaccording to their similarity in the contextual space. This class includesclassical policies such as ERM, k-Nearest Neighbors and kernel-based policies.Our main methodological contribution is to characterize exactly the worst-caseregret of any WERM policy on any given configuration of contexts. To the bestof our knowledge, this provides the first understanding of tight performanceguarantees in any contextual decision-making problem, with past literaturefocusing on upper bounds via concentration inequalities. We instead take anoptimization approach, and isolate a structure in the Newsvendor loss functionthat allows to reduce the infinite-dimensional optimization problem overworst-case distributions to a simple line search. This in turn allows us to unveil fundamental insights that were obfuscated byprevious general-purpose bounds. We characterize actual guaranteed performanceas a function of the contexts, as well as granular insights on the learningcurve of algorithms.</description><author>Omar Besbes, Will Ma, Omar Mouchtaki</author><pubDate>Thu, 27 Jul 2023 16:56:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08424v3</guid></item><item><title>Federated Model Aggregation via Self-Supervised Priors for Highly Imbalanced Medical Image Classification</title><link>http://arxiv.org/abs/2307.14959v1</link><description>In the medical field, federated learning commonly deals with highlyimbalanced datasets, including skin lesions and gastrointestinal images.Existing federated methods under highly imbalanced datasets primarily focus onoptimizing a global model without incorporating the intra-class variations thatcan arise in medical imaging due to different populations, findings, andscanners. In this paper, we study the inter-client intra-class variations withpublicly available self-supervised auxiliary networks. Specifically, we findthat employing a shared auxiliary pre-trained model, like MoCo-V2, locally onevery client yields consistent divergence measurements. Based on thesefindings, we derive a dynamic balanced model aggregation via self-supervisedpriors (MAS) to guide the global model optimization. Fed-MAS can be utilizedwith different local learning methods for effective model aggregation toward ahighly robust and unbiased global model. Our code is available at\url{https://github.com/xmed-lab/Fed-MAS}.</description><author>Marawan Elbatel, Hualiang Wang, Robert Martí, Huazhu Fu, Xiaomeng Li</author><pubDate>Thu, 27 Jul 2023 16:52:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14959v1</guid></item><item><title>Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space</title><link>http://arxiv.org/abs/2307.14953v1</link><description>This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aimsto mitigate data distribution shifts when transferring knowledge from multiplelabeled source domains to an unlabeled target domain. We propose a novel MSDAframework based on dictionary learning and optimal transport. We interpret eachdomain in MSDA as an empirical distribution. As such, we express each domain asa Wasserstein barycenter of dictionary atoms, which are empiricaldistributions. We propose a novel algorithm, DaDiL, for learning viamini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates.Based on our dictionary, we propose two novel methods for MSDA: DaDil-R, basedon the reconstruction of labeled samples in the target domain, and DaDiL-E,based on the ensembling of classifiers learned on atom distributions. Weevaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU,where we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% inclassification performance. Finally, we show that interpolations in theWasserstein hull of learned atoms provide data that can generalize to thetarget domain.</description><author>Eduardo Fernandes Montesuma, Fred Ngolè Mboula, Antoine Souloumiac</author><pubDate>Thu, 27 Jul 2023 16:46:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14953v1</guid></item><item><title>Network Fault-tolerant and Byzantine-resilient Social Learning via Collaborative Hierarchical Non-Bayesian Learning</title><link>http://arxiv.org/abs/2307.14952v1</link><description>As the network scale increases, existing fully distributed solutions start tolag behind the real-world challenges such as (1) slow information propagation,(2) network communication failures, and (3) external adversarial attacks. Inthis paper, we focus on hierarchical system architecture and address theproblem of non-Bayesian learning over networks that are vulnerable tocommunication failures and adversarial attacks. On network communication, weconsider packet-dropping link failures. We first propose a hierarchical robust push-sum algorithm that can achieveaverage consensus despite frequent packet-dropping link failures. We provide asparse information fusion rule between the parameter server and arbitrarilyselected network representatives. Then, interleaving the consensus update stepwith a dual averaging update with Kullback-Leibler (KL) divergence as theproximal function, we obtain a packet-dropping fault-tolerant non-Bayesianlearning algorithm with provable convergence guarantees. On external adversarial attacks, we consider Byzantine attacks in which thecompromised agents can send maliciously calibrated messages to others(including both the agents and the parameter server). To avoid the curse ofdimensionality of Byzantine consensus, we solve the non-Bayesian learningproblem via running multiple dynamics, each of which only involves Byzantineconsensus with scalar inputs. To facilitate resilient information propagationacross sub-networks, we use a novel Byzantine-resilient gossiping-type rule atthe parameter server.</description><author>Connor Mclaughlin, Matthew Ding, Denis Edogmus, Lili Su</author><pubDate>Thu, 27 Jul 2023 16:46:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14952v1</guid></item><item><title>A Self-Adaptive Penalty Method for Integrating Prior Knowledge Constraints into Neural ODEs</title><link>http://arxiv.org/abs/2307.14940v1</link><description>The continuous dynamics of natural systems has been effectively modelledusing Neural Ordinary Differential Equations (Neural ODEs). However, foraccurate and meaningful predictions, it is crucial that the models follow theunderlying rules or laws that govern these systems. In this work, we propose aself-adaptive penalty algorithm for Neural ODEs to enable modelling ofconstrained natural systems. The proposed self-adaptive penalty function candynamically adjust the penalty parameters. The explicit introduction of priorknowledge helps to increase the interpretability of Neural ODE -based models.We validate the proposed approach by modelling three natural systems with priorknowledge constraints: population growth, chemical reaction evolution, anddamped harmonic oscillator motion. The numerical experiments and a comparisonwith other penalty Neural ODE approaches and \emph{vanilla} Neural ODE,demonstrate the effectiveness of the proposed self-adaptive penalty algorithmfor Neural ODEs in modelling constrained natural systems. Moreover, theself-adaptive penalty approach provides more accurate and robust models withreliable and meaningful predictions.</description><author>C. Coelho, M. Fernanda P. Costa, L. L. Ferrás</author><pubDate>Thu, 27 Jul 2023 16:32:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14940v1</guid></item><item><title>Efficient Interaction-Aware Interval Analysis of Neural Network Feedback Loops</title><link>http://arxiv.org/abs/2307.14938v1</link><description>In this paper, we propose a computationally efficient framework for intervalreachability of neural network controlled systems. Our approach builds uponinclusion functions for the neural network controller and the open-loop system.We observe that many state-of-the-art neural network verifiers can produceinclusion functions for neural networks. We introduce and analyze a new classof inclusion functions for the open-loop dynamics based on bounds of thefunction Jacobian that is particularly suitable for capturing the interactionsbetween systems and neural network controllers. Next, for any dynamical system,we use inclusion functions to construct an embedding system with twice thenumber of states as the original system. We show that a single trajectory ofthis embedding system provides hyper-rectangular over-approximations ofreachable sets. We then propose two approaches for constructing a closed-loopembedding system for a neural network controlled dynamical system that accountsfor the interaction between the system and the controller in different ways.The interconnection-based approach accounts for the worst-case evolution ofeach coordinate separately by substituting the neural network inclusionfunction into the open-loop embedding system. The interaction-based approachuses the newly introduced class of Jacobian-based inclusion functions to fullycapture first-order interactions between the system and the controller.Finally, we implement our approach in a Python framework called\texttt{ReachMM} and show that on several existing benchmarks, our methodsoutperform the existing approaches in the literature. We also demonstrate thescalability of our method on a vehicle platooning example with up to $200$states.</description><author>Saber Jafarpour, Akash Harapanahalli, Samuel Coogan</author><pubDate>Thu, 27 Jul 2023 16:30:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14938v1</guid></item><item><title>PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback</title><link>http://arxiv.org/abs/2307.14936v1</link><description>Large Language Models for Code (Code LLM) are flourishing. New and powerfulmodels are released on a weekly basis, demonstrating remarkable performance onthe code generation task. Various approaches have been proposed to boost thecode generation performance of pre-trained Code LLMs, such as supervisedfine-tuning, instruction tuning, reinforcement learning, etc. In this paper, wepropose a novel RRTF (Rank Responses to align Test&amp;Teacher Feedback) framework,which can effectively and efficiently boost pre-trained large language modelsfor code generation. Under this framework, we present PanGu-Coder2, whichachieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, throughan extensive evaluation on CoderEval and LeetCode benchmarks, we show thatPanGu-Coder2 consistently outperforms all previous Code LLMs.</description><author>Bo Shen, Jiaxin Zhang, Taihong Chen, Daoguang Zan, Bing Geng, An Fu, Muhan Zeng, Ailun Yu, Jichuan Ji, Jingyang Zhao, Yuenan Guo, Qianxiang Wang</author><pubDate>Thu, 27 Jul 2023 16:28:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14936v1</guid></item><item><title>Solving Data Quality Problems with Desbordante: a Demo</title><link>http://arxiv.org/abs/2307.14935v1</link><description>Data profiling is an essential process in modern data-driven industries. Oneof its critical components is the discovery and validation of complexstatistics, including functional dependencies, data constraints, associationrules, and others. However, most existing data profiling systems that focus on complexstatistics do not provide proper integration with the tools used bycontemporary data scientists. This creates a significant barrier to theadoption of these tools in the industry. Moreover, existing systems were notcreated with industrial-grade workloads in mind. Finally, they do not aim toprovide descriptive explanations, i.e. why a given pattern is not found. It isa significant issue as it is essential to understand the underlying reasons fora specific pattern's absence to make informed decisions based on the data. Because of that, these patterns are effectively rest in thin air: theirapplication scope is rather limited, they are rarely used by the broaderpublic. At the same time, as we are going to demonstrate in this presentation,complex statistics can be efficiently used to solve many classic data qualityproblems. Desbordante is an open-source data profiler that aims to close this gap. Itis built with emphasis on industrial application: it is efficient, scalable,resilient to crashes, and provides explanations. Furthermore, it providesseamless Python integration by offloading various costly operations to the C++core, not only mining. In this demonstration, we show several scenarios that allow end users tosolve different data quality problems. Namely, we showcase typo detection, datadeduplication, and data anomaly detection scenarios.</description><author>George Chernishev, Michael Polyntsov, Anton Chizhov, Kirill Stupakov, Ilya Shchuckin, Alexander Smirnov, Maxim Strutovsky, Alexey Shlyonskikh, Mikhail Firsov, Stepan Manannikov, Nikita Bobrov, Daniil Goncharov, Ilia Barutkin, Vladislav Shalnev, Kirill Muraviev, Anna Rakhmukova, Dmitriy Shcheka, Anton Chernikov, Mikhail Vyrodov, Kurbatov Yaroslav, Maxim Fofanov, Belokonnyi Sergei, Anosov Pavel, Arthur Saliou, Eduard Gaisin, Kirill Smirnov</author><pubDate>Thu, 27 Jul 2023 16:26:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14935v1</guid></item><item><title>Graph-based Polyphonic Multitrack Music Generation</title><link>http://arxiv.org/abs/2307.14928v1</link><description>Graphs can be leveraged to model polyphonic multitrack symbolic music, wherenotes, chords and entire sections may be linked at different levels of themusical hierarchy by tonal and rhythmic relationships. Nonetheless, there is alack of works that consider graph representations in the context of deeplearning systems for music generation. This paper bridges this gap byintroducing a novel graph representation for music and a deep VariationalAutoencoder that generates the structure and the content of musical graphsseparately, one after the other, with a hierarchical architecture that matchesthe structural priors of music. By separating the structure and content ofmusical graphs, it is possible to condition generation by specifying whichinstruments are played at certain times. This opens the door to a new form ofhuman-computer interaction in the context of music co-creation. After trainingthe model on existing MIDI datasets, the experiments show that the model isable to generate appealing short and long musical sequences and torealistically interpolate between them, producing music that is tonally andrhythmically consistent. Finally, the visualization of the embeddings showsthat the model is able to organize its latent space in accordance with knownmusical concepts.</description><author>Emanuele Cosenza, Andrea Valenti, Davide Bacciu</author><pubDate>Thu, 27 Jul 2023 16:18:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14928v1</guid></item><item><title>Learning Transfer Operators by Kernel Density Estimation</title><link>http://arxiv.org/abs/2210.03124v3</link><description>Inference of transfer operators from data is often formulated as a classicalproblem that hinges on the Ulam method. The conventional description, known asthe Ulam-Galerkin method, involves projecting onto basis functions representedas characteristic functions supported over a fine grid of rectangles. From thisperspective, the Ulam-Galerkin approach can be interpreted as densityestimation using the histogram method. In this study, we recast the problemwithin the framework of statistical density estimation. This alternativeperspective allows for an explicit and rigorous analysis of bias and variance,thereby facilitating a discussion on the mean square error. Throughcomprehensive examples utilizing the logistic map and a Markov map, wedemonstrate the validity and effectiveness of this approach in estimating theeigenvectors of the Frobenius-Perron operator. We compare the performance ofHistogram Density Estimation(HDE) and Kernel Density Estimation(KDE) methodsand find that KDE generally outperforms HDE in terms of accuracy. However, itis important to note that KDE exhibits limitations around boundary points andjumps. Based on our research findings, we suggest the possibility ofincorporating other density estimation methods into this field and proposefuture investigations into the application of KDE-based estimation forhigh-dimensional maps. These findings provide valuable insights for researchersand practitioners working on estimating the Frobenius-Perron operator andhighlight the potential of density estimation techniques in this area of study. Keywords: Transfer Operators; Frobenius-Perron operator; probability densityestimation; Ulam-Galerkin method; Kernel Density Estimation; Histogram DensityEstimation.</description><author>Sudam Surasinghe, Jeremie Fish, Erik M. Bollt</author><pubDate>Thu, 27 Jul 2023 16:18:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.03124v3</guid></item><item><title>Efficient and Feasible Robotic Assembly Sequence Planning via Graph Representation Learning</title><link>http://arxiv.org/abs/2303.10135v4</link><description>Automatic Robotic Assembly Sequence Planning (RASP) can significantly improveproductivity and resilience in modern manufacturing along with the growing needfor greater product customization. One of the main challenges in realizing suchautomation resides in efficiently finding solutions from a growing number ofpotential sequences for increasingly complex assemblies. Besides, costlyfeasibility checks are always required for the robotic system. To address this,we propose a holistic graphical approach including a graph representationcalled Assembly Graph for product assemblies and a policy architecture, GraphAssembly Processing Network, dubbed GRACE for assembly sequence generation.With GRACE, we are able to extract meaningful information from the graph inputand predict assembly sequences in a step-by-step manner. In experiments, weshow that our approach can predict feasible assembly sequences across productvariants of aluminum profiles based on data collected in simulation of adual-armed robotic system. We further demonstrate that our method is capable ofdetecting infeasible assemblies, substantially alleviating the undesirableimpacts from false predictions, and hence facilitating real-world deploymentsoon. Code and training data are available at https://github.com/DLR-RM/GRACE.</description><author>Matan Atad, Jianxiang Feng, Ismael Rodríguez, Maximilian Durner, Rudolph Triebel</author><pubDate>Thu, 27 Jul 2023 16:14:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.10135v4</guid></item><item><title>Automatic Emotion Experiencer Recognition</title><link>http://arxiv.org/abs/2305.16731v4</link><description>The most prominent subtask in emotion analysis is emotion classification; toassign a category to a textual unit, for instance a social media post. Manyresearch questions from the social sciences do, however, not only require thedetection of the emotion of an author of a post but to understand who isascribed an emotion in text. This task is tackled by emotion role labelingwhich aims at extracting who is described in text to experience an emotion,why, and towards whom. This could, however, be considered overly sophisticatedif the main question to answer is who feels which emotion. A targeted approachfor such setup is to classify emotion experiencer mentions (aka "emoters")regarding the emotion they presumably perceive. This task is similar to namedentity recognition of person names with the difference that not every mentionedentity name is an emoter. While, very recently, data with emoter annotationshas been made available, no experiments have yet been performed to detect suchmentions. With this paper, we provide baseline experiments to understand howchallenging the task is. We further evaluate the impact on experiencer-specificemotion categorization and appraisal detection in a pipeline, when goldmentions are not available. We show that experiencer detection in text is achallenging task, with a precision of .82 and a recall of .56 (F1 =.66). Theseresults motivate future work of jointly modeling emoter spans andemotion/appraisal predictions.</description><author>Maximilian Wegge, Roman Klinger</author><pubDate>Thu, 27 Jul 2023 16:09:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.16731v4</guid></item><item><title>Identifiability of direct effects from summary causal graphs</title><link>http://arxiv.org/abs/2306.16958v2</link><description>Dynamic structural causal models (SCMs) are a powerful framework forreasoning in dynamic systems about direct effects which measure how a change inone variable affects another variable while holding all other variablesconstant. The causal relations in a dynamic structural causal model can bequalitatively represented with a full-time causal graph. Assuming linearity andcausal sufficiency and given the full-time causal graph, the direct causaleffect is always identifiable and can be estimated from data by adjusting onany set of variables given by the so-called single-door criterion. However, inmany application such a graph is not available for various reasons butnevertheless experts have access to an abstraction of the full-time causalgraph which represents causal relations between time series while omittingtemporal information. This paper presents a complete identifiability resultwhich characterizes all cases for which the direct effect is graphicallyidentifiable from summary causal graphs and gives two sound finite adjustmentsets that can be used to estimate the direct effect whenever it isidentifiable.</description><author>Simon Ferreira, Charles K. Assaad</author><pubDate>Thu, 27 Jul 2023 16:07:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.16958v2</guid></item><item><title>Benchmarking Performance of Deep Learning Model for Material Segmentation on Two HPC Systems</title><link>http://arxiv.org/abs/2307.14921v1</link><description>Performance Benchmarking of HPC systems is an ongoing effort that seeks toprovide information that will allow for increased performance and improve thejob schedulers that manage these systems. We develop a benchmarking tool thatutilizes machine learning models and gathers performance data onGPU-accelerated nodes while they perform material segmentation analysis. Thebenchmark uses a ML model that has been converted from Caffe to PyTorch usingthe MMdnn toolkit and the MINC-2500 dataset. Performance data is gathered ontwo ERDC DSRC systems, Onyx and Vulcanite. The data reveals that whileVulcanite has faster model times in a large number of benchmarks, and it isalso more subject to some environmental factors that can cause performancesslower than Onyx. In contrast the model times from Onyx are consistent acrossbenchmarks.</description><author>Warren R. Williams, S. Ross Glandon, Luke L. Morris, Jing-Ru C. Cheng</author><pubDate>Thu, 27 Jul 2023 16:03:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14921v1</guid></item><item><title>GET3D--: Learning GET3D from Unconstrained Image Collections</title><link>http://arxiv.org/abs/2307.14918v1</link><description>The demand for efficient 3D model generation techniques has grownexponentially, as manual creation of 3D models is time-consuming and requiresspecialized expertise. While generative models have shown potential in creating3D textured shapes from 2D images, their applicability in 3D industries islimited due to the lack of a well-defined camera distribution in real-worldscenarios, resulting in low-quality shapes. To overcome this limitation, wepropose GET3D--, the first method that directly generates textured 3D shapesfrom 2D images with unknown pose and scale. GET3D-- comprises a 3D shapegenerator and a learnable camera sampler that captures the 6D external changeson the camera. In addition, We propose a novel training schedule to stablyoptimize both the shape generator and camera sampler in a unified framework. Bycontrolling external variations using the learnable camera sampler, our methodcan generate aligned shapes with clear textures. Extensive experimentsdemonstrate the efficacy of GET3D--, which precisely fits the 6D camera posedistribution and generates high-quality shapes on both synthetic and realisticunconstrained datasets.</description><author>Fanghua Yu, Xintao Wang, Zheyuan Li, Yan-Pei Cao, Ying Shan, Chao Dong</author><pubDate>Thu, 27 Jul 2023 16:00:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14918v1</guid></item><item><title>NSA: Naturalistic Support Artifact to Boost Network Confidence</title><link>http://arxiv.org/abs/2307.14917v1</link><description>Visual AI systems are vulnerable to natural and synthetic physical corruptionin the real-world. Such corruption often arises unexpectedly and alters themodel's performance. In recent years, the primary focus has been on adversarialattacks. However, natural corruptions (e.g., snow, fog, dust) are anomnipresent threat to visual AI systems and should be considered equallyimportant. Many existing works propose interesting solutions to train robustmodels against natural corruption. These works either leverage imageaugmentations, which come with the additional cost of model training, or placesuspicious patches in the scene to design unadversarial examples. In this work,we propose the idea of naturalistic support artifacts (NSA) for robustprediction. The NSAs are shown to be beneficial in scenarios where modelparameters are inaccessible and adding artifacts in the scene is feasible. TheNSAs are natural looking objects generated through artifact training usingDC-GAN to have high visual fidelity in the scene. We test against naturalcorruptions on the Imagenette dataset and observe the improvement in predictionconfidence score by four times. We also demonstrate NSA's capability toincrease adversarial accuracy by 8\% on average. Lastly, we qualitativelyanalyze NSAs using saliency maps to understand how they help improve predictionconfidence.</description><author>Abhijith Sharma, Phil Munz, Apurva Narayan</author><pubDate>Thu, 27 Jul 2023 16:00:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14917v1</guid></item><item><title>ARC-NLP at PAN 2023: Transition-Focused Natural Language Inference for Writing Style Detection</title><link>http://arxiv.org/abs/2307.14913v1</link><description>The task of multi-author writing style detection aims at finding anypositions of writing style change in a given text document. We formulate thetask as a natural language inference problem where two consecutive paragraphsare paired. Our approach focuses on transitions between paragraphs whiletruncating input tokens for the task. As backbone models, we employ differentTransformer-based encoders with warmup phase during training. We submit themodel version that outperforms baselines and other proposed model versions inour experiments. For the easy and medium setups, we submit transition-focusednatural language inference based on DeBERTa with warmup training, and the samemodel without transition for the hard setup.</description><author>Izzet Emre Kucukkaya, Umitcan Sahin, Cagri Toraman</author><pubDate>Thu, 27 Jul 2023 15:56:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14913v1</guid></item><item><title>ARC-NLP at PAN 2023: Hierarchical Long Text Classification for Trigger Detection</title><link>http://arxiv.org/abs/2307.14912v1</link><description>Fanfiction, a popular form of creative writing set within establishedfictional universes, has gained a substantial online following. However,ensuring the well-being and safety of participants has become a criticalconcern in this community. The detection of triggering content, material thatmay cause emotional distress or trauma to readers, poses a significantchallenge. In this paper, we describe our approach for the Trigger Detectionshared task at PAN CLEF 2023, where we want to detect multiple triggeringcontent in a given Fanfiction document. For this, we build a hierarchical modelthat uses recurrence over Transformer-based language models. In our approach,we first split long documents into smaller sized segments and use them tofine-tune a Transformer model. Then, we extract feature embeddings from thefine-tuned Transformer model, which are used as input in the training ofmultiple LSTM models for trigger detection in a multi-label setting. Our modelachieves an F1-macro score of 0.372 and F1-micro score of 0.736 on thevalidation set, which are higher than the baseline results shared at PAN CLEF2023.</description><author>Umitcan Sahin, Izzet Emre Kucukkaya, Cagri Toraman</author><pubDate>Thu, 27 Jul 2023 15:55:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14912v1</guid></item><item><title>Fraunhofer SIT at CheckThat! 2023: Mixing Single-Modal Classifiers to Estimate the Check-Worthiness of Multi-Modal Tweets</title><link>http://arxiv.org/abs/2307.00610v2</link><description>The option of sharing images, videos and audio files on social media opens upnew possibilities for distinguishing between false information and fake news onthe Internet. Due to the vast amount of data shared every second on socialmedia, not all data can be verified by a computer or a human expert. Here, acheck-worthiness analysis can be used as a first step in the fact-checkingpipeline and as a filtering mechanism to improve efficiency. This paperproposes a novel way of detecting the check-worthiness in multi-modal tweets.It takes advantage of two classifiers, each trained on a single modality. Forimage data, extracting the embedded text with an OCR analysis has shown toperform best. By combining the two classifiers, the proposed solution was ableto place first in the CheckThat! 2023 Task 1A with an F1 score of 0.7297achieved on the private test set.</description><author>Raphael Frick, Inna Vogel</author><pubDate>Thu, 27 Jul 2023 15:54:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00610v2</guid></item><item><title>Weakly Supervised AI for Efficient Analysis of 3D Pathology Samples</title><link>http://arxiv.org/abs/2307.14907v1</link><description>Human tissue and its constituent cells form a microenvironment that isfundamentally three-dimensional (3D). However, the standard-of-care inpathologic diagnosis involves selecting a few two-dimensional (2D) sections formicroscopic evaluation, risking sampling bias and misdiagnosis. Diverse methodsfor capturing 3D tissue morphologies have been developed, but they have yet hadlittle translation to clinical practice; manual and computational evaluationsof such large 3D data have so far been impractical and/or unable to providepatient-level clinical insights. Here we present Modality-Agnostic Multipleinstance learning for volumetric Block Analysis (MAMBA), a deep-learning-basedplatform for processing 3D tissue images from diverse imaging modalities andpredicting patient outcomes. Archived prostate cancer specimens were imagedwith open-top light-sheet microscopy or microcomputed tomography and theresulting 3D datasets were used to train risk-stratification networks based on5-year biochemical recurrence outcomes via MAMBA. With the 3D block-basedapproach, MAMBA achieves an area under the receiver operating characteristiccurve (AUC) of 0.86 and 0.74, superior to 2D traditional single-slice-basedprognostication (AUC of 0.79 and 0.57), suggesting superior prognosticationwith 3D morphological features. Further analyses reveal that the incorporationof greater tissue volume improves prognostic performance and mitigates riskprediction variability from sampling bias, suggesting the value of capturinglarger extents of heterogeneous 3D morphology. With the rapid growth andadoption of 3D spatial biology and pathology techniques by researchers andclinicians, MAMBA provides a general and efficient framework for 3D weaklysupervised learning for clinical decision support and can help to reveal novel3D morphological biomarkers for prognosis and therapeutic response.</description><author>Andrew H. Song, Mane Williams, Drew F. K. Williamson, Guillaume Jaume, Andrew Zhang, Bowen Chen, Robert Serafin, Jonathan T. C. Liu, Alex Baras, Anil V. Parwani, Faisal Mahmood</author><pubDate>Thu, 27 Jul 2023 15:48:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14907v1</guid></item><item><title>Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions</title><link>http://arxiv.org/abs/2307.14906v1</link><description>This work introduces TRON, a scalable session-based Transformer Recommenderusing Optimized Negative-sampling. Motivated by the scalability and performancelimitations of prevailing models such as SASRec and GRU4Rec+, TRON integratestop-k negative sampling and listwise loss functions to enhance itsrecommendation accuracy. Evaluations on relevant large-scale e-commercedatasets show that TRON improves upon the recommendation quality of currentmethods while maintaining training speeds similar to SASRec. A live A/B testyielded an 18.14% increase in click-through rate over SASRec, highlighting thepotential of TRON in practical settings. For further research, we provideaccess to our source code at https://github.com/otto-de/TRON and an anonymizeddataset at https://github.com/otto-de/recsys-dataset.</description><author>Timo Wilm, Philipp Normann, Sophie Baumeister, Paul-Vincent Kobow</author><pubDate>Thu, 27 Jul 2023 15:47:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14906v1</guid></item><item><title>CodeLens: An Interactive Tool for Visualizing Code Representations</title><link>http://arxiv.org/abs/2307.14902v1</link><description>Representing source code in a generic input format is crucial to automatesoftware engineering tasks, e.g., applying machine learning algorithms toextract information. Visualizing code representations can further enable humanexperts to gain an intuitive insight into the code. Unfortunately, as of today,there is no universal tool that can simultaneously visualise different types ofcode representations. In this paper, we introduce a tool, CodeLens, whichprovides a visual interaction environment that supports various representationmethods and helps developers understand and explore them. CodeLens is designedto support multiple programming languages, such as Java, Python, andJavaScript, and four types of code representations, including sequence oftokens, abstract syntax tree (AST), data flow graph (DFG), and control flowgraph (CFG). By using CodeLens, developers can quickly visualize the specificcode representation and also obtain the represented inputs for models of code.The Web-based interface of CodeLens is available at http://www.codelens.org.The demonstration video can be found at http://www.codelens.org/demo.</description><author>Yuejun Guo, Seifeddine Bettaieb, Qiang Hu, Yves Le Traon, Qiang Tang</author><pubDate>Thu, 27 Jul 2023 15:46:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14902v1</guid></item><item><title>Text-guided Foundation Model Adaptation for Pathological Image Classification</title><link>http://arxiv.org/abs/2307.14901v1</link><description>The recent surge of foundation models in computer vision and natural languageprocessing opens up perspectives in utilizing multi-modal clinical data totrain large models with strong generalizability. Yet pathological imagedatasets often lack biomedical text annotation and enrichment. Guidingdata-efficient image diagnosis from the use of biomedical text knowledgebecomes a substantial interest. In this paper, we propose to Connect Image andText Embeddings (CITE) to enhance pathological image classification. CITEinjects text insights gained from language models pre-trained with a broadrange of biomedical texts, leading to adapt foundation models towardspathological image understanding. Through extensive experiments on thePatchGastric stomach tumor pathological image dataset, we demonstrate that CITEachieves leading performance compared with various baselines especially whentraining data is scarce. CITE offers insights into leveraging in-domain textknowledge to reinforce data-efficient pathological image classification. Codeis available at https://github.com/Yunkun-Zhang/CITE.</description><author>Yunkun Zhang, Jin Gao, Mu Zhou, Xiaosong Wang, Yu Qiao, Shaoting Zhang, Dequan Wang</author><pubDate>Thu, 27 Jul 2023 15:44:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14901v1</guid></item><item><title>Fraunhofer SIT at CheckThat! 2023: Tackling Classification Uncertainty Using Model Souping on the Example of Check-Worthiness Classification</title><link>http://arxiv.org/abs/2307.02377v2</link><description>This paper describes the second-placed approach developed by the FraunhoferSIT team in the CLEF-2023 CheckThat! lab Task 1B for English. Given a textsnippet from a political debate, the aim of this task is to determine whetherit should be assessed for check-worthiness. Detecting check-worthy statementsaims to facilitate manual fact-checking efforts by prioritizing the claims thatfact-checkers should consider first. It can also be considered as primary stepof a fact-checking system. Our best-performing method took advantage of anensemble classification scheme centered on Model Souping. When applied to theEnglish data set, our submitted model achieved an overall F1 score of 0.878 andwas ranked as the second-best model in the competition.</description><author>Raphael Frick, Inna Vogel, Jeong-Eun Choi</author><pubDate>Thu, 27 Jul 2023 15:43:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02377v2</guid></item><item><title>Retrieval-based Text Selection for Addressing Class-Imbalanced Data in Classification</title><link>http://arxiv.org/abs/2307.14899v1</link><description>This paper addresses the problem of selecting of a set of texts forannotation in text classification using retrieval methods when there are limitson the number of annotations due to constraints on human resources. Anadditional challenge addressed is dealing with binary categories that have asmall number of positive instances, reflecting severe class imbalance. In oursituation, where annotation occurs over a long time period, the selection oftexts to be annotated can be made in batches, with previous annotations guidingthe choice of the next set. To address these challenges, the paper proposesleveraging SHAP to construct a quality set of queries for Elasticsearch andsemantic search, to try to identify optimal sets of texts for annotation thatwill help with class imbalance. The approach is tested on sets of cue textsdescribing possible future events, constructed by participants involved instudies aimed to help with the management of obesity and diabetes. We introducean effective method for selecting a small set of texts for annotation andbuilding high-quality classifiers. We integrate vector search, semantic search,and machine learning classifiers to yield a good solution. Our experimentsdemonstrate improved F1 scores for the minority classes in binaryclassification.</description><author>Sareh Ahmadi, Aditya Shah, Edward Fox</author><pubDate>Thu, 27 Jul 2023 15:42:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14899v1</guid></item><item><title>Mixture of Self-Supervised Learning</title><link>http://arxiv.org/abs/2307.14897v1</link><description>Self-supervised learning is popular method because of its ability to learnfeatures in images without using its labels and is able to overcome limitedlabeled datasets used in supervised learning. Self-supervised learning works byusing a pretext task which will be trained on the model before being applied toa specific task. There are some examples of pretext tasks used inself-supervised learning in the field of image recognition, namely rotationprediction, solving jigsaw puzzles, and predicting relative positions on image.Previous studies have only used one type of transformation as a pretext task.This raises the question of how it affects if more than one pretext task isused and to use a gating network to combine all pretext tasks. Therefore, wepropose the Gated Self-Supervised Learning method to improve imageclassification which use more than one transformation as pretext task and usesthe Mixture of Expert architecture as a gating network in combining eachpretext task so that the model automatically can study and focus more on themost useful augmentations for classification. We test performance of theproposed method in several scenarios, namely CIFAR imbalance datasetclassification, adversarial perturbations, Tiny-Imagenet datasetclassification, and semi-supervised learning. Moreover, there are Grad-CAM andT-SNE analysis that are used to see the proposed method for identifyingimportant features that influence image classification and representing datafor each class and separating different classes properly. Our code is inhttps://github.com/aristorenaldo/G-SSL</description><author>Aristo Renaldo Ruslim, Novanto Yudistira, Budi Darma Setiawan</author><pubDate>Thu, 27 Jul 2023 15:38:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14897v1</guid></item><item><title>Differential Privacy for Clustering Under Continual Observation</title><link>http://arxiv.org/abs/2307.03430v2</link><description>We consider the problem of clustering privately a dataset in $\mathbb{R}^d$that undergoes both insertion and deletion of points. Specifically, we give an$\varepsilon$-differentially private clustering mechanism for the $k$-meansobjective under continual observation. This is the first approximationalgorithm for that problem with an additive error that depends onlylogarithmically in the number $T$ of updates. The multiplicative error isalmost the same as non privately. To do so we show how to perform dimensionreduction under continual observation and combine it with a differentiallyprivate greedy approximation algorithm for $k$-means. We also partially extendour results to the $k$-median problem.</description><author>Max Dupré la Tour, Monika Henzinger, David Saulpic</author><pubDate>Thu, 27 Jul 2023 15:36:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.03430v2</guid></item><item><title>Base-based Model Checking for Multi-Agent Only Believing (long version)</title><link>http://arxiv.org/abs/2307.14893v1</link><description>We present a novel semantics for the language of multi-agent only believingexploiting belief bases, and show how to use it for automatically checkingformulas of this language and of its dynamic extension with private beliefexpansion operators. We provide a PSPACE algorithm for model checking relyingon a reduction to QBF and alternative dedicated algorithm relying on theexploration of the state space. We present an implementation of the QBF-basedalgorithm and some experimental results on computation time in a concreteexample.</description><author>Tiago de Lima, Emiliano Lorini, François Schwarzentruber</author><pubDate>Thu, 27 Jul 2023 15:35:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14893v1</guid></item><item><title>Weakly Supervised Multi-Modal 3D Human Body Pose Estimation for Autonomous Driving</title><link>http://arxiv.org/abs/2307.14889v1</link><description>Accurate 3D human pose estimation (3D HPE) is crucial for enabling autonomousvehicles (AVs) to make informed decisions and respond proactively in criticalroad scenarios. Promising results of 3D HPE have been gained in several domainssuch as human-computer interaction, robotics, sports and medical analytics,often based on data collected in well-controlled laboratory environments.Nevertheless, the transfer of 3D HPE methods to AVs has received limitedresearch attention, due to the challenges posed by obtaining accurate 3D poseannotations and the limited suitability of data from other domains. We present a simple yet efficient weakly supervised approach for 3D HPE inthe AV context by employing a high-level sensor fusion between camera and LiDARdata. The weakly supervised setting enables training on the target datasetswithout any 2D/3D keypoint labels by using an off-the-shelf 2D joint extractorand pseudo labels generated from LiDAR to image projections. Our approachoutperforms state-of-the-art results by up to $\sim$ 13% on the Waymo OpenDataset in the weakly supervised setting and achieves state-of-the-art resultsin the supervised setting.</description><author>Peter Bauer, Arij Bouazizi, Ulrich Kressel, Fabian B. Flohr</author><pubDate>Thu, 27 Jul 2023 15:28:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14889v1</guid></item><item><title>3D Semantic Subspace Traverser: Empowering 3D Generative Model with Shape Editing Capability</title><link>http://arxiv.org/abs/2307.14051v2</link><description>Shape generation is the practice of producing 3D shapes as variousrepresentations for 3D content creation. Previous studies on 3D shapegeneration have focused on shape quality and structure, without or lessconsidering the importance of semantic information. Consequently, suchgenerative models often fail to preserve the semantic consistency of shapestructure or enable manipulation of the semantic attributes of shapes duringgeneration. In this paper, we proposed a novel semantic generative model named3D Semantic Subspace Traverser that utilizes semantic attributes forcategory-specific 3D shape generation and editing. Our method utilizes implicitfunctions as the 3D shape representation and combines a novel latent-space GANwith a linear subspace model to discover semantic dimensions in the locallatent space of 3D shapes. Each dimension of the subspace corresponds to aparticular semantic attribute, and we can edit the attributes of generatedshapes by traversing the coefficients of those dimensions. Experimental resultsdemonstrate that our method can produce plausible shapes with complexstructures and enable the editing of semantic attributes. The code and trainedmodels are available athttps://github.com/TrepangCat/3D_Semantic_Subspace_Traverser</description><author>Ruowei Wang, Yu Liu, Pei Su, Jianwei Zhang, Qijun Zhao</author><pubDate>Thu, 27 Jul 2023 15:24:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14051v2</guid></item><item><title>MESED: A Multi-modal Entity Set Expansion Dataset with Fine-grained Semantic Classes and Hard Negative Entities</title><link>http://arxiv.org/abs/2307.14878v1</link><description>The Entity Set Expansion (ESE) task aims to expand a handful of seed entitieswith new entities belonging to the same semantic class. Conventional ESEmethods are based on mono-modality (i.e., literal modality), which struggle todeal with complex entities in the real world such as: (1) Negative entitieswith fine-grained semantic differences. (2) Synonymous entities. (3) Polysemousentities. (4) Long-tailed entities. These challenges prompt us to proposeMulti-modal Entity Set Expansion (MESE), where models integrate informationfrom multiple modalities to represent entities. Intuitively, the benefits ofmulti-modal information for ESE are threefold: (1) Different modalities canprovide complementary information. (2) Multi-modal information provides aunified signal via common visual properties for the same semantic class orentity. (3) Multi-modal information offers robust alignment signal forsynonymous entities. To assess the performance of model in MESE and facilitatefurther research, we constructed the MESED dataset which is the firstmulti-modal dataset for ESE with large-scale and elaborate manual calibration.A powerful multi-modal model MultiExpan is proposed which is pre-trained onfour multimodal pre-training tasks. The extensive experiments and analyses onMESED demonstrate the high quality of the dataset and the effectiveness of ourMultiExpan, as well as pointing the direction for future research.</description><author>Yangning Li, Tingwei Lu, Yinghui Li, Tianyu Yu, Shulin Huang, Hai-Tao Zheng, Rui Zhang, Jun Yuan</author><pubDate>Thu, 27 Jul 2023 15:09:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14878v1</guid></item><item><title>Analyzing Explainer Robustness via Lipschitzness of Prediction Functions</title><link>http://arxiv.org/abs/2206.12481v2</link><description>Machine learning methods have significantly improved in their predictivecapabilities, but at the same time they are becoming more complex and lesstransparent. As a result, explainers are often relied on to provideinterpretability to these black-box prediction models. As crucial diagnosticstools, it is important that these explainers themselves are robust. In thispaper we focus on one particular aspect of robustness, namely that an explainershould give similar explanations for similar data inputs. We formalize thisnotion by introducing and defining explainer astuteness, analogous toastuteness of prediction functions. Our formalism allows us to connectexplainer robustness to the predictor's probabilistic Lipschitzness, whichcaptures the probability of local smoothness of a function. We provide lowerbound guarantees on the astuteness of a variety of explainers (e.g., SHAP,RISE, CXPlain) given the Lipschitzness of the prediction function. Thesetheoretical results imply that locally smooth prediction functions lendthemselves to locally robust explanations. We evaluate these resultsempirically on simulated as well as real datasets.</description><author>Zulqarnain Khan, Davin Hill, Aria Masoomi, Joshua Bone, Jennifer Dy</author><pubDate>Thu, 27 Jul 2023 15:06:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.12481v2</guid></item><item><title>Unsupervised Low Light Image Enhancement Using SNR-Aware Swin Transformer</title><link>http://arxiv.org/abs/2306.02082v2</link><description>Image captured under low-light conditions presents unpleasing artifacts,which debilitate the performance of feature extraction for many upstream visualtasks. Low-light image enhancement aims at improving brightness and contrast,and further reducing noise that corrupts the visual quality. Recently, manyimage restoration methods based on Swin Transformer have been proposed andachieve impressive performance. However, on one hand, trivially employing SwinTransformer for low-light image enhancement would expose some artifacts,including over-exposure, brightness imbalance and noise corruption, etc. On theother hand, it is impractical to capture image pairs of low-light images andcorresponding ground-truth, i.e. well-exposed image in same visual scene. Inthis paper, we propose a dual-branch network based on Swin Transformer, guidedby a signal-to-noise ratio prior map which provides the spatial-varyinginformation for low-light image enhancement. Moreover, we leverage unsupervisedlearning to construct the optimization objective based on Retinex model, toguide the training of proposed network. Experimental results demonstrate thatthe proposed model is competitive with the baseline models.</description><author>Zhijian Luo, Jiahui Tang, Yueen Hou, Zihan Huang, Yanzeng Gao</author><pubDate>Thu, 27 Jul 2023 14:59:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02082v2</guid></item><item><title>Sample Less, Learn More: Efficient Action Recognition via Frame Feature Restoration</title><link>http://arxiv.org/abs/2307.14866v1</link><description>Training an effective video action recognition model poses significantcomputational challenges, particularly under limited resource budgets. Currentmethods primarily aim to either reduce model size or utilize pre-trainedmodels, limiting their adaptability to various backbone architectures. Thispaper investigates the issue of over-sampled frames, a prevalent problem inmany approaches yet it has received relatively little attention. Despite theuse of fewer frames being a potential solution, this approach often results ina substantial decline in performance. To address this issue, we propose a novelmethod to restore the intermediate features for two sparsely sampled andadjacent video frames. This feature restoration technique brings a negligibleincrease in computational requirements compared to resource-intensive imageencoders, such as ViT. To evaluate the effectiveness of our method, we conductextensive experiments on four public datasets, including Kinetics-400,ActivityNet, UCF-101, and HMDB-51. With the integration of our method, theefficiency of three commonly used baselines has been improved by over 50%, witha mere 0.5% reduction in recognition accuracy. In addition, our method alsosurprisingly helps improve the generalization ability of the models underzero-shot settings.</description><author>Harry Cheng, Yangyang Guo, Liqiang Nie, Zhiyong Cheng, Mohan Kankanhalli</author><pubDate>Thu, 27 Jul 2023 14:52:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14866v1</guid></item><item><title>A full-resolution training framework for Sentinel-2 image fusion</title><link>http://arxiv.org/abs/2307.14864v1</link><description>This work presents a new unsupervised framework for training deep learningmodels for super-resolution of Sentinel-2 images by fusion of its 10-m and 20-mbands. The proposed scheme avoids the resolution downgrade process needed togenerate training data in the supervised case. On the other hand, a proper lossthat accounts for cycle-consistency between the network prediction and theinput components to be fused is proposed. Despite its unsupervised nature, inour preliminary experiments the proposed scheme has shown promising results incomparison to the supervised approach. Besides, by construction of the proposedloss, the resulting trained network can be ascribed to the class ofmulti-resolution analysis methods.</description><author>Matteo Ciotola, Mario Ragosta, Giovanni Poggi, Giuseppe Scarpa</author><pubDate>Thu, 27 Jul 2023 14:50:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14864v1</guid></item><item><title>IML-ViT: Image Manipulation Localization by Vision Transformer</title><link>http://arxiv.org/abs/2307.14863v1</link><description>Advanced image tampering techniques are increasingly challenging thetrustworthiness of multimedia, leading to the development of Image ManipulationLocalization (IML). But what makes a good IML model? The answer lies in the wayto capture artifacts. Exploiting artifacts requires the model to extractnon-semantic discrepancies between the manipulated and authentic regions, whichneeds to compare differences between these two areas explicitly. With theself-attention mechanism, naturally, the Transformer is the best candidate.Besides, artifacts are sensitive to image resolution, amplified undermulti-scale features, and massive at the manipulation border. Therefore, weformulate the answer to the former question as building a ViT withhigh-resolution capacity, multi-scale feature extraction capability, andmanipulation edge supervision. We term this simple but effective ViT paradigmas the IML-ViT, which has great potential to become a new benchmark for IML.Extensive experiments on five benchmark datasets verified our model outperformsthe state-of-the-art manipulation localization methods. Code and models areavailable at \url{https://github.com/SunnyHaze/IML-ViT}</description><author>Xiaochen Ma, Bo Du, Xianggen Liu, Ahmed Y. Al Hammadi, Jizhe Zhou</author><pubDate>Thu, 27 Jul 2023 14:49:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14863v1</guid></item><item><title>AI Art Curation: Re-imagining the city of Helsinki in occasion of its Biennial</title><link>http://arxiv.org/abs/2306.03753v2</link><description>Art curatorial practice is characterized by the presentation of an artcollection in a knowledgeable way. Machine processes are characterized by theircapacity to manage and analyze large amounts of data. This paper envisages AIcuration and audience interaction to explore the implications of contemporarymachine learning models for the curatorial world. This project was developedfor the occasion of the 2023 Helsinki Art Biennial, entitled New Directions MayEmerge. We use the Helsinki Art Museum (HAM) collection to re-imagine the cityof Helsinki through the lens of machine perception. We use visual-textualmodels to place indoor artworks in public spaces, assigning fictionalcoordinates based on similarity scores. We transform the space that eachartwork inhabits in the city by generating synthetic 360 art panoramas. Weguide the generation estimating depth values from 360 panoramas at each artworklocation, and machine-generated prompts of the artworks. The result of thisproject is an AI curation that places the artworks in their imagined physicalspace, blurring the lines of artwork, context, and machine perception. The workis virtually presented as a web-based installation on this linkhttp://newlyformedcity.net/, where users can navigate an alternative version ofthe city while exploring and interacting with its cultural heritage at scale.</description><author>Ludovica Schaerf, Pepe Ballesteros, Valentine Bernasconi, Iacopo Neri, Dario Negueruela del Castillo</author><pubDate>Thu, 27 Jul 2023 14:45:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03753v2</guid></item><item><title>Comparative Evaluation of Digital and Analog Chest Radiographs to Identify Tuberculosis using Deep Learning Model</title><link>http://arxiv.org/abs/2307.14859v1</link><description>Purpose:Chest X-ray (CXR) is an essential tool and one of the most prescribedimaging to detect pulmonary abnormalities, with a yearly estimate of over 2billion imaging performed worldwide. However, the accurate and timely diagnosisof TB remains an unmet goal. The prevalence of TB is highest inlow-middle-income countries, and the requirement of a portable, automated, andreliable solution is required. In this study, we compared the performance ofDL-based devices on digital and analog CXR. The evaluated DL-based device canbe used in resource-constraint settings. Methods: A total of 10,000 CXRDICOMs(.dcm) and printed photos of the films acquired with three differentcellular phones - Samsung S8, iPhone 8, and iPhone XS along with theirradiological report were retrospectively collected from various sites acrossIndia from April 2020 to March 2021. Results: 10,000 chest X-rays were utilizedto evaluate the DL-based device in identifying radiological signs of TB. TheAUC of qXR for detecting signs of tuberculosis on the original DICOMs datasetwas 0.928 with a sensitivity of 0.841 at a specificity of 0.806. At an optimalthreshold, the difference in the AUC of three cellular smartphones with theoriginal DICOMs is 0.024 (2.55%), 0.048 (5.10%), and 0.038 (1.91%). The minimumdifference demonstrates the robustness of the DL-based device in identifyingradiological signs of TB in both digital and analog CXR.</description><author>Subhankar Chattoraj, Bhargava Reddy, Manoj Tadepalli, Preetham Putha</author><pubDate>Thu, 27 Jul 2023 14:44:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14859v1</guid></item><item><title>Generative convective parametrization of dry atmospheric boundary layer</title><link>http://arxiv.org/abs/2307.14857v1</link><description>Turbulence parametrizations will remain a necessary building block inkilometer-scale Earth system models. In convective boundary layers, where themean vertical gradients of conserved properties such as potential temperatureand moisture are approximately zero, the standard ansatz which relatesturbulent fluxes to mean vertical gradients via an eddy diffusivity has to beextended by mass flux parametrizations for the typically asymmetric up- anddowndrafts in the atmospheric boundary layer. In this work, we present aparametrization for a dry convective boundary layer based on a generativeadversarial network. The model incorporates the physics of self-similar layergrowth following from the classical mixed layer theory by Deardorff. Thisenhances the training data base of the generative machine learning algorithmand thus significantly improves the predicted statistics of the syntheticallygenerated turbulence fields at different heights inside the boundary layer. Thealgorithm training is based on fully three-dimensional direct numericalsimulation data. Differently to stochastic parametrizations, our model is ableto predict the highly non-Gaussian transient statistics of buoyancyfluctuations, vertical velocity, and buoyancy flux at different heights thusalso capturing the fastest thermals penetrating into the stabilized top region.The results of our generative algorithm agree with standard two-equation ormulti-plume stochastic mass-flux schemes. The present parametrization providesadditionally the granule-type horizontal organization of the turbulentconvection which cannot be obtained in any of the other model closures. Ourwork paves the way to efficient data-driven convective parametrizations inother natural flows, such as moist convection, upper ocean mixing, orconvection in stellar interiors.</description><author>Florian Heyder, Juan Pedro Mellado, Jörg Schumacher</author><pubDate>Thu, 27 Jul 2023 14:37:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14857v1</guid></item><item><title>Exploiting the Potential of Seq2Seq Models as Robust Few-Shot Learners</title><link>http://arxiv.org/abs/2307.14856v1</link><description>In-context learning, which offers substantial advantages over fine-tuning, ispredominantly observed in decoder-only models, while encoder-decoder (i.e.,seq2seq) models excel in methods that rely on weight updates. Recently, a fewstudies have demonstrated the feasibility of few-shot learning with seq2seqmodels; however, this has been limited to tasks that align well with theseq2seq architecture, such as summarization and translation. Inspired by theseinitial studies, we provide a first-ever extensive experiment comparing thein-context few-shot learning capabilities of decoder-only and encoder-decodermodels on a broad range of tasks. Furthermore, we propose two methods to moreeffectively elicit in-context learning ability in seq2seq models:objective-aligned prompting and a fusion-based approach. Remarkably, ourapproach outperforms a decoder-only model that is six times larger and exhibitssignificant performance improvements compared to conventional seq2seq modelsacross a variety of settings. We posit that, with the right configuration andprompt design, seq2seq models can be highly effective few-shot learners for awide spectrum of applications.</description><author>Jihyeon Lee, Dain Kim, Doohae Jung, Boseop Kim, Kyoung-Woon On</author><pubDate>Thu, 27 Jul 2023 14:37:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14856v1</guid></item><item><title>ArcGPT: A Large Language Model Tailored for Real-world Archival Applications</title><link>http://arxiv.org/abs/2307.14852v1</link><description>Archives play a crucial role in preserving information and knowledge, and theexponential growth of such data necessitates efficient and automated tools formanaging and utilizing archive information resources. Archival applicationsinvolve managing massive data that are challenging to process and analyze.Although LLMs have made remarkable progress in diverse domains, there are nopublicly available archives tailored LLM. Addressing this gap, we introduceArcGPT, to our knowledge, the first general-purpose LLM tailored to thearchival field. To enhance model performance on real-world archival tasks,ArcGPT has been pre-trained on massive and extensive archival domain data.Alongside ArcGPT, we release AMBLE, a benchmark comprising four real-worldarchival tasks. Evaluation on AMBLE shows that ArcGPT outperforms existingstate-of-the-art models, marking a substantial step forward in effectivearchival data management. Ultimately, ArcGPT aims to better serve the archivalcommunity, aiding archivists in their crucial role of preserving and harnessingour collective information and knowledge.</description><author>Shitou Zhang, Jingrui Hou, Siyuan Peng, Zuchao Li, Qibiao Hu, Ping Wang</author><pubDate>Thu, 27 Jul 2023 14:31:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14852v1</guid></item><item><title>Turkish Native Language Identification</title><link>http://arxiv.org/abs/2307.14850v1</link><description>In this paper, we present the first application of Native LanguageIdentification (NLI) for the Turkish language. NLI involves predicting thewriter's first language by analysing their writing in different languages.While most NLI research has focused on English, our study extends its scope toTurkish. We used the recently constructed Turkish Learner Corpus and employed acombination of three syntactic features (CFG production rules, part-of-speechn-grams and function words) with L2 texts to demonstrate their effectiveness inthis task.</description><author>Ahmet Yavuz Uluslu, Gerold Schneider</author><pubDate>Thu, 27 Jul 2023 14:28:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14850v1</guid></item><item><title>Counterfactual Explanations for Graph Classification Through the Lenses of Density</title><link>http://arxiv.org/abs/2307.14849v1</link><description>Counterfactual examples have emerged as an effective approach to producesimple and understandable post-hoc explanations. In the context of graphclassification, previous work has focused on generating counterfactualexplanations by manipulating the most elementary units of a graph, i.e.,removing an existing edge, or adding a non-existing one. In this paper, weclaim that such language of explanation might be too fine-grained, and turn ourattention to some of the main characterizing features of real-world complexnetworks, such as the tendency to close triangles, the existence of recurringmotifs, and the organization into dense modules. We thus define a generaldensity-based counterfactual search framework to generate instance-levelcounterfactual explanations for graph classifiers, which can be instantiatedwith different notions of dense substructures. In particular, we show twospecific instantiations of this general framework: a method that searches forcounterfactual graphs by opening or closing triangles, and a method driven bymaximal cliques. We also discuss how the general method can be instantiated toexploit any other notion of dense substructures, including, for instance, agiven taxonomy of nodes. We evaluate the effectiveness of our approaches in 7brain network datasets and compare the counterfactual statements generatedaccording to several widely-used metrics. Results confirm that adopting asemantic-relevant unit of change like density is essential to define versatileand interpretable counterfactual explanation methods.</description><author>Carlo Abrate, Giulia Preti, Francesco Bonchi</author><pubDate>Thu, 27 Jul 2023 14:28:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14849v1</guid></item><item><title>Kernelised Normalising Flows</title><link>http://arxiv.org/abs/2307.14839v1</link><description>Normalising Flows are generative models characterised by their invertiblearchitecture. However, the requirement of invertibility imposes constraints ontheir expressiveness, necessitating a large number of parameters and innovativearchitectural designs to achieve satisfactory outcomes. Whilst flow-basedmodels predominantly rely on neural-network-based transformations forexpressive designs, alternative transformation methods have received limitedattention. In this work, we present Ferumal flow, a novel kernelisednormalising flow paradigm that integrates kernels into the framework. Ourresults demonstrate that a kernelised flow can yield competitive or superiorresults compared to neural network-based flows whilst maintaining parameterefficiency. Kernelised flows excel especially in the low-data regime, enablingflexible non-parametric density estimation in applications with sparse dataavailability.</description><author>Eshant English, Matthias Kirchler, Christoph Lippert</author><pubDate>Thu, 27 Jul 2023 14:18:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14839v1</guid></item><item><title>Towards Out-Of-Distribution Generalization: A Survey</title><link>http://arxiv.org/abs/2108.13624v2</link><description>Traditional machine learning paradigms are based on the assumption that bothtraining and test data follow the same statistical pattern, which ismathematically referred to as Independent and Identically Distributed($i.i.d.$). However, in real-world applications, this $i.i.d.$ assumption oftenfails to hold due to unforeseen distributional shifts, leading to considerabledegradation in model performance upon deployment. This observed discrepancyindicates the significance of investigating the Out-of-Distribution (OOD)generalization problem. OOD generalization is an emerging topic of machinelearning research that focuses on complex scenarios wherein the distributionsof the test data differ from those of the training data. This paper representsthe first comprehensive, systematic review of OOD generalization, encompassinga spectrum of aspects from problem definition, methodological development, andevaluation procedures, to the implications and future directions of the field.Our discussion begins with a precise, formal characterization of the OODgeneralization problem. Following that, we categorize existing methodologiesinto three segments: unsupervised representation learning, supervised modellearning, and optimization, according to their positions within the overarchinglearning process. We provide an in-depth discussion on representativemethodologies for each category, further elucidating the theoretical linksbetween them. Subsequently, we outline the prevailing benchmark datasetsemployed in OOD generalization studies. To conclude, we overview the existingbody of work in this domain and suggest potential avenues for future researchon OOD generalization. A summary of the OOD generalization methodologiessurveyed in this paper can be accessed athttp://out-of-distribution-generalization.com.</description><author>Jiashuo Liu, Zheyan Shen, Yue He, Xingxuan Zhang, Renzhe Xu, Han Yu, Peng Cui</author><pubDate>Thu, 27 Jul 2023 14:13:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2108.13624v2</guid></item><item><title>Simplified Concrete Dropout -- Improving the Generation of Attribution Masks for Fine-grained Classification</title><link>http://arxiv.org/abs/2307.14825v1</link><description>Fine-grained classification is a particular case of a classification problem,aiming to classify objects that share the visual appearance and can only bedistinguished by subtle differences. Fine-grained classification models areoften deployed to determine animal species or individuals in automated animalmonitoring systems. Precise visual explanations of the model's decision arecrucial to analyze systematic errors. Attention- or gradient-based methods arecommonly used to identify regions in the image that contribute the most to theclassification decision. These methods deliver either too coarse or too noisyexplanations, unsuitable for identifying subtle visual differences reliably.However, perturbation-based methods can precisely identify pixels causallyresponsible for the classification result. Fill-in of the dropout (FIDO)algorithm is one of those methods. It utilizes the concrete dropout (CD) tosample a set of attribution masks and updates the sampling parameters based onthe output of the classification model. A known problem of the algorithm is ahigh variance in the gradient estimates, which the authors have mitigated untilnow by mini-batch updates of the sampling parameters. This paper presents asolution to circumvent these computational instabilities by simplifying the CDsampling and reducing reliance on large mini-batch sizes. First, it allowsestimating the parameters with smaller mini-batch sizes without losing thequality of the estimates but with a reduced computational effort. Furthermore,our solution produces finer and more coherent attribution masks. Finally, weuse the resulting attribution masks to improve the classification performanceof a trained model without additional fine-tuning of the model.</description><author>Dimitri Korsch, Maha Shadaydeh, Joachim Denzler</author><pubDate>Thu, 27 Jul 2023 14:01:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14825v1</guid></item><item><title>Fading memory as inductive bias in residual recurrent networks</title><link>http://arxiv.org/abs/2307.14823v1</link><description>Residual connections have been proposed as architecture-based inductive biasto mitigate the problem of exploding and vanishing gradients and increase taskperformance in both feed-forward and recurrent networks (RNNs) when trainedwith the backpropagation algorithm. Yet, little is known about how residualconnections in RNNs influence their dynamics and fading memory properties.Here, we introduce weakly coupled residual recurrent networks (WCRNNs) in whichresidual connections result in well-defined Lyapunov exponents and allow forstudying properties of fading memory. We investigate how the residualconnections of WCRNNs influence their performance, network dynamics, and memoryproperties on a set of benchmark tasks. We show that several distinct forms ofresidual connections yield effective inductive biases that result in increasednetwork expressivity. In particular, residual connections that (i) result innetwork dynamics at the proximity of the edge of chaos, (ii) allow networks tocapitalize on characteristic spectral properties of the data, and (iii) resultin heterogeneous memory properties are shown to increase practicalexpressivity. In addition, we demonstrate how our results can be extended tonon-linear residuals and introduce a weakly coupled residual initializationscheme that can be used for Elman RNNs</description><author>Igor Dubinin, Felix Effenberger</author><pubDate>Thu, 27 Jul 2023 14:00:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14823v1</guid></item><item><title>Evaluating Large Language Models for Radiology Natural Language Processing</title><link>http://arxiv.org/abs/2307.13693v2</link><description>The rise of large language models (LLMs) has marked a pivotal shift in thefield of natural language processing (NLP). LLMs have revolutionized amultitude of domains, and they have made a significant impact in the medicalfield. Large language models are now more abundant than ever, and many of thesemodels exhibit bilingual capabilities, proficient in both English and Chinese.However, a comprehensive evaluation of these models remains to be conducted.This lack of assessment is especially apparent within the context of radiologyNLP. This study seeks to bridge this gap by critically evaluating thirty twoLLMs in interpreting radiology reports, a crucial component of radiology NLP.Specifically, the ability to derive impressions from radiologic findings isassessed. The outcomes of this evaluation provide key insights into theperformance, strengths, and weaknesses of these LLMs, informing their practicalapplications within the medical domain.</description><author>Zhengliang Liu, Tianyang Zhong, Yiwei Li, Yutong Zhang, Yi Pan, Zihao Zhao, Peixin Dong, Chao Cao, Yuxiao Liu, Peng Shu, Yaonai Wei, Zihao Wu, Chong Ma, Jiaqi Wang, Sheng Wang, Mengyue Zhou, Zuowei Jiang, Chunlin Li, Jason Holmes, Shaochen Xu, Lu Zhang, Haixing Dai, Kai Zhang, Lin Zhao, Yuanhao Chen, Xu Liu, Peilong Wang, Pingkun Yan, Jun Liu, Bao Ge, Lichao Sun, Dajiang Zhu, Xiang Li, Wei Liu, Xiaoyan Cai, Xintao Hu, Xi Jiang, Shu Zhang, Xin Zhang, Tuo Zhang, Shijie Zhao, Quanzheng Li, Hongtu Zhu, Dinggang Shen, Tianming Liu</author><pubDate>Thu, 27 Jul 2023 13:58:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13693v2</guid></item><item><title>DiffFit: Unlocking Transferability of Large Diffusion Models via Simple Parameter-Efficient Fine-Tuning</title><link>http://arxiv.org/abs/2304.06648v6</link><description>Diffusion models have proven to be highly effective in generatinghigh-quality images. However, adapting large pre-trained diffusion models tonew domains remains an open challenge, which is critical for real-worldapplications. This paper proposes DiffFit, a parameter-efficient strategy tofine-tune large pre-trained diffusion models that enable fast adaptation to newdomains. DiffFit is embarrassingly simple that only fine-tunes the bias termand newly-added scaling factors in specific layers, yet resulting insignificant training speed-up and reduced model storage costs. Compared withfull fine-tuning, DiffFit achieves 2$\times$ training speed-up and only needsto store approximately 0.12\% of the total model parameters. Intuitivetheoretical analysis has been provided to justify the efficacy of scalingfactors on fast adaptation. On 8 downstream datasets, DiffFit achieves superioror competitive performances compared to the full fine-tuning while being moreefficient. Remarkably, we show that DiffFit can adapt a pre-trainedlow-resolution generative model to a high-resolution one by adding minimalcost. Among diffusion-based methods, DiffFit sets a new state-of-the-art FID of3.02 on ImageNet 512$\times$512 benchmark by fine-tuning only 25 epochs from apublic pre-trained ImageNet 256$\times$256 checkpoint while being 30$\times$more training efficient than the closest competitor.</description><author>Enze Xie, Lewei Yao, Han Shi, Zhili Liu, Daquan Zhou, Zhaoqiang Liu, Jiawei Li, Zhenguo Li</author><pubDate>Thu, 27 Jul 2023 13:57:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.06648v6</guid></item><item><title>What Makes a Good Paraphrase: Do Automated Evaluations Work?</title><link>http://arxiv.org/abs/2307.14818v1</link><description>Paraphrasing is the task of expressing an essential idea or meaning indifferent words. But how different should the words be in order to beconsidered an acceptable paraphrase? And can we exclusively use automatedmetrics to evaluate the quality of a paraphrase? We attempt to answer thesequestions by conducting experiments on a German data set and performingautomatic and expert linguistic evaluation.</description><author>Anna Moskvina, Bhushan Kotnis, Chris Catacata, Michael Janz, Nasrin Saef</author><pubDate>Thu, 27 Jul 2023 13:51:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14818v1</guid></item><item><title>Models of reference production: How do they withstand the test of time?</title><link>http://arxiv.org/abs/2307.14817v1</link><description>In recent years, many NLP studies have focused solely on performanceimprovement. In this work, we focus on the linguistic and scientific aspects ofNLP. We use the task of generating referring expressions in context(REG-in-context) as a case study and start our analysis from GREC, acomprehensive set of shared tasks in English that addressed this topic over adecade ago. We ask what the performance of models would be if we assessed them(1) on more realistic datasets, and (2) using more advanced methods. We testthe models using different evaluation metrics and feature selectionexperiments. We conclude that GREC can no longer be regarded as offering areliable assessment of models' ability to mimic human reference production,because the results are highly impacted by the choice of corpus and evaluationmetrics. Our results also suggest that pre-trained language models are lessdependent on the choice of corpus than classic Machine Learning models, andtherefore make more robust class predictions.</description><author>Fahime Same, Guanyi Chen, Kees van Deemter</author><pubDate>Thu, 27 Jul 2023 13:46:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14817v1</guid></item><item><title>Towards Regulated Deep Learning</title><link>http://arxiv.org/abs/1912.13122v7</link><description>Regulation of Multi-Agent Systems (MAS) and Declarative ElectronicInstitutions (DEIs) was a multidisciplinary research topic of the past decadeinvolving (Physical and Software) Agents and Law since the beginning, butrecently evolved towards News-claimed Robot Lawyer since 2016. One of thesefirst proposals of restricting the behaviour of Software Agents was ElectronicInstitutions.However, with the recent reformulation of Artificial NeuralNetworks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legalissues regarding the use of DL has raised concerns in the ArtificialIntelligence (AI) Community. Now that the Regulation of MAS is almost correctlyaddressed, we propose the Regulation of Artificial Neural Networks asAgent-based Training of a special type of regulated Artificial Neural Networkthat we call Institutional Neural Network (INN).The main purpose of this paperis to bring attention to Artificial Teaching (AT) and to give a tentativeanswer showing a proof-of-concept implementation of Regulated Deep Learning(RDL). This paper introduces the former concept and provide $I^*$, a languagepreviously used to model declaratively and extend Electronic Institutions, as ameans to regulate the execution of Artificial Neural Networks and theirinteractions with Artificial Teachers (ATs)</description><author>Andrés García-Camino</author><pubDate>Thu, 27 Jul 2023 13:22:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1912.13122v7</guid></item><item><title>Hybrid ASP-based multi-objective scheduling of semiconductor manufacturing processes (Extended version)</title><link>http://arxiv.org/abs/2307.14799v1</link><description>Modern semiconductor manufacturing involves intricate production processesconsisting of hundreds of operations, which can take several months from lotrelease to completion. The high-tech machines used in these processes arediverse, operate on individual wafers, lots, or batches in multiple stages, andnecessitate product-specific setups and specialized maintenance procedures.This situation is different from traditional job-shop scheduling scenarios,which have less complex production processes and machines, and mainly focus onsolving highly combinatorial but abstract scheduling problems. In this work, weaddress the scheduling of realistic semiconductor manufacturing processes bymodeling their specific requirements using hybrid Answer Set Programming withdifference logic, incorporating flexible machine processing, setup, batchingand maintenance operations. Unlike existing methods that schedule semiconductormanufacturing processes locally with greedy heuristics or by independentlyoptimizing specific machine group allocations, we examine the potentials oflarge-scale scheduling subject to multiple optimization objectives.</description><author>Mohammed M. S. El-Kholany, Ramsha Ali, Martin Gebser</author><pubDate>Thu, 27 Jul 2023 13:08:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14799v1</guid></item><item><title>Machine Learning with a Reject Option: A survey</title><link>http://arxiv.org/abs/2107.11277v2</link><description>Machine learning models always make a prediction, even when it is likely tobe inaccurate. This behavior should be avoided in many decision supportapplications, where mistakes can have severe consequences. Albeit alreadystudied in 1970, machine learning with rejection recently gained interest. Thismachine learning subfield enables machine learning models to abstain frommaking a prediction when likely to make a mistake. This survey aims to provide an overview on machine learning with rejection.We introduce the conditions leading to two types of rejection, ambiguity andnovelty rejection, which we carefully formalize. Moreover, we review andcategorize strategies to evaluate a model's predictive and rejective quality.Additionally, we define the existing architectures for models with rejectionand describe the standard techniques for learning such models. Finally, weprovide examples of relevant application domains and show how machine learningwith rejection relates to other machine learning research areas.</description><author>Kilian Hendrickx, Lorenzo Perini, Dries Van der Plas, Wannes Meert, Jesse Davis</author><pubDate>Thu, 27 Jul 2023 12:41:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.11277v2</guid></item><item><title>A Comprehensive Analysis on the Leakage of Fuzzy Matchers</title><link>http://arxiv.org/abs/2307.13717v2</link><description>This paper provides a comprehensive analysis of information leakage duringdistance evaluation, with an emphasis on threshold-based obfuscated distance(i.e., Fuzzy Matcher). Leakage can occur due to a malware infection or the useof a weakly privacy-preserving matcher, exemplified by side channel attacks orpartially obfuscated designs. We provide an exhaustive catalog of informationleakage scenarios as well as their impacts on the security concerning dataprivacy. Each of the scenarios leads to generic attacks whose impacts areexpressed in terms of computational costs, hence allowing the establishment ofupper bounds on the security level.</description><author>Axel Durbet, Paul-Marie Grollemund, Kevin Thiry-Atighehchi</author><pubDate>Thu, 27 Jul 2023 12:33:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13717v2</guid></item></channel></rss>