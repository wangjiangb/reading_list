<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 11 Oct 2023 06:00:19 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression</title><link>http://arxiv.org/abs/2310.06839v1</link><description>In long context scenarios, large language models (LLMs) face three mainchallenges: higher computational/financial cost, longer latency, and inferiorperformance. Some studies reveal that the performance of LLMs depends on boththe density and the position of the key information (question relevant) in theinput prompt. Inspired by these findings, we propose LongLLMLingua for promptcompression towards improving LLMs' perception of the key information tosimultaneously address the three challenges. We conduct evaluation on a widerange of long context scenarios including single-/multi-document QA, few-shotlearning, summarization, synthetic tasks, and code completion. The experimentalresults show that LongLLMLingua compressed prompt can derive higher performancewith much less cost. The latency of the end-to-end system is also reduced. Forexample, on NaturalQuestions benchmark, LongLLMLingua gains a performance boostof up to 17.1% over the original prompt with ~4x fewer tokens as input toGPT-3.5-Turbo. It can derive cost savings of \$28.5 and \$27.4 per 1,000samples from the LongBench and ZeroScrolls benchmark, respectively.Additionally, when compressing prompts of ~10k tokens at a compression rate of2x-10x, LongLLMLingua can speed up the end-to-end latency by 1.4x-3.8x. Ourcode is available at https://aka.ms/LLMLingua.</description><author>Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng Li, Chin-Yew Lin, Yuqing Yang, Lili Qiu</author><pubDate>Tue, 10 Oct 2023 18:59:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06839v1</guid></item><item><title>AutoAD II: The Sequel -- Who, When, and What in Movie Audio Description</title><link>http://arxiv.org/abs/2310.06838v1</link><description>Audio Description (AD) is the task of generating descriptions of visualcontent, at suitable time intervals, for the benefit of visually impairedaudiences. For movies, this presents notable challenges -- AD must occur onlyduring existing pauses in dialogue, should refer to characters by name, andought to aid understanding of the storyline as a whole. To this end, we developa new model for automatically generating movie AD, given CLIP visual featuresof the frames, the cast list, and the temporal locations of the speech;addressing all three of the 'who', 'when', and 'what' questions: (i) who -- weintroduce a character bank consisting of the character's name, the actor thatplayed the part, and a CLIP feature of their face, for the principal cast ofeach movie, and demonstrate how this can be used to improve naming in thegenerated AD; (ii) when -- we investigate several models for determiningwhether an AD should be generated for a time interval or not, based on thevisual content of the interval and its neighbours; and (iii) what -- weimplement a new vision-language model for this task, that can ingest theproposals from the character bank, whilst conditioning on the visual featuresusing cross-attention, and demonstrate how this improves over previousarchitectures for AD text generation in an apples-to-apples comparison.</description><author>Tengda Han, Max Bain, Arsha Nagrani, GÃ¼l Varol, Weidi Xie, Andrew Zisserman</author><pubDate>Tue, 10 Oct 2023 18:59:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06838v1</guid></item><item><title>Generating and Evaluating Tests for K-12 Students with Language Model Simulations: A Case Study on Sentence Reading Efficiency</title><link>http://arxiv.org/abs/2310.06837v1</link><description>Developing an educational test can be expensive and time-consuming, as eachitem must be written by experts and then evaluated by collecting hundreds ofstudent responses. Moreover, many tests require multiple distinct sets ofquestions administered throughout the school year to closely monitor students'progress, known as parallel tests. In this study, we focus on tests of silentsentence reading efficiency, used to assess students' reading ability overtime. To generate high-quality parallel tests, we propose to fine-tune largelanguage models (LLMs) to simulate how previous students would have respondedto unseen items. With these simulated responses, we can estimate each item'sdifficulty and ambiguity. We first use GPT-4 to generate new test itemsfollowing a list of expert-developed rules and then apply a fine-tuned LLM tofilter the items based on criteria from psychological measurements. We alsopropose an optimal-transport-inspired technique for generating parallel testsand show the generated tests closely correspond to the original test'sdifficulty and reliability based on crowdworker responses. Our evaluation of agenerated test with 234 students from grades 2 to 8 produces test scores highlycorrelated (r=0.93) to those of a standard test form written by human expertsand evaluated across thousands of K-12 students.</description><author>Eric Zelikman, Wanjing Anya Ma, Jasmine E. Tran, Diyi Yang, Jason D. Yeatman, Nick Haber</author><pubDate>Tue, 10 Oct 2023 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06837v1</guid></item><item><title>What Does Stable Diffusion Know about the 3D Scene?</title><link>http://arxiv.org/abs/2310.06836v1</link><description>Recent advances in generative models like Stable Diffusion enable thegeneration of highly photo-realistic images. Our objective in this paper is toprobe the diffusion network to determine to what extent it 'understands'different properties of the 3D scene depicted in an image. To this end, we makethe following contributions: (i) We introduce a protocol to evaluate whether anetwork models a number of physical 'properties' of the 3D scene by probing forexplicit features that represent these properties. The probes are applied ondatasets of real images with annotations for the property. (ii) We apply thisprotocol to properties covering scene geometry, scene material, supportrelations, lighting, and view dependent measures. (iii) We find that StableDiffusion is good at a number of properties including scene geometry, supportrelations, shadows and depth, but less performant for occlusion. (iv) We alsoapply the probes to other models trained at large-scale, including DINO andCLIP, and find their performance inferior to that of Stable Diffusion.</description><author>Guanqi Zhan, Chuanxia Zheng, Weidi Xie, Andrew Zisserman</author><pubDate>Tue, 10 Oct 2023 18:59:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06836v1</guid></item><item><title>Scalable Semantic Non-Markovian Simulation Proxy for Reinforcement Learning</title><link>http://arxiv.org/abs/2310.06835v1</link><description>Recent advances in reinforcement learning (RL) have shown much promise acrossa variety of applications. However, issues such as scalability, explainability,and Markovian assumptions limit its applicability in certain domains. Weobserve that many of these shortcomings emanate from the simulator as opposedto the RL training algorithms themselves. As such, we propose a semantic proxyfor simulation based on a temporal extension to annotated logic. In comparisonwith two high-fidelity simulators, we show up to three orders of magnitudespeed-up while preserving the quality of policy learned in addition to showingthe ability to model and leverage non-Markovian dynamics and instantaneousactions while providing an explainable trace describing the outcomes of theagent actions.</description><author>Kaustuv Mukherji, Devendra Parkar, Lahari Pokala, Dyuman Aditya, Paulo Shakarian, Clark Dorman</author><pubDate>Tue, 10 Oct 2023 18:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06835v1</guid></item><item><title>Lemur: Harmonizing Natural Language and Code for Language Agents</title><link>http://arxiv.org/abs/2310.06830v1</link><description>We introduce Lemur and Lemur-Chat, openly accessible language modelsoptimized for both natural language and coding capabilities to serve as thebackbone of versatile language agents. The evolution from language chat modelsto functional language agents demands that models not only master humaninteraction, reasoning, and planning but also ensure grounding in the relevantenvironments. This calls for a harmonious blend of language and codingcapabilities in the models. Lemur and Lemur-Chat are proposed to address thisnecessity, demonstrating balanced proficiencies in both domains, unlikeexisting open-source models that tend to specialize in either. Throughmeticulous pre-training using a code-intensive corpus and instructionfine-tuning on text and code data, our models achieve state-of-the-art averagedperformance across diverse text and coding benchmarks among open-source models.Comprehensive experiments demonstrate Lemur's superiority over existingopen-source models and its proficiency across various agent tasks involvinghuman communication, tool usage, and interaction under fully- and partially-observable environments. The harmonization between natural and programminglanguages enables Lemur-Chat to significantly narrow the gap with proprietarymodels on agent abilities, providing key insights into developing advancedopen-source agents adept at reasoning, planning, and operating seamlesslyacross environments. https://github.com/OpenLemur/Lemur</description><author>Yiheng Xu, Hongjin Su, Chen Xing, Boyu Mi, Qian Liu, Weijia Shi, Binyuan Hui, Fan Zhou, Yitao Liu, Tianbao Xie, Zhoujun Cheng, Siheng Zhao, Lingpeng Kong, Bailin Wang, Caiming Xiong, Tao Yu</author><pubDate>Tue, 10 Oct 2023 18:57:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06830v1</guid></item><item><title>Teaching Language Models to Hallucinate Less with Synthetic Tasks</title><link>http://arxiv.org/abs/2310.06827v1</link><description>Large language models (LLMs) frequently hallucinate on abstractivesummarization tasks such as document-based question-answering, meetingsummarization, and clinical report generation, even though all necessaryinformation is included in context. However, optimizing LLMs to hallucinateless on these tasks is challenging, as hallucination is hard to efficientlyevaluate at each optimization step. In this work, we show that reducinghallucination on a synthetic task can also reduce hallucination on real-worlddownstream tasks. Our method, SynTra, first designs a synthetic task wherehallucinations are easy to elicit and measure. It next optimizes the LLM'ssystem message via prefix-tuning on the synthetic task, and finally transfersthe system message to realistic, hard-to-optimize tasks. Across three realisticabstractive summarization tasks, SynTra reduces hallucination for two13B-parameter LLMs using only a synthetic retrieval task for supervision. Wealso find that optimizing the system message rather than the model weights canbe critical; fine-tuning the entire model on the synthetic task cancounterintuitively increase hallucination. Overall, SynTra demonstrates thatthe extra flexibility of working with synthetic data can help mitigateundesired behaviors in practice.</description><author>Erik Jones, Hamid Palangi, Clarisse SimÃµes, Varun Chandrasekaran, Subhabrata Mukherjee, Arindam Mitra, Ahmed Awadallah, Ece Kamar</author><pubDate>Tue, 10 Oct 2023 18:57:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06827v1</guid></item><item><title>Mistral 7B</title><link>http://arxiv.org/abs/2310.06825v1</link><description>We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineeredfor superior performance and efficiency. Mistral 7B outperforms Llama 2 13Bacross all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, andcode generation. Our model leverages grouped-query attention (GQA) for fasterinference, coupled with sliding window attention (SWA) to effectively handlesequences of arbitrary length with a reduced inference cost. We also provide amodel fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpassesthe Llama 2 13B -- Chat model both on human and automated benchmarks. Ourmodels are released under the Apache 2.0 license.</description><author>Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, LÃ©lio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, TimothÃ©e Lacroix, William El Sayed</author><pubDate>Tue, 10 Oct 2023 18:54:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06825v1</guid></item><item><title>The Geometry of Truth: Emergent Linear Structure in Large Language Model Representations of True/False Datasets</title><link>http://arxiv.org/abs/2310.06824v1</link><description>Large Language Models (LLMs) have impressive capabilities, but are also proneto outputting falsehoods. Recent work has developed techniques for inferringwhether a LLM is telling the truth by training probes on the LLM's internalactivations. However, this line of work is controversial, with some authorspointing out failures of these probes to generalize in basic ways, among otherconceptual issues. In this work, we curate high-quality datasets of true/falsestatements and use them to study in detail the structure of LLM representationsof truth, drawing on three lines of evidence: 1. Visualizations of LLMtrue/false statement representations, which reveal clear linear structure. 2.Transfer experiments in which probes trained on one dataset generalize todifferent datasets. 3. Causal evidence obtained by surgically intervening in aLLM's forward pass, causing it to treat false statements as true and viceversa. Overall, we present evidence that language models linearly represent thetruth or falsehood of factual statements. We also introduce a novel technique,mass-mean probing, which generalizes better and is more causally implicated inmodel outputs than other probing techniques.</description><author>Samuel Marks, Max Tegmark</author><pubDate>Tue, 10 Oct 2023 18:54:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06824v1</guid></item><item><title>NECO: NEural Collapse Based Out-of-distribution detection</title><link>http://arxiv.org/abs/2310.06823v1</link><description>Detecting out-of-distribution (OOD) data is a critical challenge in machinelearning due to model overconfidence, often without awareness of theirepistemological limits. We hypothesize that ``neural collapse'', a phenomenonaffecting in-distribution data for models trained beyond loss convergence, alsoinfluences OOD data. To benefit from this interplay, we introduce NECO, a novelpost-hoc method for OOD detection, which leverages the geometric properties of``neural collapse'' and of principal component spaces to identify OOD data. Ourextensive experiments demonstrate that NECO achieves state-of-the-art resultson both small and large-scale OOD detection tasks while exhibiting stronggeneralization capabilities across different network architectures.Furthermore, we provide a theoretical explanation for the effectiveness of ourmethod in OOD detection. We plan to release the code after the anonymityperiod.</description><author>MouÃ¯n Ben Ammar, Nacim Belkhir, Sebastian Popescu, Antoine Manzanera, Gianni Franchi</author><pubDate>Tue, 10 Oct 2023 18:53:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06823v1</guid></item><item><title>Neural Bounding</title><link>http://arxiv.org/abs/2310.06822v1</link><description>Bounding volumes are an established concept in computer graphics and visiontasks but have seen little change since their early inception. In this work, westudy the use of neural networks as bounding volumes. Our key observation isthat bounding, which so far has primarily been considered a problem ofcomputational geometry, can be redefined as a problem of learning to classifyspace into free and empty. This learning-based approach is particularlyadvantageous in high-dimensional spaces, such as animated scenes with complexqueries, where neural networks are known to excel. However, unlocking neuralbounding requires a twist: allowing -- but also limiting -- false positives,while ensuring that the number of false negatives is strictly zero. We enablesuch tight and conservative results using a dynamically-weighted asymmetricloss function. Our results show that our neural bounding produces up to anorder of magnitude fewer false positives than traditional methods.</description><author>Wenxin Liu, Michael Fischer, Paul D. Yoo, Tobias Ritschel</author><pubDate>Tue, 10 Oct 2023 18:50:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06822v1</guid></item><item><title>LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models</title><link>http://arxiv.org/abs/2305.13655v2</link><description>Recent advancements in text-to-image diffusion models have yielded impressiveresults in generating realistic and diverse images. However, these models stillstruggle with complex prompts, such as those that involve numeracy and spatialreasoning. This work proposes to enhance prompt understanding capabilities indiffusion models. Our method leverages a pretrained large language model (LLM)for grounded generation in a novel two-stage process. In the first stage, theLLM generates a scene layout that comprises captioned bounding boxes from agiven prompt describing the desired image. In the second stage, a novelcontroller guides an off-the-shelf diffusion model for layout-grounded imagegeneration. Both stages utilize existing pretrained models without additionalmodel parameter optimization. Our method significantly outperforms the basediffusion model and several strong baselines in accurately generating imagesaccording to prompts that require various capabilities, doubling the generationaccuracy across four tasks on average. Furthermore, our method enablesinstruction-based multi-round scene specification and can handle prompts inlanguages not supported by the underlying diffusion model. We anticipate thatour method will unleash users' creativity by accurately following more complexprompts.</description><author>Long Lian, Boyi Li, Adam Yala, Trevor Darrell</author><pubDate>Tue, 10 Oct 2023 18:46:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13655v2</guid></item><item><title>Text Embeddings Reveal (Almost) As Much As Text</title><link>http://arxiv.org/abs/2310.06816v1</link><description>How much private information do text embeddings reveal about the originaltext? We investigate the problem of embedding \textit{inversion},reconstructing the full text represented in dense text embeddings. We frame theproblem as controlled generation: generating text that, when reembedded, isclose to a fixed point in latent space. We find that although a na\"ive modelconditioned on the embedding performs poorly, a multi-step method thatiteratively corrects and re-embeds text is able to recover $92\%$ of$32\text{-token}$ text inputs exactly. We train our model to decode textembeddings from two state-of-the-art embedding models, and also show that ourmodel can recover important personal information (full names) from a dataset ofclinical notes. Our code is available on Github:\href{https://github.com/jxmorris12/vec2text}{github.com/jxmorris12/vec2text}.</description><author>John X. Morris, Volodymyr Kuleshov, Vitaly Shmatikov, Alexander M. Rush</author><pubDate>Tue, 10 Oct 2023 18:39:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06816v1</guid></item><item><title>Can ChatGPT Defend its Belief in Truth? Evaluating LLM Reasoning via Debate</title><link>http://arxiv.org/abs/2305.13160v2</link><description>Large language models (LLMs) such as ChatGPT and GPT-4 have shown impressiveperformance in complex reasoning tasks. However, it is difficult to knowwhether the models are reasoning based on deep understandings of truth andlogic, or leveraging their memorized patterns in a relatively superficial way.In this work, we explore testing LLMs' reasoning by engaging with them in adebate-like conversation, where given a question, the LLM and the user need todiscuss to make the correct decision starting from opposing arguments. Uponmitigating the Clever Hans effect, our task requires the LLM to not onlyachieve the correct answer on its own, but also be able to hold and defend itsbelief instead of blindly believing or getting misled by the user's (invalid)arguments and critiques, thus testing in greater depth whether the LLM graspsthe essence of the reasoning required to solve the problem. Across a range ofcomplex reasoning benchmarks spanning math, commonsense, logic and BIG-Benchtasks, we find that despite their impressive performance as reported inexisting work on generating correct step-by-step solutions in the beginning,LLMs like ChatGPT cannot maintain their beliefs in truth for a significantportion of examples when challenged by oftentimes absurdly invalid arguments.Our work points to danger zones of model alignment, and also suggests morecareful treatments and interpretations of the recent findings that LLMs canimprove their responses based on feedback.</description><author>Boshi Wang, Xiang Yue, Huan Sun</author><pubDate>Tue, 10 Oct 2023 18:34:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.13160v2</guid></item><item><title>NEFTune: Noisy Embeddings Improve Instruction Finetuning</title><link>http://arxiv.org/abs/2310.05914v2</link><description>We show that language model finetuning can be improved, sometimesdramatically, with a simple augmentation. NEFTune adds noise to the embeddingvectors during training. Standard finetuning of LLaMA-2-7B using Alpacaachieves 29.79% on AlpacaEval, which rises to 64.69% using noisy embeddings.NEFTune also improves over strong baselines on modern instruction datasets.Models trained with Evol-Instruct see a 10% improvement, with ShareGPT an 8%improvement, and with OpenPlatypus an 8% improvement. Even powerful modelsfurther refined with RLHF such as LLaMA-2-Chat benefit from additional trainingwith NEFTune.</description><author>Neel Jain, Ping-yeh Chiang, Yuxin Wen, John Kirchenbauer, Hong-Min Chu, Gowthami Somepalli, Brian R. Bartoldson, Bhavya Kailkhura, Avi Schwarzschild, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein</author><pubDate>Tue, 10 Oct 2023 18:31:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05914v2</guid></item><item><title>GPT-MolBERTa: GPT Molecular Features Language Model for molecular property prediction</title><link>http://arxiv.org/abs/2310.03030v3</link><description>With the emergence of Transformer architectures and their powerfulunderstanding of textual data, a new horizon has opened up to predict themolecular properties based on text description. While SMILES are the mostcommon form of representation, they are lacking robustness, rich informationand canonicity, which limit their effectiveness in becoming generalizablerepresentations. Here, we present GPT-MolBERTa, a self-supervised largelanguage model (LLM) which uses detailed textual descriptions of molecules topredict their properties. A text based description of 326000 molecules werecollected using ChatGPT and used to train LLM to learn the representation ofmolecules. To predict the properties for the downstream tasks, both BERT andRoBERTa models were used in the finetuning stage. Experiments show thatGPT-MolBERTa performs well on various molecule property benchmarks, andapproaching state of the art performance in regression tasks. Additionally,further analysis of the attention mechanisms show that GPT-MolBERTa is able topick up important information from the input textual data, displaying theinterpretability of the model.</description><author>Suryanarayanan Balaji, Rishikesh Magar, Yayati Jadhav, Amir Barati Farimani</author><pubDate>Tue, 10 Oct 2023 18:30:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03030v3</guid></item><item><title>Utilizing Longitudinal Chest X-Rays and Reports to Pre-Fill Radiology Reports</title><link>http://arxiv.org/abs/2306.08749v2</link><description>Despite the reduction in turn-around times in radiology reports with the useof speech recognition software, persistent communication errors cansignificantly impact the interpretation of the radiology report. Pre-filling aradiology report holds promise in mitigating reporting errors, and despiteefforts in the literature to generate medical reports, there exists a lack ofapproaches that exploit the longitudinal nature of patient visit records in theMIMIC-CXR dataset. To address this gap, we propose to use longitudinalmulti-modal data, i.e., previous patient visit CXR, current visit CXR, andprevious visit report, to pre-fill the 'findings' section of a current patientvisit report. We first gathered the longitudinal visit information for 26,625patients from the MIMIC-CXR dataset and created a new dataset calledLongitudinal-MIMIC. With this new dataset, a transformer-based model wastrained to capture the information from longitudinal patient visit recordscontaining multi-modal data (CXR images + reports) via a cross-attention-basedmulti-modal fusion module and a hierarchical memory-driven decoder. In contrastto previous work that only uses current visit data as input to train a model,our work exploits the longitudinal information available to pre-fill the'findings' section of radiology reports. Experiments show that our approachoutperforms several recent approaches. Code will be published athttps://github.com/CelestialShine/Longitudinal-Chest-X-Ray.</description><author>Qingqing Zhu, Tejas Sudharshan Mathai, Pritam Mukherjee, Yifan Peng, Ronald M. Summers, Zhiyong Lu</author><pubDate>Tue, 10 Oct 2023 18:29:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08749v2</guid></item><item><title>A Review of Deep Learning-based Approaches for Deepfake Content Detection</title><link>http://arxiv.org/abs/2202.06095v2</link><description>Recent advancements in deep learning generative models have raised concernsas they can create highly convincing counterfeit images and videos. This posesa threat to people's integrity and can lead to social instability. To addressthis issue, there is a pressing need to develop new computational models thatcan efficiently detect forged content and alert users to potential image andvideo manipulations. This paper presents a comprehensive review of recentstudies for deepfake content detection using deep learning-based approaches. Weaim to broaden the state-of-the-art research by systematically reviewing thedifferent categories of fake content detection. Furthermore, we report theadvantages and drawbacks of the examined works and future directions towardsthe issues and shortcomings still unsolved on deepfake detection.</description><author>Leandro A. Passos, Danilo Jodas, Kelton A. P. da Costa, Luis A. Souza JÃºnior, Douglas Rodrigues, Javier Del Ser, David Camacho, JoÃ£o Paulo Papa</author><pubDate>Tue, 10 Oct 2023 18:27:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.06095v2</guid></item><item><title>Advancing Transformer's Capabilities in Commonsense Reasoning</title><link>http://arxiv.org/abs/2310.06803v1</link><description>Recent advances in general purpose pre-trained language models have showngreat potential in commonsense reasoning. However, current works still performpoorly on standard commonsense reasoning benchmarks including the Com2SenseDataset. We argue that this is due to a disconnect with current cutting-edgemachine learning methods. In this work, we aim to bridge the gap by introducingcurrent ML-based methods to improve general purpose pre-trained language modelsin the task of commonsense reasoning. Specifically, we experiment with andsystematically evaluate methods including knowledge transfer, model ensemble,and introducing an additional pairwise contrastive objective. Our best modeloutperforms the strongest previous works by ~15\% absolute gains in PairwiseAccuracy and ~8.7\% absolute gains in Standard Accuracy.</description><author>Yu Zhou, Yunqiu Han, Hanyu Zhou, Yulun Wu</author><pubDate>Tue, 10 Oct 2023 18:21:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06803v1</guid></item><item><title>Segment Anything Model (SAM) Enhanced Pseudo Labels for Weakly Supervised Semantic Segmentation</title><link>http://arxiv.org/abs/2305.05803v2</link><description>Weakly supervised semantic segmentation (WSSS) aims to bypass the need forlaborious pixel-level annotation by using only image-level annotation. Mostexisting methods rely on Class Activation Maps (CAM) to derive pixel-levelpseudo-labels and use them to train a fully supervised semantic segmentationmodel. Although these pseudo-labels are class-aware, indicating the coarseregions for particular classes, they are not object-aware and fail to delineateaccurate object boundaries. To address this, we introduce a simple yeteffective method harnessing the Segment Anything Model (SAM), a class-agnosticfoundation model capable of producing fine-grained instance masks of objects,parts, and subparts. We use CAM pseudo-labels as cues to select and combine SAMmasks, resulting in high-quality pseudo-labels that are both class-aware andobject-aware. Our approach is highly versatile and can be easily integratedinto existing WSSS methods without any modification. Despite its simplicity,our approach shows consistent gain over the state-of-the-art WSSS methods onboth PASCAL VOC and MS-COCO datasets.</description><author>Tianle Chen, Zheda Mai, Ruiwen Li, Wei-lun Chao</author><pubDate>Tue, 10 Oct 2023 18:13:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05803v2</guid></item><item><title>Inverse Factorized Q-Learning for Cooperative Multi-agent Imitation Learning</title><link>http://arxiv.org/abs/2310.06801v1</link><description>This paper concerns imitation learning (IL) (i.e, the problem of learning tomimic expert behaviors from demonstrations) in cooperative multi-agent systems.The learning problem under consideration poses several challenges,characterized by high-dimensional state and action spaces and intricateinter-agent dependencies. In a single-agent setting, IL has proven to be doneefficiently through an inverse soft-Q learning process given expertdemonstrations. However, extending this framework to a multi-agent contextintroduces the need to simultaneously learn both local value functions tocapture local observations and individual actions, and a joint value functionfor exploiting centralized learning. In this work, we introduce a novelmulti-agent IL algorithm designed to address these challenges. Our approachenables the centralized learning by leveraging mixing networks to aggregatedecentralized Q functions. A main advantage of this approach is that theweights of the mixing networks can be trained using information derived fromglobal states. We further establish conditions for the mixing networks underwhich the multi-agent objective function exhibits convexity within the Qfunction space. We present extensive experiments conducted on some challengingcompetitive and cooperative multi-agent game environments, including anadvanced version of the Star-Craft multi-agent challenge (i.e., SMACv2), whichdemonstrates the effectiveness of our proposed algorithm compared to existingstate-of-the-art multi-agent IL algorithms.</description><author>The Viet Bui, Tien Mai, Thanh Hong Nguyen</author><pubDate>Tue, 10 Oct 2023 18:11:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06801v1</guid></item><item><title>Test &amp; Evaluation Best Practices for Machine Learning-Enabled Systems</title><link>http://arxiv.org/abs/2310.06800v1</link><description>Machine learning (ML) - based software systems are rapidly gaining adoptionacross various domains, making it increasingly essential to ensure they performas intended. This report presents best practices for the Test and Evaluation(T&amp;E) of ML-enabled software systems across its lifecycle. We categorize thelifecycle of ML-enabled software systems into three stages: component,integration and deployment, and post-deployment. At the component level, theprimary objective is to test and evaluate the ML model as a standalonecomponent. Next, in the integration and deployment stage, the goal is toevaluate an integrated ML-enabled system consisting of both ML and non-MLcomponents. Finally, once the ML-enabled software system is deployed andoperationalized, the T&amp;E objective is to ensure the system performs asintended. Maintenance activities for ML-enabled software systems span thelifecycle and involve maintaining various assets of ML-enabled softwaresystems. Given its unique characteristics, the T&amp;E of ML-enabled software systems ischallenging. While significant research has been reported on T&amp;E at thecomponent level, limited work is reported on T&amp;E in the remaining two stages.Furthermore, in many cases, there is a lack of systematic T&amp;E strategiesthroughout the ML-enabled system's lifecycle. This leads practitioners toresort to ad-hoc T&amp;E practices, which can undermine user confidence in thereliability of ML-enabled software systems. New systematic testing approaches,adequacy measurements, and metrics are required to address the T&amp;E challengesacross all stages of the ML-enabled system lifecycle.</description><author>Jaganmohan Chandrasekaran, Tyler Cody, Nicola McCarthy, Erin Lanus, Laura Freeman</author><pubDate>Tue, 10 Oct 2023 18:11:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06800v1</guid></item><item><title>$f$-Policy Gradients: A General Framework for Goal Conditioned RL using $f$-Divergences</title><link>http://arxiv.org/abs/2310.06794v1</link><description>Goal-Conditioned Reinforcement Learning (RL) problems often have access tosparse rewards where the agent receives a reward signal only when it hasachieved the goal, making policy optimization a difficult problem. Severalworks augment this sparse reward with a learned dense reward function, but thiscan lead to sub-optimal policies if the reward is misaligned. Moreover, recentworks have demonstrated that effective shaping rewards for a particular problemcan depend on the underlying learning algorithm. This paper introduces a novelway to encourage exploration called $f$-Policy Gradients, or $f$-PG. $f$-PGminimizes the f-divergence between the agent's state visitation distributionand the goal, which we show can lead to an optimal policy. We derive gradientsfor various f-divergences to optimize this objective. Our learning paradigmprovides dense learning signals for exploration in sparse reward settings. Wefurther introduce an entropy-regularized policy optimization objective, that wecall $state$-MaxEnt RL (or $s$-MaxEnt RL) as a special case of our objective.We show that several metric-based shaping rewards like L2 can be used with$s$-MaxEnt RL, providing a common ground to study such metric-based shapingrewards with efficient exploration. We find that $f$-PG has better performancecompared to standard policy gradient methods on a challenging gridworld as wellas the Point Maze and FetchReach environments. More information on our websitehttps://agarwalsiddhant10.github.io/projects/fpg.html.</description><author>Siddhant Agarwal, Ishan Durugkar, Peter Stone, Amy Zhang</author><pubDate>Tue, 10 Oct 2023 18:07:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06794v1</guid></item><item><title>Spectral Entry-wise Matrix Estimation for Low-Rank Reinforcement Learning</title><link>http://arxiv.org/abs/2310.06793v1</link><description>We study matrix estimation problems arising in reinforcement learning (RL)with low-rank structure. In low-rank bandits, the matrix to be recoveredspecifies the expected arm rewards, and for low-rank Markov Decision Processes(MDPs), it may for example characterize the transition kernel of the MDP. Inboth cases, each entry of the matrix carries important information, and we seekestimation methods with low entry-wise error. Importantly, these methodsfurther need to accommodate for inherent correlations in the available data(e.g. for MDPs, the data consists of system trajectories). We investigate theperformance of simple spectral-based matrix estimation approaches: we show thatthey efficiently recover the singular subspaces of the matrix and exhibitnearly-minimal entry-wise error. These new results on low-rank matrixestimation make it possible to devise reinforcement learning algorithms thatfully exploit the underlying low-rank structure. We provide two examples ofsuch algorithms: a regret minimization algorithm for low-rank bandit problems,and a best policy identification algorithm for reward-free RL in low-rank MDPs.Both algorithms yield state-of-the-art performance guarantees.</description><author>Stefan Stojanovic, Yassir Jedra, Alexandre Proutiere</author><pubDate>Tue, 10 Oct 2023 18:06:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06793v1</guid></item><item><title>Dynamic Subgoal-based Exploration via Bayesian Optimization</title><link>http://arxiv.org/abs/1910.09143v4</link><description>Reinforcement learning in sparse-reward navigation environments withexpensive and limited interactions is challenging and poses a need foreffective exploration. Motivated by complex navigation tasks that requirereal-world training (when cheap simulators are not available), we consider anagent that faces an unknown distribution of environments and must decide on anexploration strategy. It may leverage a series of training environments toimprove its policy before it is evaluated in a test environment drawn from thesame environment distribution. Most existing approaches focus on fixedexploration strategies, while the few that view exploration as ameta-optimization problem tend to ignore the need for cost-efficientexploration. We propose a cost-aware Bayesian optimization approach thatefficiently searches over a class of dynamic subgoal-based explorationstrategies. The algorithm adjusts a variety of levers -- the locations of thesubgoals, the length of each episode, and the number of replications per trial-- in order to overcome the challenges of sparse rewards, expensiveinteractions, and noise. An experimental evaluation demonstrates that the newapproach outperforms existing baselines across a number of problem domains. Wealso provide a theoretical foundation and prove that the method asymptoticallyidentifies a near-optimal subgoal design.</description><author>Yijia Wang, Matthias Poloczek, Daniel R. Jiang</author><pubDate>Tue, 10 Oct 2023 18:06:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1910.09143v4</guid></item><item><title>Enhancing Predictive Capabilities in Data-Driven Dynamical Modeling with Automatic Differentiation: Koopman and Neural ODE Approaches</title><link>http://arxiv.org/abs/2310.06790v1</link><description>Data-driven approximations of the Koopman operator are promising forpredicting the time evolution of systems characterized by complex dynamics.Among these methods, the approach known as extended dynamic mode decompositionwith dictionary learning (EDMD-DL) has garnered significant attention. Here wepresent a modification of EDMD-DL that concurrently determines both thedictionary of observables and the corresponding approximation of the Koopmanoperator. This innovation leverages automatic differentiation to facilitategradient descent computations through the pseudoinverse. We also address theperformance of several alternative methodologies. We assess a 'pure' Koopmanapproach, which involves the direct time-integration of a linear,high-dimensional system governing the dynamics within the space of observables.Additionally, we explore a modified approach where the system alternatesbetween spaces of states and observables at each time step -- this approach nolonger satisfies the linearity of the true Koopman operator representation. Forfurther comparisons, we also apply a state space approach (neural ODEs). Weconsider systems encompassing two and three-dimensional ordinary differentialequation systems featuring steady, oscillatory, and chaotic attractors, as wellas partial differential equations exhibiting increasingly complex and intricatebehaviors. Our framework significantly outperforms EDMD-DL. Furthermore, thestate space approach offers superior performance compared to the 'pure' Koopmanapproach where the entire time evolution occurs in the space of observables.When the temporal evolution of the Koopman approach alternates between statesand observables at each time step, however, its predictions become comparableto those of the state space approach.</description><author>C. Ricardo Constante-Amores, Alec J. Linot, Michael D. Graham</author><pubDate>Tue, 10 Oct 2023 18:04:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06790v1</guid></item><item><title>OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text</title><link>http://arxiv.org/abs/2310.06786v1</link><description>There is growing evidence that pretraining on high quality, carefullythought-out tokens such as code or mathematics plays an important role inimproving the reasoning abilities of large language models. For example,Minerva, a PaLM model finetuned on billions of tokens of mathematical documentsfrom arXiv and the web, reported dramatically improved performance on problemsthat require quantitative reasoning. However, because all known open source webdatasets employ preprocessing that does not faithfully preserve mathematicalnotation, the benefits of large scale training on quantitive web documents areunavailable to the research community. We introduce OpenWebMath, an opendataset inspired by these works containing 14.7B tokens of mathematicalwebpages from Common Crawl. We describe in detail our method for extractingtext and LaTeX content and removing boilerplate from HTML documents, as well asour methods for quality filtering and deduplication. Additionally, we runsmall-scale experiments by training 1.4B parameter language models onOpenWebMath, showing that models trained on 14.7B tokens of our dataset surpassthe performance of models trained on over 20x the amount of general languagedata. We hope that our dataset, openly released on the Hugging Face Hub, willhelp spur advances in the reasoning abilities of large language models.</description><author>Keiran Paster, Marco Dos Santos, Zhangir Azerbayev, Jimmy Ba</author><pubDate>Tue, 10 Oct 2023 17:57:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06786v1</guid></item><item><title>A Supervised Embedding and Clustering Anomaly Detection method for classification of Mobile Network Faults</title><link>http://arxiv.org/abs/2310.06779v1</link><description>The paper introduces Supervised Embedding and Clustering Anomaly Detection(SEMC-AD), a method designed to efficiently identify faulty alarm logs in amobile network and alleviate the challenges of manual monitoring caused by thegrowing volume of alarm logs. SEMC-AD employs a supervised embedding approachbased on deep neural networks, utilizing historical alarm logs and their labelsto extract numerical representations for each log, effectively addressing theissue of imbalanced classification due to a small proportion of anomalies inthe dataset without employing one-hot encoding. The robustness of the embeddingis evaluated by plotting the two most significant principle components of theembedded alarm logs, revealing that anomalies form distinct clusters withsimilar embeddings. Multivariate normal Gaussian clustering is then applied tothese components, identifying clusters with a high ratio of anomalies to normalalarms (above 90%) and labeling them as the anomaly group. To classify newalarm logs, we check if their embedded vectors' two most significant principlecomponents fall within the anomaly-labeled clusters. If so, the log isclassified as an anomaly. Performance evaluation demonstrates that SEMC-ADoutperforms conventional random forest and gradient boosting methods withoutembedding. SEMC-AD achieves 99% anomaly detection, whereas random forest andXGBoost only detect 86% and 81% of anomalies, respectively. While supervisedclassification methods may excel in labeled datasets, the results demonstratethat SEMC-AD is more efficient in classifying anomalies in datasets withnumerous categorical features, significantly enhancing anomaly detection,reducing operator burden, and improving network maintenance.</description><author>R. Mosayebi, H. Kia, A. Kianpour Raki</author><pubDate>Tue, 10 Oct 2023 17:54:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06779v1</guid></item><item><title>Information Content Exploration</title><link>http://arxiv.org/abs/2310.06777v1</link><description>Sparse reward environments are known to be challenging for reinforcementlearning agents. In such environments, efficient and scalable exploration iscrucial. Exploration is a means by which an agent gains information about theenvironment. We expand on this topic and propose a new intrinsic reward thatsystemically quantifies exploratory behavior and promotes state coverage bymaximizing the information content of a trajectory taken by an agent. Wecompare our method to alternative exploration based intrinsic rewardtechniques, namely Curiosity Driven Learning and Random Network Distillation.We show that our information theoretic reward induces efficient exploration andoutperforms in various games, including Montezuma Revenge, a known difficulttask for reinforcement learning. Finally, we propose an extension thatmaximizes information content in a discretely compressed latent space whichboosts sample efficiency and generalizes to continuous state spaces.</description><author>Jacob Chmura, Hasham Burhani, Xiao Qi Shi</author><pubDate>Tue, 10 Oct 2023 17:51:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06777v1</guid></item><item><title>Uni3D: Exploring Unified 3D Representation at Scale</title><link>http://arxiv.org/abs/2310.06773v1</link><description>Scaling up representations for images or text has been extensivelyinvestigated in the past few years and has led to revolutions in learningvision and language. However, scalable representation for 3D objects and scenesis relatively unexplored. In this work, we present Uni3D, a 3D foundation modelto explore the unified 3D representation at scale. Uni3D uses a 2D initializedViT end-to-end pretrained to align the 3D point cloud features with theimage-text aligned features. Via the simple architecture and pretext task,Uni3D can leverage abundant 2D pretrained models as initialization andimage-text aligned models as the target, unlocking the great potential of 2Dmodels and scaling-up strategies to the 3D world. We efficiently scale up Uni3Dto one billion parameters, and set new records on a broad range of 3D tasks,such as zero-shot classification, few-shot classification, open-worldunderstanding and part segmentation. We show that the strong Uni3Drepresentation also enables applications such as 3D painting and retrieval inthe wild. We believe that Uni3D provides a new direction for exploring bothscaling up and efficiency of the representation in 3D domain.</description><author>Junsheng Zhou, Jinsheng Wang, Baorui Ma, Yu-Shen Liu, Tiejun Huang, Xinlong Wang</author><pubDate>Tue, 10 Oct 2023 17:49:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06773v1</guid></item><item><title>Correlated Noise Provably Beats Independent Noise for Differentially Private Learning</title><link>http://arxiv.org/abs/2310.06771v1</link><description>Differentially private learning algorithms inject noise into the learningprocess. While the most common private learning algorithm, DP-SGD, addsindependent Gaussian noise in each iteration, recent work on matrixfactorization mechanisms has shown empirically that introducing correlations inthe noise can greatly improve their utility. We characterize the asymptoticlearning utility for any choice of the correlation function, giving preciseanalytical bounds for linear regression and as the solution to a convex programfor general convex functions. We show, using these bounds, how correlated noiseprovably improves upon vanilla DP-SGD as a function of problem parameters suchas the effective dimension and condition number. Moreover, our analyticalexpression for the near-optimal correlation function circumvents the cubiccomplexity of the semi-definite program used to optimize the noise correlationmatrix in previous work. We validate our theory with experiments on privatedeep learning. Our work matches or outperforms prior work while being efficientboth in terms of compute and memory.</description><author>Christopher A. Choquette-Choo, Krishnamurthy Dvijotham, Krishna Pillutla, Arun Ganesh, Thomas Steinke, Abhradeep Thakurta</author><pubDate>Tue, 10 Oct 2023 17:48:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06771v1</guid></item><item><title>SWE-bench: Can Language Models Resolve Real-World GitHub Issues?</title><link>http://arxiv.org/abs/2310.06770v1</link><description>Language models have outpaced our ability to evaluate them effectively, butfor their future development it is essential to study the frontier of theircapabilities. We consider real-world software engineering to be a rich,sustainable, and challenging testbed for evaluating the next generation oflanguage models. We therefore introduce SWE-bench, an evaluation frameworkincluding $2,294$ software engineering problems drawn from real GitHub issuesand corresponding pull requests across $12$ popular Python repositories. Givena codebase along with a description of an issue to be resolved, a languagemodel is tasked with editing the codebase to address the issue. Resolvingissues in SWE-bench frequently requires understanding and coordinating changesacross multiple functions, classes, and even files simultaneously, calling formodels to interact with execution environments, process extremely long contextsand perform complex reasoning that goes far beyond traditional code generation.Our evaluations show that both state-of-the-art proprietary models and ourfine-tuned model SWE-Llama can resolve only the simplest issues. Claude 2 andGPT-4 solve a mere $4.8$% and $1.7$% of instances respectively, even whenprovided with an oracle retriever. Advances on SWE-bench represent stepstowards LMs that are more practical, intelligent, and autonomous.</description><author>Carlos E. Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, Karthik Narasimhan</author><pubDate>Tue, 10 Oct 2023 17:47:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06770v1</guid></item><item><title>Multi-spectral Entropy Constrained Neural Compression of Solar Imagery</title><link>http://arxiv.org/abs/2309.10791v2</link><description>Missions studying the dynamic behaviour of the Sun are defined to capturemulti-spectral images of the sun and transmit them to the ground station in adaily basis. To make transmission efficient and feasible, image compressionsystems need to be exploited. Recently successful end-to-end optimized neuralnetwork-based image compression systems have shown great potential to be usedin an ad-hoc manner. In this work we have proposed a transformer-basedmulti-spectral neural image compressor to efficiently capture redundancies bothintra/inter-wavelength. To unleash the locality of window-based self attentionmechanism, we propose an inter-window aggregated token multi head selfattention. Additionally to make the neural compressor autoencoder shiftinvariant, a randomly shifted window attention mechanism is used which makesthe transformer blocks insensitive to translations in their input domain. Wedemonstrate that the proposed approach not only outperforms the conventionalcompression algorithms but also it is able to better decorrelates images alongthe multiple wavelengths compared to single spectral compression.</description><author>Ali Zafari, Atefeh Khoshkhahtinat, Piyush M. Mehta, Nasser M. Nasrabadi, Barbara J. Thompson, Michael S. F. Kirk, Daniel da Silva</author><pubDate>Tue, 10 Oct 2023 17:44:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10791v2</guid></item><item><title>Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models</title><link>http://arxiv.org/abs/2307.10236v2</link><description>The recent performance leap of Large Language Models (LLMs) opens up newopportunities across numerous industrial applications and domains. However,erroneous generations, such as false predictions, misinformation, andhallucination made by LLMs, have also raised severe concerns for thetrustworthiness of LLMs', especially in safety-, security- andreliability-sensitive scenarios, potentially hindering real-world adoptions.While uncertainty estimation has shown its potential for interpreting theprediction risks made by general machine learning (ML) models, little is knownabout whether and to what extent it can help explore an LLM's capabilities andcounteract its undesired behavior. To bridge the gap, in this paper, weinitiate an exploratory study on the risk assessment of LLMs from the lens ofuncertainty. In particular, we experiment with twelve uncertainty estimationmethods and four LLMs on four prominent natural language processing (NLP) tasksto investigate to what extent uncertainty estimation techniques could helpcharacterize the prediction risks of LLMs. Our findings validate theeffectiveness of uncertainty estimation for revealing LLMs'uncertain/non-factual predictions. In addition to general NLP tasks, weextensively conduct experiments with four LLMs for code generation on twodatasets. We find that uncertainty estimation can potentially uncover buggyprograms generated by LLMs. Insights from our study shed light on future designand development for reliable LLMs, facilitating further research towardenhancing the trustworthiness of LLMs.</description><author>Yuheng Huang, Jiayang Song, Zhijie Wang, Huaming Chen, Felix Juefei-Xu, Lei Ma</author><pubDate>Tue, 10 Oct 2023 17:44:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10236v2</guid></item><item><title>MC-ViViT: Multi-branch Classifier-ViViT to detect Mild Cognitive Impairment in older adults using facial videos</title><link>http://arxiv.org/abs/2304.05292v3</link><description>Deep machine learning models including Convolutional Neural Networks (CNN)have been successful in the detection of Mild Cognitive Impairment (MCI) usingmedical images, questionnaires, and videos. This paper proposes a novelMulti-branch Classifier-Video Vision Transformer (MC-ViViT) model todistinguish MCI from those with normal cognition by analyzing facial features.The data comes from the I-CONECT, a behavioral intervention trial aimed atimproving cognitive function by providing frequent video chats. MC-ViViTextracts spatiotemporal features of videos in one branch and augmentsrepresentations by the MC module. The I-CONECT dataset is challenging as thedataset is imbalanced containing Hard-Easy and Positive-Negative samples, whichimpedes the performance of MC-ViViT. We propose a loss function for Hard-Easyand Positive-Negative Samples (HP Loss) by combining Focal loss and AD-CORREloss to address the imbalanced problem. Our experimental results on theI-CONECT dataset show the great potential of MC-ViViT in predicting MCI with ahigh accuracy of 90.63% accuracy on some of the interview videos.</description><author>Jian Sun, Hiroko H. Dodge, Mohammad H. Mahoor</author><pubDate>Tue, 10 Oct 2023 17:40:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.05292v3</guid></item><item><title>OmniLingo: Listening- and speaking-based language learning</title><link>http://arxiv.org/abs/2310.06764v1</link><description>In this demo paper we present OmniLingo, an architecture for distributingdata for listening- and speaking-based language learning applications and ademonstration client built using the architecture. The architecture is based onthe Interplanetary Filesystem (IPFS) and puts at the forefront user sovereigntyover data.</description><author>Francis M. Tyers, Nicholas Howell</author><pubDate>Tue, 10 Oct 2023 17:40:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06764v1</guid></item><item><title>FABind: Fast and Accurate Protein-Ligand Binding</title><link>http://arxiv.org/abs/2310.06763v1</link><description>Modeling the interaction between proteins and ligands and accuratelypredicting their binding structures is a critical yet challenging task in drugdiscovery. Recent advancements in deep learning have shown promise inaddressing this challenge, with sampling-based and regression-based methodsemerging as two prominent approaches. However, these methods have notablelimitations. Sampling-based methods often suffer from low efficiency due to theneed for generating multiple candidate structures for selection. On the otherhand, regression-based methods offer fast predictions but may experiencedecreased accuracy. Additionally, the variation in protein sizes often requiresexternal modules for selecting suitable binding pockets, further impactingefficiency. In this work, we propose $\mathbf{FABind}$, an end-to-end modelthat combines pocket prediction and docking to achieve accurate and fastprotein-ligand binding. $\mathbf{FABind}$ incorporates a unique ligand-informedpocket prediction module, which is also leveraged for docking pose estimation.The model further enhances the docking process by incrementally integrating thepredicted pocket to optimize protein-ligand binding, reducing discrepanciesbetween training and inference. Through extensive experiments on benchmarkdatasets, our proposed $\mathbf{FABind}$ demonstrates strong advantages interms of effectiveness and efficiency compared to existing methods. Our code isavailable at $\href{https://github.com/QizhiPei/FABind}{Github}$.</description><author>Qizhi Pei, Kaiyuan Gao, Lijun Wu, Jinhua Zhu, Yingce Xia, Shufang Xie, Tao Qin, Kun He, Tie-Yan Liu, Rui Yan</author><pubDate>Tue, 10 Oct 2023 17:39:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06763v1</guid></item><item><title>TRACE: A Comprehensive Benchmark for Continual Learning in Large Language Models</title><link>http://arxiv.org/abs/2310.06762v1</link><description>Aligned large language models (LLMs) demonstrate exceptional capabilities intask-solving, following instructions, and ensuring safety. However, thecontinual learning aspect of these aligned LLMs has been largely overlooked.Existing continual learning benchmarks lack sufficient challenge for leadingaligned LLMs, owing to both their simplicity and the models' potential exposureduring instruction tuning. In this paper, we introduce TRACE, a novel benchmarkdesigned to evaluate continual learning in LLMs. TRACE consists of 8 distinctdatasets spanning challenging tasks including domain-specific tasks,multilingual capabilities, code generation, and mathematical reasoning. Alldatasets are standardized into a unified format, allowing for effortlessautomatic evaluation of LLMs. Our experiments show that after training onTRACE, aligned LLMs exhibit significant declines in both general ability andinstruction-following capabilities. For example, the accuracy of llama2-chat13B on gsm8k dataset declined precipitously from 28.8\% to 2\% after trainingon our datasets. This highlights the challenge of finding a suitable tradeoffbetween achieving performance on specific tasks while preserving the originalprowess of LLMs. Empirical findings suggest that tasks inherently equipped withreasoning paths contribute significantly to preserving certain capabilities ofLLMs against potential declines. Motivated by this, we introduce theReasoning-augmented Continual Learning (RCL) approach. RCL integratestask-specific cues with meta-rationales, effectively reducing catastrophicforgetting in LLMs while expediting convergence on novel tasks.</description><author>Xiao Wang, Yuansen Zhang, Tianze Chen, Songyang Gao, Senjie Jin, Xianjun Yang, Zhiheng Xi, Rui Zheng, Yicheng Zou, Tao Gui, Qi Zhang, Xuanjing Huang</author><pubDate>Tue, 10 Oct 2023 17:38:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06762v1</guid></item><item><title>Going Beyond Neural Network Feature Similarity: The Network Feature Complexity and Its Interpretation Using Category Theory</title><link>http://arxiv.org/abs/2310.06756v1</link><description>The behavior of neural networks still remains opaque, and a recently widelynoted phenomenon is that networks often achieve similar performance wheninitialized with different random parameters. This phenomenon has attractedsignificant attention in measuring the similarity between features learned bydistinct networks. However, feature similarity could be vague in describing thesame feature since equivalent features hardly exist. In this paper, we expandthe concept of equivalent feature and provide the definition of what we callfunctionally equivalent features. These features produce equivalent outputunder certain transformations. Using this definition, we aim to derive a moreintrinsic metric for the so-called feature complexity regarding the redundancyof features learned by a neural network at each layer. We offer a formalinterpretation of our approach through the lens of category theory, awell-developed area in mathematics. To quantify the feature complexity, wefurther propose an efficient algorithm named Iterative Feature Merging. Ourexperimental results validate our ideas and theories from various perspectives.We empirically demonstrate that the functionally equivalence widely existsamong different features learned by the same neural network and we could reducethe number of parameters of the network without affecting the performance.TheIFM shows great potential as a data-agnostic model prune method. We have alsodrawn several interesting empirical findings regarding the defined featurecomplexity.</description><author>Yiting Chen, Zhanpeng Zhou, Junchi Yan</author><pubDate>Tue, 10 Oct 2023 17:27:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06756v1</guid></item><item><title>TopoMLP: An Simple yet Strong Pipeline for Driving Topology Reasoning</title><link>http://arxiv.org/abs/2310.06753v1</link><description>Topology reasoning aims to comprehensively understand road scenes and presentdrivable routes in autonomous driving. It requires detecting road centerlines(lane) and traffic elements, further reasoning their topology relationship,i.e., lane-lane topology, and lane-traffic topology. In this work, we firstpresent that the topology score relies heavily on detection performance on laneand traffic elements. Therefore, we introduce a powerful 3D lane detector andan improved 2D traffic element detector to extend the upper limit of topologyperformance. Further, we propose TopoMLP, a simple yet high-performancepipeline for driving topology reasoning. Based on the impressive detectionperformance, we develop two simple MLP-based heads for topology generation.TopoMLP achieves state-of-the-art performance on OpenLane-V2 benchmark, i.e.,41.2% OLS with ResNet-50 backbone. It is also the 1st solution for 1st OpenLaneTopology in Autonomous Driving Challenge. We hope such simple and strongpipeline can provide some new insights to the community. Code is athttps://github.com/wudongming97/TopoMLP.</description><author>Dongming Wu, Jiahao Chang, Fan Jia, Yingfei Liu, Tiancai Wang, Jianbing Shen</author><pubDate>Tue, 10 Oct 2023 17:24:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06753v1</guid></item><item><title>Comparing AI Algorithms for Optimizing Elliptic Curve Cryptography Parameters in Third-Party E-Commerce Integrations: A Pre-Quantum Era Analysis</title><link>http://arxiv.org/abs/2310.06752v1</link><description>This paper presents a comparative analysis between the Genetic Algorithm (GA)and Particle Swarm Optimization (PSO), two vital artificial intelligencealgorithms, focusing on optimizing Elliptic Curve Cryptography (ECC)parameters. These encompass the elliptic curve coefficients, prime number,generator point, group order, and cofactor. The study provides insights intowhich of the bio-inspired algorithms yields better optimization results for ECCconfigurations, examining performances under the same fitness function. Thisfunction incorporates methods to ensure robust ECC parameters, includingassessing for singular or anomalous curves and applying Pollard's rho attackand Hasse's theorem for optimization precision. The optimized parametersgenerated by GA and PSO are tested in a simulated e-commerce environment,contrasting with well-known curves like secp256k1 during the transmission oforder messages using Elliptic Curve-Diffie Hellman (ECDH) and Hash-basedMessage Authentication Code (HMAC). Focusing on traditional computing in thepre-quantum era, this research highlights the efficacy of GA and PSO in ECCoptimization, with implications for enhancing cybersecurity in third-partye-commerce integrations. We recommend the immediate consideration of thesefindings before quantum computing's widespread adoption.</description><author>Felipe Tellez, Jorge Ortiz</author><pubDate>Tue, 10 Oct 2023 17:23:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06752v1</guid></item><item><title>Assessor360: Multi-sequence Network for Blind Omnidirectional Image Quality Assessment</title><link>http://arxiv.org/abs/2305.10983v3</link><description>Blind Omnidirectional Image Quality Assessment (BOIQA) aims to objectivelyassess the human perceptual quality of omnidirectional images (ODIs) withoutrelying on pristine-quality image information. It is becoming more significantwith the increasing advancement of virtual reality (VR) technology. However,the quality assessment of ODIs is severely hampered by the fact that theexisting BOIQA pipeline lacks the modeling of the observer's browsing process.To tackle this issue, we propose a novel multi-sequence network for BOIQAcalled Assessor360, which is derived from the realistic multi-assessor ODIquality assessment procedure. Specifically, we propose a generalized RecursiveProbability Sampling (RPS) method for the BOIQA task, combining content anddetails information to generate multiple pseudo-viewport sequences from a givenstarting point. Additionally, we design a Multi-scale Feature Aggregation (MFA)module with a Distortion-aware Block (DAB) to fuse distorted and semanticfeatures of each viewport. We also devise Temporal Modeling Module (TMM) tolearn the viewport transition in the temporal domain. Extensive experimentalresults demonstrate that Assessor360 outperforms state-of-the-art methods onmultiple OIQA datasets. The code and models are available athttps://github.com/TianheWu/Assessor360.</description><author>Tianhe Wu, Shuwei Shi, Haoming Cai, Mingdeng Cao, Jing Xiao, Yinqiang Zheng, Yujiu Yang</author><pubDate>Tue, 10 Oct 2023 17:23:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10983v3</guid></item><item><title>Skill-Based Few-Shot Selection for In-Context Learning</title><link>http://arxiv.org/abs/2305.14210v2</link><description>In-context learning is the paradigm that adapts large language models todownstream tasks by providing a few examples. Few-shot selection -- selectingappropriate examples for each test instance separately -- is important forin-context learning. In this paper, we propose Skill-KNN, a skill-basedfew-shot selection method for in-context learning. The key advantages ofSkill-KNN include: (1) it addresses the problem that existing methods based onpre-trained embeddings can be easily biased by surface natural languagefeatures that are not important for the target task; (2) it does not requiretraining or fine-tuning of any models, making it suitable for frequentlyexpanding or changing example banks. The key insight is to optimize the inputsfed into the embedding model, rather than tuning the model itself. Technically,Skill-KNN generates the skill-based descriptions for each test case andcandidate example by utilizing a pre-processing few-shot prompting, thuseliminating unimportant surface features. Experimental results across fivecross-domain semantic parsing datasets and six backbone models show thatSkill-KNN significantly outperforms existing methods.</description><author>Shengnan An, Bo Zhou, Zeqi Lin, Qiang Fu, Bei Chen, Nanning Zheng, Weizhu Chen, Jian-Guang Lou</author><pubDate>Tue, 10 Oct 2023 17:23:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14210v2</guid></item><item><title>StepMix: A Python Package for Pseudo-Likelihood Estimation of Generalized Mixture Models with External Variables</title><link>http://arxiv.org/abs/2304.03853v4</link><description>StepMix is an open-source Python package for the pseudo-likelihood estimation(one-, two- and three-step approaches) of generalized finite mixture models(latent profile and latent class analysis) with external variables (covariatesand distal outcomes). In many applications in social sciences, the mainobjective is not only to cluster individuals into latent classes, but also touse these classes to develop more complex statistical models. These modelsgenerally divide into a measurement model that relates the latent classes toobserved indicators, and a structural model that relates covariates and outcomevariables to the latent classes. The measurement and structural models can beestimated jointly using the so-called one-step approach or sequentially usingstepwise methods, which present significant advantages for practitionersregarding the interpretability of the estimated latent classes. In addition tothe one-step approach, StepMix implements the most important stepwiseestimation methods from the literature, including the bias-adjusted three-stepmethods with Bolk-Croon-Hagenaars and maximum likelihood corrections and themore recent two-step approach. These pseudo-likelihood estimators are presentedin this paper under a unified framework as specific expectation-maximizationsubroutines. To facilitate and promote their adoption among the data sciencecommunity, StepMix follows the object-oriented design of the scikit-learnlibrary and provides an additional R wrapper.</description><author>Sacha Morin, Robin Legault, FÃ©lix LalibertÃ©, Zsuzsa Bakk, Charles-Ãdouard GiguÃ¨re, Roxane de la SablonniÃ¨re, Ãric Lacourse</author><pubDate>Tue, 10 Oct 2023 17:22:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03853v4</guid></item><item><title>Causal Rule Learning: Enhancing the Understanding of Heterogeneous Treatment Effect via Weighted Causal Rules</title><link>http://arxiv.org/abs/2310.06746v1</link><description>Interpretability is a key concern in estimating heterogeneous treatmenteffects using machine learning methods, especially for healthcare applicationswhere high-stake decisions are often made. Inspired by the Predictive,Descriptive, Relevant framework of interpretability, we propose causal rulelearning which finds a refined set of causal rules characterizing potentialsubgroups to estimate and enhance our understanding of heterogeneous treatmenteffects. Causal rule learning involves three phases: rule discovery, ruleselection, and rule analysis. In the rule discovery phase, we utilize a causalforest to generate a pool of causal rules with corresponding subgroup averagetreatment effects. The selection phase then employs a D-learning method toselect a subset of these rules to deconstruct individual-level treatmenteffects as a linear combination of the subgroup-level effects. This helps toanswer an ignored question by previous literature: what if an individualsimultaneously belongs to multiple groups with different average treatmenteffects? The rule analysis phase outlines a detailed procedure to furtheranalyze each rule in the subset from multiple perspectives, revealing the mostpromising rules for further validation. The rules themselves, theircorresponding subgroup treatment effects, and their weights in the linearcombination give us more insights into heterogeneous treatment effects.Simulation and real-world data analysis demonstrate the superior performance ofcausal rule learning on the interpretable estimation of heterogeneous treatmenteffect when the ground truth is complex and the sample size is sufficient.</description><author>Ying Wu, Hanzhong Liu, Kai Ren, Xiangyu Chang</author><pubDate>Tue, 10 Oct 2023 17:19:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06746v1</guid></item><item><title>HiFi-123: Towards High-fidelity One Image to 3D Content Generation</title><link>http://arxiv.org/abs/2310.06744v1</link><description>Recent advances in text-to-image diffusion models have enabled 3D generationfrom a single image. However, current image-to-3D methods often producesuboptimal results for novel views, with blurred textures and deviations fromthe reference image, limiting their practical applications. In this paper, weintroduce HiFi-123, a method designed for high-fidelity and multi-viewconsistent 3D generation. Our contributions are twofold: First, we propose areference-guided novel view enhancement technique that substantially reducesthe quality gap between synthesized and reference views. Second, capitalizingon the novel view enhancement, we present a novel reference-guided statedistillation loss. When incorporated into the optimization-based image-to-3Dpipeline, our method significantly improves 3D generation quality, achievingstate-of-the-art performance. Comprehensive evaluations demonstrate theeffectiveness of our approach over existing methods, both qualitatively andquantitatively.</description><author>Wangbo Yu, Li Yuan, Yan-Pei Cao, Xiangjun Gao, Xiaoyu Li, Long Quan, Ying Shan, Yonghong Tian</author><pubDate>Tue, 10 Oct 2023 17:14:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06744v1</guid></item><item><title>Geographic Location Encoding with Spherical Harmonics and Sinusoidal Representation Networks</title><link>http://arxiv.org/abs/2310.06743v1</link><description>Learning feature representations of geographical space is vital for anymachine learning model that integrates geolocated data, spanning applicationdomains such as remote sensing, ecology, or epidemiology. Recent work mostlyembeds coordinates using sine and cosine projections based on Double FourierSphere (DFS) features -- these embeddings assume a rectangular data domain evenon global data, which can lead to artifacts, especially at the poles. At thesame time, relatively little attention has been paid to the exact design of theneural network architectures these functional embeddings are combined with.This work proposes a novel location encoder for globally distributed geographicdata that combines spherical harmonic basis functions, natively defined onspherical surfaces, with sinusoidal representation networks (SirenNets) thatcan be interpreted as learned Double Fourier Sphere embedding. Wesystematically evaluate the cross-product of positional embeddings and neuralnetwork architectures across various classification and regression benchmarksand synthetic evaluation datasets. In contrast to previous approaches thatrequire the combination of both positional encoding and neural networks tolearn meaningful representations, we show that both spherical harmonics andsinusoidal representation networks are competitive on their own but setstate-of-the-art performances across tasks when combined. We provide sourcecode at www.github.com/marccoru/locationencoder</description><author>Marc RuÃwurm, Konstantin Klemmer, Esther Rolf, Robin Zbinden, Devis Tuia</author><pubDate>Tue, 10 Oct 2023 17:12:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06743v1</guid></item><item><title>Multi-domain improves out-of-distribution and data-limited scenarios for medical image analysis</title><link>http://arxiv.org/abs/2310.06737v1</link><description>Current machine learning methods for medical image analysis primarily focuson developing models tailored for their specific tasks, utilizing data withintheir target domain. These specialized models tend to be data-hungry and oftenexhibit limitations in generalizing to out-of-distribution samples. Recently,foundation models have been proposed, which combine data from various domainsand demonstrate excellent generalization capabilities. Building upon this, thiswork introduces the incorporation of diverse medical image domains, includingdifferent imaging modalities like X-ray, MRI, CT, and ultrasound images, aswell as various viewpoints such as axial, coronal, and sagittal views. We referto this approach as multi-domain model and compare its performance to that ofspecialized models. Our findings underscore the superior generalizationcapabilities of multi-domain models, particularly in scenarios characterized bylimited data availability and out-of-distribution, frequently encountered inhealthcare applications. The integration of diverse data allows multi-domainmodels to utilize shared information across domains, enhancing the overalloutcomes significantly. To illustrate, for organ recognition, multi-domainmodel can enhance accuracy by up to 10% compared to conventional specializedmodels.</description><author>Ece Ozkan, Xavier Boix</author><pubDate>Tue, 10 Oct 2023 17:07:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06737v1</guid></item><item><title>Growing ecosystem of deep learning methods for modeling protein$\unicode{x2013}$protein interactions</title><link>http://arxiv.org/abs/2310.06725v1</link><description>Numerous cellular functions rely on protein$\unicode{x2013}$proteininteractions. Efforts to comprehensively characterize them remain challengedhowever by the diversity of molecular recognition mechanisms employed withinthe proteome. Deep learning has emerged as a promising approach for tacklingthis problem by exploiting both experimental data and basic biophysicalknowledge about protein interactions. Here, we review the growing ecosystem ofdeep learning methods for modeling protein interactions, highlighting thediversity of these biophysically-informed models and their respectivetrade-offs. We discuss recent successes in using representation learning tocapture complex features pertinent to predicting protein interactions andinteraction sites, geometric deep learning to reason over protein structuresand predict complex structures, and generative modeling to design de novoprotein assemblies. We also outline some of the outstanding challenges andpromising new directions. Opportunities abound to discover novel interactions,elucidate their physical mechanisms, and engineer binders to modulate theirfunctions using deep learning and, ultimately, unravel how protein interactionsorchestrate complex cellular behaviors.</description><author>Julia R. Rogers, GergÅ NikolÃ©nyi, Mohammed AlQuraishi</author><pubDate>Tue, 10 Oct 2023 16:53:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06725v1</guid></item><item><title>Robust Alzheimer's Progression Modeling using Cross-Domain Self-Supervised Deep Learning</title><link>http://arxiv.org/abs/2211.08559v2</link><description>Developing successful artificial intelligence systems in practice depends onboth robust deep learning models and large, high-quality data. However,acquiring and labeling data can be prohibitively expensive and time-consumingin many real-world applications, such as clinical disease models.Self-supervised learning has demonstrated great potential in increasing modelaccuracy and robustness in small data regimes. In addition, many clinicalimaging and disease modeling applications rely heavily on regression ofcontinuous quantities. However, the applicability of self-supervised learningfor these medical-imaging regression tasks has not been extensively studied. Inthis study, we develop a cross-domain self-supervised learning approach fordisease prognostic modeling as a regression problem using medical images asinput. We demonstrate that self-supervised pretraining can improve theprediction of Alzheimer's Disease progression from brain MRI. We also show thatpretraining on extended (but not labeled) brain MRI data outperformspretraining on natural images. We further observe that the highest performanceis achieved when both natural images and extended brain-MRI data are used forpretraining.</description><author>Saba Dadsetan, Mohsen Hejrati, Shandong Wu, Somaye Hashemifar</author><pubDate>Tue, 10 Oct 2023 16:49:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.08559v2</guid></item><item><title>Improving Pseudo-Time Stepping Convergence for CFD Simulations With Neural Networks</title><link>http://arxiv.org/abs/2310.06717v1</link><description>Computational fluid dynamics (CFD) simulations of viscous fluids described bythe Navier-Stokes equations are considered. Depending on the Reynolds number ofthe flow, the Navier-Stokes equations may exhibit a highly nonlinear behavior.The system of nonlinear equations resulting from the discretization of theNavier-Stokes equations can be solved using nonlinear iteration methods, suchas Newton's method. However, fast quadratic convergence is typically onlyobtained in a local neighborhood of the solution, and for many configurations,the classical Newton iteration does not converge at all. In such cases,so-called globalization techniques may help to improve convergence. In this paper, pseudo-transient continuation is employed in order to improvenonlinear convergence. The classical algorithm is enhanced by a neural networkmodel that is trained to predict a local pseudo-time step. Generalization ofthe novel approach is facilitated by predicting the local pseudo-time stepseparately on each element using only local information on a patch of adjacentelements as input. Numerical results for standard benchmark problems, includingflow through a backward facing step geometry and Couette flow, show theperformance of the machine learning-enhanced globalization approach; as thesoftware for the simulations, the CFD module of COMSOL Multiphysics isemployed.</description><author>Anouk Zandbergen, Tycho van Noorden, Alexander Heinlein</author><pubDate>Tue, 10 Oct 2023 16:45:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06717v1</guid></item><item><title>S4Sleep: Elucidating the design space of deep-learning-based sleep stage classification models</title><link>http://arxiv.org/abs/2310.06715v1</link><description>Scoring sleep stages in polysomnography recordings is a time-consuming taskplagued by significant inter-rater variability. Therefore, it stands to benefitfrom the application of machine learning algorithms. While many algorithms havebeen proposed for this purpose, certain critical architectural decisions havenot received systematic exploration. In this study, we meticulously investigatethese design choices within the broad category of encoder-predictorarchitectures. We identify robust architectures applicable to both time seriesand spectrogram input representations. These architectures incorporatestructured state space models as integral components, leading to statisticallysignificant advancements in performance on the extensive SHHS dataset. Theseimprovements are assessed through both statistical and systematic errorestimations. We anticipate that the architectural insights gained from thisstudy will not only prove valuable for future research in sleep staging butalso hold relevance for other time series annotation tasks.</description><author>Tiezhi Wang, Nils Strodthoff</author><pubDate>Tue, 10 Oct 2023 16:42:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06715v1</guid></item><item><title>Exploring Memorization in Fine-tuned Language Models</title><link>http://arxiv.org/abs/2310.06714v1</link><description>LLMs have shown great capabilities in various tasks but also exhibitedmemorization of training data, thus raising tremendous privacy and copyrightconcerns. While prior work has studied memorization during pre-training, theexploration of memorization during fine-tuning is rather limited. Compared withpre-training, fine-tuning typically involves sensitive data and diverseobjectives, thus may bring unique memorization behaviors and distinct privacyrisks. In this work, we conduct the first comprehensive analysis to exploreLMs' memorization during fine-tuning across tasks. Our studies withopen-sourced and our own fine-tuned LMs across various tasks indicate thatfine-tuned memorization presents a strong disparity among tasks. We provide anunderstanding of this task disparity via sparse coding theory and unveil astrong correlation between memorization and attention score distribution. Byinvestigating its memorization behavior, multi-task fine-tuning paves apotential strategy to mitigate fine-tuned memorization.</description><author>Shenglai Zeng, Yaxin Li, Jie Ren, Yiding Liu, Han Xu, Pengfei He, Yue Xing, Shuaiqiang Wang, Jiliang Tang, Dawei Yin</author><pubDate>Tue, 10 Oct 2023 16:41:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06714v1</guid></item><item><title>Interpretable Traffic Event Analysis with Bayesian Networks</title><link>http://arxiv.org/abs/2310.06713v1</link><description>Although existing machine learning-based methods for traffic accidentanalysis can provide good quality results to downstream tasks, they lackinterpretability which is crucial for this critical problem. This paperproposes an interpretable framework based on Bayesian Networks for trafficaccident prediction. To enable the ease of interpretability, we design adataset construction pipeline to feed the traffic data into the framework whileretaining the essential traffic data information. With a concrete case study,our framework can derive a Bayesian Network from a dataset based on the causalrelationships between weather and traffic events across the United States.Consequently, our framework enables the prediction of traffic accidents withcompetitive accuracy while examining how the probability of these eventschanges under different conditions, thus illustrating transparent relationshipsbetween traffic and weather events. Additionally, the visualization of thenetwork simplifies the analysis of relationships between different variables,revealing the primary causes of traffic accidents and ultimately providing avaluable reference for reducing traffic accidents.</description><author>Tong Yuan, Jian Yang, Zeyi Wen</author><pubDate>Tue, 10 Oct 2023 16:38:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06713v1</guid></item><item><title>Zero-Shot Transfer in Imitation Learning</title><link>http://arxiv.org/abs/2310.06710v1</link><description>We present an algorithm that learns to imitate expert behavior and cantransfer to previously unseen domains without retraining. Such an algorithm isextremely relevant in real-world applications such as robotic learning because1) reward functions are difficult to design, 2) learned policies from onedomain are difficult to deploy in another domain and 3) learning directly inthe real world is either expensive or unfeasible due to security concerns. Toovercome these constraints, we combine recent advances in Deep RL by using anAnnealedVAE to learn a disentangled state representation and imitate an expertby learning a single Q-function which avoids adversarial training. Wedemonstrate the effectiveness of our method in 3 environments ranging indifficulty and the type of transfer knowledge required.</description><author>Alvaro Cauderan, Gauthier Boeshertz, Florian Schwarb, Calvin Zhang</author><pubDate>Tue, 10 Oct 2023 16:36:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06710v1</guid></item><item><title>Quality Control at Your Fingertips: Quality-Aware Translation Models</title><link>http://arxiv.org/abs/2310.06707v1</link><description>Maximum-a-posteriori (MAP) decoding is the most widely used decoding strategyfor neural machine translation (NMT) models. The underlying assumption is thatmodel probability correlates well with human judgment, with better translationsbeing more likely. However, research has shown that this assumption does notalways hold, and decoding strategies which directly optimize a utilityfunction, like Minimum Bayes Risk (MBR) or Quality-Aware decoding cansignificantly improve translation quality over standard MAP decoding. The maindisadvantage of these methods is that they require an additional model topredict the utility, and additional steps during decoding, which makes theentire process computationally demanding. In this paper, we propose to make theNMT models themselves quality-aware by training them to estimate the quality oftheir own output. During decoding, we can use the model's own quality estimatesto guide the generation process and produce the highest-quality translationspossible. We demonstrate that the model can self-evaluate its own output duringtranslation, eliminating the need for a separate quality estimation model.Moreover, we show that using this quality signal as a prompt during MAPdecoding can significantly improve translation quality. When using the internalquality estimate to prune the hypothesis space during MBR decoding, we can notonly further improve translation quality, but also reduce inference speed bytwo orders of magnitude.</description><author>Christian Tomani, David Vilar, Markus Freitag, Colin Cherry, Subhajit Naskar, Mara Finkelstein, Daniel Cremers</author><pubDate>Tue, 10 Oct 2023 16:33:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06707v1</guid></item><item><title>RL$^3$: Boosting Meta Reinforcement Learning via RL inside RL$^2$</title><link>http://arxiv.org/abs/2306.15909v2</link><description>Meta reinforcement learning (meta-RL) methods such as RL$^2$ have emerged aspromising approaches for learning data-efficient RL algorithms tailored to agiven task distribution. However, these RL algorithms struggle withlong-horizon tasks and out-of-distribution tasks since they rely on recurrentneural networks to process the sequence of experiences instead of summarizingthem into general RL components such as value functions. Moreover, eventransformers have a practical limit to the length of histories they canefficiently reason about before training and inference costs becomeprohibitive. In contrast, traditional RL algorithms are data-inefficient sincethey do not leverage domain knowledge, but they do converge to an optimalpolicy as more data becomes available. In this paper, we propose RL$^3$, aprincipled hybrid approach that combines traditional RL and meta-RL byincorporating task-specific action-values learned through traditional RL as aninput to the meta-RL neural network. We show that RL$^3$ earns greatercumulative reward on long-horizon and out-of-distribution tasks compared toRL$^2$, while maintaining the efficiency of the latter in the short term.Experiments are conducted on both custom and benchmark discrete domains fromthe meta-RL literature that exhibit a range of short-term, long-term, andcomplex dependencies.</description><author>Abhinav Bhatia, Samer B. Nashed, Shlomo Zilberstein</author><pubDate>Tue, 10 Oct 2023 16:26:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.15909v2</guid></item><item><title>DeepLSH: Deep Locality-Sensitive Hash Learning for Fast and Efficient Near-Duplicate Crash Report Detection</title><link>http://arxiv.org/abs/2310.06703v1</link><description>Automatic crash bucketing is a crucial phase in the software developmentprocess for efficiently triaging bug reports. It generally consists in groupingsimilar reports through clustering techniques. However, with real-timestreaming bug collection, systems are needed to quickly answer the question:What are the most similar bugs to a new one?, that is, efficiently findnear-duplicates. It is thus natural to consider nearest neighbors search totackle this problem and especially the well-known locality-sensitive hashing(LSH) to deal with large datasets due to its sublinear performance andtheoretical guarantees on the similarity search accuracy. Surprisingly, LSH hasnot been considered in the crash bucketing literature. It is indeed not trivialto derive hash functions that satisfy the so-called locality-sensitive propertyfor the most advanced crash bucketing metrics. Consequently, we study in thispaper how to leverage LSH for this task. To be able to consider the mostrelevant metrics used in the literature, we introduce DeepLSH, a Siamese DNNarchitecture with an original loss function, that perfectly approximates thelocality-sensitivity property even for Jaccard and Cosine metrics for whichexact LSH solutions exist. We support this claim with a series of experimentson an original dataset, which we make available.</description><author>Youcef Remil, Anes Bendimerad, Romain Mathonat, Chedy Raissi, Mehdi Kaytoue</author><pubDate>Tue, 10 Oct 2023 16:26:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06703v1</guid></item><item><title>Temporally Aligning Long Audio Interviews with Questions: A Case Study in Multimodal Data Integration</title><link>http://arxiv.org/abs/2310.06702v1</link><description>The problem of audio-to-text alignment has seen significant amount ofresearch using complete supervision during training. However, this is typicallynot in the context of long audio recordings wherein the text being queried doesnot appear verbatim within the audio file. This work is a collaboration with anon-governmental organization called CARE India that collects long audio healthsurveys from young mothers residing in rural parts of Bihar, India. Given aquestion drawn from a questionnaire that is used to guide these surveys, we aimto locate where the question is asked within a long audio recording. This is ofgreat value to African and Asian organizations that would otherwise have topainstakingly go through long and noisy audio recordings to locate questions(and answers) of interest. Our proposed framework, INDENT, uses across-attention-based model and prior information on the temporal ordering ofsentences to learn speech embeddings that capture the semantics of theunderlying spoken text. These learnt embeddings are used to retrieve thecorresponding audio segment based on text queries at inference time. Weempirically demonstrate the significant effectiveness (improvement in R-avg ofabout 3%) of our model over those obtained using text-based heuristics. We alsoshow how noisy ASR, generated using state-of-the-art ASR models for Indianlanguages, yields better results when used in place of speech. INDENT, trainedonly on Hindi data is able to cater to all languages supported by the(semantically) shared text space. We illustrate this empirically on 11 Indiclanguages.</description><author>Piyush Singh Pasi, Karthikeya Battepati, Preethi Jyothi, Ganesh Ramakrishnan, Tanmay Mahapatra, Manoj Singh</author><pubDate>Tue, 10 Oct 2023 16:25:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06702v1</guid></item><item><title>Multi-consensus Decentralized Accelerated Gradient Descent</title><link>http://arxiv.org/abs/2005.00797v2</link><description>This paper considers the decentralized convex optimization problem, which hasa wide range of applications in large-scale machine learning, sensor networks,and control theory. We propose novel algorithms that achieve optimalcomputation complexity and near optimal communication complexity. Ourtheoretical results give affirmative answers to the open problem on whetherthere exists an algorithm that can achieve a communication complexity (nearly)matching the lower bound depending on the global condition number instead ofthe local one. Furthermore, the linear convergence of our algorithms onlydepends on the strong convexity of global objective and it does \emph{not}require the local functions to be convex. The design of our methods relies on anovel integration of well-known techniques including Nesterov's acceleration,multi-consensus and gradient-tracking. Empirical studies show theoutperformance of our methods for machine learning applications.</description><author>Haishan Ye, Luo Luo, Ziang Zhou, Tong Zhang</author><pubDate>Tue, 10 Oct 2023 16:20:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2005.00797v2</guid></item><item><title>ABScribe: Rapid Exploration of Multiple Writing Variations in Human-AI Co-Writing Tasks using Large Language Models</title><link>http://arxiv.org/abs/2310.00117v2</link><description>Exploring alternative ideas by rewriting text is integral to the writingprocess. State-of-the-art large language models (LLMs) can simplify writingvariation generation. However, current interfaces pose challenges forsimultaneous consideration of multiple variations: creating new versionswithout overwriting text can be difficult, and pasting them sequentially canclutter documents, increasing workload and disrupting writers' flow. To tacklethis, we present ABScribe, an interface that supports rapid, yet visuallystructured, exploration of writing variations in human-AI co-writing tasks.With ABScribe, users can swiftly produce multiple variations using LLM prompts,which are auto-converted into reusable buttons. Variations are storedadjacently within text segments for rapid in-place comparisons using mouse-overinteractions on a context toolbar. Our user study with 12 writers shows thatABScribe significantly reduces task workload (d = 1.20, p &lt; 0.001), enhancesuser perceptions of the revision process (d = 2.41, p &lt; 0.001) compared to apopular baseline workflow, and provides insights into how writers explorevariations using LLMs.</description><author>Mohi Reza, Nathan Laundry, Ilya Musabirov, Peter Dushniku, Zhi Yuan "Michael" Yu, Kashish Mittal, Tovi Grossman, Michael Liut, Anastasia Kuzminykh, Joseph Jay Williams</author><pubDate>Tue, 10 Oct 2023 16:16:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00117v2</guid></item><item><title>Learning Personalized Story Evaluation</title><link>http://arxiv.org/abs/2310.03304v3</link><description>While large language models (LLMs) have shown impressive results for moreobjective tasks such as QA and retrieval, it remains nontrivial to evaluatetheir performance on open-ended text generation for reasons including (1) datacontamination; (2) multi-dimensional evaluation criteria; and (3)subjectiveness stemming from reviewers' personal preferences. To address suchissues, we propose to model personalization in an uncontaminated open-endedgeneration assessment. We create two new datasets Per-MPST and Per-DOC forpersonalized story evaluation, by re-purposing existing datasets with properanonymization and new personalized labels. We further develop a personalizedstory evaluation model PERSE to infer reviewer preferences and provide apersonalized evaluation. Specifically, given a few exemplary reviews from aparticular reviewer, PERSE predicts either a detailed review or fine-grainedcomparison in several aspects (such as interestingness and surprise) for thatreviewer on a new text input. Experimental results show that PERSE outperformsGPT-4 by 15.8% on Kendall correlation of story ratings, and by 13.7% onpairwise preference prediction accuracy. Both datasets and code will bereleased.</description><author>Danqing Wang, Kevin Yang, Hanlin Zhu, Xiaomeng Yang, Andrew Cohen, Lei Li, Yuandong Tian</author><pubDate>Tue, 10 Oct 2023 16:15:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03304v3</guid></item><item><title>Sheared LLaMA: Accelerating Language Model Pre-training via Structured Pruning</title><link>http://arxiv.org/abs/2310.06694v1</link><description>The popularity of LLaMA (Touvron et al., 2023a;b) and other recently emergedmoderate-sized large language models (LLMs) highlights the potential ofbuilding smaller yet powerful LLMs. Regardless, the cost of training suchmodels from scratch on trillions of tokens remains high. In this work, we studystructured pruning as an effective means to develop smaller LLMs frompre-trained, larger models. Our approach employs two key techniques: (1)targeted structured pruning, which prunes a larger model to a specified targetshape by removing layers, heads, and intermediate and hidden dimensions in anend-to-end manner, and (2) dynamic batch loading, which dynamically updates thecomposition of sampled data in each training batch based on varying lossesacross different domains. We demonstrate the efficacy of our approach bypresenting the Sheared-LLaMA series, pruning the LLaMA2-7B model down to 1.3Band 2.7B parameters. Sheared-LLaMA models outperform state-of-the-artopen-source models of equivalent sizes, such as Pythia, INCITE, and OpenLLaMAmodels, on a wide range of downstream and instruction tuning evaluations, whilerequiring only 3% of compute compared to training such models from scratch.This work provides compelling evidence that leveraging existing LLMs withstructured pruning is a far more cost-effective approach for building smallerLLMs.</description><author>Mengzhou Xia, Tianyu Gao, Zhiyuan Zeng, Danqi Chen</author><pubDate>Tue, 10 Oct 2023 16:13:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06694v1</guid></item><item><title>Strokes2Surface: Recovering Curve Networks From 4D Architectural Design Sketches</title><link>http://arxiv.org/abs/2306.07220v3</link><description>We present Strokes2Surface, an offline geometry reconstruction pipeline thatrecovers well-connected curve networks from imprecise 4D sketches to bridgeconcept design and digital modeling stages in architectural design. The inputto our pipeline consists of 3D strokes' polyline vertices and their timestampsas the 4th dimension, along with additional metadata recorded throughoutsketching. Inspired by architectural sketching practices, our pipeline combinesa classifier and two clustering models to achieve its goal. First, with a setof extracted hand-engineered features from the sketch, the classifierrecognizes the type of individual strokes between those depicting boundaries(Shape strokes) and those depicting enclosed areas (Scribble strokes). Next,the two clustering models parse strokes of each type into distinct groups, eachrepresenting an individual edge or face of the intended architectural object.Curve networks are then formed through topology recovery of consolidated Shapeclusters and surfaced using Scribble clusters guiding the cycle discovery. Ourevaluation is threefold: We confirm the usability of the Strokes2Surfacepipeline in architectural design use cases via a user study, we validate ourchoice of features via statistical analysis and ablation studies on ourcollected dataset, and we compare our outputs against a range ofreconstructions computed using alternative methods.</description><author>S. Rasoulzadeh, M. Wimmer, I. Kovacic</author><pubDate>Tue, 10 Oct 2023 16:10:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07220v3</guid></item><item><title>Meta-CoT: Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with Large Language Models</title><link>http://arxiv.org/abs/2310.06692v1</link><description>Large language models (LLMs) have unveiled remarkable reasoning capabilitiesby exploiting chain-of-thought (CoT) prompting, which generates intermediatereasoning chains to serve as the rationale for deriving the answer. However,current CoT methods either simply employ general prompts such as Let's thinkstep by step, or heavily rely on handcrafted task-specific demonstrations toattain preferable performances, thereby engendering an inescapable gap betweenperformance and generalization. To bridge this gap, we propose Meta-CoT, ageneralizable CoT prompting method in mixed-task scenarios where the type ofinput questions is unknown. Meta-CoT firstly categorizes the scenario based onthe input question and subsequently constructs diverse demonstrations from thecorresponding data pool in an automatic pattern. Meta-CoT simultaneously enjoysremarkable performances on ten public benchmark reasoning tasks and superiorgeneralization capabilities. Notably, Meta-CoT achieves the state-of-the-artresult on SVAMP (93.7%) without any additional program-aided methods. Ourfurther experiments on five out-of-distribution datasets verify the stabilityand generality of Meta-CoT.</description><author>Anni Zou, Zhuosheng Zhang, Hai Zhao, Xiangru Tang</author><pubDate>Tue, 10 Oct 2023 16:10:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06692v1</guid></item><item><title>Self-Convinced Prompting: Few-Shot Question Answering with Repeated Introspection</title><link>http://arxiv.org/abs/2310.05035v2</link><description>While large language models (LLMs) such as ChatGPT and PaLM have demonstratedremarkable performance in various language understanding and generation tasks,their capabilities in complex reasoning and intricate knowledge utilizationstill fall short of human-level proficiency. Recent studies have establishedthe effectiveness of prompts in steering LLMs towards generating desiredoutputs. Building on these insights, we introduce a novel framework thatharnesses the potential of large-scale pre-trained language models, toiteratively enhance performance of the LLMs. Our framework incorporates threecomponents: \textit{Normal CoT}, a \textit{Convincer}, and an\textit{Answerer}. It processes the output of a typical few-shotchain-of-thought prompt, assesses the correctness of the response, scrutinizesthe answer, refines the reasoning, and ultimately produces a new solution.Experimental results on the 7 datasets of miscellaneous problems validate theefficacy of the Self-Convince framework, achieving substantial improvementscompared to the baselines. This study contributes to the burgeoning body ofresearch focused on integrating pre-trained language models with tailoredprompts and iterative refinement processes to augment their performance incomplex tasks.</description><author>Haodi Zhang, Min Cai, Xinhe Zhang, Chen Jason Zhang, Rui Mao, Kaishun Wu</author><pubDate>Tue, 10 Oct 2023 16:03:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05035v2</guid></item><item><title>Confronting Reward Model Overoptimization with Constrained RLHF</title><link>http://arxiv.org/abs/2310.04373v2</link><description>Large language models are typically aligned with human preferences byoptimizing $\textit{reward models}$ (RMs) fitted to human feedback. However,human preferences are multi-faceted, and it is increasingly common to derivereward from a composition of simpler reward models which each capture adifferent aspect of language quality. This itself presents a challenge, as itis difficult to appropriately weight these component RMs when combining them.Compounding this difficulty, because any RM is only a proxy for humanevaluation, this process is vulnerable to $\textit{overoptimization}$, whereinpast a certain point, accumulating higher reward is associated with worse humanratings. In this paper, we perform, to our knowledge, the first study onoveroptimization in composite RMs, showing that correlation between componentRMs has a significant effect on the locations of these points. We thenintroduce an approach to solve this issue using constrained reinforcementlearning as a means of preventing the agent from exceeding each RM's thresholdof usefulness. Our method addresses the problem of weighting component RMs bylearning dynamic weights, naturally expressed by Lagrange multipliers. As aresult, each RM stays within the range at which it is an effective proxy,improving evaluation performance. Finally, we introduce an adaptive methodusing gradient-free optimization to identify and optimize towards these pointsduring a single run.</description><author>Ted Moskovitz, Aaditya K. Singh, DJ Strouse, Tuomas Sandholm, Ruslan Salakhutdinov, Anca D. Dragan, Stephen McAleer</author><pubDate>Tue, 10 Oct 2023 16:01:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.04373v2</guid></item><item><title>Generalized Wick Decompositions</title><link>http://arxiv.org/abs/2310.06686v1</link><description>We review the cumulant decomposition (a way of decomposing the expectation ofa product of random variables (e.g. $\mathbb{E}[XYZ]$) into a sum of termscorresponding to partitions of these variables.) and the Wick decomposition (away of decomposing a product of (not necessarily random) variables into a sumof terms corresponding to subsets of the variables). Then we generalize eachone to a new decomposition where the product function is generalized to anarbitrary function.</description><author>Chris MacLeod, Evgenia Nitishinskaya, Buck Shlegeris</author><pubDate>Tue, 10 Oct 2023 16:00:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06686v1</guid></item><item><title>Learning Multiplex Embeddings on Text-rich Networks with One Text Encoder</title><link>http://arxiv.org/abs/2310.06684v1</link><description>In real-world scenarios, texts in a network are often linked by multiplesemantic relations (e.g., papers in an academic network are referenced by otherpublications, written by the same author, or published in the same venue),where text documents and their relations form a multiplex text-rich network.Mainstream text representation learning methods use pretrained language models(PLMs) to generate one embedding for each text unit, expecting that all typesof relations between texts can be captured by these single-view embeddings.However, this presumption does not hold particularly in multiplex text-richnetworks. Along another line of work, multiplex graph neural networks (GNNs)directly initialize node attributes as a feature vector for node representationlearning, but they cannot fully capture the semantics of the nodes' associatedtexts. To bridge these gaps, we propose METERN, a new framework for learningMultiplex Embeddings on TExt-Rich Networks. In contrast to existing methods,METERN uses one text encoder to model the shared knowledge across relations andleverages a small number of parameters per relation to derive relation-specificrepresentations. This allows the encoder to effectively capture the multiplexstructures in the network while also preserving parameter efficiency. Weconduct experiments on nine downstream tasks in five networks from bothacademic and e-commerce domains, where METERN outperforms baselinessignificantly and consistently. The code is available athttps://github.com/PeterGriffinJin/METERN-submit.</description><author>Bowen Jin, Wentao Zhang, Yu Zhang, Yu Meng, Han Zhao, Jiawei Han</author><pubDate>Tue, 10 Oct 2023 15:59:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06684v1</guid></item><item><title>On the importance of catalyst-adsorbate 3D interactions for relaxed energy predictions</title><link>http://arxiv.org/abs/2310.06682v1</link><description>The use of machine learning for material property prediction and discoveryhas traditionally centered on graph neural networks that incorporate thegeometric configuration of all atoms. However, in practice not all thisinformation may be readily available, e.g.~when evaluating the potentiallyunknown binding of adsorbates to catalyst. In this paper, we investigatewhether it is possible to predict a system's relaxed energy in the OC20 datasetwhile ignoring the relative position of the adsorbate with respect to theelectro-catalyst. We consider SchNet, DimeNet++ and FAENet as basearchitectures and measure the impact of four modifications on modelperformance: removing edges in the input graph, pooling independentrepresentations, not sharing the backbone weights and using an attentionmechanism to propagate non-geometric relative information. We find that whileremoving binding site information impairs accuracy as expected, modified modelsare able to predict relaxed energies with remarkably decent MAE. Our worksuggests future research directions in accelerated materials discovery whereinformation on reactant configurations can be reduced or altogether omitted.</description><author>Alvaro Carbonero, Alexandre Duval, Victor Schmidt, Santiago Miret, Alex Hernandez-Garcia, Yoshua Bengio, David Rolnick</author><pubDate>Tue, 10 Oct 2023 15:57:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06682v1</guid></item><item><title>Self-Correcting Bayesian Optimization through Bayesian Active Learning</title><link>http://arxiv.org/abs/2304.11005v2</link><description>Gaussian processes are the model of choice in Bayesian optimization andactive learning. Yet, they are highly dependent on cleverly chosenhyperparameters to reach their full potential, and little effort is devoted tofinding good hyperparameters in the literature. We demonstrate the impact ofselecting good hyperparameters for GPs and present two acquisition functionsthat explicitly prioritize hyperparameter learning. Statistical distance-basedActive Learning (SAL) considers the average disagreement between samples fromthe posterior, as measured by a statistical distance. SAL outperforms thestate-of-the-art in Bayesian active learning on several test functions. We thenintroduce Self-Correcting Bayesian Optimization (SCoreBO), which extends SAL toperform Bayesian optimization and active learning simultaneously. SCoreBOlearns the model hyperparameters at improved rates compared to vanilla BO,while outperforming the latest Bayesian optimization methods on traditionalbenchmarks. Moreover, we demonstrate the importance of self-correction onatypical Bayesian optimization tasks.</description><author>Carl Hvarfner, Erik Hellsten, Frank Hutter, Luigi Nardi</author><pubDate>Tue, 10 Oct 2023 15:56:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.11005v2</guid></item><item><title>Benchmarking and Explaining Large Language Model-based Code Generation: A Causality-Centric Approach</title><link>http://arxiv.org/abs/2310.06680v1</link><description>While code generation has been widely used in various software developmentscenarios, the quality of the generated code is not guaranteed. This has been aparticular concern in the era of large language models (LLMs)- based codegeneration, where LLMs, deemed a complex and powerful black-box model, isinstructed by a high-level natural language specification, namely a prompt, togenerate code. Nevertheless, effectively evaluating and explaining the codegeneration capability of LLMs is inherently challenging, given the complexityof LLMs and the lack of transparency. Inspired by the recent progress in causality analysis and its application insoftware engineering, this paper launches a causality analysis-based approachto systematically analyze the causal relations between the LLM input promptsand the generated code. To handle various technical challenges in this study,we first propose a novel causal graph-based representation of the prompt andthe generated code, which is established over the fine-grained,human-understandable concepts in the input prompts. The formed causal graph isthen used to identify the causal relations between the prompt and the derivedcode. We illustrate the insights that our framework can provide by studyingover 3 popular LLMs with over 12 prompt adjustment strategies. The results ofthese studies illustrate the potential of our technique to provide insightsinto LLM effectiveness, and aid end-users in understanding predictions.Additionally, we demonstrate that our approach provides actionable insights toimprove the quality of the LLM-generated code by properly calibrating theprompt.</description><author>Zhenlan Ji, Pingchuan Ma, Zongjie Li, Shuai Wang</author><pubDate>Tue, 10 Oct 2023 15:56:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06680v1</guid></item><item><title>Machine Learning Quantum Systems with Magnetic p-bits</title><link>http://arxiv.org/abs/2310.06679v1</link><description>The slowing down of Moore's Law has led to a crisis as the computingworkloads of Artificial Intelligence (AI) algorithms continue skyrocketing.There is an urgent need for scalable and energy-efficient hardware catering tothe unique requirements of AI algorithms and applications. In this environment,probabilistic computing with p-bits emerged as a scalable, domain-specific, andenergy-efficient computing paradigm, particularly useful for probabilisticapplications and algorithms. In particular, spintronic devices such asstochastic magnetic tunnel junctions (sMTJ) show great promise in designingintegrated p-computers. Here, we examine how a scalable probabilistic computerwith such magnetic p-bits can be useful for an emerging field combining machinelearning and quantum physics.</description><author>Shuvro Chowdhury, Kerem Y. Camsari</author><pubDate>Tue, 10 Oct 2023 15:54:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06679v1</guid></item><item><title>Distributed Evolution Strategies with Multi-Level Learning for Large-Scale Black-Box Optimization</title><link>http://arxiv.org/abs/2310.05377v2</link><description>In the post-Moore era, the main performance gains of black-box optimizers areincreasingly depending upon parallelism, especially for large-scaleoptimization (LSO). In this paper, we propose to parallelize thewell-established covariance matrix adaptation evolution strategy (CMA-ES) andin particular its one latest variant called limited-memory CMA (LM-CMA) forLSO. To achieve scalability while maintaining the invariance property as muchas possible, we present a multilevel learning-based meta-framework. Owing toits hierarchically organized structure, Meta-ES is well-suited to implement ourdistributed meta-framework, wherein the outer-ES controls strategy parameterswhile all parallel inner-ESs run the serial LM-CMA with different settings. Forthe distribution mean update of the outer-ES, both the elitist andmulti-recombination strategy are used in parallel to avoid stagnation andregression, respectively. To exploit spatiotemporal information, the globalstep-size adaptation combines Meta-ES with the parallel cumulative step-sizeadaptation. After each isolation time, our meta-framework employs both thestructure and parameter learning strategy to combine aligned evolution pathsfor CMA reconstruction. Experiments on a set of large-scale benchmarkingfunctions with memory-intensive evaluations, arguably reflecting manydata-driven optimization problems, validate the benefits (e.g., scalabilityw.r.t. CPU cores, effectiveness w.r.t. solution quality, and adaptabilityw.r.t. second-order learning) and costs of our meta-framework.</description><author>Qiqi Duan, Chang Shao, Guochen Zhou, Qi Zhao, Yuhui Shi</author><pubDate>Tue, 10 Oct 2023 15:53:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05377v2</guid></item><item><title>SEER: A Knapsack approach to Exemplar Selection for In-Context HybridQA</title><link>http://arxiv.org/abs/2310.06675v1</link><description>Question answering over hybrid contexts is a complex task, which requires thecombination of information extracted from unstructured texts and structuredtables in various ways. Recently, In-Context Learning demonstrated significantperformance advances for reasoning tasks. In this paradigm, a large languagemodel performs predictions based on a small set of supporting exemplars. Theperformance of In-Context Learning depends heavily on the selection procedureof the supporting exemplars, particularly in the case of HybridQA, whereconsidering the diversity of reasoning chains and the large size of the hybridcontexts becomes crucial. In this work, we present Selection of ExEmplars forhybrid Reasoning (SEER), a novel method for selecting a set of exemplars thatis both representative and diverse. The key novelty of SEER is that itformulates exemplar selection as a Knapsack Integer Linear Program. TheKnapsack framework provides the flexibility to incorporate diversityconstraints that prioritize exemplars with desirable attributes, and capacityconstraints that ensure that the prompt size respects the provided capacitybudgets. The effectiveness of SEER is demonstrated on FinQA and TAT-QA, tworeal-world benchmarks for HybridQA, where it outperforms previous exemplarselection methods.</description><author>Jonathan Tonglet, Manon Reusens, Philipp Borchert, Bart Baesens</author><pubDate>Tue, 10 Oct 2023 15:50:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06675v1</guid></item><item><title>Graph-based methods coupled with specific distributional distances for adversarial attack detection</title><link>http://arxiv.org/abs/2306.00042v2</link><description>Artificial neural networks are prone to being fooled by carefully perturbedinputs which cause an egregious misclassification. These \textit{adversarial}attacks have been the focus of extensive research. Likewise, there has been anabundance of research in ways to detect and defend against them. We introduce anovel approach of detection and interpretation of adversarial attacks from agraph perspective. For an input image, we compute an associated sparse graphusing the layer-wise relevance propagation algorithm \cite{bach15}.Specifically, we only keep edges of the neural network with the highestrelevance values. Three quantities are then computed from the graph which arethen compared against those computed from the training set. The result of thecomparison is a classification of the image as benign or adversarial. To makethe comparison, two classification methods are introduced: 1) an explicitformula based on Wasserstein distance applied to the degree of node and 2) alogistic regression. Both classification methods produce strong results whichlead us to believe that a graph-based interpretation of adversarial attacks isvaluable.</description><author>Dwight Nwaigwe, Lucrezia Carboni, Martial Mermillod, Sophie Achard, Michel Dojat</author><pubDate>Tue, 10 Oct 2023 15:48:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00042v2</guid></item><item><title>Making Large Language Models Perform Better in Knowledge Graph Completion</title><link>http://arxiv.org/abs/2310.06671v1</link><description>Large language model (LLM) based knowledge graph completion (KGC) aims topredict the missing triples in the KGs with LLMs and enrich the KGs to becomebetter web infrastructure, which can benefit a lot of web-based automaticservices. However, research about LLM-based KGC is limited and lacks effectiveutilization of LLM's inference capabilities, which ignores the importantstructural information in KGs and prevents LLMs from acquiring accurate factualknowledge. In this paper, we discuss how to incorporate the helpful KGstructural information into the LLMs, aiming to achieve structrual-awarereasoning in the LLMs. We first transfer the existing LLM paradigms tostructural-aware settings and further propose a knowledge prefix adapter (KoPA)to fulfill this stated goal. KoPA employs structural embedding pre-training tocapture the structural information of entities and relations in the KG. ThenKoPA informs the LLMs of the knowledge prefix adapter which projects thestructural embeddings into the textual space and obtains virtual knowledgetokens as a prefix of the input prompt. We conduct comprehensive experiments onthese structural-aware LLM-based KGC methods and provide an in-depth analysiscomparing how the introduction of structural information would be better forLLM's knowledge reasoning ability. Our code is released athttps://github.com/zjukg/KoPA.</description><author>Yichi Zhang, Zhuo Chen, Wen Zhang, Huajun Chen</author><pubDate>Tue, 10 Oct 2023 15:47:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06671v1</guid></item><item><title>Domain Generalization by Rejecting Extreme Augmentations</title><link>http://arxiv.org/abs/2310.06670v1</link><description>Data augmentation is one of the most effective techniques for regularizingdeep learning models and improving their recognition performance in a varietyof tasks and domains. However, this holds for standard in-domain settings, inwhich the training and test data follow the same distribution. For theout-of-domain case, where the test data follow a different and unknowndistribution, the best recipe for data augmentation is unclear. In this paper,we show that for out-of-domain and domain generalization settings, dataaugmentation can provide a conspicuous and robust improvement in performance.To do that, we propose a simple training procedure: (i) use uniform sampling onstandard data augmentation transformations; (ii) increase the strengthtransformations to account for the higher data variance expected when workingout-of-domain, and (iii) devise a new reward function to reject extremetransformations that can harm the training. With this procedure, our dataaugmentation scheme achieves a level of accuracy that is comparable to orbetter than state-of-the-art methods on benchmark domain generalizationdatasets. Code: \url{https://github.com/Masseeh/DCAug}</description><author>Masih Aminbeidokhti, Fidel A. Guerrero PeÃ±a, Heitor Rapela Medeiros, Thomas Dubail, Eric Granger, Marco Pedersoli</author><pubDate>Tue, 10 Oct 2023 15:46:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06670v1</guid></item><item><title>Latent Diffusion Counterfactual Explanations</title><link>http://arxiv.org/abs/2310.06668v1</link><description>Counterfactual explanations have emerged as a promising method forelucidating the behavior of opaque black-box models. Recently, several worksleveraged pixel-space diffusion models for counterfactual generation. To handlenoisy, adversarial gradients during counterfactual generation -- causingunrealistic artifacts or mere adversarial perturbations -- they required eitherauxiliary adversarially robust models or computationally intensive guidanceschemes. However, such requirements limit their applicability, e.g., inscenarios with restricted access to the model's training data. To address theselimitations, we introduce Latent Diffusion Counterfactual Explanations (LDCE).LDCE harnesses the capabilities of recent class- or text-conditional foundationlatent diffusion models to expedite counterfactual generation and focus on theimportant, semantic parts of the data. Furthermore, we propose a novelconsensus guidance mechanism to filter out noisy, adversarial gradients thatare misaligned with the diffusion model's implicit classifier. We demonstratethe versatility of LDCE across a wide spectrum of models trained on diversedatasets with different learning paradigms. Finally, we showcase how LDCE canprovide insights into model errors, enhancing our understanding of black-boxmodel behavior.</description><author>Karim Farid, Simon Schrodi, Max Argus, Thomas Brox</author><pubDate>Tue, 10 Oct 2023 15:42:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06668v1</guid></item><item><title>SC2GAN: Rethinking Entanglement by Self-correcting Correlated GAN Space</title><link>http://arxiv.org/abs/2310.06667v1</link><description>Generative Adversarial Networks (GANs) can synthesize realistic images, withthe learned latent space shown to encode rich semantic information with variousinterpretable directions. However, due to the unstructured nature of thelearned latent space, it inherits the bias from the training data wherespecific groups of visual attributes that are not causally related tend toappear together, a phenomenon also known as spurious correlations, e.g., ageand eyeglasses or women and lipsticks. Consequently, the learned distributionoften lacks the proper modelling of the missing examples. The interpolationfollowing editing directions for one attribute could result in entangledchanges with other attributes. To address this problem, previous workstypically adjust the learned directions to minimize the changes in otherattributes, yet they still fail on strongly correlated features. In this work,we study the entanglement issue in both the training data and the learnedlatent space for the StyleGAN2-FFHQ model. We propose a novel frameworkSC$^2$GAN that achieves disentanglement by re-projecting low-density latentcode samples in the original latent space and correcting the editing directionsbased on both the high-density and low-density regions. By leveraging theoriginal meaningful directions and semantic region-specific layers, ourframework interpolates the original latent codes to generate images withattribute combination that appears infrequently, then inverts these samplesback to the original latent space. We apply our framework to pre-existingmethods that learn meaningful latent directions and showcase its strongcapability to disentangle the attributes with small amounts of low-densityregion samples added.</description><author>Zikun Chen, Han Zhao, Parham Aarabi, Ruowei Jiang</author><pubDate>Tue, 10 Oct 2023 15:42:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06667v1</guid></item><item><title>Unlock the Potential of Counterfactually-Augmented Data in Out-Of-Distribution Generalization</title><link>http://arxiv.org/abs/2310.06666v1</link><description>Counterfactually-Augmented Data (CAD) -- minimal editing of sentences to flipthe corresponding labels -- has the potential to improve theOut-Of-Distribution (OOD) generalization capability of language models, as CADinduces language models to exploit domain-independent causal features andexclude spurious correlations. However, the empirical results of CAD's OODgeneralization are not as efficient as anticipated. In this study, we attributethe inefficiency to the myopia phenomenon caused by CAD: language models onlyfocus on causal features that are edited in the augmentation operation andexclude other non-edited causal features. Therefore, the potential of CAD isnot fully exploited. To address this issue, we analyze the myopia phenomenon infeature space from the perspective of Fisher's Linear Discriminant, then weintroduce two additional constraints based on CAD's structural properties(dataset-level and sentence-level) to help language models extract morecomplete causal features in CAD, thereby mitigating the myopia phenomenon andimproving OOD generalization capability. We evaluate our method on two tasks:Sentiment Analysis and Natural Language Inference, and the experimental resultsdemonstrate that our method could unlock the potential of CAD and improve theOOD generalization performance of language models by 1.0% to 5.9%.</description><author>Caoyun Fan, Wenqing Chen, Jidong Tian, Yitian Li, Hao He, Yaohui Jin</author><pubDate>Tue, 10 Oct 2023 15:41:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06666v1</guid></item><item><title>Understanding Contrastive Learning Through the Lens of Margins</title><link>http://arxiv.org/abs/2306.11526v2</link><description>Contrastive learning, along with its variations, has been a highly effectiveself-supervised learning method across diverse domains. Contrastive learningmeasures the distance between representations using cosine similarity and usescross-entropy for representation learning. Within the same framework ofcosine-similarity-based representation learning, margins have played asignificant role in enhancing face and speaker recognition tasks.Interestingly, despite the shared reliance on the same similarity metrics andobjective functions, contrastive learning has not actively adopted margins.Furthermore, decision-boundary-based explanations are the only ones that havebeen used to explain the effect of margins in contrastive learning. In thiswork, we propose a new perspective to understand the role of margins based ongradient analysis. Based on the new perspective, we analyze how margins affectgradients of contrastive learning and separate the effect into more elementallevels. We separately analyze each and provide possible directions forimproving contrastive learning. Our experimental results demonstrate thatemphasizing positive samples and scaling gradients depending on positive sampleangles and logits are the keys to improving the generalization performance ofcontrastive learning in both seen and unseen datasets, and other factors canonly marginally improve performance.</description><author>Daniel Rho, TaeSoo Kim, Sooill Park, Jaehyun Park, JaeHan Park</author><pubDate>Tue, 10 Oct 2023 15:37:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.11526v2</guid></item><item><title>Tertiary Lymphoid Structures Generation through Graph-based Diffusion</title><link>http://arxiv.org/abs/2310.06661v1</link><description>Graph-based representation approaches have been proven to be successful inthe analysis of biomedical data, due to their capability of capturing intricatedependencies between biological entities, such as the spatial organization ofdifferent cell types in a tumor tissue. However, to further enhance ourunderstanding of the underlying governing biological mechanisms, it isimportant to accurately capture the actual distributions of such complex data.Graph-based deep generative models are specifically tailored to accomplishthat. In this work, we leverage state-of-the-art graph-based diffusion modelsto generate biologically meaningful cell-graphs. In particular, we show thatthe adopted graph diffusion model is able to accurately learn the distributionof cells in terms of their tertiary lymphoid structures (TLS) content, awell-established biomarker for evaluating the cancer progression in oncologyresearch. Additionally, we further illustrate the utility of the learnedgenerative models for data augmentation in a TLS classification task. To thebest of our knowledge, this is the first work that leverages the power of graphdiffusion models in generating meaningful biological cell structures.</description><author>Manuel Madeira, Dorina Thanou, Pascal Frossard</author><pubDate>Tue, 10 Oct 2023 15:37:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06661v1</guid></item><item><title>Memorization of Named Entities in Fine-tuned BERT Models</title><link>http://arxiv.org/abs/2212.03749v2</link><description>Privacy preserving deep learning is an emerging field in machine learningthat aims to mitigate the privacy risks in the use of deep neural networks. Onesuch risk is training data extraction from language models that have beentrained on datasets, which contain personal and privacy sensitive information.In our study, we investigate the extent of named entity memorization infine-tuned BERT models. We use single-label text classification asrepresentative downstream task and employ three different fine-tuning setups inour experiments, including one with Differentially Privacy (DP). We create alarge number of text samples from the fine-tuned BERT models utilizing a customsequential sampling strategy with two prompting strategies. We search in thesesamples for named entities and check if they are also present in thefine-tuning datasets. We experiment with two benchmark datasets in the domainsof emails and blogs. We show that the application of DP has a detrimentaleffect on the text generation capabilities of BERT. Furthermore, we show that afine-tuned BERT does not generate more named entities specific to thefine-tuning dataset than a BERT model that is pre-trained only. This suggeststhat BERT is unlikely to emit personal or privacy sensitive named entities.Overall, our results are important to understand to what extent BERT-basedservices are prone to training data extraction attacks.</description><author>Andor Diera, Nicolas Lell, Aygul Garifullina, Ansgar Scherp</author><pubDate>Tue, 10 Oct 2023 15:32:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.03749v2</guid></item><item><title>Assessing the Impact of a Supervised Classification Filter on Flow-based Hybrid Network Anomaly Detection</title><link>http://arxiv.org/abs/2310.06656v1</link><description>Constant evolution and the emergence of new cyberattacks require thedevelopment of advanced techniques for defense. This paper aims to measure theimpact of a supervised filter (classifier) in network anomaly detection. Weperform our experiments by employing a hybrid anomaly detection approach innetwork flow data. For this purpose, we extended a state-of-the-artautoencoder-based anomaly detection method by prepending a binary classifieracting as a prefilter for the anomaly detector. The method was evaluated on thepublicly available real-world dataset UGR'16. Our empirical results indicatethat the hybrid approach does offer a higher detection rate of known attacksthan a standalone anomaly detector while still retaining the ability to detectzero-day attacks. Employing a supervised binary prefilter has increased the AUCmetric by over 11%, detecting 30% more attacks while keeping the number offalse positives approximately the same.</description><author>Dominik Macko, Patrik Goldschmidt, Peter PiÅ¡tek, Daniela ChudÃ¡</author><pubDate>Tue, 10 Oct 2023 15:30:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06656v1</guid></item><item><title>Evaluating Explanation Methods for Vision-and-Language Navigation</title><link>http://arxiv.org/abs/2310.06654v1</link><description>The ability to navigate robots with natural language instructions in anunknown environment is a crucial step for achieving embodied artificialintelligence (AI). With the improving performance of deep neural modelsproposed in the field of vision-and-language navigation (VLN), it is equallyinteresting to know what information the models utilize for theirdecision-making in the navigation tasks. To understand the inner workings ofdeep neural models, various explanation methods have been developed forpromoting explainable AI (XAI). But they are mostly applied to deep neuralmodels for image or text classification tasks and little work has been done inexplaining deep neural models for VLN tasks. In this paper, we address theseproblems by building quantitative benchmarks to evaluate explanation methodsfor VLN models in terms of faithfulness. We propose a new erasure-basedevaluation pipeline to measure the step-wise textual explanation in thesequential decision-making setting. We evaluate several explanation methods fortwo representative VLN models on two popular VLN datasets and reveal valuablefindings through our experiments.</description><author>Guanqi Chen, Lei Yang, Guanhua Chen, Jia Pan</author><pubDate>Tue, 10 Oct 2023 15:22:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06654v1</guid></item><item><title>Branched Latent Neural Maps</title><link>http://arxiv.org/abs/2308.02599v3</link><description>We introduce Branched Latent Neural Maps (BLNMs) to learn finite dimensionalinput-output maps encoding complex physical processes. A BLNM is defined by asimple and compact feedforward partially-connected neural network thatstructurally disentangles inputs with different intrinsic roles, such as thetime variable from model parameters of a differential equation, whiletransferring them into a generic field of interest. BLNMs leverage latentoutputs to enhance the learned dynamics and break the curse of dimensionalityby showing excellent generalization properties with small training datasets andshort training times on a single processor. Indeed, their generalization errorremains comparable regardless of the adopted discretization during the testingphase. Moreover, the partial connections significantly reduce the number oftunable parameters. We show the capabilities of BLNMs in a challenging testcase involving electrophysiology simulations in a biventricular cardiac modelof a pediatric patient with hypoplastic left heart syndrome. The model includesa 1D Purkinje network for fast conduction and a 3D heart-torso geometry.Specifically, we trained BLNMs on 150 in silico generated 12-leadelectrocardiograms (ECGs) while spanning 7 model parameters, coveringcell-scale and organ-level. Although the 12-lead ECGs manifest very fastdynamics with sharp gradients, after automatic hyperparameter tuning theoptimal BLNM, trained in less than 3 hours on a single CPU, retains just 7hidden layers and 19 neurons per layer. The resulting mean square error is onthe order of $10^{-4}$ on a test dataset comprised of 50 electrophysiologysimulations. In the online phase, the BLNM allows for 5000x faster real-timesimulations of cardiac electrophysiology on a single core standard computer andcan be used to solve inverse problems via global optimization in a few secondsof computational time.</description><author>Matteo Salvador, Alison Lesley Marsden</author><pubDate>Tue, 10 Oct 2023 15:22:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.02599v3</guid></item><item><title>Diversity from Human Feedback</title><link>http://arxiv.org/abs/2310.06648v1</link><description>Diversity plays a significant role in many problems, such as ensemblelearning, reinforcement learning, and combinatorial optimization. How to definethe diversity measure is a longstanding problem. Many methods rely on expertexperience to define a proper behavior space and then obtain the diversitymeasure, which is, however, challenging in many scenarios. In this paper, wepropose the problem of learning a behavior space from human feedback andpresent a general method called Diversity from Human Feedback (DivHF) to solveit. DivHF learns a behavior descriptor consistent with human preference byquerying human feedback. The learned behavior descriptor can be combined withany distance measure to define a diversity measure. We demonstrate theeffectiveness of DivHF by integrating it with the Quality-Diversityoptimization algorithm MAP-Elites and conducting experiments on the QDax suite.The results show that DivHF learns a behavior space that aligns better withhuman requirements compared to direct data-driven approaches and leads to morediverse solutions under human preference. Our contributions include formulatingthe problem, proposing the DivHF method, and demonstrating its effectivenessthrough experiments.</description><author>Ren-Jian Wang, Ke Xue, Yutong Wang, Peng Yang, Haobo Fu, Qiang Fu, Chao Qian</author><pubDate>Tue, 10 Oct 2023 15:13:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06648v1</guid></item><item><title>An Efficient Smoothing and Thresholding Image Segmentation Framework with Weighted Anisotropic-Isotropic Total Variation</title><link>http://arxiv.org/abs/2202.10115v4</link><description>In this paper, we design an efficient, multi-stage image segmentationframework that incorporates a weighted difference of anisotropic and isotropictotal variation (AITV). The segmentation framework generally consists of twostages: smoothing and thresholding, thus referred to as SaT. In the firststage, a smoothed image is obtained by an AITV-regularized Mumford-Shah (MS)model, which can be solved efficiently by the alternating direction method ofmultipliers (ADMM) with a closed-form solution of a proximal operator of the$\ell_1 -\alpha \ell_2$ regularizer. Convergence of the ADMM algorithm isanalyzed. In the second stage, we threshold the smoothed image by $K$-meansclustering to obtain the final segmentation result. Numerical experimentsdemonstrate that the proposed segmentation framework is versatile for bothgrayscale and color images, efficient in producing high-quality segmentationresults within a few seconds, and robust to input images that are corruptedwith noise, blur, or both. We compare the AITV method with its original convexTV and nonconvex TV$^p (0&lt;p&lt;1)$ counterparts, showcasing the qualitative andquantitative advantages of our proposed method.</description><author>Kevin Bui, Yifei Lou, Fredrick Park, Jack Xin</author><pubDate>Tue, 10 Oct 2023 15:12:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.10115v4</guid></item><item><title>Morphologically-Aware Consensus Computation via Heuristics-based IterATive Optimization (MACCHIatO)</title><link>http://arxiv.org/abs/2309.08066v2</link><description>The extraction of consensus segmentations from several binary orprobabilistic masks is important to solve various tasks such as the analysis ofinter-rater variability or the fusion of several neural network outputs. One ofthe most widely used methods to obtain such a consensus segmentation is theSTAPLE algorithm. In this paper, we first demonstrate that the output of thatalgorithm is heavily impacted by the background size of images and the choiceof the prior. We then propose a new method to construct a binary or aprobabilistic consensus segmentation based on the Fr\'{e}chet means ofcarefully chosen distances which makes it totally independent of the imagebackground size. We provide a heuristic approach to optimize this criterionsuch that a voxel's class is fully determined by its voxel-wise distance to thedifferent masks, the connected component it belongs to and the group of raterswho segmented it. We compared extensively our method on several datasets withthe STAPLE method and the naive segmentation averaging method, showing that itleads to binary consensus masks of intermediate size between Majority Votingand STAPLE and to different posterior probabilities than Mask Averaging andSTAPLE methods. Our code is available athttps://gitlab.inria.fr/dhamzaou/jaccardmap .</description><author>Dimitri Hamzaoui, Sarah Montagne, RaphaÃ«le Renard-Penna, Nicholas Ayache, HervÃ© Delingette</author><pubDate>Tue, 10 Oct 2023 15:10:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.08066v2</guid></item><item><title>Revisiting Large Language Models as Zero-shot Relation Extractors</title><link>http://arxiv.org/abs/2310.05028v2</link><description>Relation extraction (RE) consistently involves a certain degree of labeled orunlabeled data even if under zero-shot setting. Recent studies have shown thatlarge language models (LLMs) transfer well to new tasks out-of-the-box simplygiven a natural language prompt, which provides the possibility of extractingrelations from text without any data and parameter tuning. This work focuses onthe study of exploring LLMs, such as ChatGPT, as zero-shot relation extractors.On the one hand, we analyze the drawbacks of existing RE prompts and attempt toincorporate recent prompt techniques such as chain-of-thought (CoT) to improvezero-shot RE. We propose the summarize-and-ask (\textsc{SumAsk}) prompting, asimple prompt recursively using LLMs to transform RE inputs to the effectivequestion answering (QA) format. On the other hand, we conduct comprehensiveexperiments on various benchmarks and settings to investigate the capabilitiesof LLMs on zero-shot RE. Specifically, we have the following findings: (i)\textsc{SumAsk} consistently and significantly improves LLMs performance ondifferent model sizes, benchmarks and settings; (ii) Zero-shot prompting withChatGPT achieves competitive or superior results compared with zero-shot andfully supervised methods; (iii) LLMs deliver promising performance inextracting overlapping relations; (iv) The performance varies greatly regardingdifferent relations. Different from small language models, LLMs are effectivein handling challenge none-of-the-above (NoTA) relation.</description><author>Guozheng Li, Peng Wang, Wenjun Ke</author><pubDate>Tue, 10 Oct 2023 15:09:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05028v2</guid></item><item><title>Self-Supervised Representation Learning for Online Handwriting Text Classification</title><link>http://arxiv.org/abs/2310.06645v1</link><description>Self-supervised learning offers an efficient way of extracting richrepresentations from various types of unlabeled data while avoiding the cost ofannotating large-scale datasets. This is achievable by designing a pretext taskto form pseudo labels with respect to the modality and domain of the data.Given the evolving applications of online handwritten texts, in this study, wepropose the novel Part of Stroke Masking (POSM) as a pretext task forpretraining models to extract informative representations from the onlinehandwriting of individuals in English and Chinese languages, along with twosuggested pipelines for fine-tuning the pretrained models. To evaluate thequality of the extracted representations, we use both intrinsic and extrinsicevaluation methods. The pretrained models are fine-tuned to achievestate-of-the-art results in tasks such as writer identification, genderclassification, and handedness classification, also highlighting thesuperiority of utilizing the pretrained models over the models trained fromscratch.</description><author>Pouya Mehralian, Bagher BabaAli, Ashena Gorgan Mohammadi</author><pubDate>Tue, 10 Oct 2023 15:07:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06645v1</guid></item><item><title>Zero-Level-Set Encoder for Neural Distance Fields</title><link>http://arxiv.org/abs/2310.06644v1</link><description>Neural shape representation generally refers to representing 3D geometryusing neural networks, e.g., to compute a signed distance or occupancy value ata specific spatial position. Previous methods tend to rely on the auto-decoderparadigm, which often requires densely-sampled and accurate signed distances tobe known during training and testing, as well as an additional optimizationloop during inference. This introduces a lot of computational overhead, inaddition to having to compute signed distances analytically, even duringtesting. In this paper, we present a novel encoder-decoder neural network forembedding 3D shapes in a single forward pass. Our architecture is based on amulti-scale hybrid system incorporating graph-based and voxel-based components,as well as a continuously differentiable decoder. Furthermore, the network istrained to solve the Eikonal equation and only requires knowledge of thezero-level set for training and inference. Additional volumetric samples can begenerated on-the-fly, and incorporated in an unsupervised manner. This meansthat in contrast to most previous work, our network is able to output validsigned distance fields without explicit prior knowledge of non-zero distancevalues or shape occupancy. In other words, our network computes approximatesolutions to the boundary-valued Eikonal equation. It also requires only asingle forward pass during inference, instead of the common latent codeoptimization. We further propose a modification of the loss function in casethat surface normals are not well defined, e.g., in the context ofnon-watertight surface-meshes and non-manifold geometry. We finally demonstratethe efficacy, generalizability and scalability of our method on datasetsconsisting of deforming 3D shapes, single class encoding and multiclassencoding, showcasing a wide range of possible applications.</description><author>Stefan Rhys Jeske, Jonathan Klein, Dominik L. Michels, Jan Bender</author><pubDate>Tue, 10 Oct 2023 15:07:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06644v1</guid></item><item><title>Implicit Variational Inference for High-Dimensional Posteriors</title><link>http://arxiv.org/abs/2310.06643v1</link><description>In variational inference, the benefits of Bayesian models rely on accuratelycapturing the true posterior distribution. We propose using neural samplersthat specify implicit distributions, which are well-suited for approximatingcomplex multimodal and correlated posteriors in high-dimensional spaces. Ourapproach advances inference using implicit distributions by introducing novelbounds that come about by locally linearising the neural sampler. This isdistinct from existing methods that rely on additional discriminator networksand unstable adversarial objectives. Furthermore, we present a new samplerarchitecture that, for the first time, enables implicit distributions overmillions of latent variables, addressing computational concerns by usingdifferentiable numerical approximations. Our empirical analysis indicates ourmethod is capable of recovering correlations across layers in large Bayesianneural networks, a property that is crucial for a network's performance butnotoriously challenging to achieve. To the best of our knowledge, no othermethod has been shown to accomplish this task for such large models. Throughexperiments in downstream tasks, we demonstrate that our expressive posteriorsoutperform state-of-the-art uncertainty quantification methods, validating theeffectiveness of our training algorithm and the quality of the learned implicitapproximation.</description><author>Anshuk Uppal, Kristoffer Stensbo-Smidt, Wouter K. Boomsma, Jes Frellsen</author><pubDate>Tue, 10 Oct 2023 15:06:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06643v1</guid></item><item><title>How (not) to ensemble LVLMs for VQA</title><link>http://arxiv.org/abs/2310.06641v1</link><description>This paper studies ensembling in the era of Large Vision-Language Models(LVLMs). Ensembling is a classical method to combine different models to getincreased performance. In the recent work on Encyclopedic-VQA the authorsexamine a wide variety of models to solve their task: from vanilla LVLMs, tomodels including the caption as extra context, to models augmented withLens-based retrieval of Wikipedia pages. Intuitively these models are highlycomplementary, which should make them ideal for ensembling. Indeed, an oracleexperiment shows potential gains from 48.8% accuracy (the best single model)all the way up to 67% (best possible ensemble). So it is a trivial exercise tocreate an ensemble with substantial real gains. Or is it?</description><author>Lisa Alazraki, Lluis Castrejon, Mostafa Dehghani, Fantine Huot, Jasper Uijlings, Thomas Mensink</author><pubDate>Tue, 10 Oct 2023 15:04:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06641v1</guid></item><item><title>The Lattice Overparametrization Paradigm for the Machine Learning of Lattice Operators</title><link>http://arxiv.org/abs/2310.06639v1</link><description>The machine learning of lattice operators has three possible bottlenecks.From a statistical standpoint, it is necessary to design a constrained class ofoperators based on prior information with low bias, and low complexity relativeto the sample size. From a computational perspective, there should be anefficient algorithm to minimize an empirical error over the class. From anunderstanding point of view, the properties of the learned operator need to bederived, so its behavior can be theoretically understood. The statisticalbottleneck can be overcome due to the rich literature about the representationof lattice operators, but there is no general learning algorithm for them. Inthis paper, we discuss a learning paradigm in which, by overparametrizing aclass via elements in a lattice, an algorithm for minimizing functions in alattice is applied to learn. We present the stochastic lattice gradient descentalgorithm as a general algorithm to learn on constrained classes of operatorsas long as a lattice overparametrization of it is fixed, and we discussprevious works which are proves of concept. Moreover, if there are algorithmsto compute the basis of an operator from its overparametrization, then itsproperties can be deduced and the understanding bottleneck is also overcome.This learning paradigm has three properties that modern methods based on neuralnetworks lack: control, transparency and interpretability. Nowadays, there isan increasing demand for methods with these characteristics, and we believethat mathematical morphology is in a unique position to supply them. Thelattice overparametrization paradigm could be a missing piece for it to achieveits full potential within modern machine learning.</description><author>Diego Marcondes, Junior Barrera</author><pubDate>Tue, 10 Oct 2023 15:00:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06639v1</guid></item><item><title>Blind Dates: Examining the Expression of Temporality in Historical Photographs</title><link>http://arxiv.org/abs/2310.06633v1</link><description>This paper explores the capacity of computer vision models to discerntemporal information in visual content, focusing specifically on historicalphotographs. We investigate the dating of images using OpenCLIP, an open-sourceimplementation of CLIP, a multi-modal language and vision model. Our experimentconsists of three steps: zero-shot classification, fine-tuning, and analysis ofvisual content. We use the \textit{De Boer Scene Detection} dataset, containing39,866 gray-scale historical press photographs from 1950 to 1999. The resultsshow that zero-shot classification is relatively ineffective for image dating,with a bias towards predicting dates in the past. Fine-tuning OpenCLIP with alogistic classifier improves performance and eliminates the bias. Additionally,our analysis reveals that images featuring buses, cars, cats, dogs, and peopleare more accurately dated, suggesting the presence of temporal markers. Thestudy highlights the potential of machine learning models like OpenCLIP indating images and emphasizes the importance of fine-tuning for accuratetemporal analysis. Future research should explore the application of thesefindings to color photographs and diverse datasets.</description><author>Alexandra BarancovÃ¡, Melvin Wevers, Nanne van Noord</author><pubDate>Tue, 10 Oct 2023 14:51:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06633v1</guid></item><item><title>EViT: An Eagle Vision Transformer with Bi-Fovea Self-Attention</title><link>http://arxiv.org/abs/2310.06629v1</link><description>Because of the advancement of deep learning technology, vision transformerhas demonstrated competitive performance in various computer vision tasks.Unfortunately, vision transformer still faces some challenges such as highcomputational complexity and absence of desirable inductive bias. To alleviatethese problems, this study proposes a novel Bi-Fovea Self-Attention (BFSA)inspired by the physiological structure and characteristics of bi-fovea visionin eagle eyes. This BFSA can simulate the shallow fovea and deep foveafunctions of eagle vision, enabling the network to extract featurerepresentations of targets from coarse to fine, facilitating the interaction ofmulti-scale feature representations. Additionally, this study designs a BionicEagle Vision (BEV) block based on BFSA and CNN. It combines CNN and VisionTransformer, to enhance the network's local and global representation abilityfor targets. Furthermore, this study develops a unified and efficient generalpyramid backbone network family, named Eagle Vision Transformers (EViTs) bystacking the BEV blocks. Experimental results on various computer vision tasksincluding image classification, object detection, instance segmentation andother transfer learning tasks show that the proposed EViTs performsignificantly better than the baselines under similar model sizes, whichexhibits faster speed on graphics processing unit compared to other models.Code will be released at https://github.com/nkusyl.</description><author>Yulong Shi, Mingwei Sun, Yongshuai Wang, Rui Wang, Hui Sun, Zengqiang Chen</author><pubDate>Tue, 10 Oct 2023 14:48:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06629v1</guid></item><item><title>DocumentNet: Bridging the Data Gap in Document Pre-Training</title><link>http://arxiv.org/abs/2306.08937v2</link><description>Document understanding tasks, in particular, Visually-rich Document EntityRetrieval (VDER), have gained significant attention in recent years thanks totheir broad applications in enterprise AI. However, publicly available datahave been scarce for these tasks due to strict privacy constraints and highannotation costs. To make things worse, the non-overlapping entity spaces fromdifferent datasets hinder the knowledge transfer between document types. Inthis paper, we propose a method to collect massive-scale and weakly labeleddata from the web to benefit the training of VDER models. The collecteddataset, named DocumentNet, does not depend on specific document types orentity sets, making it universally applicable to all VDER tasks. The currentDocumentNet consists of 30M documents spanning nearly 400 document typesorganized in a four-level ontology. Experiments on a set of broadly adoptedVDER tasks show significant improvements when DocumentNet is incorporated intothe pre-training for both classic and few-shot learning settings. With therecent emergence of large language models (LLMs), DocumentNet provides a largedata source to extend their multi-modal capabilities for VDER.</description><author>Lijun Yu, Jin Miao, Xiaoyu Sun, Jiayi Chen, Alexander G. Hauptmann, Hanjun Dai, Wei Wei</author><pubDate>Tue, 10 Oct 2023 14:48:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08937v2</guid></item><item><title>Deep Cardiac MRI Reconstruction with ADMM</title><link>http://arxiv.org/abs/2310.06628v1</link><description>Cardiac magnetic resonance imaging is a valuable non-invasive tool foridentifying cardiovascular diseases. For instance, Cine MRI is the benchmarkmodality for assessing the cardiac function and anatomy. On the other hand,multi-contrast (T1 and T2) mapping has the potential to assess pathologies andabnormalities in the myocardium and interstitium. However, voluntarybreath-holding and often arrhythmia, in combination with MRI's slow imagingspeed, can lead to motion artifacts, hindering real-time acquisition imagequality. Although performing accelerated acquisitions can facilitate dynamicimaging, it induces aliasing, causing low reconstructed image quality in CineMRI and inaccurate T1 and T2 mapping estimation. In this work, inspired byrelated work in accelerated MRI reconstruction, we present a deep learning(DL)-based method for accelerated cine and multi-contrast reconstruction in thecontext of dynamic cardiac imaging. We formulate the reconstruction problem asa least squares regularized optimization task, and employ vSHARP, astate-of-the-art DL-based inverse problem solver, which incorporateshalf-quadratic variable splitting and the alternating direction method ofmultipliers with neural networks. We treat the problem in two setups; a 2Dreconstruction and a 2D dynamic reconstruction task, and employ 2D and 3D deeplearning networks, respectively. Our method optimizes in both the image andk-space domains, allowing for high reconstruction fidelity. Although the targetdata is undersampled with a Cartesian equispaced scheme, we train our modelusing both Cartesian and simulated non-Cartesian undersampling schemes toenhance generalization of the model to unseen data. Furthermore, our modeladopts a deep neural network to learn and refine the sensitivity maps ofmulti-coil k-space data. Lastly, our method is jointly trained on both,undersampled cine and multi-contrast data.</description><author>George Yiasemis, Nikita Moriakov, Jan-Jakob Sonke, Jonas Teuwen</author><pubDate>Tue, 10 Oct 2023 14:46:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06628v1</guid></item></channel></rss>