<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Tue, 23 Jan 2024 06:00:19 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Exploring Simple Open-Vocabulary Semantic Segmentation</title><link>http://arxiv.org/abs/2401.12217v1</link><description>Open-vocabulary semantic segmentation models aim to accurately assign asemantic label to each pixel in an image from a set of arbitraryopen-vocabulary texts. In order to learn such pixel-level alignment, currentapproaches typically rely on a combination of (i) image-level VL model (e.g.CLIP), (ii) ground truth masks, and (iii) custom grouping encoders. In thispaper, we introduce S-Seg, a novel model that can achieve surprisingly strongperformance without depending on any of the above elements. S-Seg leveragespseudo-mask and language to train a MaskFormer, and can be easily trained frompublicly available image-text datasets. Contrary to prior works, our modeldirectly trains for pixel-level features and language alignment. Once trained,S-Seg generalizes well to multiple testing datasets without requiringfine-tuning. In addition, S-Seg has the extra benefits of scalability with dataand consistently improvement when augmented with self-training. We believe thatour simple yet effective approach will serve as a solid baseline for futureresearch.</description><author>Zihang Lai</author><pubDate>Mon, 22 Jan 2024 18:59:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12217v1</guid></item><item><title>Mitigating Covariate Shift in Misspecified Regression with Applications to Reinforcement Learning</title><link>http://arxiv.org/abs/2401.12216v1</link><description>A pervasive phenomenon in machine learning applications is distributionshift, where training and deployment conditions for a machine learning modeldiffer. As distribution shift typically results in a degradation inperformance, much attention has been devoted to algorithmic interventions thatmitigate these detrimental effects. In this paper, we study the effect ofdistribution shift in the presence of model misspecification, specificallyfocusing on $L_{\infty}$-misspecified regression and adversarial covariateshift, where the regression target remains fixed while the covariatedistribution changes arbitrarily. We show that empirical risk minimization, orstandard least squares regression, can result in undesirable misspecificationamplification where the error due to misspecification is amplified by thedensity ratio between the training and testing distributions. As our mainresult, we develop a new algorithm -- inspired by robust optimizationtechniques -- that avoids this undesirable behavior, resulting in nomisspecification amplification while still obtaining optimal statistical rates.As applications, we use this regression procedure to obtain new guarantees inoffline and online reinforcement learning with misspecification and establishnew separations between previously studied structural conditions and notions ofcoverage.</description><author>Philip Amortila, Tongyi Cao, Akshay Krishnamurthy</author><pubDate>Mon, 22 Jan 2024 18:59:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12216v1</guid></item><item><title>Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical Vision Foundation Models</title><link>http://arxiv.org/abs/2401.12215v1</link><description>Parameter-efficient fine-tuning (PEFT) that was initially developed forexploiting pre-trained large language models has recently emerged as aneffective approach to perform transfer learning on computer vision tasks.However, the effectiveness of PEFT on medical vision foundation models is stillunclear and remains to be explored. As a proof of concept, we conducted adetailed empirical study on applying PEFT to chest radiography foundationmodels. Specifically, we delved into LoRA, a representative PEFT method, andcompared it against full-parameter fine-tuning (FFT) on two self-supervisedradiography foundation models across three well-established chest radiographdatasets. Our results showed that LoRA outperformed FFT in 13 out of 18transfer learning tasks by at most 2.9% using fewer than 1% tunable parameters.Combining LoRA with foundation models, we set up new state-of-the-art on arange of data-efficient learning tasks, such as an AUROC score of 80.6% using1% labeled data on NIH ChestX-ray14. We hope this study can evoke moreattention from the community in the use of PEFT for transfer learning onmedical imaging tasks. Code and models are available athttps://github.com/RL4M/MED-PEFT.</description><author>Chenyu Lian, Hong-Yu Zhou, Yizhou Yu, Liansheng Wang</author><pubDate>Mon, 22 Jan 2024 18:59:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12215v1</guid></item><item><title>Mind Your Format: Towards Consistent Evaluation of In-Context Learning Improvements</title><link>http://arxiv.org/abs/2401.06766v2</link><description>Large language models demonstrate a remarkable capability for learning tosolve new tasks from a few examples. The prompt template, or the way the inputexamples are formatted to obtain the prompt, is an important yet oftenoverlooked aspect of in-context learning. In this work, we conduct acomprehensive study of the template format's influence on the in-contextlearning performance. We evaluate the impact of the prompt template acrossmodels (from 770M to 70B parameters) and 4 standard classification datasets. Weshow that a poor choice of the template can reduce the performance of thestrongest models and inference methods to a random guess level. Moreimportantly, the best templates do not transfer between different setups andeven between models of the same family. Our findings show that the currentlyprevalent approach to evaluation, which ignores template selection, may givemisleading results due to different templates in different works. As a firststep towards mitigating this issue, we propose Template Ensembles thataggregate model predictions across several templates. This simple test-timeaugmentation boosts average performance while being robust to the choice ofrandom set of templates.</description><author>Anton Voronov, Lena Wolf, Max Ryabinin</author><pubDate>Mon, 22 Jan 2024 18:55:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06766v2</guid></item><item><title>Large Language Models Should Ask Clarifying Questions to Increase Confidence in Generated Code</title><link>http://arxiv.org/abs/2308.13507v2</link><description>Large language models (LLMs) have significantly improved the ability toperform tasks in the field of code generation. However, there is still a gapbetween LLMs being capable coders and being top-tier software engineers. Basedon the observation that toplevel software engineers often ask clarifyingquestions to reduce ambiguity in both requirements and coding solutions, Iargue that the same should be applied to LLMs for code generation tasks. Byasking probing questions in various topics before generating the final code,the challenges of programming with LLMs, such as unclear intent specification,lack of computational thinking, and undesired code quality, may be alleviated.This, in turn, increases confidence in the generated code. In this work, Iexplore how to leverage better communication skills to achieve greaterconfidence in generated code. I propose a communication-centered process thatuses an LLM-generated communicator to identify issues with high ambiguity orlow confidence in problem descriptions and generated code. I then askclarifying questions to obtain responses from users for refining the code.</description><author>Jie JW Wu</author><pubDate>Mon, 22 Jan 2024 18:54:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.13507v2</guid></item><item><title>Beyond Task Performance: Evaluating and Reducing the Flaws of Large Multimodal Models with In-Context Learning</title><link>http://arxiv.org/abs/2310.00647v2</link><description>Following the success of Large Language Models (LLMs), Large MultimodalModels (LMMs), such as the Flamingo model and its subsequent competitors, havestarted to emerge as natural steps towards generalist agents. However,interacting with recent LMMs reveals major limitations that are hardly capturedby the current evaluation benchmarks. Indeed, task performances (e.g., VQAaccuracy) alone do not provide enough clues to understand their realcapabilities, limitations, and to which extent such models are aligned to humanexpectations. To refine our understanding of those flaws, we deviate from thecurrent evaluation paradigm, and (1) evaluate 10 recent open-source LMMs from3B up to 80B parameter scale, on 5 different axes; hallucinations, abstention,compositionality, explainability and instruction following. Our evaluation onthese axes reveals major flaws in LMMs. While the current go-to solution toalign these models is based on training, such as instruction tuning or RLHF, werather (2) explore the training-free in-context learning (ICL) as a solution,and study how it affects these limitations. Based on our ICL study, (3) we pushICL further and propose new multimodal ICL variants such as; Multitask-ICL,Chain-of-Hindsight-ICL, and Self-Correcting-ICL. Our findings are as follows.(1) Despite their success, LMMs have flaws that remain unsolved with scalingalone. (2) The effect of ICL on LMMs flaws is nuanced; despite itseffectiveness for improved explainability, answer abstention, ICL only slightlyimproves instruction following, does not improve compositional abilities, andactually even amplifies hallucinations. (3) The proposed ICL variants arepromising as post-hoc approaches to efficiently tackle some of those flaws. Thecode is available here: https://github.com/mshukor/EvALign-ICL.</description><author>Mustafa Shukor, Alexandre Rame, Corentin Dancette, Matthieu Cord</author><pubDate>Mon, 22 Jan 2024 18:53:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00647v2</guid></item><item><title>DiarizationLM: Speaker Diarization Post-Processing with Large Language Models</title><link>http://arxiv.org/abs/2401.03506v3</link><description>In this paper, we introduce DiarizationLM, a framework to leverage largelanguage models (LLM) to post-process the outputs from a speaker diarizationsystem. Various goals can be achieved with the proposed framework, such asimproving the readability of the diarized transcript, or reducing the worddiarization error rate (WDER). In this framework, the outputs of the automaticspeech recognition (ASR) and speaker diarization systems are represented as acompact textual format, which is included in the prompt to an optionallyfinetuned LLM. The outputs of the LLM can be used as the refined diarizationresults with the desired enhancement. As a post-processing step, this frameworkcan be easily applied to any off-the-shelf ASR and speaker diarization systemswithout retraining existing components. Our experiments show that a finetunedPaLM 2-S model can reduce the WDER by rel. 55.5% on the Fisher telephoneconversation dataset, and rel. 44.9% on the Callhome English dataset.</description><author>Quan Wang, Yiling Huang, Guanlong Zhao, Evan Clark, Wei Xia, Hank Liao</author><pubDate>Mon, 22 Jan 2024 18:53:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03506v3</guid></item><item><title>Connecting the Dots: Leveraging Spatio-Temporal Graph Neural Networks for Accurate Bangla Sign Language Recognition</title><link>http://arxiv.org/abs/2401.12210v1</link><description>Recent advances in Deep Learning and Computer Vision have been successfullyleveraged to serve marginalized communities in various contexts. One such areais Sign Language - a primary means of communication for the deaf community.However, so far, the bulk of research efforts and investments have gone intoAmerican Sign Language, and research activity into low-resource sign languages- especially Bangla Sign Language - has lagged significantly. In this researchpaper, we present a new word-level Bangla Sign Language dataset - BdSL40 -consisting of 611 videos over 40 words, along with two different approaches:one with a 3D Convolutional Neural Network model and another with a novel GraphNeural Network approach for the classification of BdSL40 dataset. This is thefirst study on word-level BdSL recognition, and the dataset was transcribedfrom Indian Sign Language (ISL) using the Bangla Sign Language Dictionary(1997). The proposed GNN model achieved an F1 score of 89%. The studyhighlights the significant lexical and semantic similarity between BdSL, WestBengal Sign Language, and ISL, and the lack of word-level datasets for BdSL inthe literature. We release the dataset and source code to stimulate furtherresearch.</description><author>Haz Sameen Shahgir, Khondker Salman Sayeed, Md Toki Tahmid, Tanjeem Azwad Zaman, Md. Zarif Ul Alam</author><pubDate>Mon, 22 Jan 2024 18:52:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12210v1</guid></item><item><title>CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation</title><link>http://arxiv.org/abs/2401.12208v1</link><description>Chest X-rays (CXRs) are the most frequently performed imaging test inclinical practice. Recent advances in the development of vision-languagefoundation models (FMs) give rise to the possibility of performing automatedCXR interpretation, which can assist physicians with clinical decision-makingand improve patient outcomes. However, developing FMs that can accuratelyinterpret CXRs is challenging due to the (1) limited availability oflarge-scale vision-language datasets in the medical image domain, (2) lack ofvision and language encoders that can capture the complexities of medical data,and (3) absence of evaluation frameworks for benchmarking the abilities of FMson CXR interpretation. In this work, we address these challenges by firstintroducing \emph{CheXinstruct} - a large-scale instruction-tuning datasetcurated from 28 publicly-available datasets. We then present \emph{CheXagent} -an instruction-tuned FM capable of analyzing and summarizing CXRs. To buildCheXagent, we design a clinical large language model (LLM) for parsingradiology reports, a vision encoder for representing CXR images, and a networkto bridge the vision and language modalities. Finally, we introduce\emph{CheXbench} - a novel benchmark designed to systematically evaluate FMsacross 8 clinically-relevant CXR interpretation tasks. Extensive quantitativeevaluations and qualitative reviews with five expert radiologists demonstratethat CheXagent outperforms previously-developed general- and medical-domain FMson CheXbench tasks. Furthermore, in an effort to improve model transparency, weperform a fairness evaluation across factors of sex, race and age to highlightpotential performance disparities. Our project is at\url{https://stanford-aimi.github.io/chexagent.html}.</description><author>Zhihong Chen, Maya Varma, Jean-Benoit Delbrouck, Magdalini Paschali, Louis Blankemeier, Dave Van Veen, Jeya Maria Jose Valanarasu, Alaa Youssef, Joseph Paul Cohen, Eduardo Pontes Reis, Emily B. Tsai, Andrew Johnston, Cameron Olsen, Tanishq Mathew Abraham, Sergios Gatidis, Akshay S. Chaudhari, Curtis Langlotz</author><pubDate>Mon, 22 Jan 2024 18:51:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12208v1</guid></item><item><title>Rate-Distortion-Perception Tradeoff Based on the Conditional-Distribution Perception Measure</title><link>http://arxiv.org/abs/2401.12207v1</link><description>We study the rate-distortion-perception (RDP) tradeoff for a memorylesssource model in the asymptotic limit of large block-lengths. Our perceptionmeasure is based on a divergence between the distributions of the source andreconstruction sequences conditioned on the encoder output, which was firstproposed in [1], [2]. We consider the case when there is no shared randomnessbetween the encoder and the decoder. For the case of discrete memorylesssources we derive a single-letter characterization of the RDP function, thussettling a problem that remains open for the marginal metric introduced in Blauand Michaeli [3] (with no shared randomness). Our achievability scheme is basedon lossy source coding with a posterior reference map proposed in [4]. For thecase of continuous valued sources under squared error distortion measure andsquared quadratic Wasserstein perception measure we also derive a single-lettercharacterization and show that a noise-adding mechanism at the decoder sufficesto achieve the optimal representation. For the case of zero perception loss, weshow that our characterization interestingly coincides with the results for themarginal metric derived in [5], [6] and again demonstrate that zero perceptionloss can be achieved with a $3$-dB penalty in the minimum distortion. Finallywe specialize our results to the case of Gaussian sources. We derive the RDPfunction for vector Gaussian sources and propose a waterfilling type solution.We also partially characterize the RDP function for a mixture of vectorGaussians.</description><author>Sadaf Salehkalaibar, Jun Chen, Ashish Khisti, Wei Yu</author><pubDate>Mon, 22 Jan 2024 18:49:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12207v1</guid></item><item><title>Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization</title><link>http://arxiv.org/abs/2401.12205v1</link><description>Logic synthesis, a pivotal stage in chip design, entails optimizing chipspecifications encoded in hardware description languages like Verilog intohighly efficient implementations using Boolean logic gates. The processinvolves a sequential application of logic minimization heuristics (``synthesisrecipe"), with their arrangement significantly impacting crucial metrics suchas area and delay. Addressing the challenge posed by the broad spectrum ofdesign complexities - from variations of past designs (e.g., adders andmultipliers) to entirely novel configurations (e.g., innovative processorinstructions) - requires a nuanced `synthesis recipe` guided by human expertiseand intuition. This study conducts a thorough examination of learning andsearch techniques for logic synthesis, unearthing a surprising revelation:pre-trained agents, when confronted with entirely novel designs, may veer offcourse, detrimentally affecting the search trajectory. We present ABC-RL, ameticulously tuned $\alpha$ parameter that adeptly adjusts recommendations frompre-trained agents during the search process. Computed based on similarityscores through nearest neighbor retrieval from the training dataset, ABC-RLyields superior synthesis recipes tailored for a wide array of hardwaredesigns. Our findings showcase substantial enhancements in theQuality-of-result (QoR) of synthesized circuits, boasting improvements of up to24.8% compared to state-of-the-art techniques. Furthermore, ABC-RL achieves animpressive up to 9x reduction in runtime (iso-QoR) when compared to currentstate-of-the-art methodologies.</description><author>Animesh Basak Chowdhury, Marco Romanelli, Benjamin Tan, Ramesh Karri, Siddharth Garg</author><pubDate>Mon, 22 Jan 2024 18:46:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12205v1</guid></item><item><title>Unsupervised Machine Learning for the Classification of Astrophysical X-ray Sources</title><link>http://arxiv.org/abs/2401.12203v1</link><description>The automatic classification of X-ray detections is a necessary step inextracting astrophysical information from compiled catalogs of astrophysicalsources. Classification is useful for the study of individual objects,statistics for population studies, as well as for anomaly detection, i.e., theidentification of new unexplored phenomena, including transients and spectrallyextreme sources. Despite the importance of this task, classification remainschallenging in X-ray astronomy due to the lack of optical counterparts andrepresentative training sets. We develop an alternative methodology thatemploys an unsupervised machine learning approach to provide probabilisticclasses to Chandra Source Catalog sources with a limited number of labeledsources, and without ancillary information from optical and infrared catalogs.We provide a catalog of probabilistic classes for 8,756 sources, comprising atotal of 14,507 detections, and demonstrate the success of the method atidentifying emission from young stellar objects, as well as distinguishingbetween small-scale and large-scale compact accretors with a significant levelof confidence. We investigate the consistency between the distribution offeatures among classified objects and well-established astrophysical hypothesessuch as the unified AGN model. This provides interpretability to theprobabilistic classifier. Code and tables are available publicly throughGitHub. We provide a web playground for readers to explore our finalclassification at https://umlcaxs-playground.streamlit.app.</description><author>Víctor Samuel Pérez-Díaz, Juan Rafael Martínez-Galarza, Alexander Caicedo, Raffaele D'Abrusco</author><pubDate>Mon, 22 Jan 2024 18:42:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12203v1</guid></item><item><title>OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics</title><link>http://arxiv.org/abs/2401.12202v1</link><description>Remarkable progress has been made in recent years in the fields of vision,language, and robotics. We now have vision models capable of recognizingobjects based on language queries, navigation systems that can effectivelycontrol mobile systems, and grasping models that can handle a wide range ofobjects. Despite these advancements, general-purpose applications of roboticsstill lag behind, even though they rely on these fundamental capabilities ofrecognition, navigation, and grasping. In this paper, we adopt a systems-firstapproach to develop a new Open Knowledge-based robotics framework calledOK-Robot. By combining Vision-Language Models (VLMs) for object detection,navigation primitives for movement, and grasping primitives for objectmanipulation, OK-Robot offers a integrated solution for pick-and-dropoperations without requiring any training. To evaluate its performance, we runOK-Robot in 10 real-world home environments. The results demonstrate thatOK-Robot achieves a 58.5% success rate in open-ended pick-and-drop tasks,representing a new state-of-the-art in Open Vocabulary Mobile Manipulation(OVMM) with nearly 1.8x the performance of prior work. On cleaner, unclutteredenvironments, OK-Robot's performance increases to 82%. However, the mostimportant insight gained from OK-Robot is the critical role of nuanced detailswhen combining Open Knowledge systems like VLMs with robotic modules. Videos ofour experiments are available on our website: https://ok-robot.github.io</description><author>Peiqi Liu, Yaswanth Orru, Chris Paxton, Nur Muhammad Mahi Shafiullah, Lerrel Pinto</author><pubDate>Mon, 22 Jan 2024 18:42:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12202v1</guid></item><item><title>APT: Adaptive Pruning and Tuning Pretrained Language Models for Efficient Training and Inference</title><link>http://arxiv.org/abs/2401.12200v1</link><description>Fine-tuning and inference with large Language Models (LM) are generally knownto be expensive. Parameter-efficient fine-tuning over pretrained LMs reducestraining memory by updating a small number of LM parameters but does notimprove inference efficiency. Structured pruning improves LM inferenceefficiency by removing consistent parameter blocks, yet often increasestraining memory and time. To improve both training and inference efficiency, weintroduce APT that adaptively prunes and tunes parameters for the LMs. At theearly stage of fine-tuning, APT dynamically adds salient tuning parameters forfast and accurate convergence while discarding unimportant parameters forefficiency. Compared to baselines, our experiments show that APT maintains upto 98% task performance when pruning RoBERTa and T5 models with 40% parametersleft while keeping 86.4% LLaMA models' performance with 70% parametersremained. Furthermore, APT speeds up LMs fine-tuning by up to 8x and reduceslarge LMs memory training footprint by up to 70%.</description><author>Bowen Zhao, Hannaneh Hajishirzi, Qingqing Cao</author><pubDate>Mon, 22 Jan 2024 18:39:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12200v1</guid></item><item><title>LONEStar: The Lunar Flashlight Optical Navigation Experiment</title><link>http://arxiv.org/abs/2401.12198v1</link><description>This paper documents the results from the highly successful Lunar flashlightOptical Navigation Experiment with a Star tracker (LONEStar). Launched inDecember 2022, Lunar Flashlight (LF) was a NASA-funded technology demonstrationmission. After a propulsion system anomaly prevented capture in lunar orbit, LFwas ejected from the Earth-Moon system and into heliocentric space. NASAsubsequently transferred ownership of LF to Georgia Tech to conduct an unfundedextended mission to demonstrate further advanced technology objectives,including LONEStar. From August-December 2023, the LONEStar team performedon-orbit calibration of the optical instrument and a number of different OPNAVexperiments. This campaign included the processing of nearly 400 images of starfields, Earth and Moon, and four other planets (Mercury, Mars, Jupiter, andSaturn). LONEStar provided the first on-orbit demonstrations of heliocentricnavigation using only optical observations of planets. Of special note is thesuccessful in-flight demonstration of (1) instantaneous triangulation withsimultaneous sightings of two planets with the LOST algorithm and (2) dynamictriangulation with sequential sightings of multiple planets.</description><author>Michael Krause, Ava Thrasher, Priyal Soni, Liam Smego, Reuben Isaac, Jennifer Nolan, Micah Pledger, E. Glenn Lightsey, W. Jud Ready, John Christian</author><pubDate>Mon, 22 Jan 2024 18:38:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12198v1</guid></item><item><title>Text Embedding Inversion Attacks on Multilingual Language Models</title><link>http://arxiv.org/abs/2401.12192v1</link><description>Representing textual information as real-numbered embeddings has become thenorm in NLP. Moreover, with the rise of public interest in large languagemodels (LLMs), Embeddings as a Service (EaaS) has rapidly gained traction as abusiness model. This is not without outstanding security risks, as previousresearch has demonstrated that sensitive data can be reconstructed fromembeddings, even without knowledge of the underlying model that generated them.However, such work is limited by its sole focus on English, leaving all otherlanguages vulnerable to attacks by malicious actors. %As many international andmultilingual companies leverage EaaS, there is an urgent need for research intomultilingual LLM security. To this end, this work investigates LLM securityfrom the perspective of multilingual embedding inversion. Concretely, we definethe problem of black-box multilingual and cross-lingual inversion attacks, withspecial attention to a cross-domain scenario. Our findings reveal thatmultilingual models are potentially more vulnerable to inversion attacks thantheir monolingual counterparts. This stems from the reduced data requirementsfor achieving comparable inversion performance in settings where the underlyinglanguage is not known a-priori. To our knowledge, this work is the first todelve into multilinguality within the context of inversion attacks, and ourfindings highlight the need for further investigation and enhanced defenses inthe area of NLP Security.</description><author>Yiyi Chen, Heather Lent, Johannes Bjerva</author><pubDate>Mon, 22 Jan 2024 18:34:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12192v1</guid></item><item><title>WARM: On the Benefits of Weight Averaged Reward Models</title><link>http://arxiv.org/abs/2401.12187v1</link><description>Aligning large language models (LLMs) with human preferences throughreinforcement learning (RLHF) can lead to reward hacking, where LLMs exploitfailures in the reward model (RM) to achieve seemingly high rewards withoutmeeting the underlying objectives. We identify two primary challenges whendesigning RMs to mitigate reward hacking: distribution shifts during the RLprocess and inconsistencies in human preferences. As a solution, we proposeWeight Averaged Reward Models (WARM), first fine-tuning multiple RMs, thenaveraging them in the weight space. This strategy follows the observation thatfine-tuned weights remain linearly mode connected when sharing the samepre-training. By averaging weights, WARM improves efficiency compared to thetraditional ensembling of predictions, while improving reliability underdistribution shifts and robustness to preference inconsistencies. Ourexperiments on summarization tasks, using best-of-N and RL methods, shows thatWARM improves the overall quality and alignment of LLM predictions; forexample, a policy RL fine-tuned with WARM has a 79.4% win rate against a policyRL fine-tuned with a single RM.</description><author>Alexandre Ramé, Nino Vieillard, Léonard Hussenot, Robert Dadashi, Geoffrey Cideron, Olivier Bachem, Johan Ferret</author><pubDate>Mon, 22 Jan 2024 18:27:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12187v1</guid></item><item><title>Decolonial AI Alignment: Openness, Viśe\d{s}a-Dharma, and Including Excluded Knowledges</title><link>http://arxiv.org/abs/2309.05030v2</link><description>Prior work has explicated the coloniality of artificial intelligence (AI)development and deployment through mechanisms such as extractivism, automation,sociological essentialism, surveillance, and containment. However, that workhas not engaged much with alignment: teaching behaviors to a large languagemodel (LLM) in line with desired values, and has not considered a mechanismthat arises within that process: moral absolutism -- a part of the colonialityof knowledge. Colonialism has a history of altering the beliefs and values ofcolonized peoples; in this paper, I argue that this history is recapitulated incurrent LLM alignment practices and technologies. Furthermore, I suggest thatAI alignment be decolonialized using three forms of openness: openness ofmodels, openness to society, and openness to excluded knowledges. Thissuggested approach to decolonial AI alignment uses ideas from the argumentativemoral philosophical tradition of Hinduism, which has been described as anopen-source religion. One concept used is vi\'{s}e\d{s}a-dharma, or particularcontext-specific notions of right and wrong. At the end of the paper, I providea suggested reference architecture to work toward the proposed framework.</description><author>Kush R. Varshney</author><pubDate>Mon, 22 Jan 2024 18:22:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.05030v2</guid></item><item><title>Personality Trait Inference Via Mobile Phone Sensors: A Machine Learning Approach</title><link>http://arxiv.org/abs/2401.10305v2</link><description>This study provides evidence that personality can be reliably predicted fromactivity data collected through mobile phone sensors. Employing a set of wellinformed indicators calculable from accelerometer records and movementpatterns, we were able to predict users' personality up to a 0.78 F1 score on atwo class problem. Given the fast growing number of data collected from mobilephones, our novel personality indicators open the door to exciting avenues forfuture research in social sciences. Our results reveal distinct behavioralpatterns that proved to be differentially predictive of big five personalitytraits. They potentially enable cost effective, questionnaire freeinvestigation of personality related questions at an unprecedented scale. Weshow how a combination of rich behavioral data obtained with smartphone sensingand the use of machine learning techniques can help to advance personalityresearch and can inform both practitioners and researchers about the differentbehavioral patterns of personality. These findings have practical implicationsfor organizations harnessing mobile sensor data for personality assessment,guiding the refinement of more precise and efficient prediction models in thefuture.</description><author>Wun Yung Shaney Sze, Maryglen Pearl Herrero, Roger Garriga</author><pubDate>Mon, 22 Jan 2024 18:12:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10305v2</guid></item><item><title>Universal Neurons in GPT2 Language Models</title><link>http://arxiv.org/abs/2401.12181v1</link><description>A basic question within the emerging field of mechanistic interpretability isthe degree to which neural networks learn the same underlying mechanisms. Inother words, are neural mechanisms universal across different models? In thiswork, we study the universality of individual neurons across GPT2 modelstrained from different initial random seeds, motivated by the hypothesis thatuniversal neurons are likely to be interpretable. In particular, we computepairwise correlations of neuron activations over 100 million tokens for everyneuron pair across five different seeds and find that 1-5\% of neurons areuniversal, that is, pairs of neurons which consistently activate on the sameinputs. We then study these universal neurons in detail, finding that theyusually have clear interpretations and taxonomize them into a small number ofneuron families. We conclude by studying patterns in neuron weights toestablish several universal functional roles of neurons in simple circuits:deactivating attention heads, changing the entropy of the next tokendistribution, and predicting the next token to (not) be within a particularset.</description><author>Wes Gurnee, Theo Horsley, Zifan Carl Guo, Tara Rezaei Kheirkhah, Qinyi Sun, Will Hathaway, Neel Nanda, Dimitris Bertsimas</author><pubDate>Mon, 22 Jan 2024 18:11:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12181v1</guid></item><item><title>DITTO: Diffusion Inference-Time T-Optimization for Music Generation</title><link>http://arxiv.org/abs/2401.12179v1</link><description>We propose Diffusion Inference-Time T-Optimization (DITTO), a general-purposeframe-work for controlling pre-trained text-to-music diffusion models atinference-time via optimizing initial noise latents. Our method can be used tooptimize through any differentiable feature matching loss to achieve a target(stylized) output and leverages gradient checkpointing for memory efficiency.We demonstrate a surprisingly wide-range of applications for music generationincluding inpainting, outpainting, and looping as well as intensity, melody,and musical structure control - all without ever fine-tuning the underlyingmodel. When we compare our approach against related training, guidance, andoptimization-based methods, we find DITTO achieves state-of-the-art performanceon nearly all tasks, including outperforming comparable approaches oncontrollability, audio quality, and computational efficiency, thus opening thedoor for high-quality, flexible, training-free control of diffusion models.Sound examples can be found at https://DITTO-Music.github.io/web/.</description><author>Zachary Novack, Julian McAuley, Taylor Berg-Kirkpatrick, Nicholas J. Bryan</author><pubDate>Mon, 22 Jan 2024 18:10:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12179v1</guid></item><item><title>In-Context Learning for Extreme Multi-Label Classification</title><link>http://arxiv.org/abs/2401.12178v1</link><description>Multi-label classification problems with thousands of classes are hard tosolve with in-context learning alone, as language models (LMs) might lack priorknowledge about the precise classes or how to assign them, and it is generallyinfeasible to demonstrate every class in a prompt. We propose a generalprogram, $\texttt{Infer--Retrieve--Rank}$, that defines multi-step interactionsbetween LMs and retrievers to efficiently tackle such problems. We implementthis program using the $\texttt{DSPy}$ programming model, which specifiesin-context systems in a declarative manner, and use $\texttt{DSPy}$ optimizersto tune it towards specific datasets by bootstrapping only tens of few-shotexamples. Our primary extreme classification program, optimized separately foreach task, attains state-of-the-art results across three benchmarks (HOUSE,TECH, TECHWOLF). We apply the same program to a benchmark with vastly differentcharacteristics and attain competitive performance as well (BioDEX). Unlikeprior work, our proposed solution requires no finetuning, is easily applicableto new tasks, alleviates prompt engineering, and requires only tens of labeledexamples. Our code is public at https://github.com/KarelDO/xmc.dspy.</description><author>Karel D'Oosterlinck, Omar Khattab, François Remy, Thomas Demeester, Chris Develder, Christopher Potts</author><pubDate>Mon, 22 Jan 2024 18:09:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12178v1</guid></item><item><title>Broiler-Net: A Deep Convolutional Framework for Broiler Behavior Analysis in Poultry Houses</title><link>http://arxiv.org/abs/2401.12176v1</link><description>Detecting anomalies in poultry houses is crucial for maintaining optimalchicken health conditions, minimizing economic losses and bolsteringprofitability. This paper presents a novel real-time framework for analyzingchicken behavior in cage-free poultry houses to detect abnormal behaviors.Specifically, two significant abnormalities, namely inactive broiler andhuddling behavior, are investigated in this study. The proposed frameworkcomprises three key steps: (1) chicken detection utilizing a state-of-the-artdeep learning model, (2) tracking individual chickens across consecutive frameswith a fast tracker module, and (3) detecting abnormal behaviors within thevideo stream. Experimental studies are conducted to evaluate the efficacy ofthe proposed algorithm in accurately assessing chicken behavior. The resultsillustrate that our framework provides a precise and efficient solution forreal-time anomaly detection, facilitating timely interventions to maintainchicken health and enhance overall productivity on poultry farms. Github:https://github.com/TaherehZarratEhsan/Chicken-Behavior-Analysis</description><author>Tahereh Zarrat Ehsan, Seyed Mehdi Mohtavipour</author><pubDate>Mon, 22 Jan 2024 18:09:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12176v1</guid></item><item><title>Interpreting CLIP's Image Representation via Text-Based Decomposition</title><link>http://arxiv.org/abs/2310.05916v3</link><description>We investigate the CLIP image encoder by analyzing how individual modelcomponents affect the final representation. We decompose the imagerepresentation as a sum across individual image patches, model layers, andattention heads, and use CLIP's text representation to interpret the summands.Interpreting the attention heads, we characterize each head's role byautomatically finding text representations that span its output space, whichreveals property-specific roles for many heads (e.g. location or shape). Next,interpreting the image patches, we uncover an emergent spatial localizationwithin CLIP. Finally, we use this understanding to remove spurious featuresfrom CLIP and to create a strong zero-shot image segmenter. Our resultsindicate that a scalable understanding of transformer models is attainable andcan be used to repair and improve models.</description><author>Yossi Gandelsman, Alexei A. Efros, Jacob Steinhardt</author><pubDate>Mon, 22 Jan 2024 18:08:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05916v3</guid></item><item><title>Single-View 3D Human Digitalization with Large Reconstruction Models</title><link>http://arxiv.org/abs/2401.12175v1</link><description>In this paper, we introduce Human-LRM, a single-stage feed-forward LargeReconstruction Model designed to predict human Neural Radiance Fields (NeRF)from a single image. Our approach demonstrates remarkable adaptability intraining using extensive datasets containing 3D scans and multi-view capture.Furthermore, to enhance the model's applicability for in-the-wild scenariosespecially with occlusions, we propose a novel strategy that distillsmulti-view reconstruction into single-view via a conditional triplane diffusionmodel. This generative extension addresses the inherent variations in humanbody shapes when observed from a single view, and makes it possible toreconstruct the full body human from an occluded image. Through extensiveexperiments, we show that Human-LRM surpasses previous methods by a significantmargin on several benchmarks.</description><author>Zhenzhen Weng, Jingyuan Liu, Hao Tan, Zhan Xu, Yang Zhou, Serena Yeung-Levy, Jimei Yang</author><pubDate>Mon, 22 Jan 2024 18:08:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12175v1</guid></item><item><title>Natural Strategic Ability in Stochastic Multi-Agent Systems</title><link>http://arxiv.org/abs/2401.12170v1</link><description>Strategies synthesized using formal methods can be complex and often requireinfinite memory, which does not correspond to the expected behavior when tryingto model Multi-Agent Systems (MAS). To capture such behaviors, naturalstrategies are a recently proposed framework striking a balance between theability of agents to strategize with memory and the model-checking complexity,but until now has been restricted to fully deterministic settings. For thefirst time, we consider the probabilistic temporal logics PATL and PATL* undernatural strategies (NatPATL and NatPATL*, resp.). As main result we show that,in stochastic MAS, NatPATL model-checking is NP-complete when the activecoalition is restricted to deterministic strategies. We also give a 2NEXPTIMEcomplexity result for NatPATL* with the same restriction. In the unrestrictedcase, we give an EXPSPACE complexity for NatPATL and 3EXPSPACE complexity forNatPATL*.</description><author>Raphaël Berthon, Joost-Pieter Katoen, Munyque Mittelmann, Aniello Murano</author><pubDate>Mon, 22 Jan 2024 18:04:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12170v1</guid></item><item><title>Towards Size-Independent Generalization Bounds for Deep Operator Nets</title><link>http://arxiv.org/abs/2205.11359v2</link><description>In recent times machine learning methods have made significant advances inbecoming a useful tool for analyzing physical systems. A particularly activearea in this theme has been "physics-informed machine learning" which focuseson using neural nets for numerically solving differential equations. In thiswork, we aim to advance the theory of measuring out-of-sample error whiletraining DeepONets -- which is among the most versatile ways to solve PDEsystems in one-shot. Firstly, for a class of DeepONets, we prove a bound on their Rademachercomplexity which does not explicitly scale with the width of the nets involved.Secondly, we use this to show how the Huber loss can be chosen so that forthese DeepONet classes generalization error bounds can be obtained that have noexplicit dependence on the size of the nets. We note that our theoreticalresults apply to any PDE being targeted to be solved by DeepONets.</description><author>Pulkit Gopalani, Sayar Karmakar, Dibyakanti Kumar, Anirbit Mukherjee</author><pubDate>Mon, 22 Jan 2024 18:01:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.11359v2</guid></item><item><title>SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities</title><link>http://arxiv.org/abs/2401.12168v1</link><description>Understanding and reasoning about spatial relationships is a fundamentalcapability for Visual Question Answering (VQA) and robotics. While VisionLanguage Models (VLM) have demonstrated remarkable performance in certain VQAbenchmarks, they still lack capabilities in 3D spatial reasoning, such asrecognizing quantitative relationships of physical objects like distances orsize differences. We hypothesize that VLMs' limited spatial reasoningcapability is due to the lack of 3D spatial knowledge in training data and aimto solve this problem by training VLMs with Internet-scale spatial reasoningdata. To this end, we present a system to facilitate this approach. We firstdevelop an automatic 3D spatial VQA data generation framework that scales up to2 billion VQA examples on 10 million real-world images. We then investigatevarious factors in the training recipe, including data quality, trainingpipeline, and VLM architecture. Our work features the first internet-scale 3Dspatial reasoning dataset in metric space. By training a VLM on such data, wesignificantly enhance its ability on both qualitative and quantitative spatialVQA. Finally, we demonstrate that this VLM unlocks novel downstreamapplications in chain-of-thought spatial reasoning and robotics due to itsquantitative estimation capability. Project website:https://spatial-vlm.github.io/</description><author>Boyuan Chen, Zhuo Xu, Sean Kirmani, Brian Ichter, Danny Driess, Pete Florence, Dorsa Sadigh, Leonidas Guibas, Fei Xia</author><pubDate>Mon, 22 Jan 2024 18:01:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12168v1</guid></item><item><title>Semi-supervised segmentation of land cover images using nonlinear canonical correlation analysis with multiple features and t-SNE</title><link>http://arxiv.org/abs/2401.12164v1</link><description>Image segmentation is a clustering task whereby each pixel is assigned acluster label. Remote sensing data usually consists of multiple bands ofspectral images in which there exist semantically meaningful land coversubregions, co-registered with other source data such as LIDAR (LIght DetectionAnd Ranging) data, where available. This suggests that, in order to account forspatial correlation between pixels, a feature vector associated with each pixelmay be a vectorized tensor representing the multiple bands and a local patch asappropriate. Similarly, multiple types of texture features based on a pixel'slocal patch would also be beneficial for encoding locally statisticalinformation and spatial variations, without necessarily labelling pixel-wise alarge amount of ground truth, then training a supervised model, which issometimes impractical. In this work, by resorting to label only a smallquantity of pixels, a new semi-supervised segmentation approach is proposed.Initially, over all pixels, an image data matrix is created in high dimensionalfeature space. Then, t-SNE projects the high dimensional data onto 3Dembedding. By using radial basis functions as input features, which use thelabelled data samples as centres, to pair with the output class labels, amodified canonical correlation analysis algorithm, referred to as RBF-CCA, isintroduced which learns the associated projection matrix via the small labelleddata set. The associated canonical variables, obtained for the full image, areapplied by k-means clustering algorithm. The proposed semi-supervised RBF-CCAalgorithm has been implemented on several remotely sensed multispectral images,demonstrating excellent segmentation results.</description><author>Hong Wei, James Xiao, Yichao Zhang, Xia Hong</author><pubDate>Mon, 22 Jan 2024 17:56:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12164v1</guid></item><item><title>Automated facial recognition system using deep learning for pain assessment in adults with cerebral palsy</title><link>http://arxiv.org/abs/2401.12161v1</link><description>Background: Pain assessment in individuals with neurological conditions,especially those with limited self-report ability and altered facialexpressions, presents challenges. Existing measures, relying on directobservation by caregivers, lack sensitivity and specificity. In cerebral palsy,pain is a common comorbidity and a reliable evaluation protocol is crucial.Thus, having an automatic system that recognizes facial expressions could be ofenormous help when diagnosing pain in this type of patient. Objectives: 1) to build a dataset of facial pain expressions in individualswith cerebral palsy, and 2) to develop an automated facial recognition systembased on deep learning for pain assessment addressed to this population. Methods: Ten neural networks were trained on three pain image databases,including the UNBC-McMaster Shoulder Pain Expression Archive Database, theMultimodal Intensity Pain Dataset, and the Delaware Pain Database.Additionally, a curated dataset (CPPAIN) was created, consisting of 109preprocessed facial pain expression images from individuals with cerebralpalsy, categorized by two physiotherapists using the Facial Action CodingSystem observational scale. Results: InceptionV3 exhibited promising performance on the CP-PAIN dataset,achieving an accuracy of 62.67% and an F1 score of 61.12%. Explainableartificial intelligence techniques revealed consistent essential features forpain identification across models. Conclusion: This study demonstrates the potential of deep learning models forrobust pain detection in populations with neurological conditions andcommunication disabilities. The creation of a larger dataset specific tocerebral palsy would further enhance model accuracy, offering a valuable toolfor discerning subtle and idiosyncratic pain expressions. The insights gainedcould extend to other complex neurological conditions.</description><author>Álvaro Sabater-Gárriz, F. Xavier Gaya-Morey, José María Buades-Rubio, Cristina Manresa Yee, Pedro Montoya, Inmaculada Riquelme</author><pubDate>Mon, 22 Jan 2024 17:55:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12161v1</guid></item><item><title>Benchmarking the Robustness of Image Watermarks</title><link>http://arxiv.org/abs/2401.08573v2</link><description>This paper investigates the weaknesses of image watermarking techniques. Wepresent WAVES (Watermark Analysis Via Enhanced Stress-testing), a novelbenchmark for assessing watermark robustness, overcoming the limitations ofcurrent evaluation methods.WAVES integrates detection and identification tasks,and establishes a standardized evaluation protocol comprised of a diverse rangeof stress tests. The attacks in WAVES range from traditional image distortionsto advanced and novel variations of diffusive, and adversarial attacks. Ourevaluation examines two pivotal dimensions: the degree of image qualitydegradation and the efficacy of watermark detection after attacks. We develop aseries of Performance vs. Quality 2D plots, varying over several prominentimage similarity metrics, which are then aggregated in a heuristically novelmanner to paint an overall picture of watermark robustness and attack potency.Our comprehensive evaluation reveals previously undetected vulnerabilities ofseveral modern watermarking algorithms. We envision WAVES as a toolkit for thefuture development of robust watermarking systems. The project is available athttps://wavesbench.github.io/</description><author>Bang An, Mucong Ding, Tahseen Rabbani, Aakriti Agrawal, Yuancheng Xu, Chenghao Deng, Sicheng Zhu, Abdirisak Mohamed, Yuxin Wen, Tom Goldstein, Furong Huang</author><pubDate>Mon, 22 Jan 2024 17:54:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08573v2</guid></item><item><title>Joint Hierarchical Priors and Adaptive Spatial Resolution for Efficient Neural Image Compression</title><link>http://arxiv.org/abs/2307.02273v4</link><description>Recently, the performance of neural image compression (NIC) has steadilyimproved thanks to the last line of study, reaching or outperformingstate-of-the-art conventional codecs. Despite significant progress, current NICmethods still rely on ConvNet-based entropy coding, limited in modelinglong-range dependencies due to their local connectivity and the increasingnumber of architectural biases and priors, resulting in complex underperformingmodels with high decoding latency. Motivated by the efficiency investigation ofthe Tranformer-based transform coding framework, namely SwinT-ChARM, we proposeto enhance the latter, as first, with a more straightforward yet effectiveTranformer-based channel-wise auto-regressive prior model, resulting in anabsolute image compression transformer (ICT). Through the proposed ICT, we cancapture both global and local contexts from the latent representations andbetter parameterize the distribution of the quantized latents. Further, weleverage a learnable scaling module with a sandwich ConvNeXt-basedpre-/post-processor to accurately extract more compact latent codes whilereconstructing higher-quality images. Extensive experimental results onbenchmark datasets showed that the proposed framework significantly improvesthe trade-off between coding efficiency and decoder complexity over theversatile video coding (VVC) reference encoder (VTM-18.0) and the neural codecSwinT-ChARM. Moreover, we provide model scaling studies to verify thecomputational efficiency of our approach and conduct several objective andsubjective analyses to bring to the fore the performance gap between theadaptive image compression transformer (AICT) and the neural codec SwinT-ChARM.</description><author>Ahmed Ghorbel, Wassim Hamidouche, Luce Morin</author><pubDate>Mon, 22 Jan 2024 17:37:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.02273v4</guid></item><item><title>Personalized Over-the-Air Federated Learning with Personalized Reconfigurable Intelligent Surfaces</title><link>http://arxiv.org/abs/2401.12149v1</link><description>Over-the-air federated learning (OTA-FL) provides bandwidth-efficientlearning by leveraging the inherent superposition property of wirelesschannels. Personalized federated learning balances performance for users withdiverse datasets, addressing real-life data heterogeneity. We propose the firstpersonalized OTA-FL scheme through multi-task learning, assisted by personalreconfigurable intelligent surfaces (RIS) for each user. We take a cross-layerapproach that optimizes communication and computation resources for global andpersonalized tasks in time-varying channels with imperfect channel stateinformation, using multi-task learning for non-i.i.d data. Our PROAR-PFedalgorithm adaptively designs power, local iterations, and RIS configurations.We present convergence analysis for non-convex objectives and demonstrate thatPROAR-PFed outperforms state-of-the-art on the Fashion-MNIST dataset.</description><author>Jiayu Mao, Aylin Yener</author><pubDate>Mon, 22 Jan 2024 17:36:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12149v1</guid></item><item><title>Anisotropy Is Inherent to Self-Attention in Transformers</title><link>http://arxiv.org/abs/2401.12143v1</link><description>The representation degeneration problem is a phenomenon that is widelyobserved among self-supervised learning methods based on Transformers. In NLP,it takes the form of anisotropy, a singular property of hidden representationswhich makes them unexpectedly close to each other in terms of angular distance(cosine-similarity). Some recent works tend to show that anisotropy is aconsequence of optimizing the cross-entropy loss on long-tailed distributionsof tokens. We show in this paper that anisotropy can also be observedempirically in language models with specific objectives that should not sufferdirectly from the same consequences. We also show that the anisotropy problemextends to Transformers trained on other modalities. Our observations suggestthat anisotropy is actually inherent to Transformers-based models.</description><author>Nathan Godey, Éric de la Clergerie, Benoît Sagot</author><pubDate>Mon, 22 Jan 2024 17:26:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12143v1</guid></item><item><title>Knowledge Fusion of Large Language Models</title><link>http://arxiv.org/abs/2401.10491v2</link><description>While training large language models (LLMs) from scratch can generate modelswith distinct functionalities and strengths, it comes at significant costs andmay result in redundant capabilities. Alternatively, a cost-effective andcompelling approach is to merge existing pre-trained LLMs into a more potentmodel. However, due to the varying architectures of these LLMs, directlyblending their weights is impractical. In this paper, we introduce the notionof knowledge fusion for LLMs, aimed at combining the capabilities of existingLLMs and transferring them into a single LLM. By leveraging the generativedistributions of source LLMs, we externalize their collective knowledge andunique strengths, thereby potentially elevating the capabilities of the targetmodel beyond those of any individual source LLM. We validate our approach usingthree popular LLMs with different architectures--Llama-2, MPT, andOpenLLaMA--across various benchmarks and tasks. Our findings confirm that thefusion of LLMs can improve the performance of the target model across a rangeof capabilities such as reasoning, commonsense, and code generation. Our code,model weights, and data are public at\url{https://github.com/fanqiwan/FuseLLM}.</description><author>Fanqi Wan, Xinting Huang, Deng Cai, Xiaojun Quan, Wei Bi, Shuming Shi</author><pubDate>Mon, 22 Jan 2024 17:16:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10491v2</guid></item><item><title>VRMN-bD: A Multi-modal Natural Behavior Dataset of Immersive Human Fear Responses in VR Stand-up Interactive Games</title><link>http://arxiv.org/abs/2401.12133v1</link><description>Understanding and recognizing emotions are important and challenging issuesin the metaverse era. Understanding, identifying, and predicting fear, which isone of the fundamental human emotions, in virtual reality (VR) environmentsplays an essential role in immersive game development, scene development, andnext-generation virtual human-computer interaction applications. In thisarticle, we used VR horror games as a medium to analyze fear emotions bycollecting multi-modal data (posture, audio, and physiological signals) from 23players. We used an LSTM-based model to predict fear with accuracies of 65.31%and 90.47% under 6-level classification (no fear and five different levels offear) and 2-level classification (no fear and fear), respectively. Weconstructed a multi-modal natural behavior dataset of immersive human fearresponses (VRMN-bD) and compared it with existing relevant advanced datasets.The results show that our dataset has fewer limitations in terms of collectionmethod, data scale and audience scope. We are unique and advanced in targetingmulti-modal datasets of fear and behavior in VR stand-up interactiveenvironments. Moreover, we discussed the implications of this work forcommunities and applications. The dataset and pre-trained model are availableat https://github.com/KindOPSTAR/VRMN-bD.</description><author>He Zhang, Xinyang Li, Yuanxi Sun, Xinyi Fu, Christine Qiu, John M. Carroll</author><pubDate>Mon, 22 Jan 2024 17:15:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12133v1</guid></item><item><title>Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis Using Sequential Multisequence MRI</title><link>http://arxiv.org/abs/2401.12132v1</link><description>Introduction Quantum Convolutional Neural Network (QCNN)-Long Short-TermMemory (LSTM) models were studied to provide sequential relationships for eachtimepoint in MRIs of patients with Multiple Sclerosis (MS). In this pilotstudy, we compared three QCNN-LSTM models for binary classification of MSdisability benchmarked against classical neural network architectures. Ourhypothesis is that quantum models will provide competitive performance. MethodsMatrix Product State (MPS), reverse Multistate Entanglement RenormalizationAnsatz (MERA), and Tree-Tensor Network (TTN) circuits were paired with LSTMlayer to process near-annual MRI data of patients diagnosed with MS. These werebenchmarked against a Visual Geometry Group (VGG)-LSTM and a Video VisionTransformer (ViViT). Predicted logits were measured against ground truth labelsof each patient's Extended Disability Severity Score (EDSS) using binarycross-entropy loss. Training/validation/holdout testing was partitioned using5-fold cross validation with a total split of 60:20:20. Levene's test ofvariance was used to measure statistical difference and Student's t-test forpaired model differences in mean. Results The MPS-LSTM, reverse MERA-LSTM, andTTN-LSTM had holdout testing ROC-AUC of 0.70, 0.77, and 0.81, respectively(p-value 0.915). VGG16-LSTM and ViViT performed similarly with ROC-AUC of 0.73and 0.77, respectively (p-value 0.631). Overall variance and mean were notstatistically significant (p-value 0.713), however, time to train wassignificantly faster for the QCNN-LSTMs (39.4 sec per fold vs. 224 and 218,respectively, p-value &lt;0.001). Conclusion QCNN-LSTM models performcompetitively to their classical counterparts with greater efficiency in traintime. Clinically, these can add value in terms of efficiency to time-dependentdeep learning prediction of disease progression based upon medical imaging.</description><author>John D. Mayfield, Issam El Naqa</author><pubDate>Mon, 22 Jan 2024 17:14:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12132v1</guid></item><item><title>NeuroSynt: A Neuro-symbolic Portfolio Solver for Reactive Synthesis</title><link>http://arxiv.org/abs/2401.12131v1</link><description>We introduce NeuroSynt, a neuro-symbolic portfolio solver framework forreactive synthesis. At the core of the solver lies a seamless integration ofneural and symbolic approaches to solving the reactive synthesis problem. Toensure soundness, the neural engine is coupled with model checkers verifyingthe predictions of the underlying neural models. The open-source implementationof NeuroSynt provides an integration framework for reactive synthesis in whichnew neural and state-of-the-art symbolic approaches can be seamlesslyintegrated. Extensive experiments demonstrate its efficacy in handlingchallenging specifications, enhancing the state-of-the-art reactive synthesissolvers, with NeuroSynt contributing novel solves in the current SYNTCOMPbenchmarks.</description><author>Matthias Cosler, Christopher Hahn, Ayham Omar, Frederik Schmitt</author><pubDate>Mon, 22 Jan 2024 17:13:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12131v1</guid></item><item><title>DFU: scale-robust diffusion model for zero-shot super-resolution image generation</title><link>http://arxiv.org/abs/2401.06144v2</link><description>Diffusion generative models have achieved remarkable success in generatingimages with a fixed resolution. However, existing models have limited abilityto generalize to different resolutions when training data at those resolutionsare not available. Leveraging techniques from operator learning, we present anovel deep-learning architecture, Dual-FNO UNet (DFU), which approximates thescore operator by combining both spatial and spectral information at multipleresolutions. Comparisons of DFU to baselines demonstrate its scalability: 1)simultaneously training on multiple resolutions improves FID over training atany single fixed resolution; 2) DFU generalizes beyond its trainingresolutions, allowing for coherent, high-fidelity generation athigher-resolutions with the same model, i.e. zero-shot super-resolutionimage-generation; 3) we propose a fine-tuning strategy to further enhance thezero-shot super-resolution image-generation capability of our model, leading toa FID of 11.3 at 1.66 times the maximum training resolution on FFHQ, which noother method can come close to achieving.</description><author>Alex Havrilla, Kevin Rojas, Wenjing Liao, Molei Tao</author><pubDate>Mon, 22 Jan 2024 17:11:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06144v2</guid></item><item><title>Out-of-Distribution Detection &amp; Applications With Ablated Learned Temperature Energy</title><link>http://arxiv.org/abs/2401.12129v1</link><description>As deep neural networks become adopted in high-stakes domains, it is crucialto be able to identify when inference inputs are Out-of-Distribution (OOD) sothat users can be alerted of likely drops in performance and calibrationdespite high confidence. Among many others, existing methods use the followingtwo scores to do so without training on any apriori OOD examples: a learnedtemperature and an energy score. In this paper we introduce Ablated LearnedTemperature Energy (or "AbeT" for short), a method which combines these priormethods in novel ways with effective modifications. Due to these contributions,AbeT lowers the False Positive Rate at $95\%$ True Positive Rate (FPR@95) by$35.39\%$ in classification (averaged across all ID and OOD datasets measured)compared to state of the art without training networks in multiple stages orrequiring hyperparameters or test-time backward passes. We additionally provideempirical insights as to how our model learns to distinguish betweenIn-Distribution (ID) and OOD samples while only being explicitly trained on IDsamples via exposure to misclassified ID examples at training time. Lastly, weshow the efficacy of our method in identifying predicted bounding boxes andpixels corresponding to OOD objects in object detection and semanticsegmentation, respectively - with an AUROC increase of $5.15\%$ in objectdetection and both a decrease in FPR@95 of $41.48\%$ and an increase in AUPRCof $34.20\%$ on average in semantic segmentation compared to previous state ofthe art.</description><author>Will LeVine, Benjamin Pikus, Jacob Phillips, Berk Norman, Fernando Amat Gil, Sean Hendryx</author><pubDate>Mon, 22 Jan 2024 17:11:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12129v1</guid></item><item><title>UniLVSeg: Unified Left Ventricular Segmentation with Sparsely Annotated Echocardiogram Videos through Self-Supervised Temporal Masking and Weakly Supervised Training</title><link>http://arxiv.org/abs/2310.00454v2</link><description>Echocardiography has become an indispensable clinical imaging modality forgeneral heart health assessment. From calculating biomarkers such as ejectionfraction to the probability of a patient's heart failure, accurate segmentationof the heart and its structures allows doctors to plan and execute treatmentswith greater precision and accuracy. However, achieving accurate and robustleft ventricle segmentation is time-consuming and challenging due to differentreasons. This work introduces a novel approach for consistent left ventricular(LV) segmentation from sparsely annotated echocardiogram videos. We achievethis through (1) self-supervised learning (SSL) using temporal masking followedby (2) weakly supervised training. We investigate two different segmentationapproaches: 3D segmentation and a novel 2D superimage (SI). We demonstrate howour proposed method outperforms the state-of-the-art solutions by achieving a93.32% (95%CI 93.21-93.43%) dice score on a large-scale dataset(EchoNet-Dynamic) while being more efficient. To show the effectiveness of ourapproach, we provide extensive ablation studies, including pre-trainingsettings and various deep learning backbones. Additionally, we discuss how ourproposed methodology achieves high data utility by incorporating unlabeledframes in the training process. To help support the AI in medicine community,the complete solution with the source code will be made publicly available uponacceptance.</description><author>Fadillah Maani, Asim Ukaye, Nada Saadi, Numan Saeed, Mohammad Yaqub</author><pubDate>Mon, 22 Jan 2024 17:10:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00454v2</guid></item><item><title>ICE-Score: Instructing Large Language Models to Evaluate Code</title><link>http://arxiv.org/abs/2304.14317v2</link><description>Recent advancements in the field of natural language generation havefacilitated the use of large language models to assess the quality of generatedtext. Although these models have shown promising results in tasks such asmachine translation and summarization, their applicability in code intelligencetasks remains limited without human involvement. The complexity of programmingconcepts required for such tasks makes it difficult to develop evaluationmetrics that align with human judgment. Token-matching-based metrics, such asBLEU, have demonstrated weak correlations with human practitioners in codeintelligence tasks. Moreover, utilizing human-written test suites to evaluatefunctional correctness can be challenging in domains with low resources. Toovercome these obstacles, we propose \texttt{ICE-Score}, a new evaluationmetric via instructing large language models (LLMs) for code assessments. Ourmetric addresses the limitations of existing approaches by achieving superiorcorrelations with functional correctness and human preferences, without theneed for test oracles or references. We evaluate the efficacy of our metric ontwo different aspects (\textit{human preference} and \textit{executionsuccess}) and four programming languages. Our results demonstrate that ourmetric surpasses state-of-the-art metrics for code generation, delivering highlevels of accuracy and consistency across various programming languages andtasks. We also make our evaluation metric and datasets available to thepublic\footnote{\url{https://github.com/terryyz/ice-score}}, encouragingfurther research in evaluating code intelligence tasks.</description><author>Terry Yue Zhuo</author><pubDate>Mon, 22 Jan 2024 17:06:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14317v2</guid></item><item><title>Improving genetic algorithms performance via deterministic population shrinkage</title><link>http://arxiv.org/abs/2401.12121v1</link><description>Despite the intuition that the same population size is not needed throughoutthe run of an Evolutionary Algorithm (EA), most EAs use a fixed populationsize. This paper presents an empirical study on the possible benefits of aSimple Variable Population Sizing (SVPS) scheme on the performance of GeneticAlgorithms (GAs). It consists in decreasing the population for a GA runfollowing a predetermined schedule, configured by a speed and a severityparameter. The method uses as initial population size an estimation of theminimum size needed to supply enough building blocks, using a fixed-sizeselectorecombinative GA converging within some confidence interval toward goodsolutions for a particular problem. Following this methodology, a scalabilityanalysis is conducted on deceptive, quasi-deceptive, and non-deceptive trapfunctions in order to assess whether SVPS-GA improves performances compared toa fixed-size GA under different problem instances and difficulty levels.Results show several combinations of speed-severity where SVPS-GA preserves thesolution quality while improving performances, by reducing the number ofevaluations needed for success.</description><author>Juan Luis Jiménez Laredo, Carlos Fernandes, Juan Julián Merelo, Christian Gagné</author><pubDate>Mon, 22 Jan 2024 17:05:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12121v1</guid></item><item><title>DTC: Deep Tracking Control</title><link>http://arxiv.org/abs/2309.15462v2</link><description>Legged locomotion is a complex control problem that requires both accuracyand robustness to cope with real-world challenges. Legged systems havetraditionally been controlled using trajectory optimization with inversedynamics. Such hierarchical model-based methods are appealing due to intuitivecost function tuning, accurate planning, generalization, and most importantly,the insightful understanding gained from more than one decade of extensiveresearch. However, model mismatch and violation of assumptions are commonsources of faulty operation. Simulation-based reinforcement learning, on theother hand, results in locomotion policies with unprecedented robustness andrecovery skills. Yet, all learning algorithms struggle with sparse rewardsemerging from environments where valid footholds are rare, such as gaps orstepping stones. In this work, we propose a hybrid control architecture thatcombines the advantages of both worlds to simultaneously achieve greaterrobustness, foot-placement accuracy, and terrain generalization. Our approachutilizes a model-based planner to roll out a reference motion during training.A deep neural network policy is trained in simulation, aiming to track theoptimized footholds. We evaluate the accuracy of our locomotion pipeline onsparse terrains, where pure data-driven methods are prone to fail. Furthermore,we demonstrate superior robustness in the presence of slippery or deformableground when compared to model-based counterparts. Finally, we show that ourproposed tracking controller generalizes across different trajectoryoptimization methods not seen during training. In conclusion, our work unitesthe predictive capabilities and optimality guarantees of online planning withthe inherent robustness attributed to offline learning.</description><author>Fabian Jenelten, Junzhe He, Farbod Farshidian, Marco Hutter</author><pubDate>Mon, 22 Jan 2024 17:02:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15462v2</guid></item><item><title>The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large Language Models</title><link>http://arxiv.org/abs/2401.12117v1</link><description>While large language models (LLMs) are still being adopted to new domains andutilized in novel applications, we are experiencing an influx of the newgeneration of foundation models, namely multi-modal large language models(MLLMs). These models integrate verbal and visual information, opening newpossibilities to demonstrate more complex reasoning abilities at theintersection of the two modalities. However, despite the revolutionizingprospect of MLLMs, our understanding of their reasoning abilities is limited.In this study, we assess the nonverbal abstract reasoning abilities ofopen-source and closed-source MLLMs using variations of Raven's ProgressiveMatrices. Our experiments expose the difficulty of solving such problems whileshowcasing the immense gap between open-source and closed-source models. Wealso reveal critical shortcomings with individual visual and textual modules,subjecting the models to low-performance ceilings. Finally, to improve MLLMs'performance, we experiment with various methods, such as Chain-of-Thoughtprompting, resulting in a significant (up to 100%) boost in performance.</description><author>Kian Ahrabian, Zhivar Sourati, Kexuan Sun, Jiarui Zhang, Yifan Jiang, Fred Morstatter, Jay Pujara</author><pubDate>Mon, 22 Jan 2024 16:57:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12117v1</guid></item><item><title>Extracting Formulae in Many-Valued Logic from Deep Neural Networks</title><link>http://arxiv.org/abs/2401.12113v1</link><description>We propose a new perspective on deep ReLU networks, namely as circuitcounterparts of Lukasiewicz infinite-valued logic -- a many-valued (MV)generalization of Boolean logic. An algorithm for extracting formulae in MVlogic from deep ReLU networks is presented. As the algorithm applies tonetworks with general, in particular also real-valued, weights, it can be usedto extract logical formulae from deep ReLU networks trained on data.</description><author>Yani Zhang, Helmut Bölcskei</author><pubDate>Mon, 22 Jan 2024 16:51:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12113v1</guid></item><item><title>On-Time Delivery in Crowdshipping Systems: An Agent-Based Approach Using Streaming Data</title><link>http://arxiv.org/abs/2401.12108v1</link><description>In parcel delivery, the "last mile" from the parcel hub to the customer iscostly, especially for time-sensitive delivery tasks that have to be completedwithin hours after arrival. Recently, crowdshipping has attracted increasedattention as a new alternative to traditional delivery modes. In crowdshipping,private citizens ("the crowd") perform short detours in their daily lives tocontribute to parcel delivery in exchange for small incentives. However,achieving desirable crowd behavior is challenging as the crowd is highlydynamic and consists of autonomous, self-interested individuals. Leveragingcrowdshipping for time-sensitive deliveries remains an open challenge. In thispaper, we present an agent-based approach to on-time parcel delivery withcrowds. Our system performs data stream processing on the couriers' smartphonesensor data to predict delivery delays. Whenever a delay is predicted, thesystem attempts to forge an agreement for transferring the parcel from thecurrent deliverer to a more promising courier nearby. Our experiments show thatthrough accurate delay predictions and purposeful task transfers many delayscan be prevented that would occur without our approach.</description><author>Jeremias Dötterl, Ralf Bruns, Jürgen Dunkel, Sascha Ossowski</author><pubDate>Mon, 22 Jan 2024 16:45:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12108v1</guid></item><item><title>LearnedWMP: Workload Memory Prediction Using Distribution of Query Templates</title><link>http://arxiv.org/abs/2401.12103v1</link><description>In a modern DBMS, working memory is frequently the limiting factor whenprocessing in-memory analytic query operations such as joins, sorting, andaggregation. Existing resource estimation approaches for a DBMS estimate theresource consumption of a query by computing an estimate of each individualdatabase operator in the query execution plan. Such an approach is slow anderror-prone as it relies upon simplifying assumptions, such as uniformity andindependence of the underlying data. Additionally, the existing approachfocuses on individual queries separately and does not factor in other queriesin the workload that may be executed concurrently. In this research, we areinterested in query performance optimization under concurrent execution of abatch of queries (a workload). Specifically, we focus on predicting the memorydemand for a workload rather than providing separate estimates for each querywithin it. We introduce the problem of workload memory prediction and formalizeit as a distribution regression problem. We propose Learned Workload MemoryPrediction (LearnedWMP) to improve and simplify estimating the working memorydemands of workloads. Through a comprehensive experimental evaluation, we showthat LearnedWMP reduces the memory estimation error of thestate-of-the-practice method by up to 47.6%. Compared to an alternativesingle-query model, during training and inferencing, the LearnedWMP model andits variants were 3x to 10x faster. Moreover, LearnedWMP-based models were atleast 50% smaller in most cases. Overall, the results demonstrate theadvantages of the LearnedWMP approach and its potential for a broader impact onquery performance optimization.</description><author>Shaikh Quader, Andres Jaramillo, Sumona Mukhopadhyay, Ghadeer Abuoda, Calisto Zuzarte, David Kalmuk, Marin Litoiu, Manos Papagelis</author><pubDate>Mon, 22 Jan 2024 16:38:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12103v1</guid></item><item><title>An Empirical Analysis of In-context Learning Abilities of LLMs for MT</title><link>http://arxiv.org/abs/2401.12097v1</link><description>In-context learning (ICL) has consistently demonstrated superior performanceover zero-shot performance in large language models (LLMs). However, theunderstanding of the dynamics of ICL and the aspects that influence downstreamperformance remains limited, especially for natural language generation (NLG)tasks. This work aims to address this gap by investigating the ICL capabilitiesof LLMs and studying the impact of different aspects of the in-contextdemonstrations for the task of machine translation (MT). Our preliminaryinvestigations aim to discern whether in-context learning (ICL) ispredominantly influenced by demonstrations or instructions by applying diverseperturbations to in-context demonstrations while preserving the taskinstruction. We observe varying behavior to perturbed examples across differentmodel families, notably with BLOOM-7B derivatives being severely influenced bynoise, whereas Llama 2 derivatives not only exhibit robustness but also tend toshow enhancements over the clean baseline when subject to perturbeddemonstrations. This suggests that the robustness of ICL may be governed byseveral factors, including the type of noise, perturbation direction (source ortarget), the extent of pretraining of the specific model, and fine-tuning fordownstream tasks if applicable. Further investigation is warranted to develop acomprehensive understanding of these factors in future research.</description><author>Pranjal A. Chitale, Jay Gala, Varun Gumma, Mitesh M. Khapra, Raj Dabre</author><pubDate>Mon, 22 Jan 2024 16:35:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12097v1</guid></item><item><title>Unsupervised Learning of Graph from Recipes</title><link>http://arxiv.org/abs/2401.12088v1</link><description>Cooking recipes are one of the most readily available kinds of proceduraltext. They consist of natural language instructions that can be challenging tointerpret. In this paper, we propose a model to identify relevant informationfrom recipes and generate a graph to represent the sequence of actions in therecipe. In contrast with other approaches, we use an unsupervised approach. Weiteratively learn the graph structure and the parameters of a $\mathsf{GNN}$encoding the texts (text-to-graph) one sequence at a time while providing thesupervision by decoding the graph into text (graph-to-text) and comparing thegenerated text to the input. We evaluate the approach by comparing theidentified entities with annotated datasets, comparing the difference betweenthe input and output texts, and comparing our generated graphs with thosegenerated by state of the art methods.</description><author>Aissatou Diallo, Antonis Bikakis, Luke Dickens, Anthony Hunter, Rob Miller</author><pubDate>Mon, 22 Jan 2024 16:25:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12088v1</guid></item><item><title>Revisiting Demonstration Selection Strategies in In-Context Learning</title><link>http://arxiv.org/abs/2401.12087v1</link><description>Large language models (LLMs) have shown an impressive ability to perform awide range of tasks using in-context learning (ICL), where a few examples areused to describe a task to the model. However, the performance of ICL variessignificantly with the choice of demonstrations, and it is still unclear whythis happens or what factors will influence its choice. In this work, we firstrevisit the factors contributing to this variance from both data and modelaspects, and find that the choice of demonstration is both data- andmodel-dependent. We further proposed a data- and model-dependent demonstrationselection method, \textbf{TopK + ConE}, based on the assumption that\textit{the performance of a demonstration positively correlates with itscontribution to the model's understanding of the test samples}, resulting in asimple and effective recipe for ICL. Empirically, our method yields consistentimprovements in both language understanding and generation tasks with differentmodel scales. Further analyses confirm that, besides the generality andstability under different circumstances, our method provides a unifiedexplanation for the effectiveness of previous methods. Code will be released.</description><author>Keqin Peng, Liang Ding, Yancheng Yuan, Xuebo Liu, Min Zhang, Yuanxin Ouyang, Dacheng Tao</author><pubDate>Mon, 22 Jan 2024 16:25:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12087v1</guid></item><item><title>Better Batch for Deep Probabilistic Time Series Forecasting</title><link>http://arxiv.org/abs/2305.17028v2</link><description>Deep probabilistic time series forecasting has gained significant attentiondue to its superior performance in nonlinear approximation and its ability toprovide valuable uncertainty quantification for decision-making tasks. However,many existing models oversimplify the problem by assuming that the errorprocess is time-independent, thereby overlooking the serial correlation in theerror process. To overcome this limitation, we propose an innovative trainingmethod that incorporates error autocorrelation to further enhance the accuracyof probabilistic forecasting. Our method involves constructing a mini-batch asa collection of $D$ consecutive time series segments for model training andexplicitly learning a time-varying covariance matrix over each mini-batch thatencodes the error correlation among adjacent time steps. The learned covariancematrix can be used to improve prediction accuracy and enhance uncertaintyquantification. We evaluate our method on two different neural forecastingmodels and multiple public datasets, and the experimental results confirm theeffectiveness of the proposed approach in enhancing the performance of bothmodels across a wide range of datasets, yielding notable improvements inpredictive accuracy.</description><author>Vincent Zhihao Zheng, Seongjin Choi, Lijun Sun</author><pubDate>Mon, 22 Jan 2024 16:25:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17028v2</guid></item><item><title>West-of-N: Synthetic Preference Generation for Improved Reward Modeling</title><link>http://arxiv.org/abs/2401.12086v1</link><description>The success of reinforcement learning from human feedback (RLHF) in languagemodel alignment is strongly dependent on the quality of the underlying rewardmodel. In this paper, we present a novel approach to improve reward modelquality by generating synthetic preference data, thereby augmenting thetraining dataset with on-policy, high-quality preference pairs. Motivated bythe promising results of Best-of-N sampling strategies in language modeltraining, we extend their application to reward model training. This results ina self-training strategy to generate preference pairs by selecting the best andworst candidates in a pool of responses to a given query. Empirically, we findthat this approach improves the performance of any reward model, with an effectcomparable to the addition of a similar quantity of human preference data. Thiswork opens up new avenues of research for improving RLHF for language modelalignment, by offering synthetic preference generation as a solution to rewardmodeling challenges.</description><author>Alizée Pace, Jonathan Mallinson, Eric Malmi, Sebastian Krause, Aliaksei Severyn</author><pubDate>Mon, 22 Jan 2024 16:24:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12086v1</guid></item><item><title>Collaborative Reinforcement Learning Based Unmanned Aerial Vehicle (UAV) Trajectory Design for 3D UAV Tracking</title><link>http://arxiv.org/abs/2401.12079v1</link><description>In this paper, the problem of using one active unmanned aerial vehicle (UAV)and four passive UAVs to localize a 3D target UAV in real time is investigated.In the considered model, each passive UAV receives reflection signals from thetarget UAV, which are initially transmitted by the active UAV. The receivedreflection signals allow each passive UAV to estimate the signal transmissiondistance which will be transmitted to a base station (BS) for the estimation ofthe position of the target UAV. Due to the movement of the target UAV, eachactive/passive UAV must optimize its trajectory to continuously localize thetarget UAV. Meanwhile, since the accuracy of the distance estimation depends onthe signal-to-noise ratio of the transmission signals, the active UAV mustoptimize its transmit power. This problem is formulated as an optimizationproblem whose goal is to jointly optimize the transmit power of the active UAVand trajectories of both active and passive UAVs so as to maximize the targetUAV positioning accuracy. To solve this problem, a Z function decompositionbased reinforcement learning (ZD-RL) method is proposed. Compared to valuefunction decomposition based RL (VD-RL), the proposed method can find theprobability distribution of the sum of future rewards to accurately estimatethe expected value of the sum of future rewards thus finding better transmitpower of the active UAV and trajectories for both active and passive UAVs andimproving target UAV positioning accuracy. Simulation results show that theproposed ZD-RL method can reduce the positioning errors by up to 39.4% and64.6%, compared to VD-RL and independent deep RL methods, respectively.</description><author>Yujiao Zhu, Mingzhe Chen, Sihua Wang, Ye Hu, Yuchen Liu, Changchuan Yin</author><pubDate>Mon, 22 Jan 2024 16:21:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12079v1</guid></item><item><title>Temporal Blind Spots in Large Language Models</title><link>http://arxiv.org/abs/2401.12078v1</link><description>Large language models (LLMs) have recently gained significant attention dueto their unparalleled ability to perform various natural language processingtasks. These models, benefiting from their advanced natural languageunderstanding capabilities, have demonstrated impressive zero-shot performance.However, the pre-training data utilized in LLMs is often confined to a specificcorpus, resulting in inherent freshness and temporal scope limitations.Consequently, this raises concerns regarding the effectiveness of LLMs fortasks involving temporal intents. In this study, we aim to investigate theunderlying limitations of general-purpose LLMs when deployed for tasks thatrequire a temporal understanding. We pay particular attention to handlingfactual temporal knowledge through three popular temporal QA datasets.Specifically, we observe low performance on detailed questions about the pastand, surprisingly, for rather new information. In manual and automatic testing,we find multiple temporal errors and characterize the conditions under which QAperformance deteriorates. Our analysis contributes to understanding LLMlimitations and offers valuable insights into developing future models that canbetter cater to the demands of temporally-oriented tasks. The code isavailable\footnote{https://github.com/jwallat/temporalblindspots}.</description><author>Jonas Wallat, Adam Jatowt, Avishek Anand</author><pubDate>Mon, 22 Jan 2024 16:20:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12078v1</guid></item><item><title>DeepCERES: A Deep learning method for cerebellar lobule segmentation using ultra-high resolution multimodal MRI</title><link>http://arxiv.org/abs/2401.12074v1</link><description>This paper introduces a novel multimodal and high-resolution human braincerebellum lobule segmentation method. Unlike current tools that operate atstandard resolution ($1 \text{ mm}^{3}$) or using mono-modal data, the proposedmethod improves cerebellum lobule segmentation through the use of a multimodaland ultra-high resolution ($0.125 \text{ mm}^{3}$) training dataset. To developthe method, first, a database of semi-automatically labelled cerebellum lobuleswas created to train the proposed method with ultra-high resolution T1 and T2MR images. Then, an ensemble of deep networks has been designed and developed,allowing the proposed method to excel in the complex cerebellum lobulesegmentation task, improving precision while being memory efficient. Notably,our approach deviates from the traditional U-Net model by exploring alternativearchitectures. We have also integrated deep learning with classical machinelearning methods incorporating a priori knowledge from multi-atlassegmentation, which improved precision and robustness. Finally, a new onlinepipeline, named DeepCERES, has been developed to make available the proposedmethod to the scientific community requiring as input only a single T1 MR imageat standard resolution.</description><author>Sergio Morell-Ortega, Marina Ruiz-Perez, Marien Gadea, Roberto Vivo-Hernando, Gregorio Rubio, Fernando Aparici, Mariam de la Iglesia-Vaya, Gwenaelle Catheline, Pierrick Coupé, José V. Manjón</author><pubDate>Mon, 22 Jan 2024 16:14:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12074v1</guid></item><item><title>Cross-lingual Transfer Learning for Javanese Dependency Parsing</title><link>http://arxiv.org/abs/2401.12072v1</link><description>While structure learning achieves remarkable performance in high-resourcelanguages, the situation differs for under-represented languages due to thescarcity of annotated data. This study focuses on assessing the efficacy oftransfer learning in enhancing dependency parsing for Javanese, a languagespoken by 80 million individuals but characterized by limited representation innatural language processing. We utilized the Universal Dependencies datasetconsisting of dependency treebanks from more than 100 languages, includingJavanese. We propose two learning strategies to train the model: transferlearning (TL) and hierarchical transfer learning (HTL). While TL only uses asource language to pre-train the model, the HTL method uses a source languageand an intermediate language in the learning process. The results show that ourbest model uses the HTL method, which improves performance with an increase of10% for both UAS and LAS evaluations compared to the baseline model.</description><author>Fadli Aulawi Al Ghiffari, Ika Alfina, Kurniawati Azizah</author><pubDate>Mon, 22 Jan 2024 16:13:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12072v1</guid></item><item><title>Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text</title><link>http://arxiv.org/abs/2401.12070v1</link><description>Detecting text generated by modern large language models is thought to behard, as both LLMs and humans can exhibit a wide range of complex behaviors.However, we find that a score based on contrasting two closely related languagemodels is highly accurate at separating human-generated and machine-generatedtext. Based on this mechanism, we propose a novel LLM detector that onlyrequires simple calculations using a pair of pre-trained LLMs. The method,called Binoculars, achieves state-of-the-art accuracy without any trainingdata. It is capable of spotting machine text from a range of modern LLMswithout any model-specific modifications. We comprehensively evaluateBinoculars on a number of text sources and in varied situations. Over a widerange of document types, Binoculars detects over 90% of generated samples fromChatGPT (and other LLMs) at a false positive rate of 0.01%, despite not beingtrained on any ChatGPT data.</description><author>Abhimanyu Hans, Avi Schwarzschild, Valeriia Cherepanova, Hamid Kazemi, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein</author><pubDate>Mon, 22 Jan 2024 16:09:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12070v1</guid></item><item><title>Beyond TreeSHAP: Efficient Computation of Any-Order Shapley Interactions for Tree Ensembles</title><link>http://arxiv.org/abs/2401.12069v1</link><description>While shallow decision trees may be interpretable, larger ensemble modelslike gradient-boosted trees, which often set the state of the art in machinelearning problems involving tabular data, still remain black box models. As aremedy, the Shapley value (SV) is a well-known concept in explainableartificial intelligence (XAI) research for quantifying additive featureattributions of predictions. The model-specific TreeSHAP methodology solves theexponential complexity for retrieving exact SVs from tree-based models.Expanding beyond individual feature attribution, Shapley interactions revealthe impact of intricate feature interactions of any order. In this work, wepresent TreeSHAP-IQ, an efficient method to compute any-order additive Shapleyinteractions for predictions of tree-based models. TreeSHAP-IQ is supported bya mathematical framework that exploits polynomial arithmetic to compute theinteraction scores in a single recursive traversal of the tree, akin to LinearTreeSHAP. We apply TreeSHAP-IQ on state-of-the-art tree ensembles and exploreinteractions on well-established benchmark datasets.</description><author>Maximilian Muschalik, Fabian Fumagalli, Barbara Hammer, Eyke Hüllermeier</author><pubDate>Mon, 22 Jan 2024 16:08:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12069v1</guid></item><item><title>Resource-constrained stereo singing voice cancellation</title><link>http://arxiv.org/abs/2401.12068v1</link><description>We study the problem of stereo singing voice cancellation, a subtask of musicsource separation, whose goal is to estimate an instrumental background from astereo mix. We explore how to achieve performance similar to largestate-of-the-art source separation networks starting from a small, efficientmodel for real-time speech separation. Such a model is useful when memory andcompute are limited and singing voice processing has to run with limitedlook-ahead. In practice, this is realised by adapting an existing mono model tohandle stereo input. Improvements in quality are obtained by tuning modelparameters and expanding the training set. Moreover, we highlight the benefitsa stereo model brings by introducing a new metric which detects attenuationinconsistencies between channels. Our approach is evaluated using objectiveoffline metrics and a large-scale MUSHRA trial, confirming the effectiveness ofour techniques in stringent listening tests.</description><author>Clara Borrelli, James Rae, Dogac Basaran, Matt McVicar, Mehrez Souden, Matthias Mauch</author><pubDate>Mon, 22 Jan 2024 16:05:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12068v1</guid></item><item><title>The Dimension Strikes Back with Gradients: Generalization of Gradient Methods in Stochastic Convex Optimization</title><link>http://arxiv.org/abs/2401.12058v1</link><description>We study the generalization performance of gradient methods in thefundamental stochastic convex optimization setting, focusing on its dimensiondependence. First, for full-batch gradient descent (GD) we give a constructionof a learning problem in dimension $d=O(n^2)$, where the canonical version ofGD (tuned for optimal performance of the empirical risk) trained with $n$training examples converges, with constant probability, to an approximateempirical risk minimizer with $\Omega(1)$ population excess risk. Our boundtranslates to a lower bound of $\Omega (\sqrt{d})$ on the number of trainingexamples required for standard GD to reach a non-trivial test error, answeringan open question raised by Feldman (2016) and Amir, Koren, and Livni (2021b)and showing that a non-trivial dimension dependence is unavoidable.Furthermore, for standard one-pass stochastic gradient descent (SGD), we showthat an application of the same construction technique provides a similar$\Omega(\sqrt{d})$ lower bound for the sample complexity of SGD to reach anon-trivial empirical error, despite achieving optimal test performance. Thisagain provides an exponential improvement in the dimension dependence comparedto previous work (Koren, Livni, Mansour, and Sherman, 2022), resolving an openquestion left therein.</description><author>Matan Schliserman, Uri Sherman, Tomer Koren</author><pubDate>Mon, 22 Jan 2024 15:50:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12058v1</guid></item><item><title>NEUROSEC: FPGA-Based Neuromorphic Audio Security</title><link>http://arxiv.org/abs/2401.12055v1</link><description>Neuromorphic systems, inspired by the complexity and functionality of thehuman brain, have gained interest in academic and industrial attention due totheir unparalleled potential across a wide range of applications. While theircapabilities herald innovation, it is imperative to underscore that thesecomputational paradigms, analogous to their traditional counterparts, are notimpervious to security threats. Although the exploration of neuromorphicmethodologies for image and video processing has been rigorously pursued, therealm of neuromorphic audio processing remains in its early stages. Our resultshighlight the robustness and precision of our FPGA-based neuromorphic system.Specifically, our system showcases a commendable balance between desired signaland background noise, efficient spike rate encoding, and unparalleledresilience against adversarial attacks such as FGSM and PGD. A standout featureof our framework is its detection rate of 94%, which, when compared to othermethodologies, underscores its greater capability in identifying and mitigatingthreats within 5.39 dB, a commendable SNR ratio. Furthermore, neuromorphiccomputing and hardware security serve many sensor domains in mission-criticaland privacy-preserving applications.</description><author>Murat Isik, Hiruna Vishwamith, Yusuf Sur, Kayode Inadagbo, I. Can Dikmen</author><pubDate>Mon, 22 Jan 2024 15:47:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12055v1</guid></item><item><title>CloSe: A 3D Clothing Segmentation Dataset and Model</title><link>http://arxiv.org/abs/2401.12051v1</link><description>3D Clothing modeling and datasets play crucial role in the entertainment,animation, and digital fashion industries. Existing work often lacks detailedsemantic understanding or uses synthetic datasets, lacking realism andpersonalization. To address this, we first introduce CloSe-D: a novellarge-scale dataset containing 3D clothing segmentation of 3167 scans, coveringa range of 18 distinct clothing classes. Additionally, we propose CloSe-Net,the first learning-based 3D clothing segmentation model for fine-grainedsegmentation from colored point clouds. CloSe-Net uses local point features,body-clothing correlation, and a garment-class and point features-basedattention module, improving performance over baselines and prior work. Theproposed attention module enables our model to learn appearance andgeometry-dependent clothing prior from data. We further validate the efficacyof our approach by successfully segmenting publicly available datasets ofpeople in clothing. We also introduce CloSe-T, a 3D interactive tool forrefining segmentation labels. Combining the tool with CloSe-T in a continuallearning setup demonstrates improved generalization on real-world data.Dataset, model, and tool can be found athttps://virtualhumans.mpi-inf.mpg.de/close3dv24/.</description><author>Dimitrije Antić, Garvita Tiwari, Batuhan Ozcomlekci, Riccardo Marin, Gerard Pons-Moll</author><pubDate>Mon, 22 Jan 2024 15:42:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12051v1</guid></item><item><title>HomeRobot Open Vocabulary Mobile Manipulation Challenge 2023 Participant Report (Team KuzHum)</title><link>http://arxiv.org/abs/2401.12048v1</link><description>We report an improvements to NeurIPS 2023 HomeRobot: Open Vocabulary MobileManipulation (OVMM) Challenge reinforcement learning baseline. Morespecifically, we propose more accurate semantic segmentation module, along withbetter place skill policy, and high-level heuristic that outperforms thebaseline by 2.4% of overall success rate (sevenfold improvement) and 8.2% ofpartial success rate (1.75 times improvement) on Test Standard split of thechallenge dataset. With aforementioned enhancements incorporated our agentscored 3rd place in the challenge on both simulation and real-world stages.</description><author>Volodymyr Kuzma, Vladyslav Humennyy, Ruslan Partsey</author><pubDate>Mon, 22 Jan 2024 15:40:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12048v1</guid></item><item><title>Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D</title><link>http://arxiv.org/abs/2401.12046v1</link><description>Many complex robotic manipulation tasks can be decomposed as a sequence ofpick and place actions. Training a robotic agent to learn this sequence overmany different starting conditions typically requires many iterations ordemonstrations, especially in 3D environments. In this work, we propose FourierTransporter (\ours{}) which leverages the two-fold $\SE(d)\times\SE(d)$symmetry in the pick-place problem to achieve much higher sample efficiency.\ours{} is an open-loop behavior cloning method trained using expertdemonstrations to predict pick-place actions on new environments. \ours{} isconstrained to incorporate symmetries of the pick and place actionsindependently. Our method utilizes a fiber space Fourier transformation thatallows for memory-efficient construction. We test our proposed network on theRLbench benchmark and achieve state-of-the-art results across various tasks.</description><author>Haojie Huang, Owen Howell, Xupeng Zhu, Dian Wang, Robin Walters, Robert Platt</author><pubDate>Mon, 22 Jan 2024 15:38:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12046v1</guid></item><item><title>The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images</title><link>http://arxiv.org/abs/2401.08865v2</link><description>This paper investigates discrepancies in how neural networks learn fromdifferent imaging domains, which are commonly overlooked when adopting computervision techniques from the domain of natural images to other specializeddomains such as medical images. Recent works have found that the generalizationerror of a trained network typically increases with the intrinsic dimension($d_{data}$) of its training set. Yet, the steepness of this relationshipvaries significantly between medical (radiological) and natural imagingdomains, with no existing theoretical explanation. We address this gap inknowledge by establishing and empirically validating a generalization scalinglaw with respect to $d_{data}$, and propose that the substantial scalingdiscrepancy between the two considered domains may be at least partiallyattributed to the higher intrinsic "label sharpness" ($K_F$) of medical imagingdatasets, a metric which we propose. Next, we demonstrate an additional benefitof measuring the label sharpness of a training set: it is negatively correlatedwith the trained model's adversarial robustness, which notably leads to modelsfor medical images having a substantially higher vulnerability to adversarialattack. Finally, we extend our $d_{data}$ formalism to the related metric oflearned representation intrinsic dimension ($d_{repr}$), derive ageneralization scaling law with respect to $d_{repr}$, and show that $d_{data}$serves as an upper bound for $d_{repr}$. Our theoretical results are supportedby thorough experiments with six models and eleven natural and medical imagingdatasets over a range of training set sizes. Our findings offer insights intothe influence of intrinsic dataset properties on generalization, representationlearning, and robustness in deep neural networks.</description><author>Nicholas Konz, Maciej A. Mazurowski</author><pubDate>Mon, 22 Jan 2024 15:30:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08865v2</guid></item><item><title>Look, Listen and Recognise: Character-Aware Audio-Visual Subtitling</title><link>http://arxiv.org/abs/2401.12039v1</link><description>The goal of this paper is automatic character-aware subtitle generation.Given a video and a minimal amount of metadata, we propose an audio-visualmethod that generates a full transcript of the dialogue, with precise speechtimestamps, and the character speaking identified. The key idea is to first useaudio-visual cues to select a set of high-precision audio exemplars for eachcharacter, and then use these exemplars to classify all speech segments byspeaker identity. Notably, the method does not require face detection ortracking. We evaluate the method over a variety of TV sitcoms, includingSeinfeld, Fraiser and Scrubs. We envision this system being useful for theautomatic generation of subtitles to improve the accessibility of the vastamount of videos available on modern streaming services. Project page :\url{https://www.robots.ox.ac.uk/~vgg/research/look-listen-recognise/}</description><author>Bruno Korbar, Jaesung Huh, Andrew Zisserman</author><pubDate>Mon, 22 Jan 2024 15:26:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12039v1</guid></item><item><title>Momentum-SAM: Sharpness Aware Minimization without Computational Overhead</title><link>http://arxiv.org/abs/2401.12033v1</link><description>The recently proposed optimization algorithm for deep neural networksSharpness Aware Minimization (SAM) suggests perturbing parameters beforegradient calculation by a gradient ascent step to guide the optimization intoparameter space regions of flat loss. While significant generalizationimprovements and thus reduction of overfitting could be demonstrated, thecomputational costs are doubled due to the additionally needed gradientcalculation, making SAM unfeasible in case of limited computationallycapacities. Motivated by Nesterov Accelerated Gradient (NAG) we proposeMomentum-SAM (MSAM), which perturbs parameters in the direction of theaccumulated momentum vector to achieve low sharpness without significantcomputational overhead or memory demands over SGD or Adam. We evaluate MSAM indetail and reveal insights on separable mechanisms of NAG, SAM and MSAMregarding training optimization and generalization. Code is available athttps://github.com/MarlonBecker/MSAM.</description><author>Marlon Becker, Frederick Altrock, Benjamin Risse</author><pubDate>Mon, 22 Jan 2024 15:19:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12033v1</guid></item><item><title>MINT: A wrapper to make multi-modal and multi-image AI models interactive</title><link>http://arxiv.org/abs/2401.12032v1</link><description>During the diagnostic process, doctors incorporate multimodal informationincluding imaging and the medical history - and similarly medical AIdevelopment has increasingly become multimodal. In this paper we tackle a moresubtle challenge: doctors take a targeted medical history to obtain only themost pertinent pieces of information; how do we enable AI to do the same? Wedevelop a wrapper method named MINT (Make your model INTeractive) thatautomatically determines what pieces of information are most valuable at eachstep, and ask for only the most useful information. We demonstrate the efficacyof MINT wrapping a skin disease prediction model, where multiple images and aset of optional answers to $25$ standard metadata questions (i.e., structuredmedical history) are used by a multi-modal deep network to provide adifferential diagnosis. We show that MINT can identify whether metadata inputsare needed and if so, which question to ask next. We also demonstrate that whencollecting multiple images, MINT can identify if an additional image would bebeneficial, and if so, which type of image to capture. We showed that MINTreduces the number of metadata and image inputs needed by 82% and 36.2%respectively, while maintaining predictive performance. Using real-world AIdermatology system data, we show that needing fewer inputs can retain usersthat may otherwise fail to complete the system submission and drop off withouta diagnosis. Qualitative examples show MINT can closely mimic the step-by-stepdecision making process of a clinical workflow and how this is different forstraight forward cases versus more difficult, ambiguous cases. Finally wedemonstrate how MINT is robust to different underlying multi-model classifiersand can be easily adapted to user requirements without significant modelre-training.</description><author>Jan Freyberg, Abhijit Guha Roy, Terry Spitz, Beverly Freeman, Mike Schaekermann, Patricia Strachan, Eva Schnider, Renee Wong, Dale R Webster, Alan Karthikesalingam, Yun Liu, Krishnamurthy Dvijotham, Umesh Telang</author><pubDate>Mon, 22 Jan 2024 15:17:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12032v1</guid></item><item><title>Multimodal Visual-Tactile Representation Learning through Self-Supervised Contrastive Pre-Training</title><link>http://arxiv.org/abs/2401.12024v1</link><description>The rapidly evolving field of robotics necessitates methods that canfacilitate the fusion of multiple modalities. Specifically, when it comes tointeracting with tangible objects, effectively combining visual and tactilesensory data is key to understanding and navigating the complex dynamics of thephysical world, enabling a more nuanced and adaptable response to changingenvironments. Nevertheless, much of the earlier work in merging these twosensory modalities has relied on supervised methods utilizing datasets labeledby humans.This paper introduces MViTac, a novel methodology that leveragescontrastive learning to integrate vision and touch sensations in aself-supervised fashion. By availing both sensory inputs, MViTac leveragesintra and inter-modality losses for learning representations, resulting inenhanced material property classification and more adept grasping prediction.Through a series of experiments, we showcase the effectiveness of our methodand its superiority over existing state-of-the-art self-supervised andsupervised techniques. In evaluating our methodology, we focus on two distincttasks: material classification and grasping success prediction. Our resultsindicate that MViTac facilitates the development of improved modality encoders,yielding more robust representations as evidenced by linear probingassessments.</description><author>Vedant Dave, Fotios Lygerakis, Elmar Rueckert</author><pubDate>Mon, 22 Jan 2024 15:11:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12024v1</guid></item><item><title>Augment on Manifold: Mixup Regularization with UMAP</title><link>http://arxiv.org/abs/2312.13141v2</link><description>Data augmentation techniques play an important role in enhancing theperformance of deep learning models. Despite their proven benefits in computervision tasks, their application in the other domains remains limited. Thispaper proposes a Mixup regularization scheme, referred to as UMAP Mixup,designed for ``on-manifold" automated data augmentation for deep learningpredictive models. The proposed approach ensures that the Mixup operationsresult in synthesized samples that lie on the data manifold of the features andlabels by utilizing a dimensionality reduction technique known as uniformmanifold approximation and projection. Evaluations across diverse regressiontasks show that UMAP Mixup is competitive with or outperforms other Mixupvariants, show promise for its potential as an effective tool for enhancing thegeneralization performance of deep learning models.</description><author>Yousef El-Laham, Elizabeth Fons, Dillon Daudert, Svitlana Vyetrenko</author><pubDate>Mon, 22 Jan 2024 15:07:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13141v2</guid></item><item><title>IPR-NeRF: Ownership Verification meets Neural Radiance Field</title><link>http://arxiv.org/abs/2401.09495v3</link><description>Neural Radiance Field (NeRF) models have gained significant attention in thecomputer vision community in the recent past with state-of-the-art visualquality and produced impressive demonstrations. Since then, technopreneurs havesought to leverage NeRF models into a profitable business. Therefore, NeRFmodels make it worth the risk of plagiarizers illegally copying,re-distributing, or misusing those models. This paper proposes a comprehensiveintellectual property (IP) protection framework for the NeRF model in bothblack-box and white-box settings, namely IPR-NeRF. In the black-box setting, adiffusion-based solution is introduced to embed and extract the watermark via atwo-stage optimization process. In the white-box setting, a designated digitalsignature is embedded into the weights of the NeRF model by adopting the signloss objective. Our extensive experiments demonstrate that not only does ourapproach maintain the fidelity (\ie, the rendering quality) of IPR-NeRF models,but it is also robust against both ambiguity and removal attacks compared toprior arts.</description><author>Win Kent Ong, Kam Woh Ng, Chee Seng Chan, Yi Zhe Song, Tao Xiang</author><pubDate>Mon, 22 Jan 2024 15:05:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.09495v3</guid></item><item><title>Annotation Sensitivity: Training Data Collection Methods Affect Model Performance</title><link>http://arxiv.org/abs/2311.14212v3</link><description>When training data are collected from human annotators, the design of theannotation instrument, the instructions given to annotators, thecharacteristics of the annotators, and their interactions can impact trainingdata. This study demonstrates that design choices made when creating anannotation instrument also impact the models trained on the resultingannotations. We introduce the term annotation sensitivity to refer to theimpact of annotation data collection methods on the annotations themselves andon downstream model performance and predictions. We collect annotations of hatespeech and offensive language in five experimental conditions of an annotationinstrument, randomly assigning annotators to conditions. We then fine-tune BERTmodels on each of the five resulting datasets and evaluate model performance ona holdout portion of each condition. We find considerable differences betweenthe conditions for 1) the share of hate speech/offensive language annotations,2) model performance, 3) model predictions, and 4) model learning curves. Ourresults emphasize the crucial role played by the annotation instrument whichhas received little attention in the machine learning literature. We call foradditional research into how and why the instrument impacts the annotations toinform the development of best practices in instrument design.</description><author>Christoph Kern, Stephanie Eckman, Jacob Beck, Rob Chew, Bolei Ma, Frauke Kreuter</author><pubDate>Mon, 22 Jan 2024 15:05:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14212v3</guid></item><item><title>Stereo-Matching Knowledge Distilled Monocular Depth Estimation Filtered by Multiple Disparity Consistency</title><link>http://arxiv.org/abs/2401.12019v1</link><description>In stereo-matching knowledge distillation methods of the self-supervisedmonocular depth estimation, the stereo-matching network's knowledge isdistilled into a monocular depth network through pseudo-depth maps. In thesemethods, the learning-based stereo-confidence network is generally utilized toidentify errors in the pseudo-depth maps to prevent transferring the errors.However, the learning-based stereo-confidence networks should be trained withground truth (GT), which is not feasible in a self-supervised setting. In thispaper, we propose a method to identify and filter errors in the pseudo-depthmap using multiple disparity maps by checking their consistency without theneed for GT and a training process. Experimental results show that the proposedmethod outperforms the previous methods and works well on variousconfigurations by filtering out erroneous areas where the stereo-matching isvulnerable, especially such as textureless regions, occlusion boundaries, andreflective surfaces.</description><author>Woonghyun Ka, Jae Young Lee, Jaehyun Choi, Junmo Kim</author><pubDate>Mon, 22 Jan 2024 15:05:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12019v1</guid></item><item><title>Neural Stochastic Differential Equations with Change Points: A Generative Adversarial Approach</title><link>http://arxiv.org/abs/2312.13152v2</link><description>Stochastic differential equations (SDEs) have been widely used to model realworld random phenomena. Existing works mainly focus on the case where the timeseries is modeled by a single SDE, which might be restrictive for modeling timeseries with distributional shift. In this work, we propose a change pointdetection algorithm for time series modeled as neural SDEs. Given a time seriesdataset, the proposed method jointly learns the unknown change points and theparameters of distinct neural SDE models corresponding to each change point.Specifically, the SDEs are learned under the framework of generativeadversarial networks (GANs) and the change points are detected based on theoutput of the GAN discriminator in a forward pass. At each step of the proposedalgorithm, the change points and the SDE model parameters are updated in analternating fashion. Numerical results on both synthetic and real datasets areprovided to validate the performance of our algorithm in comparison toclassical change point detection benchmarks, standard GAN-based neural SDEs,and other state-of-the-art deep generative models for time series data.</description><author>Zhongchang Sun, Yousef El-Laham, Svitlana Vyetrenko</author><pubDate>Mon, 22 Jan 2024 15:04:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13152v2</guid></item><item><title>Robustness to distribution shifts of compressed networks for edge devices</title><link>http://arxiv.org/abs/2401.12014v1</link><description>It is necessary to develop efficient DNNs deployed on edge devices withlimited computation resources. However, the compressed networks often executenew tasks in the target domain, which is different from the source domain wherethe original network is trained. It is important to investigate the robustnessof compressed networks in two types of data distribution shifts: domain shiftsand adversarial perturbations. In this study, we discover that compressedmodels are less robust to distribution shifts than their original networks.Interestingly, larger networks are more vulnerable to losing robustness thansmaller ones, even when they are compressed to a similar size as the smallernetworks. Furthermore, compact networks obtained by knowledge distillation aremuch more robust to distribution shifts than pruned networks. Finally,post-training quantization is a reliable method for achieving significantrobustness to distribution shifts, and it outperforms both pruned and distilledmodels in terms of robustness.</description><author>Lulan Shen, Ali Edalati, Brett Meyer, Warren Gross, James J. Clark</author><pubDate>Mon, 22 Jan 2024 15:00:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12014v1</guid></item><item><title>MixRT: Mixed Neural Representations For Real-Time NeRF Rendering</title><link>http://arxiv.org/abs/2312.11841v4</link><description>Neural Radiance Field (NeRF) has emerged as a leading technique for novelview synthesis, owing to its impressive photorealistic reconstruction andrendering capability. Nevertheless, achieving real-time NeRF rendering inlarge-scale scenes has presented challenges, often leading to the adoption ofeither intricate baked mesh representations with a substantial number oftriangles or resource-intensive ray marching in baked representations. Wechallenge these conventions, observing that high-quality geometry, representedby meshes with substantial triangles, is not necessary for achievingphotorealistic rendering quality. Consequently, we propose MixRT, a novel NeRFrepresentation that includes a low-quality mesh, a view-dependent displacementmap, and a compressed NeRF model. This design effectively harnesses thecapabilities of existing graphics hardware, thus enabling real-time NeRFrendering on edge devices. Leveraging a highly-optimized WebGL-based renderingframework, our proposed MixRT attains real-time rendering speeds on edgedevices (over 30 FPS at a resolution of 1280 x 720 on a MacBook M1 Pro laptop),better rendering quality (0.2 PSNR higher in indoor scenes of the Unbounded-360datasets), and a smaller storage size (less than 80% compared tostate-of-the-art methods).</description><author>Chaojian Li, Bichen Wu, Peter Vajda, Yingyan, Lin</author><pubDate>Mon, 22 Jan 2024 14:59:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.11841v4</guid></item><item><title>TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for Lazy Clients</title><link>http://arxiv.org/abs/2401.12012v1</link><description>Federated learning is a distributed collaborative machine learning paradigmthat has gained strong momentum in recent years. In federated learning, acentral server periodically coordinates models with clients and aggregates themodels trained locally by clients without necessitating access to local data.Despite its potential, the implementation of federated learning continues toencounter several challenges, predominantly the slow convergence that islargely due to data heterogeneity. The slow convergence becomes particularlyproblematic in cross-device federated learning scenarios where clients may bestrongly limited by computing power and storage space, and hence counteractingmethods that induce additional computation or memory cost on the client sidesuch as auxiliary objective terms and larger training iterations can beimpractical. In this paper, we propose a novel federated aggregation strategy,TurboSVM-FL, that poses no additional computation burden on the client side andcan significantly accelerate convergence for federated classification task,especially when clients are "lazy" and train their models solely for few epochsfor next global aggregation. TurboSVM-FL extensively utilizes support vectormachine to conduct selective aggregation and max-margin spread-outregularization on class embeddings. We evaluate TurboSVM-FL on multipledatasets including FEMNIST, CelebA, and Shakespeare using user-independentvalidation with non-iid data distribution. Our results show that TurboSVM-FLcan significantly outperform existing popular algorithms on convergence rateand reduce communication rounds while delivering better test metrics includingaccuracy, F1 score, and MCC.</description><author>Mengdi Wang, Anna Bodonhelyi, Efe Bozkir, Enkelejda Kasneci</author><pubDate>Mon, 22 Jan 2024 14:59:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12012v1</guid></item><item><title>Zero and Few-shot Semantic Parsing with Ambiguous Inputs</title><link>http://arxiv.org/abs/2306.00824v2</link><description>Despite the frequent challenges posed by ambiguity when representing meaningvia natural language, it is often ignored or deliberately removed in tasksmapping language to formally-designed representations, which generally assume aone-to-one mapping between linguistic and formal representations. We attempt toaddress this shortcoming by introducing AmP, a framework, dataset, andchallenge for translating ambiguous natural language to formal representationslike logic and code. We define templates and generate data for fivewell-documented linguistic ambiguities. Using AmP, we investigate how severalfew-shot text-to-code systems handle ambiguity, introducing three new metrics.We find that large pre-trained models perform poorly at capturing thedistribution of possible meanings without deliberate instruction. However,models are able to capture the distribution well when ambiguity is attested intheir inputs. These results motivate a call for including ambiguity explicitlyin datasets and promote considering the distribution of possible outputs whenevaluating systems. Data and code: https://github.com/esteng/ambiguous_parsing</description><author>Elias Stengel-Eskin, Kyle Rawlins, Benjamin Van Durme</author><pubDate>Mon, 22 Jan 2024 14:57:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00824v2</guid></item><item><title>Forging Tokens for Improved Storage-efficient Training</title><link>http://arxiv.org/abs/2312.10105v2</link><description>Recent advancements in Deep Neural Network (DNN) models have significantlyimproved performance across computer vision tasks. However, achieving highlygeneralizable and high-performing vision models requires extensive datasets,leading to large storage requirements. This storage challenge poses a criticalbottleneck for scaling up vision models. Motivated by the success of discreterepresentations, SeiT proposes to use Vector-Quantized (VQ) feature vectors(i.e., tokens) as network inputs for vision classification. However, applyingtraditional data augmentations to tokens faces challenges due to input domainshift. To address this issue, we introduce TokenAdapt and ColorAdapt, simpleyet effective token-based augmentation strategies. TokenAdapt realigns tokenembedding space for compatibility with spatial augmentations, preserving themodel's efficiency without requiring fine-tuning. Additionally, ColorAdaptaddresses color-based augmentations for tokens inspired by Adaptive InstanceNormalization (AdaIN). We evaluate our approach across various scenarios,including storage-efficient ImageNet-1k classification, fine-grainedclassification, robustness benchmarks, and ADE-20k semantic segmentation.Experimental results demonstrate consistent performance improvement in diverseexperiments. Code is available at https://github.com/naver-ai/tokenadapt.</description><author>Minhyun Lee, Song Park, Byeongho Heo, Dongyoon Han, Hyunjung Shim</author><pubDate>Mon, 22 Jan 2024 14:56:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10105v2</guid></item><item><title>Tensor-view Topological Graph Neural Network</title><link>http://arxiv.org/abs/2401.12007v1</link><description>Graph classification is an important learning task for graph-structured data.Graph neural networks (GNNs) have recently gained growing attention in graphlearning and have shown significant improvements in many important graphproblems. Despite their state-of-the-art performances, existing GNNs only uselocal information from a very limited neighborhood around each node, sufferingfrom loss of multi-modal information and overheads of excessive computation. Toaddress these issues, we propose a novel Tensor-view Topological Graph NeuralNetwork (TTG-NN), a class of simple yet effective topological deep learningbuilt upon persistent homology, graph convolution, and tensor operations. Thisnew method incorporates tensor learning to simultaneously capture Tensor-viewTopological (TT), as well as Tensor-view Graph (TG) structural information onboth local and global levels. Computationally, to fully exploit graph topologyand structure, we propose two flexible TT and TG representation learningmodules that disentangle feature tensor aggregation and transformation andlearn to preserve multi-modal structure with less computation. Theoretically,we derive high probability bounds on both the out-of-sample and in-sample meansquared approximation errors for our proposed Tensor Transformation Layer(TTL). Real data experiments show that the proposed TTG-NN outperforms 20state-of-the-art methods on various graph benchmarks.</description><author>Tao Wen, Elynn Chen, Yuzhou Chen</author><pubDate>Mon, 22 Jan 2024 14:55:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12007v1</guid></item><item><title>ALMs: Authorial Language Models for Authorship Attribution</title><link>http://arxiv.org/abs/2401.12005v1</link><description>In this paper, we introduce an authorship attribution method called AuthorialLanguage Models (ALMs) that involves identifying the most likely author of aquestioned document based on the perplexity of the questioned documentcalculated for a set of causal language models fine-tuned on the writings of aset of candidate author. We benchmarked ALMs against state-of-art-systems usingthe CCAT50 dataset and the Blogs50 datasets. We find that ALMs achieves amacro-average accuracy score of 83.6% on Blogs50, outperforming all othermethods, and 74.9% on CCAT50, matching the performance of the best method. Toassess the performance of ALMs on shorter texts, we also conducted textablation testing. We found that to reach a macro-average accuracy of 70%, ALMsneeds 40 tokens on Blogs50 and 400 tokens on CCAT50, while to reach 60% ALMsrequires 20 tokens on Blogs50 and 70 tokens on CCAT50.</description><author>Weihang Huang, Akira Murakami, Jack Grieve</author><pubDate>Mon, 22 Jan 2024 14:53:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12005v1</guid></item><item><title>Decision Tree Search as a Markov Decision Problem</title><link>http://arxiv.org/abs/2309.12701v2</link><description>Finding an optimal decision tree for a supervised learning task is achallenging combinatorial problem to solve at scale. It was recently proposedto frame the problem as a Markov Decision Problem (MDP) and use deepreinforcement learning to tackle scaling. Unfortunately, these methods are notcompetitive with the current branch-and-bound state-of-the-art. We proposeinstead to scale the resolution of such MDPs using an information-theoretictests generating function that heuristically, and dynamically for every state,limits the set of admissible test actions to a few good candidates. As asolver, we show empirically that our algorithm is at the very least competitivewith branch-and-bound alternatives. As a machine learning tool, a key advantageof our approach is to solve for multiple complexity-performance trade-offs atvirtually no additional cost. With such a set of solutions, a user can thenselect the tree that generalizes best and which has the interpretability levelthat best suits their needs, which no current branch-and-bound method allows.</description><author>Hector Kohler, Riad Akrour, Philippe Preux</author><pubDate>Mon, 22 Jan 2024 14:53:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.12701v2</guid></item><item><title>NLCG-Net: A Model-Based Zero-Shot Learning Framework for Undersampled Quantitative MRI Reconstruction</title><link>http://arxiv.org/abs/2401.12004v1</link><description>Typical quantitative MRI (qMRI) methods estimate parameter maps after imagereconstructing, which is prone to biases and error propagation. We propose aNonlinear Conjugate Gradient (NLCG) optimizer for model-based T2/T1 estimation,which incorporates U-Net regularization trained in a scan-specific manner. Thisend-to-end method directly estimates qMRI maps from undersampled k-space datausing mono-exponential signal modeling with zero-shot scan-specific neuralnetwork regularization to enable high fidelity T1 and T2 mapping. T2 and T1mapping results demonstrate the ability of the proposed NLCG-Net to improveestimation quality compared to subspace reconstruction at high accelerations.</description><author>Xinrui Jiang, Yohan Jun, Jaejin Cho, Mengze Gao, Xingwang Yong, Berkin Bilgic</author><pubDate>Mon, 22 Jan 2024 14:53:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12004v1</guid></item><item><title>HgbNet: predicting hemoglobin level/anemia degree from EHR data</title><link>http://arxiv.org/abs/2401.12002v1</link><description>Anemia is a prevalent medical condition that typically requires invasiveblood tests for diagnosis and monitoring. Electronic health records (EHRs) haveemerged as valuable data sources for numerous medical studies. EHR-basedhemoglobin level/anemia degree prediction is non-invasive and rapid but stillfaces some challenges due to the fact that EHR data is typically an irregularmultivariate time series containing a significant number of missing values andirregular time intervals. To address these issues, we introduce HgbNet, amachine learning-based prediction model that emulates clinicians'decision-making processes for hemoglobin level/anemia degree prediction. Themodel incorporates a NanDense layer with a missing indicator to handle missingvalues and employs attention mechanisms to account for both local irregularityand global irregularity. We evaluate the proposed method using two real-worlddatasets across two use cases. In our first use case, we predict hemoglobinlevel/anemia degree at moment T+1 by utilizing records from moments prior toT+1. In our second use case, we integrate all historical records withadditional selected test results at moment T+1 to predict hemoglobinlevel/anemia degree at the same moment, T+1. HgbNet outperforms the bestbaseline results across all datasets and use cases. These findings demonstratethe feasibility of estimating hemoglobin levels and anemia degree from EHRdata, positioning HgbNet as an effective non-invasive anemia diagnosis solutionthat could potentially enhance the quality of life for millions of affectedindividuals worldwide. To our knowledge, HgbNet is the first machine learningmodel leveraging EHR data for hemoglobin level/anemia degree prediction.</description><author>Zhuo Zhi, Moe Elbadawi, Adam Daneshmend, Mine Orlu, Abdul Basit, Andreas Demosthenous, Miguel Rodrigues</author><pubDate>Mon, 22 Jan 2024 14:52:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12002v1</guid></item><item><title>CapST: An Enhanced and Lightweight Model Attribution Approach for Synthetic Videos</title><link>http://arxiv.org/abs/2311.03782v3</link><description>Deepfake videos, generated through AI faceswapping techniques, have garneredconsiderable attention due to their potential for powerful impersonationattacks. While existing research primarily focuses on binary classification todiscern between real and fake videos, however determining the specificgeneration model for a fake video is crucial for forensic investigation.Addressing this gap, this paper investigates the model attribution problem ofDeepfake videos from a recently proposed dataset, Deepfakes from DifferentModels (DFDM), derived from various Autoencoder models. The dataset comprises6,450 Deepfake videos generated by five distinct models with variations inencoder, decoder, intermediate layer, input resolution, and compression ratio.This study formulates Deepfakes model attribution as a multiclassclassification task, proposing a segment of VGG19 as a feature extractionbackbone, known for its effectiveness in imagerelated tasks, while integrated aCapsule Network with a Spatio-Temporal attention mechanism. The Capsule modulecaptures intricate hierarchies among features for robust identification ofdeepfake attributes. Additionally, the video-level fusion technique leveragestemporal attention mechanisms to handle concatenated feature vectors,capitalizing on inherent temporal dependencies in deepfake videos. Byaggregating insights across frames, our model gains a comprehensiveunderstanding of video content, resulting in more precise predictions.Experimental results on the deepfake benchmark dataset (DFDM) demonstrate theefficacy of our proposed method, achieving up to a 4% improvement in accuratelycategorizing deepfake videos compared to baseline models while demanding fewercomputational resources.</description><author>Wasim Ahmad, Yan-Tsung Peng, Yuan-Hao Chang, Gaddisa Olani Ganfure, Sarwar Khan, Sahibzada Adil Shahzad</author><pubDate>Mon, 22 Jan 2024 14:52:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03782v3</guid></item><item><title>Modeling Stereo-Confidence Out of the End-to-End Stereo-Matching Network via Disparity Plane Sweep</title><link>http://arxiv.org/abs/2401.12001v1</link><description>We propose a novel stereo-confidence that can be measured externally tovarious stereo-matching networks, offering an alternative input modality choiceof the cost volume for learning-based approaches, especially in safety-criticalsystems. Grounded in the foundational concepts of disparity definition and thedisparity plane sweep, the proposed stereo-confidence method is built upon theidea that any shift in a stereo-image pair should be updated in a correspondingamount shift in the disparity map. Based on this idea, the proposedstereo-confidence method can be summarized in three folds. 1) Using thedisparity plane sweep, multiple disparity maps can be obtained and treated as a3-D volume (predicted disparity volume), like the cost volume is constructed.2) One of these disparity maps serves as an anchor, allowing us to define adesirable (or ideal) disparity profile at every spatial point. 3) By comparingthe desirable and predicted disparity profiles, we can quantify the level ofmatching ambiguity between left and right images for confidence measurement.Extensive experimental results using various stereo-matching networks anddatasets demonstrate that the proposed stereo-confidence method not only showscompetitive performance on its own but also consistent performance improvementswhen it is used as an input modality for learning-based stereo-confidencemethods.</description><author>Jae Young Lee, Woonghyun Ka, Jaehyun Choi, Junmo Kim</author><pubDate>Mon, 22 Jan 2024 14:52:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12001v1</guid></item><item><title>Integrating Statistical Significance and Discriminative Power in Pattern Discovery</title><link>http://arxiv.org/abs/2401.12000v1</link><description>Pattern discovery plays a central role in both descriptive and predictivetasks across multiple domains. Actionable patterns must meet rigorousstatistical significance criteria and, in the presence of target variables,further uphold discriminative power. Our work addresses the underexplored areaof guiding pattern discovery by integrating statistical significance anddiscriminative power criteria into state-of-the-art algorithms while preservingpattern quality. We also address how pattern quality thresholds, imposed bysome algorithms, can be rectified to accommodate these additional criteria. Totest the proposed methodology, we select the triclustering task as the guidingpattern discovery case and extend well-known greedy and multi-objectiveoptimization triclustering algorithms, $\delta$-Trimax and TriGen, that usevarious pattern quality criteria, such as Mean Squared Residual (MSR), LeastSquared Lines (LSL), and Multi Slope Measure (MSL). Results from three casestudies show the role of the proposed methodology in discovering patterns withpronounced improvements of discriminative power and statistical significancewithout quality deterioration, highlighting its importance in supervisedlyguiding the search. Although the proposed methodology is motivated overmultivariate time series data, it can be straightforwardly extended to patterndiscovery tasks involving multivariate, N-way (N&gt;3), transactional, andsequential data structures. Availability: The code is freely available athttps://github.com/JupitersMight/MOF_Triclustering under the MIT license.</description><author>Leonardo Alexandre, Rafael S. Costa, Rui Henriques</author><pubDate>Mon, 22 Jan 2024 14:51:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.12000v1</guid></item><item><title>Expert-Driven Monitoring of Operational ML Models</title><link>http://arxiv.org/abs/2401.11993v1</link><description>We propose Expert Monitoring, an approach that leverages domain expertise toenhance the detection and mitigation of concept drift in machine learning (ML)models. Our approach supports practitioners by consolidating domain expertiserelated to concept drift-inducing events, making this expertise accessible toon-call personnel, and enabling automatic adaptability with expert oversight.</description><author>Joran Leest, Claudia Raibulet, Ilias Gerostathopoulos, Patricia Lago</author><pubDate>Mon, 22 Jan 2024 14:46:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11993v1</guid></item><item><title>TWIZ-v2: The Wizard of Multimodal Conversational-Stimulus</title><link>http://arxiv.org/abs/2310.02118v2</link><description>In this report, we describe the vision, challenges, and scientificcontributions of the Task Wizard team, TWIZ, in the Alexa Prize TaskBotChallenge 2022. Our vision, is to build TWIZ bot as an helpful, multimodal,knowledgeable, and engaging assistant that can guide users towards thesuccessful completion of complex manual tasks. To achieve this, we focus ourefforts on three main research questions: (1) Humanly-Shaped Conversations, byproviding information in a knowledgeable way; (2) Multimodal Stimulus, makinguse of various modalities including voice, images, and videos; and (3)Zero-shot Conversational Flows, to improve the robustness of the interaction tounseen scenarios. TWIZ is an assistant capable of supporting a wide range oftasks, with several innovative features such as creative cooking, videonavigation through voice, and the robust TWIZ-LLM, a Large Language Modeltrained for dialoguing about complex manual tasks. Given ratings and feedbackprovided by users, we observed that TWIZ bot is an effective and robust system,capable of guiding users through tasks while providing several multimodalstimuli.</description><author>Rafael Ferreira, Diogo Tavares, Diogo Silva, Rodrigo Valério, João Bordalo, Inês Simões, Vasco Ramos, David Semedo, João Magalhães</author><pubDate>Mon, 22 Jan 2024 14:41:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02118v2</guid></item><item><title>Scaling Face Interaction Graph Networks to Real World Scenes</title><link>http://arxiv.org/abs/2401.11985v1</link><description>Accurately simulating real world object dynamics is essential for variousapplications such as robotics, engineering, graphics, and design. To bettercapture complex real dynamics such as contact and friction, learned simulatorsbased on graph networks have recently shown great promise. However, applyingthese learned simulators to real scenes comes with two major challenges: first,scaling learned simulators to handle the complexity of real world scenes whichcan involve hundreds of objects each with complicated 3D shapes, and second,handling inputs from perception rather than 3D state information. Here weintroduce a method which substantially reduces the memory required to rungraph-based learned simulators. Based on this memory-efficient simulationmodel, we then present a perceptual interface in the form of editable NeRFswhich can convert real-world scenes into a structured representation that canbe processed by graph network simulator. We show that our method usessubstantially less memory than previous graph-based simulators while retainingtheir accuracy, and that the simulators learned in synthetic environments canbe applied to real world scenes captured from multiple camera angles. Thispaves the way for expanding the application of learned simulators to settingswhere only perceptual information is available at inference time.</description><author>Tatiana Lopez-Guevara, Yulia Rubanova, William F. Whitney, Tobias Pfaff, Kimberly Stachenfeld, Kelsey R. Allen</author><pubDate>Mon, 22 Jan 2024 14:38:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11985v1</guid></item><item><title>Can ChatGPT Play the Role of a Teaching Assistant in an Introductory Programming Course?</title><link>http://arxiv.org/abs/2312.07343v2</link><description>The emergence of Large language models (LLMs) is expected to have a majorimpact on education. This paper explores the potential of using ChatGPT, anLLM, as a virtual Teaching Assistant (TA) in an Introductory ProgrammingCourse. We evaluate ChatGPT's capabilities by comparing its performance withthat of human TAs in some of the important TA functions. The TA functions whichwe focus on include (1) grading student code submissions, and (2) providingfeedback to undergraduate students in an introductory programming course.Firstly, we assess ChatGPT's proficiency in grading student code submissionsusing a given grading rubric and compare its performance with the gradesassigned by human TAs. Secondly, we analyze the quality and relevance of thefeedback provided by ChatGPT. This evaluation considers how well ChatGPTaddresses mistakes and offers suggestions for improvement in student solutionsfrom both code correctness and code quality perspectives. We conclude with adiscussion on the implications of integrating ChatGPT into computing educationfor automated grading, personalized learning experiences, and instructionalsupport.</description><author>Anishka, Atharva Mehta, Nipun Gupta, Aarav Balachandran, Dhruv Kumar, Pankaj Jalote</author><pubDate>Mon, 22 Jan 2024 14:29:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07343v2</guid></item><item><title>Cross-Validation Conformal Risk Control</title><link>http://arxiv.org/abs/2401.11974v1</link><description>Conformal risk control (CRC) is a recently proposed technique that appliespost-hoc to a conventional point predictor to provide calibration guarantees.Generalizing conformal prediction (CP), with CRC, calibration is ensured for aset predictor that is extracted from the point predictor to control a riskfunction such as the probability of miscoverage or the false negative rate. Theoriginal CRC requires the available data set to be split between training andvalidation data sets. This can be problematic when data availability islimited, resulting in inefficient set predictors. In this paper, a novel CRCmethod is introduced that is based on cross-validation, rather than onvalidation as the original CRC. The proposed cross-validation CRC (CV-CRC)extends a version of the jackknife-minmax from CP to CRC, allowing for thecontrol of a broader range of risk functions. CV-CRC is proved to offertheoretical guarantees on the average risk of the set predictor. Furthermore,numerical experiments show that CV-CRC can reduce the average set size withrespect to CRC when the available data are limited.</description><author>Kfir M. Cohen, Sangwoo Park, Osvaldo Simeone, Shlomo Shamai</author><pubDate>Mon, 22 Jan 2024 14:26:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11974v1</guid></item><item><title>Synergizing Machine Learning &amp; Symbolic Methods: A Survey on Hybrid Approaches to Natural Language Processing</title><link>http://arxiv.org/abs/2401.11972v1</link><description>The advancement of machine learning and symbolic approaches have underscoredtheir strengths and weaknesses in Natural Language Processing (NLP). Whilemachine learning approaches are powerful in identifying patterns in data, theyoften fall short in learning commonsense and the factual knowledge required forthe NLP tasks. Meanwhile, the symbolic methods excel in representingknowledge-rich data. However, they struggle to adapt dynamic data andgeneralize the knowledge. Bridging these two paradigms through hybridapproaches enables the alleviation of weaknesses in both while preserving theirstrengths. Recent studies extol the virtues of this union, showcasing promisingresults in a wide range of NLP tasks. In this paper, we present an overview ofhybrid approaches used for NLP. Specifically, we delve into thestate-of-the-art hybrid approaches used for a broad spectrum of NLP tasksrequiring natural language understanding, generation, and reasoning.Furthermore, we discuss the existing resources available for hybrid approachesfor NLP along with the challenges, offering a roadmap for future directions.</description><author>Rrubaa Panchendrarajan, Arkaitz Zubiaga</author><pubDate>Mon, 22 Jan 2024 14:24:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11972v1</guid></item><item><title>Machine Learning-Based Analysis of Ebola Virus' Impact on Gene Expression in Nonhuman Primates</title><link>http://arxiv.org/abs/2401.08738v2</link><description>This study introduces the Supervised Magnitude-Altitude Scoring (SMAS)methodology, a machine learning-based approach, for analyzing gene expressiondata obtained from nonhuman primates (NHPs) infected with Ebola virus (EBOV).We utilize a comprehensive dataset of NanoString gene expression profiles fromEbola-infected NHPs, deploying the SMAS system for nuanced host-pathogeninteraction analysis. SMAS effectively combines gene selection based onstatistical significance and expression changes, employing linear classifierssuch as logistic regression to accurately differentiate between RT-qPCRpositive and negative NHP samples. A key finding of our research is theidentification of IFI6 and IFI27 as critical biomarkers, demonstratingexceptional predictive performance with 100% accuracy and Area Under the Curve(AUC) metrics in classifying various stages of Ebola infection. Alongside IFI6and IFI27, genes, including MX1, OAS1, and ISG15, were significantlyupregulated, highlighting their essential roles in the immune response to EBOV.Our results underscore the efficacy of the SMAS method in revealing complexgenetic interactions and response mechanisms during EBOV infection. Thisresearch provides valuable insights into EBOV pathogenesis and aids indeveloping more precise diagnostic tools and therapeutic strategies to addressEBOV infection in particular and viral infection in general.</description><author>Mostafa Rezapour, Muhammad Khalid Khan Niazi, Hao Lu, Aarthi Narayanan, Metin Nafi Gurcan</author><pubDate>Mon, 22 Jan 2024 14:17:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08738v2</guid></item><item><title>Claim Detection for Automated Fact-checking: A Survey on Monolingual, Multilingual and Cross-Lingual Research</title><link>http://arxiv.org/abs/2401.11969v1</link><description>Automated fact-checking has drawn considerable attention over the past fewdecades due to the increase in the diffusion of misinformation on onlineplatforms. This is often carried out as a sequence of tasks comprising (i) thedetection of sentences circulating in online platforms which constitute claimsneeding verification, followed by (ii) the verification process of thoseclaims. This survey focuses on the former, by discussing existing effortstowards detecting claims needing fact-checking, with a particular focus onmultilingual data and methods. This is a challenging and fertile directionwhere existing methods are yet far from matching human performance due to theprofoundly challenging nature of the issue. Especially, the dissemination ofinformation across multiple social platforms, articulated in multiple languagesand modalities demands more generalized solutions for combating misinformation.Focusing on multilingual misinformation, we present a comprehensive survey ofexisting multilingual claim detection research. We present state-of-the-artmultilingual claim detection research categorized into three key factors of theproblem, verifiability, priority, and similarity. Further, we present adetailed overview of the existing multilingual datasets along with thechallenges and suggest possible future advancements.</description><author>Rrubaa Panchendrarajan, Arkaitz Zubiaga</author><pubDate>Mon, 22 Jan 2024 14:17:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11969v1</guid></item><item><title>Learning-assisted Stochastic Capacity Expansion Planning: A Bayesian Optimization Approach</title><link>http://arxiv.org/abs/2401.10451v2</link><description>Solving large-scale capacity expansion problems (CEPs) is central tocost-effective decarbonization of regional-scale energy systems. To ensure theintended outcomes of CEPs, modeling uncertainty due to weather-dependentvariable renewable energy (VRE) supply and energy demand becomes cruciallyimportant. However, the resulting stochastic optimization models are often lesscomputationally tractable than their deterministic counterparts. Here, wepropose a learning-assisted approximate solution method to tractably solvetwo-stage stochastic CEPs. Our method identifies low-cost planning decisions byconstructing and solving a sequence of tractable temporally aggregatedsurrogate problems. We adopt a Bayesian optimization approach to searching thespace of time series aggregation hyperparameters and compute approximatesolutions that minimize costs on a validation set of supply-demand projections.Importantly, we evaluate solved planning outcomes on a held-out set of testprojections. We apply our approach to generation and transmission expansionplanning for a joint power-gas system spanning New England. We show that ourapproach yields an estimated cost savings of up to 3.8% in comparison tobenchmark time series aggregation approaches.</description><author>Aron Brenner, Rahman Khorramfar, Dharik Mallapragada, Saurabh Amin</author><pubDate>Mon, 22 Jan 2024 14:14:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10451v2</guid></item><item><title>Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification Using Graph Neural Networks?</title><link>http://arxiv.org/abs/2305.14578v2</link><description>Given the success of Graph Neural Networks (GNNs) for structure-aware machinelearning, many studies have explored their use for text classification, butmostly in specific domains with limited data characteristics. Moreover, somestrategies prior to GNNs relied on graph mining and classical machine learning,making it difficult to assess their effectiveness in modern settings. This workextensively investigates graph representation methods for text classification,identifying practical implications and open challenges. We compare differentgraph construction schemes using a variety of GNN architectures and setupsacross five datasets, encompassing short and long documents as well asunbalanced scenarios in diverse domains. Two Transformer-based large languagemodels are also included to complement the study. The results show that i)although the effectiveness of graphs depends on the textual input features anddomain, simple graph constructions perform better the longer the documents are,ii) graph representations are especially beneficial for longer documents,outperforming Transformer-based models, iii) graph methods are particularlyefficient at solving the task.</description><author>Margarita Bugueño, Gerard de Melo</author><pubDate>Mon, 22 Jan 2024 14:13:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.14578v2</guid></item><item><title>Bridging Evolutionary Algorithms and Reinforcement Learning: A Comprehensive Survey</title><link>http://arxiv.org/abs/2401.11963v1</link><description>Evolutionary Reinforcement Learning (ERL), which integrates EvolutionaryAlgorithms (EAs) and Reinforcement Learning (RL) for optimization, hasdemonstrated remarkable performance advancements. By fusing the strengths ofboth approaches, ERL has emerged as a promising research direction. This surveyoffers a comprehensive overview of the diverse research branches in ERL.Specifically, we systematically summarize recent advancements in relevantalgorithms and identify three primary research directions: EA-assistedoptimization of RL, RL-assisted optimization of EA, and synergisticoptimization of EA and RL. Following that, we conduct an in-depth analysis ofeach research direction, organizing multiple research branches. We elucidatethe problems that each branch aims to tackle and how the integration of EA andRL addresses these challenges. In conclusion, we discuss potential challengesand prospective future research directions across various research directions.</description><author>Pengyi Li, Jianye Hao, Hongyao Tang, Xian Fu, Yan Zheng, Ke Tang</author><pubDate>Mon, 22 Jan 2024 14:06:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11963v1</guid></item><item><title>Observation-Guided Meteorological Field Downscaling at Station Scale: A Benchmark and a New Method</title><link>http://arxiv.org/abs/2401.11960v1</link><description>Downscaling (DS) of meteorological variables involves obtaininghigh-resolution states from low-resolution meteorological fields and is animportant task in weather forecasting. Previous methods based on deep learningtreat downscaling as a super-resolution task in computer vision and utilizehigh-resolution gridded meteorological fields as supervision to improveresolution at specific grid scales. However, this approach has struggled toalign with the continuous distribution characteristics of meteorologicalfields, leading to an inherent systematic bias between the downscaled resultsand the actual observations at meteorological stations. In this paper, weextend meteorological downscaling to arbitrary scattered station scales,establish a brand new benchmark and dataset, and retrieve meteorological statesat any given station location from a coarse-resolution meteorological field.Inspired by data assimilation techniques, we integrate observational data intothe downscaling process, providing multi-scale observational priors. Buildingon this foundation, we propose a new downscaling model based on hypernetworkarchitecture, namely HyperDS, which efficiently integrates differentobservational information into the model training, achieving continuous scalemodeling of the meteorological field. Through extensive experiments, ourproposed method outperforms other specially designed baseline models onmultiple surface variables. Notably, the mean squared error (MSE) for windspeed and surface pressure improved by 67% and 19.5% compared to other methods.We will release the dataset and code subsequently.</description><author>Zili Liu, Hao Chen, Lei Bai, Wenyuan Li, Keyan Chen, Zhengyi Wang, Wanli Ouyang, Zhengxia Zou, Zhenwei Shi</author><pubDate>Mon, 22 Jan 2024 14:02:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.11960v1</guid></item></channel></rss>