<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 01 Jul 2024 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Odd-One-Out: Anomaly Detection by Comparing with Neighbors</title><link>http://arxiv.org/abs/2406.20099v1</link><description>This paper introduces a novel anomaly detection (AD) problem that focuses onidentifying `odd-looking' objects relative to the other instances within ascene. Unlike the traditional AD benchmarks, in our setting, anomalies in thiscontext are scene-specific, defined by the regular instances that make up themajority. Since object instances are often partly visible from a singleviewpoint, our setting provides multiple views of each scene as input. Toprovide a testbed for future research in this task, we introduce twobenchmarks, ToysAD-8K and PartsAD-15K. We propose a novel method that generates3D object-centric representations for each instance and detects the anomalousones through a cross-examination between the instances. We rigorously analyzeour method quantitatively and qualitatively in the presented benchmarks.</description><author>Ankan Bhunia, Changjian Li, Hakan Bilen</author><pubDate>Fri, 28 Jun 2024 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20099v1</guid></item><item><title>Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs</title><link>http://arxiv.org/abs/2406.20098v1</link><description>Multimodal large language models (MLLMs) have shown impressive success acrossmodalities such as image, video, and audio in a variety of understanding andgeneration tasks. However, current MLLMs are surprisingly poor at understandingwebpage screenshots and generating their corresponding HTML code. To addressthis problem, we propose Web2Code, a benchmark consisting of a new large-scalewebpage-to-code dataset for instruction tuning and an evaluation framework forthe webpage understanding and HTML code translation abilities of MLLMs. Fordataset construction, we leverage pretrained LLMs to enhance existingwebpage-to-code datasets as well as generate a diverse pool of new webpagesrendered into images. Specifically, the inputs are webpage images andinstructions, while the responses are the webpage's HTML code. We furtherinclude diverse natural language QA pairs about the webpage content in theresponses to enable a more comprehensive understanding of the web content. Toevaluate model performance in these tasks, we develop an evaluation frameworkfor testing MLLMs' abilities in webpage understanding and web-to-codegeneration. Extensive experiments show that our proposed dataset is beneficialnot only to our proposed tasks but also in the general visual domain, whileprevious datasets result in worse performance. We hope our work will contributeto the development of general MLLMs suitable for web-based content generationand task automation. Our data and code will be available athttps://github.com/MBZUAI-LLM/web2code.</description><author>Sukmin Yun, Haokun Lin, Rusiru Thushara, Mohammad Qazim Bhat, Yongxin Wang, Zutao Jiang, Mingkai Deng, Jinhong Wang, Tianhua Tao, Junbo Li, Haonan Li, Preslav Nakov, Timothy Baldwin, Zhengzhong Liu, Eric P. Xing, Xiaodan Liang, Zhiqiang Shen</author><pubDate>Fri, 28 Jun 2024 18:59:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20098v1</guid></item><item><title>GEO: Generative Engine Optimization</title><link>http://arxiv.org/abs/2311.09735v3</link><description>The advent of large language models (LLMs) has ushered in a new paradigm ofsearch engines that use generative models to gather and summarize informationto answer user queries. This emerging technology, which we formalize under theunified framework of generative engines (GEs), can generate accurate andpersonalized responses, rapidly replacing traditional search engines likeGoogle and Bing. Generative Engines typically satisfy queries by synthesizinginformation from multiple sources and summarizing them using LLMs. While thisshift significantly improves $\textit{user}$ utility and $\textit{generativesearch engine}$ traffic, it poses a huge challenge for the third stakeholder --website and content creators. Given the black-box and fast-moving nature ofgenerative engines, content creators have little to no control over$\textit{when}$ and $\textit{how}$ their content is displayed. With generativeengines here to stay, we must ensure the creator economy is not disadvantaged.To address this, we introduce Generative Engine Optimization (GEO), the firstnovel paradigm to aid content creators in improving their content visibility ingenerative engine responses through a flexible black-box optimization frameworkfor optimizing and defining visibility metrics. We facilitate systematicevaluation by introducing GEO-bench, a large-scale benchmark of diverse userqueries across multiple domains, along with relevant web sources to answerthese queries. Through rigorous evaluation, we demonstrate that GEO can boostvisibility by up to $40\%$ in generative engine responses. Moreover, we showthe efficacy of these strategies varies across domains, underscoring the needfor domain-specific optimization methods. Our work opens a new frontier ininformation discovery systems, with profound implications for both developersof generative engines and content creators.</description><author>Pranjal Aggarwal, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, Karthik Narasimhan, Ameet Deshpande</author><pubDate>Fri, 28 Jun 2024 18:59:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09735v3</guid></item><item><title>Fishnets: Information-Optimal, Scalable Aggregation for Sets and Graphs</title><link>http://arxiv.org/abs/2310.03812v2</link><description>Set-based learning is an essential component of modern deep learning andnetwork science. Graph Neural Networks (GNNs) and their edge-free counterpartsDeepsets have proven remarkably useful on ragged and topologically challengingdatasets. The key to learning informative embeddings for set members is aspecified aggregation function, usually a sum, max, or mean. We proposeFishnets, an aggregation strategy for learning information-optimal embeddingsfor sets of data for both Bayesian inference and graph aggregation. Wedemonstrate that i) Fishnets neural summaries can be scaled optimally to anarbitrary number of data objects, ii) Fishnets aggregations are robust tochanges in data distribution, unlike standard deepsets, iii) Fishnets saturateBayesian information content and extend to regimes where MCMC techniques failand iv) Fishnets can be used as a drop-in aggregation scheme within GNNs. Weshow that by adopting a Fishnets aggregation scheme for message passing, GNNscan achieve state-of-the-art performance versus architecture size onogbn-protein data over existing benchmarks with a fraction of learnableparameters and faster training time.</description><author>T. Lucas Makinen, Justin Alsing, Benjamin D. Wandelt</author><pubDate>Fri, 28 Jun 2024 18:59:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03812v2</guid></item><item><title>LLaRA: Supercharging Robot Learning Data for Vision-Language Policy</title><link>http://arxiv.org/abs/2406.20095v1</link><description>Large Language Models (LLMs) equipped with extensive world knowledge andstrong reasoning skills can tackle diverse tasks across domains, often byposing them as conversation-style instruction-response pairs. In this paper, wepropose LLaRA: Large Language and Robotics Assistant, a framework whichformulates robot action policy as conversations, and provides improvedresponses when trained with auxiliary data that complements policy learning.LLMs with visual inputs, i.e., Vision Language Models (VLMs), have the capacityto process state information as visual-textual prompts and generate optimalpolicy decisions in text. To train such action policy VLMs, we first introducean automated pipeline to generate diverse high-quality robotics instructiondata from existing behavior cloning data. A VLM finetuned with the resultingcollection of datasets based on a conversation-style formulation tailored forrobotics tasks, can generate meaningful robot action policy decisions. Ourexperiments across multiple simulated and real-world environments demonstratethe state-of-the-art performance of the proposed LLaRA framework. The code,datasets, and pretrained models are available athttps://github.com/LostXine/LLaRA.</description><author>Xiang Li, Cristina Mata, Jongwoo Park, Kumara Kahatapitiya, Yoo Sung Jang, Jinghuan Shang, Kanchana Ranasinghe, Ryan Burgert, Mu Cai, Yong Jae Lee, Michael S. Ryoo</author><pubDate>Fri, 28 Jun 2024 18:59:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20095v1</guid></item><item><title>Scaling Synthetic Data Creation with 1,000,000,000 Personas</title><link>http://arxiv.org/abs/2406.20094v1</link><description>We propose a novel persona-driven data synthesis methodology that leveragesvarious perspectives within a large language model (LLM) to create diversesynthetic data. To fully exploit this methodology at scale, we introducePersona Hub -- a collection of 1 billion diverse personas automatically curatedfrom web data. These 1 billion personas (~13% of the world's total population),acting as distributed carriers of world knowledge, can tap into almost everyperspective encapsulated within the LLM, thereby facilitating the creation ofdiverse synthetic data at scale for various scenarios. By showcasing PersonaHub's use cases in synthesizing high-quality mathematical and logical reasoningproblems, instructions (i.e., user prompts), knowledge-rich texts, game NPCsand tools (functions) at scale, we demonstrate persona-driven data synthesis isversatile, scalable, flexible, and easy to use, potentially driving a paradigmshift in synthetic data creation and applications in practice, which may have aprofound impact on LLM research and development.</description><author>Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi, Dong Yu</author><pubDate>Fri, 28 Jun 2024 18:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20094v1</guid></item><item><title>Scalable Training of Graph Foundation Models for Atomistic Materials Modeling: A Case Study with HydraGNN</title><link>http://arxiv.org/abs/2406.12909v2</link><description>We present our work on developing and training scalable graph foundationmodels (GFM) using HydraGNN, a multi-headed graph convolutional neural networkarchitecture. HydraGNN expands the boundaries of graph neural network (GNN) inboth training scale and data diversity. It abstracts over message passingalgorithms, allowing both reproduction of and comparison across algorithmicinnovations that define convolution in GNNs. This work discusses a series ofoptimizations that have allowed scaling up the GFM training to tens ofthousands of GPUs on datasets that consist of hundreds of millions of graphs.Our GFMs use multi-task learning (MTL) to simultaneously learn graph-level andnode-level properties of atomistic structures, such as the total energy andatomic forces. Using over 150 million atomistic structures for training, weillustrate the performance of our approach along with the lessons learned ontwo United States Department of Energy (US-DOE) supercomputers, namely thePerlmutter petascale system at the National Energy Research ScientificComputing Center and the Frontier exascale system at Oak Ridge NationalLaboratory. The HydraGNN architecture enables the GFM to achieve near-linearstrong scaling performance using more than 2,000 GPUs on Perlmutter and 16,000GPUs on Frontier. Hyperparameter optimization (HPO) was performed on over64,000 GPUs on Frontier to select GFM architectures with high accuracy. Earlystopping was applied on each GFM architecture for energy awareness inperforming such an extreme-scale task. The training of an ensemble ofhighest-ranked GFM architectures continued until convergence to establishuncertainty quantification (UQ) capabilities with ensemble learning. Ourcontribution opens the door for rapidly developing, training, and deployingGFMs using large-scale computational resources to enable AI-acceleratedmaterials discovery and design.</description><author>Massimiliano Lupo Pasini, Jong Youl Choi, Kshitij Mehta, Pei Zhang, David Rogers, Jonghyun Bae, Khaled Z. Ibrahim, Ashwin M. Aji, Karl W. Schulz, Jorda Polo, Prasanna Balaprakash</author><pubDate>Fri, 28 Jun 2024 18:58:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12909v2</guid></item><item><title>LLaVolta: Efficient Multi-modal Models via Stage-wise Visual Context Compression</title><link>http://arxiv.org/abs/2406.20092v1</link><description>While significant advancements have been made in compressed representationsfor text embeddings in large language models (LLMs), the compression of visualtokens in large multi-modal models (LMMs) has remained a largely overlookedarea. In this work, we present the study on the analysis of redundancyconcerning visual tokens and efficient training within these models. Ourinitial experiments show that eliminating up to 70% of visual tokens at thetesting stage by simply average pooling only leads to a minimal 3% reduction invisual question answering accuracy on the GQA benchmark, indicating significantredundancy in visual context. Addressing this, we introduce Visual ContextCompressor, which reduces the number of visual tokens during training toenhance training efficiency without sacrificing performance. To minimizeinformation loss caused by the compression on visual tokens while maintainingtraining efficiency, we develop LLaVolta as a lite training scheme. LLaVoltaincorporates stage-wise visual context compression to progressively compressthe visual tokens from heavily to lightly, and finally no compression at theend of training, yielding no loss of information when testing. Extensiveexperiments demonstrate that our approach enhances the performance of MLLMs inboth image-language and video-language understanding, while also significantlycutting training costs. Code is available athttps://github.com/Beckschen/LLaVolta</description><author>Jieneng Chen, Luoxin Ye, Ju He, Zhao-Yang Wang, Daniel Khashabi, Alan Yuille</author><pubDate>Fri, 28 Jun 2024 18:57:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20092v1</guid></item><item><title>AutoMix: Automatically Mixing Language Models</title><link>http://arxiv.org/abs/2310.12963v4</link><description>Large language models (LLMs) are now available from cloud API providers invarious sizes and configurations. While this diversity offers a broad spectrumof choices, effectively leveraging the options to optimize computational costand performance remains challenging. In this work, we present Automix, anapproach that strategically routes queries to larger LMs, based on theapproximate correctness of outputs from a smaller LM. Central to Automix aretwo key technical contributions. First, it has a few-shot self-verificationmechanism, which estimates the reliability of its own outputs without requiringextensive training. Second, given that self-verification can be noisy, itemploys a POMDP based router that can effectively select an appropriately sizedmodel, based on answer confidence. Experiments across five language models andfive challenging datasets show that Automix consistently surpasses strongbaselines, reducing computational cost by over 50% for comparable performance.</description><author>Pranjal Aggarwal, Aman Madaan, Ankit Anand, Srividya Pranavi Potharaju, Swaroop Mishra, Pei Zhou, Aditya Gupta, Dheeraj Rajagopal, Karthik Kappaganthu, Yiming Yang, Shyam Upadhyay, Manaal Faruqui, Mausam</author><pubDate>Fri, 28 Jun 2024 18:57:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.12963v4</guid></item><item><title>Minimax And Adaptive Transfer Learning for Nonparametric Classification under Distributed Differential Privacy Constraints</title><link>http://arxiv.org/abs/2406.20088v1</link><description>This paper considers minimax and adaptive transfer learning for nonparametricclassification under the posterior drift model with distributed differentialprivacy constraints. Our study is conducted within a heterogeneous framework,encompassing diverse sample sizes, varying privacy parameters, and dataheterogeneity across different servers. We first establish the minimaxmisclassification rate, precisely characterizing the effects of privacyconstraints, source samples, and target samples on classification accuracy. Theresults reveal interesting phase transition phenomena and highlight theintricate trade-offs between preserving privacy and achieving classificationaccuracy. We then develop a data-driven adaptive classifier that achieves theoptimal rate within a logarithmic factor across a large collection of parameterspaces while satisfying the same set of differential privacy constraints.Simulation studies and real-world data applications further elucidate thetheoretical analysis with numerical results.</description><author>Arnab Auddy, T. Tony Cai, Abhinav Chakraborty</author><pubDate>Fri, 28 Jun 2024 18:55:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20088v1</guid></item><item><title>ProgressGym: Alignment with a Millennium of Moral Progress</title><link>http://arxiv.org/abs/2406.20087v1</link><description>Frontier AI systems, including large language models (LLMs), hold increasinginfluence over the epistemology of human users. Such influence can reinforceprevailing societal values, potentially contributing to the lock-in ofmisguided moral beliefs and, consequently, the perpetuation of problematicmoral practices on a broad scale. We introduce progress alignment as atechnical solution to mitigate this imminent risk. Progress alignmentalgorithms learn to emulate the mechanics of human moral progress, therebyaddressing the susceptibility of existing alignment methods to contemporarymoral blindspots. To empower research in progress alignment, we introduceProgressGym, an experimental framework allowing the learning of moral progressmechanics from history, in order to facilitate future progress in real-worldmoral decisions. Leveraging 9 centuries of historical text and 18 historicalLLMs, ProgressGym enables codification of real-world progress alignmentchallenges into concrete benchmarks. Specifically, we introduce three corechallenges: tracking evolving values (PG-Follow), preemptively anticipatingmoral progress (PG-Predict), and regulating the feedback loop between human andAI value shifts (PG-Coevolve). Alignment methods without a temporal dimensionare inapplicable to these tasks. In response, we present lifelong andextrapolative algorithms as baseline methods of progress alignment, and buildan open leaderboard soliciting novel algorithms and challenges. The frameworkand the leaderboard are available athttps://github.com/PKU-Alignment/ProgressGym andhttps://huggingface.co/spaces/PKU-Alignment/ProgressGym-LeaderBoardrespectively.</description><author>Tianyi Qiu, Yang Zhang, Xuchuan Huang, Jasmine Xinze Li, Jiaming Ji, Yaodong Yang</author><pubDate>Fri, 28 Jun 2024 18:55:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20087v1</guid></item><item><title>Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs</title><link>http://arxiv.org/abs/2406.20086v1</link><description>LLMs process text as sequences of tokens that roughly correspond to words,where less common words are represented by multiple tokens. However, individualtokens are often semantically unrelated to the meanings of the words/conceptsthey comprise. For example, Llama-2-7b's tokenizer splits the word"northeastern" into the tokens ['_n', 'ort', 'he', 'astern'], none of whichcorrespond to semantically meaningful units like "north" or "east." Similarly,the overall meanings of named entities like "Neil Young" and multi-wordexpressions like "break a leg" cannot be directly inferred from theirconstituent tokens. Mechanistically, how do LLMs convert such arbitrary groupsof tokens into useful higher-level representations? In this work, we find thatlast token representations of named entities and multi-token words exhibit apronounced "erasure" effect, where information about previous and currenttokens is rapidly forgotten in early layers. Using this observation, we proposea method to "read out" the implicit vocabulary of an autoregressive LLM byexamining differences in token representations across layers, and presentresults of this method for Llama-2-7b and Llama-3-8B. To our knowledge, this isthe first attempt to probe the implicit vocabulary of an LLM.</description><author>Sheridan Feucht, David Atkinson, Byron Wallace, David Bau</author><pubDate>Fri, 28 Jun 2024 18:54:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20086v1</guid></item><item><title>Auto Cherry-Picker: Learning from High-quality Generative Data Driven by Language</title><link>http://arxiv.org/abs/2406.20085v1</link><description>Diffusion-based models have shown great potential in generating high-qualityimages with various layouts, which can benefit downstream perception tasks.However, a fully automatic layout generation driven only by language and asuitable metric for measuring multiple generated instances has not been wellexplored. In this work, we present Auto Cherry-Picker (ACP), a novel frameworkthat generates high-quality multi-modal training examples to augment perceptionand multi-modal training. Starting with a simple list of natural languageconcepts, we prompt large language models (LLMs) to generate a detaileddescription and design reasonable layouts. Next, we use an off-the-shelftext-to-image model to generate multiple images. Then, the generated data arerefined using a comprehensively designed metric to ensure quality. Inparticular, we present a new metric, Composite Layout and Image Score (CLIS),to evaluate the generated images fairly. Our synthetic high-quality examplesboost performance in various scenarios by customizing the initial concept list,especially in addressing challenges associated with long-tailed distributionand imbalanced datasets. Experiment results on downstream tasks demonstratethat Auto Cherry-Picker can significantly improve the performance of existingmodels. In addition, we have thoroughly investigated the correlation betweenCLIS and performance gains in downstream tasks, and we find that a better CLISscore results in better performance. This finding shows the potential forevaluation metrics as the role for various visual perception and MLLM tasks.Code will be available.</description><author>Yicheng Chen, Xiangtai Li, Yining Li, Yanhong Zeng, Jianzong Wu, Xiangyu Zhao, Kai Chen</author><pubDate>Fri, 28 Jun 2024 18:53:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20085v1</guid></item><item><title>PoliFormer: Scaling On-Policy RL with Transformers Results in Masterful Navigators</title><link>http://arxiv.org/abs/2406.20083v1</link><description>We present PoliFormer (Policy Transformer), an RGB-only indoor navigationagent trained end-to-end with reinforcement learning at scale that generalizesto the real-world without adaptation despite being trained purely insimulation. PoliFormer uses a foundational vision transformer encoder with acausal transformer decoder enabling long-term memory and reasoning. It istrained for hundreds of millions of interactions across diverse environments,leveraging parallelized, multi-machine rollouts for efficient training withhigh throughput. PoliFormer is a masterful navigator, producingstate-of-the-art results across two distinct embodiments, the LoCoBot andStretch RE-1 robots, and four navigation benchmarks. It breaks through theplateaus of previous work, achieving an unprecedented 85.5% success rate inobject goal navigation on the CHORES-S benchmark, a 28.5% absolute improvement.PoliFormer can also be trivially extended to a variety of downstreamapplications such as object tracking, multi-object navigation, andopen-vocabulary navigation with no finetuning.</description><author>Kuo-Hao Zeng, Zichen Zhang, Kiana Ehsani, Rose Hendrix, Jordi Salvador, Alvaro Herrasti, Ross Girshick, Aniruddha Kembhavi, Luca Weihs</author><pubDate>Fri, 28 Jun 2024 18:51:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20083v1</guid></item><item><title>Segment Anything without Supervision</title><link>http://arxiv.org/abs/2406.20081v1</link><description>The Segmentation Anything Model (SAM) requires labor-intensive data labeling.We present Unsupervised SAM (UnSAM) for promptable and automatic whole-imagesegmentation that does not require human annotations. UnSAM utilizes adivide-and-conquer strategy to "discover" the hierarchical structure of visualscenes. We first leverage top-down clustering methods to partition an unlabeledimage into instance/semantic level segments. For all pixels within a segment, abottom-up clustering method is employed to iteratively merge them into largergroups, thereby forming a hierarchical structure. These unsupervisedmulti-granular masks are then utilized to supervise model training. Evaluatedacross seven popular datasets, UnSAM achieves competitive results with thesupervised counterpart SAM, and surpasses the previous state-of-the-art inunsupervised segmentation by 11% in terms of AR. Moreover, we show thatsupervised SAM can also benefit from our self-supervised labels. By integratingour unsupervised pseudo masks into SA-1B's ground-truth masks and trainingUnSAM with only 1% of SA-1B, a lightly semi-supervised UnSAM can often segmententities overlooked by supervised SAM, exceeding SAM's AR by over 6.7% and APby 3.9% on SA-1B.</description><author>XuDong Wang, Jingfeng Yang, Trevor Darrell</author><pubDate>Fri, 28 Jun 2024 18:47:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20081v1</guid></item><item><title>ChIRAAG: ChatGPT Informed Rapid and Automated Assertion Generation</title><link>http://arxiv.org/abs/2402.00093v3</link><description>System Verilog Assertion (SVA) formulation -- a critical yet complex task isa prerequisite in the Assertion Based Verification (ABV) process.Traditionally, SVA formulation involves expert-driven interpretation ofspecifications, which is time-consuming and prone to human error. Recently,LLM-informed automatic assertion generation is gaining interest. We designed anovel framework called ChIRAAG, based on OpenAI GPT4, to generate SVA fromnatural language specifications of a design. ChIRAAG constitutes the systematicbreakdown of design specifications into a standardized format, furthergenerating assertions from formatted specifications using LLM. Furthermore, weused few test cases to validate the LLM-generated assertions. Automaticfeedback of log messages from the simulation tool to the LLM ensures that theframework can generate correct SVAs. In our experiments, only 27% ofLLM-generated raw assertions had errors, which was rectified in few iterationsbased on the simulation log. Our results on OpenTitan designs show that LLMscan streamline and assist engineers in the assertion generation process,reshaping verification workflows.</description><author>Bhabesh Mali, Karthik Maddala, Vatsal Gupta, Sweeya Reddy, Chandan Karfa, Ramesh Karri</author><pubDate>Fri, 28 Jun 2024 18:46:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00093v3</guid></item><item><title>AI for Extreme Event Modeling and Understanding: Methodologies and Challenges</title><link>http://arxiv.org/abs/2406.20080v1</link><description>In recent years, artificial intelligence (AI) has deeply impacted variousfields, including Earth system sciences. Here, AI improved weather forecasting,model emulation, parameter estimation, and the prediction of extreme events.However, the latter comes with specific challenges, such as developing accuratepredictors from noisy, heterogeneous and limited annotated data. This paperreviews how AI is being used to analyze extreme events (like floods, droughts,wildfires and heatwaves), highlighting the importance of creating accurate,transparent, and reliable AI models. We discuss the hurdles of dealing withlimited data, integrating information in real-time, deploying models, andmaking them understandable, all crucial for gaining the trust of stakeholdersand meeting regulatory needs. We provide an overview of how AI can helpidentify and explain extreme events more effectively, improving disasterresponse and communication. We emphasize the need for collaboration acrossdifferent fields to create AI solutions that are practical, understandable, andtrustworthy for analyzing and predicting extreme events. Such collaborativeefforts aim to enhance disaster readiness and disaster risk reduction.</description><author>Gustau Camps-Valls, Miguel-Ángel Fernández-Torres, Kai-Hendrik Cohrs, Adrian Höhl, Andrea Castelletti, Aytac Pacal, Claire Robin, Francesco Martinuzzi, Ioannis Papoutsis, Ioannis Prapas, Jorge Pérez-Aracil, Katja Weigel, Maria Gonzalez-Calabuig, Markus Reichstein, Martin Rabel, Matteo Giuliani, Miguel Mahecha, Oana-Iuliana Popescu, Oscar J. Pellicer-Valero, Said Ouala, Sancho Salcedo-Sanz, Sebastian Sippel, Spyros Kondylatos, Tamara Happé, Tristan Williams</author><pubDate>Fri, 28 Jun 2024 18:45:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20080v1</guid></item><item><title>Solving Differential Equations using Physics-Informed Deep Equilibrium Models</title><link>http://arxiv.org/abs/2406.03472v2</link><description>This paper introduces Physics-Informed Deep Equilibrium Models (PIDEQs) forsolving initial value problems (IVPs) of ordinary differential equations(ODEs). Leveraging recent advancements in deep equilibrium models (DEQs) andphysics-informed neural networks (PINNs), PIDEQs combine the implicit outputrepresentation of DEQs with physics-informed training techniques. We validatePIDEQs using the Van der Pol oscillator as a benchmark problem, demonstratingtheir efficiency and effectiveness in solving IVPs. Our analysis includes keyhyperparameter considerations for optimizing PIDEQ performance. By bridgingdeep learning and physics-based modeling, this work advances computationaltechniques for solving IVPs, with implications for scientific computing andengineering applications.</description><author>Bruno Machado Pacheco, Eduardo Camponogara</author><pubDate>Fri, 28 Jun 2024 18:44:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03472v2</guid></item><item><title>Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification</title><link>http://arxiv.org/abs/2406.20079v1</link><description>Automatic factuality verification of large language model (LLM) generationsis becoming more and more widely used to combat hallucinations. A major pointof tension in the literature is the granularity of this fact-checking: largerchunks of text are hard to fact-check, but more atomic facts like propositionsmay lack context to interpret correctly. In this work, we assess the role ofcontext in these atomic facts. We argue that fully atomic facts are not theright representation, and define two criteria for molecular facts:decontextuality, or how well they can stand alone, and minimality, or howlittle extra information is added to achieve decontexuality. We quantify theimpact of decontextualization on minimality, then present a baselinemethodology for generating molecular facts automatically, aiming to add theright amount of information. We compare against various methods ofdecontextualization and find that molecular facts balance minimality with factverification accuracy in ambiguous settings.</description><author>Anisha Gunjal, Greg Durrett</author><pubDate>Fri, 28 Jun 2024 18:43:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20079v1</guid></item><item><title>GM-DF: Generalized Multi-Scenario Deepfake Detection</title><link>http://arxiv.org/abs/2406.20078v1</link><description>Existing face forgery detection usually follows the paradigm of trainingmodels in a single domain, which leads to limited generalization capacity whenunseen scenarios and unknown attacks occur. In this paper, we elaboratelyinvestigate the generalization capacity of deepfake detection models whenjointly trained on multiple face forgery detection datasets. We first find arapid degradation of detection accuracy when models are directly trained oncombined datasets due to the discrepancy across collection scenarios andgeneration methods. To address the above issue, a Generalized Multi-ScenarioDeepfake Detection framework (GM-DF) is proposed to serve multiple real-worldscenarios by a unified model. First, we propose a hybrid expert modelingapproach for domain-specific real/forgery feature extraction. Besides, as forthe commonality representation, we use CLIP to extract the common features forbetter aligning visual and textual features across domains. Meanwhile, weintroduce a masked image reconstruction mechanism to force models to capturerich forged details. Finally, we supervise the models via a domain-awaremeta-learning strategy to further enhance their generalization capacities.Specifically, we design a novel domain alignment loss to strongly align thedistributions of the meta-test domains and meta-train domains. Thus, theupdated models are able to represent both specific and common real/forgeryfeatures across multiple datasets. In consideration of the lack of study ofmulti-dataset training, we establish a new benchmark leveraging multi-sourcedata to fairly evaluate the models' generalization capacity on unseenscenarios. Both qualitative and quantitative experiments on five datasetsconducted on traditional protocols as well as the proposed benchmarkdemonstrate the effectiveness of our approach.</description><author>Yingxin Lai, Zitong Yu, Jing Yang, Bin Li, Xiangui Kang, Linlin Shen</author><pubDate>Fri, 28 Jun 2024 18:42:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20078v1</guid></item><item><title>HouseCrafter: Lifting Floorplans to 3D Scenes with 2D Diffusion Model</title><link>http://arxiv.org/abs/2406.20077v1</link><description>We introduce HouseCrafter, a novel approach that can lift a floorplan into acomplete large 3D indoor scene (e.g., a house). Our key insight is to adapt a2D diffusion model, which is trained on web-scale images, to generateconsistent multi-view color (RGB) and depth (D) images across differentlocations of the scene. Specifically, the RGB-D images are generatedautoregressively in a batch-wise manner along sampled locations based on thefloorplan, where previously generated images are used as condition to thediffusion model to produce images at nearby locations. The global floorplan andattention design in the diffusion model ensures the consistency of thegenerated images, from which a 3D scene can be reconstructed. Through extensiveevaluation on the 3D-Front dataset, we demonstrate that HouseCraft can generatehigh-quality house-scale 3D scenes. Ablation studies also validate theeffectiveness of different design choices. We will release our code and modelweights. Project page: https://neu-vi.github.io/houseCrafter/</description><author>Hieu T. Nguyen, Yiwen Chen, Vikram Voleti, Varun Jampani, Huaizu Jiang</author><pubDate>Fri, 28 Jun 2024 18:39:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20077v1</guid></item><item><title>EVF-SAM: Early Vision-Language Fusion for Text-Prompted Segment Anything Model</title><link>http://arxiv.org/abs/2406.20076v1</link><description>Segment Anything Model (SAM) has attracted widespread attention for itssuperior interactive segmentation capabilities with visual prompts whilelacking further exploration of text prompts. In this paper, we empiricallyinvestigate what text prompt encoders (e.g., CLIP or LLM) are good for adaptingSAM for referring expression segmentation and introduce the EarlyVision-language Fusion-based SAM (EVF-SAM). EVF-SAM is a simple yet effectivereferring segmentation method which exploits multimodal prompts (i.e., imageand text) and comprises a pre-trained vision-language model to generatereferring prompts and a SAM model for segmentation. Surprisingly, we observethat: (1) multimodal prompts and (2) vision-language models with early fusion(e.g., BEIT-3) are beneficial for prompting SAM for accurate referringsegmentation. Our experiments show that the proposed EVF-SAM based on BEIT-3can obtain state-of-the-art performance on RefCOCO/+/g for referring expressionsegmentation and demonstrate the superiority of prompting SAM with earlyvision-language fusion. In addition, the proposed EVF-SAM with 1.32B parametersachieves remarkably higher performance while reducing nearly 82% of parameterscompared to previous SAM methods based on large multimodal models.</description><author>Yuxuan Zhang, Tianheng Cheng, Rui Hu, ei Liu, Heng Liu, Longjin Ran, Xiaoxin Chen, Wenyu Liu, Xinggang Wang</author><pubDate>Fri, 28 Jun 2024 18:38:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20076v1</guid></item><item><title>ASSR-NeRF: Arbitrary-Scale Super-Resolution on Voxel Grid for High-Quality Radiance Fields Reconstruction</title><link>http://arxiv.org/abs/2406.20066v1</link><description>NeRF-based methods reconstruct 3D scenes by building a radiance field withimplicit or explicit representations. While NeRF-based methods can performnovel view synthesis (NVS) at arbitrary scale, the performance inhigh-resolution novel view synthesis (HRNVS) with low-resolution (LR)optimization often results in oversmoothing. On the other hand, single-imagesuper-resolution (SR) aims to enhance LR images to HR counterparts but lacksmulti-view consistency. To address these challenges, we propose Arbitrary-ScaleSuper-Resolution NeRF (ASSR-NeRF), a novel framework for super-resolution novelview synthesis (SRNVS). We propose an attention-based VoxelGridSR model todirectly perform 3D super-resolution (SR) on the optimized volume. Our model istrained on diverse scenes to ensure generalizability. For unseen scenes trainedwith LR views, we then can directly apply our VoxelGridSR to further refine thevolume and achieve multi-view consistent SR. We demonstrate quantitative andqualitatively that the proposed method achieves significant performance inSRNVS.</description><author>Ding-Jiun Huang, Zi-Ting Chou, Yu-Chiang Frank Wang, Cheng Sun</author><pubDate>Fri, 28 Jun 2024 18:22:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20066v1</guid></item><item><title>Cost-aware Bayesian optimization via the Pandora's Box Gittins index</title><link>http://arxiv.org/abs/2406.20062v1</link><description>Bayesian optimization is a technique for efficiently optimizing unknownfunctions in a black-box manner. To handle practical settings where gatheringdata requires use of finite resources, it is desirable to explicitlyincorporate function evaluation costs into Bayesian optimization policies. Tounderstand how to do so, we develop a previously-unexplored connection betweencost-aware Bayesian optimization and the Pandora's Box problem, a decisionproblem from economics. The Pandora's Box problem admits a Bayesian-optimalsolution based on an expression called the Gittins index, which can bereinterpreted as an acquisition function. We study the use of this acquisitionfunction for cost-aware Bayesian optimization, and demonstrate empirically thatit performs well, particularly in medium-high dimensions. We further show thatthis performance carries over to classical Bayesian optimization withoutexplicit evaluation costs. Our work constitutes a first step towardsintegrating techniques from Gittins index theory into Bayesian optimization.</description><author>Qian Xie, Raul Astudillo, Peter Frazier, Ziv Scully, Alexander Terenin</author><pubDate>Fri, 28 Jun 2024 18:20:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20062v1</guid></item><item><title>Applying RLAIF for Code Generation with API-usage in Lightweight LLMs</title><link>http://arxiv.org/abs/2406.20060v1</link><description>Reinforcement Learning from AI Feedback (RLAIF) has demonstrated significantpotential across various domains, including mitigating harm in LLM outputs,enhancing text summarization, and mathematical reasoning. This paper introducesan RLAIF framework for improving the code generation abilities of lightweight(&lt;1B parameters) LLMs. We specifically focus on code generation tasks thatrequire writing appropriate API calls, which is challenging due to thewell-known issue of hallucination in LLMs. Our framework extracts AI feedbackfrom a larger LLM (e.g., GPT-3.5) through a specialized prompting strategy anduses this data to train a reward model towards better alignment from smallerLLMs. We run our experiments on the Gorilla dataset and meticulously assess thequality of the model-generated code across various metrics, including AST,ROUGE, and Code-BLEU, and develop a pipeline to compute its executability rateaccurately. Our approach significantly enhances the fine-tuned LLM baseline'sperformance, achieving a 4.5% improvement in executability rate. Notably, asmaller LLM model (780M parameters) trained with RLAIF surpasses a much largerfine-tuned baseline with 7B parameters, achieving a 1.0% higher codeexecutability rate.</description><author>Sujan Dutta, Sayantan Mahinder, Raviteja Anantha, Bortik Bandyopadhyay</author><pubDate>Fri, 28 Jun 2024 18:16:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20060v1</guid></item><item><title>Exploiting Diffusion Prior for Real-World Image Super-Resolution</title><link>http://arxiv.org/abs/2305.07015v4</link><description>We present a novel approach to leverage prior knowledge encapsulated inpre-trained text-to-image diffusion models for blind super-resolution (SR).Specifically, by employing our time-aware encoder, we can achieve promisingrestoration results without altering the pre-trained synthesis model, therebypreserving the generative prior and minimizing training cost. To remedy theloss of fidelity caused by the inherent stochasticity of diffusion models, weemploy a controllable feature wrapping module that allows users to balancequality and fidelity by simply adjusting a scalar value during the inferenceprocess. Moreover, we develop a progressive aggregation sampling strategy toovercome the fixed-size constraints of pre-trained diffusion models, enablingadaptation to resolutions of any size. A comprehensive evaluation of our methodusing both synthetic and real-world benchmarks demonstrates its superiorityover current state-of-the-art approaches. Code and models are available athttps://github.com/IceClear/StableSR.</description><author>Jianyi Wang, Zongsheng Yue, Shangchen Zhou, Kelvin C. K. Chan, Chen Change Loy</author><pubDate>Fri, 28 Jun 2024 18:14:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.07015v4</guid></item><item><title>The Impact of Feature Representation on the Accuracy of Photonic Neural Networks</title><link>http://arxiv.org/abs/2406.18757v2</link><description>Photonic Neural Networks (PNNs) are gaining significant interest in theresearch community due to their potential for high parallelization, lowlatency, and energy efficiency. PNNs compute using light, which leads toseveral differences in implementation when compared to electronics, such as theneed to represent input features in the photonic domain before feeding theminto the network. In this encoding process, it is common to combine multiplefeatures into a single input to reduce the number of inputs and associateddevices, leading to smaller and more energy-efficient PNNs. Although thisalters the network's handling of input data, its impact on PNNs remainsunderstudied. This paper addresses this open question, investigating the effectof commonly used encoding strategies that combine features on the performanceand learning capabilities of PNNs. Here, using the concept of featureimportance, we develop a mathematical methodology for analyzing featurecombination. Through this methodology, we demonstrate that encoding multiplefeatures together in a single input determines their relative importance, thuslimiting the network's ability to learn from the data. Given some priorknowledge of the data, however, this can also be leveraged for higher accuracy.By selecting an optimal encoding method, we achieve up to a 12.3% improvementin accuracy of PNNs trained on the Iris dataset compared to other encodingtechniques, surpassing the performance of networks where features are notcombined. These findings highlight the importance of carefully choosing theencoding to the accuracy and decision-making strategies of PNNs, particularlyin size or power constrained applications.</description><author>Mauricio Gomes de Queiroz, Paul Jimenez, Raphael Cardoso, Mateus Vidaletti Costa, Mohab Abdalla, Ian O'Connor, Alberto Bosio, Fabio Pavanello</author><pubDate>Fri, 28 Jun 2024 18:12:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.18757v2</guid></item><item><title>SpotlessSplats: Ignoring Distractors in 3D Gaussian Splatting</title><link>http://arxiv.org/abs/2406.20055v1</link><description>3D Gaussian Splatting (3DGS) is a promising technique for 3D reconstruction,offering efficient training and rendering speeds, making it suitable forreal-time applications.However, current methods require highly controlledenvironments (no moving people or wind-blown elements, and consistent lighting)to meet the inter-view consistency assumption of 3DGS. This makesreconstruction of real-world captures problematic. We present SpotlessSplats,an approach that leverages pre-trained and general-purpose features coupledwith robust optimization to effectively ignore transient distractors. Ourmethod achieves state-of-the-art reconstruction quality both visually andquantitatively, on casual captures.</description><author>Sara Sabour, Lily Goli, George Kopanas, Mark Matthews, Dmitry Lagun, Leonidas Guibas, Alec Jacobson, David J. Fleet, Andrea Tagliasacchi</author><pubDate>Fri, 28 Jun 2024 18:07:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20055v1</guid></item><item><title>To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models</title><link>http://arxiv.org/abs/2406.20054v1</link><description>Polysemy and synonymy are two crucial interrelated facets of lexicalambiguity. While both phenomena have been studied extensively in NLP, leadingto dedicated systems, they are often been considered independently. While manytasks dealing with polysemy (e.g. Word Sense Disambiguiation or Induction)highlight the role of a word's senses, the study of synonymy is rooted in thestudy of concepts, i.e. meaning shared across the lexicon. In this paper, weintroduce Concept Induction, the unsupervised task of learning a softclustering among words that defines a set of concepts directly from data. Thistask generalizes that of Word Sense Induction. We propose a bi-level approachto Concept Induction that leverages both a local lemma-centric view and aglobal cross-lexicon perspective to induce concepts. We evaluate the obtainedclustering on SemCor's annotated data and obtain good performances (BCubed F1above 0.60). We find that the local and the global levels are mutuallybeneficial to induce concepts and also senses in our setting. Finally, wecreate static embeddings representing our induced concepts and use them on theWord-in-Context task, obtaining competitive performances with theState-of-the-Art.</description><author>Bastien Liétard, Pascal Denis, Mikaella Keller</author><pubDate>Fri, 28 Jun 2024 18:07:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20054v1</guid></item><item><title>Covert Malicious Finetuning: Challenges in Safeguarding LLM Adaptation</title><link>http://arxiv.org/abs/2406.20053v1</link><description>Black-box finetuning is an emerging interface for adapting state-of-the-artlanguage models to user needs. However, such access may also let maliciousactors undermine model safety. To demonstrate the challenge of defendingfinetuning interfaces, we introduce covert malicious finetuning, a method tocompromise model safety via finetuning while evading detection. Our methodconstructs a malicious dataset where every individual datapoint appearsinnocuous, but finetuning on the dataset teaches the model to respond toencoded harmful requests with encoded harmful responses. Applied to GPT-4, ourmethod produces a finetuned model that acts on harmful instructions 99% of thetime and avoids detection by defense mechanisms such as dataset inspection,safety evaluations, and input/output classifiers. Our findings question whetherblack-box finetuning access can be secured against sophisticated adversaries.</description><author>Danny Halawi, Alexander Wei, Eric Wallace, Tony T. Wang, Nika Haghtalab, Jacob Steinhardt</author><pubDate>Fri, 28 Jun 2024 18:05:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20053v1</guid></item><item><title>Understanding and Mitigating Language Confusion in LLMs</title><link>http://arxiv.org/abs/2406.20052v1</link><description>We investigate a surprising limitation of LLMs: their inability toconsistently generate text in a user's desired language. We create the LanguageConfusion Benchmark (LCB) to evaluate such failures, covering 15 typologicallydiverse languages with existing and newly-created English and multilingualprompts. We evaluate a range of LLMs on monolingual and cross-lingualgeneration reflecting practical use cases, finding that Llama Instruct andMistral models exhibit high degrees of language confusion and even thestrongest models fail to consistently respond in the correct language. Weobserve that base and English-centric instruct models are more prone tolanguage confusion, which is aggravated by complex prompts and high samplingtemperatures. We find that language confusion can be partially mitigated viafew-shot prompting, multilingual SFT and preference tuning. We release ourlanguage confusion benchmark, which serves as a first layer of efficient,scalable multilingual evaluation athttps://github.com/for-ai/language-confusion.</description><author>Kelly Marchisio, Wei-Yin Ko, Alexandre Bérard, Théo Dehaze, Sebastian Ruder</author><pubDate>Fri, 28 Jun 2024 18:03:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20052v1</guid></item><item><title>PruningBench: A Comprehensive Benchmark of Structural Pruning</title><link>http://arxiv.org/abs/2406.12315v2</link><description>Structural pruning has emerged as a promising approach for producing moreefficient models. Nevertheless, the community suffers from a lack ofstandardized benchmarks and metrics, leaving the progress in this area notfully comprehended. To fill this gap, we present the first comprehensivebenchmark, termed \textit{PruningBench}, for structural pruning. PruningBenchshowcases the following three characteristics: 1) PruningBench employs aunified and consistent framework for evaluating the effectiveness of diversestructural pruning techniques; 2) PruningBench systematically evaluates 16existing pruning methods, encompassing a wide array of models (e.g., CNNs andViTs) and tasks (e.g., classification and detection); 3) PruningBench provideseasily implementable interfaces to facilitate the implementation of futurepruning methods, and enables the subsequent researchers to incorporate theirwork into our leaderboards. We provide an online pruning platformhttp://pruning.vipazoo.cn for customizing pruning tasks and reproducing allresults in this paper. Codes will be made publicly onhttps://github.com/HollyLee2000/PruningBench.</description><author>Haoling Li, Changhao Li, Mengqi Xue, Gongfan Fang, Sheng Zhou, Zunlei Feng, Huiqiong Wang, Yong Wang, Lechao Cheng, Mingli Song, Jie Song</author><pubDate>Fri, 28 Jun 2024 18:03:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.12315v2</guid></item><item><title>Evaluation of autonomous systems under data distribution shifts</title><link>http://arxiv.org/abs/2406.20046v1</link><description>We posit that data can only be safe to use up to a certain threshold of thedata distribution shift, after which control must be relinquished by theautonomous system and operation halted or handed to a human operator. With theuse of a computer vision toy example we demonstrate that network predictiveaccuracy is impacted by data distribution shifts and propose distance metricsbetween training and testing data to define safe operation limits within saidshifts. We conclude that beyond an empirically obtained threshold of the datadistribution shift, it is unreasonable to expect network predictive accuracynot to degrade</description><author>Daniel Sikar, Artur Garcez</author><pubDate>Fri, 28 Jun 2024 17:58:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20046v1</guid></item><item><title>Electrostatics-based particle sampling and approximate inference</title><link>http://arxiv.org/abs/2406.20044v1</link><description>A new particle-based sampling and approximate inference method, based onelectrostatics and Newton mechanics principles, is introduced with theoreticalground, algorithm design and experimental validation. This method simulates aninteracting particle system (IPS) where particles, i.e. the freely-movingnegative charges and spatially-fixed positive charges with magnitudesproportional to the target distribution, interact with each other viaattraction and repulsion induced by the resulting electric fields described byPoisson's equation. The IPS evolves towards a steady-state where thedistribution of negative charges conforms to the target distribution. Thisphysics-inspired method offers deterministic, gradient-free sampling andinference, achieving comparable performance as other particle-based and MCMCmethods in benchmark tasks of inferring complex densities, Bayesian logisticregression and dynamical system identification. A discrete-time, discrete-spacealgorithmic design, readily extendable to continuous time and space, isprovided for usage in more general inference problems occurring inprobabilistic machine learning scenarios such as Bayesian inference, generativemodelling, and beyond.</description><author>Yongchao Huang</author><pubDate>Fri, 28 Jun 2024 17:53:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20044v1</guid></item><item><title>HAITCH: A Framework for Distortion and Motion Correction in Fetal Multi-Shell Diffusion-Weighted MRI</title><link>http://arxiv.org/abs/2406.20042v1</link><description>Diffusion magnetic resonance imaging (dMRI) is pivotal for probing themicrostructure of the rapidly-developing fetal brain. However, fetal motionduring scans and its interaction with magnetic field inhomogeneities result inartifacts and data scattering across spatial and angular domains. The effectsof those artifacts are more pronounced in high-angular resolution fetal dMRI,where signal-to-noise ratio is very low. Those effects lead to biased estimatesand compromise the consistency and reliability of dMRI analysis. This workpresents HAITCH, the first and the only publicly available tool to correct andreconstruct multi-shell high-angular resolution fetal dMRI data. HAITCH offersseveral technical advances that include a blip-reversed dual-echo acquisitionfor dynamic distortion correction, advanced motion correction for model-freeand robust reconstruction, optimized multi-shell design for enhancedinformation capture and increased tolerance to motion, and outlier detectionfor improved reconstruction fidelity. The framework is open-source, flexible,and can be used to process any type of fetal dMRI data including single-echo orsingle-shell acquisitions, but is most effective when used with multi-shellmulti-echo fetal dMRI data that cannot be processed with any of the existingtools. Validation experiments on real fetal dMRI scans demonstrate significantimprovements and accurate correction across diverse fetal ages and motionlevels. HAITCH successfully removes artifacts and reconstructs high-fidelityfetal dMRI data suitable for advanced diffusion modeling, including fiberorientation distribution function estimation. These advancements pave the wayfor more reliable analysis of the fetal brain microstructure and tractographyunder challenging imaging conditions.</description><author>Haykel Snoussi, Davood Karimi, Onur Afacan, Mustafa Utkur, Ali Gholipour</author><pubDate>Fri, 28 Jun 2024 17:40:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20042v1</guid></item><item><title>EnSolver: Uncertainty-Aware Ensemble CAPTCHA Solvers with Theoretical Guarantees</title><link>http://arxiv.org/abs/2307.15180v2</link><description>The popularity of text-based CAPTCHA as a security mechanism to protectwebsites from automated bots has prompted researches in CAPTCHA solvers, withthe aim of understanding its failure cases and subsequently making CAPTCHAsmore secure. Recently proposed solvers, built on advances in deep learning, areable to crack even the very challenging CAPTCHAs with high accuracy. However,these solvers often perform poorly on out-of-distribution samples that containvisual features different from those in the training set. Furthermore, theylack the ability to detect and avoid such samples, making them susceptible tobeing locked out by defense systems after a certain number of failed attempts.In this paper, we propose EnSolver, a family of CAPTCHA solvers that use deepensemble uncertainty to detect and skip out-of-distribution CAPTCHAs, making itharder to be detected. We prove novel theoretical bounds on the effectivenessof our solvers and demonstrate their use with state-of-the-art CAPTCHA solvers.Our experiments show that the proposed approaches perform well when crackingCAPTCHA datasets that contain both in-distribution and out-of-distributionsamples.</description><author>Duc C. Hoang, Behzad Ousat, Amin Kharraz, Cuong V. Nguyen</author><pubDate>Fri, 28 Jun 2024 17:40:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.15180v2</guid></item><item><title>BMW Agents -- A Framework For Task Automation Through Multi-agent Collaboration</title><link>http://arxiv.org/abs/2406.20041v1</link><description>Autonomous agents driven by Large Language Models (LLMs) offer enormouspotential for automation. Early proof of this technology can be found invarious demonstrations of agents solving complex tasks, interacting withexternal systems to augment their knowledge, and triggering actions. Inparticular, workflows involving multiple agents solving complex tasks in acollaborative fashion exemplify their capacity to operate in less strict andless well-defined environments. Thus, a multi-agent approach has greatpotential for serving as a backbone in many industrial applications, rangingfrom complex knowledge retrieval systems to next generation robotic processautomation. Given the reasoning abilities within the current generation ofLLMs, complex processes require a multi-step approach that includes a plan ofwell-defined and modular tasks. Depending on the level of complexity, thesetasks can be executed either by a single agent or a group of agents. In thiswork, we focus on designing a flexible agent engineering framework with carefulattention to planning and execution, capable of handling complex use caseapplications across various domains. The proposed framework providesreliability in industrial applications and presents techniques to ensure ascalable, flexible, and collaborative workflow for multiple autonomous agentsworking together towards solving tasks.</description><author>Noel Crawford, Edward B. Duffy, Iman Evazzade, Torsten Foehr, Gregory Robbins, Debbrata Kumar Saha, Jiya Varma, Marcin Ziolkowski</author><pubDate>Fri, 28 Jun 2024 17:39:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20041v1</guid></item><item><title>Importance Weighted Expectation-Maximization for Protein Sequence Design</title><link>http://arxiv.org/abs/2305.00386v2</link><description>Designing protein sequences with desired biological function is crucial inbiology and chemistry. Recent machine learning methods use a surrogatesequence-function model to replace the expensive wet-lab validation. How can weefficiently generate diverse and novel protein sequences with high fitness? Inthis paper, we propose IsEM-Pro, an approach to generate protein sequencestowards a given fitness criterion. At its core, IsEM-Pro is a latent generativemodel, augmented by combinatorial structure features from a separately learnedMarkov random fields (MRFs). We develop an Monte Carlo Expectation-Maximizationmethod (MCEM) to learn the model. During inference, sampling from its latentspace enhances diversity while its MRFs features guide the exploration in highfitness regions. Experiments on eight protein sequence design tasks show thatour IsEM-Pro outperforms the previous best methods by at least 55% on averagefitness score and generates more diverse and novel protein sequences.</description><author>Zhenqiao Song, Lei Li</author><pubDate>Fri, 28 Jun 2024 17:36:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.00386v2</guid></item><item><title>MBIAS: Mitigating Bias in Large Language Models While Retaining Context</title><link>http://arxiv.org/abs/2405.11290v3</link><description>The deployment of Large Language Models (LLMs) in diverse applicationsnecessitates an assurance of safety without compromising the contextualintegrity of the generated content. Traditional approaches, includingsafety-specific fine-tuning or adversarial testing, often yield safe outputs atthe expense of contextual meaning. This can result in a diminished capacity tohandle nuanced aspects of bias and toxicity, such as underrepresentation ornegative portrayals across various demographics. To address these challenges,we introduce MBIAS, an LLM framework carefully instruction fine-tuned on acustom dataset designed specifically for safety interventions. MBIAS isdesigned to significantly reduce biases and toxic elements in LLM outputs whilepreserving the main information. This work also details our further use ofLLMs: as annotator under human supervision and as evaluator of generatedcontent. Empirical analysis reveals that MBIAS achieves a reduction in bias andtoxicity by over 30\% in standard evaluations, and by more than 90\% in diversedemographic tests, highlighting the robustness of our approach. We make thedataset and the fine-tuned model available to the research community forfurther investigation and ensure reproducibility. The code for this project canbe accessed here https://github.com/shainarazavi/MBIAS/tree/main. Warning: This paper contains examples that may be offensive or upsetting.</description><author>Shaina Raza, Ananya Raval, Veronica Chatrath</author><pubDate>Fri, 28 Jun 2024 17:35:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.11290v3</guid></item><item><title>BioMNER: A Dataset for Biomedical Method Entity Recognition</title><link>http://arxiv.org/abs/2406.20038v1</link><description>Named entity recognition (NER) stands as a fundamental and pivotal taskwithin the realm of Natural Language Processing. Particularly within the domainof Biomedical Method NER, this task presents notable challenges, stemming fromthe continual influx of domain-specific terminologies in scholarly literature.Current research in Biomedical Method (BioMethod) NER suffers from a scarcityof resources, primarily attributed to the intricate nature of methodologicalconcepts, which necessitate a profound understanding for precise delineation.In this study, we propose a novel dataset for biomedical method entityrecognition, employing an automated BioMethod entity recognition andinformation retrieval system to assist human annotation. Furthermore, wecomprehensively explore a range of conventional and contemporary open-domainNER methodologies, including the utilization of cutting-edge large-scalelanguage models (LLMs) customised to our dataset. Our empirical findings revealthat the large parameter counts of language models surprisingly inhibit theeffective assimilation of entity extraction patterns pertaining to biomedicalmethods. Remarkably, the approach, leveraging the modestly sized ALBERT model(only 11MB), in conjunction with conditional random fields (CRF), achievesstate-of-the-art (SOTA) performance.</description><author>Chen Tang, Bohao Yang, Kun Zhao, Bo Lv, Chenghao Xiao, Frank Guerin, Chenghua Lin</author><pubDate>Fri, 28 Jun 2024 17:34:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20038v1</guid></item><item><title>Explore as a Storm, Exploit as a Raindrop: On the Benefit of Fine-Tuning Kernel Schedulers with Coordinate Descent</title><link>http://arxiv.org/abs/2406.20037v1</link><description>Machine-learning models consist of kernels, which are algorithms applyingoperations on tensors -- data indexed by a linear combination of naturalnumbers. Examples of kernels include convolutions, transpositions, andvectorial products. There are many ways to implement a kernel. Theseimplementations form the kernel's optimization space. Kernel scheduling is theproblem of finding the best implementation, given an objective function --typically execution speed. Kernel optimizers such as Ansor, Halide, and AutoTVMsolve this problem via search heuristics, which combine two phases: explorationand exploitation. The first step evaluates many different kernel optimizationspaces. The latter tries to improve the best implementations by investigating akernel within the same space. For example, Ansor combines kernel generationthrough sketches for exploration and leverages an evolutionary algorithm toexploit the best sketches. In this work, we demonstrate the potential to reduceAnsor's search time while enhancing kernel quality by incorporating DropletSearch, an AutoTVM algorithm, into Ansor's exploration phase. The approachinvolves limiting the number of samples explored by Ansor, selecting the best,and exploiting it with a coordinate descent algorithm. By applying thisapproach to the first 300 kernels that Ansor generates, we usually obtainbetter kernels in less time than if we let Ansor analyze 10,000 kernels. Thisresult has been replicated in 20 well-known deep-learning models (AlexNet,ResNet, VGG, DenseNet, etc.) running on four architectures: an AMD Ryzen 7(x86), an NVIDIA A100 tensor core, an NVIDIA RTX 3080 GPU, and an ARM A64FX. Apatch with this combined approach was approved in Ansor in February 2024. Asevidence of the generality of this search methodology, a similar patch,achieving equally good results, was submitted to TVM's MetaSchedule in June2024.</description><author>Michael Canesche, Gaurav Verma, Fernando Magno Quintao Pereira</author><pubDate>Fri, 28 Jun 2024 17:34:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20037v1</guid></item><item><title>A Simple Mixture Policy Parameterization for Improving Sample Efficiency of CVaR Optimization</title><link>http://arxiv.org/abs/2403.11062v3</link><description>Reinforcement learning algorithms utilizing policy gradients (PG) to optimizeConditional Value at Risk (CVaR) face significant challenges with sampleinefficiency, hindering their practical applications. This inefficiency stemsfrom two main facts: a focus on tail-end performance that overlooks manysampled trajectories, and the potential of gradient vanishing when the lowertail of the return distribution is overly flat. To address these challenges, wepropose a simple mixture policy parameterization. This method integrates arisk-neutral policy with an adjustable policy to form a risk-averse policy. Byemploying this strategy, all collected trajectories can be utilized for policyupdating, and the issue of vanishing gradients is counteracted by stimulatinghigher returns through the risk-neutral component, thus lifting the tail andpreventing flatness. Our empirical study reveals that this mixtureparameterization is uniquely effective across a variety of benchmark domains.Specifically, it excels in identifying risk-averse CVaR policies in some Mujocoenvironments where the traditional CVaR-PG fails to learn a reasonable policy.</description><author>Yudong Luo, Yangchen Pan, Han Wang, Philip Torr, Pascal Poupart</author><pubDate>Fri, 28 Jun 2024 17:31:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.11062v3</guid></item><item><title>MKRAG: Medical Knowledge Retrieval Augmented Generation for Medical Question Answering</title><link>http://arxiv.org/abs/2309.16035v2</link><description>Large Language Models (LLMs), although powerful in general domains, oftenperform poorly on domain-specific tasks like medical question answering (QA).Moreover, they tend to function as "black-boxes," making it challenging tomodify their behavior. To address the problem, our study delves into retrievalaugmented generation (RAG), aiming to improve LLM responses without the needfor fine-tuning or retraining. Specifically, we propose a comprehensiveretrieval strategy to extract medical facts from an external knowledge base,and then inject them into the query prompt for LLMs. Focusing on medical QAusing the MedQA-SMILE dataset, we evaluate the impact of different retrievalmodels and the number of facts provided to the LLM. Notably, ourretrieval-augmented Vicuna-7B model exhibited an accuracy improvement from44.46% to 48.54%. This work underscores the potential of RAG to enhance LLMperformance, offering a practical approach to mitigate the challenges ofblack-box LLMs.</description><author>Yucheng Shi, Shaochen Xu, Tianze Yang, Zhengliang Liu, Tianming Liu, Xiang Li, Ninghao Liu</author><pubDate>Fri, 28 Jun 2024 17:21:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16035v2</guid></item><item><title>Pairwise Difference Learning for Classification</title><link>http://arxiv.org/abs/2406.20031v1</link><description>Pairwise difference learning (PDL) has recently been introduced as a newmeta-learning technique for regression. Instead of learning a mapping frominstances to outcomes in the standard way, the key idea is to learn a functionthat takes two instances as input and predicts the difference between therespective outcomes. Given a function of this kind, predictions for a queryinstance are derived from every training example and then averaged. This paperextends PDL toward the task of classification and proposes a meta-learningtechnique for inducing a PDL classifier by solving a suitably defined (binary)classification problem on a paired version of the original training data. Weanalyze the performance of the PDL classifier in a large-scale empirical studyand find that it outperforms state-of-the-art methods in terms of predictionperformance. Last but not least, we provide an easy-to-use and publiclyavailable implementation of PDL in a Python package.</description><author>Mohamed Karim Belaid, Maximilian Rabus, Eyke Hüllermeier</author><pubDate>Fri, 28 Jun 2024 17:20:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20031v1</guid></item><item><title>LEMoE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models</title><link>http://arxiv.org/abs/2406.20030v1</link><description>Large language models (LLMs) require continual knowledge updates to stayabreast of the ever-changing world facts, prompting the formulation of lifelongmodel editing task. While recent years have witnessed the development ofvarious techniques for single and batch editing, these methods either fail toapply or perform sub-optimally when faced with lifelong editing. In this paper,we introduce LEMoE, an advanced Mixture of Experts (MoE) adaptor for lifelongmodel editing. We first analyze the factors influencing the effectiveness ofconventional MoE adaptor in lifelong editing, including catastrophicforgetting, inconsistent routing and order sensitivity. Based on theseinsights, we propose a tailored module insertion method to achieve lifelongediting, incorporating a novel KV anchor routing to enhance routing consistencybetween training and inference stage, along with a concise yet effectiveclustering-based editing order planning. Experimental results demonstrate theeffectiveness of our method in lifelong editing, surpassing previous modelediting techniques while maintaining outstanding performance in batch editingtask. Our code will be available.</description><author>Renzhi Wang, Piji Li</author><pubDate>Fri, 28 Jun 2024 17:17:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20030v1</guid></item><item><title>eMoE-Tracker: Environmental MoE-based Transformer for Robust Event-guided Object Tracking</title><link>http://arxiv.org/abs/2406.20024v1</link><description>The unique complementarity of frame-based and event cameras for high framerate object tracking has recently inspired some research attempts to developmulti-modal fusion approaches. However, these methods directly fuse bothmodalities and thus ignore the environmental attributes, e.g., motion blur,illumination variance, occlusion, scale variation, etc. Meanwhile, nointeraction between search and template features makes distinguishing targetobjects and backgrounds difficult. As a result, performance degradation isinduced especially in challenging conditions. This paper proposes a novel andeffective Transformer-based event-guided tracking framework, calledeMoE-Tracker, which achieves new SOTA performance under various conditions. Ourkey idea is to disentangle the environment into several learnable attributes todynamically learn the attribute-specific features for better interaction anddiscriminability between the target information and background. To achieve thegoal, we first propose an environmental Mix-of-Experts (eMoE) module that isbuilt upon the environmental Attributes Disentanglement to learnattribute-specific features and environmental Attributes Gating to assemble theattribute-specific features by the learnable attribute scores dynamically. TheeMoE module is a subtle router that fine-tunes the transformer backbone moreefficiently. We then introduce a contrastive relation modeling (CRM) module toimprove interaction and discriminability between the target information andbackground. Extensive experiments on diverse event-based benchmark datasetsshowcase the superior performance of our eMoE-Tracker compared to the priorarts.</description><author>Yucheng Chen, Lin Wang</author><pubDate>Fri, 28 Jun 2024 17:13:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20024v1</guid></item><item><title>LLMs and Memorization: On Quality and Specificity of Copyright Compliance</title><link>http://arxiv.org/abs/2405.18492v2</link><description>Memorization in large language models (LLMs) is a growing concern. LLMs havebeen shown to easily reproduce parts of their training data, includingcopyrighted work. This is an important problem to solve, as it may violateexisting copyright laws as well as the European AI Act. In this work, wepropose a systematic analysis to quantify the extent of potential copyrightinfringements in LLMs using European law as an example. Unlike previous work,we evaluate instruction-finetuned models in a realistic end-user scenario. Ouranalysis builds on a proposed threshold of 160 characters, which we borrow fromthe German Copyright Service Provider Act and a fuzzy text matching algorithmto identify potentially copyright-infringing textual reproductions. Thespecificity of countermeasures against copyright infringement is analyzed bycomparing model behavior on copyrighted and public domain data. We investigatewhat behaviors models show instead of producing protected text (such as refusalor hallucination) and provide a first legal assessment of these behaviors. Wefind that there are huge differences in copyright compliance, specificity, andappropriate refusal among popular LLMs. Alpaca, GPT 4, GPT 3.5, and Luminousperform best in our comparison, with OpenGPT-X, Alpaca, and Luminous producinga particularly low absolute number of potential copyright violations. Code willbe published soon.</description><author>Felix B Mueller, Rebekka Görge, Anna K Bernzen, Janna C Pirk, Maximilian Poretschkin</author><pubDate>Fri, 28 Jun 2024 17:12:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.18492v2</guid></item><item><title>ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models</title><link>http://arxiv.org/abs/2406.20015v1</link><description>Tool-augmented large language models (LLMs) are rapidly being integrated intoreal-world applications. Due to the lack of benchmarks, the community stillneeds to fully understand the hallucination issues within these models. Toaddress this challenge, we introduce a comprehensive diagnostic benchmark,ToolBH. Specifically, we assess the LLM's hallucinations through twoperspectives: depth and breadth. In terms of depth, we propose a multi-leveldiagnostic process, including (1) solvability detection, (2) solution planning,and (3) missing-tool analysis. For breadth, we consider three scenarios basedon the characteristics of the toolset: missing necessary tools, potentialtools, and limited functionality tools. Furthermore, we developed seven tasksand collected 700 evaluation samples through multiple rounds of manualannotation. The results show the significant challenges presented by the ToolBHbenchmark. The current advanced models Gemini-1.5-Pro and GPT-4o only achieve atotal score of 45.3 and 37.0, respectively, on a scale of 100. In thisbenchmark, larger model parameters do not guarantee better performance; thetraining data and response strategies also play a crucial role in tool-enhancedLLM scenarios. Our diagnostic analysis indicates that the primary reason formodel errors lies in assessing task solvability. Additionally, open-weightmodels suffer from performance drops with verbose replies, whereas proprietarymodels excel with longer reasoning.</description><author>Yuxiang Zhang, Jing Chen, Junjie Wang, Yaxin Liu, Cheng Yang, Chufan Shi, Xinyu Zhu, Zihao Lin, Hanwen Wan, Yujiu Yang, Tetsuya Sakai, Tian Feng, Hayato Yamana</author><pubDate>Fri, 28 Jun 2024 17:03:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20015v1</guid></item><item><title>On the Trade-off between Flatness and Optimization in Distributed Learning</title><link>http://arxiv.org/abs/2406.20006v1</link><description>This paper proposes a theoretical framework to evaluate and compare theperformance of gradient-descent algorithms for distributed learning in relationto their behavior around local minima in nonconvex environments. Previous workshave noticed that convergence toward flat local minima tend to enhance thegeneralization ability of learning algorithms. This work discovers twointeresting results. First, it shows that decentralized learning strategies areable to escape faster away from local minimizers and favor convergence towardflatter minima relative to the centralized solution in the large-batch trainingregime. Second, and importantly, the ultimate classification accuracy is notsolely dependent on the flatness of the local minimizer but also on how well alearning algorithm can approach that minimum. In other words, theclassification accuracy is a function of both flatness and optimizationperformance. The paper examines the interplay between the two measures offlatness and optimization error closely. One important conclusion is thatdecentralized strategies of the diffusion type deliver enhanced classificationaccuracy because it strikes a more favorable balance between flatness andoptimization performance.</description><author>Ying Cao, Zhaoxian Wu, Kun Yuan, Ali H. Sayed</author><pubDate>Fri, 28 Jun 2024 16:46:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20006v1</guid></item><item><title>Malaria Cell Detection Using Deep Neural Networks</title><link>http://arxiv.org/abs/2406.20005v1</link><description>Malaria remains one of the most pressing public health concerns globally,causing significant morbidity and mortality, especially in sub-Saharan Africa.Rapid and accurate diagnosis is crucial for effective treatment and diseasemanagement. Traditional diagnostic methods, such as microscopic examination ofblood smears, are labor-intensive and require significant expertise, which maynot be readily available in resource-limited settings. This project aims toautomate the detection of malaria-infected cells using a deep learningapproach. We employed a convolutional neural network (CNN) based on theResNet50 architecture, leveraging transfer learning to enhance performance. TheMalaria Cell Images Dataset from Kaggle, containing 27,558 images categorizedinto infected and uninfected cells, was used for training and evaluation. Ourmodel demonstrated high accuracy, precision, and recall, indicating itspotential as a reliable tool for assisting in malaria diagnosis. Additionally,a web application was developed using Streamlit to allow users to upload cellimages and receive predictions about malaria infection, making the technologyaccessible and user-friendly. This paper provides a comprehensive overview ofthe methodology, experiments, and results, highlighting the effectiveness ofdeep learning in medical image analysis.</description><author>Saurabh Sawant, Anurag Singh</author><pubDate>Fri, 28 Jun 2024 16:44:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.20005v1</guid></item><item><title>A Small and Fast BERT for Chinese Medical Punctuation Restoration</title><link>http://arxiv.org/abs/2308.12568v4</link><description>In clinical dictation, utterances after automatic speech recognition (ASR)without explicit punctuation marks may lead to the misunderstanding of dictatedreports. To give a precise and understandable clinical report with ASR,automatic punctuation restoration is required. Considering a practicalscenario, we propose a fast and light pre-trained model for Chinese medicalpunctuation restoration based on 'pretraining and fine-tuning' paradigm. Inthis work, we distill pre-trained models by incorporating supervisedcontrastive learning and a novel auxiliary pre-training task (Punctuation MarkPrediction) to make it well-suited for punctuation restoration. Our experimentson various distilled models reveal that our model can achieve 95% performancewhile 10% model size relative to state-of-the-art Chinese RoBERTa.</description><author>Tongtao Ling, Yutao Lai, Lei Chen, Shilei Huang, Yi Liu</author><pubDate>Fri, 28 Jun 2024 16:44:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.12568v4</guid></item><item><title>Robustness Assessment of a Runway Object Classifier for Safe Aircraft Taxiing</title><link>http://arxiv.org/abs/2402.00035v3</link><description>As deep neural networks (DNNs) are becoming the prominent solution for manycomputational problems, the aviation industry seeks to explore their potentialin alleviating pilot workload and in improving operational safety. However, theuse of DNNs in this type of safety-critical applications requires a thoroughcertification process. This need can be addressed through formal verification,which provides rigorous assurances -- e.g.,~by proving the absence of certainmispredictions. In this case-study paper, we demonstrate this process using animage-classifier DNN currently under development at Airbus and intended for useduring the aircraft taxiing phase. We use formal methods to assess this DNN'srobustness to three common image perturbation types: noise, brightness andcontrast, and some of their combinations. This process entails multipleinvocations of the underlying verifier, which might be computationallyexpensive; and we therefore propose a method that leverages the monotonicity ofthese robustness properties, as well as the results of past verificationqueries, in order to reduce the overall number of verification queries requiredby nearly 60%. Our results provide an indication of the level of robustnessachieved by the DNN classifier under study, and indicate that it isconsiderably more vulnerable to noise than to brightness or contrastperturbations.</description><author>Yizhak Elboher, Raya Elsaleh, Omri Isac, Mélanie Ducoffe, Audrey Galametz, Guillaume Povéda, Ryma Boumazouza, Noémie Cohen, Guy Katz</author><pubDate>Fri, 28 Jun 2024 16:42:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00035v3</guid></item><item><title>Scaling laws for learning with real and surrogate data</title><link>http://arxiv.org/abs/2402.04376v2</link><description>Collecting large quantities of high-quality data can be prohibitivelyexpensive or impractical, and a bottleneck in machine learning. One may insteadaugment a small set of $n$ data points from the target distribution with datafrom more accessible sources, e.g. data collected under different circumstancesor synthesized by generative models. We refer to such data as `surrogate data.'We introduce a weighted empirical risk minimization (ERM) approach forintegrating surrogate data into training. We analyze mathematically this methodunder several classical statistical models, and validate our findingsempirically on datasets from different domains. Our main findings are: $(i)$Integrating surrogate data can significantly reduce the test error on theoriginal distribution. Surprisingly, this can happen even when the surrogatedata is unrelated to the original ones. We trace back this behavior to theclassical Stein's paradox. $(ii)$ In order to reap the benefit of surrogatedata, it is crucial to use optimally weighted ERM. $(iii)$ The test error ofmodels trained on mixtures of real and surrogate data is approximatelydescribed by a scaling law. This scaling law can be used to predict the optimalweighting scheme, and to choose the amount of surrogate data to add.</description><author>Ayush Jain, Andrea Montanari, Eren Sasoglu</author><pubDate>Fri, 28 Jun 2024 16:36:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.04376v2</guid></item><item><title>Distributed Speculative Inference of Large Language Models</title><link>http://arxiv.org/abs/2405.14105v2</link><description>Accelerating the inference of large language models (LLMs) is an importantchallenge in artificial intelligence. This paper introduces distributedspeculative inference (DSI), a novel distributed inference algorithm that isprovably faster than speculative inference (SI) [leviathan2023fast,chen2023accelerating, miao2023specinfer] and traditional autoregressiveinference (non-SI). Like other SI algorithms, DSI works on frozen LLMs,requiring no training or architectural modifications, and it preserves thetarget distribution. Prior studies on SI have demonstrated empirical speedups (compared to non-SI)but require a fast and accurate drafter LLM. In practice, off-the-shelf LLMsoften do not have matching drafters that are sufficiently fast and accurate. Weshow a gap: SI gets slower than non-SI when using slower or less accuratedrafters. We close this gap by proving that DSI is faster than both SI andnon-SI given any drafters. By orchestrating multiple instances of the targetand drafters, DSI is not only faster than SI but also supports LLMs that cannotbe accelerated with SI. Our simulations show speedups of off-the-shelf LLMs in realistic settings:DSI is 1.29-1.92x faster than SI.</description><author>Nadav Timor, Jonathan Mamou, Daniel Korat, Moshe Berchansky, Oren Pereg, Moshe Wasserblat, Tomer Galanti, Michal Gordon, David Harel</author><pubDate>Fri, 28 Jun 2024 16:34:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.14105v2</guid></item><item><title>The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models</title><link>http://arxiv.org/abs/2406.19999v1</link><description>Following multiple instructions is a crucial ability for large languagemodels (LLMs). Evaluating this ability comes with significant challenges: (i)limited coherence between multiple instructions, (ii) positional bias where theorder of instructions affects model performance, and (iii) a lack ofobjectively verifiable tasks. To address these issues, we introduce a benchmarkdesigned to evaluate models' abilities to follow multiple instructions throughsequential instruction following (SIFo) tasks. In SIFo, the successfulcompletion of multiple instructions is verifiable by examining only the finalinstruction. Our benchmark evaluates instruction following using four tasks(text modification, question answering, mathematics, and security rulefollowing), each assessing different aspects of sequential instructionfollowing. Our evaluation of popular LLMs, both closed-source and open-source,shows that more recent and larger models significantly outperform their olderand smaller counterparts on the SIFo tasks, validating the benchmark'seffectiveness. All models struggle with following sequences of instructions,hinting at an important lack of robustness of today's language models.</description><author>Xinyi Chen, Baohao Liao, Jirui Qi, Panagiotis Eustratiadis, Christof Monz, Arianna Bisazza, Maarten de Rijke</author><pubDate>Fri, 28 Jun 2024 16:34:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19999v1</guid></item><item><title>Wavelets Are All You Need for Autoregressive Image Generation</title><link>http://arxiv.org/abs/2406.19997v1</link><description>In this paper, we take a new approach to autoregressive image generation thatis based on two main ingredients. The first is wavelet image coding, whichallows to tokenize the visual details of an image from coarse to fine detailsby ordering the information starting with the most significant bits of the mostsignificant wavelet coefficients. The second is a variant of a languagetransformer whose architecture is re-designed and optimized for token sequencesin this 'wavelet language'. The transformer learns the significant statisticalcorrelations within a token sequence, which are the manifestations ofwell-known correlations between the wavelet subbands at various resolutions. Weshow experimental results with conditioning on the generation process.</description><author>Wael Mattar, Idan Levy, Nir Sharon, Shai Dekel</author><pubDate>Fri, 28 Jun 2024 16:32:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19997v1</guid></item><item><title>Single Parent Family: A Spectrum of Family Members from a Single Pre-Trained Foundation Model</title><link>http://arxiv.org/abs/2406.19995v1</link><description>This paper introduces a novel method of Progressive Low Rank Decomposition(PLRD) tailored for the compression of large language models. Our approachleverages a pre-trained model, which is then incrementally decompressed tosmaller sizes using progressively lower ranks. This method allows forsignificant reductions in computational overhead and energy consumption, assubsequent models are derived from the original without the need for retrainingfrom scratch. We detail the implementation of PLRD, which strategicallydecreases the tensor ranks, thus optimizing the trade-off between modelperformance and resource usage. The efficacy of PLRD is demonstrated throughextensive experiments showing that models trained with PLRD method on only 1Btokens maintain comparable performance with traditionally trained models whileusing 0.1% of the tokens. The versatility of PLRD is highlighted by its abilityto generate multiple model sizes from a single foundational model, adaptingfluidly to varying computational and memory budgets. Our findings suggest thatPLRD could set a new standard for the efficient scaling of LLMs, makingadvanced AI more feasible on diverse platforms.</description><author>Habib Hajimolahoseini, Mohammad Hassanpour, Foozhan Ataiefard, Boxing Chen, Yang Liu</author><pubDate>Fri, 28 Jun 2024 16:27:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19995v1</guid></item><item><title>Scalable Bayesian uncertainty quantification with data-driven priors for radio interferometric imaging</title><link>http://arxiv.org/abs/2312.00125v2</link><description>Next-generation radio interferometers like the Square Kilometer Array havethe potential to unlock scientific discoveries thanks to their unprecedentedangular resolution and sensitivity. One key to unlocking their potentialresides in handling the deluge and complexity of incoming data. This challengerequires building radio interferometric imaging methods that can cope with themassive data sizes and provide high-quality image reconstructions withuncertainty quantification (UQ). This work proposes a method coined QuantifAIto address UQ in radio-interferometric imaging with data-driven (learned)priors for high-dimensional settings. Our model, rooted in the Bayesianframework, uses a physically motivated model for the likelihood. The modelexploits a data-driven convex prior, which can encode complex informationlearned implicitly from simulations and guarantee the log-concavity of theposterior. We leverage probability concentration phenomena of high-dimensionallog-concave posteriors that let us obtain information about the posterior,avoiding MCMC sampling techniques. We rely on convex optimisation methods tocompute the MAP estimation, which is known to be faster and better scale withdimension than MCMC sampling strategies. Our method allows us to compute localcredible intervals, i.e., Bayesian error bars, and perform hypothesis testingof structure on the reconstructed image. In addition, we propose a novelblazing-fast method to compute pixel-wise uncertainties at different scales. Wedemonstrate our method by reconstructing radio-interferometric images in asimulated setting and carrying out fast and scalable UQ, which we validate withMCMC sampling. Our method shows an improved image quality and more meaningfuluncertainties than the benchmark method based on a sparsity-promoting prior.QuantifAI's source code: https://github.com/astro-informatics/QuantifAI.</description><author>Tobías I. Liaudat, Matthijs Mars, Matthew A. Price, Marcelo Pereyra, Marta M. Betcke, Jason D. McEwen</author><pubDate>Fri, 28 Jun 2024 16:17:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00125v2</guid></item><item><title>Dynamic planning in hierarchical active inference</title><link>http://arxiv.org/abs/2402.11658v2</link><description>By dynamic planning, we refer to the ability of the human brain to infer andimpose motor trajectories related to cognitive decisions. A recent paradigm,active inference, brings fundamental insights into the adaptation of biologicalorganisms, constantly striving to minimize prediction errors to restrictthemselves to life-compatible states. Over the past years, many studies haveshown how human and animal behavior could be explained in terms of an activeinferential process - either as discrete decision-making or continuous motorcontrol - inspiring innovative solutions in robotics and artificialintelligence. Still, the literature lacks a comprehensive outlook on how toeffectively plan actions in changing environments. Setting ourselves the goalof modeling tool use, we delve into the topic of dynamic planning in activeinference, keeping in mind two crucial aspects of biological goal-directedbehavior: the capacity to understand and exploit affordances for objectmanipulation, and to learn the hierarchical interactions between the self andthe environment, including other agents. We start from a simple unit andgradually describe more advanced structures, comparing recently proposed designchoices and providing basic examples for each section. This study distancesitself from traditional views centered on neural networks and reinforcementlearning, and points toward a yet unexplored direction in active inference:hybrid representations in hierarchical models.</description><author>Matteo Priorelli, Ivilin Peev Stoianov</author><pubDate>Fri, 28 Jun 2024 16:16:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.11658v2</guid></item><item><title>Machine Learning Predictors for Min-Entropy Estimation</title><link>http://arxiv.org/abs/2406.19983v1</link><description>This study investigates the application of machine learning predictors formin-entropy estimation in Random Number Generators (RNGs), a key component incryptographic applications where accurate entropy assessment is essential forcybersecurity. Our research indicates that these predictors, and indeed anypredictor that leverages sequence correlations, primarily estimate averagemin-entropy, a metric not extensively studied in this context. We explore therelationship between average min-entropy and the traditional min-entropy,focusing on their dependence on the number of target bits being predicted.Utilizing data from Generalized Binary Autoregressive Models, a subset ofMarkov processes, we demonstrate that machine learning models (including ahybrid of convolutional and recurrent Long Short-Term Memory layers and thetransformer-based GPT-2 model) outperform traditional NIST SP 800-90Bpredictors in certain scenarios. Our findings underscore the importance ofconsidering the number of target bits in min-entropy assessment for RNGs andhighlight the potential of machine learning approaches in enhancing entropyestimation techniques for improved cryptographic security.</description><author>Javier Blanco-Romero, Vicente Lorenzo, Florina Almenares Mendoza, Daniel Díaz-Sánchez</author><pubDate>Fri, 28 Jun 2024 16:15:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19983v1</guid></item><item><title>Digital Twin Calibration for Biological System-of-Systems: Cell Culture Manufacturing Process</title><link>http://arxiv.org/abs/2405.03913v2</link><description>Biomanufacturing innovation relies on an efficient Design of Experiments(DoEs) to optimize processes and product quality. Traditional DoE methods,ignoring the underlying bioprocessing mechanisms, often suffer from a lack ofinterpretability and sample efficiency. This limitation motivates us to createa new optimal learning approach for digital twin model calibration. In thisstudy, we consider the cell culture process multi-scale mechanistic model, alsoknown as Biological System-of-Systems (Bio-SoS). This model with a modulardesign, composed of sub-models, allows us to integrate data across variousproduction processes. To calibrate the Bio-SoS digital twin, we evaluate themean squared error of model prediction and develop a computational approach toquantify the impact of parameter estimation error of individual sub-models onthe prediction accuracy of digital twin, which can guide sample-efficient andinterpretable DoEs.</description><author>Fuqiang Cheng, Wei Xie, Hua Zheng</author><pubDate>Fri, 28 Jun 2024 16:13:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.03913v2</guid></item><item><title>Nearest Neighbor Sampling for Covariate Shift Adaptation</title><link>http://arxiv.org/abs/2312.09969v2</link><description>Many existing covariate shift adaptation methods estimate sample weightsgiven to loss values to mitigate the gap between the source and the targetdistribution. However, estimating the optimal weights typically involvescomputationally expensive matrix inversion and hyper-parameter tuning. In thispaper, we propose a new covariate shift adaptation method which avoidsestimating the weights. The basic idea is to directly work on unlabeled targetdata, labeled according to the $k$-nearest neighbors in the source dataset. Ouranalysis reveals that setting $k = 1$ is an optimal choice. This propertyremoves the necessity of tuning the only hyper-parameter $k$ and leads to arunning time quasi-linear in the sample size. Our results include sharp ratesof convergence for our estimator, with a tight control of the mean square errorand explicit constants. In particular, the variance of our estimators has thesame rate of convergence as for standard parametric estimation despite theirnon-parametric nature. The proposed estimator shares similarities with somematching-based treatment effect estimators used, e.g., in biostatistics,econometrics, and epidemiology. Our experiments show that it achieves drasticreduction in the running time with remarkable accuracy.</description><author>François Portier, Lionel Truquet, Ikko Yamane</author><pubDate>Fri, 28 Jun 2024 16:10:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.09969v2</guid></item><item><title>Improved Monte Carlo tree search (MCTS) formulation with multiple root nodes for discrete sizing optimization of truss structures</title><link>http://arxiv.org/abs/2309.06045v2</link><description>This paper proposes a new method for discrete optimum design of trussstructures utilizing Monte Carlo tree search (MCTS) with update process, thebest reward, accelerating technique, and terminal condition. An improved MCTSformulation with multiple root nodes is developed in this study. Update processmeans that once a final solution is found, it is used as the initial solutionfor next search tree. The best reward is used in the backpropagation step.Accelerating technique is introduced by decreasing the width of search tree andreducing maximum number of iterations. The agent is trained to minimize thetotal structural weight under various constraints until the terminal conditionis satisfied. Then, optimal solution is the minimum value of all solutionsfound by search trees. These numerical examples show that the agent can findoptimal solution with low computational cost, stably produces an optimaldesign, and is suitable for practical engineering problems.</description><author>Fu-Yao Ko, Katsuyuki Suzuki, Kazuo Yonekura</author><pubDate>Fri, 28 Jun 2024 16:10:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.06045v2</guid></item><item><title>Comparative Analysis of LSTM Neural Networks and Traditional Machine Learning Models for Predicting Diabetes Patient Readmission</title><link>http://arxiv.org/abs/2406.19980v1</link><description>Diabetes mellitus is a chronic metabolic disorder that has emerged as one ofthe major health problems worldwide due to its high prevalence and seriouscomplications, which are pricey to manage. Effective management requires goodglycemic control and regular follow-up in the clinic; however, non-adherence toscheduled follow-ups is very common. This study uses the Diabetes 130-USHospitals dataset for analysis and prediction of readmission patients byvarious traditional machine learning models, such as XGBoost, LightGBM,CatBoost, Decision Tree, and Random Forest, and also uses an in-house LSTMneural network for comparison. The quality of the data was assured bypreprocessing it, and the performance evaluation for all these models was basedon accuracy, precision, recall, and F1-score. LightGBM turned out to be thebest traditional model, while XGBoost was the runner-up. The LSTM modelsuffered from overfitting despite high training accuracy. A major strength ofLSTM is capturing temporal dependencies among the patient data. Further, SHAPvalues were used, which improved model interpretability, whereby key factorsamong them number of lab procedures and discharge disposition were identifiedas critical in the prediction of readmissions. This study demonstrates thatmodel selection, validation, and interpretability are key steps in predictivehealthcare modeling. This will help health providers design interventions forimproved follow-up adherence and better management of diabetes.</description><author>Abolfazl Zarghani</author><pubDate>Fri, 28 Jun 2024 16:06:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19980v1</guid></item><item><title>ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting</title><link>http://arxiv.org/abs/2406.19976v1</link><description>Bilevel optimization has shown its utility across various machine learningsettings, yet most algorithms in practice require second-order information,making it challenging to scale them up. Only recently, a paradigm offirst-order algorithms emerged, capable of effectively addressing bileveloptimization problems. Nevertheless, the practical efficiency of this paradigmremains unverified, particularly in the context of large language models(LLMs). This paper introduces the first scalable instantiation of this paradigmcalled ScaleBiO, focusing on bilevel optimization for large-scale LLM datareweighting. By combining with a recently proposed memory-efficient trainingtechnique called LISA, our novel algorithm allows the paradigm to scale to34-billion-parameter LLMs on eight A40 GPUs, marking the first successfulapplication of bilevel optimization under practical scenarios for large-sizedLLMs. Empirically, extensive experiments on data reweighting verify theeffectiveness of ScaleBiO for different-scaled models, including GPT-2,LLaMA-3-8B, GPT-NeoX-20B, and Yi-34B, where bilevel optimization succeeds infiltering irrelevant data samples and selecting informative samples.Theoretically, ScaleBiO ensures the optimality of the learned data weights,along with a convergence guarantee matching the conventional first-orderbilevel optimization paradigm on smooth and strongly convex objectives.</description><author>Rui Pan, Jipeng Zhang, Xingyuan Pan, Renjie Pi, Xiaoyu Wang, Tong Zhang</author><pubDate>Fri, 28 Jun 2024 16:03:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19976v1</guid></item><item><title>STLLaVA-Med: Self-Training Large Language and Vision Assistant for Medical</title><link>http://arxiv.org/abs/2406.19973v1</link><description>Large Vision-Language Models (LVLMs) have shown significant potential inassisting medical diagnosis by leveraging extensive biomedical datasets.However, the advancement of medical image understanding and reasoningcritically depends on building high-quality visual instruction data, which iscostly and labor-intensive to obtain, particularly in the medical domain. Tomitigate this data-starving issue, we introduce Self-Training Large Languageand Vision Assistant for Medical (STLLaVA-Med). The proposed method is designedto train a policy model (an LVLM) capable of auto-generating medical visualinstruction data to improve data efficiency, guided through Direct PreferenceOptimization (DPO). Specifically, a more powerful and larger LVLM (e.g.,GPT-4o) is involved as a biomedical expert to oversee the DPO fine-tuningprocess on the auto-generated data, encouraging the policy model to alignefficiently with human preferences. We validate the efficacy and dataefficiency of STLLaVA-Med across three major medical Visual Question Answering(VQA) benchmarks, demonstrating competitive zero-shot performance with theutilization of only 9% of the medical data.</description><author>Guohao Sun, Can Qin, Huazhu Fu, Linwei Wang, Zhiqiang Tao</author><pubDate>Fri, 28 Jun 2024 16:01:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19973v1</guid></item><item><title>How well ChatGPT understand Malaysian English? An Evaluation on Named Entity Recognition and Relation Extraction</title><link>http://arxiv.org/abs/2311.11583v2</link><description>Recently, ChatGPT has attracted a lot of interest from both researchers andthe general public. While the performance of ChatGPT in named entityrecognition and relation extraction from Standard English texts issatisfactory, it remains to be seen if it can perform similarly for MalaysianEnglish. Malaysian English is unique as it exhibits morphosyntactic andsemantical adaptation from local contexts. In this study, we assess ChatGPT'scapability in extracting entities and relations from the Malaysian English News(MEN) dataset. We propose a three-step methodology referred to as\textbf{\textit{educate-predict-evaluate}}. The performance of ChatGPT isassessed using F1-Score across 18 unique prompt settings, which were carefullyengineered for a comprehensive review. From our evaluation, we found thatChatGPT does not perform well in extracting entities from Malaysian Englishnews articles, with the highest F1-Score of 0.497. Further analysis shows thatthe morphosyntactic adaptation in Malaysian English caused the limitation.However, interestingly, this morphosyntactic adaptation does not impact theperformance of ChatGPT for relation extraction.</description><author>Mohan Raj Chanthran, Lay-Ki Soon, Huey Fang Ong, Bhawani Selvaretnam</author><pubDate>Fri, 28 Jun 2024 16:01:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11583v2</guid></item><item><title>Into the Unknown: Generating Geospatial Descriptions for New Environments</title><link>http://arxiv.org/abs/2406.19967v1</link><description>Similar to vision-and-language navigation (VLN) tasks that focus on bridgingthe gap between vision and language for embodied navigation, the new Rendezvous(RVS) task requires reasoning over allocentric spatial relationships(independent of the observer's viewpoint) using non-sequential navigationinstructions and maps. However, performance substantially drops in newenvironments with no training data. Using opensource descriptions paired withcoordinates (e.g., Wikipedia) provides training data but suffers from limitedspatially-oriented text resulting in low geolocation resolution. We propose alarge-scale augmentation method for generating high-quality synthetic data fornew environments using readily available geospatial data. Our method constructsa grounded knowledge-graph, capturing entity relationships. Sampled entitiesand relations (`shop north of school') generate navigation instructions via (i)generating numerous templates using context-free grammar (CFG) to embedspecific entities and relations; (ii) feeding the entities and relation into alarge language model (LLM) for instruction generation. A comprehensiveevaluation on RVS, showed that our approach improves the 100-meter accuracy by45.83% on unseen environments. Furthermore, we demonstrate that models trainedwith CFG-based augmentation achieve superior performance compared with thosetrained with LLM-based augmentation, both in unseen and seen environments.These findings suggest that the potential advantages of explicitly structuringspatial information for text-based geospatial reasoning in previously unknown,can unlock data-scarce scenarios.</description><author>Tzuf Paz-Argaman, John Palowitch, Sayali Kulkarni, Reut Tsarfaty, Jason Baldridge</author><pubDate>Fri, 28 Jun 2024 15:56:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19967v1</guid></item><item><title>Simulating Financial Market via Large Language Model based Agents</title><link>http://arxiv.org/abs/2406.19966v1</link><description>Most economic theories typically assume that financial market participantsare fully rational individuals and use mathematical models to simulate humanbehavior in financial markets. However, human behavior is often not entirelyrational and is challenging to predict accurately with mathematical models. Inthis paper, we propose \textbf{A}gent-based \textbf{S}imulated\textbf{F}inancial \textbf{M}arket (ASFM), which first constructs a simulatedstock market with a real order matching system. Then, we propose a largelanguage model based agent as the stock trader, which contains the profile,observation, and tool-learning based action module. The trading agent cancomprehensively understand current market dynamics and financial policyinformation, and make decisions that align with their trading strategy. In theexperiments, we first verify that the reactions of our ASFM are consistent withthe real stock market in two controllable scenarios. In addition, we alsoconduct experiments in two popular economics research directions, and we findthat conclusions drawn in our \model align with the preliminary findings ineconomics research. Based on these observations, we believe our proposed ASFMprovides a new paradigm for economic research.</description><author>Shen Gao, Yuntao Wen, Minghang Zhu, Jianing Wei, Yuhan Cheng, Qunzi Zhang, Shuo Shang</author><pubDate>Fri, 28 Jun 2024 15:54:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19966v1</guid></item><item><title>Are LLM-based Evaluators Confusing NLG Quality Criteria?</title><link>http://arxiv.org/abs/2402.12055v2</link><description>Some prior work has shown that LLMs perform well in NLG evaluation fordifferent tasks. However, we discover that LLMs seem to confuse differentevaluation criteria, which reduces their reliability. For further verification,we first consider avoiding issues of inconsistent conceptualization and vagueexpression in existing NLG quality criteria themselves. So we summarize a clearhierarchical classification system for 11 common aspects with correspondingdifferent criteria from previous studies involved. Inspired by behavioraltesting, we elaborately design 18 types of aspect-targeted perturbation attacksfor fine-grained analysis of the evaluation behaviors of different LLMs. Wealso conduct human annotations beyond the guidance of the classification systemto validate the impact of the perturbations. Our experimental results revealconfusion issues inherent in LLMs, as well as other noteworthy phenomena, andnecessitate further research and improvements for LLM-based evaluation.</description><author>Xinyu Hu, Mingqi Gao, Sen Hu, Yang Zhang, Yicheng Chen, Teng Xu, Xiaojun Wan</author><pubDate>Fri, 28 Jun 2024 15:53:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12055v2</guid></item><item><title>Learning to utilize image second-order derivative information for crisp edge detection</title><link>http://arxiv.org/abs/2406.05779v3</link><description>Edge detection is a fundamental task in computer vision. It has made greatprogress under the development of deep convolutional neural networks (DCNNs),some of which have achieved a beyond human-level performance. However, recenttop-performing edge detection methods tend to generate thick and noisy edgelines. In this work, we solve this problem from two aspects: (1) the lack ofprior knowledge regarding image edges, and (2) the issue of imbalanced pixeldistribution. We propose a second-order derivative-based multi-scale contextualenhancement module (SDMCM) to help the model locate true edge pixels accuratelyby introducing the edge prior knowledge. We also construct a hybrid focal lossfunction (HFL) to alleviate the imbalanced distribution issue. In addition, weemploy the conditionally parameterized convolution (CondConv) to develop anovel boundary refinement module (BRM), which can further refine the finaloutput edge maps. In the end, we propose a U-shape network named LUS-Net whichis based on the SDMCM and BRM for crisp edge detection. We perform extensiveexperiments on three standard benchmarks, and the experiment results illustratethat our method can predict crisp and clean edge maps and achievesstate-of-the-art performance on the BSDS500 dataset (ODS=0.829), NYUD-V2dataset (ODS=0.768), and BIPED dataset (ODS=0.903).</description><author>Changsong Liu, Wei Zhang, Yanyan Liu, Yimeng Fan, Mingyang Li, Wenlin Li</author><pubDate>Fri, 28 Jun 2024 15:53:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.05779v3</guid></item><item><title>Text2Robot: Evolutionary Robot Design from Text Descriptions</title><link>http://arxiv.org/abs/2406.19963v1</link><description>Robot design has traditionally been costly and labor-intensive. Despiteadvancements in automated processes, it remains challenging to navigate a vastdesign space while producing physically manufacturable robots. We introduceText2Robot, a framework that converts user text specifications and performancepreferences into physical quadrupedal robots. Within minutes, Text2Robot canuse text-to-3D models to provide strong initializations of diversemorphologies. Within a day, our geometric processing algorithms andbody-control co-optimization produce a walking robot by explicitly consideringreal-world electronics and manufacturability. Text2Robot enables rapidprototyping and opens new opportunities for robot design with generativemodels.</description><author>Ryan P. Ringel, Zachary S. Charlick, Jiaxun Liu, Boxi Xia, Boyuan Chen</author><pubDate>Fri, 28 Jun 2024 15:51:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19963v1</guid></item><item><title>The Computational Curse of Big Data for Bayesian Additive Regression Trees: A Hitting Time Analysis</title><link>http://arxiv.org/abs/2406.19958v1</link><description>Bayesian Additive Regression Trees (BART) is a popular Bayesiannon-parametric regression model that is commonly used in causal inference andbeyond. Its strong predictive performance is supported by theoreticalguarantees that its posterior distribution concentrates around the trueregression function at optimal rates under various data generative settings andfor appropriate prior choices. In this paper, we show that the BART sampleroften converges slowly, confirming empirical observations by other researchers.Assuming discrete covariates, we show that, while the BART posteriorconcentrates on a set comprising all optimal tree structures (smallest bias andcomplexity), the Markov chain's hitting time for this set increases with $n$(training sample size), under several common data generative settings. As $n$increases, the approximate BART posterior thus becomes increasingly differentfrom the exact posterior (for the same number of MCMC samples), contrastingwith earlier concentration results on the exact posterior. This contrast ishighlighted by our simulations showing worsening frequentist undercoverage forapproximate posterior intervals and a growing ratio between the MSE of theapproximate posterior and that obtainable by artificially improving convergencevia averaging multiple sampler chains. Finally, based on our theoreticalinsights, possibilities are discussed to improve the BART sampler convergenceperformance.</description><author>Yan Shuo Tan, Omer Ronen, Theo Saarinen, Bin Yu</author><pubDate>Fri, 28 Jun 2024 15:45:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19958v1</guid></item><item><title>BESTOW: Efficient and Streamable Speech Language Model with the Best of Two Worlds in GPT and T5</title><link>http://arxiv.org/abs/2406.19954v1</link><description>Incorporating speech understanding capabilities into pretrainedlarge-language models has become a vital research direction (SpeechLLM). Theprevious architectures can be categorized as: i) GPT-style, prepend speechprompts to the text prompts as a sequence of LLM inputs like a decoder-onlymodel; ii) T5-style, introduce speech cross-attention to each layer of thepretrained LLMs. We propose BESTOW architecture to bring the BESt features fromTwO Worlds into a single model that is highly efficient and has strongmultitask capabilities. Moreover, there is no clear streaming solution foreither style, especially considering the solution should generalize to speechmultitask. We reformulate streamable SpeechLLM as a read-write policy problemand unifies the offline and streaming research with BESTOW architecture. Hencewe demonstrate the first open-source SpeechLLM solution that enables Streamingand Multitask at scale (beyond ASR) at the same time. This streamable solutionachieves very strong performance on a wide range of speech tasks (ASR, AST,SQA, unseen DynamicSuperb). It is end-to-end optimizable, with lowertraining/inference cost, and demonstrates LLM knowledge transferability tospeech.</description><author>Zhehuai Chen, He Huang, Oleksii Hrinchuk, Krishna C. Puvvada, Nithin Rao Koluguri, Piotr Żelasko, Jagadeesh Balam, Boris Ginsburg</author><pubDate>Fri, 28 Jun 2024 15:40:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19954v1</guid></item><item><title>Uncovering the hidden core-periphery structure in hyperbolic networks</title><link>http://arxiv.org/abs/2406.19953v1</link><description>The hyperbolic network models exhibit very fundamental and essentialfeatures, like small-worldness, scale-freeness, high-clustering coefficient,and community structure. In this paper, we comprehensively explore the presenceof an important feature, the core-periphery structure, in the hyperbolicnetwork models, which is often exhibited by real-world networks. We focused onwell-known hyperbolic models such as popularity-similarity optimization model(PSO) and S1/H2 models and studied core-periphery structures using awell-established method that is based on standard random walk Markov chainmodel. The observed core-periphery centralization values indicate that thecore-periphery structure can be very pronounced under certain conditions. Wealso validate our findings by statistically testing for the significance of theobserved core-periphery structure in the network geometry. This study extendsnetwork science and reveals core-periphery insights applicable to variousdomains, enhancing network performance and resiliency in transportation andinformation systems.</description><author>Imran Ansari, Pawanesh Yadav, Niteesh Sahni</author><pubDate>Fri, 28 Jun 2024 15:39:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19953v1</guid></item><item><title>Mining Reasons For And Against Vaccination From Unstructured Data Using Nichesourcing and AI Data Augmentation</title><link>http://arxiv.org/abs/2406.19951v1</link><description>We present Reasons For and Against Vaccination (RFAV), a dataset forpredicting reasons for and against vaccination, and scientific authorities usedto justify them, annotated through nichesourcing and augmented using GPT4 andGPT3.5-Turbo. We show how it is possible to mine these reasons innon-structured text, under different task definitions, despite the high levelof subjectivity involved and explore the impact of artificially augmented datausing in-context learning with GPT4 and GPT3.5-Turbo. We publish the datasetand the trained models along with the annotation manual used to trainannotators and define the task.</description><author>Damián Ariel Furman, Juan Junqueras, Z. Burçe Gümüslü, Edgar Altszyler, Joaquin Navajas, Ophelia Deroy, Justin Sulik</author><pubDate>Fri, 28 Jun 2024 15:36:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19951v1</guid></item><item><title>DWARF: Disease-weighted network for attention map refinement</title><link>http://arxiv.org/abs/2406.17032v2</link><description>The interpretability of deep learning is crucial for evaluating thereliability of medical imaging models and reducing the risks of inaccuratepatient recommendations. This study addresses the "human out of the loop" and"trustworthiness" issues in medical image analysis by integrating medicalprofessionals into the interpretability process. We propose a disease-weightedattention map refinement network (DWARF) that leverages expert feedback toenhance model relevance and accuracy. Our method employs cyclic training toiteratively improve diagnostic performance, generating precise andinterpretable feature maps. Experimental results demonstrate significantimprovements in interpretability and diagnostic accuracy across multiplemedical imaging datasets. This approach fosters effective collaboration betweenAI systems and healthcare professionals, ultimately aiming to improve patientoutcomes</description><author>Haozhe Luo, Aurélie Pahud de Mortanges, Oana Inel, Abraham Bernstein, Mauricio Reyes</author><pubDate>Fri, 28 Jun 2024 15:34:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17032v2</guid></item><item><title>Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring</title><link>http://arxiv.org/abs/2406.19949v1</link><description>Generating rationales that justify scoring decisions has been a promising wayto facilitate explainability in automated scoring systems. However, existingmethods do not match the accuracy of classifier-based methods. Plus, thegenerated rationales often contain hallucinated information. To address theseissues, we propose a novel framework capable of generating more faithfulrationales and, more importantly, matching performance with classifier-basedblack-box scoring systems. We first mimic the human assessment process byquerying Large Language Models (LLMs) to generate a thought tree. We thensummarise intermediate assessment decisions from each thought tree path forcreating synthetic rationale data and rationale preference data. Finally, weutilise the generated synthetic data to calibrate LLMs through a two-steptraining process: supervised fine-tuning and preference optimization. Extensiveexperimental results demonstrate that our framework achieves a 38% assessmentperformance improvement in the QWK score compared to prior work while producinghigher-quality rationales, as recognised by human evaluators and LLMs. Our worksheds light on the effectiveness of performing preference optimization usingsynthetic preference data obtained from thought tree paths.</description><author>Jiazheng Li, Hainiu Xu, Zhaoyue Sun, Yuxiang Zhou, David West, Cesare Aloisi, Yulan He</author><pubDate>Fri, 28 Jun 2024 15:33:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19949v1</guid></item><item><title>Kolmogorov-Smirnov GAN</title><link>http://arxiv.org/abs/2406.19948v1</link><description>We propose a novel deep generative model, the Kolmogorov-Smirnov GenerativeAdversarial Network (KSGAN). Unlike existing approaches, KSGAN formulates thelearning process as a minimization of the Kolmogorov-Smirnov (KS) distance,generalized to handle multivariate distributions. This distance is calculatedusing the quantile function, which acts as the critic in the adversarialtraining process. We formally demonstrate that minimizing the KS distance leadsto the trained approximate distribution aligning with the target distribution.We propose an efficient implementation and evaluate its effectiveness throughexperiments. The results show that KSGAN performs on par with existingadversarial methods, exhibiting stability during training, resistance to modedropping and collapse, and tolerance to variations in hyperparameter settings.Additionally, we review the literature on the Generalized KS test and discussthe connections between KSGAN and existing adversarial generative models.</description><author>Maciej Falkiewicz, Naoya Takeishi, Alexandros Kalousis</author><pubDate>Fri, 28 Jun 2024 15:30:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19948v1</guid></item><item><title>Latent variable model for high-dimensional point process with structured missingness</title><link>http://arxiv.org/abs/2402.05758v2</link><description>Longitudinal data are important in numerous fields, such as healthcare,sociology and seismology, but real-world datasets present notable challengesfor practitioners because they can be high-dimensional, contain structuredmissingness patterns, and measurement time points can be governed by an unknownstochastic process. While various solutions have been suggested, the majorityof them have been designed to account for only one of these challenges. In thiswork, we propose a flexible and efficient latent-variable model that is capableof addressing all these limitations. Our approach utilizes Gaussian processesto capture temporal correlations between samples and their associatedmissingness masks as well as to model the underlying point process. Weconstruct our model as a variational autoencoder together with deep neuralnetwork parameterised encoder and decoder models, and develop a scalableamortised variational inference approach for efficient model training. Wedemonstrate competitive performance using both simulated and real datasets.</description><author>Maksim Sinelnikov, Manuel Haussmann, Harri Lähdesmäki</author><pubDate>Fri, 28 Jun 2024 15:27:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05758v2</guid></item><item><title>Catastrophic-risk-aware reinforcement learning with extreme-value-theory-based policy gradients</title><link>http://arxiv.org/abs/2406.15612v2</link><description>This paper tackles the problem of mitigating catastrophic risk (which is riskwith very low frequency but very high severity) in the context of a sequentialdecision making process. This problem is particularly challenging due to thescarcity of observations in the far tail of the distribution of cumulativecosts (negative rewards). A policy gradient algorithm is developed, that wecall POTPG. It is based on approximations of the tail risk derived from extremevalue theory. Numerical experiments highlight the out-performance of our methodover common benchmarks, relying on the empirical distribution. An applicationto financial risk management, more precisely to the dynamic hedging of afinancial option, is presented.</description><author>Parisa Davar, Frédéric Godin, Jose Garrido</author><pubDate>Fri, 28 Jun 2024 15:23:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15612v2</guid></item><item><title>Impact of Initialization on Intra-subject Pediatric Brain MR Image Registration: A Comparative Analysis between SyN ANTs and Deep Learning-Based Approaches</title><link>http://arxiv.org/abs/2406.19943v1</link><description>This study evaluates the performance of conventional SyN ANTs andlearning-based registration methods in the context of pediatric neuroimaging,specifically focusing on intrasubject deformable registration. The comparisoninvolves three approaches: without (NR), with rigid (RR), and with rigid andaffine (RAR) initializations. In addition to initialization, performances areevaluated in terms of accuracy, speed, and the impact of age intervals and sexper pair. Data consists of the publicly available MRI scans from the CalgaryPreschool dataset, which includes 63 children aged 2-7 years, allowing for 431registration pairs. We implemented the unsupervised DL framework with a U-Netarchitecture using DeepReg and it was 5-fold cross-validated. Evaluationincludes Dice scores for tissue segmentation from 18 smaller regions obtainedby SynthSeg, analysis of log Jacobian determinants, and registration pro-ratedtraining and inference times. Learning-based approaches, with or without linearinitializations, exhibit slight superiority over SyN ANTs in terms of Dicescores. Indeed, DL-based implementations with RR and RAR initializationssignificantly outperform SyN ANTs. Both SyN ANTs and DL-based registrationinvolve parameter optimization, but the choice between these methods depends onthe scale of registration: network-based for broader coverage or SyN ANTs forspecific structures. Both methods face challenges with larger age intervals dueto greater growth changes. The main takeaway is that while DL-based methodsshow promise with faster and more accurate registrations, SyN ANTs remainsrobust and generalizable without the need for extensive training, highlightingthe importance of method selection based on specific registration needs in thepediatric context. Our code is available athttps://github.com/neuropoly/pediatric-DL-registration</description><author>Andjela Dimitrijevic, Vincent Noblet, Benjamin De Leener</author><pubDate>Fri, 28 Jun 2024 15:22:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19943v1</guid></item><item><title>GRACE: Graph-Regularized Attentive Convolutional Entanglement with Laplacian Smoothing for Robust DeepFake Video Detection</title><link>http://arxiv.org/abs/2406.19941v1</link><description>As DeepFake video manipulation techniques escalate, posing profound threats,the urgent need to develop efficient detection strategies is underscored.However, one particular issue lies with facial images being mis-detected, oftenoriginating from degraded videos or adversarial attacks, leading to unexpectedtemporal artifacts that can undermine the efficacy of DeepFake video detectiontechniques. This paper introduces a novel method for robust DeepFake videodetection, harnessing the power of the proposed Graph-Regularized AttentiveConvolutional Entanglement (GRACE) based on the graph convolutional networkwith graph Laplacian to address the aforementioned challenges. First,conventional Convolution Neural Networks are deployed to perform spatiotemporalfeatures for the entire video. Then, the spatial and temporal features aremutually entangled by constructing a graph with sparse constraint, enforcingessential features of valid face images in the noisy face sequences remaining,thus augmenting stability and performance for DeepFake video detection.Furthermore, the Graph Laplacian prior is proposed in the graph convolutionalnetwork to remove the noise pattern in the feature space to further improve theperformance. Comprehensive experiments are conducted to illustrate that ourproposed method delivers state-of-the-art performance in DeepFake videodetection under noisy face sequences. The source code is available athttps://github.com/ming053l/GRACE.</description><author>Chih-Chung Hsu, Shao-Ning Chen, Mei-Hsuan Wu, Yi-Fang Wang, Chia-Ming Lee, Yi-Shiuan Chou</author><pubDate>Fri, 28 Jun 2024 15:17:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19941v1</guid></item><item><title>Modeling State Shifting via Local-Global Distillation for Event-Frame Gaze Tracking</title><link>http://arxiv.org/abs/2404.00548v2</link><description>This paper tackles the problem of passive gaze estimation using both eventand frame data. Considering the inherently different physiological structures,it is intractable to accurately estimate gaze purely based on a given state.Thus, we reformulate gaze estimation as the quantification of the stateshifting from the current state to several prior registered anchor states.Specifically, we propose a two-stage learning-based gaze estimation frameworkthat divides the whole gaze estimation process into a coarse-to-fine approachinvolving anchor state selection and final gaze location. Moreover, to improvethe generalization ability, instead of learning a large gaze estimation networkdirectly, we align a group of local experts with a student network, where anovel denoising distillation algorithm is introduced to utilize denoisingdiffusion techniques to iteratively remove inherent noise in event data.Extensive experiments demonstrate the effectiveness of the proposed method,which surpasses state-of-the-art methods by a large margin of 15$\%$. The codewill be publicly available athttps://github.com/jdjdli/Denoise_distill_EF_gazetracker.</description><author>Jiading Li, Zhiyu Zhu, Jinhui Hou, Junhui Hou, Jinjian Wu</author><pubDate>Fri, 28 Jun 2024 15:13:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.00548v2</guid></item><item><title>Deep Learning of Multivariate Extremes via a Geometric Representation</title><link>http://arxiv.org/abs/2406.19936v1</link><description>The study of geometric extremes, where extremal dependence properties areinferred from the deterministic limiting shapes of scaled sample clouds,provides an exciting approach to modelling the extremes of multivariate data.These shapes, termed limit sets, link together several popular extremaldependence modelling frameworks. Although the geometric approach is becoming anincreasingly popular modelling tool, current inference techniques are limitedto a low dimensional setting (d &lt; 4), and generally require rigid modellingassumptions. In this work, we propose a range of novel theoretical results toaid with the implementation of the geometric extremes framework and introducethe first approach to modelling limit sets using deep learning. By leveragingneural networks, we construct asymptotically-justified yet flexiblesemi-parametric models for extremal dependence of high-dimensional data. Weshowcase the efficacy of our deep approach by modelling the complex extremaldependencies between meteorological and oceanographic variables in the NorthSea off the coast of the UK.</description><author>Callum J. R. Murphy-Barltrop, Reetam Majumder, Jordan Richards</author><pubDate>Fri, 28 Jun 2024 15:05:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19936v1</guid></item><item><title>From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis</title><link>http://arxiv.org/abs/2406.19934v1</link><description>We explore multi-step reasoning in vision-language models (VLMs). The problemis challenging, as reasoning data consisting of multiple steps of visual andlanguage processing are barely available. To overcome the challenge, we firstintroduce a least-to-most visual reasoning paradigm, which interleaves steps ofdecomposing a question into sub-questions and invoking external tools forresolving sub-questions. Based on the paradigm, we further propose a novel datasynthesis approach that can automatically create questions and multi-stepreasoning paths for an image in a bottom-up manner. Our approach divides thecomplex synthesis task into a few simple sub-tasks, and (almost entirely)relies on open-sourced models to accomplish the sub-tasks. Therefore, theentire synthesis process is reproducible and cost-efficient, and thesynthesized data is quality guaranteed. With the approach, we construct $50$kvisual reasoning examples. Then, we develop a visual reasoner throughsupervised fine-tuning, which is capable of generally enhancing the reasoningabilities of a wide range of existing VLMs in a plug-and-play fashion.Extensive experiments indicate that the visual reasoner can consistently andsignificantly improve four VLMs on four VQA benchmarks. Our code and datasetare available at https://github.com/steven-ccq/VisualReasoner.</description><author>Chuanqi Cheng, Jian Guan, Wei Wu, Rui Yan</author><pubDate>Fri, 28 Jun 2024 15:04:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19934v1</guid></item><item><title>Tracking Object Positions in Reinforcement Learning: A Metric for Keypoint Detection (extended version)</title><link>http://arxiv.org/abs/2312.00592v2</link><description>Reinforcement learning (RL) for robot control typically requires a detailedrepresentation of the environment state, including information abouttask-relevant objects not directly measurable. Keypoint detectors, such asspatial autoencoders (SAEs), are a common approach to extracting alow-dimensional representation from high-dimensional image data. SAEs aim atspatial features such as object positions, which are often usefulrepresentations in robotic RL. However, whether an SAE is actually able totrack objects in the scene and thus yields a spatial state representation wellsuited for RL tasks has rarely been examined due to a lack of establishedmetrics. In this paper, we propose to assess the performance of an SAE instanceby measuring how well keypoints track ground truth objects in images. Wepresent a computationally lightweight metric and use it to evaluate commonbaseline SAE architectures on image data from a simulated robot task. We findthat common SAEs differ substantially in their spatial extraction capability.Furthermore, we validate that SAEs that perform well in our metric achievesuperior performance when used in downstream RL. Thus, our metric is aneffective and lightweight indicator of RL performance before executingexpensive RL training. Building on these insights, we identify three keymodifications of SAE architectures to improve tracking performance. We make ourcode available at anonymous.4open.science/r/sae-rl.</description><author>Emma Cramer, Jonas Reiher, Sebastian Trimpe</author><pubDate>Fri, 28 Jun 2024 15:02:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00592v2</guid></item><item><title>Decoupling General and Personalized Knowledge in Federated Learning via Additive and Low-Rank Decomposition</title><link>http://arxiv.org/abs/2406.19931v1</link><description>To address data heterogeneity, the key strategy of Personalized FederatedLearning (PFL) is to decouple general knowledge (shared among clients) andclient-specific knowledge, as the latter can have a negative impact oncollaboration if not removed. Existing PFL methods primarily adopt a parameterpartitioning approach, where the parameters of a model are designated as one oftwo types: parameters shared with other clients to extract general knowledgeand parameters retained locally to learn client-specific knowledge. However, asthese two types of parameters are put together like a jigsaw puzzle into asingle model during the training process, each parameter may simultaneouslyabsorb both general and client-specific knowledge, thus struggling to separatethe two types of knowledge effectively. In this paper, we introduce FedDecomp,a simple but effective PFL paradigm that employs parameter additivedecomposition to address this issue. Instead of assigning each parameter of amodel as either a shared or personalized one, FedDecomp decomposes eachparameter into the sum of two parameters: a shared one and a personalized one,thus achieving a more thorough decoupling of shared and personalized knowledgecompared to the parameter partitioning method. In addition, as we find thatretaining local knowledge of specific clients requires much lower modelcapacity compared with general knowledge across all clients, we let the matrixcontaining personalized parameters be low rank during the training process.Moreover, a new alternating training strategy is proposed to further improvethe performance. Experimental results across multiple datasets and varyingdegrees of data heterogeneity demonstrate that FedDecomp outperformsstate-of-the-art methods up to 4.9\%.</description><author>Xinghao Wu, Xuefeng Liu, Jianwei Niu, Haolin Wang, Shaojie Tang, Guogang Zhu, Hao Su</author><pubDate>Fri, 28 Jun 2024 15:01:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19931v1</guid></item><item><title>Interactive Topic Models with Optimal Transport</title><link>http://arxiv.org/abs/2406.19928v1</link><description>Topic models are widely used to analyze document collections. While they arevaluable for discovering latent topics in a corpus when analysts are unfamiliarwith the corpus, analysts also commonly start with an understanding of thecontent present in a corpus. This may be through categories obtained from aninitial pass over the corpus or a desire to analyze the corpus through apredefined set of categories derived from a high level theoretical framework(e.g. political ideology). In these scenarios analysts desire a topic modelingapproach which incorporates their understanding of the corpus while supportingvarious forms of interaction with the model. In this work, we present EdTM, asan approach for label name supervised topic modeling. EdTM models topicmodeling as an assignment problem while leveraging LM/LLM based document-topicaffinities and using optimal transport for making globally coherenttopic-assignments. In experiments, we show the efficacy of our frameworkcompared to few-shot LLM classifiers, and topic models based on clustering andLDA. Further, we show EdTM's ability to incorporate various forms of analystfeedback and while remaining robust to noisy analyst inputs.</description><author>Garima Dhanania, Sheshera Mysore, Chau Minh Pham, Mohit Iyyer, Hamed Zamani, Andrew McCallum</author><pubDate>Fri, 28 Jun 2024 14:57:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19928v1</guid></item><item><title>Parallax-tolerant Image Stitching via Segmentation-guided Multi-homography Warping</title><link>http://arxiv.org/abs/2406.19922v1</link><description>Large parallax between images is an intractable issue in image stitching.Various warping-based methods are proposed to address it, yet the results areunsatisfactory. In this paper, we propose a novel image stitching method usingmulti-homography warping guided by image segmentation. Specifically, weleverage the Segment Anything Model to segment the target image into numerouscontents and partition the feature points into multiple subsets via theenergy-based multi-homography fitting algorithm. The multiple subsets offeature points are used to calculate the corresponding multiple homographies.For each segmented content in the overlapping region, we select itsbest-fitting homography with the lowest photometric error. For each segmentedcontent in the non-overlapping region, we calculate a weighted combination ofthe linearized homographies. Finally, the target image is warped via thebest-fitting homographies to align with the reference image, and the finalpanorama is generated via linear blending. Comprehensive experimental resultson the public datasets demonstrate that our method provides the best alignmentaccuracy by a large margin, compared with the state-of-the-art methods. Thesource code is available at https://github.com/tlliao/multi-homo-warp.</description><author>Tianli Liao, Ce Wang, Lei Li, Guangen Liu, Nan Li</author><pubDate>Fri, 28 Jun 2024 14:51:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19922v1</guid></item><item><title>The G-invariant graph Laplacian</title><link>http://arxiv.org/abs/2303.17001v4</link><description>Graph Laplacian based algorithms for data lying on a manifold have beenproven effective for tasks such as dimensionality reduction, clustering, anddenoising. In this work, we consider data sets whose data points lie on amanifold that is closed under the action of a known unitary matrix Lie group G.We propose to construct the graph Laplacian by incorporating the distancesbetween all the pairs of points generated by the action of G on the data set.We deem the latter construction the ``G-invariant Graph Laplacian'' (G-GL). Weshow that the G-GL converges to the Laplace-Beltrami operator on the datamanifold, while enjoying a significantly improved convergence rate compared tothe standard graph Laplacian which only utilizes the distances between thepoints in the given data set. Furthermore, we show that the G-GL admits a setof eigenfunctions that have the form of certain products between the groupelements and eigenvectors of certain matrices, which can be estimated from thedata efficiently using FFT-type algorithms. We demonstrate our construction andits advantages on the problem of filtering data on a noisy manifold closedunder the action of the special unitary group SU(2).</description><author>Eitan Rosen, Paulina Hoyos, Xiuyuan Cheng, Joe Kileel, Yoel Shkolnisky</author><pubDate>Fri, 28 Jun 2024 14:40:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.17001v4</guid></item><item><title>Learning Decision Policies with Instrumental Variables through Double Machine Learning</title><link>http://arxiv.org/abs/2405.08498v3</link><description>A common issue in learning decision-making policies in data-rich settings isspurious correlations in the offline dataset, which can be caused by hiddenconfounders. Instrumental variable (IV) regression, which utilises a keyunconfounded variable known as the instrument, is a standard technique forlearning causal relationships between confounded action, outcome, and contextvariables. Most recent IV regression algorithms use a two-stage approach, wherea deep neural network (DNN) estimator learnt in the first stage is directlyplugged into the second stage, in which another DNN is used to estimate thecausal effect. Naively plugging the estimator can cause heavy bias in thesecond stage, especially when regularisation bias is present in the first stageestimator. We propose DML-IV, a non-linear IV regression method that reducesthe bias in two-stage IV regressions and effectively learns high-performingpolicies. We derive a novel learning objective to reduce bias and design theDML-IV algorithm following the double/debiased machine learning (DML)framework. The learnt DML-IV estimator has strong convergence rate and$O(N^{-1/2})$ suboptimality guarantees that match those when the dataset isunconfounded. DML-IV outperforms state-of-the-art IV regression methods on IVregression benchmarks and learns high-performing policies in the presence ofinstruments.</description><author>Daqian Shao, Ashkan Soleymani, Francesco Quinzan, Marta Kwiatkowska</author><pubDate>Fri, 28 Jun 2024 14:31:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.08498v3</guid></item><item><title>NoteChat: A Dataset of Synthetic Doctor-Patient Conversations Conditioned on Clinical Notes</title><link>http://arxiv.org/abs/2310.15959v3</link><description>We introduce NoteChat, a novel cooperative multi-agent framework leveragingLarge Language Models (LLMs) to generate patient-physician dialogues. NoteChatembodies the principle that an ensemble of role-specific LLMs, throughstructured role-play and strategic prompting, can perform their assigned rolesmore effectively. The synergy among these role-playing LLMs results in acohesive and efficient dialogue generation. Evaluation on MTS-dialogue, abenchmark dataset for patient-physician dialogues-note pairs, shows that modelstrained with the augmented synthetic patient-physician dialogues by NoteChatoutperforms other state-of-the-art models for generating clinical notes. Ourcomprehensive automatic and human evaluation demonstrates that NoteChatsubstantially surpasses state-of-the-art models like ChatGPT and GPT-4 up to22.78% by domain experts in generating superior synthetic patient-physiciandialogues based on clinical notes. NoteChat has the potential to engagepatients directly and help clinical documentation, a leading cause of physicianburnout.</description><author>Junda Wang, Zonghai Yao, Zhichao Yang, Huixue Zhou, Rumeng Li, Xun Wang, Yucheng Xu, Hong Yu</author><pubDate>Fri, 28 Jun 2024 14:28:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.15959v3</guid></item><item><title>MatText: Do Language Models Need More than Text &amp; Scale for Materials Modeling?</title><link>http://arxiv.org/abs/2406.17295v2</link><description>Effectively representing materials as text has the potential to leverage thevast advancements of large language models (LLMs) for discovering newmaterials. While LLMs have shown remarkable success in various domains, theirapplication to materials science remains underexplored. A fundamental challengeis the lack of understanding of how to best utilize text-based representationsfor materials modeling. This challenge is further compounded by the absence ofa comprehensive benchmark to rigorously evaluate the capabilities andlimitations of these text representations in capturing the complexity ofmaterial systems. To address this gap, we propose MatText, a suite ofbenchmarking tools and datasets designed to systematically evaluate theperformance of language models in modeling materials. MatText encompasses ninedistinct text-based representations for material systems, including severalnovel representations. Each representation incorporates unique inductive biasesthat capture relevant information and integrate prior physical knowledge aboutmaterials. Additionally, MatText provides essential tools for training andbenchmarking the performance of language models in the context of materialsscience. These tools include standardized dataset splits for eachrepresentation, probes for evaluating sensitivity to geometric factors, andtools for seamlessly converting crystal structures into text. Using MatText, weconduct an extensive analysis of the capabilities of language models inmodeling materials. Our findings reveal that current language modelsconsistently struggle to capture the geometric information crucial formaterials modeling across all representations. Instead, these models tend toleverage local information, which is emphasized in some of our novelrepresentations. Our analysis underscores MatText's ability to revealshortcomings of text-based methods for materials design.</description><author>Nawaf Alampara, Santiago Miret, Kevin Maik Jablonka</author><pubDate>Fri, 28 Jun 2024 14:28:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.17295v2</guid></item><item><title>The Intelligible and Effective Graph Neural Additive Networks</title><link>http://arxiv.org/abs/2406.01317v2</link><description>Graph Neural Networks (GNNs) have emerged as the predominant approach forlearning over graph-structured data. However, most GNNs operate as black-boxmodels and require post-hoc explanations, which may not suffice in high-stakesscenarios where transparency is crucial. In this paper, we present a GNN thatis interpretable by design. Our model, Graph Neural Additive Network (GNAN), isa novel extension of the interpretable class of Generalized Additive Models,and can be visualized and fully understood by humans. GNAN is designed to befully interpretable, allowing both global and local explanations at the featureand graph levels through direct visualization of the model. Thesevisualizations describe the exact way the model uses the relationships betweenthe target variable, the features, and the graph. We demonstrate theintelligibility of GNANs in a series of examples on different tasks anddatasets. In addition, we show that the accuracy of GNAN is on par withblack-box GNNs, making it suitable for critical applications where transparencyis essential, alongside high accuracy.</description><author>Maya Bechler-Speicher, Amir Globerson, Ran Gilad-Bachrach</author><pubDate>Fri, 28 Jun 2024 14:27:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.01317v2</guid></item><item><title>JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning and Professional Question Answering Capability</title><link>http://arxiv.org/abs/2402.17887v4</link><description>Large Language Models (LLMs) have demonstrated a remarkable potential inmedical knowledge acquisition and question-answering. However, LLMs canpotentially hallucinate and yield factually incorrect outcomes, even withdomain-specific pretraining. Previously, retrieval augmented generation (RAG)has limited success in addressing hallucinations. Unlike previous methods inRAG where the retrieval model was trained separately from the LLM, we introduceJMLR (for Jointly trains LLM and information Retrieval) during the fine-tuningphase. The synchronized training mechanism enhances JMLR's ability to retrieveclinical guidelines and leverage medical knowledge to reason and answerquestions and reduces the demand for computational resources. We evaluated JMLRon the important medical question-answering application. Our experimentalresults demonstrate that JMLR-13B (70.5%) outperforms a previousstate-of-the-art open-source model using conventional pre-training andfine-tuning Meditron-70B (68.9%) and Llama2-13B with RAG (67.7%) on a medicalquestion-answering dataset. Comprehensive evaluations reveal JMLR-13B enhancesreasoning quality and reduces hallucinations better than Claude3-Opus.Additionally, JMLR-13B (148 GPU hours) also trains much faster thanMeditron-70B (42630 GPU hours). Through this work, we provide a new andefficient knowledge enhancement method for healthcare, demonstrating thepotential of integrating retrieval and LLM training for medicalquestion-answering systems.</description><author>Junda Wang, Zhichao Yang, Zonghai Yao, Hong Yu</author><pubDate>Fri, 28 Jun 2024 14:23:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17887v4</guid></item><item><title>Solving Token Gradient Conflict in Mixture-of-Experts for Large Vision-Language Model</title><link>http://arxiv.org/abs/2406.19905v1</link><description>The Mixture-of-Experts (MoE) has gained increasing attention in the study ofLarge Vision-Language Models (LVLMs). It uses a sparse model to replace thedense model, achieving comparable performance while activating fewer parametersduring inference, thus significantly reducing the inference cost. Existing MoEmethods in LVLMs encourage different experts to handle different tokens, andthus they employ a router to predict the routing for each token. However, thepredictions are based solely on sample features and do not truly reveal theoptimization direction of tokens. This can lead to severe optimizationconflicts between different tokens within an expert. To address this problem,this paper proposes a novel method based on token-level gradient analysis.Specifically, we first use token-level gradients to identify conflicting tokensin experts. Then, we add a specialized loss tailored to eliminate conflictsamong tokens within each expert. Our method can serve as a plug-in for diverseLarge Vision-Language Models, and extensive experimental results demonstratethe effectiveness of our method. The code will be publicly available athttps://github.com/longrongyang/STGC.</description><author>Longrong Yang, Dong Sheng, Chaoxiang Cai, Fan Yang, Size Li, Di Zhang, Xi Li</author><pubDate>Fri, 28 Jun 2024 14:20:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19905v1</guid></item><item><title>LatentExplainer: Explaining Latent Representations in Deep Generative Models with Multi-modal Foundation Models</title><link>http://arxiv.org/abs/2406.14862v3</link><description>Deep generative models like VAEs and diffusion models have advanced variousgeneration tasks by leveraging latent variables to learn data distributions andgenerate high-quality samples. Despite the field of explainable AI makingstrides in interpreting machine learning models, understanding latent variablesin generative models remains challenging. This paper introducesLatentExplainer, a framework for automatically generating semanticallymeaningful explanations of latent variables in deep generative models.LatentExplainer tackles three main challenges: inferring the meaning of latentvariables, aligning explanations with inductive biases, and handling varyingdegrees of explainability. By perturbing latent variables and interpretingchanges in generated data, the framework provides a systematic approach tounderstanding and controlling the data generation process, enhancing thetransparency and interpretability of deep generative models. We evaluate ourproposed method on several real-world and synthetic datasets, and the resultsdemonstrate superior performance in generating high-quality explanations oflatent variables.</description><author>Mengdan Zhu, Raasikh Kanjiani, Jiahui Lu, Andrew Choi, Qirui Ye, Liang Zhao</author><pubDate>Fri, 28 Jun 2024 14:19:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.14862v3</guid></item><item><title>Towards Learning Stochastic Population Models by Gradient Descent</title><link>http://arxiv.org/abs/2404.07049v2</link><description>Increasing effort is put into the development of methods for learningmechanistic models from data. This task entails not only the accurateestimation of parameters but also a suitable model structure. Recent work onthe discovery of dynamical systems formulates this problem as a linear equationsystem. Here, we explore several simulation-based optimization approaches,which allow much greater freedom in the objective formulation and weakerconditions on the available data. We show that even for relatively smallstochastic population models, simultaneous estimation of parameters andstructure poses major challenges for optimization procedures. Particularly, weinvestigate the application of the local stochastic gradient descent method,commonly used for training machine learning models. We demonstrate accurateestimation of models but find that enforcing the inference of parsimonious,interpretable models drastically increases the difficulty. We give an outlookon how this challenge can be overcome.</description><author>Justin N. Kreikemeyer, Philipp Andelfinger, Adelinde M. Uhrmacher</author><pubDate>Fri, 28 Jun 2024 14:14:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.07049v2</guid></item><item><title>`Just One More Sensor is Enough' -- Iterative Water Leak Localization with Physical Simulation and a Small Number of Pressure Sensors</title><link>http://arxiv.org/abs/2406.19900v1</link><description>In this article, we propose an approach to leak localisation in a complexwater delivery grid with the use of data from physical simulation (e.g. EPANETsoftware). This task is usually achieved by a network of multiple waterpressure sensors and analysis of the so-called sensitivity matrix of pressuredifferences between the network's simulated data and actual data of the networkaffected by the leak. However, most algorithms using this approach require asignificant number of pressure sensors -- a condition that is not easy tofulfil in the case of many less equipped networks. Therefore, we answer thequestion of whether leak localisation is possible by utilising very few sensorsbut having the ability to relocate one of them. Our algorithm is based onphysical simulations (EPANET software) and an iterative scheme for mobilesensor relocation. The experiments show that the proposed system can equalisethe low number of sensors with adjustments made for their positioning, giving avery good approximation of leak's position both in simulated cases andreal-life example taken from BattLeDIM competition L-Town data.</description><author>Michał Cholewa, Michał Romaszewski, Przemysław Głomb, Katarzyna Kołodziej, Michał Gorawski, Jakub Koral, Wojciech Koral, Andrzej Madej, Kryspin Musioł</author><pubDate>Fri, 28 Jun 2024 14:10:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.19900v1</guid></item></channel></rss>