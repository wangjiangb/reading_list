<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Wed, 07 Jun 2023 06:01:10 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>SAM3D: Segment Anything in 3D Scenes</title><link>http://arxiv.org/abs/2306.03908v1</link><description>In this work, we propose SAM3D, a novel framework that is able to predictmasks in 3D point clouds by leveraging the Segment-Anything Model (SAM) in RGBimages without further training or finetuning. For a point cloud of a 3D scenewith posed RGB images, we first predict segmentation masks of RGB images withSAM, and then project the 2D masks into the 3D points. Later, we merge the 3Dmasks iteratively with a bottom-up merging approach. At each step, we merge thepoint cloud masks of two adjacent frames with the bidirectional mergingapproach. In this way, the 3D masks predicted from different frames aregradually merged into the 3D masks of the whole 3D scene. Finally, we canoptionally ensemble the result from our SAM3D with the over-segmentationresults based on the geometric information of the 3D scenes. Our approach isexperimented with ScanNet dataset and qualitative results demonstrate that ourSAM3D achieves reasonable and fine-grained 3D segmentation results without anytraining or finetuning of SAM.</description><author>Yunhan Yang, Xiaoyang Wu, Tong He, Hengshuang Zhao, Xihui Liu</author><pubDate>Tue, 06 Jun 2023 18:59:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03908v1</guid></item><item><title>CL-UZH at SemEval-2023 Task 10: Sexism Detection through Incremental Fine-Tuning and Multi-Task Learning with Label Descriptions</title><link>http://arxiv.org/abs/2306.03907v1</link><description>The widespread popularity of social media has led to an increase in hateful,abusive, and sexist language, motivating methods for the automatic detection ofsuch phenomena. The goal of the SemEval shared task \textit{Towards ExplainableDetection of Online Sexism} (EDOS 2023) is to detect sexism in English socialmedia posts (subtask A), and to categorize such posts into four coarse-grainedsexism categories (subtask B), and eleven fine-grained subcategories (subtaskC). In this paper, we present our submitted systems for all three subtasks,based on a multi-task model that has been fine-tuned on a range of relatedtasks and datasets before being fine-tuned on the specific EDOS subtasks. Weimplement multi-task learning by formulating each task as binary pairwise textclassification, where the dataset and label descriptions are given along withthe input text. The results show clear improvements over a fine-tunedDeBERTa-V3 serving as a baseline leading to $F_1$-scores of 85.9\% in subtask A(rank 13/84), 64.8\% in subtask B (rank 19/69), and 44.9\% in subtask C(26/63).</description><author>Janis Goldzycher</author><pubDate>Tue, 06 Jun 2023 18:59:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03907v1</guid></item><item><title>Utterance Classification with Logical Neural Network: Explainable AI for Mental Disorder Diagnosis</title><link>http://arxiv.org/abs/2306.03902v1</link><description>In response to the global challenge of mental health problems, we proposes aLogical Neural Network (LNN) based Neuro-Symbolic AI method for the diagnosisof mental disorders. Due to the lack of effective therapy coverage for mentaldisorders, there is a need for an AI solution that can assist therapists withthe diagnosis. However, current Neural Network models lack explainability andmay not be trusted by therapists. The LNN is a Recurrent Neural Networkarchitecture that combines the learning capabilities of neural networks withthe reasoning capabilities of classical logic-based AI. The proposed systemuses input predicates from clinical interviews to output a mental disorderclass, and different predicate pruning techniques are used to achievescalability and higher scores. In addition, we provide an insight extractionmethod to aid therapists with their diagnosis. The proposed system addressesthe lack of explainability of current Neural Network models and provides a moretrustworthy solution for mental disorder diagnosis.</description><author>Yeldar Toleubay, Don Joven Agravante, Daiki Kimura, Baihan Lin, Djallel Bouneffouf, Michiaki Tatsubori</author><pubDate>Tue, 06 Jun 2023 18:58:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03902v1</guid></item><item><title>ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory</title><link>http://arxiv.org/abs/2306.03901v1</link><description>Large language models (LLMs) with memory are computationally universal.However, mainstream LLMs are not taking full advantage of memory, and thedesigns are heavily influenced by biological brains. Due to their approximatenature and proneness to the accumulation of errors, conventional neural memorymechanisms cannot support LLMs to simulate complex reasoning. In this paper, weseek inspiration from modern computer architectures to augment LLMs withsymbolic memory for complex multi-hop reasoning. Such a symbolic memoryframework is instantiated as an LLM and a set of SQL databases, where the LLMgenerates SQL instructions to manipulate the SQL databases. We validate theeffectiveness of the proposed memory framework on a synthetic dataset requiringcomplex reasoning. The project website is available athttps://chatdatabase.github.io/ .</description><author>Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, Hang Zhao</author><pubDate>Tue, 06 Jun 2023 18:58:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03901v1</guid></item><item><title>Model Spider: Learning to Rank Pre-Trained Models Efficiently</title><link>http://arxiv.org/abs/2306.03900v1</link><description>Figuring out which Pre-Trained Model (PTM) from a model zoo fits the targettask is essential to take advantage of plentiful model resources. With theavailability of numerous heterogeneous PTMs from diverse fields, efficientlyselecting the most suitable PTM is challenging due to the time-consuming costsof carrying out forward or backward passes over all PTMs. In this paper, wepropose Model Spider, which tokenizes both PTMs and tasks by summarizing theircharacteristics into vectors to enable efficient PTM selection. By leveragingthe approximated performance of PTMs on a separate set of training tasks, ModelSpider learns to construct tokens and measure the fitness score between amodel-task pair via their tokens. The ability to rank relevant PTMs higher thanothers generalizes to new tasks. With the top-ranked PTM candidates, we furtherlearn to enrich task tokens with their PTM-specific semantics to re-rank thePTMs for better selection. Model Spider balances efficiency and selectionability, making PTM selection like a spider preying on a web. Model Spiderdemonstrates promising performance in various configurations of model zoos.</description><author>Yi-Kai Zhang, Ting-Ji Huang, Yao-Xiang Ding, De-Chuan Zhan, Han-Jia Ye</author><pubDate>Tue, 06 Jun 2023 18:58:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03900v1</guid></item><item><title>Towards Label-free Scene Understanding by Vision Foundation Models</title><link>http://arxiv.org/abs/2306.03899v1</link><description>Vision foundation models such as Contrastive Vision-Language Pre-training(CLIP) and Segment Anything (SAM) have demonstrated impressive zero-shotperformance on image classification and segmentation tasks. However, theincorporation of CLIP and SAM for label-free scene understanding has yet to beexplored. In this paper, we investigate the potential of vision foundationmodels in enabling networks to comprehend 2D and 3D worlds without labelleddata. The primary challenge lies in effectively supervising networks underextremely noisy pseudo labels, which are generated by CLIP and furtherexacerbated during the propagation from the 2D to the 3D domain. To tacklethese challenges, we propose a novel Cross-modality Noisy Supervision (CNS)method that leverages the strengths of CLIP and SAM to supervise 2D and 3Dnetworks simultaneously. In particular, we introduce a prediction consistencyregularization to co-train 2D and 3D networks, then further impose thenetworks' latent space consistency using the SAM's robust featurerepresentation. Experiments conducted on diverse indoor and outdoor datasetsdemonstrate the superior performance of our method in understanding 2D and 3Dopen environments. Our 2D and 3D network achieves label-free semanticsegmentation with 28.4% and 33.5% mIoU on ScanNet, improving 4.7% and 7.9%,respectively. And for nuScenes dataset, our performance is 26.8% with animprovement of 6%. Code will be released(https://github.com/runnanchen/Label-Free-Scene-Understanding).</description><author>Runnan Chen, Youquan Liu, Lingdong Kong, Nenglun Chen, Xinge Zhu, Yuexin Ma, Tongliang Liu, Wenping Wang</author><pubDate>Tue, 06 Jun 2023 18:57:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03899v1</guid></item><item><title>blob loss: instance imbalance aware loss functions for semantic segmentation</title><link>http://arxiv.org/abs/2205.08209v3</link><description>Deep convolutional neural networks (CNN) have proven to be remarkablyeffective in semantic segmentation tasks. Most popular loss functions wereintroduced targeting improved volumetric scores, such as the Dice coefficient(DSC). By design, DSC can tackle class imbalance, however, it does notrecognize instance imbalance within a class. As a result, a large foregroundinstance can dominate minor instances and still produce a satisfactory DSC.Nevertheless, detecting tiny instances is crucial for many applications, suchas disease monitoring. For example, it is imperative to locate and surveilsmall-scale lesions in the follow-up of multiple sclerosis patients. We proposea novel family of loss functions, \emph{blob loss}, primarily aimed atmaximizing instance-level detection metrics, such as F1 score and sensitivity.\emph{Blob loss} is designed for semantic segmentation problems where detectingmultiple instances matters. We extensively evaluate a DSC-based \emph{blobloss} in five complex 3D semantic segmentation tasks featuring pronouncedinstance heterogeneity in terms of texture and morphology. Compared to softDice loss, we achieve 5% improvement for MS lesions, 3% improvement for livertumor, and an average 2% improvement for microscopy segmentation tasksconsidering F1 score.</description><author>Florian Kofler, Suprosanna Shit, Ivan Ezhov, Lucas Fidon, Izabela Horvath, Rami Al-Maskari, Hongwei Li, Harsharan Bhatia, Timo Loehr, Marie Piraud, Ali Erturk, Jan Kirschke, Jan C. Peeken, Tom Vercauteren, Claus Zimmer, Benedikt Wiestler, Bjoern Menze</author><pubDate>Tue, 06 Jun 2023 18:54:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.08209v3</guid></item><item><title>A Watermark for Large Language Models</title><link>http://arxiv.org/abs/2301.10226v3</link><description>Potential harms of large language models can be mitigated by watermarkingmodel output, i.e., embedding signals into generated text that are invisible tohumans but algorithmically detectable from a short span of tokens. We propose awatermarking framework for proprietary language models. The watermark can beembedded with negligible impact on text quality, and can be detected using anefficient open-source algorithm without access to the language model API orparameters. The watermark works by selecting a randomized set of "green" tokensbefore a word is generated, and then softly promoting use of green tokensduring sampling. We propose a statistical test for detecting the watermark withinterpretable p-values, and derive an information-theoretic framework foranalyzing the sensitivity of the watermark. We test the watermark using amulti-billion parameter model from the Open Pretrained Transformer (OPT)family, and discuss robustness and security.</description><author>John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, Tom Goldstein</author><pubDate>Tue, 06 Jun 2023 18:50:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.10226v3</guid></item><item><title>Fast Context Adaptation in Cost-Aware Continual Learning</title><link>http://arxiv.org/abs/2306.03887v1</link><description>In the past few years, DRL has become a valuable solution to automaticallylearn efficient resource management strategies in complex networks withtime-varying statistics. However, the increased complexity of 5G and Beyondnetworks requires correspondingly more complex learning agents and the learningprocess itself might end up competing with users for communication andcomputational resources. This creates friction: on the one hand, the learningprocess needs resources to quickly convergence to an effective strategy; on theother hand, the learning process needs to be efficient, i.e., take as fewresources as possible from the user's data plane, so as not to throttle users'QoS. In this paper, we investigate this trade-off and propose a dynamicstrategy to balance the resources assigned to the data plane and those reservedfor learning. With the proposed approach, a learning agent can quickly convergeto an efficient resource allocation strategy and adapt to changes in theenvironment as for the CL paradigm, while minimizing the impact on the users'QoS. Simulation results show that the proposed method outperforms staticallocation methods with minimal learning overhead, almost reaching theperformance of an ideal out-of-band CL solution.</description><author>Seyyidahmed Lahmer, Federico Mason, Federico Chiariotti, Andrea Zanella</author><pubDate>Tue, 06 Jun 2023 18:46:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03887v1</guid></item><item><title>Causal interventions expose implicit situation models for commonsense language understanding</title><link>http://arxiv.org/abs/2306.03882v1</link><description>Accounts of human language processing have long appealed to implicit``situation models'' that enrich comprehension with relevant but unstated worldknowledge. Here, we apply causal intervention techniques to recent transformermodels to analyze performance on the Winograd Schema Challenge (WSC), where asingle context cue shifts interpretation of an ambiguous pronoun. We identify arelatively small circuit of attention heads that are responsible forpropagating information from the context word that guides which of thecandidate noun phrases the pronoun ultimately attends to. We then compare howthis circuit behaves in a closely matched ``syntactic'' control where thesituation model is not strictly necessary. These analyses suggest distinctpathways through which implicit situation models are constructed to guidepronoun resolution.</description><author>Takateru Yamakoshi, James L. McClelland, Adele E. Goldberg, Robert D. Hawkins</author><pubDate>Tue, 06 Jun 2023 18:36:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03882v1</guid></item><item><title>Emergent Correspondence from Image Diffusion</title><link>http://arxiv.org/abs/2306.03881v1</link><description>Finding correspondences between images is a fundamental problem in computervision. In this paper, we show that correspondence emerges in image diffusionmodels without any explicit supervision. We propose a simple strategy toextract this implicit knowledge out of diffusion networks as image features,namely DIffusion FeaTures (DIFT), and use them to establish correspondencesbetween real images. Without any additional fine-tuning or supervision on thetask-specific data or annotations, DIFT is able to outperform bothweakly-supervised methods and competitive off-the-shelf features in identifyingsemantic, geometric, and temporal correspondences. Particularly for semanticcorrespondence, DIFT from Stable Diffusion is able to outperform DINO andOpenCLIP by 19 and 14 accuracy points respectively on the challenging SPair-71kbenchmark. It even outperforms the state-of-the-art supervised methods on 9 outof 18 categories while remaining on par for the overall performance. Projectpage: https://diffusionfeatures.github.io</description><author>Luming Tang, Menglin Jia, Qianqian Wang, Cheng Perng Phoo, Bharath Hariharan</author><pubDate>Tue, 06 Jun 2023 18:33:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03881v1</guid></item><item><title>Conditional Diffusion Models for Weakly Supervised Medical Image Segmentation</title><link>http://arxiv.org/abs/2306.03878v1</link><description>Recent advances in denoising diffusion probabilistic models have shown greatsuccess in image synthesis tasks. While there are already works exploring thepotential of this powerful tool in image semantic segmentation, its applicationin weakly supervised semantic segmentation (WSSS) remains relativelyunder-explored. Observing that conditional diffusion models (CDM) is capable ofgenerating images subject to specific distributions, in this work, we utilizecategory-aware semantic information underlied in CDM to get the prediction maskof the target object with only image-level annotations. More specifically, welocate the desired class by approximating the derivative of the output of CDMw.r.t the input condition. Our method is different from previous diffusionmodel methods with guidance from an external classifier, which accumulatesnoises in the background during the reconstruction process. Our methodoutperforms state-of-the-art CAM and diffusion model methods on two publicmedical image segmentation datasets, which demonstrates that CDM is a promisingtool in WSSS. Also, experiment shows our method is more time-efficient thanexisting diffusion model methods, making it practical for wider applications.</description><author>Xinrong Hu, Yu-Jen Chen, Tsung-Yi Ho, Yiyu Shi</author><pubDate>Tue, 06 Jun 2023 18:29:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03878v1</guid></item><item><title>Embracing Background Knowledge in the Analysis of Actual Causality: An Answer Set Programming Approach</title><link>http://arxiv.org/abs/2306.03874v1</link><description>This paper presents a rich knowledge representation language aimed atformalizing causal knowledge. This language is used for accurately and directlyformalizing common benchmark examples from the literature of actual causality.A definition of cause is presented and used to analyze the actual causes ofchanges with respect to sequences of actions representing those examples.</description><author>Michael Gelfond, Jorge Fandinno, Evgenii Balai</author><pubDate>Tue, 06 Jun 2023 18:21:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03874v1</guid></item><item><title>Deductive Verification of Chain-of-Thought Reasoning</title><link>http://arxiv.org/abs/2306.03872v1</link><description>Large Language Models (LLMs) significantly benefit from Chain-of-Thought(CoT) prompting in performing various reasoning tasks. While CoT allows modelsto produce more comprehensive reasoning processes, its emphasis on intermediatereasoning steps can inadvertently introduce hallucinations and accumulatederrors, thereby limiting models' ability to solve complex reasoning tasks.Inspired by how humans engage in careful and meticulous deductive logicalreasoning processes to solve tasks, we seek to enable language models toperform explicit and rigorous deductive reasoning, and also ensure thetrustworthiness of their reasoning process through self-verification. However,directly verifying the validity of an entire deductive reasoning process ischallenging, even with advanced models like ChatGPT. In light of this, wepropose to decompose a reasoning verification process into a series ofstep-by-step subprocesses, each only receiving their necessary context andpremises. To facilitate this procedure, we propose Natural Program, a naturallanguage-based deductive reasoning format. Our approach enables models togenerate precise reasoning steps where subsequent steps are more rigorouslygrounded on prior steps. It also empowers language models to carry outreasoning self-verification in a step-by-step manner. By integrating thisverification process into each deductive reasoning stage, we significantlyenhance the rigor and trustfulness of generated reasoning steps. Along thisprocess, we also improve the answer correctness on complex reasoning tasks.Code will be released at https://github.com/lz1oceani/verify_cot.</description><author>Zhan Ling, Yunhao Fang, Xuanlin Li, Zhiao Huang, Mingu Lee, Roland Memisevic, Hao Su</author><pubDate>Tue, 06 Jun 2023 18:18:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03872v1</guid></item><item><title>Concept-based Explanations for Out-Of-Distribution Detectors</title><link>http://arxiv.org/abs/2203.02586v3</link><description>Out-of-distribution (OOD) detection plays a crucial role in ensuring the safedeployment of deep neural network (DNN) classifiers. While a myriad of methodshave focused on improving the performance of OOD detectors, a critical gapremains in interpreting their decisions. We help bridge this gap by providingexplanations for OOD detectors based on learned high-level concepts. We firstpropose two new metrics for assessing the effectiveness of a particular set ofconcepts for explaining OOD detectors: 1) detection completeness, whichquantifies the sufficiency of concepts for explaining an OOD-detector'sdecisions, and 2) concept separability, which captures the distributionalseparation between in-distribution and OOD data in the concept space. Based onthese metrics, we propose an unsupervised framework for learning a set ofconcepts that satisfy the desired properties of high detection completeness andconcept separability, and demonstrate its effectiveness in providingconcept-based explanations for diverse off-the-shelf OOD detectors. We alsoshow how to identify prominent concepts contributing to the detection results,and provide further reasoning about their decisions.</description><author>Jihye Choi, Jayaram Raghuram, Ryan Feng, Jiefeng Chen, Somesh Jha, Atul Prakash</author><pubDate>Tue, 06 Jun 2023 18:17:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.02586v3</guid></item><item><title>A Trustworthiness Score to Evaluate CNNs Predictions</title><link>http://arxiv.org/abs/2301.08839v4</link><description>Due to the black box nature of Convolutional Neural Networks (CNNs), thecontinuous validation of CNNs during operation is challenging with the absenceof a human monitor. As a result this makes it difficult for developers andregulators to gain confidence in the deployment of autonomous systems employingCNNs. It is critical for safety during operation to know when CNN's predictionsare trustworthy or suspicious. With the absence of a human monitor, the basicapproach is to use the model's output confidence score to assess if predictionsare trustworthy or suspicious. However, the model's confidence score is aresult of computations coming from a black box, therefore lacks transparencyand makes it challenging to automatedly credit trustworthiness to predictions.We introduce the trustworthiness score (TS), a simple metric that provides amore transparent and effective way of providing confidence in CNNs predictionscompared to model's confidence score. The metric quantifies the trustworthinessin a prediction by checking for the existence of certain features in thepredictions made by the CNN. We also use the underlying idea of the TS metric,to provide a suspiciousness score (SS) in the overall input frame to help inthe detection of suspicious frames where false negatives exist. We conduct acase study using YOLOv5 on persons detection to demonstrate our method andusage of TS and SS. The case study shows that using our method consistentlyimproves the precision of predictions compared to relying on model confidencescore alone, for both 1) approving of trustworthy predictions (~20%improvement) and 2) detecting suspicious frames (~5% improvement).</description><author>Abanoub Ghobrial, Darryl Hond, Hamid Asgari, Kerstin Eder</author><pubDate>Tue, 06 Jun 2023 18:16:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.08839v4</guid></item><item><title>A Theory of Link Prediction via Relational Weisfeiler-Leman</title><link>http://arxiv.org/abs/2302.02209v2</link><description>Graph neural networks are prominent models for representation learning overgraph-structured data. While the capabilities and limitations of these modelsare well-understood for simple graphs, our understanding remains incomplete inthe context of knowledge graphs. Our goal is to provide a systematicunderstanding of the landscape of graph neural networks for knowledge graphspertaining to the prominent task of link prediction. Our analysis entails aunifying perspective on seemingly unrelated models and unlocks a series ofother models. The expressive power of various models is characterized via acorresponding relational Weisfeiler-Leman algorithm. This analysis is extendedto provide a precise logical characterization of the class of functionscaptured by a class of graph neural networks. The theoretical findingspresented in this paper explain the benefits of some widely employed practicaldesign choices, which are validated empirically.</description><author>Xingyue Huang, Miguel Romero Orth, İsmail İlkan Ceylan, Pablo Barceló</author><pubDate>Tue, 06 Jun 2023 18:15:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02209v2</guid></item><item><title>Correction of Errors in Preference Ratings from Automated Metrics for Text Generation</title><link>http://arxiv.org/abs/2306.03866v1</link><description>A major challenge in the field of Text Generation is evaluation: Humanevaluations are cost-intensive, and automated metrics often displayconsiderable disagreement with human judgments. In this paper, we propose astatistical model of Text Generation evaluation that accounts for theerror-proneness of automated metrics when used to generate preference rankingsbetween system outputs. We show that existing automated metrics are generallyover-confident in assigning significant differences between systems in thissetting. However, our model enables an efficient combination of human andautomated ratings to remedy the error-proneness of the automated metrics. Weshow that using this combination, we only require about 50% of the humanannotations typically used in evaluations to arrive at robust and statisticallysignificant results while yielding the same evaluation outcome as the purehuman evaluation in 95% of cases. We showcase the benefits of approach forthree text generation tasks: dialogue systems, machine translation, and textsummarization.</description><author>Jan Deriu, Pius von Däniken, Don Tuggener, Mark Cieliebak</author><pubDate>Tue, 06 Jun 2023 18:09:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03866v1</guid></item><item><title>AutoPEFT: Automatic Configuration Search for Parameter-Efficient Fine-Tuning</title><link>http://arxiv.org/abs/2301.12132v2</link><description>Large pretrained language models are widely used in downstream NLP tasks viatask-specific fine-tuning, but such procedures can be costly. Recently,Parameter-Efficient Fine-Tuning (PEFT) methods have achieved strong taskperformance while updating a much smaller number of parameters compared to fullmodel fine-tuning (FFT). However, it is non-trivial to make informed designchoices on the PEFT configurations, such as their architecture, the number oftunable parameters, and even the layers in which the PEFT modules are inserted.Consequently, it is highly likely that the current, manually designedconfigurations are suboptimal in terms of their performance-efficiencytrade-off. Inspired by advances in neural architecture search, we proposeAutoPEFT for automatic PEFT configuration selection: we first design anexpressive configuration search space with multiple representative PEFT modulesas building blocks. Using multi-objective Bayesian optimisation in a low-costsetup, we then discover a Pareto-optimal set of configurations with strongperformance-cost trade-offs across different numbers of parameters that arealso highly transferable across different tasks. Empirically, on GLUE andSuperGLUE tasks, we show that AutoPEFT-discovered configurations significantlyoutperform existing PEFT methods and are on par or better than FFT, withoutincurring substantial training efficiency costs.</description><author>Han Zhou, Xingchen Wan, Ivan Vulić, Anna Korhonen</author><pubDate>Tue, 06 Jun 2023 18:07:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12132v2</guid></item><item><title>Physics Inspired Approaches To Understanding Gaussian Processes</title><link>http://arxiv.org/abs/2305.10748v2</link><description>Prior beliefs about the latent function to shape inductive biases can beincorporated into a Gaussian Process (GP) via the kernel. However, beyondkernel choices, the decision-making process of GP models remains poorlyunderstood. In this work, we contribute an analysis of the loss landscape forGP models using methods from physics. We demonstrate $\nu$-continuity forMatern kernels and outline aspects of catastrophe theory at critical points inthe loss landscape. By directly including $\nu$ in the hyperparameteroptimisation for Matern kernels, we find that typical values of $\nu$ are farfrom optimal in terms of performance, yet prevail in the literature due to theincreased computational speed. We also provide an a priori method forevaluating the effect of GP ensembles and discuss various voting approachesbased on physical properties of the loss landscape. The utility of theseapproaches is demonstrated for various synthetic and real datasets. Ourfindings provide an enhanced understanding of the decision-making processbehind GPs and offer practical guidance for improving their performance andinterpretability in a range of applications.</description><author>Maximilian P. Niroomand, Luke Dicks, Edward O. Pyzer-Knapp, David J. Wales</author><pubDate>Tue, 06 Jun 2023 17:52:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10748v2</guid></item><item><title>Learning with a Mole: Transferable latent spatial representations for navigation without reconstruction</title><link>http://arxiv.org/abs/2306.03857v1</link><description>Agents navigating in 3D environments require some form of memory, whichshould hold a compact and actionable representation of the history ofobservations useful for decision taking and planning. In most end-to-endlearning approaches the representation is latent and usually does not have aclearly defined interpretation, whereas classical robotics addresses this withscene reconstruction resulting in some form of map, usually estimated withgeometry and sensor models and/or learning. In this work we propose to learn anactionable representation of the scene independently of the targeted downstreamtask and without explicitly optimizing reconstruction. The learnedrepresentation is optimized by a blind auxiliary agent trained to navigate withit on multiple short sub episodes branching out from a waypoint and, mostimportantly, without any direct visual observation. We argue and show that theblindness property is important and forces the (trained) latent representationto be the only means for planning. With probing experiments we show that thelearned representation optimizes navigability and not reconstruction. Ondownstream tasks we show that it is robust to changes in distribution, inparticular the sim2real gap, which we evaluate with a real physical robot in areal office building, significantly improving performance.</description><author>Guillaume Bono, Leonid Antsfeld, Assem Sadek, Gianluca Monaci, Christian Wolf</author><pubDate>Tue, 06 Jun 2023 17:51:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03857v1</guid></item><item><title>Iterative Translation Refinement with Large Language Models</title><link>http://arxiv.org/abs/2306.03856v1</link><description>Large language models have shown surprising performances in understandinginstructions and performing natural language tasks. In this paper, we proposeiterative translation refinement to leverage the power of large language modelsfor more natural translation and post-editing. We show that by simply involvinga large language model in an iterative process, the output quality improvesbeyond mere translation. Extensive test scenarios with GPT-3.5 reveal thatalthough iterations reduce string-based metric scores, neural metrics indicatecomparable if not improved translation quality. Further, human evaluationsdemonstrate that our method effectively reduces translationese compared toinitial GPT translations and even human references, especially for into-Englishdirections. Ablation studies underscore the importance of anchoring therefinement process to the source input and a reasonable initial translation.</description><author>Pinzhen Chen, Zhicheng Guo, Barry Haddow, Kenneth Heafield</author><pubDate>Tue, 06 Jun 2023 17:51:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03856v1</guid></item><item><title>Stochastic Gradient Descent-Induced Drift of Representation in a Two-Layer Neural Network</title><link>http://arxiv.org/abs/2302.02563v2</link><description>Representational drift refers to over-time changes in neural activationaccompanied by a stable task performance. Despite being observed in the brainand in artificial networks, the mechanisms of drift and its implications arenot fully understood. Motivated by recent experimental findings ofstimulus-dependent drift in the piriform cortex, we use theory and simulationsto study this phenomenon in a two-layer linear feedforward network.Specifically, in a continual online learning scenario, we study the driftinduced by the noise inherent in the Stochastic Gradient Descent (SGD). Bydecomposing the learning dynamics into the normal and tangent spaces of theminimum-loss manifold, we show the former corresponds to a finite variancefluctuation, while the latter could be considered as an effective diffusionprocess on the manifold. We analytically compute the fluctuation and thediffusion coefficients for the stimuli representations in the hidden layer asfunctions of network parameters and input distribution. Further, consistentwith experiments, we show that the drift rate is slower for a more frequentlypresented stimulus. Overall, our analysis yields a theoretical framework forbetter understanding of the drift phenomenon in biological and artificialneural networks.</description><author>Farhad Pashakhanloo, Alexei Koulakov</author><pubDate>Tue, 06 Jun 2023 17:45:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.02563v2</guid></item><item><title>From Key Points to Key Point Hierarchy: Structured and Expressive Opinion Summarization</title><link>http://arxiv.org/abs/2306.03853v1</link><description>Key Point Analysis (KPA) has been recently proposed for deriving fine-grainedinsights from collections of textual comments. KPA extracts the main points inthe data as a list of concise sentences or phrases, termed key points, andquantifies their prevalence. While key points are more expressive than wordclouds and key phrases, making sense of a long, flat list of key points, whichoften express related ideas in varying levels of granularity, may still bechallenging. To address this limitation of KPA, we introduce the task oforganizing a given set of key points into a hierarchy, according to theirspecificity. Such hierarchies may be viewed as a novel type of TextualEntailment Graph. We develop ThinkP, a high quality benchmark dataset of keypoint hierarchies for business and product reviews, obtained by consolidatingmultiple annotations. We compare different methods for predicting pairwiserelations between key points, and for inferring a hierarchy from these pairwisepredictions. In particular, for the task of computing pairwise key pointrelations, we achieve significant gains over existing strong baselines byapplying directional distributional similarity methods to a noveldistributional representation of key points, and further boost performance viaweak supervision.</description><author>Arie Cattan, Lilach Eden, Yoav Kantor, Roy Bar-Haim</author><pubDate>Tue, 06 Jun 2023 17:45:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03853v1</guid></item><item><title>Overcoming Simplicity Bias in Deep Networks using a Feature Sieve</title><link>http://arxiv.org/abs/2301.13293v3</link><description>Simplicity bias is the concerning tendency of deep networks to over-depend onsimple, weakly predictive features, to the exclusion of stronger, more complexfeatures. This is exacerbated in real-world applications by limited trainingdata and spurious feature-label correlations, leading to biased, incorrectpredictions. We propose a direct, interventional method for addressingsimplicity bias in DNNs, which we call the feature sieve. We aim toautomatically identify and suppress easily-computable spurious features inlower layers of the network, thereby allowing the higher network levels toextract and utilize richer, more meaningful representations. We provideconcrete evidence of this differential suppression &amp; enhancement of relevantfeatures on both controlled datasets and real-world images, and reportsubstantial gains on many real-world debiasing benchmarks (11.4% relative gainon Imagenet-A; 3.2% on BAR, etc). Crucially, we do not depend on priorknowledge of spurious attributes or features, and in fact outperform manybaselines that explicitly incorporate such information. We believe that ourfeature sieve work opens up exciting new research directions in automatedadversarial feature extraction and representation learning for deep networks.</description><author>Rishabh Tiwari, Pradeep Shenoy</author><pubDate>Tue, 06 Jun 2023 17:45:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13293v3</guid></item><item><title>Functional sufficient dimension reduction through information maximization with application to classification</title><link>http://arxiv.org/abs/2305.10880v2</link><description>Considering the case where the response variable is a categorical variableand the predictor is a random function, two novel functional sufficientdimensional reduction (FSDR) methods are proposed based on mutual informationand square loss mutual information. Compared to the classical FSDR methods,such as functional sliced inverse regression and functional sliced averagevariance estimation, the proposed methods are appealing because they arecapable of estimating multiple effective dimension reduction directions in thecase of a relatively small number of categories, especially for the binaryresponse. Moreover, the proposed methods do not require the restrictive linearconditional mean assumption and the constant covariance assumption. They avoidthe inverse problem of the covariance operator which is often encountered inthe functional sufficient dimension reduction. The functional principalcomponent analysis with truncation be used as a regularization mechanism. Undersome mild conditions, the statistical consistency of the proposed methods isestablished. It is demonstrated that the two methods are competitive comparedwith some existing FSDR methods by simulations and real data analyses.</description><author>Xinyu Li, Jianjun Xu, Wenquan Cui, Haoyang Cheng</author><pubDate>Tue, 06 Jun 2023 17:41:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10880v2</guid></item><item><title>Considering Human Factors in Risk Maps for Robust and Foresighted Driver Warning</title><link>http://arxiv.org/abs/2306.03849v1</link><description>Driver support systems that include human states in the support process is anactive research field. Many recent approaches allow, for example, to sense thedriver's drowsiness or awareness of the driving situation. However, so far,this rich information has not been utilized much for improving theeffectiveness of support systems. In this paper, we therefore propose a warningsystem that uses human states in the form of driver errors and can warn usersin some cases of upcoming risks several seconds earlier than the state of theart systems not considering human factors. The system consists of a behaviorplanner Risk Maps which directly changes its prediction of the surroundingdriving situation based on the sensed driver errors. By checking if thisdriver's behavior plan is objectively safe, a more robust and foresighteddriver warning is achieved. In different simulations of a dynamic lane changeand intersection scenarios, we show how the driver's behavior plan can becomeunsafe, given the estimate of driver errors, and experimentally validate theadvantages of considering human factors.</description><author>Tim Puphal, Ryohei Hirano, Malte Probst, Raphael Wenzel, Akihito Kimata</author><pubDate>Tue, 06 Jun 2023 17:39:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03849v1</guid></item><item><title>The Power of Preconditioning in Overparameterized Low-Rank Matrix Sensing</title><link>http://arxiv.org/abs/2302.01186v2</link><description>We propose $\textsf{ScaledGD($\lambda$)}$, a preconditioned gradient descentmethod to tackle the low-rank matrix sensing problem when the true rank isunknown, and when the matrix is possibly ill-conditioned. Usingoverparametrized factor representations, $\textsf{ScaledGD($\lambda$)}$ startsfrom a small random initialization, and proceeds by gradient descent with aspecific form of damped preconditioning to combat bad curvatures induced byoverparameterization and ill-conditioning. At the expense of lightcomputational overhead incurred by preconditioners,$\textsf{ScaledGD($\lambda$)}$ is remarkably robust to ill-conditioningcompared to vanilla gradient descent ($\textsf{GD}$) even withoverprameterization. Specifically, we show that, under the Gaussian design,$\textsf{ScaledGD($\lambda$)}$ converges to the true low-rank matrix at aconstant linear rate after a small number of iterations that scales onlylogarithmically with respect to the condition number and the problem dimension.This significantly improves over the convergence rate of vanilla $\textsf{GD}$which suffers from a polynomial dependency on the condition number. Our workprovides evidence on the power of preconditioning in accelerating theconvergence without hurting generalization in overparameterized learning.</description><author>Xingyu Xu, Yandi Shen, Yuejie Chi, Cong Ma</author><pubDate>Tue, 06 Jun 2023 17:36:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.01186v2</guid></item><item><title>Learning Human Mesh Recovery in 3D Scenes</title><link>http://arxiv.org/abs/2306.03847v1</link><description>We present a novel method for recovering the absolute pose and shape of ahuman in a pre-scanned scene given a single image. Unlike previous methods thatperform sceneaware mesh optimization, we propose to first estimate absoluteposition and dense scene contacts with a sparse 3D CNN, and later enhance apretrained human mesh recovery network by cross-attention with the derived 3Dscene cues. Joint learning on images and scene geometry enables our method toreduce the ambiguity caused by depth and occlusion, resulting in morereasonable global postures and contacts. Encoding scene-aware cues in thenetwork also allows the proposed method to be optimization-free, and opens upthe opportunity for real-time applications. The experiments show that theproposed network is capable of recovering accurate and physically-plausiblemeshes by a single forward pass and outperforms state-of-the-art methods interms of both accuracy and speed.</description><author>Zehong Shen, Zhi Cen, Sida Peng, Qing Shuai, Hujun Bao, Xiaowei Zhou</author><pubDate>Tue, 06 Jun 2023 17:35:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03847v1</guid></item><item><title>oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes</title><link>http://arxiv.org/abs/2303.17612v3</link><description>In this paper, we introduce the range of oBERTa language models, aneasy-to-use set of language models which allows Natural Language Processing(NLP) practitioners to obtain between 3.8 and 24.3 times faster models withoutexpertise in model compression. Specifically, oBERTa extends existing work onpruning, knowledge distillation, and quantization and leverages frozenembeddings improves distillation and model initialization to deliver higheraccuracy on a broad range of transfer tasks. In generating oBERTa, we explorehow the highly optimized RoBERTa differs from the BERT for pruning duringpre-training and finetuning. We find it less amenable to compression duringfine-tuning. We explore the use of oBERTa on seven representative NLP tasks andfind that the improved compression techniques allow a pruned oBERTa model tomatch the performance of BERTbase and exceed the performance of Prune OFA Largeon the SQUAD V1.1 Question Answering dataset, despite being 8x and 2x,respectively faster in inference. We release our code, training regimes, andassociated model for broad usage to encourage usage and experimentation</description><author>Daniel Campos, Alexandre Marques, Mark Kurtz, ChengXiang Zhai</author><pubDate>Tue, 06 Jun 2023 17:30:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.17612v3</guid></item><item><title>Remarks on Utility in Repeated Bets</title><link>http://arxiv.org/abs/2306.03842v1</link><description>The use of von Neumann -- Morgenstern utility is examined in the context ofmultiple choices between lotteries. Different conclusions are reached if thechoices are simultaneous or sequential. It is demonstrated that utility cannotbe additive.</description><author>Nimrod Megiddo</author><pubDate>Tue, 06 Jun 2023 17:29:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03842v1</guid></item><item><title>Enhancing Programming eTextbooks with ChatGPT Generated Counterfactual-Thinking-Inspired Questions</title><link>http://arxiv.org/abs/2306.00551v2</link><description>Digital textbooks have become an integral part of everyday learning tasks. Inthis work, we consider the use of digital textbooks for programming classes.Generally, students struggle with utilizing textbooks on programming to themaximum, with a possible reason being that the example programs provided asillustration of concepts in these textbooks don't offer sufficientinteractivity for students, and thereby not sufficiently motivating to exploreor understand these programming examples better. In our work, we explore theidea of enhancing the navigability of intelligent textbooks with the use of``counterfactual'' questions, to make students think critically about theseprograms and enhance possible program comprehension. Inspired from previousworks on nudging students on counter factual thinking, we present thepossibility to enhance digital textbooks with questions generated using GPT.</description><author>Arun Balajiee Lekshmi Narayanan, Rully Agus Hendrawan, Venktesh V</author><pubDate>Tue, 06 Jun 2023 17:27:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00551v2</guid></item><item><title>Spherical Fourier Neural Operators: Learning Stable Dynamics on the Sphere</title><link>http://arxiv.org/abs/2306.03838v1</link><description>Fourier Neural Operators (FNOs) have proven to be an efficient and effectivemethod for resolution-independent operator learning in a broad variety ofapplication areas across scientific machine learning. A key reason for theirsuccess is their ability to accurately model long-range dependencies inspatio-temporal data by learning global convolutions in a computationallyefficient manner. To this end, FNOs rely on the discrete Fourier transform(DFT), however, DFTs cause visual and spectral artifacts as well as pronounceddissipation when learning operators in spherical coordinates since theyincorrectly assume a flat geometry. To overcome this limitation, we generalizeFNOs on the sphere, introducing Spherical FNOs (SFNOs) for learning operatorson spherical geometries. We apply SFNOs to forecasting atmospheric dynamics,and demonstrate stable auto\-regressive rollouts for a year of simulated time(1,460 steps), while retaining physically plausible dynamics. The SFNO hasimportant implications for machine learning-based simulation of climatedynamics that could eventually help accelerate our response to climate change.</description><author>Boris Bonev, Thorsten Kurth, Christian Hundt, Jaideep Pathak, Maximilian Baust, Karthik Kashinath, Anima Anandkumar</author><pubDate>Tue, 06 Jun 2023 17:27:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03838v1</guid></item><item><title>Atrial Septal Defect Detection in Children Based on Ultrasound Video Using Multiple Instances Learning</title><link>http://arxiv.org/abs/2306.03835v1</link><description>Purpose: Congenital heart defect (CHD) is the most common birth defect.Thoracic echocardiography (TTE) can provide sufficient cardiac structureinformation, evaluate hemodynamics and cardiac function, and is an effectivemethod for atrial septal defect (ASD) examination. This paper aims to study adeep learning method based on cardiac ultrasound video to assist in ASDdiagnosis. Materials and methods: We select two standard views of the atrialseptum (subAS) and low parasternal four-compartment view (LPS4C) as the twoviews to identify ASD. We enlist data from 300 children patients as part of adouble-blind experiment for five-fold cross-validation to verify theperformance of our model. In addition, data from 30 children patients (15positives and 15 negatives) are collected for clinician testing and compared toour model test results (these 30 samples do not participate in model training).We propose an echocardiography video-based atrial septal defect diagnosissystem. In our model, we present a block random selection, maximal agreementdecision and frame sampling strategy for training and testing respectively,resNet18 and r3D networks are used to extract the frame features and aggregatethem to build a rich video-level representation. Results: We validate our modelusing our private dataset by five-cross validation. For ASD detection, weachieve 89.33 AUC, 84.95 accuracy, 85.70 sensitivity, 81.51 specificity and81.99 F1 score. Conclusion: The proposed model is multiple instanceslearning-based deep learning model for video atrial septal defect detectionwhich effectively improves ASD detection accuracy when compared to theperformances of previous networks and clinical doctors.</description><author>Yiman Liu, Qiming Huang, Xiaoxiang Han, Tongtong Liang, Zhifang Zhang, Lijun Chen, Jinfeng Wang, Angelos Stefanidis, Jionglong Su, Jiangang Chen, Qingli Li, Yuqi Zhang</author><pubDate>Tue, 06 Jun 2023 17:25:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03835v1</guid></item><item><title>MTS2Graph: Interpretable Multivariate Time Series Classification with Temporal Evolving Graphs</title><link>http://arxiv.org/abs/2306.03834v1</link><description>Conventional time series classification approaches based on bags of patternsor shapelets face significant challenges in dealing with a vast amount offeature candidates from high-dimensional multivariate data. In contrast, deepneural networks can learn low-dimensional features efficiently, and inparticular, Convolutional Neural Networks (CNN) have shown promising results inclassifying Multivariate Time Series (MTS) data. A key factor in the success ofdeep neural networks is this astonishing expressive power. However, this powercomes at the cost of complex, black-boxed models, conflicting with the goals ofbuilding reliable and human-understandable models. An essential criterion inunderstanding such predictive deep models involves quantifying the contributionof time-varying input variables to the classification. Hence, in this work, weintroduce a new framework for interpreting multivariate time series data byextracting and clustering the input representative patterns that highlyactivate CNN neurons. This way, we identify each signal's role anddependencies, considering all possible combinations of signals in the MTSinput. Then, we construct a graph that captures the temporal relationshipbetween the extracted patterns for each layer. An effective graph mergingstrategy finds the connection of each node to the previous layer's nodes.Finally, a graph embedding algorithm generates new representations of thecreated interpretable time-series features. To evaluate the performance of ourproposed framework, we run extensive experiments on eight datasets of theUCR/UEA archive, along with HAR and PAM datasets. The experiments indicate thebenefit of our time-aware graph-based representation in MTS classificationwhile enriching them with more interpretability.</description><author>Raneen Younis, Abdul Hakmeh, Zahra Ahmadi</author><pubDate>Tue, 06 Jun 2023 17:24:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03834v1</guid></item><item><title>Patient Dropout Prediction in Virtual Health: A Multimodal Dynamic Knowledge Graph and Text Mining Approach</title><link>http://arxiv.org/abs/2306.03833v1</link><description>Virtual health has been acclaimed as a transformative force in healthcaredelivery. Yet, its dropout issue is critical that leads to poor healthoutcomes, increased health, societal, and economic costs. Timely prediction ofpatient dropout enables stakeholders to take proactive steps to addresspatients' concerns, potentially improving retention rates. In virtual health,the information asymmetries inherent in its delivery format, between differentstakeholders, and across different healthcare delivery systems hinder theperformance of existing predictive methods. To resolve those informationasymmetries, we propose a Multimodal Dynamic Knowledge-driven DropoutPrediction (MDKDP) framework that learns implicit and explicit knowledge fromdoctor-patient dialogues and the dynamic and complex networks of variousstakeholders in both online and offline healthcare delivery systems. Weevaluate MDKDP by partnering with one of the largest virtual health platformsin China. MDKDP improves the F1-score by 3.26 percentage points relative to thebest benchmark. Comprehensive robustness analyses show that integratingstakeholder attributes, knowledge dynamics, and compact bilinear poolingsignificantly improves the performance. Our work provides significantimplications for healthcare IT by revealing the value of mining relations andknowledge across different service modalities. Practically, MDKDP offers anovel design artifact for virtual health platforms in patient dropoutmanagement.</description><author>Shuang Geng, Wenli Zhang, Jiaheng Xie, Gemin Liang, Ben Niu</author><pubDate>Tue, 06 Jun 2023 17:23:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03833v1</guid></item><item><title>Detecting Harmful Content On Online Platforms: What Platforms Need Vs. Where Research Efforts Go</title><link>http://arxiv.org/abs/2103.00153v2</link><description>The proliferation of harmful content on online platforms is a major societalproblem, which comes in many different forms including hate speech, offensivelanguage, bullying and harassment, misinformation, spam, violence, graphiccontent, sexual abuse, self harm, and many other. Online platforms seek tomoderate such content to limit societal harm, to comply with legislation, andto create a more inclusive environment for their users. Researchers havedeveloped different methods for automatically detecting harmful content, oftenfocusing on specific sub-problems or on narrow communities, as what isconsidered harmful often depends on the platform and on the context. We arguethat there is currently a dichotomy between what types of harmful contentonline platforms seek to curb, and what research efforts there are toautomatically detect such content. We thus survey existing methods as well ascontent moderation policies by online platforms in this light and we suggestdirections for future work.</description><author>Arnav Arora, Preslav Nakov, Momchil Hardalov, Sheikh Muhammad Sarwar, Vibha Nayak, Yoan Dinkov, Dimitrina Zlatkova, Kyle Dent, Ameya Bhatawdekar, Guillaume Bouchard, Isabelle Augenstein</author><pubDate>Tue, 06 Jun 2023 17:22:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2103.00153v2</guid></item><item><title>Discovering New Interpretable Conservation Laws as Sparse Invariants</title><link>http://arxiv.org/abs/2305.19525v2</link><description>Discovering conservation laws for a given dynamical system is important butchallenging. In a theorist setup (differential equations and basis functionsare both known), we propose the Sparse Invariant Detector (SID), an algorithmthat auto-discovers conservation laws from differential equations. Itsalgorithmic simplicity allows robustness and interpretability of the discoveredconserved quantities. We show that SID is able to rediscover known and evendiscover new conservation laws in a variety of systems. For two examples influid mechanics and atmospheric chemistry, SID discovers 14 and 3 conservedquantities, respectively, where only 12 and 2 were previously known to domainexperts.</description><author>Ziming Liu, Patrick Obin Sturm, Saketh Bharadwaj, Sam Silva, Max Tegmark</author><pubDate>Tue, 06 Jun 2023 17:21:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19525v2</guid></item><item><title>Sequential Principal-Agent Problems with Communication: Efficient Computation and Learning</title><link>http://arxiv.org/abs/2306.03832v1</link><description>We study a sequential decision making problem between a principal and anagent with incomplete information on both sides. In this model, the principaland the agent interact in a stochastic environment, and each is privy toobservations about the state not available to the other. The principal has thepower of commitment, both to elicit information from the agent and to providesignals about her own information. The principal and the agent communicatetheir signals to each other, and select their actions independently based onthis communication. Each player receives a payoff based on the state and theirjoint actions, and the environment moves to a new state. The interactioncontinues over a finite time horizon, and both players act to optimize theirown total payoffs over the horizon. Our model encompasses as special casesstochastic games of incomplete information and POMDPs, as well as sequentialBayesian persuasion and mechanism design problems. We study both computation ofoptimal policies and learning in our setting. While the general problems arecomputationally intractable, we study algorithmic solutions under a conditionalindependence assumption on the underlying state-observation distributions. Wepresent an polynomial-time algorithm to compute the principal's optimal policyup to an additive approximation. Additionally, we show an efficient learningalgorithm in the case where the transition probabilities are not knownbeforehand. The algorithm guarantees sublinear regret for both players.</description><author>Jiarui Gan, Rupak Majumdar, Debmalya Mandal, Goran Radanovic</author><pubDate>Tue, 06 Jun 2023 17:20:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03832v1</guid></item><item><title>Optimally tackling covariate shift in RKHS-based nonparametric regression</title><link>http://arxiv.org/abs/2205.02986v2</link><description>We study the covariate shift problem in the context of nonparametricregression over a reproducing kernel Hilbert space (RKHS). We focus on twonatural families of covariate shift problems defined using the likelihoodratios between the source and target distributions. When the likelihood ratiosare uniformly bounded, we prove that the kernel ridge regression (KRR)estimator with a carefully chosen regularization parameter is minimaxrate-optimal (up to a log factor) for a large family of RKHSs with regularkernel eigenvalues. Interestingly, KRR does not require full knowledge oflikelihood ratios apart from an upper bound on them. In striking contrast tothe standard statistical setting without covariate shift, we also demonstratethat a naive estimator, which minimizes the empirical risk over the functionclass, is strictly sub-optimal under covariate shift as compared to KRR. Wethen address the larger class of covariate shift problems where the likelihoodratio is possibly unbounded yet has a finite second moment. Here, we propose areweighted KRR estimator that weights samples based on a careful truncation ofthe likelihood ratios. Again, we are able to show that this estimator isminimax rate-optimal, up to logarithmic factors.</description><author>Cong Ma, Reese Pathak, Martin J. Wainwright</author><pubDate>Tue, 06 Jun 2023 17:20:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.02986v2</guid></item><item><title>A Communication-efficient Algorithm with Linear Convergence for Federated Minimax Learning</title><link>http://arxiv.org/abs/2206.01132v2</link><description>In this paper, we study a large-scale multi-agent minimax optimizationproblem, which models many interesting applications in statistical learning andgame theory, including Generative Adversarial Networks (GANs). The overallobjective is a sum of agents' private local objective functions. We firstanalyze an important special case, empirical minimax problem, where the overallobjective approximates a true population minimax risk by statistical samples.We provide generalization bounds for learning with this objective throughRademacher complexity analysis. Then, we focus on the federated setting, whereagents can perform local computation and communicate with a central server.Most existing federated minimax algorithms either require communication periteration or lack performance guarantees with the exception of Local StochasticGradient Descent Ascent (SGDA), a multiple-local-update descent ascentalgorithm which guarantees convergence under a diminishing stepsize. Byanalyzing Local SGDA under the ideal condition of no gradient noise, we showthat generally it cannot guarantee exact convergence with constant stepsizesand thus suffers from slow rates of convergence. To tackle this issue, wepropose FedGDA-GT, an improved Federated (Fed) Gradient Descent Ascent (GDA)method based on Gradient Tracking (GT). When local objectives are Lipschitzsmooth and strongly-convex-strongly-concave, we prove that FedGDA-GT convergeslinearly with a constant stepsize to global $\epsilon$-approximation solutionwith $\mathcal{O}(\log (1/\epsilon))$ rounds of communication, which matchesthe time complexity of centralized GDA method. Finally, we numerically showthat FedGDA-GT outperforms Local SGDA.</description><author>Zhenyu Sun, Ermin Wei</author><pubDate>Tue, 06 Jun 2023 17:17:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.01132v2</guid></item><item><title>GEO-Bench: Toward Foundation Models for Earth Monitoring</title><link>http://arxiv.org/abs/2306.03831v1</link><description>Recent progress in self-supervision has shown that pre-training large neuralnetworks on vast amounts of unsupervised data can lead to substantial increasesin generalization to downstream tasks. Such models, recently coined foundationmodels, have been transformational to the field of natural language processing.Variants have also been proposed for image data, but their applicability toremote sensing tasks is limited. To stimulate the development of foundationmodels for Earth monitoring, we propose a benchmark comprised of sixclassification and six segmentation tasks, which were carefully curated andadapted to be both relevant to the field and well-suited for model evaluation.We accompany this benchmark with a robust methodology for evaluating models andreporting aggregated results to enable a reliable assessment of progress.Finally, we report results for 20 baselines to gain information about theperformance of existing models. We believe that this benchmark will be a driverof progress across a variety of Earth monitoring tasks.</description><author>Alexandre Lacoste, Nils Lehmann, Pau Rodriguez, Evan David Sherwin, Hannah Kerner, Björn Lütjens, Jeremy Andrew Irvin, David Dao, Hamed Alemohammad, Alexandre Drouin, Mehmet Gunturkun, Gabriel Huang, David Vazquez, Dava Newman, Yoshua Bengio, Stefano Ermon, Xiao Xiang Zhu</author><pubDate>Tue, 06 Jun 2023 17:16:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03831v1</guid></item><item><title>Inductive Bias for Emergent Communication in a Continuous Setting</title><link>http://arxiv.org/abs/2306.03830v1</link><description>We study emergent communication in a multi-agent reinforcement learningsetting, where the agents solve cooperative tasks and have access to acommunication channel. The communication channel may consist of either discretesymbols or continuous variables. We introduce an inductive bias to aid with theemergence of good communication protocols for continuous messages, and we lookat the effect this type of inductive bias has for continuous and discretemessages in itself or when used in combination with reinforcement learning. Wedemonstrate that this type of inductive bias has a beneficial effect on thecommunication protocols learnt in two toy environments, Negotiation andSequence Guess.</description><author>John Isak Fjellvang Villanger, Troels Arnfred Bojesen</author><pubDate>Tue, 06 Jun 2023 17:15:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03830v1</guid></item><item><title>Ewald-based Long-Range Message Passing for Molecular Graphs</title><link>http://arxiv.org/abs/2303.04791v2</link><description>Neural architectures that learn potential energy surfaces from molecular datahave undergone fast improvement in recent years. A key driver of this successis the Message Passing Neural Network (MPNN) paradigm. Its favorable scalingwith system size partly relies upon a spatial distance limit on messages. Whilethis focus on locality is a useful inductive bias, it also impedes the learningof long-range interactions such as electrostatics and van der Waals forces. Toaddress this drawback, we propose Ewald message passing: a nonlocal Fourierspace scheme which limits interactions via a cutoff on frequency instead ofdistance, and is theoretically well-founded in the Ewald summation method. Itcan serve as an augmentation on top of existing MPNN architectures as it iscomputationally inexpensive and agnostic to architectural details. We test theapproach with four baseline models and two datasets containing diverse periodic(OC20) and aperiodic structures (OE62). We observe robust improvements inenergy mean absolute errors across all models and datasets, averaging 10% onOC20 and 16% on OE62. Our analysis shows an outsize impact of theseimprovements on structures with high long-range contributions to the groundtruth energy.</description><author>Arthur Kosmala, Johannes Gasteiger, Nicholas Gao, Stephan Günnemann</author><pubDate>Tue, 06 Jun 2023 17:15:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.04791v2</guid></item><item><title>Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How</title><link>http://arxiv.org/abs/2306.03828v1</link><description>With the ever-increasing number of pretrained models, machine learningpractitioners are continuously faced with which pretrained model to use, andhow to finetune it for a new dataset. In this paper, we propose a methodologythat jointly searches for the optimal pretrained model and the hyperparametersfor finetuning it. Our method transfers knowledge about the performance of manypretrained models with multiple hyperparameter configurations on a series ofdatasets. To this aim, we evaluated over 20k hyperparameter configurations forfinetuning 24 pretrained image classification models on 87 datasets to generatea large-scale meta-dataset. We meta-learn a multi-fidelity performancepredictor on the learning curves of this meta-dataset and use it for fasthyperparameter optimization on new datasets. We empirically demonstrate thatour resulting approach can quickly select an accurate pretrained model for anew dataset together with its optimal hyperparameters.</description><author>Sebastian Pineda Arango, Fabio Ferreira, Arlind Kadra, Frank Hutter Josif Grabocka</author><pubDate>Tue, 06 Jun 2023 17:15:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03828v1</guid></item><item><title>Bridging the Gap: Enhancing the Utility of Synthetic Data via Post-Processing Techniques</title><link>http://arxiv.org/abs/2305.10118v2</link><description>Acquiring and annotating suitable datasets for training deep learning modelsis challenging. This often results in tedious and time-consuming efforts thatcan hinder research progress. However, generative models have emerged as apromising solution for generating synthetic datasets that can replace oraugment real-world data. Despite this, the effectiveness of synthetic data islimited by their inability to fully capture the complexity and diversity ofreal-world data. To address this issue, we explore the use of GenerativeAdversarial Networks to generate synthetic datasets for training classifiersthat are subsequently evaluated on real-world images. To improve the qualityand diversity of the synthetic dataset, we propose three novel post-processingtechniques: Dynamic Sample Filtering, Dynamic Dataset Recycle, and ExpansionTrick. In addition, we introduce a pipeline called Gap Filler (GaFi), whichapplies these techniques in an optimal and coordinated manner to maximiseclassification accuracy on real-world data. Our experiments show that GaFieffectively reduces the gap with real-accuracy scores to an error of 2.03%,1.78%, and 3.99% on the Fashion-MNIST, CIFAR-10, and CIFAR-100 datasets,respectively. These results represent a new state of the art in ClassificationAccuracy Score and highlight the effectiveness of post-processing techniques inimproving the quality of synthetic datasets.</description><author>Andrea Lampis, Eugenio Lomurno, Matteo Matteucci</author><pubDate>Tue, 06 Jun 2023 17:13:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10118v2</guid></item><item><title>Understanding Generalization of Federated Learning via Stability: Heterogeneity Matters</title><link>http://arxiv.org/abs/2306.03824v1</link><description>Generalization performance is a key metric in evaluating machine learningmodels when applied to real-world applications. Good generalization indicatesthe model can predict unseen data correctly when trained under a limited numberof data. Federated learning (FL), which has emerged as a popular distributedlearning framework, allows multiple devices or clients to train a shared modelwithout violating privacy requirements. While the existing literature hasstudied extensively the generalization performances of centralized machinelearning algorithms, similar analysis in the federated settings is eitherabsent or with very restrictive assumptions on the loss functions. In thispaper, we aim to analyze the generalization performances of federated learningby means of algorithmic stability, which measures the change of the outputmodel of an algorithm when perturbing one data point. Three widely-usedalgorithms are studied, including FedAvg, SCAFFOLD, and FedProx, under convexand non-convex loss functions. Our analysis shows that the generalizationperformances of models trained by these three algorithms are closely related tothe heterogeneity of clients' datasets as well as the convergence behaviors ofthe algorithms. Particularly, in the i.i.d. setting, our results recover theclassical results of stochastic gradient descent (SGD).</description><author>Zhenyu Sun, Xiaochun Niu, Ermin Wei</author><pubDate>Tue, 06 Jun 2023 17:12:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03824v1</guid></item><item><title>Prediction of Post-Operative Renal and Pulmonary Complications Using Transformers</title><link>http://arxiv.org/abs/2306.00698v2</link><description>Postoperative complications pose a significant challenge in the healthcareindustry, resulting in elevated healthcare expenses and prolonged hospitalstays, and in rare instances, patient mortality. To improve patient outcomesand reduce healthcare costs, healthcare providers rely on various perioperativerisk scores to guide clinical decisions and prioritize care. In recent years,machine learning techniques have shown promise in predicting postoperativecomplications and fatality, with deep learning models achieving remarkablesuccess in healthcare applications. However, research on the application ofdeep learning models to intra-operative anesthesia management data is limited.In this paper, we evaluate the performance of transformer-based models inpredicting postoperative acute renal failure, postoperative pulmonarycomplications, and postoperative in-hospital mortality. We compare our method'sperformance with state-of-the-art tabular data prediction models, includinggradient boosting trees and sequential attention models, on a clinical dataset.Our results demonstrate that transformer-based models can achieve superiorperformance in predicting postoperative complications and outperformtraditional machine learning models. This work highlights the potential of deeplearning techniques, specifically transformer-based models, in revolutionizingthe healthcare industry's approach to postoperative care.</description><author>Reza Shirkavand, Fei Zhang, Heng Huang</author><pubDate>Tue, 06 Jun 2023 17:12:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00698v2</guid></item><item><title>Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability</title><link>http://arxiv.org/abs/2305.08746v3</link><description>We introduce Brain-Inspired Modular Training (BIMT), a method for makingneural networks more modular and interpretable. Inspired by brains, BIMT embedsneurons in a geometric space and augments the loss function with a costproportional to the length of each neuron connection. We demonstrate that BIMTdiscovers useful modular neural networks for many simple tasks, revealingcompositional structures in symbolic formulas, interpretable decisionboundaries and features for classification, and mathematical structure inalgorithmic datasets. The ability to directly see modules with the naked eyecan complement current mechanistic interpretability strategies such as probes,interventions or staring at all weights.</description><author>Ziming Liu, Eric Gan, Max Tegmark</author><pubDate>Tue, 06 Jun 2023 17:11:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.08746v3</guid></item><item><title>Make Your Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning</title><link>http://arxiv.org/abs/2306.00477v2</link><description>Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs)has emerged as a highly successful approach, with training only a small numberof parameters without sacrificing performance and becoming the de-factolearning paradigm with the increasing size of PLMs. However, existing PEFTmethods are not memory-efficient, because they still require caching most ofthe intermediate activations for the gradient calculation, akin to fine-tuning.One effective way to reduce the activation memory is to apply a reversiblemodel, so the intermediate activations are not necessary to be cached and canbe recomputed. Nevertheless, modifying a PLM to its reversible variant withPEFT is not straightforward, since the reversible model has a distinctarchitecture from the currently released PLMs. In this paper, we firstinvestigate what is a key factor for the success of existing PEFT methods, andrealize that it's essential to preserve the PLM's starting point wheninitializing a PEFT method. With this finding, we propose memory-efficientfine-tuning (MEFT) that inserts adapters into a PLM, preserving the PLM'sstarting point and making it reversible without additional pre-training. Weevaluate MEFT on the GLUE benchmark and five question-answering tasks withvarious backbones, BERT, RoBERTa, BART and OPT. MEFT significantly reduces theactivation memory up to 84% of full fine-tuning with a negligible amount oftrainable parameters. Moreover, MEFT achieves the same score on GLUE and acomparable score on the question-answering tasks as full fine-tuning.</description><author>Baohao Liao, Shaomu Tan, Christof Monz</author><pubDate>Tue, 06 Jun 2023 17:10:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00477v2</guid></item><item><title>Revisiting Bellman Errors for Offline Model Selection</title><link>http://arxiv.org/abs/2302.00141v2</link><description>Offline model selection (OMS), that is, choosing the best policy from a setof many policies given only logged data, is crucial for applying offline RL inreal-world settings. One idea that has been extensively explored is to selectpolicies based on the mean squared Bellman error (MSBE) of the associatedQ-functions. However, previous work has struggled to obtain adequate OMSperformance with Bellman errors, leading many researchers to abandon the idea.To this end, we elucidate why previous work has seen pessimistic results withBellman errors and identify conditions under which OMS algorithms based onBellman errors will perform well. Moreover, we develop a new estimator of theMSBE that is more accurate than prior methods. Our estimator obtains impressiveOMS performance on diverse discrete control tasks, including Atari games.</description><author>Joshua P. Zitovsky, Daniel de Marchi, Rishabh Agarwal, Michael R. Kosorok</author><pubDate>Tue, 06 Jun 2023 17:09:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.00141v2</guid></item><item><title>LEACE: Perfect linear concept erasure in closed form</title><link>http://arxiv.org/abs/2306.03819v1</link><description>Concept erasure aims to remove specified features from a representation. Itcan be used to improve fairness (e.g. preventing a classifier from using genderor race) and interpretability (e.g. removing a concept to observe changes inmodel behavior). In this paper, we introduce LEAst-squares Concept Erasure(LEACE), a closed-form method which provably prevents all linear classifiersfrom detecting a concept while inflicting the least possible damage to therepresentation. We apply LEACE to large language models with a novel procedurecalled "concept scrubbing," which erases target concept information from everylayer in the network. We demonstrate the usefulness of our method on two tasks:measuring the reliance of language models on part-of-speech information, andreducing gender bias in BERT embeddings. Code is available athttps://github.com/EleutherAI/concept-erasure.</description><author>Nora Belrose, David Schneider-Joseph, Shauli Ravfogel, Ryan Cotterell, Edward Raff, Stella Biderman</author><pubDate>Tue, 06 Jun 2023 17:07:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03819v1</guid></item><item><title>Computation with Sequences in the Brain</title><link>http://arxiv.org/abs/2306.03812v1</link><description>Even as machine learning exceeds human-level performance on manyapplications, the generality, robustness, and rapidity of the brain's learningcapabilities remain unmatched. How cognition arises from neural activity is acentral open question in neuroscience, inextricable from the study ofintelligence itself. A simple formal model of neural activity was proposed inPapadimitriou [2020] and has been subsequently shown, through both mathematicalproofs and simulations, to be capable of implementing certain simple cognitiveoperations via the creation and manipulation of assemblies of neurons. However,many intelligent behaviors rely on the ability to recognize, store, andmanipulate temporal sequences of stimuli (planning, language, navigation, tolist a few). Here we show that, in the same model, time can be capturednaturally as precedence through synaptic weights and plasticity, and, as aresult, a range of computations on sequences of assemblies can be carried out.In particular, repeated presentation of a sequence of stimuli leads to thememorization of the sequence through corresponding neural assemblies: uponfuture presentation of any stimulus in the sequence, the corresponding assemblyand its subsequent ones will be activated, one after the other, until the endof the sequence. Finally, we show that any finite state machine can be learnedin a similar way, through the presentation of appropriate patterns ofsequences. Through an extension of this mechanism, the model can be shown to becapable of universal computation. We support our analysis with a number ofexperiments to probe the limits of learning in this model in key ways. Takentogether, these results provide a concrete hypothesis for the basis of thebrain's remarkable abilities to compute and learn, with sequences playing avital role.</description><author>Max Dabagia, Christos H. Papadimitriou, Santosh S. Vempala</author><pubDate>Tue, 06 Jun 2023 16:58:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03812v1</guid></item><item><title>X-Align++: cross-modal cross-view alignment for Bird's-eye-view segmentation</title><link>http://arxiv.org/abs/2306.03810v1</link><description>Bird's-eye-view (BEV) grid is a typical representation of the perception ofroad components, e.g., drivable area, in autonomous driving. Most existingapproaches rely on cameras only to perform segmentation in BEV space, which isfundamentally constrained by the absence of reliable depth information. Thelatest works leverage both camera and LiDAR modalities but suboptimally fusetheir features using simple, concatenation-based mechanisms. In this paper, weaddress these problems by enhancing the alignment of the unimodal features inorder to aid feature fusion, as well as enhancing the alignment between thecameras' perspective view (PV) and BEV representations. We propose X-Align, anovel end-to-end cross-modal and cross-view learning framework for BEVsegmentation consisting of the following components: (i) a novel Cross-ModalFeature Alignment (X-FA) loss, (ii) an attention-based Cross-Modal FeatureFusion (X-FF) module to align multi-modal BEV features implicitly, and (iii) anauxiliary PV segmentation branch with Cross-View Segmentation Alignment (X-SA)losses to improve the PV-to-BEV transformation. We evaluate our proposed methodacross two commonly used benchmark datasets, i.e., nuScenes and KITTI-360.Notably, X-Align significantly outperforms the state-of-the-art by 3 absolutemIoU points on nuScenes. We also provide extensive ablation studies todemonstrate the effectiveness of the individual components.</description><author>Shubhankar Borse, Senthil Yogamani, Marvin Klingner, Varun Ravi, Hong Cai, Abdulaziz Almuzairee, Fatih Porikli</author><pubDate>Tue, 06 Jun 2023 16:52:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03810v1</guid></item><item><title>Certified Reinforcement Learning with Logic Guidance</title><link>http://arxiv.org/abs/1902.00778v4</link><description>Reinforcement Learning (RL) is a widely employed machine learningarchitecture that has been applied to a variety of control problems. However,applications in safety-critical domains require a systematic and formalapproach to specifying requirements as tasks or goals. We propose a model-freeRL algorithm that enables the use of Linear Temporal Logic (LTL) to formulate agoal for unknown continuous-state/action Markov Decision Processes (MDPs). Thegiven LTL property is translated into a Limit-Deterministic Generalised BuchiAutomaton (LDGBA), which is then used to shape a synchronous reward functionon-the-fly. Under certain assumptions, the algorithm is guaranteed tosynthesise a control policy whose traces satisfy the LTL specification withmaximal probability.</description><author>Hosein Hasanbeig, Daniel Kroening, Alessandro Abate</author><pubDate>Tue, 06 Jun 2023 16:52:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1902.00778v4</guid></item><item><title>Can large language models democratize access to dual-use biotechnology?</title><link>http://arxiv.org/abs/2306.03809v1</link><description>Large language models (LLMs) such as those embedded in 'chatbots' areaccelerating and democratizing research by providing comprehensible informationand expertise from many different fields. However, these models may also confereasy access to dual-use technologies capable of inflicting great harm. Toevaluate this risk, the 'Safeguarding the Future' course at MIT taskednon-scientist students with investigating whether LLM chatbots could beprompted to assist non-experts in causing a pandemic. In one hour, the chatbotssuggested four potential pandemic pathogens, explained how they can begenerated from synthetic DNA using reverse genetics, supplied the names of DNAsynthesis companies unlikely to screen orders, identified detailed protocolsand how to troubleshoot them, and recommended that anyone lacking the skills toperform reverse genetics engage a core facility or contract researchorganization. Collectively, these results suggest that LLMs will makepandemic-class agents widely accessible as soon as they are crediblyidentified, even to people with little or no laboratory training. Promisingnonproliferation measures include pre-release evaluations of LLMs by thirdparties, curating training datasets to remove harmful concepts, and verifiablyscreening all DNA generated by synthesis providers or used by contract researchorganizations and robotic cloud laboratories to engineer organisms or viruses.</description><author>Emily H. Soice, Rafael Rocha, Kimberlee Cordova, Michael Specter, Kevin M. Esvelt</author><pubDate>Tue, 06 Jun 2023 16:52:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03809v1</guid></item><item><title>Survey on LiDAR Perception in Adverse Weather Conditions</title><link>http://arxiv.org/abs/2304.06312v2</link><description>Autonomous vehicles rely on a variety of sensors to gather information abouttheir surrounding. The vehicle's behavior is planned based on the environmentperception, making its reliability crucial for safety reasons. The active LiDARsensor is able to create an accurate 3D representation of a scene, making it avaluable addition for environment perception for autonomous vehicles. Due tolight scattering and occlusion, the LiDAR's performance change under adverseweather conditions like fog, snow or rain. This limitation recently fostered alarge body of research on approaches to alleviate the decrease in perceptionperformance. In this survey, we gathered, analyzed, and discussed differentaspects on dealing with adverse weather conditions in LiDAR-based environmentperception. We address topics such as the availability of appropriate data, rawpoint cloud processing and denoising, robust perception algorithms and sensorfusion to mitigate adverse weather induced shortcomings. We furthermoreidentify the most pressing gaps in the current literature and pinpointpromising research directions.</description><author>Mariella Dreissig, Dominik Scheuble, Florian Piewak, Joschka Boedecker</author><pubDate>Tue, 06 Jun 2023 16:49:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.06312v2</guid></item><item><title>The Emergence of Essential Sparsity in Large Pre-trained Models: The Weights that Matter</title><link>http://arxiv.org/abs/2306.03805v1</link><description>Large pre-trained transformers are show-stealer in modern-day deep learning,and it becomes crucial to comprehend the parsimonious patterns that existwithin them as they grow in scale. With exploding parameter counts, LotteryTicket Hypothesis (LTH) and its variants, have lost their pragmatism insparsifying them due to high computation and memory bottleneck of therepetitive train-prune-retrain routine of iterative magnitude pruning (IMP)which worsens with increasing model size. In this paper, we comprehensivelystudy induced sparse patterns across multiple large pre-trained vision andlanguage transformers. We propose the existence of -- essential sparsitydefined with a sharp dropping point beyond which the performance declines muchfaster w.r.t the rise of sparsity level, when we directly remove weights withthe smallest magnitudes in one-shot. In the sparsity-performance curve We alsopresent an intriguing emerging phenomenon of abrupt sparsification during thepre-training of BERT, i.e., BERT suddenly becomes heavily sparse inpre-training after certain iterations. Moreover, our observations also indicatea counter-intuitive finding that BERT trained with a larger amount ofpre-training data tends to have a better ability to condense knowledge incomparatively relatively fewer parameters. Lastly, we investigate the effect ofthe pre-training loss on essential sparsity and discover that self-supervisedlearning (SSL) objectives trigger stronger emergent sparsification propertiesthan supervised learning (SL). Our codes are available at\url{https://github.com/VITA-Group/essential\_sparsity}.</description><author>Ajay Jaiswal, Shiwei Liu, Tianlong Chen, Zhangyang Wang</author><pubDate>Tue, 06 Jun 2023 16:49:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03805v1</guid></item><item><title>Learning to Ground Instructional Articles in Videos through Narrations</title><link>http://arxiv.org/abs/2306.03802v1</link><description>In this paper we present an approach for localizing steps of proceduralactivities in narrated how-to videos. To deal with the scarcity of labeled dataat scale, we source the step descriptions from a language knowledge base(wikiHow) containing instructional articles for a large variety of proceduraltasks. Without any form of manual supervision, our model learns to temporallyground the steps of procedural articles in how-to videos by matching threemodalities: frames, narrations, and step descriptions. Specifically, our methodaligns steps to video by fusing information from two distinct pathways: i) {\emdirect} alignment of step descriptions to frames, ii) {\em indirect} alignmentobtained by composing steps-to-narrations with narrations-to-videocorrespondences. Notably, our approach performs global temporal grounding ofall steps in an article at once by exploiting order information, and is trainedwith step pseudo-labels which are iteratively refined and aggressivelyfiltered. In order to validate our model we introduce a new evaluationbenchmark -- HT-Step -- obtained by manually annotating a 124-hour subset ofHowTo100M\footnote{A test server is accessible at\url{https://eval.ai/web/challenges/challenge-page/2082}.} with steps sourcedfrom wikiHow articles. Experiments on this benchmark as well as zero-shotevaluations on CrossTask demonstrate that our multi-modality alignment yieldsdramatic gains over several baselines and prior works. Finally, we show thatour inner module for matching narration-to-video outperforms by a large marginthe state of the art on the HTM-Align narration-video alignment benchmark.</description><author>Effrosyni Mavroudi, Triantafyllos Afouras, Lorenzo Torresani</author><pubDate>Tue, 06 Jun 2023 16:45:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03802v1</guid></item><item><title>Criteria Tell You More than Ratings: Criteria Preference-Aware Light Graph Convolution for Effective Multi-Criteria Recommendation</title><link>http://arxiv.org/abs/2305.18885v4</link><description>The multi-criteria (MC) recommender system, which leverages MC ratinginformation in a wide range of e-commerce areas, is ubiquitous nowadays.Surprisingly, although graph neural networks (GNNs) have been widely applied todevelop various recommender systems due to GNN's high expressive capability inlearning graph representations, it has been still unexplored how to design MCrecommender systems with GNNs. In light of this, we make the first attempttowards designing a GNN-aided MC recommender system. Specifically, rather thanstraightforwardly adopting existing GNN-based recommendation methods, we devisea novel criteria preference-aware light graph convolution CPA-LGC method, whichis capable of precisely capturing the criteria preference of users as well asthe collaborative signal in complex high-order connectivities. To this end, wefirst construct an MC expansion graph that transforms user--item MC ratingsinto an expanded bipartite graph to potentially learn from the collaborativesignal in MC ratings. Next, to strengthen the capability of criteria preferenceawareness, CPA-LGC incorporates newly characterized embeddings, includinguser-specific criteria-preference embeddings and item-specific criterionembeddings, into our graph convolution model. Through comprehensive evaluationsusing four real-world datasets, we demonstrate (a) the superiority overbenchmark MC recommendation methods and benchmark recommendation methods usingGNNs with tremendous gains, (b) the effectiveness of core components inCPA-LGC, and (c) the computational efficiency.</description><author>Jin-Duk Park, Siqing Li, Xin Cao, Won-Yong Shin</author><pubDate>Tue, 06 Jun 2023 16:45:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18885v4</guid></item><item><title>Stable Vectorization of Multiparameter Persistent Homology using Signed Barcodes as Measures</title><link>http://arxiv.org/abs/2306.03801v1</link><description>Persistent homology (PH) provides topological descriptors for geometric data,such as weighted graphs, which are interpretable, stable to perturbations, andinvariant under, e.g., relabeling. Most applications of PH focus on theone-parameter case -- where the descriptors summarize the changes in topologyof data as it is filtered by a single quantity of interest -- and there is nowa wide array of methods enabling the use of one-parameter PH descriptors indata science, which rely on the stable vectorization of these descriptors aselements of a Hilbert space. Although the multiparameter PH (MPH) of data thatis filtered by several quantities of interest encodes much richer informationthan its one-parameter counterpart, the scarceness of stability results for MPHdescriptors has so far limited the available options for the stablevectorization of MPH. In this paper, we aim to bring together the best of bothworlds by showing how the interpretation of signed barcodes -- a recent familyof MPH descriptors -- as signed measures leads to natural extensions ofvectorization strategies from one parameter to multiple parameters. Theresulting feature vectors are easy to define and to compute, and provablystable. While, as a proof of concept, we focus on simple choices of signedbarcodes and vectorizations, we already see notable performance improvementswhen comparing our feature vectors to state-of-the-art topology-based methodson various types of data.</description><author>David Loiseaux, Luis Scoccola, Mathieu Carrière, Magnus Bakke Botnan, Steve Oudot</author><pubDate>Tue, 06 Jun 2023 16:45:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03801v1</guid></item><item><title>A Survey of Learning on Small Data: Generalization, Optimization, and Challenge</title><link>http://arxiv.org/abs/2207.14443v2</link><description>Learning on big data brings success for artificial intelligence (AI), but theannotation and training costs are expensive. In future, learning on small datathat approximates the generalization ability of big data is one of the ultimatepurposes of AI, which requires machines to recognize objectives and scenariosrelying on small data as humans. A series of learning topics is going on thisway such as active learning and few-shot learning. However, there are fewtheoretical guarantees for their generalization performance. Moreover, most oftheir settings are passive, that is, the label distribution is explicitlycontrolled by finite training resources from known distributions. This surveyfollows the agnostic active sampling theory under a PAC (Probably ApproximatelyCorrect) framework to analyze the generalization error and label complexity oflearning on small data in model-agnostic supervised and unsupervised fashion.Considering multiple learning communities could produce small datarepresentation and related topics have been well surveyed, we thus subjoinnovel geometric representation perspectives for small data: the Euclidean andnon-Euclidean (hyperbolic) mean, where the optimization solutions including theEuclidean gradients, non-Euclidean gradients, and Stein gradient are presentedand discussed. Later, multiple learning communities that may be improved bylearning on small data are summarized, which yield data-efficientrepresentations, such as transfer learning, contrastive learning, graphrepresentation learning. Meanwhile, we find that the meta-learning may provideeffective parameter update policies for learning on small data. Then, weexplore multiple challenging scenarios for small data, such as the weaksupervision and multi-label. Finally, multiple data applications that maybenefit from efficient small data representation are surveyed.</description><author>Xiaofeng Cao, Weixin Bu, Shengjun Huang, Minling Zhang, Ivor W. Tsang, Yew Soon Ong, James T. Kwok</author><pubDate>Tue, 06 Jun 2023 16:44:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.14443v2</guid></item><item><title>Prompt Space Optimizing Few-shot Reasoning Success with Large Language Models</title><link>http://arxiv.org/abs/2306.03799v1</link><description>Prompt engineering is an essential technique for enhancing the abilities oflarge language models (LLMs) by providing explicit and specific instructions.It enables LLMs to excel in various tasks, such as arithmetic reasoning,question answering, summarization, relation extraction, machine translation,and sentiment analysis. Researchers have been actively exploring differentprompt engineering strategies, such as Chain of Thought (CoT), Zero-CoT, andIn-context learning. However, an unresolved problem arises from the fact thatcurrent approaches lack a solid theoretical foundation for determining optimalprompts. To address this issue in prompt engineering, we propose a new andeffective approach called Prompt Space. Our methodology utilizes textembeddings to obtain basis vectors by matrix decomposition, and then constructsa space for representing all prompts. Prompt Space significantly outperformsstate-of-the-art prompt paradigms on ten public reasoning benchmarks. Notably,without the help of the CoT method and the prompt "Let's think step by step",Prompt Space shows superior performance over the few-shot method. Overall, ourapproach provides a robust and fundamental theoretical framework for selectingsimple and effective prompts. This advancement marks a significant step towardsimproving prompt engineering for a wide variety of applications in LLMs.</description><author>Fobo Shi, Peijun Qing, Dong Yang, Nan Wang, Youbo Lei, Haonan Lu, Xiaodong Lin</author><pubDate>Tue, 06 Jun 2023 16:43:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03799v1</guid></item><item><title>AI-Supported Assessment of Load Safety</title><link>http://arxiv.org/abs/2306.03795v1</link><description>Load safety assessment and compliance is an essential step in the corporateprocess of every logistics service provider. In 2020, a total of 11,371 policechecks of trucks were carried out, during which 9.6% (1091) violations againstthe load safety regulations were detected. For a logistic service provider,every load safety violation results in height fines and damage to reputation.An assessment of load safety supported by artificial intelligence (AI) willreduce the risk of accidents by unsecured loads and fines during safetyassessments. This work shows how photos of the load, taken by the truck driveror the loadmaster after the loading process, can be used to assess load safety.By a trained two-stage artificial neural network (ANN), these photos areclassified into three different classes I) cargo loaded safely, II) cargoloaded unsafely, and III) unusable image. By applying several architectures ofconvolutional neural networks (CNN), it can be shown that it is possible todistinguish between unusable and usable images for cargo safety assessment.This distinction is quite crucial since the truck driver and the loadmastersometimes provide photos without the essential image features like the casestructure of the truck and the whole cargo. A human operator or another ANNwill then assess the load safety within the second stage.</description><author>Julius Schöning, Niklas Kruse</author><pubDate>Tue, 06 Jun 2023 16:40:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03795v1</guid></item><item><title>FAMO: Fast Adaptive Multitask Optimization</title><link>http://arxiv.org/abs/2306.03792v1</link><description>One of the grand enduring goals of AI is to create generalist agents that canlearn multiple different tasks from diverse data via multitask learning (MTL).However, gradient descent (GD) on the average loss across all tasks may yieldpoor multitask performance due to severe under-optimization of certain tasks.Previous approaches that manipulate task gradients for a more balanced lossdecrease require storing and computing all task gradients (O(K) space and timewhere K is the number of tasks), limiting their use in large-scale scenarios.In this work, we introduce Fast Adaptive Multitask Optimization (FAMO), adynamic weighting method that decreases task losses in a balanced way usingO(1) space and time. We conduct an extensive set of experiments coveringmulti-task supervised and reinforcement learning problems. Our results indicatethat FAMO achieves comparable or superior performance to state-of-the-artgradient manipulation techniques while offering significant improvements inspace and computational efficiency. Code is available athttps://github.com/Cranial-XIX/FAMO.</description><author>Bo Liu, Yihao Feng, Peter Stone, Qiang Liu</author><pubDate>Tue, 06 Jun 2023 16:39:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03792v1</guid></item><item><title>Regions of Reliability in the Evaluation of Multivariate Probabilistic Forecasts</title><link>http://arxiv.org/abs/2304.09836v2</link><description>Multivariate probabilistic time series forecasts are commonly evaluated viaproper scoring rules, i.e., functions that are minimal in expectation for theground-truth distribution. However, this property is not sufficient toguarantee good discrimination in the non-asymptotic regime. In this paper, weprovide the first systematic finite-sample study of proper scoring rules fortime-series forecasting evaluation. Through a power analysis, we identify the"region of reliability" of a scoring rule, i.e., the set of practicalconditions where it can be relied on to identify forecasting errors. We carryout our analysis on a comprehensive synthetic benchmark, specifically designedto test several key discrepancies between ground-truth and forecastdistributions, and we gauge the generalizability of our findings to real-worldtasks with an application to an electricity production problem. Our resultsreveal critical shortcomings in the evaluation of multivariate probabilisticforecasts as commonly performed in the literature.</description><author>Étienne Marcotte, Valentina Zantedeschi, Alexandre Drouin, Nicolas Chapados</author><pubDate>Tue, 06 Jun 2023 16:39:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.09836v2</guid></item><item><title>Faster Gradient-Free Algorithms for Nonsmooth Nonconvex Stochastic Optimization</title><link>http://arxiv.org/abs/2301.06428v2</link><description>We consider the optimization problem of the form $\min_{x \in \mathbb{R}^d}f(x) \triangleq \mathbb{E}_{\xi} [F(x; \xi)]$, where the component $F(x;\xi)$is $L$-mean-squared Lipschitz but possibly nonconvex and nonsmooth. Therecently proposed gradient-free method requires at most $\mathcal{O}( L^4d^{3/2} \epsilon^{-4} + \Delta L^3 d^{3/2} \delta^{-1} \epsilon^{-4})$stochastic zeroth-order oracle complexity to find a$(\delta,\epsilon)$-Goldstein stationary point of objective function, where$\Delta = f(x_0) - \inf_{x \in \mathbb{R}^d} f(x)$ and $x_0$ is the initialpoint of the algorithm. This paper proposes a more efficient algorithm usingstochastic recursive gradient estimators, which improves the complexity to$\mathcal{O}(L^3 d^{3/2} \epsilon^{-3}+ \Delta L^2 d^{3/2} \delta^{-1}\epsilon^{-3})$.</description><author>Lesi Chen, Jing Xu, Luo Luo</author><pubDate>Tue, 06 Jun 2023 16:37:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06428v2</guid></item><item><title>Asymptotics of Bayesian Uncertainty Estimation in Random Features Regression</title><link>http://arxiv.org/abs/2306.03783v1</link><description>In this paper we compare and contrast the behavior of the posteriorpredictive distribution to the risk of the maximum a posteriori estimator forthe random features regression model in the overparameterized regime. We willfocus on the variance of the posterior predictive distribution (Bayesian modelaverage) and compare its asymptotics to that of the risk of the MAP estimator.In the regime where the model dimensions grow faster than any constant multipleof the number of samples, asymptotic agreement between these two quantities isgoverned by the phase transition in the signal-to-noise ratio. They alsoasymptotically agree with each other when the number of samples grow fasterthan any constant multiple of model dimensions. Numerical simulationsillustrate finer distributional properties of the two quantities for finitedimensions. We conjecture they have Gaussian fluctuations and exhibit similarproperties as found by previous authors in a Gaussian sequence model, which isof independent theoretical interest.</description><author>Youngsoo Baek, Samuel I. Berchuck, Sayan Mukherjee</author><pubDate>Tue, 06 Jun 2023 16:36:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03783v1</guid></item><item><title>Performance-optimized deep neural networks are evolving into worse models of inferotemporal visual cortex</title><link>http://arxiv.org/abs/2306.03779v1</link><description>One of the most impactful findings in computational neuroscience over thepast decade is that the object recognition accuracy of deep neural networks(DNNs) correlates with their ability to predict neural responses to naturalimages in the inferotemporal (IT) cortex. This discovery supported thelong-held theory that object recognition is a core objective of the visualcortex, and suggested that more accurate DNNs would serve as better models ofIT neuron responses to images. Since then, deep learning has undergone arevolution of scale: billion parameter-scale DNNs trained on billions of imagesare rivaling or outperforming humans at visual tasks including objectrecognition. Have today's DNNs become more accurate at predicting IT neuronresponses to images as they have grown more accurate at object recognition? Surprisingly, across three independent experiments, we find this is not thecase. DNNs have become progressively worse models of IT as their accuracy hasincreased on ImageNet. To understand why DNNs experience this trade-off andevaluate if they are still an appropriate paradigm for modeling the visualsystem, we turn to recordings of IT that capture spatially resolved maps ofneuronal activity elicited by natural images. These neuronal activity mapsreveal that DNNs trained on ImageNet learn to rely on different visual featuresthan those encoded by IT and that this problem worsens as their accuracyincreases. We successfully resolved this issue with the neural harmonizer, aplug-and-play training routine for DNNs that aligns their learnedrepresentations with humans. Our results suggest that harmonized DNNs break thetrade-off between ImageNet accuracy and neural prediction accuracy that assailscurrent DNNs and offer a path to more accurate models of biological vision.</description><author>Drew Linsley, Ivan F. Rodriguez, Thomas Fel, Michael Arcaro, Saloni Sharma, Margaret Livingstone, Thomas Serre</author><pubDate>Tue, 06 Jun 2023 16:34:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03779v1</guid></item><item><title>Matched Pair Calibration for Ranking Fairness</title><link>http://arxiv.org/abs/2306.03775v1</link><description>We propose a test of fairness in score-based ranking systems called matchedpair calibration. Our approach constructs a set of matched item pairs withminimal confounding differences between subgroups before computing anappropriate measure of ranking error over the set. The matching step ensuresthat we compare subgroup outcomes between identically scored items so thatmeasured performance differences directly imply unfairness in subgroup-levelexposures. We show how our approach generalizes the fairness intuitions ofcalibration from a binary classification setting to ranking and connect ourapproach to other proposals for ranking fairness measures. Moreover, ourstrategy shows how the logic of marginal outcome tests extends to cases wherethe analyst has access to model scores. Lastly, we provide an example ofapplying matched pair calibration to a real-word ranking data set todemonstrate its efficacy in detecting ranking bias.</description><author>Hannah Korevaar, Chris McConnell, Edmund Tong, Erik Brinkman, Alana Shine, Misam Abbas, Blossom Metevier, Sam Corbett-Davies, Khalid El-Arini</author><pubDate>Tue, 06 Jun 2023 16:32:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03775v1</guid></item><item><title>Exploring Linguistic Features for Turkish Text Readability</title><link>http://arxiv.org/abs/2306.03774v1</link><description>This paper presents the first comprehensive study on automatic readabilityassessment of Turkish texts. We combine state-of-the-art neural network modelswith linguistic features at lexical, morphosyntactic, syntactic and discourselevels to develop an advanced readability tool. We evaluate the effectivenessof traditional readability formulas compared to modern automated methods andidentify key linguistic features that determine the readability of Turkishtexts.</description><author>Ahmet Yavuz Uluslu, Gerold Schneider</author><pubDate>Tue, 06 Jun 2023 16:32:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03774v1</guid></item><item><title>Explanation-based Finetuning Makes Models More Robust to Spurious Cues</title><link>http://arxiv.org/abs/2305.04990v3</link><description>Large Language Models (LLMs) are so powerful that they sometimes learncorrelations between labels and features that are irrelevant to the task,leading to poor generalization on out-of-distribution data. We proposeexplanation-based finetuning as a general approach to mitigate LLMs' relianceon spurious correlations. Unlike standard finetuning where the model onlypredicts the answer given the input, we finetune the model to additionallygenerate a free-text explanation supporting its answer. To evaluate our method,we finetune the model on artificially constructed training sets containingdifferent types of spurious cues, and test it on a test set without these cues.Compared to standard finetuning, our method makes GPT-3 (davinci) remarkablymore robust against spurious cues in terms of accuracy drop across fourclassification tasks: ComVE (+1.2), CREAK (+9.1), e-SNLI (+15.4), and SBIC(+6.5). The efficacy generalizes across multiple model families and scales,with greater gains for larger models. Finally, our method also works well withexplanations generated by the model, implying its applicability to moredatasets without human-written explanations.</description><author>Josh Magnus Ludan, Yixuan Meng, Tai Nguyen, Saurabh Shah, Qing Lyu, Marianna Apidianaki, Chris Callison-Burch</author><pubDate>Tue, 06 Jun 2023 16:31:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.04990v3</guid></item><item><title>Graph Classification Gaussian Processes via Spectral Features</title><link>http://arxiv.org/abs/2306.03770v1</link><description>Graph classification aims to categorise graphs based on their structure andnode attributes. In this work, we propose to tackle this task using tools fromgraph signal processing by deriving spectral features, which we then use todesign two variants of Gaussian process models for graph classification. Thefirst variant uses spectral features based on the distribution of energy of anode feature signal over the spectrum of the graph. We show that even such asimple approach, having no learned parameters, can yield competitiveperformance compared to strong neural network and graph kernel baselines. Asecond, more sophisticated variant is designed to capture multi-scale andlocalised patterns in the graph by learning spectral graph wavelet filters,obtaining improved performance on synthetic and real-world data sets. Finally,we show that both models produce well calibrated uncertainty estimates,enabling reliable decision making based on the model predictions.</description><author>Felix L. Opolka, Yin-Cong Zhi, Pietro Liò, Xiaowen Dong</author><pubDate>Tue, 06 Jun 2023 16:31:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03770v1</guid></item><item><title>Domain Generalization for Mammographic Image Analysis via Contrastive Learning</title><link>http://arxiv.org/abs/2304.10226v3</link><description>The deep learning technique has been shown to be effective in addressingseveral image analysis tasks within the computer-aided diagnosis scheme formammography. The training of an efficacious deep learning model requires largeamounts of data with sufficient diversity in terms of image style and quality.In particular, the diversity of image styles may be primarily attributed to thevendor factor. However, the collection of mammograms from large and diversevendors is very expensive and sometimes impractical. Motivatedly, a novelcontrastive learning method is developed to equip the deep learning models withbetter generalization capability. Specifically, the multi-style and multi-viewunsupervised self-learning scheme is carried out to seek robust featureembedding against various vendor styles as a pre-trained model. Afterward, thepre-trained network is further fine-tuned to the downstream tasks, e.g., massdetection, matching, BI-RADS rating, and breast density classification. Theproposed method has been extensively and rigorously evaluated with mammogramsfrom various vendor-style domains and several public datasets. The experimentalresults suggest that the proposed domain generalization method can effectivelyimprove the performance of four mammographic image tasks on data from eitherseen or unseen domains and outperform many state-of-the-art (SOTA)generalization methods.</description><author>Zheren Li, Zhiming Cui, Lichi Zhang, Sheng Wang, Chenjin Lei, Xi Ouyang, Dongdong Chen, Xiangyu Zhao, Yajia Gu, Zaiyi Liu, Chunling Liu, Dinggang Shen, Jie-Zhi Cheng</author><pubDate>Tue, 06 Jun 2023 16:25:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.10226v3</guid></item><item><title>Near-field Perception for Low-Speed Vehicle Automation using Surround-view Fisheye Cameras</title><link>http://arxiv.org/abs/2103.17001v4</link><description>Cameras are the primary sensor in automated driving systems. They providehigh information density and are optimal for detecting road infrastructure cueslaid out for human vision. Surround-view camera systems typically comprise offour fisheye cameras with 190{\deg}+ field of view covering the entire360{\deg} around the vehicle focused on near-field sensing. They are theprincipal sensors for low-speed, high accuracy, and close-range sensingapplications, such as automated parking, traffic jam assistance, and low-speedemergency braking. In this work, we provide a detailed survey of such visionsystems, setting up the survey in the context of an architecture that can bedecomposed into four modular components namely Recognition, Reconstruction,Relocalization, and Reorganization. We jointly call this the 4R Architecture.We discuss how each component accomplishes a specific aspect and provide apositional argument that they can be synergized to form a complete perceptionsystem for low-speed automation. We support this argument by presenting resultsfrom previous works and by presenting architecture proposals for such a system.Qualitative results are presented in the video at https://youtu.be/ae8bCOF77uY.</description><author>Ciaran Eising, Jonathan Horgan, Senthil Yogamani</author><pubDate>Tue, 06 Jun 2023 16:25:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2103.17001v4</guid></item><item><title>Exploring the effects of robotic design on learning and neural control</title><link>http://arxiv.org/abs/2306.03757v1</link><description>The ongoing deep learning revolution has allowed computers to outclass humansin various games and perceive features imperceptible to humans duringclassification tasks. Current machine learning techniques have clearlydistinguished themselves in specialized tasks. However, we have yet to seerobots capable of performing multiple tasks at an expert level. Most work inthis field is focused on the development of more sophisticated learningalgorithms for a robot's controller given a largely static and presupposedrobotic design. By focusing on the development of robotic bodies, rather thanneural controllers, I have discovered that robots can be designed such thatthey overcome many of the current pitfalls encountered by neural controllers inmultitask settings. Through this discovery, I also present novel metrics toexplicitly measure the learning ability of a robotic design and its resistanceto common problems such as catastrophic interference. Traditionally, the physical robot design requires human engineers to planevery aspect of the system, which is expensive and often relies on humanintuition. In contrast, within the field of evolutionary robotics, evolutionaryalgorithms are used to automatically create optimized designs, however, suchdesigns are often still limited in their ability to perform in a multitasksetting. The metrics created and presented here give a novel path to automateddesign that allow evolved robots to synergize with their controller to improvethe computational efficiency of their learning while overcoming catastrophicinterference. Overall, this dissertation intimates the ability to automatically designrobots that are more general purpose than current robots and that can performvarious tasks while requiring less computation.</description><author>Joshua Paul Powers</author><pubDate>Tue, 06 Jun 2023 16:17:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03757v1</guid></item><item><title>Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models</title><link>http://arxiv.org/abs/2305.10276v3</link><description>In this paper, we take the initiative to investigate the performance of LLMson complex planning tasks that require LLMs to understand a virtual spatialenvironment simulated via natural language and act correspondingly in text. Wepropose a benchmark named Natural Language Planning and Action (Natala)composed of a set of novel tasks: Brick World, NLVR-based Manipulations, andNatural Language Navigation. We found that current popular LLMs such as ChatGPTstill lack abilities in complex planning. This arises a question -- do the LLMshave a good understanding of the environments described in natural language, ormaybe other alternatives such as symbolic representations are neater and hencebetter to be understood by LLMs? To this end, we propose a novel method calledCoS (Chain-of-Symbol Prompting) that represents the complex environments withcondensed symbolic spatial representations during the chained intermediatethinking steps. CoS is easy to use and does not need additional training onLLMs. Extensive experiments indicate that CoS clearly surpasses the performanceof the Chain-of-Thought (CoT) Prompting in all three planning tasks with evenfewer tokens used in the inputs compared with CoT on ChatGPT and InstructGPT.The performance gain is strong, by up to 60.8% accuracy (from 31.8% to 92.6%)on Brick World for ChatGPT. CoS also reduces the number of tokens in the promptobviously, by up to 65.8% of the tokens (from 407 to 139) for the intermediatesteps from demonstrations on Brick World.</description><author>Hanxu Hu, Hongyuan Lu, Huajian Zhang, Wai Lam, Yue Zhang</author><pubDate>Tue, 06 Jun 2023 16:15:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.10276v3</guid></item><item><title>Newly Formed Cities: an AI Curation</title><link>http://arxiv.org/abs/2306.03753v1</link><description>Art curatorial processes are characterized by the presentation of acollection of artworks in a knowledgeable way. Machine processes arecharacterized by their capacity to manage and analyze large amounts of data.This paper envisages machine curation and audience interaction as a means toexplore the implications of contemporary AI models for the curatorial world.This project was developed for the occasion of the 2023 Helsinki Art Biennial,entitled New Directions May Emerge. We use the Helsinki Art Museum (HAM)collection to re-imagine the city of Helsinki through the lens of machineperception. We use visual-textual models to place artworks currently hostedinside the museum in outdoor public spaces of the city, assigning fictionalcoordinates based on similarity scores. Synthetic 360{\deg} art panoramas aregenerated using diffusion-based models to propose a machinic visual styleguided by the artworks. The result of this project will be virtually presentedas a web-based installation, where such a re-contextualization allows thenavigation of an alternative version of the city while exploring its artisticheritage. Finally, we discuss our contributions to machine curation and theethical implications that such a process entails. The web-based installation isavailable at this link: http://newlyformedcity.com/.</description><author>Dario Negueruela del Castillo, Ludovica Schaerf, Pepe Ballesteros, Iacopo Neri, Valentine Bernasconi</author><pubDate>Tue, 06 Jun 2023 16:13:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03753v1</guid></item><item><title>Towards Scalable Multi-View Reconstruction of Geometry and Materials</title><link>http://arxiv.org/abs/2306.03747v1</link><description>In this paper, we propose a novel method for joint recovery of camera pose,object geometry and spatially-varying Bidirectional Reflectance DistributionFunction (svBRDF) of 3D scenes that exceed object-scale and hence cannot becaptured with stationary light stages. The input are high-resolution RGB-Dimages captured by a mobile, hand-held capture system with point lights foractive illumination. Compared to previous works that jointly estimate geometryand materials from a hand-held scanner, we formulate this problem using asingle objective function that can be minimized using off-the-shelfgradient-based solvers. To facilitate scalability to large numbers ofobservation views and optimization variables, we introduce a distributedoptimization algorithm that reconstructs 2.5D keyframe-based representations ofthe scene. A novel multi-view consistency regularizer effectively synchronizesneighboring keyframes such that the local optimization results allow forseamless integration into a globally consistent 3D model. We provide a study onthe importance of each component in our formulation and show that our methodcompares favorably to baselines. We further demonstrate that our methodaccurately reconstructs various objects and materials and allows for expansionto spatially larger scenes. We believe that this work represents a significantstep towards making geometry and material estimation from hand-held scannersscalable.</description><author>Carolin Schmitt, Božidar Antić, Andrei Neculai, Joo Ho Lee, Andreas Geiger</author><pubDate>Tue, 06 Jun 2023 16:07:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03747v1</guid></item><item><title>Machine Learned Calabi-Yau Metrics and Curvature</title><link>http://arxiv.org/abs/2211.09801v3</link><description>Finding Ricci-flat (Calabi-Yau) metrics is a long standing problem ingeometry with deep implications for string theory and phenomenology. A newattack on this problem uses neural networks to engineer approximations to theCalabi-Yau metric within a given K\"ahler class. In this paper we investigatenumerical Ricci-flat metrics over smooth and singular K3 surfaces andCalabi-Yau threefolds. Using these Ricci-flat metric approximations for theCefal\'u family of quartic twofolds and the Dwork family of quintic threefolds,we study characteristic forms on these geometries. We observe that thenumerical stability of the numerically computed topological characteristic isheavily influenced by the choice of the neural network model, in particular, webriefly discuss a different neural network model, namely Spectral networks,which correctly approximate the topological characteristic of a Calabi-Yau.Using persistent homology, we show that high curvature regions of the manifoldsform clusters near the singular points. For our neural network approximations,we observe a Bogomolov--Yau type inequality $3c_2 \geq c_1^2$ and observe anidentity when our geometries have isolated $A_1$ type singularities. We sketcha proof that $\chi(X~\smallsetminus~\mathrm{Sing}\,{X}) +2~|\mathrm{Sing}\,{X}| = 24$ also holds for our numerical approximations.</description><author>Per Berglund, Giorgi Butbaia, Tristan Hübsch, Vishnu Jejjala, Damián Mayorga Peña, Challenger Mishra, Justin Tan</author><pubDate>Tue, 06 Jun 2023 16:06:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.09801v3</guid></item><item><title>Soft Merging of Experts with Adaptive Routing</title><link>http://arxiv.org/abs/2306.03745v1</link><description>Sparsely activated neural networks with conditional computation learn toroute their inputs through different "expert" subnetworks, providing a form ofmodularity that densely activated models lack. Despite their possible benefits,models with learned routing often underperform their parameter-matched denselyactivated counterparts as well as models that use non-learned heuristic routingstrategies. In this paper, we hypothesize that these shortcomings stem from thegradient estimation techniques used to train sparsely activated models that usenon-differentiable discrete routing decisions. To address this issue, weintroduce Soft Merging of Experts with Adaptive Routing (SMEAR), which avoidsdiscrete routing by using a single "merged" expert constructed via a weightedaverage of all of the experts' parameters. By routing activations through asingle merged expert, SMEAR does not incur a significant increase incomputational costs and enables standard gradient-based training. Weempirically validate that models using SMEAR outperform models that route basedon metadata or learn sparse routing through gradient estimation. Furthermore,we provide qualitative analysis demonstrating that the experts learned viaSMEAR exhibit a significant amount of specialization. All of the code used inour experiments is publicly available.</description><author>Mohammed Muqeeth, Haokun Liu, Colin Raffel</author><pubDate>Tue, 06 Jun 2023 16:04:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03745v1</guid></item><item><title>The Role of Relevance in Fair Ranking</title><link>http://arxiv.org/abs/2305.05608v2</link><description>Online platforms mediate access to opportunity: relevance-based rankingscreate and constrain options by allocating exposure to job openings and jobcandidates in hiring platforms, or sellers in a marketplace. In order to do soresponsibly, these socially consequential systems employ various fairnessmeasures and interventions, many of which seek to allocate exposure based onworthiness. Because these constructs are typically not directly observable,platforms must instead resort to using proxy scores such as relevance and inferthem from behavioral signals such as searcher clicks. Yet, it remains an openquestion whether relevance fulfills its role as such a worthiness score inhigh-stakes fair rankings. In this paper, we combine perspectives and toolsfrom the social sciences, information retrieval, and fairness in machinelearning to derive a set of desired criteria that relevance scores shouldsatisfy in order to meaningfully guide fairness interventions. We thenempirically show that not all of these criteria are met in a case study ofrelevance inferred from biased user click data. We assess the impact of theseviolations on the estimated system fairness and analyze whether existingfairness interventions may mitigate the identified issues. Our analyses andresults surface the pressing need for new approaches to relevance collectionand generation that are suitable for use in fair ranking.</description><author>Aparna Balagopalan, Abigail Z. Jacobs, Asia Biega</author><pubDate>Tue, 06 Jun 2023 16:02:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.05608v2</guid></item><item><title>Responsible Design Patterns for Machine Learning Pipelines</title><link>http://arxiv.org/abs/2306.01788v2</link><description>Integrating ethical practices into the AI development process for artificialintelligence (AI) is essential to ensure safe, fair, and responsible operation.AI ethics involves applying ethical principles to the entire life cycle of AIsystems. This is essential to mitigate potential risks and harms associatedwith AI, such as algorithm biases. To achieve this goal, responsible designpatterns (RDPs) are critical for Machine Learning (ML) pipelines to guaranteeethical and fair outcomes. In this paper, we propose a comprehensive frameworkincorporating RDPs into ML pipelines to mitigate risks and ensure the ethicaldevelopment of AI systems. Our framework comprises new responsible AI designpatterns for ML pipelines identified through a survey of AI ethics and datamanagement experts and validated through real-world scenarios with expertfeedback. The framework guides AI developers, data scientists, andpolicy-makers to implement ethical practices in AI development and deployresponsible AI systems in production.</description><author>Saud Hakem Al Harbi, Lionel Nganyewou Tidjon, Foutse Khomh</author><pubDate>Tue, 06 Jun 2023 16:00:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01788v2</guid></item><item><title>Learning to Do or Learning While Doing: Reinforcement Learning and Bayesian Optimisation for Online Continuous Tuning</title><link>http://arxiv.org/abs/2306.03739v1</link><description>Online tuning of real-world plants is a complex optimisation problem thatcontinues to require manual intervention by experienced human operators.Autonomous tuning is a rapidly expanding field of research, wherelearning-based methods, such as Reinforcement Learning-trained Optimisation(RLO) and Bayesian optimisation (BO), hold great promise for achievingoutstanding plant performance and reducing tuning times. Which algorithm tochoose in different scenarios, however, remains an open question. Here wepresent a comparative study using a routine task in a real particle acceleratoras an example, showing that RLO generally outperforms BO, but is not always thebest choice. Based on the study's results, we provide a clear set of criteriato guide the choice of algorithm for a given tuning task. These can ease theadoption of learning-based autonomous tuning solutions to the operation ofcomplex real-world plants, ultimately improving the availability and pushingthe limits of operability of these facilities, thereby enabling scientific andengineering advancements.</description><author>Jan Kaiser, Chenran Xu, Annika Eichler, Andrea Santamaria Garcia, Oliver Stein, Erik Bründermann, Willi Kuropka, Hannes Dinter, Frank Mayet, Thomas Vinatier, Florian Burkart, Holger Schlarb</author><pubDate>Tue, 06 Jun 2023 15:56:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03739v1</guid></item><item><title>FinRED: A Dataset for Relation Extraction in Financial Domain</title><link>http://arxiv.org/abs/2306.03736v1</link><description>Relation extraction models trained on a source domain cannot be applied on adifferent target domain due to the mismatch between relation sets. In thecurrent literature, there is no extensive open-source relation extractiondataset specific to the finance domain. In this paper, we release FinRED, arelation extraction dataset curated from financial news and earning calltranscripts containing relations from the finance domain. FinRED has beencreated by mapping Wikidata triplets using distance supervision method. Wemanually annotate the test data to ensure proper evaluation. We also experimentwith various state-of-the-art relation extraction models on this dataset tocreate the benchmark. We see a significant drop in their performance on FinREDcompared to the general relation extraction datasets which tells that we needbetter models for financial relation extraction.</description><author>Soumya Sharma, Tapas Nayak, Arusarka Bose, Ajay Kumar Meena, Koustuv Dasgupta, Niloy Ganguly, Pawan Goyal</author><pubDate>Tue, 06 Jun 2023 15:52:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03736v1</guid></item><item><title>A Cross-Linguistic Pressure for Uniform Information Density in Word Order</title><link>http://arxiv.org/abs/2306.03734v1</link><description>While natural languages differ widely in both canonical word order and wordorder flexibility, their word orders still follow shared cross-linguisticstatistical patterns, often attributed to functional pressures. In the effortto identify these pressures, prior work has compared real and counterfactualword orders. Yet one functional pressure has been overlooked in suchinvestigations: the uniform information density (UID) hypothesis, which holdsthat information should be spread evenly throughout an utterance. Here, we askwhether a pressure for UID may have influenced word order patternscross-linguistically. To this end, we use computational models to test whetherreal orders lead to greater information uniformity than counterfactual orders.In our empirical study of 10 typologically diverse languages, we find that: (i)among SVO languages, real word orders consistently have greater uniformity thanreverse word orders, and (ii) only linguistically implausible counterfactualorders consistently exceed the uniformity of real orders. These findings arecompatible with a pressure for information uniformity in the development andusage of natural languages.</description><author>Thomas Hikaru Clark, Clara Meister, Tiago Pimentel, Michael Hahn, Ryan Cotterell, Richard Futrell, Roger Levy</author><pubDate>Tue, 06 Jun 2023 15:52:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03734v1</guid></item><item><title>A Novel Approach To User Agent String Parsing For Vulnerability Analysis Using Mutli-Headed Attention</title><link>http://arxiv.org/abs/2306.03733v1</link><description>The increasing reliance on the internet has led to the proliferation of adiverse set of web-browsers and operating systems (OSs) capable of browsing theweb. User agent strings (UASs) are a component of web browsing that aretransmitted with every Hypertext Transfer Protocol (HTTP) request. They containinformation about the client device and software, which is used by web serversfor various purposes such as content negotiation and security. However, due tothe proliferation of various browsers and devices, parsing UASs is anon-trivial task due to a lack of standardization of UAS formats. Currentrules-based approaches are often brittle and can fail when encountering suchnon-standard formats. In this work, a novel methodology for parsing UASs usingMulti-Headed Attention Based transformers is proposed. The proposed methodologyexhibits strong performance in parsing a variety of UASs with differingformats. Furthermore, a framework to utilize parsed UASs to estimate thevulnerability scores for large sections of publicly visible IT networks orregions is also discussed. The methodology present here can also be easilyextended or deployed for real-time parsing of logs in enterprise settings.</description><author>Dhruv Nandakumar, Sathvik Murli, Ankur Khosla, Kevin Choi, Abdul Rahman, Drew Walsh, Scott Riede, Eric Dull, Edward Bowen</author><pubDate>Tue, 06 Jun 2023 15:49:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03733v1</guid></item><item><title>Modality-Agnostic Learning for Medical Image Segmentation Using Multi-modality Self-distillation</title><link>http://arxiv.org/abs/2306.03730v1</link><description>Medical image segmentation of tumors and organs at risk is a time-consumingyet critical process in the clinic that utilizes multi-modality imaging (e.g,different acquisitions, data types, and sequences) to increase segmentationprecision. In this paper, we propose a novel framework, Modality-Agnosticlearning through Multi-modality Self-dist-illation (MAG-MS), to investigate theimpact of input modalities on medical image segmentation. MAG-MS distillsknowledge from the fusion of multiple modalities and applies it to enhancerepresentation learning for individual modalities. Thus, it provides aversatile and efficient approach to handle limited modalities during testing.Our extensive experiments on benchmark datasets demonstrate the high efficiencyof MAG-MS and its superior segmentation performance than currentstate-of-the-art methods. Furthermore, using MAG-MS, we provide valuableinsight and guidance on selecting input modalities for medical imagesegmentation tasks.</description><author>Qisheng He, Nicholas Summerfield, Ming Dong, Carri Glide-Hurst</author><pubDate>Tue, 06 Jun 2023 15:48:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03730v1</guid></item><item><title>Transforming to Yoked Neural Networks to Improve ANN Structure</title><link>http://arxiv.org/abs/2306.02157v2</link><description>Most existing classical artificial neural networks (ANN) are designed as atree structure to imitate neural networks. In this paper, we argue that theconnectivity of a tree is not sufficient to characterize a neural network. Thenodes of the same level of a tree cannot be connected with each other, i.e.,these neural unit cannot share information with each other, which is a majordrawback of ANN. Although ANN has been significantly improved in recent yearsto more complex structures, such as the directed acyclic graph (DAG), thesemethods also have unidirectional and acyclic bias for ANN. In this paper, wepropose a method to build a bidirectional complete graph for the nodes in thesame level of an ANN, which yokes the nodes of the same level to formulate aneural module. We call our model as YNN in short. YNN promotes the informationtransfer significantly which obviously helps in improving the performance ofthe method. Our YNN can imitate neural networks much better compared with thetraditional ANN. In this paper, we analyze the existing structural bias of ANNand propose a model YNN to efficiently eliminate such structural bias. In ourmodel, nodes also carry out aggregation and transformation of features, andedges determine the flow of information. We further impose auxiliary sparsityconstraint to the distribution of connectedness, which promotes the learnedstructure to focus on critical connections. Finally, based on the optimizedstructure, we also design small neural module structure based on the minimumcut technique to reduce the computational burden of the YNN model. Thislearning process is compatible with the existing networks and different tasks.The obtained quantitative experimental results reflect that the learnedconnectivity is superior to the traditional NN structure.</description><author>Xinshun Liu, Yizhi Fang, Yichao Jiang</author><pubDate>Tue, 06 Jun 2023 15:48:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.02157v2</guid></item><item><title>Prototype-Sample Relation Distillation: Towards Replay-Free Continual Learning</title><link>http://arxiv.org/abs/2303.14771v2</link><description>In Continual learning (CL) balancing effective adaptation while combatingcatastrophic forgetting is a central challenge. Many of the recentbest-performing methods utilize various forms of prior task data, e.g. a replaybuffer, to tackle the catastrophic forgetting problem. Having access toprevious task data can be restrictive in many real-world scenarios, for examplewhen task data is sensitive or proprietary. To overcome the necessity of usingprevious tasks' data, in this work, we start with strong representationlearning methods that have been shown to be less prone to forgetting. Wepropose a holistic approach to jointly learn the representation and classprototypes while maintaining the relevance of old class prototypes and theirembedded similarities. Specifically, samples are mapped to an embedding spacewhere the representations are learned using a supervised contrastive loss.Class prototypes are evolved continually in the same latent space, enablinglearning and prediction at any point. To continually adapt the prototypeswithout keeping any prior task data, we propose a novel distillation loss thatconstrains class prototypes to maintain relative similarities as compared tonew task data. This method yields state-of-the-art performance in thetask-incremental setting, outperforming methods relying on large amounts ofdata, and provides strong performance in the class-incremental setting withoutusing any stored data points.</description><author>Nader Asadi, MohammadReza Davari, Sudhir Mudur, Rahaf Aljundi, Eugene Belilovsky</author><pubDate>Tue, 06 Jun 2023 15:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.14771v2</guid></item><item><title>Towards Visual Foundational Models of Physical Scenes</title><link>http://arxiv.org/abs/2306.03727v1</link><description>We describe a first step towards learning general-purpose visualrepresentations of physical scenes using only image prediction as a trainingcriterion. To do so, we first define "physical scene" and show that, eventhough different agents may maintain different representations of the samescene, the underlying physical scene that can be inferred is unique. Then, weshow that NeRFs cannot represent the physical scene, as they lack extrapolationmechanisms. Those, however, could be provided by Diffusion Models, at least intheory. To test this hypothesis empirically, NeRFs can be combined withDiffusion Models, a process we refer to as NeRF Diffusion, used as unsupervisedrepresentations of the physical scene. Our analysis is limited to visual data,without external grounding mechanisms that can be provided by independentsensory modalities.</description><author>Chethan Parameshwara, Alessandro Achille, Matthew Trager, Xiaolong Li, Jiawei Mo, Matthew Trager, Ashwin Swaminathan, CJ Taylor, Dheera Venkatraman, Xiaohan Fei, Stefano Soatto</author><pubDate>Tue, 06 Jun 2023 15:45:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03727v1</guid></item><item><title>Exploring Model Dynamics for Accumulative Poisoning Discovery</title><link>http://arxiv.org/abs/2306.03726v1</link><description>Adversarial poisoning attacks pose huge threats to various machine learningapplications. Especially, the recent accumulative poisoning attacks show thatit is possible to achieve irreparable harm on models via a sequence ofimperceptible attacks followed by a trigger batch. Due to the limiteddata-level discrepancy in real-time data streaming, current defensive methodsare indiscriminate in handling the poison and clean samples. In this paper, wedive into the perspective of model dynamics and propose a novel informationmeasure, namely, Memorization Discrepancy, to explore the defense via themodel-level information. By implicitly transferring the changes in the datamanipulation to that in the model outputs, Memorization Discrepancy candiscover the imperceptible poison samples based on their distinct dynamics fromthe clean samples. We thoroughly explore its properties and proposeDiscrepancy-aware Sample Correction (DSC) to defend against accumulativepoisoning attacks. Extensive experiments comprehensively characterizedMemorization Discrepancy and verified its effectiveness. The code is publiclyavailable at: https://github.com/tmlr-group/Memorization-Discrepancy.</description><author>Jianing Zhu, Xiawei Guo, Jiangchao Yao, Chao Du, Li He, Shuo Yuan, Tongliang Liu, Liang Wang, Bo Han</author><pubDate>Tue, 06 Jun 2023 15:45:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03726v1</guid></item><item><title>Towards Memory-Efficient Training for Extremely Large Output Spaces -- Learning with 500k Labels on a Single Commodity GPU</title><link>http://arxiv.org/abs/2306.03725v1</link><description>In classification problems with large output spaces (up to millions oflabels), the last layer can require an enormous amount of memory. Using sparseconnectivity would drastically reduce the memory requirements, but as we showbelow, it can result in much diminished predictive performance of the model.Fortunately, we found that this can be mitigated by introducing a penultimatelayer of intermediate size. We further demonstrate that one can constrain theconnectivity of the sparse layer to be uniform, in the sense that each outputneuron will have the exact same number of incoming connections. This allows forefficient implementations of sparse matrix multiplication and connectionredistribution on GPU hardware. Via a custom CUDA implementation, we show thatthe proposed approach can scale to datasets with 670,000 labels on a singlecommodity GPU with only 4GB memory.</description><author>Erik Schultheis, Rohit Babbar</author><pubDate>Tue, 06 Jun 2023 15:44:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03725v1</guid></item><item><title>Financial Numeric Extreme Labelling: A Dataset and Benchmarking for XBRL Tagging</title><link>http://arxiv.org/abs/2306.03723v1</link><description>The U.S. Securities and Exchange Commission (SEC) mandates all publiccompanies to file periodic financial statements that should contain numeralsannotated with a particular label from a taxonomy. In this paper, we formulatethe task of automating the assignment of a label to a particular numeral spanin a sentence from an extremely large label set. Towards this task, we releasea dataset, Financial Numeric Extreme Labelling (FNXL), annotated with 2,794labels. We benchmark the performance of the FNXL dataset by formulating thetask as (a) a sequence labelling problem and (b) a pipeline with spanextraction followed by Extreme Classification. Although the two approachesperform comparably, the pipeline solution provides a slight edge for the leastfrequent labels.</description><author>Soumya Sharma, Subhendu Khatuya, Manjunath Hegde, Afreen Shaikh. Koustuv Dasgupta, Pawan Goyal, Niloy Ganguly</author><pubDate>Tue, 06 Jun 2023 15:41:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03723v1</guid></item><item><title>Evaluating the Effectiveness of Natural Language Inference for Hate Speech Detection in Languages with Limited Labeled Data</title><link>http://arxiv.org/abs/2306.03722v1</link><description>Most research on hate speech detection has focused on English where asizeable amount of labeled training data is available. However, to expand hatespeech detection into more languages, approaches that require minimal trainingdata are needed. In this paper, we test whether natural language inference(NLI) models which perform well in zero- and few-shot settings can benefit hatespeech detection performance in scenarios where only a limited amount oflabeled data is available in the target language. Our evaluation on fivelanguages demonstrates large performance improvements of NLI fine-tuning overdirect fine-tuning in the target language. However, the effectiveness ofprevious work that proposed intermediate fine-tuning on English data is hard tomatch. Only in settings where the English training data does not match the testdomain, can our customised NLI-formulation outperform intermediate fine-tuningon English. Based on our extensive experiments, we propose a set ofrecommendations for hate speech detection in languages where minimal labeledtraining data is available.</description><author>Janis Goldzycher, Moritz Preisig, Chantal Amrhein, Gerold Schneider</author><pubDate>Tue, 06 Jun 2023 15:40:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03722v1</guid></item><item><title>OmniDet: Surround View Cameras based Multi-task Visual Perception Network for Autonomous Driving</title><link>http://arxiv.org/abs/2102.07448v3</link><description>Surround View fisheye cameras are commonly deployed in automated driving for360\deg{} near-field sensing around the vehicle. This work presents amulti-task visual perception network on unrectified fisheye images to enablethe vehicle to sense its surrounding environment. It consists of six primarytasks necessary for an autonomous driving system: depth estimation, visualodometry, semantic segmentation, motion segmentation, object detection, andlens soiling detection. We demonstrate that the jointly trained model performsbetter than the respective single task versions. Our multi-task model has ashared encoder providing a significant computational advantage and hassynergized decoders where tasks support each other. We propose a novel camerageometry based adaptation mechanism to encode the fisheye distortion model bothat training and inference. This was crucial to enable training on the WoodScapedataset, comprised of data from different parts of the world collected by 12different cameras mounted on three different cars with different intrinsics andviewpoints. Given that bounding boxes is not a good representation fordistorted fisheye images, we also extend object detection to use a polygon withnon-uniformly sampled vertices. We additionally evaluate our model on standardautomotive datasets, namely KITTI and Cityscapes. We obtain thestate-of-the-art results on KITTI for depth estimation and pose estimationtasks and competitive performance on the other tasks. We perform extensiveablation studies on various architecture choices and task weightingmethodologies. A short video at https://youtu.be/xbSjZ5OfPes providesqualitative results.</description><author>Varun Ravi Kumar, Senthil Yogamani, Hazem Rashed, Ganesh Sistu, Christian Witt, Isabelle Leang, Stefan Milz, Patrick Mäder</author><pubDate>Tue, 06 Jun 2023 15:31:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2102.07448v3</guid></item><item><title>Self-Adaptive Named Entity Recognition by Retrieving Unstructured Knowledge</title><link>http://arxiv.org/abs/2210.07523v3</link><description>Although named entity recognition (NER) helps us to extract domain-specificentities from text (e.g., artists in the music domain), it is costly to createa large amount of training data or a structured knowledge base to performaccurate NER in the target domain. Here, we propose self-adaptive NER, whichretrieves external knowledge from unstructured text to learn the usages ofentities that have not been learned well. To retrieve useful knowledge for NER,we design an effective two-stage model that retrieves unstructured knowledgeusing uncertain entities as queries. Our model predicts the entities in theinput and then finds those of which the prediction is not confident. Then, itretrieves knowledge by using these uncertain entities as queries andconcatenates the retrieved text to the original input to revise the prediction.Experiments on CrossNER datasets demonstrated that our model outperforms strongbaselines by 2.35 points in F1 metric.</description><author>Kosuke Nishida, Naoki Yoshinaga, Kyosuke Nishida</author><pubDate>Tue, 06 Jun 2023 15:30:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.07523v3</guid></item><item><title>Emotion-Conditioned Melody Harmonization with Hierarchical Variational Autoencoder</title><link>http://arxiv.org/abs/2306.03718v1</link><description>Existing melody harmonization models have made great progress in improvingthe quality of generated harmonies, but most of them ignored the emotionsbeneath the music. Meanwhile, the variability of harmonies generated byprevious methods is insufficient. To solve these problems, we propose a novelLSTM-based Hierarchical Variational Auto-Encoder (LHVAE) to investigate theinfluence of emotional conditions on melody harmonization, while improving thequality of generated harmonies and capturing the abundant variability of chordprogressions. Specifically, LHVAE incorporates latent variables and emotionalconditions at different levels (piece- and bar-level) to model the global andlocal music properties. Additionally, we introduce an attention-based melodycontext vector at each step to better learn the correspondence between melodiesand harmonies. Experimental results of the objective evaluation show that ourproposed model outperforms other LSTM-based models. Through subjectiveevaluation, we conclude that only altering the chords hardly changes theoverall emotion of the music. The qualitative analysis demonstrates the abilityof our model to generate variable harmonies.</description><author>Shulei Ji, Xinyu Yang</author><pubDate>Tue, 06 Jun 2023 15:28:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03718v1</guid></item><item><title>Toward Efficient Gradient-Based Value Estimation</title><link>http://arxiv.org/abs/2301.13757v2</link><description>Gradient-based methods for value estimation in reinforcement learning havefavorable stability properties, but they are typically much slower thanTemporal Difference (TD) learning methods. We study the root causes of thisslowness and show that Mean Square Bellman Error (MSBE) is an ill-conditionedloss function in the sense that its Hessian has large condition-number. Toresolve the adverse effect of poor conditioning of MSBE on gradient basedmethods, we propose a low complexity batch-free proximal method thatapproximately follows the Gauss-Newton direction and is asymptotically robustto parameterization. Our main algorithm, called RANS, is efficient in the sensethat it is significantly faster than the residual gradient methods while havingalmost the same computational complexity, and is competitive with TD on theclassic problems that we tested.</description><author>Arsalan Sharifnassab, Richard Sutton</author><pubDate>Tue, 06 Jun 2023 15:28:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.13757v2</guid></item><item><title>Description Logics with Abstraction and Refinement</title><link>http://arxiv.org/abs/2306.03717v1</link><description>Ontologies often require knowledge representation on multiple levels ofabstraction, but description logics (DLs) are not well-equipped for supportingthis. We propose an extension of DLs in which abstraction levels arefirst-class citizens and which provides explicit operators for the abstractionand refinement of concepts and roles across multiple abstraction levels, basedon conjunctive queries. We prove that reasoning in the resulting family of DLsis decidable while several seemingly harmless variations turn out to beundecidable. We also pinpoint the precise complexity of our logics and severalrelevant fragments.</description><author>Carsten Lutz, Lukas Schulze</author><pubDate>Tue, 06 Jun 2023 15:27:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03717v1</guid></item></channel></rss>