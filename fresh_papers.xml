<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Sun, 25 Aug 2024 13:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>DreamCinema: Cinematic Transfer with Free Camera and 3D Character</title><link>http://arxiv.org/abs/2408.12601v1</link><description>We are living in a flourishing era of digital media, where everyone has thepotential to become a personal filmmaker. Current research on cinematictransfer empowers filmmakers to reproduce and manipulate the visual elements(e.g., cinematography and character behaviors) from classic shots. However,characters in the reimagined films still rely on manual crafting, whichinvolves significant technical complexity and high costs, making itunattainable for ordinary users. Furthermore, their estimated cinematographylacks smoothness due to inadequate capturing of inter-frame motion and modelingof physical trajectories. Fortunately, the remarkable success of 2D and 3D AIGChas opened up the possibility of efficiently generating characters tailored tousers' needs, diversifying cinematography. In this paper, we proposeDreamCinema, a novel cinematic transfer framework that pioneers generative AIinto the film production paradigm, aiming at facilitating user-friendly filmcreation. Specifically, we first extract cinematic elements (i.e., human andcamera pose) and optimize the camera trajectory. Then, we apply a charactergenerator to efficiently create 3D high-quality characters with a humanstructure prior. Finally, we develop a structure-guided motion transferstrategy to incorporate generated characters into film creation and transfer itvia 3D graphics engines smoothly. Extensive experiments demonstrate theeffectiveness of our method for creating high-quality films with free cameraand 3D characters.</description><author>Weiliang Chen, Fangfu Liu, Diankun Wu, Haowen Sun, Haixu Song, Yueqi Duan</author><pubDate>Thu, 22 Aug 2024 17:59:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12601v1</guid></item><item><title>Controllable Text Generation for Large Language Models: A Survey</title><link>http://arxiv.org/abs/2408.12599v1</link><description>In Natural Language Processing (NLP), Large Language Models (LLMs) havedemonstrated high text generation quality. However, in real-world applications,LLMs must meet increasingly complex requirements. Beyond avoiding misleading orinappropriate content, LLMs are also expected to cater to specific user needs,such as imitating particular writing styles or generating text with poeticrichness. These varied demands have driven the development of Controllable TextGeneration (CTG) techniques, which ensure that outputs adhere to predefinedcontrol conditions--such as safety, sentiment, thematic consistency, andlinguistic style--while maintaining high standards of helpfulness, fluency, anddiversity. This paper systematically reviews the latest advancements in CTG for LLMs,offering a comprehensive definition of its core concepts and clarifying therequirements for control conditions and text quality. We categorize CTG tasksinto two primary types: content control and attribute control. The key methodsare discussed, including model retraining, fine-tuning, reinforcement learning,prompt engineering, latent space manipulation, and decoding-time intervention.We analyze each method's characteristics, advantages, and limitations,providing nuanced insights for achieving generation control. Additionally, wereview CTG evaluation methods, summarize its applications across domains, andaddress key challenges in current research, including reduced fluency andpracticality. We also propose several appeals, such as placing greater emphasison real-world applications in future research. This paper aims to offervaluable guidance to researchers and developers in the field. Our referencelist and Chinese version are open-sourced athttps://github.com/IAAR-Shanghai/CTGSurvey.</description><author>Xun Liang, Hanyu Wang, Yezhaohui Wang, Shichao Song, Jiawei Yang, Simin Niu, Jie Hu, Dan Liu, Shunyu Yao, Feiyu Xiong, Zhiyu Li</author><pubDate>Thu, 22 Aug 2024 17:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12599v1</guid></item><item><title>ND-SDF: Learning Normal Deflection Fields for High-Fidelity Indoor Reconstruction</title><link>http://arxiv.org/abs/2408.12598v1</link><description>Neural implicit reconstruction via volume rendering has demonstrated itseffectiveness in recovering dense 3D surfaces. However, it is non-trivial tosimultaneously recover meticulous geometry and preserve smoothness acrossregions with differing characteristics. To address this issue, previous methodstypically employ geometric priors, which are often constrained by theperformance of the prior models. In this paper, we propose ND-SDF, which learnsa Normal Ddeflection field to represent the angular deviation between the scenenormal and the prior normal. Unlike previous methods that uniformly applygeometric priors on all samples, introducing significant bias in accuracy, ourproposed normal deflection field dynamically learns and adapts the utilizationof samples based on their specific characteristics, thereby improving both theaccuracy and effectiveness of the model. Our method not only obtains smoothweakly textured regions such as walls and floors but also preserves thegeometric details of complex structures. In addition, we introduce a novel raysampling strategy based on the deflection angle to facilitate the unbiasedrendering process, which significantly improves the quality and accuracy ofintricate surfaces, especially on thin structures. Consistent improvements onvarious challenging datasets demonstrate the superiority of our method.</description><author>Ziyu Tang, Weicai Ye, Yifan Wang, Di Huang, Hujun Bao, Tong He, Guofeng Zhang</author><pubDate>Thu, 22 Aug 2024 17:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12598v1</guid></item><item><title>Non-Homophilic Graph Pre-Training and Prompt Learning</title><link>http://arxiv.org/abs/2408.12594v1</link><description>Graphs are ubiquitous for modeling complex relationships between objectsacross various fields. Graph neural networks (GNNs) have become a mainstreamtechnique for graph-based applications, but their performance heavily relies onabundant labeled data. To reduce labeling requirement, pre-training and promptlearning has become a popular alternative. However, most existing promptmethods do not differentiate homophilic and heterophilic characteristics ofreal-world graphs. In particular, many real-world graphs are non-homophilic,not strictly or uniformly homophilic with mixing homophilic and heterophilicpatterns, exhibiting varying non-homophilic characteristics across graphs andnodes. In this paper, we propose ProNoG, a novel pre-training and promptlearning framework for such non-homophilic graphs. First, we analyze existinggraph pre-training methods, providing theoretical insights into the choice ofpre-training tasks. Second, recognizing that each node exhibits uniquenon-homophilic characteristics, we propose a conditional network tocharacterize the node-specific patterns in downstream tasks. Finally, wethoroughly evaluate and analyze ProNoG through extensive experiments on tenpublic datasets.</description><author>Xingtong Yu, Jie Zhang, Yuan Fang, Renhe Jiang</author><pubDate>Thu, 22 Aug 2024 17:57:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12594v1</guid></item><item><title>Automating Deformable Gasket Assembly</title><link>http://arxiv.org/abs/2408.12593v1</link><description>In Gasket Assembly, a deformable gasket must be aligned and pressed into anarrow channel. This task is common for sealing surfaces in the manufacturingof automobiles, appliances, electronics, and other products. Gasket Assembly isa long-horizon, high-precision task and the gasket must align with the channeland be fully pressed in to achieve a secure fit. To compare approaches, wepresent 4 methods for Gasket Assembly: one policy from deep imitation learningand three procedural algorithms. We evaluate these methods with 100 physicaltrials. Results suggest that the Binary+ algorithm succeeds in 10/10 on thestraight channel whereas the learned policy based on 250 human teleoperateddemonstrations succeeds in 8/10 trials and is significantly slower. Code, CADmodels, videos, and data can be found athttps://berkeleyautomation.github.io/robot-gasket/</description><author>Simeon Adebola, Tara Sadjadpour, Karim El-Refai, Will Panitch, Zehan Ma, Roy Lin, Tianshuang Qiu, Shreya Ganti, Charlotte Le, Jaimyn Drake, Ken Goldberg</author><pubDate>Thu, 22 Aug 2024 17:57:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12593v1</guid></item><item><title>Understanding Reference Policies in Direct Preference Optimization</title><link>http://arxiv.org/abs/2407.13709v2</link><description>Direct Preference Optimization (DPO) has become a widely used training methodfor the instruction fine-tuning of large language models (LLMs). In this work,we explore an under-investigated aspect of DPO - its dependency on thereference model or policy. Such reference policies, typically instantiated asthe model to be further fine-tuned, are important since they can impose anupper limit on DPO's effectiveness. Therefore, we address three relatedresearch questions in this work. First, we explore the optimal strength of theKL divergence constraint in DPO, which penalizes deviations from the referencepolicy, and find that DPO is sensitive to this strength. Next, we examine thenecessity of the KL-constraint from the reference policies in DPO by providingboth theoretical and empirical comparisons between DPO and related learningobjectives, demonstrating DPO's superiority in this controlled setting.Additionally, we investigate whether DPO benefits from stronger referencepolicies, finding that a stronger reference policy can lead to improvedperformance, but only when it is similar to the model being fine-tuned. Ourfindings highlight the confounding role of reference policies in DPO and offerinsights for best practices, while also identifying open research questions forfuture studies.</description><author>Yixin Liu, Pengfei Liu, Arman Cohan</author><pubDate>Thu, 22 Aug 2024 17:56:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.13709v2</guid></item><item><title>Differentiable Logic Programming for Distant Supervision</title><link>http://arxiv.org/abs/2408.12591v1</link><description>We introduce a new method for integrating neural networks with logicprogramming in Neural-Symbolic AI (NeSy), aimed at learning with distantsupervision, in which direct labels are unavailable. Unlike prior methods, ourapproach does not depend on symbolic solvers for reasoning about missinglabels. Instead, it evaluates logical implications and constraints in adifferentiable manner by embedding both neural network outputs and logicprograms into matrices. This method facilitates more efficient learning underdistant supervision. We evaluated our approach against existing methods whilemaintaining a constant volume of training data. The findings indicate that ourmethod not only matches or exceeds the accuracy of other methods across varioustasks but also speeds up the learning process. These results highlight thepotential of our approach to enhance both accuracy and learning efficiency inNeSy applications.</description><author>Akihiro Takemura, Katsumi Inoue</author><pubDate>Thu, 22 Aug 2024 17:55:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12591v1</guid></item><item><title>SST: Multi-Scale Hybrid Mamba-Transformer Experts for Long-Short Range Time Series Forecasting</title><link>http://arxiv.org/abs/2404.14757v2</link><description>Despite significant progress in time series forecasting, existing forecastersoften overlook the heterogeneity between long-range and short-range timeseries, leading to performance degradation in practical applications. In thiswork, we highlight the need of distinct objectives tailored to differentranges. We point out that time series can be decomposed into global patternsand local variations, which should be addressed separately in long- andshort-range time series. To meet the objectives, we propose a multi-scalehybrid Mamba-Transformer experts model State Space Transformer (SST). SSTleverages Mamba as an expert to extract global patterns in coarse-grainedlong-range time series, and Local Window Transformer (LWT), the other expert tofocus on capturing local variations in fine-grained short-range time series.With an input-dependent mechanism, State Space Model (SSM)-based Mamba is ableto selectively retain long-term patterns and filter out fluctuations, while LWTemploys a local window to enhance locality-awareness capability, thuseffectively capturing local variations. To adaptively integrate the globalpatterns and local variations, a long-short router dynamically adjustscontributions of the two experts. SST achieves superior performance withscaling linearly $O(L)$ on time series length $L$. The comprehensiveexperiments demonstrate the SST can achieve SOTA results in long-short rangetime series forecasting while maintaining low memory footprint andcomputational cost. The code of SST is available athttps://github.com/XiongxiaoXu/SST.</description><author>Xiongxiao Xu, Canyu Chen, Yueqing Liang, Baixiang Huang, Guangji Bai, Liang Zhao, Kai Shu</author><pubDate>Thu, 22 Aug 2024 17:55:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.14757v2</guid></item><item><title>xGen-VideoSyn-1: High-fidelity Text-to-Video Synthesis with Compressed Representations</title><link>http://arxiv.org/abs/2408.12590v1</link><description>We present xGen-VideoSyn-1, a text-to-video (T2V) generation model capable ofproducing realistic scenes from textual descriptions. Building on recentadvancements, such as OpenAI's Sora, we explore the latent diffusion model(LDM) architecture and introduce a video variational autoencoder (VidVAE).VidVAE compresses video data both spatially and temporally, significantlyreducing the length of visual tokens and the computational demands associatedwith generating long-sequence videos. To further address the computationalcosts, we propose a divide-and-merge strategy that maintains temporalconsistency across video segments. Our Diffusion Transformer (DiT) modelincorporates spatial and temporal self-attention layers, enabling robustgeneralization across different timeframes and aspect ratios. We have devised adata processing pipeline from the very beginning and collected over 13Mhigh-quality video-text pairs. The pipeline includes multiple steps such asclipping, text detection, motion estimation, aesthetics scoring, and densecaptioning based on our in-house video-LLM model. Training the VidVAE and DiTmodels required approximately 40 and 642 H100 days, respectively. Our modelsupports over 14-second 720p video generation in an end-to-end way anddemonstrates competitive performance against state-of-the-art T2V models.</description><author>Can Qin, Congying Xia, Krithika Ramakrishnan, Michael Ryoo, Lifu Tu, Yihao Feng, Manli Shu, Honglu Zhou, Anas Awadalla, Jun Wang, Senthil Purushwalkam, Le Xue, Yingbo Zhou, Huan Wang, Silvio Savarese, Juan Carlos Niebles, Zeyuan Chen, Ran Xu, Caiming Xiong</author><pubDate>Thu, 22 Aug 2024 17:55:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12590v1</guid></item><item><title>Real-Time Video Generation with Pyramid Attention Broadcast</title><link>http://arxiv.org/abs/2408.12588v1</link><description>We present Pyramid Attention Broadcast (PAB), a real-time, high quality andtraining-free approach for DiT-based video generation. Our method is founded onthe observation that attention difference in the diffusion process exhibits aU-shaped pattern, indicating significant redundancy. We mitigate this bybroadcasting attention outputs to subsequent steps in a pyramid style. Itapplies different broadcast strategies to each attention based on theirvariance for best efficiency. We further introduce broadcast sequence parallelfor more efficient distributed inference. PAB demonstrates superior resultsacross three models compared to baselines, achieving real-time generation forup to 720p videos. We anticipate that our simple yet effective method willserve as a robust baseline and facilitate future research and application forvideo generation.</description><author>Xuanlei Zhao, Xiaolong Jin, Kai Wang, Yang You</author><pubDate>Thu, 22 Aug 2024 17:54:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12588v1</guid></item><item><title>Identifying the Best Arm in the Presence of Global Environment Shifts</title><link>http://arxiv.org/abs/2408.12581v1</link><description>This paper formulates a new Best-Arm Identification problem in thenon-stationary stochastic bandits setting, where the means of all arms areshifted in the same way due to a global influence of the environment. The aimis to identify the unique best arm across environmental change given a fixedtotal budget. While this setting can be regarded as a special case ofAdversarial Bandits or Corrupted Bandits, we demonstrate that existingsolutions tailored to those settings do not fully utilise the nature of thisglobal influence, and thus, do not work well in practice (despite theirtheoretical guarantees). To overcome this issue, in this paper we develop anovel selection policy that is consistent and robust in dealing with globalenvironmental shifts. We then propose an allocation policy, LinLUCB, whichexploits information about global shifts across all arms in each environment.Empirical tests depict a significant improvement in our policies against otherexisting methods.</description><author>Phurinut Srisawad, Juergen Branke, Long Tran-Thanh</author><pubDate>Thu, 22 Aug 2024 17:47:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12581v1</guid></item><item><title>RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment</title><link>http://arxiv.org/abs/2408.12579v1</link><description>Large Language Models (LLMs) like GPT-4, MedPaLM-2, and Med-Gemini achieveperformance competitively with human experts across various medical benchmarks.However, they still face challenges in making professional diagnoses akin tophysicians, particularly in efficiently gathering patient information andreasoning the final diagnosis. To this end, we introduce the RuleAlignframework, designed to align LLMs with specific diagnostic rules. We develop amedical dialogue dataset comprising rule-based communications between patientsand physicians and design an alignment learning approach through preferencelearning. Experimental results demonstrate the effectiveness of the proposedapproach. We hope that our work can serve as an inspiration for exploring thepotential of LLMs as AI physicians.</description><author>Xiaohan Wang, Xiaoyan Yang, Yuqi Zhu, Yue Shen, Jian Wang, Peng Wei, Lei Liang, Jinjie Gu, Huajun Chen, Ningyu Zhang</author><pubDate>Thu, 22 Aug 2024 17:44:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12579v1</guid></item><item><title>A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language</title><link>http://arxiv.org/abs/2408.12578v1</link><description>Increase in data, size, or compute can lead to sudden learning of specificcapabilities by a neural network -- a phenomenon often called "emergence".Beyond scientific understanding, establishing the causal factors underlyingsuch emergent capabilities is crucial to enable risk regulation frameworks forAI. In this work, we seek inspiration from study of emergent properties inother fields and propose a phenomenological definition for the concept in thecontext of neural networks. Our definition implicates the acquisition ofspecific structures underlying the data-generating process as a cause of suddenperformance growth for specific, narrower tasks. We empirically investigatethis definition by proposing an experimental system grounded in acontext-sensitive formal language and find that Transformers trained to performtasks on top of strings from this language indeed exhibit emergentcapabilities. Specifically, we show that once the language's underlying grammarand context-sensitivity inducing structures are learned by the model,performance on narrower tasks suddenly begins to improve. We then analogize ournetwork's learning dynamics with the process of percolation on a bipartitegraph, establishing a formal phase transition model that predicts the shift inthe point of emergence observed in experiment when changing the data structure.Overall, our experimental and theoretical frameworks yield a step towardsbetter defining, characterizing, and predicting emergence in neural networks.</description><author>Ekdeep Singh Lubana, Kyogo Kawaguchi, Robert P. Dick, Hidenori Tanaka</author><pubDate>Thu, 22 Aug 2024 17:44:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12578v1</guid></item><item><title>Enhanced Parking Perception by Multi-Task Fisheye Cross-view Transformers</title><link>http://arxiv.org/abs/2408.12575v1</link><description>Current parking area perception algorithms primarily focus on detectingvacant slots within a limited range, relying on error-prone homographicprojection for both labeling and inference. However, recent advancements inAdvanced Driver Assistance System (ADAS) require interaction with end-usersthrough comprehensive and intelligent Human-Machine Interfaces (HMIs). Theseinterfaces should present a complete perception of the parking area going fromdistinguishing vacant slots' entry lines to the orientation of other parkedvehicles. This paper introduces Multi-Task Fisheye Cross View Transformers (MTF-CVT), which leverages features from a four-camera fisheye Surround-viewCamera System (SVCS) with multihead attentions to create a detailed Bird-EyeView (BEV) grid feature map. Features are processed by both a segmentationdecoder and a Polygon-Yolo based object detection decoder for parking slots andvehicles. Trained on data labeled using LiDAR, MT F-CVT positions objectswithin a 25m x 25m real open-road scenes with an average error of only 20 cm.Our larger model achieves an F-1 score of 0.89. Moreover the smaller modeloperates at 16 fps on an Nvidia Jetson Orin embedded board, with similardetection results to the larger one. MT F-CVT demonstrates robustgeneralization capability across different vehicles and camera rigconfigurations. A demo video from an unseen vehicle and camera rig is availableat: https://streamable.com/jjw54x.</description><author>Antonyo Musabini, Ivan Novikov, Sana Soula, Christel Leonet, Lihao Wang, Rachid Benmokhtar, Fabian Burger, Thomas Boulay, Xavier Perrotton</author><pubDate>Thu, 22 Aug 2024 17:42:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12575v1</guid></item><item><title>MuMA-ToM: Multi-modal Multi-Agent Theory of Mind</title><link>http://arxiv.org/abs/2408.12574v1</link><description>Understanding people's social interactions in complex real-world scenariosoften relies on intricate mental reasoning. To truly understand how and whypeople interact with one another, we must infer the underlying mental statesthat give rise to the social interactions, i.e., Theory of Mind reasoning inmulti-agent interactions. Additionally, social interactions are oftenmulti-modal -- we can watch people's actions, hear their conversations, and/orread about their past behaviors. For AI systems to successfully and safelyinteract with people in real-world environments, they also need to understandpeople's mental states as well as their inferences about each other's mentalstates based on multi-modal information about their interactions. For this, weintroduce MuMA-ToM, a Multi-modal Multi-Agent Theory of Mind benchmark.MuMA-ToM is the first multi-modal Theory of Mind benchmark that evaluatesmental reasoning in embodied multi-agent interactions. In MuMA-ToM, we providevideo and text descriptions of people's multi-modal behavior in realistichousehold environments. Based on the context, we then ask questions aboutpeople's goals, beliefs, and beliefs about others' goals. We validated MuMA-ToMin a human experiment and provided a human baseline. We also proposed a novelmulti-modal, multi-agent ToM model, LIMP (Language model-based InverseMulti-agent Planning). Our experimental results show that LIMP significantlyoutperforms state-of-the-art methods, including large multi-modal models (e.g.,GPT-4o, Gemini-1.5 Pro) and a recent multi-modal ToM model, BIP-ALM.</description><author>Haojun Shi, Suyu Ye, Xinyu Fang, Chuanyang Jin, Layla Isik, Yen-Ling Kuo, Tianmin Shu</author><pubDate>Thu, 22 Aug 2024 17:41:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12574v1</guid></item><item><title>Jamba-1.5: Hybrid Transformer-Mamba Models at Scale</title><link>http://arxiv.org/abs/2408.12570v1</link><description>We present Jamba-1.5, new instruction-tuned large language models based onour Jamba architecture. Jamba is a hybrid Transformer-Mamba mixture of expertsarchitecture, providing high throughput and low memory usage across contextlengths, while retaining the same or better quality as Transformer models. Werelease two model sizes: Jamba-1.5-Large, with 94B active parameters, andJamba-1.5-Mini, with 12B active parameters. Both models are fine-tuned for avariety of conversational and instruction-following capabilties, and have aneffective context length of 256K tokens, the largest amongst open-weightmodels. To support cost-effective inference, we introduce ExpertsInt8, a novelquantization technique that allows fitting Jamba-1.5-Large on a machine with 880GB GPUs when processing 256K-token contexts without loss of quality. Whenevaluated on a battery of academic and chatbot benchmarks, Jamba-1.5 modelsachieve excellent results while providing high throughput and outperformingother open-weight models on long-context benchmarks. The model weights for bothsizes are publicly available under the Jamba Open Model License and we releaseExpertsInt8 as open source.</description><author>Jamba Team, Barak Lenz, Alan Arazi, Amir Bergman, Avshalom Manevich, Barak Peleg, Ben Aviram, Chen Almagor, Clara Fridman, Dan Padnos, Daniel Gissin, Daniel Jannai, Dor Muhlgay, Dor Zimberg, Edden M Gerber, Elad Dolev, Eran Krakovsky, Erez Safahi, Erez Schwartz, Gal Cohen, Gal Shachaf, Haim Rozenblum, Hofit Bata, Ido Blass, Inbal Magar, Itay Dalmedigos, Jhonathan Osin, Julie Fadlon, Maria Rozman, Matan Danos, Michael Gokhman, Mor Zusman, Naama Gidron, Nir Ratner, Noam Gat, Noam Rozen, Oded Fried, Ohad Leshno, Omer Antverg, Omri Abend, Opher Lieber, Or Dagan, Orit Cohavi, Raz Alon, Ro'i Belson, Roi Cohen, Rom Gilad, Roman Glozman, Shahar Lev, Shaked Meirom, Tal Delbari, Tal Ness, Tomer Asida, Tom Ben Gal, Tom Braude, Uriya Pumerantz, Yehoshua Cohen, Yonatan Belinkov, Yuval Globerson, Yuval </author><pubDate>Thu, 22 Aug 2024 17:38:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12570v1</guid></item><item><title>Sapiens: Foundation for Human Vision Models</title><link>http://arxiv.org/abs/2408.12569v1</link><description>We present Sapiens, a family of models for four fundamental human-centricvision tasks - 2D pose estimation, body-part segmentation, depth estimation,and surface normal prediction. Our models natively support 1K high-resolutioninference and are extremely easy to adapt for individual tasks by simplyfine-tuning models pretrained on over 300 million in-the-wild human images. Weobserve that, given the same computational budget, self-supervised pretrainingon a curated dataset of human images significantly boosts the performance for adiverse set of human-centric tasks. The resulting models exhibit remarkablegeneralization to in-the-wild data, even when labeled data is scarce orentirely synthetic. Our simple model design also brings scalability - modelperformance across tasks improves as we scale the number of parameters from 0.3to 2 billion. Sapiens consistently surpasses existing baselines across varioushuman-centric benchmarks. We achieve significant improvements over the priorstate-of-the-art on Humans-5K (pose) by 7.6 mAP, Humans-2K (part-seg) by 17.1mIoU, Hi4D (depth) by 22.4% relative RMSE, and THuman2 (normal) by 53.5%relative angular error.</description><author>Rawal Khirodkar, Timur Bagautdinov, Julieta Martinez, Su Zhaoen, Austin James, Peter Selednik, Stuart Anderson, Shunsuke Saito</author><pubDate>Thu, 22 Aug 2024 17:37:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12569v1</guid></item><item><title>Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune CNNs and Transformers</title><link>http://arxiv.org/abs/2408.12568v1</link><description>To solve ever more complex problems, Deep Neural Networks are scaled tobillions of parameters, leading to huge computational costs. An effectiveapproach to reduce computational requirements and increase efficiency is toprune unnecessary components of these often over-parameterized networks.Previous work has shown that attribution methods from the field of eXplainableAI serve as effective means to extract and prune the least relevant networkcomponents in a few-shot fashion. We extend the current state by proposing toexplicitly optimize hyperparameters of attribution methods for the task ofpruning, and further include transformer-based networks in our analysis. Ourapproach yields higher model compression rates of large transformer- andconvolutional architectures (VGG, ResNet, ViT) compared to previous works,while still attaining high performance on ImageNet classification tasks. Here,our experiments indicate that transformers have a higher degree ofover-parameterization compared to convolutional neural networks. Code isavailable at$\href{https://github.com/erfanhatefi/Pruning-by-eXplaining-in-PyTorch}{\text{thishttps link}}$.</description><author>Sayed Mohammad Vakilzadeh Hatefi, Maximilian Dreyer, Reduan Achtibat, Thomas Wiegand, Wojciech Samek, Sebastian Lapuschkin</author><pubDate>Thu, 22 Aug 2024 17:35:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12568v1</guid></item><item><title>Factor Adjusted Spectral Clustering for Mixture Models</title><link>http://arxiv.org/abs/2408.12564v1</link><description>This paper studies a factor modeling-based approach for clusteringhigh-dimensional data generated from a mixture of strongly correlatedvariables. Statistical modeling with correlated structures pervades modernapplications in economics, finance, genomics, wireless sensing, etc., withfactor modeling being one of the popular techniques for explaining the commondependence. Standard techniques for clustering high-dimensional data, e.g.,naive spectral clustering, often fail to yield insightful results as theirperformances heavily depend on the mixture components having a weaklycorrelated structure. To address the clustering problem in the presence of alatent factor model, we propose the Factor Adjusted Spectral Clustering (FASC)algorithm, which uses an additional data denoising step via eliminating thefactor component to cope with the data dependency. We prove this methodachieves an exponentially low mislabeling rate, with respect to the signal tonoise ratio under a general set of assumptions. Our assumption bridges manyclassical factor models in the literature, such as the pervasive factor model,the weak factor model, and the sparse factor model. The FASC algorithm is alsocomputationally efficient, requiring only near-linear sample complexity withrespect to the data dimension. We also show the applicability of the FASCalgorithm with real data experiments and numerical studies, and establish thatFASC provides significant results in many cases where traditional spectralclustering fails.</description><author>Shange Tang, Soham Jana, Jianqing Fan</author><pubDate>Thu, 22 Aug 2024 17:31:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12564v1</guid></item><item><title>SPICED: News Similarity Detection Dataset with Multiple Topics and Complexity Levels</title><link>http://arxiv.org/abs/2309.13080v2</link><description>The proliferation of news media outlets has increased the demand forintelligent systems capable of detecting redundant information in news articlesin order to enhance user experience. However, the heterogeneous nature of newscan lead to spurious findings in these systems: Simple heuristics such aswhether a pair of news are both about politics can provide strong but deceptivedownstream performance. Segmenting news similarity datasets into topicsimproves the training of these models by forcing them to learn how todistinguish salient characteristics under more narrow domains. However, thisrequires the existence of topic-specific datasets, which are currently lacking.In this article, we propose a novel dataset of similar news, SPICED, whichincludes seven topics: Crime &amp; Law, Culture &amp; Entertainment, Disasters &amp;Accidents, Economy &amp; Business, Politics &amp; Conflicts, Science &amp; Technology, andSports. Futhermore, we present four different levels of complexity,specifically designed for news similarity detection task. We benchmarked thecreated datasets using MinHash, BERT, SBERT, and SimCSE models.</description><author>Elena Shushkevich, Long Mai, Manuel V. Loureiro, Steven Derby, Tri Kurniawan Wijaya</author><pubDate>Thu, 22 Aug 2024 17:27:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.13080v2</guid></item><item><title>Comparative Study of States-based Neural Networks for Virtual Analog Audio Effects Modeling</title><link>http://arxiv.org/abs/2405.04124v4</link><description>Analog electronic circuits are at the core of an important category ofmusical devices. The nonlinear features of their electronic components giveanalog musical devices a distinctive timbre and sound quality, making themhighly desirable. Artificial neural networks have rapidly gained popularity forthe emulation of analog audio effects circuits, particularly recurrentnetworks. While neural approaches have been successful in accurately modelingdistortion circuits, they require architectural improvements that account forparameter conditioning and low latency response. In this article, we explorethe application of recent machine learning advancements for virtual analogmodeling. We compare State Space models and Linear Recurrent Units against themore common Long Short Term Memory networks. These have shown promising abilityin sequence to sequence modeling tasks, showing a notable improvement in signalhistory encoding. Our comparative study uses these black box neural modelingtechniques with a variety of audio effects. We evaluate the performance andlimitations using multiple metrics aiming to assess the models' ability toaccurately replicate energy envelopes, frequency contents, and transients inthe audio signal. To incorporate control parameters we employ the Feature wiseLinear Modulation method. Long Short Term Memory networks exhibit betteraccuracy in emulating distortions and equalizers, while the State Space model,followed by Long Short Term Memory networks when integrated in an encoderdecoder structure, outperforms others in emulating saturation and compression.When considering long time variant characteristics, the State Space modeldemonstrates the greatest accuracy. The Long Short Term Memory and, inparticular, Linear Recurrent Unit networks present more tendency to introduceaudio artifacts.</description><author>Riccardo Simionato, Stefano Fasciani</author><pubDate>Thu, 22 Aug 2024 17:25:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.04124v4</guid></item><item><title>ssProp: Energy-Efficient Training for Convolutional Neural Networks with Scheduled Sparse Back Propagation</title><link>http://arxiv.org/abs/2408.12561v1</link><description>Recently, deep learning has made remarkable strides, especially withgenerative modeling, such as large language models and probabilistic diffusionmodels. However, training these models often involves significant computationalresources, requiring billions of petaFLOPs. This high resource consumptionresults in substantial energy usage and a large carbon footprint, raisingcritical environmental concerns. Back-propagation (BP) is a major source ofcomputational expense during training deep learning models. To advance researchon energy-efficient training and allow for sparse learning on any machine anddevice, we propose a general, energy-efficient convolution module that can beseamlessly integrated into any deep learning architecture. Specifically, weintroduce channel-wise sparsity with additional gradient selection schedulersduring backward based on the assumption that BP is often dense and inefficient,which can lead to over-fitting and high computational consumption. Ourexperiments demonstrate that our approach reduces 40\% computations whilepotentially improving model performance, validated on image classification andgeneration tasks. This reduction can lead to significant energy savings and alower carbon footprint during the research and development phases oflarge-scale AI systems. Additionally, our method mitigates over-fitting in amanner distinct from Dropout, allowing it to be combined with Dropout tofurther enhance model performance and reduce computational resource usage.Extensive experiments validate that our method generalizes to a variety ofdatasets and tasks and is compatible with a wide range of deep learningarchitectures and modules. Code is publicly available athttps://github.com/lujiazho/ssProp.</description><author>Lujia Zhong, Shuo Huang, Yonggang Shi</author><pubDate>Thu, 22 Aug 2024 17:22:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12561v1</guid></item><item><title>Prefix Guidance: A Steering Wheel for Large Language Models to Defend Against Jailbreak Attacks</title><link>http://arxiv.org/abs/2408.08924v2</link><description>In recent years, the rapid development of large language models (LLMs) hasachieved remarkable performance across various tasks. However, researchindicates that LLMs are vulnerable to jailbreak attacks, where adversaries caninduce the generation of harmful content through meticulously crafted prompts.This vulnerability poses significant challenges to the secure use and promotionof LLMs. Existing defense methods offer protection from different perspectivesbut often suffer from insufficient effectiveness or a significant impact on themodel's capabilities. In this paper, we propose a plug-and-play andeasy-to-deploy jailbreak defense framework, namely Prefix Guidance (PG), whichguides the model to identify harmful prompts by directly setting the first fewtokens of the model's output. This approach combines the model's inherentsecurity capabilities with an external classifier to defend against jailbreakattacks. We demonstrate the effectiveness of PG across three models and fiveattack methods. Compared to baselines, our approach is generally more effectiveon average. Additionally, results on the Just-Eval benchmark further confirmPG's superiority to preserve the model's performance. our code is available athttps://github.com/weiyezhimeng/Prefix-Guidance.</description><author>Jiawei Zhao, Kejiang Chen, Xiaojian Yuan, Weiming Zhang</author><pubDate>Thu, 22 Aug 2024 17:21:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.08924v2</guid></item><item><title>Data Quality Antipatterns for Software Analytics</title><link>http://arxiv.org/abs/2408.12560v1</link><description>Background: Data quality is vital in software analytics, particularly formachine learning (ML) applications like software defect prediction (SDP).Despite the widespread use of ML in software engineering, the effect of dataquality antipatterns on these models remains underexplored. Objective: This study develops a taxonomy of ML-specific data qualityantipatterns and assesses their impact on software analytics models'performance and interpretation. Methods: We identified eight types and 14 sub-types of ML-specific dataquality antipatterns through a literature review. We conducted experiments todetermine the prevalence of these antipatterns in SDP data (RQ1), assess howcleaning order affects model performance (RQ2), evaluate the impact ofantipattern removal on performance (RQ3), and examine the consistency ofinterpretation from models built with different antipatterns (RQ4). Results: In our SDP case study, we identified nine antipatterns. Over 90% ofthese overlapped at both row and column levels, complicating cleaningprioritization and risking excessive data removal. The order of cleaningsignificantly impacts ML model performance, with neural networks being moreresilient to cleaning order changes than simpler models like logisticregression. Antipatterns such as Tailed Distributions and Class Overlap show astatistically significant correlation with performance metrics when otherantipatterns are cleaned. Models built with different antipatterns showedmoderate consistency in interpretation results. Conclusion: The cleaning order of different antipatterns impacts ML modelperformance. Five antipatterns have a statistically significant correlationwith model performance when others are cleaned. Additionally, modelinterpretation is moderately affected by different data quality antipatterns.</description><author>Aaditya Bhatia, Dayi Lin, Gopi Krishnan Rajbahadur, Bram Adams, Ahmed E. Hassan</author><pubDate>Thu, 22 Aug 2024 17:21:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12560v1</guid></item><item><title>From Lazy to Prolific: Tackling Missing Labels in Open Vocabulary Extreme Classification by Positive-Unlabeled Sequence Learning</title><link>http://arxiv.org/abs/2408.08981v2</link><description>Open-vocabulary Extreme Multi-label Classification (OXMC) extends traditionalXMC by allowing prediction beyond an extremely large, predefined label set(typically $10^3$ to $10^{12}$ labels), addressing the dynamic nature ofreal-world labeling tasks. However, self-selection bias in data annotationleads to significant missing labels in both training and test data,particularly for less popular inputs. This creates two critical challenges:generation models learn to be "lazy'" by under-generating labels, andevaluation becomes unreliable due to insufficient annotation in the test set.In this work, we introduce Positive-Unlabeled Sequence Learning (PUSL), whichreframes OXMC as an infinite keyphrase generation task, addressing thegeneration model's laziness. Additionally, we propose to adopt a suite ofevaluation metrics, F1@$\mathcal{O}$ and newly proposed B@$k$, to reliablyassess OXMC models with incomplete ground truths. In a highly imbalancede-commerce dataset with substantial missing labels, PUSL generates 30% moreunique labels, and 72% of its predictions align with actual user queries. Onthe less skewed EURLex-4.3k dataset, PUSL demonstrates superior F1 scores,especially as label counts increase from 15 to 30. Our approach effectivelytackles both the modeling and evaluation challenges in OXMC with missinglabels.</description><author>Ranran Haoran Zhang, Bensu Uçar, Soumik Dey, Hansi Wu, Binbin Li, Rui Zhang</author><pubDate>Thu, 22 Aug 2024 17:20:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.08981v2</guid></item><item><title>Topics as Entity Clusters: Entity-based Topics from Large Language Models and Graph Neural Networks</title><link>http://arxiv.org/abs/2301.02458v2</link><description>Topic models aim to reveal latent structures within a corpus of text,typically through the use of term-frequency statistics over bag-of-wordsrepresentations from documents. In recent years, conceptual entities --interpretable, language-independent features linked to external knowledgeresources -- have been used in place of word-level tokens, as words typicallyrequire extensive language processing with a minimal assurance ofinterpretability. However, current literature is limited when it comes toexploring purely entity-driven neural topic modeling. For instance, despite theadvantages of using entities for eliciting thematic structure, it is unclearwhether current techniques are compatible with these sparsely organised,information-dense conceptual units. In this work, we explore entity-basedneural topic modeling and propose a novel topic clustering approach usingbimodal vector representations of entities. Concretely, we extract these latentrepresentations from large language models and graph neural networks trained ona knowledge base of symbolic relations, in order to derive the most salientaspects of these conceptual units. Analysis of coherency metrics confirms thatour approach is better suited to working with entities in comparison tostate-of-the-art models, particularly when using graph-based embeddings trainedon a knowledge base.</description><author>Manuel V. Loureiro, Steven Derby, Tri Kurniawan Wijaya</author><pubDate>Thu, 22 Aug 2024 17:07:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.02458v2</guid></item><item><title>Comparing YOLOv5 Variants for Vehicle Detection: A Performance Analysis</title><link>http://arxiv.org/abs/2408.12550v1</link><description>Vehicle detection is an important task in the management of traffic andautomatic vehicles. This study provides a comparative analysis of five YOLOv5variants, YOLOv5n6s, YOLOv5s6s, YOLOv5m6s, YOLOv5l6s, and YOLOv5x6s, forvehicle detection in various environments. The research focuses on evaluatingthe effectiveness of these models in detecting different types of vehicles,such as Car, Bus, Truck, Bicycle, and Motorcycle, under varying conditionsincluding lighting, occlusion, and weather. Performance metrics such asprecision, recall, F1-score, and mean Average Precision are utilized to assessthe accuracy and reliability of each model. YOLOv5n6s demonstrated a strongbalance between precision and recall, particularly in detecting Cars. YOLOv5s6sand YOLOv5m6s showed improvements in recall, enhancing their ability to detectall relevant objects. YOLOv5l6s, with its larger capacity, provided robustperformance, especially in detecting Cars, but not good with identifyingMotorcycles and Bicycles. YOLOv5x6s was effective in recognizing Buses and Carsbut faced challenges with Motorcycle class.</description><author>Athulya Sundaresan Geetha</author><pubDate>Thu, 22 Aug 2024 17:06:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12550v1</guid></item><item><title>SiNGR: Brain Tumor Segmentation via Signed Normalized Geodesic Transform Regression</title><link>http://arxiv.org/abs/2405.16813v4</link><description>One of the primary challenges in brain tumor segmentation arises from theuncertainty of voxels close to tumor boundaries. However, the conventionalprocess of generating ground truth segmentation masks fails to treat suchuncertainties properly. Those "hard labels" with 0s and 1s conceptuallyinfluenced the majority of prior studies on brain image segmentation. As aresult, tumor segmentation is often solved through voxel classification. Inthis work, we instead view this problem as a voxel-level regression, where theground truth represents a certainty mapping from any pixel to the border of thetumor. We propose a novel ground truth label transformation, which is based ona signed geodesic transform, to capture the uncertainty in brain tumors'vicinity. We combine this idea with a Focal-like regression L1-loss thatenables effective regression learning in high-dimensional output space byappropriately weighting voxels according to their difficulty. We thoroughlyconduct an experimental evaluation to validate the components of our proposedmethod, compare it to a diverse array of state-of-the-art segmentation models,and show that it is architecture-agnostic. The code of our method is madepublicly available (\url{https://github.com/Oulu-IMEDS/SiNGR/}).</description><author>Trung Dang, Huy Hoang Nguyen, Aleksei Tiulpin</author><pubDate>Thu, 22 Aug 2024 17:04:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.16813v4</guid></item><item><title>Modeling Time-Variant Responses of Optical Compressors with Selective State Space Models</title><link>http://arxiv.org/abs/2408.12549v1</link><description>This paper presents a method for modeling optical dynamic range compressorsusing deep neural networks with Selective State Space models. The proposedapproach surpasses previous methods based on recurrent layers by employing aSelective State Space block to encode the input audio. It features a refinedtechnique integrating Feature-wise Linear Modulation and Gated Linear Units toadjust the network dynamically, conditioning the compression's attack andrelease phases according to external parameters. The proposed architecture iswell-suited for low-latency and real-time applications, crucial in live audioprocessing. The method has been validated on the analog optical compressorsTubeTech CL 1B and Teletronix LA-2A, which possess distinct characteristics.Evaluation is performed using quantitative metrics and subjective listeningtests, comparing the proposed method with other state-of-the-art models.Results show that our black-box modeling methods outperform all others,achieving accurate emulation of the compression process for both seen andunseen settings during training. We further show a correlation between thisaccuracy and the sampling density of the control parameters in the dataset andidentify settings with fast attack and slow release as the most challenging toemulate.</description><author>Riccardo Simionato</author><pubDate>Thu, 22 Aug 2024 17:03:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12549v1</guid></item><item><title>Human-In-The-Loop Machine Learning for Safe and Ethical Autonomous Vehicles: Principles, Challenges, and Opportunities</title><link>http://arxiv.org/abs/2408.12548v1</link><description>Rapid advances in Machine Learning (ML) have triggered new trends inAutonomous Vehicles (AVs). ML algorithms play a crucial role in interpretingsensor data, predicting potential hazards, and optimizing navigationstrategies. However, achieving full autonomy in cluttered and complexsituations, such as intricate intersections, diverse sceneries, variedtrajectories, and complex missions, is still challenging, and the cost of datalabeling remains a significant bottleneck. The adaptability and robustness ofhumans in complex scenarios motivate the inclusion of humans in ML process,leveraging their creativity, ethical power, and emotional intelligence toimprove ML effectiveness. The scientific community knows this approach asHuman-In-The-Loop Machine Learning (HITL-ML). Towards safe and ethicalautonomy, we present a review of HITL-ML for AVs, focusing on CurriculumLearning (CL), Human-In-The-Loop Reinforcement Learning (HITL-RL), ActiveLearning (AL), and ethical principles. In CL, human experts systematicallytrain ML models by starting with simple tasks and gradually progressing to moredifficult ones. HITL-RL significantly enhances the RL process by incorporatinghuman input through techniques like reward shaping, action injection, andinteractive learning. AL streamlines the annotation process by targetingspecific instances that need to be labeled with human oversight, reducing theoverall time and cost associated with training. Ethical principles must beembedded in AVs to align their behavior with societal values and norms. Inaddition, we provide insights and specify future research directions.</description><author>Yousef Emami, Kai Li, Luis Almeida, Wei Ni, Zhu Han</author><pubDate>Thu, 22 Aug 2024 17:02:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12548v1</guid></item><item><title>Towards Evaluating and Building Versatile Large Language Models for Medicine</title><link>http://arxiv.org/abs/2408.12547v1</link><description>In this study, we present MedS-Bench, a comprehensive benchmark designed toevaluate the performance of large language models (LLMs) in clinical contexts.Unlike existing benchmarks that focus on multiple-choice question answering,MedS-Bench spans 11 high-level clinical tasks, including clinical reportsummarization, treatment recommendations, diagnosis, named entity recognition,and medical concept explanation, among others. We evaluated six leading LLMs,e.g., MEDITRON, Mistral, InternLM 2, Llama 3, GPT-4, and Claude-3.5 usingfew-shot prompting, and found that even the most sophisticated models strugglewith these complex tasks. To address these limitations, we developed MedS-Ins,a large-scale instruction tuning dataset for medicine. MedS-Ins comprises 58medically oriented language corpora, totaling 13.5 million samples across 122tasks. To demonstrate the dataset's utility, we conducted a proof-of-conceptexperiment by performing instruction tuning on a lightweight, open-sourcemedical language model. The resulting model, MMedIns-Llama 3, significantlyoutperformed existing models across nearly all clinical tasks. To promotefurther advancements in the application of LLMs to clinical challenges, we havemade the MedS-Ins dataset fully accessible and invite the research community tocontribute to its expansion.Additionally, we have launched a dynamicleaderboard for MedS-Bench, which we plan to regularly update the test set totrack progress and enhance the adaptation of general LLMs to the medicaldomain. Leaderboard: https://henrychur.github.io/MedS-Bench/. Github:https://github.com/MAGIC-AI4Med/MedS-Ins.</description><author>Chaoyi Wu, Pengcheng Qiu, Jinxin Liu, Hongfei Gu, Na Li, Ya Zhang, Yanfeng Wang, Weidi Xie</author><pubDate>Thu, 22 Aug 2024 17:01:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12547v1</guid></item><item><title>Dynamics of Meta-learning Representation in the Teacher-student Scenario</title><link>http://arxiv.org/abs/2408.12545v1</link><description>Gradient-based meta-learning algorithms have gained popularity for theirability to train models on new tasks using limited data. Empirical observationsindicate that such algorithms are able to learn a shared representation acrosstasks, which is regarded as a key factor in their success. However, thein-depth theoretical understanding of the learning dynamics and the origin ofthe shared representation remains underdeveloped. In this work, we investigatethe meta-learning dynamics of the non-linear two-layer neural networks trainedon streaming tasks in the teach-student scenario. Through the lens ofstatistical physics analysis, we characterize the macroscopic behavior of themeta-training processes, the formation of the shared representation, and thegeneralization ability of the model on new tasks. The analysis also points tothe importance of the choice of certain hyper-parameters of the learningalgorithms.</description><author>Hui Wang, Cho Tung Yip, Bo Li</author><pubDate>Thu, 22 Aug 2024 16:59:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12545v1</guid></item><item><title>Assessing Lower Limb Strength using Internet-of-Things Enabled Chair</title><link>http://arxiv.org/abs/2209.04042v2</link><description>This project describes the application of the technologies of MachineLearning and Internet-of-Things to assess the lower limb strength ofindividuals undergoing rehabilitation or therapy. Specifically, it seeks tomeasure and assess the progress of individuals by sensors attached to chairsand processing the data through Google GPU Tensorflow CoLab. Pressure sensorsare attached to various locations on a chair, including but not limited to theseating area, backrest, hand rests, and legs. Sensor data from the individualperforming both sit-to-stand transition and stand-to-sit transition provides atime series dataset regarding the pressure distribution and vibratory motion onthe chair. The dataset and timing information can then be fed into a machinelearning model to estimate the relative strength and weakness during variousphases of the movement.</description><author>Hudson Kaleb Dy, Chelsea Yeh, Hanna Kaitlin Dy, Phillip Schodinger</author><pubDate>Thu, 22 Aug 2024 16:48:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.04042v2</guid></item><item><title>Neural interval-censored survival regression with feature selection</title><link>http://arxiv.org/abs/2206.06885v3</link><description>Survival analysis is a fundamental area of focus in biomedical research,particularly in the context of personalized medicine. This prominence is due tothe increasing prevalence of large and high-dimensional datasets, such as omicsand medical image data. However, the literature on non-linear regressionalgorithms and variable selection techniques for interval-censoring is eitherlimited or non-existent, particularly in the context of neural networks. Ourobjective is to introduce a novel predictive framework tailored forinterval-censored regression tasks, rooted in Accelerated Failure Time (AFT)models. Our strategy comprises two key components: i) a variable selectionphase leveraging recent advances on sparse neural network architectures, ii) aregression model targeting prediction of the interval-censored response. Toassess the performance of our novel algorithm, we conducted a comprehensiveevaluation through both numerical experiments and real-world applications thatencompass scenarios related to diabetes and physical activity. Our resultsoutperform traditional AFT algorithms, particularly in scenarios featuringnon-linear relationships.</description><author>Carlos García Meixide, Marcos Matabuena, Louis Abraham, Michael R. Kosorok</author><pubDate>Thu, 22 Aug 2024 16:48:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.06885v3</guid></item><item><title>Generalizing Visual Question Answering from Synthetic to Human-Written Questions via a Chain of QA with a Large Language Model</title><link>http://arxiv.org/abs/2401.06400v3</link><description>Visual question answering (VQA) is a task where an image is given, and aseries of questions are asked about the image. To build an efficient VQAalgorithm, a large amount of QA data is required which is very expensive.Generating synthetic QA pairs based on templates is a practical way to obtaindata. However, VQA models trained on those data do not perform well on complex,human-written questions. To address this issue, we propose a new method called{\it chain of QA for human-written questions} (CoQAH). CoQAH utilizes asequence of QA interactions between a large language model and a VQA modeltrained on synthetic data to reason and derive logical answers forhuman-written questions. We tested the effectiveness of CoQAH on two types ofhuman-written VQA datasets for 3D-rendered and chest X-ray images and foundthat it achieved state-of-the-art accuracy in both types of data. Notably,CoQAH outperformed general vision-language models, VQA models, and medicalfoundation models with no finetuning.</description><author>Taehee Kim, Yeongjae Cho, Heejun Shin, Yohan Jo, Dongmyung Shin</author><pubDate>Thu, 22 Aug 2024 16:46:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06400v3</guid></item><item><title>Efficient Sensor Placement from Regression with Sparse Gaussian Processes in Continuous and Discrete Spaces</title><link>http://arxiv.org/abs/2303.00028v7</link><description>The sensor placement problem is a common problem that arises when monitoringcorrelated phenomena, such as temperature, precipitation, and salinity.Existing approaches to this problem typically formulate it as the maximizationof information metrics, such as mutual information~(MI), and use optimizationmethods such as greedy algorithms in discrete domains, and derivative-freeoptimization methods such as genetic algorithms in continuous domains. However,computing MI for sensor placement requires discretizing the environment, andits computation cost depends on the size of the discretized environment. Theselimitations restrict these approaches from scaling to large problems. We present a novel formulation to the SP problem based on variationalapproximation that can be optimized using gradient descent, allowing us toefficiently find solutions in continuous domains. We generalize our method toalso handle discrete environments. Our experimental results on four real-worlddatasets demonstrate that our approach generates sensor placements consistentlyon par with or better than the prior state-of-the-art approaches in terms ofboth MI and reconstruction quality, all while being significantly faster. Ourcomputationally efficient approach enables both large-scale sensor placementand fast robotic sensor placement for informative path planning algorithms.</description><author>Kalvik Jakkala, Srinivas Akella</author><pubDate>Thu, 22 Aug 2024 16:39:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.00028v7</guid></item><item><title>A Complete Set of Quadratic Constraints for Repeated ReLU and Generalizations</title><link>http://arxiv.org/abs/2407.06888v2</link><description>This paper derives a complete set of quadratic constraints (QCs) for therepeated ReLU. The complete set of QCs is described by a collection of matrixcopositivity conditions. We also show that only two functions satisfy all QCsin our complete set: the repeated ReLU and flipped ReLU. Thus our complete setof QCs bounds the repeated ReLU as tight as possible up to the sign invarianceinherent in quadratic forms. We derive a similar complete set of incrementalQCs for repeated ReLU, which can potentially lead to less conservativeLipschitz bounds for ReLU networks than the standard LipSDP approach. The basicconstructions are also used to derive the complete sets of QCs for otherpiecewise linear activation functions such as leaky ReLU, MaxMin, andHouseHolder. Finally, we illustrate the use of the complete set of QCs toassess stability and performance for recurrent neural networks with ReLUactivation functions. We rely on a standard copositivity relaxation toformulate the stability/performance condition as a semidefinite program. Simpleexamples are provided to illustrate that the complete sets of QCs andincremental QCs can yield less conservative bounds than existing sets.</description><author>Sahel Vahedi Noori, Bin Hu, Geir Dullerud, Peter Seiler</author><pubDate>Thu, 22 Aug 2024 16:38:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.06888v2</guid></item><item><title>Automatic Organ and Pan-cancer Segmentation in Abdomen CT: the FLARE 2023 Challenge</title><link>http://arxiv.org/abs/2408.12534v1</link><description>Organ and cancer segmentation in abdomen Computed Tomography (CT) scans isthe prerequisite for precise cancer diagnosis and treatment. Most existingbenchmarks and algorithms are tailored to specific cancer types, limiting theirability to provide comprehensive cancer analysis. This work presents the firstinternational competition on abdominal organ and pan-cancer segmentation byproviding a large-scale and diverse dataset, including 4650 CT scans withvarious cancer types from over 40 medical centers. The winning team establisheda new state-of-the-art with a deep learning-based cascaded framework, achievingaverage Dice Similarity Coefficient scores of 92.3% for organs and 64.9% forlesions on the hidden multi-national testing set. The dataset and code of topteams are publicly available, offering a benchmark platform to drive furtherinnovations https://codalab.lisn.upsaclay.fr/competitions/12239.</description><author>Jun Ma, Yao Zhang, Song Gu, Cheng Ge, Ershuai Wang, Qin Zhou, Ziyan Huang, Pengju Lyu, Jian He, Bo Wang</author><pubDate>Thu, 22 Aug 2024 16:38:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12534v1</guid></item><item><title>Segment anything model 2: an application to 2D and 3D medical images</title><link>http://arxiv.org/abs/2408.00756v3</link><description>Segment Anything Model (SAM) has gained significant attention because of itsability to segment various objects in images given a prompt. The recentlydeveloped SAM 2 has extended this ability to video inputs. This opens anopportunity to apply SAM to 3D images, one of the fundamental tasks in themedical imaging field. In this paper, we extensively evaluate SAM 2's abilityto segment both 2D and 3D medical images by first collecting 21 medical imagingdatasets, including surgical videos, common 3D modalities such as computedtomography (CT), magnetic resonance imaging (MRI), and positron emissiontomography (PET) as well as 2D modalities such as X-ray and ultrasound. Twoevaluation settings of SAM 2 are considered: (1) multi-frame 3D segmentation,where prompts are provided to one or multiple slice(s) selected from thevolume, and (2) single-frame 2D segmentation, where prompts are provided toeach slice. The former only applies to videos and 3D modalities, while thelatter applies to all datasets. Our results show that SAM 2 exhibits similarperformance as SAM under single-frame 2D segmentation, and has variableperformance under multi-frame 3D segmentation depending on the choices ofslices to annotate, the direction of the propagation, the predictions utilizedduring the propagation, etc. We believe our work enhances the understanding ofSAM 2's behavior in the medical field and provides directions for future workin adapting SAM 2 to this domain. Our code is available at:https://github.com/mazurowski-lab/segment-anything2-medical-evaluation.</description><author>Haoyu Dong, Hanxue Gu, Yaqian Chen, Jichen Yang, Yuwen Chen, Maciej A. Mazurowski</author><pubDate>Thu, 22 Aug 2024 16:38:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.00756v3</guid></item><item><title>Deep Learning Improvements for Sparse Spatial Field Reconstruction</title><link>http://arxiv.org/abs/2408.12531v1</link><description>Accurately reconstructing a global spatial field from sparse data has been alongstanding problem in several domains, such as Earth Sciences and FluidDynamics. Historically, scientists have approached this problem by employingcomplex physics models to reconstruct the spatial fields. However, thesemethods are often computationally intensive. With the increase in popularity ofmachine learning (ML), several researchers have applied ML to the spatial fieldreconstruction task and observed improvements in computational efficiency. Onesuch method in arXiv:2101.00554 utilizes a sparse mask of sensor locations anda Voronoi tessellation with sensor measurements as inputs to a convolutionalneural network for reconstructing the global spatial field. In this work, wepropose multiple adjustments to the aforementioned approach and showimprovements on geoscience and fluid dynamics simulation datasets. We identifyand discuss scenarios that benefit the most using the proposed ML-based spatialfield reconstruction approach.</description><author>Robert Sunderhaft, Logan Frank, Jim Davis</author><pubDate>Thu, 22 Aug 2024 16:32:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12531v1</guid></item><item><title>Show-o: One Single Transformer to Unify Multimodal Understanding and Generation</title><link>http://arxiv.org/abs/2408.12528v1</link><description>We present a unified transformer, i.e., Show-o, that unifies multimodalunderstanding and generation. Unlike fully autoregressive models, Show-ounifies autoregressive and (discrete) diffusion modeling to adaptively handleinputs and outputs of various and mixed modalities. The unified model flexiblysupports a wide range of vision-language tasks including visualquestion-answering, text-to-image generation, text-guidedinpainting/extrapolation, and mixed-modality generation. Across variousbenchmarks, it demonstrates comparable or superior performance to existingindividual models with an equivalent or larger number of parameters tailoredfor understanding or generation. This significantly highlights its potential asa next-generation foundation model. Code and models are released athttps://github.com/showlab/Show-o.</description><author>Jinheng Xie, Weijia Mao, Zechen Bai, David Junhao Zhang, Weihao Wang, Kevin Qinghong Lin, Yuchao Gu, Zhijie Chen, Zhenheng Yang, Mike Zheng Shou</author><pubDate>Thu, 22 Aug 2024 16:32:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12528v1</guid></item><item><title>UMAD: University of Macau Anomaly Detection Benchmark Dataset</title><link>http://arxiv.org/abs/2408.12527v1</link><description>Anomaly detection is critical in surveillance systems and patrol robots byidentifying anomalous regions in images for early warning. Depending on whetherreference data are utilized, anomaly detection can be categorized into anomalydetection with reference and anomaly detection without reference. Currently,anomaly detection without reference, which is closely related toout-of-distribution (OoD) object detection, struggles with learning anomalouspatterns due to the difficulty of collecting sufficiently large and diverseanomaly datasets with the inherent rarity and novelty of anomalies.Alternatively, anomaly detection with reference employs the scheme of changedetection to identify anomalies by comparing semantic changes between areference image and a query one. However, there are very few ADr works due tothe scarcity of public datasets in this domain. In this paper, we aim toaddress this gap by introducing the UMAD Benchmark Dataset. To our bestknowledge, this is the first benchmark dataset designed specifically foranomaly detection with reference in robotic patrolling scenarios, e.g., wherean autonomous robot is employed to detect anomalous objects by comparing areference and a query video sequences. The reference sequences can be taken bythe robot along a specified route when there are no anomalous objects in thescene. The query sequences are captured online by the robot when it ispatrolling in the same scene following the same route. Our benchmark dataset iselaborated such that each query image can find a corresponding reference basedon accurate robot localization along the same route in the prebuilt 3D map,with which the reference and query images can be geometrically aligned usingadaptive warping. Besides the proposed benchmark dataset, we evaluate thebaseline models of ADr on this dataset.</description><author>Dong Li, Lineng Chen, Cheng-Zhong Xu, Hui Kong</author><pubDate>Thu, 22 Aug 2024 16:32:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12527v1</guid></item><item><title>Exploiting Student Parallelism for Low-latency GPU Inference of BERT-like Models in Online Services</title><link>http://arxiv.org/abs/2408.12526v1</link><description>Due to high accuracy, BERT-like models have been widely adopted bydiscriminative text mining and web searching. However, large BERT-like modelssuffer from inefficient online inference, as they face the following twoproblems on GPUs. First, they rely on the large model depth to achieve highaccuracy, which linearly increases the sequential computation on GPUs. Second,stochastic and dynamic online workloads cause extra costs. In this paper, wepresent Academus for low-latency online inference of BERT-like models. At thecore of Academus is the novel student parallelism, which adopts boostingensemble and stacking distillation to distill the original deep model into anequivalent group of parallel and shallow student models. This enables Academusto achieve the lower model depth (e.g., two layers) than baselines andconsequently the lowest inference latency without affecting the accuracy.Foroccasional workload bursts, it can temporarily decrease the number of studentswith minimal accuracy loss to improve throughput. Additionally, it employsspecialized system designs for student parallelism to better handle stochasticonline workloads. We conduct comprehensive experiments to verify theeffectiveness. The results show that Academus outperforms the baselines by4.1X~1.6X in latency without compromising accuracy, and achieves up to 22.27Xhigher throughput for workload bursts.</description><author>Weiyan Wang, Yilun Jin, Yiming Zhang, Victor Junqiu Wei, Han Tian, Li Chen, Kai Chen</author><pubDate>Thu, 22 Aug 2024 16:31:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12526v1</guid></item><item><title>PCGRL+: Scaling, Control and Generalization in Reinforcement Learning Level Generators</title><link>http://arxiv.org/abs/2408.12525v1</link><description>Procedural Content Generation via Reinforcement Learning (PCGRL) has beenintroduced as a means by which controllable designer agents can be trainedbased only on a set of computable metrics acting as a proxy for the level'squality and key characteristics. While PCGRL offers a unique set of affordancesfor game designers, it is constrained by the compute-intensive process oftraining RL agents, and has so far been limited to generating relatively smalllevels. To address this issue of scale, we implement several PCGRL environmentsin Jax so that all aspects of learning and simulation happen in parallel on theGPU, resulting in faster environment simulation; removing the CPU-GPU transferof information bottleneck during RL training; and ultimately resulting insignificantly improved training speed. We replicate several key results fromprior works in this new framework, letting models train for much longer thanpreviously studied, and evaluating their behavior after 1 billion timesteps.Aiming for greater control for human designers, we introduce randomized levelsizes and frozen "pinpoints" of pivotal game tiles as further ways ofcountering overfitting. To test the generalization ability of learnedgenerators, we evaluate models on large, out-of-distribution map sizes, andfind that partial observation sizes learn more robust design strategies.</description><author>Sam Earle, Zehua Jiang, Julian Togelius</author><pubDate>Thu, 22 Aug 2024 16:30:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12525v1</guid></item><item><title>Label Noise: Correcting the Forward-Correction</title><link>http://arxiv.org/abs/2307.13100v2</link><description>Training neural network classifiers on datasets with label noise poses a riskof overfitting them to the noisy labels. To address this issue, researchershave explored alternative loss functions that aim to be more robust. The`forward-correction' is a popular approach wherein the model outputs are noisedbefore being evaluated against noisy data. When the true noise model is known,applying the forward-correction guarantees consistency of the learningalgorithm. While providing some benefit, the correction is insufficient toprevent overfitting to finite noisy datasets. In this work, we propose anapproach to tackling overfitting caused by label noise. We observe that thepresence of label noise implies a lower bound on the noisy generalised risk.Motivated by this observation, we propose imposing a lower bound on thetraining loss to mitigate overfitting. Our main contribution is providingtheoretical insights that allow us to approximate the lower bound given only anestimate of the average noise rate. We empirically demonstrate that using thisbound significantly enhances robustness in various settings, with virtually noadditional computational cost.</description><author>William Toner, Amos Storkey</author><pubDate>Thu, 22 Aug 2024 16:30:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.13100v2</guid></item><item><title>Real-world Image Dehazing with Coherence-based Label Generator and Cooperative Unfolding Network</title><link>http://arxiv.org/abs/2406.07966v2</link><description>Real-world Image Dehazing (RID) aims to alleviate haze-induced degradation inreal-world settings. This task remains challenging due to the complexities inaccurately modeling real haze distributions and the scarcity of pairedreal-world data. To address these challenges, we first introduce a cooperativeunfolding network that jointly models atmospheric scattering and image scenes,effectively integrating physical knowledge into deep networks to restorehaze-contaminated details. Additionally, we propose the first RID-orientediterative mean-teacher framework, termed the Coherence-based Label Generator,to generate high-quality pseudo labels for network training. Specifically, weprovide an optimal label pool to store the best pseudo-labels during networktraining, leveraging both global and local coherence to select high-qualitycandidates and assign weights to prioritize haze-free regions. We verify theeffectiveness of our method, with experiments demonstrating that it achievesstate-of-the-art performance on RID tasks. Code will be available at\url{https://github.com/cnyvfang/CORUN-Colabator}.</description><author>Chengyu Fang, Chunming He, Fengyang Xiao, Yulun Zhang, Longxiang Tang, Yuelin Zhang, Kai Li, Xiu Li</author><pubDate>Thu, 22 Aug 2024 16:23:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.07966v2</guid></item><item><title>Advanced atom-level representations for protein flexibility prediction utilizing graph neural networks</title><link>http://arxiv.org/abs/2408.12519v1</link><description>Protein dynamics play a crucial role in many biological processes and druginteractions. However, measuring, and simulating protein dynamics ischallenging and time-consuming. While machine learning holds promise indeciphering the determinants of protein dynamics from structural information,most existing methods for protein representation learning operate at theresidue level, ignoring the finer details of atomic interactions. In this work,we propose for the first time to use graph neural networks (GNNs) to learnprotein representations at the atomic level and predict B-factors from protein3D structures. The B-factor reflects the atomic displacement of atoms inproteins, and can serve as a surrogate for protein flexibility. We compareddifferent GNN architectures to assess their performance. The Meta-GNN modelachieves a correlation coefficient of 0.71 on a large and diverse test set ofover 4k proteins (17M atoms) from the Protein Data Bank (PDB), outperformingprevious methods by a large margin. Our work demonstrates the potential ofrepresentations learned by GNNs for protein flexibility prediction and otherrelated tasks.</description><author>Sina Sarparast, Aldo Zaimi, Maximilian Ebert, Michael-Rock Goldsmith</author><pubDate>Thu, 22 Aug 2024 16:15:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12519v1</guid></item><item><title>Stochastic Compositional Minimax Optimization with Provable Convergence Guarantees</title><link>http://arxiv.org/abs/2408.12505v1</link><description>Stochastic compositional minimax problems are prevalent in machine learning,yet there are only limited established on the convergence of this class ofproblems. In this paper, we propose a formal definition of the stochasticcompositional minimax problem, which involves optimizing a minimax loss with acompositional structure either in primal , dual, or both primal and dualvariables. We introduce a simple yet effective algorithm, stochasticallyCorrected stOchastic gradient Descent Ascent (CODA), which is a descent ascenttype algorithm with compositional correction steps, and establish itsconvergence rate in aforementioned three settings. In the presence of thecompositional structure in primal, the objective function typically becomesnonconvex in primal due to function composition. Thus, we consider thenonconvex-strongly-concave and nonconvex-concave settings and show that CODAcan efficiently converge to a stationary point. In the case of composition onthe dual, the objective function becomes nonconcave in the dual variable, andwe demonstrate convergence in the strongly-convex-nonconcave andconvex-nonconcave setting. In the case of composition on both variables, theprimal and dual variables may lose convexity and concavity, respectively.Therefore, we anaylze the convergence in weakly-convex-weakly-concave setting.We also give a variance reduction version algorithm, CODA+, which achieves thebest known rate on nonconvex-strongly-concave and nonconvex-concavecompositional minimax problem. This work initiates the theoretical study of thestochastic compositional minimax problem on various settings and may informmodern machine learning scenarios such as domain adaptation or robustmodel-agnostic meta-learning.</description><author>Yuyang Deng, Fuli Qiao, Mehrdad Mahdavi</author><pubDate>Thu, 22 Aug 2024 16:00:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12505v1</guid></item><item><title>Urban Region Pre-training and Prompting: A Graph-based Approach</title><link>http://arxiv.org/abs/2408.05920v2</link><description>Urban region representation is crucial for various urban downstream tasks.However, despite the proliferation of methods and their success, acquiringgeneral urban region knowledge and adapting to different tasks remainschallenging. Previous work often neglects the spatial structures and functionallayouts between entities, limiting their ability to capture transferableknowledge across regions. Further, these methods struggle to adapt effectivelyto specific downstream tasks, as they do not adequately address the uniquefeatures and relationships required for different downstream tasks. In thispaper, we propose a $\textbf{G}$raph-based $\textbf{U}$rban $\textbf{R}$egion$\textbf{P}$re-training and $\textbf{P}$rompting framework ($\textbf{GURPP}$)for region representation learning. Specifically, we first construct an urbanregion graph that integrates detailed spatial entity data for more effectiveurban region representation. Then, we develop a subgraph-centric urban regionpre-training model to capture the heterogeneous and transferable patterns ofinteractions among entities. To further enhance the adaptability of theseembeddings to different tasks, we design two graph-based prompting methods toincorporate explicit/hidden task knowledge. Extensive experiments on variousurban region prediction tasks and different cities demonstrate the superiorperformance of our GURPP framework. We wil release code and data upon papernotification.</description><author>Jiahui Jin, Yifan Song, Dong Kan, Haojia Zhu, Xiangguo Sun, Zhicheng Li, Xigang Sun, Jinghui Zhang</author><pubDate>Thu, 22 Aug 2024 15:56:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.05920v2</guid></item><item><title>Overfitting In Contrastive Learning?</title><link>http://arxiv.org/abs/2407.15863v2</link><description>Overfitting describes a machine learning phenomenon where the model fits tooclosely to the training data, resulting in poor generalization. While thisoccurrence is thoroughly documented for many forms of supervised learning, itis not well examined in the context of unsupervised learning. In this work weexamine the nature of overfitting in unsupervised contrastive learning. We showthat overfitting can indeed occur and the mechanism behind overfitting.</description><author>Zachary Rabin, Jim Davis, Benjamin Lewis, Matthew Scherreik</author><pubDate>Thu, 22 Aug 2024 15:56:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.15863v2</guid></item><item><title>The Russian-focused embedders' exploration: ruMTEB benchmark and Russian embedding model design</title><link>http://arxiv.org/abs/2408.12503v1</link><description>Embedding models play a crucial role in Natural Language Processing (NLP) bycreating text embeddings used in various tasks such as information retrievaland assessing semantic text similarity. This paper focuses on research relatedto embedding models in the Russian language. It introduces a newRussian-focused embedding model called ru-en-RoSBERTa and the ruMTEB benchmark,the Russian version extending the Massive Text Embedding Benchmark (MTEB). Ourbenchmark includes seven categories of tasks, such as semantic textualsimilarity, text classification, reranking, and retrieval. The research alsoassesses a representative set of Russian and multilingual models on theproposed benchmark. The findings indicate that the new model achieves resultsthat are on par with state-of-the-art models in Russian. We release the modelru-en-RoSBERTa, and the ruMTEB framework comes with open-source code,integration into the original framework and a public leaderboard.</description><author>Artem Snegirev, Maria Tikhonova, Anna Maksimova, Alena Fenogenova, Alexander Abramov</author><pubDate>Thu, 22 Aug 2024 15:53:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12503v1</guid></item><item><title>Similarity of Neural Network Models: A Survey of Functional and Representational Measures</title><link>http://arxiv.org/abs/2305.06329v3</link><description>Measuring similarity of neural networks to understand and improve theirbehavior has become an issue of great importance and research interest. In thissurvey, we provide a comprehensive overview of two complementary perspectivesof measuring neural network similarity: (i) representational similarity, whichconsiders how activations of intermediate layers differ, and (ii) functionalsimilarity, which considers how models differ in their outputs. In addition toproviding detailed descriptions of existing measures, we summarize and discussresults on the properties of and relationships between these measures, andpoint to open research problems. We hope our work lays a foundation for moresystematic research on the properties and applicability of similarity measuresfor neural network models.</description><author>Max Klabunde, Tobias Schumacher, Markus Strohmaier, Florian Lemmerich</author><pubDate>Thu, 22 Aug 2024 15:52:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.06329v3</guid></item><item><title>Uncovering Latent Arguments in Social Media Messaging by Employing LLMs-in-the-Loop Strategy</title><link>http://arxiv.org/abs/2404.10259v3</link><description>The widespread use of social media has led to a surge in popularity forautomated methods of analyzing public opinion. Supervised methods are adept attext categorization, yet the dynamic nature of social media discussions poses acontinual challenge for these techniques due to the constant shifting of thefocus. On the other hand, traditional unsupervised methods for extractingthemes from public discourse, such as topic modeling, often reveal overarchingpatterns that might not capture specific nuances. Consequently, a significantportion of research into social media discourse still depends onlabor-intensive manual coding techniques and a human-in-the-loop approach,which are both time-consuming and costly. In this work, we study the problem ofdiscovering arguments associated with a specific theme. We propose a genericLLMs-in-the-Loop strategy that leverages the advanced capabilities of LargeLanguage Models (LLMs) to extract latent arguments from social media messaging.To demonstrate our approach, we apply our framework to contentious topics. Weuse two publicly available datasets: (1) the climate campaigns dataset of 14kFacebook ads with 25 themes and (2) the COVID-19 vaccine campaigns dataset of9k Facebook ads with 14 themes. Additionally, we design a downstream task asstance prediction by leveraging talking points in climate debates. Furthermore,we analyze demographic targeting and the adaptation of messaging based onreal-world events.</description><author>Tunazzina Islam, Dan Goldwasser</author><pubDate>Thu, 22 Aug 2024 15:52:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.10259v3</guid></item><item><title>The Oscars of AI Theater: A Survey on Role-Playing with Language Models</title><link>http://arxiv.org/abs/2407.11484v5</link><description>This survey explores the burgeoning field of role-playing with languagemodels, focusing on their development from early persona-based models toadvanced character-driven simulations facilitated by Large Language Models(LLMs). Initially confined to simple persona consistency due to limited modelcapabilities, role-playing tasks have now expanded to embrace complex characterportrayals involving character consistency, behavioral alignment, and overallattractiveness. We provide a comprehensive taxonomy of the critical componentsin designing these systems, including data, models and alignment, agentarchitecture and evaluation. This survey not only outlines the currentmethodologies and challenges, such as managing dynamic personal profiles andachieving high-level persona consistency but also suggests avenues for futureresearch in improving the depth and realism of role-playing applications. Thegoal is to guide future research by offering a structured overview of currentmethodologies and identifying potential areas for improvement. Relatedresources and papers are available athttps://github.com/nuochenpku/Awesome-Role-Play-Papers.</description><author>Nuo Chen, Yan Wang, Yang Deng, Jia Li</author><pubDate>Thu, 22 Aug 2024 15:44:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.11484v5</guid></item><item><title>MEDCO: Medical Education Copilots Based on A Multi-Agent Framework</title><link>http://arxiv.org/abs/2408.12496v1</link><description>Large language models (LLMs) have had a significant impact on diverseresearch domains, including medicine and healthcare. However, the potential ofLLMs as copilots in medical education remains underexplored. CurrentAI-assisted educational tools are limited by their solitary learning approachand inability to simulate the multi-disciplinary and interactive nature ofactual medical training. To address these limitations, we propose MEDCO(Medical EDucation COpilots), a novel multi-agent-based copilot systemspecially developed to emulate real-world medical training environments. MEDCOincorporates three primary agents: an agentic patient, an expert doctor, and aradiologist, facilitating a multi-modal and interactive learning environment.Our framework emphasizes the learning of proficient question-asking skills,multi-disciplinary collaboration, and peer discussions between students. Ourexperiments show that simulated virtual students who underwent training withMEDCO not only achieved substantial performance enhancements comparable tothose of advanced models, but also demonstrated human-like learning behaviorsand improvements, coupled with an increase in the number of learning samples.This work contributes to medical education by introducing a copilot thatimplements an interactive and collaborative learning approach. It also providesvaluable insights into the effectiveness of AI-integrated training paradigms.</description><author>Hao Wei, Jianing Qiu, Haibao Yu, Wu Yuan</author><pubDate>Thu, 22 Aug 2024 15:41:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12496v1</guid></item><item><title>StreamLTS: Query-based Temporal-Spatial LiDAR Fusion for Cooperative Object Detection</title><link>http://arxiv.org/abs/2407.03825v2</link><description>Cooperative perception via communication among intelligent traffic agents hasgreat potential to improve the safety of autonomous driving. However, limitedcommunication bandwidth, localization errors and asynchronized capturing timeof sensor data, all introduce difficulties to the data fusion of differentagents. To some extend, previous works have attempted to reduce the shared datasize, mitigate the spatial feature misalignment caused by localization errorsand communication delay. However, none of them have considered theasynchronized sensor ticking times, which can lead to dynamic objectmisplacement of more than one meter during data fusion. In this work, wepropose Time-Aligned COoperative Object Detection (TA-COOD), for which we adaptwidely used dataset OPV2V and DairV2X with considering asynchronous LiDARsensor ticking times and build an efficient fully sparse framework withmodeling the temporal information of individual objects with query-basedtechniques. The experiment results confirmed the superior efficiency of ourfully sparse framework compared to the state-of-the-art dense models. Moreimportantly, they show that the point-wise observation timestamps of thedynamic objects are crucial for accurate modeling the object temporal contextand the predictability of their time-related locations. The official code isavailable at \url{https://github.com/YuanYunshuang/CoSense3D}.</description><author>Yunshuang Yuan, Monika Sester</author><pubDate>Thu, 22 Aug 2024 15:40:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03825v2</guid></item><item><title>SuperSimpleNet: Unifying Unsupervised and Supervised Learning for Fast and Reliable Surface Defect Detection</title><link>http://arxiv.org/abs/2408.03143v2</link><description>The aim of surface defect detection is to identify and localise abnormalregions on the surfaces of captured objects, a task that's increasinglydemanded across various industries. Current approaches frequently fail tofulfil the extensive demands of these industries, which encompass highperformance, consistency, and fast operation, along with the capacity toleverage the entirety of the available training data. Addressing these gaps, weintroduce SuperSimpleNet, an innovative discriminative model that evolved fromSimpleNet. This advanced model significantly enhances its predecessor'straining consistency, inference time, as well as detection performance.SuperSimpleNet operates in an unsupervised manner using only normal trainingimages but also benefits from labelled abnormal training images when they areavailable. SuperSimpleNet achieves state-of-the-art results in both thesupervised and the unsupervised settings, as demonstrated by experiments acrossfour challenging benchmark datasets. Code:https://github.com/blaz-r/SuperSimpleNet .</description><author>Blaž Rolih, Matic Fučka, Danijel Skočaj</author><pubDate>Thu, 22 Aug 2024 15:38:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.03143v2</guid></item><item><title>GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models</title><link>http://arxiv.org/abs/2408.12494v1</link><description>Large language models (LLMs) have exhibited remarkable capabilities innatural language generation, but they have also been observed to magnifysocietal biases, particularly those related to gender. In response to thisissue, several benchmarks have been proposed to assess gender bias in LLMs.However, these benchmarks often lack practical flexibility or inadvertentlyintroduce biases. To address these shortcomings, we introduce GenderCARE, acomprehensive framework that encompasses innovative Criteria, bias Assessment,Reduction techniques, and Evaluation metrics for quantifying and mitigatinggender bias in LLMs. To begin, we establish pioneering criteria for genderequality benchmarks, spanning dimensions such as inclusivity, diversity,explainability, objectivity, robustness, and realisticity. Guided by thesecriteria, we construct GenderPair, a novel pair-based benchmark designed toassess gender bias in LLMs comprehensively. Our benchmark provides standardizedand realistic evaluations, including previously overlooked gender groups suchas transgender and non-binary individuals. Furthermore, we develop effectivedebiasing techniques that incorporate counterfactual data augmentation andspecialized fine-tuning strategies to reduce gender bias in LLMs withoutcompromising their overall performance. Extensive experiments demonstrate asignificant reduction in various gender bias benchmarks, with reductionspeaking at over 90% and averaging above 35% across 17 different LLMs.Importantly, these reductions come with minimal variability in mainstreamlanguage tasks, remaining below 2%. By offering a realistic assessment andtailored reduction of gender biases, we hope that our GenderCARE can representa significant step towards achieving fairness and equity in LLMs. More detailsare available at https://github.com/kstanghere/GenderCARE-ccs24.</description><author>Kunsheng Tang, Wenbo Zhou, Jie Zhang, Aishan Liu, Gelei Deng, Shuai Li, Peigui Qi, Weiming Zhang, Tianwei Zhang, Nenghai Yu</author><pubDate>Thu, 22 Aug 2024 15:35:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12494v1</guid></item><item><title>AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines</title><link>http://arxiv.org/abs/2408.12491v1</link><description>Soft-tissue and bone tumours (STBT) are rare, diagnostically challenginglesions with variable clinical behaviours and treatment approaches. Thissystematic review provides an overview of Artificial Intelligence (AI) methodsusing radiological imaging for diagnosis and prognosis of these tumours,highlighting challenges in clinical translation, and evaluating study alignmentwith the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AIinternational consensus guidelines for trustworthy and deployable AI to promotethe clinical translation of AI methods. The review covered literature fromseveral bibliographic databases, including papers published before 17/07/2024.Original research in peer-reviewed journals focused on radiology-based AI fordiagnosing or prognosing primary STBT was included. Exclusion criteria wereanimal, cadaveric, or laboratory studies, and non-English papers. Abstractswere screened by two of three independent reviewers for eligibility. Eligiblepapers were assessed against guidelines by one of three independent reviewers.The search identified 15,015 abstracts, from which 325 articles were includedfor evaluation. Most studies performed moderately on CLAIM, averaging a scoreof 28.9$\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\pm$2.1 outof 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,indicating significant room for improvement. Future efforts by AI developersshould focus on design (e.g. define unmet clinical need, intended clinicalsetting and how AI would be integrated in clinical workflow), development (e.g.build on previous work, explainability), evaluation (e.g. evaluating andaddressing biases, evaluating AI against best practices), and datareproducibility and availability (making documented code and data publiclyavailable). Following these recommendations could improve clinical translationof AI methods.</description><author>Douwe J. Spaanderman, Matthew Marzetti, Xinyi Wan, Andrew F. Scarsbrook, Philip Robinson, Edwin H. G. Oei, Jacob J. Visser, Robert Hemke, Kirsten van Langevelde, David F. Hanff, Geert J. L. H. van Leenders, Cornelis Verhoef, Dirk J. Gruühagen, Wiro J. Niessen, Stefan Klein, Martijn P. A. Starmans</author><pubDate>Thu, 22 Aug 2024 15:31:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12491v1</guid></item><item><title>Scribbles for All: Benchmarking Scribble Supervised Segmentation Across Datasets</title><link>http://arxiv.org/abs/2408.12489v1</link><description>In this work, we introduce Scribbles for All, a label and training datageneration algorithm for semantic segmentation trained on scribble labels.Training or fine-tuning semantic segmentation models with weak supervision hasbecome an important topic recently and was subject to significant advances inmodel quality. In this setting, scribbles are a promising label type to achievehigh quality segmentation results while requiring a much lower annotationeffort than usual pixel-wise dense semantic segmentation annotations. The mainlimitation of scribbles as source for weak supervision is the lack ofchallenging datasets for scribble segmentation, which hinders the developmentof novel methods and conclusive evaluations. To overcome this limitation,Scribbles for All provides scribble labels for several popular segmentationdatasets and provides an algorithm to automatically generate scribble labelsfor any dataset with dense annotations, paving the way for new insights andmodel advancements in the field of weakly supervised segmentation. In additionto providing datasets and algorithm, we evaluate state-of-the-art segmentationmodels on our datasets and show that models trained with our synthetic labelsperform competitively with respect to models trained on manual labels. Thus,our datasets enable state-of-the-art research into methods for scribble-labeledsemantic segmentation. The datasets, scribble generation algorithm, andbaselines are publicly available at https://github.com/wbkit/Scribbles4All</description><author>Wolfgang Boettcher, Lukas Hoyer, Ozan Unal, Jan Eric Lenssen, Bernt Schiele</author><pubDate>Thu, 22 Aug 2024 15:29:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12489v1</guid></item><item><title>Not All Samples Should Be Utilized Equally: Towards Understanding and Improving Dataset Distillation</title><link>http://arxiv.org/abs/2408.12483v1</link><description>Dataset Distillation (DD) aims to synthesize a small dataset capable ofperforming comparably to the original dataset. Despite the success of numerousDD methods, theoretical exploration of this area remains unaddressed. In thispaper, we take an initial step towards understanding various matching-based DDmethods from the perspective of sample difficulty. We begin by empiricallyexamining sample difficulty, measured by gradient norm, and observe thatdifferent matching-based methods roughly correspond to specific difficultytendencies. We then extend the neural scaling laws of data pruning to DD totheoretically explain these matching-based methods. Our findings suggest thatprioritizing the synthesis of easier samples from the original dataset canenhance the quality of distilled datasets, especially in low IPC(image-per-class) settings. Based on our empirical observations and theoreticalanalysis, we introduce the Sample Difficulty Correction (SDC) approach,designed to predominantly generate easier samples to achieve higher datasetquality. Our SDC can be seamlessly integrated into existing methods as a pluginwith minimal code adjustments. Experimental results demonstrate that adding SDCgenerates higher-quality distilled datasets across 7 distillation methods and 6datasets.</description><author>Shaobo Wang, Yantai Yang, Qilong Wang, Kaixin Li, Linfeng Zhang, Junchi Yan</author><pubDate>Thu, 22 Aug 2024 15:20:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12483v1</guid></item><item><title>FOUND: Foot Optimization with Uncertain Normals for Surface Deformation Using Synthetic Data</title><link>http://arxiv.org/abs/2310.18279v2</link><description>Surface reconstruction from multi-view images is a challenging task, withsolutions often requiring a large number of sampled images with high overlap.We seek to develop a method for few-view reconstruction, for the case of thehuman foot. To solve this task, we must extract rich geometric cues from RGBimages, before carefully fusing them into a final 3D object. Our FOUND approachtackles this, with 4 main contributions: (i) SynFoot, a synthetic dataset of50,000 photorealistic foot images, paired with ground truth surface normals andkeypoints; (ii) an uncertainty-aware surface normal predictor trained on oursynthetic dataset; (iii) an optimization scheme for fitting a generative footmodel to a series of images; and (iv) a benchmark dataset of calibrated imagesand high resolution ground truth geometry. We show that our normal predictoroutperforms all off-the-shelf equivalents significantly on real images, and ouroptimization scheme outperforms state-of-the-art photogrammetry pipelines,especially for a few-view setting. We release our synthetic dataset andbaseline 3D scans to the research community.</description><author>Oliver Boyne, Gwangbin Bae, James Charles, Roberto Cipolla</author><pubDate>Thu, 22 Aug 2024 15:20:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18279v2</guid></item><item><title>Self-Learning for Personalized Keyword Spotting on Ultra-Low-Power Audio Sensors</title><link>http://arxiv.org/abs/2408.12481v1</link><description>This paper proposes a self-learning framework to incrementally train(fine-tune) a personalized Keyword Spotting (KWS) model after the deployment onultra-low power smart audio sensors. We address the fundamental problem of theabsence of labeled training data by assigning pseudo-labels to the new recordedaudio frames based on a similarity score with respect to few user recordings.By experimenting with multiple KWS models with a number of parameters up to0.5M on two public datasets, we show an accuracy improvement of up to +19.2%and +16.0% vs. the initial models pretrained on a large set of generickeywords. The labeling task is demonstrated on a sensor system composed of alow-power microphone and an energy-efficient Microcontroller (MCU). Byefficiently exploiting the heterogeneous processing engines of the MCU, thealways-on labeling task runs in real-time with an average power cost of up to8.2 mW. On the same platform, we estimate an energy cost for on-device training10x lower than the labeling energy if sampling a new utterance every 5 s or16.4 s with a DS-CNN-S or a DS-CNN-M model. Our empirical result paves the wayto self-adaptive personalized KWS sensors at the extreme edge.</description><author>Manuele Rusci, Francesco Paci, Marco Fariselli, Eric Flamand, Tinne Tuytelaars</author><pubDate>Thu, 22 Aug 2024 15:17:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12481v1</guid></item><item><title>Vintern-1B: An Efficient Multimodal Large Language Model for Vietnamese</title><link>http://arxiv.org/abs/2408.12480v1</link><description>In this report, we introduce Vintern-1B, a reliable 1-billion-parametersmultimodal large language model (MLLM) for Vietnamese language tasks. Byintegrating the Qwen2-0.5B-Instruct language model with theInternViT-300M-448px visual model, Vintern-1B is optimized for a range ofapplications, including optical character recognition (OCR), documentextraction, and general question-answering in Vietnamese context. The model isfine-tuned on an extensive dataset of over 3 million image-question-answerpairs, achieving robust performance and reliable results across multipleVietnamese language benchmarks like OpenViVQA and ViTextVQA. Vintern-1B issmall enough to fit into various on-device applications easily. Additionally,we have open-sourced several Vietnamese vision question answering (VQA)datasets for text and diagrams, created with Gemini 1.5 Flash. Our models areavailable at: https://huggingface.co/5CD-AI/Vintern-1B-v2.</description><author>Khang T. Doan, Bao G. Huynh, Dung T. Hoang, Thuc D. Pham, Nhat H. Pham, Quan T. M. Nguyen, Bang Q. Vo, Suong N. Hoang</author><pubDate>Thu, 22 Aug 2024 15:15:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12480v1</guid></item><item><title>Predicting Solar Energy Generation with Machine Learning based on AQI and Weather Features</title><link>http://arxiv.org/abs/2408.12476v1</link><description>This paper addresses the pressing need for an accurate solar energyprediction model, which is crucial for efficient grid integration. We explorethe influence of the Air Quality Index and weather features on solar energygeneration, employing advanced Machine Learning and Deep Learning techniques.Our methodology uses time series modeling and makes novel use of powertransform normalization and zero-inflated modeling. Various Machine Learningalgorithms and Conv2D Long Short-Term Memory model based Deep Learning modelsare applied to these transformations for precise predictions. Resultsunderscore the effectiveness of our approach, demonstrating enhanced predictionaccuracy with Air Quality Index and weather features. We achieved a 0.9691$R^2$ Score, 0.18 MAE, 0.10 RMSE with Conv2D Long Short-Term Memory model,showcasing the power transform technique's innovation in enhancing time seriesforecasting for solar energy generation. Such results help our researchcontribute valuable insights to the synergy between Air Quality Index, weatherfeatures, and Deep Learning techniques for solar energy prediction.</description><author>Arjun Shah, Varun Viswanath, Kashish Gandhi, Dr. Nilesh Madhukar Patil</author><pubDate>Thu, 22 Aug 2024 15:13:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12476v1</guid></item><item><title>Frame Order Matters: A Temporal Sequence-Aware Model for Few-Shot Action Recognition</title><link>http://arxiv.org/abs/2408.12475v1</link><description>In this paper, we propose a novel Temporal Sequence-Aware Model (TSAM) forfew-shot action recognition (FSAR), which incorporates a sequential perceiveradapter into the pre-training framework, to integrate both the spatialinformation and the sequential temporal dynamics into the feature embeddings.Different from the existing fine-tuning approaches that capture temporalinformation by exploring the relationships among all the frames, ourperceiver-based adapter recurrently captures the sequential dynamics alongsidethe timeline, which could perceive the order change. To obtain thediscriminative representations for each class, we extend a textual corpus foreach class derived from the large language models (LLMs) and enrich the visualprototypes by integrating the contextual semantic information. Besides, Weintroduce an unbalanced optimal transport strategy for feature matching thatmitigates the impact of class-unrelated features, thereby facilitating moreeffective decision-making. Experimental results on five FSAR datasetsdemonstrate that our method set a new benchmark, beating the second-bestcompetitors with large margins.</description><author>Bozheng Li, Mushui Liu, Gaoang Wang, Yunlong Yu</author><pubDate>Thu, 22 Aug 2024 15:13:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12475v1</guid></item><item><title>Envisioning Class Entity Reasoning by Large Language Models for Few-shot Learning</title><link>http://arxiv.org/abs/2408.12469v1</link><description>Few-shot learning (FSL) aims to recognize new concepts using a limited numberof visual samples. Existing approaches attempt to incorporate semanticinformation into the limited visual data for category understanding. However,these methods often enrich class-level feature representations with abstractcategory names, failing to capture the nuanced features essential for effectivegeneralization. To address this issue, we propose a novel framework for FSL,which incorporates both the abstract class semantics and the concrete classentities extracted from Large Language Models (LLMs), to enhance therepresentation of the class prototypes. Specifically, our framework composes aSemantic-guided Visual Pattern Extraction (SVPE) module and aPrototype-Calibration (PC) module, where the SVPE meticulously extractssemantic-aware visual patterns across diverse scales, while the PC moduleseamlessly integrates these patterns to refine the visual prototype, enhancingits representativeness. Extensive experiments on four few-shot classificationbenchmarks and the BSCD-FSL cross-domain benchmarks showcase remarkableadvancements over the current state-of-the-art methods. Notably, for thechallenging one-shot setting, our approach, utilizing the ResNet-12 backbone,achieves an impressive average improvement of 1.95% over the second-bestcompetitor.</description><author>Mushui Liu, Fangtai Wu, Bozheng Li, Ziqian Lu, Yunlong Yu, Xi Li</author><pubDate>Thu, 22 Aug 2024 15:10:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12469v1</guid></item><item><title>WCEbleedGen: A wireless capsule endoscopy dataset and its benchmarking for automatic bleeding classification, detection, and segmentation</title><link>http://arxiv.org/abs/2408.12466v1</link><description>Computer-based analysis of Wireless Capsule Endoscopy (WCE) is crucial.However, a medically annotated WCE dataset for training and evaluation ofautomatic classification, detection, and segmentation of bleeding andnon-bleeding frames is currently lacking. The present work focused ondevelopment of a medically annotated WCE dataset called WCEbleedGen forautomatic classification, detection, and segmentation of bleeding andnon-bleeding frames. It comprises 2,618 WCE bleeding and non-bleeding frameswhich were collected from various internet resources and existing WCE datasets.A comprehensive benchmarking and evaluation of the developed dataset was doneusing nine classification-based, three detection-based, and threesegmentation-based deep learning models. The dataset is of high-quality, isclass-balanced and contains single and multiple bleeding sites. Overall, ourstandard benchmark results show that Visual Geometric Group (VGG) 19, You OnlyLook Once version 8 nano (YOLOv8n), and Link network (Linknet) performed bestin automatic classification, detection, and segmentation-based evaluations,respectively. Automatic bleeding diagnosis is crucial for WCE videointerpretations. This diverse dataset will aid in developing of real-time,multi-task learning-based innovative solutions for automatic bleeding diagnosisin WCE. The dataset and code are publicly available athttps://zenodo.org/records/10156571 andhttps://github.com/misahub2023/Benchmarking-Codes-of-the-WCEBleedGen-dataset.</description><author>Palak Handa, Manas Dhir, Amirreza Mahbod, Florian Schwarzhans, Ramona Woitek, Nidhi Goel, Deepak Gunjan</author><pubDate>Thu, 22 Aug 2024 15:06:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12466v1</guid></item><item><title>Smartphone-based Eye Tracking System using Edge Intelligence and Model Optimisation</title><link>http://arxiv.org/abs/2408.12463v1</link><description>A significant limitation of current smartphone-based eye-tracking algorithmsis their low accuracy when applied to video-type visual stimuli, as they aretypically trained on static images. Also, the increasing demand for real-timeinteractive applications like games, VR, and AR on smartphones requiresovercoming the limitations posed by resource constraints such as limitedcomputational power, battery life, and network bandwidth. Therefore, wedeveloped two new smartphone eye-tracking techniques for video-type visuals bycombining Convolutional Neural Networks (CNN) with two different RecurrentNeural Networks (RNN), namely Long Short Term Memory (LSTM) and Gated RecurrentUnit (GRU). Our CNN+LSTM and CNN+GRU models achieved an average Root MeanSquare Error of 0.955cm and 1.091cm, respectively. To address the computationalconstraints of smartphones, we developed an edge intelligence architecture toenhance the performance of smartphone-based eye tracking. We applied variousoptimisation methods like quantisation and pruning to deep learning models forbetter energy, CPU, and memory usage on edge devices, focusing on real-timeprocessing. Using model quantisation, the model inference time in the CNN+LSTMand CNN+GRU models was reduced by 21.72% and 19.50%, respectively, on edgedevices.</description><author>Nishan Gunawardena, Gough Yumu Lui, Jeewani Anupama Ginige, Bahman Javadi</author><pubDate>Thu, 22 Aug 2024 15:04:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12463v1</guid></item><item><title>Finding Closure: A Closer Look at the Gestalt Law of Closure in Convolutional Neural Networks</title><link>http://arxiv.org/abs/2408.12460v1</link><description>The human brain has an inherent ability to fill in gaps to perceive figuresas complete wholes, even when parts are missing or fragmented. This phenomenonis known as Closure in psychology, one of the Gestalt laws of perceptualorganization, explaining how the human brain interprets visual stimuli. Giventhe importance of Closure for human object recognition, we investigate whetherneural networks rely on a similar mechanism. Exploring this crucial humanvisual skill in neural networks has the potential to highlight theircomparability to humans. Recent studies have examined the Closure effect inneural networks. However, they typically focus on a limited selection ofConvolutional Neural Networks (CNNs) and have not reached a consensus on theircapability to perform Closure. To address these gaps, we present a systematicframework for investigating the Closure principle in neural networks. Weintroduce well-curated datasets designed to test for Closure effects, includingboth modal and amodal completion. We then conduct experiments on various CNNsemploying different measurements. Our comprehensive analysis reveals that VGG16and DenseNet-121 exhibit the Closure effect, while other CNNs show variableresults. We interpret these findings by blending insights from psychology andneural network research, offering a unique perspective that enhancestransparency in understanding neural networks. Our code and dataset will bemade available on GitHub.</description><author>Yuyan Zhang, Derya Soydaner, Lisa Koßmann, Fatemeh Behrad, Johan Wagemans</author><pubDate>Thu, 22 Aug 2024 14:59:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12460v1</guid></item><item><title>Enhancing Multi-hop Reasoning through Knowledge Erasure in Large Language Model Editing</title><link>http://arxiv.org/abs/2408.12456v1</link><description>Large language models (LLMs) face challenges with internal knowledgeinaccuracies and outdated information. Knowledge editing has emerged as apivotal approach to mitigate these issues. Although current knowledge editingtechniques exhibit promising performance in single-hop reasoning tasks, theyshow limitations when applied to multi-hop reasoning. Drawing on cognitiveneuroscience and the operational mechanisms of LLMs, we hypothesize that theresidual single-hop knowledge after editing causes edited models to revert totheir original answers when processing multi-hop questions, thereby underminingtheir performance in multihop reasoning tasks. To validate this hypothesis, weconduct a series of experiments that empirically confirm our assumptions.Building on the validated hypothesis, we propose a novel knowledge editingmethod that incorporates a Knowledge Erasure mechanism for Large language modelEditing (KELE). Specifically, we design an erasure function for residualknowledge and an injection function for new knowledge. Through jointoptimization, we derive the optimal recall vector, which is subsequentlyutilized within a rank-one editing framework to update the parameters oftargeted model layers. Extensive experiments on GPT-J and GPT-2 XL demonstratethat KELE substantially enhances the multi-hop reasoning capability of editedLLMs.</description><author>Mengqi Zhang, Bowen Fang, Qiang Liu, Pengjie Ren, Shu Wu, Zhumin Chen, Liang Wang</author><pubDate>Thu, 22 Aug 2024 14:53:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12456v1</guid></item><item><title>Relaxed Rotational Equivariance via $G$-Biases in Vision</title><link>http://arxiv.org/abs/2408.12454v1</link><description>Group Equivariant Convolution (GConv) can effectively handle rotationalsymmetry data. They assume uniform and strict rotational symmetry across allfeatures, as the transformations under the specific group. However, real-worlddata rarely conforms to strict rotational symmetry commonly referred to asRotational Symmetry-Breaking in the system or dataset, making GConv unable toadapt effectively to this phenomenon. Motivated by this, we propose a simplebut highly effective method to address this problem, which utilizes a set oflearnable biases called the $G$-Biases under the group order to break strictgroup constraints and achieve \textbf{R}elaxed \textbf{R}otational\textbf{E}quivarant \textbf{Conv}olution (RREConv). We conduct extensiveexperiments to validate Relaxed Rotational Equivariance on rotational symmetrygroups $\mathcal{C}_n$ (e.g. $\mathcal{C}_2$, $\mathcal{C}_4$, and$\mathcal{C}_6$ groups). Further experiments demonstrate that our proposedRREConv-based methods achieve excellent performance, compared to existingGConv-based methods in classification and detection tasks on natural imagedatasets.</description><author>Zhiqiang Wu, Licheng Sun, Yingjie Liu, Jian Yang, Hanlin Dong, Shing-Ho J. Lin, Xuan Tang, Jinpeng Mi, Bo Jin, Xian Wei</author><pubDate>Thu, 22 Aug 2024 14:52:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12454v1</guid></item><item><title>Time Series Clustering with General State Space Models via Stochastic Variational Inference</title><link>http://arxiv.org/abs/2407.00429v2</link><description>In this paper, we propose a novel method of model-based time seriesclustering with mixtures of general state space models (MSSMs). Each componentof MSSMs is associated with each cluster. An advantage of the proposed methodis that it enables the use of time series models appropriate to the specifictime series. This not only improves clustering and prediction accuracy but alsoenhances the interpretability of the estimated parameters. The parameters ofthe MSSMs are estimated using stochastic variational inference, a subtype ofvariational inference. The proposed method estimates the latent variables of anarbitrary state space model by using neural networks with a normalizing flow asa variational estimator. The number of clusters can be estimated using theBayesian information criterion. In addition, to prevent MSSMs from convergingto the local optimum, we propose several optimization tricks, including anadditional penalty term called entropy annealing. To our best knowledge, theproposed method is the first computationally feasible one for time seriesclustering based on general (possibly nonlinear, non-Gaussian) state spacemodels. Experiments on simulated datasets show that the proposed method iseffective for clustering, parameter estimation, and estimating the number ofclusters.</description><author>Ryoichi Ishizuka, Takashi Imai, Kaoru Kawamoto</author><pubDate>Thu, 22 Aug 2024 14:50:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.00429v2</guid></item><item><title>skscope: Fast Sparsity-Constrained Optimization in Python</title><link>http://arxiv.org/abs/2403.18540v2</link><description>Applying iterative solvers on sparsity-constrained optimization (SCO)requires tedious mathematical deduction and careful programming/debugging thathinders these solvers' broad impact. In the paper, the library skscope isintroduced to overcome such an obstacle. With skscope, users can solve the SCOby just programming the objective function. The convenience of skscope isdemonstrated through two examples in the paper, where sparse linear regressionand trend filtering are addressed with just four lines of code. Moreimportantly, skscope's efficient implementation allows state-of-the-art solversto quickly attain the sparse solution regardless of the high dimensionality ofparameter space. Numerical experiments reveal the available solvers in skscopecan achieve up to 80x speedup on the competing relaxation solutions obtainedvia the benchmarked convex solver. skscope is published on the Python PackageIndex (PyPI) and Conda, and its source code is available at:https://github.com/abess-team/skscope.</description><author>Zezhi Wang, Jin Zhu, Peng Chen, Huiyang Peng, Xiaoke Zhang, Anran Wang, Junxian Zhu, Xueqin Wang</author><pubDate>Thu, 22 Aug 2024 14:49:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.18540v2</guid></item><item><title>Diff-Cleanse: Identifying and Mitigating Backdoor Attacks in Diffusion Models</title><link>http://arxiv.org/abs/2407.21316v2</link><description>Diffusion models (DMs) are regarded as one of the most advanced generativemodels today, yet recent studies suggest that they are vulnerable to backdoorattacks, which establish hidden associations between particular input patternsand model behaviors, compromising model integrity by causing undesirableactions with manipulated inputs. This vulnerability poses substantial risks,including reputational damage to model owners and the dissemination of harmfulcontent. To mitigate the threat of backdoor attacks, there have been someinvestigations on backdoor detection and model repair. However, previous workfails to reliably purify the models backdoored by state-of-the-art attackmethods, rendering the field much underexplored. To bridge this gap, weintroduce Diff-Cleanse, a novel two-stage backdoor defense frameworkspecifically designed for DMs. The first stage employs a novel triggerinversion technique to reconstruct the trigger and detect the backdoor, and thesecond stage utilizes a structural pruning method to eliminate the backdoor. Weevaluate our framework on hundreds of DMs that are attacked by three existingbackdoor attack methods with a wide range of hyperparameter settings. Extensiveexperiments demonstrate that Diff-Cleanse achieves nearly 100\% detectionaccuracy and effectively mitigates backdoor impacts, preserving the model'sbenign performance with minimal compromise. Our code is avaliable athttps://github.com/shymuel/diff-cleanse.</description><author>Jiang Hao, Xiao Jin, Hu Xiaoguang, Chen Tianyou, Zhao Jiajia</author><pubDate>Thu, 22 Aug 2024 14:46:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.21316v2</guid></item><item><title>The 2nd Solution for LSVOS Challenge RVOS Track: Spatial-temporal Refinement for Consistent Semantic Segmentation</title><link>http://arxiv.org/abs/2408.12447v1</link><description>Referring Video Object Segmentation (RVOS) is a challenging task due to itsrequirement for temporal understanding. Due to the obstacle of computationalcomplexity, many state-of-the-art models are trained on short time intervals.During testing, while these models can effectively process information overshort time steps, they struggle to maintain consistent perception overprolonged time sequences, leading to inconsistencies in the resulting semanticsegmentation masks. To address this challenge, we take a step further in thiswork by leveraging the tracking capabilities of the newly introduced SegmentAnything Model version 2 (SAM-v2) to enhance the temporal consistency of thereferring object segmentation model. Our method achieved a score of 60.40\mathcal{J\text{\&amp;}F} on the test set of the MeViS dataset, placing 2nd placein the final ranking of the RVOS Track at the ECCV 2024 LSVOS Challenge.</description><author>Tuyen Tran</author><pubDate>Thu, 22 Aug 2024 14:43:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12447v1</guid></item><item><title>EX-DRL: Hedging Against Heavy Losses with EXtreme Distributional Reinforcement Learning</title><link>http://arxiv.org/abs/2408.12446v1</link><description>Recent advancements in Distributional Reinforcement Learning (DRL) formodeling loss distributions have shown promise in developing hedging strategiesin derivatives markets. A common approach in DRL involves learning thequantiles of loss distributions at specified levels using Quantile Regression(QR). This method is particularly effective in option hedging due to its directquantile-based risk assessment, such as Value at Risk (VaR) and ConditionalValue at Risk (CVaR). However, these risk measures depend on the accurateestimation of extreme quantiles in the loss distribution's tail, which can beimprecise in QR-based DRL due to the rarity and extremity of tail data, ashighlighted in the literature. To address this issue, we propose EXtreme DRL(EX-DRL), which enhances extreme quantile prediction by modeling the tail ofthe loss distribution with a Generalized Pareto Distribution (GPD). This methodintroduces supplementary data to mitigate the scarcity of extreme quantileobservations, thereby improving estimation accuracy through QR. Comprehensiveexperiments on gamma hedging options demonstrate that EX-DRL improves existingQR-based models by providing more precise estimates of extreme quantiles,thereby improving the computation and reliability of risk metrics for complexfinancial risk management.</description><author>Parvin Malekzadeh, Zissis Poulos, Jacky Chen, Zeyu Wang, Konstantinos N. Plataniotis</author><pubDate>Thu, 22 Aug 2024 14:41:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12446v1</guid></item><item><title>Verifiable Homomorphic Linear Combinations in Multi-Instance Time-Lock Puzzles</title><link>http://arxiv.org/abs/2408.12444v1</link><description>Time-Lock Puzzles (TLPs) have been developed to securely transmit sensitiveinformation into the future without relying on a trusted third party.Multi-instance TLP is a scalable variant of TLP that enables a server toefficiently find solutions to different puzzles provided by a client at once.Nevertheless, existing multi-instance TLPs lack support for (verifiable)homomorphic computation. To address this limitation, we introduce the"Multi-Instance partially Homomorphic TLP" (MH-TLP), a multi-instance TLPsupporting efficient verifiable homomorphic linear combinations of puzzlesbelonging to a client. It ensures anyone can verify the correctness ofcomputations and solutions. Building on MH-TLP, we further propose the"Multi-instance Multi-client verifiable partially Homomorphic TLP" (MMH-TLP).It not only supports all the features of MH-TLP but also allows for verifiablehomomorphic linear combinations of puzzles from different clients. Our schemesrefrain from using asymmetric-key cryptography for verification and, unlikemost homomorphic TLPs, do not require a trusted third party. A comprehensivecost analysis demonstrates that our schemes scale linearly with the number ofclients and puzzles.</description><author>Aydin Abadi</author><pubDate>Thu, 22 Aug 2024 14:40:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12444v1</guid></item><item><title>A Riemannian Approach for Spatiotemporal Analysis and Generation of 4D Tree-shaped Structures</title><link>http://arxiv.org/abs/2408.12443v1</link><description>We propose the first comprehensive approach for modeling and analyzing thespatiotemporal shape variability in tree-like 4D objects, i.e., 3D objectswhose shapes bend, stretch, and change in their branching structure over timeas they deform, grow, and interact with their environment. Our key contributionis the representation of tree-like 3D shapes using Square Root VelocityFunction Trees (SRVFT). By solving the spatial registration in the SRVFT space,which is equipped with an L2 metric, 4D tree-shaped structures becometime-parameterized trajectories in this space. This reduces the problem ofmodeling and analyzing 4D tree-like shapes to that of modeling and analyzingelastic trajectories in the SRVFT space, where elasticity refers to timewarping. In this paper, we propose a novel mathematical representation of theshape space of such trajectories, a Riemannian metric on that space, andcomputational tools for fast and accurate spatiotemporal registration andgeodesics computation between 4D tree-shaped structures. Leveraging thesebuilding blocks, we develop a full framework for modelling the spatiotemporalvariability using statistical models and generating novel 4D tree-likestructures from a set of exemplars. We demonstrate and validate the proposedframework using real 4D plant data.</description><author>Tahmina Khanam, Hamid Laga, Mohammed Bennamoun, Guanjin Wang, Ferdous Sohel, Farid Boussaid, Guan Wang, Anuj Srivastava</author><pubDate>Thu, 22 Aug 2024 14:39:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12443v1</guid></item><item><title>Adapting MIMO video restoration networks to low latency constraints</title><link>http://arxiv.org/abs/2408.12439v1</link><description>MIMO (multiple input, multiple output) approaches are a recent trend inneural network architectures for video restoration problems, where each networkevaluation produces multiple output frames. The video is split intonon-overlapping stacks of frames that are processed independently, resulting ina very appealing trade-off between output quality and computational cost. Inthis work we focus on the low-latency setting by limiting the number ofavailable future frames. We find that MIMO architectures suffer from problemsthat have received little attention so far, namely (1) the performance dropssignificantly due to the reduced temporal receptive field, particularly forframes at the borders of the stack, (2) there are strong temporaldiscontinuities at stack transitions which induce a step-wise motion artifact.We propose two simple solutions to alleviate these problems: recurrence acrossMIMO stacks to boost the output quality by implicitly increasing the temporalreceptive field, and overlapping of the output stacks to smooth the temporaldiscontinuity at stack transitions. These modifications can be applied to anyMIMO architecture. We test them on three state-of-the-art video denoisingnetworks with different computational cost. The proposed contributions resultin a new state-of-the-art for low-latency networks, both in terms ofreconstruction error and temporal consistency. As an additional contribution,we introduce a new benchmark consisting of drone footage that highlightstemporal consistency issues that are not apparent in the standard benchmarks.</description><author>Valéry Dewil, Zhe Zheng, Arnaud Barral, Lara Raad, Nao Nicolas, Ioannis Cassagne, Jean-michel Morel, Gabriele Facciolo, Bruno Galerne, Pablo Arias</author><pubDate>Thu, 22 Aug 2024 14:36:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12439v1</guid></item><item><title>Robotic Eye-in-hand Visual Servo Axially Aligning Nasopharyngeal Swabs with the Nasal Cavity</title><link>http://arxiv.org/abs/2408.12437v1</link><description>The nasopharyngeal (NP) swab test is a method for collecting cultures todiagnose for different types of respiratory illnesses, including COVID-19.Delegating this task to robots would be beneficial in terms of reducinginfection risks and bolstering the healthcare system, but a critical componentof the NP swab test is having the swab aligned properly with the nasal cavityso that it does not cause excessive discomfort or injury by traveling down thewrong passage. Existing research towards robotic NP swabbing typically assumesthe patient's head is held within a fixture. This simplifies the alignmentproblem, but is also dissimilar to clinical scenarios where patients aretypically free-standing. Consequently, our work creates a vision-guidedpipeline to allow an instrumented robot arm to properly position and orient NPswabs with respect to the nostrils of free-standing patients. The firstcomponent of the pipeline is a precomputed joint lookup table to allow the armto meet the patient's arbitrary position in the designated workspace, whileavoiding joint limits. Our pipeline leverages semantic face models fromcomputer vision to estimate the Euclidean pose of the face with respect to amonocular RGB-D camera placed on the end-effector. These estimates are passedinto an unscented Kalman filter on manifolds state estimator and a pose basedvisual servo control loop to move the swab to the designated pose in front ofthe nostril. Our pipeline was validated with human trials, featuring a cohortof 25 participants. The system is effective, reaching the nostril for 84% ofparticipants, and our statistical analysis did not find significant demographicbiases within the cohort.</description><author>Peter Q. Lee, John S. Zelek, Katja Mombaur</author><pubDate>Thu, 22 Aug 2024 14:36:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12437v1</guid></item><item><title>Positional Description for Numerical Normalization</title><link>http://arxiv.org/abs/2408.12430v1</link><description>We present a Positional Description Scheme (PDS) tailored for digitsequences, integrating placeholder value information for each digit. Given thestructural limitations of subword tokenization algorithms, language modelsencounter critical Text Normalization (TN) challenges when handling numericaltasks. Our schema addresses this challenge through straightforwardpre-processing, preserving the model architecture while significantlysimplifying number normalization, rendering the problem tractable. Thissimplifies the task and facilitates more compact production-ready modelscapable of learning from smaller datasets. Furthermore, our investigationsreveal that PDS enhances the arithmetic processing capabilities of languagemodels, resulting in a relative accuracy improvement of 23% to 51% on complexarithmetic tasks. We demonstrate that PDS effectively mitigates fatal numericalnormalization errors in neural models, requiring only a modest amount oftraining data without rule-based Finite State Transducers (FST). We demonstratethat PDS is essential for both the Text-To-Speech and Speech Recognition textprocessing, enabling effective TN under production constraints.</description><author>Deepanshu Gupta, Javier Latorre</author><pubDate>Thu, 22 Aug 2024 14:24:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12430v1</guid></item><item><title>FlexEdit: Marrying Free-Shape Masks to VLLM for Flexible Image Editing</title><link>http://arxiv.org/abs/2408.12429v1</link><description>Combining Vision Large Language Models (VLLMs) with diffusion models offers apowerful method for executing image editing tasks based on human languageinstructions. However, language instructions alone often fall short inaccurately conveying user requirements, particularly when users want to add,replace elements in specific areas of an image. Luckily, masks can effectivelyindicate the exact locations or elements to be edited, while they require usersto precisely draw the shapes at the desired locations, which is highlyuser-unfriendly. To address this, we propose FlexEdit, an end-to-end imageediting method that leverages both free-shape masks and language instructionsfor Flexible Editing. Our approach employs a VLLM in comprehending the imagecontent, mask, and user instructions. Additionally, we introduce the MaskEnhance Adapter (MEA) that fuses the embeddings of the VLLM with the imagedata, ensuring a seamless integration of mask information and model outputembeddings. Furthermore, we construct FSMI-Edit, a benchmark specificallytailored for free-shape mask, including 8 types of free-shape mask. Extensiveexperiments show that our method achieves state-of-the-art (SOTA) performancein LLM-based image editing, and our simple prompting technique stands out inits effectiveness. The code and data can be found athttps://github.com/A-new-b/flex_edit.</description><author>Jue Wang, Yuxiang Lin, Tianshuo Yuan, Zhi-Qi Cheng, Xiaolong Wang, Jiao GH, Wei Chen, Xiaojiang Peng</author><pubDate>Thu, 22 Aug 2024 14:22:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12429v1</guid></item><item><title>Enhanced Infield Agriculture with Interpretable Machine Learning Approaches for Crop Classification</title><link>http://arxiv.org/abs/2408.12426v1</link><description>The increasing popularity of Artificial Intelligence in recent years has ledto a surge in interest in image classification, especially in the agriculturalsector. With the help of Computer Vision, Machine Learning, and Deep Learning,the sector has undergone a significant transformation, leading to thedevelopment of new techniques for crop classification in the field. Despite theextensive research on various image classification techniques, most havelimitations such as low accuracy, limited use of data, and a lack of reportingmodel size and prediction. The most significant limitation of all is the needfor model explainability. This research evaluates four different approaches forcrop classification, namely traditional ML with handcrafted feature extractionmethods like SIFT, ORB, and Color Histogram; Custom Designed CNN andestablished DL architecture like AlexNet; transfer learning on five modelspre-trained using ImageNet such as EfficientNetV2, ResNet152V2, Xception,Inception-ResNetV2, MobileNetV3; and cutting-edge foundation models like YOLOv8and DINOv2, a self-supervised Vision Transformer Model. All models performedwell, but Xception outperformed all of them in terms of generalization,achieving 98% accuracy on the test data, with a model size of 80.03 MB and aprediction time of 0.0633 seconds. A key aspect of this research was theapplication of Explainable AI to provide the explainability of all the models.This journal presents the explainability of Xception model with LIME, SHAP, andGradCAM, ensuring transparency and trustworthiness in the models' predictions.This study highlights the importance of selecting the right model according totask-specific needs. It also underscores the important role of explainabilityin deploying AI in agriculture, providing insightful information to helpenhance AI-driven crop management strategies.</description><author>Sudi Murindanyi, Joyce Nakatumba-Nabende, Rahman Sanya, Rose Nakibuule, Andrew Katumba</author><pubDate>Thu, 22 Aug 2024 14:20:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12426v1</guid></item><item><title>Dynamic Gated Recurrent Neural Network for Compute-efficient Speech Enhancement</title><link>http://arxiv.org/abs/2408.12425v1</link><description>This paper introduces a new Dynamic Gated Recurrent Neural Network (DG-RNN)for compute-efficient speech enhancement models running on resource-constrainedhardware platforms. It leverages the slow evolution characteristic of RNNhidden states over steps, and updates only a selected set of neurons at eachstep by adding a newly proposed select gate to the RNN model. This select gateallows the computation cost of the conventional RNN to be reduced duringnetwork inference. As a realization of the DG-RNN, we further propose theDynamic Gated Recurrent Unit (D-GRU) which does not require additionalparameters. Test results obtained from several state-of-the-artcompute-efficient RNN-based speech enhancement architectures using the DNSchallenge dataset, show that the D-GRU based model variants maintain similarspeech intelligibility and quality metrics comparable to the baseline GRU basedmodels even with an average 50% reduction in GRU computes.</description><author>Longbiao Cheng, Ashutosh Pandey, Buye Xu, Tobi Delbruck, Shih-Chii Liu</author><pubDate>Thu, 22 Aug 2024 14:20:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12425v1</guid></item><item><title>Dual-path Frequency Discriminators for Few-shot Anomaly Detection</title><link>http://arxiv.org/abs/2403.04151v4</link><description>Few-shot anomaly detection (FSAD) plays a crucial role in industrialmanufacturing. However, existing FSAD methods encounter difficulties leveraginga limited number of normal samples, frequently failing to detect and locateinconspicuous anomalies in the spatial domain. We have further discovered thatthese subtle anomalies would be more noticeable in the frequency domain. Inthis paper, we propose a Dual-Path Frequency Discriminators (DFD) network froma frequency perspective to tackle these issues. The original spatial images aretransformed into multi-frequency images, making them more conducive to thetailored discriminators in detecting anomalies. Additionally, thediscriminators learn a joint representation with forms of pseudo-anomalies.Extensive experiments conducted on MVTec AD and VisA benchmarks demonstratethat our DFD surpasses current state-of-the-art methods. The code is availableat \url{https://github.com/yuhbai/DFD}.</description><author>Yuhu Bai, Jiangning Zhang, Zhaofeng Chen, Yuhang Dong, Yunkang Cao, Guanzhong Tian</author><pubDate>Thu, 22 Aug 2024 14:19:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2403.04151v4</guid></item><item><title>Can we trust the evaluation on ChatGPT?</title><link>http://arxiv.org/abs/2303.12767v2</link><description>ChatGPT, the first large language model (LLM) with mass adoption, hasdemonstrated remarkable performance in numerous natural language tasks. Despiteits evident usefulness, evaluating ChatGPT's performance in diverse problemdomains remains challenging due to the closed nature of the model and itscontinuous updates via Reinforcement Learning from Human Feedback (RLHF). Wehighlight the issue of data contamination in ChatGPT evaluations, with a casestudy of the task of stance detection. We discuss the challenge of preventingdata contamination and ensuring fair model evaluation in the age of closed andcontinuously trained models.</description><author>Rachith Aiyappa, Jisun An, Haewoon Kwak, Yong-Yeol Ahn</author><pubDate>Thu, 22 Aug 2024 14:19:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.12767v2</guid></item><item><title>Multi-Knowledge Fusion Network for Time Series Representation Learning</title><link>http://arxiv.org/abs/2408.12423v1</link><description>Forecasting the behaviour of complex dynamical systems such as interconnectedsensor networks characterized by high-dimensional multivariate time series(MTS)is of paramount importance for making informed decisions and planning for thefuture in a broad spectrum of applications. Graph forecasting networks(GFNs)are well-suited for forecasting MTS data that exhibit spatio-temporaldependencies. However, most prior works of GFN-based methods on MTS forecastingrely on domain-expertise to model the nonlinear dynamics of the system, butneglect the potential to leverage the inherent relational-structuraldependencies among time series variables underlying MTS data. On the otherhand, contemporary works attempt to infer the relational structure of thecomplex dependencies between the variables and simultaneously learn thenonlinear dynamics of the interconnected system but neglect the possibility ofincorporating domain-specific prior knowledge to improve forecast accuracy. Tothis end, we propose a hybrid architecture that combines explicit priorknowledge with implicit knowledge of the relational structure within the MTSdata. It jointly learns intra-series temporal dependencies and inter-seriesspatial dependencies by encoding time-conditioned structural spatio-temporalinductive biases to provide more accurate and reliable forecasts. It alsomodels the time-varying uncertainty of the multi-horizon forecasts to supportdecision-making by providing estimates of prediction uncertainty. The proposedarchitecture has shown promising results on multiple benchmark datasets andoutperforms state-of-the-art forecasting methods by a significant margin. Wereport and discuss the ablation studies to validate our forecastingarchitecture.</description><author>Sagar Srinivas Sakhinana, Shivam Gupta, Krishna Sai Sudhir Aripirala, Venkataramana Runkana</author><pubDate>Thu, 22 Aug 2024 14:18:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12423v1</guid></item><item><title>Human-Aware Belief Revision: A Cognitively Inspired Framework for Explanation-Guided Revision of Human Models</title><link>http://arxiv.org/abs/2405.19238v2</link><description>Traditional belief revision frameworks often rely on the principle ofminimalism, which advocates minimal changes to existing beliefs. However,research in human cognition suggests that people are inherently driven to seekexplanations for inconsistencies, thereby striving for explanatoryunderstanding rather than minimal changes when revising beliefs. Traditionalframeworks often fail to account for these cognitive patterns, relying insteadon formal principles that may not reflect actual human reasoning. To addressthis gap, we introduce Human-Aware Belief Revision, a cognitively-inspiredframework for modeling human belief revision dynamics, where given a humanmodel and an explanation for an explanandum, revises the model in a non-minimalway that aligns with human cognition. Finally, we conduct two human-subjectstudies to empirically evaluate our framework under real-world scenarios. Ourfindings support our hypotheses and provide insights into the strategies peopleemploy when resolving inconsistencies, offering some guidance for developingmore effective human-aware AI systems.</description><author>Stylianos Loukas Vasileiou, William Yeoh</author><pubDate>Thu, 22 Aug 2024 14:17:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.19238v2</guid></item><item><title>Dataset | Mindset = Explainable AI | Interpretable AI</title><link>http://arxiv.org/abs/2408.12420v1</link><description>We often use "explainable" Artificial Intelligence (XAI)" and "interpretableAI (IAI)" interchangeably when we apply various XAI tools for a given datasetto explain the reasons that underpin machine learning (ML) outputs. However,these notions can sometimes be confusing because interpretation often has asubjective connotation, while explanations lean towards objective facts. Weargue that XAI is a subset of IAI. The concept of IAI is beyond the sphere of adataset. It includes the domain of a mindset. At the core of this ambiguity isthe duality of reasons, in which we can reason either outwards or inwards. Whendirected outwards, we want the reasons to make sense through the laws ofnature. When turned inwards, we want the reasons to be happy, guided by thelaws of the heart. While XAI and IAI share reason as the common notion for thegoal of transparency, clarity, fairness, reliability, and accountability in thecontext of ethical AI and trustworthy AI (TAI), their differences lie in thatXAI emphasizes the post-hoc analysis of a dataset, and IAI requires a priorimindset of abstraction. This hypothesis can be proved by empirical experimentsbased on an open dataset and harnessed by High-Performance Computing (HPC). Thedemarcation of XAI and IAI is indispensable because it would be impossible todetermine regulatory policies for many AI applications, especially inhealthcare, human resources, banking, and finance. We aim to clarify thesenotions and lay the foundation of XAI, IAI, EAI, and TAI for many practitionersand policymakers in future AI applications and research.</description><author>Caesar Wu, Rajkumar Buyya, Yuan Fang Li, Pascal Bouvry</author><pubDate>Thu, 22 Aug 2024 14:12:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12420v1</guid></item><item><title>4D Diffusion for Dynamic Protein Structure Prediction with Reference Guided Motion Alignment</title><link>http://arxiv.org/abs/2408.12419v1</link><description>Protein structure prediction is pivotal for understanding thestructure-function relationship of proteins, advancing biological research, andfacilitating pharmaceutical development and experimental design. While deeplearning methods and the expanded availability of experimental 3D proteinstructures have accelerated structure prediction, the dynamic nature of proteinstructures has received limited attention. This study introduces an innovative4D diffusion model incorporating molecular dynamics (MD) simulation data tolearn dynamic protein structures. Our approach is distinguished by thefollowing components: (1) a unified diffusion model capable of generatingdynamic protein structures, including both the backbone and side chains,utilizing atomic grouping and side-chain dihedral angle predictions; (2) areference network that enhances structural consistency by integrating thelatent embeddings of the initial 3D protein structures; and (3) a motionalignment module aimed at improving temporal structural coherence acrossmultiple time steps. To our knowledge, this is the first diffusion-based modelaimed at predicting protein trajectories across multiple time stepssimultaneously. Validation on benchmark datasets demonstrates that our modelexhibits high accuracy in predicting dynamic 3D structures of proteinscontaining up to 256 amino acids over 32 time steps, effectively capturing bothlocal flexibility in stable states and significant conformational changes.</description><author>Kaihui Cheng, Ce Liu, Qingkun Su, Jun Wang, Liwei Zhang, Yining Tang, Yao Yao, Siyu Zhu, Yuan Qi</author><pubDate>Thu, 22 Aug 2024 14:12:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12419v1</guid></item><item><title>CODE: Confident Ordinary Differential Editing</title><link>http://arxiv.org/abs/2408.12418v1</link><description>Conditioning image generation facilitates seamless editing and the creationof photorealistic images. However, conditioning on noisy or Out-of-Distribution(OoD) images poses significant challenges, particularly in balancing fidelityto the input and realism of the output. We introduce Confident OrdinaryDifferential Editing (CODE), a novel approach for image synthesis thateffectively handles OoD guidance images. Utilizing a diffusion model as agenerative prior, CODE enhances images through score-based updates along theprobability-flow Ordinary Differential Equation (ODE) trajectory. This methodrequires no task-specific training, no handcrafted modules, and no assumptionsregarding the corruptions affecting the conditioning image. Our method iscompatible with any diffusion model. Positioned at the intersection ofconditional image generation and blind image restoration, CODE operates in afully blind manner, relying solely on a pre-trained generative model. Ourmethod introduces an alternative approach to blind restoration: instead oftargeting a specific ground truth image based on assumptions about theunderlying corruption, CODE aims to increase the likelihood of the input imagewhile maintaining fidelity. This results in the most probable in-distributionimage around the input. Our contributions are twofold. First, CODE introduces anovel editing method based on ODE, providing enhanced control, realism, andfidelity compared to its SDE-based counterpart. Second, we introduce aconfidence interval-based clipping method, which improves CODE's effectivenessby allowing it to disregard certain pixels or information, thus enhancing therestoration process in a blind manner. Experimental results demonstrate CODE'seffectiveness over existing methods, particularly in scenarios involving severedegradation or OoD inputs.</description><author>Bastien van Delft, Tommaso Martorella, Alexandre Alahi</author><pubDate>Thu, 22 Aug 2024 14:12:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12418v1</guid></item><item><title>Unlearning Trojans in Large Language Models: A Comparison Between Natural Language and Source Code</title><link>http://arxiv.org/abs/2408.12416v1</link><description>This work investigates the application of Machine Unlearning (MU) formitigating the impact of trojans embedded in conventional large language modelsof natural language (Text-LLMs) and large language models of code (Code-LLMs)We propose a novel unlearning approach, LYA, that leverages both gradientascent and elastic weight consolidation, a Fisher Information Matrix (FIM)based regularization technique, to unlearn trojans from poisoned models. Wecompare the effectiveness of LYA against conventional techniques likefine-tuning, retraining, and vanilla gradient ascent. The subject models weinvestigate are BERT and CodeBERT, for sentiment analysis and code defectdetection tasks, respectively. Our findings demonstrate that the combination ofgradient ascent and FIM-based regularization, as done in LYA, outperformsexisting methods in removing the trojan's influence from the poisoned model,while preserving its original functionality. To the best of our knowledge, thisis the first work that compares and contrasts MU of trojans in LLMs, in the NLand Coding domain.</description><author>Mahdi Kazemi, Aftab Hussain, Md Rafiqul Islam Rabin, Mohammad Amin Alipour, Sen Lin</author><pubDate>Thu, 22 Aug 2024 14:12:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12416v1</guid></item><item><title>Dynamic PDB: A New Dataset and a SE(3) Model Extension by Integrating Dynamic Behaviors and Physical Properties in Protein Structures</title><link>http://arxiv.org/abs/2408.12413v1</link><description>Despite significant progress in static protein structure collection andprediction, the dynamic behavior of proteins, one of their most vitalcharacteristics, has been largely overlooked in prior research. This oversightcan be attributed to the limited availability, diversity, and heterogeneity ofdynamic protein datasets. To address this gap, we propose to enhance existingprestigious static 3D protein structural databases, such as the Protein DataBank (PDB), by integrating dynamic data and additional physical properties.Specifically, we introduce a large-scale dataset, Dynamic PDB, encompassingapproximately 12.6K proteins, each subjected to all-atom molecular dynamics(MD) simulations lasting 1 microsecond to capture conformational changes.Furthermore, we provide a comprehensive suite of physical properties, includingatomic velocities and forces, potential and kinetic energies of proteins, andthe temperature of the simulation environment, recorded at 1 picosecondintervals throughout the simulations. For benchmarking purposes, we evaluatestate-of-the-art methods on the proposed dataset for the task of trajectoryprediction. To demonstrate the value of integrating richer physical propertiesin the study of protein dynamics and related model design, we base our approachon the SE(3) diffusion model and incorporate these physical properties into thetrajectory prediction process. Preliminary results indicate that thisstraightforward extension of the SE(3) model yields improved accuracy, asmeasured by MAE and RMSD, when the proposed physical properties are taken intoconsideration.</description><author>Ce Liu, Jun Wang, Zhiqiang Cai, Yingxu Wang, Huizhen Kuang, Kaihui Cheng, Liwei Zhang, Qingkun Su, Yining Tang, Fenglei Cao, Limei Han, Siyu Zhu, Yuan Qi</author><pubDate>Thu, 22 Aug 2024 14:06:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12413v1</guid></item><item><title>An Evaluation of Deep Learning Models for Stock Market Trend Prediction</title><link>http://arxiv.org/abs/2408.12408v1</link><description>The stock market is a fundamental component of financial systems, reflectingeconomic health, providing investment opportunities, and influencing globaldynamics. Accurate stock market predictions can lead to significant gains andpromote better investment decisions. However, predicting stock market trends ischallenging due to their non-linear and stochastic nature. This studyinvestigates the efficacy of advanced deep learning models for short-term trendforecasting using daily and hourly closing prices from the S&amp;P 500 index andthe Brazilian ETF EWZ. The models explored include Temporal ConvolutionalNetworks (TCN), Neural Basis Expansion Analysis for Time Series Forecasting(N-BEATS), Temporal Fusion Transformers (TFT), Neural HierarchicalInterpolation for Time Series Forecasting (N-HiTS), and Time-series DenseEncoder (TiDE). Furthermore, we introduce the Extended Long Short-Term Memoryfor Time Series (xLSTM-TS) model, an xLSTM adaptation optimised for time seriesprediction. Wavelet denoising techniques were applied to smooth the signal andreduce minor fluctuations, providing cleaner data as input for all approaches.Denoising significantly improved performance in predicting stock pricedirection. Among the models tested, xLSTM-TS consistently outperformed others.For example, it achieved a test accuracy of 72.82% and an F1 score of 73.16% onthe EWZ daily dataset. By leveraging advanced deep learning models andeffective data preprocessing techniques, this research provides valuableinsights into the application of machine learning for market movementforecasting, highlighting both the potential and the challenges involved.</description><author>Gonzalo Lopez Gil, Paul Duhamel-Sebline, Andrew McCarren</author><pubDate>Thu, 22 Aug 2024 13:58:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12408v1</guid></item><item><title>Multi-Source Knowledge-Based Hybrid Neural Framework for Time Series Representation Learning</title><link>http://arxiv.org/abs/2408.12409v1</link><description>Accurately predicting the behavior of complex dynamical systems,characterized by high-dimensional multivariate time series(MTS) ininterconnected sensor networks, is crucial for informed decision-making invarious applications to minimize risk. While graph forecasting networks(GFNs)are ideal for forecasting MTS data that exhibit spatio-temporal dependencies,prior works rely solely on the domain-specific knowledge of time-seriesvariables inter-relationships to model the nonlinear dynamics, neglectinginherent relational structural dependencies among the variables within the MTSdata. In contrast, contemporary works infer relational structures from MTS databut neglect domain-specific knowledge. The proposed hybrid architectureaddresses these limitations by combining both domain-specific knowledge andimplicit knowledge of the relational structure underlying the MTS data usingKnowledge-Based Compositional Generalization. The hybrid architecture showspromising results on multiple benchmark datasets, outperformingstate-of-the-art forecasting methods. Additionally, the architecture models thetime varying uncertainty of multi-horizon forecasts.</description><author>Sagar Srinivas Sakhinana, Krishna Sai Sudhir Aripirala, Shivam Gupta, Venkataramana Runkana</author><pubDate>Thu, 22 Aug 2024 13:58:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12409v1</guid></item><item><title>Adaptive Spiking Neural Networks with Hybrid Coding</title><link>http://arxiv.org/abs/2408.12407v1</link><description>The Spiking Neural Network (SNN), due to its unique spiking-driven nature, isa more energy-efficient and effective neural network compared to ArtificialNeural Networks (ANNs). The encoding method directly influences the overallperformance of the network, and currently, direct encoding is primarily usedfor directly trained SNNs. When working with static image datasets, directencoding inputs the same feature map at every time step, failing to fullyexploit the spatiotemporal properties of SNNs. While temporal encoding convertsinput data into spike trains with spatiotemporal characteristics, traditionalSNNs utilize the same neurons when processing input data across different timesteps, limiting their ability to integrate and utilize spatiotemporalinformation effectively.To address this, this paper employs temporal encodingand proposes the Adaptive Spiking Neural Network (ASNN), enhancing theutilization of temporal encoding in conventional SNNs. Additionally, temporalencoding is less frequently used because short time steps can lead tosignificant loss of input data information, often necessitating a higher numberof time steps in practical applications. However, training large SNNs with longtime steps is challenging due to hardware constraints. To overcome this, thispaper introduces a hybrid encoding approach that not only reduces the requiredtime steps for training but also continues to improve the overall networkperformance.Notably, significant improvements in classification performance areobserved on both Spikformer and Spiking ResNet architectures.our code isavailable at https://github.com/hhx0320/ASNN</description><author>Huaxu He</author><pubDate>Thu, 22 Aug 2024 13:58:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12407v1</guid></item><item><title>Generalized SAM: Efficient Fine-Tuning of SAM for Variable Input Image Sizes</title><link>http://arxiv.org/abs/2408.12406v1</link><description>There has been a lot of recent research on improving the efficiency offine-tuning foundation models. In this paper, we propose a novel efficientfine-tuning method that allows the input image size of Segment Anything Model(SAM) to be variable. SAM is a powerful foundational model for imagesegmentation trained on huge datasets, but it requires fine-tuning to recognizearbitrary classes. The input image size of SAM is fixed at 1024 x 1024,resulting in substantial computational demands during training. Furthermore,the fixed input image size may result in the loss of image information, e.g.due to fixed aspect ratios. To address this problem, we propose Generalized SAM(GSAM). Different from the previous methods, GSAM is the first to apply randomcropping during training with SAM, thereby significantly reducing thecomputational cost of training. Experiments on datasets of various types andvarious pixel counts have shown that GSAM can train more efficiently than SAMand other fine-tuning methods for SAM, achieving comparable or higher accuracy.</description><author>Sota Kato, Hinako Mitsuoka, Kazuhiro Hotta</author><pubDate>Thu, 22 Aug 2024 13:58:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2408.12406v1</guid></item><item><title>Domain Generalization through Meta-Learning: A Survey</title><link>http://arxiv.org/abs/2404.02785v3</link><description>Deep neural networks (DNNs) have revolutionized artificial intelligence butoften lack performance when faced with out-of-distribution (OOD) data, a commonscenario due to the inevitable domain shifts in real-world applications. Thislimitation stems from the common assumption that training and testing datashare the same distribution--an assumption frequently violated in practice.Despite their effectiveness with large amounts of data and computational power,DNNs struggle with distributional shifts and limited labeled data, leading tooverfitting and poor generalization across various tasks and domains.Meta-learning presents a promising approach by employing algorithms thatacquire transferable knowledge across various tasks for fast adaptation,eliminating the need to learn each task from scratch. This survey paper delvesinto the realm of meta-learning with a focus on its contribution to domaingeneralization. We first clarify the concept of meta-learning for domaingeneralization and introduce a novel taxonomy based on the feature extractionstrategy and the classifier learning methodology, offering a granular view ofmethodologies. Additionally, we present a decision graph to assist readers innavigating the taxonomy based on data availability and domain shifts, enablingthem to select and develop a proper model tailored to their specific problemrequirements. Through an exhaustive review of existing methods and underlyingtheories, we map out the fundamentals of the field. Our survey providespractical insights and an informed discussion on promising research directions.</description><author>Arsham Gholamzadeh Khoee, Yinan Yu, Robert Feldt</author><pubDate>Thu, 22 Aug 2024 13:57:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.02785v3</guid></item><item><title>AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy</title><link>http://arxiv.org/abs/2402.07862v2</link><description>Large language models (LLMs) match and sometimes exceeding human performancein many domains. This study explores the potential of LLMs to augment humanjudgement in a forecasting task. We evaluate the effect on human forecasters oftwo LLM assistants: one designed to provide high-quality ("superforecasting")advice, and the other designed to be overconfident and base-rate neglecting,thus providing noisy forecasting advice. We compare participants using theseassistants to a control group that received a less advanced model that did notprovide numerical predictions or engaged in explicit discussion of predictions.Participants (N = 991) answered a set of six forecasting questions and had theoption to consult their assigned LLM assistant throughout. Our preregisteredanalyses show that interacting with each of our frontier LLM assistantssignificantly enhances prediction accuracy by between 24 percent and 28 percentcompared to the control group. Exploratory analyses showed a pronounced outliereffect in one forecasting item, without which we find that the superforecastingassistant increased accuracy by 41 percent, compared with 29 percent for thenoisy assistant. We further examine whether LLM forecasting augmentationdisproportionately benefits less skilled forecasters, degrades thewisdom-of-the-crowd by reducing prediction diversity, or varies ineffectiveness with question difficulty. Our data do not consistently supportthese hypotheses. Our results suggest that access to a frontier LLM assistant,even a noisy one, can be a helpful decision aid in cognitively demanding taskscompared to a less powerful model that does not provide specific forecastingadvice. However, the effects of outliers suggest that further research into therobustness of this pattern is needed.</description><author>Philipp Schoenegger, Peter S. Park, Ezra Karger, Sean Trott, Philip E. Tetlock</author><pubDate>Thu, 22 Aug 2024 13:57:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07862v2</guid></item></channel></rss>