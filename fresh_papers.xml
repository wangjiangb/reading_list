<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 24 Jul 2023 06:00:27 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Differentially Private Heavy Hitter Detection using Federated Analytics</title><link>http://arxiv.org/abs/2307.11749v1</link><description>In this work, we study practical heuristics to improve the performance ofprefix-tree based algorithms for differentially private heavy hitter detection.Our model assumes each user has multiple data points and the goal is to learnas many of the most frequent data points as possible across all users' datawith aggregate and local differential privacy. We propose an adaptivehyperparameter tuning algorithm that improves the performance of the algorithmwhile satisfying computational, communication and privacy constraints. Weexplore the impact of different data-selection schemes as well as the impact ofintroducing deny lists during multiple runs of the algorithm. We test theseimprovements using extensive experimentation on the Redditdataset~\cite{caldas2018leaf} on the task of learning the most frequent words.</description><author>Karan Chadha, Junye Chen, John Duchi, Vitaly Feldman, Hanieh Hashemi, Omid Javidbakht, Audra McMillan, Kunal Talwar</author><pubDate>Fri, 21 Jul 2023 18:59:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11749v1</guid></item><item><title>BandRe: Rethinking Band-Pass Filters for Scale-Wise Object Detection Evaluation</title><link>http://arxiv.org/abs/2307.11748v1</link><description>Scale-wise evaluation of object detectors is important for real-worldapplications. However, existing metrics are either coarse or not sufficientlyreliable. In this paper, we propose novel scale-wise metrics that strike abalance between fineness and reliability, using a filter bank consisting oftriangular and trapezoidal band-pass filters. We conduct experiments with twomethods on two datasets and show that the proposed metrics can highlight thedifferences between the methods and between the datasets. Code is available athttps://github.com/shinya7y/UniverseNet .</description><author>Yosuke Shinya</author><pubDate>Fri, 21 Jul 2023 18:58:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11748v1</guid></item><item><title>Tight Bounds for $γ$-Regret via the Decision-Estimation Coefficient</title><link>http://arxiv.org/abs/2303.03327v2</link><description>In this work, we give a statistical characterization of the $\gamma$-regretfor arbitrary structured bandit problems, the regret which arises whencomparing against a benchmark that is $\gamma$ times the optimal solution. The$\gamma$-regret emerges in structured bandit problems over a function class$\mathcal{F}$ where finding an exact optimum of $f \in \mathcal{F}$ isintractable. Our characterization is given in terms of the $\gamma$-DEC, astatistical complexity parameter for the class $\mathcal{F}$, which is amodification of the constrained Decision-Estimation Coefficient (DEC) of Fosteret al., 2023 (and closely related to the original offset DEC of Foster et al.,2021). Our lower bound shows that the $\gamma$-DEC is a fundamental limit forany model class $\mathcal{F}$: for any algorithm, there exists some $f \in\mathcal{F}$ for which the $\gamma$-regret of that algorithm scales (nearly)with the $\gamma$-DEC of $\mathcal{F}$. We provide an upper bound showing thatthere exists an algorithm attaining a nearly matching $\gamma$-regret. Due tosignificant challenges in applying the prior results on the DEC to the$\gamma$-regret case, both our lower and upper bounds require novel techniquesand a new algorithm.</description><author>Margalit Glasgow, Alexander Rakhlin</author><pubDate>Fri, 21 Jul 2023 18:54:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03327v2</guid></item><item><title>Advancing Ad Auction Realism: Practical Insights &amp; Modeling Implications</title><link>http://arxiv.org/abs/2307.11732v1</link><description>This paper proposes a learning model of online ad auctions that allows forthe following four key realistic characteristics of contemporary onlineauctions: (1) ad slots can have different values and click-through ratesdepending on users' search queries, (2) the number and identity of competingadvertisers are unobserved and change with each auction, (3) advertisers onlyreceive partial, aggregated feedback, and (4) payment rules are only partiallyspecified. We model advertisers as agents governed by an adversarial banditalgorithm, independent of auction mechanism intricacies. Our objective is tosimulate the behavior of advertisers for counterfactual analysis, prediction,and inference purposes. Our findings reveal that, in such richer environments,"soft floors" can enhance key performance metrics even when bidders are drawnfrom the same population. We further demonstrate how to infer advertiser valuedistributions from observed bids, thereby affirming the practical efficacy ofour approach even in a more realistic auction setting.</description><author>Ming Chen, Sareh Nabi, Marciano Siniscalchi</author><pubDate>Fri, 21 Jul 2023 18:45:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11732v1</guid></item><item><title>Mitigating Communications Threats in Decentralized Federated Learning through Moving Target Defense</title><link>http://arxiv.org/abs/2307.11730v1</link><description>The rise of Decentralized Federated Learning (DFL) has enabled the trainingof machine learning models across federated participants, fosteringdecentralized model aggregation and reducing dependence on a server. However,this approach introduces unique communication security challenges that have yetto be thoroughly addressed in the literature. These challenges primarilyoriginate from the decentralized nature of the aggregation process, the variedroles and responsibilities of the participants, and the absence of a centralauthority to oversee and mitigate threats. Addressing these challenges, thispaper first delineates a comprehensive threat model, highlighting the potentialrisks of DFL communications. In response to these identified risks, this workintroduces a security module designed for DFL platforms to countercommunication-based attacks. The module combines security techniques such assymmetric and asymmetric encryption with Moving Target Defense (MTD)techniques, including random neighbor selection and IP/port switching. Thesecurity module is implemented in a DFL platform called Fedstellar, allowingthe deployment and monitoring of the federation. A DFL scenario has beendeployed, involving eight physical devices implementing three securityconfigurations: (i) a baseline with no security, (ii) an encryptedconfiguration, and (iii) a configuration integrating both encryption and MTDtechniques. The effectiveness of the security module is validated throughexperiments with the MNIST dataset and eclipse attacks. The results indicatedan average F1 score of 95%, with moderate increases in CPU usage (up to 63.2%+-3.5%) and network traffic (230 MB +-15 MB) under the most secureconfiguration, mitigating the risks posed by eavesdropping or eclipse attacks.</description><author>Enrique Tomás Martínez Beltrán, Pedro Miguel Sánchez Sánchez, Sergio López Bernal, Gérôme Bovet, Manuel Gil Pérez, Gregorio Martínez Pérez, Alberto Huertas Celdrán</author><pubDate>Fri, 21 Jul 2023 18:43:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11730v1</guid></item><item><title>OUTFOX: LLM-generated Essay Detection through In-context Learning with Adversarially Generated Examples</title><link>http://arxiv.org/abs/2307.11729v1</link><description>Large Language Models (LLMs) have achieved human-level fluency in textgeneration, making it difficult to distinguish between human-written andLLM-generated texts. This poses a growing risk of misuse of LLMs and demandsthe development of detectors to identify LLM-generated texts. However, existingdetectors degrade detection accuracy by simply paraphrasing LLM-generatedtexts. Furthermore, the effectiveness of these detectors in real-lifesituations, such as when students use LLMs for writing homework assignments(e.g., essays) and quickly learn how to evade these detectors, has not beenexplored. In this paper, we propose OUTFOX, a novel framework that improves therobustness of LLM-generated-text detectors by allowing both the detector andthe attacker to consider each other's output and apply this to the domain ofstudent essays. In our framework, the attacker uses the detector's predictionlabels as examples for in-context learning and adversarially generates essaysthat are harder to detect. While the detector uses the adversarially generatedessays as examples for in-context learning to learn to detect essays from astrong attacker. Our experiments show that our proposed detector learnedin-context from the attacker improves the detection performance on the attackeddataset by up to +41.3 point F1-score. While our proposed attacker candrastically degrade the performance of the detector by up to -57.0 pointF1-score compared to the paraphrasing method.</description><author>Ryuto Koike, Masahiro Kaneko, Naoaki Okazaki</author><pubDate>Fri, 21 Jul 2023 18:40:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11729v1</guid></item><item><title>On Provable Copyright Protection for Generative Models</title><link>http://arxiv.org/abs/2302.10870v2</link><description>There is a growing concern that learned conditional generative models mayoutput samples that are substantially similar to some copyrighted data $C$ thatwas in their training set. We give a formal definition of $\textit{nearaccess-freeness (NAF)}$ and prove bounds on the probability that a modelsatisfying this definition outputs a sample similar to $C$, even if $C$ isincluded in its training set. Roughly speaking, a generative model $p$ is$\textit{$k$-NAF}$ if for every potentially copyrighted data $C$, the output of$p$ diverges by at most $k$-bits from the output of a model $q$ that$\textit{did not access $C$ at all}$. We also give generative model learningalgorithms, which efficiently modify the original generative model learningalgorithm in a black box manner, that output generative models with strongbounds on the probability of sampling protected content. Furthermore, weprovide promising experiments for both language (transformers) and image(diffusion) generative models, showing minimal degradation in output qualitywhile ensuring strong protections against sampling protected content.</description><author>Nikhil Vyas, Sham Kakade, Boaz Barak</author><pubDate>Fri, 21 Jul 2023 18:37:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.10870v2</guid></item><item><title>A Competitive Learning Approach for Specialized Models: A Solution for Complex Physical Systems with Distinct Functional Regimes</title><link>http://arxiv.org/abs/2307.10496v2</link><description>Complex systems in science and engineering sometimes exhibit behavior thatchanges across different regimes. Traditional global models struggle to capturethe full range of this complex behavior, limiting their ability to accuratelyrepresent the system. In response to this challenge, we propose a novelcompetitive learning approach for obtaining data-driven models of physicalsystems. The primary idea behind the proposed approach is to employ dynamicloss functions for a set of models that are trained concurrently on the data.Each model competes for each observation during training, allowing for theidentification of distinct functional regimes within the dataset. Todemonstrate the effectiveness of the learning approach, we coupled it withvarious regression methods that employ gradient-based optimizers for training.The proposed approach was tested on various problems involving model discoveryand function approximation, demonstrating its ability to successfully identifyfunctional regimes, discover true governing equations, and reduce test errors.</description><author>Okezzi F. Ukorigho, Opeoluwa Owoyele</author><pubDate>Fri, 21 Jul 2023 18:34:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10496v2</guid></item><item><title>Terabyte-scale supervised 3D training and benchmarking dataset of the mouse kidney</title><link>http://arxiv.org/abs/2108.02226v2</link><description>The performance of machine learning algorithms, when used for segmenting 3Dbiomedical images, does not reach the level expected based on results achievedwith 2D photos. This may be explained by the comparative lack of high-volume,high-quality training datasets, which require state-of-the-art imagingfacilities, domain experts for annotation and large computational and personalresources. The HR-Kidney dataset presented in this work bridges this gap byproviding 1.7 TB of artefact-corrected synchrotron radiation-based X-rayphase-contrast microtomography images of whole mouse kidneys and validatedsegmentations of 33 729 glomeruli, which corresponds to a one to two orders ofmagnitude increase over currently available biomedical datasets. The image setsalso contain the underlying raw data, threshold- and morphology-basedsemi-automatic segmentations of renal vasculature and uriniferous tubules, aswell as true 3D manual annotations. We therewith provide a broad basis for thescientific community to build upon and expand in the fields of imageprocessing, data augmentation and machine learning, in particular unsupervisedand semi-supervised learning investigations, as well as transfer learning andgenerative adversarial networks.</description><author>Willy Kuo, Diego Rossinelli, Georg Schulz, Roland H. Wenger, Simone Hieber, Bert Müller, Vartan Kurtcuoglu</author><pubDate>Fri, 21 Jul 2023 18:27:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2108.02226v2</guid></item><item><title>Benchmark datasets for biomedical knowledge graphs with negative statements</title><link>http://arxiv.org/abs/2307.11719v1</link><description>Knowledge graphs represent facts about real-world entities. Most of thesefacts are defined as positive statements. The negative statements are scarcebut highly relevant under the open-world assumption. Furthermore, they havebeen demonstrated to improve the performance of several applications, namely inthe biomedical domain. However, no benchmark dataset supports the evaluation ofthe methods that consider these negative statements. We present a collection of datasets for three relation prediction tasks -protein-protein interaction prediction, gene-disease association prediction anddisease prediction - that aim at circumventing the difficulties in buildingbenchmarks for knowledge graphs with negative statements. These datasetsinclude data from two successful biomedical ontologies, Gene Ontology and HumanPhenotype Ontology, enriched with negative statements. We also generate knowledge graph embeddings for each dataset with two popularpath-based methods and evaluate the performance in each task. The results showthat the negative statements can improve the performance of knowledge graphembeddings.</description><author>Rita T. Sousa, Sara Silva, Catia Pesquita</author><pubDate>Fri, 21 Jul 2023 18:25:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11719v1</guid></item><item><title>A Neural Network Warm-Start Approach for the Inverse Acoustic Obstacle Scattering Problem</title><link>http://arxiv.org/abs/2212.08736v2</link><description>We consider the inverse acoustic obstacle problem for sound-soft star-shapedobstacles in two dimensions wherein the boundary of the obstacle is determinedfrom measurements of the scattered field at a collection of receivers outsidethe object. One of the standard approaches for solving this problem is toreformulate it as an optimization problem: finding the boundary of the domainthat minimizes the $L^2$ distance between computed values of the scatteredfield and the given measurement data. The optimization problem iscomputationally challenging since the local set of convexity shrinks withincreasing frequency and results in an increasing number of local minima in thevicinity of the true solution. In many practical experimental settings, lowfrequency measurements are unavailable due to limitations of the experimentalsetup or the sensors used for measurement. Thus, obtaining a good initial guessfor the optimization problem plays a vital role in this environment. We present a neural network warm-start approach for solving the inversescattering problem, where an initial guess for the optimization problem isobtained using a trained neural network. We demonstrate the effectiveness ofour method with several numerical examples. For high frequency problems, thisapproach outperforms traditional iterative methods such as Gauss-Newtoninitialized without any prior (i.e., initialized using a unit circle), orinitialized using the solution of a direct method such as the linear samplingmethod. The algorithm remains robust to noise in the scattered fieldmeasurements and also converges to the true solution for limited aperture data.However, the number of training samples required to train the neural networkscales exponentially in frequency and the complexity of the obstaclesconsidered. We conclude with a discussion of this phenomenon and potentialdirections for future research.</description><author>Mo Zhou, Jiequn Han, Manas Rachh, Carlos Borges</author><pubDate>Fri, 21 Jul 2023 18:21:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.08736v2</guid></item><item><title>Embedding Contextual Information through Reward Shaping in Multi-Agent Learning: A Case Study from Google Football</title><link>http://arxiv.org/abs/2303.15471v3</link><description>Artificial Intelligence has been used to help human complete difficult tasksin complicated environments by providing optimized strategies fordecision-making or replacing the manual labour. In environments includingmultiple agents, such as football, the most common methods to train agents areImitation Learning and Multi-Agent Reinforcement Learning (MARL). However, theagents trained by Imitation Learning cannot outperform the expert demonstrator,which makes humans hardly get new insights from the learnt policy. Besides,MARL is prone to the credit assignment problem. In environments with sparsereward signal, this method can be inefficient. The objective of our research isto create a novel reward shaping method by embedding contextual information inreward function to solve the aforementioned challenges. We demonstrate this inthe Google Research Football (GRF) environment. We quantify the contextualinformation extracted from game state observation and use this quantificationtogether with original sparse reward to create the shaped reward. Theexperiment results in the GRF environment prove that our reward shaping methodis a useful addition to state-of-the-art MARL algorithms for training agents inenvironments with sparse reward signal.</description><author>Chaoyi Gu, Varuna De Silva, Corentin Artaud, Rafael Pina</author><pubDate>Fri, 21 Jul 2023 18:20:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.15471v3</guid></item><item><title>Convergence of SGD for Training Neural Networks with Sliced Wasserstein Losses</title><link>http://arxiv.org/abs/2307.11714v1</link><description>Optimal Transport has sparked vivid interest in recent years, in particularthanks to the Wasserstein distance, which provides a geometrically sensible andintuitive way of comparing probability measures. For computational reasons, theSliced Wasserstein (SW) distance was introduced as an alternative to theWasserstein distance, and has seen uses for training generative Neural Networks(NNs). While convergence of Stochastic Gradient Descent (SGD) has been observedpractically in such a setting, there is to our knowledge no theoreticalguarantee for this observation. Leveraging recent works on convergence of SGDon non-smooth and non-convex functions by Bianchi et al. (2022), we aim tobridge that knowledge gap, and provide a realistic context under whichfixed-step SGD trajectories for the SW loss on NN parameters converge. Moreprecisely, we show that the trajectories approach the set of (sub)-gradientflow equations as the step decreases. Under stricter assumptions, we show amuch stronger convergence result for noised and projected SGD schemes, namelythat the long-run limits of the trajectories approach a set of generalisedcritical points of the loss function.</description><author>Eloi Tanguy</author><pubDate>Fri, 21 Jul 2023 18:19:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11714v1</guid></item><item><title>More From Less: Self-Supervised Knowledge Distillation for Routine Histopathology Data</title><link>http://arxiv.org/abs/2303.10656v2</link><description>Medical imaging technologies are generating increasingly large amounts ofhigh-quality, information-dense data. Despite the progress, practical use ofadvanced imaging technologies for research and diagnosis remains limited bycost and availability, so information-sparse data such as H&amp;E stains are reliedon in practice. The study of diseased tissue requires methods which canleverage these information-dense data to extract more value from routine,information-sparse data. Using self-supervised deep learning, we demonstratethat it is possible to distil knowledge during training from information-densedata into models which only require information-sparse data for inference. Thisimproves downstream classification accuracy on information-sparse data, makingit comparable with the fully-supervised baseline. We find substantial effectson the learned representations, and this training process identifies subtlefeatures which otherwise go undetected. This approach enables the design ofmodels which require only routine images, but contain insights fromstate-of-the-art data, allowing better use of the available resources.</description><author>Lucas Farndale, Robert Insall, Ke Yuan</author><pubDate>Fri, 21 Jul 2023 18:15:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.10656v2</guid></item><item><title>Statement-based Memory for Neural Source Code Summarization</title><link>http://arxiv.org/abs/2307.11709v1</link><description>Source code summarization is the task of writing natural languagedescriptions of source code behavior. Code summarization underpins softwaredocumentation for programmers. Short descriptions of code help programmersunderstand the program quickly without having to read the code itself. Lately,neural source code summarization has emerged as the frontier of research intoautomated code summarization techniques. By far the most popular targets forsummarization are program subroutines. The idea, in a nutshell, is to train anencoder-decoder neural architecture using large sets of examples of subroutinesextracted from code repositories. The encoder represents the code and thedecoder represents the summary. However, most current approaches attempt totreat the subroutine as a single unit. For example, by taking the entiresubroutine as input to a Transformer or RNN-based encoder. But code behaviortends to depend on the flow from statement to statement. Normally dynamicanalysis may shed light on this flow, but dynamic analysis on hundreds ofthousands of examples in large datasets is not practical. In this paper, wepresent a statement-based memory encoder that learns the important elements offlow during training, leading to a statement-based subroutine representationwithout the need for dynamic analysis. We implement our encoder for codesummarization and demonstrate a significant improvement over thestate-of-the-art.</description><author>Aakash Bansal, Siyuan Jiang, Sakib Haque, Collin McMillan</author><pubDate>Fri, 21 Jul 2023 18:04:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11709v1</guid></item><item><title>3D Skeletonization of Complex Grapevines for Robotic Pruning</title><link>http://arxiv.org/abs/2307.11706v1</link><description>Robotic pruning of dormant grapevines is an area of active research in orderto promote vine balance and grape quality, but so far robotic efforts havelargely focused on planar, simplified vines not representative of commercialvineyards. This paper aims to advance the robotic perception capabilitiesnecessary for pruning in denser and more complex vine structures by extendingplant skeletonization techniques. The proposed pipeline generates skeletalgrapevine models that have lower reprojection error and higher connectivitythan baseline algorithms. We also show how 3D and skeletal information enablesprediction accuracy of pruning weight for dense vines surpassing prior work,where pruning weight is an important vine metric influencing pruning siteselection.</description><author>Eric Schneider, Sushanth Jayanth, Abhisesh Silwal, George Kantor</author><pubDate>Fri, 21 Jul 2023 18:02:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11706v1</guid></item><item><title>JoinGym: An Efficient Query Optimization Environment for Reinforcement Learning</title><link>http://arxiv.org/abs/2307.11704v1</link><description>In this paper, we present \textsc{JoinGym}, an efficient and lightweightquery optimization environment for reinforcement learning (RL). Join orderselection (JOS) is a classic NP-hard combinatorial optimization problem fromdatabase query optimization and can serve as a practical testbed for thegeneralization capabilities of RL algorithms. We describe how to formulate eachof the left-deep and bushy variants of the JOS problem as a Markov DecisionProcess (MDP), and we provide an implementation adhering to the standardGymnasium API. We highlight that our implementation \textsc{JoinGym} iscompletely based on offline traces of all possible joins, which enables RLpractitioners to easily and quickly test their methods on a realistic datamanagement problem without needing to setup any systems. Moreover, we alsoprovide all possible join traces on $3300$ novel SQL queries generated from theIMDB dataset. Upon benchmarking popular RL algorithms, we find that at leastone method can obtain near-optimal performance on train-set queries but theirperformance degrades by several orders of magnitude on test-set queries. Thisgap motivates further research for RL algorithms that generalize well inmulti-task combinatorial optimization problems.</description><author>Kaiwen Wang, Junxiong Wang, Yueying Li, Nathan Kallus, Immanuel Trummer, Wen Sun</author><pubDate>Fri, 21 Jul 2023 18:00:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11704v1</guid></item><item><title>SACReg: Scene-Agnostic Coordinate Regression for Visual Localization</title><link>http://arxiv.org/abs/2307.11702v1</link><description>Scene coordinates regression (SCR), i.e., predicting 3D coordinates for everypixel of a given image, has recently shown promising potential. However,existing methods remain mostly scene-specific or limited to small scenes andthus hardly scale to realistic datasets. In this paper, we propose a newparadigm where a single generic SCR model is trained once to be then deployedto new test scenes, regardless of their scale and without further finetuning.For a given query image, it collects inputs from off-the-shelf image retrievaltechniques and Structure-from-Motion databases: a list of relevant databaseimages with sparse pointwise 2D-3D annotations. The model is based on thetransformer architecture and can take a variable number of images and sparse2D-3D annotations as input. It is trained on a few diverse datasets andsignificantly outperforms other scene regression approaches on severalbenchmarks, including scene-specific models, for visual localization. Inparticular, we set a new state of the art on the Cambridge localizationbenchmark, even outperforming feature-matching-based approaches.</description><author>Jerome Revaud, Yohann Cabon, Romain Brégier, JongMin Lee, Philippe Weinzaepfel</author><pubDate>Fri, 21 Jul 2023 17:56:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11702v1</guid></item><item><title>Enhancing Few-shot Image Classification with Cosine Transformer</title><link>http://arxiv.org/abs/2211.06828v3</link><description>This paper addresses the few-shot image classification problem, where theclassification task is performed on unlabeled query samples given a smallamount of labeled support samples only. One major challenge of the few-shotlearning problem is the large variety of object visual appearances thatprevents the support samples to represent that object comprehensively. Thismight result in a significant difference between support and query samples,therefore undermining the performance of few-shot algorithms. In this paper, wetackle the problem by proposing Few-shot Cosine Transformer (FS-CT), where therelational map between supports and queries is effectively obtained for thefew-shot tasks. The FS-CT consists of two parts, a learnable prototypicalembedding network to obtain categorical representations from support sampleswith hard cases, and a transformer encoder to effectively achieve therelational map from two different support and query samples. We introduceCosine Attention, a more robust and stable attention module that enhances thetransformer module significantly and therefore improves FS-CT performance from5% to over 20% in accuracy compared to the default scaled dot-productmechanism. Our method performs competitive results in mini-ImageNet, CUB-200,and CIFAR-FS on 1-shot learning and 5-shot learning tasks across backbones andfew-shot configurations. We also developed a custom few-shot dataset for Yogapose recognition to demonstrate the potential of our algorithm for practicalapplication. Our FS-CT with cosine attention is a lightweight, simple few-shotalgorithm that can be applied for a wide range of applications, such ashealthcare, medical, and security surveillance. The official implementationcode of our Few-shot Cosine Transformer is available athttps://github.com/vinuni-vishc/Few-Shot-Cosine-Transformer</description><author>Quang-Huy Nguyen, Cuong Q. Nguyen, Dung D. Le, Hieu H. Pham</author><pubDate>Fri, 21 Jul 2023 17:54:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.06828v3</guid></item><item><title>(Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs</title><link>http://arxiv.org/abs/2307.10490v2</link><description>We demonstrate how images and sounds can be used for indirect prompt andinstruction injection in multi-modal LLMs. An attacker generates an adversarialperturbation corresponding to the prompt and blends it into an image or audiorecording. When the user asks the (unmodified, benign) model about theperturbed image or audio, the perturbation steers the model to output theattacker-chosen text and/or make the subsequent dialog follow the attacker'sinstruction. We illustrate this attack with several proof-of-concept examplestargeting LLaVa and PandaGPT.</description><author>Eugene Bagdasaryan, Tsung-Yin Hsieh, Ben Nassi, Vitaly Shmatikov</author><pubDate>Fri, 21 Jul 2023 17:51:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10490v2</guid></item><item><title>Using simulation to calibrate real data acquisition in veterinary medicine</title><link>http://arxiv.org/abs/2307.11695v1</link><description>This paper explores the innovative use of simulation environments to enhancedata acquisition and diagnostics in veterinary medicine, focusing specificallyon gait analysis in dogs. The study harnesses the power of Blender and theBlenderproc library to generate synthetic datasets that reflect diverseanatomical, environmental, and behavioral conditions. The generated data,represented in graph form and standardized for optimal analysis, is utilized totrain machine learning algorithms for identifying normal and abnormal gaits.Two distinct datasets with varying degrees of camera angle granularity arecreated to further investigate the influence of camera perspective on modelaccuracy. Preliminary results suggest that this simulation-based approach holdspromise for advancing veterinary diagnostics by enabling more precise dataacquisition and more effective machine learning models. By integratingsynthetic and real-world patient data, the study lays a robust foundation forimproving overall effectiveness and efficiency in veterinary medicine.</description><author>Krystian Strzałka, Szymon Mazurek, Maciej Wielgosz, Paweł Russek, Jakub Caputa, Daria Łukasik, Jan Krupiński, Jakub Grzeszczyk, Michał Karwatowski, Rafał Frączek, Ernest Jamro, Marcin Pietroń, Sebastian Koryciak, Agnieszka Dąbrowska-Boruch, Kazimierz Wiatr</author><pubDate>Fri, 21 Jul 2023 17:50:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11695v1</guid></item><item><title>Fast Adaptive Test-Time Defense with Robust Features</title><link>http://arxiv.org/abs/2307.11672v1</link><description>Adaptive test-time defenses are used to improve the robustness of deep neuralnetworks to adversarial examples. However, existing methods significantlyincrease the inference time due to additional optimization on the modelparameters or the input at test time. In this work, we propose a novel adaptivetest-time defense strategy that is easy to integrate with any existing (robust)training procedure without additional test-time computation. Based on thenotion of robustness of features that we present, the key idea is to projectthe trained models to the most robust feature space, thereby reducing thevulnerability to adversarial attacks in non-robust directions. We theoreticallyshow that the top eigenspace of the feature matrix are more robust for ageneralized additive model and support our argument for a large width neuralnetwork with the Neural Tangent Kernel (NTK) equivalence. We conduct extensiveexperiments on CIFAR-10 and CIFAR-100 datasets for several robustnessbenchmarks, including the state-of-the-art methods in RobustBench, and observethat the proposed method outperforms existing adaptive test-time defenses atmuch lower computation costs.</description><author>Anurag Singh, Mahalakshmi Sabanayagam, Krikamol Muandet, Debarghya Ghoshdastidar</author><pubDate>Fri, 21 Jul 2023 17:18:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11672v1</guid></item><item><title>Universal consistency of the $k$-NN rule in metric spaces and Nagata dimension. II</title><link>http://arxiv.org/abs/2305.17282v2</link><description>We continue to investigate the $k$ nearest neighbour learning rule inseparable metric spaces. Thanks to the results of C\'erou and Guyader (2006)and Preiss (1983), this rule is known to be universally consistent in everymetric space $X$ that is sigma-finite dimensional in the sense of Nagata. Herewe show that the rule is strongly universally consistent in such spaces in theabsence of ties. Under the tie-breaking strategy applied by Devroye,Gy\"{o}rfi, Krzy\.{z}ak, and Lugosi (1994) in the Euclidean setting, we manageto show the strong universal consistency in non-Archimedian metric spaces (thatis, those of Nagata dimension zero). Combining the theorem of C\'erou andGuyader with results of Assouad and Quentin de Gromard (2006), one deduces thatthe $k$-NN rule is universally consistent in metric spaces having finitedimension in the sense of de Groot. In particular, the $k$-NN rule isuniversally consistent in the Heisenberg group which is not sigma-finitedimensional in the sense of Nagata as follows from an example independentlyconstructed by Kor\'anyi and Reimann (1995) and Sawyer and Wheeden (1992).</description><author>Sushma Kumari, Vladimir G. Pestov</author><pubDate>Fri, 21 Jul 2023 17:15:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17282v2</guid></item><item><title>An Efficient Interior-Point Method for Online Convex Optimization</title><link>http://arxiv.org/abs/2307.11668v1</link><description>A new algorithm for regret minimization in online convex optimization isdescribed. The regret of the algorithm after $T$ time periods is $O(\sqrt{T\log T})$ - which is the minimum possible up to a logarithmic term. Inaddition, the new algorithm is adaptive, in the sense that the regret boundshold not only for the time periods $1,\ldots,T$ but also for every sub-interval$s,s+1,\ldots,t$. The running time of the algorithm matches that of newlyintroduced interior point algorithms for regret minimization: in$n$-dimensional space, during each iteration the new algorithm essentiallysolves a system of linear equations of order $n$, rather than solving someconstrained convex optimization problem in $n$ dimensions and possibly manyconstraints.</description><author>Elad Hazan, Nimrod Megiddo</author><pubDate>Fri, 21 Jul 2023 17:12:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11668v1</guid></item><item><title>Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations</title><link>http://arxiv.org/abs/2307.06576v3</link><description>Precisely recommending candidate news articles to users has always been acore challenge for personalized news recommendation systems. Most recent worksprimarily focus on using advanced natural language processing techniques toextract semantic information from rich textual data, employing content-basedmethods derived from local historical news. However, this approach lacks aglobal perspective, failing to account for users' hidden motivations andbehaviors beyond semantic information. To address this challenge, we propose anovel model called GLORY (Global-LOcal news Recommendation sYstem), whichcombines global representations learned from other users with localrepresentations to enhance personalized recommendation systems. We accomplishthis by constructing a Global-aware Historical News Encoder, which includes aglobal news graph and employs gated graph neural networks to enrich newsrepresentations, thereby fusing historical news representations by a historicalnews aggregator. Similarly, we extend this approach to a Global Candidate NewsEncoder, utilizing a global entity graph and a candidate news aggregator toenhance candidate news representation. Evaluation results on two public newsdatasets demonstrate that our method outperforms existing approaches.Furthermore, our model offers more diverse recommendations.</description><author>Boming Yang, Dairui Liu, Toyotaro Suzumura, Ruihai Dong, Irene Li</author><pubDate>Fri, 21 Jul 2023 17:06:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.06576v3</guid></item><item><title>CALDA: Improving Multi-Source Time Series Domain Adaptation with Contrastive Adversarial Learning</title><link>http://arxiv.org/abs/2109.14778v2</link><description>Unsupervised domain adaptation (UDA) provides a strategy for improvingmachine learning performance in data-rich (target) domains where ground truthlabels are inaccessible but can be found in related (source) domains. In caseswhere meta-domain information such as label distributions is available, weaksupervision can further boost performance. We propose a novel framework, CALDA,to tackle these two problems. CALDA synergistically combines the principles ofcontrastive learning and adversarial learning to robustly support multi-sourceUDA (MS-UDA) for time series data. Similar to prior methods, CALDA utilizesadversarial learning to align source and target feature representations. Unlikeprior approaches, CALDA additionally leverages cross-source label informationacross domains. CALDA pulls examples with the same label close to each other,while pushing apart examples with different labels, reshaping the space throughcontrastive learning. Unlike prior contrastive adaptation methods, CALDArequires neither data augmentation nor pseudo labeling, which may be morechallenging for time series. We empirically validate our proposed approach.Based on results from human activity recognition, electromyography, andsynthetic datasets, we find utilizing cross-source information improvesperformance over prior time series and contrastive methods. Weak supervisionfurther improves performance, even in the presence of noise, allowing CALDA tooffer generalizable strategies for MS-UDA. Code is available at:https://github.com/floft/calda</description><author>Garrett Wilson, Janardhan Rao Doppa, Diane J. Cook</author><pubDate>Fri, 21 Jul 2023 17:05:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.14778v2</guid></item><item><title>Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts</title><link>http://arxiv.org/abs/2307.11661v1</link><description>Contrastive pretrained large Vision-Language Models (VLMs) like CLIP haverevolutionized visual representation learning by providing good performance ondownstream datasets. VLMs are 0-shot adapted to a downstream dataset bydesigning prompts that are relevant to the dataset. Such prompt engineeringmakes use of domain expertise and a validation dataset. Meanwhile, recentdevelopments in generative pretrained models like GPT-4 mean they can be usedas advanced internet search tools. They can also be manipulated to providevisual information in any structure. In this work, we show that GPT-4 can beused to generate text that is visually descriptive and how this can be used toadapt CLIP to downstream tasks. We show considerable improvements in 0-shottransfer accuracy on specialized fine-grained datasets like EuroSAT (~7%), DTD(~7%), SUN397 (~4.6%), and CUB (~3.3%) when compared to CLIP's default prompt.We also design a simple few-shot adapter that learns to choose the bestpossible sentences to construct generalizable classifiers that outperform therecently proposed CoCoOP by ~2% on average and by over 4% on 4 specializedfine-grained datasets. We will release the code, prompts, and auxiliary textdataset upon acceptance.</description><author>Mayug Maniparambil, Chris Vorster, Derek Molloy, Noel Murphy, Kevin McGuinness, Noel E. O'Connor</author><pubDate>Fri, 21 Jul 2023 16:49:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11661v1</guid></item><item><title>Bandits with Deterministically Evolving States</title><link>http://arxiv.org/abs/2307.11655v1</link><description>We propose a model for learning with bandit feedback while accounting fordeterministically evolving and unobservable states that we call Bandits withDeterministically Evolving States. The workhorse applications of our model arelearning for recommendation systems and learning for online ads. In both cases,the reward that the algorithm obtains at each round is a function of theshort-term reward of the action chosen and how ``healthy'' the system is (i.e.,as measured by its state). For example, in recommendation systems, the rewardthat the platform obtains from a user's engagement with a particular type ofcontent depends not only on the inherent features of the specific content, butalso on how the user's preferences have evolved as a result of interacting withother types of content on the platform. Our general model accounts for thedifferent rate $\lambda \in [0,1]$ at which the state evolves (e.g., how fast auser's preferences shift as a result of previous content consumption) andencompasses standard multi-armed bandits as a special case. The goal of thealgorithm is to minimize a notion of regret against the best-fixed sequence ofarms pulled. We analyze online learning algorithms for any possibleparametrization of the evolution rate $\lambda$. Specifically, the regret ratesobtained are: for $\lambda \in [0, 1/T^2]$: $\widetilde O(\sqrt{KT})$; for$\lambda = T^{-a/b}$ with $b &lt; a &lt; 2b$: $\widetilde O (T^{b/a})$; for $\lambda\in (1/T, 1 - 1/\sqrt{T}): \widetilde O (K^{1/3}T^{2/3})$; and for $\lambda \in[1 - 1/\sqrt{T}, 1]: \widetilde O (K\sqrt{T})$.</description><author>Khashayar Khosravi, Renato Paes Leme, Chara Podimata, Apostolis Tsorvantzis</author><pubDate>Fri, 21 Jul 2023 16:43:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11655v1</guid></item><item><title>FEDD -- Fair, Efficient, and Diverse Diffusion-based Lesion Segmentation and Malignancy Classification</title><link>http://arxiv.org/abs/2307.11654v1</link><description>Skin diseases affect millions of people worldwide, across all ethnicities.Increasing diagnosis accessibility requires fair and accurate segmentation andclassification of dermatology images. However, the scarcity of annotatedmedical images, especially for rare diseases and underrepresented skin tones,poses a challenge to the development of fair and accurate models. In thisstudy, we introduce a Fair, Efficient, and Diverse Diffusion-based frameworkfor skin lesion segmentation and malignancy classification. FEDD leveragessemantically meaningful feature embeddings learned through a denoisingdiffusion probabilistic backbone and processes them via linear probes toachieve state-of-the-art performance on Diverse Dermatology Images (DDI). Weachieve an improvement in intersection over union of 0.18, 0.13, 0.06, and 0.07while using only 5%, 10%, 15%, and 20% labeled samples, respectively.Additionally, FEDD trained on 10% of DDI demonstrates malignancy classificationaccuracy of 81%, 14% higher compared to the state-of-the-art. We showcase highefficiency in data-constrained scenarios while providing fair performance fordiverse skin tones and rare malignancy conditions. Our newly annotated DDIsegmentation masks and training code can be found onhttps://github.com/hectorcarrion/fedd.</description><author>Héctor Carrión, Narges Norouzi</author><pubDate>Fri, 21 Jul 2023 16:42:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11654v1</guid></item><item><title>Alleviating the Long-Tail Problem in Conversational Recommender Systems</title><link>http://arxiv.org/abs/2307.11650v1</link><description>Conversational recommender systems (CRS) aim to provide the recommendationservice via natural language conversations. To develop an effective CRS,high-quality CRS datasets are very crucial. However, existing CRS datasetssuffer from the long-tail issue, \ie a large proportion of items are rarely (oreven never) mentioned in the conversations, which are called long-tail items.As a result, the CRSs trained on these datasets tend to recommend frequentitems, and the diversity of the recommended items would be largely reduced,making users easier to get bored. To address this issue, this paper presents \textbf{LOT-CRS}, a novelframework that focuses on simulating and utilizing a balanced CRS dataset (\iecovering all the items evenly) for improving \textbf{LO}ng-\textbf{T}ailrecommendation performance of CRSs. In our approach, we design two pre-trainingtasks to enhance the understanding of simulated conversation for long-tailitems, and adopt retrieval-augmented fine-tuning with label smoothness strategyto further improve the recommendation of long-tail items. Extensive experimentson two public CRS datasets have demonstrated the effectiveness andextensibility of our approach, especially on long-tail recommendation.</description><author>Zhipeng Zhao, Kun Zhou, Xiaolei Wang, Wayne Xin Zhao, Fan Pan, Zhao Cao, Ji-Rong Wen</author><pubDate>Fri, 21 Jul 2023 16:28:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11650v1</guid></item><item><title>Torchhd: An Open Source Python Library to Support Research on Hyperdimensional Computing and Vector Symbolic Architectures</title><link>http://arxiv.org/abs/2205.09208v3</link><description>Hyperdimensional computing (HD), also known as vector symbolic architectures(VSA), is a framework for computing with distributed representations byexploiting properties of random high-dimensional vector spaces. The commitmentof the scientific community to aggregate and disseminate research in thisparticularly multidisciplinary area has been fundamental for its advancement.Joining these efforts, we present Torchhd, a high-performance open sourcePython library for HD/VSA. Torchhd seeks to make HD/VSA more accessible andserves as an efficient foundation for further research and applicationdevelopment. The easy-to-use library builds on top of PyTorch and featuresstate-of-the-art HD/VSA functionality, clear documentation, and implementationexamples from well-known publications. Comparing publicly available code withtheir corresponding Torchhd implementation shows that experiments can run up to100x faster. Torchhd is available at:https://github.com/hyperdimensional-computing/torchhd.</description><author>Mike Heddes, Igor Nunes, Pere Vergés, Denis Kleyko, Danny Abraham, Tony Givargis, Alexandru Nicolau, Alexander Veidenbaum</author><pubDate>Fri, 21 Jul 2023 16:27:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.09208v3</guid></item><item><title>A simple declarative model of the Federal Disaster Assistance Policy -- modelling and measuring transparency</title><link>http://arxiv.org/abs/2207.07392v4</link><description>In this paper we will provide a quantitative analysis of a simple model ofthe Federal Disaster Assistance policy from the viewpoint of three differentstakeholders. This quantitative methodology is new and has applications toother areas such as business and healthcare processes. The stakeholders areinterested in process transparency but each has a different opinion onprecisely what constitutes transparency. We will also consider threemodifications to the Federal Disaster Assistance policy and analyse, from astakeholder viewpoint, how stakeholder satisfaction changes from process toprocess. This analysis is used to rank the favourability of four policies withrespect to all collective stakeholder preferences.</description><author>Mark Dukes</author><pubDate>Fri, 21 Jul 2023 16:26:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.07392v4</guid></item><item><title>Morphological Image Analysis and Feature Extraction for Reasoning with AI-based Defect Detection and Classification Models</title><link>http://arxiv.org/abs/2307.11643v1</link><description>As the use of artificial intelligent (AI) models becomes more prevalent inindustries such as engineering and manufacturing, it is essential that thesemodels provide transparent reasoning behind their predictions. This paperproposes the AI-Reasoner, which extracts the morphological characteristics ofdefects (DefChars) from images and utilises decision trees to reason with theDefChar values. Thereafter, the AI-Reasoner exports visualisations (i.e.charts) and textual explanations to provide insights into outputs made bymasked-based defect detection and classification models. It also provideseffective mitigation strategies to enhance data pre-processing and overallmodel performance. The AI-Reasoner was tested on explaining the outputs of anIE Mask R-CNN model using a set of 366 images containing defects. The resultsdemonstrated its effectiveness in explaining the IE Mask R-CNN model'spredictions. Overall, the proposed AI-Reasoner provides a solution forimproving the performance of AI models in industrial applications that requiredefect analysis.</description><author>Jiajun Zhang, Georgina Cosma, Sarah Bugby, Axel Finke, Jason Watkins</author><pubDate>Fri, 21 Jul 2023 16:22:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11643v1</guid></item><item><title>Dense Sample Deep Learning</title><link>http://arxiv.org/abs/2307.10991v2</link><description>Deep Learning (DL) , a variant of the neural network algorithms originallyproposed in the 1980s, has made surprising progress in Artificial Intelligence(AI), ranging from language translation, protein folding, autonomous cars, andmore recently human-like language models (CHATbots), all that seemedintractable until very recently. Despite the growing use of Deep Learning (DL)networks, little is actually understood about the learning mechanisms andrepresentations that makes these networks effective across such a diverse rangeof applications. Part of the answer must be the huge scale of the architectureand of course the large scale of the data, since not much has changed since1987. But the nature of deep learned representations remain largely unknown.Unfortunately training sets with millions or billions of tokens have unknowncombinatorics and Networks with millions or billions of hidden units cannoteasily be visualized and their mechanisms cannot be easily revealed. In thispaper, we explore these questions with a large (1.24M weights; VGG) DL in anovel high density sample task (5 unique tokens with at minimum 500 exemplarsper token) which allows us to more carefully follow the emergence of categorystructure and feature construction. We use various visualization methods forfollowing the emergence of the classification and the development of thecoupling of feature detectors and structures that provide a type of graphicalbootstrapping, From these results we harvest some basic observations of thelearning dynamics of DL and propose a new theory of complex featureconstruction based on our results.</description><author>Stephen Josè Hanson, Vivek Yadav, Catherine Hanson</author><pubDate>Fri, 21 Jul 2023 16:18:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.10991v2</guid></item><item><title>Deep Reinforcement Learning Based System for Intraoperative Hyperspectral Video Autofocusing</title><link>http://arxiv.org/abs/2307.11638v1</link><description>Hyperspectral imaging (HSI) captures a greater level of spectral detail thantraditional optical imaging, making it a potentially valuable intraoperativetool when precise tissue differentiation is essential. Hardware limitations ofcurrent optical systems used for handheld real-time video HSI result in alimited focal depth, thereby posing usability issues for integration of thetechnology into the operating room. This work integrates a focus-tunable liquidlens into a video HSI exoscope, and proposes novel video autofocusing methodsbased on deep reinforcement learning. A first-of-its-kind robotic focal-timescan was performed to create a realistic and reproducible testing dataset. Webenchmarked our proposed autofocus algorithm against traditional policies, andfound our novel approach to perform significantly ($p&lt;0.05$) better thantraditional techniques ($0.070\pm.098$ mean absolute focal error compared to$0.146\pm.148$). In addition, we performed a blinded usability trial by havingtwo neurosurgeons compare the system with different autofocus policies, andfound our novel approach to be the most favourable, making our system adesirable addition for intraoperative HSI.</description><author>Charlie Budd, Jianrong Qiu, Oscar MacCormac, Martin Huber, Christopher Mower, Mirek Janatka, Théo Trotouin, Jonathan Shapey, Mads S. Bergholt, Tom Vercauteren</author><pubDate>Fri, 21 Jul 2023 16:04:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11638v1</guid></item><item><title>Integration of Domain Expert-Centric Ontology Design into the CRISP-DM for Cyber-Physical Production Systems</title><link>http://arxiv.org/abs/2307.11637v1</link><description>In the age of Industry 4.0 and Cyber-Physical Production Systems (CPPSs) vastamounts of potentially valuable data are being generated. Methods from MachineLearning (ML) and Data Mining (DM) have proven to be promising in extractingcomplex and hidden patterns from the data collected. The knowledge obtained canin turn be used to improve tasks like diagnostics or maintenance planning.However, such data-driven projects, usually performed with the Cross-IndustryStandard Process for Data Mining (CRISP-DM), often fail due to thedisproportionate amount of time needed for understanding and preparing thedata. The application of domain-specific ontologies has demonstrated itsadvantageousness in a wide variety of Industry 4.0 application scenariosregarding the aforementioned challenges. However, workflows and artifacts fromontology design for CPPSs have not yet been systematically integrated into theCRISP-DM. Accordingly, this contribution intends to present an integratedapproach so that data scientists are able to more quickly and reliably gaininsights into the CPPS. The result is exemplarily applied to an anomalydetection use case.</description><author>Milapji Singh Gill, Tom Westermann, Marvin Schieseck, Alexander Fay</author><pubDate>Fri, 21 Jul 2023 16:04:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11637v1</guid></item><item><title>Multiresolution Graph Transformers and Wavelet Positional Encoding for Learning Hierarchical Structures</title><link>http://arxiv.org/abs/2302.08647v4</link><description>Contemporary graph learning algorithms are not well-defined for largemolecules since they do not consider the hierarchical interactions among theatoms, which are essential to determine the molecular properties ofmacromolecules. In this work, we propose Multiresolution Graph Transformers(MGT), the first graph transformer architecture that can learn to representlarge molecules at multiple scales. MGT can learn to produce representationsfor the atoms and group them into meaningful functional groups or repeatingunits. We also introduce Wavelet Positional Encoding (WavePE), a new positionalencoding method that can guarantee localization in both spectral and spatialdomains. Our proposed model achieves competitive results on two macromoleculedatasets consisting of polymers and peptides, and one drug-like moleculedataset. Importantly, our model outperforms other state-of-the-art methods andachieves chemical accuracy in estimating molecular properties (e.g., GAP, HOMOand LUMO) calculated by Density Functional Theory (DFT) in the polymersdataset. Furthermore, the visualizations, including clustering results onmacromolecules and low-dimensional spaces of their representations, demonstratethe capability of our methodology in learning to represent long-range andhierarchical structures. Our PyTorch implementation is publicly available athttps://github.com/HySonLab/Multires-Graph-Transformer</description><author>Nhat Khang Ngo, Truong Son Hy, Risi Kondor</author><pubDate>Fri, 21 Jul 2023 15:59:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.08647v4</guid></item><item><title>OxfordTVG-HIC: Can Machine Make Humorous Captions from Images?</title><link>http://arxiv.org/abs/2307.11636v1</link><description>This paper presents OxfordTVG-HIC (Humorous Image Captions), a large-scaledataset for humour generation and understanding. Humour is an abstract,subjective, and context-dependent cognitive construct involving severalcognitive factors, making it a challenging task to generate and interpret.Hence, humour generation and understanding can serve as a new task forevaluating the ability of deep-learning methods to process abstract andsubjective information. Due to the scarcity of data, humour-related generationtasks such as captioning remain under-explored. To address this gap,OxfordTVG-HIC offers approximately 2.9M image-text pairs with humour scores totrain a generalizable humour captioning model. Contrary to existing captioningdatasets, OxfordTVG-HIC features a wide range of emotional and semanticdiversity resulting in out-of-context examples that are particularly conduciveto generating humour. Moreover, OxfordTVG-HIC is curated devoid of offensivecontent. We also show how OxfordTVG-HIC can be leveraged for evaluating thehumour of a generated text. Through explainability analysis of the trainedmodels, we identify the visual and linguistic cues influential for evokinghumour prediction (and generation). We observe qualitatively that these cuesare aligned with the benign violation theory of humour in cognitive psychology.</description><author>Runjia Li, Shuyang Sun, Mohamed Elhoseiny, Philip Torr</author><pubDate>Fri, 21 Jul 2023 15:58:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11636v1</guid></item><item><title>Automated wildlife image classification: An active learning tool for ecological applications</title><link>http://arxiv.org/abs/2303.15823v2</link><description>Wildlife camera trap images are being used extensively to investigate animalabundance, habitat associations, and behavior, which is complicated by the factthat experts must first classify the images manually. Artificial intelligencesystems can take over this task but usually need a large number ofalready-labeled training images to achieve sufficient performance. Thisrequirement necessitates human expert labor and poses a particular challengefor projects with few cameras or short durations. We propose a label-efficientlearning strategy that enables researchers with small or medium-sized imagedatabases to leverage the potential of modern machine learning, thus freeingcrucial resources for subsequent analyses. Our methodological proposal is two-fold: (1) We improve current strategies ofcombining object detection and image classification by tuning thehyperparameters of both models. (2) We provide an active learning (AL) systemthat allows training deep learning models very efficiently in terms of requiredhuman-labeled training images. We supply a software package that enablesresearchers to use these methods directly and thereby ensure the broadapplicability of the proposed framework in ecological practice. We show that our tuning strategy improves predictive performance. Wedemonstrate how the AL pipeline reduces the amount of pre-labeled data neededto achieve a specific predictive performance and that it is especially valuablefor improving out-of-sample predictive performance. We conclude that the combination of tuning and AL increases predictiveperformance substantially. Furthermore, we argue that our work can broadlyimpact the community through the ready-to-use software package provided.Finally, the publication of our models tailored to European wildlife dataenriches existing model bases mostly trained on data from Africa and NorthAmerica.</description><author>Ludwig Bothmann, Lisa Wimmer, Omid Charrakh, Tobias Weber, Hendrik Edelhoff, Wibke Peters, Hien Nguyen, Caryl Benjamin, Annette Menzel</author><pubDate>Fri, 21 Jul 2023 15:55:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.15823v2</guid></item><item><title>Scalable Multi-agent Skill Discovery based on Kronecker Graphs</title><link>http://arxiv.org/abs/2307.11629v1</link><description>Covering skill (a.k.a., option) discovery has been developed to improve theexploration of RL in single-agent scenarios with sparse reward signals, throughconnecting the most distant states in the embedding space provided by theFiedler vector of the state transition graph. Given that joint state spacegrows exponentially with the number of agents in multi-agent systems, existingresearches still relying on single-agent option discovery either becomeprohibitive or fail to directly discover joint options that improve theconnectivity of the joint state space. In this paper, we show how to directlycompute multi-agent options with collaborative exploratory behaviors whilestill enjoying the ease of decomposition. Our key idea is to approximate thejoint state space as a Kronecker graph, based on which we can directly estimateits Fiedler vector using the Laplacian spectrum of individual agents'transition graphs. Further, considering that directly computing the Laplacianspectrum is intractable for tasks with infinite-scale state spaces, we furtherpropose a deep learning extension of our method by estimating eigenfunctionsthrough NN-based representation learning techniques. The evaluation onmulti-agent tasks built with simulators like Mujoco, shows that the proposedalgorithm can successfully identify multi-agent options, and significantlyoutperforms the state-of-the-art. Codes are available at:https://github.itap.purdue.edu/Clan-labs/Scalable_MAOD_via_KP.</description><author>Jiayu Chen, Jingdi Chen, Tian Lan, Vaneet Aggarwal</author><pubDate>Fri, 21 Jul 2023 15:53:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11629v1</guid></item><item><title>MOISST: Multimodal Optimization of Implicit Scene for SpatioTemporal calibration</title><link>http://arxiv.org/abs/2303.03056v3</link><description>With the recent advances in autonomous driving and the decreasing cost ofLiDARs, the use of multimodal sensor systems is on the rise. However, in orderto make use of the information provided by a variety of complimentary sensors,it is necessary to accurately calibrate them. We take advantage of recentadvances in computer graphics and implicit volumetric scene representation totackle the problem of multi-sensor spatial and temporal calibration. Thanks toa new formulation of the Neural Radiance Field (NeRF) optimization, we are ableto jointly optimize calibration parameters along with scene representationbased on radiometric and geometric measurements. Our method enables accurateand robust calibration from data captured in uncontrolled and unstructuredurban environments, making our solution more scalable than existing calibrationsolutions. We demonstrate the accuracy and robustness of our method in urbanscenes typically encountered in autonomous driving scenarios.</description><author>Quentin Herau, Nathan Piasco, Moussab Bennehar, Luis Roldão, Dzmitry Tsishkou, Cyrille Migniot, Pascal Vasseur, Cédric Demonceaux</author><pubDate>Fri, 21 Jul 2023 15:45:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.03056v3</guid></item><item><title>NusaCrowd: Open Source Initiative for Indonesian NLP Resources</title><link>http://arxiv.org/abs/2212.09648v4</link><description>We present NusaCrowd, a collaborative initiative to collect and unifyexisting resources for Indonesian languages, including opening access topreviously non-public resources. Through this initiative, we have broughttogether 137 datasets and 118 standardized data loaders. The quality of thedatasets has been assessed manually and automatically, and their value isdemonstrated through multiple experiments. NusaCrowd's data collection enablesthe creation of the first zero-shot benchmarks for natural languageunderstanding and generation in Indonesian and the local languages ofIndonesia. Furthermore, NusaCrowd brings the creation of the first multilingualautomatic speech recognition benchmark in Indonesian and the local languages ofIndonesia. Our work strives to advance natural language processing (NLP)research for languages that are under-represented despite being widely spoken.</description><author>Samuel Cahyawijaya, Holy Lovenia, Alham Fikri Aji, Genta Indra Winata, Bryan Wilie, Rahmad Mahendra, Christian Wibisono, Ade Romadhony, Karissa Vincentio, Fajri Koto, Jennifer Santoso, David Moeljadi, Cahya Wirawan, Frederikus Hudi, Ivan Halim Parmonangan, Ika Alfina, Muhammad Satrio Wicaksono, Ilham Firdausi Putra, Samsul Rahmadani, Yulianti Oenang, Ali Akbar Septiandri, James Jaya, Kaustubh D. Dhole, Arie Ardiyanti Suryani, Rifki Afina Putri, Dan Su, Keith Stevens, Made Nindyatama Nityasya, Muhammad Farid Adilazuarda, Ryan Ignatius, Ryandito Diandaru, Tiezheng Yu, Vito Ghifari, Wenliang Dai, Yan Xu, Dyah Damapuspita, Cuk Tho, Ichwanul Muslim Karo Karo, Tirana Noor Fatyanosa, Ziwei Ji, Pascale Fung, Graham Neubig, Timothy Baldwin, Sebastian Ruder, Herry Sujaini, Sakriani Sakti, Ayu Purwar</author><pubDate>Fri, 21 Jul 2023 15:44:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.09648v4</guid></item><item><title>On the Complexity of the Bipartite Polarization Problem: from Neutral to Highly Polarized Discussions</title><link>http://arxiv.org/abs/2307.11621v1</link><description>The Bipartite Polarization Problem is an optimization problem where the goalis to find the highest polarized bipartition on a weighted and labelled graphthat represents a debate developed through some social network, where nodesrepresent user's opinions and edges agreement or disagreement between users.This problem can be seen as a generalization of the maxcut problem, and inprevious work approximate solutions and exact solutions have been obtained forreal instances obtained from Reddit discussions, showing that such realinstances seem to be very easy to solve. In this paper, we investigate furtherthe complexity of this problem, by introducing an instance generation modelwhere a single parameter controls the polarization of the instances in such away that this correlates with the average complexity to solve those instances.The average complexity results we obtain are consistent with our hypothesis:the higher the polarization of the instance, the easier is to find thecorresponding polarized bipartition.</description><author>Teresa Alsinet, Josep Argelich, Ramón Béjar, Santi Martínez</author><pubDate>Fri, 21 Jul 2023 15:40:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11621v1</guid></item><item><title>Offline Multi-Agent Reinforcement Learning with Implicit Global-to-Local Value Regularization</title><link>http://arxiv.org/abs/2307.11620v1</link><description>Offline reinforcement learning (RL) has received considerable attention inrecent years due to its attractive capability of learning policies from offlinedatasets without environmental interactions. Despite some success in thesingle-agent setting, offline multi-agent RL (MARL) remains to be a challenge.The large joint state-action space and the coupled multi-agent behaviors poseextra complexities for offline policy optimization. Most existing offline MARLstudies simply apply offline data-related regularizations on individual agents,without fully considering the multi-agent system at the global level. In thiswork, we present OMIGA, a new offline m ulti-agent RL algorithm with implicitglobal-to-local v alue regularization. OMIGA provides a principled framework toconvert global-level value regularization into equivalent implicit local valueregularizations and simultaneously enables in-sample learning, thus elegantlybridging multi-agent value decomposition and policy learning with offlineregularizations. Based on comprehensive experiments on the offline multi-agentMuJoCo and StarCraft II micro-management tasks, we show that OMIGA achievessuperior performance over the state-of-the-art offline MARL methods in almostall tasks.</description><author>Xiangsen Wang, Haoran Xu, Yinan Zheng, Xianyuan Zhan</author><pubDate>Fri, 21 Jul 2023 15:37:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11620v1</guid></item><item><title>Divide and Adapt: Active Domain Adaptation via Customized Learning</title><link>http://arxiv.org/abs/2307.11618v1</link><description>Active domain adaptation (ADA) aims to improve the model adaptationperformance by incorporating active learning (AL) techniques to label amaximally-informative subset of target samples. Conventional AL methods do notconsider the existence of domain shift, and hence, fail to identify the trulyvaluable samples in the context of domain adaptation. To accommodate activelearning and domain adaption, the two naturally different tasks, in acollaborative framework, we advocate that a customized learning strategy forthe target data is the key to the success of ADA solutions. We presentDivide-and-Adapt (DiaNA), a new ADA framework that partitions the targetinstances into four categories with stratified transferable properties. With anovel data subdivision protocol based on uncertainty and domainness, DiaNA canaccurately recognize the most gainful samples. While sending the informativeinstances for annotation, DiaNA employs tailored learning strategies for theremaining categories. Furthermore, we propose an informativeness score thatunifies the data partitioning criteria. This enables the use of a Gaussianmixture model (GMM) to automatically sample unlabeled data into the proposedfour categories. Thanks to the "divideand-adapt" spirit, DiaNA can handle datawith large variations of domain gap. In addition, we show that DiaNA cangeneralize to different domain adaptation settings, such as unsupervised domainadaptation (UDA), semi-supervised domain adaptation (SSDA), source-free domainadaptation (SFDA), etc.</description><author>Duojun Huang, Jichang Li, Weikai Chen, Junshi Huang, Zhenhua Chai, Guanbin Li</author><pubDate>Fri, 21 Jul 2023 15:37:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11618v1</guid></item><item><title>Robust Fully-Asynchronous Methods for Distributed Training over General Architecture</title><link>http://arxiv.org/abs/2307.11617v1</link><description>Perfect synchronization in distributed machine learning problems isinefficient and even impossible due to the existence of latency, package lossesand stragglers. We propose a Robust Fully-Asynchronous Stochastic GradientTracking method (R-FAST), where each device performs local computation andcommunication at its own pace without any form of synchronization. Differentfrom existing asynchronous distributed algorithms, R-FAST can eliminate theimpact of data heterogeneity across devices and allow for packet losses byemploying a robust gradient tracking strategy that relies on properly designedauxiliary variables for tracking and buffering the overall gradient vector.More importantly, the proposed method utilizes two spanning-tree graphs forcommunication so long as both share at least one common root, enabling flexibledesigns in communication architectures. We show that R-FAST converges inexpectation to a neighborhood of the optimum with a geometric rate for smoothand strongly convex objectives; and to a stationary point with a sublinear ratefor general non-convex settings. Extensive experiments demonstrate that R-FASTruns 1.5-2 times faster than synchronous benchmark algorithms, such asRing-AllReduce and D-PSGD, while still achieving comparable accuracy, andoutperforms existing asynchronous SOTA algorithms, such as AD-PSGD and OSGP,especially in the presence of stragglers.</description><author>Zehan Zhu, Ye Tian, Yan Huang, Jinming Xu, Shibo He</author><pubDate>Fri, 21 Jul 2023 15:36:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11617v1</guid></item><item><title>CausE: Towards Causal Knowledge Graph Embedding</title><link>http://arxiv.org/abs/2307.11610v1</link><description>Knowledge graph embedding (KGE) focuses on representing the entities andrelations of a knowledge graph (KG) into the continuous vector spaces, whichcan be employed to predict the missing triples to achieve knowledge graphcompletion (KGC). However, KGE models often only briefly learn structuralcorrelations of triple data and embeddings would be misled by the trivialpatterns and noisy links in real-world KGs. To address this issue, we build thenew paradigm of KGE in the context of causality and embedding disentanglement.We further propose a Causality-enhanced knowledge graph Embedding (CausE)framework. CausE employs causal intervention to estimate the causal effect ofthe confounder embeddings and design new training objectives to make stablepredictions. Experimental results demonstrate that CausE could outperform thebaseline models and achieve state-of-the-art KGC performance. We release ourcode in https://github.com/zjukg/CausE.</description><author>Yichi Zhang, Wen Zhang</author><pubDate>Fri, 21 Jul 2023 15:25:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11610v1</guid></item><item><title>Persistent Ballistic Entanglement Spreading with Optimal Control in Quantum Spin Chains</title><link>http://arxiv.org/abs/2307.11609v1</link><description>Entanglement propagation provides a key routine to understand quantummany-body dynamics in and out of equilibrium. In this work, we uncover that the``variational entanglement-enhancing'' field (VEEF) robustly induces apersistent ballistic spreading of entanglement in quantum spin chains. The VEEFis time dependent, and is optimally controlled to maximize the bipartiteentanglement entropy (EE) of the final state. Such a linear growth persiststill the EE reaches the genuine saturation $\tilde{S} = - \log_{2}2^{-\frac{N}{2}}=\frac{N}{2}$ with $N$ the total number of spins. The EEsatisfies $S(t) = v t$ for the time $t \leq \frac{N}{2v}$, with $v$ thevelocity. These results are in sharp contrast with the behaviors without VEEF,where the EE generally approaches a sub-saturation known as the Page value$\tilde{S}_{P} =\tilde{S} - \frac{1}{2\ln{2}}$ in the long-time limit, and theentanglement growth deviates from being linear before the Page value isreached. The dependence between the velocity and interactions is explored, with$v \simeq 2.76$, $4.98$, and $5.75$ for the spin chains with Ising, XY, andHeisenberg interactions, respectively. We further show that the nonlineargrowth of EE emerges with the presence of long-range interactions.</description><author>Ying Lu, Pei Shi, Xiao-Han Wang, Jie Hu, Shi-Ju Ran</author><pubDate>Fri, 21 Jul 2023 15:25:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11609v1</guid></item><item><title>Learning minimal representations of stochastic processes with variational autoencoders</title><link>http://arxiv.org/abs/2307.11608v1</link><description>Stochastic processes have found numerous applications in science, as they arebroadly used to model a variety of natural phenomena. Due to their intrinsicrandomness and uncertainty, they are however difficult to characterize. Here,we introduce an unsupervised machine learning approach to determine the minimalset of parameters required to effectively describe the dynamics of a stochasticprocess. Our method builds upon an extended $\beta$-variational autoencoderarchitecture. By means of simulated datasets corresponding to paradigmaticdiffusion models, we showcase its effectiveness in extracting the minimalrelevant parameters that accurately describe these dynamics. Furthermore, themethod enables the generation of new trajectories that faithfully replicate theexpected stochastic behavior. Overall, our approach enables for the autonomousdiscovery of unknown parameters describing stochastic processes, henceenhancing our comprehension of complex phenomena across various fields.</description><author>Gabriel Fernández-Fernández, Carlo Manzo, Maciej Lewenstein, Alexandre Dauphin, Gorka Muñoz-Gil</author><pubDate>Fri, 21 Jul 2023 15:25:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11608v1</guid></item><item><title>Finding Optimal Diverse Feature Sets with Alternative Feature Selection</title><link>http://arxiv.org/abs/2307.11607v1</link><description>Feature selection is popular for obtaining small, interpretable, yet highlyaccurate prediction models. Conventional feature-selection methods typicallyyield one feature set only, which might not suffice in some scenarios. Forexample, users might be interested in finding alternative feature sets withsimilar prediction quality, offering different explanations of the data. Inthis article, we introduce alternative feature selection and formalize it as anoptimization problem. In particular, we define alternatives via constraints andenable users to control the number and dissimilarity of alternatives. Next, weanalyze the complexity of this optimization problem and show NP-hardness.Further, we discuss how to integrate conventional feature-selection methods asobjectives. Finally, we evaluate alternative feature selection with 30classification datasets. We observe that alternative feature sets may indeedhave high prediction quality, and we analyze several factors influencing thisoutcome.</description><author>Jakob Bach</author><pubDate>Fri, 21 Jul 2023 15:23:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11607v1</guid></item><item><title>Consistency-guided Meta-Learning for Bootstrapping Semi-Supervised Medical Image Segmentation</title><link>http://arxiv.org/abs/2307.11604v1</link><description>Medical imaging has witnessed remarkable progress but usually requires alarge amount of high-quality annotated data which is time-consuming and costlyto obtain. To alleviate this burden, semi-supervised learning has garneredattention as a potential solution. In this paper, we present Meta-Learning forBootstrapping Medical Image Segmentation (MLB-Seg), a novel method for tacklingthe challenge of semi-supervised medical image segmentation. Specifically, ourapproach first involves training a segmentation model on a small set of cleanlabeled images to generate initial labels for unlabeled data. To furtheroptimize this bootstrapping process, we introduce a per-pixel weight mappingsystem that dynamically assigns weights to both the initialized labels and themodel's own predictions. These weights are determined using a meta-process thatprioritizes pixels with loss gradient directions closer to those of clean data,which is based on a small set of precisely annotated images. To facilitate themeta-learning process, we additionally introduce a consistency-based PseudoLabel Enhancement (PLE) scheme that improves the quality of the model's ownpredictions by ensembling predictions from various augmented versions of thesame input. In order to improve the quality of the weight maps obtained throughmultiple augmentations of a single input, we introduce a mean teacher into thePLE scheme. This method helps to reduce noise in the weight maps and stabilizeits generation process. Our extensive experimental results on public atrial andprostate segmentation datasets demonstrate that our proposed method achievesstate-of-the-art results under semi-supervision. Our code is available athttps://github.com/aijinrjinr/MLB-Seg.</description><author>Qingyue Wei, Lequan Yu, Xianhang Li, Wei Shao, Cihang Xie, Lei Xing, Yuyin Zhou</author><pubDate>Fri, 21 Jul 2023 15:14:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11604v1</guid></item><item><title>rSVDdpd: A Robust Scalable Video Surveillance Background Modelling Algorithm</title><link>http://arxiv.org/abs/2109.10680v2</link><description>A basic algorithmic task in automated video surveillance is to separatebackground and foreground objects. Camera tampering, noisy videos, low framerate, etc., pose difficulties in solving the problem. A general approach thatclassifies the tampered frames, and performs subsequent analysis on theremaining frames after discarding the tampered ones, results in loss ofinformation. Several robust methods based on robust principal componentanalysis (PCA) have been introduced to solve this problem. To date,considerable effort has been expended to develop robust PCA via PrincipalComponent Pursuit (PCP) methods with reduced computational cost and visuallyappealing foreground detection. However, the convex optimizations used in thesealgorithms do not scale well to real-world large datasets due to large matrixinversion steps. Also, an integral component of these foreground detectionalgorithms is singular value decomposition which is nonrobust. In this paper,we present a new video surveillance background modelling algorithm based on anew robust singular value decomposition technique rSVDdpd which takes care ofboth these issues. We also demonstrate the superiority of our proposedalgorithm on a benchmark dataset and a new real-life video surveillance datasetin the presence of camera tampering. Software codes and additionalillustrations are made available at the accompanying website rSVDdpd Homepage(https://subroy13.github.io/rsvddpd-home/)</description><author>Subhrajyoty Roy, Ayanendranath Basu, Abhik Ghosh</author><pubDate>Fri, 21 Jul 2023 15:13:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.10680v2</guid></item><item><title>Cascaded multitask U-Net using topological loss for vessel segmentation and centerline extraction</title><link>http://arxiv.org/abs/2307.11603v1</link><description>Vessel segmentation and centerline extraction are two crucial preliminarytasks for many computer-aided diagnosis tools dealing with vascular diseases.Recently, deep-learning based methods have been widely applied to these tasks.However, classic deep-learning approaches struggle to capture the complexgeometry and specific topology of vascular networks, which is of the utmostimportance in most applications. To overcome these limitations, the clDiceloss, a topological loss that focuses on the vessel centerlines, has beenrecently proposed. This loss requires computing, with a proposed soft-skeletonalgorithm, the skeletons of both the ground truth and the predictedsegmentation. However, the soft-skeleton algorithm provides suboptimal resultson 3D images, which makes the clDice hardly suitable on 3D images. In thispaper, we propose to replace the soft-skeleton algorithm by a U-Net whichcomputes the vascular skeleton directly from the segmentation. We show that ourmethod provides more accurate skeletons than the soft-skeleton algorithm. Wethen build upon this network a cascaded U-Net trained with the clDice loss toembed topological constraints during the segmentation. The resulting model isable to predict both the vessel segmentation and centerlines with a moreaccurate topology.</description><author>Pierre Rougé, Nicolas Passat, Odyssée Merveille</author><pubDate>Fri, 21 Jul 2023 15:12:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11603v1</guid></item><item><title>ClueReader: Heterogeneous Graph Attention Network for Multi-hop Machine Reading Comprehension</title><link>http://arxiv.org/abs/2107.00841v3</link><description>Multi-hop machine reading comprehension is a challenging task in naturallanguage processing as it requires more reasoning ability across multipledocuments. Spectral models based on graph convolutional networks have showngood inferring abilities and lead to competitive results. However, the analysisand reasoning of some are inconsistent with those of humans. Inspired by theconcept of grandmother cells in cognitive neuroscience, we propose aheterogeneous graph attention network model named ClueReader to imitate thegrandmother cell concept. The model is designed to assemble the semanticfeatures in multi-level representations and automatically concentrate oralleviate information for reasoning through the attention mechanism. The nameClueReader is a metaphor for the pattern of the model: it regards the subjectsof queries as the starting points of clues, takes the reasoning entities asbridge points, considers the latent candidate entities as grandmother cells,and the clues end up in candidate entities. The proposed model enables thevisualization of the reasoning graph, making it possible to analyze theimportance of edges connecting entities and the selectivity in the mention andcandidate nodes, which is easier to comprehend empirically. Evaluations on theopen-domain multi-hop reading dataset WikiHop and drug-drug interaction datasetMedHop proved the validity of ClueReader and showed the feasibility of itsapplication of the model in the molecular biology domain.</description><author>Peng Gao, Feng Gao, Peng Wang, Jian-Cheng Ni, Fei Wang, Hamido Fujita</author><pubDate>Fri, 21 Jul 2023 15:03:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2107.00841v3</guid></item><item><title>A Unified Algorithm Framework for Unsupervised Discovery of Skills based on Determinantal Point Process</title><link>http://arxiv.org/abs/2212.00211v2</link><description>Learning rich skills through temporal abstractions without supervision ofexternal rewards is at the frontier of Reinforcement Learning research.Existing works mainly fall into two distinctive categories: variational andLaplacian-based skill (a.k.a., option) discovery. The former maximizes thediversity of the discovered options through a mutual information loss butoverlooks coverage of the state space, while the latter focuses on improvingthe coverage of options by increasing connectivity during exploration, but doesnot consider diversity. In this paper, we propose a unified framework thatquantifies diversity and coverage through a novel use of the DeterminantalPoint Process (DPP) and enables unsupervised option discovery explicitlyoptimizing both objectives. Specifically, we define the DPP kernel matrix withthe Laplacian spectrum of the state transition graph and use the expected modenumber in the trajectories as the objective to capture and enhance bothdiversity and coverage of the learned options. The proposed option discoveryalgorithm is extensively evaluated using challenging tasks built with Mujocoand Atari, demonstrating that our proposed algorithm substantially outperformsSOTA baselines from both diversity- and coverage-driven categories. The codesare available at https://github.com/LucasCJYSDL/ODPP.</description><author>Jiayu Chen, Vaneet Aggarwal, Tian Lan</author><pubDate>Fri, 21 Jul 2023 14:57:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.00211v2</guid></item><item><title>Transferability of Convolutional Neural Networks in Stationary Learning Tasks</title><link>http://arxiv.org/abs/2307.11588v1</link><description>Recent advances in hardware and big data acquisition have accelerated thedevelopment of deep learning techniques. For an extended period of time,increasing the model complexity has led to performance improvements for varioustasks. However, this trend is becoming unsustainable and there is a need foralternative, computationally lighter methods. In this paper, we introduce anovel framework for efficient training of convolutional neural networks (CNNs)for large-scale spatial problems. To accomplish this we investigate theproperties of CNNs for tasks where the underlying signals are stationary. Weshow that a CNN trained on small windows of such signals achieves a nearlyperformance on much larger windows without retraining. This claim is supportedby our theoretical analysis, which provides a bound on the performancedegradation. Additionally, we conduct thorough experimental analysis on twotasks: multi-target tracking and mobile infrastructure on demand. Our resultsshow that the CNN is able to tackle problems with many hundreds of agents afterbeing trained with fewer than ten. Thus, CNN architectures provide solutions tothese problems at previously computationally intractable scales.</description><author>Damian Owerko, Charilaos I. Kanatsoulis, Jennifer Bondarchuk, Donald J. Bucci Jr, Alejandro Ribeiro</author><pubDate>Fri, 21 Jul 2023 14:51:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11588v1</guid></item><item><title>A Change of Heart: Improving Speech Emotion Recognition through Speech-to-Text Modality Conversion</title><link>http://arxiv.org/abs/2307.11584v1</link><description>Speech Emotion Recognition (SER) is a challenging task. In this paper, weintroduce a modality conversion concept aimed at enhancing emotion recognitionperformance on the MELD dataset. We assess our approach through twoexperiments: first, a method named Modality-Conversion that employs automaticspeech recognition (ASR) systems, followed by a text classifier; second, weassume perfect ASR output and investigate the impact of modality conversion onSER, this method is called Modality-Conversion++. Our findings indicate thatthe first method yields substantial results, while the second methodoutperforms state-of-the-art (SOTA) speech-based approaches in terms of SERweighted-F1 (WF1) score on the MELD dataset. This research highlights thepotential of modality conversion for tasks that can be conducted in alternativemodalities.</description><author>Zeinab Sadat Taghavi, Ali Satvaty, Hossein Sameti</author><pubDate>Fri, 21 Jul 2023 14:48:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11584v1</guid></item><item><title>Learning Multi-agent Skills for Tabular Reinforcement Learning using Factor Graphs</title><link>http://arxiv.org/abs/2201.08227v3</link><description>Covering skill (a.k.a., option) discovery has been developed to improve theexploration of reinforcement learning in single-agent scenarios with sparsereward signals, through connecting the most distant states in the embeddingspace provided by the Fiedler vector of the state transition graph. However,these option discovery methods cannot be directly extended to multi-agentscenarios, since the joint state space grows exponentially with the number ofagents in the system. Thus, existing researches on adopting options inmulti-agent scenarios still rely on single-agent option discovery and fail todirectly discover the joint options that can improve the connectivity of thejoint state space of agents. In this paper, we show that it is indeed possibleto directly compute multi-agent options with collaborative exploratorybehaviors among the agents, while still enjoying the ease of decomposition. Ourkey idea is to approximate the joint state space as a Kronecker graph -- theKronecker product of individual agents' state transition graphs, based on whichwe can directly estimate the Fiedler vector of the joint state space using theLaplacian spectrum of individual agents' transition graphs. This decompositionenables us to efficiently construct multi-agent joint options by encouragingagents to connect the sub-goal joint states which are corresponding to theminimum or maximum values of the estimated joint Fiedler vector. The evaluationbased on multi-agent collaborative tasks shows that the proposed algorithm cansuccessfully identify multi-agent options, and significantly outperforms priorworks using single-agent options or no options, in terms of both fasterexploration and higher cumulative rewards.</description><author>Jiayu Chen, Jingdi Chen, Tian Lan, Vaneet Aggarwal</author><pubDate>Fri, 21 Jul 2023 14:42:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.08227v3</guid></item><item><title>Multi-agent Deep Covering Skill Discovery</title><link>http://arxiv.org/abs/2210.03269v2</link><description>The use of skills (a.k.a., options) can greatly accelerate exploration inreinforcement learning, especially when only sparse reward signals areavailable. While option discovery methods have been proposed for individualagents, in multi-agent reinforcement learning settings, discoveringcollaborative options that can coordinate the behavior of multiple agents andencourage them to visit the under-explored regions of their joint state spacehas not been considered. In this case, we propose Multi-agent Deep CoveringOption Discovery, which constructs the multi-agent options through minimizingthe expected cover time of the multiple agents' joint state space. Also, wepropose a novel framework to adopt the multi-agent options in the MARL process.In practice, a multi-agent task can usually be divided into some sub-tasks,each of which can be completed by a sub-group of the agents. Therefore, ouralgorithm framework first leverages an attention mechanism to findcollaborative agent sub-groups that would benefit most from coordinatedactions. Then, a hierarchical algorithm, namely HA-MSAC, is developed to learnthe multi-agent options for each sub-group to complete their sub-tasks first,and then to integrate them through a high-level policy as the solution of thewhole task. This hierarchical option construction allows our framework tostrike a balance between scalability and effective collaboration among theagents. The evaluation based on multi-agent collaborative tasks shows that theproposed algorithm can effectively capture the agent interactions with theattention mechanism, successfully identify multi-agent options, andsignificantly outperforms prior works using single-agent options or no options,in terms of both faster exploration and higher task rewards.</description><author>Jiayu Chen, Marina Haliem, Tian Lan, Vaneet Aggarwal</author><pubDate>Fri, 21 Jul 2023 14:27:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.03269v2</guid></item><item><title>Conditional Diffusion Models for Semantic 3D Medical Image Synthesis</title><link>http://arxiv.org/abs/2305.18453v2</link><description>The demand for artificial intelligence (AI) in healthcare is rapidlyincreasing. However, significant challenges arise from data scarcity andprivacy concerns, particularly in medical imaging. While existing generativemodels have achieved success in image synthesis and image-to-image translationtasks, there remains a gap in the generation of 3D semantic medical images. Toaddress this gap, we introduce Med-DDPM, a diffusion model specificallydesigned for semantic 3D medical image synthesis, effectively tackling datascarcity and privacy issues. The novelty of Med-DDPM lies in its incorporationof semantic conditioning, enabling precise control during the image generationprocess. Our model outperforms Generative Adversarial Networks (GANs) in termsof stability and performance, generating diverse and anatomically coherentimages with high visual fidelity. Comparative analysis against state-of-the-artaugmentation techniques demonstrates that Med-DDPM produces comparable results,highlighting its potential as a data augmentation tool for enhancing modelaccuracy. In conclusion, Med-DDPM pioneers 3D semantic medical image synthesisby delivering high-quality and anatomically coherent images. Furthermore, theintegration of semantic conditioning with Med-DDPM holds promise for imageanonymization in the field of biomedical imaging, showcasing the capabilitiesof the model in addressing challenges related to data scarcity and privacyconcerns.</description><author>Zolnamar Dorjsembe, Hsing-Kuo Pao, Sodtavilan Odonchimed, Furen Xiao</author><pubDate>Fri, 21 Jul 2023 14:26:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.18453v2</guid></item><item><title>CortexMorph: fast cortical thickness estimation via diffeomorphic registration using VoxelMorph</title><link>http://arxiv.org/abs/2307.11567v1</link><description>The thickness of the cortical band is linked to various neurological andpsychiatric conditions, and is often estimated through surface-based methodssuch as Freesurfer in MRI studies. The DiReCT method, which calculates corticalthickness using a diffeomorphic deformation of the gray-white matter interfacetowards the pial surface, offers an alternative to surface-based methods.Recent studies using a synthetic cortical thickness phantom have demonstratedthat the combination of DiReCT and deep-learning-based segmentation is moresensitive to subvoxel cortical thinning than Freesurfer. While anatomical segmentation of a T1-weighted image now takes seconds,existing implementations of DiReCT rely on iterative image registration methodswhich can take up to an hour per volume. On the other hand, learning-baseddeformable image registration methods like VoxelMorph have been shown to befaster than classical methods while improving registration accuracy. This paperproposes CortexMorph, a new method that employs unsupervised deep learning todirectly regress the deformation field needed for DiReCT. By combiningCortexMorph with a deep-learning-based segmentation model, it is possible toestimate region-wise thickness in seconds from a T1-weighted image, whilemaintaining the ability to detect cortical atrophy. We validate this claim onthe OASIS-3 dataset and the synthetic cortical thickness phantom of Rusak etal.</description><author>Richard McKinley, Christian Rummel</author><pubDate>Fri, 21 Jul 2023 14:18:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11567v1</guid></item><item><title>FMT: Removing Backdoor Feature Maps via Feature Map Testing in Deep Neural Networks</title><link>http://arxiv.org/abs/2307.11565v1</link><description>Deep neural networks have been widely used in many critical applications,such as autonomous vehicles and medical diagnosis. However, their security isthreatened by backdoor attack, which is achieved by adding artificial patternsto specific training data. Existing defense strategies primarily focus on usingreverse engineering to reproduce the backdoor trigger generated by attackersand subsequently repair the DNN model by adding the trigger into inputs andfine-tuning the model with ground-truth labels. However, once the triggergenerated by the attackers is complex and invisible, the defender can notsuccessfully reproduce the trigger. Consequently, the DNN model will not berepaired since the trigger is not effectively removed. In this work, we propose Feature Map Testing~(FMT). Different from existingdefense strategies, which focus on reproducing backdoor triggers, FMT tries todetect the backdoor feature maps, which are trained to extract backdoorinformation from the inputs. After detecting these backdoor feature maps, FMTwill erase them and then fine-tune the model with a secure subset of trainingdata. Our experiments demonstrate that, compared to existing defensestrategies, FMT can effectively reduce the Attack Success Rate (ASR) evenagainst the most complex and invisible attack triggers. Second, unlikeconventional defense methods that tend to exhibit low Robust Accuracy (i.e.,the model's accuracy on the poisoned data), FMT achieves higher RA, indicatingits superiority in maintaining model performance while mitigating the effectsof backdoor attacks~(e.g., FMT obtains 87.40\% RA in CIFAR10). Third, comparedto existing feature map pruning techniques, FMT can cover more backdoor featuremaps~(e.g., FMT removes 83.33\% of backdoor feature maps from the model in theCIFAR10 \&amp; BadNet scenario).</description><author>Dong Huang, Qingwen Bu, Yahao Qing, Yichao Fu, Heming Cui</author><pubDate>Fri, 21 Jul 2023 14:17:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11565v1</guid></item><item><title>Feature Map Testing for Deep Neural Networks</title><link>http://arxiv.org/abs/2307.11563v1</link><description>Due to the widespread application of deep neural networks~(DNNs) insafety-critical tasks, deep learning testing has drawn increasing attention.During the testing process, test cases that have been fuzzed or selected usingtest metrics are fed into the model to find fault-inducing test units (e.g.,neurons and feature maps, activating which will almost certainly result in amodel error) and report them to the DNN developer, who subsequently repairthem~(e.g., retraining the model with test cases). Current test metrics,however, are primarily concerned with the neurons, which means that test casesthat are discovered either by guided fuzzing or selection with these metricsfocus on detecting fault-inducing neurons while failing to detectfault-inducing feature maps. In this work, we propose DeepFeature, which tests DNNs from the feature maplevel. When testing is conducted, DeepFeature will scrutinize every internalfeature map in the model and identify vulnerabilities that can be enhancedthrough repairing to increase the model's overall performance. Exhaustiveexperiments are conducted to demonstrate that (1) DeepFeature is a strong toolfor detecting the model's vulnerable feature maps; (2) DeepFeature's test caseselection has a high fault detection rate and can detect more types offaults~(comparing DeepFeature to coverage-guided selection techniques, thefault detection rate is increased by 49.32\%). (3) DeepFeature's fuzzer alsooutperforms current fuzzing techniques and generates valuable test cases moreefficiently.</description><author>Dong Huang, Qingwen Bu, Yahao Qing, Yichao Fu, Heming Cui</author><pubDate>Fri, 21 Jul 2023 14:15:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11563v1</guid></item><item><title>SpArX: Sparse Argumentative Explanations for Neural Networks</title><link>http://arxiv.org/abs/2301.09559v2</link><description>Neural networks (NNs) have various applications in AI, but explaining theirdecisions remains challenging. Existing approaches often focus on explaininghow changing individual inputs affects NNs' outputs. However, an explanationthat is consistent with the input-output behaviour of an NN is not necessarilyfaithful to the actual mechanics thereof. In this paper, we exploitrelationships between multi-layer perceptrons (MLPs) and quantitativeargumentation frameworks (QAFs) to create argumentative explanations for themechanics of MLPs. Our SpArX method first sparsifies the MLP while maintainingas much of the original structure as possible. It then translates the sparseMLP into an equivalent QAF to shed light on the underlying decision process ofthe MLP, producing global and/or local explanations. We demonstrateexperimentally that SpArX can give more faithful explanations than existingapproaches, while simultaneously providing deeper insights into the actualreasoning process of MLPs.</description><author>Hamed Ayoobi, Nico Potyka, Francesca Toni</author><pubDate>Fri, 21 Jul 2023 14:13:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.09559v2</guid></item><item><title>Advancing Visual Grounding with Scene Knowledge: Benchmark and Method</title><link>http://arxiv.org/abs/2307.11558v1</link><description>Visual grounding (VG) aims to establish fine-grained alignment between visionand language. Ideally, it can be a testbed for vision-and-language models toevaluate their understanding of the images and texts and their reasoningabilities over their joint space. However, most existing VG datasets areconstructed using simple description texts, which do not require sufficientreasoning over the images and texts. This has been demonstrated in a recentstudy~\cite{luo2022goes}, where a simple LSTM-based text encoder withoutpretraining can achieve state-of-the-art performance on mainstream VG datasets.Therefore, in this paper, we propose a novel benchmark of \underline{S}cene\underline{K}nowledge-guided \underline{V}isual \underline{G}rounding (SK-VG),where the image content and referring expressions are not sufficient to groundthe target objects, forcing the models to have a reasoning ability on thelong-form scene knowledge. To perform this task, we propose two approaches toaccept the triple-type input, where the former embeds knowledge into the imagefeatures before the image-query interaction; the latter leverages linguisticstructure to assist in computing the image-text matching. We conduct extensiveexperiments to analyze the above methods and show that the proposed approachesachieve promising results but still leave room for improvement, includingperformance and interpretability. The dataset and code are available at\url{https://github.com/zhjohnchan/SK-VG}.</description><author>Zhihong Chen, Ruifei Zhang, Yibing Song, Xiang Wan, Guanbin Li</author><pubDate>Fri, 21 Jul 2023 14:06:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11558v1</guid></item><item><title>CycleIK: Neuro-inspired Inverse Kinematics</title><link>http://arxiv.org/abs/2307.11554v1</link><description>The paper introduces CycleIK, a neuro-robotic approach that wraps two novelneuro-inspired methods for the inverse kinematics (IK) task, a GenerativeAdversarial Network (GAN), and a Multi-Layer Perceptron architecture. Thesemethods can be used in a standalone fashion, but we also show how embeddingthese into a hybrid neuro-genetic IK pipeline allows for further optimizationvia sequential least-squares programming (SLSQP) or a genetic algorithm (GA).The models are trained and tested on dense datasets that were collected fromrandom robot configurations of the new Neuro-Inspired COLlaborator (NICOL), asemi-humanoid robot with two redundant 8-DoF manipulators. We utilize theweighted multi-objective function from the state-of-the-art BioIK method tosupport the training process and our hybrid neuro-genetic architecture. We showthat the neural models can compete with state-of-the-art IK approaches, whichallows for deployment directly to robotic hardware. Additionally, it is shownthat the incorporation of the genetic algorithm improves the precision whilesimultaneously reducing the overall runtime.</description><author>Jan-Gerrit Habekost, Erik Strahl, Philipp Allgeuer, Matthias Kerzel, Stefan Wermter</author><pubDate>Fri, 21 Jul 2023 14:03:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11554v1</guid></item><item><title>A multi-modal representation of El Niño Southern Oscillation Diversity</title><link>http://arxiv.org/abs/2307.11552v1</link><description>The El Ni\~no-Southern Oscillation (ENSO) is characterized by alternatingperiods of warm (El Ni\~no) and cold (La Ni\~na) sea surface temperatureanomalies (SSTA) in the equatorial Pacific. Although El Ni\~no and La Ni\~naare well-defined climate patterns, no two events are alike. To date, ENSOdiversity has been described primarily in terms of the longitudinal location ofpeak SSTA, used to define a bimodal classification of events in Eastern Pacific(EP) and Central Pacific (CP) types. Here, we use low-dimensionalrepresentations of Pacific SSTAs to argue that binary categorical membershipsare unsuitable to describe ENSO events. Using fuzzy unsupervised clustering, werecover the four known ENSO categories, along with a fifth category: an ExtremeEl Ni\~no. We show that Extreme El Ni\~nos differ both in their intensity andtemporal evolution from canonical EP El Ni\~nos. We also find that CP LaNi\~nas, EP El Ni\~nos, and Extreme El Ni\~nos contribute the most tointerdecadal ENSO variability.</description><author>Jakob Schlör, Felix Strnad, Antonietta Capotondi, Bedartha Goswami</author><pubDate>Fri, 21 Jul 2023 13:58:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11552v1</guid></item><item><title>YOLOPose V2: Understanding and Improving Transformer-based 6D Pose Estimation</title><link>http://arxiv.org/abs/2307.11550v1</link><description>6D object pose estimation is a crucial prerequisite for autonomous robotmanipulation applications. The state-of-the-art models for pose estimation areconvolutional neural network (CNN)-based. Lately, Transformers, an architectureoriginally proposed for natural language processing, is achievingstate-of-the-art results in many computer vision tasks as well. Equipped withthe multi-head self-attention mechanism, Transformers enable simplesingle-stage end-to-end architectures for learning object detection and 6Dobject pose estimation jointly. In this work, we propose YOLOPose (short formfor You Only Look Once Pose estimation), a Transformer-based multi-object 6Dpose estimation method based on keypoint regression and an improved variant ofthe YOLOPose model. In contrast to the standard heatmaps for predictingkeypoints in an image, we directly regress the keypoints. Additionally, weemploy a learnable orientation estimation module to predict the orientationfrom the keypoints. Along with a separate translation estimation module, ourmodel is end-to-end differentiable. Our method is suitable for real-timeapplications and achieves results comparable to state-of-the-art methods. Weanalyze the role of object queries in our architecture and reveal that theobject queries specialize in detecting objects in specific image regions.Furthermore, we quantify the accuracy trade-off of using datasets of smallersizes to train our model.</description><author>Arul Selvam Periyasamy, Arash Amini, Vladimir Tsaturyan, Sven Behnke</author><pubDate>Fri, 21 Jul 2023 13:53:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11550v1</guid></item><item><title>Towards practical reinforcement learning for tokamak magnetic control</title><link>http://arxiv.org/abs/2307.11546v1</link><description>Reinforcement learning (RL) has shown promising results for real-time controlsystems, including the domain of plasma magnetic control. However, there arestill significant drawbacks compared to traditional feedback control approachesfor magnetic confinement. In this work, we address key drawbacks of the RLmethod; achieving higher control accuracy for desired plasma properties,reducing the steady-state error, and decreasing the required time to learn newtasks. We build on top of \cite{degrave2022magnetic}, and present algorithmicimprovements to the agent architecture and training procedure. We presentsimulation results that show up to 65\% improvement in shape accuracy, achievesubstantial reduction in the long-term bias of the plasma current, andadditionally reduce the training time required to learn new tasks by a factorof 3 or more. We present new experiments using the upgraded RL-basedcontrollers on the TCV tokamak, which validate the simulation results achieved,and point the way towards routinely achieving accurate discharges using the RLapproach.</description><author>Brendan D. Tracey, Andrea Michi, Yuri Chervonyi, Ian Davies, Cosmin Paduraru, Nevena Lazic, Federico Felici, Timo Ewalds, Craig Donner, Cristian Galperti, Jonas Buchli, Michael Neunert, Andrea Huber, Jonathan Evens, Paula Kurylowicz, Daniel J. Mankowitz, Martin Riedmiller, The TCV Team</author><pubDate>Fri, 21 Jul 2023 13:47:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11546v1</guid></item><item><title>Bridging Vision and Language Encoders: Parameter-Efficient Tuning for Referring Image Segmentation</title><link>http://arxiv.org/abs/2307.11545v1</link><description>Parameter Efficient Tuning (PET) has gained attention for reducing the numberof parameters while maintaining performance and providing better hardwareresource savings, but few studies investigate dense prediction tasks andinteraction between modalities. In this paper, we do an investigation ofefficient tuning problems on referring image segmentation. We propose a noveladapter called Bridger to facilitate cross-modal information exchange andinject task-specific information into the pre-trained model. We also design alightweight decoder for image segmentation. Our approach achieves comparable orsuperior performance with only 1.61\% to 3.38\% backbone parameter updates,evaluated on challenging benchmarks. The code is available at\url{https://github.com/kkakkkka/ETRIS}.</description><author>Zunnan Xu, Zhihong Chen, Yong Zhang, Yibing Song, Xiang Wan, Guanbin Li</author><pubDate>Fri, 21 Jul 2023 13:46:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11545v1</guid></item><item><title>Identifying Relevant Features of CSE-CIC-IDS2018 Dataset for the Development of an Intrusion Detection System</title><link>http://arxiv.org/abs/2307.11544v1</link><description>Intrusion detection systems (IDSs) are essential elements of IT systems.Their key component is a classification module that continuously evaluates somefeatures of the network traffic and identifies possible threats. Its efficiencyis greatly affected by the right selection of the features to be monitored.Therefore, the identification of a minimal set of features that are necessaryto safely distinguish malicious traffic from benign traffic is indispensable inthe course of the development of an IDS. This paper presents the preprocessingand feature selection workflow as well as its results in the case of theCSE-CIC-IDS2018 on AWS dataset, focusing on five attack types. To identify therelevant features, six feature selection methods were applied, and the finalranking of the features was elaborated based on their average score. Next,several subsets of the features were formed based on different rankingthreshold values, and each subset was tried with five classification algorithmsto determine the optimal feature set for each attack type. During theevaluation, four widely used metrics were taken into consideration.</description><author>László Göcs, Zsolt Csaba Johanyák</author><pubDate>Fri, 21 Jul 2023 13:45:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11544v1</guid></item><item><title>Learning Foresightful Dense Visual Affordance for Deformable Object Manipulation</title><link>http://arxiv.org/abs/2303.11057v3</link><description>Understanding and manipulating deformable objects (e.g., ropes and fabrics)is an essential yet challenging task with broad applications. Difficulties comefrom complex states and dynamics, diverse configurations and high-dimensionalaction space of deformable objects. Besides, the manipulation tasks usuallyrequire multiple steps to accomplish, and greedy policies may easily lead tolocal optimal states. Existing studies usually tackle this problem usingreinforcement learning or imitating expert demonstrations, with limitations inmodeling complex states or requiring hand-crafted expert policies. In thispaper, we study deformable object manipulation using dense visual affordance,with generalization towards diverse states, and propose a novel kind offoresightful dense affordance, which avoids local optima by estimating states'values for long-term manipulation. We propose a framework for learning thisrepresentation, with novel designs such as multi-stage stable learning andefficient self-supervised data collection without experts. Experimentsdemonstrate the superiority of our proposed foresightful dense affordance.Project page: https://hyperplane-lab.github.io/DeformableAffordance</description><author>Ruihai Wu, Chuanruo Ning, Hao Dong</author><pubDate>Fri, 21 Jul 2023 13:43:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11057v3</guid></item><item><title>KVN: Keypoints Voting Network with Differentiable RANSAC for Stereo Pose Estimation</title><link>http://arxiv.org/abs/2307.11543v1</link><description>Object pose estimation is a fundamental computer vision task exploited inseveral robotics and augmented reality applications. Many establishedapproaches rely on predicting 2D-3D keypoint correspondences using RANSAC(Random sample consensus) and estimating the object pose using the PnP(Perspective-n-Point) algorithm. Being RANSAC non-differentiable,correspondences cannot be directly learned in an end-to-end fashion. In thispaper, we address the stereo image-based object pose estimation problem by (i)introducing a differentiable RANSAC layer into a well-known monocular poseestimation network; (ii) exploiting an uncertainty-driven multi-view PnP solverwhich can fuse information from multiple views. We evaluate our approach on achallenging public stereo object pose estimation dataset, yieldingstate-of-the-art results against other recent approaches. Furthermore, in ourablation study, we show that the differentiable RANSAC layer plays asignificant role in the accuracy of the proposed method. We release with thispaper the open-source implementation of our method.</description><author>Ivano Donadi, Alberto Pretto</author><pubDate>Fri, 21 Jul 2023 13:43:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11543v1</guid></item><item><title>Training Latency Minimization for Model-Splitting Allowed Federated Edge Learning</title><link>http://arxiv.org/abs/2307.11532v1</link><description>To alleviate the shortage of computing power faced by clients in trainingdeep neural networks (DNNs) using federated learning (FL), we leverage the edgecomputing and split learning to propose a model-splitting allowed FL (SFL)framework, with the aim to minimize the training latency without loss of testaccuracy. Under the synchronized global update setting, the latency to completea round of global training is determined by the maximum latency for the clientsto complete a local training session. Therefore, the training latencyminimization problem (TLMP) is modelled as a minimizing-maximum problem. Tosolve this mixed integer nonlinear programming problem, we first propose aregression method to fit the quantitative-relationship between the cut-layerand other parameters of an AI-model, and thus, transform the TLMP into acontinuous problem. Considering that the two subproblems involved in the TLMP,namely, the cut-layer selection problem for the clients and the computingresource allocation problem for the parameter-server are relative independence,an alternate-optimization-based algorithm with polynomial time complexity isdeveloped to obtain a high-quality solution to the TLMP. Extensive experimentsare performed on a popular DNN-model EfficientNetV2 using dataset MNIST, andthe results verify the validity and improved performance of the proposed SFLframework.</description><author>Yao Wen, Guopeng Zhang, Kezhi Wang, Kun Yang</author><pubDate>Fri, 21 Jul 2023 13:26:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11532v1</guid></item><item><title>UWAT-GAN: Fundus Fluorescein Angiography Synthesis via Ultra-wide-angle Transformation Multi-scale GAN</title><link>http://arxiv.org/abs/2307.11530v1</link><description>Fundus photography is an essential examination for clinical and differentialdiagnosis of fundus diseases. Recently, Ultra-Wide-angle Fundus (UWF)techniques, UWF Fluorescein Angiography (UWF-FA) and UWF Scanning LaserOphthalmoscopy (UWF-SLO) have been gradually put into use. However, FluoresceinAngiography (FA) and UWF-FA require injecting sodium fluorescein which may havedetrimental influences. To avoid negative impacts, cross-modality medical imagegeneration algorithms have been proposed. Nevertheless, current methods infundus imaging could not produce high-resolution images and are unable tocapture tiny vascular lesion areas. This paper proposes a novel conditionalgenerative adversarial network (UWAT-GAN) to synthesize UWF-FA from UWF-SLO.Using multi-scale generators and a fusion module patch to better extract globaland local information, our model can generate high-resolution images. Moreover,an attention transmit module is proposed to help the decoder learn effectively.Besides, a supervised approach is used to train the network using multiple newweighted losses on different scales of data. Experiments on an in-house UWFimage dataset demonstrate the superiority of the UWAT-GAN over thestate-of-the-art methods. The source code is available at:https://github.com/Tinysqua/UWAT-GAN.</description><author>Zhaojie Fang, Zhanghao Chen, Pengxue Wei, Wangting Li, Shaochong Zhang, Ahmed Elazab, Gangyong Jia, Ruiquan Ge, Changmiao Wang</author><pubDate>Fri, 21 Jul 2023 13:23:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11530v1</guid></item><item><title>Improving Viewpoint Robustness for Visual Recognition via Adversarial Training</title><link>http://arxiv.org/abs/2307.11528v1</link><description>Viewpoint invariance remains challenging for visual recognition in the 3Dworld, as altering the viewing directions can significantly impact predictionsfor the same object. While substantial efforts have been dedicated to makingneural networks invariant to 2D image translations and rotations, viewpointinvariance is rarely investigated. Motivated by the success of adversarialtraining in enhancing model robustness, we propose Viewpoint-InvariantAdversarial Training (VIAT) to improve the viewpoint robustness of imageclassifiers. Regarding viewpoint transformation as an attack, we formulate VIATas a minimax optimization problem, where the inner maximization characterizesdiverse adversarial viewpoints by learning a Gaussian mixture distributionbased on the proposed attack method GMVFool. The outer minimization obtains aviewpoint-invariant classifier by minimizing the expected loss over theworst-case viewpoint distributions that can share the same one for differentobjects within the same category. Based on GMVFool, we contribute a large-scaledataset called ImageNet-V+ to benchmark viewpoint robustness. Experimentalresults show that VIAT significantly improves the viewpoint robustness ofvarious image classifiers based on the diversity of adversarial viewpointsgenerated by GMVFool. Furthermore, we propose ViewRS, a certified viewpointrobustness method that provides a certified radius and accuracy to demonstratethe effectiveness of VIAT from the theoretical perspective.</description><author>Shouwei Ruan, Yinpeng Dong, Hang Su, Jianteng Peng, Ning Chen, Xingxing Wei</author><pubDate>Fri, 21 Jul 2023 13:18:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11528v1</guid></item><item><title>Reduction of finite sampling noise in quantum neural networks</title><link>http://arxiv.org/abs/2306.01639v2</link><description>Quantum neural networks (QNNs) use parameterized quantum circuits withdata-dependent inputs and generate outputs through the evaluation ofexpectation values. Calculating these expectation values necessitates repeatedcircuit evaluations, thus introducing fundamental finite-sampling noise even onerror-free quantum computers. We reduce this noise by introducing the varianceregularization, a technique for reducing the variance of the expectation valueduring the quantum model training. This technique requires no additionalcircuit evaluations if the QNN is properly constructed. Our empirical findingsdemonstrate the reduced variance speeds up the training and lowers the outputnoise as well as decreases the number of necessary evaluations of gradientcircuits. This regularization method is benchmarked on the regression ofmultiple functions. We show that in our examples, it lowers the variance by anorder of magnitude on average and leads to a significantly reduced noise levelof the QNN. We finally demonstrate QNN training on a real quantum device andevaluate the impact of error mitigation. Here, the optimization is feasibleonly due to the reduced number of necessary shots in the gradient evaluationresulting from the reduced variance.</description><author>David A. Kreplin, Marco Roth</author><pubDate>Fri, 21 Jul 2023 13:16:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01639v2</guid></item><item><title>BoxSnake: Polygonal Instance Segmentation with Box Supervision</title><link>http://arxiv.org/abs/2303.11630v2</link><description>Box-supervised instance segmentation has gained much attention as it requiresonly simple box annotations instead of costly mask or polygon annotations.However, existing box-supervised instance segmentation models mainly focus onmask-based frameworks. We propose a new end-to-end training technique, termedBoxSnake, to achieve effective polygonal instance segmentation using only boxannotations for the first time. Our method consists of two loss functions: (1)a point-based unary loss that constrains the bounding box of predicted polygonsto achieve coarse-grained segmentation; and (2) a distance-aware pairwise lossthat encourages the predicted polygons to fit the object boundaries. Comparedwith the mask-based weakly-supervised methods, BoxSnake further reduces theperformance gap between the predicted segmentation and the bounding box, andshows significant superiority on the Cityscapes dataset.</description><author>Rui Yang, Lin Song, Yixiao Ge, Xiu Li</author><pubDate>Fri, 21 Jul 2023 13:15:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.11630v2</guid></item><item><title>Transformer-based end-to-end classification of variable-length volumetric data</title><link>http://arxiv.org/abs/2307.06666v2</link><description>The automatic classification of 3D medical data is memory-intensive. Also,variations in the number of slices between samples is common. Na\"ive solutionssuch as subsampling can solve these problems, but at the cost of potentiallyeliminating relevant diagnosis information. Transformers have shown promisingperformance for sequential data analysis. However, their application for longsequences is data, computationally, and memory demanding. In this paper, wepropose an end-to-end Transformer-based framework that allows to classifyvolumetric data of variable length in an efficient fashion. Particularly, byrandomizing the input volume-wise resolution(#slices) during training, weenhance the capacity of the learnable positional embedding assigned to eachvolume slice. Consequently, the accumulated positional information in eachpositional embedding can be generalized to the neighbouring slices, even forhigh-resolution volumes at the test time. By doing so, the model will be morerobust to variable volume length and amenable to different computationalbudgets. We evaluated the proposed approach in retinal OCT volumeclassification and achieved 21.96% average improvement in balanced accuracy ona 9-class diagnostic task, compared to state-of-the-art video transformers. Ourfindings show that varying the volume-wise resolution of the input duringtraining results in more informative volume representation as compared totraining with fixed number of slices per volume.</description><author>Marzieh Oghbaie, Teresa Araujo, Taha Emre, Ursula Schmidt-Erfurth, Hrvoje Bogunovic</author><pubDate>Fri, 21 Jul 2023 13:15:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.06666v2</guid></item><item><title>CopyRNeRF: Protecting the CopyRight of Neural Radiance Fields</title><link>http://arxiv.org/abs/2307.11526v1</link><description>Neural Radiance Fields (NeRF) have the potential to be a major representationof media. Since training a NeRF has never been an easy task, the protection ofits model copyright should be a priority. In this paper, by analyzing the prosand cons of possible copyright protection solutions, we propose to protect thecopyright of NeRF models by replacing the original color representation in NeRFwith a watermarked color representation. Then, a distortion-resistant renderingscheme is designed to guarantee robust message extraction in 2D renderings ofNeRF. Our proposed method can directly protect the copyright of NeRF modelswhile maintaining high rendering quality and bit accuracy when compared amongoptional solutions.</description><author>Ziyuan Luo, Qing Guo, Ka Chun Cheung, Simon See, Renjie Wan</author><pubDate>Fri, 21 Jul 2023 13:14:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11526v1</guid></item><item><title>Model Reporting for Certifiable AI: A Proposal from Merging EU Regulation into AI Development</title><link>http://arxiv.org/abs/2307.11525v1</link><description>Despite large progress in Explainable and Safe AI, practitioners suffer froma lack of regulation and standards for AI safety. In this work we merge recentregulation efforts by the European Union and first proposals for AI guidelineswith recent trends in research: data and model cards. We propose the use ofstandardized cards to document AI applications throughout the developmentprocess. Our main contribution is the introduction of use-case and operationcards, along with updates for data and model cards to cope with regulatoryrequirements. We reference both recent research as well as the source of theregulation in our cards and provide references to additional support materialand toolboxes whenever possible. The goal is to design cards that helppractitioners develop safe AI systems throughout the development process, whileenabling efficient third-party auditing of AI applications, being easy tounderstand, and building trust in the system. Our work incorporates insightsfrom interviews with certification experts as well as developers andindividuals working with the developed AI applications.</description><author>Danilo Brajovic, Niclas Renner, Vincent Philipp Goebels, Philipp Wagner, Benjamin Fresz, Martin Biller, Mara Klaeb, Janika Kutz, Jens Neuhuettler, Marco F. Huber</author><pubDate>Fri, 21 Jul 2023 13:13:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11525v1</guid></item><item><title>VERITE: A Robust Benchmark for Multimodal Misinformation Detection Accounting for Unimodal Bias</title><link>http://arxiv.org/abs/2304.14133v2</link><description>Multimedia content has become ubiquitous on social media platforms, leadingto the rise of multimodal misinformation (MM) and the urgent need for effectivestrategies to detect and prevent its spread. In recent years, the challenge ofmultimodal misinformation detection (MMD) has garnered significant attention byresearchers and has mainly involved the creation of annotated, weaklyannotated, or synthetically generated training datasets, along with thedevelopment of various deep learning MMD models. However, the problem ofunimodal bias in MMD benchmarks -- where biased or unimodal methods outperformtheir multimodal counterparts on an inherently multimodal task -- has beenoverlooked. In this study, we systematically investigate and identify thepresence of unimodal bias in widely-used MMD benchmarks (VMU-Twitter, COSMOS),raising concerns about their suitability for reliable evaluation. To addressthis issue, we introduce the "VERification of Image-TExtpairs" (VERITE)benchmark for MMD which incorporates real-world data, excludes "asymmetricmultimodal misinformation" and utilizes "modality balancing". We conduct anextensive comparative study with a Transformer-based architecture that showsthe ability of VERITE to effectively address unimodal bias, rendering it arobust evaluation framework for MMD. Furthermore, we introduce a new method --termed Crossmodal HArd Synthetic MisAlignment (CHASMA) -- for generatingrealistic synthetic training data that preserve crossmodal relations betweenlegitimate images and false human-written captions. By leveraging CHASMA in thetraining process, we observe consistent and notable improvements in predictiveperformance on VERITE; with a 9.2% increase in accuracy. We release our codeat: https://github.com/stevejpapad/image-text-verification</description><author>Stefanos-Iordanis Papadopoulos, Christos Koutlis, Symeon Papadopoulos, Panagiotis C. Petrantonakis</author><pubDate>Fri, 21 Jul 2023 13:06:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14133v2</guid></item><item><title>BatMobility: Towards Flying Without Seeing for Autonomous Drones</title><link>http://arxiv.org/abs/2307.11518v1</link><description>Unmanned aerial vehicles (UAVs) rely on optical sensors such as cameras andlidar for autonomous operation. However, such optical sensors are error-pronein bad lighting, inclement weather conditions including fog and smoke, andaround textureless or transparent surfaces. In this paper, we ask: is itpossible to fly UAVs without relying on optical sensors, i.e., can UAVs flywithout seeing? We present BatMobility, a lightweight mmWave radar-onlyperception system for UAVs that eliminates the need for optical sensors.BatMobility enables two core functionalities for UAVs -- radio flow estimation(a novel FMCW radar-based alternative for optical flow based onsurface-parallel doppler shift) and radar-based collision avoidance. We buildBatMobility using commodity sensors and deploy it as a real-time system on asmall off-the-shelf quadcopter running an unmodified flight controller. Ourevaluation shows that BatMobility achieves comparable or better performancethan commercial-grade optical sensors across a wide range of scenarios.</description><author>Emerson Sie, Zikun Liu, Deepak Vasisht</author><pubDate>Fri, 21 Jul 2023 13:03:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11518v1</guid></item><item><title>IndigoVX: Where Human Intelligence Meets AI for Optimal Decision Making</title><link>http://arxiv.org/abs/2307.11516v1</link><description>This paper defines a new approach for augmenting human intelligence with AIfor optimal goal solving. Our proposed AI, Indigo, is an acronym for InformedNumerical Decision-making through Iterative Goal-Oriented optimization. Whencombined with a human collaborator, we term the joint system IndigoVX, forVirtual eXpert. The system is conceptually simple. We envisage this methodbeing applied to games or business strategies, with the human providingstrategic context and the AI offering optimal, data-driven moves. Indigooperates through an iterative feedback loop, harnessing the human expert'scontextual knowledge and the AI's data-driven insights to craft and refinestrategies towards a well-defined goal. Using a quantified three-score schema,this hybridization allows the combined team to evaluate strategies and refinetheir plan, while adapting to challenges and changes in real-time.</description><author>Kais Dukes</author><pubDate>Fri, 21 Jul 2023 12:54:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11516v1</guid></item><item><title>Self-Supervised Hyperspectral Inpainting with the Optimisation inspired Deep Neural Network Prior</title><link>http://arxiv.org/abs/2306.07308v3</link><description>Hyperspectral Image (HSI)s cover hundreds or thousands of narrow spectralbands, conveying a wealth of spatial and spectral information. However, due tothe instrumental errors and the atmospheric changes, the HSI obtained inpractice are often contaminated by noise and dead pixels(lines), resulting inmissing information that may severely compromise the subsequent applications.We introduce here a novel HSI missing pixel prediction algorithm, called LowRank and Sparsity Constraint Plug-and-Play (LRS-PnP). It is shown that LRS-PnPis able to predict missing pixels and bands even when all spectral bands of theimage are missing. The proposed LRS-PnP algorithm is further extended to aself-supervised model by combining the LRS-PnP with the Deep Image Prior (DIP),called LRS-PnP-DIP. In a series of experiments with real data, It is shown thatthe LRS-PnP-DIP either achieves state-of-the-art inpainting performancecompared to other learning-based methods, or outperforms them.</description><author>Shuo Li, Mehrdad Yaghoobi</author><pubDate>Fri, 21 Jul 2023 12:52:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07308v3</guid></item><item><title>Semantic Self-adaptation: Enhancing Generalization with a Single Sample</title><link>http://arxiv.org/abs/2208.05788v2</link><description>The lack of out-of-domain generalization is a critical weakness of deepnetworks for semantic segmentation. Previous studies relied on the assumptionof a static model, i. e., once the training process is complete, modelparameters remain fixed at test time. In this work, we challenge this premisewith a self-adaptive approach for semantic segmentation that adjusts theinference process to each input sample. Self-adaptation operates on two levels.First, it fine-tunes the parameters of convolutional layers to the input imageusing consistency regularization. Second, in Batch Normalization layers,self-adaptation interpolates between the training and the referencedistribution derived from a single test sample. Despite both techniques beingwell known in the literature, their combination sets new state-of-the-artaccuracy on synthetic-to-real generalization benchmarks. Our empirical studysuggests that self-adaptation may complement the established practice of modelregularization at training time for improving deep network generalization toout-of-domain data. Our code and pre-trained models are available athttps://github.com/visinf/self-adaptive.</description><author>Sherwin Bahmani, Oliver Hahn, Eduard Zamfir, Nikita Araslanov, Daniel Cremers, Stefan Roth</author><pubDate>Fri, 21 Jul 2023 12:50:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.05788v2</guid></item><item><title>CORE: Cooperative Reconstruction for Multi-Agent Perception</title><link>http://arxiv.org/abs/2307.11514v1</link><description>This paper presents CORE, a conceptually simple, effective andcommunication-efficient model for multi-agent cooperative perception. Itaddresses the task from a novel perspective of cooperative reconstruction,based on two key insights: 1) cooperating agents together provide a moreholistic observation of the environment, and 2) the holistic observation canserve as valuable supervision to explicitly guide the model learning how toreconstruct the ideal observation based on collaboration. CORE instantiates theidea with three major components: a compressor for each agent to create morecompact feature representation for efficient broadcasting, a lightweightattentive collaboration component for cross-agent message aggregation, and areconstruction module to reconstruct the observation based on aggregatedfeature representations. This learning-to-reconstruct idea is task-agnostic,and offers clear and reasonable supervision to inspire more effectivecollaboration, eventually promoting perception tasks. We validate CORE onOPV2V, a large-scale multi-agent percetion dataset, in two tasks, i.e., 3Dobject detection and semantic segmentation. Results demonstrate that the modelachieves state-of-the-art performance on both tasks, and is morecommunication-efficient.</description><author>Binglu Wang, Lei Zhang, Zhaozhong Wang, Yongqiang Zhao, Tianfei Zhou</author><pubDate>Fri, 21 Jul 2023 12:50:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11514v1</guid></item><item><title>Bone mineral density estimation from a plain X-ray image by learning decomposition into projections of bone-segmented computed tomography</title><link>http://arxiv.org/abs/2307.11513v1</link><description>Osteoporosis is a prevalent bone disease that causes fractures in fragilebones, leading to a decline in daily living activities. Dual-energy X-rayabsorptiometry (DXA) and quantitative computed tomography (QCT) are highlyaccurate for diagnosing osteoporosis; however, these modalities require specialequipment and scan protocols. To frequently monitor bone health, low-cost,low-dose, and ubiquitously available diagnostic methods are highly anticipated.In this study, we aim to perform bone mineral density (BMD) estimation from aplain X-ray image for opportunistic screening, which is potentially useful forearly diagnosis. Existing methods have used multi-stage approaches consistingof extraction of the region of interest and simple regression to estimate BMD,which require a large amount of training data. Therefore, we propose anefficient method that learns decomposition into projections of bone-segmentedQCT for BMD estimation under limited datasets. The proposed method achievedhigh accuracy in BMD estimation, where Pearson correlation coefficients of0.880 and 0.920 were observed for DXA-measured BMD and QCT-measured BMDestimation tasks, respectively, and the root mean square of the coefficient ofvariation values were 3.27 to 3.79% for four measurements with different poses.Furthermore, we conducted extensive validation experiments, includingmulti-pose, uncalibrated-CT, and compression experiments toward actualapplication in routine clinical practice.</description><author>Yi Gu, Yoshito Otake, Keisuke Uemura, Mazen Soufi, Masaki Takao, Hugues Talbot, Seiji Okada, Nobuhiko Sugano, Yoshinobu Sato</author><pubDate>Fri, 21 Jul 2023 12:49:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11513v1</guid></item><item><title>Modeling Events and Interactions through Temporal Processes -- A Survey</title><link>http://arxiv.org/abs/2303.06067v2</link><description>In real-world scenario, many phenomena produce a collection of events thatoccur in continuous time. Point Processes provide a natural mathematicalframework for modeling these sequences of events. In this survey, weinvestigate probabilistic models for modeling event sequences through temporalprocesses. We revise the notion of event modeling and provide the mathematicalfoundations that characterize the literature on the topic. We define anontology to categorize the existing approaches in terms of three families:simple, marked, and spatio-temporal point processes. For each family, wesystematically review the existing approaches based based on deep learning.Finally, we analyze the scenarios where the proposed techniques can be used foraddressing prediction and modeling aspects.</description><author>Angelica Liguori, Luciano Caroprese, Marco Minici, Bruno Veloso, Francesco Spinnato, Mirco Nanni, Giuseppe Manco, Joao Gama</author><pubDate>Fri, 21 Jul 2023 12:40:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.06067v2</guid></item><item><title>Learning Neural PDE Solvers with Parameter-Guided Channel Attention</title><link>http://arxiv.org/abs/2304.14118v2</link><description>Scientific Machine Learning (SciML) is concerned with the development oflearned emulators of physical systems governed by partial differentialequations (PDE). In application domains such as weather forecasting, moleculardynamics, and inverse design, ML-based surrogate models are increasingly usedto augment or replace inefficient and often non-differentiable numericalsimulation algorithms. While a number of ML-based methods for approximating thesolutions of PDEs have been proposed in recent years, they typically do notadapt to the parameters of the PDEs, making it difficult to generalize to PDEparameters not seen during training. We propose a Channel Attention mechanismguided by PDE Parameter Embeddings (CAPE) component for neural surrogate modelsand a simple yet effective curriculum learning strategy. The CAPE module can becombined with neural PDE solvers allowing them to adapt to unseen PDEparameters. The curriculum learning strategy provides a seamless transitionbetween teacher-forcing and fully auto-regressive training. We compare CAPE inconjunction with the curriculum learning strategy using a popular PDE benchmarkand obtain consistent and significant improvements over the baseline models.The experiments also show several advantages of CAPE, such as its increasedability to generalize to unseen PDE parameters without large increasesinference time and parameter count.</description><author>Makoto Takamoto, Francesco Alesiani, Mathias Niepert</author><pubDate>Fri, 21 Jul 2023 12:36:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.14118v2</guid></item><item><title>MSKdeX: Musculoskeletal (MSK) decomposition from an X-ray image for fine-grained estimation of lean muscle mass and muscle volume</title><link>http://arxiv.org/abs/2305.19920v2</link><description>Musculoskeletal diseases such as sarcopenia and osteoporosis are majorobstacles to health during aging. Although dual-energy X-ray absorptiometry(DXA) and computed tomography (CT) can be used to evaluate musculoskeletalconditions, frequent monitoring is difficult due to the cost and accessibility(as well as high radiation exposure in the case of CT). We propose a method(named MSKdeX) to estimate fine-grained muscle properties from a plain X-rayimage, a low-cost, low-radiation, and highly accessible imaging modality,through musculoskeletal decomposition leveraging fine-grained segmentation inCT. We train a multi-channel quantitative image translation model to decomposean X-ray image into projections of CT of individual muscles to infer the leanmuscle mass and muscle volume. We propose the object-wise intensity-sum loss, asimple yet surprisingly effective metric invariant to muscle deformation andprojection direction, utilizing information in CT and X-ray images collectedfrom the same patient. While our method is basically an unpaired image-to-imagetranslation, we also exploit the nature of the bone's rigidity, which providesthe paired data through 2D-3D rigid registration, adding strong pixel-wisesupervision in unpaired training. Through the evaluation using a 539-patientdataset, we showed that the proposed method significantly outperformedconventional methods. The average Pearson correlation coefficient between thepredicted and CT-derived ground truth metrics was increased from 0.460 to0.863. We believe our method opened up a new musculoskeletal diagnosis methodand has the potential to be extended to broader applications in multi-channelquantitative image translation tasks. Our source code will be released soon.</description><author>Yi Gu, Yoshito Otake, Keisuke Uemura, Masaki Takao, Mazen Soufi, Yuta Hiasa, Hugues Talbot, Seiji Okata, Nobuhiko Sugano, Yoshinobu Sato</author><pubDate>Fri, 21 Jul 2023 12:27:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.19920v2</guid></item><item><title>Continual Learning for Abdominal Multi-Organ and Tumor Segmentation</title><link>http://arxiv.org/abs/2306.00988v2</link><description>The ability to dynamically extend a model to new data and classes is criticalfor multiple organ and tumor segmentation. However, due to privacy regulations,accessing previous data and annotations can be problematic in the medicaldomain. This poses a significant barrier to preserving the high segmentationaccuracy of the old classes when learning from new classes because of thecatastrophic forgetting problem. In this paper, we first empiricallydemonstrate that simply using high-quality pseudo labels can fairly mitigatethis problem in the setting of organ segmentation. Furthermore, we put forwardan innovative architecture designed specifically for continuous organ and tumorsegmentation, which incurs minimal computational overhead. Our proposed designinvolves replacing the conventional output layer with a suite of lightweight,class-specific heads, thereby offering the flexibility to accommodate newlyemerging classes. These heads enable independent predictions for newlyintroduced and previously learned classes, effectively minimizing the impact ofnew classes on old ones during the course of continual learning. We furtherpropose incorporating Contrastive Language-Image Pretraining (CLIP) embeddingsinto the organ-specific heads. These embeddings encapsulate the semanticinformation of each class, informed by extensive image-text co-training. Theproposed method is evaluated on both in-house and public abdominal CT datasetsunder organ and tumor segmentation tasks. Empirical results suggest that theproposed design improves the segmentation performance of a baseline neuralnetwork on newly-introduced and previously-learned classes along the learningtrajectory.</description><author>Yixiao Zhang, Xinyi Li, Huimiao Chen, Alan Yuille, Yaoyao Liu, Zongwei Zhou</author><pubDate>Fri, 21 Jul 2023 12:27:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00988v2</guid></item><item><title>Score-Based Generative Models for Medical Image Segmentation using Signed Distance Functions</title><link>http://arxiv.org/abs/2303.05966v2</link><description>Medical image segmentation is a crucial task that relies on the ability toaccurately identify and isolate regions of interest in medical images. Thereby,generative approaches allow to capture the statistical properties ofsegmentation masks that are dependent on the respective structures. In thiswork we propose a conditional score-based generative modeling framework torepresent the signed distance function (SDF) leading to an implicitdistribution of segmentation masks. The advantage of leveraging the SDF is amore natural distortion when compared to that of binary masks. By learning thescore function of the conditional distribution of SDFs we can accurately samplefrom the distribution of segmentation masks, allowing for the evaluation ofstatistical quantities. Thus, this probabilistic representation allows for thegeneration of uncertainty maps represented by the variance, which can aid infurther analysis and enhance the predictive robustness. We qualitatively andquantitatively illustrate competitive performance of the proposed method on apublic nuclei and gland segmentation data set, highlighting its potentialutility in medical image segmentation applications.</description><author>Lea Bogensperger, Dominik Narnhofer, Filip Ilic, Thomas Pock</author><pubDate>Fri, 21 Jul 2023 12:21:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05966v2</guid></item><item><title>General regularization in covariate shift adaptation</title><link>http://arxiv.org/abs/2307.11503v1</link><description>Sample reweighting is one of the most widely used methods for correcting theerror of least squares learning algorithms in reproducing kernel Hilbert spaces(RKHS), that is caused by future data distributions that are different from thetraining data distribution. In practical situations, the sample weights aredetermined by values of the estimated Radon-Nikod\'ym derivative, of the futuredata distribution w.r.t.~the training data distribution. In this work, wereview known error bounds for reweighted kernel regression in RKHS and obtain,by combination, novel results. We show under weak smoothness conditions, thatthe amount of samples, needed to achieve the same order of accuracy as in thestandard supervised learning without differences in data distributions, issmaller than proven by state-of-the-art analyses.</description><author>Duc Hoan Nguyen, Sergei V. Pereverzyev, Werner Zellinger</author><pubDate>Fri, 21 Jul 2023 12:19:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11503v1</guid></item><item><title>Adaptive ResNet Architecture for Distributed Inference in Resource-Constrained IoT Systems</title><link>http://arxiv.org/abs/2307.11499v1</link><description>As deep neural networks continue to expand and become more complex, most edgedevices are unable to handle their extensive processing requirements.Therefore, the concept of distributed inference is essential to distribute theneural network among a cluster of nodes. However, distribution may lead toadditional energy consumption and dependency among devices that suffer fromunstable transmission rates. Unstable transmission rates harm real-timeperformance of IoT devices causing low latency, high energy usage, andpotential failures. Hence, for dynamic systems, it is necessary to have aresilient DNN with an adaptive architecture that can downsize as per theavailable resources. This paper presents an empirical study that identifies theconnections in ResNet that can be dropped without significantly impacting themodel's performance to enable distribution in case of resource shortage. Basedon the results, a multi-objective optimization problem is formulated tominimize latency and maximize accuracy as per available resources. Ourexperiments demonstrate that an adaptive ResNet architecture can reduce shareddata, energy consumption, and latency throughout the distribution whilemaintaining high accuracy.</description><author>Fazeela Mazhar Khan, Emna Baccour, Aiman Erbad, Mounir Hamdi</author><pubDate>Fri, 21 Jul 2023 12:07:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11499v1</guid></item><item><title>Forecasting consumer confidence through semantic network analysis of online news</title><link>http://arxiv.org/abs/2105.04900v2</link><description>This research studies the impact of online news on social and economicconsumer perceptions through semantic network analysis. Using over 1.8 milliononline articles on Italian media covering four years, we calculate the semanticimportance of specific economic-related keywords to see if words appearing inthe articles could anticipate consumers' judgments about the economic situationand the Consumer Confidence Index. We use an innovative approach to analyze bigtextual data, combining methods and tools of text mining and social networkanalysis. Results show a strong predictive power for the judgments about thecurrent households and national situation. Our indicator offers a complementaryapproach to estimating consumer confidence, lessening the limitations oftraditional survey-based methods.</description><author>A. Fronzetti Colladon, F. Grippa, B. Guardabascio, G. Costante, F. Ravazzolo</author><pubDate>Fri, 21 Jul 2023 12:04:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2105.04900v2</guid></item><item><title>Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting</title><link>http://arxiv.org/abs/2307.11494v1</link><description>Diffusion models have achieved state-of-the-art performance in generativemodeling tasks across various domains. Prior works on time series diffusionmodels have primarily focused on developing conditional models tailored tospecific forecasting or imputation tasks. In this work, we explore thepotential of task-agnostic, unconditional diffusion models for several timeseries applications. We propose TSDiff, an unconditionally trained diffusionmodel for time series. Our proposed self-guidance mechanism enablesconditioning TSDiff for downstream tasks during inference, without requiringauxiliary networks or altering the training procedure. We demonstrate theeffectiveness of our method on three different time series tasks: forecasting,refinement, and synthetic data generation. First, we show that TSDiff iscompetitive with several task-specific conditional forecasting methods(predict). Second, we leverage the learned implicit probability density ofTSDiff to iteratively refine the predictions of base forecasters with reducedcomputational overhead over reverse diffusion (refine). Notably, the generativeperformance of the model remains intact -- downstream forecasters trained onsynthetic samples from TSDiff outperform forecasters that are trained onsamples from other state-of-the-art generative time series models, occasionallyeven outperforming models trained on real data (synthesize).</description><author>Marcel Kollovieh, Abdul Fatir Ansari, Michael Bohlke-Schneider, Jasper Zschiegner, Hao Wang, Yuyang Wang</author><pubDate>Fri, 21 Jul 2023 11:56:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11494v1</guid></item><item><title>A New Deep State-Space Analysis Framework for Patient Latent State Estimation and Classification from EHR Time Series Data</title><link>http://arxiv.org/abs/2307.11487v1</link><description>Many diseases, including cancer and chronic conditions, require extendedtreatment periods and long-term strategies. Machine learning and AI researchfocusing on electronic health records (EHRs) have emerged to address this need.Effective treatment strategies involve more than capturing sequential changesin patient test values. It requires an explainable and clinically interpretablemodel by capturing the patient's internal state over time. In this study, we propose the "deep state-space analysis framework," usingtime-series unsupervised learning of EHRs with a deep state-space model. Thisframework enables learning, visualizing, and clustering of temporal changes inpatient latent states related to disease progression. We evaluated our framework using time-series laboratory data from 12,695cancer patients. By estimating latent states, we successfully discover latentstates related to prognosis. By visualization and cluster analysis, thetemporal transition of patient status and test items during state transitionscharacteristic of each anticancer drug were identified. Our framework surpassesexisting methods in capturing interpretable latent space. It can be expected toenhance our comprehension of disease progression from EHRs, aiding treatmentadjustments and prognostic determinations.</description><author>Aya Nakamura, Ryosuke Kojima, Yuji Okamoto, Eiichiro Uchino, Yohei Mineharu, Yohei Harada, Mayumi Kamada, Manabu Muto, Motoko Yanagita, Yasushi Okuno</author><pubDate>Fri, 21 Jul 2023 11:45:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11487v1</guid></item><item><title>Redemption from Range-view for Accurate 3D Object Detection</title><link>http://arxiv.org/abs/2307.11482v1</link><description>Most recent approaches for 3D object detection predominantly rely onpoint-view or bird's-eye view representations, with limited exploration ofrange-view-based methods. The range-view representation suffers from scalevariation and surface texture deficiency, both of which pose significantlimitations for developing corresponding methods. Notably, the surface textureloss problem has been largely ignored by all existing methods, despite itssignificant impact on the accuracy of range-view-based 3D object detection. Inthis study, we propose Redemption from Range-view R-CNN (R2 R-CNN), a novel andaccurate approach that comprehensively explores the range-view representation.Our proposed method addresses scale variation through the HD Meta Kernel, whichcaptures range-view geometry information in multiple scales. Additionally, weintroduce Feature Points Redemption (FPR) to recover the lost 3D surfacetexture information from the range view, and Synchronous-Grid RoI Pooling(S-Grid RoI Pooling), a multi-scaled approach with multiple receptive fieldsfor accurate box refinement. Our R2 R-CNN outperforms existing range-view-basedmethods, achieving state-of-the-art performance on both the KITTI benchmark andthe Waymo Open Dataset. Our study highlights the critical importance ofaddressing the surface texture loss problem for accurate 3D object detection inrange-view-based methods. Codes will be made publicly available.</description><author>Yihan Wang, Qiao Yan</author><pubDate>Fri, 21 Jul 2023 11:36:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11482v1</guid></item><item><title>SA-BEV: Generating Semantic-Aware Bird's-Eye-View Feature for Multi-view 3D Object Detection</title><link>http://arxiv.org/abs/2307.11477v1</link><description>Recently, the pure camera-based Bird's-Eye-View (BEV) perception provides afeasible solution for economical autonomous driving. However, the existingBEV-based multi-view 3D detectors generally transform all image features intoBEV features, without considering the problem that the large proportion ofbackground information may submerge the object information. In this paper, wepropose Semantic-Aware BEV Pooling (SA-BEVPool), which can filter outbackground information according to the semantic segmentation of image featuresand transform image features into semantic-aware BEV features. Accordingly, wepropose BEV-Paste, an effective data augmentation strategy that closely matcheswith semantic-aware BEV feature. In addition, we design a Multi-ScaleCross-Task (MSCT) head, which combines task-specific and cross-task informationto predict depth distribution and semantic segmentation more accurately,further improving the quality of semantic-aware BEV feature. Finally, weintegrate the above modules into a novel multi-view 3D object detectionframework, namely SA-BEV. Experiments on nuScenes show that SA-BEV achievesstate-of-the-art performance. Code has been available athttps://github.com/mengtan00/SA-BEV.git.</description><author>Jinqing Zhang, Yanan Zhang, Qingjie Liu, Yunhong Wang</author><pubDate>Fri, 21 Jul 2023 11:28:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.11477v1</guid></item></channel></rss>