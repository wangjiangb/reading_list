<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 27 Nov 2023 14:00:04 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>SEGIC: Unleashing the Emergent Correspondence for In-Context Segmentation</title><link>http://arxiv.org/abs/2311.14671v1</link><description>In-context segmentation aims at segmenting novel images using a few labeledexample images, termed as "in-context examples", exploring content similaritiesbetween examples and the target. The resulting models can be generalizedseamlessly to novel segmentation tasks, significantly reducing the labeling andtraining costs compared with conventional pipelines. However, in-contextsegmentation is more challenging than classic ones due to its meta-learningnature, requiring the model to learn segmentation rules conditioned on a fewsamples, not just the segmentation. Unlike previous work with ad-hoc ornon-end-to-end designs, we propose SEGIC, an end-to-end segment-in-contextframework built upon a single vision foundation model (VFM). In particular,SEGIC leverages the emergent correspondence within VFM to capture denserelationships between target images and in-context samples. As such,information from in-context samples is then extracted into three types ofinstructions, i.e. geometric, visual, and meta instructions, serving asexplicit conditions for the final mask prediction. SEGIC is a straightforwardyet effective approach that yields state-of-the-art performance on one-shotsegmentation benchmarks. Notably, SEGIC can be easily generalized to diversetasks, including video object segmentation and open-vocabulary segmentation.Code will be available at \url{https://github.com/MengLcool/SEGIC}.</description><author>Lingchen Meng, Shiyi Lan, Hengduo Li, Jose M. Alvarez, Zuxuan Wu, Yu-Gang Jiang</author><pubDate>Fri, 24 Nov 2023 18:59:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14671v1</guid></item><item><title>Differentiable and accelerated spherical harmonic and Wigner transforms</title><link>http://arxiv.org/abs/2311.14670v1</link><description>Many areas of science and engineering encounter data defined on sphericalmanifolds. Modelling and analysis of spherical data often necessitatesspherical harmonic transforms, at high degrees, and increasingly requiresefficient computation of gradients for machine learning or other differentiableprogramming tasks. We develop novel algorithmic structures for accelerated anddifferentiable computation of generalised Fourier transforms on the sphere$\mathbb{S}^2$ and rotation group $\text{SO}(3)$, i.e. spherical harmonic andWigner transforms, respectively. We present a recursive algorithm for thecalculation of Wigner $d$-functions that is both stable to high harmonicdegrees and extremely parallelisable. By tightly coupling this with separablespherical transforms, we obtain algorithms that exhibit an extremelyparallelisable structure that is well-suited for the high throughput computingof modern hardware accelerators (e.g. GPUs). We also develop a hybrid automaticand manual differentiation approach so that gradients can be computedefficiently. Our algorithms are implemented within the JAX differentiableprogramming framework in the S2FFT software code. Numerous samplings of thesphere are supported, including equiangular and HEALPix sampling. Computationalerrors are at the order of machine precision for spherical samplings that admita sampling theorem. When benchmarked against alternative C codes we observe upto a 400-fold acceleration. Furthermore, when distributing over multiple GPUswe achieve very close to optimal linear scaling with increasing number of GPUsdue to the highly parallelised and balanced nature of our algorithms. Providedaccess to sufficiently many GPUs our transforms thus exhibit an unprecedentedeffective linear time complexity.</description><author>Matthew A. Price, Jason D. McEwen</author><pubDate>Fri, 24 Nov 2023 18:59:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14670v1</guid></item><item><title>She had Cobalt Blue Eyes: Prompt Testing to Create Aligned and Sustainable Language Models</title><link>http://arxiv.org/abs/2310.18333v2</link><description>As the use of large language models (LLMs) increases within society, as doesthe risk of their misuse. Appropriate safeguards must be in place to ensure LLMoutputs uphold the ethical standards of society, highlighting the positive rolethat artificial intelligence technologies can have. Recent events indicateethical concerns around conventionally trained LLMs, leading to overall unsafeuser experiences. This motivates our research question: how do we ensure LLMalignment? In this work, we introduce a test suite of unique prompts to fosterthe development of aligned LLMs that are fair, safe, and robust. We show thatprompting LLMs at every step of the development pipeline, including datacuration, pre-training, and fine-tuning, will result in an overall moreresponsible model. Our test suite evaluates outputs from four state-of-the-artlanguage models: GPT-3.5, GPT-4, OPT, and LLaMA-2. The assessment presented inthis paper highlights a gap between societal alignment and the capabilities ofcurrent LLMs. Additionally, implementing a test suite such as ours lowers theenvironmental overhead of making models safe and fair.</description><author>Veronica Chatrath, Oluwanifemi Bamgbose, Shaina Raza</author><pubDate>Fri, 24 Nov 2023 18:58:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.18333v2</guid></item><item><title>Understanding Self-Supervised Features for Learning Unsupervised Instance Segmentation</title><link>http://arxiv.org/abs/2311.14665v1</link><description>Self-supervised learning (SSL) can be used to solve complex visual taskswithout human labels. Self-supervised representations encode useful semanticinformation about images, and as a result, they have already been used fortasks such as unsupervised semantic segmentation. In this paper, we investigateself-supervised representations for instance segmentation without any manualannotations. We find that the features of different SSL methods vary in theirlevel of instance-awareness. In particular, DINO features, which are known tobe excellent semantic descriptors, lack behind MAE features in theirsensitivity for separating instances.</description><author>Paul Engstler, Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina</author><pubDate>Fri, 24 Nov 2023 18:55:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14665v1</guid></item><item><title>Visual Dexterity: In-Hand Reorientation of Novel and Complex Object Shapes</title><link>http://arxiv.org/abs/2211.11744v3</link><description>In-hand object reorientation is necessary for performing many dexterousmanipulation tasks, such as tool use in less structured environments thatremain beyond the reach of current robots. Prior works built reorientationsystems assuming one or many of the following: reorienting only specificobjects with simple shapes, limited range of reorientation, slow or quasistaticmanipulation, simulation-only results, the need for specialized and costlysensor suites, and other constraints which make the system infeasible forreal-world deployment. We present a general object reorientation controllerthat does not make these assumptions. It uses readings from a single commoditydepth camera to dynamically reorient complex and new object shapes by anyrotation in real-time, with the median reorientation time being close to sevenseconds. The controller is trained using reinforcement learning in simulationand evaluated in the real world on new object shapes not used for training,including the most challenging scenario of reorienting objects held in the airby a downward-facing hand that must counteract gravity during reorientation.Our hardware platform only uses open-source components that cost less than fivethousand dollars. Although we demonstrate the ability to overcome assumptionsin prior work, there is ample scope for improving absolute performance. Forinstance, the challenging duck-shaped object not used for training was droppedin 56 percent of the trials. When it was not dropped, our controller reorientedthe object within 0.4 radians (23 degrees) 75 percent of the time. Videos areavailable at: https://taochenshh.github.io/projects/visual-dexterity.</description><author>Tao Chen, Megha Tippur, Siyang Wu, Vikash Kumar, Edward Adelson, Pulkit Agrawal</author><pubDate>Fri, 24 Nov 2023 18:53:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.11744v3</guid></item><item><title>Convergence Analysis for Learning Orthonormal Deep Linear Neural Networks</title><link>http://arxiv.org/abs/2311.14658v1</link><description>Enforcing orthonormal or isometric property for the weight matrices has beenshown to enhance the training of deep neural networks by mitigating gradientexploding/vanishing and increasing the robustness of the learned networks.However, despite its practical performance, the theoretical analysis oforthonormality in neural networks is still lacking; for example, howorthonormality affects the convergence of the training process. In this letter,we aim to bridge this gap by providing convergence analysis for trainingorthonormal deep linear neural networks. Specifically, we show that Riemanniangradient descent with an appropriate initialization converges at a linear ratefor training orthonormal deep linear neural networks with a class of lossfunctions. Unlike existing works that enforce orthonormal weight matrices forall the layers, our approach excludes this requirement for one layer, which iscrucial to establish the convergence guarantee. Our results shed light on howincreasing the number of hidden layers can impact the convergence speed.Experimental results validate our theoretical analysis.</description><author>Zhen Qin, Xuwei Tan, Zhihui Zhu</author><pubDate>Fri, 24 Nov 2023 18:46:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14658v1</guid></item><item><title>Charting New Territories: Exploring the Geographic and Geospatial Capabilities of Multimodal LLMs</title><link>http://arxiv.org/abs/2311.14656v1</link><description>Multimodal large language models (MLLMs) have shown remarkable capabilitiesacross a broad range of tasks but their knowledge and abilities in thegeographic and geospatial domains are yet to be explored, despite potentialwide-ranging benefits to navigation, environmental research, urban development,and disaster response. We conduct a series of experiments exploring variousvision capabilities of MLLMs within these domains, particularly focusing on thefrontier model GPT-4V, and benchmark its performance against open-sourcecounterparts. Our methodology involves challenging these models with asmall-scale geographic benchmark consisting of a suite of visual tasks, testingtheir abilities across a spectrum of complexity. The analysis uncovers not onlywhere such models excel, including instances where they outperform humans, butalso where they falter, providing a balanced view of their capabilities in thegeographic domain. To enable the comparison and evaluation of future models,our benchmark will be publicly released.</description><author>Jonathan Roberts, Timo Lüddecke, Rehan Sheikh, Kai Han, Samuel Albanie</author><pubDate>Fri, 24 Nov 2023 18:46:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14656v1</guid></item><item><title>Multi-Visual-Inertial System: Analysis, Calibration and Estimation</title><link>http://arxiv.org/abs/2308.05303v3</link><description>In this paper, we study state estimation of multi-visual-inertial systems(MVIS) and develop sensor fusion algorithms to optimally fuse an arbitrarynumber of asynchronous inertial measurement units (IMUs) or gyroscopes andglobal and(or) rolling shutter cameras. We are especially interested in thefull calibration of the associated visual-inertial sensors, including the IMUor camera intrinsics and the IMU-IMU(or camera) spatiotemporal extrinsics aswell as the image readout time of rolling-shutter cameras (if used). To thisend, we develop a new analytic combined IMU integration with intrinsics-termedACI3-to preintegrate IMU measurements, which is leveraged to fuse auxiliaryIMUs and(or) gyroscopes alongside a base IMU. We model the multi-inertialmeasurements to include all the necessary inertial intrinsic and IMU-IMUspatiotemporal extrinsic parameters, while leveraging IMU-IMU rigid-bodyconstraints to eliminate the necessity of auxiliary inertial poses and thusreducing computational complexity. By performing observability analysis ofMVIS, we prove that the standard four unobservable directions remain - nomatter how many inertial sensors are used, and also identify, for the firsttime, degenerate motions for IMU-IMU spatiotemporal extrinsics and auxiliaryinertial intrinsics. In addition to the extensive simulations that validate ouranalysis and algorithms, we have built our own MVIS sensor rig and collectedover 25 real-world datasets to experimentally verify the proposed calibrationagainst the state-of-the-art calibration method such as Kalibr. We show thatthe proposed MVIS calibration is able to achieve competing accuracy withimproved convergence and repeatability, which is open sourced to better benefitthe community.</description><author>Yulin Yang, Patrick Geneva, Guoquan Huang</author><pubDate>Fri, 24 Nov 2023 18:43:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.05303v3</guid></item><item><title>CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers</title><link>http://arxiv.org/abs/2305.17455v3</link><description>Recent vision-language models have achieved tremendous progress far beyondwhat we ever expected. However, their computational costs are also dramaticallygrowing with rapid development, especially for the large models. It makes modelacceleration exceedingly critical in a scenario of limited resources. Althoughextensively studied for unimodal models, the acceleration for multimodalmodels, especially the vision-language Transformers, is relativelyunder-explored. To pursue more efficient and accessible vision-languageTransformers, this paper introduces \textbf{Cross}-\textbf{G}uided\textbf{E}nsemble of \textbf{T}okens (\textbf{\emph{CrossGET}}), a universalacceleration framework for vision-language Transformers. This frameworkadaptively combines tokens through real-time, cross-modal guidance, therebyachieving substantial acceleration while keeping high performance.\textit{CrossGET} has two key innovations: 1) \textit{Cross-Guided Matching andEnsemble}. \textit{CrossGET} incorporates cross-modal guided token matching andensemble to exploit cross-modal information effectively, only introducingcross-modal tokens with negligible extra parameters. 2) \textit{Complete-GraphSoft Matching}. In contrast to the existing bipartite soft matching approach,\textit{CrossGET} introduces a complete-graph soft matching policy to achievemore reliable token-matching results while maintaining parallelizability andhigh efficiency. Extensive experiments are conducted on various vision-languagetasks, including image-text retrieval, visual reasoning, image captioning, andvisual question answering. Performance on both classic multimodal architecturesand emerging multimodal LLMs demonstrate the effectiveness and versatility ofthe proposed \textit{CrossGET} framework. The code will be at\url{https://github.com/sdc17/CrossGET}.</description><author>Dachuan Shi, Chaofan Tao, Anyi Rao, Zhendong Yang, Chun Yuan, Jiaqi Wang</author><pubDate>Fri, 24 Nov 2023 18:39:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17455v3</guid></item><item><title>JetLOV: Enhancing Jet Tree Tagging through Neural Network Learning of Optimal LundNet Variables</title><link>http://arxiv.org/abs/2311.14654v1</link><description>Machine learning has played a pivotal role in advancing physics, with deeplearning notably contributing to solving complex classification problems suchas jet tagging in the field of jet physics. In this experiment, we aim toharness the full potential of neural networks while acknowledging that, attimes, we may lose sight of the underlying physics governing these models.Nevertheless, we demonstrate that we can achieve remarkable results obscuringphysics knowledge and relying completely on the model's outcome. We introduceJetLOV, a composite comprising two models: a straightforward multilayerperceptron (MLP) and the well-established LundNet. Our study reveals that wecan attain comparable jet tagging performance without relying on thepre-computed LundNet variables. Instead, we allow the network to autonomouslylearn an entirely new set of variables, devoid of a priori knowledge of theunderlying physics. These findings hold promise, particularly in addressing theissue of model dependence, which can be mitigated through generalization andtraining on diverse data sets.</description><author>Mauricio A. Diaz, Giorgio Cerro, Jacan Chaplais, Srinandan Dasmahapatra, Stefano Moretti</author><pubDate>Fri, 24 Nov 2023 18:38:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14654v1</guid></item><item><title>Data-driven Prior Learning for Bayesian Optimisation</title><link>http://arxiv.org/abs/2311.14653v1</link><description>Transfer learning for Bayesian optimisation has generally assumed a strongsimilarity between optimisation tasks, with at least a subset having similaroptimal inputs. This assumption can reduce computational costs, but it isviolated in a wide range of optimisation problems where transfer learning maynonetheless be useful. We replace this assumption with a weaker one onlyrequiring the shape of the optimisation landscape to be similar, and analysethe recent method Prior Learning for Bayesian Optimisation - PLeBO - in thissetting. By learning priors for the hyperparameters of the Gaussian processsurrogate model we can better approximate the underlying function, especiallyfor few function evaluations. We validate the learned priors and compare to abreadth of transfer learning approaches, using synthetic data and a recent airpollution optimisation problem as benchmarks. We show that PLeBO and priortransfer find good inputs in fewer evaluations.</description><author>Sigrid Passano Hellan, Christopher G. Lucas, Nigel H. Goddard</author><pubDate>Fri, 24 Nov 2023 18:37:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14653v1</guid></item><item><title>One Pass Streaming Algorithm for Super Long Token Attention Approximation in Sublinear Space</title><link>http://arxiv.org/abs/2311.14652v1</link><description>Deploying Large Language Models (LLMs) in streaming applications that involvelong contexts, particularly for extended dialogues and text analysis, is ofparamount importance but presents two significant challenges. Firstly, thememory consumption is substantial during the decoding phase due to the cachingof Key and Value states (KV) of previous tokens. Secondly, attentioncomputation is time-consuming with a time complexity of $O(n^2)$ for thegeneration of each token. In recent OpenAI DevDay (Nov 6, 2023), OpenAIreleased a new model that is able to support a 128K-long document, in ourpaper, we focus on the memory-efficient issue when context length $n$ is muchgreater than 128K ($n \gg 2^d$). Considering a single-layer self-attention withQuery, Key, and Value matrices $Q, K, V \in \mathbb{R}^{n \times d}$, thepolynomial method approximates the attention output $T \in \mathbb{R}^{n \timesd}$. It accomplishes this by constructing $U_1, U_2 \in \mathbb{R}^{n \timest}$ to expedite attention ${\sf Attn}(Q, K, V)$ computation within $n^{1+o(1)}$time executions. Despite this, storing the Key and Value matrices $K, V \in\mathbb{R}^{n \times d}$ still necessitates $O( n d)$ space, leading tosignificant memory usage. In response to these challenges, we introduce a newalgorithm that only reads one pass of the data in streaming fashion. Thismethod employs sublinear space $o(n)$ to store three sketch matrices,alleviating the need for exact $K, V$ storage. Notably, our algorithm exhibitsexceptional memory-efficient performance with super-long tokens. As the tokenlength $n$ increases, our error guarantee diminishes while the memory usageremains nearly constant. This unique attribute underscores the potential of ourtechnique in efficiently handling LLMs in streaming applications.</description><author>Raghav Addanki, Chenyang Li, Zhao Song, Chiwun Yang</author><pubDate>Fri, 24 Nov 2023 18:35:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14652v1</guid></item><item><title>History Filtering in Imperfect Information Games: Algorithms and Complexity</title><link>http://arxiv.org/abs/2311.14651v1</link><description>Historically applied exclusively to perfect information games, depth-limitedsearch with value functions has been key to recent advances in AI for imperfectinformation games. Most prominent approaches with strong theoretical guaranteesrequire subgame decomposition - a process in which a subgame is computed frompublic information and player beliefs. However, subgame decomposition canitself require non-trivial computations, and its tractability depends on theexistence of efficient algorithms for either full enumeration or generation ofthe histories that form the root of the subgame. Despite this, no formalanalysis of the tractability of such computations has been established in priorwork, and application domains have often consisted of games, such as poker, forwhich enumeration is trivial on modern hardware. Applying these ideas to morecomplex domains requires understanding their cost. In this work, we introduce and analyze the computational aspects andtractability of filtering histories for subgame decomposition. We show thatconstructing a single history from the root of the subgame is generallyintractable, and then provide a necessary and sufficient condition forefficient enumeration. We also introduce a novel Markov Chain Monte Carlo-basedgeneration algorithm for trick-taking card games - a domain where enumerationis often prohibitively expensive. Our experiments demonstrate its improvedscalability in the trick-taking card game Oh Hell. These contributions clarifywhen and how depth-limited search via subgame decomposition can be an effectivetool for sequential decision-making in imperfect information settings.</description><author>Christopher Solinas, Douglas Rebstock, Nathan R. Sturtevant, Michael Buro</author><pubDate>Fri, 24 Nov 2023 18:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14651v1</guid></item><item><title>A path-norm toolkit for modern networks: consequences, promises and challenges</title><link>http://arxiv.org/abs/2310.01225v3</link><description>This work introduces the first toolkit around path-norms that is fully ableto encompass general DAG ReLU networks with biases, skip connections and anyoperation based on the extraction of order statistics: max pooling, GroupSortetc. This toolkit notably allows us to establish generalization bounds formodern neural networks that are not only the most widely applicable path-normbased ones, but also recover or beat the sharpest known bounds of this type.These extended path-norms further enjoy the usual benefits of path-norms: easeof computation, invariance under the symmetries of the network, and improvedsharpness on feedforward networks compared to the product of operators' norms,another complexity measure most commonly used. The versatility of the toolkit and its ease of implementation allow us tochallenge the concrete promises of path-norm-based generalization bounds, bynumerically evaluating the sharpest known bounds for ResNets on ImageNet.</description><author>Antoine Gonon, Nicolas Brisebarre, Elisa Riccietti, Rémi Gribonval</author><pubDate>Fri, 24 Nov 2023 18:32:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01225v3</guid></item><item><title>Provably Efficient High-Dimensional Bandit Learning with Batched Feedbacks</title><link>http://arxiv.org/abs/2311.13180v2</link><description>We study high-dimensional multi-armed contextual bandits with batchedfeedback where the $T$ steps of online interactions are divided into $L$batches. In specific, each batch collects data according to a policy thatdepends on previous batches and the rewards are revealed only at the end of thebatch. Such a feedback structure is popular in applications such aspersonalized medicine and online advertisement, where the online data often donot arrive in a fully serial manner. We consider high-dimensional and linearsettings where the reward function of the bandit model admits either a sparseor low-rank structure and ask how small a number of batches are needed for acomparable performance with fully dynamic data in which $L = T$. For thesesettings, we design a provably sample-efficient algorithm which achieves a $\mathcal{\tilde O}(s_0^2 \log^2 T)$ regret in the sparse case and $\mathcal{\tilde O} ( r ^2 \log^2 T)$ regret in the low-rank case, using only $L= \mathcal{O}( \log T)$ batches. Here $s_0$ and $r$ are the sparsity and rankof the reward parameter in sparse and low-rank cases, respectively, and $\mathcal{\tilde O}(\cdot)$ omits logarithmic factors involving the featuredimensions. In other words, our algorithm achieves regret bounds comparable tothose in fully sequential setting with only $\mathcal{O}( \log T)$ batches. Ouralgorithm features a novel batch allocation method that adjusts the batch sizesaccording to the estimation accuracy within each batch and cumulative regret.Furthermore, we also conduct experiments with synthetic and real-world data tovalidate our theory.</description><author>Jianqing Fan, Zhaoran Wang, Zhuoran Yang, Chenlu Ye</author><pubDate>Fri, 24 Nov 2023 18:31:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13180v2</guid></item><item><title>Learning in Deep Factor Graphs with Gaussian Belief Propagation</title><link>http://arxiv.org/abs/2311.14649v1</link><description>We propose an approach to do learning in Gaussian factor graphs. We treat allrelevant quantities (inputs, outputs, parameters, latents) as random variablesin a graphical model, and view both training and prediction as inferenceproblems with different observed nodes. Our experiments show that theseproblems can be efficiently solved with belief propagation (BP), whose updatesare inherently local, presenting exciting opportunities for distributed andasynchronous training. Our approach can be scaled to deep networks and providesa natural means to do continual learning: use the BP-estimated parametermarginals of the current task as parameter priors for the next. On a videodenoising task we demonstrate the benefit of learnable parameters over aclassical factor graph approach and we show encouraging performance of deepfactor graphs for continual image classification on MNIST.</description><author>Seth Nabarro, Mark van der Wilk, Andrew J Davison</author><pubDate>Fri, 24 Nov 2023 18:31:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14649v1</guid></item><item><title>Calibrated Language Models Must Hallucinate</title><link>http://arxiv.org/abs/2311.14648v1</link><description>Recent language models have a mysterious tendency to generate false butplausible-sounding text. Such "hallucinations" are an obstacle to the usabilityof language-based AI systems and can harm people who rely upon their outputs.This work shows shows that there is an inherent statistical reason thatpretrained language models hallucinate certain types of facts, having nothingto do with the transformer LM architecture or data quality. For "arbitrary"facts whose veracity cannot be determined from the training data, we show thathallucination is necessary for language models that satisfy a statisticalcalibration condition appropriate for generative language models. Specifically,if the maximum probability of any fact is bounded, we show that the probabilityof generating a hallucination is close to the fraction of facts that occurexactly once in the training data (a "Good-Turing" estimate), even assumingideal training data without errors. One conclusion is that models pretrained to be sufficiently good predictors(i.e., calibrated) may require post-training to mitigate hallucinations on thetype of arbitrary facts that tend to appear once in the training set. However,our analysis also suggests that there is no statistical reason that pretrainingwill lead to hallucination on facts that tend to appear more than once in thetraining data (like references to publications such as articles and books,whose hallucinations have been particularly notable and problematic) or onsystematic facts (like arithmetic calculations). Therefore, differentarchitectures and learning algorithms may mitigate these latter types ofhallucinations.</description><author>Adam Tauman Kalai, Santosh S. Vempala</author><pubDate>Fri, 24 Nov 2023 18:29:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14648v1</guid></item><item><title>More is Better in Modern Machine Learning: when Infinite Overparameterization is Optimal and Overfitting is Obligatory</title><link>http://arxiv.org/abs/2311.14646v1</link><description>In our era of enormous neural networks, empirical progress has been driven bythe philosophy that more is better. Recent deep learning practice has foundrepeatedly that larger model size, more data, and more computation (resultingin lower training loss) improves performance. In this paper, we givetheoretical backing to these empirical observations by showing that these threeproperties hold in random feature (RF) regression, a class of models equivalentto shallow networks with only the last layer trained. Concretely, we first show that the test risk of RF regression decreasesmonotonically with both the number of features and the number of samples,provided the ridge penalty is tuned optimally. In particular, this implies thatinfinite width RF architectures are preferable to those of any finite width. Wethen proceed to demonstrate that, for a large class of tasks characterized bypowerlaw eigenstructure, training to near-zero training loss is obligatory:near-optimal performance can only be achieved when the training error is muchsmaller than the test error. Grounding our theory in real-world data, we findempirically that standard computer vision tasks with convolutional neuraltangent kernels clearly fall into this class. Taken together, our results tella simple, testable story of the benefits of overparameterization, overfitting,and more data in random feature models.</description><author>James B. Simon, Dhruva Karkada, Nikhil Ghosh, Mikhail Belkin</author><pubDate>Fri, 24 Nov 2023 18:27:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14646v1</guid></item><item><title>A General Framework for User-Guided Bayesian Optimization</title><link>http://arxiv.org/abs/2311.14645v1</link><description>The optimization of expensive-to-evaluate black-box functions is prevalent invarious scientific disciplines. Bayesian optimization is an automatic, generaland sample-efficient method to solve these problems with minimal knowledge ofthe underlying function dynamics. However, the ability of Bayesian optimizationto incorporate prior knowledge or beliefs about the function at hand in orderto accelerate the optimization is limited, which reduces its appeal forknowledgeable practitioners with tight budgets. To allow domain experts tocustomize the optimization routine, we propose ColaBO, the firstBayesian-principled framework for incorporating prior beliefs beyond thetypical kernel structure, such as the likely location of the optimizer or theoptimal value. The generality of ColaBO makes it applicable across differentMonte Carlo acquisition functions and types of user beliefs. We empiricallydemonstrate ColaBO's ability to substantially accelerate optimization when theprior information is accurate, and to retain approximately default performancewhen it is misleading.</description><author>Carl Hvarfner, Frank Hutter, Luigi Nardi</author><pubDate>Fri, 24 Nov 2023 18:27:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14645v1</guid></item><item><title>Continuous football player tracking from discrete broadcast data</title><link>http://arxiv.org/abs/2311.14642v1</link><description>Player tracking data remains out of reach for many professional footballteams as their video feeds are not sufficiently high quality for computervision technologies to be used. To help bridge this gap, we present a methodthat can estimate continuous full-pitch tracking data from discrete data madefrom broadcast footage. Such data could be collected by clubs or players at asimilar cost to event data, which is widely available down to semi-professionallevel. We test our method using open-source tracking data, and include aversion that can be applied to a large set of over 200 games with such discretedata.</description><author>Matthew J. Penn, Christl A. Donnelly, Samir Bhatt</author><pubDate>Fri, 24 Nov 2023 18:16:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14642v1</guid></item><item><title>Neuromorphic Intermediate Representation: A Unified Instruction Set for Interoperable Brain-Inspired Computing</title><link>http://arxiv.org/abs/2311.14641v1</link><description>Spiking neural networks and neuromorphic hardware platforms that emulateneural dynamics are slowly gaining momentum and entering main-stream usage.Despite a well-established mathematical foundation for neural dynamics, theimplementation details vary greatly across different platforms.Correspondingly, there are a plethora of software and hardware implementationswith their own unique technology stacks. Consequently, neuromorphic systemstypically diverge from the expected computational model, which challenges thereproducibility and reliability across platforms. Additionally, mostneuromorphic hardware is limited by its access via a single software frameworkswith a limited set of training procedures. Here, we establish a commonreference-frame for computations in neuromorphic systems, dubbed theNeuromorphic Intermediate Representation (NIR). NIR defines a set ofcomputational primitives as idealized continuous-time hybrid systems that canbe composed into graphs and mapped to and from various neuromorphic technologystacks. By abstracting away assumptions around discretization and hardwareconstraints, NIR faithfully captures the fundamental computation, whilesimultaneously exposing the exact differences between the evaluatedimplementation and the idealized mathematical formalism. We reproduce three NIRgraphs across 7 neuromorphic simulators and 4 hardware platforms, demonstratingsupport for an unprecedented number of neuromorphic systems. With NIR, wedecouple the evolution of neuromorphic hardware and software, ultimatelyincreasing the interoperability between platforms and improving accessibilityto neuromorphic technologies. We believe that NIR is an important step towardsthe continued study of brain-inspired hardware and bottom-up approaches aimedat an improved understanding of the computational underpinnings of nervoussystems.</description><author>Jens E. Pedersen, Steven Abreu, Matthias Jobst, Gregor Lenz, Vittorio Fra, Felix C. Bauer, Dylan R. Muir, Peng Zhou, Bernhard Vogginger, Kade Heckel, Gianvito Urgese, Sadasivan Shankar, Terrence C. Stewart, Jason K. Eshraghian, Sadique Sheik</author><pubDate>Fri, 24 Nov 2023 18:15:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14641v1</guid></item><item><title>Unsupervised high-throughput segmentation of cells and cell nuclei in quantitative phase images</title><link>http://arxiv.org/abs/2311.14639v1</link><description>In the effort to aid cytologic diagnostics by establishing automatic singlecell screening using high throughput digital holographic microscopy forclinical studies thousands of images and millions of cells are captured. Thebottleneck lies in an automatic, fast, and unsupervised segmentation techniquethat does not limit the types of cells which might occur. We propose anunsupervised multistage method that segments correctly without confusing noiseor reflections with cells and without missing cells that also includes thedetection of relevant inner structures, especially the cell nucleus in theunstained cell. In an effort to make the information reasonable andinterpretable for cytopathologists, we also introduce new cytoplasmic andnuclear features of potential help for cytologic diagnoses which exploit thequantitative phase information inherent to the measurement scheme. We show thatthe segmentation provides consistently good results over many experiments onpatient samples in a reasonable per cell analysis time.</description><author>Julia Sistermanns, Ellen Emken, Gregor Weirich, Oliver Hayden, Wolfgang Utschick</author><pubDate>Fri, 24 Nov 2023 18:12:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14639v1</guid></item><item><title>Automated Detection and Counting of Windows using UAV Imagery based Remote Sensing</title><link>http://arxiv.org/abs/2311.14635v1</link><description>Despite the technological advancements in the construction and surveyingsector, the inspection of salient features like windows in anunder-construction or existing building is predominantly a manual process.Moreover, the number of windows present in a building is directly related tothe magnitude of deformation it suffers under earthquakes. In this research, amethod to accurately detect and count the number of windows of a building bydeploying an Unmanned Aerial Vehicle (UAV) based remote sensing system isproposed. The proposed two-stage method automates the identification andcounting of windows by developing computer vision pipelines that utilize datafrom UAV's onboard camera and other sensors. Quantitative and Qualitativeresults show the effectiveness of our proposed approach in accurately detectingand counting the windows compared to the existing method.</description><author>Dhruv Patel, Shivani Chepuri, Sarvesh Thakur, K. Harikumar, Ravi Kiran S., K. Madhava Krishna</author><pubDate>Fri, 24 Nov 2023 18:08:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14635v1</guid></item><item><title>How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization</title><link>http://arxiv.org/abs/2310.01769v3</link><description>This paper rigorously shows how over-parameterization changes the convergencebehaviors of gradient descent (GD) for the matrix sensing problem, where thegoal is to recover an unknown low-rank ground-truth matrix from near-isotropiclinear measurements. First, we consider the symmetric setting with thesymmetric parameterization where $M^* \in \mathbb{R}^{n \times n}$ is apositive semi-definite unknown matrix of rank $r \ll n$, and one uses asymmetric parameterization $XX^\top$ to learn $M^*$. Here $X \in \mathbb{R}^{n\times k}$ with $k &gt; r$ is the factor matrix. We give a novel $\Omega (1/T^2)$lower bound of randomly initialized GD for the over-parameterized case ($k &gt;r$)where $T$ is the number of iterations. This is in stark contrast to theexact-parameterization scenario ($k=r$) where the convergence rate is $\exp(-\Omega (T))$. Next, we study asymmetric setting where $M^* \in\mathbb{R}^{n_1 \times n_2}$ is the unknown matrix of rank $r \ll\min\{n_1,n_2\}$, and one uses an asymmetric parameterization $FG^\top$ tolearn $M^*$ where $F \in \mathbb{R}^{n_1 \times k}$ and $G \in \mathbb{R}^{n_2\times k}$. Building on prior work, we give a global exact convergence resultof randomly initialized GD for the exact-parameterization case ($k=r$) with an$\exp (-\Omega(T))$ rate. Furthermore, we give the first global exactconvergence result for the over-parameterization case ($k&gt;r$) with an$\exp(-\Omega(\alpha^2 T))$ rate where $\alpha$ is the initialization scale.This linear convergence result in the over-parameterization case is especiallysignificant because one can apply the asymmetric parameterization to thesymmetric setting to speed up from $\Omega (1/T^2)$ to linear convergence. Onthe other hand, we propose a novel method that only modifies one step of GD andobtains a convergence rate independent of $\alpha$, recovering the rate in theexact-parameterization case.</description><author>Nuoya Xiong, Lijun Ding, Simon S. Du</author><pubDate>Fri, 24 Nov 2023 18:08:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.01769v3</guid></item><item><title>One Strike, You're Out: Detecting Markush Structures in Low Signal-to-Noise Ratio Images</title><link>http://arxiv.org/abs/2311.14633v1</link><description>Modern research increasingly relies on automated methods to assistresearchers. An example of this is Optical Chemical Structure Recognition(OCSR), which aids chemists in retrieving information about chemicals fromlarge amounts of documents. Markush structures are chemical structures thatcannot be parsed correctly by OCSR and cause errors. The focus of this researchwas to propose and test a novel method for classifying Markush structures.Within this method, a comparison was made between fixed-feature extraction andend-to-end learning (CNN). The end-to-end method performed significantly betterthan the fixed-feature method, achieving 0.928 (0.035 SD) Macro F1 compared tothe fixed-feature method's 0.701 (0.052 SD). Because of the nature of theexperiment, these figures are a lower bound and can be improved further. Theseresults suggest that Markush structures can be filtered out effectively andaccurately using the proposed method. When implemented into OCSR pipelines,this method can improve their performance and use to other researchers.</description><author>Thomas Jurriaans, Kinga Szarkowska, Eric Nalisnick, Markus Schwoerer, Camilo Thorne, Saber Akhondi</author><pubDate>Fri, 24 Nov 2023 18:02:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14633v1</guid></item><item><title>Differentially Private SGD Without Clipping Bias: An Error-Feedback Approach</title><link>http://arxiv.org/abs/2311.14632v1</link><description>Differentially Private Stochastic Gradient Descent with gradient clipping(DPSGD-GC) is a powerful tool for training deep learning models using sensitivedata, providing both a solid theoretical privacy guarantee and high efficiency.However, using DPSGD-GC to ensure Differential Privacy (DP) comes at the costof model performance degradation due to DP noise injection and gradientclipping. Existing research has extensively analyzed the theoreticalconvergence of DPSGD-GC, and has shown that it only converges when using largeclipping thresholds that are dependent on problem-specific parameters.Unfortunately, these parameters are often unknown in practice, making it hardto choose the optimal clipping threshold. Therefore, in practice, DPSGD-GCsuffers from degraded performance due to the {\it constant} bias introduced bythe clipping. In our work, we propose a new error-feedback (EF) DP algorithm as analternative to DPSGD-GC, which not only offers a diminishing utility boundwithout inducing a constant clipping bias, but more importantly, it allows foran arbitrary choice of clipping threshold that is independent of the problem.We establish an algorithm-specific DP analysis for our proposed algorithm,providing privacy guarantees based on R{\'e}nyi DP. Additionally, wedemonstrate that under mild conditions, our algorithm can achieve nearly thesame utility bound as DPSGD without gradient clipping. Our empirical results onCifar-10/100 and E2E datasets, show that the proposed algorithm achieves higheraccuracies than DPSGD while maintaining the same level of DP guarantee.</description><author>Xinwei Zhang, Zhiqi Bu, Zhiwei Steven Wu, Mingyi Hong</author><pubDate>Fri, 24 Nov 2023 17:56:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14632v1</guid></item><item><title>CatVersion: Concatenating Embeddings for Diffusion-Based Text-to-Image Personalization</title><link>http://arxiv.org/abs/2311.14631v1</link><description>We propose CatVersion, an inversion-based method that learns the personalizedconcept through a handful of examples. Subsequently, users can utilize textprompts to generate images that embody the personalized concept, therebyachieving text-to-image personalization. In contrast to existing approachesthat emphasize word embedding learning or parameter fine-tuning for thediffusion model, which potentially causes concept dilution or overfitting, ourmethod concatenates embeddings on the feature-dense space of the text encoderin the diffusion model to learn the gap between the personalized concept andits base class, aiming to maximize the preservation of prior knowledge indiffusion models while restoring the personalized concepts. To this end, wefirst dissect the text encoder's integration in the image generation process toidentify the feature-dense space of the encoder. Afterward, we concatenateembeddings on the Keys and Values in this space to learn the gap between thepersonalized concept and its base class. In this way, the concatenatedembeddings ultimately manifest as a residual on the original attention output.To more accurately and unbiasedly quantify the results of personalized imagegeneration, we improve the CLIP image alignment score based on masks.Qualitatively and quantitatively, CatVersion helps to restore personalizationconcepts more faithfully and enables more robust editing.</description><author>Ruoyu Zhao, Mingrui Zhu, Shiyin Dong, Nannan Wang, Xinbo Gao</author><pubDate>Fri, 24 Nov 2023 17:55:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14631v1</guid></item><item><title>ARIA: On the interaction between Architectures, Aggregation methods and Initializations in federated visual classification</title><link>http://arxiv.org/abs/2311.14625v1</link><description>Federated Learning (FL) is a collaborative training paradigm that allows forprivacy-preserving learning of cross-institutional models by eliminating theexchange of sensitive data and instead relying on the exchange of modelparameters between the clients and a server. Despite individual studies on howclient models are aggregated, and, more recently, on the benefits of ImageNetpre-training, there is a lack of understanding of the effect the architecturechosen for the federation has, and of how the aforementioned elementsinterconnect. To this end, we conduct the first jointARchitecture-Initialization-Aggregation study and benchmark ARIAs across arange of medical image classification tasks. We find that, contrary to currentpractices, ARIA elements have to be chosen together to achieve the bestpossible performance. Our results also shed light on good choices for eachelement depending on the task, the effect of normalisation layers, and theutility of SSL pre-training, pointing to potential directions for designingFL-specific architectures and training pipelines.</description><author>Vasilis Siomos, Sergio Naval-Marimont, Jonathan Passerat-Palmbach, Giacomo Tarroni</author><pubDate>Fri, 24 Nov 2023 17:40:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14625v1</guid></item><item><title>EGraFFBench: Evaluation of Equivariant Graph Neural Network Force Fields for Atomistic Simulations</title><link>http://arxiv.org/abs/2310.02428v2</link><description>Equivariant graph neural networks force fields (EGraFFs) have shown greatpromise in modelling complex interactions in atomic systems by exploiting thegraphs' inherent symmetries. Recent works have led to a surge in thedevelopment of novel architectures that incorporate equivariance-basedinductive biases alongside architectural innovations like graph transformersand message passing to model atomic interactions. However, thorough evaluationsof these deploying EGraFFs for the downstream task of real-world atomisticsimulations, is lacking. To this end, here we perform a systematic benchmarkingof 6 EGraFF algorithms (NequIP, Allegro, BOTNet, MACE, Equiformer, TorchMDNet),with the aim of understanding their capabilities and limitations for realisticatomistic simulations. In addition to our thorough evaluation and analysis oneight existing datasets based on the benchmarking literature, we release twonew benchmark datasets, propose four new metrics, and three challenging tasks.The new datasets and tasks evaluate the performance of EGraFF toout-of-distribution data, in terms of different crystal structures,temperatures, and new molecules. Interestingly, evaluation of the EGraFF modelsbased on dynamic simulations reveals that having a lower error on energy orforce does not guarantee stable or reliable simulation or faithful replicationof the atomic structures. Moreover, we find that no model clearly outperformsother models on all datasets and tasks. Importantly, we show that theperformance of all the models on out-of-distribution datasets is unreliable,pointing to the need for the development of a foundation model for force fieldsthat can be used in real-world simulations. In summary, this work establishes arigorous framework for evaluating machine learning force fields in the contextof atomic simulations and points to open research challenges within thisdomain.</description><author>Vaibhav Bihani, Utkarsh Pratiush, Sajid Mannan, Tao Du, Zhimin Chen, Santiago Miret, Matthieu Micoulaut, Morten M Smedskjaer, Sayan Ranu, N M Anoop Krishnan</author><pubDate>Fri, 24 Nov 2023 17:26:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02428v2</guid></item><item><title>Neural Style Transfer for Computer Games</title><link>http://arxiv.org/abs/2311.14617v1</link><description>Neural Style Transfer (NST) research has been applied to images, videos, 3Dmeshes and radiance fields, but its application to 3D computer games remainsrelatively unexplored. Whilst image and video NST systems can be used as apost-processing effect for a computer game, this results in undesired artefactsand diminished post-processing effects. Here, we present an approach forinjecting depth-aware NST as part of the 3D rendering pipeline. Qualitative andquantitative experiments are used to validate our in-game stylisationframework. We demonstrate temporally consistent results of artisticallystylised game scenes, outperforming state-of-the-art image and video NSTmethods.</description><author>Eleftherios Ioannou, Steve Maddock</author><pubDate>Fri, 24 Nov 2023 17:25:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14617v1</guid></item><item><title>XAutoML: A Visual Analytics Tool for Understanding and Validating Automated Machine Learning</title><link>http://arxiv.org/abs/2202.11954v3</link><description>In the last ten years, various automated machine learning (AutoM ) systemshave been proposed to build end-to-end machine learning (ML) pipelines withminimal human interaction. Even though such automatically synthesized MLpipelines are able to achieve a competitive performance, recent studies haveshown that users do not trust models constructed by AutoML due to missingtransparency of AutoML systems and missing explanations for the constructed MLpipelines. In a requirements analysis study with 36 domain experts, datascientists, and AutoML researchers from different professions with vastlydifferent expertise in ML, we collect detailed informational needs for AutoML.We propose XAutoML, an interactive visual analytics tool for explainingarbitrary AutoML optimization procedures and ML pipelines constructed byAutoML. XAutoML combines interactive visualizations with established techniquesfrom explainable artificial intelligence (XAI) to make the complete AutoMLprocedure transparent and explainable. By integrating XAutoML with JupyterLab,experienced users can extend the visual analytics with ad-hoc visualizationsbased on information extracted from XAutoML. We validate our approach in a userstudy with the same diverse user group from the requirements analysis. Allparticipants were able to extract useful information from XAutoML, leading to asignificantly increased understanding of ML pipelines produced by AutoML andthe AutoML optimization itself.</description><author>Marc-André Zöller, Waldemar Titov, Thomas Schlegel, Marco F. Huber</author><pubDate>Fri, 24 Nov 2023 17:12:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.11954v3</guid></item><item><title>Analysis of the expected $L_2$ error of an over-parametrized deep neural network estimate learned by gradient descent without regularization</title><link>http://arxiv.org/abs/2311.14609v1</link><description>Recent results show that estimates defined by over-parametrized deep neuralnetworks learned by applying gradient descent to a regularized empirical $L_2$risk are universally consistent and achieve good rates of convergence. In thispaper, we show that the regularization term is not necessary to obtain similarresults. In the case of a suitably chosen initialization of the network, asuitable number of gradient descent steps, and a suitable step size we showthat an estimate without a regularization term is universally consistent forbounded predictor variables. Additionally, we show that if the regressionfunction is H\"older smooth with H\"older exponent $1/2 \leq p \leq 1$, the$L_2$ error converges to zero with a convergence rate of approximately$n^{-1/(1+d)}$. Furthermore, in case of an interaction model, where theregression function consists of a sum of H\"older smooth functions with $d^*$components, a rate of convergence is derived which does not depend on the inputdimension $d$.</description><author>Selina Drews, Michael Kohler</author><pubDate>Fri, 24 Nov 2023 17:04:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14609v1</guid></item><item><title>Evolution of Neural Architectures for Financial Forecasting: A Note on Data Incompatibility during Crisis Periods</title><link>http://arxiv.org/abs/2311.14604v1</link><description>This note focuses on the optimization of neural architectures for stock indexmovement forecasting following a major market disruption or crisis. Given thatsuch crises may introduce a shift in market dynamics, this study aims toinvestigate whether the training data from market dynamics prior to the crisisare compatible with the data during the crisis period. To this end, twodistinct learning environments are designed to evaluate and reconcile theeffects of possibly different market dynamics. These environments differprincipally based on the role assigned to the pre-crisis data. In bothenvironments, a set of non-dominated architectures are identified to satisfythe multi-criteria co-evolution problem, which simultaneously addresses theselection issues related to features and hidden layer topology. To test thehypothesis of pre-crisis data incompatibility, the day-ahead movementprediction of the NASDAQ index is considered during two recent and major marketdisruptions; the 2008 financial crisis and the COVID-19 pandemic. The resultsof a detailed comparative evaluation convincingly support the incompatibilityhypothesis and highlight the need to select re-training windows carefully.</description><author>Faizal Hafiz, Jan Broekaert, Akshya Swain</author><pubDate>Fri, 24 Nov 2023 16:49:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14604v1</guid></item><item><title>Animate124: Animating One Image to 4D Dynamic Scene</title><link>http://arxiv.org/abs/2311.14603v1</link><description>We introduce Animate124 (Animate-one-image-to-4D), the first work to animatea single in-the-wild image into 3D video through textual motion descriptions,an underexplored problem with significant applications. Our 4D generationleverages an advanced 4D grid dynamic Neural Radiance Field (NeRF) model,optimized in three distinct stages using multiple diffusion priors. Initially,a static model is optimized using the reference image, guided by 2D and 3Ddiffusion priors, which serves as the initialization for the dynamic NeRF.Subsequently, a video diffusion model is employed to learn the motion specificto the subject. However, the object in the 3D videos tends to drift away fromthe reference image over time. This drift is mainly due to the misalignmentbetween the text prompt and the reference image in the video diffusion model.In the final stage, a personalized diffusion prior is therefore utilized toaddress the semantic drift. As the pioneering image-text-to-4D generationframework, our method demonstrates significant advancements over existingbaselines, evidenced by comprehensive quantitative and qualitative assessments.</description><author>Yuyang Zhao, Zhiwen Yan, Enze Xie, Lanqing Hong, Zhenguo Li, Gim Hee Lee</author><pubDate>Fri, 24 Nov 2023 16:47:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14603v1</guid></item><item><title>A Metalearned Neural Circuit for Nonparametric Bayesian Inference</title><link>http://arxiv.org/abs/2311.14601v1</link><description>Most applications of machine learning to classification assume a closed setof balanced classes. This is at odds with the real world, where classoccurrence statistics often follow a long-tailed power-law distribution and itis unlikely that all classes are seen in a single sample. NonparametricBayesian models naturally capture this phenomenon, but have significantpractical barriers to widespread adoption, namely implementation complexity andcomputational inefficiency. To address this, we present a method for extractingthe inductive bias from a nonparametric Bayesian model and transferring it toan artificial neural network. By simulating data with a nonparametric Bayesianprior, we can metalearn a sequence model that performs inference over anunlimited set of classes. After training, this "neural circuit" has distilledthe corresponding inductive bias and can successfully perform sequentialinference over an open set of classes. Our experimental results show that themetalearned neural circuit achieves comparable or better performance thanparticle filter-based methods for inference in these models while being fasterand simpler to use than methods that explicitly incorporate Bayesiannonparametric inference.</description><author>Jake C. Snell, Gianluca Bencomo, Thomas L. Griffiths</author><pubDate>Fri, 24 Nov 2023 16:43:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14601v1</guid></item><item><title>A Survey and Analysis of Evolutionary Operators for Permutations</title><link>http://arxiv.org/abs/2311.14595v1</link><description>There are many combinatorial optimization problems whose solutions are bestrepresented by permutations. The classic traveling salesperson seeks an optimalordering over a set of cities. Scheduling problems often seek optimal orderingsof tasks or activities. Although some evolutionary approaches to such problemsutilize the bit strings of a genetic algorithm, it is more common to directlyrepresent solutions with permutations. Evolving permutations directly requiresspecialized evolutionary operators. Over the years, many crossover and mutationoperators have been developed for solving permutation problems withevolutionary algorithms. In this paper, we survey the breadth of evolutionaryoperators for permutations. We implemented all of these in Chips-n-Salsa, anopen source Java library for evolutionary computation. Finally, we empiricallyanalyze the crossover operators on artificial fitness landscapes isolatingdifferent permutation features.</description><author>Vincent A. Cicirello</author><pubDate>Fri, 24 Nov 2023 16:32:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14595v1</guid></item><item><title>CMX: Cross-Modal Fusion for RGB-X Semantic Segmentation with Transformers</title><link>http://arxiv.org/abs/2203.04838v5</link><description>Scene understanding based on image segmentation is a crucial component ofautonomous vehicles. Pixel-wise semantic segmentation of RGB images can beadvanced by exploiting complementary features from the supplementary modality(X-modality). However, covering a wide variety of sensors with amodality-agnostic model remains an unresolved problem due to variations insensor characteristics among different modalities. Unlike previousmodality-specific methods, in this work, we propose a unified fusion framework,CMX, for RGB-X semantic segmentation. To generalize well across differentmodalities, that often include supplements as well as uncertainties, a unifiedcross-modal interaction is crucial for modality fusion. Specifically, we designa Cross-Modal Feature Rectification Module (CM-FRM) to calibrate bi-modalfeatures by leveraging the features from one modality to rectify the featuresof the other modality. With rectified feature pairs, we deploy a Feature FusionModule (FFM) to perform sufficient exchange of long-range contexts beforemixing. To verify CMX, for the first time, we unify five modalitiescomplementary to RGB, i.e., depth, thermal, polarization, event, and LiDAR.Extensive experiments show that CMX generalizes well to diverse multi-modalfusion, achieving state-of-the-art performances on five RGB-Depth benchmarks,as well as RGB-Thermal, RGB-Polarization, and RGB-LiDAR datasets. Besides, toinvestigate the generalizability to dense-sparse data fusion, we establish anRGB-Event semantic segmentation benchmark based on the EventScape dataset, onwhich CMX sets the new state-of-the-art. The source code of CMX is publiclyavailable at https://github.com/huaaaliu/RGBX_Semantic_Segmentation.</description><author>Jiaming Zhang, Huayao Liu, Kailun Yang, Xinxin Hu, Ruiping Liu, Rainer Stiefelhagen</author><pubDate>Fri, 24 Nov 2023 16:29:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.04838v5</guid></item><item><title>Dungeons and Data: A Large-Scale NetHack Dataset</title><link>http://arxiv.org/abs/2211.00539v3</link><description>Recent breakthroughs in the development of agents to solve challengingsequential decision making problems such as Go, StarCraft, or DOTA, have reliedon both simulated environments and large-scale datasets. However, progress onthis research has been hindered by the scarcity of open-sourced datasets andthe prohibitive computational cost to work with them. Here we present theNetHack Learning Dataset (NLD), a large and highly-scalable dataset oftrajectories from the popular game of NetHack, which is both extremelychallenging for current methods and very fast to run. NLD consists of threeparts: 10 billion state transitions from 1.5 million human trajectoriescollected on the NAO public NetHack server from 2009 to 2020; 3 billionstate-action-score transitions from 100,000 trajectories collected from thesymbolic bot winner of the NetHack Challenge 2021; and, accompanying code forusers to record, load and stream any collection of such trajectories in ahighly compressed form. We evaluate a wide range of existing algorithmsincluding online and offline RL, as well as learning from demonstrations,showing that significant research advances are needed to fully leveragelarge-scale datasets for challenging sequential decision making tasks.</description><author>Eric Hambro, Roberta Raileanu, Danielle Rothermel, Vegard Mella, Tim Rocktäschel, Heinrich Küttler, Naila Murray</author><pubDate>Fri, 24 Nov 2023 16:27:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.00539v3</guid></item><item><title>Knowledge Accumulation in Continually Learned Representations and the Issue of Feature Forgetting</title><link>http://arxiv.org/abs/2304.00933v2</link><description>While it is established that neural networks suffer from catastrophicforgetting ``at the output level'', it is debated whether this is also the caseat the level of representations. Some studies ascribe a certain level of innaterobustness to representations, that they only forget minimally and no criticalinformation, while others claim that representations are also severely affectedby forgetting. To settle this debate, we first discuss how this apparentdisagreement might stem from the coexistence of two phenomena that affect thequality of continually learned representations: knowledge accumulation andfeature forgetting. We then show that, even though it is true that featureforgetting can be small in absolute terms, newly learned information isforgotten just as catastrophically at the level of representations as it is atthe output level. Next we show that this feature forgetting is problematic asit substantially slows down knowledge accumulation. We further show thatrepresentations that are continually learned through both supervised andself-supervised learning suffer from feature forgetting. Finally, we study howfeature forgetting and knowledge accumulation are affected by different typesof continual learning methods.</description><author>Timm Hess, Eli Verwimp, Gido M. van de Ven, Tinne Tuytelaars</author><pubDate>Fri, 24 Nov 2023 16:24:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.00933v2</guid></item><item><title>Backdoor Activation Attack: Attack Large Language Models using Activation Steering for Safety-Alignment</title><link>http://arxiv.org/abs/2311.09433v2</link><description>To ensure AI safety, instruction-tuned Large Language Models (LLMs) arespecifically trained to ensure alignment, which refers to making models behavein accordance with human intentions. While these models have demonstratedcommendable results on various safety benchmarks, the vulnerability of theirsafety alignment has not been extensively studied. This is particularlytroubling given the potential harm that LLMs can inflict. Existing attackmethods on LLMs often rely on poisoned training data or the injection ofmalicious prompts. These approaches compromise the stealthiness andgeneralizability of the attacks, making them susceptible to detection.Additionally, these models often demand substantial computational resources forimplementation, making them less practical for real-world applications.Inspired by recent success in modifying model behavior through steering vectorswithout the need for optimization, and drawing on its effectiveness inred-teaming LLMs, we conducted experiments employing activation steering totarget four key aspects of LLMs: truthfulness, toxicity, bias, and harmfulness- across a varied set of attack settings. To establish a universal attackstrategy applicable to diverse target alignments without depending on manualanalysis, we automatically select the intervention layer based on contrastivelayer search. Our experiment results show that activation attacks are highlyeffective and add little or no overhead to attack efficiency. Additionally, wediscuss potential countermeasures against such activation attacks. Our code anddata are available at https://github.com/wang2226/Backdoor-Activation-AttackWarning: this paper contains content that can be offensive or upsetting.</description><author>Haoran Wang, Kai Shu</author><pubDate>Fri, 24 Nov 2023 16:22:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.09433v2</guid></item><item><title>Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models</title><link>http://arxiv.org/abs/2311.06607v2</link><description>Large Multimodal Models (LMMs) have shown promise in vision-language tasksbut struggle with high-resolution input and detailed scene understanding.Addressing these challenges, we introduce Monkey to enhance LMM capabilities.Firstly, Monkey processes input images by dividing them into uniform patches,each matching the size (e.g., 448x448) used in the original training of thewell-trained vision encoder. Equipped with individual adapter for each patch,Monkey can handle higher resolutions up to 1344x896 pixels, enabling thedetailed capture of complex visual information. Secondly, it employs amulti-level description generation method, enriching the context forscene-object associations. This two-part strategy ensures more effectivelearning from generated data: the higher resolution allows for a more detailedcapture of visuals, which in turn enhances the effectiveness of comprehensivedescriptions. Extensive ablative results validate the effectiveness of ourdesigns. Additionally, experiments on 18 datasets further demonstrate thatMonkey surpasses existing LMMs in many tasks like Image Captioning and variousVisual Question Answering formats. Specially, in qualitative tests focused ondense text question answering, Monkey has exhibited encouraging resultscompared with GPT4V. Code is available athttps://github.com/Yuliang-Liu/Monkey.</description><author>Zhang Li, Biao Yang, Qiang Liu, Zhiyin Ma, Shuo Zhang, Jingxu Yang, Yabo Sun, Yuliang Liu, Xiang Bai</author><pubDate>Fri, 24 Nov 2023 16:21:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06607v2</guid></item><item><title>GPT Struct Me: Probing GPT Models on Narrative Entity Extraction</title><link>http://arxiv.org/abs/2311.14583v1</link><description>The importance of systems that can extract structured information fromtextual data becomes increasingly pronounced given the ever-increasing volumeof text produced on a daily basis. Having a system that can effectively extractsuch information in an interoperable manner would be an asset for severaldomains, be it finance, health, or legal. Recent developments in naturallanguage processing led to the production of powerful language models that can,to some degree, mimic human intelligence. Such effectiveness raises a pertinentquestion: Can these models be leveraged for the extraction of structuredinformation? In this work, we address this question by evaluating thecapabilities of two state-of-the-art language models -- GPT-3 and GPT-3.5,commonly known as ChatGPT -- in the extraction of narrative entities, namelyevents, participants, and temporal expressions. This study is conducted on theText2Story Lusa dataset, a collection of 119 Portuguese news articles whoseannotation framework includes a set of entity structures along with severaltags and attribute values. We first select the best prompt template through anablation study over prompt components that provide varying degrees ofinformation on a subset of documents of the dataset. Subsequently, we use thebest templates to evaluate the effectiveness of the models on the remainingdocuments. The results obtained indicate that GPT models are competitive without-of-the-box baseline systems, presenting an all-in-one alternative forpractitioners with limited resources. By studying the strengths and limitationsof these models in the context of information extraction, we offer insightsthat can guide future improvements and avenues to explore in this field.</description><author>Hugo Sousa, Nuno Guimarães, Alípio Jorge, Ricardo Campos</author><pubDate>Fri, 24 Nov 2023 16:19:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14583v1</guid></item><item><title>tieval: An Evaluation Framework for Temporal Information Extraction Systems</title><link>http://arxiv.org/abs/2301.04643v3</link><description>Temporal information extraction (TIE) has attracted a great deal of interestover the last two decades, leading to the development of a significant numberof datasets. Despite its benefits, having access to a large volume of corporamakes it difficult when it comes to benchmark TIE systems. On the one hand,different datasets have different annotation schemes, thus hindering thecomparison between competitors across different corpora. On the other hand, thefact that each corpus is commonly disseminated in a different format requires aconsiderable engineering effort for a researcher/practitioner to developparsers for all of them. This constraint forces researchers to select a limitedamount of datasets to evaluate their systems which consequently limits thecomparability of the systems. Yet another obstacle that hinders thecomparability of the TIE systems is the evaluation metric employed. While mostresearch works adopt traditional metrics such as precision, recall, and $F_1$,a few others prefer temporal awareness -- a metric tailored to be morecomprehensive on the evaluation of temporal systems. Although the reason forthe absence of temporal awareness in the evaluation of most systems is notclear, one of the factors that certainly weights this decision is the necessityto implement the temporal closure algorithm in order to compute temporalawareness, which is not straightforward to implement neither is currentlyeasily available. All in all, these problems have limited the fair comparisonbetween approaches and consequently, the development of temporal extractionsystems. To mitigate these problems, we have developed tieval, a Python librarythat provides a concise interface for importing different corpora andfacilitates system evaluation. In this paper, we present the first publicrelease of tieval and highlight its most relevant features.</description><author>Hugo Sousa, Alípio Jorge, Ricardo Campos</author><pubDate>Fri, 24 Nov 2023 16:13:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.04643v3</guid></item><item><title>Example-Based Explanations of Random Forest Predictions</title><link>http://arxiv.org/abs/2311.14581v1</link><description>A random forest prediction can be computed by the scalar product of thelabels of the training examples and a set of weights that are determined by theleafs of the forest into which the test object falls; each prediction can hencebe explained exactly by the set of training examples for which the weights arenon-zero. The number of examples used in such explanations is shown to varywith the dimensionality of the training set and hyperparameters of the randomforest algorithm. This means that the number of examples involved in eachprediction can to some extent be controlled by varying these parameters.However, for settings that lead to a required predictive performance, thenumber of examples involved in each prediction may be unreasonably large,preventing the user to grasp the explanations. In order to provide more usefulexplanations, a modified prediction procedure is proposed, which includes onlythe top-weighted examples. An investigation on regression and classificationtasks shows that the number of examples used in each explanation can besubstantially reduced while maintaining, or even improving, predictiveperformance compared to the standard prediction procedure.</description><author>Henrik Boström</author><pubDate>Fri, 24 Nov 2023 16:12:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14581v1</guid></item><item><title>Large Language Models as Automated Aligners for benchmarking Vision-Language Models</title><link>http://arxiv.org/abs/2311.14580v1</link><description>With the advancements in Large Language Models (LLMs), Vision-Language Models(VLMs) have reached a new level of sophistication, showing notable competencein executing intricate cognition and reasoning tasks. However, existingevaluation benchmarks, primarily relying on rigid, hand-crafted datasets tomeasure task-specific performance, face significant limitations in assessingthe alignment of these increasingly anthropomorphic models with humanintelligence. In this work, we address the limitations via Auto-Bench, whichdelves into exploring LLMs as proficient aligners, measuring the alignmentbetween VLMs and human intelligence and value through automatic data curationand assessment. Specifically, for data curation, Auto-Bench utilizes LLMs(e.g., GPT-4) to automatically generate a vast set of question-answer-reasoningtriplets via prompting on visual symbolic representations (e.g., captions,object locations, instance relationships, and etc.). The curated data closelymatches human intent, owing to the extensive world knowledge embedded in LLMs.Through this pipeline, a total of 28.5K human-verified and 3,504K unfilteredquestion-answer-reasoning triplets have been curated, covering 4 primaryabilities and 16 sub-abilities. We subsequently engage LLMs like GPT-3.5 toserve as judges, implementing the quantitative and qualitative automatedassessments to facilitate a comprehensive evaluation of VLMs. Our validationresults reveal that LLMs are proficient in both evaluation data curation andmodel assessment, achieving an average agreement rate of 85%. We envisionAuto-Bench as a flexible, scalable, and comprehensive benchmark for evaluatingthe evolving sophisticated VLMs.</description><author>Yuanfeng Ji, Chongjian Ge, Weikai Kong, Enze Xie, Zhengying Liu, Zhengguo Li, Ping Luo</author><pubDate>Fri, 24 Nov 2023 16:12:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14580v1</guid></item><item><title>Counting Solutions to Conjunctive Queries: Structural and Hybrid Tractability</title><link>http://arxiv.org/abs/2311.14579v1</link><description>Counting the number of answers to conjunctive queries is a fundamentalproblem in databases that, under standard assumptions, does not have anefficient solution. The issue is inherently #P-hard, extending even to classesof acyclic instances. To address this, we pinpoint tractable classes by examining the structuralproperties of instances and introducing the novel concept of #-hypertreedecomposition. We establish the feasibility of counting answers in polynomialtime for classes of queries featuring bounded #-hypertree width. Additionally,employing novel techniques from the realm of fixed-parameter computationalcomplexity, we prove that, for bounded arity queries, the bounded #-hypertreewidth property precisely delineates the frontier of tractability for thecounting problem. This result closes an important gap in our understanding ofthe complexity of such a basic problem for conjunctive queries and,equivalently, for constraint satisfaction problems (CSPs). Drawing upon #-hypertree decompositions, a ''hybrid'' decomposition methodemerges. This approach leverages both the structural characteristics of thequery and properties intrinsic to the input database, including keys or other(weaker) degree constraints that limit the permissible combinations of values.Intuitively, these features may introduce distinct structural properties thatelude identification through the ''worst-possible database'' perspectiveinherent in purely structural methods.</description><author>Hubie Chen, Gianluigi Greco, Stefan Mengel, Francesco Scarcello</author><pubDate>Fri, 24 Nov 2023 16:09:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14579v1</guid></item><item><title>Navigating the Design Space of Equivariant Diffusion-Based Generative Models for De Novo 3D Molecule Generation</title><link>http://arxiv.org/abs/2309.17296v2</link><description>Deep generative diffusion models are a promising avenue for 3D de novomolecular design in materials science and drug discovery. However, theirutility is still limited by suboptimal performance on large molecularstructures and limited training data. To address this gap, we explore thedesign space of E(3)-equivariant diffusion models, focusing on previouslyunexplored areas. Our extensive comparative analysis evaluates the interplaybetween continuous and discrete state spaces. From this investigation, wepresent the EQGAT-diff model, which consistently outperforms established modelsfor the QM9 and GEOM-Drugs datasets. Significantly, EQGAT-diff takes continuousatom positions, while chemical elements and bond types are categorical and usestime-dependent loss weighting, substantially increasing training convergence,the quality of generated samples, and inference time. We also showcase thatincluding chemically motivated additional features like hybridization states inthe diffusion process enhances the validity of generated molecules. To furtherstrengthen the applicability of diffusion models to limited training data, weinvestigate the transferability of EQGAT-diff trained on the large PubChem3Ddataset with implicit hydrogen atoms to target different data distributions.Fine-tuning EQGAT-diff for just a few iterations shows an efficientdistribution shift, further improving performance throughout data sets.Finally, we test our model on the Crossdocked data set for structure-based denovo ligand generation, underlining the importance of our findings showingstate-of-the-art performance on Vina docking scores.</description><author>Tuan Le, Julian Cremer, Frank Noé, Djork-Arné Clevert, Kristof Schütt</author><pubDate>Fri, 24 Nov 2023 16:08:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17296v2</guid></item><item><title>Predicting Failure of P2P Lending Platforms through Machine Learning: The Case in China</title><link>http://arxiv.org/abs/2311.14577v1</link><description>This study employs machine learning models to predict the failure ofPeer-to-Peer (P2P) lending platforms, specifically in China. By employing thefilter method and wrapper method with forward selection and backwardelimination, we establish a rigorous and practical procedure that ensures therobustness and importance of variables in predicting platform failures. Theresearch identifies a set of robust variables that consistently appear in thefeature subsets across different selection methods and models, suggesting theirreliability and relevance in predicting platform failures. The study highlightsthat reducing the number of variables in the feature subset leads to anincrease in the false acceptance rate while the performance metrics remainstable, with an AUC value of approximately 0.96 and an F1 score of around 0.88.The findings of this research provide significant practical implications forregulatory authorities and investors operating in the Chinese P2P lendingindustry.</description><author>Jen-Yin Yeh, Hsin-Yu Chiu, Jhih-Huei Huang</author><pubDate>Fri, 24 Nov 2023 16:07:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14577v1</guid></item><item><title>RAISE -- Radiology AI Safety, an End-to-end lifecycle approach</title><link>http://arxiv.org/abs/2311.14570v1</link><description>The integration of AI into radiology introduces opportunities for improvedclinical care provision and efficiency but it demands a meticulous approach tomitigate potential risks as with any other new technology. Beginning withrigorous pre-deployment evaluation and validation, the focus should be onensuring models meet the highest standards of safety, effectiveness andefficacy for their intended applications. Input and output guardrailsimplemented during production usage act as an additional layer of protection,identifying and addressing individual failures as they occur. Continuouspost-deployment monitoring allows for tracking population-level performance(data drift), fairness, and value delivery over time. Scheduling reviews ofpost-deployment model performance and educating radiologists about newalgorithmic-driven findings is critical for AI to be effective in clinicalpractice. Recognizing that no single AI solution can provide absolute assuranceeven when limited to its intended use, the synergistic application of qualityassurance at multiple levels - regulatory, clinical, technical, and ethical -is emphasized. Collaborative efforts between stakeholders spanning healthcaresystems, industry, academia, and government are imperative to address themultifaceted challenges involved. Trust in AI is an earned privilege,contingent on a broad set of goals, among them transparently demonstrating thatthe AI adheres to the same rigorous safety, effectiveness and efficacystandards as other established medical technologies. By doing so, developerscan instil confidence among providers and patients alike, enabling theresponsible scaling of AI and the realization of its potential benefits. Theroadmap presented herein aims to expedite the achievement of deployable,reliable, and safe AI in radiology.</description><author>M. Jorge Cardoso, Julia Moosbauer, Tessa S. Cook, B. Selnur Erdal, Brad Genereaux, Vikash Gupta, Bennett A. Landman, Tiarna Lee, Parashkev Nachev, Elanchezhian Somasundaram, Ronald M. Summers, Khaled Younis, Sebastien Ourselin, Franz MJ Pfister</author><pubDate>Fri, 24 Nov 2023 15:59:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14570v1</guid></item><item><title>Electric Vehicles coordination for grid balancing using multi-objective Harris Hawks Optimization</title><link>http://arxiv.org/abs/2311.14563v1</link><description>The rise of renewables coincides with the shift towards Electrical Vehicles(EVs) posing technical and operational challenges for the energy balance of thelocal grid. Nowadays, the energy grid cannot deal with a spike in EVs usageleading to a need for more coordinated and grid aware EVs charging anddischarging strategies. However, coordinating power flow from multiple EVs intothe grid requires sophisticated algorithms and load-balancing strategies as thecomplexity increases with more control variables and EVs, necessitating largeoptimization and decision search spaces. In this paper, we propose an EVs fleetcoordination model for the day ahead aiming to ensure a reliable energy supplyand maintain a stable local grid, by utilizing EVs to store surplus energy anddischarge it during periods of energy deficit. The optimization problem isaddressed using Harris Hawks Optimization (HHO) considering criteria related toenergy grid balancing, time usage preference, and the location of EV drivers.The EVs schedules, associated with the position of individuals from thepopulation, are adjusted through exploration and exploitation operations, andtheir technical and operational feasibility is ensured, while the rabbitindividual is updated with a non-dominated EV schedule selected per iterationusing a roulette wheel algorithm. The solution is evaluated within theframework of an e-mobility service in Terni city. The results indicate thatcoordinated charging and discharging of EVs not only meet balancing servicerequirements but also align with user preferences with minimal deviations.</description><author>Cristina Bianca Pop, Tudor Cioara, Viorica Chifu, Ionut Anghel, Francesco Bellesini</author><pubDate>Fri, 24 Nov 2023 15:50:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14563v1</guid></item><item><title>Diagonal Hierarchical Consistency Learning for Semi-supervised Medical Image Segmentation</title><link>http://arxiv.org/abs/2311.06031v3</link><description>Medical image segmentation, which is essential for many clinicalapplications, has achieved almost human-level performance via data-driven deeplearning technologies. Nevertheless, its performance is predicated upon thecostly process of manually annotating a vast amount of medical images. To thisend, we propose a novel framework for robust semi-supervised medical imagesegmentation using diagonal hierarchical consistency learning (DiHC-Net).First, it is composed of multiple sub-models with identical multi-scalearchitecture but with distinct sub-layers, such as up-sampling andnormalisation layers. Second, with mutual consistency, a novel consistencyregularisation is enforced between one model's intermediate and finalprediction and soft pseudo labels from other models in a diagonal hierarchicalfashion. A series of experiments verifies the efficacy of our simple framework,outperforming all previous approaches on public Left Atrium (LA) dataset.</description><author>Heejoon Koo</author><pubDate>Fri, 24 Nov 2023 15:37:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06031v3</guid></item><item><title>Griffon: Spelling out All Object Locations at Any Granularity with Large Language Models</title><link>http://arxiv.org/abs/2311.14552v1</link><description>Replicating the innate human ability to detect all objects based on free-formtexts at any granularity remains a formidable challenge for Vision-Languagemodels. Current Large Vision Language Models (LVLMs) are predominantlyconstrained to grounding a single, pre-existing object, relying solely on datafrom Referring Expression Comprehension tasks. The limitation leads to acompromise in model design, necessitating the introduction of visual expertmodels or the integration of customized head structures. Beyond theseconstraints, our research delves into the untapped potential of LVLMs anduncover their inherent capability for basic object perception, allowing them toaccurately identify and locate objects of interest. Building on this insight,we introduce a novel language-prompted localization dataset designed to fullyunleash the capabilities of LVLMs in integrating fine-grained object perceptionwith precise location awareness. More importantly, we present$\textbf{Griffon}$, a purely LVLM-based baseline, which does not require theintroduction of any special tokens, expert models, or additional detectionmodules. It simply maintains a consistent structure with popular LVLMs byunifying data formats across various localization-related scenarios and istrained end-to-end through a well-designed pipeline. Comprehensive experimentsdemonstrate that $\textbf{Griffon}$ not only achieves state-of-the-artperformance on the fine-grained RefCOCO series but also approaches thecapabilities of the expert model Faster RCNN on the detection benchmark MSCOCO.</description><author>Yufei Zhan, Yousong Zhu, Zhiyang Chen, Fan Yang, Ming Tang, Jinqiao Wang</author><pubDate>Fri, 24 Nov 2023 15:35:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14552v1</guid></item><item><title>Generating and Imputing Tabular Data via Diffusion and Flow-based Gradient-Boosted Trees</title><link>http://arxiv.org/abs/2309.09968v2</link><description>Tabular data is hard to acquire and is subject to missing values. This paperproposes a novel approach to generate and impute mixed-type (continuous andcategorical) tabular data using score-based diffusion and conditional flowmatching. Contrary to previous work that relies on neural networks to learn thescore function or the vector field, we instead rely on XGBoost, a popularGradient-Boosted Tree (GBT) method. We empirically show on 27 differentdatasets that our approach i) generates highly realistic synthetic data whenthe training dataset is either clean or tainted by missing data and ii)generates diverse plausible data imputations. Furthermore, our methodoutperforms deep-learning generation methods on data generation and iscompetitive on data imputation. Finally, it can be trained in parallel usingCPUs without the need for a GPU. To make it easily accessible, we release ourcode through a Python library and an R package.</description><author>Alexia Jolicoeur-Martineau, Kilian Fatras, Tal Kachman</author><pubDate>Fri, 24 Nov 2023 15:33:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09968v2</guid></item><item><title>FRUITS: Feature Extraction Using Iterated Sums for Time Series Classification</title><link>http://arxiv.org/abs/2311.14549v1</link><description>We introduce a pipeline for time series classification that extracts featuresbased on the iterated-sums signature (ISS) and then applies a linearclassifier. These features are intrinsically nonlinear, capture chronologicalinformation, and, under certain settings, are invariant to time-warping. We arecompetitive with state-of-the-art methods on the UCR archive, both in terms ofaccuracy and speed. We make our code available at\url{https://github.com/irkri/fruits}.</description><author>Joscha Diehl, Richard Krieg</author><pubDate>Fri, 24 Nov 2023 15:31:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14549v1</guid></item><item><title>Hawkeye: A PyTorch-based Library for Fine-Grained Image Recognition with Deep Learning</title><link>http://arxiv.org/abs/2310.09600v2</link><description>Fine-Grained Image Recognition (FGIR) is a fundamental and challenging taskin computer vision and multimedia that plays a crucial role in IntellectualEconomy and Industrial Internet applications. However, the absence of a unifiedopen-source software library covering various paradigms in FGIR poses asignificant challenge for researchers and practitioners in the field. Toaddress this gap, we present Hawkeye, a PyTorch-based library for FGIR withdeep learning. Hawkeye is designed with a modular architecture, emphasizinghigh-quality code and human-readable configuration, providing a comprehensivesolution for FGIR tasks. In Hawkeye, we have implemented 16 state-of-the-artfine-grained methods, covering 6 different paradigms, enabling users to explorevarious approaches for FGIR. To the best of our knowledge, Hawkeye representsthe first open-source PyTorch-based library dedicated to FGIR. It is publiclyavailable at https://github.com/Hawkeye-FineGrained/Hawkeye/, providingresearchers and practitioners with a powerful tool to advance their researchand development in the field of FGIR.</description><author>Jiabei He, Yang Shen, Xiu-Shen Wei, Ye Wu</author><pubDate>Fri, 24 Nov 2023 15:29:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.09600v2</guid></item><item><title>Interpretable and intervenable ultrasonography-based machine learning models for pediatric appendicitis</title><link>http://arxiv.org/abs/2302.14460v3</link><description>Appendicitis is among the most frequent reasons for pediatric abdominalsurgeries. Previous decision support systems for appendicitis have focused onclinical, laboratory, scoring, and computed tomography data and have ignoredabdominal ultrasound, despite its noninvasive nature and widespreadavailability. In this work, we present interpretable machine learning modelsfor predicting the diagnosis, management and severity of suspected appendicitisusing ultrasound images. Our approach utilizes concept bottleneck models (CBM)that facilitate interpretation and interaction with high-level conceptsunderstandable to clinicians. Furthermore, we extend CBMs to predictionproblems with multiple views and incomplete concept sets. Our models weretrained on a dataset comprising 579 pediatric patients with 1709 ultrasoundimages accompanied by clinical and laboratory data. Results show that ourproposed method enables clinicians to utilize a human-understandable andintervenable predictive model without compromising performance or requiringtime-consuming image annotation when deployed. For predicting the diagnosis,the extended multiview CBM attained an AUROC of 0.80 and an AUPR of 0.92,performing comparably to similar black-box neural networks trained and testedon the same dataset.</description><author>Ričards Marcinkevičs, Patricia Reis Wolfertstetter, Ugne Klimiene, Kieran Chin-Cheong, Alyssia Paschke, Julia Zerres, Markus Denzinger, David Niederberger, Sven Wellmann, Ece Ozkan, Christian Knorr, Julia E. Vogt</author><pubDate>Fri, 24 Nov 2023 15:25:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.14460v3</guid></item><item><title>Inferring Latent Class Statistics from Text for Robust Visual Few-Shot Learning</title><link>http://arxiv.org/abs/2311.14544v1</link><description>In the realm of few-shot learning, foundation models like CLIP have proveneffective but exhibit limitations in cross-domain robustness especially infew-shot settings. Recent works add text as an extra modality to enhance theperformance of these models. Most of these approaches treat text as anauxiliary modality without fully exploring its potential to elucidate theunderlying class visual features distribution. In this paper, we present anovel approach that leverages text-derived statistics to predict the mean andcovariance of the visual feature distribution for each class. This predictiveframework enriches the latent space, yielding more robust and generalizablefew-shot learning models. We demonstrate the efficacy of incorporating bothmean and covariance statistics in improving few-shot classification performanceacross various datasets. Our method shows that we can use text to predict themean and covariance of the distribution offering promising improvements infew-shot learning scenarios.</description><author>Yassir Bendou, Vincent Gripon, Bastien Pasdeloup, Giulia Lioi, Lukas Mauch, Fabien Cardinaux, Ghouthi Boukli Hacene</author><pubDate>Fri, 24 Nov 2023 15:23:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14544v1</guid></item><item><title>Data-Efficient Alignment of Large Language Models with Human Feedback Through Natural Language</title><link>http://arxiv.org/abs/2311.14543v1</link><description>Learning from human feedback is a prominent technique to align the output oflarge language models (LLMs) with human expectations. Reinforcement learningfrom human feedback (RLHF) leverages human preference signals that are in theform of ranking of response pairs to perform this alignment. However, humanpreference on LLM outputs can come in much richer forms including naturallanguage, which may provide detailed feedback on strengths and weaknesses of agiven response. In this work we investigate data efficiency of modeling humanfeedback that is in natural language. Specifically, we fine-tune an open-sourceLLM, e.g., Falcon-40B-Instruct, on a relatively small amount (1000 records oreven less) of human feedback in natural language in the form of critiques andrevisions of responses. We show that this model is able to improve the qualityof responses from even some of the strongest LLMs such as ChatGPT, BARD, andVicuna, through critique and revision of those responses. For instance, throughone iteration of revision of ChatGPT responses, the revised responses have56.6% win rate over the original ones, and this win rate can be furtherimproved to 65.9% after applying the revision for five iterations.</description><author>Di Jin, Shikib Mehri, Devamanyu Hazarika, Aishwarya Padmakumar, Sungjin Lee, Yang Liu, Mahdi Namazifar</author><pubDate>Fri, 24 Nov 2023 15:20:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14543v1</guid></item><item><title>ToddlerDiffusion: Flash Interpretable Controllable Diffusion Model</title><link>http://arxiv.org/abs/2311.14542v1</link><description>Diffusion-based generative models excel in perceptually impressive synthesisbut face challenges in interpretability. This paper introducesToddlerDiffusion, an interpretable 2D diffusion image-synthesis frameworkinspired by the human generation system. Unlike traditional diffusion modelswith opaque denoising steps, our approach decomposes the generation processinto simpler, interpretable stages; generating contours, a palette, and adetailed colored image. This not only enhances overall performance but alsoenables robust editing and interaction capabilities. Each stage is meticulouslyformulated for efficiency and accuracy, surpassing Stable-Diffusion (LDM).Extensive experiments on datasets like LSUN-Churches and COCO validate ourapproach, consistently outperforming existing methods. ToddlerDiffusionachieves notable efficiency, matching LDM performance on LSUN-Churches whileoperating three times faster with a 3.76 times smaller architecture. Our sourcecode is provided in the supplementary material and will be publicly accessible.</description><author>Eslam Mohamed Bakr, Liangbing Zhao, Vincent Tao Hu, Matthieu Cord, Patrick Perez, Mohamed Elhoseiny</author><pubDate>Fri, 24 Nov 2023 15:20:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14542v1</guid></item><item><title>RDF Stream Taxonomy: Systematizing RDF Stream Types in Research and Practice</title><link>http://arxiv.org/abs/2311.14540v1</link><description>Over the years, RDF streaming was explored in research and practice from manyangles, resulting in a wide range of RDF stream definitions. This varietypresents a major challenge in discussing and integrating streaming solutions,due to the lack of a common language. This work attempts to address thiscritical research gap, by systematizing RDF stream types present in theliterature in a novel taxonomy. The proposed RDF Stream Taxonomy (RDF-STaX) isembodied in an OWL 2 DL ontology that follows the FAIR principles, making itreadily applicable in practice. Extensive documentation and additionalresources are provided, to foster the adoption of the ontology. Two realizeduse cases are presented, demonstrating the usefulness of the resource indiscussing research works and annotating streaming datasets. Another result ofthis contribution is the novel nanopublications dataset, which serves as acollaborative, living state-of-the-art review of RDF streaming. The aim ofRDF-STaX is to address a real need of the community for a better way tosystematize and describe RDF streams. The resource is designed to help driveinnovation in RDF streaming, by fostering scientific discussion, cooperation,and tool interoperability.</description><author>Piotr Sowinski, Pawel Szmeja, Maria Ganzha, Marcin Paprzycki</author><pubDate>Fri, 24 Nov 2023 15:11:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14540v1</guid></item><item><title>CMed-GPT: Prompt Tuning for Entity-Aware Chinese Medical Dialogue Generation</title><link>http://arxiv.org/abs/2311.14539v1</link><description>Medical dialogue generation relies on natural language generation techniquesto enable online medical consultations. Recently, the widespread adoption oflarge-scale models in the field of natural language processing has facilitatedrapid advancements in this technology. Existing medical dialogue models aremostly based on BERT and pre-trained on English corpora, but there is a lack ofhigh-performing models on the task of Chinese medical dialogue generation. Tosolve the above problem, this paper proposes CMed-GPT, which is the GPTpre-training language model based on Chinese medical domain text. The model isavailable in two versions, namely, base and large, with correspondingperplexity values of 8.64 and 8.01. Additionally, we incorporate lexical andentity embeddings into the dialogue text in a uniform manner to meet therequirements of downstream dialogue generation tasks. By applying bothfine-tuning and p-tuning to CMed-GPT, we lowered the PPL from 8.44 to 7.35.This study not only confirms the exceptional performance of the CMed-GPT modelin generating Chinese biomedical text but also highlights the advantages ofp-tuning over traditional fine-tuning with prefix prompts. Furthermore, wevalidate the significance of incorporating external information in medicaldialogue generation, which enhances the quality of dialogue generation.</description><author>Zhijie Qu, Juan Li, Zerui Ma, Jianqiang Li</author><pubDate>Fri, 24 Nov 2023 15:10:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14539v1</guid></item><item><title>Fair Data Representation for Machine Learning at the Pareto Frontier</title><link>http://arxiv.org/abs/2201.00292v4</link><description>As machine learning powered decision-making becomes increasingly important inour daily lives, it is imperative to strive for fairness in the underlying dataprocessing. We propose a pre-processing algorithm for fair data representationvia which supervised learning results in estimations of the Pareto frontierbetween prediction error and statistical disparity. Particularly, the presentwork applies the optimal affine transport to approach the post-processingWasserstein-2 barycenter characterization of the optimal fair $L^2$-objectivesupervised learning via a pre-processing data deformation. Furthermore, we showthat the Wasserstein-2 geodesics from the conditional (on sensitiveinformation) distributions of the learning outcome to their barycentercharacterizes the Pareto frontier between $L^2$-loss and the average pairwiseWasserstein-2 distance among sensitive groups on the learning outcome.Numerical simulations underscore the advantages: (1) the pre-processing step iscompositive with arbitrary conditional expectation estimation supervisedlearning methods and unseen data; (2) the fair representation protects thesensitive information by limiting the inference capability of the remainingdata with respect to the sensitive data; (3) the optimal affine maps arecomputationally efficient even for high-dimensional data.</description><author>Shizhou Xu, Thomas Strohmer</author><pubDate>Fri, 24 Nov 2023 15:06:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2201.00292v4</guid></item><item><title>GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Accurate Speech Emotion Recognition</title><link>http://arxiv.org/abs/2306.07848v9</link><description>Contrastive cross-modality pretraining has recently exhibited impressivesuccess in diverse fields, whereas there is limited research on their merits inspeech emotion recognition (SER). In this paper, we propose GEmo-CLAP, a kindof gender-attribute-enhanced contrastive language-audio pretraining (CLAP)method for SER. Specifically, we first construct an effective emotion CLAP(Emo-CLAP) for SER, using pre-trained text and audio encoders. Second, giventhe significance of gender information in SER, two novel multi-task learningbased GEmo-CLAP (ML-GEmo-CLAP) and soft label based GEmo-CLAP (SL-GEmo-CLAP)models are further proposed to incorporate gender information of speechsignals, forming more reasonable objectives. Experiments on IEMOCAP indicatethat our proposed two GEmo-CLAPs consistently outperform Emo-CLAP withdifferent pre-trained models. Remarkably, the proposed WavLM-based SL-GEmo-CLAPobtains the best UAR of 81.43\% and WAR of 83.16\%, which performs better thanstate-of-the-art SER methods.</description><author>Yu Pan, Yanni Hu, Yuguang Yang, Wen Fei, Jixun Yao, Heng Lu, Lei Ma, Jianjun Zhao</author><pubDate>Fri, 24 Nov 2023 15:04:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.07848v9</guid></item><item><title>Finding Foundation Models for Time Series Classification with a PreText Task</title><link>http://arxiv.org/abs/2311.14534v1</link><description>Over the past decade, Time Series Classification (TSC) has gained anincreasing attention. While various methods were explored, deep learning -particularly through Convolutional Neural Networks (CNNs)-stands out as aneffective approach. However, due to the limited availability of training data,defining a foundation model for TSC that overcomes the overfitting problem isstill a challenging task. The UCR archive, encompassing a wide spectrum ofdatasets ranging from motion recognition to ECG-based heart disease detection,serves as a prime example for exploring this issue in diverse TSC scenarios. Inthis paper, we address the overfitting challenge by introducing pre-traineddomain foundation models. A key aspect of our methodology is a novel pretexttask that spans multiple datasets. This task is designed to identify theoriginating dataset of each time series sample, with the goal of creatingflexible convolution filters that can be applied across different datasets. Theresearch process consists of two phases: a pre-training phase where the modelacquires general features through the pretext task, and a subsequentfine-tuning phase for specific dataset classifications. Our extensiveexperiments on the UCR archive demonstrate that this pre-training strategysignificantly outperforms the conventional training approach withoutpre-training. This strategy effectively reduces overfitting in small datasetsand provides an efficient route for adapting these models to new datasets, thusadvancing the capabilities of deep learning in TSC.</description><author>Ali Ismail-Fawaz, Maxime Devanne, Stefano Berretti, Jonathan Weber, Germain Forestier</author><pubDate>Fri, 24 Nov 2023 15:03:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14534v1</guid></item><item><title>FIKIT: Priority-Based Real-time GPU Multi-tasking Scheduling with Kernel Identification</title><link>http://arxiv.org/abs/2311.10359v2</link><description>Highly parallelized workloads like machine learning training, inferences andgeneral HPC tasks are greatly accelerated using GPU devices. In a cloudcomputing cluster, serving a GPU's computation power through multi-taskssharing is highly demanded since there are always more task requests than thenumber of GPU available. Existing GPU sharing solutions focus on reducingtask-level waiting time or task-level switching costs when multiple jobscompeting for a single GPU. Non-stopped computation requests come withdifferent priorities, having non-symmetric impact on QoS for sharing a GPUdevice. Existing work missed the kernel-level optimization opportunity broughtby this setting. To address this problem, we present a novel kernel-levelscheduling strategy called FIKIT: Filling Inter-kernel Idle Time. FIKITincorporates task-level priority information, fine-grained kernelidentification, and kernel measurement, allowing low priorities task'sexecution during high priority task's inter-kernel idle time. Thereby, fillingthe GPU's device runtime fully, and reduce overall GPU sharing impact to cloudservices. Across a set of ML models, the FIKIT based inference systemaccelerated high priority tasks by 1.33 to 14.87 times compared to the JCT inGPU sharing mode, and more than half of the cases are accelerated by more than3.5 times. Alternatively, under preemptive sharing, the low-priority tasks havea comparable to default GPU sharing mode JCT, with a 0.84 to 1 times ratio. Wefurther limit the kernel measurement and runtime fine-grained kernel schedulingoverhead to less than 10%.</description><author>Wenqing Wu</author><pubDate>Fri, 24 Nov 2023 14:59:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.10359v2</guid></item><item><title>Comparing Feature Engineering and End-to-End Deep Learning for Autism Spectrum Disorder Assessment based on Fullbody-Tracking</title><link>http://arxiv.org/abs/2311.14533v1</link><description>Autism Spectrum Disorder (ASD) is characterized by challenges in socialcommunication and restricted patterns, with motor abnormalities gainingtraction for early detection. However, kinematic analysis in ASD is limited,often lacking robust validation and relying on hand-crafted features for singletasks, leading to inconsistencies across studies. Thus, end-to-end models havebecome promising methods to overcome the need for feature engineering. Our aimis to assess both approaches across various kinematic tasks to measure theefficacy of commonly used features in ASD assessment, while comparing them toend-to-end models. Specifically, we developed a virtual reality environmentwith multiple motor tasks and trained models using both classificationapproaches. We prioritized a reliable validation framework with repeatedcross-validation. Our comparative analysis revealed that hand-crafted featuresoutperformed our deep learning approach in specific tasks, achieving astate-of-the-art area under the curve (AUC) of 0.90$\pm$0.06. Conversely,end-to-end models provided more consistent results with less variability acrossall VR tasks, demonstrating domain generalization and reliability, with amaximum task AUC of 0.89$\pm$0.06. These findings show that end-to-end modelsenable less variable and context-independent ASD assessments without requiringdomain knowledge or task specificity. However, they also recognize theeffectiveness of hand-crafted features in specific task scenarios.</description><author>Alberto Altozano, Maria Eleonora Minissi, Mariano Alcañiz, Javier Marín-Morales</author><pubDate>Fri, 24 Nov 2023 14:56:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14533v1</guid></item><item><title>Digital Twin-Native AI-Driven Service Architecture for Industrial Networks</title><link>http://arxiv.org/abs/2311.14532v1</link><description>The dramatic increase in the connectivity demand results in an excessiveamount of Internet of Things (IoT) sensors. To meet the management needs ofthese large-scale networks, such as accurate monitoring and learningcapabilities, Digital Twin (DT) is the key enabler. However, current attemptsregarding DT implementations remain insufficient due to the perpetualconnectivity requirements of IoT networks. Furthermore, the sensor datastreaming in IoT networks cause higher processing time than traditionalmethods. In addition to these, the current intelligent mechanisms cannotperform well due to the spatiotemporal changes in the implemented IoT networkscenario. To handle these challenges, we propose a DT-native AI-driven servicearchitecture in support of the concept of IoT networks. Within the proposedDT-native architecture, we implement a TCP-based data flow pipeline and aReinforcement Learning (RL)-based learner model. We apply the proposedarchitecture to one of the broad concepts of IoT networks, the Internet ofVehicles (IoV). We measure the efficiency of our proposed architecture and note~30% processing time-saving thanks to the TCP-based data flow pipeline.Moreover, we test the performance of the learner model by applying severallearning rate combinations for actor and critic networks and highlight the mostsuccessive model.</description><author>Kubra Duran, Matthew Broadbent, Gokhan Yurdakul, Berk Canberk</author><pubDate>Fri, 24 Nov 2023 14:56:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14532v1</guid></item><item><title>Machine Translation for Ge'ez Language</title><link>http://arxiv.org/abs/2311.14530v1</link><description>Machine translation (MT) for low-resource languages such as Ge'ez, an ancientlanguage that is no longer spoken in daily life, faces challenges such asout-of-vocabulary words, domain mismatches, and lack of sufficient labeledtraining data. In this work, we explore various methods to improve Ge'ez MT,including transfer-learning from related languages, optimizing sharedvocabulary and token segmentation approaches, finetuning large pre-trainedmodels, and using large language models (LLMs) for few-shot translation withfuzzy matches. We develop a multilingual neural machine translation (MNMT)model based on languages relatedness, which brings an average performanceimprovement of about 4 BLEU compared to standard bilingual models. We alsoattempt to finetune the NLLB-200 model, one of the most advanced translationmodels available today, but find that it performs poorly with only 4k trainingsamples for Ge'ez. Furthermore, we experiment with using GPT-3.5, astate-of-the-art LLM, for few-shot translation with fuzzy matches, whichleverages embedding similarity-based retrieval to find context examples from aparallel corpus. We observe that GPT-3.5 achieves a remarkable BLEU score of9.2 with no initial knowledge of Ge'ez, but still lower than the MNMT baselineof 15.2. Our work provides insights into the potential and limitations ofdifferent approaches for low-resource and ancient language MT.</description><author>Aman Kassahun Wassie</author><pubDate>Fri, 24 Nov 2023 14:55:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14530v1</guid></item><item><title>Real Robot Challenge 2022: Learning Dexterous Manipulation from Offline Data in the Real World</title><link>http://arxiv.org/abs/2308.07741v3</link><description>Experimentation on real robots is demanding in terms of time and costs. Forthis reason, a large part of the reinforcement learning (RL) community usessimulators to develop and benchmark algorithms. However, insights gained insimulation do not necessarily translate to real robots, in particular for tasksinvolving complex interactions with the environment. The Real Robot Challenge2022 therefore served as a bridge between the RL and robotics communities byallowing participants to experiment remotely with a real robot - as easily asin simulation. In the last years, offline reinforcement learning has matured into apromising paradigm for learning from pre-collected datasets, alleviating thereliance on expensive online interactions. We therefore asked the participantsto learn two dexterous manipulation tasks involving pushing, grasping, andin-hand orientation from provided real-robot datasets. An extensive softwaredocumentation and an initial stage based on a simulation of the real set-upmade the competition particularly accessible. By giving each team plenty ofaccess budget to evaluate their offline-learned policies on a cluster of sevenidentical real TriFinger platforms, we organized an exciting competition formachine learners and roboticists alike. In this work we state the rules of the competition, present the methods usedby the winning teams and compare their results with a benchmark ofstate-of-the-art offline RL algorithms on the challenge datasets.</description><author>Nico Gürtler, Felix Widmaier, Cansu Sancaktar, Sebastian Blaes, Pavel Kolev, Stefan Bauer, Manuel Wüthrich, Markus Wulfmeier, Martin Riedmiller, Arthur Allshire, Qiang Wang, Robert McCarthy, Hangyeol Kim, Jongchan Baek, Wookyong Kwon, Shanliang Qian, Yasunori Toshimitsu, Mike Yan Michelis, Amirhossein Kazemipour, Arman Raayatsanati, Hehui Zheng, Barnabas Gavin Cangan, Bernhard Schölkopf, Georg Martius</author><pubDate>Fri, 24 Nov 2023 14:53:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07741v3</guid></item><item><title>On Neural Quantum Support Vector Machines</title><link>http://arxiv.org/abs/2308.08467v2</link><description>In \cite{simon2023algorithms} we introduced four algorithms for the trainingof neural support vector machines (NSVMs) and demonstrated their feasibility.In this note we introduce neural quantum support vector machines, that is,NSVMs with a quantum kernel, and extend our results to this setting.</description><author>Lars Simon, Manuel Radons</author><pubDate>Fri, 24 Nov 2023 14:52:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.08467v2</guid></item><item><title>GaussianEditor: Swift and Controllable 3D Editing with Gaussian Splatting</title><link>http://arxiv.org/abs/2311.14521v1</link><description>3D editing plays a crucial role in many areas such as gaming and virtualreality. Traditional 3D editing methods, which rely on representations likemeshes and point clouds, often fall short in realistically depicting complexscenes. On the other hand, methods based on implicit 3D representations, likeNeural Radiance Field (NeRF), render complex scenes effectively but suffer fromslow processing speeds and limited control over specific scene areas. Inresponse to these challenges, our paper presents GaussianEditor, an innovativeand efficient 3D editing algorithm based on Gaussian Splatting (GS), a novel 3Drepresentation. GaussianEditor enhances precision and control in editingthrough our proposed Gaussian semantic tracing, which traces the editing targetthroughout the training process. Additionally, we propose Hierarchical Gaussiansplatting (HGS) to achieve stabilized and fine results under stochasticgenerative guidance from 2D diffusion models. We also develop editingstrategies for efficient object removal and integration, a challenging task forexisting methods. Our comprehensive experiments demonstrate GaussianEditor'ssuperior control, efficacy, and rapid performance, marking a significantadvancement in 3D editing. Project Page:https://buaacyw.github.io/gaussian-editor/</description><author>Yiwen Chen, Zilong Chen, Chi Zhang, Feng Wang, Xiaofeng Yang, Yikai Wang, Zhongang Cai, Lei Yang, Huaping Liu, Guosheng Lin</author><pubDate>Fri, 24 Nov 2023 14:46:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14521v1</guid></item><item><title>tinyCLAP: Distilling Constrastive Language-Audio Pretrained Models</title><link>http://arxiv.org/abs/2311.14517v1</link><description>Contrastive Language-Audio Pretraining (CLAP) became of crucial importance inthe field of audio and speech processing. Its employment ranges from soundevent detection to text-to-audio generation. However, one of the mainlimitations is the considerable amount of data required in the training processand the overall computational complexity during inference. This paperinvestigates how we can reduce the complexity of contrastive language-audiopre-trained models, yielding an efficient model that we call tinyCLAP. Wederive an unimodal distillation loss from first principles and explore how thedimensionality of the shared, multimodal latent space can be reduced viapruning. TinyCLAP uses only 6% of the original Microsoft CLAP parameters with aminimal reduction (less than 5%) in zero-shot classification performance acrossthe three sound event detection datasets on which it was tested</description><author>Francesco Paissan, Elisabetta Farella</author><pubDate>Fri, 24 Nov 2023 14:45:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14517v1</guid></item><item><title>FRAD: Front-Running Attacks Detection on Ethereum using Ternary Classification Model</title><link>http://arxiv.org/abs/2311.14514v1</link><description>With the evolution of blockchain technology, the issue of transactionsecurity, particularly on platforms like Ethereum, has become increasinglycritical. Front-running attacks, a unique form of security threat, posesignificant challenges to the integrity of blockchain transactions. In theseattack scenarios, malicious actors monitor other users' transaction activities,then strategically submit their own transactions with higher fees. This ensurestheir transactions are executed before the monitored transactions are includedin the block. The primary objective of this paper is to delve into acomprehensive classification of transactions associated with front-runningattacks, which aims to equip developers with specific strategies to countereach type of attack. To achieve this, we introduce a novel detection methodnamed FRAD (Front-Running Attacks Detection on Ethereum using TernaryClassification Model). This method is specifically tailored for transactionswithin decentralized applications (DApps) on Ethereum, enabling accurateclassification of front-running attacks involving transaction displacement,insertion, and suppression. Our experimental validation reveals that theMultilayer Perceptron (MLP) classifier offers the best performance in detectingfront-running attacks, achieving an impressive accuracy rate of 84.59% andF1-score of 84.60%.</description><author>Yuheng Zhang, Pin Liu, Guojun Wang, Peiqiang Li, Wanyi Gu, Houji Chen, Xuelei Liu, Jinyao Zhu</author><pubDate>Fri, 24 Nov 2023 14:42:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14514v1</guid></item><item><title>Revisiting Large Language Models as Zero-shot Relation Extractors</title><link>http://arxiv.org/abs/2310.05028v4</link><description>Relation extraction (RE) consistently involves a certain degree of labeled orunlabeled data even if under zero-shot setting. Recent studies have shown thatlarge language models (LLMs) transfer well to new tasks out-of-the-box simplygiven a natural language prompt, which provides the possibility of extractingrelations from text without any data and parameter tuning. This work focuses onthe study of exploring LLMs, such as ChatGPT, as zero-shot relation extractors.On the one hand, we analyze the drawbacks of existing RE prompts and attempt toincorporate recent prompt techniques such as chain-of-thought (CoT) to improvezero-shot RE. We propose the summarize-and-ask (\textsc{SumAsk}) prompting, asimple prompt recursively using LLMs to transform RE inputs to the effectivequestion answering (QA) format. On the other hand, we conduct comprehensiveexperiments on various benchmarks and settings to investigate the capabilitiesof LLMs on zero-shot RE. Specifically, we have the following findings: (i)\textsc{SumAsk} consistently and significantly improves LLMs performance ondifferent model sizes, benchmarks and settings; (ii) Zero-shot prompting withChatGPT achieves competitive or superior results compared with zero-shot andfully supervised methods; (iii) LLMs deliver promising performance inextracting overlapping relations; (iv) The performance varies greatly regardingdifferent relations. Different from small language models, LLMs are effectivein handling challenge none-of-the-above (NoTA) relation.</description><author>Guozheng Li, Peng Wang, Wenjun Ke</author><pubDate>Fri, 24 Nov 2023 14:34:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.05028v4</guid></item><item><title>Multi-Class Anomaly Detection based on Regularized Discriminative Coupled hypersphere-based Feature Adaptation</title><link>http://arxiv.org/abs/2311.14506v1</link><description>In anomaly detection, identification of anomalies across diverse productcategories is a complex task. This paper introduces a new model by includingclass discriminative properties obtained by a modified RegularizedDiscriminative Variational Auto-Encoder (RD-VAE) in the feature extractionprocess of Coupled-hypersphere-based Feature Adaptation (CFA). By doing so, theproposed Regularized Discriminative Coupled-hypersphere-based FeatureAdaptation (RD-CFA), forms a solution for multi-class anomaly detection. Byusing the discriminative power of RD-VAE to capture intricate classdistributions, combined with CFA's robust anomaly detection capability, theproposed method excels in discerning anomalies across various classes.Extensive evaluations on multi-class anomaly detection and localization usingthe MVTec AD and BeanTech AD datasets showcase the effectiveness of RD-CFAcompared to eight leading contemporary methods.</description><author>Mehdi Rafiei, Alexandros Iosifidis</author><pubDate>Fri, 24 Nov 2023 14:26:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14506v1</guid></item><item><title>Regret Analysis of Learning-Based Linear Quadratic Gaussian Control with Additive Exploration</title><link>http://arxiv.org/abs/2311.02679v2</link><description>In this paper, we analyze the regret incurred by a computationally efficientexploration strategy, known as naive exploration, for controlling unknownpartially observable systems within the Linear Quadratic Gaussian (LQG)framework. We introduce a two-phase control algorithm called LQG-NAIVE, whichinvolves an initial phase of injecting Gaussian input signals to obtain asystem model, followed by a second phase of an interplay between naiveexploration and control in an episodic fashion. We show that LQG-NAIVE achievesa regret growth rate of $\tilde{\mathcal{O}}(\sqrt{T})$, i.e.,$\mathcal{O}(\sqrt{T})$ up to logarithmic factors after $T$ time steps, and wevalidate its performance through numerical simulations. Additionally, wepropose LQG-IF2E, which extends the exploration signal to a `closed-loop'setting by incorporating the Fisher Information Matrix (FIM). We providecompelling numerical evidence of the competitive performance of LQG-IF2Ecompared to LQG-NAIVE.</description><author>Archith Athrey, Othmane Mazhar, Meichen Guo, Bart De Schutter, Shengling Shi</author><pubDate>Fri, 24 Nov 2023 14:25:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.02679v2</guid></item><item><title>MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement Understanding</title><link>http://arxiv.org/abs/2301.00876v3</link><description>Reading comprehension of legal text can be a particularly challenging taskdue to the length and complexity of legal clauses and a shortage ofexpert-annotated datasets. To address this challenge, we introduce the MergerAgreement Understanding Dataset (MAUD), an expert-annotated readingcomprehension dataset based on the American Bar Association's 2021 PublicTarget Deal Points Study, with over 39,000 examples and over 47,000 totalannotations. Our fine-tuned Transformer baselines show promising results, withmodels performing well above random on most questions. However, on a largesubset of questions, there is still room for significant improvement. As theonly expert-annotated merger agreement dataset, MAUD is valuable as a benchmarkfor both the legal profession and the NLP community.</description><author>Steven H. Wang, Antoine Scardigli, Leonard Tang, Wei Chen, Dimitry Levkin, Anya Chen, Spencer Ball, Thomas Woodside, Oliver Zhang, Dan Hendrycks</author><pubDate>Fri, 24 Nov 2023 14:24:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.00876v3</guid></item><item><title>Analysing the Impact of Removing Infrequent Words on Topic Quality in LDA Models</title><link>http://arxiv.org/abs/2311.14505v1</link><description>An initial procedure in text-as-data applications is text preprocessing. Oneof the typical steps, which can substantially facilitate computations, consistsin removing infrequent words believed to provide limited information about thecorpus. Despite popularity of vocabulary pruning, not many guidelines on how toimplement it are available in the literature. The aim of the paper is to fillthis gap by examining the effects of removing infrequent words for the qualityof topics estimated using Latent Dirichlet Allocation. The analysis is based onMonte Carlo experiments taking into account different criteria for infrequentterms removal and various evaluation metrics. The results indicate that pruningis beneficial and that the share of vocabulary which might be eliminated can bequite considerable.</description><author>Victor Bystrov, Viktoriia Naboka-Krell, Anna Staszewska-Bystrova, Peter Winker</author><pubDate>Fri, 24 Nov 2023 14:20:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14505v1</guid></item><item><title>StableSSM: Alleviating the Curse of Memory in State-space Models through Stable Reparameterization</title><link>http://arxiv.org/abs/2311.14495v1</link><description>In this paper, we investigate the long-term memory learning capabilities ofstate-space models (SSMs) from the perspective of parameterization. We provethat state-space models without any reparameterization exhibit a memorylimitation similar to that of traditional RNNs: the target relationships thatcan be stably approximated by state-space models must have an exponentialdecaying memory. Our analysis identifies this "curse of memory" as a result ofthe recurrent weights converging to a stability boundary, suggesting that areparameterization technique can be effective. To this end, we introduce aclass of reparameterization techniques for SSMs that effectively lift itsmemory limitations. Besides improving approximation capabilities, we furtherillustrate that a principled choice of reparameterization scheme can alsoenhance optimization stability. We validate our findings using syntheticdatasets and language models.</description><author>Shida Wang, Qianxiao Li</author><pubDate>Fri, 24 Nov 2023 14:08:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14495v1</guid></item><item><title>MVControl: Adding Conditional Control to Multi-view Diffusion for Controllable Text-to-3D Generation</title><link>http://arxiv.org/abs/2311.14494v1</link><description>We introduce MVControl, a novel neural network architecture that enhancesexisting pre-trained multi-view 2D diffusion models by incorporating additionalinput conditions, e.g. edge maps. Our approach enables the generation ofcontrollable multi-view images and view-consistent 3D content. To achievecontrollable multi-view image generation, we leverage MVDream as our basemodel, and train a new neural network module as additional plugin forend-to-end task-specific condition learning. To precisely control the shapesand views of generated images, we innovatively propose a new conditioningmechanism that predicts an embedding encapsulating the input spatial and viewconditions, which is then injected to the network globally. Once MVControl istrained, score-distillation (SDS) loss based optimization can be performed togenerate 3D content, in which process we propose to use a hybrid diffusionprior. The hybrid prior relies on a pre-trained Stable-Diffusion network andour trained MVControl for additional guidance. Extensive experimentsdemonstrate that our method achieves robust generalization and enables thecontrollable generation of high-quality 3D content.</description><author>Zhiqi Li, Yiming Chen, Lingzhe Zhao, Peidong Liu</author><pubDate>Fri, 24 Nov 2023 14:07:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14494v1</guid></item><item><title>Benchmarking Multimodal Variational Autoencoders: CdSprites+ Dataset and Toolkit</title><link>http://arxiv.org/abs/2209.03048v2</link><description>Multimodal Variational Autoencoders (VAEs) have been the subject of intenseresearch in the past years as they can integrate multiple modalities into ajoint representation and can thus serve as a promising tool for both dataclassification and generation. Several approaches toward multimodal VAElearning have been proposed so far, their comparison and evaluation havehowever been rather inconsistent. One reason is that the models differ at theimplementation level, another problem is that the datasets commonly used inthese cases were not initially designed to evaluate multimodal generativemodels. This paper addresses both mentioned issues. First, we propose a toolkitfor systematic multimodal VAE training and comparison. The toolkit currentlycomprises 4 existing multimodal VAEs and 6 commonly used benchmark datasetsalong with instructions on how to easily add a new model or a dataset. Second,we present a disentangled bimodal dataset designed to comprehensively evaluatethe joint generation and cross-generation capabilities across multipledifficulty levels. We demonstrate the utility of our dataset by comparing theimplemented state-of-the-art models.</description><author>Gabriela Sejnova, Michal Vavrecka, Karla Stepanova</author><pubDate>Fri, 24 Nov 2023 14:00:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2209.03048v2</guid></item><item><title>Sharing pattern submodels for prediction with missing values</title><link>http://arxiv.org/abs/2206.11161v3</link><description>Missing values are unavoidable in many applications of machine learning andpresent challenges both during training and at test time. When variables aremissing in recurring patterns, fitting separate pattern submodels have beenproposed as a solution. However, fitting models independently does not makeefficient use of all available data. Conversely, fitting a single shared modelto the full data set relies on imputation which often leads to biased resultswhen missingness depends on unobserved factors. We propose an alternativeapproach, called sharing pattern submodels, which i) makes predictions that arerobust to missing values at test time, ii) maintains or improves the predictivepower of pattern submodels, and iii) has a short description, enabling improvedinterpretability. Parameter sharing is enforced through sparsity-inducingregularization which we prove leads to consistent estimation. Finally, we giveconditions for when a sharing model is optimal, even when both missingness andthe target outcome depend on unobserved variables. Classification andregression experiments on synthetic and real-world data sets demonstrate thatour models achieve a favorable tradeoff between pattern specialization andinformation sharing.</description><author>Lena Stempfle, Ashkan Panahi, Fredrik D. Johansson</author><pubDate>Fri, 24 Nov 2023 13:50:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2206.11161v3</guid></item><item><title>Towards Interpretable Classification of Leukocytes based on Deep Learning</title><link>http://arxiv.org/abs/2311.14485v1</link><description>Label-free approaches are attractive in cytological imaging due to theirflexibility and cost efficiency. They are supported by machine learningmethods, which, despite the lack of labeling and the associated lower contrast,can classify cells with high accuracy where the human observer has littlechance to discriminate cells. In order to better integrate these workflows intothe clinical decision making process, this work investigates the calibration ofconfidence estimation for the automated classification of leukocytes. Inaddition, different visual explanation approaches are compared, which shouldbring machine decision making closer to professional healthcare applications.Furthermore, we were able to identify general detection patterns in neuralnetworks and demonstrate the utility of the presented approaches in differentscenarios of blood cell analysis.</description><author>Stefan Röhrl, Johannes Groll, Manuel Lengl, Simon Schumann, Christian Klenk, Dominik Heim, Martin Knopp, Oliver Hayden, Klaus Diepold</author><pubDate>Fri, 24 Nov 2023 13:48:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14485v1</guid></item><item><title>SER_AMPEL: A multi-source dataset for SER of Italian older adults</title><link>http://arxiv.org/abs/2311.14483v1</link><description>In this paper, SER_AMPEL, a multi-source dataset for speech emotionrecognition (SER) is presented. The peculiarity of the dataset is that it iscollected with the aim of providing a reference for speech emotion recognitionin case of Italian older adults. The dataset is collected following differentprotocols, in particular considering acted conversations, extracted from moviesand TV series, and recording natural conversations where the emotions areelicited by proper questions. The evidence of the need for such a datasetemerges from the analysis of the state of the art. Preliminary considerationson the critical issues of SER are reported analyzing the classification resultson a subset of the proposed dataset.</description><author>Alessandra Grossi, Francesca Gasparini</author><pubDate>Fri, 24 Nov 2023 13:47:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14483v1</guid></item><item><title>Sliding Window FastEdit: A Framework for Lesion Annotation in Whole-body PET Images</title><link>http://arxiv.org/abs/2311.14482v1</link><description>Deep learning has revolutionized the accurate segmentation of diseases inmedical imaging. However, achieving such results requires training withnumerous manual voxel annotations. This requirement presents a challenge forwhole-body Positron Emission Tomography (PET) imaging, where lesions arescattered throughout the body. To tackle this problem, we introduce SW-FastEdit- an interactive segmentation framework that accelerates the labeling byutilizing only a few user clicks instead of voxelwise annotations. While priorinteractive models crop or resize PET volumes due to memory constraints, we usethe complete volume with our sliding window-based interactive scheme. Our modeloutperforms existing non-sliding window interactive models on the AutoPETdataset and generalizes to the previously unseen HECKTOR dataset. A user studyrevealed that annotators achieve high-quality predictions with only 10 clickiterations and a low perceived NASA-TLX workload. Our framework is implementedusing MONAI Label and is available:https://github.com/matt3o/AutoPET2-Submission/</description><author>Matthias Hadlich, Zdravko Marinov, Moon Kim, Enrico Nasca, Jens Kleesiek, Rainer Stiefelhagen</author><pubDate>Fri, 24 Nov 2023 13:45:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14482v1</guid></item><item><title>Post-COVID Highlights: Challenges and Solutions of AI Techniques for Swift Identification of COVID-19</title><link>http://arxiv.org/abs/2311.06258v2</link><description>Since the onset of the COVID-19 pandemic in 2019, there has been a concertedeffort to develop cost-effective, non-invasive, and rapid AI-based tools. Thesetools were intended to alleviate the burden on healthcare systems, control therapid spread of the virus, and enhance intervention outcomes, all in responseto this unprecedented global crisis. As we transition into a post-COVID era, weretrospectively evaluate these proposed studies and offer a review of thetechniques employed in AI diagnostic models, with a focus on the solutionsproposed for different challenges. This review endeavors to provide insightsinto the diverse solutions designed to address the multifaceted challenges thatarose during the pandemic. By doing so, we aim to prepare the AI community forthe development of AI tools tailored to address public health emergencieseffectively.</description><author>Yingying Fang, Xiaodan Xing, Shiyi Wang, Simon Walsh, Guang Yang</author><pubDate>Fri, 24 Nov 2023 13:44:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06258v2</guid></item><item><title>Evolutionary game theory: the mathematics of evolution and collective behaviours</title><link>http://arxiv.org/abs/2311.14480v1</link><description>This brief discusses evolutionary game theory as a powerful and unifiedmathematical tool to study evolution of collective behaviours. It summarisessome of my recent research directions using evolutionary game theory methods,which include i) the analysis of statistical properties of the number of(stable) equilibria in a random evolutionary game, and ii) the modelling ofsafety behaviours' evolution and the risk posed by advanced ArtificialIntelligence technologies in a technology development race. Finally, itincludes an outlook and some suggestions for future researchers.</description><author>The Anh Han</author><pubDate>Fri, 24 Nov 2023 13:42:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14480v1</guid></item><item><title>Controlled Text Generation via Language Model Arithmetic</title><link>http://arxiv.org/abs/2311.14479v1</link><description>As Large Language Models (LLMs) are deployed more widely, customization withrespect to vocabulary, style and character becomes more important. In this workwe introduce model arithmetic, a novel inference framework for composing andbiasing LLMs without the need for model (re)training or highly specificdatasets. In addition, the framework allows for more precise control ofgenerated text than direct prompting and prior controlled text generation (CTG)techniques. Using model arithmetic, we can express prior CTG techniques assimple formulas and naturally extend them to new and more effectiveformulations. Further, we show that speculative sampling, a technique forefficient LLM sampling, extends to our setting. This enables highly efficienttext generation with multiple composed models with only marginal overhead overa single model. Our empirical evaluation demonstrates that model arithmeticallows fine-grained control of generated text while outperformingstate-of-the-art on the task of toxicity reduction.</description><author>Jasper Dekoninck, Marc Fischer, Luca Beurer-Kellner, Martin Vechev</author><pubDate>Fri, 24 Nov 2023 13:41:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14479v1</guid></item><item><title>PEAR: Primitive enabled Adaptive Relabeling for boosting Hierarchical Reinforcement Learning</title><link>http://arxiv.org/abs/2306.06394v4</link><description>Hierarchical reinforcement learning (HRL) has the potential to solve complexlong horizon tasks using temporal abstraction and increased exploration.However, hierarchical agents are difficult to train due to inherentnon-stationarity. We present primitive enabled adaptive relabeling (PEAR), atwo-phase approach where we first perform adaptive relabeling on a few expertdemonstrations to generate efficient subgoal supervision, and then jointlyoptimize HRL agents by employing reinforcement learning (RL) and imitationlearning (IL). We perform theoretical analysis to $(i)$ bound thesub-optimality of our approach, and $(ii)$ derive a generalized plug-and-playframework for joint optimization using RL and IL. PEAR uses a handful of expertdemonstrations and makes minimal limiting assumptions on the task structure.Additionally, it can be easily integrated with typical model free RL algorithmsto produce a practical HRL algorithm. We perform experiments on challengingrobotic environments and show that PEAR is able to solve tasks that requirelong term decision making. We empirically show that PEAR exhibits improvedperformance and sample efficiency over previous hierarchical andnon-hierarchical approaches. We also perform real world robotic experiments oncomplex tasks and demonstrate that PEAR consistently outperforms the baselines.</description><author>Utsav Singh, Vinay P Namboodiri</author><pubDate>Fri, 24 Nov 2023 13:40:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.06394v4</guid></item><item><title>Physics-Informed Graph Convolutional Networks: Towards a generalized framework for complex geometries</title><link>http://arxiv.org/abs/2310.14948v4</link><description>Since the seminal work of [9] and their Physics-Informed neural networks(PINNs), many efforts have been conducted towards solving partial differentialequations (PDEs) with Deep Learning models. However, some challenges remain,for instance the extension of such models to complex three-dimensionalgeometries, and a study on how such approaches could be combined to classicalnumerical solvers. In this work, we justify the use of graph neural networksfor these problems, based on the similarity between these architectures and themeshes used in traditional numerical techniques for solving partialdifferential equations. After proving an issue with the Physics-Informedframework for complex geometries, during the computation of PDE residuals, analternative procedure is proposed, by combining classical numerical solvers andthe Physics-Informed framework. Finally, we propose an implementation of thisapproach, that we test on a three-dimensional problem on an irregular geometry.</description><author>Marien Chenaud, José Alves, Frédéric Magoulès</author><pubDate>Fri, 24 Nov 2023 13:33:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.14948v4</guid></item><item><title>An Initialization Schema for Neuronal Networks on Tabular Data</title><link>http://arxiv.org/abs/2311.03996v2</link><description>Nowadays, many modern applications require heterogeneous tabular data, whichis still a challenging task in terms of regression and classification. Manyapproaches have been proposed to adapt neural networks for this task, butstill, boosting and bagging of decision trees are the best-performing methodsfor this task. In this paper, we show that a binomial initialized neuralnetwork can be used effectively on tabular data. The proposed approach shows asimple but effective approach for initializing the first hidden layer in neuralnetworks. We also show that this initializing schema can be used to jointlytrain ensembles by adding gradient masking to batch entries and using thebinomial initialization for the last layer in a neural network. For thispurpose, we modified the hinge binary loss and the soft max loss to make themapplicable for joint ensemble training. We evaluate our approach on multiplepublic datasets and showcase the improved performance compared to other neuralnetwork-based approaches. In addition, we discuss the limitations and possiblefurther research of our approach for improving the applicability of neuralnetworks to tabular data. Link:https://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FInitializationNeuronalNetworksTabularData&amp;mode=list</description><author>Wolfgang Fuhl</author><pubDate>Fri, 24 Nov 2023 13:28:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.03996v2</guid></item><item><title>Joint Diffusion: Mutual Consistency-Driven Diffusion Model for PET-MRI Co-Reconstruction</title><link>http://arxiv.org/abs/2311.14473v1</link><description>Positron Emission Tomography and Magnetic Resonance Imaging (PET-MRI) systemscan obtain functional and anatomical scans. PET suffers from a lowsignal-to-noise ratio. Meanwhile, the k-space data acquisition process in MRIis time-consuming. The study aims to accelerate MRI and enhance PET imagequality. Conventional approaches involve the separate reconstruction of eachmodality within PET-MRI systems. However, there exists complementaryinformation among multi-modal images. The complementary information cancontribute to image reconstruction. In this study, we propose a novel PET-MRIjoint reconstruction model employing a mutual consistency-driven diffusionmode, namely MC-Diffusion. MC-Diffusion learns the joint probabilitydistribution of PET and MRI for utilizing complementary information. Weconducted a series of contrast experiments about LPLS, Joint ISAT-net andMC-Diffusion by the ADNI dataset. The results underscore the qualitative andquantitative improvements achieved by MC-Diffusion, surpassing thestate-of-the-art method.</description><author>Taofeng Xie, Zhuo-Xu Cui, Chen Luo, Huayu Wang, Congcong Liu, Yuanzhi Zhang, Xuemei Wang, Yanjie Zhu, Qiyu Jin, Guoqing Chen, Yihang Zhou, Dong Liang, Haifeng Wang</author><pubDate>Fri, 24 Nov 2023 13:26:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14473v1</guid></item><item><title>MRxaI: Black-Box Explainability for Image Classifiers in a Medical Setting</title><link>http://arxiv.org/abs/2311.14471v1</link><description>Existing tools for explaining the output of image classifiers can be dividedinto white-box, which rely on access to the model internals, and black-box,agnostic to the model. As the usage of AI in the medical domain grows, so toodoes the usage of explainability tools. Existing work on medical imageexplanations focuses on white-box tools, such as gradcam. However, there areclear advantages to switching to a black-box tool, including the ability to useit with any classifier and the wide selection of black-box tools available. Onstandard images, black-box tools are as precise as white-box. In this paper wecompare the performance of several black-box methods against gradcam on a braincancer MRI dataset. We demonstrate that most black-box tools are not suitablefor explaining medical image classifications and present a detailed analysis ofthe reasons for their shortcomings. We also show that one black-box tool, acausal explainability-based rex, performs as well as \gradcam.</description><author>Nathan Blake, Hana Chockler, David A. Kelly, Santiago Calderon Pena, Akchunya Chanchal</author><pubDate>Fri, 24 Nov 2023 13:25:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14471v1</guid></item><item><title>Fault Detection in Telecom Networks using Bi-level Federated Graph Neural Networks</title><link>http://arxiv.org/abs/2311.14469v1</link><description>5G and Beyond Networks become increasingly complex and heterogeneous, withdiversified and high requirements from a wide variety of emerging applications.The complexity and diversity of Telecom networks place an increasing strain onmaintenance and operation efforts. Moreover, the strict security and privacyrequirements present a challenge for mobile operators to leverage network data.To detect network faults, and mitigate future failures, prior work focused onleveraging traditional ML/DL methods to locate anomalies in networks. Thecurrent approaches, although powerful, do not consider the intertwined natureof embedded and software-intensive Radio Access Network systems. In this paper,we propose a Bi-level Federated Graph Neural Network anomaly detection anddiagnosis model that is able to detect anomalies in Telecom networks in aprivacy-preserving manner, while minimizing communication costs. Our methodrevolves around conceptualizing Telecom data as a bi-level temporal GraphNeural Networks. The first graph captures the interactions between differentRAN nodes that are exposed to different deployment scenarios in the network,while each individual Radio Access Network node is further elaborated into itssoftware (SW) execution graph. Additionally, we use Federated Learning toaddress privacy and security limitations. Furthermore, we study the performanceof anomaly detection model under three settings: (1) Centralized (2) FederatedLearning and (3) Personalized Federated Learning using real-world data from anoperational network. Our comprehensive experiments showed that PersonalizedFederated Temporal Graph Neural Networks method outperforms the most commonlyused techniques for Anomaly Detection.</description><author>R. Bourgerie, T. Zanouda</author><pubDate>Fri, 24 Nov 2023 13:23:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14469v1</guid></item><item><title>Efficient Gradient Estimation via Adaptive Sampling and Importance Sampling</title><link>http://arxiv.org/abs/2311.14468v1</link><description>Machine learning problems rely heavily on stochastic gradient descent (SGD)for optimization. The effectiveness of SGD is contingent upon accuratelyestimating gradients from a mini-batch of data samples. Instead of the commonlyused uniform sampling, adaptive or importance sampling reduces noise ingradient estimation by forming mini-batches that prioritize crucial datapoints. Previous research has suggested that data points should be selectedwith probabilities proportional to their gradient norm. Nevertheless, existingalgorithms have struggled to efficiently integrate importance sampling intomachine learning frameworks. In this work, we make two contributions. First, wepresent an algorithm that can incorporate existing importance functions intoour framework. Second, we propose a simplified importance function that reliessolely on the loss gradient of the output layer. By leveraging our proposedgradient estimation techniques, we observe improved convergence inclassification and regression tasks with minimal computational overhead. Wevalidate the effectiveness of our adaptive and importance-sampling approach onimage and point-cloud datasets.</description><author>Corentin Salaün, Xingchang Huang, Iliyan Georgiev, Niloy J. Mitra, Gurprit Singh</author><pubDate>Fri, 24 Nov 2023 13:21:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14468v1</guid></item><item><title>DP-NMT: Scalable Differentially-Private Machine Translation</title><link>http://arxiv.org/abs/2311.14465v1</link><description>Neural machine translation (NMT) is a widely popular text generation task,yet there is a considerable research gap in the development ofprivacy-preserving NMT models, despite significant data privacy concerns forNMT systems. Differentially private stochastic gradient descent (DP-SGD) is apopular method for training machine learning models with concrete privacyguarantees; however, the implementation specifics of training a model withDP-SGD are not always clarified in existing models, with differing softwarelibraries used and code bases not always being public, leading toreproducibility issues. To tackle this, we introduce DP-NMT, an open-sourceframework for carrying out research on privacy-preserving NMT with DP-SGD,bringing together numerous models, datasets, and evaluation metrics in onesystematic software package. Our goal is to provide a platform for researchersto advance the development of privacy-preserving NMT systems, keeping thespecific details of the DP-SGD algorithm transparent and intuitive toimplement. We run a set of experiments on datasets from both general andprivacy-related domains to demonstrate our framework in use. We make ourframework publicly available and welcome feedback from the community.</description><author>Timour Igamberdiev, Doan Nam Long Vu, Felix Künnecke, Zhuo Yu, Jannik Holmer, Ivan Habernal</author><pubDate>Fri, 24 Nov 2023 13:19:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14465v1</guid></item><item><title>Finite Volume Features, Global Geometry Representations, and Residual Training for Deep Learning-based CFD Simulation</title><link>http://arxiv.org/abs/2311.14464v1</link><description>Computational fluid dynamics (CFD) simulation is an irreplaceable modellingstep in many engineering designs, but it is often computationally expensive.Some graph neural network (GNN)-based CFD methods have been proposed. However,the current methods inherit the weakness of traditional numerical simulators,as well as ignore the cell characteristics in the mesh used in the finitevolume method, a common method in practical CFD applications. Specifically, theinput nodes in these GNN methods have very limited information about any objectimmersed in the simulation domain and its surrounding environment. Also, thecell characteristics of the mesh such as cell volume, face surface area, andface centroid are not included in the message-passing operations in the GNNmethods. To address these weaknesses, this work proposes two novel geometricrepresentations: Shortest Vector (SV) and Directional Integrated Distance(DID). Extracted from the mesh, the SV and DID provide global geometryperspective to each input node, thus removing the need to collect thisinformation through message-passing. This work also introduces the use ofFinite Volume Features (FVF) in the graph convolutions as node and edgeattributes, enabling its message-passing operations to adjust to differentnodes. Finally, this work is the first to demonstrate how residual training,with the availability of low-resolution data, can be adopted to improve theflow field prediction accuracy. Experimental results on two datasets with fivedifferent state-of-the-art GNN methods for CFD indicate that SV, DID, FVF andresidual training can effectively reduce the predictive error of currentGNN-based methods by as much as 41%.</description><author>Loh Sher En Jessica, Naheed Anjum Arafat, Wei Xian Lim, Wai Lee Chan, Adams Wai Kin Kong</author><pubDate>Fri, 24 Nov 2023 13:19:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14464v1</guid></item><item><title>CT-xCOV: a CT-scan based Explainable Framework for COVid-19 diagnosis</title><link>http://arxiv.org/abs/2311.14462v1</link><description>In this work, CT-xCOV, an explainable framework for COVID-19 diagnosis usingDeep Learning (DL) on CT-scans is developed. CT-xCOV adopts an end-to-endapproach from lung segmentation to COVID-19 detection and explanations of thedetection model's prediction. For lung segmentation, we used the well-knownU-Net model. For COVID-19 detection, we compared three different CNNarchitectures: a standard CNN, ResNet50, and DenseNet121. After the detection,visual and textual explanations are provided. For visual explanations, weapplied three different XAI techniques, namely, Grad-Cam, Integrated Gradient(IG), and LIME. Textual explanations are added by computing the percentage ofinfection by lungs. To assess the performance of the used XAI techniques, wepropose a ground-truth-based evaluation method, measuring the similaritybetween the visualization outputs and the ground-truth infections. Theperformed experiments show that the applied DL models achieved good results.The U-Net segmentation model achieved a high Dice coefficient (98%). Theperformance of our proposed classification model (standard CNN) was validatedusing 5-fold cross-validation (acc of 98.40% and f1-score 98.23%). Lastly, theresults of the comparison of XAI techniques show that Grad-Cam gives the bestexplanations compared to LIME and IG, by achieving a Dice coefficient of 55%,on COVID-19 positive scans, compared to 29% and 24% obtained by IG and LIMErespectively. The code and the dataset used in this paper are available in theGitHub repository [1].</description><author>Ismail Elbouknify, Afaf Bouhoute, Khalid Fardousse, Ismail Berrada, Abdelmajid Badri</author><pubDate>Fri, 24 Nov 2023 13:14:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14462v1</guid></item><item><title>IDD-AW: A Benchmark for Safe and Robust Segmentation of Drive Scenes in Unstructured Traffic and Adverse Weather</title><link>http://arxiv.org/abs/2311.14459v1</link><description>Large-scale deployment of fully autonomous vehicles requires a very highdegree of robustness to unstructured traffic, and weather conditions, andshould prevent unsafe mispredictions. While there are several datasets andbenchmarks focusing on segmentation for drive scenes, they are not specificallyfocused on safety and robustness issues. We introduce the IDD-AW dataset, whichprovides 5000 pairs of high-quality images with pixel-level annotations,captured under rain, fog, low light, and snow in unstructured drivingconditions. As compared to other adverse weather datasets, we provide i.) moreannotated images, ii.) paired Near-Infrared (NIR) image for each frame, iii.)larger label set with a 4-level label hierarchy to capture unstructured trafficconditions. We benchmark state-of-the-art models for semantic segmentation inIDD-AW. We also propose a new metric called ''Safe mean Intersection over Union(Safe mIoU)'' for hierarchical datasets which penalizes dangerousmispredictions that are not captured in the traditional definition of meanIntersection over Union (mIoU). The results show that IDD-AW is one of the mostchallenging datasets to date for these tasks. The dataset and code will beavailable here: http://iddaw.github.io.</description><author>Furqan Ahmed Shaik, Abhishek Malreddy, Nikhil Reddy Billa, Kunal Chaudhary, Sunny Manchanda, Girish Varma</author><pubDate>Fri, 24 Nov 2023 13:11:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14459v1</guid></item><item><title>How to ensure a safe control strategy? Towards a SRL for urban transit autonomous operation</title><link>http://arxiv.org/abs/2311.14457v1</link><description>Deep reinforcement learning has gradually shown its latent decision-makingability in urban rail transit autonomous operation. However, sincereinforcement learning can not neither guarantee safety during learning norexecution, this is still one of the major obstacles to the practicalapplication of reinforcement learning. Given this drawback, reinforcementlearning applied in the safety-critical autonomous operation domain remainschallenging without generating a safe control command sequence that avoidsoverspeed operations. Therefore, a SSA-DRL framework is proposed in this paperfor safe intelligent control of urban rail transit autonomous operation trains.The proposed framework is combined with linear temporal logic, reinforcementlearning and Monte Carlo tree search and consists of four mainly module: apost-posed shielding, a searching tree module, a DRL framework and anadditional actor. Furthermore, the output of the framework can meet speedconstraint, schedule constraint and optimize the operation process. Finally,the proposed SSA-DRL framework for decision-making in urban rail transitautonomous operation is evaluated in sixteen different sections, and itseffectiveness is demonstrated through an ablation experiment and comparisonwith the scheduled operation plan.</description><author>Zicong Zhao</author><pubDate>Fri, 24 Nov 2023 13:11:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.14457v1</guid></item></channel></rss>