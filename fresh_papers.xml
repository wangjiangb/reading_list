<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Thu, 04 Jan 2024 06:01:07 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>PressureVision++: Estimating Fingertip Pressure from Diverse RGB Images</title><link>http://arxiv.org/abs/2301.02310v3</link><description>Touch plays a fundamental role in manipulation for humans; however, machineperception of contact and pressure typically requires invasive sensors. Recentresearch has shown that deep models can estimate hand pressure based on asingle RGB image. However, evaluations have been limited to controlled settingssince collecting diverse data with ground-truth pressure measurements isdifficult. We present a novel approach that enables diverse data to be capturedwith only an RGB camera and a cooperative participant. Our key insight is thatpeople can be prompted to apply pressure in a certain way, and this prompt canserve as a weak label to supervise models to perform well under variedconditions. We collect a novel dataset with 51 participants making fingertipcontact with diverse objects. Our network, PressureVision++, outperforms humanannotators and prior work. We also demonstrate an application ofPressureVision++ to mixed reality where pressure estimation allows everydaysurfaces to be used as arbitrary touch-sensitive interfaces. Code, data, andmodels are available online.</description><author>Patrick Grady, Jeremy A. Collins, Chengcheng Tang, Christopher D. Twigg, Kunal Aneja, James Hays, Charles C. Kemp</author><pubDate>Wed, 03 Jan 2024 18:59:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.02310v3</guid></item><item><title>LEAP-VO: Long-term Effective Any Point Tracking for Visual Odometry</title><link>http://arxiv.org/abs/2401.01887v1</link><description>Visual odometry estimates the motion of a moving camera based on visualinput. Existing methods, mostly focusing on two-view point tracking, oftenignore the rich temporal context in the image sequence, thereby overlooking theglobal motion patterns and providing no assessment of the full trajectoryreliability. These shortcomings hinder performance in scenarios with occlusion,dynamic objects, and low-texture areas. To address these challenges, we presentthe Long-term Effective Any Point Tracking (LEAP) module. LEAP innovativelycombines visual, inter-track, and temporal cues with mindfully selected anchorsfor dynamic track estimation. Moreover, LEAP's temporal probabilisticformulation integrates distribution updates into a learnable iterativerefinement module to reason about point-wise uncertainty. Based on thesetraits, we develop LEAP-VO, a robust visual odometry system adept at handlingocclusions and dynamic scenes. Our mindful integration showcases a novelpractice by employing long-term point tracking as the front-end. Extensiveexperiments demonstrate that the proposed pipeline significantly outperformsexisting baselines across various visual odometry benchmarks.</description><author>Weirong Chen, Le Chen, Rui Wang, Marc Pollefeys</author><pubDate>Wed, 03 Jan 2024 18:57:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01887v1</guid></item><item><title>From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations</title><link>http://arxiv.org/abs/2401.01885v1</link><description>We present a framework for generating full-bodied photorealistic avatars thatgesture according to the conversational dynamics of a dyadic interaction. Givenspeech audio, we output multiple possibilities of gestural motion for anindividual, including face, body, and hands. The key behind our method is incombining the benefits of sample diversity from vector quantization with thehigh-frequency details obtained through diffusion to generate more dynamic,expressive motion. We visualize the generated motion using highlyphotorealistic avatars that can express crucial nuances in gestures (e.g.sneers and smirks). To facilitate this line of research, we introduce afirst-of-its-kind multi-view conversational dataset that allows forphotorealistic reconstruction. Experiments show our model generates appropriateand diverse gestures, outperforming both diffusion- and VQ-only methods.Furthermore, our perceptual evaluation highlights the importance ofphotorealism (vs. meshes) in accurately assessing subtle motion details inconversational gestures. Code and dataset available online.</description><author>Evonne Ng, Javier Romero, Timur Bagautdinov, Shaojie Bai, Trevor Darrell, Angjoo Kanazawa, Alexander Richard</author><pubDate>Wed, 03 Jan 2024 18:55:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01885v1</guid></item><item><title>Mining Temporal Attack Patterns from Cyberthreat Intelligence Reports</title><link>http://arxiv.org/abs/2401.01883v1</link><description>Defending from cyberattacks requires practitioners to operate on high-leveladversary behavior. Cyberthreat intelligence (CTI) reports on past cyberattackincidents describe the chain of malicious actions with respect to time. Toavoid repeating cyberattack incidents, practitioners must proactively identifyand defend against recurring chain of actions - which we refer to as temporalattack patterns. Automatically mining the patterns among actions providesstructured and actionable information on the adversary behavior of pastcyberattacks. The goal of this paper is to aid security practitioners inprioritizing and proactive defense against cyberattacks by mining temporalattack patterns from cyberthreat intelligence reports. To this end, we proposeChronoCTI, an automated pipeline for mining temporal attack patterns fromcyberthreat intelligence (CTI) reports of past cyberattacks. To constructChronoCTI, we build the ground truth dataset of temporal attack patterns andapply state-of-the-art large language models, natural language processing, andmachine learning techniques. We apply ChronoCTI on a set of 713 CTI reports,where we identify 124 temporal attack patterns - which we categorize into ninepattern categories. We identify that the most prevalent pattern category is totrick victim users into executing malicious code to initiate the attack,followed by bypassing the anti-malware system in the victim network. Based onthe observed patterns, we advocate organizations to train users aboutcybersecurity best practices, introduce immutable operating systems withlimited functionalities, and enforce multi-user authentications. Moreover, weadvocate practitioners to leverage the automated mining capability of ChronoCTIand design countermeasures against the recurring attack patterns.</description><author>Md Rayhanur Rahman, Brandon Wroblewski, Quinn Matthews, Brantley Morgan, Tim Menzies, Laurie Williams</author><pubDate>Wed, 03 Jan 2024 18:53:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01883v1</guid></item><item><title>The Brain Tumor Segmentation (BraTS) Challenge 2023: Focus on Pediatrics (CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs)</title><link>http://arxiv.org/abs/2305.17033v3</link><description>Pediatric tumors of the central nervous system are the most common cause ofcancer-related death in children. The five-year survival rate for high-gradegliomas in children is less than 20\%. Due to their rarity, the diagnosis ofthese entities is often delayed, their treatment is mainly based on historictreatment concepts, and clinical trials require multi-institutionalcollaborations. The MICCAI Brain Tumor Segmentation (BraTS) Challenge is alandmark community benchmark event with a successful history of 12 years ofresource creation for the segmentation and analysis of adult glioma. Here wepresent the CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs 2023 challenge, whichrepresents the first BraTS challenge focused on pediatric brain tumors withdata acquired across multiple international consortia dedicated to pediatricneuro-oncology and clinical trials. The BraTS-PEDs 2023 challenge focuses onbenchmarking the development of volumentric segmentation algorithms forpediatric brain glioma through standardized quantitative performance evaluationmetrics utilized across the BraTS 2023 cluster of challenges. Models gainingknowledge from the BraTS-PEDs multi-parametric structural MRI (mpMRI) trainingdata will be evaluated on separate validation and unseen test mpMRI dataofhigh-grade pediatric glioma. The CBTN-CONNECT-DIPGR-ASNR-MICCAI BraTS-PEDs 2023challenge brings together clinicians and AI/imaging scientists to lead tofaster development of automated segmentation techniques that could benefitclinical trials, and ultimately the care of children with brain tumors.</description><author>Anahita Fathi Kazerooni, Nastaran Khalili, Xinyang Liu, Debanjan Haldar, Zhifan Jiang, Syed Muhammed Anwar, Jake Albrecht, Maruf Adewole, Udunna Anazodo, Hannah Anderson, Sina Bagheri, Ujjwal Baid, Timothy Bergquist, Austin J. Borja, Evan Calabrese, Verena Chung, Gian-Marco Conte, Farouk Dako, James Eddy, Ivan Ezhov, Ariana Familiar, Keyvan Farahani, Shuvanjan Haldar, Juan Eugenio Iglesias, Anastasia Janas, Elaine Johansen, Blaise V Jones, Florian Kofler, Dominic LaBella, Hollie Anne Lai, Koen Van Leemput, Hongwei Bran Li, Nazanin Maleki, Aaron S McAllister, Zeke Meier, Bjoern Menze, Ahmed W Moawad, Khanak K Nandolia, Julija Pavaine, Marie Piraud, Tina Poussaint, Sanjay P Prabhu, Zachary Reitman, Andres Rodriguez, Jeffrey D Rudie, Ibraheem Salman Shaikh, Lubdha M. Shah, Nakul Sheth, Russel</author><pubDate>Wed, 03 Jan 2024 18:41:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.17033v3</guid></item><item><title>Theoretical guarantees on the best-of-n alignment policy</title><link>http://arxiv.org/abs/2401.01879v1</link><description>A simple and effective method for the alignment of generative models is thebest-of-$n$ policy, where $n$ samples are drawn from a base policy, and rankedbased on a reward function, and the highest ranking one is selected. A commonlyused analytical expression in the literature claims that the KL divergencebetween the best-of-$n$ policy and the base policy is equal to $\log (n) -(n-1)/n.$ We disprove the validity of this claim, and show that it is an upperbound on the actual KL divergence. We also explore the tightness of this upperbound in different regimes. Finally, we propose a new estimator for the KLdivergence and empirically show that it provides a tight approximation througha few examples.</description><author>Ahmad Beirami, Alekh Agarwal, Jonathan Berant, Alexander D'Amour, Jacob Eisenstein, Chirag Nagpal, Ananda Theertha Suresh</author><pubDate>Wed, 03 Jan 2024 18:39:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01879v1</guid></item><item><title>Graph Neural Networks for Surfactant Multi-Property Prediction</title><link>http://arxiv.org/abs/2401.01874v1</link><description>Surfactants are of high importance in different industrial sectors such ascosmetics, detergents, oil recovery and drug delivery systems. Therefore, manyquantitative structure-property relationship (QSPR) models have been developedfor surfactants. Each predictive model typically focuses on one surfactantclass, mostly nonionics. Graph Neural Networks (GNNs) have exhibited a greatpredictive performance for property prediction of ionic liquids, polymers anddrugs in general. Specifically for surfactants, GNNs can successfully predictcritical micelle concentration (CMC), a key surfactant property associated withmicellization. A key factor in the predictive ability of QSPR and GNN models isthe data available for training. Based on extensive literature search, wecreate the largest available CMC database with 429 molecules and the firstlarge data collection for surface excess concentration ($\Gamma$$_{m}$),another surfactant property associated with foaming, with 164 molecules. Then,we develop GNN models to predict the CMC and $\Gamma$$_{m}$ and we exploredifferent learning approaches, i.e., single- and multi-task learning, as wellas different training strategies, namely ensemble and transfer learning. Wefind that a multi-task GNN with ensemble learning trained on all $\Gamma$$_{m}$and CMC data performs best. Finally, we test the ability of our CMC model togeneralize on industrial grade pure component surfactants. The GNN yieldshighly accurate predictions for CMC, showing great potential for futureindustrial applications.</description><author>Christoforos Brozos, Jan G. Rittig, Sandip Bhattacharya, Elie Akanny, Christina Kohlmann, Alexander Mitsos</author><pubDate>Wed, 03 Jan 2024 18:32:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01874v1</guid></item><item><title>A unified recipe for deriving (time-uniform) PAC-Bayes bounds</title><link>http://arxiv.org/abs/2302.03421v5</link><description>We present a unified framework for deriving PAC-Bayesian generalizationbounds. Unlike most previous literature on this topic, our bounds areanytime-valid (i.e., time-uniform), meaning that they hold at all stoppingtimes, not only for a fixed sample size. Our approach combines four tools inthe following order: (a) nonnegative supermartingales or reversesubmartingales, (b) the method of mixtures, (c) the Donsker-Varadhan formula(or other convex duality principles), and (d) Ville's inequality. Our mainresult is a PAC-Bayes theorem which holds for a wide class of discretestochastic processes. We show how this result implies time-uniform versions ofwell-known classical PAC-Bayes bounds, such as those of Seeger, McAllester,Maurer, and Catoni, in addition to many recent bounds. We also present severalnovel bounds. Our framework also enables us to relax traditional assumptions;in particular, we consider nonstationary loss functions and non-i.i.d. data. Insum, we unify the derivation of past bounds and ease the search for futurebounds: one may simply check if our supermartingale or submartingale conditionsare met and, if so, be guaranteed a (time-uniform) PAC-Bayes bound.</description><author>Ben Chugg, Hongjian Wang, Aaditya Ramdas</author><pubDate>Wed, 03 Jan 2024 18:32:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2302.03421v5</guid></item><item><title>On the hardness of learning under symmetries</title><link>http://arxiv.org/abs/2401.01869v1</link><description>We study the problem of learning equivariant neural networks via gradientdescent. The incorporation of known symmetries ("equivariance") into neuralnets has empirically improved the performance of learning pipelines, in domainsranging from biology to computer vision. However, a rich yet separate line oflearning theoretic research has demonstrated that actually learning shallow,fully-connected (i.e. non-symmetric) networks has exponential complexity in thecorrelational statistical query (CSQ) model, a framework encompassing gradientdescent. In this work, we ask: are known problem symmetries sufficient toalleviate the fundamental hardness of learning neural nets with gradientdescent? We answer this question in the negative. In particular, we give lowerbounds for shallow graph neural networks, convolutional networks, invariantpolynomials, and frame-averaged networks for permutation subgroups, which allscale either superpolynomially or exponentially in the relevant inputdimension. Therefore, in spite of the significant inductive bias imparted viasymmetry, actually learning the complete classes of functions represented byequivariant neural networks via gradient descent remains hard.</description><author>Bobak T. Kiani, Thien Le, Hannah Lawrence, Stefanie Jegelka, Melanie Weber</author><pubDate>Wed, 03 Jan 2024 18:24:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01869v1</guid></item><item><title>Step length measurement in the wild using FMCW radar</title><link>http://arxiv.org/abs/2401.01868v1</link><description>With an aging population, numerous assistive and monitoring technologies areunder development to enable older adults to age in place. To facilitate agingin place predicting risk factors such as falls, and hospitalization andproviding early interventions are important. Much of the work on ambientmonitoring for risk prediction has centered on gait speed analysis, utilizingprivacy-preserving sensors like radar. Despite compelling evidence thatmonitoring step length, in addition to gait speed, is crucial for predictingrisk, radar-based methods have not explored step length measurement in thehome. Furthermore, laboratory experiments on step length measurement usingradars are limited to proof of concept studies with few healthy subjects. Toaddress this gap, a radar-based step length measurement system for the home isproposed based on detection and tracking using radar point cloud, followed byDoppler speed profiling of the torso to obtain step lengths in the home. Theproposed method was evaluated in a clinical environment, involving 35 frailolder adults, to establish its validity. Additionally, the method was assessedin people's homes, with 21 frail older adults who had participated in theclinical assessment. The proposed radar-based step length measurement methodwas compared to the gold standard Zeno Walkway Gait Analysis System, revealinga 4.5cm/8.3% error in a clinical setting. Furthermore, it exhibited excellentreliability (ICC(2,k)=0.91, 95% CI 0.82 to 0.96) in uncontrolled home settings.The method also proved accurate in uncontrolled home settings, as indicated bya strong agreement (ICC(3,k)=0.81 (95% CI 0.53 to 0.92)) between homemeasurements and in-clinic assessments.</description><author>Parthipan Siva, Alexander Wong, Patricia Hewston, George Ioannidis, Dr. Jonathan Adachi, Dr. Alexander Rabinovich, Andrea Lee, Alexandra Papaioannou</author><pubDate>Wed, 03 Jan 2024 18:23:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01868v1</guid></item><item><title>Dataset Difficulty and the Role of Inductive Bias</title><link>http://arxiv.org/abs/2401.01867v1</link><description>Motivated by the goals of dataset pruning and defect identification, agrowing body of methods have been developed to score individual examples withina dataset. These methods, which we call "example difficulty scores", aretypically used to rank or categorize examples, but the consistency of rankingsbetween different training runs, scoring methods, and model architectures isgenerally unknown. To determine how example rankings vary due to these randomand controlled effects, we systematically compare different formulations ofscores over a range of runs and model architectures. We find that scoreslargely share the following traits: they are noisy over individual runs of amodel, strongly correlated with a single notion of difficulty, and revealexamples that range from being highly sensitive to insensitive to the inductivebiases of certain model architectures. Drawing from statistical genetics, wedevelop a simple method for fingerprinting model architectures using a fewsensitive examples. These findings guide practitioners in maximizing theconsistency of their scores (e.g. by choosing appropriate scoring methods,number of runs, and subsets of examples), and establishes comprehensivebaselines for evaluating scores in the future.</description><author>Devin Kwok, Nikhil Anand, Jonathan Frankle, Gintare Karolina Dziugaite, David Rolnick</author><pubDate>Wed, 03 Jan 2024 18:19:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01867v1</guid></item><item><title>A Vision Check-up for Language Models</title><link>http://arxiv.org/abs/2401.01862v1</link><description>What does learning to model relationships between strings teach largelanguage models (LLMs) about the visual world? We systematically evaluate LLMs'abilities to generate and recognize an assortment of visual concepts ofincreasing complexity and then demonstrate how a preliminary visualrepresentation learning system can be trained using models of text. As languagemodels lack the ability to consume or output visual information as pixels, weuse code to represent images in our study. Although LLM-generated images do notlook like natural images, results on image generation and the ability of modelsto correct these generated images indicate that precise modeling of strings canteach language models about numerous aspects of the visual world. Furthermore,experiments on self-supervised visual representation learning, utilizing imagesgenerated with text models, highlight the potential to train vision modelscapable of making semantic assessments of natural images using just LLMs.</description><author>Pratyusha Sharma, Tamar Rott Shaham, Manel Baradad, Stephanie Fu, Adrian Rodriguez-Munoz, Shivam Duggal, Phillip Isola, Antonio Torralba</author><pubDate>Wed, 03 Jan 2024 18:09:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01862v1</guid></item><item><title>Synthetic dataset of ID and Travel Document</title><link>http://arxiv.org/abs/2401.01858v1</link><description>This paper presents a new synthetic dataset of ID and travel documents,called SIDTD. The SIDTD dataset is created to help training and evaluatingforged ID documents detection systems. Such a dataset has become a necessity asID documents contain personal information and a public dataset of realdocuments can not be released. Moreover, forged documents are scarce, comparedto legit ones, and the way they are generated varies from one fraudster toanother resulting in a class of high intra-variability. In this paper wetrained state-of-the-art models on this dataset and we compare them to theperformance achieved in larger, but private, datasets. The creation of thisdataset will help to document image analysis community to progress in the taskof ID document verification.</description><author>Carlos Boned, Maxime Talarmain, Nabil Ghanmi, Guillaume Chiron, Sanket Biswas, Ahmad Montaser Awal, Oriol Ramos Terrades</author><pubDate>Wed, 03 Jan 2024 18:06:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01858v1</guid></item><item><title>Optimal cross-learning for contextual bandits with unknown context distributions</title><link>http://arxiv.org/abs/2401.01857v1</link><description>We consider the problem of designing contextual bandit algorithms in the``cross-learning'' setting of Balseiro et al., where the learner observes theloss for the action they play in all possible contexts, not just the context ofthe current round. We specifically consider the setting where losses are chosenadversarially and contexts are sampled i.i.d. from an unknown distribution. Inthis setting, we resolve an open problem of Balseiro et al. by providing anefficient algorithm with a nearly tight (up to logarithmic factors) regretbound of $\widetilde{O}(\sqrt{TK})$, independent of the number of contexts. Asa consequence, we obtain the first nearly tight regret bounds for the problemsof learning to bid in first-price auctions (under unknown value distributions)and sleeping bandits with a stochastic action set. At the core of our algorithm is a novel technique for coordinating theexecution of a learning algorithm over multiple epochs in such a way to removecorrelations between estimation of the unknown distribution and the actionsplayed by the algorithm. This technique may be of independent interest forother learning problems involving estimation of an unknown contextdistribution.</description><author>Jon Schneider, Julian Zimmert</author><pubDate>Wed, 03 Jan 2024 18:02:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01857v1</guid></item><item><title>Transformer Neural Autoregressive Flows</title><link>http://arxiv.org/abs/2401.01855v1</link><description>Density estimation, a central problem in machine learning, can be performedusing Normalizing Flows (NFs). NFs comprise a sequence of invertibletransformations, that turn a complex target distribution into a simple one, byexploiting the change of variables theorem. Neural Autoregressive Flows (NAFs)and Block Neural Autoregressive Flows (B-NAFs) are arguably the most perfomantmembers of the NF family. However, they suffer scalability issues and traininginstability due to the constraints imposed on the network structure. In thispaper, we propose a novel solution to these challenges by exploitingtransformers to define a new class of neural flows called Transformer NeuralAutoregressive Flows (T-NAFs). T-NAFs treat each dimension of a random variableas a separate input token, using attention masking to enforce an autoregressiveconstraint. We take an amortization-inspired approach where the transformeroutputs the parameters of an invertible transformation. The experimentalresults demonstrate that T-NAFs consistently match or outperform NAFs andB-NAFs across multiple datasets from the UCI benchmark. Remarkably, T-NAFsachieve these results using an order of magnitude fewer parameters thanprevious approaches, without composing multiple flows.</description><author>Massimiliano Patacchiola, Aliaksandra Shysheya, Katja Hofmann, Richard E. Turner</author><pubDate>Wed, 03 Jan 2024 17:51:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01855v1</guid></item><item><title>Multilingual Instruction Tuning With Just a Pinch of Multilinguality</title><link>http://arxiv.org/abs/2401.01854v1</link><description>As instruction-tuned large language models (LLMs) gain global adoption, theirability to follow instructions in multiple languages becomes increasinglycrucial. One promising approach is cross-lingual transfer, where a modelacquires specific functionality on some language by finetuning on anotherlanguage. In this work, we investigate how multilinguality during instructiontuning of a multilingual LLM affects instruction-following across languages. Wefirst show that many languages transfer some instruction-following capabilitiesto other languages from even monolingual tuning. Furthermore, we find that only40 multilingual examples in an English tuning set substantially improvemultilingual instruction-following, both in seen and unseen languages duringtuning. In general, we observe that models tuned on multilingual mixturesexhibit comparable or superior performance in several languages compared tomonolingually tuned models, despite training on 10x fewer examples in thoselanguages. Finally, we find that increasing the number of languages in theinstruction tuning set from 1 to only 2, 3, or 4 increases cross-lingualgeneralization. Our results suggest that building massively multilingualinstruction-tuned models can be done with only a very small set of multilingualinstruction-responses.</description><author>Uri Shaham, Jonathan Herzig, Roee Aharoni, Idan Szpektor, Reut Tsarfaty, Matan Eyal</author><pubDate>Wed, 03 Jan 2024 17:48:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01854v1</guid></item><item><title>The Power of Training: How Different Neural Network Setups Influence the Energy Demand</title><link>http://arxiv.org/abs/2401.01851v1</link><description>This work examines the effects of variations in machine learning trainingregimes and learning paradigms on the corresponding energy consumption. Whileincreasing data availability and innovation in high-performance hardware fuelsthe training of sophisticated models, it also supports the fading perception ofenergy consumption and carbon emission. Therefore, the goal of this work is tocreate awareness about the energy impact of general training parameters andprocesses, from learning rate over batch size to knowledge transfer. Multiplesetups with different hyperparameter initializations are evaluated on twodifferent hardware configurations to obtain meaningful results. Experiments onpretraining and multitask training are conducted on top of the baseline resultsto determine their potential towards sustainable machine learning.</description><author>Daniel Geißler, Bo Zhou, Mengxi Liu, Sungho Suh, Paul Lukowicz</author><pubDate>Wed, 03 Jan 2024 17:44:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01851v1</guid></item><item><title>CardiGraphormer: Unveiling the Power of Self-Supervised Learning in Revolutionizing Drug Discovery</title><link>http://arxiv.org/abs/2307.00859v3</link><description>In the expansive realm of drug discovery, with approximately 15,000 knowndrugs and only around 4,200 approved, the combinatorial nature of the chemicalspace presents a formidable challenge. While Artificial Intelligence (AI) hasemerged as a powerful ally, traditional AI frameworks face significant hurdles.This manuscript introduces CardiGraphormer, a groundbreaking approach thatsynergizes self-supervised learning (SSL), Graph Neural Networks (GNNs), andCardinality Preserving Attention to revolutionize drug discovery.CardiGraphormer, a novel combination of Graphormer and Cardinality PreservingAttention, leverages SSL to learn potent molecular representations and employsGNNs to extract molecular fingerprints, enhancing predictive performance andinterpretability while reducing computation time. It excels in handling complexdata like molecular structures and performs tasks associated with nodes, pairsof nodes, subgraphs, or entire graph structures. CardiGraphormer's potentialapplications in drug discovery and drug interactions are vast, from identifyingnew drug targets to predicting drug-to-drug interactions and enabling noveldrug discovery. This innovative approach provides an AI-enhanced methodology indrug development, utilizing SSL combined with GNNs to overcome existinglimitations and pave the way for a richer exploration of the vast combinatorialchemical space in drug discovery.</description><author>Abhijit Gupta</author><pubDate>Wed, 03 Jan 2024 17:43:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.00859v3</guid></item><item><title>Observable adjustments in single-index models for regularized M-estimators</title><link>http://arxiv.org/abs/2204.06990v3</link><description>We consider observations $(X,y)$ from single index models with unknown linkfunction, Gaussian covariates and a regularized M-estimator $\hat\beta$constructed from convex loss function and regularizer. In the regime wheresample size $n$ and dimension $p$ are both increasing such that $p/n$ has afinite limit, the behavior of the empirical distribution of $\hat\beta$ and thepredicted values $X\hat\beta$ has been previously characterized in a number ofmodels: The empirical distributions are known to converge to proximal operatorsof the loss and penalty in a related Gaussian sequence model, which capturesthe interplay between ratio $p/n$, loss, regularization and the data generatingprocess. This connection between$(\hat\beta,X\hat\beta)$ and the correspondingproximal operators require solving fixed-point equations that typically involveunobservable quantities such as the prior distribution on the index or the linkfunction. This paper develops a different theory to describe the empirical distributionof $\hat\beta$ and $X\hat\beta$: Approximations of $(\hat\beta,X\hat\beta)$ interms of proximal operators are provided that only involve observableadjustments. These proposed observable adjustments are data-driven, e.g., donot require prior knowledge of the index or the link function. These newadjustments yield confidence intervals for individual components of the index,as well as estimators of the correlation of $\hat\beta$ with the index. Theinterplay between loss, regularization and the model is thus captured in adata-driven manner, without solving the fixed-point equations studied inprevious works. The results apply to both strongly convex regularizers andunregularized M-estimation. Simulations are provided for the square andlogistic loss in single index models including logistic regression and 1-bitcompressed sensing with 20\% corrupted bits.</description><author>Pierre C Bellec</author><pubDate>Wed, 03 Jan 2024 17:41:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2204.06990v3</guid></item><item><title>Prediction of good reaction coordinates and future evolution of MD trajectories using Regularized Sparse Autoencoders: A novel deep learning approach</title><link>http://arxiv.org/abs/2208.10962v2</link><description>Identifying reaction coordinates(RCs) is an active area of research, giventhe crucial role RCs play in determining the progress of a chemical reaction.The choice of the reaction coordinate is often based on heuristic knowledge.However, an essential criterion for the choice is that the coordinate shouldcapture both the reactant and product states unequivocally. Also, thecoordinate should be the slowest one so that all the other degrees of freedomcan easily equilibrate along the reaction coordinate. Also, the coordinateshould be the slowest one so that all the other degrees of freedom can easilyequilibrate along the reaction coordinate. We used a regularised sparseautoencoder, an energy-based model, to discover a crucial set of reactioncoordinates. Along with discovering reaction coordinates, our model alsopredicts the evolution of a molecular dynamics(MD) trajectory. We showcasedthat including sparsity enforcing regularisation helps in choosing a small butimportant set of reaction coordinates. We used two model systems to demonstrateour approach: alanine dipeptide system and proflavine and DNA system, whichexhibited intercalation of proflavine into DNA minor groove in an aqueousenvironment. We model MD trajectory as a multivariate time series, and ourlatent variable model performs the task of multi-step time series prediction.This idea is inspired by the popular sparse coding approach - to represent eachinput sample as a linear combination of few elements taken from a set ofrepresentative patterns.</description><author>Abhijit Gupta</author><pubDate>Wed, 03 Jan 2024 17:38:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2208.10962v2</guid></item><item><title>DGDNN: Decoupled Graph Diffusion Neural Network for Stock Movement Prediction</title><link>http://arxiv.org/abs/2401.01846v1</link><description>Forecasting future stock trends remains challenging for academia and industrydue to stochastic inter-stock dynamics and hierarchical intra-stock dynamicsinfluencing stock prices. In recent years, graph neural networks have achievedremarkable performance in this problem by formulating multiple stocks asgraph-structured data. However, most of these approaches rely on artificiallydefined factors to construct static stock graphs, which fail to capture theintrinsic interdependencies between stocks that rapidly evolve. In addition,these methods often ignore the hierarchical features of the stocks and losedistinctive information within. In this work, we propose a novel graph learningapproach implemented without expert knowledge to address these issues. First,our approach automatically constructs dynamic stock graphs by entropy-drivenedge generation from a signal processing perspective. Then, we further learntask-optimal dependencies between stocks via a generalized graph diffusionprocess on constructed stock graphs. Last, a decoupled representation learningscheme is adopted to capture distinctive hierarchical intra-stock features.Experimental results demonstrate substantial improvements over state-of-the-artbaselines on real-world datasets. Moreover, the ablation study and sensitivitystudy further illustrate the effectiveness of the proposed method in modelingthe time-evolving inter-stock and intra-stock dynamics.</description><author>Zinuo You, Zijian Shi, Hongbo Bo, John Cartlidge, Li Zhang, Yan Ge</author><pubDate>Wed, 03 Jan 2024 17:36:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01846v1</guid></item><item><title>Investigating Semi-Supervised Learning Algorithms in Text Datasets</title><link>http://arxiv.org/abs/2401.01843v1</link><description>Using large training datasets enhances the generalization capabilities ofneural networks. Semi-supervised learning (SSL) is useful when there are fewlabeled data and a lot of unlabeled data. SSL methods that use dataaugmentation are most successful for image datasets. In contrast, texts do nothave consistent augmentation methods as images. Consequently, methods that useaugmentation are not as effective in text data as they are in image data. Inthis study, we compared SSL algorithms that do not require augmentation; theseare self-training, co-training, tri-training, and tri-training withdisagreement. In the experiments, we used 4 different text datasets fordifferent tasks. We examined the algorithms from a variety of perspectives byasking experiment questions and suggested several improvements. Among thealgorithms, tri-training with disagreement showed the closest performance tothe Oracle; however, performance gap shows that new semi-supervised algorithmsor improvements in existing methods are needed.</description><author>Himmet Toprak Kesgin, Mehmet Fatih Amasyali</author><pubDate>Wed, 03 Jan 2024 17:22:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01843v1</guid></item><item><title>Wasserstein Nonnegative Tensor Factorization with Manifold Regularization</title><link>http://arxiv.org/abs/2401.01842v1</link><description>Nonnegative tensor factorization (NTF) has become an important tool forfeature extraction and part-based representation with preserved intrinsicstructure information from nonnegative high-order data. However, the originalNTF methods utilize Euclidean or Kullback-Leibler divergence as the lossfunction which treats each feature equally leading to the neglect of theside-information of features. To utilize correlation information of featuresand manifold information of samples, we introduce Wasserstein manifoldnonnegative tensor factorization (WMNTF), which minimizes the Wassersteindistance between the distribution of input tensorial data and the distributionof reconstruction. Although some researches about Wasserstein distance havebeen proposed in nonnegative matrix factorization (NMF), they ignore thespatial structure information of higher-order data. We use Wasserstein distance(a.k.a Earth Mover's distance or Optimal Transport distance) as a metric andadd a graph regularizer to a latent factor. Experimental results demonstratethe effectiveness of the proposed method compared with other NMF and NTFmethods.</description><author>Jianyu Wang, Linruize Tang</author><pubDate>Wed, 03 Jan 2024 17:20:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01842v1</guid></item><item><title>Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes</title><link>http://arxiv.org/abs/2401.01841v1</link><description>A fundamental (and largely open) challenge in sequential decision-making isdealing with non-stationary environments, where exogenous environmentalconditions change over time. Such problems are traditionally modeled asnon-stationary Markov decision processes (NSMDP). However, existing approachesfor decision-making in NSMDPs have two major shortcomings: first, they assumethat the updated environmental dynamics at the current time are known (althoughfuture dynamics can change); and second, planning is largely pessimistic, i.e.,the agent acts ``safely'' to account for the non-stationary evolution of theenvironment. We argue that both these assumptions are invalid in practice --updated environmental conditions are rarely known, and as the agent interactswith the environment, it can learn about the updated dynamics and avoid beingpessimistic, at least in states whose dynamics it is confident about. Wepresent a heuristic search algorithm called \textit{Adaptive Monte Carlo TreeSearch (ADA-MCTS)} that addresses these challenges. We show that the agent canlearn the updated dynamics of the environment over time and then act as itlearns, i.e., if the agent is in a region of the state space about which it hasupdated knowledge, it can avoid being pessimistic. To quantify ``updatedknowledge,'' we disintegrate the aleatoric and epistemic uncertainty in theagent's updated belief and show how the agent can use these estimates fordecision-making. We compare the proposed approach with the multiplestate-of-the-art approaches in decision-making across multiple well-establishedopen-source problems and empirically show that our approach is faster andhighly adaptive without sacrificing safety.</description><author>Baiting Luo, Yunuo Zhang, Abhishek Dubey, Ayan Mukhopadhyay</author><pubDate>Wed, 03 Jan 2024 17:19:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01841v1</guid></item><item><title>A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models</title><link>http://arxiv.org/abs/2401.01313v2</link><description>As Large Language Models (LLMs) continue to advance in their ability to writehuman-like text, a key challenge remains around their tendency to hallucinategenerating content that appears factual but is ungrounded. This issue ofhallucination is arguably the biggest hindrance to safely deploying thesepowerful LLMs into real-world production systems that impact people's lives.The journey toward widespread adoption of LLMs in practical settings heavilyrelies on addressing and mitigating hallucinations. Unlike traditional AIsystems focused on limited tasks, LLMs have been exposed to vast amounts ofonline text data during training. While this allows them to display impressivelanguage fluency, it also means they are capable of extrapolating informationfrom the biases in training data, misinterpreting ambiguous prompts, ormodifying the information to align superficially with the input. This becomeshugely alarming when we rely on language generation capabilities for sensitiveapplications, such as summarizing medical records, financial analysis reports,etc. This paper presents a comprehensive survey of over 32 techniques developedto mitigate hallucination in LLMs. Notable among these are Retrieval AugmentedGeneration (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023),CoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023). Furthermore, weintroduce a detailed taxonomy categorizing these methods based on variousparameters, such as dataset utilization, common tasks, feedback mechanisms, andretriever types. This classification helps distinguish the diverse approachesspecifically designed to tackle hallucination issues in LLMs. Additionally, weanalyze the challenges and limitations inherent in these techniques, providinga solid foundation for future research in addressing hallucinations and relatedphenomena within the realm of LLMs.</description><author>S. M Towhidul Islam Tonmoy, S M Mehedi Zaman, Vinija Jain, Anku Rani, Vipula Rawte, Aman Chadha, Amitava Das</author><pubDate>Wed, 03 Jan 2024 17:13:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01313v2</guid></item><item><title>Frequency Domain Modality-invariant Feature Learning for Visible-infrared Person Re-Identification</title><link>http://arxiv.org/abs/2401.01839v1</link><description>Visible-infrared person re-identification (VI-ReID) is challenging due to thesignificant cross-modality discrepancies between visible and infrared images.While existing methods have focused on designing complex network architecturesor using metric learning constraints to learn modality-invariant features, theyoften overlook which specific component of the image causes the modalitydiscrepancy problem. In this paper, we first reveal that the difference in theamplitude component of visible and infrared images is the primary factor thatcauses the modality discrepancy and further propose a novel Frequency Domainmodality-invariant feature learning framework (FDMNet) to reduce modalitydiscrepancy from the frequency domain perspective. Our framework introduces twonovel modules, namely the Instance-Adaptive Amplitude Filter (IAF) module andthe Phrase-Preserving Normalization (PPNorm) module, to enhance themodality-invariant amplitude component and suppress the modality-specificcomponent at both the image- and feature-levels. Extensive experimental resultson two standard benchmarks, SYSU-MM01 and RegDB, demonstrate the superiorperformance of our FDMNet against state-of-the-art methods.</description><author>Yulin Li, Tianzhu Zhang, Yongdong Zhang</author><pubDate>Wed, 03 Jan 2024 17:11:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01839v1</guid></item><item><title>NODEC: Neural ODE For Optimal Control of Unknown Dynamical Systems</title><link>http://arxiv.org/abs/2401.01836v1</link><description>Controlling complex dynamical systems is generally associated with minimizingcertain control objectives with known dynamics under the variational calculusframework. For systems with unknown dynamics, an additional step of dynamicsmodeling is required. However, any inaccuracy in dynamics modeling will lead tosub-optimality in the resulting control function. Another set of approaches forcontrolling unknown dynamical systems - reinforcement learning, folds thedynamics modeling into controller training via value function approximation orpolicy gradient through extensively interacting with the environment, but itsuffers from low data efficiency. To address these, we introduce NODEC, a novelframework for controlling unknown dynamical systems, which combines dynamicsmodelling and controller training using a coupled neural ODE model. Through anintriguing interplay between the two coupled neural networks, NODEC learnssystem dynamics as well as optimal controls that guides the unknown dynamicalsystem towards target states. Our experiments demonstrate the effectiveness anddata efficiency of NODEC for learning optimal control of unknown dynamicalsystems.</description><author>Cheng Chi</author><pubDate>Wed, 03 Jan 2024 17:05:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01836v1</guid></item><item><title>Retrieval-Augmented Generation for Large Language Models: A Survey</title><link>http://arxiv.org/abs/2312.10997v3</link><description>Large Language Models (LLMs) demonstrate significant capabilities but facechallenges such as hallucination, outdated knowledge, and non-transparent,untraceable reasoning processes. Retrieval-Augmented Generation (RAG) hasemerged as a promising solution by incorporating knowledge from externaldatabases. This enhances the accuracy and credibility of the models,particularly for knowledge-intensive tasks, and allows for continuous knowledgeupdates and integration of domain-specific information. RAG synergisticallymerges LLMs' intrinsic knowledge with the vast, dynamic repositories ofexternal databases. This comprehensive review paper offers a detailedexamination of the progression of RAG paradigms, encompassing the Naive RAG,the Advanced RAG, and the Modular RAG. It meticulously scrutinizes thetripartite foundation of RAG frameworks, which includes the retrieval , thegeneration and the augmentation techniques. The paper highlights thestate-of-the-art technologies embedded in each of these critical components,providing a profound understanding of the advancements in RAG systems.Furthermore, this paper introduces the metrics and benchmarks for assessing RAGmodels, along with the most up-to-date evaluation framework. In conclusion, thepaper delineates prospective avenues for research, including the identificationof challenges, the expansion of multi-modalities, and the progression of theRAG infrastructure and its ecosystem.</description><author>Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo, Meng Wang, Haofen Wang</author><pubDate>Wed, 03 Jan 2024 17:04:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.10997v3</guid></item><item><title>Bridging the Gap Between Target Networks and Functional Regularization</title><link>http://arxiv.org/abs/2210.12282v2</link><description>Bootstrapping is behind much of the successes of Deep Reinforcement Learning.However, learning the value function via bootstrapping often leads to unstabletraining due to fast-changing target values. Target Networks are employed tostabilize training by using an additional set of lagging parameters to estimatethe target values. Despite the popularity of Target Networks, their effect onthe optimization is still misunderstood. In this work, we show that they act asan implicit regularizer. This regularizer has disadvantages such as beinginflexible and non convex. To overcome these issues, we propose an explicitFunctional Regularization that is a convex regularizer in function space andcan easily be tuned. We analyze the convergence of our method theoretically andempirically demonstrate that replacing Target Networks with the moretheoretically grounded Functional Regularization approach leads to bettersample efficiency and performance improvements.</description><author>Alexandre Piche, Valentin Thomas, Joseph Marino, Rafael Pardinas, Gian Maria Marconi, Christopher Pal, Mohammad Emtiyaz Khan</author><pubDate>Wed, 03 Jan 2024 17:02:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.12282v2</guid></item><item><title>Concurrent Brainstorming &amp; Hypothesis Satisfying: An Iterative Framework for Enhanced Retrieval-Augmented Generation (R2CBR3H-SR)</title><link>http://arxiv.org/abs/2401.01835v1</link><description>Addressing the complexity of comprehensive information retrieval, this studyintroduces an innovative, iterative retrieval-augmented generation system. Ourapproach uniquely integrates a vector-space driven re-ranking mechanism withconcurrent brainstorming to expedite the retrieval of highly relevantdocuments, thereby streamlining the generation of potential queries. This setsthe stage for our novel hybrid process, which synergistically combineshypothesis formulation with satisfying decision-making strategy to determinecontent adequacy, leveraging a chain of thought-based prompting technique. Thisunified hypothesize-satisfied phase intelligently distills information toascertain whether user queries have been satisfactorily addressed. Uponreaching this criterion, the system refines its output into a conciserepresentation, maximizing conceptual density with minimal verbosity. Theiterative nature of the workflow enhances process efficiency and accuracy.Crucially, the concurrency within the brainstorming phase significantlyaccelerates recursive operations, facilitating rapid convergence to solutionsatisfaction. Compared to conventional methods, our system demonstrates amarked improvement in computational time and cost-effectiveness. This researchadvances the state-of-the-art in intelligent retrieval systems, setting a newbenchmark for resource-efficient information extraction and abstraction inknowledge-intensive applications.</description><author>Arash Shahmansoori</author><pubDate>Wed, 03 Jan 2024 17:01:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01835v1</guid></item><item><title>Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling</title><link>http://arxiv.org/abs/2401.01830v1</link><description>Data augmentation is an effective technique for improving the performance ofmachine learning models. However, it has not been explored as extensively innatural language processing (NLP) as it has in computer vision. In this paper,we propose a novel text augmentation method that leverages the Fill-Maskfeature of the transformer-based BERT model. Our method involves iterativelymasking words in a sentence and replacing them with language model predictions.We have tested our proposed method on various NLP tasks and found it to beeffective in many cases. Our results are presented along with a comparison toexisting augmentation methods. Experimental results show that our proposedmethod significantly improves performance, especially on topic classificationdatasets.</description><author>Himmet Toprak Kesgin, Mehmet Fatih Amasyali</author><pubDate>Wed, 03 Jan 2024 16:47:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01830v1</guid></item><item><title>Moonshot: Towards Controllable Video Generation and Editing with Multimodal Conditions</title><link>http://arxiv.org/abs/2401.01827v1</link><description>Most existing video diffusion models (VDMs) are limited to mere textconditions. Thereby, they are usually lacking in control over visual appearanceand geometry structure of the generated videos. This work presents Moonshot, anew video generation model that conditions simultaneously on multimodal inputsof image and text. The model builts upon a core module, called multimodal videoblock (MVB), which consists of conventional spatialtemporal layers forrepresenting video features, and a decoupled cross-attention layer to addressimage and text inputs for appearance conditioning. In addition, we carefullydesign the model architecture such that it can optionally integrate withpre-trained image ControlNet modules for geometry visual conditions, withoutneeding of extra training overhead as opposed to prior methods. Experimentsshow that with versatile multimodal conditioning mechanisms, Moonshotdemonstrates significant improvement on visual quality and temporal consistencycompared to existing models. In addition, the model can be easily repurposedfor a variety of generative applications, such as personalized videogeneration, image animation and video editing, unveiling its potential to serveas a fundamental architecture for controllable video generation. Models will bemade public on https://github.com/salesforce/LAVIS.</description><author>David Junhao Zhang, Dongxu Li, Hung Le, Mike Zheng Shou, Caiming Xiong, Doyen Sahoo</author><pubDate>Wed, 03 Jan 2024 16:43:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01827v1</guid></item><item><title>M3D: Dataset Condensation by Minimizing Maximum Mean Discrepancy</title><link>http://arxiv.org/abs/2312.15927v2</link><description>Training state-of-the-art (SOTA) deep models often requires extensive data,resulting in substantial training and storage costs. To address thesechallenges, dataset condensation has been developed to learn a small syntheticset that preserves essential information from the original large-scale dataset.Nowadays, optimization-oriented methods have been the primary method in thefield of dataset condensation for achieving SOTA results. However, the bi-leveloptimization process hinders the practical application of such methods torealistic and larger datasets. To enhance condensation efficiency, previousworks proposed Distribution-Matching (DM) as an alternative, whichsignificantly reduces the condensation cost. Nonetheless, current DM-basedmethods have yielded less comparable results to optimization-oriented methodsdue to their focus on aligning only the first moment of the distributions. Inthis paper, we present a novel DM-based method named M3D for datasetcondensation by Minimizing the Maximum Mean Discrepancy between featurerepresentations of the synthetic and real images. By embedding theirdistributions in a reproducing kernel Hilbert space, we align all orders ofmoments of the distributions of real and synthetic images, resulting in a moregeneralized condensed set. Notably, our method even surpasses the SOTAoptimization-oriented method IDC on the high-resolution ImageNet dataset.Extensive analysis is conducted to verify the effectiveness of the proposedmethod.</description><author>Hansong Zhang, Shikun Li, Pengju Wang, Dan Zeng, Shiming Ge</author><pubDate>Wed, 03 Jan 2024 16:43:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15927v2</guid></item><item><title>Physio: An LLM-Based Physiotherapy Advisor</title><link>http://arxiv.org/abs/2401.01825v1</link><description>The capabilities of the most recent language models have increased theinterest in integrating them into real-world applications. However, the factthat these models generate plausible, yet incorrect text poses a constraintwhen considering their use in several domains. Healthcare is a prime example ofa domain where text-generative trustworthiness is a hard requirement tosafeguard patient well-being. In this paper, we present Physio, a chat-basedapplication for physical rehabilitation. Physio is capable of making an initialdiagnosis while citing reliable health sources to support the informationprovided. Furthermore, drawing upon external knowledge databases, Physio canrecommend rehabilitation exercises and over-the-counter medication for symptomrelief. By combining these features, Physio can leverage the power ofgenerative models for language processing while also conditioning its responseon dependable and verifiable sources. A live demo of Physio is available athttps://physio.inesctec.pt.</description><author>Rúben Almeida, Hugo Sousa, Luís F. Cunha, Nuno Guimarães, Ricardo Campos, Alípio Jorge</author><pubDate>Wed, 03 Jan 2024 16:42:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01825v1</guid></item><item><title>HawkRover: An Autonomous mmWave Vehicular Communication Testbed with Multi-sensor Fusion and Deep Learning</title><link>http://arxiv.org/abs/2401.01822v1</link><description>Connected and automated vehicles (CAVs) have become a transformativetechnology that can change our daily life. Currently, millimeter-wave (mmWave)bands are identified as the promising CAV connectivity solution. While it canprovide high data rate, their realization faces many challenges such as highattenuation during mmWave signal propagation and mobility management. Existingsolution has to initiate pilot signal to measure channel information, thenapply signal processing to calculate the best narrow beam towards the receiverend to guarantee sufficient signal power. This process takes significantoverhead and time, hence not suitable for vehicles. In this study, we proposean autonomous and low-cost testbed to collect extensive co-located mmWavesignal and other sensors data such as LiDAR (Light Detection and Ranging),cameras, ultrasonic, etc, traditionally for ``automated'', to facilitate mmWavevehicular communications. Intuitively, these sensors can build a 3D map aroundthe vehicle and signal propagation path can be estimated, eliminating iterativethe process via pilot signals. This multimodal data fusion, together with AI,is expected to bring significant advances in ``connected'' research.</description><author>Ethan Zhu, Haijian Sun</author><pubDate>Wed, 03 Jan 2024 16:38:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01822v1</guid></item><item><title>Detours for Navigating Instructional Videos</title><link>http://arxiv.org/abs/2401.01823v1</link><description>We introduce the video detours problem for navigating instructional videos.Given a source video and a natural language query asking to alter the how-tovideo's current path of execution in a certain way, the goal is to find arelated ''detour video'' that satisfies the requested alteration. To addressthis challenge, we propose VidDetours, a novel video-language approach thatlearns to retrieve the targeted temporal segments from a large repository ofhow-to's using video-and-text conditioned queries. Furthermore, we devise alanguage-based pipeline that exploits how-to video narration text to createweakly supervised training data. We demonstrate our idea applied to the domainof how-to cooking videos, where a user can detour from their current recipe tofind steps with alternate ingredients, tools, and techniques. Validating on aground truth annotated dataset of 16K samples, we show our model's significantimprovements over best available methods for video retrieval and questionanswering, with recall rates exceeding the state of the art by 35%.</description><author>Kumar Ashutosh, Zihui Xue, Tushar Nagarajan, Kristen Grauman</author><pubDate>Wed, 03 Jan 2024 16:38:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01823v1</guid></item><item><title>On the hierarchical Bayesian modelling of frequency response functions</title><link>http://arxiv.org/abs/2307.06263v2</link><description>For situations that may benefit from information sharing among datasets,e.g., population-based SHM of similar structures, the hierarchical Bayesianapproach provides a useful modelling structure. Hierarchical Bayesian modelslearn statistical distributions at the population (or parent) and the domainlevels simultaneously, to bolster statistical strength among the parameters. Asa result, variance is reduced among the parameter estimates, particularly whendata are limited. In this paper, a combined probabilistic FRF model isdeveloped for a small population of nominally-identical helicopter blades,using a hierarchical Bayesian structure, to support information transfer in thecontext of sparse data. The modelling approach is also demonstrated in atraditional SHM context, for a single helicopter blade exposed to varyingtemperatures, to show how the inclusion of physics-based knowledge can improvegeneralisation beyond the training data, in the context of scarce data. Thesemodels address critical challenges in SHM, by accommodating benign variationsthat present as differences in the underlying dynamics, while also considering(and utilising), the similarities among the domains.</description><author>T. A. Dardeno, K. Worden, N. Dervilis, R. S. Mills, L. A. Bull</author><pubDate>Wed, 03 Jan 2024 16:38:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.06263v2</guid></item><item><title>Large Language Models Relearn Removed Concepts</title><link>http://arxiv.org/abs/2401.01814v1</link><description>Advances in model editing through neuron pruning hold promise for removingundesirable concepts from large language models. However, it remains unclearwhether models have the capacity to reacquire pruned concepts after editing. Toinvestigate this, we evaluate concept relearning in models by tracking conceptsaliency and similarity in pruned neurons during retraining. Our findingsreveal that models can quickly regain performance post-pruning by relocatingadvanced concepts to earlier layers and reallocating pruned concepts to primedneurons with similar semantics. This demonstrates that models exhibitpolysemantic capacities and can blend old and new concepts in individualneurons. While neuron pruning provides interpretability into model concepts,our results highlight the challenges of permanent concept removal for improvedmodel \textit{safety}. Monitoring concept reemergence and developing techniquesto mitigate relearning of unsafe concepts will be important directions for morerobust model editing. Overall, our work strongly demonstrates the resilienceand fluidity of concept representations in LLMs post concept removal.</description><author>Michelle Lo, Shay B. Cohen, Fazl Barez</author><pubDate>Wed, 03 Jan 2024 16:15:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01814v1</guid></item><item><title>Signal Processing in the Retina: Interpretable Graph Classifier to Predict Ganglion Cell Responses</title><link>http://arxiv.org/abs/2401.01813v1</link><description>It is a popular hypothesis in neuroscience that ganglion cells in the retinaare activated by selectively detecting visual features in an observed scene.While ganglion cell firings can be predicted via data-trained deep neural nets,the networks remain indecipherable, thus providing little understanding of thecells' underlying operations. To extract knowledge from the cell firings, inthis paper we learn an interpretable graph-based classifier from data topredict the firings of ganglion cells in response to visual stimuli.Specifically, we learn a positive semi-definite (PSD) metric matrix $\mathbf{M}\succeq 0$ that defines Mahalanobis distances between graph nodes (visualevents) endowed with pre-computed feature vectors; the computed inter-nodedistances lead to edge weights and a combinatorial graph that is amenable tobinary classification. Mathematically, we define the objective of metric matrix$\mathbf{M}$ optimization using a graph adaptation of large margin nearestneighbor (LMNN), which is rewritten as a semi-definite programming (SDP)problem. We solve it efficiently via a fast approximation called Gershgorindisc perfect alignment (GDPA) linearization. The learned metric matrix$\mathbf{M}$ provides interpretability: important features are identified along$\mathbf{M}$'s diagonal, and their mutual relationships are inferred fromoff-diagonal terms. Our fast metric learning framework can be applied to otherbiological systems with pre-chosen features that require interpretation.</description><author>Yasaman Parhizkar, Gene Cheung, Andrew W. Eckford</author><pubDate>Wed, 03 Jan 2024 16:15:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01813v1</guid></item><item><title>Validation of Composite Systems by Discrepancy Propagation</title><link>http://arxiv.org/abs/2210.12061v2</link><description>Assessing the validity of a real-world system with respect to given qualitycriteria is a common yet costly task in industrial applications due to the vastnumber of required real-world tests. Validating such systems by means ofsimulation offers a promising and less expensive alternative, but requires anassessment of the simulation accuracy and therefore end-to-end measurements.Additionally, covariate shifts between simulations and actual usage can causedifficulties for estimating the reliability of such systems. In this work, wepresent a validation method that propagates bounds on distributionaldiscrepancy measures through a composite system, thereby allowing us to derivean upper bound on the failure probability of the real system from potentiallyinaccurate simulations. Each propagation step entails an optimization problem,where -- for measures such as maximum mean discrepancy (MMD) -- we developtight convex relaxations based on semidefinite programs. We demonstrate thatour propagation method yields valid and useful bounds for composite systemsexhibiting a variety of realistic effects. In particular, we show that theproposed method can successfully account for data shifts within theexperimental design as well as model inaccuracies within the simulation.</description><author>David Reeb, Kanil Patel, Karim Barsim, Martin Schiegg, Sebastian Gerwinn</author><pubDate>Wed, 03 Jan 2024 16:10:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.12061v2</guid></item><item><title>aMUSEd: An Open MUSE Reproduction</title><link>http://arxiv.org/abs/2401.01808v1</link><description>We present aMUSEd, an open-source, lightweight masked image model (MIM) fortext-to-image generation based on MUSE. With 10 percent of MUSE's parameters,aMUSEd is focused on fast image generation. We believe MIM is under-exploredcompared to latent diffusion, the prevailing approach for text-to-imagegeneration. Compared to latent diffusion, MIM requires fewer inference stepsand is more interpretable. Additionally, MIM can be fine-tuned to learnadditional styles with only a single image. We hope to encourage furtherexploration of MIM by demonstrating its effectiveness on large-scaletext-to-image generation and releasing reproducible training code. We alsorelease checkpoints for two models which directly produce images at 256x256 and512x512 resolutions.</description><author>Suraj Patil, William Berman, Robin Rombach, Patrick von Platen</author><pubDate>Wed, 03 Jan 2024 16:10:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01808v1</guid></item><item><title>Efficient Computation of Confidence Sets Using Classification on Equidistributed Grids</title><link>http://arxiv.org/abs/2401.01804v1</link><description>Economic models produce moment inequalities, which can be used to form testsof the true parameters. Confidence sets (CS) of the true parameters are derivedby inverting these tests. However, they often lack analytical expressions,necessitating a grid search to obtain the CS numerically by retaining the gridpoints that pass the test. When the statistic is not asymptotically pivotal,constructing the critical value for each grid point in the parameter space addsto the computational burden. In this paper, we convert the computational issueinto a classification problem by using a support vector machine (SVM)classifier. Its decision function provides a faster and more systematic way ofdividing the parameter space into two regions: inside vs. outside of theconfidence set. We label those points in the CS as 1 and those outside as -1.Researchers can train the SVM classifier on a grid of manageable size and useit to determine whether points on denser grids are in the CS or not. Weestablish certain conditions for the grid so that there is a tuning that allowsus to asymptotically reproduce the test in the CS. This means that in thelimit, a point is classified as belonging to the confidence set if and only ifit is labeled as 1 by the SVM.</description><author>Lujie Zhou</author><pubDate>Wed, 03 Jan 2024 16:04:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01804v1</guid></item><item><title>A quatum inspired neural network for geometric modeling</title><link>http://arxiv.org/abs/2401.01801v1</link><description>By conceiving physical systems as 3D many-body point clouds, geometric graphneural networks (GNNs), such as SE(3)/E(3) equivalent GNNs, have showcasedpromising performance. In particular, their effective message-passing mechanicsmake them adept at modeling molecules and crystalline materials. However,current geometric GNNs only offer a mean-field approximation of the many-bodysystem, encapsulated within two-body message passing, thus falling short incapturing intricate relationships within these geometric graphs. To addressthis limitation, tensor networks, widely employed by computational physics tohandle manybody systems using high-order tensors, have been introduced.Nevertheless, integrating these tensorized networks into the message-passingframework of GNNs faces scalability and symmetry conservation (e.g.,permutation and rotation) challenges. In response, we introduce an innovativeequivariant Matrix Product State (MPS)-based message-passing strategy, throughachieving an efficient implementation of the tensor contraction operation. Ourmethod effectively models complex many-body relationships, suppressingmean-field approximations, and captures symmetries within geometric graphs.Importantly, it seamlessly replaces the standard message-passing andlayer-aggregation modules intrinsic to geometric GNNs. We empirically validatethe superior accuracy of our approach on benchmark tasks, including predictingclassical Newton systems and quantum tensor Hamiltonian matrices. To ourknowledge, our approach represents the inaugural utilization of parameterizedgeometric tensor networks.</description><author>Weitao Du, Shengchao Liu, Hongyu Guo</author><pubDate>Wed, 03 Jan 2024 15:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01801v1</guid></item><item><title>Topological Data Analysis for Neural Network Analysis: A Comprehensive Survey</title><link>http://arxiv.org/abs/2312.05840v2</link><description>This survey provides a comprehensive exploration of applications ofTopological Data Analysis (TDA) within neural network analysis. Using TDA toolssuch as persistent homology and Mapper, we delve into the intricate structuresand behaviors of neural networks and their datasets. We discuss differentstrategies to obtain topological information from data and neural networks bymeans of TDA. Additionally, we review how topological information can beleveraged to analyze properties of neural networks, such as theirgeneralization capacity or expressivity. We explore practical implications ofdeep learning, specifically focusing on areas like adversarial detection andmodel selection. Our survey organizes the examined works into four broaddomains: 1. Characterization of neural network architectures; 2. Analysis ofdecision regions and boundaries; 3. Study of internal representations,activations, and parameters; 4. Exploration of training dynamics and lossfunctions. Within each category, we discuss several articles, offeringbackground information to aid in understanding the various methodologies. Weconclude with a synthesis of key insights gained from our study, accompanied bya discussion of challenges and potential advancements in the field.</description><author>Rubén Ballester, Carles Casacuberta, Sergio Escalera</author><pubDate>Wed, 03 Jan 2024 15:58:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.05840v2</guid></item><item><title>Manipulating Trajectory Prediction with Backdoors</title><link>http://arxiv.org/abs/2312.13863v2</link><description>Autonomous vehicles ought to predict the surrounding agents' trajectories toallow safe maneuvers in uncertain and complex traffic situations. As companiesincreasingly apply trajectory prediction in the real world, security becomes arelevant concern. In this paper, we focus on backdoors - a security threatacknowledged in other fields but so far overlooked for trajectory prediction.To this end, we describe and investigate four triggers that could affecttrajectory prediction. We then show that these triggers (for example, a brakingvehicle), when correlated with a desired output (for example, a curve) duringtraining, cause the desired output of a state-of-the-art trajectory predictionmodel. In other words, the model has good benign performance but is vulnerableto backdoors. This is the case even if the trigger maneuver is performed by anon-casual agent behind the target vehicle. As a side-effect, our analysisreveals interesting limitations within trajectory prediction models. Finally,we evaluate a range of defenses against backdoors. While some, like simpleoffroad checks, do not enable detection for all triggers, clustering is apromising candidate to support manual inspection to find backdoors.</description><author>Kaouther Messaoud, Kathrin Grosse, Mickael Chen, Matthieu Cord, Patrick Pérez, Alexandre Alahi</author><pubDate>Wed, 03 Jan 2024 15:52:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.13863v2</guid></item><item><title>Sharper Bounds for $\ell_p$ Sensitivity Sampling</title><link>http://arxiv.org/abs/2306.00732v2</link><description>In large scale machine learning, random sampling is a popular way toapproximate datasets by a small representative subset of examples. Inparticular, sensitivity sampling is an intensely studied technique whichprovides provable guarantees on the quality of approximation, while reducingthe number of examples to the product of the VC dimension $d$ and the totalsensitivity $\mathfrak S$ in remarkably general settings. However, guaranteesgoing beyond this general bound of $\mathfrak S d$ are known in perhaps onlyone setting, for $\ell_2$ subspace embeddings, despite intense study ofsensitivity sampling in prior work. In this work, we show the first bounds forsensitivity sampling for $\ell_p$ subspace embeddings for $p &gt; 2$ that improveover the general $\mathfrak S d$ bound, achieving a bound of roughly $\mathfrakS^{2-2/p}$ for $2&lt;p&lt;\infty$. Furthermore, our techniques yield further newresults in the study of sampling algorithms, showing that the root leveragescore sampling algorithm achieves a bound of roughly $d$ for $1\leq p&lt;2$, andthat a combination of leverage score and sensitivity sampling achieves animproved bound of roughly $d^{2/p}\mathfrak S^{2-4/p}$ for $2&lt;p&lt;\infty$. Oursensitivity sampling results yield the best known sample complexity for a wideclass of structured matrices that have small $\ell_p$ sensitivity.</description><author>David P. Woodruff, Taisuke Yasuda</author><pubDate>Wed, 03 Jan 2024 15:47:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00732v2</guid></item><item><title>CoMoSVC: Consistency Model-based Singing Voice Conversion</title><link>http://arxiv.org/abs/2401.01792v1</link><description>The diffusion-based Singing Voice Conversion (SVC) methods have achievedremarkable performances, producing natural audios with high similarity to thetarget timbre. However, the iterative sampling process results in slowinference speed, and acceleration thus becomes crucial. In this paper, wepropose CoMoSVC, a consistency model-based SVC method, which aims to achieveboth high-quality generation and high-speed sampling. A diffusion-based teachermodel is first specially designed for SVC, and a student model is furtherdistilled under self-consistency properties to achieve one-step sampling.Experiments on a single NVIDIA GTX4090 GPU reveal that although CoMoSVC has asignificantly faster inference speed than the state-of-the-art (SOTA)diffusion-based SVC system, it still achieves comparable or superior conversionperformance based on both subjective and objective metrics. Audio samples andcodes are available at https://comosvc.github.io/.</description><author>Yiwen Lu, Zhen Ye, Wei Xue, Xu Tan, Qifeng Liu, Yike Guo</author><pubDate>Wed, 03 Jan 2024 15:47:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01792v1</guid></item><item><title>Deep learning the Hurst parameter of linear fractional processes and assessing its reliability</title><link>http://arxiv.org/abs/2401.01789v1</link><description>This research explores the reliability of deep learning, specifically LongShort-Term Memory (LSTM) networks, for estimating the Hurst parameter infractional stochastic processes. The study focuses on three types of processes:fractional Brownian motion (fBm), fractional Ornstein-Uhlenbeck (fOU) process,and linear fractional stable motions (lfsm). The work involves a fastgeneration of extensive datasets for fBm and fOU to train the LSTM network on alarge volume of data in a feasible time. The study analyses the accuracy of theLSTM network's Hurst parameter estimation regarding various performancemeasures like RMSE, MAE, MRE, and quantiles of the absolute and relativeerrors. It finds that LSTM outperforms the traditional statistical methods inthe case of fBm and fOU processes; however, it has limited accuracy on lfsmprocesses. The research also delves into the implications of training lengthand valuation sequence length on the LSTM's performance. The methodology isapplied by estimating the Hurst parameter in Li-ion battery degradation dataand obtaining confidence bounds for the estimation. The study concludes thatwhile deep learning methods show promise in parameter estimation of fractionalprocesses, their effectiveness is contingent on the process type and thequality of training data.</description><author>Dániel Boros, Bálint Csanády, Iván Ivkovic, Lóránt Nagy, András Lukács, László Márkus</author><pubDate>Wed, 03 Jan 2024 15:42:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01789v1</guid></item><item><title>Applications of machine learning and IoT for Outdoor Air Pollution Monitoring and Prediction: A Systematic Literature Review</title><link>http://arxiv.org/abs/2401.01788v1</link><description>According to the World Health Organization (WHO), air pollution kills sevenmillion people every year. Outdoor air pollution is a major environmentalhealth problem affecting low, middle, and high-income countries. In the pastfew years, the research community has explored IoT-enabled machine learningapplications for outdoor air pollution prediction. The general objective ofthis paper is to systematically review applications of machine learning andInternet of Things (IoT) for outdoor air pollution prediction and thecombination of monitoring sensors and input features used. Two researchquestions were formulated for this review. 1086 publications were collected inthe initial PRISMA stage. After the screening and eligibility phases, 37 paperswere selected for inclusion. A cost-based analysis was conducted on thefindings to highlight high-cost monitoring, low-cost IoT and hybrid enabledprediction. Three methods of prediction were identified: time series,feature-based and spatio-temporal. This review's findings identify majorlimitations in applications found in the literature, namely lack of coverage,lack of diversity of data and lack of inclusion of context-specific features.This review proposes directions for future research and underlines practicalimplications in healthcare, urban planning, global synergy and smart cities.</description><author>Ihsane Gryech, Chaimae Assad, Mounir Ghogho, Abdellatif Kobbane</author><pubDate>Wed, 03 Jan 2024 15:36:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01788v1</guid></item><item><title>How to avoid machine learning pitfalls: a guide for academic researchers</title><link>http://arxiv.org/abs/2108.02497v4</link><description>This document outlines some of the common mistakes that occur when usingmachine learning, and what can be done to avoid them. Whilst it should beaccessible to anyone with a basic understanding of machine learning techniques,it was originally written for research students, and focuses on issues that areof particular concern within academic research, such as the need to do rigorouscomparisons and reach valid conclusions. It covers five stages of the machinelearning process: what to do before model building, how to reliably buildmodels, how to robustly evaluate models, how to compare models fairly, and howto report results.</description><author>Michael A. Lones</author><pubDate>Wed, 03 Jan 2024 15:35:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2108.02497v4</guid></item><item><title>Do DL models and training environments have an impact on energy consumption?</title><link>http://arxiv.org/abs/2307.05520v3</link><description>Current research in the computer vision field mainly focuses on improvingDeep Learning (DL) correctness and inference time performance. However, thereis still little work on the huge carbon footprint that has training DL models.This study aims to analyze the impact of the model architecture and trainingenvironment when training greener computer vision models. We divide this goalinto two research questions. First, we analyze the effects of modelarchitecture on achieving greener models while keeping correctness at optimallevels. Second, we study the influence of the training environment on producinggreener models. To investigate these relationships, we collect multiple metricsrelated to energy efficiency and model correctness during the models' training.Then, we outline the trade-offs between the measured energy efficiency and themodels' correctness regarding model architecture, and their relationship withthe training environment. We conduct this research in the context of a computervision system for image classification. In conclusion, we show that selectingthe proper model architecture and training environment can reduce energyconsumption dramatically (up to 81.38%) at the cost of negligible decreases incorrectness. Also, we find evidence that GPUs should scale with the models'computational complexity for better energy efficiency.</description><author>Santiago del Rey, Silverio Martínez-Fernández, Luís Cruz, Xavier Franch</author><pubDate>Wed, 03 Jan 2024 15:20:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.05520v3</guid></item><item><title>SYNTA: A novel approach for deep learning-based image analysis in muscle histopathology using photo-realistic synthetic data</title><link>http://arxiv.org/abs/2207.14650v3</link><description>Artificial intelligence (AI), machine learning, and deep learning (DL)methods are becoming increasingly important in the field of biomedical imageanalysis. However, to exploit the full potential of such methods, arepresentative number of experimentally acquired images containing asignificant number of manually annotated objects is needed as training data.Here we introduce SYNTA (synthetic data) as a novel approach for the generationof synthetic, photo-realistic, and highly complex biomedical images as trainingdata for DL systems. We show the versatility of our approach in the context ofmuscle fiber and connective tissue analysis in histological sections. Wedemonstrate that it is possible to perform robust and expert-level segmentationtasks on previously unseen real-world data, without the need for manualannotations using synthetic training data alone. Being a fully parametrictechnique, our approach poses an interpretable and controllable alternative toGenerative Adversarial Networks (GANs) and has the potential to significantlyaccelerate quantitative image analysis in a variety of biomedical applicationsin microscopy and beyond.</description><author>Leonid Mill, Oliver Aust, Jochen A. Ackermann, Philipp Burger, Monica Pascual, Katrin Palumbo-Zerr, Gerhard Krönke, Stefan Uderhardt, Georg Schett, Christoph S. Clemen, Rolf Schröder, Christian Holtzhausen, Samir Jabari, Andreas Maier, Anika Grüneboom</author><pubDate>Wed, 03 Jan 2024 15:18:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.14650v3</guid></item><item><title>Approximating Numerical Flux by Fourier Neural Operators for the Hyperbolic Conservation Laws</title><link>http://arxiv.org/abs/2401.01783v1</link><description>Classical numerical schemes exist for solving PDEs numerically, and recently,neural network-based methods have been developed. However, methodologies usingneural networks, such as PINN and neural operators, lack robustness andgeneralization power. To compensate for such drawbacks, there are many types ofresearch combining classical numerical schemes and machine learning methods byreplacing a small portion of the numerical schemes with neural networks. Inthis work, we focus on hyperbolic conservation laws and replace numericalfluxes in the numerical schemes by neural operator. For this, we constructlosses that are motivated by numerical schemes for conservation laws andapproximate numerical flux by FNO. Through experiments, we show that ourmethodology has advantages of both numerical schemes and FNO by comparing withoriginal methods. For instance, we demonstrate our method gains robustness,resolution invariance property, and feasibility of a data-driven method. Ourmethod especially has the ability to predict continuously in time andgeneralization power on the out-of-distribution samples, which are challengesto be tackled for existing neural operator methods.</description><author>Taeyoung Kim, Myungjoo Sang</author><pubDate>Wed, 03 Jan 2024 15:16:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01783v1</guid></item><item><title>LLM-SAP: Large Language Model Situational Awareness Based Planning</title><link>http://arxiv.org/abs/2312.16127v3</link><description>This work pioneers evaluating emergent planning capabilities based onsituational awareness in large language models. We contribute (i) novelbenchmarks and metrics for standardized assessment; (ii) a unique dataset tospur progress; and (iii) demonstrations that prompting and multi-agent schemessignificantly enhance planning performance in context-sensitive planning tasks.Positioning this within a situated agent and automated planning research, wehighlight inherent reliability challenges--efficiently mapping world states toactions without environmental guidance remains open despite simulated domainadvances. Although out-of-scope, limitations around validation methodology anddata availability indicate exciting directions, including fine-tuning onexpanded planning corpora and optimizations for triggering fast latentplanning. By conclusively demonstrating current methods' promise andlimitations via rigorous comparison, we catalyze investigating reliablegoal-directed reasoning for situated agents.</description><author>Liman Wang, Hanyang Zhong</author><pubDate>Wed, 03 Jan 2024 15:13:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16127v3</guid></item><item><title>Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering</title><link>http://arxiv.org/abs/2401.01780v1</link><description>While Large Language Models (LLM) are able to accumulate and restoreknowledge, they are still prone to hallucination. Especially when faced withfactual questions, LLM cannot only rely on knowledge stored in parameters toguarantee truthful and correct answers. Augmenting these models with theability to search on external information sources, such as the web, is apromising approach to ground knowledge to retrieve information. However,searching in a large collection of documents introduces additionalcomputational/time costs. An optimal behavior would be to query externalresources only when the LLM is not confident about answers. In this paper, wepropose a new LLM able to self-estimate if it is able to answer directly orneeds to request an external tool. We investigate a supervised approach byintroducing a hallucination masking mechanism in which labels are generatedusing a close book question-answering task. In addition, we propose to leverageparameter-efficient fine-tuning techniques to train our model on a small amountof data. Our model directly provides answers for $78.2\%$ of the known queriesand opts to search for $77.2\%$ of the unknown ones. This results in the APIbeing utilized only $62\%$ of the time.</description><author>Pierre Erbacher, Louis Falissar, Vincent Guigue, Laure Soulier</author><pubDate>Wed, 03 Jan 2024 15:12:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01780v1</guid></item><item><title>Recourse under Model Multiplicity via Argumentative Ensembling (Technical Report)</title><link>http://arxiv.org/abs/2312.15097v2</link><description>Model Multiplicity (MM) arises when multiple, equally performing machinelearning models can be trained to solve the same prediction task. Recentstudies show that models obtained under MM may produce inconsistent predictionsfor the same input. When this occurs, it becomes challenging to providecounterfactual explanations (CEs), a common means for offering recourserecommendations to individuals negatively affected by models' predictions. Inthis paper, we formalise this problem, which we name recourse-aware ensembling,and identify several desirable properties which methods for solving it shouldsatisfy. We show that existing ensembling methods, naturally extended indifferent ways to provide CEs, fail to satisfy these properties. We thenintroduce argumentative ensembling, deploying computational argumentation toguarantee robustness of CEs to MM, while also accommodating customisable userpreferences. We show theoretically and experimentally that argumentativeensembling satisfies properties which the existing methods lack, and that thetrade-offs are minimal wrt accuracy.</description><author>Junqi Jiang, Antonio Rago, Francesco Leofante, Francesca Toni</author><pubDate>Wed, 03 Jan 2024 15:02:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.15097v2</guid></item><item><title>Distribution Matching for Multi-Task Learning of Classification Tasks: a Large-Scale Study on Faces &amp; Beyond</title><link>http://arxiv.org/abs/2401.01219v2</link><description>Multi-Task Learning (MTL) is a framework, where multiple related tasks arelearned jointly and benefit from a shared representation space, or parametertransfer. To provide sufficient learning support, modern MTL uses annotateddata with full, or sufficiently large overlap across tasks, i.e., each inputsample is annotated for all, or most of the tasks. However, collecting suchannotations is prohibitive in many real applications, and cannot benefit fromdatasets available for individual tasks. In this work, we challenge this setupand show that MTL can be successful with classification tasks with little, ornon-overlapping annotations, or when there is big discrepancy in the size oflabeled data per task. We explore task-relatedness for co-annotation andco-training, and propose a novel approach, where knowledge exchange is enabledbetween the tasks via distribution matching. To demonstrate the generalapplicability of our method, we conducted diverse case studies in the domainsof affective computing, face recognition, species recognition, and shoppingitem classification using nine datasets. Our large-scale study of affectivetasks for basic expression recognition and facial action unit detectionillustrates that our approach is network agnostic and brings large performanceimprovements compared to the state-of-the-art in both tasks and across allstudied databases. In all case studies, we show that co-training viatask-relatedness is advantageous and prevents negative transfer (which occurswhen MT model's performance is worse than that of at least one single-taskmodel).</description><author>Dimitrios Kollias, Viktoriia Sharmanska, Stefanos Zafeiriou</author><pubDate>Wed, 03 Jan 2024 15:00:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01219v2</guid></item><item><title>A Novel Paradigm for Neural Computation: X-Net with Learnable Neurons and Adaptable Structure</title><link>http://arxiv.org/abs/2401.01772v1</link><description>Artificial neural networks (ANNs) have permeated various disciplinarydomains, ranging from bioinformatics to financial analytics, where theirapplication has become an indispensable facet of contemporary scientificresearch endeavors. However, the inherent limitations of traditional neuralnetworks arise due to their relatively fixed network structures and activationfunctions. 1, The type of activation function is single and relatively fixed,which leads to poor "unit representation ability" of the network, and it isoften used to solve simple problems with very complex networks; 2, the networkstructure is not adaptive, it is easy to cause network structure redundant orinsufficient. To address the aforementioned issues, this study proposes a novelneural network called X-Net. By utilizing our designed AlternatingBackpropagation mechanism, X-Net dynamically selects appropriate activationfunctions based on derivative information during training to enhance thenetwork's representation capability for specific tasks. Simultaneously, itaccurately adjusts the network structure at the neuron level to accommodatetasks of varying complexities and reduce computational costs. Through a seriesof experiments, we demonstrate the dual advantages of X-Net in terms ofreducing model size and improving representation power. Specifically, in termsof the number of parameters, X-Net is only 3$\%$ of baselines on average, andonly 1.4$\%$ under some tasks. In terms of representation ability, X-Net canachieve an average $R^2$=0.985 on the fitting task by only optimizing theactivation function without introducing any parameters. Finally, we also testedthe ability of X-Net to help scientific discovery on data from multipledisciplines such as society, energy, environment, and aerospace, and achievedconcise and good results.</description><author>Yanjie Li, Weijun Li, Lina Yu, Min Wu, Jinyi Liu, Wenqiang Li, Meilan Hao</author><pubDate>Wed, 03 Jan 2024 14:52:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01772v1</guid></item><item><title>SVGDreamer: Text Guided SVG Generation with Diffusion Model</title><link>http://arxiv.org/abs/2312.16476v2</link><description>Recently, text-guided scalable vector graphics (SVGs) synthesis has shownpromise in domains such as iconography and sketch. However, existingtext-to-SVG generation methods lack editability and struggle with visualquality and result diversity. To address these limitations, we propose a noveltext-guided vector graphics synthesis method called SVGDreamer. SVGDreamerincorporates a semantic-driven image vectorization (SIVE) process that enablesthe decomposition of synthesis into foreground objects and background, therebyenhancing editability. Specifically, the SIVE process introduce attention-basedprimitive control and an attention-mask loss function for effective control andmanipulation of individual elements. Additionally, we propose a VectorizedParticle-based Score Distillation (VPSD) approach to tackle the challenges ofcolor over-saturation, vector primitives over-smoothing, and limited resultdiversity in existing text-to-SVG generation methods. Furthermore, on the basisof VPSD, we introduce Reward Feedback Learning (ReFL) to accelerate VPSDconvergence and improve aesthetic appeal. Extensive experiments have beenconducted to validate the effectiveness of SVGDreamer, demonstrating itssuperiority over baseline methods in terms of editability, visual quality, anddiversity. The code and demo of SVGDreamer can be found at\href{https://ximinng.github.io/SVGDreamer-project/}{https://ximinng.github.io/SVGDreamer-project/}.</description><author>Ximing Xing, Haitao Zhou, Chuang Wang, Jing Zhang, Dong Xu, Qian Yu</author><pubDate>Wed, 03 Jan 2024 14:40:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16476v2</guid></item><item><title>Fading memory as inductive bias in residual recurrent networks</title><link>http://arxiv.org/abs/2307.14823v2</link><description>Residual connections have been proposed as an architecture-based inductivebias to mitigate the problem of exploding and vanishing gradients and increasedtask performance in both feed-forward and recurrent networks (RNNs) whentrained with the backpropagation algorithm. Yet, little is known about howresidual connections in RNNs influence their dynamics and fading memoryproperties. Here, we introduce weakly coupled residual recurrent networks(WCRNNs) in which residual connections result in well-defined Lyapunovexponents and allow for studying properties of fading memory. We investigatehow the residual connections of WCRNNs influence their performance, networkdynamics, and memory properties on a set of benchmark tasks. We show thatseveral distinct forms of residual connections yield effective inductive biasesthat result in increased network expressivity. In particular, those areresidual connections that (i) result in network dynamics at the proximity ofthe edge of chaos, (ii) allow networks to capitalize on characteristic spectralproperties of the data, and (iii) result in heterogeneous memory properties. Inaddition, we demonstrate how our results can be extended to non-linearresiduals and introduce a weakly coupled residual initialization scheme thatcan be used for Elman RNNs.</description><author>Igor Dubinin, Felix Effenberger</author><pubDate>Wed, 03 Jan 2024 14:38:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.14823v2</guid></item><item><title>Inversion-by-Inversion: Exemplar-based Sketch-to-Photo Synthesis via Stochastic Differential Equations without Training</title><link>http://arxiv.org/abs/2308.07665v2</link><description>Exemplar-based sketch-to-photo synthesis allows users to generatephoto-realistic images based on sketches. Recently, diffusion-based methodshave achieved impressive performance on image generation tasks, enablinghighly-flexible control through text-driven generation or energy functions.However, generating photo-realistic images with color and texture from sketchimages remains challenging for diffusion models. Sketches typically consist ofonly a few strokes, with most regions left blank, making it difficult fordiffusion-based methods to produce photo-realistic images. In this work, wepropose a two-stage method named ``Inversion-by-Inversion" for exemplar-basedsketch-to-photo synthesis. This approach includes shape-enhancing inversion andfull-control inversion. During the shape-enhancing inversion process, anuncolored photo is generated with the guidance of a shape-energy function. Thisstep is essential to ensure control over the shape of the generated photo. Inthe full-control inversion process, we propose an appearance-energy function tocontrol the color and texture of the final generated photo.Importantly, ourInversion-by-Inversion pipeline is training-free and can accept different typesof exemplars for color and texture control. We conducted extensive experimentsto evaluate our proposed method, and the results demonstrate its effectiveness.The code and project can be found athttps://ximinng.github.io/inversion-by-inversion-project/.</description><author>Ximing Xing, Chuang Wang, Haitao Zhou, Zhihao Hu, Chongxuan Li, Dong Xu, Qian Yu</author><pubDate>Wed, 03 Jan 2024 14:36:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.07665v2</guid></item><item><title>HOI4D: A 4D Egocentric Dataset for Category-Level Human-Object Interaction</title><link>http://arxiv.org/abs/2203.01577v4</link><description>We present HOI4D, a large-scale 4D egocentric dataset with rich annotations,to catalyze the research of category-level human-object interaction. HOI4Dconsists of 2.4M RGB-D egocentric video frames over 4000 sequences collected by4 participants interacting with 800 different object instances from 16categories over 610 different indoor rooms. Frame-wise annotations for panopticsegmentation, motion segmentation, 3D hand pose, category-level object pose andhand action have also been provided, together with reconstructed object meshesand scene point clouds. With HOI4D, we establish three benchmarking tasks topromote category-level HOI from 4D visual signals including semanticsegmentation of 4D dynamic point cloud sequences, category-level object posetracking, and egocentric action segmentation with diverse interaction targets.In-depth analysis shows HOI4D poses great challenges to existing methods andproduces great research opportunities.</description><author>Yunze Liu, Yun Liu, Che Jiang, Kangbo Lyu, Weikang Wan, Hao Shen, Boqiang Liang, Zhoujie Fu, He Wang, Li Yi</author><pubDate>Wed, 03 Jan 2024 14:31:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2203.01577v4</guid></item><item><title>Cross-target Stance Detection by Exploiting Target Analytical Perspectives</title><link>http://arxiv.org/abs/2401.01761v1</link><description>Cross-target stance detection (CTSD) is an important task, which infers theattitude of the destination target by utilizing annotated data derived from thesource target. One important approach in CTSD is to extract domain-invariantfeatures to bridge the knowledge gap between multiple targets. However, theanalysis of informal and short text structure, and implicit expressions,complicate the extraction of domain-invariant knowledge. In this paper, wepropose a Multi-Perspective Prompt-Tuning (MPPT) model for CTSD that uses theanalysis perspective as a bridge to transfer knowledge. First, we develop atwo-stage instruct-based chain-of-thought method (TsCoT) to elicit targetanalysis perspectives and provide natural language explanations (NLEs) frommultiple viewpoints by formulating instructions based on large language model(LLM). Second, we propose a multi-perspective prompt-tuning framework(MultiPLN) to fuse the NLEs into the stance predictor. Extensive experimentsresults demonstrate the superiority of MPPT against the state-of-the-artbaseline methods.</description><author>Daijun Ding, Rong Chen, Bowen Zhang, Xu Huang, Li Dong, Xiaowen Zhao, Ge Song, Liwen Jing</author><pubDate>Wed, 03 Jan 2024 14:28:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01761v1</guid></item><item><title>VGA: Vision and Graph Fused Attention Network for Rumor Detection</title><link>http://arxiv.org/abs/2401.01759v1</link><description>With the development of social media, rumors have been spread broadly onsocial media platforms, causing great harm to society. Beside textualinformation, many rumors also use manipulated images or conceal textualinformation within images to deceive people and avoid being detected, makingmultimodal rumor detection be a critical problem. The majority of multimodalrumor detection methods mainly concentrate on extracting features of sourceclaims and their corresponding images, while ignoring the comments of rumorsand their propagation structures. These comments and structures imply thewisdom of crowds and are proved to be crucial to debunk rumors. Moreover, thesemethods usually only extract visual features in a basic manner, seldom considertampering or textual information in images. Therefore, in this study, wepropose a novel Vision and Graph Fused Attention Network (VGA) for rumordetection to utilize propagation structures among posts so as to obtain thecrowd opinions and further explore visual tampering features, as well as thetextual information hidden in images. We conduct extensive experiments on threedatasets, demonstrating that VGA can effectively detect multimodal rumors andoutperform state-of-the-art methods significantly.</description><author>Lin Bai, Caiyan Jia, Ziying Song, Chaoqun Cui</author><pubDate>Wed, 03 Jan 2024 14:24:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01759v1</guid></item><item><title>TrAISformer -- A Transformer Network with Sparse Augmented Data Representation and Cross Entropy Loss for AIS-based Vessel Trajectory Prediction</title><link>http://arxiv.org/abs/2109.03958v4</link><description>Vessel trajectory prediction plays a pivotal role in numerous maritimeapplications and services. While the Automatic Identification System (AIS)offers a rich source of information to address this task, forecasting vesseltrajectory using AIS data remains challenging, even for modern machine learningtechniques, because of the inherent heterogeneous and multimodal nature ofmotion data. In this paper, we propose a novel approach to tackle thesechallenges. We introduce a discrete, high-dimensional representation of AISdata and a new loss function designed to explicitly address heterogeneity andmultimodality. The proposed model-referred to as TrAISformer-is a modifiedtransformer network that extracts long-term temporal patterns in AIS vesseltrajectories in the proposed enriched space to forecast the positions ofvessels several hours ahead. We report experimental results on real, publiclyavailable AIS data. TrAISformer significantly outperforms state-of-the-artmethods, with an average prediction performance below 10 nautical miles up to~10 hours.</description><author>Duong Nguyen, Ronan Fablet</author><pubDate>Wed, 03 Jan 2024 14:22:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.03958v4</guid></item><item><title>A Computation and Communication Efficient Method for Distributed Nonconvex Problems in the Partial Participation Setting</title><link>http://arxiv.org/abs/2205.15580v4</link><description>We present a new method that includes three key components of distributedoptimization and federated learning: variance reduction of stochasticgradients, partial participation, and compressed communication. We prove thatthe new method has optimal oracle complexity and state-of-the-art communicationcomplexity in the partial participation setting. Regardless of thecommunication compression feature, our method successfully combines variancereduction and partial participation: we get the optimal oracle complexity,never need the participation of all nodes, and do not require the boundedgradients (dissimilarity) assumption.</description><author>Alexander Tyurin, Peter Richtárik</author><pubDate>Wed, 03 Jan 2024 14:21:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2205.15580v4</guid></item><item><title>Disentangled (Un)Controllable Features</title><link>http://arxiv.org/abs/2211.00086v2</link><description>In the context of MDPs with high-dimensional states, downstream tasks arepredominantly applied on a compressed, low-dimensional representation of theoriginal input space. A variety of learning objectives have therefore been usedto attain useful representations. However, these representations usually lackinterpretability of the different features. We present a novel approach that isable to disentangle latent features into a controllable and an uncontrollablepartition. We illustrate that the resulting partitioned representations areeasily interpretable on three types of environments and show that, in adistribution of procedurally generated maze environments, it is feasible tointerpretably employ a planning algorithm in the isolated controllable latentpartition.</description><author>Jacob E. Kooi, Mark Hoogendoorn, Vincent François-Lavet</author><pubDate>Wed, 03 Jan 2024 14:20:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2211.00086v2</guid></item><item><title>Incremental FastPitch: Chunk-based High Quality Text to Speech</title><link>http://arxiv.org/abs/2401.01755v1</link><description>Parallel text-to-speech models have been widely applied for real-time speechsynthesis, and they offer more controllability and a much faster synthesisprocess compared with conventional auto-regressive models. Although parallelmodels have benefits in many aspects, they become naturally unfit forincremental synthesis due to their fully parallel architecture such astransformer. In this work, we propose Incremental FastPitch, a novel FastPitchvariant capable of incrementally producing high-quality Mel chunks by improvingthe architecture with chunk-based FFT blocks, training with receptive-fieldconstrained chunk attention masks, and inference with fixed size past modelstates. Experimental results show that our proposal can produce speech qualitycomparable to the parallel FastPitch, with a significant lower latency thatallows even lower response time for real-time speech applications.</description><author>Muyang Du, Chuan Liu, Junjie Lai</author><pubDate>Wed, 03 Jan 2024 14:17:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01755v1</guid></item><item><title>Using AI/ML to Find and Remediate Enterprise Secrets in Code &amp; Document Sharing Platforms</title><link>http://arxiv.org/abs/2401.01754v1</link><description>We introduce a new challenge to the software development community: 1)leveraging AI to accurately detect and flag up secrets in code and on populardocument sharing platforms that frequently used by developers, such asConfluence and 2) automatically remediating the detections (e.g. by suggestingpassword vault functionality). This is a challenging, and mostly unaddressedtask. Existing methods leverage heuristics and regular expressions, that can bevery noisy, and therefore increase toil on developers. The next step -modifying code itself - to automatically remediate a detection, is a complextask. We introduce two baseline AI models that have good detection performanceand propose an automatic mechanism for remediating secrets found in code,opening up the study of this task to the wider community.</description><author>Gregor Kerr, David Algorry, Senad Ibraimoski, Peter Maciver, Sean Moran</author><pubDate>Wed, 03 Jan 2024 14:15:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01754v1</guid></item><item><title>A Generative AI Assistant to Accelerate Cloud Migration</title><link>http://arxiv.org/abs/2401.01753v1</link><description>We present a tool that leverages generative AI to accelerate the migration ofon-premises applications to the cloud. The Cloud Migration LLM accepts inputfrom the user specifying the parameters of their migration, and outputs amigration strategy with an architecture diagram. A user study suggests that themigration LLM can assist inexperienced users in finding the right cloudmigration profile, while avoiding complexities of a manual approach.</description><author>Amal Vaidya, Mohan Krishna Vankayalapati, Jacky Chan, Senad Ibraimoski, Sean Moran</author><pubDate>Wed, 03 Jan 2024 14:13:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01753v1</guid></item><item><title>FullLoRA-AT: Efficiently Boosting the Robustness of Pretrained Vision Transformers</title><link>http://arxiv.org/abs/2401.01752v1</link><description>In recent years, the Vision Transformer (ViT) model has gradually becomemainstream in various computer vision tasks, and the robustness of the modelhas received increasing attention. However, existing large models tend toprioritize performance during training, potentially neglecting the robustness,which may lead to serious security concerns. In this paper, we establish a newchallenge: exploring how to use a small number of additional parameters foradversarial finetuning to quickly and effectively enhance the adversarialrobustness of a standardly trained model. To address this challenge, we developthe novel LNLoRA module, incorporating a learnable layer normalization beforethe conventional LoRA module, which helps mitigate magnitude differences inparameters between the adversarial and standard training paradigms. Furthermore, we propose the FullLoRA-AT framework by integrating thelearnable LNLoRA modules into all key components of ViT-based models whilekeeping the pretrained model frozen, which can significantly improve the modelrobustness via adversarial finetuning in a parameter-efficient manner. Extensive experiments on CIFAR-10, CIFAR-100, and Imagenette demonstrate thesuperiority of our proposed FullLoRA-AT framework. It achieves comparablerobustness with full finetuning while only requiring about 5% of the learnableparameters. This also effectively addresses concerns regarding extra modelstorage space and enormous training time caused by adversarial finetuning.</description><author>Zheng Yuan, Jie Zhang, Shiguang Shan</author><pubDate>Wed, 03 Jan 2024 14:08:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01752v1</guid></item><item><title>Quality and Quantity of Machine Translation References for Automated Metrics</title><link>http://arxiv.org/abs/2401.01283v2</link><description>Automatic machine translation metrics often use human translations todetermine the quality system translations. Common wisdom in the field dictatesthat the human references should be of very high quality. However, there are nocost-benefit analyses that could be used to guide practitioners who plan tocollect references for machine translation evaluation. We find thathigher-quality references lead to better metric correlations with humans at thesegment-level. Having up to 7 references per segment and taking their averagehelps all metrics. Interestingly, the references from vendors of differentqualities can be mixed together and improve metric success. Higher qualityreferences, however, cost more to create and we frame this as an optimizationproblem: given a specific budget, what references should be collected tomaximize metric success. These findings can be used by evaluators of sharedtasks when references need to be created under a certain budget.</description><author>Vilém Zouhar, Ondřej Bojar</author><pubDate>Wed, 03 Jan 2024 14:01:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01283v2</guid></item><item><title>A Comprehensive Study of Object Tracking in Low-Light Environments</title><link>http://arxiv.org/abs/2312.16250v2</link><description>Accurate object tracking in low-light environments is crucial, particularlyin surveillance and ethology applications. However, achieving this issignificantly challenging due to the poor quality of captured sequences.Factors such as noise, color imbalance, and low contrast contribute to thesechallenges. This paper presents a comprehensive study examining the impact ofthese distortions on automatic object trackers. Additionally, we propose asolution to enhance tracking performance by integrating denoising and low-lightenhancement methods into the transformer-based object tracking system.Experimental results show that the proposed tracker, trained with low-lightsynthetic datasets, outperforms both the vanilla MixFormer and Siam R-CNN.</description><author>Anqi Yi, Nantheera Anantrasirichai</author><pubDate>Wed, 03 Jan 2024 13:59:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.16250v2</guid></item><item><title>Towards Robust Semantic Segmentation against Patch-based Attack via Attention Refinement</title><link>http://arxiv.org/abs/2401.01750v1</link><description>The attention mechanism has been proven effective on various visual tasks inrecent years. In the semantic segmentation task, the attention mechanism isapplied in various methods, including the case of both Convolution NeuralNetworks (CNN) and Vision Transformer (ViT) as backbones. However, we observethat the attention mechanism is vulnerable to patch-based adversarial attacks.Through the analysis of the effective receptive field, we attribute it to thefact that the wide receptive field brought by global attention may lead to thespread of the adversarial patch. To address this issue, in this paper, wepropose a Robust Attention Mechanism (RAM) to improve the robustness of thesemantic segmentation model, which can notably relieve the vulnerabilityagainst patch-based attacks. Compared to the vallina attention mechanism, RAMintroduces two novel modules called Max Attention Suppression and RandomAttention Dropout, both of which aim to refine the attention matrix and limitthe influence of a single adversarial patch on the semantic segmentationresults of other positions. Extensive experiments demonstrate the effectivenessof our RAM to improve the robustness of semantic segmentation models againstvarious patch-based attack methods under different attack settings.</description><author>Zheng Yuan, Jie Zhang, Yude Wang, Shiguang Shan, Xilin Chen</author><pubDate>Wed, 03 Jan 2024 13:58:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01750v1</guid></item><item><title>Few-shot Image Generation via Information Transfer from the Built Geodesic Surface</title><link>http://arxiv.org/abs/2401.01749v1</link><description>Images generated by most of generative models trained with limited data oftenexhibit deficiencies in either fidelity, diversity, or both. One effectivesolution to address the limitation is few-shot generative model adaption.However, the type of approaches typically rely on a large-scale pre-trainedmodel, serving as a source domain, to facilitate information transfer to thetarget domain. In this paper, we propose a method called Information Transferfrom the Built Geodesic Surface (ITBGS), which contains two module: FeatureAugmentation on Geodesic Surface (FAGS); Interpolation and Regularization(I\&amp;R). With the FAGS module, a pseudo-source domain is created by projectingimage features from the training dataset into the Pre-Shape Space, subsequentlygenerating new features on the Geodesic surface. Thus, no pre-trained models isneeded for the adaption process during the training of generative models withFAGS. I\&amp;R module are introduced for supervising the interpolated images andregularizing their relative distances, respectively, to further enhance thequality of generated images. Through qualitative and quantitative experiments,we demonstrate that the proposed method consistently achieves optimal orcomparable results across a diverse range of semantically distinct datasets,even in extremely few-shot scenarios.</description><author>Yuexing Han, Liheng Ruan, Bing Wang</author><pubDate>Wed, 03 Jan 2024 13:57:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01749v1</guid></item><item><title>Adversarial Representation Learning for Robust Privacy Preservation in Audio</title><link>http://arxiv.org/abs/2305.00011v2</link><description>Sound event detection systems are widely used in various applications such assurveillance and environmental monitoring where data is automaticallycollected, processed, and sent to a cloud for sound recognition. However, thisprocess may inadvertently reveal sensitive information about users or theirsurroundings, hence raising privacy concerns. In this study, we propose a noveladversarial training method for learning representations of audio recordingsthat effectively prevents the detection of speech activity from the latentfeatures of the recordings. The proposed method trains a model to generateinvariant latent representations of speech-containing audio recordings thatcannot be distinguished from non-speech recordings by a speech classifier. Thenovelty of our work is in the optimization algorithm, where the speechclassifier's weights are regularly replaced with the weights of classifierstrained in a supervised manner. This increases the discrimination power of thespeech classifier constantly during the adversarial training, motivating themodel to generate latent representations in which speech is notdistinguishable, even using new speech classifiers trained outside theadversarial training loop. The proposed method is evaluated against a baselineapproach with no privacy measures and a prior adversarial training method,demonstrating a significant reduction in privacy violations compared to thebaseline approach. Additionally, we show that the prior adversarial method ispractically ineffective for this purpose.</description><author>Shayan Gharib, Minh Tran, Diep Luong, Konstantinos Drossos, Tuomas Virtanen</author><pubDate>Wed, 03 Jan 2024 13:51:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.00011v2</guid></item><item><title>A Survey of Text Watermarking in the Era of Large Language Models</title><link>http://arxiv.org/abs/2312.07913v3</link><description>Text watermarking algorithms play a crucial role in the copyright protectionof textual content, yet their capabilities and application scenarios have beenlimited historically. The recent developments in large language models (LLMs)have opened new opportunities for the advancement of text watermarkingtechniques. LLMs not only enhance the capabilities of text watermarkingalgorithms through their text understanding and generation abilities but alsonecessitate the use of text watermarking algorithms for their own copyrightprotection. This paper conducts a comprehensive survey of the current state oftext watermarking technology, covering four main aspects: (1) an overview andcomparison of different text watermarking techniques; (2) evaluation methodsfor text watermarking algorithms, including their success rates, impact on textquality, robustness, and unforgeability; (3) potential application scenariosfor text watermarking technology; (4) current challenges and future directionsfor development. This survey aims to provide researchers with a thoroughunderstanding of text watermarking technology, thereby promoting its furtheradvancement.</description><author>Aiwei Liu, Leyi Pan, Yijian Lu, Jingjing Li, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu</author><pubDate>Wed, 03 Jan 2024 13:29:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07913v3</guid></item><item><title>Semisupervised Anomaly Detection using Support Vector Regression with Quantum Kernel</title><link>http://arxiv.org/abs/2308.00583v2</link><description>Anomaly detection (AD) involves identifying observations or events thatdeviate in some way from the rest of the data. Machine learning techniques haveshown success in automating this process by detecting hidden patterns anddeviations in large-scale data. The potential of quantum computing for machinelearning has been widely recognized, leading to extensive research efforts todevelop suitable quantum machine learning (QML) algorithms. In particular, thesearch for QML algorithms for near-term NISQ devices is in full swing. However,NISQ devices pose additional challenges due to their limited qubit coherencetimes, low number of qubits, and high error rates. Kernel methods based onquantum kernel estimation have emerged as a promising approach to QML on NISQdevices, offering theoretical guarantees, versatility, and compatibility withNISQ constraints. Especially support vector machines (SVM) utilizing quantumkernel estimation have shown success in various supervised learning tasks.However, in the context of AD, semisupervised learning is of great relevance,and yet there is limited research published in this area. This paper introducesan approach to semisupervised AD based on the reconstruction loss of a supportvector regression (SVR) with quantum kernel. This novel model is an alternativeto the variational quantum and quantum kernel one-class classifiers, and iscompared to a quantum autoencoder as quantum baseline and a SVR withradial-basis-function (RBF) kernel as well as a classical autoencoder asclassical baselines. The models are benchmarked extensively on 10 real-world ADdata sets and one toy data set, and it is shown that our SVR model with quantumkernel performs better than the SVR with RBF kernel as well as all othermodels, achieving highest mean AUC over all data sets. In addition, our QSVRoutperforms the quantum autoencoder on 9 out of 11 data sets.</description><author>Kilian Tscharke, Sebastian Issel, Pascal Debus</author><pubDate>Wed, 03 Jan 2024 13:26:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.00583v2</guid></item><item><title>Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents</title><link>http://arxiv.org/abs/2310.19923v3</link><description>Text embedding models have emerged as powerful tools for transformingsentences into fixed-sized feature vectors that encapsulate semanticinformation. While these models are essential for tasks like informationretrieval, semantic clustering, and text re-ranking, most existing open-sourcemodels, especially those built on architectures like BERT, struggle torepresent lengthy documents and often resort to truncation. One common approachto mitigate this challenge involves splitting documents into smaller paragraphsfor embedding. However, this strategy results in a much larger set of vectors,consequently leading to increased memory consumption and computationallyintensive vector searches with elevated latency. To address these challenges, we introduce Jina Embeddings 2, an open-sourcetext embedding model capable of accommodating up to 8192 tokens. This model isdesigned to transcend the conventional 512-token limit and adeptly process longdocuments. Jina Embeddings 2 not only achieves state-of-the-art performance ona range of embedding-related tasks in the MTEB benchmark but also matches theperformance of OpenAI's proprietary ada-002 model. Additionally, ourexperiments indicate that an extended context can enhance performance in taskssuch as NarrativeQA.</description><author>Michael Günther, Jackmin Ong, Isabelle Mohr, Alaeddine Abdessalem, Tanguy Abel, Mohammad Kalim Akram, Susana Guzman, Georgios Mastrapas, Saba Sturua, Bo Wang, Maximilian Werk, Nan Wang, Han Xiao</author><pubDate>Wed, 03 Jan 2024 13:26:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.19923v3</guid></item><item><title>On Memorization and Privacy Risks of Sharpness Aware Minimization</title><link>http://arxiv.org/abs/2310.00488v2</link><description>In many recent works, there is an increased focus on designing algorithmsthat seek flatter optima for neural network loss optimization as there isempirical evidence that it leads to better generalization performance in manydatasets. In this work, we dissect these performance gains through the lens ofdata memorization in overparameterized models. We define a new metric thathelps us identify which data points specifically do algorithms seeking flatteroptima do better when compared to vanilla SGD. We find that the generalizationgains achieved by Sharpness Aware Minimization (SAM) are particularlypronounced for atypical data points, which necessitate memorization. Thisinsight helps us unearth higher privacy risks associated with SAM, which weverify through exhaustive empirical evaluations. Finally, we propose mitigationstrategies to achieve a more desirable accuracy vs privacy tradeoff.</description><author>Young In Kim, Pratiksha Agrawal, Johannes O. Royset, Rajiv Khanna</author><pubDate>Wed, 03 Jan 2024 13:23:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00488v2</guid></item><item><title>Few-shot Adaptation of Multi-modal Foundation Models: A Survey</title><link>http://arxiv.org/abs/2401.01736v1</link><description>Multi-modal (vision-language) models, such as CLIP, are replacing traditionalsupervised pre-training models (e.g., ImageNet-based pre-training) as the newgeneration of visual foundation models. These models with robust and alignedsemantic representations learned from billions of internet image-text pairs andcan be applied to various downstream tasks in a zero-shot manner. However, insome fine-grained domains like medical imaging and remote sensing, theperformance of multi-modal foundation models often leaves much to be desired.Consequently, many researchers have begun to explore few-shot adaptationmethods for these models, gradually deriving three main technical approaches:1) prompt-based methods, 2) adapter-based methods, and 3) externalknowledge-based methods. Nevertheless, this rapidly developing field hasproduced numerous results without a comprehensive survey to systematicallyorganize the research progress. Therefore, in this survey, we introduce andanalyze the research advancements in few-shot adaptation methods formulti-modal models, summarizing commonly used datasets and experimental setups,and comparing the results of different methods. In addition, due to the lack ofreliable theoretical support for existing methods, we derive the few-shotadaptation generalization error bound for multi-modal models. The theoremreveals that the generalization error of multi-modal foundation models isconstrained by three factors: domain gap, model capacity, and sample size.Based on this, we propose three possible solutions from the following aspects:1) adaptive domain generalization, 2) adaptive model selection, and 3) adaptiveknowledge utilization.</description><author>Fan Liu, Tianshu Zhang, Wenwen Dai, Wenwen Cai Xiaocong Zhou, Delong Chen</author><pubDate>Wed, 03 Jan 2024 13:19:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01736v1</guid></item><item><title>Learning Keypoints for Robotic Cloth Manipulation using Synthetic Data</title><link>http://arxiv.org/abs/2401.01734v1</link><description>Assistive robots should be able to wash, fold or iron clothes. However, dueto the variety, deformability and self-occlusions of clothes, creatinggeneral-purpose robot systems for cloth manipulation is challenging. Syntheticdata is a promising direction to improve generalization, though its usabilityis often limited by the sim-to-real gap. To advance the use of synthetic datafor cloth manipulation and to enable tasks such as robotic folding, we presenta synthetic data pipeline to train keypoint detectors for almost flattenedcloth items. To test its performance, we have also collected a real-worlddataset. We train detectors for both T-shirts, towels and shorts and obtain anaverage precision of 64.3%. Fine-tuning on real-world data improves performanceto 74.2%. Additional insight is provided by discussing various failure modes ofthe keypoint detectors and by comparing different approaches to obtain clothmeshes and materials. We also quantify the remaining sim-to-real gap and arguethat further improvements to the fidelity of cloth assets will be required tofurther reduce this gap. The code, dataset and trained models are availableonline.</description><author>Thomas Lips, Victor-Louis De Gusseme, Francis wyffels</author><pubDate>Wed, 03 Jan 2024 13:16:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01734v1</guid></item><item><title>Investigating the Suitability of Concept Drift Detection for Detecting Leakages in Water Distribution Networks</title><link>http://arxiv.org/abs/2401.01733v1</link><description>Leakages are a major risk in water distribution networks as they cause waterloss and increase contamination risks. Leakage detection is a difficult taskdue to the complex dynamics of water distribution networks. In particular,small leakages are hard to detect. From a machine-learning perspective,leakages can be modeled as concept drift. Thus, a wide variety of driftdetection schemes seems to be a suitable choice for detecting leakages. In thiswork, we explore the potential of model-loss-based and distribution-based driftdetection methods to tackle leakage detection. We additionally discuss theissue of temporal dependencies in the data and propose a way to cope with itwhen applying distribution-based detection. We evaluate different methodssystematically for leakages of different sizes and detection times.Additionally, we propose a first drift-detection-based technique for localizingleakages.</description><author>Valerie Vaquet, Fabian Hinder, Barbara Hammer</author><pubDate>Wed, 03 Jan 2024 13:12:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01733v1</guid></item><item><title>Task and Explanation Network</title><link>http://arxiv.org/abs/2401.01732v1</link><description>Explainability in deep networks has gained increased importance in recentyears. We argue herein that an AI must be tasked not just with a task but alsowith an explanation of why said task was accomplished as such. We present abasic framework -- Task and Explanation Network (TENet) -- which fullyintegrates task completion and its explanation. We believe that the field of AIas a whole should insist -- quite emphatically -- on explainability.</description><author>Moshe Sipper</author><pubDate>Wed, 03 Jan 2024 13:11:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01732v1</guid></item><item><title>STAF: 3D Human Mesh Recovery from Video with Spatio-Temporal Alignment Fusion</title><link>http://arxiv.org/abs/2401.01730v1</link><description>The recovery of 3D human mesh from monocular images has significantly beendeveloped in recent years. However, existing models usually ignore spatial andtemporal information, which might lead to mesh and image misalignment andtemporal discontinuity. For this reason, we propose a novel Spatio-TemporalAlignment Fusion (STAF) model. As a video-based model, it leverages coherenceclues from human motion by an attention-based Temporal Coherence Fusion Module(TCFM). As for spatial mesh-alignment evidence, we extract fine-grained localinformation through predicted mesh projection on the feature maps. Based on thespatial features, we further introduce a multi-stage adjacent Spatial AlignmentFusion Module (SAFM) to enhance the feature representation of the target frame.In addition to the above, we propose an Average Pooling Module (APM) to allowthe model to focus on the entire input sequence rather than just the targetframe. This method can remarkably improve the smoothness of recovery resultsfrom video. Extensive experiments on 3DPW, MPII3D, and H36M demonstrate thesuperiority of STAF. We achieve a state-of-the-art trade-off between precisionand smoothness. Our code and more video results are on the project pagehttps://yw0208.github.io/staf/</description><author>Wei Yao, Hongwen Zhang, Yunlian Sun, Jinhui Tang</author><pubDate>Wed, 03 Jan 2024 13:07:14 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01730v1</guid></item><item><title>Ravnest: Decentralized Asynchronous Training on Heterogeneous Devices</title><link>http://arxiv.org/abs/2401.01728v1</link><description>Modern deep learning models, growing larger and more complex, havedemonstrated exceptional generalization and accuracy due to training on hugedatasets. This trend is expected to continue. However, the increasing size ofthese models poses challenges in training, as traditional centralized methodsare limited by memory constraints at such scales. This paper proposes anasynchronous decentralized training paradigm for large modern deep learningmodels that harnesses the compute power of regular heterogeneous PCs withlimited resources connected across the internet to achieve favourableperformance metrics. Ravnest facilitates decentralized training by efficientlyorganizing compute nodes into clusters with similar data transfer rates andcompute capabilities, without necessitating that each node hosts the entiremodel. These clusters engage in $\textit{Zero-Bubble Asynchronous ModelParallel}$ training, and a $\textit{Parallel Multi-Ring All-Reduce}$ method isemployed to effectively execute global parameter averaging across all clusters.We have framed our asynchronous SGD loss function as a block structuredoptimization problem with delayed updates and derived an optimal convergencerate of $O\left(\frac{1}{\sqrt{K}}\right)$. We further discuss linear speedupwith respect to the number of participating clusters and the bound on thestaleness parameter.</description><author>Anirudh Rajiv Menon, Unnikrishnan Menon, Kailash Ahirwar</author><pubDate>Wed, 03 Jan 2024 13:07:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01728v1</guid></item><item><title>Lightweight Adaptive Feature De-drifting for Compressed Image Classification</title><link>http://arxiv.org/abs/2401.01724v1</link><description>JPEG is a widely used compression scheme to efficiently reduce the volume oftransmitted images. The artifacts appear among blocks due to the informationloss, which not only affects the quality of images but also harms thesubsequent high-level tasks in terms of feature drifting. High-level visionmodels trained on high-quality images will suffer performance degradation whendealing with compressed images, especially on mobile devices. Numerouslearning-based JPEG artifact removal methods have been proposed to handlevisual artifacts. However, it is not an ideal choice to use these JPEG artifactremoval methods as a pre-processing for compressed image classification for thefollowing reasons: 1. These methods are designed for human vision rather thanhigh-level vision models; 2. These methods are not efficient enough to serve aspre-processing on resource-constrained devices. To address these issues, thispaper proposes a novel lightweight AFD module to boost the performance ofpre-trained image classification models when facing compressed images. First, aFDE-Net is devised to generate the spatial-wise FDM in the DCT domain. Next,the estimated FDM is transmitted to the FE-Net to generate the mappingrelationship between degraded features and corresponding high-quality features.A simple but effective RepConv block equipped with structuralre-parameterization is utilized in FE-Net, which enriches featurerepresentation in the training phase while maintaining efficiency in thedeployment phase. After training on limited compressed images, the AFD-Modulecan serve as a "plug-and-play" model for pre-trained classification models toimprove their performance on compressed images. Experiments demonstrate thatour proposed AFD module can comprehensively improve the accuracy of thepre-trained classification models and significantly outperform the existingmethods.</description><author>Long Peng, Yang Cao, Yuejin Sun, Yang Wang</author><pubDate>Wed, 03 Jan 2024 13:03:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01724v1</guid></item><item><title>Local Adaptive Clustering Based Image Matching for Automatic Visual Identification</title><link>http://arxiv.org/abs/2401.01720v1</link><description>Monitoring cameras are extensively utilized in industrial production tomonitor equipment running. With advancements in computer vision, devicerecognition using image features is viable. This paper presents avision-assisted identification system that implements real-time automaticequipment labeling through image matching in surveillance videos. The systemdeploys the ORB algorithm to extract image features and the GMS algorithm toremove incorrect matching points. According to the principles of clustering andtemplate locality, a method known as Local Adaptive Clustering (LAC) has beenestablished to enhance label positioning. This method segments matchingtemplates using the cluster center, which improves the efficiency and stabilityof labels. The experimental results demonstrate that LAC effectively curtailsthe label drift.</description><author>Zhizhen Wang</author><pubDate>Wed, 03 Jan 2024 12:54:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01720v1</guid></item><item><title>Diabetic Retinopathy Using Gaussian Filter</title><link>http://arxiv.org/abs/2309.15216v2</link><description>The retina is an essential component of the visual system, and maintainingeyesight depends on the timely and correct detection of disorders. Thisresearch specifically addresses the early-stage detection and severityclassification of diabetic retinopathy (DR), a serious public health hazard. Wecompare the results of different deep learning models such as InceptionV3,DenseNet121 and other CNN based models by using different image filters, suchas Gaussian, grayscale and Gabor. These models could detect subtle pathologicalalterations and use that information to estimate the risk of retinal illnesses.The objective is to improve the diagnostic processes for diabetic retinopathy,the primary cause of diabetes-related blindness, by utilizing deep learningmodels. A comparative analysis between Greyscale, Gaussian and Gabor filtershas been provided after applying these filters on the retinal images. TheGaussian filter resulted to be the most promising filter giving the bestaccuracies for all the models. The best performing model was InceptionV3 whichgave an accuracy of 96% on Gaussian images, therefore Gaussian filter emergedas our most promising filter.</description><author>Roshan Vasu Muddaluru, Sharvaani Ravikumar Thoguluva, Shruti Prabha, Tanuja Konda Reddy, Dr. Suja P</author><pubDate>Wed, 03 Jan 2024 12:52:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.15216v2</guid></item><item><title>Fact-checking based fake news detection: a review</title><link>http://arxiv.org/abs/2401.01717v1</link><description>This paper reviews and summarizes the research results on fact-based fakenews from the perspectives of tasks and problems, algorithm strategies, anddatasets. First, the paper systematically explains the task definition and coreproblems of fact-based fake news detection. Second, the paper summarizes theexisting detection methods based on the algorithm principles. Third, the paperanalyzes the classic and newly proposed datasets in the field, and summarizesthe experimental results on each dataset. Finally, the paper summarizes theadvantages and disadvantages of existing methods, proposes several challengesthat methods in this field may face, and looks forward to the next stage ofresearch. It is hoped that this paper will provide reference for subsequentwork in the field.</description><author>Yuzhou Yang, Yangming Zhou, Qichao Ying, Zhenxing Qian, Dan Zeng, Liang Liu</author><pubDate>Wed, 03 Jan 2024 12:47:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01717v1</guid></item><item><title>Parallel Algorithms Align with Neural Execution</title><link>http://arxiv.org/abs/2307.04049v2</link><description>Neural algorithmic reasoners are parallel processors. Teaching themsequential algorithms contradicts this nature, rendering a significant share oftheir computations redundant. Parallel algorithms however may exploit theirfull computational power, therefore requiring fewer layers to be executed. Thisdrastically reduces training times, as we observe when comparing parallelimplementations of searching, sorting and finding strongly connected componentsto their sequential counterparts on the CLRS framework. Additionally, parallelversions achieve (often strongly) superior predictive performance.</description><author>Valerie Engelmayer, Dobrik Georgiev, Petar Veličković</author><pubDate>Wed, 03 Jan 2024 12:34:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2307.04049v2</guid></item><item><title>Evaluating Large Language Models in Semantic Parsing for Conversational Question Answering over Knowledge Graphs</title><link>http://arxiv.org/abs/2401.01711v1</link><description>Conversational question answering systems often rely on semantic parsing toenable interactive information retrieval, which involves the generation ofstructured database queries from a natural language input. Forinformation-seeking conversations about facts stored within a knowledge graph,dialogue utterances are transformed into graph queries in a process that iscalled knowledge-based conversational question answering. This paper evaluatesthe performance of large language models that have not been explicitlypre-trained on this task. Through a series of experiments on an extensivebenchmark dataset, we compare models of varying sizes with different promptingtechniques and identify common issue types in the generated output. Our resultsdemonstrate that large language models are capable of generating graph queriesfrom dialogues, with significant improvements achievable through few-shotprompting and fine-tuning techniques, especially for smaller models thatexhibit lower zero-shot performance.</description><author>Phillip Schneider, Manuel Klettner, Kristiina Jokinen, Elena Simperl, Florian Matthes</author><pubDate>Wed, 03 Jan 2024 12:28:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01711v1</guid></item><item><title>EPA: Neural Collapse Inspired Robust Out-of-Distribution Detector</title><link>http://arxiv.org/abs/2401.01710v1</link><description>Out-of-distribution (OOD) detection plays a crucial role in ensuring thesecurity of neural networks. Existing works have leveraged the fact thatIn-distribution (ID) samples form a subspace in the feature space, achievingstate-of-the-art (SOTA) performance. However, the comprehensive characteristicsof the ID subspace still leave under-explored. Recently, the discovery ofNeural Collapse ($\mathcal{NC}$) sheds light on novel properties of the IDsubspace. Leveraging insight from $\mathcal{NC}$, we observe that the PrincipalAngle between the features and the ID feature subspace forms a superiorrepresentation for measuring the likelihood of OOD. Building upon thisobservation, we propose a novel $\mathcal{NC}$-inspired OOD scoring function,named Entropy-enhanced Principal Angle (EPA), which integrates both the globalcharacteristic of the ID subspace and its inner property. We experimentallycompare EPA with various SOTA approaches, validating its superior performanceand robustness across different network architectures and OOD datasets.</description><author>Jiawei Zhang, Yufan Chen, Cheng Jin, Lei Zhu, Yuantao Gu</author><pubDate>Wed, 03 Jan 2024 12:25:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01710v1</guid></item><item><title>LLM4TS: Aligning Pre-Trained LLMs as Data-Efficient Time-Series Forecasters</title><link>http://arxiv.org/abs/2308.08469v4</link><description>Multivariate time-series forecasting is vital in various domains, e.g.,economic planning and weather prediction. Deep train-from-scratch models haveexhibited effective performance yet require large amounts of data, which limitsreal-world applicability. Recently, researchers have explored pre-trained LargeLanguage Models (LLMs) for limited non-linguistic datasets. However,incorporating LLMs with time-series data presents challenges of limitedadaptation due to different compositions between time-series and linguisticdata, and the inability to process multi-scale temporal information. To tacklethese challenges, we propose LLM4TS, a framework for time-series forecastingwith pre-trained LLMs. LLM4TS consists of a two-stage fine-tuning strategy: thetime-series alignment stage to align LLMs with the nuances of time-series data,and the forecasting fine-tuning stage, which is specifically designed fortime-series forecasting tasks. Furthermore, our framework features a noveltwo-level aggregation method that integrates multi-scale temporal data withinpre-trained LLMs, enhancing their ability to interpret time-specificinformation. In experiments across 7 time-series forecasting datasets, LLM4TSis superior to existing state-of-the-art methods, including those trained fromscratch, in full-shot scenarios, and also achieves an average improvement of6.84% in MSE in few-shot scenarios. In addition, evaluations compared withdifferent self-supervised learning approaches highlight LLM4TS's effectivenesswith representation learning in forecasting scenarios.</description><author>Ching Chang, Wei-Yao Wang, Wen-Chih Peng, Tien-Fu Chen</author><pubDate>Wed, 03 Jan 2024 12:24:57 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.08469v4</guid></item><item><title>Bayesian posterior approximation with stochastic ensembles</title><link>http://arxiv.org/abs/2212.08123v3</link><description>We introduce ensembles of stochastic neural networks to approximate theBayesian posterior, combining stochastic methods such as dropout with deepensembles. The stochastic ensembles are formulated as families of distributionsand trained to approximate the Bayesian posterior with variational inference.We implement stochastic ensembles based on Monte Carlo dropout, DropConnect anda novel non-parametric version of dropout and evaluate them on a toy problemand CIFAR image classification. For both tasks, we test the quality of theposteriors directly against Hamiltonian Monte Carlo simulations. Our resultsshow that stochastic ensembles provide more accurate posterior estimates thanother popular baselines for Bayesian inference.</description><author>Oleksandr Balabanov, Bernhard Mehlig, Hampus Linander</author><pubDate>Wed, 03 Jan 2024 12:22:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.08123v3</guid></item><item><title>EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models</title><link>http://arxiv.org/abs/2312.06281v2</link><description>We introduce EQ-Bench, a novel benchmark designed to evaluate aspects ofemotional intelligence in Large Language Models (LLMs). We assess the abilityof LLMs to understand complex emotions and social interactions by asking themto predict the intensity of emotional states of characters in a dialogue. Thebenchmark is able to discriminate effectively between a wide range of models.We find that EQ-Bench correlates strongly with comprehensive multi-domainbenchmarks like MMLU (Hendrycks et al., 2020) (r=0.97), indicating that we maybe capturing similar aspects of broad intelligence. Our benchmark produceshighly repeatable results using a set of 60 English-language questions. We alsoprovide open-source code for an automated benchmarking pipeline athttps://github.com/EQ-bench/EQ-Bench and a leaderboard at https://eqbench.com</description><author>Samuel J. Paech</author><pubDate>Wed, 03 Jan 2024 12:20:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06281v2</guid></item><item><title>SkateboardAI: The Coolest Video Action Recognition for Skateboarding</title><link>http://arxiv.org/abs/2311.11467v2</link><description>Impressed by the coolest skateboarding sports program from 2021 Tokyo OlympicGames, we are the first to curate the original real-world video datasets"SkateboardAI" in the wild, even self-design and implement diverse uni-modaland multi-modal video action recognition approaches to recognize differenttricks accurately. For uni-modal methods, we separately apply (1) CNN and LSTM;(2) CNN and BiLSTM; (3) CNN and BiLSTM with effective attention mechanisms; (4)Transformer-based action recognition pipeline. Transferred to the multi-modalconditions, we investigated the two-stream Inflated-3D architecture on"SkateboardAI" datasets to compare its performance with uni-modal cases. Insum, our objective is developing an excellent AI sport referee for the coolestskateboarding competitions.</description><author>Hanxiao Chen</author><pubDate>Wed, 03 Jan 2024 12:09:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.11467v2</guid></item><item><title>WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope</title><link>http://arxiv.org/abs/2401.01699v1</link><description>This paper introduces the WordArt Designer API, a novel framework foruser-driven artistic typography synthesis utilizing Large Language Models(LLMs) on ModelScope. We address the challenge of simplifying artistictypography for non-professionals by offering a dynamic, adaptive, andcomputationally efficient alternative to traditional rigid templates. Ourapproach leverages the power of LLMs to understand and interpret user input,facilitating a more intuitive design process. We demonstrate through variouscase studies how users can articulate their aesthetic preferences andfunctional requirements, which the system then translates into unique andcreative typographic designs. Our evaluations indicate significant improvementsin user satisfaction, design flexibility, and creative expression over existingsystems. The WordArt Designer API not only democratizes the art of typographybut also opens up new possibilities for personalized digital communication anddesign.</description><author>Jun-Yan He, Zhi-Qi Cheng, Chenyang Li, Jingdong Sun, Wangmeng Xiang, Yusen Hu, Xianhui Lin, Xiaoyang Kang, Zengke Jin, Bin Luo, Yifeng Geng, Xuansong Xie, Jingren Zhou</author><pubDate>Wed, 03 Jan 2024 12:06:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01699v1</guid></item><item><title>Patterns of Persistence and Diffusibility across World's Languages</title><link>http://arxiv.org/abs/2401.01698v1</link><description>Language similarities can be caused by genetic relatedness, areal contact,universality, or chance. Colexification, i.e.~a type of similarity where asingle lexical form is used to convey multiple meanings, is underexplored. Inour work, we shed light on the linguistic causes of cross-lingual similarity incolexification and phonology, by exploring genealogical stability (persistence)and contact-induced change (diffusibility). We construct large-scale graphsincorporating semantic, genealogical, phonological and geographical data for1,966 languages. We then show the potential of this resource, by investigatingseveral established hypotheses from previous work in linguistics, whileproposing new ones. Our results strongly support a previously establishedhypothesis in the linguistic literature, while offering contradicting evidenceto another. Our large scale resource opens for further research acrossdisciplines, e.g.~in multilingual NLP and comparative linguistics.</description><author>Yiyi Chen, Johannes Bjerva</author><pubDate>Wed, 03 Jan 2024 12:05:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01698v1</guid></item><item><title>Understanding the Effects of RLHF on LLM Generalisation and Diversity</title><link>http://arxiv.org/abs/2310.06452v2</link><description>Large language models (LLMs) fine-tuned with reinforcement learning fromhuman feedback (RLHF) have been used in some of the most widely deployed AImodels to date, such as OpenAI's ChatGPT or Anthropic's Claude. % , or Meta'sLLaMA-2. While there has been significant work developing these methods, ourunderstanding of the benefits and downsides of each stage in RLHF is stilllimited. To fill this gap, we present an extensive analysis of how each stageof the process (i.e.~supervised fine-tuning (SFT), reward modelling, and RLHF)affects two key properties: out-of-distribution (OOD) generalisation and outputdiversity. OOD generalisation is crucial given the wide range of real-worldscenarios in which these models are being used, while output diversity refersto the model's ability to generate varied outputs and is important for avariety of use cases. We perform our analysis across two base models on bothsummarisation and instruction following tasks, the latter being highly relevantfor current LLM use cases. We find that RLHF generalises better than SFT to newinputs, particularly as the distribution shift between train and test becomeslarger. However, RLHF significantly reduces output diversity compared to SFTacross a variety of measures, implying a tradeoff in current LLM fine-tuningmethods between generalisation and diversity. Our results provide guidance onwhich fine-tuning method should be used depending on the application, and showthat more research is needed to improve the tradeoff between generalisation anddiversity.</description><author>Robert Kirk, Ishita Mediratta, Christoforos Nalmpantis, Jelena Luketina, Eric Hambro, Edward Grefenstette, Roberta Raileanu</author><pubDate>Wed, 03 Jan 2024 11:58:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.06452v2</guid></item></channel></rss>