<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Fri, 10 Jan 2025 01:00:05 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>Click2Mask: Local Editing with Dynamic Mask Generation</title><link>http://arxiv.org/abs/2409.08272v2</link><description>Recent advancements in generative models have revolutionized image generationand editing, making these tasks accessible to non-experts. This paper focuseson local image editing, particularly the task of adding new content to aloosely specified area. Existing methods often require a precise mask or adetailed description of the location, which can be cumbersome and prone toerrors. We propose Click2Mask, a novel approach that simplifies the localediting process by requiring only a single point of reference (in addition tothe content description). A mask is dynamically grown around this point duringa Blended Latent Diffusion (BLD) process, guided by a masked CLIP-basedsemantic loss. Click2Mask surpasses the limitations of segmentation-based andfine-tuning dependent methods, offering a more user-friendly and contextuallyaccurate solution. Our experiments demonstrate that Click2Mask not onlyminimizes user effort but also enables competitive or superior local imagemanipulations compared to SoTA methods, according to both human judgement andautomatic metrics. Key contributions include the simplification of user input,the ability to freely add objects unconstrained by existing segments, and theintegration potential of our dynamic mask approach within other editingmethods.</description><author>Omer Regev, Omri Avrahami, Dani Lischinski</author><pubDate>Wed, 08 Jan 2025 18:59:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.08272v2</guid></item><item><title>$O(k)$-Equivariant Dimensionality Reduction on Stiefel Manifolds</title><link>http://arxiv.org/abs/2309.10775v2</link><description>Many real-world datasets live on high-dimensional Stiefel and Grassmannianmanifolds, $V_k(\mathbb{R}^N)$ and $Gr(k, \mathbb{R}^N)$ respectively, andbenefit from projection onto lower-dimensional Stiefel and Grassmannianmanifolds. In this work, we propose an algorithm called \textit{PrincipalStiefel Coordinates (PSC)} to reduce data dimensionality from $V_k(\mathbb{R}^N)$ to $V_k(\mathbb{R}^n)$ in an \textit{$O(k)$-equivariant}manner ($k \leq n \ll N$). We begin by observing that each element $\alpha \inV_n(\mathbb{R}^N)$ defines an isometric embedding of $V_k(\mathbb{R}^n)$ into$V_k(\mathbb{R}^N)$. Next, we describe two ways of finding a suitable embeddingmap $\alpha$: one via an extension of principal component analysis($\alpha_{PCA}$), and one that further minimizes data fit error using gradientdescent ($\alpha_{GD}$). Then, we define a continuous and $O(k)$-equivariantmap $\pi_\alpha$ that acts as a "closest point operator" to project the dataonto the image of $V_k(\mathbb{R}^n)$ in $V_k(\mathbb{R}^N)$ under theembedding determined by $\alpha$, while minimizing distortion. Because thisdimensionality reduction is $O(k)$-equivariant, these results extend toGrassmannian manifolds as well. Lastly, we show that $\pi_{\alpha_{PCA}}$globally minimizes projection error in a noiseless setting, while$\pi_{\alpha_{GD}}$ achieves a meaningfully different and improved outcome whenthe data does not lie exactly on the image of a linearly embeddedlower-dimensional Stiefel manifold as above. Multiple numerical experimentsusing synthetic and real-world data are performed.</description><author>Andrew Lee, Harlin Lee, Jose A. Perea, Nikolas Schonsheck, Madeleine Weinstein</author><pubDate>Wed, 08 Jan 2025 18:59:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10775v2</guid></item><item><title>Planarian Neural Networks: Evolutionary Patterns from Basic Bilateria Shaping Modern Artificial Neural Network Architectures</title><link>http://arxiv.org/abs/2501.04700v1</link><description>This study examined the viability of enhancing the prediction accuracy ofartificial neural networks (ANNs) in image classification tasks by developingANNs with evolution patterns similar to those of biological neural networks.ResNet is a widely used family of neural networks with both deep and widevariants; therefore, it was selected as the base model for our investigation.The aim of this study is to improve the image classification performance ofANNs via a novel approach inspired by the biological nervous systemarchitecture of planarians, which comprises a brain and two nerve cords. Webelieve that the unique neural architecture of planarians offers valuableinsights into the performance enhancement of ANNs. The proposed planarianneural architecture-based neural network was evaluated on the CIFAR-10 andCIFAR-100 datasets. Our results indicate that the proposed method exhibitshigher prediction accuracy than the baseline neural network models in imageclassification tasks. These findings demonstrate the significant potential ofbiologically inspired neural network architectures in improving the performanceof ANNs in a wide range of applications.</description><author>Ziyuan Huang, Mark Newman, Maria Vaida, Srikar Bellur, Roozbeh Sadeghian, Andrew Siu, Hui Wang, Kevin Huggins</author><pubDate>Wed, 08 Jan 2025 18:59:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04700v1</guid></item><item><title>EditAR: Unified Conditional Generation with Autoregressive Models</title><link>http://arxiv.org/abs/2501.04699v1</link><description>Recent progress in controllable image generation and editing is largelydriven by diffusion-based methods. Although diffusion models performexceptionally well in specific tasks with tailored designs, establishing aunified model is still challenging. In contrast, autoregressive modelsinherently feature a unified tokenized representation, which simplifies thecreation of a single foundational model for various tasks. In this work, wepropose EditAR, a single unified autoregressive framework for a variety ofconditional image generation tasks, e.g., image editing, depth-to-image,edge-to-image, segmentation-to-image. The model takes both images andinstructions as inputs, and predicts the edited images tokens in a vanillanext-token paradigm. To enhance the text-to-image alignment, we further proposeto distill the knowledge from foundation models into the autoregressivemodeling process. We evaluate its effectiveness across diverse tasks onestablished benchmarks, showing competitive performance to variousstate-of-the-art task-specific methods. Project page:https://jitengmu.github.io/EditAR/</description><author>Jiteng Mu, Nuno Vasconcelos, Xiaolong Wang</author><pubDate>Wed, 08 Jan 2025 18:59:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04699v1</guid></item><item><title>ConceptMaster: Multi-Concept Video Customization on Diffusion Transformer Models Without Test-Time Tuning</title><link>http://arxiv.org/abs/2501.04698v1</link><description>Text-to-video generation has made remarkable advancements through diffusionmodels. However, Multi-Concept Video Customization (MCVC) remains a significantchallenge. We identify two key challenges in this task: 1) the identitydecoupling problem, where directly adopting existing customization methodsinevitably mix attributes when handling multiple concepts simultaneously, and2) the scarcity of high-quality video-entity pairs, which is crucial fortraining such a model that represents and decouples various concepts well. Toaddress these challenges, we introduce ConceptMaster, an innovative frameworkthat effectively tackles the critical issues of identity decoupling whilemaintaining concept fidelity in customized videos. Specifically, we introduce anovel strategy of learning decoupled multi-concept embeddings that are injectedinto the diffusion models in a standalone manner, which effectively guaranteesthe quality of customized videos with multiple identities, even for highlysimilar visual concepts. To further overcome the scarcity of high-quality MCVCdata, we carefully establish a data construction pipeline, which enablessystematic collection of precise multi-concept video-entity data across diverseconcepts. A comprehensive benchmark is designed to validate the effectivenessof our model from three critical dimensions: concept fidelity, identitydecoupling ability, and video generation quality across six different conceptcomposition scenarios. Extensive experiments demonstrate that our ConceptMastersignificantly outperforms previous approaches for this task, paving the way forgenerating personalized and semantically accurate videos across multipleconcepts.</description><author>Yuzhou Huang, Ziyang Yuan, Quande Liu, Qiulin Wang, Xintao Wang, Ruimao Zhang, Pengfei Wan, Di Zhang, Kun Gai</author><pubDate>Wed, 08 Jan 2025 18:59:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04698v1</guid></item><item><title>Grokking at the Edge of Numerical Stability</title><link>http://arxiv.org/abs/2501.04697v1</link><description>Grokking, the sudden generalization that occurs after prolonged overfitting,is a surprising phenomenon challenging our understanding of deep learning.Although significant progress has been made in understanding grokking, thereasons behind the delayed generalization and its dependence on regularizationremain unclear. In this work, we argue that without regularization, grokkingtasks push models to the edge of numerical stability, introducing floatingpoint errors in the Softmax function, which we refer to as Softmax Collapse(SC). We demonstrate that SC prevents grokking and that mitigating SC enablesgrokking without regularization. Investigating the root cause of SC, we findthat beyond the point of overfitting, the gradients strongly align with what wecall the na\"ive loss minimization (NLM) direction. This component of thegradient does not alter the model's predictions but decreases the loss byscaling the logits, typically by scaling the weights along their currentdirection. We show that this scaling of the logits explains the delay ingeneralization characteristic of grokking and eventually leads to SC, haltingfurther learning. To validate our hypotheses, we introduce two keycontributions that address the challenges in grokking tasks: StableMax, a newactivation function that prevents SC and enables grokking withoutregularization, and $\perp$Grad, a training algorithm that promotes quickgeneralization in grokking tasks by preventing NLM altogether. Thesecontributions provide new insights into grokking, elucidating its delayedgeneralization, reliance on regularization, and the effectiveness of existinggrokking-inducing methods. Code for this paper is available athttps://github.com/LucasPrietoAl/grokking-at-the-edge-of-numerical-stability.</description><author>Lucas Prieto, Melih Barsbey, Pedro A. M. Mediano, Tolga Birdal</author><pubDate>Wed, 08 Jan 2025 18:58:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04697v1</guid></item><item><title>Test-Time Optimization for Domain Adaptive Open Vocabulary Segmentation</title><link>http://arxiv.org/abs/2501.04696v1</link><description>We present Seg-TTO, a novel framework for zero-shot, open-vocabulary semanticsegmentation (OVSS), designed to excel in specialized domain tasks. Whilecurrent open vocabulary approaches show impressive performance on standardsegmentation benchmarks under zero-shot settings, they fall short of supervisedcounterparts on highly domain-specific datasets. We focus onsegmentation-specific test-time optimization to address this gap. Segmentationrequires an understanding of multiple concepts within a single image whileretaining the locality and spatial structure of representations. We propose anovel self-supervised objective adhering to these requirements and use it toalign the model parameters with input images at test time. In the textualmodality, we learn multiple embeddings for each category to capture diverseconcepts within an image, while in the visual modality, we calculatepixel-level losses followed by embedding aggregation operations specific topreserving spatial structure. Our resulting framework termed Seg-TTO is aplug-in-play module. We integrate Seg-TTO with three state-of-the-art OVSSapproaches and evaluate across 22 challenging OVSS tasks covering a range ofspecialized domains. Our Seg-TTO demonstrates clear performance improvementsacross these establishing new state-of-the-art. Code:https://github.com/UlinduP/SegTTO.</description><author>Ulindu De Silva, Didula Samaraweera, Sasini Wanigathunga, Kavindu Kariyawasam, Kanchana Ranasinghe, Muzammal Naseer, Ranga Rodrigo</author><pubDate>Wed, 08 Jan 2025 18:58:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04696v1</guid></item><item><title>Re-ranking the Context for Multimodal Retrieval Augmented Generation</title><link>http://arxiv.org/abs/2501.04695v1</link><description>Retrieval-augmented generation (RAG) enhances large language models (LLMs) byincorporating external knowledge to generate a response within a context withimproved accuracy and reduced hallucinations. However, multi-modal RAG systemsface unique challenges: (i) the retrieval process may select irrelevant entriesto user query (e.g., images, documents), and (ii) vision-language models ormulti-modal language models like GPT-4o may hallucinate when processing theseentries to generate RAG output. In this paper, we aim to address the firstchallenge, i.e, improving the selection of relevant context from theknowledge-base in retrieval phase of the multi-modal RAG. Specifically, weleverage the relevancy score (RS) measure designed in our previous work forevaluating the RAG performance to select more relevant entries in retrievalprocess. The retrieval based on embeddings, say CLIP-based embedding, andcosine similarity usually perform poorly particularly for multi-modal data. Weshow that by using a more advanced relevancy measure, one can enhance theretrieval process by selecting more relevant pieces from the knowledge-base andeliminate the irrelevant pieces from the context by adaptively selectingup-to-$k$ entries instead of fixed number of entries. Our evaluation using COCOdataset demonstrates significant enhancement in selecting relevant context andaccuracy of the generated response.</description><author>Matin Mortaheb, Mohammad A. Amir Khojastepour, Srimat T. Chakradhar, Sennur Ulukus</author><pubDate>Wed, 08 Jan 2025 18:58:22 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04695v1</guid></item><item><title>EpiCoder: Encompassing Diversity and Complexity in Code Generation</title><link>http://arxiv.org/abs/2501.04694v1</link><description>Effective instruction tuning is indispensable for optimizing code LLMs,aligning model behavior with user expectations and enhancing model performancein real-world applications. However, most existing methods focus on codesnippets, which are limited to specific functionalities and rigid structures,restricting the complexity and diversity of the synthesized data. To addressthese limitations, we introduce a novel feature tree-based synthesis frameworkinspired by Abstract Syntax Trees (AST). Unlike AST, which captures syntacticstructure of code, our framework models semantic relationships between codeelements, enabling the generation of more nuanced and diverse data. The featuretree is constructed from raw data and refined iteratively to increase thequantity and diversity of the extracted features. This process enables theidentification of more complex patterns and relationships within the code. Bysampling subtrees with controlled depth and breadth, our framework allowsprecise adjustments to the complexity of the generated code, supporting a widerange of tasks from simple function-level operations to intricate multi-filescenarios. We fine-tuned widely-used base models to create the EpiCoder series,achieving state-of-the-art performance at both the function and file levelsacross multiple benchmarks. Notably, empirical evidence indicates that ourapproach shows significant potential in synthesizing highly complexrepository-level code data. Further analysis elucidates the merits of thisapproach by rigorously assessing data complexity and diversity through softwareengineering principles and LLM-as-a-judge method.</description><author>Yaoxiang Wang, Haoling Li, Xin Zhang, Jie Wu, Xiao Liu, Wenxiang Hu, Zhongxin Guo, Yangyu Huang, Ying Xin, Yujiu Yang, Jinsong Su, Qi Chen, Scarlett Li</author><pubDate>Wed, 08 Jan 2025 18:58:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04694v1</guid></item><item><title>Beyond Sight: Finetuning Generalist Robot Policies with Heterogeneous Sensors via Language Grounding</title><link>http://arxiv.org/abs/2501.04693v1</link><description>Interacting with the world is a multi-sensory experience: achieving effectivegeneral-purpose interaction requires making use of all available modalities --including vision, touch, and audio -- to fill in gaps from partial observation.For example, when vision is occluded reaching into a bag, a robot should relyon its senses of touch and sound. However, state-of-the-art generalist robotpolicies are typically trained on large datasets to predict robot actionssolely from visual and proprioceptive observations. In this work, we proposeFuSe, a novel approach that enables finetuning visuomotor generalist policieson heterogeneous sensor modalities for which large datasets are not readilyavailable by leveraging natural language as a common cross-modal grounding. Wecombine a multimodal contrastive loss with a sensory-grounded languagegeneration loss to encode high-level semantics. In the context of robotmanipulation, we show that FuSe enables performing challenging tasks thatrequire reasoning jointly over modalities such as vision, touch, and sound in azero-shot setting, such as multimodal prompting, compositional cross-modalprompting, and descriptions of objects it interacts with. We show that the samerecipe is applicable to widely different generalist policies, including bothdiffusion-based generalist policies and large vision-language-action (VLA)models. Extensive experiments in the real world show that FuSeis able toincrease success rates by over 20% compared to all considered baselines.</description><author>Joshua Jones, Oier Mees, Carmelo Sferrazza, Kyle Stachowicz, Pieter Abbeel, Sergey Levine</author><pubDate>Wed, 08 Jan 2025 18:57:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04693v1</guid></item><item><title>Comparative Analysis of Quantum and Classical Support Vector Classifiers for Software Bug Prediction: An Exploratory Study</title><link>http://arxiv.org/abs/2501.04690v1</link><description>Purpose: Quantum computing promises to transform problem-solving acrossvarious domains with rapid and practical solutions. Within Software Evolutionand Maintenance, Quantum Machine Learning (QML) remains mostly an underexploreddomain, particularly in addressing challenges such as detecting buggy softwarecommits from code repositories. Methods: In this study, we investigate thepractical application of Quantum Support Vector Classifiers (QSVC) fordetecting buggy software commits across 14 open-source software projects withdiverse dataset sizes encompassing 30,924 data instances. We compare the QMLalgorithm PQSVC (Pegasos QSVC) and QSVC against the classical Support VectorClassifier (SVC). Our technique addresses large datasets in QSVC algorithms bydividing them into smaller subsets. We propose and evaluate an aggregationmethod to combine predictions from these models to detect the entire testdataset. We also introduce an incremental testing methodology to overcome thedifficulties of quantum feature mapping during the testing approach. Results:The study shows the effectiveness of QSVC and PQSVC in detecting buggy softwarecommits. The aggregation technique successfully combines predictions fromsmaller data subsets, enhancing the overall detection accuracy for the entiretest dataset. The incremental testing methodology effectively manages thechallenges associated with quantum feature mapping during the testing process.Conclusion: We contribute to the advancement of QML algorithms in defectprediction, unveiling the potential for further research in this domain. Thespecific scenario of the Short-Term Activity Frame (STAF) highlights the earlydetection of buggy software commits during the initial developmental phases ofsoftware systems, particularly when dataset sizes remain insufficient to trainmachine learning models.</description><author>Md Nadim, Mohammad Hassan, Ashis Kumar Mandal, Chanchal K. Roy, Banani Roy, Kevin A. Schneider</author><pubDate>Wed, 08 Jan 2025 18:53:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04690v1</guid></item><item><title>SPAR3D: Stable Point-Aware Reconstruction of 3D Objects from Single Images</title><link>http://arxiv.org/abs/2501.04689v1</link><description>We study the problem of single-image 3D object reconstruction. Recent workshave diverged into two directions: regression-based modeling and generativemodeling. Regression methods efficiently infer visible surfaces, but strugglewith occluded regions. Generative methods handle uncertain regions better bymodeling distributions, but are computationally expensive and the generation isoften misaligned with visible surfaces. In this paper, we present SPAR3D, anovel two-stage approach aiming to take the best of both directions. The firststage of SPAR3D generates sparse 3D point clouds using a lightweight pointdiffusion model, which has a fast sampling speed. The second stage uses boththe sampled point cloud and the input image to create highly detailed meshes.Our two-stage design enables probabilistic modeling of the ill-posedsingle-image 3D task while maintaining high computational efficiency and greatoutput fidelity. Using point clouds as an intermediate representation furtherallows for interactive user edits. Evaluated on diverse datasets, SPAR3Ddemonstrates superior performance over previous state-of-the-art methods, at aninference speed of 0.7 seconds. Project page with code and model:https://spar3d.github.io</description><author>Zixuan Huang, Mark Boss, Aaryaman Vasishta, James M. Rehg, Varun Jampani</author><pubDate>Wed, 08 Jan 2025 18:52:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04689v1</guid></item><item><title>URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics</title><link>http://arxiv.org/abs/2501.04686v1</link><description>Chain-of-thought (CoT) reasoning has been widely applied in the mathematicalreasoning of Large Language Models (LLMs). Recently, the introduction ofderivative process supervision on CoT trajectories has sparked discussions onenhancing scaling capabilities during test time, thereby boosting the potentialof these models. However, in multimodal mathematical reasoning, the scarcity ofhigh-quality CoT training data has hindered existing models from achievinghigh-precision CoT reasoning and has limited the realization of reasoningpotential during test time. In this work, we propose a three-module synthesisstrategy that integrates CoT distillation, trajectory-format rewriting, andformat unification. It results in a high-quality CoT reasoning instructionfine-tuning dataset in multimodal mathematics, MMathCoT-1M. We comprehensivelyvalidate the state-of-the-art (SOTA) performance of the trained URSA-7B modelon multiple multimodal mathematical benchmarks. For test-time scaling, weintroduce a data synthesis strategy that automatically generates processannotation datasets, known as DualMath-1.1M, focusing on both interpretationand logic. By further training URSA-7B on DualMath-1.1M, we transition from CoTreasoning capabilities to robust supervision abilities. The trained URSA-RM-7Bacts as a verifier, effectively enhancing the performance of URSA-7B at testtime. URSA-RM-7B also demonstrates excellent out-of-distribution (OOD)verifying capabilities, showcasing its generalization. Model weights, trainingdata and code will be open-sourced.</description><author>Ruilin Luo, Zhuofan Zheng, Yifan Wang, Yiyao Yu, Xinzhe Ni, Zicheng Lin, Jin Zeng, Yujiu Yang</author><pubDate>Wed, 08 Jan 2025 18:49:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04686v1</guid></item><item><title>Toward Sufficient Statistical Power in Algorithmic Bias Assessment: A Test for ABROCA</title><link>http://arxiv.org/abs/2501.04683v1</link><description>Algorithmic bias is a pressing concern in educational data mining (EDM), asit risks amplifying inequities in learning outcomes. The Area Between ROCCurves (ABROCA) metric is frequently used to measure discrepancies in modelperformance across demographic groups to quantify overall model fairness.However, its skewed distribution--especially when class or group imbalancesexist--makes significance testing challenging. This study investigates ABROCA'sdistributional properties and contributes robust methods for its significancetesting. Specifically, we address (1) whether ABROCA follows any knowndistribution, (2) how to reliably test for algorithmic bias using ABROCA, and(3) the statistical power achievable with ABROCA-based bias assessments undertypical EDM sample specifications. Simulation results confirm that ABROCA doesnot match standard distributions, including those suited to accommodateskewness. We propose nonparametric randomization tests for ABROCA anddemonstrate that reliably detecting bias with ABROCA requires large samplesizes or substantial effect sizes, particularly in imbalanced settings.Findings suggest that ABROCA-based bias evaluation based on sample sizes commonin EDM tends to be underpowered, undermining the reliability of conclusionsabout model fairness. By offering open-source code to simulate power andstatistically test ABROCA, this paper aims to foster more reliable statisticaltesting in EDM research. It supports broader efforts toward replicability andequity in educational modeling.</description><author>Conrad Borchers</author><pubDate>Wed, 08 Jan 2025 18:43:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04683v1</guid></item><item><title>Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though</title><link>http://arxiv.org/abs/2501.04682v1</link><description>We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extendstraditional Chain-of-Thought (CoT) by explicitly modeling the underlyingreasoning required to arrive at a particular CoT. We present empirical evidencefrom state-of-the-art models exhibiting behaviors consistent with in-contextsearch, and explore methods for producing Meta-CoT via process supervision,synthetic data generation, and search algorithms. Finally, we outline aconcrete pipeline for training a model to produce Meta-CoTs, incorporatinginstruction tuning with linearized search traces and reinforcement learningpost-training. Finally, we discuss open research questions, including scalinglaws, verifier roles, and the potential for discovering novel reasoningalgorithms. This work provides a theoretical and practical roadmap to enableMeta-CoT in LLMs, paving the way for more powerful and human-like reasoning inartificial intelligence.</description><author>Violet Xiang, Charlie Snell, Kanishk Gandhi, Alon Albalak, Anikait Singh, Chase Blagden, Duy Phung, Rafael Rafailov, Nathan Lile, Dakota Mahan, Louis Castricato, Jan-Philipp Franken, Nick Haber, Chelsea Finn</author><pubDate>Wed, 08 Jan 2025 18:42:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04682v1</guid></item><item><title>RadGPT: Constructing 3D Image-Text Tumor Datasets</title><link>http://arxiv.org/abs/2501.04678v1</link><description>With over 85 million CT scans performed annually in the United States,creating tumor-related reports is a challenging and time-consuming task forradiologists. To address this need, we present RadGPT, an Anatomy-AwareVision-Language AI Agent for generating detailed reports from CT scans. RadGPTfirst segments tumors, including benign cysts and malignant tumors, and theirsurrounding anatomical structures, then transforms this information into bothstructured reports and narrative reports. These reports provide tumor size,shape, location, attenuation, volume, and interactions with surrounding bloodvessels and organs. Extensive evaluation on unseen hospitals shows that RadGPTcan produce accurate reports, with high sensitivity/specificity for small tumor(&lt;2 cm) detection: 80/73% for liver tumors, 92/78% for kidney tumors, and77/77% for pancreatic tumors. For large tumors, sensitivity ranges from 89% to97%. The results significantly surpass the state-of-the-art in abdominal CTreport generation. RadGPT generated reports for 17 public datasets. Through radiologist reviewand refinement, we have ensured the reports' accuracy, and created the firstpublicly available image-text 3D medical dataset, comprising over 1.8 milliontext tokens and 2.7 million images from 9,262 CT scans, including 2,947 tumorscans/reports of 8,562 tumor instances. Our reports can: (1) localize tumors ineight liver sub-segments and three pancreatic sub-segments annotated per-voxel;(2) determine pancreatic tumor stage (T1-T4) in 260 reports; and (3) presentindividual analyses of multiple tumors--rare in human-made reports.Importantly, 948 of the reports are for early-stage tumors.</description><author>Pedro R. A. S. Bassi, Mehmet Can Yavuz, Kang Wang, Xiaoxi Chen, Wenxuan Li, Sergio Decherchi, Andrea Cavalli, Yang Yang, Alan Yuille, Zongwei Zhou</author><pubDate>Wed, 08 Jan 2025 18:39:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04678v1</guid></item><item><title>Enhancing Financial VQA in Vision Language Models using Intermediate Structured Representations</title><link>http://arxiv.org/abs/2501.04675v1</link><description>Chart interpretation is crucial for visual data analysis, but accuratelyextracting information from charts poses significant challenges for automatedmodels. This study investigates the fine-tuning of DEPLOT, a modalityconversion module that translates the image of a plot or chart to a linearizedtable, on a custom dataset of 50,000 bar charts. The dataset comprises simple,stacked, and grouped bar charts, targeting the unique structural features ofthese visualizations. The finetuned DEPLOT model is evaluated against its baseversion using a test set of 1,000 images and two metrics: Relative MappingSimilarity (RMS), which measures categorical mapping accuracy, and RelativeNumber Set Similarity (RNSS), which evaluates numerical interpretationaccuracy. To further explore the reasoning capabilities of large languagemodels (LLMs), we curate an additional set of 100 bar chart images paired withquestion answer sets. Our findings demonstrate that providing a structuredintermediate table alongside the image significantly enhances LLM reasoningperformance compared to direct image queries.</description><author>Archita Srivastava, Abhas Kumar, Rajesh Kumar, Prabhakar Srinivasan</author><pubDate>Wed, 08 Jan 2025 18:33:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04675v1</guid></item><item><title>GLoG-CSUnet: Enhancing Vision Transformers with Adaptable Radiomic Features for Medical Image Segmentation</title><link>http://arxiv.org/abs/2501.02788v2</link><description>Vision Transformers (ViTs) have shown promise in medical image semanticsegmentation (MISS) by capturing long-range correlations. However, ViTs oftenstruggle to model local spatial information effectively, which is essential foraccurately segmenting fine anatomical details, particularly when applied tosmall datasets without extensive pre-training. We introduce Gabor and Laplacianof Gaussian Convolutional Swin Network (GLoG-CSUnet), a novel architectureenhancing Transformer-based models by incorporating learnable radiomicfeatures. This approach integrates dynamically adaptive Gabor and Laplacian ofGaussian (LoG) filters to capture texture, edge, and boundary information,enhancing the feature representation processed by the Transformer model. Ourmethod uniquely combines the long-range dependency modeling of Transformerswith the texture analysis capabilities of Gabor and LoG features. Evaluated onthe Synapse multi-organ and ACDC cardiac segmentation datasets, GLoG-CSUnetdemonstrates significant improvements over state-of-the-art models, achieving a1.14% increase in Dice score for Synapse and 0.99% for ACDC, with minimalcomputational overhead (only 15 and 30 additional parameters, respectively).GLoG-CSUnet's flexible design allows integration with various base models,offering a promising approach for incorporating radiomics-inspired featureextraction in Transformer architectures for medical image analysis. The codeimplementation is available on GitHub at: https://github.com/HAAIL/GLoG-CSUnet.</description><author>Niloufar Eghbali, Hassan Bagher-Ebadian, Tuka Alhanai, Mohammad M. Ghassemi</author><pubDate>Wed, 08 Jan 2025 18:33:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.02788v2</guid></item><item><title>DRIVINGVQA: Analyzing Visual Chain-of-Thought Reasoning of Vision Language Models in Real-World Scenarios with Driving Theory Tests</title><link>http://arxiv.org/abs/2501.04671v1</link><description>Large vision-language models (LVLMs) augment language models with visualunderstanding, enabling multimodal reasoning. However, due to the modality gapbetween textual and visual data, they often face significant challenges, suchas over-reliance on text priors, hallucinations, and limited capacity forcomplex visual reasoning. Existing benchmarks to evaluate visual reasoning inLVLMs often rely on schematic or synthetic images and on imprecisemachine-generated explanations. To bridge the modality gap, we presentDrivingVQA, a new benchmark derived from driving theory tests to evaluatevisual chain-of-thought reasoning in complex real-world scenarios. It offers3,931 expert-crafted multiple-choice problems and interleaved explanationsgrounded with entities relevant to the reasoning process. We leverage thisdataset to perform an extensive study of LVLMs' ability to reason about complexvisual scenarios. Our experiments reveal that open-source and proprietary LVLMsstruggle with visual chain-of-thought reasoning under zero-shot settings. Weinvestigate training strategies that leverage relevant entities to improvevisual reasoning. Notably, we observe a performance boost of up to 7\% whenreasoning over image tokens of cropped regions tied to these entities.</description><author>Charles Corbière, Simon Roburin, Syrielle Montariol, Antoine Bosselut, Alexandre Alahi</author><pubDate>Wed, 08 Jan 2025 18:31:16 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04671v1</guid></item><item><title>Are They the Same? Exploring Visual Correspondence Shortcomings of Multimodal LLMs</title><link>http://arxiv.org/abs/2501.04670v1</link><description>Recent advancements in multimodal models have shown a strong ability invisual perception, reasoning abilities, and vision-language understanding.However, studies on visual matching ability are missing, where finding thevisual correspondence of objects is essential in vision research. Our researchreveals that the matching capabilities in recent multimodal LLMs (MLLMs) stillexhibit systematic shortcomings, even with current strong MLLMs models, GPT-4o.In particular, we construct a Multimodal Visual Matching (MMVM) benchmark tofairly benchmark over 30 different MLLMs. The MMVM benchmark is built from 15open-source datasets and Internet videos with manual annotation. We categorizethe data samples of MMVM benchmark into eight aspects based on the requiredcues and capabilities to more comprehensively evaluate and analyze currentMLLMs. In addition, we have designed an automatic annotation pipeline togenerate the MMVM SFT dataset, including 220K visual matching data withreasoning annotation. Finally, we present CoLVA, a novel contrastive MLLM withtwo novel technical designs: fine-grained vision expert with object-levelcontrastive learning and instruction augmentation strategy. CoLVA achieves51.06\% overall accuracy (OA) on the MMVM benchmark, surpassing GPT-4o andbaseline by 8.41\% and 23.58\% OA, respectively. The results show theeffectiveness of our MMVM SFT dataset and our novel technical designs. Code,benchmark, dataset, and models are available athttps://github.com/zhouyiks/CoLVA.</description><author>Yikang Zhou, Tao Zhang, Shilin Xu, Shihao Chen, Qianyu Zhou, Yunhai Tong, Shunping Ji, Jiangning Zhang, Xiangtai Li, Lu Qi</author><pubDate>Wed, 08 Jan 2025 18:30:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04670v1</guid></item><item><title>Natural Variational Annealing for Multimodal Optimization</title><link>http://arxiv.org/abs/2501.04667v1</link><description>We introduce a new multimodal optimization approach called NaturalVariational Annealing (NVA) that combines the strengths of three foundationalconcepts to simultaneously search for multiple global and local modes ofblack-box nonconvex objectives. First, it implements a simultaneous search byusing variational posteriors, such as, mixtures of Gaussians. Second, itapplies annealing to gradually trade off exploration for exploitation. Finally,it learns the variational search distribution using natural-gradient learningwhere updates resemble well-known and easy-to-implement algorithms. The threeconcepts come together in NVA giving rise to new algorithms and also allowingus to incorporate "fitness shaping", a core concept from evolutionaryalgorithms. We assess the quality of search on simulations and compare them tomethods using gradient descent and evolution strategies. We also provide anapplication to a real-world inverse problem in planetary science.</description><author>Tâm Le Minh, Julyan Arbel, Thomas Möllenhoff, Mohammad Emtiyaz Khan, Florence Forbes</author><pubDate>Wed, 08 Jan 2025 18:28:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04667v1</guid></item><item><title>Enhancing Virtual Try-On with Synthetic Pairs and Error-Aware Noise Scheduling</title><link>http://arxiv.org/abs/2501.04666v1</link><description>Given an isolated garment image in a canonical product view and a separateimage of a person, the virtual try-on task aims to generate a new image of theperson wearing the target garment. Prior virtual try-on works face two majorchallenges in achieving this goal: a) the paired (human, garment) training datahas limited availability; b) generating textures on the human that perfectlymatch that of the prompted garment is difficult, often resulting in distortedtext and faded textures. Our work explores ways to tackle these issues throughboth synthetic data as well as model refinement. We introduce a garmentextraction model that generates (human, synthetic garment) pairs from a singleimage of a clothed individual. The synthetic pairs can then be used to augmentthe training of virtual try-on. We also propose an Error-Aware Refinement-basedSchr\"odinger Bridge (EARSB) that surgically targets localized generationerrors for correcting the output of a base virtual try-on model. To identifylikely errors, we propose a weakly-supervised error classifier that localizesregions for refinement, subsequently augmenting the Schr\"odinger Bridge'snoise schedule with its confidence heatmap. Experiments on VITON-HD andDressCode-Upper demonstrate that our synthetic data augmentation enhances theperformance of prior work, while EARSB improves the overall image quality. Inuser studies, our model is preferred by the users in an average of 59% ofcases.</description><author>Nannan Li, Kevin J. Shih, Bryan A. Plummer</author><pubDate>Wed, 08 Jan 2025 18:25:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04666v1</guid></item><item><title>GABAR: Graph Attention-Based Action Ranking for Relational Policy Learning</title><link>http://arxiv.org/abs/2412.04752v2</link><description>We propose a novel approach to learn relational policies for classicalplanning based on learning to rank actions. We introduce a new graphrepresentation that explicitly captures action information and propose a GraphNeural Network architecture augmented with Gated Recurrent Units (GRUs) tolearn action rankings. Our model is trained on small problem instances andgeneralizes to significantly larger instances where traditional planningbecomes computationally expensive. Experimental results across standardplanning benchmarks demonstrate that our action-ranking approach achievesgeneralization to significantly larger problems than those used in training.</description><author>Rajesh Mangannavar, Stefan Lee, Alan Fern, Prasad Tadepalli</author><pubDate>Wed, 08 Jan 2025 18:23:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04752v2</guid></item><item><title>HyFusion: Enhanced Reception Field Transformer for Hyperspectral Image Fusion</title><link>http://arxiv.org/abs/2501.04665v1</link><description>Hyperspectral image (HSI) fusion addresses the challenge of reconstructingHigh-Resolution HSIs (HR-HSIs) from High-Resolution Multispectral images(HR-MSIs) and Low-Resolution HSIs (LR-HSIs), a critical task given the highcosts and hardware limitations associated with acquiring high-quality HSIs.While existing methods leverage spatial and spectral relationships, they oftensuffer from limited receptive fields and insufficient feature utilization,leading to suboptimal performance. Furthermore, the scarcity of high-qualityHSI data highlights the importance of efficient data utilization to maximizereconstruction quality. To address these issues, we propose HyFusion, a novelframework designed to enhance the receptive field and enable effective featuremap reusing, thereby maximizing data utilization. First, HR-MSI and LR-HSIinputs are concatenated to form a quasi-fused draft, preserving complementaryspatial and spectral details. Next, the Enhanced Reception Field Block (ERFB)is introduced, combining shifting-window attention and dense connections toexpand the receptive field, effectively capturing long-range dependencies andreusing features to reduce information loss, thereby boosting data efficiency.Finally, the Dual-Coupled Network (DCN) dynamically extracts high-frequencyspectral and spatial features from LR-HSI and HR-MSI, ensuring efficientcross-domain fusion. Extensive experiments demonstrate that HyFusion achievesstate-of-the-art performance in HR-MSI/LR-HSI fusion, significantly improvingreconstruction quality while maintaining a compact model size and computationalefficiency. By integrating enhanced receptive fields and feature map reusing,HyFusion provides a practical and effective solution for HSI fusion inresource-constrained scenarios, setting a new benchmark in hyperspectralimaging. Our code will be publicly available.</description><author>Chia-Ming Lee, Yu-Fan Lin, Yu-Hao Ho, Li-Wei Kang, Chih-Chung Hsu</author><pubDate>Wed, 08 Jan 2025 18:22:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04665v1</guid></item><item><title>Hierarchical Object-Oriented POMDP Planning for Object Rearrangement</title><link>http://arxiv.org/abs/2412.01348v2</link><description>We present an online planning framework for solving multi-objectrearrangement problems in partially observable, multi-room environments.Current object rearrangement solutions, primarily based on ReinforcementLearning or hand-coded planning methods, often lack adaptability to diversechallenges. To address this limitation, we introduce a novel HierarchicalObject-Oriented Partially Observed Markov Decision Process (HOO-POMDP) planningapproach. This approach comprises of (a) an object-oriented POMDP plannergenerating sub-goals, (b) a set of low-level policies for sub-goal achievement,and (c) an abstraction system converting the continuous low-level world into arepresentation suitable for abstract planning. We evaluate our system onvarying numbers of objects, rooms, and problem types in AI2-THOR simulatedenvironments with promising results.</description><author>Rajesh Mangannavar, Alan Fern, Prasad Tadepalli</author><pubDate>Wed, 08 Jan 2025 18:20:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.01348v2</guid></item><item><title>Correlated Privacy Mechanisms for Differentially Private Distributed Mean Estimation</title><link>http://arxiv.org/abs/2407.03289v2</link><description>Differentially private distributed mean estimation (DP-DME) is a fundamentalbuilding block in privacy-preserving federated learning, where a central serverestimates the mean of $d$-dimensional vectors held by $n$ users while ensuring$(\epsilon,\delta)$-DP. Local differential privacy (LDP) and distributed DPwith secure aggregation (SA) are the most common notions of DP used in DP-DMEsettings with an untrusted server. LDP provides strong resilience to dropouts,colluding users, and adversarial attacks, but suffers from poor utility. Incontrast, SA-based DP-DME achieves an $O(n)$ utility gain over LDP in DME, butrequires increased communication and computation overheads and complexmulti-round protocols to handle dropouts and attacks. In this work, we presenta generalized framework for DP-DME, that captures LDP and SA-based mechanismsas extreme cases. Our framework provides a foundation for developing andanalyzing a variety of DP-DME protocols that leverage correlated privacymechanisms across users. To this end, we propose CorDP-DME, a novel DP-DMEmechanism based on the correlated Gaussian mechanism, that spans the gapbetween DME with LDP and distributed DP. We prove that CorDP-DME offers afavorable balance between utility and resilience to dropout and collusion. Weprovide an information-theoretic analysis of CorDP-DME, and derive theoreticalguarantees for utility under any given privacy parameters and dropout/colludinguser thresholds. Our results demonstrate that (anti) correlated Gaussian DPmechanisms can significantly improve utility in mean estimation tasks comparedto LDP -- even in adversarial settings -- while maintaining better resilienceto dropouts and attacks compared to distributed DP.</description><author>Sajani Vithana, Viveck R. Cadambe, Flavio P. Calmon, Haewon Jeong</author><pubDate>Wed, 08 Jan 2025 18:20:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.03289v2</guid></item><item><title>Representation Shattering in Transformers: A Synthetic Study with Knowledge Editing</title><link>http://arxiv.org/abs/2410.17194v3</link><description>Knowledge Editing (KE) algorithms alter models' weights to perform targetedupdates to incorrect, outdated, or otherwise unwanted factual associations. Tobetter identify the possibilities and limitations of these approaches, recentwork has shown that applying KE can adversely affect models' factual recallaccuracy and diminish their general reasoning abilities. While these studiesgive broad insights into the potential harms of KE algorithms, e.g., viaperformance evaluations on benchmarks, we argue little is understood as to whysuch destructive failures occur. Is it possible KE methods distortrepresentations of concepts beyond the targeted fact, hence hampering abilitiesat broad? If so, what is the extent of this distortion? Motivated by suchquestions, we define a novel synthetic task wherein a Transformer is trainedfrom scratch to internalize a "structured" knowledge graph. The structureenforces relationships between entities of the graph, such that editing afactual association has "trickling effects" on other entities in the graph(e.g., altering X's parent is Y to Z affects who X's siblings' parent is).Through evaluations of edited models and analysis of extracted representations,we show that KE inadvertently affects representations of entities beyond thetargeted one, distorting relevant structures that allow a model to infer unseenknowledge about an entity. We call this phenomenon representation shatteringand demonstrate that it results in degradation of factual recall and reasoningperformance more broadly. To corroborate our findings in a more naturalisticsetup, we perform preliminary experiments with pre-trained Llama and Mambamodels, reproducing the representation shattering effect therein as well.Overall, our work yields a precise mechanistic hypothesis to explain why KE hasadverse effects on model abilities.</description><author>Kento Nishi, Maya Okawa, Rahul Ramesh, Mikail Khona, Hidenori Tanaka, Ekdeep Singh Lubana</author><pubDate>Wed, 08 Jan 2025 18:18:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.17194v3</guid></item><item><title>On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena</title><link>http://arxiv.org/abs/2501.04662v1</link><description>Language Models (LMs) have been shown to exhibit a strong preference towardsentities associated with Western culture when operating in non-Westernlanguages. In this paper, we aim to uncover the origins of entity-relatedcultural biases in LMs by analyzing several contributing factors, including therepresentation of entities in pre-training data and the impact of variations inlinguistic phenomena across languages. We introduce CAMeL-2, a parallelArabic-English benchmark of 58,086 entities associated with Arab and Westerncultures and 367 masked natural contexts for entities. Our evaluations usingCAMeL-2 reveal reduced performance gaps between cultures by LMs when tested inEnglish compared to Arabic. We find that LMs struggle in Arabic with entitiesthat appear at high frequencies in pre-training, where entities can holdmultiple word senses. This also extends to entities that exhibit high lexicaloverlap with languages that are not Arabic but use the Arabic script. Further,we show how frequency-based tokenization leads to this issue in LMs, which getsworse with larger Arabic vocabularies. We will make CAMeL-2 available at:https://github.com/tareknaous/camel2</description><author>Tarek Naous, Wei Xu</author><pubDate>Wed, 08 Jan 2025 18:15:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04662v1</guid></item><item><title>Assessing Language Comprehension in Large Language Models Using Construction Grammar</title><link>http://arxiv.org/abs/2501.04661v1</link><description>Large Language Models, despite their significant capabilities, are known tofail in surprising and unpredictable ways. Evaluating their true`understanding' of language is particularly challenging due to the extensiveweb-scale data they are trained on. Therefore, we construct an evaluation tosystematically assess natural language understanding (NLU) in LLMs byleveraging Construction Grammar (CxG), which provides insights into the meaningcaptured by linguistic elements known as constructions (Cxns). CxG iswell-suited for this purpose because provides a theoretical basis to constructtargeted evaluation sets. These datasets are carefully constructed to includeexamples which are unlikely to appear in pre-training data, yet intuitive andeasy for humans to understand, enabling a more targeted and reliableassessment. Our experiments focus on downstream natural language inference andreasoning tasks by comparing LLMs' understanding of the underlying meaningscommunicated through 8 unique Cxns with that of humans. The results show thatwhile LLMs demonstrate some knowledge of constructional information, even thelatest models including GPT-o1 struggle with abstract meanings conveyed bythese Cxns, as demonstrated in cases where test sentences are dissimilar totheir pre-training data. We argue that such cases provide a more accurate testof true language understanding, highlighting key limitations in LLMs' semanticcapabilities. We make our novel dataset and associated experimental dataincluding prompts and model responses publicly available.</description><author>Wesley Scivetti, Melissa Torgbi, Austin Blodgett, Mollie Shichman, Taylor Hudson, Claire Bonial, Harish Tayyar Madabushi</author><pubDate>Wed, 08 Jan 2025 18:15:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04661v1</guid></item><item><title>Multi-task retriever fine-tuning for domain-specific and efficient RAG</title><link>http://arxiv.org/abs/2501.04652v1</link><description>Retrieval-Augmented Generation (RAG) has become ubiquitous when deployingLarge Language Models (LLMs), as it can address typical limitations such asgenerating hallucinated or outdated information. However, when buildingreal-world RAG applications, practical issues arise. First, the retrievedinformation is generally domain-specific. Since it is computationally expensiveto fine-tune LLMs, it is more feasible to fine-tune the retriever to improvethe quality of the data included in the LLM input. Second, as more applicationsare deployed in the same real-world system, one cannot afford to deployseparate retrievers. Moreover, these RAG applications normally retrievedifferent kinds of data. Our solution is to instruction fine-tune a smallretriever encoder on a variety of domain-specific tasks to allow us to deployone encoder that can serve many use cases, thereby achieving low-cost,scalability, and speed. We show how this encoder generalizes to out-of-domainsettings as well as to an unseen retrieval task on real-world enterprise usecases.</description><author>Patrice Béchard, Orlando Marquez Ayala</author><pubDate>Wed, 08 Jan 2025 18:05:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04652v1</guid></item><item><title>FlairGPT: Repurposing LLMs for Interior Designs</title><link>http://arxiv.org/abs/2501.04648v1</link><description>Interior design involves the careful selection and arrangement of objects tocreate an aesthetically pleasing, functional, and harmonized space that alignswith the client's design brief. This task is particularly challenging, as asuccessful design must not only incorporate all the necessary objects in acohesive style, but also ensure they are arranged in a way that maximizesaccessibility, while adhering to a variety of affordability and usageconsiderations. Data-driven solutions have been proposed, but these aretypically room- or domain-specific and lack explainability in their designdesign considerations used in producing the final layout. In this paper, weinvestigate if large language models (LLMs) can be directly utilized forinterior design. While we find that LLMs are not yet capable of generatingcomplete layouts, they can be effectively leveraged in a structured manner,inspired by the workflow of interior designers. By systematically probing LLMs,we can reliably generate a list of objects along with relevant constraints thatguide their placement. We translate this information into a design layoutgraph, which is then solved using an off-the-shelf constrained optimizationsetup to generate the final layouts. We benchmark our algorithm in variousdesign configurations against existing LLM-based methods and human designs, andevaluate the results using a variety of quantitative and qualitative metricsalong with user studies. In summary, we demonstrate that LLMs, when used in astructured manner, can effectively generate diverse high-quality layouts,making them a viable solution for creating large-scale virtual scenes. Projectwebpage at https://flairgpt.github.io/</description><author>Gabrielle Littlefair, Niladri Shekhar Dutt, Niloy J. Mitra</author><pubDate>Wed, 08 Jan 2025 18:01:49 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04648v1</guid></item><item><title>Structure of activity in multiregion recurrent neural networks</title><link>http://arxiv.org/abs/2402.12188v3</link><description>Neural circuits comprise multiple interconnected regions, each with complexdynamics. The interplay between local and global activity is thought tounderlie computational flexibility, yet the structure of multiregion neuralactivity and its origins in synaptic connectivity remain poorly understood. Weinvestigate recurrent neural networks with multiple regions, each containingneurons with random and structured connections. Inspired by experimentalevidence of communication subspaces, we use low-rank connectivity betweenregions to enable selective activity routing. These networks exhibithigh-dimensional fluctuations within regions and low-dimensional signaltransmission between them. Using dynamical mean-field theory, with cross-regioncurrents as order parameters, we show that regions act as both generators andtransmitters of activity -- roles that are often in tension. Tamingwithin-region activity can be crucial for effective signal routing. Unlikeprevious models that suppressed neural activity to control signal flow, ourmodel achieves routing by exciting different high-dimensional activity patternsthrough connectivity structure and nonlinear dynamics. Our analysis offersinsights into multiregion neural data and trained neural networks.</description><author>David G. Clark, Manuel Beiran</author><pubDate>Wed, 08 Jan 2025 17:50:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12188v3</guid></item><item><title>Discrete Wavelet Transform-Based Capsule Network for Hyperspectral Image Classification</title><link>http://arxiv.org/abs/2501.04643v1</link><description>Hyperspectral image (HSI) classification is a crucial technique for remotesensing to build large-scale earth monitoring systems. HSI contains much moreinformation than traditional visual images for identifying the categories ofland covers. One recent feasible solution for HSI is to leverage CapsNets forcapturing spectral-spatial information. However, these methods require highcomputational requirements due to the full connection architecture betweenstacked capsule layers. To solve this problem, a DWT-CapsNet is proposed toidentify partial but important connections in CapsNet for a effective andefficient HSI classification. Specifically, we integrate a tailored attentionmechanism into a Discrete Wavelet Transform (DWT)-based downsampling layer,alleviating the information loss problem of conventional downsampling operationin feature extractors. Moreover, we propose a novel multi-scale routingalgorithm that prunes a large proportion of connections in CapsNet. A capsulepyramid fusion mechanism is designed to aggregate the spectral-spatialrelationships in multiple levels of granularity, and then a self-attentionmechanism is further conducted in a partially and locally connectedarchitecture to emphasize the meaningful relationships. As shown in theexperimental results, our method achieves state-of-the-art accuracy whilekeeping lower computational demand regarding running time, flops, and thenumber of parameters, rendering it an appealing choice for practicalimplementation in HSI classification.</description><author>Zhiqiang Gao, Jiaqi Wang, Hangchi Shen, Zhihao Dou, Xiangbo Zhang, Kaizhu Huang</author><pubDate>Wed, 08 Jan 2025 17:49:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04643v1</guid></item><item><title>A Statistical Theory of Contrastive Pre-training and Multimodal Generative AI</title><link>http://arxiv.org/abs/2501.04641v1</link><description>Multi-modal generative AI systems, such as those combining vision andlanguage, rely on contrastive pre-training to learn representations acrossdifferent modalities. While their practical benefits are widely acknowledged, arigorous theoretical understanding of the contrastive pre-training frameworkremains limited. This paper develops a theoretical framework to explain thesuccess of contrastive pre-training in downstream tasks, such as zero-shotclassification, conditional diffusion models, and vision-language models. Weintroduce the concept of approximate sufficient statistics, a generalization ofthe classical sufficient statistics, and show that near-minimizers of thecontrastive pre-training loss are approximately sufficient, making themadaptable to diverse downstream tasks. We further propose the Joint GenerativeHierarchical Model for the joint distribution of images and text, showing thattransformers can efficiently approximate relevant functions within this modelvia belief propagation. Building on this framework, we derive sample complexityguarantees for multi-modal learning based on contrastive pre-trainedrepresentations. Numerical simulations validate these theoretical findings,demonstrating the strong generalization performance of contrastivelypre-trained transformers in various multi-modal tasks.</description><author>Kazusato Oko, Licong Lin, Yuhang Cai, Song Mei</author><pubDate>Wed, 08 Jan 2025 17:47:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04641v1</guid></item><item><title>Samba-ASR: State-Of-The-Art Speech Recognition Leveraging Structured State-Space Models</title><link>http://arxiv.org/abs/2501.02832v3</link><description>We propose Samba ASR,the first state of the art Automatic SpeechRecognition(ASR)model leveraging the novel Mamba architecture as both encoderand decoder,built on the foundation of state space models(SSMs).Unliketransformerbased ASR models,which rely on self-attention mechanisms to capturedependencies,Samba ASR effectively models both local and global temporaldependencies using efficient statespace dynamics,achieving remarkableperformance gains.By addressing the limitations of transformers,such asquadratic scaling with input length and difficulty in handling longrangedependencies,Samba ASR achieves superior accuracy and efficiency.Experimentalresults demonstrate that Samba ASR surpasses existing opensourcetransformerbased ASR models across various standard benchmarks,establishing itas the new state of theart in ASR.Extensive evaluations on the benchmarkdataset show significant improvements in Word Error Rate(WER),with competitiveperformance even in lowresource scenarios.Furthermore,the inherentcomputational efficiency and parameter optimization of the Mamba architecturemake Samba ASR a scalable and robust solution for diverse ASR tasks.Ourcontributions include the development of a new Samba ASR architecture forautomatic speech recognition(ASR),demonstrating the superiority of structuredstatespace models(SSMs)over transformer based models for speech sequenceprocessing.We provide a comprehensive evaluation on publicbenchmarks,showcasing stateoftheart(SOTA)performance,and present an indepthanalysis of computational efficiency,robustness to noise,and sequencegeneralization.This work highlights the viability of Mamba SSMs as atransformerfree alternative for efficient and accurate ASR.By leveraging theadvancements of statespace modeling,Samba ASR redefines ASR performancestandards and sets a new benchmark for future research in this field.</description><author>Syed Abdul Gaffar Shakhadri, Kruthika KR, Kartik Basavaraj Angadi</author><pubDate>Wed, 08 Jan 2025 17:46:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.02832v3</guid></item><item><title>MADation: Face Morphing Attack Detection with Foundation Models</title><link>http://arxiv.org/abs/2501.03800v2</link><description>Despite the considerable performance improvements of face recognitionalgorithms in recent years, the same scientific advances responsible for thisprogress can also be used to create efficient ways to attack them, posing athreat to their secure deployment. Morphing attack detection (MAD) systems aimto detect a specific type of threat, morphing attacks, at an early stage,preventing them from being considered for verification in critical processes.Foundation models (FM) learn from extensive amounts of unlabeled data,achieving remarkable zero-shot generalization to unseen domains. Although thisgeneralization capacity might be weak when dealing with domain-specificdownstream tasks such as MAD, FMs can easily adapt to these settings whileretaining the built-in knowledge acquired during pre-training. In this work, werecognize the potential of FMs to perform well in the MAD task when properlyadapted to its specificities. To this end, we adapt FM CLIP architectures withLoRA weights while simultaneously training a classification header. Theproposed framework, MADation surpasses our alternative FM and transformer-basedframeworks and constitutes the first adaption of FMs to the MAD task. MADationpresents competitive results with current MAD solutions in the literature andeven surpasses them in several evaluation scenarios. To encouragereproducibility and facilitate further research in MAD, we publicly release theimplementation of MADation at https: //github.com/gurayozgur/MADation</description><author>Eduarda Caldeira, Guray Ozgur, Tahar Chettaoui, Marija Ivanovska, Peter Peer, Fadi Boutros, Vitomir Struc, Naser Damer</author><pubDate>Wed, 08 Jan 2025 17:44:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03800v2</guid></item><item><title>A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding</title><link>http://arxiv.org/abs/2409.15861v2</link><description>Dialogue State Tracking (DST) is crucial for understanding user needs andexecuting appropriate system actions in task-oriented dialogues. Majority ofexisting DST methods are designed to work within predefined ontologies andassume the availability of gold domain labels, struggling with adapting to newslots values. While Large Language Models (LLMs)-based systems show promisingzero-shot DST performance, they either require extensive computationalresources or they underperform existing fully-trained systems, limiting theirpracticality. To address these limitations, we propose a zero-shot,open-vocabulary system that integrates domain classification and DST in asingle pipeline. Our approach includes reformulating DST as aquestion-answering task for less capable models and employing self-refiningprompts for more adaptable ones. Our system does not rely on fixed slot valuesdefined in the ontology allowing the system to adapt dynamically. We compareour approach with existing SOTA, and show that it provides up to 20% betterJoint Goal Accuracy (JGA) over previous methods on datasets like Multi-WOZ 2.1,with up to 90% fewer requests to the LLM API.</description><author>Abdulfattah Safa, Gözde Gül Şahin</author><pubDate>Wed, 08 Jan 2025 17:41:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.15861v2</guid></item><item><title>Diffusion Map Autoencoder</title><link>http://arxiv.org/abs/2409.05901v2</link><description>In this work, we explore various modifications to diffusion maps (DMAP),including their incorporation into a layered sequential neural network modeltrained with gradient descent. The result is a sequential neural network thatinherits the interpretability of diffusion maps.</description><author>Julio Candanedo</author><pubDate>Wed, 08 Jan 2025 17:36:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.05901v2</guid></item><item><title>Knowledge Retrieval Based on Generative AI</title><link>http://arxiv.org/abs/2501.04635v1</link><description>This study develops a question-answering system based on Retrieval-AugmentedGeneration (RAG) using Chinese Wikipedia and Lawbank as retrieval sources.Using TTQA and TMMLU+ as evaluation datasets, the system employs BGE-M3 fordense vector retrieval to obtain highly relevant search results andBGE-reranker to reorder these results based on query relevance. The mostpertinent retrieval outcomes serve as reference knowledge for a Large LanguageModel (LLM), enhancing its ability to answer questions and establishing aknowledge retrieval system grounded in generative AI. The system's effectiveness is assessed through a two-stage evaluation:automatic and assisted performance evaluations. The automatic evaluationcalculates accuracy by comparing the model's auto-generated labels with groundtruth answers, measuring performance under standardized conditions withouthuman intervention. The assisted performance evaluation involves 20finance-related multiple-choice questions answered by 20 participants withoutfinancial backgrounds. Initially, participants answer independently. Later,they receive system-generated reference information to assist in answering,examining whether the system improves accuracy when assistance is provided. The main contributions of this research are: (1) Enhanced LLM Capability: Byintegrating BGE-M3 and BGE-reranker, the system retrieves and reorders highlyrelevant results, reduces hallucinations, and dynamically accesses authorizedor public knowledge sources. (2) Improved Data Privacy: A customized RAGarchitecture enables local operation of the LLM, eliminating the need to sendprivate data to external servers. This approach enhances data security, reducesreliance on commercial services, lowers operational costs, and mitigatesprivacy risks.</description><author>Te-Lun Yang, Jyi-Shane Liu, Yuen-Hsien Tseng, Jyh-Shing Roger Jang</author><pubDate>Wed, 08 Jan 2025 17:29:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04635v1</guid></item><item><title>Disentangled Clothed Avatar Generation with Layered Representation</title><link>http://arxiv.org/abs/2501.04631v1</link><description>Clothed avatar generation has wide applications in virtual and augmentedreality, filmmaking, and more. Previous methods have achieved success ingenerating diverse digital avatars, however, generating avatars withdisentangled components (\eg, body, hair, and clothes) has long been achallenge. In this paper, we propose LayerAvatar, the first feed-forwarddiffusion-based method for generating component-disentangled clothed avatars.To achieve this, we first propose a layered UV feature plane representation,where components are distributed in different layers of the Gaussian-based UVfeature plane with corresponding semantic labels. This representation supportshigh-resolution and real-time rendering, as well as expressive animationincluding controllable gestures and facial expressions. Based on thewell-designed representation, we train a single-stage diffusion model andintroduce constrain terms to address the severe occlusion problem of theinnermost human body layer. Extensive experiments demonstrate the impressiveperformances of our method in generating disentangled clothed avatars, and wefurther explore its applications in component transfer. The project page isavailable at: https://olivia23333.github.io/LayerAvatar/</description><author>Weitian Zhang, Sijing Wu, Manwen Liao, Yichao Yan</author><pubDate>Wed, 08 Jan 2025 17:27:27 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04631v1</guid></item><item><title>FatesGS: Fast and Accurate Sparse-View Surface Reconstruction using Gaussian Splatting with Depth-Feature Consistency</title><link>http://arxiv.org/abs/2501.04628v1</link><description>Recently, Gaussian Splatting has sparked a new trend in the field of computervision. Apart from novel view synthesis, it has also been extended to the areaof multi-view reconstruction. The latest methods facilitate complete, detailedsurface reconstruction while ensuring fast training speed. However, thesemethods still require dense input views, and their output quality significantlydegrades with sparse views. We observed that the Gaussian primitives tend tooverfit the few training views, leading to noisy floaters and incompletereconstruction surfaces. In this paper, we present an innovative sparse-viewreconstruction framework that leverages intra-view depth and multi-view featureconsistency to achieve remarkably accurate surface reconstruction.Specifically, we utilize monocular depth ranking information to supervise theconsistency of depth distribution within patches and employ a smoothness lossto enhance the continuity of the distribution. To achieve finer surfacereconstruction, we optimize the absolute position of depth through multi-viewprojection features. Extensive experiments on DTU and BlendedMVS demonstratethat our method outperforms state-of-the-art methods with a speedup of 60x to200x, achieving swift and fine-grained mesh reconstruction without the need forcostly pre-training.</description><author>Han Huang, Yulun Wu, Chao Deng, Ge Gao, Ming Gu, Yu-Shen Liu</author><pubDate>Wed, 08 Jan 2025 17:19:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04628v1</guid></item><item><title>Fast and Interpretable Mortality Risk Scores for Critical Care Patients</title><link>http://arxiv.org/abs/2311.13015v4</link><description>Prediction of mortality in intensive care unit (ICU) patients typicallyrelies on black box models (that are unacceptable for use in hospitals) orhand-tuned interpretable models (that might lead to the loss in performance).We aim to bridge the gap between these two categories by building on moderninterpretable ML techniques to design interpretable mortality risk scores thatare as accurate as black boxes. We developed a new algorithm, GroupFasterRisk,which has several important benefits: it uses both hard and soft directsparsity regularization, it incorporates group sparsity to allow more cohesivemodels, it allows for monotonicity constraint to include domain knowledge, andit produces many equally-good models, which allows domain experts to chooseamong them. For evaluation, we leveraged the largest existing public ICUmonitoring datasets (MIMIC III and eICU). Models produced by GroupFasterRiskoutperformed OASIS and SAPS II scores and performed similarly to APACHE IV/IVawhile using at most a third of the parameters. For patients withsepsis/septicemia, acute myocardial infarction, heart failure, and acute kidneyfailure, GroupFasterRisk models outperformed OASIS and SOFA. Finally, differentmortality prediction ML approaches performed better based on variables selectedby GroupFasterRisk as compared to OASIS variables. GroupFasterRisk's modelsperformed better than risk scores currently used in hospitals, and on par withblack box ML models, while being orders of magnitude sparser. BecauseGroupFasterRisk produces a variety of risk scores, it allows design flexibility- the key enabler of practical model creation. GroupFasterRisk is a fast,accessible, and flexible procedure that allows learning a diverse set of sparserisk scores for mortality prediction.</description><author>Chloe Qinyu Zhu, Muhang Tian, Lesia Semenova, Jiachang Liu, Jack Xu, Joseph Scarpa, Cynthia Rudin</author><pubDate>Wed, 08 Jan 2025 17:14:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.13015v4</guid></item><item><title>HAF-RM: A Hybrid Alignment Framework for Reward Model Training</title><link>http://arxiv.org/abs/2407.04185v4</link><description>The reward model has become increasingly important in alignment, assessment,and data construction for large language models (LLMs). Most existingresearchers focus on enhancing reward models through data improvements,following the conventional training framework for reward models that directlyoptimizes the predicted rewards. In this paper, we propose a hybrid alignmentframework HaF-RM for reward model training by introducing an additionalconstraint on token-level policy probabilities in addition to the reward score.It can simultaneously supervise the internal preference model at the tokenlevel and optimize the mapping layer of the reward model at the sequence level.Experiment results on five datasets sufficiently show the validity andeffectiveness of our proposed hybrid framework for training a high-qualityreward model. By decoupling the reward modeling procedure and incorporatinghybrid supervision, our HaF-RM framework offers a principled and effectiveapproach to enhancing the performance and alignment of reward models, acritical component in the responsible development of powerful language models.We release our code at https://haf-rm.github.io.</description><author>Shujun Liu, Xiaoyu Shen, Yuhang Lai, Siyuan Wang, Shengbin Yue, Zengfeng Huang, Xuanjing Huang, Zhongyu Wei</author><pubDate>Wed, 08 Jan 2025 17:11:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.04185v4</guid></item><item><title>Forget Vectors at Play: Universal Input Perturbations Driving Machine Unlearning in Image Classification</title><link>http://arxiv.org/abs/2412.16780v2</link><description>Machine unlearning (MU), which seeks to erase the influence of specificunwanted data from already-trained models, is becoming increasingly vital inmodel editing, particularly to comply with evolving data regulations like the``right to be forgotten''. Conventional approaches are predominantlymodel-based, typically requiring retraining or fine-tuning the model's weightsto meet unlearning requirements. In this work, we approach the MU problem froma novel input perturbation-based perspective, where the model weights remainintact throughout the unlearning process. We demonstrate the existence of aproactive input-based unlearning strategy, referred to forget vector, which canbe generated as an input-agnostic data perturbation and remains as effective asmodel-based approximate unlearning approaches. We also explore forget vectorarithmetic, whereby multiple class-specific forget vectors are combined throughsimple operations (e.g., linear combinations) to generate new forget vectorsfor unseen unlearning tasks, such as forgetting arbitrary subsets acrossclasses. Extensive experiments validate the effectiveness and adaptability ofthe forget vector, showcasing its competitive performance relative tostate-of-the-art model-based methods. Codes are available athttps://github.com/Changchangsun/Forget-Vector.</description><author>Changchang Sun, Ren Wang, Yihua Zhang, Jinghan Jia, Jiancheng Liu, Gaowen Liu, Sijia Liu, Yan Yan</author><pubDate>Wed, 08 Jan 2025 17:00:18 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.16780v2</guid></item><item><title>MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation</title><link>http://arxiv.org/abs/2501.04614v1</link><description>Artificial Intelligence is revolutionizing medical practice, enhancingdiagnostic accuracy and healthcare delivery. However, its adaptation in medicalsettings still faces significant challenges, related to data availability andprivacy constraints. Synthetic data has emerged as a promising solution tomitigate these issues, addressing data scarcity while preserving privacy.Recently, Latent Diffusion Models have emerged as a powerful tool forgenerating high-quality synthetic data. Meanwhile, the integration of differentmodalities has gained interest, emphasizing the need of models capable ofhandle multimodal medical data.Existing approaches struggle to integratecomplementary information and lack the ability to generate modalitiessimultaneously. To address this challenge, we present MedCoDi-M, a6.77-billion-parameter model, designed for multimodal medical data generation,that, following Foundation Model paradigm, exploits contrastive learning andlarge quantity of data to build a shared latent space which capture therelationships between different data modalities. Further, we introduce theMulti-Prompt training technique, which significantly boosts MedCoDi-M'sgeneration under different settings. We extensively validate MedCoDi-M: firstwe benchmark it against five competitors on the MIMIC-CXR dataset, astate-of-the-art dataset for Chest X-ray and radiological report generation.Secondly, we perform a Visual Turing Test with expert radiologists to assessthe realism and clinical relevance of the generated data, ensuring alignmentwith real-world scenarios. Finally, we assess the utility of MedCoDi-M inaddressing key challenges in the medical field, such as anonymization, datascarcity and imbalance learning. The results are promising, demonstrating theapplicability of MedCoDi-M in medical contexts. Project page is athttps://cosbidev.github.io/MedCoDi-M/.</description><author>Daniele Molino, Francesco Di Feola, Eliodoro Faiella, Deborah Fazzini, Domiziana Santucci, Linlin Shen, Valerio Guarrasi, Paolo Soda</author><pubDate>Wed, 08 Jan 2025 16:53:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04614v1</guid></item><item><title>A Semantic Partitioning Method for Large-Scale Training of Knowledge Graph Embeddings</title><link>http://arxiv.org/abs/2501.04613v1</link><description>In recent years, knowledge graph embeddings have achieved great success. Manymethods have been proposed and achieved state-of-the-art results in varioustasks. However, most of the current methods present one or more of thefollowing problems: (i) They only consider fact triplets, while ignoring theontology information of knowledge graphs. (ii) The obtained embeddings do notcontain much semantic information. Therefore, using these embeddings forsemantic tasks is problematic. (iii) They do not enable large-scale training.In this paper, we propose a new algorithm that incorporates the ontology ofknowledge graphs and partitions the knowledge graph based on classes to includemore semantic information for parallel training of large-scale knowledge graphembeddings. Our preliminary results show that our algorithm performs well onseveral popular benchmarks.</description><author>Yuhe Bai</author><pubDate>Wed, 08 Jan 2025 16:53:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04613v1</guid></item><item><title>Resilient Peer-to-peer Learning based on Adaptive Aggregation</title><link>http://arxiv.org/abs/2501.04610v1</link><description>Collaborative learning in peer-to-peer networks offers the benefits ofdistributed learning while mitigating the risks associated with single pointsof failure inherent in centralized servers. However, adversarial workers posepotential threats by attempting to inject malicious information into thenetwork. Thus, ensuring the resilience of peer-to-peer learning emerges as apivotal research objective. The challenge is exacerbated in the presence ofnon-convex loss functions and non-iid data distributions. This paper introducesa resilient aggregation technique tailored for such scenarios, aimed atfostering similarity among peers' learning processes. The aggregation weightsare determined through an optimization procedure, and use the loss functioncomputed using the neighbor's models and individual private data, therebyaddressing concerns regarding data privacy in distributed machine learning.Theoretical analysis demonstrates convergence of parameters with non-convexloss functions and non-iid data distributions. Empirical evaluations acrossthree distinct machine learning tasks support the claims. The empiricalfindings, which encompass a range of diverse attack models, also demonstrateimproved accuracy when compared to existing methodologies.</description><author>Chandreyee Bhowmick, Xenofon Koutsoukos</author><pubDate>Wed, 08 Jan 2025 16:47:45 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04610v1</guid></item><item><title>Improving Zero-Shot Chinese-English Code-Switching ASR with kNN-CTC and Gated Monolingual Datastores</title><link>http://arxiv.org/abs/2406.03814v3</link><description>The kNN-CTC model has proven to be effective for monolingual automatic speechrecognition (ASR). However, its direct application to multilingual scenarioslike code-switching, presents challenges. Although there is potential forperformance improvement, a kNN-CTC model utilizing a single bilingual datastorecan inadvertently introduce undesirable noise from the alternative language. Toaddress this, we propose a novel kNN-CTC-based code-switching ASR (CS-ASR)framework that employs dual monolingual datastores and a gated datastoreselection mechanism to reduce noise interference. Our method selects theappropriate datastore for decoding each frame, ensuring the injection oflanguage-specific information into the ASR process. We apply this framework tocutting-edge CTC-based models, developing an advanced CS-ASR system. Extensiveexperiments demonstrate the remarkable effectiveness of our gated datastoremechanism in enhancing the performance of zero-shot Chinese-English CS-ASR.</description><author>Jiaming Zhou, Shiwan Zhao, Hui Wang, Tian-Hao Zhang, Haoqin Sun, Xuechen Wang, Yong Qin</author><pubDate>Wed, 08 Jan 2025 16:45:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.03814v3</guid></item><item><title>Comprehensive Examination of Unrolled Networks for Linear Inverse Problems</title><link>http://arxiv.org/abs/2501.04608v1</link><description>Unrolled networks have become prevalent in various computer vision andimaging tasks. Although they have demonstrated remarkable efficacy in solvingspecific computer vision and computational imaging tasks, their adaptation toother applications presents considerable challenges. This is primarily due tothe multitude of design decisions that practitioners working on newapplications must navigate, each potentially affecting the network's overallperformance. These decisions include selecting the optimization algorithm,defining the loss function, and determining the number of convolutional layers,among others. Compounding the issue, evaluating each design choice requirestime-consuming simulations to train, fine-tune the neural network, and optimizefor its performance. As a result, the process of exploring multiple options andidentifying the optimal configuration becomes time-consuming andcomputationally demanding. The main objectives of this paper are (1) to unifysome ideas and methodologies used in unrolled networks to reduce the number ofdesign choices a user has to make, and (2) to report a comprehensive ablationstudy to discuss the impact of each of the choices involved in designingunrolled networks and present practical recommendations based on our findings.We anticipate that this study will help scientists and engineers designunrolled networks for their applications and diagnose problems within theirnetworks efficiently.</description><author>Eric Chen, Xi Chen, Arian Maleki, Shirin Jalali</author><pubDate>Wed, 08 Jan 2025 16:44:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04608v1</guid></item><item><title>Manifolds, Random Matrices and Spectral Gaps: The geometric phases of generative diffusion</title><link>http://arxiv.org/abs/2410.05898v5</link><description>In this paper, we investigate the latent geometry of generative diffusionmodels under the manifold hypothesis. For this purpose, we analyze the spectrumof eigenvalues (and singular values) of the Jacobian of the score function,whose discontinuities (gaps) reveal the presence and dimensionality of distinctsub-manifolds. Using a statistical physics approach, we derive the spectraldistributions and formulas for the spectral gaps under several distributionalassumptions, and we compare these theoretical predictions with the spectraestimated from trained networks. Our analysis reveals the existence of threedistinct qualitative phases during the generative process: a trivial phase; amanifold coverage phase where the diffusion process fits the distributioninternal to the manifold; a consolidation phase where the score becomesorthogonal to the manifold and all particles are projected on the support ofthe data. This `division of labor' between different timescales provides anelegant explanation of why generative diffusion models are not affected by themanifold overfitting phenomenon that plagues likelihood-based models, since theinternal distribution and the manifold geometry are produced at different timepoints during generation.</description><author>Enrico Ventura, Beatrice Achilli, Gianluigi Silvestri, Carlo Lucibello, Luca Ambrogioni</author><pubDate>Wed, 08 Jan 2025 16:43:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.05898v5</guid></item><item><title>Enhancing Low-Cost Video Editing with Lightweight Adaptors and Temporal-Aware Inversion</title><link>http://arxiv.org/abs/2501.04606v1</link><description>Recent advancements in text-to-image (T2I) generation using diffusion modelshave enabled cost-effective video-editing applications by leveragingpre-trained models, eliminating the need for resource-intensive training.However, the frame-independence of T2I generation often results in poortemporal consistency. Existing methods address this issue through temporallayer fine-tuning or inference-based temporal propagation, but these approachessuffer from high training costs or limited temporal coherence. To address thesechallenges, we propose a General and Efficient Adapter (GE-Adapter) thatintegrates temporal-spatial and semantic consistency with Baliteral DDIMinversion. This framework introduces three key components: (1) Frame-basedTemporal Consistency Blocks (FTC Blocks) to capture frame-specific features andenforce smooth inter-frame transitions via temporally-aware loss functions; (2)Channel-dependent Spatial Consistency Blocks (SCD Blocks) employing bilateralfilters to enhance spatial coherence by reducing noise and artifacts; and (3)Token-based Semantic Consistency Module (TSC Module) to maintain semanticalignment using shared prompt tokens and frame-specific tokens. Our methodsignificantly improves perceptual quality, text-image alignment, and temporalcoherence, as demonstrated on the MSR-VTT dataset. Additionally, it achievesenhanced fidelity and frame-to-frame coherence, offering a practical solutionfor T2V editing.</description><author>Yangfan He, Sida Li, Kun Li, Jianhui Wang, Binxu Li, Tianyu Shi, Jun Yin, Miao Zhang, Xueqian Wang</author><pubDate>Wed, 08 Jan 2025 16:41:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04606v1</guid></item><item><title>LiLMaps: Learnable Implicit Language Maps</title><link>http://arxiv.org/abs/2501.03304v2</link><description>One of the current trends in robotics is to employ large language models(LLMs) to provide non-predefined command execution and natural human-robotinteraction. It is useful to have an environment map together with its languagerepresentation, which can be further utilized by LLMs. Such a comprehensivescene representation enables numerous ways of interaction with the map forautonomously operating robots. In this work, we present an approach thatenhances incremental implicit mapping through the integration ofvision-language features. Specifically, we (i) propose a decoder optimizationtechnique for implicit language maps which can be used when new objects appearon the scene, and (ii) address the problem of inconsistent vision-languagepredictions between different viewing positions. Our experiments demonstratethe effectiveness of LiLMaps and solid improvements in performance.</description><author>Evgenii Kruzhkov, Sven Behnke</author><pubDate>Wed, 08 Jan 2025 16:41:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03304v2</guid></item><item><title>The Indoor-Training Effect: unexpected gains from distribution shifts in the transition function</title><link>http://arxiv.org/abs/2401.15856v2</link><description>Is it better to perform tennis training in a pristine indoor environment or anoisy outdoor one? To model this problem, here we investigate whether shifts inthe transition probabilities between the training and testing environments inreinforcement learning problems can lead to better performance under certainconditions. We generate new Markov Decision Processes (MDPs) starting from agiven MDP, by adding quantifiable, parametric noise into the transitionfunction. We refer to this process as Noise Injection and the resultingenvironments as {\delta}-environments. This process allows us to createvariations of the same environment with quantitative control over noise servingas a metric of distance between environments. Conventional wisdom suggests thattraining and testing on the same MDP should yield the best results. In starkcontrast, we observe that agents can perform better when trained on thenoise-free environment and tested on the noisy {\delta}-environments, comparedto training and testing on the same {\delta}-environments. We confirm that thisfinding extends beyond noise variations: it is possible to showcase the samephenomenon in ATARI game variations including varying Ghost behaviour inPacMan, and Paddle behaviour in Pong. We demonstrate this intriguing behaviouracross 60 different variations of ATARI games, including PacMan, Pong, andBreakout. We refer to this phenomenon as the Indoor-Training Effect. Code toreproduce our experiments and to implement Noise Injection can be found athttps://bit.ly/3X6CTYk.</description><author>Serena Bono, Spandan Madan, Ishaan Grover, Mao Yasueda, Cynthia Breazeal, Hanspeter Pfister, Gabriel Kreiman</author><pubDate>Wed, 08 Jan 2025 16:31:06 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.15856v2</guid></item><item><title>Efficient Tool Use with Chain-of-Abstraction Reasoning</title><link>http://arxiv.org/abs/2401.17464v3</link><description>To achieve faithful reasoning that aligns with human expectations, largelanguage models (LLMs) need to ground their reasoning to real-world knowledge(e.g., web facts, math and physical rules). Tools help LLMs access thisexternal knowledge, but there remains challenges for fine-tuning LLM agents(e.g., Toolformer) to invoke tools in multi-step reasoning problems, whereinter-connected tool calls require holistic and efficient tool usage planning. In this work, we propose a new method for LLMs to better leverage tools inmulti-step reasoning. Our method, Chain-of-Abstraction (CoA), trains LLMs tofirst decode reasoning chains with abstract placeholders, and then call domaintools to reify each reasoning chain by filling in specific knowledge. Thisplanning with abstract chains enables LLMs to learn more general reasoningstrategies, which are robust to shifts of domain knowledge (e.g., math results)relevant to different reasoning questions. It also allows LLMs to performdecoding and calling of external tools in parallel, which avoids the inferencedelay caused by waiting for tool responses. In mathematical reasoning and WikiQA domains, we show that our method consistently outperforms previouschain-of-thought and tool-augmented baselines on both in-distribution andout-of-distribution test sets, with an average ~6% absolute QA accuracyimprovement. LLM agents trained with our method also show more efficient tooluse, with inference speed being on average ~1.4x faster than baselinetool-augmented LLMs.</description><author>Silin Gao, Jane Dwivedi-Yu, Ping Yu, Xiaoqing Ellen Tan, Ramakanth Pasunuru, Olga Golovneva, Koustuv Sinha, Asli Celikyilmaz, Antoine Bosselut, Tianlu Wang</author><pubDate>Wed, 08 Jan 2025 16:27:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17464v3</guid></item><item><title>Incentivized Symbiosis: A Paradigm for Human-Agent Coevolution</title><link>http://arxiv.org/abs/2412.06855v3</link><description>Cooperation is vital to our survival and progress. Evolutionary game theoryoffers a lens to understand the structures and incentives that enablecooperation to be a successful strategy. As artificial intelligence agentsbecome integral to human systems, the dynamics of cooperation take onunprecedented significance. The convergence of human-agent teaming, contracttheory, and decentralized frameworks like Web3, grounded in transparency,accountability, and trust, offers a foundation for fostering cooperation byestablishing enforceable rules and incentives for humans and AI agents. Weconceptualize Incentivized Symbiosis as a social contract between humans andAI, inspired by Web3 principles and encoded in blockchain technology, to defineand enforce rules, incentives, and consequences for both parties. By exploringthis paradigm, we aim to catalyze new research at the intersection of systemsthinking in AI, Web3, and society, fostering innovative pathways forcooperative human-agent coevolution.</description><author>Tomer Jordi Chaffer, Justin Goldston, Gemach D. A. T. A. I</author><pubDate>Wed, 08 Jan 2025 16:26:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.06855v3</guid></item><item><title>FrontierNet: Learning Visual Cues to Explore</title><link>http://arxiv.org/abs/2501.04597v1</link><description>Exploration of unknown environments is crucial for autonomous robots; itallows them to actively reason and decide on what new data to acquire for taskssuch as mapping, object discovery, and environmental assessment. Existingmethods, such as frontier-based methods, rely heavily on 3D map operations,which are limited by map quality and often overlook valuable context fromvisual cues. This work aims at leveraging 2D visual cues for efficientautonomous exploration, addressing the limitations of extracting goal posesfrom a 3D map. We propose a image-only frontier-based exploration system, withFrontierNet as a core component developed in this work. FrontierNet is alearning-based model that (i) detects frontiers, and (ii) predicts theirinformation gain, from posed RGB images enhanced by monocular depth priors. Ourapproach provides an alternative to existing 3D-dependent exploration systems,achieving a 16% improvement in early-stage exploration efficiency, as validatedthrough extensive simulations and real-world experiments.</description><author>Boyang Sun, Hanzhi Chen, Stefan Leutenegger, Cesar Cadena, Marc Pollefeys, Hermann Blum</author><pubDate>Wed, 08 Jan 2025 16:25:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04597v1</guid></item><item><title>Quantum-inspired Embeddings Projection and Similarity Metrics for Representation Learning</title><link>http://arxiv.org/abs/2501.04591v1</link><description>Over the last decade, representation learning, which embeds complexinformation extracted from large amounts of data into dense vector spaces, hasemerged as a key technique in machine learning. Among other applications, ithas been a key building block for large language models and advanced computervision systems based on contrastive learning. A core component ofrepresentation learning systems is the projection head, which maps the originalembeddings into different, often compressed spaces, while preserving thesimilarity relationship between vectors. In this paper, we propose a quantum-inspired projection head that includes acorresponding quantum-inspired similarity metric. Specifically, we mapclassical embeddings onto quantum states in Hilbert space and introduce aquantum circuit-based projection head to reduce embedding dimensionality. Toevaluate the effectiveness of this approach, we extended the BERT languagemodel by integrating our projection head for embedding compression. We comparedthe performance of embeddings, which were compressed using our quantum-inspiredprojection head, with those compressed using a classical projection head oninformation retrieval tasks using the TREC 2019 and TREC 2020 Deep Learningbenchmarks. The results demonstrate that our quantum-inspired method achievescompetitive performance relative to the classical method while utilizing 32times fewer parameters. Furthermore, when trained from scratch, it notablyexcels, particularly on smaller datasets. This work not only highlights theeffectiveness of the quantum-inspired approach but also emphasizes the utilityof efficient, ad hoc low-entanglement circuit simulations within neuralnetworks as a powerful quantum-inspired technique.</description><author>Ivan Kankeu, Stefan Gerd Fritsch, Gunnar Schönhoff, Elie Mounzer, Paul Lukowicz, Maximilian Kiefer-Emmanouilidis</author><pubDate>Wed, 08 Jan 2025 16:11:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04591v1</guid></item><item><title>LeGrad: An Explainability Method for Vision Transformers via Feature Formation Sensitivity</title><link>http://arxiv.org/abs/2404.03214v2</link><description>Vision Transformers (ViTs), with their ability to model long-rangedependencies through self-attention mechanisms, have become a standardarchitecture in computer vision. However, the interpretability of these modelsremains a challenge. To address this, we propose LeGrad, an explainabilitymethod specifically designed for ViTs. LeGrad computes the gradient withrespect to the attention maps of ViT layers, considering the gradient itself asthe explainability signal. We aggregate the signal over all layers, combiningthe activations of the last as well as intermediate tokens to produce themerged explainability map. This makes LeGrad a conceptually simple and aneasy-to-implement tool for enhancing the transparency of ViTs. We evaluateLeGrad in challenging segmentation, perturbation, and open-vocabulary settings,showcasing its versatility compared to other SotA explainability methodsdemonstrating its superior spatial fidelity and robustness to perturbations. Ademo and the code is available at https://github.com/WalBouss/LeGrad.</description><author>Walid Bousselham, Angie Boggust, Sofian Chaybouti, Hendrik Strobelt, Hilde Kuehne</author><pubDate>Wed, 08 Jan 2025 16:10:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2404.03214v2</guid></item><item><title>Federated-Continual Dynamic Segmentation of Histopathology guided by Barlow Continuity</title><link>http://arxiv.org/abs/2501.04588v1</link><description>Federated- and Continual Learning have been established as approaches toenable privacy-aware learning on continuously changing data, as required fordeploying AI systems in histopathology images. However, data shifts can occurin a dynamic world, spatially between institutions and temporally, due tochanging data over time. This leads to two issues: Client Drift, where thecentral model degrades from aggregating data from clients trained on shifteddata, and Catastrophic Forgetting, from temporal shifts such as changes inpatient populations. Both tend to degrade the model's performance of previouslyseen data or spatially distributed training. Despite both problems arising fromthe same underlying problem of data shifts, existing research addresses themonly individually. In this work, we introduce a method that can jointlyalleviate Client Drift and Catastrophic Forgetting by using our proposedDynamic Barlow Continuity that evaluates client updates on a public referencedataset and uses this to guide the training process to a spatially andtemporally shift-invariant model. We evaluate our approach on thehistopathology datasets BCSS and Semicol and prove our method to be highlyeffective by jointly improving the dice score as much as from 15.8% to 71.6% inClient Drift and from 42.5% to 62.8% in Catastrophic Forgetting. This enablesDynamic Learning by establishing spatio-temporal shift-invariance.</description><author>Niklas Babendererde, Haozhe Zhu, Moritz Fuchs, Jonathan Stieber, Anirban Mukhopadhyay</author><pubDate>Wed, 08 Jan 2025 16:06:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04588v1</guid></item><item><title>Identity-Preserving Video Dubbing Using Motion Warping</title><link>http://arxiv.org/abs/2501.04586v1</link><description>Video dubbing aims to synthesize realistic, lip-synced videos from areference video and a driving audio signal. Although existing methods canaccurately generate mouth shapes driven by audio, they often fail to preserveidentity-specific features, largely because they do not effectively capture thenuanced interplay between audio cues and the visual attributes of referenceidentity . As a result, the generated outputs frequently lack fidelity inreproducing the unique textural and structural details of the referenceidentity. To address these limitations, we propose IPTalker, a novel and robustframework for video dubbing that achieves seamless alignment between drivingaudio and reference identity while ensuring both lip-sync accuracy andhigh-fidelity identity preservation. At the core of IPTalker is atransformer-based alignment mechanism designed to dynamically capture and modelthe correspondence between audio features and reference images, therebyenabling precise, identity-aware audio-visual integration. Building on thisalignment, a motion warping strategy further refines the results by spatiallydeforming reference images to match the target audio-driven configuration. Adedicated refinement process then mitigates occlusion artifacts and enhancesthe preservation of fine-grained textures, such as mouth details and skinfeatures. Extensive qualitative and quantitative evaluations demonstrate thatIPTalker consistently outperforms existing approaches in terms of realism, lipsynchronization, and identity retention, establishing a new state of the artfor high-quality, identity-consistent video dubbing.</description><author>Runzhen Liu, Qinjie Lin, Yunfei Liu, Lijian Lin, Ye Zhu, Yu Li, Chuhua Xian, Fa-Ting Hong</author><pubDate>Wed, 08 Jan 2025 16:06:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04586v1</guid></item><item><title>Accelerated Extragradient-Type Methods -- Part 2: Generalization and Sublinear Convergence Rates under Co-Hypomonotonicity</title><link>http://arxiv.org/abs/2501.04585v1</link><description>Following the first part of our project, this paper comprehensively studiestwo types of extragradient-based methods: anchored extragradient and Nesterov'saccelerated extragradient for solving [non]linear inclusions (and, inparticular, equations), primarily under the Lipschitz continuity and theco-hypomonotonicity assumptions. We unify and generalize a class of anchoredextragradient methods for monotone inclusions to a wider range of schemesencompassing existing algorithms as special cases. We establish$\mathcal{O}(1/k)$ last-iterate convergence rates on the residual norm of theunderlying mapping for this general framework and then specialize it to obtainconvergence guarantees for specific instances, where $k$ denotes the iterationcounter. We extend our approach to a class of anchored Tseng'sforward-backward-forward splitting methods to obtain a broader class ofalgorithms for solving co-hypomonotone inclusions. Again, we analyze$\mathcal{O}(1/k)$ last-iterate convergence rates for this general scheme andspecialize it to obtain convergence results for existing and new variants. Wegeneralize and unify Nesterov's accelerated extra-gradient method to a newclass of algorithms that covers existing schemes as special instances whilegenerating new variants. For these schemes, we can prove $\mathcal{O}(1/k)$last-iterate convergence rates for the residual norm under co-hypomonotonicity,covering a class of nonmonotone problems. We propose another novel class ofNesterov's accelerated extragradient methods to solve inclusions.Interestingly, these algorithms achieve both $\mathcal{O}(1/k)$ and $o(1/k)$last-iterate convergence rates, and also the convergence of iterate sequencesunder co-hypomonotonicity and Lipschitz continuity. Finally, we provide a setof numerical experiments encompassing different scenarios to validate ouralgorithms and theoretical guarantees.</description><author>Quoc Tran-Dinh, Nghia Nguyen-Trung</author><pubDate>Wed, 08 Jan 2025 16:06:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04585v1</guid></item><item><title>Boosting Column Generation with Graph Neural Networks for Joint Rider Trip Planning and Crew Shift Scheduling</title><link>http://arxiv.org/abs/2401.03692v3</link><description>Optimizing service schedules is pivotal to the reliable, efficient, andinclusive on-demand mobility. This pressing challenge is further exacerbated bythe increasing needs of an aging population, the oversubscription of existingservices, and the lack of effective solution methods. This study addresses theintricacies of service scheduling, by jointly optimizing rider trip planningand crew scheduling for a complex dynamic mobility service. The resultingoptimization problems are extremely challenging computationally forstate-of-the-art methods. To address this fundamental gap, this paperintroduces the Joint Rider Trip Planning and Crew Shift Scheduling Problem(JRTPCSSP) and a novel solution method, called Attention and Gated GNN-InformedColumn Generation (AGGNNI-CG), that hybridizes column generation and machinelearning to obtain near-optimal solutions to the JRTPCSSP with real-lifeconstraints of the application. The key idea of the machine-learning componentis to dramatically reduce the number of paths to explore in the pricingproblem, accelerating the most time-consuming component of the columngeneration. The machine learning component is a graph neural network with anattention mechanism and a gated architecture, which is particularly suited tocater for the different input sizes coming from daily operations. AGGNNI-CG hasbeen applied to a challenging, real-world dataset from the Paratransit systemof Chatham County in Georgia. It produces substantial improvements compared tothe baseline column generation approach, which typically cannot producehigh-quality feasible solutions in reasonable time on large-scale complexinstances. AGGNNI-CG also produces significant improvements in service qualitycompared to the existing system.</description><author>Jiawei Lu, Tinghan Ye, Wenbo Chen, Pascal Van Hentenryck</author><pubDate>Wed, 08 Jan 2025 16:05:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.03692v3</guid></item><item><title>Asymptotic Inference for Multi-Stage Stationary Treatment Policy with Variable Selection</title><link>http://arxiv.org/abs/2301.12553v3</link><description>Dynamic treatment regimes or policies are a sequence of decision functionsover multiple stages that are tailored to individual features. One importantclass of treatment policies in practice, namely multi-stage stationarytreatment policies, prescribes treatment assignment probabilities using thesame decision function across stages, where the decision is based on the sameset of features consisting of time-evolving variables (e.g., routinelycollected disease biomarkers). Although there has been extensive literature onconstructing valid inference for the value function associated with dynamictreatment policies, little work has focused on the policies themselves,especially in the presence of high-dimensional feature variables. We aim tofill the gap in this work. Specifically, we first estimate the multi-stagestationary treatment policy using an augmented inverse probability weightedestimator for the value function to increase asymptotic efficiency, and furtherapply a penalty to select important feature variables. We then constructone-step improvements of the policy parameter estimators for valid inference.Theoretically, we show that the improved estimators are asymptotically normal,even if nuisance parameters are estimated at a slow convergence rate and thedimension of the feature variables increases with the sample size. Ournumerical studies demonstrate that the proposed method estimates a sparsepolicy with a near-optimal value function and conducts valid inference for thepolicy parameters.</description><author>Daiqi Gao, Yufeng Liu, Donglin Zeng</author><pubDate>Wed, 08 Jan 2025 16:02:24 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12553v3</guid></item><item><title>Mixture-of-Experts Graph Transformers for Interpretable Particle Collision Detection</title><link>http://arxiv.org/abs/2501.03432v2</link><description>The Large Hadron Collider at CERN produces immense volumes of complex datafrom high-energy particle collisions, demanding sophisticated analyticaltechniques for effective interpretation. Neural Networks, including GraphNeural Networks, have shown promise in tasks such as event classification andobject identification by representing collisions as graphs. However, whileGraph Neural Networks excel in predictive accuracy, their "black box" natureoften limits their interpretability, making it difficult to trust theirdecision-making processes. In this paper, we propose a novel approach thatcombines a Graph Transformer model with Mixture-of-Expert layers to achievehigh predictive performance while embedding interpretability into thearchitecture. By leveraging attention maps and expert specialization, the modeloffers insights into its internal decision-making, linking predictions tophysics-informed features. We evaluate the model on simulated events from theATLAS experiment, focusing on distinguishing rare Supersymmetric signal eventsfrom Standard Model background. Our results highlight that the model achievescompetitive classification accuracy while providing interpretable outputs thatalign with known physics, demonstrating its potential as a robust andtransparent tool for high-energy physics data analysis. This approachunderscores the importance of explainability in machine learning methodsapplied to high energy physics, offering a path toward greater trust inAI-driven discoveries.</description><author>Donatella Genovese, Alessandro Sgroi, Alessio Devoto, Samuel Valentine, Lennox Wood, Cristiano Sebastiani, Stefano Giagu, Monica D'Onofrio, Simone Scardapane</author><pubDate>Wed, 08 Jan 2025 15:57:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.03432v2</guid></item><item><title>Boosting Salient Object Detection with Knowledge Distillated from Large Foundation Models</title><link>http://arxiv.org/abs/2501.04582v1</link><description>Salient Object Detection (SOD) aims to identify and segment prominent regionswithin a scene. Traditional models rely on manually annotated pseudo labelswith precise pixel-level accuracy, which is time-consuming. We developed alow-cost, high-precision annotation method by leveraging large foundationmodels to address the challenges. Specifically, we use a weakly supervisedapproach to guide large models in generating pseudo-labels through textualprompts. Since large models do not effectively focus on the salient regions ofimages, we manually annotate a subset of text to fine-tune the model. Based onthis approach, which enables precise and rapid generation of pseudo-labels, weintroduce a new dataset, BDS-TR. Compared to the previous DUTS-TR dataset,BDS-TR is more prominent in scale and encompasses a wider variety of categoriesand scenes. This expansion will enhance our model's applicability across abroader range of scenarios and provide a more comprehensive foundationaldataset for future SOD research. Additionally, we present an edge decoder basedon dynamic upsampling, which focuses on object edges while gradually recoveringimage feature resolution. Comprehensive experiments on five benchmark datasetsdemonstrate that our method significantly outperforms state-of-the-artapproaches and also surpasses several existing fully-supervised SOD methods.The code and results will be made available.</description><author>Miaoyang He, Shuyong Gao, Tsui Qin Mok, Weifeng Ge, Wengqiang Zhang</author><pubDate>Wed, 08 Jan 2025 15:56:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04582v1</guid></item><item><title>Towards Revisiting Visual Place Recognition for Joining Submaps in Multimap SLAM</title><link>http://arxiv.org/abs/2407.12408v2</link><description>Visual SLAM is a key technology for many autonomous systems. However,tracking loss can lead to the creation of disjoint submaps in multimap SLAMsystems like ORB-SLAM3. Because of that, these systems employ submap mergingstrategies. As we show, these strategies are not always successful. In thispaper, we investigate the impact of using modern VPR approaches for submapmerging in visual SLAM. We argue that classical evaluation metrics are notsufficient to estimate the impact of a modern VPR component on the overallsystem. We show that naively replacing the VPR component does not leverage itsfull potential without requiring substantial interference in the originalsystem. Because of that, we present a post-processing pipeline along with a setof metrics that allow us to estimate the impact of modern VPR components. Weevaluate our approach on the NCLT and Newer College datasets using ORB-SLAM3with NetVLAD and HDC-DELF as VPR components. Additionally, we present a simpleapproach for combining VPR with temporal consistency for map merging. We showthat the map merging performance of ORB-SLAM3 can be improved. Building onthese results, researchers in VPR can assess the potential of their approachesfor SLAM systems.</description><author>Markus Weißflog, Stefan Schubert, Peter Protzel, Peer Neubert</author><pubDate>Wed, 08 Jan 2025 15:54:31 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2407.12408v2</guid></item><item><title>Unified Coding for Both Human Perception and Generalized Machine Analytics with CLIP Supervision</title><link>http://arxiv.org/abs/2501.04579v1</link><description>The image compression model has long struggled with adaptability andgeneralization, as the decoded bitstream typically serves only human or machineneeds and fails to preserve information for unseen visual tasks. Therefore,this paper innovatively introduces supervision obtained from multimodalpre-training models and incorporates adaptive multi-objective optimizationtailored to support both human visual perception and machine visionsimultaneously with a single bitstream, denoted as Unified and GeneralizedImage Coding for Machine (UG-ICM). Specifically, to get rid of the reliancebetween compression models with downstream task supervision, we introduceContrastive Language-Image Pre-training (CLIP) models into the trainingconstraint for improved generalization. Global-to-instance-wise CLIPsupervision is applied to help obtain hierarchical semantics that make modelsmore generalizable for the tasks relying on the information of differentgranularity. Furthermore, for supporting both human and machine visions withonly a unifying bitstream, we incorporate a conditional decoding strategy thattakes as conditions human or machine preferences, enabling the bitstream to bedecoded into different versions for corresponding preferences. As such, ourproposed UG-ICM is fully trained in a self-supervised manner, i.e., withoutawareness of any specific downstream models and tasks. The extensiveexperiments have shown that the proposed UG-ICM is capable of achievingremarkable improvements in various unseen machine analytics tasks, whilesimultaneously providing perceptually satisfying images.</description><author>Kangsheng Yin, Quan Liu, Xuelin Shen, Yulin He, Wenhan Yang, Shiqi Wang</author><pubDate>Wed, 08 Jan 2025 15:48:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04579v1</guid></item><item><title>A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation</title><link>http://arxiv.org/abs/2501.04577v1</link><description>Uncertainty estimation is an indispensable capability for AI-enabled,safety-critical applications, e.g. autonomous vehicles or medical diagnosis.Bayesian neural networks (BNNs) use Bayesian statistics to provide bothclassification predictions and uncertainty estimation, but they suffer fromhigh computational overhead associated with random number generation andrepeated sample iterations. Furthermore, BNNs are not immediately amenable toacceleration through compute-in-memory architectures due to the frequent memorywrites necessary after each RNG operation. To address these challenges, wepresent an ASIC that integrates 360 fJ/Sample Gaussian RNG directly into theSRAM memory words. This integration reduces RNG overhead and enablesfully-parallel compute-in-memory operations for BNNs. The prototype chipachieves 5.12 GSa/s RNG throughput and 102 GOp/s neural network throughputwhile occupying 0.45 mm2, bringing AI uncertainty estimation to edgecomputation.</description><author>Zephan M. Enciso, Boyang Cheng, Likai Pei, Jianbo Liu, Steven Davis, Ningyuan Cao, Michael Niemier</author><pubDate>Wed, 08 Jan 2025 15:47:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04577v1</guid></item><item><title>InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection</title><link>http://arxiv.org/abs/2501.04575v1</link><description>Graphical User Interface (GUI) Agents, powered by multimodal large languagemodels (MLLMs), have shown great potential for task automation on computingdevices such as computers and mobile phones. However, existing agents facechallenges in multi-step reasoning and reliance on textual annotations,limiting their effectiveness. We introduce \textit{InfiGUIAgent}, an MLLM-basedGUI Agent trained with a two-stage supervised fine-tuning pipeline. Stage 1enhances fundamental skills such as GUI understanding and grounding, whileStage 2 integrates hierarchical reasoning and expectation-reflection reasoningskills using synthesized data to enable native reasoning abilities of theagents. \textit{InfiGUIAgent} achieves competitive performance on several GUIbenchmarks, highlighting the impact of native reasoning skills in enhancing GUIinteraction for automation tasks. Resources are available at\url{https://github.com/Reallm-Labs/InfiGUIAgent}.</description><author>Yuhang Liu, Pengxiang Li, Zishu Wei, Congkai Xie, Xueyu Hu, Xinchen Xu, Shengyu Zhang, Xiaotian Han, Hongxia Yang, Fei Wu</author><pubDate>Wed, 08 Jan 2025 15:45:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04575v1</guid></item><item><title>Regret Analysis: a control perspective</title><link>http://arxiv.org/abs/2501.04572v1</link><description>Online learning and model reference adaptive control have many interestingintersections. One area where they differ however is in how the algorithms areanalyzed and what objective or metric is used to discriminate "good" algorithmsfrom "bad" algorithms. In adaptive control there are usually two objectives: 1)prove that all time varying parameters/states of the system are bounded, and 2)that the instantaneous error between the adaptively controlled system and areference system converges to zero over time (or at least a compact set). Foronline learning the performance of algorithms is often characterized by theregret the algorithm incurs. Regret is defined as the cumulative loss (cost)over time from the online algorithm minus the cumulative loss (cost) of thesingle optimal fixed parameter choice in hindsight. Another significantdifference between the two areas of research is with regard to the assumptionsmade in order to obtain said results. Adaptive control makes assumptions aboutthe input-output properties of the control problem and derives solutions for afixed error model or optimization task. In the online learning literatureresults are derived for classes of loss functions (i.e. convex) while a prioriassuming that all time varying parameters are bounded, which for manyoptimization tasks is not unrealistic, but is a non starter in controlapplications. In this work we discuss these differences in detail through theregret based analysis of gradient descent for convex functions and the controlbased analysis of a streaming regression problem. We close with a discussionabout the newly defined paradigm of online adaptive control and ask thefollowing question "Are regret optimal control strategies deployable?"</description><author>Travis E. Gibson, Sawal Acharya</author><pubDate>Wed, 08 Jan 2025 15:42:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04572v1</guid></item><item><title>Offline Reinforcement Learning for Learning to Dispatch for Job Shop Scheduling</title><link>http://arxiv.org/abs/2409.10589v2</link><description>The Job Shop Scheduling Problem (JSSP) is a complex combinatorialoptimization problem. While online Reinforcement Learning (RL) has shownpromise by quickly finding acceptable solutions for JSSP, it faces keylimitations: it requires extensive training interactions from scratch leadingto sample inefficiency, cannot leverage existing high-quality solutions, andoften yields suboptimal results compared to traditional methods like ConstraintProgramming (CP). We introduce Offline Reinforcement Learning for Learning toDispatch (Offline-LD), which addresses these limitations by learning frompreviously generated solutions. Our approach is motivated by scenarios wherehistorical scheduling data and expert solutions are available, although ourcurrent evaluation focuses on benchmark problems. Offline-LD adapts twoCQL-based Q-learning methods (mQRDQN and discrete mSAC) for maskable actionspaces, introduces a novel entropy bonus modification for discrete SAC, andexploits reward normalization through preprocessing. Our experimentsdemonstrate that Offline-LD outperforms online RL on both generated andbenchmark instances. Notably, by introducing noise into the expert dataset, weachieve similar or better results than those obtained from the expert dataset,suggesting that a more diverse training set is preferable because it containscounterfactual information.</description><author>Jesse van Remmerden, Zaharah Bukhsh, Yingqian Zhang</author><pubDate>Wed, 08 Jan 2025 15:41:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.10589v2</guid></item><item><title>Rethinking the Capacity of Graph Neural Networks for Branching Strategy</title><link>http://arxiv.org/abs/2402.07099v3</link><description>Graph neural networks (GNNs) have been widely used to predict properties andheuristics of mixed-integer linear programs (MILPs) and hence accelerate MILPsolvers. This paper investigates the capacity of GNNs to represent strongbranching (SB), the most effective yet computationally expensive heuristicemployed in the branch-and-bound algorithm. In the literature, message-passingGNN (MP-GNN), as the simplest GNN structure, is frequently used as a fastapproximation of SB and we find that not all MILPs's SB can be represented withMP-GNN. We precisely define a class of "MP-tractable" MILPs for which MP-GNNscan accurately approximate SB scores. Particularly, we establish a universalapproximation theorem: for any data distribution over the MP-tractable class,there always exists an MP-GNN that can approximate the SB score witharbitrarily high accuracy and arbitrarily high probability, which lays atheoretical foundation of the existing works on imitating SB with MP-GNN. ForMILPs without the MP-tractability, unfortunately, a similar result isimpossible, which can be illustrated by two MILP instances with different SBscores that cannot be distinguished by any MP-GNN, regardless of the number ofparameters. Recognizing this, we explore another GNN structure called thesecond-order folklore GNN (2-FGNN) that overcomes this limitation, and theaforementioned universal approximation theorem can be extended to the entireMILP space using 2-FGNN, regardless of the MP-tractability. A small-scalenumerical experiment is conducted to directly validate our theoreticalfindings.</description><author>Ziang Chen, Jialin Liu, Xiaohan Chen, Xinshang Wang, Wotao Yin</author><pubDate>Wed, 08 Jan 2025 15:37:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07099v3</guid></item><item><title>Large-Scale Spectral Graph Neural Networks via Laplacian Sparsification: Technical Report</title><link>http://arxiv.org/abs/2501.04570v1</link><description>Graph Neural Networks (GNNs) play a pivotal role in graph-based tasks fortheir proficiency in representation learning. Among the various GNN methods,spectral GNNs employing polynomial filters have shown promising performance ontasks involving both homophilous and heterophilous graph structures. However,The scalability of spectral GNNs on large graphs is limited because they learnthe polynomial coefficients through multiple forward propagation executionsduring forward propagation. Existing works have attempted to scale up spectralGNNs by eliminating the linear layers on the input node features, a change thatcan disrupt end-to-end training, potentially impact performance, and becomeimpractical with high-dimensional input features. To address the abovechallenges, we propose "Spectral Graph Neural Networks with LaplacianSparsification (SGNN-LS)", a novel graph spectral sparsification method toapproximate the propagation patterns of spectral GNNs. We prove that ourproposed method generates Laplacian sparsifiers that can approximate both fixedand learnable polynomial filters with theoretical guarantees. Our method allowsthe application of linear layers on the input node features, enablingend-to-end training as well as the handling of raw text features. We conduct anextensive experimental analysis on datasets spanning various graph scales andproperties to demonstrate the superior efficiency and effectiveness of ourmethod. The results show that our method yields superior results in comparisonwith the corresponding approximated base models, especially on datasetOgbn-papers100M(111M nodes, 1.6B edges) and MAG-scholar-C (2.8M features).</description><author>Haipeng Ding, Zhewei Wei, Yuhang Ye</author><pubDate>Wed, 08 Jan 2025 15:36:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04570v1</guid></item><item><title>Towards Realistic Evaluation of Commit Message Generation by Matching Online and Offline Settings</title><link>http://arxiv.org/abs/2410.12046v2</link><description>When a Commit Message Generation (CMG) system is integrated into the IDEs andother products at JetBrains, we perform online evaluation based on useracceptance of the generated messages. However, performing online experimentswith every change to a CMG system is troublesome, as each iteration affectsusers and requires time to collect enough statistics. On the other hand,offline evaluation, a prevalent approach in the research literature,facilitates fast experiments but employs automatic metrics that are notguaranteed to represent the preferences of real users. In this work, wedescribe a novel way we employed to deal with this problem at JetBrains, byleveraging an online metric - the number of edits users introduce beforecommitting the generated messages to the VCS - to select metrics for offlineexperiments. To support this new type of evaluation, we develop a novel markup collectiontool mimicking the real workflow with a CMG system, collect a dataset with 57pairs consisting of commit messages generated by GPT-4 and their counterpartsedited by human experts, and design and verify a way to synthetically extendsuch a dataset. Then, we use the final dataset of 656 pairs to study how thewidely used similarity metrics correlate with the online metric reflecting thereal users' experience. Our results indicate that edit distance exhibits the highest correlation withthe online metric, whereas commonly used similarity metrics such as BLEU andMETEOR demonstrate low correlation. This contradicts the previous studies onsimilarity metrics for CMG, suggesting that user interactions with a CMG systemin real-world settings differ significantly from the responses by humanlabelers within controlled environments. We release all the code and thedataset to support future research in the field: https://jb.gg/cmg-evaluation.</description><author>Petr Tsvetkov, Aleksandra Eliseeva, Danny Dig, Alexander Bezzubov, Yaroslav Golubev, Timofey Bryksin, Yaroslav Zharov</author><pubDate>Wed, 08 Jan 2025 15:35:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2410.12046v2</guid></item><item><title>PointDreamer: Zero-shot 3D Textured Mesh Reconstruction from Colored Point Cloud</title><link>http://arxiv.org/abs/2406.15811v2</link><description>Reconstructing textured meshes from colored point clouds is an important butchallenging task. Most existing methods yield blurry-looking textures or relyon 3D training data that are hard to acquire. Regarding this, we proposePointDreamer, a novel framework for textured mesh reconstruction from coloredpoint cloud via diffusion-based 2D inpainting. Specifically, we firstreconstruct an untextured mesh. Next, we project the input point cloud into 2Dspace to generate sparse multi-view images, and then inpaint empty pixelsutilizing a pre-trained 2D diffusion model. After that, we unproject the colorsof the inpainted dense images onto the untextured mesh, thus obtaining thefinal textured mesh. This project-inpaint-unproject pipeline bridges the gapbetween 3D point clouds and 2D diffusion models for the first time. Thanks tothe powerful 2D diffusion model pre-trained on extensive 2D data, PointDreamerreconstructs clear, high-quality textures with high robustness to sparse ornoisy input. Also, it's zero-shot requiring no extra training. In addition, wedesign Non-Border-First unprojection strategy to address the border-areainconsistency issue, which is less explored but commonly-occurred in methodsthat generate 3D textures from multiview images. Extensive qualitative andquantitative experiments on various synthetic and real-scanned datasets showthe SoTA performance of PointDreamer, by significantly outperforming baselinemethods with 30% improvement in LPIPS score (from 0.118 to 0.068). Code at:https://github.com/YuQiao0303/PointDreamer.</description><author>Qiao Yu, Xianzhi Li, Yuan Tang, Xu Han, Jinfeng Xu, Long Hu, Min Chen</author><pubDate>Wed, 08 Jan 2025 15:32:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.15811v2</guid></item><item><title>Supervision-free Vision-Language Alignment</title><link>http://arxiv.org/abs/2501.04568v1</link><description>Vision-language models (VLMs) have demonstrated remarkable potential inintegrating visual and linguistic information, but their performance is oftenconstrained by the need for extensive, high-quality image-text training data.Curation of these image-text pairs is both time-consuming and computationallyexpensive. To address this challenge, we introduce SVP (Supervision-free VisualProjection), a novel framework that enhances vision-language alignment withoutrelying on curated data or preference annotation. SVP leverages self-captioningand a pre-trained grounding model as a feedback mechanism to elicit latentinformation in VLMs. We evaluate our approach across six key areas: captioning,referring, visual question answering, multitasking, hallucination control, andobject recall. Results demonstrate significant improvements, including a 14%average improvement in captioning tasks, up to 12% increase in object recall,and substantial reduction in hallucination rates. Notably, a small VLM usingSVP achieves hallucination reductions comparable to a model five times larger,while a VLM with initially poor referring capabilities more than doubles itsperformance, approaching parity with a model twice its size.</description><author>Giorgio Giannone, Ruoteng Li, Qianli Feng, Evgeny Perevodchikov, Rui Chen, Aleix Martinez</author><pubDate>Wed, 08 Jan 2025 15:32:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04568v1</guid></item><item><title>Towards Global AI Inclusivity: A Large-Scale Multilingual Terminology Dataset</title><link>http://arxiv.org/abs/2412.18367v3</link><description>The field of machine translation has achieved significant advancements, yetdomain-specific terminology translation, particularly in AI, remainschallenging. We introduced GIST, a large-scale multilingual AI terminologydataset containing 5K terms extracted from top AI conference papers spanning2000 to 2023. The terms were translated into Arabic, Chinese, French, Japanese,and Russian using a hybrid framework that combines LLMs for extraction withhuman expertise for translation. The dataset's quality was benchmarked againstexisting resources, demonstrating superior translation accuracy throughcrowdsourced evaluation. GIST was integrated into translation workflows usingpost-translation refinement methods that required no retraining, where LLMprompting consistently improved BLEU and COMET scores. A web demonstration onthe ACL Anthology platform highlights its practical application, showcasingimproved accessibility for non-English speakers. This work aims to addresscritical gaps in AI terminology resources and fosters global inclusivity andcollaboration in AI research.</description><author>Jiarui Liu, Iman Ouzzani, Wenkai Li, Lechen Zhang, Tianyue Ou, Houda Bouamor, Zhijing Jin, Mona Diab</author><pubDate>Wed, 08 Jan 2025 15:30:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.18367v3</guid></item><item><title>Deep Multi-Objective Reinforcement Learning for Utility-Based Infrastructural Maintenance Optimization</title><link>http://arxiv.org/abs/2406.06184v2</link><description>In this paper, we introduce Multi-Objective Deep Centralized Multi-AgentActor-Critic (MO- DCMAC), a multi-objective reinforcement learning (MORL)method for infrastructural maintenance optimization, an area traditionallydominated by single-objective reinforcement learning (RL) approaches. Previoussingle-objective RL methods combine multiple objectives, such as probability ofcollapse and cost, into a singular reward signal through reward-shaping. Incontrast, MO-DCMAC can optimize a policy for multiple objectives directly, evenwhen the utility function is non-linear. We evaluated MO-DCMAC using twoutility functions, which use probability of collapse and cost as input. Thefirst utility function is the Threshold utility, in which MO-DCMAC shouldminimize cost so that the probability of collapse is never above the threshold.The second is based on the Failure Mode, Effects, and Criticality Analysis(FMECA) methodology used by asset managers to asses maintenance plans. Weevaluated MO-DCMAC, with both utility functions, in multiple maintenanceenvironments, including ones based on a case study of the historical quay wallsof Amsterdam. The performance of MO-DCMAC was compared against multiplerule-based policies based on heuristics currently used for constructingmaintenance plans. Our results demonstrate that MO-DCMAC outperformstraditional rule-based policies across various environments and utilityfunctions.</description><author>Jesse van Remmerden, Maurice Kenter, Diederik M. Roijers, Charalampos Andriotis, Yingqian Zhang, Zaharah Bukhsh</author><pubDate>Wed, 08 Jan 2025 15:28:11 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2406.06184v2</guid></item><item><title>Learnable Scaled Gradient Descent for Guaranteed Robust Tensor PCA</title><link>http://arxiv.org/abs/2501.04565v1</link><description>Robust tensor principal component analysis (RTPCA) aims to separate thelow-rank and sparse components from multi-dimensional data, making it anessential technique in the signal processing and computer vision fields.Recently emerging tensor singular value decomposition (t-SVD) has gainedconsiderable attention for its ability to better capture the low-rank structureof tensors compared to traditional matrix SVD. However, existing methods oftenrely on the computationally expensive tensor nuclear norm (TNN), which limitstheir scalability for real-world tensors. To address this issue, we explore anefficient scaled gradient descent (SGD) approach within the t-SVD framework forthe first time, and propose the RTPCA-SGD method. Theoretically, we rigorouslyestablish the recovery guarantees of RTPCA-SGD under mild assumptions,demonstrating that with appropriate parameter selection, it achieves linearconvergence to the true low-rank tensor at a constant rate, independent of thecondition number. To enhance its practical applicability, we further propose alearnable self-supervised deep unfolding model, which enables effectiveparameter learning. Numerical experiments on both synthetic and real-worlddatasets demonstrate the superior performance of the proposed methods whilemaintaining competitive computational efficiency, especially consuming lesstime than RTPCA-TNN.</description><author>Lanlan Feng, Ce Zhu, Yipeng Liu, Saiprasad Ravishankar, Longxiu Huang</author><pubDate>Wed, 08 Jan 2025 15:25:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04565v1</guid></item><item><title>Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging</title><link>http://arxiv.org/abs/2402.18205v4</link><description>Logs produced by extensive software systems are integral to monitoring systembehaviors. Advanced log analysis facilitates the detection, alerting, anddiagnosis of system faults. Log parsing, which entails transforming raw logmessages into structured templates, constitutes a critical phase in theautomation of log analytics. Existing log parsers fail to identify the correcttemplates due to reliance on human-made rules. Besides, These methods focus onstatistical features while ignoring semantic information in log messages. Toaddress these challenges, we introduce a cutting-edge \textbf{L}og parsingframework with \textbf{E}ntropy sampling and Chain-of-Thought \textbf{M}erging(Lemur). Specifically, to discard the tedious manual rules. We propose a novelsampling method inspired by information entropy, which efficiently clusterstypical logs. Furthermore, to enhance the merging of log templates, we design achain-of-thought method for large language models (LLMs). LLMs exhibitexceptional semantic comprehension, deftly distinguishing between parametersand invariant tokens. We have conducted experiments on large-scale publicdatasets. Extensive evaluation demonstrates that Lemur achieves thestate-of-the-art performance and impressive efficiency. The Code is availableat https://github.com/zwpride/lemur.</description><author>Wei Zhang, Hongcheng Guo, Anjie Le, Jian Yang, Jiaheng Liu, Zhoujun Li</author><pubDate>Wed, 08 Jan 2025 15:18:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18205v4</guid></item><item><title>OpenOmni: Large Language Models Pivot Zero-shot Omnimodal Alignment across Language with Real-time Self-Aware Emotional Speech Synthesis</title><link>http://arxiv.org/abs/2501.04561v1</link><description>Recent advancements in omnimodal learning have been achieved in understandingand generation across images, text, and speech, though mainly withinproprietary models. Limited omnimodal datasets and the inherent challengesassociated with real-time emotional speech generation have hindered open-sourceprogress. To address these issues, we propose openomni, a two-stage trainingmethod combining omnimodal alignment and speech generation to develop astate-of-the-art omnimodal large language model. In the alignment phase, apre-trained speech model is further trained on text-image tasks to generalizefrom vision to speech in a (near) zero-shot manner, outperforming modelstrained on tri-modal datasets. In the speech generation phase, a lightweightdecoder facilitates real-time emotional speech through training on speech tasksand preference learning. Experiments demonstrate that openomni consistentlyimproves across omnimodal, vision-language, and speech-language evaluations,enabling natural, emotion-rich dialogues and real-time emotional speechgeneration.</description><author>Run Luo, Ting-En Lin, Haonan Zhang, Yuchuan Wu, Xiong Liu, Min Yang, Yongbin Li, Longze Chen, Jiaming Li, Lei Zhang, Yangyi Chen, Hamid Alinejad-Rokny, Fei Huang</author><pubDate>Wed, 08 Jan 2025 15:18:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04561v1</guid></item><item><title>Motion-Zero: Zero-Shot Moving Object Control Framework for Diffusion-Based Video Generation</title><link>http://arxiv.org/abs/2401.10150v4</link><description>Recent large-scale pre-trained diffusion models have demonstrated a powerfulgenerative ability to produce high-quality videos from detailed textdescriptions. However, exerting control over the motion of objects in videosgenerated by any video diffusion model is a challenging problem. In this paper,we propose a novel zero-shot moving object trajectory control framework,Motion-Zero, to enable a bounding-box-trajectories-controlled text-to-videodiffusion model. To this end, an initial noise prior module is designed toprovide a position-based prior to improve the stability of the appearance ofthe moving object and the accuracy of position. In addition, based on theattention map of the U-net, spatial constraints are directly applied to thedenoising process of diffusion models, which further ensures the positional andspatial consistency of moving objects during the inference. Furthermore,temporal consistency is guaranteed with a proposed shift temporal attentionmechanism. Our method can be flexibly applied to various state-of-the-art videodiffusion models without any training process. Extensive experimentsdemonstrate our proposed method can control the motion trajectories of objectsand generate high-quality videos. Our project page ishttps://vpx-ecnu.github.io/MotionZero-website/</description><author>Changgu Chen, Junwei Shu, Gaoqi He, Changbo Wang, Yang Li</author><pubDate>Wed, 08 Jan 2025 15:15:12 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.10150v4</guid></item><item><title>SWEPO: Simultaneous Weighted Preference Optimization for Group Contrastive Alignment</title><link>http://arxiv.org/abs/2412.04628v2</link><description>We introduce Simultaneous Weighted Preference Optimization (SWEPO), a novelextension of Direct Preference Optimization (DPO) designed to accommodatemultiple dynamically chosen positive and negative responses for each query.SWEPO employs a weighted group contrastive loss, assigning weights to responsesbased on their deviation from the mean reward score. This approach effectivelyprioritizes responses that are significantly better or worse than the average,enhancing optimization. Our theoretical analysis demonstrates thatsimultaneously considering multiple preferences reduces alignment bias,resulting in more robust alignment. Additionally, we provide insights into thetraining dynamics of our loss function and a related function, InfoNCA.Empirical validation on the UltraFeedback dataset establishes SWEPO asstate-of-the-art, with superior performance in downstream evaluations using theAlpacaEval dataset.</description><author>Taneesh Gupta, Rahul Madhavan, Xuchao Zhang, Chetan Bansal, Saravan Rajmohan</author><pubDate>Wed, 08 Jan 2025 15:00:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.04628v2</guid></item><item><title>Tougher Text, Smarter Models: Raising the Bar for Adversarial Defence Benchmarks</title><link>http://arxiv.org/abs/2501.02654v2</link><description>Recent advancements in natural language processing have highlighted thevulnerability of deep learning models to adversarial attacks. While variousdefence mechanisms have been proposed, there is a lack of comprehensivebenchmarks that evaluate these defences across diverse datasets, models, andtasks. In this work, we address this gap by presenting an extensive benchmarkfor textual adversarial defence that significantly expands upon previous work.Our benchmark incorporates a wide range of datasets, evaluates state-of-the-artdefence mechanisms, and extends the assessment to include critical tasks suchas single-sentence classification, similarity and paraphrase identification,natural language inference, and commonsense reasoning. This work not onlyserves as a valuable resource for researchers and practitioners in the field ofadversarial robustness but also identifies key areas for future research intextual adversarial defence. By establishing a new standard for benchmarking inthis domain, we aim to accelerate progress towards more robust and reliablenatural language processing systems.</description><author>Yang Wang, Chenghua Lin</author><pubDate>Wed, 08 Jan 2025 14:53:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.02654v2</guid></item><item><title>Medical artificial intelligence toolbox (MAIT): an explainable machine learning framework for binary classification, survival modelling, and regression analyses</title><link>http://arxiv.org/abs/2501.04547v1</link><description>While machine learning offers diverse techniques suitable for exploringvarious medical research questions, a cohesive synergistic framework canfacilitate the integration and understanding of new approaches within unifiedmodel development and interpretation. We therefore introduce the MedicalArtificial Intelligence Toolbox (MAIT), an explainable, open-source Pythonpipeline for developing and evaluating binary classification, regression, andsurvival models on tabular datasets. MAIT addresses key challenges (e.g., highdimensionality, class imbalance, mixed variable types, and missingness) whilepromoting transparency in reporting (TRIPOD+AI compliant). Offering automatedconfigurations for beginners and customizable source code for experts, MAITstreamlines two primary use cases: Discovery (feature importance via unifiedscoring, e.g., SHapley Additive exPlanations - SHAP) and Prediction (modeldevelopment and deployment with optimized solutions). Moreover, MAIT proposesnew techniques including fine-tuning of probability threshold in binaryclassification, translation of cumulative hazard curves to binaryclassification, enhanced visualizations for model interpretation for mixed datatypes, and handling censoring through semi-supervised learning, to adapt to awide set of data constraints and study designs. We provide detailed tutorialson GitHub, using four open-access data sets, to demonstrate how MAIT can beused to improve implementation and interpretation of ML models in medicalresearch.</description><author>Ramtin Zargari Marandi, Anne Svane Frahm, Jens Lundgren, Daniel Dawson Murray, Maja Milojevic</author><pubDate>Wed, 08 Jan 2025 14:51:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04547v1</guid></item><item><title>Evaluating Time Series Foundation Models on Noisy Periodic Time Series</title><link>http://arxiv.org/abs/2501.00889v2</link><description>While recent advancements in foundation models have significantly impactedmachine learning, rigorous tests on the performance of time series foundationmodels (TSFMs) remain largely underexplored. This paper presents an empiricalstudy evaluating the zero-shot, long-horizon forecasting abilities of severalleading TSFMs over two synthetic datasets constituting noisy periodic timeseries. We assess model efficacy across different noise levels, underlyingfrequencies, and sampling rates. As benchmarks for comparison, we choose twostatistical techniques: a Fourier transform (FFT)-based approach and a linearautoregressive (AR) model. Our findings demonstrate that while for time serieswith bounded periods and higher sampling rates, TSFMs can match or outperformthe statistical approaches, their forecasting abilities deteriorate with longerperiods, higher noise levels, lower sampling rates and more complex shapes ofthe time series.</description><author>Syamantak Datta Gupta</author><pubDate>Wed, 08 Jan 2025 14:50:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.00889v2</guid></item><item><title>Cyber-Physical Steganography in Robotic Motion Control</title><link>http://arxiv.org/abs/2501.04541v1</link><description>Steganography, the art of information hiding, has continually evolved acrossvisual, auditory and linguistic domains, adapting to the ceaseless interplaybetween steganographic concealment and steganalytic revelation. This studyseeks to extend the horizons of what constitutes a viable steganographic mediumby introducing a steganographic paradigm in robotic motion control. Based onthe observation of the robot's inherent sensitivity to changes in itsenvironment, we propose a methodology to encode messages as environmentalstimuli influencing the motions of the robotic agent and to decode messagesfrom the resulting motion trajectory. The constraints of maximal robotintegrity and minimal motion deviation are established as fundamentalprinciples underlying secrecy. As a proof of concept, we conduct experiments insimulated environments across various manipulation tasks, incorporating roboticembodiments equipped with generalist multimodal policies.</description><author>Ching-Chun Chang, Yijie Lin, Isao Echizen</author><pubDate>Wed, 08 Jan 2025 14:44:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04541v1</guid></item><item><title>Rad4XCNN: a new agnostic method for post-hoc global explanation of CNN-derived features by means of radiomics</title><link>http://arxiv.org/abs/2405.02334v2</link><description>In recent years, machine learning-based clinical decision support systems(CDSS) have played a key role in the analysis of several medical conditions.Despite their promising capabilities, the lack of transparency in AI modelsposes significant challenges, particularly in medical contexts wherereliability is a mandatory aspect. However, it appears that explainability isinversely proportional to accuracy. For this reason, achieving transparencywithout compromising predictive accuracy remains a key challenge. This paperpresents a novel method, namely Rad4XCNN, to enhance the predictive power ofCNN-derived features with the inherent interpretability of radiomic features.Rad4XCNN diverges from conventional methods based on saliency maps, byassociating intelligible meaning to CNN-derived features by means of Radiomics,offering new perspectives on explanation methods beyond visualization maps.Using a breast cancer classification task as a case study, we evaluatedRad4XCNN on ultrasound imaging datasets, including an online dataset and twoin-house datasets for internal and external validation. Some key results are:i) CNN-derived features guarantee more robust accuracy when compared againstViT-derived and radiomic features; ii) conventional visualization map methodsfor explanation present several pitfalls; iii) Rad4XCNN does not sacrificemodel accuracy for their explainability; iv) Rad4XCNN provides a globalexplanation enabling the physician to extract global insights and findings. Ourmethod can mitigate some concerns related to the explainability-accuracytrade-off. This study highlighted the importance of proposing new methods formodel explanation without affecting their accuracy.</description><author>Francesco Prinzi, Carmelo Militello, Calogero Zarcaro, Tommaso Vincenzo Bartolotta, Salvatore Gaglio, Salvatore Vitabile</author><pubDate>Wed, 08 Jan 2025 14:42:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2405.02334v2</guid></item><item><title>Extending LLMs to New Languages: A Case Study of Llama and Persian Adaptation</title><link>http://arxiv.org/abs/2412.13375v2</link><description>Large language models (LLMs) have made great progress in classification andtext generation tasks. However, they are mainly trained on English data andoften struggle with low-resource languages. In this study, we explore adding anew language, i.e., Persian, to Llama (a model with a limited understanding ofPersian) using parameter-efficient fine-tuning. We employ a multi-stageapproach involving pretraining on monolingual Persian data, aligningrepresentations through bilingual pretraining and instruction datasets, andinstruction-tuning with task-specific datasets. We evaluate the model'sperformance at each stage on generation and classification tasks. Our findingssuggest that incorporating the Persian language, through bilingual dataalignment, can enhance classification accuracy for Persian tasks, with noadverse impact and sometimes even improvements on English tasks. Additionally,the results highlight the model's initial strength as a critical factor whenworking with limited training data, with cross-lingual alignment offeringminimal benefits for the low-resource language. Knowledge transfer from Englishto Persian has a marginal effect, primarily benefiting simple classificationtasks.</description><author>Samin Mahdizadeh Sani, Pouya Sadeghi, Thuy-Trang Vu, Yadollah Yaghoobzadeh, Gholamreza Haffari</author><pubDate>Wed, 08 Jan 2025 14:41:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2412.13375v2</guid></item><item><title>VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM</title><link>http://arxiv.org/abs/2501.00599v2</link><description>Video Large Language Models (Video LLMs) have recently exhibited remarkablecapabilities in general video understanding. However, they mainly focus onholistic comprehension and struggle with capturing fine-grained spatial andtemporal details. Besides, the lack of high-quality object-level videoinstruction data and a comprehensive benchmark further hinders theiradvancements. To tackle these challenges, we introduce the VideoRefer Suite toempower Video LLM for finer-level spatial-temporal video understanding, i.e.,enabling perception and reasoning on any objects throughout the video.Specially, we thoroughly develop VideoRefer Suite across three essentialaspects: dataset, model, and benchmark. Firstly, we introduce a multi-agentdata engine to meticulously curate a large-scale, high-quality object-levelvideo instruction dataset, termed VideoRefer-700K. Next, we present theVideoRefer model, which equips a versatile spatial-temporal object encoder tocapture precise regional and sequential representations. Finally, wemeticulously create a VideoRefer-Bench to comprehensively assess thespatial-temporal understanding capability of a Video LLM, evaluating it acrossvarious aspects. Extensive experiments and analyses demonstrate that ourVideoRefer model not only achieves promising performance on video referringbenchmarks but also facilitates general video understanding capabilities.</description><author>Yuqian Yuan, Hang Zhang, Wentong Li, Zesen Cheng, Boqiang Zhang, Long Li, Xin Li, Deli Zhao, Wenqiao Zhang, Yueting Zhuang, Jianke Zhu, Lidong Bing</author><pubDate>Wed, 08 Jan 2025 14:38:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.00599v2</guid></item><item><title>HypeRL: Parameter-Informed Reinforcement Learning for Parametric PDEs</title><link>http://arxiv.org/abs/2501.04538v1</link><description>In this work, we devise a new, general-purpose reinforcement learningstrategy for the optimal control of parametric partial differential equations(PDEs). Such problems frequently arise in applied sciences and engineering andentail a significant complexity when control and/or state variables aredistributed in high-dimensional space or depend on varying parameters.Traditional numerical methods, relying on either iterative minimizationalgorithms or dynamic programming, while reliable, often become computationallyinfeasible. Indeed, in either way, the optimal control problem must be solvedfor each instance of the parameters, and this is out of reach when dealing withhigh-dimensional time-dependent and parametric PDEs. In this paper, we proposeHypeRL, a deep reinforcement learning (DRL) framework to overcome thelimitations shown by traditional methods. HypeRL aims at approximating theoptimal control policy directly. Specifically, we employ an actor-critic DRLapproach to learn an optimal feedback control strategy that can generalizeacross the range of variation of the parameters. To effectively learn suchoptimal control laws, encoding the parameter information into the DRL policyand value function neural networks (NNs) is essential. To do so, HypeRL usestwo additional NNs, often called hypernetworks, to learn the weights and biasesof the value function and the policy NNs. We validate the proposed approach ontwo PDE-constrained optimal control benchmarks, namely a 1DKuramoto-Sivashinsky equation and a 2D Navier-Stokes equations, by showing thatthe knowledge of the PDE parameters and how this information is encoded, i.e.,via a hypernetwork, is an essential ingredient for learning parameter-dependentcontrol policies that can generalize effectively to unseen scenarios and forimproving the sample efficiency of such policies.</description><author>Nicolò Botteghi, Stefania Fresca, Mengwu Guo, Andrea Manzoni</author><pubDate>Wed, 08 Jan 2025 14:38:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04538v1</guid></item><item><title>Combining YOLO and Visual Rhythm for Vehicle Counting</title><link>http://arxiv.org/abs/2501.04534v1</link><description>Video-based vehicle detection and counting play a critical role in managingtransport infrastructure. Traditional image-based counting methods usuallyinvolve two main steps: initial detection and subsequent tracking, which areapplied to all video frames, leading to a significant increase in computationalcomplexity. To address this issue, this work presents an alternative and moreefficient method for vehicle detection and counting. The proposed approacheliminates the need for a tracking step and focuses solely on detectingvehicles in key video frames, thereby increasing its efficiency. To achievethis, we developed a system that combines YOLO, for vehicle detection, withVisual Rhythm, a way to create time-spatial images that allows us to focus onframes that contain useful information. Additionally, this method can be usedfor counting in any application involving unidirectional moving targets to bedetected and identified. Experimental analysis using real videos shows that theproposed method achieves mean counting accuracy around 99.15% over a set ofvideos, with a processing speed three times faster than tracking basedapproaches.</description><author>Victor Nascimento Ribeiro, Nina S. T. Hirata</author><pubDate>Wed, 08 Jan 2025 14:33:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04534v1</guid></item><item><title>Large Model Based Agents: State-of-the-Art, Cooperation Paradigms, Security and Privacy, and Future Trends</title><link>http://arxiv.org/abs/2409.14457v2</link><description>With the rapid advancement of large models (LMs), the development ofgeneral-purpose intelligent agents powered by LMs has become a reality. It isforeseeable that in the near future, LM-driven general AI agents will serve asessential tools in production tasks, capable of autonomous communication andcollaboration without human intervention. This paper investigates scenariosinvolving the autonomous collaboration of future LM agents. We review thecurrent state of LM agents, the key technologies enabling LM agentcollaboration, and the security and privacy challenges they face duringcooperative operations. To this end, we first explore the foundationalprinciples of LM agents, including their general architecture, key components,enabling technologies, and modern applications. We then discuss practicalcollaboration paradigms from data, computation, and knowledge perspectives toachieve connected intelligence among LM agents. After that, we analyze thesecurity vulnerabilities and privacy risks associated with LM agents,particularly in multi-agent settings, examining underlying mechanisms andreviewing current and potential countermeasures. Lastly, we propose futureresearch directions for building robust and secure LM agent ecosystems.</description><author>Yuntao Wang, Yanghe Pan, Zhou Su, Yi Deng, Quan Zhao, Linkang Du, Tom H. Luan, Jiawen Kang, Dusit Niyato</author><pubDate>Wed, 08 Jan 2025 14:29:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2409.14457v2</guid></item><item><title>Embedding Similarity Guided License Plate Super Resolution</title><link>http://arxiv.org/abs/2501.01483v2</link><description>Super-resolution (SR) techniques play a pivotal role in enhancing the qualityof low-resolution images, particularly for applications such as security andsurveillance, where accurate license plate recognition is crucial. This studyproposes a novel framework that combines pixel-based loss with embeddingsimilarity learning to address the unique challenges of license platesuper-resolution (LPSR). The introduced pixel and embedding consistency loss(PECL) integrates a Siamese network and applies contrastive loss to forceembedding similarities to improve perceptual and structural fidelity. Byeffectively balancing pixel-wise accuracy with embedding-level consistency, theframework achieves superior alignment of fine-grained features betweenhigh-resolution (HR) and super-resolved (SR) license plates. Extensiveexperiments on the CCPD dataset validate the efficacy of the proposedframework, demonstrating consistent improvements over state-of-the-art methodsin terms of PSNR_RGB, PSNR_Y and optical character recognition (OCR) accuracy.These results highlight the potential of embedding similarity learning toadvance both perceptual quality and task-specific performance in extremesuper-resolution scenarios.</description><author>Abderrezzaq Sendjasni, Mohamed-Chaker Larabi</author><pubDate>Wed, 08 Jan 2025 14:29:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.01483v2</guid></item><item><title>The Race to Efficiency: A New Perspective on AI Scaling Laws</title><link>http://arxiv.org/abs/2501.02156v3</link><description>As large-scale AI models expand, training becomes costlier and sustainingprogress grows harder. Classical scaling laws (e.g., Kaplan et al. (2020),Hoffmann et al. (2022)) predict training loss from a static compute budget yetneglect time and efficiency, prompting the question: how can we balanceballooning GPU fleets with rapidly improving hardware and algorithms? Weintroduce the relative-loss equation, a time- and efficiency-aware frameworkthat extends classical AI scaling laws. Our model shows that, without ongoingefficiency gains, advanced performance could demand millennia of training orunrealistically large GPU fleets. However, near-exponential progress remainsachievable if the "efficiency-doubling rate" parallels Moore's Law. Byformalizing this race to efficiency, we offer a quantitative roadmap forbalancing front-loaded GPU investments with incremental improvements across theAI stack. Empirical trends suggest that sustained efficiency gains can push AIscaling well into the coming decade, providing a new perspective on thediminishing returns inherent in classical scaling.</description><author>Chien-Ping Lu</author><pubDate>Wed, 08 Jan 2025 14:26:51 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.02156v3</guid></item><item><title>Human Delegation Behavior in Human-AI Collaboration: The Effect of Contextual Information</title><link>http://arxiv.org/abs/2401.04729v2</link><description>The integration of artificial intelligence (AI) into human decision-makingprocesses at the workplace presents both opportunities and challenges. Onepromising approach to leverage existing complementary capabilities is allowinghumans to delegate individual instances of decision tasks to AI. However,enabling humans to delegate instances effectively requires them to assessseveral factors. One key factor is the analysis of both their own capabilitiesand those of the AI in the context of the given task. In this work, we conducta behavioral study to explore the effects of providing contextual informationto support this delegation decision. Specifically, we investigate howcontextual information about the AI and the task domain influence humans'delegation decisions to an AI and their impact on the human-AI teamperformance. Our findings reveal that access to contextual informationsignificantly improves human-AI team performance in delegation settings.Finally, we show that the delegation behavior changes with the different typesof contextual information. Overall, this research advances the understanding ofcomputer-supported, collaborative work and provides actionable insights fordesigning more effective collaborative systems.</description><author>Philipp Spitzer, Joshua Holstein, Patrick Hemmer, Michael Vössing, Niklas Kühl, Dominik Martin, Gerhard Satzger</author><pubDate>Wed, 08 Jan 2025 14:22:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.04729v2</guid></item><item><title>NeuralDiffuser: Neuroscience-inspired Diffusion Guidance for fMRI Visual Reconstruction</title><link>http://arxiv.org/abs/2402.13809v3</link><description>Reconstructing visual stimuli from functional Magnetic Resonance Imaging fMRIenables fine-grained retrieval of brain activity. However, the accuratereconstruction of diverse details, including structure, background, texture,color, and more, remains challenging. The stable diffusion models inevitablyresult in the variability of reconstructed images, even under identicalconditions. To address this challenge, we first uncover the neuroscientificperspective of diffusion methods, which primarily involve top-down creationusing pre-trained knowledge from extensive image datasets, but tend to lackdetail-driven bottom-up perception, leading to a loss of faithful details. Inthis paper, we propose NeuralDiffuser, which incorporates primary visualfeature guidance to provide detailed cues in the form of gradients. Thisextension of the bottom-up process for diffusion models achieves both semanticcoherence and detail fidelity when reconstructing visual stimuli. Furthermore,we have developed a novel guidance strategy for reconstruction tasks thatensures the consistency of repeated outputs with original images rather thanwith various outputs. Extensive experimental results on the Natural SensesDataset (NSD) qualitatively and quantitatively demonstrate the advancement ofNeuralDiffuser by comparing it against baseline and state-of-the-art methodshorizontally, as well as conducting longitudinal ablation studies.</description><author>Haoyu Li, Hao Wu, Badong Chen</author><pubDate>Wed, 08 Jan 2025 14:21:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13809v3</guid></item><item><title>A Plug-and-Play Bregman ADMM Module for Inferring Event Branches in Temporal Point Processes</title><link>http://arxiv.org/abs/2501.04529v1</link><description>An event sequence generated by a temporal point process is often associatedwith a hidden and structured event branching process that captures thetriggering relations between its historical and current events. In this study,we design a new plug-and-play module based on the Bregman ADMM (BADMM)algorithm, which infers event branches associated with event sequences in themaximum likelihood estimation framework of temporal point processes (TPPs).Specifically, we formulate the inference of event branches as an optimizationproblem for the event transition matrix under sparse and low-rank constraints,which is embedded in existing TPP models or their learning paradigms. We canimplement this optimization problem based on subspace clustering and sparsegroup-lasso, respectively, and solve it using the Bregman ADMM algorithm, whoseunrolling leads to the proposed BADMM module. When learning a classic TPP(e.g., Hawkes process) by the expectation-maximization algorithm, the BADMMmodule helps derive structured responsibility matrices in the E-step.Similarly, the BADMM module helps derive low-rank and sparse attention maps forthe neural TPPs with self-attention layers. The structured responsibilitymatrices and attention maps, which work as learned event transition matrices,indicate event branches, e.g., inferring isolated events and those key eventstriggering many subsequent events. Experiments on both synthetic and real-worlddata show that plugging our BADMM module into existing TPP models and learningparadigms can improve model performance and provide us with interpretablestructured event branches. The code is available at\url{https://github.com/qingmeiwangdaily/BADMM_TPP}.</description><author>Qingmei Wang, Yuxin Wu, Yujie Long, Jing Huang, Fengyuan Ran, Bing Su, Hongteng Xu</author><pubDate>Wed, 08 Jan 2025 14:21:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04529v1</guid></item><item><title>Towards a Problem-Oriented Domain Adaptation Framework for Machine Learning</title><link>http://arxiv.org/abs/2501.04528v1</link><description>Domain adaptation is a sub-field of machine learning that involvestransferring knowledge from a source domain to perform the same task in thetarget domain. It is a typical challenge in machine learning that arises, e.g.,when data is obtained from various sources or when using a data basis thatchanges over time. Recent advances in the field offer promising methods, but itis still challenging for researchers and practitioners to determine if domainadaptation is suitable for a given problem -- and, subsequently, to select theappropriate approach. This article employs design science research to develop aproblem-oriented framework for domain adaptation, which is matured in threeevaluation episodes. We describe a framework that distinguishes between fivedomain adaptation scenarios, provides recommendations for addressing eachscenario, and offers guidelines for determining if a problem falls into one ofthese scenarios. During the multiple evaluation episodes, the framework istested on artificial and real-world datasets and an experimental studyinvolving 100 participants. The evaluation demonstrates that the framework hasthe explanatory power to capture any domain adaptation problem effectively. Insummary, we provide clear guidance for researchers and practitioners who wantto employ domain adaptation but lack in-depth knowledge of the possibilities.</description><author>Philipp Spitzer, Dominik Martin, Laurin Eichberger, Niklas Kühl</author><pubDate>Wed, 08 Jan 2025 14:19:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04528v1</guid></item><item><title>Towards Fair Class-wise Robustness: Class Optimal Distribution Adversarial Training</title><link>http://arxiv.org/abs/2501.04527v1</link><description>Adversarial training has proven to be a highly effective method for improvingthe robustness of deep neural networks against adversarial attacks.Nonetheless, it has been observed to exhibit a limitation in terms of robustfairness, characterized by a significant disparity in robustness acrossdifferent classes. Recent efforts to mitigate this problem have turned toclass-wise reweighted methods. However, these methods suffer from a lack ofrigorous theoretical analysis and are limited in their exploration of theweight space, as they mainly rely on existing heuristic algorithms or intuitionto compute weights. In addition, these methods fail to guarantee theconsistency of the optimization direction due to the decoupled optimization ofweights and the model parameters. They potentially lead to suboptimal weightassignments and consequently, a suboptimal model. To address these problems,this paper proposes a novel min-max training framework, Class OptimalDistribution Adversarial Training (CODAT), which employs distributionallyrobust optimization to fully explore the class-wise weight space, thus enablingthe identification of the optimal weight with theoretical guarantees.Furthermore, we derive a closed-form optimal solution to the internalmaximization and then get a deterministic equivalent objective function, whichprovides a theoretical basis for the joint optimization of weights and modelparameters. Meanwhile, we propose a fairness elasticity coefficient for theevaluation of the algorithm with regard to both robustness and robust fairness.Experimental results on various datasets show that the proposed method caneffectively improve the robust fairness of the model and outperform thestate-of-the-art approaches.</description><author>Hongxin Zhi, Hongtao Yu, Shaome Li, Xiuming Zhao, Yiteng Wu</author><pubDate>Wed, 08 Jan 2025 14:19:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2501.04527v1</guid></item></channel></rss>