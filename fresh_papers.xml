<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Arxivfresh papers</title><link></link><description>Arxiv paper</description><language>en-US</language><lastBuildDate>Mon, 04 Mar 2024 14:00:03 GMT</lastBuildDate><generator>rfeed v1.0.0</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>$\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation</title><link>http://arxiv.org/abs/2402.19457v2</link><description>Assessing the quality of summarizers poses significant challenges. Inresponse, we propose a novel task-oriented evaluation approach that assessessummarizers based on their capacity to produce summaries that are useful fordownstream tasks, while preserving task outcomes. We theoretically establish adirect relationship between the resulting error probability of these tasks andthe mutual information between source texts and generated summaries. Weintroduce $\texttt{COSMIC}$ as a practical implementation of this metric,demonstrating its strong correlation with human judgment-based metrics and itseffectiveness in predicting downstream task performance. Comparative analysesagainst established metrics like $\texttt{BERTScore}$ and $\texttt{ROUGE}$highlight the competitive performance of $\texttt{COSMIC}$.</description><author>Maxime Darrin, Philippe Formont, Jackie Chi Kit Cheung, Pablo Piantanida</author><pubDate>Fri, 01 Mar 2024 15:29:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19457v2</guid></item><item><title>MATHWELL: Generating Educational Math Word Problems at Scale</title><link>http://arxiv.org/abs/2402.15861v3</link><description>Math word problems are critical K-8 educational tools, but writing them istime-consuming and requires domain expertise. We suggest that language modelscan support K-8 math education by automatically generating problems at scale.To be educational, generated problems must be 1) solvable, 2) accurate, and 3)appropriate. Existing datasets are unlabeled for these criteria, making themill-suited for training problem generators. We introduce MATHWELL, a Llama-2(70B) model iteratively finetuned to generate K-8 math word problems using datafrom expert annotation. Using MATHWELL, we generate the largest English wordproblem dataset with Program of Thought (PoT) rationales to date, containing20,490 problems. 3,484 are scored by domain experts who find MATHWELL has a 40%higher share of problems that have executable solutions and meet all criteriathan alternatives, with 74% of its problems with executable solutions beingsolvable, accurate, and appropriate. We release our model, data, andannotations.</description><author>Bryan R Christ, Jonathan Kropko, Thomas Hartvigsen</author><pubDate>Fri, 01 Mar 2024 14:39:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15861v3</guid></item><item><title>Physics-Informed Machine Learning for Seismic Response Prediction OF Nonlinear Steel Moment Resisting Frame Structures</title><link>http://arxiv.org/abs/2402.17992v2</link><description>There is a growing interest in utilizing machine learning (ML) methods forstructural metamodeling due to the substantial computational cost oftraditional numerical simulations. The existing data-driven strategies showpotential limitations to the model robustness and interpretability as well asthe dependency of rich data. To address these challenges, this paper presents anovel physics-informed machine learning (PiML) method, which incorporatesscientific principles and physical laws into deep neural networks for modelingseismic responses of nonlinear structures. The basic concept is to constrainthe solution space of the ML model within known physical bounds. This is madepossible with three main features, namely, model order reduction, a longshort-term memory (LSTM) networks, and Newton's second law (e.g., the equationof motion). Model order reduction is essential for handling structural systemswith inherent redundancy and enhancing model efficiency. The LSTM networkcaptures temporal dependencies, enabling accurate prediction of time seriesresponses. The equation of motion is manipulated to learn system nonlinearitiesand confines the solution space within physically interpretable results. Thesefeatures enable model training with relatively sparse data and offer benefitsin terms of accuracy, interpretability, and robustness. Furthermore, a datasetof seismically designed archetype ductile planar steel moment resistant framesunder horizontal seismic loading, available in the DesignSafe-CI Database, isconsidered for evaluation of the proposed method. The resulting metamodel iscapable of handling more complex data compared to existing physics-guided LSTMmodels and outperforms other non-physics data-driven neural networks.</description><author>R. Bailey Bond, Pu Ren, Jerome F. Hajjar, Hao Sun</author><pubDate>Fri, 01 Mar 2024 14:09:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17992v2</guid></item><item><title>Credal Learning Theory</title><link>http://arxiv.org/abs/2402.00957v2</link><description>Statistical learning theory is the foundation of machine learning, providingtheoretical bounds for the risk of models learnt from a (single) training set,assumed to issue from an unknown probability distribution. In actualdeployment, however, the data distribution may (and often does) vary, causingdomain adaptation/generalization issues. In this paper we lay the foundationsfor a `credal' theory of learning, using convex sets of probabilities (credalsets) to model the variability in the data-generating distribution. Such credalsets, we argue, may be inferred from a finite sample of training sets. Boundsare derived for the case of finite hypotheses spaces (both assumingrealizability or not) as well as infinite model spaces, which directlygeneralize classical results.</description><author>Michele Caprio, Maryam Sultana, Eleni Elia, Fabio Cuzzolin</author><pubDate>Fri, 01 Mar 2024 14:07:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.00957v2</guid></item><item><title>Federated Domain Generalization: A Survey</title><link>http://arxiv.org/abs/2306.01334v2</link><description>Machine learning typically relies on the assumption that training and testingdistributions are identical and that data is centrally stored for training andtesting. However, in real-world scenarios, distributions may differsignificantly and data is often distributed across different devices,organizations, or edge nodes. Consequently, it is imperative to develop modelsthat can effectively generalize to unseen distributions where data isdistributed across different domains. In response to this challenge, there hasbeen a surge of interest in federated domain generalization (FDG) in recentyears. FDG combines the strengths of federated learning (FL) and domaingeneralization (DG) techniques to enable multiple source domains tocollaboratively learn a model capable of directly generalizing to unseendomains while preserving data privacy. However, generalizing the federatedmodel under domain shifts is a technically challenging problem that hasreceived scant attention in the research area so far. This paper presents thefirst survey of recent advances in this area. Initially, we discuss thedevelopment process from traditional machine learning to domain adaptation anddomain generalization, leading to FDG as well as provide the correspondingformal definition. Then, we categorize recent methodologies into four classes:federated domain alignment, data manipulation, learning strategies, andaggregation optimization, and present suitable algorithms in detail for eachcategory. Next, we introduce commonly used datasets, applications, evaluations,and benchmarks. Finally, we conclude this survey by providing some potentialresearch topics for the future.</description><author>Ying Li, Xingwei Wang, Rongfei Zeng, Praveen Kumar Donta, Ilir Murturi, Min Huang, Schahram Dustdar</author><pubDate>Fri, 01 Mar 2024 14:05:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.01334v2</guid></item><item><title>Few-Shot Panoptic Segmentation With Foundation Models</title><link>http://arxiv.org/abs/2309.10726v3</link><description>Current state-of-the-art methods for panoptic segmentation require an immenseamount of annotated training data that is both arduous and expensive to obtainposing a significant challenge for their widespread adoption. Concurrently,recent breakthroughs in visual representation learning have sparked a paradigmshift leading to the advent of large foundation models that can be trained withcompletely unlabeled images. In this work, we propose to leverage suchtask-agnostic image features to enable few-shot panoptic segmentation bypresenting Segmenting Panoptic Information with Nearly 0 labels (SPINO). Indetail, our method combines a DINOv2 backbone with lightweight network headsfor semantic segmentation and boundary estimation. We show that our approach,albeit being trained with only ten annotated images, predicts high-qualitypseudo-labels that can be used with any existing panoptic segmentation method.Notably, we demonstrate that SPINO achieves competitive results compared tofully supervised baselines while using less than 0.3% of the ground truthlabels, paving the way for learning complex visual recognition tasks leveragingfoundation models. To illustrate its general applicability, we further deploySPINO on real-world robotic vision systems for both outdoor and indoorenvironments. To foster future research, we make the code and trained modelspublicly available at http://spino.cs.uni-freiburg.de.</description><author>Markus Käppeler, Kürsat Petek, Niclas Vödisch, Wolfram Burgard, Abhinav Valada</author><pubDate>Fri, 01 Mar 2024 13:48:34 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.10726v3</guid></item><item><title>BenchCloudVision: A Benchmark Analysis of Deep Learning Approaches for Cloud Detection and Segmentation in Remote Sensing Imagery</title><link>http://arxiv.org/abs/2402.13918v3</link><description>Satellites equipped with optical sensors capture high-resolution imagery,providing valuable insights into various environmental phenomena. In recentyears, there has been a surge of research focused on addressing some challengesin remote sensing, ranging from water detection in diverse landscapes to thesegmentation of mountainous and terrains. Ongoing investigations goals toenhance the precision and efficiency of satellite imagery analysis. Especially,there is a growing emphasis on developing methodologies for accurate water bodydetection, snow and clouds, important for environmental monitoring, resourcemanagement, and disaster response. Within this context, this paper focus on thecloud segmentation from remote sensing imagery. Accurate remote sensing dataanalysis can be challenging due to the presence of clouds in opticalsensor-based applications. The quality of resulting products such asapplications and research is directly impacted by cloud detection, which playsa key role in the remote sensing data processing pipeline. This paper examinesseven cutting-edge semantic segmentation and detection algorithms applied toclouds identification, conducting a benchmark analysis to evaluate theirarchitectural approaches and identify the most performing ones. To increase themodel's adaptability, critical elements including the type of imagery and theamount of spectral bands used during training are analyzed. Additionally, thisresearch tries to produce machine learning algorithms that can perform cloudsegmentation using only a few spectral bands, including RGB and RGBN-IRcombinations. The model's flexibility for a variety of applications and userscenarios is assessed by using imagery from Sentinel-2 and Landsat-8 asdatasets. This benchmark can be reproduced using the material from this githublink: https://github.com/toelt-llc/cloud_segmentation_comparative.</description><author>Loddo Fabio, Dario Piga, Michelucci Umberto, El Ghazouali Safouane</author><pubDate>Fri, 01 Mar 2024 13:39:07 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13918v3</guid></item><item><title>GAMMA: Generalizable Articulation Modeling and Manipulation for Articulated Objects</title><link>http://arxiv.org/abs/2309.16264v3</link><description>Articulated objects like cabinets and doors are widespread in daily life.However, directly manipulating 3D articulated objects is challenging becausethey have diverse geometrical shapes, semantic categories, and kineticconstraints. Prior works mostly focused on recognizing and manipulatingarticulated objects with specific joint types. They can either estimate thejoint parameters or distinguish suitable grasp poses to facilitate trajectoryplanning. Although these approaches have succeeded in certain types ofarticulated objects, they lack generalizability to unseen objects, whichsignificantly impedes their application in broader scenarios. In this paper, wepropose a novel framework of Generalizable Articulation Modeling andManipulating for Articulated Objects (GAMMA), which learns both articulationmodeling and grasp pose affordance from diverse articulated objects withdifferent categories. In addition, GAMMA adopts adaptive manipulation toiteratively reduce the modeling errors and enhance manipulation performance. Wetrain GAMMA with the PartNet-Mobility dataset and evaluate with comprehensiveexperiments in SAPIEN simulation and real-world Franka robot. Results show thatGAMMA significantly outperforms SOTA articulation modeling and manipulationalgorithms in unseen and cross-category articulated objects. We willopen-source all codes and datasets in both simulation and real robots forreproduction in the final version. Images and videos are published on theproject website at: http://sites.google.com/view/gamma-articulation</description><author>Qiaojun Yu, Junbo Wang, Wenhai Liu, Ce Hao, Liu Liu, Lin Shao, Weiming Wang, Cewu Lu</author><pubDate>Fri, 01 Mar 2024 13:29:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.16264v3</guid></item><item><title>RORA: Robust Free-Text Rationale Evaluation</title><link>http://arxiv.org/abs/2402.18678v2</link><description>Free-text rationales play a pivotal role in explainable NLP, bridging theknowledge and reasoning gaps behind a model's decision-making. However, due tothe diversity of potential reasoning paths and a corresponding lack ofdefinitive ground truth, their evaluation remains a challenge. Existingevaluation metrics rely on the degree to which a rationale supports a targetlabel, but we find these fall short in evaluating rationales that inadvertentlyleak the labels. To address this problem, we propose RORA, a Robust free-textRationale evaluation against label leakage. RORA quantifies the new informationsupplied by a rationale to justify the label. This is achieved by assessing theconditional V-information \citep{hewitt-etal-2021-conditional} with apredictive family robust against leaky features that can be exploited by asmall model. RORA consistently outperforms existing approaches in evaluatinghuman-written, synthetic, or model-generated rationales, particularlydemonstrating robustness against label leakage. We also show that RORA alignswell with human judgment, providing a more reliable and accurate measurementacross diverse free-text rationales.</description><author>Zhengping Jiang, Yining Lu, Hanjie Chen, Daniel Khashabi, Benjamin Van Durme, Anqi Liu</author><pubDate>Fri, 01 Mar 2024 13:26:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18678v2</guid></item><item><title>ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled neural networks</title><link>http://arxiv.org/abs/2210.00108v4</link><description>Early backdoor attacks against machine learning set off an arms race inattack and defence development. Defences have since appeared demonstrating someability to detect backdoors in models or even remove them. These defences workby inspecting the training data, the model, or the integrity of the trainingprocedure. In this work, we show that backdoors can be added duringcompilation, circumventing any safeguards in the data preparation and modeltraining stages. The attacker can not only insert existing weight-basedbackdoors during compilation, but also a new class of weight-independentbackdoors, such as ImpNet. These backdoors are impossible to detect during thetraining or data preparation processes, because they are not yet present. Next,we demonstrate that some backdoors, including ImpNet, can only be reliablydetected at the stage where they are inserted and removing them anywhere elsepresents a significant challenge. We conclude that ML model security requiresassurance of provenance along the entire technical pipeline, including thedata, model architecture, compiler, and hardware specification.</description><author>Tim Clifford, Ilia Shumailov, Yiren Zhao, Ross Anderson, Robert Mullins</author><pubDate>Fri, 01 Mar 2024 13:17:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2210.00108v4</guid></item><item><title>The Risks of Recourse in Binary Classification</title><link>http://arxiv.org/abs/2306.00497v2</link><description>Algorithmic recourse provides explanations that help users overturn anunfavorable decision by a machine learning system. But so far very littleattention has been paid to whether providing recourse is beneficial or not. Weintroduce an abstract learning-theoretic framework that compares the risks(i.e., expected losses) for classification with and without algorithmicrecourse. This allows us to answer the question of when providing recourse isbeneficial or harmful at the population level. Surprisingly, we find that thereare many plausible scenarios in which providing recourse turns out to beharmful, because it pushes users to regions of higher class uncertainty andtherefore leads to more mistakes. We further study whether the party deployingthe classifier has an incentive to strategize in anticipation of having toprovide recourse, and we find that sometimes they do, to the detriment of theirusers. Providing algorithmic recourse may therefore also be harmful at thesystemic level. We confirm our theoretical findings in experiments on simulatedand real-world data. All in all, we conclude that the current concept ofalgorithmic recourse is not reliably beneficial, and therefore requiresrethinking.</description><author>Hidde Fokkema, Damien Garreau, Tim van Erven</author><pubDate>Fri, 01 Mar 2024 13:15:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.00497v2</guid></item><item><title>Adversarial Examples are Misaligned in Diffusion Model Manifolds</title><link>http://arxiv.org/abs/2401.06637v4</link><description>In recent years, diffusion models (DMs) have drawn significant attention fortheir success in approximating data distributions, yielding state-of-the-artgenerative results. Nevertheless, the versatility of these models extendsbeyond their generative capabilities to encompass various vision applications,such as image inpainting, segmentation, adversarial robustness, among others.This study is dedicated to the investigation of adversarial attacks through thelens of diffusion models. However, our objective does not involve enhancing theadversarial robustness of image classifiers. Instead, our focus lies inutilizing the diffusion model to detect and analyze the anomalies introduced bythese attacks on images. To that end, we systematically examine the alignmentof the distributions of adversarial examples when subjected to the process oftransformation using diffusion models. The efficacy of this approach isassessed across CIFAR-10 and ImageNet datasets, including varying image sizesin the latter. The results demonstrate a notable capacity to discriminateeffectively between benign and attacked images, providing compelling evidencethat adversarial instances do not align with the learned manifold of the DMs.</description><author>Peter Lorenz, Ricard Durall, Janis Keuper</author><pubDate>Fri, 01 Mar 2024 13:02:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.06637v4</guid></item><item><title>High-Speed Detector For Low-Powered Devices In Aerial Grasping</title><link>http://arxiv.org/abs/2402.14591v2</link><description>Autonomous aerial harvesting is a highly complex problem because it requiresnumerous interdisciplinary algorithms to be executed on mini low-poweredcomputing devices. Object detection is one such algorithm that iscompute-hungry. In this context, we make the following contributions: (i) FastFruit Detector (FFD), a resource-efficient, single-stage, andpostprocessing-free object detector based on our novel latent objectrepresentation (LOR) module, query assignment, and prediction strategy. FFDachieves 100FPS@FP32 precision on the latest 10W NVIDIA Jetson-NX embeddeddevice while co-existing with other time-critical sub-systems such as control,grasping, SLAM, a major achievement of this work. (ii) a method to generatevast amounts of training data without exhaustive manual labelling of fruitimages since they consist of a large number of instances, which increases thelabelling cost and time. (iii) an open-source fruit detection dataset havingplenty of very small-sized instances that are difficult to detect. Ourexhaustive evaluations on our and MinneApple dataset show that FFD, being onlya single-scale detector, is more accurate than many representative detectors,e.g. FFD is better than single-scale Faster-RCNN by 10.7AP, multi-scaleFaster-RCNN by 2.3AP, and better than latest single-scale YOLO-v8 by 8AP andmulti-scale YOLO-v8 by 0.3 while being considerably faster.</description><author>Ashish Kumar, Laxmidhar Behera</author><pubDate>Fri, 01 Mar 2024 12:58:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14591v2</guid></item><item><title>Unfolding Local Growth Rate Estimates for (Almost) Perfect Adversarial Detection</title><link>http://arxiv.org/abs/2212.06776v5</link><description>Convolutional neural networks (CNN) define the state-of-the-art solution onmany perceptual tasks. However, current CNN approaches largely remainvulnerable against adversarial perturbations of the input that have beencrafted specifically to fool the system while being quasi-imperceptible to thehuman eye. In recent years, various approaches have been proposed to defendCNNs against such attacks, for example by model hardening or by adding explicitdefence mechanisms. Thereby, a small "detector" is included in the network andtrained on the binary classification task of distinguishing genuine data fromdata containing adversarial perturbations. In this work, we propose a simpleand light-weight detector, which leverages recent findings on the relationbetween networks' local intrinsic dimensionality (LID) and adversarial attacks.Based on a re-interpretation of the LID measure and several simple adaptations,we surpass the state-of-the-art on adversarial detection by a significantmargin and reach almost perfect results in terms of F1-score for severalnetworks and datasets. Sources available at:https://github.com/adverML/multiLID</description><author>Peter Lorenz, Margret Keuper, Janis Keuper</author><pubDate>Fri, 01 Mar 2024 12:38:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2212.06776v5</guid></item><item><title>Multi-FAct: Assessing Multilingual LLMs' Multi-Regional Knowledge using FActScore</title><link>http://arxiv.org/abs/2402.18045v2</link><description>Large Language Models (LLMs) are prone to factuality hallucination,generating text that contradicts established knowledge. While extensiveresearch has addressed this in English, little is known about multilingualLLMs. This paper systematically evaluates multilingual LLMs' factual accuracyacross languages and geographic regions. We introduce a novel pipeline formultilingual factuality evaluation, adapting FActScore(Min et al., 2023) fordiverse languages. Our analysis across nine languages reveals that Englishconsistently outperforms others in factual accuracy and quantity of generatedfacts. Furthermore, multilingual models demonstrate a bias towards factualinformation from Western continents. These findings highlight the need forimproved multilingual factuality assessment and underscore geographical biasesin LLMs' fact generation.</description><author>Sheikh Shafayat, Eunsu Kim, Juhyun Oh, Alice Oh</author><pubDate>Fri, 01 Mar 2024 12:35:55 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18045v2</guid></item><item><title>Killer Apps: Low-Speed, Large-Scale AI Weapons</title><link>http://arxiv.org/abs/2402.01663v3</link><description>The accelerating advancements in Artificial Intelligence (AI) and MachineLearning (ML), highlighted by the development of cutting-edge GenerativePre-trained Transformer (GPT) models by organizations such as OpenAI, Meta, andAnthropic, present new challenges and opportunities in warfare and security.Much of the current focus is on AI's integration within weapons systems and itsrole in rapid decision-making in kinetic conflict. However, an equallyimportant but often overlooked aspect is the potential of AI-basedpsychological manipulation at internet scales within the information domain.These capabilities could pose significant threats to individuals,organizations, and societies globally. This paper explores the concept of AIweapons, their deployment, detection, and potential countermeasures.</description><author>Philip Feldman, Aaron Dant, James R. Foulds</author><pubDate>Fri, 01 Mar 2024 12:34:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01663v3</guid></item><item><title>Search to Fine-tune Pre-trained Graph Neural Networks for Graph-level Tasks</title><link>http://arxiv.org/abs/2308.06960v2</link><description>Recently, graph neural networks (GNNs) have shown its unprecedented successin many graph-related tasks. However, GNNs face the label scarcity issue asother neural networks do. Thus, recent efforts try to pre-train GNNs on alarge-scale unlabeled graph and adapt the knowledge from the unlabeled graph tothe target downstream task. The adaptation is generally achieved by fine-tuningthe pre-trained GNNs with a limited number of labeled data. Despite theimportance of fine-tuning, current GNNs pre-training works often ignoredesigning a good fine-tuning strategy to better leverage transferred knowledgeand improve the performance on downstream tasks. Only few works start toinvestigate a better fine-tuning strategy for pre-trained GNNs. But theirdesigns either have strong assumptions or overlook the data-aware issue forvarious downstream datasets. Therefore, we aim to design a better fine-tuningstrategy for pre-trained GNNs to improve the model performance in this paper.Given a pre-trained GNN, we propose to search to fine-tune pre-trained graphneural networks for graph-level tasks (S2PGNN), which adaptively design asuitable fine-tuning framework for the given labeled data on the downstreamtask. To ensure the improvement brought by searching fine-tuning strategy, wecarefully summarize a proper search space of fine-tuning framework that issuitable for GNNs. The empirical studies show that S2PGNN can be implemented onthe top of 10 famous pre-trained GNNs and consistently improve theirperformance. Besides, S2PGNN achieves better performance than existingfine-tuning strategies within and outside the GNN area. Our code is publiclyavailable at \url{https://anonymous.4open.science/r/code_icde2024-A9CB/}.</description><author>Zhili Wang, Shimin Di, Lei Chen, Xiaofang Zhou</author><pubDate>Fri, 01 Mar 2024 11:52:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.06960v2</guid></item><item><title>Prompting Explicit and Implicit Knowledge for Multi-hop Question Answering Based on Human Reading Process</title><link>http://arxiv.org/abs/2402.19350v2</link><description>Pre-trained language models (PLMs) leverage chains-of-thought (CoT) tosimulate human reasoning and inference processes, achieving proficientperformance in multi-hop QA. However, a gap persists between PLMs' reasoningabilities and those of humans when tackling complex problems. Psychologicalstudies suggest a vital connection between explicit information in passages andhuman prior knowledge during reading. Nevertheless, current research has giveninsufficient attention to linking input passages and PLMs' pre-training-basedknowledge from the perspective of human cognition studies. In this study, weintroduce a Prompting Explicit and Implicit knowledge (PEI) framework, whichuses prompts to connect explicit and implicit knowledge, aligning with humanreading process for multi-hop QA. We consider the input passages as explicitknowledge, employing them to elicit implicit knowledge through unified promptreasoning. Furthermore, our model incorporates type-specific reasoning viaprompts, a form of implicit knowledge. Experimental results show that PEIperforms comparably to the state-of-the-art on HotpotQA. Ablation studiesconfirm the efficacy of our model in bridging and integrating explicit andimplicit knowledge.</description><author>Guangming Huang, Yunfei Long, Cunjin Luo, Jiaxing Shen, Xia Sun</author><pubDate>Fri, 01 Mar 2024 11:48:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19350v2</guid></item><item><title>Protect and Extend -- Using GANs for Synthetic Data Generation of Time-Series Medical Records</title><link>http://arxiv.org/abs/2402.14042v2</link><description>Preservation of private user data is of paramount importance for high Qualityof Experience (QoE) and acceptability, particularly with services treatingsensitive data, such as IT-based health services. Whereas anonymizationtechniques were shown to be prone to data re-identification, synthetic datageneration has gradually replaced anonymization since it is relatively lesstime and resource-consuming and more robust to data leakage. GenerativeAdversarial Networks (GANs) have been used for generating synthetic datasets,especially GAN frameworks adhering to the differential privacy phenomena. Thisresearch compares state-of-the-art GAN-based models for synthetic datageneration to generate time-series synthetic medical records of dementiapatients which can be distributed without privacy concerns. Predictivemodeling, autocorrelation, and distribution analysis are used to assess theQuality of Generating (QoG) of the generated data. The privacy preservation ofthe respective models is assessed by applying membership inference attacks todetermine potential data leakage risks. Our experiments indicate thesuperiority of the privacy-preserving GAN (PPGAN) model over other modelsregarding privacy preservation while maintaining an acceptable level of QoG.The presented results can support better data protection for medical use casesin the future.</description><author>Navid Ashrafi, Vera Schmitt, Robert P. Spang, Sebastian Möller, Jan-Niklas Voigt-Antons</author><pubDate>Fri, 01 Mar 2024 11:46:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14042v2</guid></item><item><title>DAE-Talker: High Fidelity Speech-Driven Talking Face Generation with Diffusion Autoencoder</title><link>http://arxiv.org/abs/2303.17550v5</link><description>While recent research has made significant progress in speech-driven talkingface generation, the quality of the generated video still lags behind that ofreal recordings. One reason for this is the use of handcrafted intermediaterepresentations like facial landmarks and 3DMM coefficients, which are designedbased on human knowledge and are insufficient to precisely describe facialmovements. Additionally, these methods require an external pretrained model forextracting these representations, whose performance sets an upper bound ontalking face generation. To address these limitations, we propose a novelmethod called DAE-Talker that leverages data-driven latent representationsobtained from a diffusion autoencoder (DAE). DAE contains an image encoder thatencodes an image into a latent vector and a DDIM image decoder thatreconstructs the image from it. We train our DAE on talking face video framesand then extract their latent representations as the training target for aConformer-based speech2latent model. This allows DAE-Talker to synthesize fullvideo frames and produce natural head movements that align with the content ofspeech, rather than relying on a predetermined head pose from a template video.We also introduce pose modelling in speech2latent for pose controllability.Additionally, we propose a novel method for generating continuous video frameswith the DDIM image decoder trained on individual frames, eliminating the needfor modelling the joint distribution of consecutive frames directly. Ourexperiments show that DAE-Talker outperforms existing popular methods inlip-sync, video fidelity, and pose naturalness. We also conduct ablationstudies to analyze the effectiveness of the proposed techniques and demonstratethe pose controllability of DAE-Talker.</description><author>Chenpeng Du, Qi Chen, Xie Chen, Kai Yu</author><pubDate>Fri, 01 Mar 2024 11:43:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.17550v5</guid></item><item><title>EVE: Efficient Vision-Language Pre-training with Masked Prediction and Modality-Aware MoE</title><link>http://arxiv.org/abs/2308.11971v2</link><description>Building scalable vision-language models to learn from diverse, multimodaldata remains an open challenge. In this paper, we introduce an EfficientVision-languagE foundation model, namely EVE, which is one unified multimodalTransformer pre-trained solely by one unified pre-training task. Specifically,EVE encodes both vision and language within a shared Transformer networkintegrated with modality-aware sparse Mixture-of-Experts (MoE) modules, whichcapture modality-specific information by selectively switching to differentexperts. To unify pre-training tasks of vision and language, EVE performsmasked signal modeling on image-text pairs to reconstruct masked signals, i.e.,image pixels and text tokens, given visible signals. This simple yet effectivepre-training objective accelerates training by 3.5x compared to the modelpre-trained with Image-Text Contrastive and Image-Text Matching losses. Owingto the combination of the unified architecture and pre-training task, EVE iseasy to scale up, enabling better downstream performance with fewer resourcesand faster training speed. Despite its simplicity, EVE achievesstate-of-the-art performance on various vision-language downstream tasks,including visual question answering, visual reasoning, and image-textretrieval.</description><author>Junyi Chen, Longteng Guo, Jia Sun, Shuai Shao, Zehuan Yuan, Liang Lin, Dongyu Zhang</author><pubDate>Fri, 01 Mar 2024 11:22:54 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.11971v2</guid></item><item><title>Incentive Compatibility for AI Alignment in Sociotechnical Systems: Positions and Prospects</title><link>http://arxiv.org/abs/2402.12907v2</link><description>The burgeoning integration of artificial intelligence (AI) into human societybrings forth significant implications for societal governance and safety. Whileconsiderable strides have been made in addressing AI alignment challenges,existing methodologies primarily focus on technical facets, often neglectingthe intricate sociotechnical nature of AI systems, which can lead to amisalignment between the development and deployment contexts. To this end, weposit a new problem worth exploring: Incentive Compatibility SociotechnicalAlignment Problem (ICSAP). We hope this can call for more researchers toexplore how to leverage the principles of Incentive Compatibility (IC) fromgame theory to bridge the gap between technical and societal components tomaintain AI consensus with human societies in different contexts. We furtherdiscuss three classical game problems for achieving IC: mechanism design,contract theory, and Bayesian persuasion, in addressing the perspectives,potentials, and challenges of solving ICSAP, and provide preliminaryimplementation conceptions.</description><author>Zhaowei Zhang, Fengshuo Bai, Mingzhi Wang, Haoyang Ye, Chengdong Ma, Yaodong Yang</author><pubDate>Fri, 01 Mar 2024 11:18:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.12907v2</guid></item><item><title>Out-of-Distribution Detection using Neural Activation Prior</title><link>http://arxiv.org/abs/2402.18162v2</link><description>Out-of-distribution detection is a crucial technique for deploying machinelearning models in the real world to handle the unseen scenarios. In thispaper, we propose a simple but effective Neural Activation Prior (NAP) forout-of-distribution detection (OOD). Our neural activation prior is based on akey observation that, for a channel before the global pooling layer of a fullytrained neural network, the probability of a few of its neurons being activatedwith a larger response by an in-distribution (ID) sample is significantlyhigher than that by an OOD sample. An intuitive explanation is each channel ina model fully trained on ID dataset would play a role in detecting a certainpattern in the samples within the ID dataset, and a few neurons can beactivated with a large response when the pattern is detected in an inputsample. Thus, a new scoring function based on this prior is proposed tohighlight the role of these strongly activated neurons in OOD detection. Thisapproach is plug-and-play and does not lead to any performance degradation onin-distribution data classification and requires no extra training orstatistics from training or external datasets. Notice that previous methodsprimarily rely on post-global-pooling features of the neural networks, whilethe within-channel distribution information we leverage would be discarded bythe global pooling operator. Consequently, our method is orthogonal to existingapproaches and can be effectively combined with them in various applications.Experimental results show that our method achieves the state-of-the-artperformance on CIFAR-10, CIFAR-100 and ImageNet datasets, which demonstratesthe power of the proposed prior.</description><author>Weilin Wan, Weizhong Zhang, Cheng Jin</author><pubDate>Fri, 01 Mar 2024 11:15:46 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18162v2</guid></item><item><title>Imagine, Initialize, and Explore: An Effective Exploration Method in Multi-Agent Reinforcement Learning</title><link>http://arxiv.org/abs/2402.17978v2</link><description>Effective exploration is crucial to discovering optimal strategies formulti-agent reinforcement learning (MARL) in complex coordination tasks.Existing methods mainly utilize intrinsic rewards to enable committedexploration or use role-based learning for decomposing joint action spacesinstead of directly conducting a collective search in the entireaction-observation space. However, they often face challenges obtainingspecific joint action sequences to reach successful states in long-horizontasks. To address this limitation, we propose Imagine, Initialize, and Explore(IIE), a novel method that offers a promising solution for efficientmulti-agent exploration in complex scenarios. IIE employs a transformer modelto imagine how the agents reach a critical state that can influence eachother's transition functions. Then, we initialize the environment at this stateusing a simulator before the exploration phase. We formulate the imagination asa sequence modeling problem, where the states, observations, prompts, actions,and rewards are predicted autoregressively. The prompt consists oftimestep-to-go, return-to-go, influence value, and one-shot demonstration,specifying the desired state and trajectory as well as guiding the actiongeneration. By initializing agents at the critical states, IIE significantlyincreases the likelihood of discovering potentially important under-exploredregions. Despite its simplicity, empirical results demonstrate that our methodoutperforms multi-agent exploration baselines on the StarCraft Multi-AgentChallenge (SMAC) and SMACv2 environments. Particularly, IIE shows improvedperformance in the sparse-reward SMAC tasks and produces more effectivecurricula over the initialized states than other generative methods, such asCVAE-GAN and diffusion models.</description><author>Zeyang Liu, Lipeng Wan, Xinrui Yang, Zhuoran Chen, Xingyu Chen, Xuguang Lan</author><pubDate>Fri, 01 Mar 2024 11:08:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17978v2</guid></item><item><title>Optimal Budgeted Rejection Sampling for Generative Models</title><link>http://arxiv.org/abs/2311.00460v2</link><description>Rejection sampling methods have recently been proposed to improve theperformance of discriminator-based generative models. However, these methodsare only optimal under an unlimited sampling budget, and are usually applied toa generator trained independently of the rejection procedure. We first proposean Optimal Budgeted Rejection Sampling (OBRS) scheme that is provably optimalwith respect to \textit{any} $f$-divergence between the true distribution andthe post-rejection distribution, for a given sampling budget. Second, wepropose an end-to-end method that incorporates the sampling scheme into thetraining procedure to further enhance the model's overall performance. Throughexperiments and supporting theory, we show that the proposed methods areeffective in significantly improving the quality and diversity of the samples.</description><author>Alexandre Verine, Muni Sreenivas Pydi, Benjamin Negrevergne, Yann Chevaleyre</author><pubDate>Fri, 01 Mar 2024 10:56:19 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.00460v2</guid></item><item><title>SegReg: Segmenting OARs by Registering MR Images and CT Annotations</title><link>http://arxiv.org/abs/2311.06956v3</link><description>Organ at risk (OAR) segmentation is a critical process in radiotherapytreatment planning such as head and neck tumors. Nevertheless, in clinicalpractice, radiation oncologists predominantly perform OAR segmentationsmanually on CT scans. This manual process is highly time-consuming andexpensive, limiting the number of patients who can receive timely radiotherapy.Additionally, CT scans offer lower soft-tissue contrast compared to MRI.Despite MRI providing superior soft-tissue visualization, its time-consumingnature makes it infeasible for real-time treatment planning. To address thesechallenges, we propose a method called SegReg, which utilizes Elastic SymmetricNormalization for registering MRI to perform OAR segmentation. SegRegoutperforms the CT-only baseline by 16.78% in mDSC and 18.77% in mIoU, showingthat it effectively combines the geometric accuracy of CT with the superiorsoft-tissue contrast of MRI, making accurate automated OAR segmentation forclinical practice become possible. See project websitehttps://steve-zeyu-zhang.github.io/SegReg</description><author>Zeyu Zhang, Xuyin Qi, Bowen Zhang, Biao Wu, Hien Le, Bora Jeong, Zhibin Liao, Yunxiang Liu, Johan Verjans, Minh-Son To, Richard Hartley</author><pubDate>Fri, 01 Mar 2024 10:55:32 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.06956v3</guid></item><item><title>Implicit regularization of deep residual networks towards neural ODEs</title><link>http://arxiv.org/abs/2309.01213v2</link><description>Residual neural networks are state-of-the-art deep learning models. Theircontinuous-depth analog, neural ordinary differential equations (ODEs), arealso widely used. Despite their success, the link between the discrete andcontinuous models still lacks a solid mathematical foundation. In this article,we take a step in this direction by establishing an implicit regularization ofdeep residual networks towards neural ODEs, for nonlinear networks trained withgradient flow. We prove that if the network is initialized as a discretizationof a neural ODE, then such a discretization holds throughout training. Ourresults are valid for a finite training time, and also as the training timetends to infinity provided that the network satisfies a Polyak-Lojasiewiczcondition. Importantly, this condition holds for a family of residual networkswhere the residuals are two-layer perceptrons with an overparameterization inwidth that is only linear, and implies the convergence of gradient flow to aglobal minimum. Numerical experiments illustrate our results.</description><author>Pierre Marion, Yu-Han Wu, Michael E. Sander, Gérard Biau</author><pubDate>Fri, 01 Mar 2024 10:54:13 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.01213v2</guid></item><item><title>Recursive Chain-of-Feedback Prevents Performance Degradation from Redundant Prompting</title><link>http://arxiv.org/abs/2402.02648v2</link><description>Large Language Models (LLMs) frequently struggle with complex reasoningtasks, failing to construct logically sound steps towards the solution. Inresponse to this behavior, users often try prompting the LLMs repeatedly inhopes of reaching a better response. This paper studies such repetitivebehavior and its effect by defining a novel setting, Chain-of-Feedback (CoF).The setting takes questions that require multi-step reasoning as an input. Uponresponse, we repetitively prompt meaningless feedback (e.g. 'make anotherattempt') requesting additional trials. Surprisingly, our preliminary resultsshow that repeated meaningless feedback gradually decreases the quality of theresponses, eventually leading to a larger deviation from the intended outcome.To alleviate these troubles, we propose a novel method, RecursiveChain-of-Feedback (R-CoF). Following the logic of recursion in computerscience, R-CoF recursively revises the initially incorrect response by breakingdown each incorrect reasoning step into smaller individual problems. Ourpreliminary results show that majority of questions that LLMs fail to respondcorrectly can be answered using R-CoF without any sample data outlining thelogical process.</description><author>Jinwoo Ahn, Kyuseung Shin</author><pubDate>Fri, 01 Mar 2024 10:46:01 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.02648v2</guid></item><item><title>Speaker attribution in German parliamentary debates with QLoRA-adapted large language models</title><link>http://arxiv.org/abs/2309.09902v2</link><description>The growing body of political texts opens up new opportunities for richinsights into political dynamics and ideologies but also increases the workloadfor manual analysis. Automated speaker attribution, which detects who said whatto whom in a speech event and is closely related to semantic role labeling, isan important processing step for computational text analysis. We study thepotential of the large language model family Llama 2 to automate speakerattribution in German parliamentary debates from 2017-2021. We fine-tune Llama2 with QLoRA, an efficient training strategy, and observe our approach toachieve competitive performance in the GermEval 2023 Shared Task On SpeakerAttribution in German News Articles and Parliamentary Debates. Our results shedlight on the capabilities of large language models in automating speakerattribution, revealing a promising avenue for computational analysis ofpolitical discourse and the development of semantic role labeling systems.</description><author>Tobias Bornheim, Niklas Grieger, Patrick Gustav Blaneck, Stephan Bialonski</author><pubDate>Fri, 01 Mar 2024 10:39:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.09902v2</guid></item><item><title>Interpretable Feature Learning in Multivariate Big Data Analysis for Network Monitoring</title><link>http://arxiv.org/abs/1907.02677v3</link><description>There is an increasing interest in the development of new data-driven modelsuseful to assess the performance of communication networks. For manyapplications, like network monitoring and troubleshooting, a data model is oflittle use if it cannot be interpreted by a human operator. In this paper, wepresent an extension of the Multivariate Big Data Analysis (MBDA) methodology,a recently proposed interpretable data analysis tool. In this extension, wepropose a solution to the automatic derivation of features, a cornerstone stepfor the application of MBDA when the amount of data is massive. The resultingnetwork monitoring approach allows us to detect and diagnose disparate networkanomalies, with a data-analysis workflow that combines the advantages ofinterpretable and interactive models with the power of parallel processing. Weapply the extended MBDA to two case studies: UGR'16, a benchmark flow-basedreal-traffic dataset for anomaly detection, and Dartmouth'18, the longest andlargest Wi-Fi trace known to date.</description><author>José Camacho, Katarzyna Wasielewska, Rasmus Bro, David Kotz</author><pubDate>Fri, 01 Mar 2024 10:28:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1907.02677v3</guid></item><item><title>Hard Regularization to Prevent Deep Online Clustering Collapse without Data Augmentation</title><link>http://arxiv.org/abs/2303.16521v3</link><description>Online deep clustering refers to the joint use of a feature extractionnetwork and a clustering model to assign cluster labels to each new data pointor batch as it is processed. While faster and more versatile than offlinemethods, online clustering can easily reach the collapsed solution where theencoder maps all inputs to the same point and all are put into a singlecluster. Successful existing models have employed various techniques to avoidthis problem, most of which require data augmentation or which aim to make theaverage soft assignment across the dataset the same for each cluster. Wepropose a method that does not require data augmentation, and that, differentlyfrom existing methods, regularizes the hard assignments. Using a Bayesianframework, we derive an intuitive optimization objective that can bestraightforwardly included in the training of the encoder network. Tested onfour image datasets and one human-activity recognition dataset, it consistentlyavoids collapse more robustly than other methods and leads to more accurateclustering. We also conduct further experiments and analyses justifying ourchoice to regularize the hard cluster assignments. Code is available athttps://github.com/Lou1sM/online_hard_clustering.</description><author>Louis Mahon, Thomas Lukasiewicz</author><pubDate>Fri, 01 Mar 2024 10:22:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.16521v3</guid></item><item><title>Leveraging Gradients for Unsupervised Accuracy Estimation under Distribution Shift</title><link>http://arxiv.org/abs/2401.08909v2</link><description>Estimating test accuracy without access to the ground-truth test labels undervarying test environments is a challenging, yet extremely important problem inthe safe deployment of machine learning algorithms. Existing works rely on theinformation from either the outputs or the extracted features of neuralnetworks to formulate an estimation score correlating with the ground-truthtest accuracy. In this paper, we investigate--both empirically andtheoretically--how the information provided by the gradients can be predictiveof the ground-truth test accuracy even under a distribution shift.Specifically, we use the norm of classification-layer gradients, backpropagatedfrom the cross-entropy loss after only one gradient step over test data. Ourkey idea is that the model should be adjusted with a higher magnitude ofgradients when it does not generalize to the test dataset with a distributionshift. We provide theoretical insights highlighting the main ingredients ofsuch an approach ensuring its empirical success. Extensive experimentsconducted on diverse distribution shifts and model structures demonstrate thatour method significantly outperforms state-of-the-art algorithms.</description><author>Renchunzi Xie, Ambroise Odonnat, Vasilii Feofanov, Ievgen Redko, Jianfeng Zhang, Bo An</author><pubDate>Fri, 01 Mar 2024 10:21:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.08909v2</guid></item><item><title>Zero-Shot Aerial Object Detection with Visual Description Regularization</title><link>http://arxiv.org/abs/2402.18233v2</link><description>Existing object detection models are mainly trained on large-scale labeleddatasets. However, annotating data for novel aerial object classes is expensivesince it is time-consuming and may require expert knowledge. Thus, it isdesirable to study label-efficient object detection methods on aerial images.In this work, we propose a zero-shot method for aerial object detection namedvisual Description Regularization, or DescReg. Concretely, we identify the weaksemantic-visual correlation of the aerial objects and aim to address thechallenge with prior descriptions of their visual appearance. Instead ofdirectly encoding the descriptions into class embedding space which suffersfrom the representation gap problem, we propose to infuse the prior inter-classvisual similarity conveyed in the descriptions into the embedding learning. Theinfusion process is accomplished with a newly designed similarity-aware tripletloss which incorporates structured regularization on the representation space.We conduct extensive experiments with three challenging aerial object detectiondatasets, including DIOR, xView, and DOTA. The results demonstrate that DescRegsignificantly outperforms the state-of-the-art ZSD methods with complexprojection designs and generative frameworks, e.g., DescReg outperforms bestreported ZSD method on DIOR by 4.5 mAP on unseen classes and 8.1 in HM. Wefurther show the generalizability of DescReg by integrating it into generativeZSD methods as well as varying the detection architecture.</description><author>Zhengqing Zang, Chenyu Lin, Chenwei Tang, Tao Wang, Jiancheng Lv</author><pubDate>Fri, 01 Mar 2024 10:07:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18233v2</guid></item><item><title>Finetuning Large Language Models for Vulnerability Detection</title><link>http://arxiv.org/abs/2401.17010v4</link><description>This paper presents the results of finetuning large language models (LLMs)for the task of detecting vulnerabilities in source code. We leverageWizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, andadapt it for vulnerability detection through further finetuning. To acceleratetraining, we modify WizardCoder's training procedure, also we investigateoptimal training regimes. For the imbalanced dataset with many more negativeexamples than positive, we also explore different techniques to improveclassification performance. The finetuned WizardCoder model achievesimprovement in ROC AUC and F1 measures on balanced and imbalanced vulnerabilitydatasets over CodeBERT-like model, demonstrating the effectiveness of adaptingpretrained LLMs for vulnerability detection in source code. The keycontributions are finetuning the state-of-the-art code LLM, WizardCoder,increasing its training speed without the performance harm, optimizing thetraining procedure and regimes, handling class imbalance, and improvingperformance on difficult vulnerability detection datasets. This demonstratesthe potential for transfer learning by finetuning large pretrained languagemodels for specialized source code analysis tasks.</description><author>Alexey Shestov, Rodion Levichev, Ravil Mussabayev, Evgeny Maslov, Anton Cheshkov, Pavel Zadorozhny</author><pubDate>Fri, 01 Mar 2024 09:53:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.17010v4</guid></item><item><title>How to validate average calibration for machine learning regression tasks ?</title><link>http://arxiv.org/abs/2402.10043v2</link><description>Average calibration of the uncertainties of machine learning regression taskscan be tested in two ways. One way is to estimate the calibration error (CE) asthe difference between the mean absolute error (MSE) and the mean variance (MV)or mean squared uncertainty. The alternative is to compare the mean squaredz-scores or scaled errors (ZMS) to 1. Both approaches might lead to differentconclusion, as illustrated on an ensemble of datasets from the recent machinelearning uncertainty quantification literature. It is shown here that the CE isvery sensitive to the distribution of uncertainties, and notably to thepresence of outlying uncertainties, and that it cannot be used reliably forcalibration testing. By contrast, the ZMS statistic does not present thissensitivity issue and offers the most reliable approach in this context.Implications for the validation of conditional calibration are discussed.</description><author>Pascal Pernot</author><pubDate>Fri, 01 Mar 2024 09:34:00 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.10043v2</guid></item><item><title>Towards an end-to-end artificial intelligence driven global weather forecasting system</title><link>http://arxiv.org/abs/2312.12462v2</link><description>The weather forecasting system is important for science and society, andsignificant achievements have been made in applying artificial intelligence(AI) to medium-range weather forecasting. However, existing AI-based weatherforecasting models rely on analysis or reanalysis products from the traditionalnumerical weather prediction (NWP) systems as initial conditions for makingpredictions. Initial states are typically generated by traditional dataassimilation component, which is computational expensive and time-consuming.Here we present an AI-based data assimilation model, i.e., Adas, for globalweather variables. And we combine Adas with the advanced AI-based weatherforecasting model (i.e., FengWu) to construct the first end-to-end AI-basedglobal weather forecasting system: FengWu-Adas. We demonstrate that Adas canassimilate sparse global observations to produce high-quality analysis,enabling the system operate stably for long term. Moreover, we are the first toapply the propose methods to real-world scenarios, which is more challengingand has considerable practical application potential.</description><author>Kun Chen, Lei Bai, Fenghua Ling, Peng Ye, Tao Chen, Jing-Jia Luo, Hao Chen, Kang Chen, Tao Han, Wanli Ouyang</author><pubDate>Fri, 01 Mar 2024 09:13:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.12462v2</guid></item><item><title>PEM: Prototype-based Efficient MaskFormer for Image Segmentation</title><link>http://arxiv.org/abs/2402.19422v2</link><description>Recent transformer-based architectures have shown impressive results in thefield of image segmentation. Thanks to their flexibility, they obtainoutstanding performance in multiple segmentation tasks, such as semantic andpanoptic, under a single unified framework. To achieve such impressiveperformance, these architectures employ intensive operations and requiresubstantial computational resources, which are often not available, especiallyon edge devices. To fill this gap, we propose Prototype-based EfficientMaskFormer (PEM), an efficient transformer-based architecture that can operatein multiple segmentation tasks. PEM proposes a novel prototype-basedcross-attention which leverages the redundancy of visual features to restrictthe computation and improve the efficiency without harming the performance. Inaddition, PEM introduces an efficient multi-scale feature pyramid network,capable of extracting features that have high semantic content in an efficientway, thanks to the combination of deformable convolutions and context-basedself-modulation. We benchmark the proposed PEM architecture on two tasks,semantic and panoptic segmentation, evaluated on two different datasets,Cityscapes and ADE20K. PEM demonstrates outstanding performance on every taskand dataset, outperforming task-specific architectures while being comparableand even better than computationally-expensive baselines.</description><author>Niccolò Cavagnero, Gabriele Rosi, Claudia Cuttano, Francesca Pistilli, Marco Ciccone, Giuseppe Averta, Fabio Cermelli</author><pubDate>Fri, 01 Mar 2024 09:10:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19422v2</guid></item><item><title>The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations</title><link>http://arxiv.org/abs/2401.13662v2</link><description>In recent years, various powerful policy gradient algorithms have beenproposed in deep reinforcement learning. While all these algorithms build onthe Policy Gradient Theorem, the specific design choices differ significantlyacross algorithms. We provide a holistic overview of on-policy policy gradientalgorithms to facilitate the understanding of both their theoreticalfoundations and their practical implementations. In this overview, we include adetailed proof of the continuous version of the Policy Gradient Theorem,convergence results and a comprehensive discussion of practical algorithms. Wecompare the most prominent algorithms on continuous control environments andprovide insights on the benefits of regularization. All code is available athttps://github.com/Matt00n/PolicyGradientsJax.</description><author>Matthias Lehmann</author><pubDate>Fri, 01 Mar 2024 08:58:05 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.13662v2</guid></item><item><title>Graph Convolutional Neural Networks for Automated Echocardiography View Recognition: A Holistic Approach</title><link>http://arxiv.org/abs/2402.19062v2</link><description>To facilitate diagnosis on cardiac ultrasound (US), clinical practice hasestablished several standard views of the heart, which serve as referencepoints for diagnostic measurements and define viewports from which images areacquired. Automatic view recognition involves grouping those images intoclasses of standard views. Although deep learning techniques have beensuccessful in achieving this, they still struggle with fully verifying thesuitability of an image for specific measurements due to factors like thecorrect location, pose, and potential occlusions of cardiac structures. Ourapproach goes beyond view classification and incorporates a 3D meshreconstruction of the heart that enables several more downstream tasks, likesegmentation and pose estimation. In this work, we explore learning 3D heartmeshes via graph convolutions, using similar techniques to learn 3D meshes innatural images, such as human pose estimation. As the availability of fullyannotated 3D images is limited, we generate synthetic US images from 3D meshesby training an adversarial denoising diffusion model. Experiments wereconducted on synthetic and clinical cases for view recognition and structuredetection. The approach yielded good performance on synthetic images and,despite being exclusively trained on synthetic data, it already showedpotential when applied to clinical images. With this proof-of-concept, we aimto demonstrate the benefits of graphs to improve cardiac view recognition thatcan ultimately lead to better efficiency in cardiac diagnosis.</description><author>Sarina Thomas, Cristiana Tiago, Børge Solli Andreassen, Svein Arne Aase, Jurica Šprem, Erik Steen, Anne Solberg, Guy Ben-Yosef</author><pubDate>Fri, 01 Mar 2024 08:54:53 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19062v2</guid></item><item><title>Distributed Influence-Augmented Local Simulators for Parallel MARL in Large Networked Systems</title><link>http://arxiv.org/abs/2207.00288v2</link><description>Due to its high sample complexity, simulation is, as of today, critical forthe successful application of reinforcement learning. Many real-world problems,however, exhibit overly complex dynamics, which makes their full-scalesimulation computationally slow. In this paper, we show how to decompose largenetworked systems of many agents into multiple local components such that wecan build separate simulators that run independently and in parallel. Tomonitor the influence that the different local components exert on one another,each of these simulators is equipped with a learned model that is periodicallytrained on real trajectories. Our empirical results reveal that distributingthe simulation among different processes not only makes it possible to trainlarge multi-agent systems in just a few hours but also helps mitigate thenegative effects of simultaneous learning.</description><author>Miguel Suau, Jinke He, Mustafa Mert Çelikok, Matthijs T. J. Spaan, Frans A. Oliehoek</author><pubDate>Fri, 01 Mar 2024 08:36:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2207.00288v2</guid></item><item><title>Neeko: Leveraging Dynamic LoRA for Efficient Multi-Character Role-Playing Agent</title><link>http://arxiv.org/abs/2402.13717v2</link><description>Large Language Models (LLMs) have revolutionized open-domain dialogue agentsbut encounter challenges in multi-character role-playing (MCRP) scenarios. Toaddress the issue, we present Neeko, an innovative framework designed forefficient multiple characters imitation. Unlike existing methods, Neeko employsa dynamic low-rank adapter (LoRA) strategy, enabling it to adapt seamlessly todiverse characters. Our framework breaks down the role-playing process intoagent pre-training, multiple characters playing, and character incrementallearning, effectively handling both seen and unseen roles. This dynamicapproach, coupled with distinct LoRA blocks for each character, enhancesNeeko's adaptability to unique attributes, personalities, and speakingpatterns. As a result, Neeko demonstrates superior performance in MCRP overmost existing methods, offering more engaging and versatile user interactionexperiences. Code and data are available athttps://github.com/weiyifan1023/Neeko.</description><author>Xiaoyan Yu, Tongxu Luo, Yifan Wei, Fangyu Lei, Yiming Huang, Hao Peng, Liehuang Zhu</author><pubDate>Fri, 01 Mar 2024 08:20:48 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13717v2</guid></item><item><title>Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use</title><link>http://arxiv.org/abs/2312.04455v3</link><description>In this paper, we demonstrate that an inherent waveform pattern in theattention allocation of large language models (LLMs) significantly affectstheir performance in tasks demanding a high degree of context awareness, suchas utilizing LLMs for tool-use. Specifically, the crucial information in thecontext will be potentially overlooked by model when it is positioned in thetrough zone of the attention waveform, leading to decreased performance. Toaddress this issue, we propose a novel inference method named AttentionBuckets. It allows LLMs to process their input through multiple parallelprocesses. Each process utilizes a distinct base angle for the rotary positionembedding, thereby creating a unique attention waveform. By compensating anattention trough of a particular process with an attention peak of anotherprocess, our approach enhances LLM's awareness to various contextual positions,thus mitigating the risk of overlooking crucial information. In the largesttool-use benchmark, our method elevates a 7B model to achieve state-of-the-artperformance, comparable to that of GPT-4. On other benchmarks and some RAGtasks, which also demand a thorough understanding of contextual content,Attention Buckets also exhibited notable enhancements in performance.</description><author>Yuhan Chen, Ang Lv, Ting-En Lin, Changyu Chen, Yuchuan Wu, Fei Huang, Yongbin Li, Rui Yan</author><pubDate>Fri, 01 Mar 2024 07:56:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.04455v3</guid></item><item><title>Exploring a new machine learning based probabilistic model for high-resolution indoor radon mapping, using the German indoor radon survey data</title><link>http://arxiv.org/abs/2310.11143v3</link><description>Radon is a carcinogenic, radioactive gas that can accumulate indoors.Therefore, accurate knowledge of indoor radon concentration is crucial forassessing radon-related health effects or identifying radon-prone areas. Indoorradon concentration at the national scale is usually estimated on the basis ofextensive measurement campaigns. However, characteristics of the sample oftendiffer from the characteristics of the population due to the large number ofrelevant factors that control the indoor radon concentration such as theavailability of geogenic radon or floor level. Furthermore, the sample sizeusually does not allow estimation with high spatial resolution. We propose amodel-based approach that allows a more realistic estimation of indoor radondistribution with a higher spatial resolution than a purely data-basedapproach. A two-stage modelling approach was applied: 1) a quantile regressionforest using environmental and building data as predictors was applied toestimate the probability distribution function of indoor radon for each floorlevel of each residential building in Germany; (2) a probabilistic Monte Carlosampling technique enabled the combination and population weighting offloor-level predictions. In this way, the uncertainty of the individualpredictions is effectively propagated into the estimate of variability at theaggregated level. The results show an approximate lognormal distribution withan arithmetic mean of 63 Bq/m3, a geometric mean of 41 Bq/m3 and a 95 %ile of180 Bq/m3. The exceedance probability for 100 Bq/m3 and 300 Bq/m3 are 12.5 %(10.5 million people) and 2.2 % (1.9 million people), respectively.</description><author>Eric Petermann, Peter Bossew, Joachim Kemski, Valeria Gruber, Nils Suhr, Bernd Hoffmann</author><pubDate>Fri, 01 Mar 2024 07:39:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11143v3</guid></item><item><title>DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers</title><link>http://arxiv.org/abs/2402.16914v2</link><description>The safety alignment of Large Language Models (LLMs) is vulnerable to bothmanual and automated jailbreak attacks, which adversarially trigger LLMs tooutput harmful content. However, current methods for jailbreaking LLMs, whichnest entire harmful prompts, are not effective at concealing malicious intentand can be easily identified and rejected by well-aligned LLMs. This paperdiscovers that decomposing a malicious prompt into separated sub-prompts caneffectively obscure its underlying malicious intent by presenting it in afragmented, less detectable form, thereby addressing these limitations. Weintroduce an automatic prompt \textbf{D}ecomposition and\textbf{R}econstruction framework for jailbreak \textbf{Attack} (DrAttack).DrAttack includes three key components: (a) `Decomposition' of the originalprompt into sub-prompts, (b) `Reconstruction' of these sub-prompts implicitlyby in-context learning with semantically similar but harmless reassemblingdemo, and (c) a `Synonym Search' of sub-prompts, aiming to find sub-prompts'synonyms that maintain the original intent while jailbreaking LLMs. Anextensive empirical study across multiple open-source and closed-source LLMsdemonstrates that, with a significantly reduced number of queries, DrAttackobtains a substantial gain of success rate over prior SOTA prompt-onlyattackers. Notably, the success rate of 78.0\% on GPT-4 with merely 15 queriessurpassed previous art by 33.1\%. The project is available athttps://github.com/xirui-li/DrAttack.</description><author>Xirui Li, Ruochen Wang, Minhao Cheng, Tianyi Zhou, Cho-Jui Hsieh</author><pubDate>Fri, 01 Mar 2024 07:26:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.16914v2</guid></item><item><title>Improving the performance of weak supervision searches using transfer and meta-learning</title><link>http://arxiv.org/abs/2312.06152v2</link><description>Weak supervision searches have in principle the advantages of both being ableto train on experimental data and being able to learn distinctive signalproperties. However, the practical applicability of such searches is limited bythe fact that successfully training a neural network via weak supervision canrequire a large amount of signal. In this work, we seek to create neuralnetworks that can learn from less experimental signal by using transfer andmeta-learning. The general idea is to first train a neural network onsimulations, thereby learning concepts that can be reused or becoming a moreefficient learner. The neural network would then be trained on experimentaldata and should require less signal because of its previous training. We findthat transfer and meta-learning can substantially improve the performance ofweak supervision searches.</description><author>Hugues Beauchesne, Zong-En Chen, Cheng-Wei Chiang</author><pubDate>Fri, 01 Mar 2024 07:24:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.06152v2</guid></item><item><title>CMNER: A Chinese Multimodal NER Dataset based on Social Media</title><link>http://arxiv.org/abs/2402.13693v2</link><description>Multimodal Named Entity Recognition (MNER) is a pivotal task designed toextract named entities from text with the support of pertinent images.Nonetheless, a notable paucity of data for Chinese MNER has considerablyimpeded the progress of this natural language processing task within theChinese domain. Consequently, in this study, we compile a Chinese MultimodalNER dataset (CMNER) utilizing data sourced from Weibo, China's largest socialmedia platform. Our dataset encompasses 5,000 Weibo posts paired with 18,326corresponding images. The entities are classified into four distinctcategories: person, location, organization, and miscellaneous. We performbaseline experiments on CMNER, and the outcomes underscore the effectiveness ofincorporating images for NER. Furthermore, we conduct cross-lingual experimentson the publicly available English MNER dataset (Twitter2015), and the resultssubstantiate our hypothesis that Chinese and English multimodal NER data canmutually enhance the performance of the NER model.</description><author>Yuanze Ji, Bobo Li, Jun Zhou, Fei Li, Chong Teng, Donghong Ji</author><pubDate>Fri, 01 Mar 2024 07:12:20 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.13693v2</guid></item><item><title>Likelihood-based Mitigation of Evaluation Bias in Large Language Models</title><link>http://arxiv.org/abs/2402.15987v2</link><description>Large Language Models (LLMs) are widely used to evaluate natural languagegeneration tasks as automated metrics. However, the likelihood, a measure ofLLM's plausibility for a sentence, can vary due to superficial differences insentences, such as word order and sentence structure. It is therefore possiblethat there might be a likelihood bias if LLMs are used for evaluation: theymight overrate sentences with higher likelihoods while underrating those withlower likelihoods. In this paper, we investigate the presence and impact oflikelihood bias in LLM-based evaluators. We also propose a method to mitigatethe likelihood bias. Our method utilizes highly biased instances as few-shotexamples for in-context learning. Our experiments in evaluating thedata-to-text and grammatical error correction tasks reveal that several LLMs wetest display a likelihood bias. Furthermore, our proposed method successfullymitigates this bias, also improving evaluation performance (in terms ofcorrelation of models with human scores) significantly.</description><author>Masanari Ohi, Masahiro Kaneko, Ryuto Koike, Mengsay Loem, Naoaki Okazaki</author><pubDate>Fri, 01 Mar 2024 06:44:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15987v2</guid></item><item><title>Fast Graph Condensation with Structure-based Neural Tangent Kernel</title><link>http://arxiv.org/abs/2310.11046v2</link><description>The rapid development of Internet technology has given rise to a vast amountof graph-structured data. Graph Neural Networks (GNNs), as an effective methodfor various graph mining tasks, incurs substantial computational resource costswhen dealing with large-scale graph data. A data-centric manner solution isproposed to condense the large graph dataset into a smaller one withoutsacrificing the predictive performance of GNNs. However, existing effortscondense graph-structured data through a computational intensive bi-leveloptimization architecture also suffer from massive computation costs. In thispaper, we propose reforming the graph condensation problem as a Kernel RidgeRegression (KRR) task instead of iteratively training GNNs in the inner loop ofbi-level optimization. More specifically, We propose a novel datasetcondensation framework (GC-SNTK) for graph-structured data, where aStructure-based Neural Tangent Kernel (SNTK) is developed to capture thetopology of graph and serves as the kernel function in KRR paradigm.Comprehensive experiments demonstrate the effectiveness of our proposed modelin accelerating graph condensation while maintaining high predictionperformance. The source code is available onhttps://github.com/WANGLin0126/GCSNTK.</description><author>Lin Wang, Wenqi Fan, Jiatong Li, Yao Ma, Qing Li</author><pubDate>Fri, 01 Mar 2024 06:41:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11046v2</guid></item><item><title>InceptionXML: A Lightweight Framework with Synchronized Negative Sampling for Short Text Extreme Classification</title><link>http://arxiv.org/abs/2109.07319v3</link><description>Automatic annotation of short-text data to a large number of target labels,referred to as Short Text Extreme Classification, has found numerousapplications including prediction of related searches and productrecommendation tasks. In this paper, we propose a convolutional architectureInceptionXML which is light-weight, yet powerful, and robust to the inherentlack of word-order in short-text queries encountered in search andrecommendation tasks. We demonstrate the efficacy of applying convolutions byrecasting the operation along the embedding dimension instead of the worddimension as applied in conventional CNNs for text classification. Towardsscaling our model to datasets with millions of labels, we also proposeInceptionXML+ framework which improves upon the shortcomings of the recentlyproposed dynamic hard-negative mining technique for label shortlisting bysynchronizing the label-shortlister and extreme classifier. InceptionXML+ notonly reduces the inference time to half but is also an order of magnitudesmaller than previous state-of-the-art Astec in terms of model size. Throughour proposed models, we outperform all existing approaches on popular benchmarkdatasets.</description><author>Siddhant Kharbanda, Atmadeep Banerjee, Akash Palrecha, Devaansh Gupta, Rohit Babbar</author><pubDate>Fri, 01 Mar 2024 06:39:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2109.07319v3</guid></item><item><title>DiffAugment: Diffusion based Long-Tailed Visual Relationship Recognition</title><link>http://arxiv.org/abs/2401.01387v2</link><description>The task of Visual Relationship Recognition (VRR) aims to identifyrelationships between two interacting objects in an image and is particularlychallenging due to the widely-spread and highly imbalanced distribution of&lt;subject, relation, object&gt; triplets. To overcome the resultant performancebias in existing VRR approaches, we introduce DiffAugment -- a method whichfirst augments the tail classes in the linguistic space by making use ofWordNet and then utilizes the generative prowess of Diffusion Models to expandthe visual space for minority classes. We propose a novel hardness-awarecomponent in diffusion which is based upon the hardness of each &lt;S,R,O&gt; tripletand demonstrate the effectiveness of hardness-aware diffusion in generatingvisual embeddings for the tail classes. We also propose a novel subject andobject based seeding strategy for diffusion sampling which improves thediscriminative capability of the generated visual embeddings. Extensiveexperimentation on the GQA-LT dataset shows favorable gains in thesubject/object and relation average per-class accuracy using Diffusionaugmented samples.</description><author>Parul Gupta, Tuan Nguyen, Abhinav Dhall, Munawar Hayat, Trung Le, Thanh-Toan Do</author><pubDate>Fri, 01 Mar 2024 06:38:28 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01387v2</guid></item><item><title>Measuring Moral Inconsistencies in Large Language Models</title><link>http://arxiv.org/abs/2402.01719v3</link><description>A Large Language Model (LLM) is considered consistent if semanticallyequivalent prompts produce semantically equivalent responses. Despite recentadvancements showcasing the impressive capabilities of LLMs in conversationalsystems, we show that even state-of-the-art LLMs are highly inconsistent intheir generations, questioning their reliability. Prior research has tried tomeasure this with task-specific accuracy. However, this approach is unsuitablefor moral scenarios, such as the trolley problem, with no "correct" answer. Toaddress this issue, we propose a novel information-theoretic measure calledSemantic Graph Entropy (SGE) to measure the consistency of an LLM in moralscenarios. We leverage "Rules of Thumb" (RoTs) to explain a model'sdecision-making strategies and further enhance our metric. Compared to existingconsistency metrics, SGE correlates better with human judgments across fiveLLMs. In the future, we aim to investigate the root causes of LLMinconsistencies and propose improvements.</description><author>Vamshi Krishna Bonagiri, Sreeram Vennam, Manas Gaur, Ponnurangam Kumaraguru</author><pubDate>Fri, 01 Mar 2024 06:35:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.01719v3</guid></item><item><title>Learning to Estimate Critical Gait Parameters from Single-View RGB Videos with Transformer-Based Attention Network</title><link>http://arxiv.org/abs/2312.00398v2</link><description>Musculoskeletal diseases and cognitive impairments in patients lead todifficulties in movement as well as negative effects on their psychologicalhealth. Clinical gait analysis, a vital tool for early diagnosis and treatment,traditionally relies on expensive optical motion capture systems. Recentadvances in computer vision and deep learning have opened the door to moreaccessible and cost-effective alternatives. This paper introduces a novelspatio-temporal Transformer network to estimate critical gait parameters fromRGB videos captured by a single-view camera. Empirical evaluations on a publicdataset of cerebral palsy patients indicate that the proposed frameworksurpasses current state-of-the-art approaches and show significant improvementsin predicting general gait parameters (including Walking Speed, Gait DeviationIndex - GDI, and Knee Flexion Angle at Maximum Extension), while utilizingfewer parameters and alleviating the need for manual feature extraction.</description><author>Quoc Hung T. Le, Hieu H. Pham</author><pubDate>Fri, 01 Mar 2024 06:33:56 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.00398v2</guid></item><item><title>Graph Learning Across Data Silos</title><link>http://arxiv.org/abs/2301.06662v3</link><description>We consider the problem of inferring graph topology from smooth graph signalsin a novel but practical scenario where data are located in distributed clientsand prohibited from leaving local clients due to factors such as privacyconcerns. The main difficulty in this task is how to exploit the potentiallyheterogeneous data of all clients under data silos. To this end, we firstpropose an auto-weighted multiple graph learning model to jointly learn apersonalized graph for each local client and a single consensus graph for allclients. The personalized graphs match local data distributions, therebymitigating data heterogeneity, while the consensus graph captures the globalinformation. Moreover, the model can automatically assign appropriatecontribution weights to local graphs based on their similarity to the consensusgraph. We next devise a tailored algorithm to solve the induced problem, whereall raw data are processed locally without leaving clients. Theoretically, weestablish a provable estimation error bound and convergence analysis for theproposed model and algorithm. Finally, extensive experiments on synthetic andreal data are carried out, and the results illustrate that our approach canlearn graphs effectively in the target scenario.</description><author>Xiang Zhang, Qiao Wang</author><pubDate>Fri, 01 Mar 2024 06:32:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.06662v3</guid></item><item><title>MagicDrive: Street View Generation with Diverse 3D Geometry Control</title><link>http://arxiv.org/abs/2310.02601v6</link><description>Recent advancements in diffusion models have significantly enhanced the datasynthesis with 2D control. Yet, precise 3D control in street view generation,crucial for 3D perception tasks, remains elusive. Specifically, utilizingBird's-Eye View (BEV) as the primary condition often leads to challenges ingeometry control (e.g., height), affecting the representation of object shapes,occlusion patterns, and road surface elevations, all of which are essential toperception data synthesis, especially for 3D object detection tasks. In thispaper, we introduce MagicDrive, a novel street view generation framework,offering diverse 3D geometry controls including camera poses, road maps, and 3Dbounding boxes, together with textual descriptions, achieved through tailoredencoding strategies. Besides, our design incorporates a cross-view attentionmodule, ensuring consistency across multiple camera views. With MagicDrive, weachieve high-fidelity street-view image &amp; video synthesis that captures nuanced3D geometry and various scene descriptions, enhancing tasks like BEVsegmentation and 3D object detection.</description><author>Ruiyuan Gao, Kai Chen, Enze Xie, Lanqing Hong, Zhenguo Li, Dit-Yan Yeung, Qiang Xu</author><pubDate>Fri, 01 Mar 2024 06:29:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.02601v6</guid></item><item><title>Policy Gradient Methods for Discrete Time Linear Quadratic Regulator With Random Parameters</title><link>http://arxiv.org/abs/2303.16548v2</link><description>This paper studies an infinite horizon optimal control problem fordiscrete-time linear system and quadratic criteria, both with random parameterswhich are independent and identically distributed with respect to time. In thisgeneral setting, we apply the policy gradient method, a reinforcement learningtechnique, to search for the optimal control without requiring knowledge ofstatistical information of the parameters. We investigate the sub-Gaussianityof the state process and establish global linear convergence guarantee for thisapproach based on assumptions that are weaker and easier to verify compared toexisting results. Numerical experiments are presented to illustrate our result.</description><author>Deyue Li</author><pubDate>Fri, 01 Mar 2024 06:18:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.16548v2</guid></item><item><title>Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting</title><link>http://arxiv.org/abs/2402.05956v3</link><description>Transformer-based models have achieved some success in time seriesforecasting. Existing methods mainly model time series from limited or fixedscales, making it challenging to capture different characteristics spanningvarious scales. In this paper, we propose Pathformer, a multi-scale transformerwith adaptive pathways. The proposed Pathformer integrates both temporalresolution and temporal distance for multi-scale modeling. Multi-scale divisiondivides the time series into different temporal resolutions using patches ofvarious sizes. Based on the division of each scale, dual attention is performedover these patches to capture global correlations and local details as temporaldependencies. We further enrich the multi-scale transformer with adaptivepathways, which adaptively adjust the multi-scale modeling process based on thevarying temporal dynamics in the input time series, improving the predictionaccuracy and generalization of Pathformer. Extensive experiments on elevenreal-world datasets demonstrate that Pathformer not only achievesstate-of-the-art performance by surpassing all current models but also exhibitsstronger generalization abilities under various transfer scenarios.</description><author>Peng Chen, Yingying Zhang, Yunyao Cheng, Yang Shu, Yihang Wang, Qingsong Wen, Bin Yang, Chenjuan Guo</author><pubDate>Fri, 01 Mar 2024 06:18:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05956v3</guid></item><item><title>A Transformer-Based Deep Learning Approach for Fairly Predicting Post-Liver Transplant Risk Factors</title><link>http://arxiv.org/abs/2304.02780v2</link><description>Liver transplantation is a life-saving procedure for patients with end-stageliver disease. There are two main challenges in liver transplant: finding thebest matching patient for a donor and ensuring transplant equity amongdifferent subpopulations. The current MELD scoring system evaluates a patient'smortality risk if not receiving an organ within 90 days. However, thedonor-patient matching should also consider post-transplant risk factors, suchas cardiovascular disease, chronic rejection, etc., which are all commoncomplications after transplant. Accurate prediction of these risk scoresremains a significant challenge. In this study, we used predictive models tosolve the above challenges. Specifically, we proposed a deep-learning model topredict multiple risk factors after a liver transplant. By formulating it as amulti-task learning problem, the proposed deep neural network was trained tosimultaneously predict the five post-transplant risks and achieve equal goodperformance by exploiting task-balancing techniques. We also proposed a novelfairness-achieving algorithm to ensure prediction fairness across differentsubpopulations. We used electronic health records of 160,360 liver transplantpatients, including demographic information, clinical variables, and laboratoryvalues, collected from the liver transplant records of the United States from1987 to 2018. The model's performance was evaluated using various performancemetrics such as AUROC and AUPRC. Our experiment results highlighted the successof our multitask model in achieving task balance while maintaining accuracy.The model significantly reduced the task discrepancy by 39%. Furtherapplication of the fairness-achieving algorithm substantially reduced fairnessdisparity among all sensitive attributes (gender, age group, andrace/ethnicity) in each risk factor.</description><author>Can Li, Xiaoqian Jiang, Kai Zhang</author><pubDate>Fri, 01 Mar 2024 05:59:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.02780v2</guid></item><item><title>New Characterizations and Efficient Local Search for General Integer Linear Programming</title><link>http://arxiv.org/abs/2305.00188v4</link><description>Integer linear programming (ILP) models a wide range of practicalcombinatorial optimization problems and significantly impacts industry andmanagement sectors. This work proposes new characterizations of ILP with theconcept of boundary solutions. Motivated by the new characterizations, wedevelop a new local search algorithm Local-ILP, which is efficient for solvinggeneral ILP validated on a large heterogeneous problem dataset. We propose anew local search framework that switches between three modes, namely Search,Improve, and Restore modes. Two new operators are proposed, namely the tightmove and the lift move operators, which are associated with appropriate scoringfunctions. Different modes apply different operators to realize differentsearch strategies and the algorithm switches between three modes according tothe current search state. Putting these together, we develop a local search ILPsolver called Local-ILP. Experiments conducted on the MIPLIB dataset show theeffectiveness of our algorithm in solving large-scale hard ILP problems. In theaspect of finding a good feasible solution quickly, Local-ILP is competitiveand complementary to the state-of-the-art commercial solver Gurobi andsignificantly outperforms the state-of-the-art non-commercial solver SCIP.Moreover, our algorithm establishes new records for 6 MIPLIB open instances.The theoretical analysis of our algorithm is also presented, which shows ouralgorithm could avoid visiting unnecessary regions.</description><author>Peng Lin, Shaowei Cai, Mengchuan Zou, Jinkun Lin</author><pubDate>Fri, 01 Mar 2024 05:56:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.00188v4</guid></item><item><title>Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable Image Super Resolution</title><link>http://arxiv.org/abs/2402.18929v2</link><description>Deep learning has led to a dramatic leap on Single Image Super-Resolution(SISR) performances in recent years. %Despite the substantial advancement%While most existing work assumes a simple and fixed degradation model (e.g.,bicubic downsampling), the research of Blind SR seeks to improve modelgeneralization ability with unknown degradation. Recently, Kong et al pioneerthe investigation of a more suitable training strategy for Blind SR usingDropout. Although such method indeed brings substantial generalizationimprovements via mitigating overfitting, we argue that Dropout simultaneouslyintroduces undesirable side-effect that compromises model's capacity tofaithfully reconstruct fine details. We show both the theoretical andexperimental analyses in our paper, and furthermore, we present another easyyet effective training strategy that enhances the generalization ability of themodel by simply modulating its first and second-order features statistics.Experimental results have shown that our method could serve as a model-agnosticregularization and outperforms Dropout on seven benchmark datasets includingboth synthetic and real-world scenarios.</description><author>Hongjun Wang, Jiyuan Chen, Yinqiang Zheng, Tieyong Zeng</author><pubDate>Fri, 01 Mar 2024 05:48:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18929v2</guid></item><item><title>GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse</title><link>http://arxiv.org/abs/2401.01523v3</link><description>The exponential growth of social media has profoundly transformed howinformation is created, disseminated, and absorbed, exceeding any precedent inthe digital age. Regrettably, this explosion has also spawned a significantincrease in the online abuse of memes. Evaluating the negative impact of memesis notably challenging, owing to their often subtle and implicit meanings,which are not directly conveyed through the overt text and imagery. In light ofthis, large multimodal models (LMMs) have emerged as a focal point of interestdue to their remarkable capabilities in handling diverse multimodal tasks. Inresponse to this development, our paper aims to thoroughly examine the capacityof various LMMs (e.g., GPT-4V) to discern and respond to the nuanced aspects ofsocial abuse manifested in memes. We introduce the comprehensive memebenchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themessuch as implicit hate speech, sexism, and cyberbullying, etc. UtilizingGOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness,misogyny, offensiveness, sarcasm, and harmful content. Our extensiveexperiments across a range of LMMs reveal that current models still exhibit adeficiency in safety awareness, showing insensitivity to various forms ofimplicit abuse. We posit that this shortfall represents a critical impedimentto the realization of safe artificial intelligence. The GOAT-Bench andaccompanying resources are publicly accessible at https://goatlmm.github.io/,contributing to ongoing research in this vital field.</description><author>Hongzhan Lin, Ziyang Luo, Bo Wang, Ruichao Yang, Jing Ma</author><pubDate>Fri, 01 Mar 2024 05:26:39 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.01523v3</guid></item><item><title>Investigating White-Box Attacks for On-Device Models</title><link>http://arxiv.org/abs/2402.05493v4</link><description>Numerous mobile apps have leveraged deep learning capabilities. However,on-device models are vulnerable to attacks as they can be easily extracted fromtheir corresponding mobile apps. Existing on-device attacking approaches onlygenerate black-box attacks, which are far less effective and efficient thanwhite-box strategies. This is because mobile deep learning frameworks likeTFLite do not support gradient computing, which is necessary for white-boxattacking algorithms. Thus, we argue that existing findings may underestimatethe harmfulness of on-device attacks. To this end, we conduct a study to answerthis research question: Can on-device models be directly attacked via white-boxstrategies? We first systematically analyze the difficulties of transformingthe on-device model to its debuggable version, and propose a ReverseEngineering framework for On-device Models (REOM), which automatically reversesthe compiled on-device TFLite model to the debuggable model. Specifically, REOMfirst transforms compiled on-device models into Open Neural Network Exchangeformat, then removes the non-debuggable parts, and converts them to thedebuggable DL models format that allows attackers to exploit in a white-boxsetting. Our experimental results show that our approach is effective inachieving automated transformation among 244 TFLite models. Compared withprevious attacks using surrogate models, REOM enables attackers to achievehigher attack success rates with a hundred times smaller attack perturbations.In addition, because the ONNX platform has plenty of tools for model formatexchanging, the proposed method based on the ONNX platform can be adapted toother model formats. Our findings emphasize the need for developers tocarefully consider their model deployment strategies, and use white-box methodsto evaluate the vulnerability of on-device models.</description><author>Mingyi Zhou, Xiang Gao, Jing Wu, Kui Liu, Hailong Sun, Li Li</author><pubDate>Fri, 01 Mar 2024 05:22:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.05493v4</guid></item><item><title>UFO: A UI-Focused Agent for Windows OS Interaction</title><link>http://arxiv.org/abs/2402.07939v4</link><description>We introduce UFO, an innovative UI-Focused agent to fulfill user requeststailored to applications on Windows OS, harnessing the capabilities ofGPT-Vision. UFO employs a dual-agent framework to meticulously observe andanalyze the graphical user interface (GUI) and control information of Windowsapplications. This enables the agent to seamlessly navigate and operate withinindividual applications and across them to fulfill user requests, even whenspanning multiple applications. The framework incorporates a controlinteraction module, facilitating action grounding without human interventionand enabling fully automated execution. Consequently, UFO transforms arduousand time-consuming processes into simple tasks achievable solely throughnatural language commands. We conducted testing of UFO across 9 popular Windowsapplications, encompassing a variety of scenarios reflective of users' dailyusage. The results, derived from both quantitative metrics and real-casestudies, underscore the superior effectiveness of UFO in fulfilling userrequests. To the best of our knowledge, UFO stands as the first UI agentspecifically tailored for task completion within the Windows OS environment.The open-source code for UFO is available on https://github.com/microsoft/UFO.</description><author>Chaoyun Zhang, Liqun Li, Shilin He, Xu Zhang, Bo Qiao, Si Qin, Minghua Ma, Yu Kang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang</author><pubDate>Fri, 01 Mar 2024 05:20:47 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.07939v4</guid></item><item><title>Tree Cross Attention</title><link>http://arxiv.org/abs/2309.17388v2</link><description>Cross Attention is a popular method for retrieving information from a set ofcontext tokens for making predictions. At inference time, for each prediction,Cross Attention scans the full set of $\mathcal{O}(N)$ tokens. In practice,however, often only a small subset of tokens are required for good performance.Methods such as Perceiver IO are cheap at inference as they distill theinformation to a smaller-sized set of latent tokens $L &lt; N$ on which crossattention is then applied, resulting in only $\mathcal{O}(L)$ complexity.However, in practice, as the number of input tokens and the amount ofinformation to distill increases, the number of latent tokens needed alsoincreases significantly. In this work, we propose Tree Cross Attention (TCA) -a module based on Cross Attention that only retrieves information from alogarithmic $\mathcal{O}(\log(N))$ number of tokens for performing inference.TCA organizes the data in a tree structure and performs a tree search atinference time to retrieve the relevant tokens for prediction. Leveraging TCA,we introduce ReTreever, a flexible architecture for token-efficient inference.We show empirically that Tree Cross Attention (TCA) performs comparable toCross Attention across various classification and uncertainty regression taskswhile being significantly more token-efficient. Furthermore, we compareReTreever against Perceiver IO, showing significant gains while using the samenumber of tokens for inference.</description><author>Leo Feng, Frederick Tung, Hossein Hajimirsadeghi, Yoshua Bengio, Mohamed Osama Ahmed</author><pubDate>Fri, 01 Mar 2024 05:15:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2309.17388v2</guid></item><item><title>NaVid: Video-based VLM Plans the Next Step for Vision-and-Language Navigation</title><link>http://arxiv.org/abs/2402.15852v3</link><description>Vision-and-Language Navigation (VLN) stands as a key research problem ofEmbodied AI, aiming at enabling agents to navigate in unseen environmentsfollowing linguistic instructions. In this field, generalization is along-standing challenge, either to out-of-distribution scenes or from Sim toReal. In this paper, we propose NaVid, a video-based large vision languagemodel (VLM), to mitigate such a generalization gap. NaVid makes the firstendeavour to showcase the capability of VLMs to achieve state-of-the-art levelnavigation performance without any maps, odometer and depth inputs. Followinghuman instruction, NaVid only requires an on-the-fly video stream from amonocular RGB camera equipped on the robot to output the next-step action. Ourformulation mimics how humans navigate and naturally gets rid of the problemsintroduced by odometer noises, and the Sim2Real gaps from map or depth inputs.Moreover, our video-based approach can effectively encode the historicalobservations of robots as spatio-temporal contexts for decision-making andinstruction following. We train NaVid with 550k navigation samples collectedfrom VLN-CE trajectories, including action-planning and instruction-reasoningsamples, along with 665k large-scale web data. Extensive experiments show thatNaVid achieves SOTA performance in simulation environments and the real world,demonstrating superior cross-dataset and Sim2Real transfer. We thus believe ourproposed VLM approach plans the next step for not only the navigation agentsbut also this research field.</description><author>Jiazhao Zhang, Kunyu Wang, Rongtao Xu, Gengze Zhou, Yicong Hong, Xiaomeng Fang, Qi Wu, Zhizheng Zhang, Wang He</author><pubDate>Fri, 01 Mar 2024 05:09:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15852v3</guid></item><item><title>E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series</title><link>http://arxiv.org/abs/2402.14041v3</link><description>We propose E2USD that enables efficient-yet-accurate unsupervised MTS statedetection. E2USD exploits a Fast Fourier Transform-based Time Series Compressor(FFTCompress) and a Decomposed Dual-view Embedding Module (DDEM) that togetherencode input MTSs at low computational overhead. Additionally, we propose aFalse Negative Cancellation Contrastive Learning method (FNCCLearning) tocounteract the effects of false negatives and to achieve more cluster-friendlyembedding spaces. To reduce computational overhead further in streamingsettings, we introduce Adaptive Threshold Detection (ADATD). Comprehensiveexperiments with six baselines and six datasets offer evidence that E2USD iscapable of SOTA accuracy at significantly reduced computational overhead. Ourcode is available at https://github.com/AI4CTS/E2Usd.</description><author>Zhichen Lai, Huan Li, Dalin Zhang, Yan Zhao, Weizhu Qian, Christian S. Jensen</author><pubDate>Fri, 01 Mar 2024 04:55:02 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14041v3</guid></item><item><title>How (un)ethical are instruction-centric responses of LLMs? Unveiling the vulnerabilities of safety guardrails to harmful queries</title><link>http://arxiv.org/abs/2402.15302v2</link><description>In this study, we tackle a growing concern around the safety and ethical useof large language models (LLMs). Despite their potential, these models can betricked into producing harmful or unethical content through varioussophisticated methods, including 'jailbreaking' techniques and targetedmanipulation. Our work zeroes in on a specific issue: to what extent LLMs canbe led astray by asking them to generate responses that are instruction-centricsuch as a pseudocode, a program or a software snippet as opposed to vanillatext. To investigate this question, we introduce TechHazardQA, a datasetcontaining complex queries which should be answered in both text andinstruction-centric formats (e.g., pseudocodes), aimed at identifying triggersfor unethical responses. We query a series of LLMs -- Llama-2-13b, Llama-2-7b,Mistral-V2 and Mistral 8X7B -- and ask them to generate both text andinstruction-centric responses. For evaluation we report the harmfulness scoremetric as well as judgements from GPT-4 and humans. Overall, we observe thatasking LLMs to produce instruction-centric responses enhances the unethicalresponse generation by ~2-38% across the models. As an additional objective, weinvestigate the impact of model editing using the ROME technique, which furtherincreases the propensity for generating undesirable content. In particular,asking edited LLMs to generate instruction-centric responses further increasesthe unethical response generation by ~3-16% across the different models.</description><author>Somnath Banerjee, Sayan Layek, Rima Hazra, Animesh Mukherjee</author><pubDate>Fri, 01 Mar 2024 04:54:44 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15302v2</guid></item><item><title>Large Language Models As MOOCs Graders</title><link>http://arxiv.org/abs/2402.03776v4</link><description>Massive open online courses (MOOCs) unlock the doors to free education foranyone around the globe with access to a computer and the internet. Despitethis democratization of learning, the massive enrollment in these courses meansit is almost impossible for one instructor to assess every student's writingassignment. As a result, peer grading, often guided by a straightforwardrubric, is the method of choice. While convenient, peer grading often fallsshort in terms of reliability and validity. In this study, using 18 distinctsettings, we explore the feasibility of leveraging large language models (LLMs)to replace peer grading in MOOCs. Specifically, we focus on twostate-of-the-art LLMs: GPT-4 and GPT-3.5, across three distinct courses:Introductory Astronomy, Astrobiology, and the History and Philosophy ofAstronomy. To instruct LLMs, we use three different prompts based on a variantof the zero-shot chain-of-thought (Zero-shot-CoT) prompting technique:Zero-shot-CoT combined with instructor-provided correct answers; Zero-shot-CoTin conjunction with both instructor-formulated answers and rubrics; andZero-shot-CoT with instructor-offered correct answers and LLM-generatedrubrics. Our results show that Zero-shot-CoT, when integrated withinstructor-provided answers and rubrics, produces grades that are more alignedwith those assigned by instructors compared to peer grading. However, theHistory and Philosophy of Astronomy course proves to be more challenging interms of grading as opposed to other courses. Finally, our study reveals apromising direction for automating grading systems for MOOCs, especially insubjects with well-defined rubrics.</description><author>Shahriar Golchin, Nikhil Garuda, Christopher Impey, Matthew Wenger</author><pubDate>Fri, 01 Mar 2024 04:48:41 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03776v4</guid></item><item><title>3DSFLabelling: Boosting 3D Scene Flow Estimation by Pseudo Auto-labelling</title><link>http://arxiv.org/abs/2402.18146v2</link><description>Learning 3D scene flow from LiDAR point clouds presents significantdifficulties, including poor generalization from synthetic datasets to realscenes, scarcity of real-world 3D labels, and poor performance on real sparseLiDAR point clouds. We present a novel approach from the perspective ofauto-labelling, aiming to generate a large number of 3D scene flow pseudolabels for real-world LiDAR point clouds. Specifically, we employ theassumption of rigid body motion to simulate potential object-level rigidmovements in autonomous driving scenarios. By updating different motionattributes for multiple anchor boxes, the rigid motion decomposition isobtained for the whole scene. Furthermore, we developed a novel 3D scene flowdata augmentation method for global and local motion. By perfectly synthesizingtarget point clouds based on augmented motion parameters, we easily obtain lotsof 3D scene flow labels in point clouds highly consistent with real scenarios.On multiple real-world datasets including LiDAR KITTI, nuScenes, and Argoverse,our method outperforms all previous supervised and unsupervised methods withoutrequiring manual labelling. Impressively, our method achieves a tenfoldreduction in EPE3D metric on the LiDAR KITTI dataset, reducing it from $0.190m$to a mere $0.008m$ error.</description><author>Chaokang Jiang, Guangming Wang, Jiuming Liu, Hesheng Wang, Zhuang Ma, Zhenqiang Liu, Zhujin Liang, Yi Shan, Dalong Du</author><pubDate>Fri, 01 Mar 2024 04:26:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18146v2</guid></item><item><title>Safeguarding Data in Multimodal AI: A Differentially Private Approach to CLIP Training</title><link>http://arxiv.org/abs/2306.08173v2</link><description>The surge in multimodal AI's success has sparked concerns over data privacyin vision-and-language tasks. While CLIP has revolutionized multimodal learningthrough joint training on images and text, its potential to unintentionallydisclose sensitive information necessitates the integration ofprivacy-preserving mechanisms. We introduce a differentially private adaptationof the Contrastive Language-Image Pretraining (CLIP) model that effectivelyaddresses privacy concerns while retaining accuracy. Our proposed method,Dp-CLIP, is rigorously evaluated on benchmark datasets encompassing diversevision-and-language tasks such as image classification and visual questionanswering. We demonstrate that our approach retains performance on par with thestandard non-private CLIP model. Furthermore, we analyze our proposed algorithmunder linear representation settings. We derive the convergence rate of ouralgorithm and show a trade-off between utility and privacy when gradients areclipped per-batch and the loss function does not satisfy smoothness conditionsassumed in the literature for the analysis of DP-SGD.</description><author>Alyssa Huang, Peihan Liu, Ryumei Nakada, Linjun Zhang, Wanrong Zhang</author><pubDate>Fri, 01 Mar 2024 04:24:04 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.08173v2</guid></item><item><title>Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control</title><link>http://arxiv.org/abs/1909.12077v5</link><description>In this paper, we introduce Symplectic ODE-Net (SymODEN), a deep learningframework which can infer the dynamics of a physical system, given by anordinary differential equation (ODE), from observed state trajectories. Toachieve better generalization with fewer training samples, SymODEN incorporatesappropriate inductive bias by designing the associated computation graph in aphysics-informed manner. In particular, we enforce Hamiltonian dynamics withcontrol to learn the underlying dynamics in a transparent way, which can thenbe leveraged to draw insight about relevant physical aspects of the system,such as mass and potential energy. In addition, we propose a parametrizationwhich can enforce this Hamiltonian formalism even when the generalizedcoordinate data is embedded in a high-dimensional space or we can only accessvelocity data instead of generalized momentum. This framework, by offeringinterpretable, physically-consistent models for physical systems, opens up newpossibilities for synthesizing model-based control strategies.</description><author>Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty</author><pubDate>Fri, 01 Mar 2024 04:10:17 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/1909.12077v5</guid></item><item><title>Concise and Organized Perception Facilitates Large Language Models for Deductive Reasoning</title><link>http://arxiv.org/abs/2310.03309v2</link><description>Exploiting large language models (LLMs) to tackle deductive reasoning hasgarnered growing attention. It still remains highly challenging to achievesatisfactory results in complex deductive problems, characterized by plenty ofpremises (i.e., facts or rules) entailing intricate relationships amongentities and requiring multi-hop reasoning. One intuitive solution is todecompose the original task into smaller sub-tasks, and then chain the multiplecasual reasoning steps together in a forward (e.g., Selection-Inference) orbackward (e.g., LAMBADA) direction. However, these techniques inevitablynecessitate a large number of overall stages, leading to computationallyexpensive operations and a higher possibility of making misleading steps. Inaddition to stage-by-stage decomposition, we draw inspiration from anotheraspect of human problem-solving. Humans tend to distill the most relevantinformation and organize their thoughts systematically (e.g., creating mindmaps), which assists them in answering questions or drawing conclusionsprecisely and quickly. In light of this, we propose a novel reasoning approachnamed Concise and Organized Perception (COP). COP carefully analyzes the givenstatements to efficiently identify the most pertinent information whileeliminating redundancy. It then prompts the LLMs in a more organized form thatadapts to the model's inference process. By perceiving concise and organizedproofs, the deductive reasoning abilities of LLMs can be better elicited, andthe risk of acquiring errors caused by excessive reasoning stages is mitigated.Furthermore, our approach can be combined with the aforementioned ones tofurther boost their performance. Extensive experimental results on threepopular deductive benchmarks (i.e., ProofWriter, PrOntoQA and PrOntoQA-OOD)show that COP significantly outperforms previous state-of-the-art methods.</description><author>Shaotian Yan, Chen Shen, Junjie Liu, Jieping Ye</author><pubDate>Fri, 01 Mar 2024 03:47:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.03309v2</guid></item><item><title>Critical Appraisal of Artificial Intelligence-Mediated Communication</title><link>http://arxiv.org/abs/2305.11897v2</link><description>Over the last two decades, technology use in language learning and teachinghas significantly advanced and is now referred to as Computer-Assisted LanguageLearning (CALL). Recently, the integration of Artificial Intelligence (AI) intoCALL has brought about a significant shift in the traditional approach tolanguage education both inside and outside the classroom. In line with thisbook's scope, I explore the advantages and disadvantages of AI-mediatedcommunication in language education. I begin with a brief review of AI ineducation. I then introduce the ICALL and give a critical appraisal of thepotential of AI-powered automatic speech recognition (ASR), Machine Translation(MT), Intelligent Tutoring Systems (ITSs), AI-powered chatbots, and ExtendedReality (XR). In conclusion, I argue that it is crucial for language teachersto engage in CALL teacher education and professional development to keep upwith the ever-evolving technology landscape and improve their teachingeffectiveness.</description><author>Dara Tafazoli</author><pubDate>Fri, 01 Mar 2024 03:41:30 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2305.11897v2</guid></item><item><title>Inter-object Discriminative Graph Modeling for Indoor Scene Recognition</title><link>http://arxiv.org/abs/2311.05919v3</link><description>Variable scene layouts and coexisting objects across scenes make indoor scenerecognition still a challenging task. Leveraging object information withinscenes to enhance the distinguishability of feature representations has emergedas a key approach in this domain. Currently, most object-assisted methods use aseparate branch to process object information, combining object and scenefeatures heuristically. However, few of them pay attention to interpretablyhandle the hidden discriminative knowledge within object information. In thispaper, we propose to leverage discriminative object knowledge to enhance scenefeature representations. Initially, we capture the object-scene discriminativerelationships from a probabilistic perspective, which are transformed into anInter-Object Discriminative Prototype (IODP). Given the abundant priorknowledge from IODP, we subsequently construct a Discriminative Graph Network(DGN), in which pixel-level scene features are defined as nodes and thediscriminative relationships between node features are encoded as edges. DGNaims to incorporate inter-object discriminative knowledge into the imagerepresentation through graph convolution and mapping operations (GCN). With theproposed IODP and DGN, we obtain state-of-the-art results on several widelyused scene datasets, demonstrating the effectiveness of the proposed approach.</description><author>Chuanxin Song, Hanbo Wu, Xin Ma</author><pubDate>Fri, 01 Mar 2024 03:38:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.05919v3</guid></item><item><title>Memory-Efficient Sequential Pattern Mining with Hybrid Tries</title><link>http://arxiv.org/abs/2202.06834v2</link><description>As modern data sets continue to grow exponentially in size, the demand forefficient mining algorithms capable of handling such large data sets becomesincreasingly imperative. This paper develops a memory-efficient approach forSequential Pattern Mining (SPM), a fundamental topic in knowledge discoverythat faces a well-known memory bottleneck for large data sets. Our methodologyinvolves a novel hybrid trie data structure that exploits recurring patterns tocompactly store the data set in memory; and a corresponding mining algorithmdesigned to effectively extract patterns from this compact representation.Numerical results on real-life test instances show an average improvement of88% in memory consumption and 41% in computation time for small to medium-sizeddata sets compared to the state of the art. Furthermore, our algorithm standsout as the only capable SPM approach for large data sets within 256GB of systemmemory.</description><author>Amin Hosseininasab, Willem-Jan van Hoeve, Andre A. Cire</author><pubDate>Fri, 01 Mar 2024 03:35:35 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2202.06834v2</guid></item><item><title>TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning</title><link>http://arxiv.org/abs/2402.19467v2</link><description>It is challenging to perform question-answering over complex, multimodalcontent such as television clips. This is in part because currentvideo-language models rely on single-modality reasoning, have loweredperformance on long inputs, and lack interpetability. We propose TV-TREES, thefirst multimodal entailment tree generator. TV-TREES serves as an approach tovideo understanding that promotes interpretable joint-modality reasoning byproducing trees of entailment relationships between simple premises directlyentailed by the videos and higher-level conclusions. We then introduce the taskof multimodal entailment tree generation to evaluate the reasoning quality ofsuch methods. Our method's experimental results on the challenging TVQA datasetdemonstrate intepretable, state-of-the-art zero-shot performance on full videoclips, illustrating a best of both worlds contrast to black-box methods.</description><author>Kate Sanders, Nathaniel Weir, Benjamin Van Durme</author><pubDate>Fri, 01 Mar 2024 03:06:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.19467v2</guid></item><item><title>MuLTI: Efficient Video-and-Language Understanding with Text-Guided MultiWay-Sampler and Multiple Choice Modeling</title><link>http://arxiv.org/abs/2303.05707v2</link><description>Video-and-language understanding has a variety of applications in theindustry, such as video question answering, text-video retrieval, andmulti-label classification. Existing video-and-language understanding methodsgenerally adopt heavy multi-modal encoders and feature fusion modules, whichconsume high computational costs. Specially, they have difficulty dealing withdense video frames or long text prevalent in industrial applications. Thispaper proposes MuLTI, a highly accurate and efficient video-and-languageunderstanding model that achieves efficient and effective feature fusion andrapid adaptation to downstream tasks. Specifically, we design a Text-GuidedMultiWay-Sampler based on adapt-pooling residual mapping and self-attentionmodules to sample long sequences and fuse multi-modal features, which reducesthe computational costs and addresses performance degradation caused byprevious samplers. Therefore, MuLTI can handle longer sequences with limitedcomputational costs. Then, to further enhance the model's performance and fillin the lack of pretraining tasks in the video question answering, we propose anew pretraining task named Multiple Choice Modeling. This task bridges the gapbetween pretraining and downstream tasks and improves the model's ability toalign video and text features. Benefiting from the efficient feature fusionmodule and the new pretraining task, MuLTI achieves state-of-the-artperformance on multiple datasets. Implementation and pretrained models will bereleased.</description><author>Jiaqi Xu, Bo Liu, Yunkuo Chen, Mengli Cheng, Xing Shi</author><pubDate>Fri, 01 Mar 2024 02:32:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.05707v2</guid></item><item><title>Optimal Transport for Measures with Noisy Tree Metric</title><link>http://arxiv.org/abs/2310.13653v3</link><description>We study optimal transport (OT) problem for probability measures supported ona tree metric space. It is known that such OT problem (i.e., tree-Wasserstein(TW)) admits a closed-form expression, but depends fundamentally on theunderlying tree structure over supports of input measures. In practice, thegiven tree structure may be, however, perturbed due to noisy or adversarialmeasurements. To mitigate this issue, we follow the max-min robust OT approachwhich considers the maximal possible distances between two input measures overan uncertainty set of tree metrics. In general, this approach is hard tocompute, even for measures supported in one-dimensional space, due to itsnon-convexity and non-smoothness which hinders its practical applications,especially for large-scale settings. In this work, we propose novel uncertaintysets of tree metrics from the lens of edge deletion/addition which covers adiversity of tree structures in an elegant framework. Consequently, by buildingupon the proposed uncertainty sets, and leveraging the tree structure oversupports, we show that the robust OT also admits a closed-form expression for afast computation as its counterpart standard OT (i.e., TW). Furthermore, wedemonstrate that the robust OT satisfies the metric property and is negativedefinite. We then exploit its negative definiteness to propose positivedefinite kernels and test them in several simulations on various real-worlddatasets on document classification and topological data analysis.</description><author>Tam Le, Truyen Nguyen, Kenji Fukumizu</author><pubDate>Fri, 01 Mar 2024 02:23:59 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.13653v3</guid></item><item><title>The Machine Can't Replace the Human Heart</title><link>http://arxiv.org/abs/2402.18826v2</link><description>What is the true heart of mental healthcare -- innovation or humanity? Canvirtual therapy ever replicate the profound human bonds where healing arises?As artificial intelligence and immersive technologies promise expanded access,safeguards must ensure technologies remain supplementary tools guided byproviders' wisdom. Implementation requires nuance balancing efficiency andempathy. If conscious of ethical risks, perhaps AI could restore humanity byautomating tasks, giving providers more time to listen. Yet no algorithm canreplicate the seat of dignity within. We must ask ourselves: What future haspeople at its core? One where AI thoughtfully plays a collaborative role? Orwhere pursuit of progress leaves vulnerability behind? This commentary arguesfor a balanced approach thoughtfully integrating technology while retainingcare's irreplaceable human essence, at the heart of this profoundly humanprofession. Ultimately, by nurturing innovation and humanity together, perhapswe reach new heights of empathy previously unimaginable.</description><author>Baihan Lin</author><pubDate>Fri, 01 Mar 2024 02:21:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18826v2</guid></item><item><title>ICE-SEARCH: A Language Model-Driven Feature Selection Approach</title><link>http://arxiv.org/abs/2402.18609v2</link><description>This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method,the first work that melds language models (LMs) with evolutionary algorithmsfor feature selection (FS) tasks and demonstrates its effectiveness in MedicalPredictive Analytics (MPA) applications. ICE-SEARCH harnesses the crossover andmutation capabilities inherent in LMs within an evolutionary framework,significantly improving FS through the model's comprehensive world knowledgeand its adaptability to a variety of roles. Our evaluation of this methodologyspans three crucial MPA tasks: stroke, cardiovascular disease, and diabetes,where ICE-SEARCH outperforms traditional FS methods in pinpointing essentialfeatures for medical applications. ICE-SEARCH achieves State-of-the-Art (SOTA)performance in stroke prediction and diabetes prediction; theDecision-Randomized ICE-SEARCH ranks as SOTA in cardiovascular diseaseprediction. Our results not only demonstrate the efficacy of ICE-SEARCH inmedical FS but also underscore the versatility, efficiency, and scalability ofintegrating LMs in FS tasks. The study emphasizes the critical role ofincorporating domain-specific insights, illustrating ICE-SEARCH's robustness,generalizability, and swift convergence. This opens avenues for furtherresearch into comprehensive and intricate FS landscapes, marking a significantstride in the application of artificial intelligence in medical predictiveanalytics.</description><author>Tianze Yang, Tianyi Yang, Shaoshan Liu, Fuyuan Lvu, Xue Liu</author><pubDate>Fri, 01 Mar 2024 02:19:25 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.18609v2</guid></item><item><title>Global universal approximation of functional input maps on weighted spaces</title><link>http://arxiv.org/abs/2306.03303v3</link><description>We introduce so-called functional input neural networks defined on a possiblyinfinite dimensional weighted space with values also in a possibly infinitedimensional output space. To this end, we use an additive family to map theinput weighted space to the hidden layer, on which a non-linear scalaractivation function is applied to each neuron, and finally return the outputvia some linear readouts. Relying on Stone-Weierstrass theorems on weightedspaces, we can prove a global universal approximation result on weighted spacesfor continuous functions going beyond the usual approximation on compact sets.This then applies in particular to approximation of (non-anticipative) pathspace functionals via functional input neural networks. As a furtherapplication of the weighted Stone-Weierstrass theorem we prove a globaluniversal approximation result for linear functions of the signature. We alsointroduce the viewpoint of Gaussian process regression in this setting andemphasize that the reproducing kernel Hilbert space of the signature kernelsare Cameron-Martin spaces of certain Gaussian processes. This paves a waytowards uncertainty quantification for signature kernel regression.</description><author>Christa Cuchiero, Philipp Schmocker, Josef Teichmann</author><pubDate>Fri, 01 Mar 2024 02:17:43 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.03303v3</guid></item><item><title>Training generative models from privatized data</title><link>http://arxiv.org/abs/2306.09547v2</link><description>Local differential privacy is a powerful method for privacy-preserving datacollection. In this paper, we develop a framework for training GenerativeAdversarial Networks (GANs) on differentially privatized data. We show thatentropic regularization of optimal transport - a popular regularization methodin the literature that has often been leveraged for its computational benefits- enables the generator to learn the raw (unprivatized) data distribution eventhough it only has access to privatized samples. We prove that at the same timethis leads to fast statistical convergence at the parametric rate. This showsthat entropic regularization of optimal transport uniquely enables themitigation of both the effects of privatization noise and the curse ofdimensionality in statistical convergence. We provide experimental evidence tosupport the efficacy of our framework in practice.</description><author>Daria Reshetova, Wei-Ning Chen, Ayfer Özgür</author><pubDate>Fri, 01 Mar 2024 01:54:15 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.09547v2</guid></item><item><title>CLoVe: Encoding Compositional Language in Contrastive Vision-Language Models</title><link>http://arxiv.org/abs/2402.15021v2</link><description>Recent years have witnessed a significant increase in the performance ofVision and Language tasks. Foundational Vision-Language Models (VLMs), such asCLIP, have been leveraged in multiple settings and demonstrated remarkableperformance across several tasks. Such models excel at object-centricrecognition yet learn text representations that seem invariant to word order,failing to compose known concepts in novel ways. However, no evidence existsthat any VLM, including large-scale single-stream models such as GPT-4V,identifies compositions successfully. In this paper, we introduce a frameworkto significantly improve the ability of existing models to encode compositionallanguage, with over 10% absolute improvement on compositionality benchmarks,while maintaining or improving the performance on standard object-recognitionand retrieval benchmarks. Our code and pre-trained models are publiclyavailable at https://github.com/netflix/clove.</description><author>Santiago Castro, Amir Ziai, Avneesh Saluja, Zhuoning Yuan, Rada Mihalcea</author><pubDate>Fri, 01 Mar 2024 01:52:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15021v2</guid></item><item><title>Neural Refinement for Absolute Pose Regression with Feature Synthesis</title><link>http://arxiv.org/abs/2303.10087v2</link><description>Absolute Pose Regression (APR) methods use deep neural networks to directlyregress camera poses from RGB images. However, the predominant APRarchitectures only rely on 2D operations during inference, resulting in limitedaccuracy of pose estimation due to the lack of 3D geometry constraints orpriors. In this work, we propose a test-time refinement pipeline that leveragesimplicit geometric constraints using a robust feature field to enhance theability of APR methods to use 3D information during inference. We alsointroduce a novel Neural Feature Synthesizer (NeFeS) model, which encodes 3Dgeometric features during training and directly renders dense novel viewfeatures at test time to refine APR methods. To enhance the robustness of ourmodel, we introduce a feature fusion module and a progressive trainingstrategy. Our proposed method achieves state-of-the-art single-image APRaccuracy on indoor and outdoor datasets.</description><author>Shuai Chen, Yash Bhalgat, Xinghui Li, Jiawang Bian, Kejie Li, Zirui Wang, Victor Adrian Prisacariu</author><pubDate>Fri, 01 Mar 2024 01:40:52 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.10087v2</guid></item><item><title>Universality of almost periodicity in bounded discrete time series</title><link>http://arxiv.org/abs/2310.00290v4</link><description>We consider arbitrary bounded discrete time series. From its statisticalfeature, without any use of the Fourier transform, we find an almost periodicfunction which suitably characterizes the corresponding time series.</description><author>Tsuyoshi Yoneda</author><pubDate>Fri, 01 Mar 2024 01:35:36 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.00290v4</guid></item><item><title>SPEED: Experimental Design for Policy Evaluation in Linear Heteroscedastic Bandits</title><link>http://arxiv.org/abs/2301.12357v3</link><description>In this paper, we study the problem of optimal data collection for policyevaluation in linear bandits. In policy evaluation, we are given a targetpolicy and asked to estimate the expected reward it will obtain when executedin a multi-armed bandit environment. Our work is the first work that focuses onsuch optimal data collection strategy for policy evaluation involvingheteroscedastic reward noise in the linear bandit setting. We first formulatean optimal design for weighted least squares estimates in the heteroscedasticlinear bandit setting that reduces the MSE of the value of the target policy.We then use this formulation to derive the optimal allocation of samples peraction during data collection. We then introduce a novel algorithm SPEED(Structured Policy Evaluation Experimental Design) that tracks the optimaldesign and derive its regret with respect to the optimal design. Finally, weempirically validate that SPEED leads to policy evaluation with mean squarederror comparable to the oracle strategy and significantly lower than simplyrunning the target policy.</description><author>Subhojyoti Mukherjee, Qiaomin Xie, Josiah Hanna, Robert Nowak</author><pubDate>Fri, 01 Mar 2024 01:24:03 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2301.12357v3</guid></item><item><title>Spatially-Aware Transformer for Embodied Agents</title><link>http://arxiv.org/abs/2402.15160v3</link><description>Episodic memory plays a crucial role in various cognitive processes, such asthe ability to mentally recall past events. While cognitive science emphasizesthe significance of spatial context in the formation and retrieval of episodicmemory, the current primary approach to implementing episodic memory in AIsystems is through transformers that store temporally ordered experiences,which overlooks the spatial dimension. As a result, it is unclear how theunderlying structure could be extended to incorporate the spatial axis beyondtemporal order alone and thereby what benefits can be obtained. To addressthis, this paper explores the use of Spatially-Aware Transformer models thatincorporate spatial information. These models enable the creation ofplace-centric episodic memory that considers both temporal and spatialdimensions. Adopting this approach, we demonstrate that memory utilizationefficiency can be improved, leading to enhanced accuracy in variousplace-centric downstream tasks. Additionally, we propose the Adaptive MemoryAllocator, a memory management method based on reinforcement learning that aimsto optimize efficiency of memory utilization. Our experiments demonstrate theadvantages of our proposed model in various environments and across multipledownstream tasks, including prediction, generation, reasoning, andreinforcement learning. The source code for our models and experiments will beavailable at https://github.com/junmokane/spatially-aware-transformer.</description><author>Junmo Cho, Jaesik Yoon, Sungjin Ahn</author><pubDate>Fri, 01 Mar 2024 00:58:50 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15160v3</guid></item><item><title>ASPEST: Bridging the Gap Between Active Learning and Selective Prediction</title><link>http://arxiv.org/abs/2304.03870v3</link><description>Selective prediction aims to learn a reliable model that abstains from makingpredictions when uncertain. These predictions can then be deferred to humansfor further evaluation. As an everlasting challenge for machine learning, inmany real-world scenarios, the distribution of test data is different from thetraining data. This results in more inaccurate predictions, and often increaseddependence on humans, which can be difficult and expensive. Active learningaims to lower the overall labeling effort, and hence human dependence, byquerying the most informative examples. Selective prediction and activelearning have been approached from different angles, with the connectionbetween them missing. In this work, we introduce a new learning paradigm,active selective prediction, which aims to query more informative samples fromthe shifted target domain while increasing accuracy and coverage. For this newparadigm, we propose a simple yet effective approach, ASPEST, that utilizesensembles of model snapshots with self-training with their aggregated outputsas pseudo labels. Extensive experiments on numerous image, text and structureddatasets, which suffer from domain shifts, demonstrate that ASPEST cansignificantly outperform prior work on selective prediction and active learning(e.g. on the MNIST$\to$SVHN benchmark with the labeling budget of 100, ASPESTimproves the AUACC metric from 79.36% to 88.84%) and achieves more optimalutilization of humans in the loop.</description><author>Jiefeng Chen, Jinsung Yoon, Sayna Ebrahimi, Sercan Arik, Somesh Jha, Tomas Pfister</author><pubDate>Fri, 01 Mar 2024 00:55:08 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2304.03870v3</guid></item><item><title>SAIE Framework: Support Alone Isn't Enough -- Advancing LLM Training with Adversarial Remarks</title><link>http://arxiv.org/abs/2311.08107v2</link><description>Large Language Models (LLMs) can justify or critique their predictionsthrough discussions with other models or humans, thereby enriching theirintrinsic understanding of instances. While proactive discussions in theinference phase have been shown to boost performance, such interactions havenot been extensively explored during the training phase. We hypothesize thatincorporating interactive discussions into the training process can enhance themodels' understanding and improve their reasoning and verbal expressionabilities during inference. This work introduces the SAIE framework, whichfacilitates supportive and adversarial discussions between learner and partnermodels. The learner model receives responses from the partner, and itsparameters are then updated based on this discussion. This dynamic adjustmentprocess continues throughout the training phase, responding to the evolvingoutputs of the learner model. Our empirical evaluation across various tasks,including math problems, commonsense reasoning, and multi-domain knowledge,demonstrates that models fine-tuned with the SAIE framework outperform thosetrained with conventional fine-tuning approaches. Furthermore, our methodenhances the models' reasoning capabilities, improving both individual andmulti-agent inference performance.</description><author>Mengsay Loem, Masahiro Kaneko, Naoaki Okazaki</author><pubDate>Fri, 01 Mar 2024 00:42:58 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2311.08107v2</guid></item><item><title>SureFED: Robust Federated Learning via Uncertainty-Aware Inward and Outward Inspection</title><link>http://arxiv.org/abs/2308.02747v2</link><description>In this work, we introduce SureFED, a novel framework for byzantine robustfederated learning. Unlike many existing defense methods that rely onstatistically robust quantities, making them vulnerable to stealthy andcolluding attacks, SureFED establishes trust using the local information ofbenign clients. SureFED utilizes an uncertainty aware model evaluation andintrospection to safeguard against poisoning attacks. In particular, eachclient independently trains a clean local model exclusively using its localdataset, acting as the reference point for evaluating model updates. SureFEDleverages Bayesian models that provide model uncertainties and play a crucialrole in the model evaluation process. Our framework exhibits robustness evenwhen the majority of clients are compromised, remains agnostic to the number ofmalicious clients, and is well-suited for non-IID settings. We theoreticallyprove the robustness of our algorithm against data and model poisoning attacksin a decentralized linear regression setting. Proof-of Concept evaluations onbenchmark image classification data demonstrate the superiority of SureFED overthe state of the art defense methods under various colluding and non-colludingdata and model poisoning attacks.</description><author>Nasimeh Heydaribeni, Ruisi Zhang, Tara Javidi, Cristina Nita-Rotaru, Farinaz Koushanfar</author><pubDate>Fri, 01 Mar 2024 00:33:40 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2308.02747v2</guid></item><item><title>Edge Caching Based on Deep Reinforcement Learning and Transfer Learning</title><link>http://arxiv.org/abs/2402.14576v2</link><description>This paper addresses the escalating challenge of redundant data transmissionin networks. The surge in traffic has strained backhaul links and backbonenetworks, prompting the exploration of caching solutions at the edge router.Existing work primarily relies on Markov Decision Processes (MDP) for cachingissues, assuming fixed-time interval decisions; however, real-world scenariosinvolve random request arrivals, and despite the critical role of various filecharacteristics in determining an optimal caching policy, none of the relatedexisting work considers all these file characteristics in forming a cachingpolicy. In this paper, first, we formulate the caching problem using asemi-Markov Decision Process (SMDP) to accommodate the continuous-time natureof real-world scenarios allowing for caching decisions at random times uponfile requests. Then, we propose a double deep Q-learning-based caching approachthat comprehensively accounts for file features such as lifetime, size, andimportance. Simulation results demonstrate the superior performance of ourapproach compared to a recent Deep Reinforcement Learning-based method.Furthermore, we extend our work to include a Transfer Learning (TL) approach toaccount for changes in file request rates in the SMDP framework. The proposedTL approach exhibits fast convergence, even in scenarios with increaseddifferences in request rates between source and target domains, presenting apromising solution to the dynamic challenges of caching in real-worldenvironments.</description><author>Farnaz Niknia, Ping Wang, Zixu Wang, Aakash Agarwal, Adib S. Rezaei</author><pubDate>Fri, 01 Mar 2024 00:21:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14576v2</guid></item><item><title>Large Language Models(LLMs) on Tabular Data: Prediction, Generation, and Understanding -- A Survey</title><link>http://arxiv.org/abs/2402.17944v2</link><description>Recent breakthroughs in large language modeling have facilitated rigorousexploration of their application in diverse tasks related to tabular datamodeling, such as prediction, tabular data synthesis, question answering, andtable understanding. Each task presents unique challenges and opportunities.However, there is currently a lack of comprehensive review that summarizes andcompares the key techniques, metrics, datasets, models, and optimizationapproaches in this research domain. This survey aims to address this gap byconsolidating recent progress in these areas, offering a thorough survey andtaxonomy of the datasets, metrics, and methodologies utilized. It identifiesstrengths, limitations, unexplored territories, and gaps in the existingliterature, while providing some insights for future research directions inthis vital and rapidly evolving field. It also provides relevant code anddatasets references. Through this comprehensive review, we hope to provideinterested readers with pertinent references and insightful perspectives,empowering them with the necessary tools and knowledge to effectively navigateand address the prevailing challenges in the field.</description><author>Xi Fang, Weijie Xu, Fiona Anting Tan, Jiani Zhang, Ziqing Hu, Yanjun Qi, Scott Nickleach, Diego Socolinsky, Srinivasan Sengamedu, Christos Faloutsos</author><pubDate>Fri, 01 Mar 2024 00:14:42 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.17944v2</guid></item><item><title>Tracking and Mapping in Medical Computer Vision: A Review</title><link>http://arxiv.org/abs/2310.11475v2</link><description>As computer vision algorithms increase in capability, their applications inclinical systems will become more pervasive. These applications include:diagnostics, such as colonoscopy and bronchoscopy; guiding biopsies, minimallyinvasive interventions, and surgery; automating instrument motion; andproviding image guidance using pre-operative scans. Many of these applicationsdepend on the specific visual nature of medical scenes and require designingalgorithms to perform in this environment. In this review, we provide an update to the field of camera-based trackingand scene mapping in surgery and diagnostics in medical computer vision. Webegin with describing our review process, which results in a final list of 515papers that we cover. We then give a high-level summary of the state of the artand provide relevant background for those who need tracking and mapping fortheir clinical applications. After which, we review datasets provided in thefield and the clinical needs that motivate their design. Then, we delve intothe algorithmic side, and summarize recent developments. This summary should beespecially useful for algorithm designers and to those looking to understandthe capability of off-the-shelf methods. We maintain focus on algorithms fordeformable environments while also reviewing the essential building blocks inrigid tracking and mapping since there is a large amount of crossover inmethods. With the field summarized, we discuss the current state of thetracking and mapping methods along with needs for future algorithms, needs forquantification, and the viability of clinical applications. We then providesome research directions and questions. We conclude that new methods need to bedesigned or combined to support clinical applications in deformableenvironments, and more focus needs to be put into collecting datasets fortraining and evaluation.</description><author>Adam Schmidt, Omid Mohareri, Simon DiMaio, Michael C. Yip, Septimiu E. Salcudean</author><pubDate>Fri, 01 Mar 2024 00:11:26 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2310.11475v2</guid></item><item><title>DeepGD: A Multi-Objective Black-Box Test Selection Approach for Deep Neural Networks</title><link>http://arxiv.org/abs/2303.04878v5</link><description>Deep neural networks (DNNs) are widely used in various application domainssuch as image processing, speech recognition, and natural language processing.However, testing DNN models may be challenging due to the complexity and sizeof their input domain. Particularly, testing DNN models often requiresgenerating or exploring large unlabeled datasets. In practice, DNN testoracles, which identify the correct outputs for inputs, often require expensivemanual effort to label test data, possibly involving multiple experts to ensurelabeling correctness. In this paper, we propose DeepGD, a black-boxmulti-objective test selection approach for DNN models. It reduces the cost oflabeling by prioritizing the selection of test inputs with high fault revealingpower from large unlabeled datasets. DeepGD not only selects test inputs withhigh uncertainty scores to trigger as many mispredicted inputs as possible butalso maximizes the probability of revealing distinct faults in the DNN model byselecting diverse mispredicted inputs. The experimental results conducted onfour widely used datasets and five DNN models show that in terms offault-revealing ability: (1) White-box, coverage-based approaches fare poorly,(2) DeepGD outperforms existing black-box test selection approaches in terms offault detection, and (3) DeepGD also leads to better guidance for DNN modelretraining when using selected inputs to augment the training set.</description><author>Zohreh Aghababaeyan, Manel Abdellatif, Mahboubeh Dadkhah, Lionel Briand</author><pubDate>Thu, 29 Feb 2024 23:37:29 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2303.04878v5</guid></item><item><title>Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects</title><link>http://arxiv.org/abs/2306.10125v3</link><description>Self-supervised learning (SSL) has recently achieved impressive performanceon various time series tasks. The most prominent advantage of SSL is that itreduces the dependence on labeled data. Based on the pre-training andfine-tuning strategy, even a small amount of labeled data can achieve highperformance. Compared with many published self-supervised surveys on computervision and natural language processing, a comprehensive survey for time seriesSSL is still missing. To fill this gap, we review current state-of-the-art SSLmethods for time series data in this article. To this end, we firstcomprehensively review existing surveys related to SSL and time series, andthen provide a new taxonomy of existing time series SSL methods by summarizingthem from three perspectives: generative-based, contrastive-based, andadversarial-based. These methods are further divided into ten subcategorieswith detailed reviews and discussions about their key intuitions, mainframeworks, advantages and disadvantages. To facilitate the experiments andvalidation of time series SSL methods, we also summarize datasets commonly usedin time series forecasting, classification, anomaly detection, and clusteringtasks. Finally, we present the future directions of SSL for time seriesanalysis.</description><author>Kexin Zhang, Qingsong Wen, Chaoli Zhang, Rongyao Cai, Ming Jin, Yong Liu, James Zhang, Yuxuan Liang, Guansong Pang, Dongjin Song, Shirui Pan</author><pubDate>Thu, 29 Feb 2024 23:23:33 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2306.10125v3</guid></item><item><title>Distribution-Specific Auditing For Subgroup Fairness</title><link>http://arxiv.org/abs/2401.16439v2</link><description>We study the problem of auditing classifiers with the notion of statisticalsubgroup fairness. Kearns et al. (2018) has shown that the problem of auditingcombinatorial subgroups fairness is as hard as agnostic learning. Essentiallyall work on remedying statistical measures of discrimination against subgroupsassumes access to an oracle for this problem, despite the fact that noefficient algorithms are known for it. If we assume the data distribution isGaussian, or even merely log-concave, then a recent line of work has discoveredefficient agnostic learning algorithms for halfspaces. Unfortunately, thereduction of Kearns et al. was formulated in terms of weak, "distribution-free"learning, and thus did not establish a connection for families such aslog-concave distributions. In this work, we give positive and negative results on auditing for Gaussiandistributions: On the positive side, we present an alternative approach toleverage these advances in agnostic learning and thereby obtain the firstpolynomial-time approximation scheme (PTAS) for auditing nontrivialcombinatorial subgroup fairness: we show how to audit statistical notions offairness over homogeneous halfspace subgroups when the features are Gaussian.On the negative side, we find that under cryptographic assumptions, nopolynomial-time algorithm can guarantee any nontrivial auditing, even underGaussian feature distributions, for general halfspace subgroups.</description><author>Daniel Hsu, Jizhou Huang, Brendan Juba</author><pubDate>Thu, 29 Feb 2024 23:18:38 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2401.16439v2</guid></item><item><title>Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation</title><link>http://arxiv.org/abs/2402.03268v2</link><description>Pre-trained language models (LMs) are able to perform complex reasoningwithout explicit fine-tuning. To understand how pre-training with a next-tokenprediction objective contributes to the emergence of such reasoning capability,we propose that we can view an LM as deriving new conclusions by aggregatingindirect reasoning paths seen at pre-training time. We found this perspectiveeffective in two important cases of reasoning: logic reasoning with knowledgegraphs (KGs) and math reasoning with math word problems (MWPs). Morespecifically, we formalize the reasoning paths as random walk paths on theknowledge/reasoning graphs. Analyses of learned LM distributions suggest that aweighted sum of relevant random walk path probabilities is a reasonable way toexplain how LMs reason. Experiments and analysis on multiple KG and MWPdatasets reveal the effect of training on random walk paths and suggest thataugmenting unlabeled random walk reasoning paths can improve real-worldmulti-step reasoning performance. code:https://github.com/WANGXinyiLinda/LM_random_walk</description><author>Xinyi Wang, Alfonso Amayuelas, Kexun Zhang, Liangming Pan, Wenhu Chen, William Yang Wang</author><pubDate>Thu, 29 Feb 2024 22:54:09 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.03268v2</guid></item><item><title>Prejudice and Caprice: A Statistical Framework for Measuring Social Discrimination in Large Language Models</title><link>http://arxiv.org/abs/2402.15481v3</link><description>The growing integration of large language models (LLMs) into socialoperations amplifies their impact on decisions in crucial areas such aseconomics, law, education, and healthcare, raising public concerns about thesemodels' discrimination-related safety and reliability. However, priordiscrimination measuring frameworks solely assess the average discriminatorybehavior of LLMs, often proving inadequate due to the overlook of an additionaldiscrimination-leading factor, i.e., the LLMs' prediction variation acrossdiverse contexts. In this work, we present the Prejudice-Caprice Framework(PCF) that comprehensively measures discrimination in LLMs by considering boththeir consistently biased preference and preference variation across diversecontexts. Specifically, we mathematically dissect the aggregated contextualizeddiscrimination risk of LLMs into prejudice risk, originating from LLMs'persistent prejudice, and caprice risk, stemming from their generationinconsistency. In addition, we utilize a data-mining approach to gatherpreference-detecting probes from sentence skeletons, devoid of attributeindications, to approximate LLMs' applied contexts. While initially intendedfor assessing discrimination in LLMs, our proposed PCF facilitates thecomprehensive and flexible measurement of any inductive biases, includingknowledge alongside prejudice, across various modality models. We apply ourdiscrimination-measuring framework to 12 common LLMs, yielding intriguingfindings: i) modern LLMs demonstrate significant pro-male stereotypes, ii)LLMs' exhibited discrimination correlates with several social and economicfactors, iii) prejudice risk dominates the overall discrimination risk andfollows a normal distribution, and iv) caprice risk contributes minimally tothe overall risk but follows a fat-tailed distribution, suggesting that it iswild risk requiring enhanced surveillance.</description><author>Yiran Liu, Ke Yang, Zehan Qi, Xiao Liu, Yang Yu, Chengxiang Zhai</author><pubDate>Thu, 29 Feb 2024 22:50:10 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.15481v3</guid></item><item><title>Distributional Bellman Operators over Mean Embeddings</title><link>http://arxiv.org/abs/2312.07358v2</link><description>We propose a novel algorithmic framework for distributional reinforcementlearning, based on learning finite-dimensional mean embeddings of returndistributions. We derive several new algorithms for dynamic programming andtemporal-difference learning based on this framework, provide asymptoticconvergence theory, and examine the empirical performance of the algorithms ona suite of tabular tasks. Further, we show that this approach can bestraightforwardly combined with deep reinforcement learning, and obtain a newdeep RL agent that improves over baseline distributional approaches on theArcade Learning Environment.</description><author>Li Kevin Wenliang, Grégoire Déletang, Matthew Aitchison, Marcus Hutter, Anian Ruoss, Arthur Gretton, Mark Rowland</author><pubDate>Thu, 29 Feb 2024 22:49:37 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.07358v2</guid></item><item><title>AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation</title><link>http://arxiv.org/abs/2402.14978v2</link><description>The growing availability of generative AI technologies such as large languagemodels (LLMs) has significant implications for creative work. This paperexplores twofold aspects of integrating LLMs into the creative process - thedivergence stage of idea generation, and the convergence stage of evaluationand selection of ideas. We devised a collaborative group-AI Brainwritingideation framework, which incorporated an LLM as an enhancement into the groupideation process, and evaluated the idea generation process and the resultedsolution space. To assess the potential of using LLMs in the idea evaluationprocess, we design an evaluation engine and compared it to idea ratingsassigned by three expert and six novice evaluators. Our findings suggest thatintegrating LLM in Brainwriting could enhance both the ideation process and itsoutcome. We also provide evidence that LLMs can support idea evaluation. Weconclude by discussing implications for HCI education and practice.</description><author>Orit Shaer, Angelora Cooper, Osnat Mokryn, Andrew L. Kun, Hagit Ben Shoshan</author><pubDate>Thu, 29 Feb 2024 22:47:21 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2402.14978v2</guid></item><item><title>On Rate-Optimal Partitioning Classification from Observable and from Privatised Data</title><link>http://arxiv.org/abs/2312.14889v2</link><description>In this paper we revisit the classical method of partitioning classificationand study its convergence rate under relaxed conditions, both for observable(non-privatised) and for privatised data. Let the feature vector $X$ takevalues in $\mathbb{R}^d$ and denote its label by $Y$. Previous results on thepartitioning classifier worked with the strong density assumption, which isrestrictive, as we demonstrate through simple examples. We assume that thedistribution of $X$ is a mixture of an absolutely continuous and a discretedistribution, such that the absolutely continuous component is concentrated toa $d_a$ dimensional subspace. Here, we study the problem under much milderassumptions: in addition to the standard Lipschitz and margin conditions, anovel characteristic of the absolutely continuous component is introduced, bywhich the exact convergence rate of the classification error probability iscalculated, both for the binary and for the multi-label cases. Interestingly,this rate of convergence depends only on the intrinsic dimension $d_a$. The privacy constraints mean that the data $(X_1,Y_1), \dots ,(X_n,Y_n)$cannot be directly observed, and the classifiers are functions of therandomised outcome of a suitable local differential privacy mechanism. Thestatistician is free to choose the form of this privacy mechanism, and here weadd Laplace distributed noises to the discontinuations of all possiblelocations of the feature vector $X_i$ and to its label $Y_i$. Again, tightupper bounds on the rate of convergence of the classification error probabilityare derived, without the strong density assumption, such that this rate dependson $2\,d_a$.</description><author>Balázs Csanád Csáji, László Györfi, Ambrus Tamás, Harro Walk</author><pubDate>Thu, 29 Feb 2024 22:41:23 GMT</pubDate><guid isPermaLink="true">http://arxiv.org/abs/2312.14889v2</guid></item></channel></rss>